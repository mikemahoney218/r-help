From r.turner at auckland.ac.nz  Wed Oct  1 00:04:32 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 01 Oct 2014 11:04:32 +1300
Subject: [R] Best Distribution
In-Reply-To: <BLU170-W1308F77900877D55E6C065B89BB0@phx.gbl>
References: <BLU170-W1308F77900877D55E6C065B89BB0@phx.gbl>
Message-ID: <542B28F0.2040301@auckland.ac.nz>

On 01/10/14 08:50, eliza botto wrote:
> Dear useRs,
> I have this following data
>> dput(Prec)
> c(42.2, 45.2, 46, 48, 54, 54.1, 59.4, 61, 62.2, 63.5, 65.024, 71.9, 73.4, 76.6, 76.708, 77.5, 77.724, 78, 81.3, 84.7, 84.836, 85.09, 88.2, 91.4, 94, 95.8, 96, 97.3, 101, 101, 101.5, 102.3, 102.87, 108.7, 109.5, 110.5, 110.7, 112, 114.3, 118.11, 121.412, 128.1, 131, 140, 142, 143.3, 151.4, 153.7, 189.4, 214.3)
> I want to fit gumbel and log-normal distribution on it on the same window to see which distribution fits it the best way.
> Thankyou very much in advance.


If I understand you correctly the attached script should do what you want.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS
-------------- next part --------------
#
# Script botto.txt
#

require(MASS)
require(FAdist)

x <- c(42.2, 45.2, 46, 48, 54, 54.1, 59.4, 61, 62.2, 63.5, 65.024,
       71.9, 73.4, 76.6, 76.708, 77.5, 77.724, 78, 81.3, 84.7, 84.836,
       85.09, 88.2, 91.4, 94, 95.8, 96, 97.3, 101, 101, 101.5, 102.3,
       102.87, 108.7, 109.5, 110.5, 110.7, 112, 114.3, 118.11, 121.412,
       128.1, 131, 140, 142, 143.3, 151.4, 153.7, 189.4, 214.3)
dx <- density(x)
s <- sd(x)
xbar <- mean(x)
beta.hat <- 6*s/pi
mu.hat <- xbar - 0.5772*beta.hat
fit.g <- suppressWarnings(fitdistr(x,dgumbel,start=list(location=mu.hat,scale=beta.hat)))
fit.ln <- fitdistr(x,"lognormal")
cg <- fit.g$estimate
cln <- fit.ln$estimate
plot(dx,xlab="x",ylab="density",main="Comparison of fits",ylim=c(0,0.015))
plot(function(x){dgumbel(x,location=cg[1],scale=cg[2])},from=0,to=250,add=TRUE,col="red")
plot(function(x){dlnorm(x,meanlog=cln[1],sdlog=cln[2])},from=0,to=250,add=TRUE,col="blue")
legend("topright",lty=1,col=c("black","red","blue"),
       legend=c("non-parametric density","fitted Gumbel density",
                "fitted log normal density"))

From NordlDJ at dshs.wa.gov  Wed Oct  1 00:18:32 2014
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 30 Sep 2014 22:18:32 +0000
Subject: [R] Reading text file with fortran format
In-Reply-To: <542b1ac8.1228ec0a.1a92.23c7@mx.google.com>
References: <542b1ac8.1228ec0a.1a92.23c7@mx.google.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA276623A7F63C@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Steven Yen
> Sent: Tuesday, September 30, 2014 2:04 PM
> To: r-help
> Subject: [R] Reading text file with fortran format
> 
> Hello
> 
> I read data with fortran format:
> mydata<-read.fortran('foo.txt',
>                       c("4F10.4","F8.3","3F3.0","20F2.0"))
> colnames(mydata)<-c("q1","q2","q3","q4","income","hhsize",
>   "weekend","dietk","quart1","quart2","quart3","male","age35",
>   "age50","age65","midwest","south","west","nonmetro",
>   "suburb","black","asian","other","hispan","hhtype1",
>   "hhtype2","hhtype3","emp_stat")
> dstat(mydata,digits=6)
> 
> I produced the following sample statistics for the first 4
> variables (q1,q2,q3,q4):
> 
>               Mean  Std.dev Min       Max  Obs
> q1       0.000923 0.002509   0  0.035245 5649
> q2       0.000698 0.001681   0  0.038330 5649
> q3       0.000766 0.002138   0  0.040100 5649
> q4       0.000373 0.001140   0  0.026374 5649
> 
> The correct sample statistics are:
> Variable|       Mean       Std.Dev.     Minimum      Maximum
> --------+----------------------------------------------------
>        Q1|     9.227632     25.09311          0.0     352.4508
>        Q2|     6.983078     16.80984          0.0     383.2995
>        Q3|     7.657381     21.38337          0.0     400.9950
>        Q4|     3.727952     11.40446          0.0     263.7398
>    INCOME|     16.01603     13.70296          0.0        100.0
>    HHSIZE|     2.586475     1.464282          1.0         16.0
> 
> In other words, values for q1-q4 were scaled down by a factor of
> 10,000.
> My raw data look like (with proper format)
> 
>      0.0000    0.0000    0.0000    0.0000  48.108...
>      0.0000    0.0000    0.0000    0.0000  11.640...
>     35.3450    0.0000   95.7656    0.0000   4.667...
>      0.0000    0.0000    0.0000    0.0000   9.000...
>     84.0000    4.8038    0.0000    3.1886   2.923...
>      0.0000    0.0000    0.0000    1.1636  10.000...
>      0.0000   10.7818  109.7884    0.0000  17.000...
>      0.0000    7.9528    0.0000    4.7829  35.000...
> 
> True that the data here are space delimited. But I need to read data
> elsewhere where data are not space delimited.
> 
> Any idea/suggestion would be appreciated.
> 

The read.fortran function appears to work differently from how FORTRAN would read the data if there are already decimals points in the numbers.  If memory serves, FORTRAN ignores the decimal portion of the format if it finds a decimal in what it reads.  The read.fortran function appears to read the number 'as is' and then multiplies by 10^-d, where d is the number of decimal places in the format.  Since you have decimals specified, you should specify the format with 0 decimal places, i.e.

c("4F10.0","F8.0","3F3.0","20F2.0"))


hope this is helpful,

Dan


Daniel J. Nordlund, PhD
Research and Data Analysis Division
Services & Enterprise Support Administration
Washington State Department of Social and Health Services



From syen04 at gmail.com  Wed Oct  1 00:22:37 2014
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 30 Sep 2014 18:22:37 -0400
Subject: [R] Reading text file with fortran format
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276623A7F63C@WAXMXOLYMB025.WAX
	.wa.lcl>
References: <542b1ac8.1228ec0a.1a92.23c7@mx.google.com>
	<F7E6D18CC2877149AB5296CE54EA276623A7F63C@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <542b2d2e.c832ec0a.4abf.ffffc33e@mx.google.com>

Thanks to all.
Steven Yen

At 06:18 PM 9/30/2014, Nordlund, Dan (DSHS/RDA) wrote:
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Steven Yen
> > Sent: Tuesday, September 30, 2014 2:04 PM
> > To: r-help
> > Subject: [R] Reading text file with fortran format
> >
> > Hello
> >
> > I read data with fortran format:
> > mydata<-read.fortran('foo.txt',
> >                       c("4F10.4","F8.3","3F3.0","20F2.0"))
> > colnames(mydata)<-c("q1","q2","q3","q4","income","hhsize",
> >   "weekend","dietk","quart1","quart2","quart3","male","age35",
> >   "age50","age65","midwest","south","west","nonmetro",
> >   "suburb","black","asian","other","hispan","hhtype1",
> >   "hhtype2","hhtype3","emp_stat")
> > dstat(mydata,digits=6)
> >
> > I produced the following sample statistics for the first 4
> > variables (q1,q2,q3,q4):
> >
> >               Mean  Std.dev Min       Max  Obs
> > q1       0.000923 0.002509   0  0.035245 5649
> > q2       0.000698 0.001681   0  0.038330 5649
> > q3       0.000766 0.002138   0  0.040100 5649
> > q4       0.000373 0.001140   0  0.026374 5649
> >
> > The correct sample statistics are:
> > Variable|       Mean       Std.Dev.     Minimum      Maximum
> > --------+----------------------------------------------------
> >        Q1|     9.227632     25.09311          0.0     352.4508
> >        Q2|     6.983078     16.80984          0.0     383.2995
> >        Q3|     7.657381     21.38337          0.0     400.9950
> >        Q4|     3.727952     11.40446          0.0     263.7398
> >    INCOME|     16.01603     13.70296          0.0        100.0
> >    HHSIZE|     2.586475     1.464282          1.0         16.0
> >
> > In other words, values for q1-q4 were scaled down by a factor of
> > 10,000.
> > My raw data look like (with proper format)
> >
> >      0.0000    0.0000    0.0000    0.0000  48.108...
> >      0.0000    0.0000    0.0000    0.0000  11.640...
> >     35.3450    0.0000   95.7656    0.0000   4.667...
> >      0.0000    0.0000    0.0000    0.0000   9.000...
> >     84.0000    4.8038    0.0000    3.1886   2.923...
> >      0.0000    0.0000    0.0000    1.1636  10.000...
> >      0.0000   10.7818  109.7884    0.0000  17.000...
> >      0.0000    7.9528    0.0000    4.7829  35.000...
> >
> > True that the data here are space delimited. But I need to read data
> > elsewhere where data are not space delimited.
> >
> > Any idea/suggestion would be appreciated.
> >
>
>The read.fortran function appears to work differently from how 
>FORTRAN would read the data if there are already decimals points in 
>the numbers.  If memory serves, FORTRAN ignores the decimal portion 
>of the format if it finds a decimal in what it reads.  The 
>read.fortran function appears to read the number 'as is' and then 
>multiplies by 10^-d, where d is the number of decimal places in the 
>format.  Since you have decimals specified, you should specify the 
>format with 0 decimal places, i.e.
>
>c("4F10.0","F8.0","3F3.0","20F2.0"))
>
>
>hope this is helpful,
>
>Dan
>
>
>Daniel J. Nordlund, PhD
>Research and Data Analysis Division
>Services & Enterprise Support Administration
>Washington State Department of Social and Health Services


From eliza_botto at hotmail.com  Wed Oct  1 00:30:41 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 30 Sep 2014 22:30:41 +0000
Subject: [R] Best Distribution
In-Reply-To: <542B28F0.2040301@auckland.ac.nz>
References: <BLU170-W1308F77900877D55E6C065B89BB0@phx.gbl>,
	<542B28F0.2040301@auckland.ac.nz>
Message-ID: <BLU170-W1228EF5DDE7792628140F4789BB0@phx.gbl>

Dear Turner and Murphy,
Thankyou so very much for replying. It fixed the issue.
:) 
Eliza 
> Date: Wed, 1 Oct 2014 11:04:32 +1300
> From: r.turner at auckland.ac.nz
> To: eliza_botto at hotmail.com; r-help at r-project.org
> Subject: Re: [R] Best Distribution
> 
> On 01/10/14 08:50, eliza botto wrote:
> > Dear useRs,
> > I have this following data
> >> dput(Prec)
> > c(42.2, 45.2, 46, 48, 54, 54.1, 59.4, 61, 62.2, 63.5, 65.024, 71.9, 73.4, 76.6, 76.708, 77.5, 77.724, 78, 81.3, 84.7, 84.836, 85.09, 88.2, 91.4, 94, 95.8, 96, 97.3, 101, 101, 101.5, 102.3, 102.87, 108.7, 109.5, 110.5, 110.7, 112, 114.3, 118.11, 121.412, 128.1, 131, 140, 142, 143.3, 151.4, 153.7, 189.4, 214.3)
> > I want to fit gumbel and log-normal distribution on it on the same window to see which distribution fits it the best way.
> > Thankyou very much in advance.
> 
> 
> If I understand you correctly the attached script should do what you want.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Rolf Turner
> Technical Editor ANZJS
 		 	   		  
	[[alternative HTML version deleted]]


From phil at pricom.com.au  Wed Oct  1 02:32:57 2014
From: phil at pricom.com.au (Philip Rhoades)
Date: Wed, 1 Oct 2014 10:32:57 +1000
Subject: [R] Using R for modelling Australian Senate Election in NSW?
Message-ID: <341813da77b61a5bec0c121cbae5af0b@localhost>

People,

I am setting up an Australian Science and Technology party with Human 
Health and Longevity as it's defining, first platform plank:

   http://lestp.org

and intend to run Senate candidates at the next Federal Election (due 
late 2016).  Senators are elected from each State and Territory using a 
Proportional Representation (PR) method but it is complex and odd things 
happen with direction of preferences when the smallest groups or 
individuals are progressively eliminated from the count when producing 
the final quotas.  I have a little experience with R but it seems like 
it might be useful for modelling this situation?  A quota for a 
half-senate election (six senators to be elected in each state) is one 
seventh of the total number of votes + one vote.

My current thoughts are these:

- each Senate vote corresponds to a vector with say 80 numbers on it 
(corresponding to 80 candidates - some grouped into parties, some as 
individuals)

- the order of the numbers from 1-80 could be random on the ballot but 
in practice, there will be many identical ballots corresponding to the 
voting preference recommendations of the major parties

- the groups of votes with enough first preference votes (number "1"s) 
that constitute a "quota" will have their first candidate declared 
elected and their quota subtracted from the party's total votes - this 
process continues until there are no full quotas left to allocate

- the next stage is the elimination process - the party / individual 
with the lowest number of votes is eliminated and their second 
preference votes (their number "2"s) will be added to the count 
corresponding to the that individual - this process continues until 
another person has enough votes for a quota

- the previous exercise is repeated until all quotas have been allocated

- I can generate the approximate simulation vectors from previous data 
OK but am not sure how how to proceed with the "elimination" process 
coding etc.

Suggestions (so I don't waste too much time re-inventing wheels etc) 
would be much appreciated!

Regards,

Phil.

-- 
Philip Rhoades

GPO Box 3411
Sydney NSW	2001
Australia
E-mail:  phil at pricom.com.au


From geomodelers at gmail.com  Wed Oct  1 05:54:04 2014
From: geomodelers at gmail.com (Andre)
Date: Wed, 1 Oct 2014 10:54:04 +0700
Subject: [R] Inverse Student t-value
In-Reply-To: <OF64AC775B.53D06187-ON85257D63.006B1EFA-85257D63.006C02CD@ria.buffalo.edu>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
	<CALzoxKDOxpCYeWbwT-JAvKOMeZCzpXH1Av4ht4qk3spakOHg7A@mail.gmail.com>
	<OF64AC775B.53D06187-ON85257D63.006B1EFA-85257D63.006C02CD@ria.buffalo.edu>
Message-ID: <CALzoxKBKHTWiJV82Uoc1nWLYEVixvFmtAseCqiO0k4arMQXQ+Q@mail.gmail.com>

Hi JLucke,

Maybe the old excel function. TINV and T.INV.2T is same function for Two-Tailed
Inverse of the student`s t-distribution but T.INV use for Left-Tailed
inverse of the Student's t-distribution and can be use for  Inverse of the
student`s t-distribution.


I know automatic or functions any software but I just need a manual formula
or compute formula (TINV or T.INV.2T) step by step presented by math for
calculate until resulted.

Thanks in advance.


Cheers!



On Wed, Oct 1, 2014 at 2:39 AM, <JLucke at ria.buffalo.edu> wrote:

> The website has your answer.  The t-distribution is a regularized
> incomplete beta function.  The incomplete beta function is given by R's
> *pbeta* function.  You regularize it with R's *beta* function.  Then you
> use R's *uniroot* function to find the inverse.  Good homework problem.
>
>
>  *Andre <geomodelers at gmail.com <geomodelers at gmail.com>>*
> Sent by: r-help-bounces at r-project.org
>
> 09/30/2014 02:45 PM
>   To
> Duncan Murdoch <murdoch.duncan at gmail.com>,
> cc
> "r-help at r-project.org" <r-help at r-project.org>
> Subject
> Re: [R] Inverse Student t-value
>
>
>
>
> Hi Duncan,
>
> Let me explain again, I just need a manual expression for inverse student t
> value.
>
> You could go to web page
> http://www.danielsoper.com/statcalc3/calc.aspx?id=10
>
> That's inverse student t value calculator. Do you know a manual expression
> use it.
>
> Cheers!
>
>
> On Wednesday, October 1, 2014, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
> > On 30/09/2014 2:26 PM, Andre wrote:
> >
> >> Hi Duncan,
> >>
> >> Actually, I am trying trace the formula for the "Critical value of Z"
> and
> >> manual formula is =(I7-1)/SQRT(I7)*SQRT((TINV(0.
> >> 05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
> >>
> >> So, I got new problem for TINV formula. I just need a manual equation
> for
> >> TINV.
> >>
> >
> > Sorry, can't help.  I'm not sure I understand what you want, but if it's
> a
> > simple formula for quantiles of the t distribution, it doesn't exist.
> >
> > Duncan Murdoch
> >
> >
> >> Hope solve this problem.
> >>
> >> Cheers!
> >>
> >>
> >> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch <
> murdoch.duncan at gmail.com
> >> <mailto:murdoch.duncan at gmail.com <murdoch.duncan at gmail.com>>> wrote:
> >>
> >>     On 30/09/2014 2:11 PM, Andre wrote:
> >>
> >>         Hi Duncan,
> >>
> >>         No, that's correct. Actually, I have data set below;
> >>
> >>
> >>     Then it seems Excel is worse than I would have expected.  I
> >>     confirmed R's value in two other pieces of software,
> >>     OpenOffice and some software I wrote a long time ago based on an
> >>     algorithm published in 1977 in Applied Statistics. (They are
> >>     probably all using the same algorithm.  I wonder what Excel is
> doing?)
> >>
> >>         N= 1223
> >>         alpha= 0.05
> >>
> >>         Then
> >>         probability= 0.05/1223=0.0000408831
> >>         degree of freedom= 1223-2= 1221
> >>
> >>         So, TINV(0.0000408831,1221) returns 4.0891672
> >>
> >>
> >>         Could you show me more detail a manual equation. I really
> >>         appreciate it if you may give more detail.
> >>
> >>
> >>     I already gave you the expression:  abs(qt(0.0000408831/2,
> >>     df=1221)). For more detail, I suppose you could look at the help
> >>     page for the qt function, using help("qt").
> >>
> >>     Duncan Murdoch
> >>
> >>
> >>         Cheers!
> >>
> >>
> >>         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
> >>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com
> <murdoch.duncan at gmail.com>>
> >>         <mailto:murdoch.duncan at gmail.com <murdoch.duncan at gmail.com>
> >>         <mailto:murdoch.duncan at gmail.com <murdoch.duncan at gmail.com>
> >>> wrote:
>
> >>
> >>             On 30/09/2014 1:31 PM, Andre wrote:
> >>
> >>                 Dear Sir/Madam,
> >>
> >>                 I am trying to use calculation for two-tailed inverse
> >>         of the
> >>                 student`s
> >>                 t-distribution function presented by Excel functions
> like
> >>                 =TINV(probability, deg_freedom).
> >>
> >>                 For instance: The Excel function
> >>         =TINV(0.0000408831,1221) =         returns
> >>                   4.0891672.
> >>
> >>                 Would you like to show me a manual calculation for this?
> >>
> >>                 Appreciate your helps in advance.
> >>
> >>
> >>             That number looks pretty far off the true value. Have you
> >>         got a
> >>             typo in your example?
> >>
> >>             You can compute the answer to your question as
> >>             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
> >>
> >>             Duncan Murdoch
> >>
> >>
> >>
> >>
> >>
> >>
> >
>
>                 [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From sarah.hardy at maine.edu  Wed Oct  1 01:00:56 2014
From: sarah.hardy at maine.edu (Sarah Hardy)
Date: Tue, 30 Sep 2014 19:00:56 -0400
Subject: [R] uninstalled and reinstalled R, now cannot install packages
Message-ID: <CAFg2G_vteKmdGwOsddotZOGkLmtTRzhcbGe-rA9bHTp3NXfajQ@mail.gmail.com>

 Hello,

I have a student (running Windows 8) who ran into a problem installing the
RcmdrPlugin.IPSUR package and, despite instructions to the contrary,
uninstalled R and reinstalled. He uninstalled it using the Windows 8
utility. Now he cannot install any packages.

Here are the error messages he gets when he gets when he trys to use the
menu to install a package:
> utils:::menuInstallPkgs()
--- Please select a CRAN mirror for use in this session ---
Warning: unable to access index for repository
http://cran.mirrors.hoobly.com/bin/windows/contrib/3.1
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
type) :
  no packages were specified
In addition: Warning message:
In open.connection(con, "r") :
  unable to connect to 'cran.r-project.org' on port 80.

Here are the messages he gets when using the install.packages command (it
doesn't matter what package he tries to install):

> install.packages("rpart")
Installing package into
?C:/Users/michael.bottai/Documents/R/win-library/3.1?
(as ?lib? is unspecified)
Warning: unable to access index for repository
http://cran.mirrors.hoobly.com/bin/windows/contrib/3.1
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
Warning message:
package ?rpart? is not available (for R version 3.1.1)

Any help will be greatly appreciated!

Thank you,
Sarah


-- 
Sarah Hardy, PhD
Associate Professor of Mathematics
University of Maine Farmington
207-778-7124    Office: Brinkman 100

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Wed Oct  1 06:35:23 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 1 Oct 2014 04:35:23 +0000
Subject: [R] Converting factor data into Date-time format
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9CA76@mb02.ads.tamu.edu>
References: <BAY179-W2140BC8DC38D20EFEE65A0B9BB0@phx.gbl>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9CA76@mb02.ads.tamu.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8809@SRVEXCHMBX.precheza.cz>

Hi

Everything seems to be OK. Please check your if your objects are as required by.

str(objects) (and post result if you are in doubt :)

from your attempts I presume that datetime was not created properly
Maybe this can do it, without actual data it is hard to tell exactly.

datetime=as.POSIXct(strptime(paste(l10$Date, l10$Time, sep=" "),format="%m/%d/%Y %H:%M:%S"))

BTW, factors can be converted to POSIX class the same way as character vectors are.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of David L Carlson
> Sent: Tuesday, September 30, 2014 10:43 PM
> To: tandi perkins; r-help at r-project.org
> Subject: Re: [R] Converting factor data into Date-time format
>
> First, use stringsAsFactors=FALSE with the read.csv() function. That
> will prevent the conversion to factors. Then try to convert date and
> time to datetime objects.
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of tandi perkins
> Sent: Tuesday, September 30, 2014 12:55 PM
> To: r-help at r-project.org
> Subject: [R] Converting factor data into Date-time format
>
> Hello R help:
>
>
>
> I am
> new to this forum so I apologize in advance for any protocol missteps.
> I have a data set that is comprised of eight birds with GPS; each of
> which transmit everyday at 8:00 am, 4:00 pm, and midnight for 1 year
> (although I have some missing relocation's).  I am trying to format my
> data to be run in adehabitatLT but I am unsuccessful.  I have a "csv"
> file with the following header: "Craneid, Date, Time, Long, Lat,
> Habitat, BurstID".  R creates factor levels in the all of the data
> except Lat, Long. I have attempted the following to correctly format my
> date and time factors (data=l10):
>
>
>
> First
> attempt:
>
> 1.
>  datetime=as.POSIXct(paste(l10$Date, l10$Time), format="%m/%d/%Y
> %H:%M:%S", "America/Chicago")
>
>
>
> 2.
> coord=data.frame((l10$Longitude), (l10$Latitude))
>
>
>
> 3.
> test=as.ltraj(coord, datetime, l10$Craneid, burst=l10$ID, typeII=TRUE)
>
>
>
> Results:Error
> in as.ltraj(coord, datetime, l10$Craneid, burst = l10$ID, typeII =
> TRUE) :
>
>
> non unique dates for a given burst
>
>
>
> I
> researched this error on the list serve and found that I could have
> duplicates so I checked for duplicates in datetime and the return was
> NULL (I also check for duplicates in Excel as I am in the learning
> stages in R).  Next I read a thread posted on the R help in 2012 with a
> similar problem so I attempted what was suggested as follows:
>
>
>
> 1.
>  datetime=as.POSIXct(strptime(as.character(l10$Date, l10$Time),
> format="%m/%d/%Y %H:%M:%S"))
>
>
>
> 2.test=as.ltraj(coord,
> datetime, l10$Craneid, burst=l10$ID, typeII=TRUE)
>
>
>
> Results:
> Same error.
>
>
>
> Finally,
> I have tried:
>
>
>
> 1.
>  datetime=as.POSIXct(as.character(levels(l10$Date)(l10$Time)),
> format="%m/%d/%Y %H:%M:%S")[l10$Date][l10$Time]
>
>
>
> Results:Error
> in as.POSIXct(as.character(levels(l10$Date)(l10$Time)), format =
> "%m/%d/%Y
> %H:%M:%S") :
>
>
> attempt to apply non-function
>
>
>
> Can
> someone please explain what I am doing wrong?  My goal is to obtain
> trajectories for all birds using each bird as a burst as is detailed in
> the adehabitatLT manual and then to create Bias Random Bridges for each
> bird.
>  I did not include my data but I can if that will be helpful.
>
>
>
> Thank
> you in advance for your help,
>
> TLP
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Wed Oct  1 11:02:26 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 1 Oct 2014 10:02:26 +0100
Subject: [R] uninstalled and reinstalled R, now cannot install packages
In-Reply-To: <CAFg2G_vteKmdGwOsddotZOGkLmtTRzhcbGe-rA9bHTp3NXfajQ@mail.gmail.com>
References: <CAFg2G_vteKmdGwOsddotZOGkLmtTRzhcbGe-rA9bHTp3NXfajQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED641296152C@GOLD.corp.lgc-group.com>

Inability to access a repository index is very often an indication of a failed internet connection from R. In Windows that is often a result of incorrect proxy settings or other internet connection settings. The R Windows FAQ, 2.19 ("The Internet download functions fail") may have the answer...

As a quick diagnostic, try running  
setInternet2(use = TRUE)

as the _first_ thing after starting R. This will effectively cause R to use the same settings as Internet Explorer. If that works, add the flag --internet2 to the command line in the R shortcut. 
If that fixes the problem, edit the Windows shortcut to include --internet2 in the command lione.

If it fails, see Windows FAQ 2.19 (b). 


have a look at either edit your local R config file to use internet2 instead of the default, or reinstall R, setting the Internet2 option during the installation process.



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Sarah Hardy
> Sent: 01 October 2014 00:01
> To: r-help at r-project.org
> Subject: [R] uninstalled and reinstalled R, now cannot install packages
> 
>  Hello,
> 
> I have a student (running Windows 8) who ran into a problem installing the
> RcmdrPlugin.IPSUR package and, despite instructions to the contrary,
> uninstalled R and reinstalled. He uninstalled it using the Windows 8 utility. Now
> he cannot install any packages.
> 
> Here are the error messages he gets when he gets when he trys to use the
> menu to install a package:
> > utils:::menuInstallPkgs()
> --- Please select a CRAN mirror for use in this session ---
> Warning: unable to access index for repository
> http://cran.mirrors.hoobly.com/bin/windows/contrib/3.1
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
> Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
> type) :
>   no packages were specified
> In addition: Warning message:
> In open.connection(con, "r") :
>   unable to connect to 'cran.r-project.org' on port 80.
> 
> Here are the messages he gets when using the install.packages command (it
> doesn't matter what package he tries to install):
> 
> > install.packages("rpart")
> Installing package into
> ?C:/Users/michael.bottai/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> Warning: unable to access index for repository
> http://cran.mirrors.hoobly.com/bin/windows/contrib/3.1
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
> Warning message:
> package ?rpart? is not available (for R version 3.1.1)
> 
> Any help will be greatly appreciated!
> 
> Thank you,
> Sarah
> 
> 
> --
> Sarah Hardy, PhD
> Associate Professor of Mathematics
> University of Maine Farmington
> 207-778-7124    Office: Brinkman 100
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From mbressan at arpa.veneto.it  Wed Oct  1 13:00:34 2014
From: mbressan at arpa.veneto.it (Massimo Bressan)
Date: Wed, 01 Oct 2014 13:00:34 +0200
Subject: [R] aov and groups coding
Message-ID: <542BDED2.4070301@arpa.veneto.it>

please consider the following example:

#start code

set.seed(123)
level<-rnorm(18, 10,3)

group1<-rep(letters[1:3], each=6)
summary(aov(level~group1))

group2<-rep(1:3,each=6)
str(group2)
summary(aov(level~group2))

#same result as for group1
summary(aov(level~factor(group2)))

#same result ad for aov
anova(lm(level~group2))

#end code

what I would like to do is to perform an anova among groups (analysis of 
variance for three different gruops);
consider that groups are completely arbitrary: they are not intended to 
have any sort of scaling or ordinal meaning;

in my example same groups are coded in two alternative ways: group1 as 
"chr" (factor) and group2 as "num"; so by keeping in mind my purpose (is 
there any difference in the level among groups?) I would simply consider 
the result of aov()  for group2 (num) as a non sense (with respect to my 
specific purpuse)
is that a correct interpretation?
I hope not having misinterpreted the indications of the following thread
http://r.789695.n4.nabble.com/Question-about-factor-that-is-numeric-in-aov-td2164393.html


thank you for any help

best regards

max


From Ingrid.Charvet at rms.com  Wed Oct  1 12:59:57 2014
From: Ingrid.Charvet at rms.com (Ingrid Charvet)
Date: Wed, 1 Oct 2014 03:59:57 -0700
Subject: [R] Print list to text file with list elements names
Message-ID: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>

Hi everyone,

I want to write a list of data frames to a text file and preserve the names given to the list elements (I am using R 3.1.0).

I tried:

setNames(myList, myNames) # myNames is a vector of char elements same length as myList

sink(sprintf("%s",filename))
lapply(myList,print)
sink()

And here I have two problems:

1.       R writes each element of my list to the text file twice, so for example if I have a list with 2 elements (i.e. data frames) in it, it will write 4: in order data frame 1, data frame 2, data frame 1, data frame 2.

2.       The names of list elements do not print to the text file.

Any suggestions to solve these issues would be appreciated!
Many thanks,

Ingrid




________________________________
This message and any attachments contain information that may be RMS Inc. confidential and/or privileged. If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.



	[[alternative HTML version deleted]]


From ryota.kawauchi at gmail.com  Wed Oct  1 11:41:52 2014
From: ryota.kawauchi at gmail.com (=?UTF-8?B?5rKz5YaF5Lqu5aSq?=)
Date: Wed, 1 Oct 2014 18:41:52 +0900
Subject: [R] uninstalled and reinstalled R, now cannot install packages
In-Reply-To: <CAFg2G_vteKmdGwOsddotZOGkLmtTRzhcbGe-rA9bHTp3NXfajQ@mail.gmail.com>
References: <CAFg2G_vteKmdGwOsddotZOGkLmtTRzhcbGe-rA9bHTp3NXfajQ@mail.gmail.com>
Message-ID: <8211148138407247566@unknownmsgid>

Hi,

If your PC connects Internet via proxy server, you have to run
Rgui.exe with option "--Internet2" (i.e. Rgui.exe --Internet2).

If my suggestion doesn't make sense,     please ignore.

rgds.

---
Ryota Kawauchi

2014/10/01 13:39?Sarah Hardy <sarah.hardy at maine.edu> ??????:

> Hello,
>
> I have a student (running Windows 8) who ran into a problem installing the
> RcmdrPlugin.IPSUR package and, despite instructions to the contrary,
> uninstalled R and reinstalled. He uninstalled it using the Windows 8
> utility. Now he cannot install any packages.
>
> Here are the error messages he gets when he gets when he trys to use the
> menu to install a package:
>> utils:::menuInstallPkgs()
> --- Please select a CRAN mirror for use in this session ---
> Warning: unable to access index for repository
> http://cran.mirrors.hoobly.com/bin/windows/contrib/3.1
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
> Error in install.packages(NULL, .libPaths()[1L], dependencies = NA, type =
> type) :
>  no packages were specified
> In addition: Warning message:
> In open.connection(con, "r") :
>  unable to connect to 'cran.r-project.org' on port 80.
>
> Here are the messages he gets when using the install.packages command (it
> doesn't matter what package he tries to install):
>
>> install.packages("rpart")
> Installing package into
> ?C:/Users/michael.bottai/Documents/R/win-library/3.1?
> (as ?lib? is unspecified)
> Warning: unable to access index for repository
> http://cran.mirrors.hoobly.com/bin/windows/contrib/3.1
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.1
> Warning message:
> package ?rpart? is not available (for R version 3.1.1)
>
> Any help will be greatly appreciated!
>
> Thank you,
> Sarah
>
>
> --
> Sarah Hardy, PhD
> Associate Professor of Mathematics
> University of Maine Farmington
> 207-778-7124    Office: Brinkman 100
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dileepkunjaai at gmail.com  Wed Oct  1 13:11:07 2014
From: dileepkunjaai at gmail.com (=?UTF-8?B?4LSV4LWB4LSe4LWN4LSe4LS+4LSv4LS/IGt1bmphYWk=?=)
Date: Wed, 1 Oct 2014 16:41:07 +0530
Subject: [R] Opening netCDF file with large number of variables but size is
 small in R
Message-ID: <CALTF6smanc1wtO6Lvo+PJS-4Vx9g+F_y43j9sYJZm6hHMVKirA@mail.gmail.com>

Dear all,

  I am trying to open a netcdf file with size 1.2 MB contains more than
3000 variables using 'netcdf' package.

 I am facing problem that it taking more than  10 minute to open this small
nc file.

Is any way to make it fast ?

 I have attached one sample nc-file along with this mail.


 Thank you all in advance.




-- 
DILEEPKUMAR. R
J R F, IIT DELHI

From jholtman at gmail.com  Wed Oct  1 14:20:38 2014
From: jholtman at gmail.com (jim holtman)
Date: Wed, 1 Oct 2014 08:20:38 -0400
Subject: [R] Print list to text file with list elements names
In-Reply-To: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>
Message-ID: <CAAxdm-5Vy39Uo-aeyNSFpW=zz7J80=FN8nwL7oatjOA07b2NJw@mail.gmail.com>

The result of the 'lapply' is also printed, so try this:

sink(sprintf("%s",filename))
invisible(lapply(myList,print))
sink()

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Wed, Oct 1, 2014 at 6:59 AM, Ingrid Charvet <Ingrid.Charvet at rms.com> wrote:
> Hi everyone,
>
> I want to write a list of data frames to a text file and preserve the names given to the list elements (I am using R 3.1.0).
>
> I tried:
>
> setNames(myList, myNames) # myNames is a vector of char elements same length as myList
>
> sink(sprintf("%s",filename))
> lapply(myList,print)
> sink()
>
> And here I have two problems:
>
> 1.       R writes each element of my list to the text file twice, so for example if I have a list with 2 elements (i.e. data frames) in it, it will write 4: in order data frame 1, data frame 2, data frame 1, data frame 2.
>
> 2.       The names of list elements do not print to the text file.
>
> Any suggestions to solve these issues would be appreciated!
> Many thanks,
>
> Ingrid
>
>
>
>
> ________________________________
> This message and any attachments contain information that may be RMS Inc. confidential and/or privileged. If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mdsumner at gmail.com  Wed Oct  1 15:46:12 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 1 Oct 2014 23:46:12 +1000
Subject: [R] Opening netCDF file with large number of variables but size
 is small in R
In-Reply-To: <CALTF6smanc1wtO6Lvo+PJS-4Vx9g+F_y43j9sYJZm6hHMVKirA@mail.gmail.com>
References: <CALTF6smanc1wtO6Lvo+PJS-4Vx9g+F_y43j9sYJZm6hHMVKirA@mail.gmail.com>
Message-ID: <CAAcGz9-53qm3JHcXHrpJqSW7+64au8h1VziQrfgJHrxtiHeK2A@mail.gmail.com>

This is really a question for a package maintainer, but you don't say which
package. Potentially ncdf4 may be slow with that many vars, try the open
with

suppress_dimvals=TRUE

as an outrageously optimistic guess if that package is the one you use. We
need more details from you, as per the posting guide.

Cheers, Mike
Dear all,

  I am trying to open a netcdf file with size 1.2 MB contains more than
3000 variables using 'netcdf' package.

 I am facing problem that it taking more than  10 minute to open this small
nc file.

Is any way to make it fast ?

 I have attached one sample nc-file along with this mail.


 Thank you all in advance.




--
DILEEPKUMAR. R
J R F, IIT DELHI

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Wed Oct  1 15:51:43 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 01 Oct 2014 15:51:43 +0200
Subject: [R] Opening netCDF file with large number of variables but size
 is small in R
In-Reply-To: <CALTF6smanc1wtO6Lvo+PJS-4Vx9g+F_y43j9sYJZm6hHMVKirA@mail.gmail.com>
References: <CALTF6smanc1wtO6Lvo+PJS-4Vx9g+F_y43j9sYJZm6hHMVKirA@mail.gmail.com>
Message-ID: <542C06EF.1030308@yahoo.fr>

Le 01/10/2014 13:11, ???????? kunjaai a ?crit :
> Dear all,
>
>    I am trying to open a netcdf file with size 1.2 MB contains more than
> 3000 variables using 'netcdf' package.
>
>   I am facing problem that it taking more than  10 minute to open this small
> nc file.
>
> Is any way to make it fast ?

Have you tried the ncdf4 package ?
You can find a comparison of these package here:
http://max2.ese.u-psud.fr/epc/conservation/Girondot/Publications/Blog_r/Entrees/2014/4/27_Comparison_between_packages_RnetCDF%2C_ncdf4_and_ncdf.html


>   I have attached one sample nc-file along with this mail.

The attachments are not showing on the list.

Marc


From wdunlap at tibco.com  Wed Oct  1 16:53:44 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 1 Oct 2014 07:53:44 -0700
Subject: [R] Print list to text file with list elements names
In-Reply-To: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>
Message-ID: <CAF8bMcaGibkeNj5P2Xb=v2GVx=guJ8_qSf6WYyJu1WYtGA0oww@mail.gmail.com>

Omit the sink() statements to see what is happening -
lapply(myList,print) prints
each item in the list and then the output of lapply is printed via the
autoprinting mechanism.
If you put this into a function or saved the return value of lapply
into a variable or wrapped
the call to lapply in a call to invisible() then the autoprinting
would not happen.

You said that you wanted the name each list item printed before the
item.  print(myList)
would do that, but I assume you've already tried that and didn't like
the format.  You
can get your own formatting of the name with something like
  > myList <- list(First=data.frame(x=1:2,y=letters[1:2]),
Second=data.frame(x=1:3,z=LETTERS[24:26]))
  > invisible(lapply(seq_along(myList), function(i){ cat(sep="", "\n",
names(myList)[i], ":\n") ; print(myList[[i]])}))

  First:
    x y
  1 1 a
  2 2 b

  Second:
    x z
  1 1 X
  2 2 Y
  3 3 Z




Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 1, 2014 at 3:59 AM, Ingrid Charvet <Ingrid.Charvet at rms.com> wrote:
> Hi everyone,
>
> I want to write a list of data frames to a text file and preserve the names given to the list elements (I am using R 3.1.0).
>
> I tried:
>
> setNames(myList, myNames) # myNames is a vector of char elements same length as myList
>
> sink(sprintf("%s",filename))
> lapply(myList,print)
> sink()
>
> And here I have two problems:
>
> 1.       R writes each element of my list to the text file twice, so for example if I have a list with 2 elements (i.e. data frames) in it, it will write 4: in order data frame 1, data frame 2, data frame 1, data frame 2.
>
> 2.       The names of list elements do not print to the text file.
>
> Any suggestions to solve these issues would be appreciated!
> Many thanks,
>
> Ingrid
>
>
>
>
> ________________________________
> This message and any attachments contain information that may be RMS Inc. confidential and/or privileged. If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ingrid.Charvet at rms.com  Wed Oct  1 19:41:16 2014
From: Ingrid.Charvet at rms.com (Ingrid Charvet)
Date: Wed, 1 Oct 2014 10:41:16 -0700
Subject: [R] Print list to text file with list elements names
In-Reply-To: <CAF8bMcaGibkeNj5P2Xb=v2GVx=guJ8_qSf6WYyJu1WYtGA0oww@mail.gmail.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>
	<CAF8bMcaGibkeNj5P2Xb=v2GVx=guJ8_qSf6WYyJu1WYtGA0oww@mail.gmail.com>
Message-ID: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EACDA@MAILCA6.rms.com>

Hi Bill, thanks for your suggestions.

Regarding the list elements names, your idea works well - thank you.

However, my first issue is not resolved. I omitted the second sink statement, and R still created a text file with duplicate list elements.
Then I omitted both sink statements (keeping only the lapply), but obviously then no text file is created at all (although it does "print" properly on the R console) ...

I also tried:

> func <- function(i) { write.table(inventory[[i]],file=sprintf("test_new%d",i)) }
> lapply(1:10,func)

But here of course I get 10 different text files (one per list element) when what I would like is to have them all in one file...

Ingrid



-----Original Message-----
From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: 01 October 2014 15:54
To: Ingrid Charvet
Cc: r-help at r-project.org
Subject: Re: [R] Print list to text file with list elements names

Omit the sink() statements to see what is happening -
lapply(myList,print) prints
each item in the list and then the output of lapply is printed via the autoprinting mechanism.
If you put this into a function or saved the return value of lapply into a variable or wrapped the call to lapply in a call to invisible() then the autoprinting would not happen.

You said that you wanted the name each list item printed before the item.  print(myList) would do that, but I assume you've already tried that and didn't like the format.  You can get your own formatting of the name with something like
  > myList <- list(First=data.frame(x=1:2,y=letters[1:2]),
Second=data.frame(x=1:3,z=LETTERS[24:26]))
  > invisible(lapply(seq_along(myList), function(i){ cat(sep="", "\n", names(myList)[i], ":\n") ; print(myList[[i]])}))

  First:
    x y
  1 1 a
  2 2 b

  Second:
    x z
  1 1 X
  2 2 Y
  3 3 Z




Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 1, 2014 at 3:59 AM, Ingrid Charvet <Ingrid.Charvet at rms.com> wrote:
> Hi everyone,
>
> I want to write a list of data frames to a text file and preserve the names given to the list elements (I am using R 3.1.0).
>
> I tried:
>
> setNames(myList, myNames) # myNames is a vector of char elements same
> length as myList
>
> sink(sprintf("%s",filename))
> lapply(myList,print)
> sink()
>
> And here I have two problems:
>
> 1.       R writes each element of my list to the text file twice, so for example if I have a list with 2 elements (i.e. data frames) in it, it will write 4: in order data frame 1, data frame 2, data frame 1, data frame 2.
>
> 2.       The names of list elements do not print to the text file.
>
> Any suggestions to solve these issues would be appreciated!
> Many thanks,
>
> Ingrid
>
>
>
>
> ________________________________
> This message and any attachments contain information that may be RMS Inc. confidential and/or privileged. If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


This message and any attachments contain information that may be RMS Inc. confidential and/or privileged.  If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited.   If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Oct  1 20:04:53 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 1 Oct 2014 11:04:53 -0700
Subject: [R] Print list to text file with list elements names
In-Reply-To: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EACDA@MAILCA6.rms.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>
	<CAF8bMcaGibkeNj5P2Xb=v2GVx=guJ8_qSf6WYyJu1WYtGA0oww@mail.gmail.com>
	<C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EACDA@MAILCA6.rms.com>
Message-ID: <CAF8bMcYS-gRd1fE4rZ0A7RAV=ErnHGjOMyx_1G3qOaaGvMwDdw@mail.gmail.com>

You want to put
   lapply(myList, print)
inside a call to invisible
   invisible(lapply(myList, print))

(or put the whole sink(file)/lapply(...)/sink() sequence into a
function or use tmp<-lapply(...)
so autoprinting is suppressed)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 1, 2014 at 10:41 AM, Ingrid Charvet <Ingrid.Charvet at rms.com> wrote:
> Hi Bill, thanks for your suggestions.
>
> Regarding the list elements names, your idea works well - thank you.
>
> However, my first issue is not resolved. I omitted the second sink
> statement, and R still created a text file with duplicate list elements.
> Then I omitted both sink statements (keeping only the lapply), but obviously
> then no text file is created at all (although it does "print" properly on
> the R console) ...
>
> I also tried:
>
>> func <- function(i) {
>> write.table(inventory[[i]],file=sprintf("test_new%d",i)) }
>> lapply(1:10,func)
>
> But here of course I get 10 different text files (one per list element) when
> what I would like is to have them all in one file...
>
> Ingrid
>
>
>
> -----Original Message-----
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: 01 October 2014 15:54
> To: Ingrid Charvet
> Cc: r-help at r-project.org
> Subject: Re: [R] Print list to text file with list elements names
>
> Omit the sink() statements to see what is happening -
> lapply(myList,print) prints
> each item in the list and then the output of lapply is printed via the
> autoprinting mechanism.
> If you put this into a function or saved the return value of lapply into a
> variable or wrapped the call to lapply in a call to invisible() then the
> autoprinting would not happen.
>
> You said that you wanted the name each list item printed before the item.
> print(myList) would do that, but I assume you've already tried that and
> didn't like the format. You can get your own formatting of the name with
> something like
>> myList <- list(First=data.frame(x=1:2,y=letters[1:2]),
> Second=data.frame(x=1:3,z=LETTERS[24:26]))
>> invisible(lapply(seq_along(myList), function(i){ cat(sep="", "\n",
>> names(myList)[i], ":\n") ; print(myList[[i]])}))
>
> First:
> x y
> 1 1 a
> 2 2 b
>
> Second:
> x z
> 1 1 X
> 2 2 Y
> 3 3 Z
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Oct 1, 2014 at 3:59 AM, Ingrid Charvet <Ingrid.Charvet at rms.com>
> wrote:
>> Hi everyone,
>>
>> I want to write a list of data frames to a text file and preserve the
>> names given to the list elements (I am using R 3.1.0).
>>
>> I tried:
>>
>> setNames(myList, myNames) # myNames is a vector of char elements same
>> length as myList
>>
>> sink(sprintf("%s",filename))
>> lapply(myList,print)
>> sink()
>>
>> And here I have two problems:
>>
>> 1. R writes each element of my list to the text file twice, so for example
>> if I have a list with 2 elements (i.e. data frames) in it, it will write 4:
>> in order data frame 1, data frame 2, data frame 1, data frame 2.
>>
>> 2. The names of list elements do not print to the text file.
>>
>> Any suggestions to solve these issues would be appreciated!
>> Many thanks,
>>
>> Ingrid
>>
>>
>>
>>
>> ________________________________
>> This message and any attachments contain information that may be RMS Inc.
>> confidential and/or privileged. If you are not the intended recipient (or
>> authorized to receive for the intended recipient), and have received this
>> message in error, any use, disclosure or distribution is strictly
>> prohibited. If you have received this message in error, please notify the
>> sender immediately by replying to the e-mail and permanently deleting the
>> message from your computer and/or storage system.
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> This message and any attachments contain information that may be RMS Inc.
> confidential and/or privileged. If you are not the intended recipient (or
> authorized to receive for the intended recipient), and have received this
> message in error, any use, disclosure or distribution is strictly
> prohibited. If you have received this message in error, please notify the
> sender immediately by replying to the e-mail and permanently deleting the
> message from your computer and/or storage system.


From thi_veloso at yahoo.com.br  Wed Oct  1 14:40:40 2014
From: thi_veloso at yahoo.com.br (Thiago V. dos Santos)
Date: Wed, 1 Oct 2014 05:40:40 -0700
Subject: [R] Opening netCDF file with large number of variables but size
	is small in R
In-Reply-To: <CALTF6smanc1wtO6Lvo+PJS-4Vx9g+F_y43j9sYJZm6hHMVKirA@mail.gmail.com>
References: <CALTF6smanc1wtO6Lvo+PJS-4Vx9g+F_y43j9sYJZm6hHMVKirA@mail.gmail.com>
Message-ID: <1412167240.83377.YahooMailNeo@web121903.mail.ne1.yahoo.com>

Dileepkumar,

Which function are you using to open the netcdf file?

Without a sample of your data it is not possible to reproduce your issue. However, opening a netcdf file should be straightforward with 'raster' (from raster package) or 'nc.open' (from ncdf4 package). 
 
Greetings,
--
Thiago V. dos Santos
PhD student
Land and Atmospheric Science
University of Minnesota
http://www.laas.umn.edu/CurrentStudents/MeettheStudents/ThiagodosSantos/index.htm
Phone: (612) 323 9898


On Wednesday, October 1, 2014 6:11 AM, ???????? kunjaai <dileepkunjaai at gmail.com> wrote:
 


Dear all,

  I am trying to open a netcdf file with size 1.2 MB contains more than
3000 variables using 'netcdf' package.

I am facing problem that it taking more than  10 minute to open this small
nc file.

Is any way to make it fast ?

I have attached one sample nc-file along with this mail.


Thank you all in advance.




-- 
DILEEPKUMAR. R
J R F, IIT DELHI

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From stephen at prollenium.com  Wed Oct  1 14:29:16 2014
From: stephen at prollenium.com (Stephen Kennedy)
Date: Wed, 1 Oct 2014 08:29:16 -0400
Subject: [R] power.t.test threading on 'power'
Message-ID: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>

Simple question.  A vector of ?number of observations? can be input to power.t.test, and a vector of ?power? s is output.  But, inputting a vector of powers generates an error.  Am I missing something?

Vector of ?n? s

power.t.test(n=c(28,29,30), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")

     Two-sample t test power calculation 

              n = 28, 29, 30
          delta = 2
             sd = 3
      sig.level = 0.05
          power = 0.7933594, 0.8058963, 0.8177506
    alternative = one.sided

NOTE: n is number in *each* group



Vector of ?power? s

power.t.test(power=c(0.7,0.8,0.9), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")
Error in uniroot(function(n) eval(p.body) - power, c(2, 1e+07)) : 
  f() values at end points not of opposite sign
In addition: Warning messages:
1: In if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
  the condition has length > 1 and only the first element will be used
2: In if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
  the condition has length > 1 and only the first element will be used



Thanks,

Steve

From nick at wildfishconservancy.org  Wed Oct  1 20:20:35 2014
From: nick at wildfishconservancy.org (Nick gayeski)
Date: Wed, 1 Oct 2014 11:20:35 -0700
Subject: [R] optimize
Message-ID: <00de01cfdda4$6576e720$3064b560$@wildfishconservancy.org>

Page 53 of Robert and Casella's "Use R" book, Introduction to Monte Carlo
Methods with R,  has the following code:

 

optimize(f=function(x){dbeta(x,2.7,6.3)},

+ interval=c(0,1) ,max=T)$objective

 

This should return 

[1] 2.669744

 

I run R from R Studio. When I enter this code I receive the following error
message: Error in f(arg, ...) : unused argument (max = TRUE)

 

Can someone help me understand why I get this error?

 

Thanks.

 

NickG


	[[alternative HTML version deleted]]


From JRMHosking at gmail.com  Wed Oct  1 15:44:14 2014
From: JRMHosking at gmail.com (J. R. M. Hosking)
Date: Wed, 1 Oct 2014 09:44:14 -0400
Subject: [R] Best Distribution
In-Reply-To: <BLU170-W1308F77900877D55E6C065B89BB0@phx.gbl>
References: <BLU170-W1308F77900877D55E6C065B89BB0@phx.gbl>
Message-ID: <m0h0fc$po$1@ger.gmane.org>

On 2014-09-30 15:50, eliza botto wrote:
> Dear useRs,
> I have this following data
>> dput(Prec)
> c(42.2, 45.2, 46, 48, 54, 54.1, 59.4, 61, 62.2, 63.5, 65.024, 71.9, 73.4, 76.6, 76.708, 77.5, 77.724, 78, 81.3, 84.7, 84.836, 85.09, 88.2, 91.4, 94, 95.8, 96, 97.3, 101, 101, 101.5, 102.3, 102.87, 108.7, 109.5, 110.5, 110.7, 112, 114.3, 118.11, 121.412, 128.1, 131, 140, 142, 143.3, 151.4, 153.7, 189.4, 214.3)
> I want to fit gumbel and log-normal distribution on it on the same window to see which distribution fits it the best way.
> Thankyou very much in advance,
> Eliza 		 	   		
> 	[[alternative HTML version deleted]]
>


Package lmom has functions that make this kind of computation very 
straightforward.

library(lmom)
Prec<-c(42.2, 45.2, 46, 48, 54, 54.1, 59.4, 61, 62.2, 63.5, 65.024,
   71.9, 73.4, 76.6, 76.708, 77.5, 77.724, 78, 81.3, 84.7, 84.836,
   85.09, 88.2, 91.4, 94, 95.8, 96, 97.3, 101, 101, 101.5, 102.3,
   102.87, 108.7, 109.5, 110.5, 110.7, 112, 114.3, 118.11, 121.412,
   128.1, 131, 140, 142, 143.3, 151.4, 153.7, 189.4, 214.3)
evplot(Prec)                                        # plot data
evdistq(quagum, pelgum(samlmu(Prec)), col='green')  # add Gumbel fit
evdistq(qualn3, pelln3(samlmu(Prec), bound=0), col='blue') # lognormal
legend("topleft",c("Gumbel","lognormal"),lty=1,col=c("green","blue"))




J. R. M. Hosking


From John.Christie at Dal.Ca  Wed Oct  1 19:56:15 2014
From: John.Christie at Dal.Ca (John Christie)
Date: Wed, 1 Oct 2014 17:56:15 +0000
Subject: [R] ave documentation
Message-ID: <6C79C965-96E0-453D-8FA8-0E7D4B9F3DBB@dal.ca>

Hi,

I was looking at the ave documentation and it seems awfully sparse. How about we change the description from:

Subsets of x[] are averaged, where each subset consist of those observations with the same factor levels.

to:

Subsets of x[] are averaged, where each subset consist of those observations within a combination of factor levels. The result will have the same length as x[].

Maybe that's not just what I want either. ave is so useful any time you want to basically split/apply and want the output to be the same lenghth. Here's an example...

x <- c('a', 'a', 'b', 'b', 'c', 'c', 'a', 'a')
f <- c(1, 1, 1, 1, 2, 2, 2, 2)
ave(x, f, FUN = order )

One would never have deduced that from the help alone and it seems like a primary function. Or, more advanced

as.numeric( ave(x, f, FUN = function(x) factor(x, levels = unique(x))) )

And if this isn't where I'd send help documentation suggestions where could I?

From wdunlap at tibco.com  Wed Oct  1 21:53:58 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 1 Oct 2014 12:53:58 -0700
Subject: [R] optimize
In-Reply-To: <00de01cfdda4$6576e720$3064b560$@wildfishconservancy.org>
References: <00de01cfdda4$6576e720$3064b560$@wildfishconservancy.org>
Message-ID: <CAF8bMca13k2SpaNQ6Tt+3chG11qEp549F4GaQ7WjcaR-zA13kA@mail.gmail.com>

Change your 'max=T' to 'maximum=TRUE'.  A long time ago the '...' in
optimize's argument
list was at the end, so you could abbreviate any of its argument
names.  Now the '...' is the
third formal argument, so all the trailing arguments meant for
optimize itself must be fully
spelled out.  Otherwise they get passed to f(), which is the cause of
your error message.

(The T->TRUE is an independent issue - you may make a variable called
'T' that does not
have the value TRUE, but you cannot mask TRUE.  TRUE is a literal
value, like 123, not a
variable.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 1, 2014 at 11:20 AM, Nick gayeski
<nick at wildfishconservancy.org> wrote:
> Page 53 of Robert and Casella's "Use R" book, Introduction to Monte Carlo
> Methods with R,  has the following code:
>
>
>
> optimize(f=function(x){dbeta(x,2.7,6.3)},
>
> + interval=c(0,1) ,max=T)$objective
>
>
>
> This should return
>
> [1] 2.669744
>
>
>
> I run R from R Studio. When I enter this code I receive the following error
> message: Error in f(arg, ...) : unused argument (max = TRUE)
>
>
>
> Can someone help me understand why I get this error?
>
>
>
> Thanks.
>
>
>
> NickG
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Thu Oct  2 00:11:05 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Wed, 1 Oct 2014 18:11:05 -0400
Subject: [R] How to check to see if a variable is within a range of another
	variable
Message-ID: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>

Is there an easy way to check whether a variable is within  +/- 10%
range of another variable in R?

Say, if I have a variable 'A', whether its in +/- 10% range of
variable 'B' and if so, create another variable 'C' to say whether it
is or not?

Is there a function that is able to do that?

eventual outcome:
A B C
67 76 no
24 23 yes
40 45 yes
10 12 yes
70 72 yes
101 90 no
9 12 no


From ligges at statistik.tu-dortmund.de  Thu Oct  2 00:15:03 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 02 Oct 2014 00:15:03 +0200
Subject: [R] power.t.test threading on 'power'
In-Reply-To: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
References: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
Message-ID: <542C7CE7.1010705@statistik.tu-dortmund.de>

On 01.10.2014 14:29, Stephen Kennedy wrote:
> Simple question.  A vector of ?number of observations? can be input to power.t.test, and a vector of ?power? s is output.  But, inputting a vector of powers generates an error.  Am I missing something?
>
> Vector of ?n? s
>
> power.t.test(n=c(28,29,30), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")
>
>       Two-sample t test power calculation
>
>                n = 28, 29, 30
>            delta = 2
>               sd = 3
>        sig.level = 0.05
>            power = 0.7933594, 0.8058963, 0.8177506
>      alternative = one.sided
>
> NOTE: n is number in *each* group
>
>
>
> Vector of ?power? s
>
> power.t.test(power=c(0.7,0.8,0.9), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")
> Error in uniroot(function(n) eval(p.body) - power, c(2, 1e+07)) :
>    f() values at end points not of opposite sign
> In addition: Warning messages:
> 1: In if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
>    the condition has length > 1 and only the first element will be used
> 2: In if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
>    the condition has length > 1 and only the first element will be used
>

power.t.test oes not work on vectors in general.

Here, you want:

lapply(c(0.7, 0.8, 0.9),
     function(power)
         power.t.test(power=power, delta=2, sd=3, sig.level=0.05,
                      type="two.sample", alternative="one.sided")
)

Best,
Uwe Ligges




>
> Thanks,
>
> Steve
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From peter.langfelder at gmail.com  Thu Oct  2 00:29:15 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Wed, 1 Oct 2014 15:29:15 -0700
Subject: [R] How to check to see if a variable is within a range of
 another variable
In-Reply-To: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
References: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
Message-ID: <CA+hbrhWv9DHGDe6QJ4aE8T95fyt-g48MqizKaviqzKhwTZZdSw@mail.gmail.com>

On Wed, Oct 1, 2014 at 3:11 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> Is there an easy way to check whether a variable is within  +/- 10%
> range of another variable in R?

Yes,

checkRange = function(A, B, range = 0.1)
{
  A>=B*(1-range) & A<=B*(1+range);
}

Test:

A = c(67, 24, 40, 10, 70, 101, 9)
B = c(76, 23, 45, 12, 72, 90, 12)

outcome = checkRange(A, B)

You can create the desired data frame for example as

data.frame (A = A, B=B, C = c("no", "yes")[outcome+1])

>
> Say, if I have a variable 'A', whether its in +/- 10% range of
> variable 'B' and if so, create another variable 'C' to say whether it
> is or not?

What do you mean by range of variable B? In your example below, 40 is
not within 10% of 45, which is 4.5; 10 is not within 10% of 12 which
is 1.2.
>
> eventual outcome:
> A B C
> 67 76 no
> 24 23 yes
> 40 45 yes
> 10 12 yes
> 70 72 yes
> 101 90 no
> 9 12 no


HTH,

Peter


From ligges at statistik.tu-dortmund.de  Thu Oct  2 00:35:52 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 02 Oct 2014 00:35:52 +0200
Subject: [R] power.t.test threading on 'power'
In-Reply-To: <D0A8C0FB-E647-4530-BF52-350F52D07691@Prollenium.com>
References: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
	<542C7CE7.1010705@statistik.tu-dortmund.de>
	<D0A8C0FB-E647-4530-BF52-350F52D07691@Prollenium.com>
Message-ID: <542C81C8.3050608@statistik.tu-dortmund.de>



On 02.10.2014 00:27, Stephen Kennedy wrote:
> Thanks.  I?ve been getting some nice workarounds.  I was pleasantly surprised when the function ?threaded? on the number of samples, but I guess that was not really part of the design, just an accident.

One could argue that the error message could be improved. ;-)

Indeed, the function was not designed to work on vectors, but most parts 
of R are, hence the "accident". :-)

Best,
Uwe Ligges



> Best,
>
> Steve
>
>
>
> On Oct 1, 2014, at 6:15 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:
>
> On 01.10.2014 14:29, Stephen Kennedy wrote:
>> Simple question.  A vector of ?number of observations? can be input to power.t.test, and a vector of ?power? s is output.  But, inputting a vector of powers generates an error.  Am I missing something?
>>
>> Vector of ?n? s
>>
>> power.t.test(n=c(28,29,30), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")
>>
>>       Two-sample t test power calculation
>>
>>                n = 28, 29, 30
>>            delta = 2
>>               sd = 3
>>        sig.level = 0.05
>>            power = 0.7933594, 0.8058963, 0.8177506
>>      alternative = one.sided
>>
>> NOTE: n is number in *each* group
>>
>>
>>
>> Vector of ?power? s
>>
>> power.t.test(power=c(0.7,0.8,0.9), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")
>> Error in uniroot(function(n) eval(p.body) - power, c(2, 1e+07)) :
>>    f() values at end points not of opposite sign
>> In addition: Warning messages:
>> 1: In if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
>>    the condition has length > 1 and only the first element will be used
>> 2: In if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
>>    the condition has length > 1 and only the first element will be used
>>
>
> power.t.test oes not work on vectors in general.
>
> Here, you want:
>
> lapply(c(0.7, 0.8, 0.9),
>     function(power)
>         power.t.test(power=power, delta=2, sd=3, sig.level=0.05,
>                      type="two.sample", alternative="one.sided")
> )
>
> Best,
> Uwe Ligges
>
>
>
>
>>
>> Thanks,
>>
>> Steve
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From stephen at prollenium.com  Thu Oct  2 00:27:16 2014
From: stephen at prollenium.com (Stephen Kennedy)
Date: Wed, 1 Oct 2014 18:27:16 -0400
Subject: [R] power.t.test threading on 'power'
In-Reply-To: <542C7CE7.1010705@statistik.tu-dortmund.de>
References: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
	<542C7CE7.1010705@statistik.tu-dortmund.de>
Message-ID: <D0A8C0FB-E647-4530-BF52-350F52D07691@Prollenium.com>

Thanks.  I?ve been getting some nice workarounds.  I was pleasantly surprised when the function ?threaded? on the number of samples, but I guess that was not really part of the design, just an accident.

Best,

Steve



On Oct 1, 2014, at 6:15 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de> wrote:

On 01.10.2014 14:29, Stephen Kennedy wrote:
> Simple question.  A vector of ?number of observations? can be input to power.t.test, and a vector of ?power? s is output.  But, inputting a vector of powers generates an error.  Am I missing something?
> 
> Vector of ?n? s
> 
> power.t.test(n=c(28,29,30), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")
> 
>      Two-sample t test power calculation
> 
>               n = 28, 29, 30
>           delta = 2
>              sd = 3
>       sig.level = 0.05
>           power = 0.7933594, 0.8058963, 0.8177506
>     alternative = one.sided
> 
> NOTE: n is number in *each* group
> 
> 
> 
> Vector of ?power? s
> 
> power.t.test(power=c(0.7,0.8,0.9), delta=2, sd=3, sig.level=0.05, type="two.sample", alternative="one.sided")
> Error in uniroot(function(n) eval(p.body) - power, c(2, 1e+07)) :
>   f() values at end points not of opposite sign
> In addition: Warning messages:
> 1: In if (is.na(f.lower)) stop("f.lower = f(lower) is NA") :
>   the condition has length > 1 and only the first element will be used
> 2: In if (is.na(f.upper)) stop("f.upper = f(upper) is NA") :
>   the condition has length > 1 and only the first element will be used
> 

power.t.test oes not work on vectors in general.

Here, you want:

lapply(c(0.7, 0.8, 0.9),
   function(power)
       power.t.test(power=power, delta=2, sd=3, sig.level=0.05,
                    type="two.sample", alternative="one.sided")
)

Best,
Uwe Ligges




> 
> Thanks,
> 
> Steve
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From pdalgd at gmail.com  Thu Oct  2 00:46:33 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Oct 2014 00:46:33 +0200
Subject: [R] power.t.test threading on 'power'
In-Reply-To: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
References: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
Message-ID: <798EA142-0A8F-4A4D-B596-03E448DBE65A@gmail.com>


On 01 Oct 2014, at 14:29 , Stephen Kennedy <stephen at prollenium.com> wrote:

> Simple question.  A vector of ?number of observations? can be input to power.t.test, and a vector of ?power? s is output.  But, inputting a vector of powers generates an error.  Am I missing something?

Power.t.test was written for scalar arguments. If it happens to work with vector arguments, it is entirely coincidental. The essence of what you observe is that power is calculated by pt() which vectorizes, but n is calculated by numerical solution using uniroot() which does not vectorize. 

If you need a vectorized version, check out Vectorize().

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Peter.Alspach at plantandfood.co.nz  Thu Oct  2 00:54:36 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 2 Oct 2014 11:54:36 +1300
Subject: [R] How to check to see if a variable is within a range of
 another	variable
In-Reply-To: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
References: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2284F78EA9@AKLEXM01.PFR.CO.NZ>

Tena koe Kate

If kateDF is a data.frame with your data, then

apply(kateDF, 1, function(x) isTRUE(all.equal(x[2], x[1], check.attributes = FALSE, tolerance=0.1)))

comes close to (what I think) you want (but not to what you have illustrated in your 'eventual outcome').  Anyhow, it may be enough to allow you to get there.

HTH ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Kate Ignatius
Sent: Thursday, 2 October 2014 11:11 a.m.
To: r-help
Subject: [R] How to check to see if a variable is within a range of another variable

Is there an easy way to check whether a variable is within  +/- 10% range of another variable in R?

Say, if I have a variable 'A', whether its in +/- 10% range of variable 'B' and if so, create another variable 'C' to say whether it is or not?

Is there a function that is able to do that?

eventual outcome:
A B C
67 76 no
24 23 yes
40 45 yes
10 12 yes
70 72 yes
101 90 no
9 12 no

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
The contents of this e-mail are confidential and may be ...{{dropped:14}}


From pdalgd at gmail.com  Thu Oct  2 01:03:07 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Oct 2014 01:03:07 +0200
Subject: [R] optimize
In-Reply-To: <CAF8bMca13k2SpaNQ6Tt+3chG11qEp549F4GaQ7WjcaR-zA13kA@mail.gmail.com>
References: <00de01cfdda4$6576e720$3064b560$@wildfishconservancy.org>
	<CAF8bMca13k2SpaNQ6Tt+3chG11qEp549F4GaQ7WjcaR-zA13kA@mail.gmail.com>
Message-ID: <E955DC95-B1F7-4B7A-BC90-815F6C32CB3A@gmail.com>

Yup. And books don't rewrite themselves when the software changes, so if things don't seem to work, check the _current_ documentation.

-pd


On 01 Oct 2014, at 21:53 , William Dunlap <wdunlap at tibco.com> wrote:

> Change your 'max=T' to 'maximum=TRUE'.  A long time ago the '...' in
> optimize's argument
> list was at the end, so you could abbreviate any of its argument
> names.  Now the '...' is the
> third formal argument, so all the trailing arguments meant for
> optimize itself must be fully
> spelled out.  Otherwise they get passed to f(), which is the cause of
> your error message.
> 
> (The T->TRUE is an independent issue - you may make a variable called
> 'T' that does not
> have the value TRUE, but you cannot mask TRUE.  TRUE is a literal
> value, like 123, not a
> variable.)
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
> 
> 
> On Wed, Oct 1, 2014 at 11:20 AM, Nick gayeski
> <nick at wildfishconservancy.org> wrote:
>> Page 53 of Robert and Casella's "Use R" book, Introduction to Monte Carlo
>> Methods with R,  has the following code:
>> 
>> 
>> 
>> optimize(f=function(x){dbeta(x,2.7,6.3)},
>> 
>> + interval=c(0,1) ,max=T)$objective
>> 
>> 
>> 
>> This should return
>> 
>> [1] 2.669744
>> 
>> 
>> 
>> I run R from R Studio. When I enter this code I receive the following error
>> message: Error in f(arg, ...) : unused argument (max = TRUE)
>> 
>> 
>> 
>> Can someone help me understand why I get this error?
>> 
>> 
>> 
>> Thanks.
>> 
>> 
>> 
>> NickG
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kate.ignatius at gmail.com  Thu Oct  2 01:38:36 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Wed, 1 Oct 2014 19:38:36 -0400
Subject: [R] How to check to see if a variable is within a range of
 another variable
In-Reply-To: <ED8CD182D432434485C7D1787FB06DDC2284F78EA9@AKLEXM01.PFR.CO.NZ>
References: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2284F78EA9@AKLEXM01.PFR.CO.NZ>
Message-ID: <CAE6QMsbh7_LsSNDsKLiLE5d=iVoAgGE_aUfBGz9HA4rq4EAjAQ@mail.gmail.com>

Apologise - yes, my 10% calculations seem to be slightly off.

However, the function gives me all falses which seems to be a little
weird.   Even where both columns equal each other.   Should that be
right?

In essence I want to check whether A and B equal other give or take 10%.

On Wed, Oct 1, 2014 at 6:54 PM, Peter Alspach
<Peter.Alspach at plantandfood.co.nz> wrote:
> Tena koe Kate
>
> If kateDF is a data.frame with your data, then
>
> apply(kateDF, 1, function(x) isTRUE(all.equal(x[2], x[1], check.attributes = FALSE, tolerance=0.1)))
>
> comes close to (what I think) you want (but not to what you have illustrated in your 'eventual outcome').  Anyhow, it may be enough to allow you to get there.
>
> HTH ....
>
> Peter Alspach
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Kate Ignatius
> Sent: Thursday, 2 October 2014 11:11 a.m.
> To: r-help
> Subject: [R] How to check to see if a variable is within a range of another variable
>
> Is there an easy way to check whether a variable is within  +/- 10% range of another variable in R?
>
> Say, if I have a variable 'A', whether its in +/- 10% range of variable 'B' and if so, create another variable 'C' to say whether it is or not?
>
> Is there a function that is able to do that?
>
> eventual outcome:
> A B C
> 67 76 no
> 24 23 yes
> 40 45 yes
> 10 12 yes
> 70 72 yes
> 101 90 no
> 9 12 no
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> The contents of this e-mail are confidential and may be subject to legal privilege.
>  If you are not the intended recipient you must not use, disseminate, distribute or
>  reproduce all or any part of this e-mail or attachments.  If you have received this
>  e-mail in error, please notify the sender and delete all material pertaining to this
>  e-mail.  Any opinion or views expressed in this e-mail are those of the individual
>  sender and may not represent those of The New Zealand Institute for Plant and
>  Food Research Limited.
>


From Peter.Alspach at plantandfood.co.nz  Thu Oct  2 01:45:52 2014
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 2 Oct 2014 12:45:52 +1300
Subject: [R] How to check to see if a variable is within a range of
 another variable
In-Reply-To: <CAE6QMsbh7_LsSNDsKLiLE5d=iVoAgGE_aUfBGz9HA4rq4EAjAQ@mail.gmail.com>
References: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2284F78EA9@AKLEXM01.PFR.CO.NZ>
	<CAE6QMsbh7_LsSNDsKLiLE5d=iVoAgGE_aUfBGz9HA4rq4EAjAQ@mail.gmail.com>
Message-ID: <ED8CD182D432434485C7D1787FB06DDC2284F78EB6@AKLEXM01.PFR.CO.NZ>

Tena koe Kate

This is what I get:

kateDF
#     A  B
# 1  67 76
# 2  24 23
# 3  40 45
# 4  10 12
# 5  70 72
# 6 101 90
# 7   9 12
kateDF$C <- apply(kateDF, 1, function(x) isTRUE(all.equal(x[2], x[1], check.attributes = FALSE, tolerance=0.1)))
kateDF
#     A  B     C
# 1  67 76 FALSE
# 2  24 23  TRUE
# 3  40 45 FALSE
# 4  10 12 FALSE
# 5  70 72  TRUE
# 6 101 90 FALSE
# 7   9 12 FALSE

Which seems correct.  Can't say why you get something different without more details.

Peter Alspach

-----Original Message-----
From: Kate Ignatius [mailto:kate.ignatius at gmail.com] 
Sent: Thursday, 2 October 2014 12:39 p.m.
To: Peter Alspach
Cc: r-help
Subject: Re: [R] How to check to see if a variable is within a range of another variable

Apologise - yes, my 10% calculations seem to be slightly off.

However, the function gives me all falses which seems to be a little
weird.   Even where both columns equal each other.   Should that be
right?

In essence I want to check whether A and B equal other give or take 10%.

On Wed, Oct 1, 2014 at 6:54 PM, Peter Alspach <Peter.Alspach at plantandfood.co.nz> wrote:
> Tena koe Kate
>
> If kateDF is a data.frame with your data, then
>
> apply(kateDF, 1, function(x) isTRUE(all.equal(x[2], x[1], 
> check.attributes = FALSE, tolerance=0.1)))
>
> comes close to (what I think) you want (but not to what you have illustrated in your 'eventual outcome').  Anyhow, it may be enough to allow you to get there.
>
> HTH ....
>
> Peter Alspach
>
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Kate Ignatius
> Sent: Thursday, 2 October 2014 11:11 a.m.
> To: r-help
> Subject: [R] How to check to see if a variable is within a range of 
> another variable
>
> Is there an easy way to check whether a variable is within  +/- 10% range of another variable in R?
>
> Say, if I have a variable 'A', whether its in +/- 10% range of variable 'B' and if so, create another variable 'C' to say whether it is or not?
>
> Is there a function that is able to do that?
>
> eventual outcome:
> A B C
> 67 76 no
> 24 23 yes
> 40 45 yes
> 10 12 yes
> 70 72 yes
> 101 90 no
> 9 12 no
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> The contents of this e-mail are confidential and may be subject to legal privilege.
>  If you are not the intended recipient you must not use, disseminate, 
> distribute or  reproduce all or any part of this e-mail or 
> attachments.  If you have received this  e-mail in error, please 
> notify the sender and delete all material pertaining to this  e-mail.  
> Any opinion or views expressed in this e-mail are those of the 
> individual  sender and may not represent those of The New Zealand Institute for Plant and  Food Research Limited.
>

The contents of this e-mail are confidential and may be subject to legal privilege.
 If you are not the intended recipient you must not use, disseminate, distribute or
 reproduce all or any part of this e-mail or attachments.  If you have received this
 e-mail in error, please notify the sender and delete all material pertaining to this
 e-mail.  Any opinion or views expressed in this e-mail are those of the individual
 sender and may not represent those of The New Zealand Institute for Plant and
 Food Research Limited.

From motyocska at yahoo.com  Thu Oct  2 02:30:26 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Wed, 1 Oct 2014 17:30:26 -0700
Subject: [R] optimization question
Message-ID: <1412209826.33353.YahooMailBasic@web161602.mail.bf1.yahoo.com>

Dear All,

please provide help with the following:

we have

a <-c(0,1,1,0,1,0,0,0,0)
b <-c(0,0,0,1,0,0,0,0,0)
c <-c(1,0,1,0,1,1,0,0,0)
d <-c(0,1,0,1,0,1,0,0,0)
df <-rbind(a,b,c,d)
df <-cbind(df,h=c(sum(a)*8,sum(b)*8,sum(c)*8,sum(d)*8))
df <-cbind(df,df[,8]*c(1,2,3,2))

I would like to minimize the value for sum(df[,9]) under the following conditions:

1. all values of a,b,c, and d are binary variables and are the variables to change to get the optimal result
2. sum(a), sum(b), and sum(d) should be each 5 or more
3. sum(c) should be 3 or less
4. a[2], a[3], b[2], d[7] and d[8] are fixed to their current values.

any thoughts or reference examples you could help with is greatly appreciated

thanks

andras


From teamtraders3564 at gmail.com  Thu Oct  2 02:48:25 2014
From: teamtraders3564 at gmail.com (Jason Eyerly)
Date: Wed, 1 Oct 2014 17:48:25 -0700
Subject: [R] Best Beginner Books?
Message-ID: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>

Hey Folks,
    I?m hoping to get a general consenus on a good book for someone with no prior experience in R that is new to data science and statistical analysis. So far, I?ve been recommended to read ?Software For Data Analysis: Programming With R (Statistics And Computing)" by John Chambers. I?ve seen some other books mentioned here and there in the mailings, but I can?t recall their names. Does anyone have any though on this book, or others?

Best Regards,
	Jason Eyerly

From cryan at binghamton.edu  Thu Oct  2 03:26:16 2014
From: cryan at binghamton.edu (Christopher W Ryan)
Date: Thu, 2 Oct 2014 01:26:16 +0000
Subject: [R] Best Beginner Books?
In-Reply-To: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>
References: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>
Message-ID: <CAM+rpYmSc4==J72TNdcRwDs+wByNtkH5gRqw2+43goqc9yf7Xg@mail.gmail.com>

I would recommend these for the absolute beginner with R:

"A Beginner's Guide to R" by Zuur
and
"Data Manipulation with R" by Spector

I have not seen this, but if their pattern holds, this one coming out
from Highland Statistics will also probably be useful for a newcomer:

A Beginner's Guide to Data Exploration and Visualization with R
Ieno EN, Zuur AF
Paperback available from November 2014
Harcover available from January 2015

--Chris Ryan

On Thu, Oct 2, 2014 at 12:48 AM, Jason Eyerly <teamtraders3564 at gmail.com> wrote:
> Hey Folks,
>     I?m hoping to get a general consenus on a good book for someone with no prior experience in R that is new to data science and statistical analysis. So far, I?ve been recommended to read ?Software For Data Analysis: Programming With R (Statistics And Computing)" by John Chambers. I?ve seen some other books mentioned here and there in the mailings, but I can?t recall their names. Does anyone have any though on this book, or others?
>
> Best Regards,
>         Jason Eyerly
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From memilanuk at gmail.com  Thu Oct  2 04:14:27 2014
From: memilanuk at gmail.com (memilanuk)
Date: Wed, 1 Oct 2014 19:14:27 -0700
Subject: [R] Best Beginner Books?
In-Reply-To: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>
References: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>
Message-ID: <m0ice4$9ab$1@ger.gmane.org>

On 10/01/2014 05:48 PM, Jason Eyerly wrote:
> Hey Folks, I?m hoping to get a general consenus on a good book for
> someone with no prior experience in R that is new to data science and
> statistical analysis. So far, I?ve been recommended to read ?Software
> For Data Analysis: Programming With R (Statistics And Computing)" by
> John Chambers. I?ve seen some other books mentioned here and there in
> the mailings, but I can?t recall their names. Does anyone have any
> though on this book, or others?

There is always "R for Dummies"... (not entirely kidding, actually a 
pretty gentle intro to R via RStudio)


From teamtraders3564 at gmail.com  Thu Oct  2 04:54:36 2014
From: teamtraders3564 at gmail.com (Jason Eyerly)
Date: Wed, 1 Oct 2014 19:54:36 -0700
Subject: [R] Best Beginner Books?
In-Reply-To: <CAM+rpYmSc4==J72TNdcRwDs+wByNtkH5gRqw2+43goqc9yf7Xg@mail.gmail.com>
References: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>
	<CAM+rpYmSc4==J72TNdcRwDs+wByNtkH5gRqw2+43goqc9yf7Xg@mail.gmail.com>
Message-ID: <42FCA9C1-826F-4D81-8D24-263C90A1FB74@gmail.com>

A lot of excellent suggestions! Thank you everyone for the input. I?ve purchased via Amazon:

"A Beginner's Guide to R" by Zuur
"Data Manipulation with R" by Spector
?Introductory Statistics with R.? by Peter Dalgaard

Are there any suggestions as to which order I should read them in when they arrive? For best comprehension, I?m thinking ?Introductory Statistics with R? would be the best to start with, and perhaps the beginners guide after that, or vice versa?

-Jason E.

On Oct 1, 2014, at 18:26, Christopher W Ryan <cryan at binghamton.edu> wrote:

> "Data Manipulation with R" by Spector


	[[alternative HTML version deleted]]


From dwkikuchi at gmail.com  Thu Oct  2 03:05:12 2014
From: dwkikuchi at gmail.com (David Kikuchi)
Date: Wed, 01 Oct 2014 21:05:12 -0400
Subject: [R] pmnorm to find cdf with linear decision bound
Message-ID: <542CA4C8.2060404@gmail.com>

Hi all,

I need help calculating the error rate of an optimal responder to a 
multidimensional discrimination task. I have been trying to use pmnorm 
to do this, but am not sure about its functionality. I'm working with a 
dataset of responses (binary, attack/not attack) of subjects who were 
asked to discriminate between two different, overlapping categories of 
stimuli. The stimuli subjects viewed were bivariate normal in their 
distributions (squares with different mean blue:yellow ratios and 
sizes). It is easy to find a threshold (a line) on the bivariate plane 
that describes the optimal discrimination function. It is a diagonal. To 
find the error rate committed by this optimal responder, I need to find 
the cumulative distribution function for a bivariate normal that lies 
above the line. However, pmnorm only seems to calculate rectangular 
probabilities, i.e. only uses limits of integration perpendicular to the 
axes. Is there another function I could use?

Thanks,
David

The problem is visualized with the code below:

library(mnormt)
library(lattice)

modelms<- 31.2
mimicms<- 24
sds<- 4*4
modelmc<- 0.7
mimicmc<- 0.4
sdc<- 0.15*0.15
xv<-seq(0,1,0.01)
yv<-seq(10,50,0.1)

ys <- matrix(NA,length(xv),length(coeffs[1,]))
for(i in 1:length(xv)) ys[i,] <- 
(coeffs[1,]+coeffs[2,]*xv[i])/(coeffs[3,]*-1)

mu <- c(modelmc,modelms) #model
sigma <- matrix(c(sdc,0,0,sds),2,2)
z1<-NULL
for(x in xv){
   f <- dmnorm(cbind(x,yv), mu, sigma)
   z1<-rbind(z1,f)
}
contour(xv,yv,z1, nlevels = 5,col = "blue", lty = "solid", lwd = 1.8, 
xlab = "proportion yellow", ylab = "size")

mu <- c(mimicmc,mimicms) #mimic
sigma <- matrix(c(sdc,0,0,sds),2,2)
z2<-NULL
for(x in xv){
   f <- dmnorm(cbind(x,yv), mu, sigma)
   z2<-rbind(z2,f)
}
contour(xv,yv,z2, nlevels = 5,add = TRUE,col = "red", lty = "solid", lwd 
= 1.8)
contour(xv,yv,z2-z1, nlevels = 1,add = TRUE, col = "black", lty = 
"solid", lwd = 2.5)


From stephen at prollenium.com  Thu Oct  2 03:46:05 2014
From: stephen at prollenium.com (Stephen Kennedy)
Date: Wed, 1 Oct 2014 21:46:05 -0400
Subject: [R] power.t.test threading on 'power'
In-Reply-To: <798EA142-0A8F-4A4D-B596-03E448DBE65A@gmail.com>
References: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
	<798EA142-0A8F-4A4D-B596-03E448DBE65A@gmail.com>
Message-ID: <08856065-4216-45A1-A14F-6CDC55CB7C04@Prollenium.com>

Thanks.  I only use R on occasion, but I knew I could work around it easily (and in fact some other users were nice enough to send some code).  

When it only worked when inputting n, I thought it might be just an accident, but thought I would ask.

Thanks for the explanation.

Best,

Steve


On Oct 1, 2014, at 6:46 PM, peter dalgaard <pdalgd at gmail.com> wrote:


On 01 Oct 2014, at 14:29 , Stephen Kennedy <stephen at prollenium.com> wrote:

> Simple question.  A vector of ?number of observations? can be input to power.t.test, and a vector of ?power? s is output.  But, inputting a vector of powers generates an error.  Am I missing something?

Power.t.test was written for scalar arguments. If it happens to work with vector arguments, it is entirely coincidental. The essence of what you observe is that power is calculated by pt() which vectorizes, but n is calculated by numerical solution using uniroot() which does not vectorize. 

If you need a vectorized version, check out Vectorize().

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From arnaud.gaboury at gmail.com  Thu Oct  2 08:22:47 2014
From: arnaud.gaboury at gmail.com (arnaud gaboury)
Date: Thu, 2 Oct 2014 08:22:47 +0200
Subject: [R] Best Beginner Books?
In-Reply-To: <42FCA9C1-826F-4D81-8D24-263C90A1FB74@gmail.com>
References: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>
	<CAM+rpYmSc4==J72TNdcRwDs+wByNtkH5gRqw2+43goqc9yf7Xg@mail.gmail.com>
	<42FCA9C1-826F-4D81-8D24-263C90A1FB74@gmail.com>
Message-ID: <CAK1hC9tJA02VOzQ06+P5=rYpweY_jREyN1f3roc9S17vxFP8Xw@mail.gmail.com>

On Thu, Oct 2, 2014 at 4:54 AM, Jason Eyerly <teamtraders3564 at gmail.com> wrote:
> A lot of excellent suggestions! Thank you everyone for the input. I?ve purchased via Amazon:
>
> "A Beginner's Guide to R" by Zuur
> "Data Manipulation with R" by Spector
> ?Introductory Statistics with R.? by Peter Dalgaard
>
> Are there any suggestions as to which order I should read them in when they arrive? For best comprehension, I?m thinking ?Introductory Statistics with R? would be the best to start with, and perhaps the beginners guide after that, or vice versa?
>

I would not start with a whole book, but a good short intro (~ 30-40
pages). Feel free to pick up free publications here:
https://github.com/gabx/r-project/tree/master/documentation.


From rl at openmailbox.org  Thu Oct  2 11:01:57 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Thu, 02 Oct 2014 09:01:57 +0000
Subject: [R] apply if else statement to vector
Message-ID: <7814f923ee1c2221f1eb3f1d2e506bc6@openmailbox.org>

Subscribers,

What is the correct syntax to apply the 'if else' conditional statement 
to vector objects?

Example:

vectorx<-c(50,50,20,70)
vectory<-c(50,50,20,20)
vectorz<-function () {
	if (vectorx>vectory)
	vectorx
	else vectorx<-0
}

vectorz()
Warning message:
In if (vectorx > vectory) vectorx else vectorx <- 0 :
   the condition has length > 1 and only the first element will be used

The help manual (?'if') explains that only length=0 is acceptable; what 
is an appropriate alternative function to use please?

The desired result for vectorz is:

0 0 0 70


From petr.pikal at precheza.cz  Thu Oct  2 11:09:47 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 2 Oct 2014 09:09:47 +0000
Subject: [R] apply if else statement to vector
In-Reply-To: <7814f923ee1c2221f1eb3f1d2e506bc6@openmailbox.org>
References: <7814f923ee1c2221f1eb3f1d2e506bc6@openmailbox.org>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8B30@SRVEXCHMBX.precheza.cz>

Hi

in this case correct syntax is not to use if at all

vectorx*(vectorx>vectory)
1]  0  0  0 70

if you insist you can use

?ifelse

which is "vectorised" if

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of rl at openmailbox.org
> Sent: Thursday, October 02, 2014 11:02 AM
> To: r-help at r-project.org
> Subject: [R] apply if else statement to vector
>
> Subscribers,
>
> What is the correct syntax to apply the 'if else' conditional statement
> to vector objects?
>
> Example:
>
> vectorx<-c(50,50,20,70)
> vectory<-c(50,50,20,20)
> vectorz<-function () {
>       if (vectorx>vectory)
>       vectorx
>       else vectorx<-0
> }
>
> vectorz()
> Warning message:
> In if (vectorx > vectory) vectorx else vectorx <- 0 :
>    the condition has length > 1 and only the first element will be used
>
> The help manual (?'if') explains that only length=0 is acceptable; what
> is an appropriate alternative function to use please?
>
> The desired result for vectorz is:
>
> 0 0 0 70
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From bhh at xs4all.nl  Thu Oct  2 11:14:17 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 2 Oct 2014 11:14:17 +0200
Subject: [R] apply if else statement to vector
In-Reply-To: <7814f923ee1c2221f1eb3f1d2e506bc6@openmailbox.org>
References: <7814f923ee1c2221f1eb3f1d2e506bc6@openmailbox.org>
Message-ID: <7B1B2E2D-F350-453C-B44D-013F64077C71@xs4all.nl>


On 02-10-2014, at 11:01, rl at openmailbox.org wrote:

> Subscribers,
> 
> What is the correct syntax to apply the 'if else' conditional statement to vector objects?
> 
> Example:
> 
> vectorx<-c(50,50,20,70)
> vectory<-c(50,50,20,20)
> vectorz<-function () {
> 	if (vectorx>vectory)
> 	vectorx
> 	else vectorx<-0
> }
> 
> vectorz()
> Warning message:
> In if (vectorx > vectory) vectorx else vectorx <- 0 :
>  the condition has length > 1 and only the first element will be used
> 
> The help manual (?'if') explains that only length=0 is acceptable; what is an appropriate alternative function to use please?
> 

And at the bottom of that page (section See Also) there is a reference to ifelse. Why didn?t you have a look at that?

Replace your complete if/else statement with ifelse(vectorx>vectory,vectorx,0)

Berend


> 
> 0 0 0 70
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Ingrid.Charvet at rms.com  Thu Oct  2 11:28:04 2014
From: Ingrid.Charvet at rms.com (Ingrid Charvet)
Date: Thu, 2 Oct 2014 02:28:04 -0700
Subject: [R] Print list to text file with list elements names
In-Reply-To: <CAF8bMcYS-gRd1fE4rZ0A7RAV=ErnHGjOMyx_1G3qOaaGvMwDdw@mail.gmail.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAC29@MAILCA6.rms.com>
	<CAF8bMcaGibkeNj5P2Xb=v2GVx=guJ8_qSf6WYyJu1WYtGA0oww@mail.gmail.com>
	<C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EACDA@MAILCA6.rms.com>
	<CAF8bMcYS-gRd1fE4rZ0A7RAV=ErnHGjOMyx_1G3qOaaGvMwDdw@mail.gmail.com>
Message-ID: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B69EAD8B@MAILCA6.rms.com>

OK I get it, all options work well now.

Thank you!

-----Original Message-----
From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: 01 October 2014 19:05
To: Ingrid Charvet
Cc: r-help at r-project.org
Subject: Re: [R] Print list to text file with list elements names

You want to put
   lapply(myList, print)
inside a call to invisible
   invisible(lapply(myList, print))

(or put the whole sink(file)/lapply(...)/sink() sequence into a function or use tmp<-lapply(...) so autoprinting is suppressed)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 1, 2014 at 10:41 AM, Ingrid Charvet <Ingrid.Charvet at rms.com> wrote:
> Hi Bill, thanks for your suggestions.
>
> Regarding the list elements names, your idea works well - thank you.
>
> However, my first issue is not resolved. I omitted the second sink
> statement, and R still created a text file with duplicate list elements.
> Then I omitted both sink statements (keeping only the lapply), but
> obviously then no text file is created at all (although it does
> "print" properly on the R console) ...
>
> I also tried:
>
>> func <- function(i) {
>> write.table(inventory[[i]],file=sprintf("test_new%d",i)) }
>> lapply(1:10,func)
>
> But here of course I get 10 different text files (one per list
> element) when what I would like is to have them all in one file...
>
> Ingrid
>
>
>
> -----Original Message-----
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: 01 October 2014 15:54
> To: Ingrid Charvet
> Cc: r-help at r-project.org
> Subject: Re: [R] Print list to text file with list elements names
>
> Omit the sink() statements to see what is happening -
> lapply(myList,print) prints
> each item in the list and then the output of lapply is printed via the
> autoprinting mechanism.
> If you put this into a function or saved the return value of lapply
> into a variable or wrapped the call to lapply in a call to invisible()
> then the autoprinting would not happen.
>
> You said that you wanted the name each list item printed before the item.
> print(myList) would do that, but I assume you've already tried that
> and didn't like the format. You can get your own formatting of the
> name with something like
>> myList <- list(First=data.frame(x=1:2,y=letters[1:2]),
> Second=data.frame(x=1:3,z=LETTERS[24:26]))
>> invisible(lapply(seq_along(myList), function(i){ cat(sep="", "\n",
>> names(myList)[i], ":\n") ; print(myList[[i]])}))
>
> First:
> x y
> 1 1 a
> 2 2 b
>
> Second:
> x z
> 1 1 X
> 2 2 Y
> 3 3 Z
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Oct 1, 2014 at 3:59 AM, Ingrid Charvet
> <Ingrid.Charvet at rms.com>
> wrote:
>> Hi everyone,
>>
>> I want to write a list of data frames to a text file and preserve the
>> names given to the list elements (I am using R 3.1.0).
>>
>> I tried:
>>
>> setNames(myList, myNames) # myNames is a vector of char elements same
>> length as myList
>>
>> sink(sprintf("%s",filename))
>> lapply(myList,print)
>> sink()
>>
>> And here I have two problems:
>>
>> 1. R writes each element of my list to the text file twice, so for
>> example if I have a list with 2 elements (i.e. data frames) in it, it will write 4:
>> in order data frame 1, data frame 2, data frame 1, data frame 2.
>>
>> 2. The names of list elements do not print to the text file.
>>
>> Any suggestions to solve these issues would be appreciated!
>> Many thanks,
>>
>> Ingrid
>>
>>
>>
>>
>> ________________________________
>> This message and any attachments contain information that may be RMS Inc.
>> confidential and/or privileged. If you are not the intended recipient
>> (or authorized to receive for the intended recipient), and have
>> received this message in error, any use, disclosure or distribution
>> is strictly prohibited. If you have received this message in error,
>> please notify the sender immediately by replying to the e-mail and
>> permanently deleting the message from your computer and/or storage system.
>>
>>
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> This message and any attachments contain information that may be RMS Inc.
> confidential and/or privileged. If you are not the intended recipient
> (or authorized to receive for the intended recipient), and have
> received this message in error, any use, disclosure or distribution is
> strictly prohibited. If you have received this message in error,
> please notify the sender immediately by replying to the e-mail and
> permanently deleting the message from your computer and/or storage system.


This message and any attachments contain information that may be RMS Inc. confidential and/or privileged.  If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited.   If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Oct  2 12:50:03 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 2 Oct 2014 11:50:03 +0100
Subject: [R] How to check to see if a variable is within a range of
 another variable
In-Reply-To: <CA+hbrhWv9DHGDe6QJ4aE8T95fyt-g48MqizKaviqzKhwTZZdSw@mail.gmail.com>
References: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
	<CA+hbrhWv9DHGDe6QJ4aE8T95fyt-g48MqizKaviqzKhwTZZdSw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412961AE1@GOLD.corp.lgc-group.com>

> > Is there an easy way to check whether a variable is within  +/- 10%
> > range of another variable in R?

You could use
2*abs(A-B)/(A+B) < 0.1

which avoids an apply().
I've assumed you meant different by under 10% of the mean of the two, hence the 2/(A+B); if you meant 10% of something else, same kind of thing should work with a different bottom line. For example if you meant less than 10% of the smaller of the two, abs(A-B)/pmin(A, B) < 0.1 would do that

And if you want to check that  they all comply,
all( 2*abs(A-B)/(A+B) < 0.1 )

will do that.

I liked Peter Langfelder's suggestion of all.equal, though;  an interesting use of a tolerance I've previously seen as there only to compensate for floating point representation errors. 

Steve E




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From geomodelers at gmail.com  Thu Oct  2 13:27:42 2014
From: geomodelers at gmail.com (Andre)
Date: Thu, 2 Oct 2014 18:27:42 +0700
Subject: [R] Inverse Student t-value
In-Reply-To: <OF8EB5B20C.AD2AD3BB-ON85257D64.004E5353-85257D64.004E5BF9@ria.buffalo.edu>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
	<CALzoxKDOxpCYeWbwT-JAvKOMeZCzpXH1Av4ht4qk3spakOHg7A@mail.gmail.com>
	<OF64AC775B.53D06187-ON85257D63.006B1EFA-85257D63.006C02CD@ria.buffalo.edu>
	<CALzoxKBKHTWiJV82Uoc1nWLYEVixvFmtAseCqiO0k4arMQXQ+Q@mail.gmail.com>
	<OF8EB5B20C.AD2AD3BB-ON85257D64.004E5353-85257D64.004E5BF9@ria.buffalo.edu>
Message-ID: <CALzoxKBvcPeZmWZRN+ArA=tGFhQdysDZcm+m1N+j97AFwm3Nzw@mail.gmail.com>

Dear All,

The manual formula mean that how to calculate that value by hand for
TINV(0.0000408831, 1221) and the resulted is 4.0891672

Appreciate your help in advance.

Cheers!


On Wed, Oct 1, 2014 at 9:15 PM, <JLucke at ria.buffalo.edu> wrote:

> What do you mean by a "manual" formula?
>
>
>  *Andre <geomodelers at gmail.com <geomodelers at gmail.com>>*
>
> 09/30/2014 11:54 PM
>   To
> JLucke at ria.buffalo.edu,
> cc
> Duncan Murdoch <murdoch.duncan at gmail.com>, "r-help at r-project.org" <
> r-help at r-project.org>, r-help-bounces at r-project.org
> Subject
> Re: [R] Inverse Student t-value
>
>
>
>
> Hi JLucke,
>
> Maybe the old excel function. TINV and T.INV.2T is same function for Two-Tailed
> Inverse of the student`s t-distribution but T.INV use for Left-Tailed
> inverse of the Student's t-distribution and can be use for  Inverse of
> the student`s t-distribution.
>
>
> I know automatic or functions any software but I just need a manual
> formula or compute formula (TINV or T.INV.2T) step by step presented by
> math for calculate until resulted.
>
> Thanks in advance.
>
>
> Cheers!
>
>
>
> On Wed, Oct 1, 2014 at 2:39 AM, <*JLucke at ria.buffalo.edu*
> <JLucke at ria.buffalo.edu>> wrote:
> The website has your answer.  The t-distribution is a regularized
> incomplete beta function.  The incomplete beta function is given by R's
> *pbeta* function.  You regularize it with R's *beta* function.  Then you
> use R's *uniroot* function to find the inverse.  Good homework problem.
>
>   *Andre <**geomodelers at gmail.com* <geomodelers at gmail.com>*>*
> Sent by: *r-help-bounces at r-project.org* <r-help-bounces at r-project.org>
>
> 09/30/2014 02:45 PM
>
>   To
> Duncan Murdoch <*murdoch.duncan at gmail.com* <murdoch.duncan at gmail.com>>,
> cc
> "*r-help at r-project.org* <r-help at r-project.org>" <*r-help at r-project.org*
> <r-help at r-project.org>>
> Subject
> Re: [R] Inverse Student t-value
>
>
>
>
>
>
> Hi Duncan,
>
> Let me explain again, I just need a manual expression for inverse student t
> value.
>
> You could go to web page
> *http://www.danielsoper.com/statcalc3/calc.aspx?id=10*
> <http://www.danielsoper.com/statcalc3/calc.aspx?id=10>
>
> That's inverse student t value calculator. Do you know a manual expression
> use it.
>
> Cheers!
>
>
> On Wednesday, October 1, 2014, Duncan Murdoch <*murdoch.duncan at gmail.com*
> <murdoch.duncan at gmail.com>>
> wrote:
>
> > On 30/09/2014 2:26 PM, Andre wrote:
> >
> >> Hi Duncan,
> >>
> >> Actually, I am trying trace the formula for the "Critical value of Z"
> and
> >> manual formula is =(I7-1)/SQRT(I7)*SQRT((TINV(0.
> >> 05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
> >>
> >> So, I got new problem for TINV formula. I just need a manual equation
> for
> >> TINV.
> >>
> >
> > Sorry, can't help.  I'm not sure I understand what you want, but if it's
> a
> > simple formula for quantiles of the t distribution, it doesn't exist.
> >
> > Duncan Murdoch
> >
> >
> >> Hope solve this problem.
> >>
> >> Cheers!
> >>
> >>
> >> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch <
> *murdoch.duncan at gmail.com* <murdoch.duncan at gmail.com>
> >> <*mailto:murdoch.duncan at gmail.com* <murdoch.duncan at gmail.com>>> wrote:
> >>
> >>     On 30/09/2014 2:11 PM, Andre wrote:
> >>
> >>         Hi Duncan,
> >>
> >>         No, that's correct. Actually, I have data set below;
> >>
> >>
> >>     Then it seems Excel is worse than I would have expected.  I
> >>     confirmed R's value in two other pieces of software,
> >>     OpenOffice and some software I wrote a long time ago based on an
> >>     algorithm published in 1977 in Applied Statistics. (They are
> >>     probably all using the same algorithm.  I wonder what Excel is
> doing?)
> >>
> >>         N= 1223
> >>         alpha= 0.05
> >>
> >>         Then
> >>         probability= 0.05/1223=0.0000408831
> >>         degree of freedom= 1223-2= 1221
> >>
> >>         So, TINV(0.0000408831,1221) returns 4.0891672
> >>
> >>
> >>         Could you show me more detail a manual equation. I really
> >>         appreciate it if you may give more detail.
> >>
> >>
> >>     I already gave you the expression:  abs(qt(0.0000408831/2,
> >>     df=1221)). For more detail, I suppose you could look at the help
> >>     page for the qt function, using help("qt").
> >>
> >>     Duncan Murdoch
> >>
> >>
> >>         Cheers!
> >>
> >>
> >>         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
> >>         <*murdoch.duncan at gmail.com* <murdoch.duncan at gmail.com> <
> *mailto:murdoch.duncan at gmail.com* <murdoch.duncan at gmail.com>>
> >>         <*mailto:murdoch.duncan at gmail.com* <murdoch.duncan at gmail.com>
> >>         <*mailto:murdoch.duncan at gmail.com* <murdoch.duncan at gmail.com>
> >>> wrote:
>
> >>
> >>             On 30/09/2014 1:31 PM, Andre wrote:
> >>
> >>                 Dear Sir/Madam,
> >>
> >>                 I am trying to use calculation for two-tailed inverse
> >>         of the
> >>                 student`s
> >>                 t-distribution function presented by Excel functions
> like
> >>                 =TINV(probability, deg_freedom).
> >>
> >>                 For instance: The Excel function
> >>         =TINV(0.0000408831,1221) =         returns
> >>                   4.0891672.
> >>
> >>                 Would you like to show me a manual calculation for this?
> >>
> >>                 Appreciate your helps in advance.
> >>
> >>
> >>             That number looks pretty far off the true value. Have you
> >>         got a
> >>             typo in your example?
> >>
> >>             You can compute the answer to your question as
> >>             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
> >>
> >>             Duncan Murdoch
> >>
> >>
> >>
> >>
> >>
> >>
> >
>
>                 [[alternative HTML version deleted]]
>
> ______________________________________________
> *R-help at r-project.org* <R-help at r-project.org> mailing list
> *https://stat.ethz.ch/mailman/listinfo/r-help*
> <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide
> *http://www.R-project.org/posting-guide.html*
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Oct  2 13:55:28 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 2 Oct 2014 12:55:28 +0100
Subject: [R] Inverse Student t-value
In-Reply-To: <CALzoxKBvcPeZmWZRN+ArA=tGFhQdysDZcm+m1N+j97AFwm3Nzw@mail.gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>
	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>
	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>
	<542AF83E.40203@gmail.com>
	<CALzoxKDOxpCYeWbwT-JAvKOMeZCzpXH1Av4ht4qk3spakOHg7A@mail.gmail.com>
	<OF64AC775B.53D06187-ON85257D63.006B1EFA-85257D63.006C02CD@ria.buffalo.edu>
	<CALzoxKBKHTWiJV82Uoc1nWLYEVixvFmtAseCqiO0k4arMQXQ+Q@mail.gmail.com>
	<OF8EB5B20C.AD2AD3BB-ON85257D64.004E5353-85257D64.004E5BF9@ria.buffalo.edu>
	<CALzoxKBvcPeZmWZRN+ArA=tGFhQdysDZcm+m1N+j97AFwm3Nzw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412961B62@GOLD.corp.lgc-group.com>

> The manual formula mean that how to calculate that value by hand for
> TINV(0.0000408831, 1221) and the resulted is 4.0891672

This is not really an R help question - you're specifically asking for something that _doesn't_ use R - but if you want to know how R does it the full C and R code for pt and qt in R (the cumulative probability distribution and the inverse, quantile, function respectively) is available in the R source code, which you can obtain from CRAN; see http://CRAN.R-project.org/mirrors.html - see the source code link from any of the listed mirrors.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jvadams at usgs.gov  Thu Oct  2 14:40:08 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 2 Oct 2014 07:40:08 -0500
Subject: [R] optimization question
In-Reply-To: <1412209826.33353.YahooMailBasic@web161602.mail.bf1.yahoo.com>
References: <1412209826.33353.YahooMailBasic@web161602.mail.bf1.yahoo.com>
Message-ID: <CAN5YmCFk0+bo9FuvGVkw4dAAWMHD9TxB+LJTus_0y-UZOtp-wQ@mail.gmail.com>

Andras,

Is there an error in your post or am I missing something?

df[, 9] is made up of the last (9th) element of each of a, b, c, and d.
The minimum value for sum(df[, 9]) is 0.
Given your conditions, there are many, many ways to get this result.
Here is just one example:
a <-c(1,1,1,1,1,0,0,0,0)
b <-c(1,0,1,1,1,1,0,0,0)
c <-c(1,0,1,1,0,0,0,0,0)
d <-c(1,1,1,1,0,1,0,0,0)
df <-rbind(a,b,c,d)
df <-cbind(df,h=c(sum(a)*8,sum(b)*8,sum(c)*8,sum(d)*8))
df <-cbind(df,df[,8]*c(1,2,3,2))

Jean



On Wed, Oct 1, 2014 at 7:30 PM, Andras Farkas <motyocska at yahoo.com> wrote:

> Dear All,
>
> please provide help with the following:
>
> we have
>
> a <-c(0,1,1,0,1,0,0,0,0)
> b <-c(0,0,0,1,0,0,0,0,0)
> c <-c(1,0,1,0,1,1,0,0,0)
> d <-c(0,1,0,1,0,1,0,0,0)
> df <-rbind(a,b,c,d)
> df <-cbind(df,h=c(sum(a)*8,sum(b)*8,sum(c)*8,sum(d)*8))
> df <-cbind(df,df[,8]*c(1,2,3,2))
>
> I would like to minimize the value for sum(df[,9]) under the following
> conditions:
>
> 1. all values of a,b,c, and d are binary variables and are the variables
> to change to get the optimal result
> 2. sum(a), sum(b), and sum(d) should be each 5 or more
> 3. sum(c) should be 3 or less
> 4. a[2], a[3], b[2], d[7] and d[8] are fixed to their current values.
>
> any thoughts or reference examples you could help with is greatly
> appreciated
>
> thanks
>
> andras
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From motyocska at yahoo.com  Thu Oct  2 14:48:45 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Thu, 2 Oct 2014 12:48:45 +0000 (UTC)
Subject: [R] optimization question
In-Reply-To: <CAN5YmCFk0+bo9FuvGVkw4dAAWMHD9TxB+LJTus_0y-UZOtp-wQ@mail.gmail.com>
References: <CAN5YmCFk0+bo9FuvGVkw4dAAWMHD9TxB+LJTus_0y-UZOtp-wQ@mail.gmail.com>
Message-ID: <1131493407.140442.1412254125902.JavaMail.yahoo@jws106141.mail.bf1.yahoo.com>

There is an error jean, I apologize... I made changes to the vectors and did not correct the bottom line... this is the correct run:a <-c(0,1,1,0,1,0,0,0,0)
b <-c(0,0,0,1,0,0,0,0,0)
c <-c(1,0,1,0,1,1,0,0,0)
d <-c(0,1,0,1,0,1,0,0,0)
df <-rbind(a,b,c,d)
df <-cbind(df,h=c(sum(a)*8,sum(b)*8,sum(c)*8,sum(d)*8))
df <-cbind(df,df[,10]*c(1,2,3,2))?and I would like to minimize the value for sum(df[,11]) under the following conditions:?1. all values of a,b,c, and d are binary variables and are the variables to change to get the optimal result
 2. sum(a), sum(b), and sum(d) should be each 5 or more
 3. sum(c) should be 3 or less
 4. a[2], a[3], b[2], d[7] and d[8] are fixed to their current values.
?sorry about that and thanks for taking the time to respond,?Andras
 

     On Thursday, October 2, 2014 8:40 AM, "Adams, Jean" <jvadams at usgs.gov> wrote:
   

 Andras,
Is there an error in your post or am I missing something?
df[, 9] is made up of the last (9th) element of each of a, b, c, and d.The minimum value for sum(df[, 9]) is 0.Given your conditions, there are many, many ways to get this result.Here is just one example:a <-c(1,1,1,1,1,0,0,0,0)b <-c(1,0,1,1,1,1,0,0,0)c <-c(1,0,1,1,0,0,0,0,0)d <-c(1,1,1,1,0,1,0,0,0)df <-rbind(a,b,c,d)df <-cbind(df,h=c(sum(a)*8,sum(b)*8,sum(c)*8,sum(d)*8))df <-cbind(df,df[,8]*c(1,2,3,2))
Jean


On Wed, Oct 1, 2014 at 7:30 PM, Andras Farkas <motyocska at yahoo.com> wrote:

Dear All,

please provide help with the following:

we have

a <-c(0,1,1,0,1,0,0,0,0)
b <-c(0,0,0,1,0,0,0,0,0)
c <-c(1,0,1,0,1,1,0,0,0)
d <-c(0,1,0,1,0,1,0,0,0)
df <-rbind(a,b,c,d)
df <-cbind(df,h=c(sum(a)*8,sum(b)*8,sum(c)*8,sum(d)*8))
df <-cbind(df,df[,8]*c(1,2,3,2))

I would like to minimize the value for sum(df[,9]) under the following conditions:

1. all values of a,b,c, and d are binary variables and are the variables to change to get the optimal result
2. sum(a), sum(b), and sum(d) should be each 5 or more
3. sum(c) should be 3 or less
4. a[2], a[3], b[2], d[7] and d[8] are fixed to their current values.

any thoughts or reference examples you could help with is greatly appreciated

thanks

andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




   
	[[alternative HTML version deleted]]


From Keith.Jewell at campdenbri.co.uk  Thu Oct  2 15:06:35 2014
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Thu, 2 Oct 2014 14:06:35 +0100
Subject: [R] How to check to see if a variable is within a range of
 another variable
In-Reply-To: <ED8CD182D432434485C7D1787FB06DDC2284F78EA9@AKLEXM01.PFR.CO.NZ>
References: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2284F78EA9@AKLEXM01.PFR.CO.NZ>
Message-ID: <542D4DDB.7030202@campdenbri.co.uk>

On 01/10/2014 23:54, Peter Alspach wrote:
> Tena koe Kate
>
> If kateDF is a data.frame with your data, then
>
> apply(kateDF, 1, function(x) isTRUE(all.equal(x[2], x[1], check.attributes = FALSE, tolerance=0.1)))
>
> comes close to (what I think) you want (but not to what you have illustrated in your 'eventual outcome').  Anyhow, it may be enough to allow you to get there.
>
> HTH ....
>
> Peter Alspach
>

I seem to need to specify all.equal(..., scale) to get correct values 
for some data/tolerances:
--------------
aDF <- data.frame(a = 1:10, b=10:1)

apply(aDF, 1, function(x)
   isTRUE(all.equal(x[2], x[1], check.attributes = FALSE, tolerance = 5, 
scale = 1))
   )
#  [1] FALSE FALSE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE
apply(aDF, 1, function(x)
   isTRUE(all.equal(x[2], x[1], check.attributes = FALSE, tolerance = 5))
)
#  [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE
----------------------
I'm probably being stupid, but from reading ?all.equal I would have 
expected scale = 1 and the default scale = NULL to give identical 
results for the length one numerics being passed to all.equal.

Can anyone explain?

KJ


From Ramgad82 at gmx.net  Thu Oct  2 15:13:18 2014
From: Ramgad82 at gmx.net (Dagmar)
Date: Thu, 02 Oct 2014 15:13:18 +0200
Subject: [R] merge by time,
	certain value if 5 min before and after an "event"
Message-ID: <542D4F6E.6030607@gmx.net>

Hello! I hope someone can help me. It would save me days of work. Thanks in
advance!
I have two dataframes which look like these:


myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012
10:00:00",
"24.09.2012 11:00:00"), Event=c("low","high","low") )
myframe


mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
10:05:10")
, location=c("1","2","3","1","5") )
mydata


# I want to merge them by time so I have a dataframe which looks like this
in the end (i.e. "Low"  during 5 min before and after "high" )

result <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
10:05:10")
, location=c("1","2","3","1","5") ,
Event=c("low", "low","high","high","low"))
result

Anyone knows how do merge them?
Best regards,
Dagmar


From S.Ellison at LGCGroup.com  Thu Oct  2 15:55:11 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 2 Oct 2014 14:55:11 +0100
Subject: [R] How to check to see if a variable is within a range of
 another variable
In-Reply-To: <542D4DDB.7030202@campdenbri.co.uk>
References: <CAE6QMsbOXxefSS1k01rUH9juF72F=2Z5kuoh6B253axzsfVkkA@mail.gmail.com>
	<ED8CD182D432434485C7D1787FB06DDC2284F78EA9@AKLEXM01.PFR.CO.NZ>
	<542D4DDB.7030202@campdenbri.co.uk>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412961C3C@GOLD.corp.lgc-group.com>

Keith Jewell said:
> ... from reading ?all.equal I would have expected
> scale = 1 and the default scale = NULL to give identical results for the length
> one numerics being passed to all.equal.
> 
> Can anyone explain?

Inspectng the code in all.equal.numeric, I find

xy <- mean((if (cplx) 
        Mod
    else abs)(target - current))
if (is.null(scale)) {
        xn <- mean(abs(target))
        if (is.finite(xn) && xn > tolerance) {
            xy <- xy/xn
            "relative"
        }
        else "absolute"
    }
    else {
        xy <- xy/scale
        if (scale == 1) 
            "absolute"
        else "scaled"
    }

target is the first number supplied, current the second; in yoour example code that is x[2] and x[1] respectively. Later on xy is compared to the tolerance.

In the code, scale=NULL and scale=1 are clearly treated differently; in particular when scale is NULL the absolute difference is divided by first of the (two) numbers if that number is greater than tolerance or is used unchanged, and if scale=1 it is divided by scale throughout.

That would mean that for scale=NULL, your example will divide the difference by 10, 9, ..1 in that order before comparing with tolerance, and if scale=1 it will simply compare the difference directly with the tolerance. Calculating your case through for scale = NULL, xy will take the values 
ifelse(b>5, abs(a-b)/b, abs(a-b))
 [1] 0.9000000 0.7777778 0.6250000 0.4285714 0.1666667 1.0000000 3.0000000
 [8] 5.0000000 7.0000000 9.0000000

Of those, only the last 2 are greater than 5, which is the result you found. By contrast, when scale=1 xy takes the values
abs(a-b)
  [1] 9 7 5 3 1 1 3 5 7 9
of which the two at each end are both greater than 5.

That fairly complicated behavio0ur is probably a good reason to use a simpler calculation in which you can see how the difference is being scaled ... ;)

Steve Ellison


 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bernardo_brandaum at yahoo.com.br  Thu Oct  2 16:11:56 2014
From: bernardo_brandaum at yahoo.com.br (Bernardo Santos)
Date: Thu, 2 Oct 2014 07:11:56 -0700
Subject: [R] accumulation curve for kernel density using adehabitatHR
Message-ID: <1412259116.59924.YahooMailNeo@web126202.mail.ne1.yahoo.com>

Dear all,

I am trying to create an accumulation curve for kernel density estimation (KDE) of home range size, with kernel density in the y-axis and number of telemetry fixes in the x-axis. I am using "kernelUD" and "getverticeshr" functions from adehabitatHR package.

However, I have a problem: when re-sampling a few number of points to calculate KDE, the function getverticeshr (and sometimes kernelUD also) returns an error (maybe because the fixes are too close and it is impossible to normalize the surface, but I am not sure), and then it is impossible to build the accumulation curve.

I tried to "throw out" this cases in which the functions return errors and sample once again, but it produces a bias towards high and unrealistic values of home range estimation.

Have anyone worked with that before, or have any cues on how to solve that?

Thank you very much.
Bernardo Niebuhr

	[[alternative HTML version deleted]]


From kw1958 at gmail.com  Thu Oct  2 16:19:14 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Thu, 2 Oct 2014 10:19:14 -0400
Subject: [R] Befuddled by ddply
Message-ID: <F1B69245-738E-4632-915D-7DB141F75823@gmail.com>

Folks,

I have the following data:

mdf<-structure(list(a = 1:3, b = c(10, 20, 30)), .Names = c("a", "b"
), row.names = c(NA, -3L), class = "data.frame")

And function:

defCurveBreak<-function(x, y) {
  cumsum(rep(diff(c(0, x)), each = y)/y)
}

lapply'ing to get the result "foo"

foo<-data.frame(lapply(mdf, function(x, y) defCurveBreak(x,y), 4))
> foo
      a    b
1  0.25  2.5
2  0.50  5.0
3  0.75  7.5
4  1.00 10.0
5  1.25 12.5
6  1.50 15.0
7  1.75 17.5
8  2.00 20.0
9  2.25 22.5
10 2.50 25.0
11 2.75 27.5
12 3.00 30.0

Which all works fine. 

I was wondering is there a way to do this using ddply? Is there a reason to do this using ddply rather than the above idiom?

I spent a bunch of time trying to figure out how to set it up in ddply (is that the wrong tool?) to no avail.

Thanks for your time,
Best,
KW


From eliza_botto at hotmail.com  Thu Oct  2 16:54:12 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Thu, 2 Oct 2014 14:54:12 +0000
Subject: [R] (no subject)
Message-ID: <BLU170-W9EC28CAF7F5462542635D89B90@phx.gbl>

Dear UseRs,
I obtained following results from Anderson-Darling Goodness of fit test.
> dput(EB)
structure(c(2.911, 0.9329, 0.818, 1.539, 0.604, 0.5142, 0.4344, 0.801, 0.963, 0.9925, 0.933, 0.956, 0.883, 0.572), .Dim = c(7L, 2L), .Dimnames = list(c("EXP", "GUM", "GENLOG", "GENPARETO", "GEV", "LN", "PAR3"), c("A2", "P")))
My question is how to interpret these results? More precisely, which distribution fitted well on my data?

Thankyou very much in advance

Eliza 		 	   		  
	[[alternative HTML version deleted]]


From JLucke at ria.buffalo.edu  Thu Oct  2 17:22:07 2014
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Thu, 2 Oct 2014 11:22:07 -0400
Subject: [R] Inverse Student t-value
In-Reply-To: <CALzoxKBvcPeZmWZRN+ArA=tGFhQdysDZcm+m1N+j97AFwm3Nzw@mail.gmail.com>
References: <CALzoxKBJq72NWFt4waxNwzXS-RRErTDy7eyT6Qre4nQyfmC38g@mail.gmail.com>	<542AEFE7.4060601@gmail.com>
	<CALzoxKC6DbXf=0Vk197-DiSFRmVqP4YHrum+stGDYr3q2ymH6g@mail.gmail.com>	<542AF477.9040603@gmail.com>
	<CALzoxKBx95DYJ7oF6ghixO3MEEiEUKF+hRcnwxEi7Z_8Mgyb7Q@mail.gmail.com>	<542AF83E.40203@gmail.com>
	<CALzoxKDOxpCYeWbwT-JAvKOMeZCzpXH1Av4ht4qk3spakOHg7A@mail.gmail.com>	<OF64AC775B.53D06187-ON85257D63.006B1EFA-85257D63.006C02CD@ria.buffalo.edu>
	<CALzoxKBKHTWiJV82Uoc1nWLYEVixvFmtAseCqiO0k4arMQXQ+Q@mail.gmail.com>	<OF8EB5B20C.AD2AD3BB-ON85257D64.004E5353-85257D64.004E5BF9@ria.buffalo.edu>
	<CALzoxKBvcPeZmWZRN+ArA=tGFhQdysDZcm+m1N+j97AFwm3Nzw@mail.gmail.com>
Message-ID: <OF1BD0AF14.691C0146-ON85257D65.0052FA77-85257D65.00546CDD@ria.buffalo.edu>

Andre
For the last time, there is NO simple rational approximation to the 
quantiles of the t-distribution.

From  R help, qt = TINV is based on 
Hill, G. W. (1970) Algorithm 396: Student's t-quantiles. Communications of 
the ACM, 13(10), 619?620.  And
Hill, G. W. (1981) Remark on Algorithm 396, ACM Transactions on 
Mathematical Software, 7, 250?1. 

Both of these articles can be googled and the source code obtained from 
the ACM.  (I have done it.)
The code uses a rational approximation to the inverse for which you can 
compute values by hand.
Then you can see why we use qt().  :-)
Joe




Andre <geomodelers at gmail.com> 
10/02/2014 07:27 AM

To
JLucke at ria.buffalo.edu, 
cc
Duncan Murdoch <murdoch.duncan at gmail.com>, "r-help at r-project.org" 
<r-help at r-project.org>, r-help-bounces at r-project.org
Subject
Re: [R] Inverse Student t-value






Dear All,

The manual formula mean that how to calculate that value by hand for 
TINV(0.0000408831, 1221) and the resulted is 4.0891672

Appreciate your help in advance.

Cheers!


On Wed, Oct 1, 2014 at 9:15 PM, <JLucke at ria.buffalo.edu> wrote:
What do you mean by a "manual" formula? 



Andre <geomodelers at gmail.com> 
09/30/2014 11:54 PM 


To
JLucke at ria.buffalo.edu, 
cc
Duncan Murdoch <murdoch.duncan at gmail.com>, "r-help at r-project.org" <
r-help at r-project.org>, r-help-bounces at r-project.org 
Subject
Re: [R] Inverse Student t-value








Hi JLucke, 

Maybe the old excel function. TINV and T.INV.2T is same function for T
wo-Tailed Inverse of the student`s t-distribution but T.INV use for 
Left-Tailed inverse of the Student's t-distribution and can be use for 
 Inverse of the student`s t-distribution. 


I know automatic or functions any software but I just need a manual 
formula or compute formula (TINV or T.INV.2T) step by step presented by 
math for calculate until resulted. 

Thanks in advance. 


Cheers! 



On Wed, Oct 1, 2014 at 2:39 AM, <JLucke at ria.buffalo.edu> wrote: 
The website has your answer.  The t-distribution is a regularized 
incomplete beta function.  The incomplete beta function is given by R's 
pbeta function.  You regularize it with R's beta function.  Then you use 
R's uniroot function to find the inverse.  Good homework problem. 


Andre <geomodelers at gmail.com> 
Sent by: r-help-bounces at r-project.org 
09/30/2014 02:45 PM 


To
Duncan Murdoch <murdoch.duncan at gmail.com>, 
cc
"r-help at r-project.org" <r-help at r-project.org> 
Subject
Re: [R] Inverse Student t-value










Hi Duncan,

Let me explain again, I just need a manual expression for inverse student 
t
value.

You could go to web page
http://www.danielsoper.com/statcalc3/calc.aspx?id=10

That's inverse student t value calculator. Do you know a manual expression
use it.

Cheers!


On Wednesday, October 1, 2014, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 30/09/2014 2:26 PM, Andre wrote:
>
>> Hi Duncan,
>>
>> Actually, I am trying trace the formula for the "Critical value of Z" 
and
>> manual formula is =(I7-1)/SQRT(I7)*SQRT((TINV(0.
>> 05/I7,I7-2))^2/(I7-2+TINV(0.05/I7,I7-2)))
>>
>> So, I got new problem for TINV formula. I just need a manual equation 
for
>> TINV.
>>
>
> Sorry, can't help.  I'm not sure I understand what you want, but if it's 
a
> simple formula for quantiles of the t distribution, it doesn't exist.
>
> Duncan Murdoch
>
>
>> Hope solve this problem.
>>
>> Cheers!
>>
>>
>> On Wed, Oct 1, 2014 at 1:20 AM, Duncan Murdoch <
murdoch.duncan at gmail.com
>> <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 30/09/2014 2:11 PM, Andre wrote:
>>
>>         Hi Duncan,
>>
>>         No, that's correct. Actually, I have data set below;
>>
>>
>>     Then it seems Excel is worse than I would have expected.  I
>>     confirmed R's value in two other pieces of software,
>>     OpenOffice and some software I wrote a long time ago based on an
>>     algorithm published in 1977 in Applied Statistics. (They are
>>     probably all using the same algorithm.  I wonder what Excel is 
doing?)
>>
>>         N= 1223
>>         alpha= 0.05
>>
>>         Then
>>         probability= 0.05/1223=0.0000408831
>>         degree of freedom= 1223-2= 1221
>>
>>         So, TINV(0.0000408831,1221) returns 4.0891672
>>
>>
>>         Could you show me more detail a manual equation. I really
>>         appreciate it if you may give more detail.
>>
>>
>>     I already gave you the expression:  abs(qt(0.0000408831/2,
>>     df=1221)). For more detail, I suppose you could look at the help
>>     page for the qt function, using help("qt").
>>
>>     Duncan Murdoch
>>
>>
>>         Cheers!
>>
>>
>>         On Wed, Oct 1, 2014 at 1:01 AM, Duncan Murdoch
>>         <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>>         <mailto:murdoch.duncan at gmail.com
>>         <mailto:murdoch.duncan at gmail.com 
>>> wrote: 

>>
>>             On 30/09/2014 1:31 PM, Andre wrote:
>>
>>                 Dear Sir/Madam,
>>
>>                 I am trying to use calculation for two-tailed inverse
>>         of the
>>                 student`s
>>                 t-distribution function presented by Excel functions 
like
>>                 =TINV(probability, deg_freedom).
>>
>>                 For instance: The Excel function
>>         =TINV(0.0000408831,1221) =         returns
>>                   4.0891672.
>>
>>                 Would you like to show me a manual calculation for 
this?
>>
>>                 Appreciate your helps in advance.
>>
>>
>>             That number looks pretty far off the true value. Have you
>>         got a
>>             typo in your example?
>>
>>             You can compute the answer to your question as
>>             abs(qt(0.0000408831/2, df=1221)), but you'll get 4.117.
>>
>>             Duncan Murdoch
>>
>>
>>
>>
>>
>>
>

                [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list 
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.





	[[alternative HTML version deleted]]


From acos at dpi.inpe.br  Thu Oct  2 17:40:54 2014
From: acos at dpi.inpe.br (=?iso-8859-1?Q?Alexsandro_C=E2ndido_de_Oliveira_Silva?=)
Date: Thu, 2 Oct 2014 12:40:54 -0300
Subject: [R] tkProgressBar without progress in foreach %dopar%
Message-ID: <000001cfde57$40fc47b0$c2f4d710$@dpi.inpe.br>

I have a list (temp.data) with many raster data and some computations are in
parallel. n is the number of raster data and target is the mask. I'd like to
use a progress bar. It is created but while the loop is running the progress
is not showed. The loop ends and the progress bar is closed. I've tried to
use the functions pdCreate/pdStep in raster package, but without success...

Someone have any idea...



    mypb <- tkProgressBar(title = "R progress bar", label = "",  min = 0,
max = n, initial = 0, width = 300)



    #creating a computing cluster

    cl <- makeCluster(detectCores(),type='SOCK')

    registerDoParallel(cl, cores = detectCores())



    foreach(i=1:n,.packages=c('tcltk','rgdal','raster')) %dopar% {

      Sys.sleep(.1)

      setTkProgressBar(mypb, i, title = "R progress bar", label = NULL)




temp.data[[i]]<-mask(temp.data[[i]],target,maskvalue=as.numeric(class.outsid
e))


writeRaster(temp.data[[i]],filename=files.list[i],format='GTiff',overwrite=T
)

    }



    stopCluster(cl)

    close(mypb)





Thanks

Alexsandro





____________________________________________________________________________
_______





---
Este email est? limpo de v?rus e malwares porque a prote??o do avast! Antiv?rus est? ativa.
http://www.avast.com

	[[alternative HTML version deleted]]


From mtb954 at gmail.com  Thu Oct  2 18:12:46 2014
From: mtb954 at gmail.com (mtb954 at gmail.com)
Date: Thu, 2 Oct 2014 10:12:46 -0600
Subject: [R] Problem using predict() to draw lines() if predictor variable
 is logged on the fly
Message-ID: <CAOF_sWReW+5d0EjvVKrTxjKHHiOS753s52YL5R72H2q7z-gmWw@mail.gmail.com>

Hello,

I am plotting glms with logged predictors. I would like to define the
logged variables "on the fly" rather than hard coding them into my
dataframe.

This code (with hard-coded logged variables) works just fine:

xx<-seq(-2,.5,by=0.1); lines(xx,predict(power,list(LogArKm00=xx),type=
"response"),col="black",lwd=2,lty=1) #LogArKm00 is a variable in my
dataframe

but my attempt to define them "on the fly" doesn't work (see error below):

plot(log(WbAb,10)~log(ArKm00,10),data=dat) #power model

xx<-seq(-2,.5,by=0.1); lines(xx,predict(power,list(log(ArKm00,10)=xx),type=
"response"),col="black",lwd=2,lty=1) #trying to log the variable "on the
fly"


Error: unexpected '=' in " lines(xx,predict(power,list(log(ArKm00,10)="

I would really appreciate any help sorting this out!

Many thanks

Mark

	[[alternative HTML version deleted]]


From asma.rabe at gmail.com  Thu Oct  2 17:20:18 2014
From: asma.rabe at gmail.com (Asma rabe)
Date: Fri, 3 Oct 2014 00:20:18 +0900
Subject: [R] order clusters in heatmap.2
Message-ID: <CA+T12rjSTvMwypxHCTU9L7Dbs_cA+Rt9KujzcxArssK=K_XWnw@mail.gmail.com>

Hi ,

Is there a way to order clusters in heatmap.2  ?

Best Regards,
Asmaa

	[[alternative HTML version deleted]]


From Eli.Ateljevich at water.ca.gov  Thu Oct  2 17:40:47 2014
From: Eli.Ateljevich at water.ca.gov (Ateljevich, Eli@DWR)
Date: Thu, 2 Oct 2014 15:40:47 +0000
Subject: [R] concentrated likelihood in dlm
Message-ID: <73F8F665C0FCF549AF963069AB8CB27F4D6E14@057-SN2MPN1-043.057d.mgd.msft.net>


Hi,
I am trying to do maximum likelihood estimation on a univariate structural model with diffuse components in dlm.



The package already has an MLE function, but I would like to implement two enhancements, both of which are discussed in Harvey's Forecasting structural time series models and the Kalman Filter, section 3.4:
1. drop the d first components for diffusive terms  to construct a proper prior
2. swap in the concentrated univariate likelihood for the standard multivariate (concentrated variance being the prediction error variance).



The first item is easy, so my question surrounds item (2). My hope is to re-use the MLE calculation apparatus in dlm, but swap out either one line in dlmLL that augments the likelihood.



The concentrated likelihood requires two ingredients that come from the filter: the one step ahead prediction error and its variance. I believe that the prediction errors are easy to find. There are functions that produce it outside dlmLL and also it is pretty easy to find in dlmLL itself. I am less clear how to obtain the variance, which is the univariate Var(y(t)|y(t-1)) and is denoted f_t in Harvey's book. Here y is the observation. My confidence is low because the function is written for a multivariate filter with SVD expression and my R skills are beginning-intermediate. At best I think f is here in SVD form and I'm concerned I might have to cast it or something if I want to work with it as a scalar.



Can anyone help me with an example of how to obtain f_t? Either within dlmLL or without? I appreciate any hints I can get.



	[[alternative HTML version deleted]]


From lopez235 at llnl.gov  Thu Oct  2 19:46:43 2014
From: lopez235 at llnl.gov (Lopez, Dan)
Date: Thu, 2 Oct 2014 17:46:43 +0000
Subject: [R] Custom Function Not Completely working
In-Reply-To: <542A060C.3070204@gmail.com>
References: <56180B40A4F72A4083C75B30DA8629733A8C5714@PRDEXMBX-05.the-lab.llnl.gov>
	<542A060C.3070204@gmail.com>
Message-ID: <56180B40A4F72A4083C75B30DA8629733A8C6239@PRDEXMBX-05.the-lab.llnl.gov>

Thank you Duncan!

Dan


-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: Monday, September 29, 2014 6:23 PM
To: Lopez, Dan; R help (r-help at r-project.org)
Subject: Re: [R] Custom Function Not Completely working

On 29/09/2014, 9:07 PM, Lopez, Dan wrote:
> Hi R Experts,
> 
> I'm in the process of creating a set of convenience functions for myself. I am somewhat new to writing functions in r.
> 
> In this example I wanted to load both existing files called KuhnPerform.Rdata and KuhnPerform.Rhistory. However it only works for loading the .Rhistory file and not the .Rdata file. Can someone please tell me how to fix this so that it loads both .Rdata and .Rhistory?
> 
> I checked dir() that these files are in my working directory and are 
> spelled correctly
> 
> loads<-function(filename="KuhnPerform"){
> load(paste0(filename,".Rdata")) # Load a previously saved workspace.
> loadhistory(paste0(filename,".Rhistory")) # Load a previously saved history file.
> }

You're loading the objects from the Rdata file into the evaluation frame of your function, and they go away afterwards.  You need to specify where they should be loaded using the envir argument, e.g.


load(paste0(filename,".Rdata"), envir = parent.frame())

(The funny thing here is that the default for envir is parent.frame(), but it means something different in that context.)

Duncan Murdoch

> 
> Dan
> Workforce Analyst
> LLNL
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


From pdalgd at gmail.com  Thu Oct  2 19:50:32 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 2 Oct 2014 19:50:32 +0200
Subject: [R] Best Beginner Books?
In-Reply-To: <CAK1hC9tJA02VOzQ06+P5=rYpweY_jREyN1f3roc9S17vxFP8Xw@mail.gmail.com>
References: <6084C89E-AB60-4C1B-9346-CAE27C2F96ED@gmail.com>
	<CAM+rpYmSc4==J72TNdcRwDs+wByNtkH5gRqw2+43goqc9yf7Xg@mail.gmail.com>
	<42FCA9C1-826F-4D81-8D24-263C90A1FB74@gmail.com>
	<CAK1hC9tJA02VOzQ06+P5=rYpweY_jREyN1f3roc9S17vxFP8Xw@mail.gmail.com>
Message-ID: <6D931944-EABA-435B-BCE8-4F424B34D2D8@gmail.com>

It depends quite a bit on where you are coming from. 

If you come from the mathematical side of things, i.e. you're not scared at the thought of multiplying matrices, know a good deal about statistics and have some experience with programming languages, the document by Venables and Smith "An Introduction to R" (http://cran.r-project.org/manuals.html) may be the most efficient way to get started. 

My book, originally written for a course that use Altman's book on Medical Statistics at the main tex, is aimed at people who have been (or are being) exposed to the basic set of statistical methods and need to know how to do things in R. 

Yet others (e.g. Matloff) focus on the programming language aspects of R, some specifically target Data Science (whatever that means), etc. So you may need to shop around a little.

-pd

On 02 Oct 2014, at 08:22 , arnaud gaboury <arnaud.gaboury at gmail.com> wrote:

> On Thu, Oct 2, 2014 at 4:54 AM, Jason Eyerly <teamtraders3564 at gmail.com> wrote:
>> A lot of excellent suggestions! Thank you everyone for the input. I?ve purchased via Amazon:
>> 
>> "A Beginner's Guide to R" by Zuur
>> "Data Manipulation with R" by Spector
>> ?Introductory Statistics with R.? by Peter Dalgaard
>> 
>> Are there any suggestions as to which order I should read them in when they arrive? For best comprehension, I?m thinking ?Introductory Statistics with R? would be the best to start with, and perhaps the beginners guide after that, or vice versa?
>> 
> 
> I would not start with a whole book, but a good short intro (~ 30-40
> pages). Feel free to pick up free publications here:
> https://github.com/gabx/r-project/tree/master/documentation.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Thu Oct  2 20:02:51 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 02 Oct 2014 19:02:51 +0100
Subject: [R] tkProgressBar without progress in foreach %dopar%
In-Reply-To: <000001cfde57$40fc47b0$c2f4d710$@dpi.inpe.br>
References: <000001cfde57$40fc47b0$c2f4d710$@dpi.inpe.br>
Message-ID: <542D934B.3060803@stats.ox.ac.uk>

On 02/10/2014 16:40, Alexsandro C?ndido de Oliveira Silva wrote:
> I have a list (temp.data) with many raster data and some computations are in
> parallel. n is the number of raster data and target is the mask. I'd like to
> use a progress bar. It is created but while the loop is running the progress
> is not showed. The loop ends and the progress bar is closed. I've tried to
> use the functions pdCreate/pdStep in raster package, but without success...
>
> Someone have any idea...

You are using parallel processes here.  You do not tell us what packages 
you are actually using, but my guess is that

setTkProgressBar(mypb, i, title = "R progress bar", label = NULL)

updates a copy of mypb in the worker process, but it is the master 
process which is displaying the progress bar.

But without the complete reproducible example the posting guide asked 
for, we can only guess.

>
>
>
>      mypb <- tkProgressBar(title = "R progress bar", label = "",  min = 0,
> max = n, initial = 0, width = 300)
>
>
>
>      #creating a computing cluster
>
>      cl <- makeCluster(detectCores(),type='SOCK')
>
>      registerDoParallel(cl, cores = detectCores())
>
>
>
>      foreach(i=1:n,.packages=c('tcltk','rgdal','raster')) %dopar% {
>
>        Sys.sleep(.1)
>
>        setTkProgressBar(mypb, i, title = "R progress bar", label = NULL)
>
>
>
>
> temp.data[[i]]<-mask(temp.data[[i]],target,maskvalue=as.numeric(class.outsid
> e))
>
>
> writeRaster(temp.data[[i]],filename=files.list[i],format='GTiff',overwrite=T
> )
>
>      }
>
>
>
>      stopCluster(cl)
>
>      close(mypb)
>
>
>
>
>
> Thanks
>
> Alexsandro
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From idnat at hotmail.com  Thu Oct  2 20:30:09 2014
From: idnat at hotmail.com (tandi perkins)
Date: Thu, 2 Oct 2014 13:30:09 -0500
Subject: [R] Class ltraj and function as.ltraj
Message-ID: <BAY179-W95748164693AB8C011BA0AB9B90@phx.gbl>

Hello R Help Group:

I have been struggling to create
an object of class ltraj with the function as.ltraj (adehabitatLT) with my bird
data.  Regarding my data structure, I
have GPS for 10 birds that transmit three times/day, over the course of a year
(with missing data).  I have a L10.csv
file with the following headers: Craneid, Date, Time, Long, Lat, Habitat, ID
(for burst).  

 

Step 1:  Bring in my data with: ?stringsasFactors=FALSE? to convert all variables from Factor (except Lat/Long) to strings.  Thanks to David Carlson for that tip! Step 2: Transform my date, time vectors into POSIXct as follows: datetime=as.POSIXct(strptime(paste(L10$Date, L10$Time, sep=" "),format="%m/%d/%Y %H:%M:%S", "America/Chicago")) Thanks to Petr Pikal for that tip! Result: head(datetime)[1] "2011-07-10 17:00:38 CDT" "2011-07-11 00:01:06 CDT"[3] "2011-07-11 08:00:38 CDT" "2011-07-11 17:00:38 CDT"[5] "2011-07-12 00:01:06 CDT" "2011-07-12 08:00:38 CDT"   Good so far?. Step 3: Coord=L10[c("Longitude", "Latitude")]> head(Coord)  Longitude Latitude1    522598  33602852    522579  33601743    522618  33602744    522656  33601965    522397  33602076    522425  3360285 Good so far?.now comes the tricky part for me. Step 4: Craneid=as.character(L10$Craneid)  id=as.character(L10$ID)

 

Step 5: Test=as.ltraj(Coord, datetime, Craneid, burst=id,
type=TRUE)

 

Drum Roll Please?. Error in
as.ltraj(Coord, datetime, Craneid, burst = id, typeII = TRUE) : 

 
non unique dates for a given burst

I include my data.frame for your
review.

 

head(l10b)

 
Longitude Latitude           
datetime               Craneid    id

1    522598 
3360285 2011-07-10 17:00:38  
L1_10 L1_10

2    522579 
3360174 2011-07-11 00:01:06  
L1_10 L1_10

3    522618 
3360274 2011-07-11 08:00:38  
L1_10 L1_10

4    522656 
3360196 2011-07-11 17:00:38  
L1_10 L1_10

5    522397 
3360207 2011-07-12 00:01:06  
L1_10 L1_10

6    522425 
3360285 2011-07-12 08:00:38  
L1_10 L1_10

 

  
Longitude Latitude           
datetime                     Craneid    id

3803    558205 
3346410 2011-04-15 17:00:38  
L5_10 L5_10

3804    552813 
3341251 2011-04-16 08:00:38  
L5_10 L5_10

3805    552784 
3341373 2011-04-28 08:00:38  
L5_10 L5_10

3806    552833 
3341262 2011-04-28 17:00:38  
L5_10 L5_10

3807    573502 
3407390 2011-06-21 17:00:38  
L8_10 L8_10

3808    573271 
3407499 2011-06-23 08:00:38  
L8_10 L8_10

 

I have checked and re-checked for
duplicates and there are no duplicates.  However,
when ask for duplicates in the datetime I get some ?False? but a lot of ?True?s?
So, I am thinking it has to do with the fact that R is not picking up the
individual birds which were monitored over the same time period.

 

How do I structure my data in R to recognize the 10 separate birds with their associated coordinates and time
stamps?

 

I would ultimately like to run
Bias Bridge Movement on these data but I can?t get from square one!  Help!  

 

Thanks in advance for any and all
assistance you can provide?You all are so valuable.  
TLP


 		 	   		  
	[[alternative HTML version deleted]]


From f_j_rod at hotmail.com  Thu Oct  2 20:58:19 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Thu, 2 Oct 2014 20:58:19 +0200
Subject: [R] Loop does not work: Error in else statement (II)
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8782@SRVEXCHMBX.precheza.cz>
References: <BAY168-W58D5D19C3A6387D8BDF85BBABB0@phx.gbl>,
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8782@SRVEXCHMBX.precheza.cz>
Message-ID: <BAY168-W1104E0AB724E5CE20537691BAB90@phx.gbl>

Jim, Thanks for the comment about else! 		 	   		  
	[[alternative HTML version deleted]]


From jthayn at ilstu.edu  Thu Oct  2 21:18:43 2014
From: jthayn at ilstu.edu (Jonathan Thayn)
Date: Thu, 2 Oct 2014 14:18:43 -0500
Subject: [R] Using PCA to filter a series
Message-ID: <005E4CD0-940B-47CB-80FE-249F6829985D@ilstu.edu>

I have four time-series of similar data. I would  like to combine these into a single, clean time-series. I could simply find the mean of each time period, but I think that using principal components analysis should extract the most salient pattern and ignore some of the noise. I can compute components using princomp


d1 <- c(113, 108, 105, 103, 109, 115, 115, 102, 102, 111, 122, 122, 110, 110, 104, 121, 121, 120, 120, 137, 137, 138, 138, 136, 172, 172, 157, 165, 173, 173, 174, 174, 119, 167, 167, 144, 170, 173, 173, 169, 155, 116, 101, 114, 114, 107, 108, 108, 131, 131, 117, 113)
d2 <- c(138, 115, 127, 127, 119, 126, 126, 124, 124, 119, 119, 120, 120, 115, 109, 137, 142, 142, 143, 145, 145, 163, 169, 169, 180, 180, 174, 181, 181, 179, 173, 185, 185, 183, 183, 178, 182, 182, 181, 178, 171, 154, 145, 147, 147, 124, 124, 120, 128, 141, 141, 138)
d3 <- c(138, 120, 129, 129, 120, 126, 126, 125, 125, 119, 119, 122, 122, 115, 109, 141, 144, 144, 148, 149, 149, 163, 172, 172, 183, 183, 180, 181, 181, 181, 173, 185, 185, 183, 183, 184, 182, 182, 181, 179, 172, 154, 149, 156, 156, 125, 125, 115, 139, 140, 140, 138)
d4 <- c(134, 115, 120, 120, 117, 123, 123, 128, 128, 119, 119, 121, 121, 114, 114, 142, 145, 145, 144, 145, 145, 167, 172, 172, 179, 179, 179, 182, 182, 182, 182, 182, 184, 184, 182, 184, 183, 183, 181, 179, 172, 149, 149, 149, 149, 124, 124, 119, 131, 135, 135, 134)


pca <- princomp(cbind(d1,d2,d3,d4))
plot(pca$scores[,1])

This seems to have created the clean pattern I want, but I would like to project the first component back into the original axes? Is there a simple way to do that?




Jonathan B. Thayn
	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Thu Oct  2 21:33:23 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 2 Oct 2014 12:33:23 -0700
Subject: [R] Using PCA to filter a series
In-Reply-To: <005E4CD0-940B-47CB-80FE-249F6829985D@ilstu.edu>
References: <005E4CD0-940B-47CB-80FE-249F6829985D@ilstu.edu>
Message-ID: <7D6E0CC3-3805-4789-A433-13AB8FC423C2@u.washington.edu>


On Oct 2, 2014, at 12:18 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:

> I have four time-series of similar data. I would  like to combine these into a single, clean time-series. I could simply find the mean of each time period, but I think that using principal components analysis should extract the most salient pattern and ignore some of the noise. I can compute components using princomp
> 
> 
> d1 <- c(113, 108, 105, 103, 109, 115, 115, 102, 102, 111, 122, 122, 110, 110, 104, 121, 121, 120, 120, 137, 137, 138, 138, 136, 172, 172, 157, 165, 173, 173, 174, 174, 119, 167, 167, 144, 170, 173, 173, 169, 155, 116, 101, 114, 114, 107, 108, 108, 131, 131, 117, 113)
> d2 <- c(138, 115, 127, 127, 119, 126, 126, 124, 124, 119, 119, 120, 120, 115, 109, 137, 142, 142, 143, 145, 145, 163, 169, 169, 180, 180, 174, 181, 181, 179, 173, 185, 185, 183, 183, 178, 182, 182, 181, 178, 171, 154, 145, 147, 147, 124, 124, 120, 128, 141, 141, 138)
> d3 <- c(138, 120, 129, 129, 120, 126, 126, 125, 125, 119, 119, 122, 122, 115, 109, 141, 144, 144, 148, 149, 149, 163, 172, 172, 183, 183, 180, 181, 181, 181, 173, 185, 185, 183, 183, 184, 182, 182, 181, 179, 172, 154, 149, 156, 156, 125, 125, 115, 139, 140, 140, 138)
> d4 <- c(134, 115, 120, 120, 117, 123, 123, 128, 128, 119, 119, 121, 121, 114, 114, 142, 145, 145, 144, 145, 145, 167, 172, 172, 179, 179, 179, 182, 182, 182, 182, 182, 184, 184, 182, 184, 183, 183, 181, 179, 172, 149, 149, 149, 149, 124, 124, 119, 131, 135, 135, 134)
> 
> 
> pca <- princomp(cbind(d1,d2,d3,d4))
> plot(pca$scores[,1])
> 
> This seems to have created the clean pattern I want, but I would like to project the first component back into the original axes? Is there a simple way to do that?

Do you mean that you want to scale the scores on Axis 1 to the mean and range of your raw data?  Or their mean and variance?

See

?scale
> 
> 
> 
> 
> Jonathan B. Thayn
> 	
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific WIldland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences 
College of the Environment
University of Washington
dmck at uw.edu


From r.turner at auckland.ac.nz  Thu Oct  2 22:53:20 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 03 Oct 2014 09:53:20 +1300
Subject: [R] Anderson-Darling gof test (was "no subject")
In-Reply-To: <BLU170-W9EC28CAF7F5462542635D89B90@phx.gbl>
References: <BLU170-W9EC28CAF7F5462542635D89B90@phx.gbl>
Message-ID: <542DBB40.4070001@auckland.ac.nz>

On 03/10/14 03:54, eliza botto wrote:
> Dear UseRs,
> I obtained following results from Anderson-Darling Goodness of fit test.
>> dput(EB)
> structure(c(2.911, 0.9329, 0.818, 1.539, 0.604, 0.5142, 0.4344, 0.801, 0.963, 0.9925, 0.933, 0.956, 0.883, 0.572), .Dim = c(7L, 2L), .Dimnames = list(c("EXP", "GUM", "GENLOG", "GENPARETO", "GEV", "LN", "PAR3"), c("A2", "P")))
> My question is how to interpret these results? More precisely, which distribution fitted well on my data?


(1) Please use an informative subject line.

(2) Your posted data are somewhat opaque; one might guess that "A2" 
holds the values of the test statistic and "P" the corresponding 
p-values.  However I cannot reproduce your "P" column by applying the 
pAD() function.

(3) I don't really know anything about the Anderson-Darling test, but 
the function ad.test() requires that parameters of the distribution be 
supplied.  What is the impact of these parameters' being estimated, as 
they must surely be?

(4) This is really a statistics question rather than an R question, and 
so is not appropriate for this list.  Moreover it would appear that you 
are well out of your statistical depth.  You should seek local 
statistical consultation rather than trying to scramble your way through 
topics of which you have no proper understanding by peppering the r-help 
list with ill-posed questions.

cheers,

Rolf Turner


-- 
Rolf Turner
Technical Editor ANZJS


From jvadams at usgs.gov  Thu Oct  2 23:01:53 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 2 Oct 2014 16:01:53 -0500
Subject: [R] merge by time,
	certain value if 5 min before and after an "event"
In-Reply-To: <542D4F6E.6030607@gmx.net>
References: <542D4F6E.6030607@gmx.net>
Message-ID: <CAN5YmCGiu+FYSAKYWjfN--F6EXscDeJht-pshBh-avuKhxOP3A@mail.gmail.com>

Dagmar,

Can you explain more fully why rows 1, 2, and 5 in your result are "low"
and rows 3 and 4 are "high"?  It is not clear to me from the information
you have provided.

> result[c(1, 2, 5), ]
            Timestamp location Event
1 24.09.2012 09:05:01        1   low
2 24.09.2012 09:49:50        2   low
5 24.09.2012 10:05:10        5   low

> result[3:4, ]
            Timestamp location Event
3 24.09.2012 09:51:01        3  high
4 24.09.2012 10:04:50        1  high

Jean


On Thu, Oct 2, 2014 at 8:13 AM, Dagmar <Ramgad82 at gmx.net> wrote:

> Hello! I hope someone can help me. It would save me days of work. Thanks in
> advance!
> I have two dataframes which look like these:
>
>
> myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012
> 10:00:00",
> "24.09.2012 11:00:00"), Event=c("low","high","low") )
> myframe
>
>
> mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
> 09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
> 10:05:10")
> , location=c("1","2","3","1","5") )
> mydata
>
>
> # I want to merge them by time so I have a dataframe which looks like this
> in the end (i.e. "Low"  during 5 min before and after "high" )
>
> result <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
> 09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
> 10:05:10")
> , location=c("1","2","3","1","5") ,
> Event=c("low", "low","high","high","low"))
> result
>
> Anyone knows how do merge them?
> Best regards,
> Dagmar
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Oct  2 23:07:00 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 2 Oct 2014 16:07:00 -0500
Subject: [R] Problem using predict() to draw lines() if predictor
 variable is logged on the fly
In-Reply-To: <CAOF_sWReW+5d0EjvVKrTxjKHHiOS753s52YL5R72H2q7z-gmWw@mail.gmail.com>
References: <CAOF_sWReW+5d0EjvVKrTxjKHHiOS753s52YL5R72H2q7z-gmWw@mail.gmail.com>
Message-ID: <CAN5YmCF0=244L9MqjqF0H4-k=X=86nwG+ndX0NWixoJhzOF6Ng@mail.gmail.com>

You will have better luck getting replies to your post if you provide code
that we can run.  In other words, provide some small example data instead
of referring to your data frame that we have no access to.  You can use the
output from dput() to provide a subset of your data frame to the list.

dput(mydataframe[1:50, ])

Jean

On Thu, Oct 2, 2014 at 11:12 AM, <mtb954 at gmail.com> wrote:

> Hello,
>
> I am plotting glms with logged predictors. I would like to define the
> logged variables "on the fly" rather than hard coding them into my
> dataframe.
>
> This code (with hard-coded logged variables) works just fine:
>
> xx<-seq(-2,.5,by=0.1); lines(xx,predict(power,list(LogArKm00=xx),type=
> "response"),col="black",lwd=2,lty=1) #LogArKm00 is a variable in my
> dataframe
>
> but my attempt to define them "on the fly" doesn't work (see error below):
>
> plot(log(WbAb,10)~log(ArKm00,10),data=dat) #power model
>
> xx<-seq(-2,.5,by=0.1); lines(xx,predict(power,list(log(ArKm00,10)=xx),type=
> "response"),col="black",lwd=2,lty=1) #trying to log the variable "on the
> fly"
>
>
> Error: unexpected '=' in " lines(xx,predict(power,list(log(ArKm00,10)="
>
> I would really appreciate any help sorting this out!
>
> Many thanks
>
> Mark
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Ramgad82 at gmx.net  Thu Oct  2 23:25:16 2014
From: Ramgad82 at gmx.net (Dagmar)
Date: Thu, 02 Oct 2014 23:25:16 +0200
Subject: [R] merge by time,
 certain value if 5 min before and after an "event"
In-Reply-To: <CAN5YmCGiu+FYSAKYWjfN--F6EXscDeJht-pshBh-avuKhxOP3A@mail.gmail.com>
References: <542D4F6E.6030607@gmx.net>
	<CAN5YmCGiu+FYSAKYWjfN--F6EXscDeJht-pshBh-avuKhxOP3A@mail.gmail.com>
Message-ID: <542DC2BC.9030907@gmx.net>

Dear Jean and all,

I want all lines to be "low", but during times 9:55 - 10:05 a.m (i.e. a 
timespan of 10 min) I want them to be "high".
In my real data "low" and "high" refer to "lowtide" and "hightide" in 
the waddensea and I want to assign the location of my animal at the time 
it was taken to the tide (that means, there was water not only exactly 
at 10:00 (as taken from official data) but also 5 min before and after).

I hope that is more understandable, if not ask again. Thanks for trying 
to help,
Dagmar

Am 02.10.2014 um 23:01 schrieb Adams, Jean:
> Dagmar,
>
> Can you explain more fully why rows 1, 2, and 5 in your result are 
> "low" and rows 3 and 4 are "high"?  It is not clear to me from the 
> information you have provided.
>
> > result[c(1, 2, 5), ]
>             Timestamp location Event
> 1 24.09.2012 09:05:01        1 low
> 2 24.09.2012 09:49:50        2 low
> 5 24.09.2012 10:05:10        5 low
>
> > result[3:4, ]
>             Timestamp location Event
> 3 24.09.2012 09:51:01        3  high
> 4 24.09.2012 10:04:50        1  high
>
> Jean
>
>
> On Thu, Oct 2, 2014 at 8:13 AM, Dagmar <Ramgad82 at gmx.net 
> <mailto:Ramgad82 at gmx.net>> wrote:
>
>     Hello! I hope someone can help me. It would save me days of work.
>     Thanks in
>     advance!
>     I have two dataframes which look like these:
>
>
>     myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012
>     10:00:00",
>     "24.09.2012 11:00:00"), Event=c("low","high","low") )
>     myframe
>
>
>     mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
>     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
>     10:05:10")
>     , location=c("1","2","3","1","5") )
>     mydata
>
>
>     # I want to merge them by time so I have a dataframe which looks
>     like this
>     in the end (i.e. "Low"  during 5 min before and after "high" )
>
>     result <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
>     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
>     10:05:10")
>     , location=c("1","2","3","1","5") ,
>     Event=c("low", "low","high","high","low"))
>     result
>
>     Anyone knows how do merge them?
>     Best regards,
>     Dagmar
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Thu Oct  2 23:38:24 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 2 Oct 2014 16:38:24 -0500
Subject: [R] merge by time,
	certain value if 5 min before and after an "event"
In-Reply-To: <542DC2BC.9030907@gmx.net>
References: <542D4F6E.6030607@gmx.net>
	<CAN5YmCGiu+FYSAKYWjfN--F6EXscDeJht-pshBh-avuKhxOP3A@mail.gmail.com>
	<542DC2BC.9030907@gmx.net>
Message-ID: <CAN5YmCFamTCgrt08QgrDV4ZnReP7c+m0CccSXupaqeTFGJh+vQ@mail.gmail.com>

Thanks, Dagmar.

So, shouldn't row 3 with a time of 09:51:01 be "low" and not "high"?

Jean

On Thu, Oct 2, 2014 at 4:25 PM, Dagmar <Ramgad82 at gmx.net> wrote:

> Dear Jean and all,
>
> I want all lines to be "low", but during times 9:55 - 10:05 a.m (i.e. a
> timespan of 10 min) I want them to be "high".
> In my real data "low" and "high" refer to "lowtide" and "hightide" in
> the waddensea and I want to assign the location of my animal at the time
> it was taken to the tide (that means, there was water not only exactly
> at 10:00 (as taken from official data) but also 5 min before and after).
>
> I hope that is more understandable, if not ask again. Thanks for trying
> to help,
> Dagmar
>
> Am 02.10.2014 um 23:01 schrieb Adams, Jean:
> > Dagmar,
> >
> > Can you explain more fully why rows 1, 2, and 5 in your result are
> > "low" and rows 3 and 4 are "high"?  It is not clear to me from the
> > information you have provided.
> >
> > > result[c(1, 2, 5), ]
> >             Timestamp location Event
> > 1 24.09.2012 09:05:01        1 low
> > 2 24.09.2012 09:49:50        2 low
> > 5 24.09.2012 10:05:10        5 low
> >
> > > result[3:4, ]
> >             Timestamp location Event
> > 3 24.09.2012 09:51:01        3  high
> > 4 24.09.2012 10:04:50        1  high
> >
> > Jean
> >
> >
> > On Thu, Oct 2, 2014 at 8:13 AM, Dagmar <Ramgad82 at gmx.net
> > <mailto:Ramgad82 at gmx.net>> wrote:
> >
> >     Hello! I hope someone can help me. It would save me days of work.
> >     Thanks in
> >     advance!
> >     I have two dataframes which look like these:
> >
> >
> >     myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012
> >     10:00:00",
> >     "24.09.2012 11:00:00"), Event=c("low","high","low") )
> >     myframe
> >
> >
> >     mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
> >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
> >     10:05:10")
> >     , location=c("1","2","3","1","5") )
> >     mydata
> >
> >
> >     # I want to merge them by time so I have a dataframe which looks
> >     like this
> >     in the end (i.e. "Low"  during 5 min before and after "high" )
> >
> >     result <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
> >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
> >     10:05:10")
> >     , location=c("1","2","3","1","5") ,
> >     Event=c("low", "low","high","high","low"))
> >     result
> >
> >     Anyone knows how do merge them?
> >     Best regards,
> >     Dagmar
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Thu Oct  2 23:38:35 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Thu, 2 Oct 2014 14:38:35 -0700
Subject: [R] Using PCA to filter a series
In-Reply-To: <CDD59C3C-BDD9-4AE2-93E8-627243883F11@ilstu.edu>
References: <005E4CD0-940B-47CB-80FE-249F6829985D@ilstu.edu>
	<7D6E0CC3-3805-4789-A433-13AB8FC423C2@u.washington.edu>
	<CDD59C3C-BDD9-4AE2-93E8-627243883F11@ilstu.edu>
Message-ID: <E6070C0D-F079-4BAD-B11A-B020FE6652BD@u.washington.edu>


On Oct 2, 2014, at 2:29 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:

> Hi Don. I would like to "de-rotate? the first component back to its original state so that it aligns with the original time-series. My goal is to create a ?cleaned?, or a ?model? time-series from which noise has been removed. 

Please cc the list with replies. It?s considered courtesy plus you?ll get more help that way than just from me.

Your goal sounds almost metaphorical, at least to me.  Your first axis ?aligns? with the original time series already in that it captures the dominant variation
across all four. Beyond that, there are many approaches to signal/noise relations within time-series analysis. I am not a good source of help on these, and you probably need a statistical consult (locally?), which is not the function of this list.

> 
> 
> Jonathan Thayn
> 
> 
> 
> On Oct 2, 2014, at 2:33 PM, Don McKenzie <dmck at u.washington.edu> wrote:
> 
>> 
>> On Oct 2, 2014, at 12:18 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
>> 
>>> I have four time-series of similar data. I would  like to combine these into a single, clean time-series. I could simply find the mean of each time period, but I think that using principal components analysis should extract the most salient pattern and ignore some of the noise. I can compute components using princomp
>>> 
>>> 
>>> d1 <- c(113, 108, 105, 103, 109, 115, 115, 102, 102, 111, 122, 122, 110, 110, 104, 121, 121, 120, 120, 137, 137, 138, 138, 136, 172, 172, 157, 165, 173, 173, 174, 174, 119, 167, 167, 144, 170, 173, 173, 169, 155, 116, 101, 114, 114, 107, 108, 108, 131, 131, 117, 113)
>>> d2 <- c(138, 115, 127, 127, 119, 126, 126, 124, 124, 119, 119, 120, 120, 115, 109, 137, 142, 142, 143, 145, 145, 163, 169, 169, 180, 180, 174, 181, 181, 179, 173, 185, 185, 183, 183, 178, 182, 182, 181, 178, 171, 154, 145, 147, 147, 124, 124, 120, 128, 141, 141, 138)
>>> d3 <- c(138, 120, 129, 129, 120, 126, 126, 125, 125, 119, 119, 122, 122, 115, 109, 141, 144, 144, 148, 149, 149, 163, 172, 172, 183, 183, 180, 181, 181, 181, 173, 185, 185, 183, 183, 184, 182, 182, 181, 179, 172, 154, 149, 156, 156, 125, 125, 115, 139, 140, 140, 138)
>>> d4 <- c(134, 115, 120, 120, 117, 123, 123, 128, 128, 119, 119, 121, 121, 114, 114, 142, 145, 145, 144, 145, 145, 167, 172, 172, 179, 179, 179, 182, 182, 182, 182, 182, 184, 184, 182, 184, 183, 183, 181, 179, 172, 149, 149, 149, 149, 124, 124, 119, 131, 135, 135, 134)
>>> 
>>> 
>>> pca <- princomp(cbind(d1,d2,d3,d4))
>>> plot(pca$scores[,1])
>>> 
>>> This seems to have created the clean pattern I want, but I would like to project the first component back into the original axes? Is there a simple way to do that?
>> 
>> Do you mean that you want to scale the scores on Axis 1 to the mean and range of your raw data?  Or their mean and variance?
>> 
>> See
>> 
>> ?scale
>>> 
>>> 
>>> 
>>> 
>>> Jonathan B. Thayn
>>> 	
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Don McKenzie
>> Research Ecologist
>> Pacific WIldland Fire Sciences Lab
>> US Forest Service
>> 
>> Affiliate Professor
>> School of Environmental and Forest Sciences 
>> College of the Environment
>> University of Washington
>> dmck at uw.edu
> 

Don McKenzie
Research Ecologist
Pacific WIldland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences 
College of the Environment
University of Washington
dmck at uw.edu


	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Thu Oct  2 23:47:36 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Fri, 3 Oct 2014 07:47:36 +1000
Subject: [R] Class ltraj and function as.ltraj
In-Reply-To: <BAY179-W95748164693AB8C011BA0AB9B90@phx.gbl>
References: <BAY179-W95748164693AB8C011BA0AB9B90@phx.gbl>
Message-ID: <CAAcGz99A23uugwaUtcvPOq7yzq0o8ZbtdFVMBHLUhJvmns7jGw@mail.gmail.com>

You don't detail how you detect that 'there are no duplicates', and
also provide no proof of this. It's not the usual sense of
duplicated(), it needs to be that there are no date-times within a
burst (a single animal's trip/journey/trajectory). Can you try this on
your datetime and burst id and report:

## this tests out ok
datetime <- seq(Sys.time(), by = "3 secs", length = 20)
id <- rep(c("a", "b"), each = 10)

## none should be zero or negative
sapply(split(datetime, id), function(x) min(diff(x)))

## fudge a broken data set
datetime1 <- datetime
datetime1[15] <- datetime1[14]
sapply(split(datetime1, id), function(x) min(diff(x)))

Cheers, Mike.


On Fri, Oct 3, 2014 at 4:30 AM, tandi perkins <idnat at hotmail.com> wrote:
> Hello R Help Group:
>
> I have been struggling to create
> an object of class ltraj with the function as.ltraj (adehabitatLT) with my bird
> data.  Regarding my data structure, I
> have GPS for 10 birds that transmit three times/day, over the course of a year
> (with missing data).  I have a L10.csv
> file with the following headers: Craneid, Date, Time, Long, Lat, Habitat, ID
> (for burst).
>
>
>
> Step 1:  Bring in my data with: ?stringsasFactors=FALSE? to convert all variables from Factor (except Lat/Long) to strings.  Thanks to David Carlson for that tip! Step 2: Transform my date, time vectors into POSIXct as follows: datetime=as.POSIXct(strptime(paste(L10$Date, L10$Time, sep=" "),format="%m/%d/%Y %H:%M:%S", "America/Chicago")) Thanks to Petr Pikal for that tip! Result: head(datetime)[1] "2011-07-10 17:00:38 CDT" "2011-07-11 00:01:06 CDT"[3] "2011-07-11 08:00:38 CDT" "2011-07-11 17:00:38 CDT"[5] "2011-07-12 00:01:06 CDT" "2011-07-12 08:00:38 CDT"   Good so far?. Step 3: Coord=L10[c("Longitude", "Latitude")]> head(Coord)  Longitude Latitude1    522598  33602852    522579  33601743    522618  33602744    522656  33601965    522397  33602076    522425  3360285 Good so far?.now comes the tricky part for me. Step 4: Craneid=as.character(L10$Craneid)  id=as.character(L10$ID)
>
>
>
> Step 5: Test=as.ltraj(Coord, datetime, Craneid, burst=id,
> type=TRUE)
>
>
>
> Drum Roll Please?. Error in
> as.ltraj(Coord, datetime, Craneid, burst = id, typeII = TRUE) :
>
>
> non unique dates for a given burst
>
> I include my data.frame for your
> review.
>
>
>
> head(l10b)
>
>
> Longitude Latitude
> datetime               Craneid    id
>
> 1    522598
> 3360285 2011-07-10 17:00:38
> L1_10 L1_10
>
> 2    522579
> 3360174 2011-07-11 00:01:06
> L1_10 L1_10
>
> 3    522618
> 3360274 2011-07-11 08:00:38
> L1_10 L1_10
>
> 4    522656
> 3360196 2011-07-11 17:00:38
> L1_10 L1_10
>
> 5    522397
> 3360207 2011-07-12 00:01:06
> L1_10 L1_10
>
> 6    522425
> 3360285 2011-07-12 08:00:38
> L1_10 L1_10
>
>
>
>
> Longitude Latitude
> datetime                     Craneid    id
>
> 3803    558205
> 3346410 2011-04-15 17:00:38
> L5_10 L5_10
>
> 3804    552813
> 3341251 2011-04-16 08:00:38
> L5_10 L5_10
>
> 3805    552784
> 3341373 2011-04-28 08:00:38
> L5_10 L5_10
>
> 3806    552833
> 3341262 2011-04-28 17:00:38
> L5_10 L5_10
>
> 3807    573502
> 3407390 2011-06-21 17:00:38
> L8_10 L8_10
>
> 3808    573271
> 3407499 2011-06-23 08:00:38
> L8_10 L8_10
>
>
>
> I have checked and re-checked for
> duplicates and there are no duplicates.  However,
> when ask for duplicates in the datetime I get some ?False? but a lot of ?True?s?
> So, I am thinking it has to do with the fact that R is not picking up the
> individual birds which were monitored over the same time period.
>
>
>
> How do I structure my data in R to recognize the 10 separate birds with their associated coordinates and time
> stamps?
>
>
>
> I would ultimately like to run
> Bias Bridge Movement on these data but I can?t get from square one!  Help!
>
>
>
> Thanks in advance for any and all
> assistance you can provide?You all are so valuable.
> TLP
>
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From dcarlson at tamu.edu  Thu Oct  2 23:59:13 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 2 Oct 2014 21:59:13 +0000
Subject: [R] Using PCA to filter a series
In-Reply-To: <E6070C0D-F079-4BAD-B11A-B020FE6652BD@u.washington.edu>
References: <005E4CD0-940B-47CB-80FE-249F6829985D@ilstu.edu>
	<7D6E0CC3-3805-4789-A433-13AB8FC423C2@u.washington.edu>
	<CDD59C3C-BDD9-4AE2-93E8-627243883F11@ilstu.edu>
	<E6070C0D-F079-4BAD-B11A-B020FE6652BD@u.washington.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9D3F7@mb02.ads.tamu.edu>

I think you want to convert your principal component to the same scale as d1, d2, d3, and d4. But the "original space" is a 4-dimensional space in which d1, d2, d3, and d4 are the axes, each with its own mean and standard deviation. Here are a couple of possibilities

# plot original values for comparison
> matplot(cbind(d1, d2, d3, d4), pch=20, col=2:5)
# standardize the pc scores to the grand mean and sd
> new1 <- scale(pca$scores[,1])*sd(c(d1, d2, d3, d4)) + mean(c(d1, d2, d3, d4))
> lines(new1)
# Use least squares regression to predict the row means for the original four variables
> new2 <- predict(lm(rowMeans(cbind(d1, d2, d3, d4))~pca$scores[,1]))
> lines(new2, col="red")

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Don McKenzie
Sent: Thursday, October 2, 2014 4:39 PM
To: Jonathan Thayn
Cc: r-help at r-project.org
Subject: Re: [R] Using PCA to filter a series


On Oct 2, 2014, at 2:29 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:

> Hi Don. I would like to "de-rotate? the first component back to its original state so that it aligns with the original time-series. My goal is to create a ?cleaned?, or a ?model? time-series from which noise has been removed. 

Please cc the list with replies. It?s considered courtesy plus you?ll get more help that way than just from me.

Your goal sounds almost metaphorical, at least to me.? Your first axis ?aligns? with the original time series already in that it captures the dominant variation
across all four. Beyond that, there are many approaches to signal/noise relations within time-series analysis. I am not a good source of help on these, and you probably need a statistical consult (locally?), which is not the function of this list.

> 
> 
> Jonathan Thayn
> 
> 
> 
> On Oct 2, 2014, at 2:33 PM, Don McKenzie <dmck at u.washington.edu> wrote:
> 
>> 
>> On Oct 2, 2014, at 12:18 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
>> 
>>> I have four time-series of similar data. I would? like to combine these into a single, clean time-series. I could simply find the mean of each time period, but I think that using principal components analysis should extract the most salient pattern and ignore some of the noise. I can compute components using princomp
>>> 
>>> 
>>> d1 <- c(113, 108, 105, 103, 109, 115, 115, 102, 102, 111, 122, 122, 110, 110, 104, 121, 121, 120, 120, 137, 137, 138, 138, 136, 172, 172, 157, 165, 173, 173, 174, 174, 119, 167, 167, 144, 170, 173, 173, 169, 155, 116, 101, 114, 114, 107, 108, 108, 131, 131, 117, 113)
>>> d2 <- c(138, 115, 127, 127, 119, 126, 126, 124, 124, 119, 119, 120, 120, 115, 109, 137, 142, 142, 143, 145, 145, 163, 169, 169, 180, 180, 174, 181, 181, 179, 173, 185, 185, 183, 183, 178, 182, 182, 181, 178, 171, 154, 145, 147, 147, 124, 124, 120, 128, 141, 141, 138)
>>> d3 <- c(138, 120, 129, 129, 120, 126, 126, 125, 125, 119, 119, 122, 122, 115, 109, 141, 144, 144, 148, 149, 149, 163, 172, 172, 183, 183, 180, 181, 181, 181, 173, 185, 185, 183, 183, 184, 182, 182, 181, 179, 172, 154, 149, 156, 156, 125, 125, 115, 139, 140, 140, 138)
>>> d4 <- c(134, 115, 120, 120, 117, 123, 123, 128, 128, 119, 119, 121, 121, 114, 114, 142, 145, 145, 144, 145, 145, 167, 172, 172, 179, 179, 179, 182, 182, 182, 182, 182, 184, 184, 182, 184, 183, 183, 181, 179, 172, 149, 149, 149, 149, 124, 124, 119, 131, 135, 135, 134)
>>> 
>>> 
>>> pca <- princomp(cbind(d1,d2,d3,d4))
>>> plot(pca$scores[,1])
>>> 
>>> This seems to have created the clean pattern I want, but I would like to project the first component back into the original axes? Is there a simple way to do that?
>> 
>> Do you mean that you want to scale the scores on Axis 1 to the mean and range of your raw data?? Or their mean and variance?
>> 
>> See
>> 
>> ?scale
>>> 
>>> 
>>> 
>>> 
>>> Jonathan B. Thayn
>>>????? 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> Don McKenzie
>> Research Ecologist
>> Pacific WIldland Fire Sciences Lab
>> US Forest Service
>> 
>> Affiliate Professor
>> School of Environmental and Forest Sciences 
>> College of the Environment
>> University of Washington
>> dmck at uw.edu
> 

Don McKenzie
Research Ecologist
Pacific WIldland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences 
College of the Environment
University of Washington
dmck at uw.edu


??????? [[alternative HTML version deleted]]
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From pdalgd at gmail.com  Fri Oct  3 00:47:48 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 Oct 2014 00:47:48 +0200
Subject: [R] Problem using predict() to draw lines() if predictor
	variable is logged on the fly
In-Reply-To: <CAN5YmCF0=244L9MqjqF0H4-k=X=86nwG+ndX0NWixoJhzOF6Ng@mail.gmail.com>
References: <CAOF_sWReW+5d0EjvVKrTxjKHHiOS753s52YL5R72H2q7z-gmWw@mail.gmail.com>
	<CAN5YmCF0=244L9MqjqF0H4-k=X=86nwG+ndX0NWixoJhzOF6Ng@mail.gmail.com>
Message-ID: <FAE5E571-BEA7-46D0-B69B-403EABA61646@gmail.com>

Well, at least the immediate cause is clear:

>> list(log(ArKm00,10)=xx)

is invalid syntax. If you want a list element _named_ log(ArKm00,10), you'll need to quote the name. However, it's not going to work anyway, because that isn't what predict() expects. You don't supply logged variables, you supply the originals and predict() will do the logging.

This is how it does work:

> x <- rexp(10) ; y <- rnorm(x, mean=log(x))
> fit <- lm(y~log(x))
> fit

Call:
lm(formula = y ~ log(x))

Coefficients:
(Intercept)       log(x)  
    0.05337      1.05081  

> predict(fit, new=list(x=1))
         1 
0.05337405 

(Notice that since log(1)==0, the predicted value equals the intercept.)
 
To be more specific, this works through the fact that predict() internally generates the  model frame for newdata as, effectively,

> model.frame(delete.response(terms(fit)), list(x=1))
  log(x)
1      0

  

On 02 Oct 2014, at 23:07 , Adams, Jean <jvadams at usgs.gov> wrote:

> You will have better luck getting replies to your post if you provide code
> that we can run.  In other words, provide some small example data instead
> of referring to your data frame that we have no access to.  You can use the
> output from dput() to provide a subset of your data frame to the list.
> 
> dput(mydataframe[1:50, ])
> 
> Jean
> 
> On Thu, Oct 2, 2014 at 11:12 AM, <mtb954 at gmail.com> wrote:
> 
>> Hello,
>> 
>> I am plotting glms with logged predictors. I would like to define the
>> logged variables "on the fly" rather than hard coding them into my
>> dataframe.
>> 
>> This code (with hard-coded logged variables) works just fine:
>> 
>> xx<-seq(-2,.5,by=0.1); lines(xx,predict(power,list(LogArKm00=xx),type=
>> "response"),col="black",lwd=2,lty=1) #LogArKm00 is a variable in my
>> dataframe
>> 
>> but my attempt to define them "on the fly" doesn't work (see error below):
>> 
>> plot(log(WbAb,10)~log(ArKm00,10),data=dat) #power model
>> 
>> xx<-seq(-2,.5,by=0.1); lines(xx,predict(power,list(log(ArKm00,10)=xx),type=
>> "response"),col="black",lwd=2,lty=1) #trying to log the variable "on the
>> fly"
>> 
>> 
>> Error: unexpected '=' in " lines(xx,predict(power,list(log(ArKm00,10)="
>> 
>> I would really appreciate any help sorting this out!
>> 
>> Many thanks
>> 
>> Mark
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From patzelt at g.harvard.edu  Thu Oct  2 22:17:31 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Thu, 2 Oct 2014 16:17:31 -0400
Subject: [R] Identifying Values in Dataframe
Message-ID: <CAB9UfhR0YsuAGBEEqW4f9C_DpJj+mdYKujUX3v23jnMAh_PPhQ@mail.gmail.com>

R Help -

I'd like to identify each correlation value in the dataframe below
above/below .3/-.3 in order to graph the original data points. I've started
with the call below to identify each value by it's row and column. I'd like
to form a data object that identifies each set of variables that meet the
criteria and then use that to graph the original data.

*do.call(cbind, lapply(list(row = row(data, T), col = col(data, T), value =
data), as.character))*
structure(c(-0.0228976615669603, 0.0228976615669603, 0.0345568787488209,
-0.0345568787488209, 0.0704941162950863, 0.0501672252097525,
0.119766411337358, 0.0697823742392512, 0.0223273454311378,
-0.0223273454311378,
0.125952482472234, -0.125952482472234, -0.0748856339421511,
-0.0353553864437216,
0.199331873910442, -0.068756564596986, 0.0188033303819659,
-0.0188033303819659,
0.124483870344689, -0.124483870344689, 0.158304442010968,
-0.158304442010968,
-0.00291892981576431, 0.00291892981576431, 0.289784855159971,
0.197017018634618, 0.0725645607308865, 0.0960039687045857,
0.145044311433109,
-0.145044311433109, 0.228975321916426, -0.228975321916426,
0.26388395000877,
0.175954114053622, 0.326823414986536, 0.0464304517962428,
0.171060413427109,
-0.171060413427109, 0.125608489395663, -0.125608489395663,
0.170699125959079,
-0.170699125959079, -0.0537588992684595, 0.0537588992684595,
0.237938136557008, 0.130101348701669, 0.0420659299644508,
0.140016889896702,
0.175781963301805, -0.175781963301805, 0.277913325677977,
-0.277913325677977,
0.250436246834054, 0.149310941080417, 0.345171759606147,
0.0499822279379925,
0.180291553611261, -0.180291553611261, 0.0983047617452837,
-0.0983047617452837,
0.0908629320478729, -0.0908629320478729, 0.0162624158794471,
-0.0162624158794471, 0.219099271324641, 0.143898328556892,
0.0808498509449568,
0.0534039458771934, 0.103639895676339, -0.103639895676339,
0.224298317217259,
-0.224298317217259, 0.13939241528796, 0.0923125296440915, 0.2952647762031,
-0.0573156158960486, 0.126972946909388, -0.126972946909388,
0.145176640269481,
-0.145176640269481, 0.176722440639515, -0.176722440639515,
-0.110517827771672,
0.110517827771672, 0.265161677824653, 0.0349452421080511,
-0.00586032680446085,
0.17140674405117, -0.0141919172668973, 0.0141919172668973,
0.0416754535115447,
-0.0416754535115447, 0.110687511145091, 0.163199987771469,
0.174846924599677,
0.116657756754811, 0.184924363876472, -0.184924363876472,
0.0740138506321435,
-0.0740138506321435, 0.0653341995281647, -0.0653341995281647,
0.101098966521841, -0.101098966521841, -0.0263969055123976,
-0.129660641707532,
0.16313101271814, -0.0000382052406584783, 0.118309823316179,
-0.118309823316179, 0.0408519777835592, -0.0408519777835592,
-0.15406959482671, -0.274340973979869, 0.1465995621482,
-0.0608360452726588,
-0.00570057335076342, 0.00570057335076342, 0.0988132735291764,
-0.0988132735291764, 0.159498629897594, -0.159498629897594,
-0.0258437210789338,
0.0258437210789338, 0.311623918577701, 0.0959243386674064,
0.0373444291324758,
0.131601179184854, 0.0032064022008327, -0.0032064022008327,
0.0126042917937794,
-0.0126042917937794, 0.0288999352531186, 0.0343919995425096,
0.0375647873892517, 0.0734866249695526, 0.125835994106989,
-0.125835994106989,
0.0557071876372764, -0.0557071876372764, 0.0190687287223345,
-0.0190687287223345, 0.0301326072710063, -0.0301326072710063,
0.0881640884608706, 0.0600194980037123, 0.0948090975231923,
0.0259282757599189,
0.120417132810781, -0.120417132810781, 0.196695581235906,
-0.196695581235906,
0.166210300278382, 0.0252645245285897, 0.239953962041662,
-0.013933692494363,
0.0174600644363753, -0.0174600644363753, 0.169008089964054,
-0.169008089964054,
0.0503612778194372, -0.0503612778194372, 0.175816302924921,
-0.175816302924921,
0.141434785651191, 0.0824019401386654, 0.173429908437586,
-0.136795834367563,
0.219543981806626, -0.219543981806626, 0.290697487363267,
-0.290697487363267,
0.331683649439792, -0.0035319780591347, 0.237371764540467,
-0.172828690804139,
0.00922163769628213, -0.00922163769628213, 0.275507919516733,
-0.275507919516733, 0.128267529853407, -0.128267529853407,
-0.16619622911667,
0.16619622911667, 0.102467428865746, -0.115779804556684,
0.000997318666924614,
0.297139396802529, 0.040957786791642, -0.040957786791642,
-0.0160650315621922,
0.0160650315621922, -0.043765426943726, -0.0637020898937285,
0.142863591010818, 0.214059283535989, 0.13975223034564, -0.13975223034564,
-0.0286586386843802, 0.0286586386843802, 0.13735028629468,
-0.13735028629468,
-0.147016933653806, 0.147016933653806, 0.174438743129307,
-0.0116564727226121,
-0.0413775943824046, 0.136551598575573, 0.0614942508131549,
-0.0614942508131549,
0.0687487372508148, -0.0687487372508148, -0.0352587211103196,
-0.0872464182568976, 0.162247767446472, 0.0282617081917608,
0.175608445537029,
-0.175608445537029, -0.0339260764991994, 0.0339260764991994,
0.130002432167221, -0.130002432167221, -0.141752408742242,
0.141752408742242,
0.126603115520512, -0.0784556105378803, -0.0736773348350251,
0.154815164010555, -0.102200077602115, 0.102200077602115,
-0.137144378194025,
0.137144378194025, 0.0132012835622079, 0.113105077279414,
-0.0412435172396771,
0.182836991911806, 0.109656132908221, -0.109656132908221,
-0.0341578533716874,
0.0341578533716874, -0.0155952702450936, 0.0155952702450936,
0.0962494517693934, -0.0962494517693934, 0.0745517006304259,
0.145954619132309, 0.0997683764233029, -0.0562240100001912,
0.13254524166143,
-0.13254524166143, 0.236418162977751, -0.236418162977751,
0.0878486801199713,
-0.00445794916320147, 0.227619583487885, -0.14911359391431,
0.0214260010937822,
-0.0214260010937822, 0.120246543167583, -0.120246543167583), .Dim = c(20L,
13L), .Dimnames = list(c("Loss_Gain_PE_Amygdala_SF_right_hemisphere",
"Gain_Loss_PE_Amygdala_SF_right_hemisphere",
"Loss_Gain_EV_Amygdala_SF_right_hemisphere",
"Gain_Loss_EV_Amygdala_SF_right_hemisphere",
"Loss_PE_Amygdala_SF_right_hemisphere",
"Gain_PE_Amygdala_SF_right_hemisphere",
"Loss_EV_Amygdala_SF_right_hemisphere",
"Gain_EV_Amygdala_SF_right_hemisphere",
"Loss_Gain_PE_Amygdala_SF_left_hemisphere",
"Gain_Loss_PE_Amygdala_SF_left_hemisphere",
"Loss_Gain_EV_Amygdala_SF_left_hemisphere",
"Gain_Loss_EV_Amygdala_SF_left_hemisphere",
"Loss_PE_Amygdala_SF_left_hemisphere",
"Gain_PE_Amygdala_SF_left_hemisphere",
"Loss_EV_Amygdala_SF_left_hemisphere",
"Gain_EV_Amygdala_SF_left_hemisphere",
"Loss_Gain_PE_Amygdala_LB_right_hemisphere",
"Gain_Loss_PE_Amygdala_LB_right_hemisphere",
"Loss_Gain_EV_Amygdala_LB_right_hemisphere",
"Gain_Loss_EV_Amygdala_LB_right_hemisphere"), c("hare2f1", "hare2f2",
"hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
"ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry",
"hareResidNetExt", "extResidNetHare")))

-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University SNPLab http://scholar.harvard.edu/buckholtz
<http://scholar.harvard.edu/buckholtz>*

	[[alternative HTML version deleted]]


From kschuster at csumb.edu  Fri Oct  3 04:19:11 2014
From: kschuster at csumb.edu (Kalia Schuster)
Date: Thu, 2 Oct 2014 19:19:11 -0700
Subject: [R] (no subject)
Message-ID: <CAL+ahON4YWpWD3oDidCpXoKu1SS=RxzKSQgbENKLvk1UQqmjQw@mail.gmail.com>

Hello,
I'm new to R. I'm trying to run a power analysis in a for loop to find an
ideal sample size. The situation is I am doing counts of fish at 24
different sites and rating those sites as 1 or 2 for good or poor habitat.
So the counts are continuous but the habitat rating isn't. When I try to
run a negative binomial general linearized model with given values for mu:
exp1.302 and exp-0.32 and a given theta: exp(0.75), I get an error message
before I can run the whole loop and plot the power of the sample size
against sample. I used a template my teacher showed in class, but since he
used a poisson dist., I'm stuck on the glm.nb.
Please help! This is an assignment, so any suggestions would be wonderful
and I don't expect anything more. But please remember, I am a beginner and
only have a crude knowledge of R at this point.
Much appreciated.

#Power analysis
rm(list=ls())
graphics.off()

set.seed(1)
alpha=0.05
m=200

Ns = seq(2,40,2)
nNs = length(Ns)
NAs=rep(NA,nNs)
results= data.frame(n=Ns, power=NAs)

for(j in 1:nNs) {
  n=Ns[j]
  reject_count = 0

  for(i in 1:m )  {


      mu_poor=exp(-0.32)
      mu_suit=exp(1.302)
      mu=c(rep(mu_poor,n/2),rep(mu_suit,n/2))
      theta=exp(0.175)
      count=rnbinom(n=n,size=theta,mu=mu)
      hab_poor=1
      hab_suit=2
      habitat=sample(hab_poor:hab_suit, size=n, replace=T)
      model = glm.nb(count~habitat,link="log")
      summary(model)


      pval = summary(model)$coeff[2,4]
      pval
      reject = pval < alpha
      if (reject) reject_count = reject_count+1
    }
    reject_rate = reject_count/m
    power = reject_rate
    typeIIerror=1-reject_rate

    results[j,]$power=power
}
plot (x=Ns, y=results$power, xlab="Sample size", ylab="Power")
lines(Ns,rep(0.95,nNs))
par(lty=2)

	[[alternative HTML version deleted]]


From jthayn at ilstu.edu  Fri Oct  3 06:11:18 2014
From: jthayn at ilstu.edu (Jonathan Thayn)
Date: Thu, 2 Oct 2014 23:11:18 -0500
Subject: [R] Using PCA to filter a series
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9D3F7@mb02.ads.tamu.edu>
References: <005E4CD0-940B-47CB-80FE-249F6829985D@ilstu.edu>
	<7D6E0CC3-3805-4789-A433-13AB8FC423C2@u.washington.edu>
	<CDD59C3C-BDD9-4AE2-93E8-627243883F11@ilstu.edu>
	<E6070C0D-F079-4BAD-B11A-B020FE6652BD@u.washington.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9D3F7@mb02.ads.tamu.edu>
Message-ID: <50443357-306D-4EBD-A9A7-90C85B5B01BC@ilstu.edu>

I suppose I could calculate the eigenvectors directly and not worry about centering the time-series, since they essentially the same range to begin with:

vec <- eigen(cor(cbind(d1,d2,d3,d4)))$vector
cp <- cbind(d1,d2,d3,d4)%*%vec
cp1 <- cp[,1]

I guess there is no way to reconstruct the original input data using just the first component, though, is there? Not the original data in it entirety, just one time-series that we representative of the general pattern. Possibly something like the following, but with just the first component:

o <- cp%*%solve(vec)

Thanks for your help. It's been a long time since I've played with PCA.

Jonathan Thayn




On Oct 2, 2014, at 4:59 PM, David L Carlson wrote:

> I think you want to convert your principal component to the same scale as d1, d2, d3, and d4. But the "original space" is a 4-dimensional space in which d1, d2, d3, and d4 are the axes, each with its own mean and standard deviation. Here are a couple of possibilities
> 
> # plot original values for comparison
>> matplot(cbind(d1, d2, d3, d4), pch=20, col=2:5)
> # standardize the pc scores to the grand mean and sd
>> new1 <- scale(pca$scores[,1])*sd(c(d1, d2, d3, d4)) + mean(c(d1, d2, d3, d4))
>> lines(new1)
> # Use least squares regression to predict the row means for the original four variables
>> new2 <- predict(lm(rowMeans(cbind(d1, d2, d3, d4))~pca$scores[,1]))
>> lines(new2, col="red")
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> 
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Don McKenzie
> Sent: Thursday, October 2, 2014 4:39 PM
> To: Jonathan Thayn
> Cc: r-help at r-project.org
> Subject: Re: [R] Using PCA to filter a series
> 
> 
> On Oct 2, 2014, at 2:29 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
> 
>> Hi Don. I would like to "de-rotate? the first component back to its original state so that it aligns with the original time-series. My goal is to create a ?cleaned?, or a ?model? time-series from which noise has been removed. 
> 
> Please cc the list with replies. It?s considered courtesy plus you?ll get more help that way than just from me.
> 
> Your goal sounds almost metaphorical, at least to me.  Your first axis ?aligns? with the original time series already in that it captures the dominant variation
> across all four. Beyond that, there are many approaches to signal/noise relations within time-series analysis. I am not a good source of help on these, and you probably need a statistical consult (locally?), which is not the function of this list.
> 
>> 
>> 
>> Jonathan Thayn
>> 
>> 
>> 
>> On Oct 2, 2014, at 2:33 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>> 
>>> 
>>> On Oct 2, 2014, at 12:18 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
>>> 
>>>> I have four time-series of similar data. I would  like to combine these into a single, clean time-series. I could simply find the mean of each time period, but I think that using principal components analysis should extract the most salient pattern and ignore some of the noise. I can compute components using princomp
>>>> 
>>>> 
>>>> d1 <- c(113, 108, 105, 103, 109, 115, 115, 102, 102, 111, 122, 122, 110, 110, 104, 121, 121, 120, 120, 137, 137, 138, 138, 136, 172, 172, 157, 165, 173, 173, 174, 174, 119, 167, 167, 144, 170, 173, 173, 169, 155, 116, 101, 114, 114, 107, 108, 108, 131, 131, 117, 113)
>>>> d2 <- c(138, 115, 127, 127, 119, 126, 126, 124, 124, 119, 119, 120, 120, 115, 109, 137, 142, 142, 143, 145, 145, 163, 169, 169, 180, 180, 174, 181, 181, 179, 173, 185, 185, 183, 183, 178, 182, 182, 181, 178, 171, 154, 145, 147, 147, 124, 124, 120, 128, 141, 141, 138)
>>>> d3 <- c(138, 120, 129, 129, 120, 126, 126, 125, 125, 119, 119, 122, 122, 115, 109, 141, 144, 144, 148, 149, 149, 163, 172, 172, 183, 183, 180, 181, 181, 181, 173, 185, 185, 183, 183, 184, 182, 182, 181, 179, 172, 154, 149, 156, 156, 125, 125, 115, 139, 140, 140, 138)
>>>> d4 <- c(134, 115, 120, 120, 117, 123, 123, 128, 128, 119, 119, 121, 121, 114, 114, 142, 145, 145, 144, 145, 145, 167, 172, 172, 179, 179, 179, 182, 182, 182, 182, 182, 184, 184, 182, 184, 183, 183, 181, 179, 172, 149, 149, 149, 149, 124, 124, 119, 131, 135, 135, 134)
>>>> 
>>>> 
>>>> pca <- princomp(cbind(d1,d2,d3,d4))
>>>> plot(pca$scores[,1])
>>>> 
>>>> This seems to have created the clean pattern I want, but I would like to project the first component back into the original axes? Is there a simple way to do that?
>>> 
>>> Do you mean that you want to scale the scores on Axis 1 to the mean and range of your raw data?  Or their mean and variance?
>>> 
>>> See
>>> 
>>> ?scale
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Jonathan B. Thayn
>>>>       
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> Don McKenzie
>>> Research Ecologist
>>> Pacific WIldland Fire Sciences Lab
>>> US Forest Service
>>> 
>>> Affiliate Professor
>>> School of Environmental and Forest Sciences 
>>> College of the Environment
>>> University of Washington
>>> dmck at uw.edu
>> 
> 
> Don McKenzie
> Research Ecologist
> Pacific WIldland Fire Sciences Lab
> US Forest Service
> 
> Affiliate Professor
> School of Environmental and Forest Sciences 
> College of the Environment
> University of Washington
> dmck at uw.edu
> 
> 
>         [[alternative HTML version deleted]]
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Fri Oct  3 08:52:10 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Oct 2014 06:52:10 +0000
Subject: [R] (no subject)
In-Reply-To: <CAL+ahON4YWpWD3oDidCpXoKu1SS=RxzKSQgbENKLvk1UQqmjQw@mail.gmail.com>
References: <CAL+ahON4YWpWD3oDidCpXoKu1SS=RxzKSQgbENKLvk1UQqmjQw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8E68@SRVEXCHMBX.precheza.cz>

Hi

when trying your code I got

pval = summary(model)$coeff[2,4]
Error in summary(model)$coeff[2, 4] : subscript out of bounds

> str(summary(model)$coeff)
 num [1, 1:4] 1.73e-17 7.07e-01 2.44e-17 1.00
 - attr(*, "dimnames")=List of 2
  ..$ : chr "(Intercept)"
  ..$ : chr [1:4] "Estimate" "Std. Error" "z value" "Pr(>|z|)"
>

You can see that this object is matrix with one row, so your subscript does not work and you has to define it correctly. How it is beyond my understanding of this topic.

There are also warnings when estimating model, so maybe model is nod defined correctly

>       model = glm.nb(count~habitat,link="log")
Warning messages:
1: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace = control$trace >  :
  iteration limit reached
2: In theta.ml(Y, mu, sum(w), w, limit = control$maxit, trace = control$trace >  :
  iteration limit reached

I did not check further.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Kalia Schuster
> Sent: Friday, October 03, 2014 4:19 AM
> To: r-help at r-project.org
> Subject: [R] (no subject)
>
> Hello,
> I'm new to R. I'm trying to run a power analysis in a for loop to find
> an ideal sample size. The situation is I am doing counts of fish at 24
> different sites and rating those sites as 1 or 2 for good or poor
> habitat.
> So the counts are continuous but the habitat rating isn't. When I try
> to run a negative binomial general linearized model with given values
> for mu:
> exp1.302 and exp-0.32 and a given theta: exp(0.75), I get an error
> message before I can run the whole loop and plot the power of the
> sample size against sample. I used a template my teacher showed in
> class, but since he used a poisson dist., I'm stuck on the glm.nb.
> Please help! This is an assignment, so any suggestions would be
> wonderful and I don't expect anything more. But please remember, I am a
> beginner and only have a crude knowledge of R at this point.
> Much appreciated.
>
> #Power analysis
> rm(list=ls())
> graphics.off()
>
> set.seed(1)
> alpha=0.05
> m=200
>
> Ns = seq(2,40,2)
> nNs = length(Ns)
> NAs=rep(NA,nNs)
> results= data.frame(n=Ns, power=NAs)
>
> for(j in 1:nNs) {
>   n=Ns[j]
>   reject_count = 0
>
>   for(i in 1:m )  {
>
>
>       mu_poor=exp(-0.32)
>       mu_suit=exp(1.302)
>       mu=c(rep(mu_poor,n/2),rep(mu_suit,n/2))
>       theta=exp(0.175)
>       count=rnbinom(n=n,size=theta,mu=mu)
>       hab_poor=1
>       hab_suit=2
>       habitat=sample(hab_poor:hab_suit, size=n, replace=T)
>       model = glm.nb(count~habitat,link="log")
>       summary(model)
>
>
>       pval = summary(model)$coeff[2,4]
>       pval
>       reject = pval < alpha
>       if (reject) reject_count = reject_count+1
>     }
>     reject_rate = reject_count/m
>     power = reject_rate
>     typeIIerror=1-reject_rate
>
>     results[j,]$power=power
> }
> plot (x=Ns, y=results$power, xlab="Sample size", ylab="Power")
> lines(Ns,rep(0.95,nNs))
> par(lty=2)
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Oct  3 08:59:03 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Oct 2014 06:59:03 +0000
Subject: [R] Identifying Values in Dataframe
In-Reply-To: <CAB9UfhR0YsuAGBEEqW4f9C_DpJj+mdYKujUX3v23jnMAh_PPhQ@mail.gmail.com>
References: <CAB9UfhR0YsuAGBEEqW4f9C_DpJj+mdYKujUX3v23jnMAh_PPhQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8E7C@SRVEXCHMBX.precheza.cz>

Hi

maybe

which(abs(data)>0.3, arr.ind=T)
                                     row col
Loss_EV_Amygdala_SF_left_hemisphere   15   2
Loss_EV_Amygdala_SF_left_hemisphere   15   3
Loss_PE_Amygdala_SF_right_hemisphere   5   7
Loss_PE_Amygdala_SF_left_hemisphere   13   9

Gives you what you want.

> sel<-which(abs(data)>0.3, arr.ind=T)
> data[sel]
[1] 0.3268234 0.3451718 0.3116239 0.3316836

Regards.
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Patzelt, Edward
> Sent: Thursday, October 02, 2014 10:18 PM
> To: R-help at r-project.org
> Subject: [R] Identifying Values in Dataframe
>
> R Help -
>
> I'd like to identify each correlation value in the dataframe below
> above/below .3/-.3 in order to graph the original data points. I've
> started
> with the call below to identify each value by it's row and column. I'd
> like
> to form a data object that identifies each set of variables that meet
> the
> criteria and then use that to graph the original data.
>
> *do.call(cbind, lapply(list(row = row(data, T), col = col(data, T),
> value =
> data), as.character))*
> structure(c(-0.0228976615669603, 0.0228976615669603,
> 0.0345568787488209,
> -0.0345568787488209, 0.0704941162950863, 0.0501672252097525,
> 0.119766411337358, 0.0697823742392512, 0.0223273454311378,
> -0.0223273454311378,
> 0.125952482472234, -0.125952482472234, -0.0748856339421511,
> -0.0353553864437216,
> 0.199331873910442, -0.068756564596986, 0.0188033303819659,
> -0.0188033303819659,
> 0.124483870344689, -0.124483870344689, 0.158304442010968,
> -0.158304442010968,
> -0.00291892981576431, 0.00291892981576431, 0.289784855159971,
> 0.197017018634618, 0.0725645607308865, 0.0960039687045857,
> 0.145044311433109,
> -0.145044311433109, 0.228975321916426, -0.228975321916426,
> 0.26388395000877,
> 0.175954114053622, 0.326823414986536, 0.0464304517962428,
> 0.171060413427109,
> -0.171060413427109, 0.125608489395663, -0.125608489395663,
> 0.170699125959079,
> -0.170699125959079, -0.0537588992684595, 0.0537588992684595,
> 0.237938136557008, 0.130101348701669, 0.0420659299644508,
> 0.140016889896702,
> 0.175781963301805, -0.175781963301805, 0.277913325677977,
> -0.277913325677977,
> 0.250436246834054, 0.149310941080417, 0.345171759606147,
> 0.0499822279379925,
> 0.180291553611261, -0.180291553611261, 0.0983047617452837,
> -0.0983047617452837,
> 0.0908629320478729, -0.0908629320478729, 0.0162624158794471,
> -0.0162624158794471, 0.219099271324641, 0.143898328556892,
> 0.0808498509449568,
> 0.0534039458771934, 0.103639895676339, -0.103639895676339,
> 0.224298317217259,
> -0.224298317217259, 0.13939241528796, 0.0923125296440915,
> 0.2952647762031,
> -0.0573156158960486, 0.126972946909388, -0.126972946909388,
> 0.145176640269481,
> -0.145176640269481, 0.176722440639515, -0.176722440639515,
> -0.110517827771672,
> 0.110517827771672, 0.265161677824653, 0.0349452421080511,
> -0.00586032680446085,
> 0.17140674405117, -0.0141919172668973, 0.0141919172668973,
> 0.0416754535115447,
> -0.0416754535115447, 0.110687511145091, 0.163199987771469,
> 0.174846924599677,
> 0.116657756754811, 0.184924363876472, -0.184924363876472,
> 0.0740138506321435,
> -0.0740138506321435, 0.0653341995281647, -0.0653341995281647,
> 0.101098966521841, -0.101098966521841, -0.0263969055123976,
> -0.129660641707532,
> 0.16313101271814, -0.0000382052406584783, 0.118309823316179,
> -0.118309823316179, 0.0408519777835592, -0.0408519777835592,
> -0.15406959482671, -0.274340973979869, 0.1465995621482,
> -0.0608360452726588,
> -0.00570057335076342, 0.00570057335076342, 0.0988132735291764,
> -0.0988132735291764, 0.159498629897594, -0.159498629897594,
> -0.0258437210789338,
> 0.0258437210789338, 0.311623918577701, 0.0959243386674064,
> 0.0373444291324758,
> 0.131601179184854, 0.0032064022008327, -0.0032064022008327,
> 0.0126042917937794,
> -0.0126042917937794, 0.0288999352531186, 0.0343919995425096,
> 0.0375647873892517, 0.0734866249695526, 0.125835994106989,
> -0.125835994106989,
> 0.0557071876372764, -0.0557071876372764, 0.0190687287223345,
> -0.0190687287223345, 0.0301326072710063, -0.0301326072710063,
> 0.0881640884608706, 0.0600194980037123, 0.0948090975231923,
> 0.0259282757599189,
> 0.120417132810781, -0.120417132810781, 0.196695581235906,
> -0.196695581235906,
> 0.166210300278382, 0.0252645245285897, 0.239953962041662,
> -0.013933692494363,
> 0.0174600644363753, -0.0174600644363753, 0.169008089964054,
> -0.169008089964054,
> 0.0503612778194372, -0.0503612778194372, 0.175816302924921,
> -0.175816302924921,
> 0.141434785651191, 0.0824019401386654, 0.173429908437586,
> -0.136795834367563,
> 0.219543981806626, -0.219543981806626, 0.290697487363267,
> -0.290697487363267,
> 0.331683649439792, -0.0035319780591347, 0.237371764540467,
> -0.172828690804139,
> 0.00922163769628213, -0.00922163769628213, 0.275507919516733,
> -0.275507919516733, 0.128267529853407, -0.128267529853407,
> -0.16619622911667,
> 0.16619622911667, 0.102467428865746, -0.115779804556684,
> 0.000997318666924614,
> 0.297139396802529, 0.040957786791642, -0.040957786791642,
> -0.0160650315621922,
> 0.0160650315621922, -0.043765426943726, -0.0637020898937285,
> 0.142863591010818, 0.214059283535989, 0.13975223034564, -
> 0.13975223034564,
> -0.0286586386843802, 0.0286586386843802, 0.13735028629468,
> -0.13735028629468,
> -0.147016933653806, 0.147016933653806, 0.174438743129307,
> -0.0116564727226121,
> -0.0413775943824046, 0.136551598575573, 0.0614942508131549,
> -0.0614942508131549,
> 0.0687487372508148, -0.0687487372508148, -0.0352587211103196,
> -0.0872464182568976, 0.162247767446472, 0.0282617081917608,
> 0.175608445537029,
> -0.175608445537029, -0.0339260764991994, 0.0339260764991994,
> 0.130002432167221, -0.130002432167221, -0.141752408742242,
> 0.141752408742242,
> 0.126603115520512, -0.0784556105378803, -0.0736773348350251,
> 0.154815164010555, -0.102200077602115, 0.102200077602115,
> -0.137144378194025,
> 0.137144378194025, 0.0132012835622079, 0.113105077279414,
> -0.0412435172396771,
> 0.182836991911806, 0.109656132908221, -0.109656132908221,
> -0.0341578533716874,
> 0.0341578533716874, -0.0155952702450936, 0.0155952702450936,
> 0.0962494517693934, -0.0962494517693934, 0.0745517006304259,
> 0.145954619132309, 0.0997683764233029, -0.0562240100001912,
> 0.13254524166143,
> -0.13254524166143, 0.236418162977751, -0.236418162977751,
> 0.0878486801199713,
> -0.00445794916320147, 0.227619583487885, -0.14911359391431,
> 0.0214260010937822,
> -0.0214260010937822, 0.120246543167583, -0.120246543167583), .Dim =
> c(20L,
> 13L), .Dimnames = list(c("Loss_Gain_PE_Amygdala_SF_right_hemisphere",
> "Gain_Loss_PE_Amygdala_SF_right_hemisphere",
> "Loss_Gain_EV_Amygdala_SF_right_hemisphere",
> "Gain_Loss_EV_Amygdala_SF_right_hemisphere",
> "Loss_PE_Amygdala_SF_right_hemisphere",
> "Gain_PE_Amygdala_SF_right_hemisphere",
> "Loss_EV_Amygdala_SF_right_hemisphere",
> "Gain_EV_Amygdala_SF_right_hemisphere",
> "Loss_Gain_PE_Amygdala_SF_left_hemisphere",
> "Gain_Loss_PE_Amygdala_SF_left_hemisphere",
> "Loss_Gain_EV_Amygdala_SF_left_hemisphere",
> "Gain_Loss_EV_Amygdala_SF_left_hemisphere",
> "Loss_PE_Amygdala_SF_left_hemisphere",
> "Gain_PE_Amygdala_SF_left_hemisphere",
> "Loss_EV_Amygdala_SF_left_hemisphere",
> "Gain_EV_Amygdala_SF_left_hemisphere",
> "Loss_Gain_PE_Amygdala_LB_right_hemisphere",
> "Gain_Loss_PE_Amygdala_LB_right_hemisphere",
> "Loss_Gain_EV_Amygdala_LB_right_hemisphere",
> "Gain_Loss_EV_Amygdala_LB_right_hemisphere"), c("hare2f1", "hare2f2",
> "hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
> "ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry",
> "hareResidNetExt", "extResidNetHare")))
>
> --
>
> *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> University SNPLab http://scholar.harvard.edu/buckholtz
> <http://scholar.harvard.edu/buckholtz>*
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Oct  3 09:06:50 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Oct 2014 07:06:50 +0000
Subject: [R] merge by time,
 certain value if 5 min before and after an "event"
In-Reply-To: <CAN5YmCFamTCgrt08QgrDV4ZnReP7c+m0CccSXupaqeTFGJh+vQ@mail.gmail.com>
References: <542D4F6E.6030607@gmx.net>
	<CAN5YmCGiu+FYSAKYWjfN--F6EXscDeJht-pshBh-avuKhxOP3A@mail.gmail.com>
	<542DC2BC.9030907@gmx.net>
	<CAN5YmCFamTCgrt08QgrDV4ZnReP7c+m0CccSXupaqeTFGJh+vQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8E94@SRVEXCHMBX.precheza.cz>

Hi

If Jean's guess is correct, after simple changing Timestamp to real date

see ?strptime and ?as.POSIXct

you can use

result <- merge(mydata, myframe, all=TRUE)

use function ?na.locf from zoo package to fill NAs in Event column and get rid of all rows with NA in location e.g. by

?complete.cases

Regards

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Adams, Jean
> Sent: Thursday, October 02, 2014 11:38 PM
> To: Dagmar
> Cc: R help
> Subject: Re: [R] merge by time, certain value if 5 min before and after
> an "event"
>
> Thanks, Dagmar.
>
> So, shouldn't row 3 with a time of 09:51:01 be "low" and not "high"?
>
> Jean
>
> On Thu, Oct 2, 2014 at 4:25 PM, Dagmar <Ramgad82 at gmx.net> wrote:
>
> > Dear Jean and all,
> >
> > I want all lines to be "low", but during times 9:55 - 10:05 a.m (i.e.
> > a timespan of 10 min) I want them to be "high".
> > In my real data "low" and "high" refer to "lowtide" and "hightide" in
> > the waddensea and I want to assign the location of my animal at the
> > time it was taken to the tide (that means, there was water not only
> > exactly at 10:00 (as taken from official data) but also 5 min before
> and after).
> >
> > I hope that is more understandable, if not ask again. Thanks for
> > trying to help, Dagmar
> >
> > Am 02.10.2014 um 23:01 schrieb Adams, Jean:
> > > Dagmar,
> > >
> > > Can you explain more fully why rows 1, 2, and 5 in your result are
> > > "low" and rows 3 and 4 are "high"?  It is not clear to me from the
> > > information you have provided.
> > >
> > > > result[c(1, 2, 5), ]
> > >             Timestamp location Event
> > > 1 24.09.2012 09:05:01        1 low
> > > 2 24.09.2012 09:49:50        2 low
> > > 5 24.09.2012 10:05:10        5 low
> > >
> > > > result[3:4, ]
> > >             Timestamp location Event
> > > 3 24.09.2012 09:51:01        3  high
> > > 4 24.09.2012 10:04:50        1  high
> > >
> > > Jean
> > >
> > >
> > > On Thu, Oct 2, 2014 at 8:13 AM, Dagmar <Ramgad82 at gmx.net
> > > <mailto:Ramgad82 at gmx.net>> wrote:
> > >
> > >     Hello! I hope someone can help me. It would save me days of
> work.
> > >     Thanks in
> > >     advance!
> > >     I have two dataframes which look like these:
> > >
> > >
> > >     myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00",
> "24.09.2012
> > >     10:00:00",
> > >     "24.09.2012 11:00:00"), Event=c("low","high","low") )
> > >     myframe
> > >
> > >
> > >     mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01",
> "24.09.2012
> > >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50",
> "24.09.2012
> > >     10:05:10")
> > >     , location=c("1","2","3","1","5") )
> > >     mydata
> > >
> > >
> > >     # I want to merge them by time so I have a dataframe which
> looks
> > >     like this
> > >     in the end (i.e. "Low"  during 5 min before and after "high" )
> > >
> > >     result <- data.frame ( Timestamp=c("24.09.2012 09:05:01",
> "24.09.2012
> > >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50",
> "24.09.2012
> > >     10:05:10")
> > >     , location=c("1","2","3","1","5") ,
> > >     Event=c("low", "low","high","high","low"))
> > >     result
> > >
> > >     Anyone knows how do merge them?
> > >     Best regards,
> > >     Dagmar
> > >
> > >     ______________________________________________
> > >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> > >     https://stat.ethz.ch/mailman/listinfo/r-help
> > >     PLEASE do read the posting guide
> > >     http://www.R-project.org/posting-guide.html
> > >     and provide commented, minimal, self-contained, reproducible
> code.
> > >
> > >
> >
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Fri Oct  3 09:31:27 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 3 Oct 2014 07:31:27 +0000
Subject: [R] merge by time,
 certain value if 5 min before and after an "event"
In-Reply-To: <542DC2BC.9030907@gmx.net>
References: <542D4F6E.6030607@gmx.net>
	<CAN5YmCGiu+FYSAKYWjfN--F6EXscDeJht-pshBh-avuKhxOP3A@mail.gmail.com>
	<542DC2BC.9030907@gmx.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8EB0@SRVEXCHMBX.precheza.cz>

Hi

So if I understand correctly, you want to spread value "high" to times 5 minutes before its occurrence and 5 minutes after its occurrence.

If your dates are not extremely big you can prepare its expanded version and use code suggestions I sent previously

myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012 10:00:00", "24.09.2012 11:00:00"), Event=c("low","high","low") )
myframe$Timestamp <- as.POSIXct(strptime(myframe$Timestamp, format="%d.%m.%Y %H:%M:%S"))
expand<-data.frame(Timestamp=seq(myframe[1,1], myframe[3,1], by="5 mins"))
new <- merge(expand, myframe, all=T)
position <- which(new$Event=="high")
hhh <- c(position-1, position, position+1)
new$Event[hhh] <- "high"

If you merge this "new" data frame with your mydata and use na.locf to fill gaps you should get desired result.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Dagmar
> Sent: Thursday, October 02, 2014 11:25 PM
> Cc: R help
> Subject: Re: [R] merge by time, certain value if 5 min before and after
> an "event"
>
> Dear Jean and all,
>
> I want all lines to be "low", but during times 9:55 - 10:05 a.m (i.e. a
> timespan of 10 min) I want them to be "high".
> In my real data "low" and "high" refer to "lowtide" and "hightide" in
> the waddensea and I want to assign the location of my animal at the
> time it was taken to the tide (that means, there was water not only
> exactly at 10:00 (as taken from official data) but also 5 min before
> and after).
>
> I hope that is more understandable, if not ask again. Thanks for trying
> to help, Dagmar
>
> Am 02.10.2014 um 23:01 schrieb Adams, Jean:
> > Dagmar,
> >
> > Can you explain more fully why rows 1, 2, and 5 in your result are
> > "low" and rows 3 and 4 are "high"?  It is not clear to me from the
> > information you have provided.
> >
> > > result[c(1, 2, 5), ]
> >             Timestamp location Event
> > 1 24.09.2012 09:05:01        1 low
> > 2 24.09.2012 09:49:50        2 low
> > 5 24.09.2012 10:05:10        5 low
> >
> > > result[3:4, ]
> >             Timestamp location Event
> > 3 24.09.2012 09:51:01        3  high
> > 4 24.09.2012 10:04:50        1  high
> >
> > Jean
> >
> >
> > On Thu, Oct 2, 2014 at 8:13 AM, Dagmar <Ramgad82 at gmx.net
> > <mailto:Ramgad82 at gmx.net>> wrote:
> >
> >     Hello! I hope someone can help me. It would save me days of work.
> >     Thanks in
> >     advance!
> >     I have two dataframes which look like these:
> >
> >
> >     myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00",
> "24.09.2012
> >     10:00:00",
> >     "24.09.2012 11:00:00"), Event=c("low","high","low") )
> >     myframe
> >
> >
> >     mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01",
> "24.09.2012
> >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50",
> "24.09.2012
> >     10:05:10")
> >     , location=c("1","2","3","1","5") )
> >     mydata
> >
> >
> >     # I want to merge them by time so I have a dataframe which looks
> >     like this
> >     in the end (i.e. "Low"  during 5 min before and after "high" )
> >
> >     result <- data.frame ( Timestamp=c("24.09.2012 09:05:01",
> "24.09.2012
> >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50",
> "24.09.2012
> >     10:05:10")
> >     , location=c("1","2","3","1","5") ,
> >     Event=c("low", "low","high","high","low"))
> >     result
> >
> >     Anyone knows how do merge them?
> >     Best regards,
> >     Dagmar
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible
> code.
> >
> >
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ed.purssell at kcl.ac.uk  Fri Oct  3 09:39:00 2014
From: ed.purssell at kcl.ac.uk (Purssell, Ed)
Date: Fri, 3 Oct 2014 07:39:00 +0000
Subject: [R] Using compute.es and metafor together
Message-ID: <1412321933039.52643@kcl.ac.uk>

Dear All



For mathematically challenged people such as myself; is it ok to use the compute.es package to calculate effect sizes and then import the effect sizes d and variances of d into metafor, coding these as yi and vi respectively and then running the meta-analysis?  This seems easier because compute.es offers a lot of ways of calculating d and its variance using similar codes.



Thanks

Edward



----------------------------
Edward Purssell PhD
Senior Lecturer

Florence Nightingale Faculty of Nursing and Midwifery
King's College London
James Clerk Maxwell Building
57 Waterloo Road
London SE1 8WA
Telephone 020 7848 3021
Mobile 07782 374217
email edward.purssell at kcl.ac.uk
https://www.researchgate.net/profile/Edward_Purssell

	[[alternative HTML version deleted]]


From jmhannon.ucdavis at gmail.com  Fri Oct  3 09:55:20 2014
From: jmhannon.ucdavis at gmail.com (Michael Hannon)
Date: Fri, 3 Oct 2014 00:55:20 -0700
Subject: [R] Hadley's book: paper/PDF/etc. versus github
Message-ID: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>

Hi, folks.  I've got a sort of coupon that would allow me to get a
copy of "Advanced R" by Hadley Wickham at no cost.  OTOH, I've already
cloned the github repository, and having the "live" Rmd files (or in
this case, rmd files) is enormously more useful to me than having any
form of electronic or paper format.

The only reason I can think of for getting, say, a PDF version of the
book is that corrected versions of such books are sometimes (always?)
made available for free if you've already got the PDF version of the
book.  (I know O'Reilly does this.)

But if the github version is going to continue to exist, be updated,
and be generally available, that's even better.  IS it going to exist,
be updated, and be generally available?  Any thoughts?

Thanks,

-- Mike


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri Oct  3 10:34:33 2014
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 3 Oct 2014 10:34:33 +0200
Subject: [R] Using compute.es and metafor together
In-Reply-To: <1412321933039.52643@kcl.ac.uk>
References: <1412321933039.52643@kcl.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730DCD242896@UM-MAIL4112.unimaas.nl>

Yes, that should be fine.

By the way, you do not have to name the variables 'yi' and 'vi' (if this is what you meant by 'coding these as yi and vi respectively'). Indeed, the *argument names* for supplying pre-calculated effect sizes estimates and corresponding sampling variances are 'yi' and 'vi' in various functions in the metafor package, but the *variables names* can be different. For example:

rma(yi=d, vi=var.d, data=dat)

(assuming 'd' and 'var.d' are in data frame 'dat') would be perfectly fine. And since 'yi' and 'vi' are the first two arguments of the rma() function, that can be shortened to:

rma(d, var.d, data=dat)

I tend to use 'yi' and 'vi' also as the variable names in datasets and various examples (and the escalc() function in metafor also names the estimates and corresponding variances in that way), so that leads to rma(yi, vi, data=dat), which is just shorthand for rma(yi=yi, vi=vi, data=dat), so this may be a source of potential confusion. Just wanted to clarify that you do not have to name your variables that way.

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Purssell, Ed
> Sent: Friday, October 03, 2014 09:39
> To: r-help at r-project.org
> Subject: [R] Using compute.es and metafor together
> 
> Dear All
> 
> For mathematically challenged people such as myself; is it ok to use the
> compute.es package to calculate effect sizes and then import the effect
> sizes d and variances of d into metafor, coding these as yi and vi
> respectively and then running the meta-analysis?  This seems easier
> because compute.es offers a lot of ways of calculating d and its variance
> using similar codes.
> 
> Thanks
> Edward
> 
> ----------------------------
> Edward Purssell PhD
> Senior Lecturer
> 
> Florence Nightingale Faculty of Nursing and Midwifery
> King's College London
> James Clerk Maxwell Building
> 57 Waterloo Road
> London SE1 8WA
> Telephone 020 7848 3021
> Mobile 07782 374217
> email edward.purssell at kcl.ac.uk
> https://www.researchgate.net/profile/Edward_Purssell
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Oct  3 11:16:28 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 03 Oct 2014 02:16:28 -0700
Subject: [R] Hadley's book: paper/PDF/etc. versus github
In-Reply-To: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>
References: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>
Message-ID: <71240E3E-6242-4E77-9154-CFB5F8114150@dcn.davis.CA.us>

What a non-question. Github version for free, or PDF and github versions for free. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 3, 2014 12:55:20 AM PDT, Michael Hannon <jmhannon.ucdavis at gmail.com> wrote:
>Hi, folks.  I've got a sort of coupon that would allow me to get a
>copy of "Advanced R" by Hadley Wickham at no cost.  OTOH, I've already
>cloned the github repository, and having the "live" Rmd files (or in
>this case, rmd files) is enormously more useful to me than having any
>form of electronic or paper format.
>
>The only reason I can think of for getting, say, a PDF version of the
>book is that corrected versions of such books are sometimes (always?)
>made available for free if you've already got the PDF version of the
>book.  (I know O'Reilly does this.)
>
>But if the github version is going to continue to exist, be updated,
>and be generally available, that's even better.  IS it going to exist,
>be updated, and be generally available?  Any thoughts?
>
>Thanks,
>
>-- Mike
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From motyocska at yahoo.com  Fri Oct  3 13:15:42 2014
From: motyocska at yahoo.com (Andras Farkas)
Date: Fri, 3 Oct 2014 11:15:42 +0000 (UTC)
Subject: [R] help with subscript on axis lables
Message-ID: <1702354530.79763.1412334942619.JavaMail.yahoo@jws106121.mail.bf1.yahoo.com>

Dear All,
wonder if you could help with the following:we have:vals <- 1:5names(vals) <- paste0("ke",1:length(vals))mp <- barplot(vals, ylim = c(0, 6),ylab=expression(paste("Hour"^"-10")))

In would like to make the numbers (ke1 to ke5, respectively) in the labels of the x axis a subscript. There is plenty info on making subscripts in the title of the axis (ie: xlab=expression(...)), but was unable to find directions for my problem... Appreciate your help,
Andras
	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Fri Oct  3 14:21:38 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Fri, 3 Oct 2014 07:21:38 -0500
Subject: [R] help with subscript on axis lables
In-Reply-To: <1702354530.79763.1412334942619.JavaMail.yahoo@jws106121.mail.bf1.yahoo.com>
References: <1702354530.79763.1412334942619.JavaMail.yahoo@jws106121.mail.bf1.yahoo.com>
Message-ID: <CAN5YmCGTOry+4o1V9enRD6=5zd40G=Sw-UWuQxRedrgQcTcWWA@mail.gmail.com>

Andras,

There may be an easier way to do this, but this works.

vals <- 1:5
names(vals) <- paste0("ke",1:length(vals))
mp <- barplot(vals, ylim = c(0, 6), ylab=expression(Hour^-10), names.arg="")
sapply(vals, function(i) axis(1, at=mp[i], substitute(list(ke[x]),
list(x=i)), tick=FALSE))

Jean

On Fri, Oct 3, 2014 at 6:15 AM, Andras Farkas <motyocska at yahoo.com> wrote:

> Dear All,
> wonder if you could help with the following:we have:vals <- 1:5names(vals)
> <- paste0("ke",1:length(vals))mp <- barplot(vals, ylim = c(0,
> 6),ylab=expression(paste("Hour"^"-10")))
>
> In would like to make the numbers (ke1 to ke5, respectively) in the labels
> of the x axis a subscript. There is plenty info on making subscripts in the
> title of the axis (ie: xlab=expression(...)), but was unable to find
> directions for my problem... Appreciate your help,
> Andras
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Fri Oct  3 14:22:39 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 3 Oct 2014 14:22:39 +0200
Subject: [R] help with subscript on axis lables
In-Reply-To: <1702354530.79763.1412334942619.JavaMail.yahoo@jws106121.mail.bf1.yahoo.com>
References: <1702354530.79763.1412334942619.JavaMail.yahoo@jws106121.mail.bf1.yahoo.com>
Message-ID: <7215BE62-DFC5-4628-A2AC-AFB837D1CFBB@gmail.com>


On 03 Oct 2014, at 13:15 , Andras Farkas <motyocska at yahoo.com> wrote:

> Dear All,
> wonder if you could help with the following:we have:vals <- 1:5names(vals) <- paste0("ke",1:length(vals))mp <- barplot(vals, ylim = c(0, 6),ylab=expression(paste("Hour"^"-10")))
> 
> In would like to make the numbers (ke1 to ke5, respectively) in the labels of the x axis a subscript. There is plenty info on making subscripts in the title of the axis (ie: xlab=expression(...)), but was unable to find directions for my problem... Appreciate your help,
> Andras
> 	[[alternative HTML version deleted]]

Some ideas:

e <- as.expression(lapply(as.double(1:5), function(i)bquote("ke"[.(i)])))
plot(1:5, xaxt="n")
axis(1, at=1:5, labels=e)

barplot(rpois(5, 5), names=e)


> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From h.wickham at gmail.com  Fri Oct  3 14:37:03 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 3 Oct 2014 07:37:03 -0500
Subject: [R] Hadley's book: paper/PDF/etc. versus github
In-Reply-To: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>
References: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>
Message-ID: <CABdHhvGVFx+jHavTqO1XUiSqFLisWewEkw032Ou34B+jKMbE8Q@mail.gmail.com>

> Hi, folks.  I've got a sort of coupon that would allow me to get a
> copy of "Advanced R" by Hadley Wickham at no cost.  OTOH, I've already
> cloned the github repository, and having the "live" Rmd files (or in
> this case, rmd files) is enormously more useful to me than having any
> form of electronic or paper format.

I presume you mean https://github.com/hadley/adv-r (no need to be
secretive about it ;)

> The only reason I can think of for getting, say, a PDF version of the
> book is that corrected versions of such books are sometimes (always?)
> made available for free if you've already got the PDF version of the
> book.  (I know O'Reilly does this.)

The pdf version of the book is made from the files in that repo, so I
don't see any advantage there.  (You can build the pdf yourself if you
spend a few minutes looking for the right file ;)

> But if the github version is going to continue to exist, be updated,
> and be generally available, that's even better.  IS it going to exist,
> be updated, and be generally available?  Any thoughts?

The github version _is_ the authoritative version of the book (and in
some sense it's already slightly better than the book, since a number
of minor typos have been fixed since the book was published). C&H is
mostly print on demand, so later printings of the book are likely to
pick up the improvements, although there is still some additional
human checking in the process, so it'll only get updated every 6
months or so.

The repo and http://adv-r.had.co.nz will continue to exist for the
foreseeable future.

Hadley

-- 
http://had.co.nz/


From matthias.salvisberg at gmail.com  Fri Oct  3 14:31:52 2014
From: matthias.salvisberg at gmail.com (Matthias Salvisberg)
Date: Fri, 3 Oct 2014 14:31:52 +0200
Subject: [R] strange behavior of the compare operator
Message-ID: <CAPXHCUse_cn=+KvM99MvUq1HiT4rjar97FEhjA9mRZd=bwAQ7w@mail.gmail.com>

I had a strange behavior of a function written a few days ago. I
pointed the problem down to the following minimal example.

can anyone explain why the following comparisons don't reply the
same"correct" answer?


Thanks for your reply!

Matthias




R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Copyright (C) 2014 The R Foundation for Statistical Computing
Platform: i386-w64-mingw32/i386 (32-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.
> sessionInfo()R version 3.1.1 (2014-07-10)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=German_Switzerland.1252
LC_CTYPE=German_Switzerland.1252
LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
[5] LC_TIME=German_Switzerland.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.1> > rm(list = ls())> > myDataFrame <- data.frame(var1 =
seq(from = -1, to = 0, by = 0.01))> > any(myDataFrame$var1 ==
(0.68-1))[1] TRUE> > any(myDataFrame$var1 == -0.32)[1] FALSE> >
myDataFrame$var1[69][1] -0.32> > > str((0.68-1)) num -0.32> str(-0.32)
num -0.32> str(myDataFrame$var1) num [1:101] -1 -0.99 -0.98 -0.97
-0.96 -0.95 -0.94 -0.93 -0.92 -0.91 ...

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Fri Oct  3 14:51:36 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 3 Oct 2014 14:51:36 +0200
Subject: [R] comparing two "half-normal production" stochastic frontier
	functions
Message-ID: <m2r3yp71uv.fsf@krugs.de>

Hi

I am using the function frontier::sfa (from the package frontier) to
estimate several "half-normal production" stochastic frontier functions.

Now I want to compare the coefficients of the linear frontier function
and see if they are different.

According to my stackexchange (CrossValidated) question [1] I can
compare these as I can compare a normal linear regression. 

In R, I would uswe the function anova to do this model comparison -
correct?

Now this function does not accept objects of the type 'frontier' - so
how can I do this comparison in R?

To re-iterate, I want to know if the coefficients of the frontier line
(slope and intercept) are significantly different.

Below please find a reproducible example based on data provided in the
package, of what I did, and below the transcript.

Thanks,

Rainer

--8<---------------cut here---------------start------------->8---
library(frontier)
data(front41Data)
dat1 <- front41Data[1:30,]
dat2 <- front41Data[30:60,]
x1 <- sfa(log(output) ~ log(capital), data=dat1)
x2 <- sfa(log(output) ~ log(capital), data=dat2)
x1
x2
anova(x1, x2
--8<---------------cut here---------------end--------------->8---

,----
| > library(frontier)
| > data(front41Data)
| > dat1 <- front41Data[1:30,]
| > dat2 <- front41Data[30:60,]
| > x1 <- sfa(log(output) ~ log(capital), data=dat1)
| > x2 <- sfa(log(output) ~ log(capital), data=dat2)
| Warning message:
|   In sfa(log(output) ~ log(capital), data = dat2) : the parameter
|   'gamma' is close to the boundary of the parameter space [0,1]: this
|   can cause convergence problems and can negatively affect the validity
|   and reliability of statistical tests and might be caused by model
|   misspecification
| > x1
| 
| Call:
| sfa(formula = log(output) ~ log(capital), data = dat1)
| 
| Maximum likelihood estimates
|  (Intercept)  log(capital)       sigmaSq         gamma  
|       2.8646        0.2642        0.4364        0.8243  
| > x2
| 
| Call:
| sfa(formula = log(output) ~ log(capital), data = dat2)
| 
| Maximum likelihood estimates
|  (Intercept)  log(capital)       sigmaSq         gamma  
|       2.7035        0.4550        0.9736        0.9972  
| > 
| > anova(x1, x2)
| Error in UseMethod("anova") : 
|   no applicable method for 'anova' applied to an object of class "frontier"
`----




Footnotes: 
[1]  http://stats.stackexchange.com/questions/117319/comparing-coefficients-of-linear-stochastic-frontier-production-and-cost-funct

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141003/f9e25f8c/attachment.bin>

From jholtman at gmail.com  Fri Oct  3 15:02:32 2014
From: jholtman at gmail.com (jim holtman)
Date: Fri, 3 Oct 2014 09:02:32 -0400
Subject: [R] strange behavior of the compare operator
In-Reply-To: <CAPXHCUse_cn=+KvM99MvUq1HiT4rjar97FEhjA9mRZd=bwAQ7w@mail.gmail.com>
References: <CAPXHCUse_cn=+KvM99MvUq1HiT4rjar97FEhjA9mRZd=bwAQ7w@mail.gmail.com>
Message-ID: <CAAxdm-4m2QF6uw45wxKp1dTRx-q1zrHYmU4164d4=btPq4WXsw@mail.gmail.com>

FAQ 7.31

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 3, 2014 at 8:31 AM, Matthias Salvisberg
<matthias.salvisberg at gmail.com> wrote:
> I had a strange behavior of a function written a few days ago. I
> pointed the problem down to the following minimal example.
>
> can anyone explain why the following comparisons don't reply the
> same"correct" answer?
>
>
> Thanks for your reply!
>
> Matthias
>
>
>
>
> R version 3.1.1 (2014-07-10) -- "Sock it to Me"
> Copyright (C) 2014 The R Foundation for Statistical Computing
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
>
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
>
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
>> sessionInfo()R version 3.1.1 (2014-07-10)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=German_Switzerland.1252
> LC_CTYPE=German_Switzerland.1252
> LC_MONETARY=German_Switzerland.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Switzerland.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1> > rm(list = ls())> > myDataFrame <- data.frame(var1 =
> seq(from = -1, to = 0, by = 0.01))> > any(myDataFrame$var1 ==
> (0.68-1))[1] TRUE> > any(myDataFrame$var1 == -0.32)[1] FALSE> >
> myDataFrame$var1[69][1] -0.32> > > str((0.68-1)) num -0.32> str(-0.32)
> num -0.32> str(myDataFrame$var1) num [1:101] -1 -0.99 -0.98 -0.97
> -0.96 -0.95 -0.94 -0.93 -0.92 -0.91 ...
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Fri Oct  3 15:05:39 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 03 Oct 2014 08:05:39 -0500
Subject: [R]  merge by time,
	certain value if  5 min before and after an "event"
In-Reply-To: <mailman.23.1412330409.25191.r-help@r-project.org>
References: <mailman.23.1412330409.25191.r-help@r-project.org>
Message-ID: <31062c$982jat@ironport10.mayo.edu>

I've attached two functions used locally.  (The attachments will be stripped off of the 
r-help response, but the questioner should get them).  The functions "neardate" and 
"tmerge" were written to deal with a query that comes up very often in our medical 
statistics work, some variety of "get the closest creatinine value to the subject's date 
of rehospitalization, at least one week before but no more than 1 year prior", or tasks 
that merge two data sets to create a single (start, stop] style one.

The neardate function is a variant on match().  Given two (id, date) pairs it will find 
the first pair in list 2 that has date2 <= date1 (or >=) and the same id.  The second 
variable can be any orderable class, but dates are the most common use and hence the name.

These are being added to the survival package release that should be out real-soon-now, 
once I add some extended examples of their use to the time dependent covariates vignette.

Terry Therneau

On 10/03/2014 05:00 AM, r-help-request at r-project.org wrote:
> Hello! I hope someone can help me. It would save me days of work. Thanks in
> advance!
> I have two dataframes which look like these:
>
>
> myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012
> 10:00:00",
> "24.09.2012 11:00:00"), Event=c("low","high","low") )
> myframe
>
>
> mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
> 09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
> 10:05:10")
> , location=c("1","2","3","1","5") )
> mydata
>
>
> # I want to merge them by time so I have a dataframe which looks like this
> in the end (i.e. "Low"  during 5 min before and after "high" )
>
> result <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
> 09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
> 10:05:10")
> , location=c("1","2","3","1","5") ,
> Event=c("low", "low","high","high","low"))
> result
>
> Anyone knows how do merge them?
> Best regards,
> Dagmar
>
-------------- next part --------------
#
# Create a "nearest date" index
#  date1: the trial date
#  date2: target to match to
#
# result: an index vector for data set 1, which shows the row in data set
#  2 that has the same id, and the best date.
#
# best = "after"  The closest date in #2 that is on or after the date in #1
#        "prior"  The closest date in #2 that is on or before the date in #1
# 
neardate <- function(date1, date2, id1, id2, best=c("after", "prior")) {
    if (!missing(id1)) {
        if (length(id1) != length(date1))
            stop("id1 and date1 have different lengths")
        if (missing(id2))
            stop("either both or neither of id1 and id2 must be supplied")
        if (class(id1) != class(id2) && !(is.numeric(id1) && is.numeric(id2)))
            stop("id1 and id2 are different data types")
        if (length(id2) != length(date2))
            stop("id2 and date2 have different lengths")
    }
    else if (!missing(id2))
        stop("either both or neither of id1 and id2 must be supplied")
        
    if (class(date1) != class(date2) & !(is.numeric(date1) & is.numeric(date2)))
        stop("date1 and date2 are diffrent data types")

    if (is.factor(date1) & !is.ordered(date1)) 
        stop("date1 cannot be a factor")

    date1 <- as.numeric(date1)  # this will fail for silly inputs like a list
    date2 <- as.numeric(date2)  
    best <- match.arg(best)

    # Throw out missing dates in the second arg, but remember which ones
    rowid <- 1:length(date2)
    if (any(is.na(date2))) {
        toss <- is.na(date2)
        date2 <- date2[!toss]
        if (!missing(id2)) id2 <- id2[!toss]
        rowid <- rowid[!toss]
    }
    n2 <- length(date2)
    if (n2 ==0) stop("No valid entries in data set 2")

    # Simpler case: no id variables
    rowid <- 1:length(date2)
    if (missing(id1)) {
        if (best=="prior")
            indx2 <- approx(date2, 1:n2, date1, method="constant", yleft=NA,
                            yright=n2, rule=2, f=0)$y
        else 
            indx2 <- approx(date2, 1:n2, date1, method="constant", yleft=1,
                            yright=NA, rule=2, f=1)$y
        return(rowid[indx2])
    }

    # match id values as well
    #   First toss out any rows in id2 that are not possible targets for id1
    #   (id2 is usually the larger data set, thinning speeds it up)
    indx1 <- match(id2, id1)
    toss <- is.na(indx1) 
    if (any(toss)) {
        id2 <- id2[!toss]
        date2 <- date2[!toss]
        indx1 <- indx1[!toss]
        rowid <- rowid[!toss]
    }
    
    n2 <- length(date2)
    if (n2 ==0) stop("No valid entries in data set 2")

    # We need to create a merging id.  A minimal amount of
    #  spread for the dates keeps numeric overflow at bay
    alldate <- sort(unique(c(date1, date2)))
    date1 <- match(date1, alldate)
    date2 <- match(date2, alldate)
    delta <- 1.0 + length(alldate)  #numeric, not integer, on purpose
    hash1 <- match(id1, id1)*delta + date1
    hash2 <- indx1*delta + date2 

    if (best=="prior")
        indx2 <- approx(hash2, 1:n2, hash1, method="constant", yleft=NA,
                        yright=n2, rule=2, f=0)$y
    else 
        indx2 <- approx(hash2, 1:n2, hash1, method="constant", yleft=1,
                        yright=NA, rule=2, f=1)$y
    rowid[ifelse(id1== id2[indx2], indx2, NA)]
}
-------------- next part --------------
tmerge <- function(data, id, start="start", end, status,  ...) {
    Call <- match.call()
    # The function wants to recognize some special keywords in the
    #  arguments, so define a set of functions which will be used to
    #  mark objects
    new <- new.env(parent=parent.frame())
    assign("count", function(x) {class(x) <- c("count", class(x)); x}, 
           envir=new)
    assign("cumcount", function(x) {class(x) <- c("cumcount", class(x)); x}
           , envir=new)
    assign("event",  function(x) {class(x) <- c("event", class(x)); x}, 
           envir=new)
    assign("cumevent", function(x) {class(x) <- c("cumevent", class(x)); x}
           , envir=new)
    assign("variable", 
           function(...) {x <- list(...); class(x) <- "variable"; x},
           envir= new)
 
    if (missing(data)) stop("a data argument is required")
    dname <- names(data)
    if (missing(id)) stop("the id argument is required")

    if (!inherits(data, "tmerge")) {
        # The first call has to set up the identities of the 
        #  variables
        # Id variable first
        tname <- rep("", 4)
        names(tname) <- c("id", "start", "end", "status")

        if (length(id)==1 && is.character(id)) {
            j <- match(id, names(data))
            if (missing(j)) stop("id variable name not found in data")
            tname[1] <- id
            id <- data[[id]]
        }
        else stop("on the initial call 'id' should be a variable name")

        if (missing(end)) stop("end argument not supplied")
        if (length(end)==1 && is.character(end)) {
            j <- match(end, names(data))
            if (missing(j)) stop("end variable name not found in data")
            tname[3] <- end
        }
        else stop("on the initial call 'end' should be a variable name")

        if (missing(status)) stop("status argument not supplied")
        if (length(status)==1 && is.character(status)) {
            j <- match(status, names(data))
            if (missing(j)) stop("status variable name not found in data")
            tname[4] <- status
        }
        else stop("on the initial call 'status' should be a variable name")
        temp <- data[[status]]
        if (is.logical(temp)) {
            temp <- ifelse(temp, 0,1)
            data[[status]] <- temp
        }
        if (!is.numeric(temp)) 
            stop("status variable must be numeric or logical")
        if (any(temp!=0 & temp!=1)) 
            stop("numeric status values must be 0 or 1")
        
        # The start variable is allowed to be missing, in which case we 
        #   add one
        if (length(start)==1 && is.character(start)) {
            j <- match(start, names(data))
            if (is.na(j)) data <- cbind(data, start=0)
            tname[2] <- start
        }
        else stop("on the initial call 'start' should be a variable name")

        unused <- Call[is.na(match(names(Call), c("data", "id", "start",
                                                  "end", "status")))]
    }
    else {
        tname <- attr(data, 'tname') # data is a prior tmerge object
        unused <- Call[is.na(match(names(Call), c("data", "id")))]
    }

    if (length(unused) <=1) {
        # An initial call, usually, with nothing to add.  Rather than indent
        #  the entire remainder of the code put a return here.
        attr(data, "tname") <- tname
        attr(data, "tcount") <- NULL  #remove tcount if it exists
        class(data) <- c("tmerge", class(tdata))
        return(data)
    }

    # Now for the actual work, adding a variable into the mix
    # Each of the newvars should be a time variable which fits into the
    # time scale of the starter data set
    unused[[1]] <- as.name("list")  # The as-yet unused arguments
    args <- eval(unused, envir=new)
    argclass <- sapply(args, function(x) (class(x))[1])
    argname <- names(args)
    if (any(argname== "")) stop("all argments must have a name")
       
    check <- match(argclass, c("count", "cumcount", "event", 
                               "cumevent", "variable"))
    if (any(is.na(check)))
        stop(paste("argument(s)", argname[is.na(check)], 
                   "not a recognized type"))

    dname <- match(tname, names(data))
    names(dname) <- names(tname)
    if (any(is.na(dname))) 
        stop("data set does not match its own tname attribute")
                   
    indx <- match(id, data[[dname["id"]]])
    if (any(is.na(indx))) stop("new data has subjects not in the base data set")


    # The tcount matrix is useful for debugging
    tcount <- matrix(0L, length(argname), 7)
    dimnames(tcount) <- list(argname, c("early","late", "gap", "within", 
                                        "tied edge", "front edge", "back edge"))

    newdata <- data
    row.names(newdata) <- NULL

    for (i in 1:length(args)) {
        baseid <- newdata[[dname["id"]]]
        dstart <- newdata[[dname["start"]]]
        dstop  <- newdata[[dname["end"]]]

        # if an event time is missing then skip that obs
        if (argclass[i] == "variable")  etime <- args[[i]][[1]]
        else etime <- args[[i]]
        keep <- !is.na(etime)
        etime <- etime[keep]
        class(etime) <- class(etime)[-1] #throw away my fake class
        id <- id[keep]

        indx1 <- neardate(etime, dstart, id, baseid, best="prior")
        indx2 <- neardate(etime, dstop,  id, baseid, best="after")
        # The event times fall into one of 5 categories
        #   1. Before the first interval
        #   2. After the last interval
        #   3. Outside any interval but with time span, i.e, it falls into
        #       a gap in follow-up
        #   4. Strictly inside an interval (don't touch either end)
        #   5. Inside an interval, but touching.
        itype <- ifelse(is.na(indx1), 1,
                        ifelse(is.na(indx2), 2, 
                               ifelse(indx2 > indx1, 3,
                                      ifelse(etime== dstart[indx1] | 
                                             etime== dstop[indx2], 5, 4))))

        # Subdivide the events that touch on a boundary
        #   Common: e.g. the subject has time intervals of
        #      (a,b] and (b,c] with a new count at b.
        #  Start: an interval (a,b], new count at a, subject not at risk at a-0
        #  End: similar to start
        #  
        subtype <- ifelse(itype!=5, 0, 
                          ifelse(indx1 == indx2+1, 1,
                                 ifelse(etime==dstart[indx1], 2, 3)))
        tcount[i,] <- table(factor(itype+subtype, levels=c(1:4, 6:8)))

        if (argclass[i] == "variable") {
            stop("'variable' code not yet finished")
        }
        else {
            increment <- rep(0, nrow(newdata))
            eflag <- (argclass[i] %in% c("event", "cumevent")) # 'event' type
            if (eflag) {
                if (any(subtype==1)) { #subtype 1 events to the earlier interval
                    count1 <- table(indx2[subtype==1])
                    itemp <- as.numeric(names(count1))
                    increment[itemp] <- increment[itemp] + c(count1)
                }
                if (any(subtype==3)) { # go to the matched interval
                    count3 <- table(indx2[subtype==3])
                    itemp <- as.numeric(names(count3))
                    increment[itemp] <- increment[itemp] + c(count3)
                }
                #subtype 2 and type 3 events are ignored
            }
            else {
                if (any(itype==1)) {
                    count <- table(id[itype==1])  #there might be multiples
                    itemp <- match(names(count), baseid)
                    increment[itemp] <- increment[itemp] + c(count)
                }

                if (any(subtype==1)) { #subtype 1 events to the later interval
                    count1 <- table(indx1[subtype==1])
                    itemp <- as.numeric(names(count1))
                    increment[itemp] <- increment[itemp] + c(count1)
                }
  
                if (any(subtype==2)) { # subtype 2 go to the matched interval
                    count2 <- table(indx1[subtype==2])
                    itemp <- as.numeric(names(count2))
                    increment[itemp] <- increment[itemp] + c(count2)
                }
                # subtype 3 are ignored (as are type 3 events)
            } 


            # Type 4 forces us to split rows of the data set
            #  A single subject might have muliple jumps on a single day,
            #   or a single day a jump for multiple subjects, so we need
            #   to count up by day and subject
            if (any(itype==4)) {
                indx4 <- which(itype==4)
                n4 <- length(indx4)
                # first will be true for first of each unique (id, etime) set
                #  etime is the set of new times, indx1=the obs it went into
                #  so each of these represents a new value to insert
                firstid <- c(T, diff(indx1[indx4]) !=0)
                first <- (firstid | c(TRUE, diff(etime[indx4])!=0))
                irows<- (indx1[indx4])[first] #which rows in base to expand
                newrows <- c(table(irows))  #single interval may have >1 insert
                irows <- unique(irows)
                newcount <- diff(c(which(first), 1+n4)) #multiple events, 1 day
                etemp <- rep(1L, nrow(newdata))
                etemp[irows] <- 1+ newrows
                newindx <- rep(1:nrow(newdata), etemp)  
                newdata <- newdata[newindx,]
                increment <- increment[newindx]  #expand increment

                #
                # Now fix up the new data set
                #  For each subject the new set of start times = c(old,newtimes)
                #                                stop = c(newtimes, old)
                #                                status=c(rep(0,newtimes), old)
                #                                increment=c(old, count)
                #  rindx is the index of rows for each changed interval
                rindx <- which(diff(newindx)==0)  #the added rows
                newtimes <- (etime[indx4])[first]
                newdata[rindx,   dname["end"]] <- newtimes
                newdata[rindx+1, dname["start"]] <- newtimes
                newdata[rindx,   dname["status"]] <- 0
                if (eflag) increment[rindx] <- newcount
                else       increment[rindx+1] <- newcount
            }

            # Now update the count variable
            if (argclass[i] %in% c("cumcount", "cumevent")) {
                # Cumulative within person
                temp <- cumsum(increment)
                idname <- dname["id"]
                indx <- match(newdata[[idname]], newdata[[idname]])
                newdata[[argname[i]]] <- temp + increment[indx] - temp[indx]
            }
            else newdata[[argname[i]]] <- increment
        }
    }
    attr(newdata, "tcount") <- tcount
    row.names(newdata) <- NULL
    newdata
}

                         
    

From kw1958 at gmail.com  Fri Oct  3 15:14:47 2014
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Fri, 3 Oct 2014 09:14:47 -0400
Subject: [R] Befuddled by ddply
In-Reply-To: <CADv2QyH3DsNrA8CTd4rhbaDpUvK_Po=E2+iuezqbuVE3KSGYXA@mail.gmail.com>
References: <F1B69245-738E-4632-915D-7DB141F75823@gmail.com>
	<CADv2QyH3DsNrA8CTd4rhbaDpUvK_Po=E2+iuezqbuVE3KSGYXA@mail.gmail.com>
Message-ID: <8CF8B3D3-C1F9-467F-BF7B-AA1463A1481D@gmail.com>

Dennis,
Thanks for the help. I am using colwise now in a couple of places.
Best,
KW


On Oct 2, 2014, at 12:26 PM, Dennis Murphy <djmuser at gmail.com> wrote:

> plyr::colwise(defCurveBreak, y = 4)(mdf)
> 
> It took me a few minutes to realize that defCurveBreak() took a vector
> as its first argument; then it made more sense.
> 
> Dennis
> 
> On Thu, Oct 2, 2014 at 7:19 AM, Keith S Weintraub <kw1958 at gmail.com> wrote:
>> Folks,
>> 
>> I have the following data:
>> 
>> mdf<-structure(list(a = 1:3, b = c(10, 20, 30)), .Names = c("a", "b"
>> ), row.names = c(NA, -3L), class = "data.frame")
>> 
>> And function:
>> 
>> defCurveBreak<-function(x, y) {
>>  cumsum(rep(diff(c(0, x)), each = y)/y)
>> }
>> 
>> lapply'ing to get the result "foo"
>> 
>> foo<-data.frame(lapply(mdf, function(x, y) defCurveBreak(x,y), 4))
>>> foo
>>      a    b
>> 1  0.25  2.5
>> 2  0.50  5.0
>> 3  0.75  7.5
>> 4  1.00 10.0
>> 5  1.25 12.5
>> 6  1.50 15.0
>> 7  1.75 17.5
>> 8  2.00 20.0
>> 9  2.25 22.5
>> 10 2.50 25.0
>> 11 2.75 27.5
>> 12 3.00 30.0
>> 
>> Which all works fine.
>> 
>> I was wondering is there a way to do this using ddply? Is there a reason to do this using ddply rather than the above idiom?
>> 
>> I spent a bunch of time trying to figure out how to set it up in ddply (is that the wrong tool?) to no avail.
>> 
>> Thanks for your time,
>> Best,
>> KW
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From therneau at mayo.edu  Fri Oct  3 16:19:33 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 03 Oct 2014 09:19:33 -0500
Subject: [R] c() and dates
Message-ID: <58e5f6$iv9gkm@ironport9.mayo.edu>

I'm a bit puzzled by a certain behavior with dates.  (R version 3.1.1)

 > temp1 <- as.Date(1:2, origin="2000/5/3")
 > temp1
[1] "2000-05-04" "2000-05-05"

 > temp2 <- as.POSIXct(temp1)
 > temp2
[1] "2000-05-03 19:00:00 CDT" "2000-05-04 19:00:00 CDT"

So far so good.  On 5/4, midnight in Greenwich it was 19:00 on 5/3 in my time zone.  The 
manual page has a clear explanation of what goes on.

 > c(temp1, temp2)
[1] "2000-05-04"    "2000-05-05"    "2623237-10-15" "2623474-05-06"
 > class(c(temp1, temp2))
[1] "Date"

 > c(temp2, temp1)
[1] "2000-05-03 19:00:00 CDT" "2000-05-04 19:00:00 CDT"
[3] "1969-12-31 21:04:41 CST" "1969-12-31 21:04:42 CST"
 > class(c(temp2, temp1))
[1] "POSIXct" "POSIXt"

I would have expected c() to determine a common class, somehow, then do the conversion and 
concatonate.  That is obviously not what happens.  I've read the manual page but I must be 
missing something.  I make no claim that R is broken, mistaken, or otherwise deficient, 
only that my understanding is so.

Could someone illuminate?

Terry T.


From wdunlap at tibco.com  Fri Oct  3 16:42:28 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 3 Oct 2014 07:42:28 -0700
Subject: [R] merge by time,
	certain value if 5 min before and after an "event"
In-Reply-To: <31062c$982jat@ironport10.mayo.edu>
References: <mailman.23.1412330409.25191.r-help@r-project.org>
	<31062c$982jat@ironport10.mayo.edu>
Message-ID: <CAF8bMcaa7ytRiJ8tK9WC3ocDCGBseZkHna-FcBFQHoTSatU_=w@mail.gmail.com>

Hi Terry,

Some of that combination of sort() and approx() can be done by
findInterval(), which may be quick enough that you don't need the
'thinning' part of the code.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 3, 2014 at 6:05 AM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> I've attached two functions used locally.  (The attachments will be stripped
> off of the r-help response, but the questioner should get them).  The
> functions "neardate" and "tmerge" were written to deal with a query that
> comes up very often in our medical statistics work, some variety of "get the
> closest creatinine value to the subject's date of rehospitalization, at
> least one week before but no more than 1 year prior", or tasks that merge
> two data sets to create a single (start, stop] style one.
>
> The neardate function is a variant on match().  Given two (id, date) pairs
> it will find the first pair in list 2 that has date2 <= date1 (or >=) and
> the same id.  The second variable can be any orderable class, but dates are
> the most common use and hence the name.
>
> These are being added to the survival package release that should be out
> real-soon-now, once I add some extended examples of their use to the time
> dependent covariates vignette.
>
> Terry Therneau
>
> On 10/03/2014 05:00 AM, r-help-request at r-project.org wrote:
>>
>> Hello! I hope someone can help me. It would save me days of work. Thanks
>> in
>> advance!
>> I have two dataframes which look like these:
>>
>>
>> myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00", "24.09.2012
>> 10:00:00",
>> "24.09.2012 11:00:00"), Event=c("low","high","low") )
>> myframe
>>
>>
>> mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
>> 09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
>> 10:05:10")
>> , location=c("1","2","3","1","5") )
>> mydata
>>
>>
>> # I want to merge them by time so I have a dataframe which looks like this
>> in the end (i.e. "Low"  during 5 min before and after "high" )
>>
>> result <- data.frame ( Timestamp=c("24.09.2012 09:05:01", "24.09.2012
>> 09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50", "24.09.2012
>> 10:05:10")
>> , location=c("1","2","3","1","5") ,
>> Event=c("low", "low","high","high","low"))
>> result
>>
>> Anyone knows how do merge them?
>> Best regards,
>> Dagmar
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Fri Oct  3 16:51:56 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 3 Oct 2014 07:51:56 -0700
Subject: [R] c() and dates
In-Reply-To: <58e5f6$iv9gkm@ironport9.mayo.edu>
References: <58e5f6$iv9gkm@ironport9.mayo.edu>
Message-ID: <97624D20-3C3A-4A11-AFE3-DC2D00FE9A12@comcast.net>


On Oct 3, 2014, at 7:19 AM, Therneau, Terry M., Ph.D. wrote:

> I'm a bit puzzled by a certain behavior with dates.  (R version 3.1.1)
> 
> > temp1 <- as.Date(1:2, origin="2000/5/3")
> > temp1
> [1] "2000-05-04" "2000-05-05"
> 
> > temp2 <- as.POSIXct(temp1)
> > temp2
> [1] "2000-05-03 19:00:00 CDT" "2000-05-04 19:00:00 CDT"
> 
> So far so good.  On 5/4, midnight in Greenwich it was 19:00 on 5/3 in my time zone.  The manual page has a clear explanation of what goes on.
> 
> > c(temp1, temp2)
> [1] "2000-05-04"    "2000-05-05"    "2623237-10-15" "2623474-05-06"
> > class(c(temp1, temp2))
> [1] "Date"
> 
> > c(temp2, temp1)
> [1] "2000-05-03 19:00:00 CDT" "2000-05-04 19:00:00 CDT"
> [3] "1969-12-31 21:04:41 CST" "1969-12-31 21:04:42 CST"
> > class(c(temp2, temp1))
> [1] "POSIXct" "POSIXt"
> 
> I would have expected c() to determine a common class, somehow, then do the conversion and concatonate.  That is obviously not what happens.  I've read the manual page but I must be missing something.  I make no claim that R is broken, mistaken, or otherwise deficient, only that my understanding is so.
> 

It doesn't appear that any check is made on the commonality of class by either c.Date (which one would expect to be called when the Date object is the first argument) .....  or with c.POSIXctt:

> c.Date
function (..., recursive = FALSE) 
structure(c(unlist(lapply(list(...), unclass))), class = "Date")
<bytecode: 0x10bc1c0e0>
<environment: namespace:base>

> c.POSIXct
function (..., recursive = FALSE) 
.POSIXct(c(unlist(lapply(list(...), unclass))))
<bytecode: 0x10bc0d470>
<environment: namespace:base>

I don't find any description of the behavior of `c.Date` when I go to a help page with ?c.Date.

The only description of the action of `c.POSIXct` that I can find in the page to which we are sent with ?c.POSIXct says:

"Using c on "POSIXlt" objects converts them to the current time zone, and on "POSIXct" objects drops any "tzone" attributes (even if they are all marked with the same time zone)."


> Could someone illuminate?
> 

Agree it's "unexpected behavior" and worthy of a feature request to R Core, but until that obvious undesireable behavior is corrected, I guess the user is left with the responsibility of converting all objects to a common class.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Oct  3 16:58:52 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 3 Oct 2014 07:58:52 -0700
Subject: [R] c() and dates
In-Reply-To: <58e5f6$iv9gkm@ironport9.mayo.edu>
References: <58e5f6$iv9gkm@ironport9.mayo.edu>
Message-ID: <13653421-86DA-45F7-A865-5CF28E67AF85@comcast.net>


On Oct 3, 2014, at 7:19 AM, Therneau, Terry M., Ph.D. wrote:

> I'm a bit puzzled by a certain behavior with dates.  (R version 3.1.1)
> 
> > temp1 <- as.Date(1:2, origin="2000/5/3")
> > temp1
> [1] "2000-05-04" "2000-05-05"
> 
> > temp2 <- as.POSIXct(temp1)
> > temp2
> [1] "2000-05-03 19:00:00 CDT" "2000-05-04 19:00:00 CDT"
> 
> So far so good.  On 5/4, midnight in Greenwich it was 19:00 on 5/3 in my time zone.  The manual page has a clear explanation of what goes on.
> 
> > c(temp1, temp2)
> [1] "2000-05-04"    "2000-05-05"    "2623237-10-15" "2623474-05-06"
> > class(c(temp1, temp2))
> [1] "Date"
> 
> > c(temp2, temp1)
> [1] "2000-05-03 19:00:00 CDT" "2000-05-04 19:00:00 CDT"
> [3] "1969-12-31 21:04:41 CST" "1969-12-31 21:04:42 CST"
> > class(c(temp2, temp1))
> [1] "POSIXct" "POSIXt"
> 
> I would have expected c() to determine a common class, somehow, then do the conversion and concatonate.  That is obviously not what happens.  I've read the manual page but I must be missing something.  I make no claim that R is broken, mistaken, or otherwise deficient, only that my understanding is so.
> 
> Could someone illuminate?

Followup to my earlier post: It's pretty easy to redefine c.Date and c.POSIXct to behave in hte manner is expected:

 c.Date <- function (..., recursive = FALSE) 
   structure(c(unlist(lapply(list(...), as.Date))), class = "Date")
  temp1 <- as.Date(1:2, origin="2000/5/3")
  temp1
#[1] "2000-05-04" "2000-05-05"
  temp2 <- as.POSIXct(temp1)

  c(temp1, temp2)
#[1] "2000-05-04" "2000-05-05" "2000-05-04" "2000-05-05"
#  class(c(temp1, temp2))
#[1] "Date"
#  c(temp2, temp1)
[1] "2000-05-03 17:00:00 PDT" "2000-05-04 17:00:00 PDT" "1969-12-31 19:04:41 PST"
[4] "1969-12-31 19:04:42 PST"

 c.POSIXct <-  function (..., recursive = FALSE) 
  .POSIXct(c(unlist(lapply(list(...), as.POSIXct))))


>  c(temp1, temp2)
[1] "2000-05-04" "2000-05-05" "2000-05-04" "2000-05-05"
>  class(c(temp1, temp2))
[1] "Date"
>  c(temp2, temp1)
[1] "2000-05-03 17:00:00 PDT" "2000-05-04 17:00:00 PDT" "2000-05-03 17:00:00 PDT"
[4] "2000-05-04 17:00:00 PDT"


-- 
David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Fri Oct  3 17:33:20 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 3 Oct 2014 15:33:20 +0000
Subject: [R] Using PCA to filter a series
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9D6C1@mb02.ads.tamu.edu>

You can reconstruct the data from the first component. Here's an example using singular value decomposition on the original data matrix:

> d <- cbind(d1, d2, d3, d4)
> d.svd <- svd(d)
> new <- d.svd$u[,1] * d.svd$d[1]

new is basically your cp1. If we multiply it by each of the loadings, we can create reconstructed values based on the first component:

> dnew <- sapply(d.svd$v[,1], function(x) new * x)
> round(head(dnew), 1)
      [,1]  [,2]  [,3]  [,4]
[1,] 119.3 134.1 135.7 134.6
[2,] 104.2 117.2 118.6 117.6
[3,] 109.7 123.3 124.8 123.8
[4,] 109.3 122.9 124.3 123.3
[5,] 105.8 119.0 120.4 119.4
[6,] 111.5 125.4 126.9 125.8
> head(d)
      d1  d2  d3  d4
[1,] 113 138 138 134
[2,] 108 115 120 115
[3,] 105 127 129 120
[4,] 103 127 129 120
[5,] 109 119 120 117
[6,] 115 126 126 123

> diag(cor(d, dnew))
[1] 0.9233742 0.9921703 0.9890085 0.9910287

Since you want a single variable to stand for all four, you could scale new to the mean:

> newd <- new*mean(d.svd$v[,1])
> head(newd)
[1] 130.9300 114.3972 120.3884 119.9340 116.1588 122.3983

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: Jonathan Thayn [mailto:jthayn at ilstu.edu] 
Sent: Thursday, October 2, 2014 11:11 PM
To: David L Carlson
Cc: r-help at r-project.org
Subject: Re: [R] Using PCA to filter a series

I suppose I could calculate the eigenvectors directly and not worry about centering the time-series, since they essentially the same range to begin with:

vec <- eigen(cor(cbind(d1,d2,d3,d4)))$vector
cp <- cbind(d1,d2,d3,d4)%*%vec
cp1 <- cp[,1]

I guess there is no way to reconstruct the original input data using just the first component, though, is there? Not the original data in it entirety, just one time-series that we representative of the general pattern. Possibly something like the following, but with just the first component:

o <- cp%*%solve(vec)

Thanks for your help. It's been a long time since I've played with PCA.

Jonathan Thayn




On Oct 2, 2014, at 4:59 PM, David L Carlson wrote:

> I think you want to convert your principal component to the same scale as d1, d2, d3, and d4. But the "original space" is a 4-dimensional space in which d1, d2, d3, and d4 are the axes, each with its own mean and standard deviation. Here are a couple of possibilities
> 
> # plot original values for comparison
>> matplot(cbind(d1, d2, d3, d4), pch=20, col=2:5)
> # standardize the pc scores to the grand mean and sd
>> new1 <- scale(pca$scores[,1])*sd(c(d1, d2, d3, d4)) + mean(c(d1, d2, d3, d4))
>> lines(new1)
> # Use least squares regression to predict the row means for the original four variables
>> new2 <- predict(lm(rowMeans(cbind(d1, d2, d3, d4))~pca$scores[,1]))
>> lines(new2, col="red")
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> 
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Don McKenzie
> Sent: Thursday, October 2, 2014 4:39 PM
> To: Jonathan Thayn
> Cc: r-help at r-project.org
> Subject: Re: [R] Using PCA to filter a series
> 
> 
> On Oct 2, 2014, at 2:29 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
> 
>> Hi Don. I would like to "de-rotate? the first component back to its original state so that it aligns with the original time-series. My goal is to create a ?cleaned?, or a ?model? time-series from which noise has been removed. 
> 
> Please cc the list with replies. It?s considered courtesy plus you?ll get more help that way than just from me.
> 
> Your goal sounds almost metaphorical, at least to me.  Your first axis ?aligns? with the original time series already in that it captures the dominant variation
> across all four. Beyond that, there are many approaches to signal/noise relations within time-series analysis. I am not a good source of help on these, and you probably need a statistical consult (locally?), which is not the function of this list.
> 
>> 
>> 
>> Jonathan Thayn
>> 
>> 
>> 
>> On Oct 2, 2014, at 2:33 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>> 
>>> 
>>> On Oct 2, 2014, at 12:18 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
>>> 
>>>> I have four time-series of similar data. I would  like to combine these into a single, clean time-series. I could simply find the mean of each time period, but I think that using principal components analysis should extract the most salient pattern and ignore some of the noise. I can compute components using princomp
>>>> 
>>>> 
>>>> d1 <- c(113, 108, 105, 103, 109, 115, 115, 102, 102, 111, 122, 122, 110, 110, 104, 121, 121, 120, 120, 137, 137, 138, 138, 136, 172, 172, 157, 165, 173, 173, 174, 174, 119, 167, 167, 144, 170, 173, 173, 169, 155, 116, 101, 114, 114, 107, 108, 108, 131, 131, 117, 113)
>>>> d2 <- c(138, 115, 127, 127, 119, 126, 126, 124, 124, 119, 119, 120, 120, 115, 109, 137, 142, 142, 143, 145, 145, 163, 169, 169, 180, 180, 174, 181, 181, 179, 173, 185, 185, 183, 183, 178, 182, 182, 181, 178, 171, 154, 145, 147, 147, 124, 124, 120, 128, 141, 141, 138)
>>>> d3 <- c(138, 120, 129, 129, 120, 126, 126, 125, 125, 119, 119, 122, 122, 115, 109, 141, 144, 144, 148, 149, 149, 163, 172, 172, 183, 183, 180, 181, 181, 181, 173, 185, 185, 183, 183, 184, 182, 182, 181, 179, 172, 154, 149, 156, 156, 125, 125, 115, 139, 140, 140, 138)
>>>> d4 <- c(134, 115, 120, 120, 117, 123, 123, 128, 128, 119, 119, 121, 121, 114, 114, 142, 145, 145, 144, 145, 145, 167, 172, 172, 179, 179, 179, 182, 182, 182, 182, 182, 184, 184, 182, 184, 183, 183, 181, 179, 172, 149, 149, 149, 149, 124, 124, 119, 131, 135, 135, 134)
>>>> 
>>>> 
>>>> pca <- princomp(cbind(d1,d2,d3,d4))
>>>> plot(pca$scores[,1])
>>>> 
>>>> This seems to have created the clean pattern I want, but I would like to project the first component back into the original axes? Is there a simple way to do that?
>>> 
>>> Do you mean that you want to scale the scores on Axis 1 to the mean and range of your raw data?  Or their mean and variance?
>>> 
>>> See
>>> 
>>> ?scale
>>>> 
>>>> 
>>>> 
>>>> 
>>>> Jonathan B. Thayn
>>>>       
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> Don McKenzie
>>> Research Ecologist
>>> Pacific WIldland Fire Sciences Lab
>>> US Forest Service
>>> 
>>> Affiliate Professor
>>> School of Environmental and Forest Sciences 
>>> College of the Environment
>>> University of Washington
>>> dmck at uw.edu
>> 
> 
> Don McKenzie
> Research Ecologist
> Pacific WIldland Fire Sciences Lab
> US Forest Service
> 
> Affiliate Professor
> School of Environmental and Forest Sciences 
> College of the Environment
> University of Washington
> dmck at uw.edu
> 
> 
>         [[alternative HTML version deleted]]
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Fri Oct  3 18:09:52 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 3 Oct 2014 12:09:52 -0400
Subject: [R]  a REALLY dumb question
Message-ID: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>

So please be prepared...

Ok.  I made a copy of the arima.r function called earima.r to put in some
print statements.  Fair enough.

Now when I run earima, the .Call statements call find the C subroutines.

I know that this should be a really simple fix, but I don't know how.  I do
know that the original arima function is in stats.

Sorry for the trouble.



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Fri Oct  3 18:18:18 2014
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 03 Oct 2014 11:18:18 -0500
Subject: [R] c() and dates
In-Reply-To: <A0A0BC27-564C-4ECC-86AF-71C72BA75C30@gmail.com>
References: <58e5f6$iv9gkm@ironport9.mayo.edu>
	<A0A0BC27-564C-4ECC-86AF-71C72BA75C30@gmail.com>
Message-ID: <58e5f6$ivcro9@ironport9.mayo.edu>

Well duh -- type "c.Date" at the command prompt to see what is going on.  I suspected I 
was being dense.

Now that the behaior is clear can I follow up on David W's comment that redfining the 
c.Date function as

     structure(c(unlist(lapply(list(...), as.Date))), class = "Date")

allows for a more intellegent response, since it allows all of the as.Date machinery to be 
brought into play.

It seems like a good idea in general.  Would it be a good exchange between the current 
"nonsense result, no warning" and the new error messages that would arise, e.g., from 
c(as.Date("2000/10/1"), factor('b')).



Terry T.

On 10/03/2014 09:52 AM, peter dalgaard wrote:
> S3 only has single dispatch, so in one case it dispatches to c.Date and in the other to c.POSIXct, both of those return an object of the corresponding class. In both cases, the arguments pass through
>
> c(unlist(lapply(list(...), unclass)))
>
> which doesn't look at the class at all. Since Date objects unclass to days and POSIXct to seconds, something is bound to go wrong.


From murdoch.duncan at gmail.com  Fri Oct  3 18:18:15 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 3 Oct 2014 12:18:15 -0400
Subject: [R] a REALLY dumb question
In-Reply-To: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
References: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
Message-ID: <542ECC47.9090602@gmail.com>

On 03/10/2014 12:09 PM, Erin Hodgess wrote:
> So please be prepared...
>
> Ok.  I made a copy of the arima.r function called earima.r to put in some
> print statements.  Fair enough.
>
> Now when I run earima, the .Call statements call find the C subroutines.
>
> I know that this should be a really simple fix, but I don't know how.  I do
> know that the original arima function is in stats.
>
> Sorry for the trouble.
>
>
>
If you run

environment(arima) <- environment(stats::arima)

it should work (assuming your function is still called arima).  The 
problem is that statements like

  .Call(C_ARIMA_Like, y, mod, 0L, TRUE)

refer to variables like C_ARIMA_Like, which are local to the package 
environment of stats.  They aren't exported, so your function (which 
presumably has a different environment) can't see them.

Duncan Murdoch


From erinm.hodgess at gmail.com  Fri Oct  3 19:12:18 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 3 Oct 2014 13:12:18 -0400
Subject: [R] a REALLY dumb question
In-Reply-To: <542ECC47.9090602@gmail.com>
References: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
	<542ECC47.9090602@gmail.com>
Message-ID: <CACxE24neExqUSHOWu5ePkgvNyPh_bh9sk=aU8hd9Pje9Rgn4OA@mail.gmail.com>

thank you!!


On Fri, Oct 3, 2014 at 12:18 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 03/10/2014 12:09 PM, Erin Hodgess wrote:
>
>> So please be prepared...
>>
>> Ok.  I made a copy of the arima.r function called earima.r to put in some
>> print statements.  Fair enough.
>>
>> Now when I run earima, the .Call statements call find the C subroutines.
>>
>> I know that this should be a really simple fix, but I don't know how.  I
>> do
>> know that the original arima function is in stats.
>>
>> Sorry for the trouble.
>>
>>
>>
>>  If you run
>
> environment(arima) <- environment(stats::arima)
>
> it should work (assuming your function is still called arima).  The
> problem is that statements like
>
>  .Call(C_ARIMA_Like, y, mod, 0L, TRUE)
>
> refer to variables like C_ARIMA_Like, which are local to the package
> environment of stats.  They aren't exported, so your function (which
> presumably has a different environment) can't see them.
>
> Duncan Murdoch
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From nodecorum at yahoo.com  Fri Oct  3 19:39:31 2014
From: nodecorum at yahoo.com (Andrew)
Date: Fri, 3 Oct 2014 10:39:31 -0700
Subject: [R] Workaround for RODBC asymmetric numeric data treatment
Message-ID: <1412357971.5704.YahooMailNeo@web161604.mail.bf1.yahoo.com>

Note: I did raise report the issue below to   r-sig-db at r-project.org, but didn't see any reply.  
I'm hoping somebody on r-help can help me devise a workaround for a problem I'm having 
with RODB:


I use RODBC to read and write a good deal of data to SQL Server and I'd be extremely grateful 
if anyone has found a workaround in order to be able to write dataframes to SQL Server
using RODBC dynamically created SQL tables and read the data from those tables, or indeed any 
arbitrary SQL Server table with "float" datatypes and end up with numeric columns instead of "factor" columns
in a dataframe in R.


I have found that when RODBC creates a Microsoft SQL Server data table from a dataFrame using sqlSave(....append=FALSE), 
RODBC uses the SQL "float" datatype to store R numeric data in a dynamically-created table on the server.

However, when RODBC reads any SQL Server "float" datatype from SQL Server via sqlQuery it interprets float columns as "factor" data.


I created a standalone sample below to demonstrate the odd behavior of RODBC that I hope to overcome:

# Assuming the reader has access to SQL Server the code below is self-contained and repeatable

# I believe it demonstrates unexpected and undesirable behavior in RODBC 


library(RODBC)
library(fPortfolio)
library(timeSeries)
head(SWX.RET$SBI)
str(SWX.RET$SBI)
mydata<-as.timeSeries(SWX.RET)
head(mydata)

df2beSavedByRODBC =as.data.frame(mydata)

str(df2beSavedByRODBC)

# shows the numeric data in the dataframe
# 
# data.frame':  1916 obs. of  6 variables:
#   $ SBI : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
# $ SPI : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
...


# Let's save the dataframe to SQL Server:
  
dbconn<-odbcDriverConnect(connection="Driver={SQL Server};server=_YOURSERVERNAMEHER_;database=_YOURDBNAME_;Trusted_Connection=True;");
sqlSave(channel=dbconn,dat=df2beSavedByRODBC,tablename="testTable",rownames=TRUE,append=FALSE,addPK=FALSE,verbose=FALSE)

# The sqlSave above works very well.  The new table is create in the Microsoft SQL database and the ddl for the table is:
# 
#     [dbo].[testTable](
#       [rownames] [varchar](255) NULL,
#     [SBI] [float] NULL,
#     [SPI] [float] NULL,
#     [SII] [float] NULL,
#     [LP25] [float] NULL,
#     [LP40] [float] NULL,
#     [LP60] [float] NULL
#     )


# The numeric values from the dataframe are stored as float (i.e. numeric) in SQL server -- good!

## now let's read back the data RODBC stored in SQL server from a SQL table RODBC created:
  
  
sqlString = "select * from testTable"


dataFrameFromDB = sqlQuery(dbconn,sqlString,errors=TRUE);

str(dataFrameFromDB)

# 
# 'data.frame':  1916 obs. of  7 variables:
# $ rownames: Factor w/ 1916 levels "2000-01-04","2000-01-05",..: 1 2 3 4 5 6 7 8 9 10 ...
# $ SBI     : Factor w/ 1742 levels "-0.00041080415489958",..: 349 42 161 1418 828 48 49 1419 1024 135 ...
# $ SPI     : Factor w/ 1848 levels "-0.0020169904194276",..: 445 48 970 883 1187 377 1157 1065 951 1840 ...
...

#*********   RODBC wrote numeric data to SQL Server as float, but read the same data back as Factor !  ********


I could use some help to create a robust and flexible workaround for RODBC's asymmetric treatment of numeric data.
If there were some way to force RODBC sqlQuery to interpret all SQL Server float datatypes as numeric my problem would be solved.
FWIW:  RODBC does interpret the SQL Server "real" datatype as numeric.


Thank you,

Andrew

	[[alternative HTML version deleted]]


From evl.legrand at gmail.com  Fri Oct  3 15:32:02 2014
From: evl.legrand at gmail.com (Eve Legrand)
Date: Fri, 3 Oct 2014 09:32:02 -0400
Subject: [R] Logistic Regression & Results per Condition
Message-ID: <CA+ddqNVV9xGCp6PgwPGAY6viHB5-y1Xmpb1qGwWfHQ_jDG2SUw@mail.gmail.com>

Hi everyone!
   I conducted a study for which I conducted logistic regressions (and it
works), but now I'd like to have the results per condition, and I failed to
discover how to have them. I explain myself:
   In conduted a study in which participants can realize one behavior
(coded "1" if realized) or another one (coded "0" if realized") (and errors
are coded "2"). This DV is called "Rep2". I also had one IV called
"TypeInt". This IV has two modalities: participants can be in the
"OnlyIntention" condition or in the "ImplementationIntention" condition. We
registered participants behaviors 64 times (we had 64 repeated measures),
this variable is called "NumEssai", and 40 participants participated (this
variable is called "Sujet").
   So I realized logistic regression for panel data (so with a cluster
correction) on this variables thanks to the lrm and robcov functions, and I
obtained results which are (normally) the good ones. So I obtained the
interactions between all these variables. Here is my script:

<b>library(rms)
PunSon <- read.csv2("C:/Users/Eve/Desktop/Stats/Stats.csv")

NumEssai <- PunSon$NumEssai
Rep2 <- PunSon$Rep2
TypeInt <- PunSon$TypeInt
Sujet <- PunSon$Sujet

f <- lrm(Rep2 ~ NumEssai * TypeInt, data = PunSon[PunSon$Rep2 != 2, ],
x=TRUE, y=TRUE)
g <- robcov(f, cluster=PunSon[PunSon$Rep2 != 2, ]$Sujet)
g</b>

  But now, I'd like to have the results per condition (for example, have
the results in the "onlyintention" condition). I tried some things like
using the "factor" function (I join the script I writed below), but it
doesn't work... Does someone knows how to have results per condition?

<b>library(rms)
PunSon <- read.csv2("C:/Users/Eve/Desktop/Stats/Stats.csv")

NumEssai <- PunSon$NumEssai
Rep2 <- PunSon$Rep2
TypeInt <- factor(PunSon$TypeInt)
Sujet <- PunSon$Sujet

f <- lrm(Rep2 ~ NumEssai * TypeInt, data = PunSon[PunSon$Rep2 != 2, ],
x=TRUE, y=TRUE)
g <- robcov(f, cluster=PunSon[PunSon$Rep2 != 2, ]$Sujet)
g</b>

Thanks by advance for any help!
Eve

	[[alternative HTML version deleted]]


From evan.kransdorf at gmail.com  Fri Oct  3 17:29:32 2014
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Fri, 3 Oct 2014 08:29:32 -0700
Subject: [R] Help with PredicABEL
Message-ID: <CAKZWb7fVKV7bwZ8yTJDEONcHv+FMMeKfvW5gJP_4OOnqO+67eQ@mail.gmail.com>

I am using PredictABEL to do reclassification.  When I use it to compare
two models (+/- a new marker), I get some output without a p-valve.  Anyone
know why this might be?

#BEGIN R OUTPUT
 NRI(Categorical) [95% CI]: 0.0206 [ 0.0081 - 0.0332 ] ; p-value: 0.00129
 NRI(Continuous) [95% CI]: 0.1781 [ 0.1418 - 0.2144 ] ; p-value: 0
 IDI [95% CI]: 0.009 [ 0.0074 - 0.0107 ] ; p-value: 0

	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Fri Oct  3 20:00:14 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 3 Oct 2014 11:00:14 -0700
Subject: [R] Help with PredicABEL
In-Reply-To: <CAKZWb7fVKV7bwZ8yTJDEONcHv+FMMeKfvW5gJP_4OOnqO+67eQ@mail.gmail.com>
References: <CAKZWb7fVKV7bwZ8yTJDEONcHv+FMMeKfvW5gJP_4OOnqO+67eQ@mail.gmail.com>
Message-ID: <CA+hbrhURDz_jj+2OG79eEAFSS_-yF8T2tqyVUSaHQuayFS7LCw@mail.gmail.com>

You are getting a p-value, namely p=0. It's just that, when taken
literally, the p-values are wrong.

I'm not familiar with predictABEL, but my guess is that the p-value is
below 2e-16 or some such cutoff and gets printed as zero (the means
seem to be about 10 standard deviations away from zero, which would
give a p-value of 1e-24, plus or minus a few orders of magnitude).

You may want to ask the maintainer of predictABEL what the lowest
printed p-value is (say 1e-15), then change the p=0 values to "less
than 1e-15".


Peter

On Fri, Oct 3, 2014 at 8:29 AM, Evan Kransdorf <evan.kransdorf at gmail.com> wrote:
> I am using PredictABEL to do reclassification.  When I use it to compare
> two models (+/- a new marker), I get some output without a p-valve.  Anyone
> know why this might be?
>
> #BEGIN R OUTPUT
>  NRI(Categorical) [95% CI]: 0.0206 [ 0.0081 - 0.0332 ] ; p-value: 0.00129
>  NRI(Continuous) [95% CI]: 0.1781 [ 0.1418 - 0.2144 ] ; p-value: 0
>  IDI [95% CI]: 0.009 [ 0.0074 - 0.0107 ] ; p-value: 0
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From roger.bos at rothschild.com  Fri Oct  3 20:04:30 2014
From: roger.bos at rothschild.com (Bos, Roger)
Date: Fri, 3 Oct 2014 18:04:30 +0000
Subject: [R] Workaround for RODBC asymmetric numeric data treatment
In-Reply-To: <1412357971.5704.YahooMailNeo@web161604.mail.bf1.yahoo.com>
References: <1412357971.5704.YahooMailNeo@web161604.mail.bf1.yahoo.com>
Message-ID: <0765308CD028654885F30322557308D81ECF532F@NYCSM0208.rth.ad.rothschild.com>

Andrew,

I ran your code using my SQL Server database and it seems like it worked okay for me, in that I end up with "num" data types when I read the data back in.  So it may be a setting on your database.  I don't claim to know which one.

BTW, I had to install 5 or 6 separate packages to get fPortfolio to load.  Anyone know why install.packages("fPortfolio",repos="http://R-Forge.R-project.org") can't install all the dependencies automatically?

Thanks,

Roger


> library(RODBC)

> library(fPortfolio)
Loading required package: timeSeries

Attaching package: ?timeSeries?

The following object is masked from ?package:zoo?:

    time<-

Loading required package: fBasics


Rmetrics Package fBasics
Analysing Markets and calculating Basic Statistics
Copyright (C) 2005-2014 Rmetrics Association Zurich
Educational Software for Financial Engineering and Computational Science
Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
https://www.rmetrics.org --- Mail to: info at rmetrics.org

Attaching package: ?fBasics?

The following object is masked from ?package:TTR?:

    volatility

Loading required package: fAssets
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
  there is no package called ?DEoptimR?
Error: package ?fAssets? could not be loaded
> source(.trPaths[5], echo=TRUE, max.deparse.length=150)

> library(RODBC)

> library(fPortfolio)
Loading required package: fAssets
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called ?sn?
Error: package ?fAssets? could not be loaded
> library(RODBC)
> library(fPortfolio)
Loading required package: fAssets
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called ?sn?
Error: package ?fAssets? could not be loaded
> library(timeSeries)
> head(SWX.RET$SBI)
Error in head(SWX.RET$SBI) :
  error in evaluating the argument 'x' in selecting a method for function 'head': Error: object 'SWX.RET' not found
> library(fPortfolio)
Loading required package: fAssets
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called ?sn?
Error: package ?fAssets? could not be loaded
> library(fPortfolio)
Loading required package: fAssets


Rmetrics Package fAssets
Analysing and Modeling Financial Assets
Copyright (C) 2005-2014 Rmetrics Association Zurich
Educational Software for Financial Engineering and Computational Science
Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
https://www.rmetrics.org --- Mail to: info at rmetrics.org
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called ?slam?
Error: package or namespace load failed for ?fPortfolio?
> library(fPortfolio)
Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")

Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called ?kernlab?
Error: package or namespace load failed for ?fPortfolio?
> library(fPortfolio)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
  there is no package called ?rneos?
Error: package or namespace load failed for ?fPortfolio?
> library(fPortfolio)


Rmetrics Package fPortfolio
Portfolio Optimization
Copyright (C) 2005-2014 Rmetrics Association Zurich
Educational Software for Financial Engineering and Computational Science
Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
https://www.rmetrics.org --- Mail to: info at rmetrics.org
> head(SWX.RET$SBI)
[1] -0.0020881194 -0.0001045205 -0.0013597617  0.0004185852  0.0000000000 -0.0010467917
> str(SWX.RET$SBI)
 num [1:1916] -0.002088 -0.000105 -0.00136 0.000419 0 ...
> source(.trPaths[5], echo=TRUE, max.deparse.length=150)

> mydata<-as.timeSeries(SWX.RET)

> head(mydata)
GMT
                     SBI          SPI            SII         LP25         LP40         LP60
2000-01-04 -0.0020881194 -0.034390059  0.00001367381 -0.011994298 -0.018013035 -0.026155259
2000-01-05 -0.0001045205 -0.010408271 -0.00495530624 -0.003657054 -0.005837489 -0.009011403
2000-01-06 -0.0013597617  0.012119128  0.00381289851 -0.001323897 -0.001644737 -0.002395959
2000-01-07  0.0004185852  0.022461656 -0.00061621046  0.007714991  0.011660151  0.017062613
2000-01-10  0.0000000000  0.002107677  0.00238057889  0.003029081  0.004565523  0.006948020
2000-01-11 -0.0010467917 -0.002773654 -0.00029384531 -0.002422531 -0.003142903 -0.004183466
> source(.trPaths[5], echo=TRUE, max.deparse.length=150)

> df2beSavedByRODBC =as.data.frame(mydata)

> str(df2beSavedByRODBC)
'data.frame':   1916 obs. of  6 variables:
 $ SBI : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
 $ SPI : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
 $ SII : num  0.0000137 -0.0049553 0.0038129 -0.0006162 0.0023806 ...
 $ LP25: num  -0.01199 -0.00366 -0.00132 0.00771 0.00303 ...
 $ LP40: num  -0.01801 -0.00584 -0.00164 0.01166 0.00457 ...
 $ LP60: num  -0.02616 -0.00901 -0.0024 0.01706 0.00695 ...
> sqlSave(xf, dat=df2beSavedByRODBC,tablename="testTable",rownames=TRUE,append=FALSE,addPK=FALSE,verbose=FALSE)
> sqlString = "select * from testTable"
> dataFrameFromDB = sqlQuery(xf, sqlString,errors=TRUE);
> str(dataFrameFromDB)
'data.frame':   1916 obs. of  7 variables:
 $ rownames: chr  "2000-01-04" "2000-01-05" "2000-01-06" "2000-01-07" ...
 $ SBI     : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
 $ SPI     : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
 $ SII     : num  0.0000137 -0.0049553 0.0038129 -0.0006162 0.0023806 ...
 $ LP25    : num  -0.01199 -0.00366 -0.00132 0.00771 0.00303 ...
 $ LP40    : num  -0.01801 -0.00584 -0.00164 0.01166 0.00457 ...
 $ LP60    : num  -0.02616 -0.00901 -0.0024 0.01706 0.00695 ...




***************************************************************
This message and any attachments are for the named person's use only.
This message may contain confidential, proprietary or legally privileged
information. No right to confidential or privileged treatment
of this message is waived or lost by an error in transmission.
If you have received this message in error, please immediately
notify the sender by e-mail, delete the message, any attachments and all
copies from your system and destroy any hard copies. You must
not, directly or indirectly, use, disclose, distribute,
print or copy any part of this message or any attachments if you are not
the intended recipient.


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Andrew
Sent: Friday, October 03, 2014 1:40 PM
To: r-help at r-project.org
Subject: [R] Workaround for RODBC asymmetric numeric data treatment

Note: I did raise report the issue below to   r-sig-db at r-project.org, but didn't see any reply.
I'm hoping somebody on r-help can help me devise a workaround for a problem I'm having with RODB:


I use RODBC to read and write a good deal of data to SQL Server and I'd be extremely grateful
if anyone has found a workaround in order to be able to write dataframes to SQL Server
using RODBC dynamically created SQL tables and read the data from those tables, or indeed any
arbitrary SQL Server table with "float" datatypes and end up with numeric columns instead of "factor" columns
in a dataframe in R.


I have found that when RODBC creates a Microsoft SQL Server data table from a dataFrame using sqlSave(....append=FALSE),
RODBC uses the SQL "float" datatype to store R numeric data in a dynamically-created table on the server.

However, when RODBC reads any SQL Server "float" datatype from SQL Server via sqlQuery it interprets float columns as "factor" data.


I created a standalone sample below to demonstrate the odd behavior of RODBC that I hope to overcome:

# Assuming the reader has access to SQL Server the code below is self-contained and repeatable

# I believe it demonstrates unexpected and undesirable behavior in RODBC


library(RODBC)
library(fPortfolio)
library(timeSeries)
head(SWX.RET$SBI)
str(SWX.RET$SBI)
mydata<-as.timeSeries(SWX.RET)
head(mydata)

df2beSavedByRODBC =as.data.frame(mydata)

str(df2beSavedByRODBC)

# shows the numeric data in the dataframe
#
# data.frame':  1916 obs. of  6 variables:
#   $ SBI : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
# $ SPI : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
...


# Let's save the dataframe to SQL Server:

dbconn<-odbcDriverConnect(connection="Driver={SQL Server};server=_YOURSERVERNAMEHER_;database=_YOURDBNAME_;Trusted_Connection=True;");
sqlSave(channel=dbconn,dat=df2beSavedByRODBC,tablename="testTable",rownames=TRUE,append=FALSE,addPK=FALSE,verbose=FALSE)

# The sqlSave above works very well.  The new table is create in the Microsoft SQL database and the ddl for the table is:
#
#     [dbo].[testTable](
#       [rownames] [varchar](255) NULL,
#     [SBI] [float] NULL,
#     [SPI] [float] NULL,
#     [SII] [float] NULL,
#     [LP25] [float] NULL,
#     [LP40] [float] NULL,
#     [LP60] [float] NULL
#     )


# The numeric values from the dataframe are stored as float (i.e. numeric) in SQL server -- good!

## now let's read back the data RODBC stored in SQL server from a SQL table RODBC created:


sqlString = "select * from testTable"


dataFrameFromDB = sqlQuery(dbconn,sqlString,errors=TRUE);

str(dataFrameFromDB)

#
# 'data.frame':  1916 obs. of  7 variables:
# $ rownames: Factor w/ 1916 levels "2000-01-04","2000-01-05",..: 1 2 3 4 5 6 7 8 9 10 ...
# $ SBI     : Factor w/ 1742 levels "-0.00041080415489958",..: 349 42 161 1418 828 48 49 1419 1024 135 ...
# $ SPI     : Factor w/ 1848 levels "-0.0020169904194276",..: 445 48 970 883 1187 377 1157 1065 951 1840 ...
...

#*********   RODBC wrote numeric data to SQL Server as float, but read the same data back as Factor !  ********


I could use some help to create a robust and flexible workaround for RODBC's asymmetric treatment of numeric data.
If there were some way to force RODBC sqlQuery to interpret all SQL Server float datatypes as numeric my problem would be solved.
FWIW:  RODBC does interpret the SQL Server "real" datatype as numeric.


Thank you,

Andrew

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From stephen at prollenium.com  Fri Oct  3 19:51:16 2014
From: stephen at prollenium.com (Stephen Kennedy)
Date: Fri, 3 Oct 2014 13:51:16 -0400
Subject: [R] power.t.test threading on 'power'
In-Reply-To: <798EA142-0A8F-4A4D-B596-03E448DBE65A@gmail.com>
References: <9C8F5086-03EB-4270-B46F-AF612D7FC14A@Prollenium.com>
	<798EA142-0A8F-4A4D-B596-03E448DBE65A@gmail.com>
Message-ID: <27E98D39-3C40-4BA7-B7C6-BAB980BE4936@Prollenium.com>

Dear Professor Dalgard,

I wondered if I might ask a general question on ?power?.  Please feel free to ignore.

For ?non-inferiority? clinical trials:

H0: m1 - m2 ?  -M

Ha: m1 - m2 > -M

But when calculations are done (normal, t, or non-central t ? still learning what this is), 

Ha: m1 - m2 = 0

is assumed (for power, n, ?) .  

Why not average (integrate numerically) the results from -M to infinity and keep the original alternative hypothesis?  

In fact, calculation of the Type I error is made assuming m1 - m2 = -M, which doesn?t seem strictly accurate either.

Best,

Steve


Stephen J. Kennedy, Ph.D.
Director, Research & Development
Prollenium Medical Technologies, Inc.
138 Industrial Parkway North
Aurora, ON
L4G 4C3 Canada
+1 (905) 508-1469 X223
Stephen at Prollenium.com

On Oct 1, 2014, at 6:46 PM, peter dalgaard <pdalgd at gmail.com> wrote:


On 01 Oct 2014, at 14:29 , Stephen Kennedy <stephen at prollenium.com> wrote:

> Simple question.  A vector of ?number of observations? can be input to power.t.test, and a vector of ?power? s is output.  But, inputting a vector of powers generates an error.  Am I missing something?

Power.t.test was written for scalar arguments. If it happens to work with vector arguments, it is entirely coincidental. The essence of what you observe is that power is calculated by pt() which vectorizes, but n is calculated by numerical solution using uniroot() which does not vectorize. 

If you need a vectorized version, check out Vectorize().

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com










	[[alternative HTML version deleted]]


From 538280 at gmail.com  Fri Oct  3 21:03:02 2014
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 3 Oct 2014 13:03:02 -0600
Subject: [R] a REALLY dumb question
In-Reply-To: <CACxE24neExqUSHOWu5ePkgvNyPh_bh9sk=aU8hd9Pje9Rgn4OA@mail.gmail.com>
References: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
	<542ECC47.9090602@gmail.com>
	<CACxE24neExqUSHOWu5ePkgvNyPh_bh9sk=aU8hd9Pje9Rgn4OA@mail.gmail.com>
Message-ID: <CAFEqCdysnVAErGPcGakDZJjKSz509+cyqrqECcBggH3VDxDdEw@mail.gmail.com>

Instead of making a local copy and editing, you may consider using the
trace function with edit=TRUE, this allows you to insert things like
print statements, but takes care of the environment and other linkages
for you (and is easy to untrace when finished).

On Fri, Oct 3, 2014 at 11:12 AM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> thank you!!
>
>
> On Fri, Oct 3, 2014 at 12:18 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
>
>> On 03/10/2014 12:09 PM, Erin Hodgess wrote:
>>
>>> So please be prepared...
>>>
>>> Ok.  I made a copy of the arima.r function called earima.r to put in some
>>> print statements.  Fair enough.
>>>
>>> Now when I run earima, the .Call statements call find the C subroutines.
>>>
>>> I know that this should be a really simple fix, but I don't know how.  I
>>> do
>>> know that the original arima function is in stats.
>>>
>>> Sorry for the trouble.
>>>
>>>
>>>
>>>  If you run
>>
>> environment(arima) <- environment(stats::arima)
>>
>> it should work (assuming your function is still called arima).  The
>> problem is that statements like
>>
>>  .Call(C_ARIMA_Like, y, mod, 0L, TRUE)
>>
>> refer to variables like C_ARIMA_Like, which are local to the package
>> environment of stats.  They aren't exported, so your function (which
>> presumably has a different environment) can't see them.
>>
>> Duncan Murdoch
>>
>
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From ruipbarradas at sapo.pt  Fri Oct  3 21:18:54 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 03 Oct 2014 20:18:54 +0100
Subject: [R] Workaround for RODBC asymmetric numeric data treatment
In-Reply-To: <0765308CD028654885F30322557308D81ECF532F@NYCSM0208.rth.ad.rothschild.com>
References: <1412357971.5704.YahooMailNeo@web161604.mail.bf1.yahoo.com>
	<0765308CD028654885F30322557308D81ECF532F@NYCSM0208.rth.ad.rothschild.com>
Message-ID: <542EF69E.5010702@sapo.pt>

Hello,

Inline

Em 03-10-2014 19:04, Bos, Roger escreveu:
> Andrew,
>
> I ran your code using my SQL Server database and it seems like it worked okay for me, in that I end up with "num" data types when I read the data back in.  So it may be a setting on your database.  I don't claim to know which one.
>
> BTW, I had to install 5 or 6 separate packages to get fPortfolio to load.  Anyone know why install.packages("fPortfolio",repos="http://R-Forge.R-project.org") can't install all the dependencies automatically?

Try

install.packages(..., dependencies = TRUE)

Hope this helps,

Rui Barradas
>
> Thanks,
>
> Roger
>
>
>> library(RODBC)
>
>> library(fPortfolio)
> Loading required package: timeSeries
>
> Attaching package: ?timeSeries?
>
> The following object is masked from ?package:zoo?:
>
>      time<-
>
> Loading required package: fBasics
>
>
> Rmetrics Package fBasics
> Analysing Markets and calculating Basic Statistics
> Copyright (C) 2005-2014 Rmetrics Association Zurich
> Educational Software for Financial Engineering and Computational Science
> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> https://www.rmetrics.org --- Mail to: info at rmetrics.org
>
> Attaching package: ?fBasics?
>
> The following object is masked from ?package:TTR?:
>
>      volatility
>
> Loading required package: fAssets
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
>    there is no package called ?DEoptimR?
> Error: package ?fAssets? could not be loaded
>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>
>> library(RODBC)
>
>> library(fPortfolio)
> Loading required package: fAssets
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>    there is no package called ?sn?
> Error: package ?fAssets? could not be loaded
>> library(RODBC)
>> library(fPortfolio)
> Loading required package: fAssets
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>    there is no package called ?sn?
> Error: package ?fAssets? could not be loaded
>> library(timeSeries)
>> head(SWX.RET$SBI)
> Error in head(SWX.RET$SBI) :
>    error in evaluating the argument 'x' in selecting a method for function 'head': Error: object 'SWX.RET' not found
>> library(fPortfolio)
> Loading required package: fAssets
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>    there is no package called ?sn?
> Error: package ?fAssets? could not be loaded
>> library(fPortfolio)
> Loading required package: fAssets
>
>
> Rmetrics Package fAssets
> Analysing and Modeling Financial Assets
> Copyright (C) 2005-2014 Rmetrics Association Zurich
> Educational Software for Financial Engineering and Computational Science
> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> https://www.rmetrics.org --- Mail to: info at rmetrics.org
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>    there is no package called ?slam?
> Error: package or namespace load failed for ?fPortfolio?
>> library(fPortfolio)
> Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")
>
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>    there is no package called ?kernlab?
> Error: package or namespace load failed for ?fPortfolio?
>> library(fPortfolio)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>    there is no package called ?rneos?
> Error: package or namespace load failed for ?fPortfolio?
>> library(fPortfolio)
>
>
> Rmetrics Package fPortfolio
> Portfolio Optimization
> Copyright (C) 2005-2014 Rmetrics Association Zurich
> Educational Software for Financial Engineering and Computational Science
> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
> https://www.rmetrics.org --- Mail to: info at rmetrics.org
>> head(SWX.RET$SBI)
> [1] -0.0020881194 -0.0001045205 -0.0013597617  0.0004185852  0.0000000000 -0.0010467917
>> str(SWX.RET$SBI)
>   num [1:1916] -0.002088 -0.000105 -0.00136 0.000419 0 ...
>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>
>> mydata<-as.timeSeries(SWX.RET)
>
>> head(mydata)
> GMT
>                       SBI          SPI            SII         LP25         LP40         LP60
> 2000-01-04 -0.0020881194 -0.034390059  0.00001367381 -0.011994298 -0.018013035 -0.026155259
> 2000-01-05 -0.0001045205 -0.010408271 -0.00495530624 -0.003657054 -0.005837489 -0.009011403
> 2000-01-06 -0.0013597617  0.012119128  0.00381289851 -0.001323897 -0.001644737 -0.002395959
> 2000-01-07  0.0004185852  0.022461656 -0.00061621046  0.007714991  0.011660151  0.017062613
> 2000-01-10  0.0000000000  0.002107677  0.00238057889  0.003029081  0.004565523  0.006948020
> 2000-01-11 -0.0010467917 -0.002773654 -0.00029384531 -0.002422531 -0.003142903 -0.004183466
>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>
>> df2beSavedByRODBC =as.data.frame(mydata)
>
>> str(df2beSavedByRODBC)
> 'data.frame':   1916 obs. of  6 variables:
>   $ SBI : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
>   $ SPI : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
>   $ SII : num  0.0000137 -0.0049553 0.0038129 -0.0006162 0.0023806 ...
>   $ LP25: num  -0.01199 -0.00366 -0.00132 0.00771 0.00303 ...
>   $ LP40: num  -0.01801 -0.00584 -0.00164 0.01166 0.00457 ...
>   $ LP60: num  -0.02616 -0.00901 -0.0024 0.01706 0.00695 ...
>> sqlSave(xf, dat=df2beSavedByRODBC,tablename="testTable",rownames=TRUE,append=FALSE,addPK=FALSE,verbose=FALSE)
>> sqlString = "select * from testTable"
>> dataFrameFromDB = sqlQuery(xf, sqlString,errors=TRUE);
>> str(dataFrameFromDB)
> 'data.frame':   1916 obs. of  7 variables:
>   $ rownames: chr  "2000-01-04" "2000-01-05" "2000-01-06" "2000-01-07" ...
>   $ SBI     : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
>   $ SPI     : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
>   $ SII     : num  0.0000137 -0.0049553 0.0038129 -0.0006162 0.0023806 ...
>   $ LP25    : num  -0.01199 -0.00366 -0.00132 0.00771 0.00303 ...
>   $ LP40    : num  -0.01801 -0.00584 -0.00164 0.01166 0.00457 ...
>   $ LP60    : num  -0.02616 -0.00901 -0.0024 0.01706 0.00695 ...
>
>
>
>
> ***************************************************************
> This message and any attachments are for the named person's use only.
> This message may contain confidential, proprietary or legally privileged
> information. No right to confidential or privileged treatment
> of this message is waived or lost by an error in transmission.
> If you have received this message in error, please immediately
> notify the sender by e-mail, delete the message, any attachments and all
> copies from your system and destroy any hard copies. You must
> not, directly or indirectly, use, disclose, distribute,
> print or copy any part of this message or any attachments if you are not
> the intended recipient.
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Andrew
> Sent: Friday, October 03, 2014 1:40 PM
> To: r-help at r-project.org
> Subject: [R] Workaround for RODBC asymmetric numeric data treatment
>
> Note: I did raise report the issue below to   r-sig-db at r-project.org, but didn't see any reply.
> I'm hoping somebody on r-help can help me devise a workaround for a problem I'm having with RODB:
>
>
> I use RODBC to read and write a good deal of data to SQL Server and I'd be extremely grateful
> if anyone has found a workaround in order to be able to write dataframes to SQL Server
> using RODBC dynamically created SQL tables and read the data from those tables, or indeed any
> arbitrary SQL Server table with "float" datatypes and end up with numeric columns instead of "factor" columns
> in a dataframe in R.
>
>
> I have found that when RODBC creates a Microsoft SQL Server data table from a dataFrame using sqlSave(....append=FALSE),
> RODBC uses the SQL "float" datatype to store R numeric data in a dynamically-created table on the server.
>
> However, when RODBC reads any SQL Server "float" datatype from SQL Server via sqlQuery it interprets float columns as "factor" data.
>
>
> I created a standalone sample below to demonstrate the odd behavior of RODBC that I hope to overcome:
>
> # Assuming the reader has access to SQL Server the code below is self-contained and repeatable
>
> # I believe it demonstrates unexpected and undesirable behavior in RODBC
>
>
> library(RODBC)
> library(fPortfolio)
> library(timeSeries)
> head(SWX.RET$SBI)
> str(SWX.RET$SBI)
> mydata<-as.timeSeries(SWX.RET)
> head(mydata)
>
> df2beSavedByRODBC =as.data.frame(mydata)
>
> str(df2beSavedByRODBC)
>
> # shows the numeric data in the dataframe
> #
> # data.frame':  1916 obs. of  6 variables:
> #   $ SBI : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
> # $ SPI : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
> ...
>
>
> # Let's save the dataframe to SQL Server:
>
> dbconn<-odbcDriverConnect(connection="Driver={SQL Server};server=_YOURSERVERNAMEHER_;database=_YOURDBNAME_;Trusted_Connection=True;");
> sqlSave(channel=dbconn,dat=df2beSavedByRODBC,tablename="testTable",rownames=TRUE,append=FALSE,addPK=FALSE,verbose=FALSE)
>
> # The sqlSave above works very well.  The new table is create in the Microsoft SQL database and the ddl for the table is:
> #
> #     [dbo].[testTable](
> #       [rownames] [varchar](255) NULL,
> #     [SBI] [float] NULL,
> #     [SPI] [float] NULL,
> #     [SII] [float] NULL,
> #     [LP25] [float] NULL,
> #     [LP40] [float] NULL,
> #     [LP60] [float] NULL
> #     )
>
>
> # The numeric values from the dataframe are stored as float (i.e. numeric) in SQL server -- good!
>
> ## now let's read back the data RODBC stored in SQL server from a SQL table RODBC created:
>
>
> sqlString = "select * from testTable"
>
>
> dataFrameFromDB = sqlQuery(dbconn,sqlString,errors=TRUE);
>
> str(dataFrameFromDB)
>
> #
> # 'data.frame':  1916 obs. of  7 variables:
> # $ rownames: Factor w/ 1916 levels "2000-01-04","2000-01-05",..: 1 2 3 4 5 6 7 8 9 10 ...
> # $ SBI     : Factor w/ 1742 levels "-0.00041080415489958",..: 349 42 161 1418 828 48 49 1419 1024 135 ...
> # $ SPI     : Factor w/ 1848 levels "-0.0020169904194276",..: 445 48 970 883 1187 377 1157 1065 951 1840 ...
> ...
>
> #*********   RODBC wrote numeric data to SQL Server as float, but read the same data back as Factor !  ********
>
>
> I could use some help to create a robust and flexible workaround for RODBC's asymmetric treatment of numeric data.
> If there were some way to force RODBC sqlQuery to interpret all SQL Server float datatypes as numeric my problem would be solved.
> FWIW:  RODBC does interpret the SQL Server "real" datatype as numeric.
>
>
> Thank you,
>
> Andrew
>
>          [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Fri Oct  3 22:02:13 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 03 Oct 2014 21:02:13 +0100
Subject: [R] Workaround for RODBC asymmetric numeric data treatment
In-Reply-To: <542EF69E.5010702@sapo.pt>
References: <1412357971.5704.YahooMailNeo@web161604.mail.bf1.yahoo.com>	<0765308CD028654885F30322557308D81ECF532F@NYCSM0208.rth.ad.rothschild.com>
	<542EF69E.5010702@sapo.pt>
Message-ID: <542F00C5.9030903@stats.ox.ac.uk>

On 03/10/2014 20:18, Rui Barradas wrote:
> Hello,
>
> Inline
>
> Em 03-10-2014 19:04, Bos, Roger escreveu:
>> Andrew,
>>
>> I ran your code using my SQL Server database and it seems like it
>> worked okay for me, in that I end up with "num" data types when I read
>> the data back in.  So it may be a setting on your database.  I don't
>> claim to know which one.
>>
>> BTW, I had to install 5 or 6 separate packages to get fPortfolio to
>> load.  Anyone know why
>> install.packages("fPortfolio",repos="http://R-Forge.R-project.org")
>> can't install all the dependencies automatically?
>
> Try
>
> install.packages(..., dependencies = TRUE)

You don't need that unless you want all the Suggests recursively.

The problem is that he set repos to just one repoository, rather than 
using setRepositories().  I guess some of the unstated dependencies are 
on CRAN not R-forge.  Let's see:

 > setRepositories(graphics=FALSE)
--- Please select repositories for use in this session ---


1: + CRAN
2:   BioC software
3:   BioC annotation
4:   BioC experiment
5:   BioC extra
6:   CRAN (extras)
7:   Omegahat
8:   R-Forge
9:   rforge.net

Enter one or more numbers separated by spaces, or an empty line to cancel
1: 1 8
 > install.packages('fPortfolio')
Installing package into ?/Users/ripley/R/Library?
(as ?lib? is unspecified)
also installing the dependencies ?cubature?, ?mvtnorm?, ?mnormt?, 
?numDeriv?, ?bitops?, ?stabledist?, ?gss?, ?fMultivar?, ?sn?, 
?DEoptimR?, ?truncnorm?, ?XMLRPC?, ?RCurl?, ?XML?, ?timeDate?, 
?timeSeries?, ?fBasics?, ?fAssets?, ?fCopulae?, ?robustbase?, ?Rglpk?, 
?slam?, ?Rsymphony?, ?Rsolnp?, ?kernlab?, ?quadprog?, ?rneos?
....

>
> Hope this helps,
>
> Rui Barradas
>>
>> Thanks,
>>
>> Roger
>>
>>
>>> library(RODBC)
>>
>>> library(fPortfolio)
>> Loading required package: timeSeries
>>
>> Attaching package: ?timeSeries?
>>
>> The following object is masked from ?package:zoo?:
>>
>>      time<-
>>
>> Loading required package: fBasics
>>
>>
>> Rmetrics Package fBasics
>> Analysing Markets and calculating Basic Statistics
>> Copyright (C) 2005-2014 Rmetrics Association Zurich
>> Educational Software for Financial Engineering and Computational Science
>> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
>> https://www.rmetrics.org --- Mail to: info at rmetrics.org
>>
>> Attaching package: ?fBasics?
>>
>> The following object is masked from ?package:TTR?:
>>
>>      volatility
>>
>> Loading required package: fAssets
>> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()),
>> versionCheck = vI[[j]]) :
>>    there is no package called ?DEoptimR?
>> Error: package ?fAssets? could not be loaded
>>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>>
>>> library(RODBC)
>>
>>> library(fPortfolio)
>> Loading required package: fAssets
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>> vI[[i]]) :
>>    there is no package called ?sn?
>> Error: package ?fAssets? could not be loaded
>>> library(RODBC)
>>> library(fPortfolio)
>> Loading required package: fAssets
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>> vI[[i]]) :
>>    there is no package called ?sn?
>> Error: package ?fAssets? could not be loaded
>>> library(timeSeries)
>>> head(SWX.RET$SBI)
>> Error in head(SWX.RET$SBI) :
>>    error in evaluating the argument 'x' in selecting a method for
>> function 'head': Error: object 'SWX.RET' not found
>>> library(fPortfolio)
>> Loading required package: fAssets
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>> vI[[i]]) :
>>    there is no package called ?sn?
>> Error: package ?fAssets? could not be loaded
>>> library(fPortfolio)
>> Loading required package: fAssets
>>
>>
>> Rmetrics Package fAssets
>> Analysing and Modeling Financial Assets
>> Copyright (C) 2005-2014 Rmetrics Association Zurich
>> Educational Software for Financial Engineering and Computational Science
>> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
>> https://www.rmetrics.org --- Mail to: info at rmetrics.org
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>> vI[[i]]) :
>>    there is no package called ?slam?
>> Error: package or namespace load failed for ?fPortfolio?
>>> library(fPortfolio)
>> Package Rsolnp (1.14) loaded.  To cite, see citation("Rsolnp")
>>
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>> vI[[i]]) :
>>    there is no package called ?kernlab?
>> Error: package or namespace load failed for ?fPortfolio?
>>> library(fPortfolio)
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>> vI[[i]]) :
>>    there is no package called ?rneos?
>> Error: package or namespace load failed for ?fPortfolio?
>>> library(fPortfolio)
>>
>>
>> Rmetrics Package fPortfolio
>> Portfolio Optimization
>> Copyright (C) 2005-2014 Rmetrics Association Zurich
>> Educational Software for Financial Engineering and Computational Science
>> Rmetrics is free software and comes with ABSOLUTELY NO WARRANTY.
>> https://www.rmetrics.org --- Mail to: info at rmetrics.org
>>> head(SWX.RET$SBI)
>> [1] -0.0020881194 -0.0001045205 -0.0013597617  0.0004185852
>> 0.0000000000 -0.0010467917
>>> str(SWX.RET$SBI)
>>   num [1:1916] -0.002088 -0.000105 -0.00136 0.000419 0 ...
>>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>>
>>> mydata<-as.timeSeries(SWX.RET)
>>
>>> head(mydata)
>> GMT
>>                       SBI          SPI            SII
>> LP25         LP40         LP60
>> 2000-01-04 -0.0020881194 -0.034390059  0.00001367381 -0.011994298
>> -0.018013035 -0.026155259
>> 2000-01-05 -0.0001045205 -0.010408271 -0.00495530624 -0.003657054
>> -0.005837489 -0.009011403
>> 2000-01-06 -0.0013597617  0.012119128  0.00381289851 -0.001323897
>> -0.001644737 -0.002395959
>> 2000-01-07  0.0004185852  0.022461656 -0.00061621046  0.007714991
>> 0.011660151  0.017062613
>> 2000-01-10  0.0000000000  0.002107677  0.00238057889  0.003029081
>> 0.004565523  0.006948020
>> 2000-01-11 -0.0010467917 -0.002773654 -0.00029384531 -0.002422531
>> -0.003142903 -0.004183466
>>> source(.trPaths[5], echo=TRUE, max.deparse.length=150)
>>
>>> df2beSavedByRODBC =as.data.frame(mydata)
>>
>>> str(df2beSavedByRODBC)
>> 'data.frame':   1916 obs. of  6 variables:
>>   $ SBI : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
>>   $ SPI : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
>>   $ SII : num  0.0000137 -0.0049553 0.0038129 -0.0006162 0.0023806 ...
>>   $ LP25: num  -0.01199 -0.00366 -0.00132 0.00771 0.00303 ...
>>   $ LP40: num  -0.01801 -0.00584 -0.00164 0.01166 0.00457 ...
>>   $ LP60: num  -0.02616 -0.00901 -0.0024 0.01706 0.00695 ...
>>> sqlSave(xf,
>>> dat=df2beSavedByRODBC,tablename="testTable",rownames=TRUE,append=FALSE,addPK=FALSE,verbose=FALSE)
>>>
>>> sqlString = "select * from testTable"
>>> dataFrameFromDB = sqlQuery(xf, sqlString,errors=TRUE);
>>> str(dataFrameFromDB)
>> 'data.frame':   1916 obs. of  7 variables:
>>   $ rownames: chr  "2000-01-04" "2000-01-05" "2000-01-06" "2000-01-07"
>> ...
>>   $ SBI     : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
>>   $ SPI     : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
>>   $ SII     : num  0.0000137 -0.0049553 0.0038129 -0.0006162 0.0023806
>> ...
>>   $ LP25    : num  -0.01199 -0.00366 -0.00132 0.00771 0.00303 ...
>>   $ LP40    : num  -0.01801 -0.00584 -0.00164 0.01166 0.00457 ...
>>   $ LP60    : num  -0.02616 -0.00901 -0.0024 0.01706 0.00695 ...
>>
>>
>>
>>
>> ***************************************************************
>> This message and any attachments are for the named person's use only.
>> This message may contain confidential, proprietary or legally privileged
>> information. No right to confidential or privileged treatment
>> of this message is waived or lost by an error in transmission.
>> If you have received this message in error, please immediately
>> notify the sender by e-mail, delete the message, any attachments and all
>> copies from your system and destroy any hard copies. You must
>> not, directly or indirectly, use, disclose, distribute,
>> print or copy any part of this message or any attachments if you are not
>> the intended recipient.
>>
>>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Andrew
>> Sent: Friday, October 03, 2014 1:40 PM
>> To: r-help at r-project.org
>> Subject: [R] Workaround for RODBC asymmetric numeric data treatment
>>
>> Note: I did raise report the issue below to   r-sig-db at r-project.org,
>> but didn't see any reply.
>> I'm hoping somebody on r-help can help me devise a workaround for a
>> problem I'm having with RODB:
>>
>>
>> I use RODBC to read and write a good deal of data to SQL Server and
>> I'd be extremely grateful
>> if anyone has found a workaround in order to be able to write
>> dataframes to SQL Server
>> using RODBC dynamically created SQL tables and read the data from
>> those tables, or indeed any
>> arbitrary SQL Server table with "float" datatypes and end up with
>> numeric columns instead of "factor" columns
>> in a dataframe in R.
>>
>>
>> I have found that when RODBC creates a Microsoft SQL Server data table
>> from a dataFrame using sqlSave(....append=FALSE),
>> RODBC uses the SQL "float" datatype to store R numeric data in a
>> dynamically-created table on the server.
>>
>> However, when RODBC reads any SQL Server "float" datatype from SQL
>> Server via sqlQuery it interprets float columns as "factor" data.
>>
>>
>> I created a standalone sample below to demonstrate the odd behavior of
>> RODBC that I hope to overcome:
>>
>> # Assuming the reader has access to SQL Server the code below is
>> self-contained and repeatable
>>
>> # I believe it demonstrates unexpected and undesirable behavior in RODBC
>>
>>
>> library(RODBC)
>> library(fPortfolio)
>> library(timeSeries)
>> head(SWX.RET$SBI)
>> str(SWX.RET$SBI)
>> mydata<-as.timeSeries(SWX.RET)
>> head(mydata)
>>
>> df2beSavedByRODBC =as.data.frame(mydata)
>>
>> str(df2beSavedByRODBC)
>>
>> # shows the numeric data in the dataframe
>> #
>> # data.frame':  1916 obs. of  6 variables:
>> #   $ SBI : num  -0.002088 -0.000105 -0.00136 0.000419 0 ...
>> # $ SPI : num  -0.03439 -0.01041 0.01212 0.02246 0.00211 ...
>> ...
>>
>>
>> # Let's save the dataframe to SQL Server:
>>
>> dbconn<-odbcDriverConnect(connection="Driver={SQL
>> Server};server=_YOURSERVERNAMEHER_;database=_YOURDBNAME_;Trusted_Connection=True;");
>>
>> sqlSave(channel=dbconn,dat=df2beSavedByRODBC,tablename="testTable",rownames=TRUE,append=FALSE,addPK=FALSE,verbose=FALSE)
>>
>>
>> # The sqlSave above works very well.  The new table is create in the
>> Microsoft SQL database and the ddl for the table is:
>> #
>> #     [dbo].[testTable](
>> #       [rownames] [varchar](255) NULL,
>> #     [SBI] [float] NULL,
>> #     [SPI] [float] NULL,
>> #     [SII] [float] NULL,
>> #     [LP25] [float] NULL,
>> #     [LP40] [float] NULL,
>> #     [LP60] [float] NULL
>> #     )
>>
>>
>> # The numeric values from the dataframe are stored as float (i.e.
>> numeric) in SQL server -- good!
>>
>> ## now let's read back the data RODBC stored in SQL server from a SQL
>> table RODBC created:
>>
>>
>> sqlString = "select * from testTable"
>>
>>
>> dataFrameFromDB = sqlQuery(dbconn,sqlString,errors=TRUE);
>>
>> str(dataFrameFromDB)
>>
>> #
>> # 'data.frame':  1916 obs. of  7 variables:
>> # $ rownames: Factor w/ 1916 levels "2000-01-04","2000-01-05",..: 1 2
>> 3 4 5 6 7 8 9 10 ...
>> # $ SBI     : Factor w/ 1742 levels "-0.00041080415489958",..: 349 42
>> 161 1418 828 48 49 1419 1024 135 ...
>> # $ SPI     : Factor w/ 1848 levels "-0.0020169904194276",..: 445 48
>> 970 883 1187 377 1157 1065 951 1840 ...
>> ...
>>
>> #*********   RODBC wrote numeric data to SQL Server as float, but read
>> the same data back as Factor !  ********
>>
>>
>> I could use some help to create a robust and flexible workaround for
>> RODBC's asymmetric treatment of numeric data.
>> If there were some way to force RODBC sqlQuery to interpret all SQL
>> Server float datatypes as numeric my problem would be solved.
>> FWIW:  RODBC does interpret the SQL Server "real" datatype as numeric.
>>
>>
>> Thank you,
>>
>> Andrew
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From erinm.hodgess at gmail.com  Fri Oct  3 22:15:09 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 3 Oct 2014 16:15:09 -0400
Subject: [R] a REALLY dumb question
In-Reply-To: <CAFEqCdysnVAErGPcGakDZJjKSz509+cyqrqECcBggH3VDxDdEw@mail.gmail.com>
References: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
	<542ECC47.9090602@gmail.com>
	<CACxE24neExqUSHOWu5ePkgvNyPh_bh9sk=aU8hd9Pje9Rgn4OA@mail.gmail.com>
	<CAFEqCdysnVAErGPcGakDZJjKSz509+cyqrqECcBggH3VDxDdEw@mail.gmail.com>
Message-ID: <CACxE24=PaA5oE4k3tz5V910m-H6Z=mom-j8xq3MEvVs1d-GUwg@mail.gmail.com>

Wow!  Never thought of trace! (obviously)

thanks!

On Fri, Oct 3, 2014 at 3:03 PM, Greg Snow <538280 at gmail.com> wrote:

> Instead of making a local copy and editing, you may consider using the
> trace function with edit=TRUE, this allows you to insert things like
> print statements, but takes care of the environment and other linkages
> for you (and is easy to untrace when finished).
>
> On Fri, Oct 3, 2014 at 11:12 AM, Erin Hodgess <erinm.hodgess at gmail.com>
> wrote:
> > thank you!!
> >
> >
> > On Fri, Oct 3, 2014 at 12:18 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com>
> > wrote:
> >
> >> On 03/10/2014 12:09 PM, Erin Hodgess wrote:
> >>
> >>> So please be prepared...
> >>>
> >>> Ok.  I made a copy of the arima.r function called earima.r to put in
> some
> >>> print statements.  Fair enough.
> >>>
> >>> Now when I run earima, the .Call statements call find the C
> subroutines.
> >>>
> >>> I know that this should be a really simple fix, but I don't know how.
> I
> >>> do
> >>> know that the original arima function is in stats.
> >>>
> >>> Sorry for the trouble.
> >>>
> >>>
> >>>
> >>>  If you run
> >>
> >> environment(arima) <- environment(stats::arima)
> >>
> >> it should work (assuming your function is still called arima).  The
> >> problem is that statements like
> >>
> >>  .Call(C_ARIMA_Like, y, mod, 0L, TRUE)
> >>
> >> refer to variables like C_ARIMA_Like, which are local to the package
> >> environment of stats.  They aren't exported, so your function (which
> >> presumably has a different environment) can't see them.
> >>
> >> Duncan Murdoch
> >>
> >
> >
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics
> > University of Houston - Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>



-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From arne.henningsen at gmail.com  Sat Oct  4 06:59:45 2014
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sat, 4 Oct 2014 06:59:45 +0200
Subject: [R] comparing two "half-normal production" stochastic frontier
	functions
In-Reply-To: <m2r3yp71uv.fsf@krugs.de>
References: <m2r3yp71uv.fsf@krugs.de>
Message-ID: <CAMTWbJhkSdzgpLUz_ymECieMMWD7oqutynNFU-dgksNsLdiLjA@mail.gmail.com>

Dear Rainer

On 3 October 2014 14:51, Rainer M Krug <Rainer at krugs.de> wrote:
> I am using the function frontier::sfa (from the package frontier) to
> estimate several "half-normal production" stochastic frontier functions.
>
> Now I want to compare the coefficients of the linear frontier function
> and see if they are different.
>
> According to my stackexchange (CrossValidated) question [1] I can
> compare these as I can compare a normal linear regression.
>
> In R, I would uswe the function anova to do this model comparison -
> correct?
>
> Now this function does not accept objects of the type 'frontier' - so
> how can I do this comparison in R?
>
> To re-iterate, I want to know if the coefficients of the frontier line
> (slope and intercept) are significantly different.
>
> Below please find a reproducible example based on data provided in the
> package, of what I did, and below the transcript.
>
> --8<---------------cut here---------------start------------->8---
> library(frontier)
> data(front41Data)
> dat1 <- front41Data[1:30,]
> dat2 <- front41Data[30:60,]
> x1 <- sfa(log(output) ~ log(capital), data=dat1)
> x2 <- sfa(log(output) ~ log(capital), data=dat2)
> x1
> x2
> anova(x1, x2
> --8<---------------cut here---------------end--------------->8---

library( "frontier" )
data( "front41Data" )

# estimate pooled model
mp <- sfa( log(output) ~ log(capital), data = front41Data )

# create a dummy variable
front41Data$dum <- rep( c( 1, 0 ), 30 )

# estimate model with different intercepts and different slopes
# but the same sigmsSq and the same gamma
md <- sfa( log(output) ~ log(capital)*dum, data = front41Data )

# likelihood ratio test
lrtest( mp, md )


If you have further questions regarding the frontier package, you may
also use the "help" forum at frontier's R-Forge site:

https://r-forge.r-project.org/projects/frontier/

...and please do not forget to cite the frontier package in your
publications (see output of the R command 'citation("frontier")').

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From Ramgad82 at gmx.net  Sat Oct  4 16:33:34 2014
From: Ramgad82 at gmx.net (Dagmar)
Date: Sat, 04 Oct 2014 16:33:34 +0200
Subject: [R] merge by time,
 certain value if 5 min before and after an "event"
In-Reply-To: <CAN5YmCFamTCgrt08QgrDV4ZnReP7c+m0CccSXupaqeTFGJh+vQ@mail.gmail.com>
References: <542D4F6E.6030607@gmx.net>
	<CAN5YmCGiu+FYSAKYWjfN--F6EXscDeJht-pshBh-avuKhxOP3A@mail.gmail.com>
	<542DC2BC.9030907@gmx.net>
	<CAN5YmCFamTCgrt08QgrDV4ZnReP7c+m0CccSXupaqeTFGJh+vQ@mail.gmail.com>
Message-ID: <5430053E.90404@gmx.net>

Thank you Jean, Petr, Terry, William and everyone else who thought about 
my problem.
It is sooo good that this mailing list exists!

I solved my problem using Petr's suggestion, that didn't seem so 
complicated and worked fine for me.
Thanks again and have a great weekend,
Dagmar



Am 02.10.2014 um 23:38 schrieb Adams, Jean:
> Thanks, Dagmar.
>
> So, shouldn't row 3 with a time of 09:51:01 be "low" and not "high"?
>
> Jean
>
> On Thu, Oct 2, 2014 at 4:25 PM, Dagmar <Ramgad82 at gmx.net 
> <mailto:Ramgad82 at gmx.net>> wrote:
>
>     Dear Jean and all,
>
>     I want all lines to be "low", but during times 9:55 - 10:05 a.m
>     (i.e. a
>     timespan of 10 min) I want them to be "high".
>     In my real data "low" and "high" refer to "lowtide" and "hightide" in
>     the waddensea and I want to assign the location of my animal at
>     the time
>     it was taken to the tide (that means, there was water not only exactly
>     at 10:00 (as taken from official data) but also 5 min before and
>     after).
>
>     I hope that is more understandable, if not ask again. Thanks for
>     trying
>     to help,
>     Dagmar
>
>     Am 02.10.2014 um 23:01 schrieb Adams, Jean:
>     > Dagmar,
>     >
>     > Can you explain more fully why rows 1, 2, and 5 in your result are
>     > "low" and rows 3 and 4 are "high"?  It is not clear to me from the
>     > information you have provided.
>     >
>     > > result[c(1, 2, 5), ]
>     >             Timestamp location Event
>     > 1 24.09.2012 09:05:01        1 low
>     > 2 24.09.2012 09:49:50        2 low
>     > 5 24.09.2012 10:05:10        5 low
>     >
>     > > result[3:4, ]
>     >             Timestamp location Event
>     > 3 24.09.2012 09:51:01        3  high
>     > 4 24.09.2012 10:04:50        1  high
>     >
>     > Jean
>     >
>     >
>     > On Thu, Oct 2, 2014 at 8:13 AM, Dagmar <Ramgad82 at gmx.net
>     <mailto:Ramgad82 at gmx.net>
>     > <mailto:Ramgad82 at gmx.net <mailto:Ramgad82 at gmx.net>>> wrote:
>     >
>     >     Hello! I hope someone can help me. It would save me days of
>     work.
>     >     Thanks in
>     >     advance!
>     >     I have two dataframes which look like these:
>     >
>     >
>     >     myframe <- data.frame (Timestamp=c("24.09.2012 09:00:00",
>     "24.09.2012
>     >     10:00:00",
>     >     "24.09.2012 11:00:00"), Event=c("low","high","low") )
>     >     myframe
>     >
>     >
>     >     mydata <- data.frame ( Timestamp=c("24.09.2012 09:05:01",
>     "24.09.2012
>     >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50",
>     "24.09.2012
>     >     10:05:10")
>     >     , location=c("1","2","3","1","5") )
>     >     mydata
>     >
>     >
>     >     # I want to merge them by time so I have a dataframe which looks
>     >     like this
>     >     in the end (i.e. "Low"  during 5 min before and after "high" )
>     >
>     >     result <- data.frame ( Timestamp=c("24.09.2012 09:05:01",
>     "24.09.2012
>     >     09:49:50", "24.09.2012 09:51:01", "24.09.2012 10:04:50",
>     "24.09.2012
>     >     10:05:10")
>     >     , location=c("1","2","3","1","5") ,
>     >     Event=c("low", "low","high","high","low"))
>     >     result
>     >
>     >     Anyone knows how do merge them?
>     >     Best regards,
>     >     Dagmar
>     >
>     >     ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org>
>     <mailto:R-help at r-project.org <mailto:R-help at r-project.org>>
>     mailing list
>     >https://stat.ethz.ch/mailman/listinfo/r-help
>     >     PLEASE do read the posting guide
>     > http://www.R-project.org/posting-guide.html
>     >     and provide commented, minimal, self-contained, reproducible
>     code.
>     >
>     >
>
>
>             [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From 1104271103 at qq.com  Sat Oct  4 09:09:25 2014
From: 1104271103 at qq.com (Grace Shi)
Date: Sat, 4 Oct 2014 15:09:25 +0800
Subject: [R] Rolling window linear regression
Message-ID: <000001cfdfa2$21f257a0$65d706e0$@qq.com>

	
I have to do roll regression based on the Daily data. I use the past three
weeks of daily returns as the estimation window and the regression is
estimated rolling forward one week at a time generating time series
estimates of beta. I know I should use the rollapply in zoo package. but I
am not sure how to  do.

data example:

 stock        day             week          y              x
 "00001"      2009-01-02     2009-01      0.89          2.45
 "00001"      2009-01-03     2009-01      1.21          1.90
 "00001"      2009-01-04     2009-01      0.12          0.89
 "00001"      2009-01-05     2009-01      1.45          2.78
 "00001"      2009-01-06     2009-01      1.98          0.98
 "00001"      2009-01-09     2009-02      3.34          1.23
 "00001"      2009-01-10     2009-02      0.12          0.89
 "00001"      2009-01-11     2009-02      1.45          2.78
 "00001"      2009-01-13     2009-02      1.98          0.98
 "00001"      2009-01-16     2009-03      3.38          0.93
 "00001"      2009-01-17     2009-03      6.56          3.90
 "00001"      2009-01-18     2009-03      5.09          3.45
 "00001"      2009-01-19     2009-03      5.89          3.78

 


	[[alternative HTML version deleted]]


From tk391 at scarletmail.rutgers.edu  Sat Oct  4 17:08:44 2014
From: tk391 at scarletmail.rutgers.edu (Teis M. Kristensen)
Date: Sat, 4 Oct 2014 11:08:44 -0400
Subject: [R] R Markdown (Rstudio) Limit Results in knit Pdf
Message-ID: <379C7F97-7307-4D08-8421-619E8DDBB147@scarletmail.rutgers.edu>

Hi all,

I am writing here because I would like to limit the number of lines that are produced from a function when I knit my markdown document in R.

The code is written down as following and gives 50+ lines of data when run. My goal is to only have 9 lines of code produced by the sedist function.

```{r, results=1:9}
sedist(FILENAME, method="correlation")
```

I have tried using {r, message=1:9}, {r, Hide=1:9} and similar. 

Please let me if you have a solution.

Best,
Teis Moeller Kristensen
School of Communication and Information
Rutgers University
Office ANX A - 103


	[[alternative HTML version deleted]]


From nia_gupta at yahoo.com  Sat Oct  4 15:21:06 2014
From: nia_gupta at yahoo.com (Nia Gupta)
Date: Sat, 4 Oct 2014 13:21:06 +0000 (UTC)
Subject: [R] Question about range of letters
Message-ID: <2010156123.429301.1412428866971.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>

Hello, 

I have a column with a bunch of letters. I would like to keep some of these letters (A,C,D,L) and turn the rest into 'X'. 

I have tried using ifelse with '|' in between the argument but it didn't work nor did 4 separate ifelse statements. 

Example, I currently have:
Letters??? A??? B??? C??? D??? E
I would like to have:
Letters??? A??? X??? C??? D??? X
Thank you

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Sat Oct  4 18:06:40 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 4 Oct 2014 16:06:40 +0000
Subject: [R] Question about range of letters
References: <2010156123.429301.1412428866971.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>
Message-ID: <loom.20141004T180514-610@post.gmane.org>

Nia Gupta <nia_gupta <at> yahoo.com> writes:

> 
> Hello, 
 
> I have a column with a bunch of letters. I would like to keep some
> of these letters (A,C,D,L) and turn the rest into 'X'.
 
> I have tried using ifelse with '|' in between the argument but it
> didn't work nor did 4 separate ifelse statements.
 
> Example, I currently have:
> Letters??? A??? B??? C??? D??? E
> I would like to have:
> Letters??? A??? X??? C??? D??? X
> Thank you

  %in% will be helpful

 Letters <- LETTERS[1:5]
 targets <- c("A","C","D","L")
 Letters[!Letters %in% targets] <- "X"


From rbaer at atsu.edu  Sat Oct  4 18:14:09 2014
From: rbaer at atsu.edu (Robert Baer)
Date: Sat, 04 Oct 2014 11:14:09 -0500
Subject: [R] Question about range of letters
In-Reply-To: <2010156123.429301.1412428866971.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>
References: <2010156123.429301.1412428866971.JavaMail.yahoo@jws10603.mail.bf1.yahoo.com>
Message-ID: <54301CD1.2050404@atsu.edu>


On 10/4/2014 8:21 AM, Nia Gupta wrote:
> Hello,
>
> I have a column with a bunch of letters. I would like to keep some of these letters (A,C,D,L) and turn the rest into 'X'.
>
> I have tried using ifelse with '|' in between the argument but it didn't work nor did 4 separate ifelse statements.
>
> Example, I currently have:
> Letters    A    B    C    D    E
> I would like to have:
> Letters    A    X    C    D    X
> Thank you
>
> 	[[alternative HTML version deleted]]
try:
let = sample(LETTERS[1:5],100,replace=TRUE)
let
let1 =  ifelse(let %in% c('A','C','D'),let,'X')
let1

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Oct  4 18:15:41 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 4 Oct 2014 09:15:41 -0700
Subject: [R] Rolling window linear regression
In-Reply-To: <000001cfdfa2$21f257a0$65d706e0$@qq.com>
References: <000001cfdfa2$21f257a0$65d706e0$@qq.com>
Message-ID: <CACk-te2+ePkf+WAm9c=r7oU87bQkrFaSwyqcdbf9EZVJLjDiTw@mail.gmail.com>

Use ?loess instead.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Oct 4, 2014 at 12:09 AM, Grace Shi <1104271103 at qq.com> wrote:
>
> I have to do roll regression based on the Daily data. I use the past three
> weeks of daily returns as the estimation window and the regression is
> estimated rolling forward one week at a time generating time series
> estimates of beta. I know I should use the rollapply in zoo package. but I
> am not sure how to  do.
>
> data example:
>
>  stock        day             week          y              x
>  "00001"      2009-01-02     2009-01      0.89          2.45
>  "00001"      2009-01-03     2009-01      1.21          1.90
>  "00001"      2009-01-04     2009-01      0.12          0.89
>  "00001"      2009-01-05     2009-01      1.45          2.78
>  "00001"      2009-01-06     2009-01      1.98          0.98
>  "00001"      2009-01-09     2009-02      3.34          1.23
>  "00001"      2009-01-10     2009-02      0.12          0.89
>  "00001"      2009-01-11     2009-02      1.45          2.78
>  "00001"      2009-01-13     2009-02      1.98          0.98
>  "00001"      2009-01-16     2009-03      3.38          0.93
>  "00001"      2009-01-17     2009-03      6.56          3.90
>  "00001"      2009-01-18     2009-03      5.09          3.45
>  "00001"      2009-01-19     2009-03      5.89          3.78
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Sat Oct  4 18:45:13 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 04 Oct 2014 12:45:13 -0400
Subject: [R] get names of glm and related families from an object
Message-ID: <54302419.50606@yorku.ca>

In a function I'm writing, I want to handle a variety of families of 
glm() and related models
including MASS::glm.nb() and hopefully countreg::hurdle(), zeroinfl().  
A central part of the function
is a switch() call

     family <- object$family$family
     switch(family,
             "binomial" = {
                 },
             "quasibinomial" = {
                 },
             "poisson" = {
                 },
             "quasipoisson" = {
                 },
             "gaussian" = {
                 }
             )

But I discovered that the object$family$family slot doesn't work the 
same way with glm.nb --
I get, e.g.,
 > nmes.nbin2$family$family
[1] "Negative Binomial(1.2354)"
and the countreg functions don't return a family component.

I think I have to also use class(object), and a more complicated 
computation of family,
but maybe there's a simpler way?

-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From teamtraders3564 at gmail.com  Sat Oct  4 22:37:08 2014
From: teamtraders3564 at gmail.com (Jason Eyerly)
Date: Sat, 4 Oct 2014 13:37:08 -0700
Subject: [R] Inference() Function Insisting That I Use ANOVA Versus
	Two-Sided Hypothesis Test; R/RStudio
Message-ID: <004BA195-BE9D-4744-8F23-2E73C0C5AD1B@gmail.com>

Hello All.

I'm trying to use a custom function called Inference() as seen in the code below. There's no documentation for the function, but it is from my DASI class in Coursera. According to the feedback I have received, I am using the function properly. I'm trying to do a two-sided hypothesis test between my class variable and my wordsum variable. However, the function/R/R Studio keep insisting I do an ANOVA test. This doesn't work for me since I'm trying to reject the null, and create a confidence interval between the difference of two independent means. I've looked at the function, but as I'm no R expert, I don't see anything out of the ordinary. Any help is greatly appreciated.

load(url("http://bit.ly/dasi_gss_ws_cl"))
source("http://bit.ly/dasi_inference")

summary(gss)
by(gss$wordsum, gss$class, mean)
boxplot(gss$wordsum ~ gss$class)

gss_clean = na.omit(subset(gss, class == "WORKING" | class =="LOWER"))

inference(y = gss_clean$wordsum, x = gss_clean$class, est = "mean", type = "ht", 
          null = 0, alternative = "twosided", method = "theoretical?)

Returns:

Response variable: numerical, Explanatory variable: categorical
Error: Use alternative = 'greater' for ANOVA or chi-square test.
In addition: Warning message:
Ignoring null value since it's undefined for ANOVA.

Best Regards,
	Jason Eyerly
	[[alternative HTML version deleted]]


From friendly at yorku.ca  Sun Oct  5 02:10:10 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 04 Oct 2014 20:10:10 -0400
Subject: [R] R Markdown (Rstudio) Limit Results in knit Pdf
In-Reply-To: <379C7F97-7307-4D08-8421-619E8DDBB147@scarletmail.rutgers.edu>
References: <379C7F97-7307-4D08-8421-619E8DDBB147@scarletmail.rutgers.edu>
Message-ID: <54308C62.8030709@yorku.ca>

This is a knitr-specific question, and you are probably better off 
posting to the stackoverflow knitr questions site,
http://stackoverflow.com/questions/tagged/knitr

Nonetheless, here is what I use to add an output.lines options to chunk 
output.  This works for me using LaTeX output;  you can try it with 
markdown...

   # knitr hook function to allow an output.lines option
   # e.g.,
   #   output.lines=12 prints lines 1:12 ...
   #   output.lines=1:12 does the same
   #   output.lines=3:15 prints lines ... 3:15 ...
   #   output.lines=-(1:8) removes lines 1:8 and prints ... 9:n ...
   #   No allowance for anything but a consecutive range of lines

   hook_output <- knit_hooks$get("output")
   knit_hooks$set(output = function(x, options) {
      lines <- options$output.lines
      if (is.null(lines)) {
        return(hook_output(x, options))  # pass to default hook
      }
      x <- unlist(strsplit(x, "\n"))
      more <- "..."
      if (length(lines)==1) {        # first n lines
        if (length(x) > lines) {
          # truncate the output, but add ....
          x <- c(head(x, lines), more)
        }
      } else {
        x <- c(if (abs(lines[1])>1 | lines[1]<0) more else NULL,
               x[lines],
               if (length(x)>lines[abs(length(lines))]) more else NULL
              )
      }
      # paste these lines together
      x <- paste(c(x, ""), collapse = "\n")
      hook_output(x, options)
    })



On 10/4/2014 11:08 AM, Teis M. Kristensen wrote:
> Hi all,
>
> I am writing here because I would like to limit the number of lines that are produced from a function when I knit my markdown document in R.
>
> The code is written down as following and gives 50+ lines of data when run. My goal is to only have 9 lines of code produced by the sedist function.
>
> ```{r, results=1:9}
> sedist(FILENAME, method="correlation")
> ```
>
> I have tried using {r, message=1:9}, {r, Hide=1:9} and similar.
>
> Please let me if you have a solution.
>
> Best,
> Teis Moeller Kristensen
> School of Communication and Information
> Rutgers University
> Office ANX A - 103
>
>
> 	[[alternative HTML version deleted]]
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jthayn at ilstu.edu  Sun Oct  5 02:36:18 2014
From: jthayn at ilstu.edu (Jonathan Thayn)
Date: Sat, 4 Oct 2014 19:36:18 -0500
Subject: [R] Using PCA to filter a series
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9D6B2@mb02.ads.tamu.edu>
References: <005E4CD0-940B-47CB-80FE-249F6829985D@ilstu.edu>
	<7D6E0CC3-3805-4789-A433-13AB8FC423C2@u.washington.edu>
	<CDD59C3C-BDD9-4AE2-93E8-627243883F11@ilstu.edu>
	<E6070C0D-F079-4BAD-B11A-B020FE6652BD@u.washington.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9D3F7@mb02.ads.tamu.edu>
	<50443357-306D-4EBD-A9A7-90C85B5B01BC@ilstu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9D6B2@mb02.ads.tamu.edu>
Message-ID: <BE61C6EB-1F48-4BBC-8898-CCAFE02F16D8@ilstu.edu>

This is exactly what I was looking for. Thank you.


Jonathan Thayn




On Oct 3, 2014, at 10:32 AM, David L Carlson wrote:

> You can reconstruct the data from the first component. Here's an example using singular value decomposition on the original data matrix:
> 
>> d <- cbind(d1, d2, d3, d4)
>> d.svd <- svd(d)
>> new <- d.svd$u[,1] * d.svd$d[1]
> 
> new is basically your cp1. If we multiply it by each of the loadings, we can create reconstructed values based on the first component:
> 
>> dnew <- sapply(d.svd$v[,1], function(x) new * x)
>> round(head(dnew), 1)
>      [,1]  [,2]  [,3]  [,4]
> [1,] 119.3 134.1 135.7 134.6
> [2,] 104.2 117.2 118.6 117.6
> [3,] 109.7 123.3 124.8 123.8
> [4,] 109.3 122.9 124.3 123.3
> [5,] 105.8 119.0 120.4 119.4
> [6,] 111.5 125.4 126.9 125.8
>> head(d)
>      d1  d2  d3  d4
> [1,] 113 138 138 134
> [2,] 108 115 120 115
> [3,] 105 127 129 120
> [4,] 103 127 129 120
> [5,] 109 119 120 117
> [6,] 115 126 126 123
> 
>> diag(cor(d, dnew))
> [1] 0.9233742 0.9921703 0.9890085 0.9910287
> 
> Since you want a single variable to stand for all four, you could scale new to the mean:
> 
>> newd <- new*mean(d.svd$v[,1])
>> head(newd)
> [1] 130.9300 114.3972 120.3884 119.9340 116.1588 122.3983
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> 
> -----Original Message-----
> From: Jonathan Thayn [mailto:jthayn at ilstu.edu] 
> Sent: Thursday, October 2, 2014 11:11 PM
> To: David L Carlson
> Cc: r-help at r-project.org
> Subject: Re: [R] Using PCA to filter a series
> 
> I suppose I could calculate the eigenvectors directly and not worry about centering the time-series, since they essentially the same range to begin with:
> 
> vec <- eigen(cor(cbind(d1,d2,d3,d4)))$vector
> cp <- cbind(d1,d2,d3,d4)%*%vec
> cp1 <- cp[,1]
> 
> I guess there is no way to reconstruct the original input data using just the first component, though, is there? Not the original data in it entirety, just one time-series that we representative of the general pattern. Possibly something like the following, but with just the first component:
> 
> o <- cp%*%solve(vec)
> 
> Thanks for your help. It's been a long time since I've played with PCA.
> 
> Jonathan Thayn
> 
> 
> 
> 
> On Oct 2, 2014, at 4:59 PM, David L Carlson wrote:
> 
>> I think you want to convert your principal component to the same scale as d1, d2, d3, and d4. But the "original space" is a 4-dimensional space in which d1, d2, d3, and d4 are the axes, each with its own mean and standard deviation. Here are a couple of possibilities
>> 
>> # plot original values for comparison
>>> matplot(cbind(d1, d2, d3, d4), pch=20, col=2:5)
>> # standardize the pc scores to the grand mean and sd
>>> new1 <- scale(pca$scores[,1])*sd(c(d1, d2, d3, d4)) + mean(c(d1, d2, d3, d4))
>>> lines(new1)
>> # Use least squares regression to predict the row means for the original four variables
>>> new2 <- predict(lm(rowMeans(cbind(d1, d2, d3, d4))~pca$scores[,1]))
>>> lines(new2, col="red")
>> 
>> -------------------------------------
>> David L Carlson
>> Department of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> 
>> 
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Don McKenzie
>> Sent: Thursday, October 2, 2014 4:39 PM
>> To: Jonathan Thayn
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Using PCA to filter a series
>> 
>> 
>> On Oct 2, 2014, at 2:29 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
>> 
>>> Hi Don. I would like to "de-rotate? the first component back to its original state so that it aligns with the original time-series. My goal is to create a ?cleaned?, or a ?model? time-series from which noise has been removed. 
>> 
>> Please cc the list with replies. It?s considered courtesy plus you?ll get more help that way than just from me.
>> 
>> Your goal sounds almost metaphorical, at least to me.  Your first axis ?aligns? with the original time series already in that it captures the dominant variation
>> across all four. Beyond that, there are many approaches to signal/noise relations within time-series analysis. I am not a good source of help on these, and you probably need a statistical consult (locally?), which is not the function of this list.
>> 
>>> 
>>> 
>>> Jonathan Thayn
>>> 
>>> 
>>> 
>>> On Oct 2, 2014, at 2:33 PM, Don McKenzie <dmck at u.washington.edu> wrote:
>>> 
>>>> 
>>>> On Oct 2, 2014, at 12:18 PM, Jonathan Thayn <jthayn at ilstu.edu> wrote:
>>>> 
>>>>> I have four time-series of similar data. I would  like to combine these into a single, clean time-series. I could simply find the mean of each time period, but I think that using principal components analysis should extract the most salient pattern and ignore some of the noise. I can compute components using princomp
>>>>> 
>>>>> 
>>>>> d1 <- c(113, 108, 105, 103, 109, 115, 115, 102, 102, 111, 122, 122, 110, 110, 104, 121, 121, 120, 120, 137, 137, 138, 138, 136, 172, 172, 157, 165, 173, 173, 174, 174, 119, 167, 167, 144, 170, 173, 173, 169, 155, 116, 101, 114, 114, 107, 108, 108, 131, 131, 117, 113)
>>>>> d2 <- c(138, 115, 127, 127, 119, 126, 126, 124, 124, 119, 119, 120, 120, 115, 109, 137, 142, 142, 143, 145, 145, 163, 169, 169, 180, 180, 174, 181, 181, 179, 173, 185, 185, 183, 183, 178, 182, 182, 181, 178, 171, 154, 145, 147, 147, 124, 124, 120, 128, 141, 141, 138)
>>>>> d3 <- c(138, 120, 129, 129, 120, 126, 126, 125, 125, 119, 119, 122, 122, 115, 109, 141, 144, 144, 148, 149, 149, 163, 172, 172, 183, 183, 180, 181, 181, 181, 173, 185, 185, 183, 183, 184, 182, 182, 181, 179, 172, 154, 149, 156, 156, 125, 125, 115, 139, 140, 140, 138)
>>>>> d4 <- c(134, 115, 120, 120, 117, 123, 123, 128, 128, 119, 119, 121, 121, 114, 114, 142, 145, 145, 144, 145, 145, 167, 172, 172, 179, 179, 179, 182, 182, 182, 182, 182, 184, 184, 182, 184, 183, 183, 181, 179, 172, 149, 149, 149, 149, 124, 124, 119, 131, 135, 135, 134)
>>>>> 
>>>>> 
>>>>> pca <- princomp(cbind(d1,d2,d3,d4))
>>>>> plot(pca$scores[,1])
>>>>> 
>>>>> This seems to have created the clean pattern I want, but I would like to project the first component back into the original axes? Is there a simple way to do that?
>>>> 
>>>> Do you mean that you want to scale the scores on Axis 1 to the mean and range of your raw data?  Or their mean and variance?
>>>> 
>>>> See
>>>> 
>>>> ?scale
>>>>> 
>>>>> 
>>>>> 
>>>>> 
>>>>> Jonathan B. Thayn
>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> Don McKenzie
>>>> Research Ecologist
>>>> Pacific WIldland Fire Sciences Lab
>>>> US Forest Service
>>>> 
>>>> Affiliate Professor
>>>> School of Environmental and Forest Sciences 
>>>> College of the Environment
>>>> University of Washington
>>>> dmck at uw.edu
>>> 
>> 
>> Don McKenzie
>> Research Ecologist
>> Pacific WIldland Fire Sciences Lab
>> US Forest Service
>> 
>> Affiliate Professor
>> School of Environmental and Forest Sciences 
>> College of the Environment
>> University of Washington
>> dmck at uw.edu
>> 
>> 
>>        [[alternative HTML version deleted]]
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From wickedpuppy at gmail.com  Sun Oct  5 13:21:38 2014
From: wickedpuppy at gmail.com (billy am)
Date: Sun, 5 Oct 2014 19:21:38 +0800
Subject: [R] Removing description from lm()
Message-ID: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>

Hi ,

When I run the following code , I get both the description and the value ,
eg : Intercept and 0.5714286.

Is there a way to extract just the value 0.5714286? Thanks!


> x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)
Call:
lm(formula = x ~ y)

Coefficients:
(Intercept)            y
     0.5714       0.4286
> lm(x~y)$coefficient[1](Intercept)
  0.5714286


>

Regards
Billy

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Oct  5 15:02:39 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 05 Oct 2014 09:02:39 -0400
Subject: [R] Removing description from lm()
In-Reply-To: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
Message-ID: <5431416F.8040004@gmail.com>

On 05/10/2014, 7:21 AM, billy am wrote:
> Hi ,
> 
> When I run the following code , I get both the description and the value ,
> eg : Intercept and 0.5714286.
> 
> Is there a way to extract just the value 0.5714286? Thanks!
> 
> 
>> x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)
> Call:
> lm(formula = x ~ y)
> 
> Coefficients:
> (Intercept)            y
>      0.5714       0.4286
>> lm(x~y)$coefficient[1](Intercept)
>   0.5714286
> 

It's a name, not a description.  The result is a named vector.

To get rid of the name, call unname() on it, i.e.

unname(lm(x~y)$coefficient[1])

Duncan Murdoch


From ligges at statistik.tu-dortmund.de  Sun Oct  5 15:09:14 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 05 Oct 2014 15:09:14 +0200
Subject: [R] Removing description from lm()
In-Reply-To: <5431416F.8040004@gmail.com>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
	<5431416F.8040004@gmail.com>
Message-ID: <543142FA.2000300@statistik.tu-dortmund.de>



On 05.10.2014 15:02, Duncan Murdoch wrote:
> On 05/10/2014, 7:21 AM, billy am wrote:
>> Hi ,
>>
>> When I run the following code , I get both the description and the value ,
>> eg : Intercept and 0.5714286.
>>
>> Is there a way to extract just the value 0.5714286? Thanks!
>>
>>
>>> x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)
>> Call:
>> lm(formula = x ~ y)
>>
>> Coefficients:
>> (Intercept)            y
>>       0.5714       0.4286
>>> lm(x~y)$coefficient[1](Intercept)
>>    0.5714286
>>
>
> It's a name, not a description.  The result is a named vector.
>
> To get rid of the name, call unname() on it, i.e.
>
> unname(lm(x~y)$coefficient[1])

I guess the OP is going to use the name (here "(Intercept)" without the 
quotes) to extract the value, hence (also using the extractior function 
coef()):

coef(lm(x~y))["(Intercept)"]

Best,
Uwe Ligges



>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Rainer at krugs.de  Sun Oct  5 15:42:04 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Sun, 5 Oct 2014 15:42:04 +0200
Subject: [R] comparing two "half-normal production" stochastic frontier
	functions
In-Reply-To: <CAMTWbJhkSdzgpLUz_ymECieMMWD7oqutynNFU-dgksNsLdiLjA@mail.gmail.com>
	(Arne Henningsen's message of "Sat, 4 Oct 2014 06:59:45 +0200")
References: <m2r3yp71uv.fsf@krugs.de>
	<CAMTWbJhkSdzgpLUz_ymECieMMWD7oqutynNFU-dgksNsLdiLjA@mail.gmail.com>
Message-ID: <m2zjda63bn.fsf@krugs.de>



Arne Henningsen <arne.henningsen at gmail.com> writes:

> Dear Rainer
>
> On 3 October 2014 14:51, Rainer M Krug <Rainer at krugs.de> wrote:
>> I am using the function frontier::sfa (from the package frontier) to
>> estimate several "half-normal production" stochastic frontier functions.
>>
>> Now I want to compare the coefficients of the linear frontier function
>> and see if they are different.
>>
>> According to my stackexchange (CrossValidated) question [1] I can
>> compare these as I can compare a normal linear regression.
>>
>> In R, I would uswe the function anova to do this model comparison -
>> correct?
>>
>> Now this function does not accept objects of the type 'frontier' - so
>> how can I do this comparison in R?
>>
>> To re-iterate, I want to know if the coefficients of the frontier line
>> (slope and intercept) are significantly different.
>>
>> Below please find a reproducible example based on data provided in the
>> package, of what I did, and below the transcript.
>>
>> --8<---------------cut here---------------start------------->8---
>> library(frontier)
>> data(front41Data)
>> dat1 <- front41Data[1:30,]
>> dat2 <- front41Data[30:60,]
>> x1 <- sfa(log(output) ~ log(capital), data=dat1)
>> x2 <- sfa(log(output) ~ log(capital), data=dat2)
>> x1
>> x2
>> anova(x1, x2
>> --8<---------------cut here---------------end--------------->8---
>
> library( "frontier" )
> data( "front41Data" )
>
> # estimate pooled model
> mp <- sfa( log(output) ~ log(capital), data = front41Data )
>
> # create a dummy variable
> front41Data$dum <- rep( c( 1, 0 ), 30 )
>
> # estimate model with different intercepts and different slopes
> # but the same sigmsSq and the same gamma
> md <- sfa( log(output) ~ log(capital)*dum, data = front41Data )
>
> # likelihood ratio test
> lrtest( mp, md )
>
>
> If you have further questions regarding the frontier package, you may
> also use the "help" forum at frontier's R-Forge site:

Thanks - I will follow this up there

Rainer

>
> https://r-forge.r-project.org/projects/frontier/
>
> ...and please do not forget to cite the frontier package in your
> publications (see output of the R command 'citation("frontier")').
>
> Best regards,
> Arne

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug

PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141005/fd9098fb/attachment.bin>

From wickedpuppy at gmail.com  Sun Oct  5 16:06:22 2014
From: wickedpuppy at gmail.com (billy am)
Date: Sun, 5 Oct 2014 22:06:22 +0800
Subject: [R] Removing description from lm()
In-Reply-To: <543142FA.2000300@statistik.tu-dortmund.de>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
	<5431416F.8040004@gmail.com>
	<543142FA.2000300@statistik.tu-dortmund.de>
Message-ID: <CAJ_FNV5WJZTnY1sUTL6v+qNcYNoDjxPY757_7aZ8Wh605Ky5LQ@mail.gmail.com>

Thank you both very much. It is the unname that is what I am looking for.
Thanks!

Btw , must the [1] be there? I am writing a Shiny web app hence I would
like to display the value alone.

Thanks!

> unname(lm(x~y)$coefficient[1])[1] 0.5714286> coef(lm(x~y))["(Intercept)"](Intercept)
  0.5714286


>





On Sun, Oct 5, 2014 at 9:09 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de>
wrote:

>
>
> On 05.10.2014 15:02, Duncan Murdoch wrote:
>
>> On 05/10/2014, 7:21 AM, billy am wrote:
>>
>>> Hi ,
>>>
>>> When I run the following code , I get both the description and the value
>>> ,
>>> eg : Intercept and 0.5714286.
>>>
>>> Is there a way to extract just the value 0.5714286? Thanks!
>>>
>>>
>>>  x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)
>>>>
>>> Call:
>>> lm(formula = x ~ y)
>>>
>>> Coefficients:
>>> (Intercept)            y
>>>       0.5714       0.4286
>>>
>>>> lm(x~y)$coefficient[1](Intercept)
>>>>
>>>    0.5714286
>>>
>>>
>> It's a name, not a description.  The result is a named vector.
>>
>> To get rid of the name, call unname() on it, i.e.
>>
>> unname(lm(x~y)$coefficient[1])
>>
>
> I guess the OP is going to use the name (here "(Intercept)" without the
> quotes) to extract the value, hence (also using the extractior function
> coef()):
>
> coef(lm(x~y))["(Intercept)"]
>
> Best,
> Uwe Ligges
>
>
>
>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Oct  5 16:23:41 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 05 Oct 2014 10:23:41 -0400
Subject: [R] Removing description from lm()
In-Reply-To: <CAJ_FNV5WJZTnY1sUTL6v+qNcYNoDjxPY757_7aZ8Wh605Ky5LQ@mail.gmail.com>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>	<5431416F.8040004@gmail.com>	<543142FA.2000300@statistik.tu-dortmund.de>
	<CAJ_FNV5WJZTnY1sUTL6v+qNcYNoDjxPY757_7aZ8Wh605Ky5LQ@mail.gmail.com>
Message-ID: <5431546D.3090106@gmail.com>

On 05/10/2014, 10:06 AM, billy am wrote:
> Thank you both very much. It is the unname that is what I am looking
> for. Thanks!
> 
> Btw , must the [1] be there? I am writing a Shiny web app hence I would
> like to display the value alone.

Try leaving it out, and you'll see what it's for.  (It is generally
pretty safe to experiment in R.  Don't worry, you won't break it.)

Duncan Murdoch

> 
> Thanks!
> 
>> unname(lm(x~y)$coefficient[1])
> [1] 0.5714286
>> coef(lm(x~y))["(Intercept)"]
> (Intercept) 
>   0.5714286 
> 
> 
>> 
> 
> 
> 
> 
> 
> 
> On Sun, Oct 5, 2014 at 9:09 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de
> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
> 
> 
> 
>     On 05.10.2014 15:02, Duncan Murdoch wrote:
> 
>         On 05/10/2014, 7:21 AM, billy am wrote:
> 
>             Hi ,
> 
>             When I run the following code , I get both the description
>             and the value ,
>             eg : Intercept and 0.5714286.
> 
>             Is there a way to extract just the value 0.5714286? Thanks!
> 
> 
>                 x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)
> 
>             Call:
>             lm(formula = x ~ y)
> 
>             Coefficients:
>             (Intercept)            y
>                   0.5714       0.4286
> 
>                 lm(x~y)$coefficient[1](__Intercept)
> 
>                0.5714286
> 
> 
>         It's a name, not a description.  The result is a named vector.
> 
>         To get rid of the name, call unname() on it, i.e.
> 
>         unname(lm(x~y)$coefficient[1])
> 
> 
>     I guess the OP is going to use the name (here "(Intercept)" without
>     the quotes) to extract the value, hence (also using the extractior
>     function coef()):
> 
>     coef(lm(x~y))["(Intercept)"]
> 
>     Best,
>     Uwe Ligges
> 
> 
> 
> 
>         Duncan Murdoch
> 
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
> 
>


From pdalgd at gmail.com  Sun Oct  5 16:37:45 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 5 Oct 2014 16:37:45 +0200
Subject: [R] Removing description from lm()
In-Reply-To: <CAJ_FNV5WJZTnY1sUTL6v+qNcYNoDjxPY757_7aZ8Wh605Ky5LQ@mail.gmail.com>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
	<5431416F.8040004@gmail.com>
	<543142FA.2000300@statistik.tu-dortmund.de>
	<CAJ_FNV5WJZTnY1sUTL6v+qNcYNoDjxPY757_7aZ8Wh605Ky5LQ@mail.gmail.com>
Message-ID: <72A3D58C-524A-4354-ACD7-D6697B7EC9E4@gmail.com>


On 05 Oct 2014, at 16:06 , billy am <wickedpuppy at gmail.com> wrote:

> Thank you both very much. It is the unname that is what I am looking for.
> Thanks!
> 
> Btw , must the [1] be there? I am writing a Shiny web app hence I would
> like to display the value alone.
> 

It's part of standard printing of unnamed vectors. For nonstandard printing tasks, use cat() as in

> x <-c(a=2)
> x
a 
2 
> cat(x,"\n")
2 

(which incidentally also gets rid of the name).

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From wickedpuppy at gmail.com  Sun Oct  5 17:00:03 2014
From: wickedpuppy at gmail.com (billy am)
Date: Sun, 5 Oct 2014 23:00:03 +0800
Subject: [R] Removing description from lm()
In-Reply-To: <72A3D58C-524A-4354-ACD7-D6697B7EC9E4@gmail.com>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
	<5431416F.8040004@gmail.com>
	<543142FA.2000300@statistik.tu-dortmund.de>
	<CAJ_FNV5WJZTnY1sUTL6v+qNcYNoDjxPY757_7aZ8Wh605Ky5LQ@mail.gmail.com>
	<72A3D58C-524A-4354-ACD7-D6697B7EC9E4@gmail.com>
Message-ID: <CAJ_FNV7SNv0PH7Kfr_o10KJFHEDHxCz=wx7cLS4CK5ifKQxqEw@mail.gmail.com>

Thats it! Most splendid! Thanks! The final result, just the value alone ,
for future reference.

> x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)$coefficient[1](Intercept)
  0.5714286 > cat(lm(x~y)$coefficient[1])0.5714286


>

Thanks everyone!

Regards
Billy






On Sun, Oct 5, 2014 at 10:37 PM, peter dalgaard <pdalgd at gmail.com> wrote:

>
> On 05 Oct 2014, at 16:06 , billy am <wickedpuppy at gmail.com> wrote:
>
> > Thank you both very much. It is the unname that is what I am looking for.
> > Thanks!
> >
> > Btw , must the [1] be there? I am writing a Shiny web app hence I would
> > like to display the value alone.
> >
>
> It's part of standard printing of unnamed vectors. For nonstandard
> printing tasks, use cat() as in
>
> > x <-c(a=2)
> > x
> a
> 2
> > cat(x,"\n")
> 2
>
> (which incidentally also gets rid of the name).
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From thanoon.younis80 at gmail.com  Sun Oct  5 17:18:56 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sun, 5 Oct 2014 18:18:56 +0300
Subject: [R] truncated normal
Message-ID: <CABLo8nHnQO+4BREjGEgVJpg1Wt_3eYmZ1xE=sHLFQcUnQ3ghzA@mail.gmail.com>

Dear all R-users
I have a question regarding truncated normal distribution
: which type of  probability distribution has same properties of truncated
normal distribution?
Many thanks in advance

-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From rni.boh at gmail.com  Sun Oct  5 17:41:37 2014
From: rni.boh at gmail.com (Bob O'Hara)
Date: Sun, 5 Oct 2014 17:41:37 +0200
Subject: [R] truncated normal
In-Reply-To: <CABLo8nHnQO+4BREjGEgVJpg1Wt_3eYmZ1xE=sHLFQcUnQ3ghzA@mail.gmail.com>
References: <CABLo8nHnQO+4BREjGEgVJpg1Wt_3eYmZ1xE=sHLFQcUnQ3ghzA@mail.gmail.com>
Message-ID: <CAN-Z0xWzm3PkTS-VE121U-68mHY32q=ikF40k3Lzur-+JrebBw@mail.gmail.com>

This isn't an R question at all, so I don't know why it's on this list. But
the best answer I've got is "a truncated t-distribution with an infinite
number of degrees of freedom".

Bob

On 5 October 2014 17:18, thanoon younis <thanoon.younis80 at gmail.com> wrote:

> Dear all R-users
> I have a question regarding truncated normal distribution
> : which type of  probability distribution has same properties of truncated
> normal distribution?
> Many thanks in advance
>
> --
> Thanoon Y. Thanoon
> PhD Candidate
> Department of Mathematical Sciences
> Faculty of Science
> University Technology Malaysia, UTM
> E.Mail: Thanoon.younis80 at gmail.com
> E.Mail: dawn_prayer80 at yahoo.com
> Facebook:Thanoon Younis AL-Shakerchy
> Twitter: Thanoon Alshakerchy
> H.P:00601127550205
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Bob O'Hara

Biodiversity and Climate Research Centre
Senckenberganlage 25
D-60325 Frankfurt am Main,
Germany

Tel: +49 69 798 40226
Mobile: +49 1515 888 5440
WWW:   http://www.bik-f.de/root/index.php?page_id=219
Blog: http://occamstypewriter.org/boboh/
Journal of Negative Results - EEB: www.jnr-eeb.org

	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Sun Oct  5 17:54:59 2014
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sun, 5 Oct 2014 17:54:59 +0200
Subject: [R] Caret and Model Prediction
Message-ID: <20141005155459.GA1797@localhost.localdomain>

Dear All,
I am learning the ropes of CARET for automatic model training, more or
less following the steps of the tutorial at

http://bit.ly/ZJQINa

However, there are a few things about which I would like a piece of
advice.

Consider for instance the following model

#############################################################

 set.seed(825)

fitControl <- trainControl(## 10-fold CV
                           method = "repeatedcv",
                           number = 10,
                           ## repeated ten times
                           repeats = 10)

gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
                        n.trees = (1:30)*50,
                        shrinkage = 0.05)

nrow(gbmGrid)

gbmFit <- train(Ca+P+pH+SOC+Sand~ ., data = training,
                 method = "gbm",
                 trControl = fitControl,
                 ## This last option is actually one
                 ## for gbm() that passes through
                 verbose = TRUE,
## Now specify the exact models 
                 ## to evaludate:
                 tuneGrid = gbmGrid
                 )

#############################################################

I am trying to tune a model that predicts the values of 5 columns
whose names are "Ca","P","pH", "SOC", and "Sand".

1) Am I using the formula syntax in a correct way?

I then try to apply my model on the test data by coding

mypred <- predict(gbmFit, newdata=test)

However, at this point I am left with a couple of questions

2) does "predict" automatically select the best tuned model in gbmFit?
and if not, what am I supposed to do?
3) I do not get any error messages, but mypred consists of a single
column instead of 5 columns corresponding to the 5 variables I am
trying to predict, so something is obviously wrong (see point 1). Any
suggestions here?

Many thanks

Lorenzo


From bbolker at gmail.com  Sun Oct  5 18:32:19 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Sun, 5 Oct 2014 16:32:19 +0000
Subject: [R] truncated normal
References: <CABLo8nHnQO+4BREjGEgVJpg1Wt_3eYmZ1xE=sHLFQcUnQ3ghzA@mail.gmail.com>
	<CAN-Z0xWzm3PkTS-VE121U-68mHY32q=ikF40k3Lzur-+JrebBw@mail.gmail.com>
Message-ID: <loom.20141005T182935-440@post.gmane.org>

Bob O'Hara <rni.boh <at> gmail.com> writes:

> 
> This isn't an R question at all, so I don't know why it's on this list. But
> the best answer I've got is "a truncated t-distribution with an infinite
> number of degrees of freedom".
> 
> Bob

   Or, perhaps more productively:  "since your question is a general
statistical question, it might be more useful to ask it (e.g.) on
CrossValidated, <http://stats.stackexchange.com> ; however, you'll
also need to expand and/or clarify your question before you ask
it there.  It's not clear what kinds of similarity and/or properties
you are looking for.  More context would be helpful."

> 
> On 5 October 2014 17:18, 
> thanoon younis <thanoon.younis80 <at> gmail.com> wrote:
> 
> > Dear all R-users
> > I have a question regarding truncated normal distribution
> > : which type of  probability distribution has same properties of truncated
> > normal distribution?
> > Many thanks in advance


From gunter.berton at gene.com  Sun Oct  5 18:59:28 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 5 Oct 2014 09:59:28 -0700
Subject: [R] truncated normal
In-Reply-To: <loom.20141005T182935-440@post.gmane.org>
References: <CABLo8nHnQO+4BREjGEgVJpg1Wt_3eYmZ1xE=sHLFQcUnQ3ghzA@mail.gmail.com>
	<CAN-Z0xWzm3PkTS-VE121U-68mHY32q=ikF40k3Lzur-+JrebBw@mail.gmail.com>
	<loom.20141005T182935-440@post.gmane.org>
Message-ID: <CACk-te0G_fLa4WU-g6WLF=MqP6p6OaBhHwyWYxew-_D-gTCmAw@mail.gmail.com>

... yes.
... And do note that in sampling, truncated != censored.
(They are often confused)

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sun, Oct 5, 2014 at 9:32 AM, Ben Bolker <bbolker at gmail.com> wrote:
> Bob O'Hara <rni.boh <at> gmail.com> writes:
>
>>
>> This isn't an R question at all, so I don't know why it's on this list. But
>> the best answer I've got is "a truncated t-distribution with an infinite
>> number of degrees of freedom".
>>
>> Bob
>
>    Or, perhaps more productively:  "since your question is a general
> statistical question, it might be more useful to ask it (e.g.) on
> CrossValidated, <http://stats.stackexchange.com> ; however, you'll
> also need to expand and/or clarify your question before you ask
> it there.  It's not clear what kinds of similarity and/or properties
> you are looking for.  More context would be helpful."
>
>>
>> On 5 October 2014 17:18,
>> thanoon younis <thanoon.younis80 <at> gmail.com> wrote:
>>
>> > Dear all R-users
>> > I have a question regarding truncated normal distribution
>> > : which type of  probability distribution has same properties of truncated
>> > normal distribution?
>> > Many thanks in advance
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From email8889 at gmail.com  Sun Oct  5 17:40:11 2014
From: email8889 at gmail.com (email)
Date: Sun, 5 Oct 2014 18:40:11 +0300
Subject: [R] n-gram error with packages tau, tm, RTextTools
Message-ID: <CAJMZ3cdL1Bqa4mAFjFa+SWzks48gtrTSBgVeT-1z+c+=shLOoA@mail.gmail.com>

Hi:

I am trying to compute n-grams using package tm and tau with following code:

tokenize_ngrams <- function(x, n=3)
return(rownames(as.data.frame(unclass(textcnt(x,method="string",n=n)))))
texts <- c("This is the first document.", "This is the second file.",
"This is the third text.")
corpus <- Corpus(VectorSource(texts))
matrix <- DocumentTermMatrix(corpus,control=list(tokenize=tokenize_ngrams))


And getting following error

 Error in FUN(X[[2L]], ...) : non-character argument


also getting same error using the RTextTools package.

Any solution?

Best regards:

John


From dolremi at gmail.com  Sun Oct  5 20:04:01 2014
From: dolremi at gmail.com (Jia Xu)
Date: Sun, 5 Oct 2014 11:04:01 -0700
Subject: [R] Caret and Model Prediction
In-Reply-To: <20141005155459.GA1797@localhost.localdomain>
References: <20141005155459.GA1797@localhost.localdomain>
Message-ID: <CAKDhfe_dhmkeBO=uPT6VM3=mkXm1gJcOpyEh9_DkpXTy_2xMVw@mail.gmail.com>

Hi, Lorenzo:
  For 1) I think the formula is not correct. The formula should be outcome
~ features, and that's why you have weird result in 3)
    2) predict in caret will automatically find the best result one if
there is one(sometimes it fails). You can print the model to see the cross
validation result. Furthermore, you may specify the performance metric you
want to find the optimal result. Please see the details of the caret
tutorial to see how to.

On Sun, Oct 5, 2014 at 8:54 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Dear All,
> I am learning the ropes of CARET for automatic model training, more or
> less following the steps of the tutorial at
>
> http://bit.ly/ZJQINa
>
> However, there are a few things about which I would like a piece of
> advice.
>
> Consider for instance the following model
>
> #############################################################
>
> set.seed(825)
>
> fitControl <- trainControl(## 10-fold CV
>                           method = "repeatedcv",
>                           number = 10,
>                           ## repeated ten times
>                           repeats = 10)
>
> gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
>                        n.trees = (1:30)*50,
>                        shrinkage = 0.05)
>
> nrow(gbmGrid)
>
> gbmFit <- train(Ca+P+pH+SOC+Sand~ ., data = training,
>                 method = "gbm",
>                 trControl = fitControl,
>                 ## This last option is actually one
>                 ## for gbm() that passes through
>                 verbose = TRUE,
> ## Now specify the exact models                 ## to evaludate:
>                 tuneGrid = gbmGrid
>                 )
>
> #############################################################
>
> I am trying to tune a model that predicts the values of 5 columns
> whose names are "Ca","P","pH", "SOC", and "Sand".
>
> 1) Am I using the formula syntax in a correct way?
>
> I then try to apply my model on the test data by coding
>
> mypred <- predict(gbmFit, newdata=test)
>
> However, at this point I am left with a couple of questions
>
> 2) does "predict" automatically select the best tuned model in gbmFit?
> and if not, what am I supposed to do?
> 3) I do not get any error messages, but mypred consists of a single
> column instead of 5 columns corresponding to the 5 variables I am
> trying to predict, so something is obviously wrong (see point 1). Any
> suggestions here?
>
> Many thanks
>
> Lorenzo
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Jia Xu

	[[alternative HTML version deleted]]


From lorenzo.isella at gmail.com  Sun Oct  5 22:51:36 2014
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Sun, 5 Oct 2014 22:51:36 +0200
Subject: [R] Caret and Model Prediction
In-Reply-To: <CAKDhfe_dhmkeBO=uPT6VM3=mkXm1gJcOpyEh9_DkpXTy_2xMVw@mail.gmail.com>
References: <20141005155459.GA1797@localhost.localdomain>
	<CAKDhfe_dhmkeBO=uPT6VM3=mkXm1gJcOpyEh9_DkpXTy_2xMVw@mail.gmail.com>
Message-ID: <20141005205136.GA22164@localhost.localdomain>

Thanks a lot.
At this point then I wonder: seen that my response consists of 5
outcomes for each set of features, should I then train 5 different
models (one for each of them)?
Cheers

Lorenzo

On Sun, Oct 05, 2014 at 11:04:01AM -0700, Jia Xu wrote:
>Hi, Lorenzo:
>  For 1) I think the formula is not correct. The formula should be outcome
>~ features, and that's why you have weird result in 3)
>    2) predict in caret will automatically find the best result one if
>there is one(sometimes it fails). You can print the model to see the cross
>validation result. Furthermore, you may specify the performance metric you
>want to find the optimal result. Please see the details of the caret
>tutorial to see how to.
>
>On Sun, Oct 5, 2014 at 8:54 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
>wrote:
>
>> Dear All,
>> I am learning the ropes of CARET for automatic model training, more or
>> less following the steps of the tutorial at
>>
>> http://bit.ly/ZJQINa
>>
>> However, there are a few things about which I would like a piece of
>> advice.
>>
>> Consider for instance the following model
>>
>> #############################################################
>>
>> set.seed(825)
>>
>> fitControl <- trainControl(## 10-fold CV
>>                           method = "repeatedcv",
>>                           number = 10,
>>                           ## repeated ten times
>>                           repeats = 10)
>>
>> gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
>>                        n.trees = (1:30)*50,
>>                        shrinkage = 0.05)
>>
>> nrow(gbmGrid)
>>
>> gbmFit <- train(Ca+P+pH+SOC+Sand~ ., data = training,
>>                 method = "gbm",
>>                 trControl = fitControl,
>>                 ## This last option is actually one
>>                 ## for gbm() that passes through
>>                 verbose = TRUE,
>> ## Now specify the exact models                 ## to evaludate:
>>                 tuneGrid = gbmGrid
>>                 )
>>
>> #############################################################
>>
>> I am trying to tune a model that predicts the values of 5 columns
>> whose names are "Ca","P","pH", "SOC", and "Sand".
>>
>> 1) Am I using the formula syntax in a correct way?
>>
>> I then try to apply my model on the test data by coding
>>
>> mypred <- predict(gbmFit, newdata=test)
>>
>> However, at this point I am left with a couple of questions
>>
>> 2) does "predict" automatically select the best tuned model in gbmFit?
>> and if not, what am I supposed to do?
>> 3) I do not get any error messages, but mypred consists of a single
>> column instead of 5 columns corresponding to the 5 variables I am
>> trying to predict, so something is obviously wrong (see point 1). Any
>> suggestions here?
>>
>> Many thanks
>>
>> Lorenzo
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>-- 
>Jia Xu


From statistics84 at hotmail.com  Mon Oct  6 00:01:57 2014
From: statistics84 at hotmail.com (pari hesabi)
Date: Sun, 5 Oct 2014 22:01:57 +0000
Subject: [R] loop
Message-ID: <DUB125-W79B6CB6AB7945217782BFCC6A40@phx.gbl>

Hello ,I am trying to write a loop for sum of integrals . 
the integral is:integrand4<-function(x,a=1.5,n=3,k=0){(((a+1)*x)^k)*((2-x)^n)*(exp(-a*x-2))/(factorial(k)*factorial(n))}

integrate(integrand4,0,2).
I need a loop to give me the sum of integrals over k = 0,.....n , for every positive integer input (n).can anybody check my program and tell me about it's problem?I am looking forward to your suggestions.
B<-function(n){Sum<-1for (k in 0:n){BB<-function(k){integrand2<-function(x,a=1.5){(((a+1)*x)^k)*((2-x)^(n))*(exp(-a*x-2))/(factorial(k)*factorial(n))} integrate(integrand2,0,2)}r<-print(BB(k))sum<-sum+r}print(sum-1)} 

Best Regards,Diba 		 	   		  
	[[alternative HTML version deleted]]


From cranatic at gmail.com  Mon Oct  6 00:40:05 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 5 Oct 2014 18:40:05 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <5431c8c5efd02_3bf0bf9413c1e4@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* activity (1.0)
  Maintainer: Marcus Rowcliffe
  Author(s): Marcus Rowcliffe <marcus.rowcliffe at ioz.ac.uk>
  License: GPL-3
  http://crantastic.org/packages/activity

  Provides functions to fit kernel density functions to animal activity
  time data; plot activity distributions; quantify overall levels of
  activity; statistically compare activity metrics through
  bootstrapping; and evaluate variation in linear variables with time
  (or other circular variables).

* atmcmc (1.0)
  Maintainer: Jinyoung Yang
  Author(s): Jinyoung Yang
  License: GPL (>= 2)
  http://crantastic.org/packages/atmcmc

  Uses adaptive diagnostics to tune and run a random walk Metropolis
  MCMC algorithm, to converge to a specified target distribution and
  estimate means of functionals.

* blocksdesign (1.1)
  Maintainer: Rodney Edmondson
  Author(s): R. N. Edmondson
  License: GPL (>= 2)
  http://crantastic.org/packages/blocksdesign

  Nested block designs for unstructured treatment sets where blocks can
  be repeatedly nested and treatments can have different levels of
  replication. Blocks strata are optimized hierarchically with each
  set of nested blocks optimized within the levels of the preceding
  set. Block sizes are equal if the number of blocks exactly divides
  the number of plots, otherwise they differ by at most one plot. The
  design output is a data table giving a randomised allocation of
  treatments to blocks together with a plan table showing treatments
  in blocks and a set of blocks-by-treatments incidence matrices, one
  for each blocks stratum.

* checkpoint (0.3.2)
  Maintainer: Andrie de Vries
  Author(s): Revolution Analytics
  License: GPL-2
  http://crantastic.org/packages/checkpoint

  The goal of checkpoint is to solve the problem of package
  reproducibility in R. Specifically, checkpoint allows you to install
  packages as they existed on CRAN on a specific snapshot date as if
  you had a CRAN time machine.  To achieve reproducibility, the
  checkpoint() function installs the packages required or called by
  your project and scripts to a local library exactly as they existed
  at the specified point in time. Only those packages are available to
  your project, thereby avoiding any package updates that came later
  and may have altered your results. In this way, anyone using
  checkpoint&#39;s checkpoint() can ensure the reproducibility of your
  scripts or projects at any time. To create the snapshot archives,
  once a day (at midnight UTC) we refresh the Austria CRAN mirror, on
  the &quot;Managed R Archived Network&quot; server
  (http://mran.revolutionanalytics.com/). Immediately after completion
  of the rsync mirror process, we take a snapshot, thus creating the
  archive. Snapshot archives exist starting from 2014-09-17.

* DynNom (1.0)
  Maintainer: Amirhossein Jalali
  Author(s): Amirhossein Jalali, Alberto Alvarez-Iglesias, John Newell
  License: GPL-2
  http://crantastic.org/packages/DynNom

  The DynNom function makes it possible to present the results of an lm
  or glm model object as a dynamic nomogram that can be displayed in
  an R Studio panel or web browser.

* enpls (1.0)
  Maintainer: Xiao Nan
  Author(s): Nan Xiao <road2stat at gmail.com>, Dong-Sheng Cao <oriental-cds at 163.com>,
             Qing-Song Xu <dasongxu at gmail.com>
  License: GPL (>= 2)
  http://crantastic.org/packages/enpls

  R package for ensemble partial least squares regression, a unified
  framework for feature selection, outlier detection, and ensemble
  learning.

* gender (0.4.1)
  Maintainer: Lincoln Mullen
  Author(s): Lincoln Mullen [aut, cre], Cameron Blevins [ctb], Ben Schmidt [ctb]
  License: MIT + file LICENSE
  http://crantastic.org/packages/gender

  Encodes gender based on names and dates of birth, using either the
  Social Security Administration&#39;s data set of first names by year of
  birth or Census Bureau data from 1789 to 1940, both from the United
  States of America. By using these data sets instead of lists of male
  and female names, this package is able to more accurately guess the
  gender of a name, and it is able to report the probability that a
  name was male or female.

* lazyeval (0.1.9)
  Maintainer: Hadley Wickham
  Author(s): Hadley Wickham [aut, cre], RStudio [cph]
  License: GPL-3
  http://crantastic.org/packages/lazyeval

  A disciplined approach to non-standard evaluation.

* mdsdt (1.0)
  Maintainer: Robert X.D. Hawkins
  Author(s): Robert X.D. Hawkins <rxdh at stanford.edu>, Joe Houpt
             <joseph.houpt at wright.edu>, Noah Silbert
             <noahpoah at gmail.com>, Leslie Blaha
             <Leslie.Blaha at wpafb.af.mil>, Thomas D. Wickens
             <twickens at socrates.berkeley.edu>
  License: GPL (>= 2)
  http://crantastic.org/packages/mdsdt

  This package contains a series of tools associated with General
  Recognition Theory (Townsend &amp; Ashby, 1986), including Gaussian
  model fitting of 4x4 and more general confusion matrices, associated
  plotting and model comparison tools, and tests of marginal response
  invariance and report independence.

* measuRing (0.1)
  Maintainer: Wilson Lara
  Author(s): Wilson Lara <wilarhen at gmail.com>, Carlos Sierra
             <csierra at bgc-jena.mpg.de>
  License: GPL-3
  http://crantastic.org/packages/measuRing

  This package assists in the identification of ring borders on scanned
  image sections from dendrochronological samples. It processes the
  image section and computes luminance data from images producing a
  matrix of gray values and a time series of smoothed gray values.
  Luminance data is plotted on segmented images for users to perform
  both: visual identification of ring borders, or control of automatic
  detection. The package provides functions to visually
  include/exclude ring borders on the R graphical device, or
  automatically detect ring borders using a linear detection
  algorithm. This algorithm detects ring borders according to negative
  extreme values in the smoothed time-series of gray values.

* msda (1.0.1)
  Maintainer: Yi Yang
  Author(s): Qing Mai <mai at stat.fsu.edu>, Yi Yang <yiyang at umn.edu>,  Hui Zou
             <hzou at stat.umn.edu>
  License: GPL-2
  http://crantastic.org/packages/msda

  Efficient procedures for computing a new multi-class sparse
  discriminant analysis method that estimates all discriminant
  directions simultaneously.

* mycor (0.1)
  Maintainer: Keon-Woong Moon
  Author(s): Keon-Woong Moon [aut, cre]
  License: CC0
  http://crantastic.org/packages/mycor

  Perform correlation and linear regression test among the numeric
  columns in a data frame automatically and make plots using pairs or
  lattice::parallelplot.

* repra (0.4.1)
  Maintainer: Eduardo Ibanez
  Author(s): Eduardo Ibanez [aut, cre], National Renewable Energy Laboratory [cph]
  License: MIT + file LICENSE
  http://crantastic.org/packages/repra

  This package includes methods to calculate resource adequacy metrics
  in power systems. These methods are based in the notion of
  loss-of-load probability (LOLP) and include the treatment of
  conventional and variable renewable generators.

* rFDSN (0.0.0)
  Maintainer: Daniel Bowman
  Author(s): Daniel C. Bowman [aut, cre]
  License: GPL (>= 3)
  http://crantastic.org/packages/rFDSN

  This package facilitates searching for and downloading seismic time
  series in miniSEED format (a minimalist version of the Standard for
  the Exchange of Earthquake Data) from International Federation of
  Digital Seismograph Networks repositories. This package can also be
  used to gather information about seismic networks (stations,
  channels, locations, etc) and find historical earthquake data
  (origins, magnitudes, etc).

* rjstat (0.2)
  Maintainer: Aaron Schumacher
  Author(s): Aaron Schumacher <ajschumacher at gmail.com>, H??kon Malmedal
  License: MIT + file LICENSE
  http://crantastic.org/packages/rjstat

  Read and write the JSON-stat format (http://json-stat.org) to and from
  (lists of) R data frames. Not all features are supported, especially
  the extensive metadata features of JSON-stat.

* robustDA (1.0)
  Maintainer: Charles Bouveyron
  Author(s): Charles Bouveyron & Stephane Girard
  License: GPL-2
  http://crantastic.org/packages/robustDA

  Robust mixture discriminant analysis (RMDA, Bouveyron &amp; Girard, 2009)
  allows to build a robust supervised classifier from learning data
  with label noise. The idea of the proposed method is to confront an
  unsupervised modeling of the data with the supervised information
  carried by the labels of the learning data in order to detect
  inconsistencies. The method is able afterward to build a robust
  classifier taking into account the detected inconsistencies into the
  labels.

* saccades (0.1)
  Maintainer: Titus von der Malsburg
  Author(s): Titus von der Malsburg [aut, cph, cre]
  License: GPL-2
  http://crantastic.org/packages/saccades

  Functions for detecting eye fixations in raw eye-tracking data.  The
  detection is done using a velocity-based algorithm for saccade
  detection proposed by Ralf Engbert and Reinhold Kliegl in 2003.  The
  algorithm labels segments as saccades when the velocity of the eye
  movement exceeds a certain threshold.  Anything between two saccades
  is considered a fixation.  Thus the algorithm is not appropriate for
  data containing episodes of smooth pursuit eye movements.

* SQDA (1.0)
  Maintainer: Jiehuan Sun
  Author(s): Jiehuan Sun
  License: GPL-3
  http://crantastic.org/packages/SQDA

  Sparse Quadratic Discriminant Analysis (SQDA) can be performed. In
  SQDA, the covariance matrix are assumed to be block-diagonal.And,
  for each block, sparsity assumption is imposed on the covariance
  matrix. It is useful in high-dimensional setting.

* stabs (0.1-0)
  Maintainer: Benjamin Hofner
  Author(s): Benjamin Hofner [aut, cre], Torsten Hothorn [aut]
  License: GPL-2
  http://crantastic.org/packages/stabs

  Resampling procedures to assess the stability of selected variables
  with additional finite sample error control for high-dimensional
  variable selection procedures such as Lasso or boosting

* WRS2 (0.1-0)
  Maintainer: Patrick Mair
  Author(s): Patrick Mair [cre, aut], Felix Schoenbrodt [aut], Rand Wilcox [aut]
  License: GPL-2
  http://crantastic.org/packages/WRS2

  A user-friendly version of Wilcox&#39; robust statistics functions (WRS
  package on GitHub). It implements robust tests for ANOVA and ANCOVA
  as described in R. Wilcox (2012) &#39;Introduction to Robust Estimation
  and Hypothesis Testing&#39;.


Updated packages
----------------

ASMap (0.3-1), blocksdesign (1.1), BMA (3.18.1), boot (1.3-13),
carcass (1.3), ConConPiWiFun (0.4.4), ConConPiWiFun (0.4.3), copula
(0.999-12), corpcor (1.6.7), data.table (1.9.4), deducorrect (1.3-5),
DoE.base (0.26-3), DoE.wrapper (0.8-10), eaf (1.06), EffectStars
(1.5), EpiModel (1.1), exsic (1.1.1), fpc (2.1-9), fscaret (0.8.6.2),
FuzzyNumbers (0.3-5), gamlr (1.12-1), gapmap (0.0.2), geostatsp
(1.1.0), ggdendro (0.1-15), gMCP (0.8-8), gvcm.cat (1.7), HIBAG
(1.2.4), hierfstat (0.04-14), httpRequest (0.0.10), lavaan (0.5-17),
log4r (0.2), magicaxis (1.9.3), MASS (7.3-35), mboost (2.4-0), mco
(1.0-15), mfp (1.5.0), mi (0.09-19), multcomp (1.3-7), nleqslv (2.5),
PowerTOST (1.2-01), protViz (0.2.9), qdap (2.2.0), quantmod (0.4-1),
R2HTML (2.3.1), RandomFields (3.0.44), rbamtools (2.10.0),
RcmdrPlugin.EZR (1.26), Rcpp (0.11.3), repra (0.4.1), rgl (0.94.1143),
RHive (2.0-0.2), rsm (2.07), ScottKnott (1.2-5), semTools (0.4-6),
shiny (0.10.2.1), shiny (0.10.2), shrink (1.2.0), SightabilityModel
(1.3), simPH (1.2.3), simsem (0.5-8), soiltexture (1.2.19), splancs
(2.01-36), sprint (1.0.7), spTimer (1.0-3), steepness (0.2-2), stylo
(0.5.8-1), testthat (0.9.1), vec2dtransf (1.1), WriteXLS (3.5.1)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From jholtman at gmail.com  Mon Oct  6 00:45:17 2014
From: jholtman at gmail.com (jim holtman)
Date: Sun, 5 Oct 2014 18:45:17 -0400
Subject: [R] loop
In-Reply-To: <DUB125-W79B6CB6AB7945217782BFCC6A40@phx.gbl>
References: <DUB125-W79B6CB6AB7945217782BFCC6A40@phx.gbl>
Message-ID: <CAAxdm-4NRjsKqpArU4syp83+aBKaH6tYU71XqqKO9KmmD-dmJQ@mail.gmail.com>

Please don't post in HTML since your code was all messed up.  You did
not mention what problems you were having with your code.  Now a
couple of things to check is to look at what the structure of "r" that
you are trying to add to "sum" (which should have been "Sum" according
to your assignment earlier in the function.).

Browse[1]> str(r)
List of 5
 $ value       : num 0.0548
 $ abs.error   : num 6.08e-16
 $ subdivisions: int 1
 $ message     : chr "OK"
 $ call        : language integrate(f = integrand2, lower = 0, upper = 2)
 - attr(*, "class")= chr "integrate"

shows that "r" is a list and you want "r$value" to do the addition.
So after formatting your code, and making a couple of corrections, is
this what you were expecting to see:

> B<-function(n){
+     Sum<-1
+     for (k in 0:n){
+         BB<-function(k){
+             integrand2<-function(x,a=1.5){
+
(((a+1)*x)^k)*((2-x)^(n))*(exp(-a*x-2))/(factorial(k)*factorial(n))
+             }
+             integrate(integrand2,0,2)
+         }
+         r<-BB(k)
+         print(r)
+         Sum<-Sum+r$value
+     }
+     print(Sum-1)
+ }
> B(3)
0.05479674 with absolute error < 6.1e-16
0.03780519 with absolute error < 4.2e-16
0.02371485 with absolute error < 2.6e-16
0.01355982 with absolute error < 1.5e-16
[1] 0.1298766

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Sun, Oct 5, 2014 at 6:01 PM, pari hesabi <statistics84 at hotmail.com> wrote:
> Hello ,I am trying to write a loop for sum of integrals .
> the integral is:integrand4<-function(x,a=1.5,n=3,k=0){(((a+1)*x)^k)*((2-x)^n)*(exp(-a*x-2))/(factorial(k)*factorial(n))}
>
> integrate(integrand4,0,2).
> I need a loop to give me the sum of integrals over k = 0,.....n , for every positive integer input (n).can anybody check my program and tell me about it's problem?I am looking forward to your suggestions.
> B<-function(n){Sum<-1for (k in 0:n){BB<-function(k){integrand2<-function(x,a=1.5){(((a+1)*x)^k)*((2-x)^(n))*(exp(-a*x-2))/(factorial(k)*factorial(n))} integrate(integrand2,0,2)}r<-print(BB(k))sum<-sum+r}print(sum-1)}
>
> Best Regards,Diba
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From S.Ellison at LGCGroup.com  Mon Oct  6 15:21:06 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 6 Oct 2014 14:21:06 +0100
Subject: [R] a REALLY dumb question
In-Reply-To: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
References: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412A54F8E@GOLD.corp.lgc-group.com>

 
> Ok.  I made a copy of the arima.r function called earima.r to put in some print
> statements.  Fair enough.
> 
> Now when I run earima, the .Call statements call find the C subroutines.
> 
> I know that this should be a really simple fix

Not quite simple, as it's a nasty-looking namespace problem. But there IS a work-round using body()<-

First, copy arima from stats to an object in the global namespace; say
earima <- stats:::arima

You can confirm this still works with
> earima(lh, order = c(1,0,0))
 which does exactly the same as 
> arima(lh, order = c(1,0,0))

Now copy the earima body code - the bit between "{...}" in the source, or what you see on the console if you say 
body(earima) - into your code editor. Make your edits to that code, wrap everything (including the {}) in an expression,  and assign that amended expression back into body(earima) using body(earima) <- expression({ revised code here> }).  

Here's what that looks like

> earima <- stats:::arima ## Make the copy

> body(earima)  #Inspect original code 
{
    "%+%" <- function(a, b) .Call(C_TSconv, a, b)
    SSinit <- match.arg(SSinit)
    SS.G <- SSinit == "Gardner1980"
    upARIMA <- function(mod, phi, theta) {
	... ## This is the rest of the body code - don't lose any!
	...
}

#To add a cat() in that, we can do

> body(erima) <- expression({
    cat("Welcome to the new Arima!\n\n")           ### an illustrative cat() welcome call
    "%+%" <- function(a, b) .Call(C_TSconv, a, b)
    SSinit <- match.arg(SSinit)
    SS.G <- SSinit == "Gardner1980"
    upARIMA <- function(mod, phi, theta) {
	...
	...
})

And then 

>  earima(lh, order = c(1,0,0))  #First example from arima

#Returns (or at least displays) ...

Welcome to the new Arima!


Call:
Arima(x = lh, order = c(1, 0, 0))

Coefficients:
         ar1  intercept
      0.5739     2.4133
s.e.  0.1161     0.1466

sigma^2 estimated as 0.1975:  log likelihood = -29.38,  aic = 64.76


... which seems to be doing what you want...


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Mon Oct  6 15:36:42 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 6 Oct 2014 14:36:42 +0100
Subject: [R] a REALLY dumb question
In-Reply-To: <542ECC47.9090602@gmail.com>
References: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>
	<542ECC47.9090602@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412A54FAA@GOLD.corp.lgc-group.com>

Duncan Murdoch said:
> environment(arima) <- environment(stats::arima)

Doh!, in a word.

That is a really useful trick; same effect as copying and fooling about with body() to get an object with the right environment, but I'd completely overlooked the fact that you can assign an environment from one object directly to another object. 

This kind of thing is exactly what makes watching R-help so worthwhile.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From spencer.graves at structuremonitoring.com  Mon Oct  6 18:30:24 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 06 Oct 2014 09:30:24 -0700
Subject: [R] a REALLY dumb question
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED6412A54FAA@GOLD.corp.lgc-group.com>
References: <CACxE24=TtDOVa1bw7gjGBTQ27qdnzzRK9kivpo68oSLLnrE8uw@mail.gmail.com>	<542ECC47.9090602@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED6412A54FAA@GOLD.corp.lgc-group.com>
Message-ID: <5432C3A0.1090605@structuremonitoring.com>

On 10/6/2014 6:36 AM, S Ellison wrote:
> Duncan Murdoch said:
>> environment(arima) <- environment(stats::arima)
> Doh!, in a word.
>
> That is a really useful trick; same effect as copying and fooling about with body() to get an object with the right environment, but I'd completely overlooked the fact that you can assign an environment from one object directly to another object.
>
> This kind of thing is exactly what makes watching R-help so worthwhile.

       This is in Hadley's Advanced R (http://adv-r.had.co.nz/). This 
book is excellent.  (I learned a lot from it, and I've been using R and 
S-Plus almost daily for over 20 years;  if I'm not mistaken, he still 
accepts suggestions for changes via GitHub). Spencer Graves
>
> S Ellison
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dolremi at gmail.com  Sun Oct  5 23:45:05 2014
From: dolremi at gmail.com (Jia Xu)
Date: Sun, 5 Oct 2014 14:45:05 -0700
Subject: [R] Caret and Model Prediction
In-Reply-To: <20141005205136.GA22164@localhost.localdomain>
References: <20141005155459.GA1797@localhost.localdomain>
	<CAKDhfe_dhmkeBO=uPT6VM3=mkXm1gJcOpyEh9_DkpXTy_2xMVw@mail.gmail.com>
	<20141005205136.GA22164@localhost.localdomain>
Message-ID: <CAKDhfe_ogdxogmKARBsro61ddg85B6unpEZTAphvwsZcFQeXmA@mail.gmail.com>

Yes, you should train 5 different models, or find an outcome that can
combine them together, since caret only accepts a list or vector as
outcome.

On Sun, Oct 5, 2014 at 1:51 PM, Lorenzo Isella <lorenzo.isella at gmail.com>
wrote:

> Thanks a lot.
> At this point then I wonder: seen that my response consists of 5
> outcomes for each set of features, should I then train 5 different
> models (one for each of them)?
> Cheers
>
> Lorenzo
>
>
> On Sun, Oct 05, 2014 at 11:04:01AM -0700, Jia Xu wrote:
>
>> Hi, Lorenzo:
>>  For 1) I think the formula is not correct. The formula should be outcome
>> ~ features, and that's why you have weird result in 3)
>>    2) predict in caret will automatically find the best result one if
>> there is one(sometimes it fails). You can print the model to see the cross
>> validation result. Furthermore, you may specify the performance metric you
>> want to find the optimal result. Please see the details of the caret
>> tutorial to see how to.
>>
>> On Sun, Oct 5, 2014 at 8:54 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
>> wrote:
>>
>>  Dear All,
>>> I am learning the ropes of CARET for automatic model training, more or
>>> less following the steps of the tutorial at
>>>
>>> http://bit.ly/ZJQINa
>>>
>>> However, there are a few things about which I would like a piece of
>>> advice.
>>>
>>> Consider for instance the following model
>>>
>>> #############################################################
>>>
>>> set.seed(825)
>>>
>>> fitControl <- trainControl(## 10-fold CV
>>>                           method = "repeatedcv",
>>>                           number = 10,
>>>                           ## repeated ten times
>>>                           repeats = 10)
>>>
>>> gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
>>>                        n.trees = (1:30)*50,
>>>                        shrinkage = 0.05)
>>>
>>> nrow(gbmGrid)
>>>
>>> gbmFit <- train(Ca+P+pH+SOC+Sand~ ., data = training,
>>>                 method = "gbm",
>>>                 trControl = fitControl,
>>>                 ## This last option is actually one
>>>                 ## for gbm() that passes through
>>>                 verbose = TRUE,
>>> ## Now specify the exact models                 ## to evaludate:
>>>                 tuneGrid = gbmGrid
>>>                 )
>>>
>>> #############################################################
>>>
>>> I am trying to tune a model that predicts the values of 5 columns
>>> whose names are "Ca","P","pH", "SOC", and "Sand".
>>>
>>> 1) Am I using the formula syntax in a correct way?
>>>
>>> I then try to apply my model on the test data by coding
>>>
>>> mypred <- predict(gbmFit, newdata=test)
>>>
>>> However, at this point I am left with a couple of questions
>>>
>>> 2) does "predict" automatically select the best tuned model in gbmFit?
>>> and if not, what am I supposed to do?
>>> 3) I do not get any error messages, but mypred consists of a single
>>> column instead of 5 columns corresponding to the 5 variables I am
>>> trying to predict, so something is obviously wrong (see point 1). Any
>>> suggestions here?
>>>
>>> Many thanks
>>>
>>> Lorenzo
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>>
>> --
>> Jia Xu
>>
>


-- 
Jia Xu

	[[alternative HTML version deleted]]


From mxkuhn at gmail.com  Mon Oct  6 02:26:53 2014
From: mxkuhn at gmail.com (mxkuhn)
Date: Sun, 5 Oct 2014 20:26:53 -0400
Subject: [R] Caret and Model Prediction
In-Reply-To: <20141005205136.GA22164@localhost.localdomain>
References: <20141005155459.GA1797@localhost.localdomain>
	<CAKDhfe_dhmkeBO=uPT6VM3=mkXm1gJcOpyEh9_DkpXTy_2xMVw@mail.gmail.com>
	<20141005205136.GA22164@localhost.localdomain>
Message-ID: <BEE67397-07C5-4958-B077-32846D63D2CF@gmail.com>



> On Oct 5, 2014, at 4:51 PM, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> 
> Thanks a lot.
> At this point then I wonder: seen that my response consists of 5
> outcomes for each set of features, should I then train 5 different
> models (one for each of them)?
> Cheers

caret can only model one outcome at a time so yes. 

Max

> Lorenzo
> 
>> On Sun, Oct 05, 2014 at 11:04:01AM -0700, Jia Xu wrote:
>> Hi, Lorenzo:
>> For 1) I think the formula is not correct. The formula should be outcome
>> ~ features, and that's why you have weird result in 3)
>>   2) predict in caret will automatically find the best result one if
>> there is one(sometimes it fails). You can print the model to see the cross
>> validation result. Furthermore, you may specify the performance metric you
>> want to find the optimal result. Please see the details of the caret
>> tutorial to see how to.
>> 
>> On Sun, Oct 5, 2014 at 8:54 AM, Lorenzo Isella <lorenzo.isella at gmail.com>
>> wrote:
>> 
>>> Dear All,
>>> I am learning the ropes of CARET for automatic model training, more or
>>> less following the steps of the tutorial at
>>> 
>>> http://bit.ly/ZJQINa
>>> 
>>> However, there are a few things about which I would like a piece of
>>> advice.
>>> 
>>> Consider for instance the following model
>>> 
>>> #############################################################
>>> 
>>> set.seed(825)
>>> 
>>> fitControl <- trainControl(## 10-fold CV
>>>                          method = "repeatedcv",
>>>                          number = 10,
>>>                          ## repeated ten times
>>>                          repeats = 10)
>>> 
>>> gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9),
>>>                       n.trees = (1:30)*50,
>>>                       shrinkage = 0.05)
>>> 
>>> nrow(gbmGrid)
>>> 
>>> gbmFit <- train(Ca+P+pH+SOC+Sand~ ., data = training,
>>>                method = "gbm",
>>>                trControl = fitControl,
>>>                ## This last option is actually one
>>>                ## for gbm() that passes through
>>>                verbose = TRUE,
>>> ## Now specify the exact models                 ## to evaludate:
>>>                tuneGrid = gbmGrid
>>>                )
>>> 
>>> #############################################################
>>> 
>>> I am trying to tune a model that predicts the values of 5 columns
>>> whose names are "Ca","P","pH", "SOC", and "Sand".
>>> 
>>> 1) Am I using the formula syntax in a correct way?
>>> 
>>> I then try to apply my model on the test data by coding
>>> 
>>> mypred <- predict(gbmFit, newdata=test)
>>> 
>>> However, at this point I am left with a couple of questions
>>> 
>>> 2) does "predict" automatically select the best tuned model in gbmFit?
>>> and if not, what am I supposed to do?
>>> 3) I do not get any error messages, but mypred consists of a single
>>> column instead of 5 columns corresponding to the 5 variables I am
>>> trying to predict, so something is obviously wrong (see point 1). Any
>>> suggestions here?
>>> 
>>> Many thanks
>>> 
>>> Lorenzo
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> -- 
>> Jia Xu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wickedpuppy at gmail.com  Mon Oct  6 03:50:11 2014
From: wickedpuppy at gmail.com (billy am)
Date: Mon, 6 Oct 2014 09:50:11 +0800
Subject: [R] Removing description from lm()
In-Reply-To: <9CBE021A-9662-4422-96B3-67AB587EE210@comcast.net>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
	<9CBE021A-9662-4422-96B3-67AB587EE210@comcast.net>
Message-ID: <CAJ_FNV6Ed9nNzOdmMc8Vn6aYqayQs1k5Aw27fGGdiss+yw2a5w@mail.gmail.com>

Hi David ,

coef alone won't do as it still contains the description. As per the
example in ?coef shows ,

> x <- 1:5; coef(lm(c(1:3, 7, 6) ~ x))(Intercept)           x
       -0.7         1.5



Unless I use cat again ,

> x <- 1:5; cat(coef(lm(c(1:3, 7, 6) ~ x))[1])-0.7


Thanks!
Billy



On Mon, Oct 6, 2014 at 8:42 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

> ?coef
>
> Sent from my iPhone
>
> > On Oct 5, 2014, at 4:21 AM, billy am <wickedpuppy at gmail.com> wrote:
> >
> > Hi ,
> >
> > When I run the following code , I get both the description and the value
> ,
> > eg : Intercept and 0.5714286.
> >
> > Is there a way to extract just the value 0.5714286? Thanks!
> >
> >
> >> x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)
> > Call:
> > lm(formula = x ~ y)
> >
> > Coefficients:
> > (Intercept)            y
> >     0.5714       0.4286
> >> lm(x~y)$coefficient[1](Intercept)
> >  0.5714286
> >
> >
> >>
> >
> > Regards
> > Billy
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From johannes at huesing.name  Mon Oct  6 08:42:44 2014
From: johannes at huesing.name (Johannes Huesing)
Date: Mon, 6 Oct 2014 08:42:44 +0200
Subject: [R] R coredumps when calling functions from rms package
Message-ID: <20141006064244.GA1468@huesing.name>

My wife is trying to run some bootstrap model validation. She is using 
code to the effect of

library(rms)

residual <- sasxport.get("~/R_boot/residual.xpt") 

c1.odat <- somers2(residual$risk.5, residual$caco)["C"]        # c - statistic for original risk estimate in full sample #

fitboot <- function(data) {
                logitfit= lrm ( ... some model ..., data=data)

                absrisk.boot <- data$risk.5 * exp(predict(logitfit,data=data, type='lp') - logitfit$coefficients["Intercept"])

                ni  <- improveProb(x1=data$risk.5, x2=absrisk.boot,y=data$caco) 
                nri.boot <- ni[8]    
                idi.boot <- ni[19]
                # a half-sentence in the documentation tells us that this NRI is calculated independently of risk limits

                c1.boot <- somers2(data$risk.5, data$caco)["C"]        # c - statistic for absolute risk in the i.th sample #
                c2.boot <- somers2(absrisk.boot, data$caco)["C"]        # c - statistic for new risk estimate in the i.th sample #
			deltac.boot <- c2.boot - c1.boot				# delta-c

                absrisk.original <- residual$risk.5 * exp(predict(logitfit,data=residual, type='lp') - logitfit$coefficients["Intercept"])

                ni.Odat  = improveProb(x1=residual$risk.5, x2=absrisk.original, y=residual$caco) 
                nri.odat = ni.Odat[8]                                     
                idi.odat = ni.Odat[19]
                # a half-sentence in the documentation tells us that this NRI is calculated independently of risk limits

                c2.odat <- somers2(absrisk.original, residual$caco)["C"]      # c - statistic for new risk score on original sample 
			deltac.odat <- c2.odat - c1.odat					# delta c full sample	

                result.both <- unlist(c(nri.boot = nri.boot, idi.boot = idi.boot, deltac.boot = deltac.boot, nri.odat = nri.odat, idi.odat = idi.odat, deltac.odat = deltac.odat))             
		# combining results of NRI, IDI and C-statistics from full sample, putting the values to the data frame called 'result.both' 
                result.both
                }

set.seed(1111)

anziter <- 100

boot.res <- matrix(nrow=anziter, ncol=6)


for (i in 1:anziter) {
    boot.id <- sample(nrow(residual), nrow(residual), replace = TRUE)
    bootdat <- residual[boot.id, ]
    boot.res[i, ] <- fitboot(bootdat)
}

When run within Rgui under Windows, Rgui will terminate showing a
dialog promising that Rgui is faulty and she will be notified once
this is fixed. When run from Rscript within the Powershell, Rscript
will terminate with a message where "Rgui" is replaced by
"Rscript". When run on a different machine within Ubuntu (Trusty
Tahr), R will complain that Hmisc is in a version not recent enough
(which seems to be a problem with the current Ubuntu LTS
distribution). After fixing it, R (run within Emacs) will terminate
with a memory address error, offering a core dump.

Tossing in some trace instructions will reveal that the problems seem
to occur after entering the predict() or improveProb() function
body. In fact, when run from ESS it will print a backtrace revealing
that it was in the middle of predict(). Sometimes (even without
altering the seed) R will terminate the script with the message "GC
encountered a node (?) with an unknown SEXP type", but this has been
observed only in the Rgui calls. 

Is there a way to trap these occurrences and continue the script, 
ignoring all runs that lead to unforeseen behaviour? (So far I have 
suggested to save() the whole matrix of intermediate results to 
a file after each run, and start the script as a cron job every 
five minutes, and compile all the results to one big array after
sufficiently enough successful iterations.)

-- 
Johannes H?sing               There is something fascinating about science. 
                              One gets such wholesale returns of conjecture 
mailto:johannes at huesing.name  from such a trifling investment of fact.                
http://derwisch.wikidot.com         (Mark Twain, "Life on the Mississippi")


From miaojpm at gmail.com  Mon Oct  6 11:50:28 2014
From: miaojpm at gmail.com (jpm miao)
Date: Mon, 6 Oct 2014 17:50:28 +0800
Subject: [R] aggregating a zoo object (monthly data to quarterly data)
Message-ID: <CABcx46DDEzEpAXF3g+O1y0BtCR=VQo4777su7WfsDD09eusimw@mail.gmail.com>

I tried to convert a monthly dataset to quarterly by averaging

dt_mz<-zoo(dt_m, dt_m$date_m)
dt_mz2q<-aggregate(dt_mz, as.yearqtr, FUN=mean)

However, the resulting zoo object are just NAs

How can I get a quarterly average dataset?
Thanks!

> dput(dt_mz)
structure(c("Jan 1981", "Feb 1981", "Mar 1981", "Apr 1981", "May 1981",
"Jun 1981", "Jul 1981", "Aug 1981", "Sep 1981", "Oct 1981", "Nov 1981",
"Dec 1981", "Jan 1982", "Feb 1982", "Mar 1982", "Apr 1982", "May 1982",
"Jun 1982", "Jul 1982", "Aug 1982", "Sep 1982", "Oct 1982", "Nov 1982",
"Dec 1982", "Jan 1983", "Feb 1983", "Mar 1983", "Apr 1983", "May 1983",
"Jun 1983", "Jul 1983", "Aug 1983", "Sep 1983", "Oct 1983", "Nov 1983",
"Dec 1983", "Jan 1984", "Feb 1984", "Mar 1984", "Apr 1984", "May 1984",
"Jun 1984", "Jul 1984", "Aug 1984", "Sep 1984", "Oct 1984", "Nov 1984",
"Dec 1984", "Jan 1985", "Feb 1985", "Mar 1985", "Apr 1985", "May 1985",
"Jun 1985", "Jul 1985", "Aug 1985", "Sep 1985", "Oct 1985", "Nov 1985",
"Dec 1985", "Jan 1986", "Feb 1986", "Mar 1986", "Apr 1986", "May 1986",
"Jun 1986", "Jul 1986", "Aug 1986", "Sep 1986", "Oct 1986", "Nov 1986",
"Dec 1986", "Jan 1987", "Feb 1987", "Mar 1987", "Apr 1987", "May 1987",
"Jun 1987", "Jul 1987", "Aug 1987", "Sep 1987", "Oct 1987", "Nov 1987",
"Dec 1987", "Jan 1988", "Feb 1988", "Mar 1988", "Apr 1988", "May 1988",
"Jun 1988", "Jul 1988", "Aug 1988", "Sep 1988", "Oct 1988", "Nov 1988",
"Dec 1988", "Jan 1989", "Feb 1989", "Mar 1989", "Apr 1989", "May 1989",
"Jun 1989", "Jul 1989", "Aug 1989", "Sep 1989", "Oct 1989", "Nov 1989",
"Dec 1989", "Jan 1990", "Feb 1990", "Mar 1990", "Apr 1990", "May 1990",
"Jun 1990", "Jul 1990", "Aug 1990", "Sep 1990", "Oct 1990", "Nov 1990",
"Dec 1990", "Jan 1991", "Feb 1991", "Mar 1991", "Apr 1991", "May 1991",
"Jun 1991", "Jul 1991", "Aug 1991", "Sep 1991", "Oct 1991", "Nov 1991",
"Dec 1991", "Jan 1992", "Feb 1992", "Mar 1992", "Apr 1992", "May 1992",
"Jun 1992", "Jul 1992", "Aug 1992", "Sep 1992", "Oct 1992", "Nov 1992",
"Dec 1992", "Jan 1993", "Feb 1993", "Mar 1993", "Apr 1993", "May 1993",
"Jun 1993", "Jul 1993", "Aug 1993", "Sep 1993", "Oct 1993", "Nov 1993",
"Dec 1993", "Jan 1994", "Feb 1994", "Mar 1994", "Apr 1994", "May 1994",
"Jun 1994", "Jul 1994", "Aug 1994", "Sep 1994", "Oct 1994", "Nov 1994",
"Dec 1994", "Jan 1995", "Feb 1995", "Mar 1995", "Apr 1995", "May 1995",
"Jun 1995", "Jul 1995", "Aug 1995", "Sep 1995", "Oct 1995", "Nov 1995",
"Dec 1995", "Jan 1996", "Feb 1996", "Mar 1996", "Apr 1996", "May 1996",
"Jun 1996", "Jul 1996", "Aug 1996", "Sep 1996", "Oct 1996", "Nov 1996",
"Dec 1996", "Jan 1997", "Feb 1997", "Mar 1997", "Apr 1997", "May 1997",
"Jun 1997", "Jul 1997", "Aug 1997", "Sep 1997", "Oct 1997", "Nov 1997",
"Dec 1997", "Jan 1998", "Feb 1998", "Mar 1998", "Apr 1998", "May 1998",
"Jun 1998", "Jul 1998", "Aug 1998", "Sep 1998", "Oct 1998", "Nov 1998",
"Dec 1998", "Jan 1999", "Feb 1999", "Mar 1999", "Apr 1999", "May 1999",
"Jun 1999", "Jul 1999", "Aug 1999", "Sep 1999", "Oct 1999", "Nov 1999",
"Dec 1999", "Jan 2000", "Feb 2000", "Mar 2000", "Apr 2000", "May 2000",
"Jun 2000", "Jul 2000", "Aug 2000", "Sep 2000", "Oct 2000", "Nov 2000",
"Dec 2000", "Jan 2001", "Feb 2001", "Mar 2001", "Apr 2001", "May 2001",
"Jun 2001", "Jul 2001", "Aug 2001", "Sep 2001", "Oct 2001", "Nov 2001",
"Dec 2001", "Jan 2002", "Feb 2002", "Mar 2002", "Apr 2002", "May 2002",
"Jun 2002", "Jul 2002", "Aug 2002", "Sep 2002", "Oct 2002", "Nov 2002",
"Dec 2002", "Jan 2003", "Feb 2003", "Mar 2003", "Apr 2003", "May 2003",
"Jun 2003", "Jul 2003", "Aug 2003", "Sep 2003", "Oct 2003", "Nov 2003",
"Dec 2003", "Jan 2004", "Feb 2004", "Mar 2004", "Apr 2004", "May 2004",
"Jun 2004", "Jul 2004", "Aug 2004", "Sep 2004", "Oct 2004", "Nov 2004",
"Dec 2004", "Jan 2005", "Feb 2005", "Mar 2005", "Apr 2005", "May 2005",
"Jun 2005", "Jul 2005", "Aug 2005", "Sep 2005", "Oct 2005", "Nov 2005",
"Dec 2005", "Jan 2006", "Feb 2006", "Mar 2006", "Apr 2006", "May 2006",
"Jun 2006", "Jul 2006", "Aug 2006", "Sep 2006", "Oct 2006", "Nov 2006",
"Dec 2006", "Jan 2007", "Feb 2007", "Mar 2007", "Apr 2007", "May 2007",
"Jun 2007", "Jul 2007", "Aug 2007", "Sep 2007", "Oct 2007", "Nov 2007",
"Dec 2007", "Jan 2008", "Feb 2008", "Mar 2008", "Apr 2008", "May 2008",
"Jun 2008", "Jul 2008", "Aug 2008", "Sep 2008", "Oct 2008", "Nov 2008",
"Dec 2008", "Jan 2009", "Feb 2009", "Mar 2009", "Apr 2009", "May 2009",
"Jun 2009", "Jul 2009", "Aug 2009", "Sep 2009", "Oct 2009", "Nov 2009",
"Dec 2009", "Jan 2010", "Feb 2010", "Mar 2010", "Apr 2010", "May 2010",
"Jun 2010", "Jul 2010", "Aug 2010", "Sep 2010", "Oct 2010", "Nov 2010",
"Dec 2010", "Jan 2011", "Feb 2011", "Mar 2011", "Apr 2011", "May 2011",
"Jun 2011", "Jul 2011", "Aug 2011", "Sep 2011", "Oct 2011", "Nov 2011",
"Dec 2011", "Jan 2012", "Feb 2012", "Mar 2012", "Apr 2012", "May 2012",
"Jun 2012", "Jul 2012", "Aug 2012", "Sep 2012", "Oct 2012", "Nov 2012",
"Dec 2012", "Jan 2013", "Feb 2013", "Mar 2013", "Apr 2013", "May 2013",
"Jun 2013", "Jul 2013", "Aug 2013", "Sep 2013", "Oct 2013", "Nov 2013",
"Dec 2013", "Jan 2014", "Feb 2014", "Mar 2014", "Apr 2014", "May 2014",
"Jun 2014", "Jul 2014", "Aug 2014", " 58.05", " 59.04", " 59.30",
" 59.54", " 59.31", " 59.87", " 60.10", " 60.69", " 61.42", " 61.08",
" 60.67", " 60.59", " 60.98", " 60.79", " 60.94", " 61.10", " 61.47",
" 61.60", " 61.56", " 63.42", " 62.84", " 62.33", " 61.83", " 62.06",
" 62.08", " 62.70", " 62.96", " 63.24", " 62.80", " 63.27", " 62.56",
" 62.53", " 62.72", " 62.70", " 62.17", " 61.32", " 61.37", " 61.98",
" 62.15", " 62.27", " 63.03", " 62.97", " 62.81", " 63.04", " 63.25",
" 62.99", " 62.64", " 62.33", " 62.36", " 62.86", " 62.89", " 62.58",
" 62.38", " 62.29", " 62.35", " 62.08", " 63.11", " 63.05", " 62.16",
" 61.52", " 62.10", " 62.27", " 62.26", " 62.42", " 62.50", " 62.66",
" 62.50", " 62.85", " 64.44", " 64.31", " 63.41", " 63.13", " 62.96",
" 62.84", " 62.34", " 62.56", " 62.57", " 62.62", " 63.34", " 63.86",
" 64.09", " 63.51", " 63.69", " 64.35", " 63.31", " 63.06", " 62.70",
" 62.78", " 63.49", " 63.88", " 63.88", " 64.78", " 64.99", " 65.45",
" 65.12", " 65.06", " 65.06", " 65.63", " 65.79", " 66.38", " 66.87",
" 66.69", " 66.38", " 66.93", " 68.69", " 69.34", " 67.56", " 67.10",
" 67.57", " 67.47", " 67.98", " 68.65", " 69.36", " 69.10", " 69.56",
" 70.72", " 73.17", " 71.59", " 70.21", " 70.16", " 70.94", " 71.36",
" 71.01", " 71.47", " 71.72", " 71.88", " 72.38", " 72.55", " 72.65",
" 73.37", " 73.59", " 72.88", " 73.61", " 74.26", " 74.35", " 75.56",
" 75.82", " 75.61", " 75.06", " 74.72", " 77.13", " 77.10", " 75.87",
" 75.37", " 76.30", " 76.53", " 76.77", " 77.65", " 77.39", " 78.89",
" 77.53", " 77.20", " 77.70", " 78.04", " 78.21", " 78.86", " 78.52",
" 79.54", " 79.32", " 80.04", " 80.78", " 80.58", " 80.74", " 82.65",
" 82.90", " 82.00", " 81.25", " 80.95", " 82.63", " 82.27", " 82.38",
" 83.59", " 83.44", " 84.34", " 83.85", " 84.06", " 84.56", " 84.35",
" 84.69", " 84.65", " 84.52", " 85.36", " 84.86", " 85.95", " 85.84",
" 86.35", " 85.06", " 88.30", " 87.81", " 87.46", " 87.40", " 86.79",
" 86.19", " 87.11", " 85.79", " 86.38", " 86.49", " 87.93", " 87.88",
" 87.79", " 88.36", " 87.18", " 86.94", " 87.02", " 87.91", " 87.37",
" 87.91", " 88.21", " 87.93", " 89.20", " 88.62", " 88.18", " 88.72",
" 89.43", " 90.34", " 88.86", " 88.26", " 89.20", " 87.50", " 88.12",
" 88.36", " 88.45", " 87.89", " 89.19", " 89.24", " 89.79", " 89.53",
" 88.99", " 88.71", " 90.02", " 88.48", " 89.22", " 89.77", " 89.65",
" 89.16", " 89.44", " 90.69", " 90.71", " 91.55", " 90.46", " 90.80",
" 89.10", " 88.86", " 89.59", " 89.57", " 89.52", " 89.25", " 89.84",
" 90.22", " 91.59", " 90.51", " 88.93", " 89.28", " 90.36", " 88.87",
" 89.78", " 89.34", " 89.61", " 89.62", " 89.59", " 89.53", " 90.03",
" 90.00", " 89.61", " 90.25", " 88.99", " 88.71", " 89.68", " 89.63",
" 89.11", " 88.74", " 89.07", " 89.34", " 89.98", " 89.58", " 89.56",
" 90.26", " 89.56", " 89.50", " 90.53", " 90.45", " 90.66", " 91.70",
" 91.34", " 91.83", " 92.13", " 90.95", " 91.01", " 90.70", " 91.30",
" 91.56", " 92.02", " 92.53", " 92.82", " 93.90", " 94.60", " 94.73",
" 94.66", " 93.23", " 93.02", " 93.12", " 92.20", " 91.94", " 93.15",
" 94.00", " 94.43", " 94.64", " 94.07", " 93.56", " 93.53", " 93.45",
" 93.65", " 93.45", " 93.81", " 92.72", " 93.79", " 93.98", " 94.55",
" 94.33", " 95.58", " 96.47", " 98.52", " 97.94", " 96.77", " 96.20",
" 97.43", " 96.38", " 97.42", " 97.47", " 99.25", " 99.81", "100.06",
" 99.46", "100.87", " 99.83", " 97.99", " 97.62", " 96.13", " 96.24",
" 96.97", " 97.38", " 97.29", " 97.48", " 99.24", " 98.58", " 98.96",
" 98.22", " 97.75", " 97.87", " 98.39", " 97.45", " 98.27", " 98.12",
" 98.45", " 98.76", " 98.77", " 98.87", " 99.52", " 99.71", " 98.96",
" 98.95", " 99.69", " 98.82", " 99.56", " 99.75", "100.37", "100.07",
"100.10", "100.23", "100.77", "100.74", "100.97", "101.28", " 99.94",
"100.06", "100.99", "101.49", "102.14", "102.53", "103.53", "103.19",
"103.12", "102.34", "102.59", "102.41", "102.90", "101.42", "102.05",
"102.24", "102.75", "102.59", "102.72", "104.06", "103.78", "103.04",
"102.94", "103.26", "102.86", "103.05", "103.74", "103.90", "104.43",
"104.40", "104.85", "15.690", "14.810", "13.260", "15.120", "15.720",
"15.980", "14.630", "14.980", "12.560", "12.390", "11.500", "10.940",
"12.890", "14.830", "11.720", "11.870", "11.990", "12.900", " 9.570",
"11.100", " 8.900", " 8.790", " 8.460", " 8.380", " 7.090", " 8.160",
" 6.660", " 6.710", " 6.720", " 7.140", " 7.390", " 7.530", " 6.120",
" 6.390", " 6.000", " 6.420", " 8.100", " 8.450", " 7.230", " 6.510",
" 5.050", " 5.900", " 6.780", " 5.470", " 6.700", " 5.040", " 6.050",
" 6.610", " 6.590", " 8.350", " 6.370", " 5.417", " 6.025", " 5.427",
" 5.631", " 7.827", " 5.883", " 5.000", " 5.000", " 5.000", " 5.080",
" 5.010", " 3.570", " 3.640", " 3.500", " 4.320", " 3.500", " 3.500",
" 3.500", " 3.730", " 3.370", " 4.000", " 3.780", " 3.570", " 3.270",
" 3.650", " 3.730", " 3.450", " 5.280", " 4.030", " 4.210", " 3.640",
" 3.570", " 4.560", " 5.110", " 5.520", " 5.370", " 5.230", " 4.370",
" 5.650", " 5.410", " 3.970", " 4.190", " 3.890", " 3.510", " 4.210",
" 3.800", " 4.420", " 3.640", "10.850", "11.210", " 7.950", " 7.230",
" 8.750", " 7.060", " 8.590", " 5.490", " 5.660", "10.680", "13.030",
"13.670", "11.620", " 9.160", "11.170", "11.680", "10.040", " 6.670",
" 5.410", " 5.870", " 6.270", " 6.280", " 8.020", " 7.240", " 8.090",
" 8.430", " 8.290", " 7.870", " 8.390", " 7.040", " 4.911", " 6.829",
" 6.328", " 5.556", " 6.892", " 6.672", " 6.679", " 7.947", " 8.530",
" 7.024", " 7.132", " 6.617", " 6.072", " 5.636", " 7.037", " 7.726",
" 6.918", " 7.007", " 7.184", " 6.913", " 6.079", " 5.914", " 6.080",
" 5.082", " 6.002", " 5.700", " 5.648", " 6.721", " 7.070", " 5.524",
" 5.514", " 5.154", " 5.493", " 6.471", " 8.400", " 7.503", " 6.847",
" 5.347", " 5.583", " 6.145", " 5.687", " 6.167", " 6.553", " 5.996",
" 5.698", " 5.353", " 6.458", " 7.943", " 6.510", " 6.257", " 6.042",
" 5.705", " 6.103", " 6.082", " 5.931", " 5.453", " 5.089", " 5.043",
" 5.453", " 5.099", " 4.930", " 5.053", " 5.147", " 5.653", " 6.660",
" 6.188", " 6.562", " 5.663", " 7.208", " 7.107", " 8.112", " 7.555",
" 7.816", " 7.116", " 6.666", " 7.312", " 7.222", " 6.931", " 6.800",
" 6.877", " 6.837", " 6.748", " 6.673", " 6.521", " 6.061", " 5.401",
" 4.954", " 4.848", " 4.747", " 4.730", " 4.723", " 4.696", " 4.737",
" 4.835", " 4.841", " 4.837", " 4.817", " 4.825", " 4.730", " 4.614",
" 4.611", " 4.643", " 4.645", " 4.771", " 4.797", " 4.785", " 4.754",
" 4.799", " 4.758", " 4.739", " 4.720", " 4.655", " 4.517", " 4.360",
" 4.227", " 4.037", " 3.895", " 3.686", " 3.513", " 3.173", " 2.727",
" 2.486", " 2.390", " 2.299", " 2.277", " 2.273", " 2.265", " 2.215",
" 2.071", " 1.937", " 1.960", " 1.947", " 1.933", " 1.794", " 1.614",
" 1.302", " 1.258", " 1.203", " 1.188", " 1.181", " 1.156", " 1.027",
" 1.024", " 1.021", " 1.024", " 1.022", " 1.025", " 1.008", " 0.984",
" 0.991", " 0.972", " 0.967", " 1.018", " 1.024", " 1.048", " 1.084",
" 1.142", " 1.141", " 1.149", " 1.202", " 1.203", " 1.221", " 1.267",
" 1.266", " 1.265", " 1.324", " 1.324", " 1.365", " 1.388", " 1.387",
" 1.406", " 1.446", " 1.449", " 1.450", " 1.516", " 1.517", " 1.533",
" 1.586", " 1.587", " 1.595", " 1.658", " 1.663", " 1.661", " 1.689",
" 1.691", " 1.703", " 1.725", " 2.132", " 2.496", " 2.006", " 2.007",
" 2.019", " 2.038", " 2.038", " 2.054", " 2.088", " 2.082", " 2.084",
" 2.105", " 2.101", " 2.105", " 2.166", " 2.158", " 2.092", " 1.926",
" 1.410", " 0.872", " 0.233", " 0.143", " 0.137", " 0.131", " 0.097",
" 0.097", " 0.100", " 0.101", " 0.100", " 0.101", " 0.104", " 0.106",
" 0.108", " 0.104", " 0.130", " 0.164", " 0.174", " 0.183", " 0.196",
" 0.203", " 0.210", " 0.226", " 0.231", " 0.239", " 0.257", " 0.262",
" 0.274", " 0.296", " 0.319", " 0.344", " 0.375", " 0.388", " 0.394",
" 0.395", " 0.396", " 0.400", " 0.403", " 0.399", " 0.402", " 0.476",
" 0.512", " 0.513", " 0.445", " 0.388", " 0.389", " 0.388", " 0.386",
" 0.388", " 0.387", " 0.387", " 0.387", " 0.386", " 0.386", " 0.386",
" 0.386", " 0.386", " 0.386", " 0.387", " 0.386", " 0.387", " 0.388",
" 0.387", " 0.387", " 0.387", " 0.388", " 0.387", " 0.387", " 0.386"
), .Dim = c(404L, 3L), .Dimnames = list(NULL, c("date_m", "CPI",
"ONI")), index = structure(c(1981, 1981.08333333333, 1981.16666666667,
1981.25, 1981.33333333333, 1981.41666666667, 1981.5, 1981.58333333333,
1981.66666666667, 1981.75, 1981.83333333333, 1981.91666666667,
1982, 1982.08333333333, 1982.16666666667, 1982.25, 1982.33333333333,
1982.41666666667, 1982.5, 1982.58333333333, 1982.66666666667,
1982.75, 1982.83333333333, 1982.91666666667, 1983, 1983.08333333333,
1983.16666666667, 1983.25, 1983.33333333333, 1983.41666666667,
1983.5, 1983.58333333333, 1983.66666666667, 1983.75, 1983.83333333333,
1983.91666666667, 1984, 1984.08333333333, 1984.16666666667, 1984.25,
1984.33333333333, 1984.41666666667, 1984.5, 1984.58333333333,
1984.66666666667, 1984.75, 1984.83333333333, 1984.91666666667,
1985, 1985.08333333333, 1985.16666666667, 1985.25, 1985.33333333333,
1985.41666666667, 1985.5, 1985.58333333333, 1985.66666666667,
1985.75, 1985.83333333333, 1985.91666666667, 1986, 1986.08333333333,
1986.16666666667, 1986.25, 1986.33333333333, 1986.41666666667,
1986.5, 1986.58333333333, 1986.66666666667, 1986.75, 1986.83333333333,
1986.91666666667, 1987, 1987.08333333333, 1987.16666666667, 1987.25,
1987.33333333333, 1987.41666666667, 1987.5, 1987.58333333333,
1987.66666666667, 1987.75, 1987.83333333333, 1987.91666666667,
1988, 1988.08333333333, 1988.16666666667, 1988.25, 1988.33333333333,
1988.41666666667, 1988.5, 1988.58333333333, 1988.66666666667,
1988.75, 1988.83333333333, 1988.91666666667, 1989, 1989.08333333333,
1989.16666666667, 1989.25, 1989.33333333333, 1989.41666666667,
1989.5, 1989.58333333333, 1989.66666666667, 1989.75, 1989.83333333333,
1989.91666666667, 1990, 1990.08333333333, 1990.16666666667, 1990.25,
1990.33333333333, 1990.41666666667, 1990.5, 1990.58333333333,
1990.66666666667, 1990.75, 1990.83333333333, 1990.91666666667,
1991, 1991.08333333333, 1991.16666666667, 1991.25, 1991.33333333333,
1991.41666666667, 1991.5, 1991.58333333333, 1991.66666666667,
1991.75, 1991.83333333333, 1991.91666666667, 1992, 1992.08333333333,
1992.16666666667, 1992.25, 1992.33333333333, 1992.41666666667,
1992.5, 1992.58333333333, 1992.66666666667, 1992.75, 1992.83333333333,
1992.91666666667, 1993, 1993.08333333333, 1993.16666666667, 1993.25,
1993.33333333333, 1993.41666666667, 1993.5, 1993.58333333333,
1993.66666666667, 1993.75, 1993.83333333333, 1993.91666666667,
1994, 1994.08333333333, 1994.16666666667, 1994.25, 1994.33333333333,
1994.41666666667, 1994.5, 1994.58333333333, 1994.66666666667,
1994.75, 1994.83333333333, 1994.91666666667, 1995, 1995.08333333333,
1995.16666666667, 1995.25, 1995.33333333333, 1995.41666666667,
1995.5, 1995.58333333333, 1995.66666666667, 1995.75, 1995.83333333333,
1995.91666666667, 1996, 1996.08333333333, 1996.16666666667, 1996.25,
1996.33333333333, 1996.41666666667, 1996.5, 1996.58333333333,
1996.66666666667, 1996.75, 1996.83333333333, 1996.91666666667,
1997, 1997.08333333333, 1997.16666666667, 1997.25, 1997.33333333333,
1997.41666666667, 1997.5, 1997.58333333333, 1997.66666666667,
1997.75, 1997.83333333333, 1997.91666666667, 1998, 1998.08333333333,
1998.16666666667, 1998.25, 1998.33333333333, 1998.41666666667,
1998.5, 1998.58333333333, 1998.66666666667, 1998.75, 1998.83333333333,
1998.91666666667, 1999, 1999.08333333333, 1999.16666666667, 1999.25,
1999.33333333333, 1999.41666666667, 1999.5, 1999.58333333333,
1999.66666666667, 1999.75, 1999.83333333333, 1999.91666666667,
2000, 2000.08333333333, 2000.16666666667, 2000.25, 2000.33333333333,
2000.41666666667, 2000.5, 2000.58333333333, 2000.66666666667,
2000.75, 2000.83333333333, 2000.91666666667, 2001, 2001.08333333333,
2001.16666666667, 2001.25, 2001.33333333333, 2001.41666666667,
2001.5, 2001.58333333333, 2001.66666666667, 2001.75, 2001.83333333333,
2001.91666666667, 2002, 2002.08333333333, 2002.16666666667, 2002.25,
2002.33333333333, 2002.41666666667, 2002.5, 2002.58333333333,
2002.66666666667, 2002.75, 2002.83333333333, 2002.91666666667,
2003, 2003.08333333333, 2003.16666666667, 2003.25, 2003.33333333333,
2003.41666666667, 2003.5, 2003.58333333333, 2003.66666666667,
2003.75, 2003.83333333333, 2003.91666666667, 2004, 2004.08333333333,
2004.16666666667, 2004.25, 2004.33333333333, 2004.41666666667,
2004.5, 2004.58333333333, 2004.66666666667, 2004.75, 2004.83333333333,
2004.91666666667, 2005, 2005.08333333333, 2005.16666666667, 2005.25,
2005.33333333333, 2005.41666666667, 2005.5, 2005.58333333333,
2005.66666666667, 2005.75, 2005.83333333333, 2005.91666666667,
2006, 2006.08333333333, 2006.16666666667, 2006.25, 2006.33333333333,
2006.41666666667, 2006.5, 2006.58333333333, 2006.66666666667,
2006.75, 2006.83333333333, 2006.91666666667, 2007, 2007.08333333333,
2007.16666666667, 2007.25, 2007.33333333333, 2007.41666666667,
2007.5, 2007.58333333333, 2007.66666666667, 2007.75, 2007.83333333333,
2007.91666666667, 2008, 2008.08333333333, 2008.16666666667, 2008.25,
2008.33333333333, 2008.41666666667, 2008.5, 2008.58333333333,
2008.66666666667, 2008.75, 2008.83333333333, 2008.91666666667,
2009, 2009.08333333333, 2009.16666666667, 2009.25, 2009.33333333333,
2009.41666666667, 2009.5, 2009.58333333333, 2009.66666666667,
2009.75, 2009.83333333333, 2009.91666666667, 2010, 2010.08333333333,
2010.16666666667, 2010.25, 2010.33333333333, 2010.41666666667,
2010.5, 2010.58333333333, 2010.66666666667, 2010.75, 2010.83333333333,
2010.91666666667, 2011, 2011.08333333333, 2011.16666666667, 2011.25,
2011.33333333333, 2011.41666666667, 2011.5, 2011.58333333333,
2011.66666666667, 2011.75, 2011.83333333333, 2011.91666666667,
2012, 2012.08333333333, 2012.16666666667, 2012.25, 2012.33333333333,
2012.41666666667, 2012.5, 2012.58333333333, 2012.66666666667,
2012.75, 2012.83333333333, 2012.91666666667, 2013, 2013.08333333333,
2013.16666666667, 2013.25, 2013.33333333333, 2013.41666666667,
2013.5, 2013.58333333333, 2013.66666666667, 2013.75, 2013.83333333333,
2013.91666666667, 2014, 2014.08333333333, 2014.16666666667, 2014.25,
2014.33333333333, 2014.41666666667, 2014.5, 2014.58333333333), class =
"yearmon"), class = "zoo")

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Mon Oct  6 19:34:06 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 6 Oct 2014 12:34:06 -0500
Subject: [R] Hadley's book: paper/PDF/etc. versus github
In-Reply-To: <CAFEqCdyoXir7VhyPuOpf4tMPJsxpyn5Cd7srfUj65XWq+3Y_VA@mail.gmail.com>
References: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>
	<CABdHhvGVFx+jHavTqO1XUiSqFLisWewEkw032Ou34B+jKMbE8Q@mail.gmail.com>
	<CAFEqCdyoXir7VhyPuOpf4tMPJsxpyn5Cd7srfUj65XWq+3Y_VA@mail.gmail.com>
Message-ID: <CABdHhvGNmradtPoF5_DTLt_ta5cvVVw5QhZm9w4hxHH=ACSpWQ@mail.gmail.com>

Yes, I have, but the scripts would need some tweaking.
Hadley

On Mon, Oct 6, 2014 at 12:28 PM, Greg Snow <538280 at gmail.com> wrote:
> Hadley, have you tried producing the book in other electronic formats
> (other than pdf)? such as epub?  I tried and ended up with a file that
> worked, but all the example code was missing (which defeats the
> convenience of having it on an ebook reader), I did not check if
> everything else was there or not.
>
>  thanks,
>
> On Fri, Oct 3, 2014 at 6:37 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>> Hi, folks.  I've got a sort of coupon that would allow me to get a
>>> copy of "Advanced R" by Hadley Wickham at no cost.  OTOH, I've already
>>> cloned the github repository, and having the "live" Rmd files (or in
>>> this case, rmd files) is enormously more useful to me than having any
>>> form of electronic or paper format.
>>
>> I presume you mean https://github.com/hadley/adv-r (no need to be
>> secretive about it ;)
>>
>>> The only reason I can think of for getting, say, a PDF version of the
>>> book is that corrected versions of such books are sometimes (always?)
>>> made available for free if you've already got the PDF version of the
>>> book.  (I know O'Reilly does this.)
>>
>> The pdf version of the book is made from the files in that repo, so I
>> don't see any advantage there.  (You can build the pdf yourself if you
>> spend a few minutes looking for the right file ;)
>>
>>> But if the github version is going to continue to exist, be updated,
>>> and be generally available, that's even better.  IS it going to exist,
>>> be updated, and be generally available?  Any thoughts?
>>
>> The github version _is_ the authoritative version of the book (and in
>> some sense it's already slightly better than the book, since a number
>> of minor typos have been fixed since the book was published). C&H is
>> mostly print on demand, so later printings of the book are likely to
>> pick up the improvements, although there is still some additional
>> human checking in the process, so it'll only get updated every 6
>> months or so.
>>
>> The repo and http://adv-r.had.co.nz will continue to exist for the
>> foreseeable future.
>>
>> Hadley
>>
>> --
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com



-- 
http://had.co.nz/


From dwinsemius at comcast.net  Mon Oct  6 19:54:37 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Oct 2014 10:54:37 -0700
Subject: [R] Removing description from lm()
In-Reply-To: <CAJ_FNV6Ed9nNzOdmMc8Vn6aYqayQs1k5Aw27fGGdiss+yw2a5w@mail.gmail.com>
References: <CAJ_FNV49YTQtq2V4uxpBGrJGBZt-XKtVFeej=ENVLSA9wabtJg@mail.gmail.com>
	<9CBE021A-9662-4422-96B3-67AB587EE210@comcast.net>
	<CAJ_FNV6Ed9nNzOdmMc8Vn6aYqayQs1k5Aw27fGGdiss+yw2a5w@mail.gmail.com>
Message-ID: <486B3713-692D-4943-B215-905B0C417129@comcast.net>


On Oct 5, 2014, at 6:50 PM, billy am wrote:

> Hi David , 
> 
> coef alone won't do as it still contains the description.

It's not a "description", ; in R parlance it's a "name" although that parlance can be confused since there is also a language class called "name". In this case it's an attribute with the name "names". This is a rather special attribute since R gives you a function for setting and removing the "names" attribute.

?'names<-'


> attributes(coef(lm(c(1:3, 7, 6) ~ x))[1])
$names
[1] "(Intercept)"


> As per the example in ?coef shows ,
> 
> > 
> x <- 1:5; coef(lm(c(1:3, 7, 6) ~ x))
> 
> (Intercept)           x 
>        -0.7         1.5 
> 
> 
> 
> Unless I use cat again , 
> 
> > 
> x <- 1:5; cat(coef(lm(c(1:3, 7, 6) ~ x))[1])
> 
> -0.7
> 

You may be confused about what is happening. The other respondents suggested using `unname` because that function would return a value stripped of the attribute. The `cat` function does not actually return a value; it only creates a side-effect at the console or output to a file:

xcf <- cat(coef(lm(c(1:3, 7, 6) ~ x))[1])
-0.7
> xcf
NULL

So `unname` would be preferable if you were trying to store that value.

-- 
David

> Thanks!
> Billy
> 
> 
> 
> On Mon, Oct 6, 2014 at 8:42 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> ?coef
> 
> Sent from my iPhone
> 
> > On Oct 5, 2014, at 4:21 AM, billy am <wickedpuppy at gmail.com> wrote:
> >
> > Hi ,
> >
> > When I run the following code , I get both the description and the value ,
> > eg : Intercept and 0.5714286.
> >
> > Is there a way to extract just the value 0.5714286? Thanks!
> >
> >
> >> x <- c(1,5,3,1)> y <- c(5,8,2,3)> lm(x~y)
> > Call:
> > lm(formula = x ~ y)
> >
> > Coefficients:
> > (Intercept)            y
> >     0.5714       0.4286
> >> lm(x~y)$coefficient[1](Intercept)
> >  0.5714286
> >
> >
> >>
> >
> > Regards
> > Billy
> >
> >    [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Oct  6 20:02:33 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 6 Oct 2014 11:02:33 -0700
Subject: [R] aggregating a zoo object (monthly data to quarterly data)
In-Reply-To: <CABcx46DDEzEpAXF3g+O1y0BtCR=VQo4777su7WfsDD09eusimw@mail.gmail.com>
References: <CABcx46DDEzEpAXF3g+O1y0BtCR=VQo4777su7WfsDD09eusimw@mail.gmail.com>
Message-ID: <42E15203-2652-4E32-80C0-6F27B51B761A@comcast.net>


On Oct 6, 2014, at 2:50 AM, jpm miao wrote:

> I tried to convert a monthly dataset to quarterly by averaging
> 
> dt_mz<-zoo(dt_m, dt_m$date_m)
> dt_mz2q<-aggregate(dt_mz, as.yearqtr, FUN=mean)
> 
> However, the resulting zoo object are just NAs

Because you put those month values inside the core matrix, you coerced the matrix to character. The mean function was not able to deliver the desired output as a result. Notice all the quotes around the numbers. Go back a few steps and do not add the months to the zoo corematrix.


> 
> How can I get a quarterly average dataset?
> Thanks!
> 
>> dput(dt_mz)
> structure(c("Jan 1981", "Feb 1981", "Mar 1981", "Apr 1981", "May 1981",
> "Jun 1981", "Jul 1981", "Aug 1981", "Sep 1981", "Oct 1981", "Nov 1981",
> "Dec 1981", "Jan 1982", "Feb 1982", "Mar 1982", "Apr 1982", "May 1982",
> "Jun 1982", "Jul 1982", "Aug 1982", "Sep 1982", "Oct 1982", "Nov 1982",
> "Dec 1982", "Jan 1983", "Feb 1983", "Mar 1983", "Apr 1983", "May 1983",
> "Jun 1983", "Jul 1983", "Aug 1983", "Sep 1983", "Oct 1983", "Nov 1983",
> "Dec 1983", "Jan 1984", "Feb 1984", "Mar 1984", "Apr 1984", "May 1984",
> "Jun 1984", "Jul 1984", "Aug 1984", "Sep 1984", "Oct 1984", "Nov 1984",
> "Dec 1984", "Jan 1985", "Feb 1985", "Mar 1985", "Apr 1985", "May 1985",
> "Jun 1985", "Jul 1985", "Aug 1985", "Sep 1985", "Oct 1985", "Nov 1985",
> "Dec 1985", "Jan 1986", "Feb 1986", "Mar 1986", "Apr 1986", "May 1986",
> "Jun 1986", "Jul 1986", "Aug 1986", "Sep 1986", "Oct 1986", "Nov 1986",
> "Dec 1986", "Jan 1987", "Feb 1987", "Mar 1987", "Apr 1987", "May 1987",
> "Jun 1987", "Jul 1987", "Aug 1987", "Sep 1987", "Oct 1987", "Nov 1987",
> "Dec 1987", "Jan 1988", "Feb 1988", "Mar 1988", "Apr 1988", "May 1988",
> "Jun 1988", "Jul 1988", "Aug 1988", "Sep 1988", "Oct 1988", "Nov 1988",
> "Dec 1988", "Jan 1989", "Feb 1989", "Mar 1989", "Apr 1989", "May 1989",
> "Jun 1989", "Jul 1989", "Aug 1989", "Sep 1989", "Oct 1989", "Nov 1989",
> "Dec 1989", "Jan 1990", "Feb 1990", "Mar 1990", "Apr 1990", "May 1990",
> "Jun 1990", "Jul 1990", "Aug 1990", "Sep 1990", "Oct 1990", "Nov 1990",
> "Dec 1990", "Jan 1991", "Feb 1991", "Mar 1991", "Apr 1991", "May 1991",
> "Jun 1991", "Jul 1991", "Aug 1991", "Sep 1991", "Oct 1991", "Nov 1991",
> "Dec 1991", "Jan 1992", "Feb 1992", "Mar 1992", "Apr 1992", "May 1992",
> "Jun 1992", "Jul 1992", "Aug 1992", "Sep 1992", "Oct 1992", "Nov 1992",
> "Dec 1992", "Jan 1993", "Feb 1993", "Mar 1993", "Apr 1993", "May 1993",
> "Jun 1993", "Jul 1993", "Aug 1993", "Sep 1993", "Oct 1993", "Nov 1993",
> "Dec 1993", "Jan 1994", "Feb 1994", "Mar 1994", "Apr 1994", "May 1994",
> "Jun 1994", "Jul 1994", "Aug 1994", "Sep 1994", "Oct 1994", "Nov 1994",
> "Dec 1994", "Jan 1995", "Feb 1995", "Mar 1995", "Apr 1995", "May 1995",
> "Jun 1995", "Jul 1995", "Aug 1995", "Sep 1995", "Oct 1995", "Nov 1995",
> "Dec 1995", "Jan 1996", "Feb 1996", "Mar 1996", "Apr 1996", "May 1996",
> "Jun 1996", "Jul 1996", "Aug 1996", "Sep 1996", "Oct 1996", "Nov 1996",
> "Dec 1996", "Jan 1997", "Feb 1997", "Mar 1997", "Apr 1997", "May 1997",
> "Jun 1997", "Jul 1997", "Aug 1997", "Sep 1997", "Oct 1997", "Nov 1997",
> "Dec 1997", "Jan 1998", "Feb 1998", "Mar 1998", "Apr 1998", "May 1998",
> "Jun 1998", "Jul 1998", "Aug 1998", "Sep 1998", "Oct 1998", "Nov 1998",
> "Dec 1998", "Jan 1999", "Feb 1999", "Mar 1999", "Apr 1999", "May 1999",
> "Jun 1999", "Jul 1999", "Aug 1999", "Sep 1999", "Oct 1999", "Nov 1999",
> "Dec 1999", "Jan 2000", "Feb 2000", "Mar 2000", "Apr 2000", "May 2000",
> "Jun 2000", "Jul 2000", "Aug 2000", "Sep 2000", "Oct 2000", "Nov 2000",
> "Dec 2000", "Jan 2001", "Feb 2001", "Mar 2001", "Apr 2001", "May 2001",
> "Jun 2001", "Jul 2001", "Aug 2001", "Sep 2001", "Oct 2001", "Nov 2001",
> "Dec 2001", "Jan 2002", "Feb 2002", "Mar 2002", "Apr 2002", "May 2002",
> "Jun 2002", "Jul 2002", "Aug 2002", "Sep 2002", "Oct 2002", "Nov 2002",
> "Dec 2002", "Jan 2003", "Feb 2003", "Mar 2003", "Apr 2003", "May 2003",
> "Jun 2003", "Jul 2003", "Aug 2003", "Sep 2003", "Oct 2003", "Nov 2003",
> "Dec 2003", "Jan 2004", "Feb 2004", "Mar 2004", "Apr 2004", "May 2004",
> "Jun 2004", "Jul 2004", "Aug 2004", "Sep 2004", "Oct 2004", "Nov 2004",
> "Dec 2004", "Jan 2005", "Feb 2005", "Mar 2005", "Apr 2005", "May 2005",
> "Jun 2005", "Jul 2005", "Aug 2005", "Sep 2005", "Oct 2005", "Nov 2005",
> "Dec 2005", "Jan 2006", "Feb 2006", "Mar 2006", "Apr 2006", "May 2006",
> "Jun 2006", "Jul 2006", "Aug 2006", "Sep 2006", "Oct 2006", "Nov 2006",
> "Dec 2006", "Jan 2007", "Feb 2007", "Mar 2007", "Apr 2007", "May 2007",
> "Jun 2007", "Jul 2007", "Aug 2007", "Sep 2007", "Oct 2007", "Nov 2007",
> "Dec 2007", "Jan 2008", "Feb 2008", "Mar 2008", "Apr 2008", "May 2008",
> "Jun 2008", "Jul 2008", "Aug 2008", "Sep 2008", "Oct 2008", "Nov 2008",
> "Dec 2008", "Jan 2009", "Feb 2009", "Mar 2009", "Apr 2009", "May 2009",
> "Jun 2009", "Jul 2009", "Aug 2009", "Sep 2009", "Oct 2009", "Nov 2009",
> "Dec 2009", "Jan 2010", "Feb 2010", "Mar 2010", "Apr 2010", "May 2010",
> "Jun 2010", "Jul 2010", "Aug 2010", "Sep 2010", "Oct 2010", "Nov 2010",
> "Dec 2010", "Jan 2011", "Feb 2011", "Mar 2011", "Apr 2011", "May 2011",
> "Jun 2011", "Jul 2011", "Aug 2011", "Sep 2011", "Oct 2011", "Nov 2011",
> "Dec 2011", "Jan 2012", "Feb 2012", "Mar 2012", "Apr 2012", "May 2012",
> "Jun 2012", "Jul 2012", "Aug 2012", "Sep 2012", "Oct 2012", "Nov 2012",
> "Dec 2012", "Jan 2013", "Feb 2013", "Mar 2013", "Apr 2013", "May 2013",
> "Jun 2013", "Jul 2013", "Aug 2013", "Sep 2013", "Oct 2013", "Nov 2013",
> "Dec 2013", "Jan 2014", "Feb 2014", "Mar 2014", "Apr 2014", "May 2014",
> "Jun 2014", "Jul 2014", "Aug 2014", " 58.05", " 59.04", " 59.30",
> " 59.54", " 59.31", " 59.87", " 60.10", " 60.69", " 61.42", " 61.08",
> " 60.67", " 60.59", " 60.98", " 60.79", " 60.94", " 61.10", " 61.47",
> " 61.60", " 61.56", " 63.42", " 62.84", " 62.33", " 61.83", " 62.06",
> " 62.08", " 62.70", " 62.96", " 63.24", " 62.80", " 63.27", " 62.56",
> " 62.53", " 62.72", " 62.70", " 62.17", " 61.32", " 61.37", " 61.98",
> " 62.15", " 62.27", " 63.03", " 62.97", " 62.81", " 63.04", " 63.25",
> " 62.99", " 62.64", " 62.33", " 62.36", " 62.86", " 62.89", " 62.58",
> " 62.38", " 62.29", " 62.35", " 62.08", " 63.11", " 63.05", " 62.16",
> " 61.52", " 62.10", " 62.27", " 62.26", " 62.42", " 62.50", " 62.66",
> " 62.50", " 62.85", " 64.44", " 64.31", " 63.41", " 63.13", " 62.96",
> " 62.84", " 62.34", " 62.56", " 62.57", " 62.62", " 63.34", " 63.86",
> " 64.09", " 63.51", " 63.69", " 64.35", " 63.31", " 63.06", " 62.70",
> " 62.78", " 63.49", " 63.88", " 63.88", " 64.78", " 64.99", " 65.45",
> " 65.12", " 65.06", " 65.06", " 65.63", " 65.79", " 66.38", " 66.87",
> " 66.69", " 66.38", " 66.93", " 68.69", " 69.34", " 67.56", " 67.10",
> " 67.57", " 67.47", " 67.98", " 68.65", " 69.36", " 69.10", " 69.56",
> " 70.72", " 73.17", " 71.59", " 70.21", " 70.16", " 70.94", " 71.36",
> " 71.01", " 71.47", " 71.72", " 71.88", " 72.38", " 72.55", " 72.65",
> " 73.37", " 73.59", " 72.88", " 73.61", " 74.26", " 74.35", " 75.56",
> " 75.82", " 75.61", " 75.06", " 74.72", " 77.13", " 77.10", " 75.87",
> " 75.37", " 76.30", " 76.53", " 76.77", " 77.65", " 77.39", " 78.89",
> " 77.53", " 77.20", " 77.70", " 78.04", " 78.21", " 78.86", " 78.52",
> " 79.54", " 79.32", " 80.04", " 80.78", " 80.58", " 80.74", " 82.65",
> " 82.90", " 82.00", " 81.25", " 80.95", " 82.63", " 82.27", " 82.38",
> " 83.59", " 83.44", " 84.34", " 83.85", " 84.06", " 84.56", " 84.35",
> " 84.69", " 84.65", " 84.52", " 85.36", " 84.86", " 85.95", " 85.84",
> " 86.35", " 85.06", " 88.30", " 87.81", " 87.46", " 87.40", " 86.79",
> " 86.19", " 87.11", " 85.79", " 86.38", " 86.49", " 87.93", " 87.88",
> " 87.79", " 88.36", " 87.18", " 86.94", " 87.02", " 87.91", " 87.37",
> " 87.91", " 88.21", " 87.93", " 89.20", " 88.62", " 88.18", " 88.72",
> " 89.43", " 90.34", " 88.86", " 88.26", " 89.20", " 87.50", " 88.12",
> " 88.36", " 88.45", " 87.89", " 89.19", " 89.24", " 89.79", " 89.53",
> " 88.99", " 88.71", " 90.02", " 88.48", " 89.22", " 89.77", " 89.65",
> " 89.16", " 89.44", " 90.69", " 90.71", " 91.55", " 90.46", " 90.80",
> " 89.10", " 88.86", " 89.59", " 89.57", " 89.52", " 89.25", " 89.84",
> " 90.22", " 91.59", " 90.51", " 88.93", " 89.28", " 90.36", " 88.87",
> " 89.78", " 89.34", " 89.61", " 89.62", " 89.59", " 89.53", " 90.03",
> " 90.00", " 89.61", " 90.25", " 88.99", " 88.71", " 89.68", " 89.63",
> " 89.11", " 88.74", " 89.07", " 89.34", " 89.98", " 89.58", " 89.56",
> " 90.26", " 89.56", " 89.50", " 90.53", " 90.45", " 90.66", " 91.70",
> " 91.34", " 91.83", " 92.13", " 90.95", " 91.01", " 90.70", " 91.30",
> " 91.56", " 92.02", " 92.53", " 92.82", " 93.90", " 94.60", " 94.73",
> " 94.66", " 93.23", " 93.02", " 93.12", " 92.20", " 91.94", " 93.15",
> " 94.00", " 94.43", " 94.64", " 94.07", " 93.56", " 93.53", " 93.45",
> " 93.65", " 93.45", " 93.81", " 92.72", " 93.79", " 93.98", " 94.55",
> " 94.33", " 95.58", " 96.47", " 98.52", " 97.94", " 96.77", " 96.20",
> " 97.43", " 96.38", " 97.42", " 97.47", " 99.25", " 99.81", "100.06",
> " 99.46", "100.87", " 99.83", " 97.99", " 97.62", " 96.13", " 96.24",
> " 96.97", " 97.38", " 97.29", " 97.48", " 99.24", " 98.58", " 98.96",
> " 98.22", " 97.75", " 97.87", " 98.39", " 97.45", " 98.27", " 98.12",
> " 98.45", " 98.76", " 98.77", " 98.87", " 99.52", " 99.71", " 98.96",
> " 98.95", " 99.69", " 98.82", " 99.56", " 99.75", "100.37", "100.07",
> "100.10", "100.23", "100.77", "100.74", "100.97", "101.28", " 99.94",
> "100.06", "100.99", "101.49", "102.14", "102.53", "103.53", "103.19",
> "103.12", "102.34", "102.59", "102.41", "102.90", "101.42", "102.05",
> "102.24", "102.75", "102.59", "102.72", "104.06", "103.78", "103.04",
> "102.94", "103.26", "102.86", "103.05", "103.74", "103.90", "104.43",
> "104.40", "104.85", "15.690", "14.810", "13.260", "15.120", "15.720",
> "15.980", "14.630", "14.980", "12.560", "12.390", "11.500", "10.940",
> "12.890", "14.830", "11.720", "11.870", "11.990", "12.900", " 9.570",
> "11.100", " 8.900", " 8.790", " 8.460", " 8.380", " 7.090", " 8.160",
> " 6.660", " 6.710", " 6.720", " 7.140", " 7.390", " 7.530", " 6.120",
> " 6.390", " 6.000", " 6.420", " 8.100", " 8.450", " 7.230", " 6.510",
> " 5.050", " 5.900", " 6.780", " 5.470", " 6.700", " 5.040", " 6.050",
> " 6.610", " 6.590", " 8.350", " 6.370", " 5.417", " 6.025", " 5.427",
> " 5.631", " 7.827", " 5.883", " 5.000", " 5.000", " 5.000", " 5.080",
> " 5.010", " 3.570", " 3.640", " 3.500", " 4.320", " 3.500", " 3.500",
> " 3.500", " 3.730", " 3.370", " 4.000", " 3.780", " 3.570", " 3.270",
> " 3.650", " 3.730", " 3.450", " 5.280", " 4.030", " 4.210", " 3.640",
> " 3.570", " 4.560", " 5.110", " 5.520", " 5.370", " 5.230", " 4.370",
> " 5.650", " 5.410", " 3.970", " 4.190", " 3.890", " 3.510", " 4.210",
> " 3.800", " 4.420", " 3.640", "10.850", "11.210", " 7.950", " 7.230",
> " 8.750", " 7.060", " 8.590", " 5.490", " 5.660", "10.680", "13.030",
> "13.670", "11.620", " 9.160", "11.170", "11.680", "10.040", " 6.670",
> " 5.410", " 5.870", " 6.270", " 6.280", " 8.020", " 7.240", " 8.090",
> " 8.430", " 8.290", " 7.870", " 8.390", " 7.040", " 4.911", " 6.829",
> " 6.328", " 5.556", " 6.892", " 6.672", " 6.679", " 7.947", " 8.530",
> " 7.024", " 7.132", " 6.617", " 6.072", " 5.636", " 7.037", " 7.726",
> " 6.918", " 7.007", " 7.184", " 6.913", " 6.079", " 5.914", " 6.080",
> " 5.082", " 6.002", " 5.700", " 5.648", " 6.721", " 7.070", " 5.524",
> " 5.514", " 5.154", " 5.493", " 6.471", " 8.400", " 7.503", " 6.847",
> " 5.347", " 5.583", " 6.145", " 5.687", " 6.167", " 6.553", " 5.996",
> " 5.698", " 5.353", " 6.458", " 7.943", " 6.510", " 6.257", " 6.042",
> " 5.705", " 6.103", " 6.082", " 5.931", " 5.453", " 5.089", " 5.043",
> " 5.453", " 5.099", " 4.930", " 5.053", " 5.147", " 5.653", " 6.660",
> " 6.188", " 6.562", " 5.663", " 7.208", " 7.107", " 8.112", " 7.555",
> " 7.816", " 7.116", " 6.666", " 7.312", " 7.222", " 6.931", " 6.800",
> " 6.877", " 6.837", " 6.748", " 6.673", " 6.521", " 6.061", " 5.401",
> " 4.954", " 4.848", " 4.747", " 4.730", " 4.723", " 4.696", " 4.737",
> " 4.835", " 4.841", " 4.837", " 4.817", " 4.825", " 4.730", " 4.614",
> " 4.611", " 4.643", " 4.645", " 4.771", " 4.797", " 4.785", " 4.754",
> " 4.799", " 4.758", " 4.739", " 4.720", " 4.655", " 4.517", " 4.360",
> " 4.227", " 4.037", " 3.895", " 3.686", " 3.513", " 3.173", " 2.727",
> " 2.486", " 2.390", " 2.299", " 2.277", " 2.273", " 2.265", " 2.215",
> " 2.071", " 1.937", " 1.960", " 1.947", " 1.933", " 1.794", " 1.614",
> " 1.302", " 1.258", " 1.203", " 1.188", " 1.181", " 1.156", " 1.027",
> " 1.024", " 1.021", " 1.024", " 1.022", " 1.025", " 1.008", " 0.984",
> " 0.991", " 0.972", " 0.967", " 1.018", " 1.024", " 1.048", " 1.084",
> " 1.142", " 1.141", " 1.149", " 1.202", " 1.203", " 1.221", " 1.267",
> " 1.266", " 1.265", " 1.324", " 1.324", " 1.365", " 1.388", " 1.387",
> " 1.406", " 1.446", " 1.449", " 1.450", " 1.516", " 1.517", " 1.533",
> " 1.586", " 1.587", " 1.595", " 1.658", " 1.663", " 1.661", " 1.689",
> " 1.691", " 1.703", " 1.725", " 2.132", " 2.496", " 2.006", " 2.007",
> " 2.019", " 2.038", " 2.038", " 2.054", " 2.088", " 2.082", " 2.084",
> " 2.105", " 2.101", " 2.105", " 2.166", " 2.158", " 2.092", " 1.926",
> " 1.410", " 0.872", " 0.233", " 0.143", " 0.137", " 0.131", " 0.097",
> " 0.097", " 0.100", " 0.101", " 0.100", " 0.101", " 0.104", " 0.106",
> " 0.108", " 0.104", " 0.130", " 0.164", " 0.174", " 0.183", " 0.196",
> " 0.203", " 0.210", " 0.226", " 0.231", " 0.239", " 0.257", " 0.262",
> " 0.274", " 0.296", " 0.319", " 0.344", " 0.375", " 0.388", " 0.394",
> " 0.395", " 0.396", " 0.400", " 0.403", " 0.399", " 0.402", " 0.476",
> " 0.512", " 0.513", " 0.445", " 0.388", " 0.389", " 0.388", " 0.386",
> " 0.388", " 0.387", " 0.387", " 0.387", " 0.386", " 0.386", " 0.386",
> " 0.386", " 0.386", " 0.386", " 0.387", " 0.386", " 0.387", " 0.388",
> " 0.387", " 0.387", " 0.387", " 0.388", " 0.387", " 0.387", " 0.386"
> ), .Dim = c(404L, 3L), .Dimnames = list(NULL, c("date_m", "CPI",
> "ONI")), index = structure(c(1981, 1981.08333333333, 1981.16666666667,
> 1981.25, 1981.33333333333, 1981.41666666667, 1981.5, 1981.58333333333,
> 1981.66666666667, 1981.75, 1981.83333333333, 1981.91666666667,
> 1982, 1982.08333333333, 1982.16666666667, 1982.25, 1982.33333333333,
> 1982.41666666667, 1982.5, 1982.58333333333, 1982.66666666667,
> 1982.75, 1982.83333333333, 1982.91666666667, 1983, 1983.08333333333,
> 1983.16666666667, 1983.25, 1983.33333333333, 1983.41666666667,
> 1983.5, 1983.58333333333, 1983.66666666667, 1983.75, 1983.83333333333,
> 1983.91666666667, 1984, 1984.08333333333, 1984.16666666667, 1984.25,
> 1984.33333333333, 1984.41666666667, 1984.5, 1984.58333333333,
> 1984.66666666667, 1984.75, 1984.83333333333, 1984.91666666667,
> 1985, 1985.08333333333, 1985.16666666667, 1985.25, 1985.33333333333,
> 1985.41666666667, 1985.5, 1985.58333333333, 1985.66666666667,
> 1985.75, 1985.83333333333, 1985.91666666667, 1986, 1986.08333333333,
> 1986.16666666667, 1986.25, 1986.33333333333, 1986.41666666667,
> 1986.5, 1986.58333333333, 1986.66666666667, 1986.75, 1986.83333333333,
> 1986.91666666667, 1987, 1987.08333333333, 1987.16666666667, 1987.25,
> 1987.33333333333, 1987.41666666667, 1987.5, 1987.58333333333,
> 1987.66666666667, 1987.75, 1987.83333333333, 1987.91666666667,
> 1988, 1988.08333333333, 1988.16666666667, 1988.25, 1988.33333333333,
> 1988.41666666667, 1988.5, 1988.58333333333, 1988.66666666667,
> 1988.75, 1988.83333333333, 1988.91666666667, 1989, 1989.08333333333,
> 1989.16666666667, 1989.25, 1989.33333333333, 1989.41666666667,
> 1989.5, 1989.58333333333, 1989.66666666667, 1989.75, 1989.83333333333,
> 1989.91666666667, 1990, 1990.08333333333, 1990.16666666667, 1990.25,
> 1990.33333333333, 1990.41666666667, 1990.5, 1990.58333333333,
> 1990.66666666667, 1990.75, 1990.83333333333, 1990.91666666667,
> 1991, 1991.08333333333, 1991.16666666667, 1991.25, 1991.33333333333,
> 1991.41666666667, 1991.5, 1991.58333333333, 1991.66666666667,
> 1991.75, 1991.83333333333, 1991.91666666667, 1992, 1992.08333333333,
> 1992.16666666667, 1992.25, 1992.33333333333, 1992.41666666667,
> 1992.5, 1992.58333333333, 1992.66666666667, 1992.75, 1992.83333333333,
> 1992.91666666667, 1993, 1993.08333333333, 1993.16666666667, 1993.25,
> 1993.33333333333, 1993.41666666667, 1993.5, 1993.58333333333,
> 1993.66666666667, 1993.75, 1993.83333333333, 1993.91666666667,
> 1994, 1994.08333333333, 1994.16666666667, 1994.25, 1994.33333333333,
> 1994.41666666667, 1994.5, 1994.58333333333, 1994.66666666667,
> 1994.75, 1994.83333333333, 1994.91666666667, 1995, 1995.08333333333,
> 1995.16666666667, 1995.25, 1995.33333333333, 1995.41666666667,
> 1995.5, 1995.58333333333, 1995.66666666667, 1995.75, 1995.83333333333,
> 1995.91666666667, 1996, 1996.08333333333, 1996.16666666667, 1996.25,
> 1996.33333333333, 1996.41666666667, 1996.5, 1996.58333333333,
> 1996.66666666667, 1996.75, 1996.83333333333, 1996.91666666667,
> 1997, 1997.08333333333, 1997.16666666667, 1997.25, 1997.33333333333,
> 1997.41666666667, 1997.5, 1997.58333333333, 1997.66666666667,
> 1997.75, 1997.83333333333, 1997.91666666667, 1998, 1998.08333333333,
> 1998.16666666667, 1998.25, 1998.33333333333, 1998.41666666667,
> 1998.5, 1998.58333333333, 1998.66666666667, 1998.75, 1998.83333333333,
> 1998.91666666667, 1999, 1999.08333333333, 1999.16666666667, 1999.25,
> 1999.33333333333, 1999.41666666667, 1999.5, 1999.58333333333,
> 1999.66666666667, 1999.75, 1999.83333333333, 1999.91666666667,
> 2000, 2000.08333333333, 2000.16666666667, 2000.25, 2000.33333333333,
> 2000.41666666667, 2000.5, 2000.58333333333, 2000.66666666667,
> 2000.75, 2000.83333333333, 2000.91666666667, 2001, 2001.08333333333,
> 2001.16666666667, 2001.25, 2001.33333333333, 2001.41666666667,
> 2001.5, 2001.58333333333, 2001.66666666667, 2001.75, 2001.83333333333,
> 2001.91666666667, 2002, 2002.08333333333, 2002.16666666667, 2002.25,
> 2002.33333333333, 2002.41666666667, 2002.5, 2002.58333333333,
> 2002.66666666667, 2002.75, 2002.83333333333, 2002.91666666667,
> 2003, 2003.08333333333, 2003.16666666667, 2003.25, 2003.33333333333,
> 2003.41666666667, 2003.5, 2003.58333333333, 2003.66666666667,
> 2003.75, 2003.83333333333, 2003.91666666667, 2004, 2004.08333333333,
> 2004.16666666667, 2004.25, 2004.33333333333, 2004.41666666667,
> 2004.5, 2004.58333333333, 2004.66666666667, 2004.75, 2004.83333333333,
> 2004.91666666667, 2005, 2005.08333333333, 2005.16666666667, 2005.25,
> 2005.33333333333, 2005.41666666667, 2005.5, 2005.58333333333,
> 2005.66666666667, 2005.75, 2005.83333333333, 2005.91666666667,
> 2006, 2006.08333333333, 2006.16666666667, 2006.25, 2006.33333333333,
> 2006.41666666667, 2006.5, 2006.58333333333, 2006.66666666667,
> 2006.75, 2006.83333333333, 2006.91666666667, 2007, 2007.08333333333,
> 2007.16666666667, 2007.25, 2007.33333333333, 2007.41666666667,
> 2007.5, 2007.58333333333, 2007.66666666667, 2007.75, 2007.83333333333,
> 2007.91666666667, 2008, 2008.08333333333, 2008.16666666667, 2008.25,
> 2008.33333333333, 2008.41666666667, 2008.5, 2008.58333333333,
> 2008.66666666667, 2008.75, 2008.83333333333, 2008.91666666667,
> 2009, 2009.08333333333, 2009.16666666667, 2009.25, 2009.33333333333,
> 2009.41666666667, 2009.5, 2009.58333333333, 2009.66666666667,
> 2009.75, 2009.83333333333, 2009.91666666667, 2010, 2010.08333333333,
> 2010.16666666667, 2010.25, 2010.33333333333, 2010.41666666667,
> 2010.5, 2010.58333333333, 2010.66666666667, 2010.75, 2010.83333333333,
> 2010.91666666667, 2011, 2011.08333333333, 2011.16666666667, 2011.25,
> 2011.33333333333, 2011.41666666667, 2011.5, 2011.58333333333,
> 2011.66666666667, 2011.75, 2011.83333333333, 2011.91666666667,
> 2012, 2012.08333333333, 2012.16666666667, 2012.25, 2012.33333333333,
> 2012.41666666667, 2012.5, 2012.58333333333, 2012.66666666667,
> 2012.75, 2012.83333333333, 2012.91666666667, 2013, 2013.08333333333,
> 2013.16666666667, 2013.25, 2013.33333333333, 2013.41666666667,
> 2013.5, 2013.58333333333, 2013.66666666667, 2013.75, 2013.83333333333,
> 2013.91666666667, 2014, 2014.08333333333, 2014.16666666667, 2014.25,
> 2014.33333333333, 2014.41666666667, 2014.5, 2014.58333333333), class =
> "yearmon"), class = "zoo")
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From 538280 at gmail.com  Mon Oct  6 19:28:36 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 6 Oct 2014 11:28:36 -0600
Subject: [R] Hadley's book: paper/PDF/etc. versus github
In-Reply-To: <CABdHhvGVFx+jHavTqO1XUiSqFLisWewEkw032Ou34B+jKMbE8Q@mail.gmail.com>
References: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>
	<CABdHhvGVFx+jHavTqO1XUiSqFLisWewEkw032Ou34B+jKMbE8Q@mail.gmail.com>
Message-ID: <CAFEqCdyoXir7VhyPuOpf4tMPJsxpyn5Cd7srfUj65XWq+3Y_VA@mail.gmail.com>

Hadley, have you tried producing the book in other electronic formats
(other than pdf)? such as epub?  I tried and ended up with a file that
worked, but all the example code was missing (which defeats the
convenience of having it on an ebook reader), I did not check if
everything else was there or not.

 thanks,

On Fri, Oct 3, 2014 at 6:37 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
>> Hi, folks.  I've got a sort of coupon that would allow me to get a
>> copy of "Advanced R" by Hadley Wickham at no cost.  OTOH, I've already
>> cloned the github repository, and having the "live" Rmd files (or in
>> this case, rmd files) is enormously more useful to me than having any
>> form of electronic or paper format.
>
> I presume you mean https://github.com/hadley/adv-r (no need to be
> secretive about it ;)
>
>> The only reason I can think of for getting, say, a PDF version of the
>> book is that corrected versions of such books are sometimes (always?)
>> made available for free if you've already got the PDF version of the
>> book.  (I know O'Reilly does this.)
>
> The pdf version of the book is made from the files in that repo, so I
> don't see any advantage there.  (You can build the pdf yourself if you
> spend a few minutes looking for the right file ;)
>
>> But if the github version is going to continue to exist, be updated,
>> and be generally available, that's even better.  IS it going to exist,
>> be updated, and be generally available?  Any thoughts?
>
> The github version _is_ the authoritative version of the book (and in
> some sense it's already slightly better than the book, since a number
> of minor typos have been fixed since the book was published). C&H is
> mostly print on demand, so later printings of the book are likely to
> pick up the improvements, although there is still some additional
> human checking in the process, so it'll only get updated every 6
> months or so.
>
> The repo and http://adv-r.had.co.nz will continue to exist for the
> foreseeable future.
>
> Hadley
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From erinm.hodgess at gmail.com  Mon Oct  6 19:11:56 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 6 Oct 2014 13:11:56 -0400
Subject: [R]  a question about arimax, please
Message-ID: <CACxE24=4TbvFvLS7WvX3FSrgAJTPR_jtb8y3v5MQHdqvay_9ag@mail.gmail.com>

Hello!
I have about the arimax function, please:
If you see the example page, you see the following:
# Exhibit 11.6
air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),
period=12),xtransf=data.frame(I911=1*(seq(airmiles)==69),
I911=1*(seq(airmiles)==69)),
transfer=list(c(0,0),c(1,0)),xreg=data.frame(Dec96=1*(seq(airmiles)==12),
Jan97=1*(seq(airmiles)==13),Dec02=1*(seq(airmiles)==84)),method='ML')
Now the part that I am puzzled about the "transfer" argument, please. It is
supposed to be the MA order and the AR order, respectively. However, the AR
order is 0. Should that be reversed, please?
Thanks,
Erin.

-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From mmuurr at gmail.com  Mon Oct  6 20:00:14 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Mon, 6 Oct 2014 12:00:14 -0600
Subject: [R] par("plt") behaving inconsistely? bug?
Message-ID: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>

Hi all -- I just encountered a behavior that I believe has changed
from previous versions, though I haven't chased back the last version
that behaves as my existing code expects quite yet.
Perhaps this is a bug, though perhaps I'm missing a subtle detail
somewhere in the documentation...

Here's some code that works as expected (in R 3.1.1):

########################################
pdf()
plot.new()

original_plt <- par("plt")

plt_1 <- c(original_plt[1],
           original_plt[1] + (original_plt[2] - original_plt[1]) / 2,
           original_plt[3],
           original_plt[3] + (original_plt[4] - original_plt[3]) / 2)
par("plt" = plt_1)
plot.window(xlim = c(0, 1), ylim = c(0, 1))
box()
plt_2 <- c(plt_1[2],
           original_plt[2],
           plt_1[4],
           original_plt[4])
par("plt" = plt_2)
plot.window(xlim = c(0, 1), ylim = c(0, 1))
box()
par("plt" = original_plt)
box(lty = 2)
dev.off()
########################################

This will draw 3 boxes... one in the lower left corner (specified by
plt_1), one in the top right corner (specified by plt_2), and one
dotted box around the full plot box (original_plt).

Now, if you replace the first two box() calls by: rect(0, 0, 1, 1),
only the lower-left rectangle is drawn.
If you _add_ rect(0, 0, 1, 1) after each box() call, all boxes and
rectangles are correctly drawn.

It seems that after setting plt once, subsequent plt alterations put
the device into a state that will permits drawing of _some_ things
(e.g. box()), but not other things (e.g. rect, lines, points).

A kludge to fix this is to call box(col = "white")... but that's quite
the kludge, indeed!
Axis() works just like box(), too... but I haven't exhausted which
drawing functions work and which don't.

I'd classify this is a bug, but I thought I'd check here first.
I've also only checked this so far with the pdf() device, so I don't
know if it is somehow device-specific.

I detected this because some existing code (that worked on some
earlier version of R, sorry that I don't know which one yet...) has
suddenly stopped working!

Cheers!

-murat


From swbueno at gmail.com  Mon Oct  6 21:17:31 2014
From: swbueno at gmail.com (Santiago Bueno)
Date: Mon, 6 Oct 2014 15:17:31 -0400
Subject: [R] Unable to install packages
Message-ID: <CAGfmZu7re0R6Cf9BfkQvT370G8T5OaP0LP5PfMXxReP7vJTZyw@mail.gmail.com>

New to R. When trying to install packages always get the following message:

> install.packages("HSAUR2")
Installing package(s) into ?C:/Users/sbueno/Documents/R/win-library/2.14?
(as ?lib? is unspecified)
--- Please select a CRAN mirror for use in this session ---
Warning: unable to access index for repository
http://www.laqee.unal.edu.co/CRAN/bin/windows/contrib/2.14
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.14
Warning messages:
1: In open.connection(con, "r") : unable to resolve 'cran.r-project.org'
2: In getDependencies(pkgs, dependencies, available, lib) :
  package ?HSAUR2? is not available (for R version 2.14.0)
>

Help please!!!!

Santiago

	[[alternative HTML version deleted]]


From mmuurr at gmail.com  Mon Oct  6 20:05:35 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Mon, 6 Oct 2014 12:05:35 -0600
Subject: [R] par("plt") behaving inconsistely? bug?
In-Reply-To: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>
References: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>
Message-ID: <CA+YV+HyWxO5T0zQNh1Ma2+skrhWF5MXz5ft4WzU2Npzw1Hrhbw@mail.gmail.com>

Another (easier) kludge is augmenting a call to each par("plt" = ...) call:

par("plt" = some_plt_coordinates); box(lty = 0)

The box(lty = 0) addition makes downstream calls work as expected, but
yeah... this is a kuldge.

-m

On Mon, Oct 6, 2014 at 12:00 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> Hi all -- I just encountered a behavior that I believe has changed
> from previous versions, though I haven't chased back the last version
> that behaves as my existing code expects quite yet.
> Perhaps this is a bug, though perhaps I'm missing a subtle detail
> somewhere in the documentation...
>
> Here's some code that works as expected (in R 3.1.1):
>
> ########################################
> pdf()
> plot.new()
>
> original_plt <- par("plt")
>
> plt_1 <- c(original_plt[1],
>            original_plt[1] + (original_plt[2] - original_plt[1]) / 2,
>            original_plt[3],
>            original_plt[3] + (original_plt[4] - original_plt[3]) / 2)
> par("plt" = plt_1)
> plot.window(xlim = c(0, 1), ylim = c(0, 1))
> box()
> plt_2 <- c(plt_1[2],
>            original_plt[2],
>            plt_1[4],
>            original_plt[4])
> par("plt" = plt_2)
> plot.window(xlim = c(0, 1), ylim = c(0, 1))
> box()
> par("plt" = original_plt)
> box(lty = 2)
> dev.off()
> ########################################
>
> This will draw 3 boxes... one in the lower left corner (specified by
> plt_1), one in the top right corner (specified by plt_2), and one
> dotted box around the full plot box (original_plt).
>
> Now, if you replace the first two box() calls by: rect(0, 0, 1, 1),
> only the lower-left rectangle is drawn.
> If you _add_ rect(0, 0, 1, 1) after each box() call, all boxes and
> rectangles are correctly drawn.
>
> It seems that after setting plt once, subsequent plt alterations put
> the device into a state that will permits drawing of _some_ things
> (e.g. box()), but not other things (e.g. rect, lines, points).
>
> A kludge to fix this is to call box(col = "white")... but that's quite
> the kludge, indeed!
> Axis() works just like box(), too... but I haven't exhausted which
> drawing functions work and which don't.
>
> I'd classify this is a bug, but I thought I'd check here first.
> I've also only checked this so far with the pdf() device, so I don't
> know if it is somehow device-specific.
>
> I detected this because some existing code (that worked on some
> earlier version of R, sorry that I don't know which one yet...) has
> suddenly stopped working!
>
> Cheers!
>
> -murat


From murdoch.duncan at gmail.com  Mon Oct  6 21:29:21 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 06 Oct 2014 15:29:21 -0400
Subject: [R] Unable to install packages
In-Reply-To: <CAGfmZu7re0R6Cf9BfkQvT370G8T5OaP0LP5PfMXxReP7vJTZyw@mail.gmail.com>
References: <CAGfmZu7re0R6Cf9BfkQvT370G8T5OaP0LP5PfMXxReP7vJTZyw@mail.gmail.com>
Message-ID: <5432ED91.7080008@gmail.com>

On 06/10/2014 3:17 PM, Santiago Bueno wrote:
> New to R. When trying to install packages always get the following message:
>
> > install.packages("HSAUR2")
> Installing package(s) into ?C:/Users/sbueno/Documents/R/win-library/2.14?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> Warning: unable to access index for repository
> http://www.laqee.unal.edu.co/CRAN/bin/windows/contrib/2.14
> Warning: unable to access index for repository
> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.14
> Warning messages:
> 1: In open.connection(con, "r") : unable to resolve 'cran.r-project.org'
> 2: In getDependencies(pkgs, dependencies, available, lib) :
>    package ?HSAUR2? is not available (for R version 2.14.0)
> >
>
> Help please!!!!

Sounds as though you are having Internet problems.  Try the Windows FAQ 
2.19, from the help menu.

Duncan Murdoch


>
> Santiago
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Mon Oct  6 21:47:43 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 6 Oct 2014 12:47:43 -0700
Subject: [R] Unable to install packages
In-Reply-To: <5432ED91.7080008@gmail.com>
References: <CAGfmZu7re0R6Cf9BfkQvT370G8T5OaP0LP5PfMXxReP7vJTZyw@mail.gmail.com>
	<5432ED91.7080008@gmail.com>
Message-ID: <CAFDcVCS4j_69XgYHpi24nHJ5cauohODpjWet+eDF7GYbWBaYGA@mail.gmail.com>

On Mon, Oct 6, 2014 at 12:29 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 06/10/2014 3:17 PM, Santiago Bueno wrote:
>>
>> New to R. When trying to install packages always get the following
>> message:
>>
>> > install.packages("HSAUR2")
>> Installing package(s) into ?C:/Users/sbueno/Documents/R/win-library/2.14?
>> (as ?lib? is unspecified)
>> --- Please select a CRAN mirror for use in this session ---
>> Warning: unable to access index for repository
>> http://www.laqee.unal.edu.co/CRAN/bin/windows/contrib/2.14
>> Warning: unable to access index for repository
>> http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.14
>> Warning messages:
>> 1: In open.connection(con, "r") : unable to resolve 'cran.r-project.org'
>> 2: In getDependencies(pkgs, dependencies, available, lib) :
>>    package ?HSAUR2? is not available (for R version 2.14.0)
>> >
>>
>> Help please!!!!
>
>
> Sounds as though you are having Internet problems.  Try the Windows FAQ
> 2.19, from the help menu.

...and a very old R installation. Someone had to say that.
Install/update to most recent version (R 3.1.1) and you'll be much
better off.

/Henrik

>
> Duncan Murdoch
>
>
>
>>
>> Santiago
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From amos.elberg at gmail.com  Mon Oct  6 21:53:21 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Mon, 6 Oct 2014 15:53:21 -0400
Subject: [R] Hadley's book: paper/PDF/etc. versus github
In-Reply-To: <CAFEqCdyoXir7VhyPuOpf4tMPJsxpyn5Cd7srfUj65XWq+3Y_VA@mail.gmail.com>
References: <CACdH2Zapq+SisSJOp_C8B1iF9bRi2=stt3_TWC2exQruvJ7kfQ@mail.gmail.com>
	<CABdHhvGVFx+jHavTqO1XUiSqFLisWewEkw032Ou34B+jKMbE8Q@mail.gmail.com>
	<CAFEqCdyoXir7VhyPuOpf4tMPJsxpyn5Cd7srfUj65XWq+3Y_VA@mail.gmail.com>
Message-ID: <95A948BD-601B-4806-87A5-FB979ADD4E0B@gmail.com>

For me, it output html from rstudio complete with code etc., with no changes except a tinker to a call to setwd(), downloading some libraries, and no other intervention.  I haven't explored the rmarkdown capabilities before, and I was just amazed. 


> On Oct 6, 2014, at 1:28 PM, Greg Snow <538280 at gmail.com> wrote:
> 
> Hadley, have you tried producing the book in other electronic formats
> (other than pdf)? such as epub?  I tried and ended up with a file that
> worked, but all the example code was missing (which defeats the
> convenience of having it on an ebook reader), I did not check if
> everything else was there or not.
> 
> thanks,
> 
> On Fri, Oct 3, 2014 at 6:37 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
>>> Hi, folks.  I've got a sort of coupon that would allow me to get a
>>> copy of "Advanced R" by Hadley Wickham at no cost.  OTOH, I've already
>>> cloned the github repository, and having the "live" Rmd files (or in
>>> this case, rmd files) is enormously more useful to me than having any
>>> form of electronic or paper format.
>> 
>> I presume you mean https://github.com/hadley/adv-r (no need to be
>> secretive about it ;)
>> 
>>> The only reason I can think of for getting, say, a PDF version of the
>>> book is that corrected versions of such books are sometimes (always?)
>>> made available for free if you've already got the PDF version of the
>>> book.  (I know O'Reilly does this.)
>> 
>> The pdf version of the book is made from the files in that repo, so I
>> don't see any advantage there.  (You can build the pdf yourself if you
>> spend a few minutes looking for the right file ;)
>> 
>>> But if the github version is going to continue to exist, be updated,
>>> and be generally available, that's even better.  IS it going to exist,
>>> be updated, and be generally available?  Any thoughts?
>> 
>> The github version _is_ the authoritative version of the book (and in
>> some sense it's already slightly better than the book, since a number
>> of minor typos have been fixed since the book was published). C&H is
>> mostly print on demand, so later printings of the book are likely to
>> pick up the improvements, although there is still some additional
>> human checking in the process, so it'll only get updated every 6
>> months or so.
>> 
>> The repo and http://adv-r.had.co.nz will continue to exist for the
>> foreseeable future.
>> 
>> Hadley
>> 
>> --
>> http://had.co.nz/
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Mon Oct  6 22:08:39 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 6 Oct 2014 14:08:39 -0600
Subject: [R] par("plt") behaving inconsistely? bug?
In-Reply-To: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>
References: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>
Message-ID: <CAFEqCdxM5vz-2MCeNTNmreugXvST43jpypmknX63dpgD_amB8A@mail.gmail.com>

I believe that what is happening is that the clipping region is being
reset when you call box, but not when you call rect.  If you insert
the command "par(xpd=NA)" (or TRUE instead of NA) after the plot.new
and use the rect commands then you can see both rectangles (because
this turns the clipping off).  Working with the clipping region
(indirectly in your case) is complex since some functions properly
reset the region and others do not (and  making the others
automatically reset it may cause other problems when they reset a
clipping region that should not be reset).

So the options are:

1 dive into the source code enough to figure out if fixing rect to
work with the clipping region is simple or not and submitting a patch
2 wait for Prof Brian Ripley to notice this fact and do the above (he
has fixed a couple of other functions when made aware)
3 use par(xpd=TRUE) (or NA) to not clip to the plotting region (this
is simple, but will allow things to be drawn outside of the plotting
region, on simple example is using abline)
4 use a function that properly sets the clipping region (such as box)
before plotting anything else
5 call clip(0,1,0,1) (or with the actual user coordinates) to manually
set the clipping region
6 other?


On Mon, Oct 6, 2014 at 12:00 PM, Murat Tasan <mmuurr at gmail.com> wrote:
> Hi all -- I just encountered a behavior that I believe has changed
> from previous versions, though I haven't chased back the last version
> that behaves as my existing code expects quite yet.
> Perhaps this is a bug, though perhaps I'm missing a subtle detail
> somewhere in the documentation...
>
> Here's some code that works as expected (in R 3.1.1):
>
> ########################################
> pdf()
> plot.new()
>
> original_plt <- par("plt")
>
> plt_1 <- c(original_plt[1],
>            original_plt[1] + (original_plt[2] - original_plt[1]) / 2,
>            original_plt[3],
>            original_plt[3] + (original_plt[4] - original_plt[3]) / 2)
> par("plt" = plt_1)
> plot.window(xlim = c(0, 1), ylim = c(0, 1))
> box()
> plt_2 <- c(plt_1[2],
>            original_plt[2],
>            plt_1[4],
>            original_plt[4])
> par("plt" = plt_2)
> plot.window(xlim = c(0, 1), ylim = c(0, 1))
> box()
> par("plt" = original_plt)
> box(lty = 2)
> dev.off()
> ########################################
>
> This will draw 3 boxes... one in the lower left corner (specified by
> plt_1), one in the top right corner (specified by plt_2), and one
> dotted box around the full plot box (original_plt).
>
> Now, if you replace the first two box() calls by: rect(0, 0, 1, 1),
> only the lower-left rectangle is drawn.
> If you _add_ rect(0, 0, 1, 1) after each box() call, all boxes and
> rectangles are correctly drawn.
>
> It seems that after setting plt once, subsequent plt alterations put
> the device into a state that will permits drawing of _some_ things
> (e.g. box()), but not other things (e.g. rect, lines, points).
>
> A kludge to fix this is to call box(col = "white")... but that's quite
> the kludge, indeed!
> Axis() works just like box(), too... but I haven't exhausted which
> drawing functions work and which don't.
>
> I'd classify this is a bug, but I thought I'd check here first.
> I've also only checked this so far with the pdf() device, so I don't
> know if it is somehow device-specific.
>
> I detected this because some existing code (that worked on some
> earlier version of R, sorry that I don't know which one yet...) has
> suddenly stopped working!
>
> Cheers!
>
> -murat
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From patzelt at g.harvard.edu  Mon Oct  6 21:24:45 2014
From: patzelt at g.harvard.edu (Patzelt, Edward)
Date: Mon, 6 Oct 2014 15:24:45 -0400
Subject: [R] Identifying Values in Dataframe
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8E7C@SRVEXCHMBX.precheza.cz>
References: <CAB9UfhR0YsuAGBEEqW4f9C_DpJj+mdYKujUX3v23jnMAh_PPhQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8E7C@SRVEXCHMBX.precheza.cz>
Message-ID: <CAB9UfhSQzMCM17Qzx4wawd=4KOD1vpniRQNf=AX5mG5oCenqaA@mail.gmail.com>

Thanks Pikal -

I'd like to actually get the names of the variables for those indices both
above and below .3/-.3 with the intention of generating a grid of
scatterplots (which I will use ggplot2 for).

I played around with your code but can't seem to get the indice names.

Best,

Edward

On Fri, Oct 3, 2014 at 2:59 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> maybe
>
> which(abs(data)>0.3, arr.ind=T)
>                                      row col
> Loss_EV_Amygdala_SF_left_hemisphere   15   2
> Loss_EV_Amygdala_SF_left_hemisphere   15   3
> Loss_PE_Amygdala_SF_right_hemisphere   5   7
> Loss_PE_Amygdala_SF_left_hemisphere   13   9
>
> Gives you what you want.
>
> > sel<-which(abs(data)>0.3, arr.ind=T)
> > data[sel]
> [1] 0.3268234 0.3451718 0.3116239 0.3316836
>
> Regards.
> Petr
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Patzelt, Edward
> > Sent: Thursday, October 02, 2014 10:18 PM
> > To: R-help at r-project.org
> > Subject: [R] Identifying Values in Dataframe
> >
> > R Help -
> >
> > I'd like to identify each correlation value in the dataframe below
> > above/below .3/-.3 in order to graph the original data points. I've
> > started
> > with the call below to identify each value by it's row and column. I'd
> > like
> > to form a data object that identifies each set of variables that meet
> > the
> > criteria and then use that to graph the original data.
> >
> > *do.call(cbind, lapply(list(row = row(data, T), col = col(data, T),
> > value =
> > data), as.character))*
> > structure(c(-0.0228976615669603, 0.0228976615669603,
> > 0.0345568787488209,
> > -0.0345568787488209, 0.0704941162950863, 0.0501672252097525,
> > 0.119766411337358, 0.0697823742392512, 0.0223273454311378,
> > -0.0223273454311378,
> > 0.125952482472234, -0.125952482472234, -0.0748856339421511,
> > -0.0353553864437216,
> > 0.199331873910442, -0.068756564596986, 0.0188033303819659,
> > -0.0188033303819659,
> > 0.124483870344689, -0.124483870344689, 0.158304442010968,
> > -0.158304442010968,
> > -0.00291892981576431, 0.00291892981576431, 0.289784855159971,
> > 0.197017018634618, 0.0725645607308865, 0.0960039687045857,
> > 0.145044311433109,
> > -0.145044311433109, 0.228975321916426, -0.228975321916426,
> > 0.26388395000877,
> > 0.175954114053622, 0.326823414986536, 0.0464304517962428,
> > 0.171060413427109,
> > -0.171060413427109, 0.125608489395663, -0.125608489395663,
> > 0.170699125959079,
> > -0.170699125959079, -0.0537588992684595, 0.0537588992684595,
> > 0.237938136557008, 0.130101348701669, 0.0420659299644508,
> > 0.140016889896702,
> > 0.175781963301805, -0.175781963301805, 0.277913325677977,
> > -0.277913325677977,
> > 0.250436246834054, 0.149310941080417, 0.345171759606147,
> > 0.0499822279379925,
> > 0.180291553611261, -0.180291553611261, 0.0983047617452837,
> > -0.0983047617452837,
> > 0.0908629320478729, -0.0908629320478729, 0.0162624158794471,
> > -0.0162624158794471, 0.219099271324641, 0.143898328556892,
> > 0.0808498509449568,
> > 0.0534039458771934, 0.103639895676339, -0.103639895676339,
> > 0.224298317217259,
> > -0.224298317217259, 0.13939241528796, 0.0923125296440915,
> > 0.2952647762031,
> > -0.0573156158960486, 0.126972946909388, -0.126972946909388,
> > 0.145176640269481,
> > -0.145176640269481, 0.176722440639515, -0.176722440639515,
> > -0.110517827771672,
> > 0.110517827771672, 0.265161677824653, 0.0349452421080511,
> > -0.00586032680446085,
> > 0.17140674405117, -0.0141919172668973, 0.0141919172668973,
> > 0.0416754535115447,
> > -0.0416754535115447, 0.110687511145091, 0.163199987771469,
> > 0.174846924599677,
> > 0.116657756754811, 0.184924363876472, -0.184924363876472,
> > 0.0740138506321435,
> > -0.0740138506321435, 0.0653341995281647, -0.0653341995281647,
> > 0.101098966521841, -0.101098966521841, -0.0263969055123976,
> > -0.129660641707532,
> > 0.16313101271814, -0.0000382052406584783, 0.118309823316179,
> > -0.118309823316179, 0.0408519777835592, -0.0408519777835592,
> > -0.15406959482671, -0.274340973979869, 0.1465995621482,
> > -0.0608360452726588,
> > -0.00570057335076342, 0.00570057335076342, 0.0988132735291764,
> > -0.0988132735291764, 0.159498629897594, -0.159498629897594,
> > -0.0258437210789338,
> > 0.0258437210789338, 0.311623918577701, 0.0959243386674064,
> > 0.0373444291324758,
> > 0.131601179184854, 0.0032064022008327, -0.0032064022008327,
> > 0.0126042917937794,
> > -0.0126042917937794, 0.0288999352531186, 0.0343919995425096,
> > 0.0375647873892517, 0.0734866249695526, 0.125835994106989,
> > -0.125835994106989,
> > 0.0557071876372764, -0.0557071876372764, 0.0190687287223345,
> > -0.0190687287223345, 0.0301326072710063, -0.0301326072710063,
> > 0.0881640884608706, 0.0600194980037123, 0.0948090975231923,
> > 0.0259282757599189,
> > 0.120417132810781, -0.120417132810781, 0.196695581235906,
> > -0.196695581235906,
> > 0.166210300278382, 0.0252645245285897, 0.239953962041662,
> > -0.013933692494363,
> > 0.0174600644363753, -0.0174600644363753, 0.169008089964054,
> > -0.169008089964054,
> > 0.0503612778194372, -0.0503612778194372, 0.175816302924921,
> > -0.175816302924921,
> > 0.141434785651191, 0.0824019401386654, 0.173429908437586,
> > -0.136795834367563,
> > 0.219543981806626, -0.219543981806626, 0.290697487363267,
> > -0.290697487363267,
> > 0.331683649439792, -0.0035319780591347, 0.237371764540467,
> > -0.172828690804139,
> > 0.00922163769628213, -0.00922163769628213, 0.275507919516733,
> > -0.275507919516733, 0.128267529853407, -0.128267529853407,
> > -0.16619622911667,
> > 0.16619622911667, 0.102467428865746, -0.115779804556684,
> > 0.000997318666924614,
> > 0.297139396802529, 0.040957786791642, -0.040957786791642,
> > -0.0160650315621922,
> > 0.0160650315621922, -0.043765426943726, -0.0637020898937285,
> > 0.142863591010818, 0.214059283535989, 0.13975223034564, -
> > 0.13975223034564,
> > -0.0286586386843802, 0.0286586386843802, 0.13735028629468,
> > -0.13735028629468,
> > -0.147016933653806, 0.147016933653806, 0.174438743129307,
> > -0.0116564727226121,
> > -0.0413775943824046, 0.136551598575573, 0.0614942508131549,
> > -0.0614942508131549,
> > 0.0687487372508148, -0.0687487372508148, -0.0352587211103196,
> > -0.0872464182568976, 0.162247767446472, 0.0282617081917608,
> > 0.175608445537029,
> > -0.175608445537029, -0.0339260764991994, 0.0339260764991994,
> > 0.130002432167221, -0.130002432167221, -0.141752408742242,
> > 0.141752408742242,
> > 0.126603115520512, -0.0784556105378803, -0.0736773348350251,
> > 0.154815164010555, -0.102200077602115, 0.102200077602115,
> > -0.137144378194025,
> > 0.137144378194025, 0.0132012835622079, 0.113105077279414,
> > -0.0412435172396771,
> > 0.182836991911806, 0.109656132908221, -0.109656132908221,
> > -0.0341578533716874,
> > 0.0341578533716874, -0.0155952702450936, 0.0155952702450936,
> > 0.0962494517693934, -0.0962494517693934, 0.0745517006304259,
> > 0.145954619132309, 0.0997683764233029, -0.0562240100001912,
> > 0.13254524166143,
> > -0.13254524166143, 0.236418162977751, -0.236418162977751,
> > 0.0878486801199713,
> > -0.00445794916320147, 0.227619583487885, -0.14911359391431,
> > 0.0214260010937822,
> > -0.0214260010937822, 0.120246543167583, -0.120246543167583), .Dim =
> > c(20L,
> > 13L), .Dimnames = list(c("Loss_Gain_PE_Amygdala_SF_right_hemisphere",
> > "Gain_Loss_PE_Amygdala_SF_right_hemisphere",
> > "Loss_Gain_EV_Amygdala_SF_right_hemisphere",
> > "Gain_Loss_EV_Amygdala_SF_right_hemisphere",
> > "Loss_PE_Amygdala_SF_right_hemisphere",
> > "Gain_PE_Amygdala_SF_right_hemisphere",
> > "Loss_EV_Amygdala_SF_right_hemisphere",
> > "Gain_EV_Amygdala_SF_right_hemisphere",
> > "Loss_Gain_PE_Amygdala_SF_left_hemisphere",
> > "Gain_Loss_PE_Amygdala_SF_left_hemisphere",
> > "Loss_Gain_EV_Amygdala_SF_left_hemisphere",
> > "Gain_Loss_EV_Amygdala_SF_left_hemisphere",
> > "Loss_PE_Amygdala_SF_left_hemisphere",
> > "Gain_PE_Amygdala_SF_left_hemisphere",
> > "Loss_EV_Amygdala_SF_left_hemisphere",
> > "Gain_EV_Amygdala_SF_left_hemisphere",
> > "Loss_Gain_PE_Amygdala_LB_right_hemisphere",
> > "Gain_Loss_PE_Amygdala_LB_right_hemisphere",
> > "Loss_Gain_EV_Amygdala_LB_right_hemisphere",
> > "Gain_Loss_EV_Amygdala_LB_right_hemisphere"), c("hare2f1", "hare2f2",
> > "hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
> > "ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry",
> > "hareResidNetExt", "extResidNetHare")))
> >
> > --
> >
> > *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> > University SNPLab http://scholar.harvard.edu/buckholtz
> > <http://scholar.harvard.edu/buckholtz>*
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 

*Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
University SNPLab http://scholar.harvard.edu/buckholtz
<http://scholar.harvard.edu/buckholtz>*

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Oct  6 23:56:46 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 6 Oct 2014 23:56:46 +0200
Subject: [R] a question about arimax, please
In-Reply-To: <CACxE24=4TbvFvLS7WvX3FSrgAJTPR_jtb8y3v5MQHdqvay_9ag@mail.gmail.com>
References: <CACxE24=4TbvFvLS7WvX3FSrgAJTPR_jtb8y3v5MQHdqvay_9ag@mail.gmail.com>
Message-ID: <9C45EE6A-763F-43B8-99F4-CE7C748DFF3D@gmail.com>

In package TSA?

You may need to do some studying for yourself, this is complicated stuff. 

As I read the help page, the intention is that the transfer= bit is to allow a _covariate_ to affect the process in an ARMA-like fashion. So c(1,0) would be AR(1)-like which if I remember correctly corresponds to an exponentially decaying effect of instantaneous shocks to the system. And c(0,0) would be MA(0)-like, which I suppose would be an effect that only affected the same period as the instantaneous shock. In the example, we have the same covariate (Sept. 2001) contributing with both kinds of effect, so xtransf= has the same variable twice.

-pd

On 06 Oct 2014, at 19:11 , Erin Hodgess <erinm.hodgess at gmail.com> wrote:

> Hello!
> I have about the arimax function, please:
> If you see the example page, you see the following:
> # Exhibit 11.6
> air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),
> period=12),xtransf=data.frame(I911=1*(seq(airmiles)==69),
> I911=1*(seq(airmiles)==69)),
> transfer=list(c(0,0),c(1,0)),xreg=data.frame(Dec96=1*(seq(airmiles)==12),
> Jan97=1*(seq(airmiles)==13),Dec02=1*(seq(airmiles)==84)),method='ML')
> Now the part that I am puzzled about the "transfer" argument, please. It is
> supposed to be the MA order and the AR order, respectively. However, the AR
> order is 0. Should that be reversed, please?
> Thanks,
> Erin.
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Mathematical and Statistics
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From erinm.hodgess at gmail.com  Tue Oct  7 00:57:59 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Mon, 6 Oct 2014 18:57:59 -0400
Subject: [R] a question about arimax, please
In-Reply-To: <9C45EE6A-763F-43B8-99F4-CE7C748DFF3D@gmail.com>
References: <CACxE24=4TbvFvLS7WvX3FSrgAJTPR_jtb8y3v5MQHdqvay_9ag@mail.gmail.com>
	<9C45EE6A-763F-43B8-99F4-CE7C748DFF3D@gmail.com>
Message-ID: <CACxE24kkCeueKBJ272eRFszUPB5oNxqM6XO_pW7PMcO3yntzhw@mail.gmail.com>

This is great...thanks so much!


On Mon, Oct 6, 2014 at 5:56 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> In package TSA?
>
> You may need to do some studying for yourself, this is complicated stuff.
>
> As I read the help page, the intention is that the transfer= bit is to
> allow a _covariate_ to affect the process in an ARMA-like fashion. So
> c(1,0) would be AR(1)-like which if I remember correctly corresponds to an
> exponentially decaying effect of instantaneous shocks to the system. And
> c(0,0) would be MA(0)-like, which I suppose would be an effect that only
> affected the same period as the instantaneous shock. In the example, we
> have the same covariate (Sept. 2001) contributing with both kinds of
> effect, so xtransf= has the same variable twice.
>
> -pd
>
> On 06 Oct 2014, at 19:11 , Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> > Hello!
> > I have about the arimax function, please:
> > If you see the example page, you see the following:
> > # Exhibit 11.6
> > air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),
> > period=12),xtransf=data.frame(I911=1*(seq(airmiles)==69),
> > I911=1*(seq(airmiles)==69)),
> > transfer=list(c(0,0),c(1,0)),xreg=data.frame(Dec96=1*(seq(airmiles)==12),
> > Jan97=1*(seq(airmiles)==13),Dec02=1*(seq(airmiles)==84)),method='ML')
> > Now the part that I am puzzled about the "transfer" argument, please. It
> is
> > supposed to be the MA order and the AR order, respectively. However, the
> AR
> > order is 0. Should that be reversed, please?
> > Thanks,
> > Erin.
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics
> > University of Houston - Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Tue Oct  7 09:32:42 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 7 Oct 2014 10:32:42 +0300
Subject: [R] Changing date format
Message-ID: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>

Dear All,

How can I change the format of date of day of the year ? for example r
(i.e. "17 Apr" rather than "108").

The following is the type of the dataset I have

head(Samaru)
  Year Start End Length
1 1930   108 288    180
2 1931   118 288    170
3 1932   115 295    180
4 1933   156 294    138
5 1934   116 291    175
6 1935   134 288    154

Any idea is welcome. Thanks!!!

Cheers.
-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Tue Oct  7 11:27:57 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 07 Oct 2014 20:27:57 +1100
Subject: [R] Changing date format
In-Reply-To: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
Message-ID: <1486793.FaODssWil9@localhost.localdomain>

On Tue, 7 Oct 2014 10:32:42 AM Frederic Ntirenganya wrote:
> Dear All,
> 
> How can I change the format of date of day of the year ? for 
example r
> (i.e. "17 Apr" rather than "108").
> 
> The following is the type of the dataset I have
> 
> head(Samaru)
>   Year Start End Length
> 1 1930   108 288    180
> 2 1931   118 288    170
> 3 1932   115 295    180
> 4 1933   156 294    138
> 5 1934   116 291    175
> 6 1935   134 288    154
> 
Hi Frederic,
The easiest method I can think of is this:

Samaru$Start<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start,
 "%b %d")
Samaru$End<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$End,
 "%b %d")
Samaru

  Year  Start    End Length
1 1930 Apr 19 Oct 16    180
2 1931 Apr 29 Oct 16    170
3 1932 Apr 25 Oct 22    180
4 1933 Jun 06 Oct 22    138
5 1934 Apr 27 Oct 19    175
6 1935 May 15 Oct 16    154

Jim


From jim at bitwrit.com.au  Tue Oct  7 11:27:57 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 7 Oct 2014 20:27:57 +1100
Subject: [R] Changing date format
In-Reply-To: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
Message-ID: <1486793.FaODssWil9@localhost.localdomain>

On Tue, 7 Oct 2014 10:32:42 AM Frederic Ntirenganya wrote:
> Dear All,
> 
> How can I change the format of date of day of the year ? for 
example r
> (i.e. "17 Apr" rather than "108").
> 
> The following is the type of the dataset I have
> 
> head(Samaru)
>   Year Start End Length
> 1 1930   108 288    180
> 2 1931   118 288    170
> 3 1932   115 295    180
> 4 1933   156 294    138
> 5 1934   116 291    175
> 6 1935   134 288    154
> 
Hi Frederic,
The easiest method I can think of is this:

Samaru$Start<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start,
 "%b %d")
Samaru$End<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$End,
 "%b %d")
Samaru

  Year  Start    End Length
1 1930 Apr 19 Oct 16    180
2 1931 Apr 29 Oct 16    170
3 1932 Apr 25 Oct 22    180
4 1933 Jun 06 Oct 22    138
5 1934 Apr 27 Oct 19    175
6 1935 May 15 Oct 16    154

Jim


From goran.brostrom at umu.se  Tue Oct  7 11:51:34 2014
From: goran.brostrom at umu.se (=?windows-1252?Q?G=F6ran_Brostr=F6m?=)
Date: Tue, 7 Oct 2014 11:51:34 +0200
Subject: [R] Changing date format
In-Reply-To: <1486793.FaODssWil9@localhost.localdomain>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<1486793.FaODssWil9@localhost.localdomain>
Message-ID: <5433B7A6.2010408@umu.se>



On 2014-10-07 11:27, Jim Lemon wrote:
> On Tue, 7 Oct 2014 10:32:42 AM Frederic Ntirenganya wrote:
>> Dear All,
>>
>> How can I change the format of date of day of the year ? for
> example r
>> (i.e. "17 Apr" rather than "108").
>>
>> The following is the type of the dataset I have
>>
>> head(Samaru)
>>    Year Start End Length
>> 1 1930   108 288    180
>> 2 1931   118 288    170
>> 3 1932   115 295    180
>> 4 1933   156 294    138
>> 5 1934   116 291    175
>> 6 1935   134 288    154
>>
> Hi Frederic,
> The easiest method I can think of is this:
>
> Samaru$Start<-format(as.Date(
>   paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start,
>   "%b %d")
> Samaru$End<-format(as.Date(
>   paste(Samaru$Year,"01-01",sep="-"))+Samaru$End,
>   "%b %d")

In the package 'eha' I have a function 'toDate':

 > require(eha)
 > toDate(1930 + 108/365)
[1] "1930-04-19"

(Interestingly, we are all wrong; the correct answer seems to be 
"1930-04-18")

 > toDate
function (times)
{
     if (!is.numeric(times))
         stop("Argument must be numeric")
     times * 365.2425 + as.Date("0000-01-01")
}

The 'inverse' function is 'toTime'.

Sometimes it misses by one day; not very important in my applications, 
but may be otherwise.

G?ran B.

> Samaru
>
>    Year  Start    End Length
> 1 1930 Apr 19 Oct 16    180
> 2 1931 Apr 29 Oct 16    170
> 3 1932 Apr 25 Oct 22    180
> 4 1933 Jun 06 Oct 22    138
> 5 1934 Apr 27 Oct 19    175
> 6 1935 May 15 Oct 16    154
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jim at bitwrit.com.au  Tue Oct  7 12:01:44 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 07 Oct 2014 21:01:44 +1100
Subject: [R] Changing date format
In-Reply-To: <5433B7A6.2010408@umu.se>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<1486793.FaODssWil9@localhost.localdomain>
	<5433B7A6.2010408@umu.se>
Message-ID: <3161681.zHNUP8T3m9@localhost.localdomain>

On Tue, 7 Oct 2014 11:51:34 AM G?ran Brostr?m wrote:
> On 2014-10-07 11:27, Jim Lemon wrote:
> > On Tue, 7 Oct 2014 10:32:42 AM Frederic Ntirenganya wrote:
> >> Dear All,
> >> 
> >> How can I change the format of date of day of the year ? for
> > 
> > example r
> > 
> >> (i.e. "17 Apr" rather than "108").
> >> 
> >> The following is the type of the dataset I have
> >> 
> >> head(Samaru)
> >> 
> >>    Year Start End Length
> >> 
> >> 1 1930   108 288    180
> >> 2 1931   118 288    170
> >> 3 1932   115 295    180
> >> 4 1933   156 294    138
> >> 5 1934   116 291    175
> >> 6 1935   134 288    154
> > 
> > Hi Frederic,
> > The easiest method I can think of is this:
> > 
> > Samaru$Start<-format(as.Date(
> > 
> >   paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start,
> >   "%b %d")
> > 
> > Samaru$End<-format(as.Date(
> > 
> >   paste(Samaru$Year,"01-01",sep="-"))+Samaru$End,
> >   "%b %d")
> 
> In the package 'eha' I have a function 'toDate':
>  > require(eha)
>  > toDate(1930 + 108/365)
> 
> [1] "1930-04-19"
> 
> (Interestingly, we are all wrong; the correct answer seems to be
> "1930-04-18")
> 
>  > toDate
> 
> function (times)
> {
>      if (!is.numeric(times))
>          stop("Argument must be numeric")
>      times * 365.2425 + as.Date("0000-01-01")
> }
> 
> The 'inverse' function is 'toTime'.
> 
> Sometimes it misses by one day; not very important in my 
applications,
> but may be otherwise.
> 
Hi Goran,
You're correct.

 as.Date("Apr 19 1930","%b %d %Y") -
+ as.Date("Jan 1 1930","%b %d %Y")
Time difference of 108 days

The t

Samaru$Start<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start-1,"%b %d")
Samaru$End<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$End-1, "%b %d")

Jim


From Jose.Iparraguirre at ageuk.org.uk  Tue Oct  7 12:53:45 2014
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Tue, 7 Oct 2014 10:53:45 +0000
Subject: [R] a question about arimax, please
In-Reply-To: <CACxE24kkCeueKBJ272eRFszUPB5oNxqM6XO_pW7PMcO3yntzhw@mail.gmail.com>
References: <CACxE24=4TbvFvLS7WvX3FSrgAJTPR_jtb8y3v5MQHdqvay_9ag@mail.gmail.com>
	<9C45EE6A-763F-43B8-99F4-CE7C748DFF3D@gmail.com>
	<CACxE24kkCeueKBJ272eRFszUPB5oNxqM6XO_pW7PMcO3yntzhw@mail.gmail.com>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B243F2FA68@AGEPXMB006.uk.age.local>

Also, the package caschrono is very good for Arima-X. 
If you read French, the author, Yves Aragon, wrote an excellent book describing its use: "Series temporelles avec R" (Springer).


Prof. Jos? Iparraguirre
Chief Economist
Age UK


Age UK
Tavis House, 1- 6 Tavistock Square
London, WC1H 9NB

T 020 303 31482
E Jose.Iparraguirre at ageuk.org.uk
Twitter @jose.iparraguirre at ageuk


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Erin Hodgess
Sent: 06 October 2014 23:58
To: peter dalgaard
Cc: R help
Subject: Re: [R] a question about arimax, please

This is great...thanks so much!


On Mon, Oct 6, 2014 at 5:56 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> In package TSA?
>
> You may need to do some studying for yourself, this is complicated stuff.
>
> As I read the help page, the intention is that the transfer= bit is to 
> allow a _covariate_ to affect the process in an ARMA-like fashion. So
> c(1,0) would be AR(1)-like which if I remember correctly corresponds 
> to an exponentially decaying effect of instantaneous shocks to the 
> system. And
> c(0,0) would be MA(0)-like, which I suppose would be an effect that 
> only affected the same period as the instantaneous shock. In the 
> example, we have the same covariate (Sept. 2001) contributing with 
> both kinds of effect, so xtransf= has the same variable twice.
>
> -pd
>
> On 06 Oct 2014, at 19:11 , Erin Hodgess <erinm.hodgess at gmail.com> wrote:
>
> > Hello!
> > I have about the arimax function, please:
> > If you see the example page, you see the following:
> > # Exhibit 11.6
> > air.m1=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1
> > ,1), period=12),xtransf=data.frame(I911=1*(seq(airmiles)==69),
> > I911=1*(seq(airmiles)==69)),
> > transfer=list(c(0,0),c(1,0)),xreg=data.frame(Dec96=1*(seq(airmiles)=
> > =12),
> > Jan97=1*(seq(airmiles)==13),Dec02=1*(seq(airmiles)==84)),method='ML'
> > ) Now the part that I am puzzled about the "transfer" argument, 
> > please. It
> is
> > supposed to be the MA order and the AR order, respectively. However, 
> > the
> AR
> > order is 0. Should that be reversed, please?
> > Thanks,
> > Erin.
> >
> > --
> > Erin Hodgess
> > Associate Professor
> > Department of Mathematical and Statistics University of Houston - 
> > Downtown
> > mailto: erinm.hodgess at gmail.com
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3, 
> 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>


--
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Age UK Love Later life

www.ageuk.org.uk

-------------------------------------------------------------------------------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 
1128267, registered company number 6825798) Registered office: Tavis House, 1-6 Tavistock 
Square, London WC1H 9NA

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK 
Enterprises Limited, Age UK is an Introducer Appointed Representative of JLT Benefit Solutions 
Limited for the purposes of introducing potential annuity customers.  Age Enterprises Limited and JLT 
Benefit Solutions Limited are both authorised and regulated by the Financial Services Authority.  

Charitable Services are offered through Age UK (the Charity) and commercial products and services 
are offered by the Charity?s subsidiary companies.  The Age UK Group comprises of Age UK, and its 
subsidiary companies and charities, dedicated to improving the lives of people in later life.  Our 
network includes the three national charities Age Cymru, Age NI and Age Scotland and more than
 160 local Age UK charities.
------------------------------
This email and any files transmitted with it are confidential and intended solely for the use of the
individual or entity to whom they are addressed. If you receive a message in error, please advise the
sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this 
email are those of the author and do not necessarily reflect the opinions of Age UK or its subsidiaries 
and associated companies. Age UK monitors all e-mail transmissions passing through its network and 
may block or modify mails which are deemed to be unsuitable.


From ntfredo at gmail.com  Tue Oct  7 14:25:54 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 7 Oct 2014 15:25:54 +0300
Subject: [R] Changing date format
In-Reply-To: <3161681.zHNUP8T3m9@localhost.localdomain>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<1486793.FaODssWil9@localhost.localdomain>
	<5433B7A6.2010408@umu.se>
	<3161681.zHNUP8T3m9@localhost.localdomain>
Message-ID: <CAGh51gTQkztOUDfsHwVHVFT-B1VQk=LP0VvywndMZRPvQB0KzA@mail.gmail.com>

Thanks All. Your idea is useful!!!

On Tue, Oct 7, 2014 at 1:01 PM, Jim Lemon <jim at bitwrit.com.au> wrote:

> On Tue, 7 Oct 2014 11:51:34 AM G?ran Brostr?m wrote:
> > On 2014-10-07 11:27, Jim Lemon wrote:
> > > On Tue, 7 Oct 2014 10:32:42 AM Frederic Ntirenganya wrote:
> > >> Dear All,
> > >>
> > >> How can I change the format of date of day of the year ? for
> > >
> > > example r
> > >
> > >> (i.e. "17 Apr" rather than "108").
> > >>
> > >> The following is the type of the dataset I have
> > >>
> > >> head(Samaru)
> > >>
> > >>    Year Start End Length
> > >>
> > >> 1 1930   108 288    180
> > >> 2 1931   118 288    170
> > >> 3 1932   115 295    180
> > >> 4 1933   156 294    138
> > >> 5 1934   116 291    175
> > >> 6 1935   134 288    154
> > >
> > > Hi Frederic,
> > > The easiest method I can think of is this:
> > >
> > > Samaru$Start<-format(as.Date(
> > >
> > >   paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start,
> > >   "%b %d")
> > >
> > > Samaru$End<-format(as.Date(
> > >
> > >   paste(Samaru$Year,"01-01",sep="-"))+Samaru$End,
> > >   "%b %d")
> >
> > In the package 'eha' I have a function 'toDate':
> >  > require(eha)
> >  > toDate(1930 + 108/365)
> >
> > [1] "1930-04-19"
> >
> > (Interestingly, we are all wrong; the correct answer seems to be
> > "1930-04-18")
> >
> >  > toDate
> >
> > function (times)
> > {
> >      if (!is.numeric(times))
> >          stop("Argument must be numeric")
> >      times * 365.2425 + as.Date("0000-01-01")
> > }
> >
> > The 'inverse' function is 'toTime'.
> >
> > Sometimes it misses by one day; not very important in my
> applications,
> > but may be otherwise.
> >
> Hi Goran,
> You're correct.
>
>  as.Date("Apr 19 1930","%b %d %Y") -
> + as.Date("Jan 1 1930","%b %d %Y")
> Time difference of 108 days
>
> The t
>
> Samaru$Start<-format(as.Date(
>  paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start-1,"%b %d")
> Samaru$End<-format(as.Date(
>  paste(Samaru$Year,"01-01",sep="-"))+Samaru$End-1, "%b %d")
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From Stephen.Bond at cibc.com  Tue Oct  7 15:01:35 2014
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Tue, 7 Oct 2014 13:01:35 +0000
Subject: [R] lattice add a fit
Message-ID: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>

What is the way to add an arbitrary fit from a model to a lattice conditioning plot ?

For example
xyplot(v1 ~v2 | v3,data=mydata,
        panel=function(...){
            panel.xyplot(...)
            panel.loess(...,col.line="red")
        }
)
Will add a loess smoother. Instead, I want to put a fit from lm (but not a simple straight line) and the fit has to be done for each panel separately, not one fit for the full data set, so sth like an lm equivalent of panel.locfit (there is no panel.lmfit)
Thank you.

Stephen B


	[[alternative HTML version deleted]]


From mmuurr at gmail.com  Tue Oct  7 04:33:54 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Mon, 6 Oct 2014 20:33:54 -0600
Subject: [R] par("plt") behaving inconsistely? bug?
In-Reply-To: <CAFEqCdxM5vz-2MCeNTNmreugXvST43jpypmknX63dpgD_amB8A@mail.gmail.com>
References: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>
	<CAFEqCdxM5vz-2MCeNTNmreugXvST43jpypmknX63dpgD_amB8A@mail.gmail.com>
Message-ID: <CA+YV+HyqpfNO2U7ako1rcy9WT_DUi2WvQvsEFpMW_7cEdd=Nxg@mail.gmail.com>

6. iteratively downgrade to earlier versions of R until it's working
again... then try to diff out the offending source code change.
i can try this, but i probably won't get to it for at least a few weeks :-/

in the meantime, i'm tacking on box(lty = 0) to every par(plt = ...) call, e.g.
> par("plt" = some_plt_coordinates); box(lty = 0)

in the short term, this works.
clip(...), a combination of par("new" = TRUE); plot.new(), and a whole
bunch of other kludges work, too... pick your poison :-)

cheers and thanks!

-murat

On Mon, Oct 6, 2014 at 2:08 PM, Greg Snow <538280 at gmail.com> wrote:
> I believe that what is happening is that the clipping region is being
> reset when you call box, but not when you call rect.  If you insert
> the command "par(xpd=NA)" (or TRUE instead of NA) after the plot.new
> and use the rect commands then you can see both rectangles (because
> this turns the clipping off).  Working with the clipping region
> (indirectly in your case) is complex since some functions properly
> reset the region and others do not (and  making the others
> automatically reset it may cause other problems when they reset a
> clipping region that should not be reset).
>
> So the options are:
>
> 1 dive into the source code enough to figure out if fixing rect to
> work with the clipping region is simple or not and submitting a patch
> 2 wait for Prof Brian Ripley to notice this fact and do the above (he
> has fixed a couple of other functions when made aware)
> 3 use par(xpd=TRUE) (or NA) to not clip to the plotting region (this
> is simple, but will allow things to be drawn outside of the plotting
> region, on simple example is using abline)
> 4 use a function that properly sets the clipping region (such as box)
> before plotting anything else
> 5 call clip(0,1,0,1) (or with the actual user coordinates) to manually
> set the clipping region
> 6 other?
>
>
> On Mon, Oct 6, 2014 at 12:00 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>> Hi all -- I just encountered a behavior that I believe has changed
>> from previous versions, though I haven't chased back the last version
>> that behaves as my existing code expects quite yet.
>> Perhaps this is a bug, though perhaps I'm missing a subtle detail
>> somewhere in the documentation...
>>
>> Here's some code that works as expected (in R 3.1.1):
>>
>> ########################################
>> pdf()
>> plot.new()
>>
>> original_plt <- par("plt")
>>
>> plt_1 <- c(original_plt[1],
>>            original_plt[1] + (original_plt[2] - original_plt[1]) / 2,
>>            original_plt[3],
>>            original_plt[3] + (original_plt[4] - original_plt[3]) / 2)
>> par("plt" = plt_1)
>> plot.window(xlim = c(0, 1), ylim = c(0, 1))
>> box()
>> plt_2 <- c(plt_1[2],
>>            original_plt[2],
>>            plt_1[4],
>>            original_plt[4])
>> par("plt" = plt_2)
>> plot.window(xlim = c(0, 1), ylim = c(0, 1))
>> box()
>> par("plt" = original_plt)
>> box(lty = 2)
>> dev.off()
>> ########################################
>>
>> This will draw 3 boxes... one in the lower left corner (specified by
>> plt_1), one in the top right corner (specified by plt_2), and one
>> dotted box around the full plot box (original_plt).
>>
>> Now, if you replace the first two box() calls by: rect(0, 0, 1, 1),
>> only the lower-left rectangle is drawn.
>> If you _add_ rect(0, 0, 1, 1) after each box() call, all boxes and
>> rectangles are correctly drawn.
>>
>> It seems that after setting plt once, subsequent plt alterations put
>> the device into a state that will permits drawing of _some_ things
>> (e.g. box()), but not other things (e.g. rect, lines, points).
>>
>> A kludge to fix this is to call box(col = "white")... but that's quite
>> the kludge, indeed!
>> Axis() works just like box(), too... but I haven't exhausted which
>> drawing functions work and which don't.
>>
>> I'd classify this is a bug, but I thought I'd check here first.
>> I've also only checked this so far with the pdf() device, so I don't
>> know if it is somehow device-specific.
>>
>> I detected this because some existing code (that worked on some
>> earlier version of R, sorry that I don't know which one yet...) has
>> suddenly stopped working!
>>
>> Cheers!
>>
>> -murat
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com


From rahul.gupta at us.ibm.com  Mon Oct  6 23:23:47 2014
From: rahul.gupta at us.ibm.com (Rahul Gupta1)
Date: Mon, 6 Oct 2014 16:23:47 -0500
Subject: [R] jfindClass class not found - Please Help
Message-ID: <OF0D06B7E0.418F7FCA-ON87257D69.007579A6-86257D69.00758B90@us.ibm.com>


> library(RJDBC)
Loading required package: DBI
Loading required package: rJava
> jcc = JDBC
("com/ibm/db2/jcc/DB2Driver","/opt/ibm/db2/java/lib/db2jcc4.jar")
Error in .jfindClass(as.character(driverClass)[1]) : class not found
	[[alternative HTML version deleted]]


From dieter at duenenhof-wilhelm.de  Tue Oct  7 08:45:59 2014
From: dieter at duenenhof-wilhelm.de (H. Dieter Wilhelm)
Date: Tue, 7 Oct 2014 08:45:59 +0200
Subject: [R] Evaluation of global variables in function definitions
Message-ID: <877g0cjs2g.fsf@vsl28t2g.ww011>

Hello (),

I'd like to do the following

a <- 3
f1 <- function (x){
 a*x^2
}

a <- 5
f2 <- function (x){
 a*x^2
}

plotting f1, f2, ...

but f1 and f2 are the same, how can I evaluated the variables in the
function definition?

Thank you
      Dieter
-- 
Best wishes
H. Dieter Wilhelm
Darmstadt, Germany


From Ariadna.Angulo at uab.cat  Tue Oct  7 09:05:31 2014
From: Ariadna.Angulo at uab.cat (Ariadna Angulo Brunet)
Date: Tue, 7 Oct 2014 07:05:31 +0000
Subject: [R] Path Diagram from Mplus semPaths{semPlot}
Message-ID: <5c07546133814bb1affe307978ccfd3b@DBXPR07MB304.eurprd07.prod.outlook.com>

Hi,

I am working with an OUT file from Mplus. I want to plot a path diagram with my SEM results.
semPaths does it automatically but I want to ignore some variables of my study (meaning I don't want them on the path diagram but I want the variables include in the sem analysis.

Exactly I want to ignore  RELF AUTF and COMF, because that variables form a second order factor (BNF) and I doesn't need it in the path.

Does anyone know a command or another package/function that could work with that?

Im using the following sintaxis:

outfile <- "quested.out"
semPaths(outfile,what="est",instStyle="multi", intercepts=FALSE, rotation=4,  edge.color="black", sizeMan=5, esize=TRUE, structural="TRUE", ThreshAtSide="FALSE", layout="tree2")

and my model from Mplus looks like that:
MODEL:

    ASF BY p1mcas1 p1mcas2 p1mcas3 p1mcas4 p1mcas5;

    COMPF BY p1bnc1 p1bnc2 p1bnc3 p1bnc4 p1bnc5 p1bnc6;

    AUTF BY p1bna1 p1bna2 p1bna4 p1bna5;

    RELATF BY p1bnr1 p1bnr2 p1bnr3 p1bnr4;

    ENF BY p1en1 p1en2 p1en3 p1en4;

    IDROPF BY p1do1 p1do2r p1do3 p1do4r;



    bnf  ON asf ;
    enf  ON bnf ;
    idropf ON enf ;

    MODEL INDIRECT:
     enf IND bnf asf;
     idropf IND enf bnf;
     idropf IND enf bnf asf;


Thank you in advance,


Ariadna

	[[alternative HTML version deleted]]


From statistics84 at hotmail.com  Tue Oct  7 10:55:26 2014
From: statistics84 at hotmail.com (pari hesabi)
Date: Tue, 7 Oct 2014 08:55:26 +0000
Subject: [R] maximum likelihood estimation
Message-ID: <DUB125-W40C23339F6A3D605020ACDC6A20@phx.gbl>

HelloI am trying to estimate the parameter of a function by the Maximum Likelihood Estimation method.If  the function is the difference between two integrals: C<-function(n){integrand3<-function(x) {((2-x)^n)*(exp(ax-2))}cc<- integrate (integrand3,0,2)print(cc)}
D<-function(n){integrand4<-function(x) {((5-ax)^n)}cc<- integrate (integrand4,0,2)print(cc)}
f(n) = C(n) - D(n)
 I need to estimate parameter (a).   loglikelihood function is in the form of  sum[F(k) log(f(k))]=lnL. I am wondering how to introduce my logliklihood function to the loop below.  Can anybody help me for correcting the following loop? if there are some other packages better than this , please let me know.Thank you,Diba
n <- c(0,1,2,3,4,5,6,7,8)
F<-c(0,0,1,3,5,7,8,11,10)
loglik <- function(a) sum(F*log(C(n)-D(n)))
re <- maxLik (loglik, start=.5)
summary(re) 		 	   		  
	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Tue Oct  7 11:20:28 2014
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 7 Oct 2014 17:20:28 +0800
Subject: [R] Find growth rate of a zoo (time series) object
Message-ID: <CABcx46D8uz1DfJJKauVSrZgm2PE2RqpXdZ4+cKRnUWi_2m4JtQ@mail.gmail.com>

Hi,

   Is there any way to find the growth rate of a quarterly/monthly time
series? For example, I have a quarterly CPI level series, and I wonder how
to find the CPI growth rate (inflation rate). Is there easier way to
convert to another class and convert back?

Thanks!



> dput(dtz[1:16,"CPI"])
structure(c(58.7966666666667, 59.5733333333333, 60.7366666666667,
60.78, 60.9033333333333, 61.39, 62.6066666666667, 62.0733333333333,
62.58, 63.1033333333333, 62.6033333333333, 62.0633333333333,
61.8333333333333, 62.7566666666667, 63.0333333333333, 62.6533333333333
), index = structure(c(1981, 1981.25, 1981.5, 1981.75, 1982,
1982.25, 1982.5, 1982.75, 1983, 1983.25, 1983.5, 1983.75, 1984,
1984.25, 1984.5, 1984.75), class = "yearqtr"), class = "zoo")

	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Tue Oct  7 11:22:46 2014
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 7 Oct 2014 17:22:46 +0800
Subject: [R] Time series Regression with lags
Message-ID: <CABcx46D4pzDgdqjX6P4-BFHf3_CPnEjgqvLesHYMqW4Wp-JRWQ@mail.gmail.com>

Hi,

   I am working on zoo (time series) objects.

   Is there any way to do a time series regression with a lag period?

E.g., Y(t) = b1*X1(t)+b2*X(t-1)+b3*X2(t)....

   Is "dynlm" the default one to use? Anything else

Thanks!

	[[alternative HTML version deleted]]


From jhernandezcabrera at gmail.com  Tue Oct  7 15:40:57 2014
From: jhernandezcabrera at gmail.com (Juan Andres Hernandez)
Date: Tue, 7 Oct 2014 14:40:57 +0100
Subject: [R] How to extract table results from survival summary object
Message-ID: <CAL79i+Rfgy_dBtzq3s1esL5+P+N0r6no1SxGDHY8he6ZcdE+dw@mail.gmail.com>

Hi. I need to extract the "matrix" or "data.frame" results from a survival
object.

library(survival)
data(lung)
mod=with(lung, survfit(Surv(time,death)~ 1))
res=summary(mod)

res show in consola the "matrix" I am looking for, but I can't find the way
to save or assign this table to an object. Anyone knows how to solve it.
Thank's in advance

Juan A. Hern?ndez

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Tue Oct  7 15:54:49 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 7 Oct 2014 09:54:49 -0400
Subject: [R] Evaluation of global variables in function definitions
In-Reply-To: <877g0cjs2g.fsf@vsl28t2g.ww011>
References: <877g0cjs2g.fsf@vsl28t2g.ww011>
Message-ID: <5433F0A9.1020505@gmail.com>

On 07/10/2014 2:45 AM, H. Dieter Wilhelm wrote:
> Hello (),
>
> I'd like to do the following
>
> a <- 3
> f1 <- function (x){
>   a*x^2
> }
>
> a <- 5
> f2 <- function (x){
>   a*x^2
> }
>
> plotting f1, f2, ...
>
> but f1 and f2 are the same, how can I evaluated the variables in the
> function definition?
>
> Thank you
>        Dieter
See the "open.account" example in section 10.7, "Scope", of the 
Introduction to R manual.

Duncan Murdoch


From Stephen.Bond at cibc.com  Tue Oct  7 17:13:31 2014
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Tue, 7 Oct 2014 15:13:31 +0000
Subject: [R] lattice add a fit
In-Reply-To: <CACk-te1jj+hA0s0uRH4rpsinxsj2LweYmpkTnaWJBo8RSP5rWA@mail.gmail.com>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
	<CACk-te1jj+hA0s0uRH4rpsinxsj2LweYmpkTnaWJBo8RSP5rWA@mail.gmail.com>
Message-ID: <624EC9773CAB044ABA65327271BED9B60A8B4236@CBMCC-X10-MA01.ad.cibc.com>

Bert,

Can you provide an example how to pass the conditioned data set?

xyplot( x~y | z, data=mydata,
panel=function(...){ 
mod=lm(x~ y+w +q, data=??)
panel.lines(fitted(mod))

}

If I use mydata in place of ?? I get a global fit, not a fit for each level of z, which is what I want.

Stephen B


-----Original Message-----
From: Bert Gunter [mailto:gunter.berton at gene.com] 
Sent: Tuesday, October 07, 2014 9:30 AM
To: Bond, Stephen
Cc: r-help at R-project.org
Subject: Re: [R] lattice add a fit

Fit your model in the panel function using lm and plot the fits using ?panel.points, ?panel.lines, etc.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
Clifford Stoll




On Tue, Oct 7, 2014 at 6:01 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> What is the way to add an arbitrary fit from a model to a lattice conditioning plot ?
>
> For example
> xyplot(v1 ~v2 | v3,data=mydata,
>         panel=function(...){
>             panel.xyplot(...)
>             panel.loess(...,col.line="red")
>         }
> )
> Will add a loess smoother. Instead, I want to put a fit from lm (but 
> not a simple straight line) and the fit has to be done for each panel separately, not one fit for the full data set, so sth like an lm equivalent of panel.locfit (there is no panel.lmfit) Thank you.
>
> Stephen B
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From dcarlson at tamu.edu  Tue Oct  7 17:43:41 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 7 Oct 2014 15:43:41 +0000
Subject: [R] How to extract table results from survival summary object
In-Reply-To: <CAL79i+Rfgy_dBtzq3s1esL5+P+N0r6no1SxGDHY8he6ZcdE+dw@mail.gmail.com>
References: <CAL79i+Rfgy_dBtzq3s1esL5+P+N0r6no1SxGDHY8he6ZcdE+dw@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9E2FF@mb02.ads.tamu.edu>

This will create a data.frame containing the results of the summary(mod) object. You can find out what that is using the command ?summary.survfit. You have an error in your example since death is not a variable in lung:

> library(survival)
> data(lung)
> mod <- with(lung, survfit(Surv(time, status)~ 1))
> res <- summary(mod)
> str(res)
List of 14
 $ n        : int 228
 $ time     : num [1:139] 5 11 12 13 15 26 30 31 53 54 ...
 $ n.risk   : num [1:139] 228 227 224 223 221 220 219 218 217 215 ...
 $ n.event  : num [1:139] 1 3 1 2 1 1 1 1 2 1 ...
 $ n.censor : num [1:139] 0 0 0 0 0 0 0 0 0 0 ...
 $ surv     : num [1:139] 0.996 0.982 0.978 0.969 0.965 ...
 $ type     : chr "right"
 $ std.err  : num [1:139] 0.00438 0.00869 0.0097 0.01142 0.01219 ...
 $ upper    : num [1:139] 1 1 0.997 0.992 0.989 ...
 $ lower    : num [1:139] 0.987 0.966 0.959 0.947 0.941 ...
 $ conf.type: chr "log"
 $ conf.int : num 0.95
 $ call     : language survfit(formula = Surv(time, status) ~ 1)
 $ table    : Named num [1:7] 228 228 228 165 310 285 363
  ..- attr(*, "names")= chr [1:7] "records" "n.max" "n.start" "events" ...
 - attr(*, "class")= chr "summary.survfit"
> # Extract the columns you want
> cols <- lapply(c(2:6, 8:10) , function(x) res[x])
> # Combine the columns into a data frame
> tbl <- do.call(data.frame, cols)
> str(tbl)
'data.frame':   139 obs. of  8 variables:
 $ time    : num  5 11 12 13 15 26 30 31 53 54 ...
 $ n.risk  : num  228 227 224 223 221 220 219 218 217 215 ...
 $ n.event : num  1 3 1 2 1 1 1 1 2 1 ...
 $ n.censor: num  0 0 0 0 0 0 0 0 0 0 ...
 $ surv    : num  0.996 0.982 0.978 0.969 0.965 ...
 $ std.err : num  0.00438 0.00869 0.0097 0.01142 0.01219 ...
 $ upper   : num  1 1 0.997 0.992 0.989 ...
 $ lower   : num  0.987 0.966 0.959 0.947 0.941 ...

Since res is a list containing the columns you want plus other information, we need to extract the needed columns from res and then combine those columns into a data.frame.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Juan Andres Hernandez
Sent: Tuesday, October 7, 2014 8:41 AM
To: r-help at r-project.org
Subject: [R] How to extract table results from survival summary object

Hi. I need to extract the "matrix" or "data.frame" results from a survival
object.

library(survival)
data(lung)
mod=with(lung, survfit(Surv(time,death)~ 1))
res=summary(mod)

res show in consola the "matrix" I am looking for, but I can't find the way
to save or assign this table to an object. Anyone knows how to solve it.
Thank's in advance

Juan A. Hern?ndez

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From gunter.berton at gene.com  Tue Oct  7 17:43:59 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 7 Oct 2014 08:43:59 -0700
Subject: [R] lattice add a fit
In-Reply-To: <624EC9773CAB044ABA65327271BED9B60A8B4236@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
	<CACk-te1jj+hA0s0uRH4rpsinxsj2LweYmpkTnaWJBo8RSP5rWA@mail.gmail.com>
	<624EC9773CAB044ABA65327271BED9B60A8B4236@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <CACk-te2cmYKVdT6HEkrWmFED1MH0XdTfU12o7-gwNvjqcDH0vw@mail.gmail.com>

You need to explicitly pass the subscripts arguments and your
covariates. See ?xyplot for details. Your panel function call would
then be something like:

        panel=function(x,y,subscripts,w,z, ...){
            panel.xyplot(x,y,...)
             panel.loess(x,y,...,col.line="red"
            mod <- lm(y~x + w + z, data = data[subscripts,])
           ... etc.
}


Cheers,
Bert



Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Oct 7, 2014 at 8:13 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> Bert,
>
> Can you provide an example how to pass the conditioned data set?
>
> xyplot( x~y | z, data=mydata,
> panel=function(...){
> mod=lm(x~ y+w +q, data=??)
> panel.lines(fitted(mod))
>
> }
>
> If I use mydata in place of ?? I get a global fit, not a fit for each level of z, which is what I want.
>
> Stephen B
>
>
> -----Original Message-----
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Tuesday, October 07, 2014 9:30 AM
> To: Bond, Stephen
> Cc: r-help at R-project.org
> Subject: Re: [R] lattice add a fit
>
> Fit your model in the panel function using lm and plot the fits using ?panel.points, ?panel.lines, etc.
>
> -- Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Tue, Oct 7, 2014 at 6:01 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
>> What is the way to add an arbitrary fit from a model to a lattice conditioning plot ?
>>
>> For example
>> xyplot(v1 ~v2 | v3,data=mydata,
>>         panel=function(...){
>>             panel.xyplot(...)
>>             panel.loess(...,col.line="red")
>>         }
>> )
>> Will add a loess smoother. Instead, I want to put a fit from lm (but
>> not a simple straight line) and the fit has to be done for each panel separately, not one fit for the full data set, so sth like an lm equivalent of panel.locfit (there is no panel.lmfit) Thank you.
>>
>> Stephen B
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Tue Oct  7 17:46:11 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 7 Oct 2014 08:46:11 -0700
Subject: [R] lattice add a fit
In-Reply-To: <624EC9773CAB044ABA65327271BED9B60A8B4236@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
	<CACk-te1jj+hA0s0uRH4rpsinxsj2LweYmpkTnaWJBo8RSP5rWA@mail.gmail.com>
	<624EC9773CAB044ABA65327271BED9B60A8B4236@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <CACk-te2_BomVoPv3cfA5G_56ytJ4NykMA1-7ZCU4QKyRidcvow@mail.gmail.com>

Sorry,
you do **NOT** need to pass the covariates if the data argument to lm
is used. Or you can explicitly pass the covariates and subscript them
in your panel function.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Oct 7, 2014 at 8:13 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> Bert,
>
> Can you provide an example how to pass the conditioned data set?
>
> xyplot( x~y | z, data=mydata,
> panel=function(...){
> mod=lm(x~ y+w +q, data=??)
> panel.lines(fitted(mod))
>
> }
>
> If I use mydata in place of ?? I get a global fit, not a fit for each level of z, which is what I want.
>
> Stephen B
>
>
> -----Original Message-----
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> Sent: Tuesday, October 07, 2014 9:30 AM
> To: Bond, Stephen
> Cc: r-help at R-project.org
> Subject: Re: [R] lattice add a fit
>
> Fit your model in the panel function using lm and plot the fits using ?panel.points, ?panel.lines, etc.
>
> -- Bert
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
> (650) 467-7374
>
> "Data is not information. Information is not knowledge. And knowledge is certainly not wisdom."
> Clifford Stoll
>
>
>
>
> On Tue, Oct 7, 2014 at 6:01 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
>> What is the way to add an arbitrary fit from a model to a lattice conditioning plot ?
>>
>> For example
>> xyplot(v1 ~v2 | v3,data=mydata,
>>         panel=function(...){
>>             panel.xyplot(...)
>>             panel.loess(...,col.line="red")
>>         }
>> )
>> Will add a loess smoother. Instead, I want to put a fit from lm (but
>> not a simple straight line) and the fit has to be done for each panel separately, not one fit for the full data set, so sth like an lm equivalent of panel.locfit (there is no panel.lmfit) Thank you.
>>
>> Stephen B
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From plalehzari at platinumlp.com  Tue Oct  7 18:55:04 2014
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Tue, 7 Oct 2014 16:55:04 +0000
Subject: [R] Conditional Data Manipulation -Cumulative Product
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24D80@EX02.platinum.com>

Hello,
I have three datasets StartSignals, MainData, StopSignals and need to compound the data for each variable in MainData over dates that fall between the Start and Stop signals. (Stop signals are common and the same to all X1:X5 variables). Please see sample below:
The one way I was thinking of doing this project was to setup a nested "FOR" loop and go through the three data matrices. Is there a more elegant way of doing this?
Thank you.

StartSignals:
Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1

0

0

1

1/3/2014

0

0

1

0

0

1/4/2014

0

0

0

0

0

1/5/2014

1

0

0

0

1

1/6/2014

0

0

1

0

0

1/7/2014

0

0

0

1

0

1/8/2014

0

0

0

0

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1

1

0

1/11/2014

1

0

0

0

0

1/12/2014

0

1

0

0

1

1/13/2014

0

0

0

0

0




MainData:
Date

X1

X2

X3

X4

X5

1/1/2014

1.92

1.38

0.83

1.25

1.12

1/2/2014

0.67

1.51

1.21

0.06

1.24

1/3/2014

1.09

0.09

0.2

1.62

0.3

1/4/2014

1.81

1.33

1.57

1.68

1.41

1/5/2014

1.04

0.38

1.72

1.98

1.23

1/6/2014

1.69

1.12

0.76

1.45

1.99

1/7/2014

1.57

1.3

1.22

0.66

1.75

1/8/2014

0.5

1.75

0.27

0.09

1.91

1/9/2014

0

1.26

0.59

0.4

1.81

1/10/2014

1.31

1.57

1.68

0.98

1.79

1/11/2014

0.43

1.63

1.98

1.46

0.81

1/12/2014

1.51

0.78

1.63

0.46

1.84

1/13/2014

0.26

0.34

0.34

0.97

1.13




StopSignals:
Date

Stop

1/1/2014

0

1/2/2014

0

1/3/2014

1

1/4/2014

0

1/5/2014

1

1/6/2014

0

1/7/2014

0

1/8/2014

1

1/9/2014

0

1/10/2014

0

1/11/2014

0

1/12/2014

0

1/13/2014

1



ExpectedResult:

Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1.51

0

0

1.24

1/3/2014

0

0.14

0.2

0

0.37

1/4/2014

0

0

0

0

0

1/5/2014

1.04

0

0

0

1.23

1/6/2014

0

0

0.76

0

0

1/7/2014

0

0

0.93

0.66

0

1/8/2014

0

0

0.25

0.06

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1.68

0.98

0

1/11/2014

0.43

0

3.33

1.43

0

1/12/2014

0.65

0.78

5.42

0.66

1.84

1/13/2014

0.17

0.27

1.84

0.64

2.08










***
We are pleased to announce that, as of October 20th, 2014, we will be moving to
our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN
CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE
OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE
CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
	[[alternative HTML version deleted]]


From plalehzari at platinumlp.com  Tue Oct  7 20:07:41 2014
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Tue, 7 Oct 2014 18:07:41 +0000
Subject: [R] Conditional Data Manipulation -Cumulative Product
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24E99@EX02.platinum.com>

I noticed the data samples did not come out legible in the original email. Here is the original email with data as plain text that should make it more legible.

____________________
Hello,
I have three datasets StartSignals, MainData, StopSignals and need to compound the data for each variable in MainData over dates that fall between the Start and Stop signals. (Stop signals are common and the same to all X1:X5 variables). Please see sample below:
The one way I was thinking of doing this project was to setup a nested "FOR" loop and go through the three data matrices. Is there a more elegant way of doing this?
Thank you.

StartSignals:
Date                      X1           X2           X3           X4           X5
1/1/2014              0              0              0              0              0
1/2/2014              0              1              0              0              1
1/3/2014              0              0              1              0              0
1/4/2014              0              0              0              0              0
1/5/2014              1              0              0              0              1
1/6/2014              0              0              1              0              0
1/7/2014              0              0              0              1              0
1/8/2014              0              0              0              0              0
1/9/2014              0              0              0              0              0
1/10/2014            0              0              1              1              0
1/11/2014            1              0              0              0              0
1/12/2014            0              1              0              0              1
1/13/2014            0              0              0              0              0


MainData:
Date                      X1           X2           X3           X4           X5
1/1/2014              1.92        1.38        0.83        1.25        1.12
1/2/2014              0.67        1.51        1.21        0.06        1.24
1/3/2014              1.09        0.09        0.2          1.62        0.3
1/4/2014              1.81        1.33        1.57        1.68        1.41
1/5/2014              1.04        0.38        1.72        1.98        1.23
1/6/2014              1.69        1.12        0.76        1.45        1.99
1/7/2014              1.57        1.3          1.22        0.66        1.75
1/8/2014              0.5          1.75        0.27        0.09        1.91
1/9/2014              0              1.26        0.59        0.4          1.81
1/10/2014            1.31        1.57        1.68        0.98        1.79
1/11/2014            0.43        1.63        1.98        1.46        0.81
1/12/2014            1.51        0.78        1.63        0.46        1.84
1/13/2014            0.26        0.34        0.34        0.97        1.13


StopSignals:
Date                      Stop
1/1/2014              0
1/2/2014              0
1/3/2014              1
1/4/2014              0
1/5/2014              1
1/6/2014              0
1/7/2014              0
1/8/2014              1
1/9/2014              0
1/10/2014            0
1/11/2014            0
1/12/2014            0
1/13/2014            1

ExpectedResult:

Date                      X1           X2           X3           X4           X5
1/1/2014              0              0              0              0              0
1/2/2014              0              1.51        0              0              1.24
1/3/2014              0              0.14        0.2          0              0.37
1/4/2014              0              0              0              0              0
1/5/2014              1.04        0              0              0              1.23
1/6/2014              0              0              0.76        0              0
1/7/2014              0              0              0.93        0.66        0
1/8/2014              0              0              0.25        0.06        0
1/9/2014              0              0              0              0              0
1/10/2014            0              0              1.68        0.98        0
1/11/2014            0.43        0              3.33        1.43        0
1/12/2014            0.65        0.78        5.42        0.66        1.84
1/13/2014            0.17        0.27        1.84        0.64        2.08








***
We are pleased to announce that, as of October 20th, 2014, we will be moving to
our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN
CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE
OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE
CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
	[[alternative HTML version deleted]]


From abmathewks at gmail.com  Tue Oct  7 16:51:22 2014
From: abmathewks at gmail.com (Abraham Mathew)
Date: Tue, 7 Oct 2014 09:51:22 -0500
Subject: [R] Find common two and three word phrases in a corpus
Message-ID: <CAJ-4XAoy1D4wa_iov91KdADkFE97Et3ao31k1p0ED9N5Wj=qxA@mail.gmail.com>

Let's say I have a corpus and want to find the two, three, etc word phrases
that occur most frequently in the data. I normally do this in the following
manner but am getting an error message and am having some difficulty
diagnosing what is going wrong. Given the following data, I'd just want a
count of 2 for the number of 2 word phrases given that "that sucks" appears
twice.

dat = c("love it", "who goes there", "what is wrong", "that sucks", "that
sucks")

(corpus <- Corpus(VectorSource(dat)))

matrix <- create_matrix(corpus, ngramLength=2)

bww_freq = findFreqTerms(matrix, lowfreq=5)

Here is the error message when I attempt to create a matrix

> (corpus <- Corpus(VectorSource(dat)))
<<VCorpus (documents: 5, metadata (corpus/indexed): 0/0)>>
> matrix <- create_matrix(corpus, ngramLength=2)
Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),
 :
  dims [product 5] do not match the length of object [3]


Can anyone tell me what could be going wrong? or a workaround? or another
package which could give me the desires result in a more efficient manner.

	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Tue Oct  7 15:30:26 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 7 Oct 2014 06:30:26 -0700
Subject: [R] lattice add a fit
In-Reply-To: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <CACk-te1jj+hA0s0uRH4rpsinxsj2LweYmpkTnaWJBo8RSP5rWA@mail.gmail.com>

Fit your model in the panel function using lm and plot the fits using
?panel.points, ?panel.lines, etc.

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Oct 7, 2014 at 6:01 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> What is the way to add an arbitrary fit from a model to a lattice conditioning plot ?
>
> For example
> xyplot(v1 ~v2 | v3,data=mydata,
>         panel=function(...){
>             panel.xyplot(...)
>             panel.loess(...,col.line="red")
>         }
> )
> Will add a loess smoother. Instead, I want to put a fit from lm (but not a simple straight line) and the fit has to be done for each panel separately, not one fit for the full data set, so sth like an lm equivalent of panel.locfit (there is no panel.lmfit)
> Thank you.
>
> Stephen B
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmorgan at trystero.is  Tue Oct  7 15:50:32 2014
From: rmorgan at trystero.is (Rianna Morgan)
Date: Tue, 07 Oct 2014 06:50:32 -0700
Subject: [R] How to extract table results from survival summary object
In-Reply-To: <CAL79i+Rfgy_dBtzq3s1esL5+P+N0r6no1SxGDHY8he6ZcdE+dw@mail.gmail.com>
References: <CAL79i+Rfgy_dBtzq3s1esL5+P+N0r6no1SxGDHY8he6ZcdE+dw@mail.gmail.com>
Message-ID: <1412689832.939919.176124297.248EA020@webmail.messagingengine.com>

Hi Juan,

If you do:

summaryMatrix <- res$surv 

that should get the last matrix in the summary call assigned to
summaryMatrix.  If you're not looking for the 'surv' matrix, entering:

res$

into the console and tab-completing should allow you to select the
element of the summary object that you'd like.

Hope this helps,
-- 
  Rianna Morgan, MA
  rmorgan at trystero.is

On Tue, Oct 7, 2014, at 06:40 AM, Juan Andres Hernandez wrote:
> Hi. I need to extract the "matrix" or "data.frame" results from a
> survival
> object.
> 
> library(survival)
> data(lung)
> mod=with(lung, survfit(Surv(time,death)~ 1))
> res=summary(mod)
> 
> res show in consola the "matrix" I am looking for, but I can't find the
> way
> to save or assign this table to an object. Anyone knows how to solve it.
> Thank's in advance
> 
> Juan A. Hern?ndez
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Oct  7 21:13:16 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 7 Oct 2014 19:13:16 +0000
Subject: [R] Conditional Data Manipulation -Cumulative Product
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24D80@EX02.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24D80@EX02.platinum.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9E404@mb02.ads.tamu.edu>

You need to use plain text, not html in your email. Your data are scrambled (see below). It is better to send your data using the R dput() function:

dput(StartSignals)
dput(MainData)
dput(StopSignals)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pooya Lalehzari
Sent: Tuesday, October 7, 2014 11:55 AM
To: R help
Subject: [R] Conditional Data Manipulation -Cumulative Product

Hello,
I have three datasets StartSignals, MainData, StopSignals and need to compound the data for each variable in MainData over dates that fall between the Start and Stop signals. (Stop signals are common and the same to all X1:X5 variables). Please see sample below:
The one way I was thinking of doing this project was to setup a nested "FOR" loop and go through the three data matrices. Is there a more elegant way of doing this?
Thank you.

StartSignals:
Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1

0

0

1

1/3/2014

0

0

1

0

0

1/4/2014

0

0

0

0

0

1/5/2014

1

0

0

0

1

1/6/2014

0

0

1

0

0

1/7/2014

0

0

0

1

0

1/8/2014

0

0

0

0

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1

1

0

1/11/2014

1

0

0

0

0

1/12/2014

0

1

0

0

1

1/13/2014

0

0

0

0

0




MainData:
Date

X1

X2

X3

X4

X5

1/1/2014

1.92

1.38

0.83

1.25

1.12

1/2/2014

0.67

1.51

1.21

0.06

1.24

1/3/2014

1.09

0.09

0.2

1.62

0.3

1/4/2014

1.81

1.33

1.57

1.68

1.41

1/5/2014

1.04

0.38

1.72

1.98

1.23

1/6/2014

1.69

1.12

0.76

1.45

1.99

1/7/2014

1.57

1.3

1.22

0.66

1.75

1/8/2014

0.5

1.75

0.27

0.09

1.91

1/9/2014

0

1.26

0.59

0.4

1.81

1/10/2014

1.31

1.57

1.68

0.98

1.79

1/11/2014

0.43

1.63

1.98

1.46

0.81

1/12/2014

1.51

0.78

1.63

0.46

1.84

1/13/2014

0.26

0.34

0.34

0.97

1.13




StopSignals:
Date

Stop

1/1/2014

0

1/2/2014

0

1/3/2014

1

1/4/2014

0

1/5/2014

1

1/6/2014

0

1/7/2014

0

1/8/2014

1

1/9/2014

0

1/10/2014

0

1/11/2014

0

1/12/2014

0

1/13/2014

1



ExpectedResult:

Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1.51

0

0

1.24

1/3/2014

0

0.14

0.2

0

0.37

1/4/2014

0

0

0

0

0

1/5/2014

1.04

0

0

0

1.23

1/6/2014

0

0

0.76

0

0

1/7/2014

0

0

0.93

0.66

0

1/8/2014

0

0

0.25

0.06

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1.68

0.98

0

1/11/2014

0.43

0

3.33

1.43

0

1/12/2014

0.65

0.78

5.42

0.66

1.84

1/13/2014

0.17

0.27

1.84

0.64

2.08










***
We are pleased to announce that, as of October 20th, 2014, we will be moving to
our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN
CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE
OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE
CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From danielcastrob at gmail.com  Tue Oct  7 21:39:30 2014
From: danielcastrob at gmail.com (daniel castro)
Date: Tue, 7 Oct 2014 21:39:30 +0200
Subject: [R] quantreg crq function-incomplete taus fitted
Message-ID: <CAMUKbPiKZabxDAPo4adFBAumxjywxzO_KBBfqHnxH9L6Zegi9w@mail.gmail.com>

Hello ,

I'm trying to fit a quantile regression model for rigth censoring data
and I think I'm misunderstanding the behaviour of the function crq

I've tried

qreg1<-crq(Surv(TIME,EVENT,type="right")~VAR1+VAR2,
           data=DATA_TRAIN,method = "Portnoy",tau=-1)

qreg1<-crq(Surv(TIME,EVENT,type="right")~VAR1+VAR2,
           data=DATA_TRAIN,method = "Portnoy",tau=0.1)

this two first attemps give me 78 set of values for every tau in
$fitted.values or in $sol starting in 0 and ending in 0.348 (values of
tau) but then where are the rest un itl 1?

qreg1<-crq(Surv(TIME,EVENT,type="right")~VAR1+VAR2,
           data=DATA_TRAIN,method = "Portnoy",grid=seq(0.1,1,by=0.1))

gives only one value for tau=0.00000

I want to control the parameters tau or grid to get the results for
the quantiles I want, but it seems that I went wrong somewhere..but
where?

Thank you in advance,

Daniel Castro


From istazahn at gmail.com  Tue Oct  7 21:49:44 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 7 Oct 2014 15:49:44 -0400
Subject: [R] Find common two and three word phrases in a corpus
In-Reply-To: <CAJ-4XAoy1D4wa_iov91KdADkFE97Et3ao31k1p0ED9N5Wj=qxA@mail.gmail.com>
References: <CAJ-4XAoy1D4wa_iov91KdADkFE97Et3ao31k1p0ED9N5Wj=qxA@mail.gmail.com>
Message-ID: <CA+vqiLGVcrw_YRPqzt3Zj2UsKW_w9sh8Sq5WtdRjzc5HmRLOgg@mail.gmail.com>

Hi Abraham,


On Tue, Oct 7, 2014 at 10:51 AM, Abraham Mathew <abmathewks at gmail.com> wrote:
> Let's say I have a corpus and want to find the two, three, etc word phrases
> that occur most frequently in the data. I normally do this in the following
> manner but am getting an error message and am having some difficulty
> diagnosing what is going wrong. Given the following data, I'd just want a
> count of 2 for the number of 2 word phrases given that "that sucks" appears
> twice.
>
> dat = c("love it", "who goes there", "what is wrong", "that sucks", "that
> sucks")
>
> (corpus <- Corpus(VectorSource(dat)))
>
> matrix <- create_matrix(corpus, ngramLength=2)

It would have been nice for you to tell us which package this comes
from. If this is from RTextTools, I don't see anything in the
documentation that suggests that create_matrix expects a corpus. It
asks for a character vector, e.g.e,

matrix <- create_matrix(dat, ngramLength=2)

That may be all you need. When I tried it I got some errors that seem
to be related to the version of Weka I had installed. I never did get
create_matrix to work, following the instructions on the tm package
FAQ page (http://tm.r-forge.r-project.org/faq.html) I was able to get
this working as

library(tm)
library(RWeka)

dat = c("love", "who goes there", "what is wrong", "that sucks", "that sucks")

(corpus <- Corpus(VectorSource(dat)))

BigramTokenizer <- function(x) NGramTokenizer(x, Weka_control(min = 2, max = 2))

tdm <- TermDocumentMatrix(corpus, control = list(tokenize = BigramTokenizer))

bww_freq = findFreqTerms(tdm, lowfreq=2)


Best,
Ista

>
> bww_freq = findFreqTerms(matrix, lowfreq=5)
>
> Here is the error message when I attempt to create a matrix
>
>> (corpus <- Corpus(VectorSource(dat)))
> <<VCorpus (documents: 5, metadata (corpus/indexed): 0/0)>>
>> matrix <- create_matrix(corpus, ngramLength=2)
> Error in array(x, c(length(x), 1L), if (!is.null(names(x))) list(names(x),
>  :
>   dims [product 5] do not match the length of object [3]
>
>
> Can anyone tell me what could be going wrong? or a workaround? or another
> package which could give me the desires result in a more efficient manner.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Oct  7 23:03:16 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 7 Oct 2014 21:03:16 +0000
Subject: [R] Conditional Data Manipulation -Cumulative Product
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB32C25200@EX02.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24D80@EX02.platinum.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E404@mb02.ads.tamu.edu>
	<92FD11F467D9CA41A8AEA01FE4D76DEB32C25200@EX02.platinum.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9E4EF@mb02.ads.tamu.edu>

More clear to read, but this is much easier to load into R. Then adding 

StartSignals$Date <- as.Date(StartSignals$Date, "%m/%d/%Y")
MainData$Date <- as.Date(MainData$Date, "%m/%d/%Y")
StopSignals$Date <- as.Date(StopSignals$Date, "%m/%d/%Y")

Creates date objects out of the character strings.

But what should the final result look like? For example X1 has two start dates, "2014-01-05" and "2014-01-11" and you have stop dates of "2014-01-03", "2014-01-05", "2014-01-08", and "2014-01-13". So for X1 "2014-01-05" is both a start and stop date (value 1.04) and the second start/end would be "2014-01-11" to "2014-01-13" (values .43, 1.51, .26). What do you mean by compounding?

David C


-----Original Message-----
From: Pooya Lalehzari [mailto:plalehzari at platinumlp.com] 
Sent: Tuesday, October 7, 2014 2:59 PM
To: David L Carlson
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

Dear David,
This is the dput output but I think the previous email had it more clearly.


> dput(StartSignals)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", 
"1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", 
"1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(0L, 0L, 0L, 0L, 
1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L), X2 = c(0L, 1L, 0L, 0L, 0L, 
0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L), X3 = c(0L, 0L, 1L, 0L, 0L, 1L, 
0L, 0L, 0L, 1L, 0L, 0L, 0L), X4 = c(0L, 0L, 0L, 0L, 0L, 0L, 1L, 
0L, 0L, 1L, 0L, 0L, 0L), X5 = c(0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 
0L, 0L, 0L, 1L, 0L)), .Names = c("Date", "X1", "X2", "X3", "X4", 
"X5"), class = "data.frame", row.names = c(NA, -13L))
> dput(MainData)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", 
"1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", 
"1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(1.92, 0.67, 1.09, 
1.81, 1.04, 1.69, 1.57, 0.5, 0, 1.31, 0.43, 1.51, 0.26), X2 = c(1.38, 
1.51, 0.09, 1.33, 0.38, 1.12, 1.3, 1.75, 1.26, 1.57, 1.63, 0.78, 
0.34), X3 = c(0.83, 1.21, 0.2, 1.57, 1.72, 0.76, 1.22, 0.27, 
0.59, 1.68, 1.98, 1.63, 0.34), X4 = c(1.25, 0.06, 1.62, 1.68, 
1.98, 1.45, 0.66, 0.09, 0.4, 0.98, 1.46, 0.46, 0.97), X5 = c(1.12, 
1.24, 0.3, 1.41, 1.23, 1.99, 1.75, 1.91, 1.81, 1.79, 0.81, 1.84, 
1.13)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA, 
-13L))
> dput(StopSignals)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", 
"1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", 
"1/11/2014", "1/12/2014", "1/13/2014"), Stop = c(0L, 0L, 1L, 
0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L)), .Names = c("Date", 
"Stop"), class = "data.frame", row.names = c(NA, -13L))


-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu] 
Sent: Tuesday, October 07, 2014 3:13 PM
To: Pooya Lalehzari; R help
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

You need to use plain text, not html in your email. Your data are scrambled (see below). It is better to send your data using the R dput() function:

dput(StartSignals)
dput(MainData)
dput(StopSignals)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pooya Lalehzari
Sent: Tuesday, October 7, 2014 11:55 AM
To: R help
Subject: [R] Conditional Data Manipulation -Cumulative Product

Hello,
I have three datasets StartSignals, MainData, StopSignals and need to compound the data for each variable in MainData over dates that fall between the Start and Stop signals. (Stop signals are common and the same to all X1:X5 variables). Please see sample below:
The one way I was thinking of doing this project was to setup a nested "FOR" loop and go through the three data matrices. Is there a more elegant way of doing this?
Thank you.

StartSignals:
Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1

0

0

1

1/3/2014

0

0

1

0

0

1/4/2014

0

0

0

0

0

1/5/2014

1

0

0

0

1

1/6/2014

0

0

1

0

0

1/7/2014

0

0

0

1

0

1/8/2014

0

0

0

0

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1

1

0

1/11/2014

1

0

0

0

0

1/12/2014

0

1

0

0

1

1/13/2014

0

0

0

0

0




MainData:
Date

X1

X2

X3

X4

X5

1/1/2014

1.92

1.38

0.83

1.25

1.12

1/2/2014

0.67

1.51

1.21

0.06

1.24

1/3/2014

1.09

0.09

0.2

1.62

0.3

1/4/2014

1.81

1.33

1.57

1.68

1.41

1/5/2014

1.04

0.38

1.72

1.98

1.23

1/6/2014

1.69

1.12

0.76

1.45

1.99

1/7/2014

1.57

1.3

1.22

0.66

1.75

1/8/2014

0.5

1.75

0.27

0.09

1.91

1/9/2014

0

1.26

0.59

0.4

1.81

1/10/2014

1.31

1.57

1.68

0.98

1.79

1/11/2014

0.43

1.63

1.98

1.46

0.81

1/12/2014

1.51

0.78

1.63

0.46

1.84

1/13/2014

0.26

0.34

0.34

0.97

1.13




StopSignals:
Date

Stop

1/1/2014

0

1/2/2014

0

1/3/2014

1

1/4/2014

0

1/5/2014

1

1/6/2014

0

1/7/2014

0

1/8/2014

1

1/9/2014

0

1/10/2014

0

1/11/2014

0

1/12/2014

0

1/13/2014

1



ExpectedResult:

Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1.51

0

0

1.24

1/3/2014

0

0.14

0.2

0

0.37

1/4/2014

0

0

0

0

0

1/5/2014

1.04

0

0

0

1.23

1/6/2014

0

0

0.76

0

0

1/7/2014

0

0

0.93

0.66

0

1/8/2014

0

0

0.25

0.06

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1.68

0.98

0

1/11/2014

0.43

0

3.33

1.43

0

1/12/2014

0.65

0.78

5.42

0.66

1.84

1/13/2014

0.17

0.27

1.84

0.64

2.08










***
We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



***
We are pleased to announce that, as of October 20th, 2014, we will be moving to
our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN
CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE
OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE
CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.


From plalehzari at platinumlp.com  Tue Oct  7 23:26:56 2014
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Tue, 7 Oct 2014 21:26:56 +0000
Subject: [R] Conditional Data Manipulation -Cumulative Product
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9E4EF@mb02.ads.tamu.edu>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24D80@EX02.platinum.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E404@mb02.ads.tamu.edu>
	<92FD11F467D9CA41A8AEA01FE4D76DEB32C25200@EX02.platinum.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E4EF@mb02.ads.tamu.edu>
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB32C2539A@EX02.platinum.com>

Below is the sample output based on the sample input. Since the StopSignals are generated for all X1:X5 variables, some might not apply and not correspond to an OpenSignal for a variable so then it will be ignored (Like 1/3 for X1). If StopSignal is on the same date as the StartSignal, it will output that date's corresponding value (1/5/14 for X1) from MainData. When StopSignal is a few days after StartSignal then the values for that variable will be cumulatively multiplied (like cumsum, but a product as opposed to a sum) and that is what is shown for X1 from 1/11 to 1/13.
Please let me know if I am not clear.

Date		X1	X2	X3	X4	X5
1/1/2014	0.00 	0.00 	0.00 	0.00 	0.00 
1/2/2014	0.00 	1.51 	0.00 	0.00 	1.24 
1/3/2014	0.00 	0.14 	0.20 	0.00 	0.37 
1/4/2014	0.00 	0.00 	0.00 	0.00 	0.00 
1/5/2014	1.04 	0.00 	0.00 	0.00 	1.23 
1/6/2014	0.00 	0.00 	0.76 	0.00 	0.00 
1/7/2014	0.00 	0.00 	0.93 	0.66 	0.00 
1/8/2014	0.00 	0.00 	0.25 	0.06 	0.00 
1/9/2014	0.00 	0.00 	0.00 	0.00 	0.00 
1/10/2014	0.00 	0.00 	1.68 	0.98 	0.00 
1/11/2014	0.43 	0.00 	3.33 	1.43 	0.00 
1/12/2014	0.65 	0.78 	5.42 	0.66 	1.84 
1/13/2014	0.17 	0.27 	1.84 	0.64 	2.08

-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu] 
Sent: Tuesday, October 07, 2014 5:03 PM
To: Pooya Lalehzari
Cc: R help
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

More clear to read, but this is much easier to load into R. Then adding 

StartSignals$Date <- as.Date(StartSignals$Date, "%m/%d/%Y") MainData$Date <- as.Date(MainData$Date, "%m/%d/%Y") StopSignals$Date <- as.Date(StopSignals$Date, "%m/%d/%Y")

Creates date objects out of the character strings.

But what should the final result look like? For example X1 has two start dates, "2014-01-05" and "2014-01-11" and you have stop dates of "2014-01-03", "2014-01-05", "2014-01-08", and "2014-01-13". So for X1 "2014-01-05" is both a start and stop date (value 1.04) and the second start/end would be "2014-01-11" to "2014-01-13" (values .43, 1.51, .26). What do you mean by compounding?

David C


-----Original Message-----
From: Pooya Lalehzari [mailto:plalehzari at platinumlp.com]
Sent: Tuesday, October 7, 2014 2:59 PM
To: David L Carlson
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

Dear David,
This is the dput output but I think the previous email had it more clearly.


> dput(StartSignals)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L), X2 = c(0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L), X3 = c(0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L), X4 = c(0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L), X5 = c(0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA, -13L))
> dput(MainData)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(1.92, 0.67, 1.09, 1.81, 1.04, 1.69, 1.57, 0.5, 0, 1.31, 0.43, 1.51, 0.26), X2 = c(1.38, 1.51, 0.09, 1.33, 0.38, 1.12, 1.3, 1.75, 1.26, 1.57, 1.63, 0.78, 0.34), X3 = c(0.83, 1.21, 0.2, 1.57, 1.72, 0.76, 1.22, 0.27, 0.59, 1.68, 1.98, 1.63, 0.34), X4 = c(1.25, 0.06, 1.62, 1.68, 1.98, 1.45, 0.66, 0.09, 0.4, 0.98, 1.46, 0.46, 0.97), X5 = c(1.12, 1.24, 0.3, 1.41, 1.23, 1.99, 1.75, 1.91, 1.81, 1.79, 0.81, 1.84, 1.13)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA,
-13L))
> dput(StopSignals)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), Stop = c(0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L)), .Names = c("Date", "Stop"), class = "data.frame", row.names = c(NA, -13L))


-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu]
Sent: Tuesday, October 07, 2014 3:13 PM
To: Pooya Lalehzari; R help
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

You need to use plain text, not html in your email. Your data are scrambled (see below). It is better to send your data using the R dput() function:

dput(StartSignals)
dput(MainData)
dput(StopSignals)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pooya Lalehzari
Sent: Tuesday, October 7, 2014 11:55 AM
To: R help
Subject: [R] Conditional Data Manipulation -Cumulative Product

Hello,
I have three datasets StartSignals, MainData, StopSignals and need to compound the data for each variable in MainData over dates that fall between the Start and Stop signals. (Stop signals are common and the same to all X1:X5 variables). Please see sample below:
The one way I was thinking of doing this project was to setup a nested "FOR" loop and go through the three data matrices. Is there a more elegant way of doing this?
Thank you.

StartSignals:
Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1

0

0

1

1/3/2014

0

0

1

0

0

1/4/2014

0

0

0

0

0

1/5/2014

1

0

0

0

1

1/6/2014

0

0

1

0

0

1/7/2014

0

0

0

1

0

1/8/2014

0

0

0

0

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1

1

0

1/11/2014

1

0

0

0

0

1/12/2014

0

1

0

0

1

1/13/2014

0

0

0

0

0




MainData:
Date

X1

X2

X3

X4

X5

1/1/2014

1.92

1.38

0.83

1.25

1.12

1/2/2014

0.67

1.51

1.21

0.06

1.24

1/3/2014

1.09

0.09

0.2

1.62

0.3

1/4/2014

1.81

1.33

1.57

1.68

1.41

1/5/2014

1.04

0.38

1.72

1.98

1.23

1/6/2014

1.69

1.12

0.76

1.45

1.99

1/7/2014

1.57

1.3

1.22

0.66

1.75

1/8/2014

0.5

1.75

0.27

0.09

1.91

1/9/2014

0

1.26

0.59

0.4

1.81

1/10/2014

1.31

1.57

1.68

0.98

1.79

1/11/2014

0.43

1.63

1.98

1.46

0.81

1/12/2014

1.51

0.78

1.63

0.46

1.84

1/13/2014

0.26

0.34

0.34

0.97

1.13




StopSignals:
Date

Stop

1/1/2014

0

1/2/2014

0

1/3/2014

1

1/4/2014

0

1/5/2014

1

1/6/2014

0

1/7/2014

0

1/8/2014

1

1/9/2014

0

1/10/2014

0

1/11/2014

0

1/12/2014

0

1/13/2014

1



ExpectedResult:

Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1.51

0

0

1.24

1/3/2014

0

0.14

0.2

0

0.37

1/4/2014

0

0

0

0

0

1/5/2014

1.04

0

0

0

1.23

1/6/2014

0

0

0.76

0

0

1/7/2014

0

0

0.93

0.66

0

1/8/2014

0

0

0.25

0.06

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1.68

0.98

0

1/11/2014

0.43

0

3.33

1.43

0

1/12/2014

0.65

0.78

5.42

0.66

1.84

1/13/2014

0.17

0.27

1.84

0.64

2.08










***
We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



***
We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.



***
We are pleased to announce that, as of October 20th, 2014, we will be moving to
our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN
CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE
OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE
CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.


From eliza_botto at hotmail.com  Wed Oct  8 00:24:00 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Tue, 7 Oct 2014 22:24:00 +0000
Subject: [R] standard deviation
Message-ID: <BLU170-W91D7C0F8415982FF42C30989A20@phx.gbl>

Dear useRs,
Is there a direct command in R to calculate standard deviation of BURR distribution in R? I know the direct function in VBA and worksheet..... but is there a similar function in R?
VBA
=BurrStdev(k,alpha,beta,[gamma])
Worksheet:
=BurrStdev(k;alpha;beta;[gamma])=DistStdev("Burr(k;alpha;beta;[gamma])")
Thankyou very much in advance...
Eliza 		 	   		  
	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Oct  8 00:44:47 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 7 Oct 2014 22:44:47 +0000
Subject: [R] standard deviation
References: <BLU170-W91D7C0F8415982FF42C30989A20@phx.gbl>
Message-ID: <loom.20141008T004402-413@post.gmane.org>

eliza botto <eliza_botto <at> hotmail.com> writes:

> 
> Dear useRs,
> Is there a direct command in R to calculate standard deviation of BURR
distribution in R? I know the direct
> function in VBA and worksheet..... but is there a similar function in R?
> VBA
> =BurrStdev(k,alpha,beta,[gamma])
> Worksheet:
> =BurrStdev(k;alpha;beta;[gamma])=DistStdev("Burr(k;alpha;beta;[gamma])")
> Thankyou very much in advance...
> Eliza 		 	   		

  library("sos"); findFn("{Burr distribution}")

turns up useful stuff.

http://finzi.psych.upenn.edu/R/library/actuar/html/Burr.html

will give you raw moments, which should be convertible to
central moments etc. pretty easily.


From dcarlson at tamu.edu  Wed Oct  8 05:55:10 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 8 Oct 2014 03:55:10 +0000
Subject: [R] Conditional Data Manipulation -Cumulative Product
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB32C2566B@EX02.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24D80@EX02.platinum.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E404@mb02.ads.tamu.edu>
	<92FD11F467D9CA41A8AEA01FE4D76DEB32C25200@EX02.platinum.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E4EF@mb02.ads.tamu.edu>
	<92FD11F467D9CA41A8AEA01FE4D76DEB32C2566B@EX02.platinum.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9E5B1@mb02.ads.tamu.edu>

I think this works, at least for your example data. The function SSRuns gets the index values of the starting points and then finds the first ending point that is greater or equal. Then we cycle through the starting points and print the index values from start to stop. Those are combined into a single vector which is used to create each column of the mask for the data.

SSRuns <- function(x, y, rows) {
	a <- which(x>0)
	b <- which(y>0)
	d <- unlist(lapply(seq_along(a), function(i) 
		a[i]:head(b[a[i] <= b], 1)))
	v <- rep(0, rows)
	v[d] <- 1
	return(v)
}
mask <- sapply(StartSignals[,-1], SSRuns, y=StopSignals$Stop, 
	rows=nrow(MainData))
Results <- data.frame(Date=MainData$Date, MainData[,-1]*mask)
Results
         Date   X1   X2   X3   X4   X5
1  2014-01-01 0.00 0.00 0.00 0.00 0.00
2  2014-01-02 0.00 1.51 0.00 0.00 1.24
3  2014-01-03 0.00 0.09 0.20 0.00 0.30
4  2014-01-04 0.00 0.00 0.00 0.00 0.00
5  2014-01-05 1.04 0.00 0.00 0.00 1.23
6  2014-01-06 0.00 0.00 0.76 0.00 0.00
7  2014-01-07 0.00 0.00 1.22 0.66 0.00
8  2014-01-08 0.00 0.00 0.27 0.09 0.00
9  2014-01-09 0.00 0.00 0.00 0.00 0.00
10 2014-01-10 0.00 0.00 1.68 0.98 0.00
11 2014-01-11 0.43 0.00 1.98 1.46 0.00
12 2014-01-12 1.51 0.78 1.63 0.46 1.84
13 2014-01-13 0.26 0.34 0.34 0.97 1.13

David C

-----Original Message-----
From: Pooya Lalehzari [mailto:plalehzari at platinumlp.com] 
Sent: Tuesday, October 7, 2014 8:06 PM
To: David L Carlson
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

Hi David,
I also made a dput of the Expected Results in case if you want to read it in:
> dput(ExpResults)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(0, 0, 0, 0, 1.04, 0, 0, 0, 0, 0, 0.43, 0.65, 0.17), X2 = c(0, 1.51, 0.14, 0, 0, 0, 0, 0, 0, 0, 0, 0.78, 0.27), X3 = c(0, 0, 0.2, 0, 0, 0.76, 0.93, 0.25, 0, 1.68, 3.33, 5.42, 1.84), X4 = c(0, 0, 0, 0, 0, 0, 0.66, 0.06, 0, 0.98, 1.43, 0.66, 0.64), X5 = c(0, 1.24, 0.37, 0, 1.23, 0, 0, 0, 0, 0, 0, 1.84, 2.08)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA,
-13L))

-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu]
Sent: Tuesday, October 07, 2014 5:03 PM
To: Pooya Lalehzari
Cc: R help
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

More clear to read, but this is much easier to load into R. Then adding 

StartSignals$Date <- as.Date(StartSignals$Date, "%m/%d/%Y") MainData$Date <- as.Date(MainData$Date, "%m/%d/%Y") StopSignals$Date <- as.Date(StopSignals$Date, "%m/%d/%Y")

Creates date objects out of the character strings.

But what should the final result look like? For example X1 has two start dates, "2014-01-05" and "2014-01-11" and you have stop dates of "2014-01-03", "2014-01-05", "2014-01-08", and "2014-01-13". So for X1 "2014-01-05" is both a start and stop date (value 1.04) and the second start/end would be "2014-01-11" to "2014-01-13" (values .43, 1.51, .26). What do you mean by compounding?

David C


-----Original Message-----
From: Pooya Lalehzari [mailto:plalehzari at platinumlp.com]
Sent: Tuesday, October 7, 2014 2:59 PM
To: David L Carlson
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

Dear David,
This is the dput output but I think the previous email had it more clearly.


> dput(StartSignals)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L), X2 = c(0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L), X3 = c(0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L), X4 = c(0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L), X5 = c(0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA, -13L))
> dput(MainData)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(1.92, 0.67, 1.09, 1.81, 1.04, 1.69, 1.57, 0.5, 0, 1.31, 0.43, 1.51, 0.26), X2 = c(1.38, 1.51, 0.09, 1.33, 0.38, 1.12, 1.3, 1.75, 1.26, 1.57, 1.63, 0.78, 0.34), X3 = c(0.83, 1.21, 0.2, 1.57, 1.72, 0.76, 1.22, 0.27, 0.59, 1.68, 1.98, 1.63, 0.34), X4 = c(1.25, 0.06, 1.62, 1.68, 1.98, 1.45, 0.66, 0.09, 0.4, 0.98, 1.46, 0.46, 0.97), X5 = c(1.12, 1.24, 0.3, 1.41, 1.23, 1.99, 1.75, 1.91, 1.81, 1.79, 0.81, 1.84, 1.13)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA,
-13L))
> dput(StopSignals)
structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), Stop = c(0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L)), .Names = c("Date", "Stop"), class = "data.frame", row.names = c(NA, -13L))


-----Original Message-----
From: David L Carlson [mailto:dcarlson at tamu.edu]
Sent: Tuesday, October 07, 2014 3:13 PM
To: Pooya Lalehzari; R help
Subject: RE: [R] Conditional Data Manipulation -Cumulative Product

You need to use plain text, not html in your email. Your data are scrambled (see below). It is better to send your data using the R dput() function:

dput(StartSignals)
dput(MainData)
dput(StopSignals)

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pooya Lalehzari
Sent: Tuesday, October 7, 2014 11:55 AM
To: R help
Subject: [R] Conditional Data Manipulation -Cumulative Product

Hello,
I have three datasets StartSignals, MainData, StopSignals and need to compound the data for each variable in MainData over dates that fall between the Start and Stop signals. (Stop signals are common and the same to all X1:X5 variables). Please see sample below:
The one way I was thinking of doing this project was to setup a nested "FOR" loop and go through the three data matrices. Is there a more elegant way of doing this?
Thank you.

StartSignals:
Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1

0

0

1

1/3/2014

0

0

1

0

0

1/4/2014

0

0

0

0

0

1/5/2014

1

0

0

0

1

1/6/2014

0

0

1

0

0

1/7/2014

0

0

0

1

0

1/8/2014

0

0

0

0

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1

1

0

1/11/2014

1

0

0

0

0

1/12/2014

0

1

0

0

1

1/13/2014

0

0

0

0

0




MainData:
Date

X1

X2

X3

X4

X5

1/1/2014

1.92

1.38

0.83

1.25

1.12

1/2/2014

0.67

1.51

1.21

0.06

1.24

1/3/2014

1.09

0.09

0.2

1.62

0.3

1/4/2014

1.81

1.33

1.57

1.68

1.41

1/5/2014

1.04

0.38

1.72

1.98

1.23

1/6/2014

1.69

1.12

0.76

1.45

1.99

1/7/2014

1.57

1.3

1.22

0.66

1.75

1/8/2014

0.5

1.75

0.27

0.09

1.91

1/9/2014

0

1.26

0.59

0.4

1.81

1/10/2014

1.31

1.57

1.68

0.98

1.79

1/11/2014

0.43

1.63

1.98

1.46

0.81

1/12/2014

1.51

0.78

1.63

0.46

1.84

1/13/2014

0.26

0.34

0.34

0.97

1.13




StopSignals:
Date

Stop

1/1/2014

0

1/2/2014

0

1/3/2014

1

1/4/2014

0

1/5/2014

1

1/6/2014

0

1/7/2014

0

1/8/2014

1

1/9/2014

0

1/10/2014

0

1/11/2014

0

1/12/2014

0

1/13/2014

1



ExpectedResult:

Date

X1

X2

X3

X4

X5

1/1/2014

0

0

0

0

0

1/2/2014

0

1.51

0

0

1.24

1/3/2014

0

0.14

0.2

0

0.37

1/4/2014

0

0

0

0

0

1/5/2014

1.04

0

0

0

1.23

1/6/2014

0

0

0.76

0

0

1/7/2014

0

0

0.93

0.66

0

1/8/2014

0

0

0.25

0.06

0

1/9/2014

0

0

0

0

0

1/10/2014

0

0

1.68

0.98

0

1/11/2014

0.43

0

3.33

1.43

0

1/12/2014

0.65

0.78

5.42

0.66

1.84

1/13/2014

0.17

0.27

1.84

0.64

2.08










***
We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



***
We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.



***
We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.


From plalehzari at platinumlp.com  Wed Oct  8 06:06:36 2014
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Wed, 8 Oct 2014 04:06:36 +0000
Subject: [R] Conditional Data Manipulation -Cumulative Product
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9E5B1@mb02.ads.tamu.edu>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB32C24D80@EX02.platinum.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E404@mb02.ads.tamu.edu>
	<92FD11F467D9CA41A8AEA01FE4D76DEB32C25200@EX02.platinum.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E4EF@mb02.ads.tamu.edu>
	<92FD11F467D9CA41A8AEA01FE4D76DEB32C2566B@EX02.platinum.com>,
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9E5B1@mb02.ads.tamu.edu>
Message-ID: <D5AD5EE0-E596-4091-A92E-146DE39A5957@platinumlp.com>


Thank you very much!! I'll test it out some more and then study it to see how it does it. 
It is pretty awesome and thank you again!

Pooya. 

> On Oct 7, 2014, at 11:55 PM, "David L Carlson" <dcarlson at tamu.edu> wrote:
> 
> I think this works, at least for your example data. The function SSRuns gets the index values of the starting points and then finds the first ending point that is greater or equal. Then we cycle through the starting points and print the index values from start to stop. Those are combined into a single vector which is used to create each column of the mask for the data.
> 
> SSRuns <- function(x, y, rows) {
>    a <- which(x>0)
>    b <- which(y>0)
>    d <- unlist(lapply(seq_along(a), function(i) 
>        a[i]:head(b[a[i] <= b], 1)))
>    v <- rep(0, rows)
>    v[d] <- 1
>    return(v)
> }
> mask <- sapply(StartSignals[,-1], SSRuns, y=StopSignals$Stop, 
>    rows=nrow(MainData))
> Results <- data.frame(Date=MainData$Date, MainData[,-1]*mask)
> Results
>         Date   X1   X2   X3   X4   X5
> 1  2014-01-01 0.00 0.00 0.00 0.00 0.00
> 2  2014-01-02 0.00 1.51 0.00 0.00 1.24
> 3  2014-01-03 0.00 0.09 0.20 0.00 0.30
> 4  2014-01-04 0.00 0.00 0.00 0.00 0.00
> 5  2014-01-05 1.04 0.00 0.00 0.00 1.23
> 6  2014-01-06 0.00 0.00 0.76 0.00 0.00
> 7  2014-01-07 0.00 0.00 1.22 0.66 0.00
> 8  2014-01-08 0.00 0.00 0.27 0.09 0.00
> 9  2014-01-09 0.00 0.00 0.00 0.00 0.00
> 10 2014-01-10 0.00 0.00 1.68 0.98 0.00
> 11 2014-01-11 0.43 0.00 1.98 1.46 0.00
> 12 2014-01-12 1.51 0.78 1.63 0.46 1.84
> 13 2014-01-13 0.26 0.34 0.34 0.97 1.13
> 
> David C
> 
> -----Original Message-----
> From: Pooya Lalehzari [mailto:plalehzari at platinumlp.com] 
> Sent: Tuesday, October 7, 2014 8:06 PM
> To: David L Carlson
> Subject: RE: [R] Conditional Data Manipulation -Cumulative Product
> 
> Hi David,
> I also made a dput of the Expected Results in case if you want to read it in:
>> dput(ExpResults)
> structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(0, 0, 0, 0, 1.04, 0, 0, 0, 0, 0, 0.43, 0.65, 0.17), X2 = c(0, 1.51, 0.14, 0, 0, 0, 0, 0, 0, 0, 0, 0.78, 0.27), X3 = c(0, 0, 0.2, 0, 0, 0.76, 0.93, 0.25, 0, 1.68, 3.33, 5.42, 1.84), X4 = c(0, 0, 0, 0, 0, 0, 0.66, 0.06, 0, 0.98, 1.43, 0.66, 0.64), X5 = c(0, 1.24, 0.37, 0, 1.23, 0, 0, 0, 0, 0, 0, 1.84, 2.08)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA,
> -13L))
> 
> -----Original Message-----
> From: David L Carlson [mailto:dcarlson at tamu.edu]
> Sent: Tuesday, October 07, 2014 5:03 PM
> To: Pooya Lalehzari
> Cc: R help
> Subject: RE: [R] Conditional Data Manipulation -Cumulative Product
> 
> More clear to read, but this is much easier to load into R. Then adding 
> 
> StartSignals$Date <- as.Date(StartSignals$Date, "%m/%d/%Y") MainData$Date <- as.Date(MainData$Date, "%m/%d/%Y") StopSignals$Date <- as.Date(StopSignals$Date, "%m/%d/%Y")
> 
> Creates date objects out of the character strings.
> 
> But what should the final result look like? For example X1 has two start dates, "2014-01-05" and "2014-01-11" and you have stop dates of "2014-01-03", "2014-01-05", "2014-01-08", and "2014-01-13". So for X1 "2014-01-05" is both a start and stop date (value 1.04) and the second start/end would be "2014-01-11" to "2014-01-13" (values .43, 1.51, .26). What do you mean by compounding?
> 
> David C
> 
> 
> -----Original Message-----
> From: Pooya Lalehzari [mailto:plalehzari at platinumlp.com]
> Sent: Tuesday, October 7, 2014 2:59 PM
> To: David L Carlson
> Subject: RE: [R] Conditional Data Manipulation -Cumulative Product
> 
> Dear David,
> This is the dput output but I think the previous email had it more clearly.
> 
> 
>> dput(StartSignals)
> structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L), X2 = c(0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L), X3 = c(0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 1L, 0L, 0L, 0L), X4 = c(0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L), X5 = c(0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 0L, 0L, 1L, 0L)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA, -13L))
>> dput(MainData)
> structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), X1 = c(1.92, 0.67, 1.09, 1.81, 1.04, 1.69, 1.57, 0.5, 0, 1.31, 0.43, 1.51, 0.26), X2 = c(1.38, 1.51, 0.09, 1.33, 0.38, 1.12, 1.3, 1.75, 1.26, 1.57, 1.63, 0.78, 0.34), X3 = c(0.83, 1.21, 0.2, 1.57, 1.72, 0.76, 1.22, 0.27, 0.59, 1.68, 1.98, 1.63, 0.34), X4 = c(1.25, 0.06, 1.62, 1.68, 1.98, 1.45, 0.66, 0.09, 0.4, 0.98, 1.46, 0.46, 0.97), X5 = c(1.12, 1.24, 0.3, 1.41, 1.23, 1.99, 1.75, 1.91, 1.81, 1.79, 0.81, 1.84, 1.13)), .Names = c("Date", "X1", "X2", "X3", "X4", "X5"), class = "data.frame", row.names = c(NA,
> -13L))
>> dput(StopSignals)
> structure(list(Date = c("1/1/2014", "1/2/2014", "1/3/2014", "1/4/2014", "1/5/2014", "1/6/2014", "1/7/2014", "1/8/2014", "1/9/2014", "1/10/2014", "1/11/2014", "1/12/2014", "1/13/2014"), Stop = c(0L, 0L, 1L, 0L, 1L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L)), .Names = c("Date", "Stop"), class = "data.frame", row.names = c(NA, -13L))
> 
> 
> -----Original Message-----
> From: David L Carlson [mailto:dcarlson at tamu.edu]
> Sent: Tuesday, October 07, 2014 3:13 PM
> To: Pooya Lalehzari; R help
> Subject: RE: [R] Conditional Data Manipulation -Cumulative Product
> 
> You need to use plain text, not html in your email. Your data are scrambled (see below). It is better to send your data using the R dput() function:
> 
> dput(StartSignals)
> dput(MainData)
> dput(StopSignals)
> 
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Pooya Lalehzari
> Sent: Tuesday, October 7, 2014 11:55 AM
> To: R help
> Subject: [R] Conditional Data Manipulation -Cumulative Product
> 
> Hello,
> I have three datasets StartSignals, MainData, StopSignals and need to compound the data for each variable in MainData over dates that fall between the Start and Stop signals. (Stop signals are common and the same to all X1:X5 variables). Please see sample below:
> The one way I was thinking of doing this project was to setup a nested "FOR" loop and go through the three data matrices. Is there a more elegant way of doing this?
> Thank you.
> 
> StartSignals:
> Date
> 
> X1
> 
> X2
> 
> X3
> 
> X4
> 
> X5
> 
> 1/1/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/2/2014
> 
> 0
> 
> 1
> 
> 0
> 
> 0
> 
> 1
> 
> 1/3/2014
> 
> 0
> 
> 0
> 
> 1
> 
> 0
> 
> 0
> 
> 1/4/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/5/2014
> 
> 1
> 
> 0
> 
> 0
> 
> 0
> 
> 1
> 
> 1/6/2014
> 
> 0
> 
> 0
> 
> 1
> 
> 0
> 
> 0
> 
> 1/7/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 1
> 
> 0
> 
> 1/8/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/9/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/10/2014
> 
> 0
> 
> 0
> 
> 1
> 
> 1
> 
> 0
> 
> 1/11/2014
> 
> 1
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/12/2014
> 
> 0
> 
> 1
> 
> 0
> 
> 0
> 
> 1
> 
> 1/13/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 
> 
> 
> MainData:
> Date
> 
> X1
> 
> X2
> 
> X3
> 
> X4
> 
> X5
> 
> 1/1/2014
> 
> 1.92
> 
> 1.38
> 
> 0.83
> 
> 1.25
> 
> 1.12
> 
> 1/2/2014
> 
> 0.67
> 
> 1.51
> 
> 1.21
> 
> 0.06
> 
> 1.24
> 
> 1/3/2014
> 
> 1.09
> 
> 0.09
> 
> 0.2
> 
> 1.62
> 
> 0.3
> 
> 1/4/2014
> 
> 1.81
> 
> 1.33
> 
> 1.57
> 
> 1.68
> 
> 1.41
> 
> 1/5/2014
> 
> 1.04
> 
> 0.38
> 
> 1.72
> 
> 1.98
> 
> 1.23
> 
> 1/6/2014
> 
> 1.69
> 
> 1.12
> 
> 0.76
> 
> 1.45
> 
> 1.99
> 
> 1/7/2014
> 
> 1.57
> 
> 1.3
> 
> 1.22
> 
> 0.66
> 
> 1.75
> 
> 1/8/2014
> 
> 0.5
> 
> 1.75
> 
> 0.27
> 
> 0.09
> 
> 1.91
> 
> 1/9/2014
> 
> 0
> 
> 1.26
> 
> 0.59
> 
> 0.4
> 
> 1.81
> 
> 1/10/2014
> 
> 1.31
> 
> 1.57
> 
> 1.68
> 
> 0.98
> 
> 1.79
> 
> 1/11/2014
> 
> 0.43
> 
> 1.63
> 
> 1.98
> 
> 1.46
> 
> 0.81
> 
> 1/12/2014
> 
> 1.51
> 
> 0.78
> 
> 1.63
> 
> 0.46
> 
> 1.84
> 
> 1/13/2014
> 
> 0.26
> 
> 0.34
> 
> 0.34
> 
> 0.97
> 
> 1.13
> 
> 
> 
> 
> StopSignals:
> Date
> 
> Stop
> 
> 1/1/2014
> 
> 0
> 
> 1/2/2014
> 
> 0
> 
> 1/3/2014
> 
> 1
> 
> 1/4/2014
> 
> 0
> 
> 1/5/2014
> 
> 1
> 
> 1/6/2014
> 
> 0
> 
> 1/7/2014
> 
> 0
> 
> 1/8/2014
> 
> 1
> 
> 1/9/2014
> 
> 0
> 
> 1/10/2014
> 
> 0
> 
> 1/11/2014
> 
> 0
> 
> 1/12/2014
> 
> 0
> 
> 1/13/2014
> 
> 1
> 
> 
> 
> ExpectedResult:
> 
> Date
> 
> X1
> 
> X2
> 
> X3
> 
> X4
> 
> X5
> 
> 1/1/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/2/2014
> 
> 0
> 
> 1.51
> 
> 0
> 
> 0
> 
> 1.24
> 
> 1/3/2014
> 
> 0
> 
> 0.14
> 
> 0.2
> 
> 0
> 
> 0.37
> 
> 1/4/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/5/2014
> 
> 1.04
> 
> 0
> 
> 0
> 
> 0
> 
> 1.23
> 
> 1/6/2014
> 
> 0
> 
> 0
> 
> 0.76
> 
> 0
> 
> 0
> 
> 1/7/2014
> 
> 0
> 
> 0
> 
> 0.93
> 
> 0.66
> 
> 0
> 
> 1/8/2014
> 
> 0
> 
> 0
> 
> 0.25
> 
> 0.06
> 
> 0
> 
> 1/9/2014
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 0
> 
> 1/10/2014
> 
> 0
> 
> 0
> 
> 1.68
> 
> 0.98
> 
> 0
> 
> 1/11/2014
> 
> 0.43
> 
> 0
> 
> 3.33
> 
> 1.43
> 
> 0
> 
> 1/12/2014
> 
> 0.65
> 
> 0.78
> 
> 5.42
> 
> 0.66
> 
> 1.84
> 
> 1/13/2014
> 
> 0.17
> 
> 0.27
> 
> 1.84
> 
> 0.64
> 
> 2.08
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ***
> We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
> Platinum Partners
> 250 West 55th Street, 14th Floor, New York, NY 10019
> T: 212.582.2222 | F: 212.582.2424
> ***
> THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> ***
> We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
> Platinum Partners
> 250 West 55th Street, 14th Floor, New York, NY 10019
> T: 212.582.2222 | F: 212.582.2424
> ***
> THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.
> 
> 
> 
> ***
> We are pleased to announce that, as of October 20th, 2014, we will be moving to our new office at:
> Platinum Partners
> 250 West 55th Street, 14th Floor, New York, NY 10019
> T: 212.582.2222 | F: 212.582.2424
> ***
> THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.



***
We are pleased to announce that, as of October 20th, 2014, we will be moving to
our new office at:
Platinum Partners
250 West 55th Street, 14th Floor, New York, NY 10019
T: 212.582.2222 | F: 212.582.2424
***
THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED RECIPIENT(S) AND MAY CONTAIN
CONFIDENTIAL AND PRIVILEGED INFORMATION.ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE
OR DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE INTENDED RECIPIENT, PLEASE
CONTACT THE SENDER BY REPLY E-MAIL AND DESTROY ALL COPIES OF THE ORIGINAL E-MAIL.


From dulcalma at bigpond.com  Wed Oct  8 06:15:23 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 8 Oct 2014 14:15:23 +1000
Subject: [R] lattice add a fit
In-Reply-To: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <000001cfe2ae$7c1fa7f0$745ef7d0$@bigpond.com>

Hi Stephen

if you want and uncomplicated graph you can do the following
(data is from
https://stat.ethz.ch/pipermail/r-help/2008-December/181887.html
which has an example of smoothing with a panel function a  (follow the
thread))
May be un necessary for what you want

dput(test)
structure(list(x = 1:200, y = c(-0.211833603383945, -1.0415911337336, 
-1.1533075572692, 0.321531497643745, -1.5001298759544, -0.445533260997329, 
1.73404543257509, 0.511295615763455, 0.0996450365533331,
-0.0578911103962697, 
-1.74278762900362, -1.32495298319389, -0.547933881534948, -1.45638427585301,

0.0826868204409038, 0.927578947155782, -0.716769334937502,
0.962399675187835, 
1.54588458200656, -1.00976361360517, 0.557410853590579, 0.168781513971099, 
0.155258858301712, 2.36776473870934, -1.58564441351633, -1.10353350945666, 
0.902787057776989, 0.0683183515567076, -1.14946795040125, -0.90127498047004,

-1.19845352398361, -0.510163823550385, 0.306246343638814,
-0.0678770276660271, 
0.372202425855059, 1.14449122171645, -1.43961215364919, -0.745407767319761, 
-1.08426028148107, -0.911810459312264, 0.254473860506602,
0.0545428435691033, 
0.86939682821168, -0.495822138795001, 0.788983956205307,
-0.0482778318087694, 
0.28444147880148, -2.3449130823549, 0.352139869980497, -0.73670929392907, 
0.152865554816491, 0.466635540442577, -1.34862166637197, -0.371330904577685,

2.04819500702545, -1.03035368989461, -0.808913708097202, -0.899512468883577,

1.32164919515955, -1.90258984438615, -1.43516196895465, 0.0465901079414443, 
-0.050190824605222, -1.28753166678936, 1.15411244955901, -1.37573809203985, 
-1.14829872319585, 1.41625774885229, 0.105763612116132, -0.384659376665841, 
1.78448216497794, -1.1152932761564, -0.0721496590810866, -0.654929692334926,

1.23475033091273, -0.355004059316614, 0.0242929525502168, -1.12014689112359,

0.131516716053627, -1.01789380466415, 1.54412508731677, -0.612498366500995, 
-1.47544725093144, -1.33884056677665, 0.116000294553631, 0.441007318370771, 
0.253328166388004, -0.601324732898278, -0.681872432317887,
-0.638406595370473, 
1.1255146487638, 1.68030106840915, -0.0458152886664351, -0.359702695597414, 
-1.27276961899765, 1.65150890035352, 0.970733803202561, -0.299164223313285, 
0.0863388612193544, -1.56778219134085, -0.934175135343763,
-1.75098468827598, 
-0.350775124642839, -0.497774672576354, 0.771324636489948,
-0.69490617657808, 
-0.776286103585292, 0.0401278987521509, -0.965161644356313,
-0.443562752383677, 
0.482231363899495, 0.299362730723139, -1.13975716906454, 0.750123380303915, 
-0.346046820684503, -0.298660657494398, 1.15743160079942, 1.37831825909263, 
-0.561195292140498, -0.727441974730694, 0.542558262494051, 1.07423749905296,

-0.671511488353386, -0.140489880785358, 1.46724871140033, 0.563360651277434,

1.24069952075524, -0.253423940974, 0.196985403588085, -1.29263886475009, 
-0.700235249467159, 0.386254280503009, -0.489119591847831,
-0.863120570714887, 
0.21167415527797, -0.104722187456112, 0.885271725582058, -1.33715921875481, 
-0.419738882938569, 0.114904893946579, 0.579793678083023, 1.3375478692142, 
0.00553313645797594, -1.0480172540963, -0.293082520385054,
-0.607995018773811, 
0.22269595909434, 0.404577306401601, 0.212081041192621, -1.28370971577478, 
-0.186741150561225, 1.47504624554164, -0.335669248934062,
-0.0752650377217833, 
0.938248892501711, -1.19915518471386, -0.823130111133665, 1.77585103279627, 
-0.726506122852284, -0.854585428953646, 0.18721613856176, 0.664751685525484,

-0.378660174874064, -0.406279864316906, -0.377953114167246,
-0.578277117855972, 
-0.195896309465962, -0.752879703028692, -1.20718148517937,
0.103036243241138, 
0.707569503031958, 0.488185644365067, -0.674354094380548, 1.45780393551308, 
-0.426823625045982, 0.372084624745127, -0.489364737649147, 2.00664228219939,

0.0918083578741706, -0.563102471737825, -0.0372326923340063, 
1.00352069476112, -1.14244200325742, 1.14469060546702, 1.26070182057624, 
0.664616631427959, 0.75021683374034, -1.39029533734557, 0.818844192795068, 
-0.948663137610259, 2.87434018113975, 0.237475434622456, 0.745884070517981, 
1.19494964206119, 0.627396315033843, -0.810728351760724, 1.58246498427057, 
-0.414333063166778, -1.91414027760821, -1.68038800516161), groups =
structure(c(1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L), .Label = c("1", "2", "3", "4"), class =
"factor")), .Names = c("x", 
"y", "groups"), row.names = c(NA, -200L), class = "data.frame")

xyplot(y~x|groups, test, type = c("p","smooth"), span = 0.8, col.line="red")

span and col.line are not the default values

You will have to make your own panel function for locfit if you want to use
it
I have done it in the past - read the help for 
library(locfit)
?plot.locfit 
and the links
?lattice::prepanel

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Bond, Stephen
Sent: Tuesday, 7 October 2014 23:02
To: r-help at R-project.org
Subject: [R] lattice add a fit

What is the way to add an arbitrary fit from a model to a lattice
conditioning plot ?

For example
xyplot(v1 ~v2 | v3,data=mydata,
        panel=function(...){
            panel.xyplot(...)
            panel.loess(...,col.line="red")
        }
)
Will add a loess smoother. Instead, I want to put a fit from lm (but not a
simple straight line) and the fit has to be done for each panel separately,
not one fit for the full data set, so sth like an lm equivalent of
panel.locfit (there is no panel.lmfit)
Thank you.

Stephen B


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jweiner at tulane.edu  Tue Oct  7 22:50:37 2014
From: jweiner at tulane.edu (Weiner, Bryan J)
Date: Tue, 7 Oct 2014 20:50:37 +0000
Subject: [R] QCQP Optimization
In-Reply-To: <1412704773932-4698012.post@n4.nabble.com>
References: <1412704773932-4698012.post@n4.nabble.com>
Message-ID: <9D42ED6B-D738-4EEA-823A-90B73C84B763@tulane.edu>

I am trying to minimize a quadratic program with quadratic constraints but I
am having trouble choosing the package to use. I have been reading the
documentation and it seems like all the examples use equations instead of
vector manipulation. All of my parameters are vectors and matrices and they
can be quite large. Here is my problem:

X<-([Cf]+[H])%*%[A]
Y<-([Cf]+[H]-[R])%*%[B]I want to find H that minimizes Y%*%Dmat%*%t(Y) for a
given value of X%*%Dmat%*%t(X)

Cf, R, A, Dmat and B are matrices of constants.

The values for H sohould be between 0 and 1.

Is it possible to use Rsolnp to find the vector H even though the input
functions will all return other vectors?




--
View this message in context: http://r.789695.n4.nabble.com/QCQP-Optimization-tp4698012.html
Sent from the R help mailing list archive at Nabble.com<http://nabble.com/>.

Sent from my iPhone

On Oct 7, 2014, at 10:59 AM, BuffaloFan32 <jweiner at tulane.edu<mailto:jweiner at tulane.edu>> wrote:

I am trying to minimize a quadratic program with quadratic constraints but I
am having trouble choosing the package to use. I have been reading the
documentation and it seems like all the examples use equations instead of
vector manipulation. All of my parameters are vectors and matrices and they
can be quite large. Here is my problem:

X<-([Cf]+[H])%*%[A]
Y<-([Cf]+[H]-[R])%*%[B]I want to find H that minimizes Y%*%Dmat%*%t(Y) for a
given value of X%*%Dmat%*%t(X)

Cf, R, A, Dmat and B are matrices of constants.

The values for H sohould be between 0 and 1.

Is it possible to use Rsolnp to find the vector H even though the input
functions will all return other vectors?




--
View this message in context: http://r.789695.n4.nabble.com/QCQP-Optimization-tp4698012.html
Sent from the R help mailing list archive at Nabble.com<http://Nabble.com>.

	[[alternative HTML version deleted]]


From hafizuddinarshad21 at gmail.com  Wed Oct  8 04:25:49 2014
From: hafizuddinarshad21 at gmail.com (Hafizuddin Arshad)
Date: Tue, 7 Oct 2014 19:25:49 -0700
Subject: [R] Finding Rainfall Amount
Message-ID: <CAAPm8OoT__g5fAJZh6Qsu2LTqWr6VUgY44+nZ3yKzn1dfqGWxw@mail.gmail.com>

Dear R users,

I have this kind of data set which is part of my data:

structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L), Month = c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L), Rain = c(33, 32.7, 10.1, 43.1, 0,
11.6, 3, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA,
3.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,
0.1, 0.1, 0.1, 0.1, 1.1, 0.1, 0.1, 0.2, 1.1, 5.5, 5, 0, 0, 0,
0, 7.5, 0, 1.5, 0, 1.1, 0.1, 2.1, 0, 0, 0, 8.4, 15.5, 5.1, 5.6,
0, 1.5, 89.9, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6.9, 0, 8.1, 1.9, 0.1,
10.3, 0.5, 3.7, 19.6, 1.6, 7.6, 1.1, 1.1, 41.2, 17.6, 0.6, 2,
0, 2.5, 0.8, 0, 0, 9, 0.3, 1.8, 0.1, 2.3, 1.2, 2.1, 0, 17.5,
7.6, 1.1, 7.8, 4, 0, 0, 0, 66.9, 0, 4.9, 0, 0, 0, 0.9, 0, 0.2,
0, 2.3, 0, 9.1, 9.6, 0, 1.6, 0.7, 0, 0, 0, 30.3, 3.1, 14.4, 0.4,
0, 1.8, 14.7, 17.3, 0, 0, 3.3, 0, 0, 0, 7.5, 0.5, 0.3, 1.2, 3.3,
0, 6.9, 16.4, 0, 5.4, 30.2, 13.9, 1.8, 0, 0, 0, 0, 0, 1.2, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 28.3, 2, 0.1, 0.1, 0.1,
0.1, 0.1, 1.8, 0.2, 2, 0, 0)), .Names = c("Year", "Month", "Rain"
), class = "data.frame", row.names = c(NA, -194L))


I would like to find the rainfall total for each month within a year. The
result should be like in this form:

structure(list(V1 = c(28.4, 9.2, 48.8, 185.2, 4.1, 67.6, 49.7,
21.8, 5.6, 24.2, 0.8, 32, 88.9, 61.6, 36.8, 74, 16.3, 2.6, 7.6,
149.7, 13, 65.2, 3.8, 72.1, 49, 3.8, 24.1, 4.3, 19.6, 32.3, 5.6,
54.6, 94.2, 40.7, 101.3, 0.5, 11.7, 9.9, 86.4, 24.3, 91.3, 66.5,
13.2, 0.8, 16, 24.7, 18.1, 13.5, 126.5, 18.1, 62.5, 98.9, 212.6,
19.2, 42.4, 41.6, 73.2, 15, 43.2, 43, 1.4, 167.4, 11.4, 14, 15.6,
23.4, 23.8, 104.2, 58.8, 191.6, 37.2, 121, 36.2, 5.8, 26, 13,
18.6, 63.2, 28.6, 57.8), V2 = c(53.6, 0, 73.7, 106.8, 0, 9.2,
141.6, 32.3, 3.3, 28.5, 55.1, 0, 78.5, 71.6, 50.3, 1.3, 24.7,
201.2, 7.4, 59.9, 26.5, 46, 3.6, 5.6, 93.7, 56.1, 59.8, 33.7,
70.6, 38.9, 4.8, 18.6, 7.1, 62.2, 17.6, 17.5, 13.7, 42.2, 20.6,
18.3, 1.5, 17.1, 22.6, 2, 44.6, 8.2, 8.4, 69.6, 75.9, 59.6, 35.4,
122.9, 62.1, 43.8, 39.6, 111, 1.8, 10, 76.2, 0, 43.4, 194, 8.2,
9.8, 18.2, 5, 69.4, 1.6, 51.2, 51.2, 88.6, 43.4, 11.8, 19.6,
68.2, 48.6, 6.4, 102.4, 24.5, 73), V3 = c(1.3, 0.3, 73.4, 29.5,
58.6, 6.3, 119.7, 30, 6.3, 175.5, 66.3, 14.8, 24.2, 32.7, 28.9,
29.7, 1.6, 132.6, 10.9, 67.8, 23.7, 10.4, 53.6, 15.2, 82.4, 90.2,
3.8, 52.5, 81.2, 5.6, 67.8, 1, 3.3, 85.8, 138.6, 38, 47.8, 72.5,
5.9, 39.6, 16.5, 27.8, 39.5, 9.7, 58, 11.5, 14.8, 99.3, 48.1,
33.5, 14.3, 70.9, 17.5, 58.6, 20.8, 88.2, 72.8, 20.2, 32, 131,
52.4, 17.4, 46.6, 3.8, 35.2, 102.2, 10.6, 43.2, 33.4, 101.8,
43, 53.8, 42.8, 1.6, 45.4, 7.8, 1.2, 18, 39.4, 28), V4 = c(29.5,
0, 37.8, 9.1, 123.2, 1.8, 27.2, 44.5, 33.7, 73.2, 98.2, 29.5,
99.5, 117.7, 37.3, 19.9, 47.2, 185.8, 100, 21.9, 25, 80.5, 49.1,
7.4, 47.9, 30, 41.2, 32.8, 16.5, 88.9, 99.4, 43, 47.1, 10.2,
104.7, 21.6, 46, 89.8, 60.6, 60.4, 18.6, 24.4, 134.1, 20.9, 20.3,
2.6, 63.9, 83.8, 109.2, 54.6, 36, 134.9, 168, 24.6, 10, 14, 50.4,
35.4, 7.2, 31.6, 72.2, 38, 49.6, 36.2, 33.2, 172, 143.6, 10,
122, 6.4, 10.4, 29.4, 5.8, 118.8, 17.6, 26, 15.2, 18, 36.6, 18.6
), V5 = c(52.1, 68.4, 51.2, 20.6, 89.5, 58, 56, 37.7, 56.1, 153.7,
16.7, 58, 0, 23.7, 9.9, 40.6, 20.1, 29.7, 35.7, 4.3, 158.9, 12.2,
83.2, 28.5, 38.7, 28.7, 70.5, 38.6, 59, 100.2, 154.2, 61.7, 23.7,
67.3, 147.5, 17.5, 115.2, 12.4, 136.6, 16, 113.9, 103.5, 42.9,
48.3, 72.4, 33.6, 138.8, 67.8, 38.9, 61.8, 19.6, 51.9, 115.8,
63.8, 7.6, 78.4, 137, 30.6, 53, 55.8, 126.8, 9.2, 84.2, 61, 161.4,
111.4, 90.2, 11.2, 38.4, 32.2, 20.2, 39.8, 82, 14.6, 31.6, 36.8,
47.6, 4.6, 64.2, 24), V6 = c(65.9, 149.5, 69.4, 77.7, 102.8,
14.5, 58.1, 49.3, 37.9, 201.4, 99, 63.1, 40.9, 50.4, 105.9, 39.4,
89.1, 132, 14.2, 45.8, 104.6, 56.2, 22.6, 104.4, 58.5, 70.4,
40.8, 23.8, 31.5, 100.7, 144.4, 96.4, 45.4, 89.2, 127.5, 120.2,
18.8, 38.5, 21.3, 70.4, 94.3, 86.5, 80.5, 16.4, 77.5, 37.4, 58,
20.4, 42.5, 42.5, 11, 102.1, 19.3, 13.2, 25, 96.2, 64.8, 60.4,
170.6, 31.8, 66.8, 11.6, 68.2, 35.4, 75, 62.8, 81.2, 162.1, 55,
30.8, 101.2, 97.8, 24, 64.6, 46.2, 71, 103.3, 131.6, 33, 24.8
), V7 = c(72.6, 87.1, 34, 71.4, 62.8, 94.7, 59.2, 29, 54.7, 62.9,
54.1, 50.3, 100.4, 95, 142.2, 26.8, 32.5, 51.2, 40.7, 63.9, 43.8,
71.8, 29.2, 49.7, 145.8, 119.1, 29.7, 78.3, 69.7, 89.2, 73, 72,
45.4, 109.6, 128.8, 60.8, 122.4, 44.3, 139.5, 64.8, 46.5, 90.9,
165.8, 53.2, 57.4, 31.8, 61.6, 134.9, 42.9, 56.1, 46, 96.7, 149.6,
110.6, 43, 31.6, 119.6, 72, 157.6, 17, 101.6, 110.2, 48.6, 191.8,
106.6, 53.2, 154.4, 95.8, 42, 147.4, 52.2, 96.8, 24.6, 76.4,
29.4, 87.6, 71.9, 73.2, 104.3, 80), V8 = c(67.6, 59.2, 108.4,
35.9, 88.2, 91.3, 22.8, 49.6, 77.9, 67.6, 91.2, 48.9, 124.6,
54.6, 85.8, 62.8, 63.3, 174.7, 32.3, 22.7, 99.9, 123.2, 4.8,
149, 66, 73.9, 37.4, 22.4, 69.5, 87.3, 66.9, 87.2, 81.5, 109.1,
47.4, 22.8, 92.4, 60.9, 77.5, 91.3, 91.9, 78.2, 39.4, 107.5,
57.9, 65.5, 76, 47.2, 145.5, 95.9, 106, 120.4, 108, 96.8, 30.2,
16.6, 54, 63, 120.6, 10, 144.2, 126.4, 160.6, 88.2, 23.4, 83.8,
110.8, 99.8, 128.8, 35.1, 18.6, 84, 80.8, 78.6, 53.8, 142.2,
67.8, 126, 19.9, 49.8), V9 = c(58.7, 35.7, 50.7, 49.3, 38.9,
22.4, 28, 79.2, 24.9, 36.7, 34.5, 94.4, 51, 87.2, 11.4, 82, 25.2,
43.8, 50, 42.5, 51, 56.3, 8.4, 29.2, 5.4, 70.7, 48.1, 63.1, 84.5,
53, 82.4, 99.1, 30.6, 74.2, 74.6, 43, 71.2, 67, 111.5, 29, 51.2,
106, 132.9, 64.6, 114.2, 32.5, 21.7, 69.1, 126.1, 42.7, 15.3,
76.7, 79.6, 93.4, 93.8, 31.6, 129, 54.6, 57.8, 45.4, 82.2, 68.8,
31.6, 63.4, 61.2, 47, 49.6, 85.8, 133.4, 125.8, 24.8, 93.8, 67.8,
135, 50.2, 57.4, 50.6, 125.4, 10.8, 23.6), V10 = c(34.5, 55.1,
61.6, 17.6, 53.7, 89.5, 69.9, 28.8, 98.6, 47.8, 45.7, 30.1, 203,
107, 32.5, 73.6, 9.7, 84.9, 3.6, 32.7, 79.1, 35.5, 69.9, 81,
20, 85.3, 127.9, 214.7, 113.1, 83, 101.1, 59.1, 41.7, 145.7,
95.4, 50.5, 123.2, 82.6, 37.6, 41.8, 68, 82.6, 97, 51.2, 121.7,
46.1, 64.8, 54.2, 31, 38.9, 20.8, 106.7, 137.8, 180.8, 111.4,
16.2, 51, 63.6, 26.8, 9.2, 85, 74, 94.8, 131.4, 23.4, 70.8, 72.4,
8.6, 168, 126, 24.2, 58.2, 13.8, 40, 6.4, 85.5, 6.2, 107, 29.4,
12.2), V11 = c(0, 30.4, 125.3, 16.8, 16.6, 18, 5.3, 26.5, 42.5,
87.1, 33.3, 61.5, 151.9, 13.3, 13, 25, 5.1, 118.1, 41.6, 34.5,
49.5, 66.8, 14.3, 44.5, 103.5, 59.3, 74, 103.3, 61.5, 23, 73.5,
48.9, 158.7, 49, 32.1, 19.1, 50.5, 99.6, 47.5, 56.1, 32, 38.3,
40.7, 36.8, 63.9, 9.4, 49.9, 33.5, 101, 150.3, 36.9, 82.2, 39.4,
14.2, 45.4, 15.8, 88.4, 19.8, 22.2, 2.8, 37.4, 9.2, 62.6, 37.6,
81, 33.2, 9, 11.8, 96, 80.8, 52.8, 46.4, 49.2, 94.2, 15.2, 86.2,
100.6, 56.2, 90.6, 74.4), V12 = c(38.8, 86.8, 73.4, 0, 32.5,
36.3, 3.3, 44.2, 157.5, 1, 22.1, 179.7, 42, 37.1, 184.2, 31.5,
1.5, 3.8, 54.7, 19.3, 19.9, 0.5, 45.5, 15.8, 42.7, 104.7, 52.6,
15.4, 67.4, 21.7, 66.5, 11.8, 124.4, 39.3, 17.3, 77.5, 11.4,
18, 68.2, 77, 41.3, 16.3, 61.6, 24.6, 197.3, 4.6, 62.1, 24.4,
37.9, 97.7, 1.3, 69.8, 13.9, 98.4, 30.6, 8.6, 43.4, 102, 35,
21.8, 55.4, 18.2, 67.6, 47, 127.8, 28.2, 14, 67.8, 112, 136.6,
35.2, 35.8, 9.6, 13, 8.8, 119.6, 68.4, 45.8, 77, 56.6)), .Names = c("V1",
"V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10", "V11",
"V12"), class = "data.frame", row.names = c(NA, -80L))

where V1 until V12 as month and 1 until 80 as a years. How can I do this in
R? Thank you for helping me.


Arshad

	[[alternative HTML version deleted]]


From pollaroid at gmail.com  Wed Oct  8 09:57:46 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Wed, 8 Oct 2014 09:57:46 +0200
Subject: [R] Generate sequence of date based on a group ID
Message-ID: <CAAC1QdBYVMW=2_Hpi0zSX6YR6SsJedP5Ef_76N9ffJRoMhOSrA@mail.gmail.com>

I want to generate a sequence of date based on a group id(similar IDs
should have same date). The id variable contains unequal observations
and the length of the data set also varies.  How could I create a
sequence that starts on specific date (say January 1, 2000 onwards)
and continues until the end without specifying length?


Sample data follows:

df<-structure(list(id = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,

3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L), out1 = c(0L,

0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,

0L, 1L, 0L, 0L, 0L, 1L)), .Names = c("id", "out1"), class =
"data.frame", row.names = c(NA,

-23L))


From jim at bitwrit.com.au  Wed Oct  8 11:09:02 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 08 Oct 2014 20:09:02 +1100
Subject: [R] Finding Rainfall Amount
In-Reply-To: <CAAPm8OoT__g5fAJZh6Qsu2LTqWr6VUgY44+nZ3yKzn1dfqGWxw@mail.gmail.com>
References: <CAAPm8OoT__g5fAJZh6Qsu2LTqWr6VUgY44+nZ3yKzn1dfqGWxw@mail.gmail.com>
Message-ID: <2280028.Usv9ugvvDV@localhost.localdomain>

On Tue, 7 Oct 2014 07:25:49 PM Hafizuddin Arshad wrote:
> Dear R users,
> 
> I have this kind of data set which is part of my data:
> 
> ...
> 
> I would like to find the rainfall total for each month within a year. The
> result should be like in this form:
> 
> ...
> 
> where V1 until V12 as month and 1 until 80 as a years. How can I do 
this in
> R? 

Hi Arshad,
This might be what you want:

yearcorr<-min(raindat$Year)-1
years<-unique(raindat$Year)
rainmonth<-as.data.frame(matrix(0,nrow=2,ncol=12))
for(year in years) {
 for(month in 1:12) {
  if(any(raindat$Year==year&raindat$Month==month))
   rainmonth[year-yearcorr,month]<-
    mean(raindat$Rain[raindat$Year==year&raindat$Month==month],na.rm=TRUE)
 }
}
rownames(rainmonth)<-years
names(rainmonth)<-month.abb

Jim


From barry.king at qlx.com  Wed Oct  8 12:54:03 2014
From: barry.king at qlx.com (Barry King)
Date: Wed, 8 Oct 2014 06:54:03 -0400
Subject: [R] Function on an array
Message-ID: <CAP8WkrxGP-hTGr4sWuiMBdjdL+nVm+LniihFjHx+cEM2FhYQFA@mail.gmail.com>

ex1 <- c('Y', 'N', 'Y')
ex2 <- c('Y', 'N', 'Y')
ex3 <- c('N', 'N', 'Y')
ex4 <- c('N', 'N', 'Y')

status <- array(NA, dim=3)

# I am trying to return 'Okay' if any of the values
# in a column above is 'Y' but I am not constructing
# the function corrrectly.  Any assistance is
# greatly appreciated

status_fnc <- function(e){
  if (e[ ,1] == 'Y' | e[ ,2] == 'Y' | e[ ,3] == 'Y' | e[ ,4] == 'Y'){
    return('Okay')
  } else return('Not okay')
}
status <- sapply(cbind(ex1, ex2, ex3, ex4), status_fnc)

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Wed Oct  8 13:50:21 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 8 Oct 2014 13:50:21 +0200
Subject: [R] Function on an array
In-Reply-To: <CAP8WkrxGP-hTGr4sWuiMBdjdL+nVm+LniihFjHx+cEM2FhYQFA@mail.gmail.com>
References: <CAP8WkrxGP-hTGr4sWuiMBdjdL+nVm+LniihFjHx+cEM2FhYQFA@mail.gmail.com>
Message-ID: <CAHuTOvo4S11fYfEEK+R-PxSGOo-rbhbzXOx--m64VDdbEGZAxw@mail.gmail.com>

Dear Barry,

some thoughts:

1) e in your function status_fnc is a vector when applied on a matrix
like object, but you index it as a matrix (e[,i] should be e[i]).
2) You can simplify the if statement by using the function any
(replacing all the OR statements) on the vector, so use any(e=='Y')
here.
3) sapply applies over a list, which your object isn't. You provide a
matrix (cbind), so you should use apply in that case.

So one solution might be:

ex1 <- c('Y', 'N', 'Y')
ex2 <- c('Y', 'N', 'Y')
ex3 <- c('N', 'N', 'Y')
ex4 <- c('N', 'N', 'Y')
status_fnc <- function(e){
  if (any(e=='Y'))
    return('Okay')
  else
    return('Not okay')
}
status <- apply(cbind(ex1, ex2, ex3, ex4), 1, status_fnc)
status

On 8 October 2014 12:54, Barry King <barry.king at qlx.com> wrote:
> ex1 <- c('Y', 'N', 'Y')
> ex2 <- c('Y', 'N', 'Y')
> ex3 <- c('N', 'N', 'Y')
> ex4 <- c('N', 'N', 'Y')
>
> status <- array(NA, dim=3)
>
> # I am trying to return 'Okay' if any of the values
> # in a column above is 'Y' but I am not constructing
> # the function corrrectly.  Any assistance is
> # greatly appreciated
>
> status_fnc <- function(e){
>   if (e[ ,1] == 'Y' | e[ ,2] == 'Y' | e[ ,3] == 'Y' | e[ ,4] == 'Y'){
>     return('Okay')
>   } else return('Not okay')
> }
> status <- sapply(cbind(ex1, ex2, ex3, ex4), status_fnc)
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dulcalma at bigpond.com  Wed Oct  8 14:03:41 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Wed, 8 Oct 2014 22:03:41 +1000
Subject: [R] Finding Rainfall Amount
In-Reply-To: <CAAPm8OoT__g5fAJZh6Qsu2LTqWr6VUgY44+nZ3yKzn1dfqGWxw@mail.gmail.com>
References: <CAAPm8OoT__g5fAJZh6Qsu2LTqWr6VUgY44+nZ3yKzn1dfqGWxw@mail.gmail.com>
Message-ID: <000001cfe2ef$e7c32220$b7496660$@bigpond.com>

If you make a factor with year with levels including all the years that you
want then use tapply eg  with dat as the name of the data.frame
The same applies for Month but I have not done so

dat$Yr <- factor(dat$Year, levels = c(1971:1980))
with(dat, tapply(Rain,  list(Yr, Month), sum, na.rm=T))
         1    2     9    10    11    12
1971 138.5 14.1 138.3 144.4 139.8 172.7
1972  36.0   NA    NA    NA    NA    NA
1973    NA   NA    NA    NA    NA    NA
1974    NA   NA    NA    NA    NA    NA
1975    NA   NA    NA    NA    NA    NA
1976    NA   NA    NA    NA    NA    NA
1977    NA   NA    NA    NA    NA    NA
1978    NA   NA    NA    NA    NA    NA
1979    NA   NA    NA    NA    NA    NA
1980    NA   NA    NA    NA    NA    NA

regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
Behalf Of Hafizuddin Arshad
Sent: Wednesday, 8 October 2014 12:26
To: r-help at r-project.org
Subject: [R] Finding Rainfall Amount

Dear R users,

I have this kind of data set which is part of my data:

structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L), Month = c(1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L,
10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L,
11L, 11L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L), Rain = c(33, 32.7, 10.1, 43.1, 0,
11.6, 3, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA,
3.9, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1,
0.1, 0.1, 0.1, 0.1, 1.1, 0.1, 0.1, 0.2, 1.1, 5.5, 5, 0, 0, 0,
0, 7.5, 0, 1.5, 0, 1.1, 0.1, 2.1, 0, 0, 0, 8.4, 15.5, 5.1, 5.6,
0, 1.5, 89.9, 0, 0, 0, 0, 0, 0, 0, 0, 6, 6.9, 0, 8.1, 1.9, 0.1,
10.3, 0.5, 3.7, 19.6, 1.6, 7.6, 1.1, 1.1, 41.2, 17.6, 0.6, 2,
0, 2.5, 0.8, 0, 0, 9, 0.3, 1.8, 0.1, 2.3, 1.2, 2.1, 0, 17.5,
7.6, 1.1, 7.8, 4, 0, 0, 0, 66.9, 0, 4.9, 0, 0, 0, 0.9, 0, 0.2,
0, 2.3, 0, 9.1, 9.6, 0, 1.6, 0.7, 0, 0, 0, 30.3, 3.1, 14.4, 0.4,
0, 1.8, 14.7, 17.3, 0, 0, 3.3, 0, 0, 0, 7.5, 0.5, 0.3, 1.2, 3.3,
0, 6.9, 16.4, 0, 5.4, 30.2, 13.9, 1.8, 0, 0, 0, 0, 0, 1.2, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, NA, 28.3, 2, 0.1, 0.1, 0.1,
0.1, 0.1, 1.8, 0.2, 2, 0, 0)), .Names = c("Year", "Month", "Rain"
), class = "data.frame", row.names = c(NA, -194L))


I would like to find the rainfall total for each month within a year. The
result should be like in this form:

structure(list(V1 = c(28.4, 9.2, 48.8, 185.2, 4.1, 67.6, 49.7,
21.8, 5.6, 24.2, 0.8, 32, 88.9, 61.6, 36.8, 74, 16.3, 2.6, 7.6,
149.7, 13, 65.2, 3.8, 72.1, 49, 3.8, 24.1, 4.3, 19.6, 32.3, 5.6,
54.6, 94.2, 40.7, 101.3, 0.5, 11.7, 9.9, 86.4, 24.3, 91.3, 66.5,
13.2, 0.8, 16, 24.7, 18.1, 13.5, 126.5, 18.1, 62.5, 98.9, 212.6,
19.2, 42.4, 41.6, 73.2, 15, 43.2, 43, 1.4, 167.4, 11.4, 14, 15.6,
23.4, 23.8, 104.2, 58.8, 191.6, 37.2, 121, 36.2, 5.8, 26, 13,
18.6, 63.2, 28.6, 57.8), V2 = c(53.6, 0, 73.7, 106.8, 0, 9.2,
141.6, 32.3, 3.3, 28.5, 55.1, 0, 78.5, 71.6, 50.3, 1.3, 24.7,
201.2, 7.4, 59.9, 26.5, 46, 3.6, 5.6, 93.7, 56.1, 59.8, 33.7,
70.6, 38.9, 4.8, 18.6, 7.1, 62.2, 17.6, 17.5, 13.7, 42.2, 20.6,
18.3, 1.5, 17.1, 22.6, 2, 44.6, 8.2, 8.4, 69.6, 75.9, 59.6, 35.4,
122.9, 62.1, 43.8, 39.6, 111, 1.8, 10, 76.2, 0, 43.4, 194, 8.2,
9.8, 18.2, 5, 69.4, 1.6, 51.2, 51.2, 88.6, 43.4, 11.8, 19.6,
68.2, 48.6, 6.4, 102.4, 24.5, 73), V3 = c(1.3, 0.3, 73.4, 29.5,
58.6, 6.3, 119.7, 30, 6.3, 175.5, 66.3, 14.8, 24.2, 32.7, 28.9,
29.7, 1.6, 132.6, 10.9, 67.8, 23.7, 10.4, 53.6, 15.2, 82.4, 90.2,
3.8, 52.5, 81.2, 5.6, 67.8, 1, 3.3, 85.8, 138.6, 38, 47.8, 72.5,
5.9, 39.6, 16.5, 27.8, 39.5, 9.7, 58, 11.5, 14.8, 99.3, 48.1,
33.5, 14.3, 70.9, 17.5, 58.6, 20.8, 88.2, 72.8, 20.2, 32, 131,
52.4, 17.4, 46.6, 3.8, 35.2, 102.2, 10.6, 43.2, 33.4, 101.8,
43, 53.8, 42.8, 1.6, 45.4, 7.8, 1.2, 18, 39.4, 28), V4 = c(29.5,
0, 37.8, 9.1, 123.2, 1.8, 27.2, 44.5, 33.7, 73.2, 98.2, 29.5,
99.5, 117.7, 37.3, 19.9, 47.2, 185.8, 100, 21.9, 25, 80.5, 49.1,
7.4, 47.9, 30, 41.2, 32.8, 16.5, 88.9, 99.4, 43, 47.1, 10.2,
104.7, 21.6, 46, 89.8, 60.6, 60.4, 18.6, 24.4, 134.1, 20.9, 20.3,
2.6, 63.9, 83.8, 109.2, 54.6, 36, 134.9, 168, 24.6, 10, 14, 50.4,
35.4, 7.2, 31.6, 72.2, 38, 49.6, 36.2, 33.2, 172, 143.6, 10,
122, 6.4, 10.4, 29.4, 5.8, 118.8, 17.6, 26, 15.2, 18, 36.6, 18.6
), V5 = c(52.1, 68.4, 51.2, 20.6, 89.5, 58, 56, 37.7, 56.1, 153.7,
16.7, 58, 0, 23.7, 9.9, 40.6, 20.1, 29.7, 35.7, 4.3, 158.9, 12.2,
83.2, 28.5, 38.7, 28.7, 70.5, 38.6, 59, 100.2, 154.2, 61.7, 23.7,
67.3, 147.5, 17.5, 115.2, 12.4, 136.6, 16, 113.9, 103.5, 42.9,
48.3, 72.4, 33.6, 138.8, 67.8, 38.9, 61.8, 19.6, 51.9, 115.8,
63.8, 7.6, 78.4, 137, 30.6, 53, 55.8, 126.8, 9.2, 84.2, 61, 161.4,
111.4, 90.2, 11.2, 38.4, 32.2, 20.2, 39.8, 82, 14.6, 31.6, 36.8,
47.6, 4.6, 64.2, 24), V6 = c(65.9, 149.5, 69.4, 77.7, 102.8,
14.5, 58.1, 49.3, 37.9, 201.4, 99, 63.1, 40.9, 50.4, 105.9, 39.4,
89.1, 132, 14.2, 45.8, 104.6, 56.2, 22.6, 104.4, 58.5, 70.4,
40.8, 23.8, 31.5, 100.7, 144.4, 96.4, 45.4, 89.2, 127.5, 120.2,
18.8, 38.5, 21.3, 70.4, 94.3, 86.5, 80.5, 16.4, 77.5, 37.4, 58,
20.4, 42.5, 42.5, 11, 102.1, 19.3, 13.2, 25, 96.2, 64.8, 60.4,
170.6, 31.8, 66.8, 11.6, 68.2, 35.4, 75, 62.8, 81.2, 162.1, 55,
30.8, 101.2, 97.8, 24, 64.6, 46.2, 71, 103.3, 131.6, 33, 24.8
), V7 = c(72.6, 87.1, 34, 71.4, 62.8, 94.7, 59.2, 29, 54.7, 62.9,
54.1, 50.3, 100.4, 95, 142.2, 26.8, 32.5, 51.2, 40.7, 63.9, 43.8,
71.8, 29.2, 49.7, 145.8, 119.1, 29.7, 78.3, 69.7, 89.2, 73, 72,
45.4, 109.6, 128.8, 60.8, 122.4, 44.3, 139.5, 64.8, 46.5, 90.9,
165.8, 53.2, 57.4, 31.8, 61.6, 134.9, 42.9, 56.1, 46, 96.7, 149.6,
110.6, 43, 31.6, 119.6, 72, 157.6, 17, 101.6, 110.2, 48.6, 191.8,
106.6, 53.2, 154.4, 95.8, 42, 147.4, 52.2, 96.8, 24.6, 76.4,
29.4, 87.6, 71.9, 73.2, 104.3, 80), V8 = c(67.6, 59.2, 108.4,
35.9, 88.2, 91.3, 22.8, 49.6, 77.9, 67.6, 91.2, 48.9, 124.6,
54.6, 85.8, 62.8, 63.3, 174.7, 32.3, 22.7, 99.9, 123.2, 4.8,
149, 66, 73.9, 37.4, 22.4, 69.5, 87.3, 66.9, 87.2, 81.5, 109.1,
47.4, 22.8, 92.4, 60.9, 77.5, 91.3, 91.9, 78.2, 39.4, 107.5,
57.9, 65.5, 76, 47.2, 145.5, 95.9, 106, 120.4, 108, 96.8, 30.2,
16.6, 54, 63, 120.6, 10, 144.2, 126.4, 160.6, 88.2, 23.4, 83.8,
110.8, 99.8, 128.8, 35.1, 18.6, 84, 80.8, 78.6, 53.8, 142.2,
67.8, 126, 19.9, 49.8), V9 = c(58.7, 35.7, 50.7, 49.3, 38.9,
22.4, 28, 79.2, 24.9, 36.7, 34.5, 94.4, 51, 87.2, 11.4, 82, 25.2,
43.8, 50, 42.5, 51, 56.3, 8.4, 29.2, 5.4, 70.7, 48.1, 63.1, 84.5,
53, 82.4, 99.1, 30.6, 74.2, 74.6, 43, 71.2, 67, 111.5, 29, 51.2,
106, 132.9, 64.6, 114.2, 32.5, 21.7, 69.1, 126.1, 42.7, 15.3,
76.7, 79.6, 93.4, 93.8, 31.6, 129, 54.6, 57.8, 45.4, 82.2, 68.8,
31.6, 63.4, 61.2, 47, 49.6, 85.8, 133.4, 125.8, 24.8, 93.8, 67.8,
135, 50.2, 57.4, 50.6, 125.4, 10.8, 23.6), V10 = c(34.5, 55.1,
61.6, 17.6, 53.7, 89.5, 69.9, 28.8, 98.6, 47.8, 45.7, 30.1, 203,
107, 32.5, 73.6, 9.7, 84.9, 3.6, 32.7, 79.1, 35.5, 69.9, 81,
20, 85.3, 127.9, 214.7, 113.1, 83, 101.1, 59.1, 41.7, 145.7,
95.4, 50.5, 123.2, 82.6, 37.6, 41.8, 68, 82.6, 97, 51.2, 121.7,
46.1, 64.8, 54.2, 31, 38.9, 20.8, 106.7, 137.8, 180.8, 111.4,
16.2, 51, 63.6, 26.8, 9.2, 85, 74, 94.8, 131.4, 23.4, 70.8, 72.4,
8.6, 168, 126, 24.2, 58.2, 13.8, 40, 6.4, 85.5, 6.2, 107, 29.4,
12.2), V11 = c(0, 30.4, 125.3, 16.8, 16.6, 18, 5.3, 26.5, 42.5,
87.1, 33.3, 61.5, 151.9, 13.3, 13, 25, 5.1, 118.1, 41.6, 34.5,
49.5, 66.8, 14.3, 44.5, 103.5, 59.3, 74, 103.3, 61.5, 23, 73.5,
48.9, 158.7, 49, 32.1, 19.1, 50.5, 99.6, 47.5, 56.1, 32, 38.3,
40.7, 36.8, 63.9, 9.4, 49.9, 33.5, 101, 150.3, 36.9, 82.2, 39.4,
14.2, 45.4, 15.8, 88.4, 19.8, 22.2, 2.8, 37.4, 9.2, 62.6, 37.6,
81, 33.2, 9, 11.8, 96, 80.8, 52.8, 46.4, 49.2, 94.2, 15.2, 86.2,
100.6, 56.2, 90.6, 74.4), V12 = c(38.8, 86.8, 73.4, 0, 32.5,
36.3, 3.3, 44.2, 157.5, 1, 22.1, 179.7, 42, 37.1, 184.2, 31.5,
1.5, 3.8, 54.7, 19.3, 19.9, 0.5, 45.5, 15.8, 42.7, 104.7, 52.6,
15.4, 67.4, 21.7, 66.5, 11.8, 124.4, 39.3, 17.3, 77.5, 11.4,
18, 68.2, 77, 41.3, 16.3, 61.6, 24.6, 197.3, 4.6, 62.1, 24.4,
37.9, 97.7, 1.3, 69.8, 13.9, 98.4, 30.6, 8.6, 43.4, 102, 35,
21.8, 55.4, 18.2, 67.6, 47, 127.8, 28.2, 14, 67.8, 112, 136.6,
35.2, 35.8, 9.6, 13, 8.8, 119.6, 68.4, 45.8, 77, 56.6)), .Names = c("V1",
"V2", "V3", "V4", "V5", "V6", "V7", "V8", "V9", "V10", "V11",
"V12"), class = "data.frame", row.names = c(NA, -80L))

where V1 until V12 as month and 1 until 80 as a years. How can I do this in
R? Thank you for helping me.


Arshad

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Wed Oct  8 15:36:37 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 8 Oct 2014 16:36:37 +0300
Subject: [R] Data formart
Message-ID: <CAGh51gSP5SwyQtfrdAGLKbmDySih3eUqjRf1HfnXHzmx_EFtow@mail.gmail.com>

Dear All,

Change the format of the start and end columns so that data appear as the
day of the year. For instance: Apr 24 rather than 115.

The idea is that I want the non=leap years to be 366 days instead of being
365 days. ie. Each year must have 366 days. for example: in the column
Start2, Apr 18 will be Apr 17.

> head(Samaru)
  Year Start End Length Start2   End2
1 1930   108 288    180 Apr 18 Oct 15
2 1931   118 288    170 Apr 28 Oct 15
3 1932   115 295    180 Apr 24 Oct 21
4 1933   156 294    138 Jun 05 Oct 21
5 1934   116 291    175 Apr 26 Oct 18
6 1935   134 288    154 May 14 Oct 15

Any idea is welcome. Thamks!!!!
-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Wed Oct  8 15:49:02 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 8 Oct 2014 16:49:02 +0300
Subject: [R] Changing date format
In-Reply-To: <CAGh51gTQkztOUDfsHwVHVFT-B1VQk=LP0VvywndMZRPvQB0KzA@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<1486793.FaODssWil9@localhost.localdomain>
	<5433B7A6.2010408@umu.se>
	<3161681.zHNUP8T3m9@localhost.localdomain>
	<CAGh51gTQkztOUDfsHwVHVFT-B1VQk=LP0VvywndMZRPvQB0KzA@mail.gmail.com>
Message-ID: <CAGh51gTLd7Nyt=e0Mp0oHbGs5DGg0Y_2E-V+QaY7joygG0zszg@mail.gmail.com>

The idea is that I want the non-leap years to be 366 days instead of being
365 days. ie. Each year must have 366 days.

for example: in the column Start2, Apr 18 will be Apr 17.

> head(Samaru)
  Year Start End Length Start2   End2
1 1930   108 288    180 Apr 18 Oct 15
2 1931   118 288    170 Apr 28 Oct 15
3 1932   115 295    180 Apr 24 Oct 21
4 1933   156 294    138 Jun 05 Oct 21
5 1934   116 291    175 Apr 26 Oct 18
6 1935   134 288    154 May 14 Oct 15

Is there a way to that in R?

On Tue, Oct 7, 2014 at 3:25 PM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> Thanks All. Your idea is useful!!!
>
> On Tue, Oct 7, 2014 at 1:01 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
>
>> On Tue, 7 Oct 2014 11:51:34 AM G?ran Brostr?m wrote:
>> > On 2014-10-07 11:27, Jim Lemon wrote:
>> > > On Tue, 7 Oct 2014 10:32:42 AM Frederic Ntirenganya wrote:
>> > >> Dear All,
>> > >>
>> > >> How can I change the format of date of day of the year ? for
>> > >
>> > > example r
>> > >
>> > >> (i.e. "17 Apr" rather than "108").
>> > >>
>> > >> The following is the type of the dataset I have
>> > >>
>> > >> head(Samaru)
>> > >>
>> > >>    Year Start End Length
>> > >>
>> > >> 1 1930   108 288    180
>> > >> 2 1931   118 288    170
>> > >> 3 1932   115 295    180
>> > >> 4 1933   156 294    138
>> > >> 5 1934   116 291    175
>> > >> 6 1935   134 288    154
>> > >
>> > > Hi Frederic,
>> > > The easiest method I can think of is this:
>> > >
>> > > Samaru$Start<-format(as.Date(
>> > >
>> > >   paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start,
>> > >   "%b %d")
>> > >
>> > > Samaru$End<-format(as.Date(
>> > >
>> > >   paste(Samaru$Year,"01-01",sep="-"))+Samaru$End,
>> > >   "%b %d")
>> >
>> > In the package 'eha' I have a function 'toDate':
>> >  > require(eha)
>> >  > toDate(1930 + 108/365)
>> >
>> > [1] "1930-04-19"
>> >
>> > (Interestingly, we are all wrong; the correct answer seems to be
>> > "1930-04-18")
>> >
>> >  > toDate
>> >
>> > function (times)
>> > {
>> >      if (!is.numeric(times))
>> >          stop("Argument must be numeric")
>> >      times * 365.2425 + as.Date("0000-01-01")
>> > }
>> >
>> > The 'inverse' function is 'toTime'.
>> >
>> > Sometimes it misses by one day; not very important in my
>> applications,
>> > but may be otherwise.
>> >
>> Hi Goran,
>> You're correct.
>>
>>  as.Date("Apr 19 1930","%b %d %Y") -
>> + as.Date("Jan 1 1930","%b %d %Y")
>> Time difference of 108 days
>>
>> The t
>>
>> Samaru$Start<-format(as.Date(
>>  paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start-1,"%b %d")
>> Samaru$End<-format(as.Date(
>>  paste(Samaru$Year,"01-01",sep="-"))+Samaru$End-1, "%b %d")
>>
>> Jim
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> --
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jvadams at usgs.gov  Wed Oct  8 15:52:20 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Wed, 8 Oct 2014 08:52:20 -0500
Subject: [R] Generate sequence of date based on a group ID
In-Reply-To: <CAAC1QdBYVMW=2_Hpi0zSX6YR6SsJedP5Ef_76N9ffJRoMhOSrA@mail.gmail.com>
References: <CAAC1QdBYVMW=2_Hpi0zSX6YR6SsJedP5Ef_76N9ffJRoMhOSrA@mail.gmail.com>
Message-ID: <CAN5YmCHpcjAX9Dg8r_vrX5wNq2bkxB+fQ=oya+px_gUTV7YSpA@mail.gmail.com>

Does this work for you?

df$in1 <- 0
df$in1[match(unique(df$id), df$id)] <- 1
df$date <- as.Date("2000-01-01") + cumsum(df$in1) - 1

Jean

On Wed, Oct 8, 2014 at 2:57 AM, Kuma Raj <pollaroid at gmail.com> wrote:

> I want to generate a sequence of date based on a group id(similar IDs
> should have same date). The id variable contains unequal observations
> and the length of the data set also varies.  How could I create a
> sequence that starts on specific date (say January 1, 2000 onwards)
> and continues until the end without specifying length?
>
>
> Sample data follows:
>
> df<-structure(list(id = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,
>
> 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L), out1 = c(0L,
>
> 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,
>
> 0L, 1L, 0L, 0L, 0L, 1L)), .Names = c("id", "out1"), class =
> "data.frame", row.names = c(NA,
>
> -23L))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From neal at walfield.org  Wed Oct  8 16:22:13 2014
From: neal at walfield.org (Neal H. Walfield)
Date: Wed, 08 Oct 2014 16:22:13 +0200
Subject: [R] write.table produces a file that read.table can't read
Message-ID: <87egui3alm.wl%neal@walfield.org>

Hi,

I'm using R version 3.1.1 on Debian via the CRAN repositories.

Consider the following MWE that writes a data.frame out to a file and
reads it back in (note that one of the strings contains a double
quote):

  > write.table(data.frame(a=1:3, b=c("a", "b\"b", "c")), '/tmp/a', row.names=FALSE, na="?", sep=",")
  > read.table('/tmp/a', header=TRUE, row.names=NULL, sep=',', na.strings='?', allowEscapes=T)
  [1] a b
  <0 rows> (or 0-length row.names)

/tmp/a contains the following:

  $ cat /tmp/a 
  "a","b"
  1,"a"
  2,"b\"b"
  3,"c"

Removing the double quote, it works:

  > write.table(data.frame(a=1:3, b=c("a", "bb", "c")), '/tmp/a', row.names=FALSE, na="?", sep=",")
  > read.table('/tmp/a', header=TRUE, row.names=NULL, sep=',', na.strings='?', allowEscapes=T)
    a  b
  1 1  a
  2 2 bb
  3 3  c

Why does allowEscapes not work for double quotes?  Or, why does
write.table produce a file that read.table can't read!

Thanks for any advice!

Neal


From rshepard at appl-ecosys.com  Wed Oct  8 16:34:19 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 8 Oct 2014 07:34:19 -0700 (PDT)
Subject: [R] CoDA: Interpreting acomp() Summary Output
Message-ID: <alpine.LNX.2.11.1410080719330.9684@localhost>

   Using package 'compositions' on count data and scaling with Aitchison
geometry using function acomp(), the summary() function displays matrices
for (among other descriptive statistics) minimum, Q1, median, Q3, and
maximum. These matrices are not symmetric because they are based on
log-ratios. An example is the median matrix:

$med
             filter     gather     graze   predate     shred
filter   1.0000000 0.09060847 0.7083333 0.1833333  1.416667
gather  11.4166667 1.00000000 9.0000000 2.2083333 18.750000
graze    1.4166667 0.11111111 1.0000000 0.2403846  1.750000
predate  5.5000000 0.45299145 4.1666667 1.0000000  8.500000
shred    0.7083333 0.05341880 0.5833333 0.1180556  1.000000

   What should I read to learn how to interpret this output?[1]

   I need to explain the results to non-technical decision-makers so they can
see (boxplot() does a great job of this) and understand the variability of
each data set.

Rich

[1] 'Analyzing Compositional Data with R', page 79, mentions these measures
of center and distribution but not how to interpret them.


From erinm.hodgess at gmail.com  Wed Oct  8 17:03:08 2014
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 8 Oct 2014 11:03:08 -0400
Subject: [R]  an opinion question about State Space and Kalman Filters,
	please
Message-ID: <CACxE24kO73wOtT-eZ2Rr0zWn3HOjiRGHC=Bn1YooAw7gGGraeA@mail.gmail.com>

Hello!

Could anyone recommend a good book on state space/Kalman filters, please?
Those which include R steps are nice, but not necessary.  I'm most
interested in the state space/Kalman filters.

I would like to do a sort of compare and contrast with arima results.

Thanks,
Erin


-- 
Erin Hodgess
Associate Professor
Department of Mathematical and Statistics
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com

	[[alternative HTML version deleted]]


From f_j_rod at hotmail.com  Wed Oct  8 17:06:30 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Wed, 8 Oct 2014 17:06:30 +0200
Subject: [R] Obtain a list of data tables from a main data table
Message-ID: <BAY168-W12804307508D3E75E8AFDF3BAA30@phx.gbl>

 

Hi everybody,

 

I have (as an example) the following
two data tables:

 

all <-
data.table(ID = c(rep(c(100:105),c(3,2,2,3,3,3))),

     value =
c(100,120,110,90,45,35,270,50,65,40,25,55,75,30,95,70))

DT <-
data.table(ID = 100:105, code=c(2,1,3,2,3,1))

 

My aim is to construct as many sub data tables as different values for
the integer variable code, and I have
done:

code_1
<- all[ID %in% DT[code==1]$ID] 

code_2
<- all[ID %in% DT[code==2]$ID] 

code_3
<- all[ID %in% DT[code==3]$ID] 

 

Because maximum code value can be very
high, ?is it possible to obtain a list of the above 3 data tables through a
loop? I mean something like:

 

for (i in
1:max(DT$code)){

  paste(code,?_?,[i]) <- }

return(list)]

 

Thank
you very much to all the members!

 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Oct  8 18:00:55 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 08 Oct 2014 10:00:55 -0600
Subject: [R] Obtain a list of data tables from a main data table
In-Reply-To: <BAY168-W12804307508D3E75E8AFDF3BAA30@phx.gbl>
References: <BAY168-W12804307508D3E75E8AFDF3BAA30@phx.gbl>
Message-ID: <1053C91E-3948-4B0C-BD69-23792C9A8B0A@dcn.davis.CA.us>

Please be aware that by posting your question in HTML format instead of plain text you have sent us a corrupted message. Please adjust your email software settings when sending to this list.

I thought the whole purpose of data.table was to allow group data processing without creating oodles of separate tables.

What is your intended use of ask if these tables?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 8, 2014 9:06:30 AM MDT, "Frank S." <f_j_rod at hotmail.com> wrote:
> 
>
>Hi everybody,
>
> 
>
>I have (as an example) the following
>two data tables:
>
> 
>
>all <-
>data.table(ID = c(rep(c(100:105),c(3,2,2,3,3,3))),
>
>     value =
>c(100,120,110,90,45,35,270,50,65,40,25,55,75,30,95,70))
>
>DT <-
>data.table(ID = 100:105, code=c(2,1,3,2,3,1))
>
> 
>
>My aim is to construct as many sub data tables as different values for
>the integer variable code, and I have
>done:
>
>code_1
><- all[ID %in% DT[code==1]$ID] 
>
>code_2
><- all[ID %in% DT[code==2]$ID] 
>
>code_3
><- all[ID %in% DT[code==3]$ID] 
>
> 
>
>Because maximum code value can be very
>high, ?is it possible to obtain a list of the above 3 data tables
>through a
>loop? I mean something like:
>
> 
>
>for (i in
>1:max(DT$code)){
>
>  paste(code,?_?,[i]) <- }
>
>return(list)]
>
> 
>
>Thank
>you very much to all the members!
>
> 		 	   		  
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kmezhoud at gmail.com  Wed Oct  8 18:14:35 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Wed, 8 Oct 2014 17:14:35 +0100
Subject: [R] Desktop icon to run R and load/run specific package
Message-ID: <CALJKBv_rH+EeMTJ_v+4cQN6DJ6b+ouXCp3xWJvZzA6hEDQoH=A@mail.gmail.com>

Hi,
I'm developing R package with GUI.
I would write a file that run R and load package by double clic.
I am using Kubuntu.
If there is a solution with windows or mac, I am interested too.
Thanks
Karim

	[[alternative HTML version deleted]]


From david at revolutionanalytics.com  Wed Oct  8 18:25:15 2014
From: david at revolutionanalytics.com (David Smith)
Date: Wed, 8 Oct 2014 11:25:15 -0500
Subject: [R] Revolutions blog: September 2014 roundup
Message-ID: <CABgvEC_jE4pTqLaBtLL6+Dx08rrbMw-uFQLJxMW2BvWjwy0vvA@mail.gmail.com>

Revolution Analytics staff and guests write about R every weekday at
the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of September:

Norm Matloff argues that T-tests shouldn't be part of the Statistics
curriculum and questions the "star system" for p-values in R:
http://bit.ly/1rX82HF

A nice video introduction to the dplyr package and the %>% operator,
presented by Kevin Markham: http://bit.ly/1rX8566

An animation of police militarization in the US, created with R and
open data published by the New York Times: http://bit.ly/1rX8564

An overview of the miscellaneous R functions in the DescTools package:
http://bit.ly/1rX82HH

Some guidance from Will Stanton on becoming a "data hacker" using R
and Hadoop: http://bit.ly/1rX8565

A tutorial on publishing ggplot2 graphics to the web with plotly:
http://bit.ly/1rX82HG

A Shiny app that implements the Travelling Salesman problem and
animates the simulating annealing algorithm behind the solution:
http://bit.ly/1rX8569

R code for comparing performance of machine learning models:
http://bit.ly/1rX85D6

Presentations at DataWeek on applications of R at companies:
http://bit.ly/1rX82HI

Announcing new members for the R Foundation and the R Core team:
http://bit.ly/1rX8568

A graduate student uses R to look at the popularity of posts on
Reddit: http://bit.ly/1rX82HJ

Google introduces the CausalImpact package for R, and uses it to
evaluate performance of marketing campaigns: http://bit.ly/1rX8567

A review of several recent and upcoming conferences that include
R-related tracks: http://bit.ly/1rX856a

More presentations and video interview from the useR! 2014 conference,
from DataScience.LA: http://bit.ly/1rX85D9

A detailed Rcpp example based on the Collatz Conjecture: http://bit.ly/1rX85D7

Use Rmarkdown to create documents combining text, mathematics, and R
graphical and tabular output: http://bit.ly/1rX856b

A very early example of data analysis: Nile floods in 450 BC
http://bit.ly/1rX85D8

The Rockefeller Institute of Government uses R to simulate the
finances of public sector pension funds: http://bit.ly/1rX856e

General interest stories (not related to R) in the past month
included: ET for the Atari 2600 (http://bit.ly/1rX856c), Talk Like a
Pirate day photos (http://bit.ly/1rX856f), a parody lifestyle magazine
for data scientists (http://bit.ly/1rX85Db) and the spread of the Ice
Bucket Challenge (http://bit.ly/1rX85Da).

Meeting times for local R user groups
(http://blog.revolutionanalytics.com/local-r-groups.html) can be found
on the updated R Community Calendar at:
http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
You can receive daily blog posts via email using services like
blogtrottr.com, or join the Revolution Analytics mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com or via Twitter (I'm
@revodavid).

Cheers,
# David

-- 
David M Smith <david at revolutionanalytics.com>
Chief Community Officer, Revolution Analytics
http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Chicago IL, USA)
Twitter: @revodavid

-- 
Try Revolution Enterprise R Now!  
<https://aws.amazon.com/marketplace/seller-profile/ref=_ptnr_emailfooter?ie=UTF8&id=3c6536d3-8115-4bc0-a713-be58e257a7be>
Get a 14 Day Free Trial of Revolution R Enterprise on AWS Marketplace


From zadig_1 at excite.com  Wed Oct  8 18:26:16 2014
From: zadig_1 at excite.com (ce)
Date: Wed, 08 Oct 2014 12:26:16 -0400
Subject: [R] Desktop icon to run R and load/run specific package
Message-ID: <20141008122616.16833@web006.roc2.bluetie.com>

Did you try to create a file containing 

#!/usr/bin/Rscript

library(mypackage) 
....


you also need to give execute permission like chmod 755 myfile.R

-----Original Message-----
From: "Karim Mezhoud" [kmezhoud at gmail.com]
Date: 10/08/2014 12:16 PM
To: R-help at r-project.org
Subject: [R] Desktop icon to run R and load/run specific package

Hi,
I'm developing R package with GUI.
I would write a file that run R and load package by double clic.
I am using Kubuntu.
If there is a solution with windows or mac, I am interested too.
Thanks
Karim

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Oct  8 18:29:48 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 8 Oct 2014 09:29:48 -0700
Subject: [R] lattice add a fit
In-Reply-To: <000001cfe2ae$7c1fa7f0$745ef7d0$@bigpond.com>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
	<000001cfe2ae$7c1fa7f0$745ef7d0$@bigpond.com>
Message-ID: <C14CE528-F86A-43FD-8849-1815DC6385ED@comcast.net>


On Oct 7, 2014, at 9:15 PM, Duncan Mackay wrote:

I'm a tad puzzled by the comments about needing to build a panel function for locfit. The various plot.locfit functions are actually lattice calls. 

locfit:::panel.locfit  # already exists, and even has versions for 1d, 2d and 3d purposes.

And there is a llines.locfit function that will add locfit smooths to existing lattice plots.

It's a very simple function and could easily be modified to any regression method that has a predict functions:

> locfit:::llines.locfit
function (x, m = 100, tr = x$trans, ...) 
{
    newx <- lfmarg(x, m = m)[[1]]  # probably need to modify to your purposes
    y <- predict(x, newx, tr = tr)
    llines(newx, y, ...)
}
<environment: namespace:locfit>

-- 
David

> 
> You will have to make your own panel function for locfit if you want to use
> it
> I have done it in the past - read the help for 
> library(locfit)
> ?plot.locfit 
> and the links
> ?lattice::prepanel
> 
> Regards
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Bond, Stephen
> Sent: Tuesday, 7 October 2014 23:02
> To: r-help at R-project.org
> Subject: [R] lattice add a fit
> 
> What is the way to add an arbitrary fit from a model to a lattice
> conditioning plot ?
> 
> For example
> xyplot(v1 ~v2 | v3,data=mydata,
>        panel=function(...){
>            panel.xyplot(...)
>            panel.loess(...,col.line="red")
>        }
> )
> Will add a loess smoother. Instead, I want to put a fit from lm (but not a
> simple straight line) and the fit has to be done for each panel separately,
> not one fit for the full data set, so sth like an lm equivalent of
> panel.locfit (there is no panel.lmfit)
> Thank you.
> 
> Stephen B
> 
> 
> 	[[alternative HTML version deleted]]
> 


David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Wed Oct  8 18:34:27 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 8 Oct 2014 16:34:27 +0000
Subject: [R] write.table produces a file that read.table can't read
In-Reply-To: <87egui3alm.wl%neal@walfield.org>
References: <87egui3alm.wl%neal@walfield.org>
Message-ID: <D05AB531.10E557%macqueen1@llnl.gov>

How about:

tmp <- data.frame(a=1:3, b=c("a", "b\"b", "c"))

write.table(tmp, './tmp.write', row.names=FALSE, sep="\t?, quote=FALSE)

tmp.in <- read.table('./tmp.write', sep='\t', head=TRUE, quote="")



> all.equal(tmp, tmp.in)
[1] TRUE



-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/8/14, 7:22 AM, "Neal H. Walfield" <neal at walfield.org> wrote:

>Hi,
>
>I'm using R version 3.1.1 on Debian via the CRAN repositories.
>
>Consider the following MWE that writes a data.frame out to a file and
>reads it back in (note that one of the strings contains a double
>quote):
>
>  > write.table(data.frame(a=1:3, b=c("a", "b\"b", "c")), '/tmp/a',
>row.names=FALSE, na="?", sep=",")
>  > read.table('/tmp/a', header=TRUE, row.names=NULL, sep=',',
>na.strings='?', allowEscapes=T)
>  [1] a b
>  <0 rows> (or 0-length row.names)
>
>/tmp/a contains the following:
>
>  $ cat /tmp/a 
>  "a","b"
>  1,"a"
>  2,"b\"b"
>  3,"c"
>
>Removing the double quote, it works:
>
>  > write.table(data.frame(a=1:3, b=c("a", "bb", "c")), '/tmp/a',
>row.names=FALSE, na="?", sep=",")
>  > read.table('/tmp/a', header=TRUE, row.names=NULL, sep=',',
>na.strings='?', allowEscapes=T)
>    a  b
>  1 1  a
>  2 2 bb
>  3 3  c
>
>Why does allowEscapes not work for double quotes?  Or, why does
>write.table produce a file that read.table can't read!
>
>Thanks for any advice!
>
>Neal
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Oct  8 18:35:55 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 8 Oct 2014 09:35:55 -0700
Subject: [R] Obtain a list of data tables from a main data table
In-Reply-To: <BAY168-W12804307508D3E75E8AFDF3BAA30@phx.gbl>
References: <BAY168-W12804307508D3E75E8AFDF3BAA30@phx.gbl>
Message-ID: <C7C6E170-4959-47CC-96EA-66AF06870A2C@comcast.net>


On Oct 8, 2014, at 8:06 AM, Frank S. wrote:

> 
> 
> Hi everybody,
> 
> 
> 
> I have (as an example) the following
> two data tables:
> 
> 
> 
> all <-
> data.table(ID = c(rep(c(100:105),c(3,2,2,3,3,3))),
> 
>     value =
> c(100,120,110,90,45,35,270,50,65,40,25,55,75,30,95,70))
> 
> DT <-
> data.table(ID = 100:105, code=c(2,1,3,2,3,1))
> 
> 
> 
> My aim is to construct as many sub data tables as different values for
> the integer variable code, and I have
> done:
> 
> code_1
> <- all[ID %in% DT[code==1]$ID] 
> 
> code_2
> <- all[ID %in% DT[code==2]$ID] 
> 
> code_3
> <- all[ID %in% DT[code==3]$ID] 
> 
> 
> 
> Because maximum code value can be very
> high, ?is it possible to obtain a list of the above 3 data tables through a
> loop? I mean something like:
> 
> 
> 
> for (i in
> 1:max(DT$code)){
> 
>  paste(code,?_?,[i]) <- }
> 
> return(list)]

Why not use lapply (since it is designed to return a list) and call the subset function in the data.table package?

> 
> 
> 
> Thank
> you very much to all the members!
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]

This is a plain text mailing list.

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From Stephen.Bond at cibc.com  Wed Oct  8 20:14:32 2014
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Wed, 8 Oct 2014 18:14:32 +0000
Subject: [R] lattice add a fit
In-Reply-To: <C14CE528-F86A-43FD-8849-1815DC6385ED@comcast.net>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
	<000001cfe2ae$7c1fa7f0$745ef7d0$@bigpond.com>
	<C14CE528-F86A-43FD-8849-1815DC6385ED@comcast.net>
Message-ID: <624EC9773CAB044ABA65327271BED9B60A8B43F0@CBMCC-X10-MA01.ad.cibc.com>

Folks,

This is just misunderstanding. I did not want a panel function for locfit. In my email I say:

 Instead, I want to put a fit from lm (but 
 not a simple straight line) and the fit has to be done for each panel 
 separately, not one fit for the full data set, so sth like an lm 
 equivalent of panel.locfit (there is no panel.lmfit) Thank you.

Bert Gunter provided the answer to my question. Maybe I should have sent a thank you note to the list to finalize.
Kind regards

Stephen Bond 


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Wednesday, October 08, 2014 12:30 PM
To: Duncan Mackay
Cc: R; Bond, Stephen
Subject: Re: [R] lattice add a fit


On Oct 7, 2014, at 9:15 PM, Duncan Mackay wrote:

I'm a tad puzzled by the comments about needing to build a panel function for locfit. The various plot.locfit functions are actually lattice calls. 

locfit:::panel.locfit  # already exists, and even has versions for 1d, 2d and 3d purposes.

And there is a llines.locfit function that will add locfit smooths to existing lattice plots.

It's a very simple function and could easily be modified to any regression method that has a predict functions:

> locfit:::llines.locfit
function (x, m = 100, tr = x$trans, ...) {
    newx <- lfmarg(x, m = m)[[1]]  # probably need to modify to your purposes
    y <- predict(x, newx, tr = tr)
    llines(newx, y, ...)
}
<environment: namespace:locfit>

--
David

> 
> You will have to make your own panel function for locfit if you want 
> to use it I have done it in the past - read the help for
> library(locfit)
> ?plot.locfit
> and the links
> ?lattice::prepanel
> 
> Regards
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science University of New England 
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Bond, Stephen
> Sent: Tuesday, 7 October 2014 23:02
> To: r-help at R-project.org
> Subject: [R] lattice add a fit
> 
> What is the way to add an arbitrary fit from a model to a lattice 
> conditioning plot ?
> 
> For example
> xyplot(v1 ~v2 | v3,data=mydata,
>        panel=function(...){
>            panel.xyplot(...)
>            panel.loess(...,col.line="red")
>        }
> )
> Will add a loess smoother. Instead, I want to put a fit from lm (but 
> not a simple straight line) and the fit has to be done for each panel 
> separately, not one fit for the full data set, so sth like an lm 
> equivalent of panel.locfit (there is no panel.lmfit) Thank you.
> 
> Stephen B
> 
> 
> 	[[alternative HTML version deleted]]
> 


David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Wed Oct  8 20:30:01 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 08 Oct 2014 12:30:01 -0600
Subject: [R] Data formart
In-Reply-To: <CAGh51gSP5SwyQtfrdAGLKbmDySih3eUqjRf1HfnXHzmx_EFtow@mail.gmail.com>
References: <CAGh51gSP5SwyQtfrdAGLKbmDySih3eUqjRf1HfnXHzmx_EFtow@mail.gmail.com>
Message-ID: <AFF2DB14-CADD-497D-AA8D-F11ADBD5D143@dcn.davis.CA.us>

This is like using the formula Area=3*r^2 for the area of a circle... you can figure out a way to do it but it is still wrong. Why not leave the data as day of year instead of misleading anyone who looks at it?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 8, 2014 7:36:37 AM MDT, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>Dear All,
>
>Change the format of the start and end columns so that data appear as
>the
>day of the year. For instance: Apr 24 rather than 115.
>
>The idea is that I want the non=leap years to be 366 days instead of
>being
>365 days. ie. Each year must have 366 days. for example: in the column
>Start2, Apr 18 will be Apr 17.
>
>> head(Samaru)
>  Year Start End Length Start2   End2
>1 1930   108 288    180 Apr 18 Oct 15
>2 1931   118 288    170 Apr 28 Oct 15
>3 1932   115 295    180 Apr 24 Oct 21
>4 1933   156 294    138 Jun 05 Oct 21
>5 1934   116 291    175 Apr 26 Oct 18
>6 1935   134 288    154 May 14 Oct 15
>
>Any idea is welcome. Thamks!!!!


From amos.elberg at gmail.com  Wed Oct  8 21:20:33 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Wed, 8 Oct 2014 15:20:33 -0400
Subject: [R] Data formart
In-Reply-To: <CAGh51gSP5SwyQtfrdAGLKbmDySih3eUqjRf1HfnXHzmx_EFtow@mail.gmail.com>
References: <CAGh51gSP5SwyQtfrdAGLKbmDySih3eUqjRf1HfnXHzmx_EFtow@mail.gmail.com>
Message-ID: <etPan.54358efc.5bd062c2.17f96@macpro.local>

You can adapt: ? format(as.Date(paste(Year, sep = "-", ifelse(Year %% 4 == 0, Start, ifelse(Start > 59, Start - 1, Start))), "%Y-%j"), "%b %d?)

But 60% of the dates in your data.frame will then be wrong. ?


From:?Frederic Ntirenganya <ntfredo at gmail.com>
Reply:?Frederic Ntirenganya <ntfredo at gmail.com>>
Date:?October 8, 2014 at 9:38:34 AM
To:?r-help at r-project.org <r-help at r-project.org>>
Subject:? [R] Data formart  

Dear All,  

Change the format of the start and end columns so that data appear as the  
day of the year. For instance: Apr 24 rather than 115.  

The idea is that I want the non=leap years to be 366 days instead of being  
365 days. ie. Each year must have 366 days. for example: in the column  
Start2, Apr 18 will be Apr 17.  

> head(Samaru)  
Year Start End Length Start2 End2  
1 1930 108 288 180 Apr 18 Oct 15  
2 1931 118 288 170 Apr 28 Oct 15  
3 1932 115 295 180 Apr 24 Oct 21  
4 1933 156 294 138 Jun 05 Oct 21  
5 1934 116 291 175 Apr 26 Oct 18  
6 1935 134 288 154 May 14 Oct 15  

Any idea is welcome. Thamks!!!!  
--  
Frederic Ntirenganya  
Maseno University,  
Kenya.  
Mobile:(+254)718492836  
Email: fredo at aims.ac.za  
https://sites.google.com/a/aims.ac.za/fredo/  

[[alternative HTML version deleted]]  

______________________________________________  
R-help at r-project.org mailing list  
https://stat.ethz.ch/mailman/listinfo/r-help  
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html  
and provide commented, minimal, self-contained, reproducible code.  

	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Wed Oct  8 10:29:26 2014
From: smartpink111 at yahoo.com (arun)
Date: Wed, 8 Oct 2014 08:29:26 +0000 (UTC)
Subject: [R] Generate sequence of date based on a group ID
In-Reply-To: <CAAC1QdBYVMW=2_Hpi0zSX6YR6SsJedP5Ef_76N9ffJRoMhOSrA@mail.gmail.com>
References: <CAAC1QdBYVMW=2_Hpi0zSX6YR6SsJedP5Ef_76N9ffJRoMhOSrA@mail.gmail.com>
Message-ID: <1560332463.831238.1412756966611.JavaMail.yahoo@jws106102.mail.bf1.yahoo.com>



If the `ids` are ordered as shown in the example, perhaps you need

   tbl <- table(df$id)
   
   rep(seq(as.Date("2000-01-01"), length.out=length(tbl), by=1), tbl)
    [1] "2000-01-01" "2000-01-01" "2000-01-01" "2000-01-01" "2000-01-01"
    [6] "2000-01-02" "2000-01-02" "2000-01-02" "2000-01-02" "2000-01-02"
    [11] "2000-01-03" "2000-01-03" "2000-01-03" "2000-01-03" "2000-01-03"
    [16] "2000-01-04" "2000-01-04" "2000-01-04" "2000-01-04" "2000-01-05"
    [21] "2000-01-05" "2000-01-05" "2000-01-05"

A.K.


On Wednesday, October 8, 2014 3:57 AM, Kuma Raj <pollaroid at gmail.com> wrote:



I want to generate a sequence of date based on a group id(similar IDs
should have same date). The id variable contains unequal observations
and the length of the data set also varies.  How could I create a
sequence that starts on specific date (say January 1, 2000 onwards)
and continues until the end without specifying length?


Sample data follows:

df<-structure(list(id = c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L,

3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 5L, 5L, 5L, 5L), out1 = c(0L,

0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L, 0L, 0L, 1L, 0L, 0L,

0L, 1L, 0L, 0L, 0L, 1L)), .Names = c("id", "out1"), class =
"data.frame", row.names = c(NA,

-23L))

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dieter at duenenhof-wilhelm.de  Wed Oct  8 11:53:47 2014
From: dieter at duenenhof-wilhelm.de (H. Dieter Wilhelm)
Date: Wed, 8 Oct 2014 11:53:47 +0200
Subject: [R] Evaluation of global variables in function definitions
References: <877g0cjs2g.fsf@vsl28t2g.ww011> <5433F0A9.1020505@gmail.com>
Message-ID: <87eguisx90.fsf@vsl28t2g.ww011>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

> On 07/10/2014 2:45 AM, H. Dieter Wilhelm wrote:
>> Hello (),
>>
>> I'd like to do the following
>>
>> a <- 3
>> f1 <- function (x){
>>   a*x^2
>> }
>>
>> a <- 5
>> f2 <- function (x){
>>   a*x^2
>> }
>>
>> plotting f1, f2, ...
>>
>> but f1 and f2 are the same, how can I evaluated the variables in the
>> function definition?
>>
>> Thank you
>>        Dieter
> See the "open.account" example in section 10.7, "Scope", of the
> Introduction to R manual.

Sorry but above section teaches my how to change global variables in
functions.  But I would like to overcome the "lazy evaluation" of global
variables in functions.  Because I can't put expensive computations into
each function.

a <- complicated_a_computation(args1)
b <- complicated_b_computation(args1)
c <- ...
d
...

f1 <- function(x) a*x+b*exp(x)+c/x+...

a <- complicated_a_computation(args2)
b <- complicated_b_computation(args2)
c <- ...
d
...

f2 <- function(x) a*x+b*exp(x)+c/x +...

Yes in principle I could rename the global variables to a1, a2, b1, b2,
...  But I'd like to learn the principles of R.  Is above somehow
possible with the use of the substitute() command?

Thanks
-- 
Best wishes
H. Dieter Wilhelm
Darmstadt, Germany


From mark.hogue at srs.gov  Wed Oct  8 13:02:36 2014
From: mark.hogue at srs.gov (mark.hogue at srs.gov)
Date: Wed, 8 Oct 2014 07:02:36 -0400
Subject: [R] reading in hexadecimal data - not working with data ending in E
Message-ID: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>

I am trying to read in data from an instrument that is recorded in 
hexadecimal format. Using either: 

    y.hex <- read.table(file="hex.data", as.is=TRUE) 

or 

    y.hex <- read.table(file="hex.data", text=TRUE) 

gets all the data in just fine except points like `055E` or `020E`. In 
these cases, the E is stripped so I get just 055 or 020. 

The question is how should this data be imported to avoid the E-ending 
problem? 

(By the way, my follow-up is to convert this data using, `y <- 
strtoi(y.hex, 16L)`) 

Thanks for any suggestions, 

Mark Hogue 
	[[alternative HTML version deleted]]


From wkreinen at gmail.com  Wed Oct  8 13:02:50 2014
From: wkreinen at gmail.com (Wim Kreinen)
Date: Wed, 8 Oct 2014 13:02:50 +0200
Subject: [R] glm - rgamma vector as predictor
Message-ID: <CAPFhJgZmCtYyhV3wDTK8b0F8gnyT0yQOPovVrgKP2tJ9Of1o2w@mail.gmail.com>

 I have a strange question concerning the fit of a Gamma generalized linear
model with glm (and further using gamma.shape to measure the shape
parameter).

Actually, I started with rgamma to generate some random vectors because I
wanted to play around with various conditions (and become familiar with
gamma shape). But before you can start with gamma shape you need to have a
glm object.

Assuming

gamma.random <- rgamma (1000,1.5)

is my random vector.

How do I create a glm object if I only have one vector? I guess, my random
vector is the predictor and the response is the probability (in the sense
of a pdf). Can anybody give me a hint how the syntax is?

glm (? ~ gamma.random, family=Gamma)

Thanks Wim

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Wed Oct  8 21:12:48 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 08 Oct 2014 15:12:48 -0400
Subject: [R] cbind in a loop...better way?
Message-ID: <54358CB0.6090506@gmail.com>

...or some such. I'm trying to work up a function wherein the user 
passes a list of matrices to the function, which then (1) takes each 
matrix, (2) performs an operation to 'vectorize' the matrix (i.e., given 
an (m x n) matrix x, this produces the vector Y of length  m*n that 
contains the columns of the matrix x, stacked below each other), and 
then (3) cbinds them together.

Here is an example using the case where I know how many matrices I need 
to cbind together. For this example, 2 square (3x3) matrices:

  a <- matrix(c,0,20,50,0.05,0,0,0,0.1,0),3,3,byrow=T)
  b <- matrix(c(0,15,45,0.15,0,0,0,0.2,0),3,3,byrow=T)

I want to vec them, and then cbind them together. So,

result  <- cbind(matrix(a,nr=9), matrix(b,nr=9))

which yields the following:

       [,1]  [,2]
  [1,]  0.00  0.00
  [2,]  0.05  0.15
  [3,]  0.00  0.00
  [4,] 20.00 15.00
  [5,]  0.00  0.00
  [6,]  0.10  0.20
  [7,] 50.00 45.00
  [8,]  0.00  0.00
  [9,]  0.00  0.00

Easy enough. But, I want to put it in a function, where the number and 
dimensions  of the matrices is not specified. Something like

Using matrices (a) and (b) from above, let

   env <- list(a,b).

Now, a function (or attempt at same) to perform the desired operations:

   vec=function(matlist) {

       n_mat=length(matlist);
       size_mat=dim(matlist[[1]])[1];

       result=cbind()

        for (i in 1:n_mat) {
          result=cbind(result,matrix(matlist[[i]],nr=size_mat^2))
                           }

      return(result)

    }


When I run vec(env), I get the *right answer*, but I am wondering if 
there is a *better* way to get there from here than the approach I use 
(above). I'm not so much interested in 'computational efficiency' as I 
am in stability, and flexibility.

Thanks...


From f_j_rod at hotmail.com  Wed Oct  8 21:46:30 2014
From: f_j_rod at hotmail.com (Frank S.)
Date: Wed, 8 Oct 2014 21:46:30 +0200
Subject: [R] Obtain a list of data tables from a main data table
In-Reply-To: <C7C6E170-4959-47CC-96EA-66AF06870A2C@comcast.net>
References: <BAY168-W12804307508D3E75E8AFDF3BAA30@phx.gbl>,
	<C7C6E170-4959-47CC-96EA-66AF06870A2C@comcast.net>
Message-ID: <BAY168-W740B207CC4189BA85813FCBAA30@phx.gbl>

Hi,
 
I think I got it!
 
The clue: Function split!
 		 	   		  
	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Oct  8 21:57:58 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 08 Oct 2014 15:57:58 -0400
Subject: [R] reading in hexadecimal data - not working with data ending
 in E
In-Reply-To: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>
References: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>
Message-ID: <54359746.6020204@gmail.com>

On 08/10/2014 7:02 AM, mark.hogue at srs.gov wrote:
> I am trying to read in data from an instrument that is recorded in
> hexadecimal format. Using either:
>
>      y.hex <- read.table(file="hex.data", as.is=TRUE)
>
> or
>
>      y.hex <- read.table(file="hex.data", text=TRUE)
>
> gets all the data in just fine except points like `055E` or `020E`. In
> these cases, the E is stripped so I get just 055 or 020.

You need to read the ?read.table help.  as.is and text don't do anything 
like what you want.

The argument you need to use is colClasses.  I think you want to set it 
to "character".

Duncan Murdoch
>
> The question is how should this data be imported to avoid the E-ending
> problem?
>
> (By the way, my follow-up is to convert this data using, `y <-
> strtoi(y.hex, 16L)`)
>
> Thanks for any suggestions,
>
> Mark Hogue
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Oct  8 21:58:15 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 8 Oct 2014 12:58:15 -0700
Subject: [R] reading in hexadecimal data - not working with data ending
	in E
In-Reply-To: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>
References: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>
Message-ID: <CAF8bMcbgJO963GLs7V6Kw3FaVGKs7i1v_vqQWEA5Uje173bHiA@mail.gmail.com>

I did not see a reproducible example, but you should use
colClasses="character" to
read in the data as character, then use something like as.hexmode() to
convert it to integers.  E.g.,

  > z <- read.table(text="ColA ColB\n1e 33\n2e  44\n10  5e\n",
header=TRUE, colClasses="character")
  > str(z)
  'data.frame':   3 obs. of  2 variables:
   $ ColA: chr  "1e" "2e" "10"
   $ ColB: chr  "33" "44" "5e"
  > z[] <- lapply(z, function(zi)as.integer(as.hexmode(zi)))
  > str(z)
  'data.frame':   3 obs. of  2 variables:
   $ ColA: int  30 46 16
   $ ColB: int  51 68 94

If you leave out the colClasses="character" then read.table will say
that all those
strings look like decimal numerals ("1e" being read as "1e+0", giving 1*10^0).


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 8, 2014 at 4:02 AM,  <mark.hogue at srs.gov> wrote:
> I am trying to read in data from an instrument that is recorded in
> hexadecimal format. Using either:
>
>     y.hex <- read.table(file="hex.data", as.is=TRUE)
>
> or
>
>     y.hex <- read.table(file="hex.data", text=TRUE)
>
> gets all the data in just fine except points like `055E` or `020E`. In
> these cases, the E is stripped so I get just 055 or 020.
>
> The question is how should this data be imported to avoid the E-ending
> problem?
>
> (By the way, my follow-up is to convert this data using, `y <-
> strtoi(y.hex, 16L)`)
>
> Thanks for any suggestions,
>
> Mark Hogue
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Wed Oct  8 22:02:10 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 8 Oct 2014 16:02:10 -0400
Subject: [R] Evaluation of global variables in function definitions
In-Reply-To: <87eguisx90.fsf@vsl28t2g.ww011>
References: <877g0cjs2g.fsf@vsl28t2g.ww011> <5433F0A9.1020505@gmail.com>
	<87eguisx90.fsf@vsl28t2g.ww011>
Message-ID: <54359842.8040804@gmail.com>

On 08/10/2014 5:53 AM, H. Dieter Wilhelm wrote:
> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
>
> > On 07/10/2014 2:45 AM, H. Dieter Wilhelm wrote:
> >> Hello (),
> >>
> >> I'd like to do the following
> >>
> >> a <- 3
> >> f1 <- function (x){
> >>   a*x^2
> >> }
> >>
> >> a <- 5
> >> f2 <- function (x){
> >>   a*x^2
> >> }
> >>
> >> plotting f1, f2, ...
> >>
> >> but f1 and f2 are the same, how can I evaluated the variables in the
> >> function definition?
> >>
> >> Thank you
> >>        Dieter
> > See the "open.account" example in section 10.7, "Scope", of the
> > Introduction to R manual.
>
> Sorry but above section teaches my how to change global variables in
> functions.

That's only part of what it tells you.  The open.account example binds 
values into the environment of the function.  That's what you want to 
do:  when you create f1, you want the values of a,b,c, etc. bound into 
its environment.  Then when you create f2, you want new values bound 
there.  So do it something like this:

makefun <- function(a,b,c,d) {
   force(a); force(b); force(c); force(d) # evaluate them now!
   function(x)  a*x+b*exp(x)+c/x+...
}

a <- complicated_a_computation(args1)
b <- complicated_b_computation(args1)
c <- ...
d
...

f1 <- makefun(a,b,c,d)

a <- complicated_a_computation(args2)
b <- complicated_b_computation(args2)
c <- ...
d
...

f2 <- makefun(a,b,c,d)

Duncan Murdoch

>   But I would like to overcome the "lazy evaluation" of global
> variables in functions.  Because I can't put expensive computations into
> each function.
>
> a <- complicated_a_computation(args1)
> b <- complicated_b_computation(args1)
> c <- ...
> d
> ...
>
> f1 <- function(x) a*x+b*exp(x)+c/x+...
>
> a <- complicated_a_computation(args2)
> b <- complicated_b_computation(args2)
> c <- ...
> d
> ...
>
> f2 <- function(x) a*x+b*exp(x)+c/x +...
>
> Yes in principle I could rename the global variables to a1, a2, b1, b2,
> ...  But I'd like to learn the principles of R.  Is above somehow
> possible with the use of the substitute() command?
>
> Thanks


From john.archie.mckown at gmail.com  Wed Oct  8 22:04:21 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 8 Oct 2014 15:04:21 -0500
Subject: [R] reading in hexadecimal data - not working with data ending
	in E
In-Reply-To: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>
References: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>
Message-ID: <CAAJSdjgMYjmUZTcQz8JRf5m89LT5E79yED014SXHhcn+tvwSFA@mail.gmail.com>

On Wed, Oct 8, 2014 at 6:02 AM, <mark.hogue at srs.gov> wrote:

> I am trying to read in data from an instrument that is recorded in
> hexadecimal format. Using either:
>
>     y.hex <- read.table(file="hex.data", as.is=TRUE)
>
> or
>
>     y.hex <- read.table(file="hex.data", text=TRUE)
>
> gets all the data in just fine except points like `055E` or `020E`. In
> these cases, the E is stripped so I get just 055 or 020.
>
> The question is how should this data be imported to avoid the E-ending
> problem?
>
> (By the way, my follow-up is to convert this data using, `y <-
> strtoi(y.hex, 16L)`)
>
> Thanks for any suggestions,
>

?Please don't post in HTML, it is against forum policy. And it often
results in poorly formatted messages, which many ignore.?

?Try:

y.hex <- read.table(file="hex.data",as.is=TRUE,colClasses="character");?



>
> Mark Hogue
>


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Wed Oct  8 22:06:21 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 8 Oct 2014 13:06:21 -0700
Subject: [R] Evaluation of global variables in function definitions
In-Reply-To: <87eguisx90.fsf@vsl28t2g.ww011>
References: <877g0cjs2g.fsf@vsl28t2g.ww011> <5433F0A9.1020505@gmail.com>
	<87eguisx90.fsf@vsl28t2g.ww011>
Message-ID: <CAF8bMcaJB+nQq=tWm+bGqrwF40HqCEJXmiF_3ZGtvdcgq5A6eA@mail.gmail.com>

fFactory <- function(args) {
    a <- complicated_a_computation(args)
    b <- complicated_b_computation(args)
    function(x) a*x + b*exp(x)
}
f1 <- fFactory(args1)
f2 <- fFactory(args2)

f1(x)
f2(x) # will get different result than f1(x)

f1 and f2 will look the same but produce different results because
environment(f1)
contains different values of a and b than environment(f2).

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 8, 2014 at 2:53 AM, H. Dieter Wilhelm
<dieter at duenenhof-wilhelm.de> wrote:
> Duncan Murdoch <murdoch.duncan at gmail.com> writes:
>
>> On 07/10/2014 2:45 AM, H. Dieter Wilhelm wrote:
>>> Hello (),
>>>
>>> I'd like to do the following
>>>
>>> a <- 3
>>> f1 <- function (x){
>>>   a*x^2
>>> }
>>>
>>> a <- 5
>>> f2 <- function (x){
>>>   a*x^2
>>> }
>>>
>>> plotting f1, f2, ...
>>>
>>> but f1 and f2 are the same, how can I evaluated the variables in the
>>> function definition?
>>>
>>> Thank you
>>>        Dieter
>> See the "open.account" example in section 10.7, "Scope", of the
>> Introduction to R manual.
>
> Sorry but above section teaches my how to change global variables in
> functions.  But I would like to overcome the "lazy evaluation" of global
> variables in functions.  Because I can't put expensive computations into
> each function.
>
> a <- complicated_a_computation(args1)
> b <- complicated_b_computation(args1)
> c <- ...
> d
> ...
>
> f1 <- function(x) a*x+b*exp(x)+c/x+...
>
> a <- complicated_a_computation(args2)
> b <- complicated_b_computation(args2)
> c <- ...
> d
> ...
>
> f2 <- function(x) a*x+b*exp(x)+c/x +...
>
> Yes in principle I could rename the global variables to a1, a2, b1, b2,
> ...  But I'd like to learn the principles of R.  Is above somehow
> possible with the use of the substitute() command?
>
> Thanks
> --
> Best wishes
> H. Dieter Wilhelm
> Darmstadt, Germany
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Wed Oct  8 22:17:30 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 8 Oct 2014 20:17:30 +0000
Subject: [R] cbind in a loop...better way?
In-Reply-To: <54358CB0.6090506@gmail.com>
References: <54358CB0.6090506@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9EA5D@mb02.ads.tamu.edu>

How about

> do.call(cbind, lapply(env, as.vector))
       [,1]  [,2]
 [1,]  0.00  0.00
 [2,]  0.05  0.15
 [3,]  0.00  0.00
 [4,] 20.00 15.00
 [5,]  0.00  0.00
 [6,]  0.10  0.20
 [7,] 50.00 45.00
 [8,]  0.00  0.00
 [9,]  0.00  0.00

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Evan Cooch
Sent: Wednesday, October 8, 2014 2:13 PM
To: r-help at r-project.org
Subject: [R] cbind in a loop...better way?

...or some such. I'm trying to work up a function wherein the user 
passes a list of matrices to the function, which then (1) takes each 
matrix, (2) performs an operation to 'vectorize' the matrix (i.e., given 
an (m x n) matrix x, this produces the vector Y of length  m*n that 
contains the columns of the matrix x, stacked below each other), and 
then (3) cbinds them together.

Here is an example using the case where I know how many matrices I need 
to cbind together. For this example, 2 square (3x3) matrices:

  a <- matrix(c,0,20,50,0.05,0,0,0,0.1,0),3,3,byrow=T)
  b <- matrix(c(0,15,45,0.15,0,0,0,0.2,0),3,3,byrow=T)

I want to vec them, and then cbind them together. So,

result  <- cbind(matrix(a,nr=9), matrix(b,nr=9))

which yields the following:

       [,1]  [,2]
  [1,]  0.00  0.00
  [2,]  0.05  0.15
  [3,]  0.00  0.00
  [4,] 20.00 15.00
  [5,]  0.00  0.00
  [6,]  0.10  0.20
  [7,] 50.00 45.00
  [8,]  0.00  0.00
  [9,]  0.00  0.00

Easy enough. But, I want to put it in a function, where the number and 
dimensions  of the matrices is not specified. Something like

Using matrices (a) and (b) from above, let

   env <- list(a,b).

Now, a function (or attempt at same) to perform the desired operations:

   vec=function(matlist) {

       n_mat=length(matlist);
       size_mat=dim(matlist[[1]])[1];

       result=cbind()

        for (i in 1:n_mat) {
          result=cbind(result,matrix(matlist[[i]],nr=size_mat^2))
                           }

      return(result)

    }


When I run vec(env), I get the *right answer*, but I am wondering if 
there is a *better* way to get there from here than the approach I use 
(above). I'm not so much interested in 'computational efficiency' as I 
am in stability, and flexibility.

Thanks...

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Wed Oct  8 22:24:55 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 8 Oct 2014 20:24:55 +0000
Subject: [R] glm - rgamma vector as predictor
References: <CAPFhJgZmCtYyhV3wDTK8b0F8gnyT0yQOPovVrgKP2tJ9Of1o2w@mail.gmail.com>
Message-ID: <loom.20141008T222328-405@post.gmane.org>

Wim Kreinen <wkreinen <at> gmail.com> writes:

>

[snip]

> 
> Actually, I started with rgamma to generate some random vectors because I
> wanted to play around with various conditions (and become familiar with
> gamma shape). But before you can start with gamma shape you need to have a
> glm object.
> 
> Assuming
> 
> gamma.random <- rgamma (1000,1.5)
> 
> is my random vector.
> 
> How do I create a glm object if I only have one vector? I guess, my random
> vector is the predictor and the response is the probability (in the sense
> of a pdf). Can anybody give me a hint how the syntax is?

 [snip]

I think you're looking for

  MASS::gamma.shape(glm(gamma.random ~ 1, family=Gamma))


From tofeealany at yahoo.com  Wed Oct  8 21:47:44 2014
From: tofeealany at yahoo.com (Midea Algaf)
Date: Wed, 8 Oct 2014 21:47:44 +0200
Subject: [R] ADF test
Message-ID: <B6B7D821-1342-427E-8899-F9B58199F1DD@yahoo.com>

Hi 
I need to know how can I do dicky-fuller test in R
Regards
Mideast

???? ???? ??? iPad ????? ???
	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Oct  8 23:29:26 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 08 Oct 2014 22:29:26 +0100
Subject: [R] ADF test
In-Reply-To: <B6B7D821-1342-427E-8899-F9B58199F1DD@yahoo.com>
References: <B6B7D821-1342-427E-8899-F9B58199F1DD@yahoo.com>
Message-ID: <5435ACB6.8020103@sapo.pt>

Hello,

Try package tseries, function adf.test().

Hope this helps,

Rui Barradas

Em 08-10-2014 20:47, Midea Algaf escreveu:
> Hi
> I need to know how can I do dicky-fuller test in R
> Regards
> Mideast
>
> ???? ???? ??? iPad ????? ???
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dulcalma at bigpond.com  Thu Oct  9 01:09:51 2014
From: dulcalma at bigpond.com (Duncan Mackay)
Date: Thu, 9 Oct 2014 09:09:51 +1000
Subject: [R] lattice add a fit
In-Reply-To: <624EC9773CAB044ABA65327271BED9B60A8B43F0@CBMCC-X10-MA01.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B60A8B41E9@CBMCC-X10-MA01.ad.cibc.com>
	<000001cfe2ae$7c1fa7f0$745ef7d0$@bigpond.com>
	<C14CE528-F86A-43FD-8849-1815DC6385ED@comcast.net>
	<624EC9773CAB044ABA65327271BED9B60A8B43F0@CBMCC-X10-MA01.ad.cibc.com>
Message-ID: <000f01cfe34c$f7435b40$e5ca11c0$@bigpond.com>

Hi

Then try

xyplot(... , type = c("p","r"))

Have a look at

? lattice::panel.xyplot for full type explanation 

I cannot remember what Bert wrote. Your mention of smoothers and locfit can
be quite a different story 

Duncan



-----Original Message-----
From: Bond, Stephen [mailto:Stephen.Bond at cibc.com] 
Sent: Thursday, 9 October 2014 04:15
To: David Winsemius; Duncan Mackay
Cc: R
Subject: RE: [R] lattice add a fit

Folks,

This is just misunderstanding. I did not want a panel function for locfit.
In my email I say:

 Instead, I want to put a fit from lm (but 
 not a simple straight line) and the fit has to be done for each panel 
 separately, not one fit for the full data set, so sth like an lm 
 equivalent of panel.locfit (there is no panel.lmfit) Thank you.

Bert Gunter provided the answer to my question. Maybe I should have sent a
thank you note to the list to finalize.
Kind regards

Stephen Bond 


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Wednesday, October 08, 2014 12:30 PM
To: Duncan Mackay
Cc: R; Bond, Stephen
Subject: Re: [R] lattice add a fit


On Oct 7, 2014, at 9:15 PM, Duncan Mackay wrote:

I'm a tad puzzled by the comments about needing to build a panel function
for locfit. The various plot.locfit functions are actually lattice calls. 

locfit:::panel.locfit  # already exists, and even has versions for 1d, 2d
and 3d purposes.

And there is a llines.locfit function that will add locfit smooths to
existing lattice plots.

It's a very simple function and could easily be modified to any regression
method that has a predict functions:

> locfit:::llines.locfit
function (x, m = 100, tr = x$trans, ...) {
    newx <- lfmarg(x, m = m)[[1]]  # probably need to modify to your
purposes
    y <- predict(x, newx, tr = tr)
    llines(newx, y, ...)
}
<environment: namespace:locfit>

--
David

> 
> You will have to make your own panel function for locfit if you want 
> to use it I have done it in the past - read the help for
> library(locfit)
> ?plot.locfit
> and the links
> ?lattice::prepanel
> 
> Regards
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science University of New England 
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Bond, Stephen
> Sent: Tuesday, 7 October 2014 23:02
> To: r-help at R-project.org
> Subject: [R] lattice add a fit
> 
> What is the way to add an arbitrary fit from a model to a lattice 
> conditioning plot ?
> 
> For example
> xyplot(v1 ~v2 | v3,data=mydata,
>        panel=function(...){
>            panel.xyplot(...)
>            panel.loess(...,col.line="red")
>        }
> )
> Will add a loess smoother. Instead, I want to put a fit from lm (but 
> not a simple straight line) and the fit has to be done for each panel 
> separately, not one fit for the full data set, so sth like an lm 
> equivalent of panel.locfit (there is no panel.lmfit) Thank you.
> 
> Stephen B
> 
> 
> 	[[alternative HTML version deleted]]
> 


David Winsemius
Alameda, CA, USA


From paul at stat.auckland.ac.nz  Thu Oct  9 04:16:29 2014
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Thu, 09 Oct 2014 15:16:29 +1300
Subject: [R] par("plt") behaving inconsistely? bug?
In-Reply-To: <CA+YV+HyqpfNO2U7ako1rcy9WT_DUi2WvQvsEFpMW_7cEdd=Nxg@mail.gmail.com>
References: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>	<CAFEqCdxM5vz-2MCeNTNmreugXvST43jpypmknX63dpgD_amB8A@mail.gmail.com>
	<CA+YV+HyqpfNO2U7ako1rcy9WT_DUi2WvQvsEFpMW_7cEdd=Nxg@mail.gmail.com>
Message-ID: <5435EFFD.8080103@stat.auckland.ac.nz>

Hi

The canonical poison is this ...

par(plt)
plot.new()
...
par(plt)
par(new=TRUE)
plot.new()
...
par(plt)
par(new=TRUE)
plot.new()

The idea is to set up parameters that control the placement of a plot, 
e.g., par(plt), and then start a plot, with plot.new().  If you want 
more than one plot on a page (and par(mfrow) does not suffice) then you 
set up new placement parameters, tell R not to start a new page, with 
par(new=TRUE), then start another plot, with plot.new().

Your code does not follow the "spirit" of the R graphics model because 
it starts a plot with one set of placement parameters and then changes 
those placement parameters several times within the same plot (instead 
of starting a new plot for each new set of placement parameters).

I had a look at the C code that leads to your "surprising" result and 
there is at least one infelicity in there, but I could not see a simple 
fix that would make your example "work" without a high risk of breaking 
other things.  So I'm afraid my best advice is to change your code to 
work with the graphics system.

The layout() function might provide a less unpleasant approach to having 
more than one plot region on the page, depending on how complex your 
arrangement of plot regions is.

Another alternative is to use the 'grid' graphics package, which is 
designed to allow for the flexible creation of multiple regions, 
depending on what you want to draw in each of those regions.

Paul

On 10/07/14 15:33, Murat Tasan wrote:
> 6. iteratively downgrade to earlier versions of R until it's working
> again... then try to diff out the offending source code change.
> i can try this, but i probably won't get to it for at least a few weeks :-/
>
> in the meantime, i'm tacking on box(lty = 0) to every par(plt = ...) call, e.g.
>> par("plt" = some_plt_coordinates); box(lty = 0)
>
> in the short term, this works.
> clip(...), a combination of par("new" = TRUE); plot.new(), and a whole
> bunch of other kludges work, too... pick your poison :-)
>
> cheers and thanks!
>
> -murat
>
> On Mon, Oct 6, 2014 at 2:08 PM, Greg Snow <538280 at gmail.com> wrote:
>> I believe that what is happening is that the clipping region is being
>> reset when you call box, but not when you call rect.  If you insert
>> the command "par(xpd=NA)" (or TRUE instead of NA) after the plot.new
>> and use the rect commands then you can see both rectangles (because
>> this turns the clipping off).  Working with the clipping region
>> (indirectly in your case) is complex since some functions properly
>> reset the region and others do not (and  making the others
>> automatically reset it may cause other problems when they reset a
>> clipping region that should not be reset).
>>
>> So the options are:
>>
>> 1 dive into the source code enough to figure out if fixing rect to
>> work with the clipping region is simple or not and submitting a patch
>> 2 wait for Prof Brian Ripley to notice this fact and do the above (he
>> has fixed a couple of other functions when made aware)
>> 3 use par(xpd=TRUE) (or NA) to not clip to the plotting region (this
>> is simple, but will allow things to be drawn outside of the plotting
>> region, on simple example is using abline)
>> 4 use a function that properly sets the clipping region (such as box)
>> before plotting anything else
>> 5 call clip(0,1,0,1) (or with the actual user coordinates) to manually
>> set the clipping region
>> 6 other?
>>
>>
>> On Mon, Oct 6, 2014 at 12:00 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>> Hi all -- I just encountered a behavior that I believe has changed
>>> from previous versions, though I haven't chased back the last version
>>> that behaves as my existing code expects quite yet.
>>> Perhaps this is a bug, though perhaps I'm missing a subtle detail
>>> somewhere in the documentation...
>>>
>>> Here's some code that works as expected (in R 3.1.1):
>>>
>>> ########################################
>>> pdf()
>>> plot.new()
>>>
>>> original_plt <- par("plt")
>>>
>>> plt_1 <- c(original_plt[1],
>>>             original_plt[1] + (original_plt[2] - original_plt[1]) / 2,
>>>             original_plt[3],
>>>             original_plt[3] + (original_plt[4] - original_plt[3]) / 2)
>>> par("plt" = plt_1)
>>> plot.window(xlim = c(0, 1), ylim = c(0, 1))
>>> box()
>>> plt_2 <- c(plt_1[2],
>>>             original_plt[2],
>>>             plt_1[4],
>>>             original_plt[4])
>>> par("plt" = plt_2)
>>> plot.window(xlim = c(0, 1), ylim = c(0, 1))
>>> box()
>>> par("plt" = original_plt)
>>> box(lty = 2)
>>> dev.off()
>>> ########################################
>>>
>>> This will draw 3 boxes... one in the lower left corner (specified by
>>> plt_1), one in the top right corner (specified by plt_2), and one
>>> dotted box around the full plot box (original_plt).
>>>
>>> Now, if you replace the first two box() calls by: rect(0, 0, 1, 1),
>>> only the lower-left rectangle is drawn.
>>> If you _add_ rect(0, 0, 1, 1) after each box() call, all boxes and
>>> rectangles are correctly drawn.
>>>
>>> It seems that after setting plt once, subsequent plt alterations put
>>> the device into a state that will permits drawing of _some_ things
>>> (e.g. box()), but not other things (e.g. rect, lines, points).
>>>
>>> A kludge to fix this is to call box(col = "white")... but that's quite
>>> the kludge, indeed!
>>> Axis() works just like box(), too... but I haven't exhausted which
>>> drawing functions work and which don't.
>>>
>>> I'd classify this is a bug, but I thought I'd check here first.
>>> I've also only checked this so far with the pdf() device, so I don't
>>> know if it is somehow device-specific.
>>>
>>> I detected this because some existing code (that worked on some
>>> earlier version of R, sorry that I don't know which one yet...) has
>>> suddenly stopped working!
>>>
>>> Cheers!
>>>
>>> -murat
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From evan.cooch at gmail.com  Thu Oct  9 03:16:46 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Wed, 08 Oct 2014 21:16:46 -0400
Subject: [R] cbind in a loop...better way?
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9EA5D@mb02.ads.tamu.edu>
References: <54358CB0.6090506@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9EA5D@mb02.ads.tamu.edu>
Message-ID: <5435E1FE.3030308@gmail.com>

That works as well. I'll collate your response and a couple of others, 
and post tomorrow.

On 10/8/2014 4:17 PM, David L Carlson wrote:
> How about
>
>> do.call(cbind, lapply(env, as.vector))
>         [,1]  [,2]
>   [1,]  0.00  0.00
>   [2,]  0.05  0.15
>   [3,]  0.00  0.00
>   [4,] 20.00 15.00
>   [5,]  0.00  0.00
>   [6,]  0.10  0.20
>   [7,] 50.00 45.00
>   [8,]  0.00  0.00
>   [9,]  0.00  0.00
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Evan Cooch
> Sent: Wednesday, October 8, 2014 2:13 PM
> To: r-help at r-project.org
> Subject: [R] cbind in a loop...better way?
>
> ...or some such. I'm trying to work up a function wherein the user
> passes a list of matrices to the function, which then (1) takes each
> matrix, (2) performs an operation to 'vectorize' the matrix (i.e., given
> an (m x n) matrix x, this produces the vector Y of length  m*n that
> contains the columns of the matrix x, stacked below each other), and
> then (3) cbinds them together.
>
> Here is an example using the case where I know how many matrices I need
> to cbind together. For this example, 2 square (3x3) matrices:
>
>    a <- matrix(c,0,20,50,0.05,0,0,0,0.1,0),3,3,byrow=T)
>    b <- matrix(c(0,15,45,0.15,0,0,0,0.2,0),3,3,byrow=T)
>
> I want to vec them, and then cbind them together. So,
>
> result  <- cbind(matrix(a,nr=9), matrix(b,nr=9))
>
> which yields the following:
>
>         [,1]  [,2]
>    [1,]  0.00  0.00
>    [2,]  0.05  0.15
>    [3,]  0.00  0.00
>    [4,] 20.00 15.00
>    [5,]  0.00  0.00
>    [6,]  0.10  0.20
>    [7,] 50.00 45.00
>    [8,]  0.00  0.00
>    [9,]  0.00  0.00
>
> Easy enough. But, I want to put it in a function, where the number and
> dimensions  of the matrices is not specified. Something like
>
> Using matrices (a) and (b) from above, let
>
>     env <- list(a,b).
>
> Now, a function (or attempt at same) to perform the desired operations:
>
>     vec=function(matlist) {
>
>         n_mat=length(matlist);
>         size_mat=dim(matlist[[1]])[1];
>
>         result=cbind()
>
>          for (i in 1:n_mat) {
>            result=cbind(result,matrix(matlist[[i]],nr=size_mat^2))
>                             }
>
>        return(result)
>
>      }
>
>
> When I run vec(env), I get the *right answer*, but I am wondering if
> there is a *better* way to get there from here than the approach I use
> (above). I'm not so much interested in 'computational efficiency' as I
> am in stability, and flexibility.
>
> Thanks...
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


	[[alternative HTML version deleted]]


From timhesterberg at gmail.com  Thu Oct  9 08:14:55 2014
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Wed, 8 Oct 2014 23:14:55 -0700
Subject: [R] How can I overwrite a method in R?
Message-ID: <CAAWNEwZNPp1P4_brEbsEHVQZf+tc7zDGMGvbTKgiG6mMdQno5A@mail.gmail.com>

How can I create an improved version of a method in R, and have it be used?

Short version:
I think plot.histogram has a bug, and I'd like to try a version with a fix.
But when I call hist(), my fixed version doesn't get used.

Long version:
hist() calls plot() which calls plot.histogram() which fails to pass ...
when it calls plot.window().
As a result hist() ignores xaxs and yaxs arguments.
I'd like to make my own copy of plot.histogram that passes ... to
plot.window().

If I just make my own copy of plot.histogram, plot() ignores it, because my
version is not part of the same graphics package that plot belongs to.

If I copy hist, hist.default and plot, the copies inherit the same
environments as
the originals, and behave the same.

If I also change the environment of each to .GlobalEnv, hist.default fails
in
a .Call because it cannot find C_BinCount.

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Thu Oct  9 09:10:07 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 9 Oct 2014 10:10:07 +0300
Subject: [R] Data formart
In-Reply-To: <etPan.54358efc.5bd062c2.17f96@macpro.local>
References: <CAGh51gSP5SwyQtfrdAGLKbmDySih3eUqjRf1HfnXHzmx_EFtow@mail.gmail.com>
	<etPan.54358efc.5bd062c2.17f96@macpro.local>
Message-ID: <CAGh51gTh=E9BzxsAWCg3TNs+F=FQz_xutQ045e3QLVzGVKKVgw@mail.gmail.com>

Hi Amos,

This approach gives a column of NA.

On Wed, Oct 8, 2014 at 10:20 PM, Amos B. Elberg <amos.elberg at gmail.com>
wrote:

> You can adapt:   format(as.Date(paste(Year, sep = "-", ifelse(Year %% 4 ==
> 0, Start, ifelse(Start > 59, Start - 1, Start))), "%Y-%j"), "%b %d?)
>
> But 60% of the dates in your data.frame will then be wrong.
>
>
> From: Frederic Ntirenganya <ntfredo at gmail.com> <ntfredo at gmail.com>
> Reply: Frederic Ntirenganya <ntfredo at gmail.com>> <ntfredo at gmail.com>
> Date: October 8, 2014 at 9:38:34 AM
> To: r-help at r-project.org <r-help at r-project.org>> <r-help at r-project.org>
> Subject:  [R] Data formart
>
> Dear All,
>
> Change the format of the start and end columns so that data appear as the
> day of the year. For instance: Apr 24 rather than 115.
>
> The idea is that I want the non=leap years to be 366 days instead of being
> 365 days. ie. Each year must have 366 days. for example: in the column
> Start2, Apr 18 will be Apr 17.
>
> > head(Samaru)
> Year Start End Length Start2 End2
> 1 1930 108 288 180 Apr 18 Oct 15
> 2 1931 118 288 170 Apr 28 Oct 15
> 3 1932 115 295 180 Apr 24 Oct 21
> 4 1933 156 294 138 Jun 05 Oct 21
> 5 1934 116 291 175 Apr 26 Oct 18
> 6 1935 134 288 154 May 14 Oct 15
>
> Any idea is welcome. Thamks!!!!
> --
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Thu Oct  9 09:43:38 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 9 Oct 2014 07:43:38 +0000
Subject: [R] Identifying Values in Dataframe
In-Reply-To: <CAB9UfhSQzMCM17Qzx4wawd=4KOD1vpniRQNf=AX5mG5oCenqaA@mail.gmail.com>
References: <CAB9UfhR0YsuAGBEEqW4f9C_DpJj+mdYKujUX3v23jnMAh_PPhQ@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE8E7C@SRVEXCHMBX.precheza.cz>
	<CAB9UfhSQzMCM17Qzx4wawd=4KOD1vpniRQNf=AX5mG5oCenqaA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE9742@SRVEXCHMBX.precheza.cz>

Hi

Hm. You get row and column number by which. So if you want names why not just use rownames or colnames.

Something like
rownames(data)[sel[,1]]
colnames(data)[sel[,2]]

shal give you appropriate row and column names.

Regards
Petr

From: Patzelt, Edward [mailto:patzelt at g.harvard.edu]
Sent: Monday, October 06, 2014 9:25 PM
To: PIKAL Petr
Cc: R-help at r-project.org
Subject: Re: [R] Identifying Values in Dataframe

Thanks Pikal -

I'd like to actually get the names of the variables for those indices both above and below .3/-.3 with the intention of generating a grid of scatterplots (which I will use ggplot2 for).

I played around with your code but can't seem to get the indice names.

Best,

Edward

On Fri, Oct 3, 2014 at 2:59 AM, PIKAL Petr <petr.pikal at precheza.cz<mailto:petr.pikal at precheza.cz>> wrote:
Hi

maybe

which(abs(data)>0.3, arr.ind=T)
                                     row col
Loss_EV_Amygdala_SF_left_hemisphere   15   2
Loss_EV_Amygdala_SF_left_hemisphere   15   3
Loss_PE_Amygdala_SF_right_hemisphere   5   7
Loss_PE_Amygdala_SF_left_hemisphere   13   9

Gives you what you want.

> sel<-which(abs(data)>0.3, arr.ind=T)
> data[sel]
[1] 0.3268234 0.3451718 0.3116239 0.3316836

Regards.
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-<mailto:r-help-bounces at r->
> project.org<http://project.org>] On Behalf Of Patzelt, Edward
> Sent: Thursday, October 02, 2014 10:18 PM
> To: R-help at r-project.org<mailto:R-help at r-project.org>
> Subject: [R] Identifying Values in Dataframe
>
> R Help -
>
> I'd like to identify each correlation value in the dataframe below
> above/below .3/-.3 in order to graph the original data points. I've
> started
> with the call below to identify each value by it's row and column. I'd
> like
> to form a data object that identifies each set of variables that meet
> the
> criteria and then use that to graph the original data.
>
> *do.call(cbind, lapply(list(row = row(data, T), col = col(data, T),
> value =
> data), as.character))*
> structure(c(-0.0228976615669603, 0.0228976615669603,
> 0.0345568787488209,
> -0.0345568787488209, 0.0704941162950863, 0.0501672252097525,
> 0.119766411337358, 0.0697823742392512, 0.0223273454311378,
> -0.0223273454311378,
> 0.125952482472234, -0.125952482472234, -0.0748856339421511,
> -0.0353553864437216,
> 0.199331873910442, -0.068756564596986, 0.0188033303819659,
> -0.0188033303819659,
> 0.124483870344689, -0.124483870344689, 0.158304442010968,
> -0.158304442010968,
> -0.00291892981576431, 0.00291892981576431, 0.289784855159971,
> 0.197017018634618, 0.0725645607308865, 0.0960039687045857,
> 0.145044311433109,
> -0.145044311433109, 0.228975321916426, -0.228975321916426,
> 0.26388395000877,
> 0.175954114053622, 0.326823414986536, 0.0464304517962428,
> 0.171060413427109,
> -0.171060413427109, 0.125608489395663, -0.125608489395663,
> 0.170699125959079,
> -0.170699125959079, -0.0537588992684595, 0.0537588992684595,
> 0.237938136557008, 0.130101348701669, 0.0420659299644508,
> 0.140016889896702,
> 0.175781963301805, -0.175781963301805, 0.277913325677977,
> -0.277913325677977,
> 0.250436246834054, 0.149310941080417, 0.345171759606147,
> 0.0499822279379925,
> 0.180291553611261, -0.180291553611261, 0.0983047617452837,
> -0.0983047617452837,
> 0.0908629320478729, -0.0908629320478729, 0.0162624158794471,
> -0.0162624158794471, 0.219099271324641, 0.143898328556892,
> 0.0808498509449568,
> 0.0534039458771934, 0.103639895676339, -0.103639895676339,
> 0.224298317217259,
> -0.224298317217259, 0.13939241528796, 0.0923125296440915,
> 0.2952647762031,
> -0.0573156158960486, 0.126972946909388, -0.126972946909388,
> 0.145176640269481,
> -0.145176640269481, 0.176722440639515, -0.176722440639515,
> -0.110517827771672,
> 0.110517827771672, 0.265161677824653, 0.0349452421080511,
> -0.00586032680446085,
> 0.17140674405117, -0.0141919172668973, 0.0141919172668973,
> 0.0416754535115447,
> -0.0416754535115447, 0.110687511145091, 0.163199987771469,
> 0.174846924599677,
> 0.116657756754811, 0.184924363876472, -0.184924363876472,
> 0.0740138506321435,
> -0.0740138506321435, 0.0653341995281647, -0.0653341995281647,
> 0.101098966521841, -0.101098966521841, -0.0263969055123976,
> -0.129660641707532,
> 0.16313101271814, -0.0000382052406584783, 0.118309823316179,
> -0.118309823316179, 0.0408519777835592, -0.0408519777835592,
> -0.15406959482671, -0.274340973979869, 0.1465995621482,
> -0.0608360452726588,
> -0.00570057335076342, 0.00570057335076342, 0.0988132735291764,
> -0.0988132735291764, 0.159498629897594, -0.159498629897594,
> -0.0258437210789338,
> 0.0258437210789338, 0.311623918577701, 0.0959243386674064,
> 0.0373444291324758,
> 0.131601179184854, 0.0032064022008327, -0.0032064022008327,
> 0.0126042917937794,
> -0.0126042917937794, 0.0288999352531186, 0.0343919995425096,
> 0.0375647873892517, 0.0734866249695526, 0.125835994106989,
> -0.125835994106989,
> 0.0557071876372764, -0.0557071876372764, 0.0190687287223345,
> -0.0190687287223345, 0.0301326072710063, -0.0301326072710063,
> 0.0881640884608706, 0.0600194980037123, 0.0948090975231923,
> 0.0259282757599189,
> 0.120417132810781, -0.120417132810781, 0.196695581235906,
> -0.196695581235906,
> 0.166210300278382, 0.0252645245285897, 0.239953962041662,
> -0.013933692494363,
> 0.0174600644363753, -0.0174600644363753, 0.169008089964054,
> -0.169008089964054,
> 0.0503612778194372, -0.0503612778194372, 0.175816302924921,
> -0.175816302924921,
> 0.141434785651191, 0.0824019401386654, 0.173429908437586,
> -0.136795834367563,
> 0.219543981806626, -0.219543981806626, 0.290697487363267,
> -0.290697487363267,
> 0.331683649439792, -0.0035319780591347, 0.237371764540467,
> -0.172828690804139,
> 0.00922163769628213, -0.00922163769628213, 0.275507919516733,
> -0.275507919516733, 0.128267529853407, -0.128267529853407,
> -0.16619622911667,
> 0.16619622911667, 0.102467428865746, -0.115779804556684,
> 0.000997318666924614,
> 0.297139396802529, 0.040957786791642, -0.040957786791642,
> -0.0160650315621922,
> 0.0160650315621922, -0.043765426943726, -0.0637020898937285,
> 0.142863591010818, 0.214059283535989, 0.13975223034564, -
> 0.13975223034564,
> -0.0286586386843802, 0.0286586386843802, 0.13735028629468,
> -0.13735028629468,
> -0.147016933653806, 0.147016933653806, 0.174438743129307,
> -0.0116564727226121,
> -0.0413775943824046, 0.136551598575573, 0.0614942508131549,
> -0.0614942508131549,
> 0.0687487372508148, -0.0687487372508148, -0.0352587211103196,
> -0.0872464182568976, 0.162247767446472, 0.0282617081917608,
> 0.175608445537029,
> -0.175608445537029, -0.0339260764991994, 0.0339260764991994,
> 0.130002432167221, -0.130002432167221, -0.141752408742242,
> 0.141752408742242,
> 0.126603115520512, -0.0784556105378803, -0.0736773348350251,
> 0.154815164010555, -0.102200077602115, 0.102200077602115,
> -0.137144378194025,
> 0.137144378194025, 0.0132012835622079, 0.113105077279414,
> -0.0412435172396771,
> 0.182836991911806, 0.109656132908221, -0.109656132908221,
> -0.0341578533716874,
> 0.0341578533716874, -0.0155952702450936, 0.0155952702450936,
> 0.0962494517693934, -0.0962494517693934, 0.0745517006304259,
> 0.145954619132309, 0.0997683764233029, -0.0562240100001912,
> 0.13254524166143,
> -0.13254524166143, 0.236418162977751, -0.236418162977751,
> 0.0878486801199713,
> -0.00445794916320147, 0.227619583487885, -0.14911359391431,
> 0.0214260010937822,
> -0.0214260010937822, 0.120246543167583, -0.120246543167583), .Dim =
> c(20L,
> 13L), .Dimnames = list(c("Loss_Gain_PE_Amygdala_SF_right_hemisphere",
> "Gain_Loss_PE_Amygdala_SF_right_hemisphere",
> "Loss_Gain_EV_Amygdala_SF_right_hemisphere",
> "Gain_Loss_EV_Amygdala_SF_right_hemisphere",
> "Loss_PE_Amygdala_SF_right_hemisphere",
> "Gain_PE_Amygdala_SF_right_hemisphere",
> "Loss_EV_Amygdala_SF_right_hemisphere",
> "Gain_EV_Amygdala_SF_right_hemisphere",
> "Loss_Gain_PE_Amygdala_SF_left_hemisphere",
> "Gain_Loss_PE_Amygdala_SF_left_hemisphere",
> "Loss_Gain_EV_Amygdala_SF_left_hemisphere",
> "Gain_Loss_EV_Amygdala_SF_left_hemisphere",
> "Loss_PE_Amygdala_SF_left_hemisphere",
> "Gain_PE_Amygdala_SF_left_hemisphere",
> "Loss_EV_Amygdala_SF_left_hemisphere",
> "Gain_EV_Amygdala_SF_left_hemisphere",
> "Loss_Gain_PE_Amygdala_LB_right_hemisphere",
> "Gain_Loss_PE_Amygdala_LB_right_hemisphere",
> "Loss_Gain_EV_Amygdala_LB_right_hemisphere",
> "Gain_Loss_EV_Amygdala_LB_right_hemisphere"), c("hare2f1", "hare2f2",
> "hare4", "hare", "ext_t", "total_barrat_11_imputed", "mcq_k",
> "ppitots", "ppi_1_corrected", "ppi_2_corrected", "total_buss_perry",
> "hareResidNetExt", "extResidNetHare")))
>
> --
>
> *Edward H Patzelt | Clinical Science PhD StudentPsychology | Harvard
> University SNPLab http://scholar.harvard.edu/buckholtz
> <http://scholar.harvard.edu/buckholtz>*
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________



________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From amos.elberg at gmail.com  Thu Oct  9 09:49:42 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Thu, 9 Oct 2014 03:49:42 -0400
Subject: [R] Data formart
In-Reply-To: <CAGh51gTh=E9BzxsAWCg3TNs+F=FQz_xutQ045e3QLVzGVKKVgw@mail.gmail.com>
References: <CAGh51gSP5SwyQtfrdAGLKbmDySih3eUqjRf1HfnXHzmx_EFtow@mail.gmail.com>
	<etPan.54358efc.5bd062c2.17f96@macpro.local>
	<CAGh51gTh=E9BzxsAWCg3TNs+F=FQz_xutQ045e3QLVzGVKKVgw@mail.gmail.com>
Message-ID: <902C47AE-94D9-4EB1-9CB5-4BA2D8DC92DC@gmail.com>

The code changes a single row; that's why I said you'd have to adapt it to your application. 


> On Oct 9, 2014, at 3:10 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> 
> Hi Amos,
> 
> This approach gives a column of NA. 
> 
>> On Wed, Oct 8, 2014 at 10:20 PM, Amos B. Elberg <amos.elberg at gmail.com> wrote:
>> You can adapt:   format(as.Date(paste(Year, sep = "-", ifelse(Year %% 4 == 0, Start, ifelse(Start > 59, Start - 1, Start))), "%Y-%j"), "%b %d?)
>> 
>> But 60% of the dates in your data.frame will then be wrong.  
>> 
>> 
>> From: Frederic Ntirenganya <ntfredo at gmail.com>
>> Reply: Frederic Ntirenganya <ntfredo at gmail.com>>
>> Date: October 8, 2014 at 9:38:34 AM
>> To: r-help at r-project.org <r-help at r-project.org>>
>> Subject:  [R] Data formart 
>> 
>>> Dear All, 
>>> 
>>> Change the format of the start and end columns so that data appear as the 
>>> day of the year. For instance: Apr 24 rather than 115. 
>>> 
>>> The idea is that I want the non=leap years to be 366 days instead of being 
>>> 365 days. ie. Each year must have 366 days. for example: in the column 
>>> Start2, Apr 18 will be Apr 17. 
>>> 
>>> > head(Samaru) 
>>> Year Start End Length Start2 End2 
>>> 1 1930 108 288 180 Apr 18 Oct 15 
>>> 2 1931 118 288 170 Apr 28 Oct 15 
>>> 3 1932 115 295 180 Apr 24 Oct 21 
>>> 4 1933 156 294 138 Jun 05 Oct 21 
>>> 5 1934 116 291 175 Apr 26 Oct 18 
>>> 6 1935 134 288 154 May 14 Oct 15 
>>> 
>>> Any idea is welcome. Thamks!!!! 
>>> -- 
>>> Frederic Ntirenganya 
>>> Maseno University, 
>>> Kenya. 
>>> Mobile:(+254)718492836 
>>> Email: fredo at aims.ac.za 
>>> https://sites.google.com/a/aims.ac.za/fredo/ 
>>> 
>>> [[alternative HTML version deleted]] 
>>> 
>>> ______________________________________________ 
>>> R-help at r-project.org mailing list 
>>> https://stat.ethz.ch/mailman/listinfo/r-help 
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From alexandra.posekany at gmail.com  Thu Oct  9 10:37:45 2014
From: alexandra.posekany at gmail.com (Alexandra Posekany)
Date: Thu, 9 Oct 2014 10:37:45 +0200
Subject: [R] Gaussian mixture model based clustering
Message-ID: <CAChty-qn+ouSwQUyGzOc4tgciPTQbgO+8V9xrh3E=AuRG1ii-Q@mail.gmail.com>

Hey everybody,
I am looking for a R implementation of uni- and multivariate GMM clustering
which is both fast and can provide me with estimates of the respective
components' means and covariance matrices, not just the observations'
labels for the components which I am not interested in. As it is meant as
part of a larger algorithm and supposed to be the initialisation of another
GMM based method which should work efficiently, Bayesian Gibbs sampling
based methods are unfortunately not an option.
Thanks for sharing your experience!
Best,
Alex

	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Thu Oct  9 10:54:03 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 09 Oct 2014 19:54:03 +1100
Subject: [R] Changing date format
In-Reply-To: <CAGh51gTLd7Nyt=e0Mp0oHbGs5DGg0Y_2E-V+QaY7joygG0zszg@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<CAGh51gTQkztOUDfsHwVHVFT-B1VQk=LP0VvywndMZRPvQB0KzA@mail.gmail.com>
	<CAGh51gTLd7Nyt=e0Mp0oHbGs5DGg0Y_2E-V+QaY7joygG0zszg@mail.gmail.com>
Message-ID: <42814805.aGzeENWWZQ@localhost.localdomain>

On Wed, 8 Oct 2014 04:49:02 PM Frederic Ntirenganya wrote:
> The idea is that I want the non-leap years to be 366 days instead of 
being
> 365 days. ie. Each year must have 366 days.
> 
> for example: in the column Start2, Apr 18 will be Apr 17.
> 
> > head(Samaru)
> 
>   Year Start End Length Start2   End2
> 1 1930   108 288    180 Apr 18 Oct 15
> 2 1931   118 288    170 Apr 28 Oct 15
> 3 1932   115 295    180 Apr 24 Oct 21
> 4 1933   156 294    138 Jun 05 Oct 21
> 5 1934   116 291    175 Apr 26 Oct 18
> 6 1935   134 288    154 May 14 Oct 15
> 
> Is there a way to that in R?
> 
Hi Frederic,
That doesn't sound like a good idea to me. Instead of having about 
one quarter of the dates wrong, you will have about three quarters 
wrong. When I check the code I sent you:

Samaru$Start<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start-1,"%b %d")
Samaru$End<-format(as.Date(
 paste(Samaru$Year,"01-01",sep="-"))+Samaru$End-1, "%b %d")

it appears to correct for leap years. If you really want to do it yourself,
you can get a list of leap years here:

http://kalender-365.de/leap-years.php

I think the simplest way is to correct your Start and End fields before 
doing the calculation:

# create a vector of leap years
leap_years<-c(1804,1808,1812,1816,1820,1824,1828,...,2400)
# subtract 1 from Start entries in leap years and
# equal to or greater than 1 March
Samaru$Start<-Samaru$Start -
 (Samaru$Year %in% leap_years & Samaru$Start > 59)
# same for End
Samaru$End<-Samaru$End -
 (Samaru$Year %in% leap_years & Samaru$End > 59)

However, I don't think you have to worry about leap years if you are 
using the code I sent.

Jim


From murdoch.duncan at gmail.com  Thu Oct  9 10:55:37 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 9 Oct 2014 04:55:37 -0400
Subject: [R] How can I overwrite a method in R?
In-Reply-To: <CAAWNEwZNPp1P4_brEbsEHVQZf+tc7zDGMGvbTKgiG6mMdQno5A@mail.gmail.com>
References: <CAAWNEwZNPp1P4_brEbsEHVQZf+tc7zDGMGvbTKgiG6mMdQno5A@mail.gmail.com>
Message-ID: <54364D89.1020003@gmail.com>

On 09/10/2014, 2:14 AM, Tim Hesterberg wrote:
> How can I create an improved version of a method in R, and have it be used?
> 
> Short version:
> I think plot.histogram has a bug, and I'd like to try a version with a fix.
> But when I call hist(), my fixed version doesn't get used.

To be clear, we're talking S3 methods here.  Your long version below
documents the issue pretty well.  There isn't a simple way to do what
you want, but there are a couple of not-really-simple ways.

The best is to submit a bug report with a patch for the method that
doesn't work, and eventually the base version will probably get fixed.
But maybe not the way you fixed it, and we might not agree that it's a
bug.  So this is a little slow and no use while you are testing your patch.

You can install R from source, and develop your patch that way.  This is
best if you are thinking of submitting the bug report.

If you want local changes that might not make it into the base code,
then I think the best thing to do is to change the class, and write a
method for a new class.  hist() produces objects of class "histogram";
you can modify a local copy to produce objects of class
c("newhistogram", "histogram").  Then plot() on one of those will call
plot.newhistogram in preference to plot.histogram.

An alternative approach that is less work in the short term, but more
error prone in the long term is to make a habit of calling hist() with
plot=FALSE, then call plot.histogram() on the result explicitly.  If you
have a local version of plot.histogram() this should use yours.

One more inline comment below.

> 
> Long version:
> hist() calls plot() which calls plot.histogram() which fails to pass ...
> when it calls plot.window().
> As a result hist() ignores xaxs and yaxs arguments.
> I'd like to make my own copy of plot.histogram that passes ... to
> plot.window().
> 
> If I just make my own copy of plot.histogram, plot() ignores it, because my
> version is not part of the same graphics package that plot belongs to.
> 
> If I copy hist, hist.default and plot, the copies inherit the same
> environments as
> the originals, and behave the same.
> 
> If I also change the environment of each to .GlobalEnv, hist.default fails
> in
> a .Call because it cannot find C_BinCount.

You could fix this by prefixing C_BinCount as graphics:::C_BinCount, but
that's internal code that might change in future releases.

Duncan Murdoch

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ntfredo at gmail.com  Thu Oct  9 11:30:57 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 9 Oct 2014 12:30:57 +0300
Subject: [R] Changing date format
In-Reply-To: <42814805.aGzeENWWZQ@localhost.localdomain>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<CAGh51gTQkztOUDfsHwVHVFT-B1VQk=LP0VvywndMZRPvQB0KzA@mail.gmail.com>
	<CAGh51gTLd7Nyt=e0Mp0oHbGs5DGg0Y_2E-V+QaY7joygG0zszg@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
Message-ID: <CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>

Hi Lemon,

I am using the code you sent. It's correct for the leap years.
What I want to do is to have both leap  and no-leap years to have 366 days.
that means the 1st March is day 61 of each year.
This will help me to link it with Instat for climatic data analysis.

On Thu, Oct 9, 2014 at 11:54 AM, Jim Lemon <jim at bitwrit.com.au> wrote:

> On Wed, 8 Oct 2014 04:49:02 PM Frederic Ntirenganya wrote:
> > The idea is that I want the non-leap years to be 366 days instead of
> being
> > 365 days. ie. Each year must have 366 days.
> >
> > for example: in the column Start2, Apr 18 will be Apr 17.
> >
> > > head(Samaru)
> >
> >   Year Start End Length Start2   End2
> > 1 1930   108 288    180 Apr 18 Oct 15
> > 2 1931   118 288    170 Apr 28 Oct 15
> > 3 1932   115 295    180 Apr 24 Oct 21
> > 4 1933   156 294    138 Jun 05 Oct 21
> > 5 1934   116 291    175 Apr 26 Oct 18
> > 6 1935   134 288    154 May 14 Oct 15
> >
> > Is there a way to that in R?
> >
> Hi Frederic,
> That doesn't sound like a good idea to me. Instead of having about
> one quarter of the dates wrong, you will have about three quarters
> wrong. When I check the code I sent you:
>
> Samaru$Start<-format(as.Date(
>  paste(Samaru$Year,"01-01",sep="-"))+Samaru$Start-1,"%b %d")
> Samaru$End<-format(as.Date(
>  paste(Samaru$Year,"01-01",sep="-"))+Samaru$End-1, "%b %d")
>
> it appears to correct for leap years. If you really want to do it yourself,
> you can get a list of leap years here:
>
> http://kalender-365.de/leap-years.php
>
> I think the simplest way is to correct your Start and End fields before
> doing the calculation:
>
> # create a vector of leap years
> leap_years<-c(1804,1808,1812,1816,1820,1824,1828,...,2400)
> # subtract 1 from Start entries in leap years and
> # equal to or greater than 1 March
> Samaru$Start<-Samaru$Start -
>  (Samaru$Year %in% leap_years & Samaru$Start > 59)
> # same for End
> Samaru$End<-Samaru$End -
>  (Samaru$Year %in% leap_years & Samaru$End > 59)
>
> However, I don't think you have to worry about leap years if you are
> using the code I sent.
>
> Jim
>
>


-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Thu Oct  9 12:07:57 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 09 Oct 2014 21:07:57 +1100
Subject: [R] Changing date format
In-Reply-To: <CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
Message-ID: <12845409.rVEsxnvE7c@localhost.localdomain>

On Thu, 9 Oct 2014 12:30:57 PM Frederic Ntirenganya wrote:
> Hi Lemon,
> 
> I am using the code you sent. It's correct for the leap years.
> What I want to do is to have both leap  and no-leap years to have 366 
days.
> that means the 1st March is day 61 of each year.
> This will help me to link it with Instat for climatic data analysis.
> 
Are you sure that the Start and End day of year numbers haven't 
already been corrected for leap years? If not, you can correct both for all 
years like this:

Samaru$Start<-Samaru$Start - Samaru$Start > 60)
Samaru$End<-Samaru$End - Samaru$End > 60)

as you don't want to shift the dates before Feb 29.

Jim


From marcel.au at web.de  Thu Oct  9 12:53:17 2014
From: marcel.au at web.de (marcel Austenfeld)
Date: Thu, 9 Oct 2014 12:53:17 +0200
Subject: [R] Event after a package is loaded
Message-ID: <trinity-c501e769-e15f-468d-9ee0-a2ae8c013b0e-1412851997767@3capp-webde-bs36>

Hello,

i would like to call a self defined R function after a package (not a specific one - library (anyAvailablePackage)) has been loaded into the R environment.
I there a general method available in R which can be used for that?

Any help is appreciated.
?


From ntfredo at gmail.com  Thu Oct  9 13:31:44 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 9 Oct 2014 14:31:44 +0300
Subject: [R] Changing date format
In-Reply-To: <12845409.rVEsxnvE7c@localhost.localdomain>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
	<12845409.rVEsxnvE7c@localhost.localdomain>
Message-ID: <CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>

This idea substract 1 for the all column which is not what i want.

We know that the leap years have 366 days. I don't need to change anything
on them

the non-leap years have 365 days. This is what i want to change to be 366
days rather than 365 days.

On Thu, Oct 9, 2014 at 1:07 PM, Jim Lemon <jim at bitwrit.com.au> wrote:

> On Thu, 9 Oct 2014 12:30:57 PM Frederic Ntirenganya wrote:
> > Hi Lemon,
> >
> > I am using the code you sent. It's correct for the leap years.
> > What I want to do is to have both leap  and no-leap years to have 366
> days.
> > that means the 1st March is day 61 of each year.
> > This will help me to link it with Instat for climatic data analysis.
> >
> Are you sure that the Start and End day of year numbers haven't
> already been corrected for leap years? If not, you can correct both for all
> years like this:
>
> Samaru$Start<-Samaru$Start - Samaru$Start > 60)
> Samaru$End<-Samaru$End - Samaru$End > 60)
>
> as you don't want to shift the dates before Feb 29.
>
> Jim
>
>


-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Oct  9 13:32:54 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 09 Oct 2014 07:32:54 -0400
Subject: [R] Event after a package is loaded
In-Reply-To: <trinity-c501e769-e15f-468d-9ee0-a2ae8c013b0e-1412851997767@3capp-webde-bs36>
References: <trinity-c501e769-e15f-468d-9ee0-a2ae8c013b0e-1412851997767@3capp-webde-bs36>
Message-ID: <54367266.9040908@gmail.com>

On 09/10/2014, 6:53 AM, marcel Austenfeld wrote:
> Hello,
> 
> i would like to call a self defined R function after a package (not a specific one - library (anyAvailablePackage)) has been loaded into the R environment.
> I there a general method available in R which can be used for that?

No, I don't think so.  ?setHook defines user hooks, but they are set
separately by package, not generally.  You could change the
loadNamespace function if you want, but it won't work for other users.

Duncan Murdoch


From ntfredo at gmail.com  Thu Oct  9 13:54:20 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 9 Oct 2014 14:54:20 +0300
Subject: [R] Event after a package is loaded
In-Reply-To: <54367266.9040908@gmail.com>
References: <trinity-c501e769-e15f-468d-9ee0-a2ae8c013b0e-1412851997767@3capp-webde-bs36>
	<54367266.9040908@gmail.com>
Message-ID: <CAGh51gQZpYMgAnQnUvx5aDYRYCDjbUUrV7GKn8Vkf+BCyUhJRg@mail.gmail.com>

I don't think the is an appropriate option for that.

On Thu, Oct 9, 2014 at 2:32 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 09/10/2014, 6:53 AM, marcel Austenfeld wrote:
> > Hello,
> >
> > i would like to call a self defined R function after a package (not a
> specific one - library (anyAvailablePackage)) has been loaded into the R
> environment.
> > I there a general method available in R which can be used for that?
>
> No, I don't think so.  ?setHook defines user hooks, but they are set
> separately by package, not generally.  You could change the
> loadNamespace function if you want, but it won't work for other users.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu Oct  9 14:00:31 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 9 Oct 2014 07:00:31 -0500
Subject: [R] How can I overwrite a method in R?
In-Reply-To: <CAAWNEwZNPp1P4_brEbsEHVQZf+tc7zDGMGvbTKgiG6mMdQno5A@mail.gmail.com>
References: <CAAWNEwZNPp1P4_brEbsEHVQZf+tc7zDGMGvbTKgiG6mMdQno5A@mail.gmail.com>
Message-ID: <CABdHhvGBy6TeKYXPS9f9rG-OfHAOJegf_5SowtLR-fMkA1iWQw@mail.gmail.com>

This is usually ill-advised, but I think it's the right solution for
your problem:

assignInNamespace("plot.histogram", function(...) plot(1:10), "graphics")
hist(1:10)

Haley

On Thu, Oct 9, 2014 at 1:14 AM, Tim Hesterberg <timhesterberg at gmail.com> wrote:
> How can I create an improved version of a method in R, and have it be used?
>
> Short version:
> I think plot.histogram has a bug, and I'd like to try a version with a fix.
> But when I call hist(), my fixed version doesn't get used.
>
> Long version:
> hist() calls plot() which calls plot.histogram() which fails to pass ...
> when it calls plot.window().
> As a result hist() ignores xaxs and yaxs arguments.
> I'd like to make my own copy of plot.histogram that passes ... to
> plot.window().
>
> If I just make my own copy of plot.histogram, plot() ignores it, because my
> version is not part of the same graphics package that plot belongs to.
>
> If I copy hist, hist.default and plot, the copies inherit the same
> environments as
> the originals, and behave the same.
>
> If I also change the environment of each to .GlobalEnv, hist.default fails
> in
> a .Call because it cannot find C_BinCount.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From marcel.au at web.de  Thu Oct  9 14:13:22 2014
From: marcel.au at web.de (marcel Austenfeld)
Date: Thu, 9 Oct 2014 14:13:22 +0200
Subject: [R] Event after a package is loaded
In-Reply-To: <CAGh51gQZpYMgAnQnUvx5aDYRYCDjbUUrV7GKn8Vkf+BCyUhJRg@mail.gmail.com>
References: <trinity-c501e769-e15f-468d-9ee0-a2ae8c013b0e-1412851997767@3capp-webde-bs36>
	<54367266.9040908@gmail.com>,
	<CAGh51gQZpYMgAnQnUvx5aDYRYCDjbUUrV7GKn8Vkf+BCyUhJRg@mail.gmail.com>
Message-ID: <trinity-b90a294a-bea8-4efa-a775-5feb40a84a16-1412856801954@3capp-webde-bs52>

Thank you for the fast reply!

Best regards

Marcel
?

Gesendet:?Donnerstag, 09. Oktober 2014 um 13:54 Uhr
Von:?"Frederic Ntirenganya" <ntfredo at gmail.com>
An:?"Duncan Murdoch" <murdoch.duncan at gmail.com>
Cc:?"marcel Austenfeld" <marcel.au at web.de>, r-help at r-project.org
Betreff:?Re: [R] Event after a package is loaded

I don't think the is an appropriate option for that.
?
On Thu, Oct 9, 2014 at 2:32 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:On 09/10/2014, 6:53 AM, marcel Austenfeld wrote:
> Hello,
>
> i would like to call a self defined R function after a package (not a specific one - library (anyAvailablePackage)) has been loaded into the R environment.
> I there a general method available in R which can be used for that?

No, I don't think so.? ?setHook defines user hooks, but they are set
separately by package, not generally.? You could change the
loadNamespace function if you want, but it won't work for other users.

Duncan Murdoch

______________________________________________
R-help at r-project.org[R-help at r-project.org] mailing list
https://stat.ethz.ch/mailman/listinfo/r-help[https://stat.ethz.ch/mailman/listinfo/r-help]
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html[http://www.R-project.org/posting-guide.html]
and provide commented, minimal, self-contained, reproducible code.


--

Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email:?fredo at aims.ac.za[fredo at aims.ac.za]
https://sites.google.com/a/aims.ac.za/fredo/


From petr.pikal at precheza.cz  Thu Oct  9 14:27:07 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 9 Oct 2014 12:27:07 +0000
Subject: [R] Changing date format
In-Reply-To: <CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
	<12845409.rVEsxnvE7c@localhost.localdomain>
	<CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frederic Ntirenganya
> Sent: Thursday, October 09, 2014 1:32 PM
> To: Jim Lemon
> Cc: r-help at r-project.org
> Subject: Re: [R] Changing date format
>
> This idea substract 1 for the all column which is not what i want.
>
> We know that the leap years have 366 days. I don't need to change
> anything on them
>
> the non-leap years have 365 days. This is what i want to change to be
> 366 days rather than 365 days.

But this is a question of calendar reform not R. I must admit it would be a tough job as leap day is needed to stay in tune with solar year. Your suggestion would quickly result in out of sync with the Sun.

Regards
Petr

>
> On Thu, Oct 9, 2014 at 1:07 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
>
> > On Thu, 9 Oct 2014 12:30:57 PM Frederic Ntirenganya wrote:
> > > Hi Lemon,
> > >
> > > I am using the code you sent. It's correct for the leap years.
> > > What I want to do is to have both leap  and no-leap years to have
> > > 366
> > days.
> > > that means the 1st March is day 61 of each year.
> > > This will help me to link it with Instat for climatic data
> analysis.
> > >
> > Are you sure that the Start and End day of year numbers haven't
> > already been corrected for leap years? If not, you can correct both
> > for all years like this:
> >
> > Samaru$Start<-Samaru$Start - Samaru$Start > 60) Samaru$End<-
> Samaru$End
> > - Samaru$End > 60)
> >
> > as you don't want to shift the dates before Feb 29.
> >
> > Jim
> >
> >
>
>
> --
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ntfredo at gmail.com  Thu Oct  9 14:29:47 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 9 Oct 2014 15:29:47 +0300
Subject: [R] Changing date format
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
	<12845409.rVEsxnvE7c@localhost.localdomain>
	<CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>
Message-ID: <CAGh51gSLxBs8bZJ_gsQHK+CevGqO3trx+OJ4krs3mf3mxL+3ng@mail.gmail.com>

Hi Pikal,

I am not talking about changing calender, I need this in my analysis.

On Thu, Oct 9, 2014 at 3:27 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Frederic Ntirenganya
> > Sent: Thursday, October 09, 2014 1:32 PM
> > To: Jim Lemon
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Changing date format
> >
> > This idea substract 1 for the all column which is not what i want.
> >
> > We know that the leap years have 366 days. I don't need to change
> > anything on them
> >
> > the non-leap years have 365 days. This is what i want to change to be
> > 366 days rather than 365 days.
>
> But this is a question of calendar reform not R. I must admit it would be
> a tough job as leap day is needed to stay in tune with solar year. Your
> suggestion would quickly result in out of sync with the Sun.
>
> Regards
> Petr
>
> >
> > On Thu, Oct 9, 2014 at 1:07 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
> >
> > > On Thu, 9 Oct 2014 12:30:57 PM Frederic Ntirenganya wrote:
> > > > Hi Lemon,
> > > >
> > > > I am using the code you sent. It's correct for the leap years.
> > > > What I want to do is to have both leap  and no-leap years to have
> > > > 366
> > > days.
> > > > that means the 1st March is day 61 of each year.
> > > > This will help me to link it with Instat for climatic data
> > analysis.
> > > >
> > > Are you sure that the Start and End day of year numbers haven't
> > > already been corrected for leap years? If not, you can correct both
> > > for all years like this:
> > >
> > > Samaru$Start<-Samaru$Start - Samaru$Start > 60) Samaru$End<-
> > Samaru$End
> > > - Samaru$End > 60)
> > >
> > > as you don't want to shift the dates before Feb 29.
> > >
> > > Jim
> > >
> > >
> >
> >
> > --
> > Frederic Ntirenganya
> > Maseno University,
> > Kenya.
> > Mobile:(+254)718492836
> > Email: fredo at aims.ac.za
> > https://sites.google.com/a/aims.ac.za/fredo/
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Oct  9 14:48:09 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 09 Oct 2014 08:48:09 -0400
Subject: [R] Changing date format
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>	<42814805.aGzeENWWZQ@localhost.localdomain>	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>	<12845409.rVEsxnvE7c@localhost.localdomain>	<CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>
Message-ID: <54368409.6010104@gmail.com>

On 09/10/2014, 8:27 AM, PIKAL Petr wrote:
> Hi
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Frederic Ntirenganya
>> Sent: Thursday, October 09, 2014 1:32 PM
>> To: Jim Lemon
>> Cc: r-help at r-project.org
>> Subject: Re: [R] Changing date format
>>
>> This idea substract 1 for the all column which is not what i want.
>>
>> We know that the leap years have 366 days. I don't need to change
>> anything on them
>>
>> the non-leap years have 365 days. This is what i want to change to be
>> 366 days rather than 365 days.
> 
> But this is a question of calendar reform not R. I must admit it would be a tough job as leap day is needed to stay in tune with solar year. Your suggestion would quickly result in out of sync with the Sun.

R Core is powerful, but I doubt if we could reform the calendar in this
way.

And I'd be against it in any case:  I like to swim on my summer
vacations, but if August slipped into the winter, the lakes around here
would be frozen.

Duncan Murdoch


From arne.henningsen at gmail.com  Thu Oct  9 15:29:16 2014
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Thu, 9 Oct 2014 15:29:16 +0200
Subject: [R] maximum likelihood estimation
In-Reply-To: <DUB125-W40C23339F6A3D605020ACDC6A20@phx.gbl>
References: <DUB125-W40C23339F6A3D605020ACDC6A20@phx.gbl>
Message-ID: <CAMTWbJh9XxD_a3qZt0diVvU4bgNHJJeqjGwWfVx7GGLy3x5sDg@mail.gmail.com>

Dear Pari

On 7 October 2014 10:55, pari hesabi <statistics84 at hotmail.com> wrote:
> HelloI am trying to estimate the parameter of a function by the Maximum Likelihood Estimation method.If  the function is the difference between two integrals: C<-function(n){integrand3<-function(x) {((2-x)^n)*(exp(ax-2))}cc<- integrate (integrand3,0,2)print(cc)}
> D<-function(n){integrand4<-function(x) {((5-ax)^n)}cc<- integrate (integrand4,0,2)print(cc)}
> f(n) = C(n) - D(n)
>  I need to estimate parameter (a).   loglikelihood function is in the form of  sum[F(k) log(f(k))]=lnL. I am wondering how to introduce my logliklihood function to the loop below.  Can anybody help me for correcting the following loop? if there are some other packages better than this , please let me know.Thank you,Diba
> n <- c(0,1,2,3,4,5,6,7,8)
> F<-c(0,0,1,3,5,7,8,11,10)
> loglik <- function(a) sum(F*log(C(n)-D(n)))
> re <- maxLik (loglik, start=.5)
> summary(re)

Unfortunately, I cannot reproduce your example, because I get an error
message about an unexpected symbol.

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From felipe.parra at quantil.com.co  Thu Oct  9 16:30:20 2014
From: felipe.parra at quantil.com.co (Luis Felipe Parra)
Date: Thu, 9 Oct 2014 10:30:20 -0400
Subject: [R] Bug in myintegrate in Elliptic package
Message-ID: <CACNozQe_rddU6cLTUCMeXypbj8xjr4=U+kxtehYP+q4ofZChFw@mail.gmail.com>

Hello,

I was using my integrate today and spend a couple of hours trying to figure
out why I was getting some weird results in my code when using myintegrate
function to do complex integration, after some time decided just to change
the name of the integration dummy variable in the code from 'x' to 'y' and
the code worked perfectly, here is the outpus of what I was using:

>   #Find the CDF to find the call prices
>   CDF_Merton = function(y,psi_measure){
+     integrand_cdf = function(u_vec,y,psi_measure)
Im(exp(-1i*u_vec*y)*psi_measure(u_vec))/u_vec
+   return(1/2 -
1/pi*Re(myintegrate(integrand_cdf,0,100,y=y,psi_measure=psi_measure)))
+   }
>   CDF_Merton(y=0.1,psi_measure=psi)
[1] 0.9368239

>
>   CDF_Merton = function(x,psi_measure){
+     integrand_cdf = function(u_vec,x,psi_measure)
Im(exp(-1i*u_vec*x)*psi_measure(u_vec))/u_vec
+   return(1/2 -
1/pi*Re(myintegrate(integrand_cdf,0,100,x=x,psi_measure=psi_measure)))
+   }
>   CDF_Merton(x=0.1,psi_measure=psi)
[1] 59.03344

where you can see that both codes are exactly the same except for the dummy
variable used to integrate, does any body know what might be going on here?

Thanks

Felipe Parra


-- 

Este mensaje de correo electr?nico es enviado por Quantil S.A.S y puede
contener informaci?n confidencial o privilegiada.

This e-mail is sent by Quantil S.A.S and may contain confidential or
privileged information

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Thu Oct  9 14:36:59 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 09 Oct 2014 08:36:59 -0400
Subject: [R] cbind in a loop...better way? | summary
In-Reply-To: <54358CB0.6090506@gmail.com>
References: <54358CB0.6090506@gmail.com>
Message-ID: <5436816B.3040501@gmail.com>

Two solutions proposed -- not entirely orthogonal, but both do the 
trick. Instead of nesting cbin in a loop (as I did originally -- OP, 
below),

1\   do.call(cbind, lapply(mat_list, as.vector))

or

2\   sapply(mat_list,function(x) as.vector(x))


Both work fine. Thanks to Jeff Laake (2) + David Carlson (1) for their 
suggestions.


On 10/8/2014 3:12 PM, Evan Cooch wrote:
> ...or some such. I'm trying to work up a function wherein the user 
> passes a list of matrices to the function, which then (1) takes each 
> matrix, (2) performs an operation to 'vectorize' the matrix (i.e., 
> given an (m x n) matrix x, this produces the vector Y of length  m*n 
> that contains the columns of the matrix x, stacked below each other), 
> and then (3) cbinds them together.
>
> Here is an example using the case where I know how many matrices I 
> need to cbind together. For this example, 2 square (3x3) matrices:
>
>  a <- matrix(c,0,20,50,0.05,0,0,0,0.1,0),3,3,byrow=T)
>  b <- matrix(c(0,15,45,0.15,0,0,0,0.2,0),3,3,byrow=T)
>
> I want to vec them, and then cbind them together. So,
>
> result  <- cbind(matrix(a,nr=9), matrix(b,nr=9))
>
> which yields the following:
>
>       [,1]  [,2]
>  [1,]  0.00  0.00
>  [2,]  0.05  0.15
>  [3,]  0.00  0.00
>  [4,] 20.00 15.00
>  [5,]  0.00  0.00
>  [6,]  0.10  0.20
>  [7,] 50.00 45.00
>  [8,]  0.00  0.00
>  [9,]  0.00  0.00
>
> Easy enough. But, I want to put it in a function, where the number and 
> dimensions  of the matrices is not specified. Something like
>
> Using matrices (a) and (b) from above, let
>
>   env <- list(a,b).
>
> Now, a function (or attempt at same) to perform the desired operations:
>
>   vec=function(matlist) {
>
>       n_mat=length(matlist);
>       size_mat=dim(matlist[[1]])[1];
>
>       result=cbind()
>
>        for (i in 1:n_mat) {
>          result=cbind(result,matrix(matlist[[i]],nr=size_mat^2))
>                           }
>
>      return(result)
>
>    }
>
>
> When I run vec(env), I get the *right answer*, but I am wondering if 
> there is a *better* way to get there from here than the approach I use 
> (above). I'm not so much interested in 'computational efficiency' as I 
> am in stability, and flexibility.
>
> Thanks...
>
> .
>


From trichter at uni-bremen.de  Thu Oct  9 13:19:46 2014
From: trichter at uni-bremen.de (Tim Richter-Heitmann)
Date: Thu, 09 Oct 2014 13:19:46 +0200
Subject: [R] [vegan] Error in as.vector(x, mode) : ,
 cannot coerce type 'builtin' to vector of type 'any' when
 performing anova on CCA objects
Message-ID: <54366F52.4050704@uni-bremen.de>

Hi there,

i have three dataframes, which have the same structure (data.frame, 358 
observations of 340 variables, every column is "num"eric), and are 
basically submatrices of a parental dataset.

I can perform a CCA on all of them (with the explanatory dataset being 
"abio")

/cca1_ab <- cca(df1~., data=abio)/

I can also perform an anova on all three cca-derived values

/anova(cca1_ab)/

However, if i do

/sig1_ab<-anova(cca1_ab, by="term", perm=200)/

which i believe gives me confidence values for the fitting of the 
explanatory variables, only one of the cca-derived values gives an 
unexpected

Error in as.vector(x, mode) : ,  cannot coerce type 'builtin' to vector 
of type 'any'

The other two are working fine. Its hard to come up with an explanation, 
as the datasets look and behave the same otherwise.

Any idea why this could happen?

I am sorry for not providing data for reproduction, as the data sets are 
pretty large.

-- 
Tim Richter-Heitmann (M.Sc.)
PhD Candidate



International Max-Planck Research School for Marine Microbiology
University of Bremen
Microbial Ecophysiology Group (AG Friedrich)
FB02 - Biologie/Chemie
Leobener Stra?e (NW2 A2130)
D-28359 Bremen
Tel.: 0049(0)421 218-63062
Fax: 0049(0)421 218-63069


	[[alternative HTML version deleted]]


From mark.hogue at srs.gov  Thu Oct  9 14:36:07 2014
From: mark.hogue at srs.gov (mark.hogue at srs.gov)
Date: Thu, 9 Oct 2014 08:36:07 -0400
Subject: [R] reading in hexadecimal data - not working with data ending
	in E
In-Reply-To: <54359746.6020204@gmail.com>
References: <OFDDA4824F.B7C76DBC-ON85257D6B.003CA376-85257D6B.003CAA0D@srs.gov>
	<54359746.6020204@gmail.com>
Message-ID: <OF8B71B28E.B3E4F913-ON85257D6C.00451C73-85257D6C.004539E3@srs.gov>

Thanks to all for your help. The colClasses option did do the trick. 


	[[alternative HTML version deleted]]


From sonahrazia at yahoo.com  Thu Oct  9 15:01:28 2014
From: sonahrazia at yahoo.com (nabila kazmi)
Date: Thu, 9 Oct 2014 13:01:28 +0000 (UTC)
Subject: [R] Remove from the mailing list
Message-ID: <2220785.30005.1412859688446.JavaMail.yahoo@jws10063.mail.ne1.yahoo.com>

Hi there,
Please can you remove me from the mailing list, I keep getting the conversations which are of no use to me.
BestKazmi
	[[alternative HTML version deleted]]


From baccts at hotmail.com  Thu Oct  9 18:11:40 2014
From: baccts at hotmail.com (C Lin)
Date: Thu, 9 Oct 2014 12:11:40 -0400
Subject: [R] How can I overwrite a method in R?
In-Reply-To: <CABdHhvGBy6TeKYXPS9f9rG-OfHAOJegf_5SowtLR-fMkA1iWQw@mail.gmail.com>
References: <CAAWNEwZNPp1P4_brEbsEHVQZf+tc7zDGMGvbTKgiG6mMdQno5A@mail.gmail.com>,
	<CABdHhvGBy6TeKYXPS9f9rG-OfHAOJegf_5SowtLR-fMkA1iWQw@mail.gmail.com>
Message-ID: <COL129-W30E28B996CB526A1CF068CBA00@phx.gbl>

I posted similar question a while ago. Search for "modify function in a package".
In your case, the following should work.

source('plot.histogram.R')
assignInNamespace('plot.histogram',plot.histogram,ns='graphics')
environment(plot.histogram) <- asNamespace('graphics');

Assuming you have your own plot.histogram function inside "plot.histogram.R" and the plot.histogram function you are trying to overwrite is in graphics package.

Lin

----------------------------------------
> From: h.wickham at gmail.com
> Date: Thu, 9 Oct 2014 07:00:31 -0500
> To: timhesterberg at gmail.com
> CC: R-help at stat.math.ethz.ch
> Subject: Re: [R] How can I overwrite a method in R?
>
> This is usually ill-advised, but I think it's the right solution for
> your problem:
>
> assignInNamespace("plot.histogram", function(...) plot(1:10), "graphics")
> hist(1:10)
>
> Haley
>
> On Thu, Oct 9, 2014 at 1:14 AM, Tim Hesterberg <timhesterberg at gmail.com> wrote:
>> How can I create an improved version of a method in R, and have it be used?
>>
>> Short version:
>> I think plot.histogram has a bug, and I'd like to try a version with a fix.
>> But when I call hist(), my fixed version doesn't get used.
>>
>> Long version:
>> hist() calls plot() which calls plot.histogram() which fails to pass ...
>> when it calls plot.window().
>> As a result hist() ignores xaxs and yaxs arguments.
>> I'd like to make my own copy of plot.histogram that passes ... to
>> plot.window().
>>
>> If I just make my own copy of plot.histogram, plot() ignores it, because my
>> version is not part of the same graphics package that plot belongs to.
>>
>> If I copy hist, hist.default and plot, the copies inherit the same
>> environments as
>> the originals, and behave the same.
>>
>> If I also change the environment of each to .GlobalEnv, hist.default fails
>> in
>> a .Call because it cannot find C_BinCount.
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> http://had.co.nz/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
 		 	   		  

From maitra.mbox.ignored at inbox.com  Thu Oct  9 18:35:57 2014
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Thu, 9 Oct 2014 11:35:57 -0500
Subject: [R] Gaussian mixture model based clustering
In-Reply-To: <CAChty-qn+ouSwQUyGzOc4tgciPTQbgO+8V9xrh3E=AuRG1ii-Q@mail.gmail.com>
References: <CAChty-qn+ouSwQUyGzOc4tgciPTQbgO+8V9xrh3E=AuRG1ii-Q@mail.gmail.com>
Message-ID: <20141009113557.75011994147be8939b130be9@inbox.com>

There are lots! eg: Mclust or EMCluster and many more.

Ranjan

On Thu, 9 Oct 2014 10:37:45 +0200 Alexandra Posekany <alexandra.posekany at gmail.com> wrote:

> Hey everybody,
> I am looking for a R implementation of uni- and multivariate GMM clustering
> which is both fast and can provide me with estimates of the respective
> components' means and covariance matrices, not just the observations'
> labels for the components which I am not interested in. As it is meant as
> part of a larger algorithm and supposed to be the initialisation of another
> GMM based method which should work efficiently, Bayesian Gibbs sampling
> based methods are unfortunately not an option.
> Thanks for sharing your experience!
> Best,
> Alex
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From Ingrid.Charvet at rms.com  Thu Oct  9 19:19:54 2014
From: Ingrid.Charvet at rms.com (Ingrid Charvet)
Date: Thu, 9 Oct 2014 10:19:54 -0700
Subject: [R] jitter function when length(x) = 1
Message-ID: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B6B3AB28@MAILCA6.rms.com>

Hello,

A quick question relating to the documentation of the jitter function:
http://127.0.0.1:15714/library/base/html/jitter.html

jitter(x, factor = 1, amount = NULL)

"If amount is NULL (default), we set a <- factor * d/5 where d is the smallest difference between adjacent unique (apart from fuzz) x values."

Therefore if length(x) = 1, then d = 0, which means jitter(x) should be equal to x?
Which is not the case, i.e.

> x <- 1
> jitter(x)
[1] 0.9842914

So how does jitter deals with this situation? Does it assume d = x?

Thanks
IC

________________________________
This message and any attachments contain information that may be RMS Inc. confidential and/or privileged. If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.



	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Thu Oct  9 19:34:47 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 09 Oct 2014 18:34:47 +0100
Subject: [R] jitter function when length(x) = 1
In-Reply-To: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B6B3AB28@MAILCA6.rms.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B6B3AB28@MAILCA6.rms.com>
Message-ID: <5436C737.6010700@sapo.pt>

Hello,

You can see the code for jitter by typing its name at the prompt.
Inline.

Em 09-10-2014 18:19, Ingrid Charvet escreveu:
> Hello,
>
> A quick question relating to the documentation of the jitter function:
> http://127.0.0.1:15714/library/base/html/jitter.html
>
> jitter(x, factor = 1, amount = NULL)
>
> "If amount is NULL (default), we set a <- factor * d/5 where d is the smallest difference between adjacent unique (apart from fuzz) x values."
>
> Therefore if length(x) = 1, then d = 0, which means jitter(x) should be equal to x?
> Which is not the case, i.e.
>
>> x <- 1
>> jitter(x)
> [1] 0.9842914
>
> So how does jitter deals with this situation? Does it assume d = x?

It doesn't assume, it computes range(x) and acts accordingly. The code 
lines are

     z <- diff(r <- range(x[is.finite(x)]))
     if (z == 0)
         z <- abs(r[1L])

It has the effect of setting z to x. Try running them. (And with x <- 2 
to see the difference.)

Hope this helps,

Rui Barradas
>
> Thanks
> IC
>
> ________________________________
> This message and any attachments contain information that may be RMS Inc. confidential and/or privileged. If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Thu Oct  9 19:52:34 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 9 Oct 2014 17:52:34 +0000
Subject: [R] cbind in a loop...better way? | summary
In-Reply-To: <5436816B.3040501@gmail.com>
References: <54358CB0.6090506@gmail.com> <5436816B.3040501@gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726F9EEFF@mb02.ads.tamu.edu>

Actually Jeff Laake's can be made even shorter with

sapply(mat_list, as.vector)

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Evan Cooch
Sent: Thursday, October 9, 2014 7:37 AM
To: Evan Cooch; r-help at r-project.org
Subject: Re: [R] cbind in a loop...better way? | summary

Two solutions proposed -- not entirely orthogonal, but both do the 
trick. Instead of nesting cbin in a loop (as I did originally -- OP, 
below),

1\   do.call(cbind, lapply(mat_list, as.vector))

or

2\   sapply(mat_list,function(x) as.vector(x))


Both work fine. Thanks to Jeff Laake (2) + David Carlson (1) for their 
suggestions.


On 10/8/2014 3:12 PM, Evan Cooch wrote:
> ...or some such. I'm trying to work up a function wherein the user 
> passes a list of matrices to the function, which then (1) takes each 
> matrix, (2) performs an operation to 'vectorize' the matrix (i.e., 
> given an (m x n) matrix x, this produces the vector Y of length  m*n 
> that contains the columns of the matrix x, stacked below each other), 
> and then (3) cbinds them together.
>
> Here is an example using the case where I know how many matrices I 
> need to cbind together. For this example, 2 square (3x3) matrices:
>
>  a <- matrix(c,0,20,50,0.05,0,0,0,0.1,0),3,3,byrow=T)
>  b <- matrix(c(0,15,45,0.15,0,0,0,0.2,0),3,3,byrow=T)
>
> I want to vec them, and then cbind them together. So,
>
> result  <- cbind(matrix(a,nr=9), matrix(b,nr=9))
>
> which yields the following:
>
>       [,1]  [,2]
>  [1,]  0.00  0.00
>  [2,]  0.05  0.15
>  [3,]  0.00  0.00
>  [4,] 20.00 15.00
>  [5,]  0.00  0.00
>  [6,]  0.10  0.20
>  [7,] 50.00 45.00
>  [8,]  0.00  0.00
>  [9,]  0.00  0.00
>
> Easy enough. But, I want to put it in a function, where the number and 
> dimensions  of the matrices is not specified. Something like
>
> Using matrices (a) and (b) from above, let
>
>   env <- list(a,b).
>
> Now, a function (or attempt at same) to perform the desired operations:
>
>   vec=function(matlist) {
>
>       n_mat=length(matlist);
>       size_mat=dim(matlist[[1]])[1];
>
>       result=cbind()
>
>        for (i in 1:n_mat) {
>          result=cbind(result,matrix(matlist[[i]],nr=size_mat^2))
>                           }
>
>      return(result)
>
>    }
>
>
> When I run vec(env), I get the *right answer*, but I am wondering if 
> there is a *better* way to get there from here than the approach I use 
> (above). I'm not so much interested in 'computational efficiency' as I 
> am in stability, and flexibility.
>
> Thanks...
>
> .
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Oct  9 19:53:42 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 9 Oct 2014 10:53:42 -0700
Subject: [R] jitter function when length(x) = 1
In-Reply-To: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B6B3AB28@MAILCA6.rms.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD01B6B3AB28@MAILCA6.rms.com>
Message-ID: <C39D3FE0-0E89-448C-A83F-7517CF68B783@comcast.net>


On Oct 9, 2014, at 10:19 AM, Ingrid Charvet wrote:

> Hello,
> 
> A quick question relating to the documentation of the jitter function:
> http://127.0.0.1:15714/library/base/html/jitter.html
> 
> jitter(x, factor = 1, amount = NULL)
> 
> "If amount is NULL (default), we set a <- factor * d/5 where d is the smallest difference between adjacent unique (apart from fuzz) x values."
> 
> Therefore if length(x) = 1, then d = 0, which means jitter(x) should be equal to x?
> Which is not the case, i.e.
> 
>> x <- 1
>> jitter(x)
> [1] 0.9842914
> 
> So how does jitter deals with this situation? Does it assume d = x?

The code is right at your fingertips. Just type:

jitter

-- 
David.

> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From liuwensui at gmail.com  Thu Oct  9 20:09:30 2014
From: liuwensui at gmail.com (Wensui Liu)
Date: Thu, 9 Oct 2014 14:09:30 -0400
Subject: [R] cbind in a loop...better way? | summary
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9EEFF@mb02.ads.tamu.edu>
References: <54358CB0.6090506@gmail.com> <5436816B.3040501@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9EEFF@mb02.ads.tamu.edu>
Message-ID: <CAKyN3iCJe8eAv5tTcLRABwZWST-6tDyLA--JJ3cOReXFnkX3YQ@mail.gmail.com>

How about foreach() run in parallel?
On Oct 9, 2014 1:54 PM, "David L Carlson" <dcarlson at tamu.edu> wrote:

> Actually Jeff Laake's can be made even shorter with
>
> sapply(mat_list, as.vector)
>
> David C
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Evan Cooch
> Sent: Thursday, October 9, 2014 7:37 AM
> To: Evan Cooch; r-help at r-project.org
> Subject: Re: [R] cbind in a loop...better way? | summary
>
> Two solutions proposed -- not entirely orthogonal, but both do the
> trick. Instead of nesting cbin in a loop (as I did originally -- OP,
> below),
>
> 1\   do.call(cbind, lapply(mat_list, as.vector))
>
> or
>
> 2\   sapply(mat_list,function(x) as.vector(x))
>
>
> Both work fine. Thanks to Jeff Laake (2) + David Carlson (1) for their
> suggestions.
>
>
> On 10/8/2014 3:12 PM, Evan Cooch wrote:
> > ...or some such. I'm trying to work up a function wherein the user
> > passes a list of matrices to the function, which then (1) takes each
> > matrix, (2) performs an operation to 'vectorize' the matrix (i.e.,
> > given an (m x n) matrix x, this produces the vector Y of length  m*n
> > that contains the columns of the matrix x, stacked below each other),
> > and then (3) cbinds them together.
> >
> > Here is an example using the case where I know how many matrices I
> > need to cbind together. For this example, 2 square (3x3) matrices:
> >
> >  a <- matrix(c,0,20,50,0.05,0,0,0,0.1,0),3,3,byrow=T)
> >  b <- matrix(c(0,15,45,0.15,0,0,0,0.2,0),3,3,byrow=T)
> >
> > I want to vec them, and then cbind them together. So,
> >
> > result  <- cbind(matrix(a,nr=9), matrix(b,nr=9))
> >
> > which yields the following:
> >
> >       [,1]  [,2]
> >  [1,]  0.00  0.00
> >  [2,]  0.05  0.15
> >  [3,]  0.00  0.00
> >  [4,] 20.00 15.00
> >  [5,]  0.00  0.00
> >  [6,]  0.10  0.20
> >  [7,] 50.00 45.00
> >  [8,]  0.00  0.00
> >  [9,]  0.00  0.00
> >
> > Easy enough. But, I want to put it in a function, where the number and
> > dimensions  of the matrices is not specified. Something like
> >
> > Using matrices (a) and (b) from above, let
> >
> >   env <- list(a,b).
> >
> > Now, a function (or attempt at same) to perform the desired operations:
> >
> >   vec=function(matlist) {
> >
> >       n_mat=length(matlist);
> >       size_mat=dim(matlist[[1]])[1];
> >
> >       result=cbind()
> >
> >        for (i in 1:n_mat) {
> >          result=cbind(result,matrix(matlist[[i]],nr=size_mat^2))
> >                           }
> >
> >      return(result)
> >
> >    }
> >
> >
> > When I run vec(env), I get the *right answer*, but I am wondering if
> > there is a *better* way to get there from here than the approach I use
> > (above). I'm not so much interested in 'computational efficiency' as I
> > am in stability, and flexibility.
> >
> > Thanks...
> >
> > .
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From evan.cooch at gmail.com  Thu Oct  9 21:15:40 2014
From: evan.cooch at gmail.com (Evan Cooch)
Date: Thu, 09 Oct 2014 15:15:40 -0400
Subject: [R] cbind in a loop...better way? | summary
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726F9EEFF@mb02.ads.tamu.edu>
References: <54358CB0.6090506@gmail.com> <5436816B.3040501@gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726F9EEFF@mb02.ads.tamu.edu>
Message-ID: <5436DEDC.6060405@gmail.com>

Thanks!

On 10/9/2014 1:52 PM, David L Carlson wrote:
> Actually Jeff Laake's can be made even shorter with
>
> sapply(mat_list, as.vector)
>
> David C
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Evan Cooch
> Sent: Thursday, October 9, 2014 7:37 AM
> To: Evan Cooch; r-help at r-project.org
> Subject: Re: [R] cbind in a loop...better way? | summary
>
> Two solutions proposed -- not entirely orthogonal, but both do the
> trick. Instead of nesting cbin in a loop (as I did originally -- OP,
> below),
>
> 1\   do.call(cbind, lapply(mat_list, as.vector))
>
> or
>
> 2\   sapply(mat_list,function(x) as.vector(x))
>
>
> Both work fine. Thanks to Jeff Laake (2) + David Carlson (1) for their
> suggestions.
>
>
> On 10/8/2014 3:12 PM, Evan Cooch wrote:
>> ...or some such. I'm trying to work up a function wherein the user
>> passes a list of matrices to the function, which then (1) takes each
>> matrix, (2) performs an operation to 'vectorize' the matrix (i.e.,
>> given an (m x n) matrix x, this produces the vector Y of length  m*n
>> that contains the columns of the matrix x, stacked below each other),
>> and then (3) cbinds them together.
>>
>> Here is an example using the case where I know how many matrices I
>> need to cbind together. For this example, 2 square (3x3) matrices:
>>
>>   a <- matrix(c,0,20,50,0.05,0,0,0,0.1,0),3,3,byrow=T)
>>   b <- matrix(c(0,15,45,0.15,0,0,0,0.2,0),3,3,byrow=T)
>>
>> I want to vec them, and then cbind them together. So,
>>
>> result  <- cbind(matrix(a,nr=9), matrix(b,nr=9))
>>
>> which yields the following:
>>
>>        [,1]  [,2]
>>   [1,]  0.00  0.00
>>   [2,]  0.05  0.15
>>   [3,]  0.00  0.00
>>   [4,] 20.00 15.00
>>   [5,]  0.00  0.00
>>   [6,]  0.10  0.20
>>   [7,] 50.00 45.00
>>   [8,]  0.00  0.00
>>   [9,]  0.00  0.00
>>
>> Easy enough. But, I want to put it in a function, where the number and
>> dimensions  of the matrices is not specified. Something like
>>
>> Using matrices (a) and (b) from above, let
>>
>>    env <- list(a,b).
>>
>> Now, a function (or attempt at same) to perform the desired operations:
>>
>>    vec=function(matlist) {
>>
>>        n_mat=length(matlist);
>>        size_mat=dim(matlist[[1]])[1];
>>
>>        result=cbind()
>>
>>         for (i in 1:n_mat) {
>>           result=cbind(result,matrix(matlist[[i]],nr=size_mat^2))
>>                            }
>>
>>       return(result)
>>
>>     }
>>
>>
>> When I run vec(env), I get the *right answer*, but I am wondering if
>> there is a *better* way to get there from here than the approach I use
>> (above). I'm not so much interested in 'computational efficiency' as I
>> am in stability, and flexibility.
>>
>> Thanks...
>>
>> .
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> .
>


From ivaniaandrade21 at gmail.com  Thu Oct  9 18:38:37 2014
From: ivaniaandrade21 at gmail.com (Ivania Andrade)
Date: Thu, 9 Oct 2014 09:38:37 -0700
Subject: [R] Windows RT
Message-ID: <CAMSuU5xGgdLyLHGkpRHRBZk=ATyKrdECiARdzhvfJYsvH3bd+A@mail.gmail.com>

Hello,

I have a 32 GB Surface Windows RT and I am trying to download R, but it's
not letting me. Is there a certain way I am suppose to download it? Thank
you for any help you may provide.

Ivania Andrade

	[[alternative HTML version deleted]]


From john at formby.plus.com  Thu Oct  9 18:43:35 2014
From: john at formby.plus.com (John Hodgson)
Date: Thu, 09 Oct 2014 17:43:35 +0100
Subject: [R] Odd error from mvrnorm?
Message-ID: <5436BB37.5050203@formby.plus.com>

I have tried to generate multivariate normal samples with the following 
means and co-variances

 > mu
[1]  1.4696642  6.3169666 -3.8702044  0.8411024 -2.6525455 6.1894152
 > Sigma
                [,1]         [,2]          [,3] [,4]            
[,5]        [,6]
[1,]  0.00015768570  0.002258112 -0.0007021312    0.007184825 
-0.00009748966  -0.2297289
[2,]  0.00225811184  0.456999600 -0.5582839996   -1.296776834 
0.97284350454  -5.1210395
[3,] -0.00070213121 -0.558284000  1.2288752207   -0.333759058 
-2.54049486833   4.5709810
[4,]  0.00718482510 -1.296776834 -0.3337590577 3443.775312311 
0.25065256727 -11.5361060
[5,] -0.00009748966  0.972843505 -2.5404948683    0.250652567 
6.42422097236 -15.2357478
[6,] -0.22972890073 -5.121039455  4.5709810480  -11.536106031 
-15.23574783025 422.4494214
 >
But get the following error message

 > mvrnorm(n=1,mu=mu,Sigma=Sigma)
Error in drop(mu) + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
   non-conformable arrays

I can see that the values in Sigma are extremely variable in magnitude, 
but the matrix is not singular,
and the error message does not seem to point in this direction.

Can anyone see what I'm missing, or suggest a line of attack?

Thanks

John Hodgson


From jdnewmil at dcn.davis.CA.us  Thu Oct  9 22:22:11 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 09 Oct 2014 14:22:11 -0600
Subject: [R] Windows RT
In-Reply-To: <CAMSuU5xGgdLyLHGkpRHRBZk=ATyKrdECiARdzhvfJYsvH3bd+A@mail.gmail.com>
References: <CAMSuU5xGgdLyLHGkpRHRBZk=ATyKrdECiARdzhvfJYsvH3bd+A@mail.gmail.com>
Message-ID: <782A7D23-4BB2-4987-9719-7FBA32037ED7@dcn.davis.CA.us>

That is a baffling description. I don't see how what "something" does to prevent you from transferring a file is related to R.

That said, installing could be a problem ... or not.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 9, 2014 10:38:37 AM MDT, Ivania Andrade <ivaniaandrade21 at gmail.com> wrote:
>Hello,
>
>I have a 32 GB Surface Windows RT and I am trying to download R, but
>it's
>not letting me. Is there a certain way I am suppose to download it?
>Thank
>you for any help you may provide.
>
>Ivania Andrade
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Thu Oct  9 22:24:29 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 09 Oct 2014 16:24:29 -0400
Subject: [R] Windows RT
In-Reply-To: <CAMSuU5xGgdLyLHGkpRHRBZk=ATyKrdECiARdzhvfJYsvH3bd+A@mail.gmail.com>
References: <CAMSuU5xGgdLyLHGkpRHRBZk=ATyKrdECiARdzhvfJYsvH3bd+A@mail.gmail.com>
Message-ID: <5436EEFD.9000202@gmail.com>

On 09/10/2014, 12:38 PM, Ivania Andrade wrote:
> Hello,
> 
> I have a 32 GB Surface Windows RT and I am trying to download R, but it's
> not letting me. Is there a certain way I am suppose to download it? Thank
> you for any help you may provide.

There's nothing really special about downloading R, but I don't know if
that OS can run it.  I think you'll have to ask Microsoft.

Duncan Murdoch

> 
> Ivania Andrade
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From pdalgd at gmail.com  Thu Oct  9 22:57:57 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 9 Oct 2014 22:57:57 +0200
Subject: [R] Odd error from mvrnorm?
In-Reply-To: <5436BB37.5050203@formby.plus.com>
References: <5436BB37.5050203@formby.plus.com>
Message-ID: <938FC33D-8195-4B03-94E7-299F371B67E4@gmail.com>


On 09 Oct 2014, at 18:43 , John Hodgson <john at formby.plus.com> wrote:

> I have tried to generate multivariate normal samples with the following means and co-variances
> 
> > mu
> [1]  1.4696642  6.3169666 -3.8702044  0.8411024 -2.6525455 6.1894152
> > Sigma
>               [,1]         [,2]          [,3] [,4]            [,5]        [,6]
> [1,]  0.00015768570  0.002258112 -0.0007021312    0.007184825 -0.00009748966  -0.2297289
> [2,]  0.00225811184  0.456999600 -0.5582839996   -1.296776834 0.97284350454  -5.1210395
> [3,] -0.00070213121 -0.558284000  1.2288752207   -0.333759058 -2.54049486833   4.5709810
> [4,]  0.00718482510 -1.296776834 -0.3337590577 3443.775312311 0.25065256727 -11.5361060
> [5,] -0.00009748966  0.972843505 -2.5404948683    0.250652567 6.42422097236 -15.2357478
> [6,] -0.22972890073 -5.121039455  4.5709810480  -11.536106031 -15.23574783025 422.4494214
> >
> But get the following error message
> 
> > mvrnorm(n=1,mu=mu,Sigma=Sigma)
> Error in drop(mu) + eS$vectors %*% diag(sqrt(pmax(ev, 0)), p) %*% t(X) :
>  non-conformable arrays
> 
> I can see that the values in Sigma are extremely variable in magnitude, but the matrix is not singular,
> and the error message does not seem to point in this direction.
> 
> Can anyone see what I'm missing, or suggest a line of attack?

Well, you could set options(error=recover) and have a look the components of the failing expression.

For a workaround, I'd try something like generating variates from the correlation matrix and 
scaling by the SD. 

Given that the diagonal elements vary by a factor of ~5e-8, it is actually surprising that there is no protests about hitting the tolerance of 1e-6, but that only kicks in when checking for _negative_ eigenvalues.

I can't seem to reproduce this, so you might need to state your R version etc. and provide some reproducible code.

- Peter D.

> 
> Thanks
> 
> John Hodgson
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Thu Oct  9 23:13:18 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 9 Oct 2014 14:13:18 -0700
Subject: [R] Windows RT
In-Reply-To: <5436EEFD.9000202@gmail.com>
References: <CAMSuU5xGgdLyLHGkpRHRBZk=ATyKrdECiARdzhvfJYsvH3bd+A@mail.gmail.com>
	<5436EEFD.9000202@gmail.com>
Message-ID: <4559B8C8-F22B-4216-A0CD-97A08BBA0700@comcast.net>


On Oct 9, 2014, at 1:24 PM, Duncan Murdoch wrote:

> On 09/10/2014, 12:38 PM, Ivania Andrade wrote:
>> Hello,
>> 
>> I have a 32 GB Surface Windows RT and I am trying to download R, but it's
>> not letting me. Is there a certain way I am suppose to download it? Thank
>> you for any help you may provide.
> 
> There's nothing really special about downloading R, but I don't know if
> that OS can run it.  I think you'll have to ask Microsoft.

Ivania;

Microsoft is unlikely to answer. You need to realize that the device you have does not use the same processor or software API used by regular Windows 8 machines. Programs need to be compiled for "Windows Runtime (WinRT)". Microsoft considers the incompatibility of the Surface with open source programs to be a "feature" protecting the unwise users from contamination by the outside world.

http://en.wikipedia.org/wiki/Windows_RT#Differences_from_Windows_8
http://en.wikipedia.org/wiki/Windows_RT#Software_compatibility

Welcome to the Hotel Microsoft.

-- 
David.
> 
> Duncan Murdoch
> 
>> 
>> Ivania Andrade
>> 
> 


David Winsemius
Alameda, CA, USA


From r.turner at auckland.ac.nz  Thu Oct  9 23:17:42 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 10 Oct 2014 10:17:42 +1300
Subject: [R] Bug in myintegrate in Elliptic package
In-Reply-To: <CACNozQe_rddU6cLTUCMeXypbj8xjr4=U+kxtehYP+q4ofZChFw@mail.gmail.com>
References: <CACNozQe_rddU6cLTUCMeXypbj8xjr4=U+kxtehYP+q4ofZChFw@mail.gmail.com>
Message-ID: <5436FB76.50805@auckland.ac.nz>



(1) The example is not reproducible since we don't have "psi" or know 
what it is.

(2) The package is called "elliptic" *NOT* "Elliptic".  The R language 
(unlike Micro$oft crap) is case sensitive.

(3) The code was given in a chaotic manner, making it impossible to copy 
and paste it into an R console.

(4) That being said, it's pretty obvious what's going on.  ***Look at
the code*** for "myintegrate()".  It uses "x" as the dummy variable for
the function "f(x,...)" that is its first argument.  If you use "x" as
the name of one of the "..." arguments you wind up getting a call of
the form "f(x,x=0.1,psi_measure=psi)" --- no wonder the poor damned 
thing gets confused and gets it wrong.

Try:

    melvin <- function(x,...){x^2}
    melvin(2)
    melvin(2,x=5)

and you'll see the sort of thing that happens.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS

On 10/10/14 03:30, Luis Felipe Parra wrote:
> Hello,
>
> I was using my integrate today and spend a couple of hours trying to figure
> out why I was getting some weird results in my code when using myintegrate
> function to do complex integration, after some time decided just to change
> the name of the integration dummy variable in the code from 'x' to 'y' and
> the code worked perfectly, here is the outpus of what I was using:
>
>>    #Find the CDF to find the call prices
>>    CDF_Merton = function(y,psi_measure){
> +     integrand_cdf = function(u_vec,y,psi_measure)
> Im(exp(-1i*u_vec*y)*psi_measure(u_vec))/u_vec
> +   return(1/2 -
> 1/pi*Re(myintegrate(integrand_cdf,0,100,y=y,psi_measure=psi_measure)))
> +   }
>>    CDF_Merton(y=0.1,psi_measure=psi)
> [1] 0.9368239
>
>>
>>    CDF_Merton = function(x,psi_measure){
> +     integrand_cdf = function(u_vec,x,psi_measure)
> Im(exp(-1i*u_vec*x)*psi_measure(u_vec))/u_vec
> +   return(1/2 -
> 1/pi*Re(myintegrate(integrand_cdf,0,100,x=x,psi_measure=psi_measure)))
> +   }
>>    CDF_Merton(x=0.1,psi_measure=psi)
> [1] 59.03344
>
> where you can see that both codes are exactly the same except for the dummy
> variable used to integrate, does any body know what might be going on here?


From joseclaudio.faria at gmail.com  Fri Oct 10 02:56:08 2014
From: joseclaudio.faria at gmail.com (Jose Claudio Faria)
Date: Thu, 9 Oct 2014 21:56:08 -0300
Subject: [R] agricolae package: doubt about test used in kruskal and
	order.group function
Message-ID: <CAN+Emd9Rw2K=Q7rGEdBU2hRUiQw48nD29R+KtbqUAoOHeW_V2g@mail.gmail.com>

Hello,

Does anyone know which comparison test is applied in the function
order.group of the package agricolae?

The test is not documented nor in kruskal function or order.group
(called by kruskal function).

Thanks in advance,
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\
Jose Claudio Faria
Estatistica
UESC/DCET/Brasil
joseclaudio.faria at gmail.com
Telefones:
55(73)3680.5545 - UESC
55(73)9966.9100 - VIVO
55(73)9100.7351 - TIM
55(73)8817.6159 - OI
///\\\///\\\///\\\///\\\///\\\///\\\///\\\///\\\


From timhesterberg at gmail.com  Fri Oct 10 06:12:26 2014
From: timhesterberg at gmail.com (Tim Hesterberg)
Date: Thu, 9 Oct 2014 21:12:26 -0700
Subject: [R] How can I overwrite a method in R?
In-Reply-To: <COL129-W30E28B996CB526A1CF068CBA00@phx.gbl>
References: <CAAWNEwZNPp1P4_brEbsEHVQZf+tc7zDGMGvbTKgiG6mMdQno5A@mail.gmail.com>
	<CABdHhvGBy6TeKYXPS9f9rG-OfHAOJegf_5SowtLR-fMkA1iWQw@mail.gmail.com>
	<COL129-W30E28B996CB526A1CF068CBA00@phx.gbl>
Message-ID: <CAAWNEwbK6jYehBgA5ubALCoDYu1tog+KGQXAPfVL98=+ZZcjnQ@mail.gmail.com>

Thank you Duncan, Brian, Hadley, and Lin.

In Lin's suggestion, I believe the latter two statements should be
reversed, so that the environment is added before the function is placed
into the graphics namespace.

source('plot.histogram.R')
environment(plot.histogram) <- asNamespace('graphics')
assignInNamespace('plot.histogram', plot.histogram, ns='graphics')

The middle statement could also be
environment(plot.histogram) <- environment(graphics:::plot.histogram)
The point is to ensure that the replacement version has the same
environment as the original.

Having tested this, I will now submit a bug report :-)

On Thu, Oct 9, 2014 at 9:11 AM, C Lin <baccts at hotmail.com> wrote:

> I posted similar question a while ago. Search for "modify function in a
> package".
> In your case, the following should work.
>
> source('plot.histogram.R')
> assignInNamespace('plot.histogram',plot.histogram,ns='graphics')
> environment(plot.histogram) <- asNamespace('graphics');
>
> Assuming you have your own plot.histogram function inside
> "plot.histogram.R" and the plot.histogram function you are trying to
> overwrite is in graphics package.
>
> Lin
>
> ----------------------------------------
> > From: h.wickham at gmail.com
> > Date: Thu, 9 Oct 2014 07:00:31 -0500
> > To: timhesterberg at gmail.com
> > CC: R-help at stat.math.ethz.ch
> > Subject: Re: [R] How can I overwrite a method in R?
> >
> > This is usually ill-advised, but I think it's the right solution for
> > your problem:
> >
> > assignInNamespace("plot.histogram", function(...) plot(1:10), "graphics")
> > hist(1:10)
> >
> > Haley
> >
> > On Thu, Oct 9, 2014 at 1:14 AM, Tim Hesterberg <timhesterberg at gmail.com>
> wrote:
> >> How can I create an improved version of a method in R, and have it be
> used?
> >>
> >> Short version:
> >> I think plot.histogram has a bug, and I'd like to try a version with a
> fix.
> >> But when I call hist(), my fixed version doesn't get used.
> >>
> >> Long version:
> >> hist() calls plot() which calls plot.histogram() which fails to pass ...
> >> when it calls plot.window().
> >> As a result hist() ignores xaxs and yaxs arguments.
> >> I'd like to make my own copy of plot.histogram that passes ... to
> >> plot.window().
> >>
> >> If I just make my own copy of plot.histogram, plot() ignores it,
> because my
> >> version is not part of the same graphics package that plot belongs to.
> >>
> >> If I copy hist, hist.default and plot, the copies inherit the same
> >> environments as
> >> the originals, and behave the same.
> >>
> >> If I also change the environment of each to .GlobalEnv, hist.default
> fails
> >> in
> >> a .Call because it cannot find C_BinCount.
> >>
> >> [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > http://had.co.nz/
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>



-- 
Tim Hesterberg
http://www.timhesterberg.net
 (resampling, water bottle rockets, computers to Costa Rica, hot shower =
2650 light bulbs, ...)

Help your students understand statistics:
    Mathematical Statistics with Resampling and R, Chihara & Hesterberg
http://www.timhesterberg.net/bootstrap/

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Oct 10 07:24:49 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 10 Oct 2014 13:24:49 +0800 (CST)
Subject: [R]  how to break the loop using sapply?
Message-ID: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>


Dear expeRts,
?? i? use sapply for loop,?and i want to break it when i needed, how to do that?? e.g.

sapply( 1:10, function(i) {
if(i==5) break and jump out of the function sapply
} )

I want to do it because i have to loop 1000000 times, but i don't know when it will break, that means, it may need break at i=5 or at i=50000, for the possible of the? last case, i don't use for loop, because it slow(is it right?).
So,if you happen to know it ,may you help me?


--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From jdnewmil at dcn.davis.CA.us  Fri Oct 10 07:58:29 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 09 Oct 2014 22:58:29 -0700
Subject: [R] how to break the loop using sapply?
In-Reply-To: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>
References: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>
Message-ID: <08AA0866-F1AD-4080-B6B0-71D575042CD8@dcn.davis.CA.us>

Don't use apply functions if you want to do what you describe. They don't work that way. Use a while control structure.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 9, 2014 10:24:49 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>
>Dear expeRts,
>?? i? use sapply for loop,?and i want to break it when i needed, how to
>do that?? e.g.
>
>sapply( 1:10, function(i) {
>if(i==5) break and jump out of the function sapply
>} )
>
>I want to do it because i have to loop 1000000 times, but i don't know
>when it will break, that means, it may need break at i=5 or at i=50000,
>for the possible of the? last case, i don't use for loop, because it
>slow(is it right?).
>So,if you happen to know it ,may you help me?
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From statistics84 at hotmail.com  Fri Oct 10 08:04:57 2014
From: statistics84 at hotmail.com (pari hesabi)
Date: Fri, 10 Oct 2014 06:04:57 +0000
Subject: [R] maximum likelihood estimation
Message-ID: <DUB125-W4384FAAE61C192C373C0B7C6A10@phx.gbl>

Hello,As an example for Exponential distribution the MLE is got by this structure:t <- rexp(100, 2)loglik <- function(theta){ log(theta) - theta*t}a <- maxLik(loglik, start=1)print(a)Exponential distribution has a simple loglikelihood function.  But if a new pdf has a more complicated form like:pr(N(2)=n)= integral( ((2-x)^n)*(exp(ax-2))) - integral (((5-ax)^n)), both integrals are defined over the interval(0,2) with respect to x.   I  also need to use the loglike of the form : [F log(pr(n))]=lnL  where F is the vector of observations and (n) is the vector of input for  the defined pmf.  Do you think how I can insert (define) the  pr(n) in the loop below?  loglik <- function(a) sum(F*(log(pr(n)))?> > n <- c(0,1,2,3,4,5,6,7,8)> > F<-c(0,0,1,3,5,7,8,11,10)> > loglik <- function(a) sum(F*(log(pr(n)))??????> > re <- maxLik (loglik, start=.5)> > summary(re)I would be grateful if you let me know your idea.Best Regards,pari 		 	   		  
	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Oct 10 08:12:33 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 10 Oct 2014 14:12:33 +0800 (CST)
Subject: [R] how to break the loop using sapply?
In-Reply-To: <08AA0866-F1AD-4080-B6B0-71D575042CD8@dcn.davis.CA.us>
References: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>
	<08AA0866-F1AD-4080-B6B0-71D575042CD8@dcn.davis.CA.us>
Message-ID: <5804a06f.10e5c.148f8aff242.Coremail.rhelpmaillist@163.com>



Is that mean while may be more effient than? for in R? as i know, while and for? are all just functions in R. 
Tks for your suggestion to not use apply that way, but i want to know, if possible, is there any way to break it ?
Actually, there is a additional question:
? x<- c(3,4,5,6,9)
?sapply(x ,function(i){
foo(i)? #do something to each value in x,how can i know the i's index in x?
)}
In my way , i always 
sapply(seq(x),function(i){
foo(x[i])
})
or 
Map( function(i,index){
foo(i)? # through index to know the i's index in x
},x ,seq(x)) 

How you solve the problem? I mean just use apply functions.



--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-10-10 13:58:29, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us> wrote:
>Don't use apply functions if you want to do what you describe. They don't work that way. Use a while control structure.
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>--------------------------------------------------------------------------- 
>Sent from my phone. Please excuse my brevity.
>
>On October 9, 2014 10:24:49 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>>
>>Dear expeRts,
>>?? i? use sapply for loop,?and i want to break it when i needed, how to
>>do that?? e.g.
>>
>>sapply( 1:10, function(i) {
>>if(i==5) break and jump out of the function sapply
>>} )
>>
>>I want to do it because i have to loop 1000000 times, but i don't know
>>when it will break, that means, it may need break at i=5 or at i=50000,
>>for the possible of the? last case, i don't use for loop, because it
>>slow(is it right?).
>>So,if you happen to know it ,may you help me?
>>
>>
>>--
>>
>>PO SU
>>mail: desolator88 at 163.com 
>>Majored in Statistics from SJTU
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>

From ntfredo at gmail.com  Fri Oct 10 08:32:38 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Fri, 10 Oct 2014 09:32:38 +0300
Subject: [R] Changing date format
In-Reply-To: <54368409.6010104@gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
	<12845409.rVEsxnvE7c@localhost.localdomain>
	<CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>
	<54368409.6010104@gmail.com>
Message-ID: <CAGh51gQO1h6_NoygB0dQWBTQTDUs3b4wSxsVxSP2ZFga8Sd-fA@mail.gmail.com>

Dear All,

The following function gives me what I wanted.
The input of function is one value and this push me to use sapply function
to call it.

Is there a better way of doing this?

#====================================================
day <- function(x){

         if(x== 60) {
               y = "29 Feb"
         }

         if(x < 60){
                y =  format(strptime(x, format = "%j"), format ="%d-%b")
        }

        if(x > 60){
                y =  format(strptime(x - 1, format = "%j"), format ="%d-%b")
       }
    y
}

sapply(Samaru$Start,day)

 [1] "17-Apr" "27-Apr" "24-Apr" "04-Jun" "25-Apr" "13-May" "22-Apr"
"05-May" "27-Apr" "13-May" "27-Apr"
#=======================================================


On Thu, Oct 9, 2014 at 3:48 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 09/10/2014, 8:27 AM, PIKAL Petr wrote:
> > Hi
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Frederic Ntirenganya
> >> Sent: Thursday, October 09, 2014 1:32 PM
> >> To: Jim Lemon
> >> Cc: r-help at r-project.org
> >> Subject: Re: [R] Changing date format
> >>
> >> This idea substract 1 for the all column which is not what i want.
> >>
> >> We know that the leap years have 366 days. I don't need to change
> >> anything on them
> >>
> >> the non-leap years have 365 days. This is what i want to change to be
> >> 366 days rather than 365 days.
> >
> > But this is a question of calendar reform not R. I must admit it would
> be a tough job as leap day is needed to stay in tune with solar year. Your
> suggestion would quickly result in out of sync with the Sun.
>
> R Core is powerful, but I doubt if we could reform the calendar in this
> way.
>
> And I'd be against it in any case:  I like to swim on my summer
> vacations, but if August slipped into the winter, the lakes around here
> would be frozen.
>
> Duncan Murdoch
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 10 08:37:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 09 Oct 2014 23:37:16 -0700
Subject: [R] how to break the loop using sapply?
In-Reply-To: <5804a06f.10e5c.148f8aff242.Coremail.rhelpmaillist@163.com>
References: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>
	<08AA0866-F1AD-4080-B6B0-71D575042CD8@dcn.davis.CA.us>
	<5804a06f.10e5c.148f8aff242.Coremail.rhelpmaillist@163.com>
Message-ID: <F0B51426-06A5-4D5B-8E27-C85FB4168C80@dcn.davis.CA.us>

Is it possible to break it? I already told you that... NO. Also your mention of efficiency is not relevant. Keep in mind that apply functions are not significantly faster than for loops or while loops. They are just compact ways to express your intent. Usually people having speed problems with for loops are doing something wasteful inside their loop.

Re you're alternate question: you can't do that either. Your use of seq is the correct way if that is what you want to do.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 9, 2014 11:12:33 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>
>
>Is that mean while may be more effient than? for in R? as i know, while
>and for? are all just functions in R. 
>Tks for your suggestion to not use apply that way, but i want to know,
>if possible, is there any way to break it ?
>Actually, there is a additional question:
>? x<- c(3,4,5,6,9)
>?sapply(x ,function(i){
>foo(i)? #do something to each value in x,how can i know the i's index
>in x?
>)}
>In my way , i always 
>sapply(seq(x),function(i){
>foo(x[i])
>})
>or 
>Map( function(i,index){
>foo(i)? # through index to know the i's index in x
>},x ,seq(x)) 
>
>How you solve the problem? I mean just use apply functions.
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>
>
>
>
>At 2014-10-10 13:58:29, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
>wrote:
>>Don't use apply functions if you want to do what you describe. They
>don't work that way. Use a while control structure.
>>
>>---------------------------------------------------------------------------
>>Jeff Newmiller                        The     .....       .....  Go
>Live...
>>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>---------------------------------------------------------------------------
>
>>Sent from my phone. Please excuse my brevity.
>>
>>On October 9, 2014 10:24:49 PM PDT, PO SU <rhelpmaillist at 163.com>
>wrote:
>>>
>>>Dear expeRts,
>>>?? i? use sapply for loop,?and i want to break it when i needed, how
>to
>>>do that?? e.g.
>>>
>>>sapply( 1:10, function(i) {
>>>if(i==5) break and jump out of the function sapply
>>>} )
>>>
>>>I want to do it because i have to loop 1000000 times, but i don't
>know
>>>when it will break, that means, it may need break at i=5 or at
>i=50000,
>>>for the possible of the? last case, i don't use for loop, because it
>>>slow(is it right?).
>>>So,if you happen to know it ,may you help me?
>>>
>>>
>>>--
>>>
>>>PO SU
>>>mail: desolator88 at 163.com 
>>>Majored in Statistics from SJTU
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>


From hpages at fhcrc.org  Fri Oct 10 08:44:47 2014
From: hpages at fhcrc.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Thu, 09 Oct 2014 23:44:47 -0700
Subject: [R] how to break the loop using sapply?
In-Reply-To: <5804a06f.10e5c.148f8aff242.Coremail.rhelpmaillist@163.com>
References: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>	<08AA0866-F1AD-4080-B6B0-71D575042CD8@dcn.davis.CA.us>
	<5804a06f.10e5c.148f8aff242.Coremail.rhelpmaillist@163.com>
Message-ID: <5437805F.5050807@fhcrc.org>

Hi,

On 10/09/2014 11:12 PM, PO SU wrote:
>
>
> Is that mean while may be more effient than  for in R? as i know, while and for  are all just functions in R.
> Tks for your suggestion to not use apply that way, but i want to know, if possible, is there any way to break it ?

As Jeff said, you cannot break the loop that happens inside
the sapply() call. Also it is *not* true that for or while are
less efficient than sapply() or lapply():

 > a <- numeric(100000)

 > system.time(for (i in 1:100000) {a[i] <- i * (i - 1) / 2})
    user  system elapsed
   0.148   0.000   0.147

 > system.time(b <- sapply(1:100000, function(i) {i * (i - 1) / 2}))
    user  system elapsed
   0.194   0.007   0.201

 > identical(a, b)
[1] TRUE

 > system.time(c <- unlist(lapply(1:100000, function(i) {i * (i - 1) / 2})))
    user  system elapsed
   0.116   0.000   0.119

 > identical(a, c)
[1] TRUE

OK lapply() is maybe slightly faster but not significantly. And the
more work you need to do inside the loop, the less significant this
difference will be.

> Actually, there is a additional question:
>    x<- c(3,4,5,6,9)
>   sapply(x ,function(i){
> foo(i)  #do something to each value in x,how can i know the i's index in x?
> )}

You can't. Inside the anonymous function, you only have access to 'i'
which is an element of 'x', not its index in 'x'.

> In my way , i always
> sapply(seq(x),function(i){
> foo(x[i])
> })

Yes, if you want to loop on the index instead of the elements, you
need to do something like that. Using seq_along(x) is probably
cleaner than seq(x) for this.

Cheers,
H.

> or
> Map( function(i,index){
> foo(i)  # through index to know the i's index in x
> },x ,seq(x))
>
> How you solve the problem? I mean just use apply functions.
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
>
> At 2014-10-10 13:58:29, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us> wrote:
>> Don't use apply functions if you want to do what you describe. They don't work that way. Use a while control structure.
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 9, 2014 10:24:49 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>>>
>>> Dear expeRts,
>>>     i  use sapply for loop, and i want to break it when i needed, how to
>>> do that?  e.g.
>>>
>>> sapply( 1:10, function(i) {
>>> if(i==5) break and jump out of the function sapply
>>> } )
>>>
>>> I want to do it because i have to loop 1000000 times, but i don't know
>>> when it will break, that means, it may need break at i=5 or at i=50000,
>>> for the possible of the  last case, i don't use for loop, because it
>>> slow(is it right?).
>>> So,if you happen to know it ,may you help me?
>>>
>>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From fsmairura at yahoo.com  Fri Oct 10 08:18:43 2014
From: fsmairura at yahoo.com (Franklin Mairura)
Date: Thu, 9 Oct 2014 23:18:43 -0700
Subject: [R] Bar plot in R with more than 2 factors
Message-ID: <1412921923.21473.YahooMailNeo@web162801.mail.bf1.yahoo.com>

Please help, it possible to make an r means barplot in R using base, where there are more than 2 factors and not with lattice, Franklin. 

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Oct 10 10:21:23 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 10 Oct 2014 16:21:23 +0800 (CST)
Subject: [R] how to break the loop using sapply?
In-Reply-To: <5437805F.5050807@fhcrc.org>
References: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>
	<08AA0866-F1AD-4080-B6B0-71D575042CD8@dcn.davis.CA.us>
	<5804a06f.10e5c.148f8aff242.Coremail.rhelpmaillist@163.com>
	<5437805F.5050807@fhcrc.org>
Message-ID: <76321064.26904.148f925e699.Coremail.rhelpmaillist@163.com>


OK,? it? seems that i misunderstand something,? i forget how and when i pick up the monition in my mind that " as possible as avoid using for loop".
TKS for all your suggestions!
But i still want the way to break sapply, if not exsits now,?create it ..... 
such as:
?sapply<-function(...){
out<-FALSE
.....
if(out==TRUE) return
}
sapply(1:10, function(i){
if(i=5)? out<-TRUE 
}
)
That means to rewrite sapply, and create a virable in it?, let called OUT, then mayebe in sapply(1:10,FUN)
FUN can use OUT. because i think in sapply,? FUN is an inner function,so it can use OUT.
when it let OUT=TRUE. sapply should be break..........







--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-10-10 14:44:47, "Herv? Pag?s" <hpages at fhcrc.org> wrote:
>Hi,
>
>On 10/09/2014 11:12 PM, PO SU wrote:
>>
>>
>> Is that mean while may be more effient than  for in R? as i know, while and for  are all just functions in R.
>> Tks for your suggestion to not use apply that way, but i want to know, if possible, is there any way to break it ?
>
>As Jeff said, you cannot break the loop that happens inside
>the sapply() call. Also it is *not* true that for or while are
>less efficient than sapply() or lapply():
>
> > a <- numeric(100000)
>
> > system.time(for (i in 1:100000) {a[i] <- i * (i - 1) / 2})
>    user  system elapsed
>   0.148   0.000   0.147
>
> > system.time(b <- sapply(1:100000, function(i) {i * (i - 1) / 2}))
>    user  system elapsed
>   0.194   0.007   0.201
>
> > identical(a, b)
>[1] TRUE
>
> > system.time(c <- unlist(lapply(1:100000, function(i) {i * (i - 1) / 2})))
>    user  system elapsed
>   0.116   0.000   0.119
>
> > identical(a, c)
>[1] TRUE
>
>OK lapply() is maybe slightly faster but not significantly. And the
>more work you need to do inside the loop, the less significant this
>difference will be.
>
>> Actually, there is a additional question:
>>    x<- c(3,4,5,6,9)
>>   sapply(x ,function(i){
>> foo(i)  #do something to each value in x,how can i know the i's index in x?
>> )}
>
>You can't. Inside the anonymous function, you only have access to 'i'
>which is an element of 'x', not its index in 'x'.
>
>> In my way , i always
>> sapply(seq(x),function(i){
>> foo(x[i])
>> })
>
>Yes, if you want to loop on the index instead of the elements, you
>need to do something like that. Using seq_along(x) is probably
>cleaner than seq(x) for this.
>
>Cheers,
>H.
>
>> or
>> Map( function(i,index){
>> foo(i)  # through index to know the i's index in x
>> },x ,seq(x))
>>
>> How you solve the problem? I mean just use apply functions.
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>>
>>
>>
>>
>> At 2014-10-10 13:58:29, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us> wrote:
>>> Don't use apply functions if you want to do what you describe. They don't work that way. Use a while control structure.
>>>
>>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>>                                       Live:   OO#.. Dead: OO#..  Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>> ---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On October 9, 2014 10:24:49 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>>>>
>>>> Dear expeRts,
>>>>     i  use sapply for loop, and i want to break it when i needed, how to
>>>> do that?  e.g.
>>>>
>>>> sapply( 1:10, function(i) {
>>>> if(i==5) break and jump out of the function sapply
>>>> } )
>>>>
>>>> I want to do it because i have to loop 1000000 times, but i don't know
>>>> when it will break, that means, it may need break at i=5 or at i=50000,
>>>> for the possible of the  last case, i don't use for loop, because it
>>>> slow(is it right?).
>>>> So,if you happen to know it ,may you help me?
>>>>
>>>>
>>>> --
>>>>
>>>> PO SU
>>>> mail: desolator88 at 163.com
>>>> Majored in Statistics from SJTU
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>-- 
>Herv? Pag?s
>
>Program in Computational Biology
>Division of Public Health Sciences
>Fred Hutchinson Cancer Research Center
>1100 Fairview Ave. N, M1-B514
>P.O. Box 19024
>Seattle, WA 98109-1024
>
>E-mail: hpages at fhcrc.org
>Phone:  (206) 667-5791
>Fax:    (206) 667-1319

From jim at bitwrit.com.au  Fri Oct 10 10:22:32 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 10 Oct 2014 19:22:32 +1100
Subject: [R] Bar plot in R with more than 2 factors
In-Reply-To: <1412921923.21473.YahooMailNeo@web162801.mail.bf1.yahoo.com>
References: <1412921923.21473.YahooMailNeo@web162801.mail.bf1.yahoo.com>
Message-ID: <10022104.RO9PDgGSXg@localhost.localdomain>

On Thu, 9 Oct 2014 11:18:43 PM Franklin Mairura wrote:
> Please help, it possible to make an r means barplot in R using base, 
where
> there are more than 2 factors and not with lattice, Franklin.
> 
Hi Franklin,
Have a look at the barNest function in the plotrix package.

Jim


From petr.pikal at precheza.cz  Fri Oct 10 10:55:55 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 10 Oct 2014 08:55:55 +0000
Subject: [R] Changing date format
In-Reply-To: <CAGh51gQO1h6_NoygB0dQWBTQTDUs3b4wSxsVxSP2ZFga8Sd-fA@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
	<12845409.rVEsxnvE7c@localhost.localdomain>
	<CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>
	<54368409.6010104@gmail.com>
	<CAGh51gQO1h6_NoygB0dQWBTQTDUs3b4wSxsVxSP2ZFga8Sd-fA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE9A94@SRVEXCHMBX.precheza.cz>

Hi

But It is not doing what you wanted.  It does not extend 365 days year to 366 days. Instead it will incorrectly rename all days after 28th February in non leap years

> format(strptime(59, format = "%j"), "%d-%b")
[1] "28-II"
> format(strptime(60, format = "%j"), "%d-%b")
[1] "01-III"
> format(strptime(61, format = "%j"), "%d-%b")
[1] "02-III"
> day(59)
[1] "28-II"
> day(60)
[1] "29 Feb"
> day(61)
[1] "01-III"

So the effect is that day 61 in 2014 which actually was 2nd of March after your function will be named 1st of March. As a result it will remove 31.December in non leap year as in that case you do not have 366th day.

I did not follow whole thread but my vague memory reminds me that you want change number of days for aligning with some data. I do not believe that anybody violates calendar in such a way that all years have 366 days.

I may be mistaken but isn?t ?merge function what you really want?

Petr


From: Frederic Ntirenganya [mailto:ntfredo at gmail.com]
Sent: Friday, October 10, 2014 8:33 AM
To: Duncan Murdoch
Cc: PIKAL Petr; r-help at r-project.org
Subject: Re: [R] Changing date format

Dear All,
The following function gives me what I wanted.
The input of function is one value and this push me to use sapply function to call it.

Is there a better way of doing this?
#====================================================
day <- function(x){

         if(x== 60) {
               y = "29 Feb"
         }

         if(x < 60){
                y =  format(strptime(x, format = "%j"), format ="%d-%b")
        }

        if(x > 60){
                y =  format(strptime(x - 1, format = "%j"), format ="%d-%b")
       }
    y
}

sapply(Samaru$Start,day)

 [1] "17-Apr" "27-Apr" "24-Apr" "04-Jun" "25-Apr" "13-May" "22-Apr" "05-May" "27-Apr" "13-May" "27-Apr"
#=======================================================

On Thu, Oct 9, 2014 at 3:48 PM, Duncan Murdoch <murdoch.duncan at gmail.com<mailto:murdoch.duncan at gmail.com>> wrote:
On 09/10/2014, 8:27 AM, PIKAL Petr wrote:
> Hi
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-<mailto:r-help-bounces at r->
>> project.org<http://project.org>] On Behalf Of Frederic Ntirenganya
>> Sent: Thursday, October 09, 2014 1:32 PM
>> To: Jim Lemon
>> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
>> Subject: Re: [R] Changing date format
>>
>> This idea substract 1 for the all column which is not what i want.
>>
>> We know that the leap years have 366 days. I don't need to change
>> anything on them
>>
>> the non-leap years have 365 days. This is what i want to change to be
>> 366 days rather than 365 days.
>
> But this is a question of calendar reform not R. I must admit it would be a tough job as leap day is needed to stay in tune with solar year. Your suggestion would quickly result in out of sync with the Sun.

R Core is powerful, but I doubt if we could reform the calendar in this
way.

And I'd be against it in any case:  I like to swim on my summer
vacations, but if August slipped into the winter, the lakes around here
would be frozen.

Duncan Murdoch



--
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za<mailto:fredo at aims.ac.za>
https://sites.google.com/a/aims.ac.za/fredo/

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

	[[alternative HTML version deleted]]


From abhinabaroy09 at gmail.com  Fri Oct 10 13:28:12 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Fri, 10 Oct 2014 16:58:12 +0530
Subject: [R] Count number of Fridays in a month
Message-ID: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>

Hi R helpers,

I want to write a function which will

1. Count the number of fridays in the current month ( to extract month from
given date) and also the number of fridays in the preceeding month

2. Calculate the ratio of the number of fridays in current month to the
number of fridays in the precceding month

3. Return a integer value calculated as
    ifelse(ratio>1,1,ifesle(ration<1,-1),0)

The date which is passed is in the format *'31-may-2014'*

So, given the date '31-may-2014'

Number of fridays in May2014 = 5
Number of fridays in Apr2014 = 4

Ratio = 5/4 >1
Hence, the function will return a value 1

I want to call the function by passing '31-may-2014' as an argument

How can this be done in R?

Any help will be appreciated

Thanks and regards,
Abhinaba

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Oct 10 13:44:17 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Oct 2014 07:44:17 -0400
Subject: [R] Count number of Fridays in a month
In-Reply-To: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
References: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
Message-ID: <5437C691.7020006@gmail.com>

On 10/10/2014, 7:28 AM, Abhinaba Roy wrote:
> Hi R helpers,
> 
> I want to write a function which will
> 
> 1. Count the number of fridays in the current month ( to extract month from
> given date) and also the number of fridays in the preceeding month
> 
> 2. Calculate the ratio of the number of fridays in current month to the
> number of fridays in the precceding month
> 
> 3. Return a integer value calculated as
>     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
> 
> The date which is passed is in the format *'31-may-2014'*
> 
> So, given the date '31-may-2014'
> 
> Number of fridays in May2014 = 5
> Number of fridays in Apr2014 = 4
> 
> Ratio = 5/4 >1
> Hence, the function will return a value 1
> 
> I want to call the function by passing '31-may-2014' as an argument
> 
> How can this be done in R?
> 
> Any help will be appreciated

Convert your string to a POSIXlt object using as.POSIXlt.  Then you can
extract year, month and weekday from the result, and go from there.
(The only unobvious part is figuring out how many days are in each
month, but there are questions online giving various ways to do this.)

Duncan Murdoch


From jdnewmil at dcn.davis.CA.us  Fri Oct 10 13:59:59 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 10 Oct 2014 04:59:59 -0700
Subject: [R] how to break the loop using sapply?
In-Reply-To: <76321064.26904.148f925e699.Coremail.rhelpmaillist@163.com>
References: <591e7f45.20dcc.148f8843d0b.Coremail.rhelpmaillist@163.com>
	<08AA0866-F1AD-4080-B6B0-71D575042CD8@dcn.davis.CA.us>
	<5804a06f.10e5c.148f8aff242.Coremail.rhelpmaillist@163.com>
	<5437805F.5050807@fhcrc.org>
	<76321064.26904.148f925e699.Coremail.rhelpmaillist@163.com>
Message-ID: <7EFDC787-194F-4EB5-874D-344F14379CE8@dcn.davis.CA.us>

Doing as much as possible with vectors instead of loops of a good thing. Fooling yourself that apply functions are vectorized is, well, not a good thing.

If you want to write a function to use instead of sapply, fine, but don't call it *apply because those functions always give you one result for each input item you start with, and anyone who reads your code will be confused if you rename a standard function. I think you need to use ?while.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 10, 2014 1:21:23 AM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>
>OK,? it? seems that i misunderstand something,? i forget how and when i
>pick up the monition in my mind that " as possible as avoid using for
>loop".
>TKS for all your suggestions!
>But i still want the way to break sapply, if not exsits now,?create it
>..... 
>such as:
>?sapply<-function(...){
>out<-FALSE
>.....
>if(out==TRUE) return
>}
>sapply(1:10, function(i){
>if(i=5)? out<-TRUE 
>}
>)
>That means to rewrite sapply, and create a virable in it?, let called
>OUT, then mayebe in sapply(1:10,FUN)
>FUN can use OUT. because i think in sapply,? FUN is an inner
>function,so it can use OUT.
>when it let OUT=TRUE. sapply should be break..........
>
>
>
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>
>
>
>
>At 2014-10-10 14:44:47, "Herv? Pag?s" <hpages at fhcrc.org> wrote:
>>Hi,
>>
>>On 10/09/2014 11:12 PM, PO SU wrote:
>>>
>>>
>>> Is that mean while may be more effient than  for in R? as i know,
>while and for  are all just functions in R.
>>> Tks for your suggestion to not use apply that way, but i want to
>know, if possible, is there any way to break it ?
>>
>>As Jeff said, you cannot break the loop that happens inside
>>the sapply() call. Also it is *not* true that for or while are
>>less efficient than sapply() or lapply():
>>
>> > a <- numeric(100000)
>>
>> > system.time(for (i in 1:100000) {a[i] <- i * (i - 1) / 2})
>>    user  system elapsed
>>   0.148   0.000   0.147
>>
>> > system.time(b <- sapply(1:100000, function(i) {i * (i - 1) / 2}))
>>    user  system elapsed
>>   0.194   0.007   0.201
>>
>> > identical(a, b)
>>[1] TRUE
>>
>> > system.time(c <- unlist(lapply(1:100000, function(i) {i * (i - 1) /
>2})))
>>    user  system elapsed
>>   0.116   0.000   0.119
>>
>> > identical(a, c)
>>[1] TRUE
>>
>>OK lapply() is maybe slightly faster but not significantly. And the
>>more work you need to do inside the loop, the less significant this
>>difference will be.
>>
>>> Actually, there is a additional question:
>>>    x<- c(3,4,5,6,9)
>>>   sapply(x ,function(i){
>>> foo(i)  #do something to each value in x,how can i know the i's
>index in x?
>>> )}
>>
>>You can't. Inside the anonymous function, you only have access to 'i'
>>which is an element of 'x', not its index in 'x'.
>>
>>> In my way , i always
>>> sapply(seq(x),function(i){
>>> foo(x[i])
>>> })
>>
>>Yes, if you want to loop on the index instead of the elements, you
>>need to do something like that. Using seq_along(x) is probably
>>cleaner than seq(x) for this.
>>
>>Cheers,
>>H.
>>
>>> or
>>> Map( function(i,index){
>>> foo(i)  # through index to know the i's index in x
>>> },x ,seq(x))
>>>
>>> How you solve the problem? I mean just use apply functions.
>>>
>>>
>>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>>
>>>
>>>
>>>
>>> At 2014-10-10 13:58:29, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
>wrote:
>>>> Don't use apply functions if you want to do what you describe. They
>don't work that way. Use a while control structure.
>>>>
>>>>
>---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#. 
>Live Go...
>>>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#. 
>with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>>>
>---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On October 9, 2014 10:24:49 PM PDT, PO SU <rhelpmaillist at 163.com>
>wrote:
>>>>>
>>>>> Dear expeRts,
>>>>>     i  use sapply for loop, and i want to break it when i needed,
>how to
>>>>> do that?  e.g.
>>>>>
>>>>> sapply( 1:10, function(i) {
>>>>> if(i==5) break and jump out of the function sapply
>>>>> } )
>>>>>
>>>>> I want to do it because i have to loop 1000000 times, but i don't
>know
>>>>> when it will break, that means, it may need break at i=5 or at
>i=50000,
>>>>> for the possible of the  last case, i don't use for loop, because
>it
>>>>> slow(is it right?).
>>>>> So,if you happen to know it ,may you help me?
>>>>>
>>>>>
>>>>> --
>>>>>
>>>>> PO SU
>>>>> mail: desolator88 at 163.com
>>>>> Majored in Statistics from SJTU
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>-- 
>>Herv? Pag?s
>>
>>Program in Computational Biology
>>Division of Public Health Sciences
>>Fred Hutchinson Cancer Research Center
>>1100 Fairview Ave. N, M1-B514
>>P.O. Box 19024
>>Seattle, WA 98109-1024
>>
>>E-mail: hpages at fhcrc.org
>>Phone:  (206) 667-5791
>>Fax:    (206) 667-1319


From abhinabaroy09 at gmail.com  Fri Oct 10 14:10:02 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Fri, 10 Oct 2014 17:40:02 +0530
Subject: [R] Count number of Fridays in a month
In-Reply-To: <5437C691.7020006@gmail.com>
References: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
	<5437C691.7020006@gmail.com>
Message-ID: <CANtKHPWhqvdcijZGb8yPmxQ6kpEWEJvgqwF8RSgnDzjmg3DsLQ@mail.gmail.com>

Hi Duncan,

I have converted the string to a POSIXIt object using

> strptime('31-may-2014',format="%d-%b-%Y")

But could not figure out the way forward.

Could you please elaborate a bit?

On Fri, Oct 10, 2014 at 5:14 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 10/10/2014, 7:28 AM, Abhinaba Roy wrote:
> > Hi R helpers,
> >
> > I want to write a function which will
> >
> > 1. Count the number of fridays in the current month ( to extract month
> from
> > given date) and also the number of fridays in the preceeding month
> >
> > 2. Calculate the ratio of the number of fridays in current month to the
> > number of fridays in the precceding month
> >
> > 3. Return a integer value calculated as
> >     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
> >
> > The date which is passed is in the format *'31-may-2014'*
> >
> > So, given the date '31-may-2014'
> >
> > Number of fridays in May2014 = 5
> > Number of fridays in Apr2014 = 4
> >
> > Ratio = 5/4 >1
> > Hence, the function will return a value 1
> >
> > I want to call the function by passing '31-may-2014' as an argument
> >
> > How can this be done in R?
> >
> > Any help will be appreciated
>
> Convert your string to a POSIXlt object using as.POSIXlt.  Then you can
> extract year, month and weekday from the result, and go from there.
> (The only unobvious part is figuring out how many days are in each
> month, but there are questions online giving various ways to do this.)
>
> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Oct 10 14:16:09 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 10 Oct 2014 08:16:09 -0400
Subject: [R] Count number of Fridays in a month
In-Reply-To: <CANtKHPWhqvdcijZGb8yPmxQ6kpEWEJvgqwF8RSgnDzjmg3DsLQ@mail.gmail.com>
References: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
	<5437C691.7020006@gmail.com>
	<CANtKHPWhqvdcijZGb8yPmxQ6kpEWEJvgqwF8RSgnDzjmg3DsLQ@mail.gmail.com>
Message-ID: <5437CE09.6070704@gmail.com>

On 10/10/2014 8:10 AM, Abhinaba Roy wrote:
> Hi Duncan,
>
> I have converted the string to a POSIXIt object using
>
> > strptime('31-may-2014',format="%d-%b-%Y")
>
> But could not figure out the way forward.
>
> Could you please elaborate a bit?

Try this:

?POSIXlt

Duncan Murdoch

>
> On Fri, Oct 10, 2014 at 5:14 PM, Duncan Murdoch 
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 10/10/2014, 7:28 AM, Abhinaba Roy wrote:
>     > Hi R helpers,
>     >
>     > I want to write a function which will
>     >
>     > 1. Count the number of fridays in the current month ( to extract
>     month from
>     > given date) and also the number of fridays in the preceeding month
>     >
>     > 2. Calculate the ratio of the number of fridays in current month
>     to the
>     > number of fridays in the precceding month
>     >
>     > 3. Return a integer value calculated as
>     >     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
>     >
>     > The date which is passed is in the format *'31-may-2014'*
>     >
>     > So, given the date '31-may-2014'
>     >
>     > Number of fridays in May2014 = 5
>     > Number of fridays in Apr2014 = 4
>     >
>     > Ratio = 5/4 >1
>     > Hence, the function will return a value 1
>     >
>     > I want to call the function by passing '31-may-2014' as an argument
>     >
>     > How can this be done in R?
>     >
>     > Any help will be appreciated
>
>     Convert your string to a POSIXlt object using as.POSIXlt.  Then
>     you can
>     extract year, month and weekday from the result, and go from there.
>     (The only unobvious part is figuring out how many days are in each
>     month, but there are questions online giving various ways to do this.)
>
>     Duncan Murdoch
>
>


From b.rowlingson at lancaster.ac.uk  Fri Oct 10 14:56:19 2014
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Fri, 10 Oct 2014 13:56:19 +0100
Subject: [R] Count number of Fridays in a month
In-Reply-To: <070a13250cdf4da19444e5067257a2bd@EX-1-HT0.lancs.local>
References: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
	<5437C691.7020006@gmail.com>
	<CANtKHPWhqvdcijZGb8yPmxQ6kpEWEJvgqwF8RSgnDzjmg3DsLQ@mail.gmail.com>
	<070a13250cdf4da19444e5067257a2bd@EX-1-HT0.lancs.local>
Message-ID: <CANVKczOBad+4BPV6uKnLYVRDsV+Qt6pn7x_cCjnKeN4B_N7RhQ@mail.gmail.com>

Or try this:

fridays <- function(the_day){
    require(lubridate)
    day(the_day) = 1
    the_month = seq(the_day, the_day+months(1)-days(1),1)
    sum(wday(the_month) == 6)
}

That returns the number of Fridays in the month of a Date object given as arg:

> fridays(as.Date("2012-01-01"))
[1] 4
> fridays(as.Date("2012-02-01"))
[1] 4
> fridays(as.Date("2012-03-01"))
[1] 5
> fridays(as.Date("2012-04-01"))
[1] 4

Then you can build a function to compute the friday count ratio
between the month of a date and the previous month, given a data in
that string format you specified (d-m-y)

friday_ratio<- function(dayX){
    require(lubridate)
    the_day = as.Date(dmy(dayX))
    day(the_day)=1
    the_prev_month = the_day
    month(the_prev_month) = month(the_day)-1
    nf_current = fridays(the_day)
    nf_prev = fridays(the_prev_month)
    nf_current/nf_prev
}

> friday_ratio("31-may-2014")
[1] 1.25
> friday_ratio("1-may-2014")
[1] 1.25
> friday_ratio("1-jun-2014")
[1] 0.8
> friday_ratio("1-jul-2014")
[1] 1
> friday_ratio("1-aug-2014")
[1] 1.25

it is left as an exercise to convert this to the +1/0/-1 value - I
think the abs function may help...

Also, an exercise is to vectorise this over a vector of string dates.




On Fri, Oct 10, 2014 at 1:16 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 10/10/2014 8:10 AM, Abhinaba Roy wrote:
>> Hi Duncan,
>>
>> I have converted the string to a POSIXIt object using
>>
>> > strptime('31-may-2014',format="%d-%b-%Y")
>>
>> But could not figure out the way forward.
>>
>> Could you please elaborate a bit?
>
> Try this:
>
> ?POSIXlt
>
> Duncan Murdoch
>
>>
>> On Fri, Oct 10, 2014 at 5:14 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>
>>     On 10/10/2014, 7:28 AM, Abhinaba Roy wrote:
>>     > Hi R helpers,
>>     >
>>     > I want to write a function which will
>>     >
>>     > 1. Count the number of fridays in the current month ( to extract
>>     month from
>>     > given date) and also the number of fridays in the preceeding month
>>     >
>>     > 2. Calculate the ratio of the number of fridays in current month
>>     to the
>>     > number of fridays in the precceding month
>>     >
>>     > 3. Return a integer value calculated as
>>     >     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
>>     >
>>     > The date which is passed is in the format *'31-may-2014'*
>>     >
>>     > So, given the date '31-may-2014'
>>     >
>>     > Number of fridays in May2014 = 5
>>     > Number of fridays in Apr2014 = 4
>>     >
>>     > Ratio = 5/4 >1
>>     > Hence, the function will return a value 1
>>     >
>>     > I want to call the function by passing '31-may-2014' as an argument
>>     >
>>     > How can this be done in R?
>>     >
>>     > Any help will be appreciated
>>
>>     Convert your string to a POSIXlt object using as.POSIXlt.  Then
>>     you can
>>     extract year, month and weekday from the result, and go from there.
>>     (The only unobvious part is figuring out how many days are in each
>>     month, but there are questions online giving various ways to do this.)
>>
>>     Duncan Murdoch
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From arne.henningsen at gmail.com  Fri Oct 10 15:43:07 2014
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Fri, 10 Oct 2014 15:43:07 +0200
Subject: [R] maximum likelihood estimation
In-Reply-To: <DUB125-W4384FAAE61C192C373C0B7C6A10@phx.gbl>
References: <DUB125-W4384FAAE61C192C373C0B7C6A10@phx.gbl>
Message-ID: <CAMTWbJjsQqSgarT_1d4o6OKeTVnkzEwiHJsXSyshpkOzqd_m2g@mail.gmail.com>

On 10 October 2014 08:04, pari hesabi <statistics84 at hotmail.com> wrote:
> Hello,As an example for Exponential distribution the MLE is got by this structure:t <- rexp(100, 2)loglik <- function(theta){ log(theta) - theta*t}a <- maxLik(loglik, start=1)print(a)Exponential distribution has a simple loglikelihood function.  But if a new pdf has a more complicated form like:pr(N(2)=n)= integral( ((2-x)^n)*(exp(ax-2))) - integral (((5-ax)^n)), both integrals are defined over the interval(0,2) with respect to x.   I  also need to use the loglike of the form : [F log(pr(n))]=lnL  where F is the vector of observations and (n) is the vector of input for  the defined pmf.  Do you think how I can insert (define) the  pr(n) in the loop below?  loglik <- function(a) sum(F*(log(pr(n)))?> > n <- c(0,1,2,3,4,5,6,7,8)> > F<-c(0,0,1,3,5,7,8,11,10)> > loglik <- function(a) sum(F*(log(pr(n)))??????> > re <- maxLik (loglik, start=.5)> > summary(re)I would be grateful if you let me know your idea.Best Regards,pari

> [...]
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Your example is not reproducible:

> pr(N(2)=n)= integral( ((2-x)^n)*(exp(ax-2))) - integral (((5-ax)^n))
Error: unexpected '=' in "pr(N(2)="

Please format your email in a way that one can easily copy the R code
to the R console.

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From t.tasnuva at gmail.com  Fri Oct 10 16:16:54 2014
From: t.tasnuva at gmail.com (Tasnuva Tabassum)
Date: Fri, 10 Oct 2014 07:16:54 -0700
Subject: [R] (no subject)
Message-ID: <CA+wU8YCLhE+c7UKBmAv=VdW8jUpJFf3eDMLiF0BykNkTb73jZA@mail.gmail.com>

I want to get rid of this thread. what to do?

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Fri Oct 10 16:36:58 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Fri, 10 Oct 2014 16:36:58 +0200
Subject: [R] (no subject)
In-Reply-To: <CA+wU8YCLhE+c7UKBmAv=VdW8jUpJFf3eDMLiF0BykNkTb73jZA@mail.gmail.com>
References: <CA+wU8YCLhE+c7UKBmAv=VdW8jUpJFf3eDMLiF0BykNkTb73jZA@mail.gmail.com>
Message-ID: <CAHuTOvo4hBvNsmmhMz_j4Cz4XtCOQ=9Syd2CBe2vJcDshhjazg@mail.gmail.com>

follow instructions on
https://stat.ethz.ch/mailman/listinfo/r-help
at
"To unsubscribe from R-help, get a password reminder, or change your
subscription options enter your subscription email address: "
...

On 10 October 2014 16:16, Tasnuva Tabassum <t.tasnuva at gmail.com> wrote:
> I want to get rid of this thread. what to do?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From john.archie.mckown at gmail.com  Fri Oct 10 14:02:54 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Fri, 10 Oct 2014 07:02:54 -0500
Subject: [R] Changing date format
In-Reply-To: <CAGh51gQO1h6_NoygB0dQWBTQTDUs3b4wSxsVxSP2ZFga8Sd-fA@mail.gmail.com>
References: <CAGh51gRMhoajksi3CcjwwWwjmHp6fE1tu_hS4WHKaCOaFm_k1Q@mail.gmail.com>
	<42814805.aGzeENWWZQ@localhost.localdomain>
	<CAGh51gSfdaqDe4AG7Atv4yVxbpzCoEEAMXzCs-+yAg1jS20G1g@mail.gmail.com>
	<12845409.rVEsxnvE7c@localhost.localdomain>
	<CAGh51gTYsGP3F2wXPh5Y4rRKRuyg=r0-oLJMOaw1SjUy9yuA_w@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BE992A@SRVEXCHMBX.precheza.cz>
	<54368409.6010104@gmail.com>
	<CAGh51gQO1h6_NoygB0dQWBTQTDUs3b4wSxsVxSP2ZFga8Sd-fA@mail.gmail.com>
Message-ID: <CAAJSdjis=7Jgkq2_riQOq6LDxvjWJDG0HQGM1AFN1WBUt_Y_Cg@mail.gmail.com>

On Fri, Oct 10, 2014 at 1:32 AM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:

Please try to not post in HTML. It is one of the forum "rules".

> Dear All,
>
> The following function gives me what I wanted.
> The input of function is one value and this push me to use sapply function
> to call it.
>
> Is there a better way of doing this?
>
> #====================================================
> day <- function(x){
>
>          if(x== 60) {
>                y = "29 Feb"
>          }
>
>          if(x < 60){
>                 y =  format(strptime(x, format = "%j"), format ="%d-%b")
>         }
>
>         if(x > 60){
>                 y =  format(strptime(x - 1, format = "%j"), format ="%d-%b")
>        }
>     y
> }
>
> sapply(Samaru$Start,day)
>
>  [1] "17-Apr" "27-Apr" "24-Apr" "04-Jun" "25-Apr" "13-May" "22-Apr"
> "05-May" "27-Apr" "13-May" "27-Apr"
> #=======================================================

I make no comment about whether the above is "correct" or you, because
I don't know. There is much that I don't know. There is a way to
reformulate the function in a way that I personally think is better.
You might want to look at:

day <- function(x) { ifelse(x==60,"29
Feb",format(strptime(x-(x>60),format="%j"),format="%d-%b")); }

The "trick" is that x-(x>60) will subtract 1 from x when x is greater
than 60, but 0 if it is less than or equal to 60. And the ifelse takes
care of the case where x is equal to 60. As I said, I don't know that
this really gives you want, but it is functionally equivalent to the
code you posted. However, it is not as obvious. As we say about the
lottery: "You pay your money, you take your chance."


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From parvin_dehghani at yahoo.com  Fri Oct 10 14:38:04 2014
From: parvin_dehghani at yahoo.com (Parvin Dehghani)
Date: Fri, 10 Oct 2014 05:38:04 -0700
Subject: [R] Maximum likelihood Estimation
Message-ID: <1412944684.11754.YahooMailNeo@web141202.mail.bf1.yahoo.com>



maximum likelihood estimation
pari hesabi  
6:04 AM 
To: r-help at r-project.org
Hello,
As an example for Exponential distribution the MLE is got by this structure:
t <- rexp(100, 2)
loglik <- function(theta){ log(theta) - theta*t}
a <- maxLik(loglik, start=1)
print(a)

Exponential distribution has a simple loglikelihood function.  But if a new pdf has a more complicated form like:
pr(N(2)=n)= integral( ((2-x)^n)*(exp(ax-2))) - integral (((5-ax)^n)), both integrals are defined over the interval(0,2) with respect to x.  
 I  also need to use the loglike of the form : [F log(pr(n))]=lnL  where F is the vector of observations and (n) is the vector of input for  the defined pmf.  Do you think how I can insert (define) the  pr(n) in the loop below? 
My question is related to:    loglik <- function(a) sum(F*(log(pr(n)))?



> > n <- c(0,1,2,3,4,5,6,7,8)
> > F<-c(0,0,1,3,5,7,8,11,10)
> > loglik <- function(a) sum(F*(log(pr(n)))??????
> > re <- maxLik (loglik, start=.5)
> > summary(re)

I would be grateful if you let me know your idea.
Best Regards,
pari

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Oct 10 17:32:32 2014
From: jholtman at gmail.com (jim holtman)
Date: Fri, 10 Oct 2014 11:32:32 -0400
Subject: [R] Count number of Fridays
In-Reply-To: <CANtKHPU5rCjjBjyQNJ79jQTx2qgS3LK=hUqQoVyxC9=wEDuX1A@mail.gmail.com>
References: <CANtKHPU5rCjjBjyQNJ79jQTx2qgS3LK=hUqQoVyxC9=wEDuX1A@mail.gmail.com>
Message-ID: <CAAxdm-6g8Fy7xJ39o13NhNkDha3bMfv=mz-Y+JsB79j0rPii=A@mail.gmail.com>

Here is one way of doing it:


> require(lubridate)
> now <- as.Date('2014-10-10')  # some date
> # get first of month
> first_mon <- now - day(now) + 1
> # create sequence of days in the month so you can count Fridays
> x <- seq(first_mon, by = '1 day', length = days_in_month(first_mon))
> first_fri <- sum(wday(x) == 6)  # count fridays
> # first of previous month
> prev_mon <- first_mon - day(first_mon - 1)
> # create sequence of days in month
> x <- seq(prev_mon, by = '1 day', length = days_in_month(prev_mon))
> prev_fri <- sum(wday(x) == 6)
>
> cat('Fri this month:', first_fri, 'Fri last month:', prev_fri, '\n')
Fri this month: 5 Fri last month: 4
> sign(first_fri - prev_fri)  # will do the 'ifelse'-type test you want
[1] 1
>

Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.


On Fri, Oct 10, 2014 at 7:31 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi Jim,
>
> Thanks for your previous solution. I am learning to work with dates now.
>
> I want to write a function which will
>
> 1. Count the number of fridays in the current month ( to extract month from
> given date) and also the number of fridays in the preceeding month
>
> 2. Calculate the ratio of the number of fridays in current month to the
> number of fridays in the precceding month
>
> 3. Return a integer value calculated as
>     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
>
> The date which is passed is in the format '31-may-2014'
>
> So, given the date '31-may-2014'
>
> Number of fridays in May2014 = 5
> Number of fridays in Apr2014 = 4
>
> Ratio = 5/4 >1
> Hence, the function will return a value 1
>
> I want to call the function by passing '31-may-2014' as an argument
>
> How can this be done in R?
>
> Any help will be appreciated
>
> Thanks and regards,
> Abhinaba
>
> On Mon, Aug 4, 2014 at 9:36 PM, jim holtman <jholtman at gmail.com> wrote:
>>
>> Here is the solution using 'rle':
>>
>> > require(data.table)
>> > x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
>> +  CB26A    201302         1
>> +  CB26A    201302         0
>> +  CB26A    201302         0
>> +  CB26A    201303         1
>> +  CB26A    201303         1
>> +  CB26A    201304         0
>> +  CB26A    201305         1
>> +  CB26A    201305         0
>> +  CB26A    201306         1
>> +  CB27A    201304         0
>> +  CB27A    201304         0
>> +  CB27A    201305         1
>> +  CB27A    201306         1
>> +  CB27A    201306         0
>> +  CB27A    201307         0
>> +  CB27A    201308         1", header = TRUE, as.is = TRUE)
>> > setDT(x)
>> > # convert to a Date object for comparison
>> > x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
>> > # separate by CASE_ID and only keep the first 3 months
>> > x[
>> +      , {
>> +          # determine the end date as 3 months from the first date
>> +          endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
>> +          # now count the changes
>> +          list(nChanges = length(rle(ATT_1[(MYD >= MYD[1L]) & (MYD <=
>> endDate)])[[1L]]) - 1L)
>> +        }
>> +      , by = CASE_ID
>> +      ]
>>    CASE_ID nChanges
>> 1:   CB26A        5
>> 2:   CB27A        2
>>
>> Jim Holtman
>> Data Munger Guru
>>
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>>
>>
>> On Mon, Aug 4, 2014 at 11:39 AM, Bert Gunter <gunter.berton at gene.com>
>> wrote:
>> > Or ?rle
>> >
>> > Bert
>> >
>> >
>> >
>> > Sent from my iPhone -- please excuse typos.
>> >
>> >> On Aug 4, 2014, at 8:28 AM, jim holtman <jholtman at gmail.com> wrote:
>> >>
>> >> Try this, but I only get 2 changes for CB27A instead of you indicated
>> >> 3:
>> >>
>> >>> require(data.table)
>> >>> x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
>> >> + CB26A    201302         1
>> >> + CB26A    201302         0
>> >> + CB26A    201302         0
>> >> + CB26A    201303         1
>> >> + CB26A    201303         1
>> >> + CB26A    201304         0
>> >> + CB26A    201305         1
>> >> + CB26A    201305         0
>> >> + CB26A    201306         1
>> >> + CB27A    201304         0
>> >> + CB27A    201304         0
>> >> + CB27A    201305         1
>> >> + CB27A    201306         1
>> >> + CB27A    201306         0
>> >> + CB27A    201307         0
>> >> + CB27A    201308         1", header = TRUE, as.is = TRUE)
>> >>> setDT(x)
>> >>> # convert to a Date object for comparison
>> >>> x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
>> >>> # separate by CASE_ID and only keep the first 3 months
>> >>> x[
>> >> +     , {
>> >> +         # determine the end date as 3 months from the first date
>> >> +         endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
>> >> +         # extract what is changing
>> >> +         changes <- ATT_1[(MYD >= MYD[1L]) & (MYD <= endDate)]
>> >> +         # now count the changes
>> >> +         list(nChanges = sum(head(changes, -1L) != tail(changes,
>> >> -1L)))
>> >> +       }
>> >> +     , by = CASE_ID
>> >> +     ]
>> >>   CASE_ID nChanges
>> >> 1:   CB26A        5
>> >> 2:   CB27A        2
>> >>
>> >> Jim Holtman
>> >> Data Munger Guru
>> >>
>> >> What is the problem that you are trying to solve?
>> >> Tell me what you want to do, not how you want to do it.
>> >>
>> >>
>> >>> On Wed, Jul 30, 2014 at 3:08 AM, Abhinaba Roy
>> >>> <abhinabaroy09 at gmail.com> wrote:
>> >>> Dear R-helpers,
>> >>>
>> >>> I want to count the number of times ATT_1 has changed in a period of 3
>> >>> months(can be 4months) from the first YEAR_MTH entry for a CASE_ID. So
>> >>> if
>> >>> for a CASE_ID we have data only for two distinct YEAR_MTH, then all
>> >>> the
>> >>> entries should be considered, otherwise only the relevant entries will
>> >>> be
>> >>> considered for calculation.
>> >>> E.g. if the first YEAR_MTH entry is 201304 then get the number of
>> >>> changes
>> >>> till 201307(inclusive), similarly if the first YEAR_MTH entry is
>> >>> 201302
>> >>> then get the number of changes till 201305.
>> >>>
>> >>> Dataset
>> >>> CASE_ID YEAR_MTH ATT_1
>> >>> CB26A    201302         1
>> >>> CB26A    201302         0
>> >>> CB26A    201302         0
>> >>> CB26A    201303         1
>> >>> CB26A    201303         1
>> >>> CB26A    201304         0
>> >>> CB26A    201305         1
>> >>> CB26A    201305         0
>> >>> CB26A    201306         1
>> >>> CB27A    201304         0
>> >>> CB27A    201304         0
>> >>> CB27A    201305         1
>> >>> CB27A    201306         1
>> >>> CB27A    201306         0
>> >>> CB27A    201307         0
>> >>> CB27A    201308         1
>> >>>
>> >>> The final dataset should look like
>> >>>
>> >>> ID_CASE    No.of changes
>> >>> CB26A        5
>> >>> CB27A        3
>> >>>
>> >>> where 'No.of changes' refer to the change in 3 months (201302-201305
>> >>> for
>> >>> CB26A and 201304-201307 for CB27A).
>> >>>
>> >>> How can this be done in R?
>> >>>
>> >>> Regards,
>> >>> Abhinaba Roy
>> >>>
>> >>>        [[alternative HTML version deleted]]
>> >>>
>> >>> ______________________________________________
>> >>> R-help at r-project.org mailing list
>> >>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>> PLEASE do read the posting guide
>> >>> http://www.R-project.org/posting-guide.html
>> >>> and provide commented, minimal, self-contained, reproducible code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>
>


From ggrothendieck at gmail.com  Sat Oct 11 01:00:39 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 10 Oct 2014 19:00:39 -0400
Subject: [R] Count number of Fridays in a month
In-Reply-To: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
References: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
Message-ID: <CAP01uRnoWnwypH9ytwWtU2VyaNKkA28fROddEUhAB5gdrX+G1A@mail.gmail.com>

On Fri, Oct 10, 2014 at 7:28 AM, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
> Hi R helpers,
>
> I want to write a function which will
>
> 1. Count the number of fridays in the current month ( to extract month from
> given date) and also the number of fridays in the preceeding month
>
> 2. Calculate the ratio of the number of fridays in current month to the
> number of fridays in the precceding month
>
> 3. Return a integer value calculated as
>     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
>
> The date which is passed is in the format *'31-may-2014'*
>
> So, given the date '31-may-2014'
>
> Number of fridays in May2014 = 5
> Number of fridays in Apr2014 = 4
>
> Ratio = 5/4 >1
> Hence, the function will return a value 1
>
> I want to call the function by passing '31-may-2014' as an argument

If d is a "Date" class variable equal to a month end date, e.g.

   d <- as.Date("31-may-2014", format = "%d-%b-%Y")

then this gives the ratio of the number of Fridays in d's month
to the number of Fridays in the prior month:

   days <- seq(as.Date(cut(d - 32, "month")), d, "day")
   ratio <- exp(diff(log(tapply(format(days, "%w") == 5, format(days,
"%Y%m"), sum))))

Now apply the formula in your point 3 to ratio and put it all in a function.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From zhiqiu.hu at gmail.com  Sat Oct 11 01:13:22 2014
From: zhiqiu.hu at gmail.com (Zhiqiu Hu)
Date: Fri, 10 Oct 2014 17:13:22 -0600
Subject: [R] How to remove the second line generated by addHeader function
 in the rtf package
Message-ID: <CAJQNJzeKw6RWh9D4nH2wQJFLY6bsrEHBCdoLO6UwcvPn+=NqUQ@mail.gmail.com>

Dear friends,

The addHeader function in the rtf package always generates two rows of texts
even if a subtitle was not specified. Is there any way to stop the function
from generating the second blank line?

FYI, I cannot use the other functions, such as the addParagram and the
addText, because the addHeader function is the only one allowing to set up
TOC levels for contents.

I appreciate your kind help with the matters.

Sincerely,

Zhiqiu

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Sat Oct 11 04:55:32 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 11 Oct 2014 10:55:32 +0800 (CST)
Subject: [R] Count number of Fridays in a month
In-Reply-To: <5437C691.7020006@gmail.com>
References: <CANtKHPW6+omWmedk_rPSam0fiGquUu=2HTFv3_SHwa5_+iM5YQ@mail.gmail.com>
	<5437C691.7020006@gmail.com>
Message-ID: <442bf62a.5511.148fd21ed5c.Coremail.rhelpmaillist@163.com>


In my Impression, there seems? exsits a function (let just call weekday)?which can return a POSIXlt format date 's weekday. That means,? weekday( 31-may-2014 ) may return the right weekday maybe 5, so? a clumsy method is start to judge from 1-may-2014 to 31-may-2014 , you get? a vector x, sum(which(x==5)) should return the right number. so do the April-2014. 
FOR MORE EFFICIENT, may be you should look into the function weekday ( not the true name) to get how it work ,it may help you do less things to get what you want.
FOR weekday,sorry for my forgot of where it located, it may in ?POSIXlt? ?format? ? strptime and other?related keywords's document.





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-10-10 19:44:17, "Duncan Murdoch" <murdoch.duncan at gmail.com> wrote:
>On 10/10/2014, 7:28 AM, Abhinaba Roy wrote:
>> Hi R helpers,
>> 
>> I want to write a function which will
>> 
>> 1. Count the number of fridays in the current month ( to extract month from
>> given date) and also the number of fridays in the preceeding month
>> 
>> 2. Calculate the ratio of the number of fridays in current month to the
>> number of fridays in the precceding month
>> 
>> 3. Return a integer value calculated as
>>     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
>> 
>> The date which is passed is in the format *'31-may-2014'*
>> 
>> So, given the date '31-may-2014'
>> 
>> Number of fridays in May2014 = 5
>> Number of fridays in Apr2014 = 4
>> 
>> Ratio = 5/4 >1
>> Hence, the function will return a value 1
>> 
>> I want to call the function by passing '31-may-2014' as an argument
>> 
>> How can this be done in R?
>> 
>> Any help will be appreciated
>
>Convert your string to a POSIXlt object using as.POSIXlt.  Then you can
>extract year, month and weekday from the result, and go from there.
>(The only unobvious part is figuring out how many days are in each
>month, but there are questions online giving various ways to do this.)
>
>Duncan Murdoch
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From thanoon.younis80 at gmail.com  Sat Oct 11 06:09:13 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sat, 11 Oct 2014 07:09:13 +0300
Subject: [R] errors in initial values in R2winBUGS
Message-ID: <CABLo8nGRNC44YXTtMOqK3eXQvDMMFYUYgTX+xRj8kpGsHVwyKg@mail.gmail.com>

Dear all R users
I am trying to find the bayesian analysis using R2winBUGS but i have errors
in initial values with two groups.
the R-code
#Initial values for the MCMC in WinBUGS

init1<-list(uby1=rep(0.0,10),lam1=c(0.0,0.0,0.0,0.0,0.0,0.0),
gam1=c(1.0,1.0,1.0,1.0,1.0,1.0),psd1=1.0,phi1=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),uby2=rep(0.0,10),lam2=c(0.0,0.0,0.0,0.0,0.0,0.0),
gam2=c(1.0,1.0,1.0,1.0,1.0,1.0),psd2=1.0,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),

init2<-list(uby1=rep(0.5,10),lam1=c(0.5,0.5,0.5,0.5,0.5,0.5),
gam1=c(0.0,0.0,0.0,0.0,0.0,0.0),psd1=0.6,phi1=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),uby2=rep(0.5,10),lam2=c(0.5,0.5,0.5,0.5,0.5,0.5),
gam2=c(0.0,0.0,0.0,0.0,0.0,0.0),psd2=0.6,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),


and the errors are

Error: unexpected ',' in:
"3,byrow=TRUE),uby2=rep(0.0,10),lam2=c(0.0,0.0,0.0,0.0,0.0,0.0),
gam2=c(1.0,1.0,1.0,1.0,1.0,1.0),psd2=1.0,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),"

and

Error: unexpected ',' in:
"3,byrow=TRUE),uby2=rep(0.5,10),lam2=c(0.5,0.5,0.5,0.5,0.5,0.5),
gam2=c(0.0,0.0,0.0,0.0,0.0,0.0),psd2=0.6,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),"



any help would be greatly appreciated


-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From abhinabaroy09 at gmail.com  Sat Oct 11 08:06:15 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Sat, 11 Oct 2014 11:36:15 +0530
Subject: [R] Count number of Fridays
In-Reply-To: <CAAxdm-6g8Fy7xJ39o13NhNkDha3bMfv=mz-Y+JsB79j0rPii=A@mail.gmail.com>
References: <CANtKHPU5rCjjBjyQNJ79jQTx2qgS3LK=hUqQoVyxC9=wEDuX1A@mail.gmail.com>
	<CAAxdm-6g8Fy7xJ39o13NhNkDha3bMfv=mz-Y+JsB79j0rPii=A@mail.gmail.com>
Message-ID: <CANtKHPXKdk4n5MCxhcz10O+gQvrBzge60hJA=n33jpUuJ=ESTg@mail.gmail.com>

Thanks Jim :)

Regards
Abhinaba

On Fri, Oct 10, 2014 at 9:02 PM, jim holtman <jholtman at gmail.com> wrote:

> Here is one way of doing it:
>
>
> > require(lubridate)
> > now <- as.Date('2014-10-10')  # some date
> > # get first of month
> > first_mon <- now - day(now) + 1
> > # create sequence of days in the month so you can count Fridays
> > x <- seq(first_mon, by = '1 day', length = days_in_month(first_mon))
> > first_fri <- sum(wday(x) == 6)  # count fridays
> > # first of previous month
> > prev_mon <- first_mon - day(first_mon - 1)
> > # create sequence of days in month
> > x <- seq(prev_mon, by = '1 day', length = days_in_month(prev_mon))
> > prev_fri <- sum(wday(x) == 6)
> >
> > cat('Fri this month:', first_fri, 'Fri last month:', prev_fri, '\n')
> Fri this month: 5 Fri last month: 4
> > sign(first_fri - prev_fri)  # will do the 'ifelse'-type test you want
> [1] 1
> >
>
> Jim Holtman
> Data Munger Guru
>
> What is the problem that you are trying to solve?
> Tell me what you want to do, not how you want to do it.
>
>
> On Fri, Oct 10, 2014 at 7:31 AM, Abhinaba Roy <abhinabaroy09 at gmail.com>
> wrote:
> > Hi Jim,
> >
> > Thanks for your previous solution. I am learning to work with dates now.
> >
> > I want to write a function which will
> >
> > 1. Count the number of fridays in the current month ( to extract month
> from
> > given date) and also the number of fridays in the preceeding month
> >
> > 2. Calculate the ratio of the number of fridays in current month to the
> > number of fridays in the precceding month
> >
> > 3. Return a integer value calculated as
> >     ifelse(ratio>1,1,ifesle(ration<1,-1),0)
> >
> > The date which is passed is in the format '31-may-2014'
> >
> > So, given the date '31-may-2014'
> >
> > Number of fridays in May2014 = 5
> > Number of fridays in Apr2014 = 4
> >
> > Ratio = 5/4 >1
> > Hence, the function will return a value 1
> >
> > I want to call the function by passing '31-may-2014' as an argument
> >
> > How can this be done in R?
> >
> > Any help will be appreciated
> >
> > Thanks and regards,
> > Abhinaba
> >
> > On Mon, Aug 4, 2014 at 9:36 PM, jim holtman <jholtman at gmail.com> wrote:
> >>
> >> Here is the solution using 'rle':
> >>
> >> > require(data.table)
> >> > x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
> >> +  CB26A    201302         1
> >> +  CB26A    201302         0
> >> +  CB26A    201302         0
> >> +  CB26A    201303         1
> >> +  CB26A    201303         1
> >> +  CB26A    201304         0
> >> +  CB26A    201305         1
> >> +  CB26A    201305         0
> >> +  CB26A    201306         1
> >> +  CB27A    201304         0
> >> +  CB27A    201304         0
> >> +  CB27A    201305         1
> >> +  CB27A    201306         1
> >> +  CB27A    201306         0
> >> +  CB27A    201307         0
> >> +  CB27A    201308         1", header = TRUE, as.is = TRUE)
> >> > setDT(x)
> >> > # convert to a Date object for comparison
> >> > x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
> >> > # separate by CASE_ID and only keep the first 3 months
> >> > x[
> >> +      , {
> >> +          # determine the end date as 3 months from the first date
> >> +          endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
> >> +          # now count the changes
> >> +          list(nChanges = length(rle(ATT_1[(MYD >= MYD[1L]) & (MYD <=
> >> endDate)])[[1L]]) - 1L)
> >> +        }
> >> +      , by = CASE_ID
> >> +      ]
> >>    CASE_ID nChanges
> >> 1:   CB26A        5
> >> 2:   CB27A        2
> >>
> >> Jim Holtman
> >> Data Munger Guru
> >>
> >> What is the problem that you are trying to solve?
> >> Tell me what you want to do, not how you want to do it.
> >>
> >>
> >> On Mon, Aug 4, 2014 at 11:39 AM, Bert Gunter <gunter.berton at gene.com>
> >> wrote:
> >> > Or ?rle
> >> >
> >> > Bert
> >> >
> >> >
> >> >
> >> > Sent from my iPhone -- please excuse typos.
> >> >
> >> >> On Aug 4, 2014, at 8:28 AM, jim holtman <jholtman at gmail.com> wrote:
> >> >>
> >> >> Try this, but I only get 2 changes for CB27A instead of you indicated
> >> >> 3:
> >> >>
> >> >>> require(data.table)
> >> >>> x <- read.table(text = "CASE_ID YEAR_MTH ATT_1
> >> >> + CB26A    201302         1
> >> >> + CB26A    201302         0
> >> >> + CB26A    201302         0
> >> >> + CB26A    201303         1
> >> >> + CB26A    201303         1
> >> >> + CB26A    201304         0
> >> >> + CB26A    201305         1
> >> >> + CB26A    201305         0
> >> >> + CB26A    201306         1
> >> >> + CB27A    201304         0
> >> >> + CB27A    201304         0
> >> >> + CB27A    201305         1
> >> >> + CB27A    201306         1
> >> >> + CB27A    201306         0
> >> >> + CB27A    201307         0
> >> >> + CB27A    201308         1", header = TRUE, as.is = TRUE)
> >> >>> setDT(x)
> >> >>> # convert to a Date object for comparison
> >> >>> x[, MYD := as.Date(paste0(YEAR_MTH, '01'), format = "%Y%m%d")]
> >> >>> # separate by CASE_ID and only keep the first 3 months
> >> >>> x[
> >> >> +     , {
> >> >> +         # determine the end date as 3 months from the first date
> >> >> +         endDate <- seq(MYD[1L], by = '3 months', length = 2)[2L]
> >> >> +         # extract what is changing
> >> >> +         changes <- ATT_1[(MYD >= MYD[1L]) & (MYD <= endDate)]
> >> >> +         # now count the changes
> >> >> +         list(nChanges = sum(head(changes, -1L) != tail(changes,
> >> >> -1L)))
> >> >> +       }
> >> >> +     , by = CASE_ID
> >> >> +     ]
> >> >>   CASE_ID nChanges
> >> >> 1:   CB26A        5
> >> >> 2:   CB27A        2
> >> >>
> >> >> Jim Holtman
> >> >> Data Munger Guru
> >> >>
> >> >> What is the problem that you are trying to solve?
> >> >> Tell me what you want to do, not how you want to do it.
> >> >>
> >> >>
> >> >>> On Wed, Jul 30, 2014 at 3:08 AM, Abhinaba Roy
> >> >>> <abhinabaroy09 at gmail.com> wrote:
> >> >>> Dear R-helpers,
> >> >>>
> >> >>> I want to count the number of times ATT_1 has changed in a period
> of 3
> >> >>> months(can be 4months) from the first YEAR_MTH entry for a CASE_ID.
> So
> >> >>> if
> >> >>> for a CASE_ID we have data only for two distinct YEAR_MTH, then all
> >> >>> the
> >> >>> entries should be considered, otherwise only the relevant entries
> will
> >> >>> be
> >> >>> considered for calculation.
> >> >>> E.g. if the first YEAR_MTH entry is 201304 then get the number of
> >> >>> changes
> >> >>> till 201307(inclusive), similarly if the first YEAR_MTH entry is
> >> >>> 201302
> >> >>> then get the number of changes till 201305.
> >> >>>
> >> >>> Dataset
> >> >>> CASE_ID YEAR_MTH ATT_1
> >> >>> CB26A    201302         1
> >> >>> CB26A    201302         0
> >> >>> CB26A    201302         0
> >> >>> CB26A    201303         1
> >> >>> CB26A    201303         1
> >> >>> CB26A    201304         0
> >> >>> CB26A    201305         1
> >> >>> CB26A    201305         0
> >> >>> CB26A    201306         1
> >> >>> CB27A    201304         0
> >> >>> CB27A    201304         0
> >> >>> CB27A    201305         1
> >> >>> CB27A    201306         1
> >> >>> CB27A    201306         0
> >> >>> CB27A    201307         0
> >> >>> CB27A    201308         1
> >> >>>
> >> >>> The final dataset should look like
> >> >>>
> >> >>> ID_CASE    No.of changes
> >> >>> CB26A        5
> >> >>> CB27A        3
> >> >>>
> >> >>> where 'No.of changes' refer to the change in 3 months (201302-201305
> >> >>> for
> >> >>> CB26A and 201304-201307 for CB27A).
> >> >>>
> >> >>> How can this be done in R?
> >> >>>
> >> >>> Regards,
> >> >>> Abhinaba Roy
> >> >>>
> >> >>>        [[alternative HTML version deleted]]
> >> >>>
> >> >>> ______________________________________________
> >> >>> R-help at r-project.org mailing list
> >> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >>> PLEASE do read the posting guide
> >> >>> http://www.R-project.org/posting-guide.html
> >> >>> and provide commented, minimal, self-contained, reproducible code.
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From mathias1979 at yahoo.com  Sat Oct 11 03:20:00 2014
From: mathias1979 at yahoo.com (Matt Borkowski)
Date: Sat, 11 Oct 2014 01:20:00 +0000 (UTC)
Subject: [R] Problem Invoking System Commands from R
Message-ID: <1123428557.207332.1412990400120.JavaMail.yahoo@jws10736.mail.gq1.yahoo.com>

Hello,
First please keep in mind I am not a programmer and know very little about R. I am running the 64bit version of R on a Windows 8.1 machine. I am trying to run a script (which I have successfully run in the past) to download some weather data from a NOAA ftp site.
When I attempt to run the following command:? ? ?system("wget -P data/raw ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2013/724620-23061-2013.gz")

it returns status 127, which as I understand simply means the command will not run.
If I go directly to my command prompt in Windows, navigate to my working director, and run? ? ?wget -P data/raw ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2013/724620-23061-2013.gz
the command runs and the file downloads without a problem.?
Playing around, it seems I can't invoke any system commands from R. Even a simple?? ? ?system("dir")
returns status 127.
I have moved to a new computer since I last successfully ran this script...I'm wondering if this might be a permissions issue or other security setting preventing me from invoking system commands.
Any ideas?
-Matt
	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Sat Oct 11 09:00:15 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 11 Oct 2014 08:00:15 +0100
Subject: [R] Problem Invoking System Commands from R
In-Reply-To: <1123428557.207332.1412990400120.JavaMail.yahoo@jws10736.mail.gq1.yahoo.com>
References: <1123428557.207332.1412990400120.JavaMail.yahoo@jws10736.mail.gq1.yahoo.com>
Message-ID: <5438D57F.4020906@stats.ox.ac.uk>

Please do follow the posting guide and not sent HTML: it gets mangled.

There are two issues here:

1) Paths.  Use Sys.which("wget") to see if the command is on your path. 
  I suspect it is not, and you need to set the path when running R in 
the same way as is done for your shell.  Compare the setting of PATH in 
your shell with Sys.getenv("PATH") in R, and use Sys.getenv() to set it 
(or do so on the shortcut used to start R: see the rw-FAQ).

3) AFAIR 'dir' is not a system command.  See ?system (on Windows) and 
note that shell() is required for some commands: this is one.

These are not R issues, and you may need to seek local Windows help.

On 11/10/2014 02:20, Matt Borkowski wrote:
> Hello,
> First please keep in mind I am not a programmer and know very little about R. I am running the 64bit version of R on a Windows 8.1 machine. I am trying to run a script (which I have successfully run in the past) to download some weather data from a NOAA ftp site.
> When I attempt to run the following command:     system("wget -P data/raw ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2013/724620-23061-2013.gz")
>
> it returns status 127, which as I understand simply means the command will not run.
> If I go directly to my command prompt in Windows, navigate to my working director, and run     wget -P data/raw ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2013/724620-23061-2013.gz
> the command runs and the file downloads without a problem.
> Playing around, it seems I can't invoke any system commands from R. Even a simple      system("dir")
> returns status 127.
> I have moved to a new computer since I last successfully ran this script...I'm wondering if this might be a permissions issue or other security setting preventing me from invoking system commands.
> Any ideas?
> -Matt
> 	[[alternative HTML version deleted]]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From rhelpmaillist at 163.com  Sat Oct 11 11:25:14 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 11 Oct 2014 17:25:14 +0800 (CST)
Subject: [R]  complain about   a[-integer(0)]
Message-ID: <7269d854.e96a.148fe86b757.Coremail.rhelpmaillist@163.com>


Dear helpeRs,
??? let a <- 1:10 
??? let b <- integer(0) first, then i will randomly write a integer differently in the range(1,10) ?or NULL into b. for supposed 5 times. 
?? then i want to get a[-b],that means i not want the values?at index b.?
?? if?any time?of ?5 times?generate a integer, it works fine. but when all the 5 times generate NULL, it can't work!
? Because of? the? a[-integer(0)] =integer(0) .
? I ask the same question once before, now i encount it again, i think a[-integer(0)] should return a not integer(0) !
? Is any one have the same idea with me ? or give me a oppisite case that a[-integer(0)] need to be integer(0) ?
 




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From jim at bitwrit.com.au  Sat Oct 11 11:57:40 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 11 Oct 2014 20:57:40 +1100
Subject: [R] complain about   a[-integer(0)]
In-Reply-To: <7269d854.e96a.148fe86b757.Coremail.rhelpmaillist@163.com>
References: <7269d854.e96a.148fe86b757.Coremail.rhelpmaillist@163.com>
Message-ID: <4171250.6Qhq7hj5pp@localhost.localdomain>

On Sat, 11 Oct 2014 05:25:14 PM PO SU wrote:
> Dear helpeRs,
>     let a <- 1:10
>     let b <- integer(0) first, then i will randomly write a integer
> differently in the range(1,10)  or NULL into b. for supposed 5 times. 
then
> i want to get a[-b],that means i not want the values at index b. if any
> time of  5 times generate a integer, it works fine. but when all the 5
> times generate NULL, it can't work! Because of  the  a[-integer(0)]
> =integer(0) .
>   I ask the same question once before, now i encount it again, i think
> a[-integer(0)] should return a not integer(0) ! Is any one have the 
same
> idea with me ? or give me a oppisite case that a[-integer(0)] need to 
be
> integer(0) ?
> 
Hi PO SU,
How about:

if(length(b)) a<-a[-b]

Jim


From rhelpmaillist at 163.com  Sat Oct 11 12:41:12 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 11 Oct 2014 18:41:12 +0800 (CST)
Subject: [R] complain about   a[-integer(0)]
In-Reply-To: <4171250.6Qhq7hj5pp@localhost.localdomain>
References: <7269d854.e96a.148fe86b757.Coremail.rhelpmaillist@163.com>
	<4171250.6Qhq7hj5pp@localhost.localdomain>
Message-ID: <9d3bc3.fbbd.148fecc43c0.Coremail.rhelpmaillist@163.com>

Tks, i have to do it.....





--

PO SU
mail: desolator88 at 163.com
Majored in Statistics from SJTU



At 2014-10-11 17:57:40, "Jim Lemon" <jim at bitwrit.com.au> wrote:
>On Sat, 11 Oct 2014 05:25:14 PM PO SU wrote:
>> Dear helpeRs,
>>     let a <- 1:10
>>     let b <- integer(0) first, then i will randomly write a integer
>> differently in the range(1,10)  or NULL into b. for supposed 5 times. 
>then
>> i want to get a[-b],that means i not want the values at index b. if any
>> time of  5 times generate a integer, it works fine. but when all the 5
>> times generate NULL, it can't work! Because of  the  a[-integer(0)]
>> =integer(0) .
>>   I ask the same question once before, now i encount it again, i think
>> a[-integer(0)] should return a not integer(0) ! Is any one have the 
>same
>> idea with me ? or give me a oppisite case that a[-integer(0)] need to 
>be
>> integer(0) ?
>> 
>Hi PO SU,
>How about:
>
>if(length(b)) a<-a[-b]
>
>Jim
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Sat Oct 11 16:29:01 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 11 Oct 2014 07:29:01 -0700
Subject: [R] complain about   a[-integer(0)]
In-Reply-To: <7269d854.e96a.148fe86b757.Coremail.rhelpmaillist@163.com>
References: <7269d854.e96a.148fe86b757.Coremail.rhelpmaillist@163.com>
Message-ID: <13C20D26-E49B-447C-BBF5-C265AD696B3C@dcn.davis.CA.us>

I don't understand what you think it should actually return.  As for why it should behave the way it does now... hmmm, keep in mind that each sub-expression needs to make sense as well. 

Consider -integer(0)... applying the unary negation operator to a vector of integers yields a new vector of the same length as the original one where each element has had its sign changed. If there are no elements in the vector to begin with, there should be no elements in the result. With no elements in the result, there is nowhere to for the negative sign to have an effect. Thus, -integer(0) is the same as integer(0). R would have to recognize the -integer(0) expression as a whole and treat it specially to get a different result than the result it gives now, and I don't like the idea that length(a[-integer(0)]) might be non-zero as a special case even though length(integer(0)) is zero. So, no, I definitely don't agree with you.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 11, 2014 2:25:14 AM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>
>Dear helpeRs,
>??? let a <- 1:10 
>??? let b <- integer(0) first, then i will randomly write a integer
>differently in the range(1,10) ?or NULL into b. for supposed 5 times. 
>?? then i want to get a[-b],that means i not want the values?at index
>b.?
>?? if?any time?of ?5 times?generate a integer, it works fine. but when
>all the 5 times generate NULL, it can't work!
>? Because of? the? a[-integer(0)] =integer(0) .
>? I ask the same question once before, now i encount it again, i think
>a[-integer(0)] should return a not integer(0) !
>? Is any one have the same idea with me ? or give me a oppisite case
>that a[-integer(0)] need to be integer(0) ?
> 
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mathias1979 at yahoo.com  Sat Oct 11 15:05:30 2014
From: mathias1979 at yahoo.com (Matt Borkowski)
Date: Sat, 11 Oct 2014 13:05:30 +0000 (UTC)
Subject: [R] Problem Invoking System Commands from R
In-Reply-To: <5438D57F.4020906@stats.ox.ac.uk>
References: <5438D57F.4020906@stats.ox.ac.uk>
Message-ID: <1812299418.234970.1413032730047.JavaMail.yahoo@jws10752.mail.gq1.yahoo.com>

I appreciate the feedback.

1) The paths are properly set...I only wonder if the spaces in the path to wget.exe are problematic for R. The full path (C:\\Program Files (x86)\\GnuWin32\\bin) is properly included in the return list for Sys.getenv("PATH"). Sys.which("wget") returns:

>"C:\\PROGRA~2\\GnuWin32\\bin\\wget.exe"

Note that in this return, the folder 'Program Files (x86)' was truncated. Not sure if that is a problem in this. Also as mentioned, wget works fine directly from the Windows CMD line, so it strikes me as an issue calling a system command from R as opposed to a problem with the command itself.

2) 'dir' is a recognized command at the Windows command line...but it is somewhat irrelevant as I was only using it to determine whether any calls to the Windows command line from R were working...it is not essential to the script.

One further point, I booted up my old machine last night and reinstalled R and wget...and was successfully able to run the script. Old machine is Windows XP versus Windows 8.1 on my new machine. Perhaps this confirms it is a Windows permission issue and not an R problem?

-Matt


On Saturday, October 11, 2014 3:00 AM, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:



Please do follow the posting guide and not sent HTML: it gets mangled.

There are two issues here:

1) Paths.  Use Sys.which("wget") to see if the command is on your path. 
  I suspect it is not, and you need to set the path when running R in 
the same way as is done for your shell.  Compare the setting of PATH in 
your shell with Sys.getenv("PATH") in R, and use Sys.getenv() to set it 
(or do so on the shortcut used to start R: see the rw-FAQ).

3) AFAIR 'dir' is not a system command.  See ?system (on Windows) and 
note that shell() is required for some commands: this is one.

These are not R issues, and you may need to seek local Windows help.


On 11/10/2014 02:20, Matt Borkowski wrote:
> Hello,
> First please keep in mind I am not a programmer and know very little about R. I am running the 64bit version of R on a Windows 8.1 machine. I am trying to run a script (which I have successfully run in the past) to download some weather data from a NOAA ftp site.
> When I attempt to run the following command:     system("wget -P data/raw ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2013/724620-23061-2013.gz")
>
> it returns status 127, which as I understand simply means the command will not run.
> If I go directly to my command prompt in Windows, navigate to my working director, and run     wget -P data/raw ftp://ftp.ncdc.noaa.gov/pub/data/noaa/2013/724620-23061-2013.gz
> the command runs and the file downloads without a problem.
> Playing around, it seems I can't invoke any system commands from R. Even a simple      system("dir")
> returns status 127.
> I have moved to a new computer since I last successfully ran this script...I'm wondering if this might be a permissions issue or other security setting preventing me from invoking system commands.
> Any ideas?
> -Matt
>     [[alternative HTML version deleted]]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From zadig_1 at excite.com  Sat Oct 11 18:03:07 2014
From: zadig_1 at excite.com (ce)
Date: Sat, 11 Oct 2014 12:03:07 -0400
Subject: [R] xts array in minutes ?
Message-ID: <20141011120307.24949@web007.roc2.bluetie.com>


Dear all,

I want to convert to character arrays  "2014-10:10 00:00:00" and "2014-10-10:23:59:00" to an array of minutes :

2014-10:10 00:00:00
2014-10:10 00:01:00
2014-10:10 00:02:00

What is the best way to do it ?
thanks


From john.archie.mckown at gmail.com  Sat Oct 11 18:20:22 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Sat, 11 Oct 2014 11:20:22 -0500
Subject: [R] xts array in minutes ?
In-Reply-To: <20141011120307.24949@web007.roc2.bluetie.com>
References: <20141011120307.24949@web007.roc2.bluetie.com>
Message-ID: <CAAJSdjgWcL5Z-Qv+03OmFauAHrp+mjjRmHQfqyCkT1PRs3o6eg@mail.gmail.com>

On Sat, Oct 11, 2014 at 11:03 AM, ce <zadig_1 at excite.com> wrote:
>
> Dear all,
>
> I want to convert to character arrays  "2014-10:10 00:00:00" and "2014-10-10:23:59:00" to an array of minutes :
>
> 2014-10:10 00:00:00
> 2014-10:10 00:01:00
> 2014-10:10 00:02:00
>
> What is the best way to do it ?
> thanks
>

Best? I don't know. My way:

minutes<-as.xts(as.POSIXct(seq(as.POSIXlt('2014-10-10
00:00:00'),as.POSIXlt('2014-10-10 23:59:00'),'min')));


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From zadig_1 at excite.com  Sat Oct 11 18:32:49 2014
From: zadig_1 at excite.com (ce)
Date: Sat, 11 Oct 2014 12:32:49 -0400
Subject: [R] xts array in minutes ?
Message-ID: <20141011123249.1837@web006.roc2.bluetie.com>


that's very good , thanks. 


-----Original Message-----
From: "John McKown" [john.archie.mckown at gmail.com]
Date: 10/11/2014 12:20 PM
To: "ce" <zadig_1 at excite.com>
CC: "r-help" <r-help at r-project.org>
Subject: Re: [R] xts array in minutes ?

On Sat, Oct 11, 2014 at 11:03 AM, ce <zadig_1 at excite.com> wrote:
>
> Dear all,
>
> I want to convert to character arrays  "2014-10:10 00:00:00" and "2014-10-10:23:59:00" to an array of minutes :
>
> 2014-10:10 00:00:00
> 2014-10:10 00:01:00
> 2014-10:10 00:02:00
>
> What is the best way to do it ?
> thanks
>

Best? I don't know. My way:

minutes<-as.xts(as.POSIXct(seq(as.POSIXlt('2014-10-10
00:00:00'),as.POSIXlt('2014-10-10 23:59:00'),'min')));


-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From moonkid at posteo.org  Sat Oct 11 19:17:51 2014
From: moonkid at posteo.org (moonkid at posteo.org)
Date: Sat, 11 Oct 2014 19:17:51 +0200
Subject: [R] understanding the no-label concept
Message-ID: <20141011171810.5553825B17EF@mx02.posteo.de>

I am new to R but a bit familiar with Stata and SPSS and a software dev.

As I understand it right, there is no possibility to give variables or
values a lable. Is that right?

Just for example. "x" need a name. And the four values (1, 2, 3, 4)
need it to.

[code]
> table(x)

1  2  3  4
17  6  6  2 
[/code]

I understand that R itself is powerful and well developed. So I try to
understand why it doesn't support labels.

And in the next step I try to understand how do you work with your data
and publish (e.g. with *TeX) it without using labels? R can put out
*TeX-code, right? I don't want to modify the outputted code manually. It
would waste my time and decreases my efficiency.


From rmh at temple.edu  Sat Oct 11 22:04:45 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 11 Oct 2014 16:04:45 -0400
Subject: [R] understanding the no-label concept
In-Reply-To: <20141011171810.5553825B17EF@mx02.posteo.de>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
Message-ID: <CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>

It looks like a terminology issue.  R has names for elements of a
vector and for rows and
columns of a matrix or data.frame, and more generally for all
dimensions of multi-dimensional array.

I think your next step is to read the introductory document.
Start with either of these (they are the same content)
system.file("../../doc/manual/R-intro.html")
system.file("../../doc/manual/R-intro.pdf")

For the specific situations you described, here are examples.

aa <- 1:5
names(aa) <- letters[1:5]
aa
names(aa) <- c("ABC","DEF","GHI","LMN","OPQ")
aa

bb <- matrix(1:12, 3, 4, dimnames=list(letters[1:3], LETTERS[1:4]))
bb

## install.packages("Hmisc") ## if you don't have it yet
library(Hmisc)
latex(bb)



Rich


On Sat, Oct 11, 2014 at 1:17 PM,  <moonkid at posteo.org> wrote:
> I am new to R but a bit familiar with Stata and SPSS and a software dev.
>
> As I understand it right, there is no possibility to give variables or
> values a lable. Is that right?
>
> Just for example. "x" need a name. And the four values (1, 2, 3, 4)
> need it to.
>
> [code]
>> table(x)
>
> 1  2  3  4
> 17  6  6  2
> [/code]
>
> I understand that R itself is powerful and well developed. So I try to
> understand why it doesn't support labels.
>
> And in the next step I try to understand how do you work with your data
> and publish (e.g. with *TeX) it without using labels? R can put out
> *TeX-code, right? I don't want to modify the outputted code manually. It
> would waste my time and decreases my efficiency.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sat Oct 11 22:08:08 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 11 Oct 2014 13:08:08 -0700
Subject: [R] understanding the no-label concept
In-Reply-To: <20141011171810.5553825B17EF@mx02.posteo.de>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
Message-ID: <CACk-te2Wr3ix+ruqcpWtiQ6Jzm_U6WdEg9NjPonnNr-oWqD2tw@mail.gmail.com>

No, you are wrong. Read the docs! -- start with "An Introduction to R"
which ships with R.

Please do not post further until after you have done your homework.

x <- c(a=1,b=2,c=3)

See also ?names.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, Oct 11, 2014 at 10:17 AM,  <moonkid at posteo.org> wrote:
> I am new to R but a bit familiar with Stata and SPSS and a software dev.
>
> As I understand it right, there is no possibility to give variables or
> values a lable. Is that right?
>
> Just for example. "x" need a name. And the four values (1, 2, 3, 4)
> need it to.
>
> [code]
>> table(x)
>
> 1  2  3  4
> 17  6  6  2
> [/code]
>
> I understand that R itself is powerful and well developed. So I try to
> understand why it doesn't support labels.
>
> And in the next step I try to understand how do you work with your data
> and publish (e.g. with *TeX) it without using labels? R can put out
> *TeX-code, right? I don't want to modify the outputted code manually. It
> would waste my time and decreases my efficiency.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Sat Oct 11 23:06:57 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 11 Oct 2014 23:06:57 +0200
Subject: [R] errors in initial values in R2winBUGS
In-Reply-To: <CABLo8nGRNC44YXTtMOqK3eXQvDMMFYUYgTX+xRj8kpGsHVwyKg@mail.gmail.com>
References: <CABLo8nGRNC44YXTtMOqK3eXQvDMMFYUYgTX+xRj8kpGsHVwyKg@mail.gmail.com>
Message-ID: <54399BF1.6050108@statistik.tu-dortmund.de>



On 11.10.2014 06:09, thanoon younis wrote:
> Dear all R users
> I am trying to find the bayesian analysis using R2winBUGS but i have errors
> in initial values with two groups.
> the R-code
> #Initial values for the MCMC in WinBUGS
>
> init1<-list(uby1=rep(0.0,10),lam1=c(0.0,0.0,0.0,0.0,0.0,0.0),
> gam1=c(1.0,1.0,1.0,1.0,1.0,1.0),psd1=1.0,phi1=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),uby2=rep(0.0,10),lam2=c(0.0,0.0,0.0,0.0,0.0,0.0),
> gam2=c(1.0,1.0,1.0,1.0,1.0,1.0),psd2=1.0,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),


The comma at the very end is too much ....

Best,
Uwe Ligges


> init2<-list(uby1=rep(0.5,10),lam1=c(0.5,0.5,0.5,0.5,0.5,0.5),
> gam1=c(0.0,0.0,0.0,0.0,0.0,0.0),psd1=0.6,phi1=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),uby2=rep(0.5,10),lam2=c(0.5,0.5,0.5,0.5,0.5,0.5),
> gam2=c(0.0,0.0,0.0,0.0,0.0,0.0),psd2=0.6,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),
>
>
> and the errors are
>
> Error: unexpected ',' in:
> "3,byrow=TRUE),uby2=rep(0.0,10),lam2=c(0.0,0.0,0.0,0.0,0.0,0.0),
> gam2=c(1.0,1.0,1.0,1.0,1.0,1.0),psd2=1.0,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),"
>
> and
>
> Error: unexpected ',' in:
> "3,byrow=TRUE),uby2=rep(0.5,10),lam2=c(0.5,0.5,0.5,0.5,0.5,0.5),
> gam2=c(0.0,0.0,0.0,0.0,0.0,0.0),psd2=0.6,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),"
>
>
>
> any help would be greatly appreciated
>
>


From dwinsemius at comcast.net  Sat Oct 11 23:16:45 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 11 Oct 2014 14:16:45 -0700
Subject: [R] understanding the no-label concept
In-Reply-To: <CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
	<CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>
Message-ID: <97FC7925-E3CA-4281-A52B-18ABFFAF4FB5@comcast.net>


On Oct 11, 2014, at 1:04 PM, Richard M. Heiberger wrote:

> It looks like a terminology issue.  R has names for elements of a
> vector and for rows and
> columns of a matrix or data.frame, and more generally for all
> dimensions of multi-dimensional array.
> 
> I think your next step is to read the introductory document.
> Start with either of these (they are the same content)
> system.file("../../doc/manual/R-intro.html")
> system.file("../../doc/manual/R-intro.pdf")
> 
> For the specific situations you described, here are examples.
> 
> aa <- 1:5
> names(aa) <- letters[1:5]
> aa
> names(aa) <- c("ABC","DEF","GHI","LMN","OPQ")
> aa
> 
> bb <- matrix(1:12, 3, 4, dimnames=list(letters[1:3], LETTERS[1:4]))
> bb
> 
> ## install.packages("Hmisc") ## if you don't have it yet
> library(Hmisc)
> latex(bb)

Hmisc also has a labeling facility and mechanisms for importing SAS labels. (I don't know if importation of SPSS labels is supported.) Hmisc::label uses the capacity of R to attach attributes to data-objects. So pay particular attention to the introductory material that Richard (and  Bert Gunther) refer you to in the area of "attributes", and read ?Hmisc::label (after installing that package.)

-- 
David.

> 
> Rich
> 
> 
> On Sat, Oct 11, 2014 at 1:17 PM,  <moonkid at posteo.org> wrote:
>> I am new to R but a bit familiar with Stata and SPSS and a software dev.
>> 
>> As I understand it right, there is no possibility to give variables or
>> values a lable. Is that right?
>> 
>> Just for example. "x" need a name. And the four values (1, 2, 3, 4)
>> need it to.
>> 
>> [code]
>>> table(x)
>> 
>> 1  2  3  4
>> 17  6  6  2
>> [/code]
>> 
>> I understand that R itself is powerful and well developed. So I try to
>> understand why it doesn't support labels.
>> 
>> And in the next step I try to understand how do you work with your data
>> and publish (e.g. with *TeX) it without using labels? R can put out
>> *TeX-code, right? I don't want to modify the outputted code manually. It
>> would waste my time and decreases my efficiency.
> 


David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Sun Oct 12 00:14:11 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 11 Oct 2014 15:14:11 -0700
Subject: [R] understanding the no-label concept
In-Reply-To: <20141011171810.5553825B17EF@mx02.posteo.de>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
Message-ID: <CAF8bMcbio6-7v9+_75Ftrs3mXvvT6RYXC3KyN_kXMpBHWUa0Tg@mail.gmail.com>

You can use 'factors' to assign labels to small integer values.  E.g.,
   > x <- c(1,2,3,4,3)
   > fx <- factor(x, levels=1:5, labels=c("One","Two","Three","Four","Five"))
   > table(fx)
   fx
     One   Two Three  Four  Five
       1     1     2     1     0

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Oct 11, 2014 at 10:17 AM,  <moonkid at posteo.org> wrote:
> I am new to R but a bit familiar with Stata and SPSS and a software dev.
>
> As I understand it right, there is no possibility to give variables or
> values a lable. Is that right?
>
> Just for example. "x" need a name. And the four values (1, 2, 3, 4)
> need it to.
>
> [code]
>> table(x)
>
> 1  2  3  4
> 17  6  6  2
> [/code]
>
> I understand that R itself is powerful and well developed. So I try to
> understand why it doesn't support labels.
>
> And in the next step I try to understand how do you work with your data
> and publish (e.g. with *TeX) it without using labels? R can put out
> *TeX-code, right? I don't want to modify the outputted code manually. It
> would waste my time and decreases my efficiency.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From danielmiquelluti at yahoo.com.br  Sun Oct 12 02:32:04 2014
From: danielmiquelluti at yahoo.com.br (Daniel Miquelluti)
Date: Sat, 11 Oct 2014 17:32:04 -0700
Subject: [R] errors in initial values in R2winBUGS
In-Reply-To: <54399BF1.6050108@statistik.tu-dortmund.de>
References: <CABLo8nGRNC44YXTtMOqK3eXQvDMMFYUYgTX+xRj8kpGsHVwyKg@mail.gmail.com>
	<54399BF1.6050108@statistik.tu-dortmund.de>
Message-ID: <1413073924.17596.YahooMailNeo@web162903.mail.bf1.yahoo.com>

You are separating the objects using commas, the correct should be semicolons.

Example:
xi1=matrix(data=rep(0.0,600),ncol=3);xi2=matrix(data=rep(0.0,600),ncol=3))


Best regards,
Daniel Miquelluti



Em S?bado, 11 de Outubro de 2014 18:06, Uwe Ligges <ligges at statistik.tu-dortmund.de> escreveu:
 




On 11.10.2014 06:09, thanoon younis wrote:
> Dear all R users
> I am trying to find the bayesian analysis using R2winBUGS but i have errors
> in initial values with two groups.
> the R-code
> #Initial values for the MCMC in WinBUGS
>
> init1<-list(uby1=rep(0.0,10),lam1=c(0.0,0.0,0.0,0.0,0.0,0.0),
> gam1=c(1.0,1.0,1.0,1.0,1.0,1.0),psd1=1.0,phi1=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),uby2=rep(0.0,10),lam2=c(0.0,0.0,0.0,0.0,0.0,0.0),
> gam2=c(1.0,1.0,1.0,1.0,1.0,1.0),psd2=1.0,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),


The comma at the very end is too much ....

Best,
Uwe Ligges


> init2<-list(uby1=rep(0.5,10),lam1=c(0.5,0.5,0.5,0.5,0.5,0.5),
> gam1=c(0.0,0.0,0.0,0.0,0.0,0.0),psd1=0.6,phi1=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),uby2=rep(0.5,10),lam2=c(0.5,0.5,0.5,0.5,0.5,0.5),
> gam2=c(0.0,0.0,0.0,0.0,0.0,0.0),psd2=0.6,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),
>
>
> and the errors are
>
> Error: unexpected ',' in:
> "3,byrow=TRUE),uby2=rep(0.0,10),lam2=c(0.0,0.0,0.0,0.0,0.0,0.0),
> gam2=c(1.0,1.0,1.0,1.0,1.0,1.0),psd2=1.0,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),"
>
> and
>
> Error: unexpected ',' in:
> "3,byrow=TRUE),uby2=rep(0.5,10),lam2=c(0.5,0.5,0.5,0.5,0.5,0.5),
> gam2=c(0.0,0.0,0.0,0.0,0.0,0.0),psd2=0.6,phi2=matrix(data=c(1.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0),ncol=3,byrow=TRUE),
> xi1=matrix(data=rep(0.0,600),ncol=3),xi2=matrix(data=rep(0.0,600),ncol=3)),"
>
>
>
> any help would be greatly appreciated
>
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From ivanvallesperez at gmail.com  Sun Oct 12 01:58:11 2014
From: ivanvallesperez at gmail.com (=?iso-8859-1?Q?Iv=E1n_Vall=E9s_P=E9rez?=)
Date: Sun, 12 Oct 2014 01:58:11 +0200
Subject: [R] Help with caret, please
Message-ID: <F00D0632-7F27-4B64-AFF0-6FF0EDB3B4C7@gmail.com>

Hello,

I am using caret package in order to train a K-Nearest Neigbors algorithm. For this, I am running this code:

Control <- trainControl(method="cv", summaryFunction=twoClassSummary, classProb=T)

tGrid=data.frame(k=1:100)

trainingInfo <- train(Formula, data=trainData, method = "knn",tuneGrid=tGrid,
                              trControl=Control, metric =  "ROC")
As you can see, I am interested in obtain the AUC parameter of the ROC. This code works good but returns the testing error (which the algorithm uses for tuning the k parameter of the model) as the mean of the error of the CrossValidation folds. I am interested in return, in addition of the testing error, the trainingerror (the mean across each fold of the error obtained with the training data). ?How can I do it? 

Thank you
	[[alternative HTML version deleted]]


From mxkuhn at gmail.com  Sun Oct 12 03:21:17 2014
From: mxkuhn at gmail.com (Max Kuhn)
Date: Sat, 11 Oct 2014 21:21:17 -0400
Subject: [R] Help with caret, please
In-Reply-To: <F00D0632-7F27-4B64-AFF0-6FF0EDB3B4C7@gmail.com>
References: <F00D0632-7F27-4B64-AFF0-6FF0EDB3B4C7@gmail.com>
Message-ID: <CAJ9CoW=qghR3qoOs12ZETNNdrDaV5WCEarf8EiTiXwSGhkA5sg@mail.gmail.com>

What you are asking is a bad idea on multiple levels. You will grossly
over-estimate the area under the ROC curve. Consider the 1-NN model: you
will have perfect predictions every time.

To do this, you will need to run train again and modify the index and
indexOut objects:

library(caret)

  set.seed(1)
  dat <- twoClassSim(200)

  set.seed(2)
  folds <- createFolds(dat$Class, returnTrain = TRUE)

  Control <- trainControl(method="cv",
                          summaryFunction=twoClassSummary,
                          classProb=T,
                          index = folds,
                          indexOut = folds)

  tGrid=data.frame(k=1:100)

  set.seed(3)
  a_bad_idea <- train(Class ~ ., data=dat,
                      method = "knn",
                      tuneGrid=tGrid,
                      trControl=Control, metric =  "ROC")

Max

On Sat, Oct 11, 2014 at 7:58 PM, Iv?n Vall?s P?rez <
ivanvallesperez at gmail.com> wrote:

> Hello,
>
> I am using caret package in order to train a K-Nearest Neigbors algorithm.
> For this, I am running this code:
>
> Control <- trainControl(method="cv", summaryFunction=twoClassSummary,
> classProb=T)
>
> tGrid=data.frame(k=1:100)
>
> trainingInfo <- train(Formula, data=trainData, method =
> "knn",tuneGrid=tGrid,
>                               trControl=Control, metric =  "ROC")
> As you can see, I am interested in obtain the AUC parameter of the ROC.
> This code works good but returns the testing error (which the algorithm
> uses for tuning the k parameter of the model) as the mean of the error of
> the CrossValidation folds. I am interested in return, in addition of the
> testing error, the trainingerror (the mean across each fold of the error
> obtained with the training data). ?How can I do it?
>
> Thank you
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Sun Oct 12 08:12:40 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Sun, 12 Oct 2014 08:12:40 +0200
Subject: [R] Update package dor r-devlop
Message-ID: <543A1BD8.90603@yahoo.fr>

I use R-devel 3.2 in order to check "as cran" packages that I develop.
To maintain my package uptodate, I cannot use the update.packages() 
directly because the packages are not still compiled for version 3.2. 
Then I use:
update.packages(contriburl = contrib.url(repos=options("repos")$repos, 
type="source"))

But at the time of installation, I get an error, for example:
 > update.packages(contriburl = 
contrib.url(repos=options("repos")$repos, type="source"))
nlme :
  Version 3.1-117 installed in 
/Library/Frameworks/R.framework/Versions/3.2/Resources/library
  Version 3.1-118 available at http://cran.irsn.fr/src/contrib
Update (y/N/c)?  y
essai de l'URL 'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tgz'
Error in download.file(url, destfile, method, mode = "wb", ...) :
   impossible d'ouvrir l'URL 
'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tgz'
De plus : Warning message:
In download.file(url, destfile, method, mode = "wb", ...) :
   ouverture impossible : le statut HTTP ?tait '404 Not Found'
Warning in download.packages(pkgs, destdir = tmpd, available = available,  :
   le t?l?chargement du package ?nlme? a ?chou?

When I use :
install.packages("nlme", type="source")
essai de l'URL 'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tar.gz'
Content type 'application/x-gzip' length 759483 bytes (741 Kb)
URL ouverte
==================================================
downloaded 741 Kb

It works well.

It seems at .tgz is not available in CRAN mirror. It is normal ?
Is it a way to force .tar.gz to be used ?

Thanks

Marc Girondot


From c.caballero at bcbl.eu  Sun Oct 12 08:14:09 2014
From: c.caballero at bcbl.eu (Cesar Caballero)
Date: Sun, 12 Oct 2014 08:14:09 +0200 (CEST)
Subject: [R] rbind in array of lists
In-Reply-To: <154976578.3447548.1413094035154.JavaMail.root@bcbl.eu>
Message-ID: <1725180130.3447570.1413094449001.JavaMail.root@bcbl.eu>

Hi all,

I have an array of lists. All lists have the same names and the vectors inside each name have the same dimension.

For instance,

a[1:4]
[[1]]
[[1]]$var1
[1] 1 2 3 4 5

[[1]]$var2
[1] 6 7


[[2]]
[[2]]$var1
[1]  2  4  6  8 10

[[2]]$var2
[1] 12 14

[[3]]
[[3]]$var1
[1]  3  6  9 12 15

[[3]]$var2
[1] 18 21


I would like to apply rbind to concatenate all vectors for a given name, e.g. concatenate all the a[[]]$a
How can I do that?

Thanks very much in advance.

Best wishes
Cesar


----------------------------------------------------------------------
Cesar Caballero
MRI engineer
www.bcbl.eu 

Legal disclaimer/Aviso legal/Lege-oharra: www.bcbl.eu/legal-disclaimer


From jdnewmil at dcn.davis.CA.us  Sun Oct 12 08:25:11 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 11 Oct 2014 23:25:11 -0700
Subject: [R] Update package dor r-devlop
In-Reply-To: <543A1BD8.90603@yahoo.fr>
References: <543A1BD8.90603@yahoo.fr>
Message-ID: <9692E7B0-E607-4AC1-9D63-D729DE91AF2B@dcn.davis.CA.us>

Off topic. See the Posting Guide, which indicates that development questions belong on R-devel.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 11, 2014 11:12:40 PM PDT, Marc Girondot <marc_grt at yahoo.fr> wrote:
>I use R-devel 3.2 in order to check "as cran" packages that I develop.
>To maintain my package uptodate, I cannot use the update.packages() 
>directly because the packages are not still compiled for version 3.2. 
>Then I use:
>update.packages(contriburl = contrib.url(repos=options("repos")$repos, 
>type="source"))
>
>But at the time of installation, I get an error, for example:
> > update.packages(contriburl = 
>contrib.url(repos=options("repos")$repos, type="source"))
>nlme :
>  Version 3.1-117 installed in 
>/Library/Frameworks/R.framework/Versions/3.2/Resources/library
>  Version 3.1-118 available at http://cran.irsn.fr/src/contrib
>Update (y/N/c)?  y
>essai de l'URL 'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tgz'
>Error in download.file(url, destfile, method, mode = "wb", ...) :
>   impossible d'ouvrir l'URL 
>'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tgz'
>De plus : Warning message:
>In download.file(url, destfile, method, mode = "wb", ...) :
>   ouverture impossible : le statut HTTP ?tait '404 Not Found'
>Warning in download.packages(pkgs, destdir = tmpd, available =
>available,  :
>   le t?l?chargement du package ?nlme? a ?chou?
>
>When I use :
>install.packages("nlme", type="source")
>essai de l'URL 'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tar.gz'
>Content type 'application/x-gzip' length 759483 bytes (741 Kb)
>URL ouverte
>==================================================
>downloaded 741 Kb
>
>It works well.
>
>It seems at .tgz is not available in CRAN mirror. It is normal ?
>Is it a way to force .tar.gz to be used ?
>
>Thanks
>
>Marc Girondot
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sun Oct 12 08:56:27 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 12 Oct 2014 07:56:27 +0100
Subject: [R] Update package dor r-devlop
In-Reply-To: <9692E7B0-E607-4AC1-9D63-D729DE91AF2B@dcn.davis.CA.us>
References: <543A1BD8.90603@yahoo.fr>
	<9692E7B0-E607-4AC1-9D63-D729DE91AF2B@dcn.davis.CA.us>
Message-ID: <543A261B.6090403@stats.ox.ac.uk>

On 12/10/2014 07:25, Jeff Newmiller wrote:
> Off topic. See the Posting Guide, which indicates that development questions belong on R-devel.

And questions about Mac-specific distributions of R on R-sig-mac.

But note that the best way to select source packages is

options(pkgType = "source")

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 11, 2014 11:12:40 PM PDT, Marc Girondot <marc_grt at yahoo.fr> wrote:
>> I use R-devel 3.2 in order to check "as cran" packages that I develop.
>> To maintain my package uptodate, I cannot use the update.packages()
>> directly because the packages are not still compiled for version 3.2.
>> Then I use:
>> update.packages(contriburl = contrib.url(repos=options("repos")$repos,
>> type="source"))
>>
>> But at the time of installation, I get an error, for example:
>>> update.packages(contriburl =
>> contrib.url(repos=options("repos")$repos, type="source"))
>> nlme :
>>   Version 3.1-117 installed in
>> /Library/Frameworks/R.framework/Versions/3.2/Resources/library
>>   Version 3.1-118 available at http://cran.irsn.fr/src/contrib
>> Update (y/N/c)?  y
>> essai de l'URL 'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tgz'
>> Error in download.file(url, destfile, method, mode = "wb", ...) :
>>    impossible d'ouvrir l'URL
>> 'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tgz'
>> De plus : Warning message:
>> In download.file(url, destfile, method, mode = "wb", ...) :
>>    ouverture impossible : le statut HTTP ?tait '404 Not Found'
>> Warning in download.packages(pkgs, destdir = tmpd, available =
>> available,  :
>>    le t?l?chargement du package ?nlme? a ?chou?
>>
>> When I use :
>> install.packages("nlme", type="source")
>> essai de l'URL 'http://cran.irsn.fr/src/contrib/nlme_3.1-118.tar.gz'
>> Content type 'application/x-gzip' length 759483 bytes (741 Kb)
>> URL ouverte
>> ==================================================
>> downloaded 741 Kb
>>
>> It works well.
>>
>> It seems at .tgz is not available in CRAN mirror. It is normal ?
>> Is it a way to force .tar.gz to be used ?
>>
>> Thanks
>>
>> Marc Girondot
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From ripley at stats.ox.ac.uk  Sun Oct 12 08:57:51 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 12 Oct 2014 07:57:51 +0100
Subject: [R] understanding the no-label concept
In-Reply-To: <97FC7925-E3CA-4281-A52B-18ABFFAF4FB5@comcast.net>
References: <20141011171810.5553825B17EF@mx02.posteo.de>	<CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>
	<97FC7925-E3CA-4281-A52B-18ABFFAF4FB5@comcast.net>
Message-ID: <543A266F.60001@stats.ox.ac.uk>

On 11/10/2014 22:16, David Winsemius wrote:
>
> On Oct 11, 2014, at 1:04 PM, Richard M. Heiberger wrote:
>
>> It looks like a terminology issue.  R has names for elements of a
>> vector and for rows and
>> columns of a matrix or data.frame, and more generally for all
>> dimensions of multi-dimensional array.
>>
>> I think your next step is to read the introductory document.
>> Start with either of these (they are the same content)
>> system.file("../../doc/manual/R-intro.html")
>> system.file("../../doc/manual/R-intro.pdf")
>>
>> For the specific situations you described, here are examples.
>>
>> aa <- 1:5
>> names(aa) <- letters[1:5]
>> aa
>> names(aa) <- c("ABC","DEF","GHI","LMN","OPQ")
>> aa
>>
>> bb <- matrix(1:12, 3, 4, dimnames=list(letters[1:3], LETTERS[1:4]))
>> bb
>>
>> ## install.packages("Hmisc") ## if you don't have it yet
>> library(Hmisc)
>> latex(bb)
>
> Hmisc also has a labeling facility and mechanisms for importing SAS labels.
(I don't know if importation of SPSS labels is supported.)

It is, in package foreign.

Hmisc::label uses the capacity of R to attach attributes to data-objects.
So pay particular attention to the introductory material that Richard 
(and  Bert Gunther) refer you to in the area of "attributes", and read 
?Hmisc::label (after installing that package.)
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From thanoon.younis80 at gmail.com  Sun Oct 12 15:06:06 2014
From: thanoon.younis80 at gmail.com (thanoon younis)
Date: Sun, 12 Oct 2014 16:06:06 +0300
Subject: [R] problem in R2winBUGS
Message-ID: <CABLo8nFX5Pmuk-VpNmyHm+KcatO7NJq9Ew_FKg96fuUeqF8sow@mail.gmail.com>

Dear all Rusers
I have error when i wanted to call winbugs from R to estamate parameters
using bayesian analysis.

 #Call WinBUGS

model<-bugs(data1,data2,init1,init2,parameters,model.file="D:/Run/model.txt",
    n.chains=2,n.iter=10000,n.burnin=4000,n.thin=1,DIC=True,
    bugs.directory="c:/Program Files/WinBUGS14/",
    working.directory="D:/Run/")

and the error is
#Call WinBUGS
>
model<-bugs(data1,data2,init1,init2,parameters,model.file="D:/Run/model.txt",
+     n.chains=2,n.iter=10000,n.burnin=4000,n.thin=1,DIC=True,
+     bugs.directory="c:/Program Files/WinBUGS14/",
+     working.directory="D:/Run/")
Error in bugs(data1, data2, init1, init2, parameters, model.file =
"D:/Run/model.txt",  :
  Number of initialized chains (length(inits)) != n.chains

any help would be greatly appreciated

-- 
Thanoon Y. Thanoon
PhD Candidate
Department of Mathematical Sciences
Faculty of Science
University Technology Malaysia, UTM
E.Mail: Thanoon.younis80 at gmail.com
E.Mail: dawn_prayer80 at yahoo.com
Facebook:Thanoon Younis AL-Shakerchy
Twitter: Thanoon Alshakerchy
H.P:00601127550205

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Sun Oct 12 17:45:26 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 12 Oct 2014 16:45:26 +0100
Subject: [R] rbind in array of lists
In-Reply-To: <1725180130.3447570.1413094449001.JavaMail.root@bcbl.eu>
References: <1725180130.3447570.1413094449001.JavaMail.root@bcbl.eu>
Message-ID: <543AA216.1020303@sapo.pt>

Hello,

Try the following.

do.call(rbind, lapply(a, '[[', "var1"))
do.call(rbind, lapply(a, '[[', "var2"))


Hope this helps,

Rui Barradas

Em 12-10-2014 07:14, Cesar Caballero escreveu:
> Hi all,
>
> I have an array of lists. All lists have the same names and the vectors inside each name have the same dimension.
>
> For instance,
>
> a[1:4]
> [[1]]
> [[1]]$var1
> [1] 1 2 3 4 5
>
> [[1]]$var2
> [1] 6 7
>
>
> [[2]]
> [[2]]$var1
> [1]  2  4  6  8 10
>
> [[2]]$var2
> [1] 12 14
>
> [[3]]
> [[3]]$var1
> [1]  3  6  9 12 15
>
> [[3]]$var2
> [1] 18 21
>
>
> I would like to apply rbind to concatenate all vectors for a given name, e.g. concatenate all the a[[]]$a
> How can I do that?
>
> Thanks very much in advance.
>
> Best wishes
> Cesar
>
>
> ----------------------------------------------------------------------
> Cesar Caballero
> MRI engineer
> www.bcbl.eu
>
> Legal disclaimer/Aviso legal/Lege-oharra: www.bcbl.eu/legal-disclaimer
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sun Oct 12 19:26:37 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 12 Oct 2014 10:26:37 -0700
Subject: [R] rbind in array of lists
In-Reply-To: <543AA216.1020303@sapo.pt>
References: <1725180130.3447570.1413094449001.JavaMail.root@bcbl.eu>
	<543AA216.1020303@sapo.pt>
Message-ID: <79E0CB8D-277E-4640-A9EB-3A53AC282D21@comcast.net>


On Oct 12, 2014, at 8:45 AM, Rui Barradas wrote:

> Hello,
> 
> Try the following.
> 
> do.call(rbind, lapply(a, '[[', "var1"))
> do.call(rbind, lapply(a, '[[', "var2"))

Could perhaps (untested) make it more general with:

do.call(rbind, lapply(a, '[[', names(a[[1]])[1]))
do.call(rbind, lapply(a, '[[', names(a[[1]])[2]))

And then seeing that, could perhaps make it a one-liner with:

lapply( names(a[[1]]),   function(nm) do.call(rbind, lapply(a, '[[', nm)) )

-- 
David.
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 12-10-2014 07:14, Cesar Caballero escreveu:
>> Hi all,
>> 
>> I have an array of lists. All lists have the same names and the vectors inside each name have the same dimension.
>> 
>> For instance,
>> 
>> a[1:4]
>> [[1]]
>> [[1]]$var1
>> [1] 1 2 3 4 5
>> 
>> [[1]]$var2
>> [1] 6 7
>> 
>> 
>> [[2]]
>> [[2]]$var1
>> [1]  2  4  6  8 10
>> 
>> [[2]]$var2
>> [1] 12 14
>> 
>> [[3]]
>> [[3]]$var1
>> [1]  3  6  9 12 15
>> 
>> [[3]]$var2
>> [1] 18 21
>> 
>> 
>> I would like to apply rbind to concatenate all vectors for a given name, e.g. concatenate all the a[[]]$a
>> How can I do that?
>> 
>> Thanks very much in advance.
>> 
>> Best wishes
>> Cesar
>> 
>> 
>> ----------------------------------------------------------------------
>> Cesar Caballero
>> MRI engineer
>> www.bcbl.eu
>> 
>> Legal disclaimer/Aviso legal/Lege-oharra: www.bcbl.eu/legal-disclaimer
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ruipbarradas at sapo.pt  Sun Oct 12 19:31:41 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 12 Oct 2014 18:31:41 +0100
Subject: [R] rbind in array of lists
In-Reply-To: <79E0CB8D-277E-4640-A9EB-3A53AC282D21@comcast.net>
References: <1725180130.3447570.1413094449001.JavaMail.root@bcbl.eu>
	<543AA216.1020303@sapo.pt>
	<79E0CB8D-277E-4640-A9EB-3A53AC282D21@comcast.net>
Message-ID: <543ABAFD.1080402@sapo.pt>

Hello,

Em 12-10-2014 18:26, David Winsemius escreveu:
>
> On Oct 12, 2014, at 8:45 AM, Rui Barradas wrote:
>
>> Hello,
>>
>> Try the following.
>>
>> do.call(rbind, lapply(a, '[[', "var1"))
>> do.call(rbind, lapply(a, '[[', "var2"))
>
> Could perhaps (untested) make it more general with:
>
> do.call(rbind, lapply(a, '[[', names(a[[1]])[1]))
> do.call(rbind, lapply(a, '[[', names(a[[1]])[2]))
>
> And then seeing that, could perhaps make it a one-liner with:
>
> lapply( names(a[[1]]),   function(nm) do.call(rbind, lapply(a, '[[', nm)) )

Yes, I had thought of

lapply(seq_along(a[[1]]), function(i) do.call(rbind, lapply(a, '[[', i)))


Rui Barradas
>


From cmora at Dal.Ca  Sun Oct 12 22:20:42 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Sun, 12 Oct 2014 20:20:42 +0000
Subject: [R] Is xyz point inside 3d convex hull?
Message-ID: <1413145241750.57790@Dal.Ca>

Hi everyone,

I wonder if there is a code in r that can generate a 3d convex hull from a data-frame containing 3 columns and then use another database with the same three columns and for each row determine if the xyz point is inside or not the convex hull generated with the first database?

The package geometry allows to calculate a hull and it's volume. I was planning to calculate the volume of the convex hull after adding each point in the second database and if the hull gets bigger then the point is out and if not then the point is in. A problem with this method is that I have over 10 million points and the calculation for each point will take a lot of time.

Any guidance will be greatly appreciated,

Thanks,

Camilo

	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Sun Oct 12 22:24:25 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Sun, 12 Oct 2014 13:24:25 -0700
Subject: [R] Is xyz point inside 3d convex hull?
In-Reply-To: <1413145241750.57790@Dal.Ca>
References: <1413145241750.57790@Dal.Ca>
Message-ID: <F70AD697-D1F4-4693-9714-ED0947C987B4@u.washington.edu>

Check the R-news archive with approrpriate keywords.  There was a long exchange awhile back when I asked a similar question.

On Oct 12, 2014, at 1:20 PM, Camilo Mora <cmora at Dal.Ca> wrote:

> Hi everyone,
> 
> I wonder if there is a code in r that can generate a 3d convex hull from a data-frame containing 3 columns and then use another database with the same three columns and for each row determine if the xyz point is inside or not the convex hull generated with the first database?
> 
> The package geometry allows to calculate a hull and it's volume. I was planning to calculate the volume of the convex hull after adding each point in the second database and if the hull gets bigger then the point is out and if not then the point is in. A problem with this method is that I have over 10 million points and the calculation for each point will take a lot of time.
> 
> Any guidance will be greatly appreciated,
> 
> Thanks,
> 
> Camilo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From ligges at statistik.tu-dortmund.de  Sun Oct 12 23:15:30 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 12 Oct 2014 23:15:30 +0200
Subject: [R] problem in R2winBUGS
In-Reply-To: <CABLo8nFX5Pmuk-VpNmyHm+KcatO7NJq9Ew_FKg96fuUeqF8sow@mail.gmail.com>
References: <CABLo8nFX5Pmuk-VpNmyHm+KcatO7NJq9Ew_FKg96fuUeqF8sow@mail.gmail.com>
Message-ID: <543AEF72.8090503@statistik.tu-dortmund.de>



On 12.10.2014 15:06, thanoon younis wrote:
> Dear all Rusers
> I have error when i wanted to call winbugs from R to estamate parameters
> using bayesian analysis.
>
>   #Call WinBUGS
>
> model<-bugs(data1,data2,init1,init2,parameters,model.file="D:/Run/model.txt",
>      n.chains=2,n.iter=10000,n.burnin=4000,n.thin=1,DIC=True,
>      bugs.directory="c:/Program Files/WinBUGS14/",
>      working.directory="D:/Run/")
>
> and the error is
> #Call WinBUGS
>>
> model<-bugs(data1,data2,init1,init2,parameters,model.file="D:/Run/model.txt",
> +     n.chains=2,n.iter=10000,n.burnin=4000,n.thin=1,DIC=True,
> +     bugs.directory="c:/Program Files/WinBUGS14/",
> +     working.directory="D:/Run/")
> Error in bugs(data1, data2, init1, init2, parameters, model.file =
> "D:/Run/model.txt",  :
>    Number of initialized chains (length(inits)) != n.chains
>
> any help would be greatly appreciated
>


See ?bugs and find that you need to specify exactly one data object and 
one inits object. The latter can be a list containing inits for each chain.

Best,
Uwe Ligges


From cranatic at gmail.com  Mon Oct 13 00:40:05 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 12 Oct 2014 18:40:05 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <543b03456ec4e_5968648b13c188@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* adwave (1.0)
  Maintainer: Murray Cox
  Author(s): Jean Sanderson
  License: GPL (>= 2)
  http://crantastic.org/packages/adwave

  Implements wavelet-based approaches for describing population
  admixture. Principal Components Analysis (PCA) is used to define the
  population structure and produce a localized admixture signal for
  each individual. Wavelet summaries of the PCA output describe
  variation present in the data and can be related to population-level
  demographic processes. For more details, see accompanying paper.

* bdscale (1.0)
  Maintainer: Dave Mills
  Author(s): Dave Mills <dave.a.mills at gmail.com>
  License: GPL-2
  http://crantastic.org/packages/bdscale

  Provides a continuous date scale, omitting weekends and holidays

* BNSP (1.0.0)
  Maintainer: Georgios Papageorgiou
  Author(s): Georgios Papageorgiou
  License: GPL (>= 2)
  http://crantastic.org/packages/BNSP

  Markov chain Monte Carlo algorithms for non- and semi-parametric
  models

* CEC (0.9.1)
  Maintainer: Konrad Kamieniecki
  Author(s): Konrad Kamieniecki
  License: GPL-3
  http://crantastic.org/packages/CEC

  Cross-Entropy Clustering (CEC) divides the data into Gaussian type
  clusters. It performs the automatic reduction of unnecessary
  clusters, while at the same time allows the simultaneous use of
  various type Gaussian mixture models.

* ENiRG (0.1)
  Maintainer: Fernando Garcia Canovas
  Author(s): Fernando Canovas, Chiara Magliozzi, Jose Antonio Palazon-Ferrando,
             Frederico Mestre, Mercedes Gonzalez-Wanguemert
  License: GPL (>= 2)
  http://crantastic.org/packages/ENiRG

  The package allows to perform the Ecological Niche Factor Analysis,
  calculate habitat suitability maps and classify the habitat in
  suitability classes. Computations are executed in a throw-away GRASS
  environment from R in order to be able to perform analysis with
  large data sets.

* HiDimMaxStable (0.1)
  Maintainer: Alexis Bienvenue
  Author(s): Alexis Bienven??e [aut, cre], Christian Robert [aut]
  License: GPL (>= 2)
  http://crantastic.org/packages/HiDimMaxStable

  Inference of high dimensional max-stable distributions, from the paper
  &quot;Likelihood based inference for high-dimensional extreme value
  distributions&quot;, by A. Bienven??e and C. Robert, arXiv:1403.0065
  [stat.AP].

* HierO (0.1)
  Maintainer: Kari Tokola
  Author(s): Kari Tokola
  License: GPL-2
  http://crantastic.org/packages/HierO

  HierO is a graphical user interface (GUI) tool for calculating optimal
  statistical power and sample size for hierarchical data structure.
  HierO constructs a user defined sample size optimization problem to
  GAMS (General Algebraic Modeling System)form and uses Rneos package
  to send the problem to NEOS server for solving.

* ibelief (1.0)
  Maintainer: Kuang Zhou
  Author(s): Kuang Zhou <kzhoumath at 163.com>; Arnaud Martin
             <arnaud.martin at univ-rennes1.fr>
  License: GPL (>= 2)
  http://crantastic.org/packages/ibelief

  This package contains several basic functions to implement belief
  functions.

* MareyMap (1.2)
  Maintainer: Aurelie Siberchicot
  Author(s): Aurelie Siberchicot, Clement Rezvoy, Delphine Charif, Laurent Gueguen
             and Gabriel Marais
  License: GPL (>= 2)
  http://crantastic.org/packages/MareyMap

  A package to graphically estimate local recombination rates across a
  genome using marey maps.

* mfblock (1.0)
  Maintainer: Marc Fortier
  Author(s): Marc Fortier
  License: GPL-3
  http://crantastic.org/packages/mfblock

  Implementation of the simulated method of moments (smm) of Oh and
  Patton for copula-based multivariate models

* msBP (1.0)
  Maintainer: Antonio Canale
  Author(s): Antonio Canale
  License: GPL-2
  http://crantastic.org/packages/msBP

  Performs Bayesian nonparametric multiscale density estimation and
  multiscale testing of group differences with multiscale Bernstein
  polynomials (msBP) mixtures as in Canale and Dunson (2014).

* mvprpb (1.0.4)
  Maintainer: Noboru Nomura
  Author(s): Noboru Nomura
  License: BSD_3_clause + file LICENSE
  http://crantastic.org/packages/mvprpb

  Computes orthant probabilities multivariate normal distribution.

* NB (0.9)
  Maintainer: Tin-Yu Hui
  Author(s): Tin-Yu Hui @ Imperial College London
  License: GPL (>= 2)
  http://crantastic.org/packages/NB

  Estimate the effective population size of a closed population using
  genetic data collected from two or more data points.

* PerFit (1.2)
  Maintainer: Jorge N. Tendeiro
  Author(s): Jorge N. Tendeiro
  License: GPL (>= 2)
  http://crantastic.org/packages/PerFit

  PerFit contains several person fit indices that allow assessing
  whether individual response patterns to tests or questionnaires are
  (im)plausible given  the other respondents in the sample or a
  specified Item Response Theory model.

* PLordprob (1.0)
  Maintainer: Euloge Clovis Kenne Pagui
  Author(s): Euloge Clovis Kenne Pagui [aut,cre], Antonio Canale [aut], Alan Genz
             [ctb],  Adelchi Azzalini [ctb]
  License: GPL-2
  http://crantastic.org/packages/PLordprob

  Multivariate ordered probit model, i.e. the extension of the scalar
  ordered probit model where the observed variables have dimension
  greater than one. Estimation of the parameters is done via
  maximization of the pairwise likelihood, a special case of the
  composite likehood obtained as product of bivariate marginal
  distributions. The package uses the Fortran 77 subroutine SADMVN by
  Alan Genz, with minor adaptations made by Adelchi Azzalini in his
  &quot;mvnormt&quot; package for evaluating the two-dimensional Gaussian
  integrals involved in the pairwise log-likelihood. Optimization of
  the latter objective function  is performed via quasi-Newton
  box-constrained optimization algorithm, as implemented in nlminb.

* qicharts (0.1.0)
  Maintainer: Jacob Anhoej
  Author(s): Jacob Anhoej [aut, cre]
  License: GPL-3
  http://crantastic.org/packages/qicharts

  Functions for making run charts and  basic Shewhart control charts for
  measure and count data. The main function, qic, creates run and
  control charts and has a simple interface with a rich set of options
  to control data analysis and plotting, including options for
  automatic data aggregation by subgroups, easy analysis of
  before-and-after data, exclusion of one or more data points from
  analysis, and splitting charts into sequential time periods. Missing
  values and empty subgroups are handled gracefully.

* RAdwords (0.1)
  Maintainer: Johannes Burkhardt
  Author(s): Johannes Burkhardt <johannes.burkhardt at gmail.com>, Matthias Bannert
             <matthias.bannert at gmail.com>
  License: GPL (>= 2) | MIT + file LICENSE
  http://crantastic.org/packages/RAdwords

  The aim of RAdwords is loading Adwords data into R. Therefore the
  package implements three main features. First, the package provides
  an authentication process for R with the Adwords API via OAUTH2.
  Second, the package offers an interface to apply the Adwords query
  language in R and query the Adwords API with ad-hoc reports. Third,
  the received data are transformed into suitable data formats for
  further data processing and data analysis.

* RSQLServer (0.1.1)
  Maintainer: Imanuel Costigan
  Author(s): Imanuel Costigan [aut, cre], The jTDS Project [aut] (for MSSQL Server
             driver), Simon Urbanek [ctb], The Legion Of The Bouncy
             Castle [cph, ctb]
  License: GPL-2
  http://crantastic.org/packages/RSQLServer

  RSQLServer wraps the jTDS Project&#39;s JDBC 3.0 SQL Server driver and
  extends the RJDBC classes and DBI methods. It defines a
  SQLServerDriver, SQLServerConnection &amp; SQLServerRsult S4 classes as
  extensions of the RJDBC equivalent classes. Most of the DBI methods
  will simply be calls to methods defined by RJDBC classes. However,
  the dbConnect and some of the dbGetInfo methods are specific to SQL
  Server. The jTDS drivers do extend to Sybase SQL Server, but
  currently, only Microsoft SQL Server is supported by this package.

* saps (1.0.0)
  Maintainer: Daniel Schmolze
  Author(s): Daniel Schmolze [aut, cre], Andrew Beck [aut], Benjamin Haibe-Kains
             [aut]
  License: MIT + file LICENSE
  http://crantastic.org/packages/saps

  Functions implementing the Significance Analysis of Prognostic
  Signatures method (SAPS). SAPS provides a robust method for
  identifying biologically significant gene sets associated with
  patient survival. Three basic statistics are computed. First,
  patients are clustered into two survival groups based on
  differential expression of a candidate gene set. P_pure is
  calculated as the probability of no survival difference between the
  two groups. Next, the same procedure is applied to randomly
  generated gene sets, and P_random is calculated as the proportion
  achieving a P_pure as significant as the candidate gene set.
  Finally, a pre-ranked Gene Set Enrichment Analysis (GSEA) is
  performed by ranking all genes by concordance index, and P_enrich is
  computed to indicate the degree to which the candidate gene set is
  enriched for genes with univariate prognostic significance. A
  SAPS_score is calculated to summarize the three statistics, and
  optionally a Q-value is computed to estimate the significance of the
  SAPS_score by calculating SAPS_scores for random gene sets.

* snipEM (1.0)
  Maintainer: Alessio Farcomeni
  Author(s): Alessio Farcomeni, Andy Leung
  License: GPL (>= 2)
  http://crantastic.org/packages/snipEM

  Snipping methods

* sptm (14.10-8)
  Maintainer: Youyi Fong
  Author(s): Youyi Fong <yfong at fhcrc.org>, Krisztian Sebestyen
             <ksebestyen at gmail.com>
  License: GPL (>= 2)
  http://crantastic.org/packages/sptm

  Semiparametric transformation model, calibration weights

* TEEReg (1.0)
  Maintainer: Wei Jiang
  Author(s): Wei Jiang and Matthew S. Mayo
  License: GPL (>= 2)
  http://crantastic.org/packages/TEEReg

  For fitting multiple linear regressions, the ordinary least squares
  approach is sensitive to outliers and/or violations of model
  assumptions. The trimmed elemental estimators are more robust to
  such situations. This package contains functions for computing the
  trimmed elemental estimates, as well as for creating the
  bias-corrected and accelerated bootstrap confidence intervals in the
  context of trimmed elemental regressions.

* vegan3d (0.65-0)
  Maintainer: Jari Oksanen
  Author(s): Jari Oksanen [aut, cre], Roeland Kindt [aut], Gavin L. Simpson [aut]
  License: GPL-2
  http://crantastic.org/packages/vegan3d

  Static and dynamic 3D plots to be used with ordination results and in
  diversity analysis, especially with the vegan package


Updated packages
----------------

Benchmarking (0.24), cclust (0.6-19), checkpoint (0.3.3), devtools
(1.6.1), diseasemapping (1.1.0), frailtypack (2.7.1), fscaret
(0.8.6.3), G2Sd (2.1.2), geospt (1.0-0), GISTools (0.7-4),
GlobalOptions (0.0.2), grofit (1.1.1-1), lfe (1.7-1404), lfe
(1.7-1401), minqa (1.2.4), mirt (1.6.1), mnormpow (0.1.1), MonetDB.R
(0.9.5), moult (1.4), mpcv (1.1), MplusAutomation (0.6-3), mpt
(0.5-0), MTurkR (0.5.51), nlme (3.1-118), ParamHelpers (1.4), phangorn
(1.99-9), pingr (1.1.0), PivotalR (0.1.17.8), PowerTOST (1.2-02),
protr (0.4-1), pvclust (1.3-0), qcc (2.6), quantmod (0.4-2), R.matlab
(3.1.1), R.utils (1.34.0), rcdk (3.3.1), Rcmdr (2.1-3), Rdsm (2.1.1),
repra (0.4.2), RMark (2.1.9), robustreg (0.1-5), sft (2.0-7),
stringdist (0.8.1), subselect (0.12-4), VecStatGraphs3D (1.6), VLMC
(1.4-0), YourCast (1.6.2), ZIM (1.0.2)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From anna.zakrisson at su.se  Sun Oct 12 09:24:41 2014
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Sun, 12 Oct 2014 07:24:41 +0000
Subject: [R] seqinr ?: Splitting a factor name into several columns. Dealing
 with metabarcoding data.
Message-ID: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>

Hi,

I have a question how to split a factor name into different columns. I have metabarcoding data and need to merge the FASTA-file with the taxonomy- and counttable files (dataframes). To be able to do this merge, I need to isolate the common identifier, that unfortunately is baked in with a lot of other labels in the factor name eg:
sequence identifier: M01271_77_000000000.A8J0P_1_1101_10150_1525.1.322519.sample_1.sample_2

I want to split this name at every "." to get several columns:
column1: M01271_77_000000000
column2: A8J0P_1_1101_10150_1525
column3: 1
column4: 322519
column5: sample_1
column6: sample_2

I must add that I have no influence on how these names are given. This is how thay are supplied from Illumina Miseq. I just need to be able to deal with it.

Here is some extremely simplified dummy data to further show the issue at hand:

df1 <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
                  Z.identifierA.B1298712 = factor(rep(LETTERS[1:2], each = 5)))
df2 <- data.frame(cbind(B = 13:22, K = rnorm(10)),
                  Q.identifierA.B4668726 = factor(rep(LETTERS[1:2], each = 5)))

# I have metabarcoding data with one FASTA-file, one count table and one taxonomy file
# Above dummy data is just showing the issue at hand. I want to be able to merge my three
# original data frames (here, the dummy data is only two dataframes). The problem is that
# the only identifier that is commmon for the dataframes is "hidden" in the
# factor name eg: Z.identifierA.1298712 and Q.identifierA.4668726. I hence need to be able
# to split this name up into different columns to get "identifierA" alone as one column name
# Then I can merge the dataframes.
# How can I do this in R. I know that it can be done in excel, but I would like to
# produce a complete R-script to get a fast pipeline and avoid copy and paste errors.
# This is what I want it to look:

df1.goal <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
                  Z = factor(rep(LETTERS[1:2], each = 5)),
                  identifierA = factor(rep(LETTERS[1:2], each = 5)),
                  B1298712 = factor(rep(LETTERS[1:2], each = 5)))

# Many thank's and with kind regards
Anna Zakrisson

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>

	[[alternative HTML version deleted]]


From infojomy at gmail.com  Sun Oct 12 11:58:28 2014
From: infojomy at gmail.com (Jomy Jose)
Date: Sun, 12 Oct 2014 15:28:28 +0530
Subject: [R] Q-Q Plot for loglogistic,
	lognormal and 2 parameter exponential distributions
Message-ID: <CADGufDHMDG+M1k3C2gHGPNXGN2oyWRVK0CKNtMxFj-=nrup1QQ@mail.gmail.com>

Is there any R package that can plot Q-Q plot for loglogistic,lognormal and
2 parameter exponential distributions or is there a way to check the model
fit for these distributions in R ?

	[[alternative HTML version deleted]]


From leobriant at gmail.com  Mon Oct 13 02:25:21 2014
From: leobriant at gmail.com (Brian Leo)
Date: Sun, 12 Oct 2014 17:25:21 -0700
Subject: [R] How best to model these datasets
Message-ID: <CAJi8COtvHq9EDZYT1BF79nFQ2nvYjsCNpwQ71UpQftHYJsr2uw@mail.gmail.com>

Hello,

I am a stats novice and I was wondering what kind of model would work best
with the two datasets that are displayed.  The graphs show an incremental
area analysis for two feral cat home ranges where area increases with
increasing number of GPS fixes.

Thanks,

Brian


-- 
Brian Leo
School of Aquatic and Fishery Sciences
University of Washington
1122 Boat St NE
Box 355020
Seattle, WA 98195
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot.png
Type: image/png
Size: 46519 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141012/32b5a038/attachment.png>

From jdnewmil at dcn.davis.CA.us  Mon Oct 13 04:22:21 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 12 Oct 2014 19:22:21 -0700
Subject: [R] How best to model these datasets
In-Reply-To: <CAJi8COtvHq9EDZYT1BF79nFQ2nvYjsCNpwQ71UpQftHYJsr2uw@mail.gmail.com>
References: <CAJi8COtvHq9EDZYT1BF79nFQ2nvYjsCNpwQ71UpQftHYJsr2uw@mail.gmail.com>
Message-ID: <3DBD2D5E-5B84-43AA-984A-15498863AAB5@dcn.davis.CA.us>

This list is for questions about R (see the Posting Guide), yet this is a question about statistics. You might consider paying at CrossValidated, but I would suggest not being quite so vague.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 12, 2014 5:25:21 PM PDT, Brian Leo <leobriant at gmail.com> wrote:
>Hello,
>
>I am a stats novice and I was wondering what kind of model would work
>best
>with the two datasets that are displayed.  The graphs show an
>incremental
>area analysis for two feral cat home ranges where area increases with
>increasing number of GPS fixes.
>
>Thanks,
>
>Brian


From dilaradi21 at gmail.com  Mon Oct 13 04:25:47 2014
From: dilaradi21 at gmail.com (dila radi)
Date: Sun, 12 Oct 2014 19:25:47 -0700
Subject: [R] Finding the Summation of Monthly Amount
Message-ID: <CAMgoKBJVmXLGm1fxgkHGpcyUko+ZCU=tfmiGTdzrM3miB6snKw@mail.gmail.com>

Hi all,

Could someone help me on this? I have this kind of data set

structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1972L, 1972L, 1972L, 1972L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1973L, 1973L, 1973L), Month = c(1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), Rain = c(68, 6, 6.3, 55.3,
18.2, 1.2, 5.3, 0, 0, 1.2, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.5,
0, 0, 12.1, 0.5, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 50.8, 7.1, 0, 0, 0, 4, 22, 14.7, 0, 17.7, 0,
106.6, 0, 4.8, 14.7, 2.2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 8.6, 3.3, 0, 16.7, 0, 5.8, 9.1, 0, 0, 0, 0, 0, 0, 0, 12.6,
12.9, 0, 0, 0, 0, 0, 3.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50.7,
1.2, 2.5, 0, 0, 0, 0, 17, 0, 2.5, 0, 0, 0, 0, 3.8, 0, 0, 0, 0,
0, 0, 2.7, 2.7, 12.6, 0, 0, 0, 0, 0, 0, 0, 3.3, 0, 0, 5.5, 2.5,
0, 35.5, 5, 3.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6.3,
0, 0, 0, 5.8, 0, 0, 0, 15.4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.5,
30.2, 64.5, 0, 11.9, 3.8, 3.3, 7.1, 27.9, 32, 106.6, 0.2, 0,
5.3, 4.5, 0, 0, 1.5, 11.9, 6.6, 0, 0, 11.9, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 8.3, 8.1, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 30.9, 1.2,
0, 0, 9.3, 82.5, 16.5, 0, 0, 0, 0.7, 0, 0, 36, 0, 3.8, 0, 0,
0, 0, 0, 0, 0, 4.3, 0, 0, 38, 8.8, 0, 26.4, 0, 0, 0.7, 13.4,
9.6, 8.3, 0, 3.8, 8.8, 0, 45.7, 1.2, 12.9, 0, 0, 0, 21.3, 1,
0)), .Names = c("Year", "Month", "Rain"), class = "data.frame", row.names =
c(NA,
-271L))

and I want to find the sum of Rain in column 3 according to their month.
How could I achieved this so that it would appear as follow:

structure(list(Year = c(1971L, 1971L, 1971L, 1972L, 1972L, 1972L,
1973L, 1973L, 1973L), Month = c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
3L), Rain = c(176.8, 228.2, 90.9, 81, 73.1, 127.7, 242.8, 189.5,
204.2)), .Names = c("Year", "Month", "Rain"), class = "data.frame",
row.names = c(NA,
-9L))

Thank you so much

Dila

	[[alternative HTML version deleted]]


From mmuurr at gmail.com  Mon Oct 13 05:09:06 2014
From: mmuurr at gmail.com (Murat Tasan)
Date: Sun, 12 Oct 2014 21:09:06 -0600
Subject: [R] par("plt") behaving inconsistely? bug?
In-Reply-To: <5435EFFD.8080103@stat.auckland.ac.nz>
References: <CA+YV+HxbDw693gooVktzekSYgnAaBTdC=Wtfurz54g1o1bsg-A@mail.gmail.com>
	<CAFEqCdxM5vz-2MCeNTNmreugXvST43jpypmknX63dpgD_amB8A@mail.gmail.com>
	<CA+YV+HyqpfNO2U7ako1rcy9WT_DUi2WvQvsEFpMW_7cEdd=Nxg@mail.gmail.com>
	<5435EFFD.8080103@stat.auckland.ac.nz>
Message-ID: <CA+YV+HwGuD3ZLh8hqL_Au=KFSOZKofMt=yunHk-RravXyLdPBw@mail.gmail.com>

Fair enough, thanks for the reply, Paul.
I guess my follow-up thought is just on some undocumented
inconsistencies with which drawing functions handle upstream par(plt)
changes.
box() and axis(), for example, doesn't seem to mind at all, while more
data-oriented commands, e.g. points(...), balk without either (i)
something like par(new=TRUE); plot.new(); , or (ii) box() or axis()
appearing upstream.
But, at the same time, if no plot.new() call has ever been made on the
current device, both box() and points() give the same (or similar)
"plot.new() hasn't been called yet" error.

I'm not complaining, rather just sharing observations on some
seemingly (to me, perhaps not to all!) undocumented inconsistencies in
behavior.
I love having the par(plt) functionality around, and I think your
'best practices' description for its use is great.
Perhaps some version of your post can be added to the man page for par(plt)?

Cheers and thanks again!

-murat


On Wed, Oct 8, 2014 at 8:16 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> Hi
>
> The canonical poison is this ...
>
> par(plt)
> plot.new()
> ...
> par(plt)
> par(new=TRUE)
> plot.new()
> ...
> par(plt)
> par(new=TRUE)
> plot.new()
>
> The idea is to set up parameters that control the placement of a plot, e.g.,
> par(plt), and then start a plot, with plot.new().  If you want more than one
> plot on a page (and par(mfrow) does not suffice) then you set up new
> placement parameters, tell R not to start a new page, with par(new=TRUE),
> then start another plot, with plot.new().
>
> Your code does not follow the "spirit" of the R graphics model because it
> starts a plot with one set of placement parameters and then changes those
> placement parameters several times within the same plot (instead of starting
> a new plot for each new set of placement parameters).
>
> I had a look at the C code that leads to your "surprising" result and there
> is at least one infelicity in there, but I could not see a simple fix that
> would make your example "work" without a high risk of breaking other things.
> So I'm afraid my best advice is to change your code to work with the
> graphics system.
>
> The layout() function might provide a less unpleasant approach to having
> more than one plot region on the page, depending on how complex your
> arrangement of plot regions is.
>
> Another alternative is to use the 'grid' graphics package, which is designed
> to allow for the flexible creation of multiple regions, depending on what
> you want to draw in each of those regions.
>
> Paul
>
>
> On 10/07/14 15:33, Murat Tasan wrote:
>>
>> 6. iteratively downgrade to earlier versions of R until it's working
>> again... then try to diff out the offending source code change.
>> i can try this, but i probably won't get to it for at least a few weeks
>> :-/
>>
>> in the meantime, i'm tacking on box(lty = 0) to every par(plt = ...) call,
>> e.g.
>>>
>>> par("plt" = some_plt_coordinates); box(lty = 0)
>>
>>
>> in the short term, this works.
>> clip(...), a combination of par("new" = TRUE); plot.new(), and a whole
>> bunch of other kludges work, too... pick your poison :-)
>>
>> cheers and thanks!
>>
>> -murat
>>
>> On Mon, Oct 6, 2014 at 2:08 PM, Greg Snow <538280 at gmail.com> wrote:
>>>
>>> I believe that what is happening is that the clipping region is being
>>> reset when you call box, but not when you call rect.  If you insert
>>> the command "par(xpd=NA)" (or TRUE instead of NA) after the plot.new
>>> and use the rect commands then you can see both rectangles (because
>>> this turns the clipping off).  Working with the clipping region
>>> (indirectly in your case) is complex since some functions properly
>>> reset the region and others do not (and  making the others
>>> automatically reset it may cause other problems when they reset a
>>> clipping region that should not be reset).
>>>
>>> So the options are:
>>>
>>> 1 dive into the source code enough to figure out if fixing rect to
>>> work with the clipping region is simple or not and submitting a patch
>>> 2 wait for Prof Brian Ripley to notice this fact and do the above (he
>>> has fixed a couple of other functions when made aware)
>>> 3 use par(xpd=TRUE) (or NA) to not clip to the plotting region (this
>>> is simple, but will allow things to be drawn outside of the plotting
>>> region, on simple example is using abline)
>>> 4 use a function that properly sets the clipping region (such as box)
>>> before plotting anything else
>>> 5 call clip(0,1,0,1) (or with the actual user coordinates) to manually
>>> set the clipping region
>>> 6 other?
>>>
>>>
>>> On Mon, Oct 6, 2014 at 12:00 PM, Murat Tasan <mmuurr at gmail.com> wrote:
>>>>
>>>> Hi all -- I just encountered a behavior that I believe has changed
>>>> from previous versions, though I haven't chased back the last version
>>>> that behaves as my existing code expects quite yet.
>>>> Perhaps this is a bug, though perhaps I'm missing a subtle detail
>>>> somewhere in the documentation...
>>>>
>>>> Here's some code that works as expected (in R 3.1.1):
>>>>
>>>> ########################################
>>>> pdf()
>>>> plot.new()
>>>>
>>>> original_plt <- par("plt")
>>>>
>>>> plt_1 <- c(original_plt[1],
>>>>             original_plt[1] + (original_plt[2] - original_plt[1]) / 2,
>>>>             original_plt[3],
>>>>             original_plt[3] + (original_plt[4] - original_plt[3]) / 2)
>>>> par("plt" = plt_1)
>>>> plot.window(xlim = c(0, 1), ylim = c(0, 1))
>>>> box()
>>>> plt_2 <- c(plt_1[2],
>>>>             original_plt[2],
>>>>             plt_1[4],
>>>>             original_plt[4])
>>>> par("plt" = plt_2)
>>>> plot.window(xlim = c(0, 1), ylim = c(0, 1))
>>>> box()
>>>> par("plt" = original_plt)
>>>> box(lty = 2)
>>>> dev.off()
>>>> ########################################
>>>>
>>>> This will draw 3 boxes... one in the lower left corner (specified by
>>>> plt_1), one in the top right corner (specified by plt_2), and one
>>>> dotted box around the full plot box (original_plt).
>>>>
>>>> Now, if you replace the first two box() calls by: rect(0, 0, 1, 1),
>>>> only the lower-left rectangle is drawn.
>>>> If you _add_ rect(0, 0, 1, 1) after each box() call, all boxes and
>>>> rectangles are correctly drawn.
>>>>
>>>> It seems that after setting plt once, subsequent plt alterations put
>>>> the device into a state that will permits drawing of _some_ things
>>>> (e.g. box()), but not other things (e.g. rect, lines, points).
>>>>
>>>> A kludge to fix this is to call box(col = "white")... but that's quite
>>>> the kludge, indeed!
>>>> Axis() works just like box(), too... but I haven't exhausted which
>>>> drawing functions work and which don't.
>>>>
>>>> I'd classify this is a bug, but I thought I'd check here first.
>>>> I've also only checked this so far with the pdf() device, so I don't
>>>> know if it is somehow device-specific.
>>>>
>>>> I detected this because some existing code (that worked on some
>>>> earlier version of R, sorry that I don't know which one yet...) has
>>>> suddenly stopped working!
>>>>
>>>> Cheers!
>>>>
>>>> -murat
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
>>> --
>>> Gregory (Greg) L. Snow Ph.D.
>>> 538280 at gmail.com
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Dr Paul Murrell
> Department of Statistics
> The University of Auckland
> Private Bag 92019
> Auckland
> New Zealand
> 64 9 3737599 x85392
> paul at stat.auckland.ac.nz
> http://www.stat.auckland.ac.nz/~paul/


From rhelpmaillist at 163.com  Mon Oct 13 06:21:56 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 13 Oct 2014 12:21:56 +0800 (CST)
Subject: [R]   Not related with R,
 but  i want to jion in a statistics help maillist, can you tell me some ?
Message-ID: <59da469a.6937.14907bdbed8.Coremail.rhelpmaillist@163.com>


Dear usRers,
??? I? have some statistic problems, and i want to join a Professional maillist for it. can you tell me some maillists?TKS!





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From pdalgd at gmail.com  Mon Oct 13 09:53:45 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 13 Oct 2014 09:53:45 +0200
Subject: [R] Finding the Summation of Monthly Amount
In-Reply-To: <CAMgoKBJVmXLGm1fxgkHGpcyUko+ZCU=tfmiGTdzrM3miB6snKw@mail.gmail.com>
References: <CAMgoKBJVmXLGm1fxgkHGpcyUko+ZCU=tfmiGTdzrM3miB6snKw@mail.gmail.com>
Message-ID: <DABDB894-0F6B-460A-BE03-04AC52979413@gmail.com>

Looks like a job for aggregate()

-pd

On 13 Oct 2014, at 04:25 , dila radi <dilaradi21 at gmail.com> wrote:

> Hi all,
> 
> Could someone help me on this? I have this kind of data set
> 
> structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1972L, 1972L, 1972L, 1972L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1973L, 1973L, 1973L), Month = c(1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
> 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L,
> 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L), Rain = c(68, 6, 6.3, 55.3,
> 18.2, 1.2, 5.3, 0, 0, 1.2, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2.5,
> 0, 0, 12.1, 0.5, 0, 0, 0, 0, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 50.8, 7.1, 0, 0, 0, 4, 22, 14.7, 0, 17.7, 0,
> 106.6, 0, 4.8, 14.7, 2.2, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 8.6, 3.3, 0, 16.7, 0, 5.8, 9.1, 0, 0, 0, 0, 0, 0, 0, 12.6,
> 12.9, 0, 0, 0, 0, 0, 3.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 50.7,
> 1.2, 2.5, 0, 0, 0, 0, 17, 0, 2.5, 0, 0, 0, 0, 3.8, 0, 0, 0, 0,
> 0, 0, 2.7, 2.7, 12.6, 0, 0, 0, 0, 0, 0, 0, 3.3, 0, 0, 5.5, 2.5,
> 0, 35.5, 5, 3.3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 6.3,
> 0, 0, 0, 5.8, 0, 0, 0, 15.4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 5.5,
> 30.2, 64.5, 0, 11.9, 3.8, 3.3, 7.1, 27.9, 32, 106.6, 0.2, 0,
> 5.3, 4.5, 0, 0, 1.5, 11.9, 6.6, 0, 0, 11.9, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 8.3, 8.1, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 30.9, 1.2,
> 0, 0, 9.3, 82.5, 16.5, 0, 0, 0, 0.7, 0, 0, 36, 0, 3.8, 0, 0,
> 0, 0, 0, 0, 0, 4.3, 0, 0, 38, 8.8, 0, 26.4, 0, 0, 0.7, 13.4,
> 9.6, 8.3, 0, 3.8, 8.8, 0, 45.7, 1.2, 12.9, 0, 0, 0, 21.3, 1,
> 0)), .Names = c("Year", "Month", "Rain"), class = "data.frame", row.names =
> c(NA,
> -271L))
> 
> and I want to find the sum of Rain in column 3 according to their month.
> How could I achieved this so that it would appear as follow:
> 
> structure(list(Year = c(1971L, 1971L, 1971L, 1972L, 1972L, 1972L,
> 1973L, 1973L, 1973L), Month = c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 2L,
> 3L), Rain = c(176.8, 228.2, 90.9, 81, 73.1, 127.7, 242.8, 189.5,
> 204.2)), .Names = c("Year", "Month", "Rain"), class = "data.frame",
> row.names = c(NA,
> -9L))
> 
> Thank you so much
> 
> Dila
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From Keith.Jewell at campdenbri.co.uk  Mon Oct 13 10:25:16 2014
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Mon, 13 Oct 2014 09:25:16 +0100
Subject: [R] Is xyz point inside 3d convex hull?
In-Reply-To: <F70AD697-D1F4-4693-9714-ED0947C987B4@u.washington.edu>
References: <1413145241750.57790@Dal.Ca>
	<F70AD697-D1F4-4693-9714-ED0947C987B4@u.washington.edu>
Message-ID: <543B8C6C.10500@campdenbri.co.uk>

Back in 2009 I posted some code to this list, see:
<http://tolstoy.newcastle.edu.au/R/e8/help/09/12/8784.html>

I submitted the function 'inhull' to the geometry package maintainer, 
but I don't think it was ever included.

HTH

Keith J
On 12/10/2014 21:24, Don McKenzie wrote:
> Check the R-news archive with approrpriate keywords.  There was a long exchange awhile back when I asked a similar question.
>
> On Oct 12, 2014, at 1:20 PM, Camilo Mora <cmora at Dal.Ca> wrote:
>
>> Hi everyone,
>>
>> I wonder if there is a code in r that can generate a 3d convex hull from a data-frame containing 3 columns and then use another database with the same three columns and for each row determine if the xyz point is inside or not the convex hull generated with the first database?
>>
>> The package geometry allows to calculate a hull and it's volume. I was planning to calculate the volume of the convex hull after adding each point in the second database and if the hull gets bigger then the point is out and if not then the point is in. A problem with this method is that I have over 10 million points and the calculation for each point will take a lot of time.
>>
>> Any guidance will be greatly appreciated,
>>
>> Thanks,
>>
>> Camilo
>>
>> 	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon Oct 13 10:55:49 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 13 Oct 2014 10:55:49 +0200
Subject: [R] Q-Q Plot for loglogistic,
	lognormal and 2 parameter exponential distributions
In-Reply-To: <CADGufDHMDG+M1k3C2gHGPNXGN2oyWRVK0CKNtMxFj-=nrup1QQ@mail.gmail.com>
References: <CADGufDHMDG+M1k3C2gHGPNXGN2oyWRVK0CKNtMxFj-=nrup1QQ@mail.gmail.com>
Message-ID: <C32CE26B-B099-4DB0-88FE-5E2531524F65@gmail.com>

A basic approach is

x <- rchisq(1000, 4)
qqplot(qchisq(ppoints(x), 4), x) 
abline(0,1)

Substitute whatever distribution and parameters that might apply. Notice that if you don't have a location-scale family of distributions, you need to compare to the identity line, not just look for linearity.

-pd

On 12 Oct 2014, at 11:58 , Jomy Jose <infojomy at gmail.com> wrote:

> Is there any R package that can plot Q-Q plot for loglogistic,lognormal and
> 2 parameter exponential distributions or is there a way to check the model
> fit for these distributions in R ?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pollaroid at gmail.com  Mon Oct 13 14:57:45 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Mon, 13 Oct 2014 14:57:45 +0200
Subject: [R] How to sum some columns based on their names
Message-ID: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>

I want to sum columns based on their names. As an exampel how could I
sum columns which contain 6574, 7584 and 85 as column names?  In
addition, how could I sum those which contain 6574, 7584 and 85 in
ther names and have a prefix "f". My data contains several variables
with

I want to sum columns based on their names. As an exampel how could I
sum columns which contain 6574, 7584 and 85 as column names?  In
addition, how could I sum those which contain 6574, 7584 and 85 in
ther names and have a prefix "f". My data contains several variables
with

dput(df1)
structure(list(date = structure(c(1230768000, 1230854400, 1230940800,
1231027200, 1231113600, 1231200000, 1231286400, 1231372800, 1231459200,
1231545600, 1231632000), class = c("POSIXct", "POSIXt"), tzone = "UTC"),
    f014card = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), f1534card = c(0,
    1, 1, 0, 0, 1, 0, 0, 1, 0, 1), f3564card = c(1, 6, 1, 5,
    5, 4, 4, 7, 6, 4, 6), f6574card = c(3, 6, 4, 5, 5, 2, 10,
    3, 4, 2, 4), f7584card = c(13, 6, 1, 4, 10, 6, 8, 12, 10,
    4, 3), f85card = c(5, 3, 1, 0, 2, 10, 7, 9, 1, 7, 3), m014card = c(0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0), m1534card = c(0, 0, 1, 0,
    0, 0, 0, 1, 1, 1, 0), m3564card = c(12, 7, 4, 7, 12, 13,
    12, 7, 12, 2, 11), m6574card = c(3, 4, 8, 8, 8, 10, 7, 6,
    7, 7, 5), m7584card = c(8, 10, 5, 4, 12, 7, 14, 11, 9, 1,
    11), m85card = c(1, 4, 3, 0, 3, 4, 5, 5, 4, 5, 0)), .Names = c("date",
"f014card", "f1534card", "f3564card", "f6574card", "f7584card",
"f85card", "m014card", "m1534card", "m3564card", "m6574card",
"m7584card", "m85card"), class = "data.frame", row.names = c("1",
"2", "3", "4", "5", "6", "7", "8", "9", "10", "11"))


From deter088 at umn.edu  Mon Oct 13 15:05:43 2014
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 13 Oct 2014 08:05:43 -0500
Subject: [R] How to sum some columns based on their names
In-Reply-To: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
References: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
Message-ID: <CAOLJphkH-OD4EEdj2E7NxrgjQCOBJBy28bUHc1F7qVrcMP+_xA@mail.gmail.com>

You can use grep with some basic regex, index your dataframe, and colSums

colSums(df[,grep("*6574*|*7584*|*85*", colnames(df))])
colSums(df[,grep("f6574*|f7584*|f85*", colnames(df))])


Regards,
Dr. Charles Determan

On Mon, Oct 13, 2014 at 7:57 AM, Kuma Raj <pollaroid at gmail.com> wrote:

> I want to sum columns based on their names. As an exampel how could I
> sum columns which contain 6574, 7584 and 85 as column names?  In
> addition, how could I sum those which contain 6574, 7584 and 85 in
> ther names and have a prefix "f". My data contains several variables
> with
>
> I want to sum columns based on their names. As an exampel how could I
> sum columns which contain 6574, 7584 and 85 as column names?  In
> addition, how could I sum those which contain 6574, 7584 and 85 in
> ther names and have a prefix "f". My data contains several variables
> with
>
> dput(df1)
> structure(list(date = structure(c(1230768000, 1230854400, 1230940800,
> 1231027200, 1231113600, 1231200000, 1231286400, 1231372800, 1231459200,
> 1231545600, 1231632000), class = c("POSIXct", "POSIXt"), tzone = "UTC"),
>     f014card = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), f1534card = c(0,
>     1, 1, 0, 0, 1, 0, 0, 1, 0, 1), f3564card = c(1, 6, 1, 5,
>     5, 4, 4, 7, 6, 4, 6), f6574card = c(3, 6, 4, 5, 5, 2, 10,
>     3, 4, 2, 4), f7584card = c(13, 6, 1, 4, 10, 6, 8, 12, 10,
>     4, 3), f85card = c(5, 3, 1, 0, 2, 10, 7, 9, 1, 7, 3), m014card = c(0,
>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0), m1534card = c(0, 0, 1, 0,
>     0, 0, 0, 1, 1, 1, 0), m3564card = c(12, 7, 4, 7, 12, 13,
>     12, 7, 12, 2, 11), m6574card = c(3, 4, 8, 8, 8, 10, 7, 6,
>     7, 7, 5), m7584card = c(8, 10, 5, 4, 12, 7, 14, 11, 9, 1,
>     11), m85card = c(1, 4, 3, 0, 3, 4, 5, 5, 4, 5, 0)), .Names = c("date",
> "f014card", "f1534card", "f3564card", "f6574card", "f7584card",
> "f85card", "m014card", "m1534card", "m3564card", "m6574card",
> "m7584card", "m85card"), class = "data.frame", row.names = c("1",
> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"))
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Dr. Charles Determan, PhD
Integrated Biosciences

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Oct 13 15:30:27 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 13 Oct 2014 06:30:27 -0700
Subject: [R] How to sum some columns based on their names
In-Reply-To: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
References: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
Message-ID: <DAF67522-D8B7-427A-81AA-030575FC3F03@dcn.davis.CA.us>

Learn regular expressions.. there are many websites and books that describe how they work. R has a number of functions that use them...

?regexp
?grep

For example...

grep("^[^0-9]*(6574|85|7584)[^0-9]*$",names(dta))

where dta is your data frame. You can read that regular expression as zero or more characters that are not digits at the beginning of the string, followed by any of three specified sequences of digits, followed by zero or more non-digit characters at the end of the string.

You can then use that function as the column specification index to look only at certain columns. The sapply function can apply the sum function to all of those columns:

sapply(dta[,grep("^[^0-9]*(6574|85|7584)[^0-9]*$",names(dta))],sum)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 13, 2014 5:57:45 AM PDT, Kuma Raj <pollaroid at gmail.com> wrote:
>I want to sum columns based on their names. As an exampel how could I
>sum columns which contain 6574, 7584 and 85 as column names?  In
>addition, how could I sum those which contain 6574, 7584 and 85 in
>ther names and have a prefix "f". My data contains several variables
>with
>
>I want to sum columns based on their names. As an exampel how could I
>sum columns which contain 6574, 7584 and 85 as column names?  In
>addition, how could I sum those which contain 6574, 7584 and 85 in
>ther names and have a prefix "f". My data contains several variables
>with
>
>dput(df1)
>structure(list(date = structure(c(1230768000, 1230854400, 1230940800,
>1231027200, 1231113600, 1231200000, 1231286400, 1231372800, 1231459200,
>1231545600, 1231632000), class = c("POSIXct", "POSIXt"), tzone =
>"UTC"),
>    f014card = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), f1534card = c(0,
>    1, 1, 0, 0, 1, 0, 0, 1, 0, 1), f3564card = c(1, 6, 1, 5,
>    5, 4, 4, 7, 6, 4, 6), f6574card = c(3, 6, 4, 5, 5, 2, 10,
>    3, 4, 2, 4), f7584card = c(13, 6, 1, 4, 10, 6, 8, 12, 10,
>  4, 3), f85card = c(5, 3, 1, 0, 2, 10, 7, 9, 1, 7, 3), m014card = c(0,
>    0, 0, 0, 0, 0, 0, 0, 0, 0, 0), m1534card = c(0, 0, 1, 0,
>    0, 0, 0, 1, 1, 1, 0), m3564card = c(12, 7, 4, 7, 12, 13,
>    12, 7, 12, 2, 11), m6574card = c(3, 4, 8, 8, 8, 10, 7, 6,
>    7, 7, 5), m7584card = c(8, 10, 5, 4, 12, 7, 14, 11, 9, 1,
> 11), m85card = c(1, 4, 3, 0, 3, 4, 5, 5, 4, 5, 0)), .Names = c("date",
>"f014card", "f1534card", "f3564card", "f6574card", "f7584card",
>"f85card", "m014card", "m1534card", "m3564card", "m6574card",
>"m7584card", "m85card"), class = "data.frame", row.names = c("1",
>"2", "3", "4", "5", "6", "7", "8", "9", "10", "11"))
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Oct 13 15:32:24 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 13 Oct 2014 06:32:24 -0700
Subject: [R] How to sum some columns based on their names
In-Reply-To: <CAOLJphkH-OD4EEdj2E7NxrgjQCOBJBy28bUHc1F7qVrcMP+_xA@mail.gmail.com>
References: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
	<CAOLJphkH-OD4EEdj2E7NxrgjQCOBJBy28bUHc1F7qVrcMP+_xA@mail.gmail.com>
Message-ID: <43C230D9-97A7-4714-9C03-22168AB8E90D@dcn.davis.CA.us>

Your regular expressions are invalid, Charles. You seem to be thinking of file name globbing as at the command line.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 13, 2014 6:05:43 AM PDT, Charles Determan Jr <deter088 at umn.edu> wrote:
>You can use grep with some basic regex, index your dataframe, and
>colSums
>
>colSums(df[,grep("*6574*|*7584*|*85*", colnames(df))])
>colSums(df[,grep("f6574*|f7584*|f85*", colnames(df))])
>
>
>Regards,
>Dr. Charles Determan
>
>On Mon, Oct 13, 2014 at 7:57 AM, Kuma Raj <pollaroid at gmail.com> wrote:
>
>> I want to sum columns based on their names. As an exampel how could I
>> sum columns which contain 6574, 7584 and 85 as column names?  In
>> addition, how could I sum those which contain 6574, 7584 and 85 in
>> ther names and have a prefix "f". My data contains several variables
>> with
>>
>> I want to sum columns based on their names. As an exampel how could I
>> sum columns which contain 6574, 7584 and 85 as column names?  In
>> addition, how could I sum those which contain 6574, 7584 and 85 in
>> ther names and have a prefix "f". My data contains several variables
>> with
>>
>> dput(df1)
>> structure(list(date = structure(c(1230768000, 1230854400, 1230940800,
>> 1231027200, 1231113600, 1231200000, 1231286400, 1231372800,
>1231459200,
>> 1231545600, 1231632000), class = c("POSIXct", "POSIXt"), tzone =
>"UTC"),
>>     f014card = c(0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), f1534card = c(0,
>>     1, 1, 0, 0, 1, 0, 0, 1, 0, 1), f3564card = c(1, 6, 1, 5,
>>     5, 4, 4, 7, 6, 4, 6), f6574card = c(3, 6, 4, 5, 5, 2, 10,
>>     3, 4, 2, 4), f7584card = c(13, 6, 1, 4, 10, 6, 8, 12, 10,
>>     4, 3), f85card = c(5, 3, 1, 0, 2, 10, 7, 9, 1, 7, 3), m014card =
>c(0,
>>     0, 0, 0, 0, 0, 0, 0, 0, 0, 0), m1534card = c(0, 0, 1, 0,
>>     0, 0, 0, 1, 1, 1, 0), m3564card = c(12, 7, 4, 7, 12, 13,
>>     12, 7, 12, 2, 11), m6574card = c(3, 4, 8, 8, 8, 10, 7, 6,
>>     7, 7, 5), m7584card = c(8, 10, 5, 4, 12, 7, 14, 11, 9, 1,
>>     11), m85card = c(1, 4, 3, 0, 3, 4, 5, 5, 4, 5, 0)), .Names =
>c("date",
>> "f014card", "f1534card", "f3564card", "f6574card", "f7584card",
>> "f85card", "m014card", "m1534card", "m3564card", "m6574card",
>> "m7584card", "m85card"), class = "data.frame", row.names = c("1",
>> "2", "3", "4", "5", "6", "7", "8", "9", "10", "11"))
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From istazahn at gmail.com  Mon Oct 13 15:42:50 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 13 Oct 2014 09:42:50 -0400
Subject: [R] seqinr ?: Splitting a factor name into several columns.
 Dealing with metabarcoding data.
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>
Message-ID: <CA+vqiLFwVHfMnc6xzOx9J8tvN3rU_gwHSEdt5oWQUPR01xAiyg@mail.gmail.com>

Hi Anna,


On Sun, Oct 12, 2014 at 3:24 AM, Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:
> Hi,
>
> I have a question how to split a factor name into different columns. I have metabarcoding data and need to merge the FASTA-file with the taxonomy- and counttable files (dataframes). To be able to do this merge, I need to isolate the common identifier, that unfortunately is baked in with a lot of other labels in the factor name eg:
> sequence identifier: M01271_77_000000000.A8J0P_1_1101_10150_1525.1.322519.sample_1.sample_2
>
> I want to split this name at every "." to get several columns:
> column1: M01271_77_000000000
> column2: A8J0P_1_1101_10150_1525
> column3: 1
> column4: 322519
> column5: sample_1
> column6: sample_2
>
> I must add that I have no influence on how these names are given. This is how thay are supplied from Illumina Miseq. I just need to be able to deal with it.
>
> Here is some extremely simplified dummy data to further show the issue at hand:
>
> df1 <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>                   Z.identifierA.B1298712 = factor(rep(LETTERS[1:2], each = 5)))
> df2 <- data.frame(cbind(B = 13:22, K = rnorm(10)),
>                   Q.identifierA.B4668726 = factor(rep(LETTERS[1:2], each = 5)))
>
> # I have metabarcoding data with one FASTA-file, one count table and one taxonomy file
> # Above dummy data is just showing the issue at hand. I want to be able to merge my three
> # original data frames (here, the dummy data is only two dataframes). The problem is that
> # the only identifier that is commmon for the dataframes is "hidden" in the
> # factor name eg: Z.identifierA.1298712 and Q.identifierA.4668726. I hence need to be able
> # to split this name up into different columns to get "identifierA" alone as one column name
> # Then I can merge the dataframes.
> # How can I do this in R. I know that it can be done in excel, but I would like to
> # produce a complete R-script to get a fast pipeline and avoid copy and paste errors.
> # This is what I want it to look:
>
> df1.goal <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>                   Z = factor(rep(LETTERS[1:2], each = 5)),
>                   identifierA = factor(rep(LETTERS[1:2], each = 5)),
>                   B1298712 = factor(rep(LETTERS[1:2], each = 5)))

Use strsplit to separate the components, something like

separateNames <- strsplit(names(df1)[3], split = "\\.")[[1]]
for(name in separateNames) {
    df1[[name]] <- df1[[3]]
}
df1[[3]] <- NULL

Best,
Ista

>
> # Many thank's and with kind regards
> Anna Zakrisson
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bartosz.baranowski at roche.com  Mon Oct 13 10:11:17 2014
From: bartosz.baranowski at roche.com (Baranowski, Bartosz)
Date: Mon, 13 Oct 2014 10:11:17 +0200
Subject: [R]  User authentication
Message-ID: <CAA0o7YKu7y=OziJTbtMC9KT-nQNN_b0XAOo53LQ-m8iPQwptsw@mail.gmail.com>

Hi all,

I am envisioning the user logging into a shiny app, or RStudio
server, and then, based on that authentication, obtaining the
necessary credentials to access other remote systems.
Is there maybe any working solution for this kind of problem?
All the help would be greatly appreciated.

Kind Regards,
Bartosz Baranowski


From David.Kaethner at dlr.de  Mon Oct 13 10:42:27 2014
From: David.Kaethner at dlr.de (David.Kaethner at dlr.de)
Date: Mon, 13 Oct 2014 08:42:27 +0000
Subject: [R] seqinr ?: Splitting a factor name into several columns.
 Dealing with metabarcoding data.
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>
Message-ID: <CDB1C7AAB482D246A4AEF6C17ACD9CF2346326A8@dlrexmbx02.intra.dlr.de>

I'm not sure I understood your problem, maybe like this:

# split identifiers into columns
df1 <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
                  Z.identifierA.B1298712 = factor(rep(LETTERS[1:2], each = 5)))

id <- names(df1)[3]
x <- do.call(rbind, str_split(id, "\\."))
y <- sapply(x, function(z) z <- df1[,id])

df1.goal <- data.frame(df1[,-3], y)

-dk

-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von Anna Zakrisson Braeunlich
Gesendet: Sonntag, 12. Oktober 2014 09:25
An: r-help at r-project.org
Betreff: [R] seqinr ?: Splitting a factor name into several columns. Dealing with metabarcoding data.

Hi,

I have a question how to split a factor name into different columns. I have metabarcoding data and need to merge the FASTA-file with the taxonomy- and counttable files (dataframes). To be able to do this merge, I need to isolate the common identifier, that unfortunately is baked in with a lot of other labels in the factor name eg:
sequence identifier: M01271_77_000000000.A8J0P_1_1101_10150_1525.1.322519.sample_1.sample_2

I want to split this name at every "." to get several columns:
column1: M01271_77_000000000
column2: A8J0P_1_1101_10150_1525
column3: 1
column4: 322519
column5: sample_1
column6: sample_2

I must add that I have no influence on how these names are given. This is how thay are supplied from Illumina Miseq. I just need to be able to deal with it.

Here is some extremely simplified dummy data to further show the issue at hand:

df1 <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
                  Z.identifierA.B1298712 = factor(rep(LETTERS[1:2], each = 5)))
df2 <- data.frame(cbind(B = 13:22, K = rnorm(10)),
                  Q.identifierA.B4668726 = factor(rep(LETTERS[1:2], each = 5)))

# I have metabarcoding data with one FASTA-file, one count table and one taxonomy file # Above dummy data is just showing the issue at hand. I want to be able to merge my three # original data frames (here, the dummy data is only two dataframes). The problem is that # the only identifier that is commmon for the dataframes is "hidden" in the # factor name eg: Z.identifierA.1298712 and Q.identifierA.4668726. I hence need to be able # to split this name up into different columns to get "identifierA" alone as one column name # Then I can merge the dataframes.
# How can I do this in R. I know that it can be done in excel, but I would like to # produce a complete R-script to get a fast pipeline and avoid copy and paste errors.
# This is what I want it to look:

df1.goal <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
                  Z = factor(rep(LETTERS[1:2], each = 5)),
                  identifierA = factor(rep(LETTERS[1:2], each = 5)),
                  B1298712 = factor(rep(LETTERS[1:2], each = 5)))

# Many thank's and with kind regards
Anna Zakrisson

><(((( >` . .   ` . .  ` . . ><(((( >` . .   ` . .  ` . .><(((( >` . .   
>` . .  ` . .><(((( >

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences Stockholm University Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><(((( >` . .   ` . .  ` . . ><(((( >` . .   ` . .  ` . .><(((( >` . .   
>` . .  ` . .><(((( >

	[[alternative HTML version deleted]]


From teotjunk at hotmail.com  Mon Oct 13 15:37:38 2014
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Mon, 13 Oct 2014 21:37:38 +0800
Subject: [R] Loading a rda file for predicton
Message-ID: <SNT148-W74D24077EBE384B60AF9DADFAC0@phx.gbl>

I tried this

--------------------------------------------------------------------------------------------
fit<-glm(Pred~Pressure+MissingStep, data = Test, family="binomial")

save(fit,file="pred.rda")

pred<-load("pred.rda")


predict(pred,Testsamp,type="response")

------------------------------------------------------------------------------------

But got this error message

 no applicable method for 'predict' applied to an object of class "character"

What did I do wrong?


Tjun Kiat

 		 	   		  
	[[alternative HTML version deleted]]


From peter.langfelder at gmail.com  Mon Oct 13 21:43:42 2014
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Mon, 13 Oct 2014 12:43:42 -0700
Subject: [R] Loading a rda file for predicton
In-Reply-To: <SNT148-W74D24077EBE384B60AF9DADFAC0@phx.gbl>
References: <SNT148-W74D24077EBE384B60AF9DADFAC0@phx.gbl>
Message-ID: <CA+hbrhWk+yjo--Vrz37iy43x_dPjiY4NxTQ137SRSdCEi_54hw@mail.gmail.com>

see help(load) and pay particular attention to what the function
returns: the names of the loaded objects, not the object(s)
themselves.

You have to use

predict(fit,Testsamp,type="response")

since the load() created a variable 'fit' (same name as the one saved).

HTH

Peter



On Mon, Oct 13, 2014 at 6:37 AM, TJUN KIAT TEO <teotjunk at hotmail.com> wrote:
> I tried this
>
> --------------------------------------------------------------------------------------------
> fit<-glm(Pred~Pressure+MissingStep, data = Test, family="binomial")
>
> save(fit,file="pred.rda")
>
> pred<-load("pred.rda")
>
>
> predict(pred,Testsamp,type="response")
>
> ------------------------------------------------------------------------------------
>
> But got this error message
>
>  no applicable method for 'predict' applied to an object of class "character"
>
> What did I do wrong?
>
>
> Tjun Kiat
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Mon Oct 13 22:46:12 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Mon, 13 Oct 2014 16:46:12 -0400
Subject: [R] Help with a function [along columns]
Message-ID: <CAE6QMsb58bXkybpm0t8PX1GRTKbxTVMx-Sq4KAtfvnSS2qfa4Q@mail.gmail.com>

Hi all,

I need help with a function.  I'm trying to write a function to apply
to varying number of columns in a lot of files - hence the function...
but I'm getting stuck.  Here it is:

gt<- function(x) {
    alleles <- sapply(x, function(.) strsplit(as.character(.), "/"))
    gt <- apply(x, function(.) ifelse(x[1] == vcf[3] & x[2] == vcf[3], 'RR',
    ifelse(x[1] == vcf[4] & x[2] == vcf[4], 'AA',
    ifelse(x[1] == vcf[3] & x[2] == vcf[4], 'RA',
    ifelse(x[1] == vcf[4] & x[2] == vcf[3], 'RA', '')))))
}

I have different sized family genetic files and at the end of the day
I want to see whether the alleles of each person in the family match
the ref and/or the alt and if so, give AA, RA or RR.

Like so:

REF ALT Sample_1 GT_1 Sample_2 GT_2
A G A/A RR A/G RA
T G G/G AA T/T RR
A T T/T AA A/A RR
G A G/A RA G/G RR
G A G/G RR G/A RA
T C C/C AA C/C AA
T C C/C AA C/C AA
C T C/T RA T/T AA
G A A/A AA A/A AA
T G T/G RA G/G AA


Is there an easy way to do this?

Thanks!


From kate.ignatius at gmail.com  Tue Oct 14 02:54:51 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Mon, 13 Oct 2014 20:54:51 -0400
Subject: [R] Help with a function [along columns]
In-Reply-To: <CAE6QMsb58bXkybpm0t8PX1GRTKbxTVMx-Sq4KAtfvnSS2qfa4Q@mail.gmail.com>
References: <CAE6QMsb58bXkybpm0t8PX1GRTKbxTVMx-Sq4KAtfvnSS2qfa4Q@mail.gmail.com>
Message-ID: <CAE6QMsawEoDiQOfSdifCX0j_NO3PMA++umzv0eq2kmqSGJNwMg@mail.gmail.com>

Just an update to this:

gtal <- function(d) {
    alleles <- sapply(d, function(.) strsplit(as.character(.), "/"))
    gt <- unlist(lapply(alleles, function(x)
           ifelse(identical(x[[1]], vcf[,3]) & identical(x[[2]], vcf[,3]), 'RR',
           ifelse(identical(x[[1]], vcf[,4]) & identical(x[[2]], vcf[,4]), 'AA',
           ifelse(identical(x[[1]], vcf[,3]) & identical(x[[2]], vcf[,4]), 'RA',
           ifelse(identical(x[[1]], vcf[,4]) & identical(x[[2]],
vcf[,3]), 'RA', ''))))))
}

I've got something working but I'm having trouble with the gt part...
I'm getting the error: object of type 'closure' is not subsettable.
The vcf is my original file that I want to match with so not sure
whether this a problem.

On Mon, Oct 13, 2014 at 4:46 PM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> Hi all,
>
> I need help with a function.  I'm trying to write a function to apply
> to varying number of columns in a lot of files - hence the function...
> but I'm getting stuck.  Here it is:
>
> gt<- function(x) {
>     alleles <- sapply(x, function(.) strsplit(as.character(.), "/"))
>     gt <- apply(x, function(.) ifelse(x[1] == vcf[3] & x[2] == vcf[3], 'RR',
>     ifelse(x[1] == vcf[4] & x[2] == vcf[4], 'AA',
>     ifelse(x[1] == vcf[3] & x[2] == vcf[4], 'RA',
>     ifelse(x[1] == vcf[4] & x[2] == vcf[3], 'RA', '')))))
> }
>
> I have different sized family genetic files and at the end of the day
> I want to see whether the alleles of each person in the family match
> the ref and/or the alt and if so, give AA, RA or RR.
>
> Like so:
>
> REF ALT Sample_1 GT_1 Sample_2 GT_2
> A G A/A RR A/G RA
> T G G/G AA T/T RR
> A T T/T AA A/A RR
> G A G/A RA G/G RR
> G A G/G RR G/A RA
> T C C/C AA C/C AA
> T C C/C AA C/C AA
> C T C/T RA T/T AA
> G A A/A AA A/A AA
> T G T/G RA G/G AA
>
>
> Is there an easy way to do this?
>
> Thanks!


From syen04 at gmail.com  Tue Oct 14 07:55:41 2014
From: syen04 at gmail.com (Steven Yen)
Date: Tue, 14 Oct 2014 01:55:41 -0400
Subject: [R] Reading text file with fortran format
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA276623A7F63C@WAXMXOLYMB025.WAX
	.wa.lcl>
References: <542b1ac8.1228ec0a.1a92.23c7@mx.google.com>
	<F7E6D18CC2877149AB5296CE54EA276623A7F63C@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <543cbadd.53caec0a.22bb.7d09@mx.google.com>

Hello
Any idea how to read a text file with fortran format, WITH MULTIPLE 
RECORDS? My fortran format is as follows, and I do know I need to 
change F7.4 to F7.0, and 2F2.0 to 2I2, etc.
I just have no idea how to handle the "slash" (/) which dictates a 
jump to the next record in fortran. Thank you all.
---

  10   FORMAT(F8.0,4F2.0,6F7.4,F8.4,3F4.1,2F3.0,36F2.0,11F8.5
      * /2F8.5,F10.4,F2.0,F8.1,F10.4,F11.4,F6.2,F2.0,3F10.4,2F12.7,2F2.0,
      * F4.0,2F2.0,F8.5,5F2.0)


From madhvi.gupta at orkash.com  Tue Oct 14 08:17:58 2014
From: madhvi.gupta at orkash.com (madhvi)
Date: Tue, 14 Oct 2014 11:47:58 +0530
Subject: [R] How to Install R 3.1.0 on ubuntu 12.0.4
Message-ID: <543CC016.9080908@orkash.com>

Hi,
Can anyone tell me the steps to install R 3.1.0 and rstudio on ubuntu 
12.0.4.

Thanks
Madhvi


From kridox at ymail.com  Tue Oct 14 08:28:08 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 14 Oct 2014 15:28:08 +0900
Subject: [R] How to Install R 3.1.0 on ubuntu 12.0.4
In-Reply-To: <543CC016.9080908@orkash.com>
References: <543CC016.9080908@orkash.com>
Message-ID: <CAAcyNCyq0RB-fEwfkBjNVE6dPEtnNisGSHJVoD8Tqa+wqs=__g@mail.gmail.com>

Hi,

http://cran.r-project.org/bin/linux/ubuntu/
http://www.rstudio.com/products/rstudio/download/

Enjoy,
Pascal

On Tue, Oct 14, 2014 at 3:17 PM, madhvi <madhvi.gupta at orkash.com> wrote:
> Hi,
> Can anyone tell me the steps to install R 3.1.0 and rstudio on ubuntu
> 12.0.4.
>
> Thanks
> Madhvi
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From kridox at ymail.com  Tue Oct 14 08:39:34 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 14 Oct 2014 15:39:34 +0900
Subject: [R] How to Install R 3.1.0 on ubuntu 12.0.4
In-Reply-To: <543CC33D.2000809@orkash.com>
References: <543CC016.9080908@orkash.com>
	<CAAcyNCyq0RB-fEwfkBjNVE6dPEtnNisGSHJVoD8Tqa+wqs=__g@mail.gmail.com>
	<543CC33D.2000809@orkash.com>
Message-ID: <CAAcyNCwtXCdFH2Hk0LJn67F33PyJSZ=_mksKXz-oEQkzGDqRAg@mail.gmail.com>

Please reply to the list, not only to me.

RStudio is for Ubuntu 10.04+ (please note the "+").

About R 3.1.0, you probably will have to compile from the source.

Regards,
Pascal


On Tue, Oct 14, 2014 at 3:31 PM, madhvi <madhvi.gupta at orkash.com> wrote:
> Hi,
> I have followed these links but it is giving R version 3.1.1 and R studio
> for ubuntu 10.04
>
> Madhvi
>
> On Tuesday 14 October 2014 11:58 AM, Pascal Oettli wrote:
>>
>> Hi,
>>
>> http://cran.r-project.org/bin/linux/ubuntu/
>> http://www.rstudio.com/products/rstudio/download/
>>
>> Enjoy,
>> Pascal
>>
>> On Tue, Oct 14, 2014 at 3:17 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>>>
>>> Hi,
>>> Can anyone tell me the steps to install R 3.1.0 and rstudio on ubuntu
>>> 12.0.4.
>>>
>>> Thanks
>>> Madhvi
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From david at boomer.org  Mon Oct 13 22:43:06 2014
From: david at boomer.org (David Bourne)
Date: Mon, 13 Oct 2014 14:43:06 -0600
Subject: [R] Legend (guides) for point and two line graph
Message-ID: <AEFD3722-0DBA-46AB-9290-26294877C2C9@boomer.org>

I?m trying to generate a plot with a series of data points and best fit lines from two stat models. I?m generating the best-fits with another program. I have the data in a csv file as:

Time,Observed,Calculated,Model
0.000,0.00000,13.0810,1C
0.2500,15.0000,12.5298,1C
0.5000,12.0000,12.0018,1C
1.000,9.00000,11.0117,1C
2.000,8.00000,9.26969,1C
4.000,6.50000,6.56882,1C
6.000,4.80000,4.65489,1C
9.000,3.20000,2.77680,1C
12.00,2.10000,1.65641,1C
18.00,1.80000,0.589422,1C
24.00,0.900000,0.209736,1C
0.000,0.00000,21.7130,2C
0.2500,15.0000,15.0512,2C
0.5000,12.0000,11.8203,2C
1.000,9.00000,9.29374,2C
2.000,8.00000,7.82242,2C
4.000,6.50000,6.20213,2C
6.000,4.80000,4.93346,2C
9.000,3.20000,3.50010,2C
12.00,2.10000,2.48310,2C
18.00,1.80000,1.24979,2C
24.00,0.900000,0.629039,2C

I read in the data with (R 3.1.1 GUI 1.65 Mavericks build (6784)):

>rtest <- read.csv("rtest.csv",header=TRUE)

Checked with

>rtest
    Time Observed Calculated Model
1   0.00      0.0  13.081000    1C
2   0.25     15.0  12.529800    1C
3   0.50     12.0  12.001800    1C
4   1.00      9.0  11.011700    1C
5   2.00      8.0   9.269690    1C
6   4.00      6.5   6.568820    1C
7   6.00      4.8   4.654890    1C
8   9.00      3.2   2.776800    1C
9  12.00      2.1   1.656410    1C
10 18.00      1.8   0.589422    1C
11 24.00      0.9   0.209736    1C
12  0.00      0.0  21.713000    2C
13  0.25     15.0  15.051200    2C
14  0.50     12.0  11.820300    2C
15  1.00      9.0   9.293740    2C
16  2.00      8.0   7.822420    2C
17  4.00      6.5   6.202130    2C
18  6.00      4.8   4.933460    2C
19  9.00      3.2   3.500100    2C
20 12.00      2.1   2.483100    2C
21 18.00      1.8   1.249790    2C
22 24.00      0.9   0.629039    2C

Generated the graph with:

ggplot(rtest, aes(x=Time, y=Calculated,color=Model, group=Model)) + geom_line(aes(size=2)) + geom_point(aes(y=Observed, size=Observed), size=6, colour="black") + scale_colour_manual(values=c("green","red")) + labs(size="Observed?)

Which resulted in the plot:

http://www.boomer.org/rtest/rtest.pdf

I?d like to:

1) get rid of the Observed / 2 legend(guide)
2) maybe keep the Observed and have a circle, i.e., loose the ?2?
3) understand how to create, format the legend

This seems like a common enough problem but the online documentation, R for Dummies nor the R Graphic Cookbook seems to have an answer (from my reading).

Thanks for any clues/suggestion.

David

From pseo at stanford.edu  Tue Oct 14 01:27:35 2014
From: pseo at stanford.edu (Patricia Seo)
Date: Mon, 13 Oct 2014 16:27:35 -0700 (PDT)
Subject: [R] Storing vectors as vectors in a list without losing each
 individual vector
In-Reply-To: <37611980.1457519.1413242002917.JavaMail.zimbra@stanford.edu>
Message-ID: <1758053343.1515751.1413242855336.JavaMail.zimbra@stanford.edu>

Hi everyone,

My help request is similar to what was asked by Ken Termiso on April 18th, 2005. Link here: https://stat.ethz.ch/pipermail/r-help/2005-April/069729.html

Matt Wiener answered with suggesting a vector list where you hand type each of the vectors. This is not what I want to do. What I want to do is automate the process. So, in other words creating a list through a loop. 

For example:

My data frame is called "df" and I have four variables/vectors that are v7, v8, v9, 10. Each variable/vector is an integer (no character strings). I want to create a list called "Indexes" so that I can use this list for "for-in" loops to SEPARATELY plot each and every variable/vector. 

If I followed Matt Wiener's suggestion, I would input this:


Indexes = list()
Indexes[[1]] = df$v7 
Indexes[[2]] = df$v8
Indexes[[3]] = df$v9
Indexes[[4]] = df$v10

But if I want to include more than four variable/vectors (let's say I want to include 25 of them!), I do not want to have to type all of it. If I do the following command:

Indexes <- c(df$v7, df$v8, df$v9, df$v10)

then I run into the same problem as Ken Termiso with having all the integers in one vector. I need to keep the variables/vectors separate. 

Is this just not possible in R? Any help would be great. Thank you!


From madhvi.gupta at orkash.com  Tue Oct 14 09:08:43 2014
From: madhvi.gupta at orkash.com (madhvi)
Date: Tue, 14 Oct 2014 12:38:43 +0530
Subject: [R] How to Install R 3.1.0 on ubuntu 12.0.4
In-Reply-To: <CAAcyNCwtXCdFH2Hk0LJn67F33PyJSZ=_mksKXz-oEQkzGDqRAg@mail.gmail.com>
References: <543CC016.9080908@orkash.com>
	<CAAcyNCyq0RB-fEwfkBjNVE6dPEtnNisGSHJVoD8Tqa+wqs=__g@mail.gmail.com>
	<543CC33D.2000809@orkash.com>
	<CAAcyNCwtXCdFH2Hk0LJn67F33PyJSZ=_mksKXz-oEQkzGDqRAg@mail.gmail.com>
Message-ID: <543CCBFB.8040105@orkash.com>

Hi,
How to install RStudio after downloading debian  package

Madhvi
On Tuesday 14 October 2014 12:09 PM, Pascal Oettli wrote:
> Please reply to the list, not only to me.
>
> RStudio is for Ubuntu 10.04+ (please note the "+").
>
> About R 3.1.0, you probably will have to compile from the source.
>
> Regards,
> Pascal
>
>
> On Tue, Oct 14, 2014 at 3:31 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>> Hi,
>> I have followed these links but it is giving R version 3.1.1 and R studio
>> for ubuntu 10.04
>>
>> Madhvi
>>
>> On Tuesday 14 October 2014 11:58 AM, Pascal Oettli wrote:
>>> Hi,
>>>
>>> http://cran.r-project.org/bin/linux/ubuntu/
>>> http://www.rstudio.com/products/rstudio/download/
>>>
>>> Enjoy,
>>> Pascal
>>>
>>> On Tue, Oct 14, 2014 at 3:17 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>>>> Hi,
>>>> Can anyone tell me the steps to install R 3.1.0 and rstudio on ubuntu
>>>> 12.0.4.
>>>>
>>>> Thanks
>>>> Madhvi
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
>


From kridox at ymail.com  Tue Oct 14 09:20:23 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 14 Oct 2014 16:20:23 +0900
Subject: [R] How to Install R 3.1.0 on ubuntu 12.0.4
In-Reply-To: <543CCBFB.8040105@orkash.com>
References: <543CC016.9080908@orkash.com>
	<CAAcyNCyq0RB-fEwfkBjNVE6dPEtnNisGSHJVoD8Tqa+wqs=__g@mail.gmail.com>
	<543CC33D.2000809@orkash.com>
	<CAAcyNCwtXCdFH2Hk0LJn67F33PyJSZ=_mksKXz-oEQkzGDqRAg@mail.gmail.com>
	<543CCBFB.8040105@orkash.com>
Message-ID: <CAAcyNCzCFUxYkWwCC77a3QyRewO52VH63MXW0zGjwJepfr72Bg@mail.gmail.com>

The support for RStudio is located here: https://support.rstudio.com

Regards,
Pascal

On Tue, Oct 14, 2014 at 4:08 PM, madhvi <madhvi.gupta at orkash.com> wrote:
> Hi,
> How to install RStudio after downloading debian  package
>
> Madhvi
>
> On Tuesday 14 October 2014 12:09 PM, Pascal Oettli wrote:
>>
>> Please reply to the list, not only to me.
>>
>> RStudio is for Ubuntu 10.04+ (please note the "+").
>>
>> About R 3.1.0, you probably will have to compile from the source.
>>
>> Regards,
>> Pascal
>>
>>
>> On Tue, Oct 14, 2014 at 3:31 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>>>
>>> Hi,
>>> I have followed these links but it is giving R version 3.1.1 and R studio
>>> for ubuntu 10.04
>>>
>>> Madhvi
>>>
>>> On Tuesday 14 October 2014 11:58 AM, Pascal Oettli wrote:
>>>>
>>>> Hi,
>>>>
>>>> http://cran.r-project.org/bin/linux/ubuntu/
>>>> http://www.rstudio.com/products/rstudio/download/
>>>>
>>>> Enjoy,
>>>> Pascal
>>>>
>>>> On Tue, Oct 14, 2014 at 3:17 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>>>>>
>>>>> Hi,
>>>>> Can anyone tell me the steps to install R 3.1.0 and rstudio on ubuntu
>>>>> 12.0.4.
>>>>>
>>>>> Thanks
>>>>> Madhvi
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>>>
>>
>>
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From madhvi.gupta at orkash.com  Tue Oct 14 09:22:19 2014
From: madhvi.gupta at orkash.com (madhvi)
Date: Tue, 14 Oct 2014 12:52:19 +0530
Subject: [R] How to Install R 3.1.0 on ubuntu 12.0.4
In-Reply-To: <CAAcyNCzCFUxYkWwCC77a3QyRewO52VH63MXW0zGjwJepfr72Bg@mail.gmail.com>
References: <543CC016.9080908@orkash.com>
	<CAAcyNCyq0RB-fEwfkBjNVE6dPEtnNisGSHJVoD8Tqa+wqs=__g@mail.gmail.com>
	<543CC33D.2000809@orkash.com>
	<CAAcyNCwtXCdFH2Hk0LJn67F33PyJSZ=_mksKXz-oEQkzGDqRAg@mail.gmail.com>
	<543CCBFB.8040105@orkash.com>
	<CAAcyNCzCFUxYkWwCC77a3QyRewO52VH63MXW0zGjwJepfr72Bg@mail.gmail.com>
Message-ID: <543CCF2B.8030303@orkash.com>

Hi,
Thanks for your help.I got it installed.


Madhvi
On Tuesday 14 October 2014 12:50 PM, Pascal Oettli wrote:
> The support for RStudio is located here: https://support.rstudio.com
>
> Regards,
> Pascal
>
> On Tue, Oct 14, 2014 at 4:08 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>> Hi,
>> How to install RStudio after downloading debian  package
>>
>> Madhvi
>>
>> On Tuesday 14 October 2014 12:09 PM, Pascal Oettli wrote:
>>> Please reply to the list, not only to me.
>>>
>>> RStudio is for Ubuntu 10.04+ (please note the "+").
>>>
>>> About R 3.1.0, you probably will have to compile from the source.
>>>
>>> Regards,
>>> Pascal
>>>
>>>
>>> On Tue, Oct 14, 2014 at 3:31 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>>>> Hi,
>>>> I have followed these links but it is giving R version 3.1.1 and R studio
>>>> for ubuntu 10.04
>>>>
>>>> Madhvi
>>>>
>>>> On Tuesday 14 October 2014 11:58 AM, Pascal Oettli wrote:
>>>>> Hi,
>>>>>
>>>>> http://cran.r-project.org/bin/linux/ubuntu/
>>>>> http://www.rstudio.com/products/rstudio/download/
>>>>>
>>>>> Enjoy,
>>>>> Pascal
>>>>>
>>>>> On Tue, Oct 14, 2014 at 3:17 PM, madhvi <madhvi.gupta at orkash.com> wrote:
>>>>>> Hi,
>>>>>> Can anyone tell me the steps to install R 3.1.0 and rstudio on ubuntu
>>>>>> 12.0.4.
>>>>>>
>>>>>> Thanks
>>>>>> Madhvi
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>>
>>>
>
>


From miaojpm at gmail.com  Tue Oct 14 09:36:32 2014
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 14 Oct 2014 15:36:32 +0800
Subject: [R] ggplot "scale_x_date" : to plot quarterly scale?
Message-ID: <CABcx46BQsp-JXZQBjqFmi+28cZk=U_K3bxvj_dJMcDtZUqJt7A@mail.gmail.com>

Hi,

  I am plotting time series by  ggplot2, but I believe that my question
applies to other plotting tool as well.

  I want to make my x-axis the quarterly scale, e.g:
2000Q1 2000Q2.....

   However, scale_x_date and date_format("%m/%d") support all time formats
BUT QUARTERs........

library(scales) # to access breaks/formatting functions
dt + scale_x_date()
dt + scale_x_date(labels = date_format("%m/%d"))

   Is there any solution?

Thanks!

	[[alternative HTML version deleted]]


From michel.arnaud at cirad.fr  Tue Oct 14 10:46:27 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Tue, 14 Oct 2014 10:46:27 +0200
Subject: [R] To build a new Df from 2 Df
In-Reply-To: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
References: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
Message-ID: <543CE2E3.1010506@cirad.fr>

Hello

I have 2 df Dem and Rap.
I would want to build all the df (dfnew) by associating these two df 
(Dem and Rap) in the following way :

For each value of Dem$Nom (dfnew$Demandeur), I associate 2 different 
values of Rap$Nom (dfnew$Rapporteur1 and dfnew$Rapporteur2) in such a way

  * for each dfnew$Demandeur, dfnew$Rapporteur1 does not have the same
    value for Departement as Dem$Departement
  * for each dfnew$Demandeur, dfnew$Rapporteur2 does not have the same
    value for Unite as Dem$Unite
  * the value of table(dfnew$Rapporteur1) and the value of
    table(dfnew$Rapporteur2) must be balanced and not too different
    (Accepted differences : 1)

table(dfnew$Rapporteur1)
Rapporteur01 Rapporteur02 Rapporteur03 Rapporteur04 Rapporteur05
            4                   4 4                      4               
   4

Thanks for your help
Michel

  Dem <- structure(list(Nom = c("John", "Jim", "Julie", "Charles", 
"Michel",
"Emma", "Sandra", "Elodie", "Thierry", "Albert", "Jean", "Francois",
"Pierre", "Cyril", "Damien", "Jean-Michel", "Vincent", "Daniel",
"Yvan", "Catherine"), Departement = c("D", "A", "A", "C", "D",
"B", "D", "B", "C", "D", "B", "B", "B", "A", "C", "D", "B", "A",
"D", "D"), Unite = c("Unite8", "Unite4", "Unite4", "Unite7",
"Unite9", "Unite1", "Unite6", "Unite5", "Unite7", "Unite3", "Unite2",
"Unite6", "Unite8", "Unite8", "Unite3", "Unite8", "Unite9", "Unite7",
"Unite9", "Unite5")), .Names = c("Nom", "Departement", "Unite"
), row.names = c(NA, -20L), class = "data.frame")

Rap <- structure(list(Nom = c("Rapporteur01", "Rapporteur02", 
"Rapporteur03",
"Rapporteur04", "Rapporteur05"), Departement = c("C", "D", "C",
"C", "D"), Unite = c("Unite10", "Unite6", "Unite5", "Unite5",
"Unite4")), .Names = c("Nom", "Departement", "Unite"), row.names = c(NA,
-5L), class = "data.frame")

dfnew <- structure(list(Demandeur = structure(c(13L, 12L, 14L, 3L, 15L,
8L, 17L, 7L, 18L, 1L, 10L, 9L, 16L, 4L, 5L, 11L, 19L, 6L, 20L,
2L), .Label = c("Albert", "Catherine", "Charles", "Cyril", "Damien",
"Daniel", "Elodie", "Emma", "Francois", "Jean", "Jean-Michel",
"Jim", "John", "Julie", "Michel", "Pierre", "Sandra", "Thierry",
"Vincent", "Yvan"), class = "factor"), Rapporteur1 = structure(c(3L,
1L, 3L, 5L, 1L, 5L, 1L, 2L, 5L, 4L, 2L, 4L, 2L, 3L, 5L, 4L, 4L,
2L, 3L, 1L), .Label = c("Rapporteur01", "Rapporteur02", "Rapporteur03",
"Rapporteur04", "Rapporteur05"), class = "factor"), Rapporteur2 = 
structure(c(1L,
3L, 4L, 4L, 2L, 4L, 5L, 1L, 2L, 3L, 3L, 3L, 5L, 5L, 1L, 1L, 2L,
5L, 4L, 2L), .Label = c("Rapporteur01", "Rapporteur02", "Rapporteur03",
"Rapporteur04", "Rapporteur05"), class = "factor")), .Names = 
c("Demandeur",
"Rapporteur1", "Rapporteur2"), row.names = c(NA, -20L), class = 
"data.frame")


-- 
Michel ARNAUD
Cirad Montpellier


	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Tue Oct 14 10:48:01 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 14 Oct 2014 19:48:01 +1100
Subject: [R] Help with a function [along columns]
In-Reply-To: <CAE6QMsawEoDiQOfSdifCX0j_NO3PMA++umzv0eq2kmqSGJNwMg@mail.gmail.com>
References: <CAE6QMsb58bXkybpm0t8PX1GRTKbxTVMx-Sq4KAtfvnSS2qfa4Q@mail.gmail.com>
	<CAE6QMsawEoDiQOfSdifCX0j_NO3PMA++umzv0eq2kmqSGJNwMg@mail.gmail.com>
Message-ID: <4575046.6Ce11yzkM5@localhost.localdomain>

On Mon, 13 Oct 2014 08:54:51 PM Kate Ignatius wrote:
> Just an update to this:
> 
> gtal <- function(d) {
>     alleles <- sapply(d, function(.) strsplit(as.character(.), "/"))
>     gt <- unlist(lapply(alleles, function(x)
>            ifelse(identical(x[[1]], vcf[,3]) & identical(x[[2]], vcf[,3]),
> 'RR', ifelse(identical(x[[1]], vcf[,4]) & identical(x[[2]], vcf[,4]), 'AA',
> ifelse(identical(x[[1]], vcf[,3]) & identical(x[[2]], vcf[,4]), 'RA',
> ifelse(identical(x[[1]], vcf[,4]) & identical(x[[2]],
> vcf[,3]), 'RA', ''))))))
> }
> 
> I've got something working but I'm having trouble with the gt part...
> I'm getting the error: object of type 'closure' is not subsettable.
> The vcf is my original file that I want to match with so not sure
> whether this a problem.
> 

Hi Kate,
Unless you have passed "vcf" to your function, it is unlikely to recognize 
it. As you are working with genome data, I suspect that there is a 
function named "vcf" somewhere in the parent environment and you 
can't subset a function.

Jim


From fsmairura at yahoo.com  Tue Oct 14 10:48:33 2014
From: fsmairura at yahoo.com (Franklin Mairura)
Date: Tue, 14 Oct 2014 01:48:33 -0700
Subject: [R] ggplot "scale_x_date" : to plot quarterly scale?
In-Reply-To: <CABcx46BQsp-JXZQBjqFmi+28cZk=U_K3bxvj_dJMcDtZUqJt7A@mail.gmail.com>
References: <CABcx46BQsp-JXZQBjqFmi+28cZk=U_K3bxvj_dJMcDtZUqJt7A@mail.gmail.com>
Message-ID: <1413276513.92849.YahooMailNeo@web162802.mail.bf1.yahoo.com>



Try this code, this may get a solution close to what you need. The advantage with this code is that you specify the text you want to appear on the xaxis. The dates have to be supplied as text formats, and located on the xaxis using the axis and at commands. the at command allows for customised location whether intervals are equal or not. The matplot command draws the lineplot, which is basically what a time series is. Using excel makes customised syntax building for R easier, by the CONCATENATE Excel worksheet functuion. 


Canopy<-(factor(c(1,2,3)))
a<-c(0.336,0.852,0.794)
b<-c(0.21,0.353333333333333,0.878333333333333)
c<-c(0.443333333333333,0.65,1.18833333333333)
d<-c(0.052,0.106,0.142)
e<-c(0.275,0.203333333333333,0.633333333333333)
f<-c(0.35,0.365,0.796666666666667)
g<-c(0.16,0.466666666666667,0.696666666666667)
h<-c(0.586666666666667,0.873333333333333,2.29)
i<-c(0.836666666666667,2.55625,2.675)
j<-c(0.536666666666667,1.68,2.52333333333333)
k<-c(0.163333333333333,0.136666666666667,0.156666666666667)
l<-c(0.186666666666667,0.228333333333333,0.446666666666667)
m<-c(0.175,0.265,0.755)
n<-c(0.536,1.834,2.378)
o<-c(0.248333333333333,1.05666666666667,1.60666666666667)
p<-c(1.07,0.9275,2.05)
q<-c(0.1225,0.5975,0.6075)
r<-c(0.155,0.325,1.635)
s<-c(0.418333333333333,1.82,3.68333333333333)
t<-c(1.25,1.2925,2.3925)
u<-c(1.416,2.304,2.258)
v<-c(0.446666666666667,1.235,2.85)

RUST<-data.frame(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v)

matplot(ylim=c(0,5),Canopy,RUST,type="o",pch=c(1:23),lty=c(1:23),col=c(1:23),xaxt="n",lwd=2,cex=1.5,ylab="Rust Score",xlab="Canopy level")
axis(1, at=1:3,lab=c("Top","Middle","Lower"),cex.axis=1,font=4)
#mtext("Canopy level",side=1,line=3,)
legend("topleft",col=c(1:23),cex=0.6,ncol=2,pch=c(1:23),lwd=2,lty=c(1:23),c("a","b","c","d","e","f","g",
"h","i","j","k","l","m","n","o","p","q","r","s","t","u","v","w"))

segments(1,1.71535,1,2.28465)
segments(2,2.868,2,3.532)
segments(3,4.169,3,5.031)
segments(0.99,1.71535,1.01,1.71535)
segments(0.99,2.28465,1.01,2.28465)
segments(1.99,2.868,2.01,2.868)
segments(1.99,3.532,2.01,3.532)
segments(2.99,5.031,3.01,5.031)
segments(2.99,4.169,3.01,4.169)



On Tuesday, October 14, 2014 10:37 AM, jpm miao <miaojpm at gmail.com> wrote:
 


Hi,

  I am plotting time series by  ggplot2, but I believe that my question
applies to other plotting tool as well.

  I want to make my x-axis the quarterly scale, e.g:
2000Q1 2000Q2.....

   However, scale_x_date and date_format("%m/%d") support all time formats
BUT QUARTERs........

library(scales) # to access breaks/formatting functions
dt + scale_x_date()
dt + scale_x_date(labels = date_format("%m/%d"))

   Is there any solution?

Thanks!

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From hb at biostat.ucsf.edu  Tue Oct 14 11:25:14 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 14 Oct 2014 02:25:14 -0700
Subject: [R] Storing vectors as vectors in a list without losing each
 individual vector
In-Reply-To: <1758053343.1515751.1413242855336.JavaMail.zimbra@stanford.edu>
References: <37611980.1457519.1413242002917.JavaMail.zimbra@stanford.edu>
	<1758053343.1515751.1413242855336.JavaMail.zimbra@stanford.edu>
Message-ID: <CAFDcVCQvmL2edpPX1DZZxZ65p9kEZBgypyStv+Sh+K-2wCEW6g@mail.gmail.com>

On Oct 13, 2014 11:58 PM, "Patricia Seo" <pseo at stanford.edu> wrote:
>
> Hi everyone,
>
> My help request is similar to what was asked by Ken Termiso on April
18th, 2005. Link here:
https://stat.ethz.ch/pipermail/r-help/2005-April/069729.html
>
> Matt Wiener answered with suggesting a vector list where you hand type
each of the vectors. This is not what I want to do. What I want to do is
automate the process. So, in other words creating a list through a loop.
>
> For example:
>
> My data frame is called "df" and I have four variables/vectors that are
v7, v8, v9, 10. Each variable/vector is an integer (no character strings).
I want to create a list called "Indexes" so that I can use this list for
"for-in" loops to SEPARATELY plot each and every variable/vector.
>
> If I followed Matt Wiener's suggestion, I would input this:
>
>
> Indexes = list()
> Indexes[[1]] = df$v7
> Indexes[[2]] = df$v8
> Indexes[[3]] = df$v9
> Indexes[[4]] = df$v10
>
> But if I want to include more than four variable/vectors (let's say I
want to include 25 of them!), I do not want to have to type all of it. If I
do the following command:
>
> Indexes <- c(df$v7, df$v8, df$v9, df$v10)
>
> then I run into the same problem as Ken Termiso with having all the
integers in one vector. I need to keep the variables/vectors separate.

Does

Indexes <- list(df$v7, df$v8, df$v9, df$v10)

do what you want?

Henrik

>
> Is this just not possible in R? Any help would be great. Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Tue Oct 14 11:33:14 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Tue, 14 Oct 2014 17:33:14 +0800 (CST)
Subject: [R]   how to ajust y-axis values in plot() ?
Message-ID: <2cd499e7.1ce20.1490e011d61.Coremail.rhelpmaillist@163.com>


Dear helpeRs,
? I want to plot( 11:20 ) in a plot.
?if i just type the code above, the y value? will be from 11 to 20, now i want the value from a given range like? 0 to 40, how can i do it? 
I read ?plot? for a while but? still can't solve it. 
Actually, the qustion is founded when i already plot a plot like plot(11:20) , but when i abline(h=40), i found it will go out of the plot even after i used abline(h=40,xpd=T).
SO, may you help me?





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From tom.n.walker at gmail.com  Tue Oct 14 11:34:21 2014
From: tom.n.walker at gmail.com (Tom Walker)
Date: Tue, 14 Oct 2014 10:34:21 +0100
Subject: [R] ggplot - start axis label with superscript
Message-ID: <81D2724A-D6E2-4A63-8DAF-3E84CA876E83@gmail.com>

Dear help,

I?m stuck trying to begin an axis label in ggplot with a superscript. While I?m fine using expression to insert them in between normal text in an axis label, this doesn?t appear to work at the start of an expression. For example:

mydata <- data.frame(x = 1:10, y = 10:1)

# this works:
ggplot(mydata) +
  aes(x = x, y = y) +
  geom_line() +
  ylab(expression(paste(Incorrect^{14}, "C", sep = "")))

# this doesn?t work (and is what I would like to be able to do):
ggplot(mydata) +
  aes(x = x, y = y) +
  geom_line() +
  ylab(expression(paste(^{14}, "C", sep = "")))

Any help on this issue would be much appreciated! 

Many thanks,

Tom

From Rainer at krugs.de  Tue Oct 14 11:51:17 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 14 Oct 2014 11:51:17 +0200
Subject: [R] evaluate NA to FALSE instead of NA?
Message-ID: <m2r3ybm12i.fsf@krugs.de>

Hi

I want to evaluate NA and NaN to FALSE (for indexing) so I would like to
have the result as indicated here:

,----
| > p <- c(1:10/100, NA, NaN)
| > p
|  [1] 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10   NA  NaN
| > p[p<=0.05]
| [1] 0.01 0.02 0.03 0.04 0.05   NA   NA
| > p[sapply(p<=0.05, isTRUE)]
| [1] 0.01 0.02 0.03 0.04 0.05  <<<=== I want this
`----

Is there a way that I can do this more easily then in my example above?
It works, but it strikes me that there is not a better way of doing
this - am I missing a command or option?

Thanks,

Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141014/832c205b/attachment.bin>

From fsmairura at yahoo.com  Tue Oct 14 11:51:45 2014
From: fsmairura at yahoo.com (Franklin Mairura)
Date: Tue, 14 Oct 2014 02:51:45 -0700
Subject: [R] ggplot "scale_x_date" : to plot quarterly scale?
In-Reply-To: <1413276513.92849.YahooMailNeo@web162802.mail.bf1.yahoo.com>
References: <CABcx46BQsp-JXZQBjqFmi+28cZk=U_K3bxvj_dJMcDtZUqJt7A@mail.gmail.com>
	<1413276513.92849.YahooMailNeo@web162802.mail.bf1.yahoo.com>
Message-ID: <1413280305.45074.YahooMailNeo@web162802.mail.bf1.yahoo.com>

Dear jpm, have attached a simpler example, hope this helps. Regards. 


plot(0:100,pch="",xaxt="n",)
axis(1, at=1,lab=c("abcd"),cex.axis=1,font=4)
 axis(1, at=20,lab=c("efgh"),cex.axis=1,font=4)
axis(1, at=60,lab=c("ijkl"),cex.axis=1,font=4)




On Tuesday, October 14, 2014 11:48 AM, Franklin Mairura <fsmairura at yahoo.com> wrote:
 




Try this code, this may get a solution close to what you need. The advantage with this code is that you specify the text you want to appear on the xaxis. The dates have to be supplied as text formats, and located on the xaxis using the axis and at commands. the at command allows for customised location whether intervals are equal or not. The matplot command draws the lineplot, which is basically what a time series is. Using excel makes customised syntax building for R easier, by the CONCATENATE Excel worksheet functuion. 


Canopy<-(factor(c(1,2,3)))
a<-c(0.336,0.852,0.794)
b<-c(0.21,0.353333333333333,0.878333333333333)
c<-c(0.443333333333333,0.65,1.18833333333333)
d<-c(0.052,0.106,0.142)
e<-c(0.275,0.203333333333333,0.633333333333333)
f<-c(0.35,0.365,0.796666666666667)
g<-c(0.16,0.466666666666667,0.696666666666667)
h<-c(0.586666666666667,0.873333333333333,2.29)
i<-c(0.836666666666667,2.55625,2.675)
j<-c(0.536666666666667,1.68,2.52333333333333)
k<-c(0.163333333333333,0.136666666666667,0.156666666666667)
l<-c(0.186666666666667,0.228333333333333,0.446666666666667)
m<-c(0.175,0.265,0.755)
n<-c(0.536,1.834,2.378)
o<-c(0.248333333333333,1.05666666666667,1.60666666666667)
p<-c(1.07,0.9275,2.05)
q<-c(0.1225,0.5975,0.6075)
r<-c(0.155,0.325,1.635)
s<-c(0.418333333333333,1.82,3.68333333333333)
t<-c(1.25,1.2925,2.3925)
u<-c(1.416,2.304,2.258)
v<-c(0.446666666666667,1.235,2.85)

RUST<-data.frame(a,b,c,d,e,f,g,h,i,j,k,l,m,n,o,p,q,r,s,t,u,v)

matplot(ylim=c(0,5),Canopy,RUST,type="o",pch=c(1:23),lty=c(1:23),col=c(1:23),xaxt="n",lwd=2,cex=1.5,ylab="Rust Score",xlab="Canopy level")
axis(1, at=1:3,lab=c("Top","Middle","Lower"),cex.axis=1,font=4)
#mtext("Canopy level",side=1,line=3,)
legend("topleft",col=c(1:23),cex=0.6,ncol=2,pch=c(1:23),lwd=2,lty=c(1:23),c("a","b","c","d","e","f","g",
"h","i","j","k","l","m","n","o","p","q","r","s","t","u","v","w"))

segments(1,1.71535,1,2.28465)
segments(2,2.868,2,3.532)
segments(3,4.169,3,5.031)
segments(0.99,1.71535,1.01,1.71535)
segments(0.99,2.28465,1.01,2.28465)
segments(1.99,2.868,2.01,2.868)
segments(1.99,3.532,2.01,3.532)
segments(2.99,5.031,3.01,5.031)
segments(2.99,4.169,3.01,4.169)



On Tuesday, October 14, 2014 10:37 AM, jpm miao <miaojpm at gmail.com> wrote:
 


Hi,

  I am plotting time series by  ggplot2, but I believe that my question
applies to other plotting tool as well.

  I want to make my x-axis the quarterly scale, e.g:
2000Q1 2000Q2.....

   However, scale_x_date and date_format("%m/%d") support all time formats
BUT QUARTERs........

library(scales) # to access breaks/formatting functions
dt + scale_x_date()
dt + scale_x_date(labels = date_format("%m/%d"))

   Is there any solution?

Thanks!

    [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From kridox at ymail.com  Tue Oct 14 12:00:32 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 14 Oct 2014 19:00:32 +0900
Subject: [R] evaluate NA to FALSE instead of NA?
In-Reply-To: <m2r3ybm12i.fsf@krugs.de>
References: <m2r3ybm12i.fsf@krugs.de>
Message-ID: <CAAcyNCwrO_vDmk1c7GaF+FVcLwnQ+_RwDKCHcyD2LnwiYVOQdw@mail.gmail.com>

Hi Rainer,

As "complete.cases()" does?

p <- c(1:10/100, NA, NaN)
complete.cases(p)
 [1]  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE  TRUE FALSE FALSE

Regards,
Pascal


On Tue, Oct 14, 2014 at 6:51 PM, Rainer M Krug <Rainer at krugs.de> wrote:
> Hi
>
> I want to evaluate NA and NaN to FALSE (for indexing) so I would like to
> have the result as indicated here:
>
> ,----
> | > p <- c(1:10/100, NA, NaN)
> | > p
> |  [1] 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10   NA  NaN
> | > p[p<=0.05]
> | [1] 0.01 0.02 0.03 0.04 0.05   NA   NA
> | > p[sapply(p<=0.05, isTRUE)]
> | [1] 0.01 0.02 0.03 0.04 0.05  <<<=== I want this
> `----
>
> Is there a way that I can do this more easily then in my example above?
> It works, but it strikes me that there is not a better way of doing
> this - am I missing a command or option?
>
> Thanks,
>
> Rainer
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From sven.templer at gmail.com  Tue Oct 14 12:04:08 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Tue, 14 Oct 2014 12:04:08 +0200
Subject: [R] evaluate NA to FALSE instead of NA?
In-Reply-To: <m2r3ybm12i.fsf@krugs.de>
References: <m2r3ybm12i.fsf@krugs.de>
Message-ID: <CAHuTOvpa9=qD=cK65eY+AJ+oFzZyKiKWr2M6=AJ6x8GMX+3HYw@mail.gmail.com>

use:

which(p<=.05)

this will not yield logical, but integer indices without NA

On 14 October 2014 11:51, Rainer M Krug <Rainer at krugs.de> wrote:
> Hi
>
> I want to evaluate NA and NaN to FALSE (for indexing) so I would like to
> have the result as indicated here:
>
> ,----
> | > p <- c(1:10/100, NA, NaN)
> | > p
> |  [1] 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10   NA  NaN
> | > p[p<=0.05]
> | [1] 0.01 0.02 0.03 0.04 0.05   NA   NA
> | > p[sapply(p<=0.05, isTRUE)]
> | [1] 0.01 0.02 0.03 0.04 0.05  <<<=== I want this
> `----
>
> Is there a way that I can do this more easily then in my example above?
> It works, but it strikes me that there is not a better way of doing
> this - am I missing a command or option?
>
> Thanks,
>
> Rainer
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jwiley.psych at gmail.com  Tue Oct 14 12:06:03 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Tue, 14 Oct 2014 21:06:03 +1100
Subject: [R] evaluate NA to FALSE instead of NA?
In-Reply-To: <m2r3ybm12i.fsf@krugs.de>
References: <m2r3ybm12i.fsf@krugs.de>
Message-ID: <CANz9Z_+3XyXiPZvHFzeUUzyY8jiXSsKJjJq=R3rcE-VEcHaVBQ@mail.gmail.com>

Hi,

Perhaps still not as short as you want, but I normally use which():

p <- c(1:10/100, NA, NaN)
p[which(p <= .05)]
[1] 0.01 0.02 0.03 0.04 0.05

Cheers,

Josh



On Tue, Oct 14, 2014 at 8:51 PM, Rainer M Krug <Rainer at krugs.de> wrote:

> Hi
>
> I want to evaluate NA and NaN to FALSE (for indexing) so I would like to
> have the result as indicated here:
>
> ,----
> | > p <- c(1:10/100, NA, NaN)
> | > p
> |  [1] 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10   NA  NaN
> | > p[p<=0.05]
> | [1] 0.01 0.02 0.03 0.04 0.05   NA   NA
> | > p[sapply(p<=0.05, isTRUE)]
> | [1] 0.01 0.02 0.03 0.04 0.05  <<<=== I want this
> `----
>
> Is there a way that I can do this more easily then in my example above?
> It works, but it strikes me that there is not a better way of doing
> this - am I missing a command or option?
>
> Thanks,
>
> Rainer
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

	[[alternative HTML version deleted]]


From Rainer at krugs.de  Tue Oct 14 12:13:27 2014
From: Rainer at krugs.de (Rainer M Krug)
Date: Tue, 14 Oct 2014 12:13:27 +0200
Subject: [R] SOLVED: evaluate NA to FALSE instead of NA?
In-Reply-To: <m2r3ybm12i.fsf@krugs.de> (Rainer M. Krug's message of "Tue, 14
	Oct 2014 11:51:17 +0200")
References: <m2r3ybm12i.fsf@krugs.de>
Message-ID: <m2k343m01k.fsf@krugs.de>


Thanks Joshua and Sven - I completely forgot about which() .

Pascal - I never new about complete.cases - interesting function.

Thanks,

Rainer
 

Rainer M Krug <Rainer at krugs.de> writes:

> Hi
>
> I want to evaluate NA and NaN to FALSE (for indexing) so I would like to
> have the result as indicated here:
>
> ,----
> | > p <- c(1:10/100, NA, NaN)
> | > p
> |  [1] 0.01 0.02 0.03 0.04 0.05 0.06 0.07 0.08 0.09 0.10   NA  NaN
> | > p[p<=0.05]
> | [1] 0.01 0.02 0.03 0.04 0.05   NA   NA
> | > p[sapply(p<=0.05, isTRUE)]
> | [1] 0.01 0.02 0.03 0.04 0.05  <<<=== I want this
> `----
>
> Is there a way that I can do this more easily then in my example above?
> It works, but it strikes me that there is not a better way of doing
> this - am I missing a command or option?
>
> Thanks,
>
> Rainer

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141014/7b017434/attachment.bin>

From S.Ellison at LGCGroup.com  Tue Oct 14 13:34:00 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 14 Oct 2014 12:34:00 +0100
Subject: [R] ggplot - start axis label with superscript
In-Reply-To: <81D2724A-D6E2-4A63-8DAF-3E84CA876E83@gmail.com>
References: <81D2724A-D6E2-4A63-8DAF-3E84CA876E83@gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412AE93F3@GOLD.corp.lgc-group.com>

 
> I'm stuck trying to begin an axis label in ggplot with a superscript. 
For a crude work-round, you could try

ggplot(mydata) +
  aes(x = x, y = y) +
  geom_line() +
  ylab(expression(paste(' '^{14}, "C", sep = "")))


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Tue Oct 14 13:41:09 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 14 Oct 2014 12:41:09 +0100
Subject: [R] SOLVED: evaluate NA to FALSE instead of NA?
In-Reply-To: <m2k343m01k.fsf@krugs.de>
References: <m2r3ybm12i.fsf@krugs.de> <m2k343m01k.fsf@krugs.de>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412AE93FE@GOLD.corp.lgc-group.com>

> Thanks Joshua and Sven - I completely forgot about which() .
Also 
na.omit(p[p<=0.05])

#and
p[p<=0.05 & !is.na(p)]

S.



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ruipbarradas at sapo.pt  Tue Oct 14 13:45:17 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 14 Oct 2014 12:45:17 +0100
Subject: [R] how to ajust y-axis values in plot() ?
In-Reply-To: <2cd499e7.1ce20.1490e011d61.Coremail.rhelpmaillist@163.com>
References: <2cd499e7.1ce20.1490e011d61.Coremail.rhelpmaillist@163.com>
Message-ID: <543D0CCD.2040706@sapo.pt>

Hello,

Use the argument ylim. See ?par instead of plot.

plot(11:20, ylim = c(0, 40))
abline(h=40)

Hope this helps,

Rui Barradas


Em 14-10-2014 10:33, PO SU escreveu:
>
> Dear helpeRs,
>    I want to plot( 11:20 ) in a plot.
>   if i just type the code above, the y value  will be from 11 to 20, now i want the value from a given range like  0 to 40, how can i do it?
> I read ?plot  for a while but  still can't solve it.
> Actually, the qustion is founded when i already plot a plot like plot(11:20) , but when i abline(h=40), i found it will go out of the plot even after i used abline(h=40,xpd=T).
> SO, may you help me?
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From S.Ellison at LGCGroup.com  Tue Oct 14 13:48:59 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 14 Oct 2014 12:48:59 +0100
Subject: [R] how to ajust y-axis values in plot() ?
In-Reply-To: <2cd499e7.1ce20.1490e011d61.Coremail.rhelpmaillist@163.com>
References: <2cd499e7.1ce20.1490e011d61.Coremail.rhelpmaillist@163.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412AE9416@GOLD.corp.lgc-group.com>



> ? I want to plot( 11:20 ) in a plot.
> ?if i just type the code above, the y value? will be from 11 to 20, now i want the
> value from a given range like? 0 to 40, how can i do it?
See the ylim= argument to plot.default; eg
plot(x, y, ylim=c(0,40))

Also look at ?par and note that plot() and other things often take many of par's arguments.


> Actually, the qustion is founded when i already plot a plot like plot(11:20) , but
> when i abline(h=40), i found it will go out of the plot even after i used
> abline(h=40,xpd=T).
Um, yes. A horizontal line at y=40 would not even be inside the plot window if the plot region is scaled to c(11,20). Where did you expect/want the line to appear? 

S


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From ggrothendieck at gmail.com  Tue Oct 14 14:14:03 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Tue, 14 Oct 2014 08:14:03 -0400
Subject: [R] ggplot "scale_x_date" : to plot quarterly scale?
In-Reply-To: <CABcx46BQsp-JXZQBjqFmi+28cZk=U_K3bxvj_dJMcDtZUqJt7A@mail.gmail.com>
References: <CABcx46BQsp-JXZQBjqFmi+28cZk=U_K3bxvj_dJMcDtZUqJt7A@mail.gmail.com>
Message-ID: <CAP01uRmZ4MYStA1BJZsa43O0_KiUgHNW-_TRgDeYdG1gZO1=FQ@mail.gmail.com>

On Tue, Oct 14, 2014 at 3:36 AM, jpm miao <miaojpm at gmail.com> wrote:
> Hi,
>
>   I am plotting time series by  ggplot2, but I believe that my question
> applies to other plotting tool as well.
>
>   I want to make my x-axis the quarterly scale, e.g:
> 2000Q1 2000Q2.....
>
>    However, scale_x_date and date_format("%m/%d") support all time formats
> BUT QUARTERs........
>
> library(scales) # to access breaks/formatting functions
> dt + scale_x_date()
> dt + scale_x_date(labels = date_format("%m/%d"))
>

1. zoo has a "yearqtr" class and its ggplot2 interface includes
scale_x_yearqtr() so:

library(zoo)
library(ggplot2)
library(scales)

# test data
DF <- data.frame(date = seq(as.Date("2014-01-01"), length = 4, by = "3
months"),
                             y = c(1, 4, 2, 3))

# convert date to yearmon class
DF2 <- transform(DF, date = as.yearqtr(date))

ggplot(DF2, aes(date, y)) + geom_line() + scale_x_yearqtr(format = "%YQ%q")

2. zoo also has a zoo method for ggplot2's autoplot generic so we
could just convert DF to zoo and write:

z <- zoo(DF$y, as.yearqtr(DF$date))
autoplot(z) + scale_x_yearqtr(format = "%YQ%q")

In both cases if the format argument is omitted one gets a default of
format = "%Y-%q".




-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From David.Kaethner at dlr.de  Tue Oct 14 13:18:22 2014
From: David.Kaethner at dlr.de (David.Kaethner at dlr.de)
Date: Tue, 14 Oct 2014 11:18:22 +0000
Subject: [R] To build a new Df from 2 Df
In-Reply-To: <543CE2E3.1010506@cirad.fr>
References: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
	<543CE2E3.1010506@cirad.fr>
Message-ID: <CDB1C7AAB482D246A4AEF6C17ACD9CF234632B7A@dlrexmbx02.intra.dlr.de>

Hello,

here's a draft of a solution. I hope it's not overly complicated.

# find all possible combinations
combi <- expand.grid(Dem$Nom, Rap$Nom); names(combi) <- c("Dem", "Rap")

# we need the corresponding departments and units 
combi$DemDep <- apply(combi, 1, function(x) Dem$Departement[x[1] == Dem$Nom])
combi$DemUni <- apply(combi, 1, function(x) Dem$Unite[x[1] == Dem$Nom])
combi$RapDep <- apply(combi, 1, function(x) Rap$Departement[x[2] == Rap$Nom])
combi$RapUni <- apply(combi, 1, function(x) Rap$Unite[x[2] == Rap$Nom])

# we exclude the combinations that we don't want
dep <- combi[combi$DemDep != combi$RapDep, c("Dem", "Rap")]
dep$id <- as.numeric(dep$Rap)
uni <- combi[combi$DemUni != combi$RapUni, c("Dem", "Rap")]
uni$id <- as.numeric(uni$Rap)

# preliminary result
resDep <- reshape(dep,
        timevar = "id",
        idvar = "Dem",
        direction = "wide"
)

resUni <- reshape(uni,
                  timevar = "id",
                  idvar = "Dem",
                  direction = "wide"
)

In resDep and resUni you find the results for Rapporteur1 and Rapporteur2. NAs indicate where conditions did not match. For Rap1/Rap2 you can now choose any column from resDep and resUni that is not NA for that specific Demandeur. I wasn't exactly sure about your third condition, so I'll leave that to you. But with the complete possible matches, you have a more general solution.

Btw, you can construct data.frames just like this:

Dem <- data.frame(
  Nom = c("John", "Jim", "Julie", "Charles", "Michel", "Emma", "Sandra", "Elodie", "Thierry", "Albert", "Jean", "Francois", "Pierre", "Cyril", "Damien", "Jean-Michel", "Vincent", "Daniel", "Yvan", "Catherine"),
  Departement = c("D", "A", "A", "C", "D", "B", "D", "B", "C", "D", "B", "B", "B", "A", "C", "D", "B", "A", "D", "D"),
  Unite = c("Unite8", "Unite4", "Unite4", "Unite7", "Unite9", "Unite1", "Unite6", "Unite5", "Unite7", "Unite3", "Unite2", "Unite6", "Unite8", "Unite8", "Unite3", "Unite8", "Unite9", "Unite7", "Unite9", "Unite5")
)

-dk

-----Urspr?ngliche Nachricht-----
Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von Arnaud Michel
Gesendet: Dienstag, 14. Oktober 2014 10:46
An: r-help at r-project.org
Betreff: [R] To build a new Df from 2 Df

Hello

I have 2 df Dem and Rap.
I would want to build all the df (dfnew) by associating these two df (Dem and Rap) in the following way :

For each value of Dem$Nom (dfnew$Demandeur), I associate 2 different values of Rap$Nom (dfnew$Rapporteur1 and dfnew$Rapporteur2) in such a way

  * for each dfnew$Demandeur, dfnew$Rapporteur1 does not have the same
    value for Departement as Dem$Departement
  * for each dfnew$Demandeur, dfnew$Rapporteur2 does not have the same
    value for Unite as Dem$Unite
  * the value of table(dfnew$Rapporteur1) and the value of
    table(dfnew$Rapporteur2) must be balanced and not too different
    (Accepted differences : 1)

table(dfnew$Rapporteur1)
Rapporteur01 Rapporteur02 Rapporteur03 Rapporteur04 Rapporteur05
            4                   4 4                      4               
   4

Thanks for your help
Michel

  Dem <- structure(list(Nom = c("John", "Jim", "Julie", "Charles", "Michel", "Emma", "Sandra", "Elodie", "Thierry", "Albert", "Jean", "Francois", "Pierre", "Cyril", "Damien", "Jean-Michel", "Vincent", "Daniel", "Yvan", "Catherine"), Departement = c("D", "A", "A", "C", "D", "B", "D", "B", "C", "D", "B", "B", "B", "A", "C", "D", "B", "A", "D", "D"), Unite = c("Unite8", "Unite4", "Unite4", "Unite7", "Unite9", "Unite1", "Unite6", "Unite5", "Unite7", "Unite3", "Unite2", "Unite6", "Unite8", "Unite8", "Unite3", "Unite8", "Unite9", "Unite7", "Unite9", "Unite5")), .Names = c("Nom", "Departement", "Unite"
), row.names = c(NA, -20L), class = "data.frame")

Rap <- structure(list(Nom = c("Rapporteur01", "Rapporteur02", "Rapporteur03", "Rapporteur04", "Rapporteur05"), Departement = c("C", "D", "C", "C", "D"), Unite = c("Unite10", "Unite6", "Unite5", "Unite5", "Unite4")), .Names = c("Nom", "Departement", "Unite"), row.names = c(NA, -5L), class = "data.frame")

dfnew <- structure(list(Demandeur = structure(c(13L, 12L, 14L, 3L, 15L, 8L, 17L, 7L, 18L, 1L, 10L, 9L, 16L, 4L, 5L, 11L, 19L, 6L, 20L, 2L), .Label = c("Albert", "Catherine", "Charles", "Cyril", "Damien", "Daniel", "Elodie", "Emma", "Francois", "Jean", "Jean-Michel", "Jim", "John", "Julie", "Michel", "Pierre", "Sandra", "Thierry", "Vincent", "Yvan"), class = "factor"), Rapporteur1 = structure(c(3L, 1L, 3L, 5L, 1L, 5L, 1L, 2L, 5L, 4L, 2L, 4L, 2L, 3L, 5L, 4L, 4L, 2L, 3L, 1L), .Label = c("Rapporteur01", "Rapporteur02", "Rapporteur03", "Rapporteur04", "Rapporteur05"), class = "factor"), Rapporteur2 = structure(c(1L, 3L, 4L, 4L, 2L, 4L, 5L, 1L, 2L, 3L, 3L, 3L, 5L, 5L, 1L, 1L, 2L, 5L, 4L, 2L), .Label = c("Rapporteur01", "Rapporteur02", "Rapporteur03", "Rapporteur04", "Rapporteur05"), class = "factor")), .Names = c("Demandeur", "Rapporteur1", "Rapporteur2"), row.names = c(NA, -20L), class =
"data.frame")


--
Michel ARNAUD
Cirad Montpellier


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Tue Oct 14 15:15:28 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 14 Oct 2014 13:15:28 +0000
Subject: [R] Storing vectors as vectors in a list without losing each
 individual vector
In-Reply-To: <1758053343.1515751.1413242855336.JavaMail.zimbra@stanford.edu>
References: <37611980.1457519.1413242002917.JavaMail.zimbra@stanford.edu>
	<1758053343.1515751.1413242855336.JavaMail.zimbra@stanford.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FA8F99@mb02.ads.tamu.edu>

If you just want to plot the various combinations of a set of variables/columns, you don't need a list, just another data frame/matrix with the combinations of the column numbers you want to plot:

> df <- matrix(rnorm(100), 10, 10)
> df <- data.frame(df)
> comb <- expand.grid(7:10, 7:10)
> comb <- comb[comb[,1] < comb[,2],]
> rownames(comb) <- NULL
> comb
  Var1 Var2
1    7    8
2    7    9
3    8    9
4    7   10
5    8   10
6    9   10
> windows(record=TRUE)
> apply(comb, 1, function(x) plot(df[,x[1]], df[,x[2]], 
+ main=paste("Plot of", x[1], "with", x[2])))
NULL

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Patricia Seo
Sent: Monday, October 13, 2014 6:28 PM
To: r-help at r-project.org
Subject: [R] Storing vectors as vectors in a list without losing each individual vector

Hi everyone,

My help request is similar to what was asked by Ken Termiso on April 18th, 2005. Link here: https://stat.ethz.ch/pipermail/r-help/2005-April/069729.html

Matt Wiener answered with suggesting a vector list where you hand type each of the vectors. This is not what I want to do. What I want to do is automate the process. So, in other words creating a list through a loop. 

For example:

My data frame is called "df" and I have four variables/vectors that are v7, v8, v9, 10. Each variable/vector is an integer (no character strings). I want to create a list called "Indexes" so that I can use this list for "for-in" loops to SEPARATELY plot each and every variable/vector. 

If I followed Matt Wiener's suggestion, I would input this:


Indexes = list()
Indexes[[1]] = df$v7 
Indexes[[2]] = df$v8
Indexes[[3]] = df$v9
Indexes[[4]] = df$v10

But if I want to include more than four variable/vectors (let's say I want to include 25 of them!), I do not want to have to type all of it. If I do the following command:

Indexes <- c(df$v7, df$v8, df$v9, df$v10)

then I run into the same problem as Ken Termiso with having all the integers in one vector. I need to keep the variables/vectors separate. 

Is this just not possible in R? Any help would be great. Thank you!

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From kate.ignatius at gmail.com  Tue Oct 14 16:23:55 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 14 Oct 2014 10:23:55 -0400
Subject: [R] grep won't work finding one column
Message-ID: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>

I'm having an issue with grep:

I have numerous columns that end with .at... when I use grep like so:

df[,grep(".at",colnames(df))]

it works fine.  When I have one column that ends with .at, it does not
work.  Why is that?  As this is loop with varying number of columns
ending in .at I would like some code that would work with 1 to n
number of columns.

Is there something more optimal than grep?

Thanks!


From john.archie.mckown at gmail.com  Tue Oct 14 16:38:01 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 14 Oct 2014 09:38:01 -0500
Subject: [R] grep won't work finding one column
In-Reply-To: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
Message-ID: <CAAJSdjg6Q0iFUahO83YmdBN9A5SQHz6ZY6hsXSNAgimapc0Rig@mail.gmail.com>

On Tue, Oct 14, 2014 at 9:23 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> I'm having an issue with grep:
>
> I have numerous columns that end with .at... when I use grep like so:
>
> df[,grep(".at",colnames(df))]
>
> it works fine.  When I have one column that ends with .at, it does not
> work.  Why is that?  As this is loop with varying number of columns
> ending in .at I would like some code that would work with 1 to n
> number of columns.
>
> Is there something more optimal than grep?
>
> Thanks!

I can't answer your direct question. But do you realize that your code
does not match your words? The grep show does not _only_ match columns
who name end with the characters '.at'. It matches all column names
which contain any character followed by the characters "at". To do the
match with only columns whose names end with the characters ".at", you
need: grep("\.at$",colnames(df)).

You might want to post an example which fails. Just to be complete, be
sure to use the dput() function so that it is easy for members of the
group to cut'n'paste to get your data into our own R workspace.

-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From kate.ignatius at gmail.com  Tue Oct 14 16:55:29 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 14 Oct 2014 10:55:29 -0400
Subject: [R] grep won't work finding one column
In-Reply-To: <CAAJSdjg6Q0iFUahO83YmdBN9A5SQHz6ZY6hsXSNAgimapc0Rig@mail.gmail.com>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
	<CAAJSdjg6Q0iFUahO83YmdBN9A5SQHz6ZY6hsXSNAgimapc0Rig@mail.gmail.com>
Message-ID: <CAE6QMsaJRkuN4EPmFg3Y-2Xf-Uv73Cy4VsEQPDDtRHATpi8mWw@mail.gmail.com>

For example,

DF will usually have numerous columns with sample1.at sample1.dp
sample1.fg sample2.at sample2.dp sample2.fg and so on....

I'm running this code in R as part of a shell script which runs over
several different file sizes so sometimes it will come across a file
with one sample in it: i.e. sample1: when the R code runs through this
file... trying to grep out  the "sample1.at" column does not work and
it will halt and stop.

Here is some sample data... say I want to get out the AT_ only column....


Sample_1 AT_1
A/A RR
G/G AA
T/T AA
G/A RA
G/G RR
C/C AA
C/C AA
C/T RA
A/A AA
T/G RA

it will have a problem grepping out this single column.

On Tue, Oct 14, 2014 at 10:38 AM, John McKown
<john.archie.mckown at gmail.com> wrote:
> On Tue, Oct 14, 2014 at 9:23 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> I'm having an issue with grep:
>>
>> I have numerous columns that end with .at... when I use grep like so:
>>
>> df[,grep(".at",colnames(df))]
>>
>> it works fine.  When I have one column that ends with .at, it does not
>> work.  Why is that?  As this is loop with varying number of columns
>> ending in .at I would like some code that would work with 1 to n
>> number of columns.
>>
>> Is there something more optimal than grep?
>>
>> Thanks!
>
> I can't answer your direct question. But do you realize that your code
> does not match your words? The grep show does not _only_ match columns
> who name end with the characters '.at'. It matches all column names
> which contain any character followed by the characters "at". To do the
> match with only columns whose names end with the characters ".at", you
> need: grep("\.at$",colnames(df)).
>
> You might want to post an example which fails. Just to be complete, be
> sure to use the dput() function so that it is easy for members of the
> group to cut'n'paste to get your data into our own R workspace.
>
> --
> There is nothing more pleasant than traveling and meeting new people!
> Genghis Khan
>
> Maranatha! <><
> John McKown


From jdnewmil at dcn.davis.CA.us  Tue Oct 14 16:57:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 14 Oct 2014 07:57:16 -0700
Subject: [R] grep won't work finding one column
In-Reply-To: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
Message-ID: <773EA324-8623-44DF-9DE0-D099D533C602@dcn.davis.CA.us>

Your question is missing a reproducible example, and you don't say how it does not work, so we cannot tell what is going on.

Two things do come to mind, though.

A) Data frame subsets with only one column by default return a vector, which is a different type of object than a single-column data frame. You would need to read ?"[.data.frame" about the "drop" argument if you wanted to consistently get a data frame from this expression.

B) The period is a wildcard in regular expressions. If you expect to limit your search to literal ".at" at the end of the name then you should use the search pattern  "\\.at$" instead (the first slash allows the second one to be stored by R in the string, and the second one is the only one seen by grep, which it reads as making the period not act like a wildcard). You really should read about regular expressions before using them. There are many tutorials on the web about this topic.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 14, 2014 7:23:55 AM PDT, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>I'm having an issue with grep:
>
>I have numerous columns that end with .at... when I use grep like so:
>
>df[,grep(".at",colnames(df))]
>
>it works fine.  When I have one column that ends with .at, it does not
>work.  Why is that?  As this is loop with varying number of columns
>ending in .at I would like some code that would work with 1 to n
>number of columns.
>
>Is there something more optimal than grep?
>
>Thanks!
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rl at openmailbox.org  Tue Oct 14 17:00:55 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Tue, 14 Oct 2014 15:00:55 +0000
Subject: [R] package installation failure virtualisation environment
Message-ID: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>

Subscribers,

A version of R is installed in a virtual machine, which has complete 
internet access via the host.

The following error occurs when a package is selected:

install.packages([packagename], dependencies=TRUE)
--- Please select a CRAN mirror for use in this session ---
Killed

The error also occurs with:

install.packages()

The process is killed as shown previously (but not the R session), after 
selection of a package in the Tcl/tk dialogue window.

The error occurs both as root and normal user.

Any suggestions please to solve?

R.version
                _
platform       i686-pc-linux-gnu
arch           i686
os             linux-gnu
system         i686, linux-gnu
status
major          3
minor          1.1
year           2014
month          07
day            10
svn rev        66115
language       R
version.string R version 3.1.1 (2014-07-10)
nickname       Sock it to Me


From ivan.calandra at univ-reims.fr  Tue Oct 14 17:01:37 2014
From: ivan.calandra at univ-reims.fr (Ivan Calandra)
Date: Tue, 14 Oct 2014 17:01:37 +0200
Subject: [R] grep won't work finding one column
In-Reply-To: <CAAJSdjg6Q0iFUahO83YmdBN9A5SQHz6ZY6hsXSNAgimapc0Rig@mail.gmail.com>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
	<CAAJSdjg6Q0iFUahO83YmdBN9A5SQHz6ZY6hsXSNAgimapc0Rig@mail.gmail.com>
Message-ID: <543D3AD1.3040603@univ-reims.fr>

Shouldn't it be
grep("\\.at$",colnames(df))
with double back slash?

Ivan

--
Ivan Calandra
University of Reims Champagne-Ardenne
GEGENA? - EA 3795
CREA - 2 esplanade Roland Garros
51100 Reims, France
+33(0)3 26 77 36 89
ivan.calandra at univ-reims.fr
https://www.researchgate.net/profile/Ivan_Calandra

Le 14/10/14 16:38, John McKown a ?crit :
> On Tue, Oct 14, 2014 at 9:23 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>> I'm having an issue with grep:
>>
>> I have numerous columns that end with .at... when I use grep like so:
>>
>> df[,grep(".at",colnames(df))]
>>
>> it works fine.  When I have one column that ends with .at, it does not
>> work.  Why is that?  As this is loop with varying number of columns
>> ending in .at I would like some code that would work with 1 to n
>> number of columns.
>>
>> Is there something more optimal than grep?
>>
>> Thanks!
> I can't answer your direct question. But do you realize that your code
> does not match your words? The grep show does not _only_ match columns
> who name end with the characters '.at'. It matches all column names
> which contain any character followed by the characters "at". To do the
> match with only columns whose names end with the characters ".at", you
> need: grep("\.at$",colnames(df)).
>
> You might want to post an example which fails. Just to be complete, be
> sure to use the dput() function so that it is easy for members of the
> group to cut'n'paste to get your data into our own R workspace.
>


From john.archie.mckown at gmail.com  Tue Oct 14 17:06:42 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 14 Oct 2014 10:06:42 -0500
Subject: [R] grep won't work finding one column
In-Reply-To: <CAE6QMsaJRkuN4EPmFg3Y-2Xf-Uv73Cy4VsEQPDDtRHATpi8mWw@mail.gmail.com>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
	<CAAJSdjg6Q0iFUahO83YmdBN9A5SQHz6ZY6hsXSNAgimapc0Rig@mail.gmail.com>
	<CAE6QMsaJRkuN4EPmFg3Y-2Xf-Uv73Cy4VsEQPDDtRHATpi8mWw@mail.gmail.com>
Message-ID: <CAAJSdjgZi0fQP9x1a8VVr1Jva+NPXWSeGOo+uWL6N0JTOXtZHg@mail.gmail.com>

AT and at are not the same. If you want an case insensitive compare
for the characters "at" you need the "ignore.case=TRUE" added. E.g.:

df[,grep(".at",colnames(df),ignore.case=TRUE)

That should match the column name you gave. Which does not match your
initial description which said "ending with .at". That has an embedded
AT. So I am still a bit confused about your needs.

On Tue, Oct 14, 2014 at 9:55 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
> For example,
>
> DF will usually have numerous columns with sample1.at sample1.dp
> sample1.fg sample2.at sample2.dp sample2.fg and so on....
>
> I'm running this code in R as part of a shell script which runs over
> several different file sizes so sometimes it will come across a file
> with one sample in it: i.e. sample1: when the R code runs through this
> file... trying to grep out  the "sample1.at" column does not work and
> it will halt and stop.
>
> Here is some sample data... say I want to get out the AT_ only column....
>
>
> Sample_1 AT_1
> A/A RR
> G/G AA
> T/T AA
> G/A RA
> G/G RR
> C/C AA
> C/C AA
> C/T RA
> A/A AA
> T/G RA
>
> it will have a problem grepping out this single column.
>
> On Tue, Oct 14, 2014 at 10:38 AM, John McKown
> <john.archie.mckown at gmail.com> wrote:
>> On Tue, Oct 14, 2014 at 9:23 AM, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>> I'm having an issue with grep:
>>>
>>> I have numerous columns that end with .at... when I use grep like so:
>>>
>>> df[,grep(".at",colnames(df))]
>>>
>>> it works fine.  When I have one column that ends with .at, it does not
>>> work.  Why is that?  As this is loop with varying number of columns
>>> ending in .at I would like some code that would work with 1 to n
>>> number of columns.
>>>
>>> Is there something more optimal than grep?
>>>
>>> Thanks!
>>
>> I can't answer your direct question. But do you realize that your code
>> does not match your words? The grep show does not _only_ match columns
>> who name end with the characters '.at'. It matches all column names
>> which contain any character followed by the characters "at". To do the
>> match with only columns whose names end with the characters ".at", you
>> need: grep("\.at$",colnames(df)).
>>
>> You might want to post an example which fails. Just to be complete, be
>> sure to use the dput() function so that it is easy for members of the
>> group to cut'n'paste to get your data into our own R workspace.
>>
>> --
>> There is nothing more pleasant than traveling and meeting new people!
>> Genghis Khan
>>
>> Maranatha! <><
>> John McKown



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From john.archie.mckown at gmail.com  Tue Oct 14 17:08:47 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Tue, 14 Oct 2014 10:08:47 -0500
Subject: [R] grep won't work finding one column
In-Reply-To: <543D3AD1.3040603@univ-reims.fr>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
	<CAAJSdjg6Q0iFUahO83YmdBN9A5SQHz6ZY6hsXSNAgimapc0Rig@mail.gmail.com>
	<543D3AD1.3040603@univ-reims.fr>
Message-ID: <CAAJSdjj9ZOt0eMb0LRxfh57yEVVwdq1=PwNfvadjq5RLVraHCA@mail.gmail.com>

You're right. I don't use regexps in R very much. In most other
languages, a single \ is needed. The R parser is different and I
forgot. Thanks for the heads up.

On Tue, Oct 14, 2014 at 10:01 AM, Ivan Calandra
<ivan.calandra at univ-reims.fr> wrote:
> Shouldn't it be
> grep("\\.at$",colnames(df))
> with double back slash?
>
> Ivan
>
> --
> Ivan Calandra
> University of Reims Champagne-Ardenne
> GEGENA? - EA 3795
> CREA - 2 esplanade Roland Garros
> 51100 Reims, France
> +33(0)3 26 77 36 89
> ivan.calandra at univ-reims.fr
> https://www.researchgate.net/profile/Ivan_Calandra
>
> Le 14/10/14 16:38, John McKown a ?crit :
>>
>> On Tue, Oct 14, 2014 at 9:23 AM, Kate Ignatius <kate.ignatius at gmail.com>
>> wrote:
>>>
>>> I'm having an issue with grep:
>>>
>>> I have numerous columns that end with .at... when I use grep like so:
>>>
>>> df[,grep(".at",colnames(df))]
>>>
>>> it works fine.  When I have one column that ends with .at, it does not
>>> work.  Why is that?  As this is loop with varying number of columns
>>> ending in .at I would like some code that would work with 1 to n
>>> number of columns.
>>>
>>> Is there something more optimal than grep?
>>>
>>> Thanks!
>>
>> I can't answer your direct question. But do you realize that your code
>> does not match your words? The grep show does not _only_ match columns
>> who name end with the characters '.at'. It matches all column names
>> which contain any character followed by the characters "at". To do the
>> match with only columns whose names end with the characters ".at", you
>> need: grep("\.at$",colnames(df)).
>>
>> You might want to post an example which fails. Just to be complete, be
>> sure to use the dput() function so that it is easy for members of the
>> group to cut'n'paste to get your data into our own R workspace.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
There is nothing more pleasant than traveling and meeting new people!
Genghis Khan

Maranatha! <><
John McKown


From kate.ignatius at gmail.com  Tue Oct 14 17:09:28 2014
From: kate.ignatius at gmail.com (Kate Ignatius)
Date: Tue, 14 Oct 2014 11:09:28 -0400
Subject: [R] grep won't work finding one column
In-Reply-To: <773EA324-8623-44DF-9DE0-D099D533C602@dcn.davis.CA.us>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>
	<773EA324-8623-44DF-9DE0-D099D533C602@dcn.davis.CA.us>
Message-ID: <CAE6QMsatHtDx+D4EnXenPiiuwjaGo0dubd7R--xZK_Q0pMSCUw@mail.gmail.com>

In the sense - it does not work.  it works when there are 50 samples
in the file, but it does not work when there is one.

The usual headings are:  sample1.at sample1.dp
sample1.fg sample2.at sample2.dp sample2.fg.... and so on to a max of
sample50.at sample50.dp sample50.fg

using this greps out all the .at columns perfectly:

df[,grep(".at",colnames(df))]

When I come across a file when there is one sample:

sample1.at sample1.dp sample1.fg

Using this:

df[,grep(".at",colnames(df))]

returns nothing.

Oh - AT/at was just an example... thats not my problem...



On Tue, Oct 14, 2014 at 10:57 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Your question is missing a reproducible example, and you don't say how it does not work, so we cannot tell what is going on.
>
> Two things do come to mind, though.
>
> A) Data frame subsets with only one column by default return a vector, which is a different type of object than a single-column data frame. You would need to read ?"[.data.frame" about the "drop" argument if you wanted to consistently get a data frame from this expression.
>
> B) The period is a wildcard in regular expressions. If you expect to limit your search to literal ".at" at the end of the name then you should use the search pattern  "\\.at$" instead (the first slash allows the second one to be stored by R in the string, and the second one is the only one seen by grep, which it reads as making the period not act like a wildcard). You really should read about regular expressions before using them. There are many tutorials on the web about this topic.
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 14, 2014 7:23:55 AM PDT, Kate Ignatius <kate.ignatius at gmail.com> wrote:
>>I'm having an issue with grep:
>>
>>I have numerous columns that end with .at... when I use grep like so:
>>
>>df[,grep(".at",colnames(df))]
>>
>>it works fine.  When I have one column that ends with .at, it does not
>>work.  Why is that?  As this is loop with varying number of columns
>>ending in .at I would like some code that would work with 1 to n
>>number of columns.
>>
>>Is there something more optimal than grep?
>>
>>Thanks!
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>


From sven.templer at gmail.com  Tue Oct 14 17:40:57 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Tue, 14 Oct 2014 17:40:57 +0200
Subject: [R] package installation failure virtualisation environment
In-Reply-To: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
References: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
Message-ID: <CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>

Prevent graphic menues with:
options(menu.graphics = FALSE)
or and define repositories:
options(repos = c(CRAN = "http://cran.r-project.org"))

On 14 October 2014 17:00,  <rl at openmailbox.org> wrote:
> Subscribers,
>
> A version of R is installed in a virtual machine, which has complete
> internet access via the host.
>
> The following error occurs when a package is selected:
>
> install.packages([packagename], dependencies=TRUE)
> --- Please select a CRAN mirror for use in this session ---
> Killed
>
> The error also occurs with:
>
> install.packages()
>
> The process is killed as shown previously (but not the R session), after
> selection of a package in the Tcl/tk dialogue window.
>
> The error occurs both as root and normal user.
>
> Any suggestions please to solve?
>
> R.version
>                _
> platform       i686-pc-linux-gnu
> arch           i686
> os             linux-gnu
> system         i686, linux-gnu
> status
> major          3
> minor          1.1
> year           2014
> month          07
> day            10
> svn rev        66115
> language       R
> version.string R version 3.1.1 (2014-07-10)
> nickname       Sock it to Me
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From evan.kransdorf at gmail.com  Tue Oct 14 20:12:48 2014
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Tue, 14 Oct 2014 11:12:48 -0700
Subject: [R] Help with functions - printing a variables name
Message-ID: <CAKZWb7fYu=YPxXVmdojDs-Q9O4mEM7z8FunA5KcYhNn8K3t8jA@mail.gmail.com>

Hello Everyone,

I was wondering if someone could help me implement a function in R.

I want to pass a vector x to my function, peform some math, then output the
data.  However, I want the output for x to be the *name of the vector
I am *using
as input.

For example, data<-c(1,5,10)

> func1<-function(x) {
    y<-x^2
    z<-x^3
    out<-cbind(x,y,z)
    return(out)
} #function

Desired output:
data, 1, 1
data, 25, 125
data, 100, 1000

Thanks very much for your help, Evan

	[[alternative HTML version deleted]]


From carlos.nasher at googlemail.com  Tue Oct 14 20:42:30 2014
From: carlos.nasher at googlemail.com (Carlos Nasher)
Date: Tue, 14 Oct 2014 20:42:30 +0200
Subject: [R] apply function to multiple list arguments
Message-ID: <CAP=BVWPGd-wGZVHsnMU3RR55hhMCP3KfB2SisAf72ACdNtbU6Q@mail.gmail.com>

Hi R helpers,

I'm struggling how to apply a function to multiple lists. My function uses
a dataframe, a list of parameters and a fixed value as arguments. Now I
want to apply that function to several dataframes contained in list, with
several lists of parameters (also contained in a list) and the fixed value.
Here's an example:


#####

fix <- 2 # fixed value

x <- c(1,2,3)
y <- c(4,5,6)

df_1 <- data.frame(x,y) # first dataframe
df_2 <- 2*df_1 # second dataframe

list_df <- list(df_1,df_2) # list containing dataframes

par_1 <- list(a=5,b=10) # first list of parameters
par_2 <- list(a=6,b=11) # second list of parameters

list_par <- list(par_1,par_2) # list of lists of parameters

f <- function(data,params,z){
  res <- (data$x*params$a+data$y*params$b)*z
  return(res)
}

res_1 <- f(data = df_1, params = par_1, z = fix) # result of applying
function to first dataframe and first list of parameters
res_2 <- f(data = df_2, params = par_2, z = fix) # result of applying
function to second dataframe and second list of parameters

#####

I got the list of dataframes and parameters from a former use of lapply. I
was hoping to get the desired results (res_1, res_2) again in a list. I
tried mapply, but I don't get it running. Can anybody help?

Thanks and best regards,
Carlos



-- 
-----------------------------------------------------------------
Carlos Nasher
Buchenstr. 12
22299 Hamburg

tel:            +49 (0)40 67952962
mobil:        +49 (0)175 9386725
mail:          carlos.nasher at gmail.com

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Tue Oct 14 20:42:27 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 14 Oct 2014 19:42:27 +0100
Subject: [R] Help with functions - printing a variables name
In-Reply-To: <CAKZWb7fYu=YPxXVmdojDs-Q9O4mEM7z8FunA5KcYhNn8K3t8jA@mail.gmail.com>
References: <CAKZWb7fYu=YPxXVmdojDs-Q9O4mEM7z8FunA5KcYhNn8K3t8jA@mail.gmail.com>
Message-ID: <543D6E93.2080909@sapo.pt>

Hello,

Maybe something like

data<-c(1,5,10)
func1<-function(x) {
     nm <- deparse(substitute(x))
     y<-x^2
     z<-x^3
     out<-data.frame(nm,y,z)
     return(out)
} #function

func1(data[1])

Hope this helps,

Rui Barradas

Em 14-10-2014 19:12, Evan Kransdorf escreveu:
> Hello Everyone,
>
> I was wondering if someone could help me implement a function in R.
>
> I want to pass a vector x to my function, peform some math, then output the
> data.  However, I want the output for x to be the *name of the vector
> I am *using
> as input.
>
> For example, data<-c(1,5,10)
>
>> func1<-function(x) {
>      y<-x^2
>      z<-x^3
>      out<-cbind(x,y,z)
>      return(out)
> } #function
>
> Desired output:
> data, 1, 1
> data, 25, 125
> data, 100, 1000
>
> Thanks very much for your help, Evan
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Tue Oct 14 20:51:19 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 14 Oct 2014 19:51:19 +0100
Subject: [R] apply function to multiple list arguments
In-Reply-To: <CAP=BVWPGd-wGZVHsnMU3RR55hhMCP3KfB2SisAf72ACdNtbU6Q@mail.gmail.com>
References: <CAP=BVWPGd-wGZVHsnMU3RR55hhMCP3KfB2SisAf72ACdNtbU6Q@mail.gmail.com>
Message-ID: <543D70A7.7080509@sapo.pt>

Hello,

Have you tried

mapply(f, list_df, list_par, MoreArgs = list(z = fix), SIMPLIFY = FALSE)

?


Hope this helps,

Rui Barradas

Em 14-10-2014 19:42, Carlos Nasher escreveu:
> Hi R helpers,
>
> I'm struggling how to apply a function to multiple lists. My function uses
> a dataframe, a list of parameters and a fixed value as arguments. Now I
> want to apply that function to several dataframes contained in list, with
> several lists of parameters (also contained in a list) and the fixed value.
> Here's an example:
>
>
> #####
>
> fix <- 2 # fixed value
>
> x <- c(1,2,3)
> y <- c(4,5,6)
>
> df_1 <- data.frame(x,y) # first dataframe
> df_2 <- 2*df_1 # second dataframe
>
> list_df <- list(df_1,df_2) # list containing dataframes
>
> par_1 <- list(a=5,b=10) # first list of parameters
> par_2 <- list(a=6,b=11) # second list of parameters
>
> list_par <- list(par_1,par_2) # list of lists of parameters
>
> f <- function(data,params,z){
>    res <- (data$x*params$a+data$y*params$b)*z
>    return(res)
> }
>
> res_1 <- f(data = df_1, params = par_1, z = fix) # result of applying
> function to first dataframe and first list of parameters
> res_2 <- f(data = df_2, params = par_2, z = fix) # result of applying
> function to second dataframe and second list of parameters
>
> #####
>
> I got the list of dataframes and parameters from a former use of lapply. I
> was hoping to get the desired results (res_1, res_2) again in a list. I
> tried mapply, but I don't get it running. Can anybody help?
>
> Thanks and best regards,
> Carlos
>
>
>


From r.turner at auckland.ac.nz  Tue Oct 14 22:37:05 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 15 Oct 2014 09:37:05 +1300
Subject: [R] grep won't work finding one column
In-Reply-To: <CAE6QMsatHtDx+D4EnXenPiiuwjaGo0dubd7R--xZK_Q0pMSCUw@mail.gmail.com>
References: <CAE6QMsY1Y0d5fO7g5KBnYH4VaAuhN=GXDpeMiAC=PRXyMveknw@mail.gmail.com>	<773EA324-8623-44DF-9DE0-D099D533C602@dcn.davis.CA.us>
	<CAE6QMsatHtDx+D4EnXenPiiuwjaGo0dubd7R--xZK_Q0pMSCUw@mail.gmail.com>
Message-ID: <543D8971.1020100@auckland.ac.nz>

On 15/10/14 04:09, Kate Ignatius wrote:
> In the sense - it does not work.  it works when there are 50 samples
> in the file, but it does not work when there is one.
>
> The usual headings are:  sample1.at sample1.dp
> sample1.fg sample2.at sample2.dp sample2.fg.... and so on to a max of
> sample50.at sample50.dp sample50.fg
>
> using this greps out all the .at columns perfectly:
>
> df[,grep(".at",colnames(df))]
>
> When I come across a file when there is one sample:
>
> sample1.at sample1.dp sample1.fg
>
> Using this:
>
> df[,grep(".at",colnames(df))]
>
> returns nothing.
>
> Oh - AT/at was just an example... thats not my problem...

You are being (deliberately?) obtuse.

It's *all* your problem.  You have to be precise when working with 
computers and when providing examples.  Don't build examples with 
confusing red herrings.

Your assertion that "df[,grep(".at",colnames(df))] returns nothing" is 
simple ***INCORRECT***.  It works just fine.  See the (tidy, completely 
reproducible) example in the attached file "kate.txt".

Note that, with a single ".at" column in your data frame, what is 
returned is ***NOT*** a data frame but rather a vector.  If you want a 
(one-column) data frame you need to use "drop=FALSE" in your 
subscripting call.

You need to study up on R and learn how it works (read the Introduction 
to R) and stop going off half-cocked.

cheers,

Rolf Turner

P.S.  It is a ***bad*** idea to use "df" as the name of a data frame. 
The string "df" is the name of a *function* in base R (it is the 
probability density function for the F distribution).  Although R is 
clever enough to distinguish functions from data objects in *most* 
circumstances, at the very least confusion could arise.

R. T.

-- 
Rolf Turner
Technical Editor ANZJS
-------------- next part --------------
#
# Check it out.
#

# Data frame with one ".at" column.
d1 <- as.data.frame(matrix(1,ncol=3,nrow=10))
n1 <- c("sample1.at","sample1.dp","sample1.g")
names(d1) <- n1

# Data frame with many ".at" columns.
d2 <- as.data.frame(matrix(1,ncol=50,nrow=10))
set.seed(42)
n2 <- paste("sample",1:50,sample(c(".at",".dp",".fg"),50,TRUE),sep="")
names(d2) <- n2

# Extract the ".at" columns.
print(d1[,grep(".at",colnames(d1))])
print(d2[,grep(".at",colnames(d2))])

From rshepard at appl-ecosys.com  Wed Oct 15 00:00:59 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 14 Oct 2014 15:00:59 -0700 (PDT)
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
Message-ID: <alpine.LNX.2.11.1410141459580.18019@localhost>

   A rather strange situation here and I've not found the source of the
problem.

   The point is to print a ternary plot matrix of compositional data with
ellipses enclosing 95% of the variance in each plot. The ellipses display on
the monitor, dev = x11cairo, but not when sent directly to a file, dev =
pdf.

   Here's winters.acomp:

structure(c(0.0666666666666667, 0.0612244897959184, 0.0434782608695652, 
0.043956043956044, 0.05, 0.0161290322580645, 0.6, 0.571428571428571, 
0.623188405797101, 0.593406593406593, 0.433333333333333, 0.629032258064516, 
0.0666666666666667, 0.0612244897959184, 0.101449275362319, 0.0659340659340659, 
0.0666666666666667, 0.032258064516129, 0.244444444444444, 0.26530612244898, 
0.217391304347826, 0.263736263736264, 0.366666666666667, 0.290322580645161, 
0.0222222222222222, 0.0408163265306122, 0.0144927536231884, 0.032967032967033, 
0.0833333333333333, 0.032258064516129), .Dim = c(6L, 5L), .Dimnames = list(
     NULL, c("filter", "gather", "graze", "predate", "shred")), class = "acomp")

   And this is the command sequence:

> library(compositions)
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> r <- sqrt(qchisq(p=0.95, df=4))
> mn <- mean(winters.acomp)
> vr <- var(winters.acomp)
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
 	col='red', lwd=2)
# monitor plot window is manually closed.
> pdf("winters-pdf.pdf")
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
 	col='red', lwd=2)
> dev.off()

   What am I not seeing here that causes the different outputs?

Rich


From r.turner at auckland.ac.nz  Wed Oct 15 01:25:03 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 15 Oct 2014 12:25:03 +1300
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
In-Reply-To: <alpine.LNX.2.11.1410141459580.18019@localhost>
References: <alpine.LNX.2.11.1410141459580.18019@localhost>
Message-ID: <543DB0CF.3020007@auckland.ac.nz>



In all probability this is FAQ 7.22.  I.e. use:

>   print(ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL,
>         aspanel=FALSE,col='red', lwd=2))

cheers,

Rolf Turner

P. S.  See also fortune(123).

R. T.

On 15/10/14 11:00, Rich Shepard wrote:
>    A rather strange situation here and I've not found the source of the
> problem.
>
>    The point is to print a ternary plot matrix of compositional data with
> ellipses enclosing 95% of the variance in each plot. The ellipses
> display on
> the monitor, dev = x11cairo, but not when sent directly to a file, dev =
> pdf.
>
>    Here's winters.acomp:
>
> structure(c(0.0666666666666667, 0.0612244897959184, 0.0434782608695652,
> 0.043956043956044, 0.05, 0.0161290322580645, 0.6, 0.571428571428571,
> 0.623188405797101, 0.593406593406593, 0.433333333333333,
> 0.629032258064516, 0.0666666666666667, 0.0612244897959184,
> 0.101449275362319, 0.0659340659340659, 0.0666666666666667,
> 0.032258064516129, 0.244444444444444, 0.26530612244898,
> 0.217391304347826, 0.263736263736264, 0.366666666666667,
> 0.290322580645161, 0.0222222222222222, 0.0408163265306122,
> 0.0144927536231884, 0.032967032967033, 0.0833333333333333,
> 0.032258064516129), .Dim = c(6L, 5L), .Dimnames = list(
>      NULL, c("filter", "gather", "graze", "predate", "shred")), class =
> "acomp")
>
>    And this is the command sequence:
>
>> library(compositions)
>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> r <- sqrt(qchisq(p=0.95, df=4))
>> mn <- mean(winters.acomp)
>> vr <- var(winters.acomp)
>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
>      col='red', lwd=2)
> # monitor plot window is manually closed.
>> pdf("winters-pdf.pdf")
>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
>      col='red', lwd=2)
>> dev.off()
>
>    What am I not seeing here that causes the different outputs?

-- 
Rolf Turner
Technical Editor ANZJS


From rshepard at appl-ecosys.com  Wed Oct 15 01:40:07 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 14 Oct 2014 16:40:07 -0700 (PDT)
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
In-Reply-To: <543DB0CF.3020007@auckland.ac.nz>
References: <alpine.LNX.2.11.1410141459580.18019@localhost>
	<543DB0CF.3020007@auckland.ac.nz>
Message-ID: <alpine.LNX.2.11.1410141639040.18019@localhost>

On Wed, 15 Oct 2014, Rolf Turner wrote:

> In all probability this is FAQ 7.22.  I.e. use:
>
>>   print(ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL,
>>         aspanel=FALSE,col='red', lwd=2))

Rolf,

   Thank you. Didn't occur to me to look in the FAQ for this issue.

> P. S.  See also fortune(123).

   OK.

Regards,

Rich


From r.turner at auckland.ac.nz  Wed Oct 15 03:46:11 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Wed, 15 Oct 2014 14:46:11 +1300
Subject: [R] r-help@r-project.org
Message-ID: <543DD1E3.9070709@auckland.ac.nz>

[I sent this email to Rich and to the list after some private 
communication with Rich.  However it got held up for being too big, 
presumably because of the pdf attachment.  So I am re-sending it to the 
list *without* the attachment.]

I resorted to actually trying the expedient of installing "compositions" 
and running your code.  It works just fine.  I attach the 
"winters-pdf.pdf" file that was produced.

I thus have no idea what's causing the problem that you are 
experiencing.  It is indeed *not* an FAQ 7.22 problem.  Something weird 
is going on in your system.

cheers,

Rolf

-- 
Rolf Turner
Technical Editor ANZJS


From michel.arnaud at cirad.fr  Wed Oct 15 08:51:16 2014
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 15 Oct 2014 08:51:16 +0200
Subject: [R] To build a new Df from 2 Df
In-Reply-To: <CDB1C7AAB482D246A4AEF6C17ACD9CF234632B7A@dlrexmbx02.intra.dlr.de>
References: <CAAC1QdCpGWhUch7goX_Ot_EsvC8if54xnkop_Wz_HN1S3u1buA@mail.gmail.com>
	<543CE2E3.1010506@cirad.fr>
	<CDB1C7AAB482D246A4AEF6C17ACD9CF234632B7A@dlrexmbx02.intra.dlr.de>
Message-ID: <543E1964.3000905@cirad.fr>

Thank you David
Now, the problem is to list all the combinations which verify the 
condition III (ie every Rapporteur has to have more or less the same 
number of demandeur)
Have you any idea ?
Michel




Le 14/10/2014 13:18, David.Kaethner at dlr.de a ?crit :
> Hello,
>
> here's a draft of a solution. I hope it's not overly complicated.
>
> # find all possible combinations
> combi <- expand.grid(Dem$Nom, Rap$Nom); names(combi) <- c("Dem", "Rap")
>
> # we need the corresponding departments and units
> combi$DemDep <- apply(combi, 1, function(x) Dem$Departement[x[1] == Dem$Nom])
> combi$DemUni <- apply(combi, 1, function(x) Dem$Unite[x[1] == Dem$Nom])
> combi$RapDep <- apply(combi, 1, function(x) Rap$Departement[x[2] == Rap$Nom])
> combi$RapUni <- apply(combi, 1, function(x) Rap$Unite[x[2] == Rap$Nom])
>
> # we exclude the combinations that we don't want
> dep <- combi[combi$DemDep != combi$RapDep, c("Dem", "Rap")]
> dep$id <- as.numeric(dep$Rap)
> uni <- combi[combi$DemUni != combi$RapUni, c("Dem", "Rap")]
> uni$id <- as.numeric(uni$Rap)
>
> # preliminary result
> resDep <- reshape(dep,
>          timevar = "id",
>          idvar = "Dem",
>          direction = "wide"
> )
>
> resUni <- reshape(uni,
>                    timevar = "id",
>                    idvar = "Dem",
>                    direction = "wide"
> )
>
> In resDep and resUni you find the results for Rapporteur1 and Rapporteur2. NAs indicate where conditions did not match. For Rap1/Rap2 you can now choose any column from resDep and resUni that is not NA for that specific Demandeur. I wasn't exactly sure about your third condition, so I'll leave that to you. But with the complete possible matches, you have a more general solution.
>
> Btw, you can construct data.frames just like this:
>
> Dem <- data.frame(
>    Nom = c("John", "Jim", "Julie", "Charles", "Michel", "Emma", "Sandra", "Elodie", "Thierry", "Albert", "Jean", "Francois", "Pierre", "Cyril", "Damien", "Jean-Michel", "Vincent", "Daniel", "Yvan", "Catherine"),
>    Departement = c("D", "A", "A", "C", "D", "B", "D", "B", "C", "D", "B", "B", "B", "A", "C", "D", "B", "A", "D", "D"),
>    Unite = c("Unite8", "Unite4", "Unite4", "Unite7", "Unite9", "Unite1", "Unite6", "Unite5", "Unite7", "Unite3", "Unite2", "Unite6", "Unite8", "Unite8", "Unite3", "Unite8", "Unite9", "Unite7", "Unite9", "Unite5")
> )
>
> -dk
>
> -----Urspr?ngliche Nachricht-----
> Von: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Im Auftrag von Arnaud Michel
> Gesendet: Dienstag, 14. Oktober 2014 10:46
> An: r-help at r-project.org
> Betreff: [R] To build a new Df from 2 Df
>
> Hello
>
> I have 2 df Dem and Rap.
> I would want to build all the df (dfnew) by associating these two df (Dem and Rap) in the following way :
>
> For each value of Dem$Nom (dfnew$Demandeur), I associate 2 different values of Rap$Nom (dfnew$Rapporteur1 and dfnew$Rapporteur2) in such a way
>
>    * for each dfnew$Demandeur, dfnew$Rapporteur1 does not have the same
>      value for Departement as Dem$Departement
>    * for each dfnew$Demandeur, dfnew$Rapporteur2 does not have the same
>      value for Unite as Dem$Unite
>    * the value of table(dfnew$Rapporteur1) and the value of
>      table(dfnew$Rapporteur2) must be balanced and not too different
>      (Accepted differences : 1)
>
> table(dfnew$Rapporteur1)
> Rapporteur01 Rapporteur02 Rapporteur03 Rapporteur04 Rapporteur05
>              4                   4 4                      4
>     4
>
> Thanks for your help
> Michel
>
>    Dem <- structure(list(Nom = c("John", "Jim", "Julie", "Charles", "Michel", "Emma", "Sandra", "Elodie", "Thierry", "Albert", "Jean", "Francois", "Pierre", "Cyril", "Damien", "Jean-Michel", "Vincent", "Daniel", "Yvan", "Catherine"), Departement = c("D", "A", "A", "C", "D", "B", "D", "B", "C", "D", "B", "B", "B", "A", "C", "D", "B", "A", "D", "D"), Unite = c("Unite8", "Unite4", "Unite4", "Unite7", "Unite9", "Unite1", "Unite6", "Unite5", "Unite7", "Unite3", "Unite2", "Unite6", "Unite8", "Unite8", "Unite3", "Unite8", "Unite9", "Unite7", "Unite9", "Unite5")), .Names = c("Nom", "Departement", "Unite"
> ), row.names = c(NA, -20L), class = "data.frame")
>
> Rap <- structure(list(Nom = c("Rapporteur01", "Rapporteur02", "Rapporteur03", "Rapporteur04", "Rapporteur05"), Departement = c("C", "D", "C", "C", "D"), Unite = c("Unite10", "Unite6", "Unite5", "Unite5", "Unite4")), .Names = c("Nom", "Departement", "Unite"), row.names = c(NA, -5L), class = "data.frame")
>
> dfnew <- structure(list(Demandeur = structure(c(13L, 12L, 14L, 3L, 15L, 8L, 17L, 7L, 18L, 1L, 10L, 9L, 16L, 4L, 5L, 11L, 19L, 6L, 20L, 2L), .Label = c("Albert", "Catherine", "Charles", "Cyril", "Damien", "Daniel", "Elodie", "Emma", "Francois", "Jean", "Jean-Michel", "Jim", "John", "Julie", "Michel", "Pierre", "Sandra", "Thierry", "Vincent", "Yvan"), class = "factor"), Rapporteur1 = structure(c(3L, 1L, 3L, 5L, 1L, 5L, 1L, 2L, 5L, 4L, 2L, 4L, 2L, 3L, 5L, 4L, 4L, 2L, 3L, 1L), .Label = c("Rapporteur01", "Rapporteur02", "Rapporteur03", "Rapporteur04", "Rapporteur05"), class = "factor"), Rapporteur2 = structure(c(1L, 3L, 4L, 4L, 2L, 4L, 5L, 1L, 2L, 3L, 3L, 3L, 5L, 5L, 1L, 1L, 2L, 5L, 4L, 2L), .Label = c("Rapporteur01", "Rapporteur02", "Rapporteur03", "Rapporteur04", "Rapporteur05"), class = "factor")), .Names = c("Demandeur", "Rapporteur1", "Rapporteur2"), row.names = c(NA, -20L), class =
> "data.frame")
>
>
> --
> Michel ARNAUD
> Cirad Montpellier
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

-- 
Michel ARNAUD
Cirad Montpellier


From Camille.Dezecache at ecofog.gf  Tue Oct 14 20:07:46 2014
From: Camille.Dezecache at ecofog.gf (Camille Dezecache)
Date: Tue, 14 Oct 2014 18:07:46 +0000
Subject: [R] Error using betamix function
Message-ID: <AA5A756AED56E94E90199127F670A33A0A1FFBB1@Zolive-CAS2.ecofog.gf>

Hi all,

I'm trying to use the betamix function (betareg package) to create a beta mixture model but get this error that I don't understand:
"Error in lm.wfit(x, linkfun(y), weights, offset = offset[[1L]]) :
  NA/NaN/Inf in 'y'
Error in lm.wfit(x, linkfun(y), weights, offset = offset[[1L]]) :
  NA/NaN/Inf in 'y'
Error in lm.wfit(x, linkfun(y), weights, offset = offset[[1L]]) :
  NA/NaN/Inf in 'y'
Error in flexmix::stepFlexmix(fullformula, data = mf, k = k, nrep = nstart,  :
  no convergence to a suitable mixture"

The code I wrote was:
"beta_mix_model <- betamix(formula = def_relat ~ data_roads,
                          k = 2)"

I'm making the hypothesis that def_relat (ie the level of deforestation) is a function of data_roads (ie distance to roads). When a pixel is far from a road, its probability of deforestation is very close to zero with very low uncertainty. Closer to roads however, deforestation is possible (with very high uncertainty of the intensity of deforestation) but occurences of deforestation also occur. This is why I'm considering to groups of observations, with a beta distribution of probability for modelling a probability of deforestation between 0 and 1.

I don't understand the error message, because none of the data I'm using includes NA or Inf. Does anyone has an idea of the reason why I get this error, or can tell me if I'm using the function betamix the wrong way?

Thanks,
Camille

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Wed Oct 15 09:01:27 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Wed, 15 Oct 2014 10:01:27 +0300
Subject: [R] Sum of two consecutive number in dataset.
Message-ID: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>

Dear All,

i am solving the following problem in my work.

The first day from April 01 that gets more than 20 mm on a single day, or
totalled
over 2 consecutive days. i.e April 01 = 92th day of the year.

The column of interest is "Rain".
> head(Samaru56)
  Year Day Rain
1 1928   1    0
2 1928   2    0
3 1928   3    0
4 1928   4    0
5 1928   5    0
6 1928   6    0

I used the loop below but it is not printing anything.

sow_day=c()
for (i in 1928:1983){
  for (j in 92:366){
    k=j-1
    s_rain=Samaru56$Rain[k] + Samaru56$Rain[j]
    if (s_rain>=20)
      sow_day=j
      break
  }
  Samaru56$year=Samaru56$Year[sow_day]
  Samaru56$Day=Samaru56$Day[sow_day]
  Samaru56$Rain=Samaru56$Rain[sow_day]
}
sow_day

Any idea is welcome on how I can solve this problem. Thanks

-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From infojomy at gmail.com  Wed Oct 15 09:30:17 2014
From: infojomy at gmail.com (Jomy Jose)
Date: Wed, 15 Oct 2014 13:00:17 +0530
Subject: [R] Parameter estimation of loglogistic,
 lognormal and 2 parameter exponential distributions
Message-ID: <CADGufDHnsmg2z=aK7FNXoDyg1E1ZxvxhODpo0C_U_uw4-KdM4A@mail.gmail.com>

How to estimate paremeters  the of  loglogistic,lognormal and  2 parameter
exponential distributions in R using fitdistr function.

	[[alternative HTML version deleted]]


From rl at openmailbox.org  Wed Oct 15 10:51:48 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Wed, 15 Oct 2014 08:51:48 +0000
Subject: [R] package installation failure virtualisation environment
In-Reply-To: <CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>
References: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
	<CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>
Message-ID: <5a91706aac4e7f4b536fbdb094166737@openmailbox.org>

On 2014-10-14 15:40, Sven E. Templer wrote:
> Prevent graphic menues with:
> options(menu.graphics = FALSE)

Same response after a pause: 'Killed'

> or and define repositories:
> options(repos = c(CRAN = "http://cran.r-project.org"))
> 

Same response after a pause: 'Killed'


From miaojpm at gmail.com  Wed Oct 15 11:00:22 2014
From: miaojpm at gmail.com (jpm miao)
Date: Wed, 15 Oct 2014 17:00:22 +0800
Subject: [R] lag operator on a zoo object - code sharing
Message-ID: <CABcx46Ch58f96kSPqvcRihnbkfxNqS_v1QTaimb8QadbQ-xy6w@mail.gmail.com>

Hi,
   I could not find a nice lag operator on zoo object. Perhaps there is,
but I just couldn't find it. Basically I want the operator to return the
lagged zoo object (with one or more variables ) with the original date. For
example, if I write lag(x, -3), then I got the lagged series, but the first
three observations are deleted. My code could work, but is not polished.
Someone helps or comments?


lagzoo<-function(x, lag_n)
{

  if(is.zoo(x)==FALSE)
  {
    stop("zoo objects for lagzoo, please")
  }
  if(ncol(x)==1)
  {
    y<-x
  t<-time(x)
  n<-length(t)

  y[(lag_n+1):n]<-x[1:(n-lag_n)]
  y[1:lag_n]<-NA
  return(y)
  }
  else
  {
    y<-x
    n<-nrow(x)
    y[(lag_n+1):n,]<-x[1:(n-lag_n),]
    y[1:lag_n,]<-NA
    return(y)
  }
}

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Wed Oct 15 11:13:01 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 15 Oct 2014 11:13:01 +0200
Subject: [R] package installation failure virtualisation environment
In-Reply-To: <5a91706aac4e7f4b536fbdb094166737@openmailbox.org>
References: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
	<CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>
	<5a91706aac4e7f4b536fbdb094166737@openmailbox.org>
Message-ID: <CAHuTOvqHXRuB7TtwVFXL4NfCqTS21hCMqbbFxgX78QeaPgR6bA@mail.gmail.com>

did you check the connection in R via for example:

head(readLines("http://cran.r-project.org/web/licenses/GPL-3"))

which should yield:

[1] "                    GNU GENERAL PUBLIC LICENSE"
[2] "                       Version 3, 29 June 2007"
[3] ""
[4] " Copyright (C) 2007 Free Software Foundation, Inc. <http://fsf.org/>"
[5] " Everyone is permitted to copy and distribute verbatim copies"
[6] " of this license document, but changing it is not allowed."

On 15 October 2014 10:51,  <rl at openmailbox.org> wrote:
> On 2014-10-14 15:40, Sven E. Templer wrote:
>>
>> Prevent graphic menues with:
>> options(menu.graphics = FALSE)
>
>
> Same response after a pause: 'Killed'
>
>> or and define repositories:
>> options(repos = c(CRAN = "http://cran.r-project.org"))
>>
>
> Same response after a pause: 'Killed'
>
>


From Achim.Zeileis at uibk.ac.at  Wed Oct 15 11:13:52 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Wed, 15 Oct 2014 11:13:52 +0200 (CEST)
Subject: [R] lag operator on a zoo object - code sharing
In-Reply-To: <CABcx46Ch58f96kSPqvcRihnbkfxNqS_v1QTaimb8QadbQ-xy6w@mail.gmail.com>
References: <CABcx46Ch58f96kSPqvcRihnbkfxNqS_v1QTaimb8QadbQ-xy6w@mail.gmail.com>
Message-ID: <alpine.DEB.2.11.1410151111380.27650@paninaro.uibk.ac.at>

On Wed, 15 Oct 2014, jpm miao wrote:

> Hi,
>   I could not find a nice lag operator on zoo object. Perhaps there is,
> but I just couldn't find it.

See ?lag.zoo.

> Basically I want the operator to return the
> lagged zoo object (with one or more variables ) with the original date. For
> example, if I write lag(x, -3), then I got the lagged series, but the first
> three observations are deleted.

Set na.pad = TRUE.

> My code could work, but is not polished.

Yes, the ncol() does not work on vectors without dim and leads cannot be 
computed.

> Someone helps or comments?
>
>
> lagzoo<-function(x, lag_n)
> {
>
>  if(is.zoo(x)==FALSE)
>  {
>    stop("zoo objects for lagzoo, please")
>  }
>  if(ncol(x)==1)
>  {
>    y<-x
>  t<-time(x)
>  n<-length(t)
>
>  y[(lag_n+1):n]<-x[1:(n-lag_n)]
>  y[1:lag_n]<-NA
>  return(y)
>  }
>  else
>  {
>    y<-x
>    n<-nrow(x)
>    y[(lag_n+1):n,]<-x[1:(n-lag_n),]
>    y[1:lag_n,]<-NA
>    return(y)
>  }
> }
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From kridox at ymail.com  Wed Oct 15 11:17:25 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 15 Oct 2014 18:17:25 +0900
Subject: [R] lag operator on a zoo object - code sharing
In-Reply-To: <CABcx46Ch58f96kSPqvcRihnbkfxNqS_v1QTaimb8QadbQ-xy6w@mail.gmail.com>
References: <CABcx46Ch58f96kSPqvcRihnbkfxNqS_v1QTaimb8QadbQ-xy6w@mail.gmail.com>
Message-ID: <CAAcyNCyT4TeUQz+hoPTgALO8DTm+nQ4cyBHc4F5BkgoV1MUiVg@mail.gmail.com>

Hi,

You probably missed the "na.pad" argument of the "lag" function (for
zoo objects).
?zoo:::lag.zoo

Regards,
Pascal

On Wed, Oct 15, 2014 at 6:00 PM, jpm miao <miaojpm at gmail.com> wrote:
> Hi,
>    I could not find a nice lag operator on zoo object. Perhaps there is,
> but I just couldn't find it. Basically I want the operator to return the
> lagged zoo object (with one or more variables ) with the original date. For
> example, if I write lag(x, -3), then I got the lagged series, but the first
> three observations are deleted. My code could work, but is not polished.
> Someone helps or comments?
>
>
> lagzoo<-function(x, lag_n)
> {
>
>   if(is.zoo(x)==FALSE)
>   {
>     stop("zoo objects for lagzoo, please")
>   }
>   if(ncol(x)==1)
>   {
>     y<-x
>   t<-time(x)
>   n<-length(t)
>
>   y[(lag_n+1):n]<-x[1:(n-lag_n)]
>   y[1:lag_n]<-NA
>   return(y)
>   }
>   else
>   {
>     y<-x
>     n<-nrow(x)
>     y[(lag_n+1):n,]<-x[1:(n-lag_n),]
>     y[1:lag_n,]<-NA
>     return(y)
>   }
> }
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From petr.pikal at precheza.cz  Wed Oct 15 11:59:40 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 15 Oct 2014 09:59:40 +0000
Subject: [R] Sum of two consecutive number in dataset.
In-Reply-To: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
References: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA2C9@SRVEXCHMBX.precheza.cz>

Hi

twodays <- rowSums(embed(Samaru56$Rain,2))

gives you sum of rain in 2 cosecutive days

sel <- which(twodays>20)

gives you vector of row numbers in which above condition results in TRUE value

Samaru56[sel,]

selects these rows

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frederic Ntirenganya
> Sent: Wednesday, October 15, 2014 9:01 AM
> To: r-help at r-project.org
> Subject: [R] Sum of two consecutive number in dataset.
>
> Dear All,
>
> i am solving the following problem in my work.
>
> The first day from April 01 that gets more than 20 mm on a single day,
> or totalled over 2 consecutive days. i.e April 01 = 92th day of the
> year.
>
> The column of interest is "Rain".
> > head(Samaru56)
>   Year Day Rain
> 1 1928   1    0
> 2 1928   2    0
> 3 1928   3    0
> 4 1928   4    0
> 5 1928   5    0
> 6 1928   6    0
>
> I used the loop below but it is not printing anything.
>
> sow_day=c()
> for (i in 1928:1983){
>   for (j in 92:366){
>     k=j-1
>     s_rain=Samaru56$Rain[k] + Samaru56$Rain[j]
>     if (s_rain>=20)
>       sow_day=j
>       break
>   }
>   Samaru56$year=Samaru56$Year[sow_day]
>   Samaru56$Day=Samaru56$Day[sow_day]
>   Samaru56$Rain=Samaru56$Rain[sow_day]
> }
> sow_day
>
> Any idea is welcome on how I can solve this problem. Thanks
>
> --
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Oct 15 12:09:48 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 15 Oct 2014 10:09:48 +0000
Subject: [R] how to ajust y-axis values in plot() ?
In-Reply-To: <2cd499e7.1ce20.1490e011d61.Coremail.rhelpmaillist@163.com>
References: <2cd499e7.1ce20.1490e011d61.Coremail.rhelpmaillist@163.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA35C@SRVEXCHMBX.precheza.cz>

Hi

is

> plot(11:20, ylim=c(0,40))
> abline(h=40)
>

what you want?

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of PO SU
> Sent: Tuesday, October 14, 2014 11:33 AM
> To: R. Help
> Subject: [R] how to ajust y-axis values in plot() ?
>
>
> Dear helpeRs,
>   I want to plot( 11:20 ) in a plot.
>  if i just type the code above, the y value  will be from 11 to 20, now
> i want the value from a given range like  0 to 40, how can i do it?
> I read ?plot  for a while but  still can't solve it.
> Actually, the qustion is founded when i already plot a plot like
> plot(11:20) , but when i abline(h=40), i found it will go out of the
> plot even after i used abline(h=40,xpd=T).
> SO, may you help me?
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From rshepard at appl-ecosys.com  Tue Oct 14 23:20:40 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 14 Oct 2014 14:20:40 -0700 (PDT)
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
Message-ID: <alpine.LNX.2.11.1410141404560.18019@localhost>

   A rather strange situation here and I've not found the source of the
problem.

   The point is to print a ternary plot matrix of compositional data with
ellipses enclosing 95% of the variance in each plot. The ellipses display on
the monitor, dev = x11cairo (see attached winters-x11cairo.pdf), but not when
sent directly to a file, dev = pdf (see attached winters-pdf.pdf).

   Here's winters.acomp:

structure(c(0.0666666666666667, 0.0612244897959184, 0.0434782608695652, 
0.043956043956044, 0.05, 0.0161290322580645, 0.6, 0.571428571428571, 
0.623188405797101, 0.593406593406593, 0.433333333333333, 0.629032258064516, 
0.0666666666666667, 0.0612244897959184, 0.101449275362319, 0.0659340659340659, 
0.0666666666666667, 0.032258064516129, 0.244444444444444, 0.26530612244898, 
0.217391304347826, 0.263736263736264, 0.366666666666667, 0.290322580645161, 
0.0222222222222222, 0.0408163265306122, 0.0144927536231884, 0.032967032967033, 
0.0833333333333333, 0.032258064516129), .Dim = c(6L, 5L), .Dimnames = list(
     NULL, c("filter", "gather", "graze", "predate", "shred")), class = "acomp")

   And this is the command sequence:

> library(compositions)
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> r <- sqrt(qchisq(p=0.95, df=4))
> mn <- mean(winters.acomp)
> vr <- var(winters.acomp)
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
 	col='red', lwd=2)
# monitor plot window is manually closed.
> pdf("winters-pdf.pdf")
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
 	col='red', lwd=2)
> dev.off()

   What am I not seeing here that causes the different outputs?

Rich
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winters-x11cairo.pdf
Type: application/pdf
Size: 178553 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141014/f12157aa/attachment.pdf>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: winters-pdf.pdf
Type: application/pdf
Size: 181383 bytes
Desc: 
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141014/f12157aa/attachment-0001.pdf>

From albmont at centroin.com.br  Wed Oct 15 13:42:00 2014
From: albmont at centroin.com.br (ALBERTO VIEIRA FERREIRA MONTEIRO)
Date: Wed, 15 Oct 2014 08:42:00 -0300
Subject: [R] gsub regexp question
Message-ID: <CAEyj4=_uLH+CdNR6uk+09EYNWehPcfGZrOyiprEEcqSuLZ9ywg@mail.gmail.com>

I just found a curious behaviour of regexp and I'd like to share with y'all.

gsub("^([[:alnum:]\\[\\]]*).*", "\\1", "array[n] <- 10", perl=T) #
works as expected ("array[n]")

gsub("^([[:alnum:]\\[\\]]*).*", "\\1", "array[n] <- 10", perl=F) #
doesn't work ("a")

I didn't find anything in the documentation explain what's going on,
and why the second gsub doesn't work.

Alberto Monteiro


From fsmairura at yahoo.com  Wed Oct 15 14:26:07 2014
From: fsmairura at yahoo.com (Franklin Mairura)
Date: Wed, 15 Oct 2014 05:26:07 -0700
Subject: [R] Sum of two consecutive number in dataset.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA2C9@SRVEXCHMBX.precheza.cz>
References: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA2C9@SRVEXCHMBX.precheza.cz>
Message-ID: <1413375967.19128.YahooMailNeo@web162806.mail.bf1.yahoo.com>

Hi, this sound like u are calculating cummulative rainfall, this can also be done in excel, then import the matrix to R, hope can help,
Franklin, Maseno, Kenya. 



On Wednesday, October 15, 2014 1:02 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
 


Hi

twodays <- rowSums(embed(Samaru56$Rain,2))

gives you sum of rain in 2 cosecutive days

sel <- which(twodays>20)

gives you vector of row numbers in which above condition results in TRUE value

Samaru56[sel,]

selects these rows

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Frederic Ntirenganya
> Sent: Wednesday, October 15, 2014 9:01 AM
> To: r-help at r-project.org
> Subject: [R] Sum of two consecutive number in dataset.
>
> Dear All,
>
> i am solving the following problem in my work.
>
> The first day from April 01 that gets more than 20 mm on a single day,
> or totalled over 2 consecutive days. i.e April 01 = 92th day of the
> year.
>
> The column of interest is "Rain".
> > head(Samaru56)
>   Year Day Rain
> 1 1928   1    0
> 2 1928   2    0
> 3 1928   3    0
> 4 1928   4    0
> 5 1928   5    0
> 6 1928   6    0
>
> I used the loop below but it is not printing anything.
>
> sow_day=c()
> for (i in 1928:1983){
>   for (j in 92:366){
>     k=j-1
>     s_rain=Samaru56$Rain[k] + Samaru56$Rain[j]
>     if (s_rain>=20)
>       sow_day=j
>       break
>   }
>   Samaru56$year=Samaru56$Year[sow_day]
>   Samaru56$Day=Samaru56$Day[sow_day]
>   Samaru56$Rain=Samaru56$Rain[sow_day]
> }
> sow_day
>
> Any idea is welcome on how I can solve this problem. Thanks
>
> --
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From daniela.droguett.leon at gmail.com  Wed Oct 15 15:27:05 2014
From: daniela.droguett.leon at gmail.com (Daniela Droguett)
Date: Wed, 15 Oct 2014 10:27:05 -0300
Subject: [R] vcov function and cross terms
Message-ID: <CABD9s953hiBTeEH=Bkja8RjdEo3w-ArhDmrWZpB1aYh4-kcCjg@mail.gmail.com>

Hi,

I would like to apply the vcov function from the survey package for the
variables api00 and api99 grouped by the stype variable which can assume H,
M and E categories.

?From the code in the survey package manual:?

?data(api)
dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
rclus1<-as.svrepdesign(dclus1)
mns<-svyby(~api00, ~stype, rclus1, svymean,covmat=TRUE)
vcov(mns)

I have tried the following changes in order to get the variance matrix
estimation (as part of Taylor Linearization).

> data(api)
> dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)

?> mns<-svyby(~api00+api99, ~stype, dclus1, svytotal)
> mns
  stype     api00     api99 se.api00 se.api99
E     E 3162561.8 2962356.8 842713.7 796474.0
H     H  293115.0  282283.9 104059.8 101492.9
M     M  534308.7  514982.0 108710.7 105036.6
> vcov(mns)
             E:api00     H:api00     M:api00      E:api99     H:api99
M:api99
E:api00 710166313660           0           0            0           0
    0
H:api00            0 10828434454           0            0           0
    0
M:api00            0           0 11818006832            0           0
    0
E:api99            0           0           0 634370797647           0
    0
H:api99            0           0           0            0 10300818294
    0
M:api99            0           0           0            0           0
11032691751
Warning message:
In vcov.svyby(mns) : Only diagonal elements of vcov() available

How to obtain the cross terms in the matrix above?

I have no clue on how to implement that.

Thanks a lot!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Oct 15 15:27:33 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 15 Oct 2014 06:27:33 -0700
Subject: [R] gsub regexp question
In-Reply-To: <CAEyj4=_uLH+CdNR6uk+09EYNWehPcfGZrOyiprEEcqSuLZ9ywg@mail.gmail.com>
References: <CAEyj4=_uLH+CdNR6uk+09EYNWehPcfGZrOyiprEEcqSuLZ9ywg@mail.gmail.com>
Message-ID: <1A4B1D90-1D76-43BA-9D79-DAAE4D5F1225@dcn.davis.CA.us>

I believe the backslash is not considered an escape character by the extended RE library used by R (perl=FALSE), so it is being treated as a literal. This means that the last ] is outside the character class and is the atom that the * applies to.

 gsub("^([[:alnum:]\\[\\]]*).*", "\\1", "a]]]rray[n] <- 10", perl=FALSE)

yields

"a]]]"

(Using F in place of FALSE is bad form.)
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 15, 2014 4:42:00 AM PDT, ALBERTO VIEIRA FERREIRA MONTEIRO <albmont at centroin.com.br> wrote:
>I just found a curious behaviour of regexp and I'd like to share with
>y'all.
>
>gsub("^([[:alnum:]\\[\\]]*).*", "\\1", "array[n] <- 10", perl=T) #
>works as expected ("array[n]")
>
>gsub("^([[:alnum:]\\[\\]]*).*", "\\1", "array[n] <- 10", perl=F) #
>doesn't work ("a")
>
>I didn't find anything in the documentation explain what's going on,
>and why the second gsub doesn't work.
>
>Alberto Monteiro
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Wed Oct 15 15:41:36 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Wed, 15 Oct 2014 09:41:36 -0400
Subject: [R] vcov function and cross terms
In-Reply-To: <CABD9s953hiBTeEH=Bkja8RjdEo3w-ArhDmrWZpB1aYh4-kcCjg@mail.gmail.com>
References: <CABD9s953hiBTeEH=Bkja8RjdEo3w-ArhDmrWZpB1aYh4-kcCjg@mail.gmail.com>
Message-ID: <CAOwvMDzUV5O+U2J5ZRdo+2iQ75ibxKE+TAiWcgbRP3TBmCpT4w@mail.gmail.com>

it might be slightly different, but i think the result is very close to a
tsl result (which hasn't been implemented)..  could you use this?

mns<-svyby(~api00+api99, ~stype, rclus1, svytotal,covmat=TRUE)
vcov(mns)




On Wed, Oct 15, 2014 at 9:27 AM, Daniela Droguett <
daniela.droguett.leon at gmail.com> wrote:

> Hi,
>
> I would like to apply the vcov function from the survey package for the
> variables api00 and api99 grouped by the stype variable which can assume H,
> M and E categories.
>
> ?From the code in the survey package manual:?
>
> ?data(api)
> dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
> rclus1<-as.svrepdesign(dclus1)
> mns<-svyby(~api00, ~stype, rclus1, svymean,covmat=TRUE)
> vcov(mns)
>
> I have tried the following changes in order to get the variance matrix
> estimation (as part of Taylor Linearization).
>
> > data(api)
> > dclus1<-svydesign(id=~dnum, weights=~pw, data=apiclus1, fpc=~fpc)
>
> ?> mns<-svyby(~api00+api99, ~stype, dclus1, svytotal)
> > mns
>   stype     api00     api99 se.api00 se.api99
> E     E 3162561.8 2962356.8 842713.7 796474.0
> H     H  293115.0  282283.9 104059.8 101492.9
> M     M  534308.7  514982.0 108710.7 105036.6
> > vcov(mns)
>              E:api00     H:api00     M:api00      E:api99     H:api99
> M:api99
> E:api00 710166313660           0           0            0           0
>     0
> H:api00            0 10828434454           0            0           0
>     0
> M:api00            0           0 11818006832            0           0
>     0
> E:api99            0           0           0 634370797647           0
>     0
> H:api99            0           0           0            0 10300818294
>     0
> M:api99            0           0           0            0           0
> 11032691751
> Warning message:
> In vcov.svyby(mns) : Only diagonal elements of vcov() available
>
> How to obtain the cross terms in the matrix above?
>
> I have no clue on how to implement that.
>
> Thanks a lot!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Oct 15 16:09:54 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 15 Oct 2014 14:09:54 +0000
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
In-Reply-To: <alpine.LNX.2.11.1410141404560.18019@localhost>
References: <alpine.LNX.2.11.1410141404560.18019@localhost>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FA936A@mb02.ads.tamu.edu>

I haven't looked at the source so I don't know exactly what is going on, but I think I have a work around. While running your example I noticed that ellipse() does not just add the ellipse to the plot produced by plot(), it replots the figure. However, just running ellipse() without plot() generates an error "Error in if (coorgeo == "acomp") { : argument is of length zero" so ellipse needs the plot environment produced by plot(). Moving the pdf() file works on my Windows machine:

> plot(winters.acomp, main="Winters Creek", cex=0.5)
> pdf("winters-pdf.pdf")
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
+  col='red', lwd=2)
> dev.off()

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Rich Shepard
Sent: Tuesday, October 14, 2014 4:21 PM
To: r-help at r-project.org
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF

   A rather strange situation here and I've not found the source of the
problem.

   The point is to print a ternary plot matrix of compositional data with
ellipses enclosing 95% of the variance in each plot. The ellipses display on
the monitor, dev = x11cairo (see attached winters-x11cairo.pdf), but not when
sent directly to a file, dev = pdf (see attached winters-pdf.pdf).

   Here's winters.acomp:

structure(c(0.0666666666666667, 0.0612244897959184, 0.0434782608695652, 
0.043956043956044, 0.05, 0.0161290322580645, 0.6, 0.571428571428571, 
0.623188405797101, 0.593406593406593, 0.433333333333333, 0.629032258064516,
0.0666666666666667, 0.0612244897959184, 0.101449275362319, 0.0659340659340659, 
0.0666666666666667, 0.032258064516129, 0.244444444444444, 0.26530612244898,
0.217391304347826, 0.263736263736264, 0.366666666666667, 0.290322580645161,
0.0222222222222222, 0.0408163265306122, 0.0144927536231884, 0.032967032967033, 
0.0833333333333333, 0.032258064516129), .Dim = c(6L, 5L), .Dimnames = list(
     NULL, c("filter", "gather", "graze", "predate", "shred")), class = "acomp")

   And this is the command sequence:

> library(compositions)
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> r <- sqrt(qchisq(p=0.95, df=4))
> mn <- mean(winters.acomp)
> vr <- var(winters.acomp)
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
 	col='red', lwd=2)
# monitor plot window is manually closed.
> pdf("winters-pdf.pdf")
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
 	col='red', lwd=2)
> dev.off()

   What am I not seeing here that causes the different outputs?

Rich


From tom at maladmin.com  Wed Oct 15 16:15:42 2014
From: tom at maladmin.com (Tom Wright)
Date: Wed, 15 Oct 2014 10:15:42 -0400
Subject: [R] Sum of two consecutive number in dataset.
In-Reply-To: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
References: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
Message-ID: <1413382542.2181.15.camel@tom-laptop>

A couple of observations:
1) I'm not sure what the variable i is doing, looks like you are trying
to loop through years but perhaps you left that bit of code out for
clarity.
2) On the first loop of i you are assigning the values of
Samaru56[sow_day,] to all values in Samaru56. For future loops all
values on Samaru56 will be the same.

My approach to this problem would be:
rowCount<-nrow(Samaru56)
Samaru56$two_day<-vector(length=rowCount)

#first day doesnt have a two day value
Samaru56$two_day[2:rowCount]<-
	Samaru56$Rain[1:rowCount-1] + Samaru56$Rain[2:rowCount]

sow_day <- min(c(
		which(Samaru56$Rain > 20 & Samaru$Day>91),
		which(Samaru56$two_day > 20 & Samaru$Day>91)))


#first day doesnt have a two day value

On Wed, 2014-10-15 at 10:01 +0300, Frederic Ntirenganya wrote:
> Dear All,
> 
> i am solving the following problem in my work.
> 
> The first day from April 01 that gets more than 20 mm on a single day, or
> totalled
> over 2 consecutive days. i.e April 01 = 92th day of the year.
> 
> The column of interest is "Rain".
> > head(Samaru56)
>   Year Day Rain
> 1 1928   1    0
> 2 1928   2    0
> 3 1928   3    0
> 4 1928   4    0
> 5 1928   5    0
> 6 1928   6    0
> 
> I used the loop below but it is not printing anything.
> 
> sow_day=c()
> for (i in 1928:1983){
>   for (j in 92:366){
>     k=j-1
>     s_rain=Samaru56$Rain[k] + Samaru56$Rain[j]
>     if (s_rain>=20)
>       sow_day=j
>       break
>   }
>   Samaru56$year=Samaru56$Year[sow_day]
>   Samaru56$Day=Samaru56$Day[sow_day]
>   Samaru56$Rain=Samaru56$Rain[sow_day]
> }
> sow_day
> 
> Any idea is welcome on how I can solve this problem. Thanks
>


From rshepard at appl-ecosys.com  Wed Oct 15 16:20:25 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 15 Oct 2014 07:20:25 -0700 (PDT)
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FA936A@mb02.ads.tamu.edu>
References: <alpine.LNX.2.11.1410141404560.18019@localhost>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FA936A@mb02.ads.tamu.edu>
Message-ID: <alpine.LNX.2.11.1410150715440.509@localhost>

On Wed, 15 Oct 2014, David L Carlson wrote:

> I haven't looked at the source so I don't know exactly what is going on,
> but I think I have a work around. While running your example I noticed
> that ellipse() does not just add the ellipse to the plot produced by
> plot(), it replots the figure. However, just running ellipse() without
> plot() generates an error "Error in if (coorgeo == "acomp") { : argument
> is of length zero" so ellipse needs the plot environment produced by
> plot(). Moving the pdf() file works on my Windows machine:
>
>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> pdf("winters-pdf.pdf")
>> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
> +  col='red', lwd=2)
>> dev.off()

David,

   How interesting! I saw what I now know as the plot being redrawn when the
ellipses were added but did not recognize the significance. I'll try this
in a while but it should work here, too.

Much appreciated,

Rich


From wdunlap at tibco.com  Wed Oct 15 17:11:00 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 15 Oct 2014 08:11:00 -0700
Subject: [R] Sum of two consecutive number in dataset.
In-Reply-To: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
References: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
Message-ID: <CAF8bMcZWP_NxtowA0z=8t6Cj5ebCRv3XhH5eg3z-td7KVtPYvQ@mail.gmail.com>

Break down your problem into parts:
# compute two-day totals.  I use filter here, but there are many ways
twoDayTotal <- function (x, init = 0)
{
    # init lets you supply rainfall from day previous to first in x
    filter(c(init, x), c(1, 1))[-length(x)]
}
# compute the first time a logical vector contains a TRUE
firstTime <-function (x, time. = as.vector(time(x)))
{
    stopifnot(is.logical(x))
    time.[!is.na(x) & x][1]
}
# combine them
f <- function(x, ...) firstTime(x>22 | twoDayTotal(x)>22, ...)
# test it
f(c(5, 20, 3, 4, 25))
# [1] 2
f(c(0, 25, 3, 4, 25), time=92:96)
# [1] 93
f(ts(c(0, 25, 3, 4, 25), start=92))
# [1] 93


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 15, 2014 at 12:01 AM, Frederic Ntirenganya
<ntfredo at gmail.com> wrote:
> Dear All,
>
> i am solving the following problem in my work.
>
> The first day from April 01 that gets more than 20 mm on a single day, or
> totalled
> over 2 consecutive days. i.e April 01 = 92th day of the year.
>
> The column of interest is "Rain".
>> head(Samaru56)
>   Year Day Rain
> 1 1928   1    0
> 2 1928   2    0
> 3 1928   3    0
> 4 1928   4    0
> 5 1928   5    0
> 6 1928   6    0
>
> I used the loop below but it is not printing anything.
>
> sow_day=c()
> for (i in 1928:1983){
>   for (j in 92:366){
>     k=j-1
>     s_rain=Samaru56$Rain[k] + Samaru56$Rain[j]
>     if (s_rain>=20)
>       sow_day=j
>       break
>   }
>   Samaru56$year=Samaru56$Year[sow_day]
>   Samaru56$Day=Samaru56$Day[sow_day]
>   Samaru56$Rain=Samaru56$Rain[sow_day]
> }
> sow_day
>
> Any idea is welcome on how I can solve this problem. Thanks
>
> --
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Oct 15 17:34:23 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 15 Oct 2014 08:34:23 -0700
Subject: [R] Sum of two consecutive number in dataset.
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA2C9@SRVEXCHMBX.precheza.cz>
References: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA2C9@SRVEXCHMBX.precheza.cz>
Message-ID: <0BFF4651-B15F-4E58-A17E-8D2F5A12F6A6@dcn.davis.CA.us>

twodays <- c(filter(x,c(1,1),sides=1))

might be more efficient with memory than the embed approach, which might be important if more than two days were of interest.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 15, 2014 2:59:40 AM PDT, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>Hi
>
>twodays <- rowSums(embed(Samaru56$Rain,2))
>
>gives you sum of rain in 2 cosecutive days
>
>sel <- which(twodays>20)
>
>gives you vector of row numbers in which above condition results in
>TRUE value
>
>Samaru56[sel,]
>
>selects these rows
>
>Regards
>Petr
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Frederic Ntirenganya
>> Sent: Wednesday, October 15, 2014 9:01 AM
>> To: r-help at r-project.org
>> Subject: [R] Sum of two consecutive number in dataset.
>>
>> Dear All,
>>
>> i am solving the following problem in my work.
>>
>> The first day from April 01 that gets more than 20 mm on a single
>day,
>> or totalled over 2 consecutive days. i.e April 01 = 92th day of the
>> year.
>>
>> The column of interest is "Rain".
>> > head(Samaru56)
>>   Year Day Rain
>> 1 1928   1    0
>> 2 1928   2    0
>> 3 1928   3    0
>> 4 1928   4    0
>> 5 1928   5    0
>> 6 1928   6    0
>>
>> I used the loop below but it is not printing anything.
>>
>> sow_day=c()
>> for (i in 1928:1983){
>>   for (j in 92:366){
>>     k=j-1
>>     s_rain=Samaru56$Rain[k] + Samaru56$Rain[j]
>>     if (s_rain>=20)
>>       sow_day=j
>>       break
>>   }
>>   Samaru56$year=Samaru56$Year[sow_day]
>>   Samaru56$Day=Samaru56$Day[sow_day]
>>   Samaru56$Rain=Samaru56$Rain[sow_day]
>> }
>> sow_day
>>
>> Any idea is welcome on how I can solve this problem. Thanks
>>
>> --
>> Frederic Ntirenganya
>> Maseno University,
>> Kenya.
>> Mobile:(+254)718492836
>> Email: fredo at aims.ac.za
>> https://sites.google.com/a/aims.ac.za/fredo/
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
>modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
>ze strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and
>are intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into
>a contract in any time, for any reason, and without stating any
>reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer)
>excludes any acceptance of the offer on the part of the recipient
>containing any amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by
>the recipient.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Oct 15 17:36:36 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 15 Oct 2014 08:36:36 -0700
Subject: [R] package installation failure virtualisation environment
In-Reply-To: <5a91706aac4e7f4b536fbdb094166737@openmailbox.org>
References: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
	<CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>
	<5a91706aac4e7f4b536fbdb094166737@openmailbox.org>
Message-ID: <CAF8bMcZeJhebpC5c7L5Qcxj2eX+vBB0p5=g=Y=bmw-6AQLzhKg@mail.gmail.com>

Have you looked at recent entries in the system log files in /var/log,
especially /var/log/kern.log?
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 15, 2014 at 1:51 AM,  <rl at openmailbox.org> wrote:
> On 2014-10-14 15:40, Sven E. Templer wrote:
>>
>> Prevent graphic menues with:
>> options(menu.graphics = FALSE)
>
>
> Same response after a pause: 'Killed'
>
>> or and define repositories:
>> options(repos = c(CRAN = "http://cran.r-project.org"))
>>
>
> Same response after a pause: 'Killed'
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Wed Oct 15 18:00:48 2014
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 15 Oct 2014 09:00:48 -0700 (PDT)
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FA936A@mb02.ads.tamu.edu>
References: <alpine.LNX.2.11.1410141404560.18019@localhost>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FA936A@mb02.ads.tamu.edu>
Message-ID: <alpine.LNX.2.11.1410150850460.509@localhost>

On Wed, 15 Oct 2014, David L Carlson wrote:

> I haven't looked at the source so I don't know exactly what is going on,
> but I think I have a work around:

>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> pdf("winters-pdf.pdf")
>> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
> +  col='red', lwd=2)
>> dev.off()

   Well, there is certainly something different here:

> library(compositions)
> plot(winters.acomp, main="Winters Creek", cex=0.5)
> r <- sqrt(qchisq(p=0.95, df=4))
> mn <- mean(winters.acomp)
> vr <- var(winters.acomp)
> pdf("winters-ffg-prop.pdf")
> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
> col='red', lwd=2)
Error in if (coorgeo == "acomp") { : argument is of length zero
> dev.off()

   So it works for David and Rolf, but not for me. Environment: R-3.1.1 on
Slackware-14.1 in Emacs-24.3 with ESS-13.09-1 and compositions-1.40-1.

   I would appreciate assistance from one of you R gurus in finding the
source of this problem and fixing it. Communicating off the mail list (until
the solution is reached) might be a good idea to avoid clutter.

TIA,

Rich


From abhinabaroy09 at gmail.com  Wed Oct 15 20:21:49 2014
From: abhinabaroy09 at gmail.com (Abhinaba Roy)
Date: Wed, 15 Oct 2014 23:51:49 +0530
Subject: [R] Passing object value in command line
Message-ID: <CANtKHPWWbyUf=SQzdK9BDnhKYMT0OUZNh3_yEDfsnGWYda3TTw@mail.gmail.com>

Hi R-helpers,

I have a R script (mainCall.R) which takes the value of an object *'Mon'*
as '31-may-2014' or '31-aug-2014' .

How can I run the R script by passing the value of Mon from the command
prompt?

Any help will be appreciated

Regards,
Abhinaba

	[[alternative HTML version deleted]]


From adam.n.jenkins13 at gmail.com  Wed Oct 15 14:23:58 2014
From: adam.n.jenkins13 at gmail.com (Adam.N.Jenkins13@gmail.com)
Date: Wed, 15 Oct 2014 13:23:58 +0100
Subject: [R] Retrieving lists of colnames
Message-ID: <520F3B10-BA3A-4CFC-9A74-147F7C0BFBBB@gmail.com>



Hi what I have is a large excel doc (100 columns, 350 row) with data values from 0-10000. The end goal is for each row to have a list of colnames of which columns contain values >0. I've been tinkering around with apply mostly and some other functions, any help offered would be greatly appreciated.

From rhtardin at gmail.com  Wed Oct 15 17:48:19 2014
From: rhtardin at gmail.com (Rodrigo Tardin)
Date: Wed, 15 Oct 2014 11:48:19 -0400
Subject: [R] Proportion data GAM
Message-ID: <CAE5HZZKWidrZC96p6Svvx2exN_2kiOj7Cx_UhFk30D9tK97XOQ@mail.gmail.com>

Hi all,

I am not sure if this is the right place for this question or if there is
one more specific.
Anyway, I hope somebody can help me.

I am trying to run a GAM with beta distribution from mgcv package.
My dependent variable is a proportion continuously ranging from 0 to 1
(whales density) and I have three co-variates Depth, Distance to Coast and
Seabed Slope.

>From what I read, beta distribution is the most appropriate for my response
variable and not binomial.
According to mgcv manual, it is possible to specify beta distribution on a
GAM with the "betar" function, but I get the following error:
could not find function "betar"

My code is:
library(mgcv)
a2=gam(Density~s(DEPTH,k=4)+s(DISTCOAST_1,k=4)+s(SLOPE,k=4),
family=betar(link="logit"),data=misti,gamma=1.4)

The beta family is specified exactly as it is shown in the manual:
bm <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=betar(link="logit"),data=dat)

Does anyone know what it seems to be the problem?
Thanks in advance,
Rodrigo


Rodrigo Tardin

Shor Term Scholar - Duke Marine Lab. - Duke University
Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
M.Sc em Biologia Animal - PPGBA - UFRRJ
Especialista em Doc?ncia do Ensino Superior - IAVM
Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA

	[[alternative HTML version deleted]]


From jlessan13 at ku.edu.tr  Wed Oct 15 14:53:02 2014
From: jlessan13 at ku.edu.tr (JAVAD LESSAN)
Date: Wed, 15 Oct 2014 15:53:02 +0300
Subject: [R] HELP
Message-ID: <CAHFo0LvPsW6hAnOuzKF80u3Wizbc7VL3WSB7Ne0Um=J-he0ibg@mail.gmail.com>

Hello There!

I have an issue reading a large text file and parsing it. I would be
grateful if you let me you can help me about? Thanks.

Javad

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Wed Oct 15 20:51:42 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 15 Oct 2014 11:51:42 -0700
Subject: [R] Passing object value in command line
In-Reply-To: <CANtKHPWWbyUf=SQzdK9BDnhKYMT0OUZNh3_yEDfsnGWYda3TTw@mail.gmail.com>
References: <CANtKHPWWbyUf=SQzdK9BDnhKYMT0OUZNh3_yEDfsnGWYda3TTw@mail.gmail.com>
Message-ID: <A0B5125A-726D-4702-A9EA-2D8DDEA124A4@dcn.davis.CA.us>

There is this great document called the R Reference that comes with the software in which you can search for "command" and find the answer.

There is also a useful function called apropos that can search the help files from the R prompt. Try apropos("command").

There is also a manual for this mailing list (the Posting Guide mentioned in the footer of this message) that points out that HTML email is stripped when sent to this list, so what you see is not what we see unless you send in plain text. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 15, 2014 11:21:49 AM PDT, Abhinaba Roy <abhinabaroy09 at gmail.com> wrote:
>Hi R-helpers,
>
>I have a R script (mainCall.R) which takes the value of an object
>*'Mon'*
>as '31-may-2014' or '31-aug-2014' .
>
>How can I run the R script by passing the value of Mon from the command
>prompt?
>
>Any help will be appreciated
>
>Regards,
>Abhinaba
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From s.wood at bath.ac.uk  Wed Oct 15 21:22:50 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 15 Oct 2014 20:22:50 +0100
Subject: [R] Proportion data GAM
In-Reply-To: <CAE5HZZKWidrZC96p6Svvx2exN_2kiOj7Cx_UhFk30D9tK97XOQ@mail.gmail.com>
References: <CAE5HZZKWidrZC96p6Svvx2exN_2kiOj7Cx_UhFk30D9tK97XOQ@mail.gmail.com>
Message-ID: <543EC98A.8000201@bath.ac.uk>

Can you give the result of typing
sessionInfo()
in the session where this happens, please?

On 15/10/14 16:48, Rodrigo Tardin wrote:
> Hi all,
>
> I am not sure if this is the right place for this question or if there is
> one more specific.
> Anyway, I hope somebody can help me.
>
> I am trying to run a GAM with beta distribution from mgcv package.
> My dependent variable is a proportion continuously ranging from 0 to 1
> (whales density) and I have three co-variates Depth, Distance to Coast and
> Seabed Slope.
>
>>From what I read, beta distribution is the most appropriate for my response
> variable and not binomial.
> According to mgcv manual, it is possible to specify beta distribution on a
> GAM with the "betar" function, but I get the following error:
> could not find function "betar"
>
> My code is:
> library(mgcv)
> a2=gam(Density~s(DEPTH,k=4)+s(DISTCOAST_1,k=4)+s(SLOPE,k=4),
> family=betar(link="logit"),data=misti,gamma=1.4)
>
> The beta family is specified exactly as it is shown in the manual:
> bm <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=betar(link="logit"),data=dat)
>
> Does anyone know what it seems to be the problem?
> Thanks in advance,
> Rodrigo
>
>
> Rodrigo Tardin
>
> Shor Term Scholar - Duke Marine Lab. - Duke University
> Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
> M.Sc em Biologia Animal - PPGBA - UFRRJ
> Especialista em Doc?ncia do Ensino Superior - IAVM
> Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From s.wood at bath.ac.uk  Wed Oct 15 21:42:34 2014
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 15 Oct 2014 20:42:34 +0100
Subject: [R] Proportion data GAM
In-Reply-To: <CAE5HZZJm1ZoEPckWA97rq2kpgGeQpcN7__b3nopTVp23DbMLVw@mail.gmail.com>
References: <CAE5HZZKWidrZC96p6Svvx2exN_2kiOj7Cx_UhFk30D9tK97XOQ@mail.gmail.com>
	<543EC98A.8000201@bath.ac.uk>
	<CAE5HZZJm1ZoEPckWA97rq2kpgGeQpcN7__b3nopTVp23DbMLVw@mail.gmail.com>
Message-ID: <543ECE2A.3080205@bath.ac.uk>

Rodrigo,

OK, it looks as if your mgcv help files/manual are somehow out of sync 
with the package version you have loaded. 'betar' is only available from 
mgcv 1.8. If you update to the current mgcv from CRAN then this problem 
should be solved.

best,
Simon

ps. beta regression is only available with REML (or ML) smoothness 
selection in mgcv, so the 'gamma' parameter will be ignored.

pps. Do you really want to limit all your smooths to a maximum of 3 
degrees of freedom by setting k=?. I'd be inclined to allow the 
smoothing parameter selection do its thing with a higher k, and only get 
really restrictive on k if the resulting models somehow don't make sense.

On 15/10/14 20:34, Rodrigo Tardin wrote:
> Hi Simon,
>
> The result of sessionInfo() is:
> R version 3.1.0 (2014-04-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
> [5] LC_TIME=Portuguese_Brazil.1252
>
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods
>    base
>
> other attached packages:
> [1] gamlss_4.3-1      gamlss.dist_4.3-1 MASS_7.3-31
> gamlss.data_4.2-7 MuMIn_1.10.0
> [6] ggplot2_1.0.0     mgcv_1.7-29       nlme_3.1-117      betareg_3.0-5
>
> loaded via a namespace (and not attached):
>   [1] colorspace_1.2-4  digest_0.6.4      flexmix_2.3-12    Formula_1.1-2
>   [5] grid_3.1.0        gtable_0.1.2      lattice_0.20-29   lmtest_0.9-33
>   [9] Matrix_1.1-3      modeltools_0.2-21 munsell_0.4.2     nnet_7.3-8
> [13] plyr_1.8.1        proto_0.3-10      Rcpp_0.11.2       reshape2_1.4
> [17] sandwich_2.3-1    scales_0.2.4      stats4_3.1.0      stringr_0.6.2
> [21] survival_2.37-7   tools_3.1.0       zoo_1.7-11
>
> Is this that you were asking or the sessionInfo() of the code (it would
> be sessionInfo(a2))?
>
> If it is the sessionInfo(a2) the result is:
> Error in if (pkg == "base") file.path(.Library, "base") else if (pkg
> %in%  :
>    missing value where TRUE/FALSE needed
> In addition: There were 50 or more warnings (use warnings() to see the
> first 50)
>
> Thanks
>
> Rodrigo Tardin
>
> Shor Term Scholar - Duke Marine Lab. - Duke University
> Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
> M.Sc em Biologia Animal - PPGBA - UFRRJ
> Especialista em Doc?ncia do Ensino Superior - IAVM
> Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA
>
> 2014-10-15 15:22 GMT-04:00 Simon Wood <s.wood at bath.ac.uk
> <mailto:s.wood at bath.ac.uk>>:
>
>     Can you give the result of typing
>     sessionInfo()
>     in the session where this happens, please?
>
>
>     On 15/10/14 16:48, Rodrigo Tardin wrote:
>
>         Hi all,
>
>         I am not sure if this is the right place for this question or if
>         there is
>         one more specific.
>         Anyway, I hope somebody can help me.
>
>         I am trying to run a GAM with beta distribution from mgcv package.
>         My dependent variable is a proportion continuously ranging from
>         0 to 1
>         (whales density) and I have three co-variates Depth, Distance to
>         Coast and
>         Seabed Slope.
>
>              From what I read, beta distribution is the most appropriate
>             for my response
>
>         variable and not binomial.
>         According to mgcv manual, it is possible to specify beta
>         distribution on a
>         GAM with the "betar" function, but I get the following error:
>         could not find function "betar"
>
>         My code is:
>         library(mgcv)
>         a2=gam(Density~s(DEPTH,k=4)+s(__DISTCOAST_1,k=4)+s(SLOPE,k=4),
>         family=betar(link="logit"),__data=misti,gamma=1.4)
>
>         The beta family is specified exactly as it is shown in the manual:
>         bm <-
>         gam(y~s(x0)+s(x1)+s(x2)+s(x3),__family=betar(link="logit"),__data=dat)
>
>         Does anyone know what it seems to be the problem?
>         Thanks in advance,
>         Rodrigo
>
>
>         Rodrigo Tardin
>
>         Shor Term Scholar - Duke Marine Lab. - Duke University
>         Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
>         M.Sc em Biologia Animal - PPGBA - UFRRJ
>         Especialista em Doc?ncia do Ensino Superior - IAVM
>         Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA
>
>                  [[alternative HTML version deleted]]
>
>
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     --
>     Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
>     +44 (0)1225 386603 <tel:%2B44%20%280%291225%20386603>
>     http://people.bath.ac.uk/sw283
>
>     ________________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/__listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/__posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From rhtardin at gmail.com  Wed Oct 15 21:34:07 2014
From: rhtardin at gmail.com (Rodrigo Tardin)
Date: Wed, 15 Oct 2014 15:34:07 -0400
Subject: [R] Proportion data GAM
In-Reply-To: <543EC98A.8000201@bath.ac.uk>
References: <CAE5HZZKWidrZC96p6Svvx2exN_2kiOj7Cx_UhFk30D9tK97XOQ@mail.gmail.com>
	<543EC98A.8000201@bath.ac.uk>
Message-ID: <CAE5HZZJm1ZoEPckWA97rq2kpgGeQpcN7__b3nopTVp23DbMLVw@mail.gmail.com>

Hi Simon,

The result of sessionInfo() is:
R version 3.1.0 (2014-04-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
[3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
[5] LC_TIME=Portuguese_Brazil.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
base

other attached packages:
[1] gamlss_4.3-1      gamlss.dist_4.3-1 MASS_7.3-31       gamlss.data_4.2-7
MuMIn_1.10.0
[6] ggplot2_1.0.0     mgcv_1.7-29       nlme_3.1-117      betareg_3.0-5

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4  digest_0.6.4      flexmix_2.3-12    Formula_1.1-2
 [5] grid_3.1.0        gtable_0.1.2      lattice_0.20-29   lmtest_0.9-33
 [9] Matrix_1.1-3      modeltools_0.2-21 munsell_0.4.2     nnet_7.3-8
[13] plyr_1.8.1        proto_0.3-10      Rcpp_0.11.2       reshape2_1.4
[17] sandwich_2.3-1    scales_0.2.4      stats4_3.1.0      stringr_0.6.2
[21] survival_2.37-7   tools_3.1.0       zoo_1.7-11

Is this that you were asking or the sessionInfo() of the code (it would be
sessionInfo(a2))?

If it is the sessionInfo(a2) the result is:
Error in if (pkg == "base") file.path(.Library, "base") else if (pkg %in%
 :
  missing value where TRUE/FALSE needed
In addition: There were 50 or more warnings (use warnings() to see the
first 50)

Thanks

Rodrigo Tardin

Shor Term Scholar - Duke Marine Lab. - Duke University
Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
M.Sc em Biologia Animal - PPGBA - UFRRJ
Especialista em Doc?ncia do Ensino Superior - IAVM
Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA

2014-10-15 15:22 GMT-04:00 Simon Wood <s.wood at bath.ac.uk>:

> Can you give the result of typing
> sessionInfo()
> in the session where this happens, please?
>
>
> On 15/10/14 16:48, Rodrigo Tardin wrote:
>
>> Hi all,
>>
>> I am not sure if this is the right place for this question or if there is
>> one more specific.
>> Anyway, I hope somebody can help me.
>>
>> I am trying to run a GAM with beta distribution from mgcv package.
>> My dependent variable is a proportion continuously ranging from 0 to 1
>> (whales density) and I have three co-variates Depth, Distance to Coast and
>> Seabed Slope.
>>
>>  From what I read, beta distribution is the most appropriate for my
>>> response
>>>
>> variable and not binomial.
>> According to mgcv manual, it is possible to specify beta distribution on a
>> GAM with the "betar" function, but I get the following error:
>> could not find function "betar"
>>
>> My code is:
>> library(mgcv)
>> a2=gam(Density~s(DEPTH,k=4)+s(DISTCOAST_1,k=4)+s(SLOPE,k=4),
>> family=betar(link="logit"),data=misti,gamma=1.4)
>>
>> The beta family is specified exactly as it is shown in the manual:
>> bm <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),family=betar(link="logit"),data=dat)
>>
>> Does anyone know what it seems to be the problem?
>> Thanks in advance,
>> Rodrigo
>>
>>
>> Rodrigo Tardin
>>
>> Shor Term Scholar - Duke Marine Lab. - Duke University
>> Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
>> M.Sc em Biologia Animal - PPGBA - UFRRJ
>> Especialista em Doc?ncia do Ensino Superior - IAVM
>> Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA
>>
>>         [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> --
> Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
> +44 (0)1225 386603               http://people.bath.ac.uk/sw283
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rhtardin at gmail.com  Wed Oct 15 22:20:36 2014
From: rhtardin at gmail.com (Rodrigo Tardin)
Date: Wed, 15 Oct 2014 16:20:36 -0400
Subject: [R] Proportion data GAM
In-Reply-To: <543ECE2A.3080205@bath.ac.uk>
References: <CAE5HZZKWidrZC96p6Svvx2exN_2kiOj7Cx_UhFk30D9tK97XOQ@mail.gmail.com>
	<543EC98A.8000201@bath.ac.uk>
	<CAE5HZZJm1ZoEPckWA97rq2kpgGeQpcN7__b3nopTVp23DbMLVw@mail.gmail.com>
	<543ECE2A.3080205@bath.ac.uk>
Message-ID: <CAE5HZZJYBC5Fb7JnJVdkiSStD1jYu2kXTS=KDEirsWEKtTz4Vw@mail.gmail.com>

Thanks Simon!

That worked!
I did not constrain my k as you suggested, but when I saw my results, my
degrees of freedom are not larger than 1, the REML is negative and all
covariates are not significant (what it does not make sense). Is there
something wrong?

Here's the results of summary (a2)

Family: Beta regression(76.885)
Link function: logit

Formula:
MDENS1 ~ s(DEPTH2) + s(DISTCOAST_1) + s(DIST_DIVE) + s(TOUR)

Parametric coefficients:
            Estimate Std. Error z value Pr(>|z|)
(Intercept)  -6.7613     0.0252  -268.3   <2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Approximate significance of smooth terms:
                 edf Ref.df Chi.sq p-value
s(DEPTH2)      1.005  1.009  0.004   0.948
s(DISTCOAST_1) 1.004  1.008  0.077   0.785
s(DIST_DIVE)   1.004  1.008  0.065   0.801
s(TOUR)        1.004  1.008  0.010   0.922

R-sq.(adj) =  -0.00255   Deviance explained = 11.7%
-REML = -19521  Scale est. = 1         n = 1560

Thanks a lot one more time!

Rodrigo Tardin

Shor Term Scholar - Duke Marine Lab. - Duke University
Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
M.Sc em Biologia Animal - PPGBA - UFRRJ
Especialista em Doc?ncia do Ensino Superior - IAVM
Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA

2014-10-15 15:42 GMT-04:00 Simon Wood <s.wood at bath.ac.uk>:

> Rodrigo,
>
> OK, it looks as if your mgcv help files/manual are somehow out of sync
> with the package version you have loaded. 'betar' is only available from
> mgcv 1.8. If you update to the current mgcv from CRAN then this problem
> should be solved.
>
> best,
> Simon
>
> ps. beta regression is only available with REML (or ML) smoothness
> selection in mgcv, so the 'gamma' parameter will be ignored.
>
> pps. Do you really want to limit all your smooths to a maximum of 3
> degrees of freedom by setting k=?. I'd be inclined to allow the smoothing
> parameter selection do its thing with a higher k, and only get really
> restrictive on k if the resulting models somehow don't make sense.
>
>
> On 15/10/14 20:34, Rodrigo Tardin wrote:
>
>> Hi Simon,
>>
>> The result of sessionInfo() is:
>> R version 3.1.0 (2014-04-10)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=Portuguese_Brazil.1252  LC_CTYPE=Portuguese_Brazil.1252
>> [3] LC_MONETARY=Portuguese_Brazil.1252 LC_NUMERIC=C
>> [5] LC_TIME=Portuguese_Brazil.1252
>>
>> attached base packages:
>> [1] splines   stats     graphics  grDevices utils     datasets  methods
>>    base
>>
>> other attached packages:
>> [1] gamlss_4.3-1      gamlss.dist_4.3-1 MASS_7.3-31
>> gamlss.data_4.2-7 MuMIn_1.10.0
>> [6] ggplot2_1.0.0     mgcv_1.7-29       nlme_3.1-117      betareg_3.0-5
>>
>> loaded via a namespace (and not attached):
>>   [1] colorspace_1.2-4  digest_0.6.4      flexmix_2.3-12    Formula_1.1-2
>>   [5] grid_3.1.0        gtable_0.1.2      lattice_0.20-29   lmtest_0.9-33
>>   [9] Matrix_1.1-3      modeltools_0.2-21 munsell_0.4.2     nnet_7.3-8
>> [13] plyr_1.8.1        proto_0.3-10      Rcpp_0.11.2       reshape2_1.4
>> [17] sandwich_2.3-1    scales_0.2.4      stats4_3.1.0      stringr_0.6.2
>> [21] survival_2.37-7   tools_3.1.0       zoo_1.7-11
>>
>> Is this that you were asking or the sessionInfo() of the code (it would
>> be sessionInfo(a2))?
>>
>> If it is the sessionInfo(a2) the result is:
>> Error in if (pkg == "base") file.path(.Library, "base") else if (pkg
>> %in%  :
>>    missing value where TRUE/FALSE needed
>> In addition: There were 50 or more warnings (use warnings() to see the
>> first 50)
>>
>> Thanks
>>
>> Rodrigo Tardin
>>
>> Shor Term Scholar - Duke Marine Lab. - Duke University
>> Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
>> M.Sc em Biologia Animal - PPGBA - UFRRJ
>> Especialista em Doc?ncia do Ensino Superior - IAVM
>> Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA
>>
>> 2014-10-15 15:22 GMT-04:00 Simon Wood <s.wood at bath.ac.uk
>> <mailto:s.wood at bath.ac.uk>>:
>>
>>     Can you give the result of typing
>>     sessionInfo()
>>     in the session where this happens, please?
>>
>>
>>     On 15/10/14 16:48, Rodrigo Tardin wrote:
>>
>>         Hi all,
>>
>>         I am not sure if this is the right place for this question or if
>>         there is
>>         one more specific.
>>         Anyway, I hope somebody can help me.
>>
>>         I am trying to run a GAM with beta distribution from mgcv package.
>>         My dependent variable is a proportion continuously ranging from
>>         0 to 1
>>         (whales density) and I have three co-variates Depth, Distance to
>>         Coast and
>>         Seabed Slope.
>>
>>              From what I read, beta distribution is the most appropriate
>>             for my response
>>
>>         variable and not binomial.
>>         According to mgcv manual, it is possible to specify beta
>>         distribution on a
>>         GAM with the "betar" function, but I get the following error:
>>         could not find function "betar"
>>
>>         My code is:
>>         library(mgcv)
>>         a2=gam(Density~s(DEPTH,k=4)+s(__DISTCOAST_1,k=4)+s(SLOPE,k=4),
>>         family=betar(link="logit"),__data=misti,gamma=1.4)
>>
>>         The beta family is specified exactly as it is shown in the manual:
>>         bm <-
>>         gam(y~s(x0)+s(x1)+s(x2)+s(x3),__family=betar(link="logit"),_
>> _data=dat)
>>
>>         Does anyone know what it seems to be the problem?
>>         Thanks in advance,
>>         Rodrigo
>>
>>
>>         Rodrigo Tardin
>>
>>         Shor Term Scholar - Duke Marine Lab. - Duke University
>>         Doutorando em Ecologia e Evolu??o - IBRAG - UERJ
>>         M.Sc em Biologia Animal - PPGBA - UFRRJ
>>         Especialista em Doc?ncia do Ensino Superior - IAVM
>>         Laborat?rio de Bioac?stica e Ecologia de Cet?ceos - UFRRJ/ IF/ DCA
>>
>>                  [[alternative HTML version deleted]]
>>
>>
>>
>>         ________________________________________________
>>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>         https://stat.ethz.ch/mailman/__listinfo/r-help
>>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>>         PLEASE do read the posting guide
>>         http://www.R-project.org/__posting-guide.html
>>         <http://www.R-project.org/posting-guide.html>
>>         and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>     --
>>     Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
>>     +44 (0)1225 386603 <tel:%2B44%20%280%291225%20386603>
>>     http://people.bath.ac.uk/sw283
>>
>>     ________________________________________________
>>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/__listinfo/r-help
>>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>>     PLEASE do read the posting guide
>>     http://www.R-project.org/__posting-guide.html
>>     <http://www.R-project.org/posting-guide.html>
>>     and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>
> --
> Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
> +44 (0)1225 386603               http://people.bath.ac.uk/sw283
>

	[[alternative HTML version deleted]]


From honkit at stanford.edu  Wed Oct 15 22:28:24 2014
From: honkit at stanford.edu (Stephen HK Wong)
Date: Wed, 15 Oct 2014 13:28:24 -0700 (PDT)
Subject: [R] how to loop through dataframe objects in environment
Message-ID: <468080410.6714878.1413404904231.JavaMail.zimbra@stanford.edu>

Dear All,

I  have many 50 objects they are all dataframes. Each dataframe has many rows and four column. I simply want to do an addition of 3rd and 4th column and save the result into 5th column. Since there are many dataframes, I don't want to do it one by one,  is there a way to loop through all objects and perform the similar action ?

One way I can think of is like this:

for (i in 1:50){
get(ls()[i])[,3]+get(ls()[i][,4]
}

But I don't know how to save the addition result back to 5th column of each dataframe.


Many Thanks!



Stephen HK Wong


From macqueen1 at llnl.gov  Thu Oct 16 00:34:16 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 15 Oct 2014 22:34:16 +0000
Subject: [R] Passing object value in command line
In-Reply-To: <CANtKHPWWbyUf=SQzdK9BDnhKYMT0OUZNh3_yEDfsnGWYda3TTw@mail.gmail.com>
References: <CANtKHPWWbyUf=SQzdK9BDnhKYMT0OUZNh3_yEDfsnGWYda3TTw@mail.gmail.com>
Message-ID: <D0644409.10F443%macqueen1@llnl.gov>

Don?t know exactly what you mean by ?passing the value of Mon from the
command prompt?, but it could be

At the R prompt:

> Mon <- ?31-may-2014?
> source(mainCall.R)

If, on the other hand, you mean shell prompt, then within R see
  ?commandArgs

On 10/15/14, 11:21 AM, "Abhinaba Roy" <abhinabaroy09 at gmail.com> wrote:

>Hi R-helpers,
>
>I have a R script (mainCall.R) which takes the value of an object *'Mon'*
>as '31-may-2014' or '31-aug-2014' .
>
>How can I run the R script by passing the value of Mon from the command
>prompt?
>
>Any help will be appreciated
>
>Regards,
>Abhinaba
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Thu Oct 16 08:16:10 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Oct 2014 06:16:10 +0000
Subject: [R] Retrieving lists of colnames
In-Reply-To: <520F3B10-BA3A-4CFC-9A74-147F7C0BFBBB@gmail.com>
References: <520F3B10-BA3A-4CFC-9A74-147F7C0BFBBB@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA5BC@SRVEXCHMBX.precheza.cz>

Hi

First of all you shall transfer your data to R.

Maybe it can be solved by apply but in your case I would use for cycle

Let say your data frame is named doc

lll<-vector(nrow(doc), mode="list")
for(i in 1:nrow(doc)) lll[[i]]<-colnames(doc)[(which(doc[i,]>0))]

Cheers
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Adam.N.Jenkins13 at gmail.com
> Sent: Wednesday, October 15, 2014 2:24 PM
> To: r-help at r-project.org
> Subject: [R] Retrieving lists of colnames
>
>
>
> Hi what I have is a large excel doc (100 columns, 350 row) with data
> values from 0-10000. The end goal is for each row to have a list of
> colnames of which columns contain values >0. I've been tinkering around
> with apply mostly and some other functions, any help offered would be
> greatly appreciated.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Thu Oct 16 08:35:47 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Oct 2014 06:35:47 +0000
Subject: [R] HELP
In-Reply-To: <CAHFo0LvPsW6hAnOuzKF80u3Wizbc7VL3WSB7Ne0Um=J-he0ibg@mail.gmail.com>
References: <CAHFo0LvPsW6hAnOuzKF80u3Wizbc7VL3WSB7Ne0Um=J-he0ibg@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA5DB@SRVEXCHMBX.precheza.cz>

Hi

It will be even worse with age, try to contact optician :-)

If you want to get better answer you need to provide more info about your file, what you did and how it failed.

Cheers
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of JAVAD LESSAN
> Sent: Wednesday, October 15, 2014 2:53 PM
> To: r-help at r-project.org
> Subject: [R] HELP
>
> Hello There!
>
> I have an issue reading a large text file and parsing it. I would be
> grateful if you let me you can help me about? Thanks.
>
> Javad
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From vikash.kr.117 at gmail.com  Thu Oct 16 05:59:01 2014
From: vikash.kr.117 at gmail.com (Vikash Kumar)
Date: Thu, 16 Oct 2014 09:29:01 +0530
Subject: [R] how to loop through dataframe objects in environment
In-Reply-To: <468080410.6714878.1413404904231.JavaMail.zimbra@stanford.edu>
References: <468080410.6714878.1413404904231.JavaMail.zimbra@stanford.edu>
Message-ID: <CAALD-ggGTaYvKn=FNBGtUJsAKP3iKu8-6UEfT3OwJ6a2AEEktA@mail.gmail.com>

Hi Stephen,

Try out lapply(). It would help you loop through all data frames and sum.

Regards,
Vikash

On Thu, Oct 16, 2014 at 1:58 AM, Stephen HK Wong <honkit at stanford.edu>
wrote:

> Dear All,
>
> I  have many 50 objects they are all dataframes. Each dataframe has many
> rows and four column. I simply want to do an addition of 3rd and 4th column
> and save the result into 5th column. Since there are many dataframes, I
> don't want to do it one by one,  is there a way to loop through all objects
> and perform the similar action ?
>
> One way I can think of is like this:
>
> for (i in 1:50){
> get(ls()[i])[,3]+get(ls()[i][,4]
> }
>
> But I don't know how to save the addition result back to 5th column of
> each dataframe.
>
>
> Many Thanks!
>
>
>
> Stephen HK Wong
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From vikash.kr.117 at gmail.com  Thu Oct 16 07:05:55 2014
From: vikash.kr.117 at gmail.com (Vikash Kumar)
Date: Thu, 16 Oct 2014 10:35:55 +0530
Subject: [R] Retrieving lists of colnames
In-Reply-To: <520F3B10-BA3A-4CFC-9A74-147F7C0BFBBB@gmail.com>
References: <520F3B10-BA3A-4CFC-9A74-147F7C0BFBBB@gmail.com>
Message-ID: <CAALD-gg=RBgp9Zjc85+EbT+6Q4fkSzjdyNJOLZXo0RVHBY4k7A@mail.gmail.com>

Hi Adam,

I guess below code would help you achieve the desired ouput.

> colnames(data[,which(apply(data,2,FUN = function(x){any(x>0.5)}))])

Happy Learning!

Vikash

On Wed, Oct 15, 2014 at 5:53 PM, Adam.N.Jenkins13 at gmail.com <
adam.n.jenkins13 at gmail.com> wrote:

>
>
> Hi what I have is a large excel doc (100 columns, 350 row) with data
> values from 0-10000. The end goal is for each row to have a list of
> colnames of which columns contain values >0. I've been tinkering around
> with apply mostly and some other functions, any help offered would be
> greatly appreciated.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rl at openmailbox.org  Thu Oct 16 11:00:26 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Thu, 16 Oct 2014 09:00:26 +0000
Subject: [R] package installation failure virtualisation environment
In-Reply-To: <CAHuTOvqHXRuB7TtwVFXL4NfCqTS21hCMqbbFxgX78QeaPgR6bA@mail.gmail.com>
References: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
	<CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>
	<5a91706aac4e7f4b536fbdb094166737@openmailbox.org>
	<CAHuTOvqHXRuB7TtwVFXL4NfCqTS21hCMqbbFxgX78QeaPgR6bA@mail.gmail.com>
Message-ID: <3a08ac0ef13f80724d2289650d7636b7@openmailbox.org>

On 2014-10-15 09:13, Sven E. Templer wrote:
> did you check the connection in R via for example:
> 
> head(readLines("http://cran.r-project.org/web/licenses/GPL-3"))
> 
> which should yield:
> 
> [1] "                    GNU GENERAL PUBLIC LICENSE"
> [2] "                       Version 3, 29 June 2007"
> [3] ""
> [4] " Copyright (C) 2007 Free Software Foundation, Inc. 
> <http://fsf.org/>"
> [5] " Everyone is permitted to copy and distribute verbatim copies"
> [6] " of this license document, but changing it is not allowed."
> 

Yes, this result is seen.


From rl at openmailbox.org  Thu Oct 16 11:03:49 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Thu, 16 Oct 2014 09:03:49 +0000
Subject: [R] package installation failure virtualisation environment
In-Reply-To: <CAF8bMcZeJhebpC5c7L5Qcxj2eX+vBB0p5=g=Y=bmw-6AQLzhKg@mail.gmail.com>
References: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
	<CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>
	<5a91706aac4e7f4b536fbdb094166737@openmailbox.org>
	<CAF8bMcZeJhebpC5c7L5Qcxj2eX+vBB0p5=g=Y=bmw-6AQLzhKg@mail.gmail.com>
Message-ID: <39e65e879192f1b99d1821b4522df68c@openmailbox.org>

On 2014-10-15 15:36, William Dunlap wrote:
> Have you looked at recent entries in the system log files in /var/log,
> especially /var/log/kern.log?

No such log file exist and other files in the directory do not make 
reference to R and any general errors (e.g. internet access).


From petr.pikal at precheza.cz  Thu Oct 16 11:56:12 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 16 Oct 2014 09:56:12 +0000
Subject: [R] Retrieving lists of colnames
In-Reply-To: <CAALD-gg=RBgp9Zjc85+EbT+6Q4fkSzjdyNJOLZXo0RVHBY4k7A@mail.gmail.com>
References: <520F3B10-BA3A-4CFC-9A74-147F7C0BFBBB@gmail.com>
	<CAALD-gg=RBgp9Zjc85+EbT+6Q4fkSzjdyNJOLZXo0RVHBY4k7A@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA6D8@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Vikash Kumar
> Sent: Thursday, October 16, 2014 7:06 AM
> To: Adam.N.Jenkins13 at gmail.com
> Cc: r-help at r-project.org
> Subject: Re: [R] Retrieving lists of colnames
>
> Hi Adam,
>
> I guess below code would help you achieve the desired ouput.
>
> > colnames(data[,which(apply(data,2,FUN = function(x){any(x>0.5)}))])

I do not think so. It will give you overall names but not names for each row, which as I understand Adam needs.

Try

> data<-data.frame(embed(1:12,2))
> data<6
         X1    X2
 [1,]  TRUE  TRUE
 [2,]  TRUE  TRUE
 [3,]  TRUE  TRUE
 [4,]  TRUE  TRUE
 [5,] FALSE  TRUE
 [6,] FALSE FALSE
 [7,] FALSE FALSE
 [8,] FALSE FALSE
 [9,] FALSE FALSE
[10,] FALSE FALSE
[11,] FALSE FALSE

> colnames(data[,which(apply(data,2,FUN = function(x){any(x<6)}))])
[1] "X1" "X2"


> lll<-vector(nrow(data), mode="list")
> for(i in 1:nrow(data)) lll[[i]]<-colnames(data)[(which(data[i,]<6))]
> lll
[[1]]
[1] "X1" "X2"

[[2]]
[1] "X1" "X2"

[[3]]
[1] "X1" "X2"

[[4]]
[1] "X1" "X2"

[[5]]
[1] "X2"

[[6]]
character(0)

[[7]]
character(0)

[[8]]
character(0)

[[9]]
character(0)

[[10]]
character(0)

[[11]]
character(0)


Cheers
Petr


>
> Happy Learning!
>
> Vikash
>
> On Wed, Oct 15, 2014 at 5:53 PM, Adam.N.Jenkins13 at gmail.com <
> adam.n.jenkins13 at gmail.com> wrote:
>
> >
> >
> > Hi what I have is a large excel doc (100 columns, 350 row) with data
> > values from 0-10000. The end goal is for each row to have a list of
> > colnames of which columns contain values >0. I've been tinkering
> > around with apply mostly and some other functions, any help offered
> > would be greatly appreciated.
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From jdnewmil at dcn.davis.CA.us  Thu Oct 16 12:47:23 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 16 Oct 2014 03:47:23 -0700
Subject: [R] how to loop through dataframe objects in environment
In-Reply-To: <CAALD-ggGTaYvKn=FNBGtUJsAKP3iKu8-6UEfT3OwJ6a2AEEktA@mail.gmail.com>
References: <468080410.6714878.1413404904231.JavaMail.zimbra@stanford.edu>
	<CAALD-ggGTaYvKn=FNBGtUJsAKP3iKu8-6UEfT3OwJ6a2AEEktA@mail.gmail.com>
Message-ID: <06501A0B-91FC-4118-BBB5-E3A7B6CB9148@dcn.davis.CA.us>

This advice works best when you use the lapply function to load your data frames to begin with. That way your like-structured data frames are grouped into one list that you can loop through without complicated use of get and assign.

dtadir <- "mydatadir"
fnames <- list.files( dtadir )
dtalist <- lapply( fnames, function( fn ) { read.csv( file.path( dtadir, fn ) ) }
for ( idx in seq_along( dtalist ) ) {
  dtalist[[ idx]]$result <- dtalist[[ idx ]][ , 3 ] + dtalist[[ idx ]][ , 4 ]
}

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 15, 2014 8:59:01 PM PDT, Vikash Kumar <vikash.kr.117 at gmail.com> wrote:
>Hi Stephen,
>
>Try out lapply(). It would help you loop through all data frames and
>sum.
>
>Regards,
>Vikash
>
>On Thu, Oct 16, 2014 at 1:58 AM, Stephen HK Wong <honkit at stanford.edu>
>wrote:
>
>> Dear All,
>>
>> I  have many 50 objects they are all dataframes. Each dataframe has
>many
>> rows and four column. I simply want to do an addition of 3rd and 4th
>column
>> and save the result into 5th column. Since there are many dataframes,
>I
>> don't want to do it one by one,  is there a way to loop through all
>objects
>> and perform the similar action ?
>>
>> One way I can think of is like this:
>>
>> for (i in 1:50){
>> get(ls()[i])[,3]+get(ls()[i][,4]
>> }
>>
>> But I don't know how to save the addition result back to 5th column
>of
>> each dataframe.
>>
>>
>> Many Thanks!
>>
>>
>>
>> Stephen HK Wong
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From vikash.kr.117 at gmail.com  Thu Oct 16 12:11:42 2014
From: vikash.kr.117 at gmail.com (Vikash Kumar)
Date: Thu, 16 Oct 2014 15:41:42 +0530
Subject: [R] Retrieving lists of colnames
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA6D8@SRVEXCHMBX.precheza.cz>
References: <520F3B10-BA3A-4CFC-9A74-147F7C0BFBBB@gmail.com>
	<CAALD-gg=RBgp9Zjc85+EbT+6Q4fkSzjdyNJOLZXo0RVHBY4k7A@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA6D8@SRVEXCHMBX.precheza.cz>
Message-ID: <CAALD-gibTmH0CAjq-b54ixLJt61C_xyH8+ki1=Kqaq=z_1n=Wg@mail.gmail.com>

Hi, It works! Only one thing we need to note is when we have only one
column name as an output we do not get the results.


> d=c(11:21)
> e=c(51:61)
> data<-data.frame(embed(1:12,2))
> data=cbind(data,d,e)
> data>6
         X1          X2          d     e
 [1,] FALSE FALSE TRUE TRUE
 [2,] FALSE FALSE TRUE TRUE
 [3,] FALSE FALSE TRUE TRUE
 [4,] FALSE FALSE TRUE TRUE
 [5,] FALSE FALSE TRUE TRUE
 [6,]  TRUE FALSE TRUE TRUE
 [7,]  TRUE  TRUE TRUE TRUE
 [8,]  TRUE  TRUE TRUE TRUE
 [9,]  TRUE  TRUE TRUE TRUE
[10,]  TRUE  TRUE TRUE TRUE
[11,]  TRUE  TRUE TRUE TRUE
> data<-data.frame(data)
*> names(data[,which(apply(data,2,FUN = function(x){all(x>6)}))])*
[1] "d" "e"

Thanks


On Thu, Oct 16, 2014 at 3:26 PM, PIKAL Petr <petr.pikal at precheza.cz> wrote:

> Hi
>
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of Vikash Kumar
> > Sent: Thursday, October 16, 2014 7:06 AM
> > To: Adam.N.Jenkins13 at gmail.com
> > Cc: r-help at r-project.org
> > Subject: Re: [R] Retrieving lists of colnames
> >
> > Hi Adam,
> >
> > I guess below code would help you achieve the desired ouput.
> >
> > > colnames(data[,which(apply(data,2,FUN = function(x){any(x>0.5)}))])
>
> I do not think so. It will give you overall names but not names for each
> row, which as I understand Adam needs.
>
> Try
>
> > data<-data.frame(embed(1:12,2))
> > data<6
>          X1    X2
>  [1,]  TRUE  TRUE
>  [2,]  TRUE  TRUE
>  [3,]  TRUE  TRUE
>  [4,]  TRUE  TRUE
>  [5,] FALSE  TRUE
>  [6,] FALSE FALSE
>  [7,] FALSE FALSE
>  [8,] FALSE FALSE
>  [9,] FALSE FALSE
> [10,] FALSE FALSE
> [11,] FALSE FALSE
>
> > colnames(data[,which(apply(data,2,FUN = function(x){any(x<6)}))])
> [1] "X1" "X2"
>
>
> > lll<-vector(nrow(data), mode="list")
> > for(i in 1:nrow(data)) lll[[i]]<-colnames(data)[(which(data[i,]<6))]
> > lll
> [[1]]
> [1] "X1" "X2"
>
> [[2]]
> [1] "X1" "X2"
>
> [[3]]
> [1] "X1" "X2"
>
> [[4]]
> [1] "X1" "X2"
>
> [[5]]
> [1] "X2"
>
> [[6]]
> character(0)
>
> [[7]]
> character(0)
>
> [[8]]
> character(0)
>
> [[9]]
> character(0)
>
> [[10]]
> character(0)
>
> [[11]]
> character(0)
>
>
> Cheers
> Petr
>
>
> >
> > Happy Learning!
> >
> > Vikash
> >
> > On Wed, Oct 15, 2014 at 5:53 PM, Adam.N.Jenkins13 at gmail.com <
> > adam.n.jenkins13 at gmail.com> wrote:
> >
> > >
> > >
> > > Hi what I have is a large excel doc (100 columns, 350 row) with data
> > > values from 0-10000. The end goal is for each row to have a list of
> > > colnames of which columns contain values >0. I've been tinkering
> > > around with apply mostly and some other functions, any help offered
> > > would be greatly appreciated.
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie
> vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email
> jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
> ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout;
> Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany
> p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n
> nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto
> emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich
> existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are
> intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a
> contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer) excludes
> any acceptance of the offer on the part of the recipient containing any
> amendment or variation.
> - the sender insists on that the respective contract is concluded only
> upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter
> into any contracts on behalf of the company except for cases in which
> he/she is expressly authorized to do so in writing, and such authorization
> or power of attorney is submitted to the recipient or the person
> represented by the recipient, or the existence of such authorization is
> known to the recipient of the person represented by the recipient.
>

	[[alternative HTML version deleted]]


From oehm8895 at uni-landau.de  Thu Oct 16 13:00:25 2014
From: oehm8895 at uni-landau.de (Gunnar Oehmichen)
Date: Thu, 16 Oct 2014 13:00:25 +0200
Subject: [R] ggplot: Stacked bar/pie chart - Objects above the bar/pie
Message-ID: <543FA549.2010702@uni-landau.de>

Hello,

I would like to draw a circle on top of a pie chart (The plot does not
need to fullfill scientific standards). The circle represents the
relation of a reference-value in comparison to the summed values of the
pie-pieces. To be able to do this I partly followed:
http://rpubs.com/RobinLovelace/11641 . But i have the problem of some
bar/pie pieces being placed above the stacked bar/outside of the pie
chart, see graph PA / PA + coord_polar.

System: $platform [1] "i686-pc-linux-gnu"; $version.string [1] "R
version 3.1.1 (2014-07-10)"; ggplot2_0.9.3.1

####

require (ggplot2)

mdf <- structure(list(
  VG = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L),
                 .Label = c("A", "B"), class = "factor"),
  variable = structure(c(4L, 3L, 5L, 1L, 2L, 1L, 4L, 3L, 2L, 5L),
                       .Label = c("a", "b", "c",  "d", "e"), class =
"factor"),
  value = c(0, 8407346.56, 0, 124901773, 0, 184987520, 14612608,
3165030, 0, 0),
  reference = c(0.75, 0.75, 0.75, 0.75, 0.75, 1.25, 1.25, 1.25, 1.25,
1.25)),
  .Names = c("VG", "variable", "value", "reference"),
  row.names = c(16L, 17L, 18L,   19L, 20L, 46L, 47L, 48L, 49L, 50L),
class = "data.frame")

# Calculate position
pos <- function (x) 0.5 * (cumsum(x) + cumsum(c(0, x[-length(x)])))
lmdf <- dlply (mdf, "VG")
lmdf <- lapply (lmdf, function (X) { X$pos <- pos (X$value)
                             return (X) })
mdf <- rbind.data.frame (lmdf[[1]], lmdf[[2]])

# height (radius) of all pieces (variable) in one bar (pie) will be the
same:
mdf$rad <- 1

# abline from the reference column in the dataframe
INTCA <- unique (mdf$reference[mdf$VG=="A"])
PA <- ggplot (mdf[mdf$VG=="A",], aes (x = pos, y = rad)) +
  geom_bar (stat = "identity", aes (fill = variable, width = value)) +
  geom_abline(intercept = INTCA, slope = 0)

PA
PA + coord_polar()
# Object c is placed above its position on the y axis

# abline from the reference column in the dataframe
INTCB <- unique (mdf$reference[mdf$VG=="B"])
PB <- ggplot (mdf[mdf$VG=="B",], aes (x = pos, y = rad)) +
  geom_bar (stat = "identity", aes (fill = variable, width = value)) +
  geom_abline(intercept = INTCB, slope = 0)

PB
PB + coord_polar()
# all objects are within rad = 1

###

Your help would be very much appreciated,

Gunnar


From Ray.Liu at takeda.com  Thu Oct 16 15:00:11 2014
From: Ray.Liu at takeda.com (Liu, Ray)
Date: Thu, 16 Oct 2014 13:00:11 +0000
Subject: [R] Job Opening - PhD Discovery Statistician at Cambridge, MA
Message-ID: <501F96C104F3F84B8F7EB3F299A1647FB938A617@EX10-MBX02PRD.corp.mpi.com>

To all:

We have an immediate opening for one PhD statistician in the Analytical Innovation and Consultation group at Cambridge MA site. This group provides statistical project support and consultation services to Takeda's discovery, manufacturing, translational research, phase I clinical trial and outcome research areas. The person will work primary with discovery and CMC scientists, with the option to work on other areas. This is a perfect position for the person who enjoys learning science, promoting quantitative thinking and developing novel methodology. If you are interested in more details about this position, please send inquiries directly to ray.liu at takeda.com . Thanks.


________________________________

This e-mail, including any attachments, is a confidential business communication, and may contain information that is confidential, proprietary and/or privileged. This e-mail is intended only for the individual(s) to whom it is addressed, and may not be saved, copied, printed, disclosed or used by anyone else. If you are not the(an) intended recipient, please immediately delete this e-mail from your computer system and notify the sender. Thank you.


From wdunlap at tibco.com  Thu Oct 16 17:52:16 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 16 Oct 2014 08:52:16 -0700
Subject: [R] package installation failure virtualisation environment
In-Reply-To: <39e65e879192f1b99d1821b4522df68c@openmailbox.org>
References: <a9fc73b1e241e833dd1e8f84a61e6d02@openmailbox.org>
	<CAHuTOvpbSCHenVnPvb5wqVsFyG5ms1vycbq=jTHAERbaTWvJAg@mail.gmail.com>
	<5a91706aac4e7f4b536fbdb094166737@openmailbox.org>
	<CAF8bMcZeJhebpC5c7L5Qcxj2eX+vBB0p5=g=Y=bmw-6AQLzhKg@mail.gmail.com>
	<39e65e879192f1b99d1821b4522df68c@openmailbox.org>
Message-ID: <CAF8bMcZ2B2eiwviBubu4krXJ6rVnPeGbFmqP6f2sk8ZfBymkJw@mail.gmail.com>

The log files may not have the name of the process ("R"), but only its
process number.  A good way to look at the log files in /var/log is to
cause your 'Kill' problem then use 'ls -lstA' or 'ls -lstrA' in
/var/log to see which ones changed recently.
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Oct 16, 2014 at 2:03 AM,  <rl at openmailbox.org> wrote:
> On 2014-10-15 15:36, William Dunlap wrote:
>>
>> Have you looked at recent entries in the system log files in /var/log,
>> especially /var/log/kern.log?
>
>
> No such log file exist and other files in the directory do not make
> reference to R and any general errors (e.g. internet access).


From fabian_schlegel at hotmail.com  Thu Oct 16 17:51:47 2014
From: fabian_schlegel at hotmail.com (moeby)
Date: Thu, 16 Oct 2014 08:51:47 -0700 (PDT)
Subject: [R] Help for i-else iwth more than one alternative
Message-ID: <DUB124-W10423113091DECAB736FF48CAB0@phx.gbl>

I try to run an if-else command line where the else argument should be the
corresponding value of the pmax command.

#####################
#opt.fc is the optimal forecast
#rmax is the vector of the maximized r squared from pmax-command of 2 data
sets containing r squares 
#fc1 are the estimates of a specific forecast model (e.g. AR1)
#fc are the estimates of a specific forecast model, namely the Benchmark
(e.g. mean)

opt.fc <- as.numeric(373) #data length is 373
for (x in 1:373)
{
if (rmax[x] < 0.1)
opt.fc[x] <- fc[x] #if rmax smaller than the value 0.1 the forecast of the
benchmark should be used.
else
opt.fc[x] <- fc1[x] #else the forecast of fc model should be used.
}
So far, so easy.

How can I compute the opt.fc when I have more than one alternative forecast
model, let's say fc2 and fc3. 
In Addition, I want to use the values from the forecast model where the
values of the corresponding r squared are maxed (pmax(fcr1,fcr2,fcr3...)
..... :(

any ideas?
 
Thank you very much in advance.
 
 		 	   		  



--
View this message in context: http://r.789695.n4.nabble.com/Help-for-i-else-iwth-more-than-one-alternative-tp4698410.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From bartjoosen at hotmail.com  Thu Oct 16 20:12:53 2014
From: bartjoosen at hotmail.com (Bart Joosen)
Date: Thu, 16 Oct 2014 18:12:53 +0000
Subject: [R] Time outside limits
Message-ID: <SNT151-W6422FACA8096C8244938BD8AB0@phx.gbl>

Hi,
I'm currently facing the problem that I need to write a function where I get a dataframe back which contains the time (in hours) outside the limits of a temperature sensor, each month, and for how long exactly.
I wrote a for loop which check:- if a datapoint is outside the limit- if the previous datapoint is outside the limt, then count + 1- if the next datapoint isn't outside: write in dataframe.
I guess this could be with some vectorisation function, I tried with seq_along, and match, but couldn't figure it out.
Here some sample data:
y <- c(rnorm(10,25), rnorm(10,32),rnorm(10,25), rnorm(10,20), rnorm(10,25))x <- seq(c(ISOdate(2000,3,20)), by = "hour", length.out = length(y))
limits of y: c(22,27)
Thanks
Bart 		 	   		  
	[[alternative HTML version deleted]]


From daniel319 at gmail.com  Thu Oct 16 20:44:58 2014
From: daniel319 at gmail.com (daniel)
Date: Thu, 16 Oct 2014 15:44:58 -0300
Subject: [R] Time outside limits
In-Reply-To: <SNT151-W6422FACA8096C8244938BD8AB0@phx.gbl>
References: <SNT151-W6422FACA8096C8244938BD8AB0@phx.gbl>
Message-ID: <CAPfrkhmJAj=c66HG4dPBJ9hjgdjN6-v0uvzXcFgpyCnH+BC3Pg@mail.gmail.com>

Bart,

Check if the following could help you.

library(xts)
y <- c(rnorm(10,25), rnorm(10,32),rnorm(10,25), rnorm(10,20),
rnorm(10,25)); x <- seq(c(ISOdate(2000,3,20)), by = "hour", length.out =
length(y))
z <- xts( y, order.by=as.POSIXct(x))
limit <- ifelse( lag(z) < 22 | z > 27, 1, 0)


Daniel Merino

2014-10-16 15:12 GMT-03:00 Bart Joosen <bartjoosen at hotmail.com>:

> Hi,
> I'm currently facing the problem that I need to write a function where I
> get a dataframe back which contains the time (in hours) outside the limits
> of a temperature sensor, each month, and for how long exactly.
> I wrote a for loop which check:- if a datapoint is outside the limit- if
> the previous datapoint is outside the limt, then count + 1- if the next
> datapoint isn't outside: write in dataframe.
> I guess this could be with some vectorisation function, I tried with
> seq_along, and match, but couldn't figure it out.
> Here some sample data:
> y <- c(rnorm(10,25), rnorm(10,32),rnorm(10,25), rnorm(10,20),
> rnorm(10,25))x <- seq(c(ISOdate(2000,3,20)), by = "hour", length.out =
> length(y))
> limits of y: c(22,27)
> Thanks
> Bart
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Daniel

	[[alternative HTML version deleted]]


From macqueen1 at llnl.gov  Thu Oct 16 21:09:39 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 16 Oct 2014 19:09:39 +0000
Subject: [R] Help for i-else iwth more than one alternative
In-Reply-To: <DUB124-W10423113091DECAB736FF48CAB0@phx.gbl>
References: <DUB124-W10423113091DECAB736FF48CAB0@phx.gbl>
Message-ID: <D065629D.10F5C9%macqueen1@llnl.gov>

If I understand what you?re trying to do, then I believe this will do the
same as your little loop:

  opt.fc <- fc
  opt.fc[rmax < 0.1] <- fc1[rmax < 0.1]

(this is an example of vectorization, and it?s fundamental to how R works
and the power of R)

Then to extend it, use the same method

  opt.fx[ {some expression} ] <- fc2[ {some expression} ]

But I have no idea what {some expression} should be. Perhaps it has
something to do with the maximized r squared values, but I can?t tell from
what you?ve said. In any case, the {some expression} has to result in a
logical vector of the same length as the others (373 in your example).

Hope this helps.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/16/14, 8:51 AM, "moeby" <fabian_schlegel at hotmail.com> wrote:

>I try to run an if-else command line where the else argument should be the
>corresponding value of the pmax command.
>
>#####################
>#opt.fc is the optimal forecast
>#rmax is the vector of the maximized r squared from pmax-command of 2 data
>sets containing r squares
>#fc1 are the estimates of a specific forecast model (e.g. AR1)
>#fc are the estimates of a specific forecast model, namely the Benchmark
>(e.g. mean)
>
>opt.fc <- as.numeric(373) #data length is 373
>for (x in 1:373)
>{
>if (rmax[x] < 0.1)
>opt.fc[x] <- fc[x] #if rmax smaller than the value 0.1 the forecast of the
>benchmark should be used.
>else
>opt.fc[x] <- fc1[x] #else the forecast of fc model should be used.
>}
>So far, so easy.
>
>How can I compute the opt.fc when I have more than one alternative
>forecast
>model, let's say fc2 and fc3.
>In Addition, I want to use the values from the forecast model where the
>values of the corresponding r squared are maxed (pmax(fcr1,fcr2,fcr3...)
>..... :(
>
>any ideas?
> 
>Thank you very much in advance.
> 
> 		 	   		  
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Help-for-i-else-iwth-more-than-one-alternati
>ve-tp4698410.html
>Sent from the R help mailing list archive at Nabble.com.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From moonkid at posteo.org  Thu Oct 16 21:07:29 2014
From: moonkid at posteo.org (moonkid at posteo.org)
Date: Thu, 16 Oct 2014 21:07:29 +0200
Subject: [R] understanding the no-label concept
In-Reply-To: <97FC7925-E3CA-4281-A52B-18ABFFAF4FB5@comcast.net>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
	<CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>
	<97FC7925-E3CA-4281-A52B-18ABFFAF4FB5@comcast.net>
Message-ID: <20141016190758.B11F912B9FA6@mx02.posteo.de>

On 2014-10-11 14:16 David Winsemius <dwinsemius at comcast.net> wrote:
> Hmisc...

Tried but has no effect on table() calls.


From moonkid at posteo.org  Thu Oct 16 21:09:18 2014
From: moonkid at posteo.org (moonkid at posteo.org)
Date: Thu, 16 Oct 2014 21:09:18 +0200
Subject: [R] understanding the no-label concept
In-Reply-To: <CAF8bMcbio6-7v9+_75Ftrs3mXvvT6RYXC3KyN_kXMpBHWUa0Tg@mail.gmail.com>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
	<CAF8bMcbio6-7v9+_75Ftrs3mXvvT6RYXC3KyN_kXMpBHWUa0Tg@mail.gmail.com>
Message-ID: <20141016190944.5A6AD12B9FA3@mx02.posteo.de>

On 2014-10-11 15:14 William Dunlap <wdunlap at tibco.com> wrote:
> You can use 'factors' to assign labels to small integer values.  E.g.,
>    > x <- c(1,2,3,4,3)
>    > fx <- factor(x, levels=1:5,
>    > labels=c("One","Two","Three","Four","Five")) table(fx)
>    fx
>      One   Two Three  Four  Five
>        1     1     2     1     0

Looks nice. It works! Thanks.

Now I will refere (going back) to the doc to try to understand the
concept behind it.

Reading the introduction before that had no effect on my
understanding. ;)


From moonkid at posteo.org  Thu Oct 16 21:19:31 2014
From: moonkid at posteo.org (moonkid at posteo.org)
Date: Thu, 16 Oct 2014 21:19:31 +0200
Subject: [R] understanding the no-label concept
In-Reply-To: <CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
	<CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>
Message-ID: <20141016192001.20F77231AB7@mx02.posteo.de>

> aa <- 1:5
> names(aa) <- c("Eins", "Zwei", "Drei", "Vier", "F?nf")
> aa
Eins Zwei Drei Vier F?nf
   1    2    3    4    5
> table(aa)
1 2 3 4 5
1 1 1 1 1

You see? It didn't work.

> aa <- c(aa, 1, 2)
> aa
Eins Zwei Drei Vier F?nf
   1    2    3    4    5    1    2

This is no solution for my case.

But...

> bb <- matrix(1:12, 3, 4, dimnames=list(letters[1:3], LETTERS[1:4]))

Nice. But look dam complex for a simple task. I see I have to change a
lot of the concepts in my mind and my workflows.


From 538280 at gmail.com  Thu Oct 16 22:01:39 2014
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 16 Oct 2014 14:01:39 -0600
Subject: [R] HELP
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA5DB@SRVEXCHMBX.precheza.cz>
References: <CAHFo0LvPsW6hAnOuzKF80u3Wizbc7VL3WSB7Ne0Um=J-he0ibg@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA5DB@SRVEXCHMBX.precheza.cz>
Message-ID: <CAFEqCdxseR7Rjmcv3fb+cw2MVp7_X2-qRneTJX9hLEUWEax4gA@mail.gmail.com>

I think we have a fortune candidate.

On Thu, Oct 16, 2014 at 12:35 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
> Hi
>
> It will be even worse with age, try to contact optician :-)
>
> If you want to get better answer you need to provide more info about your file, what you did and how it failed.
>
> Cheers
> Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of JAVAD LESSAN
>> Sent: Wednesday, October 15, 2014 2:53 PM
>> To: r-help at r-project.org
>> Subject: [R] HELP
>>
>> Hello There!
>>
>> I have an issue reading a large text file and parsing it. I would be
>> grateful if you let me you can help me about? Thanks.
>>
>> Javad
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From clint at ecy.wa.gov  Thu Oct 16 22:36:00 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Thu, 16 Oct 2014 13:36:00 -0700 (PDT)
Subject: [R] Time outside limits
In-Reply-To: <CAPfrkhmJAj=c66HG4dPBJ9hjgdjN6-v0uvzXcFgpyCnH+BC3Pg@mail.gmail.com>
References: <SNT151-W6422FACA8096C8244938BD8AB0@phx.gbl>
	<CAPfrkhmJAj=c66HG4dPBJ9hjgdjN6-v0uvzXcFgpyCnH+BC3Pg@mail.gmail.com>
Message-ID: <alpine.LRH.2.11.1410161335410.9850@aeolus.ecy.wa.gov>

?rle

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Thu, 16 Oct 2014, daniel wrote:

> Bart,
>
> Check if the following could help you.
>
> library(xts)
> y <- c(rnorm(10,25), rnorm(10,32),rnorm(10,25), rnorm(10,20),
> rnorm(10,25)); x <- seq(c(ISOdate(2000,3,20)), by = "hour", length.out =
> length(y))
> z <- xts( y, order.by=as.POSIXct(x))
> limit <- ifelse( lag(z) < 22 | z > 27, 1, 0)
>
>
> Daniel Merino
>
> 2014-10-16 15:12 GMT-03:00 Bart Joosen <bartjoosen at hotmail.com>:
>
>> Hi,
>> I'm currently facing the problem that I need to write a function where I
>> get a dataframe back which contains the time (in hours) outside the limits
>> of a temperature sensor, each month, and for how long exactly.
>> I wrote a for loop which check:- if a datapoint is outside the limit- if
>> the previous datapoint is outside the limt, then count + 1- if the next
>> datapoint isn't outside: write in dataframe.
>> I guess this could be with some vectorisation function, I tried with
>> seq_along, and match, but couldn't figure it out.
>> Here some sample data:
>> y <- c(rnorm(10,25), rnorm(10,32),rnorm(10,25), rnorm(10,20),
>> rnorm(10,25))x <- seq(c(ISOdate(2000,3,20)), by = "hour", length.out =
>> length(y))
>> limits of y: c(22,27)
>> Thanks
>> Bart
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
> -- 
> Daniel
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r.turner at auckland.ac.nz  Fri Oct 17 01:07:28 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 17 Oct 2014 12:07:28 +1300
Subject: [R] HELP
In-Reply-To: <CAFEqCdxseR7Rjmcv3fb+cw2MVp7_X2-qRneTJX9hLEUWEax4gA@mail.gmail.com>
References: <CAHFo0LvPsW6hAnOuzKF80u3Wizbc7VL3WSB7Ne0Um=J-he0ibg@mail.gmail.com>	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA5DB@SRVEXCHMBX.precheza.cz>
	<CAFEqCdxseR7Rjmcv3fb+cw2MVp7_X2-qRneTJX9hLEUWEax4gA@mail.gmail.com>
Message-ID: <54404FB0.1000206@auckland.ac.nz>

On 17/10/14 09:01, Greg Snow wrote:
> I think we have a fortune candidate.

Second the nomination!

cheers,

Rolf

>
> On Thu, Oct 16, 2014 at 12:35 AM, PIKAL Petr <petr.pikal at precheza.cz> wrote:
>> Hi
>>
>> It will be even worse with age, try to contact optician :-)
>>
>> If you want to get better answer you need to provide more info about your file, what you did and how it failed.
>>
>> Cheers
>> Petr
>>
>>
>>> -----Original Message-----
>>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>>> project.org] On Behalf Of JAVAD LESSAN
>>> Sent: Wednesday, October 15, 2014 2:53 PM
>>> To: r-help at r-project.org
>>> Subject: [R] HELP
>>>
>>> Hello There!
>>>
>>> I have an issue reading a large text file and parsing it. I would be
>>> grateful if you let me you can help me about? Thanks.
>>>
>>> Javad

-- 
Rolf Turner
Technical Editor ANZJS


From jeremy.miles at gmail.com  Fri Oct 17 01:32:08 2014
From: jeremy.miles at gmail.com (Jeremy Miles)
Date: Thu, 16 Oct 2014 16:32:08 -0700
Subject: [R] Difference betweeen cor.test() and formula everyone says to use
Message-ID: <CAMtGSxmf+jnCdCroG=WdCojPA14ufkQyTeDY=uHBJ+BOm05z-w@mail.gmail.com>

I'm trying to understand how cor.test() is calculating the p-value of
a correlation. It gives a p-value based on t, but every text I've ever
seen gives the calculation based on z.

For example:
> data(cars)
> with(cars[1:10, ], cor.test(speed, dist))

Pearson's product-moment correlation

data:  speed and dist
t = 2.3893, df = 8, p-value = 0.04391
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.02641348 0.90658582
sample estimates:
      cor
0.6453079

But when I use the regular formula:
> r <- cor(cars[1:10, ])[1, 2]
> r.z <- fisherz(r)
> se <- se <- 1/sqrt(10 - 3)
> z <- r.z / se
> (1 - pnorm(z))*2
[1] 0.04237039

My p-value is different.  The help file for cor.test doesn't (seem to)
have any reference to this, and I can see in the source code that it
is doing something different. I'm just not sure what.

Thanks,

Jeremy


From jwiley.psych at gmail.com  Fri Oct 17 02:20:26 2014
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Fri, 17 Oct 2014 11:20:26 +1100
Subject: [R] Difference betweeen cor.test() and formula everyone says to
	use
In-Reply-To: <CAMtGSxmf+jnCdCroG=WdCojPA14ufkQyTeDY=uHBJ+BOm05z-w@mail.gmail.com>
References: <CAMtGSxmf+jnCdCroG=WdCojPA14ufkQyTeDY=uHBJ+BOm05z-w@mail.gmail.com>
Message-ID: <CANz9Z_KnK=0QTRAy2qLG3LTSkqv_QO7VMj49OqdK1kMkF8FiVg@mail.gmail.com>

Hi Jeremy,

I don't know about references, but this around.  See for example:
http://afni.nimh.nih.gov/sscc/gangc/tr.html

the relevant line in cor.test is:

STATISTIC <- c(t = sqrt(df) * r/sqrt(1 - r^2))

You can convert *t*s to *r*s and vice versa.

Best,

Josh



On Fri, Oct 17, 2014 at 10:32 AM, Jeremy Miles <jeremy.miles at gmail.com>
wrote:

> I'm trying to understand how cor.test() is calculating the p-value of
> a correlation. It gives a p-value based on t, but every text I've ever
> seen gives the calculation based on z.
>
> For example:
> > data(cars)
> > with(cars[1:10, ], cor.test(speed, dist))
>
> Pearson's product-moment correlation
>
> data:  speed and dist
> t = 2.3893, df = 8, p-value = 0.04391
> alternative hypothesis: true correlation is not equal to 0
> 95 percent confidence interval:
>  0.02641348 0.90658582
> sample estimates:
>       cor
> 0.6453079
>
> But when I use the regular formula:
> > r <- cor(cars[1:10, ])[1, 2]
> > r.z <- fisherz(r)
> > se <- se <- 1/sqrt(10 - 3)
> > z <- r.z / se
> > (1 - pnorm(z))*2
> [1] 0.04237039
>
> My p-value is different.  The help file for cor.test doesn't (seem to)
> have any reference to this, and I can see in the source code that it
> is doing something different. I'm just not sure what.
>
> Thanks,
>
> Jeremy
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Joshua F. Wiley
Ph.D. Student, UCLA Department of Psychology
http://joshuawiley.com/
Senior Analyst, Elkhart Group Ltd.
http://elkhartgroup.com
Office: 260.673.5518

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Oct 17 06:29:45 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 17 Oct 2014 12:29:45 +0800 (CST)
Subject: [R]  how to overwrite  a  Unary operator ?
Message-ID: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>


Dear expeRts,
? Now i want to know how to implement an Unary operator?like? i++ in cpp's ?synax form.
??e.g.?? 2++? will let 2 be 3 ,? a<-2 ,a++?,will let a be 3
I tried this :
?'%++%'<-function(x){
?? x<<-x+1
}
but it have?problem,?the biggest one is?? it seems? the function need two params like?? a%++%b , how to write a function needing just one param?

TKS !



--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From r.turner at auckland.ac.nz  Fri Oct 17 07:09:47 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 17 Oct 2014 18:09:47 +1300
Subject: [R] how to overwrite  a  Unary operator ?
In-Reply-To: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
Message-ID: <5440A49B.4080001@auckland.ac.nz>

On 17/10/14 17:29, PO SU wrote:
>
> Dear expeRts,
>    Now i want to know how to implement an Unary operator like  i++ in cpp's  synax form.
>    e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
> I tried this :
>   '%++%'<-function(x){
>     x<<-x+1
> }
> but it have problem, the biggest one is it seems the function need
> twoparams like a%++%b , how to write a function needing just one param?
>
> TKS !

Just ***DON'T***.  The "++" operator is useful only for those wish to 
write code which is obscure to the point of incomprehensibility.  It 
makes C and its offspring "write only" languages.

If you are going to use R, use R and don't pollute it with such 
abominations.

cheers,

Rolf Turner


-- 
Rolf Turner
Technical Editor ANZJS


From predeus at gmail.com  Fri Oct 17 04:02:37 2014
From: predeus at gmail.com (Alexander Predeus)
Date: Thu, 16 Oct 2014 22:02:37 -0400
Subject: [R] Making a very specific heatmap in R (ggplot2?)
Message-ID: <CADvsxOn087fh2sB2ppR5vCaKD+EWtbpYNMWEC_fY3wjQfrVuJA@mail.gmail.com>

Hello All,

I'm trying to figure out the (automated) way to generate heatmaps from
simple data tables with annotated rows and columns. In the end, I need
these files to be easily viewed in a browser.

The initial data tables are simple; numbers are row-normalized (values are
real numbers varying from -1.0 to +1.0), with rows numbered from a zero to
a certain integer, and columns are named with (sometimes lengthy) strings.

What I came up with so far is building the heatmap using standard facility
with a set resolution of the final png file:

Which sort of works sometimes:

And fails pretty miserably other times:

What I really would like to do, is to make a heatmap with set number of
pixels per square, with a set font size (in pixels as well), and then save
it as a .png with variable resolution (appropriate for each concrete
heatmap). That way, a cell would be always say 10 by 10 pixels, and the
text on the right is always 8 pixels tall.

Alternatively, of course, it would be very neat to save it in some vector
format easily interpreted by the browser, but I have an impression it is
not an easy feat to accomplish.

Thank you very much in advance.

	[[alternative HTML version deleted]]


From rhelpmaillist at 163.com  Fri Oct 17 07:36:57 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 17 Oct 2014 13:36:57 +0800 (CST)
Subject: [R] how to overwrite  a  Unary operator ?
In-Reply-To: <5440A49B.4080001@auckland.ac.nz>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
Message-ID: <6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>


Tks for your advice,? let the ++ problem alone, how to write an Unary operator ? Is it permitted in R?
such????as??? a<-2 , a%+2%??will let a? be 4 .
I just want to know it , i won't pollute r with it , because i know what is r?.? : )








--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>On 17/10/14 17:29, PO SU wrote:
>>
>> Dear expeRts,
>>    Now i want to know how to implement an Unary operator like  i++ in cpp's  synax form.
>>    e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>> I tried this :
>>   '%++%'<-function(x){
>>     x<<-x+1
>> }
>> but it have problem, the biggest one is it seems the function need
>> twoparams like a%++%b , how to write a function needing just one param?
>>
>> TKS !
>
>Just ***DON'T***.  The "++" operator is useful only for those wish to 
>write code which is obscure to the point of incomprehensibility.  It 
>makes C and its offspring "write only" languages.
>
>If you are going to use R, use R and don't pollute it with such 
>abominations.
>
>cheers,
>
>Rolf Turner
>
>
>-- 
>Rolf Turner
>Technical Editor ANZJS

From dwinsemius at comcast.net  Fri Oct 17 09:16:47 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Oct 2014 00:16:47 -0700
Subject: [R] how to overwrite  a  Unary operator ?
In-Reply-To: <6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
	<6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
Message-ID: <881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>


On Oct 16, 2014, at 10:36 PM, PO SU wrote:

>
> Tks for your advice,  let the ++ problem alone, how to write an  
> Unary operator ? Is it permitted in R?
> such    as    a<-2 , a%+2%  will let a  be 4 .

OK, that's just wrong. Oh, OK, just for fun, as it were:

inc <- function(x)
{
  eval.parent(substitute(x <- x + 1))
}


 > inc(10)
Error in 10 <- 10 + 1 : invalid (do_set) left-hand side to assignment
 > y=10
 > inc(y)
 > y
[1] 11


> I just want to know it , i won't pollute r with it , because i know  
> what is r .  : )
>
It's certainly permitted. Just look at all the overloadings of the "+"  
operator in graphics packages. Look up the documentation on methods in  
R.

Why not just use a well-behaved function, though?

.inc <- function(x) x+1
 > .inc(10)
[1] 11

Then you won't be tempted to try 10 <- .inc(10) because it just  
wouldn't make sense.

-- 
David.

> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
>
> At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>> On 17/10/14 17:29, PO SU wrote:
>>>
>>> Dear expeRts,
>>>   Now i want to know how to implement an Unary operator like  i++  
>>> in cpp's  synax form.
>>>   e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>>> I tried this :
>>>  '%++%'<-function(x){
>>>    x<<-x+1
>>> }
>>> but it have problem, the biggest one is it seems the function need
>>> twoparams like a%++%b , how to write a function needing just one  
>>> param?
>>>
>>> TKS !
>>
>> Just ***DON'T***.  The "++" operator is useful only for those wish to
>> write code which is obscure to the point of incomprehensibility.  It
>> makes C and its offspring "write only" languages.
>>
>> If you are going to use R, use R and don't pollute it with such
>> abominations.
>>
>> cheers,
>>
>> Rolf Turner
>>
>>
>> -- 
>> Rolf Turner
>> Technical Editor ANZJS
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From puetz at mpipsykl.mpg.de  Fri Oct 17 11:01:20 2014
From: puetz at mpipsykl.mpg.de (=?iso-8859-1?Q?Benno_P=FCtz?=)
Date: Fri, 17 Oct 2014 11:01:20 +0200
Subject: [R] how to overwrite  a  Unary operator ?
In-Reply-To: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
Message-ID: <ECC7AE89-194D-466C-9A62-84AB434F4922@mpipsykl.mpg.de>


On 17 Oct 2014, at 06:29, PO SU <rhelpmaillist at 163.com> wrote:

>   e.g.   2++  will let 2 be 3
That would not even work in C ...

While I use this in C, I second Rolf on the general issue.

Benno

From pdalgd at gmail.com  Fri Oct 17 12:02:44 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 17 Oct 2014 12:02:44 +0200
Subject: [R] Difference betweeen cor.test() and formula everyone says to
	use
In-Reply-To: <CANz9Z_KnK=0QTRAy2qLG3LTSkqv_QO7VMj49OqdK1kMkF8FiVg@mail.gmail.com>
References: <CAMtGSxmf+jnCdCroG=WdCojPA14ufkQyTeDY=uHBJ+BOm05z-w@mail.gmail.com>
	<CANz9Z_KnK=0QTRAy2qLG3LTSkqv_QO7VMj49OqdK1kMkF8FiVg@mail.gmail.com>
Message-ID: <46FE150B-A30F-4AD0-8FB5-E5CE830F6270@gmail.com>

This is pretty much standard. I'm quite sure that other stats packages do likewise and I wouldn't know who "everyone" is. It is not unheard of that textbook authors give suboptimal formulas in order not to confuse students, though.

The basic point is that the t transformation gives the exact distribution under the null. Fisher's Z is only approximately normally distributed. 

The t transformation works because if beta is the regression coefficient of y on x, beta==0 iff rho==0, and we have exact theory for testing beta==0 by a t-test.

Off-null, the t-approach does not readily transfer, so confidence intervals tend to be based on the Z-transformation.

-Peter D.



On 17 Oct 2014, at 02:20 , Joshua Wiley <jwiley.psych at gmail.com> wrote:

> Hi Jeremy,
> 
> I don't know about references, but this around.  See for example:
> http://afni.nimh.nih.gov/sscc/gangc/tr.html
> 
> the relevant line in cor.test is:
> 
> STATISTIC <- c(t = sqrt(df) * r/sqrt(1 - r^2))
> 
> You can convert *t*s to *r*s and vice versa.
> 
> Best,
> 
> Josh
> 
> 
> 
> On Fri, Oct 17, 2014 at 10:32 AM, Jeremy Miles <jeremy.miles at gmail.com>
> wrote:
> 
>> I'm trying to understand how cor.test() is calculating the p-value of
>> a correlation. It gives a p-value based on t, but every text I've ever
>> seen gives the calculation based on z.
>> 
>> For example:
>>> data(cars)
>>> with(cars[1:10, ], cor.test(speed, dist))
>> 
>> Pearson's product-moment correlation
>> 
>> data:  speed and dist
>> t = 2.3893, df = 8, p-value = 0.04391
>> alternative hypothesis: true correlation is not equal to 0
>> 95 percent confidence interval:
>> 0.02641348 0.90658582
>> sample estimates:
>>      cor
>> 0.6453079
>> 
>> But when I use the regular formula:
>>> r <- cor(cars[1:10, ])[1, 2]
>>> r.z <- fisherz(r)
>>> se <- se <- 1/sqrt(10 - 3)
>>> z <- r.z / se
>>> (1 - pnorm(z))*2
>> [1] 0.04237039
>> 
>> My p-value is different.  The help file for cor.test doesn't (seem to)
>> have any reference to this, and I can see in the source code that it
>> is doing something different. I'm just not sure what.
>> 
>> Thanks,
>> 
>> Jeremy
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> Joshua F. Wiley
> Ph.D. Student, UCLA Department of Psychology
> http://joshuawiley.com/
> Senior Analyst, Elkhart Group Ltd.
> http://elkhartgroup.com
> Office: 260.673.5518
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chobophil at gmail.com  Fri Oct 17 12:53:30 2014
From: chobophil at gmail.com (Phil)
Date: Fri, 17 Oct 2014 12:53:30 +0200
Subject: [R] {car} outlierTest looses p/q values
Message-ID: <5440F52A.7050503@gmail.com>

Hi guys,

I came across a strange phenomena and can't figure out why it happens by 
myself so here we go.

I got a dataframe which consists of double numbers which I want to 
check, row-wise if there are outliers in the rows.

So I iterate over the rows and create a glm using the numbers of that 
particular row. Which might look like this:

case1)
         x1        x2        x3        x4        x5        x6 x7        
x8        x9        x10        x11
     0.00     3.91     0.00     0.00     0.00   68.03   40.39 0.00     
0.00      0.00       4.11

or like this:
case2)
         x1        x2        x3        x4        x5        x6 x7        
x8        x9        x10        x11
      1.00     1.00    1.00     1.00     1.00     1.00     1.00 1.00     
1.00     1.00      5.34

or any other combination of double numbers...

however, using a glm like this:

glModel <- glm(vector ~ some_other_meta_data_which_is_double_numbers)

and testing it with:

  test.Res <- outlierTest(glModel,digits=4,cutoff=Inf,n.max=Inf)

I always get a result consisting of the desired p and q values but not 
if the vector I use looks like case2. There is no error message and the 
computation does not stop either.
However, all p and q values are produced except for the last value x11.

Any idea why this particular value gets dropped from the output of the 
outlierTest Method in the car package.

Here is the sessioninfo:

  sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-redhat-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
  [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
  [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
  [7] LC_PAPER=en_US.utf8       LC_NAME=C
  [9] LC_ADDRESS=C              LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] ggplot2_1.0.0      car_2.0-21         RColorBrewer_1.0-5 iNEXT_1.0
[5] vegan_2.0-10       lattice_0.20-29    permute_0.8-3

loaded via a namespace (and not attached):
  [1] colorspace_1.2-4 compiler_3.1.1   digest_0.6.4 grid_3.1.1
  [5] gtable_0.1.2     labeling_0.3     MASS_7.3-33 munsell_0.4.2
  [9] nnet_7.3-8       plyr_1.8.1       proto_0.3-10 Rcpp_0.11.2
[13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1

Any help is highly appreciated.

Thanks

Phil


From oehm8895 at uni-landau.de  Fri Oct 17 12:52:04 2014
From: oehm8895 at uni-landau.de (Gunnar Oehmichen)
Date: Fri, 17 Oct 2014 12:52:04 +0200
Subject: [R] ggplot: Stacked bar/pie chart - Objects above the bar/pie
Message-ID: <5440F4D4.1000807@uni-landau.de>

Hello,

I would like to draw a circle on top of a pie chart (The plot does not
need to fullfill scientific standards). The circle represents the
relation of a reference-value in comparison to the summed values of the
pie-pieces. To be able to do this I partly followed:
http://rpubs.com/RobinLovelace/11641 . But i have the problem of some
bar/pie pieces being placed above the stacked bar/outside of the pie
chart, see graph PA / PA + coord_polar.

System: $platform [1] "i686-pc-linux-gnu"; $version.string [1] "R
version 3.1.1 (2014-07-10)"; ggplot2_0.9.3.1

####

require (ggplot2)

mdf <- structure(list(
  VG = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L),
                 .Label = c("A", "B"), class = "factor"),
  variable = structure(c(4L, 3L, 5L, 1L, 2L, 1L, 4L, 3L, 2L, 5L),
                       .Label = c("a", "b", "c",  "d", "e"), class =
"factor"),
  value = c(0, 8407346.56, 0, 124901773, 0, 184987520, 14612608,
3165030, 0, 0),
  reference = c(0.75, 0.75, 0.75, 0.75, 0.75, 1.25, 1.25, 1.25, 1.25,
1.25)),
  .Names = c("VG", "variable", "value", "reference"),
  row.names = c(16L, 17L, 18L,   19L, 20L, 46L, 47L, 48L, 49L, 50L),
class = "data.frame")

# Calculate position
pos <- function (x) 0.5 * (cumsum(x) + cumsum(c(0, x[-length(x)])))
lmdf <- dlply (mdf, "VG")
lmdf <- lapply (lmdf, function (X) { X$pos <- pos (X$value)
                             return (X) })
mdf <- rbind.data.frame (lmdf[[1]], lmdf[[2]])

# height (radius) of all pieces (variable) in one bar (pie) will be the
same:
mdf$rad <- 1

# abline from the reference column in the dataframe
INTCA <- unique (mdf$reference[mdf$VG=="A"])
PA <- ggplot (mdf[mdf$VG=="A",], aes (x = pos, y = rad)) +
  geom_bar (stat = "identity", aes (fill = variable, width = value)) +
  geom_abline(intercept = INTCA, slope = 0)

PA
PA + coord_polar()
# Object c is placed above its position on the y axis

# abline from the reference column in the dataframe
INTCB <- unique (mdf$reference[mdf$VG=="B"])
PB <- ggplot (mdf[mdf$VG=="B",], aes (x = pos, y = rad)) +
  geom_bar (stat = "identity", aes (fill = variable, width = value)) +
  geom_abline(intercept = INTCB, slope = 0)

PB
PB + coord_polar()
# all objects are within rad = 1

###

Your help would be very much appreciated,

Gunnar


From rhelpmaillist at 163.com  Fri Oct 17 10:06:29 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 17 Oct 2014 16:06:29 +0800 (CST)
Subject: [R] how to overwrite  a  Unary operator ?
In-Reply-To: <881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
	<6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
	<881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>
Message-ID: <2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>


Tks for your alternative way's details. but like you mentioned in graphics package, i still wonder how to overload an operator which can pass one param like +2 .
There seems exists some examples for my needing. But i try to find them but without any results.
can you show me some examples from it??






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-10-17 15:16:47, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>On Oct 16, 2014, at 10:36 PM, PO SU wrote:
>
>>
>> Tks for your advice,  let the ++ problem alone, how to write an  
>> Unary operator ? Is it permitted in R?
>> such    as    a<-2 , a%+2%  will let a  be 4 .
>
>OK, that's just wrong. Oh, OK, just for fun, as it were:
>
>inc <- function(x)
>{
>  eval.parent(substitute(x <- x + 1))
>}
>
>
> > inc(10)
>Error in 10 <- 10 + 1 : invalid (do_set) left-hand side to assignment
> > y=10
> > inc(y)
> > y
>[1] 11
>
>
>> I just want to know it , i won't pollute r with it , because i know  
>> what is r .  : )
>>
>It's certainly permitted. Just look at all the overloadings of the "+"  
>operator in graphics packages. Look up the documentation on methods in  
>R.
>
>Why not just use a well-behaved function, though?
>
>.inc <- function(x) x+1
> > .inc(10)
>[1] 11
>
>Then you won't be tempted to try 10 <- .inc(10) because it just  
>wouldn't make sense.
>
>-- 
>David.
>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>>
>>
>>
>>
>> At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>> On 17/10/14 17:29, PO SU wrote:
>>>>
>>>> Dear expeRts,
>>>>   Now i want to know how to implement an Unary operator like  i++  
>>>> in cpp's  synax form.
>>>>   e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>>>> I tried this :
>>>>  '%++%'<-function(x){
>>>>    x<<-x+1
>>>> }
>>>> but it have problem, the biggest one is it seems the function need
>>>> twoparams like a%++%b , how to write a function needing just one  
>>>> param?
>>>>
>>>> TKS !
>>>
>>> Just ***DON'T***.  The "++" operator is useful only for those wish to
>>> write code which is obscure to the point of incomprehensibility.  It
>>> makes C and its offspring "write only" languages.
>>>
>>> If you are going to use R, use R and don't pollute it with such
>>> abominations.
>>>
>>> cheers,
>>>
>>> Rolf Turner
>>>
>>>
>>> -- 
>>> Rolf Turner
>>> Technical Editor ANZJS
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius, MD
>Alameda, CA, USA
>

From Swapnil.Khobragade at lntinfotech.com  Fri Oct 17 11:04:02 2014
From: Swapnil.Khobragade at lntinfotech.com (Swapnil Khobragade)
Date: Fri, 17 Oct 2014 14:34:02 +0530
Subject: [R] need help for error "incompatible dimensions"
Message-ID: <24E59E774BB54C4D835922C8D6BA8093014B04C422@POWINMSMBX01.pwiodc.lntinfotech.com>







Hello,

I m R user trying  to map and find correlation between two entities i.e. time and usability of cup from log file, but its showing error while compilation.
Is there any specific package(s) by means of which I can effectively run the code meant for different dimensions computation?


I have attached .R file and log file (.txt)
Please find attachment..






Regards,
Swapnil Khobragade
Larsen & Toubro Infotech Ltd.
Bldg. No.5&6, 1st Floor,
Airoli, Navi Mumbai - 400708.
e-mail ID: swapnil.khobragade at lntinfotech.com<mailto:swapnil.khobragade at lntinfotech.com>

________________________________
The contents of this e-mail and any attachment(s) may contain confidential or privileged information for the intended recipient(s). Unintended recipients are prohibited from taking action on the basis of information in this e-mail and using or disseminating the information, and must notify the sender and delete it from their system. L&T Infotech will not accept responsibility or liability for the accuracy or completeness of, or the presence of any virus or disabling code in this e-mail"
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: cpu.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141017/ca8d9f67/attachment.txt>

From petr.pikal at precheza.cz  Fri Oct 17 14:17:26 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 17 Oct 2014 12:17:26 +0000
Subject: [R] need help for error "incompatible dimensions"
In-Reply-To: <24E59E774BB54C4D835922C8D6BA8093014B04C422@POWINMSMBX01.pwiodc.lntinfotech.com>
References: <24E59E774BB54C4D835922C8D6BA8093014B04C422@POWINMSMBX01.pwiodc.lntinfotech.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAA5D@SRVEXCHMBX.precheza.cz>

Hi

Your .R attachment did not come through. Included txt file did not have headers. Maybe you just want

cor(whatever is the name of your numeric object)

Cheers
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Swapnil Khobragade
> Sent: Friday, October 17, 2014 11:04 AM
> To: r-help at r-project.org
> Cc: skhobragade08 at gmail.com
> Subject: [R] need help for error "incompatible dimensions"
>
>
>
>
>
>
>
> Hello,
>
> I m R user trying  to map and find correlation between two entities
> i.e. time and usability of cup from log file, but its showing error
> while compilation.
> Is there any specific package(s) by means of which I can effectively
> run the code meant for different dimensions computation?
>
>
> I have attached .R file and log file (.txt) Please find attachment..
>
>
>
>
>
>
> Regards,
> Swapnil Khobragade
> Larsen & Toubro Infotech Ltd.
> Bldg. No.5&6, 1st Floor,
> Airoli, Navi Mumbai - 400708.
> e-mail ID:
> swapnil.khobragade at lntinfotech.com<mailto:swapnil.khobragade at lntinfotec
> h.com>
>
> ________________________________
> The contents of this e-mail and any attachment(s) may contain
> confidential or privileged information for the intended recipient(s).
> Unintended recipients are prohibited from taking action on the basis of
> information in this e-mail and using or disseminating the information,
> and must notify the sender and delete it from their system. L&T
> Infotech will not accept responsibility or liability for the accuracy
> or completeness of, or the presence of any virus or disabling code in
> this e-mail"

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From monaly.mistry at gmail.com  Fri Oct 17 15:26:54 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Fri, 17 Oct 2014 14:26:54 +0100
Subject: [R] assigning letter to a column
Message-ID: <CANpv+67WpMcYSgEH2-3dVVFkpeyAccgdCcxgAnLPh6QQU4HqJA@mail.gmail.com>

Hi,

I'm having trouble with assigning a letter to a column based on the value
of another column.
Since I have separate data files I've saved then into one folder and I'm
reading them in separately into the function.

The code is below.

#F= fast; S= slow; I1= Intermediate score 1; I2=Intermediate score 2
filename<-list.files(pattern="*.txt")
filename
corloc<- function(x){
  x<-read.table(filename[x], sep="\t", header=TRUE) #will extract the
relevant data file from folder 1998. ex. corloc(1) will return 1998
breeding year data
  x[,"ForS"]<-0 #new column
  for (i in length(x$CORLOC)){ #this is the bit that I'm having a problem
with since it's not assigning the appropriate letter into the "ForS" column
  ifelse(x$COR_LOC>=3 | x$COR_LOC<15.230, ForS<-"S",
         ifelse(x$COR_LOC>=15.230 | x$COR_LOC<19.810, ForS<-"I1",
                ifelse(x$COR_LOC>=19.810 | x$COR_LOC<25.540,
FS<-"I2",ForS<-"F")))}
  print(x)
}

I've tried some of the solutions on stackoverflow but still was
unsuccessful.

Best,

Monaly.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 17 15:46:14 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 17 Oct 2014 06:46:14 -0700
Subject: [R] Making a very specific heatmap in R (ggplot2?)
In-Reply-To: <CADvsxOn087fh2sB2ppR5vCaKD+EWtbpYNMWEC_fY3wjQfrVuJA@mail.gmail.com>
References: <CADvsxOn087fh2sB2ppR5vCaKD+EWtbpYNMWEC_fY3wjQfrVuJA@mail.gmail.com>
Message-ID: <2C82F3BF-7F49-4459-9D3D-E981BD337520@dcn.davis.CA.us>

As the Posting Guide indicates, this is a text-only mailing list, and small, reproducible (self-contained) examples of R code are expected. You are not getting much response because what you sent is not what we see, and we cannot tweak code you do not share.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 16, 2014 7:02:37 PM PDT, Alexander Predeus <predeus at gmail.com> wrote:
>Hello All,
>
>I'm trying to figure out the (automated) way to generate heatmaps from
>simple data tables with annotated rows and columns. In the end, I need
>these files to be easily viewed in a browser.
>
>The initial data tables are simple; numbers are row-normalized (values
>are
>real numbers varying from -1.0 to +1.0), with rows numbered from a zero
>to
>a certain integer, and columns are named with (sometimes lengthy)
>strings.
>
>What I came up with so far is building the heatmap using standard
>facility
>with a set resolution of the final png file:
>
>Which sort of works sometimes:
>
>And fails pretty miserably other times:
>
>What I really would like to do, is to make a heatmap with set number of
>pixels per square, with a set font size (in pixels as well), and then
>save
>it as a .png with variable resolution (appropriate for each concrete
>heatmap). That way, a cell would be always say 10 by 10 pixels, and the
>text on the right is always 8 pixels tall.
>
>Alternatively, of course, it would be very neat to save it in some
>vector
>format easily interpreted by the browser, but I have an impression it
>is
>not an easy feat to accomplish.
>
>Thank you very much in advance.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Oct 17 16:14:50 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 17 Oct 2014 14:14:50 +0000
Subject: [R] assigning letter to a column
In-Reply-To: <CANpv+67WpMcYSgEH2-3dVVFkpeyAccgdCcxgAnLPh6QQU4HqJA@mail.gmail.com>
References: <CANpv+67WpMcYSgEH2-3dVVFkpeyAccgdCcxgAnLPh6QQU4HqJA@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FA9FE9@mb02.ads.tamu.edu>

I think it is doing exactly what you have told it to do, but that is probably not what you want it to do.

First, you do not need a loop since the ifelse() function is vectorized. Read the manual page and the examples carefully. Also you are coding ifelse() as if it were the same as if() {} else() {}. Again you need to refer to the documentation.

Second, this seems like a job for cut() not ifelse().

Third, look at your code. The first statement is x$COR_LOC>=3 | x$COR_LOC<15.230 so everything greater than 3 will be coded as "S." That is probably all of your data. You probably want to use & (and) instead of | (or). It is not clear what you want to happen for values less than 3 but they will be NA (missing).

Your entire ifelse() boils down to

set.seed(42)
x <- data.frame(COR_LOC=runif(100, 0, 30))
x$ForS <- cut(x$COR_LOC, breaks=c(3, 15.23, 19.81, 25.40, Inf),
	labels=c("S", "I1", "I2", "F"), right=FALSE)

No loops, no ifelse's. Anything below 3 will 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Monaly Mistry
Sent: Friday, October 17, 2014 8:27 AM
To: r-help at r-project.org
Subject: [R] assigning letter to a column

Hi,

I'm having trouble with assigning a letter to a column based on the value
of another column.
Since I have separate data files I've saved then into one folder and I'm
reading them in separately into the function.

The code is below.

#F= fast; S= slow; I1= Intermediate score 1; I2=Intermediate score 2
filename<-list.files(pattern="*.txt")
filename
corloc<- function(x){
  x<-read.table(filename[x], sep="\t", header=TRUE) #will extract the
relevant data file from folder 1998. ex. corloc(1) will return 1998
breeding year data
  x[,"ForS"]<-0 #new column
  for (i in length(x$CORLOC)){ #this is the bit that I'm having a problem
with since it's not assigning the appropriate letter into the "ForS" column
  ifelse(x$COR_LOC>=3 | x$COR_LOC<15.230, ForS<-"S",
         ifelse(x$COR_LOC>=15.230 | x$COR_LOC<19.810, ForS<-"I1",
                ifelse(x$COR_LOC>=19.810 | x$COR_LOC<25.540,
FS<-"I2",ForS<-"F")))}
  print(x)
}

I've tried some of the solutions on stackoverflow but still was
unsuccessful.

Best,

Monaly.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Oct 17 16:27:33 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 17 Oct 2014 14:27:33 +0000
Subject: [R] assigning letter to a column
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FA9FE9@mb02.ads.tamu.edu>
References: <CANpv+67WpMcYSgEH2-3dVVFkpeyAccgdCcxgAnLPh6QQU4HqJA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FA9FE9@mb02.ads.tamu.edu>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FAA034@mb02.ads.tamu.edu>

Minor correction, given your code, values less than 3 will be coded as "S" since they are less than 15.23. In the code I suggested, values less than 3 will be coded as missing (NA).

David C

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of David L Carlson
Sent: Friday, October 17, 2014 9:15 AM
To: Monaly Mistry; r-help at r-project.org
Subject: Re: [R] assigning letter to a column

I think it is doing exactly what you have told it to do, but that is probably not what you want it to do.

First, you do not need a loop since the ifelse() function is vectorized. Read the manual page and the examples carefully. Also you are coding ifelse() as if it were the same as if() {} else() {}. Again you need to refer to the documentation.

Second, this seems like a job for cut() not ifelse().

Third, look at your code. The first statement is x$COR_LOC>=3 | x$COR_LOC<15.230 so everything greater than 3 will be coded as "S." That is probably all of your data. You probably want to use & (and) instead of | (or). It is not clear what you want to happen for values less than 3 but they will be NA (missing).

Your entire ifelse() boils down to

set.seed(42)
x <- data.frame(COR_LOC=runif(100, 0, 30))
x$ForS <- cut(x$COR_LOC, breaks=c(3, 15.23, 19.81, 25.40, Inf),
	labels=c("S", "I1", "I2", "F"), right=FALSE)

No loops, no ifelse's. Anything below 3 will 

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Monaly Mistry
Sent: Friday, October 17, 2014 8:27 AM
To: r-help at r-project.org
Subject: [R] assigning letter to a column

Hi,

I'm having trouble with assigning a letter to a column based on the value
of another column.
Since I have separate data files I've saved then into one folder and I'm
reading them in separately into the function.

The code is below.

#F= fast; S= slow; I1= Intermediate score 1; I2=Intermediate score 2
filename<-list.files(pattern="*.txt")
filename
corloc<- function(x){
  x<-read.table(filename[x], sep="\t", header=TRUE) #will extract the
relevant data file from folder 1998. ex. corloc(1) will return 1998
breeding year data
  x[,"ForS"]<-0 #new column
  for (i in length(x$CORLOC)){ #this is the bit that I'm having a problem
with since it's not assigning the appropriate letter into the "ForS" column
  ifelse(x$COR_LOC>=3 | x$COR_LOC<15.230, ForS<-"S",
         ifelse(x$COR_LOC>=15.230 | x$COR_LOC<19.810, ForS<-"I1",
                ifelse(x$COR_LOC>=19.810 | x$COR_LOC<25.540,
FS<-"I2",ForS<-"F")))}
  print(x)
}

I've tried some of the solutions on stackoverflow but still was
unsuccessful.

Best,

Monaly.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Fri Oct 17 17:43:23 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 17 Oct 2014 11:43:23 -0400
Subject: [R] {car} outlierTest looses p/q values
In-Reply-To: <5440F52A.7050503@gmail.com>
References: <5440F52A.7050503@gmail.com>
Message-ID: <web-531893112@cgpsrv2.cis.mcmaster.ca>

Dear Phil,

After reading your posting several times, I still don't understand what you did. As usual, having a reproducible example illustrating the error would be a great help. I do have a guess about the source of the error: glm() failed in some way for the problematic case.

Best,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	

On Fri, 17 Oct 2014 12:53:30 +0200
 Phil <chobophil at gmail.com> wrote:
> Hi guys,
> 
> I came across a strange phenomena and can't figure out why it happens by myself so here we go.
> 
> I got a dataframe which consists of double numbers which I want to check, row-wise if there are outliers in the rows.
> 
> So I iterate over the rows and create a glm using the numbers of that particular row. Which might look like this:
> 
> case1)
>          x1        x2        x3        x4        x5        x6 x7        
> x8        x9        x10        x11
>      0.00     3.91     0.00     0.00     0.00   68.03   40.39 0.00     
> 0.00      0.00       4.11
> 
> or like this:
> case2)
>          x1        x2        x3        x4        x5        x6 x7        
> x8        x9        x10        x11
>       1.00     1.00    1.00     1.00     1.00     1.00     1.00 1.00     
> 1.00     1.00      5.34
> 
> or any other combination of double numbers...
> 
> however, using a glm like this:
> 
> glModel <- glm(vector ~ some_other_meta_data_which_is_double_numbers)
> 
> and testing it with:
> 
>   test.Res <- outlierTest(glModel,digits=4,cutoff=Inf,n.max=Inf)
> 
> I always get a result consisting of the desired p and q values but not if the vector I use looks like case2. There is no error message and the computation does not stop either.
> However, all p and q values are produced except for the last value x11.
> 
> Any idea why this particular value gets dropped from the output of the outlierTest Method in the car package.
> 
> Here is the sessioninfo:
> 
>   sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-redhat-linux-gnu (64-bit)
> 
> locale:
>   [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>   [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>   [7] LC_PAPER=en_US.utf8       LC_NAME=C
>   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
> 
> other attached packages:
> [1] ggplot2_1.0.0      car_2.0-21         RColorBrewer_1.0-5 iNEXT_1.0
> [5] vegan_2.0-10       lattice_0.20-29    permute_0.8-3
> 
> loaded via a namespace (and not attached):
>   [1] colorspace_1.2-4 compiler_3.1.1   digest_0.6.4 grid_3.1.1
>   [5] gtable_0.1.2     labeling_0.3     MASS_7.3-33 munsell_0.4.2
>   [9] nnet_7.3-8       plyr_1.8.1       proto_0.3-10 Rcpp_0.11.2
> [13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
> 
> Any help is highly appreciated.
> 
> Thanks
> 
> Phil
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Fri Oct 17 18:54:40 2014
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 17 Oct 2014 10:54:40 -0600
Subject: [R] how to overwrite a Unary operator ?
In-Reply-To: <2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
	<6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
	<881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>
	<2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>
Message-ID: <CAFEqCdwZ5gk+FJm6DqUHOcjEt73qV7aAA0hJS4f=R=A_RcaK2A@mail.gmail.com>

You may be interested in looking at Reference Classes/objects (see
?setRefClass).  This is a form of OO programming that is more similar
to C++ and Java.  You could create a counter object that you could
then increment with syntax like:

x$inc()
x$inc(5)

The first would increment by the default (1), the second would then
increment by 5.



On Fri, Oct 17, 2014 at 2:06 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Tks for your alternative way's details. but like you mentioned in graphics package, i still wonder how to overload an operator which can pass one param like +2 .
> There seems exists some examples for my needing. But i try to find them but without any results.
> can you show me some examples from it?
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-10-17 15:16:47, "David Winsemius" <dwinsemius at comcast.net> wrote:
>>
>>On Oct 16, 2014, at 10:36 PM, PO SU wrote:
>>
>>>
>>> Tks for your advice,  let the ++ problem alone, how to write an
>>> Unary operator ? Is it permitted in R?
>>> such    as    a<-2 , a%+2%  will let a  be 4 .
>>
>>OK, that's just wrong. Oh, OK, just for fun, as it were:
>>
>>inc <- function(x)
>>{
>>  eval.parent(substitute(x <- x + 1))
>>}
>>
>>
>> > inc(10)
>>Error in 10 <- 10 + 1 : invalid (do_set) left-hand side to assignment
>> > y=10
>> > inc(y)
>> > y
>>[1] 11
>>
>>
>>> I just want to know it , i won't pollute r with it , because i know
>>> what is r .  : )
>>>
>>It's certainly permitted. Just look at all the overloadings of the "+"
>>operator in graphics packages. Look up the documentation on methods in
>>R.
>>
>>Why not just use a well-behaved function, though?
>>
>>.inc <- function(x) x+1
>> > .inc(10)
>>[1] 11
>>
>>Then you won't be tempted to try 10 <- .inc(10) because it just
>>wouldn't make sense.
>>
>>--
>>David.
>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>>
>>>
>>>
>>>
>>> At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>>> On 17/10/14 17:29, PO SU wrote:
>>>>>
>>>>> Dear expeRts,
>>>>>   Now i want to know how to implement an Unary operator like  i++
>>>>> in cpp's  synax form.
>>>>>   e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>>>>> I tried this :
>>>>>  '%++%'<-function(x){
>>>>>    x<<-x+1
>>>>> }
>>>>> but it have problem, the biggest one is it seems the function need
>>>>> twoparams like a%++%b , how to write a function needing just one
>>>>> param?
>>>>>
>>>>> TKS !
>>>>
>>>> Just ***DON'T***.  The "++" operator is useful only for those wish to
>>>> write code which is obscure to the point of incomprehensibility.  It
>>>> makes C and its offspring "write only" languages.
>>>>
>>>> If you are going to use R, use R and don't pollute it with such
>>>> abominations.
>>>>
>>>> cheers,
>>>>
>>>> Rolf Turner
>>>>
>>>>
>>>> --
>>>> Rolf Turner
>>>> Technical Editor ANZJS
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>David Winsemius, MD
>>Alameda, CA, USA
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From monaly.mistry at gmail.com  Fri Oct 17 19:17:44 2014
From: monaly.mistry at gmail.com (Monaly Mistry)
Date: Fri, 17 Oct 2014 18:17:44 +0100
Subject: [R] assigning letter to a column
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FAA034@mb02.ads.tamu.edu>
References: <CANpv+67WpMcYSgEH2-3dVVFkpeyAccgdCcxgAnLPh6QQU4HqJA@mail.gmail.com>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FA9FE9@mb02.ads.tamu.edu>
	<53BF8FB63FAF2E4A9455EF1EE94DA726FAA034@mb02.ads.tamu.edu>
Message-ID: <CANpv+65Mg6y=GctUwma5pbb_bd+0Jr77UW6GXhYpb7exNiRw2w@mail.gmail.com>

Thank you for your help David, will make sure to check the documentation.

Best,

Monaly

On Fri, Oct 17, 2014 at 3:27 PM, David L Carlson <dcarlson at tamu.edu> wrote:

> Minor correction, given your code, values less than 3 will be coded as "S"
> since they are less than 15.23. In the code I suggested, values less than 3
> will be coded as missing (NA).
>
> David C
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of David L Carlson
> Sent: Friday, October 17, 2014 9:15 AM
> To: Monaly Mistry; r-help at r-project.org
> Subject: Re: [R] assigning letter to a column
>
> I think it is doing exactly what you have told it to do, but that is
> probably not what you want it to do.
>
> First, you do not need a loop since the ifelse() function is vectorized.
> Read the manual page and the examples carefully. Also you are coding
> ifelse() as if it were the same as if() {} else() {}. Again you need to
> refer to the documentation.
>
> Second, this seems like a job for cut() not ifelse().
>
> Third, look at your code. The first statement is x$COR_LOC>=3 |
> x$COR_LOC<15.230 so everything greater than 3 will be coded as "S." That is
> probably all of your data. You probably want to use & (and) instead of |
> (or). It is not clear what you want to happen for values less than 3 but
> they will be NA (missing).
>
> Your entire ifelse() boils down to
>
> set.seed(42)
> x <- data.frame(COR_LOC=runif(100, 0, 30))
> x$ForS <- cut(x$COR_LOC, breaks=c(3, 15.23, 19.81, 25.40, Inf),
>         labels=c("S", "I1", "I2", "F"), right=FALSE)
>
> No loops, no ifelse's. Anything below 3 will
>
> -------------------------------------
> David L Carlson
> Department of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Monaly Mistry
> Sent: Friday, October 17, 2014 8:27 AM
> To: r-help at r-project.org
> Subject: [R] assigning letter to a column
>
> Hi,
>
> I'm having trouble with assigning a letter to a column based on the value
> of another column.
> Since I have separate data files I've saved then into one folder and I'm
> reading them in separately into the function.
>
> The code is below.
>
> #F= fast; S= slow; I1= Intermediate score 1; I2=Intermediate score 2
> filename<-list.files(pattern="*.txt")
> filename
> corloc<- function(x){
>   x<-read.table(filename[x], sep="\t", header=TRUE) #will extract the
> relevant data file from folder 1998. ex. corloc(1) will return 1998
> breeding year data
>   x[,"ForS"]<-0 #new column
>   for (i in length(x$CORLOC)){ #this is the bit that I'm having a problem
> with since it's not assigning the appropriate letter into the "ForS" column
>   ifelse(x$COR_LOC>=3 | x$COR_LOC<15.230, ForS<-"S",
>          ifelse(x$COR_LOC>=15.230 | x$COR_LOC<19.810, ForS<-"I1",
>                 ifelse(x$COR_LOC>=19.810 | x$COR_LOC<25.540,
> FS<-"I2",ForS<-"F")))}
>   print(x)
> }
>
> I've tried some of the solutions on stackoverflow but still was
> unsuccessful.
>
> Best,
>
> Monaly.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Oct 17 19:40:50 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Oct 2014 10:40:50 -0700
Subject: [R] how to overwrite  a  Unary operator ?
In-Reply-To: <2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
	<6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
	<881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>
	<2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>
Message-ID: <F13368A3-5F0F-4273-ACB7-94AC9B15E506@comcast.net>


On Oct 17, 2014, at 1:06 AM, PO SU wrote:

> 
> Tks for your alternative way's details. but like you mentioned in graphics package, i still wonder how to overload an operator which can pass one param like +2 .
> There seems exists some examples for my needing. But i try to find them but without any results.
> can you show me some examples from it? 
> 

I think this might be a case of "if you don't know enough to do it, then you don't know why you shouldn't do it." (Or vice versa?) I did search for a relevant fortune to support my impression, but the various entries for fortune("parse") and fortune("eval") didn't seem to hit the mark.

library(ggplot2)
help(pack="ggplot2")  # scroll to bottom of page
ggplot2:::`+.gg`   # this shows the S3 method of adding an operator based on the S3 method dispatch.

I was able to emulate that example to create a C-like, unary `+` operator for a new class, but I'm not willing to put it in print for fear that my karmic account might be depleted.

-- 
David.

> --
> 
> PO SU
> mail: desolator88 at 163.com 
> Majored in Statistics from SJTU
> 
> 
> 
> At 2014-10-17 15:16:47, "David Winsemius" <dwinsemius at comcast.net> wrote:
>> 
>> On Oct 16, 2014, at 10:36 PM, PO SU wrote:
>> 
>>> 
>>> Tks for your advice,  let the ++ problem alone, how to write an  
>>> Unary operator ? Is it permitted in R?
>>> such    as    a<-2 , a%+2%  will let a  be 4 .
>> 
>> OK, that's just wrong. Oh, OK, just for fun, as it were:
>> 
>> inc <- function(x)
>> {
>> eval.parent(substitute(x <- x + 1))
>> }
>> 
>> 
>>> inc(10)
>> Error in 10 <- 10 + 1 : invalid (do_set) left-hand side to assignment
>>> y=10
>>> inc(y)
>>> y
>> [1] 11
>> 
>> 
>>> I just want to know it , i won't pollute r with it , because i know  
>>> what is r .  : )
>>> 
>> It's certainly permitted. Just look at all the overloadings of the "+"  
>> operator in graphics packages. Look up the documentation on methods in  
>> R.
>> 
>> Why not just use a well-behaved function, though?
>> 
>> .inc <- function(x) x+1
>>> .inc(10)
>> [1] 11
>> 
>> Then you won't be tempted to try 10 <- .inc(10) because it just  
>> wouldn't make sense.
>> 
>> -- 
>> David.
>> 
>>> --
>>> 
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>> 
>>> 
>>> 
>>> 
>>> At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>>> On 17/10/14 17:29, PO SU wrote:
>>>>> 
>>>>> Dear expeRts,
>>>>>  Now i want to know how to implement an Unary operator like  i++  
>>>>> in cpp's  synax form.
>>>>>  e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>>>>> I tried this :
>>>>> '%++%'<-function(x){
>>>>>   x<<-x+1
>>>>> }
>>>>> but it have problem, the biggest one is it seems the function need
>>>>> twoparams like a%++%b , how to write a function needing just one  
>>>>> param?
>>>>> 
>>>>> TKS !
>>>> 
>>>> Just ***DON'T***.  The "++" operator is useful only for those wish to
>>>> write code which is obscure to the point of incomprehensibility.  It
>>>> makes C and its offspring "write only" languages.
>>>> 
>>>> If you are going to use R, use R and don't pollute it with such
>>>> abominations.
>>>> 
>>>> cheers,
>>>> 
>>>> Rolf Turner
>>>> 
>>>> 
>>>> -- 
>>>> Rolf Turner
>>>> Technical Editor ANZJS
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius, MD
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From jfox at mcmaster.ca  Fri Oct 17 20:54:37 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 17 Oct 2014 14:54:37 -0400
Subject: [R] {car} outlierTest looses p/q values
In-Reply-To: <CAA4NQG8fL2xOy851Pg1TVLvaMFMLk-j31a1cFsQP2rdV+sWgww@mail.gmail.com>
References: <5440F52A.7050503@gmail.com>
	<web-531893112@cgpsrv2.cis.mcmaster.ca>
	<CAA4NQG8fL2xOy851Pg1TVLvaMFMLk-j31a1cFsQP2rdV+sWgww@mail.gmail.com>
Message-ID: <web-531937413@cgpsrv2.cis.mcmaster.ca>

Dear Phil,

Yes, that's a bit clearer. One can invent data configurations where certain studentized residuals are undefined. For example, try the following:

y <- c(0, 0, 0, 0, 0, 1)
x <- 1:6
xx <- (1:6 - 3.5)^2
rstudent(lm(y ~ x))
rstudent(lm(y ~ xx))
plot(x, y)
plot(xx, y)

The plots should clarify what's going on.

I'm copying to r-help since the discussion began there.

I hope this helps,
 John

On Fri, 17 Oct 2014 18:35:59 +0200
 Philip Stevens <chobophil at gmail.com> wrote:
> Dear John,
> 
> Thank you for your fast reply. Unfortunately I am out of office right now
> but I will get back to you on Monday asap with a toy example and some code.
> Meanwhile let me try to explain further.
> 
> Basically not the glm but the outlierTest afterwards fails. And it only
> fails if all values, used to set up the glm, are exactly 1 except for one
> value which can be arbitrary large. I construct the glm from a vector of
> doubles (the target values) and a vector of other numeric values(metadata).
> (So this should be fit <- glm(targetVector ~ metadata) ) And want to check
> if one of those doubles(in the target vector) is an outlier using
> outlierTest(fit). The residuals are calculated by the glm but the
> outlierTest does not report a p nor a q value for the one value in the
> target vector which is not 1. And I can't figure out why...
> 
> I hope this makes it a bit clearer.
> Anyways I will come back to you on Monday.
> 
> Best,
> 
> Phil
> Am 17.10.2014 17:43 schrieb "John Fox" <jfox at mcmaster.ca>:
> 
> > Dear Phil,
> >
> > After reading your posting several times, I still don't understand what
> > you did. As usual, having a reproducible example illustrating the error
> > would be a great help. I do have a guess about the source of the error:
> > glm() failed in some way for the problematic case.
> >
> > Best,
> >  John
> >
> > ------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> >
> >
> > On Fri, 17 Oct 2014 12:53:30 +0200
> >  Phil <chobophil at gmail.com> wrote:
> > > Hi guys,
> > >
> > > I came across a strange phenomena and can't figure out why it happens by
> > myself so here we go.
> > >
> > > I got a dataframe which consists of double numbers which I want to
> > check, row-wise if there are outliers in the rows.
> > >
> > > So I iterate over the rows and create a glm using the numbers of that
> > particular row. Which might look like this:
> > >
> > > case1)
> > >          x1        x2        x3        x4        x5        x6 x7
> > > x8        x9        x10        x11
> > >      0.00     3.91     0.00     0.00     0.00   68.03   40.39 0.00
> > > 0.00      0.00       4.11
> > >
> > > or like this:
> > > case2)
> > >          x1        x2        x3        x4        x5        x6 x7
> > > x8        x9        x10        x11
> > >       1.00     1.00    1.00     1.00     1.00     1.00     1.00 1.00
> > > 1.00     1.00      5.34
> > >
> > > or any other combination of double numbers...
> > >
> > > however, using a glm like this:
> > >
> > > glModel <- glm(vector ~ some_other_meta_data_which_is_double_numbers)
> > >
> > > and testing it with:
> > >
> > >   test.Res <- outlierTest(glModel,digits=4,cutoff=Inf,n.max=Inf)
> > >
> > > I always get a result consisting of the desired p and q values but not
> > if the vector I use looks like case2. There is no error message and the
> > computation does not stop either.
> > > However, all p and q values are produced except for the last value x11.
> > >
> > > Any idea why this particular value gets dropped from the output of the
> > outlierTest Method in the car package.
> > >
> > > Here is the sessioninfo:
> > >
> > >   sessionInfo()
> > > R version 3.1.1 (2014-07-10)
> > > Platform: x86_64-redhat-linux-gnu (64-bit)
> > >
> > > locale:
> > >   [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> > >   [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> > >   [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
> > >   [7] LC_PAPER=en_US.utf8       LC_NAME=C
> > >   [9] LC_ADDRESS=C              LC_TELEPHONE=C
> > > [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> > >
> > > attached base packages:
> > > [1] stats     graphics  grDevices utils     datasets  methods base
> > >
> > > other attached packages:
> > > [1] ggplot2_1.0.0      car_2.0-21         RColorBrewer_1.0-5 iNEXT_1.0
> > > [5] vegan_2.0-10       lattice_0.20-29    permute_0.8-3
> > >
> > > loaded via a namespace (and not attached):
> > >   [1] colorspace_1.2-4 compiler_3.1.1   digest_0.6.4 grid_3.1.1
> > >   [5] gtable_0.1.2     labeling_0.3     MASS_7.3-33 munsell_0.4.2
> > >   [9] nnet_7.3-8       plyr_1.8.1       proto_0.3-10 Rcpp_0.11.2
> > > [13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
> > >
> > > Any help is highly appreciated.
> > >
> > > Thanks
> > >
> > > Phil
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From JLucke at ria.buffalo.edu  Fri Oct 17 16:15:05 2014
From: JLucke at ria.buffalo.edu (JLucke at ria.buffalo.edu)
Date: Fri, 17 Oct 2014 10:15:05 -0400
Subject: [R] Difference betweeen cor.test() and formula everyone says to
	use
In-Reply-To: <CAMtGSxmf+jnCdCroG=WdCojPA14ufkQyTeDY=uHBJ+BOm05z-w@mail.gmail.com>
References: <CAMtGSxmf+jnCdCroG=WdCojPA14ufkQyTeDY=uHBJ+BOm05z-w@mail.gmail.com>
Message-ID: <OFBB44528F.DF3F34A7-ON85257D74.004D3442-85257D74.004E4A6C@ria.buffalo.edu>

The distribution of the statistic $ndf * r^2 / (1-r^2)$ with  the true 
value $\rho = zero$ follows an $F(1,ndf)$ distribution.
So the t-test is the correct test for $\rho=0$. 
Fisher's z is an asymptotically normal  transformation for any value of 
$\rho$. 
Thus  Fisher's z is better for testing $\rho= \rho_0 $ or $\rho_1 = 
\rho_2$.
The two statistics will not be equivalent at $\rho=0$ because the 
statistics are based on different assumptions.




Jeremy Miles <jeremy.miles at gmail.com> 
Sent by: r-help-bounces at r-project.org
10/16/2014 07:32 PM

To
r-help <r-help at r-project.org>, 
cc

Subject
[R] Difference betweeen cor.test() and formula everyone says to use






I'm trying to understand how cor.test() is calculating the p-value of
a correlation. It gives a p-value based on t, but every text I've ever
seen gives the calculation based on z.

For example:
> data(cars)
> with(cars[1:10, ], cor.test(speed, dist))

Pearson's product-moment correlation

data:  speed and dist
t = 2.3893, df = 8, p-value = 0.04391
alternative hypothesis: true correlation is not equal to 0
95 percent confidence interval:
 0.02641348 0.90658582
sample estimates:
      cor
0.6453079

But when I use the regular formula:
> r <- cor(cars[1:10, ])[1, 2]
> r.z <- fisherz(r)
> se <- se <- 1/sqrt(10 - 3)
> z <- r.z / se
> (1 - pnorm(z))*2
[1] 0.04237039

My p-value is different.  The help file for cor.test doesn't (seem to)
have any reference to this, and I can see in the source code that it
is doing something different. I'm just not sure what.

Thanks,

Jeremy

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide 
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From rainersachs at berkeley.edu  Fri Oct 17 20:57:00 2014
From: rainersachs at berkeley.edu (Rainer K. SACHS)
Date: Fri, 17 Oct 2014 11:57:00 -0700
Subject: [R] Microsoft fighting against cxxfunction() and winning
Message-ID: <CA+G8hjwmFR55=-NBOfArbQ13oc0+Rxr2Kw_izWktaVM4ZF4ZTQ@mail.gmail.com>

Running Windows 7, 64 bit (but also including, I think, 32 bit R files)
RStudio 0.98.501
win-library 3.1

Getting error messages, probably related to add_path, for the
following example script; I did look within RStudio and on the
internet but can't understand the errors, let alone fix them, so any
hints would be appreciated.

library(inline)
library(Rcpp)
library(devtools)
f2 <- cxxfunction( signature(x = "integer", y = "numeric" ) , '
      return wrap( as<int>(x) * as<double>(y) ) ;
    ', plugin = "Rcpp" )
fx( 2L, 5 )
# add_path("Rtools\\bin",after=0)
# add_path("Rtools\\gcc-4.6.3\\bin",after=1)
# get_path()

1) If I run as is, the error message is:
Error in compileCode(f, code, language = language, verbose = verbose) :
  Compilation ERROR, function(s)/method(s) not created! Warning message:
running command 'make -f "C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf" -f
"C:/PROGRA~1/R/R-31~1.1/share/make/winshlib.mk"
SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
SHLIB="file1a2c862738.dll" WIN=64 TCLBIN=64
OBJECTS="file1a2c862738.o"' had status 127
In addition: Warning message:
running command 'C:/PROGRA~1/R/R-31~1.1/bin/x64/R CMD SHLIB
file1a2c862738.cpp 2> file1a2c862738.cpp.err.txt' had status 1

2) If I uncomment the commented lines I get a longer, more
interesting, even less comprehensible error message:
Error in compileCode(f, code, language = language, verbose = verbose) :
  Compilation ERROR, function(s)/method(s) not created! cygwin warning:
  MS-DOS style path detected: C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf
  Preferred POSIX equivalent is:
/cygdrive/c/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf
  CYGWIN environment variable option "nodosfilewarning" turns off this warning.
  Consult the user's guide for more details about POSIX paths:
    http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
Syntax error: EOF in backquote substitution
make: *** [file20681e531a0b.o] Error 2
Warning message:
running command 'make -f "C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf" -f
"C:/PROGRA~1/R/R-31~1.1/share/make/winshlib.mk"
SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
SHLIB="file20681e531a0b.dll" WIN=64 TCLBIN=64
OBJECTS="file20681e531a0b.o"' had status 2
In addition: Warning message:
running command 'C:/PROGRA~1/R/R-31~1.1/bin/x64/R CMD SHLIB
file20681e531a0b.cpp 2> file20681e531a0b.cpp.err.txt' had status 1
>

3) If I try to read cygwin-ug-net/using.html they don't seem to
address 64 bit Windows.

Any suggestions? Thank you, Ray Sachs


From Gerrit.Eichner at math.uni-giessen.de  Fri Oct 17 22:39:26 2014
From: Gerrit.Eichner at math.uni-giessen.de (Gerrit Eichner)
Date: Fri, 17 Oct 2014 22:39:26 +0200 (MEST)
Subject: [R]  [survMisc]: error message in examples of comp()
Message-ID: <Pine.SOC.4.64.1410172229140.9057@solcom.hrz.uni-giessen.de>

Hello, list members,

I have tried to contact the maintainer of the survMisc package, but my 
message could not be delivered. I can't get survMisc package to work as 
expected or documented, respectively. Maybe one of you has an idea 
regarding the following problem:

When, e.g., trying to executed the first few lines of code in the examples 
section of comp() (one of the package functions), i.e.,

> data(kidney,package="KMsurv")
> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney)
> comp(s1)


I receive the following error message:

Error in parse(text = t2) : <text>:1:8: unexpected input
1: paste( ``
             ^


Could this be an encoding-related issue inside the code? Does somebody 
have an idea where to look for a solution for this problem?

Below you'll find my survMisc version and R session info. Thanks for any 
support!

  Kind regards  --  Gerrit

---------------------------------------------------------------------
Dr. Gerrit Eichner                   Mathematical Institute, Room 212
gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
---------------------------------------------------------------------


> citation( "survMisc")

To cite package .survMisc. in publications use:

   Chris Dardis (2014). survMisc: Miscellaneous functions for survival
   data.. R package version 0.4.2.
   http://CRAN.R-project.org/package=survMisc


> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
[3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
[5] LC_TIME=German_Germany.1252

attached base packages:
[1] splines   stats     graphics  grDevices utils     datasets  methods
[8] base

other attached packages:
[1] survMisc_0.4.2   rpart_4.1-8      data.table_1.9.2 ggplot2_1.0.0
[5] survival_2.37-7  fortunes_1.5-2

loaded via a namespace (and not attached):
  [1] colorspace_1.2-4 digest_0.6.4     gam_1.09.1       grid_3.1.1
  [5] gtable_0.1.2     km.ci_0.5-2      KMsurv_0.1-5     MASS_7.3-33
  [9] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     Rcpp_0.11.2
[13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1


From dwinsemius at comcast.net  Sat Oct 18 02:34:34 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Oct 2014 17:34:34 -0700
Subject: [R] [survMisc]: error message in examples of comp()
In-Reply-To: <Pine.SOC.4.64.1410172229140.9057@solcom.hrz.uni-giessen.de>
References: <Pine.SOC.4.64.1410172229140.9057@solcom.hrz.uni-giessen.de>
Message-ID: <BD6D05EB-FBFE-4E0B-ACC4-CA9A5D0C4FF8@comcast.net>


On Oct 17, 2014, at 1:39 PM, Gerrit Eichner wrote:

> Hello, list members,
> 
> I have tried to contact the maintainer of the survMisc package, but my message could not be delivered. I can't get survMisc package to work as expected or documented, respectively. Maybe one of you has an idea regarding the following problem:
> 
> When, e.g., trying to executed the first few lines of code in the examples section of comp() (one of the package functions), i.e.,
> 
>> data(kidney,package="KMsurv")
>> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney)
>> comp(s1)
> 
> 
> I receive the following error message:
> 
> Error in parse(text = t2) : <text>:1:8: unexpected input
> 1: paste( ``
>            ^

I get the same error on a Mac in an English locale. I'm afraid the code in the offending function `.getTne` appears somewhat cobbled together. When I try to debug, I get a single row, 1920 column matrix for n1 which is numeric with all entries == 1. Object `t1` cannot be found.

{
    s <- Es <- .SD <- NULL
    n1 <- names(dt1)
    f1 <- function(x) paste(dQuote(paste(x, "=", sep = "")), 
        ", get(", dQuote(x), ")", sep = "")
    t1 <- paste(sapply(n1, f1), sep = ",")
    if (length(t1) > 1) {
        t1[2:length(t1)] <- sub("\"", "\"_", t1[2:length(t1)], 
            fixed = TRUE)
    }
    t1 <- paste(t1, collapse = ",")
    t2 <- paste("paste(", t1, ", sep='')")

# next line throw the error.

    p1 <- parse(text = t2)
    q <- quote(eval(p1))
    dt1[, `:=`("s", as.factor(eval(q, envir = .SD)))]
    stopifnot(attr(model.response(mf), "type") == "right")
    y <- data.table(unclass(model.response(mf, "numeric")))

I'm afraid I have been o help.

-- 
David.
> 
> 
> Could this be an encoding-related issue inside the code? Does somebody have an idea where to look for a solution for this problem?
> 
> Below you'll find my survMisc version and R session info. Thanks for any support!
> 
> Kind regards  --  Gerrit
> 
> ---------------------------------------------------------------------
> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
> ---------------------------------------------------------------------
> 
> 
>> citation( "survMisc")
> 
> To cite package .survMisc. in publications use:
> 
>  Chris Dardis (2014). survMisc: Miscellaneous functions for survival
>  data.. R package version 0.4.2.
>  http://CRAN.R-project.org/package=survMisc
> 
> 
>> sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
> [5] LC_TIME=German_Germany.1252
> 
> attached base packages:
> [1] splines   stats     graphics  grDevices utils     datasets  methods
> [8] base
> 
> other attached packages:
> [1] survMisc_0.4.2   rpart_4.1-8      data.table_1.9.2 ggplot2_1.0.0
> [5] survival_2.37-7  fortunes_1.5-2
> 
> loaded via a namespace (and not attached):
> [1] colorspace_1.2-4 digest_0.6.4     gam_1.09.1       grid_3.1.1
> [5] gtable_0.1.2     km.ci_0.5-2      KMsurv_0.1-5     MASS_7.3-33
> [9] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     Rcpp_0.11.2
> [13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Sat Oct 18 02:57:26 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 17 Oct 2014 17:57:26 -0700
Subject: [R] [survMisc]: error message in examples of comp()
In-Reply-To: <BD6D05EB-FBFE-4E0B-ACC4-CA9A5D0C4FF8@comcast.net>
References: <Pine.SOC.4.64.1410172229140.9057@solcom.hrz.uni-giessen.de>
	<BD6D05EB-FBFE-4E0B-ACC4-CA9A5D0C4FF8@comcast.net>
Message-ID: <CAF8bMcb3uqxag0Fsq20CFjumtM9C1G=mHdez+vN_VuJt_D7OZw@mail.gmail.com>

If you execute the command
  options(useFancyQuotes=FALSE)
before calling comp(s1) that error should go away.

dQuote() was being used inappropriately - its value depends on the
option "useFancyQuotes" so should really only be used for messages or
text that machines don't have to parse.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Fri, Oct 17, 2014 at 5:34 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Oct 17, 2014, at 1:39 PM, Gerrit Eichner wrote:
>
>> Hello, list members,
>>
>> I have tried to contact the maintainer of the survMisc package, but my message could not be delivered. I can't get survMisc package to work as expected or documented, respectively. Maybe one of you has an idea regarding the following problem:
>>
>> When, e.g., trying to executed the first few lines of code in the examples section of comp() (one of the package functions), i.e.,
>>
>>> data(kidney,package="KMsurv")
>>> s1 <- survfit(Surv(time=time, event=delta) ~ type, data=kidney)
>>> comp(s1)
>>
>>
>> I receive the following error message:
>>
>> Error in parse(text = t2) : <text>:1:8: unexpected input
>> 1: paste( ``
>>            ^
>
> I get the same error on a Mac in an English locale. I'm afraid the code in the offending function `.getTne` appears somewhat cobbled together. When I try to debug, I get a single row, 1920 column matrix for n1 which is numeric with all entries == 1. Object `t1` cannot be found.
>
> {
>     s <- Es <- .SD <- NULL
>     n1 <- names(dt1)
>     f1 <- function(x) paste(dQuote(paste(x, "=", sep = "")),
>         ", get(", dQuote(x), ")", sep = "")
>     t1 <- paste(sapply(n1, f1), sep = ",")
>     if (length(t1) > 1) {
>         t1[2:length(t1)] <- sub("\"", "\"_", t1[2:length(t1)],
>             fixed = TRUE)
>     }
>     t1 <- paste(t1, collapse = ",")
>     t2 <- paste("paste(", t1, ", sep='')")
>
> # next line throw the error.
>
>     p1 <- parse(text = t2)
>     q <- quote(eval(p1))
>     dt1[, `:=`("s", as.factor(eval(q, envir = .SD)))]
>     stopifnot(attr(model.response(mf), "type") == "right")
>     y <- data.table(unclass(model.response(mf, "numeric")))
>
> I'm afraid I have been o help.
>
> --
> David.
>>
>>
>> Could this be an encoding-related issue inside the code? Does somebody have an idea where to look for a solution for this problem?
>>
>> Below you'll find my survMisc version and R session info. Thanks for any support!
>>
>> Kind regards  --  Gerrit
>>
>> ---------------------------------------------------------------------
>> Dr. Gerrit Eichner                   Mathematical Institute, Room 212
>> gerrit.eichner at math.uni-giessen.de   Justus-Liebig-University Giessen
>> Tel: +49-(0)641-99-32104          Arndtstr. 2, 35392 Giessen, Germany
>> Fax: +49-(0)641-99-32109        http://www.uni-giessen.de/cms/eichner
>> ---------------------------------------------------------------------
>>
>>
>>> citation( "survMisc")
>>
>> To cite package .survMisc. in publications use:
>>
>>  Chris Dardis (2014). survMisc: Miscellaneous functions for survival
>>  data.. R package version 0.4.2.
>>  http://CRAN.R-project.org/package=survMisc
>>
>>
>>> sessionInfo()
>> R version 3.1.1 (2014-07-10)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=German_Germany.1252  LC_CTYPE=German_Germany.1252
>> [3] LC_MONETARY=German_Germany.1252 LC_NUMERIC=C
>> [5] LC_TIME=German_Germany.1252
>>
>> attached base packages:
>> [1] splines   stats     graphics  grDevices utils     datasets  methods
>> [8] base
>>
>> other attached packages:
>> [1] survMisc_0.4.2   rpart_4.1-8      data.table_1.9.2 ggplot2_1.0.0
>> [5] survival_2.37-7  fortunes_1.5-2
>>
>> loaded via a namespace (and not attached):
>> [1] colorspace_1.2-4 digest_0.6.4     gam_1.09.1       grid_3.1.1
>> [5] gtable_0.1.2     km.ci_0.5-2      KMsurv_0.1-5     MASS_7.3-33
>> [9] munsell_0.4.2    plyr_1.8.1       proto_0.3-10     Rcpp_0.11.2
>> [13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From chichi.shu at hotmail.com  Fri Oct 17 22:21:27 2014
From: chichi.shu at hotmail.com (Chichi Shu)
Date: Fri, 17 Oct 2014 16:21:27 -0400
Subject: [R] Comparing values of different columns: Error: level sets of
	factors are different
Message-ID: <BLU177-DS1161AAC664D30C6F6FA4ED8FA80@phx.gbl>

Hi, R listers,
I??m trying to compare a value of a row in a column to values of previous rows in another column in a loop. ??i?? is just from first row to the last row. j is an another looping controller indicating the rows that row[i] will be compared to and j will be rows before row[i]. I want to compare phone_1[i] with phone_2[j] and vise versa.
for (i in 1: nrow(df)) {
  if (df$Incremental[i] == 1) {mark[i] <- 1}
    else {for (j in (i ?C df$Incremental[i] + 1) : (i - 1)) {
      if ((df$Phone_1[i] != "" & df$Phone_1[i] == df$Phone_2[j]) | (df$Phone_2[i] != "" & df$Phone_2[i] == df$Phone_1[j])) {
        mark[i] <- mark[j]}
          else {mark[i] <- mark[i-1] + 1}
                                                                                   }
}
However I??m getting an error with phone_1[i] and phone_2[j], indicating that ??level sets of factors are different??. I??m not sure what I need to do to fix it.
Thanks!
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Oct 18 05:36:22 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 17 Oct 2014 20:36:22 -0700
Subject: [R] Comparing values of different columns: Error: level sets of
	factors are different
In-Reply-To: <BLU177-DS1161AAC664D30C6F6FA4ED8FA80@phx.gbl>
References: <BLU177-DS1161AAC664D30C6F6FA4ED8FA80@phx.gbl>
Message-ID: <E2503483-DA7C-420E-9435-233DB27D8364@comcast.net>


On Oct 17, 2014, at 1:21 PM, Chichi Shu wrote:

> Hi, R listers,
> I??m trying to compare a value of a row in a column to values of previous rows in another column in a loop. ??i?? is just from first row to the last row. j is an another looping controller indicating the rows that row[i] will be compared to and j will be rows before row[i]. I want to compare phone_1[i] with phone_2[j] and vise versa.
> for (i in 1: nrow(df)) {
>  if (df$Incremental[i] == 1) {mark[i] <- 1}
>    else {for (j in (i ?C df$Incremental[i] + 1) : (i - 1)) {
>      if ((df$Phone_1[i] != "" & df$Phone_1[i] == df$Phone_2[j]) | (df$Phone_2[i] != "" & df$Phone_2[i] == df$Phone_1[j])) {
>        mark[i] <- mark[j]}
>          else {mark[i] <- mark[i-1] + 1}
>                                                                                   }
> }
> However I??m getting an error with phone_1[i] and phone_2[j], indicating that ??level sets of factors are different??. I??m not sure what I need to do to fix it.

Factor fixing. An ancient, aRcane sport.

Perhaps:
lev2 <- unique( c( levels(phone_1), levels(phone_2) ) )
phone_1 <- factor(phone_1, levels=lev2)
phone_2 <- factor(phone_2, levels=lev2)




> Thanks!
> 	[[alternative HTML version deleted]]

And HTML posting is not well supported. Learn to post in that most ancient of computer tongues, plain text.

> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 

David Winsemius
Alameda, CA, USA


From rhelpmaillist at 163.com  Sat Oct 18 12:41:02 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 18 Oct 2014 18:41:02 +0800 (CST)
Subject: [R]  how to judge a virable  is a integer?
Message-ID: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>



Dear usRers,
? ?I want to judge virable is or not a integer?
? e.g. ?is.integer(1) ?FALSE ? because it is a numeric, but i want it's true.
as.integer may not be used. because i don't know a is 1 or 1.1.





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From bhh at xs4all.nl  Sat Oct 18 12:58:48 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 18 Oct 2014 12:58:48 +0200
Subject: [R] how to judge a virable  is a integer?
In-Reply-To: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
Message-ID: <A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>


On 18-10-2014, at 12:41, PO SU <rhelpmaillist at 163.com> wrote:

> 
> 
> Dear usRers,
>    I want to judge virable is or not a integer?
>   e.g.  is.integer(1)  FALSE   because it is a numeric, but i want it's true.
> as.integer may not be used. because i don't know a is 1 or 1.1.
> 

is.integer is surely what you need if you wish to test if a variable is integer.
See this

# a <- 1
# b <- 1L

# is.integer(a)
[1] FALSE

# is.integer(b)
[1] TRUE

See the help for is.integer to see how you can test for a wholenumber, which might be what you want.

Berend


From rhelpmaillist at 163.com  Sat Oct 18 13:21:41 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 18 Oct 2014 19:21:41 +0800 (CST)
Subject: [R] how to judge a virable  is a integer?
In-Reply-To: <A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
Message-ID: <25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>


But i use a<-10/b , ?b is some value ,may be ?5, maybe 5.5?
not in the form ?xxL ,so how can i do in the situation to judge a ?






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-10-18 18:58:48, "Berend Hasselman" <bhh at xs4all.nl> wrote:
>
>On 18-10-2014, at 12:41, PO SU <rhelpmaillist at 163.com> wrote:
>
>> 
>> 
>> Dear usRers,
>>    I want to judge virable is or not a integer?
>>   e.g.  is.integer(1)  FALSE   because it is a numeric, but i want it's true.
>> as.integer may not be used. because i don't know a is 1 or 1.1.
>> 
>
>is.integer is surely what you need if you wish to test if a variable is integer.
>See this
>
># a <- 1
># b <- 1L
>
># is.integer(a)
>[1] FALSE
>
># is.integer(b)
>[1] TRUE
>
>See the help for is.integer to see how you can test for a wholenumber, which might be what you want.
>
>Berend
>

From S.Ellison at LGCGroup.com  Sat Oct 18 14:10:09 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Sat, 18 Oct 2014 13:10:09 +0100
Subject: [R] how to judge a virable  is a integer?
In-Reply-To: <25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
Message-ID: <0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>

> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
If you do floating point arithmetic on integers you'll usually get floating point answers, including the 5.0.

See FAQ 7.31 for the usual floating point problem, and ?all.equal for the usual answer to it. You could see if a result is close to an integer by,for example, using all.equal to compare it to itself after rounding.

S

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From rhelpmaillist at 163.com  Sat Oct 18 16:25:29 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sat, 18 Oct 2014 22:25:29 +0800 (CST)
Subject: [R] how to judge a virable  is a integer?
In-Reply-To: <0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
Message-ID: <13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>


It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but deeply, when i want to know 1 is an integer, ?there seems no easy way to get the answer.
So, is there anyone happen to know it?




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:
>> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
>If you do floating point arithmetic on integers you'll usually get floating point answers, including the 5.0.
>
>See FAQ 7.31 for the usual floating point problem, and ?all.equal for the usual answer to it. You could see if a result is close to an integer by,for example, using all.equal to compare it to itself after rounding.
>
>S
>
>*******************************************************************
>This email and any attachments are confidential. Any use, copying or
>disclosure other than by the intended recipient is unauthorised. If 
>you have received this message in error, please notify the sender 
>immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
>and delete this message and any copies from your computer and network. 
>LGC Limited. Registered in England 2991879. 
>Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From sergio.fonda99 at gmail.com  Sat Oct 18 16:40:41 2014
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Sat, 18 Oct 2014 16:40:41 +0200
Subject: [R] how to judge a virable is a integer?
In-Reply-To: <13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
Message-ID: <CAJRuHoo-r8aJKNWNcGdLRTMmZn_UD1NhJKM5+u-FGqGyYEZFxg@mail.gmail.com>

Don't know if this trivial reply will be useful

>a=5
>is.numeric(a)
>[1] TRUE
>b="try"
>is.numeric(b)
>[1] FALSE
 Il 18/ott/2014 16:29 "PO SU" <rhelpmaillist at 163.com> ha scritto:

>
> It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but
> deeply, when i want to know 1 is an integer,  there seems no easy way to
> get the answer.
> So, is there anyone happen to know it?
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:
> >> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
> >If you do floating point arithmetic on integers you'll usually get
> floating point answers, including the 5.0.
> >
> >See FAQ 7.31 for the usual floating point problem, and ?all.equal for the
> usual answer to it. You could see if a result is close to an integer by,for
> example, using all.equal to compare it to itself after rounding.
> >
> >S
> >
> >*******************************************************************
> >This email and any attachments are confidential. Any use, copying or
> >disclosure other than by the intended recipient is unauthorised. If
> >you have received this message in error, please notify the sender
> >immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
> >and delete this message and any copies from your computer and network.
> >LGC Limited. Registered in England 2991879.
> >Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sergio.fonda99 at gmail.com  Sat Oct 18 16:48:15 2014
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Sat, 18 Oct 2014 16:48:15 +0200
Subject: [R] how to judge a virable is a integer?
In-Reply-To: <13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
Message-ID: <CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>

Sorry for my previous hurry misunderstanding.
Try this link:
http://stackoverflow.com/questions/3476782/how-to-check-if-the-number-is-integer


2014-10-18 16:25 GMT+02:00 PO SU <rhelpmaillist at 163.com>:

>
> It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but
> deeply, when i want to know 1 is an integer,  there seems no easy way to
> get the answer.
> So, is there anyone happen to know it?
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:
> >> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
> >If you do floating point arithmetic on integers you'll usually get
> floating point answers, including the 5.0.
> >
> >See FAQ 7.31 for the usual floating point problem, and ?all.equal for the
> usual answer to it. You could see if a result is close to an integer by,for
> example, using all.equal to compare it to itself after rounding.
> >
> >S
> >
> >*******************************************************************
> >This email and any attachments are confidential. Any use, copying or
> >disclosure other than by the intended recipient is unauthorised. If
> >you have received this message in error, please notify the sender
> >immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
> >and delete this message and any copies from your computer and network.
> >LGC Limited. Registered in England 2991879.
> >Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sergio.fonda99 at gmail.com  Sat Oct 18 17:02:45 2014
From: sergio.fonda99 at gmail.com (Sergio Fonda)
Date: Sat, 18 Oct 2014 17:02:45 +0200
Subject: [R] how to judge a virable is a integer?
In-Reply-To: <13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
Message-ID: <CAJRuHoozDbsJyG9V1z4hQo2d-Tk7x7bW5qcomTFBuN3h3rksKg@mail.gmail.com>

Further and last trial:

> a=5.102> a-floor(a)==0[1] FALSE> a=5.9> a-floor(a)==0[1] FALSE> a=19> a-floor(a)==0[1] TRUE

All the best,

Sergio



2014-10-18 16:25 GMT+02:00 PO SU <rhelpmaillist at 163.com>:

>
> It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but
> deeply, when i want to know 1 is an integer,  there seems no easy way to
> get the answer.
> So, is there anyone happen to know it?
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:
> >> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
> >If you do floating point arithmetic on integers you'll usually get
> floating point answers, including the 5.0.
> >
> >See FAQ 7.31 for the usual floating point problem, and ?all.equal for the
> usual answer to it. You could see if a result is close to an integer by,for
> example, using all.equal to compare it to itself after rounding.
> >
> >S
> >
> >*******************************************************************
> >This email and any attachments are confidential. Any use, copying or
> >disclosure other than by the intended recipient is unauthorised. If
> >you have received this message in error, please notify the sender
> >immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
> >and delete this message and any copies from your computer and network.
> >LGC Limited. Registered in England 2991879.
> >Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From anna.zakrisson at su.se  Sat Oct 18 06:59:10 2014
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Sat, 18 Oct 2014 04:59:10 +0000
Subject: [R] seqinr ?: Splitting a factor name into several columns.
 Dealing with metabarcoding data.
In-Reply-To: <CA+vqiLFwVHfMnc6xzOx9J8tvN3rU_gwHSEdt5oWQUPR01xAiyg@mail.gmail.com>
References: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>,
	<CA+vqiLFwVHfMnc6xzOx9J8tvN3rU_gwHSEdt5oWQUPR01xAiyg@mail.gmail.com>
Message-ID: <11019DCE9B47004F90B2D9C62FF157921BD8F25F@ebox-prod-srv06.win.su.se>

Thank you! That was a easy and fast solution!

May I post a follow-up question? (I am not sure if this would rather should be posted as a new question, but I post it here and then I can re-post it if this is the wrong place to ask this). I am ever so grateful for your help!
/Anna


######################### FOLLOW-UP QUESTION ####################################

df1 <- data.frame(cbind(Identifier = c("M123.B23.VJHJ", "M123.B24.VJHJ",
                                       "M123.B23.VLKE", "M123.B23.HKJH",
                                       "M123.B24.LKJH"),
                                       Sequence = c("ATATATATATA", "ATATATATATA",
                                                    "ATATAGCATATA", "ATATATAGGGTA",
                                                    "ATCGCGCGAATA"))) 



# as a follow-up question:
# How can I split the identifier in df1 above into several columns based on the 
# separating dots? The real data includes thousands of rows.
# This is what I want it to look like in the end:

df1_solution <- data.frame(cbind(Identifier1 = c("M123", "M123",
                                       "M123", "M123",
                                       "M123"),
                        Identifier2 = c("B23", "B24", "B23", "B23", "B24"),
                        Identifier3 = c("VJHJ", "VJHJ", "VLKE", "HKJH", "LKJH"),
                        Sequence = c("ATATATATATA", "ATATATATATA",
                                     "ATATAGCATATA", "ATATATAGGGTA",
                                     "ATCGCGCGAATA")))

# I am very grateful for your help! I am no whiz at R and everything I know
# is self-taught. Therefore, some basics can turn out to be quite some
# obsatcles for me. 
# /Anna

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>

________________________________________
From: Ista Zahn [istazahn at gmail.com]
Sent: 13 October 2014 15:42
To: Anna Zakrisson Braeunlich
Cc: r-help at r-project.org
Subject: Re: [R] seqinr ?: Splitting a factor name into several columns. Dealing with metabarcoding data.

Hi Anna,


On Sun, Oct 12, 2014 at 3:24 AM, Anna Zakrisson Braeunlich
<anna.zakrisson at su.se> wrote:
> Hi,
>
> I have a question how to split a factor name into different columns. I have metabarcoding data and need to merge the FASTA-file with the taxonomy- and counttable files (dataframes). To be able to do this merge, I need to isolate the common identifier, that unfortunately is baked in with a lot of other labels in the factor name eg:
> sequence identifier: M01271_77_000000000.A8J0P_1_1101_10150_1525.1.322519.sample_1.sample_2
>
> I want to split this name at every "." to get several columns:
> column1: M01271_77_000000000
> column2: A8J0P_1_1101_10150_1525
> column3: 1
> column4: 322519
> column5: sample_1
> column6: sample_2
>
> I must add that I have no influence on how these names are given. This is how thay are supplied from Illumina Miseq. I just need to be able to deal with it.
>
> Here is some extremely simplified dummy data to further show the issue at hand:
>
> df1 <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>                   Z.identifierA.B1298712 = factor(rep(LETTERS[1:2], each = 5)))
> df2 <- data.frame(cbind(B = 13:22, K = rnorm(10)),
>                   Q.identifierA.B4668726 = factor(rep(LETTERS[1:2], each = 5)))
>
> # I have metabarcoding data with one FASTA-file, one count table and one taxonomy file
> # Above dummy data is just showing the issue at hand. I want to be able to merge my three
> # original data frames (here, the dummy data is only two dataframes). The problem is that
> # the only identifier that is commmon for the dataframes is "hidden" in the
> # factor name eg: Z.identifierA.1298712 and Q.identifierA.4668726. I hence need to be able
> # to split this name up into different columns to get "identifierA" alone as one column name
> # Then I can merge the dataframes.
> # How can I do this in R. I know that it can be done in excel, but I would like to
> # produce a complete R-script to get a fast pipeline and avoid copy and paste errors.
> # This is what I want it to look:
>
> df1.goal <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>                   Z = factor(rep(LETTERS[1:2], each = 5)),
>                   identifierA = factor(rep(LETTERS[1:2], each = 5)),
>                   B1298712 = factor(rep(LETTERS[1:2], each = 5)))

Use strsplit to separate the components, something like

separateNames <- strsplit(names(df1)[3], split = "\\.")[[1]]
for(name in separateNames) {
    df1[[name]] <- df1[[3]]
}
df1[[3]] <- NULL

Best,
Ista

>
> # Many thank's and with kind regards
> Anna Zakrisson
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ajss_alt at yahoo.com  Sat Oct 18 09:59:23 2014
From: ajss_alt at yahoo.com (Amarjit Singh)
Date: Sat, 18 Oct 2014 07:59:23 +0000 (UTC)
Subject: [R] command for plm
Message-ID: <1948380769.138704.1413619163479.JavaMail.yahoo@jws10973.mail.sg3.yahoo.com>

Dear allI am trying to carry out step-wise panel regression analysis by making adaptation in the use of plm package. Say, I am trying to regress the explained variable (DEP) on 3 explanatory variables (EX1, EX2, EX3) using a panel data set (dat). Of course, the required set of instructions would be:require(plm)reg <- plm(DEP ~ EX1 + EX2 + EX3, data = dat, method = "within") ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?... (A)But, what I wish to do (for the purpose of carrying out the analysis iteratively) is as follows:dep <- "DEP"exp <- c("EX1", "EX2", "EX3")and then use somehow these dep and exp to get a ?statement compatible with (A). I tried the following
frm <- as.formula(paste(dep, "~", exp))
reg <- plm(frm, data = dat, method = "within)But it did not work properly. I could get the output only in respect of DEP ~ EX1, whereas I need the same in respect of?DEP ~ EX1 + EX2 + EX3.Kindly help. ?RegardsAmarjit Singh
	[[alternative HTML version deleted]]


From umairdurrani at outlook.com  Sat Oct 18 16:57:31 2014
From: umairdurrani at outlook.com (umair durrani)
Date: Sat, 18 Oct 2014 19:57:31 +0500
Subject: [R] Smoothing Data-dplyr
Message-ID: <BLU170-W123602022521950F6A05199C9A90@phx.gbl>

Please note that I have already asked this question on stackoverflow.com but did not get a satisfactory answer. I have a data set containing velocities of 2169 vehicles recorded at 
intervals of 0.1 seconds. So, there are many rows for an individual 
vehicle. Here I am reproducing the data only for the vehicle # 2:   
> dput(uma)
structure(list(Vehicle.ID = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
2, 2), Frame.ID = 13:445, Vehicle.velocity = c(40, 40, 40, 40, 
40, 40, 40, 40.02, 40.03, 39.93, 39.61, 39.14, 38.61, 38.28, 
38.42, 38.78, 38.92, 38.54, 37.51, 36.34, 35.5, 35.08, 34.96, 
34.98, 35, 34.99, 34.98, 35.1, 35.49, 36.2, 37.15, 38.12, 38.76, 
38.95, 38.95, 38.99, 39.18, 39.34, 39.2, 38.89, 38.73, 38.88, 
39.28, 39.68, 39.94, 40.02, 40, 39.99, 39.99, 39.65, 38.92, 38.52, 
38.8, 39.72, 40.76, 41.07, 40.8, 40.59, 40.75, 41.38, 42.37, 
43.37, 44.06, 44.29, 44.13, 43.9, 43.92, 44.21, 44.59, 44.87, 
44.99, 45.01, 45.01, 45, 45, 45, 44.79, 44.32, 43.98, 43.97, 
44.29, 44.76, 45.06, 45.36, 45.92, 46.6, 47.05, 47.05, 46.6, 
45.92, 45.36, 45.06, 44.96, 44.97, 44.99, 44.99, 44.99, 44.99, 
45.01, 45.02, 44.9, 44.46, 43.62, 42.47, 41.41, 40.72, 40.49, 
40.6, 40.76, 40.72, 40.5, 40.38, 40.43, 40.38, 39.83, 38.59, 
37.02, 35.73, 35.04, 34.85, 34.91, 34.99, 34.99, 34.97, 34.96, 
34.98, 35.07, 35.29, 35.54, 35.67, 35.63, 35.53, 35.53, 35.63, 
35.68, 35.55, 35.28, 35.06, 35.09, 35.49, 36.22, 37.08, 37.8, 
38.3, 38.73, 39.18, 39.62, 39.83, 39.73, 39.58, 39.57, 39.71, 
39.91, 40, 39.98, 39.97, 40.08, 40.38, 40.81, 41.27, 41.69, 42.2, 
42.92, 43.77, 44.49, 44.9, 45.03, 45.01, 45, 45, 45, 45, 45, 
45, 45, 45, 45, 45, 45, 44.99, 45.03, 45.26, 45.83, 46.83, 48.2, 
49.68, 50.95, 51.83, 52.19, 52, 51.35, 50.38, 49.38, 48.63, 48.15, 
47.87, 47.78, 48.01, 48.63, 49.52, 50.39, 50.9, 50.96, 50.68, 
50.3, 50.05, 49.94, 49.87, 49.82, 49.82, 49.88, 49.96, 50, 50, 
49.98, 49.98, 50.16, 50.64, 51.43, 52.33, 53.01, 53.27, 53.22, 
53.25, 53.75, 54.86, 56.36, 57.64, 58.28, 58.29, 57.94, 57.51, 
57.07, 56.64, 56.43, 56.73, 57.5, 58.27, 58.55, 58.32, 57.99, 
57.89, 57.92, 57.74, 57.12, 56.24, 55.51, 55.1, 54.97, 54.98, 
55.02, 55.03, 54.86, 54.3, 53.25, 51.8, 50.36, 49.41, 49.06, 
49.17, 49.4, 49.51, 49.52, 49.51, 49.45, 49.24, 48.84, 48.29, 
47.74, 47.33, 47.12, 47.06, 47.07, 47.08, 47.05, 47.04, 47.25, 
47.68, 47.93, 47.56, 46.31, 44.43, 42.7, 41.56, 41.03, 40.92, 
40.92, 40.98, 41.19, 41.45, 41.54, 41.32, 40.85, 40.37, 40.09, 
39.99, 39.99, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 39.98, 
39.97, 40.1, 40.53, 41.36, 42.52, 43.71, 44.57, 45.01, 45.1, 
45.04, 45, 45, 45, 45, 45, 45, 44.98, 44.97, 45.08, 45.39, 45.85, 
46.2, 46.28, 46.21, 46.29, 46.74, 47.49, 48.35, 49.11, 49.63, 
49.89, 49.94, 49.97, 50.14, 50.44, 50.78, 51.03, 51.12, 51.05, 
50.85, 50.56, 50.26, 50.06, 50.1, 50.52, 51.36, 52.5, 53.63, 
54.46, 54.9, 55.03, 55.09, 55.23, 55.35, 55.35, 55.23, 55.07, 
54.99, 54.98, 54.97, 55.06, 55.37, 55.91, 56.66, 57.42, 58.07, 
58.7, 59.24, 59.67, 59.95, 60.02, 60, 60, 60, 60, 60, 60.01, 
60.06, 60.23, 60.65, 61.34, 62.17, 62.93, 63.53, 64, 64.41, 64.75, 
65.04, 65.3, 65.57, 65.75, 65.74, 65.66, 65.62, 65.71, 65.91, 
66.1, 66.26, 66.44, 66.61, 66.78, 66.91, 66.99, 66.91, 66.7, 
66.56, 66.6, 66.83, 67.17, 67.45, 67.75, 68.15, 68.64, 69.15, 
69.57, 69.79, 69.79, 69.72, 69.72, 69.81, 69.94, 70, 70.01, 70.02, 
70.03)), row.names = c(NA, 433L), class = "data.frame", .Names = c("Vehicle.ID", 
"Frame.ID", "Vehicle.velocity"))  
I am trying to smooth the data using dplyr. Here is the code:  
 uma <- tbl_df(uma)
    uma <- uma %>%     # take data frame 
      group_by(Vehicle.ID)  %>%  # group by Vehicle ID
      mutate(i = 1:length(Frame.ID), im1 = i-1, Nai = length(Frame.ID) - i,
             Dv = pmin(im1, Nai, 30),
             imDv = i - Dv,
             ipDv = i + Dv) %>%  # finding i, i-1 and Nalpha-i, D, i-D and i+D for location, velocity and acceleration
      ungroup()  
         
    
    umav <- uma %>%
      group_by(Vehicle.ID, Frame.ID) %>%
      do(data.frame(kv = .$imDv:.$ipDv)) %>%
      left_join(x=., y=uma) %>%
      mutate(imk = i - kv, aimk = (-1) * abs(imk), delta = 10, kernel = exp(aimk/delta)) %>%
      ungroup() %>%
      group_by(Vehicle.ID) %>%
      mutate(p = Vehicle.velocity2[match(kv,i)], kernelp = p * kernel) %>%
      ungroup() %>%
      group_by(Vehicle.ID, Frame.ID) %>%
      summarise(Z = sum(kernel), prod = sum(kernelp)) %>%
      mutate(svel = prod/Z) %>%
      ungroup()

The code works but takes 1 hour. I think the delay is caused by do(data.frame(kv = .$imDv:.$ipDv)). Is there any faster way to do this?
 		 	   		  
	[[alternative HTML version deleted]]


From althu07 at gmail.com  Sat Oct 18 17:42:10 2014
From: althu07 at gmail.com (althu07)
Date: Sat, 18 Oct 2014 10:42:10 -0500
Subject: [R] Build a package on one Mac but unable to load this on another
	Mac
Message-ID: <CAKcWPz+WwbaXUUrs=7QTcef02Gs0pG6kAjOXToPsgEK5jK6bJw@mail.gmail.com>

Hi, I build a package on one Mac. I can install the package on another Mac
but it cannot be loaded. The following is the error message.

Error in dyn.load(file, DLLpath = DLLpath, ...) :
unable to load shared object
'/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so':
dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so,
6): Library not loaded: /usr/local/lib/libgfortran.3.dylib
Referenced from:
/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so
Reason: image not found
Error: package or namespace load failed for ?mypkgfe?

If I install the gfortran on the user's Mac, the package can be installed
and loaded successfully. But I don't think this is a good option to solve
this problem as it requires too much on the user's end. Is there anyway to
build the package so that it can be successfully loaded even the Mac
doesn't have gfortran preinstalled?

It seems the Mavericks OS X can load the package but not the Snow Leopard
OS X. I am wondering if this has anything to do with the fact that R for
Snow Leopard doesn't include GNU Fortran.

Thanks!

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Sat Oct 18 17:52:15 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 18 Oct 2014 08:52:15 -0700
Subject: [R] how to judge a virable is a integer?
In-Reply-To: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF8bMcbjeUHEny6NeRjxBM1-O1hvYP-nwyvvVQLMAEo6TGEqxw@mail.gmail.com>

It sounds like you want an 'is.integral' function to tell if a
number acts like a mathematical integer, as opposed to
'is.integer', which tells if a number is stored as a 32-bit
computer integer.  The test will depend on what properties
of mathematical integers you are most interested in.

   is.integral <- function (x)  (floor(x) == x) & (abs(x) + 1 > abs(x))
will return TRUE if x has no fractional part and the number's
putative successor (predecessor if negative) is different than
the number.  That latter test is equivalent (roughly) to log2(abs(x))<53 and
comes into play when you run out of bits in the mantissa of
a double precision number.  (One might want it to return NA in
that case, but I think FALSE works better.)


Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Oct 18, 2014 at 3:41 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
>
> Dear usRers,
>    I want to judge virable is or not a integer?
>   e.g.  is.integer(1)  FALSE   because it is a numeric, but i want it's true.
> as.integer may not be used. because i don't know a is 1 or 1.1.
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sat Oct 18 17:59:10 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 18 Oct 2014 08:59:10 -0700
Subject: [R] Smoothing Data-dplyr
In-Reply-To: <BLU170-W123602022521950F6A05199C9A90@phx.gbl>
References: <BLU170-W123602022521950F6A05199C9A90@phx.gbl>
Message-ID: <AD1DF83B-0F05-4ED4-A487-6A8E3609D03B@comcast.net>


On Oct 18, 2014, at 7:57 AM, umair durrani wrote:

> Please note that I have already asked this question on stackoverflow.com but did not get a satisfactory answer.

You should say what was unsatisfactory about the answer you were offered:
http://stackoverflow.com/questions/26434652/data-smoothing-in-r

You got 3 answers that appeared to be improvements including one using Rcpp that gave you a 6 thousand fold improvement in running time.

-- 
David.

> I have a data set containing velocities of 2169 vehicles recorded at 
> intervals of 0.1 seconds. So, there are many rows for an individual 
> vehicle. Here I am reproducing the data only for the vehicle # 2:   
>> dput(uma)
> structure(list(Vehicle.ID = c(2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 
> 2, 2), Frame.ID = 13:445, Vehicle.velocity = c(40, 40, 40, 40, 
> 40, 40, 40, 40.02, 40.03, 39.93, 39.61, 39.14, 38.61, 38.28, 
> 38.42, 38.78, 38.92, 38.54, 37.51, 36.34, 35.5, 35.08, 34.96, 
> 34.98, 35, 34.99, 34.98, 35.1, 35.49, 36.2, 37.15, 38.12, 38.76, 
> 38.95, 38.95, 38.99, 39.18, 39.34, 39.2, 38.89, 38.73, 38.88, 
> 39.28, 39.68, 39.94, 40.02, 40, 39.99, 39.99, 39.65, 38.92, 38.52, 
> 38.8, 39.72, 40.76, 41.07, 40.8, 40.59, 40.75, 41.38, 42.37, 
> 43.37, 44.06, 44.29, 44.13, 43.9, 43.92, 44.21, 44.59, 44.87, 
> 44.99, 45.01, 45.01, 45, 45, 45, 44.79, 44.32, 43.98, 43.97, 
> 44.29, 44.76, 45.06, 45.36, 45.92, 46.6, 47.05, 47.05, 46.6, 
> 45.92, 45.36, 45.06, 44.96, 44.97, 44.99, 44.99, 44.99, 44.99, 
> 45.01, 45.02, 44.9, 44.46, 43.62, 42.47, 41.41, 40.72, 40.49, 
> 40.6, 40.76, 40.72, 40.5, 40.38, 40.43, 40.38, 39.83, 38.59, 
> 37.02, 35.73, 35.04, 34.85, 34.91, 34.99, 34.99, 34.97, 34.96, 
> 34.98, 35.07, 35.29, 35.54, 35.67, 35.63, 35.53, 35.53, 35.63, 
> 35.68, 35.55, 35.28, 35.06, 35.09, 35.49, 36.22, 37.08, 37.8, 
> 38.3, 38.73, 39.18, 39.62, 39.83, 39.73, 39.58, 39.57, 39.71, 
> 39.91, 40, 39.98, 39.97, 40.08, 40.38, 40.81, 41.27, 41.69, 42.2, 
> 42.92, 43.77, 44.49, 44.9, 45.03, 45.01, 45, 45, 45, 45, 45, 
> 45, 45, 45, 45, 45, 45, 44.99, 45.03, 45.26, 45.83, 46.83, 48.2, 
> 49.68, 50.95, 51.83, 52.19, 52, 51.35, 50.38, 49.38, 48.63, 48.15, 
> 47.87, 47.78, 48.01, 48.63, 49.52, 50.39, 50.9, 50.96, 50.68, 
> 50.3, 50.05, 49.94, 49.87, 49.82, 49.82, 49.88, 49.96, 50, 50, 
> 49.98, 49.98, 50.16, 50.64, 51.43, 52.33, 53.01, 53.27, 53.22, 
> 53.25, 53.75, 54.86, 56.36, 57.64, 58.28, 58.29, 57.94, 57.51, 
> 57.07, 56.64, 56.43, 56.73, 57.5, 58.27, 58.55, 58.32, 57.99, 
> 57.89, 57.92, 57.74, 57.12, 56.24, 55.51, 55.1, 54.97, 54.98, 
> 55.02, 55.03, 54.86, 54.3, 53.25, 51.8, 50.36, 49.41, 49.06, 
> 49.17, 49.4, 49.51, 49.52, 49.51, 49.45, 49.24, 48.84, 48.29, 
> 47.74, 47.33, 47.12, 47.06, 47.07, 47.08, 47.05, 47.04, 47.25, 
> 47.68, 47.93, 47.56, 46.31, 44.43, 42.7, 41.56, 41.03, 40.92, 
> 40.92, 40.98, 41.19, 41.45, 41.54, 41.32, 40.85, 40.37, 40.09, 
> 39.99, 39.99, 40, 40, 40, 40, 40, 40, 40, 40, 40, 40, 39.98, 
> 39.97, 40.1, 40.53, 41.36, 42.52, 43.71, 44.57, 45.01, 45.1, 
> 45.04, 45, 45, 45, 45, 45, 45, 44.98, 44.97, 45.08, 45.39, 45.85, 
> 46.2, 46.28, 46.21, 46.29, 46.74, 47.49, 48.35, 49.11, 49.63, 
> 49.89, 49.94, 49.97, 50.14, 50.44, 50.78, 51.03, 51.12, 51.05, 
> 50.85, 50.56, 50.26, 50.06, 50.1, 50.52, 51.36, 52.5, 53.63, 
> 54.46, 54.9, 55.03, 55.09, 55.23, 55.35, 55.35, 55.23, 55.07, 
> 54.99, 54.98, 54.97, 55.06, 55.37, 55.91, 56.66, 57.42, 58.07, 
> 58.7, 59.24, 59.67, 59.95, 60.02, 60, 60, 60, 60, 60, 60.01, 
> 60.06, 60.23, 60.65, 61.34, 62.17, 62.93, 63.53, 64, 64.41, 64.75, 
> 65.04, 65.3, 65.57, 65.75, 65.74, 65.66, 65.62, 65.71, 65.91, 
> 66.1, 66.26, 66.44, 66.61, 66.78, 66.91, 66.99, 66.91, 66.7, 
> 66.56, 66.6, 66.83, 67.17, 67.45, 67.75, 68.15, 68.64, 69.15, 
> 69.57, 69.79, 69.79, 69.72, 69.72, 69.81, 69.94, 70, 70.01, 70.02, 
> 70.03)), row.names = c(NA, 433L), class = "data.frame", .Names = c("Vehicle.ID", 
> "Frame.ID", "Vehicle.velocity"))  
> I am trying to smooth the data using dplyr. Here is the code:  
> uma <- tbl_df(uma)
>    uma <- uma %>%     # take data frame 
>      group_by(Vehicle.ID)  %>%  # group by Vehicle ID
>      mutate(i = 1:length(Frame.ID), im1 = i-1, Nai = length(Frame.ID) - i,
>             Dv = pmin(im1, Nai, 30),
>             imDv = i - Dv,
>             ipDv = i + Dv) %>%  # finding i, i-1 and Nalpha-i, D, i-D and i+D for location, velocity and acceleration
>      ungroup()  
> 
> 
>    umav <- uma %>%
>      group_by(Vehicle.ID, Frame.ID) %>%
>      do(data.frame(kv = .$imDv:.$ipDv)) %>%
>      left_join(x=., y=uma) %>%
>      mutate(imk = i - kv, aimk = (-1) * abs(imk), delta = 10, kernel = exp(aimk/delta)) %>%
>      ungroup() %>%
>      group_by(Vehicle.ID) %>%
>      mutate(p = Vehicle.velocity2[match(kv,i)], kernelp = p * kernel) %>%
>      ungroup() %>%
>      group_by(Vehicle.ID, Frame.ID) %>%
>      summarise(Z = sum(kernel), prod = sum(kernelp)) %>%
>      mutate(svel = prod/Z) %>%
>      ungroup()
> 
> The code works but takes 1 hour. I think the delay is caused by do(data.frame(kv = .$imDv:.$ipDv)). Is there any faster way to do this?
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Oct 18 18:07:51 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 18 Oct 2014 09:07:51 -0700
Subject: [R] Build a package on one Mac but unable to load this on
	another Mac
In-Reply-To: <CAKcWPz+WwbaXUUrs=7QTcef02Gs0pG6kAjOXToPsgEK5jK6bJw@mail.gmail.com>
References: <CAKcWPz+WwbaXUUrs=7QTcef02Gs0pG6kAjOXToPsgEK5jK6bJw@mail.gmail.com>
Message-ID: <A13E741E-793B-4D61-B1A6-3483918C9797@comcast.net>


On Oct 18, 2014, at 8:42 AM, althu07 wrote:

> Hi, I build a package on one Mac. I can install the package on another Mac
> but it cannot be loaded. The following is the error message.
> 
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object
> '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so':
> dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so,
> 6): Library not loaded: /usr/local/lib/libgfortran.3.dylib
> Referenced from:
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so
> Reason: image not found
> Error: package or namespace load failed for ?mypkgfe?
> 
> If I install the gfortran on the user's Mac, the package can be installed
> and loaded successfully. But I don't think this is a good option to solve
> this problem as it requires too much on the user's end. Is there anyway to
> build the package so that it can be successfully loaded even the Mac
> doesn't have gfortran preinstalled?
> 
> It seems the Mavericks OS X can load the package but not the Snow Leopard
> OS X. I am wondering if this has anything to do with the fact that R for
> Snow Leopard doesn't include GNU Fortran.

As far as Macs are concerned there are two forks in the R versions: one running on Snow Leopard, Lion and Mountain Lion and the other running on Mavericks and Yosemite. If you submit the package to CRAN it will build two different versions using the correct toolchains (and the correct XQuartz and Java packages). If  you are doing this on your own, you will need to have two different versions each with the correct toolchains. This is something that is described in the admin documents. And future questions should go to the correct mailing list: R-SIG-Mac: https://stat.ethz.ch/mailman/listinfo/r-sig-mac


> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]

And like rhelp, R-SIG-Mac is a plain text mailing list.

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From amos.elberg at gmail.com  Sat Oct 18 18:34:25 2014
From: amos.elberg at gmail.com (Amos B. Elberg)
Date: Sat, 18 Oct 2014 12:34:25 -0400
Subject: [R] Build a package on one Mac but unable to load this on
	another Mac
In-Reply-To: <CAKcWPz+WwbaXUUrs=7QTcef02Gs0pG6kAjOXToPsgEK5jK6bJw@mail.gmail.com>
References: <CAKcWPz+WwbaXUUrs=7QTcef02Gs0pG6kAjOXToPsgEK5jK6bJw@mail.gmail.com>
Message-ID: <4E750703-7A16-4212-BFC4-012F92400526@gmail.com>

You could include just that library in your distribution, and change the dynamic link path using install_name_tool. I assume how to do so in detail is beyond the intended scope of this mailing list.


> On Oct 18, 2014, at 11:42 AM, althu07 <althu07 at gmail.com> wrote:
> 
> Hi, I build a package on one Mac. I can install the package on another Mac
> but it cannot be loaded. The following is the error message.
> 
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
> unable to load shared object
> '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so':
> dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so,
> 6): Library not loaded: /usr/local/lib/libgfortran.3.dylib
> Referenced from:
> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so
> Reason: image not found
> Error: package or namespace load failed for ?mypkgfe?
> 
> If I install the gfortran on the user's Mac, the package can be installed
> and loaded successfully. But I don't think this is a good option to solve
> this problem as it requires too much on the user's end. Is there anyway to
> build the package so that it can be successfully loaded even the Mac
> doesn't have gfortran preinstalled?
> 
> It seems the Mavericks OS X can load the package but not the Snow Leopard
> OS X. I am wondering if this has anything to do with the fact that R for
> Snow Leopard doesn't include GNU Fortran.
> 
> Thanks!
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sat Oct 18 18:51:17 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 18 Oct 2014 17:51:17 +0100
Subject: [R] Build a package on one Mac but unable to load this on
 another Mac
In-Reply-To: <4E750703-7A16-4212-BFC4-012F92400526@gmail.com>
References: <CAKcWPz+WwbaXUUrs=7QTcef02Gs0pG6kAjOXToPsgEK5jK6bJw@mail.gmail.com>
	<4E750703-7A16-4212-BFC4-012F92400526@gmail.com>
Message-ID: <54429A85.1050401@stats.ox.ac.uk>

On 18/10/2014 17:34, Amos B. Elberg wrote:
> You could include just that library in your distribution, and change the dynamic link path using install_name_tool. I assume how to do so in detail is beyond the intended scope of this mailing list.

In fact you just need to change the path, as that library is included in 
the CRAN R distribution (which I guess is what it being used, although 
no one said which R it was).  Look in 
/Library/Frameworks/R.framework/Versions/Current/Resources/lib  ....

It is also most likely possible to link against a static libgfortran, as 
we do on Windows.

But this is indeed the wrong list: see the posting guide which it seems 
neither of you have read.  Follow-ups to R-sig-mac ....

>
>> On Oct 18, 2014, at 11:42 AM, althu07 <althu07 at gmail.com> wrote:
>>
>> Hi, I build a package on one Mac. I can install the package on another Mac
>> but it cannot be loaded. The following is the error message.
>>
>> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>> unable to load shared object
>> '/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so':
>> dlopen(/Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so,
>> 6): Library not loaded: /usr/local/lib/libgfortran.3.dylib
>> Referenced from:
>> /Library/Frameworks/R.framework/Versions/3.1/Resources/library/mypkgfe/libs/mypkgfe.so
>> Reason: image not found
>> Error: package or namespace load failed for ?mypkgfe?
>>
>> If I install the gfortran on the user's Mac, the package can be installed
>> and loaded successfully. But I don't think this is a good option to solve
>> this problem as it requires too much on the user's end. Is there anyway to
>> build the package so that it can be successfully loaded even the Mac
>> doesn't have gfortran preinstalled?
>>
>> It seems the Mavericks OS X can load the package but not the Snow Leopard
>> OS X. I am wondering if this has anything to do with the fact that R for
>> Snow Leopard doesn't include GNU Fortran.
>>
>> Thanks!
>>
>>     [[alternative HTML version deleted]]


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From rhelpmaillist at 163.com  Sat Oct 18 19:02:16 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Sun, 19 Oct 2014 01:02:16 +0800 (CST)
Subject: [R] how to judge a virable is a integer?
In-Reply-To: <CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
	<CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>
Message-ID: <8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>


Tks for your help, after investigate in your link, i find there seems three ways can be adoped:
1. ? ?is.wholenumber <- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) < tol)
 e.g. is.wholenumber(1)
2. ??x%%1==0


3. all.equal(a, as.integer(a))


and also included your last suggestion using floor. and also tks for other helpers?








--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

At 2014-10-18 22:48:15, "Sergio Fonda" <sergio.fonda99 at gmail.com> wrote:
 


Sorry for my previous hurry misunderstanding.
Try this link:
http://stackoverflow.com/questions/3476782/how-to-check-if-the-number-is-integer




2014-10-18 16:25 GMT+02:00 PO SU <rhelpmaillist at 163.com>:



It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but deeply, when i want to know 1 is an integer, ?there seems no easy way to get the answer.

So, is there anyone happen to know it?









--



PO SU

mail: desolator88 at 163.com

Majored in Statistics from SJTU







At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:

>> But i use a<-10/b ,? b is some value ,may be? 5, maybe 5.5

>If you do floating point arithmetic on integers you'll usually get floating point answers, including the 5.0.

>

>See FAQ 7.31 for the usual floating point problem, and ?all.equal for the usual answer to it. You could see if a result is close to an integer by,for example, using all.equal to compare it to itself after rounding.

>

>S

>

>*******************************************************************

>This email and any attachments are confidential. Any use, copying or

>disclosure other than by the intended recipient is unauthorised. If

>you have received this message in error, please notify the sender

>immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com

>and delete this message and any copies from your computer and network.

>LGC Limited. Registered in England 2991879.

>Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

______________________________________________

R-help at r-project.org mailing list

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.




From wdunlap at tibco.com  Sat Oct 18 19:33:05 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 18 Oct 2014 10:33:05 -0700
Subject: [R] how to judge a virable is a integer?
In-Reply-To: <8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
	<CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>
	<8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>
Message-ID: <CAF8bMcaAnGvZiTrrmMMnFX2Oe4iExCM8VxqqUOoHN6uGY44Xew@mail.gmail.com>

3. all.equal(a, as.integer(a))

Note that this one tests if 'a' can be stored accurately as a 32-bit signed
integer.  If you want to know if 'a' can be used as an accurate count, then
you want to test if a+1>a (use abs() in case a is negative).  E.g., try this
for a<-2^49-1, about 5*10^14.

You have to decide what properties of integers you are interested in.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sat, Oct 18, 2014 at 10:02 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Tks for your help, after investigate in your link, i find there seems three ways can be adoped:
> 1.    is.wholenumber <- function(x, tol = .Machine$double.eps^0.5)  abs(x - round(x)) < tol)
>  e.g. is.wholenumber(1)
> 2.   x%%1==0
>
>
> 3. all.equal(a, as.integer(a))
>
>
> and also included your last suggestion using floor. and also tks for other helpers?
>
>
>
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
> At 2014-10-18 22:48:15, "Sergio Fonda" <sergio.fonda99 at gmail.com> wrote:
>
>
>
> Sorry for my previous hurry misunderstanding.
> Try this link:
> http://stackoverflow.com/questions/3476782/how-to-check-if-the-number-is-integer
>
>
>
>
> 2014-10-18 16:25 GMT+02:00 PO SU <rhelpmaillist at 163.com>:
>
>
>
> It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but deeply, when i want to know 1 is an integer,  there seems no easy way to get the answer.
>
> So, is there anyone happen to know it?
>
>
>
>
>
>
>
>
>
> --
>
>
>
> PO SU
>
> mail: desolator88 at 163.com
>
> Majored in Statistics from SJTU
>
>
>
>
>
>
>
> At 2014-10-18 20:10:09, "S Ellison" <S.Ellison at LGCGroup.com> wrote:
>
>>> But i use a<-10/b ,  b is some value ,may be  5, maybe 5.5
>
>>If you do floating point arithmetic on integers you'll usually get floating point answers, including the 5.0.
>
>>
>
>>See FAQ 7.31 for the usual floating point problem, and ?all.equal for the usual answer to it. You could see if a result is close to an integer by,for example, using all.equal to compare it to itself after rounding.
>
>>
>
>>S
>
>>
>
>>*******************************************************************
>
>>This email and any attachments are confidential. Any use, copying or
>
>>disclosure other than by the intended recipient is unauthorised. If
>
>>you have received this message in error, please notify the sender
>
>>immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com
>
>>and delete this message and any copies from your computer and network.
>
>>LGC Limited. Registered in England 2991879.
>
>>Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK
>
> ______________________________________________
>
> R-help at r-project.org mailing list
>
> https://stat.ethz.ch/mailman/listinfo/r-help
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>
> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From edd at debian.org  Sun Oct 19 00:09:33 2014
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 18 Oct 2014 17:09:33 -0500
Subject: [R] Microsoft fighting against cxxfunction() and winning
In-Reply-To: <CA+G8hjwmFR55=-NBOfArbQ13oc0+Rxr2Kw_izWktaVM4ZF4ZTQ@mail.gmail.com>
References: <CA+G8hjwmFR55=-NBOfArbQ13oc0+Rxr2Kw_izWktaVM4ZF4ZTQ@mail.gmail.com>
Message-ID: <21570.58653.726723.165161@max.nulle.part>


On 17 October 2014 at 11:57, Rainer K. SACHS wrote:
| Running Windows 7, 64 bit (but also including, I think, 32 bit R files)
| RStudio 0.98.501
| win-library 3.1
| 
| Getting error messages, probably related to add_path, for the
| following example script; I did look within RStudio and on the
| internet but can't understand the errors, let alone fix them, so any
| hints would be appreciated.
| 
| library(inline)
| library(Rcpp)
| library(devtools)
| f2 <- cxxfunction( signature(x = "integer", y = "numeric" ) , '
|       return wrap( as<int>(x) * as<double>(y) ) ;
|     ', plugin = "Rcpp" )
| fx( 2L, 5 )
| # add_path("Rtools\\bin",after=0)
| # add_path("Rtools\\gcc-4.6.3\\bin",after=1)
| # get_path()

1)  Wrong list. This is an Rcpp question; you should ask those on rcpp-devel
    (where you need to be subscribed to post).

2)  You are making your life way too complicated by sticking to a valid,
    documented (and working, I may add) method which has long been
    superseeded by Rcpp Attributes).  So one really quick way of writing
    what you spec up there is

    R> library(Rcpp)
    R> cppFunction("double f2(int x, double y) { return x * y; }")
    R> f2( 2L, 5)
    [1] 10
    R> 

3)  Like some people, I find Windows a little cumbersome due to the need for
    fiddling for PATH settings and the like -- but there are heuristics that
    help.  If you do the above in RStudio and have, say, not all tools in
    your path, RStudio will check and tell you so.  Give it a try.

Hope this helps, and that you find Rcpp helpful.  Please bring further
questions to the rcpp-devel list.

Dirk

| 
| 1) If I run as is, the error message is:
| Error in compileCode(f, code, language = language, verbose = verbose) :
|   Compilation ERROR, function(s)/method(s) not created! Warning message:
| running command 'make -f "C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf" -f
| "C:/PROGRA~1/R/R-31~1.1/share/make/winshlib.mk"
| SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
| SHLIB="file1a2c862738.dll" WIN=64 TCLBIN=64
| OBJECTS="file1a2c862738.o"' had status 127
| In addition: Warning message:
| running command 'C:/PROGRA~1/R/R-31~1.1/bin/x64/R CMD SHLIB
| file1a2c862738.cpp 2> file1a2c862738.cpp.err.txt' had status 1
| 
| 2) If I uncomment the commented lines I get a longer, more
| interesting, even less comprehensible error message:
| Error in compileCode(f, code, language = language, verbose = verbose) :
|   Compilation ERROR, function(s)/method(s) not created! cygwin warning:
|   MS-DOS style path detected: C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf
|   Preferred POSIX equivalent is:
| /cygdrive/c/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf
|   CYGWIN environment variable option "nodosfilewarning" turns off this warning.
|   Consult the user's guide for more details about POSIX paths:
|     http://cygwin.com/cygwin-ug-net/using.html#using-pathnames
| Syntax error: EOF in backquote substitution
| make: *** [file20681e531a0b.o] Error 2
| Warning message:
| running command 'make -f "C:/PROGRA~1/R/R-31~1.1/etc/x64/Makeconf" -f
| "C:/PROGRA~1/R/R-31~1.1/share/make/winshlib.mk"
| SHLIB_LDFLAGS='$(SHLIB_CXXLDFLAGS)' SHLIB_LD='$(SHLIB_CXXLD)'
| SHLIB="file20681e531a0b.dll" WIN=64 TCLBIN=64
| OBJECTS="file20681e531a0b.o"' had status 2
| In addition: Warning message:
| running command 'C:/PROGRA~1/R/R-31~1.1/bin/x64/R CMD SHLIB
| file20681e531a0b.cpp 2> file20681e531a0b.cpp.err.txt' had status 1
| >
| 
| 3) If I try to read cygwin-ug-net/using.html they don't seem to
| address 64 bit Windows.
| 
| Any suggestions? Thank you, Ray Sachs
| 
| ______________________________________________
| R-help at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-help
| PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
| and provide commented, minimal, self-contained, reproducible code.

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From syen04 at gmail.com  Sun Oct 19 06:17:48 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 19 Oct 2014 00:17:48 -0400
Subject: [R] Checking if a matrix exists/is defined
Message-ID: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>

Hello
Can someone help me with the following, specifically in judging 
whether a matrix exists. I have trouble with the first line below. In 
this case, matrix obj$hessian exists and is 74 x 74. I receive the 
error message:

Warning message:
In all(w$hessian) : coercing argument of type 'double' to logical

Thank you all.

---
if (!all(obj$hessian)|OPG){
   vb<-obj$gradientObs; vb<-solve(t(vb)%*%vb)
   vb.method<-"; v(b)=inv(G'G)"
} else {
   vb<- solve(-obj$hessian)
   vb.method<-"; v(b)=inv(-H)"
} 
	[[alternative HTML version deleted]]


From rmh at temple.edu  Sun Oct 19 07:50:51 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 19 Oct 2014 01:50:51 -0400
Subject: [R] Checking if a matrix exists/is defined
In-Reply-To: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
Message-ID: <CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>

all() takes a logical argument, not numeric.  See ?all

I think you are looking for
is.null(obj$hessian)

If this isn't what you are looking for, please send a reproducible example
to the entire list.

Rich

On Sun, Oct 19, 2014 at 12:17 AM, Steven Yen <syen04 at gmail.com> wrote:
> Hello
> Can someone help me with the following, specifically in judging
> whether a matrix exists. I have trouble with the first line below. In
> this case, matrix obj$hessian exists and is 74 x 74. I receive the
> error message:
>
> Warning message:
> In all(w$hessian) : coercing argument of type 'double' to logical
>
> Thank you all.
>
> ---
> if (!all(obj$hessian)|OPG){
>    vb<-obj$gradientObs; vb<-solve(t(vb)%*%vb)
>    vb.method<-"; v(b)=inv(G'G)"
> } else {
>    vb<- solve(-obj$hessian)
>    vb.method<-"; v(b)=inv(-H)"
> }
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From johannes at huesing.name  Sun Oct 19 06:34:26 2014
From: johannes at huesing.name (Johannes Huesing)
Date: Sun, 19 Oct 2014 06:34:26 +0200
Subject: [R] Checking if a matrix exists/is defined
In-Reply-To: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
Message-ID: <20141019043425.GA4104@huesing.name>

Steven Yen <syen04 at gmail.com> [Sun, Oct 19, 2014 at 06:17:48AM CEST]:
> Hello
> Can someone help me with the following, specifically in judging 
> whether a matrix exists. 

exists(my.matrix)

> I have trouble with the first line below. In 
> this case, matrix obj$hessian exists and is 74 x 74. I receive the 
> error message:
> 
> Warning message:

Looks like a warning message to me.

> In all(w$hessian) : coercing argument of type 'double' to logical
> 

all expects a logical vector, instead it finds a double vector. Trying
to make sense of it, it converts the double vector to logical using
as.logical(). Looking up ?as.logical I fail, however, to see which
rules it uses to convert double to logical. Possibly 0 -> FALSE and
everything else -> TRUE.

-- 
Johannes H?sing               There is something fascinating about science. 
                              One gets such wholesale returns of conjecture 
mailto:johannes at huesing.name  from such a trifling investment of fact.                
http://derwisch.wikidot.com         (Mark Twain, "Life on the Mississippi")


From jdnewmil at dcn.davis.ca.us  Sun Oct 19 08:25:45 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 18 Oct 2014 23:25:45 -0700 (PDT)
Subject: [R] seqinr ?: Splitting a factor name into several columns.
 Dealing with metabarcoding data.
In-Reply-To: <11019DCE9B47004F90B2D9C62FF157921BD8F25F@ebox-prod-srv06.win.su.se>
References: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>,
	<CA+vqiLFwVHfMnc6xzOx9J8tvN3rU_gwHSEdt5oWQUPR01xAiyg@mail.gmail.com>
	<11019DCE9B47004F90B2D9C62FF157921BD8F25F@ebox-prod-srv06.win.su.se>
Message-ID: <alpine.BSF.2.00.1410182249130.42999@pedal.dcn.davis.ca.us>

On Sat, 18 Oct 2014, Anna Zakrisson Braeunlich wrote:

> Thank you! That was a easy and fast solution!

If it was so easy, why couldn't you adapt Ista's solution? I suspect 
it is because you don't understand his suggestion.

> May I post a follow-up question? (I am not sure if this would rather 
> should be posted as a new question, but I post it here and then I can 
> re-post it if this is the wrong place to ask this). I am ever so 
> grateful for your help!

This probably should have been a new thread, but I will bite anyway.

> /Anna
>
>
> ######################### FOLLOW-UP QUESTION ####################################
>
> df1 <- data.frame(cbind(Identifier = c("M123.B23.VJHJ", "M123.B24.VJHJ",
>                                       "M123.B23.VLKE", "M123.B23.HKJH",
>                                       "M123.B24.LKJH"),
>                                       Sequence = c("ATATATATATA", "ATATATATATA",
>                                                    "ATATAGCATATA", "ATATATAGGGTA",
>                                                    "ATCGCGCGAATA")))

Just because R has a habit of making factors at the drop of a hat doesn't 
mean that if your data are still not ready to be treated as factors that 
you have to accept what it does. When you read the data in via read.csv 
you can use the colClasses argument or the stringsAsFactors argument to 
stop that. You can use stringsAsFactors when you create the data frame 
also, and you can always go back and turn any particular column into a 
factor after you are done manipulating characters.

Also, somewhere you picked up the bad habit of using cbind before you make 
your data frame... that is almost never a good idea, because in data 
frames each column can be have its own storage mode, while cbind creates a 
matrix where every element must have the same storage mode.

df1 <- data.frame( Identifier = c( "M123.B23.VJHJ", "M123.B24.VJHJ"
                                  , "M123.B23.VLKE", "M123.B23.HKJH"
                                  , "M123.B24.LKJH" )
                  , Sequence = c( "ATATATATATA", "ATATATATATA"
                                , "ATATAGCATATA", "ATATATAGGGTA"
                                , "ATCGCGCGAATA" )
                  , stringsAsFactors=FALSE
                  )


>
> # as a follow-up question:
> # How can I split the identifier in df1 above into several columns based on the
> # separating dots? The real data includes thousands of rows.
> # This is what I want it to look like in the end:
>
> df1_solution <- data.frame(cbind(Identifier1 = c("M123", "M123",
>                                       "M123", "M123",
>                                       "M123"),
>                        Identifier2 = c("B23", "B24", "B23", "B23", "B24"),
>                        Identifier3 = c("VJHJ", "VJHJ", "VLKE", "HKJH", "LKJH"),
>                        Sequence = c("ATATATATATA", "ATATATATATA",
>                                     "ATATAGCATATA", "ATATATAGGGTA",
>                                     "ATCGCGCGAATA")))

df1_solution <- data.frame( Identifier1 = c( "M123", "M123"
                                            , "M123", "M123"
                                            , "M123" )
                           , Identifier2 = c( "B23", "B24", "B23"
                                            , "B23", "B24" )
                           , Identifier3 = c( "VJHJ", "VJHJ"
                                            , "VLKE", "HKJH", "LKJH")
                           , Sequence = c( "ATATATATATA", "ATATATATATA"
                                         , "ATATAGCATATA", "ATATATAGGGTA"
                                         , "ATCGCGCGAATA" )
                           , stringsAsFactors=FALSE
                          )


> # I am very grateful for your help! I am no whiz at R and everything I know
> # is self-taught. Therefore, some basics can turn out to be quite some
> # obsatcles for me.
> # /Anna

Pretty much all of us are here to teach ourselves R, Anna. Keep reading 
other people's questions. Learn to try each fragment alone at the command 
line to figure out what is happening. Use the str() function frequently.

# the basic split
parts <- strsplit( as.character( df1$Identifier ), ".", fixed=TRUE )

# extension of Ista's approach to assembly
ans1 <- data.frame( Identifier1 = rep( NA, nrow( ans1 ) )
                   , Identifier2 = rep( NA, nrow( ans1 ) )
                   , Identifier3 = rep( NA, nrow( ans1 ) )
                   , stringsAsFactors = FALSE
)
# note all memory is pre-allocated above... avoid successively
# accumulating rows with rbind... that would be very slow
for ( rw in seq_along( df1$Identifier ) ) {
   v <- parts[[ rw ]]
   ans1[ rw, "Identifier1" ] <- v[ 1 ]
   ans1[ rw, "Identifier2" ] <- v[ 2 ]
   ans1[ rw, "Identifier3" ] <- v[ 3 ]
}
ans1$Sequence <- df1$Sequence

#---- alternative method of assembly
# uses "list-to-data.frame apply" from plyr package
library(plyr)
ans2 <- ldply( parts
              , function( v ) { # called once for each item in parts list
                       # all single-row data frames created in this
                       # function are concatenated at once by ldply to
                       # make one big data.frame "ans2"
                       data.frame( Identifier1=v[1]
                                 , Identifier2=v[2]
                                 , Identifier3=v[3]
                                 , stringsAsFactors=FALSE
                                 )
                }
              )
ans2$Sequence <- DF$Sequence


>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> ________________________________________
> From: Ista Zahn [istazahn at gmail.com]
> Sent: 13 October 2014 15:42
> To: Anna Zakrisson Braeunlich
> Cc: r-help at r-project.org
> Subject: Re: [R] seqinr ?: Splitting a factor name into several columns. Dealing with metabarcoding data.
>
> Hi Anna,
>
>
> On Sun, Oct 12, 2014 at 3:24 AM, Anna Zakrisson Braeunlich
> <anna.zakrisson at su.se> wrote:
>> Hi,
>>
>> I have a question how to split a factor name into different columns. I have metabarcoding data and need to merge the FASTA-file with the taxonomy- and counttable files (dataframes). To be able to do this merge, I need to isolate the common identifier, that unfortunately is baked in with a lot of other labels in the factor name eg:
>> sequence identifier: M01271_77_000000000.A8J0P_1_1101_10150_1525.1.322519.sample_1.sample_2
>>
>> I want to split this name at every "." to get several columns:
>> column1: M01271_77_000000000
>> column2: A8J0P_1_1101_10150_1525
>> column3: 1
>> column4: 322519
>> column5: sample_1
>> column6: sample_2
>>
>> I must add that I have no influence on how these names are given. This is how thay are supplied from Illumina Miseq. I just need to be able to deal with it.
>>
>> Here is some extremely simplified dummy data to further show the issue at hand:
>>
>> df1 <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>>                   Z.identifierA.B1298712 = factor(rep(LETTERS[1:2], each = 5)))
>> df2 <- data.frame(cbind(B = 13:22, K = rnorm(10)),
>>                   Q.identifierA.B4668726 = factor(rep(LETTERS[1:2], each = 5)))
>>
>> # I have metabarcoding data with one FASTA-file, one count table and one taxonomy file
>> # Above dummy data is just showing the issue at hand. I want to be able to merge my three
>> # original data frames (here, the dummy data is only two dataframes). The problem is that
>> # the only identifier that is commmon for the dataframes is "hidden" in the
>> # factor name eg: Z.identifierA.1298712 and Q.identifierA.4668726. I hence need to be able
>> # to split this name up into different columns to get "identifierA" alone as one column name
>> # Then I can merge the dataframes.
>> # How can I do this in R. I know that it can be done in excel, but I would like to
>> # produce a complete R-script to get a fast pipeline and avoid copy and paste errors.
>> # This is what I want it to look:
>>
>> df1.goal <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>>                   Z = factor(rep(LETTERS[1:2], each = 5)),
>>                   identifierA = factor(rep(LETTERS[1:2], each = 5)),
>>                   B1298712 = factor(rep(LETTERS[1:2], each = 5)))
>
> Use strsplit to separate the components, something like
>
> separateNames <- strsplit(names(df1)[3], split = "\\.")[[1]]
> for(name in separateNames) {
>    df1[[name]] <- df1[[3]]
> }
> df1[[3]] <- NULL
>
> Best,
> Ista
>
>>
>> # Many thank's and with kind regards
>> Anna Zakrisson
>>
>>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>>
>> Anna Zakrisson Braeunlich
>> PhD student
>>
>> Department of Ecology, Environment and Plant Sciences
>> Stockholm University
>> Svante Arrheniusv. 21A
>> SE-106 91 Stockholm
>> Sweden/Sverige
>>
>> Lives in Berlin.
>> For paper mail:
>> Katzbachstr. 21
>> D-10965, Berlin
>> Germany/Deutschland
>>
>> E-mail: anna.zakrisson at su.se
>> Tel work: +49-(0)3091541281
>> Mobile: +49-(0)15777374888
>> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>>
>>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From syen04 at gmail.com  Sun Oct 19 09:05:01 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 19 Oct 2014 03:05:01 -0400
Subject: [R] Checking if a matrix exists/is defined
In-Reply-To: <CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.g
	mail.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
Message-ID: <5443629f.edcaec0a.1451.ffff88b9@mx.google.com>

Thank you Rich. It works like a charm! Earlier I worked around 
by  judging its determinant:

dd<-NULL
if (invH) dd<-det(obj$hessian)
if (invH & exists("dd")){
...
}

Now I do

if (!is.null(obj$hessian) & invH){
...
}

which is more direct. Thanks again.

Steven

At 01:50 AM 10/19/2014, Richard M. Heiberger wrote:
>all() takes a logical argument, not numeric.  See ?all
>
>I think you are looking for
>is.null(obj$hessian)
>
>If this isn't what you are looking for, please send a reproducible example
>to the entire list.
>
>Rich
>
>On Sun, Oct 19, 2014 at 12:17 AM, Steven Yen <syen04 at gmail.com> wrote:
> > Hello
> > Can someone help me with the following, specifically in judging
> > whether a matrix exists. I have trouble with the first line below. In
> > this case, matrix obj$hessian exists and is 74 x 74. I receive the
> > error message:
> >
> > Warning message:
> > In all(w$hessian) : coercing argument of type 'double' to logical
> >
> > Thank you all.
> >
> > ---
> > if (!all(obj$hessian)|OPG){
> >    vb<-obj$gradientObs; vb<-solve(t(vb)%*%vb)
> >    vb.method<-"; v(b)=inv(G'G)"
> > } else {
> >    vb<- solve(-obj$hessian)
> >    vb.method<-"; v(b)=inv(-H)"
> > }
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.


From cmora at Dal.Ca  Sun Oct 19 10:09:28 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Sun, 19 Oct 2014 08:09:28 +0000
Subject: [R] Plotting sum rather than count in hexbin
Message-ID: <1413706167988.74157@Dal.Ca>


Hi everyone,

This may be a trivial solution but I would appreciate any help.

I have a database with three variables. I would like to plot the first two variables in a xy plot making the color of points proportional to the values in the third variable. Given that many points overlap, I decided to use the hexbin package, which allows aggregating the points by a third variable.
I figured out how to make the sums by hexbins but I am falling short in how to link the sums back to the hexbins and then plot the hexbins color coded by the sums?.  Below is the code so far.

Thanks,

Camilo



library(hexbin)


#generates data for three variables
dat=data.frame(    x = c(rep(1:10,3)),
                                    y = c(rep(1:10,3)),
                                    z = c(rep(1:10,3)))

#generates hexbin with the x and y variables
hbin<-hexbin(dat$x, dat$y, xbins=10, IDs=TRUE)

#sum values of points inside hexbins
SumHexBin<-hexTapply(hbin, dat$z, sum)


#the question is how to link the SumHexBin back to the hbin and then plot it color coding bins by the sums?



	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Sun Oct 19 10:10:50 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Sun, 19 Oct 2014 11:10:50 +0300
Subject: [R] Sum of two consecutive number in dataset.
In-Reply-To: <0BFF4651-B15F-4E58-A17E-8D2F5A12F6A6@dcn.davis.CA.us>
References: <CAGh51gT4Ydis38GXVzzw-2tNjY09zfAsXMXbRmh0yHJ43+cg=Q@mail.gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEA2C9@SRVEXCHMBX.precheza.cz>
	<0BFF4651-B15F-4E58-A17E-8D2F5A12F6A6@dcn.davis.CA.us>
Message-ID: <CAGh51gTGGTbYR_cdCfLK9cY=gaf9QBzS60bJBifH_W4kHk=cwA@mail.gmail.com>

Dear All,

Thanks for the useful ideas.

This is how I solved the problem and it works well.
####################################################################################
sowdays=function(data,Year){
  Year = unique(data$Year)
  #gives you sum of rain in 2 consecutive days
  twodays <- rowSums(embed(Samaru56$Rain,2))
  # the condition of heavy rainfall
  sel <- which(twodays>=20)
  #gives you vector of row numbers in which above condition results is TRUE
value
  #Samaru56[sel,]
  D=Samaru56[sel,]
  day<- c()
  for (year in 1928: 1983){
      S <- subset(D, D$Year == year) #subset each year
      for(i in S$Day[S$Day>91]){
         if(S[S$Day == i, 3] >= 20){
            day[year-(min(Year)-1)] = i
            break
         }
      }
  }
  day
}
sowdays(Samaru56, Samaru56$Year)
#######################################################################################
I want to make it with the additional condition that there is no 10 day (or
longer) dry
spell in the next 30 days. In definition a 'dry day' is here defined as a
day with less than 0.85 mm of rain.

Any idea of how I can include this condition in the above condition is can
help me alot. Thanks.

Regards,
Fredo.

On Wed, Oct 15, 2014 at 6:34 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> twodays <- c(filter(x,c(1,1),sides=1))
>
> might be more efficient with memory than the embed approach, which might
> be important if more than two days were of interest.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 15, 2014 2:59:40 AM PDT, PIKAL Petr <petr.pikal at precheza.cz>
> wrote:
> >Hi
> >
> >twodays <- rowSums(embed(Samaru56$Rain,2))
> >
> >gives you sum of rain in 2 cosecutive days
> >
> >sel <- which(twodays>20)
> >
> >gives you vector of row numbers in which above condition results in
> >TRUE value
> >
> >Samaru56[sel,]
> >
> >selects these rows
> >
> >Regards
> >Petr
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Frederic Ntirenganya
> >> Sent: Wednesday, October 15, 2014 9:01 AM
> >> To: r-help at r-project.org
> >> Subject: [R] Sum of two consecutive number in dataset.
> >>
> >> Dear All,
> >>
> >> i am solving the following problem in my work.
> >>
> >> The first day from April 01 that gets more than 20 mm on a single
> >day,
> >> or totalled over 2 consecutive days. i.e April 01 = 92th day of the
> >> year.
> >>
> >> The column of interest is "Rain".
> >> > head(Samaru56)
> >>   Year Day Rain
> >> 1 1928   1    0
> >> 2 1928   2    0
> >> 3 1928   3    0
> >> 4 1928   4    0
> >> 5 1928   5    0
> >> 6 1928   6    0
> >>
> >> I used the loop below but it is not printing anything.
> >>
> >> sow_day=c()
> >> for (i in 1928:1983){
> >>   for (j in 92:366){
> >>     k=j-1
> >>     s_rain=Samaru56$Rain[k] + Samaru56$Rain[j]
> >>     if (s_rain>=20)
> >>       sow_day=j
> >>       break
> >>   }
> >>   Samaru56$year=Samaru56$Year[sow_day]
> >>   Samaru56$Day=Samaru56$Day[sow_day]
> >>   Samaru56$Rain=Samaru56$Rain[sow_day]
> >> }
> >> sow_day
> >>
> >> Any idea is welcome on how I can solve this problem. Thanks
> >>
> >> --
> >> Frederic Ntirenganya
> >> Maseno University,
> >> Kenya.
> >> Mobile:(+254)718492836
> >> Email: fredo at aims.ac.za
> >> https://sites.google.com/a/aims.ac.za/fredo/
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-
> >> guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >________________________________
> >Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
> >ur?eny pouze jeho adres?t?m.
> >Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> >neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> >kopie vyma?te ze sv?ho syst?mu.
> >Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> >email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> >Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> >modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> >V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> >- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> >smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> >- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> >p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> >ze strany p??jemce s dodatkem ?i odchylkou.
> >- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> >v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> >- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> >spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> >zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> >adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> >p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> >zn?m?.
> >
> >This e-mail and any documents attached to it may be confidential and
> >are intended only for its intended recipients.
> >If you received this e-mail by mistake, please immediately inform its
> >sender. Delete the contents of this e-mail with all attachments and its
> >copies from your system.
> >If you are not the intended recipient of this e-mail, you are not
> >authorized to use, disseminate, copy or disclose this e-mail in any
> >manner.
> >The sender of this e-mail shall not be liable for any possible damage
> >caused by modifications of the e-mail or by delay with transfer of the
> >email.
> >
> >In case that this e-mail forms part of business dealings:
> >- the sender reserves the right to end negotiations about entering into
> >a contract in any time, for any reason, and without stating any
> >reasoning.
> >- if the e-mail contains an offer, the recipient is entitled to
> >immediately accept such offer; The sender of this e-mail (offer)
> >excludes any acceptance of the offer on the part of the recipient
> >containing any amendment or variation.
> >- the sender insists on that the respective contract is concluded only
> >upon an express mutual agreement on all its aspects.
> >- the sender of this e-mail informs that he/she is not authorized to
> >enter into any contracts on behalf of the company except for cases in
> >which he/she is expressly authorized to do so in writing, and such
> >authorization or power of attorney is submitted to the recipient or the
> >person represented by the recipient, or the existence of such
> >authorization is known to the recipient of the person represented by
> >the recipient.
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jim at bitwrit.com.au  Sun Oct 19 11:29:46 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 19 Oct 2014 20:29:46 +1100
Subject: [R] ggplot: Stacked bar/pie chart - Objects above the bar/pie
In-Reply-To: <5440F4D4.1000807@uni-landau.de>
References: <5440F4D4.1000807@uni-landau.de>
Message-ID: <1970609.coPBiDFfiG@localhost.localdomain>

On Fri, 17 Oct 2014 12:52:04 PM Gunnar Oehmichen wrote:
> Hello,
> 
> I would like to draw a circle on top of a pie chart (The plot does not
> need to fullfill scientific standards). The circle represents the
> relation of a reference-value in comparison to the summed values of 
the
> pie-pieces. To be able to do this I partly followed:
> http://rpubs.com/RobinLovelace/11641 . But i have the problem of 
some
> bar/pie pieces being placed above the stacked bar/outside of the pie
> chart, see graph PA / PA + coord_polar.
> 
Hi Gunnar,
I'm not certain that I have got the correct idea of what you want, but 
have a look at this:

library(plotrix)
vals<-by(mdf$value,mdf$variable,sum)
poss<-by(mdf$pos,mdf$variable,sum)
radial.pie(poss,c(0,cumsum(6.28*vals/sum(vals))),
 labels=letters[1:5],show.grid.labels=3,
 radial.lim=c(0,max(poss)))
legend(200000000,200000000,letters[1:5],fill=rainbow(5),
 bg="white")
draw.circle(0,0,radius=poss[2],border="red")

I didn't get exactly where you wanted the circle, so I guessed with the red 
circle.

Jim


From jim at bitwrit.com.au  Sun Oct 19 12:27:26 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sun, 19 Oct 2014 21:27:26 +1100
Subject: [R] Plotting sum rather than count in hexbin
In-Reply-To: <1413706167988.74157@Dal.Ca>
References: <1413706167988.74157@Dal.Ca>
Message-ID: <5941629.ix6tMaeBOy@localhost.localdomain>

On Sun, 19 Oct 2014 08:09:28 AM Camilo Mora wrote:
> Hi everyone,
> 
> This may be a trivial solution but I would appreciate any help.
> 
> I have a database with three variables. I would like to plot the first 
two
> variables in a xy plot making the color of points proportional to the
> values in the third variable. Given that many points overlap, I 
decided to
> use the hexbin package, which allows aggregating the points by a 
third
> variable. I figured out how to make the sums by hexbins but I am 
falling
> short in how to link the sums back to the hexbins and then plot the 
hexbins
> color coded by the sums?.  Below is the code so far.
> 
> Thanks,
> 
> Camilo
> 
> 
> 
> library(hexbin)
> 
> 
> #generates data for three variables
> dat=data.frame(    x = c(rep(1:10,3)),
>                                     y = c(rep(1:10,3)),
>                                     z = c(rep(1:10,3)))
> 
> #generates hexbin with the x and y variables
> hbin<-hexbin(dat$x, dat$y, xbins=10, IDs=TRUE)
> 
> #sum values of points inside hexbins
> SumHexBin<-hexTapply(hbin, dat$z, sum)
> 
> 
> #the question is how to link the SumHexBin back to the hbin and 
then plot it
> color coding bins by the sums?
> 
Hi Camilo,
The color.scale function (plotrix) will convert numeric values into colors 
in a number of ways. I think you want the names of SumHexBin as 
numbers, so a simple way is:

library(plotrix)
hbincol<-color.scale(as.numeric(names(SumHexBin)),
 extremes=c("red","green"))

Jim


From wbonat at gmail.com  Sun Oct 19 16:43:52 2014
From: wbonat at gmail.com (Wagner Bonat)
Date: Sun, 19 Oct 2014 16:43:52 +0200
Subject: [R] Trace of product of matrices
Message-ID: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>

Dear,

I have to compute the trace of a product between four matrices. For
example, I know the matrices Wi, Wj and C, I need to compute this

-trace(Wi%*%C^-1%*%Wj%*%C^-1)


I would like to avoid compute the complete matrix and after take the
diagonal, something like

sum(diag( solve(Wi,C)%*% solve(Wj,C)))

Any idea is welcome.

Thanks

-- 
Wagner Hugo Bonat
LEG - Laborat?rio de Estat?stica e Geoinforma??o
UFPR - Universidade Federal do Paran?

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Oct 19 17:42:33 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 19 Oct 2014 17:42:33 +0200
Subject: [R] Trace of product of matrices
In-Reply-To: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
References: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
Message-ID: <06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>


> On 19 Oct 2014, at 16:43 , Wagner Bonat <wbonat at gmail.com> wrote:
> 
> Dear,
> 
> I have to compute the trace of a product between four matrices. For
> example, I know the matrices Wi, Wj and C, I need to compute this
> 
> -trace(Wi%*%C^-1%*%Wj%*%C^-1)
> 
> 
> I would like to avoid compute the complete matrix and after take the
> diagonal, something like
> 
> sum(diag( solve(Wi,C)%*% solve(Wj,C)))

<this can't be right: it is C that is the invertible matrix>

> 
> Any idea is welcome.
> 

The usual "trick" is that the trace of a matrix product is the inner product in matrix space, which is just the sum of the  elementwise products 

tr(AB) = tr(BA) = sum_i sum_j a_ij b_ij. 

In R, this becomes simply sum(A*B) -- notice that the ordinary product is used, not %*%. So presumably, you are looking for

sum(solve(C, Wi) * solve(C, Wj))


> Thanks
> 
> -- 
> Wagner Hugo Bonat
> LEG - Laborat?rio de Estat?stica e Geoinforma??o
> UFPR - Universidade Federal do Paran?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From spencer.graves at structuremonitoring.com  Sun Oct 19 18:45:38 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 19 Oct 2014 09:45:38 -0700
Subject: [R] Trace of product of matrices
In-Reply-To: <06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
References: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
	<06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
Message-ID: <5443EAB2.3090106@structuremonitoring.com>

On 10/19/2014 8:42 AM, peter dalgaard wrote:
>> On 19 Oct 2014, at 16:43 , Wagner Bonat <wbonat at gmail.com> wrote:
>>
>> Dear,
>>
>> I have to compute the trace of a product between four matrices. For
>> example, I know the matrices Wi, Wj and C, I need to compute this
>>
>> -trace(Wi%*%C^-1%*%Wj%*%C^-1)
>>
>>
>> I would like to avoid compute the complete matrix and after take the
>> diagonal, something like
>>
>> sum(diag( solve(Wi,C)%*% solve(Wj,C)))
> <this can't be right: it is C that is the invertible matrix>
>
>> Any idea is welcome.
>>
> The usual "trick" is that the trace of a matrix product is the inner product in matrix space, which is just the sum of the  elementwise products
>
> tr(AB) = tr(BA) = sum_i sum_j a_ij b_ij.
>
> In R, this becomes simply sum(A*B) -- notice that the ordinary product is used, not %*%. So presumably, you are looking for
>
> sum(solve(C, Wi) * solve(C, Wj))

missing a transpose?


 > A <- matrix(1:4, 2)
 > sum(diag(A %*% A))
[1] 29
 > sum(A*A)
[1] 30
 > sum(diag(A %*% t(A)))
[1] 30
 >


       See "Trace of a product" in the Wikipedia article on "Trace 
(linear algebra)" 
(https://en.wikipedia.org/wiki/Trace_%28linear_algebra%29#Trace_of_a_product). 



       Spencer

>> Thanks
>>
>> -- 
>> Wagner Hugo Bonat
>> LEG - Laborat?rio de Estat?stica e Geoinforma??o
>> UFPR - Universidade Federal do Paran?
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at structuremonitoring.com  Sun Oct 19 19:00:49 2014
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 19 Oct 2014 10:00:49 -0700
Subject: [R] Trace of product of matrices
In-Reply-To: <06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
References: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
	<06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
Message-ID: <5443EE41.5080302@structuremonitoring.com>

On 10/19/2014 8:42 AM, peter dalgaard wrote:
>> On 19 Oct 2014, at 16:43 , Wagner Bonat <wbonat at gmail.com> wrote:
>>
>> Dear,
>>
>> I have to compute the trace of a product between four matrices. For
>> example, I know the matrices Wi, Wj and C, I need to compute this
>>
>> -trace(Wi%*%C^-1%*%Wj%*%C^-1)
>>
>>
>> I would like to avoid compute the complete matrix and after take the
>> diagonal, something like
>>
>> sum(diag( solve(Wi,C)%*% solve(Wj,C)))
> <this can't be right: it is C that is the invertible matrix>
>
>> Any idea is welcome.
>>
> The usual "trick" is that the trace of a matrix product is the inner product in matrix space, which is just the sum of the  elementwise products
>
> tr(AB) = tr(BA) = sum_i sum_j a_ij b_ij.
>
> In R, this becomes simply sum(A*B) -- notice that the ordinary product is used, not %*%. So presumably, you are looking for
>
> sum(solve(C, Wi) * solve(C, Wj))

missing a transpose?


> A <- matrix(1:4, 2)
> sum(diag(A %*% A))
[1] 29
> sum(A*A)
[1] 30
> sum(diag(A %*% t(A)))
[1] 30
>

and  sum(A*t(A))
[1] 29


	  This is the answer you want, I think.  [Sorry:  I hit send before I 
thought through what I was doing.  Suppose A is a row vector and B a 
column vector.  Then the elementwise product A*B returns an error in R 
but A%*%B is a scalar while B%*%A is not, and sum(A*t(B)) = sum(t(A)*B) 
= trace(A%*%B).

When A and B are not square but the product is, then A*B = the 
elementwise product of A and B is not defined, but A*t(B) is, and so is 
t(A)*B.  When A


       See "Trace of a product" in the Wikipedia article on "Trace 
(linear algebra)" 
(https://en.wikipedia.org/wiki/Trace_%28linear_algebra%29#Trace_of_a_product). 



       Spencer

>> Thanks
>>
>> --
>> Wagner Hugo Bonat
>> LEG - Laborat?rio de Estat?stica e Geoinforma??o
>> UFPR - Universidade Federal do Paran?
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From anna.zakrisson at su.se  Sun Oct 19 13:56:56 2014
From: anna.zakrisson at su.se (Anna Zakrisson Braeunlich)
Date: Sun, 19 Oct 2014 11:56:56 +0000
Subject: [R] seqinr ?: Splitting a factor name into several columns.
 Dealing with metabarcoding data.
In-Reply-To: <alpine.BSF.2.00.1410182249130.42999@pedal.dcn.davis.ca.us>
References: <11019DCE9B47004F90B2D9C62FF157921BD843EE@ebox-prod-srv04.win.su.se>,
	<CA+vqiLFwVHfMnc6xzOx9J8tvN3rU_gwHSEdt5oWQUPR01xAiyg@mail.gmail.com>
	<11019DCE9B47004F90B2D9C62FF157921BD8F25F@ebox-prod-srv06.win.su.se>,
	<alpine.BSF.2.00.1410182249130.42999@pedal.dcn.davis.ca.us>
Message-ID: <11019DCE9B47004F90B2D9C62FF157921BD8F95F@ebox-prod-srv06.win.su.se>

Hi Jeff an many thank's for your time. 
I meant that it was easy as in not requiring som many steps...

I have managed to get it to run and it has solved my problem perfectly. Thank you for all your tips and instructions! Up until now, I have used excel for all problems similar to this one and only used R for the statistics part. I intend to make a permanent swith to R as I can see the benefits. I am just severely frustrated by my own inabilities. Therefore, once again many thank?s for your time! 

kind regards
Anna

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>

Anna Zakrisson Braeunlich
PhD student

Department of Ecology, Environment and Plant Sciences
Stockholm University
Svante Arrheniusv. 21A
SE-106 91 Stockholm
Sweden/Sverige

Lives in Berlin.
For paper mail:
Katzbachstr. 21
D-10965, Berlin
Germany/Deutschland

E-mail: anna.zakrisson at su.se
Tel work: +49-(0)3091541281
Mobile: +49-(0)15777374888
LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b

><((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>

________________________________________
From: Jeff Newmiller [jdnewmil at dcn.davis.ca.us]
Sent: 19 October 2014 08:25
To: Anna Zakrisson Braeunlich
Cc: Ista Zahn; r-help at r-project.org
Subject: Re: [R] seqinr ?: Splitting a factor name into several columns. Dealing with metabarcoding data.

On Sat, 18 Oct 2014, Anna Zakrisson Braeunlich wrote:

> Thank you! That was a easy and fast solution!

If it was so easy, why couldn't you adapt Ista's solution? I suspect
it is because you don't understand his suggestion.

> May I post a follow-up question? (I am not sure if this would rather
> should be posted as a new question, but I post it here and then I can
> re-post it if this is the wrong place to ask this). I am ever so
> grateful for your help!

This probably should have been a new thread, but I will bite anyway.

> /Anna
>
>
> ######################### FOLLOW-UP QUESTION ####################################
>
> df1 <- data.frame(cbind(Identifier = c("M123.B23.VJHJ", "M123.B24.VJHJ",
>                                       "M123.B23.VLKE", "M123.B23.HKJH",
>                                       "M123.B24.LKJH"),
>                                       Sequence = c("ATATATATATA", "ATATATATATA",
>                                                    "ATATAGCATATA", "ATATATAGGGTA",
>                                                    "ATCGCGCGAATA")))

Just because R has a habit of making factors at the drop of a hat doesn't
mean that if your data are still not ready to be treated as factors that
you have to accept what it does. When you read the data in via read.csv
you can use the colClasses argument or the stringsAsFactors argument to
stop that. You can use stringsAsFactors when you create the data frame
also, and you can always go back and turn any particular column into a
factor after you are done manipulating characters.

Also, somewhere you picked up the bad habit of using cbind before you make
your data frame... that is almost never a good idea, because in data
frames each column can be have its own storage mode, while cbind creates a
matrix where every element must have the same storage mode.

df1 <- data.frame( Identifier = c( "M123.B23.VJHJ", "M123.B24.VJHJ"
                                  , "M123.B23.VLKE", "M123.B23.HKJH"
                                  , "M123.B24.LKJH" )
                  , Sequence = c( "ATATATATATA", "ATATATATATA"
                                , "ATATAGCATATA", "ATATATAGGGTA"
                                , "ATCGCGCGAATA" )
                  , stringsAsFactors=FALSE
                  )


>
> # as a follow-up question:
> # How can I split the identifier in df1 above into several columns based on the
> # separating dots? The real data includes thousands of rows.
> # This is what I want it to look like in the end:
>
> df1_solution <- data.frame(cbind(Identifier1 = c("M123", "M123",
>                                       "M123", "M123",
>                                       "M123"),
>                        Identifier2 = c("B23", "B24", "B23", "B23", "B24"),
>                        Identifier3 = c("VJHJ", "VJHJ", "VLKE", "HKJH", "LKJH"),
>                        Sequence = c("ATATATATATA", "ATATATATATA",
>                                     "ATATAGCATATA", "ATATATAGGGTA",
>                                     "ATCGCGCGAATA")))

df1_solution <- data.frame( Identifier1 = c( "M123", "M123"
                                            , "M123", "M123"
                                            , "M123" )
                           , Identifier2 = c( "B23", "B24", "B23"
                                            , "B23", "B24" )
                           , Identifier3 = c( "VJHJ", "VJHJ"
                                            , "VLKE", "HKJH", "LKJH")
                           , Sequence = c( "ATATATATATA", "ATATATATATA"
                                         , "ATATAGCATATA", "ATATATAGGGTA"
                                         , "ATCGCGCGAATA" )
                           , stringsAsFactors=FALSE
                          )


> # I am very grateful for your help! I am no whiz at R and everything I know
> # is self-taught. Therefore, some basics can turn out to be quite some
> # obsatcles for me.
> # /Anna

Pretty much all of us are here to teach ourselves R, Anna. Keep reading
other people's questions. Learn to try each fragment alone at the command
line to figure out what is happening. Use the str() function frequently.

# the basic split
parts <- strsplit( as.character( df1$Identifier ), ".", fixed=TRUE )

# extension of Ista's approach to assembly
ans1 <- data.frame( Identifier1 = rep( NA, nrow( ans1 ) )
                   , Identifier2 = rep( NA, nrow( ans1 ) )
                   , Identifier3 = rep( NA, nrow( ans1 ) )
                   , stringsAsFactors = FALSE
)
# note all memory is pre-allocated above... avoid successively
# accumulating rows with rbind... that would be very slow
for ( rw in seq_along( df1$Identifier ) ) {
   v <- parts[[ rw ]]
   ans1[ rw, "Identifier1" ] <- v[ 1 ]
   ans1[ rw, "Identifier2" ] <- v[ 2 ]
   ans1[ rw, "Identifier3" ] <- v[ 3 ]
}
ans1$Sequence <- df1$Sequence

#---- alternative method of assembly
# uses "list-to-data.frame apply" from plyr package
library(plyr)
ans2 <- ldply( parts
              , function( v ) { # called once for each item in parts list
                       # all single-row data frames created in this
                       # function are concatenated at once by ldply to
                       # make one big data.frame "ans2"
                       data.frame( Identifier1=v[1]
                                 , Identifier2=v[2]
                                 , Identifier3=v[3]
                                 , stringsAsFactors=FALSE
                                 )
                }
              )
ans2$Sequence <- DF$Sequence


>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> Anna Zakrisson Braeunlich
> PhD student
>
> Department of Ecology, Environment and Plant Sciences
> Stockholm University
> Svante Arrheniusv. 21A
> SE-106 91 Stockholm
> Sweden/Sverige
>
> Lives in Berlin.
> For paper mail:
> Katzbachstr. 21
> D-10965, Berlin
> Germany/Deutschland
>
> E-mail: anna.zakrisson at su.se
> Tel work: +49-(0)3091541281
> Mobile: +49-(0)15777374888
> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>
>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>
> ________________________________________
> From: Ista Zahn [istazahn at gmail.com]
> Sent: 13 October 2014 15:42
> To: Anna Zakrisson Braeunlich
> Cc: r-help at r-project.org
> Subject: Re: [R] seqinr ?: Splitting a factor name into several columns. Dealing with metabarcoding data.
>
> Hi Anna,
>
>
> On Sun, Oct 12, 2014 at 3:24 AM, Anna Zakrisson Braeunlich
> <anna.zakrisson at su.se> wrote:
>> Hi,
>>
>> I have a question how to split a factor name into different columns. I have metabarcoding data and need to merge the FASTA-file with the taxonomy- and counttable files (dataframes). To be able to do this merge, I need to isolate the common identifier, that unfortunately is baked in with a lot of other labels in the factor name eg:
>> sequence identifier: M01271_77_000000000.A8J0P_1_1101_10150_1525.1.322519.sample_1.sample_2
>>
>> I want to split this name at every "." to get several columns:
>> column1: M01271_77_000000000
>> column2: A8J0P_1_1101_10150_1525
>> column3: 1
>> column4: 322519
>> column5: sample_1
>> column6: sample_2
>>
>> I must add that I have no influence on how these names are given. This is how thay are supplied from Illumina Miseq. I just need to be able to deal with it.
>>
>> Here is some extremely simplified dummy data to further show the issue at hand:
>>
>> df1 <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>>                   Z.identifierA.B1298712 = factor(rep(LETTERS[1:2], each = 5)))
>> df2 <- data.frame(cbind(B = 13:22, K = rnorm(10)),
>>                   Q.identifierA.B4668726 = factor(rep(LETTERS[1:2], each = 5)))
>>
>> # I have metabarcoding data with one FASTA-file, one count table and one taxonomy file
>> # Above dummy data is just showing the issue at hand. I want to be able to merge my three
>> # original data frames (here, the dummy data is only two dataframes). The problem is that
>> # the only identifier that is commmon for the dataframes is "hidden" in the
>> # factor name eg: Z.identifierA.1298712 and Q.identifierA.4668726. I hence need to be able
>> # to split this name up into different columns to get "identifierA" alone as one column name
>> # Then I can merge the dataframes.
>> # How can I do this in R. I know that it can be done in excel, but I would like to
>> # produce a complete R-script to get a fast pipeline and avoid copy and paste errors.
>> # This is what I want it to look:
>>
>> df1.goal <- data.frame(cbind(X = 1:10, Y = rnorm(10)),
>>                   Z = factor(rep(LETTERS[1:2], each = 5)),
>>                   identifierA = factor(rep(LETTERS[1:2], each = 5)),
>>                   B1298712 = factor(rep(LETTERS[1:2], each = 5)))
>
> Use strsplit to separate the components, something like
>
> separateNames <- strsplit(names(df1)[3], split = "\\.")[[1]]
> for(name in separateNames) {
>    df1[[name]] <- df1[[3]]
> }
> df1[[3]] <- NULL
>
> Best,
> Ista
>
>>
>> # Many thank's and with kind regards
>> Anna Zakrisson
>>
>>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>>
>> Anna Zakrisson Braeunlich
>> PhD student
>>
>> Department of Ecology, Environment and Plant Sciences
>> Stockholm University
>> Svante Arrheniusv. 21A
>> SE-106 91 Stockholm
>> Sweden/Sverige
>>
>> Lives in Berlin.
>> For paper mail:
>> Katzbachstr. 21
>> D-10965, Berlin
>> Germany/Deutschland
>>
>> E-mail: anna.zakrisson at su.se
>> Tel work: +49-(0)3091541281
>> Mobile: +49-(0)15777374888
>> LinkedIn: http://se.linkedin.com/pub/anna-zakrisson-braeunlich/33/5a2/51b
>>
>>> <((((?>`?. . ? `?. .? `?. . ><((((?>`?. . ? `?. .? `?. .><((((?>`?. . ? `?. .? `?. .><((((?>
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------


From rhelpmaillist at 163.com  Sun Oct 19 19:13:50 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 20 Oct 2014 01:13:50 +0800 (CST)
Subject: [R] how to overwrite  a  Unary operator ?
In-Reply-To: <F13368A3-5F0F-4273-ACB7-94AC9B15E506@comcast.net>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
	<6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
	<881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>
	<2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>
	<F13368A3-5F0F-4273-ACB7-94AC9B15E506@comcast.net>
Message-ID: <3da32d72.7d24.14929669b06.Coremail.rhelpmaillist@163.com>


TKS , but i still have a question that maybe i can write a new S3 method for +, but how can i create a new operator which can pass one param?
becasue + is far away from ++ to let me know that 2 will be 3.
So, it's still a question......




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-10-18 01:40:50, "David Winsemius" <dwinsemius at comcast.net> wrote:
>
>On Oct 17, 2014, at 1:06 AM, PO SU wrote:
>
>> 
>> Tks for your alternative way's details. but like you mentioned in graphics package, i still wonder how to overload an operator which can pass one param like +2 .
>> There seems exists some examples for my needing. But i try to find them but without any results.
>> can you show me some examples from it? 
>> 
>
>I think this might be a case of "if you don't know enough to do it, then you don't know why you shouldn't do it." (Or vice versa?) I did search for a relevant fortune to support my impression, but the various entries for fortune("parse") and fortune("eval") didn't seem to hit the mark.
>
>library(ggplot2)
>help(pack="ggplot2")  # scroll to bottom of page
>ggplot2:::`+.gg`   # this shows the S3 method of adding an operator based on the S3 method dispatch.
>
>I was able to emulate that example to create a C-like, unary `+` operator for a new class, but I'm not willing to put it in print for fear that my karmic account might be depleted.
>
>-- 
>David.
>
>> --
>> 
>> PO SU
>> mail: desolator88 at 163.com 
>> Majored in Statistics from SJTU
>> 
>> 
>> 
>> At 2014-10-17 15:16:47, "David Winsemius" <dwinsemius at comcast.net> wrote:
>>> 
>>> On Oct 16, 2014, at 10:36 PM, PO SU wrote:
>>> 
>>>> 
>>>> Tks for your advice,  let the ++ problem alone, how to write an  
>>>> Unary operator ? Is it permitted in R?
>>>> such    as    a<-2 , a%+2%  will let a  be 4 .
>>> 
>>> OK, that's just wrong. Oh, OK, just for fun, as it were:
>>> 
>>> inc <- function(x)
>>> {
>>> eval.parent(substitute(x <- x + 1))
>>> }
>>> 
>>> 
>>>> inc(10)
>>> Error in 10 <- 10 + 1 : invalid (do_set) left-hand side to assignment
>>>> y=10
>>>> inc(y)
>>>> y
>>> [1] 11
>>> 
>>> 
>>>> I just want to know it , i won't pollute r with it , because i know  
>>>> what is r .  : )
>>>> 
>>> It's certainly permitted. Just look at all the overloadings of the "+"  
>>> operator in graphics packages. Look up the documentation on methods in  
>>> R.
>>> 
>>> Why not just use a well-behaved function, though?
>>> 
>>> .inc <- function(x) x+1
>>>> .inc(10)
>>> [1] 11
>>> 
>>> Then you won't be tempted to try 10 <- .inc(10) because it just  
>>> wouldn't make sense.
>>> 
>>> -- 
>>> David.
>>> 
>>>> --
>>>> 
>>>> PO SU
>>>> mail: desolator88 at 163.com
>>>> Majored in Statistics from SJTU
>>>> 
>>>> 
>>>> 
>>>> 
>>>> At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>>>> On 17/10/14 17:29, PO SU wrote:
>>>>>> 
>>>>>> Dear expeRts,
>>>>>>  Now i want to know how to implement an Unary operator like  i++  
>>>>>> in cpp's  synax form.
>>>>>>  e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>>>>>> I tried this :
>>>>>> '%++%'<-function(x){
>>>>>>   x<<-x+1
>>>>>> }
>>>>>> but it have problem, the biggest one is it seems the function need
>>>>>> twoparams like a%++%b , how to write a function needing just one  
>>>>>> param?
>>>>>> 
>>>>>> TKS !
>>>>> 
>>>>> Just ***DON'T***.  The "++" operator is useful only for those wish to
>>>>> write code which is obscure to the point of incomprehensibility.  It
>>>>> makes C and its offspring "write only" languages.
>>>>> 
>>>>> If you are going to use R, use R and don't pollute it with such
>>>>> abominations.
>>>>> 
>>>>> cheers,
>>>>> 
>>>>> Rolf Turner
>>>>> 
>>>>> 
>>>>> -- 
>>>>> Rolf Turner
>>>>> Technical Editor ANZJS
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius, MD
>>> Alameda, CA, USA
>>> 
>
>David Winsemius
>Alameda, CA, USA
>

From rhelpmaillist at 163.com  Sun Oct 19 19:17:32 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 20 Oct 2014 01:17:32 +0800 (CST)
Subject: [R] how to overwrite a Unary operator ?
In-Reply-To: <CAFEqCdwZ5gk+FJm6DqUHOcjEt73qV7aAA0hJS4f=R=A_RcaK2A@mail.gmail.com>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
	<6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
	<881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>
	<2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>
	<CAFEqCdwZ5gk+FJm6DqUHOcjEt73qV7aAA0hJS4f=R=A_RcaK2A@mail.gmail.com>
Message-ID: <2a7dabb8.7d45.1492969ff69.Coremail.rhelpmaillist@163.com>


It's a good way to use RF OOS, but it's not my needing, actually, i want is there exists a way to write a ?%++% form function that can pass one param to it?
So i can use ?1%++% ?to get 2 ,a<-2 , a%++% to get a<-3 .
It seems that the operator overwrite system in R, must pass two params. Is it true?




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU



At 2014-10-18 00:54:40, "Greg Snow" <538280 at gmail.com> wrote:
>You may be interested in looking at Reference Classes/objects (see
>?setRefClass).  This is a form of OO programming that is more similar
>to C++ and Java.  You could create a counter object that you could
>then increment with syntax like:
>
>x$inc()
>x$inc(5)
>
>The first would increment by the default (1), the second would then
>increment by 5.
>
>
>
>On Fri, Oct 17, 2014 at 2:06 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>
>> Tks for your alternative way's details. but like you mentioned in graphics package, i still wonder how to overload an operator which can pass one param like +2 .
>> There seems exists some examples for my needing. But i try to find them but without any results.
>> can you show me some examples from it?
>>
>>
>>
>>
>>
>>
>> --
>>
>> PO SU
>> mail: desolator88 at 163.com
>> Majored in Statistics from SJTU
>>
>>
>>
>> At 2014-10-17 15:16:47, "David Winsemius" <dwinsemius at comcast.net> wrote:
>>>
>>>On Oct 16, 2014, at 10:36 PM, PO SU wrote:
>>>
>>>>
>>>> Tks for your advice,  let the ++ problem alone, how to write an
>>>> Unary operator ? Is it permitted in R?
>>>> such    as    a<-2 , a%+2%  will let a  be 4 .
>>>
>>>OK, that's just wrong. Oh, OK, just for fun, as it were:
>>>
>>>inc <- function(x)
>>>{
>>>  eval.parent(substitute(x <- x + 1))
>>>}
>>>
>>>
>>> > inc(10)
>>>Error in 10 <- 10 + 1 : invalid (do_set) left-hand side to assignment
>>> > y=10
>>> > inc(y)
>>> > y
>>>[1] 11
>>>
>>>
>>>> I just want to know it , i won't pollute r with it , because i know
>>>> what is r .  : )
>>>>
>>>It's certainly permitted. Just look at all the overloadings of the "+"
>>>operator in graphics packages. Look up the documentation on methods in
>>>R.
>>>
>>>Why not just use a well-behaved function, though?
>>>
>>>.inc <- function(x) x+1
>>> > .inc(10)
>>>[1] 11
>>>
>>>Then you won't be tempted to try 10 <- .inc(10) because it just
>>>wouldn't make sense.
>>>
>>>--
>>>David.
>>>
>>>> --
>>>>
>>>> PO SU
>>>> mail: desolator88 at 163.com
>>>> Majored in Statistics from SJTU
>>>>
>>>>
>>>>
>>>>
>>>> At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>>>> On 17/10/14 17:29, PO SU wrote:
>>>>>>
>>>>>> Dear expeRts,
>>>>>>   Now i want to know how to implement an Unary operator like  i++
>>>>>> in cpp's  synax form.
>>>>>>   e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>>>>>> I tried this :
>>>>>>  '%++%'<-function(x){
>>>>>>    x<<-x+1
>>>>>> }
>>>>>> but it have problem, the biggest one is it seems the function need
>>>>>> twoparams like a%++%b , how to write a function needing just one
>>>>>> param?
>>>>>>
>>>>>> TKS !
>>>>>
>>>>> Just ***DON'T***.  The "++" operator is useful only for those wish to
>>>>> write code which is obscure to the point of incomprehensibility.  It
>>>>> makes C and its offspring "write only" languages.
>>>>>
>>>>> If you are going to use R, use R and don't pollute it with such
>>>>> abominations.
>>>>>
>>>>> cheers,
>>>>>
>>>>> Rolf Turner
>>>>>
>>>>>
>>>>> --
>>>>> Rolf Turner
>>>>> Technical Editor ANZJS
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>David Winsemius, MD
>>>Alameda, CA, USA
>>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>-- 
>Gregory (Greg) L. Snow Ph.D.
>538280 at gmail.com

From cmora at Dal.Ca  Sun Oct 19 20:11:47 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Sun, 19 Oct 2014 18:11:47 +0000
Subject: [R] Plotting sum rather than count in hexbin
In-Reply-To: <5941629.ix6tMaeBOy@localhost.localdomain>
References: <1413706167988.74157@Dal.Ca>,
	<5941629.ix6tMaeBOy@localhost.localdomain>
Message-ID: <1413742308361.90579@Dal.Ca>

Thanks Jim,

Sorry for the confusion. Is there a way to plot the hexbin using the colors generated based on the sums of the values of the points at each hexbin? My problem is not so much about the use of a color scale as it is for Hexbin to display the sum of the bins rather than the count.

Thanks again,

Camilo

________________________________________
From: Jim Lemon <jim at bitwrit.com.au>
Sent: Sunday, October 19, 2014 10:27 AM
To: r-help at r-project.org
Cc: Camilo Mora
Subject: Re: [R] Plotting sum rather than count in hexbin

On Sun, 19 Oct 2014 08:09:28 AM Camilo Mora wrote:
> Hi everyone,
>
> This may be a trivial solution but I would appreciate any help.
>
> I have a database with three variables. I would like to plot the first
two
> variables in a xy plot making the color of points proportional to the
> values in the third variable. Given that many points overlap, I
decided to
> use the hexbin package, which allows aggregating the points by a
third
> variable. I figured out how to make the sums by hexbins but I am
falling
> short in how to link the sums back to the hexbins and then plot the
hexbins
> color coded by the sums?.  Below is the code so far.
>
> Thanks,
>
> Camilo
>
>
>
> library(hexbin)
>
>
> #generates data for three variables
> dat=data.frame(    x = c(rep(1:10,3)),
>                                     y = c(rep(1:10,3)),
>                                     z = c(rep(1:10,3)))
>
> #generates hexbin with the x and y variables
> hbin<-hexbin(dat$x, dat$y, xbins=10, IDs=TRUE)
>
> #sum values of points inside hexbins
> SumHexBin<-hexTapply(hbin, dat$z, sum)
>
>
> #the question is how to link the SumHexBin back to the hbin and
then plot it
> color coding bins by the sums?
>
Hi Camilo,
The color.scale function (plotrix) will convert numeric values into colors
in a number of ways. I think you want the names of SumHexBin as
numbers, so a simple way is:

library(plotrix)
hbincol<-color.scale(as.numeric(names(SumHexBin)),
 extremes=c("red","green"))

Jim



From pdalgd at gmail.com  Sun Oct 19 21:26:39 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 19 Oct 2014 21:26:39 +0200
Subject: [R] Trace of product of matrices
In-Reply-To: <5443EE41.5080302@structuremonitoring.com>
References: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
	<06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
	<5443EE41.5080302@structuremonitoring.com>
Message-ID: <48CBE996-7F4C-41E9-AEB5-8F03C04919EE@gmail.com>


> On 19 Oct 2014, at 19:00 , Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
> 
> On 10/19/2014 8:42 AM, peter dalgaard wrote:
>>> On 19 Oct 2014, at 16:43 , Wagner Bonat <wbonat at gmail.com> wrote:
>>> 
>>> Dear,
>>> 
>>> I have to compute the trace of a product between four matrices. For
>>> example, I know the matrices Wi, Wj and C, I need to compute this
>>> 
>>> -trace(Wi%*%C^-1%*%Wj%*%C^-1)
>>> 
>>> 
>>> I would like to avoid compute the complete matrix and after take the
>>> diagonal, something like
>>> 
>>> sum(diag( solve(Wi,C)%*% solve(Wj,C)))
>> <this can't be right: it is C that is the invertible matrix>
>> 
>>> Any idea is welcome.
>>> 
>> The usual "trick" is that the trace of a matrix product is the inner product in matrix space, which is just the sum of the  elementwise products
>> 
>> tr(AB) = tr(BA) = sum_i sum_j a_ij b_ij.
>> 
>> In R, this becomes simply sum(A*B) -- notice that the ordinary product is used, not %*%. So presumably, you are looking for
>> 
>> sum(solve(C, Wi) * solve(C, Wj))
> 
> missing a transpose?

Yep... 

tr(AB) = tr(BA) = sum_i sum_j a_ij b_ji

which is of course sum(A*t(B)) or vice versa. Thanks.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From eliza_botto at hotmail.com  Sun Oct 19 22:05:02 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Sun, 19 Oct 2014 20:05:02 +0000
Subject: [R] distance from fitted line
Message-ID: <BLU170-W71402E65C3E132743B2F3189960@phx.gbl>

Dear useRs,
I have the following dataset.
> dput(EB)
c(77.724, 76.708, 84.836, 85.09, 118.11, 65.024, 121.412, 63.5, 102.87, 81.3, 108.7, 110.7, 71.9, 42.2, 101, 151.4, 94, 112, 48, 73.4, 76.6, 62.2, 59.4, 114.3, 214.3, 110.5, 46, 84.7, 128.1, 45.2, 109.5, 102.3, 77.5, 61, 97.3, 78, 142, 88.2, 54, 91.4, 54.1, 96, 143.3, 153.7, 101.5, 95.8, 101, 131, 140, 189.4)
I fitted generalized Extreme Value distribution on it by using following codes
library(nsRFA)
q=EB
lmom=Lmoments(q)
pr = par.GEV (lambda1=lmom["l1"], lambda2=lmom["l2"], tau3=lmom["lca"])
RP = c(1.01,2, 10, 20, 50, 100, 200, 500)
quant = invF.GEV (1-1/RP, pr$xi, pr$alfa, pr$k)
qs = sort(q)
pp = 1:length(qs)/(length(qs)+1)
RPpp = 1/(1-pp)
plot(RP, quant, type="l", log="x",col="black",ylim=c(0,500),xlim=c(0.1,500))
points(RPpp, qs)
What I want to do now is to calculate the distance of all the points from the "fitted line" and ultimately calculating RMSE of the data.
Is there a way of doing it?

Thankyou very much in advance

Eliza 		 	   		  
	[[alternative HTML version deleted]]


From cmora at Dal.Ca  Mon Oct 20 00:38:29 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Sun, 19 Oct 2014 22:38:29 +0000
Subject: [R] Plotting sum rather than count in hexbin
In-Reply-To: <5941629.ix6tMaeBOy@localhost.localdomain>
References: <1413706167988.74157@Dal.Ca>,
	<5941629.ix6tMaeBOy@localhost.localdomain>
Message-ID: <1413758311639.64183@Dal.Ca>

I figure out a way to display the hexbins color coded proportional to a third attribute of the points falling on a given hexbin. I share it for future reference or in case anyone has a way to improve it.

Cheers

C

------------------------------------
library(plotrix)
library(hexbin)

#creates a scale of colors
myColorRamp <- function(colors, values) {
    v <- (values - min(values))/diff(range(values))
    x <- colorRamp(colors)(v)
    rgb(x[,1], x[,2], x[,3], maxColorValue = 255)
}

#generates data for three variables
dat=data.frame( x = c(rep(1:10,3)), y = c(rep(1:10,3)), z = c(rep(1:10,3)))

#generates hexbin with the x and y variables
hbin<-hexbin(dat$x, dat$y, xbins=10, IDs=TRUE)

#sums points falling inside bin
SumHexBin<-data.frame(sums=hexTapply(hbin, dat$z, sum))

#do color scale based on values of points in a third variable
cols <- myColorRamp(c("white","green","yellow", "red"), SumHexBin$sums)

## setup coordinate system of the plot
P <- plot(hbin, type="n",legend=FALSE)# asp=1

##add hexagons (in the proper viewport):
pushHexport(P$plot.vp)

#plots hexbins based on colors of third column
grid.hexagons(hbin, style= "lattice", border = gray(.9), pen = cols,  minarea = 1, maxarea = 1)


From cranatic at gmail.com  Mon Oct 20 00:40:06 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 19 Oct 2014 18:40:06 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <54443dc61976_872f5f59381cb@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* bio3d (2.1-1)
  Maintainer: Barry Grant
  Author(s): Barry Grant, Xin-Qiu Yao, Lars Skjaerven, Julien Ide
  License: GPL (>= 2)
  http://crantastic.org/packages/bio3d

  Utilities to process, organize and explore protein structure, 
  sequence and dynamics data.  Features include the ability to read
  and  write structure, sequence and dynamic trajectory data, perform
  sequence  and structure database searches, data summaries, atom
  selection,  alignment, superposition, rigid core identification,
  clustering,  torsion analysis, distance matrix analysis, structure
  and sequence  conservation analysis, normal mode analysis, principal
  component  analysis of heterogeneous structure data, and correlation
  network    analysis from normal mode and molecular dynamics data. 
  In addition,  various utility functions are provided to enable the
  statistical and  graphical power of the R environment to work with
  biological sequence  and structural data.  Please refer to the URLs
  below for more information.

* CLME (1.0-1)
  Maintainer: Casey M. Jelsema
  Author(s): Casey M. Jelsema
  License: GPL-2 | GPL-3
  http://crantastic.org/packages/CLME

  Implements constrained inference for linear mixed effects models using
  residual bootstrap methodology.

* CP (1.5)
  Maintainer: Andreas Kuehnapfel
  Author(s): Andreas Kuehnapfel
  License: GPL-3
  http://crantastic.org/packages/CP

  Functions for calculating the conditional power for different models
  in survival time analysis within randomized clinical trials with two
  different treatments to be compared and survival as an endpoint.

* dataRetrieval (1.4.0)
  Maintainer: Laura DeCicco
  Author(s): Robert Hirsch [aut], Laura DeCicco [aut, cre]
  License: Unlimited | file LICENSE
  http://crantastic.org/packages/dataRetrieval

  Collection of functions to help retrieve USGS data from either web
  services or user-provided data files.

* ecoval (1.0)
  Maintainer: Nele Schuwirth
  Author(s): Nele Schuwirth <nele.schuwirth at eawag.ch> and Peter Reichert
             <peter.reichert at eawag.ch>  with contributions by Simone
             Langhans
  License: GPL (>= 2)
  http://crantastic.org/packages/ecoval

  Functions for evaluating and visualizing ecological assessment
  procedures for surface waters containing physical, chemical and
  biological assessments in the form of value functions.

* enigma (0.1.0)
  Maintainer: Scott Chamberlain
  Author(s): Scott Chamberlain [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/enigma

  Enigma (https://enigma.io) holds many public datasets from
  governments, companies, universities, and organizations. Enigma
  provides an API for data, metadata, and statistics on each of the
  datasets. enigma is an R client to interact with the Enigma API,
  including getting the data and metadata for datasets in Enigma, as
  well as collecting statistics on datasets. In addition, you can
  download a gzipped csv file of a dataset if you want the whole
  dataset. An API key from Enigma is required to use enigma.

* flam (1.0)
  Maintainer: Ashley Petersen
  Author(s): Ashley Petersen
  License: GPL (>= 2)
  http://crantastic.org/packages/flam

  Implements the fused lasso additive model as proposed in Petersen, A.,
  Witten, D., and Simon, N. (2014). Fused Lasso Additive Model. arXiv
  preprint arXiv:1409.5391.

* gets (0.1)
  Maintainer: Genaro Sucarrat
  Author(s): Genaro Sucarrat
  License: GPL-2
  http://crantastic.org/packages/gets

  Automated multi-path General-to-Specific (GETS) model selection of
  either an AR-X model with log-ARCH-X errors, or a log-ARCH-X model
  of the log-variance. The three main functions of the package are
  arx, getsm and getsv. The first function estimates an AR-X model
  with log-ARCH-X errors. The second function undertakes GETS model
  selection of the mean specification of an arx object, whereas the
  third function undertakes GETS model selection of the log-variance
  specification of an arx object.

* ggRandomForests (1.0.0)
  Maintainer: John Ehrlinger
  Author(s): John Ehrlinger <john.ehrlinger at gmail.com>
  License: GPL (>= 3)
  http://crantastic.org/packages/ggRandomForests

  The ggRandomForests package contains tools for creating and plotting
  data structures to visually understand random forest models. The
  functions are designed for use with the randomForestSRC package.
  This package is structured to extract intermediate data objects from
  the random forest. S3 Plot functions, which use the ggplot2 package,
  are included for each data object.

* highTtest (1.0)
  Maintainer: Shannon Holloway
  Author(s): Hongyuan Cao [aut], Michael Kosorok [aut], Shannon Holloway [aut, cre]
  License: GPL-2
  http://crantastic.org/packages/highTtest

  Implements the method developed by Cao and Kosorok (2011) for the
  significance analysis of thousands of features in high-dimensional
  biological studies. It is an asymptotically valid data-driven
  procedure to find critical values for rejection regions controlling
  the k-familywise error rate, false discovery rate, and the tail
  probability of false discovery proportion.

* landpred (1.0)
  Maintainer: Layla Parast
  Author(s): Layla Parast
  License: GPL
  http://crantastic.org/packages/landpred

  This package includes functions for landmark prediction of a survival
  outcome incorporating covariate and short-term event information.
  For more information about landmark prediction please see: Parast,
  Layla, Su-Chun Cheng, and Tianxi Cai. Incorporating short-term
  outcome information to predict long-term survival with discrete
  markers. Biometrical Journal 53.2 (2011): 294-307.

* logbin (1.0)
  Maintainer: Mark Donoghoe
  Author(s): Mark Donoghoe <mark.donoghoe at mq.edu.au>
  License: GPL (>= 2)
  http://crantastic.org/packages/logbin

  Methods for fitting log-link GLMs and GAMs for binomial data.  The
  package uses EM-type algorithms with more stable convergence
  properties than standard methods.

* logconPH (1.0)
  Maintainer: Clifford Anderson-Bergman
  Author(s): Clifford Anderson-Bergman
  License: GPL-2
  http://crantastic.org/packages/logconPH

  Computes a cox PH model with a log concave baseline distribution. If
  no covariates are provided, estimates the log concave NPMLE. Built
  specifically for interval censored data, where data is a n by 2
  matrix with [i, 1] as the left side of the interval for subject i
  and [i,2] as right side. Uncensored data can be entered by setting
  [i,1] = [i,2]. Alternatively, this can also handle uncensored data.
  If all the data is uncensored, you may enter data as a length(n)
  vector.

* mdscore (0.1-2)
  Maintainer: Antonio Hermes M. da Silva-Junior
  Author(s): Antonio Hermes M. da Silva-Junior [aut, cre], Damiao N. da Silva
             [aut], Silvia L. P. Ferrari [ctb]
  License: GPL (>= 2)
  http://crantastic.org/packages/mdscore

  A set of functions to obtain modified score test for generalized
  linear models.

* metaMix (0.1)
  Maintainer: Sofia Morfopoulou
  Author(s): Sofia Morfopoulou <sofia.morfopoulou.10 at ucl.ac.uk>
  License: GPL-3
  http://crantastic.org/packages/metaMix

  metaMix resolves complex metagenomic mixtures by analysing deep
  sequencing data, using a Mixture Model based approach. The use of
  parallel Monte Carlo Markov chains for the exploration of the
  species space enables the identification of the set of species more
  likely to contribute to the mixture.

* MRH (1.0)
  Maintainer: Yolanda Hagar
  Author(s): Yolanda Hagar, Yuanting Chen, Vanja Dukic
  License: GPL-2
  http://crantastic.org/packages/MRH

  Used on survival data to jointly estimate the hazard rate and the
  effects of covariates on failure times.

* nsgp (1.0.5)
  Maintainer: Markus Heinonen
  Author(s): Markus Heinonen
  License: GPL-2
  http://crantastic.org/packages/nsgp

  A Gaussian process regression using a Gaussian kernel for both
  one-sample and two-sample cases. Includes non-stationary Gaussian
  kernel (exponential decay function) and several likelihood ratio
  tests for differential testing along target points.

* pBrackets (1.0)
  Maintainer: ADES
  Author(s): Andreas Schulz
  License: GPL (>= 2.0)
  http://crantastic.org/packages/pBrackets

  Adds different kinds of brackets to a plot, including braces,
  chevrons, parentheses or square brackets.

* prettyunits (1.0.0)
  Maintainer: &quot;Gabor Csardi&quot;
  Author(s): "Gabor Csardi" [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/prettyunits

  Pretty, human readable formatting of quantities. Time intervals:
  1337000 -&gt; 15d 11h 23m 20s. Vague time intervals: 2674000 -&gt; about a
  month ago. Bytes: 1337 -&gt; 1.34 kB.

* QualInt (1.0.0)
  Maintainer: Lixi Yu
  Author(s): Lixi Yu, Eun-Young Suh, Guohua (James) Pan
  License: GPL-2
  http://crantastic.org/packages/QualInt

  Used for testing for qualitative interactions between treatment
  effects and patient subgroups. Here the term treatment effect means
  a comparison result of two treatments within each patient subgroup.
  Models included in this package are Gaussian, binomial and Cox
  models. Methods included here are interval based graphical approach
  and Gail Simon LRT.

* RCMIP5 (1.0)
  Maintainer: Kathe Todd-Brown
  Author(s): Ben Bond-Lamberty [aut], Kathe Todd-Brown [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/RCMIP5

  Working with CMIP5 data can be tricky, forcing scientists to write
  custom scripts and programs. The `RCMIP5` package aims to ease this
  process, providing a standard, robust, and high-performance set of
  scripts to (i) explore what data have been downloaded, (ii) identify
  missing data, (iii) average (or apply other mathematical operations)
  across experimental ensembles, (iv) produce both temporal and
  spatial statistical summaries, (v) regrid data, and (vi) produce
  easy-to-work-with graphical and data summaries.

* rex (0.1.0)
  Maintainer: Jim Hester
  Author(s): Kevin Ushey, Jim Hester
  License: MIT + file LICENSE
  http://crantastic.org/packages/rex

  A simpler, human-readable interface for the construction of regular
  expressions.

* rfoaas (0.0.4)
  Maintainer: Dirk Eddelbuettel
  Author(s): Dirk Eddelbuettel <edd at debian.org>
  License: GPL (>= 2)
  http://crantastic.org/packages/rfoaas

  R access to the FOAAS (F... Off As A Service) web service

* rivernet (1.0)
  Maintainer: Peter Reichert
  Author(s): Peter Reichert
  License: GPL (>= 2)
  http://crantastic.org/packages/rivernet

  Functions for reading, analysing and plotting river networks. For this
  package, river networks consist of sections and nodes with
  associated attributes,  e.g. to characterise their morphological,
  chemical and biological state. The package provides functions to
  read this data from text files, to analyse the network structure and
  network paths and regions consisting of sections and nodes that
  fulfill prescribed criteria, and to plot the river network and
  associated properties.

* RMKdiscrete (0.1)
  Maintainer: Robert M. Kirkpatrick
  Author(s): Robert M. Kirkpatrick <rkirkpatrick2 at vcu.edu>
  License: GPL (>= 2)
  http://crantastic.org/packages/RMKdiscrete

  Sundry discrete probability distributions and helper functions.

* segmag (1.2.2)
  Maintainer: Frank Papenmeier
  Author(s): Frank Papenmeier [aut, cre], Konstantin Sering [ctb]
  License: GPL (>= 3)
  http://crantastic.org/packages/segmag

  This package contains functions that help to determine event
  boundaries in event segmentation experiments by bootstrapping a
  critical segmentation magnitude under the null hypothesis that all
  key presses were randomly distributed across the experiment.
  Segmentation magnitude is defined as the sum of Gaussians centered
  at the times of the segmentation key presses performed by the
  participants. Within a participant, the maximum of the overlaid
  Gaussians is used to prevent an excessive influence of a single
  participant on the overall outcome (e.g. if a participant is
  pressing the key multiple times in succession). Further functions
  are included, such as plotting the results.

* sisVIVE (1.0)
  Maintainer: Hyunseung Kang
  Author(s): Hyunseung Kang <khyuns at wharton.upenn.edu>
  License: GPL-2
  http://crantastic.org/packages/sisVIVE

  Selects invalid instruments amongst a candidate of potentially bad
  instruments. The algorithm selects potentially invalid instruments
  and provides an estimate of the causal effect between exposure and
  outcome. The paper, Instrumental Variables Estimation with Some
  Invalid Instruments and its Application to Mendelian Randomization
  by Hyunseung Kang, Anru Zhang, T. Tony Cai, and Dylan S. Small (on
  arXiv) has more details on this procedure.

* spark (1.0.0)
  Maintainer: &quot;Gabor Csardi&quot;
  Author(s): "Gabor Csardi" [aut, cre]
  License: MIT + file LICENSE
  http://crantastic.org/packages/spark

  Sparklines in the terminal. Essentially an R implementation of the
  original shell project: http://zachholman.com/spark/

* statar (0.1)
  Maintainer: Matthieu Gomez
  Author(s): Matthieu Gomez [aut, cre]
  License: GPL-2
  http://crantastic.org/packages/statar

  statar includes a set of functions for vectors: mode, tag, bin and
  winsorize. statar includes a set of functions for data.tables:
  summarize (in tables or graphs), panel data operations (lag, fill in
  gaps, fill in missing values) and SQL-type joins.

* vetools (1.3-28)
  Maintainer: Andrew Sajo-Castelli
  Author(s): Andrew Sajo-Castelli [aut, cre], Desiree Villalta [ctb], Lelys Bravo
             [ctb]
  License: GPL
  http://crantastic.org/packages/vetools

  Integrated data management library that offers a variety of tools
  concerning the loading and manipulation of environmental data
  available from different Venezuelan governmental sources. Facilities
  are provided to plot temporal and spatial data as well as understand
  the health of a collection of meteorological data.

* windex (1.0)
  Maintainer: Kevin Arbuckle
  Author(s): Kevin Arbuckle and Amanda Minter
  License: GPL-2
  http://crantastic.org/packages/windex

  Analysing convergent evolution using the Wheatsheaf index.


Updated packages
----------------

AICcmodavg (2.0-1), AlgDesign (1.1-7.3), ASMap (0.3-2), BcDiag
(1.0.5), circlize (0.1.2), clustvarsel (2.1), crayon (1.1.0), cwhmisc
(5.0), datamart (0.5.2), dice (1.2), eegkit (1.0-1), epinet (2.0.8),
evtree (1.0-0), frailtypack (2.7.2), GA (2.2), gsg (2.0), kselection
(0.1.1), matrixStats (0.10.3), mclogit (0.3-1), memisc (0.96-10), msBP
(1.0-1), MVN (3.5), NbClust (2.0.3), NPCirc (2.0.1), overlap (0.2.4),
pdc (1.0), PtProcess (3.3-7), R.devices (2.12.0), randomLCA (1.0-0),
raster (2.3-12), raster (2.3-10), rcdk (3.3.2), RcmdrPlugin.steepness
(0.3-2), rNOMADS (2.0.3), SCGLR (2.0.1), SemiParBIVProbit (3.2-12),
SMR (2.0), spgrass6 (0.8-6), spgwr (0.6-25), sptm (14.10-11), StMoSim
(3.0), stochvol (0.9-0), strvalidator (1.3.1), tis (1.27), utility
(1.3)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From rhelpmaillist at 163.com  Mon Oct 20 04:29:15 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 20 Oct 2014 10:29:15 +0800 (CST)
Subject: [R]   How to read tif format file?
Message-ID: <c6b0e8.9df9.1492b631908.Coremail.rhelpmaillist@163.com>


Dear expeRts,
?? I want to read a? a.tif file into? R.
?When i? try this:
readGDAL("a.tif"), i get the following error:


a.tif?has?GDAL?driver?GTiff?
and?has?7200?rows?and?7200?columns

error: can't allocate 395.5 mb vector
but i can GDAL.open("a.tif") it.
SO what's wrong with readGDAL? 





--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From rhelpmaillist at 163.com  Mon Oct 20 04:32:21 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Mon, 20 Oct 2014 10:32:21 +0800 (CST)
Subject: [R]  HOW to call R code from matlab?
Message-ID: <774202ea.9f84.1492b65f0e7.Coremail.rhelpmaillist@163.com>



Dear expeRts,
?? I am fammilar with matlab , i want to call some r codes from it , what can i refer?
?I tried R.matlab. But it seems can't work well. so, do you have any other suggestions?




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From hb at biostat.ucsf.edu  Mon Oct 20 04:48:50 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 19 Oct 2014 19:48:50 -0700
Subject: [R] HOW to call R code from matlab?
In-Reply-To: <774202ea.9f84.1492b65f0e7.Coremail.rhelpmaillist@163.com>
References: <774202ea.9f84.1492b65f0e7.Coremail.rhelpmaillist@163.com>
Message-ID: <CAFDcVCRtw7iaYP9O+YhsHHuBAjAf7QuYb+2sUHmoQ8bmoQs4kw@mail.gmail.com>

On Oct 19, 2014 7:33 PM, "PO SU" <rhelpmaillist at 163.com> wrote:
>
>
>
> Dear expeRts,
>    I am fammilar with matlab , i want to call some r codes from it , what
can i refer?
>  I tried R.matlab. But it seems can't work well.

Correct, R.matlab can only be used to call MATLAB from R, but not the other
way around.

I'll let someone else comment on whether there exists something in MATLAB
for calling R or not.

Henrik
(author of R.matlab)

> so, do you have any other suggestions?
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mdsumner at gmail.com  Mon Oct 20 05:50:28 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Mon, 20 Oct 2014 14:50:28 +1100
Subject: [R] How to read tif format file?
In-Reply-To: <c6b0e8.9df9.1492b631908.Coremail.rhelpmaillist@163.com>
References: <c6b0e8.9df9.1492b631908.Coremail.rhelpmaillist@163.com>
Message-ID: <CAAcGz989jJScNDoZnp3pGjt70BjKnCZ_N13Obtorbsg3bB1+Hw@mail.gmail.com>

What's wrong is that readGDAL tries to allocate all the memory
required and build an object to essentially replace the file, and your
machine cannot provide sufficient resources for that. GDAL.open
provides an open connnection to the file that can be queried in
different ways to read parts of the file as necessary.

You can provide low level arguments to readGDAL to subset/subsample:
"offset", "region.dim", and "output.dim". See ?readGDAL.

But, there are facilities in the raster package to open the file with
GDAL.open and read on demand. Try this:

library(raster)
raster("a.tif")

If your .tif has more than one band, you'll have to use
raster::brick() or raster::stack(), which will read only the first
band by default.

Cheers, Mike.

On Mon, Oct 20, 2014 at 1:29 PM, PO SU <rhelpmaillist at 163.com> wrote:
>
> Dear expeRts,
>    I want to read a  a.tif file into  R.
>  When i  try this:
> readGDAL("a.tif"), i get the following error:
>
>
> a.tif has GDAL driver GTiff
> and has 7200 rows and 7200 columns
>
> error: can't allocate 395.5 mb vector
> but i can GDAL.open("a.tif") it.
> SO what's wrong with readGDAL?
>
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From chiefmurphy at gmail.com  Mon Oct 20 08:18:18 2014
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Sun, 19 Oct 2014 23:18:18 -0700
Subject: [R] pasteFromExcel
Message-ID: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>

To Users of Excel:

Following advice from Brian and Markus, I created an RMarkdown "vignette"
that shows an example of how the pasteFromExcel function in the excelRio
package on github could be used by an actuary to transfer a triangle from
Excel to R. See today's post at http://trinostics.blogspot.com/

Unfortunately, if you are located outside the US, the demonstrated
functionality will not work for you because the currency regex implemented
assumes the dollar sign ($) and comma/decimal punctuation of the form
999,999.00.

If anyone is interested in contributing currency regex expressions that
work in your locale, I would be happy to try to incorporate them in the
package. If anyone knows how best to determine the user's locale (might
"timezone" suffice?), I'd appreciate that help too.

Thanks a lot.

Dan

	[[alternative HTML version deleted]]


From infojomy at gmail.com  Mon Oct 20 08:21:45 2014
From: infojomy at gmail.com (Jomy Jose)
Date: Mon, 20 Oct 2014 11:51:45 +0530
Subject: [R] 2 missing observation of LSD analysis in R
Message-ID: <CADGufDFXUrZQqHKPJastXO+Uu-eg9R_k=eQHDpzWkLMFawjviQ@mail.gmail.com>

How to deal with the analysis of 2 missing observations in case of Latin
square design

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Mon Oct 20 09:02:37 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Mon, 20 Oct 2014 10:02:37 +0300
Subject: [R] 2 missing observation of LSD analysis in R
In-Reply-To: <CADGufDFXUrZQqHKPJastXO+Uu-eg9R_k=eQHDpzWkLMFawjviQ@mail.gmail.com>
References: <CADGufDFXUrZQqHKPJastXO+Uu-eg9R_k=eQHDpzWkLMFawjviQ@mail.gmail.com>
Message-ID: <CAGh51gSBe2XuaCmgLt7Cc5jEbbaDMK5t19w4u4Jrwq3OXHVSQA@mail.gmail.com>

I guess you can use na.string="1st missing value "
then data[data==second missing value]<-NA.


On Mon, Oct 20, 2014 at 9:21 AM, Jomy Jose <infojomy at gmail.com> wrote:

> How to deal with the analysis of 2 missing observations in case of Latin
> square design
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Oct 20 09:03:36 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 20 Oct 2014 07:03:36 +0000
Subject: [R] format negative numbers
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>

Dear all.

Before I start fishing in (for me) murky regular expression waters I try to ask community about changing format of negative numbers.

For some reason I get a file with negative numbers formatted with negative sign at end of number.

something like

0.123-

It is imported as factors and I need to convert it to numbers again. Before converting I need to change it to "correct" format

-0.123

Does anybody know some simple way?

Cheers
Petr


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From Swapnil.Khobragade at lntinfotech.com  Mon Oct 20 09:03:34 2014
From: Swapnil.Khobragade at lntinfotech.com (Swapnil Khobragade)
Date: Mon, 20 Oct 2014 12:33:34 +0530
Subject: [R] need help for predictive analytics part
Message-ID: <24E59E774BB54C4D835922C8D6BA8093014B04C82A@POWINMSMBX01.pwiodc.lntinfotech.com>


Hello sir,

 Actually, I 'm novice to R programming and currently working on prediction part for CPU usage log file (attached with mail).
My task is to predict next hour CPU usage by taking "Time" as response and  %user    %nice   %system   %iowait    %steal     %idle, either all or one as predictor(s).
Please help me out.

I have attached CPU usage log file with mail.
Please find attachment.


Thank You in advance.





Regards,
Swapnil Khobragade
Larsen & Toubro Infotech Ltd.
Bldg. No.5&6, 1st Floor,
Airoli, Navi Mumbai - 400708.
e-mail ID: swapnil.khobragade at lntinfotech.com
Tel: @@@@@@@(Direct) | +91 9503043368 (M)



The contents of this e-mail and any attachment(s) may contain confidential or privileged information for the intended recipient(s). Unintended recipients are prohibited from taking action on the basis of information in this e-mail and  using or disseminating the information,  and must notify the sender and delete it from their system. L&T Infotech will not accept responsibility or liability for the accuracy or completeness of, or the presence of any virus or disabling code in this e-mail"
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: cpuhour1.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141020/1f47230d/attachment.txt>

From ntfredo at gmail.com  Mon Oct 20 09:47:44 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Mon, 20 Oct 2014 10:47:44 +0300
Subject: [R] Dry Spell Problem.
Message-ID: <CAGh51gRfrwP2dWD+owJvSkmFKFRDNJCWLUYEaCbxjOytjXFsew@mail.gmail.com>

Dear All,

I want to solve the following problem on a climatic dataset. It contains
Year, Day and Rain as Columns names.

Ex: > head(Samaru56)
  Year Day Rain
1 1928   1    0
2 1928   2    0
3 1928   3    0
4 1928   4    0
5 1928   5    0
6 1928   6    0

The first day from April 01 that gets more than 20 mm on a single day, or
totalled
over 2 consecutive days with the additional condition that there is no 10
day (or longer) dry spell in the next 30 days.

Any help is appreciated. Thanks!!!

Regards,
Frederic.
-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From Swapnil.Khobragade at lntinfotech.com  Mon Oct 20 10:47:17 2014
From: Swapnil.Khobragade at lntinfotech.com (Swapnil Khobragade)
Date: Mon, 20 Oct 2014 14:17:17 +0530
Subject: [R] FW: need help for predictive analytics part
In-Reply-To: <24E59E774BB54C4D835922C8D6BA8093014B04C82A@POWINMSMBX01.pwiodc.lntinfotech.com>
References: <24E59E774BB54C4D835922C8D6BA8093014B04C82A@POWINMSMBX01.pwiodc.lntinfotech.com>
Message-ID: <24E59E774BB54C4D835922C8D6BA8093014B04C8E1@POWINMSMBX01.pwiodc.lntinfotech.com>



Hello sir,

 Actually, I 'm novice to R programming and currently working on prediction part for CPU usage log file (attached with mail).
My task is to predict next hour CPU usage by taking "Time" as response and  %user    %nice   %system   %iowait    %steal     %idle, either all or one as predictor(s).
Please help me out.

I have attached CPU usage log file with mail.
Please find attachment.


Thank You in advance.

################################################  This code is not working #################################

cpu <- read.table(file = "D:/Swapnil/Data/cpu.txt", header = FALSE, col.names = c("Time","CPU","user","Nice","System","Iowait","Steal","Idle") )
#cpu

user <- rep(cpu$user)
Time <- c(cpu$Time)
Time

Time <- c(cpu$Time)
user <- rep(cpu$user)
user

plot(cpu$user, xaxt="n", ylab="USER", xlab="")
axis(1, labels=paste(cpu$user), at=1:11)

cor(user, Time)

fit <- lm(Time ~ user)
fit

attributes(fit)

fit$coefficients

residuals(fit)
summary(fit)

plot(fit)


	#prdiction part

Time2hr <- data.frame(user=2.00)
user2hr <-predict(fit, newdata=Time2hr)

user2hr <-predict(fit, newdata=Time2hr)
style <- c(rep(1,11))
plot(c(Time, user2hr), xaxt="n", ylab="TIME", xlab="", pch=style, col=style)
axis(1, at=1:11,labels=c(paste(cpu$user,sep="Q"), "2011Q1", "2011Q2", "2011Q3", 

#########################################################################


Regards,
Swapnil Khobragade
Larsen & Toubro Infotech Ltd.
Bldg. No.5&6, 1st Floor,
Airoli, Navi Mumbai - 400708.
e-mail ID: swapnil.khobragade at lntinfotech.com
Tel: @@@@@@@(Direct) | +91 9503043368 (M)



The contents of this e-mail and any attachment(s) may contain confidential or privileged information for the intended recipient(s). Unintended recipients are prohibited from taking action on the basis of information in this e-mail and  using or disseminating the information,  and must notify the sender and delete it from their system. L&T Infotech will not accept responsibility or liability for the accuracy or completeness of, or the presence of any virus or disabling code in this e-mail"
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: cpuhour1.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141020/25def3c0/attachment.txt>
-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: ATT00001..txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141020/25def3c0/attachment-0001.txt>

From Swapnil.Khobragade at lntinfotech.com  Mon Oct 20 11:00:14 2014
From: Swapnil.Khobragade at lntinfotech.com (Swapnil Khobragade)
Date: Mon, 20 Oct 2014 14:30:14 +0530
Subject: [R] need help for predictive analytics part
In-Reply-To: <24E59E774BB54C4D835922C8D6BA8093014B04C8E1@POWINMSMBX01.pwiodc.lntinfotech.com>
References: <24E59E774BB54C4D835922C8D6BA8093014B04C82A@POWINMSMBX01.pwiodc.lntinfotech.com>
	<24E59E774BB54C4D835922C8D6BA8093014B04C8E1@POWINMSMBX01.pwiodc.lntinfotech.com>
Message-ID: <24E59E774BB54C4D835922C8D6BA8093014B04C8F3@POWINMSMBX01.pwiodc.lntinfotech.com>


Hello sir,

 Actually, I 'm novice to R programming and currently working on prediction part for CPU usage log file (attached with mail).
My task is to predict next hour CPU usage by taking "Time" as response and  %user    %nice   %system   %iowait    %steal     %idle, either all or one as predictor(s).
Please help me out.

I have attached CPU usage log file with mail.
Please find attachment.


Thank You in advance.

################################################  This code is not working #################################

cpu <- read.table(file = "D:/Swapnil/Data/cpu.txt", header = FALSE, col.names = c("Time","CPU","user","Nice","System","Iowait","Steal","Idle") ) #cpu

user <- rep(cpu$user)
Time <- c(cpu$Time)
Time

Time <- c(cpu$Time)
user <- rep(cpu$user)
user

plot(cpu$user, xaxt="n", ylab="USER", xlab="") axis(1, labels=paste(cpu$user), at=1:11)

cor(user, Time)

fit <- lm(Time ~ user)
fit

attributes(fit)

fit$coefficients

residuals(fit)
summary(fit)

plot(fit)


        #prdiction part

Time2hr <- data.frame(user=2.00)
user2hr <-predict(fit, newdata=Time2hr)

user2hr <-predict(fit, newdata=Time2hr)
style <- c(rep(1,11))
plot(c(Time, user2hr), xaxt="n", ylab="TIME", xlab="", pch=style, col=style) axis(1, at=1:11,labels=c(paste(cpu$user,sep="Q"), "2011Q1", "2011Q2", "2011Q3",

#########################################################################


Regards,
Swapnil Khobragade
Larsen & Toubro Infotech Ltd.
Bldg. No.5&6, 1st Floor,
Airoli, Navi Mumbai - 400708.
e-mail ID: swapnil.khobragade at lntinfotech.com
Tel: @@@@@@@(Direct) | +91 9503043368 (M)

The contents of this e-mail and any attachment(s) may contain confidential or privileged information for the intended recipient(s). Unintended recipients are prohibited from taking action on the basis of information in this e-mail and  using or disseminating the information,  and must notify the sender and delete it from their system. L&T Infotech will not accept responsibility or liability for the accuracy or completeness of, or the presence of any virus or disabling code in this e-mail"

From kridox at ymail.com  Mon Oct 20 11:25:30 2014
From: kridox at ymail.com (Pascal Oettli)
Date: Mon, 20 Oct 2014 18:25:30 +0900
Subject: [R] Dry Spell Problem.
In-Reply-To: <CAGh51gRfrwP2dWD+owJvSkmFKFRDNJCWLUYEaCbxjOytjXFsew@mail.gmail.com>
References: <CAGh51gRfrwP2dWD+owJvSkmFKFRDNJCWLUYEaCbxjOytjXFsew@mail.gmail.com>
Message-ID: <CAAcyNCyP=5ogx7Vnr1ejRE4=tDuHLAjiqK1To9xKQdrgDJiAEA@mail.gmail.com>

Hi,

Did you have a look at the "dw.spell" function from the "RMRAINGEN"
package? It might be a starting point for you.

Regards,
Pascal

On Mon, Oct 20, 2014 at 4:47 PM, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
> Dear All,
>
> I want to solve the following problem on a climatic dataset. It contains
> Year, Day and Rain as Columns names.
>
> Ex: > head(Samaru56)
>   Year Day Rain
> 1 1928   1    0
> 2 1928   2    0
> 3 1928   3    0
> 4 1928   4    0
> 5 1928   5    0
> 6 1928   6    0
>
> The first day from April 01 that gets more than 20 mm on a single day, or
> totalled
> over 2 consecutive days with the additional condition that there is no 10
> day (or longer) dry spell in the next 30 days.
>
> Any help is appreciated. Thanks!!!
>
> Regards,
> Frederic.
> --
> Frederic Ntirenganya
> Maseno University,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Pascal Oettli
Project Scientist
JAMSTEC
Yokohama, Japan


From eliza_botto at hotmail.com  Mon Oct 20 12:00:11 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Mon, 20 Oct 2014 10:00:11 +0000
Subject: [R] distance from fitted line
In-Reply-To: <OF35C7FB0E.2D231DDC-ONC1257D77.0030D34A-C1257D77.003279B0@pcsierteelt.be>
References: <BLU170-W71402E65C3E132743B2F3189960@phx.gbl>,
	<OF35C7FB0E.2D231DDC-ONC1257D77.0030D34A-C1257D77.003279B0@pcsierteelt.be>
Message-ID: <BLU170-W554B3865E3A2223DCB4D9389970@phx.gbl>

Thankyou very much Joachim. Actually I already know the residual() command. I only wanted to know that is there a way to account for the fitted lines? its more of a criosity rather than a problem. 
:)
Thankyou very much once again.

Eliza

To: eliza_botto at hotmail.com
Subject: Re: [R] distance from fitted line
From: Joachim.Audenaert at pcsierteelt.be
Date: Mon, 20 Oct 2014 11:11:21 +0200

Hello Eliza,



I'm quite new to R, but I use the residuals
function to calculate the distance from my data points to the fitted line
of my nls (non linear least squares model).



residuals(name of your fitted model)



I would check for a model that fits
your datapoints and then calculate the residuals of the model to your data.
Why do you fit the generalized Extreme Value distribution
to your points in stead
of a regression model?



Met vriendelijke groeten/Kind Regards,



Joachim Audenaert 

onderzoeker gewasbescherming



PCS |
proefcentrum voor sierteelt




Schaessestraat 18, 9070
Destelbergen, Belgi?

T: +32 (0)9 353 94 71 | F: +32 (0)9 353 94 95

E: joachim.audenaert at pcsierteelt.be
| W: www.pcsierteelt.be



>> KEN JIJ DE
8 BASISPRINCIPES VAN IPM? MEER INFO OP WWW.PCSIERTEELT.BE
    






From:      
 eliza botto <eliza_botto at hotmail.com>

To:      
 "r-help at r-project.org"
<r-help at r-project.org>

Date:      
 19/10/2014 22:08

Subject:    
   [R] distance
from fitted line

Sent by:    
   r-help-bounces at r-project.org









Dear useRs,

I have the following dataset.

> dput(EB)

c(77.724, 76.708, 84.836, 85.09, 118.11, 65.024, 121.412, 63.5, 102.87,
81.3, 108.7, 110.7, 71.9, 42.2, 101, 151.4, 94, 112, 48, 73.4, 76.6, 62.2,
59.4, 114.3, 214.3, 110.5, 46, 84.7, 128.1, 45.2, 109.5, 102.3, 77.5, 61,
97.3, 78, 142, 88.2, 54, 91.4, 54.1, 96, 143.3, 153.7, 101.5, 95.8, 101,
131, 140, 189.4)

I fitted generalized Extreme Value distribution on it by using following
codes

library(nsRFA)

q=EB

lmom=Lmoments(q)

pr = par.GEV (lambda1=lmom["l1"], lambda2=lmom["l2"],
tau3=lmom["lca"])

RP = c(1.01,2, 10, 20, 50, 100, 200, 500)

quant = invF.GEV (1-1/RP, pr$xi, pr$alfa, pr$k)

qs = sort(q)

pp = 1:length(qs)/(length(qs)+1)

RPpp = 1/(1-pp)

plot(RP, quant, type="l", log="x",col="black",ylim=c(0,500),xlim=c(0.1,500))

points(RPpp, qs)

What I want to do now is to calculate the distance of all the points from
the "fitted line" and ultimately calculating RMSE of the data.

Is there a way of doing it?



Thankyou very much in advance



Eliza                  
               
                 
                 
               
     

                
[[alternative HTML version deleted]]



______________________________________________

R-help at r-project.org mailing list

https://stat.ethz.ch/mailman/listinfo/r-help

PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

and provide commented, minimal, self-contained, reproducible code.







PCS-proeven
leiden tot nieuwe erkenningen in de sierteelt
| Het
PCS op LinkedIn

Disclaimer\ | Please consider the environment before pri...{{dropped:6}}


From m.fatemi82 at gmail.com  Mon Oct 20 10:27:48 2014
From: m.fatemi82 at gmail.com (M Fatemi)
Date: Mon, 20 Oct 2014 11:57:48 +0330
Subject: [R] saving parameters as a variable
Message-ID: <CAP7mSY5njy6-W_sHPC9Z2AJb2_PSf=ScNmik-tW9fxHiKgSFHw@mail.gmail.com>

Hi;
In the simulation studies we need to save some measure in the output as a
variable to do some calculation on them,  how we can do that?

For example: the p-value , t-value, in t-test  ( t.test( ) )

or

The estimated parameters in some models,(Ex: IRT model: graded response
model) in ltm package:
(see grm model in attachment file)


grm(data, constrained = FALSE, *IRT.param* = TRUE, ...)

*IRT.param:*

bij: difficulty parameter for item i and category j)
ai : discriminant parameter for item i)
thata(k) : ability parameter for person k

Note that this package does not give theta(k) even in output!
How can i load theta parameters?

Thanks in advanse
-------------- next part --------------
A non-text attachment was scrubbed...
Name: GRM.png
Type: image/png
Size: 6495 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141020/66131974/attachment.png>

From julian.bothe at elitepartner.de  Mon Oct 20 12:26:38 2014
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Mon, 20 Oct 2014 12:26:38 +0200 (CEST)
Subject: [R] dbHasCompleted() always returns TRUE for POSTGRES Database with
	RJDBC?
Message-ID: <549b5d1c.00000a58.00000005@FIW7PC12.ELITEMEDIANET>

Hello Simon, Hello everyone,

I have a problem with retrieving database-queries chunkwise. In my query
(Postgresql-Database,  Postgres-Version 9.1) dbHasCompleted seems to
always return TRUE. 

dbGetQuery works for smaller tables, but not for the whole query, since
then a Heap-Overflow-Error will occur (and a Error:
"java.lang.OutOfMemoryError: GC overhead limit exceeded" when trying to
set a larger size).

Does anybody else have or had this problem?

 

All the best

Julian

 

######## adapted Example from help (?dbHasCompleted ), Works #######

require("RSQLite")
 
con <- dbConnect(RSQLite::SQLite(), ":memory:")
dbWriteTable(con, "mtcars", mtcars)
 
# Fetch all results
res <- dbSendQuery(con, "SELECT * FROM mtcars WHERE cyl = 4")
dbFetch(res)
dbClearResult(res)
 
# Fetch in chunks
res <- dbSendQuery(con, "SELECT * FROM mtcars")
dbHasCompleted(res) ## RETURNS FALSE !!!
 
while (!dbHasCompleted(res)) {
  chunk <- fetch(res, 10)
  print(nrow(chunk))
}
dbClearResult(res)
dbDisconnect(con)

 

 

########## My Code, lamentably not reproducible because of needed
Postgres-Server, not working #########

 

# Connect to Postgres-Database 

res2 <- dbSendQuery(Postgres_con, 

                   "select  id from mytable limit 1000;"       

)

 

dbHasCompleted(res2) ##RETURNS TRUE!

 

while (!dbHasCompleted(res2)) {

  chunk <- fetch(res2, 10 )

  rbind(dk, chunk)

}

 

try({

  dbClearResult(res2)

  rm(chunk,res2)

})


	[[alternative HTML version deleted]]


From rainer.schuermann at gmx.net  Mon Oct 20 12:48:31 2014
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Mon, 20 Oct 2014 12:48:31 +0200
Subject: [R] format negative numbers
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>
Message-ID: <201410201248.31302.rainer.schuermann@gmx.net>

Maybe not the most elegant way but at least works:

library( stringr )
x <- as.factor( "123.4-" )
x <- -as.numeric( str_replace( as.character( x ), "-", "" ) )
x
[1] -123.4



On Monday 20 October 2014 09:03:36 PIKAL Petr wrote:
> Dear all.
> 
> Before I start fishing in (for me) murky regular expression waters I try to ask community about changing format of negative numbers.
> 
> For some reason I get a file with negative numbers formatted with negative sign at end of number.
> 
> something like
> 
> 0.123-
> 
> It is imported as factors and I need to convert it to numbers again. Before converting I need to change it to "correct" format
> 
> -0.123
> 
> Does anybody know some simple way?
> 
> Cheers
> Petr
.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From marc_grt at yahoo.fr  Mon Oct 20 12:53:16 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Mon, 20 Oct 2014 12:53:16 +0200
Subject: [R] format negative numbers
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>
Message-ID: <5444E99C.3050309@yahoo.fr>

Is it what you want?

 > st <- "0.123-"
 > gsub("(.+)(-)", "\\2\\1", st)
[1] "-0.123"
 > st <- "0.123"
 > gsub("(.+)(-)", "\\2\\1", st)
[1] "0.123"

Sincerely
Marc

Le 20/10/2014 09:03, PIKAL Petr a ?crit :
> Dear all.
>
> Before I start fishing in (for me) murky regular expression waters I try to ask community about changing format of negative numbers.
>
> For some reason I get a file with negative numbers formatted with negative sign at end of number.
>
> something like
>
> 0.123-
>
> It is imported as factors and I need to convert it to numbers again. Before converting I need to change it to "correct" format
>
> -0.123
>
> Does anybody know some simple way?
>
> Cheers
> Petr
>
>
> ________________________________
> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
> Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
> Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
>
> V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
> - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.
>
> This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
> If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
> If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
> The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.
>
> In case that this e-mail forms part of business dealings:
> - the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
> - if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
> - the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
> - the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rl at openmailbox.org  Mon Oct 20 12:53:21 2014
From: rl at openmailbox.org (rl at openmailbox.org)
Date: Mon, 20 Oct 2014 10:53:21 +0000
Subject: [R] create vector objects by recurrence equation function
Message-ID: <86b3f421c5c7eb55036caa48a89f6544@openmailbox.org>

Subscribers,

A spreadsheet contains (what appears to a low aptitude mathematician!) a 
recurrence equation:

	cellb1=2	cellc1=0.1	celld1=5
cella2=1/(k1*cellb1)	cellb2=cellb1+cellc1+celld1	cellc2=cella2*cellb2	celld2=cellb2*k2

where k are constants.

Could someone please direct to a relevant function name in the manual, 
to create a vector (e.g. length 10) for subsequent values that would be 
in equivalent spreadsheet cells cellc3, celld3, cellc4, celld4, etc.?


From petr.pikal at precheza.cz  Mon Oct 20 13:32:37 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 20 Oct 2014 11:32:37 +0000
Subject: [R] format negative numbers
In-Reply-To: <5444E99C.3050309@yahoo.fr>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>
	<5444E99C.3050309@yahoo.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAE17@SRVEXCHMBX.precheza.cz>

Hi

Thanks to all who responded.

My input string is rather clumsy. Actually it can have leading or trailing empty space too, it can be mixture of positive and negative numbers.

In the meantime I made small function which just strips of - sign and make numbers from factors, find numbers which have - sign and change numbers which shall be negative to negative. Not as elegant as your solution but works even when there are leading or trailing spaces.

zapor <- function(x) {
num<-as.numeric(gsub("(-)", "", x))
zap<- grep("-", x)
num[zap]<- num[zap] * (-1)
num}

> x <- as.factor( c("   123.4-   " , "   123   "))
> zapor(x)
[1] -123.4  123.0
>

I just thought that there is some reason for presenting negative numbers with minus sign behind the number in finance community and therefore somebody already invented clever way how to deal with such numbers.

Cheers
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Marc Girondot
> Sent: Monday, October 20, 2014 12:53 PM
> To: r-help at r-project.org
> Subject: Re: [R] format negative numbers
>
> Is it what you want?
>
>  > st <- "0.123-"
>  > gsub("(.+)(-)", "\\2\\1", st)
> [1] "-0.123"
>  > st <- "0.123"
>  > gsub("(.+)(-)", "\\2\\1", st)
> [1] "0.123"
>
> Sincerely
> Marc
>
> Le 20/10/2014 09:03, PIKAL Petr a ?crit :
> > Dear all.
> >
> > Before I start fishing in (for me) murky regular expression waters I
> try to ask community about changing format of negative numbers.
> >
> > For some reason I get a file with negative numbers formatted with
> negative sign at end of number.
> >
> > something like
> >
> > 0.123-
> >
> > It is imported as factors and I need to convert it to numbers again.
> Before converting I need to change it to "correct" format
> >
> > -0.123
> >
> > Does anybody know some simple way?
> >
> > Cheers
> > Petr
> >
> >
> > ________________________________
> > Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> jsou ur?eny pouze jeho adres?t?m.
> > Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
> neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
> kopie vyma?te ze sv?ho syst?mu.
> > Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
> email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
> > Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou
> modifikacemi ?i zpo?d?n?m p?enosu e-mailu.
> >
> > V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
> > - vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
> smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
> > - a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
> p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky
> ze strany p??jemce s dodatkem ?i odchylkou.
> > - trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
> v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
> > - odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
> spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
> zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
> adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
> p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
> zn?m?.
> >
> > This e-mail and any documents attached to it may be confidential and
> are intended only for its intended recipients.
> > If you received this e-mail by mistake, please immediately inform its
> sender. Delete the contents of this e-mail with all attachments and its
> copies from your system.
> > If you are not the intended recipient of this e-mail, you are not
> authorized to use, disseminate, copy or disclose this e-mail in any
> manner.
> > The sender of this e-mail shall not be liable for any possible damage
> caused by modifications of the e-mail or by delay with transfer of the
> email.
> >
> > In case that this e-mail forms part of business dealings:
> > - the sender reserves the right to end negotiations about entering
> into a contract in any time, for any reason, and without stating any
> reasoning.
> > - if the e-mail contains an offer, the recipient is entitled to
> immediately accept such offer; The sender of this e-mail (offer)
> excludes any acceptance of the offer on the part of the recipient
> containing any amendment or variation.
> > - the sender insists on that the respective contract is concluded
> only upon an express mutual agreement on all its aspects.
> > - the sender of this e-mail informs that he/she is not authorized to
> enter into any contracts on behalf of the company except for cases in
> which he/she is expressly authorized to do so in writing, and such
> authorization or power of attorney is submitted to the recipient or the
> person represented by the recipient, or the existence of such
> authorization is known to the recipient of the person represented by
> the recipient.
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From S.Ellison at LGCGroup.com  Mon Oct 20 15:01:05 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 20 Oct 2014 14:01:05 +0100
Subject: [R] how to judge a virable  is a integer?
In-Reply-To: <13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412C1FCA9@GOLD.corp.lgc-group.com>

> It's due to that, 1 is a numeric, 1.2 is a numeric, though it's true. but deeply,
> when i want to know 1 is an integer, ?there seems no easy way to get the
> answer.
> So, is there anyone happen to know it?

First, you are not being as clear as you may think when you say " when i want to know 1 is an integer". It isn't. 1L is an integer. 1 is floating point. Do you want to know whether something is _stored as_ integer (eg 2L), whether it is a floating point number with exactly no nonzero digits after the point (eg 2.0), or whether it is something which would normally be expected to be integer if represented to infinite precision but is not exactly represented because of finite machine precision (eg sqrt(2)^2)?

Once you've sorted out which of those you want - I think the last of the three - please read the posts you?re replying to. all.equal() was the suggested answer and is likely to be the nearest to a reliable answer you will get. Almost anything else will at least sometimes fail; for example

sqrt(4.0) == 2L
# [1] TRUE

#But 
sqrt(2)^2 == 2L
#[1] FALSE

#whereas 
all.equal(sqrt(2)^2, 2L)
#[1] TRUE

Thus, all.equal can be used to test for something that would normally be considered an integer within machine precision, for example using
nearly.integer <- function(x) all.equal(x, round(x))

You may make the comparison closer to a 'within machine precision' comparison  by amending the tol argument to all.equal, which is documented on the help page you were referred to.

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From S.Ellison at LGCGroup.com  Mon Oct 20 15:08:57 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 20 Oct 2014 14:08:57 +0100
Subject: [R] how to judge a virable is a integer?
In-Reply-To: <8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>
References: <690d9165.1afb1.14922d8a014.Coremail.rhelpmaillist@163.com>
	<A38E19EC-B6B9-48A2-8104-EFBD8155FC9F@xs4all.nl>
	<25838d30.14585.14922fdd93b.Coremail.rhelpmaillist@163.com>
	<0301C365-5456-429A-A8FB-5D1CE2746342@LGCGroup.com>
	<13dbd627.1c610.14923a61cbe.Coremail.rhelpmaillist@163.com>
	<CAJRuHoqqfLpgeZK8VyfuxZE1UM8F2nh2ucYiH7BZc09GFat6Rw@mail.gmail.com>
	<8f0756d.11.1492435a673.Coremail.rhelpmaillist@163.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412C1FCB4@GOLD.corp.lgc-group.com>

> 3. all.equal(a, as.integer(a))

Closer, but be aware that all.equal will not always return TRUE or FALSE and - more importantly - as.integer truncates towards zero and does NOT generally round to the nearest integer.

a <- 4 - sqrt(2)^2 #Analytically 2
all.equal(a, as.integer(a))
# [1] "Mean relative difference: 0.5"
#because
as.integer(a)
# [1] 1

To return FALSE from all.equal, wrap it in something like

if(all.equal(a, round(a))==TRUE) TRUE else FALSE


S


*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From kmezhoud at gmail.com  Mon Oct 20 15:28:30 2014
From: kmezhoud at gmail.com (Karim Mezhoud)
Date: Mon, 20 Oct 2014 14:28:30 +0100
Subject: [R] matching genes to a list of gene groups an built binary data
	frame
Message-ID: <CALJKBv_c4Wcii5ao4fh50G78XDtPpX5YLP64Np-gKW_Xa1F-uA@mail.gmail.com>

Dear All,

I have a gene list
Genes <- c("ACACA", "BAX" , "BCL2", "BID", "BAX", "MAPK9")

and a list of group of genes

ListGroup <- list(group1=c("ACACA" ,"AHSA1"     ,"AIMP2"    , "AKR1B1",
"AKT1",      "AKT1S1"), group2=c("ANXA1"  ,   "AR"   ,     "ARID1A" ,
"ATM"     ,  "BAK1" ,     "BAX"  ), group3=c("BCL2"  ,    "BCL2L1"  ,
"BCL2L11" ,  "BECN1" ,    "BID"  ,     "BIRC2"))

ListGroup
$group1
[1] "ACACA"  "AHSA1"  "AIMP2"  "AKR1B1" "AKT1"   "AKT1S1"
$group2
[1] "ANXA1"  "AR"     "ARID1A" "ATM"    "BAK1"   "BAX"
$group3
[1] "BCL2"    "BCL2L1"  "BCL2L11" "BECN1"   "BID"     "BIRC2"

I would like to built a data frame as:

                   ACACA   BAX  BCL2  BID  BAX   MAPK9
group1            1             0        0          0     0           0
group2            0             1         0          0     1           0
group3            0              0        1           1     0           0

Many thanks,
Karim

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Mon Oct 20 15:36:33 2014
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Mon, 20 Oct 2014 15:36:33 +0200
Subject: [R] strange loadings matrix after varimax rotation: PCA with prcomp
	in R
Message-ID: <CALC46t_njCmFsRSrLUbAk5RYWGEUmJgx0Gz1dE1xc0rNxWkapw@mail.gmail.com>

Hello.
I ran a PCA analysis on a dataset with 5 variables and retained two
components. I rotated them and now I want to predict the scores in a new
data set for which the original variables are available.

I normally use the predict.prcomp() function to predict using a prcomp
object. For example..

PC1=predict(data.pca, new.data)[,1]

...will predict the first component in the new dataset.

But how to do it with the rotated components/loadings, since after
varimax() we don't have a prcomp object anymore?

Thanks in advance!

David

	[[alternative HTML version deleted]]


From chirleu at gmail.com  Mon Oct 20 15:41:30 2014
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Mon, 20 Oct 2014 15:41:30 +0200
Subject: [R] how to predict scores after varimax rotation (using prcomp()
	and varimax())?
Message-ID: <CALC46t_8C+dwndXP9qC_oGTkUngCBV_zKRBN_QUuJ+LvFoB3Pw@mail.gmail.com>

Hello.
I ran a PCA analysis on a dataset with 5 variables and retained two
components. I rotated them and now I want to predict the scores in a new
data set for which the original variables are available.

I normally use the predict.prcomp() function to predict using a prcomp
object. For example..

PC1=predict(data.pca, new.data)[,1]

...will predict the first component in the new dataset.

But how to do it with the rotated components/loadings, since after
varimax() we don't have a prcomp object anymore?

Thanks in advance!

David

	[[alternative HTML version deleted]]


From enricoc57 at gmail.com  Mon Oct 20 16:46:28 2014
From: enricoc57 at gmail.com (Enrico Colosimo)
Date: Mon, 20 Oct 2014 12:46:28 -0200
Subject: [R] making a plot
Message-ID: <CAGOkrw6W97xJ1GqcdL0ZcOt7FQABDQReTu9=MQT7k6L0R6az8g@mail.gmail.com>

Dear all,

I am struggling to make a plot for my survival analysis
class.

This is my script


 labels<-c('1','2','3','4','5','6')
 ano<-c(2001,2002,2003,2004,2006,2008)
 ranges<-c(6,3,4,5,4,2)
 dotchart(ano, labels=labels, xlab='ano',
ylab='Pacientes',pch=20,xlim=c(min(ano),  max(ano+ranges)))
 segments(ano,1:6,ano+ranges,1:6,pch=25,lty=1,lend=4)

I need to put an asterix (failure) by the end of the three first lines and
a small circle (censoring)
by the end of the last three.

Someone can help me?

Thanks,
Enrico.

	[[alternative HTML version deleted]]


From armandres at gmail.com  Mon Oct 20 17:24:51 2014
From: armandres at gmail.com (=?UTF-8?B?QW5kcsOpcyBBcmFnw7Nu?=)
Date: Mon, 20 Oct 2014 10:24:51 -0500
Subject: [R] making a plot
In-Reply-To: <CAGOkrw6W97xJ1GqcdL0ZcOt7FQABDQReTu9=MQT7k6L0R6az8g@mail.gmail.com>
References: <CAGOkrw6W97xJ1GqcdL0ZcOt7FQABDQReTu9=MQT7k6L0R6az8g@mail.gmail.com>
Message-ID: <CAP=fr+TFJXnRZ1U1N7BZa8D=JUpcNjY2C6Ly8mVZ-rUryY8LTw@mail.gmail.com>

Enrico,

This may help you:

text(locator(1), "*", cex=1.5,adj=0.5

and

text(locator(1), "?", cex=1.5,adj=0.5


Draw your plot, then write the code, locate the cursor on your plot, put
the symbols where you want itl and click.

Regards,


Andr?s

PS ?locator





2014-10-20 9:46 GMT-05:00 Enrico Colosimo <enricoc57 at gmail.com>:

> Dear all,
>
> I am struggling to make a plot for my survival analysis
> class.
>
> This is my script
>
>
>  labels<-c('1','2','3','4','5','6')
>  ano<-c(2001,2002,2003,2004,2006,2008)
>  ranges<-c(6,3,4,5,4,2)
>  dotchart(ano, labels=labels, xlab='ano',
> ylab='Pacientes',pch=20,xlim=c(min(ano),  max(ano+ranges)))
>  segments(ano,1:6,ano+ranges,1:6,pch=25,lty=1,lend=4)
>
> I need to put an asterix (failure) by the end of the three first lines and
> a small circle (censoring)
> by the end of the last three.
>
> Someone can help me?
>
> Thanks,
> Enrico.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Mon Oct 20 17:30:21 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 20 Oct 2014 11:30:21 -0400
Subject: [R] How to clear R memory in a for loop
Message-ID: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>

Dear Rers,

I am trying to run a for-loop in R.
During each iteration I read in an mp3 file and do some basic processing.
If I do what I need to do for each file one by one - it works fine.
But once I start running a loop, it soon runs out of memory and says: can't
allocate a vector of size...
In each iteration of my loop I always overwrite the previously created
object and do gc().

Any hints on how to fight this?

Thanks a lot!

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Oct 20 17:40:03 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 20 Oct 2014 08:40:03 -0700
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
Message-ID: <214D6540-4BBC-4012-9359-B39AC7846F58@dcn.davis.CA.us>

You don't say what processing you are doing.. the answer to your question is very likely there. To communicate effectively on this mailing list, self-contained examples are needed. And in order to not corrupt the example you will need to post in plain text.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 20, 2014 8:30:21 AM PDT, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>Dear Rers,
>
>I am trying to run a for-loop in R.
>During each iteration I read in an mp3 file and do some basic
>processing.
>If I do what I need to do for each file one by one - it works fine.
>But once I start running a loop, it soon runs out of memory and says:
>can't
>allocate a vector of size...
>In each iteration of my loop I always overwrite the previously created
>object and do gc().
>
>Any hints on how to fight this?
>
>Thanks a lot!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dimitri.liakhovitski at gmail.com  Mon Oct 20 18:05:45 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 20 Oct 2014 12:05:45 -0400
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <214D6540-4BBC-4012-9359-B39AC7846F58@dcn.davis.CA.us>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<214D6540-4BBC-4012-9359-B39AC7846F58@dcn.davis.CA.us>
Message-ID: <CAN2xGJYm1J1DFUqA=_6HEV35nPz6WmLMPpxMA02Zk6kNvKpDyA@mail.gmail.com>

Jeff,

here is what I do with each file using library(tuneR):

b<-readMP3("cairnomount.mp3")
myrange<-range(b at left)
write.table(myrange,"x myrange.txt",sep="\t")

Would you like me to attach a bunch of large mp3 files?
I don't feel I have the right to clog people's inboxes with large files.

Thanks!



On Mon, Oct 20, 2014 at 11:40 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> You don't say what processing you are doing.. the answer to your question
> is very likely there. To communicate effectively on this mailing list,
> self-contained examples are needed. And in order to not corrupt the example
> you will need to post in plain text.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 20, 2014 8:30:21 AM PDT, Dimitri Liakhovitski <
> dimitri.liakhovitski at gmail.com> wrote:
> >Dear Rers,
> >
> >I am trying to run a for-loop in R.
> >During each iteration I read in an mp3 file and do some basic
> >processing.
> >If I do what I need to do for each file one by one - it works fine.
> >But once I start running a loop, it soon runs out of memory and says:
> >can't
> >allocate a vector of size...
> >In each iteration of my loop I always overwrite the previously created
> >object and do gc().
> >
> >Any hints on how to fight this?
> >
> >Thanks a lot!
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Dimitri Liakhovitski

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Oct 20 18:25:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 20 Oct 2014 09:25:16 -0700
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <CAN2xGJYm1J1DFUqA=_6HEV35nPz6WmLMPpxMA02Zk6kNvKpDyA@mail.gmail.com>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<214D6540-4BBC-4012-9359-B39AC7846F58@dcn.davis.CA.us>
	<CAN2xGJYm1J1DFUqA=_6HEV35nPz6WmLMPpxMA02Zk6kNvKpDyA@mail.gmail.com>
Message-ID: <9B64D82F-C20C-45D1-8FC3-86F3803CF790@dcn.davis.CA.us>

It is your responsibility (not mine) to simplify your example to the point where it is small, self-contained, and reproducible (see the footer of this message). In fact, doing so often highlights the issue to you before you share it. If any old downloadable mp3 file can be used to reproduce the problem then you would not need to share yours. (Note that this list strips off most attachments, so links are better anyway.)

I suspect that one file read repeatedly might create the problem... if it doesn't, then that would be helpful to know. In any event, your "example" is missing the key element of repetition, so it is not hardly reproducible. The extra things you are doing to make it loop are likely to be important here.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 20, 2014 9:05:45 AM PDT, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>Jeff,
>
>here is what I do with each file using library(tuneR):
>
>b<-readMP3("cairnomount.mp3")
>myrange<-range(b at left)
>write.table(myrange,"x myrange.txt",sep="\t")
>
>Would you like me to attach a bunch of large mp3 files?
>I don't feel I have the right to clog people's inboxes with large
>files.
>
>Thanks!
>
>
>
>On Mon, Oct 20, 2014 at 11:40 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> You don't say what processing you are doing.. the answer to your
>question
>> is very likely there. To communicate effectively on this mailing
>list,
>> self-contained examples are needed. And in order to not corrupt the
>example
>> you will need to post in plain text.
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 20, 2014 8:30:21 AM PDT, Dimitri Liakhovitski <
>> dimitri.liakhovitski at gmail.com> wrote:
>> >Dear Rers,
>> >
>> >I am trying to run a for-loop in R.
>> >During each iteration I read in an mp3 file and do some basic
>> >processing.
>> >If I do what I need to do for each file one by one - it works fine.
>> >But once I start running a loop, it soon runs out of memory and
>says:
>> >can't
>> >allocate a vector of size...
>> >In each iteration of my loop I always overwrite the previously
>created
>> >object and do gc().
>> >
>> >Any hints on how to fight this?
>> >
>> >Thanks a lot!
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>


From john.archie.mckown at gmail.com  Mon Oct 20 18:53:35 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Mon, 20 Oct 2014 11:53:35 -0500
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
Message-ID: <CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>

On Mon, Oct 20, 2014 at 10:30 AM, Dimitri Liakhovitski <
dimitri.liakhovitski at gmail.com> wrote:

> Dear Rers,
>
> I am trying to run a for-loop in R.
> During each iteration I read in an mp3 file and do some basic processing.
> If I do what I need to do for each file one by one - it works fine.
> But once I start running a loop, it soon runs out of memory and says: can't
> allocate a vector of size...
> In each iteration of my loop I always overwrite the previously created
> object and do gc().
>
> Any hints on how to fight this?
>
> Thanks a lot!
>
>
>
?Please don't use HTML for messages.

What occurs to me, from reading the other replies, is that perhaps within
the loop you are causing other objects to be allocated. And that can be
done just by doing a simple assignment, so it may not be obvious. What this
can do is cause what we called a "sand bar" in the old days. That's where
you allocate a big chunk of memory for an object. Say this take up 1/2 of
your available space. You now create a small object. This object is
_probably_ right next to the large object. You now release the large
object. Your apparent free space is now almost what it was at the
beginning. But when you try to allocate another large object which is, say,
2/3 of the maximum space, you can't because that small object is sitting
right in the middle of our memory space. So you _can_ allocate 2 large
objects which are 1/3 your free space size, but not 1 object which is 2/3
of the free space size. Which can lead to your type of situation.

This is just a SWAG based on some experience in other systems. Most
"garbage collection" do _not_ do memory consolidation. I don't know about
R.?


-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Mon Oct 20 18:53:27 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 20 Oct 2014 09:53:27 -0700
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <9B64D82F-C20C-45D1-8FC3-86F3803CF790@dcn.davis.CA.us>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<214D6540-4BBC-4012-9359-B39AC7846F58@dcn.davis.CA.us>
	<CAN2xGJYm1J1DFUqA=_6HEV35nPz6WmLMPpxMA02Zk6kNvKpDyA@mail.gmail.com>
	<9B64D82F-C20C-45D1-8FC3-86F3803CF790@dcn.davis.CA.us>
Message-ID: <CAF8bMcbmwe8Lq-6_tkXr=QwQzraPbNA=7CqacXp5gBHeN7FP3Q@mail.gmail.com>

tuneR::readMP3 may not be allocating (or freeing) memory correctly.  On both
Linux and Windows I get the following (where 'jingle.mp3' is a sample mp3 that
comes with Processing 2.1 which has a quarter million samples in it).  If I do
this as a sequence of top-level expression instead of as a for loop R does not
crash.  Perhaps you should talk with tuneR's maintainer, who could run valgrind
over it.

> library(tuneR)
tuneR >= 1.0 has changed its Wave class definition.
Use updateWave(object) to convert Wave objects saved with previous
versions of tuneR.
> b <- readMP3("jingle.mp3")
> for(i in 1:100){cat(i,"");b <- readMP3("jingle.mp3")}
1 2
 *** caught segfault ***
address 0x3a81000, cause 'memory not mapped'

Traceback:
 1: .Call("do_read_mp3", data, package = "tuneR")
 2: readMP3("jingle.mp3")

Possible actions:
1: abort (with core dump, if enabled)
2: normal R exit
3: exit R without saving workspace
4: exit R saving workspace
Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Mon, Oct 20, 2014 at 9:25 AM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> It is your responsibility (not mine) to simplify your example to the point where it is small, self-contained, and reproducible (see the footer of this message). In fact, doing so often highlights the issue to you before you share it. If any old downloadable mp3 file can be used to reproduce the problem then you would not need to share yours. (Note that this list strips off most attachments, so links are better anyway.)
>
> I suspect that one file read repeatedly might create the problem... if it doesn't, then that would be helpful to know. In any event, your "example" is missing the key element of repetition, so it is not hardly reproducible. The extra things you are doing to make it loop are likely to be important here.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 20, 2014 9:05:45 AM PDT, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>Jeff,
>>
>>here is what I do with each file using library(tuneR):
>>
>>b<-readMP3("cairnomount.mp3")
>>myrange<-range(b at left)
>>write.table(myrange,"x myrange.txt",sep="\t")
>>
>>Would you like me to attach a bunch of large mp3 files?
>>I don't feel I have the right to clog people's inboxes with large
>>files.
>>
>>Thanks!
>>
>>
>>
>>On Mon, Oct 20, 2014 at 11:40 AM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us>
>>wrote:
>>
>>> You don't say what processing you are doing.. the answer to your
>>question
>>> is very likely there. To communicate effectively on this mailing
>>list,
>>> self-contained examples are needed. And in order to not corrupt the
>>example
>>> you will need to post in plain text.
>>>
>>---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>>Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>> Go...
>>>                                       Live:   OO#.. Dead: OO#..
>>Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>rocks...1k
>>>
>>---------------------------------------------------------------------------
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On October 20, 2014 8:30:21 AM PDT, Dimitri Liakhovitski <
>>> dimitri.liakhovitski at gmail.com> wrote:
>>> >Dear Rers,
>>> >
>>> >I am trying to run a for-loop in R.
>>> >During each iteration I read in an mp3 file and do some basic
>>> >processing.
>>> >If I do what I need to do for each file one by one - it works fine.
>>> >But once I start running a loop, it soon runs out of memory and
>>says:
>>> >can't
>>> >allocate a vector of size...
>>> >In each iteration of my loop I always overwrite the previously
>>created
>>> >object and do gc().
>>> >
>>> >Any hints on how to fight this?
>>> >
>>> >Thanks a lot!
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> >______________________________________________
>>> >R-help at r-project.org mailing list
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Oct 20 19:04:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Oct 2014 10:04:13 -0700
Subject: [R] pasteFromExcel
In-Reply-To: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
References: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
Message-ID: <6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>


On Oct 19, 2014, at 11:18 PM, Dan Murphy wrote:

> To Users of Excel:
> 
> Following advice from Brian and Markus, I created an RMarkdown "vignette"
> that shows an example of how the pasteFromExcel function in the excelRio
> package on github could be used by an actuary to transfer a triangle from
> Excel to R. See today's post at http://trinostics.blogspot.com/
> 
> Unfortunately, if you are located outside the US, the demonstrated
> functionality will not work for you because the currency regex implemented
> assumes the dollar sign ($) and comma/decimal punctuation of the form
> 999,999.00.
> 
> If anyone is interested in contributing currency regex expressions that
> work in your locale, I would be happy to try to incorporate them in the
> package. If anyone knows how best to determine the user's locale (might
> "timezone" suffice?), I'd appreciate that help too.
> 

?Sys.getlocale   # perhaps "LC_MONETARY"

?options   # look for OutDec


> 	[[alternative HTML version deleted]]



David Winsemius
Alameda, CA, USA


From macqueen1 at llnl.gov  Mon Oct 20 19:22:00 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 20 Oct 2014 17:22:00 +0000
Subject: [R] format negative numbers
Message-ID: <D06A924F.10FBE1%macqueen1@llnl.gov>

You could do it with minimal use of regular expressions, along the lines
of this example:

x <- c('123','2.31','2.313-', '45-')
is.neg <- grepl('-',x)
xn <- x
xn[is.neg] <- paste0( '-', substring(x[is.neg],1, nchar(x[is.neg])-1))
xn <- as.numeric(xn)
                   
I made a copy, 'xn', so that original and final can easily be compared,
but it's not necessary to do so.


-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/20/14, 12:03 AM, "PIKAL Petr" <petr.pikal at precheza.cz> wrote:

>Dear all.
>
>Before I start fishing in (for me) murky regular expression waters I try
>to ask community about changing format of negative numbers.
>
>For some reason I get a file with negative numbers formatted with
>negative sign at end of number.
>
>something like
>
>0.123-
>
>It is imported as factors and I need to convert it to numbers again.
>Before converting I need to change it to "correct" format
>
>-0.123
>
>Does anybody know some simple way?
>
>Cheers
>Petr
>
>
>________________________________
>Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou
>ur?eny pouze jeho adres?t?m.
>Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav?
>neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho
>kopie vyma?te ze sv?ho syst?mu.
>Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento
>email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
>Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi
>?i zpo?d?n?m p?enosu e-mailu.
>
>V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
>- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en?
>smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
>- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn?
>p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze
>strany p??jemce s dodatkem ?i odchylkou.
>- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve
>v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
>- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za
>spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn?
>zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly
>adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje,
>p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen?
>zn?m?.
>
>This e-mail and any documents attached to it may be confidential and are
>intended only for its intended recipients.
>If you received this e-mail by mistake, please immediately inform its
>sender. Delete the contents of this e-mail with all attachments and its
>copies from your system.
>If you are not the intended recipient of this e-mail, you are not
>authorized to use, disseminate, copy or disclose this e-mail in any
>manner.
>The sender of this e-mail shall not be liable for any possible damage
>caused by modifications of the e-mail or by delay with transfer of the
>email.
>
>In case that this e-mail forms part of business dealings:
>- the sender reserves the right to end negotiations about entering into a
>contract in any time, for any reason, and without stating any reasoning.
>- if the e-mail contains an offer, the recipient is entitled to
>immediately accept such offer; The sender of this e-mail (offer) excludes
>any acceptance of the offer on the part of the recipient containing any
>amendment or variation.
>- the sender insists on that the respective contract is concluded only
>upon an express mutual agreement on all its aspects.
>- the sender of this e-mail informs that he/she is not authorized to
>enter into any contracts on behalf of the company except for cases in
>which he/she is expressly authorized to do so in writing, and such
>authorization or power of attorney is submitted to the recipient or the
>person represented by the recipient, or the existence of such
>authorization is known to the recipient of the person represented by the
>recipient.
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chiefmurphy at gmail.com  Mon Oct 20 19:29:21 2014
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Mon, 20 Oct 2014 10:29:21 -0700
Subject: [R] pasteFromExcel
In-Reply-To: <6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>
References: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
	<6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>
Message-ID: <CAHgH9_EGpxS2CGZmNRWrYyqrq-fTAZGhRADAD1+66razu0FuyA@mail.gmail.com>

Nice.
So if someone were to offer a currency regular expression that works
in their locale, I should also ask them to give me the results of
Sys.getlocale("LC_MONETARY")
and
options("OutDec")
and confirm that MS Excel honors that OutDec.
Thank you, David.
-Dan

On Mon, Oct 20, 2014 at 10:04 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Oct 19, 2014, at 11:18 PM, Dan Murphy wrote:
>
>> To Users of Excel:
>>
>> Following advice from Brian and Markus, I created an RMarkdown "vignette"
>> that shows an example of how the pasteFromExcel function in the excelRio
>> package on github could be used by an actuary to transfer a triangle from
>> Excel to R. See today's post at http://trinostics.blogspot.com/
>>
>> Unfortunately, if you are located outside the US, the demonstrated
>> functionality will not work for you because the currency regex implemented
>> assumes the dollar sign ($) and comma/decimal punctuation of the form
>> 999,999.00.
>>
>> If anyone is interested in contributing currency regex expressions that
>> work in your locale, I would be happy to try to incorporate them in the
>> package. If anyone knows how best to determine the user's locale (might
>> "timezone" suffice?), I'd appreciate that help too.
>>
>
> ?Sys.getlocale   # perhaps "LC_MONETARY"
>
> ?options   # look for OutDec
>
>
>>       [[alternative HTML version deleted]]
>
>
>
> David Winsemius
> Alameda, CA, USA
>


From istazahn at gmail.com  Mon Oct 20 19:31:44 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 20 Oct 2014 13:31:44 -0400
Subject: [R] understanding the no-label concept
In-Reply-To: <20141016192001.20F77231AB7@mx02.posteo.de>
References: <20141011171810.5553825B17EF@mx02.posteo.de>
	<CAGx1TMDus=6eHda91FZjKGSCqbnC780zAzMB-2cdNFsNO4SqKA@mail.gmail.com>
	<20141016192001.20F77231AB7@mx02.posteo.de>
Message-ID: <CA+vqiLFLbfbHd2h4sF8vbuRVM2ZnYuPXeSBbKPqsiGbZ7QbNjg@mail.gmail.com>

On Thu, Oct 16, 2014 at 3:19 PM,  <moonkid at posteo.org> wrote:
>> aa <- 1:5
>> names(aa) <- c("Eins", "Zwei", "Drei", "Vier", "F?nf")
>> aa
> Eins Zwei Drei Vier F?nf
>    1    2    3    4    5
>> table(aa)
> 1 2 3 4 5
> 1 1 1 1 1
>
> You see? It didn't work.

perhaps you want

table(names(aa))

Or maybe just

aa <- - c("Eins", "Zwei", "Drei", "Vier", "F?nf")
table(aa)

>
>> aa <- c(aa, 1, 2)
>> aa
> Eins Zwei Drei Vier F?nf
>    1    2    3    4    5    1    2

This does get more complicated if you want to add things by number.
But why not just


aa <- - c("Eins", "Zwei", "Drei", "Vier", "F?nf")
aa <- c(aa, "Eins", "Zwei")
table(aa)

?

>
> This is no solution for my case.
>
> But...
>
>> bb <- matrix(1:12, 3, 4, dimnames=list(letters[1:3], LETTERS[1:4]))

Not really sure what this is meant to demonstrate.

More generally there is no one-to-one mapping between the stata
concept of variable and value labels to concepts in R. First, there is
no equivalent of Stata variable labels. There is ?comment but it
doesn't survive subsetting. The role that value labels play in Stata
are covered variously in R by 1) just using character strings to store
the information that you would typically put in a stata value label,
b) naming your variable, or c) using factors. Personally I usually
find option 1) more convenient.

Best,
Ista

>
> Nice. But look dam complex for a simple task. I see I have to change a
> lot of the concepts in my mind and my workflows.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Oct 20 19:32:33 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Oct 2014 10:32:33 -0700
Subject: [R] matching genes to a list of gene groups an built binary
	data frame
In-Reply-To: <CALJKBv_c4Wcii5ao4fh50G78XDtPpX5YLP64Np-gKW_Xa1F-uA@mail.gmail.com>
References: <CALJKBv_c4Wcii5ao4fh50G78XDtPpX5YLP64Np-gKW_Xa1F-uA@mail.gmail.com>
Message-ID: <46029CE0-9A53-4B9D-99C1-0BD5B99E3198@comcast.net>


On Oct 20, 2014, at 6:28 AM, Karim Mezhoud wrote:

> Genes <- c("ACACA", "BAX" , "BCL2", "BID", "BAX", "MAPK9")
> 
> and a list of group of genes
> 
> ListGroup <- list(group1=c("ACACA" ,"AHSA1"     ,"AIMP2"    , "AKR1B1",
> "AKT1",      "AKT1S1"), group2=c("ANXA1"  ,   "AR"   ,     "ARID1A" ,
> "ATM"     ,  "BAK1" ,     "BAX"  ), group3=c("BCL2"  ,    "BCL2L1"  ,
> "BCL2L11" ,  "BECN1" ,    "BID"  ,     "BIRC2"))

Desired:

> I would like to built a data frame as:
> 
>                   ACACA   BAX  BCL2  BID  BAX   MAPK9
> group1            1             0        0          0     0           0
> group2            0             1         0          0     1           0
> group3            0              0        1           1     0           0
> 


> sapply(Genes, function(x) as.numeric(sapply(ListGroup, '%in%', x=x) ) )
     ACACA BAX BCL2 BID BAX MAPK9
[1,]     1   0    0   0   0     0
[2,]     0   1    0   0   1     0
[3,]     0   0    1   1   0     0

?'%in%'

The x=x asserts that the x value will be used as the first argument to %in% so ListGroup items will be used as the table arguments. It's a matrix, so as.data.frame would be needed to deliver a dfrm.

-- 
David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Oct 20 19:37:35 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Oct 2014 10:37:35 -0700
Subject: [R] making a plot
In-Reply-To: <CAP=fr+TFJXnRZ1U1N7BZa8D=JUpcNjY2C6Ly8mVZ-rUryY8LTw@mail.gmail.com>
References: <CAGOkrw6W97xJ1GqcdL0ZcOt7FQABDQReTu9=MQT7k6L0R6az8g@mail.gmail.com>
	<CAP=fr+TFJXnRZ1U1N7BZa8D=JUpcNjY2C6Ly8mVZ-rUryY8LTw@mail.gmail.com>
Message-ID: <3B0C5142-05D0-476C-A398-ED89924AA5D5@comcast.net>


On Oct 20, 2014, at 8:24 AM, Andr?s Arag?n wrote:

> Enrico,
> 
> This may help you:
> 
> text(locator(1), "*", cex=1.5,adj=0.5
> 
> and
> 
> text(locator(1), "?", cex=1.5,adj=0.5

Why not just use the values of x2 and  y2 that were given to segments:

> text( (ano+ranges)[1:3], 1:3, "*", cex=1.5,adj=0.5)
> text( (ano+ranges)[4:6], 4:6 , "?", cex=1.5,adj=0.5)

> 
> 
> Draw your plot, then write the code, locate the cursor on your plot, put
> the symbols where you want itl and click.
> 
> Regards,
> 
> 
> Andr?s
> 
> PS ?locator
> 
> 
> 2014-10-20 9:46 GMT-05:00 Enrico Colosimo <enricoc57 at gmail.com>:
> 
>> Dear all,
>> 
>> I am struggling to make a plot for my survival analysis
>> class.
>> 
>> This is my script
>> 
>> 
>> labels<-c('1','2','3','4','5','6')
>> ano<-c(2001,2002,2003,2004,2006,2008)
>> ranges<-c(6,3,4,5,4,2)
>> dotchart(ano, labels=labels, xlab='ano',
>> ylab='Pacientes',pch=20,xlim=c(min(ano),  max(ano+ranges)))
>> segments(ano,1:6,ano+ranges,1:6,pch=25,lty=1,lend=4)
>> 
>> I need to put an asterix (failure) by the end of the three first lines and
>> a small circle (censoring)
>> by the end of the last three.
>> 
>> Someone can help me?
>> 
>> Thanks,
>> Enrico.
>> 
>>        [[alternative HTML version deleted]]
> 
-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Oct 20 19:56:02 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Oct 2014 10:56:02 -0700
Subject: [R] pasteFromExcel
In-Reply-To: <CAHgH9_EGpxS2CGZmNRWrYyqrq-fTAZGhRADAD1+66razu0FuyA@mail.gmail.com>
References: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
	<6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>
	<CAHgH9_EGpxS2CGZmNRWrYyqrq-fTAZGhRADAD1+66razu0FuyA@mail.gmail.com>
Message-ID: <0547CC1D-B0DF-459F-B92C-1F2374EB43BE@comcast.net>


On Oct 20, 2014, at 10:29 AM, Dan Murphy wrote:

> Nice.
> So if someone were to offer a currency regular expression that works
> in their locale, I should also ask them to give me the results of
> Sys.getlocale("LC_MONETARY")
> and
> options("OutDec")
> and confirm that MS Excel honors that OutDec.

I'm not sure we can know what you mean by "confirm that MS Excel honors that OutDec." The result of options("OutDec") was intended for you to determine what character not to remove from a monetary value in an R workspace. If the assumption is that all values will be in the same unit and that the user is not doing any currency conversions then:

>  decsep <- options("OutDec")
> rmchar <- paste0( "[$??", c(".", ",")[!c(".", ",") %in% decsep], "]" )
> gsub(rmchar, "", c("$1,000", "1,200", "800"))
[1] "1000" "1200" "800" 


> Thank you, David.
> -Dan
> 
> On Mon, Oct 20, 2014 at 10:04 AM, David Winsemius
> <dwinsemius at comcast.net> wrote:
>> 
>> On Oct 19, 2014, at 11:18 PM, Dan Murphy wrote:
>> 
>>> To Users of Excel:
>>> 
>>> Following advice from Brian and Markus, I created an RMarkdown "vignette"
>>> that shows an example of how the pasteFromExcel function in the excelRio
>>> package on github could be used by an actuary to transfer a triangle from
>>> Excel to R. See today's post at http://trinostics.blogspot.com/
>>> 
>>> Unfortunately, if you are located outside the US, the demonstrated
>>> functionality will not work for you because the currency regex implemented
>>> assumes the dollar sign ($) and comma/decimal punctuation of the form
>>> 999,999.00.
>>> 
>>> If anyone is interested in contributing currency regex expressions that
>>> work in your locale, I would be happy to try to incorporate them in the
>>> package. If anyone knows how best to determine the user's locale (might
>>> "timezone" suffice?), I'd appreciate that help too.
>>> 
>> 
>> ?Sys.getlocale   # perhaps "LC_MONETARY"
>> 
>> ?options   # look for OutDec
>> 
>> 
>>>      [[alternative HTML version deleted]]
>> 
>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From dwkikuchi at gmail.com  Mon Oct 20 19:48:05 2014
From: dwkikuchi at gmail.com (David Kikuchi)
Date: Mon, 20 Oct 2014 13:48:05 -0400
Subject: [R] glmer with multiple random slopes
Message-ID: <54454AD5.70500@gmail.com>

Hi all,

I'm modeling the probability that a subject attacks or rejects a prey 
item based on its proportion of yellow coloration and size. There are 
two populations of prey, one defended and the other undefended, so 
subjects should reject one type and accept others. Each subject has a 
unique rejection threshold that is a line on a contour plot with 
coloration and size on the x and y axes. I want to estimate the error 
around that line's slope, and believe that I need to estimate two random 
slopes per subject to do so, one in the color dimension and the other in 
the size dimension. The code that I think I should use to do this is: 
glmer(attack ~ prop.color + size + (prop.color + size|subject, family = 
binomial), but I cannot find a reference or example for fitting random 
slopes in different continuous dimensions. I would appreciate any 
pointers in the right direction.

Thanks,
David

In case I've given a poor description of the problem, below is code to 
visualize the rejection threshold, using an optimal decision threshold 
rather than one estimated from the data:

library(mnormt)
library(lattice)

modelms<- 31.2
mimicms<- 24
sds<- 4*4
modelmc<- 0.7
mimicmc<- 0.4
sdc<- 0.15*0.15
xv<-seq(0,1,0.01)
yv<-seq(10,50,0.1)

ys <- matrix(NA,length(xv),length(coeffs[1,]))
for(i in 1:length(xv)) ys[i,] <- 
(coeffs[1,]+coeffs[2,]*xv[i])/(coeffs[3,]*-1)

mu <- c(modelmc,modelms) #model
sigma <- matrix(c(sdc,0,0,sds),2,2)
z1<-NULL
for(x in xv){
   f <- dmnorm(cbind(x,yv), mu, sigma)
   z1<-rbind(z1,f)
}
contour(xv,yv,z1, nlevels = 5,col = "blue", lty = "solid", lwd = 1.8, 
xlab = "proportion yellow", ylab = "size")

mu <- c(mimicmc,mimicms) #mimic
sigma <- matrix(c(sdc,0,0,sds),2,2)
z2<-NULL
for(x in xv){
   f <- dmnorm(cbind(x,yv), mu, sigma)
   z2<-rbind(z2,f)
}
contour(xv,yv,z2, nlevels = 5,add = TRUE,col = "red", lty = "solid", lwd 
= 1.8)
contour(xv,yv,z2-z1, nlevels = 1,add = TRUE, col = "black", lty = 
"solid", lwd = 2.5)


From dimitri.liakhovitski at gmail.com  Mon Oct 20 21:12:29 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Mon, 20 Oct 2014 15:12:29 -0400
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <CAF8bMcbmwe8Lq-6_tkXr=QwQzraPbNA=7CqacXp5gBHeN7FP3Q@mail.gmail.com>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<214D6540-4BBC-4012-9359-B39AC7846F58@dcn.davis.CA.us>
	<CAN2xGJYm1J1DFUqA=_6HEV35nPz6WmLMPpxMA02Zk6kNvKpDyA@mail.gmail.com>
	<9B64D82F-C20C-45D1-8FC3-86F3803CF790@dcn.davis.CA.us>
	<CAF8bMcbmwe8Lq-6_tkXr=QwQzraPbNA=7CqacXp5gBHeN7FP3Q@mail.gmail.com>
Message-ID: <CAN2xGJZ9fZ6gSWYJaTRBAwi7Ao0xmx53wnLi7wcuBQhedj27_Q@mail.gmail.com>

Thank you, everybody.
Bill - do I interpret your response correctly if I say: we should
check if tuneR is handling .wav files better than mp3 files.

On Mon, Oct 20, 2014 at 12:53 PM, William Dunlap <wdunlap at tibco.com> wrote:
> tuneR::readMP3 may not be allocating (or freeing) memory correctly.  On both
> Linux and Windows I get the following (where 'jingle.mp3' is a sample mp3 that
> comes with Processing 2.1 which has a quarter million samples in it).  If I do
> this as a sequence of top-level expression instead of as a for loop R does not
> crash.  Perhaps you should talk with tuneR's maintainer, who could run valgrind
> over it.
>
>> library(tuneR)
> tuneR >= 1.0 has changed its Wave class definition.
> Use updateWave(object) to convert Wave objects saved with previous
> versions of tuneR.
>> b <- readMP3("jingle.mp3")
>> for(i in 1:100){cat(i,"");b <- readMP3("jingle.mp3")}
> 1 2
>  *** caught segfault ***
> address 0x3a81000, cause 'memory not mapped'
>
> Traceback:
>  1: .Call("do_read_mp3", data, package = "tuneR")
>  2: readMP3("jingle.mp3")
>
> Possible actions:
> 1: abort (with core dump, if enabled)
> 2: normal R exit
> 3: exit R without saving workspace
> 4: exit R saving workspace
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Mon, Oct 20, 2014 at 9:25 AM, Jeff Newmiller
> <jdnewmil at dcn.davis.ca.us> wrote:
>> It is your responsibility (not mine) to simplify your example to the point where it is small, self-contained, and reproducible (see the footer of this message). In fact, doing so often highlights the issue to you before you share it. If any old downloadable mp3 file can be used to reproduce the problem then you would not need to share yours. (Note that this list strips off most attachments, so links are better anyway.)
>>
>> I suspect that one file read repeatedly might create the problem... if it doesn't, then that would be helpful to know. In any event, your "example" is missing the key element of repetition, so it is not hardly reproducible. The extra things you are doing to make it loop are likely to be important here.
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 20, 2014 9:05:45 AM PDT, Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com> wrote:
>>>Jeff,
>>>
>>>here is what I do with each file using library(tuneR):
>>>
>>>b<-readMP3("cairnomount.mp3")
>>>myrange<-range(b at left)
>>>write.table(myrange,"x myrange.txt",sep="\t")
>>>
>>>Would you like me to attach a bunch of large mp3 files?
>>>I don't feel I have the right to clog people's inboxes with large
>>>files.
>>>
>>>Thanks!
>>>
>>>
>>>
>>>On Mon, Oct 20, 2014 at 11:40 AM, Jeff Newmiller
>>><jdnewmil at dcn.davis.ca.us>
>>>wrote:
>>>
>>>> You don't say what processing you are doing.. the answer to your
>>>question
>>>> is very likely there. To communicate effectively on this mailing
>>>list,
>>>> self-contained examples are needed. And in order to not corrupt the
>>>example
>>>> you will need to post in plain text.
>>>>
>>>---------------------------------------------------------------------------
>>>> Jeff Newmiller                        The     .....       .....  Go
>>>Live...
>>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>>>> Go...
>>>>                                       Live:   OO#.. Dead: OO#..
>>>Playing
>>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>>>rocks...1k
>>>>
>>>---------------------------------------------------------------------------
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On October 20, 2014 8:30:21 AM PDT, Dimitri Liakhovitski <
>>>> dimitri.liakhovitski at gmail.com> wrote:
>>>> >Dear Rers,
>>>> >
>>>> >I am trying to run a for-loop in R.
>>>> >During each iteration I read in an mp3 file and do some basic
>>>> >processing.
>>>> >If I do what I need to do for each file one by one - it works fine.
>>>> >But once I start running a loop, it soon runs out of memory and
>>>says:
>>>> >can't
>>>> >allocate a vector of size...
>>>> >In each iteration of my loop I always overwrite the previously
>>>created
>>>> >object and do gc().
>>>> >
>>>> >Any hints on how to fight this?
>>>> >
>>>> >Thanks a lot!
>>>> >
>>>> >       [[alternative HTML version deleted]]
>>>> >
>>>> >______________________________________________
>>>> >R-help at r-project.org mailing list
>>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>>> >PLEASE do read the posting guide
>>>> >http://www.R-project.org/posting-guide.html
>>>> >and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From r.turner at auckland.ac.nz  Mon Oct 20 21:40:39 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Tue, 21 Oct 2014 08:40:39 +1300
Subject: [R] distance from fitted line
In-Reply-To: <BLU170-W554B3865E3A2223DCB4D9389970@phx.gbl>
References: <BLU170-W71402E65C3E132743B2F3189960@phx.gbl>,
	<OF35C7FB0E.2D231DDC-ONC1257D77.0030D34A-C1257D77.003279B0@pcsierteelt.be>
	<BLU170-W554B3865E3A2223DCB4D9389970@phx.gbl>
Message-ID: <54456537.3030303@auckland.ac.nz>


On 20/10/14 23:00, eliza botto wrote:

> Thankyou very much Joachim. Actually I already know the residual()
> command. I only wanted to know that is there a way to account for the
> fitted lines? its more of a criosity rather than a problem. :)
> Thankyou very much once again.

What (on earth!) do you mean by "account for the fitted lines"?  The 
residuals *are* the (signed, vertical) distances of the observed values 
from the fitted line.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From 538280 at gmail.com  Mon Oct 20 21:53:55 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 20 Oct 2014 13:53:55 -0600
Subject: [R] how to overwrite a Unary operator ?
In-Reply-To: <2a7dabb8.7d45.1492969ff69.Coremail.rhelpmaillist@163.com>
References: <5c556266.d43.1491c5e5847.Coremail.rhelpmaillist@163.com>
	<5440A49B.4080001@auckland.ac.nz>
	<6d4464b4.eab.1491c9bdf5f.Coremail.rhelpmaillist@163.com>
	<881433D6-D5D7-43DA-BF92-8C1716A19BF9@comcast.net>
	<2d09a624.a365.1491d24c694.Coremail.rhelpmaillist@163.com>
	<CAFEqCdwZ5gk+FJm6DqUHOcjEt73qV7aAA0hJS4f=R=A_RcaK2A@mail.gmail.com>
	<2a7dabb8.7d45.1492969ff69.Coremail.rhelpmaillist@163.com>
Message-ID: <CAFEqCdx8iMkMhrLBsStgO-HFZwjNpU9SqjvQeWb8ANpFm_FnLA@mail.gmail.com>

There is currently no way to write your own unary operator in R.  The
only current unary operators are prefix (-, +, !).  It would take some
major changes to the parser to recognize the syntax that you want
(which could also break other things that already work well), and with
the oo and other methods it is not really needed.  You can technically
pass and empty expression to a binary operator:

> `%++%` <- function(a,b) a + 1
> x <- 5
> x %++% {}
[1] 6

but that does not change the value of the variable (and using `assign`
just creates its own problems).  And syntax like above is more
appropriate for a obfuscated R contest than for anything that you want
to be understood.


There are assignment functions and you could create an object type and
an assignment for such that you might be able to have syntax like:

a <- {}

to increment a, but you would need to declare a class for a before
using it and it would probably be even more complicated than needed.

If you really want C like syntax then you could always make an active binding:

> f <- local({
+   e <- environment()
+   x <- 1
+   list(inc = function(v) {
+     if(missing(v)) {
+  e$x <- e$x + 1
+ } else {
+ stop('unary inc cannot be assigned to')
+ }
+     x
+   },
+   dec = function(v) {
+     e$x <- e$x - 1
+ x
+ } ) } )
>
> makeActiveBinding("x++", f$inc, .GlobalEnv)
> makeActiveBinding("x--", f$dec, .GlobalEnv)
>
> `x++`
[1] 2
> `x++`
[1] 3
> `x++`
[1] 4
> `x--`
[1] 3
> `x--`
[1] 2
> `x++`
[1] 3
>

But it seems simpler to just go with the reference class system at this point.

On Sun, Oct 19, 2014 at 11:17 AM, PO SU <rhelpmaillist at 163.com> wrote:
>
> It's a good way to use RF OOS, but it's not my needing, actually, i want is there exists a way to write a  %++% form function that can pass one param to it?
> So i can use  1%++%  to get 2 ,a<-2 , a%++% to get a<-3 .
> It seems that the operator overwrite system in R, must pass two params. Is it true?
>
>
>
>
> --
>
> PO SU
> mail: desolator88 at 163.com
> Majored in Statistics from SJTU
>
>
>
> At 2014-10-18 00:54:40, "Greg Snow" <538280 at gmail.com> wrote:
>>You may be interested in looking at Reference Classes/objects (see
>>?setRefClass).  This is a form of OO programming that is more similar
>>to C++ and Java.  You could create a counter object that you could
>>then increment with syntax like:
>>
>>x$inc()
>>x$inc(5)
>>
>>The first would increment by the default (1), the second would then
>>increment by 5.
>>
>>
>>
>>On Fri, Oct 17, 2014 at 2:06 AM, PO SU <rhelpmaillist at 163.com> wrote:
>>>
>>> Tks for your alternative way's details. but like you mentioned in graphics package, i still wonder how to overload an operator which can pass one param like +2 .
>>> There seems exists some examples for my needing. But i try to find them but without any results.
>>> can you show me some examples from it?
>>>
>>>
>>>
>>>
>>>
>>>
>>> --
>>>
>>> PO SU
>>> mail: desolator88 at 163.com
>>> Majored in Statistics from SJTU
>>>
>>>
>>>
>>> At 2014-10-17 15:16:47, "David Winsemius" <dwinsemius at comcast.net> wrote:
>>>>
>>>>On Oct 16, 2014, at 10:36 PM, PO SU wrote:
>>>>
>>>>>
>>>>> Tks for your advice,  let the ++ problem alone, how to write an
>>>>> Unary operator ? Is it permitted in R?
>>>>> such    as    a<-2 , a%+2%  will let a  be 4 .
>>>>
>>>>OK, that's just wrong. Oh, OK, just for fun, as it were:
>>>>
>>>>inc <- function(x)
>>>>{
>>>>  eval.parent(substitute(x <- x + 1))
>>>>}
>>>>
>>>>
>>>> > inc(10)
>>>>Error in 10 <- 10 + 1 : invalid (do_set) left-hand side to assignment
>>>> > y=10
>>>> > inc(y)
>>>> > y
>>>>[1] 11
>>>>
>>>>
>>>>> I just want to know it , i won't pollute r with it , because i know
>>>>> what is r .  : )
>>>>>
>>>>It's certainly permitted. Just look at all the overloadings of the "+"
>>>>operator in graphics packages. Look up the documentation on methods in
>>>>R.
>>>>
>>>>Why not just use a well-behaved function, though?
>>>>
>>>>.inc <- function(x) x+1
>>>> > .inc(10)
>>>>[1] 11
>>>>
>>>>Then you won't be tempted to try 10 <- .inc(10) because it just
>>>>wouldn't make sense.
>>>>
>>>>--
>>>>David.
>>>>
>>>>> --
>>>>>
>>>>> PO SU
>>>>> mail: desolator88 at 163.com
>>>>> Majored in Statistics from SJTU
>>>>>
>>>>>
>>>>>
>>>>>
>>>>> At 2014-10-17 13:09:47, "Rolf Turner" <r.turner at auckland.ac.nz> wrote:
>>>>>> On 17/10/14 17:29, PO SU wrote:
>>>>>>>
>>>>>>> Dear expeRts,
>>>>>>>   Now i want to know how to implement an Unary operator like  i++
>>>>>>> in cpp's  synax form.
>>>>>>>   e.g.   2++  will let 2 be 3 ,  a<-2 ,a++ ,will let a be 3
>>>>>>> I tried this :
>>>>>>>  '%++%'<-function(x){
>>>>>>>    x<<-x+1
>>>>>>> }
>>>>>>> but it have problem, the biggest one is it seems the function need
>>>>>>> twoparams like a%++%b , how to write a function needing just one
>>>>>>> param?
>>>>>>>
>>>>>>> TKS !
>>>>>>
>>>>>> Just ***DON'T***.  The "++" operator is useful only for those wish to
>>>>>> write code which is obscure to the point of incomprehensibility.  It
>>>>>> makes C and its offspring "write only" languages.
>>>>>>
>>>>>> If you are going to use R, use R and don't pollute it with such
>>>>>> abominations.
>>>>>>
>>>>>> cheers,
>>>>>>
>>>>>> Rolf Turner
>>>>>>
>>>>>>
>>>>>> --
>>>>>> Rolf Turner
>>>>>> Technical Editor ANZJS
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>>David Winsemius, MD
>>>>Alameda, CA, USA
>>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>--
>>Gregory (Greg) L. Snow Ph.D.
>>538280 at gmail.com



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From eliza_botto at hotmail.com  Mon Oct 20 22:34:30 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Mon, 20 Oct 2014 20:34:30 +0000
Subject: [R] distance from fitted line
In-Reply-To: <54456537.3030303@auckland.ac.nz>
References: <BLU170-W71402E65C3E132743B2F3189960@phx.gbl>,
	<OF35C7FB0E.2D231DDC-ONC1257D77.0030D34A-C1257D77.003279B0@pcsierteelt.be>
	<BLU170-W554B3865E3A2223DCB4D9389970@phx.gbl>,
	<54456537.3030303@auckland.ac.nz>
Message-ID: <BLU170-W1409393DBBE6172A5D29ACA89970@phx.gbl>

Thankyou Turner,
As i said It was out of my curiosity.Thankyou very much for your reply.   :)
Eliza

> Date: Tue, 21 Oct 2014 08:40:39 +1300
> From: r.turner at auckland.ac.nz
> To: eliza_botto at hotmail.com
> CC: joachim.audenaert at pcsierteelt.be; r-help at r-project.org
> Subject: Re: [R] distance from fitted line
> 
> 
> On 20/10/14 23:00, eliza botto wrote:
> 
> > Thankyou very much Joachim. Actually I already know the residual()
> > command. I only wanted to know that is there a way to account for the
> > fitted lines? its more of a criosity rather than a problem. :)
> > Thankyou very much once again.
> 
> What (on earth!) do you mean by "account for the fitted lines"?  The 
> residuals *are* the (signed, vertical) distances of the observed values 
> from the fitted line.
> 
> cheers,
> 
> Rolf Turner
> 
> -- 
> Rolf Turner
> Technical Editor ANZJS
 		 	   		  
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Oct 20 23:04:13 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Oct 2014 14:04:13 -0700
Subject: [R] format negative numbers
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAE17@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>
	<5444E99C.3050309@yahoo.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAE17@SRVEXCHMBX.precheza.cz>
Message-ID: <48A56878-2C14-4BFD-96D2-626886D2A364@comcast.net>


On Oct 20, 2014, at 4:32 AM, PIKAL Petr wrote:

> Hi
> 
> Thanks to all who responded.
> 
> My input string is rather clumsy. Actually it can have leading or trailing empty space too, it can be mixture of positive and negative numbers.
> 
> In the meantime I made small function which just strips of - sign and make numbers from factors, find numbers which have - sign and change numbers which shall be negative to negative. Not as elegant as your solution but works even when there are leading or trailing spaces.
> 
> zapor <- function(x) {
> num<-as.numeric(gsub("(-)", "", x))

Might want to just use sub() since your method would accept things like "-----100----"

> zap<- grep("-", x)
> num[zap]<- num[zap] * (-1)
> num}
> 
>> x <- as.factor( c("   123.4-   " , "   123   "))
>> zapor(x)
> [1] -123.4  123.0
>> 

gsub("^(\\s+)([0-9.]+)(-){0,1}(\\s)+$", "\\3\\2",
                as.factor( c("   123.4-   " , "   123   ") ) )
[1] "-123.4" "123"  

Then just `as.numeric`. You method looks more elegant. Depending on the local you may get into trouble with variation in decimal markers.


> 
> I just thought that there is some reason for presenting negative numbers with minus sign behind the number in finance community and therefore somebody already invented clever way how to deal with such numbers.
> 
> Cheers
> Petr
> 
> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Marc Girondot
>> Sent: Monday, October 20, 2014 12:53 PM
>> To: r-help at r-project.org
>> Subject: Re: [R] format negative numbers
>> 
>> Is it what you want?
>> 
>>> st <- "0.123-"
>>> gsub("(.+)(-)", "\\2\\1", st)
>> [1] "-0.123"
>>> st <- "0.123"
>>> gsub("(.+)(-)", "\\2\\1", st)
>> [1] "0.123"
>> 
>> Sincerely
>> Marc
>> 
>> Le 20/10/2014 09:03, PIKAL Petr a ?crit :
>>> Dear all.
>>> 
>>> Before I start fishing in (for me) murky regular expression waters I
>> try to ask community about changing format of negative numbers.
>>> 
>>> For some reason I get a file with negative numbers formatted with
>> negative sign at end of number.
>>> 
>>> something like
>>> 
>>> 0.123-
>>> 
>>> It is imported as factors and I need to convert it to numbers again.
>> Before converting I need to change it to "correct" format
>>> 
>>> -0.123
>>> 
>>> Does anybody know some simple way?
>>> 
>>> Cheers
>>> Petr
>>> 
>>> 
>>> ________________________________
>>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
>> 

David Winsemius
Alameda, CA, USA


From enricoc57 at gmail.com  Mon Oct 20 23:14:28 2014
From: enricoc57 at gmail.com (Enrico Colosimo)
Date: Mon, 20 Oct 2014 19:14:28 -0200
Subject: [R] making a plot
In-Reply-To: <3B0C5142-05D0-476C-A398-ED89924AA5D5@comcast.net>
References: <CAGOkrw6W97xJ1GqcdL0ZcOt7FQABDQReTu9=MQT7k6L0R6az8g@mail.gmail.com>
	<CAP=fr+TFJXnRZ1U1N7BZa8D=JUpcNjY2C6Ly8mVZ-rUryY8LTw@mail.gmail.com>
	<3B0C5142-05D0-476C-A398-ED89924AA5D5@comcast.net>
Message-ID: <CAGOkrw4fvodf0sBY9r19W9pkcyUi0_zV9QASa6QcjPbU5FccGw@mail.gmail.com>

Thanks David and Adr?s,

it worked fine.

Enrico.


2014-10-20 15:37 GMT-02:00 David Winsemius <dwinsemius at comcast.net>:

>
> On Oct 20, 2014, at 8:24 AM, Andr?s Arag?n wrote:
>
> > Enrico,
> >
> > This may help you:
> >
> > text(locator(1), "*", cex=1.5,adj=0.5
> >
> > and
> >
> > text(locator(1), "?", cex=1.5,adj=0.5
>
> Why not just use the values of x2 and  y2 that were given to segments:
>
> > text( (ano+ranges)[1:3], 1:3, "*", cex=1.5,adj=0.5)
> > text( (ano+ranges)[4:6], 4:6 , "?", cex=1.5,adj=0.5)
>
> >
> >
> > Draw your plot, then write the code, locate the cursor on your plot, put
> > the symbols where you want itl and click.
> >
> > Regards,
> >
> >
> > Andr?s
> >
> > PS ?locator
> >
> >
> > 2014-10-20 9:46 GMT-05:00 Enrico Colosimo <enricoc57 at gmail.com>:
> >
> >> Dear all,
> >>
> >> I am struggling to make a plot for my survival analysis
> >> class.
> >>
> >> This is my script
> >>
> >>
> >> labels<-c('1','2','3','4','5','6')
> >> ano<-c(2001,2002,2003,2004,2006,2008)
> >> ranges<-c(6,3,4,5,4,2)
> >> dotchart(ano, labels=labels, xlab='ano',
> >> ylab='Pacientes',pch=20,xlim=c(min(ano),  max(ano+ranges)))
> >> segments(ano,1:6,ano+ranges,1:6,pch=25,lty=1,lend=4)
> >>
> >> I need to put an asterix (failure) by the end of the three first lines
> and
> >> a small circle (censoring)
> >> by the end of the last three.
> >>
> >> Someone can help me?
> >>
> >> Thanks,
> >> Enrico.
> >>
> >>        [[alternative HTML version deleted]]
> >
> --
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From chiefmurphy at gmail.com  Mon Oct 20 23:34:57 2014
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Mon, 20 Oct 2014 14:34:57 -0700
Subject: [R] pasteFromExcel
In-Reply-To: <0547CC1D-B0DF-459F-B92C-1F2374EB43BE@comcast.net>
References: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
	<6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>
	<CAHgH9_EGpxS2CGZmNRWrYyqrq-fTAZGhRADAD1+66razu0FuyA@mail.gmail.com>
	<0547CC1D-B0DF-459F-B92C-1F2374EB43BE@comcast.net>
Message-ID: <CAHgH9_G7cxCpxi1_vRj_b3mXi6nNmFGhgX3j-=WAdEYuQ7ng3Q@mail.gmail.com>

Good ideas, David.

1) By "confirm that MS Excel honors that OutDec" I mean that, in a
location (France? others?) where options("OutDec") is a comma, does MS
Excel format numbers that way when displaying currencies with decimal
places? I have no way of knowing if that is true in all OutDec = ","
locales.

2) I wish it were as simple as just removing unwanted "adornments."
The issue is that such "adornments" must be in their proper places for
the character string to represent a currency value, or a numeric value
for that matter. If I add one more comma to your first element in the
wrong place, it should not translate to a valid numeric, but it does
with your gsub, which would be a bug if that were in pasteFromExcel:
> gsub(rmchar, "", c("$1,0,00", "1,200", "800"))
[1] "1000" "1200" "800"

When I originally looked into this I believed I couldn't be the first
one asking that question .. and I wasn't. There are many hits for
regular expressions that purport to successfully identify well-formed
*US dollar* currency strings. The expression in pasteFromExcel is
based on http://stackoverflow.com/questions/354044/what-is-the-best-u-s-currency-regex.

I'm curious if anyone has come across -- and tested -- a similar
regular expression in other places that might have use for
pasteFromExcel.

This is how pasteFromExcel uses its currency regular expression (the
first ugly assignment is what I'm looking for in other locales around
the world -- maybe there's a Regular Expression mailing list out
there):

currencypattern <-
"^\\$?\\-?([1-9]{1}[0-9]{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\-?\\$?([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\$?\\(([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))\\)$"

# Here's a test vector
x <- c("1,234.00", "12,34.00", "$1,000", "(124)", "$(123)", "($123)",
"  1,000   ", "NA")

# grep will tell you whether elements of x, trimmed of
beginning/ending whitespace, match the currencypattern
grep(currencypattern, trim(x))
[1] 1 3 4 5 7  # correct answer

*Now* one may remove unwanted characters from the well-formed strings.
And deal with the "negatives" of course .. and NAs. See how that's
done in excelRio.r in the excelRio package on github:
https://github.com/trinostics/excelRio

Thanks for your interest.


On Mon, Oct 20, 2014 at 10:56 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Oct 20, 2014, at 10:29 AM, Dan Murphy wrote:
>
>> Nice.
>> So if someone were to offer a currency regular expression that works
>> in their locale, I should also ask them to give me the results of
>> Sys.getlocale("LC_MONETARY")
>> and
>> options("OutDec")
>> and confirm that MS Excel honors that OutDec.
>
> I'm not sure we can know what you mean by "confirm that MS Excel honors that OutDec." The result of options("OutDec") was intended for you to determine what character not to remove from a monetary value in an R workspace. If the assumption is that all values will be in the same unit and that the user is not doing any currency conversions then:
>
>>  decsep <- options("OutDec")
>> rmchar <- paste0( "[$??", c(".", ",")[!c(".", ",") %in% decsep], "]" )
>> gsub(rmchar, "", c("$1,000", "1,200", "800"))
> [1] "1000" "1200" "800"
>
>
>> Thank you, David.
>> -Dan
>>
>> On Mon, Oct 20, 2014 at 10:04 AM, David Winsemius
>> <dwinsemius at comcast.net> wrote:
>>>
>>> On Oct 19, 2014, at 11:18 PM, Dan Murphy wrote:
>>>
>>>> To Users of Excel:
>>>>
>>>> Following advice from Brian and Markus, I created an RMarkdown "vignette"
>>>> that shows an example of how the pasteFromExcel function in the excelRio
>>>> package on github could be used by an actuary to transfer a triangle from
>>>> Excel to R. See today's post at http://trinostics.blogspot.com/
>>>>
>>>> Unfortunately, if you are located outside the US, the demonstrated
>>>> functionality will not work for you because the currency regex implemented
>>>> assumes the dollar sign ($) and comma/decimal punctuation of the form
>>>> 999,999.00.
>>>>
>>>> If anyone is interested in contributing currency regex expressions that
>>>> work in your locale, I would be happy to try to incorporate them in the
>>>> package. If anyone knows how best to determine the user's locale (might
>>>> "timezone" suffice?), I'd appreciate that help too.
>>>>
>>>
>>> ?Sys.getlocale   # perhaps "LC_MONETARY"
>>>
>>> ?options   # look for OutDec
>>>
>>>
>>>>      [[alternative HTML version deleted]]
>>>
>>>
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From dwinsemius at comcast.net  Tue Oct 21 00:39:30 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 20 Oct 2014 15:39:30 -0700
Subject: [R] pasteFromExcel
In-Reply-To: <CAHgH9_G7cxCpxi1_vRj_b3mXi6nNmFGhgX3j-=WAdEYuQ7ng3Q@mail.gmail.com>
References: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
	<6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>
	<CAHgH9_EGpxS2CGZmNRWrYyqrq-fTAZGhRADAD1+66razu0FuyA@mail.gmail.com>
	<0547CC1D-B0DF-459F-B92C-1F2374EB43BE@comcast.net>
	<CAHgH9_G7cxCpxi1_vRj_b3mXi6nNmFGhgX3j-=WAdEYuQ7ng3Q@mail.gmail.com>
Message-ID: <1111627E-C50F-487F-96A0-91324B4F7AF7@comcast.net>


On Oct 20, 2014, at 2:34 PM, Dan Murphy wrote:

> Good ideas, David.
> 
> 1) By "confirm that MS Excel honors that OutDec" I mean that, in a
> location (France? others?) where options("OutDec") is a comma, does MS
> Excel format numbers that way when displaying currencies with decimal
> places? I have no way of knowing if that is true in all OutDec = ","
> locales.
> 
> 2) I wish it were as simple as just removing unwanted "adornments."
> The issue is that such "adornments" must be in their proper places for
> the character string to represent a currency value, or a numeric value
> for that matter. If I add one more comma to your first element in the
> wrong place, it should not translate to a valid numeric, but it does
> with your gsub, which would be a bug if that were in pasteFromExcel:
>> gsub(rmchar, "", c("$1,0,00", "1,200", "800"))
> [1] "1000" "1200" "800"

If you wanted to restrict the substitutions to only the commas that were succeeded by three digits then this succeeds:

gsub("(\\,)(\\d{3,3})", "\\2", c("1,000,000,000.00") )
[1] "1000000000.00"

You should also take a look at formatC which has provisions for output using commas.

- 
david.


> 
> When I originally looked into this I believed I couldn't be the first
> one asking that question .. and I wasn't. There are many hits for
> regular expressions that purport to successfully identify well-formed
> *US dollar* currency strings. The expression in pasteFromExcel is
> based on http://stackoverflow.com/questions/354044/what-is-the-best-u-s-currency-regex.
> 
> I'm curious if anyone has come across -- and tested -- a similar
> regular expression in other places that might have use for
> pasteFromExcel.
> 
> This is how pasteFromExcel uses its currency regular expression (the
> first ugly assignment is what I'm looking for in other locales around
> the world -- maybe there's a Regular Expression mailing list out
> there):
> 
> currencypattern <-
> "^\\$?\\-?([1-9]{1}[0-9]{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\-?\\$?([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\$?\\(([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))\\)$"
> 
> # Here's a test vector
> x <- c("1,234.00", "12,34.00", "$1,000", "(124)", "$(123)", "($123)",
> "  1,000   ", "NA")
> 
> # grep will tell you whether elements of x, trimmed of
> beginning/ending whitespace, match the currencypattern
> grep(currencypattern, trim(x))
> [1] 1 3 4 5 7  # correct answer
> 
> *Now* one may remove unwanted characters from the well-formed strings.
> And deal with the "negatives" of course .. and NAs. See how that's
> done in excelRio.r in the excelRio package on github:
> https://github.com/trinostics/excelRio
> 
> Thanks for your interest.
> 
> 
> On Mon, Oct 20, 2014 at 10:56 AM, David Winsemius
> <dwinsemius at comcast.net> wrote:
>> 
>> On Oct 20, 2014, at 10:29 AM, Dan Murphy wrote:
>> 
>>> Nice.
>>> So if someone were to offer a currency regular expression that works
>>> in their locale, I should also ask them to give me the results of
>>> Sys.getlocale("LC_MONETARY")
>>> and
>>> options("OutDec")
>>> and confirm that MS Excel honors that OutDec.
>> 
>> I'm not sure we can know what you mean by "confirm that MS Excel honors that OutDec." The result of options("OutDec") was intended for you to determine what character not to remove from a monetary value in an R workspace. If the assumption is that all values will be in the same unit and that the user is not doing any currency conversions then:
>> 
>>> decsep <- options("OutDec")
>>> rmchar <- paste0( "[$??", c(".", ",")[!c(".", ",") %in% decsep], "]" )
>>> gsub(rmchar, "", c("$1,000", "1,200", "800"))
>> [1] "1000" "1200" "800"
>> 
>> 
>>> Thank you, David.
>>> -Dan
>>> 
>>> On Mon, Oct 20, 2014 at 10:04 AM, David Winsemius
>>> <dwinsemius at comcast.net> wrote:
>>>> 
>>>> On Oct 19, 2014, at 11:18 PM, Dan Murphy wrote:
>>>> 
>>>>> To Users of Excel:
>>>>> 
>>>>> Following advice from Brian and Markus, I created an RMarkdown "vignette"
>>>>> that shows an example of how the pasteFromExcel function in the excelRio
>>>>> package on github could be used by an actuary to transfer a triangle from
>>>>> Excel to R. See today's post at http://trinostics.blogspot.com/
>>>>> 
>>>>> Unfortunately, if you are located outside the US, the demonstrated
>>>>> functionality will not work for you because the currency regex implemented
>>>>> assumes the dollar sign ($) and comma/decimal punctuation of the form
>>>>> 999,999.00.
>>>>> 
>>>>> If anyone is interested in contributing currency regex expressions that
>>>>> work in your locale, I would be happy to try to incorporate them in the
>>>>> package. If anyone knows how best to determine the user's locale (might
>>>>> "timezone" suffice?), I'd appreciate that help too.
>>>>> 
>>>> 
>>>> ?Sys.getlocale   # perhaps "LC_MONETARY"
>>>> 
>>>> ?options   # look for OutDec
>>>> 
>>>> 
>>>>>     [[alternative HTML version deleted]]
>>>> 
>>>> 
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From paul at stat.auckland.ac.nz  Tue Oct 21 02:51:26 2014
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 21 Oct 2014 13:51:26 +1300
Subject: [R] Ternary Plots Do Not Display Ellipses in PDF
In-Reply-To: <alpine.LNX.2.11.1410141404560.18019@localhost>
References: <alpine.LNX.2.11.1410141404560.18019@localhost>
Message-ID: <5445AE0E.1000700@stat.auckland.ac.nz>

Hi

I think the problem is that, as David Carlson pointed out, ellipses() 
works by redrawing the plot and adding more to it.

This means that your PDF version has *two pages*, one with the original 
plot, then another with the plot-plus-ellipses.

Paul

On 10/15/14 10:20, Rich Shepard wrote:
>    A rather strange situation here and I've not found the source of the
> problem.
>
>    The point is to print a ternary plot matrix of compositional data with
> ellipses enclosing 95% of the variance in each plot. The ellipses
> display on
> the monitor, dev = x11cairo (see attached winters-x11cairo.pdf), but not
> when
> sent directly to a file, dev = pdf (see attached winters-pdf.pdf).
>
>    Here's winters.acomp:
>
> structure(c(0.0666666666666667, 0.0612244897959184, 0.0434782608695652,
> 0.043956043956044, 0.05, 0.0161290322580645, 0.6, 0.571428571428571,
> 0.623188405797101, 0.593406593406593, 0.433333333333333,
> 0.629032258064516, 0.0666666666666667, 0.0612244897959184,
> 0.101449275362319, 0.0659340659340659, 0.0666666666666667,
> 0.032258064516129, 0.244444444444444, 0.26530612244898,
> 0.217391304347826, 0.263736263736264, 0.366666666666667,
> 0.290322580645161, 0.0222222222222222, 0.0408163265306122,
> 0.0144927536231884, 0.032967032967033, 0.0833333333333333,
> 0.032258064516129), .Dim = c(6L, 5L), .Dimnames = list(
>      NULL, c("filter", "gather", "graze", "predate", "shred")), class =
> "acomp")
>
>    And this is the command sequence:
>
>> library(compositions)
>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> r <- sqrt(qchisq(p=0.95, df=4))
>> mn <- mean(winters.acomp)
>> vr <- var(winters.acomp)
>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
>      col='red', lwd=2)
> # monitor plot window is manually closed.
>> pdf("winters-pdf.pdf")
>> plot(winters.acomp, main="Winters Creek", cex=0.5)
>> ellipses(mean=mn, var=vr, r=r, steps=72, thinRatio=NULL, aspanel=FALSE,
>      col='red', lwd=2)
>> dev.off()
>
>    What am I not seeing here that causes the different outputs?
>
> Rich
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From ripley at stats.ox.ac.uk  Tue Oct 21 08:26:42 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Oct 2014 07:26:42 +0100
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>
Message-ID: <5445FCA2.1000307@stats.ox.ac.uk>

On 20/10/2014 17:53, John McKown wrote:
> On Mon, Oct 20, 2014 at 10:30 AM, Dimitri Liakhovitski <
> dimitri.liakhovitski at gmail.com> wrote:
>
>> Dear Rers,
>>
>> I am trying to run a for-loop in R.
>> During each iteration I read in an mp3 file and do some basic processing.
>> If I do what I need to do for each file one by one - it works fine.
>> But once I start running a loop, it soon runs out of memory and says: can't
>> allocate a vector of size...
>> In each iteration of my loop I always overwrite the previously created
>> object and do gc().
>>
>> Any hints on how to fight this?
>>
>> Thanks a lot!
>>
>>
>>
> ?Please don't use HTML for messages.
>
> What occurs to me, from reading the other replies, is that perhaps within
> the loop you are causing other objects to be allocated. And that can be
> done just by doing a simple assignment, so it may not be obvious. What this
> can do is cause what we called a "sand bar" in the old days. That's where
> you allocate a big chunk of memory for an object. Say this take up 1/2 of
> your available space. You now create a small object. This object is
> _probably_ right next to the large object. You now release the large
> object. Your apparent free space is now almost what it was at the
> beginning. But when you try to allocate another large object which is, say,
> 2/3 of the maximum space, you can't because that small object is sitting
> right in the middle of our memory space. So you _can_ allocate 2 large
> objects which are 1/3 your free space size, but not 1 object which is 2/3
> of the free space size. Which can lead to your type of situation.
>
> This is just a SWAG based on some experience in other systems. Most
> "garbage collection" do _not_ do memory consolidation. I don't know about
> R.?
>
>
That is true of R (except for the early days which did have a moving 
garbage collector).

However 'your available space' is not the amount of RAM you have but the 
process address space.  The latter is enormous on any 64-bit OS, so 
'memory fragmentation' (as this is termed) is a thing of the past except 
for those limited to many-years-old OSes.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From chobophil at gmail.com  Tue Oct 21 09:34:07 2014
From: chobophil at gmail.com (Phil)
Date: Tue, 21 Oct 2014 09:34:07 +0200
Subject: [R] {car} outlierTest looses p/q values
In-Reply-To: <web-531937413@cgpsrv2.cis.mcmaster.ca>
References: <5440F52A.7050503@gmail.com>
	<web-531893112@cgpsrv2.cis.mcmaster.ca>
	<CAA4NQG8fL2xOy851Pg1TVLvaMFMLk-j31a1cFsQP2rdV+sWgww@mail.gmail.com>
	<web-531937413@cgpsrv2.cis.mcmaster.ca>
Message-ID: <54460C6F.3010209@gmail.com>

Hi all,

as John pointed out, there is a way to create settings where the 
studentized residuals are undefined. However, after cross-checking it 
seems that the residuals are getting calculated without any error. The 
problem comes up when I use outlierTest to assign a p,q value,respectively.

Below is the code and some printouts:


non.zero.orga.vector <- 
c(1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,13.98) #targervector

print(meta.Matrix[,3])
  x1         x28          x2      x3      x4         x51     x52     x5 
     x6      x7     x82
      4.6     35.8      4.1      5.4      5.2     27.9 48.2      4.5    
5.7    4.2    100.5

print(meta.Matrix[,10])
      x1                      x28               x2     x3
0.2990466     1.0497156     0.2805028 0.3517993

       x4          x51                x52                  x5
0.3543678 1.0178604 0.4933182 0.2810865

     x6                   x7              x82
0.4349550 0.3269192 3.0889747

glModel <- glm(non.zero.orga.vector ~ meta.Matrix[,3]+meta.Matrix[,10]) 
#create glm for testing

print(glModel$residuals) #check if residuals are calculated for every 
entry in the target vector
   x1                   x28                x2                x3         
     x4              x51           x52
  0.6600696 -2.5816334  0.7438969  0.4129873  0.3976498 -2.5350861 
0.3128240
        x5            x6                    x7           x82
  0.7465766  0.0102020  0.5181337  1.3143796



  test.Res <- outlierTest(glModel,digits=4,cutoff=Inf,n.max=Inf) #test 
the glm for outlier, cutoff=Inf/n.max=Inf == report everything

print(test.Res$bonf.p) #check if q-value exists
      x28              x51              x52           x5     x2       
         x1               x7           x3
0.1915995 0.2240759 2.1637438 6.0211575 6.0306110 6.4618792 7.1932613 
7.7595619
       x4               x6
7.8394477 9.9437848



As you see the glm calculates residuals for x82 (which is in fact 1.314) 
but the outlierTest does not assign a p/q value to it. Does anyone know why?

Thanks in advance,

Phil

On 10/17/2014 08:54 PM, John Fox wrote:
> Dear Phil,
>
> Yes, that's a bit clearer. One can invent data configurations where certain studentized residuals are undefined. For example, try the following:
>
> y <- c(0, 0, 0, 0, 0, 1)
> x <- 1:6
> xx <- (1:6 - 3.5)^2
> rstudent(lm(y ~ x))
> rstudent(lm(y ~ xx))
> plot(x, y)
> plot(xx, y)
>
> The plots should clarify what's going on.
>
> I'm copying to r-help since the discussion began there.
>
> I hope this helps,
>   John
>
> On Fri, 17 Oct 2014 18:35:59 +0200
>   Philip Stevens <chobophil at gmail.com> wrote:
>> Dear John,
>>
>> Thank you for your fast reply. Unfortunately I am out of office right now
>> but I will get back to you on Monday asap with a toy example and some code.
>> Meanwhile let me try to explain further.
>>
>> Basically not the glm but the outlierTest afterwards fails. And it only
>> fails if all values, used to set up the glm, are exactly 1 except for one
>> value which can be arbitrary large. I construct the glm from a vector of
>> doubles (the target values) and a vector of other numeric values(metadata).
>> (So this should be fit <- glm(targetVector ~ metadata) ) And want to check
>> if one of those doubles(in the target vector) is an outlier using
>> outlierTest(fit). The residuals are calculated by the glm but the
>> outlierTest does not report a p nor a q value for the one value in the
>> target vector which is not 1. And I can't figure out why...
>>
>> I hope this makes it a bit clearer.
>> Anyways I will come back to you on Monday.
>>
>> Best,
>>
>> Phil
>> Am 17.10.2014 17:43 schrieb "John Fox" <jfox at mcmaster.ca>:
>>
>>> Dear Phil,
>>>
>>> After reading your posting several times, I still don't understand what
>>> you did. As usual, having a reproducible example illustrating the error
>>> would be a great help. I do have a guess about the source of the error:
>>> glm() failed in some way for the problematic case.
>>>
>>> Best,
>>>   John
>>>
>>> ------------------------------------------------
>>> John Fox, Professor
>>> McMaster University
>>> Hamilton, Ontario, Canada
>>> http://socserv.mcmaster.ca/jfox/
>>>
>>>
>>> On Fri, 17 Oct 2014 12:53:30 +0200
>>>   Phil <chobophil at gmail.com> wrote:
>>>> Hi guys,
>>>>
>>>> I came across a strange phenomena and can't figure out why it happens by
>>> myself so here we go.
>>>> I got a dataframe which consists of double numbers which I want to
>>> check, row-wise if there are outliers in the rows.
>>>> So I iterate over the rows and create a glm using the numbers of that
>>> particular row. Which might look like this:
>>>> case1)
>>>>           x1        x2        x3        x4        x5        x6 x7
>>>> x8        x9        x10        x11
>>>>       0.00     3.91     0.00     0.00     0.00   68.03   40.39 0.00
>>>> 0.00      0.00       4.11
>>>>
>>>> or like this:
>>>> case2)
>>>>           x1        x2        x3        x4        x5        x6 x7
>>>> x8        x9        x10        x11
>>>>        1.00     1.00    1.00     1.00     1.00     1.00     1.00 1.00
>>>> 1.00     1.00      5.34
>>>>
>>>> or any other combination of double numbers...
>>>>
>>>> however, using a glm like this:
>>>>
>>>> glModel <- glm(vector ~ some_other_meta_data_which_is_double_numbers)
>>>>
>>>> and testing it with:
>>>>
>>>>    test.Res <- outlierTest(glModel,digits=4,cutoff=Inf,n.max=Inf)
>>>>
>>>> I always get a result consisting of the desired p and q values but not
>>> if the vector I use looks like case2. There is no error message and the
>>> computation does not stop either.
>>>> However, all p and q values are produced except for the last value x11.
>>>>
>>>> Any idea why this particular value gets dropped from the output of the
>>> outlierTest Method in the car package.
>>>> Here is the sessioninfo:
>>>>
>>>>    sessionInfo()
>>>> R version 3.1.1 (2014-07-10)
>>>> Platform: x86_64-redhat-linux-gnu (64-bit)
>>>>
>>>> locale:
>>>>    [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
>>>>    [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
>>>>    [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
>>>>    [7] LC_PAPER=en_US.utf8       LC_NAME=C
>>>>    [9] LC_ADDRESS=C              LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods base
>>>>
>>>> other attached packages:
>>>> [1] ggplot2_1.0.0      car_2.0-21         RColorBrewer_1.0-5 iNEXT_1.0
>>>> [5] vegan_2.0-10       lattice_0.20-29    permute_0.8-3
>>>>
>>>> loaded via a namespace (and not attached):
>>>>    [1] colorspace_1.2-4 compiler_3.1.1   digest_0.6.4 grid_3.1.1
>>>>    [5] gtable_0.1.2     labeling_0.3     MASS_7.3-33 munsell_0.4.2
>>>>    [9] nnet_7.3-8       plyr_1.8.1       proto_0.3-10 Rcpp_0.11.2
>>>> [13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
>>>>
>>>> Any help is highly appreciated.
>>>>
>>>> Thanks
>>>>
>>>> Phil
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>>
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
> 	
> 	
>


From miaojpm at gmail.com  Tue Oct 21 10:28:38 2014
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 21 Oct 2014 16:28:38 +0800
Subject: [R] Dealing with NAs in lm or gmm
Message-ID: <CABcx46A6E8k8MD9+t9Z8tTyiFXwWaPtiyvc6mB-KeBfZt94WuA@mail.gmail.com>

Hi,

   My question is about NAs in the function "gmm", but I believe that the
same issues occur in the case of "lm".

   I try to estimate a model by "gmm" function (GMM, generalized method of
moments). Each of the  variables has 94 rows, but the resulting fitted
model has only 89 rows. Then the function removes the rows with NAs.  I
want to add a 94*1 vector, ONI, to the resulting fitted values; I want to
find the fitted value with NAs kept. How can I do it? na.action?

   Code:

   > gmm8<-gmm(y~RDR1+xx, xiv)
Warning message:
In getDat(object$g, object$x) :
  There are missing values. Associated observations have been removed

> ONI.gmm8<-fitted(gmm8)+0.85*ONI
Error in NextMethod(.Generic) :
  dims [product 89] do not match the length of object [94]
In addition: Warning message:
In `+.default`(fitted(gmm8), 0.85 * ONI) :
  longer object length is not a multiple of shorter object length

Help on na.action:
na.action
a function which indicates what should happen when the data contain NAs.
The default is set by the na.action setting of options, and is na.fail if
that is unset. The ?factory-fresh? default is na.omit. Another possible
value is NULL, no action. Value na.exclude can be useful.

Thanks!

Miao

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Tue Oct 21 11:27:23 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 21 Oct 2014 09:27:23 +0000
Subject: [R] Dealing with NAs in lm or gmm
In-Reply-To: <CABcx46A6E8k8MD9+t9Z8tTyiFXwWaPtiyvc6mB-KeBfZt94WuA@mail.gmail.com>
References: <CABcx46A6E8k8MD9+t9Z8tTyiFXwWaPtiyvc6mB-KeBfZt94WuA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B0816A@inbomail.inbo.be>

You want na.action = na.exclude. Or remove rows with NA values from your dataset. Which is IMHO the safest way to build a model.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens jpm miao
Verzonden: dinsdag 21 oktober 2014 10:29
Aan: r-help
Onderwerp: [R] Dealing with NAs in lm or gmm

Hi,

   My question is about NAs in the function "gmm", but I believe that the same issues occur in the case of "lm".

   I try to estimate a model by "gmm" function (GMM, generalized method of moments). Each of the  variables has 94 rows, but the resulting fitted model has only 89 rows. Then the function removes the rows with NAs.  I want to add a 94*1 vector, ONI, to the resulting fitted values; I want to find the fitted value with NAs kept. How can I do it? na.action?

   Code:

   > gmm8<-gmm(y~RDR1+xx, xiv)
Warning message:
In getDat(object$g, object$x) :
  There are missing values. Associated observations have been removed

> ONI.gmm8<-fitted(gmm8)+0.85*ONI
Error in NextMethod(.Generic) :
  dims [product 89] do not match the length of object [94] In addition: Warning message:
In `+.default`(fitted(gmm8), 0.85 * ONI) :
  longer object length is not a multiple of shorter object length

Help on na.action:
na.action
a function which indicates what should happen when the data contain NAs.
The default is set by the na.action setting of options, and is na.fail if that is unset. The ?factory-fresh? default is na.omit. Another possible value is NULL, no action. Value na.exclude can be useful.

Thanks!

Miao

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

From miaojpm at gmail.com  Tue Oct 21 11:35:06 2014
From: miaojpm at gmail.com (jpm miao)
Date: Tue, 21 Oct 2014 17:35:06 +0800
Subject: [R] Dealing with NAs in lm or gmm
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B0816A@inbomail.inbo.be>
References: <CABcx46A6E8k8MD9+t9Z8tTyiFXwWaPtiyvc6mB-KeBfZt94WuA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B0816A@inbomail.inbo.be>
Message-ID: <CABcx46DL9e1Ns6fgfy88zEFYWjCeNazuOJNtXXFic96c=BUynA@mail.gmail.com>

I tries "na.action = na.exclude" but it returns a fitted vector with NAs
removed.
Is there any way to return the fitted vector with NAs (In my case, 94*1
matrix)?

> gmm8<-gmm(y~RDR1+xx, xiv, na.action = na.exclude)
Warning message:
In getDat(object$g, object$x) :
  There are missing values. Associated observations have been removed
> nrow(fitted(gmm8))
[1] 89
> nrow(xx)
NULL
> nrow(as.matrix(xx))
[1] 94
> nrow(RDR1)
[1] 94
> nrow(y)
[1] 94

2014-10-21 17:27 GMT+08:00 ONKELINX, Thierry <Thierry.ONKELINX at inbo.be>:

> You want na.action = na.exclude. Or remove rows with NA values from your
> dataset. Which is IMHO the safest way to build a model.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> Namens jpm miao
> Verzonden: dinsdag 21 oktober 2014 10:29
> Aan: r-help
> Onderwerp: [R] Dealing with NAs in lm or gmm
>
> Hi,
>
>    My question is about NAs in the function "gmm", but I believe that the
> same issues occur in the case of "lm".
>
>    I try to estimate a model by "gmm" function (GMM, generalized method of
> moments). Each of the  variables has 94 rows, but the resulting fitted
> model has only 89 rows. Then the function removes the rows with NAs.  I
> want to add a 94*1 vector, ONI, to the resulting fitted values; I want to
> find the fitted value with NAs kept. How can I do it? na.action?
>
>    Code:
>
>    > gmm8<-gmm(y~RDR1+xx, xiv)
> Warning message:
> In getDat(object$g, object$x) :
>   There are missing values. Associated observations have been removed
>
> > ONI.gmm8<-fitted(gmm8)+0.85*ONI
> Error in NextMethod(.Generic) :
>   dims [product 89] do not match the length of object [94] In addition:
> Warning message:
> In `+.default`(fitted(gmm8), 0.85 * ONI) :
>   longer object length is not a multiple of shorter object length
>
> Help on na.action:
> na.action
> a function which indicates what should happen when the data contain NAs.
> The default is set by the na.action setting of options, and is na.fail if
> that is unset. The ?factory-fresh? default is na.omit. Another possible
> value is NULL, no action. Value na.exclude can be useful.
>
> Thanks!
>
> Miao
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Tue Oct 21 11:51:14 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Tue, 21 Oct 2014 09:51:14 +0000
Subject: [R] Dealing with NAs in lm or gmm
In-Reply-To: <CABcx46DL9e1Ns6fgfy88zEFYWjCeNazuOJNtXXFic96c=BUynA@mail.gmail.com>
References: <CABcx46A6E8k8MD9+t9Z8tTyiFXwWaPtiyvc6mB-KeBfZt94WuA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B0816A@inbomail.inbo.be>
	<CABcx46DL9e1Ns6fgfy88zEFYWjCeNazuOJNtXXFic96c=BUynA@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B081A4@inbomail.inbo.be>

It looks like gmm is not handling na.exclude correctly. You should contact the package maintainer.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be<mailto:Thierry.Onkelinx at inbo.be>
www.inbo.be<http://www.inbo.be/>

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

Van: jpm miao [mailto:miaojpm at gmail.com]
Verzonden: dinsdag 21 oktober 2014 11:35
Aan: ONKELINX, Thierry
CC: r-help
Onderwerp: Re: [R] Dealing with NAs in lm or gmm

I tries "na.action = na.exclude" but it returns a fitted vector with NAs removed.
Is there any way to return the fitted vector with NAs (In my case, 94*1 matrix)?

> gmm8<-gmm(y~RDR1+xx, xiv, na.action = na.exclude)
Warning message:
In getDat(object$g, object$x) :
  There are missing values. Associated observations have been removed
> nrow(fitted(gmm8))
[1] 89
> nrow(xx)
NULL
> nrow(as.matrix(xx))
[1] 94
> nrow(RDR1)
[1] 94
> nrow(y)
[1] 94

2014-10-21 17:27 GMT+08:00 ONKELINX, Thierry <Thierry.ONKELINX at inbo.be<mailto:Thierry.ONKELINX at inbo.be>>:
You want na.action = na.exclude. Or remove rows with NA values from your dataset. Which is IMHO the safest way to build a model.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51<tel:%2B%2032%202%20525%2002%2051>
+ 32 54 43 61 85<tel:%2B%2032%2054%2043%2061%2085>
Thierry.Onkelinx at inbo.be<mailto:Thierry.Onkelinx at inbo.be>
www.inbo.be<http://www.inbo.be>

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>] Namens jpm miao
Verzonden: dinsdag 21 oktober 2014 10:29
Aan: r-help
Onderwerp: [R] Dealing with NAs in lm or gmm

Hi,

   My question is about NAs in the function "gmm", but I believe that the same issues occur in the case of "lm".

   I try to estimate a model by "gmm" function (GMM, generalized method of moments). Each of the  variables has 94 rows, but the resulting fitted model has only 89 rows. Then the function removes the rows with NAs.  I want to add a 94*1 vector, ONI, to the resulting fitted values; I want to find the fitted value with NAs kept. How can I do it? na.action?

   Code:

   > gmm8<-gmm(y~RDR1+xx, xiv)
Warning message:
In getDat(object$g, object$x) :
  There are missing values. Associated observations have been removed

> ONI.gmm8<-fitted(gmm8)+0.85*ONI
Error in NextMethod(.Generic) :
  dims [product 89] do not match the length of object [94] In addition: Warning message:
In `+.default`(fitted(gmm8), 0.85 * ONI) :
  longer object length is not a multiple of shorter object length

Help on na.action:
na.action
a function which indicates what should happen when the data contain NAs.
The default is set by the na.action setting of options, and is na.fail if that is unset. The ?factory-fresh? default is na.omit. Another possible value is NULL, no action. Value na.exclude can be useful.

Thanks!

Miao
        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.

	[[alternative HTML version deleted]]


From Swapnil.Khobragade at lntinfotech.com  Tue Oct 21 12:33:29 2014
From: Swapnil.Khobragade at lntinfotech.com (Swapnil Khobragade)
Date: Tue, 21 Oct 2014 16:03:29 +0530
Subject: [R] undesirable output for lm( )
Message-ID: <24E59E774BB54C4D835922C8D6BA8093014B04CD55@POWINMSMBX01.pwiodc.lntinfotech.com>

Hi,

I have written this code and it is working fine

Example 1:

>fit <- lm(cpi ~ year + quarter)
>(cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011 + fit$coefficients[[3]]*(1:4))

*****************************************************************************************
Example 2:

>fit <- lm(cpi ~ year )
>(cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011)

I'm getting an undesirable output for this calculation.
Plz help in correcting the mistakes to get clear output.



Regards,
Swapnil Khobragade
e-mail ID: swapnil.khobragade at lntinfotech.com<mailto:swapnil.khobragade at lntinfotech.com>
Tel: @@@@@@@(Direct) | +91 9503043368 (M)


________________________________
The contents of this e-mail and any attachment(s) may contain confidential or privileged information for the intended recipient(s). Unintended recipients are prohibited from taking action on the basis of information in this e-mail and using or disseminating the information, and must notify the sender and delete it from their system. L&T Infotech will not accept responsibility or liability for the accuracy or completeness of, or the presence of any virus or disabling code in this e-mail"

	[[alternative HTML version deleted]]


From enrico.bibbona at unito.it  Tue Oct 21 13:24:42 2014
From: enrico.bibbona at unito.it (Enrico Bibbona)
Date: Tue, 21 Oct 2014 13:24:42 +0200
Subject: [R] "source" command inside R package scripts
Message-ID: <CAFvnaTatUefWn-E2NbnjtCT9J64Ho5UOrPdbA_5JHsG+njjJXA@mail.gmail.com>

I have built a new package. I would like to put an R script (let us call it
"script.R) into a subdirectory of the /pkg/R/ directory, called /pkg/R/sub/
and I would like that such code is run when the package is installed.

My way of doing so was to put an R script into /pkg/R/ with source command
like

source("./R/sub/script.R")

that does not give me any error, but I know that the script (which
actuallly defines a few functions is not run. What is wrong? What can I do
better?
Thanks, Enrico

-- 
Enrico Bibbona
Dipartimento di Matematica
Universit? di Torino
https://sites.google.com/site/enricobibbona/

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Tue Oct 21 14:07:53 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 21 Oct 2014 14:07:53 +0200
Subject: [R] undesirable output for lm( )
In-Reply-To: <24E59E774BB54C4D835922C8D6BA8093014B04CD55@POWINMSMBX01.pwiodc.lntinfotech.com>
References: <24E59E774BB54C4D835922C8D6BA8093014B04CD55@POWINMSMBX01.pwiodc.lntinfotech.com>
Message-ID: <4ED7E6D5-766D-48F1-B494-D8D492C298BE@gmail.com>

This is rubbish. We don't know what the output is nor what you perceive is wrong with it.

And what is the business of cc-ing

"respond-auto at linuxmafia.com" <respond-auto at linuxmafia.com>
"esr at thyrsus.com" <esr at thyrsus.com>

?

(The latter is Eric S. Raymond, who I strongly believe has no interest in your R problems.)

This reeks of deliberate trouble-making. Unless you can come up with a credible explanation for this, I strongly suggest that you be barred from this mailing list.

Peter Dalgaard


On 21 Oct 2014, at 12:33 , Swapnil Khobragade <Swapnil.Khobragade at lntinfotech.com> wrote:

> Hi,
> 
> I have written this code and it is working fine
> 
> Example 1:
> 
>> fit <- lm(cpi ~ year + quarter)
>> (cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011 + fit$coefficients[[3]]*(1:4))
> 
> *****************************************************************************************
> Example 2:
> 
>> fit <- lm(cpi ~ year )
>> (cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011)
> 
> I'm getting an undesirable output for this calculation.
> Plz help in correcting the mistakes to get clear output.
> 
> 
> 
> Regards,
> Swapnil Khobragade
> e-mail ID: swapnil.khobragade at lntinfotech.com<mailto:swapnil.khobragade at lntinfotech.com>
> Tel: @@@@@@@(Direct) | +91 9503043368 (M)
> 
> 
> ________________________________
> The contents of this e-mail and any attachment(s) may contain confidential or privileged information for the intended recipient(s). Unintended recipients are prohibited from taking action on the basis of information in this e-mail and using or disseminating the information, and must notify the sender and delete it from their system. L&T Infotech will not accept responsibility or liability for the accuracy or completeness of, or the presence of any virus or disabling code in this e-mail"
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From chiefmurphy at gmail.com  Tue Oct 21 15:03:30 2014
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Tue, 21 Oct 2014 06:03:30 -0700
Subject: [R] pasteFromExcel
In-Reply-To: <1111627E-C50F-487F-96A0-91324B4F7AF7@comcast.net>
References: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
	<6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>
	<CAHgH9_EGpxS2CGZmNRWrYyqrq-fTAZGhRADAD1+66razu0FuyA@mail.gmail.com>
	<0547CC1D-B0DF-459F-B92C-1F2374EB43BE@comcast.net>
	<CAHgH9_G7cxCpxi1_vRj_b3mXi6nNmFGhgX3j-=WAdEYuQ7ng3Q@mail.gmail.com>
	<1111627E-C50F-487F-96A0-91324B4F7AF7@comcast.net>
Message-ID: <CAHgH9_H-5a0HMYMSYCX+8MfkyeBzZzVUyYpe4x92bbPM5onR9g@mail.gmail.com>

Sure, that is one pattern to try to detect, but there are many more
(e.g., cannot have multiple '$' or '?'). For speed, I'm looking for a
*single* expression to detect valid currency strings in one grep.

The one shown for US works. For euros, it might suffice to replace '$'
with '?' but I cannot test that in my location. Can you? I.e.,

Change currencypattern to

currencypattern <-
  "^\\??\\-?([1-9]{1}[0-9]{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))?|^\\-?\\??([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))?|^\\??\\(([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))\\)?"

Does Excel display euro values per the format within this test vector?

x <- c("1,234.00", "12,34.00", "?1,000", "(124)", "$(123)", "(?123)",
"  1,000   ", "NA")

and does grep yield the correct answer? It should, but better to test
it than assume.

grep(currencypattern, trim(x))
[1] 1 3 4 5 7  # correct answer

I suppose my biggest holdup is knowing how Excel formats currencies in
other denominations. Maybe there's a way for me to test euro,
sterling, etc. in my location, but I haven't discovered it yet. :(

Again, thanks for your help.

-Dan

On Mon, Oct 20, 2014 at 3:39 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Oct 20, 2014, at 2:34 PM, Dan Murphy wrote:
>
>> Good ideas, David.
>>
>> 1) By "confirm that MS Excel honors that OutDec" I mean that, in a
>> location (France? others?) where options("OutDec") is a comma, does MS
>> Excel format numbers that way when displaying currencies with decimal
>> places? I have no way of knowing if that is true in all OutDec = ","
>> locales.
>>
>> 2) I wish it were as simple as just removing unwanted "adornments."
>> The issue is that such "adornments" must be in their proper places for
>> the character string to represent a currency value, or a numeric value
>> for that matter. If I add one more comma to your first element in the
>> wrong place, it should not translate to a valid numeric, but it does
>> with your gsub, which would be a bug if that were in pasteFromExcel:
>>> gsub(rmchar, "", c("$1,0,00", "1,200", "800"))
>> [1] "1000" "1200" "800"
>
> If you wanted to restrict the substitutions to only the commas that were succeeded by three digits then this succeeds:
>
> gsub("(\\,)(\\d{3,3})", "\\2", c("1,000,000,000.00") )
> [1] "1000000000.00"
>
> You should also take a look at formatC which has provisions for output using commas.
>
> -
> david.
>
>
>>
>> When I originally looked into this I believed I couldn't be the first
>> one asking that question .. and I wasn't. There are many hits for
>> regular expressions that purport to successfully identify well-formed
>> *US dollar* currency strings. The expression in pasteFromExcel is
>> based on http://stackoverflow.com/questions/354044/what-is-the-best-u-s-currency-regex.
>>
>> I'm curious if anyone has come across -- and tested -- a similar
>> regular expression in other places that might have use for
>> pasteFromExcel.
>>
>> This is how pasteFromExcel uses its currency regular expression (the
>> first ugly assignment is what I'm looking for in other locales around
>> the world -- maybe there's a Regular Expression mailing list out
>> there):
>>
>> currencypattern <-
>> "^\\$?\\-?([1-9]{1}[0-9]{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\-?\\$?([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\$?\\(([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))\\)$"
>>
>> # Here's a test vector
>> x <- c("1,234.00", "12,34.00", "$1,000", "(124)", "$(123)", "($123)",
>> "  1,000   ", "NA")
>>
>> # grep will tell you whether elements of x, trimmed of
>> beginning/ending whitespace, match the currencypattern
>> grep(currencypattern, trim(x))
>> [1] 1 3 4 5 7  # correct answer
>>
>> *Now* one may remove unwanted characters from the well-formed strings.
>> And deal with the "negatives" of course .. and NAs. See how that's
>> done in excelRio.r in the excelRio package on github:
>> https://github.com/trinostics/excelRio
>>
>> Thanks for your interest.
>>
>>
>> On Mon, Oct 20, 2014 at 10:56 AM, David Winsemius
>> <dwinsemius at comcast.net> wrote:
>>>
>>> On Oct 20, 2014, at 10:29 AM, Dan Murphy wrote:
>>>
>>>> Nice.
>>>> So if someone were to offer a currency regular expression that works
>>>> in their locale, I should also ask them to give me the results of
>>>> Sys.getlocale("LC_MONETARY")
>>>> and
>>>> options("OutDec")
>>>> and confirm that MS Excel honors that OutDec.
>>>
>>> I'm not sure we can know what you mean by "confirm that MS Excel honors that OutDec." The result of options("OutDec") was intended for you to determine what character not to remove from a monetary value in an R workspace. If the assumption is that all values will be in the same unit and that the user is not doing any currency conversions then:
>>>
>>>> decsep <- options("OutDec")
>>>> rmchar <- paste0( "[$??", c(".", ",")[!c(".", ",") %in% decsep], "]" )
>>>> gsub(rmchar, "", c("$1,000", "1,200", "800"))
>>> [1] "1000" "1200" "800"
>>>
>>>
>>>> Thank you, David.
>>>> -Dan
>>>>
>>>> On Mon, Oct 20, 2014 at 10:04 AM, David Winsemius
>>>> <dwinsemius at comcast.net> wrote:
>>>>>
>>>>> On Oct 19, 2014, at 11:18 PM, Dan Murphy wrote:
>>>>>
>>>>>> To Users of Excel:
>>>>>>
>>>>>> Following advice from Brian and Markus, I created an RMarkdown "vignette"
>>>>>> that shows an example of how the pasteFromExcel function in the excelRio
>>>>>> package on github could be used by an actuary to transfer a triangle from
>>>>>> Excel to R. See today's post at http://trinostics.blogspot.com/
>>>>>>
>>>>>> Unfortunately, if you are located outside the US, the demonstrated
>>>>>> functionality will not work for you because the currency regex implemented
>>>>>> assumes the dollar sign ($) and comma/decimal punctuation of the form
>>>>>> 999,999.00.
>>>>>>
>>>>>> If anyone is interested in contributing currency regex expressions that
>>>>>> work in your locale, I would be happy to try to incorporate them in the
>>>>>> package. If anyone knows how best to determine the user's locale (might
>>>>>> "timezone" suffice?), I'd appreciate that help too.
>>>>>>
>>>>>
>>>>> ?Sys.getlocale   # perhaps "LC_MONETARY"
>>>>>
>>>>> ?options   # look for OutDec
>>>>>
>>>>>
>>>>>>     [[alternative HTML version deleted]]
>>>>>
>>>>>
>>>>>
>>>>> David Winsemius
>>>>> Alameda, CA, USA
>>>>>
>>>
>>> David Winsemius
>>> Alameda, CA, USA
>>>
>
> David Winsemius
> Alameda, CA, USA
>


From ntfredo at gmail.com  Tue Oct 21 15:12:16 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 21 Oct 2014 16:12:16 +0300
Subject: [R] Dealing with NAs in lm or gmm
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B081A4@inbomail.inbo.be>
References: <CABcx46A6E8k8MD9+t9Z8tTyiFXwWaPtiyvc6mB-KeBfZt94WuA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B0816A@inbomail.inbo.be>
	<CABcx46DL9e1Ns6fgfy88zEFYWjCeNazuOJNtXXFic96c=BUynA@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B081A4@inbomail.inbo.be>
Message-ID: <CAGh51gSV0B8a7rHyMvyvrnBFo6EE6ZLnBvT4sAiCJAsj_igZcQ@mail.gmail.com>

I suggest you remove the NAs in your dataset if it does not affect your
results.

That can be done by using na.omit command. Thanks.

On Tue, Oct 21, 2014 at 12:51 PM, ONKELINX, Thierry <
Thierry.ONKELINX at inbo.be> wrote:

> It looks like gmm is not handling na.exclude correctly. You should contact
> the package maintainer.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be<mailto:Thierry.Onkelinx at inbo.be>
> www.inbo.be<http://www.inbo.be/>
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> Van: jpm miao [mailto:miaojpm at gmail.com]
> Verzonden: dinsdag 21 oktober 2014 11:35
> Aan: ONKELINX, Thierry
> CC: r-help
> Onderwerp: Re: [R] Dealing with NAs in lm or gmm
>
> I tries "na.action = na.exclude" but it returns a fitted vector with NAs
> removed.
> Is there any way to return the fitted vector with NAs (In my case, 94*1
> matrix)?
>
> > gmm8<-gmm(y~RDR1+xx, xiv, na.action = na.exclude)
> Warning message:
> In getDat(object$g, object$x) :
>   There are missing values. Associated observations have been removed
> > nrow(fitted(gmm8))
> [1] 89
> > nrow(xx)
> NULL
> > nrow(as.matrix(xx))
> [1] 94
> > nrow(RDR1)
> [1] 94
> > nrow(y)
> [1] 94
>
> 2014-10-21 17:27 GMT+08:00 ONKELINX, Thierry <Thierry.ONKELINX at inbo.be
> <mailto:Thierry.ONKELINX at inbo.be>>:
> You want na.action = na.exclude. Or remove rows with NA values from your
> dataset. Which is IMHO the safest way to build a model.
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51<tel:%2B%2032%202%20525%2002%2051>
> + 32 54 43 61 85<tel:%2B%2032%2054%2043%2061%2085>
> Thierry.Onkelinx at inbo.be<mailto:Thierry.Onkelinx at inbo.be>
> www.inbo.be<http://www.inbo.be>
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>
> [mailto:r-help-bounces at r-project.org<mailto:r-help-bounces at r-project.org>]
> Namens jpm miao
> Verzonden: dinsdag 21 oktober 2014 10:29
> Aan: r-help
> Onderwerp: [R] Dealing with NAs in lm or gmm
>
> Hi,
>
>    My question is about NAs in the function "gmm", but I believe that the
> same issues occur in the case of "lm".
>
>    I try to estimate a model by "gmm" function (GMM, generalized method of
> moments). Each of the  variables has 94 rows, but the resulting fitted
> model has only 89 rows. Then the function removes the rows with NAs.  I
> want to add a 94*1 vector, ONI, to the resulting fitted values; I want to
> find the fitted value with NAs kept. How can I do it? na.action?
>
>    Code:
>
>    > gmm8<-gmm(y~RDR1+xx, xiv)
> Warning message:
> In getDat(object$g, object$x) :
>   There are missing values. Associated observations have been removed
>
> > ONI.gmm8<-fitted(gmm8)+0.85*ONI
> Error in NextMethod(.Generic) :
>   dims [product 89] do not match the length of object [94] In addition:
> Warning message:
> In `+.default`(fitted(gmm8), 0.85 * ONI) :
>   longer object length is not a multiple of shorter object length
>
> Help on na.action:
> na.action
> a function which indicates what should happen when the data contain NAs.
> The default is set by the na.action setting of options, and is na.fail if
> that is unset. The ?factory-fresh? default is na.omit. Another possible
> value is NULL, no action. Value na.exclude can be useful.
>
> Thanks!
>
> Miao
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Tue Oct 21 15:19:44 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 21 Oct 2014 16:19:44 +0300
Subject: [R] undesirable output for lm( )
In-Reply-To: <4ED7E6D5-766D-48F1-B494-D8D492C298BE@gmail.com>
References: <24E59E774BB54C4D835922C8D6BA8093014B04CD55@POWINMSMBX01.pwiodc.lntinfotech.com>
	<4ED7E6D5-766D-48F1-B494-D8D492C298BE@gmail.com>
Message-ID: <CAGh51gRdSMrFM23VYf3rdLe3qcV1eFpct7Xwr--PAFUAAo00+A@mail.gmail.com>

Hi Swapnil,

Can you please explain your specific problem.  You said it is working well.
What is the desirable output? What is your output?
What do you want from it?

Cheers,
Fredo.

On Tue, Oct 21, 2014 at 3:07 PM, peter dalgaard <pdalgd at gmail.com> wrote:

> This is rubbish. We don't know what the output is nor what you perceive is
> wrong with it.
>
> And what is the business of cc-ing
>
> "respond-auto at linuxmafia.com" <respond-auto at linuxmafia.com>
> "esr at thyrsus.com" <esr at thyrsus.com>
>
> ?
>
> (The latter is Eric S. Raymond, who I strongly believe has no interest in
> your R problems.)
>
> This reeks of deliberate trouble-making. Unless you can come up with a
> credible explanation for this, I strongly suggest that you be barred from
> this mailing list.
>
> Peter Dalgaard
>
>
> On 21 Oct 2014, at 12:33 , Swapnil Khobragade <
> Swapnil.Khobragade at lntinfotech.com> wrote:
>
> > Hi,
> >
> > I have written this code and it is working fine
> >
> > Example 1:
> >
> >> fit <- lm(cpi ~ year + quarter)
> >> (cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011 +
> fit$coefficients[[3]]*(1:4))
> >
> >
> *****************************************************************************************
> > Example 2:
> >
> >> fit <- lm(cpi ~ year )
> >> (cpi2011 <- fit$coefficients[[1]] + fit$coefficients[[2]]*2011)
> >
> > I'm getting an undesirable output for this calculation.
> > Plz help in correcting the mistakes to get clear output.
> >
> >
> >
> > Regards,
> > Swapnil Khobragade
> > e-mail ID: swapnil.khobragade at lntinfotech.com<mailto:
> swapnil.khobragade at lntinfotech.com>
> > Tel: @@@@@@@(Direct) | +91 9503043368 (M)
> >
> >
> > ________________________________
> > The contents of this e-mail and any attachment(s) may contain
> confidential or privileged information for the intended recipient(s).
> Unintended recipients are prohibited from taking action on the basis of
> information in this e-mail and using or disseminating the information, and
> must notify the sender and delete it from their system. L&T Infotech will
> not accept responsibility or liability for the accuracy or completeness of,
> or the presence of any virus or disabling code in this e-mail"
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Frederic Ntirenganya
Maseno University,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Tue Oct 21 15:53:11 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 21 Oct 2014 09:53:11 -0400
Subject: [R] {car} outlierTest looses p/q values
In-Reply-To: <54460C6F.3010209@gmail.com>
References: <5440F52A.7050503@gmail.com>
	<web-531893112@cgpsrv2.cis.mcmaster.ca>
	<CAA4NQG8fL2xOy851Pg1TVLvaMFMLk-j31a1cFsQP2rdV+sWgww@mail.gmail.com>
	<web-531937413@cgpsrv2.cis.mcmaster.ca>
	<54460C6F.3010209@gmail.com>
Message-ID: <web-532350658@cgpsrv2.cis.mcmaster.ca>

Dear Phil,

I'll bypass questions about why one would want to do this, why you're using glm() rather than lm(), etc., and just point out that the *studentized* residual for the 11th observation is undefined for your example. Simplifying your code:

-------- snip -------

> y <- c(1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,13.98) 
> x1 <- c(4.6, 35.8, 4.1, 5.4, 5.2, 27.9, 48.2, 4.5, 5.7, 4.2, 100.5)
> x2 <- c(0.2990466, 1.0497156, 0.2805028, 0.3517993, 0.3543678, 1.0178604, 
+         0.4933182, 0.2810865, 0.4349550, 0.3269192, 3.0889747)

> mod.glm <- glm(y ~ x1 + x2)

> rstudent(mod.glm)
           1            2            3            4            5            6            7            8            9 
 0.459064418 -2.342404171  0.520003419  0.284592752  0.274181980 -2.283387024  1.236226216  0.521360367  0.007045656 
          10           11 
 0.359359609          NaN 

> residuals(mod.glm)
          1           2           3           4           5           6           7           8           9          10 
 0.66006969 -2.58163338  0.74389676  0.41298738  0.39764981 -2.53508626  0.31282392  0.74657662  0.01020209  0.51813375 
         11 
 1.31437963 

------------- snip ----------

Best,
 John

On Tue, 21 Oct 2014 09:34:07 +0200
 Phil <chobophil at gmail.com> wrote:
> Hi all,
> 
> as John pointed out, there is a way to create settings where the studentized residuals are undefined. However, after cross-checking it seems that the residuals are getting calculated without any error. The problem comes up when I use outlierTest to assign a p,q value,respectively.
> 
> Below is the code and some printouts:
> 
> 
> non.zero.orga.vector <- c(1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,1.00,13.98) #targervector
> 
> print(meta.Matrix[,3])
>   x1         x28          x2      x3      x4         x51     x52     x5 
>      x6      x7     x82
>       4.6     35.8      4.1      5.4      5.2     27.9 48.2      4.5    
> 5.7    4.2    100.5
> 
> print(meta.Matrix[,10])
>       x1                      x28               x2     x3
> 0.2990466     1.0497156     0.2805028 0.3517993
> 
>        x4          x51                x52                  x5
> 0.3543678 1.0178604 0.4933182 0.2810865
> 
>      x6                   x7              x82
> 0.4349550 0.3269192 3.0889747
> 
> glModel <- glm(non.zero.orga.vector ~ meta.Matrix[,3]+meta.Matrix[,10]) #create glm for testing
> 
> print(glModel$residuals) #check if residuals are calculated for every entry in the target vector
>    x1                   x28                x2                x3         
>      x4              x51           x52
>   0.6600696 -2.5816334  0.7438969  0.4129873  0.3976498 -2.5350861 
> 0.3128240
>         x5            x6                    x7           x82
>   0.7465766  0.0102020  0.5181337  1.3143796
> 
> 
> 
>   test.Res <- outlierTest(glModel,digits=4,cutoff=Inf,n.max=Inf) #test 
> the glm for outlier, cutoff=Inf/n.max=Inf == report everything
> 
> print(test.Res$bonf.p) #check if q-value exists
>       x28              x51              x52           x5     x2       
>          x1               x7           x3
> 0.1915995 0.2240759 2.1637438 6.0211575 6.0306110 6.4618792 7.1932613 7.7595619
>        x4               x6
> 7.8394477 9.9437848
> 
> 
> 
> As you see the glm calculates residuals for x82 (which is in fact 1.314) but the outlierTest does not assign a p/q value to it. Does anyone know why?
> 
> Thanks in advance,
> 
> Phil
> 
> On 10/17/2014 08:54 PM, John Fox wrote:
> > Dear Phil,
> >
> > Yes, that's a bit clearer. One can invent data configurations where certain studentized residuals are undefined. For example, try the following:
> >
> > y <- c(0, 0, 0, 0, 0, 1)
> > x <- 1:6
> > xx <- (1:6 - 3.5)^2
> > rstudent(lm(y ~ x))
> > rstudent(lm(y ~ xx))
> > plot(x, y)
> > plot(xx, y)
> >
> > The plots should clarify what's going on.
> >
> > I'm copying to r-help since the discussion began there.
> >
> > I hope this helps,
> >   John
> >
> > On Fri, 17 Oct 2014 18:35:59 +0200
> >   Philip Stevens <chobophil at gmail.com> wrote:
> >> Dear John,
> >>
> >> Thank you for your fast reply. Unfortunately I am out of office right now
> >> but I will get back to you on Monday asap with a toy example and some code.
> >> Meanwhile let me try to explain further.
> >>
> >> Basically not the glm but the outlierTest afterwards fails. And it only
> >> fails if all values, used to set up the glm, are exactly 1 except for one
> >> value which can be arbitrary large. I construct the glm from a vector of
> >> doubles (the target values) and a vector of other numeric values(metadata).
> >> (So this should be fit <- glm(targetVector ~ metadata) ) And want to check
> >> if one of those doubles(in the target vector) is an outlier using
> >> outlierTest(fit). The residuals are calculated by the glm but the
> >> outlierTest does not report a p nor a q value for the one value in the
> >> target vector which is not 1. And I can't figure out why...
> >>
> >> I hope this makes it a bit clearer.
> >> Anyways I will come back to you on Monday.
> >>
> >> Best,
> >>
> >> Phil
> >> Am 17.10.2014 17:43 schrieb "John Fox" <jfox at mcmaster.ca>:
> >>
> >>> Dear Phil,
> >>>
> >>> After reading your posting several times, I still don't understand what
> >>> you did. As usual, having a reproducible example illustrating the error
> >>> would be a great help. I do have a guess about the source of the error:
> >>> glm() failed in some way for the problematic case.
> >>>
> >>> Best,
> >>>   John
> >>>
> >>> ------------------------------------------------
> >>> John Fox, Professor
> >>> McMaster University
> >>> Hamilton, Ontario, Canada
> >>> http://socserv.mcmaster.ca/jfox/
> >>>
> >>>
> >>> On Fri, 17 Oct 2014 12:53:30 +0200
> >>>   Phil <chobophil at gmail.com> wrote:
> >>>> Hi guys,
> >>>>
> >>>> I came across a strange phenomena and can't figure out why it happens by
> >>> myself so here we go.
> >>>> I got a dataframe which consists of double numbers which I want to
> >>> check, row-wise if there are outliers in the rows.
> >>>> So I iterate over the rows and create a glm using the numbers of that
> >>> particular row. Which might look like this:
> >>>> case1)
> >>>>           x1        x2        x3        x4        x5        x6 x7
> >>>> x8        x9        x10        x11
> >>>>       0.00     3.91     0.00     0.00     0.00   68.03   40.39 0.00
> >>>> 0.00      0.00       4.11
> >>>>
> >>>> or like this:
> >>>> case2)
> >>>>           x1        x2        x3        x4        x5        x6 x7
> >>>> x8        x9        x10        x11
> >>>>        1.00     1.00    1.00     1.00     1.00     1.00     1.00 1.00
> >>>> 1.00     1.00      5.34
> >>>>
> >>>> or any other combination of double numbers...
> >>>>
> >>>> however, using a glm like this:
> >>>>
> >>>> glModel <- glm(vector ~ some_other_meta_data_which_is_double_numbers)
> >>>>
> >>>> and testing it with:
> >>>>
> >>>>    test.Res <- outlierTest(glModel,digits=4,cutoff=Inf,n.max=Inf)
> >>>>
> >>>> I always get a result consisting of the desired p and q values but not
> >>> if the vector I use looks like case2. There is no error message and the
> >>> computation does not stop either.
> >>>> However, all p and q values are produced except for the last value x11.
> >>>>
> >>>> Any idea why this particular value gets dropped from the output of the
> >>> outlierTest Method in the car package.
> >>>> Here is the sessioninfo:
> >>>>
> >>>>    sessionInfo()
> >>>> R version 3.1.1 (2014-07-10)
> >>>> Platform: x86_64-redhat-linux-gnu (64-bit)
> >>>>
> >>>> locale:
> >>>>    [1] LC_CTYPE=en_US.utf8       LC_NUMERIC=C
> >>>>    [3] LC_TIME=en_US.utf8        LC_COLLATE=en_US.utf8
> >>>>    [5] LC_MONETARY=en_US.utf8    LC_MESSAGES=en_US.utf8
> >>>>    [7] LC_PAPER=en_US.utf8       LC_NAME=C
> >>>>    [9] LC_ADDRESS=C              LC_TELEPHONE=C
> >>>> [11] LC_MEASUREMENT=en_US.utf8 LC_IDENTIFICATION=C
> >>>>
> >>>> attached base packages:
> >>>> [1] stats     graphics  grDevices utils     datasets  methods base
> >>>>
> >>>> other attached packages:
> >>>> [1] ggplot2_1.0.0      car_2.0-21         RColorBrewer_1.0-5 iNEXT_1.0
> >>>> [5] vegan_2.0-10       lattice_0.20-29    permute_0.8-3
> >>>>
> >>>> loaded via a namespace (and not attached):
> >>>>    [1] colorspace_1.2-4 compiler_3.1.1   digest_0.6.4 grid_3.1.1
> >>>>    [5] gtable_0.1.2     labeling_0.3     MASS_7.3-33 munsell_0.4.2
> >>>>    [9] nnet_7.3-8       plyr_1.8.1       proto_0.3-10 Rcpp_0.11.2
> >>>> [13] reshape2_1.4     scales_0.2.4     stringr_0.6.2    tools_3.1.1
> >>>>
> >>>> Any help is highly appreciated.
> >>>>
> >>>> Thanks
> >>>>
> >>>> Phil
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>>
> >>>
> >>>
> > ------------------------------------------------
> > John Fox, Professor
> > McMaster University
> > Hamilton, Ontario, Canada
> > http://socserv.mcmaster.ca/jfox/
> > 	
> > 	
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From dimitri.liakhovitski at gmail.com  Tue Oct 21 16:47:35 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 21 Oct 2014 10:47:35 -0400
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <5445FCA2.1000307@stats.ox.ac.uk>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>
	<5445FCA2.1000307@stats.ox.ac.uk>
Message-ID: <CAN2xGJbaiWJEL4jmtT64NVzs6d524zz3SQyYa772VxYF8ZsjKw@mail.gmail.com>

I will try with .wav files and report back.
So far, I am not sure I understood what could be done (if anything) to fix it...

On Tue, Oct 21, 2014 at 2:26 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 20/10/2014 17:53, John McKown wrote:
>>
>> On Mon, Oct 20, 2014 at 10:30 AM, Dimitri Liakhovitski <
>> dimitri.liakhovitski at gmail.com> wrote:
>>
>>> Dear Rers,
>>>
>>> I am trying to run a for-loop in R.
>>> During each iteration I read in an mp3 file and do some basic processing.
>>> If I do what I need to do for each file one by one - it works fine.
>>> But once I start running a loop, it soon runs out of memory and says:
>>> can't
>>> allocate a vector of size...
>>> In each iteration of my loop I always overwrite the previously created
>>> object and do gc().
>>>
>>> Any hints on how to fight this?
>>>
>>> Thanks a lot!
>>>
>>>
>>>
>> Please don't use HTML for messages.
>>
>> What occurs to me, from reading the other replies, is that perhaps within
>> the loop you are causing other objects to be allocated. And that can be
>> done just by doing a simple assignment, so it may not be obvious. What
>> this
>> can do is cause what we called a "sand bar" in the old days. That's where
>> you allocate a big chunk of memory for an object. Say this take up 1/2 of
>> your available space. You now create a small object. This object is
>> _probably_ right next to the large object. You now release the large
>> object. Your apparent free space is now almost what it was at the
>> beginning. But when you try to allocate another large object which is,
>> say,
>> 2/3 of the maximum space, you can't because that small object is sitting
>> right in the middle of our memory space. So you _can_ allocate 2 large
>> objects which are 1/3 your free space size, but not 1 object which is 2/3
>> of the free space size. Which can lead to your type of situation.
>>
>> This is just a SWAG based on some experience in other systems. Most
>> "garbage collection" do _not_ do memory consolidation. I don't know about
>> R.
>>
>>
> That is true of R (except for the early days which did have a moving garbage
> collector).
>
> However 'your available space' is not the amount of RAM you have but the
> process address space.  The latter is enormous on any 64-bit OS, so 'memory
> fragmentation' (as this is termed) is a thing of the past except for those
> limited to many-years-old OSes.
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From ripley at stats.ox.ac.uk  Tue Oct 21 16:51:12 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 21 Oct 2014 15:51:12 +0100
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <CAN2xGJbaiWJEL4jmtT64NVzs6d524zz3SQyYa772VxYF8ZsjKw@mail.gmail.com>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>	<CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>	<5445FCA2.1000307@stats.ox.ac.uk>
	<CAN2xGJbaiWJEL4jmtT64NVzs6d524zz3SQyYa772VxYF8ZsjKw@mail.gmail.com>
Message-ID: <544672E0.7080509@stats.ox.ac.uk>

On 21/10/2014 15:47, Dimitri Liakhovitski wrote:
> I will try with .wav files and report back.
> So far, I am not sure I understood what could be done (if anything) to fix it...

This is nothing to do with my reply!

The posting guide asked you to contact the tuneR maintainer *before 
posting*.  What did he say?

Bill Dunlap's reply pointed to a bug in tuneR (or a library it uses).

>
> On Tue, Oct 21, 2014 at 2:26 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On 20/10/2014 17:53, John McKown wrote:
>>>
>>> On Mon, Oct 20, 2014 at 10:30 AM, Dimitri Liakhovitski <
>>> dimitri.liakhovitski at gmail.com> wrote:
>>>
>>>> Dear Rers,
>>>>
>>>> I am trying to run a for-loop in R.
>>>> During each iteration I read in an mp3 file and do some basic processing.
>>>> If I do what I need to do for each file one by one - it works fine.
>>>> But once I start running a loop, it soon runs out of memory and says:
>>>> can't
>>>> allocate a vector of size...
>>>> In each iteration of my loop I always overwrite the previously created
>>>> object and do gc().
>>>>
>>>> Any hints on how to fight this?
>>>>
>>>> Thanks a lot!
>>>>
>>>>
>>>>
>>> Please don't use HTML for messages.
>>>
>>> What occurs to me, from reading the other replies, is that perhaps within
>>> the loop you are causing other objects to be allocated. And that can be
>>> done just by doing a simple assignment, so it may not be obvious. What
>>> this
>>> can do is cause what we called a "sand bar" in the old days. That's where
>>> you allocate a big chunk of memory for an object. Say this take up 1/2 of
>>> your available space. You now create a small object. This object is
>>> _probably_ right next to the large object. You now release the large
>>> object. Your apparent free space is now almost what it was at the
>>> beginning. But when you try to allocate another large object which is,
>>> say,
>>> 2/3 of the maximum space, you can't because that small object is sitting
>>> right in the middle of our memory space. So you _can_ allocate 2 large
>>> objects which are 1/3 your free space size, but not 1 object which is 2/3
>>> of the free space size. Which can lead to your type of situation.
>>>
>>> This is just a SWAG based on some experience in other systems. Most
>>> "garbage collection" do _not_ do memory consolidation. I don't know about
>>> R.
>>>
>>>
>> That is true of R (except for the early days which did have a moving garbage
>> collector).
>>
>> However 'your available space' is not the amount of RAM you have but the
>> process address space.  The latter is enormous on any 64-bit OS, so 'memory
>> fragmentation' (as this is termed) is a thing of the past except for those
>> limited to many-years-old OSes.
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From wdunlap at tibco.com  Tue Oct 21 19:00:22 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 21 Oct 2014 10:00:22 -0700
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <544672E0.7080509@stats.ox.ac.uk>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>
	<5445FCA2.1000307@stats.ox.ac.uk>
	<CAN2xGJbaiWJEL4jmtT64NVzs6d524zz3SQyYa772VxYF8ZsjKw@mail.gmail.com>
	<544672E0.7080509@stats.ox.ac.uk>
Message-ID: <CAF8bMcYG8a7RBLZTWZ9jGiOBhvy96LZzbHk357Su8vHZ95Q4Dg@mail.gmail.com>

A few minutes with valgrind showed that output_pos was never
initialized, so the output array was not getting filled correctly.
The following fixes that problem

diff -ru tuneR/src/readmp3.c /homes/bill/packages/tuneR/src/readmp3.c
--- tuneR/src/readmp3.c 2014-04-07 04:38:21.000000000 -0700
+++ /homes/bill/packages/tuneR/src/readmp3.c    2014-10-21
09:54:19.351867000 -0700
@@ -96,6 +96,7 @@
   state.input = blob;
   state.input_size = n_blob;
   state.output_size = 0;
+  state.output_pos = 0;
   mad_decoder_init(&decoder, &state,
            mad_input_cb, mad_header_cb, NULL,
            NULL, NULL, NULL);

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Tue, Oct 21, 2014 at 7:51 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 21/10/2014 15:47, Dimitri Liakhovitski wrote:
>>
>> I will try with .wav files and report back.
>> So far, I am not sure I understood what could be done (if anything) to fix
>> it...
>
>
> This is nothing to do with my reply!
>
> The posting guide asked you to contact the tuneR maintainer *before
> posting*.  What did he say?
>
> Bill Dunlap's reply pointed to a bug in tuneR (or a library it uses).
>
>
>>
>> On Tue, Oct 21, 2014 at 2:26 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> wrote:
>>>
>>> On 20/10/2014 17:53, John McKown wrote:
>>>>
>>>>
>>>> On Mon, Oct 20, 2014 at 10:30 AM, Dimitri Liakhovitski <
>>>> dimitri.liakhovitski at gmail.com> wrote:
>>>>
>>>>> Dear Rers,
>>>>>
>>>>> I am trying to run a for-loop in R.
>>>>> During each iteration I read in an mp3 file and do some basic
>>>>> processing.
>>>>> If I do what I need to do for each file one by one - it works fine.
>>>>> But once I start running a loop, it soon runs out of memory and says:
>>>>> can't
>>>>> allocate a vector of size...
>>>>> In each iteration of my loop I always overwrite the previously created
>>>>> object and do gc().
>>>>>
>>>>> Any hints on how to fight this?
>>>>>
>>>>> Thanks a lot!
>>>>>
>>>>>
>>>>>
>>>> Please don't use HTML for messages.
>>>>
>>>> What occurs to me, from reading the other replies, is that perhaps
>>>> within
>>>> the loop you are causing other objects to be allocated. And that can be
>>>> done just by doing a simple assignment, so it may not be obvious. What
>>>> this
>>>> can do is cause what we called a "sand bar" in the old days. That's
>>>> where
>>>> you allocate a big chunk of memory for an object. Say this take up 1/2
>>>> of
>>>> your available space. You now create a small object. This object is
>>>> _probably_ right next to the large object. You now release the large
>>>> object. Your apparent free space is now almost what it was at the
>>>> beginning. But when you try to allocate another large object which is,
>>>> say,
>>>> 2/3 of the maximum space, you can't because that small object is sitting
>>>> right in the middle of our memory space. So you _can_ allocate 2 large
>>>> objects which are 1/3 your free space size, but not 1 object which is
>>>> 2/3
>>>> of the free space size. Which can lead to your type of situation.
>>>>
>>>> This is just a SWAG based on some experience in other systems. Most
>>>> "garbage collection" do _not_ do memory consolidation. I don't know
>>>> about
>>>> R.
>>>>
>>>>
>>> That is true of R (except for the early days which did have a moving
>>> garbage
>>> collector).
>>>
>>> However 'your available space' is not the amount of RAM you have but the
>>> process address space.  The latter is enormous on any 64-bit OS, so
>>> 'memory
>>> fragmentation' (as this is termed) is a thing of the past except for
>>> those
>>> limited to many-years-old OSes.
>>>
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Emeritus Professor of Applied Statistics, University of Oxford
>>> 1 South Parks Road, Oxford OX1 3TG, UK
>
>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ligges at statistik.tu-dortmund.de  Tue Oct 21 20:29:02 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 21 Oct 2014 20:29:02 +0200
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <CAF8bMcYG8a7RBLZTWZ9jGiOBhvy96LZzbHk357Su8vHZ95Q4Dg@mail.gmail.com>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>
	<5445FCA2.1000307@stats.ox.ac.uk>
	<CAN2xGJbaiWJEL4jmtT64NVzs6d524zz3SQyYa772VxYF8ZsjKw@mail.gmail.com>
	<544672E0.7080509@stats.ox.ac.uk>
	<CAF8bMcYG8a7RBLZTWZ9jGiOBhvy96LZzbHk357Su8vHZ95Q4Dg@mail.gmail.com>
Message-ID: <5446A5EE.6060709@statistik.tu-dortmund.de>



On 21.10.2014 19:00, William Dunlap wrote:
> A few minutes with valgrind showed that output_pos was never
> initialized, so the output array was not getting filled correctly.
> The following fixes that problem
>
> diff -ru tuneR/src/readmp3.c /homes/bill/packages/tuneR/src/readmp3.c
> --- tuneR/src/readmp3.c 2014-04-07 04:38:21.000000000 -0700
> +++ /homes/bill/packages/tuneR/src/readmp3.c    2014-10-21
> 09:54:19.351867000 -0700
> @@ -96,6 +96,7 @@
>     state.input = blob;
>     state.input_size = n_blob;
>     state.output_size = 0;
> +  state.output_pos = 0;
>     mad_decoder_init(&decoder, &state,
>              mad_input_cb, mad_header_cb, NULL,
>              NULL, NULL, NULL);


Thanks, Bill!
I haven't found the time to look at it.
Now in the master sources, bugfix release will follow shortly,
Uwe


> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Tue, Oct 21, 2014 at 7:51 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On 21/10/2014 15:47, Dimitri Liakhovitski wrote:
>>>
>>> I will try with .wav files and report back.
>>> So far, I am not sure I understood what could be done (if anything) to fix
>>> it...
>>
>>
>> This is nothing to do with my reply!
>>
>> The posting guide asked you to contact the tuneR maintainer *before
>> posting*.  What did he say?
>>
>> Bill Dunlap's reply pointed to a bug in tuneR (or a library it uses).
>>
>>
>>>
>>> On Tue, Oct 21, 2014 at 2:26 AM, Prof Brian Ripley
>>> <ripley at stats.ox.ac.uk> wrote:
>>>>
>>>> On 20/10/2014 17:53, John McKown wrote:
>>>>>
>>>>>
>>>>> On Mon, Oct 20, 2014 at 10:30 AM, Dimitri Liakhovitski <
>>>>> dimitri.liakhovitski at gmail.com> wrote:
>>>>>
>>>>>> Dear Rers,
>>>>>>
>>>>>> I am trying to run a for-loop in R.
>>>>>> During each iteration I read in an mp3 file and do some basic
>>>>>> processing.
>>>>>> If I do what I need to do for each file one by one - it works fine.
>>>>>> But once I start running a loop, it soon runs out of memory and says:
>>>>>> can't
>>>>>> allocate a vector of size...
>>>>>> In each iteration of my loop I always overwrite the previously created
>>>>>> object and do gc().
>>>>>>
>>>>>> Any hints on how to fight this?
>>>>>>
>>>>>> Thanks a lot!
>>>>>>
>>>>>>
>>>>>>
>>>>> Please don't use HTML for messages.
>>>>>
>>>>> What occurs to me, from reading the other replies, is that perhaps
>>>>> within
>>>>> the loop you are causing other objects to be allocated. And that can be
>>>>> done just by doing a simple assignment, so it may not be obvious. What
>>>>> this
>>>>> can do is cause what we called a "sand bar" in the old days. That's
>>>>> where
>>>>> you allocate a big chunk of memory for an object. Say this take up 1/2
>>>>> of
>>>>> your available space. You now create a small object. This object is
>>>>> _probably_ right next to the large object. You now release the large
>>>>> object. Your apparent free space is now almost what it was at the
>>>>> beginning. But when you try to allocate another large object which is,
>>>>> say,
>>>>> 2/3 of the maximum space, you can't because that small object is sitting
>>>>> right in the middle of our memory space. So you _can_ allocate 2 large
>>>>> objects which are 1/3 your free space size, but not 1 object which is
>>>>> 2/3
>>>>> of the free space size. Which can lead to your type of situation.
>>>>>
>>>>> This is just a SWAG based on some experience in other systems. Most
>>>>> "garbage collection" do _not_ do memory consolidation. I don't know
>>>>> about
>>>>> R.
>>>>>
>>>>>
>>>> That is true of R (except for the early days which did have a moving
>>>> garbage
>>>> collector).
>>>>
>>>> However 'your available space' is not the amount of RAM you have but the
>>>> process address space.  The latter is enormous on any 64-bit OS, so
>>>> 'memory
>>>> fragmentation' (as this is termed) is a thing of the past except for
>>>> those
>>>> limited to many-years-old OSes.
>>>>
>>>>
>>>> --
>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>> Emeritus Professor of Applied Statistics, University of Oxford
>>>> 1 South Parks Road, Oxford OX1 3TG, UK
>>
>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Emeritus Professor of Applied Statistics, University of Oxford
>> 1 South Parks Road, Oxford OX1 3TG, UK
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From Stephanie.Clerc at sanofi.com  Tue Oct 21 14:24:36 2014
From: Stephanie.Clerc at sanofi.com (Stephanie.Clerc at sanofi.com)
Date: Tue, 21 Oct 2014 12:24:36 +0000
Subject: [R] MMSB
Message-ID: <D11F74152DFEF44C86F20F3F9201686E66E0D930@XSPW10A407K.pharma.aventis.com>

Hi,

I am trying to fit a mixed-membership stochastic blockmodel using mmsb.collapsed.gibbs.sampler. I get an error message: "Error in rep(list(matrix(integer(0), nrow = 2, ncol = 0)), dim(network)[1]) :   invalid 'times' argument". Could you explain what is the problem exactly?
I am working on the famous Zachary Karate Club data and have submitted the following code, where ZKCnet was created as an undirected network:
mmsb.collapsed.gibbs.sampler(network=ZKCnet,K=2,num.iterations=50, alpha=1/2,beta.prior=list(matrix(1,2,2),matrix(1,2,2)))

Thank you very much for your help,
Best regards,

St?phanie CLERC, senior biostatistician
Sanofi-aventis R&D - Biostatistics and Programming
Tel : +33 1 60 49 43 37


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Oct 21 22:23:33 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 21 Oct 2014 13:23:33 -0700
Subject: [R] pasteFromExcel
In-Reply-To: <CAHgH9_H-5a0HMYMSYCX+8MfkyeBzZzVUyYpe4x92bbPM5onR9g@mail.gmail.com>
References: <CAHgH9_F7dLVGULxfok1f3xLjZTT3WX8UPnOohmXWj-28nj7cwA@mail.gmail.com>
	<6771D3CB-B8B2-43B6-9F65-6C113DCABDE3@comcast.net>
	<CAHgH9_EGpxS2CGZmNRWrYyqrq-fTAZGhRADAD1+66razu0FuyA@mail.gmail.com>
	<0547CC1D-B0DF-459F-B92C-1F2374EB43BE@comcast.net>
	<CAHgH9_G7cxCpxi1_vRj_b3mXi6nNmFGhgX3j-=WAdEYuQ7ng3Q@mail.gmail.com>
	<1111627E-C50F-487F-96A0-91324B4F7AF7@comcast.net>
	<CAHgH9_H-5a0HMYMSYCX+8MfkyeBzZzVUyYpe4x92bbPM5onR9g@mail.gmail.com>
Message-ID: <1C700FE7-51A7-4C2D-8A75-139225AA05EA@comcast.net>

To the List;

I replied privately with a screenshot and an .xlsx worked example since it seemed the major issue was how Excel handled currency formatting for character strings created n R, ... not really an on-topic subject matter for this list. I know Dan also reads the R-SIG-Insurance list and it may be more on-topic over there.

-- 
David.

On Oct 21, 2014, at 6:03 AM, Dan Murphy wrote:

> Sure, that is one pattern to try to detect, but there are many more
> (e.g., cannot have multiple '$' or '?'). For speed, I'm looking for a
> *single* expression to detect valid currency strings in one grep.
> 
> The one shown for US works. For euros, it might suffice to replace '$'
> with '?' but I cannot test that in my location. Can you? I.e.,
> 
> Change currencypattern to
> 
> currencypattern <-
>  "^\\??\\-?([1-9]{1}[0-9]{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))?|^\\-?\\??([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))?|^\\??\\(([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))\\)?"
> 
> Does Excel display euro values per the format within this test vector?
> 
> x <- c("1,234.00", "12,34.00", "?1,000", "(124)", "$(123)", "(?123)",
> "  1,000   ", "NA")
> 
> and does grep yield the correct answer? It should, but better to test
> it than assume.
> 
> grep(currencypattern, trim(x))
> [1] 1 3 4 5 7  # correct answer
> 
> I suppose my biggest holdup is knowing how Excel formats currencies in
> other denominations. Maybe there's a way for me to test euro,
> sterling, etc. in my location, but I haven't discovered it yet. :(
> 
> Again, thanks for your help.
> 
> -Dan
> 
> On Mon, Oct 20, 2014 at 3:39 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Oct 20, 2014, at 2:34 PM, Dan Murphy wrote:
>> 
>>> Good ideas, David.
>>> 
>>> 1) By "confirm that MS Excel honors that OutDec" I mean that, in a
>>> location (France? others?) where options("OutDec") is a comma, does MS
>>> Excel format numbers that way when displaying currencies with decimal
>>> places? I have no way of knowing if that is true in all OutDec = ","
>>> locales.
>>> 
>>> 2) I wish it were as simple as just removing unwanted "adornments."
>>> The issue is that such "adornments" must be in their proper places for
>>> the character string to represent a currency value, or a numeric value
>>> for that matter. If I add one more comma to your first element in the
>>> wrong place, it should not translate to a valid numeric, but it does
>>> with your gsub, which would be a bug if that were in pasteFromExcel:
>>>> gsub(rmchar, "", c("$1,0,00", "1,200", "800"))
>>> [1] "1000" "1200" "800"
>> 
>> If you wanted to restrict the substitutions to only the commas that were succeeded by three digits then this succeeds:
>> 
>> gsub("(\\,)(\\d{3,3})", "\\2", c("1,000,000,000.00") )
>> [1] "1000000000.00"
>> 
>> You should also take a look at formatC which has provisions for output using commas.
>> 
>> -
>> david.
>> 
>> 
>>> 
>>> When I originally looked into this I believed I couldn't be the first
>>> one asking that question .. and I wasn't. There are many hits for
>>> regular expressions that purport to successfully identify well-formed
>>> *US dollar* currency strings. The expression in pasteFromExcel is
>>> based on http://stackoverflow.com/questions/354044/what-is-the-best-u-s-currency-regex.
>>> 
>>> I'm curious if anyone has come across -- and tested -- a similar
>>> regular expression in other places that might have use for
>>> pasteFromExcel.
>>> 
>>> This is how pasteFromExcel uses its currency regular expression (the
>>> first ugly assignment is what I'm looking for in other locales around
>>> the world -- maybe there's a Regular Expression mailing list out
>>> there):
>>> 
>>> currencypattern <-
>>> "^\\$?\\-?([1-9]{1}[0-9]{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\-?\\$?([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))$|^\\$?\\(([1-9]{1}\\d{0,2}(\\,\\d{3})*(\\.\\d{0,2})?|[1-9]{1}\\d{0,}(\\.\\d{0,2})?|0(\\.\\d{0,2})?|(\\.\\d{1,2}))\\)$"
>>> 
>>> # Here's a test vector
>>> x <- c("1,234.00", "12,34.00", "$1,000", "(124)", "$(123)", "($123)",
>>> "  1,000   ", "NA")
>>> 
>>> # grep will tell you whether elements of x, trimmed of
>>> beginning/ending whitespace, match the currencypattern
>>> grep(currencypattern, trim(x))
>>> [1] 1 3 4 5 7  # correct answer
>>> 
>>> *Now* one may remove unwanted characters from the well-formed strings.
>>> And deal with the "negatives" of course .. and NAs. See how that's
>>> done in excelRio.r in the excelRio package on github:
>>> https://github.com/trinostics/excelRio
>>> 
>>> Thanks for your interest.
>>> 
>>> 
>>> On Mon, Oct 20, 2014 at 10:56 AM, David Winsemius
>>> <dwinsemius at comcast.net> wrote:
>>>> 
>>>> On Oct 20, 2014, at 10:29 AM, Dan Murphy wrote:
>>>> 
>>>>> Nice.
>>>>> So if someone were to offer a currency regular expression that works
>>>>> in their locale, I should also ask them to give me the results of
>>>>> Sys.getlocale("LC_MONETARY")
>>>>> and
>>>>> options("OutDec")
>>>>> and confirm that MS Excel honors that OutDec.
>>>> 
>>>> I'm not sure we can know what you mean by "confirm that MS Excel honors that OutDec." The result of options("OutDec") was intended for you to determine what character not to remove from a monetary value in an R workspace. If the assumption is that all values will be in the same unit and that the user is not doing any currency conversions then:
>>>> 
>>>>> decsep <- options("OutDec")
>>>>> rmchar <- paste0( "[$??", c(".", ",")[!c(".", ",") %in% decsep], "]" )
>>>>> gsub(rmchar, "", c("$1,000", "1,200", "800"))
>>>> [1] "1000" "1200" "800"
>>>> 
>>>> 
>>>>> Thank you, David.
>>>>> -Dan
>>>>> 
>>>>> On Mon, Oct 20, 2014 at 10:04 AM, David Winsemius
>>>>> <dwinsemius at comcast.net> wrote:
>>>>>> 
>>>>>> On Oct 19, 2014, at 11:18 PM, Dan Murphy wrote:
>>>>>> 
>>>>>>> To Users of Excel:
>>>>>>> 
>>>>>>> Following advice from Brian and Markus, I created an RMarkdown "vignette"
>>>>>>> that shows an example of how the pasteFromExcel function in the excelRio
>>>>>>> package on github could be used by an actuary to transfer a triangle from
>>>>>>> Excel to R. See today's post at http://trinostics.blogspot.com/
>>>>>>> 
>>>>>>> Unfortunately, if you are located outside the US, the demonstrated
>>>>>>> functionality will not work for you because the currency regex implemented
>>>>>>> assumes the dollar sign ($) and comma/decimal punctuation of the form
>>>>>>> 999,999.00.
>>>>>>> 
>>>>>>> If anyone is interested in contributing currency regex expressions that
>>>>>>> work in your locale, I would be happy to try to incorporate them in the
>>>>>>> package. If anyone knows how best to determine the user's locale (might
>>>>>>> "timezone" suffice?), I'd appreciate that help too.
>>>>>>> 
>>>>>> 
>>>>>> ?Sys.getlocale   # perhaps "LC_MONETARY"
>>>>>> 
>>>>>> ?options   # look for OutDec
>>>>>> 
>>>>>> 
>>>>>>>    [[alternative HTML version deleted]]
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> David Winsemius
>>>>>> Alameda, CA, USA
>>>>>> 
>>>> 
>>>> David Winsemius
>>>> Alameda, CA, USA
>>>> 
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From ajss_alt at yahoo.com  Tue Oct 21 21:35:24 2014
From: ajss_alt at yahoo.com (Amarjit Singh)
Date: Tue, 21 Oct 2014 19:35:24 +0000 (UTC)
Subject: [R] R-code for carrying out step-wise panel regression
Message-ID: <222202178.298383.1413920124369.JavaMail.yahoo@jws10963.mail.sg3.yahoo.com>

Dear all
For one of my empirical research investigation, ?I tried to carry out step-wise panel regression analysis by making adaptation in the use of plm package (since stepAIC command does not work with plm). Say, I tried to regress an explained variable (DEP) on 3 explanatory variables (EX1, EX2, EX3) using a panel data set (dat). Of course, the required set of instructions would be:require(plm)reg <- plm(DEP ~ EX1 + EX2 + EX3, data = dat, method = "within") ? ? ? ? ? ? ... (A)But, what I wish to do (for the purpose of carrying out the analysis iteratively) is as follows:dep <- "DEP"exp <- c("EX1", "EX2", "EX3")and then use somehow these dep and exp to get a ?statement compatible with (A). I tried the following
frm <- as.formula(paste(dep, "~", exp))reg <- plm(frm, data = dat, method = "within)But it did not work properly. I could get the output only in respect of DEP ~ EX1, whereas I need the same in respect of DEP ~ EX1 + EX2 + EX3.Kindly help. ?Or, you may pl. suggest some alternative via media.RegardsAmarjit Singh

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Tue Oct 21 23:03:20 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 21 Oct 2014 16:03:20 -0500
Subject: [R] "source" command inside R package scripts
In-Reply-To: <CAFvnaTatUefWn-E2NbnjtCT9J64Ho5UOrPdbA_5JHsG+njjJXA@mail.gmail.com>
References: <CAFvnaTatUefWn-E2NbnjtCT9J64Ho5UOrPdbA_5JHsG+njjJXA@mail.gmail.com>
Message-ID: <CABdHhvGpH1YseUVd3aac+_CKtU_y1VUke2jFfbOxvTN9Mr-Q+g@mail.gmail.com>

Your source function will be called when the package is _built_, not
when it's loaded/attached. There's almost certainly a better way to
solve your problem than using source() inside a package

Hadley

On Tue, Oct 21, 2014 at 6:24 AM, Enrico Bibbona <enrico.bibbona at unito.it> wrote:
> I have built a new package. I would like to put an R script (let us call it
> "script.R) into a subdirectory of the /pkg/R/ directory, called /pkg/R/sub/
> and I would like that such code is run when the package is installed.
>
> My way of doing so was to put an R script into /pkg/R/ with source command
> like
>
> source("./R/sub/script.R")
>
> that does not give me any error, but I know that the script (which
> actuallly defines a few functions is not run. What is wrong? What can I do
> better?
> Thanks, Enrico
>
> --
> Enrico Bibbona
> Dipartimento di Matematica
> Universit? di Torino
> https://sites.google.com/site/enricobibbona/
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From zadig_1 at excite.com  Wed Oct 22 04:02:57 2014
From: zadig_1 at excite.com (ce)
Date: Tue, 21 Oct 2014 22:02:57 -0400
Subject: [R] Socket question about isIncomplete and isOpen
Message-ID: <20141021220257.16555@web003.roc2.bluetie.com>


I am trying to repeat socket example in ?socketConnection 

Server process :

con1 <- socketConnection(port = 6011, server = TRUE)
while(TRUE) { writeLines("aaaaa",con1 );  Sys.sleep(1) }

Client process

con2 <- socketConnection(Sys.info()["nodename"], port = 6011)
readLines(con2, n = 1 )
while(isIncomplete(con2)) 
{
        msg <- readLines(con2, n = 1 )
        if(!(is.character(msg) && length(msg) == 0)) { cat("msg = "); print(msg) }

}

I have two problems 

1- client side isIncomplete(con2) is always return FALSE and while loop ends 

2- client while loop works if I use isOpen(con2) but  if server dies  client loop doesn't exit ?


From moonkid at posteo.org  Wed Oct 22 02:45:33 2014
From: moonkid at posteo.org (moonkid at posteo.org)
Date: Wed, 22 Oct 2014 02:45:33 +0200
Subject: [R] =?utf-8?q?=5BSweave=5D_doesn=27t_accept_unicode=3F?=
Message-ID: <49891056c4600a8052e765867b7f9c3c@posteo.de>

Of course I manage and write my tex-files in unicode (utf-8) (running 
XeTeX). That is why my R-output need to be in unicode, too.

But Sweave doesn't accept unicode files.

[R]
> Sweave("analy.Snw")
Fehler: ?analy.Snw? is not ASCII and does not declare an encoding
[/R]

[analy.Snw]
<<>>=
x <- ?

table(x)
@
[/analy.Snw]

How should I "declare an encoding". I can not find an option for the 
<<>>.

I don't have to declare any of my tex-files explicite because XeTeX use 
the files like they come. It knows for itself the encoding.


From yihsuc at gmail.com  Wed Oct 22 02:32:25 2014
From: yihsuc at gmail.com (YIHSU CHEN)
Date: Tue, 21 Oct 2014 17:32:25 -0700
Subject: [R] add text to the first line of an output file
Message-ID: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>

Hi guys;

I want to write some text at the first line of an output file.  The output
file will be used for other software.  In particular, the following text
"ampl.tab 2 1" needs to be added to the first line of an  df output file.
As a hypothetic example, the output in text file should be like:

ampl.tab 2 1
A  B
2   3
4   6
2   0

Thanks for help.

Yihsu

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Wed Oct 22 05:58:34 2014
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 22 Oct 2014 05:58:34 +0200
Subject: [R] [Sweave] doesn't accept unicode?
In-Reply-To: <49891056c4600a8052e765867b7f9c3c@posteo.de>
References: <49891056c4600a8052e765867b7f9c3c@posteo.de>
Message-ID: <54472B6A.7060705@yahoo.fr>

Look at here for an example using an encoding in knitr:
http://max2.ese.u-psud.fr/epc/conservation/Girondot/Publications/Blog_r/Entrees/2014/9/4_symbol_in_knitr.html

Sincerely

Marc

Le 22/10/2014 02:45, moonkid at posteo.org a ?crit :
> Of course I manage and write my tex-files in unicode (utf-8) (running
> XeTeX). That is why my R-output need to be in unicode, too.
>
> But Sweave doesn't accept unicode files.
>
> [R]
>> Sweave("analy.Snw")
> Fehler: ?analy.Snw? is not ASCII and does not declare an encoding
> [/R]
>
> [analy.Snw]
> <<>>=
> x <- ?
>
> table(x)
> @
> [/analy.Snw]
>
> How should I "declare an encoding". I can not find an option for the <<>>.
>
> I don't have to declare any of my tex-files explicite because XeTeX use
> the files like they come. It knows for itself the encoding.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From xie at yihui.name  Wed Oct 22 06:35:25 2014
From: xie at yihui.name (Yihui Xie)
Date: Tue, 21 Oct 2014 23:35:25 -0500
Subject: [R] [Sweave] doesn't accept unicode?
In-Reply-To: <54472B6A.7060705@yahoo.fr>
References: <49891056c4600a8052e765867b7f9c3c@posteo.de>
	<54472B6A.7060705@yahoo.fr>
Message-ID: <CANROs4d5Av4JOCt+51gvzigzqUwoKJyG7z=0w0S5MGikcfHDMg@mail.gmail.com>

That blog post is not entirely correct about UTF-8: if you use
pdflatex, you have to declare the font encoding
\usepackage[T1]{fontenc} when you save the document with UTF-8, e.g.
the following minimal example should work with pdflatex + knitr in
RStudio with UTF-8:

\documentclass{article}
\usepackage[T1]{fontenc}
\usepackage[utf8]{inputenc}
\begin{document}
<<>>=
degree <- "?"
print(degree)
@
\end{document}

For XeTeX, you will have to use different packages, fontspec and
xunicode. Here is a minimal example for XeTeX:

\documentclass{article}
\usepackage{fontspec}
\usepackage{xunicode}
\begin{document}
<<>>=
degree <- "?"
print(degree)
@
\end{document}

Similar things apply to ?. You need to specify the argument `encoding
= 'UTF-8'` when calling Sweave() or knitr::knit().

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Tue, Oct 21, 2014 at 10:58 PM, Marc Girondot <marc_grt at yahoo.fr> wrote:
> Look at here for an example using an encoding in knitr:
> http://max2.ese.u-psud.fr/epc/conservation/Girondot/Publications/Blog_r/Entrees/2014/9/4_symbol_in_knitr.html
>
> Sincerely
>
> Marc
>
> Le 22/10/2014 02:45, moonkid at posteo.org a ?crit :
>
>> Of course I manage and write my tex-files in unicode (utf-8) (running
>> XeTeX). That is why my R-output need to be in unicode, too.
>>
>> But Sweave doesn't accept unicode files.
>>
>> [R]
>>>
>>> Sweave("analy.Snw")
>>
>> Fehler: ?analy.Snw? is not ASCII and does not declare an encoding
>> [/R]
>>
>> [analy.Snw]
>> <<>>=
>> x <- ?
>>
>> table(x)
>> @
>> [/analy.Snw]
>>
>> How should I "declare an encoding". I can not find an option for the <<>>.
>>
>> I don't have to declare any of my tex-files explicite because XeTeX use
>> the files like they come. It knows for itself the encoding.


From sven.templer at gmail.com  Wed Oct 22 09:32:24 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 22 Oct 2014 09:32:24 +0200
Subject: [R] add text to the first line of an output file
In-Reply-To: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>
References: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>
Message-ID: <CAHuTOvpYQ7a73+BhyAQLziJwXUncyPX0wjycu_QHSpoR_FWx5w@mail.gmail.com>

Hi.

You can't.

But using a second file where you first write your header and then
append the original file is a solution. ?cat and ?write.table with a
focus on the 'append' argument should help. you can then use ?unlink
to delete the original file and ?file.rename to rename the second, if
desired.

Best, Sven.

On 22 October 2014 02:32, YIHSU CHEN <yihsuc at gmail.com> wrote:
> Hi guys;
>
> I want to write some text at the first line of an output file.  The output
> file will be used for other software.  In particular, the following text
> "ampl.tab 2 1" needs to be added to the first line of an  df output file.
> As a hypothetic example, the output in text file should be like:
>
> ampl.tab 2 1
> A  B
> 2   3
> 4   6
> 2   0
>
> Thanks for help.
>
> Yihsu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tcmuigai at gmail.com  Wed Oct 22 11:02:01 2014
From: tcmuigai at gmail.com (Charles Thuo)
Date: Wed, 22 Oct 2014 12:02:01 +0300
Subject: [R] running the aggregate claims distribution using the package
	"actuar"
Message-ID: <CAAJc=rN=o44HNkVtmuhmKE-wU4AN7ZhQpKawe0eMBy774zJKJA@mail.gmail.com>

# i  run the following after fitting claims data into the negative binomial
as the frequency  distribution and the lognormal for the severity
distribution using the package "fitdistrplus".

require(actuar)


fx<- discretize(plnorm(x,11.69,0.79331),method="unbiased",step=500,from=0,


        to=qlnorm(1-1E-6,11.69,0.79331),lev=levlnorm(x,11.69,0.79331))



 pb<- 2.6/18.6


 pn<- dnbinom(0:qnbinom(1-1E-6,size=2.6,prob=pb),size=2.6,prob=pb)



 Fs<-
aggregateDist("convolution",model.sev=fx,model.freq=pn,x.scale=1,tol=1E-6)


# The Fs function stalls and does not produce and output. Can anyoen advise
why this is the case?

# On the other hand does the convolution method require iterations.

# In case the function Fs run successfully how are the parameters of the Fs
distribution extracted. How would the same parameters be related to an
existing portfolio of outstanding claims.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Oct 22 11:04:11 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 22 Oct 2014 10:04:11 +0100
Subject: [R] add text to the first line of an output file
In-Reply-To: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>
References: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>
Message-ID: <5447730B.4030902@sapo.pt>

Hello,

Just use ?cat and ?write.table with append = TRUE. Something like the 
following.

txt <- "ampl.tab 2 1"
dat <- read.table(text = "
A  B
2   3
4   6
2   0
", header = TRUE)

tmp <- "tmp.txt"
cat(txt, "\n", file = tmp) " Don't forget the newline "\n"
write.table(dat, file = tmp, append = TRUE, row.names = FALSE)
#unlink(tmp)  # Clean up


Hope this helps,

Rui Barradas

Em 22-10-2014 01:32, YIHSU CHEN escreveu:
> Hi guys;
>
> I want to write some text at the first line of an output file.  The output
> file will be used for other software.  In particular, the following text
> "ampl.tab 2 1" needs to be added to the first line of an  df output file.
> As a hypothetic example, the output in text file should be like:
>
> ampl.tab 2 1
> A  B
> 2   3
> 4   6
> 2   0
>
> Thanks for help.
>
> Yihsu
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From hb at biostat.ucsf.edu  Wed Oct 22 11:04:19 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 22 Oct 2014 02:04:19 -0700
Subject: [R] add text to the first line of an output file
In-Reply-To: <CAHuTOvpYQ7a73+BhyAQLziJwXUncyPX0wjycu_QHSpoR_FWx5w@mail.gmail.com>
References: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>
	<CAHuTOvpYQ7a73+BhyAQLziJwXUncyPX0wjycu_QHSpoR_FWx5w@mail.gmail.com>
Message-ID: <CAFDcVCRB-VE8Mv+=BoFQq1D_kJkZo_EAZ+emAZzNj-yUFrwniQ@mail.gmail.com>

You can! Open a file connection and write to that. Whatever write commands
you use will append to the output. Don't forget to close the connection at
the end. See ?file

Henrik
On Oct 22, 2014 12:33 AM, "Sven E. Templer" <sven.templer at gmail.com> wrote:

> Hi.
>
> You can't.
>
> But using a second file where you first write your header and then
> append the original file is a solution. ?cat and ?write.table with a
> focus on the 'append' argument should help. you can then use ?unlink
> to delete the original file and ?file.rename to rename the second, if
> desired.
>
> Best, Sven.
>
> On 22 October 2014 02:32, YIHSU CHEN <yihsuc at gmail.com> wrote:
> > Hi guys;
> >
> > I want to write some text at the first line of an output file.  The
> output
> > file will be used for other software.  In particular, the following text
> > "ampl.tab 2 1" needs to be added to the first line of an  df output file.
> > As a hypothetic example, the output in text file should be like:
> >
> > ampl.tab 2 1
> > A  B
> > 2   3
> > 4   6
> > 2   0
> >
> > Thanks for help.
> >
> > Yihsu
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Wed Oct 22 11:07:40 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 22 Oct 2014 11:07:40 +0200
Subject: [R] add text to the first line of an output file
In-Reply-To: <CAFDcVCRB-VE8Mv+=BoFQq1D_kJkZo_EAZ+emAZzNj-yUFrwniQ@mail.gmail.com>
References: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>
	<CAHuTOvpYQ7a73+BhyAQLziJwXUncyPX0wjycu_QHSpoR_FWx5w@mail.gmail.com>
	<CAFDcVCRB-VE8Mv+=BoFQq1D_kJkZo_EAZ+emAZzNj-yUFrwniQ@mail.gmail.com>
Message-ID: <CAHuTOvotQ9i=3r5BcQqJCiB3LCcK92sCSSr1rRg-8vO_EpMwSQ@mail.gmail.com>

He wants to prepend, not append.

On 22 October 2014 11:04, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> You can! Open a file connection and write to that. Whatever write commands
> you use will append to the output. Don't forget to close the connection at
> the end. See ?file
>
> Henrik
>
> On Oct 22, 2014 12:33 AM, "Sven E. Templer" <sven.templer at gmail.com> wrote:
>>
>> Hi.
>>
>> You can't.
>>
>> But using a second file where you first write your header and then
>> append the original file is a solution. ?cat and ?write.table with a
>> focus on the 'append' argument should help. you can then use ?unlink
>> to delete the original file and ?file.rename to rename the second, if
>> desired.
>>
>> Best, Sven.
>>
>> On 22 October 2014 02:32, YIHSU CHEN <yihsuc at gmail.com> wrote:
>> > Hi guys;
>> >
>> > I want to write some text at the first line of an output file.  The
>> > output
>> > file will be used for other software.  In particular, the following text
>> > "ampl.tab 2 1" needs to be added to the first line of an  df output
>> > file.
>> > As a hypothetic example, the output in text file should be like:
>> >
>> > ampl.tab 2 1
>> > A  B
>> > 2   3
>> > 4   6
>> > 2   0
>> >
>> > Thanks for help.
>> >
>> > Yihsu
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Oct 22 12:46:13 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 22 Oct 2014 10:46:13 +0000
Subject: [R] format negative numbers
In-Reply-To: <48A56878-2C14-4BFD-96D2-626886D2A364@comcast.net>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAC9C@SRVEXCHMBX.precheza.cz>
	<5444E99C.3050309@yahoo.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEAE17@SRVEXCHMBX.precheza.cz>
	<48A56878-2C14-4BFD-96D2-626886D2A364@comcast.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEB19E@SRVEXCHMBX.precheza.cz>

Thanks to all

It seems that negative format nnnn- is very rare so there is no interest in providing some function for changing such numbers to "correct" ones. My function seems to be similar to solution of others so I stay with it for the time being.

Cheers
Petr


> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Monday, October 20, 2014 11:04 PM
> To: PIKAL Petr
> Cc: Marc Girondot; r-help at r-project.org
> Subject: Re: [R] format negative numbers
>
>
> On Oct 20, 2014, at 4:32 AM, PIKAL Petr wrote:
>
> > Hi
> >
> > Thanks to all who responded.
> >
> > My input string is rather clumsy. Actually it can have leading or
> trailing empty space too, it can be mixture of positive and negative
> numbers.
> >
> > In the meantime I made small function which just strips of - sign and
> make numbers from factors, find numbers which have - sign and change
> numbers which shall be negative to negative. Not as elegant as your
> solution but works even when there are leading or trailing spaces.
> >
> > zapor <- function(x) {
> > num<-as.numeric(gsub("(-)", "", x))
>
> Might want to just use sub() since your method would accept things like
> "-----100----"
>
> > zap<- grep("-", x)
> > num[zap]<- num[zap] * (-1)
> > num}
> >
> >> x <- as.factor( c("   123.4-   " , "   123   "))
> >> zapor(x)
> > [1] -123.4  123.0
> >>
>
> gsub("^(\\s+)([0-9.]+)(-){0,1}(\\s)+$", "\\3\\2",
>                 as.factor( c("   123.4-   " , "   123   ") ) )
> [1] "-123.4" "123"
>
> Then just `as.numeric`. You method looks more elegant. Depending on the
> local you may get into trouble with variation in decimal markers.
>
>
> >
> > I just thought that there is some reason for presenting negative
> numbers with minus sign behind the number in finance community and
> therefore somebody already invented clever way how to deal with such
> numbers.
> >
> > Cheers
> > Petr
> >
> >
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> >> project.org] On Behalf Of Marc Girondot
> >> Sent: Monday, October 20, 2014 12:53 PM
> >> To: r-help at r-project.org
> >> Subject: Re: [R] format negative numbers
> >>
> >> Is it what you want?
> >>
> >>> st <- "0.123-"
> >>> gsub("(.+)(-)", "\\2\\1", st)
> >> [1] "-0.123"
> >>> st <- "0.123"
> >>> gsub("(.+)(-)", "\\2\\1", st)
> >> [1] "0.123"
> >>
> >> Sincerely
> >> Marc
> >>
> >> Le 20/10/2014 09:03, PIKAL Petr a ?crit :
> >>> Dear all.
> >>>
> >>> Before I start fishing in (for me) murky regular expression waters
> I
> >> try to ask community about changing format of negative numbers.
> >>>
> >>> For some reason I get a file with negative numbers formatted with
> >> negative sign at end of number.
> >>>
> >>> something like
> >>>
> >>> 0.123-
> >>>
> >>> It is imported as factors and I need to convert it to numbers
> again.
> >> Before converting I need to change it to "correct" format
> >>>
> >>> -0.123
> >>>
> >>> Does anybody know some simple way?
> >>>
> >>> Cheers
> >>> Petr
> >>>
> >>>
> >>> ________________________________
> >>> Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a
> >>
>
> David Winsemius
> Alameda, CA, USA


________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From hb at biostat.ucsf.edu  Wed Oct 22 16:57:14 2014
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 22 Oct 2014 07:57:14 -0700
Subject: [R] add text to the first line of an output file
In-Reply-To: <CAHuTOvotQ9i=3r5BcQqJCiB3LCcK92sCSSr1rRg-8vO_EpMwSQ@mail.gmail.com>
References: <CAPSQWp=XkBqD3zkoyu_on2MV27zts4tjZioyrjFO9=LNp4cbAQ@mail.gmail.com>
	<CAHuTOvpYQ7a73+BhyAQLziJwXUncyPX0wjycu_QHSpoR_FWx5w@mail.gmail.com>
	<CAFDcVCRB-VE8Mv+=BoFQq1D_kJkZo_EAZ+emAZzNj-yUFrwniQ@mail.gmail.com>
	<CAHuTOvotQ9i=3r5BcQqJCiB3LCcK92sCSSr1rRg-8vO_EpMwSQ@mail.gmail.com>
Message-ID: <CAFDcVCRQ+yWSW0h988N6ksKKqS1jY9jm358_iJWVRWStupzZzw@mail.gmail.com>

Alright, if it is the case that the "output file" already exists, then yes
Sven's suggestion is more or less the only solution.

Henrik
On Oct 22, 2014 2:08 AM, "Sven E. Templer" <sven.templer at gmail.com> wrote:

> He wants to prepend, not append.
>
> On 22 October 2014 11:04, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> > You can! Open a file connection and write to that. Whatever write
> commands
> > you use will append to the output. Don't forget to close the connection
> at
> > the end. See ?file
> >
> > Henrik
> >
> > On Oct 22, 2014 12:33 AM, "Sven E. Templer" <sven.templer at gmail.com>
> wrote:
> >>
> >> Hi.
> >>
> >> You can't.
> >>
> >> But using a second file where you first write your header and then
> >> append the original file is a solution. ?cat and ?write.table with a
> >> focus on the 'append' argument should help. you can then use ?unlink
> >> to delete the original file and ?file.rename to rename the second, if
> >> desired.
> >>
> >> Best, Sven.
> >>
> >> On 22 October 2014 02:32, YIHSU CHEN <yihsuc at gmail.com> wrote:
> >> > Hi guys;
> >> >
> >> > I want to write some text at the first line of an output file.  The
> >> > output
> >> > file will be used for other software.  In particular, the following
> text
> >> > "ampl.tab 2 1" needs to be added to the first line of an  df output
> >> > file.
> >> > As a hypothetic example, the output in text file should be like:
> >> >
> >> > ampl.tab 2 1
> >> > A  B
> >> > 2   3
> >> > 4   6
> >> > 2   0
> >> >
> >> > Thanks for help.
> >> >
> >> > Yihsu
> >> >
> >> >         [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bbolker at gmail.com  Wed Oct 22 17:08:25 2014
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 22 Oct 2014 15:08:25 +0000
Subject: [R] glmer with multiple random slopes
References: <54454AD5.70500@gmail.com>
Message-ID: <loom.20141022T170743-332@post.gmane.org>

David Kikuchi <dwkikuchi <at> gmail.com> writes:

> 
> Hi all,
> 
> I'm modeling the probability that a subject attacks or rejects a prey 
> item based on its proportion of yellow coloration and size. There are 
> two populations of prey, one defended and the other undefended, so 
> subjects should reject one type and accept others. Each subject has a 
> unique rejection threshold that is a line on a contour plot with 
> coloration and size on the x and y axes. I want to estimate the error 
> around that line's slope, and believe that I need to estimate two random 
> slopes per subject to do so, one in the color dimension and the other in 
> the size dimension. The code that I think I should use to do this is: 
> glmer(attack ~ prop.color + size + (prop.color + size|subject, family = 
> binomial), but I cannot find a reference or example for fitting random 
> slopes in different continuous dimensions. I would appreciate any 
> pointers in the right direction.
> 
> Thanks,
> David

     This seems perfectly reasonable.  It might be more on-topic 
on r-sig-mixed-models at r-project.org (send follow-ups there please).

My only concern with this model is the size of your data set -- you
probably need a reasonably large number of trials per subject (20-30, or more?),
and a reasonably large number of subjects (at least 10, preferably >20?)
in order to estimate the among-subject variation in the response reasonably
well.

You should be able to use lme4's simulate method to simulate data and
try a power analysis -- the hardest part is figuring out what the 'theta'
(random-effects) parameters mean (the among-subject variance-covariance
matrix is a 3*3 matrix (intercept, color, size), the parameters fill in
a lower-triangular matrix

  t1  0  0
  t2  t4 0
  t3  t5 t6

which is multiplied by its transpose 

  t1  t2  t3
  0   t4  t5
  0    0  t6

to get the variance-covariance matrix.


From zilefacelvis at yahoo.com  Wed Oct 22 17:37:42 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 22 Oct 2014 08:37:42 -0700
Subject: [R] Split fixed width data in R
Message-ID: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>

Hi,
I have fixed width data that I would like to split into columns. Here is a sanpshot of the data (actual data is a list object):
lst1Sub<-
"20131124GGG1 23.00" 
"20131125GGG1 15.00"   
"20131128GGG1  0.00" 
"201312 1GGG1  0.00"
"201312 4GGG1  0.00"
"201312 7GGG1 10.00" 
"20131210GGG1  0.00"
"20131213GGG1  0.00" 
"20131216GGG1  0.00" 
"20131219GGG1  0.00" 
"20131222GGG1  0.00"
"20131225GGG1  0.00"   
"20131228GGG1  0.00" 

The following script will split the data into [Year Month Day Site Precipitation]
------------------------------------------------------------------------------------------------------
library(stringr)
dateSite <- gsub("(.*G.{3}).*","\\1",lst1Sub); 
dat1 <- data.frame(Year=as.numeric(substr(dateSite,1,4)), Month=as.numeric(substr(dateSite,5,6)), 
                   Day=as.numeric(substr(dateSite,7,8)),Site=substr(dateSite,9,12),Rain=substr(dateSite,13,18),stringsAsFactors=FALSE);
lst3 <- lapply(lst1Sub,function(x) {dateSite <- gsub("(.*G.{3}).*","\\1",x); 
                                    dat1 <- data.frame(Year=as.numeric(substr(dateSite,1,4)), Month=as.numeric(substr(dateSite,5,6)),Day=as.numeric(substr(dateSite,7,8)),Site=substr(dateSite,9,12),stringsAsFactors=FALSE); 
                                    Sims <- str_trim(gsub(".*G.{3}\\s?(.*)","\\1",x));Sims[grep("\\d+-",Sims)] <- gsub("(.*)([-][0-9]+\\.[0-9]+)","\\1 \\2",gsub("^([0-9]+\\.[0-9]+)(.*)","\\1 \\2", Sims[grep("\\d+-",Sims)])); 
                                    Sims1 <- read.table(text=Sims,header=FALSE); names(Sims1) <- c("Precipitation");dat2 <- cbind(dat1,Sims1)}) 
------------------------------------------------------------------------------------------------------------------------------------------

Problem: the above script deletes the first value of my precipitation values. For example, after splitting, "20131124GGG1 23.00" becomes 
2013 11 24 GGG1 3.00 INSTEAD of 2013 11 24 GGG1 23.00 (right answer).

Anything wrong with the string trimming? Is there another way to arrive at the same answer?

Thanks,
AT.


From G.Rudge at bham.ac.uk  Wed Oct 22 17:48:43 2014
From: G.Rudge at bham.ac.uk (Gavin Rudge)
Date: Wed, 22 Oct 2014 15:48:43 +0000
Subject: [R] creating individual records from a frequency distribution
Message-ID: <B8D87DA108D62D448DBE22A7775AB6BB5D3A1597@EX3.adf.bham.ac.uk>

I've got data frame containing a simple frequency distribution of numbers of people in three age groups by area.

df1<-data.frame(area=c(1,2),group1=c(2,3),group2=c(1,5),group3=c(4,0))
df1

I want to get a data frame with one record per person (in my case 15 of them) which would look like this, with variables indicating the area and age group to which each belongs

df2<-data.frame(person_id=seq(1:15),area=c(rep(1,7),rep(2,8)),group_num=c(1,1,2,3,3,3,3,1,1,1,2,2,2,2,2))
df2

This is not the same as melting wide to long data as in reshape2, as I'm melting from aggregated data. I can get vectors of columns values using the rep command, but sewing them together and allowing for zeros looks a bit cumbersome. I'm assuming there is a simple command that does this sort of thing.

Any help gratefully received,

GavinR

	[[alternative HTML version deleted]]


From clint at ecy.wa.gov  Wed Oct 22 17:54:04 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Wed, 22 Oct 2014 08:54:04 -0700 (PDT)
Subject: [R] Split fixed width data in R
In-Reply-To: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <alpine.LRH.2.11.1410220853510.9850@aeolus.ecy.wa.gov>

?read.fortran

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Wed, 22 Oct 2014, Zilefac Elvis wrote:

> Hi,
> I have fixed width data that I would like to split into columns. Here is a sanpshot of the data (actual data is a list object):
> lst1Sub<-
> "20131124GGG1 23.00"
> "20131125GGG1 15.00"
> "20131128GGG1  0.00"
> "201312 1GGG1  0.00"
> "201312 4GGG1  0.00"
> "201312 7GGG1 10.00"
> "20131210GGG1  0.00"
> "20131213GGG1  0.00"
> "20131216GGG1  0.00"
> "20131219GGG1  0.00"
> "20131222GGG1  0.00"
> "20131225GGG1  0.00"
> "20131228GGG1  0.00"
>
> The following script will split the data into [Year Month Day Site Precipitation]
> ------------------------------------------------------------------------------------------------------
> library(stringr)
> dateSite <- gsub("(.*G.{3}).*","\\1",lst1Sub);
> dat1 <- data.frame(Year=as.numeric(substr(dateSite,1,4)), Month=as.numeric(substr(dateSite,5,6)),
>                   Day=as.numeric(substr(dateSite,7,8)),Site=substr(dateSite,9,12),Rain=substr(dateSite,13,18),stringsAsFactors=FALSE);
> lst3 <- lapply(lst1Sub,function(x) {dateSite <- gsub("(.*G.{3}).*","\\1",x);
>                                    dat1 <- data.frame(Year=as.numeric(substr(dateSite,1,4)), Month=as.numeric(substr(dateSite,5,6)),Day=as.numeric(substr(dateSite,7,8)),Site=substr(dateSite,9,12),stringsAsFactors=FALSE);
>                                    Sims <- str_trim(gsub(".*G.{3}\\s?(.*)","\\1",x));Sims[grep("\\d+-",Sims)] <- gsub("(.*)([-][0-9]+\\.[0-9]+)","\\1 \\2",gsub("^([0-9]+\\.[0-9]+)(.*)","\\1 \\2", Sims[grep("\\d+-",Sims)]));
>                                    Sims1 <- read.table(text=Sims,header=FALSE); names(Sims1) <- c("Precipitation");dat2 <- cbind(dat1,Sims1)})
> ------------------------------------------------------------------------------------------------------------------------------------------
>
> Problem: the above script deletes the first value of my precipitation values. For example, after splitting, "20131124GGG1 23.00" becomes
> 2013 11 24 GGG1 3.00 INSTEAD of 2013 11 24 GGG1 23.00 (right answer).
>
> Anything wrong with the string trimming? Is there another way to arrive at the same answer?
>
> Thanks,
> AT.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From S.Ellison at LGCGroup.com  Wed Oct 22 18:03:09 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 22 Oct 2014 17:03:09 +0100
Subject: [R] Split fixed width data in R
In-Reply-To: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412C2085C@GOLD.corp.lgc-group.com>

This seems to do a fair bit of it on your example data; you can pull out the date bits separately using Date functions if you need them

decode.lst <- function(x) { 
	data.frame(Date=as.Date(substr(x,1,8), format="%Y%m%d"), 
			Site=substr(x, 9,12), 
			Precipitation=as.numeric(substring(x,13)))
}

decode.lst(lst1Sub)


S Ellison



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Zilefac Elvis
> Sent: 22 October 2014 16:38
> To: R. Help
> Subject: [R] Split fixed width data in R
> 
> Hi,
> I have fixed width data that I would like to split into columns. Here is a sanpshot
> of the data (actual data is a list object):
> lst1Sub<-
> "20131124GGG1 23.00"
> "20131125GGG1 15.00"
> "20131128GGG1  0.00"
> "201312 1GGG1  0.00"
> "201312 4GGG1  0.00"
> "201312 7GGG1 10.00"
> "20131210GGG1  0.00"
> "20131213GGG1  0.00"
> "20131216GGG1  0.00"
> "20131219GGG1  0.00"
> "20131222GGG1  0.00"
> "20131225GGG1  0.00"
> "20131228GGG1  0.00"
> 
> The following script will split the data into [Year Month Day Site Precipitation]
> ------------------------------------------------------------------------------------------------------
> library(stringr)
> dateSite <- gsub("(.*G.{3}).*","\\1",lst1Sub);
> dat1 <- data.frame(Year=as.numeric(substr(dateSite,1,4)),
> Month=as.numeric(substr(dateSite,5,6)),
> 
> Day=as.numeric(substr(dateSite,7,8)),Site=substr(dateSite,9,12),Rain=substr(dat
> eSite,13,18),stringsAsFactors=FALSE);
> lst3 <- lapply(lst1Sub,function(x) {dateSite <- gsub("(.*G.{3}).*","\\1",x);
>                                     dat1 <-
> data.frame(Year=as.numeric(substr(dateSite,1,4)),
> Month=as.numeric(substr(dateSite,5,6)),Day=as.numeric(substr(dateSite,7,8)),Si
> te=substr(dateSite,9,12),stringsAsFactors=FALSE);
>                                     Sims <-
> str_trim(gsub(".*G.{3}\\s?(.*)","\\1",x));Sims[grep("\\d+-",Sims)] <- gsub("(.*)([-
> ][0-9]+\\.[0-9]+)","\\1 \\2",gsub("^([0-9]+\\.[0-9]+)(.*)","\\1 \\2",
> Sims[grep("\\d+-",Sims)]));
>                                     Sims1 <- read.table(text=Sims,header=FALSE);
> names(Sims1) <- c("Precipitation");dat2 <- cbind(dat1,Sims1)})
> -------------------------------------------------------------------------------------------------------
> -----------------------------------
> 
> Problem: the above script deletes the first value of my precipitation values. For
> example, after splitting, "20131124GGG1 23.00" becomes
> 2013 11 24 GGG1 3.00 INSTEAD of 2013 11 24 GGG1 23.00 (right answer).
> 
> Anything wrong with the string trimming? Is there another way to arrive at the
> same answer?
> 
> Thanks,
> AT.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Wed Oct 22 18:08:30 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 22 Oct 2014 17:08:30 +0100
Subject: [R] Split fixed width data in R
In-Reply-To: <alpine.LRH.2.11.1410220853510.9850@aeolus.ecy.wa.gov>
References: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<alpine.LRH.2.11.1410220853510.9850@aeolus.ecy.wa.gov>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412C20860@GOLD.corp.lgc-group.com>



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Clint Bowman
> 
> ?read.fortran

Also read.fwf if it's in a file.

S



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From cmcastaneda42 at gmail.com  Tue Oct 21 18:01:20 2014
From: cmcastaneda42 at gmail.com (Carlos M Castaneda)
Date: Tue, 21 Oct 2014 09:01:20 -0700
Subject: [R] assignment 2 part 1,2,3
Message-ID: <CAGN4sprzL7XvezAdvBeygLvpxEs23BL5Uk-V9V-brjLPK5JcRA@mail.gmail.com>

I am not taking this course for a grade, just self interest. I am stock
with  making the function. is there any where I can see how is done. I will
not submit the  home work. I want to use the homework as a tool to
understand.\ the Coding for R.
Thanks

	[[alternative HTML version deleted]]


From Matthias.Weber at fntsoftware.com  Wed Oct 22 11:34:00 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Wed, 22 Oct 2014 11:34:00 +0200
Subject: [R] sort a data.frame in a different way
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF2CB@mail.ell.fnt.de>

Hello together,

i have a little problem. Maybe anyone can help me.

I have a data. frame which look like this one:
     1000     1001     1002    1003
1    5          6         12        11
2    4          3          8        1

What i need is a data.frame, which looks like this one. The Column names should be in the first column, and the values right of the column name. The solution look like this one:
              A           B
1000      5           4
1001      6           3
1002     12          8
1003     11          1

maybe anyone can help me.

Thank you.

Best regards. Mat


________________________________
This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.

	[[alternative HTML version deleted]]


From info.vasukv at gmail.com  Wed Oct 22 11:35:55 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Wed, 22 Oct 2014 15:05:55 +0530
Subject: [R] Fwd: as.POSIXlt() Function
In-Reply-To: <CAJhrTnr2XPPWiuogoidy1AFg29OmNAPZHae+Q=SP8Y_PBDhDxQ@mail.gmail.com>
References: <CAJhrTnr2XPPWiuogoidy1AFg29OmNAPZHae+Q=SP8Y_PBDhDxQ@mail.gmail.com>
Message-ID: <CAJhrTnogoL19pgDyki4aFCp+3=gB82zr2yavgThGpDzkJcswrw@mail.gmail.com>

Hi,

I am a new R user and also not sure about the below concern is really a bug,

My concern are listed below,

Look at the below example, when Sys.Date () is called within the as.POSIXlt
() function. Why it is displaying only the date value and the timezone is
selected to UTC even though the TZ variable is set to "PST8PDT".  I could
not see this kind of behavior with as.POSIXct () function.

This is happening in both LINUX 32 and 64 bit operating system.


Example:

> version
               _
platform       i386-redhat-linux-gnu
arch           i386
os             linux-gnu
system         i386, linux-gnu
status
major          2
minor          10.0
year           2009
month          10
day            26
svn rev        50208
language       R
version.string R version 2.10.0 (2009-10-26)
> Sys.setenv(TZ="PST8PDT");
> Sys.setenv(ORA_SDTZ="PST8PDT");
>
> Sys.getenv("TZ");
       TZ
"PST8PDT"
> Sys.getenv("ORA_SDTZ");
 ORA_SDTZ
"PST8PDT"
>
> as.POSIXct(Sys.Date());
[1] "2014-10-20 17:00:00 PDT"
> c(as.POSIXct(Sys.Date()));
[1] "2014-10-20 17:00:00 PDT"
>
> as.POSIXlt(Sys.Date());
[1] "2014-10-21 UTC"
> c(as.POSIXlt(Sys.Date()));
[1] "2014-10-20 17:00:00 PDT"
>
> as.POSIXct(Sys.time());
[1] "2014-10-21 20:59:23 PDT"
> c(as.POSIXct(Sys.time()));
[1] "2014-10-21 20:59:23 PDT"
>
> as.POSIXlt(Sys.time());
[1] "2014-10-21 20:59:23 PDT"
> c(as.POSIXlt(Sys.time()));
[1] "2014-10-21 20:59:23 PDT"
>

Thanks
Vasanth

	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Oct 22 14:55:26 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 22 Oct 2014 09:55:26 -0300
Subject: [R] import and export data for RMark package
Message-ID: <COL130-W550C86297E0F7F585CA6FCFA950@phx.gbl>

Dear R users,I wondering how I can import and extract the data of .txt format to the format that is compatible with RMark package for further analysis. I tried following example but did not work. Would you give any suggestions?

install.packages("RMark")library(RMark)
#Import table (inp format)  in R and Exportexample.1 <- convert.inp("http://www.montana.edu/rotella/502/deer.inp")head(example.1)
# wanted to add the variable "states" (locations)example.1$state<-ifelse(row.names(example.1) > 76, c("B"), c("A"))
# to save it in txtwrite.table(example.1, "testing.txt", row.names=F, sep = "\t")
# import the txt file data<-import.chdata("testing.txt", field.names=c("ch","freq","states"), header=FALSE)data<-data[-1,]mstrata.processed=process.data(data, model="Multistrata")# it did not work
# to export the data into inp formatexport.chdata(mstrata.processed, filename="testing")

Thanks Kristi
 		 	   		  
	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Oct 22 15:18:06 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 22 Oct 2014 10:18:06 -0300
Subject: [R] import and export data for RMark package
In-Reply-To: <COL130-W550C86297E0F7F585CA6FCFA950@phx.gbl>
References: <COL130-W550C86297E0F7F585CA6FCFA950@phx.gbl>
Message-ID: <COL130-W7022F4186917866FBF672AFA950@phx.gbl>

Dear R users,I wondering how I can import and extract the data of .txt format to the format that is compatible with RMark package for further analysis. I tried following example but did not work. Would you give any suggestions?

install.packages("RMark")library(RMark)
#Import table (inp format)  in R and Exportexample.1 <- convert.inp("http://www.montana.edu/rotella/502/deer.inp")head(example.1)
# wanted to add the variable "states" (locations)example.1$state<-ifelse(row.names(example.1) > 76, c("B"), c("A"))
# to save it in txtwrite.table(example.1, "testing.txt", row.names=F, sep = "\t")
# import the txt file data<-import.chdata("testing.txt", field.names=c("ch","freq","states"), header=FALSE)data<-data[-1,]mstrata.processed=process.data(data, model="Multistrata")# it did not work
# to export the data into inp formatexport.chdata(mstrata.processed, filename="testing")

Thanks Kristi
 		 	   		   		 	   		  
	[[alternative HTML version deleted]]


From kristi.glover at hotmail.com  Wed Oct 22 17:36:15 2014
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 22 Oct 2014 12:36:15 -0300
Subject: [R] how to import and export data in RMark package
Message-ID: <COL130-W604EAD284AB69CDD1D9983FA950@phx.gbl>

Dear R users,I wondering how I can import and extract the data of 
.txt format to the format that is compatible with RMark package . I tried following script to import and export. Importing was OK but did not work for exporting. Would you give any suggestions?

install.packages("RMark")library(RMark)# example 

#Import table (inp format)  in R and Exportexample.1 <- convert.inp("http://www.montana.edu/rotella/502/deer.inp")head(example.1)
# wanted to add the variable "states" (locations)example.1$state<-ifelse(row.names(example.1) > 76, c("B"), c("A"))
# to save it in txtwrite.table(example.1, "testing.txt", row.names=F, sep = "\t")
# import the txt file data<-import.chdata("testing.txt", field.names=c("ch","freq","states"), header=FALSE)data<-data[-1,]mstrata.processed=process.data(data, model="Multistrata")# it did not work
# to export the data into .inp formatexport.chdata(mstrata.processed, filename="testing")

Thanks Kristi
 		 	   		  
	[[alternative HTML version deleted]]


From sven.templer at gmail.com  Wed Oct 22 20:25:36 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 22 Oct 2014 20:25:36 +0200
Subject: [R] creating individual records from a frequency distribution
In-Reply-To: <B8D87DA108D62D448DBE22A7775AB6BB5D3A1597@EX3.adf.bham.ac.uk>
References: <B8D87DA108D62D448DBE22A7775AB6BB5D3A1597@EX3.adf.bham.ac.uk>
Message-ID: <CAHuTOvrxxsi7d_tc+MwRB3ivRAqOo6WB0NmxjKaZndpk9yi96w@mail.gmail.com>

With melt and rep you are close. If you combine them it works:

library(reshape)
# your data:
df1 <- data.frame(area=c(1,2),group1=c(2,3),group2=c(1,5),group3=c(4,0))
df2<-data.frame(person_id=seq(1:15),area=c(rep(1,7),rep(2,8)),group_num=c(1,1,2,3,3,3,3,1,1,1,2,2,2,2,2))
# first melt
d <- melt(df1,"area",2:4)
# then repeat each row by 'counts'
d <- d[rep(seq(nrow(d)), times=d$value),]
# then order (if order of id's is not arbitrary), and add ids
d <- d[order(d$area,d$variable),]
d$value <- seq(nrow(d))
# compare
cbind(df2,"---",d)

Best, Sven.

On 22 October 2014 17:48, Gavin Rudge <G.Rudge at bham.ac.uk> wrote:
> I've got data frame containing a simple frequency distribution of numbers of people in three age groups by area.
>
> df1<-data.frame(area=c(1,2),group1=c(2,3),group2=c(1,5),group3=c(4,0))
> df1
>
> I want to get a data frame with one record per person (in my case 15 of them) which would look like this, with variables indicating the area and age group to which each belongs
>
> df2<-data.frame(person_id=seq(1:15),area=c(rep(1,7),rep(2,8)),group_num=c(1,1,2,3,3,3,3,1,1,1,2,2,2,2,2))
> df2
>
> This is not the same as melting wide to long data as in reshape2, as I'm melting from aggregated data. I can get vectors of columns values using the rep command, but sewing them together and allowing for zeros looks a bit cumbersome. I'm assuming there is a simple command that does this sort of thing.
>
> Any help gratefully received,
>
> GavinR
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sven.templer at gmail.com  Wed Oct 22 20:30:41 2014
From: sven.templer at gmail.com (Sven E. Templer)
Date: Wed, 22 Oct 2014 20:30:41 +0200
Subject: [R] sort a data.frame in a different way
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF2CB@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2CB@mail.ell.fnt.de>
Message-ID: <CAHuTOvrJ63a1u+89sJeBtih0YYh7m3yDoQMZTdg5fZqN5Eoq2w@mail.gmail.com>

seems like a transpose, so use

?t
t(your.data.frame)


On 22 October 2014 11:34, Matthias Weber <Matthias.Weber at fntsoftware.com> wrote:
> Hello together,
>
> i have a little problem. Maybe anyone can help me.
>
> I have a data. frame which look like this one:
>      1000     1001     1002    1003
> 1    5          6         12        11
> 2    4          3          8        1
>
> What i need is a data.frame, which looks like this one. The Column names should be in the first column, and the values right of the column name. The solution look like this one:
>               A           B
> 1000      5           4
> 1001      6           3
> 1002     12          8
> 1003     11          1
>
> maybe anyone can help me.
>
> Thank you.
>
> Best regards. Mat
>
>
> ________________________________
> This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.
>
> Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.
>
>         [[alternative HTML version deleted]]

please read mailing list guidelines, and don't send HTML messages

>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jeff.laake at noaa.gov  Wed Oct 22 21:33:49 2014
From: jeff.laake at noaa.gov (Jeff Laake - NOAA Federal)
Date: Wed, 22 Oct 2014 12:33:49 -0700
Subject: [R] import and export data for RMark package
In-Reply-To: <COL130-W550C86297E0F7F585CA6FCFA950@phx.gbl>
References: <COL130-W550C86297E0F7F585CA6FCFA950@phx.gbl>
Message-ID: <CA+_rFBKkKdp0kseMQ72EJRJtSKJUyN2Ypjtn+3tkb6L-bZ1LRg@mail.gmail.com>

Kristi-

Any questions related to RMark should be sent to the forum on RMark at
phidot.org.  If you provide me with a snippet of your data I will try to
help you.

regards --jeff

On Wed, Oct 22, 2014 at 5:55 AM, Kristi Glover <kristi.glover at hotmail.com>
wrote:

> Dear R users,I wondering how I can import and extract the data of .txt
> format to the format that is compatible with RMark package for further
> analysis. I tried following example but did not work. Would you give any
> suggestions?
>
> install.packages("RMark")library(RMark)
> #Import table (inp format)  in R and Exportexample.1 <- convert.inp("
> http://www.montana.edu/rotella/502/deer.inp")head(example.1)
> # wanted to add the variable "states"
> (locations)example.1$state<-ifelse(row.names(example.1) > 76, c("B"),
> c("A"))
> # to save it in txtwrite.table(example.1, "testing.txt", row.names=F, sep
> = "\t")
> # import the txt file data<-import.chdata("testing.txt",
> field.names=c("ch","freq","states"),
> header=FALSE)data<-data[-1,]mstrata.processed=process.data(data,
> model="Multistrata")# it did not work
> # to export the data into inp formatexport.chdata(mstrata.processed,
> filename="testing")
>
> Thanks Kristi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitri.liakhovitski at gmail.com  Wed Oct 22 21:37:09 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 22 Oct 2014 15:37:09 -0400
Subject: [R] How to clear R memory in a for loop
In-Reply-To: <5446A5EE.6060709@statistik.tu-dortmund.de>
References: <CAN2xGJZKhL4ej77YL9kh=8yaiUJfziqGaN8FBPCbWdNCqpxCCw@mail.gmail.com>
	<CAAJSdjgdFK10dbiN8scN2DOdeU=8aCB64jv8jp1o7GF2ptK3iw@mail.gmail.com>
	<5445FCA2.1000307@stats.ox.ac.uk>
	<CAN2xGJbaiWJEL4jmtT64NVzs6d524zz3SQyYa772VxYF8ZsjKw@mail.gmail.com>
	<544672E0.7080509@stats.ox.ac.uk>
	<CAF8bMcYG8a7RBLZTWZ9jGiOBhvy96LZzbHk357Su8vHZ95Q4Dg@mail.gmail.com>
	<5446A5EE.6060709@statistik.tu-dortmund.de>
Message-ID: <CAN2xGJaS4EiCVYipyab9Tw3LbQ84v7jt4oJLikufkk3m0Hsicw@mail.gmail.com>

Thank you very much for looking into it, gentlemen!

On Tue, Oct 21, 2014 at 2:29 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 21.10.2014 19:00, William Dunlap wrote:
>>
>> A few minutes with valgrind showed that output_pos was never
>> initialized, so the output array was not getting filled correctly.
>> The following fixes that problem
>>
>> diff -ru tuneR/src/readmp3.c /homes/bill/packages/tuneR/src/readmp3.c
>> --- tuneR/src/readmp3.c 2014-04-07 04:38:21.000000000 -0700
>> +++ /homes/bill/packages/tuneR/src/readmp3.c    2014-10-21
>> 09:54:19.351867000 -0700
>> @@ -96,6 +96,7 @@
>>     state.input = blob;
>>     state.input_size = n_blob;
>>     state.output_size = 0;
>> +  state.output_pos = 0;
>>     mad_decoder_init(&decoder, &state,
>>              mad_input_cb, mad_header_cb, NULL,
>>              NULL, NULL, NULL);
>
>
>
> Thanks, Bill!
> I haven't found the time to look at it.
> Now in the master sources, bugfix release will follow shortly,
> Uwe
>
>
>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Tue, Oct 21, 2014 at 7:51 AM, Prof Brian Ripley
>> <ripley at stats.ox.ac.uk> wrote:
>>>
>>> On 21/10/2014 15:47, Dimitri Liakhovitski wrote:
>>>>
>>>>
>>>> I will try with .wav files and report back.
>>>> So far, I am not sure I understood what could be done (if anything) to
>>>> fix
>>>> it...
>>>
>>>
>>>
>>> This is nothing to do with my reply!
>>>
>>> The posting guide asked you to contact the tuneR maintainer *before
>>> posting*.  What did he say?
>>>
>>> Bill Dunlap's reply pointed to a bug in tuneR (or a library it uses).
>>>
>>>
>>>>
>>>> On Tue, Oct 21, 2014 at 2:26 AM, Prof Brian Ripley
>>>> <ripley at stats.ox.ac.uk> wrote:
>>>>>
>>>>>
>>>>> On 20/10/2014 17:53, John McKown wrote:
>>>>>>
>>>>>>
>>>>>>
>>>>>> On Mon, Oct 20, 2014 at 10:30 AM, Dimitri Liakhovitski <
>>>>>> dimitri.liakhovitski at gmail.com> wrote:
>>>>>>
>>>>>>> Dear Rers,
>>>>>>>
>>>>>>> I am trying to run a for-loop in R.
>>>>>>> During each iteration I read in an mp3 file and do some basic
>>>>>>> processing.
>>>>>>> If I do what I need to do for each file one by one - it works fine.
>>>>>>> But once I start running a loop, it soon runs out of memory and says:
>>>>>>> can't
>>>>>>> allocate a vector of size...
>>>>>>> In each iteration of my loop I always overwrite the previously
>>>>>>> created
>>>>>>> object and do gc().
>>>>>>>
>>>>>>> Any hints on how to fight this?
>>>>>>>
>>>>>>> Thanks a lot!
>>>>>>>
>>>>>>>
>>>>>>>
>>>>>> Please don't use HTML for messages.
>>>>>>
>>>>>> What occurs to me, from reading the other replies, is that perhaps
>>>>>> within
>>>>>> the loop you are causing other objects to be allocated. And that can
>>>>>> be
>>>>>> done just by doing a simple assignment, so it may not be obvious. What
>>>>>> this
>>>>>> can do is cause what we called a "sand bar" in the old days. That's
>>>>>> where
>>>>>> you allocate a big chunk of memory for an object. Say this take up 1/2
>>>>>> of
>>>>>> your available space. You now create a small object. This object is
>>>>>> _probably_ right next to the large object. You now release the large
>>>>>> object. Your apparent free space is now almost what it was at the
>>>>>> beginning. But when you try to allocate another large object which is,
>>>>>> say,
>>>>>> 2/3 of the maximum space, you can't because that small object is
>>>>>> sitting
>>>>>> right in the middle of our memory space. So you _can_ allocate 2 large
>>>>>> objects which are 1/3 your free space size, but not 1 object which is
>>>>>> 2/3
>>>>>> of the free space size. Which can lead to your type of situation.
>>>>>>
>>>>>> This is just a SWAG based on some experience in other systems. Most
>>>>>> "garbage collection" do _not_ do memory consolidation. I don't know
>>>>>> about
>>>>>> R.
>>>>>>
>>>>>>
>>>>> That is true of R (except for the early days which did have a moving
>>>>> garbage
>>>>> collector).
>>>>>
>>>>> However 'your available space' is not the amount of RAM you have but
>>>>> the
>>>>> process address space.  The latter is enormous on any 64-bit OS, so
>>>>> 'memory
>>>>> fragmentation' (as this is termed) is a thing of the past except for
>>>>> those
>>>>> limited to many-years-old OSes.
>>>>>
>>>>>
>>>>> --
>>>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>>>> Emeritus Professor of Applied Statistics, University of Oxford
>>>>> 1 South Parks Road, Oxford OX1 3TG, UK
>>>
>>>
>>>
>>>
>>>
>>> --
>>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>>> Emeritus Professor of Applied Statistics, University of Oxford
>>> 1 South Parks Road, Oxford OX1 3TG, UK
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.



-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Wed Oct 22 21:57:26 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 22 Oct 2014 15:57:26 -0400
Subject: [R] reducing the sampling rate of a .wav file
Message-ID: <CAN2xGJZE5v4AVxBBRXUOnx_97n1qniW5-S51Mon7h6Z2G5mLZQ@mail.gmail.com>

I've read in a wav file using 'tuneR':

silence<-readWave("silence0.5sec.wav")

I run summary(silence):

Wave Object
Number of Samples:      22051
Duration (seconds):     0.5
Samplingrate (Hertz):   44100
Channels (Mono/Stereo): Mono
PCM (integer format):   TRUE
Bit (8/16/24/32/64):    16

Summary statistics for channel(s):

   Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
      0       0       0       0       0       0


I would like to save this file as a lower frequency file so that:
Samplingrate (Hertz):   8000

Is it possible?
I am trying:
savewav(silence,filename="silence0.5sec 8000.wav",f=800)

But it doesn't work - it saves the file but when I read it in,
Samplingrate is still 44100

-- 
Dimitri Liakhovitski


From ligges at statistik.tu-dortmund.de  Wed Oct 22 22:03:26 2014
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Wed, 22 Oct 2014 22:03:26 +0200
Subject: [R] reducing the sampling rate of a .wav file
In-Reply-To: <CAN2xGJZE5v4AVxBBRXUOnx_97n1qniW5-S51Mon7h6Z2G5mLZQ@mail.gmail.com>
References: <CAN2xGJZE5v4AVxBBRXUOnx_97n1qniW5-S51Mon7h6Z2G5mLZQ@mail.gmail.com>
Message-ID: <54480D8E.2090301@statistik.tu-dortmund.de>



On 22.10.2014 21:57, Dimitri Liakhovitski wrote:
> I've read in a wav file using 'tuneR':
>
> silence<-readWave("silence0.5sec.wav")
>
> I run summary(silence):
>
> Wave Object
> Number of Samples:      22051
> Duration (seconds):     0.5
> Samplingrate (Hertz):   44100
> Channels (Mono/Stereo): Mono
> PCM (integer format):   TRUE
> Bit (8/16/24/32/64):    16
>
> Summary statistics for channel(s):
>
>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>        0       0       0       0       0       0
>
>
> I would like to save this file as a lower frequency file so that:
> Samplingrate (Hertz):   8000
>
> Is it possible?
> I am trying:
> savewav(silence,filename="silence0.5sec 8000.wav",f=800)
>
> But it doesn't work - it saves the file but when I read it in,
> Samplingrate is still 44100
>

What is savewav? At least not a tuneR function...

In "tuneR":


silence8000 <- downsample(silence, 8000)
writeWave(silence8000, file="silence0.5sec 8000.wav")

Best,
Uwe Ligges


From dimitri.liakhovitski at gmail.com  Wed Oct 22 22:48:21 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 22 Oct 2014 16:48:21 -0400
Subject: [R] reducing the sampling rate of a .wav file
In-Reply-To: <54480D8E.2090301@statistik.tu-dortmund.de>
References: <CAN2xGJZE5v4AVxBBRXUOnx_97n1qniW5-S51Mon7h6Z2G5mLZQ@mail.gmail.com>
	<54480D8E.2090301@statistik.tu-dortmund.de>
Message-ID: <CAN2xGJZTFQc6j_8v917G03pxDwC-5-zqX+_QHjjiBuXZjH=tcQ@mail.gmail.com>

Thank you so much, Uwe!
seavewav is from another package :)

On Wed, Oct 22, 2014 at 4:03 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 22.10.2014 21:57, Dimitri Liakhovitski wrote:
>>
>> I've read in a wav file using 'tuneR':
>>
>> silence<-readWave("silence0.5sec.wav")
>>
>> I run summary(silence):
>>
>> Wave Object
>> Number of Samples:      22051
>> Duration (seconds):     0.5
>> Samplingrate (Hertz):   44100
>> Channels (Mono/Stereo): Mono
>> PCM (integer format):   TRUE
>> Bit (8/16/24/32/64):    16
>>
>> Summary statistics for channel(s):
>>
>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>        0       0       0       0       0       0
>>
>>
>> I would like to save this file as a lower frequency file so that:
>> Samplingrate (Hertz):   8000
>>
>> Is it possible?
>> I am trying:
>> savewav(silence,filename="silence0.5sec 8000.wav",f=800)
>>
>> But it doesn't work - it saves the file but when I read it in,
>> Samplingrate is still 44100
>>
>
> What is savewav? At least not a tuneR function...
>
> In "tuneR":
>
>
> silence8000 <- downsample(silence, 8000)
> writeWave(silence8000, file="silence0.5sec 8000.wav")
>
> Best,
> Uwe Ligges



-- 
Dimitri Liakhovitski


From dimitri.liakhovitski at gmail.com  Wed Oct 22 23:01:21 2014
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Wed, 22 Oct 2014 17:01:21 -0400
Subject: [R] reducing the sampling rate of a .wav file
In-Reply-To: <54480D8E.2090301@statistik.tu-dortmund.de>
References: <CAN2xGJZE5v4AVxBBRXUOnx_97n1qniW5-S51Mon7h6Z2G5mLZQ@mail.gmail.com>
	<54480D8E.2090301@statistik.tu-dortmund.de>
Message-ID: <CAN2xGJa7iS29Yn8fL=em=dya3r2TR2NRQQKbT_b1JNfo8NF+OQ@mail.gmail.com>

Thank you so much, Uwe!
seavewav is from another package :)

On Wed, Oct 22, 2014 at 4:03 PM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 22.10.2014 21:57, Dimitri Liakhovitski wrote:
>>
>> I've read in a wav file using 'tuneR':
>>
>> silence<-readWave("silence0.5sec.wav")
>>
>> I run summary(silence):
>>
>> Wave Object
>> Number of Samples:      22051
>> Duration (seconds):     0.5
>> Samplingrate (Hertz):   44100
>> Channels (Mono/Stereo): Mono
>> PCM (integer format):   TRUE
>> Bit (8/16/24/32/64):    16
>>
>> Summary statistics for channel(s):
>>
>>     Min. 1st Qu.  Median    Mean 3rd Qu.    Max.
>>        0       0       0       0       0       0
>>
>>
>> I would like to save this file as a lower frequency file so that:
>> Samplingrate (Hertz):   8000
>>
>> Is it possible?
>> I am trying:
>> savewav(silence,filename="silence0.5sec 8000.wav",f=800)
>>
>> But it doesn't work - it saves the file but when I read it in,
>> Samplingrate is still 44100
>>
>
> What is savewav? At least not a tuneR function...
>
> In "tuneR":
>
>
> silence8000 <- downsample(silence, 8000)
> writeWave(silence8000, file="silence0.5sec 8000.wav")
>
> Best,
> Uwe Ligges



-- 
Dimitri Liakhovitski


From zilefacelvis at yahoo.com  Wed Oct 22 23:41:16 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 22 Oct 2014 14:41:16 -0700
Subject: [R] Split fixed width data in R
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED6412C2085C@GOLD.corp.lgc-group.com>
References: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<A4E5A0B016B8CB41A485FC629B633CED6412C2085C@GOLD.corp.lgc-group.com>
Message-ID: <1414014076.37555.YahooMailNeo@web160602.mail.bf1.yahoo.com>

Thanks Ellison.
Just what I wanted.
Cheers.
AT.


On Wednesday, October 22, 2014 10:03 AM, S Ellison <S.Ellison at LGCGroup.com> wrote:
This seems to do a fair bit of it on your example data; you can pull out the date bits separately using Date functions if you need them

decode.lst <- function(x) { 
    data.frame(Date=as.Date(substr(x,1,8), format="%Y%m%d"), 
            Site=substr(x, 9,12), 
            Precipitation=as.numeric(substring(x,13)))
}

decode.lst(lst1Sub)


S Ellison






> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On
> Behalf Of Zilefac Elvis
> Sent: 22 October 2014 16:38
> To: R. Help
> Subject: [R] Split fixed width data in R
> 
> Hi,
> I have fixed width data that I would like to split into columns. Here is a sanpshot
> of the data (actual data is a list object):
> lst1Sub<-
> "20131124GGG1 23.00"
> "20131125GGG1 15.00"
> "20131128GGG1  0.00"
> "201312 1GGG1  0.00"
> "201312 4GGG1  0.00"
> "201312 7GGG1 10.00"
> "20131210GGG1  0.00"
> "20131213GGG1  0.00"
> "20131216GGG1  0.00"
> "20131219GGG1  0.00"
> "20131222GGG1  0.00"
> "20131225GGG1  0.00"
> "20131228GGG1  0.00"
> 
> The following script will split the data into [Year Month Day Site Precipitation]
> ------------------------------------------------------------------------------------------------------
> library(stringr)
> dateSite <- gsub("(.*G.{3}).*","\\1",lst1Sub);
> dat1 <- data.frame(Year=as.numeric(substr(dateSite,1,4)),
> Month=as.numeric(substr(dateSite,5,6)),
> 
> Day=as.numeric(substr(dateSite,7,8)),Site=substr(dateSite,9,12),Rain=substr(dat
> eSite,13,18),stringsAsFactors=FALSE);
> lst3 <- lapply(lst1Sub,function(x) {dateSite <- gsub("(.*G.{3}).*","\\1",x);
>                                     dat1 <-
> data.frame(Year=as.numeric(substr(dateSite,1,4)),
> Month=as.numeric(substr(dateSite,5,6)),Day=as.numeric(substr(dateSite,7,8)),Si
> te=substr(dateSite,9,12),stringsAsFactors=FALSE);
>                                     Sims <-
> str_trim(gsub(".*G.{3}\\s?(.*)","\\1",x));Sims[grep("\\d+-",Sims)] <- gsub("(.*)([-
> ][0-9]+\\.[0-9]+)","\\1 \\2",gsub("^([0-9]+\\.[0-9]+)(.*)","\\1 \\2",
> Sims[grep("\\d+-",Sims)]));
>                                     Sims1 <- read.table(text=Sims,header=FALSE);
> names(Sims1) <- c("Precipitation");dat2 <- cbind(dat1,Sims1)})
> -------------------------------------------------------------------------------------------------------
> -----------------------------------
> 
> Problem: the above script deletes the first value of my precipitation values. For
> example, after splitting, "20131124GGG1 23.00" becomes
> 2013 11 24 GGG1 3.00 INSTEAD of 2013 11 24 GGG1 23.00 (right answer).
> 
> Anything wrong with the string trimming? Is there another way to arrive at the
> same answer?
> 
> Thanks,
> AT.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From dwinsemius at comcast.net  Thu Oct 23 01:17:57 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 22 Oct 2014 16:17:57 -0700
Subject: [R] assignment 2 part 1,2,3
In-Reply-To: <CAGN4sprzL7XvezAdvBeygLvpxEs23BL5Uk-V9V-brjLPK5JcRA@mail.gmail.com>
References: <CAGN4sprzL7XvezAdvBeygLvpxEs23BL5Uk-V9V-brjLPK5JcRA@mail.gmail.com>
Message-ID: <CDEC9961-C1BF-4D50-8C78-C17866FD566D@comcast.net>

You should read the Posting Guide. It makes very clear that no mind reading services are offered.

On Oct 21, 2014, at 9:01 AM, Carlos M Castaneda wrote:

> I am not taking this course for a grade, just self interest. I am stock
> with  making the function. is there any where I can see how is done. I will
> not submit the  home work. I want to use the homework as a tool to
> understand.\ the Coding for R.
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
> and provide commented, minimal, self-contained, reproducible code.
^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

David Winsemius
Alameda, CA, USA


From john.archie.mckown at gmail.com  Thu Oct 23 01:23:32 2014
From: john.archie.mckown at gmail.com (John McKown)
Date: Wed, 22 Oct 2014 18:23:32 -0500
Subject: [R] Split fixed width data in R
In-Reply-To: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
References: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
Message-ID: <CAAJSdjg=6QX1C1+09d+zUmJ+8Amo2axE5AqqsHjQzddDEHmp_g@mail.gmail.com>

On Wed, Oct 22, 2014 at 10:37 AM, Zilefac Elvis <zilefacelvis at yahoo.com>
wrote:

> Hi,
> I have fixed width data that I would like to split into columns. Here is a
> sanpshot of the data (actual data is a list object):
> ?<snip>
>

> Thanks,
> AT.
>
>
?I see you already have an answer that you like. I will add that read.fwf
might also be a possibility. It's difficult for me to tell if that last
column is always 6 characters in length.

file <- textConnection(list_object)
read.fwf(file=file,c(4,2,2,4,6))


-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Thu Oct 23 02:52:59 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 23 Oct 2014 13:52:59 +1300
Subject: [R] assignment 2 part 1,2,3
In-Reply-To: <CDEC9961-C1BF-4D50-8C78-C17866FD566D@comcast.net>
References: <CAGN4sprzL7XvezAdvBeygLvpxEs23BL5Uk-V9V-brjLPK5JcRA@mail.gmail.com>
	<CDEC9961-C1BF-4D50-8C78-C17866FD566D@comcast.net>
Message-ID: <5448516B.9010701@auckland.ac.nz>


Fortune nomination!

cheers,

Rolf

On 23/10/14 12:17, David Winsemius wrote:
> You should read the Posting Guide. It makes very clear that no mind reading services are offered.
>
> On Oct 21, 2014, at 9:01 AM, Carlos M Castaneda wrote:
>
>> I am not taking this course for a grade, just self interest. I am stock
>> with  making the function. is there any where I can see how is done. I will
>> not submit the  home work. I want to use the homework as a tool to
>> understand.\ the Coding for R.
>> Thanks


-- 
Rolf Turner
Technical Editor ANZJS


From zilefacelvis at yahoo.com  Thu Oct 23 03:48:55 2014
From: zilefacelvis at yahoo.com (Zilefac Elvis)
Date: Wed, 22 Oct 2014 18:48:55 -0700
Subject: [R] Split fixed width data in R
In-Reply-To: <CAAJSdjg=6QX1C1+09d+zUmJ+8Amo2axE5AqqsHjQzddDEHmp_g@mail.gmail.com>
References: <1413992262.71326.YahooMailNeo@web160601.mail.bf1.yahoo.com>
	<CAAJSdjg=6QX1C1+09d+zUmJ+8Amo2axE5AqqsHjQzddDEHmp_g@mail.gmail.com>
Message-ID: <1414028935.67603.YahooMailNeo@web160603.mail.bf1.yahoo.com>

Thanks John.
AT.


On Wednesday, October 22, 2014 5:23 PM, John McKown <john.archie.mckown at gmail.com> wrote:
 


On Wed, Oct 22, 2014 at 10:37 AM, Zilefac Elvis <zilefacelvis at yahoo.com>wrote:

Hi,
>I have fixed width data that I would like to split into columns. Here is a sanpshot of the data (actual data is a list object):
>?<snip>

>Thanks,
>AT.
>
>

?I see you already have an answer that you like. I will add that read.fwf might also be a possibility. It's difficult for me to tell if that last column is always 6 characters in length.

file <- textConnection(list_object)
read.fwf(file=file,c(4,2,2,4,6))

-- 
The temperature of the aqueous content of an unremittingly ogled
culinary vessel will not achieve 100 degrees on the Celsius scale.

Maranatha! <><
John McKown 
	[[alternative HTML version deleted]]


From miaojpm at gmail.com  Thu Oct 23 04:30:29 2014
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 23 Oct 2014 10:30:29 +0800
Subject: [R] Add an NA column to a zoo object
Message-ID: <CABcx46B+MBmXEs9MeGeTj6g-Y9nSec8bbyMnBVu19kr39c8=yQ@mail.gmail.com>

Hi ,

  I have a zoo object with several rows fx, r3m, etc. I would like to
create in the zoo object the lag of one column. One thing I can think of is
to create the lag first and then merge it into the original zoo object,
which is tedious. Can I add an NA column to the zoo object first and then
put the lag into the NA column? Thanks!


datz<-zoo(dat, dat[,"date1"])
fxlag3m<-lag(datz[,"fx"], -65, na.pad=TRUE)
datz<-merge(datz, fxlag3m)
> head(datz)
           date       fx     r3m     r6m     r1y     date1      fxlag3m
2009-01-01 2009-01-01  90.90 -7.3500 -7.8500 -8.3000 2009-01-01 <NA>
2009-01-02 2009-01-02  91.16 -7.3458 -8.0487 -8.4645 2009-01-02 <NA>
2009-01-05 2009-01-05  93.19 -6.9000 -7.6000 -8.2500 2009-01-05 <NA>
2009-01-06 2009-01-06  93.97 -6.7000 -7.3500 -8.0500 2009-01-06 <NA>
2009-01-07 2009-01-07  93.23 -6.3500 -7.1000 -7.7000 2009-01-07 <NA>
2009-01-08 2009-01-08  91.63 -6.6500 -7.3500 -7.8000 2009-01-08 <NA>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Oct 23 04:46:42 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 22 Oct 2014 19:46:42 -0700
Subject: [R] Fwd: as.POSIXlt() Function
In-Reply-To: <CAJhrTnogoL19pgDyki4aFCp+3=gB82zr2yavgThGpDzkJcswrw@mail.gmail.com>
References: <CAJhrTnr2XPPWiuogoidy1AFg29OmNAPZHae+Q=SP8Y_PBDhDxQ@mail.gmail.com>
	<CAJhrTnogoL19pgDyki4aFCp+3=gB82zr2yavgThGpDzkJcswrw@mail.gmail.com>
Message-ID: <4FDBAC44-C3AF-4B65-B048-726332E9CA04@dcn.davis.CA.us>

Because PST8PDT probably is not a valid TZ on your operating system. Try "America/LosAngeles"
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 22, 2014 2:35:55 AM PDT, Vasantha Kumar Kesavan <info.vasukv at gmail.com> wrote:
>Hi,
>
>I am a new R user and also not sure about the below concern is really a
>bug,
>
>My concern are listed below,
>
>Look at the below example, when Sys.Date () is called within the
>as.POSIXlt
>() function. Why it is displaying only the date value and the timezone
>is
>selected to UTC even though the TZ variable is set to "PST8PDT".  I
>could
>not see this kind of behavior with as.POSIXct () function.
>
>This is happening in both LINUX 32 and 64 bit operating system.
>
>
>Example:
>
>> version
>               _
>platform       i386-redhat-linux-gnu
>arch           i386
>os             linux-gnu
>system         i386, linux-gnu
>status
>major          2
>minor          10.0
>year           2009
>month          10
>day            26
>svn rev        50208
>language       R
>version.string R version 2.10.0 (2009-10-26)
>> Sys.setenv(TZ="PST8PDT");
>> Sys.setenv(ORA_SDTZ="PST8PDT");
>>
>> Sys.getenv("TZ");
>       TZ
>"PST8PDT"
>> Sys.getenv("ORA_SDTZ");
> ORA_SDTZ
>"PST8PDT"
>>
>> as.POSIXct(Sys.Date());
>[1] "2014-10-20 17:00:00 PDT"
>> c(as.POSIXct(Sys.Date()));
>[1] "2014-10-20 17:00:00 PDT"
>>
>> as.POSIXlt(Sys.Date());
>[1] "2014-10-21 UTC"
>> c(as.POSIXlt(Sys.Date()));
>[1] "2014-10-20 17:00:00 PDT"
>>
>> as.POSIXct(Sys.time());
>[1] "2014-10-21 20:59:23 PDT"
>> c(as.POSIXct(Sys.time()));
>[1] "2014-10-21 20:59:23 PDT"
>>
>> as.POSIXlt(Sys.time());
>[1] "2014-10-21 20:59:23 PDT"
>> c(as.POSIXlt(Sys.time()));
>[1] "2014-10-21 20:59:23 PDT"
>>
>
>Thanks
>Vasanth
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Oct 23 06:15:44 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 22 Oct 2014 21:15:44 -0700
Subject: [R] Fwd: as.POSIXlt() Function
In-Reply-To: <4FDBAC44-C3AF-4B65-B048-726332E9CA04@dcn.davis.CA.us>
References: <CAJhrTnr2XPPWiuogoidy1AFg29OmNAPZHae+Q=SP8Y_PBDhDxQ@mail.gmail.com>
	<CAJhrTnogoL19pgDyki4aFCp+3=gB82zr2yavgThGpDzkJcswrw@mail.gmail.com>
	<4FDBAC44-C3AF-4B65-B048-726332E9CA04@dcn.davis.CA.us>
Message-ID: <C26C9A2E-B2B3-4BB6-A68D-3AAB943BE932@comcast.net>


On Oct 22, 2014, at 7:46 PM, Jeff Newmiller wrote:

> Because PST8PDT probably is not a valid TZ on your operating system. Try "America/LosAngeles"

For me (on a Mac) it has an intervening dash:

> Sys.timezone(location = TRUE)
[1] "America/Los_Angeles"

However, on a mac the system returns a differnt results:

>  Sys.getenv("TZ")
[1] ""

-- 
David.

> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> On October 22, 2014 2:35:55 AM PDT, Vasantha Kumar Kesavan <info.vasukv at gmail.com> wrote:
>> Hi,
>> 
>> I am a new R user and also not sure about the below concern is really a
>> bug,
>> 
>> My concern are listed below,
>> 
>> Look at the below example, when Sys.Date () is called within the
>> as.POSIXlt
>> () function. Why it is displaying only the date value and the timezone
>> is
>> selected to UTC even though the TZ variable is set to "PST8PDT".  I
>> could
>> not see this kind of behavior with as.POSIXct () function.
>> 
>> This is happening in both LINUX 32 and 64 bit operating system.
>> 
>> 
>> Example:
>> 
>>> version
>>              _
>> platform       i386-redhat-linux-gnu
>> arch           i386
>> os             linux-gnu
>> system         i386, linux-gnu
>> status
>> major          2
>> minor          10.0
>> year           2009
>> month          10
>> day            26
>> svn rev        50208
>> language       R
>> version.string R version 2.10.0 (2009-10-26)
>>> Sys.setenv(TZ="PST8PDT");
>>> Sys.setenv(ORA_SDTZ="PST8PDT");
>>> 
>>> Sys.getenv("TZ");
>>      TZ
>> "PST8PDT"
>>> Sys.getenv("ORA_SDTZ");
>> ORA_SDTZ
>> "PST8PDT"
>>> 
>>> as.POSIXct(Sys.Date());
>> [1] "2014-10-20 17:00:00 PDT"
>>> c(as.POSIXct(Sys.Date()));
>> [1] "2014-10-20 17:00:00 PDT"
>>> 
>>> as.POSIXlt(Sys.Date());
>> [1] "2014-10-21 UTC"
>>> c(as.POSIXlt(Sys.Date()));
>> [1] "2014-10-20 17:00:00 PDT"
>>> 
>>> as.POSIXct(Sys.time());
>> [1] "2014-10-21 20:59:23 PDT"
>>> c(as.POSIXct(Sys.time()));
>> [1] "2014-10-21 20:59:23 PDT"
>>> 
>>> as.POSIXlt(Sys.time());
>> [1] "2014-10-21 20:59:23 PDT"
>>> c(as.POSIXlt(Sys.time()));
>> [1] "2014-10-21 20:59:23 PDT"
>>> 
>> 
>> Thanks
>> Vasanth
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From hafizuddinarshad21 at gmail.com  Thu Oct 23 02:29:21 2014
From: hafizuddinarshad21 at gmail.com (Hafizuddin Arshad)
Date: Wed, 22 Oct 2014 17:29:21 -0700
Subject: [R] Merge of the rows by finding the sum of the rows
Message-ID: <CAAPm8OpHZR3oaRTY+Vf0QSouDaDi76Kv-oxtrOUSiMxOXh_i1A@mail.gmail.com>

Dear R users,

Can someone help me on this?  I would like to find the sum of the Rain if
the Month appears more than once. For example in row 3 and 4, October
appear more than once, so I want to find the sum of the two rows and
replace it so that the Month just appear once. It some sort of merge but by
finding the sum for the third column. This is my data:

structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L,
1974L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1976L,
1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L), Month = c(3L,
6L, 10L, 10L, 11L, 11L, 11L, 11L, 12L, 2L, 9L, 12L, 12L, 12L,
12L, 3L, 9L, 10L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 8L, 9L,
11L, 11L, 11L, 11L, 11L, 12L, 12L, 1L, 2L, 4L, 10L, 11L, 12L,
12L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L), Rain = c(196,
88.8, 96, 70.6, 104.9, 80, 102.8, 161.5, 123.4, 70.8, 99, 77.7,
130.8, 134.1, 86.3, 213.3, 169.9, 89.4, 78.7, 81.5, 100.3, 107.1,
93.2, 83.8, 253.2, 75.4, 134.5, 84.5, 82.5, 82.5, 119.5, 119.5,
134.5, 83.5, 372.5, 79.5, 112, 80.5, 129.5, 120.5, 126, 73, 93.5,
86.5, 140.5, 76, 180.5, 75, 130.5, 130.5)), .Names = c("Year",
"Month", "Rain"), row.names = c(NA, 50L), class = "data.frame")

Thank you so much for the help.


Arshad

	[[alternative HTML version deleted]]


From moonkid at posteo.org  Thu Oct 23 03:25:06 2014
From: moonkid at posteo.org (moonkid at posteo.org)
Date: Thu, 23 Oct 2014 03:25:06 +0200
Subject: [R] =?utf-8?q?=5BSweave=5D_doesn=27t_accept_unicode=3F?=
In-Reply-To: <CANROs4d5Av4JOCt+51gvzigzqUwoKJyG7z=0w0S5MGikcfHDMg@mail.gmail.com>
References: <49891056c4600a8052e765867b7f9c3c@posteo.de>
	<54472B6A.7060705@yahoo.fr>
	<CANROs4d5Av4JOCt+51gvzigzqUwoKJyG7z=0w0S5MGikcfHDMg@mail.gmail.com>
Message-ID: <2d629a113414f9184db828ba2cc9aea4@posteo.de>

Maybe your answers are solutions, but not in my case.
As I indicated with my code-sample I don't have a complete tex-file 
(with usepackage, document-env, etc). I only generate a piece of a tex 
file to \input it later in my puplication tex-file.

So there is no way to specifiy an encoding with a \usepackage. Btw: 
XeTeX don't need any specification for the encoding. Loading xunicode 
explicite is not needed.

The answer for Sweave is simple and in the help-page (I should have read 
more carefully before - but it was 3 oclock in the morning).

> Sweave("analy.Snw", encoding="bytes")

Now Sweave don't care about the encoding.


From young_2304 at hotmail.com  Thu Oct 23 03:44:58 2014
From: young_2304 at hotmail.com (escaping)
Date: Wed, 22 Oct 2014 18:44:58 -0700
Subject: [R] how to build a heatmap like this
Message-ID: <BAY173-W25B01028EBBE7E7A9DFFFAFF920@phx.gbl>

Hi, everyone,

I am a new R user, and was required to build several heatmaps as shown in attached file. To reach it, I need to normalize the RPKM data  of exon-level expression to generate Z-score using R. The data looks like
mpleId

			
				geneName

			
				start

			
				end

			
				rpkm

		


				PC10-6

			
				KIF1B

			
				10270764

			
				10270936

			
				4.00059

		


				PC10-6

			
				KIF1B

			
				10292308

			
				10292492

			
				35.3023

		


				PC10-6

			
				KIF1B

			
				10316305

			
				10316381

			
				85.9611

		


				PC10-6

			
				KIF1B

			
				10318551

			
				10318730

			
				64.5961
Exons and introns are required to shown on the heatmap.

Does anyone know how to do it? 

Thanks a lot!

Yizi



  		 	   		  

From Andrew.Hoskins at csiro.au  Thu Oct 23 06:48:37 2014
From: Andrew.Hoskins at csiro.au (Andrew.Hoskins at csiro.au)
Date: Thu, 23 Oct 2014 04:48:37 +0000
Subject: [R] Help with GLM starting values in user defined link function
Message-ID: <4CE25E390851FA45B44CDBF653F0978723212B@ExMBX01-CDC.nexus.csiro.au>

Hi R-list,

I'm trying to fit a binomial GLM with user defined link function (negative exponential), however I seem to be unable to find the correct starting values to initialise such a model. I've tried taking starting values from a logistic and log models fit to the same data and also tried to substitute the intercept from the null model in as the starting value for this model, however all continue to return the same error.

Any help or tips with how to determine some valid starting values (or just to confirm that I've specified the link function correctly) would be greatly appreciated.

See below for some example code.

Andrew


## Example fit of negative exponential binomial GLM

## define link function
negexp <- function()
{
    linkfun <- function(mu) 1-exp(-mu)
    linkinv <- function(eta) -log(1-eta)
    mu.eta <- function(eta) 1/(1-eta)
    valideta <- function(eta) TRUE
    link <- paste0("negexp")
    structure(list(linkfun = linkfun, linkinv = linkinv,
                   mu.eta = mu.eta, valideta = valideta, name = link),
              class = "link-glm")
}

## create some data

y <- c(0,0,0,0,0,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0
                ,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,1,1,0,1,0,1,1,0,1,0,1,0,1,1
                ,0,1,0,0,1,0,0,1,1,1,0,0,1,1,1,1,0,0,0,1,0,1,0,1,0,0)


eco <- c(0.30406146,0.77127034,0.27507740,0.34660849,0.10496959,0.87483283,1.34652163,0.59570289,0.76557945
                ,1.07105129,0.85681582,1.15885519,0.62478718,0.82327890,0.61921331,1.40337615,1.69376337,0.96662890
                ,0.62756558,1.22148480,0.29509170,1.20822702,1.04490241,0.63994034,0.44537652,0.80908805,1.38793219
                ,0.68987695,0.65253113,0.10996619,2.18030035,0.95187860,1.91719194,0.55910638,0.42246265,0.99747093
                ,0.65609015,1.56408171,0.09024976,0.49430176,0.89651639,0.13943031,0.72264673,0.33212781,0.53156567
                ,0.24478163,0.20439708,0.26577897,0.73061755,1.41380646,0.45361391,0.53961802,0.20099582,0.16278695
                ,0.51188479,1.23152701,1.45180489,0.16136045,0.84696597,1.06556860,0.31352700,7.54728452,0.47765713
                ,1.62966928,0.51514442,0.87203787,0.33515181,0.71407043,0.84767445,0.33640927,0.70331392,0.41617675
                ,1.41137914,0.22586531,0.92797131,1.34627407,0.21408341,0.38903027,0.91690877,0.95946623,0.46114617
                ,0.62965571,7.50492235,1.96516642,0.61555184,1.24061426,0.95281453,1.02729643,1.44581350,1.63148077
                ,1.02291891,0.80319545,0.92136436,1.22428318,0.59172977,1.56985149,0.35790202,2.23402940,0.98565537
                ,0.41658919)

geog <- c(254.94615,277.78675,3.69047,47.92363,0.90241,449.44532,1795.89910,985.66843,1063.47287
                ,160.27883,58.72738,1093.00270,1423.51194,1232.16769,54.56121,4772.54353,1877.95322,1110.18161
                ,174.53805,2829.67281,551.22870,1781.67608,495.13007,44.42326,1057.72959,783.99003,3025.58558
                ,1855.59219,1715.27590,41.75478,3687.95693,2125.34324,751.42284,1598.04527,1625.35627,848.40949
                ,1484.40835,3332.15554,214.99678,136.60188,1388.07919,77.21198,2366.56327,617.31749,1421.72213
                ,537.38636,223.57615,256.35456,3022.63678,4783.64718,45.97153,194.79090,2.65647,69.08392
                ,948.66990,1480.70503,2805.30205,144.55345,1134.92666,728.04570,1421.45250,827.57959,1517.75701
                ,682.77014,1060.09369,448.44398,848.64842,1437.74925,2887.23135,56.28056,725.78408,91.19194
                ,1905.87208,749.92265,261.19075,2529.80027,371.16338,1130.14904,802.23348,1851.86105,1274.20599
                ,260.79728,1427.11459,3891.82373,482.58143,2011.86414,1310.10546,975.37470,1087.50127,2195.28667
                ,2358.70761,44.82955,1553.35558,2261.60567,1216.64486,1674.70189,165.13405,1463.93362,1542.33074
                ,1683.01992)

testDat <- data.frame(y,eco,geog)


## Fit model (doesn't work)
fit <- glm(y ~ eco + geog,data=testDat,family=binomial(negexp()))

## try logistic to get starting values (doesn't work)
fit.logit <- glm(y ~ eco + geog,data=testDat,family=binomial(logit))
fit <- glm(y ~ eco + geog,data=testDat,family=binomial(negexp()),start=coef(fit.logit))

## try quasibinomial log (doesn't work)
fit.log <- glm(y ~ eco + geog,data=testDat,family=quasibinomial(log),start=c(-1,0,0))
fit <- glm(y ~ eco + geog,data=testDat,family=binomial(negexp()),start=coef(fit.log))

## try null with 0.5 for other coefs (doesn't work)
fit.null <- glm(y ~ 1,data=testDat,family=binomial(negexp()))
fit <- glm(y ~ eco + geog,data=testDat,family=binomial(negexp()),start=c(coef(fit.null),0.5,0.5))

## try again (null intercept, logit coefs)
fit <- glm(y ~ eco + geog,data=testDat,family=binomial(negexp()),start=c(coef(fit.null),coef(fit.logit)[2:3]))

## try again (null intercept, log coefs)
fit <- glm(y ~ eco + geog,data=testDat,family=binomial(negexp()),start=c(coef(fit.null),coef(fit.log)[2:3]))

Andrew Hoskins
Postdoctoral reasearch fellow
Ecosystem Sciences
CSIRO

E Andrew.Hoskins at csiro.au T +61 2 6246 5902
Black Mountain Laboratories
Clunies Ross Street, Acton, ACT 2601, Australia
www.csiro.au

PLEASE NOTE
The information contained in this email may be confidential or privileged. Any unauthorised use or disclosure is prohibited. If you have received this email in error, please delete it immediately and notify the sender by return email. Thank you. To the extent permitted by law, CSIRO does not represent, warrant and/or guarantee that the integrity of this communication has been maintained or that the communication is free of errors, virus, interception or interference.

Please consider the environment before printing this email.


	[[alternative HTML version deleted]]


From bronder1 at duq.edu  Thu Oct 23 07:54:26 2014
From: bronder1 at duq.edu (Stephen Bronder)
Date: Thu, 23 Oct 2014 05:54:26 +0000
Subject: [R] New package PANICr: Looking for reviewer for vignette
Message-ID: <1414043664930.53713@duq.edu>

Hello!


I recently finished a package that performs nonstationarity tests for large panels and was wondering if anyone would be willing to read over the vignette I wrote. The package uses the PANIC methodology from Bai and Ng (2004, 2010) and is currently available on github. This is the first vignette I have ever written so I would appreciate comments and feedback.


The PANICr package vignette and github are linked below:


https://steve-bronder.squarespace.com/panic-vignette/


https://github.com/Stevo15025/PANICr


Take care,


Steve Bronder


	[[alternative HTML version deleted]]


From info.vasukv at gmail.com  Thu Oct 23 08:56:16 2014
From: info.vasukv at gmail.com (Vasantha Kumar Kesavan)
Date: Thu, 23 Oct 2014 12:26:16 +0530
Subject: [R] Fwd: as.POSIXlt() Function
In-Reply-To: <C26C9A2E-B2B3-4BB6-A68D-3AAB943BE932@comcast.net>
References: <CAJhrTnr2XPPWiuogoidy1AFg29OmNAPZHae+Q=SP8Y_PBDhDxQ@mail.gmail.com>
	<CAJhrTnogoL19pgDyki4aFCp+3=gB82zr2yavgThGpDzkJcswrw@mail.gmail.com>
	<4FDBAC44-C3AF-4B65-B048-726332E9CA04@dcn.davis.CA.us>
	<C26C9A2E-B2B3-4BB6-A68D-3AAB943BE932@comcast.net>
Message-ID: <CAJhrTnqdKkjsEvFT56_hkEHFBiXzY2_jZDO6TztYHqt6H7f4ng@mail.gmail.com>

PST8PDT is the valid timezone in my machine and I have verified it.

I am followed your suggestion. there is no difference in the output.


*> Sys.setenv(TZ="America/Los_Angeles");*
*> Sys.getenv("TZ");*
*                   TZ *
*"America/Los_Angeles" *
*> as.POSIXlt(Sys.Date());*
*[1] "2014-10-22 UTC"*
*> as.POSIXct(Sys.Date());*
*[1] "2014-10-21 17:00:00 PDT"*
*> as.POSIXct(Sys.time());*
*[1] "2014-10-22 23:53:39 PDT"*
*> as.POSIXlt(Sys.time());*
*[1] "2014-10-22 23:53:43 PDT"*


[root at srv1 ~]# ls /usr/share/zoneinfo
Africa      Asia       Canada   Cuba   EST      Factory  GMT0
Hongkong  Iran         Japan      Mexico   Navajo   Poland      PRC
 ROK        Universal  W-SU
*America*     Atlantic   CET      EET    EST5EDT  GB       GMT-0      HST
    iso3166.tab  Kwajalein  Mideast  NZ       Portugal    *PST8PDT*
 Singapore  US         zone.tab
Antarctica  Australia  Chile    Egypt  Etc      GB-Eire  GMT+0      Iceland
  Israel       Libya      MST      NZ-CHAT  posix       right    Turkey
UTC        Zulu
Arctic      Brazil     CST6CDT  Eire   Europe   GMT      Greenwich  Indian
   Jamaica      MET        MST7MDT  Pacific  posixrules  ROC      UCT
 WET
[root at srv1 ~]#

Thanks
Vasanth

On Thu, Oct 23, 2014 at 9:45 AM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On Oct 22, 2014, at 7:46 PM, Jeff Newmiller wrote:
>
> > Because PST8PDT probably is not a valid TZ on your operating system. Try
> "America/LosAngeles"
>
> For me (on a Mac) it has an intervening dash:
>
> > Sys.timezone(location = TRUE)
> [1] "America/Los_Angeles"
>
> However, on a mac the system returns a differnt results:
>
> >  Sys.getenv("TZ")
> [1] ""
>
> --
> David.
>
> >
> ---------------------------------------------------------------------------
> > Jeff Newmiller                        The     .....       .....  Go
> Live...
> > DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
> >                                      Live:   OO#.. Dead: OO#..  Playing
> > Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> > /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> >
> ---------------------------------------------------------------------------
> > Sent from my phone. Please excuse my brevity.
> >
> > On October 22, 2014 2:35:55 AM PDT, Vasantha Kumar Kesavan <
> info.vasukv at gmail.com> wrote:
> >> Hi,
> >>
> >> I am a new R user and also not sure about the below concern is really a
> >> bug,
> >>
> >> My concern are listed below,
> >>
> >> Look at the below example, when Sys.Date () is called within the
> >> as.POSIXlt
> >> () function. Why it is displaying only the date value and the timezone
> >> is
> >> selected to UTC even though the TZ variable is set to "PST8PDT".  I
> >> could
> >> not see this kind of behavior with as.POSIXct () function.
> >>
> >> This is happening in both LINUX 32 and 64 bit operating system.
> >>
> >>
> >> Example:
> >>
> >>> version
> >>              _
> >> platform       i386-redhat-linux-gnu
> >> arch           i386
> >> os             linux-gnu
> >> system         i386, linux-gnu
> >> status
> >> major          2
> >> minor          10.0
> >> year           2009
> >> month          10
> >> day            26
> >> svn rev        50208
> >> language       R
> >> version.string R version 2.10.0 (2009-10-26)
> >>> Sys.setenv(TZ="PST8PDT");
> >>> Sys.setenv(ORA_SDTZ="PST8PDT");
> >>>
> >>> Sys.getenv("TZ");
> >>      TZ
> >> "PST8PDT"
> >>> Sys.getenv("ORA_SDTZ");
> >> ORA_SDTZ
> >> "PST8PDT"
> >>>
> >>> as.POSIXct(Sys.Date());
> >> [1] "2014-10-20 17:00:00 PDT"
> >>> c(as.POSIXct(Sys.Date()));
> >> [1] "2014-10-20 17:00:00 PDT"
> >>>
> >>> as.POSIXlt(Sys.Date());
> >> [1] "2014-10-21 UTC"
> >>> c(as.POSIXlt(Sys.Date()));
> >> [1] "2014-10-20 17:00:00 PDT"
> >>>
> >>> as.POSIXct(Sys.time());
> >> [1] "2014-10-21 20:59:23 PDT"
> >>> c(as.POSIXct(Sys.time()));
> >> [1] "2014-10-21 20:59:23 PDT"
> >>>
> >>> as.POSIXlt(Sys.time());
> >> [1] "2014-10-21 20:59:23 PDT"
> >>> c(as.POSIXlt(Sys.time()));
> >> [1] "2014-10-21 20:59:23 PDT"
> >>>
> >>
> >> Thanks
> >> Vasanth
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From rainer.schuermann at gmx.net  Thu Oct 23 11:40:23 2014
From: rainer.schuermann at gmx.net (R)
Date: Thu, 23 Oct 2014 11:40:23 +0200
Subject: [R] Installing gWidgetsRGtk2: R session is headless
Message-ID: <201410231140.23254.rainer.schuermann@gmx.net>

I have written some gWidgets scripts before in the past but have a different box now (Debian KWheezy) and cannot get gWidgets working. It may be an obvious mistake but auntie Google (who has helped me a lot to get as far as I am now) leaves me in the dark now.
Here is where I am stuck:
- - - - -
> library( gWidgets )
> library( gWidgetsRGtk2 )
Loading required package: RGtk2
No protocol specified
R session is headless; GTK+ not initialized.
>  obj <- gbutton("Hello world", container = gwindow())

(R:15675): GLib-GObject-WARNING **: invalid (NULL) pointer instance

(R:15675): GLib-GObject-CRITICAL **: g_signal_connect_data: assertion `G_TYPE_CHECK_INSTANCE (instance)' failed

(R:15675): Gtk-WARNING **: Screen for GtkWindow not set; you must always set
a screen for a GtkWindow before using the window

(R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_default_colormap: assertion `GDK_IS_SCREEN (screen)' failed

(R:15675): Gdk-CRITICAL **: IA__gdk_colormap_get_visual: assertion `GDK_IS_COLORMAP (colormap)' failed

(R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_default_colormap: assertion `GDK_IS_SCREEN (screen)' failed

(R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_root_window: assertion `GDK_IS_SCREEN (screen)' failed

(R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_root_window: assertion `GDK_IS_SCREEN (screen)' failed

(R:15675): Gdk-CRITICAL **: IA__gdk_window_new: assertion `GDK_IS_WINDOW (parent)' failed

 *** caught segfault ***
address 0x18, cause 'memory not mapped'

Traceback:
 1: .Call(name, ..., PACKAGE = PACKAGE)
 2: .RGtkCall("S_gtk_widget_show", object, PACKAGE = "RGtk2")
 3: method(obj, ...)
 4: window$Show()
 5: .gwindow(toolkit, title, visible, width, height, parent, handler,     action, ...)
 6: .gwindow(toolkit, title, visible, width, height, parent, handler,     action, ...)
 7: gwindow()
 8: .gbutton(toolkit, text, border, handler, action, container, ...)
 9: .gbutton(toolkit, text, border, handler, action, container, ...)
10: gbutton("Hello world", container = gwindow())


- - - - -
> sessionInfo()                                                                                                                                                                            
R version 3.1.1 (2014-07-10)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.1.1


From ruipbarradas at sapo.pt  Thu Oct 23 11:46:40 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 23 Oct 2014 10:46:40 +0100
Subject: [R] Merge of the rows by finding the sum of the rows
In-Reply-To: <CAAPm8OpHZR3oaRTY+Vf0QSouDaDi76Kv-oxtrOUSiMxOXh_i1A@mail.gmail.com>
References: <CAAPm8OpHZR3oaRTY+Vf0QSouDaDi76Kv-oxtrOUSiMxOXh_i1A@mail.gmail.com>
Message-ID: <5448CE80.7060204@sapo.pt>

Hello,

Try

aggregate(Rain ~ Year + Month, data = dat, FUN = sum)


Hope this helps,

Rui Barradas

Em 23-10-2014 01:29, Hafizuddin Arshad escreveu:
> Dear R users,
>
> Can someone help me on this?  I would like to find the sum of the Rain if
> the Month appears more than once. For example in row 3 and 4, October
> appear more than once, so I want to find the sum of the two rows and
> replace it so that the Month just appear once. It some sort of merge but by
> finding the sum for the third column. This is my data:
>
> structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
> 1971L, 1971L, 1971L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
> 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
> 1973L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L,
> 1974L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1976L,
> 1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L), Month = c(3L,
> 6L, 10L, 10L, 11L, 11L, 11L, 11L, 12L, 2L, 9L, 12L, 12L, 12L,
> 12L, 3L, 9L, 10L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 8L, 9L,
> 11L, 11L, 11L, 11L, 11L, 12L, 12L, 1L, 2L, 4L, 10L, 11L, 12L,
> 12L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L), Rain = c(196,
> 88.8, 96, 70.6, 104.9, 80, 102.8, 161.5, 123.4, 70.8, 99, 77.7,
> 130.8, 134.1, 86.3, 213.3, 169.9, 89.4, 78.7, 81.5, 100.3, 107.1,
> 93.2, 83.8, 253.2, 75.4, 134.5, 84.5, 82.5, 82.5, 119.5, 119.5,
> 134.5, 83.5, 372.5, 79.5, 112, 80.5, 129.5, 120.5, 126, 73, 93.5,
> 86.5, 140.5, 76, 180.5, 75, 130.5, 130.5)), .Names = c("Year",
> "Month", "Rain"), row.names = c(NA, 50L), class = "data.frame")
>
> Thank you so much for the help.
>
>
> Arshad
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From S.Ellison at LGCGroup.com  Thu Oct 23 12:22:57 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 23 Oct 2014 11:22:57 +0100
Subject: [R] assignment 2 part 1,2,3
In-Reply-To: <CAGN4sprzL7XvezAdvBeygLvpxEs23BL5Uk-V9V-brjLPK5JcRA@mail.gmail.com>
References: <CAGN4sprzL7XvezAdvBeygLvpxEs23BL5Uk-V9V-brjLPK5JcRA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412CC44B6@GOLD.corp.lgc-group.com>

> I am not taking this course for a grade, just self interest. I am stock with
> making the function. is there any where I can see how is done. 

Go to the HTML help for R and read "An Introduction to R", section 10, "Writing your own functions" (the clue's in the title). Don't miss out section 10.7, "Scope"; it's important, but follows 'advanced examples' which are less important for a beginner.

After that, Google.

And after that, R-help again.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ntfredo at gmail.com  Thu Oct 23 14:33:31 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 23 Oct 2014 15:33:31 +0300
Subject: [R] Computing Water Balance using a loop.
Message-ID: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>

Dear All,

I want to calculate water balance using the following formula:
Water balance today = Water balance yesterday + Rainfall ? Evaporation

This is a sample of data I am using:

head(Wb30)
  May Rainfall Evaporation Water_Balance
1   7        0           5             0
2   8       10           5            NA
3   9        0           5            NA
4  10        0           5            NA
5  11        2           5            NA
6  12       23           5            NA

The following is the loop am trying to use but it is not working well.

#Water balance today = Water balance yesterday + Rainfall ? Evaporation
#If Water balance today < 0 then Water balance today = 0
#If Water balance today > 100 then Water balance today = 100
wb=c()
for (w in 1:length(Wb30$Water_Balance)){
  if(w<0 & w>100){w<-0 & w<-100}
  #print (w);
 for (i in 1:length(Wb30$Rainfall)){
    for (j in 1:length(Wb30$Evaporation)){
    }
  }
 wb<-Wb30$Water_Balance[w] + Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]
}
wb

Any suggest of what I am missing for it to work correctly is welcome.


Regards,

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Oct 23 14:44:36 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 23 Oct 2014 08:44:36 -0400
Subject: [R] Computing Water Balance using a loop.
In-Reply-To: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
References: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
Message-ID: <5448F834.9000002@gmail.com>

On 23/10/2014, 8:33 AM, Frederic Ntirenganya wrote:
> Dear All,
> 
> I want to calculate water balance using the following formula:
> Water balance today = Water balance yesterday + Rainfall ? Evaporation
> 
> This is a sample of data I am using:
> 
> head(Wb30)
>   May Rainfall Evaporation Water_Balance
> 1   7        0           5             0
> 2   8       10           5            NA
> 3   9        0           5            NA
> 4  10        0           5            NA
> 5  11        2           5            NA
> 6  12       23           5            NA
> 
> The following is the loop am trying to use but it is not working well.
> 
> #Water balance today = Water balance yesterday + Rainfall ? Evaporation
> #If Water balance today < 0 then Water balance today = 0
> #If Water balance today > 100 then Water balance today = 100
> wb=c()
> for (w in 1:length(Wb30$Water_Balance)){
>   if(w<0 & w>100){w<-0 & w<-100}

The line above doesn't make sense.  It is impossible for w to be both
less than 0 and greater than 100, so the condition will never be true.
And if it is true, "w<-0 & w<-100" is not a sensible thing to do.

>   #print (w);
>  for (i in 1:length(Wb30$Rainfall)){
>     for (j in 1:length(Wb30$Evaporation)){
>     }
>   }

Those loops do nothing.

>  wb<-Wb30$Water_Balance[w] + Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]

Those should be using w-1 in place of w, and w in place of i+1 and j+1.

Duncan Murdoch

> }
> wb
> 
> Any suggest of what I am missing for it to work correctly is welcome.
> 
> 
> Regards,
> 
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rsherry8 at comcast.net  Thu Oct 23 14:56:59 2014
From: rsherry8 at comcast.net (Robert Sherry)
Date: Thu, 23 Oct 2014 08:56:59 -0400
Subject: [R] Help Getting the Price of Gold
Message-ID: <5448FB1B.5010407@comcast.net>

I am trying to get the current price of gold for my application. I am 
using the library quantmod. The
R commands I use are:
      getMetals(c('XAU'), from=Sys.Date(), autoassign = FALSE )
      XAUUSD$XAU.USD[1,1]

I would expect the value in  XAUUSD$XAU.USD[1,1] to be a scalar but it 
comes back with a date and a number. All I want is the current value, 
not today's date. How do I just get the value?

Thanks
Bob

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Thu Oct 23 15:13:56 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 23 Oct 2014 09:13:56 -0400
Subject: [R] Help Getting the Price of Gold
In-Reply-To: <5448FB1B.5010407@comcast.net>
References: <5448FB1B.5010407@comcast.net>
Message-ID: <5448FF14.1040601@gmail.com>

On 23/10/2014, 8:56 AM, Robert Sherry wrote:
> I am trying to get the current price of gold for my application. I am 
> using the library quantmod. The
> R commands I use are:
>       getMetals(c('XAU'), from=Sys.Date(), autoassign = FALSE )
>       XAUUSD$XAU.USD[1,1]
> 
> I would expect the value in  XAUUSD$XAU.USD[1,1] to be a scalar but it 
> comes back with a date and a number. All I want is the current value, 
> not today's date. How do I just get the value?

That function returns time series objects (of class c("xts", "zoo")).
Use as.numeric() to convert to plain numbers, e.g.

as.numeric(XAUUSD$XAU.USD[1,1])

Duncan Murdoch


From ntfredo at gmail.com  Thu Oct 23 15:35:27 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Thu, 23 Oct 2014 16:35:27 +0300
Subject: [R] Computing Water Balance using a loop.
In-Reply-To: <5448F834.9000002@gmail.com>
References: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
	<5448F834.9000002@gmail.com>
Message-ID: <CAGh51gQqEzqcrGs0BhHn6Aj+z1aRf3sGcgv8JdrsCRHoWfCthw@mail.gmail.com>

Dear Duncan,

Those condition should be there and also look at Rainfall and evaporation
columns.
If i change it to be like the following loop, it can't do it.

The problem is how to include those conditions and also respect the formula?

wb=c()
for (w in 1:length(Wb30$Water_Balance)){
  if(w<0){
   w=0
  }

 wb=Wb30$Water_Balance[w-1] + Wb30$Rainfall[w]-Wb30$Evaporation[w]
}
wb

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Thu, Oct 23, 2014 at 3:44 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 23/10/2014, 8:33 AM, Frederic Ntirenganya wrote:
> > Dear All,
> >
> > I want to calculate water balance using the following formula:
> > Water balance today = Water balance yesterday + Rainfall ? Evaporation
> >
> > This is a sample of data I am using:
> >
> > head(Wb30)
> >   May Rainfall Evaporation Water_Balance
> > 1   7        0           5             0
> > 2   8       10           5            NA
> > 3   9        0           5            NA
> > 4  10        0           5            NA
> > 5  11        2           5            NA
> > 6  12       23           5            NA
> >
> > The following is the loop am trying to use but it is not working well.
> >
> > #Water balance today = Water balance yesterday + Rainfall ? Evaporation
> > #If Water balance today < 0 then Water balance today = 0
> > #If Water balance today > 100 then Water balance today = 100
> > wb=c()
> > for (w in 1:length(Wb30$Water_Balance)){
> >   if(w<0 & w>100){w<-0 & w<-100}
>
> The line above doesn't make sense.  It is impossible for w to be both
> less than 0 and greater than 100, so the condition will never be true.
> And if it is true, "w<-0 & w<-100" is not a sensible thing to do.
>
> >   #print (w);
> >  for (i in 1:length(Wb30$Rainfall)){
> >     for (j in 1:length(Wb30$Evaporation)){
> >     }
> >   }
>
> Those loops do nothing.
>
> >  wb<-Wb30$Water_Balance[w] + Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]
>
> Those should be using w-1 in place of w, and w in place of i+1 and j+1.
>
> Duncan Murdoch
>
> > }
> > wb
> >
> > Any suggest of what I am missing for it to work correctly is welcome.
> >
> >
> > Regards,
> >
> > Frederic Ntirenganya
> > Maseno University,
> > African Maths Initiative,
> > Kenya.
> > Mobile:(+254)718492836
> > Email: fredo at aims.ac.za
> > https://sites.google.com/a/aims.ac.za/fredo/
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Thu Oct 23 16:23:15 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 23 Oct 2014 07:23:15 -0700
Subject: [R] Computing Water Balance using a loop.
In-Reply-To: <CAGh51gQqEzqcrGs0BhHn6Aj+z1aRf3sGcgv8JdrsCRHoWfCthw@mail.gmail.com>
References: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
	<5448F834.9000002@gmail.com>
	<CAGh51gQqEzqcrGs0BhHn6Aj+z1aRf3sGcgv8JdrsCRHoWfCthw@mail.gmail.com>
Message-ID: <BCAD0CCB-FCBB-4B1F-AF9F-CD0A9E2FDECB@dcn.davis.CA.us>

Counting chickens after they have left the coop is not going to work. If your inputs push w outside the limits of physics then your input data are invalid. Arbitrarily forcing w to fit in that case partially ignores the inputs anyway... and since there are many ways for the data to be invalid you should be trying to understand how your data are invalid so you can figure out if you can extract any meaning from it. Drift? Random (lots of ways... which)? Offset? Marking the bad records in a new status column is a start... blindly proceeding to pretend as though there were no problem in the data is deceptive.

Once you get the input data cleaned up so you don't need to butcher the output, the R way to do this is

Wb30$Water_Balance <- with( Wb30, cumsum( Rainfall - Evaporation ) )
Wb30$ValidWB <- with( Wb30, 0 == cumsum( 0 <= Water_Balance & Water_Balance <= 100 ) )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2014 6:35:27 AM PDT, Frederic Ntirenganya <ntfredo at gmail.com> wrote:
>Dear Duncan,
>
>Those condition should be there and also look at Rainfall and
>evaporation
>columns.
>If i change it to be like the following loop, it can't do it.
>
>The problem is how to include those conditions and also respect the
>formula?
>
>wb=c()
>for (w in 1:length(Wb30$Water_Balance)){
>  if(w<0){
>   w=0
>  }
>
> wb=Wb30$Water_Balance[w-1] + Wb30$Rainfall[w]-Wb30$Evaporation[w]
>}
>wb
>
>Regards,
>Frederic.
>
>Frederic Ntirenganya
>Maseno University,
>African Maths Initiative,
>Kenya.
>Mobile:(+254)718492836
>Email: fredo at aims.ac.za
>https://sites.google.com/a/aims.ac.za/fredo/
>
>On Thu, Oct 23, 2014 at 3:44 PM, Duncan Murdoch
><murdoch.duncan at gmail.com>
>wrote:
>
>> On 23/10/2014, 8:33 AM, Frederic Ntirenganya wrote:
>> > Dear All,
>> >
>> > I want to calculate water balance using the following formula:
>> > Water balance today = Water balance yesterday + Rainfall ?
>Evaporation
>> >
>> > This is a sample of data I am using:
>> >
>> > head(Wb30)
>> >   May Rainfall Evaporation Water_Balance
>> > 1   7        0           5             0
>> > 2   8       10           5            NA
>> > 3   9        0           5            NA
>> > 4  10        0           5            NA
>> > 5  11        2           5            NA
>> > 6  12       23           5            NA
>> >
>> > The following is the loop am trying to use but it is not working
>well.
>> >
>> > #Water balance today = Water balance yesterday + Rainfall ?
>Evaporation
>> > #If Water balance today < 0 then Water balance today = 0
>> > #If Water balance today > 100 then Water balance today = 100
>> > wb=c()
>> > for (w in 1:length(Wb30$Water_Balance)){
>> >   if(w<0 & w>100){w<-0 & w<-100}
>>
>> The line above doesn't make sense.  It is impossible for w to be both
>> less than 0 and greater than 100, so the condition will never be
>true.
>> And if it is true, "w<-0 & w<-100" is not a sensible thing to do.
>>
>> >   #print (w);
>> >  for (i in 1:length(Wb30$Rainfall)){
>> >     for (j in 1:length(Wb30$Evaporation)){
>> >     }
>> >   }
>>
>> Those loops do nothing.
>>
>> >  wb<-Wb30$Water_Balance[w] +
>Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]
>>
>> Those should be using w-1 in place of w, and w in place of i+1 and
>j+1.
>>
>> Duncan Murdoch
>>
>> > }
>> > wb
>> >
>> > Any suggest of what I am missing for it to work correctly is
>welcome.
>> >
>> >
>> > Regards,
>> >
>> > Frederic Ntirenganya
>> > Maseno University,
>> > African Maths Initiative,
>> > Kenya.
>> > Mobile:(+254)718492836
>> > Email: fredo at aims.ac.za
>> > https://sites.google.com/a/aims.ac.za/fredo/
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Oct 23 16:30:25 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 23 Oct 2014 07:30:25 -0700
Subject: [R] Computing Water Balance using a loop.
In-Reply-To: <BCAD0CCB-FCBB-4B1F-AF9F-CD0A9E2FDECB@dcn.davis.CA.us>
References: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
	<5448F834.9000002@gmail.com>
	<CAGh51gQqEzqcrGs0BhHn6Aj+z1aRf3sGcgv8JdrsCRHoWfCthw@mail.gmail.com>
	<BCAD0CCB-FCBB-4B1F-AF9F-CD0A9E2FDECB@dcn.davis.CA.us>
Message-ID: <6F833BCC-EA43-4328-983A-5B79D1B48AFE@dcn.davis.CA.us>

Sorry... That last expression was backward...

Wb30$ValidWB <- with( Wb30, 0 == cumsum( Water_Balance < 0 | 100 < Water_Balance ) )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2014 7:23:15 AM PDT, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>Counting chickens after they have left the coop is not going to work.
>If your inputs push w outside the limits of physics then your input
>data are invalid. Arbitrarily forcing w to fit in that case partially
>ignores the inputs anyway... and since there are many ways for the data
>to be invalid you should be trying to understand how your data are
>invalid so you can figure out if you can extract any meaning from it.
>Drift? Random (lots of ways... which)? Offset? Marking the bad records
>in a new status column is a start... blindly proceeding to pretend as
>though there were no problem in the data is deceptive.
>
>Once you get the input data cleaned up so you don't need to butcher the
>output, the R way to do this is
>
>Wb30$Water_Balance <- with( Wb30, cumsum( Rainfall - Evaporation ) )
>Wb30$ValidWB <- with( Wb30, 0 == cumsum( 0 <= Water_Balance &
>Water_Balance <= 100 ) )
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------
>
>Sent from my phone. Please excuse my brevity.
>
>On October 23, 2014 6:35:27 AM PDT, Frederic Ntirenganya
><ntfredo at gmail.com> wrote:
>>Dear Duncan,
>>
>>Those condition should be there and also look at Rainfall and
>>evaporation
>>columns.
>>If i change it to be like the following loop, it can't do it.
>>
>>The problem is how to include those conditions and also respect the
>>formula?
>>
>>wb=c()
>>for (w in 1:length(Wb30$Water_Balance)){
>>  if(w<0){
>>   w=0
>>  }
>>
>> wb=Wb30$Water_Balance[w-1] + Wb30$Rainfall[w]-Wb30$Evaporation[w]
>>}
>>wb
>>
>>Regards,
>>Frederic.
>>
>>Frederic Ntirenganya
>>Maseno University,
>>African Maths Initiative,
>>Kenya.
>>Mobile:(+254)718492836
>>Email: fredo at aims.ac.za
>>https://sites.google.com/a/aims.ac.za/fredo/
>>
>>On Thu, Oct 23, 2014 at 3:44 PM, Duncan Murdoch
>><murdoch.duncan at gmail.com>
>>wrote:
>>
>>> On 23/10/2014, 8:33 AM, Frederic Ntirenganya wrote:
>>> > Dear All,
>>> >
>>> > I want to calculate water balance using the following formula:
>>> > Water balance today = Water balance yesterday + Rainfall ?
>>Evaporation
>>> >
>>> > This is a sample of data I am using:
>>> >
>>> > head(Wb30)
>>> >   May Rainfall Evaporation Water_Balance
>>> > 1   7        0           5             0
>>> > 2   8       10           5            NA
>>> > 3   9        0           5            NA
>>> > 4  10        0           5            NA
>>> > 5  11        2           5            NA
>>> > 6  12       23           5            NA
>>> >
>>> > The following is the loop am trying to use but it is not working
>>well.
>>> >
>>> > #Water balance today = Water balance yesterday + Rainfall ?
>>Evaporation
>>> > #If Water balance today < 0 then Water balance today = 0
>>> > #If Water balance today > 100 then Water balance today = 100
>>> > wb=c()
>>> > for (w in 1:length(Wb30$Water_Balance)){
>>> >   if(w<0 & w>100){w<-0 & w<-100}
>>>
>>> The line above doesn't make sense.  It is impossible for w to be
>both
>>> less than 0 and greater than 100, so the condition will never be
>>true.
>>> And if it is true, "w<-0 & w<-100" is not a sensible thing to do.
>>>
>>> >   #print (w);
>>> >  for (i in 1:length(Wb30$Rainfall)){
>>> >     for (j in 1:length(Wb30$Evaporation)){
>>> >     }
>>> >   }
>>>
>>> Those loops do nothing.
>>>
>>> >  wb<-Wb30$Water_Balance[w] +
>>Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]
>>>
>>> Those should be using w-1 in place of w, and w in place of i+1 and
>>j+1.
>>>
>>> Duncan Murdoch
>>>
>>> > }
>>> > wb
>>> >
>>> > Any suggest of what I am missing for it to work correctly is
>>welcome.
>>> >
>>> >
>>> > Regards,
>>> >
>>> > Frederic Ntirenganya
>>> > Maseno University,
>>> > African Maths Initiative,
>>> > Kenya.
>>> > Mobile:(+254)718492836
>>> > Email: fredo at aims.ac.za
>>> > https://sites.google.com/a/aims.ac.za/fredo/
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>>
>>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rsherry8 at comcast.net  Thu Oct 23 16:42:49 2014
From: rsherry8 at comcast.net (Robert Sherry)
Date: Thu, 23 Oct 2014 10:42:49 -0400
Subject: [R] Problem getting Option Quotes
Message-ID: <544913E9.3070205@comcast.net>


I am using R and quantmod to get stock and option quotes. However, it 
has stopped working. I expect the following
function call to produce a list of options:
         getOptionChain( "XOM", Exp = "2015-01-20" )
However, I get the following error messages:
     Error in lapply(strsplit(opt, "<tr>"), function(.) gsub(",", "", 
gsub("N/A",  :
       subscript out of bounds
     In addition: Warning message:
     In readLines(paste(paste("http://finance.yahoo.com/q/op?s=", 
Symbols,  :
       incomplete final line found on 
'http://finance.yahoo.com/q/op?s=XOM&m=2015-01-20+Options'

Has something changed? Am I doing something wrong?

Thanks
Bob


From ken.knoblauch at inserm.fr  Thu Oct 23 17:27:09 2014
From: ken.knoblauch at inserm.fr (Ken Knoblauch)
Date: Thu, 23 Oct 2014 15:27:09 +0000
Subject: [R] Help with GLM starting values in user defined link function
References: <4CE25E390851FA45B44CDBF653F0978723212B@ExMBX01-CDC.nexus.csiro.au>
Message-ID: <loom.20141023T170850-770@post.gmane.org>

 <Andrew.Hoskins <at> csiro.au> writes:
> I'm trying to fit a binomial GLM with user defined
 link
 function (negative exponential), however I seem to
> be unable to find the correct starting values to 
initialise such a model. I've tried taking starting
> values from a logistic and log models fit to the 
same data and also tried to substitute the intercept 
from
> the null model in as the starting value for this 
model, however all continue to return the same error.
> 
> Andrew
> 
> ## Example fit of negative exponential binomial 
GLM
> 
> ## define link function
> negexp <- function()
> {
>     linkfun <- function(mu) 1-exp(-mu)
>     linkinv <- function(eta) -log(1-eta)
>     mu.eta <- function(eta) 1/(1-eta)
>     valideta <- function(eta) TRUE
>     link <- paste0("negexp")
>     structure(list(linkfun = linkfun, linkinv = linkinv,
>                    mu.eta = mu.eta, valideta = valideta, 
name = link),
>               class = "link-glm")
> }
> 
---SNIP---

Take a look at the limits of eta for the extreme values 
of mu and compare them with the linear predictor of 
your link applied to say the fitted values of your logit 
fit.  It seems to suggest that two values fall outside 
the range of valid eta, according to your linkfun: 
c(62, 83).  I got it to work
with these removed although there were lots of other
warnings that you might have to worry about.
Also, when choosing start values you might want
to base them on a fit with your link rather than
a different one. So, I got start values by trying

EV <- negexp()$linkfun(fitted(fit.logit))
LE.lm <- lm(EV ~ eco + geog, testDat)    
Ec <- coef(LE.lm)    

with these defined as in your mail (sorry I snipped 
your code out).  
So, I found
which(fitted(LE.lm) > (1 - exp(-1)))
62 83 
62 83

and then

glm(y ~ eco + geog, family = binomial(negexp()), 
       data = testDat[-c(62, 83), ], start = Ec)   


Coefficients:
(Intercept)          eco         geog  
  1.593e-01    2.085e-01    4.713e-06  

Degrees of Freedom: 97 Total (i.e. Null);  95 Residual
Null Deviance:	    134.4 
Residual Deviance: 112.3 	AIC: 118.3
There were 27 warnings (use warnings() to see them)

HTH

> 
> Andrew Hoskins
> Postdoctoral reasearch fellow
> Ecosystem Sciences
> CSIRO
> 
> E Andrew.Hoskins <at> csiro.au T +61 2 6246 5902
> Black Mountain Laboratories
> Clunies Ross Street, Acton, ACT 2601, Australia
> www.csiro.au
> 

> 

-- 
Kenneth Knoblauch
Inserm U846
Stem-cell and Brain Research Institute
Department of Integrative Neurosciences
18 avenue du Doyen L?pine
69500 Bron
France
tel: +33 (0)4 72 91 34 77
fax: +33 (0)4 72 91 34 61
portable: +33 (0)6 84 10 64 10
http://www.sbri.fr/members/kenneth-knoblauch.html


From sarahschmid98 at gmail.com  Thu Oct 23 17:06:41 2014
From: sarahschmid98 at gmail.com (Sarah)
Date: Thu, 23 Oct 2014 17:06:41 +0200
Subject: [R] Apply Function to Columns
Message-ID: <8CF1C263-962A-4861-8005-D46DD33FF29E@gmail.com>

Hello List, 

I have a database which consist of 912 plots. For each plot, I have the presence/absence information of 260 species of plants and also 5 different environmental variables (ddeg, mind, srad, slp, topo).

The dataframe looks like this: 

  Plot_Number        X       	 Y 	ddeg mind   srad slp topo Galium_mollugo Gentiana_nivalis
1        1 		557747.6 149726.8 2598 -625 236363   8  176              0                0
2        2 		572499.4 145503.5 2178 -176 161970  14 -137              0                0
3        3 		579100.4 151800.4 1208  632 267572  33  129              0                0
4        4 		581301.7 150300.1 1645   83 246633  15  -70              0                0
5        5 		579838.7 124770.9 1102 1637 158300   2 -231              0                0
6        6 		577011.1 121328.6  731 2223 180286  41   70              0                0

Now, what I wanted to do is to calculate spatial autocorrelation of each environmental variable for each species, but only for the plots where the species is present. 

I will use the correlog function of the package ncf (doesn?t really matter). The correlog function work with an argument X which is the longitude, an argument Y which is the latitude and an argument Z which is the variable you want to test for autocorrelation (in my case, the different environmental variables). 

So, for the first species I have the following script:

ddeg.correlog.9<-correlog(plant[plant[,9]=="1", 2], plant[plant[,9]=="1", 3], plant[plant[,9]=="1", 4]) 

X = plant[plant[,9]=="1", 2] ?>  only the X coordinate where my species 9 is present
Y = plant[plant[,9]=="1", 3] ?>  only the Y coordinate where my species 9 is present
Z = plant[plant[,9]=="1", 4] ?>  only the value of the environmental variable where my species 9 is present

plant: dataframe
9: column corresponding to the first species
2: column corresponding to the X coordinate
3: column correspondind to the Y coordinate
4: column corresponding to the first environmental variable

So my question is: how do I repeat this script for every species (basically, I just have to change the number ? 9 ? into 10, 11 and so on) ?

I try to write a function but I?m new in R and didn?t manage to do it. I was also considering to use the function ? lapply ?, but I don?t think I can use it in this case, isn?t it? 

Thank you very much for your help !

Sarah

From ruipbarradas at sapo.pt  Thu Oct 23 17:49:38 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 23 Oct 2014 16:49:38 +0100
Subject: [R] Apply Function to Columns
In-Reply-To: <8CF1C263-962A-4861-8005-D46DD33FF29E@gmail.com>
References: <8CF1C263-962A-4861-8005-D46DD33FF29E@gmail.com>
Message-ID: <54492392.4050907@sapo.pt>

Hello,

Yes, you can use lapply. Maybe something like the following. Note that 
the result is a list with one member per species. (Untested).

ddeg.correlog.list <- lapply(9:11, function(p)
	correlog(plant[plant[,p]=="1", 2], plant[plant[,p]=="1", 3], 
plant[plant[,p]=="1", 4]))


Hope this helps,

Rui Barradas

Em 23-10-2014 16:06, Sarah escreveu:
> Hello List,
>
> I have a database which consist of 912 plots. For each plot, I have the presence/absence information of 260 species of plants and also 5 different environmental variables (ddeg, mind, srad, slp, topo).
>
> The dataframe looks like this:
>
>    Plot_Number        X       	 Y 	ddeg mind   srad slp topo Galium_mollugo Gentiana_nivalis
> 1        1 		557747.6 149726.8 2598 -625 236363   8  176              0                0
> 2        2 		572499.4 145503.5 2178 -176 161970  14 -137              0                0
> 3        3 		579100.4 151800.4 1208  632 267572  33  129              0                0
> 4        4 		581301.7 150300.1 1645   83 246633  15  -70              0                0
> 5        5 		579838.7 124770.9 1102 1637 158300   2 -231              0                0
> 6        6 		577011.1 121328.6  731 2223 180286  41   70              0                0
>
> Now, what I wanted to do is to calculate spatial autocorrelation of each environmental variable for each species, but only for the plots where the species is present.
>
> I will use the correlog function of the package ncf (doesn?t really matter). The correlog function work with an argument X which is the longitude, an argument Y which is the latitude and an argument Z which is the variable you want to test for autocorrelation (in my case, the different environmental variables).
>
> So, for the first species I have the following script:
>
> ddeg.correlog.9<-correlog(plant[plant[,9]=="1", 2], plant[plant[,9]=="1", 3], plant[plant[,9]=="1", 4])
>
> X = plant[plant[,9]=="1", 2] ?>  only the X coordinate where my species 9 is present
> Y = plant[plant[,9]=="1", 3] ?>  only the Y coordinate where my species 9 is present
> Z = plant[plant[,9]=="1", 4] ?>  only the value of the environmental variable where my species 9 is present
>
> plant: dataframe
> 9: column corresponding to the first species
> 2: column corresponding to the X coordinate
> 3: column correspondind to the Y coordinate
> 4: column corresponding to the first environmental variable
>
> So my question is: how do I repeat this script for every species (basically, I just have to change the number ? 9 ? into 10, 11 and so on) ?
>
> I try to write a function but I?m new in R and didn?t manage to do it. I was also considering to use the function ? lapply ?, but I don?t think I can use it in this case, isn?t it?
>
> Thank you very much for your help !
>
> Sarah
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Thu Oct 23 18:17:24 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 23 Oct 2014 16:17:24 +0000
Subject: [R] Computing Water Balance using a loop.
In-Reply-To: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
References: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
Message-ID: <D06E7498.1101B9%macqueen1@llnl.gov>

If I understand the problem correctly, then I?d suggest this:

ndays <- nrow(Wb30)

for (iday in 2:ndays) {

  Wb30$Water_Balance[iday] <- Wb30$Water_Balance[iday-1] +
     Wb30$Rainfall[iday] - Wb30$Evaporation[iday]

  Wb30$Water_Balance[iday] <- min(Wb30$Water_Balance[iday], 100)
  Wb30$Water_Balance[iday] <- max(Wb30$Water_Balance[iday], 0)

}

It may be possible without a loop, but I think a loop is easier to
understand in the current circumstances. And is likely to be fast enough
that it does not matter.

- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/23/14, 5:33 AM, "Frederic Ntirenganya" <ntfredo at gmail.com> wrote:

>Dear All,
>
>I want to calculate water balance using the following formula:
>Water balance today = Water balance yesterday + Rainfall - Evaporation
>
>This is a sample of data I am using:
>
>head(Wb30)
>  May Rainfall Evaporation Water_Balance
>1   7        0           5             0
>2   8       10           5            NA
>3   9        0           5            NA
>4  10        0           5            NA
>5  11        2           5            NA
>6  12       23           5            NA
>
>The following is the loop am trying to use but it is not working well.
>
>#Water balance today = Water balance yesterday + Rainfall - Evaporation
>#If Water balance today < 0 then Water balance today = 0
>#If Water balance today > 100 then Water balance today = 100
>wb=c()
>for (w in 1:length(Wb30$Water_Balance)){
>  if(w<0 & w>100){w<-0 & w<-100}
>  #print (w);
> for (i in 1:length(Wb30$Rainfall)){
>    for (j in 1:length(Wb30$Evaporation)){
>    }
>  }
> wb<-Wb30$Water_Balance[w] + Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]
>}
>wb
>
>Any suggest of what I am missing for it to work correctly is welcome.
>
>
>Regards,
>
>Frederic Ntirenganya
>Maseno University,
>African Maths Initiative,
>Kenya.
>Mobile:(+254)718492836
>Email: fredo at aims.ac.za
>https://sites.google.com/a/aims.ac.za/fredo/
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lawrence.michael at gene.com  Thu Oct 23 19:35:00 2014
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 23 Oct 2014 10:35:00 -0700
Subject: [R] Installing gWidgetsRGtk2: R session is headless
In-Reply-To: <201410231140.23254.rainer.schuermann@gmx.net>
References: <201410231140.23254.rainer.schuermann@gmx.net>
Message-ID: <CAOQ5Nyff06oRPVvZdwUstvnA7_f9PY=VCo+Y+tq4rHOA7uCjng@mail.gmail.com>

Perhaps this is a permissions (Xauthority) issue: is the same user running
both the X11 display and the R session?



On Thu, Oct 23, 2014 at 2:40 AM, R <rainer.schuermann at gmx.net> wrote:

> I have written some gWidgets scripts before in the past but have a
> different box now (Debian KWheezy) and cannot get gWidgets working. It may
> be an obvious mistake but auntie Google (who has helped me a lot to get as
> far as I am now) leaves me in the dark now.
> Here is where I am stuck:
> - - - - -
> > library( gWidgets )
> > library( gWidgetsRGtk2 )
> Loading required package: RGtk2
> No protocol specified
> R session is headless; GTK+ not initialized.
> >  obj <- gbutton("Hello world", container = gwindow())
>
> (R:15675): GLib-GObject-WARNING **: invalid (NULL) pointer instance
>
> (R:15675): GLib-GObject-CRITICAL **: g_signal_connect_data: assertion
> `G_TYPE_CHECK_INSTANCE (instance)' failed
>
> (R:15675): Gtk-WARNING **: Screen for GtkWindow not set; you must always
> set
> a screen for a GtkWindow before using the window
>
> (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_default_colormap: assertion
> `GDK_IS_SCREEN (screen)' failed
>
> (R:15675): Gdk-CRITICAL **: IA__gdk_colormap_get_visual: assertion
> `GDK_IS_COLORMAP (colormap)' failed
>
> (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_default_colormap: assertion
> `GDK_IS_SCREEN (screen)' failed
>
> (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_root_window: assertion
> `GDK_IS_SCREEN (screen)' failed
>
> (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_root_window: assertion
> `GDK_IS_SCREEN (screen)' failed
>
> (R:15675): Gdk-CRITICAL **: IA__gdk_window_new: assertion `GDK_IS_WINDOW
> (parent)' failed
>
>  *** caught segfault ***
> address 0x18, cause 'memory not mapped'
>
> Traceback:
>  1: .Call(name, ..., PACKAGE = PACKAGE)
>  2: .RGtkCall("S_gtk_widget_show", object, PACKAGE = "RGtk2")
>  3: method(obj, ...)
>  4: window$Show()
>  5: .gwindow(toolkit, title, visible, width, height, parent, handler,
>  action, ...)
>  6: .gwindow(toolkit, title, visible, width, height, parent, handler,
>  action, ...)
>  7: gwindow()
>  8: .gbutton(toolkit, text, border, handler, action, container, ...)
>  9: .gbutton(toolkit, text, border, handler, action, container, ...)
> 10: gbutton("Hello world", container = gwindow())
>
>
> - - - - -
> > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From zuzulaz at gmail.com  Thu Oct 23 20:45:54 2014
From: zuzulaz at gmail.com (zuzana zajkova)
Date: Thu, 23 Oct 2014 20:45:54 +0200
Subject: [R] Heatmap - strange horizontal lines
Message-ID: <CADQCJLB3bax-aNdh1mL5E41ahhdWPVZEmB5qXvsnEkEyQ=L+Jg@mail.gmail.com>

Dear list,

I would like to make heatmaps from my data. Acctualy, I have already done
it, but the issue it that is doesn't work well for all files.

All files have the same structure, after importing them I do few
calculations using the same script, to obtain variables for plotting.

You can find the files here, the pb2166 is the one which works fine and I
get normal (expected) heatmap plot, the pb2214 it the other type, for which
I obtain strange horizontal lines...

https://www.dropbox.com/s/rz2ywnloepvr3d8/pb2166.csv?dl=0
https://www.dropbox.com/s/42taaybtbortv0p/pb2214.csv?dl=0

The structure of data is this (the same, from my point of view...):

str(pb2166)
'data.frame':  55119 obs. of  3 variables:
 $ dtime: num  17.9 18.1 18.3 18.4 18.6 ...
 $ act  : int  9 1 0 0 0 0 0 0 0 0 ...
 $ jul  : num  13573 13573 13573 13573 13573 ...

str(pb2214)
'data.frame':  44707 obs. of  3 variables:
 $ dtime: num  17.9 18.1 18.2 18.4 18.6 ...
 $ act  : int  9 1 0 0 0 0 0 0 0 0 ...
 $ jul  : num  13573 13573 13573 13573 13573 ...


To  create a heatmap I tried ggplot/qlot and levelplot aswell, the results
are the same... for pb2166 works ok, for pb2214 doesn't...

qplot(jul, dtime, data=pb2166, geom="tile", fill=act) +
scale_fill_gradient(low="gold", high="green4")
levelplot(act ~ jul * dtime, pb2166 )

qplot(jul, dtime, data=pb2214, geom="tile", fill=act) +
scale_fill_gradient(low="gold", high="green4")
levelplot(act ~ jul * dtime, pb2214 )

I would be very thankful if somebody could take a look on the data and find
something what I am missing.

Kind regards,

Zuzana

	[[alternative HTML version deleted]]


From munkey906 at gmail.com  Thu Oct 23 21:05:19 2014
From: munkey906 at gmail.com (Theodore Van Rooy)
Date: Thu, 23 Oct 2014 13:05:19 -0600
Subject: [R] OpenStreetMapR
Message-ID: <CAKjDV=pAdm0evNuL6vKQeraJg7LWyOZ8x7VnHgarM-TJMHGTmA@mail.gmail.com>

Hi All,

This isn't a request for help.  I just wanted to post that we've recently
completed a new package for R which allows you to do Open Street Map
plotting via Leaflet.

It's not on CRAN (yet), but it is on Github.

http://greentheo.github.io/OpenStreetMapR/

Theodore Van Rooy
royaltyanalytics.com

	[[alternative HTML version deleted]]


From Ingrid.Charvet at rms.com  Thu Oct 23 18:35:28 2014
From: Ingrid.Charvet at rms.com (Ingrid Charvet)
Date: Thu, 23 Oct 2014 09:35:28 -0700
Subject: [R] Interpolate through NAs using monotonic smoothing spline
Message-ID: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD027F767F2A@MAILCA6.rms.com>

In the figure attached "test", I would like to interpolate the empty - "NA" section to connect the two curves.

1/ I tried using "na.approx" and "na.spline", without success.

na.approx(test,na.rm=FALSE)
na.spline(test,na.rm=FALSE)

In the first case it just draws a straight line between the end and beginning points of each curve, respectively, which doesn't look smooth. In the second case the cubic spline interpolation results overshoot above 1.0 which I would like to avoid (see attached test.na) .

2/ I have also used  splinefun for a monotonic increasing spline, which is the best result so far
Yfun <- splinefun(X,test,method="monoH.FC")
test.spline <- Yfun(X)

however the resulting curve displays a "kink" at the limit of the interpolation zone (see attached figure test.splinefun).

is there a way to constrain the spline in na.spline in 1/, for example, to force it to be monotonic strictly increasing?
Alternatively can we alter the smoothing performed by splinefun somehow to avoid this "kink"?

Any other suggestions welcome!
Thank you
IC


________________________________
This message and any attachments contain information that may be RMS Inc. confidential and/or privileged. If you are not the intended recipient (or authorized to receive for the intended recipient), and have received this message in error, any use, disclosure or distribution is strictly prohibited. If you have received this message in error, please notify the sender immediately by replying to the e-mail and permanently deleting the message from your computer and/or storage system.



From Matthias.Weber at fntsoftware.com  Thu Oct 23 17:57:27 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Thu, 23 Oct 2014 17:57:27 +0200
Subject: [R] dotplot with library lattice
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>

Hello together,

i have a short question. Maybe anyone can help me to create a barplot in R with the package lattice.

I have the following data as ouput values and the following code:

Data (d):

KOST                  Budget        IST
1060                 -2.18          0
1080                  91037.71   91647.15
1100                  955573.87  907938.98
1120                  23326.8          0
1150                 2521.57          0
1180                 51302.03   48760.45
1200                  2027.04    -1667.5
1210                 2385.03    2386.06
1220                       0          0
1250                  528.87          0
1255                 766.54          0
1260                 12154.97    4861.41
Gesamtbudget 1141622.25 1054236.55

Code:

### read the data

d$KOST <- ordered( d$KOST, levels = d$KOST)

### load lattice and grid
require( lattice )

 ### setup the key
k <- simpleKey( c( "Budget",  "IST" ) )
k$points$fill <- c("blue", "darkgreen")
k$points$pch <- 21
k$points$col <- "black"
k$points$cex <- 1

 ### create the plot
dotplot( KOST ~ Budget + IST , data = d, horiz = TRUE,
     par.settings = list(
         superpose.symbol = list(
             pch = 21,
             fill = c( "blue", "darkgreen"),
             cex = 3,
             col = "black"
         )
      ) , xlab = "Kostenstellen?bersicht", key = k,
      panel = function(x, y,  ...){
        panel.dotplot( x, y, ... )
#       grid.text(
  #           unit( x, "native") , unit( y, "native") ,
   #          label = x, gp = gpar( cex = .7 ) )
      } )

The result look like the attached graph. But this is not exactly what I want. I want the "Budget" on the right side (100), and the "IST"-Value in dependence of the "Budget" between 0 and 100. As a example. If there is a budget over 100.000 and the "IST"-Value ist around 50.000, the blue button should be on the right side and the green button right in the middle.

Maybe anyone can help me.

Thank you.

Best regards.

Mat


________________________________
This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Unbenannt.png
Type: image/png
Size: 16042 bytes
Desc: Unbenannt.png
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20141023/de4f140c/attachment.png>

From jdnewmil at dcn.davis.CA.us  Fri Oct 24 02:31:42 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 23 Oct 2014 17:31:42 -0700
Subject: [R] Interpolate through NAs using monotonic smoothing spline
In-Reply-To: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD027F767F2A@MAILCA6.rms.com>
References: <C3D5060A3AC3D94BBFB1F17B7E6F4EDD027F767F2A@MAILCA6.rms.com>
Message-ID: <E9962CB4-CF8D-4D1D-8E88-F072D2EE59C1@dcn.davis.CA.us>

A very limited set of attachment types are allowed on this list.. yours was not one of them. Reading the Posting Guide will inform you about many useful things.

Self-contained R code is the expected mode of communication here.

>From your description, you might consider monotonic spline fitting the diff() of your data and integrating the fitted result... but without your sample plots I could be way off.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2014 9:35:28 AM PDT, Ingrid Charvet <Ingrid.Charvet at rms.com> wrote:
>In the figure attached "test", I would like to interpolate the empty -
>"NA" section to connect the two curves.
>
>1/ I tried using "na.approx" and "na.spline", without success.
>
>na.approx(test,na.rm=FALSE)
>na.spline(test,na.rm=FALSE)
>
>In the first case it just draws a straight line between the end and
>beginning points of each curve, respectively, which doesn't look
>smooth. In the second case the cubic spline interpolation results
>overshoot above 1.0 which I would like to avoid (see attached test.na)
>.
>
>2/ I have also used  splinefun for a monotonic increasing spline, which
>is the best result so far
>Yfun <- splinefun(X,test,method="monoH.FC")
>test.spline <- Yfun(X)
>
>however the resulting curve displays a "kink" at the limit of the
>interpolation zone (see attached figure test.splinefun).
>
>is there a way to constrain the spline in na.spline in 1/, for example,
>to force it to be monotonic strictly increasing?
>Alternatively can we alter the smoothing performed by splinefun somehow
>to avoid this "kink"?
>
>Any other suggestions welcome!
>Thank you
>IC
>
>
>________________________________
>This message and any attachments contain information that may be RMS
>Inc. confidential and/or privileged. If you are not the intended
>recipient (or authorized to receive for the intended recipient), and
>have received this message in error, any use, disclosure or
>distribution is strictly prohibited. If you have received this message
>in error, please notify the sender immediately by replying to the
>e-mail and permanently deleting the message from your computer and/or
>storage system.
>
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From Andrew.Hoskins at csiro.au  Fri Oct 24 05:10:30 2014
From: Andrew.Hoskins at csiro.au (Andrew.Hoskins at csiro.au)
Date: Fri, 24 Oct 2014 03:10:30 +0000
Subject: [R] Help with GLM starting values in user defined link function
In-Reply-To: <mailman.29.1414058408.29667.r-help@r-project.org>
References: <mailman.29.1414058408.29667.r-help@r-project.org>
Message-ID: <4CE25E390851FA45B44CDBF653F097872321C4@ExMBX01-CDC.nexus.csiro.au>

Hi Ken, 

Many thanks for your advice. 

Earlier this morning I stepped my way through the glm.fit function to see where things were falling over and realised that first and foremost I had my link function wrong (link and inverse were back to front). I've now fixed this and can get the model to produce coefficients following your example. However, once I try to fit the complete model (where eco is offset rather than estimated), I still end up with an error that the model was unable to fit coefficients. Although it does seem to make it though some iterations of the IRLS algorithm before this happens. I also end up with the same error when I first estimate the coefficient for eco and then try to offset the estimated eco coefficient*eco, which seems to suggest to me that there is something not right with how the link is working with offset. 

See below for the example code. 

I was wondering if you or anyone else has some more great advice? 

Thanks in advance. 

Andrew 

## Example fit of negative exponential binomial GLM 

## define link function 
negexp <- function() 
{ 
    linkfun <- function(mu) -log(1-mu) 
    linkinv <- function(eta) 1-exp(-eta) 
    mu.eta <- function(eta) exp(-eta) 
    valideta <- function(eta) all(is.finite(eta)) 
    link <- paste0("negexp") 
    structure(list(linkfun = linkfun, linkinv = linkinv, 
                   mu.eta = mu.eta, valideta = valideta, name = link), 
              class = "link-glm") 
} 

## create some data 

y <- c(0,0,0,0,0,1,1,1,0,1,0,1,1,0,0,1,1,1,1,0,1,0,1,0,1,0,1,1,1,0,1,0,1,0,0,1,0 
                ,1,0,0,1,0,0,0,0,0,0,0,0,0,0,0,0,1,0,1,0,0,0,1,1,1,0,1,0,1,1,0,1,0,1,0,1,1 
                ,0,1,0,0,1,0,0,1,1,1,0,0,1,1,1,1,0,0,0,1,0,1,0,1,0,0) 


eco <- c(0.30406146,0.77127034,0.27507740,0.34660849,0.10496959,0.87483283,1.34652163,0.59570289,0.76557945 
                ,1.07105129,0.85681582,1.15885519,0.62478718,0.82327890,0.61921331,1.40337615,1.69376337,0.96662890 
                ,0.62756558,1.22148480,0.29509170,1.20822702,1.04490241,0.63994034,0.44537652,0.80908805,1.38793219 
                ,0.68987695,0.65253113,0.10996619,2.18030035,0.95187860,1.91719194,0.55910638,0.42246265,0.99747093 
                ,0.65609015,1.56408171,0.09024976,0.49430176,0.89651639,0.13943031,0.72264673,0.33212781,0.53156567 
                ,0.24478163,0.20439708,0.26577897,0.73061755,1.41380646,0.45361391,0.53961802,0.20099582,0.16278695 
                ,0.51188479,1.23152701,1.45180489,0.16136045,0.84696597,1.06556860,0.31352700,7.54728452,0.47765713 
                ,1.62966928,0.51514442,0.87203787,0.33515181,0.71407043,0.84767445,0.33640927,0.70331392,0.41617675 
                ,1.41137914,0.22586531,0.92797131,1.34627407,0.21408341,0.38903027,0.91690877,0.95946623,0.46114617 
                ,0.62965571,7.50492235,1.96516642,0.61555184,1.24061426,0.95281453,1.02729643,1.44581350,1.63148077 
                ,1.02291891,0.80319545,0.92136436,1.22428318,0.59172977,1.56985149,0.35790202,2.23402940,0.98565537 
                ,0.41658919) 

geog <- c(254.94615,277.78675,3.69047,47.92363,0.90241,449.44532,1795.89910,985.66843,1063.47287 
                ,160.27883,58.72738,1093.00270,1423.51194,1232.16769,54.56121,4772.54353,1877.95322,1110.18161 
                ,174.53805,2829.67281,551.22870,1781.67608,495.13007,44.42326,1057.72959,783.99003,3025.58558 
                ,1855.59219,1715.27590,41.75478,3687.95693,2125.34324,751.42284,1598.04527,1625.35627,848.40949 
                ,1484.40835,3332.15554,214.99678,136.60188,1388.07919,77.21198,2366.56327,617.31749,1421.72213 
                ,537.38636,223.57615,256.35456,3022.63678,4783.64718,45.97153,194.79090,2.65647,69.08392 
                ,948.66990,1480.70503,2805.30205,144.55345,1134.92666,728.04570,1421.45250,827.57959,1517.75701 
                ,682.77014,1060.09369,448.44398,848.64842,1437.74925,2887.23135,56.28056,725.78408,91.19194 
                ,1905.87208,749.92265,261.19075,2529.80027,371.16338,1130.14904,802.23348,1851.86105,1274.20599 
                ,260.79728,1427.11459,3891.82373,482.58143,2011.86414,1310.10546,975.37470,1087.50127,2195.28667 
                ,2358.70761,44.82955,1553.35558,2261.60567,1216.64486,1674.70189,165.13405,1463.93362,1542.33074 
                ,1683.01992) 

testDat <- data.frame(y,eco,geog) 

## fit model 
fit.logit <- glm(y~eco+geog,family=binomial(cloglog),data=testDat) 
##EV <- negexp()$linkfun(fitted(fit.logit)) ## linking the fitted values doesn't work but ignoring this will 
LE.lm <- lm(EV ~ eco + geog, testDat)     
Ec <- coef(LE.lm) 
glm(y ~ eco + geog, family = binomial(negexp()),data=testDat,start=Ec) 


## fit model using offset 

fit.logit <- glm(y~offset(eco)+geog,family=binomial(cloglog),data=testDat) 
##EV <- negexp()$linkfun(fitted(fit.logit)) ## linking the fitted values doesn't work but ignoring this will 
LE.lm <- lm(EV ~ offset(eco) + geog, testDat)     
Ec <- coef(LE.lm) 
glm(y ~ offset(eco) + geog, family = binomial(negexp()),data=testDat,start=Ec) 

## fit model using offset with eco*coefficient * eco 

fit.logit <- glm(y~offset(coef(fit2)[2]*eco)+geog,family=binomial(cloglog),data=testDat) 
##EV <- negexp()$linkfun(fitted(fit.logit)) ## linking the fitted values doesn't work but ignoring this will 
LE.lm <- lm(EV ~ offset(coef(fit2)[2]*eco) + geog, testDat)     
Ec <- coef(LE.lm) 
fit2 <- glm(y ~ offset(coef(fit2)[2]*eco) + geog, family = binomial(negexp()),data=testDat,start=Ec)

-----Original Message-----
<Andrew.Hoskins <at> csiro.au> writes: 
> I'm trying to fit a binomial GLM with user defined 
 link 
 function (negative exponential), however I seem to 
> be unable to find the correct starting values to 
initialise such a model. I've tried taking starting 
> values from a logistic and log models fit to the 
same data and also tried to substitute the intercept 
from 
> the null model in as the starting value for this 
model, however all continue to return the same error. 
> 
> Andrew 
> 
> ## Example fit of negative exponential binomial 
GLM

> 
> ## define link function 
> negexp <- function() 
> { 
>     linkfun <- function(mu) 1-exp(-mu) 
>     linkinv <- function(eta) -log(1-eta) 
>     mu.eta <- function(eta) 1/(1-eta) 
>     valideta <- function(eta) TRUE 
>     link <- paste0("negexp") 
>     structure(list(linkfun = linkfun, linkinv = linkinv, 
>                    mu.eta = mu.eta, valideta = valideta,
... [show rest of quote]
name = link), 
>               class = "link-glm") 
> } 
> 
---SNIP--- 

Take a look at the limits of eta for the extreme values 
of mu and compare them with the linear predictor of 
your link applied to say the fitted values of your logit 
fit.  It seems to suggest that two values fall outside 
the range of valid eta, according to your linkfun: 
c(62, 83).  I got it to work 
with these removed although there were lots of other 
warnings that you might have to worry about. 
Also, when choosing start values you might want 
to base them on a fit with your link rather than 
a different one. So, I got start values by trying 

EV <- negexp()$linkfun(fitted(fit.logit)) 
LE.lm <- lm(EV ~ eco + geog, testDat)     
Ec <- coef(LE.lm)     

with these defined as in your mail (sorry I snipped 
your code out).   
So, I found 
which(fitted(LE.lm) > (1 - exp(-1))) 
62 83 
62 83 

and then 

glm(y ~ eco + geog, family = binomial(negexp()), 
       data = testDat[-c(62, 83), ], start = Ec)   


Coefficients: 
(Intercept)          eco         geog   
  1.593e-01    2.085e-01    4.713e-06   

Degrees of Freedom: 97 Total (i.e. Null);  95 Residual 
Null Deviance:	   134.4 
Residual Deviance: 112.3 AIC: 118.3 
There were 27 warnings (use warnings() to see them) 

HTH 

> 
> Andrew Hoskins 
> Postdoctoral reasearch fellow 
> Ecosystem Sciences 
> CSIRO 
> 
> E Andrew.Hoskins <at> csiro.au T +61 2 6246 5902 
> Black Mountain Laboratories 
> Clunies Ross Street, Acton, ACT 2601, Australia 
> www.csiro.au 
>
... [show rest of quote]

> 

-- 
Kenneth Knoblauch 
Inserm U846 
Stem-cell and Brain Research Institute 
Department of Integrative Neurosciences 
18 avenue du Doyen L?pine 
69500 Bron 
France 
tel: +33 (0)4 72 91 34 77 
fax: +33 (0)4 72 91 34 61 
portable: +33 (0)6 84 10 64 10 
http://www.sbri.fr/members/kenneth-knoblauch.html


From rhelpmaillist at 163.com  Fri Oct 24 05:35:06 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 24 Oct 2014 11:35:06 +0800 (CST)
Subject: [R]  how to calculate a numeric's digits count?
Message-ID: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>


Dear usRers,
? Now i want to cal ,e.g. 
?cal(1.234)? will get 3
?cal(1) will get 0
?cal(1.3045) will get 4
?But the difficult part is cal(1.3450) will get 4 not 3.
So, is there anyone happen to know the solution to this problem, or it can't be solved in R, because 1.340 will always be transformed autolly to 1.34?






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU

From mick.jordan at oracle.com  Fri Oct 24 01:05:12 2014
From: mick.jordan at oracle.com (Mick Jordan)
Date: Thu, 23 Oct 2014 16:05:12 -0700
Subject: [R] Clarification on debug output
Message-ID: <544989A8.9000705@oracle.com>


I hope someone can explain what the #1 means (and for that matter the 
[2] in the debug output below. I can't find anything in the spec that 
explains what they mean.

Thanks

 > f(1)
debugging in: f(1)
debugging in: f()
debug at #1: {
     if (x < 0)
         -x
     else x
}
Browse[2]>


From jdnewmil at dcn.davis.CA.us  Fri Oct 24 06:04:18 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 23 Oct 2014 21:04:18 -0700
Subject: [R] how to calculate a numeric's digits count?
In-Reply-To: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
References: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
Message-ID: <3A0F3010-A7B9-479A-945D-AD812CD50FEF@dcn.davis.CA.us>

I am baffled. I think those were English words but they didn't make any sense to me. Not was there a reproducible example to turn to. Can you try again?
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2014 8:35:06 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>
>Dear usRers,
>? Now i want to cal ,e.g. 
>?cal(1.234)? will get 3
>?cal(1) will get 0
>?cal(1.3045) will get 4
>?But the difficult part is cal(1.3450) will get 4 not 3.
>So, is there anyone happen to know the solution to this problem, or it
>can't be solved in R, because 1.340 will always be transformed autolly
>to 1.34?
>
>
>
>
>
>
>--
>
>PO SU
>mail: desolator88 at 163.com 
>Majored in Statistics from SJTU
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rainer.schuermann at gmx.net  Fri Oct 24 06:38:54 2014
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Fri, 24 Oct 2014 06:38:54 +0200
Subject: [R] Installing gWidgetsRGtk2: R session is headless
In-Reply-To: <CAOQ5Nyff06oRPVvZdwUstvnA7_f9PY=VCo+Y+tq4rHOA7uCjng@mail.gmail.com>
References: <201410231140.23254.rainer.schuermann@gmx.net>
	<CAOQ5Nyff06oRPVvZdwUstvnA7_f9PY=VCo+Y+tq4rHOA7uCjng@mail.gmail.com>
Message-ID: <201410240638.54926.rainer.schuermann@gmx.net>

Michael, thanks, that was it!
I had installed the packages as root and tried them out as root (not a good idea I know, but I was lazy), while running the the X11 display as user.
Worse is that I have done that many times. One more thing learned.
Thanks again,
Rainer



On Thursday 23 October 2014 19:35:00 Michael Lawrence wrote:
> Perhaps this is a permissions (Xauthority) issue: is the same user running
> both the X11 display and the R session?
> 
> 
> 
> On Thu, Oct 23, 2014 at 2:40 AM, R <rainer.schuermann at gmx.net> wrote:
> 
> > I have written some gWidgets scripts before in the past but have a
> > different box now (Debian KWheezy) and cannot get gWidgets working. It may
> > be an obvious mistake but auntie Google (who has helped me a lot to get as
> > far as I am now) leaves me in the dark now.
> > Here is where I am stuck:
> > - - - - -
> > > library( gWidgets )
> > > library( gWidgetsRGtk2 )
> > Loading required package: RGtk2
> > No protocol specified
> > R session is headless; GTK+ not initialized.
> > >  obj <- gbutton("Hello world", container = gwindow())
> >
> > (R:15675): GLib-GObject-WARNING **: invalid (NULL) pointer instance
> >
> > (R:15675): GLib-GObject-CRITICAL **: g_signal_connect_data: assertion
> > `G_TYPE_CHECK_INSTANCE (instance)' failed
> >
> > (R:15675): Gtk-WARNING **: Screen for GtkWindow not set; you must always
> > set
> > a screen for a GtkWindow before using the window
> >
> > (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_default_colormap: assertion
> > `GDK_IS_SCREEN (screen)' failed
> >
> > (R:15675): Gdk-CRITICAL **: IA__gdk_colormap_get_visual: assertion
> > `GDK_IS_COLORMAP (colormap)' failed
> >
> > (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_default_colormap: assertion
> > `GDK_IS_SCREEN (screen)' failed
> >
> > (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_root_window: assertion
> > `GDK_IS_SCREEN (screen)' failed
> >
> > (R:15675): Gdk-CRITICAL **: IA__gdk_screen_get_root_window: assertion
> > `GDK_IS_SCREEN (screen)' failed
> >
> > (R:15675): Gdk-CRITICAL **: IA__gdk_window_new: assertion `GDK_IS_WINDOW
> > (parent)' failed
> >
> >  *** caught segfault ***
> > address 0x18, cause 'memory not mapped'
> >
> > Traceback:
> >  1: .Call(name, ..., PACKAGE = PACKAGE)
> >  2: .RGtkCall("S_gtk_widget_show", object, PACKAGE = "RGtk2")
> >  3: method(obj, ...)
> >  4: window$Show()
> >  5: .gwindow(toolkit, title, visible, width, height, parent, handler,
> >  action, ...)
> >  6: .gwindow(toolkit, title, visible, width, height, parent, handler,
> >  action, ...)
> >  7: gwindow()
> >  8: .gbutton(toolkit, text, border, handler, action, container, ...)
> >  9: .gbutton(toolkit, text, border, handler, action, container, ...)
> > 10: gbutton("Hello world", container = gwindow())
> >
> >
> > - - - - -
> > > sessionInfo()
> > R version 3.1.1 (2014-07-10)
> > Platform: x86_64-pc-linux-gnu (64-bit)
> >
> > locale:
> >  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> >  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
> >  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> >  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
> >  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> > [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
> >
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> >
> > loaded via a namespace (and not attached):
> > [1] tools_3.1.1
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rhelpmaillist at 163.com  Fri Oct 24 08:11:08 2014
From: rhelpmaillist at 163.com (PO SU)
Date: Fri, 24 Oct 2014 14:11:08 +0800 (CST)
Subject: [R] how to calculate a numeric's digits count?
In-Reply-To: <3A0F3010-A7B9-479A-945D-AD812CD50FEF@dcn.davis.CA.us>
References: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
	<3A0F3010-A7B9-479A-945D-AD812CD50FEF@dcn.davis.CA.us>
Message-ID: <47fc238.1f3e3.14940c7ae64.Coremail.rhelpmaillist@163.com>


Ok,? what i want is ?find how many numbers after? . in a numeric ,and i don't know if there is already exists a function to do it( i wrote one by myself which will be showed later).
e.g.
1.234 has 3 numbers after . 
1 has 0 number
1.5342 has 4 numbers 
And i solved the above format using:
find<-function(x)
{
    str<-as.character(x)
    if(is.na(strsplit(str,"\\.")[[1]][2])) return(0)
    else return(nchar(strsplit(str,"\\.")[[1]][2]))  
}

But when i? find(1.340)? i get 2 not 3. find(1.3400) will also get 2 not 4.
So,my question is how to implement the above needing? TKS.




--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU




At 2014-10-24 12:04:18, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us> wrote:
>I am baffled. I think those were English words but they didn't make any sense to me. Not was there a reproducible example to turn to. Can you try again?
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>--------------------------------------------------------------------------- 
>Sent from my phone. Please excuse my brevity.
>
>On October 23, 2014 8:35:06 PM PDT, PO SU <rhelpmaillist at 163.com> wrote:
>>
>>Dear usRers,
>>? Now i want to cal ,e.g. 
>>?cal(1.234)? will get 3
>>?cal(1) will get 0
>>?cal(1.3045) will get 4
>>?But the difficult part is cal(1.3450) will get 4 not 3.
>>So, is there anyone happen to know the solution to this problem, or it
>>can't be solved in R, because 1.340 will always be transformed autolly
>>to 1.34?
>>
>>
>>
>>
>>
>>
>>--
>>
>>PO SU
>>mail: desolator88 at 163.com 
>>Majored in Statistics from SJTU
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>

From olivier.crouzet at univ-nantes.fr  Fri Oct 24 09:05:57 2014
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Fri, 24 Oct 2014 09:05:57 +0200
Subject: [R] how to calculate a numeric's digits count?
In-Reply-To: <47fc238.1f3e3.14940c7ae64.Coremail.rhelpmaillist@163.com>
References: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
	<3A0F3010-A7B9-479A-945D-AD812CD50FEF@dcn.davis.CA.us>
	<47fc238.1f3e3.14940c7ae64.Coremail.rhelpmaillist@163.com>
Message-ID: <20141024090557.01a956a5524ed8a3f4a7a2c9@univ-nantes.fr>

Le Fri, 24 Oct 2014 14:11:08 +0800 (CST), PO SU a ?crit :

> 
> Ok,? what i want is ?find how many numbers after? . in a numeric ,and
> i don't know if there is already exists a function to do it( i wrote
> one by myself which will be showed later). e.g. 1.234 has 3 numbers
> after . 1 has 0 number
> 1.5342 has 4 numbers 
> And i solved the above format using:
> find<-function(x)
> {
>     str<-as.character(x)
>     if(is.na(strsplit(str,"\\.")[[1]][2])) return(0)
      else return(nchar(strsplit(str,"\\.")[[1]][2]))  
> }

It appears that your initial vector (x) is a numeric one that you
(obviously) need to transform to a character vector. So any number
it contains will have been shortened to its minimal representation when
you convert it to string. As far as I can tell (though I'm no expert in
number representation), you should work with x as a string vector from
the very beginning (which, to me, seems rather intuitive as the 0 in
1.230 is, really, only a string isn't it ?)

If you can "see" zeros when you print the numeric vector by e.g. 
print (x), that's simply because R displays them with a default
precision but they may contain many more digits... Try dput (x) before
str <- as.character (x) and you will see what I mean.

Also, it may be usefull to look at what the following lines produce :
sprintf("%.10f", x)
sprintf("%.30f", x)

You will see that actually R stores many more digits that what you
think there are and that your "0" in "1.340" for example is,
really not single... except when it is basically a string.

Olivier.

> 
> But when i? find(1.340)? i get 2 not 3. find(1.3400) will also get 2
> not 4. So,my question is how to implement the above needing? TKS.
> 
> 
> 
> 
> --
> 
> PO SU
> mail: desolator88 at 163.com 
> Majored in Statistics from SJTU
> 
> 
> 
> 
> At 2014-10-24 12:04:18, "Jeff Newmiller" <jdnewmil at dcn.davis.CA.us>
> wrote:
> >I am baffled. I think those were English words but they didn't make
> >any sense to me. Not was there a reproducible example to turn to.
> >Can you try again?
> >---------------------------------------------------------------------------
> >Jeff Newmiller                        The     .....       .....  Go
> >Live... DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.
> >##.#.  Live Go...
> >                                      Live:   OO#.. Dead: OO#..
> > Playing
> >Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >/Software/Embedded Controllers)               .OO#.       .OO#.
> >rocks...1k
> >--------------------------------------------------------------------------- 
> >Sent from my phone. Please excuse my brevity.
> >
> >On October 23, 2014 8:35:06 PM PDT, PO SU <rhelpmaillist at 163.com>
> >wrote:
> >>
> >>Dear usRers,
> >>? Now i want to cal ,e.g. 
> >>?cal(1.234)? will get 3
> >>?cal(1) will get 0
> >>?cal(1.3045) will get 4
> >>?But the difficult part is cal(1.3450) will get 4 not 3.
> >>So, is there anyone happen to know the solution to this problem, or
> >>it can't be solved in R, because 1.340 will always be transformed
> >>autolly to 1.34?
> >>
> >>
> >>
> >>
> >>
> >>
> >>--
> >>
> >>PO SU
> >>mail: desolator88 at 163.com 
> >>Majored in Statistics from SJTU
> >>______________________________________________
> >>R-help at r-project.org mailing list
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


From sarahschmid98 at gmail.com  Fri Oct 24 09:24:15 2014
From: sarahschmid98 at gmail.com (Sarah)
Date: Fri, 24 Oct 2014 09:24:15 +0200
Subject: [R] Apply Function to Columns
In-Reply-To: <3DA37DB1-D024-4A7F-9AF7-859AEAE8B82E@gmail.com>
References: <8CF1C263-962A-4861-8005-D46DD33FF29E@gmail.com>
	<54492392.4050907@sapo.pt>
	<3DA37DB1-D024-4A7F-9AF7-859AEAE8B82E@gmail.com>
Message-ID: <F76380B7-A1BE-4C4C-8775-AB38CEA4306D@gmail.com>


> Le 24 oct. 2014 ? 09:23, Sarah <sarahschmid98 at gmail.com> a ?crit :
> 
> Thank you very much, it helped a lot!
> 
> I just have another question know. I want to make plot for every species. I just add the function ? plot correlog ? to the previous function and I have now the following script: 
> 
> ddeg.correlog.list <- lapply(9:20, function(p)
>   plot.correlog(correlog(plant[plant[,p]=="1", 2], plant[plant[,p]=="1", 3], 
>                          plant[plant[,p]=="1", 4],increment=2500)))
> 
> It?s working, but I wanted to know if there is a way to save each plot. I found that I can use the dev.off function or the ggplot function of the package ggplot2, but I can?t figure out how to use it within the lapply function. Do you think there is a way?
> 
> Thank you for your help!
> 
> Sarah
> 
>> Le 23 oct. 2014 ? 17:49, Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>> a ?crit :
>> 
>> Hello,
>> 
>> Yes, you can use lapply. Maybe something like the following. Note that the result is a list with one member per species. (Untested).
>> 
>> ddeg.correlog.list <- lapply(9:11, function(p)
>> 	correlog(plant[plant[,p]=="1", 2], plant[plant[,p]=="1", 3], plant[plant[,p]=="1", 4]))
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> Em 23-10-2014 16:06, Sarah escreveu:
>>> Hello List,
>>> 
>>> I have a database which consist of 912 plots. For each plot, I have the presence/absence information of 260 species of plants and also 5 different environmental variables (ddeg, mind, srad, slp, topo).
>>> 
>>> The dataframe looks like this:
>>> 
>>>   Plot_Number        X       	 Y 	ddeg mind   srad slp topo Galium_mollugo Gentiana_nivalis
>>> 1        1 		557747.6 149726.8 2598 -625 236363   8  176              0                0
>>> 2        2 		572499.4 145503.5 2178 -176 161970  14 -137              0                0
>>> 3        3 		579100.4 151800.4 1208  632 267572  33  129              0                0
>>> 4        4 		581301.7 150300.1 1645   83 246633  15  -70              0                0
>>> 5        5 		579838.7 124770.9 1102 1637 158300   2 -231              0                0
>>> 6        6 		577011.1 121328.6  731 2223 180286  41   70              0                0
>>> 
>>> Now, what I wanted to do is to calculate spatial autocorrelation of each environmental variable for each species, but only for the plots where the species is present.
>>> 
>>> I will use the correlog function of the package ncf (doesn?t really matter). The correlog function work with an argument X which is the longitude, an argument Y which is the latitude and an argument Z which is the variable you want to test for autocorrelation (in my case, the different environmental variables).
>>> 
>>> So, for the first species I have the following script:
>>> 
>>> ddeg.correlog.9<-correlog(plant[plant[,9]=="1", 2], plant[plant[,9]=="1", 3], plant[plant[,9]=="1", 4])
>>> 
>>> X = plant[plant[,9]=="1", 2] ?>  only the X coordinate where my species 9 is present
>>> Y = plant[plant[,9]=="1", 3] ?>  only the Y coordinate where my species 9 is present
>>> Z = plant[plant[,9]=="1", 4] ?>  only the value of the environmental variable where my species 9 is present
>>> 
>>> plant: dataframe
>>> 9: column corresponding to the first species
>>> 2: column corresponding to the X coordinate
>>> 3: column correspondind to the Y coordinate
>>> 4: column corresponding to the first environmental variable
>>> 
>>> So my question is: how do I repeat this script for every species (basically, I just have to change the number ? 9 ? into 10, 11 and so on) ?
>>> 
>>> I try to write a function but I?m new in R and didn?t manage to do it. I was also considering to use the function ? lapply ?, but I don?t think I can use it in this case, isn?t it?
>>> 
>>> Thank you very much for your help !
>>> 
>>> Sarah
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
> 


	[[alternative HTML version deleted]]


From ntfredo at gmail.com  Fri Oct 24 09:49:40 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Fri, 24 Oct 2014 10:49:40 +0300
Subject: [R] Computing Water Balance using a loop.
In-Reply-To: <D06E7498.1101B9%macqueen1@llnl.gov>
References: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
	<D06E7498.1101B9%macqueen1@llnl.gov>
Message-ID: <CAGh51gQS1ZkOcdgzeP7rXjcXi=yiWmoEP4=3uCVGa3-pBhnV0A@mail.gmail.com>

Hi Mac,

The first entry is 0 for water balance. That means the 3rd should be zero
according to the formula.

Water balance today = Water balance yesterday + Rainfall ? Evaporation

This loop gives 5 for each date. I don't see why ?

  May Rainfall Evaporation Water_Balance
1   7        0           5             0
2   8       10           5            NA
3   9        0           5            NA
4  10        0           5            NA
5  11        2           5            NA
6  12       23           5            NA

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Thu, Oct 23, 2014 at 7:17 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> If I understand the problem correctly, then I?d suggest this:
>
> ndays <- nrow(Wb30)
>
> for (iday in 2:ndays) {
>
>   Wb30$Water_Balance[iday] <- Wb30$Water_Balance[iday-1] +
>      Wb30$Rainfall[iday] - Wb30$Evaporation[iday]
>
>   Wb30$Water_Balance[iday] <- min(Wb30$Water_Balance[iday], 100)
>   Wb30$Water_Balance[iday] <- max(Wb30$Water_Balance[iday], 0)
>
> }
>
> It may be possible without a loop, but I think a loop is easier to
> understand in the current circumstances. And is likely to be fast enough
> that it does not matter.
>
> -
> Don MacQueen
>
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
>
>
>
>
>
> On 10/23/14, 5:33 AM, "Frederic Ntirenganya" <ntfredo at gmail.com> wrote:
>
> >Dear All,
> >
> >I want to calculate water balance using the following formula:
> >Water balance today = Water balance yesterday + Rainfall - Evaporation
> >
> >This is a sample of data I am using:
> >
> >head(Wb30)
> >  May Rainfall Evaporation Water_Balance
> >1   7        0           5             0
> >2   8       10           5            NA
> >3   9        0           5            NA
> >4  10        0           5            NA
> >5  11        2           5            NA
> >6  12       23           5            NA
> >
> >The following is the loop am trying to use but it is not working well.
> >
> >#Water balance today = Water balance yesterday + Rainfall - Evaporation
> >#If Water balance today < 0 then Water balance today = 0
> >#If Water balance today > 100 then Water balance today = 100
> >wb=c()
> >for (w in 1:length(Wb30$Water_Balance)){
> >  if(w<0 & w>100){w<-0 & w<-100}
> >  #print (w);
> > for (i in 1:length(Wb30$Rainfall)){
> >    for (j in 1:length(Wb30$Evaporation)){
> >    }
> >  }
> > wb<-Wb30$Water_Balance[w] + Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]
> >}
> >wb
> >
> >Any suggest of what I am missing for it to work correctly is welcome.
> >
> >
> >Regards,
> >
> >Frederic Ntirenganya
> >Maseno University,
> >African Maths Initiative,
> >Kenya.
> >Mobile:(+254)718492836
> >Email: fredo at aims.ac.za
> >https://sites.google.com/a/aims.ac.za/fredo/
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Fri Oct 24 10:33:32 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 24 Oct 2014 09:33:32 +0100
Subject: [R] Clarification on debug output
In-Reply-To: <544989A8.9000705@oracle.com>
References: <544989A8.9000705@oracle.com>
Message-ID: <544A0EDC.3030209@stats.ox.ac.uk>

On 24/10/2014 00:05, Mick Jordan wrote:
>
> I hope someone can explain what the #1 means (and for that matter the
> [2] in the debug output below. I can't find anything in the spec that
> explains what they mean.
>
> Thanks
>
>  > f(1)
> debugging in: f(1)
> debugging in: f()
> debug at #1: {

#1 is a 'srcref': see its help.  It is a line number in the source file 
(if this was recorded, which it is not by default for package code, for 
example).

>      if (x < 0)
>          -x
>      else x
> }
> Browse[2]>

'2' is the 'browser level': the browser can be called recursively.  It 
is a count of 'contexts', so the first browse is normally starting at 
context 2, and browsing from the browser gives 3 ....


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From jim at bitwrit.com.au  Fri Oct 24 11:28:38 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 24 Oct 2014 20:28:38 +1100
Subject: [R] dotplot with library lattice
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
Message-ID: <707072790.FfmNddDgBm@localhost.localdomain>

On Thu, 23 Oct 2014 05:57:27 PM Matthias Weber wrote:
> Hello together,
> 
> i have a short question. Maybe anyone can help me to create a 
barplot in R
> with the package lattice.
> 
> I have the following data as ouput values and the following code:
> 
> Data (d):
> 
> KOST                  Budget        IST
> 1060                 -2.18          0
> 1080                  91037.71   91647.15
> 1100                  955573.87  907938.98
> 1120                  23326.8          0
> 1150                 2521.57          0
> 1180                 51302.03   48760.45
> 1200                  2027.04    -1667.5
> 1210                 2385.03    2386.06
> 1220                       0          0
> 1250                  528.87          0
> 1255                 766.54          0
> 1260                 12154.97    4861.41
> Gesamtbudget 1141622.25 1054236.55
> 
> Code:
> 
> ### read the data
> 
> d$KOST <- ordered( d$KOST, levels = d$KOST)
> 
> ### load lattice and grid
> require( lattice )
> 
>  ### setup the key
> k <- simpleKey( c( "Budget",  "IST" ) )
> k$points$fill <- c("blue", "darkgreen")
> k$points$pch <- 21
> k$points$col <- "black"
> k$points$cex <- 1
> 
>  ### create the plot
> dotplot( KOST ~ Budget + IST , data = d, horiz = TRUE,
>      par.settings = list(
>          superpose.symbol = list(
>              pch = 21,
>              fill = c( "blue", "darkgreen"),
>              cex = 3,
>              col = "black"
>          )
>       ) , xlab = "Kostenstellen?bersicht", key = k,
>       panel = function(x, y,  ...){
>         panel.dotplot( x, y, ... )
> #       grid.text(
>   #           unit( x, "native") , unit( y, "native") ,
>    #          label = x, gp = gpar( cex = .7 ) )
>       } )
> 
> The result look like the attached graph. But this is not exactly what I
> want. I want the "Budget" on the right side (100), and the "IST"-Value 
in
> dependence of the "Budget" between 0 and 100. As a example. If 
there is a
> budget over 100.000 and the "IST"-Value ist around 50.000, the blue 
button
> should be on the right side and the green button right in the middle.
> 
> Maybe anyone can help me.
> 
> Thank you.
> 
> Best regards.
> 
> Mat
> 
> 
Hi Mat,
I must admit that I have probably misunderstood your request. I have 
assumed that you want the Budget as the x axis and the KOST as the 
y axis. You seemed to be asking for Budget to be always 100 and that 
didn't make sense. For some reason the "scipen" option stopped 
working for me after the first plot and so I couldn't get rid of the 
scientific notation on the x axis. Also this was done in base graphics 
rather than lattice. I also left the "Gesamtbudget" (Total budget) out as 
it would have squeezed most of the dots even farther to the left. 
However, it might help.

mwdat<-read.table(text=
"KOST                  Budget        IST
1060                 -2.18          0
1080                  91037.71   91647.15
1100                  955573.87  907938.98
1120                  23326.8          0
1150                 2521.57          0
1180                 51302.03   48760.45
1200                  2027.04    -1667.5
1210                 2385.03    2386.06
1220                       0          0
1250                  528.87          0
1255                 766.54          0
1260                 12154.97    4861.41",
 header=TRUE)
options(scipen=4)
par(las=1)
plot(mwdat$Budget,mwdat$KOST,main="IST against Budget",
 xlab="Budget",ylab="KOST",
 xlim=range(mwdat$Budget),ylim=range(mwdat$KOST),
 type="n",yaxt="n")
abline(h=mwdat$KOST,lty=2,col="lightgray")
points(mwdat$Budget,mwdat$KOST,pch=19,col="blue",cex=3)
points(mwdat$IST,mwdat$KOST,pch=19,col="green",cex=3)
legend(400000,1250,c("Budget","IST"),pch=19,
 col=c("blue","green"),bty="n")
options(scipen=0)
axis(2,at=mwdat$KOST)
par(las=0)

Jim


From teotjunk at hotmail.com  Fri Oct 24 09:59:51 2014
From: teotjunk at hotmail.com (TJUN KIAT TEO)
Date: Fri, 24 Oct 2014 15:59:51 +0800
Subject: [R] Fine Tuning Parameters for LogReg in Caret
Message-ID: <SNT148-W422E682179294EA122309DF930@phx.gbl>

Is there a guide somewhere on how to set the tuning parameters for logistic regression in Caret ?


Tjun Kiat


 		 	   		  
	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Fri Oct 24 11:50:55 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 24 Oct 2014 10:50:55 +0100
Subject: [R] how to calculate a numeric's digits count?
In-Reply-To: <20141024090557.01a956a5524ed8a3f4a7a2c9@univ-nantes.fr>
References: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
	<3A0F3010-A7B9-479A-945D-AD812CD50FEF@dcn.davis.CA.us>
	<47fc238.1f3e3.14940c7ae64.Coremail.rhelpmaillist@163.com>
	<20141024090557.01a956a5524ed8a3f4a7a2c9@univ-nantes.fr>
Message-ID: <4C256D85-8EE4-4727-87D5-7076F093B4CD@LGCGroup.com>

Dear Po Su,

All floating point numbers in R have exactly the same number of binary digits (53) and therefore the same number of decimal digits (15.95, as decimals aren't represented exactly in binary). If you want to find out how many decimal digits are after the decimal point, you could try subtracting floor(log10(x)) from 16.
Anything else is pretty much futile - to the point of nonsensical. You can never have exact representation of all decimal fractions in a binary computer, and once you understand that you can see that the number of decimal digits you get from any character representation depends only on how much you decide to round when converting to character format. That is essentially arbitrary, so any games you play with conversion to character are just telling you how many digits you decided to round each number to, not how many there were to start with.


S Ellison




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ntfredo at gmail.com  Fri Oct 24 11:54:48 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Fri, 24 Oct 2014 12:54:48 +0300
Subject: [R] Computing Water Balance using a loop.
In-Reply-To: <CAGh51gQS1ZkOcdgzeP7rXjcXi=yiWmoEP4=3uCVGa3-pBhnV0A@mail.gmail.com>
References: <CAGh51gQ7PNRYZxe9=1MX_yhgRyx=uQ3dhvwnCJ1m2bVgG_mCtA@mail.gmail.com>
	<D06E7498.1101B9%macqueen1@llnl.gov>
	<CAGh51gQS1ZkOcdgzeP7rXjcXi=yiWmoEP4=3uCVGa3-pBhnV0A@mail.gmail.com>
Message-ID: <CAGh51gSFMV53bmw4QiHVVLCbZ14JVyuOM0_6mQ_pbAfVGMBf3Q@mail.gmail.com>

Thanks All,

This is how I solved the problem and working correctly.

  ndays <- nrow(Wb30)
  for (iday in 2:ndays) {

    #Wb30$Water_Balance <- with( Wb30, cumsum(Water_Balance + Rainfall -
Evaporation ) )
    # Wb30$Water_Balance <- with( Wb30, cumsum(Wb30$Water_Balance[iday-1] +
Wb30$Rainfall[iday] - Wb30$Evaporation[iday] ) )
    #Wb30$Water_Balance[iday] <- min(Wb30$Water_Balance[iday], 0)
    #Wb30$Water_Balance[iday] <- max(Wb30$Water_Balance[iday], 100)
    #Wb30$ValidWB <- with( Wb30, 0 == cumsum( Water_Balance < 0 | 100 <
Water_Balance ) )
    Wb30$Water_Balance[iday] <- Wb30$Water_Balance[iday-1] +
Wb30$Rainfall[iday] - Wb30$Evaporation[iday]
    if (Wb30$Water_Balance[iday]<0){
      Wb30$Water_Balance[iday]=0
    }else if(Wb30$Water_Balance[iday]>100){
      Wb30$Water_Balance[iday]=100
    }
  }

Regards,
Frederic.

Frederic Ntirenganya
Maseno University,
African Maths Initiative,
Kenya.
Mobile:(+254)718492836
Email: fredo at aims.ac.za
https://sites.google.com/a/aims.ac.za/fredo/

On Fri, Oct 24, 2014 at 10:49 AM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> Hi Mac,
>
> The first entry is 0 for water balance. That means the 3rd should be zero
> according to the formula.
>
> Water balance today = Water balance yesterday + Rainfall ? Evaporation
>
> This loop gives 5 for each date. I don't see why ?
>
>   May Rainfall Evaporation Water_Balance
> 1   7        0           5             0
> 2   8       10           5            NA
> 3   9        0           5            NA
> 4  10        0           5            NA
> 5  11        2           5            NA
> 6  12       23           5            NA
>
> Regards,
> Frederic.
>
> Frederic Ntirenganya
> Maseno University,
> African Maths Initiative,
> Kenya.
> Mobile:(+254)718492836
> Email: fredo at aims.ac.za
> https://sites.google.com/a/aims.ac.za/fredo/
>
> On Thu, Oct 23, 2014 at 7:17 PM, MacQueen, Don <macqueen1 at llnl.gov> wrote:
>
>> If I understand the problem correctly, then I?d suggest this:
>>
>> ndays <- nrow(Wb30)
>>
>> for (iday in 2:ndays) {
>>
>>   Wb30$Water_Balance[iday] <- Wb30$Water_Balance[iday-1] +
>>      Wb30$Rainfall[iday] - Wb30$Evaporation[iday]
>>
>>   Wb30$Water_Balance[iday] <- min(Wb30$Water_Balance[iday], 100)
>>   Wb30$Water_Balance[iday] <- max(Wb30$Water_Balance[iday], 0)
>>
>> }
>>
>> It may be possible without a loop, but I think a loop is easier to
>> understand in the current circumstances. And is likely to be fast enough
>> that it does not matter.
>>
>> -
>> Don MacQueen
>>
>> Lawrence Livermore National Laboratory
>> 7000 East Ave., L-627
>> Livermore, CA 94550
>> 925-423-1062
>>
>>
>>
>>
>>
>> On 10/23/14, 5:33 AM, "Frederic Ntirenganya" <ntfredo at gmail.com> wrote:
>>
>> >Dear All,
>> >
>> >I want to calculate water balance using the following formula:
>> >Water balance today = Water balance yesterday + Rainfall - Evaporation
>> >
>> >This is a sample of data I am using:
>> >
>> >head(Wb30)
>> >  May Rainfall Evaporation Water_Balance
>> >1   7        0           5             0
>> >2   8       10           5            NA
>> >3   9        0           5            NA
>> >4  10        0           5            NA
>> >5  11        2           5            NA
>> >6  12       23           5            NA
>> >
>> >The following is the loop am trying to use but it is not working well.
>> >
>> >#Water balance today = Water balance yesterday + Rainfall - Evaporation
>> >#If Water balance today < 0 then Water balance today = 0
>> >#If Water balance today > 100 then Water balance today = 100
>> >wb=c()
>> >for (w in 1:length(Wb30$Water_Balance)){
>> >  if(w<0 & w>100){w<-0 & w<-100}
>> >  #print (w);
>> > for (i in 1:length(Wb30$Rainfall)){
>> >    for (j in 1:length(Wb30$Evaporation)){
>> >    }
>> >  }
>> > wb<-Wb30$Water_Balance[w] + Wb30$Rainfall[i+1]-Wb30$Evaporation[j+1]
>> >}
>> >wb
>> >
>> >Any suggest of what I am missing for it to work correctly is welcome.
>> >
>> >
>> >Regards,
>> >
>> >Frederic Ntirenganya
>> >Maseno University,
>> >African Maths Initiative,
>> >Kenya.
>> >Mobile:(+254)718492836
>> >Email: fredo at aims.ac.za
>> >https://sites.google.com/a/aims.ac.za/fredo/
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Fri Oct 24 12:36:04 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 24 Oct 2014 06:36:04 -0400
Subject: [R] how to calculate a numeric's digits count?
In-Reply-To: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
References: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
Message-ID: <544A2B94.4090109@gmail.com>

On 23/10/2014, 11:35 PM, PO SU wrote:
> 
> Dear usRers,
>   Now i want to cal ,e.g. 
>  cal(1.234)  will get 3
>  cal(1) will get 0
>  cal(1.3045) will get 4
>  But the difficult part is cal(1.3450) will get 4 not 3.
> So, is there anyone happen to know the solution to this problem, or it can't be solved in R, because 1.340 will always be transformed autolly to 1.34?
> 

No, there's no way to do what you want unless you put quotes around the
number.  R parses 1.345 and 1.3450 as exactly the same thing, whereas
"1.345" and "1.3450" are different.

Duncan Murdoch


From ruipbarradas at sapo.pt  Fri Oct 24 13:31:27 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 24 Oct 2014 12:31:27 +0100
Subject: [R] Apply Function to Columns
In-Reply-To: <3DA37DB1-D024-4A7F-9AF7-859AEAE8B82E@gmail.com>
References: <8CF1C263-962A-4861-8005-D46DD33FF29E@gmail.com>
	<54492392.4050907@sapo.pt>
	<3DA37DB1-D024-4A7F-9AF7-859AEAE8B82E@gmail.com>
Message-ID: <544A388F.4030405@sapo.pt>

Hello,

Please cc the list, the odds of getting more and better answers are greater.
And you should tell us from what package do the function plot.correlog 
comes. library(what)?

As for your question, assuming you want to save your plots as PNG files, 
you could do something like the following.


fun <- function(p){
	fname <- paste0("correlog", p)
	png(filename = fname)
	plot.correlog(...)
	dev.off()
}
ddeg.correlog.list <- lapply(9:20, fun)

See the help page for ?png. It lists several other graphics file formats 
you can use.

Hope this helps,

Rui Barradas

Em 24-10-2014 08:23, Sarah escreveu:
> Thank you very much, it helped a lot!
>
> I just have another question know. I want to make plot for every
> species. I just add the function ? plot correlog ? to the previous
> function and I have now the following script:
>
> ddeg.correlog.list <- lapply(9:20, function(p)
> *plot.correlog*(correlog(plant[plant[,p]=="1", 2], plant[plant[,p]=="1",
> 3],
>                           plant[plant[,p]=="1", 4],increment=2500)))
>
> It?s working, but I wanted to know if there is a way to save each plot.
> I found that I can use the dev.off function or the ggplot function of
> the package ggplot2, but I can?t figure out how to use it within the
> lapply function. Do you think there is a way?
>
> Thank you for your help!
>
> Sarah
>
>> Le 23 oct. 2014 ? 17:49, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> a ?crit :
>>
>> Hello,
>>
>> Yes, you can use lapply. Maybe something like the following. Note that
>> the result is a list with one member per species. (Untested).
>>
>> ddeg.correlog.list <- lapply(9:11, function(p)
>> correlog(plant[plant[,p]=="1", 2], plant[plant[,p]=="1", 3],
>> plant[plant[,p]=="1", 4]))
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 23-10-2014 16:06, Sarah escreveu:
>>> Hello List,
>>>
>>> I have a database which consist of 912 plots. For each plot, I have
>>> the presence/absence information of 260 species of plants and also 5
>>> different environmental variables (ddeg, mind, srad, slp, topo).
>>>
>>> The dataframe looks like this:
>>>
>>>   Plot_Number        X Y ddeg mind   srad slp topo Galium_mollugo
>>> Gentiana_nivalis
>>> 1        1 557747.6 149726.8 2598 -625 236363   8  176              0
>>>                0
>>> 2        2 572499.4 145503.5 2178 -176 161970  14 -137              0
>>>                0
>>> 3        3 579100.4 151800.4 1208  632 267572  33  129              0
>>>                0
>>> 4        4 581301.7 150300.1 1645   83 246633  15  -70              0
>>>                0
>>> 5        5 579838.7 124770.9 1102 1637 158300   2 -231              0
>>>                0
>>> 6        6 577011.1 121328.6  731 2223 180286  41   70              0
>>>                0
>>>
>>> Now, what I wanted to do is to calculate spatial autocorrelation of
>>> each environmental variable for each species, but only for the plots
>>> where the species is present.
>>>
>>> I will use the correlog function of the package ncf (doesn?t really
>>> matter). The correlog function work with an argument X which is the
>>> longitude, an argument Y which is the latitude and an argument Z
>>> which is the variable you want to test for autocorrelation (in my
>>> case, the different environmental variables).
>>>
>>> So, for the first species I have the following script:
>>>
>>> ddeg.correlog.9<-correlog(plant[plant[,9]=="1", 2],
>>> plant[plant[,9]=="1", 3], plant[plant[,9]=="1", 4])
>>>
>>> X = plant[plant[,9]=="1", 2] ?>  only the X coordinate where my
>>> species 9 is present
>>> Y = plant[plant[,9]=="1", 3] ?>  only the Y coordinate where my
>>> species 9 is present
>>> Z = plant[plant[,9]=="1", 4] ?>  only the value of the environmental
>>> variable where my species 9 is present
>>>
>>> plant: dataframe
>>> 9: column corresponding to the first species
>>> 2: column corresponding to the X coordinate
>>> 3: column correspondind to the Y coordinate
>>> 4: column corresponding to the first environmental variable
>>>
>>> So my question is: how do I repeat this script for every species
>>> (basically, I just have to change the number ? 9 ? into 10, 11 and so
>>> on) ?
>>>
>>> I try to write a function but I?m new in R and didn?t manage to do
>>> it. I was also considering to use the function ? lapply ?, but I
>>> don?t think I can use it in this case, isn?t it?
>>>
>>> Thank you very much for your help !
>>>
>>> Sarah
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>


From sarahschmid98 at gmail.com  Fri Oct 24 14:45:56 2014
From: sarahschmid98 at gmail.com (Sarah Schmid)
Date: Fri, 24 Oct 2014 14:45:56 +0200
Subject: [R] RE : Re:  Apply Function to Columns
Message-ID: <3l09k9pnr0xro59yl0coqf30.1414154756907@email.android.com>

Hello !?

Yes, I realized just after sending you the email that I didn't cc the list, so I sent it again just after that.?

And thank you very much for your help, it works perfectly !?

And the package I used was ncf.

Sarah

-------- Message d'origine --------
De : Rui Barradas <ruipbarradas at sapo.pt> 
Date :  
A : Sarah <sarahschmid98 at gmail.com> 
Cc : R-help at r-project.org 
Objet : Re: [R] Apply Function to Columns 
 
Hello,

Please cc the list, the odds of getting more and better answers are greater.
And you should tell us from what package do the function plot.correlog 
comes. library(what)?

As for your question, assuming you want to save your plots as PNG files, 
you could do something like the following.


fun <- function(p){
fname <- paste0("correlog", p)
png(filename = fname)
plot.correlog(...)
dev.off()
}
ddeg.correlog.list <- lapply(9:20, fun)

See the help page for ?png. It lists several other graphics file formats 
you can use.

Hope this helps,

Rui Barradas

Em 24-10-2014 08:23, Sarah escreveu:
> Thank you very much, it helped a lot!
>
> I just have another question know. I want to make plot for every
> species. I just add the function ? plot correlog ? to the previous
> function and I have now the following script:
>
> ddeg.correlog.list <- lapply(9:20, function(p)
> *plot.correlog*(correlog(plant[plant[,p]=="1", 2], plant[plant[,p]=="1",
> 3],
>?????????????????????????? plant[plant[,p]=="1", 4],increment=2500)))
>
> It?s working, but I wanted to know if there is a way to save each plot.
> I found that I can use the dev.off function or the ggplot function of
> the package ggplot2, but I can?t figure out how to use it within the
> lapply function. Do you think there is a way?
>
> Thank you for your help!
>
> Sarah
>
>> Le 23 oct. 2014 ? 17:49, Rui Barradas <ruipbarradas at sapo.pt
>> <mailto:ruipbarradas at sapo.pt>> a ?crit :
>>
>> Hello,
>>
>> Yes, you can use lapply. Maybe something like the following. Note that
>> the result is a list with one member per species. (Untested).
>>
>> ddeg.correlog.list <- lapply(9:11, function(p)
>> correlog(plant[plant[,p]=="1", 2], plant[plant[,p]=="1", 3],
>> plant[plant[,p]=="1", 4]))
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 23-10-2014 16:06, Sarah escreveu:
>>> Hello List,
>>>
>>> I have a database which consist of 912 plots. For each plot, I have
>>> the presence/absence information of 260 species of plants and also 5
>>> different environmental variables (ddeg, mind, srad, slp, topo).
>>>
>>> The dataframe looks like this:
>>>
>>>?? Plot_Number??????? X Y ddeg mind?? srad slp topo Galium_mollugo
>>> Gentiana_nivalis
>>> 1??????? 1 557747.6 149726.8 2598 -625 236363?? 8? 176????????????? 0
>>>??????????????? 0
>>> 2??????? 2 572499.4 145503.5 2178 -176 161970? 14 -137????????????? 0
>>>??????????????? 0
>>> 3??????? 3 579100.4 151800.4 1208? 632 267572? 33? 129????????????? 0
>>>??????????????? 0
>>> 4??????? 4 581301.7 150300.1 1645?? 83 246633? 15? -70????????????? 0
>>>??????????????? 0
>>> 5??????? 5 579838.7 124770.9 1102 1637 158300?? 2 -231????????????? 0
>>>??????????????? 0
>>> 6??????? 6 577011.1 121328.6? 731 2223 180286? 41?? 70????????????? 0
>>>??????????????? 0
>>>
>>> Now, what I wanted to do is to calculate spatial autocorrelation of
>>> each environmental variable for each species, but only for the plots
>>> where the species is present.
>>>
>>> I will use the correlog function of the package ncf (doesn?t really
>>> matter). The correlog function work with an argument X which is the
>>> longitude, an argument Y which is the latitude and an argument Z
>>> which is the variable you want to test for autocorrelation (in my
>>> case, the different environmental variables).
>>>
>>> So, for the first species I have the following script:
>>>
>>> ddeg.correlog.9<-correlog(plant[plant[,9]=="1", 2],
>>> plant[plant[,9]=="1", 3], plant[plant[,9]=="1", 4])
>>>
>>> X = plant[plant[,9]=="1", 2] ?>? only the X coordinate where my
>>> species 9 is present
>>> Y = plant[plant[,9]=="1", 3] ?>? only the Y coordinate where my
>>> species 9 is present
>>> Z = plant[plant[,9]=="1", 4] ?>? only the value of the environmental
>>> variable where my species 9 is present
>>>
>>> plant: dataframe
>>> 9: column corresponding to the first species
>>> 2: column corresponding to the X coordinate
>>> 3: column correspondind to the Y coordinate
>>> 4: column corresponding to the first environmental variable
>>>
>>> So my question is: how do I repeat this script for every species
>>> (basically, I just have to change the number ? 9 ? into 10, 11 and so
>>> on) ?
>>>
>>> I try to write a function but I?m new in R and didn?t manage to do
>>> it. I was also considering to use the function ? lapply ?, but I
>>> don?t think I can use it in this case, isn?t it?
>>>
>>> Thank you very much for your help !
>>>
>>> Sarah
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Fri Oct 24 15:55:49 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Fri, 24 Oct 2014 13:55:49 +0000
Subject: [R] how to calculate a numeric's digits count?
In-Reply-To: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
References: <4b17a57d.15983.1494038d2d1.Coremail.rhelpmaillist@163.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FAC8F8@mb02.ads.tamu.edu>

Where do these numbers come from? If they are calculated values, they are actually many decimal places longer than your examples. They are represented on your terminal with fewer decimals according to the setting of options("digits"). 

For example:

> sqrt(2)*sqrt(2)
[1] 2
> sqrt(2)*sqrt(2) == 2  
[1] FALSE
# FAQ 7.31 Why doesn?t R think these numbers are equal?
> options("digits")
$digits
[1] 7
> options(digits=22)
> sqrt(2)*sqrt(2)
[1] 2.000000000000000444089

If the numbers were read from a plain text file and you are talking about how they are represented in the file, analyze them as character strings.

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of PO SU
Sent: Thursday, October 23, 2014 10:35 PM
To: R. Help
Subject: [R] how to calculate a numeric's digits count?


Dear usRers,
? Now i want to cal ,e.g. 
?cal(1.234)? will get 3
?cal(1) will get 0
?cal(1.3045) will get 4
?But the difficult part is cal(1.3450) will get 4 not 3.
So, is there anyone happen to know the solution to this problem, or it can't be solved in R, because 1.340 will always be transformed autolly to 1.34?






--

PO SU
mail: desolator88 at 163.com 
Majored in Statistics from SJTU
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From Mike.Beddo at dataventures.com  Fri Oct 24 18:24:39 2014
From: Mike.Beddo at dataventures.com (Mike Beddo)
Date: Fri, 24 Oct 2014 16:24:39 +0000
Subject: [R] Error: Line starting 'Package: tools ...' is malformed!
Message-ID: <AA01911644A2F84FB4571C323FC45DD56A5213F9@TWIX.dataventures.local>

I'm building R-3.1.1 (64 bit) from source on AIX 7.1. It was going well until I hit this:

xlc_r -q64 -Wl,-brtl -Wl,-G -Wl,-bexpall -Wl,-bnoentry -lc -L/opt/freeware/lib64 -L/opt/freeware/lib -Wl,-blibpath:/opt/freeware/lib64:/opt/freeware/lib:/usr/lib:/lib -Wl,-bmaxdata:0x80000000 -o tools.so text.o init.o Rmd5.o md5.o signals.o install.o getfmts.o http.o gramLatex.o gramRd.o -lm
make[6]: Entering directory `/home/meb/source/R-3.1.1/src/library/tools/src'
mkdir -p -- ../../../../library/tools/libs
make[6]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools/src'
make[5]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools/src'
make[4]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
Error: Line starting 'Package: tools ...' is malformed!
Execution halted
make[3]: *** [all] Error 1
make[3]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/meb/source/R-3.1.1/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/meb/source/R-3.1.1/src'
make: *** [R] Error 1
$ oslevel
7.1.0.0

Can someone help?

Thanks,

Mike


From jdnewmil at dcn.davis.CA.us  Fri Oct 24 18:42:41 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 24 Oct 2014 09:42:41 -0700
Subject: [R] Error: Line starting 'Package: tools ...' is malformed!
In-Reply-To: <AA01911644A2F84FB4571C323FC45DD56A5213F9@TWIX.dataventures.local>
References: <AA01911644A2F84FB4571C323FC45DD56A5213F9@TWIX.dataventures.local>
Message-ID: <9A67F3C0-CEC4-449C-9B85-FF5CD73854BF@dcn.davis.CA.us>

Helpful tip: there is a Posting Guide that points out that there is an R-devel mailing list for this kind of question, among other useful advice.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 24, 2014 9:24:39 AM PDT, Mike Beddo <Mike.Beddo at dataventures.com> wrote:
>I'm building R-3.1.1 (64 bit) from source on AIX 7.1. It was going well
>until I hit this:
>
>xlc_r -q64 -Wl,-brtl -Wl,-G -Wl,-bexpall -Wl,-bnoentry -lc
>-L/opt/freeware/lib64 -L/opt/freeware/lib
>-Wl,-blibpath:/opt/freeware/lib64:/opt/freeware/lib:/usr/lib:/lib
>-Wl,-bmaxdata:0x80000000 -o tools.so text.o init.o Rmd5.o md5.o
>signals.o install.o getfmts.o http.o gramLatex.o gramRd.o -lm
>make[6]: Entering directory
>`/home/meb/source/R-3.1.1/src/library/tools/src'
>mkdir -p -- ../../../../library/tools/libs
>make[6]: Leaving directory
>`/home/meb/source/R-3.1.1/src/library/tools/src'
>make[5]: Leaving directory
>`/home/meb/source/R-3.1.1/src/library/tools/src'
>make[4]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
>Error: Line starting 'Package: tools ...' is malformed!
>Execution halted
>make[3]: *** [all] Error 1
>make[3]: Leaving directory `/home/meb/source/R-3.1.1/src/library/tools'
>make[2]: *** [R] Error 1
>make[2]: Leaving directory `/home/meb/source/R-3.1.1/src/library'
>make[1]: *** [R] Error 1
>make[1]: Leaving directory `/home/meb/source/R-3.1.1/src'
>make: *** [R] Error 1
>$ oslevel
>7.1.0.0
>
>Can someone help?
>
>Thanks,
>
>Mike
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Fri Oct 24 18:51:20 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 24 Oct 2014 09:51:20 -0700
Subject: [R] Heatmap - strange horizontal lines
In-Reply-To: <CADQCJLB3bax-aNdh1mL5E41ahhdWPVZEmB5qXvsnEkEyQ=L+Jg@mail.gmail.com>
References: <CADQCJLB3bax-aNdh1mL5E41ahhdWPVZEmB5qXvsnEkEyQ=L+Jg@mail.gmail.com>
Message-ID: <F3FC59D1-43C9-4B56-8F2F-5478F046A82C@dcn.davis.CA.us>

I don't use these functions often enough to know their idiosyncrasies, but they appear to treat zero like a NA, and your second file has lots of zeros. I suspect this is due to the default way the continuous act data are 'cut" excluding the left side of the bins. If you read the help files you may find a way to change this or you could cut it to a factor yourself and give the factor to be plotted instead of the continuous variable.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 23, 2014 11:45:54 AM PDT, zuzana zajkova <zuzulaz at gmail.com> wrote:
>Dear list,
>
>I would like to make heatmaps from my data. Acctualy, I have already
>done
>it, but the issue it that is doesn't work well for all files.
>
>All files have the same structure, after importing them I do few
>calculations using the same script, to obtain variables for plotting.
>
>You can find the files here, the pb2166 is the one which works fine and
>I
>get normal (expected) heatmap plot, the pb2214 it the other type, for
>which
>I obtain strange horizontal lines...
>
>https://www.dropbox.com/s/rz2ywnloepvr3d8/pb2166.csv?dl=0
>https://www.dropbox.com/s/42taaybtbortv0p/pb2214.csv?dl=0
>
>The structure of data is this (the same, from my point of view...):
>
>str(pb2166)
>'data.frame':  55119 obs. of  3 variables:
> $ dtime: num  17.9 18.1 18.3 18.4 18.6 ...
> $ act  : int  9 1 0 0 0 0 0 0 0 0 ...
> $ jul  : num  13573 13573 13573 13573 13573 ...
>
>str(pb2214)
>'data.frame':  44707 obs. of  3 variables:
> $ dtime: num  17.9 18.1 18.2 18.4 18.6 ...
> $ act  : int  9 1 0 0 0 0 0 0 0 0 ...
> $ jul  : num  13573 13573 13573 13573 13573 ...
>
>
>To  create a heatmap I tried ggplot/qlot and levelplot aswell, the
>results
>are the same... for pb2166 works ok, for pb2214 doesn't...
>
>qplot(jul, dtime, data=pb2166, geom="tile", fill=act) +
>scale_fill_gradient(low="gold", high="green4")
>levelplot(act ~ jul * dtime, pb2166 )
>
>qplot(jul, dtime, data=pb2214, geom="tile", fill=act) +
>scale_fill_gradient(low="gold", high="green4")
>levelplot(act ~ jul * dtime, pb2214 )
>
>I would be very thankful if somebody could take a look on the data and
>find
>something what I am missing.
>
>Kind regards,
>
>Zuzana
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From alemu.tadesse at gmail.com  Fri Oct 24 19:13:12 2014
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Fri, 24 Oct 2014 11:13:12 -0600
Subject: [R] I cannot get files from this site
Message-ID: <CACGkHRN+N=yz2Xkad=naHqY7ugCyA-4bPmPsSAPXMMzPuSBJFw@mail.gmail.com>

Dear r-help users,

I have been trying to download files from this link
ftp://ftp.bsrn.awi.de/tat/tat0100.dat.gz sinsce yesterday using
download.file (which I use very often for such task) and unfortunately it
did not work for me for this ftp site. I can manually download the files -
but not with script with both R and python. Is there any tip for this ?

Thank you in Advance and happy Friday.

Alemu

	[[alternative HTML version deleted]]


From guido.biele at neuro-cognition.org  Fri Oct 24 12:06:11 2014
From: guido.biele at neuro-cognition.org (Guido Biele)
Date: Fri, 24 Oct 2014 12:06:11 +0200
Subject: [R] rgdal: Convert ESRI ArcGis geo database (gdb directory) to
 geojson, or shapefile map
Message-ID: <CAKXF9PRuXOoJfQVk-RQTzWOudVM55tgpLL5quBoD+FNJ92Gz_g@mail.gmail.com>

Hello,

I have an ESRI  ArGis geo database directory which I would like to convert
to geojson or a shape file (or anything else that I can read into R).

Unfortunately that does not work out of the box with rgdal, because it does
not come with the fileGDB or openfileGDB driver.
I could successfully install gdal and the fileGDB driver/extension, but it
seems that i can use gdal only to convert the gdb file to a SQL database.

So before I start to learn about SQL, I thought I ask if anybody can point
me to a tutorial or similar that explains how to convert the contents of a
GDB folder to a R-readable format.

I also wondered if it would be possible to let rgdal know that it could
access the required drivers because I installed them manually.
I would appreciate any hint about this too!

Thanks in advance!
Best Guido

	[[alternative HTML version deleted]]


From dan.vatnik at gmail.com  Fri Oct 24 17:31:47 2014
From: dan.vatnik at gmail.com (Dan Vatnik)
Date: Fri, 24 Oct 2014 11:31:47 -0400
Subject: [R] Extra documentation not appearing
Message-ID: <CAPwpSvh9U_xmJ5L7Yo5sC6UGJLRsh6cOyX6HxhC=pGf8v=5LFg@mail.gmail.com>

Hi,

I have loaded my first package to CRAN and I have noticed a documentation
issue.
When I install the package from CRAN, it installs a Windows binary since I
am using a Windows machine.
I have a PDF file in my doc folder. Originally, it was in the inst/doc/
folder but when I load the binary, there
is no more inst folder so the doc folder is directly in the package folder.
The issue arises in my package's index page. It has a link to the
DESCRIPTION file and it has a link to the
Extra documentation section on top. The link to the Extra documentation
does not lead anywhere so my PDF
is inaccessible.
My package is named "traj".
Do you know what might be the issue?

Thank You,
Dan

	[[alternative HTML version deleted]]


From Matthias.Weber at fntsoftware.com  Fri Oct 24 12:49:39 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Fri, 24 Oct 2014 12:49:39 +0200
Subject: [R] dotplot with library lattice
In-Reply-To: <707072790.FfmNddDgBm@localhost.localdomain>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
	<707072790.FfmNddDgBm@localhost.localdomain>
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF2D9@mail.ell.fnt.de>

Hi Jim,

thanks for your reply.

Doesn't look very bad, but what I mean with "Budget 100", is the percentage of the process on the x-axis. As a example, the Budget for ""1120" is 23326.8. At the moment we have "0" as value for IST. In this case, the blue button should be stand at 100% (x-axis = process in %) on the right side and the green button is on the x-axis at 0 (left side), because the value is 0. If the value for "1120" rises up to 11663, the blue button is still at 100% on the right side (the blue button is in all cases on the right side) and the green button is right in the middle, because the Budget is 50% full.

I want always to see the "Process" of the green button in dependence of the blue button at 100%.

Maybe you can help me.

Thank you.

Best regards.

Mat

-----Urspr?ngliche Nachricht-----
Von: Jim Lemon [mailto:jim at bitwrit.com.au]
Gesendet: Freitag, 24. Oktober 2014 11:29
An: r-help at r-project.org
Cc: Matthias Weber
Betreff: Re: [R] dotplot with library lattice

On Thu, 23 Oct 2014 05:57:27 PM Matthias Weber wrote:
> Hello together,
>
> i have a short question. Maybe anyone can help me to create a
barplot in R
> with the package lattice.
>
> I have the following data as ouput values and the following code:
>
> Data (d):
>
> KOST                  Budget        IST
> 1060                 -2.18          0
> 1080                  91037.71   91647.15
> 1100                  955573.87  907938.98
> 1120                  23326.8          0
> 1150                 2521.57          0
> 1180                 51302.03   48760.45
> 1200                  2027.04    -1667.5
> 1210                 2385.03    2386.06
> 1220                       0          0
> 1250                  528.87          0
> 1255                 766.54          0
> 1260                 12154.97    4861.41
> Gesamtbudget 1141622.25 1054236.55
>
> Code:
>
> ### read the data
>
> d$KOST <- ordered( d$KOST, levels = d$KOST)
>
> ### load lattice and grid
> require( lattice )
>
>  ### setup the key
> k <- simpleKey( c( "Budget",  "IST" ) ) k$points$fill <- c("blue",
> "darkgreen") k$points$pch <- 21 k$points$col <- "black"
> k$points$cex <- 1
>
>  ### create the plot
> dotplot( KOST ~ Budget + IST , data = d, horiz = TRUE,
>      par.settings = list(
>          superpose.symbol = list(
>              pch = 21,
>              fill = c( "blue", "darkgreen"),
>              cex = 3,
>              col = "black"
>          )
>       ) , xlab = "Kostenstellen?bersicht", key = k,
>       panel = function(x, y,  ...){
>         panel.dotplot( x, y, ... )
> #       grid.text(
>   #           unit( x, "native") , unit( y, "native") ,
>    #          label = x, gp = gpar( cex = .7 ) )
>       } )
>
> The result look like the attached graph. But this is not exactly what
> I want. I want the "Budget" on the right side (100), and the
> "IST"-Value
in
> dependence of the "Budget" between 0 and 100. As a example. If
there is a
> budget over 100.000 and the "IST"-Value ist around 50.000, the blue
button
> should be on the right side and the green button right in the middle.
>
> Maybe anyone can help me.
>
> Thank you.
>
> Best regards.
>
> Mat
>
>
Hi Mat,
I must admit that I have probably misunderstood your request. I have assumed that you want the Budget as the x axis and the KOST as the y axis. You seemed to be asking for Budget to be always 100 and that didn't make sense. For some reason the "scipen" option stopped working for me after the first plot and so I couldn't get rid of the scientific notation on the x axis. Also this was done in base graphics rather than lattice. I also left the "Gesamtbudget" (Total budget) out as it would have squeezed most of the dots even farther to the left.
However, it might help.

mwdat<-read.table(text=
"KOST                  Budget        IST
1060                 -2.18          0
1080                  91037.71   91647.15
1100                  955573.87  907938.98
1120                  23326.8          0
1150                 2521.57          0
1180                 51302.03   48760.45
1200                  2027.04    -1667.5
1210                 2385.03    2386.06
1220                       0          0
1250                  528.87          0
1255                 766.54          0
1260                 12154.97    4861.41",
 header=TRUE)
options(scipen=4)
par(las=1)
plot(mwdat$Budget,mwdat$KOST,main="IST against Budget",  xlab="Budget",ylab="KOST",  xlim=range(mwdat$Budget),ylim=range(mwdat$KOST),
 type="n",yaxt="n")
abline(h=mwdat$KOST,lty=2,col="lightgray")
points(mwdat$Budget,mwdat$KOST,pch=19,col="blue",cex=3)
points(mwdat$IST,mwdat$KOST,pch=19,col="green",cex=3)
legend(400000,1250,c("Budget","IST"),pch=19,
 col=c("blue","green"),bty="n")
options(scipen=0)
axis(2,at=mwdat$KOST)
par(las=0)

Jim


This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.


From chrisaa at med.umich.edu  Fri Oct 24 22:11:40 2014
From: chrisaa at med.umich.edu (Andrews, Chris)
Date: Fri, 24 Oct 2014 20:11:40 +0000
Subject: [R] Default Display of hist.Date with breaks="months"
Message-ID: <30411786F64EEF46856EFBA2CD9177992C323F24@UHEXMBSPR03.umhs.med.umich.edu>

Hi all,

The default display of random dates with breaks="months" is less than optimal.

set.seed(20141024)
random.dates <- as.Date("2001/1/1") + round(365*stats::runif(100))
hist(random.dates, "months")

The 13 edges of the 12 bars are labelled "Dec", "Jan", "Feb", ..., "Nov", "Dec".
The first bar represents the number of days in January, the label on the RIGHT edge of the bar.

It is clear what is happening if the format is changed.

hist(random.dates, "months", format = "%d %b", las=2)

The labels are now "Dec 31", "Jan 31", "Feb 28", ....  which isn't intuitive to me.

I'd rather have this as the default behavior (but without having to explicitly create the breaks)

hist(random.dates, breaks=as.Date(c(paste("2001",1:12,"1",sep="/"), "2002/1/1")), right=FALSE)
hist(random.dates, breaks=as.Date(c(paste("2001",1:12,"1",sep="/"), "2002/1/1")), right=FALSE, format = "%d %b", las=2)

I guess none of that is a question.  Have a nice weekend.

Chris



R version 3.1.1 (2014-07-10)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_3.1.1

**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 


From eric.archer at noaa.gov  Fri Oct 24 23:54:51 2014
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Fri, 24 Oct 2014 14:54:51 -0700
Subject: [R] "command not found" from system() call in GUI with proper PATH
Message-ID: <CAGrYeXi-qiLmEGiv++b27qY5NqmtFMcNyS8c36UvAMSNPJTDXA@mail.gmail.com>

<Apologies for the cross-posting, but I couldn't tell if this was a general
R issue, or Mac-specific>

When running a system file from within R, I have just started to get a
"command not found" error although my PATH seems to be properly set and I
can run the same system file from the terminal. The program I am trying to
run is 'fastsimcoal' and is in /usr/local/bin. I confirm this in the
terminal with

SWC-EARCHER-ML-3:~ eric.archer$ which fastsimcoal
/usr/local/bin/fastsimcoal

In the examples below, Sys.getenv("PATH") shows that /usr/local/bin is in
the PATH. I get the same error for any program in /usr/local/bin. However,
programs in other folders in the path seem to run through system()
properly.

Also, note that the return from Sys.getenv("PATH") is the same for running
in R-Studio vs. R in the terminal, but is truncated in the R GUI. As far as
I can tell I do not have a .Rprofile file in my default working directory,
R_HOME, or R_HOME/etc.

A final piece of information: I have just upgraded to OSX Yosemite v10.10.
This was not happening at some point prior to the upgrade, but it has been
a while since I tried this particular command, so I do not know if it was
working immediately prior to the OS upgrade.

Any help or insight is greatly appreciated.

Cheers,
eric

The examples:

>From within R-Studio v0.98.1079:

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.1.1
> getwd()
[1] "/Users/eric.archer"
> Sys.getenv("PATH")
[1]
"/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/git/bin:/usr/texbin"
> system("fastsimcoal")
sh: fastsimcoal: command not found


The same script in the R console through the GUI gives:

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> getwd()
[1] "/Users/eric.archer"
> Sys.getenv("PATH")
[1] "/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin"
> system("fastsimcoal")
>
/bin/sh: fastsimcoal: command not found


Running it through R in a  terminal window, it runs (output of
'fastsimcoal' truncated):

> sessionInfo()
R version 3.1.1 (2014-07-10)
Platform: x86_64-apple-darwin13.1.0 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
> getwd()
[1] "/Users/eric.archer"
> Sys.getenv("PATH")
[1]
"/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/git/bin:/usr/texbin"
> system("fastsimcoal")


fastSimcoal2 (ver 2.1 December 2013)

Usage:

 -h  --help              : prints this help
 -i  --ifile test.par    : name of parameter file
...

----

*Eric Archer, Ph.D.*
Southwest Fisheries Science Center
NMFS, NOAA
8901 La Jolla Shores Drive
La Jolla, CA 92037 USA
858-546-7121 (work)
858-546-7003 (FAX)

Marine Mammal Genetics Group: swfsc.noaa.gov/mmtd-mmgenetics
ETP Cetacean Assessment Program: swfsc.noaa.gov/mmtd-etp

"


*The universe doesn't care what you believe. The wonderful thing about
science is that it   doesn't ask for your faith, it just asks   for your
eyes.*"  - Randall Munroe

"*Lighthouses are more helpful than churches.*"
   - Benjamin Franklin

   "*...but I'll take a GPS over either one.*"
       - John C. "Craig" George

	[[alternative HTML version deleted]]


From dotnetsqltraining at gmail.com  Fri Oct 24 23:50:20 2014
From: dotnetsqltraining at gmail.com (dotnet sql)
Date: Sat, 25 Oct 2014 08:50:20 +1100
Subject: [R] RCurl memory leak in getURL method
Message-ID: <CABqr0AwgydZkwrnE2JiROsYBiPNT7-5vLPgAee6wnW+Y2FEUAw@mail.gmail.com>

Hi

It looks like we have hit a bug in RCurl. The method getURL seems to be
leaking memory. A simple test case to reproduce the bug is given here:

>library(RCurl)
>handle<-getCurlHandle()
>range<-1:100
>for (r in range) {x<-getURL(url="news.google.com.au",curl=handle)}

If I run this code, the memory allocated to the R session is never
recovered.

We are using RCurl for some long running experiments and we are running out
of memory on the test system.

The specs of our test system are as follows:
OS: Ubuntu 14.04 (64 bit)
Memory: 24 GB
RCurl version: 1.95-4.3

Any ideas about how to get around this issue?

Thanks

	[[alternative HTML version deleted]]


From dolremi at gmail.com  Fri Oct 24 20:20:20 2014
From: dolremi at gmail.com (Jia Xu)
Date: Fri, 24 Oct 2014 11:20:20 -0700
Subject: [R] Fine Tuning Parameters for LogReg in Caret
In-Reply-To: <SNT148-W422E682179294EA122309DF930@phx.gbl>
References: <SNT148-W422E682179294EA122309DF930@phx.gbl>
Message-ID: <CAKDhfe9nt7HBLPc89No0AZrgeLtoAb8vZHAMe=gJeEXZGbsYtA@mail.gmail.com>

Hi, Tjun:
  You can use getModelInfo() function in caret to find more details for
each model.

On Fri, Oct 24, 2014 at 12:59 AM, TJUN KIAT TEO <teotjunk at hotmail.com>
wrote:

> Is there a guide somewhere on how to set the tuning parameters for
> logistic regression in Caret ?
>
>
> Tjun Kiat
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Jia Xu

	[[alternative HTML version deleted]]


From emma.sherratt at gmail.com  Sat Oct 25 00:04:44 2014
From: emma.sherratt at gmail.com (Emma Sherratt)
Date: Sat, 25 Oct 2014 09:04:44 +1100
Subject: [R] [R-SIG-Mac] "command not found" from system() call in GUI
 with proper PATH
In-Reply-To: <CAGrYeXi-qiLmEGiv++b27qY5NqmtFMcNyS8c36UvAMSNPJTDXA@mail.gmail.com>
References: <CAGrYeXi-qiLmEGiv++b27qY5NqmtFMcNyS8c36UvAMSNPJTDXA@mail.gmail.com>
Message-ID: <CAF1_pPss_HwvAQoL43wcf06c9b4rVKvTjO_2OBihzQSK0+L8-g@mail.gmail.com>

I had the same problem and Simon Urbanek replied to me with the following:

It is, because Yosemite ignores PATH for processes started from a GUI
application. You will see if you run
system("echo $PATH")

You have to use full paths in Yosemite for anything that is not on the
"sanctioned" PATH -- or use R from the shell.

On Saturday, October 25, 2014, Eric Archer - NOAA Federal <
eric.archer at noaa.gov> wrote:

> <Apologies for the cross-posting, but I couldn't tell if this was a general
> R issue, or Mac-specific>
>
> When running a system file from within R, I have just started to get a
> "command not found" error although my PATH seems to be properly set and I
> can run the same system file from the terminal. The program I am trying to
> run is 'fastsimcoal' and is in /usr/local/bin. I confirm this in the
> terminal with
>
> SWC-EARCHER-ML-3:~ eric.archer$ which fastsimcoal
> /usr/local/bin/fastsimcoal
>
> In the examples below, Sys.getenv("PATH") shows that /usr/local/bin is in
> the PATH. I get the same error for any program in /usr/local/bin. However,
> programs in other folders in the path seem to run through system()
> properly.
>
> Also, note that the return from Sys.getenv("PATH") is the same for running
> in R-Studio vs. R in the terminal, but is truncated in the R GUI. As far as
> I can tell I do not have a .Rprofile file in my default working directory,
> R_HOME, or R_HOME/etc.
>
> A final piece of information: I have just upgraded to OSX Yosemite v10.10.
> This was not happening at some point prior to the upgrade, but it has been
> a while since I tried this particular command, so I do not know if it was
> working immediately prior to the OS upgrade.
>
> Any help or insight is greatly appreciated.
>
> Cheers,
> eric
>
> The examples:
>
> >From within R-Studio v0.98.1079:
>
> > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_3.1.1
> > getwd()
> [1] "/Users/eric.archer"
> > Sys.getenv("PATH")
> [1]
>
> "/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin:/opt/X11/bin:/usr/local/git/bin:/usr/texbin"
> > system("fastsimcoal")
> sh: fastsimcoal: command not found
>
>
> The same script in the R console through the GUI gives:
>
> > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> > getwd()
> [1] "/Users/eric.archer"
> > Sys.getenv("PATH")
> [1] "/usr/bin:/bin:/usr/sbin:/sbin:/usr/local/bin"
> > system("fastsimcoal")
> >
> /bin/sh: fastsimcoal: command not found
>
>
> Running it through R in a  terminal window, it runs (output of
> 'fastsimcoal' truncated):
>
> > sessionInfo()
> R version 3.1.1 (2014-07-10)
> Platform: x86_64-apple-darwin13.1.0 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> > getwd()
> [1] "/Users/eric.archer"
> > Sys.getenv("PATH")
> [1]
>
> "/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin:/opt/X11/bin:/usr/local/git/bin:/usr/texbin"
> > system("fastsimcoal")
>
>
> fastSimcoal2 (ver 2.1 December 2013)
>
> Usage:
>
>  -h  --help              : prints this help
>  -i  --ifile test.par    : name of parameter file
> ...
>
> ----
>
> *Eric Archer, Ph.D.*
> Southwest Fisheries Science Center
> NMFS, NOAA
> 8901 La Jolla Shores Drive
> La Jolla, CA 92037 USA
> 858-546-7121 (work)
> 858-546-7003 (FAX)
>
> Marine Mammal Genetics Group: swfsc.noaa.gov/mmtd-mmgenetics
> ETP Cetacean Assessment Program: swfsc.noaa.gov/mmtd-etp
>
> "
>
>
> *The universe doesn't care what you believe. The wonderful thing about
> science is that it   doesn't ask for your faith, it just asks   for your
> eyes.*"  - Randall Munroe
>
> "*Lighthouses are more helpful than churches.*"
>    - Benjamin Franklin
>
>    "*...but I'll take a GPS over either one.*"
>        - John C. "Craig" George
>
>         [[alternative HTML version deleted]]
>
> _______________________________________________
> R-SIG-Mac mailing list
> R-SIG-Mac at r-project.org <javascript:;>
> https://stat.ethz.ch/mailman/listinfo/r-sig-mac
>


-- 

~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

Emma Sherratt, PhD.

Lecturer in Zoology,
Zoology Division, School of Environmental and Rural Science,
Room L118 Bldg C02,
University of New England,
Armidale, NSW, Australia, 2351
Tel: +61 2 6773 5038
email: emma.sherratt at une.edu.au

Caecilians are legless amphibians...

*                      __
    (\   .-.   .-.   /_")
     \\_//^\\_//^\\_//
      `"`   `"`   `"`*

learn more about them here: www.emmasherratt.com/caecilians

	[[alternative HTML version deleted]]


From tomnyberg at gmail.com  Sat Oct 25 00:37:56 2014
From: tomnyberg at gmail.com (Thomas Nyberg)
Date: Fri, 24 Oct 2014 18:37:56 -0400
Subject: [R] readChar maxing out at screen width when using gnu screen?
Message-ID: <544AD4C4.1070907@gmail.com>

I am running:

R version 3.1.1 (2014-07-10) -- "Sock it to Me"
Platform: x86_64-unknown-linux-gnu (64-bit)

It is an Amazon 64 Linux instance with the following version: 
3.3.4-5.fc17.x86_64

I compiled R myself as well as the newest version of gnu screen.


I create a file with a couple hundred bytes by doing the following 
(using bash):

 > for i in {1..100}; do echo $i >> testfile; done

Next I load R and run the following:

 > readChar('testfile', 200)
[1] 
"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n2"

That output is exactly the width of the screen (as in the window in gnu 
screen). If I double the screen width (which I can do by removing my 
split screen mode), it will return the following string:

[1] 
"1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n"


Now my normal belief here would be that screen is somehow causing the 
bug, but honestly that makes no sense at all. What global changes could 
screen possibly make which would cause readChar to ignore its parameter 
telling it how many numbers to read in? I mean writing this in C would 
be a few lines and touch nothing that screen could affect.

Can somebody reproduce this? If not, another solution to my issue would 
be if somebody could tell me another way to read in an entire file as a 
string. The following is what I'm using which is causing the problem:

readfile <- function(filepath) {
     text <- readChar(filepath, file.info(filepath)$size)
     text
}

Thanks for any help. Cheers.

Thomas


From jim at bitwrit.com.au  Sat Oct 25 03:27:12 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Sat, 25 Oct 2014 12:27:12 +1100
Subject: [R] dotplot with library lattice
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF2D9@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
	<707072790.FfmNddDgBm@localhost.localdomain>
	<7E39CF5278A2C948968C39502CF451020174CEADF2D9@mail.ell.fnt.de>
Message-ID: <1709300.gu1B0lVq0c@localhost.localdomain>

On Fri, 24 Oct 2014 12:49:39 PM Matthias Weber wrote:
>
> I want always to see the "Process" of the green button in 
dependence
> of the blue button at 100%.

Okay.

mwdat<-read.table(text=
"KOST                  Budget        IST
1060                 -2.18          0
1080                  91037.71   91647.15
1100                  955573.87  907938.98
1120                  23326.8          0
1150                 2521.57          0
1180                 51302.03   48760.45
1200                  2027.04    -1667.5
1210                 2385.03    2386.06
1220                       0          0
1250                  528.87          0
1255                 766.54          0
1260                 12154.97    4861.41
Gesamtbudget 1141622.25 1054236.55",
 header=TRUE)
par(las=1,mar=c(5,7,4,6))
plot(rep(100,13),1:13,main="IST against Budget",
 xlab="IST/Budget (prozent)",ylab="KOST",
 xlim=c(0,100),type="n",yaxt="n")
abline(h=1:13,lty=2,col="lightgray")
points(rep(100,13),1:13,pch=19,col="blue",cex=3)
mwdat$ISTpct<-100*mwdat$IST/mwdat$Budget
# fix divide by zero
mwdat$ISTpct[9]<-0
points(mwdat$ISTpct,1:13,pch=19,col="green",cex=3)
legend(105,10,c("Budget","IST"),pch=19,
 col=c("blue","green"),bty="n",xpd=TRUE)
axis(2,at=1:13,labels=mwdat$KOST)
par(las=0,mar=c(5,4,4,2))

Jim


From hafizuddinarshad21 at gmail.com  Sat Oct 25 04:14:44 2014
From: hafizuddinarshad21 at gmail.com (Hafizuddin Arshad)
Date: Fri, 24 Oct 2014 19:14:44 -0700
Subject: [R] Finding Sum
Message-ID: <CAAPm8OqVU+1sdVo3J5Km4ia3usLD1Ec9Dox4OFxP4_jWEQfaMw@mail.gmail.com>

Hi,

I really need help on this. I have this data set:

structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
1971L, 1971L, 1971L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
1973L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L,
1974L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1976L,
1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1977L,
1977L, 1977L, 1977L, 1977L, 1977L, 1978L, 1978L, 1978L, 1978L,
1978L, 1978L, 1978L, 1979L, 1979L, 1979L, 1979L, 1979L, 1980L,
1980L, 1980L, 1980L, 1980L, 1980L, 1980L, 1981L, 1981L, 1981L,
1981L, 1982L, 1982L, 1982L, 1982L, 1982L, 1982L, 1983L, 1983L,
1983L, 1983L, 1983L, 1983L, 1983L, 1983L, 1983L, 1984L, 1984L,
1984L, 1985L, 1985L, 1985L, 1985L, 1985L, 1985L, 1987L, 1987L,
1987L, 1987L, 1987L, 1987L, 1988L, 1988L, 1988L, 1988L, 1988L,
1988L, 1988L, 1989L, 1989L, 1989L, 1989L, 1989L, 1989L, 1989L,
1990L, 1990L, 1991L, 1991L, 1991L, 1991L, 1991L, 1991L, 1991L,
1991L, 1991L, 1991L, 1991L, 1992L, 1992L, 1993L, 1993L, 1993L,
1994L, 1994L, 1994L, 1994L, 1994L, 1994L, 1994L, 1994L, 1994L,
1994L, 1994L, 1994L, 1994L, 1995L, 1995L, 1995L, 1995L), Month = c(3L,
6L, 10L, 10L, 11L, 11L, 11L, 11L, 12L, 2L, 9L, 12L, 12L, 12L,
12L, 3L, 9L, 10L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 8L, 9L,
11L, 11L, 11L, 11L, 11L, 12L, 12L, 1L, 2L, 4L, 10L, 11L, 12L,
12L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 9L, 10L, 11L,
12L, 12L, 12L, 6L, 6L, 9L, 11L, 11L, 12L, 12L, 10L, 11L, 11L,
11L, 11L, 7L, 9L, 11L, 12L, 12L, 12L, 12L, 7L, 11L, 12L, 12L,
7L, 10L, 12L, 12L, 12L, 12L, 5L, 11L, 12L, 12L, 12L, 12L, 12L,
12L, 12L, 11L, 12L, 12L, 3L, 3L, 11L, 12L, 12L, 12L, 6L, 12L,
12L, 12L, 12L, 12L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 9L, 9L,
10L, 10L, 11L, 12L, 12L, 4L, 9L, 1L, 6L, 8L, 10L, 11L, 11L, 11L,
11L, 12L, 12L, 12L, 6L, 12L, 6L, 10L, 10L, 5L, 10L, 10L, 10L,
11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 2L, 11L, 11L, 12L
), Rain = c(196, 88.8, 96, 70.6, 104.9, 80, 102.8, 161.5, 123.4,
70.8, 99, 77.7, 130.8, 134.1, 86.3, 213.3, 169.9, 89.4, 78.7,
81.5, 100.3, 107.1, 93.2, 83.8, 253.2, 75.4, 134.5, 84.5, 82.5,
82.5, 119.5, 119.5, 134.5, 83.5, 372.5, 79.5, 112, 80.5, 129.5,
120.5, 126, 73, 93.5, 86.5, 140.5, 76, 180.5, 75, 130.5, 130.5,
104, 110.5, 210.5, 70.5, 120.5, 120, 81, 84, 74.5, 82, 73.5,
177.5, 77.5, 88, 92.5, 93.5, 103, 93.5, 82, 85, 102.5, 76.5,
180, 144.5, 117, 73, 253.5, 99, 196, 105, 88.8, 71, 82.5, 191,
184.8, 72.5, 104.5, 107, 187, 141.5, 149.5, 115.5, 252, 199.5,
106.5, 192, 217.5, 112, 127, 87.5, 73, 75, 102, 102, 160, 172,
129, 150, 77, 120, 111, 190, 287.5, 120, 288, 183, 74, 77.5,
122, 112, 100, 140, 91, 158, 105, 100, 83, 75, 260, 80, 135,
218, 87, 85, 240, 115, 80, 76, 100.5, 82, 184, 72.5, 79, 152,
120, 128, 120, 154, 135, 141, 156, 132, 260, 73.5, 76.5, 129,
200, 70.5)), .Names = c("Year", "Month", "Rain"), class = "data.frame",
row.names = c(NA,
-158L))


I want to find the sum of the Rain according to their Month regardless of
their Years. The problem with my data is the Month is not fixed to Jan-
Dec. For example I want to find the sum of Rain for January( if have) from
1971 to 1995 regardless of their years and so on. I have tried this:

## monthly_summary.2 code use monthly data with mean, var and sd
monthly_summary.2 <- function(dt)
{ mt1 <- matrix(dt[,3],nrow=12,ncol=82,byrow=F)
  mt <- t(mt1)
  colnames(mt) <- c("Jan","Feb","Mar","Apr","May","June","July",
                    "Aug","Sept","Oct","Nov","Dec")
  mn <- colMeans(mt)
  vr <- diag(var(mt[,c(1:12)]))
  sd <- sqrt(vr)
  #rbind(mt,mn = mn,vr = vr,sd = sd)
  rbind(mn = mn,vr = vr,sd = sd)
}
## call function for monthly summary of data, mean, variance and std
ddt1.1 <- monthly_summary.2(dt1); round(ddt1.2,2) # kb

but R gives me this:

In matrix(dt[, 3], nrow = 12, ncol = 82, byrow = F) :
  data length [290] is not a sub-multiple or multiple of the number of rows
[12]

Can you help me on this? The output should be something like this:

structure(c(135.073170731707, 3766.29433303222, 61.3701420320356,
115.35, 1962.35981481481, 44.2985306168818, 131.704878048781,
3508.69256850346, 59.2342178854711, 118.080487804878, 2323.96677506775,
48.2075385709305, 138.373170731707, 4960.1308762421, 70.4281965993883,
115.891463414634, 2313.38375338753, 48.0976481066126, 132.14512195122,
4258.86522282445, 65.2599817868841, 112.348780487805, 1813.78573923517,
42.5885634793564, 130.989024390244, 4305.92740891298, 65.6195657476715,
109.289024390244, 1722.0859274315, 41.4980231749838, 131.365853658537,
3999.19635049684, 63.2391994770399, 109.503658536585, 1622.71838151159,
40.2829788063345), .Dim = c(3L, 12L), .Dimnames = list(c("mn",
"vr", "sd"), c("Jan", "Feb", "Mar", "Apr", "May", "June", "July",
"Aug", "Sept", "Oct", "Nov", "Dec")))


Thank you.


Arshad

	[[alternative HTML version deleted]]


From rmh at temple.edu  Sat Oct 25 06:06:55 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sat, 25 Oct 2014 00:06:55 -0400
Subject: [R] dotplot with library lattice
In-Reply-To: <1709300.gu1B0lVq0c@localhost.localdomain>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
	<707072790.FfmNddDgBm@localhost.localdomain>
	<7E39CF5278A2C948968C39502CF451020174CEADF2D9@mail.ell.fnt.de>
	<1709300.gu1B0lVq0c@localhost.localdomain>
Message-ID: <CAGx1TMBzFE0YCWNO9wYxtxSBS-0UpYAz3ecGQ4oj+y4DV_2CNw@mail.gmail.com>

## My interpretation is that KOST is a categorical budget code id, and
## not an amount of currency.  This is based on both you and Jim using
## even spacing for the rows of the dotplot.  Your first line of the
## email said barplot, so my example uses likert in the HH package
## which is built on barchart in the lattice package.

## Your example shows negative IST, IST larger than budget, and
## negative budgets.  My solution handles the first two cases.
## It forces the percents for the negative budget to zero.

## install.packages("HH")  ## if necessary

mwdat <- read.table(text=
"KOST                  Budget        IST
1060                 -2.18          0
1080                  91037.71   91647.15
1100                  955573.87  907938.98
1120                  23326.8          0
1150                 2521.57          0
1180                 51302.03   48760.45
1200                  2027.04    -1667.5
1210                 2385.03    2386.06
1220                       0          0
1250                  528.87          0
1255                 766.54          0
1260                 12154.97    4861.41",
 header=TRUE)

mwdat3 <- with(mwdat,
               data.frame(KOST=KOST,
                          ISTneg=pmax(0, -IST),
                          IST=pmax(IST, 0),
                          BudgetNotAttained=pmax(0, Budget-IST),
                          OverBudget=pmax(0, IST-Budget),
                          Budget=Budget))
mwdat3percent <- mwdat3
BudgetNonzero <- mwdat3$Budget != 0
mwdat3percent[BudgetNonzero, 2:5] <- 100 * (mwdat3percent[BudgetNonzero, 2:5] /
                                              mwdat3percent[BudgetNonzero, 6])
BudgetNegative <- mwdat3$Budget < 0
mwdat3percent[BudgetNegative, 2:5] <- 0
ISTneg <- mwdat3percent$ISTneg > 0
mwdat3percent$BudgetNotAttained[ISTneg] <- 100

ISTcolors <- likertColor(nc=6, ReferenceZero=1.5)[c(1,3,2,6)]

likert(KOST ~ ISTneg + IST + BudgetNotAttained + OverBudget,
       data=mwdat3percent, ReferenceZero=1.5,
       col=ISTcolors,
       xlab="Percent of Budget", xlimEqualLeftRight=TRUE,
       rightAxisLabels=mwdat3$Budget, ylab.right="Budget",
       par.settings=list(layout.widths=list(axis.right=1.5))) +
         layer(panel.abline(v=100, col="gray65"), under=TRUE)

On Fri, Oct 24, 2014 at 9:27 PM, Jim Lemon <jim at bitwrit.com.au> wrote:
> On Fri, 24 Oct 2014 12:49:39 PM Matthias Weber wrote:
>>
>> I want always to see the "Process" of the green button in
> dependence
>> of the blue button at 100%.
>
> Okay.
>
> mwdat<-read.table(text=
> "KOST                  Budget        IST
> 1060                 -2.18          0
> 1080                  91037.71   91647.15
> 1100                  955573.87  907938.98
> 1120                  23326.8          0
> 1150                 2521.57          0
> 1180                 51302.03   48760.45
> 1200                  2027.04    -1667.5
> 1210                 2385.03    2386.06
> 1220                       0          0
> 1250                  528.87          0
> 1255                 766.54          0
> 1260                 12154.97    4861.41
> Gesamtbudget 1141622.25 1054236.55",
>  header=TRUE)
> par(las=1,mar=c(5,7,4,6))
> plot(rep(100,13),1:13,main="IST against Budget",
>  xlab="IST/Budget (prozent)",ylab="KOST",
>  xlim=c(0,100),type="n",yaxt="n")
> abline(h=1:13,lty=2,col="lightgray")
> points(rep(100,13),1:13,pch=19,col="blue",cex=3)
> mwdat$ISTpct<-100*mwdat$IST/mwdat$Budget
> # fix divide by zero
> mwdat$ISTpct[9]<-0
> points(mwdat$ISTpct,1:13,pch=19,col="green",cex=3)
> legend(105,10,c("Budget","IST"),pch=19,
>  col=c("blue","green"),bty="n",xpd=TRUE)
> axis(2,at=1:13,labels=mwdat$KOST)
> par(las=0,mar=c(5,4,4,2))
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Oct 25 06:57:16 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 24 Oct 2014 21:57:16 -0700
Subject: [R] Finding Sum
In-Reply-To: <CAAPm8OqVU+1sdVo3J5Km4ia3usLD1Ec9Dox4OFxP4_jWEQfaMw@mail.gmail.com>
References: <CAAPm8OqVU+1sdVo3J5Km4ia3usLD1Ec9Dox4OFxP4_jWEQfaMw@mail.gmail.com>
Message-ID: <18B9AAE0-5B4B-4825-956F-8BA5BCE15890@dcn.davis.CA.us>

Please post in plain text to avoid corruption of your message.

Your data has duplicates in it... I don't get the numbers you provided, even if I remove the duplicates. See

table(dta$Year,dta$Month)

There are many ways to do this kind of calculation. One is to use the base R function aggregate(), as in

aggregate(dta$Rain,list(Month=dta$Month),FUN=mean)

Other solutions involve packages plyr, data.table, sqldf, or dplyr, each of which  has documentation you can read and tutorials you can search for. The common principle they all share is the idea of a "grouping column" that defines whichv vector elements belong together... in this case, the Month column.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 24, 2014 7:14:44 PM PDT, Hafizuddin Arshad <hafizuddinarshad21 at gmail.com> wrote:
>Hi,
>
>I really need help on this. I have this data set:
>
>structure(list(Year = c(1971L, 1971L, 1971L, 1971L, 1971L, 1971L,
>1971L, 1971L, 1971L, 1972L, 1972L, 1972L, 1972L, 1972L, 1972L,
>1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L, 1973L,
>1973L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L, 1974L,
>1974L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1975L, 1976L,
>1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1976L, 1977L,
>1977L, 1977L, 1977L, 1977L, 1977L, 1978L, 1978L, 1978L, 1978L,
>1978L, 1978L, 1978L, 1979L, 1979L, 1979L, 1979L, 1979L, 1980L,
>1980L, 1980L, 1980L, 1980L, 1980L, 1980L, 1981L, 1981L, 1981L,
>1981L, 1982L, 1982L, 1982L, 1982L, 1982L, 1982L, 1983L, 1983L,
>1983L, 1983L, 1983L, 1983L, 1983L, 1983L, 1983L, 1984L, 1984L,
>1984L, 1985L, 1985L, 1985L, 1985L, 1985L, 1985L, 1987L, 1987L,
>1987L, 1987L, 1987L, 1987L, 1988L, 1988L, 1988L, 1988L, 1988L,
>1988L, 1988L, 1989L, 1989L, 1989L, 1989L, 1989L, 1989L, 1989L,
>1990L, 1990L, 1991L, 1991L, 1991L, 1991L, 1991L, 1991L, 1991L,
>1991L, 1991L, 1991L, 1991L, 1992L, 1992L, 1993L, 1993L, 1993L,
>1994L, 1994L, 1994L, 1994L, 1994L, 1994L, 1994L, 1994L, 1994L,
>1994L, 1994L, 1994L, 1994L, 1995L, 1995L, 1995L, 1995L), Month = c(3L,
>6L, 10L, 10L, 11L, 11L, 11L, 11L, 12L, 2L, 9L, 12L, 12L, 12L,
>12L, 3L, 9L, 10L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 8L, 9L,
>11L, 11L, 11L, 11L, 11L, 12L, 12L, 1L, 2L, 4L, 10L, 11L, 12L,
>12L, 10L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 9L, 10L, 11L,
>12L, 12L, 12L, 6L, 6L, 9L, 11L, 11L, 12L, 12L, 10L, 11L, 11L,
>11L, 11L, 7L, 9L, 11L, 12L, 12L, 12L, 12L, 7L, 11L, 12L, 12L,
>7L, 10L, 12L, 12L, 12L, 12L, 5L, 11L, 12L, 12L, 12L, 12L, 12L,
>12L, 12L, 11L, 12L, 12L, 3L, 3L, 11L, 12L, 12L, 12L, 6L, 12L,
>12L, 12L, 12L, 12L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 9L, 9L,
>10L, 10L, 11L, 12L, 12L, 4L, 9L, 1L, 6L, 8L, 10L, 11L, 11L, 11L,
>11L, 12L, 12L, 12L, 6L, 12L, 6L, 10L, 10L, 5L, 10L, 10L, 10L,
>11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 2L, 11L, 11L, 12L
>), Rain = c(196, 88.8, 96, 70.6, 104.9, 80, 102.8, 161.5, 123.4,
>70.8, 99, 77.7, 130.8, 134.1, 86.3, 213.3, 169.9, 89.4, 78.7,
>81.5, 100.3, 107.1, 93.2, 83.8, 253.2, 75.4, 134.5, 84.5, 82.5,
>82.5, 119.5, 119.5, 134.5, 83.5, 372.5, 79.5, 112, 80.5, 129.5,
>120.5, 126, 73, 93.5, 86.5, 140.5, 76, 180.5, 75, 130.5, 130.5,
>104, 110.5, 210.5, 70.5, 120.5, 120, 81, 84, 74.5, 82, 73.5,
>177.5, 77.5, 88, 92.5, 93.5, 103, 93.5, 82, 85, 102.5, 76.5,
>180, 144.5, 117, 73, 253.5, 99, 196, 105, 88.8, 71, 82.5, 191,
>184.8, 72.5, 104.5, 107, 187, 141.5, 149.5, 115.5, 252, 199.5,
>106.5, 192, 217.5, 112, 127, 87.5, 73, 75, 102, 102, 160, 172,
>129, 150, 77, 120, 111, 190, 287.5, 120, 288, 183, 74, 77.5,
>122, 112, 100, 140, 91, 158, 105, 100, 83, 75, 260, 80, 135,
>218, 87, 85, 240, 115, 80, 76, 100.5, 82, 184, 72.5, 79, 152,
>120, 128, 120, 154, 135, 141, 156, 132, 260, 73.5, 76.5, 129,
>200, 70.5)), .Names = c("Year", "Month", "Rain"), class = "data.frame",
>row.names = c(NA,
>-158L))
>
>
>I want to find the sum of the Rain according to their Month regardless
>of
>their Years. The problem with my data is the Month is not fixed to Jan-
>Dec. For example I want to find the sum of Rain for January( if have)
>from
>1971 to 1995 regardless of their years and so on. I have tried this:
>
>## monthly_summary.2 code use monthly data with mean, var and sd
>monthly_summary.2 <- function(dt)
>{ mt1 <- matrix(dt[,3],nrow=12,ncol=82,byrow=F)
>  mt <- t(mt1)
>  colnames(mt) <- c("Jan","Feb","Mar","Apr","May","June","July",
>                    "Aug","Sept","Oct","Nov","Dec")
>  mn <- colMeans(mt)
>  vr <- diag(var(mt[,c(1:12)]))
>  sd <- sqrt(vr)
>  #rbind(mt,mn = mn,vr = vr,sd = sd)
>  rbind(mn = mn,vr = vr,sd = sd)
>}
>## call function for monthly summary of data, mean, variance and std
>ddt1.1 <- monthly_summary.2(dt1); round(ddt1.2,2) # kb
>
>but R gives me this:
>
>In matrix(dt[, 3], nrow = 12, ncol = 82, byrow = F) :
>data length [290] is not a sub-multiple or multiple of the number of
>rows
>[12]
>
>Can you help me on this? The output should be something like this:
>
>structure(c(135.073170731707, 3766.29433303222, 61.3701420320356,
>115.35, 1962.35981481481, 44.2985306168818, 131.704878048781,
>3508.69256850346, 59.2342178854711, 118.080487804878, 2323.96677506775,
>48.2075385709305, 138.373170731707, 4960.1308762421, 70.4281965993883,
>115.891463414634, 2313.38375338753, 48.0976481066126, 132.14512195122,
>4258.86522282445, 65.2599817868841, 112.348780487805, 1813.78573923517,
>42.5885634793564, 130.989024390244, 4305.92740891298, 65.6195657476715,
>109.289024390244, 1722.0859274315, 41.4980231749838, 131.365853658537,
>3999.19635049684, 63.2391994770399, 109.503658536585, 1622.71838151159,
>40.2829788063345), .Dim = c(3L, 12L), .Dimnames = list(c("mn",
>"vr", "sd"), c("Jan", "Feb", "Mar", "Apr", "May", "June", "July",
>"Aug", "Sept", "Oct", "Nov", "Dec")))
>
>
>Thank you.
>
>
>Arshad
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Oct 25 07:15:48 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 24 Oct 2014 22:15:48 -0700
Subject: [R] how to build a heatmap like this
In-Reply-To: <BAY173-W25B01028EBBE7E7A9DFFFAFF920@phx.gbl>
References: <BAY173-W25B01028EBBE7E7A9DFFFAFF920@phx.gbl>
Message-ID: <4EF794BC-E82E-4EDD-A5C4-36313743EF84@dcn.davis.CA.us>

Your question is hard to follow (too much genetics jargon?), and because you posted using HTML instead of plain text your table (?) is corrupted also.

You should read [1], [2], and might consider looking at Bioconductor [3].

[1] Posting Guide, mentioned at the bottom of this email
[2] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
[3] http://www.bioconductor.org

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 22, 2014 6:44:58 PM PDT, escaping <young_2304 at hotmail.com> wrote:
>Hi, everyone,
>
>I am a new R user, and was required to build several heatmaps as shown
>in attached file. To reach it, I need to normalize the RPKM data  of
>exon-level expression to generate Z-score using R. The data looks like
>mpleId
>
>			
>				geneName
>
>			
>				start
>
>			
>				end
>
>			
>				rpkm
>
>		
>
>
>				PC10-6
>
>			
>				KIF1B
>
>			
>				10270764
>
>			
>				10270936
>
>			
>				4.00059
>
>		
>
>
>				PC10-6
>
>			
>				KIF1B
>
>			
>				10292308
>
>			
>				10292492
>
>			
>				35.3023
>
>		
>
>
>				PC10-6
>
>			
>				KIF1B
>
>			
>				10316305
>
>			
>				10316381
>
>			
>				85.9611
>
>		
>
>
>				PC10-6
>
>			
>				KIF1B
>
>			
>				10318551
>
>			
>				10318730
>
>			
>				64.5961
>Exons and introns are required to shown on the heatmap.
>
>Does anyone know how to do it? 
>
>Thanks a lot!
>
>Yizi
>
>
>
>  		 	   		  
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From axel.urbiz at gmail.com  Sat Oct 25 10:51:58 2014
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Sat, 25 Oct 2014 04:51:58 -0400
Subject: [R] Rubik cube-like plot in R
Message-ID: <CAAyVsXJCGsdC2nRueNuxKwT98PrX0DJHe3cheUVBOug2mcXJSQ@mail.gmail.com>

Hi there,

I need to create a Rubik cube plot in R, except that I don't need the face
colours (all faces with the same colour is fine).

I'd appreciate your guidance in terms of what graphic tool would be best
for this purpose.

Best,
Axel.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Sat Oct 25 11:40:17 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 25 Oct 2014 11:40:17 +0200
Subject: [R] RCurl memory leak in getURL method
In-Reply-To: <CABqr0AwgydZkwrnE2JiROsYBiPNT7-5vLPgAee6wnW+Y2FEUAw@mail.gmail.com>
References: <CABqr0AwgydZkwrnE2JiROsYBiPNT7-5vLPgAee6wnW+Y2FEUAw@mail.gmail.com>
Message-ID: <21579.28673.702365.907548@stat.math.ethz.ch>

>>>>> dotnet sql <dotnetsqltraining at gmail.com>
>>>>>     on Sat, 25 Oct 2014 08:50:20 +1100 writes:

    > Hi It looks like we have hit a bug in RCurl. The method
    > getURL seems to be leaking memory. A simple test case to
    > reproduce the bug is given here:

    >> library(RCurl)
    >> handle<-getCurlHandle()
    >> range<-1:100
    >> for (r in range) {x<-getURL(url="news.google.com.au",curl=handle)}

    > If I run this code, the memory allocated to the R session is never
    > recovered.

    > We are using RCurl for some long running experiments and we are running out
    > of memory on the test system.

    > The specs of our test system are as follows:
    > OS: Ubuntu 14.04 (64 bit)
    > Memory: 24 GB
    > RCurl version: 1.95-4.3

    > Any ideas about how to get around this issue?

What did the maintainer of the RCurl package say when you asked
him?  
Inside R,  use     maintainer("RCurl")
and then e-mail him, a very smart and nice guy.




    > Thanks

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Oct 25 11:56:21 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 25 Oct 2014 05:56:21 -0400
Subject: [R] Extra documentation not appearing
In-Reply-To: <CAPwpSvh9U_xmJ5L7Yo5sC6UGJLRsh6cOyX6HxhC=pGf8v=5LFg@mail.gmail.com>
References: <CAPwpSvh9U_xmJ5L7Yo5sC6UGJLRsh6cOyX6HxhC=pGf8v=5LFg@mail.gmail.com>
Message-ID: <544B73C5.3070800@gmail.com>

On 24/10/2014, 11:31 AM, Dan Vatnik wrote:
> Hi,
> 
> I have loaded my first package to CRAN and I have noticed a documentation
> issue.
> When I install the package from CRAN, it installs a Windows binary since I
> am using a Windows machine.
> I have a PDF file in my doc folder. Originally, it was in the inst/doc/
> folder but when I load the binary, there
> is no more inst folder so the doc folder is directly in the package folder.
> The issue arises in my package's index page. It has a link to the
> DESCRIPTION file and it has a link to the
> Extra documentation section on top. The link to the Extra documentation
> does not lead anywhere so my PDF
> is inaccessible.
> My package is named "traj".
> Do you know what might be the issue?
> 

Looks like a bug in R's help server.  If you look at the Extra
documentation link, you'll see something like this:

http://127.0.0.1:16447/library/traj/doc/index.html

That link gives a blank page.  If you manually take away the index.html
part and give this:

http://127.0.0.1:16447/library/traj/doc

it works fine.  I'll take a look into this.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sat Oct 25 13:32:17 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 25 Oct 2014 07:32:17 -0400
Subject: [R] Extra documentation not appearing
In-Reply-To: <CAPwpSvh9U_xmJ5L7Yo5sC6UGJLRsh6cOyX6HxhC=pGf8v=5LFg@mail.gmail.com>
References: <CAPwpSvh9U_xmJ5L7Yo5sC6UGJLRsh6cOyX6HxhC=pGf8v=5LFg@mail.gmail.com>
Message-ID: <544B8A41.6030507@gmail.com>

On 24/10/2014, 11:31 AM, Dan Vatnik wrote:
> Hi,
> 
> I have loaded my first package to CRAN and I have noticed a documentation
> issue.
> When I install the package from CRAN, it installs a Windows binary since I
> am using a Windows machine.
> I have a PDF file in my doc folder. Originally, it was in the inst/doc/
> folder but when I load the binary, there
> is no more inst folder so the doc folder is directly in the package folder.
> The issue arises in my package's index page. It has a link to the
> DESCRIPTION file and it has a link to the
> Extra documentation section on top. The link to the Extra documentation
> does not lead anywhere so my PDF
> is inaccessible.
> My package is named "traj".
> Do you know what might be the issue?

This is a bug in the R help system.  Since you don't have any vignettes
in that package, it doesn't produce the index page that links to it.

There are two workarounds:  make your extra documentation file into a
vignette (one way is to rename the source from *.tex (I assume) to
*.Rnw, and add a %\VignetteIndexEntry line), and avoid the bug.
Alternatively, include your own inst/doc/index.html file to link to it.

I will fix the bug so that a directory listing is shown that includes
your file, but it won't make it into the upcoming 3.1.2 release.  It
will make it into 3.1.3, but that likely won't appear before the spring.
But even with this change, I still recommend changing your document to a
vignette.  They get a display with a title, unlike unknown files in
inst/doc.

Duncan Murdoch


From jfox at mcmaster.ca  Sat Oct 25 16:43:49 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 25 Oct 2014 10:43:49 -0400
Subject: [R] R Markdown and scan()
Message-ID: <web-533057525@cgpsrv2.cis.mcmaster.ca>

Dear JJ and list members,

I wonder whether it's possible to get scan() to read in-line data in an R Markdown document. The following code, for example, works (of course) when entered in the R console but fails in an R block in an R Markdown document (using an up-to-date version of RStudio):

```{r}
x <- scan()
1 2 3
4 5 6

x
````

I'm aware of a couple of work-arounds, such as putting the data in a file or a character string (as below), but am interested in whether it's possible to get this to work directly.

```{r}
text <- "
1 2 3
4 5 6
"
(x <- scan(file=textConnection(text)))
````

Any help would be appreciated.

John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From pdalgd at gmail.com  Sat Oct 25 17:11:14 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 25 Oct 2014 17:11:14 +0200
Subject: [R] R Markdown and scan()
In-Reply-To: <web-533057525@cgpsrv2.cis.mcmaster.ca>
References: <web-533057525@cgpsrv2.cis.mcmaster.ca>
Message-ID: <AE7BB933-FE34-479C-8092-74D2E67779A3@gmail.com>


> On 25 Oct 2014, at 16:43 , John Fox <jfox at mcmaster.ca> wrote:
> 
> Dear JJ and list members,
> 
> I wonder whether it's possible to get scan() to read in-line data in an R Markdown document. The following code, for example, works (of course) when entered in the R console but fails in an R block in an R Markdown document (using an up-to-date version of RStudio):
> 
> ```{r}
> x <- scan()
> 1 2 3
> 4 5 6
> 
> x
> ````
> 
> I'm aware of a couple of work-arounds, such as putting the data in a file or a character string (as below), but am interested in whether it's possible to get this to work directly.
> 
> ```{r}
> text <- "
> 1 2 3
> 4 5 6
> "
> (x <- scan(file=textConnection(text)))
> ````
> 
> Any help would be appreciated.

This generally isn't easy. You can't source() a file like that either, it only works on std.input, and even there it is tricky it you have tabs in the (pasted) data. Notice that
 
scan(text="
1 2 3
4 5 6
")

was designed for the purpose of reading inline data.

 
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Sat Oct 25 17:58:28 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 25 Oct 2014 11:58:28 -0400
Subject: [R] R Markdown and scan()
In-Reply-To: <AE7BB933-FE34-479C-8092-74D2E67779A3@gmail.com>
References: <web-533057525@cgpsrv2.cis.mcmaster.ca>
	<AE7BB933-FE34-479C-8092-74D2E67779A3@gmail.com>
Message-ID: <web-533061812@cgpsrv2.cis.mcmaster.ca>

Dear Peter,

Thanks for the suggestion -- it's a bit better for the example I provided than my approach of using textConnection() of putting the lines in a file. 

I'd still be interested in whether I've missed something like a text-chunk option that would allow the R Markdown document to behave like a script executed at the console. For example, your approach doesn't work for the application where I encountered the problem, which is in a function that calls scan() and that passes the file argument to it, but doesn't use the text argument.

Best,
 John

On Sat, 25 Oct 2014 17:11:14 +0200
 peter dalgaard <pdalgd at gmail.com> wrote:
> 
> > On 25 Oct 2014, at 16:43 , John Fox <jfox at mcmaster.ca> wrote:
> > 
> > Dear JJ and list members,
> > 
> > I wonder whether it's possible to get scan() to read in-line data in an R Markdown document. The following code, for example, works (of course) when entered in the R console but fails in an R block in an R Markdown document (using an up-to-date version of RStudio):
> > 
> > ```{r}
> > x <- scan()
> > 1 2 3
> > 4 5 6
> > 
> > x
> > ````
> > 
> > I'm aware of a couple of work-arounds, such as putting the data in a file or a character string (as below), but am interested in whether it's possible to get this to work directly.
> > 
> > ```{r}
> > text <- "
> > 1 2 3
> > 4 5 6
> > "
> > (x <- scan(file=textConnection(text)))
> > ````
> > 
> > Any help would be appreciated.
> 
> This generally isn't easy. You can't source() a file like that either, it only works on std.input, and even there it is tricky it you have tabs in the (pasted) data. Notice that
>  
> scan(text="
> 1 2 3
> 4 5 6
> ")
> 
> was designed for the purpose of reading inline data.
> 
>  
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
>


From josh.m.ulrich at gmail.com  Sat Oct 25 19:03:12 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 25 Oct 2014 12:03:12 -0500
Subject: [R] Problem getting Option Quotes
In-Reply-To: <544913E9.3070205@comcast.net>
References: <544913E9.3070205@comcast.net>
Message-ID: <CAPPM_gR7jss9tsFx4fcuyj3YADDqfvmYz=NXCqSbXAYLXHkhpA@mail.gmail.com>

On Thu, Oct 23, 2014 at 9:42 AM, Robert Sherry <rsherry8 at comcast.net> wrote:
>
> I am using R and quantmod to get stock and option quotes. However, it has
> stopped working. I expect the following
> function call to produce a list of options:
>         getOptionChain( "XOM", Exp = "2015-01-20" )
> However, I get the following error messages:
>     Error in lapply(strsplit(opt, "<tr>"), function(.) gsub(",", "",
> gsub("N/A",  :
>       subscript out of bounds
>     In addition: Warning message:
>     In readLines(paste(paste("http://finance.yahoo.com/q/op?s=", Symbols,  :
>       incomplete final line found on
> 'http://finance.yahoo.com/q/op?s=XOM&m=2015-01-20+Options'
>
> Has something changed? Am I doing something wrong?
>
Yahoo changed the webpage the data are scraped from.  The function
will have to be re-written to scrape from the new page.

> Thanks
> Bob
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From xie at yihui.name  Sat Oct 25 20:53:21 2014
From: xie at yihui.name (Yihui Xie)
Date: Sat, 25 Oct 2014 13:53:21 -0500
Subject: [R] R Markdown and scan()
In-Reply-To: <web-533061812@cgpsrv2.cis.mcmaster.ca>
References: <web-533057525@cgpsrv2.cis.mcmaster.ca>
	<AE7BB933-FE34-479C-8092-74D2E67779A3@gmail.com>
	<web-533061812@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CANROs4drq2PNX+4tA=zpea5YyR56pieYfZogQRWZJnNK050mmg@mail.gmail.com>

RStudio uses a non-interactive R session to compile R Markdown
documents, which means the functions that involve human interaction
will not work. The only way to make these functions work is to use an
interactive R session, which basically means you should not click the
button in RStudio to compile the documents, but should type
rmarkdown::render() in the R console instead. You cannot put the
numbers under scan() and expect they will be read by scan() as if they
were typed by a human, even though they look similar.

If the function in your case only allows file input for scan(), I
guess the only way is to make a connection, such as textConnection()
as you mentioned.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Sat, Oct 25, 2014 at 10:58 AM, John Fox <jfox at mcmaster.ca> wrote:
> Dear Peter,
>
> Thanks for the suggestion -- it's a bit better for the example I provided than my approach of using textConnection() of putting the lines in a file.
>
> I'd still be interested in whether I've missed something like a text-chunk option that would allow the R Markdown document to behave like a script executed at the console. For example, your approach doesn't work for the application where I encountered the problem, which is in a function that calls scan() and that passes the file argument to it, but doesn't use the text argument.
>
> Best,
>  John
>
> On Sat, 25 Oct 2014 17:11:14 +0200
>  peter dalgaard <pdalgd at gmail.com> wrote:
>>
>> > On 25 Oct 2014, at 16:43 , John Fox <jfox at mcmaster.ca> wrote:
>> >
>> > Dear JJ and list members,
>> >
>> > I wonder whether it's possible to get scan() to read in-line data in an R Markdown document. The following code, for example, works (of course) when entered in the R console but fails in an R block in an R Markdown document (using an up-to-date version of RStudio):
>> >
>> > ```{r}
>> > x <- scan()
>> > 1 2 3
>> > 4 5 6
>> >
>> > x
>> > ````
>> >
>> > I'm aware of a couple of work-arounds, such as putting the data in a file or a character string (as below), but am interested in whether it's possible to get this to work directly.
>> >
>> > ```{r}
>> > text <- "
>> > 1 2 3
>> > 4 5 6
>> > "
>> > (x <- scan(file=textConnection(text)))
>> > ````
>> >
>> > Any help would be appreciated.
>>
>> This generally isn't easy. You can't source() a file like that either, it only works on std.input, and even there it is tricky it you have tabs in the (pasted) data. Notice that
>>
>> scan(text="
>> 1 2 3
>> 4 5 6
>> ")
>>
>> was designed for the purpose of reading inline data.
>>
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Sat Oct 25 22:50:05 2014
From: jfox at mcmaster.ca (John Fox)
Date: Sat, 25 Oct 2014 16:50:05 -0400
Subject: [R] R Markdown and scan()
In-Reply-To: <CANROs4drq2PNX+4tA=zpea5YyR56pieYfZogQRWZJnNK050mmg@mail.gmail.com>
References: <web-533057525@cgpsrv2.cis.mcmaster.ca>
	<AE7BB933-FE34-479C-8092-74D2E67779A3@gmail.com>
	<web-533061812@cgpsrv2.cis.mcmaster.ca>
	<CANROs4drq2PNX+4tA=zpea5YyR56pieYfZogQRWZJnNK050mmg@mail.gmail.com>
Message-ID: <web-533077219@cgpsrv2.cis.mcmaster.ca>

Dear Yihui,

OK -- thanks. That's what I figured, but I hoped that there were something I missed.

Best,
 John

On Sat, 25 Oct 2014 13:53:21 -0500
 Yihui Xie <xie at yihui.name> wrote:
> RStudio uses a non-interactive R session to compile R Markdown
> documents, which means the functions that involve human interaction
> will not work. The only way to make these functions work is to use an
> interactive R session, which basically means you should not click the
> button in RStudio to compile the documents, but should type
> rmarkdown::render() in the R console instead. You cannot put the
> numbers under scan() and expect they will be read by scan() as if they
> were typed by a human, even though they look similar.
> 
> If the function in your case only allows file input for scan(), I
> guess the only way is to make a connection, such as textConnection()
> as you mentioned.
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> 
> 
> On Sat, Oct 25, 2014 at 10:58 AM, John Fox <jfox at mcmaster.ca> wrote:
> > Dear Peter,
> >
> > Thanks for the suggestion -- it's a bit better for the example I provided than my approach of using textConnection() of putting the lines in a file.
> >
> > I'd still be interested in whether I've missed something like a text-chunk option that would allow the R Markdown document to behave like a script executed at the console. For example, your approach doesn't work for the application where I encountered the problem, which is in a function that calls scan() and that passes the file argument to it, but doesn't use the text argument.
> >
> > Best,
> >  John
> >
> > On Sat, 25 Oct 2014 17:11:14 +0200
> >  peter dalgaard <pdalgd at gmail.com> wrote:
> >>
> >> > On 25 Oct 2014, at 16:43 , John Fox <jfox at mcmaster.ca> wrote:
> >> >
> >> > Dear JJ and list members,
> >> >
> >> > I wonder whether it's possible to get scan() to read in-line data in an R Markdown document. The following code, for example, works (of course) when entered in the R console but fails in an R block in an R Markdown document (using an up-to-date version of RStudio):
> >> >
> >> > ```{r}
> >> > x <- scan()
> >> > 1 2 3
> >> > 4 5 6
> >> >
> >> > x
> >> > ````
> >> >
> >> > I'm aware of a couple of work-arounds, such as putting the data in a file or a character string (as below), but am interested in whether it's possible to get this to work directly.
> >> >
> >> > ```{r}
> >> > text <- "
> >> > 1 2 3
> >> > 4 5 6
> >> > "
> >> > (x <- scan(file=textConnection(text)))
> >> > ````
> >> >
> >> > Any help would be appreciated.
> >>
> >> This generally isn't easy. You can't source() a file like that either, it only works on std.input, and even there it is tricky it you have tabs in the (pasted) data. Notice that
> >>
> >> scan(text="
> >> 1 2 3
> >> 4 5 6
> >> ")
> >>
> >> was designed for the purpose of reading inline data.
> >>
> >>
> >> --
> >> Peter Dalgaard, Professor,
> >> Center for Statistics, Copenhagen Business School
> >> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> >> Phone: (+45)38153501
> >> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From kydaviddoyle at gmail.com  Sun Oct 26 04:40:15 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Sat, 25 Oct 2014 22:40:15 -0500
Subject: [R] kruskal test p value way too low.
Message-ID: <CACftpvqXxcHuX_m6H2ZVnNS-5muni51Q3qzTFWg8134HEO9hWA@mail.gmail.com>

Hello,

I'm trying to run kruskal test on some data but the p values seemed way too
low.  So I tried it on some similar data and still got p-value =
1.611e-09.  I'm sure it is a simple mistake but I can't figure it out.

Below is my data and code.  Could it be because there are some miss data /
NAs in the data set??  If so, could some one point me towards a solution??

Thank you for your time.
David

mydata <-read.csv("http://doylesdartden.com/R/test.csv", sep=",")
kruskal.test(mydata, AMMONIA~Well)

        Kruskal-Wallis rank sum test

data:  mydata
Kruskal-Wallis chi-squared = 36.3952, df = 1, p-value = 1.611e-09

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Sun Oct 26 06:37:32 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Sun, 26 Oct 2014 18:37:32 +1300
Subject: [R] kruskal test p value way too low.
In-Reply-To: <CACftpvqXxcHuX_m6H2ZVnNS-5muni51Q3qzTFWg8134HEO9hWA@mail.gmail.com>
References: <CACftpvqXxcHuX_m6H2ZVnNS-5muni51Q3qzTFWg8134HEO9hWA@mail.gmail.com>
Message-ID: <544C889C.6010809@auckland.ac.nz>

On 26/10/14 16:40, David Doyle wrote:
> Hello,
>
> I'm trying to run kruskal test on some data but the p values seemed way too
> low.  So I tried it on some similar data and still got p-value =
> 1.611e-09.  I'm sure it is a simple mistake but I can't figure it out.
>
> Below is my data and code.  Could it be because there are some miss data /
> NAs in the data set??  If so, could some one point me towards a solution??
>
> Thank you for your time.
> David
>
> mydata <-read.csv("http://doylesdartden.com/R/test.csv", sep=",")
> kruskal.test(mydata, AMMONIA~Well)
>
>          Kruskal-Wallis rank sum test
>
> data:  mydata
> Kruskal-Wallis chi-squared = 36.3952, df = 1, p-value = 1.611e-09

Thank you for providing a clear question and an easily reproducible example.

The problem is your syntax for the call to the kruskal.test() function.

It should be:

     kruskal.test(AMMONIA ~ Well, data=mydata)

This gives a p-value of 1 (which agrees with wilcox.test); t.test() 
gives a p-value of 0.7958) so harmony is restored to the universe.

IMHO there is a bit of a design flaw in kruskal.test(); it should have 
thrown an error, given your syntax.  The wilcox.test() function *does* 
throw an error.

cheers,

Rolf Turner

-- 
Rolf Turner
Technical Editor ANZJS


From mdsumner at gmail.com  Sun Oct 26 07:21:47 2014
From: mdsumner at gmail.com (Michael Sumner)
Date: Sun, 26 Oct 2014 17:21:47 +1100
Subject: [R] rgdal: Convert ESRI ArcGis geo database (gdb directory) to
 geojson, or shapefile map
In-Reply-To: <CAKXF9PRuXOoJfQVk-RQTzWOudVM55tgpLL5quBoD+FNJ92Gz_g@mail.gmail.com>
References: <CAKXF9PRuXOoJfQVk-RQTzWOudVM55tgpLL5quBoD+FNJ92Gz_g@mail.gmail.com>
Message-ID: <CAAcGz9-ccNUdY2K5c2n8t+erNkiz1-KPGKxxQTOvzYCO09z-xg@mail.gmail.com>

This driver is present in the Windows binary on CRAN (at least it was
in July): https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140710/5dda6bc4/attachment.pl

I'm not sure about on Linux, I thought it was there but I may have
inadvertently switched to an older GDAL on some systems. I can try
this out on a test VM though, I'm keen to have rgal-recipes for
installing on various systems.

Let me know if:
1) you want Windows or Linux
2) you want help building / installing on Linux (Ubuntu)

(Compiling the Windows binary is hard and mysterious, but I'd love to
be able to do that too. I can do all of it except the final .zip
package bundle which I don't understand yet)

Cheers, Mike.

On Fri, Oct 24, 2014 at 9:06 PM, Guido Biele
<guido.biele at neuro-cognition.org> wrote:
> Hello,
>
> I have an ESRI  ArGis geo database directory which I would like to convert
> to geojson or a shape file (or anything else that I can read into R).
>
> Unfortunately that does not work out of the box with rgdal, because it does
> not come with the fileGDB or openfileGDB driver.
> I could successfully install gdal and the fileGDB driver/extension, but it
> seems that i can use gdal only to convert the gdb file to a SQL database.
>
> So before I start to learn about SQL, I thought I ask if anybody can point
> me to a tutorial or similar that explains how to convert the contents of a
> GDB folder to a R-readable format.
>
> I also wondered if it would be possible to let rgdal know that it could
> access the required drivers because I installed them manually.
> I would appreciate any hint about this too!
>
> Thanks in advance!
> Best Guido
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Michael Sumner
Software and Database Engineer
Australian Antarctic Division
Hobart, Australia
e-mail: mdsumner at gmail.com


From wush978 at gmail.com  Sat Oct 25 11:25:15 2014
From: wush978 at gmail.com (Wush Wu)
Date: Sat, 25 Oct 2014 17:25:15 +0800
Subject: [R]  Looking for Feature Hashing
Message-ID: <CABjzuv47p+CitzhKUWj9gmN1-bCOLZgRhsiJzN3-7s=Ng7rYoQ@mail.gmail.com>

Dear all,

Sorry that I am not sure that whether I should ask the question here or
R-devel. Is there any existed packages which implements or is implementing
feature hashing or similar function?

For who does not know "feature hashing", please let me give a brief
explanation here.

Feature hashing is a technique to convert a large amount of string to dummy
variables quickly( similar to `stats::contrasts` ). For example, if I want
to convert a character vector `x <- c("asdfa", "adsfausd", .....)` to dummy
variable, I need to construct a mapping between the string and the index
(`base::factor`). However, if the `x` has lots of different elements and
the size of `x` is huge, the overhead of constructing index is large.
Moreover, the overhead is larger for the distributed environment.

A good hashing function could be used to map the string to the index
quickly without the overhead of constructing the index. The probability of
"collision" might be small if we pick a good hashing function. For details,
please see http://en.wikipedia.org/wiki/Feature_hashing

Best,
Wush Wu
PhD Student Graduate Institute of Electrical Engineering, National Taiwan
University

	[[alternative HTML version deleted]]


From jingsizhang2016 at u.northwestern.edu  Sat Oct 25 19:25:55 2014
From: jingsizhang2016 at u.northwestern.edu (Jingsi Zhang)
Date: Sat, 25 Oct 2014 12:25:55 -0500
Subject: [R] About the availability of a new package
Message-ID: <CAC1f+kPyPWO9BoAC2Fv643Ju8Sp-71_ct7rcP=vpDevkrc4j_A@mail.gmail.com>

Hi

How does one know the availability of CRAN packages by the name of
publications? I know there is a long list of available packages by date of
publications, but it's so inconvenient to find the one I need. It happened
at least twice when I failed to repeat other's simulation results, and sent
authors an email to request for their R codes. And they mentioned there was
a newly developed package.  But before repeating their methods, I had
already searched their Homepage and papers, including the supplementary
material, but there wasn't much information about the R package they
developed for the paper.

I'll  greatly appreciate if any one know how to find the possible existing
R package for  newly published papers.

Best
Joyce Zhang

	[[alternative HTML version deleted]]


From dotnetsqltraining at gmail.com  Sun Oct 26 03:01:47 2014
From: dotnetsqltraining at gmail.com (Ramnnek Singh)
Date: Sun, 26 Oct 2014 13:01:47 +1100
Subject: [R] RCurl memory leak in getURL method
In-Reply-To: <21579.28673.702365.907548@stat.math.ethz.ch>
References: <CABqr0AwgydZkwrnE2JiROsYBiPNT7-5vLPgAee6wnW+Y2FEUAw@mail.gmail.com>
	<21579.28673.702365.907548@stat.math.ethz.ch>
Message-ID: <544c5618.1123460a.3dee.5b4c@mx.google.com>

Thanks Martin. 

Duncan has replied on http://stackoverflow.com/questions/26556629/rcurl-memory-leak-in-geturl-method

I will test it in the application I have and update the thread here as well.


-----Original Message-----
From: "Martin Maechler" <maechler at stat.math.ethz.ch>
Sent: ?25/?10/?2014 8:40 PM
To: "dotnet sql" <dotnetsqltraining at gmail.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Subject: Re: [R] RCurl memory leak in getURL method

>>>>> dotnet sql <dotnetsqltraining at gmail.com>
>>>>>     on Sat, 25 Oct 2014 08:50:20 +1100 writes:

    > Hi It looks like we have hit a bug in RCurl. The method
    > getURL seems to be leaking memory. A simple test case to
    > reproduce the bug is given here:

    >> library(RCurl)
    >> handle<-getCurlHandle()
    >> range<-1:100
    >> for (r in range) {x<-getURL(url="news.google.com.au",curl=handle)}

    > If I run this code, the memory allocated to the R session is never
    > recovered.

    > We are using RCurl for some long running experiments and we are running out
    > of memory on the test system.

    > The specs of our test system are as follows:
    > OS: Ubuntu 14.04 (64 bit)
    > Memory: 24 GB
    > RCurl version: 1.95-4.3

    > Any ideas about how to get around this issue?

What did the maintainer of the RCurl package say when you asked
him?  
Inside R,  use     maintainer("RCurl")
and then e-mail him, a very smart and nice guy.




    > Thanks

    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From wush978 at gmail.com  Sun Oct 26 10:51:39 2014
From: wush978 at gmail.com (Wush Wu)
Date: Sun, 26 Oct 2014 17:51:39 +0800
Subject: [R]  Matrix::sparse.model.matrix produces inconsistent result
Message-ID: <CABjzuv6Yet41LBqCe-d_gKsjBaXOLqBVjOKd9y4-vJNtn7kyJw@mail.gmail.com>

Hi,

I notice that the Matrix::sparse.model.matrix produces inconsistent matrix
when the contrasts is a sparse matrix.

Here is a minimal example:

```r
library(Matrix)
class(CO2[[1]]) <- class(CO2[[2]]) <- "factor"
get_contr <- function(is_sparse) {
  contr <- list()
  contr[["Plant"]] <- contrasts(CO2[[1]], FALSE, sparse = is_sparse)
  contr[["Type"]] <- contrasts(CO2[[2]], FALSE, sparse = is_sparse)
  contr[["Treatment"]] <- contrasts(CO2[[3]], FALSE, sparse = is_sparse)
  contr
}
m1 <- sparse.model.matrix(~.^2, CO2, get_contr(TRUE))
m2 <- sparse.model.matrix(~.^2, CO2, get_contr(FALSE))
dim(m1)
dim(m2)
```

The dimension is different:

> dim(m1)

[1] 84 66

> dim(m2)

[1]  84 104

>

The example should be reproduced with docker image rocker/r-base

Wush
PhD Student of Graduate Institute of Electrical Engineering, National
Taiwan University

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun Oct 26 11:43:14 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 26 Oct 2014 06:43:14 -0400
Subject: [R] Looking for Feature Hashing
In-Reply-To: <CABjzuv47p+CitzhKUWj9gmN1-bCOLZgRhsiJzN3-7s=Ng7rYoQ@mail.gmail.com>
References: <CABjzuv47p+CitzhKUWj9gmN1-bCOLZgRhsiJzN3-7s=Ng7rYoQ@mail.gmail.com>
Message-ID: <544CD042.3020202@gmail.com>

On 25/10/2014, 5:25 AM, Wush Wu wrote:
> Dear all,
> 
> Sorry that I am not sure that whether I should ask the question here or
> R-devel. Is there any existed packages which implements or is implementing
> feature hashing or similar function?
> 
> For who does not know "feature hashing", please let me give a brief
> explanation here.
> 
> Feature hashing is a technique to convert a large amount of string to dummy
> variables quickly( similar to `stats::contrasts` ). For example, if I want
> to convert a character vector `x <- c("asdfa", "adsfausd", .....)` to dummy
> variable, I need to construct a mapping between the string and the index
> (`base::factor`). However, if the `x` has lots of different elements and
> the size of `x` is huge, the overhead of constructing index is large.
> Moreover, the overhead is larger for the distributed environment.
> 
> A good hashing function could be used to map the string to the index
> quickly without the overhead of constructing the index. The probability of
> "collision" might be small if we pick a good hashing function. For details,
> please see http://en.wikipedia.org/wiki/Feature_hashing

The "digest" package implements several different hash functions.  You
could use the hash values as names in an environment to index arbitrary
objects associated with the values.

Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Oct 26 11:53:51 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 26 Oct 2014 06:53:51 -0400
Subject: [R] About the availability of a new package
In-Reply-To: <CAC1f+kPyPWO9BoAC2Fv643Ju8Sp-71_ct7rcP=vpDevkrc4j_A@mail.gmail.com>
References: <CAC1f+kPyPWO9BoAC2Fv643Ju8Sp-71_ct7rcP=vpDevkrc4j_A@mail.gmail.com>
Message-ID: <544CD2BF.8080106@gmail.com>

On 25/10/2014, 1:25 PM, Jingsi Zhang wrote:
> Hi
> 
> How does one know the availability of CRAN packages by the name of
> publications? I know there is a long list of available packages by date of
> publications, but it's so inconvenient to find the one I need. It happened
> at least twice when I failed to repeat other's simulation results, and sent
> authors an email to request for their R codes. And they mentioned there was
> a newly developed package.  But before repeating their methods, I had
> already searched their Homepage and papers, including the supplementary
> material, but there wasn't much information about the R package they
> developed for the paper.
> 
> I'll  greatly appreciate if any one know how to find the possible existing
> R package for  newly published papers.

Google should help.  For example, if you do the search

"Quantile Autoregression" site:cran.r-project.org

(which is the title of a paper by Roger Koenker in JASA, 2006), you'll
find links to vignettes in the quantreg package by him, as well as one
other package doing related things.  You can also use the sos package to
search package help pages.  (That one doesn't find anything relevant for
"Quantile Autoregression".)

Duncan Murdoch


From kydaviddoyle at gmail.com  Sun Oct 26 14:55:30 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Sun, 26 Oct 2014 08:55:30 -0500
Subject: [R] kruskal test p value way too low.
In-Reply-To: <544C889C.6010809@auckland.ac.nz>
References: <CACftpvqXxcHuX_m6H2ZVnNS-5muni51Q3qzTFWg8134HEO9hWA@mail.gmail.com>
	<544C889C.6010809@auckland.ac.nz>
Message-ID: <CACftpvqAhY7PABsToteka2k7i6cf0rjNBDFmVLKg_KqSR0WDcQ@mail.gmail.com>

Thank for your help!!  That took care of the problem!

Thank  you again

David "Kentucky Geologist trying to learn R" Doyle

On Sun, Oct 26, 2014 at 12:37 AM, Rolf Turner <r.turner at auckland.ac.nz>
wrote:

> On 26/10/14 16:40, David Doyle wrote:
>
>> Hello,
>>
>> I'm trying to run kruskal test on some data but the p values seemed way
>> too
>> low.  So I tried it on some similar data and still got p-value =
>> 1.611e-09.  I'm sure it is a simple mistake but I can't figure it out.
>>
>> Below is my data and code.  Could it be because there are some miss data /
>> NAs in the data set??  If so, could some one point me towards a solution??
>>
>> Thank you for your time.
>> David
>>
>> mydata <-read.csv("http://doylesdartden.com/R/test.csv", sep=",")
>> kruskal.test(mydata, AMMONIA~Well)
>>
>>          Kruskal-Wallis rank sum test
>>
>> data:  mydata
>> Kruskal-Wallis chi-squared = 36.3952, df = 1, p-value = 1.611e-09
>>
>
> Thank you for providing a clear question and an easily reproducible
> example.
>
> The problem is your syntax for the call to the kruskal.test() function.
>
> It should be:
>
>     kruskal.test(AMMONIA ~ Well, data=mydata)
>
> This gives a p-value of 1 (which agrees with wilcox.test); t.test() gives
> a p-value of 0.7958) so harmony is restored to the universe.
>
> IMHO there is a bit of a design flaw in kruskal.test(); it should have
> thrown an error, given your syntax.  The wilcox.test() function *does*
> throw an error.
>
> cheers,
>
> Rolf Turner
>
> --
> Rolf Turner
> Technical Editor ANZJS
>

	[[alternative HTML version deleted]]


From syen04 at gmail.com  Sun Oct 26 19:35:40 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 26 Oct 2014 14:35:40 -0400
Subject: [R] Selecting rows/columns of a matrix
In-Reply-To: <5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
Message-ID: <544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>

Dear

I am interested in selecting rows and columns of a matrix with a 
criterion defined by a binary indicator vector. Let  matrix a be

 > a<-matrix(1:16, 4,4,byrow=T)
 > a
      [,1] [,2] [,3] [,4]
[1,]    1    2    3    4
[2,]    5    6    7    8
[3,]    9   10   11   12
[4,]   13   14   15   16

Elsewhere in Gauss, I select the first and third rows and columns of 
a by defining a column vector j = [1,0,1,0]. Then, select the rows of 
a using j, and then selecting the rows of the transpose of the 
resulting matrix using j again. I get the 2 x 2 matrix as desired. Is 
there a way to do this in R? below are my Gauss commands. Thank you.

---

j

1
0
1
0

a=selif(a,j); a

1  2  3  4
9 10 11 12

a=selif(a',j); a

1  9
3 11


From ruipbarradas at sapo.pt  Sun Oct 26 19:45:35 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 26 Oct 2014 18:45:35 +0000
Subject: [R] Selecting rows/columns of a matrix
In-Reply-To: <544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
Message-ID: <544D414F.50303@sapo.pt>

Hello,

Try the following.

a[as.logical(j), as.logical(j)]

# or
b <- a[as.logical(j), ]
t(b)[as.logical(j), ]


Hope this helps,

Rui Barradas

Em 26-10-2014 18:35, Steven Yen escreveu:
> Dear
>
> I am interested in selecting rows and columns of a matrix with a
> criterion defined by a binary indicator vector. Let  matrix a be
>
>  > a<-matrix(1:16, 4,4,byrow=T)
>  > a
>       [,1] [,2] [,3] [,4]
> [1,]    1    2    3    4
> [2,]    5    6    7    8
> [3,]    9   10   11   12
> [4,]   13   14   15   16
>
> Elsewhere in Gauss, I select the first and third rows and columns of a
> by defining a column vector j = [1,0,1,0]. Then, select the rows of a
> using j, and then selecting the rows of the transpose of the resulting
> matrix using j again. I get the 2 x 2 matrix as desired. Is there a way
> to do this in R? below are my Gauss commands. Thank you.
>
> ---
>
> j
>
> 1
> 0
> 1
> 0
>
> a=selif(a,j); a
>
> 1  2  3  4
> 9 10 11 12
>
> a=selif(a',j); a
>
> 1  9
> 3 11
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sun Oct 26 19:49:18 2014
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 26 Oct 2014 18:49:18 +0000
Subject: [R] Selecting rows/columns of a matrix
In-Reply-To: <544D414F.50303@sapo.pt>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt>
Message-ID: <544D422E.1050605@sapo.pt>

Sorry, that should be

t(a[as.logical(j), as.logical(j)])

Rui Barradas

Em 26-10-2014 18:45, Rui Barradas escreveu:
> Hello,
>
> Try the following.
>
> a[as.logical(j), as.logical(j)]
>
> # or
> b <- a[as.logical(j), ]
> t(b)[as.logical(j), ]
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 26-10-2014 18:35, Steven Yen escreveu:
>> Dear
>>
>> I am interested in selecting rows and columns of a matrix with a
>> criterion defined by a binary indicator vector. Let  matrix a be
>>
>>  > a<-matrix(1:16, 4,4,byrow=T)
>>  > a
>>       [,1] [,2] [,3] [,4]
>> [1,]    1    2    3    4
>> [2,]    5    6    7    8
>> [3,]    9   10   11   12
>> [4,]   13   14   15   16
>>
>> Elsewhere in Gauss, I select the first and third rows and columns of a
>> by defining a column vector j = [1,0,1,0]. Then, select the rows of a
>> using j, and then selecting the rows of the transpose of the resulting
>> matrix using j again. I get the 2 x 2 matrix as desired. Is there a way
>> to do this in R? below are my Gauss commands. Thank you.
>>
>> ---
>>
>> j
>>
>> 1
>> 0
>> 1
>> 0
>>
>> a=selif(a,j); a
>>
>> 1  2  3  4
>> 9 10 11 12
>>
>> a=selif(a',j); a
>>
>> 1  9
>> 3 11
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Sun Oct 26 19:56:37 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 26 Oct 2014 11:56:37 -0700
Subject: [R] Selecting rows/columns of a matrix
In-Reply-To: <544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
Message-ID: <CAF8bMcYTOuChSGPnzcRW-eq-YR7KO01X2CWx0z7+26h-CwtgXw@mail.gmail.com>

Use logical vectors and the "[" operator:  x[condition] can be read as
'x such that condition [is true]'.  E.g.,
   > a<-matrix(1:16, 4,4,byrow=T)
   > j <- c(TRUE, FALSE, TRUE, FALSE)
   > a[j,,drop=FALSE]
        [,1] [,2] [,3] [,4]
   [1,]    1    2    3    4
   [2,]    9   10   11   12
   > a[,j,drop=FALSE]
        [,1] [,2]
   [1,]    1    3
   [2,]    5    7
   [3,]    9   11
   [4,]   13   15
   > a[j,j,drop=FALSE] # apply t() to the result if you want the transpose
        [,1] [,2]
   [1,]    1    3
   [2,]    9   11
The drop=FALSE is not needed in these examples, but prevents single-row
or -column results from be converted to vectors.

See "An Introduction to R" (under Help>Manuals in the Windows GUI,
or look on the R website) for details on these and many other issues.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Sun, Oct 26, 2014 at 11:35 AM, Steven Yen <syen04 at gmail.com> wrote:
> Dear
>
> I am interested in selecting rows and columns of a matrix with a criterion
> defined by a binary indicator vector. Let  matrix a be
>
>> a<-matrix(1:16, 4,4,byrow=T)
>> a
>      [,1] [,2] [,3] [,4]
> [1,]    1    2    3    4
> [2,]    5    6    7    8
> [3,]    9   10   11   12
> [4,]   13   14   15   16
>
> Elsewhere in Gauss, I select the first and third rows and columns of a by
> defining a column vector j = [1,0,1,0]. Then, select the rows of a using j,
> and then selecting the rows of the transpose of the resulting matrix using j
> again. I get the 2 x 2 matrix as desired. Is there a way to do this in R?
> below are my Gauss commands. Thank you.
>
> ---
>
> j
>
> 1
> 0
> 1
> 0
>
> a=selif(a,j); a
>
> 1  2  3  4
> 9 10 11 12
>
> a=selif(a',j); a
>
> 1  9
> 3 11
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From syen04 at gmail.com  Sun Oct 26 19:57:05 2014
From: syen04 at gmail.com (Steven Yen)
Date: Sun, 26 Oct 2014 14:57:05 -0400
Subject: [R] Selecting rows/columns of a matrix
In-Reply-To: <544D422E.1050605@sapo.pt>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
Message-ID: <544d4402.26dcec0a.7867.fffff267@mx.google.com>

Rui

Thanks. This works great. Below, I get the 2nd, 4th, and 6th rows/columns:

 > (a<-matrix(1:36,6,6))
      [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    7   13   19   25   31
[2,]    2    8   14   20   26   32
[3,]    3    9   15   21   27   33
[4,]    4   10   16   22   28   34
[5,]    5   11   17   23   29   35
[6,]    6   12   18   24   30   36
 > (j<-matrix(c(0,1,0,1,0,1)))
      [,1]
[1,]    0
[2,]    1
[3,]    0
[4,]    1
[5,]    0
[6,]    1
 > ((a[as.logical(j), as.logical(j)]))
      [,1] [,2] [,3]
[1,]    8   20   32
[2,]   10   22   34
[3,]   12   24   36

Steven Yen

At 02:49 PM 10/26/2014, Rui Barradas wrote:
>Sorry, that should be
>
>t(a[as.logical(j), as.logical(j)])
>
>Rui Barradas
>
>Em 26-10-2014 18:45, Rui Barradas escreveu:
>>Hello,
>>
>>Try the following.
>>
>>a[as.logical(j), as.logical(j)]
>>
>># or
>>b <- a[as.logical(j), ]
>>t(b)[as.logical(j), ]
>>
>>
>>Hope this helps,
>>
>>Rui Barradas
>>
>>Em 26-10-2014 18:35, Steven Yen escreveu:
>>>Dear
>>>
>>>I am interested in selecting rows and columns of a matrix with a
>>>criterion defined by a binary indicator vector. Let  matrix a be
>>>
>>>  > a<-matrix(1:16, 4,4,byrow=T)
>>>  > a
>>>       [,1] [,2] [,3] [,4]
>>>[1,]    1    2    3    4
>>>[2,]    5    6    7    8
>>>[3,]    9   10   11   12
>>>[4,]   13   14   15   16
>>>
>>>Elsewhere in Gauss, I select the first and third rows and columns of a
>>>by defining a column vector j = [1,0,1,0]. Then, select the rows of a
>>>using j, and then selecting the rows of the transpose of the resulting
>>>matrix using j again. I get the 2 x 2 matrix as desired. Is there a way
>>>to do this in R? below are my Gauss commands. Thank you.
>>>
>>>---
>>>
>>>j
>>>
>>>1
>>>0
>>>1
>>>0
>>>
>>>a=selif(a,j); a
>>>
>>>1  2  3  4
>>>9 10 11 12
>>>
>>>a=selif(a',j); a
>>>
>>>1  9
>>>3 11
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Sun Oct 26 21:19:54 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Sun, 26 Oct 2014 20:19:54 +0000
Subject: [R] Selecting rows/columns of a matrix
In-Reply-To: <544d4402.26dcec0a.7867.fffff267@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>	<544D414F.50303@sapo.pt>
	<544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FAD0E8@mb02.ads.tamu.edu>

Note that you do not have to create the vector of 1's (TRUE) and 0's (FALSE) if you know the index values:

> j <- c(2, 4, 6)
> a[j, j]
     [,1] [,2] [,3]
[1,]    8   20   32
[2,]   10   22   34
[3,]   12   24   36

==============================
David L. Carlson
Department of Anthropology
Texas A&M University


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Steven Yen
Sent: Sunday, October 26, 2014 1:57 PM
To: Rui Barradas; r-help
Subject: Re: [R] Selecting rows/columns of a matrix

Rui

Thanks. This works great. Below, I get the 2nd, 4th, and 6th rows/columns:

 > (a<-matrix(1:36,6,6))
      [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    1    7   13   19   25   31
[2,]    2    8   14   20   26   32
[3,]    3    9   15   21   27   33
[4,]    4   10   16   22   28   34
[5,]    5   11   17   23   29   35
[6,]    6   12   18   24   30   36
 > (j<-matrix(c(0,1,0,1,0,1)))
      [,1]
[1,]    0
[2,]    1
[3,]    0
[4,]    1
[5,]    0
[6,]    1
 > ((a[as.logical(j), as.logical(j)]))
      [,1] [,2] [,3]
[1,]    8   20   32
[2,]   10   22   34
[3,]   12   24   36

Steven Yen

At 02:49 PM 10/26/2014, Rui Barradas wrote:
>Sorry, that should be
>
>t(a[as.logical(j), as.logical(j)])
>
>Rui Barradas
>
>Em 26-10-2014 18:45, Rui Barradas escreveu:
>>Hello,
>>
>>Try the following.
>>
>>a[as.logical(j), as.logical(j)]
>>
>># or
>>b <- a[as.logical(j), ]
>>t(b)[as.logical(j), ]
>>
>>
>>Hope this helps,
>>
>>Rui Barradas
>>
>>Em 26-10-2014 18:35, Steven Yen escreveu:
>>>Dear
>>>
>>>I am interested in selecting rows and columns of a matrix with a 
>>>criterion defined by a binary indicator vector. Let  matrix a be
>>>
>>>  > a<-matrix(1:16, 4,4,byrow=T)
>>>  > a
>>>       [,1] [,2] [,3] [,4]
>>>[1,]    1    2    3    4
>>>[2,]    5    6    7    8
>>>[3,]    9   10   11   12
>>>[4,]   13   14   15   16
>>>
>>>Elsewhere in Gauss, I select the first and third rows and columns of 
>>>a by defining a column vector j = [1,0,1,0]. Then, select the rows of 
>>>a using j, and then selecting the rows of the transpose of the 
>>>resulting matrix using j again. I get the 2 x 2 matrix as desired. Is 
>>>there a way to do this in R? below are my Gauss commands. Thank you.
>>>
>>>---
>>>
>>>j
>>>
>>>1
>>>0
>>>1
>>>0
>>>
>>>a=selif(a,j); a
>>>
>>>1  2  3  4
>>>9 10 11 12
>>>
>>>a=selif(a',j); a
>>>
>>>1  9
>>>3 11
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From evan.kransdorf at gmail.com  Sun Oct 26 21:45:04 2014
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Sun, 26 Oct 2014 13:45:04 -0700
Subject: [R] Help with Lowess smoother
Message-ID: <CAKZWb7dtKssehN+cjWUpG6yRKzV5X=OZVz1=hs1r=FkoeYCqWg@mail.gmail.com>

Hello,

I'm trying to use Lowess smooters to plot some data for regression
analyses.  When I do with certain variables, I get the following error:

> plot(lowess(data$V1,data$V2))
Error in lowess(data$V1, data$V2) : 'delta' must be finite and > 0

Does anyone know where the problem is?  I suspect there's a problem with my
data somewhere.

Many thanks!

	[[alternative HTML version deleted]]


From dmck at u.washington.edu  Sun Oct 26 21:51:22 2014
From: dmck at u.washington.edu (Don McKenzie)
Date: Sun, 26 Oct 2014 13:51:22 -0700
Subject: [R] Help with Lowess smoother
In-Reply-To: <CAKZWb7dtKssehN+cjWUpG6yRKzV5X=OZVz1=hs1r=FkoeYCqWg@mail.gmail.com>
References: <CAKZWb7dtKssehN+cjWUpG6yRKzV5X=OZVz1=hs1r=FkoeYCqWg@mail.gmail.com>
Message-ID: <4D782AE1-A46B-4CB6-B7D9-083C9808AA81@u.washington.edu>


> On Oct 26, 2014, at 1:45 PM, Evan Kransdorf <evan.kransdorf at gmail.com> wrote:
> 
> Hello,
> 
> I'm trying to use Lowess smooters to plot some data for regression
> analyses.  When I do with certain variables, I get the following error:
> 
>> plot(lowess(data$V1,data$V2))
> Error in lowess(data$V1, data$V2) : 'delta' must be finite and > 0
> 
> Does anyone know where the problem is?  I suspect there's a problem with my
> data somewhere.

That sounds like a good guess, but without a reproducible example, no one can say for sure.
> 
> Many thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie
Research Ecologist
Pacific Wildland Fire Sciences Lab
US Forest Service

Affiliate Faculty
School of Environmental and Forest Sciences
University of Washington
dmck at uw.edu


From evan.kransdorf at gmail.com  Sun Oct 26 21:33:01 2014
From: evan.kransdorf at gmail.com (Evan Kransdorf)
Date: Sun, 26 Oct 2014 13:33:01 -0700
Subject: [R] Help
Message-ID: <CAKZWb7e71bp=92v=8zG2ftANN=CMwZjVqHW19sBDJQC68rB6gQ@mail.gmail.com>

Hello,

I'm trying to use Lowess smooters to plot some data for regression
analyses.  When I do with certain variables, I get the following error:

> plot(lowess(data$V1,data$V2))
Error in lowess(data$V1, data$V2) : 'delta' must be finite and > 0

Does anyone know where the problem is?  I suspect there's a problem with my
data somewhere.

Many thanks!

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sun Oct 26 22:41:56 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 26 Oct 2014 22:41:56 +0100
Subject: [R] Help with Lowess smoother
In-Reply-To: <4D782AE1-A46B-4CB6-B7D9-083C9808AA81@u.washington.edu>
References: <CAKZWb7dtKssehN+cjWUpG6yRKzV5X=OZVz1=hs1r=FkoeYCqWg@mail.gmail.com>
	<4D782AE1-A46B-4CB6-B7D9-083C9808AA81@u.washington.edu>
Message-ID: <7F8C7579-109B-438D-A482-69177A5A3FCF@gmail.com>


> On 26 Oct 2014, at 21:51 , Don McKenzie <dmck at u.washington.edu> wrote:
> 
>> 
>> On Oct 26, 2014, at 1:45 PM, Evan Kransdorf <evan.kransdorf at gmail.com> wrote:
>> 
>> Hello,
>> 
>> I'm trying to use Lowess smooters to plot some data for regression
>> analyses.  When I do with certain variables, I get the following error:
>> 
>>> plot(lowess(data$V1,data$V2))
>> Error in lowess(data$V1, data$V2) : 'delta' must be finite and > 0
>> 
>> Does anyone know where the problem is?  I suspect there's a problem with my
>> data somewhere.
> 
> That sounds like a good guess, but without a reproducible example, no one can say for sure.

Well, given that delta is an unspecified argument and that its default, which the poster might have looked up, is diff(range(x)), the poster might have suspected that perhaps the range of x, i.e. data$V1, is either 0 or non-finite. In the former case, all values of x are identical, in the latter, there are Inf or NA values among them. Either way, summary(data$V1) should be enlightening. 


>> 
>> Many thanks!
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> Don McKenzie
> Research Ecologist
> Pacific Wildland Fire Sciences Lab
> US Forest Service
> 
> Affiliate Faculty
> School of Environmental and Forest Sciences
> University of Washington
> dmck at uw.edu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil at dcn.davis.CA.us  Sun Oct 26 23:20:18 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 26 Oct 2014 15:20:18 -0700
Subject: [R] Help
In-Reply-To: <CAKZWb7e71bp=92v=8zG2ftANN=CMwZjVqHW19sBDJQC68rB6gQ@mail.gmail.com>
References: <CAKZWb7e71bp=92v=8zG2ftANN=CMwZjVqHW19sBDJQC68rB6gQ@mail.gmail.com>
Message-ID: <2B3851B6-3DA2-4FA4-B87F-D92B72D77984@dcn.davis.CA.us>

Have you investigated your data using the str function?

str(data)

Also, read the Posting Guide and learn how to use your email software to post using plain text so we will see what you see.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 26, 2014 1:33:01 PM PDT, Evan Kransdorf <evan.kransdorf at gmail.com> wrote:
>Hello,
>
>I'm trying to use Lowess smooters to plot some data for regression
>analyses.  When I do with certain variables, I get the following error:
>
>> plot(lowess(data$V1,data$V2))
>Error in lowess(data$V1, data$V2) : 'delta' must be finite and > 0
>
>Does anyone know where the problem is?  I suspect there's a problem
>with my
>data somewhere.
>
>Many thanks!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From cranatic at gmail.com  Sun Oct 26 23:40:05 2014
From: cranatic at gmail.com (Crantastic)
Date: Sun, 26 Oct 2014 18:40:05 -0400
Subject: [R] CRAN (and crantastic) updates this week
Message-ID: <544d7845a2f58_1aee920d9341e0@284802-web2.revolution-computing.com.tmail>

CRAN (and crantastic) updates this week

New packages
------------

* BayesMixSurv (0.9)
  Maintainer: Alireza S. Mahani
  Author(s): Alireza S. Mahani, Mansour T.A. Sharabiani
  License: GPL (>= 2)
  http://crantastic.org/packages/BayesMixSurv

  Bayesian Mixture Survival Models using Additive Mixture-of-Weibull
  Hazards, with Lasso Shrinkage and Stratification

* cdcsis (1.0)
  Maintainer: Canhong Wen
  Author(s): Canhong Wen, Wenliang Pan, Mian Huang, and Xueqin Wang
  License: GPL (>= 2)
  http://crantastic.org/packages/cdcsis

  Gives conditional distance correlation and performs the conditional
  distance correlation sure independence screening procedure for
  ultrahigh dimensional data. The conditional distance correlation is
  a novel conditional dependence measurement of two random variables
  given a third variable. The conditional distance correlation sure
  independence screening is used for screening variables in ultrahigh
  dimensional setting.

* choroplethrMaps (1.0)
  Maintainer: Ari Lamstein
  Author(s): Ari Lamstein <arilamstein at gmail.com>
  License: BSD_3_clause + file LICENSE
  http://crantastic.org/packages/choroplethrMaps

  Contains 3 maps. 1) US States 2) US Counties 3) Countries of the
  world.

* commentr (0.1)
  Maintainer: Erik Bulow
  Author(s): Erik Bulow
  License: GPL-2
  http://crantastic.org/packages/commentr

  Functions to produce nicely formatted comments to use in R-scripts (or
  Latex/HTML/markdown etc). A comment with formatting is printed to
  the console and can then be copied to a script.

* DetMCD (0.0.1)
  Maintainer: Vakili Kaveh
  Author(s): Vakili Kaveh [aut, cre], Mia Hubert [ths]
  License: GPL (>= 2)
  http://crantastic.org/packages/DetMCD

  DetMCD is a new algorithm for robust and deterministic estimation of
  location and scatter. The benefits of robust and deterministic
  estimation are explained in Hubert, M., Rousseeuw, P.J. and
  Verdonck, T. (2012),&quot;A deterministic algorithm for robust location
  and scatter&quot;, Journal of   Computational and Graphical Statistics,
  Volume 21, Number 3, Pages 618--637.

* FDGcopulas (1.0)
  Maintainer: Gildas Mazo
  Author(s): Gildas Mazo, Stephane Girard
  License: GPL (>= 3)
  http://crantastic.org/packages/FDGcopulas

  FDG copulas are a class of copulas featuring an interesting balance
  between flexibility and tractability. This package provides tools to
  construct, calculate the pairwise dependence coefficients of,
  simulate from, and fit FDG copulas. The acronym FDG stands for
  &#39;one-Factor with Durante Generators&#39;, as an FDG copula is a
  one-factor copula -- that is, the variables are independent given a
  latent factor -- whose linking copulas belong to the Durante class
  of bivariate copulas (also referred to as exchangeable
  Marshall-Olkin or semilinear copulas).

* glmvsd (1.0)
  Maintainer: Yi Yang
  Author(s): Ying Nan <nanx0006 at gmail.com>, Yi Yang <yiyang at umn.edu>, Yuhong Yang
             <yyang at stat.umn.edu>
  License: GPL-2
  http://crantastic.org/packages/glmvsd

  Variable selection deviation measures and instability tests for
  high-dimensional model selection methods such as LASSO, SCAD and
  MCP, etc., to decide whether the sparse patterns identified by those
  methods are reliable.

* highD2pop (1.0)
  Maintainer: Karl Gregory
  Author(s): Karl Gregory
  License: GPL (>= 2)
  http://crantastic.org/packages/highD2pop

  Performs the generalized component test from Gregory et al (2015), as
  well as the tests from Chen and Qin (2010), Srivastava and Kubokawa
  (2013), and Cai, Liu, and Xia (2014) for equality of two population
  mean vectors when the length of the vectors exceeds the sample size.

* indicoio (0.3)
  Maintainer: Madison May
  Author(s): Alexander Gedranovich <gedranovich at gmail.com>
  License: MIT + file LICENSE
  http://crantastic.org/packages/indicoio

  R-based client for Machine Learning APIs at http://indico.io. Provides
  wrappers for following APIs: Positive/Negative Sentiment Analysis,
  Political Sentiment Analysis, Image Feature Extraction, Facial
  Emotion Recognition, Facial Feature Extraction, Language Detection

* JMdesign (1.1)
  Maintainer: Shannon Holloway
  Author(s): Emil A. Cornea, Liddy M. Chen, Bahjat F. Qaqish, Haitao Chu, and
             Joseph G. Ibrahim
  License: GPL-2
  http://crantastic.org/packages/JMdesign

  Performs power calculations for joint modeling of longitudinal and
  survival data with k-th order trajectories when the
  variance-covariance matrix, Sigma_theta, is unknown.

* lmenssp (1.0)
  Maintainer: Ozgur Asar
  Author(s): Ozgur Asar, Peter J. Diggle
  License: GPL (>= 2)
  http://crantastic.org/packages/lmenssp

  Fit, filter and smooth mixed models with non-stationary processes

* managelocalrepo (0.1.4)
  Maintainer: Imanuel Costigan
  Author(s): Imanuel Costigan <i.costigan at me.com>
  License: GPL-2
  http://crantastic.org/packages/managelocalrepo

  This will allow easier management of a CRAN-style repository on local
  networks (i.e. not on CRAN). This might be necessary where hosted
  packages contain intellectual property owned by a corporation.

* matR (0.9)
  Maintainer: Daniel Braithwaite
  Author(s): Daniel Braithwaite [aut, cre], Kevin Keegan [aut], University of
             Chicago [cph]
  License: BSD_2_clause + file LICENSE
  http://crantastic.org/packages/matR

  An analysis platform for metagenomics combining  specialized tools and
  workflows, easy handling of the BIOM  format, and transparent access
  to MG-RAST resources.  matR integrates  easily with other R packages
  and non-R software.

* openssl (0.1)
  Maintainer: Jeroen Ooms
  Author(s): Jeroen Ooms
  License: MIT + file LICENSE
  http://crantastic.org/packages/openssl

  This package interfaces to the OpenSSL libraries libssl and libcrypto.
  Currently it only implements bindings to the OpenSSL random number
  generator in order to generate crypto secure random bytes in R.

* ore (1.0.1)
  Maintainer: Jon Clayden
  Author(s): Jon Clayden, based on Onigmo by K. Kosako and K. Takata
  License: BSD_3_clause + file LICENCE
  http://crantastic.org/packages/ore

  Provides an alternative to R&#39;s built-in functionality for handling
  regular expressions, based on the Oniguruma library. It offers
  first-class compiled regex objects, partial matching and
  function-based substitutions, amongst other features.

* P2C2M (0.5)
  Maintainer: Michael Gruenstaeudl
  Author(s): Michael Gruenstaeudl, Noah Reid
  License: GPL (>= 2)
  http://crantastic.org/packages/P2C2M

  P2C2M is an R package to conduct posterior predictive checks of
  coalescent models using gene and species trees generated by BEAST
  and *BEAST, respectively. The functionality of P2C2M can be extended
  via two third-party R packages that are available from the author
  websites only: genealogicalSorting
  (http://www.genealogicalsorting.org) and phybase
  (http://odyssey.bioinformatics.uga.edu/~lliu/phybase/). To use these
  optional packages, installation of the Python libraries NumPy (&gt;=
  1.9.0) and DendroPy (= 3.12.0) is necessary.

* PANICr (0.0.0.2)
  Maintainer: Steve Bronder
  Author(s): Steve Bronder <sbronder at stevebronder.com>
  License: GPL-3
  http://crantastic.org/packages/PANICr

  This package contains a methodology that makes use of the factor
  structure of large dimensional panels to understand the nature of
  nonstationarity inherent in data. This is referred to as PANIC -
  Panel Analysis of Nonstationarity in Idiosyncratic and Common
  Components. PANIC (2004) includes valid pooling methods that allow
  panel tests to be constructed. PANIC (2004) can detect whether the
  nonstationarity in a series is pervasive, or variable specific, or
  both. PANIC (2010) includes two new tests on the idiosyncratic
  component that estimates the pooled autoregressive coefficient and
  sample moment, respectively. The PANIC model approximates the number
  of factors based on Bai and Ng (2002)

* PHENIX (1.0)
  Maintainer: A. J. Mu??oz-Pajares
  Author(s): R. Torices, A. J. Mu??oz-Pajares
  License: GPL (>= 2)
  http://crantastic.org/packages/PHENIX

  Provides functions to estimate the size-controlled phenotypic
  integration index, a novel method by Torices &amp; M??ndez (2014) to
  solve problems due to individual size when estimating integration
  (namely, larger individuals have larger components, which will drive
  a correlation between components only due to resource availability
  that might overestimate the observed measures of integration). In
  addition, the package also provides the classical estimation by
  Wagner (1984) and a bootstrapping method to test the significance of
  both integration indices.

* rsml (1.0)
  Maintainer: Guillaume Lobet
  Author(s): Guillaume Lobet
  License: GPL-2
  http://crantastic.org/packages/rsml

  Read and analyse Root System Markup Language (RSML) files.

* rtkpp (0.8.3)
  Maintainer: Serge Iovleff
  Author(s): Serge Iovleff [aut, cre], Vincent Kubicki [ctb], Quentin Grimonprez
             [ctb], Parmeet Bhatia [ctb]
  License: GPL (>= 2) | LGPL (>= 2) | file LICENSE
  http://crantastic.org/packages/rtkpp

  STK++ (http://www.stkpp.org) is a collection of C++ classes for
  statistics, clustering, linear algebra, arrays (with an Eigen-like
  API), regression, dimension reduction, etc. The integration of the
  library to R is using Rcpp. Some functionalities of the Clustering
  project provided by the library are available in the R environment
  as R functions. . The rtkpp package includes the header files from
  the STK++ library (currently version 0.8.2). Thus users do not need
  to install STK++ itself in order to use it. . STK++ is licensed
  under the GNU LGPL version 2 or later. rtkpp (the stkpp integration
  into R) is licensed under the GNU GPL version 2 or later.

* ruv (0.9.4)
  Maintainer: Johann Gagnon-Bartsch
  Author(s): Johann Gagnon-Bartsch <johann at stat.berkeley.edu>
  License: GPL
  http://crantastic.org/packages/ruv

  The algorithms in this package attempt to adjust for systematic errors
  of unknown origin in high-dimensional data.  The algorithms were
  originally developed for use with genomic data, especially
  microarray data, but may be useful with other types of
  high-dimensional data as well.  The algorithms included in this
  package are RUV-2, RUV-4, RUV-inv, and RUV-rinv, along with various
  supporting algorithms.  These algorithms were proposed by
  Gagnon-Bartsch and Speed (2012), and by Gagnon-Bartsch, Jacob and
  Speed (2013).  The algorithms require the user to specifiy a set of
  negative control variables, as described in the references.

* saeSim (0.6.0)
  Maintainer: Sebastian Warnholz
  Author(s): Sebastian Warnholz <Sebastian.Warnholz at fu-berlin.de>
  License: GPL-3 | file LICENSE
  http://crantastic.org/packages/saeSim

  Tools for the simulation of data in the context of small area
  estimation. Combine all steps of your simulation - from data
  generation over drawing samples to model fitting - in one object.
  This enables easy modification and combination of different
  scenarios. You can store your results in a folder or start the
  simulation in parallel.

* scrm (1.3-2)
  Maintainer: Paul Staab
  Author(s): Paul Staab [aut, cre, cph], Zhu Sha [aut, cph], Dirk Metzler [ths],
             Gerton Lunter [aut, cph, ths]
  License: GPL (>= 3)
  http://crantastic.org/packages/scrm

  A coalescent simulator that allows the rapid simulation of biological
  sequences under neutral models of evolution.

* sigloc (0.0.4)
  Maintainer: Sergey S. Berg
  Author(s): Sergey S. Berg
  License: GPL (>= 2)
  http://crantastic.org/packages/sigloc

  A collection of tools for estimating the location of a transmitter
  signal from radio telemetry studies using the maximum likelihood
  estimation (MLE) approach described in Lenth (1981).

* TDboost (1.0)
  Maintainer: Yi Yang
  Author(s): Yi Yang <yiyang at umn.edu>, Wei Qian <weiqian at stat.umn.edu>, Hui Zou
             <hzou at stat.umn.edu>
  License: GPL-3
  http://crantastic.org/packages/TDboost

  A fully nonparametric Tweedie model using the gradient boosting. It is
  capable of fitting a flexible nonlinear model and capturing
  interactions among predictors.

* traj (1.0)
  Maintainer: Dan Vatnik
  Author(s): Marie-Pierre Sylvestre, Dan Vatnik
  License: GPL-2
  http://crantastic.org/packages/traj

  Implements the three step procedure proposed by Leffondree et al.
  (2004) to identify clusters of individual longitudinal trajectories.
  The procedure involves (1) calculating 24 measures describing the
  features of the trajectories; (2) using factor analysis to select a
  subset of the 24 measures and (3) using cluster analysis to identify
  clusters of trajectories, and classify each individual trajectory in
  one of the clusters.


Updated packages
----------------

AutoSEARCH (1.3), BayesFactor (0.9.9), bio3d (2.1-2), CAMAN (0.72),
confidence (1.1-0), DBKGrad (1.6), equate (2.0-3), extracat (1.7-1),
FSelector (0.20), GGIR (1.1-3), HiDimDA (0.2-2), highr (0.4), httpuv
(1.3.2), imputeYn (1.2), jackknifeKME (1.1), JADE (1.9-92), JMdesign
(1.1), logconPH (1.2), logconPH (1.1), MAINT.Data (0.3), MESS (0.3-2),
MPTinR (1.6.3), MRH (1.1), nhlscrapr (1.8), npmlreg (0.46-1), ore
(1.0.1), pcaPP (1.9-60), PKfit (1.2.4), polyCub (0.5-1), prevalence
(0.3.0), rasterVis (0.32), redcapAPI (1.0.1), restlos (0.1-3), rex
(0.1.1), RnavGraph (0.1.7), Rook (1.1-1), rpf (0.40), RSQLite (1.0.0),
rtkpp (0.8.3), SamplingStrata (1.0-3), scrm (1.3-2), sgof (2.1.1),
sparr (0.3-6), spatstat (1.39-1), spatstat (1.39-0), speedglm
(0.2-1.0), STARSEQ (1.2.1), stepp (3.0-11), synbreed (0.10-3), tclust
(1.2-3), timeordered (0.9.7), TwoStepCLogit (1.2.3), VIM (4.1.0), WRS2
(0.2-0)



This email provided as a service for the R community by
http://crantastic.org.

Like it?  Hate it?  Please let us know: cranatic at gmail.com.


From kydaviddoyle at gmail.com  Mon Oct 27 02:49:48 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Sun, 26 Oct 2014 20:49:48 -0500
Subject: [R] Box Plot size and labels
Message-ID: <CACftpvo7W1Cm474MDSQm08UyqfcTGznz7145r+m1dJqOdcMsBA@mail.gmail.com>

Hello,

I'm doing some box plots in Rmarkdown to MS Word file.  When they come into
the word file they are not quite wide enough for labels for the different
boxes.  Is there a way for me to set the size the box plot would be so I
can make it wider?

Or reduce the font size so they can all fit on the graph??

My data and code are below

Thank you for your time.
David Doyle

MS <- read.table("http://www.doylesdartden.com/R/MS.csv", header=TRUE,
sep=",",)

#Sets whic are detections and nondetects
MS$Detections <- ifelse(MS$D_AMMONIA==1, "Detected", "NonDetect")

MSAmmoniax <- c("Well", "AMMONIA")
MSAmmonia <- MS[MSAmmoniax]

plot(MSAmmonia, notch=TRUE, ylab = "Ammonia (mg/L)", cex = 0.1,
col=(c("green","white")))
legend("topleft", inset=.002, title="Gradient",
       c("Up","Down"), fill=terrain.colors(2), horiz=TRUE, cex = 0.7,)
title(main="Lower Mudstone Ammonia Box Plots")

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Mon Oct 27 03:27:30 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 26 Oct 2014 19:27:30 -0700
Subject: [R] Box Plot size and labels
In-Reply-To: <CACftpvo7W1Cm474MDSQm08UyqfcTGznz7145r+m1dJqOdcMsBA@mail.gmail.com>
References: <CACftpvo7W1Cm474MDSQm08UyqfcTGznz7145r+m1dJqOdcMsBA@mail.gmail.com>
Message-ID: <5136884B-34BA-4BD4-9041-905D9EEBD770@dcn.davis.CA.us>

Your code uses the default graphics output device (most likely the windows() device, guessing from your use of MSWord). The png() device might produce more consistent results. Since you are using RMarkdown, you may be using knitr which has chunk options that can be used to control the device used and its graphic properties.

See

?png
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 26, 2014 6:49:48 PM PDT, David Doyle <kydaviddoyle at gmail.com> wrote:
>Hello,
>
>I'm doing some box plots in Rmarkdown to MS Word file.  When they come
>into
>the word file they are not quite wide enough for labels for the
>different
>boxes.  Is there a way for me to set the size the box plot would be so
>I
>can make it wider?
>
>Or reduce the font size so they can all fit on the graph??
>
>My data and code are below
>
>Thank you for your time.
>David Doyle
>
>MS <- read.table("http://www.doylesdartden.com/R/MS.csv", header=TRUE,
>sep=",",)
>
>#Sets whic are detections and nondetects
>MS$Detections <- ifelse(MS$D_AMMONIA==1, "Detected", "NonDetect")
>
>MSAmmoniax <- c("Well", "AMMONIA")
>MSAmmonia <- MS[MSAmmoniax]
>
>plot(MSAmmonia, notch=TRUE, ylab = "Ammonia (mg/L)", cex = 0.1,
>col=(c("green","white")))
>legend("topleft", inset=.002, title="Gradient",
>       c("Up","Down"), fill=terrain.colors(2), horiz=TRUE, cex = 0.7,)
>title(main="Lower Mudstone Ammonia Box Plots")
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kydaviddoyle at gmail.com  Mon Oct 27 04:27:00 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Sun, 26 Oct 2014 22:27:00 -0500
Subject: [R] Plot size
In-Reply-To: <CADv2QyGebBywxKFtzYaKuwscCHqPnOdqtGyOCPABuJ-PHJ4dTA@mail.gmail.com>
References: <CACftpvrgd6ZKGk22oM6zTQG7x7yRyusE0+i1r42c0AwCSVk6VA@mail.gmail.com>
	<CADv2QyGebBywxKFtzYaKuwscCHqPnOdqtGyOCPABuJ-PHJ4dTA@mail.gmail.com>
Message-ID: <CACftpvry+PZiPq5WAHLyscwnoq+cVbhseKKjqY7BttnH8Nd55A@mail.gmail.com>

Thank You!!

On Sun, Oct 26, 2014 at 10:01 PM, Dennis Murphy <djmuser at gmail.com> wrote:

> I'd suggest using the knitr code chunk options in Rmarkdown to control
> the plot size in the document; e.g.,
>
> ```{r myplot, fig.height=5, fig.width=6}
> <your plot code>
> ```
> If you use RStudio, it will provide code completion for you as you
> type the code chunk header.
>
> Dennis
>
> On Sun, Oct 26, 2014 at 6:03 PM, David Doyle <kydaviddoyle at gmail.com>
> wrote:
> > Hi Folks,
> >
> > I'm trying to adjust the plot size so it can be pulled into a document by
> > Rmarkdown.  Any suggestions??
> >
> > .  The data and code are below
> >
> > library(ggplot2)
> >
> > MS <- read.table("http://www.doylesdartden.com/R/MS.csv", header=TRUE,
> > sep=",",)
> >
> > #Sets whic are detections and nondetects
> > MS$Detections <- ifelse(MS$D_AMMONIA==1, "Detected", "NonDetect")
> >
> > #does the plot
> > p <- ggplot(data = MS, aes(x=Year, y=AMMONIA, col=Detections)) +
> >   geom_point(aes(shape=Detections)) +
> >
> >   ##sets the colors
> >   scale_colour_manual(values=c("black","red")) +
> >
> >   #location of the legend
> >   theme(legend.position=c("none")) +
> >
> >   #sets the line color, type and size
> >   geom_line(colour="black", linetype="dotted", size=0.5) +
> >   ylab("Ammonia (mg/L)") +
> >   ##Graph title
> >   ggtitle("Lower Mudstone Ammonia Time Sereis")
> >
> > ## does the graph using the Well IDs as the different wells.
> > p + facet_grid(Well ~ .)
> >
> >
> > --
> > --
> > You received this message because you are subscribed to the ggplot2
> mailing
> > list.
> > Please provide a reproducible example:
> > https://github.com/hadley/devtools/wiki/Reproducibility
> >
> > To post: email ggplot2 at googlegroups.com
> > To unsubscribe: email ggplot2+unsubscribe at googlegroups.com
> > More options: http://groups.google.com/group/ggplot2
> >
> > ---
> > You received this message because you are subscribed to the Google Groups
> > "ggplot2" group.
> > To unsubscribe from this group and stop receiving emails from it, send an
> > email to ggplot2+unsubscribe at googlegroups.com.
> > For more options, visit https://groups.google.com/d/optout.
>

	[[alternative HTML version deleted]]


From cmora at Dal.Ca  Mon Oct 27 06:05:37 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Mon, 27 Oct 2014 05:05:37 +0000
Subject: [R] =?windows-1252?q?=22inahull=94_from_package_alphahull_not_wor?=
 =?windows-1252?q?king_when_used_with_apply?=
Message-ID: <1414386337700.89765@Dal.Ca>

Hi everyone,

I have a two column (x,y) database with say 20 million rows. I want to check the points that are inside of a hull created with the package alphahull. The function that does this is call ?inahull?, and it runs well when I use it for one point at a time. But when I try to optimize the function using ?apply?, it gives me the wrong results. I wonder what I am doing wrong? Below is the code: I also wonder if "inahull", could be used in data.table?

library (alphahull)
DT<-data.frame(x=c(0.25,0.75,0.75,0.25),y=c(0.25,0.25,0.75,0.75))

#creates hull
HULL<-ahull(DT, alpha=0.5)

#generate two points as test
TEST<-data.frame(x=c(0.25,0.5),y=c(0.5,0.5))
TEST<-data.matrix(TEST)

#check individual points
InPoint1<-inahull(HULL, c(TEST[1,1],TEST[1,2]))
InPoint2<-inahull(HULL, c(TEST[2,1],TEST[2,2]))

> InPoint1
[1] FALSE
> InPoint2
[1] TRUE

#repead check using apply
in2D=apply(TEST, 1,function(x, y) inahull(HULL, p = TEST))
> in2D
[1] FALSE FALSE





	[[alternative HTML version deleted]]


From kasterma at kasterma.net  Mon Oct 27 07:03:20 2014
From: kasterma at kasterma.net (Bart Kastermans)
Date: Mon, 27 Oct 2014 07:03:20 +0100
Subject: [R]
 =?utf-8?q?=22inahull=E2=80=9D_from_package_alphahull_not_work?=
 =?utf-8?q?ing_when_used_with_apply?=
In-Reply-To: <1414386337700.89765@Dal.Ca>
References: <1414386337700.89765@Dal.Ca>
Message-ID: <544DE028.4070103@kasterma.net>

On 27/10/14 06:05, Camilo Mora wrote:
> Hi everyone,
> 
> I have a two column (x,y) database with say 20 million rows. I want to check the points that are inside of a hull created with the package alphahull. The function that does this is call ?inahull?, and it runs well when I use it for one point at a time. But when I try to optimize the function using ?apply?, it gives me the wrong results. I wonder what I am doing wrong? Below is the code: I also wonder if "inahull", could be used in data.table?
> 
> library (alphahull)
> DT<-data.frame(x=c(0.25,0.75,0.75,0.25),y=c(0.25,0.25,0.75,0.75))
> 
> #creates hull
> HULL<-ahull(DT, alpha=0.5)
> 
> #generate two points as test
> TEST<-data.frame(x=c(0.25,0.5),y=c(0.5,0.5))
> TEST<-data.matrix(TEST)
> 
> #check individual points
> InPoint1<-inahull(HULL, c(TEST[1,1],TEST[1,2]))
> InPoint2<-inahull(HULL, c(TEST[2,1],TEST[2,2]))
> 
>> InPoint1
> [1] FALSE
>> InPoint2
> [1] TRUE
> 
> #repead check using apply
> in2D=apply(TEST, 1,function(x, y) inahull(HULL, p = TEST))

Why do x or y not appear in the function expression?  Note that any
apply with a function that does not use its argument will give a
constant sequence.  Now also, apply gives the whole dimension as an
argument, so once you try to use y as an argument you will get the error
(I tried just to get the error correct):

    Error: argument "y" is missing, with no default

If that wasn't enough yet; let me ask another question, what is wrong
with p = TEST?

Best,
Bart

>> in2D
> [1] FALSE FALSE
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From guido.biele at neuro-cognition.org  Mon Oct 27 09:20:19 2014
From: guido.biele at neuro-cognition.org (Guido Biele)
Date: Mon, 27 Oct 2014 09:20:19 +0100
Subject: [R] rgdal: Convert ESRI ArcGis geo database (gdb directory) to
 geojson, or shapefile map
In-Reply-To: <CAAcGz9-ccNUdY2K5c2n8t+erNkiz1-KPGKxxQTOvzYCO09z-xg@mail.gmail.com>
References: <CAKXF9PRuXOoJfQVk-RQTzWOudVM55tgpLL5quBoD+FNJ92Gz_g@mail.gmail.com>
	<CAAcGz9-ccNUdY2K5c2n8t+erNkiz1-KPGKxxQTOvzYCO09z-xg@mail.gmail.com>
Message-ID: <CAKXF9PRrmTLtOzuc0ASdCaardTu0LkE5Lrds0BELzg+WffuGNw@mail.gmail.com>

Thanks,
Now I found the driver in the current rgdal version!

Unfortunately I still can't open the database, even though the OpenfileGDB
driver is used.
When I list the layers
and then try to load one of the layers, I get the error message that no
features are found:

ogrListLayers("Stoy.gdb")
[1] "veg_storbyomrader"         "veg_traffikert_veg"
 "flyplass_store_flyplasser" "bane_storbyomrader"
[5] "bane_traffikert_bane"
attr(,"driver")
[1] "OpenFileGDB"
attr(,"nlayers")
[1] 5
> m = readOGR("Stoy.gdb",layer = "veg_storbyomrader")
Error in readOGR("Stoy.gdb", layer = "veg_storbyomrader") :
  no features found
In addition: Warning message:
In ogrFIDs(dsn = dsn, layer = layer) : no features found


Is this likely due to the database, or could this be a problem with the
driver?

In case that helps, here is the link to the map layer I want to extrac (the
link is to a web page, but I have the data base file).
http://www.miljostatus.no/kart/?lang=no&extent=152517|6532562|210570|6557188&layers=147:46;20:100;138:100;&basemap=KART&opacity=71&saturation=90

Best - Guido


On Sun, Oct 26, 2014 at 7:21 AM, Michael Sumner <mdsumner at gmail.com> wrote:

> This driver is present in the Windows binary on CRAN (at least it was
> in July):
> https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140710/5dda6bc4/attachment.pl
>
> I'm not sure about on Linux, I thought it was there but I may have
> inadvertently switched to an older GDAL on some systems. I can try
> this out on a test VM though, I'm keen to have rgal-recipes for
> installing on various systems.
>
> Let me know if:
> 1) you want Windows or Linux
> 2) you want help building / installing on Linux (Ubuntu)
>
> (Compiling the Windows binary is hard and mysterious, but I'd love to
> be able to do that too. I can do all of it except the final .zip
> package bundle which I don't understand yet)
>
> Cheers, Mike.
>
> On Fri, Oct 24, 2014 at 9:06 PM, Guido Biele
> <guido.biele at neuro-cognition.org> wrote:
> > Hello,
> >
> > I have an ESRI  ArGis geo database directory which I would like to
> convert
> > to geojson or a shape file (or anything else that I can read into R).
> >
> > Unfortunately that does not work out of the box with rgdal, because it
> does
> > not come with the fileGDB or openfileGDB driver.
> > I could successfully install gdal and the fileGDB driver/extension, but
> it
> > seems that i can use gdal only to convert the gdb file to a SQL database.
> >
> > So before I start to learn about SQL, I thought I ask if anybody can
> point
> > me to a tutorial or similar that explains how to convert the contents of
> a
> > GDB folder to a R-readable format.
> >
> > I also wondered if it would be possible to let rgdal know that it could
> > access the required drivers because I installed them manually.
> > I would appreciate any hint about this too!
> >
> > Thanks in advance!
> > Best Guido
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>

	[[alternative HTML version deleted]]


From Thierry.ONKELINX at inbo.be  Mon Oct 27 09:31:09 2014
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Mon, 27 Oct 2014 08:31:09 +0000
Subject: [R] rgdal: Convert ESRI ArcGis geo database (gdb directory) to
 geojson, or shapefile map
In-Reply-To: <CAKXF9PRrmTLtOzuc0ASdCaardTu0LkE5Lrds0BELzg+WffuGNw@mail.gmail.com>
References: <CAKXF9PRuXOoJfQVk-RQTzWOudVM55tgpLL5quBoD+FNJ92Gz_g@mail.gmail.com>
	<CAAcGz9-ccNUdY2K5c2n8t+erNkiz1-KPGKxxQTOvzYCO09z-xg@mail.gmail.com>
	<CAKXF9PRrmTLtOzuc0ASdCaardTu0LkE5Lrds0BELzg+WffuGNw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427F3B0C1A7@inbomail.inbo.be>

Dear Guido,

Do you know how the gdb is stored? I had problems reading for a gdb on our networkdrive. Reading from a local copy worked. It turned out that the original copy on the networkdrive was indexed. Reading an unindexed gdb from the networkdrive was no problem.

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Guido Biele
Verzonden: maandag 27 oktober 2014 9:20
Aan: Michael Sumner
CC: r-help at r-project.org
Onderwerp: Re: [R] rgdal: Convert ESRI ArcGis geo database (gdb directory) to geojson, or shapefile map

Thanks,
Now I found the driver in the current rgdal version!

Unfortunately I still can't open the database, even though the OpenfileGDB driver is used.
When I list the layers
and then try to load one of the layers, I get the error message that no features are found:

ogrListLayers("Stoy.gdb")
[1] "veg_storbyomrader"         "veg_traffikert_veg"
 "flyplass_store_flyplasser" "bane_storbyomrader"
[5] "bane_traffikert_bane"
attr(,"driver")
[1] "OpenFileGDB"
attr(,"nlayers")
[1] 5
> m = readOGR("Stoy.gdb",layer = "veg_storbyomrader")
Error in readOGR("Stoy.gdb", layer = "veg_storbyomrader") :
  no features found
In addition: Warning message:
In ogrFIDs(dsn = dsn, layer = layer) : no features found


Is this likely due to the database, or could this be a problem with the driver?

In case that helps, here is the link to the map layer I want to extrac (the link is to a web page, but I have the data base file).
http://www.miljostatus.no/kart/?lang=no&extent=152517|6532562|210570|6557188&layers=147:46;20:100;138:100;&basemap=KART&opacity=71&saturation=90

Best - Guido


On Sun, Oct 26, 2014 at 7:21 AM, Michael Sumner <mdsumner at gmail.com> wrote:

> This driver is present in the Windows binary on CRAN (at least it was
> in July):
> https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140710/5dda6bc4
> /attachment.pl
>
> I'm not sure about on Linux, I thought it was there but I may have
> inadvertently switched to an older GDAL on some systems. I can try
> this out on a test VM though, I'm keen to have rgal-recipes for
> installing on various systems.
>
> Let me know if:
> 1) you want Windows or Linux
> 2) you want help building / installing on Linux (Ubuntu)
>
> (Compiling the Windows binary is hard and mysterious, but I'd love to
> be able to do that too. I can do all of it except the final .zip
> package bundle which I don't understand yet)
>
> Cheers, Mike.
>
> On Fri, Oct 24, 2014 at 9:06 PM, Guido Biele
> <guido.biele at neuro-cognition.org> wrote:
> > Hello,
> >
> > I have an ESRI  ArGis geo database directory which I would like to
> convert
> > to geojson or a shape file (or anything else that I can read into R).
> >
> > Unfortunately that does not work out of the box with rgdal, because
> > it
> does
> > not come with the fileGDB or openfileGDB driver.
> > I could successfully install gdal and the fileGDB driver/extension,
> > but
> it
> > seems that i can use gdal only to convert the gdb file to a SQL database.
> >
> > So before I start to learn about SQL, I thought I ask if anybody can
> point
> > me to a tutorial or similar that explains how to convert the
> > contents of
> a
> > GDB folder to a R-readable format.
> >
> > I also wondered if it would be possible to let rgdal know that it
> > could access the required drivers because I installed them manually.
> > I would appreciate any hint about this too!
> >
> > Thanks in advance!
> > Best Guido
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> Hobart, Australia
> e-mail: mdsumner at gmail.com
>

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From jim at bitwrit.com.au  Mon Oct 27 09:47:06 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 27 Oct 2014 19:47:06 +1100
Subject: [R] dotplot with library lattice
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF2DE@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
	<1709300.gu1B0lVq0c@localhost.localdomain>
	<7E39CF5278A2C948968C39502CF451020174CEADF2DE@mail.ell.fnt.de>
Message-ID: <5483501.3ZsGK1Yh3h@localhost.localdomain>

On Mon, 27 Oct 2014 08:53:51 AM Matthias Weber wrote:
> Hi Jim,
> 
> looks perfect to me. Thank you very much. One last question. Is there 
any
> possibility to add 3 horizontal lines in the graph. One at 25%, the other
> one at 50% and the last one at 75%? So I can see the process a bit 
better?
> 
Hi Mat,
Change this:

abline(h=1:13,lty=2,col="lightgray")

to this:

abline(h=1:13,v=c(25,50,75),lty=2,col="lightgray")

Jim


From guido.biele at neuro-cognition.org  Mon Oct 27 09:47:34 2014
From: guido.biele at neuro-cognition.org (Guido Biele)
Date: Mon, 27 Oct 2014 09:47:34 +0100
Subject: [R] rgdal: Convert ESRI ArcGis geo database (gdb directory) to
 geojson, or shapefile map
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427F3B0C1A7@inbomail.inbo.be>
References: <CAKXF9PRuXOoJfQVk-RQTzWOudVM55tgpLL5quBoD+FNJ92Gz_g@mail.gmail.com>
	<CAAcGz9-ccNUdY2K5c2n8t+erNkiz1-KPGKxxQTOvzYCO09z-xg@mail.gmail.com>
	<CAKXF9PRrmTLtOzuc0ASdCaardTu0LkE5Lrds0BELzg+WffuGNw@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427F3B0C1A7@inbomail.inbo.be>
Message-ID: <CAKXF9PTz14KTZVQg2uah1OwXmzB+oby6pWZSvZfWdCwOLjZEcg@mail.gmail.com>

Dear Thierry,

thanks for your quick response!
I did try to load a local copy. But that did not work.
There is actually lots of information about the data base online (
http://kart.klif.no/arcgis/rest/services/Miljostatus/Stoysoner_veg/MapServer
)
but none of this seems to be helpful to load the map in R.

Best - Guido

On Mon, Oct 27, 2014 at 9:31 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be
> wrote:

> Dear Guido,
>
> Do you know how the gdb is stored? I had problems reading for a gdb on our
> networkdrive. Reading from a local copy worked. It turned out that the
> original copy on the networkdrive was indexed. Reading an unindexed gdb
> from the networkdrive was no problem.
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> -----Oorspronkelijk bericht-----
> Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> Namens Guido Biele
> Verzonden: maandag 27 oktober 2014 9:20
> Aan: Michael Sumner
> CC: r-help at r-project.org
> Onderwerp: Re: [R] rgdal: Convert ESRI ArcGis geo database (gdb directory)
> to geojson, or shapefile map
>
> Thanks,
> Now I found the driver in the current rgdal version!
>
> Unfortunately I still can't open the database, even though the OpenfileGDB
> driver is used.
> When I list the layers
> and then try to load one of the layers, I get the error message that no
> features are found:
>
> ogrListLayers("Stoy.gdb")
> [1] "veg_storbyomrader"         "veg_traffikert_veg"
>  "flyplass_store_flyplasser" "bane_storbyomrader"
> [5] "bane_traffikert_bane"
> attr(,"driver")
> [1] "OpenFileGDB"
> attr(,"nlayers")
> [1] 5
> > m = readOGR("Stoy.gdb",layer = "veg_storbyomrader")
> Error in readOGR("Stoy.gdb", layer = "veg_storbyomrader") :
>   no features found
> In addition: Warning message:
> In ogrFIDs(dsn = dsn, layer = layer) : no features found
>
>
> Is this likely due to the database, or could this be a problem with the
> driver?
>
> In case that helps, here is the link to the map layer I want to extrac
> (the link is to a web page, but I have the data base file).
>
> http://www.miljostatus.no/kart/?lang=no&extent=152517|6532562|210570|6557188&layers=147:46;20:100;138:100;&basemap=KART&opacity=71&saturation=90
>
> Best - Guido
>
>
> On Sun, Oct 26, 2014 at 7:21 AM, Michael Sumner <mdsumner at gmail.com>
> wrote:
>
> > This driver is present in the Windows binary on CRAN (at least it was
> > in July):
> > https://stat.ethz.ch/pipermail/r-sig-geo/attachments/20140710/5dda6bc4
> > /attachment.pl
> >
> > I'm not sure about on Linux, I thought it was there but I may have
> > inadvertently switched to an older GDAL on some systems. I can try
> > this out on a test VM though, I'm keen to have rgal-recipes for
> > installing on various systems.
> >
> > Let me know if:
> > 1) you want Windows or Linux
> > 2) you want help building / installing on Linux (Ubuntu)
> >
> > (Compiling the Windows binary is hard and mysterious, but I'd love to
> > be able to do that too. I can do all of it except the final .zip
> > package bundle which I don't understand yet)
> >
> > Cheers, Mike.
> >
> > On Fri, Oct 24, 2014 at 9:06 PM, Guido Biele
> > <guido.biele at neuro-cognition.org> wrote:
> > > Hello,
> > >
> > > I have an ESRI  ArGis geo database directory which I would like to
> > convert
> > > to geojson or a shape file (or anything else that I can read into R).
> > >
> > > Unfortunately that does not work out of the box with rgdal, because
> > > it
> > does
> > > not come with the fileGDB or openfileGDB driver.
> > > I could successfully install gdal and the fileGDB driver/extension,
> > > but
> > it
> > > seems that i can use gdal only to convert the gdb file to a SQL
> database.
> > >
> > > So before I start to learn about SQL, I thought I ask if anybody can
> > point
> > > me to a tutorial or similar that explains how to convert the
> > > contents of
> > a
> > > GDB folder to a R-readable format.
> > >
> > > I also wondered if it would be possible to let rgdal know that it
> > > could access the required drivers because I installed them manually.
> > > I would appreciate any hint about this too!
> > >
> > > Thanks in advance!
> > > Best Guido
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Michael Sumner
> > Software and Database Engineer
> > Australian Antarctic Division
> > Hobart, Australia
> > e-mail: mdsumner at gmail.com
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver
> weer en binden het INBO onder geen enkel beding, zolang dit bericht niet
> bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the
> writer and may not be regarded as stating an official position of INBO, as
> long as the message is not confirmed by a duly signed document.
>

	[[alternative HTML version deleted]]


From ripley at stats.ox.ac.uk  Mon Oct 27 10:27:39 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 27 Oct 2014 09:27:39 +0000
Subject: [R] kruskal test p value way too low.
In-Reply-To: <544C889C.6010809@auckland.ac.nz>
References: <CACftpvqXxcHuX_m6H2ZVnNS-5muni51Q3qzTFWg8134HEO9hWA@mail.gmail.com>
	<544C889C.6010809@auckland.ac.nz>
Message-ID: <544E100B.1000108@stats.ox.ac.uk>

On 26/10/2014 05:37, Rolf Turner wrote:
> On 26/10/14 16:40, David Doyle wrote:
>> Hello,
>>
>> I'm trying to run kruskal test on some data but the p values seemed
>> way too
>> low.  So I tried it on some similar data and still got p-value =
>> 1.611e-09.  I'm sure it is a simple mistake but I can't figure it out.
>>
>> Below is my data and code.  Could it be because there are some miss
>> data /
>> NAs in the data set??  If so, could some one point me towards a
>> solution??
>>
>> Thank you for your time.
>> David
>>
>> mydata <-read.csv("http://doylesdartden.com/R/test.csv", sep=",")
>> kruskal.test(mydata, AMMONIA~Well)
>>
>>          Kruskal-Wallis rank sum test
>>
>> data:  mydata
>> Kruskal-Wallis chi-squared = 36.3952, df = 1, p-value = 1.611e-09
>
> Thank you for providing a clear question and an easily reproducible
> example.
>
> The problem is your syntax for the call to the kruskal.test() function.
>
> It should be:
>
>      kruskal.test(AMMONIA ~ Well, data=mydata)
>
> This gives a p-value of 1 (which agrees with wilcox.test); t.test()
> gives a p-value of 0.7958) so harmony is restored to the universe.
>
> IMHO there is a bit of a design flaw in kruskal.test(); it should have
> thrown an error, given your syntax.  The wilcox.test() function *does*

 From the help page

      ## Default S3 method:
      kruskal.test(x, g, ...)

Arguments:

        x: a numeric vector of data values, or a list of numeric data
           vectors.

        g: a vector or factor object giving the group for the
           corresponding elements of ?x?.  Ignored if ?x? is a list.

x was a list, hence g is ignored.  The only thing you can quibble about 
is if the elements of x were 'numeric data vectors': one is a factor and 
it is conventional in R to coerce to the specification, as happened here.

I have added a warning if such coercion is done.


> throw an error.
>
> cheers,
>
> Rolf Turner
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From Matthias.Weber at fntsoftware.com  Mon Oct 27 08:53:51 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Mon, 27 Oct 2014 08:53:51 +0100
Subject: [R] dotplot with library lattice
In-Reply-To: <1709300.gu1B0lVq0c@localhost.localdomain>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
	<707072790.FfmNddDgBm@localhost.localdomain>
	<7E39CF5278A2C948968C39502CF451020174CEADF2D9@mail.ell.fnt.de>
	<1709300.gu1B0lVq0c@localhost.localdomain>
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF2DE@mail.ell.fnt.de>

Hi Jim,

looks perfect to me. Thank you very much. One last question. Is there any possibility to add 3 horizontal lines in the graph. One at 25%, the other one at 50% and the last one at 75%? So I can see the process a bit better?

Thank you.

Best regards.

Mat

-----Urspr?ngliche Nachricht-----
Von: Jim Lemon [mailto:jim at bitwrit.com.au]
Gesendet: Samstag, 25. Oktober 2014 03:27
An: Matthias Weber
Cc: r-help at r-project.org
Betreff: Re: AW: [R] dotplot with library lattice

On Fri, 24 Oct 2014 12:49:39 PM Matthias Weber wrote:
>
> I want always to see the "Process" of the green button in
dependence
> of the blue button at 100%.

Okay.

mwdat<-read.table(text=
"KOST                  Budget        IST
1060                 -2.18          0
1080                  91037.71   91647.15
1100                  955573.87  907938.98
1120                  23326.8          0
1150                 2521.57          0
1180                 51302.03   48760.45
1200                  2027.04    -1667.5
1210                 2385.03    2386.06
1220                       0          0
1250                  528.87          0
1255                 766.54          0
1260                 12154.97    4861.41
Gesamtbudget 1141622.25 1054236.55",
 header=TRUE)
par(las=1,mar=c(5,7,4,6))
plot(rep(100,13),1:13,main="IST against Budget",  xlab="IST/Budget (prozent)",ylab="KOST",
 xlim=c(0,100),type="n",yaxt="n")
abline(h=1:13,lty=2,col="lightgray")
points(rep(100,13),1:13,pch=19,col="blue",cex=3)
mwdat$ISTpct<-100*mwdat$IST/mwdat$Budget
# fix divide by zero
mwdat$ISTpct[9]<-0
points(mwdat$ISTpct,1:13,pch=19,col="green",cex=3)
legend(105,10,c("Budget","IST"),pch=19,
 col=c("blue","green"),bty="n",xpd=TRUE)
axis(2,at=1:13,labels=mwdat$KOST)
par(las=0,mar=c(5,4,4,2))

Jim


This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.


From davidfeitosa at gmail.com  Mon Oct 27 12:42:43 2014
From: davidfeitosa at gmail.com (David Feitosa)
Date: Mon, 27 Oct 2014 08:42:43 -0300
Subject: [R] plot hclust object
Message-ID: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>

Hello!

I have a code that creates an hclust object.
After the object creation I plot the object as a dendrogram,
similar to the left image of this link:

http://www.cs.jhu.edu/~razvanm/fs-expedition/hclust-example.png

I would like to create another image, but similar to the right,
as a set of nested  dots and elipses/circles.

Anybody knows how to do this?

Thanks in advance.

David Feitosa

(\_(\
(=?;?)
(("")("")

	[[alternative HTML version deleted]]


From qiong.cai at gmail.com  Mon Oct 27 13:37:12 2014
From: qiong.cai at gmail.com (Qiong Cai)
Date: Mon, 27 Oct 2014 13:37:12 +0100
Subject: [R] big datasets for R
Message-ID: <CAOrq85HXZxgSuA-zDy5eE30M6QLXUvu8cqTkWBfEwoVBG1A7Ng@mail.gmail.com>

Hi,

Could anyone please tell me where I can find very big datasets for R?  I'd
like to do some benchmarking on R by stressing R a lot.

Thanks
Qiong

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Mon Oct 27 16:05:12 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 27 Oct 2014 08:05:12 -0700
Subject: [R] big datasets for R
In-Reply-To: <CAOrq85HXZxgSuA-zDy5eE30M6QLXUvu8cqTkWBfEwoVBG1A7Ng@mail.gmail.com>
References: <CAOrq85HXZxgSuA-zDy5eE30M6QLXUvu8cqTkWBfEwoVBG1A7Ng@mail.gmail.com>
Message-ID: <4C5B6A47-3EE0-48E8-BC91-8ECA3422C37F@comcast.net>


> On Oct 27, 2014, at 5:37 AM, Qiong Cai <qiong.cai at gmail.com> wrote:
> 
> Hi,
> 
> Could anyone please tell me where I can find very big datasets for R?  I'd
> like to do some benchmarking on R by stressing R a lot.

http://archive.ics.uci.edu/ml/datasets.html?format=&task=&att=&area=&numAtt=&numIns=&type=&sort=instDown&view=table

> 
> Thanks
> Qiong
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From 538280 at gmail.com  Mon Oct 27 19:33:18 2014
From: 538280 at gmail.com (Greg Snow)
Date: Mon, 27 Oct 2014 12:33:18 -0600
Subject: [R] plot hclust object
In-Reply-To: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>
References: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>
Message-ID: <CAFEqCdy6zbhhfFaPrhvaGGu2eQK75JtzYXt-TNavMgWsMZsSyw@mail.gmail.com>

I don't know of any tools that automate this process.  For small
sample sizes it may be easiest to just do this by hand, for large
sample sizes that plot will probably be to complicated to make sense
of.  There may be a range of moderate sample sizes for which
automation (or partial automation) would be helpful.  The hclust
object has a component of "height" which is an indicator of the
distance between 2 components being combined into a cluster, you could
convert this into a distance matrix (or extract the distance matrix
used to do the clustering if it is available) and then use
multidimensional scaling (cmdscale function is one option) to produce
a 2 dimensional set of points.  Drawing the circles/ellipses/ovals
will be more difficult, possibly generate a cloud of normal points, or
a small circle, around each point with the variability/radius low
enough that the clouds are unlikely to overlap, then find the convex
hull (chull function) for the points within a cluster and draw that
(it will be a polygon rather than a smooth curve).  The gBuffer
command in the rgeos package may be another way to create polygons
around the points in a group.

On Mon, Oct 27, 2014 at 5:42 AM, David Feitosa <davidfeitosa at gmail.com> wrote:
> Hello!
>
> I have a code that creates an hclust object.
> After the object creation I plot the object as a dendrogram,
> similar to the left image of this link:
>
> http://www.cs.jhu.edu/~razvanm/fs-expedition/hclust-example.png
>
> I would like to create another image, but similar to the right,
> as a set of nested  dots and elipses/circles.
>
> Anybody knows how to do this?
>
> Thanks in advance.
>
> David Feitosa
>
> (\_(\
> (=?;?)
> (("")("")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From cmora at Dal.Ca  Mon Oct 27 19:42:28 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Mon, 27 Oct 2014 18:42:28 +0000
Subject: [R] "inahull? from package alphahull not working when used with
	lapply
Message-ID: <1414435351211.11127@Dal.Ca>

Hi Bart,

Even after putting the variables in the apply function, the results come not right:

library (alphahull)
DT=data.frame(x=c(0.25,0.25,0.75,0.75),y=c(0.25,0.75,0.75,0.25))
Hull <- ahull(DT, alpha = 0.5)

TEST<- data.frame(x=c(0.25,0.5),y=c(0.5,0.5))
plot(Hull)
points(TEST)

InHul2D <- function(Val1, Val2, Hull) inahull(Hull, p = c(Val1, Val2))

IN <- apply(TEST, 1, function(x,y) InHul2D("x","y",Hull))


	[[alternative HTML version deleted]]


From kasterma at kasterma.net  Mon Oct 27 20:09:43 2014
From: kasterma at kasterma.net (Bart Kastermans)
Date: Mon, 27 Oct 2014 20:09:43 +0100
Subject: [R] "inahull? from package alphahull not working when used with
	lapply
In-Reply-To: <1414435351211.11127@Dal.Ca>
References: <1414435351211.11127@Dal.Ca>
Message-ID: <544E9877.6090804@kasterma.net>

On 27/10/14 19:42, Camilo Mora wrote:
> Hi Bart,
> 
> Even after putting the variables in the apply function, the results come not right:
> 
> library (alphahull)
> DT=data.frame(x=c(0.25,0.25,0.75,0.75),y=c(0.25,0.75,0.75,0.25))
> Hull <- ahull(DT, alpha = 0.5)
> 
> TEST<- data.frame(x=c(0.25,0.5),y=c(0.5,0.5))
> plot(Hull)
> points(TEST)
> 
> InHul2D <- function(Val1, Val2, Hull) inahull(Hull, p = c(Val1, Val2))
> 
> IN <- apply(TEST, 1, function(x,y) InHul2D("x","y",Hull))
> 
> 

Try with this version of your function:

InHul2D <- function(Val1, Val2, Hull) {
    stopifnot(is.numeric(Val1),
              is.numeric(Val2))
    inahull(Hull, p = c(Val1, Val2))
}

And answer the question; why would you put quotes around x and y in
InHul2D call in apply?  Once you remove the quotes, and get the error
"Error: argument "y" is missing, with no default" that I mentioned in my
last email, look at my last email to find out why.

I'll be happy to help you further with this, but then you have to
explain the output you get from using my version of InHul2D (before you
remove the quotes), and why my last email didn't solve the problem after
you removed the quotes.

Check ?stopifnot, and ?is.numeric

Best,
Bart


From dcarlson at tamu.edu  Mon Oct 27 21:35:46 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Mon, 27 Oct 2014 20:35:46 +0000
Subject: [R] "inahull? from package alphahull not working when used
	with	lapply
In-Reply-To: <544E9877.6090804@kasterma.net>
References: <1414435351211.11127@Dal.Ca> <544E9877.6090804@kasterma.net>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FAD447@mb02.ads.tamu.edu>

Why not just

> library (alphahull)
> DT=data.frame(x=c(0.25,0.25,0.75,0.75),y=c(0.25,0.75,0.75,0.25))
> Hull <- ahull(DT, alpha = 0.5)
> TEST<- data.frame(x=c(0.25,0.5),y=c(0.5,0.5))
> apply(TEST, 1, function(x) inahull(Hull, x))
[1] FALSE  TRUE

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Bart Kastermans
Sent: Monday, October 27, 2014 2:10 PM
To: r-help at r-project.org
Subject: Re: [R] "inahull? from package alphahull not working when used with lapply

On 27/10/14 19:42, Camilo Mora wrote:
> Hi Bart,
> 
> Even after putting the variables in the apply function, the results come not right:
> 
> library (alphahull)
> DT=data.frame(x=c(0.25,0.25,0.75,0.75),y=c(0.25,0.75,0.75,0.25))
> Hull <- ahull(DT, alpha = 0.5)
> 
> TEST<- data.frame(x=c(0.25,0.5),y=c(0.5,0.5))
> plot(Hull)
> points(TEST)
> 
> InHul2D <- function(Val1, Val2, Hull) inahull(Hull, p = c(Val1, Val2))
> 
> IN <- apply(TEST, 1, function(x,y) InHul2D("x","y",Hull))
> 
> 

Try with this version of your function:

InHul2D <- function(Val1, Val2, Hull) {
    stopifnot(is.numeric(Val1),
              is.numeric(Val2))
    inahull(Hull, p = c(Val1, Val2))
}

And answer the question; why would you put quotes around x and y in
InHul2D call in apply?  Once you remove the quotes, and get the error
"Error: argument "y" is missing, with no default" that I mentioned in my
last email, look at my last email to find out why.

I'll be happy to help you further with this, but then you have to
explain the output you get from using my version of InHul2D (before you
remove the quotes), and why my last email didn't solve the problem after
you removed the quotes.

Check ?stopifnot, and ?is.numeric

Best,
Bart

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From amandali at uchicago.edu  Mon Oct 27 22:29:22 2014
From: amandali at uchicago.edu (Amanda Li)
Date: Mon, 27 Oct 2014 17:29:22 -0400
Subject: [R] how to define a geometric distribution for "glm"
Message-ID: <CALwvZ4WJB-KVEYTXxHNO=h8UG50rnPKqdKbP9KQvKOwS5aXywg@mail.gmail.com>

Hello,

I was trying to apply "glm" to a dataset that assumes geometric
distribution. I cannot use "glm.nb" in MASS package (negative.binomial (1))
because it tries to estimate this "1" while I am interested in "p", the
probability of success. Does anyone know how I can define a geometric
distribution within "family" so that I can use glm assuming geometric
distribution to estimate "p"?

I am not sure how "quasi" within the family works in this case and I am not
sure whether it can be used to assume geometric distribution.

Thanks in advance for your help! I really appreciate it!
Best regards,
Amanda

	[[alternative HTML version deleted]]


From cmora at Dal.Ca  Mon Oct 27 22:41:05 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Mon, 27 Oct 2014 21:41:05 +0000
Subject: [R] "inahull? from package alphahull not working when used
	with	lapply
In-Reply-To: <53BF8FB63FAF2E4A9455EF1EE94DA726FAD447@mb02.ads.tamu.edu>
References: <1414435351211.11127@Dal.Ca> <544E9877.6090804@kasterma.net>,
	<53BF8FB63FAF2E4A9455EF1EE94DA726FAD447@mb02.ads.tamu.edu>
Message-ID: <1414446061273.87921@Dal.Ca>

Yes, that works. curiously, I tried that initially but it did not work because of the "" around x.
Thank you very much for your help
________________________________________

for future readers inhull can be used with apply using:

library (alphahull)
DT=data.frame(x=c(0.25,0.25,0.75,0.75),y=c(0.25,0.75,0.75,0.25))
Hull <- ahull(DT, alpha = 0.5)
TEST<- data.frame(x=c(0.25,0.5),y=c(0.5,0.5))
sd<-apply(TEST, 1, function(x) inahull(Hull, x))

From pdalgd at gmail.com  Mon Oct 27 23:27:18 2014
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 27 Oct 2014 23:27:18 +0100
Subject: [R] how to define a geometric distribution for "glm"
In-Reply-To: <CALwvZ4WJB-KVEYTXxHNO=h8UG50rnPKqdKbP9KQvKOwS5aXywg@mail.gmail.com>
References: <CALwvZ4WJB-KVEYTXxHNO=h8UG50rnPKqdKbP9KQvKOwS5aXywg@mail.gmail.com>
Message-ID: <915DA65A-A9CB-438D-BD91-1699AF3B1317@gmail.com>

The likelihood for the geometric distribution is the same as for the binomial distribution, except for the constant term, so estimates and LRT will be the same. The properties of the estimator will be different, e.g. the estimate of p is not unbiased, but asymptotically the likelihood procedures should work (asymptotic in this case means a reasonably large total number of both successes and failures, I suppose.) 

So, if your geometric variate is called y, with the R convention of counting the number of failures (not number of experiments), it should work with
	
glm(cbind(1,y) ~ whatever, family="binomial")

[The likelihood equivalence is fairly well-known in statistical theory as a counterargument to the strong likelihood principle that all inference should be based solely on the likelihood function.]

- Peter D.

> On 27 Oct 2014, at 22:29 , Amanda Li <amandali at uchicago.edu> wrote:
> 
> Hello,
> 
> I was trying to apply "glm" to a dataset that assumes geometric
> distribution. I cannot use "glm.nb" in MASS package (negative.binomial (1))
> because it tries to estimate this "1" while I am interested in "p", the
> probability of success. Does anyone know how I can define a geometric
> distribution within "family" so that I can use glm assuming geometric
> distribution to estimate "p"?
> 
> I am not sure how "quasi" within the family works in this case and I am not
> sure whether it can be used to assume geometric distribution.
> 
> Thanks in advance for your help! I really appreciate it!
> Best regards,
> Amanda
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From amandali at uchicago.edu  Mon Oct 27 23:41:38 2014
From: amandali at uchicago.edu (Amanda Li)
Date: Mon, 27 Oct 2014 18:41:38 -0400
Subject: [R] how to define a geometric distribution for "glm"
In-Reply-To: <915DA65A-A9CB-438D-BD91-1699AF3B1317@gmail.com>
References: <CALwvZ4WJB-KVEYTXxHNO=h8UG50rnPKqdKbP9KQvKOwS5aXywg@mail.gmail.com>
	<915DA65A-A9CB-438D-BD91-1699AF3B1317@gmail.com>
Message-ID: <CALwvZ4WUfjLeTFyqbAaCuRwhyGWeQE63NbmXz8f45yifuU6PXw@mail.gmail.com>

Hi Peter,

Thank you very much for your help! However, for my dataset, it may not
asymptotically work. May I ask whether you know how to define a new family?

Thank you very much again!

Best,
Amanda

2014-10-27 18:27 GMT-04:00 peter dalgaard <pdalgd at gmail.com>:

> The likelihood for the geometric distribution is the same as for the
> binomial distribution, except for the constant term, so estimates and LRT
> will be the same. The properties of the estimator will be different, e.g.
> the estimate of p is not unbiased, but asymptotically the likelihood
> procedures should work (asymptotic in this case means a reasonably large
> total number of both successes and failures, I suppose.)
>
> So, if your geometric variate is called y, with the R convention of
> counting the number of failures (not number of experiments), it should work
> with
>
> glm(cbind(1,y) ~ whatever, family="binomial")
>
> [The likelihood equivalence is fairly well-known in statistical theory as
> a counterargument to the strong likelihood principle that all inference
> should be based solely on the likelihood function.]
>
> - Peter D.
>
> > On 27 Oct 2014, at 22:29 , Amanda Li <amandali at uchicago.edu> wrote:
> >
> > Hello,
> >
> > I was trying to apply "glm" to a dataset that assumes geometric
> > distribution. I cannot use "glm.nb" in MASS package (negative.binomial
> (1))
> > because it tries to estimate this "1" while I am interested in "p", the
> > probability of success. Does anyone know how I can define a geometric
> > distribution within "family" so that I can use glm assuming geometric
> > distribution to estimate "p"?
> >
> > I am not sure how "quasi" within the family works in this case and I am
> not
> > sure whether it can be used to assume geometric distribution.
> >
> > Thanks in advance for your help! I really appreciate it!
> > Best regards,
> > Amanda
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From pseo at stanford.edu  Tue Oct 28 01:58:45 2014
From: pseo at stanford.edu (Patricia Seo)
Date: Mon, 27 Oct 2014 17:58:45 -0700 (PDT)
Subject: [R] Loop with ggplot2 not as simple as it seems...
In-Reply-To: <1472164797.1927227.1414456113275.JavaMail.zimbra@stanford.edu>
Message-ID: <1573665279.1951586.1414457925688.JavaMail.zimbra@stanford.edu>

Hi everyone,

I have been battling with this problem for the past month and reading all that I can about it, but I just can't seem to understand what I'm doing wrong. It seems easy and I can replicate others well-recorded attempts, but can not seem to apply this to my data.

I have created a data.frame to easily illustrate my problem. I would like to plot columns 5:7 in my data without having to write-out-every-single-variable name. In this example it is only three columns but in my actual data set it is more like 50 columns. Here is the simplified data frame:

sid <- c(1001:1010) #student id
age <- c(10, 12, 14, 15, 13, 16, 14, 12, 14, 10)
race <- race <- c("w", "b", "a", "w", "a", "w", "b", "a", "w", "a")
gender <- gender <-c("M", "F", "M", "F", "M", "F", "M", "F", "M", "F")
read <- rnorm(10, 100, 50) 
write <- rnorm(10, 100, 50)
math<-rnorm(10, 100, 50)

scores <- data.frame(sid, age, race, gender, read, write, math)

My end goal is to produce a .png like this for every column:

ggplot(scores, aes(x=scores$read, fill=scores$gender)) + geom_density(alpha=.3)

In other words, I would like to write a loop that would produce separate .pngs for each column. No facet-wrap. I would like one plot showing the distribution of one score for male and female in one .png file.

Failed Attempt #1 of 3: My first attempt was to melt data since I know ggplot2 likes melted data. I have tried melting the data using sid, age, race and gender as the id variable. But I?m not sure how to plot what I would like above with just using values. In my actual data set there are over 50 columns to plot (instead of the simple three in the example scores data). I tried creating:

xobject <- subset(scores.melt, variable=read)

but it gives me the error: Don't know how to automatically pick scale for object of type data.frame. Defaulting to continuous
Error: Aesthetics must either be length one, or the same length as the dataProblems:test1

Failed Attempt #2 of 3: My second attempt is below but it had similar problems to what others have mentioned with ggplot changing the names of each plot but keeping the last known data column so all the graphs look the same. It works in terms of titles but not data! And I have tried as_string() but to no avail:

for (i in 5:7) {
  column_to_plot = as.character(paste("Col_", i, sep=""))
  png(paste0("Graph", column_to_plot,".png"))
  ggplot(scores, aes(x=column_to_plot, fill=gender )) + geom_density(alpha=.3)
  ggsave(paste0("Graph", column_to_plot,".png"))
 
}

Failed Attempt #3 of 3: My third attempt is my most successful attempt. It is because I created a vector that includes the list of variables I would like to plot. Unfortunately, I have two problems with this method: (1) Don?t know how to include the corresponding title name so I know which plot corresponds to the score even though I do indicate the names of the Indexes, and (2) It is annoying to have to write the entire list of variables I want to plot especially if there are 50 variable names. I know I can specify columns 5:7 (like above) but I?m not grasping the logics of this loop:

Indexes = list()
Indexes[[1]] = scores$read 
Indexes[[2]] = scores$write
Indexes[[3]] = scores$math

names(Indexes) = c(?Scores for Read?,
                   ?Scores for Write?, ?Scores for Math?)

##### for some reason, I have to run the top half and after it has processed that, run the bottom half#####

for(i in seq(along = Indexes)) { 
  Index = Indexes[[i]] 
  
  for(j in 1:length(gender)) { 
    png(paste0("Graph", Index,".png"))
    ggplot(scores, aes(x=Index, fill = gender)) + geom_density(alpha=.3)
    ggsave(paste0("Graph", Index,".png"))
    
  }
}  

Any help would be much appreciated. I know this is a frankenstein from previous questions and problems with loops in ggplot2, but just understand what I'm doing wrong would even be a huge help.


From kydaviddoyle at gmail.com  Tue Oct 28 02:10:01 2014
From: kydaviddoyle at gmail.com (David Doyle)
Date: Mon, 27 Oct 2014 20:10:01 -0500
Subject: [R] Order of boxs in box plots
Message-ID: <CACftpvoQJiQPy6CcRKOmaHeynEvGVAAac-_B3shfscmF87AKGQ@mail.gmail.com>

Hello,

I'm doing some box plots to look at the distributions of groundwater
results. It is plotting the well in the order of their IDs.  ie. MW1B then
MW3B then MW4A.....

 I would like to plot the wells in the order they are at the site such as MW1B
then WES-14-4-93 then ........  Is there a way I can control that??

My data and code are below.

Thank you for your time
David Doyle


MS <- read.table("http://www.doylesdartden.com/R/MS.csv", header=TRUE,
sep=",",)
MSAmmoniax <- c("Well", "AMMONIA")
MSAmmonia <- MS[MSAmmoniax]

plot(MSAmmonia, notch=TRUE, ylab = "Ammonia (mg/L)", cex =
1,col=(c("green","White","White","white","white","green")))
legend("topleft", inset=.002, title="Gradient",
       c("Up","Down"), fill=terrain.colors(2), horiz=TRUE, cex = 0.7,)
title(main="Lower Mudstone Ammonia Box Plots")

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Oct 28 02:36:49 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 27 Oct 2014 18:36:49 -0700
Subject: [R] Order of boxs in box plots
In-Reply-To: <CACftpvoQJiQPy6CcRKOmaHeynEvGVAAac-_B3shfscmF87AKGQ@mail.gmail.com>
References: <CACftpvoQJiQPy6CcRKOmaHeynEvGVAAac-_B3shfscmF87AKGQ@mail.gmail.com>
Message-ID: <EFFA082B-831D-4209-BFEE-889845DCE881@comcast.net>


On Oct 27, 2014, at 6:10 PM, David Doyle wrote:

> Hello,
> 
> I'm doing some box plots to look at the distributions of groundwater
> results. It is plotting the well in the order of their IDs.  ie. MW1B then
> MW3B then MW4A.....
> 
> I would like to plot the wells in the order they are at the site such as MW1B
> then WES-14-4-93 then ........  Is there a way I can control that??
> 
> My data and code are below.
> 
> Thank you for your time
> David Doyle
> 
> 
> MS <- read.table("http://www.doylesdartden.com/R/MS.csv", header=TRUE,
> sep=",",)
> MSAmmoniax <- c("Well", "AMMONIA")
> MSAmmonia <- MS[MSAmmoniax]
> 

Pretty much all plotting routines (base, lattice, gpplot2)  use the levels as the ordering principle:

levels(MSAmmonia$Well) <- levels(MSAmmonia$Well)[c(1,6,2:5)]


> plot(MSAmmonia, notch=TRUE, ylab = "Ammonia (mg/L)", cex =
> 1,col=(c("green","White","White","white","white","green")))
> legend("topleft", inset=.002, title="Gradient",
>       c("Up","Down"), fill=terrain.colors(2), horiz=TRUE, cex = 0.7,)
> title(main="Lower Mudstone Ammonia Box Plots")


> 	[[alternative HTML version deleted]]
> 
You should learn to post in plain text.

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From stephen.amrock at gmail.com  Mon Oct 27 16:11:18 2014
From: stephen.amrock at gmail.com (Stephen Amrock)
Date: Mon, 27 Oct 2014 11:11:18 -0400
Subject: [R] "survey" package -- doesn't appear to match svy
Message-ID: <CAA3=aowkRva=XkpUwp0e=OPEt5eeu5wyZOYAEFPAF4kc_MsxqA@mail.gmail.com>

Hi,

I'm new to R and have encountered two issues in coding using the "survey"
package:

(1) Code from *svytable* using "survey" package does not correspond to
Stata estimates from *svy: tab*. I call

    svyd.nation <- svydesign(ids = ~1, probs = ~wt_national, strata =
~stratum, data=nats.sub)
    svytable(formula = ~wpev, design = svyd.nation, Ntotal = 100)

where the equivalent Stata would be:

    svyset [pw=wt_national], strata(stratum)
    svy: tab wpev

These are inverse probability weights but Stata and R give different %s for
the tabulations. I know from published results that the Stata code is
correct.  Any ideas as to what I've done incorrectly in R?

(2) Alternative weights---which I've verified in R have the same
distribution as in Stata---produce a strange "inf" output.

    svyd.st <- svydesign(ids = ~1, probs = ~wt_state, strata = ~stratum,
data=nats.sub)
    svytable(~wpev, design = svyd.st, Ntotal=100)

This produces the following output:

    wpev
    0 1

The code
    svytable(~wpev, svyd.st)

produces the output:

    wpev
    0   1
    Inf Inf

Why are these alternative weights -- which work in Stata when resetting
svyset -- not working in R?

Any insights would be much appreciated!! Many thanks!
- S

	[[alternative HTML version deleted]]


From cmora at Dal.Ca  Tue Oct 28 06:38:06 2014
From: cmora at Dal.Ca (Camilo Mora)
Date: Tue, 28 Oct 2014 05:38:06 +0000
Subject: [R] Using a function for rows over a subset of columns in data.table
Message-ID: <1414474688920.13055@Dal.Ca>

Hi everyone,

This may be a trivial solution but I have not been able to figure what is wrong with this code.

The basic premise of the code is to use data.table to append a new column to a data.table that indicates if the values  per row at two other columns are within a 2d hull generated with the package alphahull.

I get the right results when I apply the function to a data.table with only the two columns to consider, But the results are off when I try to apply the same function selecting the two columns from a data.table with numerous columns. I think my problem is how the columns are selected for use in the function. Any help will be much appreciated.

library (alphahull)
library(data.table)

#creates a hull
DT=data.frame(x=c(0.25,0.25,0.75,0.75),y=c(0.25,0.75,0.75,0.25))
Hull <- ahull(DT, alpha = 0.5)

#applying the "inahull" function to a datatable with just the two colunms
TwoColumn<- data.table(x=c(0.25,0.5,0.5,0.5,0),y=c(0.5,0.5,0.5,.5,0))
TwoColumn[, INHULL := apply(TwoColumn, 1, function(x) inahull(Hull, x))]
#the results are correct


#now if I apply the same function to a selection of two  columns  in a data.table with several columns, the codes dies not work
ThreColumn<- data.table(w=c(1,2,3,4,5), z=c(1,2,3,4,5),x=c(0.25,0.5,0.5,0.5,0),y=c(0.5,0.5,0.5,.5,0))
ThreColumn[, INHULL := lapply(.SD, function(x) inahull(Hull, x)), .SDcols=c(x,y)]



	[[alternative HTML version deleted]]


From ajdamico at gmail.com  Tue Oct 28 08:42:13 2014
From: ajdamico at gmail.com (Anthony Damico)
Date: Tue, 28 Oct 2014 03:42:13 -0400
Subject: [R] "survey" package -- doesn't appear to match svy
In-Reply-To: <CAA3=aowkRva=XkpUwp0e=OPEt5eeu5wyZOYAEFPAF4kc_MsxqA@mail.gmail.com>
References: <CAA3=aowkRva=XkpUwp0e=OPEt5eeu5wyZOYAEFPAF4kc_MsxqA@mail.gmail.com>
Message-ID: <CAOwvMDy1z-AYnfFW6VhxJALsyJM1jKiy2W=MmBgGjTdEodysKw@mail.gmail.com>

could you provide a minimal reproducible example?  perhaps use ?dput.


in general the survey package matches all other languages
http://journal.r-project.org/archive/2009-2/RJournal_2009-2_Damico.pdf


here's an example of a minimal reproducible example that does match
http://www.ats.ucla.edu/stat/stata/faq/svy_stata_subpop.htm


library(foreign)
library(survey)
x <- read.dta( "
http://www.ats.ucla.edu/stat/stata/seminars/svy_stata_intro/strsrs.dta" )
y <- svydesign( ~ 1 , strat = ~strat , data = x , weights = ~ pw , fpc =
~fpc )
svytable( ~ yr_rnd , y )
z <- subset( y , yr_rnd == 1 )
svymean( ~ ell , z )



there are lots of examples of R matching official published statistics
(often computed with stata) here--
https://github.com/ajdamico/usgsd/search?utf8=%E2%9C%93&q=replication





On Mon, Oct 27, 2014 at 11:11 AM, Stephen Amrock <stephen.amrock at gmail.com>
wrote:

> Hi,
>
> I'm new to R and have encountered two issues in coding using the "survey"
> package:
>
> (1) Code from *svytable* using "survey" package does not correspond to
> Stata estimates from *svy: tab*. I call
>
>     svyd.nation <- svydesign(ids = ~1, probs = ~wt_national, strata =
> ~stratum, data=nats.sub)
>     svytable(formula = ~wpev, design = svyd.nation, Ntotal = 100)
>
> where the equivalent Stata would be:
>
>     svyset [pw=wt_national], strata(stratum)
>     svy: tab wpev
>
> These are inverse probability weights but Stata and R give different %s for
> the tabulations. I know from published results that the Stata code is
> correct.  Any ideas as to what I've done incorrectly in R?
>
> (2) Alternative weights---which I've verified in R have the same
> distribution as in Stata---produce a strange "inf" output.
>
>     svyd.st <- svydesign(ids = ~1, probs = ~wt_state, strata = ~stratum,
> data=nats.sub)
>     svytable(~wpev, design = svyd.st, Ntotal=100)
>
> This produces the following output:
>
>     wpev
>     0 1
>
> The code
>     svytable(~wpev, svyd.st)
>
> produces the output:
>
>     wpev
>     0   1
>     Inf Inf
>
> Why are these alternative weights -- which work in Stata when resetting
> svyset -- not working in R?
>
> Any insights would be much appreciated!! Many thanks!
> - S
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Oct 28 11:05:57 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Oct 2014 11:05:57 +0100
Subject: [R] Trace of product of matrices
In-Reply-To: <48CBE996-7F4C-41E9-AEB5-8F03C04919EE@gmail.com>
References: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
	<06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
	<5443EE41.5080302@structuremonitoring.com>
	<48CBE996-7F4C-41E9-AEB5-8F03C04919EE@gmail.com>
Message-ID: <21583.27269.378313.909231@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Sun, 19 Oct 2014 21:26:39 +0200 writes:

    >> On 19 Oct 2014, at 19:00 , Spencer Graves <spencer.graves at structuremonitoring.com> wrote:
    >> 
    >> On 10/19/2014 8:42 AM, peter dalgaard wrote:
    >>>> On 19 Oct 2014, at 16:43 , Wagner Bonat <wbonat at gmail.com> wrote:
    >>>> 
    >>>> Dear,
    >>>> 
    >>>> I have to compute the trace of a product between four matrices. For
    >>>> example, I know the matrices Wi, Wj and C, I need to compute this
    >>>> 
    >>>> -trace(Wi%*%C^-1%*%Wj%*%C^-1)
    >>>> 
    >>>> 
    >>>> I would like to avoid compute the complete matrix and after take the
    >>>> diagonal, something like
    >>>> 
    >>>> sum(diag( solve(Wi,C)%*% solve(Wj,C)))
    >>> <this can't be right: it is C that is the invertible matrix>
    >>> 
    >>>> Any idea is welcome.
    >>>> 
    >>> The usual "trick" is that the trace of a matrix product is the inner product in matrix space, which is just the sum of the  elementwise products
    >>> 
    >>> tr(AB) = tr(BA) = sum_i sum_j a_ij b_ij.
    >>> 
    >>> In R, this becomes simply sum(A*B) -- notice that the ordinary product is used, not %*%. So presumably, you are looking for
    >>> 
    >>> sum(solve(C, Wi) * solve(C, Wj))
    >> 
    >> missing a transpose?

    > Yep... 

    > tr(AB) = tr(BA) = sum_i sum_j a_ij b_ji

    > which is of course sum(A*t(B)) or vice versa. Thanks.

Thank you, Peter, and Spencer.

For a few years now, I have had in my TODO file for the Matrix
package:

** TODO tr(A %*% B) {and even  tr(A %*% B %*% C) ...} are also needed
  frequently in some computations {conditional normal distr. ...}.
  Since this can be done faster than by
    sum(diag(A %*% B))  even for traditional matrices, e.g.
    	       sum(A * t(B)) or {even faster for "full" mat}
	       crossprod(as.vector(A), as.vector(B))
  and even more so for, e.g.  <sparse> %*% <dense>
  {used in Soeren's 'gR' computations},
  we should also provide a generic and methods.

** TODO diag(A %*% B) might look like a "generalization" of tr(A %*% B),
  but as the above tricks show, is not really.
  Still, it's well worth to provide  diag.prod(A, B):

  Well, if A %*% B is square,   diag(A %*% B)  ===  colSums(t(A) * B)
  and we should probably teach people about that !

-----------

Are there good suggestions for a sensible function name for
these potential matrix utility function?

  trprod()
  traceprod()

  diagprod()
?

--
Martin <Maechler at stat.math.ethz.ch>  http://stat.ethz.ch/people/maechler
Seminar f?r Statistik, ETH Z?rich  HG G 16      R?mistrasse 101
CH-8092 Zurich, SWITZERLAND
phone: +41-44-632-3408       fax: ...-1228      <><


From chirleu at gmail.com  Tue Oct 28 11:25:41 2014
From: chirleu at gmail.com (=?UTF-8?Q?David_Villegas_R=C3=ADos?=)
Date: Tue, 28 Oct 2014 11:25:41 +0100
Subject: [R] how to structure data to use a cengaussian/cenpoisson
	distribution in MCMCglmm
Message-ID: <CALC46t-5Nd8F4-ipHfPCzax8dt5AWG480xZs-jLjmAD3t3zQyQ@mail.gmail.com>

Hi.
I was wondering how data has to be structured in the database to be able to
run a mixed-model with the MCMCglmm funcion using censored family
distributions, like "cengaussian" or "cenpoisson". I know my response
variable should have two columns, but can anyone provide an example of
this? In my particular case, I'll work with right censored data, so data
are censored at 1200 seconds.

Thank you in advance.

David

	[[alternative HTML version deleted]]


From bhh at xs4all.nl  Tue Oct 28 11:38:29 2014
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 28 Oct 2014 11:38:29 +0100
Subject: [R] Trace of product of matrices
In-Reply-To: <21583.27269.378313.909231@stat.math.ethz.ch>
References: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
	<06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
	<5443EE41.5080302@structuremonitoring.com>
	<48CBE996-7F4C-41E9-AEB5-8F03C04919EE@gmail.com>
	<21583.27269.378313.909231@stat.math.ethz.ch>
Message-ID: <83353E53-A99B-46D6-8A31-E7669B8A65F8@xs4all.nl>


On 28-10-2014, at 11:05, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> ?...
> Thank you, Peter, and Spencer.
> 
> For a few years now, I have had in my TODO file for the Matrix
> package:
> 
> ** TODO tr(A %*% B) {and even  tr(A %*% B %*% C) ...} are also needed
>  frequently in some computations {conditional normal distr. ...}.
>  Since this can be done faster than by
>    sum(diag(A %*% B))  even for traditional matrices, e.g.
>    	       sum(A * t(B)) or {even faster for "full" mat}
> 	       crossprod(as.vector(A), as.vector(B))


Shouldn?t that be  crossprod(as.vector(t(A)),as.vector(B)) or crossprod(as.vector(A),as.vector(t(B))) ?

Berend

>  and even more so for, e.g.  <sparse> %*% <dense>
>  {used in Soeren's 'gR' computations},
>  we should also provide a generic and methods.
> 
> ** TODO diag(A %*% B) might look like a "generalization" of tr(A %*% B),
>  but as the above tricks show, is not really.
>  Still, it's well worth to provide  diag.prod(A, B):
> 
>  Well, if A %*% B is square,   diag(A %*% B)  ===  colSums(t(A) * B)
>  and we should probably teach people about that !
> 
> -----------
> 
> Are there good suggestions for a sensible function name for
> these potential matrix utility function?
> 
>  trprod()
>  traceprod()
> 
>  diagprod()
> ?
> 
> --
> Martin <Maechler at stat.math.ethz.ch>  http://stat.ethz.ch/people/maechler
> Seminar f?r Statistik, ETH Z?rich  HG G 16      R?mistrasse 101
> CH-8092 Zurich, SWITZERLAND
> phone: +41-44-632-3408       fax: ...-1228      <><
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ntfredo at gmail.com  Tue Oct 28 13:40:41 2014
From: ntfredo at gmail.com (Frederic Ntirenganya)
Date: Tue, 28 Oct 2014 15:40:41 +0300
Subject: [R] Putting R script in a function.
Message-ID: <CAGh51gS5pZA+KvCHdjaLx7zki560s7WfDJJDn32iMwwbQqhAvg@mail.gmail.com>

Hi All,

I wrote this script to calculate the water balance using the following
formula:
Water_Balance = Water_Balance yesterday + Rainfall - Evaporation.

The code works well and I want to put into a function.

conditions: Water_Balance<0 is equal to 0.
                 Water_Balance>100 is equal to 100.

Any idea on how I can make it us a function is welcome.


# Adding a new column for water balance to the data frame and evaporation
Samsmall$Water_Balance <- NA
Samsmall$Evaporation<-5
# initialization
Samsmall$Water_Balance[1]=0
# loop for calculating water balance for a given dataset
ndays <- nrow(Samsmall)
for (iday in 2:ndays) {
  Samsmall$Water_Balance[iday] <- Samsmall$Water_Balance[iday-1] +
Samsmall$Rain[iday] - Samsmall$Evaporation[iday]
  if (Samsmall$Water_Balance[iday]<0){
    Samsmall$Water_Balance[iday]=0
  }else if(Samsmall$Water_Balance[iday]>100){
    Samsmall$Water_Balance[iday]=100
  }
}
## Table of water balance for a specific year.
require(reshape2)
samsmall30<-subset(Samsmall,Year==1930)
attach(samsmall30)
#produce table with data
sam30<-dcast(samsmall30,Day~Month,value.var="Water_Balance")
#add column names as months
colnames(sam30)[2:13]<-month.abb[1:12]


Regards,
Frederic.

	[[alternative HTML version deleted]]


From gildas.mazo at inria.fr  Tue Oct 28 11:23:45 2014
From: gildas.mazo at inria.fr (Gildas Mazo)
Date: Tue, 28 Oct 2014 11:23:45 +0100
Subject: [R] Nonparametric Estimation of Tail Dependence Coefficients
Message-ID: <544F6EB1.70702@inria.fr>

Dear all,

in which package can I find an implementation of the nonparametric 
estimation of tail dependence coefficients:
lambda_L = lim_{u\to 0} P[F_1(X_1)<u|F_2(X_2)<u]
lambda_U = lim_{u\to 1} P[F_1(X_1)>u|F_2(X_2)>u],
where (X_1,X_2) has marginal distribution functions F_1 and F_2?

(The nonparametric estimators typically require to choose a tuning 
parameter, often called 'k', which can be automated by using a 'plateau 
finding' algorithm, which I would like to be implemented as well).

Thank you very much for your help,
Gildas


From erasmo.papagni at gmail.com  Tue Oct 28 11:36:44 2014
From: erasmo.papagni at gmail.com (Erasmo Papagni)
Date: Tue, 28 Oct 2014 11:36:44 +0100
Subject: [R] breakpoints
Message-ID: <544F71BC.9030802@unina2.it>

Hello,

Using the package strucchange to implement Bai-Perron methods I found 
that sometimes intervals between 2 break dates are exactly equal

to the  minimum that I set in the command "breakpoints". I think this is 
a problem and a signal of possible different breaks with a trimming 
value lower

than the one I specified. This case arises in Bai-Perron 2003 when they 
apply their methodology to the Phillips curve: the distance between the 
dates

1967 and 1975 is 8 years, and is equal to the minimum allowed.

Thanks a lot

Erasmo Papagni

Departemnt of Economics
University of Naples II


From tramni at abv.bg  Tue Oct 28 14:08:31 2014
From: tramni at abv.bg (Martin Ivanov)
Date: Tue, 28 Oct 2014 15:08:31 +0200 (EET)
Subject: [R] spectral coherence & non-overlapping windows: confidence
	intervals?
Message-ID: <490961565.28383.1414501711565.JavaMail.apache@nm52.abv.bg>

Dear R users,

The confidence intervals for the squared coherence and phase, plotted by plot.spec.coherence() and plot.spec.phase, respectively,
use the formulae 10.14 and 10.11 from Bloomfield, P. (1976) Fourier Analysis of Time Series: An Introduction. Wiley:

gg <- 2/x$df
se <- sqrt(gg/2)
?z <- -qnorm((1 - ci)/2)
coh <- sqrt(x$coh);
(tanh(atanh(coh) + z * se))^2; # this is the 95% line for the coherence
cl <- asin(pmin(0.9999, qt(ci, 2/gg - 2) * sqrt(gg *? (coh^{ -2 } - 1)/(2 * (1 - gg))))); # this is for the phase

Does somebody know how these formulae extend in case of calculating the cross-spectrum via 
K non-overlapping windows, i.e. via the Welch method? I would be very thankful if you could direct 
me to some literature. I tried finding something on the topic myself, but the information is only
for the case when one smooths with spectral windows.

Best regards,
Martin


From Achim.Zeileis at uibk.ac.at  Tue Oct 28 14:08:28 2014
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 28 Oct 2014 14:08:28 +0100 (CET)
Subject: [R] breakpoints
In-Reply-To: <544F71BC.9030802@unina2.it>
References: <544F71BC.9030802@unina2.it>
Message-ID: <alpine.DEB.2.11.1410281403250.31052@paninaro.uibk.ac.at>

On Tue, 28 Oct 2014, Erasmo Papagni wrote:

> Hello,
>
> Using the package strucchange to implement Bai-Perron methods I found 
> that sometimes intervals between 2 break dates are exactly equal to the 
> minimum that I set in the command "breakpoints". I think this is a 
> problem and a signal of possible different breaks with a trimming value 
> lower than the one I specified.

Yes, that's possible. You can easily explore, though, how the results 
change if you require a smaller minimal segment size. The idea is that the 
minimal segment size needs to be big enough to lead to reliable parameter 
estimates but small enough to be below the smalles true segment size. 
Then, if the minimal segment size is neither too small or too large, then 
the results shouldn't be affected (much) by the precise value of the 
minal segment size.

> This case arises in Bai-Perron 2003 when they apply their methodology to 
> the Phillips curve: the distance between the dates 1967 and 1975 is 8 
> years, and is equal to the minimum allowed.

Yes, however in help("PhillipsCurve", package = "strucchange") we also 
explore some additional specifications with a smaller value which still 
yields the same breakpoints.

However, I think that this particular data set and model are not bad but 
it's probably fair to say that they are not the most convincing case for 
structural change techniques either.

Best,
Z

> Thanks a lot
>
> Erasmo Papagni
>
> Departemnt of Economics
> University of Naples II
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From maechler at stat.math.ethz.ch  Tue Oct 28 16:18:29 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Oct 2014 16:18:29 +0100
Subject: [R] Trace of product of matrices
In-Reply-To: <83353E53-A99B-46D6-8A31-E7669B8A65F8@xs4all.nl>
References: <CANt=4MhSYjchVuH8gNz6FhMgW8hiU-PXJAvgHLtVnQA69f6Fqg@mail.gmail.com>
	<06F08DF4-81FF-4419-A352-F9A513F31E8D@gmail.com>
	<5443EE41.5080302@structuremonitoring.com>
	<48CBE996-7F4C-41E9-AEB5-8F03C04919EE@gmail.com>
	<21583.27269.378313.909231@stat.math.ethz.ch>
	<83353E53-A99B-46D6-8A31-E7669B8A65F8@xs4all.nl>
Message-ID: <21583.46021.363873.28382@stat.math.ethz.ch>

>>>>> Berend Hasselman <bhh at xs4all.nl>
>>>>>     on Tue, 28 Oct 2014 11:38:29 +0100 writes:

    > On 28-10-2014, at 11:05, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

    >> ?...
    >> Thank you, Peter, and Spencer.
    >> 
    >> For a few years now, I have had in my TODO file for the Matrix
    >> package:
    >> 
    >> ** TODO tr(A %*% B) {and even  tr(A %*% B %*% C) ...} are also needed
    >> frequently in some computations {conditional normal distr. ...}.
    >> Since this can be done faster than by
    >> sum(diag(A %*% B))  even for traditional matrices, e.g.
    >> sum(A * t(B)) or {even faster for "full" mat}
    >> crossprod(as.vector(A), as.vector(B))


    > Shouldn?t that be  crossprod(as.vector(t(A)),as.vector(B)) or crossprod(as.vector(A),as.vector(t(B))) ?

    > Berend

yes, of course;  thanks for catching that!

Martin


    >> and even more so for, e.g.  <sparse> %*% <dense>
    >> {used in Soeren's 'gR' computations},
    >> we should also provide a generic and methods.
    >> 
    >> ** TODO diag(A %*% B) might look like a "generalization" of tr(A %*% B),
    >> but as the above tricks show, is not really.
    >> Still, it's well worth to provide  diag.prod(A, B):
    >> 
    >> Well, if A %*% B is square,   diag(A %*% B)  ===  colSums(t(A) * B)
    >> and we should probably teach people about that !
    >> 
    >> -----------
    >> 
    >> Are there good suggestions for a sensible function name for
    >> these potential matrix utility function?
    >> 
    >> trprod()
    >> traceprod()
    >> 
    >> diagprod()
    >> ?
    >> 
    >> --
    >> Martin <Maechler at stat.math.ethz.ch>  http://stat.ethz.ch/people/maechler
    >> Seminar f?r Statistik, ETH Z?rich  HG G 16      R?mistrasse 101
    >> CH-8092 Zurich, SWITZERLAND
    >> phone: +41-44-632-3408       fax: ...-1228      <><
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.


From maechler at stat.math.ethz.ch  Tue Oct 28 16:31:50 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Oct 2014 16:31:50 +0100
Subject: [R] plot hclust object
In-Reply-To: <CAFEqCdy6zbhhfFaPrhvaGGu2eQK75JtzYXt-TNavMgWsMZsSyw@mail.gmail.com>
References: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>
	<CAFEqCdy6zbhhfFaPrhvaGGu2eQK75JtzYXt-TNavMgWsMZsSyw@mail.gmail.com>
Message-ID: <21583.46822.302622.792661@stat.math.ethz.ch>

>>>>> Greg Snow <538280 at gmail.com>
>>>>>     on Mon, 27 Oct 2014 12:33:18 -0600 writes:

    > I don't know of any tools that automate this process.  For small
    > sample sizes it may be easiest to just do this by hand, for large
    > sample sizes that plot will probably be to complicated to make sense
    > of.  There may be a range of moderate sample sizes for which
    > automation (or partial automation) would be helpful.  The hclust
    > object has a component of "height" which is an indicator of the
    > distance between 2 components being combined into a cluster, you could
    > convert this into a distance matrix 

it has been known for many years how to do this; still, I have
only learned about it from Robert Gentleman (yes, one of the two
fathers of R), when we added the function 

	cophenetic() 
to R
which does exactly do this: 
Provide the distance matrix which is implicitly defined by a
hierarchical clustering.

Martin Maechler, ETH Zurich

    > (or extract the distance matrix used to do the clustering
    > if it is available) and then use multidimensional scaling
    > (cmdscale function is one option) to produce a 2
    > dimensional set of points.  Drawing the
    > circles/ellipses/ovals will be more difficult, possibly
    > generate a cloud of normal points, or a small circle,
    > around each point with the variability/radius low enough
    > that the clouds are unlikely to overlap, then find the
    > convex hull (chull function) for the points within a
    > cluster and draw that (it will be a polygon rather than a
    > smooth curve).  The gBuffer command in the rgeos package
    > may be another way to create polygons around the points in
    > a group.

    > On Mon, Oct 27, 2014 at 5:42 AM, David Feitosa <davidfeitosa at gmail.com> wrote:
    >> Hello!
    >> 
    >> I have a code that creates an hclust object.
    >> After the object creation I plot the object as a dendrogram,
    >> similar to the left image of this link:
    >> 
    >> http://www.cs.jhu.edu/~razvanm/fs-expedition/hclust-example.png
    >> 
    >> I would like to create another image, but similar to the right,
    >> as a set of nested  dots and elipses/circles.
    >> 
    >> Anybody knows how to do this?
    >> 
    >> Thanks in advance.
    >> 
    >> David Feitosa
    >> 
    >> (\_(\
    >> (=?;?)
    >> (("")("")
    >> 
    >> [[alternative HTML version deleted]]
    >> 
    >> ______________________________________________
    >> R-help at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> and provide commented, minimal, self-contained, reproducible code.



    > -- 
    > Gregory (Greg) L. Snow Ph.D.
    > 538280 at gmail.com

    > ______________________________________________
    > R-help at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From friendly at yorku.ca  Tue Oct 28 16:47:05 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 28 Oct 2014 11:47:05 -0400
Subject: [R] merge coefficients from a glmlist of models
Message-ID: <544FBA79.7060104@yorku.ca>

In the vcdExtra package, I have a function glmlist to collect a set of 
glm() models as a "glmlist" object,
and other functions that generate & fit such a collection of models.

This is my working example, fitting a set of models to the Donner data

# install.packages("vcdExtra", repos="http://R-Forge.R-project.org")# 
needs devel version
data("Donner", package="vcdExtra")
# make survived a factor
Donner$survived <- factor(Donner$survived, labels=c("no", "yes"))
Donner$family.size <- ave(as.numeric(Donner$family), Donner$family, 
FUN=length)
# collapse small families into "Other"
fam <- Donner$family
levels(fam)[c(3,4,6,7,9)] <- "Other"
# reorder, putting Other last
fam = factor(fam,levels(fam)[c(1, 2, 4:6, 3)])
Donner$family <- fam

# fit models
donner.mod0 <- glm(survived ~ age, data=Donner, family=binomial)
donner.mod1 <- glm(survived ~ age + sex, data=Donner, family=binomial)
donner.mod2 <- glm(survived ~ age * sex , data=Donner, family=binomial)
donner.mod3 <- glm(survived ~ poly(age,2) + sex, data=Donner, 
family=binomial)
donner.mod4 <- glm(survived ~ poly(age,2) * sex, data=Donner, 
family=binomial)
mods <- glmlist(donner.mod1, donner.mod2, donner.mod3, donner.mod4)

I'd like to write other methods for handling a glmlist, similar to the 
way stats::anova.glmlist works, e.g.,

 > library(vcdExtra)
 > mods <- glmlist(donner.mod1, donner.mod2, donner.mod3, donner.mod4)
 >
 > anova(mods, test="Chisq")
Analysis of Deviance Table

Model 1: survived ~ age + sex
Model 2: survived ~ age * sex
Model 3: survived ~ poly(age, 2) + sex
Model 4: survived ~ poly(age, 2) * sex
Resid. Df Resid. Dev Df Deviance Pr(>Chi)
1 87 111.128
2 86 110.727 1 0.4003 0.52692
3 86 106.731 0 3.9958
4 84 97.799 2 8.9321 0.01149 *
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

# gives same result as anova() with an explicit list of models:

 > anova(donner.mod1, donner.mod2, donner.mod3, donner.mod4, test="Chisq")
Analysis of Deviance Table

Model 1: survived ~ age + sex
Model 2: survived ~ age * sex
Model 3: survived ~ poly(age, 2) + sex
Model 4: survived ~ poly(age, 2) * sex
Resid. Df Resid. Dev Df Deviance Pr(>Chi)
1 87 111.128
2 86 110.727 1 0.4003 0.52692
3 86 106.731 0 3.9958
4 84 97.799 2 8.9321 0.01149 *
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Then, using the function vcdExtra::Summarise, I can define a 
Summarise.glmlist method that is essentially

sumry <- lapply(mods, Summarise)
do.call(rbind, sumry)

 > Summarise(mods)# not yet added to the package
Likelihood summary table:
AIC BIC LR Chisq Df Pr(>Chisq)
donner.mod1 117.13 124.63 111.128 87 0.04159 *
donner.mod2 118.73 128.73 110.727 86 0.03755 *
donner.mod3 114.73 124.73 106.731 86 0.06439 .
donner.mod4 109.80 124.80 97.799 84 0.14408
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Similarly, I can define a residuals.glmlist method, using using cbind() 
to collect the residuals from all
models.
But I'm stumped on a coef() method, because the coefficients fitted in 
various models
differ.

 > coefs <- lapply(mods, "coef")
 > coefs
$donner.mod1
(Intercept) age sexMale
1.59915455 -0.03379836 -1.20678665

$donner.mod2
(Intercept) age sexMale age:sexMale
1.85514867 -0.04565225 -1.62177307 0.01957257

$donner.mod3
(Intercept) poly(age, 2)1 poly(age, 2)2 sexMale
0.8792031 -7.9366059 -6.6929413 -1.3745016

$donner.mod4
(Intercept) poly(age, 2)1 poly(age, 2)2 sexMale
0.7621901 -26.9688970 -30.5626032 -1.0995718
poly(age, 2)1:sexMale poly(age, 2)2:sexMale
22.7210591 28.8975876

The result I want is a data.frame with columns corresponding to the 
models, and rows corresponding
to the unique coefficient names, with NA filled in where a term is missing.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From Pradip.Muhuri at samhsa.hhs.gov  Tue Oct 28 16:44:26 2014
From: Pradip.Muhuri at samhsa.hhs.gov (Muhuri, Pradip (SAMHSA/CBHSQ))
Date: Tue, 28 Oct 2014 15:44:26 +0000
Subject: [R] Adding  labels to ColSums
Message-ID: <E18C153EBB81024CB60FCE9B4C34D57C37F4D3B2@pl-emsmb11>

Hello,

I was trying to add labels to the colSums  of the  "integers" variable corresponding to a "factor".  Below are the  warning message and the reproducible code.  How would I tweak the code to replace the "NA" with the "Total" in the output?  Your advice toward resolving the issue would be greatly appreciated.

Thanks,

Pradip Muhuri



###################  warning message - from the console  ############################
rb.data <- rbind(s.data2, c("Total", colSums(s.data2[,2, drop=FALSE]))) # row bind with the column total

Warning message:
In `[<-.factor`(`*tmp*`, ri, value = "Total") :
  invalid factor level, NA generated
> rb.data
Source: local data frame [7 x 2]

  years.before.initiated.cat anl.count
1                      [0,1]        89
2                      (1,2]        73
3                      (2,3]        72
4                      (3,4]        82
5                      (4,5]        82
6                      (5,6]        86
7                         NA       484
#########################  reproducible code #################################################
library(dplyr)

i.data2 <- data.frame(sample(1:6, size=484, replace=T)) # simulate data to create a data frame
colnames(i.data2) <- "years.before.initiated" # add a column name
                      
m.data2 <- mutate(i.data2,  years.before.initiated.cat = 
                    cut(years.before.initiated, breaks=c(0,1,2,3,4,5,6),include.lowest=TRUE))
                        # create a new variable

g.data2 <- group_by(m.data2, years.before.initiated.cat) # group by years.before.initiated.cat
s.data2 <- summarise(g.data2, anl.count =n() ) # summarize to get the count

rb.data <- rbind(s.data2, c("Total", colSums(s.data2[,2, drop=FALSE]))) # row bind with the column total
rb.data
###########################################################################################

Pradip K. Muhuri, PhD
SAMHSA/CBHSQ
1 Choke Cherry Road, Room 2-1071
Rockville, MD 20857
Tel: 240-276-1070
Fax: 240-276-1260
ommented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Tue Oct 28 17:13:04 2014
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 28 Oct 2014 12:13:04 -0400
Subject: [R] merge coefficients from a glmlist of models
In-Reply-To: <544FBA79.7060104@yorku.ca>
References: <544FBA79.7060104@yorku.ca>
Message-ID: <002d01cff2ca$0ddd8290$299887b0$@mcmaster.ca>

Hi Michael,

How about this?


coef.glmlist <- function(object, result=c("list", "matrix", "data.frame"),
...){
    result <- match.arg(result)
    coefs <- lapply(object, coef)
    if (result == "list") return(coefs)
    coef.names <- unique(unlist(lapply(coefs, names)))
    n.mods <- length(object)
    coef.matrix <- matrix(NA, length(coef.names), n.mods)
    rownames(coef.matrix) <- coef.names
    colnames(coef.matrix) <- names(object)
    for (i in 1:n.mods){
        coef <- coef(object[[i]])
        coef.matrix[names(coef), i] <- coef
    }
    if (result == "matrix") return(coef.matrix)
    as.data.frame(coef.matrix)
}

> coef(mods, result="data.frame")
                      donner.mod1 donner.mod2 donner.mod3 donner.mod4
(Intercept)            1.59915455  1.85514867   0.8792031   0.7621901
age                   -0.03379836 -0.04565225          NA          NA
sexMale               -1.20678665 -1.62177307  -1.3745016  -1.0995718
age:sexMale                    NA  0.01957257          NA          NA
poly(age, 2)1                  NA          NA  -7.9366059 -26.9688970
poly(age, 2)2                  NA          NA  -6.6929413 -30.5626032
poly(age, 2)1:sexMale          NA          NA          NA  22.7210591
poly(age, 2)2:sexMale          NA          NA          NA  28.8975876

Best,
 John

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Michael Friendly
> Sent: Tuesday, October 28, 2014 11:47 AM
> To: R-help
> Subject: [R] merge coefficients from a glmlist of models
> 
> In the vcdExtra package, I have a function glmlist to collect a set of
> glm() models as a "glmlist" object,
> and other functions that generate & fit such a collection of models.
> 
> This is my working example, fitting a set of models to the Donner data
> 
> # install.packages("vcdExtra", repos="http://R-Forge.R-project.org")#
> needs devel version
> data("Donner", package="vcdExtra")
> # make survived a factor
> Donner$survived <- factor(Donner$survived, labels=c("no", "yes"))
> Donner$family.size <- ave(as.numeric(Donner$family), Donner$family,
> FUN=length)
> # collapse small families into "Other"
> fam <- Donner$family
> levels(fam)[c(3,4,6,7,9)] <- "Other"
> # reorder, putting Other last
> fam = factor(fam,levels(fam)[c(1, 2, 4:6, 3)])
> Donner$family <- fam
> 
> # fit models
> donner.mod0 <- glm(survived ~ age, data=Donner, family=binomial)
> donner.mod1 <- glm(survived ~ age + sex, data=Donner, family=binomial)
> donner.mod2 <- glm(survived ~ age * sex , data=Donner, family=binomial)
> donner.mod3 <- glm(survived ~ poly(age,2) + sex, data=Donner,
> family=binomial)
> donner.mod4 <- glm(survived ~ poly(age,2) * sex, data=Donner,
> family=binomial)
> mods <- glmlist(donner.mod1, donner.mod2, donner.mod3, donner.mod4)
> 
> I'd like to write other methods for handling a glmlist, similar to the
> way stats::anova.glmlist works, e.g.,
> 
>  > library(vcdExtra)
>  > mods <- glmlist(donner.mod1, donner.mod2, donner.mod3, donner.mod4)
>  >
>  > anova(mods, test="Chisq")
> Analysis of Deviance Table
> 
> Model 1: survived ~ age + sex
> Model 2: survived ~ age * sex
> Model 3: survived ~ poly(age, 2) + sex
> Model 4: survived ~ poly(age, 2) * sex
> Resid. Df Resid. Dev Df Deviance Pr(>Chi)
> 1 87 111.128
> 2 86 110.727 1 0.4003 0.52692
> 3 86 106.731 0 3.9958
> 4 84 97.799 2 8.9321 0.01149 *
> ---
> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> # gives same result as anova() with an explicit list of models:
> 
>  > anova(donner.mod1, donner.mod2, donner.mod3, donner.mod4,
> test="Chisq")
> Analysis of Deviance Table
> 
> Model 1: survived ~ age + sex
> Model 2: survived ~ age * sex
> Model 3: survived ~ poly(age, 2) + sex
> Model 4: survived ~ poly(age, 2) * sex
> Resid. Df Resid. Dev Df Deviance Pr(>Chi)
> 1 87 111.128
> 2 86 110.727 1 0.4003 0.52692
> 3 86 106.731 0 3.9958
> 4 84 97.799 2 8.9321 0.01149 *
> ---
> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Then, using the function vcdExtra::Summarise, I can define a
> Summarise.glmlist method that is essentially
> 
> sumry <- lapply(mods, Summarise)
> do.call(rbind, sumry)
> 
>  > Summarise(mods)# not yet added to the package
> Likelihood summary table:
> AIC BIC LR Chisq Df Pr(>Chisq)
> donner.mod1 117.13 124.63 111.128 87 0.04159 *
> donner.mod2 118.73 128.73 110.727 86 0.03755 *
> donner.mod3 114.73 124.73 106.731 86 0.06439 .
> donner.mod4 109.80 124.80 97.799 84 0.14408
> ---
> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> Similarly, I can define a residuals.glmlist method, using using cbind()
> to collect the residuals from all
> models.
> But I'm stumped on a coef() method, because the coefficients fitted in
> various models
> differ.
> 
>  > coefs <- lapply(mods, "coef")
>  > coefs
> $donner.mod1
> (Intercept) age sexMale
> 1.59915455 -0.03379836 -1.20678665
> 
> $donner.mod2
> (Intercept) age sexMale age:sexMale
> 1.85514867 -0.04565225 -1.62177307 0.01957257
> 
> $donner.mod3
> (Intercept) poly(age, 2)1 poly(age, 2)2 sexMale
> 0.8792031 -7.9366059 -6.6929413 -1.3745016
> 
> $donner.mod4
> (Intercept) poly(age, 2)1 poly(age, 2)2 sexMale
> 0.7621901 -26.9688970 -30.5626032 -1.0995718
> poly(age, 2)1:sexMale poly(age, 2)2:sexMale
> 22.7210591 28.8975876
> 
> The result I want is a data.frame with columns corresponding to the
> models, and rows corresponding
> to the unique coefficient names, with NA filled in where a term is
> missing.
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Tue Oct 28 17:31:27 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 28 Oct 2014 10:31:27 -0600
Subject: [R] plot hclust object
In-Reply-To: <21583.46822.302622.792661@stat.math.ethz.ch>
References: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>
	<CAFEqCdy6zbhhfFaPrhvaGGu2eQK75JtzYXt-TNavMgWsMZsSyw@mail.gmail.com>
	<21583.46822.302622.792661@stat.math.ethz.ch>
Message-ID: <CAFEqCdyjQK7UFwaR7VjeqSzQ+DJSUoir=XJ0-uqYnp-eTgAkBQ@mail.gmail.com>

Thanks Martin,  It is always great to learn that I don't need to
reinvent the wheel (especially when I learn that before reinventing).

Do you know if there are any help pages that point to cophenetic (see
also or other sections).  Maybe it is just the way that my brain is
wired (along with being a dabbler, but not expert at cluster
analysis), but for some reason the word cophenetic never occurred to
me as a search term while thinking about how to create the requested
plot.

On Tue, Oct 28, 2014 at 9:31 AM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Greg Snow <538280 at gmail.com>
>>>>>>     on Mon, 27 Oct 2014 12:33:18 -0600 writes:
>
>     > I don't know of any tools that automate this process.  For small
>     > sample sizes it may be easiest to just do this by hand, for large
>     > sample sizes that plot will probably be to complicated to make sense
>     > of.  There may be a range of moderate sample sizes for which
>     > automation (or partial automation) would be helpful.  The hclust
>     > object has a component of "height" which is an indicator of the
>     > distance between 2 components being combined into a cluster, you could
>     > convert this into a distance matrix
>
> it has been known for many years how to do this; still, I have
> only learned about it from Robert Gentleman (yes, one of the two
> fathers of R), when we added the function
>
>         cophenetic()
> to R
> which does exactly do this:
> Provide the distance matrix which is implicitly defined by a
> hierarchical clustering.
>
> Martin Maechler, ETH Zurich
>
>     > (or extract the distance matrix used to do the clustering
>     > if it is available) and then use multidimensional scaling
>     > (cmdscale function is one option) to produce a 2
>     > dimensional set of points.  Drawing the
>     > circles/ellipses/ovals will be more difficult, possibly
>     > generate a cloud of normal points, or a small circle,
>     > around each point with the variability/radius low enough
>     > that the clouds are unlikely to overlap, then find the
>     > convex hull (chull function) for the points within a
>     > cluster and draw that (it will be a polygon rather than a
>     > smooth curve).  The gBuffer command in the rgeos package
>     > may be another way to create polygons around the points in
>     > a group.
>
>     > On Mon, Oct 27, 2014 at 5:42 AM, David Feitosa <davidfeitosa at gmail.com> wrote:
>     >> Hello!
>     >>
>     >> I have a code that creates an hclust object.
>     >> After the object creation I plot the object as a dendrogram,
>     >> similar to the left image of this link:
>     >>
>     >> http://www.cs.jhu.edu/~razvanm/fs-expedition/hclust-example.png
>     >>
>     >> I would like to create another image, but similar to the right,
>     >> as a set of nested  dots and elipses/circles.
>     >>
>     >> Anybody knows how to do this?
>     >>
>     >> Thanks in advance.
>     >>
>     >> David Feitosa
>     >>
>     >> (\_(\
>     >> (=?;?)
>     >> (("")("")
>     >>
>     >> [[alternative HTML version deleted]]
>     >>
>     >> ______________________________________________
>     >> R-help at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     > --
>     > Gregory (Greg) L. Snow Ph.D.
>     > 538280 at gmail.com
>
>     > ______________________________________________
>     > R-help at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     > and provide commented, minimal, self-contained, reproducible code.



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From friendly at yorku.ca  Tue Oct 28 17:32:38 2014
From: friendly at yorku.ca (Michael Friendly)
Date: Tue, 28 Oct 2014 12:32:38 -0400
Subject: [R] merge coefficients from a glmlist of models
In-Reply-To: <002d01cff2ca$0ddd8290$299887b0$@mcmaster.ca>
References: <544FBA79.7060104@yorku.ca>
	<002d01cff2ca$0ddd8290$299887b0$@mcmaster.ca>
Message-ID: <544FC526.5000800@yorku.ca>

On 10/28/2014 12:13 PM, John Fox wrote:
> Hi Michael,
>
> How about this?
That's perfect! And more general than I had hoped for.  You probably 
used mindreader() :-)
-Michael

>
>
> coef.glmlist <- function(object, result=c("list", "matrix", "data.frame"),
> ...){
>      result <- match.arg(result)
>      coefs <- lapply(object, coef)
>      if (result == "list") return(coefs)
>      coef.names <- unique(unlist(lapply(coefs, names)))
>      n.mods <- length(object)
>      coef.matrix <- matrix(NA, length(coef.names), n.mods)
>      rownames(coef.matrix) <- coef.names
>      colnames(coef.matrix) <- names(object)
>      for (i in 1:n.mods){
>          coef <- coef(object[[i]])
>          coef.matrix[names(coef), i] <- coef
>      }
>      if (result == "matrix") return(coef.matrix)
>      as.data.frame(coef.matrix)
> }
>
>> coef(mods, result="data.frame")
>                        donner.mod1 donner.mod2 donner.mod3 donner.mod4
> (Intercept)            1.59915455  1.85514867   0.8792031   0.7621901
> age                   -0.03379836 -0.04565225          NA          NA
> sexMale               -1.20678665 -1.62177307  -1.3745016  -1.0995718
> age:sexMale                    NA  0.01957257          NA          NA
> poly(age, 2)1                  NA          NA  -7.9366059 -26.9688970
> poly(age, 2)2                  NA          NA  -6.6929413 -30.5626032
> poly(age, 2)1:sexMale          NA          NA          NA  22.7210591
> poly(age, 2)2:sexMale          NA          NA          NA  28.8975876
>
> Best,
>   John
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Michael Friendly
>> Sent: Tuesday, October 28, 2014 11:47 AM
>> To: R-help
>> Subject: [R] merge coefficients from a glmlist of models
>>
>> In the vcdExtra package, I have a function glmlist to collect a set of
>> glm() models as a "glmlist" object,
>> and other functions that generate & fit such a collection of models.
>>
>> This is my working example, fitting a set of models to the Donner data
>>
>> # install.packages("vcdExtra", repos="http://R-Forge.R-project.org")#
>> needs devel version
>> data("Donner", package="vcdExtra")
>> # make survived a factor
>> Donner$survived <- factor(Donner$survived, labels=c("no", "yes"))
>> Donner$family.size <- ave(as.numeric(Donner$family), Donner$family,
>> FUN=length)
>> # collapse small families into "Other"
>> fam <- Donner$family
>> levels(fam)[c(3,4,6,7,9)] <- "Other"
>> # reorder, putting Other last
>> fam = factor(fam,levels(fam)[c(1, 2, 4:6, 3)])
>> Donner$family <- fam
>>
>> # fit models
>> donner.mod0 <- glm(survived ~ age, data=Donner, family=binomial)
>> donner.mod1 <- glm(survived ~ age + sex, data=Donner, family=binomial)
>> donner.mod2 <- glm(survived ~ age * sex , data=Donner, family=binomial)
>> donner.mod3 <- glm(survived ~ poly(age,2) + sex, data=Donner,
>> family=binomial)
>> donner.mod4 <- glm(survived ~ poly(age,2) * sex, data=Donner,
>> family=binomial)
>> mods <- glmlist(donner.mod1, donner.mod2, donner.mod3, donner.mod4)
>>
>> I'd like to write other methods for handling a glmlist, similar to the
>> way stats::anova.glmlist works, e.g.,
>>
>>   > library(vcdExtra)
>>   > mods <- glmlist(donner.mod1, donner.mod2, donner.mod3, donner.mod4)
>>   >
>>   > anova(mods, test="Chisq")
>> Analysis of Deviance Table
>>
>> Model 1: survived ~ age + sex
>> Model 2: survived ~ age * sex
>> Model 3: survived ~ poly(age, 2) + sex
>> Model 4: survived ~ poly(age, 2) * sex
>> Resid. Df Resid. Dev Df Deviance Pr(>Chi)
>> 1 87 111.128
>> 2 86 110.727 1 0.4003 0.52692
>> 3 86 106.731 0 3.9958
>> 4 84 97.799 2 8.9321 0.01149 *
>> ---
>> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> # gives same result as anova() with an explicit list of models:
>>
>>   > anova(donner.mod1, donner.mod2, donner.mod3, donner.mod4,
>> test="Chisq")
>> Analysis of Deviance Table
>>
>> Model 1: survived ~ age + sex
>> Model 2: survived ~ age * sex
>> Model 3: survived ~ poly(age, 2) + sex
>> Model 4: survived ~ poly(age, 2) * sex
>> Resid. Df Resid. Dev Df Deviance Pr(>Chi)
>> 1 87 111.128
>> 2 86 110.727 1 0.4003 0.52692
>> 3 86 106.731 0 3.9958
>> 4 84 97.799 2 8.9321 0.01149 *
>> ---
>> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Then, using the function vcdExtra::Summarise, I can define a
>> Summarise.glmlist method that is essentially
>>
>> sumry <- lapply(mods, Summarise)
>> do.call(rbind, sumry)
>>
>>   > Summarise(mods)# not yet added to the package
>> Likelihood summary table:
>> AIC BIC LR Chisq Df Pr(>Chisq)
>> donner.mod1 117.13 124.63 111.128 87 0.04159 *
>> donner.mod2 118.73 128.73 110.727 86 0.03755 *
>> donner.mod3 114.73 124.73 106.731 86 0.06439 .
>> donner.mod4 109.80 124.80 97.799 84 0.14408
>> ---
>> Signif. codes: 0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>>
>> Similarly, I can define a residuals.glmlist method, using using cbind()
>> to collect the residuals from all
>> models.
>> But I'm stumped on a coef() method, because the coefficients fitted in
>> various models
>> differ.
>>
>>   > coefs <- lapply(mods, "coef")
>>   > coefs
>> $donner.mod1
>> (Intercept) age sexMale
>> 1.59915455 -0.03379836 -1.20678665
>>
>> $donner.mod2
>> (Intercept) age sexMale age:sexMale
>> 1.85514867 -0.04565225 -1.62177307 0.01957257
>>
>> $donner.mod3
>> (Intercept) poly(age, 2)1 poly(age, 2)2 sexMale
>> 0.8792031 -7.9366059 -6.6929413 -1.3745016
>>
>> $donner.mod4
>> (Intercept) poly(age, 2)1 poly(age, 2)2 sexMale
>> 0.7621901 -26.9688970 -30.5626032 -1.0995718
>> poly(age, 2)1:sexMale poly(age, 2)2:sexMale
>> 22.7210591 28.8975876
>>
>> The result I want is a data.frame with columns corresponding to the
>> models, and rows corresponding
>> to the unique coefficient names, with NA filled in where a term is
>> missing.
>>
>>
>> --
>> Michael Friendly     Email: friendly AT yorku DOT ca
>> Professor, Psychology Dept. & Chair, Quantitative Methods
>> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
>> 4700 Keele Street    Web:http://www.datavis.ca
>> Toronto, ONT  M3J 1P3 CANADA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jvadams at usgs.gov  Tue Oct 28 18:09:57 2014
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 28 Oct 2014 12:09:57 -0500
Subject: [R] Putting R script in a function.
In-Reply-To: <CAGh51gS5pZA+KvCHdjaLx7zki560s7WfDJJDn32iMwwbQqhAvg@mail.gmail.com>
References: <CAGh51gS5pZA+KvCHdjaLx7zki560s7WfDJJDn32iMwwbQqhAvg@mail.gmail.com>
Message-ID: <CAN5YmCHPcCDJEN2qbC9KYZ-SkYeNL0pwp7V+W+WitjUNbTKHAA@mail.gmail.com>

Frederic,

You can simplify your code somewhat using vectorization and the cumsum()
function instead of a for loop.  Since you focus in on a single year,
perhaps you could do the calculations for all the years, and store the
result in an array, instead.  Then you could grab any day*month matrix from
that array as needed.

For example, I created a fake data set and ran the following bit of code ...

Jean


# Fake data
Samsmall <- data.frame(Year=sample(1930:1933, 20, TRUE), Month=rep(1:2,
10),
     Day=sample(20), Rain=sample(20))

Samsmall$Evaporation <- 5
Samsmall$Water_Balance <- cumsum(Samsmall$Rain - Samsmall$Evaporation)
Samsmall$Water_Balance[Samsmall$Water_Balance < 0] <- 0
Samsmall$Water_Balance[Samsmall$Water_Balance > 100] <- 100
Samsmall$Mon <- factor(Samsmall$Month, 1:12, month.abb)

tapply(Samsmall$Water_Balance, list(Samsmall$Day, Samsmall$Mon,
Samsmall$Year), mean)


On Tue, Oct 28, 2014 at 7:40 AM, Frederic Ntirenganya <ntfredo at gmail.com>
wrote:

> Hi All,
>
> I wrote this script to calculate the water balance using the following
> formula:
> Water_Balance = Water_Balance yesterday + Rainfall - Evaporation.
>
> The code works well and I want to put into a function.
>
> conditions: Water_Balance<0 is equal to 0.
>                  Water_Balance>100 is equal to 100.
>
> Any idea on how I can make it us a function is welcome.
>
>
> # Adding a new column for water balance to the data frame and evaporation
> Samsmall$Water_Balance <- NA
> Samsmall$Evaporation<-5
> # initialization
> Samsmall$Water_Balance[1]=0
> # loop for calculating water balance for a given dataset
> ndays <- nrow(Samsmall)
> for (iday in 2:ndays) {
>   Samsmall$Water_Balance[iday] <- Samsmall$Water_Balance[iday-1] +
> Samsmall$Rain[iday] - Samsmall$Evaporation[iday]
>   if (Samsmall$Water_Balance[iday]<0){
>     Samsmall$Water_Balance[iday]=0
>   }else if(Samsmall$Water_Balance[iday]>100){
>     Samsmall$Water_Balance[iday]=100
>   }
> }
> ## Table of water balance for a specific year.
> require(reshape2)
> samsmall30<-subset(Samsmall,Year==1930)
> attach(samsmall30)
> #produce table with data
> sam30<-dcast(samsmall30,Day~Month,value.var="Water_Balance")
> #add column names as months
> colnames(sam30)[2:13]<-month.abb[1:12]
>
>
> Regards,
> Frederic.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From antonioparedes14 at gmail.com  Tue Oct 28 17:47:58 2014
From: antonioparedes14 at gmail.com (Antonio Paredes)
Date: Tue, 28 Oct 2014 12:47:58 -0400
Subject: [R] R and Newest version of Java
Message-ID: <CAPgUJvNWRtzwOVfETKhsPOhgV_FL+6MYzH_q0-dG+We=u-XCaQ@mail.gmail.com>

Hell All,

Last night I updated Java to it newest version and this morning when I got
to my office some of the R packages, that I am using in a current project,
are not loading at all. For example

Loading required package: XLConnectJars
Error : .onLoad failed in loadNamespace() for 'rJava', details:
  call: fun(libname, pkgname)
  error: No CurrentVersion entry in Software/JavaSoft registry! Try
re-installing Java and make sure R and Java have matching architectures.
Error: package ?XLConnectJars? could not be loaded

I did re-installed Java but the issue continues. Are there any known issues
associated with how R is interacting with the latest version of Java?

Thank you very much.

-- 
-Tony

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Oct 28 19:26:29 2014
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 28 Oct 2014 19:26:29 +0100
Subject: [R] plot hclust object
In-Reply-To: <CAFEqCdyjQK7UFwaR7VjeqSzQ+DJSUoir=XJ0-uqYnp-eTgAkBQ@mail.gmail.com>
References: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>
	<CAFEqCdy6zbhhfFaPrhvaGGu2eQK75JtzYXt-TNavMgWsMZsSyw@mail.gmail.com>
	<21583.46822.302622.792661@stat.math.ethz.ch>
	<CAFEqCdyjQK7UFwaR7VjeqSzQ+DJSUoir=XJ0-uqYnp-eTgAkBQ@mail.gmail.com>
Message-ID: <21583.57301.272760.264491@stat.math.ethz.ch>

>>>>> Greg Snow <538280 at gmail.com>
>>>>>     on Tue, 28 Oct 2014 10:31:27 -0600 writes:

    > Thanks Martin,  It is always great to learn that I don't need to
    > reinvent the wheel (especially when I learn that before reinventing).

    > Do you know if there are any help pages that point to cophenetic (see
    > also or other sections).  Maybe it is just the way that my brain is
    > wired (along with being a dabbler, but not expert at cluster
    > analysis), but for some reason the word cophenetic never occurred to
    > me as a search term while thinking about how to create the requested plot.

I understand.  Indeed, the world is never going to be perfect, nor is R.

Currently the only link to 'cophenetic' is in  ?reorder.dendrogram
and it's easy possible you'd neither have seen that page.

I strongly agree that more \link's would be useful in general
and in particular for cophenetic. I'm happy to take suggestions,
notably if they already use  Rd syntax ... ;-)

Martin

    > On Tue, Oct 28, 2014 at 9:31 AM, Martin Maechler
    > <maechler at stat.math.ethz.ch> wrote:
    >>>>>>> Greg Snow <538280 at gmail.com>
    >>>>>>> on Mon, 27 Oct 2014 12:33:18 -0600 writes:
    >> 
    >> > I don't know of any tools that automate this process.  For small
    >> > sample sizes it may be easiest to just do this by hand, for large
    >> > sample sizes that plot will probably be to complicated to make sense
    >> > of.  There may be a range of moderate sample sizes for which
    >> > automation (or partial automation) would be helpful.  The hclust
    >> > object has a component of "height" which is an indicator of the
    >> > distance between 2 components being combined into a cluster, you could
    >> > convert this into a distance matrix
    >> 
    >> it has been known for many years how to do this; still, I have
    >> only learned about it from Robert Gentleman (yes, one of the two
    >> fathers of R), when we added the function
    >> 
    >> cophenetic()
    >> to R
    >> which does exactly do this:
    >> Provide the distance matrix which is implicitly defined by a
    >> hierarchical clustering.
    >> 
    >> Martin Maechler, ETH Zurich
    >> 
    >> > (or extract the distance matrix used to do the clustering
    >> > if it is available) and then use multidimensional scaling
    >> > (cmdscale function is one option) to produce a 2
    >> > dimensional set of points.  Drawing the
    >> > circles/ellipses/ovals will be more difficult, possibly
    >> > generate a cloud of normal points, or a small circle,
    >> > around each point with the variability/radius low enough
    >> > that the clouds are unlikely to overlap, then find the
    >> > convex hull (chull function) for the points within a
    >> > cluster and draw that (it will be a polygon rather than a
    >> > smooth curve).  The gBuffer command in the rgeos package
    >> > may be another way to create polygons around the points in
    >> > a group.
    >> 
    >> > On Mon, Oct 27, 2014 at 5:42 AM, David Feitosa <davidfeitosa at gmail.com> wrote:
    >> >> Hello!
    >> >>
    >> >> I have a code that creates an hclust object.
    >> >> After the object creation I plot the object as a dendrogram,
    >> >> similar to the left image of this link:
    >> >>
    >> >> http://www.cs.jhu.edu/~razvanm/fs-expedition/hclust-example.png
    >> >>
    >> >> I would like to create another image, but similar to the right,
    >> >> as a set of nested  dots and elipses/circles.
    >> >>
    >> >> Anybody knows how to do this?
    >> >>
    >> >> Thanks in advance.
    >> >>
    >> >> David Feitosa
    >> >>
    >> >> (\_(\
    >> >> (=?;?)
    >> >> (("")("")
    >> >>
    >> >> [[alternative HTML version deleted]]
    >> >>
    >> >> ______________________________________________
    >> >> R-help at r-project.org mailing list
    >> >> https://stat.ethz.ch/mailman/listinfo/r-help
    >> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> >> and provide commented, minimal, self-contained, reproducible code.
    >> 
    >> 
    >> 
    >> > --
    >> > Gregory (Greg) L. Snow Ph.D.
    >> > 538280 at gmail.com
    >> 
    >> > ______________________________________________
    >> > R-help at r-project.org mailing list
    >> > https://stat.ethz.ch/mailman/listinfo/r-help
    >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    >> > and provide commented, minimal, self-contained, reproducible code.



    > -- 
    > Gregory (Greg) L. Snow Ph.D.
    > 538280 at gmail.com


From ripley at stats.ox.ac.uk  Tue Oct 28 19:43:03 2014
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 28 Oct 2014 18:43:03 +0000
Subject: [R] R and Newest version of Java
In-Reply-To: <CAPgUJvNWRtzwOVfETKhsPOhgV_FL+6MYzH_q0-dG+We=u-XCaQ@mail.gmail.com>
References: <CAPgUJvNWRtzwOVfETKhsPOhgV_FL+6MYzH_q0-dG+We=u-XCaQ@mail.gmail.com>
Message-ID: <544FE3B7.8010506@stats.ox.ac.uk>

On 28/10/2014 16:47, Antonio Paredes wrote:
> Hell All,
>
> Last night I updated Java to it newest version and this morning when I got
> to my office some of the R packages, that I am using in a current project,
> are not loading at all. For example
>
> Loading required package: XLConnectJars
> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>    call: fun(libname, pkgname)
>    error: No CurrentVersion entry in Software/JavaSoft registry! Try
> re-installing Java and make sure R and Java have matching architectures.
> Error: package ?XLConnectJars? could not be loaded
>
> I did re-installed Java but the issue continues. Are there any known issues
> associated with how R is interacting with the latest version of Java?

Whatever that version is and whatever platform this is (for the latter, 
see the posting guide)!

If you mean Oracle Java, I use the current 8u25 on several platforms.

At a guess this is Windows and you installed 32-bit Java for use with 
64-bit R or v.v.: the architectures have to match ....

>
> Thank you very much.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From 538280 at gmail.com  Tue Oct 28 21:28:31 2014
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 28 Oct 2014 14:28:31 -0600
Subject: [R] plot hclust object
In-Reply-To: <21583.57301.272760.264491@stat.math.ethz.ch>
References: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>
	<CAFEqCdy6zbhhfFaPrhvaGGu2eQK75JtzYXt-TNavMgWsMZsSyw@mail.gmail.com>
	<21583.46822.302622.792661@stat.math.ethz.ch>
	<CAFEqCdyjQK7UFwaR7VjeqSzQ+DJSUoir=XJ0-uqYnp-eTgAkBQ@mail.gmail.com>
	<21583.57301.272760.264491@stat.math.ethz.ch>
Message-ID: <CAFEqCdyhnMbwyw+Ehcd5XCKBZye53AatDK1B=07mhCZRGvehvQ@mail.gmail.com>

I would suggest links to cophenetic on the help pages for dendrogram
and possibly plot.hclust and related functions.

I was not complaining.  I always enjoy learning new things, it is a
testament to the breadth and depth of R that even after more than 25
years using S and R, that I can still be pleasantly surprised with
functions that I did not know about.

The word cophenetic just has a nice ring to it, has a similar rhythm
and rhymes with copacetic (I think I will challenge my writer
co-worker to come up with a poem including both words).  I can see
some of the origin of the word in genetics, but dropped in casual
conversation it could be interpreted to mean any number of things.  I
may ask my wife when I get home if she is feeling cophenetic and want
to cluster after the kids are in bed (though I should be careful not
to agnes, daisy, pam, etc. or she may choose snuggling with the cats
instead of me as her clustering).

On Tue, Oct 28, 2014 at 12:26 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Greg Snow <538280 at gmail.com>
>>>>>>     on Tue, 28 Oct 2014 10:31:27 -0600 writes:
>
>     > Thanks Martin,  It is always great to learn that I don't need to
>     > reinvent the wheel (especially when I learn that before reinventing).
>
>     > Do you know if there are any help pages that point to cophenetic (see
>     > also or other sections).  Maybe it is just the way that my brain is
>     > wired (along with being a dabbler, but not expert at cluster
>     > analysis), but for some reason the word cophenetic never occurred to
>     > me as a search term while thinking about how to create the requested plot.
>
> I understand.  Indeed, the world is never going to be perfect, nor is R.
>
> Currently the only link to 'cophenetic' is in  ?reorder.dendrogram
> and it's easy possible you'd neither have seen that page.
>
> I strongly agree that more \link's would be useful in general
> and in particular for cophenetic. I'm happy to take suggestions,
> notably if they already use  Rd syntax ... ;-)
>
> Martin
>
>     > On Tue, Oct 28, 2014 at 9:31 AM, Martin Maechler
>     > <maechler at stat.math.ethz.ch> wrote:
>     >>>>>>> Greg Snow <538280 at gmail.com>
>     >>>>>>> on Mon, 27 Oct 2014 12:33:18 -0600 writes:
>     >>
>     >> > I don't know of any tools that automate this process.  For small
>     >> > sample sizes it may be easiest to just do this by hand, for large
>     >> > sample sizes that plot will probably be to complicated to make sense
>     >> > of.  There may be a range of moderate sample sizes for which
>     >> > automation (or partial automation) would be helpful.  The hclust
>     >> > object has a component of "height" which is an indicator of the
>     >> > distance between 2 components being combined into a cluster, you could
>     >> > convert this into a distance matrix
>     >>
>     >> it has been known for many years how to do this; still, I have
>     >> only learned about it from Robert Gentleman (yes, one of the two
>     >> fathers of R), when we added the function
>     >>
>     >> cophenetic()
>     >> to R
>     >> which does exactly do this:
>     >> Provide the distance matrix which is implicitly defined by a
>     >> hierarchical clustering.
>     >>
>     >> Martin Maechler, ETH Zurich
>     >>
>     >> > (or extract the distance matrix used to do the clustering
>     >> > if it is available) and then use multidimensional scaling
>     >> > (cmdscale function is one option) to produce a 2
>     >> > dimensional set of points.  Drawing the
>     >> > circles/ellipses/ovals will be more difficult, possibly
>     >> > generate a cloud of normal points, or a small circle,
>     >> > around each point with the variability/radius low enough
>     >> > that the clouds are unlikely to overlap, then find the
>     >> > convex hull (chull function) for the points within a
>     >> > cluster and draw that (it will be a polygon rather than a
>     >> > smooth curve).  The gBuffer command in the rgeos package
>     >> > may be another way to create polygons around the points in
>     >> > a group.
>     >>
>     >> > On Mon, Oct 27, 2014 at 5:42 AM, David Feitosa <davidfeitosa at gmail.com> wrote:
>     >> >> Hello!
>     >> >>
>     >> >> I have a code that creates an hclust object.
>     >> >> After the object creation I plot the object as a dendrogram,
>     >> >> similar to the left image of this link:
>     >> >>
>     >> >> http://www.cs.jhu.edu/~razvanm/fs-expedition/hclust-example.png
>     >> >>
>     >> >> I would like to create another image, but similar to the right,
>     >> >> as a set of nested  dots and elipses/circles.
>     >> >>
>     >> >> Anybody knows how to do this?
>     >> >>
>     >> >> Thanks in advance.
>     >> >>
>     >> >> David Feitosa
>     >> >>
>     >> >> (\_(\
>     >> >> (=?;?)
>     >> >> (("")("")
>     >> >>
>     >> >> [[alternative HTML version deleted]]
>     >> >>
>     >> >> ______________________________________________
>     >> >> R-help at r-project.org mailing list
>     >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>     >> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> >> and provide commented, minimal, self-contained, reproducible code.
>     >>
>     >>
>     >>
>     >> > --
>     >> > Gregory (Greg) L. Snow Ph.D.
>     >> > 538280 at gmail.com
>     >>
>     >> > ______________________________________________
>     >> > R-help at r-project.org mailing list
>     >> > https://stat.ethz.ch/mailman/listinfo/r-help
>     >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>     >> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>     > --
>     > Gregory (Greg) L. Snow Ph.D.
>     > 538280 at gmail.com



-- 
Gregory (Greg) L. Snow Ph.D.
538280 at gmail.com


From gunter.berton at gene.com  Tue Oct 28 21:41:35 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 28 Oct 2014 13:41:35 -0700
Subject: [R] plot hclust object
In-Reply-To: <CAFEqCdyhnMbwyw+Ehcd5XCKBZye53AatDK1B=07mhCZRGvehvQ@mail.gmail.com>
References: <CAL1rLtrzdvgZPg8hafcQuBxzk_xCHNKjHvjDkM2OfJOfG=ggSQ@mail.gmail.com>
	<CAFEqCdy6zbhhfFaPrhvaGGu2eQK75JtzYXt-TNavMgWsMZsSyw@mail.gmail.com>
	<21583.46822.302622.792661@stat.math.ethz.ch>
	<CAFEqCdyjQK7UFwaR7VjeqSzQ+DJSUoir=XJ0-uqYnp-eTgAkBQ@mail.gmail.com>
	<21583.57301.272760.264491@stat.math.ethz.ch>
	<CAFEqCdyhnMbwyw+Ehcd5XCKBZye53AatDK1B=07mhCZRGvehvQ@mail.gmail.com>
Message-ID: <CACk-te1FuXJsnigw5JceNXSCEf97s_hM9h_wqHkJ+8JDo=Pskg@mail.gmail.com>

Copacetic cophenetics are a way
To better see much genetics.



;-)

-- Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Tue, Oct 28, 2014 at 1:28 PM, Greg Snow <538280 at gmail.com> wrote:
> I would suggest links to cophenetic on the help pages for dendrogram
> and possibly plot.hclust and related functions.
>
> I was not complaining.  I always enjoy learning new things, it is a
> testament to the breadth and depth of R that even after more than 25
> years using S and R, that I can still be pleasantly surprised with
> functions that I did not know about.
>
> The word cophenetic just has a nice ring to it, has a similar rhythm
> and rhymes with copacetic (I think I will challenge my writer
> co-worker to come up with a poem including both words).  I can see
> some of the origin of the word in genetics, but dropped in casual
> conversation it could be interpreted to mean any number of things.  I
> may ask my wife when I get home if she is feeling cophenetic and want
> to cluster after the kids are in bed (though I should be careful not
> to agnes, daisy, pam, etc. or she may choose snuggling with the cats
> instead of me as her clustering).
>
> On Tue, Oct 28, 2014 at 12:26 PM, Martin Maechler
> <maechler at stat.math.ethz.ch> wrote:
>>>>>>> Greg Snow <538280 at gmail.com>
>>>>>>>     on Tue, 28 Oct 2014 10:31:27 -0600 writes:
>>
>>     > Thanks Martin,  It is always great to learn that I don't need to
>>     > reinvent the wheel (especially when I learn that before reinventing).
>>
>>     > Do you know if there are any help pages that point to cophenetic (see
>>     > also or other sections).  Maybe it is just the way that my brain is
>>     > wired (along with being a dabbler, but not expert at cluster
>>     > analysis), but for some reason the word cophenetic never occurred to
>>     > me as a search term while thinking about how to create the requested plot.
>>
>> I understand.  Indeed, the world is never going to be perfect, nor is R.
>>
>> Currently the only link to 'cophenetic' is in  ?reorder.dendrogram
>> and it's easy possible you'd neither have seen that page.
>>
>> I strongly agree that more \link's would be useful in general
>> and in particular for cophenetic. I'm happy to take suggestions,
>> notably if they already use  Rd syntax ... ;-)
>>
>> Martin
>>
>>     > On Tue, Oct 28, 2014 at 9:31 AM, Martin Maechler
>>     > <maechler at stat.math.ethz.ch> wrote:
>>     >>>>>>> Greg Snow <538280 at gmail.com>
>>     >>>>>>> on Mon, 27 Oct 2014 12:33:18 -0600 writes:
>>     >>
>>     >> > I don't know of any tools that automate this process.  For small
>>     >> > sample sizes it may be easiest to just do this by hand, for large
>>     >> > sample sizes that plot will probably be to complicated to make sense
>>     >> > of.  There may be a range of moderate sample sizes for which
>>     >> > automation (or partial automation) would be helpful.  The hclust
>>     >> > object has a component of "height" which is an indicator of the
>>     >> > distance between 2 components being combined into a cluster, you could
>>     >> > convert this into a distance matrix
>>     >>
>>     >> it has been known for many years how to do this; still, I have
>>     >> only learned about it from Robert Gentleman (yes, one of the two
>>     >> fathers of R), when we added the function
>>     >>
>>     >> cophenetic()
>>     >> to R
>>     >> which does exactly do this:
>>     >> Provide the distance matrix which is implicitly defined by a
>>     >> hierarchical clustering.
>>     >>
>>     >> Martin Maechler, ETH Zurich
>>     >>
>>     >> > (or extract the distance matrix used to do the clustering
>>     >> > if it is available) and then use multidimensional scaling
>>     >> > (cmdscale function is one option) to produce a 2
>>     >> > dimensional set of points.  Drawing the
>>     >> > circles/ellipses/ovals will be more difficult, possibly
>>     >> > generate a cloud of normal points, or a small circle,
>>     >> > around each point with the variability/radius low enough
>>     >> > that the clouds are unlikely to overlap, then find the
>>     >> > convex hull (chull function) for the points within a
>>     >> > cluster and draw that (it will be a polygon rather than a
>>     >> > smooth curve).  The gBuffer command in the rgeos package
>>     >> > may be another way to create polygons around the points in
>>     >> > a group.
>>     >>
>>     >> > On Mon, Oct 27, 2014 at 5:42 AM, David Feitosa <davidfeitosa at gmail.com> wrote:
>>     >> >> Hello!
>>     >> >>
>>     >> >> I have a code that creates an hclust object.
>>     >> >> After the object creation I plot the object as a dendrogram,
>>     >> >> similar to the left image of this link:
>>     >> >>
>>     >> >> http://www.cs.jhu.edu/~razvanm/fs-expedition/hclust-example.png
>>     >> >>
>>     >> >> I would like to create another image, but similar to the right,
>>     >> >> as a set of nested  dots and elipses/circles.
>>     >> >>
>>     >> >> Anybody knows how to do this?
>>     >> >>
>>     >> >> Thanks in advance.
>>     >> >>
>>     >> >> David Feitosa
>>     >> >>
>>     >> >> (\_(\
>>     >> >> (=?;?)
>>     >> >> (("")("")
>>     >> >>
>>     >> >> [[alternative HTML version deleted]]
>>     >> >>
>>     >> >> ______________________________________________
>>     >> >> R-help at r-project.org mailing list
>>     >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     >> >> and provide commented, minimal, self-contained, reproducible code.
>>     >>
>>     >>
>>     >>
>>     >> > --
>>     >> > Gregory (Greg) L. Snow Ph.D.
>>     >> > 538280 at gmail.com
>>     >>
>>     >> > ______________________________________________
>>     >> > R-help at r-project.org mailing list
>>     >> > https://stat.ethz.ch/mailman/listinfo/r-help
>>     >> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>     >> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>>     > --
>>     > Gregory (Greg) L. Snow Ph.D.
>>     > 538280 at gmail.com
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tim at hoolihan.net  Tue Oct 28 19:22:13 2014
From: tim at hoolihan.net (Tim Hoolihan)
Date: Tue, 28 Oct 2014 14:22:13 -0400
Subject: [R]  big datasets for R
In-Reply-To: <mailman.25.1414494008.30795.r-help@r-project.org>
References: <mailman.25.1414494008.30795.r-help@r-project.org>
Message-ID: <21860B0E-ED83-43EC-8F1B-C0B1A158329B@hoolihan.net>

Another source of large datasets is the Public Data Sets on AWS http://aws.amazon.com/public-data-sets/
Tim Hoolihan
@thoolihan
http://linkedin.com/in/timhoolihan


On Oct 28, 2014, at 7:00 AM, r-help-request at r-project.org wrote:

> ------------------------------
> 
> Message: 2
> Date: Mon, 27 Oct 2014 13:37:12 +0100
> From: Qiong Cai <qiong.cai at gmail.com>
> To: r-help at r-project.org
> Subject: [R] big datasets for R
> Message-ID:
> 	<CAOrq85HXZxgSuA-zDy5eE30M6QLXUvu8cqTkWBfEwoVBG1A7Ng at mail.gmail.com>
> Content-Type: text/plain; charset="UTF-8"
> 
> Hi,
> 
> Could anyone please tell me where I can find very big datasets for R?  I'd
> like to do some benchmarking on R by stressing R a lot.
> 
> Thanks
> Qiong
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ------------------------------


	[[alternative HTML version deleted]]


From jacksonjordancm at gmail.com  Wed Oct 29 00:11:22 2014
From: jacksonjordancm at gmail.com (Chris Jackson-Jordan)
Date: Tue, 28 Oct 2014 19:11:22 -0400
Subject: [R] weighting histograms
Message-ID: <CAPtX2qnkWyd8hMH_NnJ2egg4G2OMhqoT4iXd-V4gdbm0B-DNJA@mail.gmail.com>

I am attempting to weight a histogram with another variable in the
spreadsheet.
does anyone know an easy way of doing this. I have been attempting to use
weighted.hist from the plotrix package but I can't figure out how to use
the other variable as the weight.

I need to weight the Teton_Co_V column in this spreadsheet with GROUP_SIZE
column.

library(plotrix)
training <- read.csv("Biota_subset.csv")
y <- subset(training, select = c(Teton_Co_V))
x <- subset(training, select = c(GROUP_SIZE))
weighted.hist(y, x)

Any suggestions would be great!

Chris

From petr.pikal at precheza.cz  Wed Oct 29 08:49:37 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 29 Oct 2014 07:49:37 +0000
Subject: [R] Loop with ggplot2 not as simple as it seems...
In-Reply-To: <1573665279.1951586.1414457925688.JavaMail.zimbra@stanford.edu>
References: <1472164797.1927227.1414456113275.JavaMail.zimbra@stanford.edu>
	<1573665279.1951586.1414457925688.JavaMail.zimbra@stanford.edu>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEBD91@SRVEXCHMBX.precheza.cz>

Hi Patricia

You are somewhat circling around solution.

Is this what you wanted?

for (i in 5:7) {
  plotname = paste("Graph", names(scores)[i], sep="")
  png(paste0(plotname,".png"))
  p <- ggplot(scores, aes(x=scores[,i], fill=gender ))
  print(p+ geom_density(alpha=.3)+xlab(names(scores)[i]))
dev.off()
}

Cheers
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Patricia Seo
> Sent: Tuesday, October 28, 2014 1:59 AM
> To: r-help at r-project.org
> Subject: [R] Loop with ggplot2 not as simple as it seems...
>
> Hi everyone,
>
> I have been battling with this problem for the past month and reading
> all that I can about it, but I just can't seem to understand what I'm
> doing wrong. It seems easy and I can replicate others well-recorded
> attempts, but can not seem to apply this to my data.
>
> I have created a data.frame to easily illustrate my problem. I would
> like to plot columns 5:7 in my data without having to write-out-every-
> single-variable name. In this example it is only three columns but in
> my actual data set it is more like 50 columns. Here is the simplified
> data frame:
>
> sid <- c(1001:1010) #student id
> age <- c(10, 12, 14, 15, 13, 16, 14, 12, 14, 10)
> race <- race <- c("w", "b", "a", "w", "a", "w", "b", "a", "w", "a")
> gender <- gender <-c("M", "F", "M", "F", "M", "F", "M", "F", "M", "F")
> read <- rnorm(10, 100, 50)
> write <- rnorm(10, 100, 50)
> math<-rnorm(10, 100, 50)
>
> scores <- data.frame(sid, age, race, gender, read, write, math)
>
> My end goal is to produce a .png like this for every column:
>
> ggplot(scores, aes(x=scores$read, fill=scores$gender)) +
> geom_density(alpha=.3)
>
> In other words, I would like to write a loop that would produce
> separate .pngs for each column. No facet-wrap. I would like one plot
> showing the distribution of one score for male and female in one .png
> file.
>
> Failed Attempt #1 of 3: My first attempt was to melt data since I know
> ggplot2 likes melted data. I have tried melting the data using sid,
> age, race and gender as the id variable. But I?m not sure how to plot
> what I would like above with just using values. In my actual data set
> there are over 50 columns to plot (instead of the simple three in the
> example scores data). I tried creating:
>
> xobject <- subset(scores.melt, variable=read)
>
> but it gives me the error: Don't know how to automatically pick scale
> for object of type data.frame. Defaulting to continuous
> Error: Aesthetics must either be length one, or the same length as the
> dataProblems:test1
>
> Failed Attempt #2 of 3: My second attempt is below but it had similar
> problems to what others have mentioned with ggplot changing the names
> of each plot but keeping the last known data column so all the graphs
> look the same. It works in terms of titles but not data! And I have
> tried as_string() but to no avail:
>
> for (i in 5:7) {
>   column_to_plot = as.character(paste("Col_", i, sep=""))
>   png(paste0("Graph", column_to_plot,".png"))
>   ggplot(scores, aes(x=column_to_plot, fill=gender )) +
> geom_density(alpha=.3)
>   ggsave(paste0("Graph", column_to_plot,".png"))
>
> }
>
> Failed Attempt #3 of 3: My third attempt is my most successful attempt.
> It is because I created a vector that includes the list of variables I
> would like to plot. Unfortunately, I have two problems with this
> method: (1) Don?t know how to include the corresponding title name so I
> know which plot corresponds to the score even though I do indicate the
> names of the Indexes, and (2) It is annoying to have to write the
> entire list of variables I want to plot especially if there are 50
> variable names. I know I can specify columns 5:7 (like above) but I?m
> not grasping the logics of this loop:
>
> Indexes = list()
> Indexes[[1]] = scores$read
> Indexes[[2]] = scores$write
> Indexes[[3]] = scores$math
>
> names(Indexes) = c(?Scores for Read?,
>                    ?Scores for Write?, ?Scores for Math?)
>
> ##### for some reason, I have to run the top half and after it has
> processed that, run the bottom half#####
>
> for(i in seq(along = Indexes)) {
>   Index = Indexes[[i]]
>
>   for(j in 1:length(gender)) {
>     png(paste0("Graph", Index,".png"))
>     ggplot(scores, aes(x=Index, fill = gender)) +
> geom_density(alpha=.3)
>     ggsave(paste0("Graph", Index,".png"))
>
>   }
> }
>
> Any help would be much appreciated. I know this is a frankenstein from
> previous questions and problems with loops in ggplot2, but just
> understand what I'm doing wrong would even be a huge help.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Oct 29 08:57:08 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 29 Oct 2014 07:57:08 +0000
Subject: [R] Adding  labels to ColSums
In-Reply-To: <E18C153EBB81024CB60FCE9B4C34D57C37F4D3B2@pl-emsmb11>
References: <E18C153EBB81024CB60FCE9B4C34D57C37F4D3B2@pl-emsmb11>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEBDC3@SRVEXCHMBX.precheza.cz>

Hi

Most probably
years.before.initiated.cat

is a factor. You have basically two options.

change it to character by ?as.character

or

add level named "Total" by

levels(years.before.initiated.cat)<-c(levels(years.before.initiated.cat), "Total")

Cheers
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Muhuri, Pradip (SAMHSA/CBHSQ)
> Sent: Tuesday, October 28, 2014 4:44 PM
> To: R help
> Subject: [R] Adding labels to ColSums
>
> Hello,
>
> I was trying to add labels to the colSums  of the  "integers" variable
> corresponding to a "factor".  Below are the  warning message and the
> reproducible code.  How would I tweak the code to replace the "NA" with
> the "Total" in the output?  Your advice toward resolving the issue
> would be greatly appreciated.
>
> Thanks,
>
> Pradip Muhuri
>
>
>
> ###################  warning message - from the console
> ############################ rb.data <- rbind(s.data2, c("Total",
> colSums(s.data2[,2, drop=FALSE]))) # row bind with the column total
>
> Warning message:
> In `[<-.factor`(`*tmp*`, ri, value = "Total") :
>   invalid factor level, NA generated
> > rb.data
> Source: local data frame [7 x 2]
>
>   years.before.initiated.cat anl.count
> 1                      [0,1]        89
> 2                      (1,2]        73
> 3                      (2,3]        72
> 4                      (3,4]        82
> 5                      (4,5]        82
> 6                      (5,6]        86
> 7                         NA       484
> #########################  reproducible code
> #################################################
> library(dplyr)
>
> i.data2 <- data.frame(sample(1:6, size=484, replace=T)) # simulate data
> to create a data frame
> colnames(i.data2) <- "years.before.initiated" # add a column name
>
> m.data2 <- mutate(i.data2,  years.before.initiated.cat =
>                     cut(years.before.initiated,
> breaks=c(0,1,2,3,4,5,6),include.lowest=TRUE))
>                         # create a new variable
>
> g.data2 <- group_by(m.data2, years.before.initiated.cat) # group by
> years.before.initiated.cat
> s.data2 <- summarise(g.data2, anl.count =n() ) # summarize to get the
> count
>
> rb.data <- rbind(s.data2, c("Total", colSums(s.data2[,2, drop=FALSE])))
> # row bind with the column total rb.data
> #######################################################################
> ####################
>
> Pradip K. Muhuri, PhD
> SAMHSA/CBHSQ
> 1 Choke Cherry Road, Room 2-1071
> Rockville, MD 20857
> Tel: 240-276-1070
> Fax: 240-276-1260
> ommented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From petr.pikal at precheza.cz  Wed Oct 29 09:11:35 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 29 Oct 2014 08:11:35 +0000
Subject: [R] weighting histograms
In-Reply-To: <CAPtX2qnkWyd8hMH_NnJ2egg4G2OMhqoT4iXd-V4gdbm0B-DNJA@mail.gmail.com>
References: <CAPtX2qnkWyd8hMH_NnJ2egg4G2OMhqoT4iXd-V4gdbm0B-DNJA@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEBDD8@SRVEXCHMBX.precheza.cz>

Hi

Your example is not reproducible as we do not have Biota_subset and have no idea what is its structure. You also do not mention any error.

Most probably x and y are not what you think it is.

This works as expected.

testx<-sample(1:10,300,TRUE)
testw<-seq(1,4,by=0.01)
weighted.hist(testx,testw,breaks=1:10,main="Test weighted histogram")

Cheers
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Chris Jackson-Jordan
> Sent: Wednesday, October 29, 2014 12:11 AM
> To: R help
> Subject: [R] weighting histograms
>
> I am attempting to weight a histogram with another variable in the
> spreadsheet.
> does anyone know an easy way of doing this. I have been attempting to
> use weighted.hist from the plotrix package but I can't figure out how
> to use the other variable as the weight.
>
> I need to weight the Teton_Co_V column in this spreadsheet with
> GROUP_SIZE column.
>
> library(plotrix)
> training <- read.csv("Biota_subset.csv") y <- subset(training, select =
> c(Teton_Co_V)) x <- subset(training, select = c(GROUP_SIZE))
> weighted.hist(y, x)
>
> Any suggestions would be great!
>
> Chris

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From alex at chaotic-neutral.de  Wed Oct 29 09:48:05 2014
From: alex at chaotic-neutral.de (Alexander Engelhardt)
Date: Wed, 29 Oct 2014 09:48:05 +0100
Subject: [R] foreach/dopar's processes accumulate RAM
Message-ID: <5450A9C5.7010800@chaotic-neutral.de>

Hello all,

I have a triple nested loop in R like this:

all <- list()
for(a in A){
     all[[a]] <- list()
     for(b in B){
         all[[a]][[b]] <- foreach(c=C, .combine=rbind) %dopar% {
             ## I'm leaving out some preprocessing here
             this_GAM <- gam(formula, data=data, family=nb(link="log", 
theta=THETA))
             predict(this_GAM, newdata=newdata)
         }
     }
}

The problem I have is that, with time, the individual R processes which 
the %dopar% spawns use up more and more RAM. When I start the triple 
loop, each process requires about 2GB of RAM, but after around eight 
hours, they use >4GB each. Here's the first two lines of a 'top' output:

   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND 

20880 engelhar  20   0 7042m 4.0g 2436 R 59.2  6.4  14:30.15 R 

20878 engelhar  20   0 7042m 4.3g 2436 D 53.5  6.8  14:07.18 R 


I don't understand how this can happen. To my understanding, as soon as 
the foreach loop is done, i.e. as soon as a new 'b' is chosen from 'B' 
in the second loop, the individual parallel R processes should terminate 
and release the memory. There should not be an increase of memory 
consumption over time.

Does anyone know what is going on and how I can avoid this behavior?

Thanks in advance,
  Alex Engelhardt


From rsasmay at inia.cl  Wed Oct 29 13:42:49 2014
From: rsasmay at inia.cl (ROCIO SASMAY MONTANO)
Date: Wed, 29 Oct 2014 09:42:49 -0300
Subject: [R] How to cite R-Project
Message-ID: <CAEm3p0--gUKi0kCnfWCcjH9m9XwhFzLAcJA3ssdr01DMFATO4w@mail.gmail.com>

Dear Sirs

I'm editorial assistant of Chilean Journal of Agricultural Research and I
need to cite R-Project with the format: STATISTICA (StatSoft, Inc., Tulsa,
Oklahoma, USA). Could you give me the right citation?

Thanks

Best regards

-- 


 Roc?o Sasmay M.
Asistente de Edici?n ChileanJAR
INIA Quilamapu
AV. Vicente Mendez 515
(56-42) 206771
www.inia.cl
En el fondo de cada comienzo hay un hechizo que nos protege y nos ayuda a
vivir (H. Hesse)

-- 
INIA trabaja para que su quehacer sea amigable con el medio ambiente. 
Reafirma este compromiso al obtener la certificaci?n CEMARS? del Programa 
carboNZero para la reducci?n de emisiones de gases de efecto invernadero.

	[[alternative HTML version deleted]]


From Christoph.Hanck at vwl.uni-due.de  Wed Oct 29 13:16:53 2014
From: Christoph.Hanck at vwl.uni-due.de (Hanck, Christoph)
Date: Wed, 29 Oct 2014 12:16:53 +0000
Subject: [R] assigning a function within a loop
Message-ID: <2669DFACA6C93848AED7306DE9F3CA820CBED880@WIWINF-EXDAG01.wiwinf.uni-due.de>

Hi,

I am trying to run several polynomial regressions on simulated data and produce fitted values with the pol1, pol2 functions (predict produces not so nice plots, see http://www.r-bloggers.com/polynomial-regression-techniques/). Below's a simplified version of what I try to achieve. It seems that while assigning within a loop does work, my assignment gets overwritten.

Any ideas - I suspect it is a basic mistake, my first post here...

Best,
Christoph

rm(list=ls())

# data generation
N=10
u = rnorm(N,0,.25)
x = sort(runif(N))
y = sin(2*pi*x)+u

# number of polynomials (just 2 for simplicity here)
degree = 2

plot(x,y)
for(i in 1:degree)
{
  nam <- paste("fit",i,sep = "")
  assign(nam, lm(y~poly(x,i,raw=TRUE))) # works nicely and I can access fit1, fit2 later

  nam2 <- paste("pol",i,sep = "")
  assign(nam2, function(x) matrix(x^rep(0:i,each=length(x)),ncol=i+1)%*%get(paste("fit",i,sep = ""))$coefficient[1:(i+1)])

  if(i==1) print(pol1(x)) # something different than pol2(x)
  #curve(get(paste("pol",i,sep = "")), col=20+i, lwd=2, add = TRUE) # the ultimate goal
}

print(pol1(x)) # produces the same result as pol2(x), although it did not in the loop
print(pol2(x))

	[[alternative HTML version deleted]]


From alexander.myltsev at phystech.edu  Wed Oct 29 11:28:58 2014
From: alexander.myltsev at phystech.edu (Alexander Myltsev)
Date: Wed, 29 Oct 2014 14:28:58 +0400
Subject: [R] SQL Requests Templating
Message-ID: <CADJNC9jptH7RunwGHMuDRS2um2=hj9Gzs63C+2rrO7jg5cPaOQ@mail.gmail.com>

Hi,

I am new to R.

What I'd like to know is how to empower sqldf with templates like
https://www.playframework.com/documentation/2.3.x/ScalaAnorm does? What
does seasoned R-hacker use for this purpose: dedicated R-package that I am
not aware of, or kind of format string, or something else?

A.

	[[alternative HTML version deleted]]


From tjolitz at gmail.com  Wed Oct 29 14:09:00 2014
From: tjolitz at gmail.com (Thorsten Jolitz)
Date: Wed, 29 Oct 2014 14:09:00 +0100
Subject: [R] Ways to get all function signatures of a library?
Message-ID: <87mw8f6n0z.fsf@gmail.com>


Hi List, 

are there ways to get signatures of all functions of a library in a
format that is easy to process by a programm (list, xml or so)?

The info about function name, return value and arguments (types) is all
there in the docs, but more in a human readable format embedded in much
extra information. How to extract it without writing a documentation
parser or so? I'm pretty sure the functionality exists, but did not find
it.

Thanks for any hint.

-- 
cheers,
Thorsten


From jdnewmil at dcn.davis.CA.us  Wed Oct 29 14:25:52 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 29 Oct 2014 06:25:52 -0700
Subject: [R] How to cite R-Project
In-Reply-To: <CAEm3p0--gUKi0kCnfWCcjH9m9XwhFzLAcJA3ssdr01DMFATO4w@mail.gmail.com>
References: <CAEm3p0--gUKi0kCnfWCcjH9m9XwhFzLAcJA3ssdr01DMFATO4w@mail.gmail.com>
Message-ID: <32B40C19-5E7D-4917-9569-84A039565AC0@dcn.davis.CA.us>

Run the function

citation()

at the R prompt.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 29, 2014 5:42:49 AM PDT, ROCIO SASMAY MONTANO <rsasmay at inia.cl> wrote:
>Dear Sirs
>
>I'm editorial assistant of Chilean Journal of Agricultural Research and
>I
>need to cite R-Project with the format: STATISTICA (StatSoft, Inc.,
>Tulsa,
>Oklahoma, USA). Could you give me the right citation?
>
>Thanks
>
>Best regards
>
>-- 
>
>
> Roc?o Sasmay M.
>Asistente de Edici?n ChileanJAR
>INIA Quilamapu
>AV. Vicente Mendez 515
>(56-42) 206771
>www.inia.cl
>En el fondo de cada comienzo hay un hechizo que nos protege y nos ayuda
>a
>vivir (H. Hesse)
>
>-- 
>INIA trabaja para que su quehacer sea amigable con el medio ambiente. 
>Reafirma este compromiso al obtener la certificaci?n CEMARS? del
>Programa 
>carboNZero para la reducci?n de emisiones de gases de efecto
>invernadero.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Wed Oct 29 14:57:34 2014
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 29 Oct 2014 06:57:34 -0700
Subject: [R] Ways to get all function signatures of a library?
In-Reply-To: <87mw8f6n0z.fsf@gmail.com>
References: <87mw8f6n0z.fsf@gmail.com>
Message-ID: <CACk-te0QVKkEYK5VqOjgMhS5a=pK5tWy70GiyPtGNTgNB87h0A@mail.gmail.com>

Perhaps the
?formals
function in R is what you are looking for. Or maybe its (internal C) code.

Cheers,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Wed, Oct 29, 2014 at 6:09 AM, Thorsten Jolitz <tjolitz at gmail.com> wrote:
>
> Hi List,
>
> are there ways to get signatures of all functions of a library in a
> format that is easy to process by a programm (list, xml or so)?
>
> The info about function name, return value and arguments (types) is all
> there in the docs, but more in a human readable format embedded in much
> extra information. How to extract it without writing a documentation
> parser or so? I'm pretty sure the functionality exists, but did not find
> it.
>
> Thanks for any hint.
>
> --
> cheers,
> Thorsten
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Wed Oct 29 15:15:33 2014
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 29 Oct 2014 14:15:33 +0000
Subject: [R] assigning a function within a loop
In-Reply-To: <2669DFACA6C93848AED7306DE9F3CA820CBED880@WIWINF-EXDAG01.wiwinf.uni-due.de>
References: <2669DFACA6C93848AED7306DE9F3CA820CBED880@WIWINF-EXDAG01.wiwinf.uni-due.de>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802BEBF59@SRVEXCHMBX.precheza.cz>

Hi

instead of this paste/assign/get stuff use list for keeping cycle result

something like

nam <- vector("list", degree)

for (i in 1:degree) {
nam[[i]] <- lm(y~poly(x,i,raw=TRUE))
}

Cheers
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Hanck, Christoph
> Sent: Wednesday, October 29, 2014 1:17 PM
> To: r-help at r-project.org
> Subject: [R] assigning a function within a loop
>
> Hi,
>
> I am trying to run several polynomial regressions on simulated data and
> produce fitted values with the pol1, pol2 functions (predict produces
> not so nice plots, see http://www.r-bloggers.com/polynomial-regression-
> techniques/). Below's a simplified version of what I try to achieve. It
> seems that while assigning within a loop does work, my assignment gets
> overwritten.
>
> Any ideas - I suspect it is a basic mistake, my first post here...
>
> Best,
> Christoph
>
> rm(list=ls())
>
> # data generation
> N=10
> u = rnorm(N,0,.25)
> x = sort(runif(N))
> y = sin(2*pi*x)+u
>
> # number of polynomials (just 2 for simplicity here) degree = 2
>
> plot(x,y)
> for(i in 1:degree)
> {
>   nam <- paste("fit",i,sep = "")
>   assign(nam, lm(y~poly(x,i,raw=TRUE))) # works nicely and I can access
> fit1, fit2 later
>
>   nam2 <- paste("pol",i,sep = "")
>   assign(nam2, function(x)
> matrix(x^rep(0:i,each=length(x)),ncol=i+1)%*%get(paste("fit",i,sep =
> ""))$coefficient[1:(i+1)])
>
>   if(i==1) print(pol1(x)) # something different than pol2(x)
>   #curve(get(paste("pol",i,sep = "")), col=20+i, lwd=2, add = TRUE) #
> the ultimate goal }
>
> print(pol1(x)) # produces the same result as pol2(x), although it did
> not in the loop
> print(pol2(x))
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From prgosek at gmail.com  Wed Oct 29 15:16:01 2014
From: prgosek at gmail.com (=?UTF-8?Q?Michal_Kvasni=C4=8Dka?=)
Date: Wed, 29 Oct 2014 15:16:01 +0100
Subject: [R] Voronoi/Thiessen polygon neighbors?
Message-ID: <CALs_GZVpadxWzCCWShg0KiK7VrFiUje2VbsFFXF6uSODip4Saw@mail.gmail.com>

Hello.

I have a set of points in 2D. I can construct Voronoi polygons around them
with deldir package  and function from this page:


http://stackoverflow.com/questions/9403660/how-to-create-thiessen-polygons-from-points-using-r-packages

What I need is to find the list of all polygon neighbors of each original
point. (Let us say that each original point is represented with its Voronoi
polygon. These polygons are numbered. I have to find a list of all indices
of the polygons that share a line segment with polygon 1, polygon 2, etc.)

I can go through all line segments of all polygons and search for the
polygon that shares the line segment but I guess there is a better way to
do it. Can you help me to find it please?

Best wishes,
Michal Kvasnicka

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Oct 29 15:51:46 2014
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 29 Oct 2014 10:51:46 -0400
Subject: [R] How to cite R-Project
In-Reply-To: <CAEm3p0--gUKi0kCnfWCcjH9m9XwhFzLAcJA3ssdr01DMFATO4w@mail.gmail.com>
References: <CAEm3p0--gUKi0kCnfWCcjH9m9XwhFzLAcJA3ssdr01DMFATO4w@mail.gmail.com>
Message-ID: <5450FF02.9080907@gmail.com>

On 29/10/2014 8:42 AM, ROCIO SASMAY MONTANO wrote:
> Dear Sirs
>
> I'm editorial assistant of Chilean Journal of Agricultural Research and I
> need to cite R-Project with the format: STATISTICA (StatSoft, Inc., Tulsa,
> Oklahoma, USA). Could you give me the right citation?
>
> Thanks
>
> Best regards
>

Here's what the citation() function gives:To cite R in publications use:

   R Core Team (2014). R: A language and environment for statistical
   computing. R Foundation for Statistical Computing, Vienna, Austria.
   URL http://www.R-project.org/.

A BibTeX entry for LaTeX users is

   @Manual{,
     title = {R: A Language and Environment for Statistical Computing},
     author = {{R Core Team}},
     organization = {R Foundation for Statistical Computing},
     address = {Vienna, Austria},
     year = {2014},
     url = {http://www.R-project.org/},
   }

We have invested a lot of time and effort in creating R, please cite it
when using it for data analysis. See also ?citation("pkgname")? for
citing R packages.

Duncan Murdoch


From tjolitz at gmail.com  Wed Oct 29 15:51:47 2014
From: tjolitz at gmail.com (Thorsten Jolitz)
Date: Wed, 29 Oct 2014 15:51:47 +0100
Subject: [R] Ways to get all function signatures of a library?
References: <87mw8f6n0z.fsf@gmail.com>
	<CACk-te0QVKkEYK5VqOjgMhS5a=pK5tWy70GiyPtGNTgNB87h0A@mail.gmail.com>
Message-ID: <87ioj36i9o.fsf@gmail.com>

Bert Gunter <gunter.berton at gene.com> writes:

> Perhaps the
> ?formals
> function in R is what you are looking for. Or maybe its (internal C) code.

yes, thats a pretty good fit (and no, I'm not asking about internal C
code), thanks.

So now that I have ways to extract machine-readable info about an R
function, how can I map all functions in an R package without having
prior knowledge about the package's content?

In pseudo-code, something like (apply 'formals (pkg-functions "PKG")).

If I'm lucky, there exist another simple function for that too
... thanks again for any hints.

> On Wed, Oct 29, 2014 at 6:09 AM, Thorsten Jolitz <tjolitz at gmail.com> wrote:
>>
>> Hi List,
>>
>> are there ways to get signatures of all functions of a library in a
>> format that is easy to process by a programm (list, xml or so)?
>>
>> The info about function name, return value and arguments (types) is all
>> there in the docs, but more in a human readable format embedded in much
>> extra information. How to extract it without writing a documentation
>> parser or so? I'm pretty sure the functionality exists, but did not find
>> it.
>>
>> Thanks for any hint.
>>
>> --
>> cheers,
>> Thorsten
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

-- 
cheers,
Thorsten


From syen04 at gmail.com  Wed Oct 29 16:41:39 2014
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 29 Oct 2014 11:41:39 -0400
Subject: [R] Injecting a column of characters to a matrix of numerics
In-Reply-To: <544d4402.26dcec0a.7867.fffff267@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
Message-ID: <54510abb.46dfec0a.3c7b.70ed@mx.google.com>

Hello
I am designing a regression printout, which works out nicely. Then, I 
try to inject a column of characters to indicate a discrete regressor 
with a dot (.). Then, all numbers seem to turn into characters, in 
quotations. Is there a way to do this right? Below, I show the lines 
of codes before and after. Thanks.
Steven Yen

---
out<-round(cbind(me,se,t,p),digits)
colnames(out)<-c("estimates","s.e.","|t-value|","p-value")
rownames(out)<-rownames(me)
out
             estimates     s.e. |t-value|  p-value
(Intercept)  0.223263 0.146167  1.527459 0.127173
sex          0.049830 0.039612  1.257973 0.208890
age         -0.070423 0.029539  2.384035 0.017433
yrmarry      0.015567 0.005298  2.938126 0.003429
children     0.060525 0.044778  1.351659 0.176993
religius    -0.053128 0.014413  3.686260 0.000248
educ         0.003226 0.008453  0.381636 0.702866
occu         0.003915 0.011860  0.330147 0.741404
rating      -0.077856 0.014466  5.381925 0.000000

out<-round(cbind(me,se,t,p),digits); out<-cbind(out,disc)
colnames(out)<-c("estimates","s.e.","|t-value|","p-value","disc")
rownames(out)<-rownames(me)

(Intercept) "0.223263"  "0.146167" "1.527459" "0.127173" ""
sex         "0.04983"   "0.039612" "1.257973" "0.20889"  "."
age         "-0.070423" "0.029539" "2.384035" "0.017433" ""
yrmarry     "0.015567"  "0.005298" "2.938126" "0.003429" ""
children    "0.060525"  "0.044778" "1.351659" "0.176993" "."
religius    "-0.053128" "0.014413" "3.68626"  "0.000248" ""
educ        "0.003226"  "0.008453" "0.381636" "0.702866" ""
occu        "0.003915"  "0.01186"  "0.330147" "0.741404" ""
rating      "-0.077856" "0.014466" "5.381925" "0"        ""


From kevin.thorpe at utoronto.ca  Wed Oct 29 16:52:58 2014
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 29 Oct 2014 11:52:58 -0400
Subject: [R] Injecting a column of characters to a matrix of numerics
In-Reply-To: <54510abb.46dfec0a.3c7b.70ed@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<54510abb.46dfec0a.3c7b.70ed@mx.google.com>
Message-ID: <54510D5A.60800@utoronto.ca>

On 10/29/2014 11:41 AM, Steven Yen wrote:
> Hello
> I am designing a regression printout, which works out nicely. Then, I
> try to inject a column of characters to indicate a discrete regressor
> with a dot (.). Then, all numbers seem to turn into characters, in
> quotations. Is there a way to do this right? Below, I show the lines of
> codes before and after. Thanks.
> Steven Yen
>
> ---
> out<-round(cbind(me,se,t,p),digits)
> colnames(out)<-c("estimates","s.e.","|t-value|","p-value")
> rownames(out)<-rownames(me)
> out
>              estimates     s.e. |t-value|  p-value
> (Intercept)  0.223263 0.146167  1.527459 0.127173
> sex          0.049830 0.039612  1.257973 0.208890
> age         -0.070423 0.029539  2.384035 0.017433
> yrmarry      0.015567 0.005298  2.938126 0.003429
> children     0.060525 0.044778  1.351659 0.176993
> religius    -0.053128 0.014413  3.686260 0.000248
> educ         0.003226 0.008453  0.381636 0.702866
> occu         0.003915 0.011860  0.330147 0.741404
> rating      -0.077856 0.014466  5.381925 0.000000
>
> out<-round(cbind(me,se,t,p),digits); out<-cbind(out,disc)
> colnames(out)<-c("estimates","s.e.","|t-value|","p-value","disc")
> rownames(out)<-rownames(me)
>
> (Intercept) "0.223263"  "0.146167" "1.527459" "0.127173" ""
> sex         "0.04983"   "0.039612" "1.257973" "0.20889"  "."
> age         "-0.070423" "0.029539" "2.384035" "0.017433" ""
> yrmarry     "0.015567"  "0.005298" "2.938126" "0.003429" ""
> children    "0.060525"  "0.044778" "1.351659" "0.176993" "."
> religius    "-0.053128" "0.014413" "3.68626"  "0.000248" ""
> educ        "0.003226"  "0.008453" "0.381636" "0.702866" ""
> occu        "0.003915"  "0.01186"  "0.330147" "0.741404" ""
> rating      "-0.077856" "0.014466" "5.381925" "0"        ""

Use data frames instead.

out<-data.frame(round(cbind(me,se,t,p),digits)); out<-cbind(out,disc)
names(out)<-c("estimates","s.e.","|t-value|","p-value","disc")

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From syen04 at gmail.com  Wed Oct 29 16:58:52 2014
From: syen04 at gmail.com (Steven Yen)
Date: Wed, 29 Oct 2014 11:58:52 -0400
Subject: [R] Injecting a column of characters to a matrix of  numerics
In-Reply-To: <54510D5A.60800@utoronto.ca>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<54510abb.46dfec0a.3c7b.70ed@mx.google.com>
	<54510D5A.60800@utoronto.ca>
Message-ID: <54510ebe.2525ec0a.5302.715f@mx.google.com>

Wonderful. Works great!
Steven Yen

At 11:52 AM 10/29/2014, Kevin E. Thorpe wrote:
>On 10/29/2014 11:41 AM, Steven Yen wrote:
>>Hello
>>I am designing a regression printout, which works out nicely. Then, I
>>try to inject a column of characters to indicate a discrete regressor
>>with a dot (.). Then, all numbers seem to turn into characters, in
>>quotations. Is there a way to do this right? Below, I show the lines of
>>codes before and after. Thanks.
>>Steven Yen
>>
>>---
>>out<-round(cbind(me,se,t,p),digits)
>>colnames(out)<-c("estimates","s.e.","|t-value|","p-value")
>>rownames(out)<-rownames(me)
>>out
>>              estimates     s.e. |t-value|  p-value
>>(Intercept)  0.223263 0.146167  1.527459 0.127173
>>sex          0.049830 0.039612  1.257973 0.208890
>>age         -0.070423 0.029539  2.384035 0.017433
>>yrmarry      0.015567 0.005298  2.938126 0.003429
>>children     0.060525 0.044778  1.351659 0.176993
>>religius    -0.053128 0.014413  3.686260 0.000248
>>educ         0.003226 0.008453  0.381636 0.702866
>>occu         0.003915 0.011860  0.330147 0.741404
>>rating      -0.077856 0.014466  5.381925 0.000000
>>
>>out<-round(cbind(me,se,t,p),digits); out<-cbind(out,disc)
>>colnames(out)<-c("estimates","s.e.","|t-value|","p-value","disc")
>>rownames(out)<-rownames(me)
>>
>>(Intercept) "0.223263"  "0.146167" "1.527459" "0.127173" ""
>>sex         "0.04983"   "0.039612" "1.257973" "0.20889"  "."
>>age         "-0.070423" "0.029539" "2.384035" "0.017433" ""
>>yrmarry     "0.015567"  "0.005298" "2.938126" "0.003429" ""
>>children    "0.060525"  "0.044778" "1.351659" "0.176993" "."
>>religius    "-0.053128" "0.014413" "3.68626"  "0.000248" ""
>>educ        "0.003226"  "0.008453" "0.381636" "0.702866" ""
>>occu        "0.003915"  "0.01186"  "0.330147" "0.741404" ""
>>rating      "-0.077856" "0.014466" "5.381925" "0"        ""
>
>Use data frames instead.
>
>out<-data.frame(round(cbind(me,se,t,p),digits)); out<-cbind(out,disc)
>names(out)<-c("estimates","s.e.","|t-value|","p-value","disc")
>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>
>--
>Kevin E. Thorpe
>Head of Biostatistics,  Applied Health Research Centre (AHRC)
>Li Ka Shing Knowledge Institute of St. Michael's
>Assistant Professor, Dalla Lana School of Public Health
>University of Toronto
>email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From tomnyberg at gmail.com  Wed Oct 29 16:23:05 2014
From: tomnyberg at gmail.com (Thomas Nyberg)
Date: Wed, 29 Oct 2014 11:23:05 -0400
Subject: [R] Using readLines on a file without resetting internal file
 offset parameter?
Message-ID: <54510659.5040503@gmail.com>

Hi everyone,

I would like to read a file line by line, but I would rather not load 
all lines into memory first. I've tried using readLines with n = 1, but 
that seems to reset the internal file descriptor's file offset after 
each call. I.e. this is the current behavior:

-------

bash $ echo 1 > testfile
bash $ echo 2 >> testfile
bash $ cat testfile
1
2

bash > R
R > f <- file('testfile')
R > readLines(f, n = 1)
[1] "1"
R > readLines(f, n = 1)
[1] "1"

-------

I would like the behavior to be:

-------

bash > R
R > f <- file('testfile')
R > readLines(f, n = 1)
[1] "1"
R > readLines(f, n = 1)
[1] "2"

-------

I'm coming to R from a python background, where the default behavior is 
exactly the opposite. I.e. when you read a line from a file it is your 
responsibility to use seek explicitly to get back to the original 
position in the file (this is rarely necessary though). Is there some 
flag to turn off the default behavior of resetting the file offset in R?

Cheers,
Thomas


From ben.bighair at gmail.com  Wed Oct 29 16:52:48 2014
From: ben.bighair at gmail.com (Ben Tupper)
Date: Wed, 29 Oct 2014 11:52:48 -0400
Subject: [R] Injecting a column of characters to a matrix of numerics
In-Reply-To: <54510abb.46dfec0a.3c7b.70ed@mx.google.com>
References: <54433b6d.28ceec0a.2acc.ffff8276@mx.google.com>
	<CAGx1TMCbCzvFO5Oa2-uMqUehrxpLULOmB4T6keMdid67eUdNyQ@mail.gmail.com>
	<5443629f.edcaec0a.1451.ffff88b9@mx.google.com>
	<544d3efe.72c9ec0a.692e.ffffeefe@mx.google.com>
	<544D414F.50303@sapo.pt> <544D422E.1050605@sapo.pt>
	<544d4402.26dcec0a.7867.fffff267@mx.google.com>
	<54510abb.46dfec0a.3c7b.70ed@mx.google.com>
Message-ID: <2260F281-2949-43E4-8407-1F573D1B90B6@gmail.com>

Hi,

On Oct 29, 2014, at 11:41 AM, Steven Yen <syen04 at gmail.com> wrote:

> Hello
> I am designing a regression printout, which works out nicely. Then, I try to inject a column of characters to indicate a discrete regressor with a dot (.). Then, all numbers seem to turn into characters, in quotations. Is there a way to do this right? Below, I show the lines of codes before and after. Thanks.
> Steven Yen
> 
> ---
> out<-round(cbind(me,se,t,p),digits)
> colnames(out)<-c("estimates","s.e.","|t-value|","p-value")
> rownames(out)<-rownames(me)
> out
>            estimates     s.e. |t-value|  p-value
> (Intercept)  0.223263 0.146167  1.527459 0.127173
> sex          0.049830 0.039612  1.257973 0.208890
> age         -0.070423 0.029539  2.384035 0.017433
> yrmarry      0.015567 0.005298  2.938126 0.003429
> children     0.060525 0.044778  1.351659 0.176993
> religius    -0.053128 0.014413  3.686260 0.000248
> educ         0.003226 0.008453  0.381636 0.702866
> occu         0.003915 0.011860  0.330147 0.741404
> rating      -0.077856 0.014466  5.381925 0.000000
> 
> out<-round(cbind(me,se,t,p),digits); out<-cbind(out,disc)
> colnames(out)<-c("estimates","s.e.","|t-value|","p-value","disc")
> rownames(out)<-rownames(me)
> 
> (Intercept) "0.223263"  "0.146167" "1.527459" "0.127173" ""
> sex         "0.04983"   "0.039612" "1.257973" "0.20889"  "."
> age         "-0.070423" "0.029539" "2.384035" "0.017433" ""
> yrmarry     "0.015567"  "0.005298" "2.938126" "0.003429" ""
> children    "0.060525"  "0.044778" "1.351659" "0.176993" "."
> religius    "-0.053128" "0.014413" "3.68626"  "0.000248" ""
> educ        "0.003226"  "0.008453" "0.381636" "0.702866" ""
> occu        "0.003915"  "0.01186"  "0.330147" "0.741404" ""
> rating      "-0.077856" "0.014466" "5.381925" "0"        ""
> 


It appears the 'out' is originally a numeric matrix, thus adding column of characters demotes the entire matrix to character.  Convert 'out' to data.frame to allow mixed data types.

> out<-round(cbind(me,se,t,p),digits); out <- as.data.frame(out) ; out<-cbind(out,disc)


Cheers,
Ben

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Wed Oct 29 17:13:11 2014
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 29 Oct 2014 12:13:11 -0400
Subject: [R] Ways to get all function signatures of a library?
In-Reply-To: <87mw8f6n0z.fsf@gmail.com>
References: <87mw8f6n0z.fsf@gmail.com>
Message-ID: <CAP01uRmWbkP57EUH0xrQW7pOerF5oD=k7wY2vpqfmjVGyDWSHg@mail.gmail.com>

On Wed, Oct 29, 2014 at 9:09 AM, Thorsten Jolitz <tjolitz at gmail.com> wrote:
>
> Hi List,
>
> are there ways to get signatures of all functions of a library in a
> format that is easy to process by a programm (list, xml or so)?
>
> The info about function name, return value and arguments (types) is all
> there in the docs, but more in a human readable format embedded in much
> extra information. How to extract it without writing a documentation
> parser or so? I'm pretty sure the functionality exists, but did not find
> it.
>

In general, R functions do not have argument and return types (and
don't even have to have names) but maybe this would do:

library(lattice) # need this for make.groups

# load the package of interest
library(zoo)

DF <- do.call(make.groups, Map(function(x) names(formals(get(x))),
ls("package:zoo")))
rownames(DF) <- NULL

giving:

> head(DF)
    data           which
1      x         as.Date
2    ...         as.Date
3      x as.Date.numeric
4 origin as.Date.numeric
5    ... as.Date.numeric
6      x      as.Date.ts





-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From wdunlap at tibco.com  Wed Oct 29 17:22:50 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 29 Oct 2014 09:22:50 -0700
Subject: [R] Using readLines on a file without resetting internal file
 offset parameter?
In-Reply-To: <54510659.5040503@gmail.com>
References: <54510659.5040503@gmail.com>
Message-ID: <CAF8bMcbO824By19oNgKosAK0R1FvnCLGzhAU30ET7KsXykqMbw@mail.gmail.com>

Open your file object before calling readLines and close it when you
are done with
a sequence of calls to readLines.

  > tf <- tempfile()
  > cat(sep="\n", letters[1:10], file=tf)
  > f <- file(tf)
  > open(f)
  > # or f <- file(tf, "r") instead of previous 2 lines
  > readLines(f, n=1)
  [1] "a"
  > readLines(f, n=1)
  [1] "b"
  > readLines(f, n=2)
  [1] "c" "d"
  > close(f)

I/O operations on an unopened connection generally open it, do the operation,
then close it.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 29, 2014 at 8:23 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
> Hi everyone,
>
> I would like to read a file line by line, but I would rather not load all
> lines into memory first. I've tried using readLines with n = 1, but that
> seems to reset the internal file descriptor's file offset after each call.
> I.e. this is the current behavior:
>
> -------
>
> bash $ echo 1 > testfile
> bash $ echo 2 >> testfile
> bash $ cat testfile
> 1
> 2
>
> bash > R
> R > f <- file('testfile')
> R > readLines(f, n = 1)
> [1] "1"
> R > readLines(f, n = 1)
> [1] "1"
>
> -------
>
> I would like the behavior to be:
>
> -------
>
> bash > R
> R > f <- file('testfile')
> R > readLines(f, n = 1)
> [1] "1"
> R > readLines(f, n = 1)
> [1] "2"
>
> -------
>
> I'm coming to R from a python background, where the default behavior is
> exactly the opposite. I.e. when you read a line from a file it is your
> responsibility to use seek explicitly to get back to the original position
> in the file (this is rarely necessary though). Is there some flag to turn
> off the default behavior of resetting the file offset in R?
>
> Cheers,
> Thomas
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Wed Oct 29 17:59:26 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 29 Oct 2014 09:59:26 -0700
Subject: [R] Using readLines on a file without resetting internal file
 offset parameter?
In-Reply-To: <54511AFA.9080601@gmail.com>
References: <54510659.5040503@gmail.com>
	<CAF8bMcbO824By19oNgKosAK0R1FvnCLGzhAU30ET7KsXykqMbw@mail.gmail.com>
	<54511AFA.9080601@gmail.com>
Message-ID: <CAF8bMcY0xvnmqqBd-bcwNQcMZLgYF2zBXtO5GX1T5JOMVxCw3Q@mail.gmail.com>

I meant you should close the file when you are done with it, not after
every few lines.
File descriptors are a limited resource.

As for the rationale for the default behavior, there is a common use
pattern of reading
and parsing an entire file (or url, etc.), examining the results, and trying
again with a different parsing scheme.  In that case the default
behavior works well.

In any case, I assume the behavior is documented in help("file").

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 29, 2014 at 9:51 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
> Thanks for the response! I'd rather keep the file open than close it, since
> it would flush the internal buffer. The whole reason I'm doing this is to
> take advantage of the buffering and closing it would defeat the purpose.
>
> I actually just found a solution which is to open the files with the "r"
> flag explicitly. I.e. the following is what I want.
>
> -----
>
> bash $ echo 1 > testfile
> bash $ echo 2 >> testfile
> bash $ cat testfile
> 1
> 2
>
> bash $ R
> R > f <- file('testfile', 'r')
> R > readLines(f, n = 1)
> [1] "1"
> R > readLines(f, n = 1)
> [1] "2"
> R > readLines(f, n = 1)
> character(0)
>
> -----
>
> If you want to use writeLines in this same fashion you'll also need to open
> the original file with the "w" as well.
>
> It's very odd that file('filename') will let you read from it, but will not
> act the same as file('filename', 'r') when it comes to readLines. Is this a
> bug or is there some reasoning behind this? Regardless, it's certainly
> extremely unintuitive.
>
> Thanks again for the response!
>
> Cheers,
> Thomas
>
>
> On 10/29/2014 12:22 PM, William Dunlap wrote:
>>
>> Open your file object before calling readLines and close it when you
>> are done with
>> a sequence of calls to readLines.
>>
>>    > tf <- tempfile()
>>    > cat(sep="\n", letters[1:10], file=tf)
>>    > f <- file(tf)
>>    > open(f)
>>    > # or f <- file(tf, "r") instead of previous 2 lines
>>    > readLines(f, n=1)
>>    [1] "a"
>>    > readLines(f, n=1)
>>    [1] "b"
>>    > readLines(f, n=2)
>>    [1] "c" "d"
>>    > close(f)
>>
>> I/O operations on an unopened connection generally open it, do the
>> operation,
>> then close it.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Oct 29, 2014 at 8:23 AM, Thomas Nyberg <tomnyberg at gmail.com>
>> wrote:
>>>
>>> Hi everyone,
>>>
>>> I would like to read a file line by line, but I would rather not load all
>>> lines into memory first. I've tried using readLines with n = 1, but that
>>> seems to reset the internal file descriptor's file offset after each
>>> call.
>>> I.e. this is the current behavior:
>>>
>>> -------
>>>
>>> bash $ echo 1 > testfile
>>> bash $ echo 2 >> testfile
>>> bash $ cat testfile
>>> 1
>>> 2
>>>
>>> bash > R
>>> R > f <- file('testfile')
>>> R > readLines(f, n = 1)
>>> [1] "1"
>>> R > readLines(f, n = 1)
>>> [1] "1"
>>>
>>> -------
>>>
>>> I would like the behavior to be:
>>>
>>> -------
>>>
>>> bash > R
>>> R > f <- file('testfile')
>>> R > readLines(f, n = 1)
>>> [1] "1"
>>> R > readLines(f, n = 1)
>>> [1] "2"
>>>
>>> -------
>>>
>>> I'm coming to R from a python background, where the default behavior is
>>> exactly the opposite. I.e. when you read a line from a file it is your
>>> responsibility to use seek explicitly to get back to the original
>>> position
>>> in the file (this is rarely necessary though). Is there some flag to turn
>>> off the default behavior of resetting the file offset in R?
>>>
>>> Cheers,
>>> Thomas
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From tomnyberg at gmail.com  Wed Oct 29 17:51:06 2014
From: tomnyberg at gmail.com (Thomas Nyberg)
Date: Wed, 29 Oct 2014 12:51:06 -0400
Subject: [R] Using readLines on a file without resetting internal file
 offset parameter?
In-Reply-To: <CAF8bMcbO824By19oNgKosAK0R1FvnCLGzhAU30ET7KsXykqMbw@mail.gmail.com>
References: <54510659.5040503@gmail.com>
	<CAF8bMcbO824By19oNgKosAK0R1FvnCLGzhAU30ET7KsXykqMbw@mail.gmail.com>
Message-ID: <54511AFA.9080601@gmail.com>

Thanks for the response! I'd rather keep the file open than close it, 
since it would flush the internal buffer. The whole reason I'm doing 
this is to take advantage of the buffering and closing it would defeat 
the purpose.

I actually just found a solution which is to open the files with the "r" 
flag explicitly. I.e. the following is what I want.

-----

bash $ echo 1 > testfile
bash $ echo 2 >> testfile
bash $ cat testfile
1
2

bash $ R
R > f <- file('testfile', 'r')
R > readLines(f, n = 1)
[1] "1"
R > readLines(f, n = 1)
[1] "2"
R > readLines(f, n = 1)
character(0)

-----

If you want to use writeLines in this same fashion you'll also need to 
open the original file with the "w" as well.

It's very odd that file('filename') will let you read from it, but will 
not act the same as file('filename', 'r') when it comes to readLines. Is 
this a bug or is there some reasoning behind this? Regardless, it's 
certainly extremely unintuitive.

Thanks again for the response!

Cheers,
Thomas

On 10/29/2014 12:22 PM, William Dunlap wrote:
> Open your file object before calling readLines and close it when you
> are done with
> a sequence of calls to readLines.
>
>    > tf <- tempfile()
>    > cat(sep="\n", letters[1:10], file=tf)
>    > f <- file(tf)
>    > open(f)
>    > # or f <- file(tf, "r") instead of previous 2 lines
>    > readLines(f, n=1)
>    [1] "a"
>    > readLines(f, n=1)
>    [1] "b"
>    > readLines(f, n=2)
>    [1] "c" "d"
>    > close(f)
>
> I/O operations on an unopened connection generally open it, do the operation,
> then close it.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Oct 29, 2014 at 8:23 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
>> Hi everyone,
>>
>> I would like to read a file line by line, but I would rather not load all
>> lines into memory first. I've tried using readLines with n = 1, but that
>> seems to reset the internal file descriptor's file offset after each call.
>> I.e. this is the current behavior:
>>
>> -------
>>
>> bash $ echo 1 > testfile
>> bash $ echo 2 >> testfile
>> bash $ cat testfile
>> 1
>> 2
>>
>> bash > R
>> R > f <- file('testfile')
>> R > readLines(f, n = 1)
>> [1] "1"
>> R > readLines(f, n = 1)
>> [1] "1"
>>
>> -------
>>
>> I would like the behavior to be:
>>
>> -------
>>
>> bash > R
>> R > f <- file('testfile')
>> R > readLines(f, n = 1)
>> [1] "1"
>> R > readLines(f, n = 1)
>> [1] "2"
>>
>> -------
>>
>> I'm coming to R from a python background, where the default behavior is
>> exactly the opposite. I.e. when you read a line from a file it is your
>> responsibility to use seek explicitly to get back to the original position
>> in the file (this is rarely necessary though). Is there some flag to turn
>> off the default behavior of resetting the file offset in R?
>>
>> Cheers,
>> Thomas
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jan.vanvinkenroye at tik.uni-stuttgart.de  Wed Oct 29 17:56:47 2014
From: jan.vanvinkenroye at tik.uni-stuttgart.de (Jan Vanvinkenroye)
Date: Wed, 29 Oct 2014 17:56:47 +0100
Subject: [R] Fwd: Combining stacked bar charts for logfile analysis
References: <52FDE8FF-8B52-47EA-916C-41479EF850E0@tik.uni-stuttgart.de>
Message-ID: <C93CA7FB-6E87-4DA7-AFA0-0C755E47B48B@tik.uni-stuttgart.de>



Anfang der weitergeleiteten Nachricht:

Von: Jan Vanvinkenroye <jan.vanvinkenroye at tik.uni-stuttgart.de>
Datum: 29. Oktober 2014 17:52:06 MEZ
Betreff: Combining stacked bar charts for logfile analysis
An: r-help at r-project.org

Hello Everyone,

in order to assess webserver response time i would like to combine some information from
a apache logfile. [1] This is my first project using R and I would be very gratefull if someone
could help me or point me in the right direction :): 


So far I managed to read the file to a dataframe, factorize the response time (duration_microseconds) to 
three discrete classes ("gut", "ok", "schlecht") <=50000,<=200000ms,<20000ms. 

barplot(table(access_log$bewertung), beside = FALSE, width = 1, xlab="Response Time", ylab="Percentage", col=c("green", "yellow", "red"))

gives me an aggregated percentage of response time of every request in the logfile and

qplot(time, duration_microseconds, data=access_log, shape=bewertung)

returns plot of the response times over time. 


How can i combine both plots with a stacked bar chart/hour/day? The given example only contains only 20 lines
the original log file serveral thousand. A plot of this information led to a somehow crowded (=mostly black) 
plot. 




[1] my data.frame
access_log <-
structure(list(host = structure(c(7L, 7L, 7L, 7L, 7L, 7L, 7L, 
7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L), .Label = c("126.88.69.199", 
"141.43.100.201", "141.58.109.90", "141.58.110.210", "0.0.0.0", 
"141.58.1", "1.1.1.1"), class = "factor"), time = c("2014-07-17 16:25:02", 
"2014-07-17 16:25:02", "2014-07-17 16:25:02", "2014-07-17 16:25:08", 
"2014-07-17 16:25:02", "2014-07-17 16:25:02", "2014-07-17 16:25:12", 
"2014-07-17 16:25:13", "2014-07-17 16:25:13", "2014-07-17 16:25:12", 
"2014-07-17 16:25:02", "2014-07-17 16:25:02", "2014-07-17 16:25:02", 
"2014-07-17 16:25:08", "2014-07-17 16:25:02", "2014-07-17 16:25:02", 
"2014-07-17 16:25:12", "2014-07-17 16:25:13", "2014-07-17 16:25:13", 
"2014-07-17 16:25:12"), time_zone = structure(c(1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L
), .Label = "+0200", class = "factor"), request = structure(c(4L, 
4L, 4L, 4L, 1L, 1L, 3L, 4L, 1L, 2L, 4L, 4L, 4L, 4L, 1L, 1L, 3L, 
4L, 1L, 2L), .Label = c("GET /home/ HTTP/1.1", "GET /home/bildergalerie/Beratung.jpg HTTP/1.1", 
"GET /home/css/realm_xhtml_2.0.css HTTP/1.1", "GET /home/r.html HTTP/1.1"
), class = "factor"), status = structure(c(2L, 2L, 2L, 2L, 1L, 
1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L), .Label = c("200", 
"302"), class = "factor"), bytes = structure(c(1L, 1L, 1L, 1L, 
3L, 3L, 4L, 1L, 3L, 2L, 1L, 1L, 1L, 1L, 3L, 3L, 4L, 1L, 3L, 2L
), .Label = c("-", "109640", "27930", "856"), class = "factor"), 
   referal = structure(c(1L, 1L, 2L, 1L, 2L, 1L, 3L, 1L, 1L, 
   3L, 1L, 1L, 2L, 1L, 2L, 1L, 3L, 1L, 1L, 3L), .Label = c("-", 
   "http://en.wikipedia.org/wiki/University_of_Stuttgart", "http://www.uni-stuttgart.de/home/"
   ), class = "factor"), browser = structure(c(2L, 2L, 3L, 1L, 
   3L, 2L, 3L, 2L, 1L, 3L, 2L, 2L, 3L, 1L, 3L, 2L, 3L, 2L, 1L, 
   3L), .Label = c("libwww-perl/5.805", "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)", 
   "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2095.0 Safari/537.36"
   ), class = "factor"), duration_seconds = c(0, 0, 0, 0, 8, 
   9, 0, 0, 0, 1, 0, 0, 0, 0, 8, 9, 0, 0, 0, 1), duration_microseconds = c(11263, 
   2386, 1626, 1970, 8944261, 9474883, 1018, 2953, 73138, 1080564, 
   11263, 2386, 1626, 1970, 8944261, 9474883, 1018, 2953, 73138, 
   1080564), bewertung = structure(c(1L, 1L, 1L, 1L, 3L, 3L, 
   1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 3L, 3L, 1L, 1L, 1L, 2L), .Label = c("gut", 
   "ok", "schlecht"), class = "factor")), .Names = c("host", 
"time", "time_zone", "request", "status", "bytes", "referal", 
"browser", "duration_seconds", "duration_microseconds", "bewertung"
), row.names = c(NA, 20L), class = "data.frame")







--- 

mit freundlichen Gr??en

Jan Vanvinkenroye

Jan Vanvinkenroye, Dipl. P?d., Evasys- / Vitero Adminstration, Forschung & Evaluation
Informations- und Kommunikationszentrum der Universit?t Stuttgart (IZUS)
Technische Informations- und Kommunikationsdienste (TIK-Dienste, ehem. RUS)
Abteilung f?r Neue Medien in Forschung und Lehre (NFL)
Allmandring 30a ? 70550 Stuttgart ? Tel +49(0)711-685-87325 ? Fax +49(0)711-685-77325 
jan.vanvinkenroye at tik.uni-stuttgart.de ? http://www.izus.uni-stuttgart.de/


From cjohndavies at gmail.com  Wed Oct 29 18:12:19 2014
From: cjohndavies at gmail.com (CJ Davies)
Date: Wed, 29 Oct 2014 17:12:19 +0000
Subject: [R]  Variance of multiple non-contiguous time periods?
Message-ID: <54511FF3.5090606@gmail.com>

I am trying to show that the red line ('yaw') in the upper of the two 
plots here;

http://i.imgur.com/N4Xxb4f.png

varies more within the pink sections ('transition 1') than in the light 
blue sections ('real').

I tried to use var.test() however this runs into a problem because 
although the red line doesn't vary much *within* any particular light 
blue section, it does vary a lot *between* light blue sections.

For example, in the light blue section around t=90 the red line doesn't 
move much & likewise in the light blue section around t=160 the red line 
doesn't move much. But between these two sections the red line has moved 
substantially.

So if I simply subset the data according to pink/light blue & then put 
those resultant subsets into var.test(), the answer does not show the 
relationship that I want it to.

Can anybody shed some light on a sensible method of solving this?

Regards,
CJ Davies


From tomnyberg at gmail.com  Wed Oct 29 18:12:54 2014
From: tomnyberg at gmail.com (Thomas Nyberg)
Date: Wed, 29 Oct 2014 13:12:54 -0400
Subject: [R] Using readLines on a file without resetting internal file
 offset parameter?
In-Reply-To: <CAF8bMcY0xvnmqqBd-bcwNQcMZLgYF2zBXtO5GX1T5JOMVxCw3Q@mail.gmail.com>
References: <54510659.5040503@gmail.com>
	<CAF8bMcbO824By19oNgKosAK0R1FvnCLGzhAU30ET7KsXykqMbw@mail.gmail.com>
	<54511AFA.9080601@gmail.com>
	<CAF8bMcY0xvnmqqBd-bcwNQcMZLgYF2zBXtO5GX1T5JOMVxCw3Q@mail.gmail.com>
Message-ID: <54512016.7080701@gmail.com>

Yeah of course you should close the file when done. I didn't give a 
complete code snippet.

In any case, a quick glance at the documentation seems to imply that 
opening a file as file('filename') will defer the choice of mode (i.e. 
is it 'r', 'w', etc.?) until it is first used. In my case the first use 
is a read, so it should presumably be set to "r". However as shown in my 
examples this does work differently than opening it as 
file('filename','r') in the first place.

I do agree that it is reasonable that the default behavior of 
readLines/writeLines might be to reset the file offset each time, but I 
certainly do not agree that that should be happening dependent upon 
whether the original file is opened without 'r' and then read from 
versus being opened with 'r' in the first place. That kind of a 
side-effect really makes no sense to me and is entirely unintuitive. If 
the goal was to have the default behavior to reset the file offset, a 
reasonable thing would be to have a flag in readLines like 
reset_fileoffset = TRUE or something like that.

In any case, thanks so much for the help!

Cheers,
Thomas

On 10/29/2014 12:59 PM, William Dunlap wrote:
> I meant you should close the file when you are done with it, not after
> every few lines.
> File descriptors are a limited resource.
>
> As for the rationale for the default behavior, there is a common use
> pattern of reading
> and parsing an entire file (or url, etc.), examining the results, and trying
> again with a different parsing scheme.  In that case the default
> behavior works well.
>
> In any case, I assume the behavior is documented in help("file").
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Wed, Oct 29, 2014 at 9:51 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
>> Thanks for the response! I'd rather keep the file open than close it, since
>> it would flush the internal buffer. The whole reason I'm doing this is to
>> take advantage of the buffering and closing it would defeat the purpose.
>>
>> I actually just found a solution which is to open the files with the "r"
>> flag explicitly. I.e. the following is what I want.
>>
>> -----
>>
>> bash $ echo 1 > testfile
>> bash $ echo 2 >> testfile
>> bash $ cat testfile
>> 1
>> 2
>>
>> bash $ R
>> R > f <- file('testfile', 'r')
>> R > readLines(f, n = 1)
>> [1] "1"
>> R > readLines(f, n = 1)
>> [1] "2"
>> R > readLines(f, n = 1)
>> character(0)
>>
>> -----
>>
>> If you want to use writeLines in this same fashion you'll also need to open
>> the original file with the "w" as well.
>>
>> It's very odd that file('filename') will let you read from it, but will not
>> act the same as file('filename', 'r') when it comes to readLines. Is this a
>> bug or is there some reasoning behind this? Regardless, it's certainly
>> extremely unintuitive.
>>
>> Thanks again for the response!
>>
>> Cheers,
>> Thomas
>>
>>
>> On 10/29/2014 12:22 PM, William Dunlap wrote:
>>>
>>> Open your file object before calling readLines and close it when you
>>> are done with
>>> a sequence of calls to readLines.
>>>
>>>     > tf <- tempfile()
>>>     > cat(sep="\n", letters[1:10], file=tf)
>>>     > f <- file(tf)
>>>     > open(f)
>>>     > # or f <- file(tf, "r") instead of previous 2 lines
>>>     > readLines(f, n=1)
>>>     [1] "a"
>>>     > readLines(f, n=1)
>>>     [1] "b"
>>>     > readLines(f, n=2)
>>>     [1] "c" "d"
>>>     > close(f)
>>>
>>> I/O operations on an unopened connection generally open it, do the
>>> operation,
>>> then close it.
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Wed, Oct 29, 2014 at 8:23 AM, Thomas Nyberg <tomnyberg at gmail.com>
>>> wrote:
>>>>
>>>> Hi everyone,
>>>>
>>>> I would like to read a file line by line, but I would rather not load all
>>>> lines into memory first. I've tried using readLines with n = 1, but that
>>>> seems to reset the internal file descriptor's file offset after each
>>>> call.
>>>> I.e. this is the current behavior:
>>>>
>>>> -------
>>>>
>>>> bash $ echo 1 > testfile
>>>> bash $ echo 2 >> testfile
>>>> bash $ cat testfile
>>>> 1
>>>> 2
>>>>
>>>> bash > R
>>>> R > f <- file('testfile')
>>>> R > readLines(f, n = 1)
>>>> [1] "1"
>>>> R > readLines(f, n = 1)
>>>> [1] "1"
>>>>
>>>> -------
>>>>
>>>> I would like the behavior to be:
>>>>
>>>> -------
>>>>
>>>> bash > R
>>>> R > f <- file('testfile')
>>>> R > readLines(f, n = 1)
>>>> [1] "1"
>>>> R > readLines(f, n = 1)
>>>> [1] "2"
>>>>
>>>> -------
>>>>
>>>> I'm coming to R from a python background, where the default behavior is
>>>> exactly the opposite. I.e. when you read a line from a file it is your
>>>> responsibility to use seek explicitly to get back to the original
>>>> position
>>>> in the file (this is rarely necessary though). Is there some flag to turn
>>>> off the default behavior of resetting the file offset in R?
>>>>
>>>> Cheers,
>>>> Thomas
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From psegurado at isa.ulisboa.pt  Wed Oct 29 18:20:13 2014
From: psegurado at isa.ulisboa.pt (Pedro Segurado)
Date: Wed, 29 Oct 2014 17:20:13 -0000
Subject: [R] problem in loop using windows executable
Message-ID: <000001cff39c$9c951f20$d5bf5d60$@isa.ulisboa.pt>

Dear all,

I am trying to develop a R script that basically uses a loop that includes 5
main steps: (1) it runs a windows executable file outside R that requires a
set of *.txt files using the shell function (Note: I have tried system and
system(shhQuote()) and the problem remains), (2) it imports the output txt
file of the executable, (3) it deletes the existing input txt files from the
windows folder, (4) it uses values of the imported output file to help
producing new tables to be used as input files to the executable and (5) it
exports those tables in txt format to the windows folder.

Now the problem. I am running this script in a laptop. I have change the
energy saving settings to the highest performance possible, it no energy
saving options at all. If I move the mouse frequently there is no problem,
the whole process is not interrupted. However, if I do not move the mouse,
the process stops (not always in the same loop and the same file) with the
following error:

Error in file(file, ifelse(append, "a", "w")) : 
  cannot open the connection
In addition: Warning message:
In file(file, ifelse(append, "a", "w")) :
  cannot open file 'nodes_29.txt': Permission denied

The file "nodes_29.txt" is one of the executable input files that is
produced in the loop, which can have the same name as previous txt files
that were meanwhile deleted in previous loops (again, please note that the
error is not always in the same loop number and the same file). 

Any idea?

Thanks!
Pedro


From wdunlap at tibco.com  Wed Oct 29 18:51:37 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 29 Oct 2014 10:51:37 -0700
Subject: [R] Using readLines on a file without resetting internal file
 offset parameter?
In-Reply-To: <54512016.7080701@gmail.com>
References: <54510659.5040503@gmail.com>
	<CAF8bMcbO824By19oNgKosAK0R1FvnCLGzhAU30ET7KsXykqMbw@mail.gmail.com>
	<54511AFA.9080601@gmail.com>
	<CAF8bMcY0xvnmqqBd-bcwNQcMZLgYF2zBXtO5GX1T5JOMVxCw3Q@mail.gmail.com>
	<54512016.7080701@gmail.com>
Message-ID: <CAF8bMcamhC=5J18CqhG1Aq0KJ=-ZvrGQg071Z5H15OkSsJ_Ldg@mail.gmail.com>

I agree that file's use of its 'mode' argument can be confusing.  That is
one reason I didn't use it my example and made an explicit call to open()
after calling file() without the mode argument.

(Having to distinguish between 'binary' and 'text' mode on Windows,
'rb' and 'rt'
or 'wb' and 'wt', can add to the confusion.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Wed, Oct 29, 2014 at 10:12 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
> Yeah of course you should close the file when done. I didn't give a complete
> code snippet.
>
> In any case, a quick glance at the documentation seems to imply that opening
> a file as file('filename') will defer the choice of mode (i.e. is it 'r',
> 'w', etc.?) until it is first used. In my case the first use is a read, so
> it should presumably be set to "r". However as shown in my examples this
> does work differently than opening it as file('filename','r') in the first
> place.
>
> I do agree that it is reasonable that the default behavior of
> readLines/writeLines might be to reset the file offset each time, but I
> certainly do not agree that that should be happening dependent upon whether
> the original file is opened without 'r' and then read from versus being
> opened with 'r' in the first place. That kind of a side-effect really makes
> no sense to me and is entirely unintuitive. If the goal was to have the
> default behavior to reset the file offset, a reasonable thing would be to
> have a flag in readLines like reset_fileoffset = TRUE or something like
> that.
>
> In any case, thanks so much for the help!
>
> Cheers,
> Thomas
>
>
> On 10/29/2014 12:59 PM, William Dunlap wrote:
>>
>> I meant you should close the file when you are done with it, not after
>> every few lines.
>> File descriptors are a limited resource.
>>
>> As for the rationale for the default behavior, there is a common use
>> pattern of reading
>> and parsing an entire file (or url, etc.), examining the results, and
>> trying
>> again with a different parsing scheme.  In that case the default
>> behavior works well.
>>
>> In any case, I assume the behavior is documented in help("file").
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Wed, Oct 29, 2014 at 9:51 AM, Thomas Nyberg <tomnyberg at gmail.com>
>> wrote:
>>>
>>> Thanks for the response! I'd rather keep the file open than close it,
>>> since
>>> it would flush the internal buffer. The whole reason I'm doing this is to
>>> take advantage of the buffering and closing it would defeat the purpose.
>>>
>>> I actually just found a solution which is to open the files with the "r"
>>> flag explicitly. I.e. the following is what I want.
>>>
>>> -----
>>>
>>> bash $ echo 1 > testfile
>>> bash $ echo 2 >> testfile
>>> bash $ cat testfile
>>> 1
>>> 2
>>>
>>> bash $ R
>>> R > f <- file('testfile', 'r')
>>> R > readLines(f, n = 1)
>>> [1] "1"
>>> R > readLines(f, n = 1)
>>> [1] "2"
>>> R > readLines(f, n = 1)
>>> character(0)
>>>
>>> -----
>>>
>>> If you want to use writeLines in this same fashion you'll also need to
>>> open
>>> the original file with the "w" as well.
>>>
>>> It's very odd that file('filename') will let you read from it, but will
>>> not
>>> act the same as file('filename', 'r') when it comes to readLines. Is this
>>> a
>>> bug or is there some reasoning behind this? Regardless, it's certainly
>>> extremely unintuitive.
>>>
>>> Thanks again for the response!
>>>
>>> Cheers,
>>> Thomas
>>>
>>>
>>> On 10/29/2014 12:22 PM, William Dunlap wrote:
>>>>
>>>>
>>>> Open your file object before calling readLines and close it when you
>>>> are done with
>>>> a sequence of calls to readLines.
>>>>
>>>>     > tf <- tempfile()
>>>>     > cat(sep="\n", letters[1:10], file=tf)
>>>>     > f <- file(tf)
>>>>     > open(f)
>>>>     > # or f <- file(tf, "r") instead of previous 2 lines
>>>>     > readLines(f, n=1)
>>>>     [1] "a"
>>>>     > readLines(f, n=1)
>>>>     [1] "b"
>>>>     > readLines(f, n=2)
>>>>     [1] "c" "d"
>>>>     > close(f)
>>>>
>>>> I/O operations on an unopened connection generally open it, do the
>>>> operation,
>>>> then close it.
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>
>>>> On Wed, Oct 29, 2014 at 8:23 AM, Thomas Nyberg <tomnyberg at gmail.com>
>>>> wrote:
>>>>>
>>>>>
>>>>> Hi everyone,
>>>>>
>>>>> I would like to read a file line by line, but I would rather not load
>>>>> all
>>>>> lines into memory first. I've tried using readLines with n = 1, but
>>>>> that
>>>>> seems to reset the internal file descriptor's file offset after each
>>>>> call.
>>>>> I.e. this is the current behavior:
>>>>>
>>>>> -------
>>>>>
>>>>> bash $ echo 1 > testfile
>>>>> bash $ echo 2 >> testfile
>>>>> bash $ cat testfile
>>>>> 1
>>>>> 2
>>>>>
>>>>> bash > R
>>>>> R > f <- file('testfile')
>>>>> R > readLines(f, n = 1)
>>>>> [1] "1"
>>>>> R > readLines(f, n = 1)
>>>>> [1] "1"
>>>>>
>>>>> -------
>>>>>
>>>>> I would like the behavior to be:
>>>>>
>>>>> -------
>>>>>
>>>>> bash > R
>>>>> R > f <- file('testfile')
>>>>> R > readLines(f, n = 1)
>>>>> [1] "1"
>>>>> R > readLines(f, n = 1)
>>>>> [1] "2"
>>>>>
>>>>> -------
>>>>>
>>>>> I'm coming to R from a python background, where the default behavior is
>>>>> exactly the opposite. I.e. when you read a line from a file it is your
>>>>> responsibility to use seek explicitly to get back to the original
>>>>> position
>>>>> in the file (this is rarely necessary though). Is there some flag to
>>>>> turn
>>>>> off the default behavior of resetting the file offset in R?
>>>>>
>>>>> Cheers,
>>>>> Thomas
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Oct 29 18:53:47 2014
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 29 Oct 2014 10:53:47 -0700
Subject: [R] Fwd: Combining stacked bar charts for logfile analysis
In-Reply-To: <C93CA7FB-6E87-4DA7-AFA0-0C755E47B48B@tik.uni-stuttgart.de>
References: <52FDE8FF-8B52-47EA-916C-41479EF850E0@tik.uni-stuttgart.de>
	<C93CA7FB-6E87-4DA7-AFA0-0C755E47B48B@tik.uni-stuttgart.de>
Message-ID: <CAGx1TMC=x7=2AxTnVQpGT-fGnmiJscpjpns6AUtwU9AGQHwMWA@mail.gmail.com>

Jan,

Thank you for posting a reproducible example.
This is my first pass at providing a stacked bar chart by time.  I have placed
schlecht on the negative side and both ok and gut on the positive side.
I don't know what you mean by percent from this data snippet.
I show how to produce a likert plot using both counts or percents.
You might want time on a different granularity,
There are many more options in likert, see ?likert and demo(likert) for details.

Time.bewertung <- with(access_log, table(as.POSIXct(access_log$time),
bewertung))
install.packages("HH")  ## if you don't have it yet
library(HH)
likert(Time.bewertung[,3:1], ReferenceZero=1.5)
likert(Time.bewertung[,3:1], ReferenceZero=1.5, as.percent=TRUE)

Rich

On Wed, Oct 29, 2014 at 9:56 AM, Jan Vanvinkenroye
<jan.vanvinkenroye at tik.uni-stuttgart.de> wrote:
>
>
> Anfang der weitergeleiteten Nachricht:
>
> Von: Jan Vanvinkenroye <jan.vanvinkenroye at tik.uni-stuttgart.de>
> Datum: 29. Oktober 2014 17:52:06 MEZ
> Betreff: Combining stacked bar charts for logfile analysis
> An: r-help at r-project.org
>
> Hello Everyone,
>
> in order to assess webserver response time i would like to combine some information from
> a apache logfile. [1] This is my first project using R and I would be very gratefull if someone
> could help me or point me in the right direction :):
>
>
> So far I managed to read the file to a dataframe, factorize the response time (duration_microseconds) to
> three discrete classes ("gut", "ok", "schlecht") <=50000,<=200000ms,<20000ms.
>
> barplot(table(access_log$bewertung), beside = FALSE, width = 1, xlab="Response Time", ylab="Percentage", col=c("green", "yellow", "red"))
>
> gives me an aggregated percentage of response time of every request in the logfile and
>
> qplot(time, duration_microseconds, data=access_log, shape=bewertung)
>
> returns plot of the response times over time.
>
>
> How can i combine both plots with a stacked bar chart/hour/day? The given example only contains only 20 lines
> the original log file serveral thousand. A plot of this information led to a somehow crowded (=mostly black)
> plot.
>
>
>
>
> [1] my data.frame
> access_log <-
> structure(list(host = structure(c(7L, 7L, 7L, 7L, 7L, 7L, 7L,
> 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 7L), .Label = c("126.88.69.199",
> "141.43.100.201", "141.58.109.90", "141.58.110.210", "0.0.0.0",
> "141.58.1", "1.1.1.1"), class = "factor"), time = c("2014-07-17 16:25:02",
> "2014-07-17 16:25:02", "2014-07-17 16:25:02", "2014-07-17 16:25:08",
> "2014-07-17 16:25:02", "2014-07-17 16:25:02", "2014-07-17 16:25:12",
> "2014-07-17 16:25:13", "2014-07-17 16:25:13", "2014-07-17 16:25:12",
> "2014-07-17 16:25:02", "2014-07-17 16:25:02", "2014-07-17 16:25:02",
> "2014-07-17 16:25:08", "2014-07-17 16:25:02", "2014-07-17 16:25:02",
> "2014-07-17 16:25:12", "2014-07-17 16:25:13", "2014-07-17 16:25:13",
> "2014-07-17 16:25:12"), time_zone = structure(c(1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L
> ), .Label = "+0200", class = "factor"), request = structure(c(4L,
> 4L, 4L, 4L, 1L, 1L, 3L, 4L, 1L, 2L, 4L, 4L, 4L, 4L, 1L, 1L, 3L,
> 4L, 1L, 2L), .Label = c("GET /home/ HTTP/1.1", "GET /home/bildergalerie/Beratung.jpg HTTP/1.1",
> "GET /home/css/realm_xhtml_2.0.css HTTP/1.1", "GET /home/r.html HTTP/1.1"
> ), class = "factor"), status = structure(c(2L, 2L, 2L, 2L, 1L,
> 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 2L, 1L, 1L), .Label = c("200",
> "302"), class = "factor"), bytes = structure(c(1L, 1L, 1L, 1L,
> 3L, 3L, 4L, 1L, 3L, 2L, 1L, 1L, 1L, 1L, 3L, 3L, 4L, 1L, 3L, 2L
> ), .Label = c("-", "109640", "27930", "856"), class = "factor"),
>    referal = structure(c(1L, 1L, 2L, 1L, 2L, 1L, 3L, 1L, 1L,
>    3L, 1L, 1L, 2L, 1L, 2L, 1L, 3L, 1L, 1L, 3L), .Label = c("-",
>    "http://en.wikipedia.org/wiki/University_of_Stuttgart", "http://www.uni-stuttgart.de/home/"
>    ), class = "factor"), browser = structure(c(2L, 2L, 3L, 1L,
>    3L, 2L, 3L, 2L, 1L, 3L, 2L, 2L, 3L, 1L, 3L, 2L, 3L, 2L, 1L,
>    3L), .Label = c("libwww-perl/5.805", "Mozilla/5.0 (compatible; MSIE 9.0; Windows NT 6.1; Trident/5.0)",
>    "Mozilla/5.0 (Windows NT 6.1; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/38.0.2095.0 Safari/537.36"
>    ), class = "factor"), duration_seconds = c(0, 0, 0, 0, 8,
>    9, 0, 0, 0, 1, 0, 0, 0, 0, 8, 9, 0, 0, 0, 1), duration_microseconds = c(11263,
>    2386, 1626, 1970, 8944261, 9474883, 1018, 2953, 73138, 1080564,
>    11263, 2386, 1626, 1970, 8944261, 9474883, 1018, 2953, 73138,
>    1080564), bewertung = structure(c(1L, 1L, 1L, 1L, 3L, 3L,
>    1L, 1L, 1L, 2L, 1L, 1L, 1L, 1L, 3L, 3L, 1L, 1L, 1L, 2L), .Label = c("gut",
>    "ok", "schlecht"), class = "factor")), .Names = c("host",
> "time", "time_zone", "request", "status", "bytes", "referal",
> "browser", "duration_seconds", "duration_microseconds", "bewertung"
> ), row.names = c(NA, 20L), class = "data.frame")
>
>
>
>
>
>
>
> ---
>
> mit freundlichen Gr??en
>
> Jan Vanvinkenroye
>
> Jan Vanvinkenroye, Dipl. P?d., Evasys- / Vitero Adminstration, Forschung & Evaluation
> Informations- und Kommunikationszentrum der Universit?t Stuttgart (IZUS)
> Technische Informations- und Kommunikationsdienste (TIK-Dienste, ehem. RUS)
> Abteilung f?r Neue Medien in Forschung und Lehre (NFL)
> Allmandring 30a ? 70550 Stuttgart ? Tel +49(0)711-685-87325 ? Fax +49(0)711-685-77325
> jan.vanvinkenroye at tik.uni-stuttgart.de ? http://www.izus.uni-stuttgart.de/
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Oct 29 20:00:37 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 29 Oct 2014 12:00:37 -0700
Subject: [R] problem in loop using windows executable
In-Reply-To: <000001cff39c$9c951f20$d5bf5d60$@isa.ulisboa.pt>
References: <000001cff39c$9c951f20$d5bf5d60$@isa.ulisboa.pt>
Message-ID: <A205E16A-6618-4D97-9099-167977F19035@dcn.davis.CA.us>

My suggestion is that you provide a reproducible example, as the Posting Guide requests.

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 29, 2014 10:20:13 AM PDT, Pedro Segurado <psegurado at isa.ulisboa.pt> wrote:
>Dear all,
>
>I am trying to develop a R script that basically uses a loop that
>includes 5
>main steps: (1) it runs a windows executable file outside R that
>requires a
>set of *.txt files using the shell function (Note: I have tried system
>and
>system(shhQuote()) and the problem remains), (2) it imports the output
>txt
>file of the executable, (3) it deletes the existing input txt files
>from the
>windows folder, (4) it uses values of the imported output file to help
>producing new tables to be used as input files to the executable and
>(5) it
>exports those tables in txt format to the windows folder.
>
>Now the problem. I am running this script in a laptop. I have change
>the
>energy saving settings to the highest performance possible, it no
>energy
>saving options at all. If I move the mouse frequently there is no
>problem,
>the whole process is not interrupted. However, if I do not move the
>mouse,
>the process stops (not always in the same loop and the same file) with
>the
>following error:
>
>Error in file(file, ifelse(append, "a", "w")) : 
>  cannot open the connection
>In addition: Warning message:
>In file(file, ifelse(append, "a", "w")) :
>  cannot open file 'nodes_29.txt': Permission denied
>
>The file "nodes_29.txt" is one of the executable input files that is
>produced in the loop, which can have the same name as previous txt
>files
>that were meanwhile deleted in previous loops (again, please note that
>the
>error is not always in the same loop number and the same file). 
>
>Any idea?
>
>Thanks!
>Pedro
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tjolitz at gmail.com  Wed Oct 29 19:48:36 2014
From: tjolitz at gmail.com (Thorsten Jolitz)
Date: Wed, 29 Oct 2014 19:48:36 +0100
Subject: [R] Ways to get all function signatures of a library?
References: <87mw8f6n0z.fsf@gmail.com>
	<CAP01uRmWbkP57EUH0xrQW7pOerF5oD=k7wY2vpqfmjVGyDWSHg@mail.gmail.com>
Message-ID: <87bnou7lvf.fsf@gmail.com>

Gabor Grothendieck <ggrothendieck at gmail.com> writes:

> On Wed, Oct 29, 2014 at 9:09 AM, Thorsten Jolitz <tjolitz at gmail.com> wrote:
>>
>> Hi List,
>>
>> are there ways to get signatures of all functions of a library in a
>> format that is easy to process by a programm (list, xml or so)?
>>
>> The info about function name, return value and arguments (types) is all
>> there in the docs, but more in a human readable format embedded in much
>> extra information. How to extract it without writing a documentation
>> parser or so? I'm pretty sure the functionality exists, but did not find
>> it.
>>
>
> In general, R functions do not have argument and return types (and
> don't even have to have names) but maybe this would do:
 
Thats ok, I only need to know about it. Makes calling these functions
even easier.

> library(lattice) # need this for make.groups
>
> # load the package of interest
> library(zoo)
>
> DF <- do.call(make.groups, Map(function(x) names(formals(get(x))),
> ls("package:zoo")))
> rownames(DF) <- NULL
>
> giving:
>
>> head(DF)
>     data           which
> 1      x         as.Date
> 2    ...         as.Date
> 3      x as.Date.numeric
> 4 origin as.Date.numeric
> 5    ... as.Date.numeric
> 6      x      as.Date.ts

Thats a nice solution, thanks a lot! 

-- 
cheers,
Thorsten


From alemu.tadesse at gmail.com  Wed Oct 29 20:20:59 2014
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Wed, 29 Oct 2014 13:20:59 -0600
Subject: [R] reading data from a web
Message-ID: <CACGkHRON9pKPdRRZLqDwdO87nx5kXj6wMVZ+mAStZ35wLPwRZg@mail.gmail.com>

Dear All,

I have data of the format shown in the link
http://www.data.jma.go.jp/gmd/env/data/radiation/data/geppo/201004/DR201004_sap.txt
 that I need to read. I have downloaded all the data from the link and I
have it on my computer. I used the following script (got it from web) and
was able to read the data. But, it is not in the format that I wanted it to
be. I want it a data frame and clean numbers.
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(data) modifyList(data, lapply(data[,
sapply(data, is.logical)],asNumeric))

data=read.fwf(filename, widths=c(c1),skip=18, header=FALSE)
data$V2<-as.numeric(gsub(" ","", as.character(data$V2) , fixed=TRUE))
f <- factorsNumeric(data)

Any help is appreciated.

Best,

Alemu

	[[alternative HTML version deleted]]


From dcarlson at tamu.edu  Wed Oct 29 21:34:53 2014
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 29 Oct 2014 20:34:53 +0000
Subject: [R] reading data from a web
In-Reply-To: <CACGkHRON9pKPdRRZLqDwdO87nx5kXj6wMVZ+mAStZ35wLPwRZg@mail.gmail.com>
References: <CACGkHRON9pKPdRRZLqDwdO87nx5kXj6wMVZ+mAStZ35wLPwRZg@mail.gmail.com>
Message-ID: <53BF8FB63FAF2E4A9455EF1EE94DA726FADE26@mb02.ads.tamu.edu>

You did not read the data with the commands you provided since c1 is not defined so read.fwf() fails immediately. Here is a solution that works for the link you provided, but would need to be modified for months that do not have 30 days:

> lnk <- "http://www.data.jma.go.jp/gmd/env/data/radiation/data/geppo/201004/DR201004_sap.txt"
> raw <- readLines(lnk) # Read the file as text lines
> raw <- raw[19:48]     # Pull out the data
> raw <- substr(raw, 16, nchar(raw))  # Strip the leading blanks
> raw <- gsub("  +", ",", raw)        # Replace two or more blanks with a comma
> raw <- gsub("\\.\\.\\.", "NA", raw) # Replace ... with NA
> Solar <- read.csv(text=raw, header=FALSE, colClasses=c("character", 
+   rep("numeric", 25)))
> str(Solar)
'data.frame':   30 obs. of  26 variables:
 $ V1 : chr  "4 1" "4 2" "4 3" "4 4" ...
 $ V2 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ V3 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ V4 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ V5 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ V6 : num  NA NA NA NA NA NA NA NA NA NA ...
 $ V7 : num  0 0 0 2 0 8 0 75 2 0 ...
 $ V8 : num  0 0 17 133 0 27 36 218 1 1 ...
 $ V9 : num  0 98 29 205 0 23 4 280 1 0 ...
 $ V10: num  2 190 62 100 0 9 0 310 7 12 ...
 $ V11: num  0 237 49 227 86 9 0 321 0 0 ...
 $ V12: num  0 303 21 151 177 13 1 304 52 0 ...
 $ V13: num  0 286 72 199 131 8 2 320 33 6 ...
 $ V14: num  0 318 203 284 30 1 102 285 9 130 ...
 $ V15: num  0 314 241 282 10 0 43 286 93 107 ...
 $ V16: num  1 270 171 256 6 1 0 272 181 27 ...
 $ V17: num  3 190 100 214 34 0 11 255 177 0 ...
 $ V18: num  0 89 69 129 24 0 8 205 138 0 ...
 $ V19: num  0 7 2 27 2 0 0 80 30 0 ...
 $ V20: num  0 0 0 0 0 0 0 0 0 0 ...
 $ V21: num  NA NA NA NA NA NA NA NA NA NA ...
 $ V22: num  NA NA NA NA NA NA NA NA NA NA ...
 $ V23: num  NA NA NA NA NA NA NA NA NA NA ...
 $ V24: num  NA NA NA NA NA NA NA NA NA NA ...
 $ V25: num  NA NA NA NA NA NA NA NA NA NA ...
 $ V26: num  6 2302 1036 2209 500 ...

-------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Alemu Tadesse
Sent: Wednesday, October 29, 2014 2:21 PM
To: r-help at r-project.org
Subject: [R] reading data from a web

Dear All,

I have data of the format shown in the link
http://www.data.jma.go.jp/gmd/env/data/radiation/data/geppo/201004/DR201004_sap.txt
 that I need to read. I have downloaded all the data from the link and I
have it on my computer. I used the following script (got it from web) and
was able to read the data. But, it is not in the format that I wanted it to
be. I want it a data frame and clean numbers.
asNumeric <- function(x) as.numeric(as.character(x))
factorsNumeric <- function(data) modifyList(data, lapply(data[,
sapply(data, is.logical)],asNumeric))

data=read.fwf(filename, widths=c(c1),skip=18, header=FALSE)
data$V2<-as.numeric(gsub(" ","", as.character(data$V2) , fixed=TRUE))
f <- factorsNumeric(data)

Any help is appreciated.

Best,

Alemu

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From r.turner at auckland.ac.nz  Wed Oct 29 21:47:46 2014
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 30 Oct 2014 09:47:46 +1300
Subject: [R] Voronoi/Thiessen polygon neighbors?
In-Reply-To: <CALs_GZVpadxWzCCWShg0KiK7VrFiUje2VbsFFXF6uSODip4Saw@mail.gmail.com>
References: <CALs_GZVpadxWzCCWShg0KiK7VrFiUje2VbsFFXF6uSODip4Saw@mail.gmail.com>
Message-ID: <54515272.1060700@auckland.ac.nz>

On 30/10/14 03:16, Michal Kvasni?ka wrote:
> Hello.
>
> I have a set of points in 2D. I can construct Voronoi polygons around them
> with deldir package  and function from this page:
>
>
> http://stackoverflow.com/questions/9403660/how-to-create-thiessen-polygons-from-points-using-r-packages
>
> What I need is to find the list of all polygon neighbors of each original
> point. (Let us say that each original point is represented with its Voronoi
> polygon. These polygons are numbered. I have to find a list of all indices
> of the polygons that share a line segment with polygon 1, polygon 2, etc.)
>
> I can go through all line segments of all polygons and search for the
> polygon that shares the line segment but I guess there is a better way to
> do it. Can you help me to find it please?

Look at the "dirsgs" component of the object returned by deldir().  It 
has two columns named "ind1" and "ind2".  These are the indices of pairs 
of points which are Delaunay neighbours, i.e. points such that the line 
joining them is intersected by an edge of a Dirichlet (Voronoi) tile.

This should provide you with the information you want.

cheers,

Rolf Turner (author of the "deldir" package)

-- 
Rolf Turner
Technical Editor ANZJS


From jim at bitwrit.com.au  Thu Oct 30 09:34:43 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 30 Oct 2014 19:34:43 +1100
Subject: [R] dotplot with library lattice
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF304@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
	<5483501.3ZsGK1Yh3h@localhost.localdomain>
	<7E39CF5278A2C948968C39502CF451020174CEADF304@mail.ell.fnt.de>
Message-ID: <1993806.gTaEL4XCId@localhost.localdomain>

On Thu, 30 Oct 2014 09:25:53 AM Matthias Weber wrote:
> Hi Jim,
> 
> the graph looks at the moment nearly perfect. I have one last 
question.
> How can I change the scaling of the x-axis. At the moment i see the 
values
> at 0,20,40,60,80,100.
> 
> My wish is, that the x-axis looks like the abline, so the scaling for the
> x-axis should be at 0,25,50,75,100.
> 
> Thanks a lot.
> 
> Best regards.
> 
> Mat

Hi Mat,
Add xaxt="n" to the plot command to suppress the default x axis:

plot(rep(100,13),1:13,main="IST against Budget",
 xlab="IST/Budget (prozent)",ylab="KOST",
 xlim=c(0,100),type="n",xaxt="n",yaxt="n")

and add a custom x axis:

axis(1,at=c(0,25,50,75,100))

Jim


From p_connolly at slingshot.co.nz  Thu Oct 30 09:50:00 2014
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Thu, 30 Oct 2014 21:50:00 +1300
Subject: [R] Oddity using multcompView package
Message-ID: <20141030085000.GA21276@slingshot.co.nz>

The multcompView has some useful features but I'm sure this isn't
intentional.  Excuse the size.  This is about the smallest
reproducible example I can do:

require("multcompView")

> mm <- structure(list(TempNom = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 4L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 
5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 
6L), .Label = c("15", "18", "21", "22", "24", "27"), class = "factor"), 
    Days = c(14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 14L, 
    14L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 16L, 
    16L, 16L, 17L, 17L, 17L, 17L, 17L, 18L, 18L, 18L, 18L, 19L, 
    19L, 19L, 19L, 20L, 20L, 20L, 20L, 21L, 21L, 21L, 21L, 21L, 
    22L, 23L, 23L, 25L, 25L, 26L, 26L, 27L, 27L, 27L, 28L, 10L, 
    10L, 11L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 13L, 
    13L, 13L, 13L, 13L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L, 
    14L, 14L, 14L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 15L, 
    16L, 16L, 17L, 17L, 17L, 17L, 18L, 18L, 18L, 18L, 18L, 18L, 
    19L, 20L, 20L, 20L, 20L, 21L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
    8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
    9L, 9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 12L, 
    12L, 12L, 13L, 13L, 14L, 14L, 14L, 14L, 14L, 14L, 15L, 15L, 
    16L, 16L, 17L, 17L, 17L, 18L, 20L, 8L, 8L, 8L, 8L, 9L, 9L, 
    9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 10L, 10L, 10L, 10L, 
    10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 
    11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 11L, 12L, 12L, 12L, 
    12L, 12L, 13L, 13L, 13L, 13L, 13L, 13L, 14L, 14L, 14L, 14L, 
    15L, 15L, 15L, 15L, 15L, 15L, 15L, 16L, 16L, 17L, 17L, 18L, 
    18L, 18L, 19L, 19L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 
    8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
    9L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 11L, 
    11L, 12L, 12L, 12L, 12L, 12L, 12L, 13L, 14L, 14L, 14L, 15L, 
    16L, 16L, 17L, 6L, 6L, 6L, 6L, 7L, 7L, 7L, 7L, 7L, 7L, 7L, 
    7L, 8L, 8L, 8L, 8L, 8L, 8L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 
    9L, 10L, 10L, 10L, 10L, 10L, 10L, 11L, 12L, 12L, 12L, 12L, 
    12L, 13L, 13L, 16L)), class = c("tbl_df", "tbl", "data.frame"
), row.names = c(NA, -343L), .Names = c("TempNom", "Days"))
> mm.aov <- aov(Days ~ TempNom, data = mm)
> model.tables(mm.aov, "means")
Tables of means
Grand mean
         
12.74052 

 TempNom 
      15    18    21    22    24     27
    18.4 14.87 11.22 11.92 10.27  9.095
rep 57.0 55.00 65.00 72.00 52.00 42.000
> multcompLetters(TukeyHSD(mm.aov)$TempNom[,4])
  18   21   22   24   27   15 
 "a" "bc"  "b" "cd"  "d"  "e" 
> 


Something is clearly wrong with letter "e" for TempNom = 15.

Theory1:
First, I tried reordering the output by name, but that results in "e"
for the longest (i.e. 15) and "a" for the runner-up.

Theory2:
Then I tried assuming the letters were correct and in the correct
order but were labelled incorrectly.

If I put the output into a dataframe, it's easier to see what we have.

> TT <- data.frame(T = c(model.tables(mm.aov, "means")[[1]]$TempNom))
> TT$Group <- multcompLetters(TukeyHSD(mm.aov)$TempNom[,4])$
monospacedLetters[rownames(TT)]# (sorted a la Theory1)
> TT$GroupA <- multcompLetters(TukeyHSD(mm.aov)$TempNom[,4])$
monospacedLetters # (unsorted a la Theory2)
> TT
           T Group GroupA
15 18.403509     e  a    
18 14.872727 a       bc  
21 11.215385  bc     b   
22 11.916667  b       cd 
24 10.269231   cd      d 
27  9.095238    d       e
> 

In this example, it appears GroupA (Theory2) makes more sense.
However, in larger examples, that approach can result in two values in
separate groups even though there's less than 0.1% difference between
them and sustantial standard error.

In those cases (too large to show here) it makes more sense to modify
the Group column by changing the "e" to "a" and moving the other
letters along by 1.

The code for the multcompLetters function is nicely commented but
before I launch into checking it for bugs, I thought it prudent to ask
if anyone else had encountered anything similar.  Or am I simply
asking too much of an unbalanced data set?


> sessionInfo()

R version 3.1.1 (2014-07-10)
Platform: i686-pc-linux-gnu (32-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] grid      grDevices utils     stats     graphics  methods   base     

other attached packages:
[1] dplyr_0.3.0.2      multcompView_0.1-5 lattice_0.20-29   

loaded via a namespace (and not attached):
[1] assertthat_0.1 DBI_0.3.1      lazyeval_0.1.9 magrittr_1.0.1 parallel_3.1.1
[6] Rcpp_0.11.3    tools_3.1.1   
> 

TIA

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.

PS: the problem existed without dplyr and DBI


From Matthias.Weber at fntsoftware.com  Thu Oct 30 09:25:53 2014
From: Matthias.Weber at fntsoftware.com (Matthias Weber)
Date: Thu, 30 Oct 2014 09:25:53 +0100
Subject: [R] dotplot with library lattice
In-Reply-To: <5483501.3ZsGK1Yh3h@localhost.localdomain>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>
	<1709300.gu1B0lVq0c@localhost.localdomain>
	<7E39CF5278A2C948968C39502CF451020174CEADF2DE@mail.ell.fnt.de>
	<5483501.3ZsGK1Yh3h@localhost.localdomain>
Message-ID: <7E39CF5278A2C948968C39502CF451020174CEADF304@mail.ell.fnt.de>

Hi Jim,

the graph looks at the moment nearly perfect. I have one last question.
How can I change the scaling of the x-axis. At the moment i see the values at 0,20,40,60,80,100.

My wish is, that the x-axis looks like the abline, so the scaling for the x-axis should be at 0,25,50,75,100.

Thanks a lot.

Best regards.

Mat

-----Urspr?ngliche Nachricht-----
Von: Jim Lemon [mailto:jim at bitwrit.com.au]
Gesendet: Montag, 27. Oktober 2014 09:47
An: Matthias Weber
Cc: r-help at r-project.org
Betreff: Re: AW: [R] dotplot with library lattice

On Mon, 27 Oct 2014 08:53:51 AM Matthias Weber wrote:
> Hi Jim,
>
> looks perfect to me. Thank you very much. One last question. Is there
any
> possibility to add 3 horizontal lines in the graph. One at 25%, the
> other one at 50% and the last one at 75%? So I can see the process a
> bit
better?
>
Hi Mat,
Change this:

abline(h=1:13,lty=2,col="lightgray")

to this:

abline(h=1:13,v=c(25,50,75),lty=2,col="lightgray")

Jim


This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.


From fsmairura at yahoo.com  Thu Oct 30 13:57:06 2014
From: fsmairura at yahoo.com (Franklin Mairura)
Date: Thu, 30 Oct 2014 05:57:06 -0700
Subject: [R] dotplot with library lattice
In-Reply-To: <7E39CF5278A2C948968C39502CF451020174CEADF304@mail.ell.fnt.de>
References: <7E39CF5278A2C948968C39502CF451020174CEADF2D6@mail.ell.fnt.de>	<1709300.gu1B0lVq0c@localhost.localdomain>	<7E39CF5278A2C948968C39502CF451020174CEADF2DE@mail.ell.fnt.de>	<5483501.3ZsGK1Yh3h@localhost.localdomain>
	<7E39CF5278A2C948968C39502CF451020174CEADF304@mail.ell.fnt.de>
Message-ID: <1414673826.60089.YahooMailNeo@web162803.mail.bf1.yahoo.com>

Dear all, 

This is bargraph.CI (sciplot package) qstn. How do you draw the bargraph while subsetting, rather than doing a series of subsets. there is a subset function within bargraph.CI, how is it implemented?
Any advice, Thanks



On Thursday, October 30, 2014 1:52 AM, Matthias Weber <Matthias.Weber at fntsoftware.com> wrote:
 


Hi Jim,

the graph looks at the moment nearly perfect. I have one last question.
How can I change the scaling of the x-axis. At the moment i see the values at 0,20,40,60,80,100.

My wish is, that the x-axis looks like the abline, so the scaling for the x-axis should be at 0,25,50,75,100.

Thanks a lot.

Best regards.

Mat

-----Urspr?ngliche Nachricht-----
Von: Jim Lemon [mailto:jim at bitwrit.com.au]
Gesendet: Montag, 27. Oktober 2014 09:47
An: Matthias Weber
Cc: r-help at r-project.org
Betreff: Re: AW: [R] dotplot with library lattice

On Mon, 27 Oct 2014 08:53:51 AM Matthias Weber wrote:
> Hi Jim,
>
> looks perfect to me. Thank you very much. One last question. Is there
any
> possibility to add 3 horizontal lines in the graph. One at 25%, the
> other one at 50% and the last one at 75%? So I can see the process a
> bit
better?
>
Hi Mat,
Change this:

abline(h=1:13,lty=2,col="lightgray")

to this:

abline(h=1:13,v=c(25,50,75),lty=2,col="lightgray")

Jim


This e-mail may contain trade secrets, privileged, undisclosed or otherwise confidential information. If you have received this e-mail in error, you are hereby notified that any review, copying or distribution of it is strictly prohibited. Please inform us immediately and destroy the original transmittal. Thank you for your cooperation.

Diese E-Mail kann Betriebs- oder Geschaeftsgeheimnisse oder sonstige vertrauliche Informationen enthalten. Sollten Sie diese E-Mail irrtuemlich erhalten haben, ist Ihnen eine Kenntnisnahme des Inhalts, eine Vervielfaeltigung oder Weitergabe der E-Mail ausdruecklich untersagt. Bitte benachrichtigen Sie uns und vernichten Sie die empfangene E-Mail. Vielen Dank.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
	[[alternative HTML version deleted]]


From tomnyberg at gmail.com  Thu Oct 30 16:17:59 2014
From: tomnyberg at gmail.com (Thomas Nyberg)
Date: Thu, 30 Oct 2014 11:17:59 -0400
Subject: [R] How to speed up list access in R?
Message-ID: <545256A7.2070709@gmail.com>

Hello,

I want to do the following: Given a set of (number, value) pairs, I want 
to create a list l so that l[[toString(number)]] returns the vector of 
values associated to that number. It is hundreds of times slower than 
the equivalent that I would write in python. I'm pretty new to R so I 
bet I'm using its data structures inefficiently, but I've tried more or 
less everything I can think of and can't really speed it up. I have done 
some profiling which helped me find problem areas, but I couldn't speed 
things up even with that information. I'm thinking I'm just 
fundamentally using R in a silly way.

I've included code for the different versions. I wrote the python code 
in a style to make it as clear to R programmers as possible. Thanks a 
lot! Any help would be greatly appreciated!

Cheers,
Thomas


R code (with two versions depending on commenting):

-----

numbers <- numeric(0)
for (i in 1:5) {
     numbers <- c(numbers, sample(1:30000, 10000))
}

values <- numeric(0)
for (i in 1:length(numbers)) {
     values <- append(values, sample(1:10, 1))
}

            starttime <- Sys.time()

d = list()
for (i in 1:length(numbers)) {
     number = toString(numbers[i])
     value = values[i]
     if (is.null(d[[number]])) {
     #if (number %in% names(d)) {
         d[[number]] <- c(value)
     } else {
         d[[number]] <- append(d[[number]], value)
     }
}

endtime <- Sys.time()

print(format(endtime - starttime))

-----

uncommented version: "45.64791 secs"
commented version: "1.423056 mins"



Another version of R code:

-----

numbers <- numeric(0)
for (i in 1:5) {
     numbers <- c(numbers, sample(1:30000, 10000))
}

values <- numeric(0)
for (i in 1:length(numbers)) {
     values <- append(values, sample(1:10, 1))
}

starttime <- Sys.time()

d = list()
for (number in unique(numbers)) {
     d[[toString(number)]] <- numeric(0)
}
for (i in 1:length(numbers)) {
     number = toString(numbers[i])
     value = values[i]
     d[[number]] <- append(d[[number]], value)
}

endtime <- Sys.time()

print(format(endtime - starttime))

-----

"47.15579 secs"



The python code:

-----

import random
import time

numbers = []
for i in range(5):
     numbers += random.sample(range(30000), 10000)

values = []
for i in range(len(numbers)):
     values.append(random.randint(1, 10))

starttime = time.time()

d = {}
for i in range(len(numbers)):
     number = numbers[i]
     value = values[i]
     if d.has_key(number):
         d[number].append(value)
     else:
         d[number] = [value]

endtime = time.time()

print endtime - starttime, "seconds"

-----

0.123021125793 seconds


From jdnewmil at dcn.davis.CA.us  Thu Oct 30 16:27:39 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 30 Oct 2014 08:27:39 -0700
Subject: [R] foreach/dopar's processes accumulate RAM
In-Reply-To: <5450A9C5.7010800@chaotic-neutral.de>
References: <5450A9C5.7010800@chaotic-neutral.de>
Message-ID: <9CCB74A5-43BB-4A71-959B-625ECFDBF224@dcn.davis.CA.us>

Don't know the answer, partly because you have not shown enough of your code. The reason small, reproducible examples are specified in the footer and Posting Guide is to avoid this problem.
AFAIK all of the parallel processing libraries in R re-use the child processes, so garbage collection could be an issue. The nested for loops are probably a red herring, though, since that simply expands the number of iterations. The total number of iterations is probably relevant, and the setup of your parallel processes is probably important, as well as your sessionInfo().
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 29, 2014 1:48:05 AM PDT, Alexander Engelhardt <alex at chaotic-neutral.de> wrote:
>Hello all,
>
>I have a triple nested loop in R like this:
>
>all <- list()
>for(a in A){
>     all[[a]] <- list()
>     for(b in B){
>         all[[a]][[b]] <- foreach(c=C, .combine=rbind) %dopar% {
>             ## I'm leaving out some preprocessing here
>             this_GAM <- gam(formula, data=data, family=nb(link="log", 
>theta=THETA))
>             predict(this_GAM, newdata=newdata)
>         }
>     }
>}
>
>The problem I have is that, with time, the individual R processes which
>
>the %dopar% spawns use up more and more RAM. When I start the triple 
>loop, each process requires about 2GB of RAM, but after around eight 
>hours, they use >4GB each. Here's the first two lines of a 'top'
>output:
>
>   PID USER      PR  NI  VIRT  RES  SHR S %CPU %MEM    TIME+  COMMAND 
>
>20880 engelhar  20   0 7042m 4.0g 2436 R 59.2  6.4  14:30.15 R 
>
>20878 engelhar  20   0 7042m 4.3g 2436 D 53.5  6.8  14:07.18 R 
>
>
>I don't understand how this can happen. To my understanding, as soon as
>
>the foreach loop is done, i.e. as soon as a new 'b' is chosen from 'B' 
>in the second loop, the individual parallel R processes should
>terminate 
>and release the memory. There should not be an increase of memory 
>consumption over time.
>
>Does anyone know what is going on and how I can avoid this behavior?
>
>Thanks in advance,
>  Alex Engelhardt
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From johnwasige at gmail.com  Thu Oct 30 16:17:35 2014
From: johnwasige at gmail.com (John Wasige)
Date: Thu, 30 Oct 2014 16:17:35 +0100
Subject: [R] Putting R script in a function.
In-Reply-To: <CAGh51gS5pZA+KvCHdjaLx7zki560s7WfDJJDn32iMwwbQqhAvg@mail.gmail.com>
References: <CAGh51gS5pZA+KvCHdjaLx7zki560s7WfDJJDn32iMwwbQqhAvg@mail.gmail.com>
Message-ID: <CAJgdCD6UXDHNRx3ptuCJR8+ugsAaniqbnVjC80cVtuxzKi9Q2g@mail.gmail.com>

Hello community, I need help on how I can perform PCA on stacked raster
(multiple bands/ layers) in R. Does any body have an idea or script? Thanks?

	[[alternative HTML version deleted]]


From ryszard at czerminski.net  Thu Oct 30 14:10:29 2014
From: ryszard at czerminski.net (=?UTF-8?Q?Ryszard_Czermi=C5=84ski?=)
Date: Thu, 30 Oct 2014 09:10:29 -0400
Subject: [R] RForcecom VERY SLOW on large data sets
Message-ID: <CANS_STh3+zreEX7CC3dpN7vwo0_R9UHrxEh4h2Am_Q+UHgByLA@mail.gmail.com>

I started using RForcecom package to extract data from SalesForce.
It works very well for data sets with ~< 100K records, however
for a data set with ~400K records it becomes VERY SLOW
and export takes ~14h.

For comparison exporting the same table as csv using "report export" in
SalesForce
takes about 1 minute.

Any ideas why? and how to make it faster?

Best regards,
Ryszard

	[[alternative HTML version deleted]]


From olivier.crouzet at univ-nantes.fr  Thu Oct 30 16:48:41 2014
From: olivier.crouzet at univ-nantes.fr (Olivier Crouzet)
Date: Thu, 30 Oct 2014 16:48:41 +0100
Subject: [R] How to speed up list access in R?
In-Reply-To: <545256A7.2070709@gmail.com>
References: <545256A7.2070709@gmail.com>
Message-ID: <20141030164841.55da737c84ad83731e3c81e6@univ-nantes.fr>

Hi,

perhaps pre-generating the list before processing would speed it up
significantly. Though it may still be slower than python.

e.g. try something like:

d = as.list(rep(NA,length(numbers)))

rather than:

d = list()

Olivier.

On Thu, 30 Oct
2014 11:17:59 -0400 Thomas Nyberg <tomnyberg at gmail.com> wrote:

> Hello,
> 
> I want to do the following: Given a set of (number, value) pairs, I
> want to create a list l so that l[[toString(number)]] returns the
> vector of values associated to that number. It is hundreds of times
> slower than the equivalent that I would write in python. I'm pretty
> new to R so I bet I'm using its data structures inefficiently, but
> I've tried more or less everything I can think of and can't really
> speed it up. I have done some profiling which helped me find problem
> areas, but I couldn't speed things up even with that information. I'm
> thinking I'm just fundamentally using R in a silly way.
> 
> I've included code for the different versions. I wrote the python
> code in a style to make it as clear to R programmers as possible.
> Thanks a lot! Any help would be greatly appreciated!
> 
> Cheers,
> Thomas
> 
> 
> R code (with two versions depending on commenting):
> 
> -----
> 
> numbers <- numeric(0)
> for (i in 1:5) {
>      numbers <- c(numbers, sample(1:30000, 10000))
> }
> 
> values <- numeric(0)
> for (i in 1:length(numbers)) {
>      values <- append(values, sample(1:10, 1))
> }
> 
>             starttime <- Sys.time()
> 
> d = list()
> for (i in 1:length(numbers)) {
>      number = toString(numbers[i])
>      value = values[i]
>      if (is.null(d[[number]])) {
>      #if (number %in% names(d)) {
>          d[[number]] <- c(value)
>      } else {
>          d[[number]] <- append(d[[number]], value)
>      }
> }
> 
> endtime <- Sys.time()
> 
> print(format(endtime - starttime))
> 
> -----
> 
> uncommented version: "45.64791 secs"
> commented version: "1.423056 mins"
> 
> 
> 
> Another version of R code:
> 
> -----
> 
> numbers <- numeric(0)
> for (i in 1:5) {
>      numbers <- c(numbers, sample(1:30000, 10000))
> }
> 
> values <- numeric(0)
> for (i in 1:length(numbers)) {
>      values <- append(values, sample(1:10, 1))
> }
> 
> starttime <- Sys.time()
> 
> d = list()
> for (number in unique(numbers)) {
>      d[[toString(number)]] <- numeric(0)
> }
> for (i in 1:length(numbers)) {
>      number = toString(numbers[i])
>      value = values[i]
>      d[[number]] <- append(d[[number]], value)
> }
> 
> endtime <- Sys.time()
> 
> print(format(endtime - starttime))
> 
> -----
> 
> "47.15579 secs"
> 
> 
> 
> The python code:
> 
> -----
> 
> import random
> import time
> 
> numbers = []
> for i in range(5):
>      numbers += random.sample(range(30000), 10000)
> 
> values = []
> for i in range(len(numbers)):
>      values.append(random.randint(1, 10))
> 
> starttime = time.time()
> 
> d = {}
> for i in range(len(numbers)):
>      number = numbers[i]
>      value = values[i]
>      if d.has_key(number):
>          d[number].append(value)
>      else:
>          d[number] = [value]
> 
> endtime = time.time()
> 
> print endtime - starttime, "seconds"
> 
> -----
> 
> 0.123021125793 seconds
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html and provide commented,
> minimal, self-contained, reproducible code.


-- 
  Olivier Crouzet, PhD
  Laboratoire de Linguistique -- EA3827
  Universit? de Nantes
  Chemin de la Censive du Tertre - BP 81227
  44312 Nantes cedex 3
  France

     phone:        (+33) 02 40 14 14 05 (lab.)
                   (+33) 02 40 14 14 36 (office)
     fax:          (+33) 02 40 14 13 27
     e-mail:       olivier.crouzet at univ-nantes.fr
 		
  http://www.lling.univ-nantes.fr/


From jdnewmil at dcn.davis.CA.us  Thu Oct 30 17:00:14 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 30 Oct 2014 09:00:14 -0700
Subject: [R] How to speed up list access in R?
In-Reply-To: <545256A7.2070709@gmail.com>
References: <545256A7.2070709@gmail.com>
Message-ID: <0FF41BF1-6E4D-4CCE-979C-830E1C940B06@dcn.davis.CA.us>

Look at sqldf or data.table packages. Lists are slow for lookup and not particularly efficient with memory. numeric indexing into matrices or data frames is more typical in R, and the above mentioned packages support indexing to speed up lookups. Also, carefully consider whether you can program your processing in bulk... vector or relational processing can be critical for performance.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 30, 2014 8:17:59 AM PDT, Thomas Nyberg <tomnyberg at gmail.com> wrote:
>Hello,
>
>I want to do the following: Given a set of (number, value) pairs, I
>want 
>to create a list l so that l[[toString(number)]] returns the vector of 
>values associated to that number. It is hundreds of times slower than 
>the equivalent that I would write in python. I'm pretty new to R so I 
>bet I'm using its data structures inefficiently, but I've tried more or
>
>less everything I can think of and can't really speed it up. I have
>done 
>some profiling which helped me find problem areas, but I couldn't speed
>
>things up even with that information. I'm thinking I'm just 
>fundamentally using R in a silly way.
>
>I've included code for the different versions. I wrote the python code 
>in a style to make it as clear to R programmers as possible. Thanks a 
>lot! Any help would be greatly appreciated!
>
>Cheers,
>Thomas
>
>
>R code (with two versions depending on commenting):
>
>-----
>
>numbers <- numeric(0)
>for (i in 1:5) {
>     numbers <- c(numbers, sample(1:30000, 10000))
>}
>
>values <- numeric(0)
>for (i in 1:length(numbers)) {
>     values <- append(values, sample(1:10, 1))
>}
>
>            starttime <- Sys.time()
>
>d = list()
>for (i in 1:length(numbers)) {
>     number = toString(numbers[i])
>     value = values[i]
>     if (is.null(d[[number]])) {
>     #if (number %in% names(d)) {
>         d[[number]] <- c(value)
>     } else {
>         d[[number]] <- append(d[[number]], value)
>     }
>}
>
>endtime <- Sys.time()
>
>print(format(endtime - starttime))
>
>-----
>
>uncommented version: "45.64791 secs"
>commented version: "1.423056 mins"
>
>
>
>Another version of R code:
>
>-----
>
>numbers <- numeric(0)
>for (i in 1:5) {
>     numbers <- c(numbers, sample(1:30000, 10000))
>}
>
>values <- numeric(0)
>for (i in 1:length(numbers)) {
>     values <- append(values, sample(1:10, 1))
>}
>
>starttime <- Sys.time()
>
>d = list()
>for (number in unique(numbers)) {
>     d[[toString(number)]] <- numeric(0)
>}
>for (i in 1:length(numbers)) {
>     number = toString(numbers[i])
>     value = values[i]
>     d[[number]] <- append(d[[number]], value)
>}
>
>endtime <- Sys.time()
>
>print(format(endtime - starttime))
>
>-----
>
>"47.15579 secs"
>
>
>
>The python code:
>
>-----
>
>import random
>import time
>
>numbers = []
>for i in range(5):
>     numbers += random.sample(range(30000), 10000)
>
>values = []
>for i in range(len(numbers)):
>     values.append(random.randint(1, 10))
>
>starttime = time.time()
>
>d = {}
>for i in range(len(numbers)):
>     number = numbers[i]
>     value = values[i]
>     if d.has_key(number):
>         d[number].append(value)
>     else:
>         d[number] = [value]
>
>endtime = time.time()
>
>print endtime - starttime, "seconds"
>
>-----
>
>0.123021125793 seconds
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pollaroid at gmail.com  Thu Oct 30 17:03:11 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Thu, 30 Oct 2014 17:03:11 +0100
Subject: [R] How can I merge data with differing length?
Message-ID: <CAAC1QdC8X_df=E=i7Oc82yMvkYeSpLJ+g+Tx1U3WtXbjmzTb=w@mail.gmail.com>

How can I merge  data frame df and "tem" shown below by filling the
head of "tem"  with missing values?


a<- rnorm(1825, 20)
b<- rnorm(1825, 30)
date<-seq(as.Date("2000/1/1"), by = "day", length.out = 1825)

df<-data.frame(date,a,b)


tem<- rpois(1095,  lambda=21)

Thanks


From wdunlap at tibco.com  Thu Oct 30 17:05:22 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 30 Oct 2014 09:05:22 -0700
Subject: [R] How to speed up list access in R?
In-Reply-To: <545256A7.2070709@gmail.com>
References: <545256A7.2070709@gmail.com>
Message-ID: <CAF8bMcY0wjEP+4FYOUD_3=8e0FVgBDbTKWAAQvyAi5TXSqnjjQ@mail.gmail.com>

Repeatedly extending vectors takes a lot of time.  You can do what you want with
  d2 <- split(values, factor(numbers, levels=unique(numbers)))
If you would like the labels on d2 to be in numeric order then you can
simplify that to
  d3 <- split(values, numbers)

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Oct 30, 2014 at 8:17 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
> Hello,
>
> I want to do the following: Given a set of (number, value) pairs, I want to
> create a list l so that l[[toString(number)]] returns the vector of values
> associated to that number. It is hundreds of times slower than the
> equivalent that I would write in python. I'm pretty new to R so I bet I'm
> using its data structures inefficiently, but I've tried more or less
> everything I can think of and can't really speed it up. I have done some
> profiling which helped me find problem areas, but I couldn't speed things up
> even with that information. I'm thinking I'm just fundamentally using R in a
> silly way.
>
> I've included code for the different versions. I wrote the python code in a
> style to make it as clear to R programmers as possible. Thanks a lot! Any
> help would be greatly appreciated!
>
> Cheers,
> Thomas
>
>
> R code (with two versions depending on commenting):
>
> -----
>
> numbers <- numeric(0)
> for (i in 1:5) {
>     numbers <- c(numbers, sample(1:30000, 10000))
> }
>
> values <- numeric(0)
> for (i in 1:length(numbers)) {
>     values <- append(values, sample(1:10, 1))
> }
>
>            starttime <- Sys.time()
>
> d = list()
> for (i in 1:length(numbers)) {
>     number = toString(numbers[i])
>     value = values[i]
>     if (is.null(d[[number]])) {
>     #if (number %in% names(d)) {
>         d[[number]] <- c(value)
>     } else {
>         d[[number]] <- append(d[[number]], value)
>     }
> }
>
> endtime <- Sys.time()
>
> print(format(endtime - starttime))
>
> -----
>
> uncommented version: "45.64791 secs"
> commented version: "1.423056 mins"
>
>
>
> Another version of R code:
>
> -----
>
> numbers <- numeric(0)
> for (i in 1:5) {
>     numbers <- c(numbers, sample(1:30000, 10000))
> }
>
> values <- numeric(0)
> for (i in 1:length(numbers)) {
>     values <- append(values, sample(1:10, 1))
> }
>
> starttime <- Sys.time()
>
> d = list()
> for (number in unique(numbers)) {
>     d[[toString(number)]] <- numeric(0)
> }
> for (i in 1:length(numbers)) {
>     number = toString(numbers[i])
>     value = values[i]
>     d[[number]] <- append(d[[number]], value)
> }
>
> endtime <- Sys.time()
>
> print(format(endtime - starttime))
>
> -----
>
> "47.15579 secs"
>
>
>
> The python code:
>
> -----
>
> import random
> import time
>
> numbers = []
> for i in range(5):
>     numbers += random.sample(range(30000), 10000)
>
> values = []
> for i in range(len(numbers)):
>     values.append(random.randint(1, 10))
>
> starttime = time.time()
>
> d = {}
> for i in range(len(numbers)):
>     number = numbers[i]
>     value = values[i]
>     if d.has_key(number):
>         d[number].append(value)
>     else:
>         d[number] = [value]
>
> endtime = time.time()
>
> print endtime - starttime, "seconds"
>
> -----
>
> 0.123021125793 seconds
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Thu Oct 30 17:34:06 2014
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 30 Oct 2014 12:34:06 -0400
Subject: [R] How to speed up list access in R?
In-Reply-To: <CAF8bMcY0wjEP+4FYOUD_3=8e0FVgBDbTKWAAQvyAi5TXSqnjjQ@mail.gmail.com>
References: <545256A7.2070709@gmail.com>
	<CAF8bMcY0wjEP+4FYOUD_3=8e0FVgBDbTKWAAQvyAi5TXSqnjjQ@mail.gmail.com>
Message-ID: <CA+vqiLEy3f1kd1j-CvRymaoMwdq4bF-Fz8m3r-fy8BQdgDB6Yg@mail.gmail.com>

Bill beat me to it, I was just about to post the same thing. The R
split version is still slower than python on my system, but the times
are now on the same order of magnitude, about a 10th of a second in
both cases.

You can also speed up the set-up part by sampling all at once instead
of repeatedly, e.g.,

sample(1:10, length(numbers2), replace=TRUE)

instead of

values <- numeric(0)
for (i in 1:length(numbers)) {
    values <- append(values, sample(1:10, 1))
}

Best,
Ista
On Thu, Oct 30, 2014 at 12:05 PM, William Dunlap <wdunlap at tibco.com> wrote:
> Repeatedly extending vectors takes a lot of time.  You can do what you want with
>   d2 <- split(values, factor(numbers, levels=unique(numbers)))
> If you would like the labels on d2 to be in numeric order then you can
> simplify that to
>   d3 <- split(values, numbers)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Oct 30, 2014 at 8:17 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
>> Hello,
>>
>> I want to do the following: Given a set of (number, value) pairs, I want to
>> create a list l so that l[[toString(number)]] returns the vector of values
>> associated to that number. It is hundreds of times slower than the
>> equivalent that I would write in python. I'm pretty new to R so I bet I'm
>> using its data structures inefficiently, but I've tried more or less
>> everything I can think of and can't really speed it up. I have done some
>> profiling which helped me find problem areas, but I couldn't speed things up
>> even with that information. I'm thinking I'm just fundamentally using R in a
>> silly way.
>>
>> I've included code for the different versions. I wrote the python code in a
>> style to make it as clear to R programmers as possible. Thanks a lot! Any
>> help would be greatly appreciated!
>>
>> Cheers,
>> Thomas
>>
>>
>> R code (with two versions depending on commenting):
>>
>> -----
>>
>> numbers <- numeric(0)
>> for (i in 1:5) {
>>     numbers <- c(numbers, sample(1:30000, 10000))
>> }
>>
>> values <- numeric(0)
>> for (i in 1:length(numbers)) {
>>     values <- append(values, sample(1:10, 1))
>> }
>>
>>            starttime <- Sys.time()
>>
>> d = list()
>> for (i in 1:length(numbers)) {
>>     number = toString(numbers[i])
>>     value = values[i]
>>     if (is.null(d[[number]])) {
>>     #if (number %in% names(d)) {
>>         d[[number]] <- c(value)
>>     } else {
>>         d[[number]] <- append(d[[number]], value)
>>     }
>> }
>>
>> endtime <- Sys.time()
>>
>> print(format(endtime - starttime))
>>
>> -----
>>
>> uncommented version: "45.64791 secs"
>> commented version: "1.423056 mins"
>>
>>
>>
>> Another version of R code:
>>
>> -----
>>
>> numbers <- numeric(0)
>> for (i in 1:5) {
>>     numbers <- c(numbers, sample(1:30000, 10000))
>> }
>>
>> values <- numeric(0)
>> for (i in 1:length(numbers)) {
>>     values <- append(values, sample(1:10, 1))
>> }
>>
>> starttime <- Sys.time()
>>
>> d = list()
>> for (number in unique(numbers)) {
>>     d[[toString(number)]] <- numeric(0)
>> }
>> for (i in 1:length(numbers)) {
>>     number = toString(numbers[i])
>>     value = values[i]
>>     d[[number]] <- append(d[[number]], value)
>> }
>>
>> endtime <- Sys.time()
>>
>> print(format(endtime - starttime))
>>
>> -----
>>
>> "47.15579 secs"
>>
>>
>>
>> The python code:
>>
>> -----
>>
>> import random
>> import time
>>
>> numbers = []
>> for i in range(5):
>>     numbers += random.sample(range(30000), 10000)
>>
>> values = []
>> for i in range(len(numbers)):
>>     values.append(random.randint(1, 10))
>>
>> starttime = time.time()
>>
>> d = {}
>> for i in range(len(numbers)):
>>     number = numbers[i]
>>     value = values[i]
>>     if d.has_key(number):
>>         d[number].append(value)
>>     else:
>>         d[number] = [value]
>>
>> endtime = time.time()
>>
>> print endtime - starttime, "seconds"
>>
>> -----
>>
>> 0.123021125793 seconds
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From johnwasige at gmail.com  Thu Oct 30 17:06:41 2014
From: johnwasige at gmail.com (John Wasige)
Date: Thu, 30 Oct 2014 17:06:41 +0100
Subject: [R] PCA on stacked raster (multiple bands/ layers) in R
Message-ID: <CAJgdCD65pseb-t5yEbteryPAcS+-X-vy8kp1_B3Ar3Xzjfq4wA@mail.gmail.com>

Hello community, I need help on how I can perform PCA on stacked raster
(multiple bands/ layers) in R. Does any body have an idea or script? Thanks?
John

	[[alternative HTML version deleted]]


From surangakas at gmail.com  Thu Oct 30 17:26:31 2014
From: surangakas at gmail.com (Suranga Kasthurirathne)
Date: Thu, 30 Oct 2014 12:26:31 -0400
Subject: [R] Setting a class / outcome variable for Weka Principal
	Components Analysis
Message-ID: <CAMBYo-2H6MUiugXxOHfEqxox49FTH-iKW6fWWu2bn_xRL05jdw@mail.gmail.com>

Hi everyone,

I've relatively new to R, and i'm trying to use it to perform a Principal
Components analysis (PCA)
I've done this using WEKA previously, and now i'm trying to do so using R's
prcomp and princomp (both options would work for me).

One problem i've found is that while WEKA PCA allows us to specify a class
/ outcome variable / column for the dataset, apparently R project (both
prcomp and princomp) don't.

I've read through a number of documents including this
<http://cran.r-project.org/web/packages/HSAUR/vignettes/Ch_principal_components_analysis.pdf>
with limited success, so wanted to raise this question here. How does one
set the class variable when performing a PCA ?
Any advice would be  greatly appreciated !


-- 
Best Regards,
Suranga

	[[alternative HTML version deleted]]


From info at aghmed.fsnet.co.uk  Thu Oct 30 17:45:33 2014
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Thu, 30 Oct 2014 16:45:33 +0000
Subject: [R] How can I merge data with differing length?
In-Reply-To: <CAAC1QdC8X_df=E=i7Oc82yMvkYeSpLJ+g+Tx1U3WtXbjmzTb=w@mail.gmail.com>
References: <CAAC1QdC8X_df=E=i7Oc82yMvkYeSpLJ+g+Tx1U3WtXbjmzTb=w@mail.gmail.com>
Message-ID: <54526B2D.1020804@aghmed.fsnet.co.uk>



On 30/10/2014 16:03, Kuma Raj wrote:
> How can I merge  data frame df and "tem" shown below by filling the
> head of "tem"  with missing values?
does

c(rep(NA, nrow(df) - length(tem)), tem)

help?

>
>
> a<- rnorm(1825, 20)
> b<- rnorm(1825, 30)
> date<-seq(as.Date("2000/1/1"), by = "day", length.out = 1825)
>
> df<-data.frame(date,a,b)
>
>
> tem<- rpois(1095,  lambda=21)
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michael
http://www.dewey.myzen.co.uk


From tomnyberg at gmail.com  Thu Oct 30 18:02:43 2014
From: tomnyberg at gmail.com (Thomas Nyberg)
Date: Thu, 30 Oct 2014 13:02:43 -0400
Subject: [R] How to speed up list access in R?
In-Reply-To: <CAF8bMcY0wjEP+4FYOUD_3=8e0FVgBDbTKWAAQvyAi5TXSqnjjQ@mail.gmail.com>
References: <545256A7.2070709@gmail.com>
	<CAF8bMcY0wjEP+4FYOUD_3=8e0FVgBDbTKWAAQvyAi5TXSqnjjQ@mail.gmail.com>
Message-ID: <54526F33.40309@gmail.com>

Thanks to all for the help everyone! For the moment I'll stick with 
Bill's solution, but I'll check out the other recommendations as well.

Regarding the issue of slow looks ups for lists, are there any hash map 
implementations in R that are faster? I like using fairly simple logic 
and data structures when prototyping and then only optimize code when 
and where it's necessary which is why I'm curious about these basic objects.

On another note, is there a vector style implementation that changes the 
vectors in place? If I'm not mistaken, the append operation creates and 
returns a new vector each time which is line with the functional nature 
of R. If there were some way to have it mutable, it could be much 
faster. This is fairly standard in many languages. Behind the scenes 
memory is allocated at say 2 times the current size so that you only 
need log(n) extensions when building up a vector like this. Are there 
any such equivalents in R? I presume that lists are mutable (am I 
wrong?), but they seem to have the lookup slowdown problem.

Again thanks a lot!

Cheers,
Thomas

On 10/30/2014 12:05 PM, William Dunlap wrote:
> Repeatedly extending vectors takes a lot of time.  You can do what you want with
>    d2 <- split(values, factor(numbers, levels=unique(numbers)))
> If you would like the labels on d2 to be in numeric order then you can
> simplify that to
>    d3 <- split(values, numbers)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Oct 30, 2014 at 8:17 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
>> Hello,
>>
>> I want to do the following: Given a set of (number, value) pairs, I want to
>> create a list l so that l[[toString(number)]] returns the vector of values
>> associated to that number. It is hundreds of times slower than the
>> equivalent that I would write in python. I'm pretty new to R so I bet I'm
>> using its data structures inefficiently, but I've tried more or less
>> everything I can think of and can't really speed it up. I have done some
>> profiling which helped me find problem areas, but I couldn't speed things up
>> even with that information. I'm thinking I'm just fundamentally using R in a
>> silly way.
>>
>> I've included code for the different versions. I wrote the python code in a
>> style to make it as clear to R programmers as possible. Thanks a lot! Any
>> help would be greatly appreciated!
>>
>> Cheers,
>> Thomas
>>
>>
>> R code (with two versions depending on commenting):
>>
>> -----
>>
>> numbers <- numeric(0)
>> for (i in 1:5) {
>>      numbers <- c(numbers, sample(1:30000, 10000))
>> }
>>
>> values <- numeric(0)
>> for (i in 1:length(numbers)) {
>>      values <- append(values, sample(1:10, 1))
>> }
>>
>>             starttime <- Sys.time()
>>
>> d = list()
>> for (i in 1:length(numbers)) {
>>      number = toString(numbers[i])
>>      value = values[i]
>>      if (is.null(d[[number]])) {
>>      #if (number %in% names(d)) {
>>          d[[number]] <- c(value)
>>      } else {
>>          d[[number]] <- append(d[[number]], value)
>>      }
>> }
>>
>> endtime <- Sys.time()
>>
>> print(format(endtime - starttime))
>>
>> -----
>>
>> uncommented version: "45.64791 secs"
>> commented version: "1.423056 mins"
>>
>>
>>
>> Another version of R code:
>>
>> -----
>>
>> numbers <- numeric(0)
>> for (i in 1:5) {
>>      numbers <- c(numbers, sample(1:30000, 10000))
>> }
>>
>> values <- numeric(0)
>> for (i in 1:length(numbers)) {
>>      values <- append(values, sample(1:10, 1))
>> }
>>
>> starttime <- Sys.time()
>>
>> d = list()
>> for (number in unique(numbers)) {
>>      d[[toString(number)]] <- numeric(0)
>> }
>> for (i in 1:length(numbers)) {
>>      number = toString(numbers[i])
>>      value = values[i]
>>      d[[number]] <- append(d[[number]], value)
>> }
>>
>> endtime <- Sys.time()
>>
>> print(format(endtime - starttime))
>>
>> -----
>>
>> "47.15579 secs"
>>
>>
>>
>> The python code:
>>
>> -----
>>
>> import random
>> import time
>>
>> numbers = []
>> for i in range(5):
>>      numbers += random.sample(range(30000), 10000)
>>
>> values = []
>> for i in range(len(numbers)):
>>      values.append(random.randint(1, 10))
>>
>> starttime = time.time()
>>
>> d = {}
>> for i in range(len(numbers)):
>>      number = numbers[i]
>>      value = values[i]
>>      if d.has_key(number):
>>          d[number].append(value)
>>      else:
>>          d[number] = [value]
>>
>> endtime = time.time()
>>
>> print endtime - starttime, "seconds"
>>
>> -----
>>
>> 0.123021125793 seconds
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Thu Oct 30 18:05:06 2014
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 30 Oct 2014 10:05:06 -0700
Subject: [R] How to speed up list access in R?
In-Reply-To: <54526F33.40309@gmail.com>
References: <545256A7.2070709@gmail.com>
	<CAF8bMcY0wjEP+4FYOUD_3=8e0FVgBDbTKWAAQvyAi5TXSqnjjQ@mail.gmail.com>
	<54526F33.40309@gmail.com>
Message-ID: <CAF8bMcaKuzj+kFx4+=+Uww187QwO_01+Lnf+FZsMdD3SJS5oXQ@mail.gmail.com>

You can try using an environment instead of a list.

Bill Dunlap
TIBCO Software
wdunlap tibco.com


On Thu, Oct 30, 2014 at 10:02 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
> Thanks to all for the help everyone! For the moment I'll stick with Bill's
> solution, but I'll check out the other recommendations as well.
>
> Regarding the issue of slow looks ups for lists, are there any hash map
> implementations in R that are faster? I like using fairly simple logic and
> data structures when prototyping and then only optimize code when and where
> it's necessary which is why I'm curious about these basic objects.
>
> On another note, is there a vector style implementation that changes the
> vectors in place? If I'm not mistaken, the append operation creates and
> returns a new vector each time which is line with the functional nature of
> R. If there were some way to have it mutable, it could be much faster. This
> is fairly standard in many languages. Behind the scenes memory is allocated
> at say 2 times the current size so that you only need log(n) extensions when
> building up a vector like this. Are there any such equivalents in R? I
> presume that lists are mutable (am I wrong?), but they seem to have the
> lookup slowdown problem.
>
> Again thanks a lot!
>
> Cheers,
> Thomas
>
>
> On 10/30/2014 12:05 PM, William Dunlap wrote:
>>
>> Repeatedly extending vectors takes a lot of time.  You can do what you
>> want with
>>    d2 <- split(values, factor(numbers, levels=unique(numbers)))
>> If you would like the labels on d2 to be in numeric order then you can
>> simplify that to
>>    d3 <- split(values, numbers)
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>>
>> On Thu, Oct 30, 2014 at 8:17 AM, Thomas Nyberg <tomnyberg at gmail.com>
>> wrote:
>>>
>>> Hello,
>>>
>>> I want to do the following: Given a set of (number, value) pairs, I want
>>> to
>>> create a list l so that l[[toString(number)]] returns the vector of
>>> values
>>> associated to that number. It is hundreds of times slower than the
>>> equivalent that I would write in python. I'm pretty new to R so I bet I'm
>>> using its data structures inefficiently, but I've tried more or less
>>> everything I can think of and can't really speed it up. I have done some
>>> profiling which helped me find problem areas, but I couldn't speed things
>>> up
>>> even with that information. I'm thinking I'm just fundamentally using R
>>> in a
>>> silly way.
>>>
>>> I've included code for the different versions. I wrote the python code in
>>> a
>>> style to make it as clear to R programmers as possible. Thanks a lot! Any
>>> help would be greatly appreciated!
>>>
>>> Cheers,
>>> Thomas
>>>
>>>
>>> R code (with two versions depending on commenting):
>>>
>>> -----
>>>
>>> numbers <- numeric(0)
>>> for (i in 1:5) {
>>>      numbers <- c(numbers, sample(1:30000, 10000))
>>> }
>>>
>>> values <- numeric(0)
>>> for (i in 1:length(numbers)) {
>>>      values <- append(values, sample(1:10, 1))
>>> }
>>>
>>>             starttime <- Sys.time()
>>>
>>> d = list()
>>> for (i in 1:length(numbers)) {
>>>      number = toString(numbers[i])
>>>      value = values[i]
>>>      if (is.null(d[[number]])) {
>>>      #if (number %in% names(d)) {
>>>          d[[number]] <- c(value)
>>>      } else {
>>>          d[[number]] <- append(d[[number]], value)
>>>      }
>>> }
>>>
>>> endtime <- Sys.time()
>>>
>>> print(format(endtime - starttime))
>>>
>>> -----
>>>
>>> uncommented version: "45.64791 secs"
>>> commented version: "1.423056 mins"
>>>
>>>
>>>
>>> Another version of R code:
>>>
>>> -----
>>>
>>> numbers <- numeric(0)
>>> for (i in 1:5) {
>>>      numbers <- c(numbers, sample(1:30000, 10000))
>>> }
>>>
>>> values <- numeric(0)
>>> for (i in 1:length(numbers)) {
>>>      values <- append(values, sample(1:10, 1))
>>> }
>>>
>>> starttime <- Sys.time()
>>>
>>> d = list()
>>> for (number in unique(numbers)) {
>>>      d[[toString(number)]] <- numeric(0)
>>> }
>>> for (i in 1:length(numbers)) {
>>>      number = toString(numbers[i])
>>>      value = values[i]
>>>      d[[number]] <- append(d[[number]], value)
>>> }
>>>
>>> endtime <- Sys.time()
>>>
>>> print(format(endtime - starttime))
>>>
>>> -----
>>>
>>> "47.15579 secs"
>>>
>>>
>>>
>>> The python code:
>>>
>>> -----
>>>
>>> import random
>>> import time
>>>
>>> numbers = []
>>> for i in range(5):
>>>      numbers += random.sample(range(30000), 10000)
>>>
>>> values = []
>>> for i in range(len(numbers)):
>>>      values.append(random.randint(1, 10))
>>>
>>> starttime = time.time()
>>>
>>> d = {}
>>> for i in range(len(numbers)):
>>>      number = numbers[i]
>>>      value = values[i]
>>>      if d.has_key(number):
>>>          d[number].append(value)
>>>      else:
>>>          d[number] = [value]
>>>
>>> endtime = time.time()
>>>
>>> print endtime - starttime, "seconds"
>>>
>>> -----
>>>
>>> 0.123021125793 seconds
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From tomnyberg at gmail.com  Thu Oct 30 18:14:20 2014
From: tomnyberg at gmail.com (Thomas Nyberg)
Date: Thu, 30 Oct 2014 13:14:20 -0400
Subject: [R] How to speed up list access in R?
In-Reply-To: <CADv2QyEwkYMm8oEwX9oC4NihsfXaUsUB0ZHcr90FdX0TtfmMYw@mail.gmail.com>
References: <545256A7.2070709@gmail.com>
	<CADv2QyEwkYMm8oEwX9oC4NihsfXaUsUB0ZHcr90FdX0TtfmMYw@mail.gmail.com>
Message-ID: <545271EC.6030908@gmail.com>

(CCing the list because I definitely think it would be useful to have 
this in the archives.)

Thanks so much! It's clear that I'm going to need to read this email 
plus references quite a few times before things sink in. I guess I'll 
have to change my point of view entirely for this language. I understand 
much of the theory behind functional languages and have made much use of 
vectorization in programming in the past, but I tended to only do that 
when absolutely necessary to avoid complexity. I guess I really will 
have to fundamentally change my programming style and turn that theory 
into practice.

Thanks again everyone!

Cheers,
Thomas

On 10/30/2014 12:58 PM, Dennis Murphy wrote:
> Hi:
>
> You're making several fundamental mistakes that people who move to R
> from a conventional programming language often make. The ones that are
> immediately apparent are:
>
> (i) Initializing empty objects.
> (ii) Populating the object one element at a time.
> (iii) An over-reliance on for loops to do the job.
>
> One of the most important features of R is the concept of
> vectorization, which basically means "program the entire object, not
> its pieces". Item (ii) usually guarantees slow processing because R
> uses lazy evaluation, which means that in cases like yours, the memory
> used in each iteration is accumulated until the loop is complete,
> which in turn means that iterations will get progressively longer as R
> has to search harder for memory. One quick fix to (ii) is to
> pre-allocate the required space, but the better fix is to use
> vectorization whenever possible, because then the actual looping takes
> place at the compiler level rather than inside the interpreter - the
> former is generally much faster.
>
> If I read your code properly, you may have meant to do something like this:
>
> numbers <- sample(seq(30000), 50000, replace = TRUE)
> values <- sample(seq(10), 50000, replace = TRUE)
> L <- split(numbers, values)
> sapply(L, length)    # returns the length of each of the ten
> subvectors in the list
>
> The time it takes to create the list on my system:
>
>> system.time({
> + numbers <- sample(seq(30000), 50000, replace = TRUE)
> + values <- sample(seq(10), 50000, replace = TRUE)
> + L <- split(numbers, values)  })
>     user  system elapsed
>        0       0       0
>
> The length of the numeric vectors associated with each value:
>
> sapply(L, length)
>     1    2    3    4    5    6    7    8    9   10
> 4976 4968 4912 5111 5009 5074 4987 4950 5166 4847
>
> Notice the following features of my code:
>
> * no object initialization
> * no loops
>
>
> More comments inline.
>
> On Thu, Oct 30, 2014 at 8:17 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
>> Hello,
>>
>> I want to do the following: Given a set of (number, value) pairs, I want to
>> create a list l so that l[[toString(number)]] returns the vector of values
>> associated to that number. It is hundreds of times slower than the
>> equivalent that I would write in python. I'm pretty new to R so I bet I'm
>> using its data structures inefficiently, but I've tried more or less
>> everything I can think of and can't really speed it up. I have done some
>> profiling which helped me find problem areas, but I couldn't speed things up
>> even with that information. I'm thinking I'm just fundamentally using R in a
>> silly way.
>>
>> I've included code for the different versions. I wrote the python code in a
>> style to make it as clear to R programmers as possible. Thanks a lot! Any
>> help would be greatly appreciated!
>>
>> Cheers,
>> Thomas
>>
>>
>> R code (with two versions depending on commenting):
>>
>> -----
>>
>> numbers <- numeric(0)
>> for (i in 1:5) {
>>      numbers <- c(numbers, sample(1:30000, 10000))
>> }
>>
>> values <- numeric(0)
>> for (i in 1:length(numbers)) {
>>      values <- append(values, sample(1:10, 1))
>> }
>
> The two loops above are classic cases of initializing empty vectors
> and populating them one element at a time. This may be efficient in
> Python, C or Java, but it is not so in R because R uses lazy
> evaluation, which means that an expression is not evaluated until its
> values are needed. In this case, they are needed at the end of the
> loop.
>
> When you have the time, download Patrick Burns' classic R Inferno,
> which covers this problem as well as many other "gotchas" that bite
> the inexperienced R programmer.
>>
>>             starttime <- Sys.time()
>>
>> d = list()
>> for (i in 1:length(numbers)) {
>>      number = toString(numbers[i])
>>      value = values[i]
>>      if (is.null(d[[number]])) {
>>      #if (number %in% names(d)) {
>>          d[[number]] <- c(value)
>>      } else {
>>          d[[number]] <- append(d[[number]], value)
>>      }
>> }
>
> (1) Conversion to string is unnecessary.
> (2) Use of append() is unnecessary. As Bill mentioned, split()
> performs the same purpose as your code.
>
> One use of list objects in R allows for its components to have the
> same type but different lengths.
>
> The takeaway: efficient programming in Python does not necessarily
> translate to efficient programming in R. You need to think somewhat
> differently in R. My approach is to think in terms of entire objects
> rather than its elements and program accordingly, which comes in handy
> as I can do
>
> mean(x)      # find the arithmetic average of the numeric vector x
> median(x)   # find the sample median of the numeric vector x
>
> etc., which are vectorized functions. Trying to program these in a
> standard programming language requires a lot more code and as a result
> the code is clunkier and less transparent to an external reader.
>
> Dennis
>
>>
>> endtime <- Sys.time()
>>
>> print(format(endtime - starttime))
>>
>> -----
>>
>> uncommented version: "45.64791 secs"
>> commented version: "1.423056 mins"
>>
>>
>>
>> Another version of R code:
>>
>> -----
>>
>> numbers <- numeric(0)
>> for (i in 1:5) {
>>      numbers <- c(numbers, sample(1:30000, 10000))
>> }
>>
>> values <- numeric(0)
>> for (i in 1:length(numbers)) {
>>      values <- append(values, sample(1:10, 1))
>> }
>>
>> starttime <- Sys.time()
>>
>> d = list()
>> for (number in unique(numbers)) {
>>      d[[toString(number)]] <- numeric(0)
>> }
>> for (i in 1:length(numbers)) {
>>      number = toString(numbers[i])
>>      value = values[i]
>>      d[[number]] <- append(d[[number]], value)
>> }
>>
>> endtime <- Sys.time()
>>
>> print(format(endtime - starttime))
>>
>> -----
>>
>> "47.15579 secs"
>>
>>
>>
>> The python code:
>>
>> -----
>>
>> import random
>> import time
>>
>> numbers = []
>> for i in range(5):
>>      numbers += random.sample(range(30000), 10000)
>>
>> values = []
>> for i in range(len(numbers)):
>>      values.append(random.randint(1, 10))
>>
>> starttime = time.time()
>>
>> d = {}
>> for i in range(len(numbers)):
>>      number = numbers[i]
>>      value = values[i]
>>      if d.has_key(number):
>>          d[number].append(value)
>>      else:
>>          d[number] = [value]
>>
>> endtime = time.time()
>>
>> print endtime - starttime, "seconds"
>>
>> -----
>>
>> 0.123021125793 seconds
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From gbediaga at gmail.com  Thu Oct 30 18:14:57 2014
From: gbediaga at gmail.com (Gustavo Bediaga)
Date: Thu, 30 Oct 2014 10:14:57 -0700 (PDT)
Subject: [R] PCA on stacked raster (multiple bands/ layers) in R
In-Reply-To: <CAJgdCD65pseb-t5yEbteryPAcS+-X-vy8kp1_B3Ar3Xzjfq4wA@mail.gmail.com>
References: <CAJgdCD65pseb-t5yEbteryPAcS+-X-vy8kp1_B3Ar3Xzjfq4wA@mail.gmail.com>
Message-ID: <477f18e9-4342-4d9b-91d7-19fa3bbcf8dd@googlegroups.com>

Hi,

You have to transform it to a Data Frame.

Try:

files <- stack(rasterlist)

filesdf<-as.data.frame(files)

pca <- princomp(formula = ~., data = filesdf, cor = TRUE, 
na.action=na.exclude)


hope it helps

Gustavo

Em quinta-feira, 30 de outubro de 2014 14h38min56s UTC-2, John Wasige 
escreveu:
>
> Hello community, I need help on how I can perform PCA on stacked raster
> (multiple bands/ layers) in R. Does any body have an idea or script? 
> Thanks?
> John
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-h... at r-project.org <javascript:> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

From jim at bitwrit.com.au  Thu Oct 30 21:19:01 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 31 Oct 2014 07:19:01 +1100
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <54511FF3.5090606@gmail.com>
References: <54511FF3.5090606@gmail.com>
Message-ID: <8472588.RvbE93ndq3@localhost.localdomain>

On Wed, 29 Oct 2014 05:12:19 PM CJ Davies wrote:
> I am trying to show that the red line ('yaw') in the upper of the two
> plots here;
> 
> http://i.imgur.com/N4Xxb4f.png
> 
> varies more within the pink sections ('transition 1') than in the light
> blue sections ('real').
> 
> I tried to use var.test() however this runs into a problem because
> although the red line doesn't vary much *within* any particular light
> blue section, it does vary a lot *between* light blue sections.
> 
> For example, in the light blue section around t=90 the red line 
doesn't
> move much & likewise in the light blue section around t=160 the 
red line
> doesn't move much. But between these two sections the red line 
has moved
> substantially.
> 
> So if I simply subset the data according to pink/light blue & then put
> those resultant subsets into var.test(), the answer does not show 
the
> relationship that I want it to.
> 
> Can anybody shed some light on a sensible method of solving this?
> 
Hi CJ,
If your dataset has the transition type coded for each observation:

rotation	transition 
90		blue
90		blue
115		pink
-10		pink
30		green
...

you could aggregate all the observations within each transition type 
and test that.

Jim


From mccormack at molbio.mgh.harvard.edu  Thu Oct 30 21:46:51 2014
From: mccormack at molbio.mgh.harvard.edu (Matthew)
Date: Thu, 30 Oct 2014 16:46:51 -0400
Subject: [R] change default installation of R
Message-ID: <5452A3BB.1050007@molbio.mgh.harvard.edu>

I have R version 2.15.0 installed in /usr/local/bin, and this is the 
default; in other words when I type which R this is the path I get.

I also have installed R into/usr/local/R-3.1.1/.   I used ./configure 
and then make to install this version. After make, I get the following 
error messages:

../unix/sys-std.o: In function `initialize_rlcompletion':
/usr/local/R-3.1.1/src/unix/sys-std.c:689: undefined reference to 
`rl_sort_completion_matches'
collect2: ld returned 1 exit status
make[3]: *** [R.bin] Error 1
make[3]: Leaving directory `/usr/local/R-3.1.1/src/main'
make[2]: *** [R] Error 2
make[2]: Leaving directory `/usr/local/R-3.1.1/src/main'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/usr/local/R-3.1.1/src'
make: *** [R] Error 1

I want to change R-3.1.1 to the default, so that when I type which R, I 
get /usr/local/R-3.1.1

To do this I first cd'd into /usr/local/bin and renamed R to R-old_10-30-14
then created a symlink by 'ln -s /usr/local/R-3.1.1/bin  R'
but when I type which R, I get 'no R in ... , where ' . . . ' is my PATH 
variable.

If I remove the symlink and then create another one with ln -s 
/usr/local/R-3.1.1/bin/R  R,
then after typing 'which R', I get
/usr/local/bin/R: line 259: /usr/local/R-3.1.1/bin/exe
c/R: No such file or directory
/usr/local/bin/R: line 259: exec: /usr/local/R-3.1.1/bin/exec/R: cannot 
execute: No such file or directory

This is the same message I get if I just type at the command line: 
/usr/local/R-3.1.1/bin/R.

Matthew

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Thu Oct 30 22:09:10 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 30 Oct 2014 16:09:10 -0500
Subject: [R] How to speed up list access in R?
In-Reply-To: <CAF8bMcaKuzj+kFx4+=+Uww187QwO_01+Lnf+FZsMdD3SJS5oXQ@mail.gmail.com>
References: <545256A7.2070709@gmail.com>
	<CAF8bMcY0wjEP+4FYOUD_3=8e0FVgBDbTKWAAQvyAi5TXSqnjjQ@mail.gmail.com>
	<54526F33.40309@gmail.com>
	<CAF8bMcaKuzj+kFx4+=+Uww187QwO_01+Lnf+FZsMdD3SJS5oXQ@mail.gmail.com>
Message-ID: <CABdHhvFydbahgUo6TQYD295euqJFNpLW-NsGNbCfq8sMaK+4Fg@mail.gmail.com>

Or do all the subsetting in one pass - [ will use a hashmap.

Hadley

On Thu, Oct 30, 2014 at 12:05 PM, William Dunlap <wdunlap at tibco.com> wrote:
> You can try using an environment instead of a list.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
>
> On Thu, Oct 30, 2014 at 10:02 AM, Thomas Nyberg <tomnyberg at gmail.com> wrote:
>> Thanks to all for the help everyone! For the moment I'll stick with Bill's
>> solution, but I'll check out the other recommendations as well.
>>
>> Regarding the issue of slow looks ups for lists, are there any hash map
>> implementations in R that are faster? I like using fairly simple logic and
>> data structures when prototyping and then only optimize code when and where
>> it's necessary which is why I'm curious about these basic objects.
>>
>> On another note, is there a vector style implementation that changes the
>> vectors in place? If I'm not mistaken, the append operation creates and
>> returns a new vector each time which is line with the functional nature of
>> R. If there were some way to have it mutable, it could be much faster. This
>> is fairly standard in many languages. Behind the scenes memory is allocated
>> at say 2 times the current size so that you only need log(n) extensions when
>> building up a vector like this. Are there any such equivalents in R? I
>> presume that lists are mutable (am I wrong?), but they seem to have the
>> lookup slowdown problem.
>>
>> Again thanks a lot!
>>
>> Cheers,
>> Thomas
>>
>>
>> On 10/30/2014 12:05 PM, William Dunlap wrote:
>>>
>>> Repeatedly extending vectors takes a lot of time.  You can do what you
>>> want with
>>>    d2 <- split(values, factor(numbers, levels=unique(numbers)))
>>> If you would like the labels on d2 to be in numeric order then you can
>>> simplify that to
>>>    d3 <- split(values, numbers)
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>>
>>>
>>> On Thu, Oct 30, 2014 at 8:17 AM, Thomas Nyberg <tomnyberg at gmail.com>
>>> wrote:
>>>>
>>>> Hello,
>>>>
>>>> I want to do the following: Given a set of (number, value) pairs, I want
>>>> to
>>>> create a list l so that l[[toString(number)]] returns the vector of
>>>> values
>>>> associated to that number. It is hundreds of times slower than the
>>>> equivalent that I would write in python. I'm pretty new to R so I bet I'm
>>>> using its data structures inefficiently, but I've tried more or less
>>>> everything I can think of and can't really speed it up. I have done some
>>>> profiling which helped me find problem areas, but I couldn't speed things
>>>> up
>>>> even with that information. I'm thinking I'm just fundamentally using R
>>>> in a
>>>> silly way.
>>>>
>>>> I've included code for the different versions. I wrote the python code in
>>>> a
>>>> style to make it as clear to R programmers as possible. Thanks a lot! Any
>>>> help would be greatly appreciated!
>>>>
>>>> Cheers,
>>>> Thomas
>>>>
>>>>
>>>> R code (with two versions depending on commenting):
>>>>
>>>> -----
>>>>
>>>> numbers <- numeric(0)
>>>> for (i in 1:5) {
>>>>      numbers <- c(numbers, sample(1:30000, 10000))
>>>> }
>>>>
>>>> values <- numeric(0)
>>>> for (i in 1:length(numbers)) {
>>>>      values <- append(values, sample(1:10, 1))
>>>> }
>>>>
>>>>             starttime <- Sys.time()
>>>>
>>>> d = list()
>>>> for (i in 1:length(numbers)) {
>>>>      number = toString(numbers[i])
>>>>      value = values[i]
>>>>      if (is.null(d[[number]])) {
>>>>      #if (number %in% names(d)) {
>>>>          d[[number]] <- c(value)
>>>>      } else {
>>>>          d[[number]] <- append(d[[number]], value)
>>>>      }
>>>> }
>>>>
>>>> endtime <- Sys.time()
>>>>
>>>> print(format(endtime - starttime))
>>>>
>>>> -----
>>>>
>>>> uncommented version: "45.64791 secs"
>>>> commented version: "1.423056 mins"
>>>>
>>>>
>>>>
>>>> Another version of R code:
>>>>
>>>> -----
>>>>
>>>> numbers <- numeric(0)
>>>> for (i in 1:5) {
>>>>      numbers <- c(numbers, sample(1:30000, 10000))
>>>> }
>>>>
>>>> values <- numeric(0)
>>>> for (i in 1:length(numbers)) {
>>>>      values <- append(values, sample(1:10, 1))
>>>> }
>>>>
>>>> starttime <- Sys.time()
>>>>
>>>> d = list()
>>>> for (number in unique(numbers)) {
>>>>      d[[toString(number)]] <- numeric(0)
>>>> }
>>>> for (i in 1:length(numbers)) {
>>>>      number = toString(numbers[i])
>>>>      value = values[i]
>>>>      d[[number]] <- append(d[[number]], value)
>>>> }
>>>>
>>>> endtime <- Sys.time()
>>>>
>>>> print(format(endtime - starttime))
>>>>
>>>> -----
>>>>
>>>> "47.15579 secs"
>>>>
>>>>
>>>>
>>>> The python code:
>>>>
>>>> -----
>>>>
>>>> import random
>>>> import time
>>>>
>>>> numbers = []
>>>> for i in range(5):
>>>>      numbers += random.sample(range(30000), 10000)
>>>>
>>>> values = []
>>>> for i in range(len(numbers)):
>>>>      values.append(random.randint(1, 10))
>>>>
>>>> starttime = time.time()
>>>>
>>>> d = {}
>>>> for i in range(len(numbers)):
>>>>      number = numbers[i]
>>>>      value = values[i]
>>>>      if d.has_key(number):
>>>>          d[number].append(value)
>>>>      else:
>>>>          d[number] = [value]
>>>>
>>>> endtime = time.time()
>>>>
>>>> print endtime - starttime, "seconds"
>>>>
>>>> -----
>>>>
>>>> 0.123021125793 seconds
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From jim at bitwrit.com.au  Thu Oct 30 22:33:06 2014
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 31 Oct 2014 08:33:06 +1100
Subject: [R] Variance of multiple non-contiguous time periods?
In-Reply-To: <8472588.RvbE93ndq3@localhost.localdomain>
References: <54511FF3.5090606@gmail.com>
	<8472588.RvbE93ndq3@localhost.localdomain>
Message-ID: <4408509.xBT3BS7zPY@localhost.localdomain>

On Fri, 31 Oct 2014 07:19:01 AM Jim Lemon wrote:
> On Wed, 29 Oct 2014 05:12:19 PM CJ Davies wrote:
> > I am trying to show that the red line ('yaw') in the upper of the two
> > plots here;
> > 
> > http://i.imgur.com/N4Xxb4f.png
> > 
> > varies more within the pink sections ('transition 1') than in the 
light
> > blue sections ('real').
> > 
> > I tried to use var.test() however this runs into a problem because
> > although the red line doesn't vary much *within* any particular 
light
> > blue section, it does vary a lot *between* light blue sections.
> > 
> > For example, in the light blue section around t=90 the red line
> 
> doesn't
> 
> > move much & likewise in the light blue section around t=160 the
> 
> red line
> 
> > doesn't move much. But between these two sections the red line
> 
> has moved
> 
> > substantially.
> > 
> > So if I simply subset the data according to pink/light blue & then 
put
> > those resultant subsets into var.test(), the answer does not show
> 
> the
> 
> > relationship that I want it to.
> > 
> > Can anybody shed some light on a sensible method of solving 
this?
> 
> Hi CJ,
> If your dataset has the transition type coded for each observation:
> 
> rotation	transition
> 90		blue
> 90		blue
> 115		pink
> -10		pink
> 30		green
> ...
> 
> you could aggregate all the observations within each transition type
> and test that.
> 
> Jim
> 
Oops,
What I meant was aggregate all the _deviations_ within each transition 
type.

Jim


From alemu.tadesse at gmail.com  Fri Oct 31 01:00:40 2014
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Thu, 30 Oct 2014 18:00:40 -0600
Subject: [R] problem with Zenith angle calculation
Message-ID: <CACGkHRP2T3Y19-3z1yXBhkb2AOJzhvcY=kRxPhdh2MSViFx-ag@mail.gmail.com>

Dea R users,

In the package insol
I was trying to calculate sunzenith angle. I am using two different date
formats as shown below and both give me different results. Comapring the
results from NOAA website the one below is correct.

xx<-JD(ISOdate(2010,10,1,11))
sv=sunvector(xx,lat,lon,tmz)
zenith=sunpos(sv)
azimuth<-zenith[1,1]
zenith<-zenith[1,2]
zenith
[1] 40.18603
However, the one below is not correct. I have several datetimes and either
I have to use loop to separate year, month, day hour to use the one above.
when I try insert a vector of year, month, day, hour   the formula above
doesn't work. I wish I know how to do it for several dates correctly using
the one below.


x<-JD(as.POSIXct("2010-10-01 11:00:00",tz="",format="%Y-%m-%d %H:%M:%S"))
sv=sunvector(x,lat,lon,tmz)
zenith=sunpos(sv)
azimuth<-zenith[1,1]
zenith<-zenith[1,2]
 zenith
[1] 77.79948

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 31 02:03:23 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 30 Oct 2014 18:03:23 -0700
Subject: [R] problem with Zenith angle calculation
In-Reply-To: <CACGkHRP2T3Y19-3z1yXBhkb2AOJzhvcY=kRxPhdh2MSViFx-ag@mail.gmail.com>
References: <CACGkHRP2T3Y19-3z1yXBhkb2AOJzhvcY=kRxPhdh2MSViFx-ag@mail.gmail.com>
Message-ID: <C59AF238-97AD-4F2A-ABE1-752494AF48E5@dcn.davis.CA.us>

Your example is not reproducible. For example you don't indicate what lat and lon values you are using.
Nor do you specify what time zone you are working in. These are all crucial to obtain consistency.

I have no experience using the insol package, and had no luck trying it just now, but the maptools package can do the job. You may need to correspond with the insol package maintainer with a reproducible example to figure out if the package is buggy or not.

library(maptools)
Sys.setenv( "Etc/GMT+5" ) # US Eastern no daylight savings
lat <- 40
lon <- -80
dtm <- as.POSIXct( "2014-10-30 10:00:00" )
site <- SpatialPoints( matrix( c( lon, lat ), nrow=1 )
azel <- solarpos( site, dtm )
# 145.2686  28.96532

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 30, 2014 5:00:40 PM PDT, Alemu Tadesse <alemu.tadesse at gmail.com> wrote:
>Dea R users,
>
>In the package insol
>I was trying to calculate sunzenith angle. I am using two different
>date
>formats as shown below and both give me different results. Comapring
>the
>results from NOAA website the one below is correct.
>
>xx<-JD(ISOdate(2010,10,1,11))
>sv=sunvector(xx,lat,lon,tmz)
>zenith=sunpos(sv)
>azimuth<-zenith[1,1]
>zenith<-zenith[1,2]
>zenith
>[1] 40.18603
>However, the one below is not correct. I have several datetimes and
>either
>I have to use loop to separate year, month, day hour to use the one
>above.
>when I try insert a vector of year, month, day, hour   the formula
>above
>doesn't work. I wish I know how to do it for several dates correctly
>using
>the one below.
>
>
>x<-JD(as.POSIXct("2010-10-01 11:00:00",tz="",format="%Y-%m-%d
>%H:%M:%S"))
>sv=sunvector(x,lat,lon,tmz)
>zenith=sunpos(sv)
>azimuth<-zenith[1,1]
>zenith<-zenith[1,2]
> zenith
>[1] 77.79948
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lordpreetam at gmail.com  Fri Oct 31 05:27:18 2014
From: lordpreetam at gmail.com (Preetam Pal)
Date: Fri, 31 Oct 2014 09:57:18 +0530
Subject: [R] Dropping variables from data set
Message-ID: <54530ff2.aa77420a.5660.ffff9f7c@mx.google.com>

 Hi,
I have 15 variables x1, x2, .... , x15 and I want to create 15 data sets where the i-th data set D-i will be contain all variables except the variable, x-i, for i in 1 to 15. It would be great if someone can help me out with this. I have had very little exposure to R or general coding before this.
Thanks,
Preetam
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 31 05:48:22 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 30 Oct 2014 21:48:22 -0700
Subject: [R] Dropping variables from data set
In-Reply-To: <54530ff2.aa77420a.5660.ffff9f7c@mx.google.com>
References: <54530ff2.aa77420a.5660.ffff9f7c@mx.google.com>
Message-ID: <615371D1-B9DC-4A63-B9A7-4CA62D27F764@dcn.davis.CA.us>

Sounds like homework. See the Posting Guide.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 30, 2014 9:27:18 PM PDT, Preetam Pal <lordpreetam at gmail.com> wrote:
> Hi,
>I have 15 variables x1, x2, .... , x15 and I want to create 15 data
>sets where the i-th data set D-i will be contain all variables except
>the variable, x-i, for i in 1 to 15. It would be great if someone can
>help me out with this. I have had very little exposure to R or general
>coding before this.
>Thanks,
>Preetam
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lordpreetam at gmail.com  Fri Oct 31 07:14:07 2014
From: lordpreetam at gmail.com (Preetam Pal)
Date: Fri, 31 Oct 2014 11:44:07 +0530
Subject: [R] Variable selection from given data
Message-ID: <545328c0.a985440a.75f4.ffffa7ad@mx.google.com>

Hi,

I am doing quantile regression of y on a set of 15 explanatory variables x1, x2,....x15. I want to run 15 regression models where in the i-th model, y would be regressed on all x variables except x-i. Then I would compare the results. At this point, I donot know how to create the 15 data sets by dropping the individual x variables. Any help to create the corresponding data sets would be appreciated. I am new to R or general coding.
Thanks,
Preetam
	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri Oct 31 07:30:18 2014
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 30 Oct 2014 23:30:18 -0700
Subject: [R] Variable selection from given data
In-Reply-To: <545328c0.a985440a.75f4.ffffa7ad@mx.google.com>
References: <545328c0.a985440a.75f4.ffffa7ad@mx.google.com>
Message-ID: <5616DC95-A3F9-44D0-B115-E7B8A6D4EC53@comcast.net>

Untested and with the presumption that you have the appropriate package loaded:

sapply(1:15, function(x) qr(y ~ ., df[-grep(paste0(?x?,i)]) )


> On Oct 30, 2014, at 11:14 PM, Preetam Pal <lordpreetam at gmail.com> wrote:
> 
> Hi,
> 
> I am doing quantile regression of y on a set of 15 explanatory variables x1, x2,....x15. I want to run 15 regression models where in the i-th model, y would be regressed on all x variables except x-i. Then I would compare the results. At this point, I donot know how to create the 15 data sets by dropping the individual x variables. Any help to create the corresponding data sets would be appreciated. I am new to R or general coding.
> Thanks,
> Preetam
> 	[[alternative HTML version deleted]]
> 
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html

The posting guide requests that you learn to post in plain text.

> and provide commented, minimal, self-contained, reproducible code.

? and provide an example to get tested code.


David Winsemius, MD
Alameda, CA, USA


From parvin_dehghani at yahoo.com  Fri Oct 31 07:44:10 2014
From: parvin_dehghani at yahoo.com (Parvin Dehghani)
Date: Fri, 31 Oct 2014 06:44:10 +0000 (UTC)
Subject: [R] MLE
Message-ID: <1074657628.52427.1414737850149.JavaMail.yahoo@jws10633.mail.bf1.yahoo.com>

HiI have a probability mass function similar to?pr(N=n)= integral(((2-x)^n)*(exp(ax-2))) - integral (((5-ax)^n)), ? both integrals are defined over the interval(0,2) with respect to x.?I am going to estimate the parameter (a) with method of maximum likelihood estimation. The loglikelihood ?is : ? ? ? ? ? ? ? [F log(pr(n))]=lnL??where F is the vector of observations and (n) is the vector of input for ?the defined pmf?.?Can anybody suggest me the fastest way of getting the MLE?I have tried this program:n<-c(0,1,2,3,4,5,6,7,8)F<-c(0,0,1,3,5,7,8,11,10)loglik<- function(a) {sum(F*log(pr(n)))}re<- maxlik(loglik, start=.5)summary(re)
I don't know how to define the probability mass function ( pr(n) ) in the written program.I would appreciate for any help.Best Regards


	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Fri Oct 31 11:13:24 2014
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Fri, 31 Oct 2014 11:13:24 +0100
Subject: [R]   R 3.1.2 is released
Message-ID: <97264A18-3A52-4B9B-B97F-A78923BE6818@cbs.dk>

The build system rolled up R-3.1.2.tar.gz (codename "Pumpkin Helmet") this morning.

The list below details the changes in this release.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.1.2.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course. 

For the R Core Team

Peter Dalgaard


These are the md5sums for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = 23bbd5f6f8060f187cc02a7b84b342b5
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = c1e4c113071453c7832e5d9ecea623eb
MD5 (INSTALL) = 3964b9119adeaab9ceb633773fc94aac
MD5 (NEWS) = 15cc434143e5e9a8ae3d34eead26521c
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 8e2f4d1d5228663ae598a09bf1e2bc6b
MD5 (NEWS.html) = 561c491e3bf9554c86675b614c85d34c
MD5 (R-latest.tar.gz) = 3af29ec06704cbd08d4ba8d69250ae74
MD5 (R.css) = 444535b9cb76ddff1bab1e1865a3fb14
MD5 (README) = aece1dfbd18c1760128c3787f5456af6
MD5 (RESOURCES) = a59076c1ac7e9bab0f0a38b3f57a3914
MD5 (THANKS) = 1989ce89fb3891420c9964dc418ab71c
MD5 (R-3/R-3.1.2.tar.gz) = 3af29ec06704cbd08d4ba8d69250ae74


This is the relevant part of the NEWS file


CHANGES IN R 3.1.2:

  NEW FEATURES:

    * embedFonts() now defaults to format = "ps2write" for .ps and .eps
      files.  This is available in Ghostscript 9.x (since 2010) whereas
      the previous default, format = "pswrite", was removed in
      Ghostscript 9.10.

    * For consistency with [dpqr]norm(), [dp]lnorm(sdlog = 0) model a
      point mass at exp(mulog) rather than return NaN (for an error).

    * capabilities() now reports if ICU is compiled in for use for
      collation (it is only actually used if a suitable locale is set
      for collation, and never for a C locale).

    * (OS X only.) Package tcltk checks when loaded if it is linked
      against the CRAN X11-based Tcl/Tk and if so that the Tcl/Tk
      component and the X11 libraries are installed.  This allows more
      informative error messages to be given advising the installation
      of the missing component or of XQuartz.

      The X11() device and X11-based versions of the data editor and
      viewer (invoked by edit() and View() for data frames and matrices
      from command-line R) check that the X11 libraries are installed
      and if not advises installing XQuartz.

    * icuSetCollate() allows locale = "default", and locale = "none" to
      use OS services rather than ICU for collation.

      Environment variable R_ICU_LOCALE can be used to set the default
      ICU locale, in case the one derived from the OS locale is
      inappropriate (this is currently necessary on Windows).

    * New function icuGetCollate() to report on the ICU collation
      locale in use (if any).

    * utils::URLencode() was updated to use unreserved and reserved
      characters from RFC 3986, <URL:
      http://tools.ietf.org/html/rfc3986>, instead of RFC 1738.

    * unique(warnings()) and c(warnings()) are now supported.

    * The Bioconductor 'version' used by setRepositories() now defaults
      to 3.0. (It can be set at runtime _via_ environment variable
      R_BIOC_VERSION.)

  INSTALLATION and INCLUDED SOFTWARE:

    * The configure script reports on the more important
      capabilities/options which will not be compiled in.

      More types of external BLAS are recognized by name in that
      report.

    * When building R as a shared library, the -L${R_HOME}/lib${R_ARCH}
      flag is placed earlier in the link commands used during
      installation and when packages are installed: this helps ensure
      that the current build has priority if an R shared library has
      already been installed by e.g. install-libR in a library
      mentioned in LDFLAGS (and not in 'your system's library
      directory' as documented). (Wish of PR#15790.)

    * LaTeX package upquote is no longer required for R's use of
      inconsolata.

    * (Windows only) If both 32 and 64 bit versions of R are installed,
      the bin/R.exe and bin/Rscript.exe executables now run 64 bit R.
      (To run 32 bit R, overwrite these files with copies of
      bin/i386/Rfe.exe.)

  UTILITIES:

    * Running R CMD check with _R_CHECK_DEPENDS_ONLY_ true now makes
      the VignetteBuilder packages available even if they are listed in
      Suggests, since they are needed to recognise and process
      non-Sweave vignettes.

    * R CMD check now reports empty importFrom declarations in a
      NAMESPACE file, as these are common errors (writing
      importFrom(Pkg) where import(Pkg) was intended).

    * R CMD check now by default checks code usage directly on the
      package namespace without loading and attaching the package and
      its suggests and enhances.  For good practice with packages in
      the Suggests field, see SS1.1.3.1 of 'Writing R Extensions'.  For
      use of lazy-data objects in the package's own code, see ?data.

  BUG FIXES:

    * dmultinom() did not handle non-finite probabilities correctly.

    * prettyNum(x, zero.print=*) now also works when x contains NAs.

    * A longstanding bug exhibited by nlminb() on Windows was traced to
      a compiler bug in gcc 4.6.3; a workaround has been put in place.
      (PR#15244 and PR#15914).

    * Rendering of \command in HTML versions of help pages has been
      improved: this is particularly evident on the help page for
      INSTALL.

    * as.hexmode(x) and as.octmode(x) now behave correctly for some
      numeric x, e.g., c(NA, 1) or c(1, pi).

    * drop1() failed if the scope argument had no variables to drop.
      (PR#15935)

    * edit() (and hence fix()) failed if an object had a non-character
      attribute named "source" (an attribute that had been used in R
      prior to version 2.14.0).

    * callGeneric() could fail if the generic had ... as a formal
      argument. (PR#15937).

    * Forking in package parallel called C entry point exit in the
      child.  This was unsafe (_exit should have been called), and
      could flush stdin of the main R process (seen most often on
      Solaris).

      As good practice, stdout is now flushed before forking a child.

    * R objects such as list(`a\b` = 1) now print correctly.

    * getAnywhere("C_pbinom") now returns correctly a single object
      (rather than unlisting it).

    * The confint() method for nls() fits failed it these has specified
      parameter limits despite using an algorithm other than "port".
      (PR#15960)

    * Subclassing an S4 class failed if the class required arguments to
      the generator, through its initialize() method.

    * removeSource() did not properly handle expressions containing
      arguments that were supplied as missing, e.g.  x[i,]. (PR#15957)

    * as.environment(list()) now works, and as.list() of such an
      environment is now the same as list().

    * Several tcltk functions failed when run in unusual environments.
      (PR#15970)

    * options(list()) now works (trivially). (PR#15979)

    * merge(<dendrogram>, ..) now works correctly for two `independent'
      dendrograms (PR#15648), and still compatibly via adjust = "auto"
      e.g. for two branches of an existing dendrogram.

    * The plot method for "hclust" objects gets an optional argument
      check; When that is true (the default) it checks more carefully
      for valid input.

    * (Windows only) If a user chose to install 64 bit R but not 32 bit
      R, the bin/R and bin/Rscript executables failed to run.
      (PR#15981)

    * Various possible buffer overruns have been prevented, and missed
      memory protection added. (PR#15990)

    * Rscript no longer passes --args to R when there are no extra
      ("user") arguments.

    * objects like getClass("refClass")@prototype now print() and str()
      without error.

    * identical() now also looks at the S4 bit.

    * hist(x, breaks) is more robust in adding a small fuzz to few
      breaks when some are very large. (PR#15988)

    * sub() and gsub() did not handle regular expressions like "\s{2,}"
      properly if the text contained NA or non-ascii elements in a
      UTF-8 locale.  Part of this was due to a bug in the TRE library.
      (PR#16009)

    * RShowDoc("NEWS") now displays the PDF version.

    * Matrices and arrays with last dimension zero did not print at all
      or incompletely.  (PR#16012)

    * plot.histogram() and hence hist() now respect the xaxs, yaxs and
      lab graphics parameters.  (PR#16021)

    * bw.SJ(x) and other bw.*() no longer segfault when x contains
      non-finite values. (PR#16024)

    * R CMD Rd2pdf unintentionally ignored its --os option.

    * The internal method of download.file() was not reporting file
      sizes and progress correctly on files larger than 2GB (inherited
      from libxml2).  This is corrected for 64-bit builds (32-bit
      platforms may not support such files, but where possible will be
      supported in future versions of R).

    * Work around a bug in OS X Yosemite where key environment
      variables may be duplicated causing issues in subprocesses. The
      duplicates are now removed on R startup (via Rprofile).
      (PR#16042)

    * Adjust X11 auto-launch detection in DISPLAY on OS X to recognize
      latest XQuartz.


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From paul.bivand at gmail.com  Fri Oct 31 12:18:29 2014
From: paul.bivand at gmail.com (Paul Bivand)
Date: Fri, 31 Oct 2014 11:18:29 +0000
Subject: [R] R and Newest version of Java
In-Reply-To: <544FE3B7.8010506@stats.ox.ac.uk>
References: <CAPgUJvNWRtzwOVfETKhsPOhgV_FL+6MYzH_q0-dG+We=u-XCaQ@mail.gmail.com>
	<544FE3B7.8010506@stats.ox.ac.uk>
Message-ID: <CAC=KSNi3RAo7dQaE3559=Qp5ZFLnoZpAJHtrxTXR-MSaYjnbHg@mail.gmail.com>

After updating Java, I have to run R CMD javareconf. On Windows
64-bit, the java default updater has in the past removed the 64-bit
version as it updates that wanted for 32-bit browsers. The 64-bit
version needed reinstalling manually.

Paul Bivand

On 28 October 2014 18:43, Prof Brian Ripley <ripley at stats.ox.ac.uk> wrote:
> On 28/10/2014 16:47, Antonio Paredes wrote:
>>
>> Hell All,
>>
>> Last night I updated Java to it newest version and this morning when I got
>> to my office some of the R packages, that I am using in a current project,
>> are not loading at all. For example
>>
>> Loading required package: XLConnectJars
>> Error : .onLoad failed in loadNamespace() for 'rJava', details:
>>    call: fun(libname, pkgname)
>>    error: No CurrentVersion entry in Software/JavaSoft registry! Try
>> re-installing Java and make sure R and Java have matching architectures.
>> Error: package ?XLConnectJars? could not be loaded
>>
>> I did re-installed Java but the issue continues. Are there any known
>> issues
>> associated with how R is interacting with the latest version of Java?
>
>
> Whatever that version is and whatever platform this is (for the latter, see
> the posting guide)!
>
> If you mean Oracle Java, I use the current 8u25 on several platforms.
>
> At a guess this is Windows and you installed 32-bit Java for use with 64-bit
> R or v.v.: the architectures have to match ....
>
>>
>> Thank you very much.
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pollaroid at gmail.com  Fri Oct 31 12:33:24 2014
From: pollaroid at gmail.com (Kuma Raj)
Date: Fri, 31 Oct 2014 12:33:24 +0100
Subject: [R] How to update R without losing packages
Message-ID: <CAAC1QdAHBBs4cZC47uUMHhB1-_2AkkpO3ttj3adiyL2Rz+5fdA@mail.gmail.com>

A solution on the link below  provides the steps of updating R without
losing packages in Unix.
http://zvfak.blogspot.se/2012/06/updating-r-but-keeping-your-installed.html

How could I do that on windows 7 platform?

Thanks


From prgosek at gmail.com  Fri Oct 31 12:56:26 2014
From: prgosek at gmail.com (=?UTF-8?Q?Michal_Kvasni=C4=8Dka?=)
Date: Fri, 31 Oct 2014 12:56:26 +0100
Subject: [R] Knitr: how to find out from within a .Rmd file the output type?
Message-ID: <CALs_GZUbQ3xXUoX6GLBsD08EmK90rUOGG_V_syrRbXZU5akwFw@mail.gmail.com>

Hi.

Is there a way how to find out from within a .Rmd file what output format
is generated?

The reason is this: I write a paper in R markdown in RStudio. Sometimes I
generate .html, sometimes .pdf. My paper presents a table of regression
models using stargazer function. I've got the following code in my paper:

```{r, echo=FALSE, message=FALSE, results='asis'}
model2 <- lm(...)
model3 <- lm(...)
model5 <- lm(...)
stargazer(model2, model3, model5,
          ...,
          type="html")
```

Whenever I change the output format from .html do .pdf, I have to change
the line type="html" to type="latex" manually. (The same holds true for
many other functions, e.g. xtable.)

It would be nice to replace the direct declaration with

      type=some_knitr_variable

What is the true name of the some_knitr_variable? I was not able to find it
anywhere.

Many thanks for your help.

Best wishes,
Michal

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Fri Oct 31 13:50:09 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 31 Oct 2014 12:50:09 +0000
Subject: [R] change default installation of R
In-Reply-To: <5452A3BB.1050007@molbio.mgh.harvard.edu>
References: <5452A3BB.1050007@molbio.mgh.harvard.edu>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412D4E228@GOLD.corp.lgc-group.com>



 
> I want to change R-3.1.1 to the default, so that when I type which R, I get
> /usr/local/R-3.1.1
Change your PATH to include the R 3.1.1 directory instead of the version 2 directory?

S 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Fri Oct 31 14:05:33 2014
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 31 Oct 2014 13:05:33 +0000
Subject: [R] How to update R without losing packages
In-Reply-To: <CAAC1QdAHBBs4cZC47uUMHhB1-_2AkkpO3ttj3adiyL2Rz+5fdA@mail.gmail.com>
References: <CAAC1QdAHBBs4cZC47uUMHhB1-_2AkkpO3ttj3adiyL2Rz+5fdA@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED6412D4E239@GOLD.corp.lgc-group.com>



> A solution on the link below  provides the steps of updating R without losing
> packages in Unix.
> http://zvfak.blogspot.se/2012/06/updating-r-but-keeping-your-installed.html
> 
> How could I do that on windows 7 platform?
See the R Windows FAQ, FAQ 2.8.




*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jdnewmil at dcn.davis.CA.us  Fri Oct 31 14:10:17 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 31 Oct 2014 06:10:17 -0700
Subject: [R] How to update R without losing packages
In-Reply-To: <CAAC1QdAHBBs4cZC47uUMHhB1-_2AkkpO3ttj3adiyL2Rz+5fdA@mail.gmail.com>
References: <CAAC1QdAHBBs4cZC47uUMHhB1-_2AkkpO3ttj3adiyL2Rz+5fdA@mail.gmail.com>
Message-ID: <C508E2CC-32E7-4B4B-92DA-397106AFDEFF@dcn.davis.CA.us>

Read the comments at the bottom of that blog post.

Note that copying your packages library and updating only works for minor version upgrades... there is no shortcut for a 2.x to 3.x upgrade. That is not your biggest problem though, since not all packages seem to make the jump (become unavailable) during major version changes so some scripts may have to be rewritten to use different approaches anyway. 
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 31, 2014 4:33:24 AM PDT, Kuma Raj <pollaroid at gmail.com> wrote:
>A solution on the link below  provides the steps of updating R without
>losing packages in Unix.
>http://zvfak.blogspot.se/2012/06/updating-r-but-keeping-your-installed.html
>
>How could I do that on windows 7 platform?
>
>Thanks
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From charles.santana at gmail.com  Fri Oct 31 14:12:08 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Fri, 31 Oct 2014 14:12:08 +0100
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
Message-ID: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>

A = matrix(1:10,nrow=5)
B = A[-c(1,2,3),];

So
> A
     [,1] [,2]
[1,]    1    6
[2,]    2    7
[3,]    3    8
[4,]    4    9
[5,]    5   10

and
> B
     [,1] [,2]
[1,]    4    9
[2,]    5   10

I would like to compare A and B in order to find in which rows of A I can
find the  rows of B. Something similar to %in% with one dimensional arrays.
In the example above, the answer should be 4 and 5.

I did a function to do it (see it below), it gives me the correct answer
for this toy example, but the excess of for-loops makes it extremely slow
for larger matrices. I was wondering if there is a better way to do this
kind of comparison. Any idea? Sorry if it is a stupid question.

matbinmata<-function(B,A){
    res<-c();
    rowsB = length(B[,1]);
    rowsA = length(A[,1]);
    colsB = length(B[1,]);
    colsA = length(A[1,]);
    for (i in 1:rowsB){
        for (j in 1:colsB){
            for (k in 1:rowsA){
                for (l in 1:colsA){
                    if(A[k,l]==B[i,j]){res<-c(res,k);}
                }
            }
        }
    }
    return(unique(sort(res)));
}


Best,

Charles


-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From charles.santana at gmail.com  Fri Oct 31 14:20:38 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Fri, 31 Oct 2014 14:20:38 +0100
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
In-Reply-To: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
Message-ID: <CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>

My apologies, because I sent the message before finishing it. i am very
sorry about this. Please find below my message (I use to write the messages
from the end to the beginning... sorry :)).

Dear all,

I am trying to compare two matrices, in order to find in which rows of a
matrix A I can find the same values as in matrix B. I am trying to do it
for matrices with around 2500 elements, but please find below a toy example:

A = matrix(1:10,nrow=5)
B = A[-c(1,2,3),];

So
> A
     [,1] [,2]
[1,]    1    6
[2,]    2    7
[3,]    3    8
[4,]    4    9
[5,]    5   10

and
> B
     [,1] [,2]
[1,]    4    9
[2,]    5   10

I would like to compare A and B in order to find in which rows of A I can
find the  rows of B. Something similar to %in% with one dimensional arrays.
In the example above, the answer should be 4 and 5.

I did a function to do it (see it below), it gives me the correct answer
for this toy example, but the excess of for-loops makes it extremely slow
for larger matrices. I was wondering if there is a better way to do this
kind of comparison. Any idea? Sorry if it is a stupid question.

matbinmata<-function(B,A){
    res<-c();
    rowsB = length(B[,1]);
    rowsA = length(A[,1]);
    colsB = length(B[1,]);
    colsA = length(A[1,]);
    for (i in 1:rowsB){
        for (j in 1:colsB){
            for (k in 1:rowsA){
                for (l in 1:colsA){
                    if(A[k,l]==B[i,j]){res<-c(res,k);}
                }
            }
        }
    }
    return(unique(sort(res)));
}


Best,

Charles

On Fri, Oct 31, 2014 at 2:12 PM, Charles Novaes de Santana <
charles.santana at gmail.com> wrote:

> A = matrix(1:10,nrow=5)
> B = A[-c(1,2,3),];
>
> So
> > A
>      [,1] [,2]
> [1,]    1    6
> [2,]    2    7
> [3,]    3    8
> [4,]    4    9
> [5,]    5   10
>
> and
> > B
>      [,1] [,2]
> [1,]    4    9
> [2,]    5   10
>
> I would like to compare A and B in order to find in which rows of A I can
> find the  rows of B. Something similar to %in% with one dimensional arrays.
> In the example above, the answer should be 4 and 5.
>
> I did a function to do it (see it below), it gives me the correct answer
> for this toy example, but the excess of for-loops makes it extremely slow
> for larger matrices. I was wondering if there is a better way to do this
> kind of comparison. Any idea? Sorry if it is a stupid question.
>
> matbinmata<-function(B,A){
>     res<-c();
>     rowsB = length(B[,1]);
>     rowsA = length(A[,1]);
>     colsB = length(B[1,]);
>     colsA = length(A[1,]);
>     for (i in 1:rowsB){
>         for (j in 1:colsB){
>             for (k in 1:rowsA){
>                 for (l in 1:colsA){
>                     if(A[k,l]==B[i,j]){res<-c(res,k);}
>                 }
>             }
>         }
>     }
>     return(unique(sort(res)));
> }
>
>
> Best,
>
> Charles
>
>
> --
> Um ax?! :)
>
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
>



-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 31 14:21:17 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 31 Oct 2014 06:21:17 -0700
Subject: [R] Knitr: how to find out from within a .Rmd file the output
	type?
In-Reply-To: <CALs_GZUbQ3xXUoX6GLBsD08EmK90rUOGG_V_syrRbXZU5akwFw@mail.gmail.com>
References: <CALs_GZUbQ3xXUoX6GLBsD08EmK90rUOGG_V_syrRbXZU5akwFw@mail.gmail.com>
Message-ID: <6CB007B8-7F74-4DAC-B4B8-D3A959C58DA1@dcn.davis.CA.us>

AFAIK markdown is syntactically incompatible with LaTeX, except for math mode expressions. That is why we have separate extensions Rmd and Rnw for the two types of files. I don't know where one could successfully make use of the variable you are asking about.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 31, 2014 4:56:26 AM PDT, "Michal Kvasni?ka" <prgosek at gmail.com> wrote:
>Hi.
>
>Is there a way how to find out from within a .Rmd file what output
>format
>is generated?
>
>The reason is this: I write a paper in R markdown in RStudio. Sometimes
>I
>generate .html, sometimes .pdf. My paper presents a table of regression
>models using stargazer function. I've got the following code in my
>paper:
>
>```{r, echo=FALSE, message=FALSE, results='asis'}
>model2 <- lm(...)
>model3 <- lm(...)
>model5 <- lm(...)
>stargazer(model2, model3, model5,
>          ...,
>          type="html")
>```
>
>Whenever I change the output format from .html do .pdf, I have to
>change
>the line type="html" to type="latex" manually. (The same holds true for
>many other functions, e.g. xtable.)
>
>It would be nice to replace the direct declaration with
>
>      type=some_knitr_variable
>
>What is the true name of the some_knitr_variable? I was not able to
>find it
>anywhere.
>
>Many thanks for your help.
>
>Best wishes,
>Michal
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jfox at mcmaster.ca  Fri Oct 31 14:35:06 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 31 Oct 2014 09:35:06 -0400
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
In-Reply-To: <CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
Message-ID: <web-533934847@cgpsrv2.cis.mcmaster.ca>

Dear Charles,

How about the following?

----------- snip ---------

> AA <- as.list(as.data.frame(t(A)))
> BB <- as.list(as.data.frame(t(B)))
> which(AA %in% BB)
[1] 4 5

----------- snip ---------

This seems reasonably fast. For example:

----------- snip ---------

> A <- matrix(1:10000, 10000, 10)
> B <- A[1:1000, ]
> 
> system.time({
+   AA <- as.list(as.data.frame(t(A)))
+   BB <- as.list(as.data.frame(t(B)))
+   print(sum(AA %in% BB))
+ })
[1] 1000
   user  system elapsed 
   0.26    0.00    0.26 

----------- snip ---------

I hope this helps,
 John

------------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/
	
	
	

On Fri, 31 Oct 2014 14:20:38 +0100
 Charles Novaes de Santana <charles.santana at gmail.com> wrote:
> My apologies, because I sent the message before finishing it. i am very
> sorry about this. Please find below my message (I use to write the messages
> from the end to the beginning... sorry :)).
> 
> Dear all,
> 
> I am trying to compare two matrices, in order to find in which rows of a
> matrix A I can find the same values as in matrix B. I am trying to do it
> for matrices with around 2500 elements, but please find below a toy example:
> 
> A = matrix(1:10,nrow=5)
> B = A[-c(1,2,3),];
> 
> So
> > A
>      [,1] [,2]
> [1,]    1    6
> [2,]    2    7
> [3,]    3    8
> [4,]    4    9
> [5,]    5   10
> 
> and
> > B
>      [,1] [,2]
> [1,]    4    9
> [2,]    5   10
> 
> I would like to compare A and B in order to find in which rows of A I can
> find the  rows of B. Something similar to %in% with one dimensional arrays.
> In the example above, the answer should be 4 and 5.
> 
> I did a function to do it (see it below), it gives me the correct answer
> for this toy example, but the excess of for-loops makes it extremely slow
> for larger matrices. I was wondering if there is a better way to do this
> kind of comparison. Any idea? Sorry if it is a stupid question.
> 
> matbinmata<-function(B,A){
>     res<-c();
>     rowsB = length(B[,1]);
>     rowsA = length(A[,1]);
>     colsB = length(B[1,]);
>     colsA = length(A[1,]);
>     for (i in 1:rowsB){
>         for (j in 1:colsB){
>             for (k in 1:rowsA){
>                 for (l in 1:colsA){
>                     if(A[k,l]==B[i,j]){res<-c(res,k);}
>                 }
>             }
>         }
>     }
>     return(unique(sort(res)));
> }
> 
> 
> Best,
> 
> Charles
> 
> On Fri, Oct 31, 2014 at 2:12 PM, Charles Novaes de Santana <
> charles.santana at gmail.com> wrote:
> 
> > A = matrix(1:10,nrow=5)
> > B = A[-c(1,2,3),];
> >
> > So
> > > A
> >      [,1] [,2]
> > [1,]    1    6
> > [2,]    2    7
> > [3,]    3    8
> > [4,]    4    9
> > [5,]    5   10
> >
> > and
> > > B
> >      [,1] [,2]
> > [1,]    4    9
> > [2,]    5   10
> >
> > I would like to compare A and B in order to find in which rows of A I can
> > find the  rows of B. Something similar to %in% with one dimensional arrays.
> > In the example above, the answer should be 4 and 5.
> >
> > I did a function to do it (see it below), it gives me the correct answer
> > for this toy example, but the excess of for-loops makes it extremely slow
> > for larger matrices. I was wondering if there is a better way to do this
> > kind of comparison. Any idea? Sorry if it is a stupid question.
> >
> > matbinmata<-function(B,A){
> >     res<-c();
> >     rowsB = length(B[,1]);
> >     rowsA = length(A[,1]);
> >     colsB = length(B[1,]);
> >     colsA = length(A[1,]);
> >     for (i in 1:rowsB){
> >         for (j in 1:colsB){
> >             for (k in 1:rowsA){
> >                 for (l in 1:colsA){
> >                     if(A[k,l]==B[i,j]){res<-c(res,k);}
> >                 }
> >             }
> >         }
> >     }
> >     return(unique(sort(res)));
> > }
> >
> >
> > Best,
> >
> > Charles
> >
> >
> > --
> > Um ax?! :)
> >
> > --
> > Charles Novaes de Santana, PhD
> > http://www.imedea.uib-csic.es/~charles
> >
> 
> 
> 
> -- 
> Um ax?! :)
> 
> --
> Charles Novaes de Santana, PhD
> http://www.imedea.uib-csic.es/~charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From charles.santana at gmail.com  Fri Oct 31 14:39:20 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Fri, 31 Oct 2014 14:39:20 +0100
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
In-Reply-To: <web-533934847@cgpsrv2.cis.mcmaster.ca>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
	<web-533934847@cgpsrv2.cis.mcmaster.ca>
Message-ID: <CAH-FEnjUBRLi=tatcSutbYZDH19pxa6XQ2TdnN4wd810nswj=g@mail.gmail.com>

Great!! It is perfect!

Thank you, John, for this elegant and fast suggestion!

Best,

Charles

On Fri, Oct 31, 2014 at 2:35 PM, John Fox <jfox at mcmaster.ca> wrote:

> Dear Charles,
>
> How about the following?
>
> ----------- snip ---------
>
> > AA <- as.list(as.data.frame(t(A)))
> > BB <- as.list(as.data.frame(t(B)))
> > which(AA %in% BB)
> [1] 4 5
>
> ----------- snip ---------
>
> This seems reasonably fast. For example:
>
> ----------- snip ---------
>
> > A <- matrix(1:10000, 10000, 10)
> > B <- A[1:1000, ]
> >
> > system.time({
> +   AA <- as.list(as.data.frame(t(A)))
> +   BB <- as.list(as.data.frame(t(B)))
> +   print(sum(AA %in% BB))
> + })
> [1] 1000
>    user  system elapsed
>    0.26    0.00    0.26
>
> ----------- snip ---------
>
> I hope this helps,
>  John
>
> ------------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.mcmaster.ca/jfox/
>
>
>
>
> On Fri, 31 Oct 2014 14:20:38 +0100
>  Charles Novaes de Santana <charles.santana at gmail.com> wrote:
> > My apologies, because I sent the message before finishing it. i am very
> > sorry about this. Please find below my message (I use to write the
> messages
> > from the end to the beginning... sorry :)).
> >
> > Dear all,
> >
> > I am trying to compare two matrices, in order to find in which rows of a
> > matrix A I can find the same values as in matrix B. I am trying to do it
> > for matrices with around 2500 elements, but please find below a toy
> example:
> >
> > A = matrix(1:10,nrow=5)
> > B = A[-c(1,2,3),];
> >
> > So
> > > A
> >      [,1] [,2]
> > [1,]    1    6
> > [2,]    2    7
> > [3,]    3    8
> > [4,]    4    9
> > [5,]    5   10
> >
> > and
> > > B
> >      [,1] [,2]
> > [1,]    4    9
> > [2,]    5   10
> >
> > I would like to compare A and B in order to find in which rows of A I can
> > find the  rows of B. Something similar to %in% with one dimensional
> arrays.
> > In the example above, the answer should be 4 and 5.
> >
> > I did a function to do it (see it below), it gives me the correct answer
> > for this toy example, but the excess of for-loops makes it extremely slow
> > for larger matrices. I was wondering if there is a better way to do this
> > kind of comparison. Any idea? Sorry if it is a stupid question.
> >
> > matbinmata<-function(B,A){
> >     res<-c();
> >     rowsB = length(B[,1]);
> >     rowsA = length(A[,1]);
> >     colsB = length(B[1,]);
> >     colsA = length(A[1,]);
> >     for (i in 1:rowsB){
> >         for (j in 1:colsB){
> >             for (k in 1:rowsA){
> >                 for (l in 1:colsA){
> >                     if(A[k,l]==B[i,j]){res<-c(res,k);}
> >                 }
> >             }
> >         }
> >     }
> >     return(unique(sort(res)));
> > }
> >
> >
> > Best,
> >
> > Charles
> >
> > On Fri, Oct 31, 2014 at 2:12 PM, Charles Novaes de Santana <
> > charles.santana at gmail.com> wrote:
> >
> > > A = matrix(1:10,nrow=5)
> > > B = A[-c(1,2,3),];
> > >
> > > So
> > > > A
> > >      [,1] [,2]
> > > [1,]    1    6
> > > [2,]    2    7
> > > [3,]    3    8
> > > [4,]    4    9
> > > [5,]    5   10
> > >
> > > and
> > > > B
> > >      [,1] [,2]
> > > [1,]    4    9
> > > [2,]    5   10
> > >
> > > I would like to compare A and B in order to find in which rows of A I
> can
> > > find the  rows of B. Something similar to %in% with one dimensional
> arrays.
> > > In the example above, the answer should be 4 and 5.
> > >
> > > I did a function to do it (see it below), it gives me the correct
> answer
> > > for this toy example, but the excess of for-loops makes it extremely
> slow
> > > for larger matrices. I was wondering if there is a better way to do
> this
> > > kind of comparison. Any idea? Sorry if it is a stupid question.
> > >
> > > matbinmata<-function(B,A){
> > >     res<-c();
> > >     rowsB = length(B[,1]);
> > >     rowsA = length(A[,1]);
> > >     colsB = length(B[1,]);
> > >     colsA = length(A[1,]);
> > >     for (i in 1:rowsB){
> > >         for (j in 1:colsB){
> > >             for (k in 1:rowsA){
> > >                 for (l in 1:colsA){
> > >                     if(A[k,l]==B[i,j]){res<-c(res,k);}
> > >                 }
> > >             }
> > >         }
> > >     }
> > >     return(unique(sort(res)));
> > > }
> > >
> > >
> > > Best,
> > >
> > > Charles
> > >
> > >
> > > --
> > > Um ax?! :)
> > >
> > > --
> > > Charles Novaes de Santana, PhD
> > > http://www.imedea.uib-csic.es/~charles
> > >
> >
> >
> >
> > --
> > Um ax?! :)
> >
> > --
> > Charles Novaes de Santana, PhD
> > http://www.imedea.uib-csic.es/~charles
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.CA.us  Fri Oct 31 15:15:27 2014
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 31 Oct 2014 07:15:27 -0700
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
In-Reply-To: <CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
Message-ID: <26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>

Thank you for the reproducible example, but posting in HTML can corrupt your example code so please learn to set your email client mail format appropriately when posting to this list.

I think this [1] post, found with a quick Google search for "R match matrix", fits your situation perfectly.

match(data.frame(t(B)), data.frame(t(A)))

Note that concatenating vectors in loops is bad news... a basic optimization for your code would be to preallocate a logical result vector and fill in each element with a TRUE/FALSE in the outer loop, and use the which() function on that completed vector to identify the index numbers (if you really need that). For example:

lresult <- rep( NA, nrow(A) )
for ( ia in seq.int( nrow( A ) ) ) {
  lres <- FALSE
  ib <- 0
  while ( ib < nrow( B ) & !lres ) {
    ib <- ib + 1
    lres <- all( A[ ia, ] == B[ ib, ] )
  }
  lresult[ ia ] <- lres
}
result <- which( lresult )

[1] http://stackoverflow.com/questions/12697122/in-r-match-function-for-rows-or-columns-of-matrix
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

On October 31, 2014 6:20:38 AM PDT, Charles Novaes de Santana <charles.santana at gmail.com> wrote:
>My apologies, because I sent the message before finishing it. i am very
>sorry about this. Please find below my message (I use to write the
>messages
>from the end to the beginning... sorry :)).
>
>Dear all,
>
>I am trying to compare two matrices, in order to find in which rows of
>a
>matrix A I can find the same values as in matrix B. I am trying to do
>it
>for matrices with around 2500 elements, but please find below a toy
>example:
>
>A = matrix(1:10,nrow=5)
>B = A[-c(1,2,3),];
>
>So
>> A
>     [,1] [,2]
>[1,]    1    6
>[2,]    2    7
>[3,]    3    8
>[4,]    4    9
>[5,]    5   10
>
>and
>> B
>     [,1] [,2]
>[1,]    4    9
>[2,]    5   10
>
>I would like to compare A and B in order to find in which rows of A I
>can
>find the  rows of B. Something similar to %in% with one dimensional
>arrays.
>In the example above, the answer should be 4 and 5.
>
>I did a function to do it (see it below), it gives me the correct
>answer
>for this toy example, but the excess of for-loops makes it extremely
>slow
>for larger matrices. I was wondering if there is a better way to do
>this
>kind of comparison. Any idea? Sorry if it is a stupid question.
>
>matbinmata<-function(B,A){
>    res<-c();
>    rowsB = length(B[,1]);
>    rowsA = length(A[,1]);
>    colsB = length(B[1,]);
>    colsA = length(A[1,]);
>    for (i in 1:rowsB){
>        for (j in 1:colsB){
>            for (k in 1:rowsA){
>                for (l in 1:colsA){
>                    if(A[k,l]==B[i,j]){res<-c(res,k);}
>                }
>            }
>        }
>    }
>    return(unique(sort(res)));
>}
>
>
>Best,
>
>Charles
>
>On Fri, Oct 31, 2014 at 2:12 PM, Charles Novaes de Santana <
>charles.santana at gmail.com> wrote:
>
>> A = matrix(1:10,nrow=5)
>> B = A[-c(1,2,3),];
>>
>> So
>> > A
>>      [,1] [,2]
>> [1,]    1    6
>> [2,]    2    7
>> [3,]    3    8
>> [4,]    4    9
>> [5,]    5   10
>>
>> and
>> > B
>>      [,1] [,2]
>> [1,]    4    9
>> [2,]    5   10
>>
>> I would like to compare A and B in order to find in which rows of A I
>can
>> find the  rows of B. Something similar to %in% with one dimensional
>arrays.
>> In the example above, the answer should be 4 and 5.
>>
>> I did a function to do it (see it below), it gives me the correct
>answer
>> for this toy example, but the excess of for-loops makes it extremely
>slow
>> for larger matrices. I was wondering if there is a better way to do
>this
>> kind of comparison. Any idea? Sorry if it is a stupid question.
>>
>> matbinmata<-function(B,A){
>>     res<-c();
>>     rowsB = length(B[,1]);
>>     rowsA = length(A[,1]);
>>     colsB = length(B[1,]);
>>     colsA = length(A[1,]);
>>     for (i in 1:rowsB){
>>         for (j in 1:colsB){
>>             for (k in 1:rowsA){
>>                 for (l in 1:colsA){
>>                     if(A[k,l]==B[i,j]){res<-c(res,k);}
>>                 }
>>             }
>>         }
>>     }
>>     return(unique(sort(res)));
>> }
>>
>>
>> Best,
>>
>> Charles
>>
>>
>> --
>> Um ax?! :)
>>
>> --
>> Charles Novaes de Santana, PhD
>> http://www.imedea.uib-csic.es/~charles
>>
>
>
>
>-- 
>Um ax?! :)
>
>--
>Charles Novaes de Santana, PhD
>http://www.imedea.uib-csic.es/~charles
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From charles.santana at gmail.com  Fri Oct 31 15:29:53 2014
From: charles.santana at gmail.com (Charles Novaes de Santana)
Date: Fri, 31 Oct 2014 15:29:53 +0100
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
In-Reply-To: <26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
	<26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>
Message-ID: <CAH-FEnjBu7V=YCbbZ4EFxeQgwef_N+-9F_cMd-3woa4ou+Ai8g@mail.gmail.com>

Thank you, Jeff, for your message.

I did a search, but maybe my problem was that I didn't know the correct way
to search my problem (in other words: my vocabulary in R/English  is not
good). Because of this I choose to send a message to the list the most
detailed as possible, and with a first solution, that was not the optimum
one.

Thank you very much for taking your time to think about my problem and to
search for a good solution! I much appreciate it! But I think John'
suggestion does what I need and it is much simpler :)

Best,

Charles
P.S.: the HTML issue is probably because I am using a webmail-client and I
did a copy and paste from the first email I sent.

On Fri, Oct 31, 2014 at 3:15 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Thank you for the reproducible example, but posting in HTML can corrupt
> your example code so please learn to set your email client mail format
> appropriately when posting to this list.
>
> I think this [1] post, found with a quick Google search for "R match
> matrix", fits your situation perfectly.
>
> match(data.frame(t(B)), data.frame(t(A)))
>
> Note that concatenating vectors in loops is bad news... a basic
> optimization for your code would be to preallocate a logical result vector
> and fill in each element with a TRUE/FALSE in the outer loop, and use the
> which() function on that completed vector to identify the index numbers (if
> you really need that). For example:
>
> lresult <- rep( NA, nrow(A) )
> for ( ia in seq.int( nrow( A ) ) ) {
>   lres <- FALSE
>   ib <- 0
>   while ( ib < nrow( B ) & !lres ) {
>     ib <- ib + 1
>     lres <- all( A[ ia, ] == B[ ib, ] )
>   }
>   lresult[ ia ] <- lres
> }
> result <- which( lresult )
>
> [1]
> http://stackoverflow.com/questions/12697122/in-r-match-function-for-rows-or-columns-of-matrix
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 31, 2014 6:20:38 AM PDT, Charles Novaes de Santana <
> charles.santana at gmail.com> wrote:
> >My apologies, because I sent the message before finishing it. i am very
> >sorry about this. Please find below my message (I use to write the
> >messages
> >from the end to the beginning... sorry :)).
> >
> >Dear all,
> >
> >I am trying to compare two matrices, in order to find in which rows of
> >a
> >matrix A I can find the same values as in matrix B. I am trying to do
> >it
> >for matrices with around 2500 elements, but please find below a toy
> >example:
> >
> >A = matrix(1:10,nrow=5)
> >B = A[-c(1,2,3),];
> >
> >So
> >> A
> >     [,1] [,2]
> >[1,]    1    6
> >[2,]    2    7
> >[3,]    3    8
> >[4,]    4    9
> >[5,]    5   10
> >
> >and
> >> B
> >     [,1] [,2]
> >[1,]    4    9
> >[2,]    5   10
> >
> >I would like to compare A and B in order to find in which rows of A I
> >can
> >find the  rows of B. Something similar to %in% with one dimensional
> >arrays.
> >In the example above, the answer should be 4 and 5.
> >
> >I did a function to do it (see it below), it gives me the correct
> >answer
> >for this toy example, but the excess of for-loops makes it extremely
> >slow
> >for larger matrices. I was wondering if there is a better way to do
> >this
> >kind of comparison. Any idea? Sorry if it is a stupid question.
> >
> >matbinmata<-function(B,A){
> >    res<-c();
> >    rowsB = length(B[,1]);
> >    rowsA = length(A[,1]);
> >    colsB = length(B[1,]);
> >    colsA = length(A[1,]);
> >    for (i in 1:rowsB){
> >        for (j in 1:colsB){
> >            for (k in 1:rowsA){
> >                for (l in 1:colsA){
> >                    if(A[k,l]==B[i,j]){res<-c(res,k);}
> >                }
> >            }
> >        }
> >    }
> >    return(unique(sort(res)));
> >}
> >
> >
> >Best,
> >
> >Charles
> >
> >On Fri, Oct 31, 2014 at 2:12 PM, Charles Novaes de Santana <
> >charles.santana at gmail.com> wrote:
> >
> >> A = matrix(1:10,nrow=5)
> >> B = A[-c(1,2,3),];
> >>
> >> So
> >> > A
> >>      [,1] [,2]
> >> [1,]    1    6
> >> [2,]    2    7
> >> [3,]    3    8
> >> [4,]    4    9
> >> [5,]    5   10
> >>
> >> and
> >> > B
> >>      [,1] [,2]
> >> [1,]    4    9
> >> [2,]    5   10
> >>
> >> I would like to compare A and B in order to find in which rows of A I
> >can
> >> find the  rows of B. Something similar to %in% with one dimensional
> >arrays.
> >> In the example above, the answer should be 4 and 5.
> >>
> >> I did a function to do it (see it below), it gives me the correct
> >answer
> >> for this toy example, but the excess of for-loops makes it extremely
> >slow
> >> for larger matrices. I was wondering if there is a better way to do
> >this
> >> kind of comparison. Any idea? Sorry if it is a stupid question.
> >>
> >> matbinmata<-function(B,A){
> >>     res<-c();
> >>     rowsB = length(B[,1]);
> >>     rowsA = length(A[,1]);
> >>     colsB = length(B[1,]);
> >>     colsA = length(A[1,]);
> >>     for (i in 1:rowsB){
> >>         for (j in 1:colsB){
> >>             for (k in 1:rowsA){
> >>                 for (l in 1:colsA){
> >>                     if(A[k,l]==B[i,j]){res<-c(res,k);}
> >>                 }
> >>             }
> >>         }
> >>     }
> >>     return(unique(sort(res)));
> >> }
> >>
> >>
> >> Best,
> >>
> >> Charles
> >>
> >>
> >> --
> >> Um ax?! :)
> >>
> >> --
> >> Charles Novaes de Santana, PhD
> >> http://www.imedea.uib-csic.es/~charles
> >>
> >
> >
> >
> >--
> >Um ax?! :)
> >
> >--
> >Charles Novaes de Santana, PhD
> >http://www.imedea.uib-csic.es/~charles
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Um ax?! :)

--
Charles Novaes de Santana, PhD
http://www.imedea.uib-csic.es/~charles

	[[alternative HTML version deleted]]


From jfox at mcmaster.ca  Fri Oct 31 15:40:10 2014
From: jfox at mcmaster.ca (John Fox)
Date: Fri, 31 Oct 2014 10:40:10 -0400
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
In-Reply-To: <26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
	<26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>
Message-ID: <000f01cff518$92e14210$b8a3c630$@mcmaster.ca>

Dear Jeff,

For curiosity, I compared your solution with the one I posted earlier this morning (when I was working on a slower computer, accounting for the somewhat different timings for my solution):

------------ snip ----------

> A <- matrix(1:10000, 10000, 10)
> B <- A[1:1000, ]
> 
> system.time({
+    AA <- as.list(as.data.frame(t(A)))
+    BB <- as.list(as.data.frame(t(B)))
+    print(sum(AA %in% BB))
+  })
[1] 1000
   user  system elapsed 
   0.14    0.01    0.16 
> 
> 
> system.time({
+     lresult <- rep( NA, nrow(A) )
+     for ( ia in seq.int( nrow( A ) ) ) {
+         lres <- FALSE
+         ib <- 0
+         while ( ib < nrow( B ) & !lres ) {
+             ib <- ib + 1
+             lres <- all( A[ ia, ] == B[ ib, ] )
+         }
+         lresult[ ia ] <- lres
+     }
+     print(sum( lresult ))
+ })
[1] 1000
   user  system elapsed 
  45.76    0.01   45.77 
> 46/0.16
[1] 287.5

------------ snip ----------

So the solution using nested loops is more than 2 orders of magnitude slower for this problem. Of course, for a one-off problem, depending on its size, the difference may not matter.

Best,
 John

-----------------------------------------------
John Fox, Professor
McMaster University
Hamilton, Ontario, Canada
http://socserv.socsci.mcmaster.ca/jfox/



> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Jeff Newmiller
> Sent: Friday, October 31, 2014 10:15 AM
> To: Charles Novaes de Santana; r-help at r-project.org
> Subject: Re: [R] Comparing matrices in R - matrixB %in% matrixA
> 
> Thank you for the reproducible example, but posting in HTML can corrupt
> your example code so please learn to set your email client mail format
> appropriately when posting to this list.
> 
> I think this [1] post, found with a quick Google search for "R match
> matrix", fits your situation perfectly.
> 
> match(data.frame(t(B)), data.frame(t(A)))
> 
> Note that concatenating vectors in loops is bad news... a basic
> optimization for your code would be to preallocate a logical result
> vector and fill in each element with a TRUE/FALSE in the outer loop,
> and use the which() function on that completed vector to identify the
> index numbers (if you really need that). For example:
> 
> lresult <- rep( NA, nrow(A) )
> for ( ia in seq.int( nrow( A ) ) ) {
>   lres <- FALSE
>   ib <- 0
>   while ( ib < nrow( B ) & !lres ) {
>     ib <- ib + 1
>     lres <- all( A[ ia, ] == B[ ib, ] )
>   }
>   lresult[ ia ] <- lres
> }
> result <- which( lresult )
> 
> [1] http://stackoverflow.com/questions/12697122/in-r-match-function-
> for-rows-or-columns-of-matrix
> -----------------------------------------------------------------------
> ----
> Jeff Newmiller                        The     .....       .....  Go
> Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..
> Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.
> rocks...1k
> -----------------------------------------------------------------------
> ----
> Sent from my phone. Please excuse my brevity.
> 
> On October 31, 2014 6:20:38 AM PDT, Charles Novaes de Santana
> <charles.santana at gmail.com> wrote:
> >My apologies, because I sent the message before finishing it. i am
> very
> >sorry about this. Please find below my message (I use to write the
> >messages
> >from the end to the beginning... sorry :)).
> >
> >Dear all,
> >
> >I am trying to compare two matrices, in order to find in which rows of
> >a
> >matrix A I can find the same values as in matrix B. I am trying to do
> >it
> >for matrices with around 2500 elements, but please find below a toy
> >example:
> >
> >A = matrix(1:10,nrow=5)
> >B = A[-c(1,2,3),];
> >
> >So
> >> A
> >     [,1] [,2]
> >[1,]    1    6
> >[2,]    2    7
> >[3,]    3    8
> >[4,]    4    9
> >[5,]    5   10
> >
> >and
> >> B
> >     [,1] [,2]
> >[1,]    4    9
> >[2,]    5   10
> >
> >I would like to compare A and B in order to find in which rows of A I
> >can
> >find the  rows of B. Something similar to %in% with one dimensional
> >arrays.
> >In the example above, the answer should be 4 and 5.
> >
> >I did a function to do it (see it below), it gives me the correct
> >answer
> >for this toy example, but the excess of for-loops makes it extremely
> >slow
> >for larger matrices. I was wondering if there is a better way to do
> >this
> >kind of comparison. Any idea? Sorry if it is a stupid question.
> >
> >matbinmata<-function(B,A){
> >    res<-c();
> >    rowsB = length(B[,1]);
> >    rowsA = length(A[,1]);
> >    colsB = length(B[1,]);
> >    colsA = length(A[1,]);
> >    for (i in 1:rowsB){
> >        for (j in 1:colsB){
> >            for (k in 1:rowsA){
> >                for (l in 1:colsA){
> >                    if(A[k,l]==B[i,j]){res<-c(res,k);}
> >                }
> >            }
> >        }
> >    }
> >    return(unique(sort(res)));
> >}
> >
> >
> >Best,
> >
> >Charles
> >
> >On Fri, Oct 31, 2014 at 2:12 PM, Charles Novaes de Santana <
> >charles.santana at gmail.com> wrote:
> >
> >> A = matrix(1:10,nrow=5)
> >> B = A[-c(1,2,3),];
> >>
> >> So
> >> > A
> >>      [,1] [,2]
> >> [1,]    1    6
> >> [2,]    2    7
> >> [3,]    3    8
> >> [4,]    4    9
> >> [5,]    5   10
> >>
> >> and
> >> > B
> >>      [,1] [,2]
> >> [1,]    4    9
> >> [2,]    5   10
> >>
> >> I would like to compare A and B in order to find in which rows of A
> I
> >can
> >> find the  rows of B. Something similar to %in% with one dimensional
> >arrays.
> >> In the example above, the answer should be 4 and 5.
> >>
> >> I did a function to do it (see it below), it gives me the correct
> >answer
> >> for this toy example, but the excess of for-loops makes it extremely
> >slow
> >> for larger matrices. I was wondering if there is a better way to do
> >this
> >> kind of comparison. Any idea? Sorry if it is a stupid question.
> >>
> >> matbinmata<-function(B,A){
> >>     res<-c();
> >>     rowsB = length(B[,1]);
> >>     rowsA = length(A[,1]);
> >>     colsB = length(B[1,]);
> >>     colsA = length(A[1,]);
> >>     for (i in 1:rowsB){
> >>         for (j in 1:colsB){
> >>             for (k in 1:rowsA){
> >>                 for (l in 1:colsA){
> >>                     if(A[k,l]==B[i,j]){res<-c(res,k);}
> >>                 }
> >>             }
> >>         }
> >>     }
> >>     return(unique(sort(res)));
> >> }
> >>
> >>
> >> Best,
> >>
> >> Charles
> >>
> >>
> >> --
> >> Um ax?! :)
> >>
> >> --
> >> Charles Novaes de Santana, PhD
> >> http://www.imedea.uib-csic.es/~charles
> >>
> >
> >
> >
> >--
> >Um ax?! :)
> >
> >--
> >Charles Novaes de Santana, PhD
> >http://www.imedea.uib-csic.es/~charles
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gcr at wisdomandwonder.com  Fri Oct 31 16:09:20 2014
From: gcr at wisdomandwonder.com (Grant Rettke)
Date: Fri, 31 Oct 2014 10:09:20 -0500
Subject: [R] RForcecom VERY SLOW on large data sets
In-Reply-To: <CANS_STh3+zreEX7CC3dpN7vwo0_R9UHrxEh4h2Am_Q+UHgByLA@mail.gmail.com>
References: <CANS_STh3+zreEX7CC3dpN7vwo0_R9UHrxEh4h2Am_Q+UHgByLA@mail.gmail.com>
Message-ID: <CAAjq1mcipcy2oGwE8rmDqdbiLsLpLB0CZX_ouEXk7iWiESHkog@mail.gmail.com>

On Thu, Oct 30, 2014 at 8:10 AM, Ryszard Czermi?ski
<ryszard at czerminski.net> wrote:
> For comparison exporting the same table as csv using "report export" in
> SalesForce
> takes about 1 minute.
>
> Any ideas why? and how to make it faster?

One idea is to export to CSV and load it yourself.


From prgosek at gmail.com  Fri Oct 31 16:15:57 2014
From: prgosek at gmail.com (=?UTF-8?Q?Michal_Kvasni=C4=8Dka?=)
Date: Fri, 31 Oct 2014 16:15:57 +0100
Subject: [R] Knitr: how to find out from within a .Rmd file the output
	type?
In-Reply-To: <6CB007B8-7F74-4DAC-B4B8-D3A959C58DA1@dcn.davis.CA.us>
References: <CALs_GZUbQ3xXUoX6GLBsD08EmK90rUOGG_V_syrRbXZU5akwFw@mail.gmail.com>
	<6CB007B8-7F74-4DAC-B4B8-D3A959C58DA1@dcn.davis.CA.us>
Message-ID: <CALs_GZVCx-q3BWuKiv+7ZBym5VdK2unsgFb1ZeS2eh7GAykK6Q@mail.gmail.com>

Yes, markdown is not LaTex. However, RStudio run pandoc that can convert
markdown to HTML, LaTeX, Word, and many other markup (or almost markup)
languages. The conversion to the first three mentioned works automatically
in RStudio.

But you are right in one thing: perhaps it is not a matter of knitr but of
the machinery (whatever it is) behind that runs knitr and then pandoc. Any
idea how it works?

Best wishes,
Michal


2014-10-31 14:21 GMT+01:00 Jeff Newmiller <jdnewmil at dcn.davis.ca.us>:

> AFAIK markdown is syntactically incompatible with LaTeX, except for math
> mode expressions. That is why we have separate extensions Rmd and Rnw for
> the two types of files. I don't know where one could successfully make use
> of the variable you are asking about.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 31, 2014 4:56:26 AM PDT, "Michal Kvasni?ka" <prgosek at gmail.com>
> wrote:
> >Hi.
> >
> >Is there a way how to find out from within a .Rmd file what output
> >format
> >is generated?
> >
> >The reason is this: I write a paper in R markdown in RStudio. Sometimes
> >I
> >generate .html, sometimes .pdf. My paper presents a table of regression
> >models using stargazer function. I've got the following code in my
> >paper:
> >
> >```{r, echo=FALSE, message=FALSE, results='asis'}
> >model2 <- lm(...)
> >model3 <- lm(...)
> >model5 <- lm(...)
> >stargazer(model2, model3, model5,
> >          ...,
> >          type="html")
> >```
> >
> >Whenever I change the output format from .html do .pdf, I have to
> >change
> >the line type="html" to type="latex" manually. (The same holds true for
> >many other functions, e.g. xtable.)
> >
> >It would be nice to replace the direct declaration with
> >
> >      type=some_knitr_variable
> >
> >What is the true name of the some_knitr_variable? I was not able to
> >find it
> >anywhere.
> >
> >Many thanks for your help.
> >
> >Best wishes,
> >Michal
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jeff.laake at noaa.gov  Fri Oct 31 16:15:56 2014
From: jeff.laake at noaa.gov (Jeff Laake - NOAA Federal)
Date: Fri, 31 Oct 2014 08:15:56 -0700
Subject: [R] Knitr: how to find out from within a .Rmd file the output
	type?
In-Reply-To: <6CB007B8-7F74-4DAC-B4B8-D3A959C58DA1@dcn.davis.CA.us>
References: <CALs_GZUbQ3xXUoX6GLBsD08EmK90rUOGG_V_syrRbXZU5akwFw@mail.gmail.com>
	<6CB007B8-7F74-4DAC-B4B8-D3A959C58DA1@dcn.davis.CA.us>
Message-ID: <CA+_rFBJV4LebifQSMV8Q3CJNnp+jdixt8nXrCd=1RzoZG5XL-w@mail.gmail.com>

This has worked for me to choose the type of code to use to create tables
whether it is pdf or hml/word

doc.type <-
strsplit(rmarkdown:::default_output_format("20141014_Regex_Rmarkdown.Rmd")$name,"_")[[1]][1]

where you would use your .rmd filename in place of
20141014_Regex_Rmarkdown.Rmd  I havenb't worked out how to get the
file.nname within the document, so I hardcode it.

--jeff



On Fri, Oct 31, 2014 at 6:21 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> AFAIK markdown is syntactically incompatible with LaTeX, except for math
> mode expressions. That is why we have separate extensions Rmd and Rnw for
> the two types of files. I don't know where one could successfully make use
> of the variable you are asking about.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
> Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
> Sent from my phone. Please excuse my brevity.
>
> On October 31, 2014 4:56:26 AM PDT, "Michal Kvasni?ka" <prgosek at gmail.com>
> wrote:
> >Hi.
> >
> >Is there a way how to find out from within a .Rmd file what output
> >format
> >is generated?
> >
> >The reason is this: I write a paper in R markdown in RStudio. Sometimes
> >I
> >generate .html, sometimes .pdf. My paper presents a table of regression
> >models using stargazer function. I've got the following code in my
> >paper:
> >
> >```{r, echo=FALSE, message=FALSE, results='asis'}
> >model2 <- lm(...)
> >model3 <- lm(...)
> >model5 <- lm(...)
> >stargazer(model2, model3, model5,
> >          ...,
> >          type="html")
> >```
> >
> >Whenever I change the output format from .html do .pdf, I have to
> >change
> >the line type="html" to type="latex" manually. (The same holds true for
> >many other functions, e.g. xtable.)
> >
> >It would be nice to replace the direct declaration with
> >
> >      type=some_knitr_variable
> >
> >What is the true name of the some_knitr_variable? I was not able to
> >find it
> >anywhere.
> >
> >Many thanks for your help.
> >
> >Best wishes,
> >Michal
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Fri Oct 31 16:19:15 2014
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 31 Oct 2014 10:19:15 -0500
Subject: [R] Knitr: how to find out from within a .Rmd file the output
	type?
In-Reply-To: <CALs_GZUbQ3xXUoX6GLBsD08EmK90rUOGG_V_syrRbXZU5akwFw@mail.gmail.com>
References: <CALs_GZUbQ3xXUoX6GLBsD08EmK90rUOGG_V_syrRbXZU5akwFw@mail.gmail.com>
Message-ID: <CABdHhvEictum8s7iCmY0eAmYL=POxtVP8CrD3A5x1x-mi44F0Q@mail.gmail.com>

Try knitr::opts_knit$get('rmarkdown.pandoc.to')

Hadley

On Fri, Oct 31, 2014 at 6:56 AM, Michal Kvasni?ka <prgosek at gmail.com> wrote:
> Hi.
>
> Is there a way how to find out from within a .Rmd file what output format
> is generated?
>
> The reason is this: I write a paper in R markdown in RStudio. Sometimes I
> generate .html, sometimes .pdf. My paper presents a table of regression
> models using stargazer function. I've got the following code in my paper:
>
> ```{r, echo=FALSE, message=FALSE, results='asis'}
> model2 <- lm(...)
> model3 <- lm(...)
> model5 <- lm(...)
> stargazer(model2, model3, model5,
>           ...,
>           type="html")
> ```
>
> Whenever I change the output format from .html do .pdf, I have to change
> the line type="html" to type="latex" manually. (The same holds true for
> many other functions, e.g. xtable.)
>
> It would be nice to replace the direct declaration with
>
>       type=some_knitr_variable
>
> What is the true name of the some_knitr_variable? I was not able to find it
> anywhere.
>
> Many thanks for your help.
>
> Best wishes,
> Michal
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
http://had.co.nz/


From eliza_botto at hotmail.com  Fri Oct 31 16:22:24 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 31 Oct 2014 15:22:24 +0000
Subject: [R] lat/log to meter
Message-ID: <BLU170-W4428DBED549C1965B2A255899A0@phx.gbl>

Dear UseRs,Is there a way in R to convert latitude and longitude in degree.minute.second to meter? (e.g. 45'55'')Thankyou very much in Advance,Eliza 		 	   		  
	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Oct 31 16:27:50 2014
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 31 Oct 2014 08:27:50 -0700 (PDT)
Subject: [R] Comparing matrices in R - matrixB %in% matrixA
In-Reply-To: <000f01cff518$92e14210$b8a3c630$@mcmaster.ca>
References: <CAH-FEnjfDBZF2-1HWR0_ULd71Kfrd3z+ES13ZdXaj4wGD1OVOw@mail.gmail.com>
	<CAH-FEnh+1DDFOsWNq5GF7p-iLpBOOUEaKst+NZGm1Pc-f+arvA@mail.gmail.com>
	<26C7B3B6-6596-418C-9CC4-C65558E54F53@dcn.davis.CA.us>
	<000f01cff518$92e14210$b8a3c630$@mcmaster.ca>
Message-ID: <alpine.BSF.2.00.1410310822530.42077@pedal.dcn.davis.ca.us>

Since both of you seem to have misinterpreted my response, consider the 
following for clarification:

> A <- matrix(1:1000, 1000, 10)
> B <- A[1:100, ]
> # my recommended solution
> t1 <- system.time({match(as.data.frame(t(B)), as.data.frame(t(A)))})
> # similar to John's recommended solution
> t2 <- system.time({
+   AA <- as.list(as.data.frame(t(A)))
+   BB <- as.list(as.data.frame(t(B)))
+   which( AA %in% BB )
+ })
> t3 <- system.time({
+   lresult <- rep( NA, nrow(A) )
+   for ( ia in seq.int( nrow( A ) ) ) {
+     lres <- FALSE
+     ib <- 0
+     while ( ib < nrow( B ) & !lres ) {
+       ib <- ib + 1
+       lres <- all( A[ ia, ] == B[ ib, ] )
+     }
+     lresult[ ia ] <- lres
+   }
+   which( lresult )
+ })
> t4 <- system.time({
+   res<-c()
+   rowsB = length(B[,1])
+   rowsA = length(A[,1])
+   colsB = length(B[1,])
+   colsA = length(A[1,])
+   for (i in 1:rowsB){
+     for (j in 1:colsB){
+       for (k in 1:rowsA){
+         for (l in 1:colsA){
+           if(A[k,l]==B[i,j]){res<-c(res,k)}
+         }
+       }
+     }
+   }
+   unique(sort(res))
+ })
> t1
    user  system elapsed
   0.022   0.000   0.020
> t2
    user  system elapsed
    0.02    0.00    0.02
> t3
    user  system elapsed
   0.748   0.000   0.746
> t4
    user  system elapsed
  16.612   0.016  16.636
> # data.frames are lists, but applying as.list seems to speed up the 
> # match for some reason
> t2[1]/t1[1]
user.self
0.9090909
> # intended comparison for learning purposes
> t4[1]/t3[1]
user.self
  22.20856

I recognize that the reference implementation does not need to be 
optimized, but the changes I suggested to it illustrate an incremental 
improvement toward "thinking in R" rather than the optimal solution.

On Fri, 31 Oct 2014, John Fox wrote:

> Dear Jeff,
>
> For curiosity, I compared your solution with the one I posted earlier this morning (when I was working on a slower computer, accounting for the somewhat different timings for my solution):
>
> ------------ snip ----------
>
>> A <- matrix(1:10000, 10000, 10)
>> B <- A[1:1000, ]
>>
>> system.time({
> +    AA <- as.list(as.data.frame(t(A)))
> +    BB <- as.list(as.data.frame(t(B)))
> +    print(sum(AA %in% BB))
> +  })
> [1] 1000
>   user  system elapsed
>   0.14    0.01    0.16
>>
>>
>> system.time({
> +     lresult <- rep( NA, nrow(A) )
> +     for ( ia in seq.int( nrow( A ) ) ) {
> +         lres <- FALSE
> +         ib <- 0
> +         while ( ib < nrow( B ) & !lres ) {
> +             ib <- ib + 1
> +             lres <- all( A[ ia, ] == B[ ib, ] )
> +         }
> +         lresult[ ia ] <- lres
> +     }
> +     print(sum( lresult ))
> + })
> [1] 1000
>   user  system elapsed
>  45.76    0.01   45.77
>> 46/0.16
> [1] 287.5
>
> ------------ snip ----------
>
> So the solution using nested loops is more than 2 orders of magnitude slower for this problem. Of course, for a one-off problem, depending on its size, the difference may not matter.
>
> Best,
> John
>
> -----------------------------------------------
> John Fox, Professor
> McMaster University
> Hamilton, Ontario, Canada
> http://socserv.socsci.mcmaster.ca/jfox/
>
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Jeff Newmiller
>> Sent: Friday, October 31, 2014 10:15 AM
>> To: Charles Novaes de Santana; r-help at r-project.org
>> Subject: Re: [R] Comparing matrices in R - matrixB %in% matrixA
>>
>> Thank you for the reproducible example, but posting in HTML can corrupt
>> your example code so please learn to set your email client mail format
>> appropriately when posting to this list.
>>
>> I think this [1] post, found with a quick Google search for "R match
>> matrix", fits your situation perfectly.
>>
>> match(data.frame(t(B)), data.frame(t(A)))
>>
>> Note that concatenating vectors in loops is bad news... a basic
>> optimization for your code would be to preallocate a logical result
>> vector and fill in each element with a TRUE/FALSE in the outer loop,
>> and use the which() function on that completed vector to identify the
>> index numbers (if you really need that). For example:
>>
>> lresult <- rep( NA, nrow(A) )
>> for ( ia in seq.int( nrow( A ) ) ) {
>>   lres <- FALSE
>>   ib <- 0
>>   while ( ib < nrow( B ) & !lres ) {
>>     ib <- ib + 1
>>     lres <- all( A[ ia, ] == B[ ib, ] )
>>   }
>>   lresult[ ia ] <- lres
>> }
>> result <- which( lresult )
>>
>> [1] http://stackoverflow.com/questions/12697122/in-r-match-function-
>> for-rows-or-columns-of-matrix
>> -----------------------------------------------------------------------
>> ----
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#..
>> Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> -----------------------------------------------------------------------
>> ----
>> Sent from my phone. Please excuse my brevity.
>>
>> On October 31, 2014 6:20:38 AM PDT, Charles Novaes de Santana
>> <charles.santana at gmail.com> wrote:
>>> My apologies, because I sent the message before finishing it. i am
>> very
>>> sorry about this. Please find below my message (I use to write the
>>> messages
>>> from the end to the beginning... sorry :)).
>>>
>>> Dear all,
>>>
>>> I am trying to compare two matrices, in order to find in which rows of
>>> a
>>> matrix A I can find the same values as in matrix B. I am trying to do
>>> it
>>> for matrices with around 2500 elements, but please find below a toy
>>> example:
>>>
>>> A = matrix(1:10,nrow=5)
>>> B = A[-c(1,2,3),];
>>>
>>> So
>>>> A
>>>     [,1] [,2]
>>> [1,]    1    6
>>> [2,]    2    7
>>> [3,]    3    8
>>> [4,]    4    9
>>> [5,]    5   10
>>>
>>> and
>>>> B
>>>     [,1] [,2]
>>> [1,]    4    9
>>> [2,]    5   10
>>>
>>> I would like to compare A and B in order to find in which rows of A I
>>> can
>>> find the  rows of B. Something similar to %in% with one dimensional
>>> arrays.
>>> In the example above, the answer should be 4 and 5.
>>>
>>> I did a function to do it (see it below), it gives me the correct
>>> answer
>>> for this toy example, but the excess of for-loops makes it extremely
>>> slow
>>> for larger matrices. I was wondering if there is a better way to do
>>> this
>>> kind of comparison. Any idea? Sorry if it is a stupid question.
>>>
>>> matbinmata<-function(B,A){
>>>    res<-c();
>>>    rowsB = length(B[,1]);
>>>    rowsA = length(A[,1]);
>>>    colsB = length(B[1,]);
>>>    colsA = length(A[1,]);
>>>    for (i in 1:rowsB){
>>>        for (j in 1:colsB){
>>>            for (k in 1:rowsA){
>>>                for (l in 1:colsA){
>>>                    if(A[k,l]==B[i,j]){res<-c(res,k);}
>>>                }
>>>            }
>>>        }
>>>    }
>>>    return(unique(sort(res)));
>>> }
>>>
>>>
>>> Best,
>>>
>>> Charles
>>>
>>> On Fri, Oct 31, 2014 at 2:12 PM, Charles Novaes de Santana <
>>> charles.santana at gmail.com> wrote:
>>>
>>>> A = matrix(1:10,nrow=5)
>>>> B = A[-c(1,2,3),];
>>>>
>>>> So
>>>>> A
>>>>      [,1] [,2]
>>>> [1,]    1    6
>>>> [2,]    2    7
>>>> [3,]    3    8
>>>> [4,]    4    9
>>>> [5,]    5   10
>>>>
>>>> and
>>>>> B
>>>>      [,1] [,2]
>>>> [1,]    4    9
>>>> [2,]    5   10
>>>>
>>>> I would like to compare A and B in order to find in which rows of A
>> I
>>> can
>>>> find the  rows of B. Something similar to %in% with one dimensional
>>> arrays.
>>>> In the example above, the answer should be 4 and 5.
>>>>
>>>> I did a function to do it (see it below), it gives me the correct
>>> answer
>>>> for this toy example, but the excess of for-loops makes it extremely
>>> slow
>>>> for larger matrices. I was wondering if there is a better way to do
>>> this
>>>> kind of comparison. Any idea? Sorry if it is a stupid question.
>>>>
>>>> matbinmata<-function(B,A){
>>>>     res<-c();
>>>>     rowsB = length(B[,1]);
>>>>     rowsA = length(A[,1]);
>>>>     colsB = length(B[1,]);
>>>>     colsA = length(A[1,]);
>>>>     for (i in 1:rowsB){
>>>>         for (j in 1:colsB){
>>>>             for (k in 1:rowsA){
>>>>                 for (l in 1:colsA){
>>>>                     if(A[k,l]==B[i,j]){res<-c(res,k);}
>>>>                 }
>>>>             }
>>>>         }
>>>>     }
>>>>     return(unique(sort(res)));
>>>> }
>>>>
>>>>
>>>> Best,
>>>>
>>>> Charles
>>>>
>>>>
>>>> --
>>>> Um ax?! :)
>>>>
>>>> --
>>>> Charles Novaes de Santana, PhD
>>>> http://www.imedea.uib-csic.es/~charles
>>>>
>>>
>>>
>>>
>>> --
>>> Um ax?! :)
>>>
>>> --
>>> Charles Novaes de Santana, PhD
>>> http://www.imedea.uib-csic.es/~charles
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From clint at ecy.wa.gov  Fri Oct 31 16:29:15 2014
From: clint at ecy.wa.gov (Clint Bowman)
Date: Fri, 31 Oct 2014 08:29:15 -0700 (PDT)
Subject: [R] lat/log to meter
In-Reply-To: <BLU170-W4428DBED549C1965B2A255899A0@phx.gbl>
References: <BLU170-W4428DBED549C1965B2A255899A0@phx.gbl>
Message-ID: <alpine.LRH.2.11.1410310828340.9850@aeolus.ecy.wa.gov>

Eliza,

Would transforming to UTM coordinates work?

Clint

Clint Bowman			INTERNET:	clint at ecy.wa.gov
Air Quality Modeler		INTERNET:	clint at math.utah.edu
Department of Ecology		VOICE:		(360) 407-6815
PO Box 47600			FAX:		(360) 407-7534
Olympia, WA 98504-7600

         USPS:           PO Box 47600, Olympia, WA 98504-7600
         Parcels:        300 Desmond Drive, Lacey, WA 98503-1274

On Fri, 31 Oct 2014, eliza botto wrote:

> Dear UseRs,Is there a way in R to convert latitude and longitude in degree.minute.second to meter? (e.g. 45'55'')Thankyou very much in Advance,Eliza
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petretta at unina.it  Fri Oct 31 16:31:00 2014
From: petretta at unina.it (Mario Petretta)
Date: Fri, 31 Oct 2014 16:31:00 +0100
Subject: [R] 3D scatterplot and agreement among three methods in the same
	subject
Message-ID: <001901cff51f$ace1e370$06a5aa50$@unina.it>

Dear all,

I use R 3.1.1 for Windows.

I would like to use three-dimensional scatterplots to evaluate the agreement
among 3 laboratory methods in a set of 30 subjects (all subjects was
evaluated with each of the three methods), using a line of best fit (slope
and intercept) and the line of identity.

Moreover, I would like to evaluate the SD of the residual errors (distance
from line of best fit) to assess the disagreement between any method and the
average value among all 3  methods. For this purpose, no single method was
used as a standard to which the other 2 methods would be compared. 

The file is:

Id 	method1	method2	meth3		
1	5		6		6	    	
2	4		7		6
3	8		9		12
..	...		...		...
29	8		7		10
30	12		14		13

I know that the package "scatterplot3d" is useful for plotting the data, and
also I read the previous post
http://r.789695.n4.nabble.com/Fit-a-3-Dimensional-Line-to-Data-Points-td8635
96.html . However the R square and SD of the residual errors are not
reported in this example.

 
Any suggestion is welcome.

-------------------------------------------------------
Mario Petretta
Associate Professor of Internal Medicine
Department of Translational Medical Sciences
Naples University Federico II Italy


From macqueen1 at llnl.gov  Fri Oct 31 17:14:30 2014
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Fri, 31 Oct 2014 16:14:30 +0000
Subject: [R] lat/log to meter
In-Reply-To: <BLU170-W4428DBED549C1965B2A255899A0@phx.gbl>
References: <BLU170-W4428DBED549C1965B2A255899A0@phx.gbl>
Message-ID: <D079030C.110EBC%macqueen1@llnl.gov>

see spTransform() in the sp package
(and ask on R-Sig-Geo)

There is also a function in one of the spatial-related packages to convert
lat/long in dms format to decimal, but I don?t remember its name.

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 10/31/14, 8:22 AM, "eliza botto" <eliza_botto at hotmail.com> wrote:

>Dear UseRs,Is there a way in R to convert latitude and longitude in
>degree.minute.second to meter? (e.g. 45'55'')Thankyou very much in
>Advance,Eliza 		 	   		
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From zadig_1 at excite.com  Fri Oct 31 17:44:00 2014
From: zadig_1 at excite.com (ce)
Date: Fri, 31 Oct 2014 12:44:00 -0400
Subject: [R] lappy and xts get all indexes from a list ?
Message-ID: <20141031124400.26433@web006.roc2.bluetie.com>

Dear all,

I have a list , and I want to get all indexes ( dates ) of xts objects  in one list:

foo<-list(A = xts(seq(2),seq(Sys.Date(),Sys.Date()+2,length.out=2)), B = xts(seq(1),seq(Sys.Date()-2,Sys.Date()-1,length.out=1)) )

> foo
$A
           [,1]
2014-10-31    1
2014-11-02    2

$B
           [,1]
2014-10-29    1

lapply(foo, function(x) index(x))      gives A and B values separately . I want to get one list like :

"2014-10-31" "2014-11-02" "2014-10-29"

Thanks a lot.


From josh.m.ulrich at gmail.com  Fri Oct 31 18:25:37 2014
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 31 Oct 2014 12:25:37 -0500
Subject: [R] lappy and xts get all indexes from a list ?
In-Reply-To: <20141031124400.26433@web006.roc2.bluetie.com>
References: <20141031124400.26433@web006.roc2.bluetie.com>
Message-ID: <CAPPM_gTz8mHUw8o0wgJZ_OKh3sTYrADPqVcNm77qOFLxZQP+1A@mail.gmail.com>

I do this a few times in the blotter package.  Try:
Dates <- unique(do.call(c,c(lapply(foo, index), use.names=FALSE,
recursive=FALSE)))


On Fri, Oct 31, 2014 at 11:44 AM, ce <zadig_1 at excite.com> wrote:
> Dear all,
>
> I have a list , and I want to get all indexes ( dates ) of xts objects  in one list:
>
> foo<-list(A = xts(seq(2),seq(Sys.Date(),Sys.Date()+2,length.out=2)), B = xts(seq(1),seq(Sys.Date()-2,Sys.Date()-1,length.out=1)) )
>
>> foo
> $A
>            [,1]
> 2014-10-31    1
> 2014-11-02    2
>
> $B
>            [,1]
> 2014-10-29    1
>
> lapply(foo, function(x) index(x))      gives A and B values separately . I want to get one list like :
>
> "2014-10-31" "2014-11-02" "2014-10-29"
>
> Thanks a lot.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From eliza_botto at hotmail.com  Fri Oct 31 18:32:36 2014
From: eliza_botto at hotmail.com (eliza botto)
Date: Fri, 31 Oct 2014 17:32:36 +0000
Subject: [R] lat/log to meter
In-Reply-To: <D079030C.110EBC%macqueen1@llnl.gov>
References: <BLU170-W4428DBED549C1965B2A255899A0@phx.gbl>,
	<D079030C.110EBC%macqueen1@llnl.gov>
Message-ID: <BLU170-W109B759114BBCD7B627CF91899A0@phx.gbl>

Thankyou MacQueen and clint. I figured out. :)cheers,
Eliza

> From: macqueen1 at llnl.gov
> To: eliza_botto at hotmail.com; r-help at r-project.org
> Subject: Re: [R] lat/log to meter
> Date: Fri, 31 Oct 2014 16:14:30 +0000
> 
> see spTransform() in the sp package
> (and ask on R-Sig-Geo)
> 
> There is also a function in one of the spatial-related packages to convert
> lat/long in dms format to decimal, but I don?t remember its name.
> 
> -- 
> Don MacQueen
> 
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> 
> 
> 
> 
> 
> On 10/31/14, 8:22 AM, "eliza botto" <eliza_botto at hotmail.com> wrote:
> 
> >Dear UseRs,Is there a way in R to convert latitude and longitude in
> >degree.minute.second to meter? (e.g. 45'55'')Thankyou very much in
> >Advance,Eliza 		 	   		
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
 		 	   		  
	[[alternative HTML version deleted]]


From dodie at statcourse.com  Fri Oct 31 18:22:17 2014
From: dodie at statcourse.com (dodie)
Date: Fri, 31 Oct 2014 10:22:17 -0700 (PDT)
Subject: [R] Sorting within a dataframe Thank you
Message-ID: <20141031102539.7a8c353efd3e02796b49014cf9536f50.a193f3c4ed.wbe@email01.secureserver.net>

Thank you. 


-------- Original Message -------- 
Subject: Re: Sorting within a dataframe 
From: "jfzeac [via R]" &lt; ml-node+s789695n4699000h31 at n4.nabble.com &gt; 
Date: Thu, October 30, 2014 8:57 am 
To: dodie &lt; dodie at statcourse.com &gt; 

 Hi, a = data[order(data$x),]      If you reply to this email, your message will be added to the discussion below:  http://r.789695.n4.nabble.com/Sorting-within-a-dataframe-tp4698992p4699000.html    To unsubscribe from Sorting within a dataframe, click here .  NAML  






--
View this message in context: http://r.789695.n4.nabble.com/RE-Sorting-within-a-dataframe-Thank-you-tp4699065.html
Sent from the R help mailing list archive at Nabble.com.
	[[alternative HTML version deleted]]


From upananda.pani at gmail.com  Fri Oct 31 19:24:32 2014
From: upananda.pani at gmail.com (Upananda Pani)
Date: Fri, 31 Oct 2014 23:54:32 +0530
Subject: [R] converting individual data series to natural log (continuously
 compounded return)
Message-ID: <CAEezrQSFsGLQjVdiKjhLGO75BaV83xRhT5vAxYJ0qavxBSh=9g@mail.gmail.com>

Hi All,

I want to convert my price data into  natural log (continuously compounded
return)  by using Performance Analytics Package, I am getting the following
error.

 rfut = Return.calculate(fut)
Error in checkData(prices, method = "xts") :


Please help me.

With sincere regards,
Upananda

-- 


You may delay, but time will not.


Research Scholar
alternative mail id: upani at iitkgp.ac.in
Department of HSS, IIT KGP
KGP

From alemu.tadesse at gmail.com  Fri Oct 31 20:12:49 2014
From: alemu.tadesse at gmail.com (Alemu Tadesse)
Date: Fri, 31 Oct 2014 13:12:49 -0600
Subject: [R] grided files
Message-ID: <CACGkHRMHPZ2e6YQEE8YNBhDsjjMno4W2ASAsQP5FiwqopQa53g@mail.gmail.com>

Dear All,

I have a file the sample of which is attached. I was trying to read the
data and put it in a data frame. For example in this file, I have 1998 snow
depth data and each block of data belongs to one month.    Each data point
belongs to a given latitude and longitude (which is in another file). If I
can read this data and put it in some kind of table where I can provided
the index of the latitude and longitude and get the the data that would be
awesome, but it is taking time. I am wondering if have read such a file.

Best,

Alemu
-------------- next part --------------
	1998		8				
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
	1998		9				
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
	1998		10				
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0
0	0	0	0	0	0	0	0

From daniel319 at gmail.com  Fri Oct 31 21:06:26 2014
From: daniel319 at gmail.com (daniel)
Date: Fri, 31 Oct 2014 17:06:26 -0300
Subject: [R] converting individual data series to natural log
 (continuously compounded return)
In-Reply-To: <CAEezrQSFsGLQjVdiKjhLGO75BaV83xRhT5vAxYJ0qavxBSh=9g@mail.gmail.com>
References: <CAEezrQSFsGLQjVdiKjhLGO75BaV83xRhT5vAxYJ0qavxBSh=9g@mail.gmail.com>
Message-ID: <CAPfrkh=Rer7Ekr9rJ-uX=bt+SOC3+LVAUGm0etaxWU3Dd4X6cQ@mail.gmail.com>

Upananda,

I don't know your fut data, next time would help a simple dput(fut). Taking
into account the error message check the following:

library(PerformanceAnalytics)
df <- data.frame( sample(10)/100+100, seq(as.Date("2014-10-22"),
as.Date("2014-10-31"), by="day"))
str(df)
Return.calculate(df, "log")
#Error en checkData(prices, method = "xts") :
#  The data cannot be converted into a time series.  If you are trying to
pass in names from a data object with one column, you should use the form
'data[rows, columns, drop = FALSE]'.  Rownames should have standard date
formats, such as '1985-03-15'.
df <- data.frame( sample(10)/100+100, row.names=seq(as.Date("2014-10-22"),
as.Date("2014-10-31"), by="day"))
str(df)
Return.calculate(df, "log")
df <- xts( sample(10)/100+100, order.by=seq(as.Date("2014-10-22"),
as.Date("2014-10-31"), by="day"))
str(df)
Return.calculate(df, "log")

If you are going to use the PerformanceAnalytics package I highly recommend
you to checkl the xts package.

Daniel Merino



2014-10-31 15:24 GMT-03:00 Upananda Pani <upananda.pani at gmail.com>:

> Hi All,
>
> I want to convert my price data into  natural log (continuously compounded
> return)  by using Performance Analytics Package, I am getting the following
> error.
>
>  rfut = Return.calculate(fut)
> Error in checkData(prices, method = "xts") :
>
>
> Please help me.
>
> With sincere regards,
> Upananda
>
> --
>
>
> You may delay, but time will not.
>
>
> Research Scholar
> alternative mail id: upani at iitkgp.ac.in
> Department of HSS, IIT KGP
> KGP
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Daniel

	[[alternative HTML version deleted]]


From jholtman at gmail.com  Fri Oct 31 22:33:23 2014
From: jholtman at gmail.com (jim holtman)
Date: Fri, 31 Oct 2014 17:33:23 -0400
Subject: [R] grided files
In-Reply-To: <CACGkHRMHPZ2e6YQEE8YNBhDsjjMno4W2ASAsQP5FiwqopQa53g@mail.gmail.com>
References: <CACGkHRMHPZ2e6YQEE8YNBhDsjjMno4W2ASAsQP5FiwqopQa53g@mail.gmail.com>
Message-ID: <CAAxdm-5Cc0udUncCVfH_BfkYTb+4Rq-ELnMTrGezq-nXcduhbg@mail.gmail.com>

Here is an example of how you might do it:


> # read in all the data so you can break it apart.
> # it looks like there is head and then 17 lines of data
> data_in <-
readLines("C:\\Users\\jh52822\\Downloads\\analysis_mly_avg_1998.txt")
> indx <- 1L  # start at the first line
> all_data <- NULL
> while (indx < length(data_in)){
+     header <- data_in[indx]
+     # replace tabs in header with spaces
+     header <- gsub("\t+", " ", header)
+     # create a dataframe from the next 17 lines
+     new_data <- read.table(text = data_in[(indx + 1L):(indx + 17L)])
+     new_data$header <- header  # add to the file
+     all_data <- rbind(all_data, new_data)
+     indx <- indx + 18L
+ }
>
>
> str(all_data)
'data.frame':   51 obs. of  9 variables:
 $ V1    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V2    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V3    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V4    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V5    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V6    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V7    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ V8    : int  0 0 0 0 0 0 0 0 0 0 ...
 $ header: chr  " 1998 8 " " 1998 8 " " 1998 8 " " 1998 8 " ...
> all_data
   V1 V2 V3 V4 V5 V6 V7 V8    header
1   0  0  0  0  0  0  0  0   1998 8
2   0  0  0  0  0  0  0  0   1998 8
3   0  0  0  0  0  0  0  0   1998 8
4   0  0  0  0  0  0  0  0   1998 8
5   0  0  0  0  0  0  0  0   1998 8
6   0  0  0  0  0  0  0  0   1998 8
7   0  0  0  0  0  0  0  0   1998 8
8   0  0  0  0  0  0  0  0   1998 8
9   0  0  0  0  0  0  0  0   1998 8
10  0  0  0  0  0  0  0  0   1998 8
11  0  0  0  0  0  0  0  0   1998 8
12  0  0  0  0  0  0  0  0   1998 8
13  0  0  0  0  0  0  0  0   1998 8
14  0  0  0  0  0  0  0  0   1998 8
15  0  0  0  0  0  0  0  0   1998 8
16  0  0  0  0  0  0  0  0   1998 8
17  0  0  0  0  0  0  0  0   1998 8
18  0  0  0  0  0  0  0  0   1998 9
19  0  0  0  0  0  0  0  0   1998 9
20  0  0  0  0  0  0  0  0   1998 9
21  0  0  0  0  0  0  0  0   1998 9
22  0  0  0  0  0  0  0  0   1998 9
23  0  0  0  0  0  0  0  0   1998 9
24  0  0  0  0  0  0  0  0   1998 9
25  0  0  0  0  0  0  0  0   1998 9
26  0  0  0  0  0  0  0  0   1998 9
27  0  0  0  0  0  0  0  0   1998 9
28  0  0  0  0  0  0  0  0   1998 9
29  0  0  0  0  0  0  0  0   1998 9
30  0  0  0  0  0  0  0  0   1998 9
31  0  0  0  0  0  0  0  0   1998 9
32  0  0  0  0  0  0  0  0   1998 9
33  0  0  0  0  0  0  0  0   1998 9
34  0  0  0  0  0  0  0  0   1998 9
35  0  0  0  0  0  0  0  0  1998 10
36  0  0  0  0  0  0  0  0  1998 10
37  0  0  0  0  0  0  0  0  1998 10
38  0  0  0  0  0  0  0  0  1998 10
39  0  0  0  0  0  0  0  0  1998 10
40  0  0  0  0  0  0  0  0  1998 10
41  0  0  0  0  0  0  0  0  1998 10
42  0  0  0  0  0  0  0  0  1998 10
43  0  0  0  0  0  0  0  0  1998 10
44  0  0  0  0  0  0  0  0  1998 10
45  0  0  0  0  0  0  0  0  1998 10
46  0  0  0  0  0  0  0  0  1998 10
47  0  0  0  0  0  0  0  0  1998 10
48  0  0  0  0  0  0  0  0  1998 10
49  0  0  0  0  0  0  0  0  1998 10
50  0  0  0  0  0  0  0  0  1998 10
51  0  0  0  0  0  0  0  0  1998 10



Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Oct 31, 2014 at 3:12 PM, Alemu Tadesse <alemu.tadesse at gmail.com>
wrote:

> Dear All,
>
> I have a file the sample of which is attached. I was trying to read the
> data and put it in a data frame. For example in this file, I have 1998 snow
> depth data and each block of data belongs to one month.    Each data point
> belongs to a given latitude and longitude (which is in another file). If I
> can read this data and put it in some kind of table where I can provided
> the index of the latitude and longitude and get the the data that would be
> awesome, but it is taking time. I am wondering if have read such a file.
>
> Best,
>
> Alemu
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


