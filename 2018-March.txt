From stephen66 at gmail.com  Thu Mar  1 07:18:48 2018
From: stephen66 at gmail.com (Stephen HonKit Wong)
Date: Wed, 28 Feb 2018 22:18:48 -0800
Subject: [R] how to make row.names based on column1 with duplicated values
Message-ID: <CAF4LHohk83q52x-ecSmEHcDts23Pkk=C9vA39K7sXeTwOQT4cg@mail.gmail.com>

Dear All,
Suppose I have a dataframe like this with many thousands rows all with
different names:
data.frame(gene=c("a","b","c","d","c","d","c","f"),value=c(20,300,48,55,9,2,100,200)),

I want to set column "gene" as row.names, but there are duplicates (c, d),
which I want to transform into this as row names: a, b, c-1, d-1, c-2, d-2,
c-3, f

Many thanks!

Stephen

	[[alternative HTML version deleted]]


From esetlzn at gmail.com  Thu Mar  1 07:19:48 2018
From: esetlzn at gmail.com (zn l)
Date: Thu, 1 Mar 2018 14:19:48 +0800
Subject: [R] Script file bug
Message-ID: <D1FC2DF2-E60E-4C88-A4B7-3F4F9A7981E2@gmail.com>

Hi?
  There is a bug in R 3.4.3(kite-eating tree) in mac os x 10.13.3. If a script have a comment in the first line, any output of this script  like plot won?t display in the screen.

?_?

From jdnewmil at dcn.davis.ca.us  Thu Mar  1 09:04:27 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 1 Mar 2018 00:04:27 -0800 (PST)
Subject: [R] Script file bug
In-Reply-To: <D1FC2DF2-E60E-4C88-A4B7-3F4F9A7981E2@gmail.com>
References: <D1FC2DF2-E60E-4C88-A4B7-3F4F9A7981E2@gmail.com>
Message-ID: <alpine.BSF.2.00.1802282358520.24033@pedal.dcn.davis.ca.us>

On Thu, 1 Mar 2018, zn l wrote:

> Hi?
>  There is a bug in R 3.4.3(kite-eating tree) in mac os x 10.13.3. If a 
> script have a comment in the first line, any output of this script like 
> plot won?t display in the screen.

a) If this is specific to Mac, you will get better quality responses on 
r-sig-mac mailing list.

b) I don't see this behavior on R3.4.3 on Windows.

c) Are you perhaps using lattice or ggplot graphs, and are unfamiliar with 
R FAQ 7.16 or 7.22?

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Thu Mar  1 09:12:44 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 1 Mar 2018 00:12:44 -0800 (PST)
Subject: [R] 
 how to make row.names based on column1 with duplicated values
In-Reply-To: <CAF4LHohk83q52x-ecSmEHcDts23Pkk=C9vA39K7sXeTwOQT4cg@mail.gmail.com>
References: <CAF4LHohk83q52x-ecSmEHcDts23Pkk=C9vA39K7sXeTwOQT4cg@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1803010006050.24033@pedal.dcn.davis.ca.us>

On Wed, 28 Feb 2018, Stephen HonKit Wong wrote:

> Dear All,
> Suppose I have a dataframe like this with many thousands rows all with
> different names:
> data.frame(gene=c("a","b","c","d","c","d","c","f"),value=c(20,300,48,55,9,2,100,200)),
>
> I want to set column "gene" as row.names, but there are duplicates (c, d),
> which I want to transform into this as row names: a, b, c-1, d-1, c-2, d-2,
> c-3, f

a) My reaction is that this doesn't actually sound like a very useful 
thing to do, so I caution you to beware of trying to accomplish too much 
with this capability... if it continues to be difficult to do what you 
want once you have these row names that appear nowhere else in your data, 
start looking for other ways to obtain the actual answers you want.

b) If your data frame is stored in `dta`, then you can do

rownames( dta ) <- make.names( dta$gene, unique = TRUE, sep="-" )

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From r.turner at auckland.ac.nz  Thu Mar  1 09:52:57 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Thu, 1 Mar 2018 21:52:57 +1300
Subject: [R] Repeated use of dyn.load().
Message-ID: <1cce5919-bbff-f3d0-95c4-5e9e9c6e24ef@auckland.ac.nz>


I am working with a function "foo" that explicitly dynamically loads a 
shared object library or "DLL", doing something like dyn.load("bar.so"). 
  This is a debugging exercise so I make changes to the underlying 
Fortran code (yes, I acknowledge that I am a dinosaur) remake the DLL 
"bar.so" and then run foo again.  This is all *without* quitting and 
restarting R.  (I'm going to have to do this a few brazillion times, and
I want the iterations to be as quick as possible.)

This seems to work --- i.e. foo seems to obtain the latest version of 
bar.so.  But have I just been lucky so far?  (I have not experimented 
heavily).

Am I running risks of leading myself down the garden path?  Are there 
Traps for Young (or even Old) Players lurking about?

I would appreciate Wise Counsel.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276

P. S.:

 > sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.3 LTS

Matrix products: default
BLAS: /usr/local/lib64/R/lib/libRblas.so
LAPACK: /usr/local/lib64/R/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_NZ.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_NZ.UTF-8        LC_COLLATE=en_NZ.UTF-8
  [5] LC_MONETARY=en_NZ.UTF-8    LC_MESSAGES=en_NZ.UTF-8
  [7] LC_PAPER=en_NZ.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_NZ.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] misc_0.0-16

loaded via a namespace (and not attached):
  [1] compiler_3.4.3       deldir_0.1-15        Matrix_1.2-10
  [4] spatstat.utils_1.8-0 mgcv_1.8-22          abind_1.4-5
  [7] spatstat.data_1.2-0  spatstat_1.55-0      rpart_4.1-11
[10] nlme_3.1-131         grid_3.4.3           polyclip_1.6-1
[13] lattice_0.20-35      goftest_1.1-1        tensor_1.5


From petr.pikal at precheza.cz  Thu Mar  1 10:56:36 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 1 Mar 2018 09:56:36 +0000
Subject: [R] 
 how to make row.names based on column1 with duplicated values
In-Reply-To: <alpine.BSF.2.00.1803010006050.24033@pedal.dcn.davis.ca.us>
References: <CAF4LHohk83q52x-ecSmEHcDts23Pkk=C9vA39K7sXeTwOQT4cg@mail.gmail.com>
 <alpine.BSF.2.00.1803010006050.24033@pedal.dcn.davis.ca.us>
Message-ID: <aae6f22a1b784f91a00602a354755681@SRVEXCHCM1301.precheza.cz>

Hi

You probably meant
make.unique( gene, sep="-" )
[1] "a"   "b"   "c"   "d"   "c-1" "d-1" "c-2" "f"

I second your objection to such name tweeking.

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
> Newmiller
> Sent: Thursday, March 1, 2018 9:13 AM
> To: Stephen HonKit Wong <stephen66 at gmail.com>
> Cc: r-help at r-project.org
> Subject: Re: [R] how to make row.names based on column1 with duplicated
> values
>
> On Wed, 28 Feb 2018, Stephen HonKit Wong wrote:
>
> > Dear All,
> > Suppose I have a dataframe like this with many thousands rows all with
> > different names:
> > data.frame(gene=c("a","b","c","d","c","d","c","f"),value=c(20,300,48,5
> > 5,9,2,100,200)),
> >
> > I want to set column "gene" as row.names, but there are duplicates (c,
> > d), which I want to transform into this as row names: a, b, c-1, d-1,
> > c-2, d-2, c-3, f
>
> a) My reaction is that this doesn't actually sound like a very useful thing to do,
> so I caution you to beware of trying to accomplish too much with this
> capability... if it continues to be difficult to do what you want once you have
> these row names that appear nowhere else in your data, start looking for other
> ways to obtain the actual answers you want.
>
> b) If your data frame is stored in `dta`, then you can do
>
> rownames( dta ) <- make.names( dta$gene, unique = TRUE, sep="-" )
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ruipbarradas at sapo.pt  Thu Mar  1 13:21:14 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 1 Mar 2018 12:21:14 +0000
Subject: [R] Repeated use of dyn.load().
In-Reply-To: <1cce5919-bbff-f3d0-95c4-5e9e9c6e24ef@auckland.ac.nz>
References: <1cce5919-bbff-f3d0-95c4-5e9e9c6e24ef@auckland.ac.nz>
Message-ID: <44f8b3fc-8b8f-8155-d903-0d63ddd96b1e@sapo.pt>

Hello,

In such cases, with C code, I call dyn.unload before loading the 
modified shared lib again.
I don't know if this changed recently, but it used to be needed or else 
R wouldn't load the new lib. When I call dyn.unload followed by dyn.load 
I never had problems.
(Or the other way around, call dyn.unload before modifying the C code.)

Hope this helps,

Rui Barradas

On 3/1/2018 8:52 AM, Rolf Turner wrote:
> 
> I am working with a function "foo" that explicitly dynamically loads a 
> shared object library or "DLL", doing something like dyn.load("bar.so"). 
>  ?This is a debugging exercise so I make changes to the underlying 
> Fortran code (yes, I acknowledge that I am a dinosaur) remake the DLL 
> "bar.so" and then run foo again.? This is all *without* quitting and 
> restarting R.? (I'm going to have to do this a few brazillion times, and
> I want the iterations to be as quick as possible.)
> 
> This seems to work --- i.e. foo seems to obtain the latest version of 
> bar.so.? But have I just been lucky so far?? (I have not experimented 
> heavily).
> 
> Am I running risks of leading myself down the garden path?? Are there 
> Traps for Young (or even Old) Players lurking about?
> 
> I would appreciate Wise Counsel.
> 
> cheers,
> 
> Rolf Turner
>


From jdnewmil at dcn.davis.ca.us  Thu Mar  1 15:25:14 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Mar 2018 06:25:14 -0800
Subject: [R] Script file bug
In-Reply-To: <9692D4CE-30E3-4ADF-8355-C94270DFA662@gmail.com>
References: <D1FC2DF2-E60E-4C88-A4B7-3F4F9A7981E2@gmail.com>
 <alpine.BSF.2.00.1802282358520.24033@pedal.dcn.davis.ca.us>
 <9692D4CE-30E3-4ADF-8355-C94270DFA662@gmail.com>
Message-ID: <3A4B5236-6EFE-4676-833F-859BBB2B7409@dcn.davis.ca.us>

Please always reply-all so the mailing list can record the answer along with your question. I am cc'ing this time.  Thanks for the unusual case.
-- 
Sent from my phone. Please excuse my brevity.

On March 1, 2018 12:46:53 AM PST, zn l <esetlzn at gmail.com> wrote:
>It is my mistake. I find that I input # character in the Chinese.  The
>R.app won?t display any error messages. 
>
>?_?
>
>> ? 2018?3?1??16:04?Jeff Newmiller <jdnewmil at dcn.davis.ca.us> ???
>> 
>>> On Thu, 1 Mar 2018, zn l wrote:
>>> 
>>> Hi?
>>> There is a bug in R 3.4.3(kite-eating tree) in mac os x 10.13.3. If
>a script have a comment in the first line, any output of this script
>like plot won?t display in the screen.
>> 
>> a) If this is specific to Mac, you will get better quality responses
>on r-sig-mac mailing list.
>> 
>> b) I don't see this behavior on R3.4.3 on Windows.
>> 
>> c) Are you perhaps using lattice or ggplot graphs, and are unfamiliar
>with R FAQ 7.16 or 7.22?
>> 
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                      Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------


From wdunlap at tibco.com  Thu Mar  1 17:01:34 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 1 Mar 2018 08:01:34 -0800
Subject: [R] 
 how to make row.names based on column1 with duplicated values
In-Reply-To: <CAF4LHohk83q52x-ecSmEHcDts23Pkk=C9vA39K7sXeTwOQT4cg@mail.gmail.com>
References: <CAF4LHohk83q52x-ecSmEHcDts23Pkk=C9vA39K7sXeTwOQT4cg@mail.gmail.com>
Message-ID: <CAF8bMcb1yChZs9w1gCkYsssJnocZjx1A2Ph_EuqXLjw_zv+e6A@mail.gmail.com>

You can do this with ave():

gene <- c("a","b","c","d","c","d","c","f")
ave(gene, gene, FUN=function(x)if(length(x)>1)paste(x,seq_along(x),sep="-")
else x)
# [1] "a"   "b"   "c-1" "d-1" "c-2" "d-2" "c-3" "f"

You can probably speed it up a bit by pulling the paste() out of FUN
and doing it later.  It would be simpler if you put the '-N' after all
genes,
not just the ones that were not repeated.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Feb 28, 2018 at 10:18 PM, Stephen HonKit Wong <stephen66 at gmail.com>
wrote:

> Dear All,
> Suppose I have a dataframe like this with many thousands rows all with
> different names:
> data.frame(gene=c("a","b","c","d","c","d","c","f"),value=c(
> 20,300,48,55,9,2,100,200)),
>
> I want to set column "gene" as row.names, but there are duplicates (c, d),
> which I want to transform into this as row names: a, b, c-1, d-1, c-2, d-2,
> c-3, f
>
> Many thanks!
>
> Stephen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From klebyn at yahoo.com.br  Thu Mar  1 17:04:59 2018
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Thu, 1 Mar 2018 13:04:59 -0300
Subject: [R] KK transform - Kramers-kronig relations
Message-ID: <8157a19b-2666-c241-81bf-ce1562dd8ac1@yahoo.com.br>

Hello everyone
Anyone know if there is implementation of Kramers-kronig relations[1] in
any package?
Thanks in advance for your attention.
Cleber Borges

[1] - https://en.wikipedia.org/wiki/Kramers%E2%80%93Kronig_relations


---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Thu Mar  1 19:44:59 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 1 Mar 2018 20:44:59 +0200
Subject: [R] Repeated use of dyn.load().
In-Reply-To: <44f8b3fc-8b8f-8155-d903-0d63ddd96b1e@sapo.pt>
References: <1cce5919-bbff-f3d0-95c4-5e9e9c6e24ef@auckland.ac.nz>
 <44f8b3fc-8b8f-8155-d903-0d63ddd96b1e@sapo.pt>
Message-ID: <CAGgJW75=0RpE1E9pLqbxeefuCX3O7HYZhA3JFc__Qn4s7oZBLQ@mail.gmail.com>

Good question Rolf.
Rui, thanks for pointing out dyn.unload.
When I started using Rcpp a couple of years ago I got burned by stale .so
enough times that I adopted a policy of recompile-then-start new R session.
My workflow does not include Rolf's "brazillion" repeats, so the overhead
of this approach has not been too painful.
The documentation for dyn.unload (via ?dyn.unload) includes the following
statement:

"The function dyn.unload unlinks the DLL. Note that unloading a DLL and
then re-loading a DLL of the same name may or may not work: on Solaris it
uses the first version loaded."

Eric



On Thu, Mar 1, 2018 at 2:21 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> In such cases, with C code, I call dyn.unload before loading the modified
> shared lib again.
> I don't know if this changed recently, but it used to be needed or else R
> wouldn't load the new lib. When I call dyn.unload followed by dyn.load I
> never had problems.
> (Or the other way around, call dyn.unload before modifying the C code.)
>
> Hope this helps,
>
> Rui Barradas
>
> On 3/1/2018 8:52 AM, Rolf Turner wrote:
>
>>
>> I am working with a function "foo" that explicitly dynamically loads a
>> shared object library or "DLL", doing something like dyn.load("bar.so").
>>  This is a debugging exercise so I make changes to the underlying Fortran
>> code (yes, I acknowledge that I am a dinosaur) remake the DLL "bar.so" and
>> then run foo again.  This is all *without* quitting and restarting R.  (I'm
>> going to have to do this a few brazillion times, and
>> I want the iterations to be as quick as possible.)
>>
>> This seems to work --- i.e. foo seems to obtain the latest version of
>> bar.so.  But have I just been lucky so far?  (I have not experimented
>> heavily).
>>
>> Am I running risks of leading myself down the garden path?  Are there
>> Traps for Young (or even Old) Players lurking about?
>>
>> I would appreciate Wise Counsel.
>>
>> cheers,
>>
>> Rolf Turner
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m.ashton at enduringinvestments.com  Thu Mar  1 23:02:55 2018
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Thu, 1 Mar 2018 22:02:55 +0000
Subject: [R] RExcel issues
Message-ID: <389dd89dd8f7457189a24c6f49ee1286@MBX084-W1-CA-3.exch084.serverpod.net>

Hi -

For a while I've used RExcel without problems to run a repeating portfolio optimization problem where I solve for a portfolio allocation targeting a particular risk, then solve for a different risk, etc. I call the commands with (e.g.) rinterface.Rrun "(R command)"

Recently that macro started blowing up, returning #RErrors, and when I try to trace the error I find that it is some kind of OLE error. I can't seem to find anything about it online and it's hard to replicate for someone else since you'd have to have my installation and my spreadsheet.

But I thought I'd ask the community and see if anyone else has had this problem recently with Rexcel. I'm calling solnp from within the RRun command, but again...it worked for a long time and I don't think it's the inputs that are wonky. Perhaps an update of R was incompatible with Rexcel? I've updated Rexcel to 3.2.16 but it made no difference.

Any suggestions of what to try will be warmly entertained!

Thanks,

Mike

Michael Ashton, CFA
Managing Principal

Enduring Investments LLC
W: 973.457.4602
C: 551.655.8006


	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Thu Mar  1 23:37:16 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 1 Mar 2018 14:37:16 -0800
Subject: [R] RExcel issues
In-Reply-To: <389dd89dd8f7457189a24c6f49ee1286@MBX084-W1-CA-3.exch084.serverpod.net>
References: <389dd89dd8f7457189a24c6f49ee1286@MBX084-W1-CA-3.exch084.serverpod.net>
Message-ID: <254F2601-3218-409B-AC59-91FDEE7D731B@comcast.net>


> On Mar 1, 2018, at 2:02 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
> 
> Hi -
> 
> For a while I've used RExcel without problems to run a repeating portfolio optimization problem where I solve for a portfolio allocation targeting a particular risk, then solve for a different risk, etc. I call the commands with (e.g.) rinterface.Rrun "(R command)"
> 
> Recently that macro started blowing up, returning #RErrors, and when I try to trace the error I find that it is some kind of OLE error. I can't seem to find anything about it online and it's hard to replicate for someone else since you'd have to have my installation and my spreadsheet.
> 
> But I thought I'd ask the community and see if anyone else has had this problem recently with Rexcel. I'm calling solnp from within the RRun command, but again...it worked for a long time and I don't think it's the inputs that are wonky. Perhaps an update of R was incompatible with Rexcel? I've updated Rexcel to 3.2.16 but it made no difference.

I'm pretty sure that RExcel is a commercial program and I assume that licensed users are expected to bring problems to the vendor.

http://rcom.univie.ac.at/contact.html


> 
> Any suggestions of what to try will be warmly entertained!
> 
> Thanks,
> 
> Mike
> 
> Michael Ashton, CFA
> Managing Principal
> 
> Enduring Investments LLC
> W: 973.457.4602
> C: 551.655.8006

I assume with that address you have a commercial license.

-- 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From m.ashton at enduringinvestments.com  Thu Mar  1 23:44:12 2018
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Thu, 1 Mar 2018 22:44:12 +0000
Subject: [R] RExcel issues
In-Reply-To: <254F2601-3218-409B-AC59-91FDEE7D731B@comcast.net>
References: <389dd89dd8f7457189a24c6f49ee1286@MBX084-W1-CA-3.exch084.serverpod.net>,
 <254F2601-3218-409B-AC59-91FDEE7D731B@comcast.net>
Message-ID: <B1838BB2-4085-4F60-9379-DFBD3E087B62@enduringinvestments.com>

No, this is home use. I wasn?t even aware there was a commercial license. 

> On Mar 1, 2018, at 5:37 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Mar 1, 2018, at 2:02 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>> 
>> Hi -
>> 
>> For a while I've used RExcel without problems to run a repeating portfolio optimization problem where I solve for a portfolio allocation targeting a particular risk, then solve for a different risk, etc. I call the commands with (e.g.) rinterface.Rrun "(R command)"
>> 
>> Recently that macro started blowing up, returning #RErrors, and when I try to trace the error I find that it is some kind of OLE error. I can't seem to find anything about it online and it's hard to replicate for someone else since you'd have to have my installation and my spreadsheet.
>> 
>> But I thought I'd ask the community and see if anyone else has had this problem recently with Rexcel. I'm calling solnp from within the RRun command, but again...it worked for a long time and I don't think it's the inputs that are wonky. Perhaps an update of R was incompatible with Rexcel? I've updated Rexcel to 3.2.16 but it made no difference.
> 
> I'm pretty sure that RExcel is a commercial program and I assume that licensed users are expected to bring problems to the vendor.
> 
> http://rcom.univie.ac.at/contact.html
> 
> 
>> 
>> Any suggestions of what to try will be warmly entertained!
>> 
>> Thanks,
>> 
>> Mike
>> 
>> Michael Ashton, CFA
>> Managing Principal
>> 
>> Enduring Investments LLC
>> W: 973.457.4602
>> C: 551.655.8006
> 
> I assume with that address you have a commercial license.
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 


From m.ashton at enduringinvestments.com  Thu Mar  1 23:45:37 2018
From: m.ashton at enduringinvestments.com (Michael Ashton)
Date: Thu, 1 Mar 2018 22:45:37 +0000
Subject: [R] RExcel issues
In-Reply-To: <254F2601-3218-409B-AC59-91FDEE7D731B@comcast.net>
References: <389dd89dd8f7457189a24c6f49ee1286@MBX084-W1-CA-3.exch084.serverpod.net>,
 <254F2601-3218-409B-AC59-91FDEE7D731B@comcast.net>
Message-ID: <A2B6FD5C-0307-4B2F-952F-250DCF1F47B6@enduringinvestments.com>

Thanks though - didn?t know there was that ecosystem. I will try that list. 

> On Mar 1, 2018, at 5:37 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Mar 1, 2018, at 2:02 PM, Michael Ashton <m.ashton at enduringinvestments.com> wrote:
>> 
>> Hi -
>> 
>> For a while I've used RExcel without problems to run a repeating portfolio optimization problem where I solve for a portfolio allocation targeting a particular risk, then solve for a different risk, etc. I call the commands with (e.g.) rinterface.Rrun "(R command)"
>> 
>> Recently that macro started blowing up, returning #RErrors, and when I try to trace the error I find that it is some kind of OLE error. I can't seem to find anything about it online and it's hard to replicate for someone else since you'd have to have my installation and my spreadsheet.
>> 
>> But I thought I'd ask the community and see if anyone else has had this problem recently with Rexcel. I'm calling solnp from within the RRun command, but again...it worked for a long time and I don't think it's the inputs that are wonky. Perhaps an update of R was incompatible with Rexcel? I've updated Rexcel to 3.2.16 but it made no difference.
> 
> I'm pretty sure that RExcel is a commercial program and I assume that licensed users are expected to bring problems to the vendor.
> 
> http://rcom.univie.ac.at/contact.html
> 
> 
>> 
>> Any suggestions of what to try will be warmly entertained!
>> 
>> Thanks,
>> 
>> Mike
>> 
>> Michael Ashton, CFA
>> Managing Principal
>> 
>> Enduring Investments LLC
>> W: 973.457.4602
>> C: 551.655.8006
> 
> I assume with that address you have a commercial license.
> 
> -- 
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 


From ruipbarradas at sapo.pt  Thu Mar  1 21:35:44 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 1 Mar 2018 20:35:44 +0000
Subject: [R] Repeated use of dyn.load().
In-Reply-To: <CAGgJW75=0RpE1E9pLqbxeefuCX3O7HYZhA3JFc__Qn4s7oZBLQ@mail.gmail.com>
References: <1cce5919-bbff-f3d0-95c4-5e9e9c6e24ef@auckland.ac.nz>
 <44f8b3fc-8b8f-8155-d903-0d63ddd96b1e@sapo.pt>
 <CAGgJW75=0RpE1E9pLqbxeefuCX3O7HYZhA3JFc__Qn4s7oZBLQ@mail.gmail.com>
Message-ID: <2c5e6405-8e80-5016-c537-dac30a250dd0@sapo.pt>

Hello,

Inline.

On 3/1/2018 6:44 PM, Eric Berger wrote:
> Good question Rolf.
> Rui, thanks for pointing out dyn.unload.
> When I started using Rcpp a couple of years ago I got burned by stale 
> .so enough times that I adopted a policy of recompile-then-start new R 
> session.
> My workflow does not include Rolf's "brazillion" repeats, so the 
> overhead of this approach has not been too painful.
> The documentation for dyn.unload (via ?dyn.unload) includes the 
> following statement:
> 
> "The function dyn.unload unlinks the DLL. Note that unloading a DLL and 
> then re-loading a DLL of the same name may or may not work: on Solaris 
> it uses the first version loaded."

Yes, I had noticed that sentence. But I have never used Solaris, and in 
Windows it works, to unload and then reload the dll loads the last one.

Also, in order to have code that works in other OS's I use two functions 
that are independent of the shared library extension used by the OS, 
'dll' or 'so'.

dynLoad <- function(dynlib){
     dynlib <- paste(dynlib, .Platform$dynlib.ext, sep = "")
     dyn.load(dynlib)
}

dynUnload <- function(dynlib){
     dynlib <- paste(dynlib, .Platform$dynlib.ext, sep = "")
     dyn.unload(dynlib)
}

These have saved me lots and lots of typing along the years. (Note that 
they still call paste/sep = "")

Hope this helps,

Rui Barradas

> 
> Eric
> 
> 
> 
> On Thu, Mar 1, 2018 at 2:21 PM, Rui Barradas <ruipbarradas at sapo.pt 
> <mailto:ruipbarradas at sapo.pt>> wrote:
> 
>     Hello,
> 
>     In such cases, with C code, I call dyn.unload before loading the
>     modified shared lib again.
>     I don't know if this changed recently, but it used to be needed or
>     else R wouldn't load the new lib. When I call dyn.unload followed by
>     dyn.load I never had problems.
>     (Or the other way around, call dyn.unload before modifying the C code.)
> 
>     Hope this helps,
> 
>     Rui Barradas
> 
>     On 3/1/2018 8:52 AM, Rolf Turner wrote:
> 
> 
>         I am working with a function "foo" that explicitly dynamically
>         loads a shared object library or "DLL", doing something like
>         dyn.load("bar.so").? ?This is a debugging exercise so I make
>         changes to the underlying Fortran code (yes, I acknowledge that
>         I am a dinosaur) remake the DLL "bar.so" and then run foo
>         again.? This is all *without* quitting and restarting R.? (I'm
>         going to have to do this a few brazillion times, and
>         I want the iterations to be as quick as possible.)
> 
>         This seems to work --- i.e. foo seems to obtain the latest
>         version of bar.so.? But have I just been lucky so far?? (I have
>         not experimented heavily).
> 
>         Am I running risks of leading myself down the garden path?? Are
>         there Traps for Young (or even Old) Players lurking about?
> 
>         I would appreciate Wise Counsel.
> 
>         cheers,
> 
>         Rolf Turner
> 
> 
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
> 
>


From jdnewmil at dcn.davis.ca.us  Fri Mar  2 04:49:14 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 01 Mar 2018 19:49:14 -0800
Subject: [R] Words near one another.
In-Reply-To: <287291262.10660072.1519804100088@mail.yahoo.com>
References: <287291262.10660072.1519804100088.ref@mail.yahoo.com>
 <287291262.10660072.1519804100088@mail.yahoo.com>
Message-ID: <4C2A44C2-445E-4983-9413-8CC8CDEF88FC@dcn.davis.ca.us>

Problem is not that your question is obvious, but that it is not clear what you want. 

However, you should be aware that R is a powerful programing language in which almost any algorithm you can find can be implemented. If you don't find answers when you Google or read the Text analysis Task View, then you can read some literature on the topic and create some tools to meet your needs.
-- 
Sent from my phone. Please excuse my brevity.

On February 27, 2018 11:48:20 PM PST, mathias svane hansen via R-help <r-help at r-project.org> wrote:
>Hi everyone. 
>
>I'm very new to R, so please forgive me, if I ask the obvious. I am
>currently using R to fulltextsearches in PDF files, using the PDFsearch
>package and it is working quite well. My question is however if it is
>possible search for words near one another fx "house" & "Busstop". 
>
>Thank you. 
>
>M. S. Hansen
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From L.J.Bonnett at liverpool.ac.uk  Fri Mar  2 14:38:43 2018
From: L.J.Bonnett at liverpool.ac.uk (Bonnett, Laura)
Date: Fri, 2 Mar 2018 13:38:43 +0000
Subject: [R] Variable centring within "predict.coxph"
Message-ID: <189d0de953d84ab2b144d84bbcae5a06@liverpool.ac.uk>

Dear R-help,

I am using R-3.3.2 on Windows 10.  I teach on a course which has 4 computer practical sessions related to the development and validation of clinical prediction models.  These are currently written for Stata and I am in the process of writing them for use in R too (as I far prefer R to Stata!)

I notice that predictions made from a Cox model in Stata are based on un-centred variables, while they are based on centred variables in R.  I am aware that variable centring is the preferred approach to ensure sensible predictions from models and thus usually I am pleased that variable centring is automatically applied within coxph in R.  However, for the sake of producing identical results across the software packages, is there a way to produce predictions from a Cox model in R without variable centring?

I am using the 'survival' package as follows (for example):
library(survival)
test1 <- list(time=c(4,3,1,1,2,2,3),
              status=c(1,1,1,0,1,1,0),
              x=c(0,2,1,1,1,0,0),
              sex=c(0,0,0,0,1,1,1))
mod1 <- coxph(Surv(time, status) ~ x + sex, test1)
predict(mod1,type="lp")

[This can of course be alternatively obtained from mod1$linear.predictor]

Many thanks for your assistance.

Kind regards,
Laura


	[[alternative HTML version deleted]]


From marchenamarlene at gmail.com  Fri Mar  2 11:16:11 2018
From: marchenamarlene at gmail.com (marlene marchena)
Date: Fri, 2 Mar 2018 11:16:11 +0100
Subject: [R] [R-pkgs] release of SCperf 1.1.1 and bullwhipgame packages
Message-ID: <CAKOtKsV7nrihXUL9oqAsN=QD99q0OX9MVAHJ87noQdTLjX2zmg@mail.gmail.com>

Dear R users.

I'm pleased to announce the release of *SCperf*  1.1.1  and *bullwhipgame*
packages on CRAN.

The *SCperf* package implements functions for planning and managing
Inventories in a Supply Chain:

https://CRAN.R-project.org/package=SCperf
<https://cran.r-project.org/package=SCperf>

And the *bullwhipgame* is a  shiny app demo of the bullwhip effect,  the
increase in demand variability along the supply chain. This educational
game seeks  to present the dynamics of the distribution of a product and to
show typical problems arising from a non-coordinated system:

https://CRAN.R-project.org/package=bullwhipgame
<https://cran.r-project.org/package=bullwhipgame>

The *bullwhipgame* app has been developed to substitute some related
functions (now deprecated) from the *SCperf* package and it is still in
development.  Comments, suggestions, bug report or just want to contribute
to the project please do not hesitate to contact me.

Kind regards,

Marlene Marchena

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From L.J.Bonnett at liverpool.ac.uk  Fri Mar  2 17:54:34 2018
From: L.J.Bonnett at liverpool.ac.uk (Bonnett, Laura)
Date: Fri, 2 Mar 2018 16:54:34 +0000
Subject: [R] Rstmp2 - linear predictors, AICs and BICs
Message-ID: <6ba5a0234b3f44e68d217b6109cde810@liverpool.ac.uk>

Dear R-help,

I am using R-3.3.2 on Windows 10.  As per my previous post today, I teach on a course which has 4 computer practical sessions related to the development and validation of clinical prediction models.  These are currently written for Stata and I am in the process of writing them for use in R too (as I far prefer R to Stata!)

Part of the practical requires the student to fit a flexible parametric model (using stmp2 in Stata).  They then need to establish the AIC and BIC for models with different numbers of knots.  Finally, they need to obtain the linear predictor for their chosen model.

The AIC can easily be established using the following code:
data(brcancer)
fit_3k <- stpm2(Surv(rectime,censrec==1)~hormon,data=brcancer,df=3)
fit_4k <- stpm2(Surv(rectime,censrec==1)~hormon,data=brcancer,df=4)
fit_5k <- stpm2(Surv(rectime,censrec==1)~hormon,data=brcancer,df=5)

AIC(fit_3k)
AIC(fit_4k)
AIC(fit_5k)
(although these equivalent values for my real dataset are different to those obtained using equivalent code in Stata).

However, the BIC equivalent code leads to "NA" responses.  I know that BIC is extractable within the equivalent code in Stata, so is anyone aware of how to extract the BIC in R?

Also, it is easy to obtain predictions from the model using code such as:
predict(fit_3k,type="hazard")

However, is there a way to extract the linear predictors for each individual?

Many thanks for your help.

Kind regards,
Laura

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Fri Mar  2 19:19:28 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Fri, 2 Mar 2018 20:19:28 +0200
Subject: [R] Variable centring within "predict.coxph"
In-Reply-To: <189d0de953d84ab2b144d84bbcae5a06@liverpool.ac.uk>
References: <189d0de953d84ab2b144d84bbcae5a06@liverpool.ac.uk>
Message-ID: <CAGgJW75KNPiEpOP1ctx0UmAqHLB_RKBPw9BG1ia0nvo=L_xp0g@mail.gmail.com>

Hi Laura,
I will state up front that I have no experience or knowledge of the Cox
model or the survival package.
Out of curiosity I loaded the package and did ?coxph and found the
following comment in the documentation:

"The routine internally scales and centers data to avoid overflow in the
argument to the exponential function. These actions do not change the
result, but lead to more numerical stability."

This would seem to imply that for "good" cases, i.e. those which are
numerically stable, the two approaches (centered or not-centered) should
give the same results. Maybe you can find a test data set that is a "good"
case and compare the Stata and R results for that data to gain confidence
that you are calling the package correctly.

HTH,
Eric



On Fri, Mar 2, 2018 at 3:38 PM, Bonnett, Laura <L.J.Bonnett at liverpool.ac.uk>
wrote:

> Dear R-help,
>
> I am using R-3.3.2 on Windows 10.  I teach on a course which has 4
> computer practical sessions related to the development and validation of
> clinical prediction models.  These are currently written for Stata and I am
> in the process of writing them for use in R too (as I far prefer R to
> Stata!)
>
> I notice that predictions made from a Cox model in Stata are based on
> un-centred variables, while they are based on centred variables in R.  I am
> aware that variable centring is the preferred approach to ensure sensible
> predictions from models and thus usually I am pleased that variable
> centring is automatically applied within coxph in R.  However, for the sake
> of producing identical results across the software packages, is there a way
> to produce predictions from a Cox model in R without variable centring?
>
> I am using the 'survival' package as follows (for example):
> library(survival)
> test1 <- list(time=c(4,3,1,1,2,2,3),
>               status=c(1,1,1,0,1,1,0),
>               x=c(0,2,1,1,1,0,0),
>               sex=c(0,0,0,0,1,1,1))
> mod1 <- coxph(Surv(time, status) ~ x + sex, test1)
> predict(mod1,type="lp")
>
> [This can of course be alternatively obtained from mod1$linear.predictor]
>
> Many thanks for your assistance.
>
> Kind regards,
> Laura
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ycding at coh.org  Fri Mar  2 19:34:36 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Fri, 2 Mar 2018 18:34:36 +0000
Subject: [R] data analysis for partial two-by-two factorial design
Message-ID: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>

Dear R users,

I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.

Thank you very much!

Yuan Chun Ding


---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely f...{{dropped:28}}


From mtsagris at yahoo.gr  Fri Mar  2 19:50:54 2018
From: mtsagris at yahoo.gr (michael tsagris)
Date: Fri, 2 Mar 2018 18:50:54 +0000 (UTC)
Subject: [R] Desktop.ini hiddeln file creates during compilaiton
References: <1942851973.13885821.1520016654437.ref@mail.yahoo.com>
Message-ID: <1942851973.13885821.1520016654437@mail.yahoo.com>

Hello,?I?am experiencing some difficult time with my R package. Every time I compilei it a hidden file, desktop.ini, is?being created. I am using C++ behind, linkking to Rcpp. The file is generated even when I compile it with?Linux, and in many different computers. Does anybody have any advice or ideas?
	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Mar  2 21:32:12 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Fri, 2 Mar 2018 12:32:12 -0800
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>

This list provides help on R programming (see the posting guide linked
below for details on what is/is not considered on topic), and generally
avoids discussion of purely statistical issues, which is what your query
appears to be. The simple answer is yes, you can fit the model as
described,  but you clearly need the off topic discussion as to what it
does or does not mean. For that, you might try the stats.stackexchange.com
statistical site.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org> wrote:

> Dear R users,
>
> I need to analyze data generated from a partial two-by-two factorial
> design: two levels for drug A (yes, no), two levels for drug B (yes, no);
> however, data points are available only for three groups, no drugA/no
> drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group
> of no drugA/yes drugB.  I think we can not investigate interaction between
> drug A and drug B, can I still run  model using R as usual:  response
> variable = drug A + drug B?  any suggestion is appreciated.
>
> Thank you very much!
>
> Yuan Chun Ding
>
>
> ---------------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> This message (and any attachments) are intended solely...{{dropped:13}}


From ycding at coh.org  Fri Mar  2 21:44:24 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Fri, 2 Mar 2018 20:44:24 +0000
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6A6BB1F@PPWEXCH2KX14.coh.org>

Hi Bert,

Thank  you so much for your direction, I have asked a question on stackexchange website.

Ding

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Friday, March 02, 2018 12:32 PM
To: Ding, Yuan Chun
Cc: r-help at r-project.org
Subject: Re: [R] data analysis for partial two-by-two factorial design

________________________________
[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
________________________________

This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com> statistical site.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Dear R users,

I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.

Thank you very much!

Yuan Chun Ding


---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely f...{{dropped:28}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Mar  3 00:33:24 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 02 Mar 2018 15:33:24 -0800
Subject: [R] Desktop.ini hiddeln file creates during compilaiton
In-Reply-To: <1942851973.13885821.1520016654437@mail.yahoo.com>
References: <1942851973.13885821.1520016654437.ref@mail.yahoo.com>
 <1942851973.13885821.1520016654437@mail.yahoo.com>
Message-ID: <3C206652-ECAD-46E0-8D58-CF262050F0B2@dcn.davis.ca.us>

Make a reproducible example [1][2][3], because it doesn't happen for me. Then post your example at [4] or [5], because this is the wrong list for this question. 

You may find that the act of browsing the directory using a GUI is what creates that file rather than the compilation itself.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

[4] http://stat.ethz.ch/mailman/listinfo/r-package-devel

[5] https://github.com/RcppCore/Rcpp/issues
-- 
Sent from my phone. Please excuse my brevity.

On March 2, 2018 10:50:54 AM PST, michael tsagris via R-help <r-help at r-project.org> wrote:
>Hello,?I?am experiencing some difficult time with my R package. Every
>time I compilei it a hidden file, desktop.ini, is?being created. I am
>using C++ behind, linkking to Rcpp. The file is generated even when I
>compile it with?Linux, and in many different computers. Does anybody
>have any advice or ideas?
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From allaisone1 at hotmail.com  Sat Mar  3 01:14:28 2018
From: allaisone1 at hotmail.com (Allaisone 1)
Date: Sat, 3 Mar 2018 00:14:28 +0000
Subject: [R] reshaping column items into rows per unique ID
In-Reply-To: <CA+8X3fU1fRn2x9p4S9=5MdyBZqRDJKEJ6woC1uvyNccJUPYGWA@mail.gmail.com>
References: <DB6P195MB010148B9F2CF1D2DE012AC2980C20@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>,
 <CA+8X3fU1fRn2x9p4S9=5MdyBZqRDJKEJ6woC1uvyNccJUPYGWA@mail.gmail.com>
Message-ID: <DB6P195MB01014C4DF8C23AFC3B1452D080C40@DB6P195MB0101.EURP195.PROD.OUTLOOK.COM>

Many thanks all for your very helpful replays.

I wasn't aware by stretch_df function in PrettyR package!.. It has produced exactly what I want in a very simple and efficient way!. Thank you so much Jim.

Kind Regards
Allaisone

________________________________________
From: Jim Lemon <drjimlemon at gmail.com>
Sent: 25 February 2018 21:48:51
To: Allaisone 1; r-help mailing list
Subject: Re: [R] reshaping column items into rows per unique ID

Hi Allaisone,
If you want a data frame as the output you will have to put up with a
few NA values unless each Customer has the same number of diet types:

a1df<-read.table(text="CustomerID    DietType
1                           a
1                            c
1                            b
2                            f
2                             a
3                             j
4                             c
4                             c
4                              f",
header=TRUE,stringsAsFactors=FALSE)
library(prettyR)
stretch_df(a1df,"CustomerID","DietType")
  CustomerID DietType_1 DietType_2 DietType_3
1          1          a          c          b
2          2          f          a       <NA>
3          3          j       <NA>       <NA>
4          4          c          c          f

Jim


On Sun, Feb 25, 2018 at 11:59 PM, Allaisone 1 <allaisone1 at hotmail.com> wrote:
> Hi All
>
> I have a datafram which looks like this :
>
> CustomerID    DietType
> 1                           a
> 1                            c
> 1                            b
> 2                            f
> 2                             a
> 3                             j
> 4                             c
> 4                             c
> 4                              f
>
> And I would like to reshape this so I can see the list of DietTypes per customer in rows instead of columns like this :
>
>> MyDf
> CustomerID      DietType   DietType  DietType
> 1                                a            c               b
> 2                                 f             a
> 3                                 j
> 4                                 c              c             f
>
> I tried many times using melt(),spread (),and dcast () functions but was not able to produce the desired table. The best attempt was by typing :
>
> # 1) Adding new column with unique values:
> MyDf $newcol <- c (1:9)
> #2) then :
> NewDf <- dcast (MyDf,CustomerID~newcol,value.var=DietType)
>
> This produces the desired table but with many NA values like this :
>
> CustomerID    1   2   3    4     5    6     7   8   9
> 1                    a  c    b   NA NA NA NA NA NA
> 2                  NA NA NA  f     a  NA NA NA NA
> 3                  NA NA NA NA NA  j   NA NA NA
> 4                  NA NA NA NA NA NA c     c     f
>
>   As you see, the lette/s indicating DietType move to the right side each time we move down leaving many NA values and as my original files is very large, I expect that the final output would contain around 800,000 columns and 70,000 rows. This is why my code works with small data but does not work with my large file because of memory issue even though I'm using large PC.
>
> What changes I need to do with my code to produce the desired table where the list of DietTypes are grouped in rows exactly like the second table shown abover?
>
> Regards
> Allaisnoe
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mtsagris at yahoo.gr  Sat Mar  3 06:55:20 2018
From: mtsagris at yahoo.gr (michael tsagris)
Date: Sat, 3 Mar 2018 05:55:20 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBEZXNrdG9wLmluaSBoaWRkZWxuIGZpbGUg?=
 =?utf-8?q?creates_during_compilaiton?=
In-Reply-To: <3C206652-ECAD-46E0-8D58-CF262050F0B2@dcn.davis.ca.us>
References: <1942851973.13885821.1520016654437.ref@mail.yahoo.com>
 <1942851973.13885821.1520016654437@mail.yahoo.com>
 <3C206652-ECAD-46E0-8D58-CF262050F0B2@dcn.davis.ca.us>
Message-ID: <258508518.8408384.1520056520406@mail.yahoo.com>

Thanks for the reply. I will try everything.? 

    ???? 1:33 ?.?. ???????, 3 ??????? 2018, ?/? Jeff Newmiller <jdnewmil at dcn.davis.ca.us> ??????:
 

 Make a reproducible example [1][2][3], because it doesn't happen for me. Then post your example at [4] or [5], because this is the wrong list for this question. 

You may find that the act of browsing the directory using a GUI is what creates that file rather than the compilation itself.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

[4] http://stat.ethz.ch/mailman/listinfo/r-package-devel

[5] https://github.com/RcppCore/Rcpp/issues
-- 
Sent from my phone. Please excuse my brevity.

On March 2, 2018 10:50:54 AM PST, michael tsagris via R-help <r-help at r-project.org> wrote:
>Hello,?I?am experiencing some difficult time with my R package. Every
>time I compilei it a hidden file, desktop.ini, is?being created. I am
>using C++ behind, linkking to Rcpp. The file is generated even when I
>compile it with?Linux, and in many different computers. Does anybody
>have any advice or ideas?
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From mtsagris at yahoo.gr  Sat Mar  3 13:11:58 2018
From: mtsagris at yahoo.gr (michael tsagris)
Date: Sat, 3 Mar 2018 12:11:58 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBEZXNrdG9wLmluaSBoaWRkZWxuIGZpbGUg?=
 =?utf-8?q?creates_during_compilaiton?=
In-Reply-To: <3C206652-ECAD-46E0-8D58-CF262050F0B2@dcn.davis.ca.us>
References: <1942851973.13885821.1520016654437.ref@mail.yahoo.com>
 <1942851973.13885821.1520016654437@mail.yahoo.com>
 <3C206652-ECAD-46E0-8D58-CF262050F0B2@dcn.davis.ca.us>
Message-ID: <1206144805.14286823.1520079118634@mail.yahoo.com>

Hi Jeff,
I cannot reproduce it. It's somehting that happens, the dektop.ini file is being created during compilation. Who can help me with this?
I cannot send the e-mail to the other list you suggested because I am not a subscriber.? 

    ???? 1:33 ?.?. ???????, 3 ??????? 2018, ?/? Jeff Newmiller <jdnewmil at dcn.davis.ca.us> ??????:
 

 Make a reproducible example [1][2][3], because it doesn't happen for me. Then post your example at [4] or [5], because this is the wrong list for this question. 

You may find that the act of browsing the directory using a GUI is what creates that file rather than the compilation itself.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)

[4] http://stat.ethz.ch/mailman/listinfo/r-package-devel

[5] https://github.com/RcppCore/Rcpp/issues
-- 
Sent from my phone. Please excuse my brevity.

On March 2, 2018 10:50:54 AM PST, michael tsagris via R-help <r-help at r-project.org> wrote:
>Hello,?I?am experiencing some difficult time with my R package. Every
>time I compilei it a hidden file, desktop.ini, is?being created. I am
>using C++ behind, linkking to Rcpp. The file is generated even when I
>compile it with?Linux, and in many different computers. Does anybody
>have any advice or ideas?
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

   
	[[alternative HTML version deleted]]


From whjktk at gmail.com  Sat Mar  3 14:39:54 2018
From: whjktk at gmail.com (Wahaj Habib)
Date: Sat, 3 Mar 2018 20:39:54 +0700
Subject: [R] Fwd: Adding a timeline style graphic using r-highcharter
In-Reply-To: <CABBjMERhqz1Yz=OPitmq7-YuZuny+Aw+zbLeGe5Lee-XBmEWVQ@mail.gmail.com>
References: <CABBjMERhqz1Yz=OPitmq7-YuZuny+Aw+zbLeGe5Lee-XBmEWVQ@mail.gmail.com>
Message-ID: <CABBjMESbs-ixtD6DswdkT1VifE8Y2EzEUuO8MyeYjgoFFdArDg@mail.gmail.com>

 Adding a timeline style graphic using r-highcharter
I have hydro-graphs that I am creating using *highcharter* library in R. I
want to add another variable(or adjust value with any existing variable) to
this graph as a timeline (as shown in the image). The value table for this
variable is a time series data frame as well but, the values are as "0" and
"1" where "0" shows no flood and "1" shows flood. So I want to show (only
value "1") this as flood duration as a timeline.
image link
https://i.stack.imgur.com/2hVoZ.png

link for data and code
https://drive.google.com/open?id=1I76ASCvu7V7Iv-MjeVAAXONnyJqCyOWi

	[[alternative HTML version deleted]]


From christienkerbert at gmail.com  Sun Mar  4 00:04:32 2018
From: christienkerbert at gmail.com (Christien Kerbert)
Date: Sun, 4 Mar 2018 00:04:32 +0100
Subject: [R] lmrob gives NA coefficients
Message-ID: <CACoCsecbONvDk1M4mhejP==m+WqRpJjJEWEBGhh1GJwaiBSE5A@mail.gmail.com>

Dear list members,

I want to perform an MM-regression. This seems an easy task using the
function lmrob(), however, this function provides me with NA coefficients.
My data generating process is as follows:

rho <- 0.15  # low interdependency
Sigma <- matrix(rho, d, d); diag(Sigma) <- 1
x.clean <- mvrnorm(n, rep(0,d), Sigma)
beta <- c(1.0, 2.0, 3.0, 4.0)
error <- rnorm(n = n, mean = 0, sd = 1)
y <- as.data.frame(beta[1]*rep(1, n) + beta[2]*x.clean[,1] +
beta[3]*x.clean[,2] + beta[4]*x.clean[,3] + error)
xy.clean <- cbind(x.clean, y)
colnames(xy.clean) <- c("x1", "x2", "x3", "y")

Then, I pass the following formula to lmrob: f <- y ~ x1 + x2 + x3

Finally, I run lmrob: lmrob(f, data = data, cov = ".vcov.w")
and this results in NA coefficients.

It would be great if anyone can help me out. Thanks in advance.

Regards,
Christien

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sun Mar  4 00:52:17 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 3 Mar 2018 15:52:17 -0800
Subject: [R] lmrob gives NA coefficients
In-Reply-To: <CACoCsecbONvDk1M4mhejP==m+WqRpJjJEWEBGhh1GJwaiBSE5A@mail.gmail.com>
References: <CACoCsecbONvDk1M4mhejP==m+WqRpJjJEWEBGhh1GJwaiBSE5A@mail.gmail.com>
Message-ID: <9B84138C-D650-4276-BE01-2C3B5D337C2F@comcast.net>


> On Mar 3, 2018, at 3:04 PM, Christien Kerbert <christienkerbert at gmail.com> wrote:
> 
> Dear list members,
> 
> I want to perform an MM-regression. This seems an easy task using the
> function lmrob(), however, this function provides me with NA coefficients.
> My data generating process is as follows:
> 
> rho <- 0.15  # low interdependency
> Sigma <- matrix(rho, d, d); diag(Sigma) <- 1
> x.clean <- mvrnorm(n, rep(0,d), Sigma)

Which package are you using for mvrnorm?

> beta <- c(1.0, 2.0, 3.0, 4.0)
> error <- rnorm(n = n, mean = 0, sd = 1)
> y <- as.data.frame(beta[1]*rep(1, n) + beta[2]*x.clean[,1] +
> beta[3]*x.clean[,2] + beta[4]*x.clean[,3] + error)
> xy.clean <- cbind(x.clean, y)
> colnames(xy.clean) <- c("x1", "x2", "x3", "y")
> 
> Then, I pass the following formula to lmrob: f <- y ~ x1 + x2 + x3
> 
> Finally, I run lmrob: lmrob(f, data = data, cov = ".vcov.w")
> and this results in NA coefficients.

It would also be more courteous to specify the package where you are getting lmrob.

> 
> It would be great if anyone can help me out. Thanks in advance.
> 
> Regards,
> Christien
> 
> 	[[alternative HTML version deleted]]

This is a plain text mailing list although it doesn't seem to have created problems this time.

> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From christienkerbert at gmail.com  Sun Mar  4 11:14:10 2018
From: christienkerbert at gmail.com (Christien Kerbert)
Date: Sun, 4 Mar 2018 11:14:10 +0100
Subject: [R] lmrob gives NA coefficients
In-Reply-To: <9B84138C-D650-4276-BE01-2C3B5D337C2F@comcast.net>
References: <CACoCsecbONvDk1M4mhejP==m+WqRpJjJEWEBGhh1GJwaiBSE5A@mail.gmail.com>
 <9B84138C-D650-4276-BE01-2C3B5D337C2F@comcast.net>
Message-ID: <CACoCseeU43ftRB1oyQokbV5+v34HA5kydae2RonOXw4XUEHA5Q@mail.gmail.com>

Thanks for your reply.

I use mvrnorm from the *MASS* package and lmrob from the *robustbase*
package.

To further explain my data generating process, the idea is as follows. The
explanatory variables are generated my a multivariate normal distribution
where the covariance matrix of the variables is defined by Sigma in my
code, with ones on the diagonal and rho = 0.15 on the non-diagonal. Then y
is created by y = 1 - 2*x1 + 3*x3 + 4*x4 + error and the error term is
standard normal distributed.

Hope this helps.

Regards,
Christien

In this section, we provide a simulation study to illustrate the
performance of four estimators, the (GLS), S, MM and MM ridge estimator for
SUR model. This simulation process is executed to generate data for the
following equation   Where  In this simulation, we set the initial value
for ?= [1,2,3] for k=3. The explanatory variables are generated by
multivariate normal distribution MNNk=3 (0,?x) where diag(?x)=1,
off-diag(?x)= ?X= 0.15 for low interdependency and ?x= 0.70 for high
interdependency. Where ?x is correlation between explanatory variables. We
chose two sample size 25 for small sample and 100 for large sample. The
specific error in equations ?i, i=1,2,?..,n, we generated by MVNk=3 (0,
??), ?? the variance covariance matrix of errors, diag(??)= 1,
off-diag(??)= ??= 0.15. To investigate the robustness of the estimators
against outliers, we chosen different percentages of outliers ( 20%, 45%).
We choose shrink parameter in (12) by minimize the new robust Cross
Validation (CVMM) criterion which avoided

2018-03-04 0:52 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Mar 3, 2018, at 3:04 PM, Christien Kerbert <
> christienkerbert at gmail.com> wrote:
> >
> > Dear list members,
> >
> > I want to perform an MM-regression. This seems an easy task using the
> > function lmrob(), however, this function provides me with NA
> coefficients.
> > My data generating process is as follows:
> >
> > rho <- 0.15  # low interdependency
> > Sigma <- matrix(rho, d, d); diag(Sigma) <- 1
> > x.clean <- mvrnorm(n, rep(0,d), Sigma)
>
> Which package are you using for mvrnorm?
>
> > beta <- c(1.0, 2.0, 3.0, 4.0)
> > error <- rnorm(n = n, mean = 0, sd = 1)
> > y <- as.data.frame(beta[1]*rep(1, n) + beta[2]*x.clean[,1] +
> > beta[3]*x.clean[,2] + beta[4]*x.clean[,3] + error)
> > xy.clean <- cbind(x.clean, y)
> > colnames(xy.clean) <- c("x1", "x2", "x3", "y")
> >
> > Then, I pass the following formula to lmrob: f <- y ~ x1 + x2 + x3
> >
> > Finally, I run lmrob: lmrob(f, data = data, cov = ".vcov.w")
> > and this results in NA coefficients.
>
> It would also be more courteous to specify the package where you are
> getting lmrob.
>
> >
> > It would be great if anyone can help me out. Thanks in advance.
> >
> > Regards,
> > Christien
> >
> >       [[alternative HTML version deleted]]
>
> This is a plain text mailing list although it doesn't seem to have created
> problems this time.
>
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Sun Mar  4 11:30:53 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 4 Mar 2018 12:30:53 +0200
Subject: [R] lmrob gives NA coefficients
In-Reply-To: <CACoCseeU43ftRB1oyQokbV5+v34HA5kydae2RonOXw4XUEHA5Q@mail.gmail.com>
References: <CACoCsecbONvDk1M4mhejP==m+WqRpJjJEWEBGhh1GJwaiBSE5A@mail.gmail.com>
 <9B84138C-D650-4276-BE01-2C3B5D337C2F@comcast.net>
 <CACoCseeU43ftRB1oyQokbV5+v34HA5kydae2RonOXw4XUEHA5Q@mail.gmail.com>
Message-ID: <CAGgJW75qjA6HYPyRTqdRpRqcx8gPcLJ3E0F85guv1gLekhNhcg@mail.gmail.com>

What is 'd'? What is 'n'?


On Sun, Mar 4, 2018 at 12:14 PM, Christien Kerbert <
christienkerbert at gmail.com> wrote:

> Thanks for your reply.
>
> I use mvrnorm from the *MASS* package and lmrob from the *robustbase*
> package.
>
> To further explain my data generating process, the idea is as follows. The
> explanatory variables are generated my a multivariate normal distribution
> where the covariance matrix of the variables is defined by Sigma in my
> code, with ones on the diagonal and rho = 0.15 on the non-diagonal. Then y
> is created by y = 1 - 2*x1 + 3*x3 + 4*x4 + error and the error term is
> standard normal distributed.
>
> Hope this helps.
>
> Regards,
> Christien
>
> In this section, we provide a simulation study to illustrate the
> performance of four estimators, the (GLS), S, MM and MM ridge estimator for
> SUR model. This simulation process is executed to generate data for the
> following equation   Where  In this simulation, we set the initial value
> for ?= [1,2,3] for k=3. The explanatory variables are generated by
> multivariate normal distribution MNNk=3 (0,?x) where diag(?x)=1,
> off-diag(?x)= ?X= 0.15 for low interdependency and ?x= 0.70 for high
> interdependency. Where ?x is correlation between explanatory variables. We
> chose two sample size 25 for small sample and 100 for large sample. The
> specific error in equations ?i, i=1,2,?..,n, we generated by MVNk=3 (0,
> ??), ?? the variance covariance matrix of errors, diag(??)= 1,
> off-diag(??)= ??= 0.15. To investigate the robustness of the estimators
> against outliers, we chosen different percentages of outliers ( 20%, 45%).
> We choose shrink parameter in (12) by minimize the new robust Cross
> Validation (CVMM) criterion which avoided
>
> 2018-03-04 0:52 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:
>
> >
> > > On Mar 3, 2018, at 3:04 PM, Christien Kerbert <
> > christienkerbert at gmail.com> wrote:
> > >
> > > Dear list members,
> > >
> > > I want to perform an MM-regression. This seems an easy task using the
> > > function lmrob(), however, this function provides me with NA
> > coefficients.
> > > My data generating process is as follows:
> > >
> > > rho <- 0.15  # low interdependency
> > > Sigma <- matrix(rho, d, d); diag(Sigma) <- 1
> > > x.clean <- mvrnorm(n, rep(0,d), Sigma)
> >
> > Which package are you using for mvrnorm?
> >
> > > beta <- c(1.0, 2.0, 3.0, 4.0)
> > > error <- rnorm(n = n, mean = 0, sd = 1)
> > > y <- as.data.frame(beta[1]*rep(1, n) + beta[2]*x.clean[,1] +
> > > beta[3]*x.clean[,2] + beta[4]*x.clean[,3] + error)
> > > xy.clean <- cbind(x.clean, y)
> > > colnames(xy.clean) <- c("x1", "x2", "x3", "y")
> > >
> > > Then, I pass the following formula to lmrob: f <- y ~ x1 + x2 + x3
> > >
> > > Finally, I run lmrob: lmrob(f, data = data, cov = ".vcov.w")
> > > and this results in NA coefficients.
> >
> > It would also be more courteous to specify the package where you are
> > getting lmrob.
> >
> > >
> > > It would be great if anyone can help me out. Thanks in advance.
> > >
> > > Regards,
> > > Christien
> > >
> > >       [[alternative HTML version deleted]]
> >
> > This is a plain text mailing list although it doesn't seem to have
> created
> > problems this time.
> >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
> >  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Sun Mar  4 12:08:54 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 4 Mar 2018 13:08:54 +0200
Subject: [R] lmrob gives NA coefficients
In-Reply-To: <CACoCsefjLUJ=kVP9KRoGpqU0nmVrs4ogbYUZ1jXOUmiUYbXOJg@mail.gmail.com>
References: <CACoCsecbONvDk1M4mhejP==m+WqRpJjJEWEBGhh1GJwaiBSE5A@mail.gmail.com>
 <9B84138C-D650-4276-BE01-2C3B5D337C2F@comcast.net>
 <CACoCseeU43ftRB1oyQokbV5+v34HA5kydae2RonOXw4XUEHA5Q@mail.gmail.com>
 <CAGgJW75qjA6HYPyRTqdRpRqcx8gPcLJ3E0F85guv1gLekhNhcg@mail.gmail.com>
 <CACoCsefjLUJ=kVP9KRoGpqU0nmVrs4ogbYUZ1jXOUmiUYbXOJg@mail.gmail.com>
Message-ID: <CAGgJW74M8MUpJa4oeZ8=Q=JPbTYFE-oxhK1fvJjBC_CzHumntw@mail.gmail.com>

Hard to help you if you don't provide a reproducible example.

On Sun, Mar 4, 2018 at 1:05 PM, Christien Kerbert <
christienkerbert at gmail.com> wrote:

> d is the number of observed variables (d = 3 in this example). n is the
> number of observations.
>
> 2018-03-04 11:30 GMT+01:00 Eric Berger <ericjberger at gmail.com>:
>
>> What is 'd'? What is 'n'?
>>
>>
>> On Sun, Mar 4, 2018 at 12:14 PM, Christien Kerbert <
>> christienkerbert at gmail.com> wrote:
>>
>>> Thanks for your reply.
>>>
>>> I use mvrnorm from the *MASS* package and lmrob from the *robustbase*
>>> package.
>>>
>>> To further explain my data generating process, the idea is as follows.
>>> The
>>> explanatory variables are generated my a multivariate normal distribution
>>> where the covariance matrix of the variables is defined by Sigma in my
>>> code, with ones on the diagonal and rho = 0.15 on the non-diagonal. Then
>>> y
>>> is created by y = 1 - 2*x1 + 3*x3 + 4*x4 + error and the error term is
>>> standard normal distributed.
>>>
>>> Hope this helps.
>>>
>>> Regards,
>>> Christien
>>>
>>> In this section, we provide a simulation study to illustrate the
>>> performance of four estimators, the (GLS), S, MM and MM ridge estimator
>>> for
>>> SUR model. This simulation process is executed to generate data for the
>>> following equation   Where  In this simulation, we set the initial value
>>>
>>> for ?= [1,2,3] for k=3. The explanatory variables are generated by
>>> multivariate normal distribution MNNk=3 (0,?x) where diag(?x)=1,
>>> off-diag(?x)= ?X= 0.15 for low interdependency and ?x= 0.70 for high
>>> interdependency. Where ?x is correlation between explanatory variables.
>>> We
>>> chose two sample size 25 for small sample and 100 for large sample. The
>>> specific error in equations ?i, i=1,2,?..,n, we generated by MVNk=3 (0,
>>> ??), ?? the variance covariance matrix of errors, diag(??)= 1,
>>> off-diag(??)= ??= 0.15. To investigate the robustness of the estimators
>>> against outliers, we chosen different percentages of outliers ( 20%,
>>> 45%).
>>> We choose shrink parameter in (12) by minimize the new robust Cross
>>> Validation (CVMM) criterion which avoided
>>>
>>> 2018-03-04 0:52 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:
>>>
>>> >
>>> > > On Mar 3, 2018, at 3:04 PM, Christien Kerbert <
>>> > christienkerbert at gmail.com> wrote:
>>> > >
>>> > > Dear list members,
>>> > >
>>> > > I want to perform an MM-regression. This seems an easy task using the
>>> > > function lmrob(), however, this function provides me with NA
>>> > coefficients.
>>> > > My data generating process is as follows:
>>> > >
>>> > > rho <- 0.15  # low interdependency
>>> > > Sigma <- matrix(rho, d, d); diag(Sigma) <- 1
>>> > > x.clean <- mvrnorm(n, rep(0,d), Sigma)
>>> >
>>> > Which package are you using for mvrnorm?
>>> >
>>> > > beta <- c(1.0, 2.0, 3.0, 4.0)
>>> > > error <- rnorm(n = n, mean = 0, sd = 1)
>>> > > y <- as.data.frame(beta[1]*rep(1, n) + beta[2]*x.clean[,1] +
>>> > > beta[3]*x.clean[,2] + beta[4]*x.clean[,3] + error)
>>> > > xy.clean <- cbind(x.clean, y)
>>> > > colnames(xy.clean) <- c("x1", "x2", "x3", "y")
>>> > >
>>> > > Then, I pass the following formula to lmrob: f <- y ~ x1 + x2 + x3
>>> > >
>>> > > Finally, I run lmrob: lmrob(f, data = data, cov = ".vcov.w")
>>> > > and this results in NA coefficients.
>>> >
>>> > It would also be more courteous to specify the package where you are
>>> > getting lmrob.
>>> >
>>> > >
>>> > > It would be great if anyone can help me out. Thanks in advance.
>>> > >
>>> > > Regards,
>>> > > Christien
>>> > >
>>> > >       [[alternative HTML version deleted]]
>>> >
>>> > This is a plain text mailing list although it doesn't seem to have
>>> created
>>> > problems this time.
>>> >
>>> > >
>>> > > ______________________________________________
>>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > > PLEASE do read the posting guide http://www.R-project.org/
>>> > posting-guide.html
>>> > > and provide commented, minimal, self-contained, reproducible code.
>>> >
>>> > David Winsemius
>>> > Alameda, CA, USA
>>> >
>>> > 'Any technology distinguishable from magic is insufficiently advanced.'
>>> >  -Gehm's Corollary to Clarke's Third Law
>>> >
>>> >
>>> >
>>> >
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From vanamelie at gmail.com  Sun Mar  4 13:10:28 2018
From: vanamelie at gmail.com (=?UTF-8?Q?Vaniscotte_Am=c3=a9lie?=)
Date: Sun, 4 Mar 2018 13:10:28 +0100
Subject: [R] Random effect in GAM (mgcv)
Message-ID: <6dc9c2e3-194f-695a-d8e3-12a46144a985@gmail.com>

Dear R users,


I am using the *mgcv package* to model the ratio of hectares of damaged 
culture by wild boar in french departments according to some 
environmental covariates. I used a _Beta distribution_ for the response.


For each department, we estimated the damaged in 3 different culture 
types (??Culture??). Our statistical individual are therefore the 
department crossed by the culture type.

Also, the department are clustered into landscape types (??Cluster??).

Since I want to get the effect of the Culture type and the Landscape, I 
keep those variables as fixed effects in the model.


Also, since we have 5 repetitions of the response and of some covariates 
measurement in time per department and culture type, I put a random 
effect on the Department per Culture type and the Year as fixed effect 
as well.


The model takes the form?:


*gam_tot <- gam (resp ~ Culture + Clust**er**:Culture + s(**Year**,k=4, 
by=Culture) + s(**X1**, by=Culture) + s(**X2**, by=Culture) + s(Depts, 
bs="re", by=Culture) *

*, family=betar(link="logit"),method="REML",data=data,select=FALSE)*


Then, I estimated the part of the model explained deviance provided by 
each covariate. For that, I run the model without the given covariate 
(keeping smooth parameters constant between models), and compute the 
difference in deviance between the Full model (with the given covariate) 
and the penalized model (without the given covariate):

(Full model Deviance ? Penalized model Deviance) / Full Model Deviance


 From that, I get a _huge proportion of Deviance explained by the random 
effect_ (Department) of about 30?%, while the others covariates 
explained less than 1?%.



*At this point, I have few questions?:*


*- Do you think my model formula is correct regarding my data and 
questions??*


*- Is my estimate of explained deviance correct??*

*In that case, how can I explain such a huge discrepancy between **the 
part of deviance explained by **random and fixed effects?? *


Thanks for your help,



Am?lie


	[[alternative HTML version deleted]]


From christienkerbert at gmail.com  Sun Mar  4 12:05:19 2018
From: christienkerbert at gmail.com (Christien Kerbert)
Date: Sun, 4 Mar 2018 12:05:19 +0100
Subject: [R] lmrob gives NA coefficients
In-Reply-To: <CAGgJW75qjA6HYPyRTqdRpRqcx8gPcLJ3E0F85guv1gLekhNhcg@mail.gmail.com>
References: <CACoCsecbONvDk1M4mhejP==m+WqRpJjJEWEBGhh1GJwaiBSE5A@mail.gmail.com>
 <9B84138C-D650-4276-BE01-2C3B5D337C2F@comcast.net>
 <CACoCseeU43ftRB1oyQokbV5+v34HA5kydae2RonOXw4XUEHA5Q@mail.gmail.com>
 <CAGgJW75qjA6HYPyRTqdRpRqcx8gPcLJ3E0F85guv1gLekhNhcg@mail.gmail.com>
Message-ID: <CACoCsefjLUJ=kVP9KRoGpqU0nmVrs4ogbYUZ1jXOUmiUYbXOJg@mail.gmail.com>

d is the number of observed variables (d = 3 in this example). n is the
number of observations.

2018-03-04 11:30 GMT+01:00 Eric Berger <ericjberger at gmail.com>:

> What is 'd'? What is 'n'?
>
>
> On Sun, Mar 4, 2018 at 12:14 PM, Christien Kerbert <
> christienkerbert at gmail.com> wrote:
>
>> Thanks for your reply.
>>
>> I use mvrnorm from the *MASS* package and lmrob from the *robustbase*
>> package.
>>
>> To further explain my data generating process, the idea is as follows. The
>> explanatory variables are generated my a multivariate normal distribution
>> where the covariance matrix of the variables is defined by Sigma in my
>> code, with ones on the diagonal and rho = 0.15 on the non-diagonal. Then y
>> is created by y = 1 - 2*x1 + 3*x3 + 4*x4 + error and the error term is
>> standard normal distributed.
>>
>> Hope this helps.
>>
>> Regards,
>> Christien
>>
>> In this section, we provide a simulation study to illustrate the
>> performance of four estimators, the (GLS), S, MM and MM ridge estimator
>> for
>> SUR model. This simulation process is executed to generate data for the
>> following equation   Where  In this simulation, we set the initial value
>>
>> for ?= [1,2,3] for k=3. The explanatory variables are generated by
>> multivariate normal distribution MNNk=3 (0,?x) where diag(?x)=1,
>> off-diag(?x)= ?X= 0.15 for low interdependency and ?x= 0.70 for high
>> interdependency. Where ?x is correlation between explanatory variables. We
>> chose two sample size 25 for small sample and 100 for large sample. The
>> specific error in equations ?i, i=1,2,?..,n, we generated by MVNk=3 (0,
>> ??), ?? the variance covariance matrix of errors, diag(??)= 1,
>> off-diag(??)= ??= 0.15. To investigate the robustness of the estimators
>> against outliers, we chosen different percentages of outliers ( 20%, 45%).
>> We choose shrink parameter in (12) by minimize the new robust Cross
>> Validation (CVMM) criterion which avoided
>>
>> 2018-03-04 0:52 GMT+01:00 David Winsemius <dwinsemius at comcast.net>:
>>
>> >
>> > > On Mar 3, 2018, at 3:04 PM, Christien Kerbert <
>> > christienkerbert at gmail.com> wrote:
>> > >
>> > > Dear list members,
>> > >
>> > > I want to perform an MM-regression. This seems an easy task using the
>> > > function lmrob(), however, this function provides me with NA
>> > coefficients.
>> > > My data generating process is as follows:
>> > >
>> > > rho <- 0.15  # low interdependency
>> > > Sigma <- matrix(rho, d, d); diag(Sigma) <- 1
>> > > x.clean <- mvrnorm(n, rep(0,d), Sigma)
>> >
>> > Which package are you using for mvrnorm?
>> >
>> > > beta <- c(1.0, 2.0, 3.0, 4.0)
>> > > error <- rnorm(n = n, mean = 0, sd = 1)
>> > > y <- as.data.frame(beta[1]*rep(1, n) + beta[2]*x.clean[,1] +
>> > > beta[3]*x.clean[,2] + beta[4]*x.clean[,3] + error)
>> > > xy.clean <- cbind(x.clean, y)
>> > > colnames(xy.clean) <- c("x1", "x2", "x3", "y")
>> > >
>> > > Then, I pass the following formula to lmrob: f <- y ~ x1 + x2 + x3
>> > >
>> > > Finally, I run lmrob: lmrob(f, data = data, cov = ".vcov.w")
>> > > and this results in NA coefficients.
>> >
>> > It would also be more courteous to specify the package where you are
>> > getting lmrob.
>> >
>> > >
>> > > It would be great if anyone can help me out. Thanks in advance.
>> > >
>> > > Regards,
>> > > Christien
>> > >
>> > >       [[alternative HTML version deleted]]
>> >
>> > This is a plain text mailing list although it doesn't seem to have
>> created
>> > problems this time.
>> >
>> > >
>> > > ______________________________________________
>> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > > https://stat.ethz.ch/mailman/listinfo/r-help
>> > > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > > and provide commented, minimal, self-contained, reproducible code.
>> >
>> > David Winsemius
>> > Alameda, CA, USA
>> >
>> > 'Any technology distinguishable from magic is insufficiently advanced.'
>> >  -Gehm's Corollary to Clarke's Third Law
>> >
>> >
>> >
>> >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Mar  4 16:37:18 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Mar 2018 07:37:18 -0800
Subject: [R] Random effect in GAM (mgcv)
In-Reply-To: <6dc9c2e3-194f-695a-d8e3-12a46144a985@gmail.com>
References: <6dc9c2e3-194f-695a-d8e3-12a46144a985@gmail.com>
Message-ID: <CAGxFJbRWvGjJbUVEwgYORweAQruOL3pWZb5ZM19rz371R78XYg@mail.gmail.com>

Statistics questions are largely off  topic on this list, although they do
sometimes intersect R programming issues, which are on topic. However, I
believe a statistics list like stats.stackexchange.com might be more
suitable for your query.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Mar 4, 2018 at 4:10 AM, Vaniscotte Am?lie <vanamelie at gmail.com>
wrote:

> Dear R users,
>
>
> I am using the *mgcv package* to model the ratio of hectares of damaged
> culture by wild boar in french departments according to some
> environmental covariates. I used a _Beta distribution_ for the response.
>
>
> For each department, we estimated the damaged in 3 different culture
> types (? Culture ?). Our statistical individual are therefore the
> department crossed by the culture type.
>
> Also, the department are clustered into landscape types (? Cluster ?).
>
> Since I want to get the effect of the Culture type and the Landscape, I
> keep those variables as fixed effects in the model.
>
>
> Also, since we have 5 repetitions of the response and of some covariates
> measurement in time per department and culture type, I put a random
> effect on the Department per Culture type and the Year as fixed effect
> as well.
>
>
> The model takes the form :
>
>
> *gam_tot <- gam (resp ~ Culture + Clust**er**:Culture + s(**Year**,k=4,
> by=Culture) + s(**X1**, by=Culture) + s(**X2**, by=Culture) + s(Depts,
> bs="re", by=Culture) *
>
> *, family=betar(link="logit"),method="REML",data=data,select=FALSE)*
>
>
> Then, I estimated the part of the model explained deviance provided by
> each covariate. For that, I run the model without the given covariate
> (keeping smooth parameters constant between models), and compute the
> difference in deviance between the Full model (with the given covariate)
> and the penalized model (without the given covariate):
>
> (Full model Deviance ? Penalized model Deviance) / Full Model Deviance
>
>
>  From that, I get a _huge proportion of Deviance explained by the random
> effect_ (Department) of about 30 %, while the others covariates
> explained less than 1 %.
>
>
>
> *At this point, I have few questions :*
>
>
> *- Do you think my model formula is correct regarding my data and
> questions ?*
>
>
> *- Is my estimate of explained deviance correct ?*
>
> *In that case, how can I explain such a huge discrepancy between **the
> part of deviance explained by **random and fixed effects ? *
>
>
> Thanks for your help,
>
>
>
> Am?lie
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sun Mar  4 16:39:29 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Mar 2018 21:09:29 +0530
Subject: [R] Change Function based on ifelse() condtion
Message-ID: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>

Hi again,

I am looking for some way to alternately use 2 related functions,
based on some ifelse() condition.

For example, I have 2 functions mclapply() and lapply()

However, mclapply() function has one extra parameter 'mc.cores' which
lapply doesnt not have.

I know when mc.cores = 1, these 2 functions are essentially same,
however I am looking for more general way to control them within
ifelse() constion

Can someone please help me how can I use them within ifelse() condition.

Thanks for your pointer


From murdoch.duncan at gmail.com  Sun Mar  4 17:04:18 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 4 Mar 2018 11:04:18 -0500
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
Message-ID: <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>

On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
> Hi again,
> 
> I am looking for some way to alternately use 2 related functions,
> based on some ifelse() condition.
> 
> For example, I have 2 functions mclapply() and lapply()
> 
> However, mclapply() function has one extra parameter 'mc.cores' which
> lapply doesnt not have.
> 
> I know when mc.cores = 1, these 2 functions are essentially same,
> however I am looking for more general way to control them within
> ifelse() constion
> 
> Can someone please help me how can I use them within ifelse() condition.

Don't.  ifelse() usually evaluates *both* the true and false values, and 
then selects entries from each.  Just use an if statement.

Duncan Murdoch


From bogaso.christofer at gmail.com  Sun Mar  4 17:38:56 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Mar 2018 22:08:56 +0530
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
Message-ID: <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>

Hi,

As an example, I want to create below kind of custom Function which
either be mclapply pr lapply

Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
if (Apply_MC) {
return(mclapply(X, FUN, ...))
} else {
if (any(names(list(...)) == 'mc.cores')) {
list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
}
return(lapply(X, FUN, ...))
}
}

However when Apply_MC = FALSE it generates below error saying :

  '...' used in an incorrect context


Appreciate if you can help me with the correct approach. Thanks,


On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
>>
>> Hi again,
>>
>> I am looking for some way to alternately use 2 related functions,
>> based on some ifelse() condition.
>>
>> For example, I have 2 functions mclapply() and lapply()
>>
>> However, mclapply() function has one extra parameter 'mc.cores' which
>> lapply doesnt not have.
>>
>> I know when mc.cores = 1, these 2 functions are essentially same,
>> however I am looking for more general way to control them within
>> ifelse() constion
>>
>> Can someone please help me how can I use them within ifelse() condition.
>
>
> Don't.  ifelse() usually evaluates *both* the true and false values, and
> then selects entries from each.  Just use an if statement.
>
> Duncan Murdoch


From ericjberger at gmail.com  Sun Mar  4 17:48:23 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 4 Mar 2018 18:48:23 +0200
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
Message-ID: <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>

Hi Christofer,
You cannot assign to list(...). You can do the following

myList <- list(...)[!names(list(...)) %in% 'mc.cores']

HTH,
Eric

On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> As an example, I want to create below kind of custom Function which
> either be mclapply pr lapply
>
> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
> if (Apply_MC) {
> return(mclapply(X, FUN, ...))
> } else {
> if (any(names(list(...)) == 'mc.cores')) {
> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
> }
> return(lapply(X, FUN, ...))
> }
> }
>
> However when Apply_MC = FALSE it generates below error saying :
>
>   '...' used in an incorrect context
>
>
> Appreciate if you can help me with the correct approach. Thanks,
>
>
> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
> >>
> >> Hi again,
> >>
> >> I am looking for some way to alternately use 2 related functions,
> >> based on some ifelse() condition.
> >>
> >> For example, I have 2 functions mclapply() and lapply()
> >>
> >> However, mclapply() function has one extra parameter 'mc.cores' which
> >> lapply doesnt not have.
> >>
> >> I know when mc.cores = 1, these 2 functions are essentially same,
> >> however I am looking for more general way to control them within
> >> ifelse() constion
> >>
> >> Can someone please help me how can I use them within ifelse() condition.
> >
> >
> > Don't.  ifelse() usually evaluates *both* the true and false values, and
> > then selects entries from each.  Just use an if statement.
> >
> > Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sun Mar  4 17:52:07 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Mar 2018 22:22:07 +0530
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
Message-ID: <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>

@Eric - with this approach I am getting below error :

Error in FUN(X[[i]], ...) : unused argument (list())

On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <ericjberger at gmail.com> wrote:
> Hi Christofer,
> You cannot assign to list(...). You can do the following
>
> myList <- list(...)[!names(list(...)) %in% 'mc.cores']
>
> HTH,
> Eric
>
> On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>>
>> Hi,
>>
>> As an example, I want to create below kind of custom Function which
>> either be mclapply pr lapply
>>
>> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
>> if (Apply_MC) {
>> return(mclapply(X, FUN, ...))
>> } else {
>> if (any(names(list(...)) == 'mc.cores')) {
>> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
>> }
>> return(lapply(X, FUN, ...))
>> }
>> }
>>
>> However when Apply_MC = FALSE it generates below error saying :
>>
>>   '...' used in an incorrect context
>>
>>
>> Appreciate if you can help me with the correct approach. Thanks,
>>
>>
>> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
>> >>
>> >> Hi again,
>> >>
>> >> I am looking for some way to alternately use 2 related functions,
>> >> based on some ifelse() condition.
>> >>
>> >> For example, I have 2 functions mclapply() and lapply()
>> >>
>> >> However, mclapply() function has one extra parameter 'mc.cores' which
>> >> lapply doesnt not have.
>> >>
>> >> I know when mc.cores = 1, these 2 functions are essentially same,
>> >> however I am looking for more general way to control them within
>> >> ifelse() constion
>> >>
>> >> Can someone please help me how can I use them within ifelse()
>> >> condition.
>> >
>> >
>> > Don't.  ifelse() usually evaluates *both* the true and false values, and
>> > then selects entries from each.  Just use an if statement.
>> >
>> > Duncan Murdoch
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From ericjberger at gmail.com  Sun Mar  4 18:07:25 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 4 Mar 2018 19:07:25 +0200
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
 <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
Message-ID: <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>

Hi Christofer,
Before you made the change that I suggested, your program was stopping at
the statement: list(...) = list(..) .etc
This means that it never tried to execute the statement:
return(lapply(X,FUN,...))
Now that you have made the change, it gets past the first statement and
tries to execute the statement: return(lapply(X,FUN,...)).
That attempt is generating the error message because whatever you are
passing in as the FUN argument is not expecting extra arguments.

HTH,
Eric


On Sun, Mar 4, 2018 at 6:52 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> @Eric - with this approach I am getting below error :
>
> Error in FUN(X[[i]], ...) : unused argument (list())
>
> On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <ericjberger at gmail.com>
> wrote:
> > Hi Christofer,
> > You cannot assign to list(...). You can do the following
> >
> > myList <- list(...)[!names(list(...)) %in% 'mc.cores']
> >
> > HTH,
> > Eric
> >
> > On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
> > <bogaso.christofer at gmail.com> wrote:
> >>
> >> Hi,
> >>
> >> As an example, I want to create below kind of custom Function which
> >> either be mclapply pr lapply
> >>
> >> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
> >> if (Apply_MC) {
> >> return(mclapply(X, FUN, ...))
> >> } else {
> >> if (any(names(list(...)) == 'mc.cores')) {
> >> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
> >> }
> >> return(lapply(X, FUN, ...))
> >> }
> >> }
> >>
> >> However when Apply_MC = FALSE it generates below error saying :
> >>
> >>   '...' used in an incorrect context
> >>
> >>
> >> Appreciate if you can help me with the correct approach. Thanks,
> >>
> >>
> >> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch <
> murdoch.duncan at gmail.com>
> >> wrote:
> >> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
> >> >>
> >> >> Hi again,
> >> >>
> >> >> I am looking for some way to alternately use 2 related functions,
> >> >> based on some ifelse() condition.
> >> >>
> >> >> For example, I have 2 functions mclapply() and lapply()
> >> >>
> >> >> However, mclapply() function has one extra parameter 'mc.cores' which
> >> >> lapply doesnt not have.
> >> >>
> >> >> I know when mc.cores = 1, these 2 functions are essentially same,
> >> >> however I am looking for more general way to control them within
> >> >> ifelse() constion
> >> >>
> >> >> Can someone please help me how can I use them within ifelse()
> >> >> condition.
> >> >
> >> >
> >> > Don't.  ifelse() usually evaluates *both* the true and false values,
> and
> >> > then selects entries from each.  Just use an if statement.
> >> >
> >> > Duncan Murdoch
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >
>

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sun Mar  4 18:11:09 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Mar 2018 22:41:09 +0530
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
 <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
 <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>
Message-ID: <CA+dpOJnJD4VPLMPGJaqy5kCLDXf1MDD-2bO9yjRO_kmS=vRMig@mail.gmail.com>

My modified function looks below :

Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
if (Apply_MC) {
return(mclapply(X, FUN, ...))
} else {
if (any(names(list(...)) == 'mc.cores')) {
myList = list(...)[!names(list(...)) %in% 'mc.cores']
}
return(lapply(X, FUN, myList))
}
}

Here, I am not passing ... anymore rather passing myList

On Sun, Mar 4, 2018 at 10:37 PM, Eric Berger <ericjberger at gmail.com> wrote:
> Hi Christofer,
> Before you made the change that I suggested, your program was stopping at
> the statement: list(...) = list(..) .etc
> This means that it never tried to execute the statement:
> return(lapply(X,FUN,...))
> Now that you have made the change, it gets past the first statement and
> tries to execute the statement: return(lapply(X,FUN,...)).
> That attempt is generating the error message because whatever you are
> passing in as the FUN argument is not expecting extra arguments.
>
> HTH,
> Eric
>
>
> On Sun, Mar 4, 2018 at 6:52 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>>
>> @Eric - with this approach I am getting below error :
>>
>> Error in FUN(X[[i]], ...) : unused argument (list())
>>
>> On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <ericjberger at gmail.com>
>> wrote:
>> > Hi Christofer,
>> > You cannot assign to list(...). You can do the following
>> >
>> > myList <- list(...)[!names(list(...)) %in% 'mc.cores']
>> >
>> > HTH,
>> > Eric
>> >
>> > On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
>> > <bogaso.christofer at gmail.com> wrote:
>> >>
>> >> Hi,
>> >>
>> >> As an example, I want to create below kind of custom Function which
>> >> either be mclapply pr lapply
>> >>
>> >> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
>> >> if (Apply_MC) {
>> >> return(mclapply(X, FUN, ...))
>> >> } else {
>> >> if (any(names(list(...)) == 'mc.cores')) {
>> >> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
>> >> }
>> >> return(lapply(X, FUN, ...))
>> >> }
>> >> }
>> >>
>> >> However when Apply_MC = FALSE it generates below error saying :
>> >>
>> >>   '...' used in an incorrect context
>> >>
>> >>
>> >> Appreciate if you can help me with the correct approach. Thanks,
>> >>
>> >>
>> >> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch
>> >> <murdoch.duncan at gmail.com>
>> >> wrote:
>> >> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
>> >> >>
>> >> >> Hi again,
>> >> >>
>> >> >> I am looking for some way to alternately use 2 related functions,
>> >> >> based on some ifelse() condition.
>> >> >>
>> >> >> For example, I have 2 functions mclapply() and lapply()
>> >> >>
>> >> >> However, mclapply() function has one extra parameter 'mc.cores'
>> >> >> which
>> >> >> lapply doesnt not have.
>> >> >>
>> >> >> I know when mc.cores = 1, these 2 functions are essentially same,
>> >> >> however I am looking for more general way to control them within
>> >> >> ifelse() constion
>> >> >>
>> >> >> Can someone please help me how can I use them within ifelse()
>> >> >> condition.
>> >> >
>> >> >
>> >> > Don't.  ifelse() usually evaluates *both* the true and false values,
>> >> > and
>> >> > then selects entries from each.  Just use an if statement.
>> >> >
>> >> > Duncan Murdoch
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>
>


From ericjberger at gmail.com  Sun Mar  4 18:15:02 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 4 Mar 2018 19:15:02 +0200
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CA+dpOJnJD4VPLMPGJaqy5kCLDXf1MDD-2bO9yjRO_kmS=vRMig@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
 <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
 <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>
 <CA+dpOJnJD4VPLMPGJaqy5kCLDXf1MDD-2bO9yjRO_kmS=vRMig@mail.gmail.com>
Message-ID: <CAGgJW76tPtKom3xzxsDv-+ee=6amDkOXEjKrt2_ZtrcVOJLVyw@mail.gmail.com>

That's fine. The issue is how you called Lapply_me(). What did you pass as
the argument to FUN?
And if you did not pass anything that how is FUN declared?
You have not shown that in your email.




On Sun, Mar 4, 2018 at 7:11 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> My modified function looks below :
>
> Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
> if (Apply_MC) {
> return(mclapply(X, FUN, ...))
> } else {
> if (any(names(list(...)) == 'mc.cores')) {
> myList = list(...)[!names(list(...)) %in% 'mc.cores']
> }
> return(lapply(X, FUN, myList))
> }
> }
>
> Here, I am not passing ... anymore rather passing myList
>
> On Sun, Mar 4, 2018 at 10:37 PM, Eric Berger <ericjberger at gmail.com>
> wrote:
> > Hi Christofer,
> > Before you made the change that I suggested, your program was stopping at
> > the statement: list(...) = list(..) .etc
> > This means that it never tried to execute the statement:
> > return(lapply(X,FUN,...))
> > Now that you have made the change, it gets past the first statement and
> > tries to execute the statement: return(lapply(X,FUN,...)).
> > That attempt is generating the error message because whatever you are
> > passing in as the FUN argument is not expecting extra arguments.
> >
> > HTH,
> > Eric
> >
> >
> > On Sun, Mar 4, 2018 at 6:52 PM, Christofer Bogaso
> > <bogaso.christofer at gmail.com> wrote:
> >>
> >> @Eric - with this approach I am getting below error :
> >>
> >> Error in FUN(X[[i]], ...) : unused argument (list())
> >>
> >> On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <ericjberger at gmail.com>
> >> wrote:
> >> > Hi Christofer,
> >> > You cannot assign to list(...). You can do the following
> >> >
> >> > myList <- list(...)[!names(list(...)) %in% 'mc.cores']
> >> >
> >> > HTH,
> >> > Eric
> >> >
> >> > On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
> >> > <bogaso.christofer at gmail.com> wrote:
> >> >>
> >> >> Hi,
> >> >>
> >> >> As an example, I want to create below kind of custom Function which
> >> >> either be mclapply pr lapply
> >> >>
> >> >> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
> >> >> if (Apply_MC) {
> >> >> return(mclapply(X, FUN, ...))
> >> >> } else {
> >> >> if (any(names(list(...)) == 'mc.cores')) {
> >> >> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
> >> >> }
> >> >> return(lapply(X, FUN, ...))
> >> >> }
> >> >> }
> >> >>
> >> >> However when Apply_MC = FALSE it generates below error saying :
> >> >>
> >> >>   '...' used in an incorrect context
> >> >>
> >> >>
> >> >> Appreciate if you can help me with the correct approach. Thanks,
> >> >>
> >> >>
> >> >> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch
> >> >> <murdoch.duncan at gmail.com>
> >> >> wrote:
> >> >> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
> >> >> >>
> >> >> >> Hi again,
> >> >> >>
> >> >> >> I am looking for some way to alternately use 2 related functions,
> >> >> >> based on some ifelse() condition.
> >> >> >>
> >> >> >> For example, I have 2 functions mclapply() and lapply()
> >> >> >>
> >> >> >> However, mclapply() function has one extra parameter 'mc.cores'
> >> >> >> which
> >> >> >> lapply doesnt not have.
> >> >> >>
> >> >> >> I know when mc.cores = 1, these 2 functions are essentially same,
> >> >> >> however I am looking for more general way to control them within
> >> >> >> ifelse() constion
> >> >> >>
> >> >> >> Can someone please help me how can I use them within ifelse()
> >> >> >> condition.
> >> >> >
> >> >> >
> >> >> > Don't.  ifelse() usually evaluates *both* the true and false
> values,
> >> >> > and
> >> >> > then selects entries from each.  Just use an if statement.
> >> >> >
> >> >> > Duncan Murdoch
> >> >>
> >> >> ______________________________________________
> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> PLEASE do read the posting guide
> >> >> http://www.R-project.org/posting-guide.html
> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> >
> >
> >
>

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sun Mar  4 18:21:44 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Mar 2018 22:51:44 +0530
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CAGgJW76tPtKom3xzxsDv-+ee=6amDkOXEjKrt2_ZtrcVOJLVyw@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
 <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
 <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>
 <CA+dpOJnJD4VPLMPGJaqy5kCLDXf1MDD-2bO9yjRO_kmS=vRMig@mail.gmail.com>
 <CAGgJW76tPtKom3xzxsDv-+ee=6amDkOXEjKrt2_ZtrcVOJLVyw@mail.gmail.com>
Message-ID: <CA+dpOJkHmVb3KwjEjHj=HwKrG=Qr4nx-97doNdLPDmkoK1esLQ@mail.gmail.com>

Below is my full implementation (tried to make it simple as for demonstration)

Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
if (Apply_MC) {
return(mclapply(X, FUN, ...))
} else {
if (any(names(list(...)) == 'mc.cores')) {
myList = list(...)[!names(list(...)) %in% 'mc.cores']
}
return(lapply(X, FUN, myList))
}
}


Lapply_me(as.list(1:4), function(xx) {
if (xx == 1) return('a')
if (xx == 2) return('b')
if (xx == 3) return('c')
if (xx == 4) return('d')
}, Apply_MC = FALSE, mc.cores = 2)

Error message :

Error in FUN(X[[i]], ...) : unused argument (list())

Kindly note that, with Apply_MC = TRUE, it is working perfectly.

On Sun, Mar 4, 2018 at 10:45 PM, Eric Berger <ericjberger at gmail.com> wrote:
> That's fine. The issue is how you called Lapply_me(). What did you pass as
> the argument to FUN?
> And if you did not pass anything that how is FUN declared?
> You have not shown that in your email.
>
>
>
>
> On Sun, Mar 4, 2018 at 7:11 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>>
>> My modified function looks below :
>>
>> Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
>> if (Apply_MC) {
>> return(mclapply(X, FUN, ...))
>> } else {
>> if (any(names(list(...)) == 'mc.cores')) {
>> myList = list(...)[!names(list(...)) %in% 'mc.cores']
>> }
>> return(lapply(X, FUN, myList))
>> }
>> }
>>
>> Here, I am not passing ... anymore rather passing myList
>>
>> On Sun, Mar 4, 2018 at 10:37 PM, Eric Berger <ericjberger at gmail.com>
>> wrote:
>> > Hi Christofer,
>> > Before you made the change that I suggested, your program was stopping
>> > at
>> > the statement: list(...) = list(..) .etc
>> > This means that it never tried to execute the statement:
>> > return(lapply(X,FUN,...))
>> > Now that you have made the change, it gets past the first statement and
>> > tries to execute the statement: return(lapply(X,FUN,...)).
>> > That attempt is generating the error message because whatever you are
>> > passing in as the FUN argument is not expecting extra arguments.
>> >
>> > HTH,
>> > Eric
>> >
>> >
>> > On Sun, Mar 4, 2018 at 6:52 PM, Christofer Bogaso
>> > <bogaso.christofer at gmail.com> wrote:
>> >>
>> >> @Eric - with this approach I am getting below error :
>> >>
>> >> Error in FUN(X[[i]], ...) : unused argument (list())
>> >>
>> >> On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <ericjberger at gmail.com>
>> >> wrote:
>> >> > Hi Christofer,
>> >> > You cannot assign to list(...). You can do the following
>> >> >
>> >> > myList <- list(...)[!names(list(...)) %in% 'mc.cores']
>> >> >
>> >> > HTH,
>> >> > Eric
>> >> >
>> >> > On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
>> >> > <bogaso.christofer at gmail.com> wrote:
>> >> >>
>> >> >> Hi,
>> >> >>
>> >> >> As an example, I want to create below kind of custom Function which
>> >> >> either be mclapply pr lapply
>> >> >>
>> >> >> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
>> >> >> if (Apply_MC) {
>> >> >> return(mclapply(X, FUN, ...))
>> >> >> } else {
>> >> >> if (any(names(list(...)) == 'mc.cores')) {
>> >> >> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
>> >> >> }
>> >> >> return(lapply(X, FUN, ...))
>> >> >> }
>> >> >> }
>> >> >>
>> >> >> However when Apply_MC = FALSE it generates below error saying :
>> >> >>
>> >> >>   '...' used in an incorrect context
>> >> >>
>> >> >>
>> >> >> Appreciate if you can help me with the correct approach. Thanks,
>> >> >>
>> >> >>
>> >> >> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch
>> >> >> <murdoch.duncan at gmail.com>
>> >> >> wrote:
>> >> >> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
>> >> >> >>
>> >> >> >> Hi again,
>> >> >> >>
>> >> >> >> I am looking for some way to alternately use 2 related functions,
>> >> >> >> based on some ifelse() condition.
>> >> >> >>
>> >> >> >> For example, I have 2 functions mclapply() and lapply()
>> >> >> >>
>> >> >> >> However, mclapply() function has one extra parameter 'mc.cores'
>> >> >> >> which
>> >> >> >> lapply doesnt not have.
>> >> >> >>
>> >> >> >> I know when mc.cores = 1, these 2 functions are essentially same,
>> >> >> >> however I am looking for more general way to control them within
>> >> >> >> ifelse() constion
>> >> >> >>
>> >> >> >> Can someone please help me how can I use them within ifelse()
>> >> >> >> condition.
>> >> >> >
>> >> >> >
>> >> >> > Don't.  ifelse() usually evaluates *both* the true and false
>> >> >> > values,
>> >> >> > and
>> >> >> > then selects entries from each.  Just use an if statement.
>> >> >> >
>> >> >> > Duncan Murdoch
>> >> >>
>> >> >> ______________________________________________
>> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> PLEASE do read the posting guide
>> >> >> http://www.R-project.org/posting-guide.html
>> >> >> and provide commented, minimal, self-contained, reproducible code.
>> >> >
>> >> >
>> >
>> >
>
>


From dwinsemius at comcast.net  Sun Mar  4 18:27:47 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 4 Mar 2018 09:27:47 -0800
Subject: [R] Random effect in GAM (mgcv)
In-Reply-To: <CAGxFJbRWvGjJbUVEwgYORweAQruOL3pWZb5ZM19rz371R78XYg@mail.gmail.com>
References: <6dc9c2e3-194f-695a-d8e3-12a46144a985@gmail.com>
 <CAGxFJbRWvGjJbUVEwgYORweAQruOL3pWZb5ZM19rz371R78XYg@mail.gmail.com>
Message-ID: <E14A1790-2CDD-4DCC-9DF2-0BCDFFFE9337@comcast.net>


> On Mar 4, 2018, at 7:37 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> Statistics questions are largely off  topic on this list, although they do
> sometimes intersect R programming issues, which are on topic. However, I
> believe a statistics list like stats.stackexchange.com might be more
> suitable for your query.
> 
> Cheers,
> Bert

What Bert says is certainly true of rhelp, but is not the case for the R mixed models mailing list. I think you should repost your question there. You should first read their mailing list info and configure you mail client to send plain text. Your current posting is marred by the presence of extraneous symbols that are the plain-text translation of HTML formatting. Those doubles asterisks are surely not in your formula. Furthermore, I for one do not see how one could determine "correctness" of an answer without access to the data.

Best of luck;
David.
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Sun, Mar 4, 2018 at 4:10 AM, Vaniscotte Am?lie <vanamelie at gmail.com>
> wrote:
> 
>> Dear R users,
>> 
>> 
>> I am using the *mgcv package* to model the ratio of hectares of damaged
>> culture by wild boar in french departments according to some
>> environmental covariates. I used a _Beta distribution_ for the response.
>> 
>> 
>> For each department, we estimated the damaged in 3 different culture
>> types (? Culture ?). Our statistical individual are therefore the
>> department crossed by the culture type.
>> 
>> Also, the department are clustered into landscape types (? Cluster ?).
>> 
>> Since I want to get the effect of the Culture type and the Landscape, I
>> keep those variables as fixed effects in the model.
>> 
>> 
>> Also, since we have 5 repetitions of the response and of some covariates
>> measurement in time per department and culture type, I put a random
>> effect on the Department per Culture type and the Year as fixed effect
>> as well.
>> 
>> 
>> The model takes the form :
>> 
>> 
>> *gam_tot <- gam (resp ~ Culture + Clust**er**:Culture + s(**Year**,k=4,
>> by=Culture) + s(**X1**, by=Culture) + s(**X2**, by=Culture) + s(Depts,
>> bs="re", by=Culture) *
>> 
>> *, family=betar(link="logit"),method="REML",data=data,select=FALSE)*
>> 
>> 
>> Then, I estimated the part of the model explained deviance provided by
>> each covariate. For that, I run the model without the given covariate
>> (keeping smooth parameters constant between models), and compute the
>> difference in deviance between the Full model (with the given covariate)
>> and the penalized model (without the given covariate):
>> 
>> (Full model Deviance ? Penalized model Deviance) / Full Model Deviance
>> 
>> 
>> From that, I get a _huge proportion of Deviance explained by the random
>> effect_ (Department) of about 30 %, while the others covariates
>> explained less than 1 %.
>> 
>> 
>> 
>> *At this point, I have few questions :*
>> 
>> 
>> *- Do you think my model formula is correct regarding my data and
>> questions ?*
>> 
>> 
>> *- Is my estimate of explained deviance correct ?*
>> 
>> *In that case, how can I explain such a huge discrepancy between **the
>> part of deviance explained by **random and fixed effects ? *
>> 
>> 
>> Thanks for your help,
>> 
>> 
>> 
>> Am?lie
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From ericjberger at gmail.com  Sun Mar  4 18:58:14 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Sun, 4 Mar 2018 19:58:14 +0200
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CA+dpOJkHmVb3KwjEjHj=HwKrG=Qr4nx-97doNdLPDmkoK1esLQ@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
 <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
 <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>
 <CA+dpOJnJD4VPLMPGJaqy5kCLDXf1MDD-2bO9yjRO_kmS=vRMig@mail.gmail.com>
 <CAGgJW76tPtKom3xzxsDv-+ee=6amDkOXEjKrt2_ZtrcVOJLVyw@mail.gmail.com>
 <CA+dpOJkHmVb3KwjEjHj=HwKrG=Qr4nx-97doNdLPDmkoK1esLQ@mail.gmail.com>
Message-ID: <CAGgJW76uHbps5X+VbHPUR5zbpoomOLFeqhrAFyf2=w+4beEdqw@mail.gmail.com>

The reason that it works for Apply_MC=TRUE is that in that case you call
mclapply(X,FUN,...) and
the mclapply() function strips off the mc.cores argument from the "..."
list before calling FUN, so FUN is being called with zero arguments,
exactly as it is declared.

A quick workaround is to change the line

Lapply_me(as.list(1:4), function(xx) {

to

Lapply_me(as.list(1:4), function(xx,dummyList) {

HTH,
Eric


On Sun, Mar 4, 2018 at 7:21 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Below is my full implementation (tried to make it simple as for
> demonstration)
>
> Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
> if (Apply_MC) {
> return(mclapply(X, FUN, ...))
> } else {
> if (any(names(list(...)) == 'mc.cores')) {
> myList = list(...)[!names(list(...)) %in% 'mc.cores']
> }
> return(lapply(X, FUN, myList))
> }
> }
>
>
> Lapply_me(as.list(1:4), function(xx) {
> if (xx == 1) return('a')
> if (xx == 2) return('b')
> if (xx == 3) return('c')
> if (xx == 4) return('d')
> }, Apply_MC = FALSE, mc.cores = 2)
>
> Error message :
>
> Error in FUN(X[[i]], ...) : unused argument (list())
>
> Kindly note that, with Apply_MC = TRUE, it is working perfectly.
>
> On Sun, Mar 4, 2018 at 10:45 PM, Eric Berger <ericjberger at gmail.com>
> wrote:
> > That's fine. The issue is how you called Lapply_me(). What did you pass
> as
> > the argument to FUN?
> > And if you did not pass anything that how is FUN declared?
> > You have not shown that in your email.
> >
> >
> >
> >
> > On Sun, Mar 4, 2018 at 7:11 PM, Christofer Bogaso
> > <bogaso.christofer at gmail.com> wrote:
> >>
> >> My modified function looks below :
> >>
> >> Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
> >> if (Apply_MC) {
> >> return(mclapply(X, FUN, ...))
> >> } else {
> >> if (any(names(list(...)) == 'mc.cores')) {
> >> myList = list(...)[!names(list(...)) %in% 'mc.cores']
> >> }
> >> return(lapply(X, FUN, myList))
> >> }
> >> }
> >>
> >> Here, I am not passing ... anymore rather passing myList
> >>
> >> On Sun, Mar 4, 2018 at 10:37 PM, Eric Berger <ericjberger at gmail.com>
> >> wrote:
> >> > Hi Christofer,
> >> > Before you made the change that I suggested, your program was stopping
> >> > at
> >> > the statement: list(...) = list(..) .etc
> >> > This means that it never tried to execute the statement:
> >> > return(lapply(X,FUN,...))
> >> > Now that you have made the change, it gets past the first statement
> and
> >> > tries to execute the statement: return(lapply(X,FUN,...)).
> >> > That attempt is generating the error message because whatever you are
> >> > passing in as the FUN argument is not expecting extra arguments.
> >> >
> >> > HTH,
> >> > Eric
> >> >
> >> >
> >> > On Sun, Mar 4, 2018 at 6:52 PM, Christofer Bogaso
> >> > <bogaso.christofer at gmail.com> wrote:
> >> >>
> >> >> @Eric - with this approach I am getting below error :
> >> >>
> >> >> Error in FUN(X[[i]], ...) : unused argument (list())
> >> >>
> >> >> On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <ericjberger at gmail.com>
> >> >> wrote:
> >> >> > Hi Christofer,
> >> >> > You cannot assign to list(...). You can do the following
> >> >> >
> >> >> > myList <- list(...)[!names(list(...)) %in% 'mc.cores']
> >> >> >
> >> >> > HTH,
> >> >> > Eric
> >> >> >
> >> >> > On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
> >> >> > <bogaso.christofer at gmail.com> wrote:
> >> >> >>
> >> >> >> Hi,
> >> >> >>
> >> >> >> As an example, I want to create below kind of custom Function
> which
> >> >> >> either be mclapply pr lapply
> >> >> >>
> >> >> >> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
> >> >> >> if (Apply_MC) {
> >> >> >> return(mclapply(X, FUN, ...))
> >> >> >> } else {
> >> >> >> if (any(names(list(...)) == 'mc.cores')) {
> >> >> >> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
> >> >> >> }
> >> >> >> return(lapply(X, FUN, ...))
> >> >> >> }
> >> >> >> }
> >> >> >>
> >> >> >> However when Apply_MC = FALSE it generates below error saying :
> >> >> >>
> >> >> >>   '...' used in an incorrect context
> >> >> >>
> >> >> >>
> >> >> >> Appreciate if you can help me with the correct approach. Thanks,
> >> >> >>
> >> >> >>
> >> >> >> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch
> >> >> >> <murdoch.duncan at gmail.com>
> >> >> >> wrote:
> >> >> >> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
> >> >> >> >>
> >> >> >> >> Hi again,
> >> >> >> >>
> >> >> >> >> I am looking for some way to alternately use 2 related
> functions,
> >> >> >> >> based on some ifelse() condition.
> >> >> >> >>
> >> >> >> >> For example, I have 2 functions mclapply() and lapply()
> >> >> >> >>
> >> >> >> >> However, mclapply() function has one extra parameter 'mc.cores'
> >> >> >> >> which
> >> >> >> >> lapply doesnt not have.
> >> >> >> >>
> >> >> >> >> I know when mc.cores = 1, these 2 functions are essentially
> same,
> >> >> >> >> however I am looking for more general way to control them
> within
> >> >> >> >> ifelse() constion
> >> >> >> >>
> >> >> >> >> Can someone please help me how can I use them within ifelse()
> >> >> >> >> condition.
> >> >> >> >
> >> >> >> >
> >> >> >> > Don't.  ifelse() usually evaluates *both* the true and false
> >> >> >> > values,
> >> >> >> > and
> >> >> >> > then selects entries from each.  Just use an if statement.
> >> >> >> >
> >> >> >> > Duncan Murdoch
> >> >> >>
> >> >> >> ______________________________________________
> >> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> >> PLEASE do read the posting guide
> >> >> >> http://www.R-project.org/posting-guide.html
> >> >> >> and provide commented, minimal, self-contained, reproducible code.
> >> >> >
> >> >> >
> >> >
> >> >
> >
> >
>

	[[alternative HTML version deleted]]


From bogaso.christofer at gmail.com  Sun Mar  4 19:18:21 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Sun, 4 Mar 2018 23:48:21 +0530
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CAGgJW76uHbps5X+VbHPUR5zbpoomOLFeqhrAFyf2=w+4beEdqw@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
 <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
 <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>
 <CA+dpOJnJD4VPLMPGJaqy5kCLDXf1MDD-2bO9yjRO_kmS=vRMig@mail.gmail.com>
 <CAGgJW76tPtKom3xzxsDv-+ee=6amDkOXEjKrt2_ZtrcVOJLVyw@mail.gmail.com>
 <CA+dpOJkHmVb3KwjEjHj=HwKrG=Qr4nx-97doNdLPDmkoK1esLQ@mail.gmail.com>
 <CAGgJW76uHbps5X+VbHPUR5zbpoomOLFeqhrAFyf2=w+4beEdqw@mail.gmail.com>
Message-ID: <CA+dpOJkTY6WcXPdZfThGwCQy0Ey0Q0asFvRyZG5oBBs8O8747A@mail.gmail.com>

Thanks Eric, this is working.

On Sun, Mar 4, 2018 at 11:28 PM, Eric Berger <ericjberger at gmail.com> wrote:
> The reason that it works for Apply_MC=TRUE is that in that case you call
> mclapply(X,FUN,...) and
> the mclapply() function strips off the mc.cores argument from the "..." list
> before calling FUN, so FUN is being called with zero arguments, exactly as
> it is declared.
>
> A quick workaround is to change the line
>
> Lapply_me(as.list(1:4), function(xx) {
>
> to
>
> Lapply_me(as.list(1:4), function(xx,dummyList) {
>
> HTH,
> Eric
>
>
> On Sun, Mar 4, 2018 at 7:21 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>>
>> Below is my full implementation (tried to make it simple as for
>> demonstration)
>>
>> Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
>> if (Apply_MC) {
>> return(mclapply(X, FUN, ...))
>> } else {
>> if (any(names(list(...)) == 'mc.cores')) {
>> myList = list(...)[!names(list(...)) %in% 'mc.cores']
>> }
>> return(lapply(X, FUN, myList))
>> }
>> }
>>
>>
>> Lapply_me(as.list(1:4), function(xx) {
>> if (xx == 1) return('a')
>> if (xx == 2) return('b')
>> if (xx == 3) return('c')
>> if (xx == 4) return('d')
>> }, Apply_MC = FALSE, mc.cores = 2)
>>
>> Error message :
>>
>> Error in FUN(X[[i]], ...) : unused argument (list())
>>
>> Kindly note that, with Apply_MC = TRUE, it is working perfectly.
>>
>> On Sun, Mar 4, 2018 at 10:45 PM, Eric Berger <ericjberger at gmail.com>
>> wrote:
>> > That's fine. The issue is how you called Lapply_me(). What did you pass
>> > as
>> > the argument to FUN?
>> > And if you did not pass anything that how is FUN declared?
>> > You have not shown that in your email.
>> >
>> >
>> >
>> >
>> > On Sun, Mar 4, 2018 at 7:11 PM, Christofer Bogaso
>> > <bogaso.christofer at gmail.com> wrote:
>> >>
>> >> My modified function looks below :
>> >>
>> >> Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
>> >> if (Apply_MC) {
>> >> return(mclapply(X, FUN, ...))
>> >> } else {
>> >> if (any(names(list(...)) == 'mc.cores')) {
>> >> myList = list(...)[!names(list(...)) %in% 'mc.cores']
>> >> }
>> >> return(lapply(X, FUN, myList))
>> >> }
>> >> }
>> >>
>> >> Here, I am not passing ... anymore rather passing myList
>> >>
>> >> On Sun, Mar 4, 2018 at 10:37 PM, Eric Berger <ericjberger at gmail.com>
>> >> wrote:
>> >> > Hi Christofer,
>> >> > Before you made the change that I suggested, your program was
>> >> > stopping
>> >> > at
>> >> > the statement: list(...) = list(..) .etc
>> >> > This means that it never tried to execute the statement:
>> >> > return(lapply(X,FUN,...))
>> >> > Now that you have made the change, it gets past the first statement
>> >> > and
>> >> > tries to execute the statement: return(lapply(X,FUN,...)).
>> >> > That attempt is generating the error message because whatever you are
>> >> > passing in as the FUN argument is not expecting extra arguments.
>> >> >
>> >> > HTH,
>> >> > Eric
>> >> >
>> >> >
>> >> > On Sun, Mar 4, 2018 at 6:52 PM, Christofer Bogaso
>> >> > <bogaso.christofer at gmail.com> wrote:
>> >> >>
>> >> >> @Eric - with this approach I am getting below error :
>> >> >>
>> >> >> Error in FUN(X[[i]], ...) : unused argument (list())
>> >> >>
>> >> >> On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <ericjberger at gmail.com>
>> >> >> wrote:
>> >> >> > Hi Christofer,
>> >> >> > You cannot assign to list(...). You can do the following
>> >> >> >
>> >> >> > myList <- list(...)[!names(list(...)) %in% 'mc.cores']
>> >> >> >
>> >> >> > HTH,
>> >> >> > Eric
>> >> >> >
>> >> >> > On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
>> >> >> > <bogaso.christofer at gmail.com> wrote:
>> >> >> >>
>> >> >> >> Hi,
>> >> >> >>
>> >> >> >> As an example, I want to create below kind of custom Function
>> >> >> >> which
>> >> >> >> either be mclapply pr lapply
>> >> >> >>
>> >> >> >> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
>> >> >> >> if (Apply_MC) {
>> >> >> >> return(mclapply(X, FUN, ...))
>> >> >> >> } else {
>> >> >> >> if (any(names(list(...)) == 'mc.cores')) {
>> >> >> >> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
>> >> >> >> }
>> >> >> >> return(lapply(X, FUN, ...))
>> >> >> >> }
>> >> >> >> }
>> >> >> >>
>> >> >> >> However when Apply_MC = FALSE it generates below error saying :
>> >> >> >>
>> >> >> >>   '...' used in an incorrect context
>> >> >> >>
>> >> >> >>
>> >> >> >> Appreciate if you can help me with the correct approach. Thanks,
>> >> >> >>
>> >> >> >>
>> >> >> >> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch
>> >> >> >> <murdoch.duncan at gmail.com>
>> >> >> >> wrote:
>> >> >> >> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
>> >> >> >> >>
>> >> >> >> >> Hi again,
>> >> >> >> >>
>> >> >> >> >> I am looking for some way to alternately use 2 related
>> >> >> >> >> functions,
>> >> >> >> >> based on some ifelse() condition.
>> >> >> >> >>
>> >> >> >> >> For example, I have 2 functions mclapply() and lapply()
>> >> >> >> >>
>> >> >> >> >> However, mclapply() function has one extra parameter
>> >> >> >> >> 'mc.cores'
>> >> >> >> >> which
>> >> >> >> >> lapply doesnt not have.
>> >> >> >> >>
>> >> >> >> >> I know when mc.cores = 1, these 2 functions are essentially
>> >> >> >> >> same,
>> >> >> >> >> however I am looking for more general way to control them
>> >> >> >> >> within
>> >> >> >> >> ifelse() constion
>> >> >> >> >>
>> >> >> >> >> Can someone please help me how can I use them within ifelse()
>> >> >> >> >> condition.
>> >> >> >> >
>> >> >> >> >
>> >> >> >> > Don't.  ifelse() usually evaluates *both* the true and false
>> >> >> >> > values,
>> >> >> >> > and
>> >> >> >> > then selects entries from each.  Just use an if statement.
>> >> >> >> >
>> >> >> >> > Duncan Murdoch
>> >> >> >>
>> >> >> >> ______________________________________________
>> >> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> >> >> PLEASE do read the posting guide
>> >> >> >> http://www.R-project.org/posting-guide.html
>> >> >> >> and provide commented, minimal, self-contained, reproducible
>> >> >> >> code.
>> >> >> >
>> >> >> >
>> >> >
>> >> >
>> >
>> >
>
>


From pgilbert902 at gmail.com  Sun Mar  4 19:18:32 2018
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sun, 4 Mar 2018 13:18:32 -0500
Subject: [R] Random Seed Location
In-Reply-To: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
References: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
Message-ID: <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>

On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
wrote:

(Sorry to be a bit slow responding.)

You have not supplied a complete example, which would be good in this 
case because what you are suggesting could be a serious bug in R or a 
package. Serious journals require reproducibility these days. For 
example, JSS is very clear on this point.

To your question
 > My question simply is:  should the location of the set.seed command 
matter,
 > provided that it is applied before any commands which involve randomness
 > (such as partitioning)?

the answer is no, it should not matter. But the proviso is important.

You can determine where things are messing up using something like

  set.seed(654321)
  zk <- RNGkind()        # [1] "Mersenne-Twister" "Inversion"
  zk
  z <- runif(2)
  z
  set.seed(654321)

  #  install.packages(c('caret', 'ggplot2', 'e1071'))
  library(caret)
  all(runif(2)  == z)   # should be true but it is not always

  set.seed(654321)
  library(ggplot2)
  all(runif(2)  == z)   # should be true

  set.seed(654321)
  library(e1071)
  all(runif(2)  == z)   # should be true

  all(RNGkind() == zk)  # should be true

On my computer package caret seems to sometimes, but not always, do 
something that advances or changes the RNG. So you will need to set the 
seed after that package is loaded if you want reproducibility.

As Bill Dunlap points out, parallel can introduce much more complicated 
issues. If you are in fact using parallel then we really need a new 
thread with a better subject line, and the discussion will get much messier.

The short answer is that, yes you should be able to get reproducible 
results with parallel computing. If you cannot then you are almost 
certainly doing something wrong. To publish you really must have 
reproducible results.

In the example that Bill gave, I think the problem is that set.seed() 
only resets the seed in the main thread, the nodes continue to operate 
with unreset RNG. To demonstrate this to yourself you can do

  library(parallel)
  cl <- parallel::makeCluster(3)
  parallel::clusterCall(cl, function()set.seed(100))
  parallel::clusterCall(cl, function()RNGkind())
  parallel::clusterCall(cl, function()runif(2)) # similar result from 
all nodes
                                                # [1] 0.3077661 0.2576725

However, do *NOT* do that in real work. You will be getting the same RNG 
stream from each node. If you are using random numbers and parallel you 
need to read a lot more, and probably consider a variant of the 
"L'Ecuyer" generator or something designed for parallel computing.

One special point I will mention because it does not seem to be widely
appreciated: the number of nodes affects the random stream, so recording 
the number of compute nodes along with the RNG and seed information is 
important for reproducible results. This has the unfortunate consequence 
that an experiment cannot be reproduced on a larger cluster. (If anyone 
knows differently I would very much like to hear.)

Paul Gilbert


 > Hi all,
 >
 > For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
 > different results (e.g., error rates, classification probabilities) from
 > run
 > to run even though I am using the same random seed.
 >
 > Nothing else (input-wise) is changing, but my results are somewhat
 > different
 > from run to run.  The only randomness should be in the partitioning, 
and I
 > have set the seed before this point.
 >
 > My question simply is:  should the location of the set.seed command 
matter,
 > provided that it is applied before any commands which involve randomness
 > (such as partitioning)?
 >
 > If you need to see the code, it is below:
 >
 > Thank you,
 > Gary
 >
 >
 > A.      Separate the original (in-sample) data from the new 
(out-of-sample)
 > data.  Set a random seed.
 >
 >> InvestTech <- as.data.frame(InvestTechRevised)
 >> outOfSample <- InvestTech[5001:nrow(InvestTech), ]
 >> InvestTech <- InvestTech[1:5000, ]
 >> set.seed(654321)
 >
 > B.      Install and load the caret, ggplot2 and e1071 packages.
 >
 >> install.packages(?caret?)
 >> install.packages(?ggplot2?)
 >> install.packages(?e1071?)
 >> library(caret)
 >> library(ggplot2)
 >> library(e1071)
 >
 > C.      Bin the predictor variables with approximately equal counts using
 > the cut_number function from the ggplot2 package.  We will use 20 bins.
 >
 >> InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
 >> InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
 >> outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
 >> outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
 >
 > D.      Partition the original (in-sample) data into 60% training and 40%
 > validation sets.
 >
 >> n <- nrow(InvestTech)
 >> train <- sample(1:n, size = 0.6 * n, replace = FALSE)
 >> InvestTechTrain <- InvestTech[train, ]
 >> InvestTechVal <- InvestTech[-train, ]
 >
 > E.      Use the naiveBayes function in the e1071 package to fit the 
model.
 >
 >> model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data = 
InvestTechTrain)
 >> prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
 >> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
 >
 > F.      Use the confusionMatrix function in the caret package to 
output the
 > confusion matrix.
 >
 >> confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
 > ?everything?, positive = ?1?)
 >> accuracy <- confMtr$overall[1]
 >> valError <- 1 ? accuracy
 >> confMtr
 >
 > G.      Classify the 18 new (out-of-sample) readers using the following
 > code.
 >> prob <- predict(model, newdata = outOfSample, type = ?raw?)
 >> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
 >> cbind(pred, prob, outOfSample[, -3])
 >
 >
 >


If your computations involve the parallel package then set.seed(seed)
may not produce repeatable results.  E.g.,

 > cl <- parallel::makeCluster(3)  # Create cluster with 3 nodes on local
host
 > set.seed(100); runif(2)
[1] 0.3077661 0.2576725
 > parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
          [,1]     [,2]     [,3]
[1,] 101.7779 102.5308 103.3459
[2,] 101.8128 102.6114 103.9102
 >
 > set.seed(100); runif(2)
[1] 0.3077661 0.2576725
 > parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
          [,1]     [,2]     [,3]
[1,] 101.1628 102.9643 103.2684
[2,] 101.9205 102.6937 103.7907


Bill Dunlap
TIBCO Software
wdunlap tibco.com


From bgunter.4567 at gmail.com  Sun Mar  4 19:21:11 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Mar 2018 10:21:11 -0800
Subject: [R] Change Function based on ifelse() condtion
In-Reply-To: <CAGgJW76uHbps5X+VbHPUR5zbpoomOLFeqhrAFyf2=w+4beEdqw@mail.gmail.com>
References: <CA+dpOJ=GfqjE8DHXfoMOMWzmYfFKVgppujvvThj2u6f6xNRWHg@mail.gmail.com>
 <17384058-6c52-ef0a-ed53-e6c272526e1a@gmail.com>
 <CA+dpOJkg9MrT0=29ShUK9Eyf9UXSfCDjGGK5S+0-NOc50+OGNA@mail.gmail.com>
 <CAGgJW76ajKme24xjcNaEMhMU2BDRF2Ahn3J2Nm0VSbVyEitTiw@mail.gmail.com>
 <CA+dpOJmSpAC6yN4mcHvMqJhBe1X1NBo15KOad9yP0ui4y_-E6g@mail.gmail.com>
 <CAGgJW76TVjy+8_6dGVNFQx6Jbu=VcLxuRW3Uc-U2GsU=sr3Ang@mail.gmail.com>
 <CA+dpOJnJD4VPLMPGJaqy5kCLDXf1MDD-2bO9yjRO_kmS=vRMig@mail.gmail.com>
 <CAGgJW76tPtKom3xzxsDv-+ee=6amDkOXEjKrt2_ZtrcVOJLVyw@mail.gmail.com>
 <CA+dpOJkHmVb3KwjEjHj=HwKrG=Qr4nx-97doNdLPDmkoK1esLQ@mail.gmail.com>
 <CAGgJW76uHbps5X+VbHPUR5zbpoomOLFeqhrAFyf2=w+4beEdqw@mail.gmail.com>
Message-ID: <CAGxFJbRpABg8Je46z8vUFunt_ehVcMCJ2Opa8TG0AC-owjAYhA@mail.gmail.com>

... and note also:

> f <- function(...)list(...) <- list(...)  ## you cannot have list(...) on
LHS

> f(x=1,y="a")
Error in list(...) <- list(...) : '...' used in an incorrect context


In addition to Eric's suggestions, maybe something like this construction
is useful:

Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
   if (Apply_MC) {
      return(mclapply(X, FUN, ...))
   } else {
      if (any(names(list(...)) == 'mc.cores')) {
         l = list(...)[!names(list(...)) %in% 'mc.cores']
      }
      return(do.call(lapply,c(list(X,FUN),l)))
   }
}

> Lapply_me (X=1:5,FUN=sum,mc.cores=4)
[[1]]
[1] 1

[[2]]
[1] 2

[[3]]
[1] 3

[[4]]
[1] 4

[[5]]
[1] 5

Though the program logic needs fixing: if none of the names in list(...)
are "mc.cores," l is undefined!

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Mar 4, 2018 at 9:58 AM, Eric Berger <ericjberger at gmail.com> wrote:

> The reason that it works for Apply_MC=TRUE is that in that case you call
> mclapply(X,FUN,...) and
> the mclapply() function strips off the mc.cores argument from the "..."
> list before calling FUN, so FUN is being called with zero arguments,
> exactly as it is declared.
>
> A quick workaround is to change the line
>
> Lapply_me(as.list(1:4), function(xx) {
>
> to
>
> Lapply_me(as.list(1:4), function(xx,dummyList) {
>
> HTH,
> Eric
>
>
> On Sun, Mar 4, 2018 at 7:21 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
> > Below is my full implementation (tried to make it simple as for
> > demonstration)
> >
> > Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
> > if (Apply_MC) {
> > return(mclapply(X, FUN, ...))
> > } else {
> > if (any(names(list(...)) == 'mc.cores')) {
> > myList = list(...)[!names(list(...)) %in% 'mc.cores']
> > }
> > return(lapply(X, FUN, myList))
> > }
> > }
> >
> >
> > Lapply_me(as.list(1:4), function(xx) {
> > if (xx == 1) return('a')
> > if (xx == 2) return('b')
> > if (xx == 3) return('c')
> > if (xx == 4) return('d')
> > }, Apply_MC = FALSE, mc.cores = 2)
> >
> > Error message :
> >
> > Error in FUN(X[[i]], ...) : unused argument (list())
> >
> > Kindly note that, with Apply_MC = TRUE, it is working perfectly.
> >
> > On Sun, Mar 4, 2018 at 10:45 PM, Eric Berger <ericjberger at gmail.com>
> > wrote:
> > > That's fine. The issue is how you called Lapply_me(). What did you pass
> > as
> > > the argument to FUN?
> > > And if you did not pass anything that how is FUN declared?
> > > You have not shown that in your email.
> > >
> > >
> > >
> > >
> > > On Sun, Mar 4, 2018 at 7:11 PM, Christofer Bogaso
> > > <bogaso.christofer at gmail.com> wrote:
> > >>
> > >> My modified function looks below :
> > >>
> > >> Lapply_me = function(X = X, FUN = FUN, Apply_MC = FALSE, ...) {
> > >> if (Apply_MC) {
> > >> return(mclapply(X, FUN, ...))
> > >> } else {
> > >> if (any(names(list(...)) == 'mc.cores')) {
> > >> myList = list(...)[!names(list(...)) %in% 'mc.cores']
> > >> }
> > >> return(lapply(X, FUN, myList))
> > >> }
> > >> }
> > >>
> > >> Here, I am not passing ... anymore rather passing myList
> > >>
> > >> On Sun, Mar 4, 2018 at 10:37 PM, Eric Berger <ericjberger at gmail.com>
> > >> wrote:
> > >> > Hi Christofer,
> > >> > Before you made the change that I suggested, your program was
> stopping
> > >> > at
> > >> > the statement: list(...) = list(..) .etc
> > >> > This means that it never tried to execute the statement:
> > >> > return(lapply(X,FUN,...))
> > >> > Now that you have made the change, it gets past the first statement
> > and
> > >> > tries to execute the statement: return(lapply(X,FUN,...)).
> > >> > That attempt is generating the error message because whatever you
> are
> > >> > passing in as the FUN argument is not expecting extra arguments.
> > >> >
> > >> > HTH,
> > >> > Eric
> > >> >
> > >> >
> > >> > On Sun, Mar 4, 2018 at 6:52 PM, Christofer Bogaso
> > >> > <bogaso.christofer at gmail.com> wrote:
> > >> >>
> > >> >> @Eric - with this approach I am getting below error :
> > >> >>
> > >> >> Error in FUN(X[[i]], ...) : unused argument (list())
> > >> >>
> > >> >> On Sun, Mar 4, 2018 at 10:18 PM, Eric Berger <
> ericjberger at gmail.com>
> > >> >> wrote:
> > >> >> > Hi Christofer,
> > >> >> > You cannot assign to list(...). You can do the following
> > >> >> >
> > >> >> > myList <- list(...)[!names(list(...)) %in% 'mc.cores']
> > >> >> >
> > >> >> > HTH,
> > >> >> > Eric
> > >> >> >
> > >> >> > On Sun, Mar 4, 2018 at 6:38 PM, Christofer Bogaso
> > >> >> > <bogaso.christofer at gmail.com> wrote:
> > >> >> >>
> > >> >> >> Hi,
> > >> >> >>
> > >> >> >> As an example, I want to create below kind of custom Function
> > which
> > >> >> >> either be mclapply pr lapply
> > >> >> >>
> > >> >> >> Lapply_me = function(X = X, FUN = FUN, ..., Apply_MC = FALSE) {
> > >> >> >> if (Apply_MC) {
> > >> >> >> return(mclapply(X, FUN, ...))
> > >> >> >> } else {
> > >> >> >> if (any(names(list(...)) == 'mc.cores')) {
> > >> >> >> list(...) = list(...)[!names(list(...)) %in% 'mc.cores']
> > >> >> >> }
> > >> >> >> return(lapply(X, FUN, ...))
> > >> >> >> }
> > >> >> >> }
> > >> >> >>
> > >> >> >> However when Apply_MC = FALSE it generates below error saying :
> > >> >> >>
> > >> >> >>   '...' used in an incorrect context
> > >> >> >>
> > >> >> >>
> > >> >> >> Appreciate if you can help me with the correct approach. Thanks,
> > >> >> >>
> > >> >> >>
> > >> >> >> On Sun, Mar 4, 2018 at 9:34 PM, Duncan Murdoch
> > >> >> >> <murdoch.duncan at gmail.com>
> > >> >> >> wrote:
> > >> >> >> > On 04/03/2018 10:39 AM, Christofer Bogaso wrote:
> > >> >> >> >>
> > >> >> >> >> Hi again,
> > >> >> >> >>
> > >> >> >> >> I am looking for some way to alternately use 2 related
> > functions,
> > >> >> >> >> based on some ifelse() condition.
> > >> >> >> >>
> > >> >> >> >> For example, I have 2 functions mclapply() and lapply()
> > >> >> >> >>
> > >> >> >> >> However, mclapply() function has one extra parameter
> 'mc.cores'
> > >> >> >> >> which
> > >> >> >> >> lapply doesnt not have.
> > >> >> >> >>
> > >> >> >> >> I know when mc.cores = 1, these 2 functions are essentially
> > same,
> > >> >> >> >> however I am looking for more general way to control them
> > within
> > >> >> >> >> ifelse() constion
> > >> >> >> >>
> > >> >> >> >> Can someone please help me how can I use them within ifelse()
> > >> >> >> >> condition.
> > >> >> >> >
> > >> >> >> >
> > >> >> >> > Don't.  ifelse() usually evaluates *both* the true and false
> > >> >> >> > values,
> > >> >> >> > and
> > >> >> >> > then selects entries from each.  Just use an if statement.
> > >> >> >> >
> > >> >> >> > Duncan Murdoch
> > >> >> >>
> > >> >> >> ______________________________________________
> > >> >> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
> see
> > >> >> >> https://stat.ethz.ch/mailman/listinfo/r-help
> > >> >> >> PLEASE do read the posting guide
> > >> >> >> http://www.R-project.org/posting-guide.html
> > >> >> >> and provide commented, minimal, self-contained, reproducible
> code.
> > >> >> >
> > >> >> >
> > >> >
> > >> >
> > >
> > >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gwblack001 at sbcglobal.net  Sun Mar  4 22:40:17 2018
From: gwblack001 at sbcglobal.net (Gary Black)
Date: Sun, 4 Mar 2018 15:40:17 -0600
Subject: [R] Random Seed Location
In-Reply-To: <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
References: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
 <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
Message-ID: <61C18210-9415-4BE1-8E07-6835B5B57505@sbcglobal.net>

Thank you, everybody, who replied!  I appreciate your valuable advise!  I will move the location of the set.seed() command to after all packages have been installed and loaded.

Best regards,
Gary

Sent from my iPad

> On Mar 4, 2018, at 12:18 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> 
> On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
> wrote:
> 
> (Sorry to be a bit slow responding.)
> 
> You have not supplied a complete example, which would be good in this case because what you are suggesting could be a serious bug in R or a package. Serious journals require reproducibility these days. For example, JSS is very clear on this point.
> 
> To your question
> > My question simply is:  should the location of the set.seed command matter,
> > provided that it is applied before any commands which involve randomness
> > (such as partitioning)?
> 
> the answer is no, it should not matter. But the proviso is important.
> 
> You can determine where things are messing up using something like
> 
> set.seed(654321)
> zk <- RNGkind()        # [1] "Mersenne-Twister" "Inversion"
> zk
> z <- runif(2)
> z
> set.seed(654321)
> 
> #  install.packages(c('caret', 'ggplot2', 'e1071'))
> library(caret)
> all(runif(2)  == z)   # should be true but it is not always
> 
> set.seed(654321)
> library(ggplot2)
> all(runif(2)  == z)   # should be true
> 
> set.seed(654321)
> library(e1071)
> all(runif(2)  == z)   # should be true
> 
> all(RNGkind() == zk)  # should be true
> 
> On my computer package caret seems to sometimes, but not always, do something that advances or changes the RNG. So you will need to set the seed after that package is loaded if you want reproducibility.
> 
> As Bill Dunlap points out, parallel can introduce much more complicated issues. If you are in fact using parallel then we really need a new thread with a better subject line, and the discussion will get much messier.
> 
> The short answer is that, yes you should be able to get reproducible results with parallel computing. If you cannot then you are almost certainly doing something wrong. To publish you really must have reproducible results.
> 
> In the example that Bill gave, I think the problem is that set.seed() only resets the seed in the main thread, the nodes continue to operate with unreset RNG. To demonstrate this to yourself you can do
> 
> library(parallel)
> cl <- parallel::makeCluster(3)
> parallel::clusterCall(cl, function()set.seed(100))
> parallel::clusterCall(cl, function()RNGkind())
> parallel::clusterCall(cl, function()runif(2)) # similar result from all nodes
>                                               # [1] 0.3077661 0.2576725
> 
> However, do *NOT* do that in real work. You will be getting the same RNG stream from each node. If you are using random numbers and parallel you need to read a lot more, and probably consider a variant of the "L'Ecuyer" generator or something designed for parallel computing.
> 
> One special point I will mention because it does not seem to be widely
> appreciated: the number of nodes affects the random stream, so recording the number of compute nodes along with the RNG and seed information is important for reproducible results. This has the unfortunate consequence that an experiment cannot be reproduced on a larger cluster. (If anyone knows differently I would very much like to hear.)
> 
> Paul Gilbert
> 
> 
> > Hi all,
> >
> > For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
> > different results (e.g., error rates, classification probabilities) from
> > run
> > to run even though I am using the same random seed.
> >
> > Nothing else (input-wise) is changing, but my results are somewhat
> > different
> > from run to run.  The only randomness should be in the partitioning, and I
> > have set the seed before this point.
> >
> > My question simply is:  should the location of the set.seed command matter,
> > provided that it is applied before any commands which involve randomness
> > (such as partitioning)?
> >
> > If you need to see the code, it is below:
> >
> > Thank you,
> > Gary
> >
> >
> > A.      Separate the original (in-sample) data from the new (out-of-sample)
> > data.  Set a random seed.
> >
> >> InvestTech <- as.data.frame(InvestTechRevised)
> >> outOfSample <- InvestTech[5001:nrow(InvestTech), ]
> >> InvestTech <- InvestTech[1:5000, ]
> >> set.seed(654321)
> >
> > B.      Install and load the caret, ggplot2 and e1071 packages.
> >
> >> install.packages(?caret?)
> >> install.packages(?ggplot2?)
> >> install.packages(?e1071?)
> >> library(caret)
> >> library(ggplot2)
> >> library(e1071)
> >
> > C.      Bin the predictor variables with approximately equal counts using
> > the cut_number function from the ggplot2 package.  We will use 20 bins.
> >
> >> InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
> >> InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
> >> outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
> >> outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
> >
> > D.      Partition the original (in-sample) data into 60% training and 40%
> > validation sets.
> >
> >> n <- nrow(InvestTech)
> >> train <- sample(1:n, size = 0.6 * n, replace = FALSE)
> >> InvestTechTrain <- InvestTech[train, ]
> >> InvestTechVal <- InvestTech[-train, ]
> >
> > E.      Use the naiveBayes function in the e1071 package to fit the model.
> >
> >> model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data = InvestTechTrain)
> >> prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
> >> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
> >
> > F.      Use the confusionMatrix function in the caret package to output the
> > confusion matrix.
> >
> >> confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
> > ?everything?, positive = ?1?)
> >> accuracy <- confMtr$overall[1]
> >> valError <- 1 ? accuracy
> >> confMtr
> >
> > G.      Classify the 18 new (out-of-sample) readers using the following
> > code.
> >> prob <- predict(model, newdata = outOfSample, type = ?raw?)
> >> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
> >> cbind(pred, prob, outOfSample[, -3])
> >
> >
> >
> 
> 
> If your computations involve the parallel package then set.seed(seed)
> may not produce repeatable results.  E.g.,
> 
> > cl <- parallel::makeCluster(3)  # Create cluster with 3 nodes on local
> host
> > set.seed(100); runif(2)
> [1] 0.3077661 0.2576725
> > parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>         [,1]     [,2]     [,3]
> [1,] 101.7779 102.5308 103.3459
> [2,] 101.8128 102.6114 103.9102
> >
> > set.seed(100); runif(2)
> [1] 0.3077661 0.2576725
> > parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>         [,1]     [,2]     [,3]
> [1,] 101.1628 102.9643 103.2684
> [2,] 101.9205 102.6937 103.7907
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com


From henrik.bengtsson at gmail.com  Sun Mar  4 23:54:23 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 4 Mar 2018 14:54:23 -0800
Subject: [R] Random Seed Location
In-Reply-To: <61C18210-9415-4BE1-8E07-6835B5B57505@sbcglobal.net>
References: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
 <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
 <61C18210-9415-4BE1-8E07-6835B5B57505@sbcglobal.net>
Message-ID: <CAFDcVCS5OYS7d2kf26rnPuM_AnKBZUsJOY6f8ZebZj4EPVuZ7A@mail.gmail.com>

The following helps identify when .GlobalEnv$.Random.seed has changed:

rng_tracker <- local({
  last <- .GlobalEnv$.Random.seed
  function(...) {
    curr <- .GlobalEnv$.Random.seed
    if (!identical(curr, last)) {
      warning(".Random.seed changed")
      last <<- curr
    }
    TRUE
  }
})

addTaskCallback(rng_tracker, name = "RNG tracker")


EXAMPLE:

> sample.int(1L)
[1] 1
Warning: .Random.seed changed

This will help you find for instance:

## Loading ggplot2 does not affect the RNG seed
> loadNamespace("ggplot2")
<environment: namespace:ggplot2>

## But attaching it does
> library("ggplot2")
Warning: .Random.seed changed

which reveals:

> ggplot2:::.onAttach
function (...)
{
    if (!interactive() || stats::runif(1) > 0.1)
        return()
    tips <- c("Need help? Try the ggplot2 mailing list:
http://groups.google.com/group/ggplot2.",
        "Find out what's changed in ggplot2 at
http://github.com/tidyverse/ggplot2/releases.",
        "Use suppressPackageStartupMessages() to eliminate package
startup messages.",
        "Stackoverflow is a great place to get help:
http://stackoverflow.com/tags/ggplot2.",
        "Need help getting started? Try the cookbook for R:
http://www.cookbook-r.com/Graphs/",
        "Want to understand how all the pieces fit together? Buy the
ggplot2 book: http://ggplot2.org/book/")
    tip <- sample(tips, 1)
    packageStartupMessage(paste(strwrap(tip), collapse = "\n"))
}
<environment: namespace:ggplot2>

There are probably many case of this in different R packages.


R WISH:

There could be a

preserveRandomSeed({
  tip <- sample(tips, 1)
})

function in R for these type of random needs where true random
properties are non-critical.  This type of
"draw-a-random-number-and-reset-the-seed" is for instance used in
parallel:::initDefaultClusterOptions() which is called when the
'parallel' package is loaded:

seed <- .GlobalEnv$.Random.seed
ran1 <- sample.int(.Machine$integer.max - 1L, 1L) / .Machine$integer.max
port <- 11000 + 1000 * ((ran1 + unclass(Sys.time()) / 300) %% 1)
if(is.null(seed)) ## there was none, initially
rm( ".Random.seed", envir = .GlobalEnv, inherits = FALSE)
else # reset
assign(".Random.seed", seed, envir = .GlobalEnv, inherits = FALSE)

/Henrik

On Sun, Mar 4, 2018 at 1:40 PM, Gary Black <gwblack001 at sbcglobal.net> wrote:
> Thank you, everybody, who replied!  I appreciate your valuable advise!  I will move the location of the set.seed() command to after all packages have been installed and loaded.
>
> Best regards,
> Gary
>
> Sent from my iPad
>
>> On Mar 4, 2018, at 12:18 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>
>> On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
>> wrote:
>>
>> (Sorry to be a bit slow responding.)
>>
>> You have not supplied a complete example, which would be good in this case because what you are suggesting could be a serious bug in R or a package. Serious journals require reproducibility these days. For example, JSS is very clear on this point.
>>
>> To your question
>> > My question simply is:  should the location of the set.seed command matter,
>> > provided that it is applied before any commands which involve randomness
>> > (such as partitioning)?
>>
>> the answer is no, it should not matter. But the proviso is important.
>>
>> You can determine where things are messing up using something like
>>
>> set.seed(654321)
>> zk <- RNGkind()        # [1] "Mersenne-Twister" "Inversion"
>> zk
>> z <- runif(2)
>> z
>> set.seed(654321)
>>
>> #  install.packages(c('caret', 'ggplot2', 'e1071'))
>> library(caret)
>> all(runif(2)  == z)   # should be true but it is not always
>>
>> set.seed(654321)
>> library(ggplot2)
>> all(runif(2)  == z)   # should be true
>>
>> set.seed(654321)
>> library(e1071)
>> all(runif(2)  == z)   # should be true
>>
>> all(RNGkind() == zk)  # should be true
>>
>> On my computer package caret seems to sometimes, but not always, do something that advances or changes the RNG. So you will need to set the seed after that package is loaded if you want reproducibility.
>>
>> As Bill Dunlap points out, parallel can introduce much more complicated issues. If you are in fact using parallel then we really need a new thread with a better subject line, and the discussion will get much messier.
>>
>> The short answer is that, yes you should be able to get reproducible results with parallel computing. If you cannot then you are almost certainly doing something wrong. To publish you really must have reproducible results.
>>
>> In the example that Bill gave, I think the problem is that set.seed() only resets the seed in the main thread, the nodes continue to operate with unreset RNG. To demonstrate this to yourself you can do
>>
>> library(parallel)
>> cl <- parallel::makeCluster(3)
>> parallel::clusterCall(cl, function()set.seed(100))
>> parallel::clusterCall(cl, function()RNGkind())
>> parallel::clusterCall(cl, function()runif(2)) # similar result from all nodes
>>                                               # [1] 0.3077661 0.2576725
>>
>> However, do *NOT* do that in real work. You will be getting the same RNG stream from each node. If you are using random numbers and parallel you need to read a lot more, and probably consider a variant of the "L'Ecuyer" generator or something designed for parallel computing.
>>
>> One special point I will mention because it does not seem to be widely
>> appreciated: the number of nodes affects the random stream, so recording the number of compute nodes along with the RNG and seed information is important for reproducible results. This has the unfortunate consequence that an experiment cannot be reproduced on a larger cluster. (If anyone knows differently I would very much like to hear.)
>>
>> Paul Gilbert
>>
>>
>> > Hi all,
>> >
>> > For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
>> > different results (e.g., error rates, classification probabilities) from
>> > run
>> > to run even though I am using the same random seed.
>> >
>> > Nothing else (input-wise) is changing, but my results are somewhat
>> > different
>> > from run to run.  The only randomness should be in the partitioning, and I
>> > have set the seed before this point.
>> >
>> > My question simply is:  should the location of the set.seed command matter,
>> > provided that it is applied before any commands which involve randomness
>> > (such as partitioning)?
>> >
>> > If you need to see the code, it is below:
>> >
>> > Thank you,
>> > Gary
>> >
>> >
>> > A.      Separate the original (in-sample) data from the new (out-of-sample)
>> > data.  Set a random seed.
>> >
>> >> InvestTech <- as.data.frame(InvestTechRevised)
>> >> outOfSample <- InvestTech[5001:nrow(InvestTech), ]
>> >> InvestTech <- InvestTech[1:5000, ]
>> >> set.seed(654321)
>> >
>> > B.      Install and load the caret, ggplot2 and e1071 packages.
>> >
>> >> install.packages(?caret?)
>> >> install.packages(?ggplot2?)
>> >> install.packages(?e1071?)
>> >> library(caret)
>> >> library(ggplot2)
>> >> library(e1071)
>> >
>> > C.      Bin the predictor variables with approximately equal counts using
>> > the cut_number function from the ggplot2 package.  We will use 20 bins.
>> >
>> >> InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
>> >> InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
>> >> outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
>> >> outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
>> >
>> > D.      Partition the original (in-sample) data into 60% training and 40%
>> > validation sets.
>> >
>> >> n <- nrow(InvestTech)
>> >> train <- sample(1:n, size = 0.6 * n, replace = FALSE)
>> >> InvestTechTrain <- InvestTech[train, ]
>> >> InvestTechVal <- InvestTech[-train, ]
>> >
>> > E.      Use the naiveBayes function in the e1071 package to fit the model.
>> >
>> >> model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data = InvestTechTrain)
>> >> prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
>> >> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>> >
>> > F.      Use the confusionMatrix function in the caret package to output the
>> > confusion matrix.
>> >
>> >> confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
>> > ?everything?, positive = ?1?)
>> >> accuracy <- confMtr$overall[1]
>> >> valError <- 1 ? accuracy
>> >> confMtr
>> >
>> > G.      Classify the 18 new (out-of-sample) readers using the following
>> > code.
>> >> prob <- predict(model, newdata = outOfSample, type = ?raw?)
>> >> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>> >> cbind(pred, prob, outOfSample[, -3])
>> >
>> >
>> >
>>
>>
>> If your computations involve the parallel package then set.seed(seed)
>> may not produce repeatable results.  E.g.,
>>
>> > cl <- parallel::makeCluster(3)  # Create cluster with 3 nodes on local
>> host
>> > set.seed(100); runif(2)
>> [1] 0.3077661 0.2576725
>> > parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>>         [,1]     [,2]     [,3]
>> [1,] 101.7779 102.5308 103.3459
>> [2,] 101.8128 102.6114 103.9102
>> >
>> > set.seed(100); runif(2)
>> [1] 0.3077661 0.2576725
>> > parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>>         [,1]     [,2]     [,3]
>> [1,] 101.1628 102.9643 103.2684
>> [2,] 101.9205 102.6937 103.7907
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Mar  5 00:23:27 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 4 Mar 2018 18:23:27 -0500
Subject: [R] Random Seed Location
In-Reply-To: <CAFDcVCS5OYS7d2kf26rnPuM_AnKBZUsJOY6f8ZebZj4EPVuZ7A@mail.gmail.com>
References: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
 <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
 <61C18210-9415-4BE1-8E07-6835B5B57505@sbcglobal.net>
 <CAFDcVCS5OYS7d2kf26rnPuM_AnKBZUsJOY6f8ZebZj4EPVuZ7A@mail.gmail.com>
Message-ID: <6567d1c9-336e-47b4-937c-a83c7e1269e9@gmail.com>

On 04/03/2018 5:54 PM, Henrik Bengtsson wrote:
> The following helps identify when .GlobalEnv$.Random.seed has changed:
> 
> rng_tracker <- local({
>    last <- .GlobalEnv$.Random.seed
>    function(...) {
>      curr <- .GlobalEnv$.Random.seed
>      if (!identical(curr, last)) {
>        warning(".Random.seed changed")
>        last <<- curr
>      }
>      TRUE
>    }
> })
> 
> addTaskCallback(rng_tracker, name = "RNG tracker")
> 
> 
> EXAMPLE:
> 
>> sample.int(1L)
> [1] 1
> Warning: .Random.seed changed
> 
> This will help you find for instance:
> 
> ## Loading ggplot2 does not affect the RNG seed
>> loadNamespace("ggplot2")
> <environment: namespace:ggplot2>
> 
> ## But attaching it does
>> library("ggplot2")
> Warning: .Random.seed changed
> 
> which reveals:
> 
>> ggplot2:::.onAttach
> function (...)
> {
>      if (!interactive() || stats::runif(1) > 0.1)
>          return()
>      tips <- c("Need help? Try the ggplot2 mailing list:
> http://groups.google.com/group/ggplot2.",
>          "Find out what's changed in ggplot2 at
> http://github.com/tidyverse/ggplot2/releases.",
>          "Use suppressPackageStartupMessages() to eliminate package
> startup messages.",
>          "Stackoverflow is a great place to get help:
> http://stackoverflow.com/tags/ggplot2.",
>          "Need help getting started? Try the cookbook for R:
> http://www.cookbook-r.com/Graphs/",
>          "Want to understand how all the pieces fit together? Buy the
> ggplot2 book: http://ggplot2.org/book/")
>      tip <- sample(tips, 1)
>      packageStartupMessage(paste(strwrap(tip), collapse = "\n"))
> }
> <environment: namespace:ggplot2>
> 
> There are probably many case of this in different R packages.
> 
> 
> R WISH:
> 
> There could be a
> 
> preserveRandomSeed({
>    tip <- sample(tips, 1)
> })
> 
> function in R for these type of random needs where true random
> properties are non-critical.  This type of
> "draw-a-random-number-and-reset-the-seed" is for instance used in
> parallel:::initDefaultClusterOptions() which is called when the
> 'parallel' package is loaded:
> 
> seed <- .GlobalEnv$.Random.seed
> ran1 <- sample.int(.Machine$integer.max - 1L, 1L) / .Machine$integer.max
> port <- 11000 + 1000 * ((ran1 + unclass(Sys.time()) / 300) %% 1)
> if(is.null(seed)) ## there was none, initially
> rm( ".Random.seed", envir = .GlobalEnv, inherits = FALSE)
> else # reset
> assign(".Random.seed", seed, envir = .GlobalEnv, inherits = FALSE)

An issue is that .Random.seed doesn't contain the full state of the RNG 
system, so restoring it doesn't necessarily lead to an identical 
sequence of output.  The only way to guarantee the sequence will repeat 
is to call set.seed(n), and that only leads to a tiny fraction of 
possible states.

Expanding .Random.seed so that it does contain the full state would be a 
good idea, and that would make your preserveRandomSeed really easy to write.

Here's a demo that .Random.seed is not enough:

 > set.seed(123, normal.kind = "Box-Muller")
 > rnorm(1)
[1] -0.1613431
 > save <- .Random.seed
 > rnorm(1)
[1] 0.6706031
 > .Random.seed <- save
 > rnorm(1)
[1] -0.4194403

If .Random.seed were the complete state, the 2nd and 3rd rnorm results 
would be the same.

Duncan Murdoch


> 
> /Henrik
> 
> On Sun, Mar 4, 2018 at 1:40 PM, Gary Black <gwblack001 at sbcglobal.net> wrote:
>> Thank you, everybody, who replied!  I appreciate your valuable advise!  I will move the location of the set.seed() command to after all packages have been installed and loaded.
>>
>> Best regards,
>> Gary
>>
>> Sent from my iPad
>>
>>> On Mar 4, 2018, at 12:18 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>>
>>> On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
>>> wrote:
>>>
>>> (Sorry to be a bit slow responding.)
>>>
>>> You have not supplied a complete example, which would be good in this case because what you are suggesting could be a serious bug in R or a package. Serious journals require reproducibility these days. For example, JSS is very clear on this point.
>>>
>>> To your question
>>>> My question simply is:  should the location of the set.seed command matter,
>>>> provided that it is applied before any commands which involve randomness
>>>> (such as partitioning)?
>>>
>>> the answer is no, it should not matter. But the proviso is important.
>>>
>>> You can determine where things are messing up using something like
>>>
>>> set.seed(654321)
>>> zk <- RNGkind()        # [1] "Mersenne-Twister" "Inversion"
>>> zk
>>> z <- runif(2)
>>> z
>>> set.seed(654321)
>>>
>>> #  install.packages(c('caret', 'ggplot2', 'e1071'))
>>> library(caret)
>>> all(runif(2)  == z)   # should be true but it is not always
>>>
>>> set.seed(654321)
>>> library(ggplot2)
>>> all(runif(2)  == z)   # should be true
>>>
>>> set.seed(654321)
>>> library(e1071)
>>> all(runif(2)  == z)   # should be true
>>>
>>> all(RNGkind() == zk)  # should be true
>>>
>>> On my computer package caret seems to sometimes, but not always, do something that advances or changes the RNG. So you will need to set the seed after that package is loaded if you want reproducibility.
>>>
>>> As Bill Dunlap points out, parallel can introduce much more complicated issues. If you are in fact using parallel then we really need a new thread with a better subject line, and the discussion will get much messier.
>>>
>>> The short answer is that, yes you should be able to get reproducible results with parallel computing. If you cannot then you are almost certainly doing something wrong. To publish you really must have reproducible results.
>>>
>>> In the example that Bill gave, I think the problem is that set.seed() only resets the seed in the main thread, the nodes continue to operate with unreset RNG. To demonstrate this to yourself you can do
>>>
>>> library(parallel)
>>> cl <- parallel::makeCluster(3)
>>> parallel::clusterCall(cl, function()set.seed(100))
>>> parallel::clusterCall(cl, function()RNGkind())
>>> parallel::clusterCall(cl, function()runif(2)) # similar result from all nodes
>>>                                                # [1] 0.3077661 0.2576725
>>>
>>> However, do *NOT* do that in real work. You will be getting the same RNG stream from each node. If you are using random numbers and parallel you need to read a lot more, and probably consider a variant of the "L'Ecuyer" generator or something designed for parallel computing.
>>>
>>> One special point I will mention because it does not seem to be widely
>>> appreciated: the number of nodes affects the random stream, so recording the number of compute nodes along with the RNG and seed information is important for reproducible results. This has the unfortunate consequence that an experiment cannot be reproduced on a larger cluster. (If anyone knows differently I would very much like to hear.)
>>>
>>> Paul Gilbert
>>>
>>>
>>>> Hi all,
>>>>
>>>> For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
>>>> different results (e.g., error rates, classification probabilities) from
>>>> run
>>>> to run even though I am using the same random seed.
>>>>
>>>> Nothing else (input-wise) is changing, but my results are somewhat
>>>> different
>>>> from run to run.  The only randomness should be in the partitioning, and I
>>>> have set the seed before this point.
>>>>
>>>> My question simply is:  should the location of the set.seed command matter,
>>>> provided that it is applied before any commands which involve randomness
>>>> (such as partitioning)?
>>>>
>>>> If you need to see the code, it is below:
>>>>
>>>> Thank you,
>>>> Gary
>>>>
>>>>
>>>> A.      Separate the original (in-sample) data from the new (out-of-sample)
>>>> data.  Set a random seed.
>>>>
>>>>> InvestTech <- as.data.frame(InvestTechRevised)
>>>>> outOfSample <- InvestTech[5001:nrow(InvestTech), ]
>>>>> InvestTech <- InvestTech[1:5000, ]
>>>>> set.seed(654321)
>>>>
>>>> B.      Install and load the caret, ggplot2 and e1071 packages.
>>>>
>>>>> install.packages(?caret?)
>>>>> install.packages(?ggplot2?)
>>>>> install.packages(?e1071?)
>>>>> library(caret)
>>>>> library(ggplot2)
>>>>> library(e1071)
>>>>
>>>> C.      Bin the predictor variables with approximately equal counts using
>>>> the cut_number function from the ggplot2 package.  We will use 20 bins.
>>>>
>>>>> InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
>>>>> InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
>>>>> outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
>>>>> outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
>>>>
>>>> D.      Partition the original (in-sample) data into 60% training and 40%
>>>> validation sets.
>>>>
>>>>> n <- nrow(InvestTech)
>>>>> train <- sample(1:n, size = 0.6 * n, replace = FALSE)
>>>>> InvestTechTrain <- InvestTech[train, ]
>>>>> InvestTechVal <- InvestTech[-train, ]
>>>>
>>>> E.      Use the naiveBayes function in the e1071 package to fit the model.
>>>>
>>>>> model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data = InvestTechTrain)
>>>>> prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
>>>>> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>>>>
>>>> F.      Use the confusionMatrix function in the caret package to output the
>>>> confusion matrix.
>>>>
>>>>> confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
>>>> ?everything?, positive = ?1?)
>>>>> accuracy <- confMtr$overall[1]
>>>>> valError <- 1 ? accuracy
>>>>> confMtr
>>>>
>>>> G.      Classify the 18 new (out-of-sample) readers using the following
>>>> code.
>>>>> prob <- predict(model, newdata = outOfSample, type = ?raw?)
>>>>> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>>>>> cbind(pred, prob, outOfSample[, -3])
>>>>
>>>>
>>>>
>>>
>>>
>>> If your computations involve the parallel package then set.seed(seed)
>>> may not produce repeatable results.  E.g.,
>>>
>>>> cl <- parallel::makeCluster(3)  # Create cluster with 3 nodes on local
>>> host
>>>> set.seed(100); runif(2)
>>> [1] 0.3077661 0.2576725
>>>> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>>>          [,1]     [,2]     [,3]
>>> [1,] 101.7779 102.5308 103.3459
>>> [2,] 101.8128 102.6114 103.9102
>>>>
>>>> set.seed(100); runif(2)
>>> [1] 0.3077661 0.2576725
>>>> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>>>          [,1]     [,2]     [,3]
>>> [1,] 101.1628 102.9643 103.2684
>>> [2,] 101.9205 102.6937 103.7907
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From henrik.bengtsson at gmail.com  Mon Mar  5 00:26:14 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 4 Mar 2018 15:26:14 -0800
Subject: [R] Random Seed Location
In-Reply-To: <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
References: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
 <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
Message-ID: <CAFDcVCS-XfYjdA-aTB4TNcx+9pXk3pB_gZzt3eTPNSKsDJNuzQ@mail.gmail.com>

On Sun, Mar 4, 2018 at 10:18 AM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
> On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
> wrote:
>
> (Sorry to be a bit slow responding.)
>
> You have not supplied a complete example, which would be good in this case
> because what you are suggesting could be a serious bug in R or a package.
> Serious journals require reproducibility these days. For example, JSS is
> very clear on this point.
>
> To your question
>> My question simply is:  should the location of the set.seed command
>> matter,
>> provided that it is applied before any commands which involve randomness
>> (such as partitioning)?
>
> the answer is no, it should not matter. But the proviso is important.
>
> You can determine where things are messing up using something like
>
>  set.seed(654321)
>  zk <- RNGkind()        # [1] "Mersenne-Twister" "Inversion"
>  zk
>  z <- runif(2)
>  z
>  set.seed(654321)
>
>  #  install.packages(c('caret', 'ggplot2', 'e1071'))
>  library(caret)
>  all(runif(2)  == z)   # should be true but it is not always
>
>  set.seed(654321)
>  library(ggplot2)
>  all(runif(2)  == z)   # should be true
>
>  set.seed(654321)
>  library(e1071)
>  all(runif(2)  == z)   # should be true
>
>  all(RNGkind() == zk)  # should be true
>
> On my computer package caret seems to sometimes, but not always, do
> something that advances or changes the RNG. So you will need to set the seed
> after that package is loaded if you want reproducibility.
>
> As Bill Dunlap points out, parallel can introduce much more complicated
> issues. If you are in fact using parallel then we really need a new thread
> with a better subject line, and the discussion will get much messier.
>
> The short answer is that, yes you should be able to get reproducible results
> with parallel computing. If you cannot then you are almost certainly doing
> something wrong. To publish you really must have reproducible results.
>
> In the example that Bill gave, I think the problem is that set.seed() only
> resets the seed in the main thread, the nodes continue to operate with
> unreset RNG. To demonstrate this to yourself you can do
>
>  library(parallel)
>  cl <- parallel::makeCluster(3)
>  parallel::clusterCall(cl, function()set.seed(100))
>  parallel::clusterCall(cl, function()RNGkind())
>  parallel::clusterCall(cl, function()runif(2)) # similar result from all
> nodes
>                                                # [1] 0.3077661 0.2576725
>
> However, do *NOT* do that in real work. You will be getting the same RNG
> stream from each node. If you are using random numbers and parallel you need
> to read a lot more, and probably consider a variant of the "L'Ecuyer"
> generator or something designed for parallel computing.
>
> One special point I will mention because it does not seem to be widely
> appreciated: the number of nodes affects the random stream, so recording the
> number of compute nodes along with the RNG and seed information is important
> for reproducible results. This has the unfortunate consequence that an
> experiment cannot be reproduced on a larger cluster. (If anyone knows
> differently I would very much like to hear.)

[Disclaimer: I'm the author] future.apply::future_lapply(X, ...,
future.seed) etc. can produce identical RNG results regardless of how
'X' is chunked up.  For example,

library(future.apply)

task <- function(i) {
  c(i = i, random = sample.int(10, size = 1), pid = Sys.getpid())
}

y <- list()

plan(multiprocess, workers = 1L)
y[[1]] <- future_sapply(1:10, FUN = task, future.seed = 42)

plan(multiprocess, workers = 2L)
y[[2]] <- future_sapply(1:10, FUN = task, future.seed = 42)

plan(multiprocess, workers = 3L)
y[[3]] <- future_sapply(1:10, FUN = task, future.seed = 42)

gives the exact same random output:

> y

[[1]]
        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
i          1     2     3     4     5     6     7     8     9    10
random     5    10     1     8     7     9     3     5    10     4
pid    31933 31933 31933 31933 31933 31933 31933 31933 31933 31933

[[2]]
        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
i          1     2     3     4     5     6     7     8     9    10
random     5    10     1     8     7     9     3     5    10     4
pid    32141 32141 32141 32141 32141 32142 32142 32142 32142 32142

[[3]]
        [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10]
i          1     2     3     4     5     6     7     8     9    10
random     5    10     1     8     7     9     3     5    10     4
pid    32199 32199 32199 32200 32200 32200 32200 32201 32201 32201

To base the RNG on the current RNG seed (== .GlobalEnv$.Random.seed),
one can use 'future.seed = TRUE'.  For performance reasons, I choose
the default to be 'future.seed = FALSE', because there can be a
substantial overhead in setting up reproducible L'Ecuyer
subRNG-streams for all elements in 'X'.

I think the snowFT package by Sevcikova & Rossini also provides this
mechanism; Hana Sevcikova is also behind the rlecuyer package.

Hope this helps

/Henrik

>
> Paul Gilbert
>
>
>
>> Hi all,
>>
>> For some odd reason when running na?ve bayes, k-NN, etc., I get slightly
>> different results (e.g., error rates, classification probabilities) from
>> run
>> to run even though I am using the same random seed.
>>
>> Nothing else (input-wise) is changing, but my results are somewhat
>> different
>> from run to run.  The only randomness should be in the partitioning, and I
>> have set the seed before this point.
>>
>> My question simply is:  should the location of the set.seed command
>> matter,
>> provided that it is applied before any commands which involve randomness
>> (such as partitioning)?
>>
>> If you need to see the code, it is below:
>>
>> Thank you,
>> Gary
>>
>>
>> A.      Separate the original (in-sample) data from the new
>> (out-of-sample)
>> data.  Set a random seed.
>>
>>> InvestTech <- as.data.frame(InvestTechRevised)
>>> outOfSample <- InvestTech[5001:nrow(InvestTech), ]
>>> InvestTech <- InvestTech[1:5000, ]
>>> set.seed(654321)
>>
>> B.      Install and load the caret, ggplot2 and e1071 packages.
>>
>>> install.packages(?caret?)
>>> install.packages(?ggplot2?)
>>> install.packages(?e1071?)
>>> library(caret)
>>> library(ggplot2)
>>> library(e1071)
>>
>> C.      Bin the predictor variables with approximately equal counts using
>> the cut_number function from the ggplot2 package.  We will use 20 bins.
>>
>>> InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
>>> InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
>>> outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
>>> outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
>>
>> D.      Partition the original (in-sample) data into 60% training and 40%
>> validation sets.
>>
>>> n <- nrow(InvestTech)
>>> train <- sample(1:n, size = 0.6 * n, replace = FALSE)
>>> InvestTechTrain <- InvestTech[train, ]
>>> InvestTechVal <- InvestTech[-train, ]
>>
>> E.      Use the naiveBayes function in the e1071 package to fit the model.
>>
>>> model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data = InvestTechTrain)
>>> prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
>>> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>>
>> F.      Use the confusionMatrix function in the caret package to output
>> the
>> confusion matrix.
>>
>>> confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
>> ?everything?, positive = ?1?)
>>> accuracy <- confMtr$overall[1]
>>> valError <- 1 ? accuracy
>>> confMtr
>>
>> G.      Classify the 18 new (out-of-sample) readers using the following
>> code.
>>> prob <- predict(model, newdata = outOfSample, type = ?raw?)
>>> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>>> cbind(pred, prob, outOfSample[, -3])
>>
>>
>>
>
>
> If your computations involve the parallel package then set.seed(seed)
> may not produce repeatable results.  E.g.,
>
>> cl <- parallel::makeCluster(3)  # Create cluster with 3 nodes on local
> host
>> set.seed(100); runif(2)
> [1] 0.3077661 0.2576725
>> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>          [,1]     [,2]     [,3]
> [1,] 101.7779 102.5308 103.3459
> [2,] 101.8128 102.6114 103.9102
>>
>> set.seed(100); runif(2)
> [1] 0.3077661 0.2576725
>> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>          [,1]     [,2]     [,3]
> [1,] 101.1628 102.9643 103.2684
> [2,] 101.9205 102.6937 103.7907
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From henrik.bengtsson at gmail.com  Mon Mar  5 01:14:08 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 4 Mar 2018 16:14:08 -0800
Subject: [R] Random Seed Location
In-Reply-To: <6567d1c9-336e-47b4-937c-a83c7e1269e9@gmail.com>
References: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
 <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
 <61C18210-9415-4BE1-8E07-6835B5B57505@sbcglobal.net>
 <CAFDcVCS5OYS7d2kf26rnPuM_AnKBZUsJOY6f8ZebZj4EPVuZ7A@mail.gmail.com>
 <6567d1c9-336e-47b4-937c-a83c7e1269e9@gmail.com>
Message-ID: <CAFDcVCTuqP0iRQ48oOS4mrnauLgyEhQ_bbhD1FjnPYyU8N=UbA@mail.gmail.com>

On Sun, Mar 4, 2018 at 3:23 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 04/03/2018 5:54 PM, Henrik Bengtsson wrote:
>>
>> The following helps identify when .GlobalEnv$.Random.seed has changed:
>>
>> rng_tracker <- local({
>>    last <- .GlobalEnv$.Random.seed
>>    function(...) {
>>      curr <- .GlobalEnv$.Random.seed
>>      if (!identical(curr, last)) {
>>        warning(".Random.seed changed")
>>        last <<- curr
>>      }
>>      TRUE
>>    }
>> })
>>
>> addTaskCallback(rng_tracker, name = "RNG tracker")
>>
>>
>> EXAMPLE:
>>
>>> sample.int(1L)
>>
>> [1] 1
>> Warning: .Random.seed changed
>>
>> This will help you find for instance:
>>
>> ## Loading ggplot2 does not affect the RNG seed
>>>
>>> loadNamespace("ggplot2")
>>
>> <environment: namespace:ggplot2>
>>
>> ## But attaching it does
>>>
>>> library("ggplot2")
>>
>> Warning: .Random.seed changed
>>
>> which reveals:
>>
>>> ggplot2:::.onAttach
>>
>> function (...)
>> {
>>      if (!interactive() || stats::runif(1) > 0.1)
>>          return()
>>      tips <- c("Need help? Try the ggplot2 mailing list:
>> http://groups.google.com/group/ggplot2.",
>>          "Find out what's changed in ggplot2 at
>> http://github.com/tidyverse/ggplot2/releases.",
>>          "Use suppressPackageStartupMessages() to eliminate package
>> startup messages.",
>>          "Stackoverflow is a great place to get help:
>> http://stackoverflow.com/tags/ggplot2.",
>>          "Need help getting started? Try the cookbook for R:
>> http://www.cookbook-r.com/Graphs/",
>>          "Want to understand how all the pieces fit together? Buy the
>> ggplot2 book: http://ggplot2.org/book/")
>>      tip <- sample(tips, 1)
>>      packageStartupMessage(paste(strwrap(tip), collapse = "\n"))
>> }
>> <environment: namespace:ggplot2>
>>
>> There are probably many case of this in different R packages.
>>
>>
>> R WISH:
>>
>> There could be a
>>
>> preserveRandomSeed({
>>    tip <- sample(tips, 1)
>> })
>>
>> function in R for these type of random needs where true random
>> properties are non-critical.  This type of
>> "draw-a-random-number-and-reset-the-seed" is for instance used in
>> parallel:::initDefaultClusterOptions() which is called when the
>> 'parallel' package is loaded:
>>
>> seed <- .GlobalEnv$.Random.seed
>> ran1 <- sample.int(.Machine$integer.max - 1L, 1L) / .Machine$integer.max
>> port <- 11000 + 1000 * ((ran1 + unclass(Sys.time()) / 300) %% 1)
>> if(is.null(seed)) ## there was none, initially
>> rm( ".Random.seed", envir = .GlobalEnv, inherits = FALSE)
>> else # reset
>> assign(".Random.seed", seed, envir = .GlobalEnv, inherits = FALSE)
>
>
> An issue is that .Random.seed doesn't contain the full state of the RNG
> system, so restoring it doesn't necessarily lead to an identical sequence of
> output.  The only way to guarantee the sequence will repeat is to call
> set.seed(n), and that only leads to a tiny fraction of possible states.
>
> Expanding .Random.seed so that it does contain the full state would be a
> good idea, and that would make your preserveRandomSeed really easy to write.
>
> Here's a demo that .Random.seed is not enough:
>
>> set.seed(123, normal.kind = "Box-Muller")
>> rnorm(1)
> [1] -0.1613431
>> save <- .Random.seed
>> rnorm(1)
> [1] 0.6706031
>> .Random.seed <- save
>> rnorm(1)
> [1] -0.4194403
>
> If .Random.seed were the complete state, the 2nd and 3rd rnorm results would
> be the same.

Ah... good point - I forgot about that "oddity", which is documented
in help(".Random.seed"):

".Random.seed saves the seed set for the uniform random-number
generator, at least for the system generators. It does not necessarily
save the state of other generators, and in particular does not save
the state of the Box?Muller normal generator. If you want to reproduce
work later, call set.seed (preferably with explicit values for kind
and normal.kind) rather than set .Random.seed."

So, this is is only for some of the RNG kinds.  Is the reason for this
limitation that it is not possible for R (not even the R internals) to
get hold of some of the RNG generators?  In other words, it is
unlikely to ever be fixed?

Since there is no bijective function to infer `x` such that
`set.seed(x)` resets the RNG state properly, the best we have is
'.Random.seed' for resetting it.  Would a start be to implement
preserveRandomSeed() for supported RNGkind():s and give an informative
warning in other cases?

/Henrik

>
> Duncan Murdoch
>
>
>
>>
>> /Henrik
>>
>> On Sun, Mar 4, 2018 at 1:40 PM, Gary Black <gwblack001 at sbcglobal.net>
>> wrote:
>>>
>>> Thank you, everybody, who replied!  I appreciate your valuable advise!  I
>>> will move the location of the set.seed() command to after all packages have
>>> been installed and loaded.
>>>
>>> Best regards,
>>> Gary
>>>
>>> Sent from my iPad
>>>
>>>> On Mar 4, 2018, at 12:18 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:
>>>>
>>>> On Mon, Feb 26, 2018 at 3:25 PM, Gary Black <gwblack001 at sbcglobal.net>
>>>> wrote:
>>>>
>>>> (Sorry to be a bit slow responding.)
>>>>
>>>> You have not supplied a complete example, which would be good in this
>>>> case because what you are suggesting could be a serious bug in R or a
>>>> package. Serious journals require reproducibility these days. For example,
>>>> JSS is very clear on this point.
>>>>
>>>> To your question
>>>>>
>>>>> My question simply is:  should the location of the set.seed command
>>>>> matter,
>>>>> provided that it is applied before any commands which involve
>>>>> randomness
>>>>> (such as partitioning)?
>>>>
>>>>
>>>> the answer is no, it should not matter. But the proviso is important.
>>>>
>>>> You can determine where things are messing up using something like
>>>>
>>>> set.seed(654321)
>>>> zk <- RNGkind()        # [1] "Mersenne-Twister" "Inversion"
>>>> zk
>>>> z <- runif(2)
>>>> z
>>>> set.seed(654321)
>>>>
>>>> #  install.packages(c('caret', 'ggplot2', 'e1071'))
>>>> library(caret)
>>>> all(runif(2)  == z)   # should be true but it is not always
>>>>
>>>> set.seed(654321)
>>>> library(ggplot2)
>>>> all(runif(2)  == z)   # should be true
>>>>
>>>> set.seed(654321)
>>>> library(e1071)
>>>> all(runif(2)  == z)   # should be true
>>>>
>>>> all(RNGkind() == zk)  # should be true
>>>>
>>>> On my computer package caret seems to sometimes, but not always, do
>>>> something that advances or changes the RNG. So you will need to set the seed
>>>> after that package is loaded if you want reproducibility.
>>>>
>>>> As Bill Dunlap points out, parallel can introduce much more complicated
>>>> issues. If you are in fact using parallel then we really need a new thread
>>>> with a better subject line, and the discussion will get much messier.
>>>>
>>>> The short answer is that, yes you should be able to get reproducible
>>>> results with parallel computing. If you cannot then you are almost certainly
>>>> doing something wrong. To publish you really must have reproducible results.
>>>>
>>>> In the example that Bill gave, I think the problem is that set.seed()
>>>> only resets the seed in the main thread, the nodes continue to operate with
>>>> unreset RNG. To demonstrate this to yourself you can do
>>>>
>>>> library(parallel)
>>>> cl <- parallel::makeCluster(3)
>>>> parallel::clusterCall(cl, function()set.seed(100))
>>>> parallel::clusterCall(cl, function()RNGkind())
>>>> parallel::clusterCall(cl, function()runif(2)) # similar result from all
>>>> nodes
>>>>                                                # [1] 0.3077661 0.2576725
>>>>
>>>> However, do *NOT* do that in real work. You will be getting the same RNG
>>>> stream from each node. If you are using random numbers and parallel you need
>>>> to read a lot more, and probably consider a variant of the "L'Ecuyer"
>>>> generator or something designed for parallel computing.
>>>>
>>>> One special point I will mention because it does not seem to be widely
>>>> appreciated: the number of nodes affects the random stream, so recording
>>>> the number of compute nodes along with the RNG and seed information is
>>>> important for reproducible results. This has the unfortunate consequence
>>>> that an experiment cannot be reproduced on a larger cluster. (If anyone
>>>> knows differently I would very much like to hear.)
>>>>
>>>> Paul Gilbert
>>>>
>>>>
>>>>> Hi all,
>>>>>
>>>>> For some odd reason when running na?ve bayes, k-NN, etc., I get
>>>>> slightly
>>>>> different results (e.g., error rates, classification probabilities)
>>>>> from
>>>>> run
>>>>> to run even though I am using the same random seed.
>>>>>
>>>>> Nothing else (input-wise) is changing, but my results are somewhat
>>>>> different
>>>>> from run to run.  The only randomness should be in the partitioning,
>>>>> and I
>>>>> have set the seed before this point.
>>>>>
>>>>> My question simply is:  should the location of the set.seed command
>>>>> matter,
>>>>> provided that it is applied before any commands which involve
>>>>> randomness
>>>>> (such as partitioning)?
>>>>>
>>>>> If you need to see the code, it is below:
>>>>>
>>>>> Thank you,
>>>>> Gary
>>>>>
>>>>>
>>>>> A.      Separate the original (in-sample) data from the new
>>>>> (out-of-sample)
>>>>> data.  Set a random seed.
>>>>>
>>>>>> InvestTech <- as.data.frame(InvestTechRevised)
>>>>>> outOfSample <- InvestTech[5001:nrow(InvestTech), ]
>>>>>> InvestTech <- InvestTech[1:5000, ]
>>>>>> set.seed(654321)
>>>>>
>>>>>
>>>>> B.      Install and load the caret, ggplot2 and e1071 packages.
>>>>>
>>>>>> install.packages(?caret?)
>>>>>> install.packages(?ggplot2?)
>>>>>> install.packages(?e1071?)
>>>>>> library(caret)
>>>>>> library(ggplot2)
>>>>>> library(e1071)
>>>>>
>>>>>
>>>>> C.      Bin the predictor variables with approximately equal counts
>>>>> using
>>>>> the cut_number function from the ggplot2 package.  We will use 20 bins.
>>>>>
>>>>>> InvestTech[, 1] <- cut_number(InvestTech[, 1], n = 20)
>>>>>> InvestTech[, 2] <- cut_number(InvestTech[, 2], n = 20)
>>>>>> outOfSample[, 1] <- cut_number(outOfSample[, 1], n = 20)
>>>>>> outOfSample[, 2] <- cut_number(outOfSample[, 2], n = 20)
>>>>>
>>>>>
>>>>> D.      Partition the original (in-sample) data into 60% training and
>>>>> 40%
>>>>> validation sets.
>>>>>
>>>>>> n <- nrow(InvestTech)
>>>>>> train <- sample(1:n, size = 0.6 * n, replace = FALSE)
>>>>>> InvestTechTrain <- InvestTech[train, ]
>>>>>> InvestTechVal <- InvestTech[-train, ]
>>>>>
>>>>>
>>>>> E.      Use the naiveBayes function in the e1071 package to fit the
>>>>> model.
>>>>>
>>>>>> model <- naiveBayes(`Purchase (1=yes, 0=no)` ~ ., data =
>>>>>> InvestTechTrain)
>>>>>> prob <- predict(model, newdata = InvestTechVal, type = ?raw?)
>>>>>> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>>>>>
>>>>>
>>>>> F.      Use the confusionMatrix function in the caret package to output
>>>>> the
>>>>> confusion matrix.
>>>>>
>>>>>> confMtr <- confusionMatrix(pred,unlist(InvestTechVal[, 3]),mode =
>>>>>
>>>>> ?everything?, positive = ?1?)
>>>>>>
>>>>>> accuracy <- confMtr$overall[1]
>>>>>> valError <- 1 ? accuracy
>>>>>> confMtr
>>>>>
>>>>>
>>>>> G.      Classify the 18 new (out-of-sample) readers using the following
>>>>> code.
>>>>>>
>>>>>> prob <- predict(model, newdata = outOfSample, type = ?raw?)
>>>>>> pred <- ifelse(prob[, 2] >= 0.3, 1, 0)
>>>>>> cbind(pred, prob, outOfSample[, -3])
>>>>>
>>>>>
>>>>>
>>>>>
>>>>
>>>>
>>>> If your computations involve the parallel package then set.seed(seed)
>>>> may not produce repeatable results.  E.g.,
>>>>
>>>>> cl <- parallel::makeCluster(3)  # Create cluster with 3 nodes on local
>>>>
>>>> host
>>>>>
>>>>> set.seed(100); runif(2)
>>>>
>>>> [1] 0.3077661 0.2576725
>>>>>
>>>>> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>>>>
>>>>          [,1]     [,2]     [,3]
>>>> [1,] 101.7779 102.5308 103.3459
>>>> [2,] 101.8128 102.6114 103.9102
>>>>>
>>>>>
>>>>> set.seed(100); runif(2)
>>>>
>>>> [1] 0.3077661 0.2576725
>>>>>
>>>>> parallel::parSapply(cl, 101:103, function(i)runif(2, i, i+1))
>>>>
>>>>          [,1]     [,2]     [,3]
>>>> [1,] 101.1628 102.9643 103.2684
>>>> [2,] 101.9205 102.6937 103.7907
>>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From jspark4 at uic.edu  Mon Mar  5 03:28:10 2018
From: jspark4 at uic.edu (Sparks, John)
Date: Mon, 5 Mar 2018 02:28:10 +0000
Subject: [R] Interpret List Label as Date from Quantmod getOptionChain
Message-ID: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>

Hi R Helpers,


Is it possible to interpret the top level of the list as a date after downloading all the option chain data for a ticker?


For example, after I run


aapl_total<-getOptionChain("AAPL", NULL)


the top descriptor of the lists is a date (Mar.09.2018, Mar.23.2018, etc.).


So if want to subset down to those parts of the list that correspond to say, (expiration) year=2019; or say, Mar or Apr or May of 2019, is this possible?


Guidance would be appreciated.

Thanks.


--John J. Sparks, Ph.D.




str(aapl_total)

List of 16
 $ Mar.09.2018:List of 2
  ..$ calls:'data.frame':       31 obs. of  7 variables:
  .. ..$ Strike: num [1:31] 135 143 146 147 148 ...
  .. ..$ Last  : num [1:31] 42.4 36.2 32 28.4 31 ...
  .. ..$ Chg   : num [1:31] 0 0 12.6 -4.71 0 ...
  .. ..$ Bid   : num [1:31] 41 35.8 32.8 29.1 28.1 ...
  .. ..$ Ask   : num [1:31] 41.5 36.4 33.4 29.5 28.6 ...
  .. ..$ Vol   : int [1:31] 5 2 1 45 2 2 90 3 11 129 ...
  .. ..$ OI    : int [1:31] 17 0 117 58 3 22 171 84 707 238 ...
  ..$ puts :'data.frame':       37 obs. of  7 variables:
  .. ..$ Strike: num [1:37] 130 135 138 139 140 141 142 143 144 145 ...
  .. ..$ Last  : num [1:37] 0.01 0.07 0.27 0.04 0.03 0.98 0.05 0.03 0.03 0.01 ...
  .. ..$ Chg   : num [1:37] 0 -0.12 0 0 0 0 -0.05 0 0 -0.01 ...
  .. ..$ Bid   : num [1:37] 0 0.01 0 0 0 0.05 0.06 0 0 0 ...
  .. ..$ Ask   : num [1:37] 0.04 0.07 0.02 0.03 0.02 0.13 0.13 0.03 0.03 0.02 ...
  .. ..$ Vol   : int [1:37] 2 11 1 10 5 0 1 150 1 127 ...
  .. ..$ OI    : int [1:37] 8 12 1 0 723 192 37 275 125 297 ...
 $ Mar.23.2018:List of 2
  ..$ calls:'data.frame':       35 obs. of  7 variables:



	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar  5 03:38:44 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 4 Mar 2018 18:38:44 -0800
Subject: [R] Interpret List Label as Date from Quantmod getOptionChain
In-Reply-To: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
References: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
Message-ID: <CAGxFJbSa64D-5cwTYzUQyChD2Dr4=BcBz1Qb5j-ghFWkkZRLyA@mail.gmail.com>

Package?

The **names** of the top levels of your lists, "Mar.09.2018", "Mar.23.2018"
certainly look like dates and if they are -- I have no idea what
package/context is -- they certainly could be formatted as such. See e.g.
"date-time" . There are also several package that provide date tools.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Mar 4, 2018 at 6:28 PM, Sparks, John <jspark4 at uic.edu> wrote:

> Hi R Helpers,
>
>
> Is it possible to interpret the top level of the list as a date after
> downloading all the option chain data for a ticker?
>
>
> For example, after I run
>
>
> aapl_total<-getOptionChain("AAPL", NULL)
>
>
> the top descriptor of the lists is a date (Mar.09.2018, Mar.23.2018, etc.).
>
>
> So if want to subset down to those parts of the list that correspond to
> say, (expiration) year=2019; or say, Mar or Apr or May of 2019, is this
> possible?
>
>
> Guidance would be appreciated.
>
> Thanks.
>
>
> --John J. Sparks, Ph.D.
>
>
>
>
> str(aapl_total)
>
> List of 16
>  $ Mar.09.2018:List of 2
>   ..$ calls:'data.frame':       31 obs. of  7 variables:
>   .. ..$ Strike: num [1:31] 135 143 146 147 148 ...
>   .. ..$ Last  : num [1:31] 42.4 36.2 32 28.4 31 ...
>   .. ..$ Chg   : num [1:31] 0 0 12.6 -4.71 0 ...
>   .. ..$ Bid   : num [1:31] 41 35.8 32.8 29.1 28.1 ...
>   .. ..$ Ask   : num [1:31] 41.5 36.4 33.4 29.5 28.6 ...
>   .. ..$ Vol   : int [1:31] 5 2 1 45 2 2 90 3 11 129 ...
>   .. ..$ OI    : int [1:31] 17 0 117 58 3 22 171 84 707 238 ...
>   ..$ puts :'data.frame':       37 obs. of  7 variables:
>   .. ..$ Strike: num [1:37] 130 135 138 139 140 141 142 143 144 145 ...
>   .. ..$ Last  : num [1:37] 0.01 0.07 0.27 0.04 0.03 0.98 0.05 0.03 0.03
> 0.01 ...
>   .. ..$ Chg   : num [1:37] 0 -0.12 0 0 0 0 -0.05 0 0 -0.01 ...
>   .. ..$ Bid   : num [1:37] 0 0.01 0 0 0 0.05 0.06 0 0 0 ...
>   .. ..$ Ask   : num [1:37] 0.04 0.07 0.02 0.03 0.02 0.13 0.13 0.03 0.03
> 0.02 ...
>   .. ..$ Vol   : int [1:37] 2 11 1 10 5 0 1 150 1 127 ...
>   .. ..$ OI    : int [1:37] 8 12 1 0 723 192 37 275 125 297 ...
>  $ Mar.23.2018:List of 2
>   ..$ calls:'data.frame':       35 obs. of  7 variables:
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jspark4 at uic.edu  Mon Mar  5 03:46:45 2018
From: jspark4 at uic.edu (Sparks, John)
Date: Mon, 5 Mar 2018 02:46:45 +0000
Subject: [R] Interpret List Label as Date from Quantmod getOptionChain
In-Reply-To: <CAGxFJbSa64D-5cwTYzUQyChD2Dr4=BcBz1Qb5j-ghFWkkZRLyA@mail.gmail.com>
References: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>,
 <CAGxFJbSa64D-5cwTYzUQyChD2Dr4=BcBz1Qb5j-ghFWkkZRLyA@mail.gmail.com>
Message-ID: <BN6PR05MB3586084F69FB8BEC34073711FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>

Package?  Quantmod.  In the subject line.


I agree that they look like dates, I don't know how to determine if they are actually dates.


Josh Ulrich usually answers questions along these lines very informatively and quickly.   One reasonable course of action is to wait to see if he does the same with this one.


--JJS


________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Sunday, March 4, 2018 8:38 PM
To: Sparks, John
Cc: r-help at r-project.org
Subject: Re: [R] Interpret List Label as Date from Quantmod getOptionChain

Package?

The **names** of the top levels of your lists, "Mar.09.2018", "Mar.23.2018" certainly look like dates and if they are -- I have no idea what package/context is -- they certainly could be formatted as such. See e.g. "date-time" . There are also several package that provide date tools.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Mar 4, 2018 at 6:28 PM, Sparks, John <jspark4 at uic.edu<mailto:jspark4 at uic.edu>> wrote:
Hi R Helpers,


Is it possible to interpret the top level of the list as a date after downloading all the option chain data for a ticker?


For example, after I run


aapl_total<-getOptionChain("AAPL", NULL)


the top descriptor of the lists is a date (Mar.09.2018, Mar.23.2018, etc.).


So if want to subset down to those parts of the list that correspond to say, (expiration) year=2019; or say, Mar or Apr or May of 2019, is this possible?


Guidance would be appreciated.

Thanks.


--John J. Sparks, Ph.D.




str(aapl_total)

List of 16
 $ Mar.09.2018:List of 2
  ..$ calls:'data.frame':       31 obs. of  7 variables:
  .. ..$ Strike: num [1:31] 135 143 146 147 148 ...
  .. ..$ Last  : num [1:31] 42.4 36.2 32 28.4 31 ...
  .. ..$ Chg   : num [1:31] 0 0 12.6 -4.71 0 ...
  .. ..$ Bid   : num [1:31] 41 35.8 32.8 29.1 28.1 ...
  .. ..$ Ask   : num [1:31] 41.5 36.4 33.4 29.5 28.6 ...
  .. ..$ Vol   : int [1:31] 5 2 1 45 2 2 90 3 11 129 ...
  .. ..$ OI    : int [1:31] 17 0 117 58 3 22 171 84 707 238 ...
  ..$ puts :'data.frame':       37 obs. of  7 variables:
  .. ..$ Strike: num [1:37] 130 135 138 139 140 141 142 143 144 145 ...
  .. ..$ Last  : num [1:37] 0.01 0.07 0.27 0.04 0.03 0.98 0.05 0.03 0.03 0.01 ...
  .. ..$ Chg   : num [1:37] 0 -0.12 0 0 0 0 -0.05 0 0 -0.01 ...
  .. ..$ Bid   : num [1:37] 0 0.01 0 0 0 0.05 0.06 0 0 0 ...
  .. ..$ Ask   : num [1:37] 0.04 0.07 0.02 0.03 0.02 0.13 0.13 0.03 0.03 0.02 ...
  .. ..$ Vol   : int [1:37] 2 11 1 10 5 0 1 150 1 127 ...
  .. ..$ OI    : int [1:37] 8 12 1 0 723 192 37 275 125 297 ...
 $ Mar.23.2018:List of 2
  ..$ calls:'data.frame':       35 obs. of  7 variables:



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
R-help -- Main R Mailing List: Primary help - Homepage - SfS<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and the availability of new code, questions and answers about problems and solutions using R ...



PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From edd at debian.org  Mon Mar  5 03:57:46 2018
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 4 Mar 2018 20:57:46 -0600
Subject: [R] Interpret List Label as Date from Quantmod getOptionChain
In-Reply-To: <BN6PR05MB3586084F69FB8BEC34073711FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
References: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
 <CAGxFJbSa64D-5cwTYzUQyChD2Dr4=BcBz1Qb5j-ghFWkkZRLyA@mail.gmail.com>
 <BN6PR05MB3586084F69FB8BEC34073711FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
Message-ID: <23196.45610.344244.77022@rob.eddelbuettel.com>


On 5 March 2018 at 02:46, Sparks, John wrote:
| I agree that they look like dates, I don't know how to determine if they are actually dates.

You know options but you are confused about maturity dates, i.e. expiry?

In information in that list (ie along the date dimension) is the expiry; at
each date you have another list for both puts and calls, and inside each of
those a grid given by the active strikes (ie where bids/asks/trades happen).

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jspark4 at uic.edu  Mon Mar  5 04:13:47 2018
From: jspark4 at uic.edu (Sparks, John)
Date: Mon, 5 Mar 2018 03:13:47 +0000
Subject: [R] Interpret List Label as Date from Quantmod getOptionChain
In-Reply-To: <23196.45610.344244.77022@rob.eddelbuettel.com>
References: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
 <CAGxFJbSa64D-5cwTYzUQyChD2Dr4=BcBz1Qb5j-ghFWkkZRLyA@mail.gmail.com>
 <BN6PR05MB3586084F69FB8BEC34073711FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>,
 <23196.45610.344244.77022@rob.eddelbuettel.com>
Message-ID: <BN6PR05MB35867BD503CE046D11916BADFADA0@BN6PR05MB3586.namprd05.prod.outlook.com>

Hi Dirk,


Thanks for your note.


I understand that expiry dates are the dates that the option expires, so I don't think that I am confused about that (although the upper limits of one's confusion is difficult to accurately estimate).


My lack of clarity come from treating those "dates"  as actual dates as opposed to strings, which one could reasonably interpret them to be from their appearance, yet the str() lists them in date order, not alphabetical order.


So if I execute


library(quantmod)

#in fairness, I did not include this last time and my example was therefore not reproducible.  Apologies to Bert and everyone else #for not following the posting guidelines.


aapl_total<-getOptionChain("AAPL", NULL)


How could I then get the subset of the entire list which only has expiry dates in 2019, or more specifically, in Mar or Apr or May of 2019?


Guidance (that is not too burdensome) would be appreciated.


--JJS




________________________________
From: Dirk Eddelbuettel <dirk.eddelbuettel at gmail.com> on behalf of Dirk Eddelbuettel <edd at debian.org>
Sent: Sunday, March 4, 2018 8:57 PM
To: Sparks, John
Cc: Bert Gunter; r-help at r-project.org
Subject: Re: [R] Interpret List Label as Date from Quantmod getOptionChain


On 5 March 2018 at 02:46, Sparks, John wrote:
| I agree that they look like dates, I don't know how to determine if they are actually dates.

You know options but you are confused about maturity dates, i.e. expiry?

In information in that list (ie along the date dimension) is the expiry; at
each date you have another list for both puts and calls, and inside each of
those a grid given by the active strikes (ie where bids/asks/trades happen).

Dirk

--
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
Dirk Eddelbuettel<http://dirk.eddelbuettel.com/>
dirk.eddelbuettel.com
Welcome. I contribute to several open source efforts, mostly Debian and R. Besides looking after a number of Debian packages, I ...




	[[alternative HTML version deleted]]


From edd at debian.org  Mon Mar  5 04:41:44 2018
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 4 Mar 2018 21:41:44 -0600
Subject: [R] Interpret List Label as Date from Quantmod getOptionChain
In-Reply-To: <BN6PR05MB35867BD503CE046D11916BADFADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
References: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
 <CAGxFJbSa64D-5cwTYzUQyChD2Dr4=BcBz1Qb5j-ghFWkkZRLyA@mail.gmail.com>
 <BN6PR05MB3586084F69FB8BEC34073711FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
 <23196.45610.344244.77022@rob.eddelbuettel.com>
 <BN6PR05MB35867BD503CE046D11916BADFADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
Message-ID: <23196.48248.708862.672189@rob.eddelbuettel.com>


On 5 March 2018 at 03:13, Sparks, John wrote:
| library(quantmod)
| #in fairness, I did not include this last time and my example was therefore not reproducible.  Apologies to Bert and everyone else #for not following the posting guidelines.
| aapl_total<-getOptionChain("AAPL", NULL)>
| 
| How could I then get the subset of the entire list which only has expiry dates in 2019, or more specifically, in Mar or Apr or May of 2019?

Here you go:

R> aapl_total<-getOptionChain("AAPL", NULL)     # your query
R> names(aapl_total)                            # the list element names
 [1] "Mar.09.2018" "Mar.23.2018" "Mar.29.2018" "Apr.06.2018" "Apr.13.2018" "Apr.20.2018" "May.18.2018"
 [8] "Jun.15.2018" "Aug.17.2018" "Sep.21.2018" "Oct.19.2018" "Nov.16.2018" "Jan.18.2019" "Jun.21.2019"
[15] "Jan.17.2020" "Jun.19.2020"
R> library(anytime)    # one of many tools to parse dates, this one is easiest in my biased view
R> anydate(names(aapl_total))
 [1] "2018-03-09" "2018-03-23" "2018-03-29" "2018-04-06" "2018-04-13" "2018-04-20" "2018-05-18"
 [8] "2018-06-15" "2018-08-17" "2018-09-21" "2018-10-19" "2018-11-16" "2019-01-18" "2019-06-21"
[15] "2020-01-17" "2020-06-19"
R> dvec <- anydate(names(aapl_total))           # helper variable
R> ind <- dvec >= anydate("2018-04-01") & dvec <= anydate("2018-04-30")     # one example
R> ind
 [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
R> str(aapl_total[ind])                         # index return object by desired dates
List of 3
 $ Apr.06.2018:List of 2
  ..$ calls:'data.frame':	24 obs. of  7 variables:
  .. ..$ Strike: num [1:24] 145 150 152 155 158 ...
  .. ..$ Last  : num [1:24] 30.4 24 27.1 20.9 22.1 ...
  .. ..$ Chg   : num [1:24] -3.12 0 0 -2.87 0 ...
  .. ..$ Bid   : num [1:24] 31.4 26.6 24.1 21.8 21.9 ...
  .. ..$ Ask   : num [1:24] 31.9 27.1 24.7 22.3 22.5 ...
  .. ..$ Vol   : int [1:24] 2 1 50 2 216 51 50 55 33 109 ...
  .. ..$ OI    : int [1:24] 30 1 50 2 0 32 57 101 136 297 ...
  ..$ puts :'data.frame':	21 obs. of  7 variables:
  .. ..$ Strike: num [1:21] 145 147 148 149 150 ...
  .. ..$ Last  : num [1:21] 0.27 0.14 0.17 0.18 0.36 0.49 0.68 0.81 0.96 1.17 ...
  .. ..$ Chg   : num [1:21] 0.13 0 -0.08 0 -0.07 ...
  .. ..$ Bid   : num [1:21] 0.14 0.18 0.13 0.23 0.27 0.35 0.46 0.61 0.81 1.06 ...
  .. ..$ Ask   : num [1:21] 0.24 0.28 0.21 0.35 0.36 0.45 0.56 0.71 0.9 1.17 ...
  .. ..$ Vol   : int [1:21] 12 1 1 3 86 15 31 74 39 213 ...
  .. ..$ OI    : int [1:21] 97 1 2 14 177 395 160 368 271 211 ...
 $ Apr.13.2018:List of 2
  ..$ calls:'data.frame':	19 obs. of  7 variables:
  .. ..$ Strike: num [1:19] 155 160 162 165 168 ...
  .. ..$ Last  : num [1:19] 21.2 16.9 14.9 13.1 10.7 ...
  .. ..$ Chg   : int [1:19] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ Bid   : num [1:19] 21.6 17.3 15.2 13.3 11.3 ...
  .. ..$ Ask   : num [1:19] 22.9 17.9 15.7 13.6 11.5 ...
  .. ..$ Vol   : int [1:19] 20 1 7 44 46 22 62 313 71 327 ...
  .. ..$ OI    : int [1:19] 20 20 6 11 11 0 153 156 19 54 ...
  ..$ puts :'data.frame':	18 obs. of  7 variables:
  .. ..$ Strike: num [1:18] 145 148 149 150 152 ...
  .. ..$ Last  : num [1:18] 0.38 0.48 0.56 0.56 0.69 0.87 1.04 1.05 1.34 1.75 ...
  .. ..$ Chg   : int [1:18] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ Bid   : num [1:18] 0.06 0.19 0.22 0.28 0.42 0.54 0.73 0.98 1.28 1.64 ...
  .. ..$ Ask   : num [1:18] 0.6 0.42 0.45 0.47 0.58 0.72 0.9 1.13 1.44 1.8 ...
  .. ..$ Vol   : int [1:18] 25 103 1 50 64 74 24 47 100 324 ...
  .. ..$ OI    : int [1:18] 0 6 0 0 7 10 11 19 56 19 ...
 $ Apr.20.2018:List of 2
  ..$ calls:'data.frame':	60 obs. of  7 variables:
  .. ..$ Strike: num [1:60] 2.5 5 7.5 10 12.5 17.5 22.5 40 50 55 ...
  .. ..$ Last  : num [1:60] 171 173 171 158 163 ...
  .. ..$ Chg   : num [1:60] -1 0 0 0 -3.6 ...
  .. ..$ Bid   : num [1:60] 166 166 163 148 164 ...
  .. ..$ Ask   : num [1:60] 168 167 165 152 164 ...
  .. ..$ Vol   : int [1:60] 5 10 10 10 1 10 5 4 300 10 ...
  .. ..$ OI    : int [1:60] 5 15 10 5 1 10 5 0 0 0 ...
  ..$ puts :'data.frame':	48 obs. of  7 variables:
  .. ..$ Strike: num [1:48] 2.5 50 55 60 65 70 75 80 85 90 ...
  .. ..$ Last  : num [1:48] 0.01 0.01 0.01 0.02 0.02 0.01 0.01 0.02 0.07 0.02 ...
  .. ..$ Chg   : num [1:48] 0 0 -0.01 0 -0.01 -0.02 0 0 0 0 ...
  .. ..$ Bid   : num [1:48] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ Ask   : num [1:48] 0.02 0.02 0.02 0.03 0.07 0.02 0.02 0.03 0.04 0.04 ...
  .. ..$ Vol   : int [1:48] 1 2 1 212 2 5 3 32 385 11 ...
  .. ..$ OI    : int [1:48] 1 0 1 212 621 473 3529 362 1823 1164 ...
R> 

You probably want such questions on the r-sig-finance list.

Cheers from across town,  Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From jspark4 at uic.edu  Mon Mar  5 05:05:40 2018
From: jspark4 at uic.edu (Sparks, John)
Date: Mon, 5 Mar 2018 04:05:40 +0000
Subject: [R] Interpret List Label as Date from Quantmod getOptionChain
In-Reply-To: <23196.48248.708862.672189@rob.eddelbuettel.com>
References: <BN6PR05MB35863AB7323ED873FC27DA45FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
 <CAGxFJbSa64D-5cwTYzUQyChD2Dr4=BcBz1Qb5j-ghFWkkZRLyA@mail.gmail.com>
 <BN6PR05MB3586084F69FB8BEC34073711FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>
 <23196.45610.344244.77022@rob.eddelbuettel.com>
 <BN6PR05MB35867BD503CE046D11916BADFADA0@BN6PR05MB3586.namprd05.prod.outlook.com>,
 <23196.48248.708862.672189@rob.eddelbuettel.com>
Message-ID: <BN6PR05MB35864A80DF4D226B86A73389FADA0@BN6PR05MB3586.namprd05.prod.outlook.com>

Looks great.  Thanks!


--JJS


________________________________
From: Dirk Eddelbuettel <dirk.eddelbuettel at gmail.com> on behalf of Dirk Eddelbuettel <edd at debian.org>
Sent: Sunday, March 4, 2018 9:41 PM
To: Sparks, John
Cc: Dirk Eddelbuettel; r-help at r-project.org
Subject: Re: [R] Interpret List Label as Date from Quantmod getOptionChain


On 5 March 2018 at 03:13, Sparks, John wrote:
| library(quantmod)
| #in fairness, I did not include this last time and my example was therefore not reproducible.  Apologies to Bert and everyone else #for not following the posting guidelines.
| aapl_total<-getOptionChain("AAPL", NULL)>
|
| How could I then get the subset of the entire list which only has expiry dates in 2019, or more specifically, in Mar or Apr or May of 2019?

Here you go:

R> aapl_total<-getOptionChain("AAPL", NULL)     # your query
R> names(aapl_total)                            # the list element names
 [1] "Mar.09.2018" "Mar.23.2018" "Mar.29.2018" "Apr.06.2018" "Apr.13.2018" "Apr.20.2018" "May.18.2018"
 [8] "Jun.15.2018" "Aug.17.2018" "Sep.21.2018" "Oct.19.2018" "Nov.16.2018" "Jan.18.2019" "Jun.21.2019"
[15] "Jan.17.2020" "Jun.19.2020"
R> library(anytime)    # one of many tools to parse dates, this one is easiest in my biased view
R> anydate(names(aapl_total))
 [1] "2018-03-09" "2018-03-23" "2018-03-29" "2018-04-06" "2018-04-13" "2018-04-20" "2018-05-18"
 [8] "2018-06-15" "2018-08-17" "2018-09-21" "2018-10-19" "2018-11-16" "2019-01-18" "2019-06-21"
[15] "2020-01-17" "2020-06-19"
R> dvec <- anydate(names(aapl_total))           # helper variable
R> ind <- dvec >= anydate("2018-04-01") & dvec <= anydate("2018-04-30")     # one example
R> ind
 [1] FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
R> str(aapl_total[ind])                         # index return object by desired dates
List of 3
 $ Apr.06.2018:List of 2
  ..$ calls:'data.frame':       24 obs. of  7 variables:
  .. ..$ Strike: num [1:24] 145 150 152 155 158 ...
  .. ..$ Last  : num [1:24] 30.4 24 27.1 20.9 22.1 ...
  .. ..$ Chg   : num [1:24] -3.12 0 0 -2.87 0 ...
  .. ..$ Bid   : num [1:24] 31.4 26.6 24.1 21.8 21.9 ...
  .. ..$ Ask   : num [1:24] 31.9 27.1 24.7 22.3 22.5 ...
  .. ..$ Vol   : int [1:24] 2 1 50 2 216 51 50 55 33 109 ...
  .. ..$ OI    : int [1:24] 30 1 50 2 0 32 57 101 136 297 ...
  ..$ puts :'data.frame':       21 obs. of  7 variables:
  .. ..$ Strike: num [1:21] 145 147 148 149 150 ...
  .. ..$ Last  : num [1:21] 0.27 0.14 0.17 0.18 0.36 0.49 0.68 0.81 0.96 1.17 ...
  .. ..$ Chg   : num [1:21] 0.13 0 -0.08 0 -0.07 ...
  .. ..$ Bid   : num [1:21] 0.14 0.18 0.13 0.23 0.27 0.35 0.46 0.61 0.81 1.06 ...
  .. ..$ Ask   : num [1:21] 0.24 0.28 0.21 0.35 0.36 0.45 0.56 0.71 0.9 1.17 ...
  .. ..$ Vol   : int [1:21] 12 1 1 3 86 15 31 74 39 213 ...
  .. ..$ OI    : int [1:21] 97 1 2 14 177 395 160 368 271 211 ...
 $ Apr.13.2018:List of 2
  ..$ calls:'data.frame':       19 obs. of  7 variables:
  .. ..$ Strike: num [1:19] 155 160 162 165 168 ...
  .. ..$ Last  : num [1:19] 21.2 16.9 14.9 13.1 10.7 ...
  .. ..$ Chg   : int [1:19] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ Bid   : num [1:19] 21.6 17.3 15.2 13.3 11.3 ...
  .. ..$ Ask   : num [1:19] 22.9 17.9 15.7 13.6 11.5 ...
  .. ..$ Vol   : int [1:19] 20 1 7 44 46 22 62 313 71 327 ...
  .. ..$ OI    : int [1:19] 20 20 6 11 11 0 153 156 19 54 ...
  ..$ puts :'data.frame':       18 obs. of  7 variables:
  .. ..$ Strike: num [1:18] 145 148 149 150 152 ...
  .. ..$ Last  : num [1:18] 0.38 0.48 0.56 0.56 0.69 0.87 1.04 1.05 1.34 1.75 ...
  .. ..$ Chg   : int [1:18] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ Bid   : num [1:18] 0.06 0.19 0.22 0.28 0.42 0.54 0.73 0.98 1.28 1.64 ...
  .. ..$ Ask   : num [1:18] 0.6 0.42 0.45 0.47 0.58 0.72 0.9 1.13 1.44 1.8 ...
  .. ..$ Vol   : int [1:18] 25 103 1 50 64 74 24 47 100 324 ...
  .. ..$ OI    : int [1:18] 0 6 0 0 7 10 11 19 56 19 ...
 $ Apr.20.2018:List of 2
  ..$ calls:'data.frame':       60 obs. of  7 variables:
  .. ..$ Strike: num [1:60] 2.5 5 7.5 10 12.5 17.5 22.5 40 50 55 ...
  .. ..$ Last  : num [1:60] 171 173 171 158 163 ...
  .. ..$ Chg   : num [1:60] -1 0 0 0 -3.6 ...
  .. ..$ Bid   : num [1:60] 166 166 163 148 164 ...
  .. ..$ Ask   : num [1:60] 168 167 165 152 164 ...
  .. ..$ Vol   : int [1:60] 5 10 10 10 1 10 5 4 300 10 ...
  .. ..$ OI    : int [1:60] 5 15 10 5 1 10 5 0 0 0 ...
  ..$ puts :'data.frame':       48 obs. of  7 variables:
  .. ..$ Strike: num [1:48] 2.5 50 55 60 65 70 75 80 85 90 ...
  .. ..$ Last  : num [1:48] 0.01 0.01 0.01 0.02 0.02 0.01 0.01 0.02 0.07 0.02 ...
  .. ..$ Chg   : num [1:48] 0 0 -0.01 0 -0.01 -0.02 0 0 0 0 ...
  .. ..$ Bid   : num [1:48] 0 0 0 0 0 0 0 0 0 0 ...
  .. ..$ Ask   : num [1:48] 0.02 0.02 0.02 0.03 0.07 0.02 0.02 0.03 0.04 0.04 ...
  .. ..$ Vol   : int [1:48] 1 2 1 212 2 5 3 32 385 11 ...
  .. ..$ OI    : int [1:48] 1 0 1 212 621 473 3529 362 1823 1164 ...
R>

You probably want such questions on the r-sig-finance list.

Cheers from across town,  Dirk

--
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
Dirk Eddelbuettel<http://dirk.eddelbuettel.com/>
dirk.eddelbuettel.com
Welcome. I contribute to several open source efforts, mostly Debian and R. Besides looking after a number of Debian packages, I ...




	[[alternative HTML version deleted]]


From JohnSparks at msn.com  Mon Mar  5 03:14:43 2018
From: JohnSparks at msn.com (John Sparks)
Date: Mon, 5 Mar 2018 02:14:43 +0000
Subject: [R] quantmod getOptionChain Interpret List Label As Date
Message-ID: <DM3PR20MB0540E36B092B931DB8C27741CEDA0@DM3PR20MB0540.namprd20.prod.outlook.com>

Hi R Helpers,


Is it possible to interpret the top level of the list as a date after downloading all the option chain data for a ticker?


For example, after I run


aapl_total<-getOptionChain("AAPL", NULL)


the top descriptor of the lists is a date (Mar.09.2018, Mar.23.2018, etc.).


So if want to subset down to those parts of the list that correspond to say, (expiration) year=2019; or say, Mar or Apr or May of 2019, is this possible?


Guidance would be appreciated.

Thanks.


--John J. Sparks, Ph.D.




str(aapl_total)

List of 16
 $ Mar.09.2018:List of 2
  ..$ calls:'data.frame':       31 obs. of  7 variables:
  .. ..$ Strike: num [1:31] 135 143 146 147 148 ...
  .. ..$ Last  : num [1:31] 42.4 36.2 32 28.4 31 ...
  .. ..$ Chg   : num [1:31] 0 0 12.6 -4.71 0 ...
  .. ..$ Bid   : num [1:31] 41 35.8 32.8 29.1 28.1 ...
  .. ..$ Ask   : num [1:31] 41.5 36.4 33.4 29.5 28.6 ...
  .. ..$ Vol   : int [1:31] 5 2 1 45 2 2 90 3 11 129 ...
  .. ..$ OI    : int [1:31] 17 0 117 58 3 22 171 84 707 238 ...
  ..$ puts :'data.frame':       37 obs. of  7 variables:
  .. ..$ Strike: num [1:37] 130 135 138 139 140 141 142 143 144 145 ...
  .. ..$ Last  : num [1:37] 0.01 0.07 0.27 0.04 0.03 0.98 0.05 0.03 0.03 0.01 ...
  .. ..$ Chg   : num [1:37] 0 -0.12 0 0 0 0 -0.05 0 0 -0.01 ...
  .. ..$ Bid   : num [1:37] 0 0.01 0 0 0 0.05 0.06 0 0 0 ...
  .. ..$ Ask   : num [1:37] 0.04 0.07 0.02 0.03 0.02 0.13 0.13 0.03 0.03 0.02 ...
  .. ..$ Vol   : int [1:37] 2 11 1 10 5 0 1 150 1 127 ...
  .. ..$ OI    : int [1:37] 8 12 1 0 723 192 37 275 125 297 ...
 $ Mar.23.2018:List of 2
  ..$ calls:'data.frame':       35 obs. of  7 variables:



	[[alternative HTML version deleted]]


From mtsagris at yahoo.gr  Mon Mar  5 11:51:32 2018
From: mtsagris at yahoo.gr (michael tsagris)
Date: Mon, 5 Mar 2018 10:51:32 +0000 (UTC)
Subject: [R] Problem with Rd2.tex tduring compilation
References: <2027377563.15687851.1520247092785.ref@mail.yahoo.com>
Message-ID: <2027377563.15687851.1520247092785@mail.yahoo.com>

Hello, I am receiving this message when uploading my R package to rdevel.
https://win-builder.r-project.org/incoming_pretest/180305_110240_Compositional_29/00check.log
Can anybody please help? 

	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Mar  5 13:15:21 2018
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 5 Mar 2018 12:15:21 +0000
Subject: [R] Problem with Rd2.tex tduring compilation
In-Reply-To: <2027377563.15687851.1520247092785@mail.yahoo.com>
References: <2027377563.15687851.1520247092785.ref@mail.yahoo.com>
 <2027377563.15687851.1520247092785@mail.yahoo.com>
Message-ID: <86bac8c3-1ada-d3f1-2907-875aa431748a@dewey.myzen.co.uk>

The error is that one of your documentation files is failing. Try 
compiling each one separately with
R CMD Rd2pdf yourfilenamehere.Rd
and see what happens.

There is a list especially for package developers which might be better 
in future.

Michael

On 05/03/2018 10:51, michael tsagris via R-help wrote:
> Hello, I am receiving this message when uploading my R package to rdevel.
> https://win-builder.r-project.org/incoming_pretest/180305_110240_Compositional_29/00check.log
> Can anybody please help?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From mtsagris at yahoo.gr  Mon Mar  5 14:46:01 2018
From: mtsagris at yahoo.gr (michael tsagris)
Date: Mon, 5 Mar 2018 13:46:01 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBQcm9ibGVtIHdpdGggUmQyLnRleCB0ZHVy?=
 =?utf-8?q?ing_compilation?=
In-Reply-To: <86bac8c3-1ada-d3f1-2907-875aa431748a@dewey.myzen.co.uk>
References: <2027377563.15687851.1520247092785.ref@mail.yahoo.com>
 <2027377563.15687851.1520247092785@mail.yahoo.com>
 <86bac8c3-1ada-d3f1-2907-875aa431748a@dewey.myzen.co.uk>
Message-ID: <235279152.15952334.1520257561779@mail.yahoo.com>

Hi and thanks for the prompt reply. I cannot say I understood or know what to do. 
Can you please tell me which is this mailing list?
 

    ???? 2:15 ?.?. ???????, 5 ??????? 2018, ?/? Michael Dewey <lists at dewey.myzen.co.uk> ??????:
 

 The error is that one of your documentation files is failing. Try 
compiling each one separately with
R CMD Rd2pdf yourfilenamehere.Rd
and see what happens.

There is a list especially for package developers which might be better 
in future.

Michael

On 05/03/2018 10:51, michael tsagris via R-help wrote:
> Hello, I am receiving this message when uploading my R package to rdevel.
> https://win-builder.r-project.org/incoming_pretest/180305_110240_Compositional_29/00check.log
> Can anybody please help?
> 
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


   
	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Mon Mar  5 14:59:05 2018
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Mon, 5 Mar 2018 13:59:05 +0000
Subject: [R] 
 =?utf-8?b?zqPPh861z4Q6ICBQcm9ibGVtIHdpdGggUmQyLnRleCB0ZHVy?=
 =?utf-8?q?ing_compilation?=
In-Reply-To: <235279152.15952334.1520257561779@mail.yahoo.com>
References: <2027377563.15687851.1520247092785.ref@mail.yahoo.com>
 <2027377563.15687851.1520247092785@mail.yahoo.com>
 <86bac8c3-1ada-d3f1-2907-875aa431748a@dewey.myzen.co.uk>
 <235279152.15952334.1520257561779@mail.yahoo.com>
Message-ID: <0e594c03-65b1-ba7c-7f0b-f8d9aeff20d5@dewey.myzen.co.uk>

https://stat.ethz.ch/mailman/listinfo/r-package-devel

On 05/03/2018 13:46, michael tsagris wrote:
> Hi and thanks for the prompt reply. I cannot say I understood or know 
> what to do.
> Can you please tell me which is this mailing list?
> 
> 
> 
> ???? 2:15 ?.?. ???????, 5 ??????? 2018, ?/? Michael Dewey 
> <lists at dewey.myzen.co.uk> ??????:
> 
> 
> The error is that one of your documentation files is failing. Try
> compiling each one separately with
> R CMD Rd2pdf yourfilenamehere.Rd
> and see what happens.
> 
> There is a list especially for package developers which might be better
> in future.
> 
> Michael
> 
> On 05/03/2018 10:51, michael tsagris via R-help wrote:
>  > Hello, I am receiving this message when uploading my R package to rdevel.
>  > 
> https://win-builder.r-project.org/incoming_pretest/180305_110240_Compositional_29/00check.log
>  > Can anybody please help?
> 
>  >
>  > ??? [[alternative HTML version deleted]]
>  >
>  > ______________________________________________
>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
>  > and provide commented, minimal, self-contained, reproducible code.
>  >
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From neerajdhanraj at gmail.com  Fri Mar  2 17:59:45 2018
From: neerajdhanraj at gmail.com (Neeraj Dhanraj)
Date: Fri, 2 Mar 2018 22:29:45 +0530
Subject: [R] [R-pkgs] WindCurves
Message-ID: <CAC58_YkNk8wNsn38UUanEprg1xGGRqMb1C6vc-9KS2MzL17Y6Q@mail.gmail.com>

Dear all
Have a look at 'WindCurves' package.
The package WindCurves is a tool used to fit the wind turbine power curves.
It can be useful for researchers, data analysts/scientist, practitioners,
statistians and students working on wind turbine power curves.

The package and Vignette are available at:

https://CRAN.R-project.org/package=WindCurves
<https://cran.r-project.org/package=WindCurves>

https://cran.r-project.org/web/packages/WindCurves/
vignettes/WindCurves_Info.html

Feedback and proposals for research collaborations are welcomed.

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From bgunter.4567 at gmail.com  Mon Mar  5 15:56:29 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Mar 2018 06:56:29 -0800
Subject: [R] WAAAYYY OFF TOPIC -- For Statistics Buffs only
Message-ID: <CAGxFJbR7V74kUC4frSkdZ768rdZqQmtXBde5bpv=U+NFhs2Oxg@mail.gmail.com>

A really nice example of an instance where an "outlier" was the whole story
scientifically and hiding it with statistical summaries, here an "average"
of some sort, lost the science.  Moral: "Look at your data and think."
(Ellis Ott)

https://www.sciencenews.org/article/proxima-centauri-flare-may-have-fried-earths-nearest-exoplanet?tgt=nr

Cheers,
Bert

	[[alternative HTML version deleted]]


From mtsagris at yahoo.gr  Mon Mar  5 16:00:36 2018
From: mtsagris at yahoo.gr (michael tsagris)
Date: Mon, 5 Mar 2018 15:00:36 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6IM6jz4fOtc+EOiAgUHJvYmxlbSB3aXRoIFJk?=
 =?utf-8?q?2=2Etex_tduring_compilation?=
In-Reply-To: <0e594c03-65b1-ba7c-7f0b-f8d9aeff20d5@dewey.myzen.co.uk>
References: <2027377563.15687851.1520247092785.ref@mail.yahoo.com>
 <2027377563.15687851.1520247092785@mail.yahoo.com>
 <86bac8c3-1ada-d3f1-2907-875aa431748a@dewey.myzen.co.uk>
 <235279152.15952334.1520257561779@mail.yahoo.com>
 <0e594c03-65b1-ba7c-7f0b-f8d9aeff20d5@dewey.myzen.co.uk>
Message-ID: <1202798866.16080886.1520262036465@mail.yahoo.com>

Cheers. 
 

    ???? 3:59 ?.?. ???????, 5 ??????? 2018, ?/? Michael Dewey <lists at dewey.myzen.co.uk> ??????:
 

 https://stat.ethz.ch/mailman/listinfo/r-package-devel

On 05/03/2018 13:46, michael tsagris wrote:
> Hi and thanks for the prompt reply. I cannot say I understood or know 
> what to do.
> Can you please tell me which is this mailing list?
> 
> 
> 
> ???? 2:15 ?.?. ???????, 5 ??????? 2018, ?/? Michael Dewey 
> <lists at dewey.myzen.co.uk> ??????:
> 
> 
> The error is that one of your documentation files is failing. Try
> compiling each one separately with
> R CMD Rd2pdf yourfilenamehere.Rd
> and see what happens.
> 
> There is a list especially for package developers which might be better
> in future.
> 
> Michael
> 
> On 05/03/2018 10:51, michael tsagris via R-help wrote:
>? > Hello, I am receiving this message when uploading my R package to rdevel.
>? > 
> https://win-builder.r-project.org/incoming_pretest/180305_110240_Compositional_29/00check.log
>? > Can anybody please help?
> 
>? >
>? > ??? [[alternative HTML version deleted]]
>? >
>? > ______________________________________________
>? > R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see
>? > https://stat.ethz.ch/mailman/listinfo/r-help
>? > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html 
> <http://www.r-project.org/posting-guide.html>
>? > and provide commented, minimal, self-contained, reproducible code.
>? >
> 
> -- 
> Michael
> http://www.dewey.myzen.co.uk/home.html
> 
> 
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


   
	[[alternative HTML version deleted]]


From ycding at coh.org  Mon Mar  5 17:52:25 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Mon, 5 Mar 2018 16:52:25 +0000
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>

Hi Bert,

I am very sorry to bother you again.

For the following question, as you suggested, I posted it in both Biostars website and stackexchange website, so far no reply.

I really hope that you can do me a great favor to share your points about how to explain the coefficients for drug A and drug B if run anova model (response variable = drug A + drug B). is it different from running three separate T tests?

Thank you so much!!

Ding

I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.


From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Friday, March 02, 2018 12:32 PM
To: Ding, Yuan Chun
Cc: r-help at r-project.org
Subject: Re: [R] data analysis for partial two-by-two factorial design

________________________________
[Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
________________________________

This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com> statistical site.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
Dear R users,

I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.

Thank you very much!

Yuan Chun Ding


---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely f...{{dropped:28}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ss5505 at cumc.columbia.edu  Mon Mar  5 19:07:24 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Mon, 5 Mar 2018 18:07:24 +0000
Subject: [R] Help with apply and new column?
Message-ID: <CY1PR02MB1690728352DDB29B2244D02281DA0@CY1PR02MB1690.namprd02.prod.outlook.com>

Hello members,

Can I ask question for apply, adding new column to data frame on this e-mail list?

Thanks!



	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Mar  5 19:47:48 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 05 Mar 2018 10:47:48 -0800
Subject: [R] Help with apply and new column?
In-Reply-To: <CY1PR02MB1690728352DDB29B2244D02281DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
References: <CY1PR02MB1690728352DDB29B2244D02281DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
Message-ID: <92341B98-DF3C-4B23-923D-B27FF147FE4A@dcn.davis.ca.us>

Read the Posting Guide... (see message footer) ... some relevant things you can find there:

a) Yes, this appears to be about how to use an R base function so it is on topic
b) Post a reproducible example (include some sample data, preferably using the dput function)
c) Post using plain text so the mailing list doesn't convert it for you and mangle things in a way you did not intend. 
-- 
Sent from my phone. Please excuse my brevity.

On March 5, 2018 10:07:24 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>Hello members,
>
>Can I ask question for apply, adding new column to data frame on this
>e-mail list?
>
>Thanks!
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ss5505 at cumc.columbia.edu  Mon Mar  5 20:06:36 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Mon, 5 Mar 2018 19:06:36 +0000
Subject: [R] Help with apply and new column?
In-Reply-To: <92341B98-DF3C-4B23-923D-B27FF147FE4A@dcn.davis.ca.us>
References: <CY1PR02MB1690728352DDB29B2244D02281DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
 <92341B98-DF3C-4B23-923D-B27FF147FE4A@dcn.davis.ca.us>
Message-ID: <CY1PR02MB169008824D405915BEA5639781DA0@CY1PR02MB1690.namprd02.prod.outlook.com>

Thanks. I think nabble is good for programming questions. Bear with me if I'm incorrect.

Data: Genomics SNP information 
Goal: I need to add Chromosome and SNP position to the data frame I'm using through apply.

I'd like to add new column from text processed through apply function.

For example:  10:60523:T:G  (Column 2)
CHR: 10
Position: 60523

Dataset:
chr	rs	ps	n_miss	allele1	allele0	af	beta	se	l_remle	p_wald
-9	10:60523:T:G	-9	0	T	G	0.977	-1.769354e-02	3.597196e-02	1.566731e-01	6.228309e-01
-9	10:60684:A:C	-9	0	A	C	0.973	1.698925e-02	2.942366e-02	1.561001e-01	5.636926e-01
-9	10:61331:A:G	-9	0	A	G	0.973	1.708586e-02	2.942424e-02	1.560944e-01	5.614851e-01
-9	10:62010:C:T	-9	0	C	T	0.980	-8.513143e-03	3.837054e-02	1.566875e-01	8.244260e-01

Code:

--------------------------------------------------------
data<-read.table("small.txt",header = T) # read data
data<-data[,c(2,11)] #delete other columns not needed 

#--split data on : and get chromosome and position

split_rs<-function(rs){  
    
    chr<-vector(,length(rs)) # create new vector to store chr
    pos<-vector(,length(rs)) #create new vector to store position
    
    for(i in 1:length(rs)){ #iterate over RS column

        if(grepl(":",rs[i])){ #if : in column string 
            temp <- strsplit(rs[i],":",fixed=T)         #split        
            chr[i] <-temp[[1]][1] #store CHR
            pos[i] <- temp[[1]][2]  #store position
        }    
    }
    return(list(chr=chr,pos=pos)) #return making a list
}

data$POS<-"NA" #add new column CHR and make NA 
data$CHR <- "NA" #add new column POS and make NA

temp<-apply(data,2,split_rs) #send data frame to function 

#--I assign value from list sent -- I would like to improve this part

data$CHR<-temp$rs$chr
data$POS<-temp$rs$pos

rm(temp)

colnames(data)<-c("SNP","P","CHR","BP")
--------------------------------------------------------



-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Monday, March 5, 2018 1:48 PM
To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>; R Help <r-help at r-project.org>
Subject: Re: [R] Help with apply and new column?

Read the Posting Guide... (see message footer) ... some relevant things you can find there:

a) Yes, this appears to be about how to use an R base function so it is on topic
b) Post a reproducible example (include some sample data, preferably using the dput function)
c) Post using plain text so the mailing list doesn't convert it for you and mangle things in a way you did not intend. 
--
Sent from my phone. Please excuse my brevity.

On March 5, 2018 10:07:24 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>Hello members,
>
>Can I ask question for apply, adding new column to data frame on this 
>e-mail list?
>
>Thanks!
>
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Mon Mar  5 21:36:19 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 5 Mar 2018 12:36:19 -0800 (PST)
Subject: [R] Help with apply and new column?
In-Reply-To: <CY1PR02MB169008824D405915BEA5639781DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
References: <CY1PR02MB1690728352DDB29B2244D02281DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
 <92341B98-DF3C-4B23-923D-B27FF147FE4A@dcn.davis.ca.us>
 <CY1PR02MB169008824D405915BEA5639781DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
Message-ID: <alpine.BSF.2.00.1803051224390.63004@pedal.dcn.davis.ca.us>

Comments interspersed, and some code at the end.

On Mon, 5 Mar 2018, Sariya, Sanjeev wrote:

> Thanks. I think nabble is good for programming questions. Bear with me 
> if I'm incorrect.

You may have found R-help archives at Nabble, but R-help has nothing to do 
with Nabble.

>
> Data: Genomics SNP information

I know almost nothing about using R for genomics.

> Goal: I need to add Chromosome and SNP position to the data frame I'm using through apply.
>
> I'd like to add new column from text processed through apply function.
>
> For example:  10:60523:T:G  (Column 2)
> CHR: 10
> Position: 60523

Assuming Position is "P", what are your "SNP" and "BP" in the names you 
assigned below as c("SNP","P","CHR","BP")?

> Dataset:
> chr	rs	ps	n_miss	allele1	allele0	af	beta	se	l_remle	p_wald
> -9	10:60523:T:G	-9	0	T	G	0.977	-1.769354e-02	3.597196e-02	1.566731e-01	6.228309e-01
> -9	10:60684:A:C	-9	0	A	C	0.973	1.698925e-02	2.942366e-02	1.561001e-01	5.636926e-01
> -9	10:61331:A:G	-9	0	A	G	0.973	1.708586e-02	2.942424e-02	1.560944e-01	5.614851e-01
> -9	10:62010:C:T	-9	0	C	T	0.980	-8.513143e-03	3.837054e-02	1.566875e-01	8.244260e-01
>
> Code:
>
> --------------------------------------------------------
> data<-read.table("small.txt",header = T) # read data
> data<-data[,c(2,11)] #delete other columns not needed
>
> #--split data on : and get chromosome and position
>
> split_rs<-function(rs){
>
>    chr<-vector(,length(rs)) # create new vector to store chr
>    pos<-vector(,length(rs)) #create new vector to store position
>
>    for(i in 1:length(rs)){ #iterate over RS column
>
>        if(grepl(":",rs[i])){ #if : in column string
>            temp <- strsplit(rs[i],":",fixed=T)         #split
>            chr[i] <-temp[[1]][1] #store CHR
>            pos[i] <- temp[[1]][2]  #store position
>        }
>    }
>    return(list(chr=chr,pos=pos)) #return making a list
> }
>
> data$POS<-"NA" #add new column CHR and make NA
> data$CHR <- "NA" #add new column POS and make NA
>
> temp<-apply(data,2,split_rs) #send data frame to function
>
> #--I assign value from list sent -- I would like to improve this part
>
> data$CHR<-temp$rs$chr
> data$POS<-temp$rs$pos
>
> rm(temp)
>
> colnames(data)<-c("SNP","P","CHR","BP")
> --------------------------------------------------------

######################################################
# Your code was pretty severely broken... it would not run,
# and I don't know what you expected to see as output.

# 1) data is the name of a function in base R... re-using
#    it can lead to puzzling errors
# 2) With all this character manipulation, you need to read
#    your character data in as character, not as factors
# 3) Don't use the T variable... use the constant TRUE,
#    since T can easily be overwritten to some non-TRUE value.
dta <- read.table( "small.txt", header = TRUE, as.is = TRUE ) # read data
dta <- dta[ , c( 2, 11 ) ] #delete other columns not needed

# 4) Not at all clear why you want to split all of the columns
#    using apply( ..., 2, ... ) when only one column has ":" characters
#temp <- apply( dta, 2, split_rs ) #send data frame to function
temp <- strsplit( dta$rs, ":" ) # gets the whole column splits at once

# wildly guessing here
rs_chrmatrix <- do.call( rbind, temp )
rs_DF <- as.data.frame( rs_chrmatrix, stringsAsFactors = FALSE )
names( rs_DF ) <- c( "CHR", "P", "X1", "X2" )
rs_DF$P <- as.integer( rs_DF$P )

str( rs_DF )
##################################################




>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Monday, March 5, 2018 1:48 PM
> To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>; R Help <r-help at r-project.org>
> Subject: Re: [R] Help with apply and new column?
>
> Read the Posting Guide... (see message footer) ... some relevant things you can find there:
>
> a) Yes, this appears to be about how to use an R base function so it is on topic
> b) Post a reproducible example (include some sample data, preferably using the dput function)
> c) Post using plain text so the mailing list doesn't convert it for you and mangle things in a way you did not intend.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 5, 2018 10:07:24 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>> Hello members,
>>
>> Can I ask question for apply, adding new column to data frame on this
>> e-mail list?
>>
>> Thanks!
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From ss5505 at cumc.columbia.edu  Mon Mar  5 22:12:29 2018
From: ss5505 at cumc.columbia.edu (Sariya, Sanjeev)
Date: Mon, 5 Mar 2018 21:12:29 +0000
Subject: [R] Help with apply and new column?
In-Reply-To: <alpine.BSF.2.00.1803051224390.63004@pedal.dcn.davis.ca.us>
References: <CY1PR02MB1690728352DDB29B2244D02281DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
 <92341B98-DF3C-4B23-923D-B27FF147FE4A@dcn.davis.ca.us>
 <CY1PR02MB169008824D405915BEA5639781DA0@CY1PR02MB1690.namprd02.prod.outlook.com>
 <alpine.BSF.2.00.1803051224390.63004@pedal.dcn.davis.ca.us>
Message-ID: <CY1PR02MB169071E382B18D1C4625A16081DA0@CY1PR02MB1690.namprd02.prod.outlook.com>

Thank you, that helps. 

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Monday, March 5, 2018 3:36 PM
To: Sariya, Sanjeev <ss5505 at cumc.columbia.edu>
Cc: r-help at r-project.org; R Help <r-help at r-project.org>
Subject: RE: [R] Help with apply and new column?

Comments interspersed, and some code at the end.

On Mon, 5 Mar 2018, Sariya, Sanjeev wrote:

> Thanks. I think nabble is good for programming questions. Bear with me 
> if I'm incorrect.

You may have found R-help archives at Nabble, but R-help has nothing to do with Nabble.

>
> Data: Genomics SNP information

I know almost nothing about using R for genomics.

> Goal: I need to add Chromosome and SNP position to the data frame I'm using through apply.
>
> I'd like to add new column from text processed through apply function.
>
> For example:  10:60523:T:G  (Column 2)
> CHR: 10
> Position: 60523

Assuming Position is "P", what are your "SNP" and "BP" in the names you assigned below as c("SNP","P","CHR","BP")?

> Dataset:
> chr	rs	ps	n_miss	allele1	allele0	af	beta	se	l_remle	p_wald
> -9	10:60523:T:G	-9	0	T	G	0.977	-1.769354e-02	3.597196e-02	1.566731e-01	6.228309e-01
> -9	10:60684:A:C	-9	0	A	C	0.973	1.698925e-02	2.942366e-02	1.561001e-01	5.636926e-01
> -9	10:61331:A:G	-9	0	A	G	0.973	1.708586e-02	2.942424e-02	1.560944e-01	5.614851e-01
> -9	10:62010:C:T	-9	0	C	T	0.980	-8.513143e-03	3.837054e-02	1.566875e-01	8.244260e-01
>
> Code:
>
> --------------------------------------------------------
> data<-read.table("small.txt",header = T) # read data 
> data<-data[,c(2,11)] #delete other columns not needed
>
> #--split data on : and get chromosome and position
>
> split_rs<-function(rs){
>
>    chr<-vector(,length(rs)) # create new vector to store chr
>    pos<-vector(,length(rs)) #create new vector to store position
>
>    for(i in 1:length(rs)){ #iterate over RS column
>
>        if(grepl(":",rs[i])){ #if : in column string
>            temp <- strsplit(rs[i],":",fixed=T)         #split
>            chr[i] <-temp[[1]][1] #store CHR
>            pos[i] <- temp[[1]][2]  #store position
>        }
>    }
>    return(list(chr=chr,pos=pos)) #return making a list }
>
> data$POS<-"NA" #add new column CHR and make NA data$CHR <- "NA" #add 
> new column POS and make NA
>
> temp<-apply(data,2,split_rs) #send data frame to function
>
> #--I assign value from list sent -- I would like to improve this part
>
> data$CHR<-temp$rs$chr
> data$POS<-temp$rs$pos
>
> rm(temp)
>
> colnames(data)<-c("SNP","P","CHR","BP")
> --------------------------------------------------------

######################################################
# Your code was pretty severely broken... it would not run, # and I don't know what you expected to see as output.

# 1) data is the name of a function in base R... re-using
#    it can lead to puzzling errors
# 2) With all this character manipulation, you need to read
#    your character data in as character, not as factors
# 3) Don't use the T variable... use the constant TRUE,
#    since T can easily be overwritten to some non-TRUE value.
dta <- read.table( "small.txt", header = TRUE, as.is = TRUE ) # read data dta <- dta[ , c( 2, 11 ) ] #delete other columns not needed

# 4) Not at all clear why you want to split all of the columns
#    using apply( ..., 2, ... ) when only one column has ":" characters
#temp <- apply( dta, 2, split_rs ) #send data frame to function temp <- strsplit( dta$rs, ":" ) # gets the whole column splits at once

# wildly guessing here
rs_chrmatrix <- do.call( rbind, temp )
rs_DF <- as.data.frame( rs_chrmatrix, stringsAsFactors = FALSE ) names( rs_DF ) <- c( "CHR", "P", "X1", "X2" ) rs_DF$P <- as.integer( rs_DF$P )

str( rs_DF )
##################################################




>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Monday, March 5, 2018 1:48 PM
> To: r-help at r-project.org; Sariya, Sanjeev <ss5505 at cumc.columbia.edu>; 
> R Help <r-help at r-project.org>
> Subject: Re: [R] Help with apply and new column?
>
> Read the Posting Guide... (see message footer) ... some relevant things you can find there:
>
> a) Yes, this appears to be about how to use an R base function so it 
> is on topic
> b) Post a reproducible example (include some sample data, preferably 
> using the dput function)
> c) Post using plain text so the mailing list doesn't convert it for you and mangle things in a way you did not intend.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 5, 2018 10:07:24 AM PST, "Sariya, Sanjeev" <ss5505 at cumc.columbia.edu> wrote:
>> Hello members,
>>
>> Can I ask question for apply, adding new column to data frame on this 
>> e-mail list?
>>
>> Thanks!
>>
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From pgilbert902 at gmail.com  Mon Mar  5 22:40:46 2018
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 5 Mar 2018 16:40:46 -0500
Subject: [R] Random Seed Location
In-Reply-To: <CAFDcVCTuqP0iRQ48oOS4mrnauLgyEhQ_bbhD1FjnPYyU8N=UbA@mail.gmail.com>
References: <mailman.348697.1.1519729201.9541.r-help@r-project.org>
 <34ee0ae5-2c5f-673c-c6e4-5ad37e86a440@gmail.com>
 <61C18210-9415-4BE1-8E07-6835B5B57505@sbcglobal.net>
 <CAFDcVCS5OYS7d2kf26rnPuM_AnKBZUsJOY6f8ZebZj4EPVuZ7A@mail.gmail.com>
 <6567d1c9-336e-47b4-937c-a83c7e1269e9@gmail.com>
 <CAFDcVCTuqP0iRQ48oOS4mrnauLgyEhQ_bbhD1FjnPYyU8N=UbA@mail.gmail.com>
Message-ID: <86494783-33cd-4c55-5994-8c7d91eeb1d5@gmail.com>



On 03/04/2018 07:14 PM, Henrik Bengtsson wrote:
> On Sun, Mar 4, 2018 at 3:23 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
...
>> An issue is that .Random.seed doesn't contain the full state of the RNG
>> system, so restoring it doesn't necessarily lead to an identical sequence of
>> output.  The only way to guarantee the sequence will repeat is to call
>> set.seed(n), and that only leads to a tiny fraction of possible states.
>>
>> Expanding .Random.seed so that it does contain the full state would be a
>> good idea, and that would make your preserveRandomSeed really easy to write.
>>
>> Here's a demo that .Random.seed is not enough:
>>
>>> set.seed(123, normal.kind = "Box-Muller")
>>> rnorm(1)
>> [1] -0.1613431
>>> save <- .Random.seed
>>> rnorm(1)
>> [1] 0.6706031
>>> .Random.seed <- save
>>> rnorm(1)
>> [1] -0.4194403
>>
>> If .Random.seed were the complete state, the 2nd and 3rd rnorm results would
>> be the same.

To be pedantic, it is not the RNG state that is the problem, it is the 
state of the normal transformation "Box-Muller".  And, again pedantic

 >So, this is is only for some of the RNG kinds.

As I recall, it is not a problem for any RNG kinds, it is only a problem 
with the Box-Muller normal.kind. Things may have changed, and parallel 
adds the need to record number of nodes.

>Is the reason for this
> limitation that it is not possible for R (not even the R internals) to
> get hold of some of the RNG generators?  In other words, it is
> unlikely to ever be fixed?

It has been around for a very long time (since at least R 0.99) and, as 
I recall, it was not easy to fix. I think the more substantial reason is 
that Box-Muller is no longer the default or preferred normal generator. 
It may only be used for backward compatibility, in which case messing 
with it could be a disaster with very little potential benefit.

Paul


From dwinsemius at comcast.net  Mon Mar  5 23:03:11 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Mar 2018 14:03:11 -0800
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
Message-ID: <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>


> On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
> 
> Hi Bert,
> 
> I am very sorry to bother you again.
> 
> For the following question, as you suggested, I posted it in both Biostars website and stackexchange website, so far no reply.
> 
> I really hope that you can do me a great favor to share your points about how to explain the coefficients for drug A and drug B if run anova model (response variable = drug A + drug B). is it different from running three separate T tests?
> 
> Thank you so much!!
> 
> Ding
> 
> I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.

Replied on CrossValidated where this would be on-topic.

-- 
David,

> 
> 
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> Sent: Friday, March 02, 2018 12:32 PM
> To: Ding, Yuan Chun
> Cc: r-help at r-project.org
> Subject: Re: [R] data analysis for partial two-by-two factorial design
> 
> ________________________________
> [Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
> ________________________________
> 
> This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com> statistical site.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
> Dear R users,
> 
> I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
> 
> Thank you very much!
> 
> Yuan Chun Ding
> 
> 
> ---------------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> This message (and any attachments) are intended solely...{{dropped:31}}


From bgunter.4567 at gmail.com  Mon Mar  5 23:27:28 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Mar 2018 14:27:28 -0800
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
Message-ID: <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>

David:

I believe your response on SO is incorrect. This is a standard OFAT (one
factor at a time) design, so that assuming additivity (no interactions),
the effects of drugA and drugB can be determined via the model you rejected:

For example, if baseline control (no drugs) has a response of 0, drugA has
an effect of 1, drugB has an effect of 2, and the effects are additive,
with no noise we would have:

> d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y"))
> y <- c(0,1,3)

And a straighforward inear model recovers the effects:

> lm(y ~ drugA + drugB, data=d)

Call:
lm(formula = y ~ drugA + drugB, data = d)

Coefficients:
(Intercept)       drugAy       drugBy
  1.282e-16    1.000e+00    2.000e+00

As usual, OFAT designs are blind to interactions, so that if they really
exist, the interpretation as additive effects is incorrect.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
> >
> > Hi Bert,
> >
> > I am very sorry to bother you again.
> >
> > For the following question, as you suggested, I posted it in both
> Biostars website and stackexchange website, so far no reply.
> >
> > I really hope that you can do me a great favor to share your points
> about how to explain the coefficients for drug A and drug B if run anova
> model (response variable = drug A + drug B). is it different from running
> three separate T tests?
> >
> > Thank you so much!!
> >
> > Ding
> >
> > I need to analyze data generated from a partial two-by-two factorial
> design: two levels for drug A (yes, no), two levels for drug B (yes, no);
> however, data points are available only for three groups, no drugA/no
> drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group
> of no drugA/yes drugB.  I think we can not investigate interaction between
> drug A and drug B, can I still run  model using R as usual:  response
> variable = drug A + drug B?  any suggestion is appreciated.
>
> Replied on CrossValidated where this would be on-topic.
>
> --
> David,
>
> >
> >
> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > Sent: Friday, March 02, 2018 12:32 PM
> > To: Ding, Yuan Chun
> > Cc: r-help at r-project.org
> > Subject: Re: [R] data analysis for partial two-by-two factorial design
> >
> > ________________________________
> > [Attention: This email came from an external source. Do not open
> attachments or click on links from unknown senders or unexpected emails.]
> > ________________________________
> >
> > This list provides help on R programming (see the posting guide linked
> below for details on what is/is not considered on topic), and generally
> avoids discussion of purely statistical issues, which is what your query
> appears to be. The simple answer is yes, you can fit the model as
> described,  but you clearly need the off topic discussion as to what it
> does or does not mean. For that, you might try the stats.stackexchange.com
> <http://stats.stackexchange.com> statistical site.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:
> ycding at coh.org>> wrote:
> > Dear R users,
> >
> > I need to analyze data generated from a partial two-by-two factorial
> design: two levels for drug A (yes, no), two levels for drug B (yes, no);
> however, data points are available only for three groups, no drugA/no
> drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group
> of no drugA/yes drugB.  I think we can not investigate interaction between
> drug A and drug B, can I still run  model using R as usual:  response
> variable = drug A + drug B?  any suggestion is appreciated.
> >
> > Thank you very much!
> >
> > Yuan Chun Ding
> >
> >
> > ---------------------------------------------------------------------
> > -SECURITY/CONFIDENTIALITY WARNING-
> > This message (and any attachments) are intended solely f...{{dropped:28}}
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From ycding at coh.org  Mon Mar  5 23:44:30 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Mon, 5 Mar 2018 22:44:30 +0000
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
 <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
Message-ID: <A86C6438FB909A409DDEF926277952B6A6C42E@PPWEXCH2KX14.coh.org>

Hi Bert and David,

Thank you so much for willingness to spend some time on my problem!!!  I have some statistical knowledge (going to get a master in applied statisitics), but do not have a chance to purse a phD for statistics, so I am always be careful before starting to do analysis and hope to gather supportive information from real statisticians.

Sorry that I did not tell more info about experiment design.

I did not do this experiment, my collaborator did it and I only got chance to analyze the data.

There are nine dishes of cells.  Three replicates for each treatment combination.  So randomly select three dishes for no drug A/no drug B treatment, a second three dishes for drug A only, then last three dishes to add both A and B drugs.  After drug treatments, they measure DNA methylation and genes or gene expression as outcome or response variables(two differnet types of response variables).

My boss might want to find out net effect of drug B, but I think we can not exclude the confounding effect of drugA. For example, it is possible that drug B has no effect, only has effect when drug A is present.   I asked my collaborator whey she omitted the fourth combination drugA only treatment, she said it was expensive to measure methylation or gene expression, so they performed the experiments based on their hypothesis which is too complicated here, so not illustrated here in details.  I am still not happy that they could just add three more replicates to do a full 2X2 design.

On the weekend, I also thought about doing a one-way anova, but then I have to do three pairwise comparisons to find out the pair to show difference if p value for one way anova is significant.

Thanks,

Ding

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Monday, March 05, 2018 2:27 PM
To: David Winsemius
Cc: Ding, Yuan Chun; r-help at r-project.org
Subject: Re: [R] data analysis for partial two-by-two factorial design

David:
I believe your response on SO is incorrect. This is a standard OFAT (one factor at a time) design, so that assuming additivity (no interactions), the effects of drugA and drugB can be determined via the model you rejected:
For example, if baseline control (no drugs) has a response of 0, drugA has an effect of 1, drugB has an effect of 2, and the effects are additive, with no noise we would have:

> d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y"))
> y <- c(0,1,3)
And a straighforward inear model recovers the effects:

> lm(y ~ drugA + drugB, data=d)

Call:
lm(formula = y ~ drugA + drugB, data = d)

Coefficients:
(Intercept)       drugAy       drugBy
  1.282e-16    1.000e+00    2.000e+00
As usual, OFAT designs are blind to interactions, so that if they really exist, the interpretation as additive effects is incorrect.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>> wrote:

> On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
>
> Hi Bert,
>
> I am very sorry to bother you again.
>
> For the following question, as you suggested, I posted it in both Biostars website and stackexchange website, so far no reply.
>
> I really hope that you can do me a great favor to share your points about how to explain the coefficients for drug A and drug B if run anova model (response variable = drug A + drug B). is it different from running three separate T tests?
>
> Thank you so much!!
>
> Ding
>
> I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.

Replied on CrossValidated where this would be on-topic.

--
David,

>
>
> From: Bert Gunter [mailto:bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>]
> Sent: Friday, March 02, 2018 12:32 PM
> To: Ding, Yuan Chun
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] data analysis for partial two-by-two factorial design
>
> ________________________________
> [Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
> ________________________________
>
> This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com><http://stats.stackexchange.com> statistical site.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org><mailto:ycding at coh.org<mailto:ycding at coh.org>>> wrote:
> Dear R users,
>
> I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
>
> Thank you very much!
>
> Yuan Chun Ding
>
>
> ---------------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> This message (and any attachments) are intended solely f...{{dropped:28}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-project.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






	[[alternative HTML version deleted]]


From ycding at coh.org  Mon Mar  5 23:48:50 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Mon, 5 Mar 2018 22:48:50 +0000
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A6C42E@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
 <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C42E@PPWEXCH2KX14.coh.org>
Message-ID: <A86C6438FB909A409DDEF926277952B6A6C447@PPWEXCH2KX14.coh.org>

I am sorry that I made a typo:
.   I asked my collaborator whey she omitted the fourth combination drugA only treatment,
I wanted to say .   "I asked my collaborator why she omitted the fourth combination drugB only treatment",

Ding 

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Ding, Yuan Chun
Sent: Monday, March 05, 2018 2:45 PM
To: Bert Gunter; David Winsemius
Cc: r-help at r-project.org
Subject: Re: [R] data analysis for partial two-by-two factorial design

Hi Bert and David,

Thank you so much for willingness to spend some time on my problem!!!  I have some statistical knowledge (going to get a master in applied statisitics), but do not have a chance to purse a phD for statistics, so I am always be careful before starting to do analysis and hope to gather supportive information from real statisticians.

Sorry that I did not tell more info about experiment design.

I did not do this experiment, my collaborator did it and I only got chance to analyze the data.

There are nine dishes of cells.  Three replicates for each treatment combination.  So randomly select three dishes for no drug A/no drug B treatment, a second three dishes for drug A only, then last three dishes to add both A and B drugs.  After drug treatments, they measure DNA methylation and genes or gene expression as outcome or response variables(two differnet types of response variables).

My boss might want to find out net effect of drug B, but I think we can not exclude the confounding effect of drugA. For example, it is possible that drug B has no effect, only has effect when drug A is present.   I asked my collaborator whey she omitted the fourth combination drugA only treatment, she said it was expensive to measure methylation or gene expression, so they performed the experiments based on their hypothesis which is too complicated here, so not illustrated here in details.  I am still not happy that they could just add three more replicates to do a full 2X2 design.

On the weekend, I also thought about doing a one-way anova, but then I have to do three pairwise comparisons to find out the pair to show difference if p value for one way anova is significant.

Thanks,

Ding

From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Monday, March 05, 2018 2:27 PM
To: David Winsemius
Cc: Ding, Yuan Chun; r-help at r-project.org
Subject: Re: [R] data analysis for partial two-by-two factorial design

David:
I believe your response on SO is incorrect. This is a standard OFAT (one factor at a time) design, so that assuming additivity (no interactions), the effects of drugA and drugB can be determined via the model you rejected:
For example, if baseline control (no drugs) has a response of 0, drugA has an effect of 1, drugB has an effect of 2, and the effects are additive, with no noise we would have:

> d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y")) y <- 
> c(0,1,3)
And a straighforward inear model recovers the effects:

> lm(y ~ drugA + drugB, data=d)

Call:
lm(formula = y ~ drugA + drugB, data = d)

Coefficients:
(Intercept)       drugAy       drugBy
  1.282e-16    1.000e+00    2.000e+00
As usual, OFAT designs are blind to interactions, so that if they really exist, the interpretation as additive effects is incorrect.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net<mailto:dwinsemius at comcast.net>> wrote:

> On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
>
> Hi Bert,
>
> I am very sorry to bother you again.
>
> For the following question, as you suggested, I posted it in both Biostars website and stackexchange website, so far no reply.
>
> I really hope that you can do me a great favor to share your points about how to explain the coefficients for drug A and drug B if run anova model (response variable = drug A + drug B). is it different from running three separate T tests?
>
> Thank you so much!!
>
> Ding
>
> I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.

Replied on CrossValidated where this would be on-topic.

--
David,

>
>
> From: Bert Gunter 
> [mailto:bgunter.4567 at gmail.com<mailto:bgunter.4567 at gmail.com>]
> Sent: Friday, March 02, 2018 12:32 PM
> To: Ding, Yuan Chun
> Cc: r-help at r-project.org<mailto:r-help at r-project.org>
> Subject: Re: [R] data analysis for partial two-by-two factorial design
>
> ________________________________
> [Attention: This email came from an external source. Do not open 
> attachments or click on links from unknown senders or unexpected 
> emails.] ________________________________
>
> This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com><http://stats.stackexchange.com> statistical site.
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org><mailto:ycding at coh.org<mailto:ycding at coh.org>>> wrote:
> Dear R users,
>
> I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
>
> Thank you very much!
>
> Yuan Chun Ding
>
>
> ---------------------------------------------------------------------
> -SECURITY/CONFIDENTIALITY WARNING-
> This message (and any attachments) are intended solely 
> f...{{dropped:28}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org><mailto:R-help at r-proj
> ect.org<mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE 
> and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To 
> UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Mar  6 00:00:07 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Mar 2018 15:00:07 -0800
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
 <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
Message-ID: <8415EA34-CC50-480C-A3CD-899604AEB953@comcast.net>


> On Mar 5, 2018, at 2:27 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> David:
> 
> I believe your response on SO is incorrect. This is a standard OFAT (one factor at a time) design, so that assuming additivity (no interactions), the effects of drugA and drugB can be determined via the model you rejected:

>> three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.

> 
> For example, if baseline control (no drugs) has a response of 0, drugA has an effect of 1, drugB has an effect of 2, and the effects are additive, with no noise we would have:
> 
> > d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y"))

d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB")
> 
> > y <- c(0,1,3)
> 
> And a straighforward inear model recovers the effects:
> 
> > lm(y ~ drugA + drugB, data=d)
> 
> Call:
> lm(formula = y ~ drugA + drugB, data = d)
> 
> Coefficients:
> (Intercept)       drugAy       drugBy  
>   1.282e-16    1.000e+00    2.000e+00  

I think the labeling above is rather to mislead since what is labeled drugB is actually A&B. I think the method I suggest is more likely to be interpreted correctly:

> d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB"))
>  y <- c(0,1,3)
> lm(y ~ trt, data=d2)

Call:
lm(formula = y ~ trt, data = d2)

Coefficients:
   (Intercept)  trtDrugA_drugB   trtDrugA_only  
     2.564e-16       3.000e+00       1.000e+00  

-- 
David.
> 
> As usual, OFAT designs are blind to interactions, so that if they really exist, the interpretation as additive effects is incorrect.
> 
> Cheers,
> Bert
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
> >
> > Hi Bert,
> >
> > I am very sorry to bother you again.
> >
> > For the following question, as you suggested, I posted it in both Biostars website and stackexchange website, so far no reply.
> >
> > I really hope that you can do me a great favor to share your points about how to explain the coefficients for drug A and drug B if run anova model (response variable = drug A + drug B). is it different from running three separate T tests?
> >
> > Thank you so much!!
> >
> > Ding
> >
> > I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
> 
> Replied on CrossValidated where this would be on-topic.
> 
> --
> David,
> 
> >
> >
> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > Sent: Friday, March 02, 2018 12:32 PM
> > To: Ding, Yuan Chun
> > Cc: r-help at r-project.org
> > Subject: Re: [R] data analysis for partial two-by-two factorial design
> >
> > ________________________________
> > [Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
> > ________________________________
> >
> > This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com> statistical site.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
> > Dear R users,
> >
> > I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
> >
> > Thank you very much!
> >
> > Yuan Chun Ding
> >
> >
> > ---------------------------------------------------------------------
> > -SECURITY/CONFIDENTIALITY WARNING-
> > This message (and any attachments) are intended solely f...{{dropped:28}}
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From bgunter.4567 at gmail.com  Tue Mar  6 00:04:28 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Mar 2018 15:04:28 -0800
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <8415EA34-CC50-480C-A3CD-899604AEB953@comcast.net>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
 <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
 <8415EA34-CC50-480C-A3CD-899604AEB953@comcast.net>
Message-ID: <CAGxFJbRW_+EEqoMUBZ0KG-+yEPvV297Hxkpr8okR-OayuMUVtQ@mail.gmail.com>

But of course the whole point of additivity is to decompose the combined
effect as the sum of individual effects.

"Mislead" is a subjective judgment, so no comment. The explanation I
provided is standard. I used it for decades when I taught in industry.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 5, 2018 at 3:00 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 5, 2018, at 2:27 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > David:
> >
> > I believe your response on SO is incorrect. This is a standard OFAT (one
> factor at a time) design, so that assuming additivity (no interactions),
> the effects of drugA and drugB can be determined via the model you rejected:
>
> >> three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug
> B, omitting the fourth group of no drugA/yes drugB.
>
> >
> > For example, if baseline control (no drugs) has a response of 0, drugA
> has an effect of 1, drugB has an effect of 2, and the effects are additive,
> with no noise we would have:
> >
> > > d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y"))
>
> d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB")
> >
> > > y <- c(0,1,3)
> >
> > And a straighforward inear model recovers the effects:
> >
> > > lm(y ~ drugA + drugB, data=d)
> >
> > Call:
> > lm(formula = y ~ drugA + drugB, data = d)
> >
> > Coefficients:
> > (Intercept)       drugAy       drugBy
> >   1.282e-16    1.000e+00    2.000e+00
>
> I think the labeling above is rather to mislead since what is labeled
> drugB is actually A&B. I think the method I suggest is more likely to be
> interpreted correctly:
>
> > d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB"))
> >  y <- c(0,1,3)
> > lm(y ~ trt, data=d2)
>
> Call:
> lm(formula = y ~ trt, data = d2)
>
> Coefficients:
>    (Intercept)  trtDrugA_drugB   trtDrugA_only
>      2.564e-16       3.000e+00       1.000e+00
>
> --
> David.
> >
> > As usual, OFAT designs are blind to interactions, so that if they really
> exist, the interpretation as additive effects is incorrect.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> > > On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
> > >
> > > Hi Bert,
> > >
> > > I am very sorry to bother you again.
> > >
> > > For the following question, as you suggested, I posted it in both
> Biostars website and stackexchange website, so far no reply.
> > >
> > > I really hope that you can do me a great favor to share your points
> about how to explain the coefficients for drug A and drug B if run anova
> model (response variable = drug A + drug B). is it different from running
> three separate T tests?
> > >
> > > Thank you so much!!
> > >
> > > Ding
> > >
> > > I need to analyze data generated from a partial two-by-two factorial
> design: two levels for drug A (yes, no), two levels for drug B (yes, no);
> however, data points are available only for three groups, no drugA/no
> drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group
> of no drugA/yes drugB.  I think we can not investigate interaction between
> drug A and drug B, can I still run  model using R as usual:  response
> variable = drug A + drug B?  any suggestion is appreciated.
> >
> > Replied on CrossValidated where this would be on-topic.
> >
> > --
> > David,
> >
> > >
> > >
> > > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > > Sent: Friday, March 02, 2018 12:32 PM
> > > To: Ding, Yuan Chun
> > > Cc: r-help at r-project.org
> > > Subject: Re: [R] data analysis for partial two-by-two factorial design
> > >
> > > ________________________________
> > > [Attention: This email came from an external source. Do not open
> attachments or click on links from unknown senders or unexpected emails.]
> > > ________________________________
> > >
> > > This list provides help on R programming (see the posting guide linked
> below for details on what is/is not considered on topic), and generally
> avoids discussion of purely statistical issues, which is what your query
> appears to be. The simple answer is yes, you can fit the model as
> described,  but you clearly need the off topic discussion as to what it
> does or does not mean. For that, you might try the stats.stackexchange.com
> <http://stats.stackexchange.com> statistical site.
> > >
> > > Cheers,
> > > Bert
> > >
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > > On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org
> <mailto:ycding at coh.org>> wrote:
> > > Dear R users,
> > >
> > > I need to analyze data generated from a partial two-by-two factorial
> design: two levels for drug A (yes, no), two levels for drug B (yes, no);
> however, data points are available only for three groups, no drugA/no
> drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group
> of no drugA/yes drugB.  I think we can not investigate interaction between
> drug A and drug B, can I still run  model using R as usual:  response
> variable = drug A + drug B?  any suggestion is appreciated.
> > >
> > > Thank you very much!
> > >
> > > Yuan Chun Ding
> > >
> > >
> > > ---------------------------------------------------------------------
> > > -SECURITY/CONFIDENTIALITY WARNING-
> > > This message (and any attachments) are intended solely
> f...{{dropped:28}}
> > >
> > > ______________________________________________
> > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar  6 00:06:54 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 5 Mar 2018 15:06:54 -0800
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A6C42E@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
 <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C42E@PPWEXCH2KX14.coh.org>
Message-ID: <CAGxFJbReuZvJ2s+rar6HRhhKi+SL2fJcr==o9JPCxu6=Zqv-2g@mail.gmail.com>

Yuan:

IMHO you need to stop making up your own statistical analyses and get local
expert help.

I have nothing further to say. Do what you will.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 5, 2018 at 2:44 PM, Ding, Yuan Chun <ycding at coh.org> wrote:

> Hi Bert and David,
>
>
>
> Thank you so much for willingness to spend some time on my problem!!!  I
> have some statistical knowledge (going to get a master in applied
> statisitics), but do not have a chance to purse a phD for statistics, so I
> am always be careful before starting to do analysis and hope to gather
> supportive information from real statisticians.
>
>
>
> Sorry that I did not tell more info about experiment design.
>
>
>
> I did not do this experiment, my collaborator did it and I only got chance
> to analyze the data.
>
>
>
> There are nine dishes of cells.  Three replicates for each treatment
> combination.  So randomly select three dishes for no drug A/no drug B
> treatment, a second three dishes for drug A only, then last three dishes to
> add both A and B drugs.  After drug treatments, they measure DNA
> methylation and genes or gene expression as outcome or response
> variables(two differnet types of response variables).
>
>
>
> My boss might want to find out net effect of drug B, but I think we can
> not exclude the confounding effect of drugA. For example, it is possible
> that drug B has no effect, only has effect when drug A is present.   I
> asked my collaborator whey she omitted the fourth combination drugA only
> treatment, she said it was expensive to measure methylation or gene
> expression, so they performed the experiments based on their hypothesis
> which is too complicated here, so not illustrated here in details.  I am
> still not happy that they could just add three more replicates to do a full
> 2X2 design.
>
>
>
> On the weekend, I also thought about doing a one-way anova, but then I
> have to do three pairwise comparisons to find out the pair to show
> difference if p value for one way anova is significant.
>
>
>
> Thanks,
>
>
> Ding
>
>
>
> *From:* Bert Gunter [mailto:bgunter.4567 at gmail.com]
> *Sent:* Monday, March 05, 2018 2:27 PM
> *To:* David Winsemius
> *Cc:* Ding, Yuan Chun; r-help at r-project.org
>
> *Subject:* Re: [R] data analysis for partial two-by-two factorial design
>
>
>
> David:
>
> I believe your response on SO is incorrect. This is a standard OFAT (one
> factor at a time) design, so that assuming additivity (no interactions),
> the effects of drugA and drugB can be determined via the model you rejected:
>
> For example, if baseline control (no drugs) has a response of 0, drugA has
> an effect of 1, drugB has an effect of 2, and the effects are additive,
> with no noise we would have:
>
> > d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y"))
> > y <- c(0,1,3)
>
> And a straighforward inear model recovers the effects:
>
>
> > lm(y ~ drugA + drugB, data=d)
>
> Call:
> lm(formula = y ~ drugA + drugB, data = d)
>
> Coefficients:
> (Intercept)       drugAy       drugBy
>   1.282e-16    1.000e+00    2.000e+00
>
> As usual, OFAT designs are blind to interactions, so that if they really
> exist, the interpretation as additive effects is incorrect.
>
>
>
> Cheers,
>
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
>
> On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
>
>
> > On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
> >
> > Hi Bert,
> >
> > I am very sorry to bother you again.
> >
> > For the following question, as you suggested, I posted it in both
> Biostars website and stackexchange website, so far no reply.
> >
> > I really hope that you can do me a great favor to share your points
> about how to explain the coefficients for drug A and drug B if run anova
> model (response variable = drug A + drug B). is it different from running
> three separate T tests?
> >
> > Thank you so much!!
> >
> > Ding
> >
> > I need to analyze data generated from a partial two-by-two factorial
> design: two levels for drug A (yes, no), two levels for drug B (yes, no);
> however, data points are available only for three groups, no drugA/no
> drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group
> of no drugA/yes drugB.  I think we can not investigate interaction between
> drug A and drug B, can I still run  model using R as usual:  response
> variable = drug A + drug B?  any suggestion is appreciated.
>
> Replied on CrossValidated where this would be on-topic.
>
> --
> David,
>
> >
> >
> > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > Sent: Friday, March 02, 2018 12:32 PM
> > To: Ding, Yuan Chun
> > Cc: r-help at r-project.org
> > Subject: Re: [R] data analysis for partial two-by-two factorial design
> >
> > ________________________________
> > [Attention: This email came from an external source. Do not open
> attachments or click on links from unknown senders or unexpected emails.]
> > ________________________________
> >
> > This list provides help on R programming (see the posting guide linked
> below for details on what is/is not considered on topic), and generally
> avoids discussion of purely statistical issues, which is what your query
> appears to be. The simple answer is yes, you can fit the model as
> described,  but you clearly need the off topic discussion as to what it
> does or does not mean. For that, you might try the stats.stackexchange.com
> <http://stats.stackexchange.com> statistical site.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:
> ycding at coh.org>> wrote:
> > Dear R users,
> >
> > I need to analyze data generated from a partial two-by-two factorial
> design: two levels for drug A (yes, no), two levels for drug B (yes, no);
> however, data points are available only for three groups, no drugA/no
> drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group
> of no drugA/yes drugB.  I think we can not investigate interaction between
> drug A and drug B, can I still run  model using R as usual:  response
> variable = drug A + drug B?  any suggestion is appreciated.
> >
> > Thank you very much!
> >
> > Yuan Chun Ding
> >
> >
> > ---------------------------------------------------------------------
> > -SECURITY/CONFIDENTIALITY WARNING-
> > This message (and any attachments) are intended solely f...{{dropped:28}}
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To
> UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From Alexander.Herr at csiro.au  Tue Mar  6 00:28:32 2018
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Mon, 5 Mar 2018 23:28:32 +0000
Subject: [R] raster time series statistics
Message-ID: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>

Hi List,

The following code returns an "Error in as.POSIXlt.character(x, tz, ...) :   character string is not in a standard unambiguous format"

require(raster)
require(rts)
require(stringi)
r <- raster(ncol=100, nrow=100)
values(r) <- runif(ncell(r))
list(ID=seq(1:24),month=rep(str_pad(1:12, pad = 0,width = 2 , "left"),2),year=sort(rep(2016:2017,12)))->dt
stack(r)->s
r->rs
for(i in 1:23){
rs[]<-r[]*i
  addLayer(s,rs)->s
print(nlayers(s))
}
timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']))
rts(s,time=as.yearmon(timelst))->rsts
str(rsts at time)
apply.monthly(rsts,mean)

I was expecting that the statistics accept the yearmonth format of the timeslot, as it allows subsetting.
Any suggestions?
Thanks
Herry

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Tue Mar  6 00:54:54 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Mar 2018 15:54:54 -0800
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <CAGxFJbRW_+EEqoMUBZ0KG-+yEPvV297Hxkpr8okR-OayuMUVtQ@mail.gmail.com>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
 <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
 <8415EA34-CC50-480C-A3CD-899604AEB953@comcast.net>
 <CAGxFJbRW_+EEqoMUBZ0KG-+yEPvV297Hxkpr8okR-OayuMUVtQ@mail.gmail.com>
Message-ID: <24D263EB-83D0-4604-B8A3-C50D5A9993D2@comcast.net>


> On Mar 5, 2018, at 3:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> But of course the whole point of additivity is to decompose the combined effect as the sum of individual effects.

Agreed. Furthermore your encoding of the treatment assignments has the advantage that the default treatment contrast for A+B will have a statistical estimate associated with it. That was a deficiency of my encoding that Ding found problematic. I did have the incorrect notion that the encoding of Drug B in the single drug situation would have been NA and that the `lm`-function would produce nothing useful. Your setup had not occurred to me.

Best;
David.

> 
> "Mislead" is a subjective judgment, so no comment. The explanation I provided is standard. I used it for decades when I taught in industry.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Mar 5, 2018 at 3:00 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Mar 5, 2018, at 2:27 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > David:
> >
> > I believe your response on SO is incorrect. This is a standard OFAT (one factor at a time) design, so that assuming additivity (no interactions), the effects of drugA and drugB can be determined via the model you rejected:
> 
> >> three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.
> 
> >
> > For example, if baseline control (no drugs) has a response of 0, drugA has an effect of 1, drugB has an effect of 2, and the effects are additive, with no noise we would have:
> >
> > > d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y"))
> 
> d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB")
> >
> > > y <- c(0,1,3)
> >
> > And a straighforward inear model recovers the effects:
> >
> > > lm(y ~ drugA + drugB, data=d)
> >
> > Call:
> > lm(formula = y ~ drugA + drugB, data = d)
> >
> > Coefficients:
> > (Intercept)       drugAy       drugBy
> >   1.282e-16    1.000e+00    2.000e+00
> 
> I think the labeling above is rather to mislead since what is labeled drugB is actually A&B. I think the method I suggest is more likely to be interpreted correctly:
> 
> > d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB"))
> >  y <- c(0,1,3)
> > lm(y ~ trt, data=d2)
> 
> Call:
> lm(formula = y ~ trt, data = d2)
> 
> Coefficients:
>    (Intercept)  trtDrugA_drugB   trtDrugA_only
>      2.564e-16       3.000e+00       1.000e+00
> 
> --
> David.
> >
> > As usual, OFAT designs are blind to interactions, so that if they really exist, the interpretation as additive effects is incorrect.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
> > >
> > > Hi Bert,
> > >
> > > I am very sorry to bother you again.
> > >
> > > For the following question, as you suggested, I posted it in both Biostars website and stackexchange website, so far no reply.
> > >
> > > I really hope that you can do me a great favor to share your points about how to explain the coefficients for drug A and drug B if run anova model (response variable = drug A + drug B). is it different from running three separate T tests?
> > >
> > > Thank you so much!!
> > >
> > > Ding
> > >
> > > I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
> >
> > Replied on CrossValidated where this would be on-topic.
> >
> > --
> > David,
> >
> > >
> > >
> > > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > > Sent: Friday, March 02, 2018 12:32 PM
> > > To: Ding, Yuan Chun
> > > Cc: r-help at r-project.org
> > > Subject: Re: [R] data analysis for partial two-by-two factorial design
> > >
> > > ________________________________
> > > [Attention: This email came from an external source. Do not open attachments or click on links from unknown senders or unexpected emails.]
> > > ________________________________
> > >
> > > This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com> statistical site.
> > >
> > > Cheers,
> > > Bert
> > >
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > > On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
> > > Dear R users,
> > >
> > > I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
> > >
> > > Thank you very much!
> > >
> > > Yuan Chun Ding
> > >
> > >
> > > ---------------------------------------------------------------------
> > > -SECURITY/CONFIDENTIALITY WARNING-
> > > This message (and any attachments) are intended solely f...{{dropped:28}}
> > >
> > > ______________________________________________
> > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwinsemius at comcast.net  Tue Mar  6 01:10:18 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 5 Mar 2018 16:10:18 -0800
Subject: [R] raster time series statistics
In-Reply-To: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
References: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
Message-ID: <E9375221-D4C3-4D34-BAE0-EB1F2AB42ED2@comcast.net>


> On Mar 5, 2018, at 3:28 PM, <Alexander.Herr at csiro.au> <Alexander.Herr at csiro.au> wrote:
> 
> Hi List,
> 
> The following code returns an "Error in as.POSIXlt.character(x, tz, ...) :   character string is not in a standard unambiguous format"

I'm unable to produce that error. Which function was being evaluated to produce the error? I don't see where as.POSIXlt would have been called. You don't have any Date or POSIXt-classed variables. (I did need to also load the stringr package to get str_pad into my workspace.)

> 
> require(raster)
> require(rts)
> require(stringi)
> r <- raster(ncol=100, nrow=100)
> values(r) <- runif(ncell(r))
> list(ID=seq(1:24),month=rep(str_pad(1:12, pad = 0,width = 2 , "left"),2),year=sort(rep(2016:2017,12)))->dt
> stack(r)->s
> r->rs
> for(i in 1:23){
> rs[]<-r[]*i
>  addLayer(s,rs)->s
> print(nlayers(s))
> }
> timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']))
> rts(s,time=as.yearmon(timelst))->rsts
> str(rsts at time)
> apply.monthly(rsts,mean)
> 
> I was expecting that the statistics accept the yearmonth format of the timeslot, as it allows subsetting.
> Any suggestions?
> Thanks
> Herry
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From drjimlemon at gmail.com  Tue Mar  6 01:13:50 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Mar 2018 11:13:50 +1100
Subject: [R] raster time series statistics
In-Reply-To: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
References: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
Message-ID: <CA+8X3fVpJ6FyZSMDoPK5affYxxuGFBiT5wUE85hqP0A7uE7TFQ@mail.gmail.com>

Hi Herry,
This is probably due to a call to strptime (or similar). No, it
doesn't accept %Y-%m as a valid format. Maybe add a constant day to
all the dates as that will work:

dt<-list(ID=seq(1:24),month=rep(formatC(1:12,flag=0,width=2),2),
 year=sort(rep(2016:2017,12)))
timelst<-paste(unlist(dt['year']),unlist(dt['month']),"01",sep="-")
strptime(timelst,format="%Y-%m-%d")

Jim



On Tue, Mar 6, 2018 at 10:28 AM,  <Alexander.Herr at csiro.au> wrote:
> Hi List,
>
> The following code returns an "Error in as.POSIXlt.character(x, tz, ...) :   character string is not in a standard unambiguous format"
>
> require(raster)
> require(rts)
> require(stringi)
> r <- raster(ncol=100, nrow=100)
> values(r) <- runif(ncell(r))
> list(ID=seq(1:24),month=rep(str_pad(1:12, pad = 0,width = 2 , "left"),2),year=sort(rep(2016:2017,12)))->dt
> stack(r)->s
> r->rs
> for(i in 1:23){
> rs[]<-r[]*i
>   addLayer(s,rs)->s
> print(nlayers(s))
> }
> timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']))
> rts(s,time=as.yearmon(timelst))->rsts
> str(rsts at time)
> apply.monthly(rsts,mean)
>
> I was expecting that the statistics accept the yearmonth format of the timeslot, as it allows subsetting.
> Any suggestions?
> Thanks
> Herry
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Alexander.Herr at csiro.au  Tue Mar  6 01:32:58 2018
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Tue, 6 Mar 2018 00:32:58 +0000
Subject: [R] raster time series statistics
In-Reply-To: <CA+8X3fVpJ6FyZSMDoPK5affYxxuGFBiT5wUE85hqP0A7uE7TFQ@mail.gmail.com>
References: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
 <CA+8X3fVpJ6FyZSMDoPK5affYxxuGFBiT5wUE85hqP0A7uE7TFQ@mail.gmail.com>
Message-ID: <824cabfef9264a35ad8f3ca9dff62498@exch1-mel.nexus.csiro.au>

Thanks Jim

Still getting the same error for apply.montly
Updated code:

require(raster)
require(rts)
require(stringr)
r <- raster(ncol=100, nrow=100)
values(r) <- runif(ncell(r))
stack(r)->s
r->rs
for(i in 1:23){
 rs[]<-r[]*i
  addLayer(s,rs)->s
 print(nlayers(s))
}
dt<-list(ID=seq(1:24),month=rep(formatC(1:12,flag=0,width=2),2),
 year=sort(rep(2016:2017,12)))
 timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']),"-01")
strptime(timelst,format="%Y-%m-%d")->t1

rts(s,time=as.yearmon(t1))->rsts
subset(rsts,'2017')->r2017
class(r2017 at time)
class(rsts at time)

apply.monthly(rsts,mean)



-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com] 
Sent: Tuesday, 6 March 2018 11:14 AM
To: Herr, Alexander (L&W, Black Mountain) <Alexander.Herr at csiro.au>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] raster time series statistics

Hi Herry,
This is probably due to a call to strptime (or similar). No, it doesn't accept %Y-%m as a valid format. Maybe add a constant day to all the dates as that will work:

dt<-list(ID=seq(1:24),month=rep(formatC(1:12,flag=0,width=2),2),
 year=sort(rep(2016:2017,12)))
timelst<-paste(unlist(dt['year']),unlist(dt['month']),"01",sep="-")
strptime(timelst,format="%Y-%m-%d")

Jim



On Tue, Mar 6, 2018 at 10:28 AM,  <Alexander.Herr at csiro.au> wrote:
> Hi List,
>
> The following code returns an "Error in as.POSIXlt.character(x, tz, ...) :   character string is not in a standard unambiguous format"
>
> require(raster)
> require(rts)
> require(stringi)
> r <- raster(ncol=100, nrow=100)
> values(r) <- runif(ncell(r))
> list(ID=seq(1:24),month=rep(str_pad(1:12, pad = 0,width = 2 , 
> "left"),2),year=sort(rep(2016:2017,12)))->dt
> stack(r)->s
> r->rs
> for(i in 1:23){
> rs[]<-r[]*i
>   addLayer(s,rs)->s
> print(nlayers(s))
> }
> timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']))
> rts(s,time=as.yearmon(timelst))->rsts
> str(rsts at time)
> apply.monthly(rsts,mean)
>
> I was expecting that the statistics accept the yearmonth format of the timeslot, as it allows subsetting.
> Any suggestions?
> Thanks
> Herry
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From Alexander.Herr at csiro.au  Tue Mar  6 01:36:05 2018
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Tue, 6 Mar 2018 00:36:05 +0000
Subject: [R] raster time series statistics
In-Reply-To: <E9375221-D4C3-4D34-BAE0-EB1F2AB42ED2@comcast.net>
References: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
 <E9375221-D4C3-4D34-BAE0-EB1F2AB42ED2@comcast.net>
Message-ID: <a36c04372ea84db9a52ca9e1ade4fa9b@exch1-mel.nexus.csiro.au>

Last line in the following (updated) code produces the error
require(raster)
require(rts)
require(stringr)
r <- raster(ncol=100, nrow=100)
values(r) <- runif(ncell(r))
stack(r)->s
r->rs
for(i in 1:23){
 rs[]<-r[]*i
  addLayer(s,rs)->s
 print(nlayers(s))
}
dt<-list(ID=seq(1:24),month=rep(formatC(1:12,flag=0,width=2),2),
 year=sort(rep(2016:2017,12)))
 timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']),"-01")
strptime(timelst,format="%Y-%m-%d")->t1

rts(s,time=as.yearmon(t1))->rsts
subset(rsts,'2017')->r2017
class(r2017 at time)
class(rsts at time)

apply.monthly(rsts,mean)



-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Tuesday, 6 March 2018 11:10 AM
To: Herr, Alexander (L&W, Black Mountain) <Alexander.Herr at csiro.au>
Cc: r-help at r-project.org
Subject: Re: [R] raster time series statistics


> On Mar 5, 2018, at 3:28 PM, <Alexander.Herr at csiro.au> <Alexander.Herr at csiro.au> wrote:
> 
> Hi List,
> 
> The following code returns an "Error in as.POSIXlt.character(x, tz, ...) :   character string is not in a standard unambiguous format"

I'm unable to produce that error. Which function was being evaluated to produce the error? I don't see where as.POSIXlt would have been called. You don't have any Date or POSIXt-classed variables. (I did need to also load the stringr package to get str_pad into my workspace.)

> 
> require(raster)
> require(rts)
> require(stringi)
> r <- raster(ncol=100, nrow=100)
> values(r) <- runif(ncell(r))
> list(ID=seq(1:24),month=rep(str_pad(1:12, pad = 0,width = 2 , 
> "left"),2),year=sort(rep(2016:2017,12)))->dt
> stack(r)->s
> r->rs
> for(i in 1:23){
> rs[]<-r[]*i
>  addLayer(s,rs)->s
> print(nlayers(s))
> }
> timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']))
> rts(s,time=as.yearmon(timelst))->rsts
> str(rsts at time)
> apply.monthly(rsts,mean)
> 
> I was expecting that the statistics accept the yearmonth format of the timeslot, as it allows subsetting.
> Any suggestions?
> Thanks
> Herry
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From drjimlemon at gmail.com  Tue Mar  6 01:39:31 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 6 Mar 2018 11:39:31 +1100
Subject: [R] raster time series statistics
In-Reply-To: <a36c04372ea84db9a52ca9e1ade4fa9b@exch1-mel.nexus.csiro.au>
References: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
 <E9375221-D4C3-4D34-BAE0-EB1F2AB42ED2@comcast.net>
 <a36c04372ea84db9a52ca9e1ade4fa9b@exch1-mel.nexus.csiro.au>
Message-ID: <CA+8X3fXMSMPW_YLL6tpY1cqHYnaCLsFYFsgBpc1jiuM_dmUP3w@mail.gmail.com>

I can't test that at the moment as I don't have the libraries. Perhaps later.

Jim

On Tue, Mar 6, 2018 at 11:36 AM,  <Alexander.Herr at csiro.au> wrote:
> Last line in the following (updated) code produces the error
> require(raster)
> require(rts)
> require(stringr)
> r <- raster(ncol=100, nrow=100)
> values(r) <- runif(ncell(r))
> stack(r)->s
> r->rs
> for(i in 1:23){
>  rs[]<-r[]*i
>   addLayer(s,rs)->s
>  print(nlayers(s))
> }
> dt<-list(ID=seq(1:24),month=rep(formatC(1:12,flag=0,width=2),2),
>  year=sort(rep(2016:2017,12)))
>  timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']),"-01")
> strptime(timelst,format="%Y-%m-%d")->t1
>
> rts(s,time=as.yearmon(t1))->rsts
> subset(rsts,'2017')->r2017
> class(r2017 at time)
> class(rsts at time)
>
> apply.monthly(rsts,mean)
>
>
>
> -----Original Message-----
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Tuesday, 6 March 2018 11:10 AM
> To: Herr, Alexander (L&W, Black Mountain) <Alexander.Herr at csiro.au>
> Cc: r-help at r-project.org
> Subject: Re: [R] raster time series statistics
>
>
>> On Mar 5, 2018, at 3:28 PM, <Alexander.Herr at csiro.au> <Alexander.Herr at csiro.au> wrote:
>>
>> Hi List,
>>
>> The following code returns an "Error in as.POSIXlt.character(x, tz, ...) :   character string is not in a standard unambiguous format"
>
> I'm unable to produce that error. Which function was being evaluated to produce the error? I don't see where as.POSIXlt would have been called. You don't have any Date or POSIXt-classed variables. (I did need to also load the stringr package to get str_pad into my workspace.)
>
>>
>> require(raster)
>> require(rts)
>> require(stringi)
>> r <- raster(ncol=100, nrow=100)
>> values(r) <- runif(ncell(r))
>> list(ID=seq(1:24),month=rep(str_pad(1:12, pad = 0,width = 2 ,
>> "left"),2),year=sort(rep(2016:2017,12)))->dt
>> stack(r)->s
>> r->rs
>> for(i in 1:23){
>> rs[]<-r[]*i
>>  addLayer(s,rs)->s
>> print(nlayers(s))
>> }
>> timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']))
>> rts(s,time=as.yearmon(timelst))->rsts
>> str(rsts at time)
>> apply.monthly(rsts,mean)
>>
>> I was expecting that the statistics accept the yearmonth format of the timeslot, as it allows subsetting.
>> Any suggestions?
>> Thanks
>> Herry
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ycding at coh.org  Tue Mar  6 02:11:34 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Tue, 6 Mar 2018 01:11:34 +0000
Subject: [R] data analysis for partial two-by-two factorial design
In-Reply-To: <24D263EB-83D0-4604-B8A3-C50D5A9993D2@comcast.net>
References: <A86C6438FB909A409DDEF926277952B6A6BA75@PPWEXCH2KX14.coh.org>
 <CAGxFJbT0cVbTthk_VSTNdrD+EaFHtPP0qtBBksXPP77eDtWSFg@mail.gmail.com>
 <A86C6438FB909A409DDEF926277952B6A6C236@PPWEXCH2KX14.coh.org>
 <BE9F8A28-DECD-42D5-AA75-3E5CD2C807A6@comcast.net>
 <CAGxFJbRhdfzGhJX+nkOiqmabmYDCe-KFFNOz2=S83cp69gCFeQ@mail.gmail.com>
 <8415EA34-CC50-480C-A3CD-899604AEB953@comcast.net>
 <CAGxFJbRW_+EEqoMUBZ0KG-+yEPvV297Hxkpr8okR-OayuMUVtQ@mail.gmail.com>
 <24D263EB-83D0-4604-B8A3-C50D5A9993D2@comcast.net>
Message-ID: <A86C6438FB909A409DDEF926277952B6A6C536@PPWEXCH2KX14.coh.org>

Thanks a lot, after reading this message, I think I got the advantage of Bert's coding. Those two drugs indeed do not interact with each other, so additive assumption is valid. 

I learned a lot today. Thanks again.

Ding

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Monday, March 05, 2018 3:55 PM
To: Bert Gunter
Cc: Ding, Yuan Chun; r-help at r-project.org
Subject: Re: [R] data analysis for partial two-by-two factorial design


> On Mar 5, 2018, at 3:04 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> But of course the whole point of additivity is to decompose the combined effect as the sum of individual effects.

Agreed. Furthermore your encoding of the treatment assignments has the advantage that the default treatment contrast for A+B will have a statistical estimate associated with it. That was a deficiency of my encoding that Ding found problematic. I did have the incorrect notion that the encoding of Drug B in the single drug situation would have been NA and that the `lm`-function would produce nothing useful. Your setup had not occurred to me.

Best;
David.

> 
> "Mislead" is a subjective judgment, so no comment. The explanation I provided is standard. I used it for decades when I taught in industry.
> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Mar 5, 2018 at 3:00 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> > On Mar 5, 2018, at 2:27 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > David:
> >
> > I believe your response on SO is incorrect. This is a standard OFAT (one factor at a time) design, so that assuming additivity (no interactions), the effects of drugA and drugB can be determined via the model you rejected:
> 
> >> three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.
> 
> >
> > For example, if baseline control (no drugs) has a response of 0, drugA has an effect of 1, drugB has an effect of 2, and the effects are additive, with no noise we would have:
> >
> > > d <- data.frame(drugA = c("n","y","y"),drugB = c("n","n","y"))
> 
> d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB")
> >
> > > y <- c(0,1,3)
> >
> > And a straighforward inear model recovers the effects:
> >
> > > lm(y ~ drugA + drugB, data=d)
> >
> > Call:
> > lm(formula = y ~ drugA + drugB, data = d)
> >
> > Coefficients:
> > (Intercept)       drugAy       drugBy
> >   1.282e-16    1.000e+00    2.000e+00
> 
> I think the labeling above is rather to mislead since what is labeled drugB is actually A&B. I think the method I suggest is more likely to be interpreted correctly:
> 
> > d2 <- data.frame(trt = c("Baseline","DrugA_only","DrugA_drugB"))
> >  y <- c(0,1,3)
> > lm(y ~ trt, data=d2)
> 
> Call:
> lm(formula = y ~ trt, data = d2)
> 
> Coefficients:
>    (Intercept)  trtDrugA_drugB   trtDrugA_only
>      2.564e-16       3.000e+00       1.000e+00
> 
> --
> David.
> >
> > As usual, OFAT designs are blind to interactions, so that if they really exist, the interpretation as additive effects is incorrect.
> >
> > Cheers,
> > Bert
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> > On Mon, Mar 5, 2018 at 2:03 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >
> > > On Mar 5, 2018, at 8:52 AM, Ding, Yuan Chun <ycding at coh.org> wrote:
> > >
> > > Hi Bert,
> > >
> > > I am very sorry to bother you again.
> > >
> > > For the following question, as you suggested, I posted it in both Biostars website and stackexchange website, so far no reply.
> > >
> > > I really hope that you can do me a great favor to share your points about how to explain the coefficients for drug A and drug B if run anova model (response variable = drug A + drug B). is it different from running three separate T tests?
> > >
> > > Thank you so much!!
> > >
> > > Ding
> > >
> > > I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
> >
> > Replied on CrossValidated where this would be on-topic.
> >
> > --
> > David,
> >
> > >
> > >
> > > From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
> > > Sent: Friday, March 02, 2018 12:32 PM
> > > To: Ding, Yuan Chun
> > > Cc: r-help at r-project.org
> > > Subject: Re: [R] data analysis for partial two-by-two factorial 
> > > design
> > >
> > > ________________________________
> > > [Attention: This email came from an external source. Do not open 
> > > attachments or click on links from unknown senders or unexpected 
> > > emails.] ________________________________
> > >
> > > This list provides help on R programming (see the posting guide linked below for details on what is/is not considered on topic), and generally avoids discussion of purely statistical issues, which is what your query appears to be. The simple answer is yes, you can fit the model as described,  but you clearly need the off topic discussion as to what it does or does not mean. For that, you might try the stats.stackexchange.com<http://stats.stackexchange.com> statistical site.
> > >
> > > Cheers,
> > > Bert
> > >
> > >
> > > Bert Gunter
> > >
> > > "The trouble with having an open mind is that people keep coming along and sticking things into it."
> > > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> > >
> > > On Fri, Mar 2, 2018 at 10:34 AM, Ding, Yuan Chun <ycding at coh.org<mailto:ycding at coh.org>> wrote:
> > > Dear R users,
> > >
> > > I need to analyze data generated from a partial two-by-two factorial design: two levels for drug A (yes, no), two levels for drug B (yes, no);  however, data points are available only for three groups, no drugA/no drugB, yes drugA/no drugB, yes drugA/yes drug B, omitting the fourth group of no drugA/yes drugB.  I think we can not investigate interaction between drug A and drug B, can I still run  model using R as usual:  response variable = drug A + drug B?  any suggestion is appreciated.
> > >
> > > Thank you very much!
> > >
> > > Yuan Chun Ding
> > >
> > >
> > > ------------------------------------------------------------------
> > > --- -SECURITY/CONFIDENTIALITY WARNING- This message (and any 
> > > attachments) are intended solely f...{{dropped:28}}
> > >
> > > ______________________________________________
> > > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- 
> > > To UNSUBSCRIBE and more, see 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide 
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide 
> > > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From Alexander.Herr at csiro.au  Tue Mar  6 06:07:20 2018
From: Alexander.Herr at csiro.au (Alexander.Herr at csiro.au)
Date: Tue, 6 Mar 2018 05:07:20 +0000
Subject: [R] raster time series statistics
In-Reply-To: <CA+8X3fXMSMPW_YLL6tpY1cqHYnaCLsFYFsgBpc1jiuM_dmUP3w@mail.gmail.com>
References: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
 <E9375221-D4C3-4D34-BAE0-EB1F2AB42ED2@comcast.net>
 <a36c04372ea84db9a52ca9e1ade4fa9b@exch1-mel.nexus.csiro.au>
 <CA+8X3fXMSMPW_YLL6tpY1cqHYnaCLsFYFsgBpc1jiuM_dmUP3w@mail.gmail.com>
Message-ID: <dedd90e691884fe3a689c85270bc2001@exch1-mel.nexus.csiro.au>

It works if you use as.Date. But this defeates the purpose for the yearmon notion...

require(raster)
require(rts)
require(stringr)
r <- raster(ncol=100, nrow=100)
values(r) <- runif(ncell(r))
stack(r)->s
r->rs
for(i in 1:23){
 rs[]<-r[]*i
  addLayer(s,rs)->s
 print(nlayers(s))
}
dt<-list(ID=seq(1:24),month=rep(formatC(1:12,flag=0,width=2),2), year=sort(rep(2016:2017,12)))
 timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']),"-01")
strptime(timelst,format="%Y-%m-%d")->t1


rts(s,time=as.yearmon(t1))->rsts
subset(rsts,'2017')->r2017
class(r2017 at time)
class(rsts at time)
apply.monthly(rsts,mean) # this creates error

rts(s,time=as.Date(t1))->rsts1
apply.monthly(rsts1,mean) # this creates output


-----Original Message-----
From: Jim Lemon [mailto:drjimlemon at gmail.com] 
Sent: Tuesday, 6 March 2018 11:40 AM
To: Herr, Alexander (L&W, Black Mountain) <Alexander.Herr at csiro.au>
Cc: David Winsemius <dwinsemius at comcast.net>; r-help mailing list <r-help at r-project.org>
Subject: Re: [R] raster time series statistics


From dwinsemius at comcast.net  Tue Mar  6 09:10:53 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 6 Mar 2018 00:10:53 -0800
Subject: [R] raster time series statistics
In-Reply-To: <dedd90e691884fe3a689c85270bc2001@exch1-mel.nexus.csiro.au>
References: <23dca0338de74c379d558747afaddd0c@exch1-mel.nexus.csiro.au>
 <E9375221-D4C3-4D34-BAE0-EB1F2AB42ED2@comcast.net>
 <a36c04372ea84db9a52ca9e1ade4fa9b@exch1-mel.nexus.csiro.au>
 <CA+8X3fXMSMPW_YLL6tpY1cqHYnaCLsFYFsgBpc1jiuM_dmUP3w@mail.gmail.com>
 <dedd90e691884fe3a689c85270bc2001@exch1-mel.nexus.csiro.au>
Message-ID: <8B2AB422-C479-42D1-95DA-B3ADBC3F6AFD@comcast.net>


> On Mar 5, 2018, at 9:07 PM, <Alexander.Herr at csiro.au> <Alexander.Herr at csiro.au> wrote:
> 
> It works if you use as.Date. But this defeates the purpose for the yearmon notion...
> 
> require(raster)
> require(rts)
> require(stringr)
> r <- raster(ncol=100, nrow=100)
> values(r) <- runif(ncell(r))
> stack(r)->s
> r->rs
> for(i in 1:23){
> rs[]<-r[]*i
>  addLayer(s,rs)->s
> print(nlayers(s))
> }
> dt<-list(ID=seq(1:24),month=rep(formatC(1:12,flag=0,width=2),2), year=sort(rep(2016:2017,12)))
> timelst<-paste0(unlist(dt['year']),'-',unlist(dt['month']),"-01")
> strptime(timelst,format="%Y-%m-%d")->t1
> 
> 
> rts(s,time=as.yearmon(t1))->rsts
> subset(rsts,'2017')->r2017
> class(r2017 at time)
> class(rsts at time)
> apply.monthly(rsts,mean) # this creates error
> 
> rts(s,time=as.Date(t1))->rsts1
> apply.monthly(rsts1,mean) # this creates output

So it appears that you have shown that apply.monthly doesn't work with 'yearmon'-classed vectors in the endpoints of a RasterStackTS. It's not documented as doing so after all. So this is really a feature request for the maintainer. You should contact the responsible individual.

maintainer('rts')
[1] "Babak Naimi <naimi.b at gmail.com>"

> 
> 
> -----Original Message-----
> From: Jim Lemon [mailto:drjimlemon at gmail.com] 
> Sent: Tuesday, 6 March 2018 11:40 AM
> To: Herr, Alexander (L&W, Black Mountain) <Alexander.Herr at csiro.au>
> Cc: David Winsemius <dwinsemius at comcast.net>; r-help mailing list <r-help at r-project.org>
> Subject: Re: [R] raster time series statistics
> 

David Winsemius
Alameda, CA, USA


From nourdinekabouch at yahoo.com  Tue Mar  6 09:57:17 2018
From: nourdinekabouch at yahoo.com (Kabouch Nourdine)
Date: Tue, 6 Mar 2018 08:57:17 +0000 (UTC)
Subject: [R] package installation
References: <1510843236.11654309.1520326637297.ref@mail.yahoo.com>
Message-ID: <1510843236.11654309.1520326637297@mail.yahoo.com>

Hi,?When installing packages is there any?preferable path.
In my case I got this message in R consol:The downloaded binary packages are in? ? ? ? ?C: ~\ Temp \ RtmpQLTD5e \ downloaded_packages
this is a temporary files that I delete every time.
Is it possible to install packages in a specefic folder.
	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Tue Mar  6 10:26:10 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 6 Mar 2018 09:26:10 +0000
Subject: [R] package installation
In-Reply-To: <1510843236.11654309.1520326637297@mail.yahoo.com>
References: <1510843236.11654309.1520326637297.ref@mail.yahoo.com>
 <1510843236.11654309.1520326637297@mail.yahoo.com>
Message-ID: <a10884506af34d3882d48f3543ba20d2@SRVEXCHCM1301.precheza.cz>

Hi

If you installed through install.packages you could specify lib

see help page

lib
character vector giving the library directories where to install the packages. Recycled as needed. If missing, defaults to the first element of .libPaths().

But I believe you hardly need to do it. You probably do not know how to handle different locations for different packages and if you scatter packages within your computer you could have problems with invoking them.

Cheers
Petr


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Kabouch
> Nourdine via R-help
> Sent: Tuesday, March 6, 2018 9:57 AM
> To: r-help at r-project.org
> Subject: [R] package installation
>
> Hi, When installing packages is there any preferable path.
> In my case I got this message in R consol:The downloaded binary packages are
> in         C: ~\ Temp \ RtmpQLTD5e \ downloaded_packages this is a temporary
> files that I delete every time.
> Is it possible to install packages in a specefic folder.
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From faiz7r at gmail.com  Tue Mar  6 13:03:46 2018
From: faiz7r at gmail.com (faiz rasool)
Date: Tue, 6 Mar 2018 17:03:46 +0500
Subject: [R] couple of how-to-do it in R questions regarding corelations and
 mean and SD of likert items
Message-ID: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>

Dear list, I have the following how-to-do it in R, questions.

Suppose I have ten independent variables, and one dependent variable.
I want to find the Pearson correlation of all the IVs with the DV, but
not the correlation between the IVs.

What I know so far, about R, that I have to type the cor () function
ten times, each time requesting for a correlation between one IV and
the DV.

I was wondering that is there a way that I can accomplish what I want
with a single function or a fewer line of codes.

My final goal is to create a table in Microsoft word comprising of ten
rows, each row for each independent variable and its correlation with
the DV.

Based on what I know, I?ll be typing cor (IV,,DV), ten times, and then
typing the values in the table in MS  Word.


Secondly, I  would like to create a table that provides the details of
means and standard deviations, of multiple variables.

The variables are  ratings scores of  likert  type items. What I?d
like to do is to construct a table, where each row has the question,
its mean and standard deviation. I know that using the psych package,
I can have the mean of each item in the scale, but, how to develop a
table that has the item, mean, and SD on a same row? I do not know.

Thank you for reading my questions.

Regards,
Faiz.


From petr.pikal at precheza.cz  Tue Mar  6 14:10:10 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 6 Mar 2018 13:10:10 +0000
Subject: [R] 
 couple of how-to-do it in R questions regarding corelations and
 mean and SD of likert items
In-Reply-To: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
References: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
Message-ID: <0a559d5e649849c29c57f7efe81bea5a@SRVEXCHCM1301.precheza.cz>

Hi

For first question, maybe I am completely wrong but

cor(swiss[,-1], swiss[,1])

should give you what you want in one step.

Second question

Without an example it is hard to say but maybe aggregate is the way forward.

> aggregate(iris[,1:4], list(iris$Species), function (x) c(mean=mean(x), sd=sd(x)))
     Group.1 Sepal.Length.mean Sepal.Length.sd Sepal.Width.mean Sepal.Width.sd
1     setosa         5.0060000       0.3524897        3.4280000      0.3790644
2 versicolor         5.9360000       0.5161711        2.7700000      0.3137983
3  virginica         6.5880000       0.6358796        2.9740000      0.3224966

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of faiz rasool
> Sent: Tuesday, March 6, 2018 1:04 PM
> To: r-help at r-project.org
> Subject: [R] couple of how-to-do it in R questions regarding corelations and
> mean and SD of likert items
>
> Dear list, I have the following how-to-do it in R, questions.
>
> Suppose I have ten independent variables, and one dependent variable.
> I want to find the Pearson correlation of all the IVs with the DV, but not the
> correlation between the IVs.
>
> What I know so far, about R, that I have to type the cor () function ten times,
> each time requesting for a correlation between one IV and the DV.
>
> I was wondering that is there a way that I can accomplish what I want with a
> single function or a fewer line of codes.
>
> My final goal is to create a table in Microsoft word comprising of ten rows,
> each row for each independent variable and its correlation with the DV.
>
> Based on what I know, I?ll be typing cor (IV,,DV), ten times, and then typing the
> values in the table in MS  Word.
>
>
> Secondly, I  would like to create a table that provides the details of means and
> standard deviations, of multiple variables.
>
> The variables are  ratings scores of  likert  type items. What I?d like to do is to
> construct a table, where each row has the question, its mean and standard
> deviation. I know that using the psych package, I can have the mean of each
> item in the scale, but, how to develop a table that has the item, mean, and SD
> on a same row? I do not know.
>
> Thank you for reading my questions.
>
> Regards,
> Faiz.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From dcarlson at tamu.edu  Tue Mar  6 15:10:48 2018
From: dcarlson at tamu.edu (David L Carlson)
Date: Tue, 6 Mar 2018 14:10:48 +0000
Subject: [R] 
 couple of how-to-do it in R questions regarding corelations and
 mean and SD of likert items
In-Reply-To: <0a559d5e649849c29c57f7efe81bea5a@SRVEXCHCM1301.precheza.cz>
References: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
 <0a559d5e649849c29c57f7efe81bea5a@SRVEXCHCM1301.precheza.cz>
Message-ID: <10f097e41acc452ca655ab7b7cdd4164@exch-2p-mbx-w2.ads.tamu.edu>

Your quickest way to learn about R is to use the manual pages that are included with your installation. Typing the command ?cor produces a page with the following information:

x 	a numeric vector, *matrix* or *data frame*.
y 	NULL (default) or a vector, *matrix* or *data frame* with compatible dimensions to x. The default is equivalent to y = x (but more efficient).

In other words cor(x, y) gives you the correlations between x (rows) and y (columns). 

Descriptive statistics can be found in many packages and each organizes the material differently. In addition to aggregate() which makes it possible to put multiple variables on a single row, you might look at numSummary() in package RcmdrMisc if you want a single variable on each row:

library(RcmdrMisc)
data(iris)
options(digits=3)
numSummary(iris[, 1:4], statistics=c("mean", "sd"))
             mean    sd   n
Sepal.Length 5.84 0.828 150
Sepal.Width  3.06 0.436 150
Petal.Length 3.76 1.765 150
Petal.Width  1.20 0.762 150

numSummary(iris[, 1:4], statistics=c("mean", "sd"), groups=iris$Species)

Variable: Sepal.Length 
           mean    sd  n
setosa     5.01 0.352 50
versicolor 5.94 0.516 50
virginica  6.59 0.636 50

Variable: Sepal.Width 
           mean    sd  n
setosa     3.43 0.379 50
versicolor 2.77 0.314 50
virginica  2.97 0.322 50

Variable: Petal.Length 
           mean    sd  n
setosa     1.46 0.174 50
versicolor 4.26 0.470 50
virginica  5.55 0.552 50

Variable: Petal.Width 
            mean    sd  n
setosa     0.246 0.105 50
versicolor 1.326 0.198 50
virginica  2.026 0.275 50

---------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Tuesday, March 6, 2018 7:10 AM
To: faiz rasool <faiz7r at gmail.com>; r-help at r-project.org
Subject: Re: [R] couple of how-to-do it in R questions regarding corelations and mean and SD of likert items

Hi

For first question, maybe I am completely wrong but

cor(swiss[,-1], swiss[,1])

should give you what you want in one step.

Second question

Without an example it is hard to say but maybe aggregate is the way forward.

> aggregate(iris[,1:4], list(iris$Species), function (x) c(mean=mean(x), 
> sd=sd(x)))
     Group.1 Sepal.Length.mean Sepal.Length.sd Sepal.Width.mean Sepal.Width.sd
1     setosa         5.0060000       0.3524897        3.4280000      0.3790644
2 versicolor         5.9360000       0.5161711        2.7700000      0.3137983
3  virginica         6.5880000       0.6358796        2.9740000      0.3224966

Cheers
Petr

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of faiz 
> rasool
> Sent: Tuesday, March 6, 2018 1:04 PM
> To: r-help at r-project.org
> Subject: [R] couple of how-to-do it in R questions regarding 
> corelations and mean and SD of likert items
>
> Dear list, I have the following how-to-do it in R, questions.
>
> Suppose I have ten independent variables, and one dependent variable.
> I want to find the Pearson correlation of all the IVs with the DV, but 
> not the correlation between the IVs.
>
> What I know so far, about R, that I have to type the cor () function 
> ten times, each time requesting for a correlation between one IV and the DV.
>
> I was wondering that is there a way that I can accomplish what I want 
> with a single function or a fewer line of codes.
>
> My final goal is to create a table in Microsoft word comprising of ten 
> rows, each row for each independent variable and its correlation with the DV.
>
> Based on what I know, I?ll be typing cor (IV,,DV), ten times, and then 
> typing the values in the table in MS  Word.
>
>
> Secondly, I  would like to create a table that provides the details of 
> means and standard deviations, of multiple variables.
>
> The variables are  ratings scores of  likert  type items. What I?d 
> like to do is to construct a table, where each row has the question, 
> its mean and standard deviation. I know that using the psych package, 
> I can have the mean of each item in the scale, but, how to develop a 
> table that has the item, mean, and SD on a same row? I do not know.
>
> Thank you for reading my questions.
>
> Regards,
> Faiz.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.
______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From jdnewmil at dcn.davis.ca.us  Tue Mar  6 16:20:40 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 06 Mar 2018 07:20:40 -0800
Subject: [R] package installation
In-Reply-To: <1510843236.11654309.1520326637297@mail.yahoo.com>
References: <1510843236.11654309.1520326637297.ref@mail.yahoo.com>
 <1510843236.11654309.1520326637297@mail.yahoo.com>
Message-ID: <DA739F0E-A040-43AF-AB03-12B69AC08496@dcn.davis.ca.us>

There is the directory that the compressed file gets downloaded (Temp), and there is another directory where the the extracted files are "installed" ("library"). You can read all about this in the "R Administration and Installation Manual" that comes with R.
The message about the download directory occurs when the library cannot be written to. I am aware of two issues that can interfere with that step on Windows:

A) You have multiple copies of R open on Windows with existing packages open. Install packages with only one copy of R open. 

B) You ran R or the setup program with Administrator privileges at some point, and some or all of the packages in your user library (usually C:\Users\Yourname\Documents\R\win-library) have abnormal permissions. Cleaning up such a mess usually involves using Administrator privileges to completely remove C:\Users\Yourname\Documents\R\ and then starting R and installing all your packages again.
-- 
Sent from my phone. Please excuse my brevity.

On March 6, 2018 12:57:17 AM PST, Kabouch Nourdine via R-help <r-help at r-project.org> wrote:
>Hi,?When installing packages is there any?preferable path.
>In my case I got this message in R consol:The downloaded binary
>packages are in? ? ? ? ?C: ~\ Temp \ RtmpQLTD5e \ downloaded_packages
>this is a temporary files that I delete every time.
>Is it possible to install packages in a specefic folder.
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Tue Mar  6 17:21:52 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 6 Mar 2018 16:21:52 +0000
Subject: [R] 
 couple of how-to-do it in R questions regarding corelations and
 mean and SD of likert items
In-Reply-To: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
References: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
Message-ID: <40ca4899-a55f-2e42-c17a-b7d6a143f976@sapo.pt>

Hello,

You can use function apply() to do what you want without needing to type 
the same 10 times. Here is a reproducible example.

set.seed(2234)    # Make the results reproducible

# Make up some data
dv <- rnorm(100)
iv <- replicate(10, rnorm(100))

apply(iv, 2, cor, dv)

Now suppose you have a matrix (or data.frame)

dat <- cbind(dv, iv)

apply(dat[, -1], 2, cor, dat[, 1])


Hope this helps,

Rui Barradas



On 3/6/2018 12:03 PM, faiz rasool wrote:
> Dear list, I have the following how-to-do it in R, questions.
> 
> Suppose I have ten independent variables, and one dependent variable.
> I want to find the Pearson correlation of all the IVs with the DV, but
> not the correlation between the IVs.
> 
> What I know so far, about R, that I have to type the cor () function
> ten times, each time requesting for a correlation between one IV and
> the DV.
> 
> I was wondering that is there a way that I can accomplish what I want
> with a single function or a fewer line of codes.
> 
> My final goal is to create a table in Microsoft word comprising of ten
> rows, each row for each independent variable and its correlation with
> the DV.
> 
> Based on what I know, I?ll be typing cor (IV,,DV), ten times, and then
> typing the values in the table in MS  Word.
> 
> 
> Secondly, I  would like to create a table that provides the details of
> means and standard deviations, of multiple variables.
> 
> The variables are  ratings scores of  likert  type items. What I?d
> like to do is to construct a table, where each row has the question,
> its mean and standard deviation. I know that using the psych package,
> I can have the mean of each item in the scale, but, how to develop a
> table that has the item, mean, and SD on a same row? I do not know.
> 
> Thank you for reading my questions.
> 
> Regards,
> Faiz.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh at temple.edu  Tue Mar  6 17:29:20 2018
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 6 Mar 2018 11:29:20 -0500
Subject: [R] 
 couple of how-to-do it in R questions regarding corelations and
 mean and SD of likert items
In-Reply-To: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
References: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
Message-ID: <CAGx1TMCZAzoyQNRJRR49_EE4txRmmrVxGMwj0qyYCetyp_HEUw@mail.gmail.com>

Please look at the microplot package,

install.packages("microplot") ## it will bring in lots of other packages.

Specifically look at the demo

demo("tablesPlusGraphicColumn", package="microplot")

The last item in that demo is an MS Word table with the text of the
question, some numerical information, and the likert plot all in the
same table.
This is essentially what you are asking for.

Please write me off-list if you need help applying this to your data.
I am planning a new release of microplot in a few days, and I would
like to verify that your example works smoothly.

On Tue, Mar 6, 2018 at 7:03 AM, faiz rasool <faiz7r at gmail.com> wrote:
> Dear list, I have the following how-to-do it in R, questions.
>
> Suppose I have ten independent variables, and one dependent variable.
> I want to find the Pearson correlation of all the IVs with the DV, but
> not the correlation between the IVs.
>
> What I know so far, about R, that I have to type the cor () function
> ten times, each time requesting for a correlation between one IV and
> the DV.
>
> I was wondering that is there a way that I can accomplish what I want
> with a single function or a fewer line of codes.
>
> My final goal is to create a table in Microsoft word comprising of ten
> rows, each row for each independent variable and its correlation with
> the DV.
>
> Based on what I know, I?ll be typing cor (IV,,DV), ten times, and then
> typing the values in the table in MS  Word.
>
>
> Secondly, I  would like to create a table that provides the details of
> means and standard deviations, of multiple variables.
>
> The variables are  ratings scores of  likert  type items. What I?d
> like to do is to construct a table, where each row has the question,
> its mean and standard deviation. I know that using the psych package,
> I can have the mean of each item in the scale, but, how to develop a
> table that has the item, mean, and SD on a same row? I do not know.
>
> Thank you for reading my questions.
>
> Regards,
> Faiz.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Mar  6 21:55:47 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 7 Mar 2018 07:55:47 +1100
Subject: [R] 
 couple of how-to-do it in R questions regarding corelations and
 mean and SD of likert items
In-Reply-To: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
References: <CAFhDWBWUYDVg-=mZe2HWPfCknyK_gcfH=HgaaefpKb+-Mt45yw@mail.gmail.com>
Message-ID: <CA+8X3fUXS87yU+-=EJeaD+iCM6p7dnOVwBWcmgDjVg3pF0pP=Q@mail.gmail.com>

Hi Faiz,
Just to add to the confusion:

library(prettyR)
describe(iris)

You can specify which summary measures you want in the "num.desc" argument.

Jim

On Tue, Mar 6, 2018 at 11:03 PM, faiz rasool <faiz7r at gmail.com> wrote:
> Dear list, I have the following how-to-do it in R, questions.
>
> Suppose I have ten independent variables, and one dependent variable.
> I want to find the Pearson correlation of all the IVs with the DV, but
> not the correlation between the IVs.
>
> What I know so far, about R, that I have to type the cor () function
> ten times, each time requesting for a correlation between one IV and
> the DV.
>
> I was wondering that is there a way that I can accomplish what I want
> with a single function or a fewer line of codes.
>
> My final goal is to create a table in Microsoft word comprising of ten
> rows, each row for each independent variable and its correlation with
> the DV.
>
> Based on what I know, I?ll be typing cor (IV,,DV), ten times, and then
> typing the values in the table in MS  Word.
>
>
> Secondly, I  would like to create a table that provides the details of
> means and standard deviations, of multiple variables.
>
> The variables are  ratings scores of  likert  type items. What I?d
> like to do is to construct a table, where each row has the question,
> its mean and standard deviation. I know that using the psych package,
> I can have the mean of each item in the scale, but, how to develop a
> table that has the item, mean, and SD on a same row? I do not know.
>
> Thank you for reading my questions.
>
> Regards,
> Faiz.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From plessthanpointohfive at gmail.com  Tue Mar  6 23:26:52 2018
From: plessthanpointohfive at gmail.com (Jen)
Date: Tue, 06 Mar 2018 22:26:52 +0000
Subject: [R] Capturing warning within user-defined function
In-Reply-To: <deb72d0b3c85414fbed631e190f1943c@cdc.gov>
References: <deb72d0b3c85414fbed631e190f1943c@cdc.gov>
Message-ID: <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>

Hi, I am trying to automate the creation of tables for some simply
analyses. There are lots and lots of tables, thus the creation of a
user-defined function to make and output them to excel.

My problem is that some of the analyses have convergence issues, which I
want captured and included in the output so the folks looking at them know
how to view those estimates.

I am successfully able to do this in a straightforward set of steps.
However, once I place those steps inside a function it fails.

Here's the code (sorry this is a long post):

# create data
wt <- rgamma(6065, 0.7057511981,  0.0005502062)
grp <- sample(c(replicate(315, "Group1"), replicate(3672, "Group2"),
replicate(1080, "Group3"), replicate(998, "Group4")))
dta <- data.frame(grp, wt)
head(dta)
str(dta)

# declare design
my.svy <- svydesign(ids=~1, weights=~wt, data=dta)

# subset
grp1 <- subset(my.svy, grp == "Group1")

# set options and clear old warnings
options(warn=0)
assign("last.warning", NULL, envir = baseenv())

## proportions and CIs
p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])

# save warnings
wrn1 <- warnings(p)

ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])

## sample counts
n <- unwtd.count(~grp, grp1)[1]

## combine into table
overall <- data.frame(n, p, ci_l, ci_u)
colnames(overall) <- c("counts", "Group1", "LL", "UL")

## add any warnings
ind <- length(wrn1)
ind

if (ind == 0) { msg <- "No warnings" }
if (ind > 0) {msg <- names(warnings()) }
overall[1,5] <- msg

print(overall)

Here's the output from the above:

> # set options and clear old warnings
> options(warn=0)
> assign("last.warning", NULL, envir = baseenv())
>
> ## proportions and CIs
> p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
Warning message:
glm.fit: algorithm did not converge
>
> # save warnings
> wrn1 <- warnings(p)
>
> ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
Warning message:
glm.fit: algorithm did not converge
> ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
Warning message:
glm.fit: algorithm did not converge
>
> ## sample counts
> n <- unwtd.count(~grp, grp1)[1]
>
> ## combine into table
> overall <- data.frame(n, p, ci_l, ci_u)
> colnames(overall) <- c("counts", "Group1", "LL", "UL")
>
> ## add any warnings
> ind <- length(wrn1)
> ind
[1] 1
>
> if (ind == 0) { msg <- "No warnings" }
> if (ind > 0) {msg <- names(warnings()) }
> overall[1,5] <- msg
>
> print(overall)
       counts       Group1           LL           UL
          V5
counts    315 2.364636e-12 2.002372e-12 2.792441e-12 glm.fit: algorithm did
not converge

Here's the function:

est <- function(var) {

## set up formula
formula <- paste ("~", var)

## set options and clear old warning
options(warn=0)
assign("last.warning", NULL, envir = baseenv())

## proportions and CIs
p <- ((svyciprop(as.formula(formula), grp1, family=quasibinomial))[1])

## save warnings
wrn1 <- warnings(p)

ci_l <- (confint(svyciprop(as.formula(formula) , grp1,
family=quasibinomial), 'ci')[1])
ci_u <- (confint(svyciprop(as.formula(formula) , grp1,
family=quasibinomial), 'ci')[2])

## sample counts
n <- unwtd.count(as.formula(formula), grp1)[1]

## combine into table
overall <- data.frame(n, p, ci_l, ci_u)
colnames(overall) <- c("counts", "Group1", "LL", "UL")


## add any warnings
ind <- length(warnings(p))
print(ind)

if (ind == 0) { msg <- "No warnings" }
if (ind > 0) {msg <- names(warnings()) }
overall[1,5] <- msg

print(overall)

}

Here's the output from running the function:

> est("grp")
[1] 0
       counts       Group1           LL           UL          V5
counts    315 2.364636e-12 2.002372e-12 2.792441e-12 No warnings
Warning messages:
1: glm.fit: algorithm did not converge
2: glm.fit: algorithm did not converge
3: glm.fit: algorithm did not converge

So, the warnings are showing up in the output at the end of the function
but they're not being captured like they are when run outside of the
function. Note the 0 output from print(ind) and V7 has "No warnings".
I know a lot of things "behave" differently inside functions. Case in
point, the use of "as.formula(var)" rather than just "~grp" being passed to
the function.

I've failed to find a solution after much searching of various R related
forums. I even posted this to stackoverflow but with no response. So, if
anyone can help, I'd be appreciative.

(sidenote: I used rgamma to create my sampling weights because that's what
most resembles the distribution of my weights and it's close enough to
reproduce the convergence issue. If I used rnorm or even rlnorm or rweibull
I couldn't reproduce it. Just FYI.)

Best,

Jen

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Mar  6 23:41:59 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Mar 2018 14:41:59 -0800
Subject: [R] Capturing warning within user-defined function
In-Reply-To: <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>
References: <deb72d0b3c85414fbed631e190f1943c@cdc.gov>
 <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>
Message-ID: <CAF8bMcbEjwb6jFxi7Z04X6Z88pXxkexXuC-4ciBZL3SJTAHYcg@mail.gmail.com>

You can capture warnings by using withCallingHandlers.   Here is an example,
its help file has more information.

dataList <- list(
   A = data.frame(y=c(TRUE,TRUE,TRUE,FALSE,FALSE), x=1:5),
   B = data.frame(y=c(TRUE,TRUE,FALSE,TRUE,FALSE), x=1:5),
   C = data.frame(y=c(FALSE,FALSE,TRUE,TRUE,TRUE), x=1:5))

withWarnings <- function(expr) {
   .warnings <- NULL # warning handler will append to this using '<<-'
   value <- withCallingHandlers(expr,
                                warning=function(e) {
                                    .warnings <<- c(.warnings,
conditionMessage(e))
                                    invokeRestart("muffleWarning")
                                })
   structure(value, warnings=.warnings)
}
z <- lapply(dataList, function(data) withWarnings(coef(glm(data=data, y ~
x, family=binomial))))
z

The last line produces

> z
$A
(Intercept)           x
  160.80782   -45.97184
attr(,"warnings")
[1] "glm.fit: fitted probabilities numerically 0 or 1 occurred"

$B
(Intercept)           x
   3.893967   -1.090426

$C
(Intercept)           x
 -115.02321    45.97184
attr(,"warnings")
[1] "glm.fit: fitted probabilities numerically 0 or 1 occurred"

and lapply(z, attr, "warnings") will give you the warnings themselves.



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 6, 2018 at 2:26 PM, Jen <plessthanpointohfive at gmail.com> wrote:

> Hi, I am trying to automate the creation of tables for some simply
> analyses. There are lots and lots of tables, thus the creation of a
> user-defined function to make and output them to excel.
>
> My problem is that some of the analyses have convergence issues, which I
> want captured and included in the output so the folks looking at them know
> how to view those estimates.
>
> I am successfully able to do this in a straightforward set of steps.
> However, once I place those steps inside a function it fails.
>
> Here's the code (sorry this is a long post):
>
> # create data
> wt <- rgamma(6065, 0.7057511981,  0.0005502062)
> grp <- sample(c(replicate(315, "Group1"), replicate(3672, "Group2"),
> replicate(1080, "Group3"), replicate(998, "Group4")))
> dta <- data.frame(grp, wt)
> head(dta)
> str(dta)
>
> # declare design
> my.svy <- svydesign(ids=~1, weights=~wt, data=dta)
>
> # subset
> grp1 <- subset(my.svy, grp == "Group1")
>
> # set options and clear old warnings
> options(warn=0)
> assign("last.warning", NULL, envir = baseenv())
>
> ## proportions and CIs
> p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
>
> # save warnings
> wrn1 <- warnings(p)
>
> ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
> ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
>
> ## sample counts
> n <- unwtd.count(~grp, grp1)[1]
>
> ## combine into table
> overall <- data.frame(n, p, ci_l, ci_u)
> colnames(overall) <- c("counts", "Group1", "LL", "UL")
>
> ## add any warnings
> ind <- length(wrn1)
> ind
>
> if (ind == 0) { msg <- "No warnings" }
> if (ind > 0) {msg <- names(warnings()) }
> overall[1,5] <- msg
>
> print(overall)
>
> Here's the output from the above:
>
> > # set options and clear old warnings
> > options(warn=0)
> > assign("last.warning", NULL, envir = baseenv())
> >
> > ## proportions and CIs
> > p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
> Warning message:
> glm.fit: algorithm did not converge
> >
> > # save warnings
> > wrn1 <- warnings(p)
> >
> > ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
> Warning message:
> glm.fit: algorithm did not converge
> > ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
> Warning message:
> glm.fit: algorithm did not converge
> >
> > ## sample counts
> > n <- unwtd.count(~grp, grp1)[1]
> >
> > ## combine into table
> > overall <- data.frame(n, p, ci_l, ci_u)
> > colnames(overall) <- c("counts", "Group1", "LL", "UL")
> >
> > ## add any warnings
> > ind <- length(wrn1)
> > ind
> [1] 1
> >
> > if (ind == 0) { msg <- "No warnings" }
> > if (ind > 0) {msg <- names(warnings()) }
> > overall[1,5] <- msg
> >
> > print(overall)
>        counts       Group1           LL           UL
>           V5
> counts    315 2.364636e-12 2.002372e-12 2.792441e-12 glm.fit: algorithm did
> not converge
>
> Here's the function:
>
> est <- function(var) {
>
> ## set up formula
> formula <- paste ("~", var)
>
> ## set options and clear old warning
> options(warn=0)
> assign("last.warning", NULL, envir = baseenv())
>
> ## proportions and CIs
> p <- ((svyciprop(as.formula(formula), grp1, family=quasibinomial))[1])
>
> ## save warnings
> wrn1 <- warnings(p)
>
> ci_l <- (confint(svyciprop(as.formula(formula) , grp1,
> family=quasibinomial), 'ci')[1])
> ci_u <- (confint(svyciprop(as.formula(formula) , grp1,
> family=quasibinomial), 'ci')[2])
>
> ## sample counts
> n <- unwtd.count(as.formula(formula), grp1)[1]
>
> ## combine into table
> overall <- data.frame(n, p, ci_l, ci_u)
> colnames(overall) <- c("counts", "Group1", "LL", "UL")
>
>
> ## add any warnings
> ind <- length(warnings(p))
> print(ind)
>
> if (ind == 0) { msg <- "No warnings" }
> if (ind > 0) {msg <- names(warnings()) }
> overall[1,5] <- msg
>
> print(overall)
>
> }
>
> Here's the output from running the function:
>
> > est("grp")
> [1] 0
>        counts       Group1           LL           UL          V5
> counts    315 2.364636e-12 2.002372e-12 2.792441e-12 No warnings
> Warning messages:
> 1: glm.fit: algorithm did not converge
> 2: glm.fit: algorithm did not converge
> 3: glm.fit: algorithm did not converge
>
> So, the warnings are showing up in the output at the end of the function
> but they're not being captured like they are when run outside of the
> function. Note the 0 output from print(ind) and V7 has "No warnings".
> I know a lot of things "behave" differently inside functions. Case in
> point, the use of "as.formula(var)" rather than just "~grp" being passed to
> the function.
>
> I've failed to find a solution after much searching of various R related
> forums. I even posted this to stackoverflow but with no response. So, if
> anyone can help, I'd be appreciative.
>
> (sidenote: I used rgamma to create my sampling weights because that's what
> most resembles the distribution of my weights and it's close enough to
> reproduce the convergence issue. If I used rnorm or even rlnorm or rweibull
> I couldn't reproduce it. Just FYI.)
>
> Best,
>
> Jen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar  6 23:45:30 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 6 Mar 2018 14:45:30 -0800
Subject: [R] Capturing warning within user-defined function
In-Reply-To: <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>
References: <deb72d0b3c85414fbed631e190f1943c@cdc.gov>
 <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>
Message-ID: <CAGxFJbQgyp6A95rGTSfWjZiGVhg0kXbDfTtwzoVA1SJk6ig9hg@mail.gmail.com>

1. I did not attempt to sort through your voluminous code. But I suspect
you are trying to reinvent wheels.

2. I don't understand this:

"I've failed to find a solution after much searching of various R related
forums."

A web search on "error handling in R" **immediately** brought up ?tryCatch,
which I think is what you want.
If not, you should probably explain why it isn't, so that someone with more
patience than I can muster will sort through your code to help.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Mar 6, 2018 at 2:26 PM, Jen <plessthanpointohfive at gmail.com> wrote:

> Hi, I am trying to automate the creation of tables for some simply
> analyses. There are lots and lots of tables, thus the creation of a
> user-defined function to make and output them to excel.
>
> My problem is that some of the analyses have convergence issues, which I
> want captured and included in the output so the folks looking at them know
> how to view those estimates.
>
> I am successfully able to do this in a straightforward set of steps.
> However, once I place those steps inside a function it fails.
>
> Here's the code (sorry this is a long post):
>
> # create data
> wt <- rgamma(6065, 0.7057511981,  0.0005502062)
> grp <- sample(c(replicate(315, "Group1"), replicate(3672, "Group2"),
> replicate(1080, "Group3"), replicate(998, "Group4")))
> dta <- data.frame(grp, wt)
> head(dta)
> str(dta)
>
> # declare design
> my.svy <- svydesign(ids=~1, weights=~wt, data=dta)
>
> # subset
> grp1 <- subset(my.svy, grp == "Group1")
>
> # set options and clear old warnings
> options(warn=0)
> assign("last.warning", NULL, envir = baseenv())
>
> ## proportions and CIs
> p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
>
> # save warnings
> wrn1 <- warnings(p)
>
> ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
> ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
>
> ## sample counts
> n <- unwtd.count(~grp, grp1)[1]
>
> ## combine into table
> overall <- data.frame(n, p, ci_l, ci_u)
> colnames(overall) <- c("counts", "Group1", "LL", "UL")
>
> ## add any warnings
> ind <- length(wrn1)
> ind
>
> if (ind == 0) { msg <- "No warnings" }
> if (ind > 0) {msg <- names(warnings()) }
> overall[1,5] <- msg
>
> print(overall)
>
> Here's the output from the above:
>
> > # set options and clear old warnings
> > options(warn=0)
> > assign("last.warning", NULL, envir = baseenv())
> >
> > ## proportions and CIs
> > p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
> Warning message:
> glm.fit: algorithm did not converge
> >
> > # save warnings
> > wrn1 <- warnings(p)
> >
> > ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
> Warning message:
> glm.fit: algorithm did not converge
> > ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
> Warning message:
> glm.fit: algorithm did not converge
> >
> > ## sample counts
> > n <- unwtd.count(~grp, grp1)[1]
> >
> > ## combine into table
> > overall <- data.frame(n, p, ci_l, ci_u)
> > colnames(overall) <- c("counts", "Group1", "LL", "UL")
> >
> > ## add any warnings
> > ind <- length(wrn1)
> > ind
> [1] 1
> >
> > if (ind == 0) { msg <- "No warnings" }
> > if (ind > 0) {msg <- names(warnings()) }
> > overall[1,5] <- msg
> >
> > print(overall)
>        counts       Group1           LL           UL
>           V5
> counts    315 2.364636e-12 2.002372e-12 2.792441e-12 glm.fit: algorithm did
> not converge
>
> Here's the function:
>
> est <- function(var) {
>
> ## set up formula
> formula <- paste ("~", var)
>
> ## set options and clear old warning
> options(warn=0)
> assign("last.warning", NULL, envir = baseenv())
>
> ## proportions and CIs
> p <- ((svyciprop(as.formula(formula), grp1, family=quasibinomial))[1])
>
> ## save warnings
> wrn1 <- warnings(p)
>
> ci_l <- (confint(svyciprop(as.formula(formula) , grp1,
> family=quasibinomial), 'ci')[1])
> ci_u <- (confint(svyciprop(as.formula(formula) , grp1,
> family=quasibinomial), 'ci')[2])
>
> ## sample counts
> n <- unwtd.count(as.formula(formula), grp1)[1]
>
> ## combine into table
> overall <- data.frame(n, p, ci_l, ci_u)
> colnames(overall) <- c("counts", "Group1", "LL", "UL")
>
>
> ## add any warnings
> ind <- length(warnings(p))
> print(ind)
>
> if (ind == 0) { msg <- "No warnings" }
> if (ind > 0) {msg <- names(warnings()) }
> overall[1,5] <- msg
>
> print(overall)
>
> }
>
> Here's the output from running the function:
>
> > est("grp")
> [1] 0
>        counts       Group1           LL           UL          V5
> counts    315 2.364636e-12 2.002372e-12 2.792441e-12 No warnings
> Warning messages:
> 1: glm.fit: algorithm did not converge
> 2: glm.fit: algorithm did not converge
> 3: glm.fit: algorithm did not converge
>
> So, the warnings are showing up in the output at the end of the function
> but they're not being captured like they are when run outside of the
> function. Note the 0 output from print(ind) and V7 has "No warnings".
> I know a lot of things "behave" differently inside functions. Case in
> point, the use of "as.formula(var)" rather than just "~grp" being passed to
> the function.
>
> I've failed to find a solution after much searching of various R related
> forums. I even posted this to stackoverflow but with no response. So, if
> anyone can help, I'd be appreciative.
>
> (sidenote: I used rgamma to create my sampling weights because that's what
> most resembles the distribution of my weights and it's close enough to
> reproduce the convergence issue. If I used rnorm or even rlnorm or rweibull
> I couldn't reproduce it. Just FYI.)
>
> Best,
>
> Jen
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From plessthanpointohfive at gmail.com  Tue Mar  6 23:48:06 2018
From: plessthanpointohfive at gmail.com (Jen)
Date: Tue, 06 Mar 2018 22:48:06 +0000
Subject: [R] Capturing warning within user-defined function
In-Reply-To: <CAF8bMcbEjwb6jFxi7Z04X6Z88pXxkexXuC-4ciBZL3SJTAHYcg@mail.gmail.com>
References: <deb72d0b3c85414fbed631e190f1943c@cdc.gov>
 <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>
 <CAF8bMcbEjwb6jFxi7Z04X6Z88pXxkexXuC-4ciBZL3SJTAHYcg@mail.gmail.com>
Message-ID: <CAOxgQ=Wp3BTT7+no06Euvo5siL18fSQz_xYU1xkpt8gev7sRHQ@mail.gmail.com>

Hi William,

Thanks, I'll give that a shot. I tried using withCallingHandlers without
success but II admit I'm not familiar with it and may have used it wrong.

I'll report back.

Jen


On Tue, Mar 6, 2018, 5:42 PM William Dunlap <wdunlap at tibco.com> wrote:

> You can capture warnings by using withCallingHandlers.   Here is an
> example,
> its help file has more information.
>
> dataList <- list(
>    A = data.frame(y=c(TRUE,TRUE,TRUE,FALSE,FALSE), x=1:5),
>    B = data.frame(y=c(TRUE,TRUE,FALSE,TRUE,FALSE), x=1:5),
>    C = data.frame(y=c(FALSE,FALSE,TRUE,TRUE,TRUE), x=1:5))
>
> withWarnings <- function(expr) {
>    .warnings <- NULL # warning handler will append to this using '<<-'
>    value <- withCallingHandlers(expr,
>                                 warning=function(e) {
>                                     .warnings <<- c(.warnings,
> conditionMessage(e))
>                                     invokeRestart("muffleWarning")
>                                 })
>    structure(value, warnings=.warnings)
> }
> z <- lapply(dataList, function(data) withWarnings(coef(glm(data=data, y ~
> x, family=binomial))))
> z
>
> The last line produces
>
> > z
> $A
> (Intercept)           x
>   160.80782   -45.97184
> attr(,"warnings")
> [1] "glm.fit: fitted probabilities numerically 0 or 1 occurred"
>
> $B
> (Intercept)           x
>    3.893967   -1.090426
>
> $C
> (Intercept)           x
>  -115.02321    45.97184
> attr(,"warnings")
> [1] "glm.fit: fitted probabilities numerically 0 or 1 occurred"
>
> and lapply(z, attr, "warnings") will give you the warnings themselves.
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Mar 6, 2018 at 2:26 PM, Jen <plessthanpointohfive at gmail.com>
> wrote:
>
>> Hi, I am trying to automate the creation of tables for some simply
>> analyses. There are lots and lots of tables, thus the creation of a
>> user-defined function to make and output them to excel.
>>
>> My problem is that some of the analyses have convergence issues, which I
>> want captured and included in the output so the folks looking at them know
>> how to view those estimates.
>>
>> I am successfully able to do this in a straightforward set of steps.
>> However, once I place those steps inside a function it fails.
>>
>> Here's the code (sorry this is a long post):
>>
>> # create data
>> wt <- rgamma(6065, 0.7057511981,  0.0005502062)
>> grp <- sample(c(replicate(315, "Group1"), replicate(3672, "Group2"),
>> replicate(1080, "Group3"), replicate(998, "Group4")))
>> dta <- data.frame(grp, wt)
>> head(dta)
>> str(dta)
>>
>> # declare design
>> my.svy <- svydesign(ids=~1, weights=~wt, data=dta)
>>
>> # subset
>> grp1 <- subset(my.svy, grp == "Group1")
>>
>> # set options and clear old warnings
>> options(warn=0)
>> assign("last.warning", NULL, envir = baseenv())
>>
>> ## proportions and CIs
>> p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
>>
>> # save warnings
>> wrn1 <- warnings(p)
>>
>> ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
>> ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
>>
>> ## sample counts
>> n <- unwtd.count(~grp, grp1)[1]
>>
>> ## combine into table
>> overall <- data.frame(n, p, ci_l, ci_u)
>> colnames(overall) <- c("counts", "Group1", "LL", "UL")
>>
>> ## add any warnings
>> ind <- length(wrn1)
>> ind
>>
>> if (ind == 0) { msg <- "No warnings" }
>> if (ind > 0) {msg <- names(warnings()) }
>> overall[1,5] <- msg
>>
>> print(overall)
>>
>> Here's the output from the above:
>>
>> > # set options and clear old warnings
>> > options(warn=0)
>> > assign("last.warning", NULL, envir = baseenv())
>> >
>> > ## proportions and CIs
>> > p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
>> Warning message:
>> glm.fit: algorithm did not converge
>> >
>> > # save warnings
>> > wrn1 <- warnings(p)
>> >
>> > ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
>> Warning message:
>> glm.fit: algorithm did not converge
>> > ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
>> Warning message:
>> glm.fit: algorithm did not converge
>> >
>> > ## sample counts
>> > n <- unwtd.count(~grp, grp1)[1]
>> >
>> > ## combine into table
>> > overall <- data.frame(n, p, ci_l, ci_u)
>> > colnames(overall) <- c("counts", "Group1", "LL", "UL")
>> >
>> > ## add any warnings
>> > ind <- length(wrn1)
>> > ind
>> [1] 1
>> >
>> > if (ind == 0) { msg <- "No warnings" }
>> > if (ind > 0) {msg <- names(warnings()) }
>> > overall[1,5] <- msg
>> >
>> > print(overall)
>>        counts       Group1           LL           UL
>>           V5
>> counts    315 2.364636e-12 2.002372e-12 2.792441e-12 glm.fit: algorithm
>> did
>> not converge
>>
>> Here's the function:
>>
>> est <- function(var) {
>>
>> ## set up formula
>> formula <- paste ("~", var)
>>
>> ## set options and clear old warning
>> options(warn=0)
>> assign("last.warning", NULL, envir = baseenv())
>>
>> ## proportions and CIs
>> p <- ((svyciprop(as.formula(formula), grp1, family=quasibinomial))[1])
>>
>> ## save warnings
>> wrn1 <- warnings(p)
>>
>> ci_l <- (confint(svyciprop(as.formula(formula) , grp1,
>> family=quasibinomial), 'ci')[1])
>> ci_u <- (confint(svyciprop(as.formula(formula) , grp1,
>> family=quasibinomial), 'ci')[2])
>>
>> ## sample counts
>> n <- unwtd.count(as.formula(formula), grp1)[1]
>>
>> ## combine into table
>> overall <- data.frame(n, p, ci_l, ci_u)
>> colnames(overall) <- c("counts", "Group1", "LL", "UL")
>>
>>
>> ## add any warnings
>> ind <- length(warnings(p))
>> print(ind)
>>
>> if (ind == 0) { msg <- "No warnings" }
>> if (ind > 0) {msg <- names(warnings()) }
>> overall[1,5] <- msg
>>
>> print(overall)
>>
>> }
>>
>> Here's the output from running the function:
>>
>> > est("grp")
>> [1] 0
>>        counts       Group1           LL           UL          V5
>> counts    315 2.364636e-12 2.002372e-12 2.792441e-12 No warnings
>> Warning messages:
>> 1: glm.fit: algorithm did not converge
>> 2: glm.fit: algorithm did not converge
>> 3: glm.fit: algorithm did not converge
>>
>> So, the warnings are showing up in the output at the end of the function
>> but they're not being captured like they are when run outside of the
>> function. Note the 0 output from print(ind) and V7 has "No warnings".
>> I know a lot of things "behave" differently inside functions. Case in
>> point, the use of "as.formula(var)" rather than just "~grp" being passed
>> to
>> the function.
>>
>> I've failed to find a solution after much searching of various R related
>> forums. I even posted this to stackoverflow but with no response. So, if
>> anyone can help, I'd be appreciative.
>>
>> (sidenote: I used rgamma to create my sampling weights because that's what
>> most resembles the distribution of my weights and it's close enough to
>> reproduce the convergence issue. If I used rnorm or even rlnorm or
>> rweibull
>> I couldn't reproduce it. Just FYI.)
>>
>> Best,
>>
>> Jen
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Tue Mar  6 23:57:36 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 6 Mar 2018 14:57:36 -0800
Subject: [R] Capturing warning within user-defined function
In-Reply-To: <CAGxFJbQgyp6A95rGTSfWjZiGVhg0kXbDfTtwzoVA1SJk6ig9hg@mail.gmail.com>
References: <deb72d0b3c85414fbed631e190f1943c@cdc.gov>
 <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>
 <CAGxFJbQgyp6A95rGTSfWjZiGVhg0kXbDfTtwzoVA1SJk6ig9hg@mail.gmail.com>
Message-ID: <CAF8bMcbH0PRRKH-ZaVSsduTsHd75QhfAXzaL7s0AcxXG+tZguw@mail.gmail.com>

tryCatch() is good for catching errors but not so good for warnings, as
it does not let you resume evaluating the expression that emitted
the warning.  withCallingHandlers(), with its companion invokeRestart(),
lets you collect the warnings while letting the evaluation run to
completion.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 6, 2018 at 2:45 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> 1. I did not attempt to sort through your voluminous code. But I suspect
> you are trying to reinvent wheels.
>
> 2. I don't understand this:
>
> "I've failed to find a solution after much searching of various R related
> forums."
>
> A web search on "error handling in R" **immediately** brought up ?tryCatch,
> which I think is what you want.
> If not, you should probably explain why it isn't, so that someone with more
> patience than I can muster will sort through your code to help.
>
> Cheers,
> Bert
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Tue, Mar 6, 2018 at 2:26 PM, Jen <plessthanpointohfive at gmail.com>
> wrote:
>
> > Hi, I am trying to automate the creation of tables for some simply
> > analyses. There are lots and lots of tables, thus the creation of a
> > user-defined function to make and output them to excel.
> >
> > My problem is that some of the analyses have convergence issues, which I
> > want captured and included in the output so the folks looking at them
> know
> > how to view those estimates.
> >
> > I am successfully able to do this in a straightforward set of steps.
> > However, once I place those steps inside a function it fails.
> >
> > Here's the code (sorry this is a long post):
> >
> > # create data
> > wt <- rgamma(6065, 0.7057511981,  0.0005502062)
> > grp <- sample(c(replicate(315, "Group1"), replicate(3672, "Group2"),
> > replicate(1080, "Group3"), replicate(998, "Group4")))
> > dta <- data.frame(grp, wt)
> > head(dta)
> > str(dta)
> >
> > # declare design
> > my.svy <- svydesign(ids=~1, weights=~wt, data=dta)
> >
> > # subset
> > grp1 <- subset(my.svy, grp == "Group1")
> >
> > # set options and clear old warnings
> > options(warn=0)
> > assign("last.warning", NULL, envir = baseenv())
> >
> > ## proportions and CIs
> > p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
> >
> > # save warnings
> > wrn1 <- warnings(p)
> >
> > ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
> > ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
> >
> > ## sample counts
> > n <- unwtd.count(~grp, grp1)[1]
> >
> > ## combine into table
> > overall <- data.frame(n, p, ci_l, ci_u)
> > colnames(overall) <- c("counts", "Group1", "LL", "UL")
> >
> > ## add any warnings
> > ind <- length(wrn1)
> > ind
> >
> > if (ind == 0) { msg <- "No warnings" }
> > if (ind > 0) {msg <- names(warnings()) }
> > overall[1,5] <- msg
> >
> > print(overall)
> >
> > Here's the output from the above:
> >
> > > # set options and clear old warnings
> > > options(warn=0)
> > > assign("last.warning", NULL, envir = baseenv())
> > >
> > > ## proportions and CIs
> > > p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
> > Warning message:
> > glm.fit: algorithm did not converge
> > >
> > > # save warnings
> > > wrn1 <- warnings(p)
> > >
> > > ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
> > Warning message:
> > glm.fit: algorithm did not converge
> > > ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
> > Warning message:
> > glm.fit: algorithm did not converge
> > >
> > > ## sample counts
> > > n <- unwtd.count(~grp, grp1)[1]
> > >
> > > ## combine into table
> > > overall <- data.frame(n, p, ci_l, ci_u)
> > > colnames(overall) <- c("counts", "Group1", "LL", "UL")
> > >
> > > ## add any warnings
> > > ind <- length(wrn1)
> > > ind
> > [1] 1
> > >
> > > if (ind == 0) { msg <- "No warnings" }
> > > if (ind > 0) {msg <- names(warnings()) }
> > > overall[1,5] <- msg
> > >
> > > print(overall)
> >        counts       Group1           LL           UL
> >           V5
> > counts    315 2.364636e-12 2.002372e-12 2.792441e-12 glm.fit: algorithm
> did
> > not converge
> >
> > Here's the function:
> >
> > est <- function(var) {
> >
> > ## set up formula
> > formula <- paste ("~", var)
> >
> > ## set options and clear old warning
> > options(warn=0)
> > assign("last.warning", NULL, envir = baseenv())
> >
> > ## proportions and CIs
> > p <- ((svyciprop(as.formula(formula), grp1, family=quasibinomial))[1])
> >
> > ## save warnings
> > wrn1 <- warnings(p)
> >
> > ci_l <- (confint(svyciprop(as.formula(formula) , grp1,
> > family=quasibinomial), 'ci')[1])
> > ci_u <- (confint(svyciprop(as.formula(formula) , grp1,
> > family=quasibinomial), 'ci')[2])
> >
> > ## sample counts
> > n <- unwtd.count(as.formula(formula), grp1)[1]
> >
> > ## combine into table
> > overall <- data.frame(n, p, ci_l, ci_u)
> > colnames(overall) <- c("counts", "Group1", "LL", "UL")
> >
> >
> > ## add any warnings
> > ind <- length(warnings(p))
> > print(ind)
> >
> > if (ind == 0) { msg <- "No warnings" }
> > if (ind > 0) {msg <- names(warnings()) }
> > overall[1,5] <- msg
> >
> > print(overall)
> >
> > }
> >
> > Here's the output from running the function:
> >
> > > est("grp")
> > [1] 0
> >        counts       Group1           LL           UL          V5
> > counts    315 2.364636e-12 2.002372e-12 2.792441e-12 No warnings
> > Warning messages:
> > 1: glm.fit: algorithm did not converge
> > 2: glm.fit: algorithm did not converge
> > 3: glm.fit: algorithm did not converge
> >
> > So, the warnings are showing up in the output at the end of the function
> > but they're not being captured like they are when run outside of the
> > function. Note the 0 output from print(ind) and V7 has "No warnings".
> > I know a lot of things "behave" differently inside functions. Case in
> > point, the use of "as.formula(var)" rather than just "~grp" being passed
> to
> > the function.
> >
> > I've failed to find a solution after much searching of various R related
> > forums. I even posted this to stackoverflow but with no response. So, if
> > anyone can help, I'd be appreciative.
> >
> > (sidenote: I used rgamma to create my sampling weights because that's
> what
> > most resembles the distribution of my weights and it's close enough to
> > reproduce the convergence issue. If I used rnorm or even rlnorm or
> rweibull
> > I couldn't reproduce it. Just FYI.)
> >
> > Best,
> >
> > Jen
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From plessthanpointohfive at gmail.com  Wed Mar  7 00:12:21 2018
From: plessthanpointohfive at gmail.com (Jen)
Date: Tue, 06 Mar 2018 23:12:21 +0000
Subject: [R] Capturing warning within user-defined function
In-Reply-To: <CAF8bMcbH0PRRKH-ZaVSsduTsHd75QhfAXzaL7s0AcxXG+tZguw@mail.gmail.com>
References: <deb72d0b3c85414fbed631e190f1943c@cdc.gov>
 <CAOxgQ=WdknChePBfNpMQskMh3sn-KXQ_1-mmoeYb2+2ggBqQCA@mail.gmail.com>
 <CAGxFJbQgyp6A95rGTSfWjZiGVhg0kXbDfTtwzoVA1SJk6ig9hg@mail.gmail.com>
 <CAF8bMcbH0PRRKH-ZaVSsduTsHd75QhfAXzaL7s0AcxXG+tZguw@mail.gmail.com>
Message-ID: <CAOxgQ=Xvg-f+FhjYDdbc-B=ykRBnuXWQ_tNZ77OskO9RXCsnrg@mail.gmail.com>

I did explore tryCatch but wasn't successful.

However, I did just try your solution, William, and it worked!

I just had to modify this line in my function:

p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])

to

p <- withWarnings((svyciprop(~grp, grp1, family=quasibinomial))[1])

Then I could use p[1] to get my estimated proportion.

Then I used:

ind <- length(attr(p, "warnings"))
print(ind)

if (ind > 0) {msg <- names(warnings()) }
else { msg <- "No warnings" }

overall[1,5] <- msg

to complete my table.

Thanks, again, William!

Jen





On Tue, Mar 6, 2018, 5:57 PM William Dunlap <wdunlap at tibco.com> wrote:

> tryCatch() is good for catching errors but not so good for warnings, as
> it does not let you resume evaluating the expression that emitted
> the warning.  withCallingHandlers(), with its companion invokeRestart(),
> lets you collect the warnings while letting the evaluation run to
> completion.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Mar 6, 2018 at 2:45 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>
>> 1. I did not attempt to sort through your voluminous code. But I suspect
>> you are trying to reinvent wheels.
>>
>> 2. I don't understand this:
>>
>> "I've failed to find a solution after much searching of various R related
>> forums."
>>
>> A web search on "error handling in R" **immediately** brought up
>> ?tryCatch,
>> which I think is what you want.
>> If not, you should probably explain why it isn't, so that someone with
>> more
>> patience than I can muster will sort through your code to help.
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Tue, Mar 6, 2018 at 2:26 PM, Jen <plessthanpointohfive at gmail.com>
>> wrote:
>>
>> > Hi, I am trying to automate the creation of tables for some simply
>> > analyses. There are lots and lots of tables, thus the creation of a
>> > user-defined function to make and output them to excel.
>> >
>> > My problem is that some of the analyses have convergence issues, which I
>> > want captured and included in the output so the folks looking at them
>> know
>> > how to view those estimates.
>> >
>> > I am successfully able to do this in a straightforward set of steps.
>> > However, once I place those steps inside a function it fails.
>> >
>> > Here's the code (sorry this is a long post):
>> >
>> > # create data
>> > wt <- rgamma(6065, 0.7057511981,  0.0005502062)
>> > grp <- sample(c(replicate(315, "Group1"), replicate(3672, "Group2"),
>> > replicate(1080, "Group3"), replicate(998, "Group4")))
>> > dta <- data.frame(grp, wt)
>> > head(dta)
>> > str(dta)
>> >
>> > # declare design
>> > my.svy <- svydesign(ids=~1, weights=~wt, data=dta)
>> >
>> > # subset
>> > grp1 <- subset(my.svy, grp == "Group1")
>> >
>> > # set options and clear old warnings
>> > options(warn=0)
>> > assign("last.warning", NULL, envir = baseenv())
>> >
>> > ## proportions and CIs
>> > p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
>> >
>> > # save warnings
>> > wrn1 <- warnings(p)
>> >
>> > ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[1])
>> > ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial), 'ci')[2])
>> >
>> > ## sample counts
>> > n <- unwtd.count(~grp, grp1)[1]
>> >
>> > ## combine into table
>> > overall <- data.frame(n, p, ci_l, ci_u)
>> > colnames(overall) <- c("counts", "Group1", "LL", "UL")
>> >
>> > ## add any warnings
>> > ind <- length(wrn1)
>> > ind
>> >
>> > if (ind == 0) { msg <- "No warnings" }
>> > if (ind > 0) {msg <- names(warnings()) }
>> > overall[1,5] <- msg
>> >
>> > print(overall)
>> >
>> > Here's the output from the above:
>> >
>> > > # set options and clear old warnings
>> > > options(warn=0)
>> > > assign("last.warning", NULL, envir = baseenv())
>> > >
>> > > ## proportions and CIs
>> > > p <- ((svyciprop(~grp, grp1, family=quasibinomial))[1])
>> > Warning message:
>> > glm.fit: algorithm did not converge
>> > >
>> > > # save warnings
>> > > wrn1 <- warnings(p)
>> > >
>> > > ci_l <- (confint(svyciprop(~grp, grp1, family=quasibinomial),
>> 'ci')[1])
>> > Warning message:
>> > glm.fit: algorithm did not converge
>> > > ci_u <- (confint(svyciprop(~grp, grp1, family=quasibinomial),
>> 'ci')[2])
>> > Warning message:
>> > glm.fit: algorithm did not converge
>> > >
>> > > ## sample counts
>> > > n <- unwtd.count(~grp, grp1)[1]
>> > >
>> > > ## combine into table
>> > > overall <- data.frame(n, p, ci_l, ci_u)
>> > > colnames(overall) <- c("counts", "Group1", "LL", "UL")
>> > >
>> > > ## add any warnings
>> > > ind <- length(wrn1)
>> > > ind
>> > [1] 1
>> > >
>> > > if (ind == 0) { msg <- "No warnings" }
>> > > if (ind > 0) {msg <- names(warnings()) }
>> > > overall[1,5] <- msg
>> > >
>> > > print(overall)
>> >        counts       Group1           LL           UL
>> >           V5
>> > counts    315 2.364636e-12 2.002372e-12 2.792441e-12 glm.fit: algorithm
>> did
>> > not converge
>> >
>> > Here's the function:
>> >
>> > est <- function(var) {
>> >
>> > ## set up formula
>> > formula <- paste ("~", var)
>> >
>> > ## set options and clear old warning
>> > options(warn=0)
>> > assign("last.warning", NULL, envir = baseenv())
>> >
>> > ## proportions and CIs
>> > p <- ((svyciprop(as.formula(formula), grp1, family=quasibinomial))[1])
>> >
>> > ## save warnings
>> > wrn1 <- warnings(p)
>> >
>> > ci_l <- (confint(svyciprop(as.formula(formula) , grp1,
>> > family=quasibinomial), 'ci')[1])
>> > ci_u <- (confint(svyciprop(as.formula(formula) , grp1,
>> > family=quasibinomial), 'ci')[2])
>> >
>> > ## sample counts
>> > n <- unwtd.count(as.formula(formula), grp1)[1]
>> >
>> > ## combine into table
>> > overall <- data.frame(n, p, ci_l, ci_u)
>> > colnames(overall) <- c("counts", "Group1", "LL", "UL")
>> >
>> >
>> > ## add any warnings
>> > ind <- length(warnings(p))
>> > print(ind)
>> >
>> > if (ind == 0) { msg <- "No warnings" }
>> > if (ind > 0) {msg <- names(warnings()) }
>> > overall[1,5] <- msg
>> >
>> > print(overall)
>> >
>> > }
>> >
>> > Here's the output from running the function:
>> >
>> > > est("grp")
>> > [1] 0
>> >        counts       Group1           LL           UL          V5
>> > counts    315 2.364636e-12 2.002372e-12 2.792441e-12 No warnings
>> > Warning messages:
>> > 1: glm.fit: algorithm did not converge
>> > 2: glm.fit: algorithm did not converge
>> > 3: glm.fit: algorithm did not converge
>> >
>> > So, the warnings are showing up in the output at the end of the function
>> > but they're not being captured like they are when run outside of the
>> > function. Note the 0 output from print(ind) and V7 has "No warnings".
>> > I know a lot of things "behave" differently inside functions. Case in
>> > point, the use of "as.formula(var)" rather than just "~grp" being
>> passed to
>> > the function.
>> >
>> > I've failed to find a solution after much searching of various R related
>> > forums. I even posted this to stackoverflow but with no response. So, if
>> > anyone can help, I'd be appreciative.
>> >
>> > (sidenote: I used rgamma to create my sampling weights because that's
>> what
>> > most resembles the distribution of my weights and it's close enough to
>> > reproduce the convergence issue. If I used rnorm or even rlnorm or
>> rweibull
>> > I couldn't reproduce it. Just FYI.)
>> >
>> > Best,
>> >
>> > Jen
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> > posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From bigfloppydog at gmail.com  Wed Mar  7 03:09:28 2018
From: bigfloppydog at gmail.com (Big Floppy Dog)
Date: Tue, 6 Mar 2018 20:09:28 -0600
Subject: [R] ggplot2: plot gruped/nested split violins
Message-ID: <CAJ_H8e-W1aXL8gcPft5n3_j1uJ90L5nGdTPk4AWFLhjospk-jg@mail.gmail.com>

Hi,

I posted this on StackOverflow also but did not get a response so I thought
that I would also try luck here. The post is at:

https://stackoverflow.com/questions/49120060/ggplot2-display-blocks-of-nested-split-violins

Basically, I have the following test example:

--cut-and-paste-from-here-on

df <- data.frame(dens = rnorm(5000),
             split = as.factor(sample(1:2, 5000, replace = T)),
             method = as.factor(sample(c("A","B"), 5000, replace = T))
             counts = sample(c(1, 10, 100, 1000, 10000), 5000, replace = T))

-stop-cut-and-paste-here


What i am wanting to do is to do split violin plots for splits 1 and 2
within groups A and B for each count (which would be in the logscale, but
that is not important for this example). We have four groups for each
setting but there is a nested aspect to it.

Here is what I have tried:


-start-cut-and-paste-again---

GeomSplitViolin <- ggproto("GeomSplitViolin", GeomViolin,

  draw_group = function(self, data, ..., draw_quantiles = NULL){
    # By @YAK: https://stackoverflow.com/questions/35717353/split-violin-plot-with-ggplot2
    data <- transform(data, xminv = x - violinwidth * (x - xmin),
xmaxv = x + violinwidth * (xmax - x))
    grp <- data[1,'group']
    newdata <- plyr::arrange(transform(data, x = if(grp%%2==1) xminv
else xmaxv), if(grp%%2==1) y else -y)
    newdata <- rbind(newdata[1, ], newdata, newdata[nrow(newdata), ],
newdata[1, ])
    newdata[c(1,nrow(newdata)-1,nrow(newdata)), 'x'] <- round(newdata[1, 'x'])
    if (length(draw_quantiles) > 0 & !scales::zero_range(range(data$y))) {
      stopifnot(all(draw_quantiles >= 0), all(draw_quantiles <= 1))
      quantiles <- create_quantile_segment_frame(data, draw_quantiles,
split = TRUE, grp = grp)
      aesthetics <- data[rep(1, nrow(quantiles)), setdiff(names(data),
c("x", "y")), drop = FALSE]
      aesthetics$alpha <- rep(1, nrow(quantiles))
      both <- cbind(quantiles, aesthetics)
      quantile_grob <- GeomPath$draw_panel(both, ...)
      ggplot2:::ggname("geom_split_violin",
grid::grobTree(GeomPolygon$draw_panel(newdata, ...), quantile_grob))
    }
    else {
      ggplot2:::ggname("geom_split_violin",
GeomPolygon$draw_panel(newdata, ...))
    }
  })

create_quantile_segment_frame <- function (data, draw_quantiles, split
= FALSE, grp = NULL) {
  dens <- cumsum(data$density)/sum(data$density)
  ecdf <- stats::approxfun(dens, data$y)
  ys <- ecdf(draw_quantiles)
  violin.xminvs <- (stats::approxfun(data$y, data$xminv))(ys)
  violin.xmaxvs <- (stats::approxfun(data$y, data$xmaxv))(ys)
  violin.xs <- (stats::approxfun(data$y, data$x))(ys)
  if (grp %% 2 == 0) {
    data.frame(x = ggplot2:::interleave(violin.xs, violin.xmaxvs),
               y = rep(ys, each = 2), group = rep(ys, each = 2))
  } else {
    data.frame(x = ggplot2:::interleave(violin.xminvs, violin.xs),
               y = rep(ys, each = 2), group = rep(ys, each = 2))
  }}



geom_split_violin <- function (mapping = NULL, data = NULL, stat =
"ydensity", position = "identity", ..., draw_quantiles = NULL, trim =
TRUE, scale = "area", na.rm = FALSE, show.legend = NA, inherit.aes =
TRUE) {
  layer(data = data, mapping = mapping, stat = stat, geom =
GeomSplitViolin, position = position, show.legend = show.legend,
inherit.aes = inherit.aes, params = list(trim = trim, scale = scale,
draw_quantiles = draw_quantiles, na.rm = na.rm, ...))}


ggplot(df, aes(x = factor(counts), y = dens, fill =
interaction(split,method))) +
           geom_split_violin(draw_quantiles = c(0.25, 0.5, 0.75)) +
scale_fill_manual(values=RColorBrewer::brewer.pal(name="Paired",n=4))
+ theme_light() + theme(legend.position="bottom")


--stop-cut-and-paste-again---

Now, I  almost get what i want but for the fact that the two split violins
for a "Count" end up on top of the other. What I want is them to be next to
each other and separated from the values for the other "Counts".

In other words, what I want is really the light blue and the dark blue to
be the two halves of a split violin plot and the light green and the dark
green to be the two halves of another split violin plot and these plots
should be bunched together.

Let me know if something is not clear, sorry for that.

As I mentioned, I also posted on SO, and I will keep both fora updated if I
get a good answer in either (unless someone else also posts there
directly).

TIA for any suggestions!

BFD

	[[alternative HTML version deleted]]


From freddy-barron at hotmail.com  Wed Mar  7 05:15:03 2018
From: freddy-barron at hotmail.com (carlos alfredo barron gallardo)
Date: Wed, 7 Mar 2018 04:15:03 +0000
Subject: [R] Problems update version
Message-ID: <CO2PR0601MB807A4A1ED2538D55D73491DE8D80@CO2PR0601MB807.namprd06.prod.outlook.com>

Hello.
I'm trying to install bioconductor software on my ubuntu linux computer system. I've installed already the latest R version but when trying to install any semiconductor package, I can't. After write the command on R, it says that I have to upload my R to the new version but I have already the latest version. Could someone help me?

Sent from my Huawei Mobile

From bendix.carstensen at regionh.dk  Wed Mar  7 06:20:02 2018
From: bendix.carstensen at regionh.dk (Bendix Carstensen)
Date: Wed, 7 Mar 2018 05:20:02 +0000
Subject: [R] Names of variables needed in newdata for predict.glm
Message-ID: <1520400001495.13693@regionh.dk>

I would like to extract the names, modes [numeric/factor] and levels
of variables needed in a data frame supplied as newdata= argument to
predict.glm()

Here is a small example illustrating my troubles; what I want from
(both of) the glm objects is the vector c("x","f","Y") and an
indication that f is a factor:

library( splines )
dd <- data.frame( D = sample(0:1,200,rep=T),
                  x = abs(rnorm(200)),
                  f = factor(sample(letters[1:4],200,rep=T)),
                  Y = runif(200,0.5,10) )
mx <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) , offset=log(Y) , family=poisson, data=dd)
mi <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) + offset(log(Y)), family=poisson, data=dd)

attr(mx$terms,"dataClasses")
attr(mi$terms,"dataClasses")
mi$xlevels
mx$xlevels

...so far not quite there.

Regards,

Bendix Carstensen

Senior Statistician
Steno Diabetes Center
Clinical Epidemiology
Niels Steensens Vej 2-4
DK-2820 Gentofte, Denmark
b at bxc.dk
bendix.carstensen at regionh.dk
http://BendixCarstensen.com

________________________________


Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.


From jdnewmil at dcn.davis.ca.us  Wed Mar  7 09:31:02 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 07 Mar 2018 00:31:02 -0800
Subject: [R] Problems update version
In-Reply-To: <CO2PR0601MB807A4A1ED2538D55D73491DE8D80@CO2PR0601MB807.namprd06.prod.outlook.com>
References: <CO2PR0601MB807A4A1ED2538D55D73491DE8D80@CO2PR0601MB807.namprd06.prod.outlook.com>
Message-ID: <5B736556-A781-4260-8666-A04D81FB2FD6@dcn.davis.ca.us>

Ubuntu standard distro is normally quite old. Read and perform the steps described at https://cran.r-project.org/bin/linux/ubuntu/
-- 
Sent from my phone. Please excuse my brevity.

On March 6, 2018 8:15:03 PM PST, carlos alfredo barron gallardo <freddy-barron at hotmail.com> wrote:
>Hello.
>I'm trying to install bioconductor software on my ubuntu linux computer
>system. I've installed already the latest R version but when trying to
>install any semiconductor package, I can't. After write the command on
>R, it says that I have to upload my R to the new version but I have
>already the latest version. Could someone help me?
>
>Sent from my Huawei Mobile
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From marc_grt at yahoo.fr  Thu Mar  8 06:26:46 2018
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Thu, 8 Mar 2018 06:26:46 +0100
Subject: [R] Names of variables needed in newdata for predict.glm
In-Reply-To: <1520400001495.13693@regionh.dk>
References: <1520400001495.13693@regionh.dk>
Message-ID: <a70c15d9-651b-4f8d-dbbb-46b790cdb2a1@yahoo.fr>

Hi,

Some try:
 > names(mi$xlevels)
[1] "f"
 > all.vars(mi$formula)
[1] "D" "x" "f" "Y"
 > names(mx$xlevels)
[1] "f"
 > all.vars(mx$formula)
[1] "D" "x" "f"

When offset is indicated out of the formula, it does not work...

Marc

Le 07/03/2018 ? 06:20, Bendix Carstensen a ?crit?:
> I would like to extract the names, modes [numeric/factor] and levels
> of variables needed in a data frame supplied as newdata= argument to
> predict.glm()
>
> Here is a small example illustrating my troubles; what I want from
> (both of) the glm objects is the vector c("x","f","Y") and an
> indication that f is a factor:
>
> library( splines )
> dd <- data.frame( D = sample(0:1,200,rep=T),
>                    x = abs(rnorm(200)),
>                    f = factor(sample(letters[1:4],200,rep=T)),
>                    Y = runif(200,0.5,10) )
> mx <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) , offset=log(Y) , family=poisson, data=dd)
> mi <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) + offset(log(Y)), family=poisson, data=dd)
>
> attr(mx$terms,"dataClasses")
> attr(mi$terms,"dataClasses")
> mi$xlevels
> mx$xlevels
>
> ...so far not quite there.
>
> Regards,
>
> Bendix Carstensen
>
> Senior Statistician
> Steno Diabetes Center
> Clinical Epidemiology
> Niels Steensens Vej 2-4
> DK-2820 Gentofte, Denmark
> b at bxc.dk
> bendix.carstensen at regionh.dk
> http://BendixCarstensen.com
>
> ________________________________
>
>
> Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ashimkapoor at gmail.com  Thu Mar  8 07:46:41 2018
From: ashimkapoor at gmail.com (Ashim Kapoor)
Date: Thu, 8 Mar 2018 12:16:41 +0530
Subject: [R] grepAMModelLib in package AMML not working as expected
Message-ID: <CAC8=1eq_SM9Tu+8gFtNNAcpp=t9jD_i3e8wSmDChji6yNGkv4A@mail.gmail.com>

Dear All,

Here is a minimal working example :

library(AMModels)

mymodels <- amModelLib(description = "Simple AM Model library")

dataset1 <- 1:100
dataset2 <- seq(2,200,2)

model1 <- lm(dataset2~1)
model2 <- lm(dataset2~ dataset1)

m1 <- amModel(model = model1,comment  = "Initial model.")
m2 <- amModel(model = model2,comment  = "Final model.")

mymodels <- insertAMModelLib(model = list(m1=m1,m2=m2),amml = mymodels)


> grepAMModelLib(pattern= "m1",amml = mymodels,search = "model")

Description:
[1] Simple AM Model library

Info:
** no informative metadata **


Models:
  name class package
1   m1    lm      NA

Data:

 --- There are no datasets ---


Here I am searching for all models which have the letter "1".

> grepAMModelLib(pattern= "1",amml = mymodels,search = "model")

Description:
[1] Simple AM Model library

Info:
** no informative metadata **


Models:
  name class package
1   m1    lm      NA
2   m2    lm      NA

Data:

 --- There are no datasets ---
>

The above should return only model m1. Why does the result of grepping
return both m1 and m2 ? Where do I misunderstand ?

Best Regards,
Ashim

	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Thu Mar  8 08:07:38 2018
From: chocold12 at gmail.com (lily li)
Date: Thu, 8 Mar 2018 00:07:38 -0700
Subject: [R] add single points to a level plot
Message-ID: <CAN5afy-J0AOQVJ3FxVG735ZAqAFYy5K4pWABQ4BA-A+R8YkLwQ@mail.gmail.com>

Hi all,

I'm trying to add single points with known coordinates to a level plot, but
could not find the proper answer. I got to know that layer() function is
good for this, but I don't know which package is related to this function.
The source is here:
https://stackoverflow.com/questions/28597149/add-xy-points-to-raster-map-generated-by-levelplot

but my question is a little different as I know the coordinates of the
single point, rather than a range. Thanks for any help you could provide.

	[[alternative HTML version deleted]]


From marc_schwartz at me.com  Thu Mar  8 16:04:48 2018
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 08 Mar 2018 10:04:48 -0500
Subject: [R] Names of variables needed in newdata for predict.glm
In-Reply-To: <a70c15d9-651b-4f8d-dbbb-46b790cdb2a1@yahoo.fr>
References: <1520400001495.13693@regionh.dk>
 <a70c15d9-651b-4f8d-dbbb-46b790cdb2a1@yahoo.fr>
Message-ID: <AFA4E9BD-AC9E-46C0-898E-F82FECDE6B80@me.com>

Hi Bendix,

If the 'model' argument to glm() is TRUE (the default), you can get the structure of the model frame that was used to fit the model, by using:

> str(mx$data)
'data.frame':	200 obs. of  4 variables:
 $ D: int  0 1 0 1 1 0 1 1 1 1 ...
 $ x: num  0.705 2.15 0.572 1.249 0.807 ...
 $ f: Factor w/ 4 levels "a","b","c","d": 1 4 1 4 4 1 4 2 4 4 ...
 $ Y: num  0.787 8.267 3.085 5.738 9.593 ...


> str(mi$data)
'data.frame':	200 obs. of  4 variables:
 $ D: int  0 1 0 1 1 0 1 1 1 1 ...
 $ x: num  0.705 2.15 0.572 1.249 0.807 ...
 $ f: Factor w/ 4 levels "a","b","c","d": 1 4 1 4 4 1 4 2 4 4 ...
 $ Y: num  0.787 8.267 3.085 5.738 9.593 ...


The first column in the data frame will be the response variable.

In both cases, the offset variable 'Y' is included, whether the offset was part of the formula or specified as a separate argument.

You can then process the results as you need from there, such as:

> sapply(mx$data, class)
        D         x         f         Y 
"integer" "numeric"  "factor" "numeric" 


Regards,

Marc Schwartz




> On Mar 8, 2018, at 12:26 AM, Marc Girondot via R-help <r-help at r-project.org> wrote:
> 
> Hi,
> 
> Some try:
> > names(mi$xlevels)
> [1] "f"
> > all.vars(mi$formula)
> [1] "D" "x" "f" "Y"
> > names(mx$xlevels)
> [1] "f"
> > all.vars(mx$formula)
> [1] "D" "x" "f"
> 
> When offset is indicated out of the formula, it does not work...
> 
> Marc
> 
> Le 07/03/2018 ? 06:20, Bendix Carstensen a ?crit :
>> I would like to extract the names, modes [numeric/factor] and levels
>> of variables needed in a data frame supplied as newdata= argument to
>> predict.glm()
>> 
>> Here is a small example illustrating my troubles; what I want from
>> (both of) the glm objects is the vector c("x","f","Y") and an
>> indication that f is a factor:
>> 
>> library( splines )
>> dd <- data.frame( D = sample(0:1,200,rep=T),
>>                   x = abs(rnorm(200)),
>>                   f = factor(sample(letters[1:4],200,rep=T)),
>>                   Y = runif(200,0.5,10) )
>> mx <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) , offset=log(Y) , family=poisson, data=dd)
>> mi <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) + offset(log(Y)), family=poisson, data=dd)
>> 
>> attr(mx$terms,"dataClasses")
>> attr(mi$terms,"dataClasses")
>> mi$xlevels
>> mx$xlevels
>> 
>> ...so far not quite there.
>> 
>> Regards,
>> 
>> Bendix Carstensen
>> 
>> Senior Statistician
>> Steno Diabetes Center
>> Clinical Epidemiology
>> Niels Steensens Vej 2-4
>> DK-2820 Gentofte, Denmark
>> b at bxc.dk
>> bendix.carstensen at regionh.dk
>> http://BendixCarstensen.com


	[[alternative HTML version deleted]]


From chocold12 at gmail.com  Thu Mar  8 16:11:34 2018
From: chocold12 at gmail.com (lily li)
Date: Thu, 8 Mar 2018 08:11:34 -0700
Subject: [R] add single points to a level plot
In-Reply-To: <CAN5afy-J0AOQVJ3FxVG735ZAqAFYy5K4pWABQ4BA-A+R8YkLwQ@mail.gmail.com>
References: <CAN5afy-J0AOQVJ3FxVG735ZAqAFYy5K4pWABQ4BA-A+R8YkLwQ@mail.gmail.com>
Message-ID: <CAN5afy8DMW0+AwrL2wPvELyw0nyfMUjF44x_rJ-5rWY7p5_DKg@mail.gmail.com>

Hi all,

I ran the code:
> s <- stack(replicate(2, raster(matrix(runif(100), 10))))
> xy <- data.frame(coordinates(sampleRandom(s, 10, sp=TRUE)),
+                  z1=runif(10), z2=runif(10))
> levelplot(s, margin=FALSE, at=seq(0, 1, 0.05)) +
+   layer(sp.points(xy, pch=ifelse(pts$z1 < 0.5, 2, 3), cex=2, col=1),
columns=1) +
+   layer(sp.points(xy, pch=ifelse(pts$z2 < 0.5, 2, 3), cex=2, col=1),
columns=2)

And got the error:
Error in UseMethod("levelplot") :
  no applicable method for 'levelplot' applied to an object of class
"c('RasterStack', 'Raster', 'RasterStackBrick', 'BasicRaster')"

what is the problem? Thanks.

On Thu, Mar 8, 2018 at 12:07 AM, lily li <chocold12 at gmail.com> wrote:

> Hi all,
>
> I'm trying to add single points with known coordinates to a level plot,
> but could not find the proper answer. I got to know that layer() function
> is good for this, but I don't know which package is related to this
> function. The source is here:
> https://stackoverflow.com/questions/28597149/add-xy-points-to-raster-map-
> generated-by-levelplot
>
> but my question is a little different as I know the coordinates of the
> single point, rather than a range. Thanks for any help you could provide.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Thu Mar  8 16:48:02 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 8 Mar 2018 17:48:02 +0200
Subject: [R] add single points to a level plot
In-Reply-To: <CAN5afy8DMW0+AwrL2wPvELyw0nyfMUjF44x_rJ-5rWY7p5_DKg@mail.gmail.com>
References: <CAN5afy-J0AOQVJ3FxVG735ZAqAFYy5K4pWABQ4BA-A+R8YkLwQ@mail.gmail.com>
 <CAN5afy8DMW0+AwrL2wPvELyw0nyfMUjF44x_rJ-5rWY7p5_DKg@mail.gmail.com>
Message-ID: <CAGgJW764Yc_CcEk8J3FX3ij+QUevrcrQ_sw-nNgXWALZ5pGVxA@mail.gmail.com>

You need to load the package 'rasterVis'

> library(rasterVis)

HTH,
Eric


On Thu, Mar 8, 2018 at 5:11 PM, lily li <chocold12 at gmail.com> wrote:

> Hi all,
>
> I ran the code:
> > s <- stack(replicate(2, raster(matrix(runif(100), 10))))
> > xy <- data.frame(coordinates(sampleRandom(s, 10, sp=TRUE)),
> +                  z1=runif(10), z2=runif(10))
> > levelplot(s, margin=FALSE, at=seq(0, 1, 0.05)) +
> +   layer(sp.points(xy, pch=ifelse(pts$z1 < 0.5, 2, 3), cex=2, col=1),
> columns=1) +
> +   layer(sp.points(xy, pch=ifelse(pts$z2 < 0.5, 2, 3), cex=2, col=1),
> columns=2)
>
> And got the error:
> Error in UseMethod("levelplot") :
>   no applicable method for 'levelplot' applied to an object of class
> "c('RasterStack', 'Raster', 'RasterStackBrick', 'BasicRaster')"
>
> what is the problem? Thanks.
>
> On Thu, Mar 8, 2018 at 12:07 AM, lily li <chocold12 at gmail.com> wrote:
>
> > Hi all,
> >
> > I'm trying to add single points with known coordinates to a level plot,
> > but could not find the proper answer. I got to know that layer() function
> > is good for this, but I don't know which package is related to this
> > function. The source is here:
> > https://stackoverflow.com/questions/28597149/add-xy-
> points-to-raster-map-
> > generated-by-levelplot
> >
> > but my question is a little different as I know the coordinates of the
> > single point, rather than a range. Thanks for any help you could provide.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar  8 16:53:22 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 08 Mar 2018 07:53:22 -0800
Subject: [R] add single points to a level plot
In-Reply-To: <CAN5afy8DMW0+AwrL2wPvELyw0nyfMUjF44x_rJ-5rWY7p5_DKg@mail.gmail.com>
References: <CAN5afy-J0AOQVJ3FxVG735ZAqAFYy5K4pWABQ4BA-A+R8YkLwQ@mail.gmail.com>
 <CAN5afy8DMW0+AwrL2wPvELyw0nyfMUjF44x_rJ-5rWY7p5_DKg@mail.gmail.com>
Message-ID: <7CC27E4C-6334-470C-9DBC-53A8F6F1B3F2@dcn.davis.ca.us>

library(sos)
findFn( "layer" )
findFn( "levelplot" )

Also, experts in spatial analysis tend to answer questions on the special mailing list where the Posting Guide says they should. Read it to find out where that is. 
-- 
Sent from my phone. Please excuse my brevity.

On March 8, 2018 7:11:34 AM PST, lily li <chocold12 at gmail.com> wrote:
>Hi all,
>
>I ran the code:
>> s <- stack(replicate(2, raster(matrix(runif(100), 10))))
>> xy <- data.frame(coordinates(sampleRandom(s, 10, sp=TRUE)),
>+                  z1=runif(10), z2=runif(10))
>> levelplot(s, margin=FALSE, at=seq(0, 1, 0.05)) +
>+   layer(sp.points(xy, pch=ifelse(pts$z1 < 0.5, 2, 3), cex=2, col=1),
>columns=1) +
>+   layer(sp.points(xy, pch=ifelse(pts$z2 < 0.5, 2, 3), cex=2, col=1),
>columns=2)
>
>And got the error:
>Error in UseMethod("levelplot") :
>  no applicable method for 'levelplot' applied to an object of class
>"c('RasterStack', 'Raster', 'RasterStackBrick', 'BasicRaster')"
>
>what is the problem? Thanks.
>
>On Thu, Mar 8, 2018 at 12:07 AM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi all,
>>
>> I'm trying to add single points with known coordinates to a level
>plot,
>> but could not find the proper answer. I got to know that layer()
>function
>> is good for this, but I don't know which package is related to this
>> function. The source is here:
>>
>https://stackoverflow.com/questions/28597149/add-xy-points-to-raster-map-
>> generated-by-levelplot
>>
>> but my question is a little different as I know the coordinates of
>the
>> single point, rather than a range. Thanks for any help you could
>provide.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From chocold12 at gmail.com  Thu Mar  8 18:10:48 2018
From: chocold12 at gmail.com (lily li)
Date: Thu, 8 Mar 2018 10:10:48 -0700
Subject: [R] add single points to a level plot
In-Reply-To: <CAGgJW764Yc_CcEk8J3FX3ij+QUevrcrQ_sw-nNgXWALZ5pGVxA@mail.gmail.com>
References: <CAN5afy-J0AOQVJ3FxVG735ZAqAFYy5K4pWABQ4BA-A+R8YkLwQ@mail.gmail.com>
 <CAN5afy8DMW0+AwrL2wPvELyw0nyfMUjF44x_rJ-5rWY7p5_DKg@mail.gmail.com>
 <CAGgJW764Yc_CcEk8J3FX3ij+QUevrcrQ_sw-nNgXWALZ5pGVxA@mail.gmail.com>
Message-ID: <CAN5afy-xHmv5om9C2L5T_pzhcxq6d=m6ena=FUqpcRb6rAoLcw@mail.gmail.com>

Thanks.
Now it can run and generate plots, but there are the two lines on each of
the plots. I don't know the problem for this?

Error using packet 1
any(sp) is not TRUE



On Thu, Mar 8, 2018 at 8:48 AM, Eric Berger <ericjberger at gmail.com> wrote:

> You need to load the package 'rasterVis'
>
> > library(rasterVis)
>
> HTH,
> Eric
>
>
> On Thu, Mar 8, 2018 at 5:11 PM, lily li <chocold12 at gmail.com> wrote:
>
>> Hi all,
>>
>> I ran the code:
>> > s <- stack(replicate(2, raster(matrix(runif(100), 10))))
>> > xy <- data.frame(coordinates(sampleRandom(s, 10, sp=TRUE)),
>> +                  z1=runif(10), z2=runif(10))
>> > levelplot(s, margin=FALSE, at=seq(0, 1, 0.05)) +
>> +   layer(sp.points(xy, pch=ifelse(pts$z1 < 0.5, 2, 3), cex=2, col=1),
>> columns=1) +
>> +   layer(sp.points(xy, pch=ifelse(pts$z2 < 0.5, 2, 3), cex=2, col=1),
>> columns=2)
>>
>> And got the error:
>> Error in UseMethod("levelplot") :
>>   no applicable method for 'levelplot' applied to an object of class
>> "c('RasterStack', 'Raster', 'RasterStackBrick', 'BasicRaster')"
>>
>> what is the problem? Thanks.
>>
>> On Thu, Mar 8, 2018 at 12:07 AM, lily li <chocold12 at gmail.com> wrote:
>>
>> > Hi all,
>> >
>> > I'm trying to add single points with known coordinates to a level plot,
>> > but could not find the proper answer. I got to know that layer()
>> function
>> > is good for this, but I don't know which package is related to this
>> > function. The source is here:
>> > https://stackoverflow.com/questions/28597149/add-xy-points-
>> to-raster-map-
>> > generated-by-levelplot
>> >
>> > but my question is a little different as I know the coordinates of the
>> > single point, rather than a range. Thanks for any help you could
>> provide.
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From shynosusanjohn1994 at gmail.com  Fri Mar  9 10:25:10 2018
From: shynosusanjohn1994 at gmail.com (shyno susan john)
Date: Fri, 9 Mar 2018 14:55:10 +0530
Subject: [R] For Extracting gridded netcdf data into output files where each
 file representing the individual grid
Message-ID: <CAOCASCHefyJxUQ1FxSZmv5tSHePNH0A9G+-0-g6DN-pcoMUtjw@mail.gmail.com>

Hi,

I have to calculate Extemes, for that I wrote a script for extracting IMD
Tmax data for one year. I need to get output files where each file
representing the individual grid with daily values.Since, my data is of
0.5*0.5 resolution, I need to get 3721(61*61=3721) output files. But, I am
only getting 3482 output files.

I think the problem is with naming the output files using paste command,

The loop part I had done is as follows:

 for (i in 1:length(ny)){

  for (j in 1:length(nx)){

        for (l in 1:365){


write.csv(list(t_array[i,j,]),paste(i,j,".csv",sep=""),row.names=T)
      }}}

I am looking forward for your suggestions......

	[[alternative HTML version deleted]]


From ntuzov at beacon.partek.com  Fri Mar  9 16:50:44 2018
From: ntuzov at beacon.partek.com (Nik Tuzov)
Date: Fri, 9 Mar 2018 09:50:44 -0600 (CST)
Subject: [R] Package gamlss used inside foreach() and %dopar% fails to find
 an object
In-Reply-To: <1291945444.888856.1520609737831.JavaMail.zimbra@beacon.partek.com>
References: <1291945444.888856.1520609737831.JavaMail.zimbra@beacon.partek.com>
Message-ID: <130419626.889065.1520610644644.JavaMail.zimbra@beacon.partek.com>


Hello all:

Please help me with this "can't find object" issue. I'm trying to get leave-one-out predicted values for Beta-binomial regression.  
It may be the gamlss issue because the code seems to work when %do% is used. I have searched for similar issues, but haven't managed to figure it out. This is on Windows 10 platform.

Thanks in advance,
Nik

# --------------------------------------------------------------

library('gamlss')
library('foreach')
library('doParallel')

registerDoParallel(cores = 4)
# Generate data
set.seed(314)
sample.size <- 30
input.processed.cut <- data.frame(TP = round(runif(sample.size) * 100), 
                                  FP = round(runif(sample.size) * 100), 
                                  x = runif(sample.size))
# Fit Beta-binomial
model3 <- gamlss(formula = cbind(TP, FP) ~ x,   
                 family = BB,  
                 data = input.processed.cut) 

# Get the leave-one-out values
loo_predict.mu <- function(model.obj, input.data) {
  yhat <- foreach(i = 1 : nrow(input.data), .packages="gamlss", .combine = rbind) %dopar% {
    updated.model.obj <- update(model.obj, data = input.data[-i, ])
    predict(updated.model.obj, what = "mu", newdata = input.data[i,], type = "response")
  }
  return(data.frame(result = yhat[, 1], row.names = NULL))
}

par.run <- loo_predict.mu(model3, input.processed.cut)

# Error in { : task 1 failed - "object 'input.data' not found" 

# ------------------------------------------------------------------------

> version
               _                           
platform       x86_64-w64-mingw32          
arch           x86_64                      
os             mingw32                     
system         x86_64, mingw32             
status                                     
major          3                           
minor          4.3                         
year           2017                        
month          11                          
day            30                          
svn rev        73796                       
language       R                           
version.string R version 3.4.3 (2017-11-30)
nickname       Kite-Eating Tree


From jdnewmil at dcn.davis.ca.us  Fri Mar  9 18:16:21 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 09 Mar 2018 09:16:21 -0800
Subject: [R] 
 Package gamlss used inside foreach() and %dopar% fails to find
 an object
In-Reply-To: <130419626.889065.1520610644644.JavaMail.zimbra@beacon.partek.com>
References: <1291945444.888856.1520609737831.JavaMail.zimbra@beacon.partek.com>
 <130419626.889065.1520610644644.JavaMail.zimbra@beacon.partek.com>
Message-ID: <CCB86E33-8850-41F3-ABEA-5C4841D995FB@dcn.davis.ca.us>

If the code you are running in parallel is complicated, maybe foreach is not sophisticated enough to find all the variables you refer to. Maybe use parallel::clusterExport yourself? But be a aware that passing parameters is much safer than directly accessing globals in parallel processing, so this might just be your warning to not do that anyway. 
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2018 7:50:44 AM PST, Nik Tuzov <ntuzov at beacon.partek.com> wrote:
>
>Hello all:
>
>Please help me with this "can't find object" issue. I'm trying to get
>leave-one-out predicted values for Beta-binomial regression.  
>It may be the gamlss issue because the code seems to work when %do% is
>used. I have searched for similar issues, but haven't managed to figure
>it out. This is on Windows 10 platform.
>
>Thanks in advance,
>Nik
>
># --------------------------------------------------------------
>
>library('gamlss')
>library('foreach')
>library('doParallel')
>
>registerDoParallel(cores = 4)
># Generate data
>set.seed(314)
>sample.size <- 30
>input.processed.cut <- data.frame(TP = round(runif(sample.size) * 100),
>
>                                 FP = round(runif(sample.size) * 100), 
>                                  x = runif(sample.size))
># Fit Beta-binomial
>model3 <- gamlss(formula = cbind(TP, FP) ~ x,   
>                 family = BB,  
>                 data = input.processed.cut) 
>
># Get the leave-one-out values
>loo_predict.mu <- function(model.obj, input.data) {
>yhat <- foreach(i = 1 : nrow(input.data), .packages="gamlss", .combine
>= rbind) %dopar% {
>    updated.model.obj <- update(model.obj, data = input.data[-i, ])
>predict(updated.model.obj, what = "mu", newdata = input.data[i,], type
>= "response")
>  }
>  return(data.frame(result = yhat[, 1], row.names = NULL))
>}
>
>par.run <- loo_predict.mu(model3, input.processed.cut)
>
># Error in { : task 1 failed - "object 'input.data' not found" 
>
>#
>------------------------------------------------------------------------
>
>> version
>               _                           
>platform       x86_64-w64-mingw32          
>arch           x86_64                      
>os             mingw32                     
>system         x86_64, mingw32             
>status                                     
>major          3                           
>minor          4.3                         
>year           2017                        
>month          11                          
>day            30                          
>svn rev        73796                       
>language       R                           
>version.string R version 3.4.3 (2017-11-30)
>nickname       Kite-Eating Tree
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ntuzov at beacon.partek.com  Fri Mar  9 18:30:51 2018
From: ntuzov at beacon.partek.com (Nik Tuzov)
Date: Fri, 9 Mar 2018 11:30:51 -0600 (CST)
Subject: [R] 
 Package gamlss used inside foreach() and %dopar% fails to find
 an object
In-Reply-To: <CCB86E33-8850-41F3-ABEA-5C4841D995FB@dcn.davis.ca.us>
References: <1291945444.888856.1520609737831.JavaMail.zimbra@beacon.partek.com>
 <130419626.889065.1520610644644.JavaMail.zimbra@beacon.partek.com>
 <CCB86E33-8850-41F3-ABEA-5C4841D995FB@dcn.davis.ca.us>
Message-ID: <367340309.891783.1520616651575.JavaMail.zimbra@beacon.partek.com>


Hello Jeff:

Thanks for replying.
I made a mistake in my original post.
The same error is generated with %do% as well, so it seems to be gamlss-related.

Nik


----- Original Message -----
From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
To: "r-help" <r-help at r-project.org>, "Nik Tuzov" <ntuzov at beacon.partek.com>
Sent: Friday, March 9, 2018 11:16:21 AM
Subject: Re: [R] Package gamlss used inside foreach() and %dopar% fails to find an object

If the code you are running in parallel is complicated, maybe foreach is not sophisticated enough to find all the variables you refer to. Maybe use parallel::clusterExport yourself? But be a aware that passing parameters is much safer than directly accessing globals in parallel processing, so this might just be your warning to not do that anyway. 
-- 
Sent from my phone. Please excuse my brevity.

On March 9, 2018 7:50:44 AM PST, Nik Tuzov <ntuzov at beacon.partek.com> wrote:
>
>Hello all:
>
>Please help me with this "can't find object" issue. I'm trying to get
>leave-one-out predicted values for Beta-binomial regression.  
>It may be the gamlss issue because the code seems to work when %do% is
>used. I have searched for similar issues, but haven't managed to figure
>it out. This is on Windows 10 platform.
>
>Thanks in advance,
>Nik
>
># --------------------------------------------------------------
>
>library('gamlss')
>library('foreach')
>library('doParallel')
>
>registerDoParallel(cores = 4)
># Generate data
>set.seed(314)
>sample.size <- 30
>input.processed.cut <- data.frame(TP = round(runif(sample.size) * 100),
>
>                                 FP = round(runif(sample.size) * 100), 
>                                  x = runif(sample.size))
># Fit Beta-binomial
>model3 <- gamlss(formula = cbind(TP, FP) ~ x,   
>                 family = BB,  
>                 data = input.processed.cut) 
>
># Get the leave-one-out values
>loo_predict.mu <- function(model.obj, input.data) {
>yhat <- foreach(i = 1 : nrow(input.data), .packages="gamlss", .combine
>= rbind) %dopar% {
>    updated.model.obj <- update(model.obj, data = input.data[-i, ])
>predict(updated.model.obj, what = "mu", newdata = input.data[i,], type
>= "response")
>  }
>  return(data.frame(result = yhat[, 1], row.names = NULL))
>}
>
>par.run <- loo_predict.mu(model3, input.processed.cut)
>
># Error in { : task 1 failed - "object 'input.data' not found" 
>
>#
>------------------------------------------------------------------------
>
>> version
>               _                           
>platform       x86_64-w64-mingw32          
>arch           x86_64                      
>os             mingw32                     
>system         x86_64, mingw32             
>status                                     
>major          3                           
>minor          4.3                         
>year           2017                        
>month          11                          
>day            30                          
>svn rev        73796                       
>language       R                           
>version.string R version 3.4.3 (2017-11-30)
>nickname       Kite-Eating Tree
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dmh.stasinopoulos at gmail.com  Sat Mar 10 14:34:59 2018
From: dmh.stasinopoulos at gmail.com (Dimitrios Stasinopoulos)
Date: Sat, 10 Mar 2018 13:34:59 +0000
Subject: [R] . Package gamlss used inside foreach() and %dopar% fails to
 find an object (Nik Tuzov)
Message-ID: <424DC535-4CAF-4DD5-8BD5-EB19BF6F7247@staff.londonmet.ac.uk>

Dear Nik 

Try the following code 


loo_predict.mu <- function(model.obj, input.data) {
  yhat <- foreach(i = 1 : nrow(input.data), .packages="gamlss", .combine = rbind) %dopar% {
    updated.model.obj <- update(model.obj, data = input.data[-i, ])
    predict(updated.model.obj, what = "mu", data = input.data[-i, ],
            newdata = input.data[i,], type = "response")
  }
  return(data.frame(result = yhat[, 1], row.names = NULL))
}

par.run <- loo_predict.mu(model3, input.processed.cut)

The predict command in this case also need the old data.

Thanks
Mikis 



Prof Dimitrios Mikis Stasinopoulos
stasinom at staff.londonmet.ac.uk




	[[alternative HTML version deleted]]


From ycding at coh.org  Sat Mar 10 22:30:42 2018
From: ycding at coh.org (Ding, Yuan Chun)
Date: Sat, 10 Mar 2018 21:30:42 +0000
Subject: [R] error message from sqldf
Message-ID: <A86C6438FB909A409DDEF926277952B6A6D60D@PPWEXCH2KX14.coh.org>

Dear R users,

I got the following error message from running sqldf code in R.   do you know how to fix it?  I read the sqldf package instruction and did not find a solution.

Thank you,

Ding

chr10 <- sqldf("select * from manifest where CHR==10")

UCN3cpg <-  sqldf("select * from chr10 where MAPINFO between 5405573 and 5407594),
overwrite = TRUE")
Error: Table chr10 exists in database, and both overwrite and append are FALSE


>





---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely f...{{dropped:22}}


From chema at rinzewind.org  Sat Mar 10 22:53:35 2018
From: chema at rinzewind.org (=?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos)
Date: Sat, 10 Mar 2018 16:53:35 -0500
Subject: [R] error message from sqldf
In-Reply-To: <A86C6438FB909A409DDEF926277952B6A6D60D@PPWEXCH2KX14.coh.org>
References: <A86C6438FB909A409DDEF926277952B6A6D60D@PPWEXCH2KX14.coh.org>
Message-ID: <20180310215335.GD5049@equipaje>

On Sat, Mar 10, 2018 at 09:30:42PM +0000, Ding, Yuan Chun wrote:
> chr10 <- sqldf("select * from manifest where CHR==10")
> 
> UCN3cpg <-  sqldf("select * from chr10 where MAPINFO between 5405573 and 5407594),
> overwrite = TRUE")
> Error: Table chr10 exists in database, and both overwrite and append are FALSE

Could it be that `chr10` already exists when you try to run your code. 
What about rewriting it as:

chr10 <- sqldf("select * from manifest where CHR==10", overwrite = TRUE)

Also, it seems to me that the second line is not closing the quotes 
properly. Shouldn't this be correct instead?

UCN3cpg <-  sqldf("select * from chr10 where MAPINFO between 5405573 and 5407594",
                  overwrite = TRUE)

Cheers,

-- 
Jos? Mar?a (Chema) Mateos
https://rinzewind.org/blog-es || https://rinzewind.org/blog-en


From krcabrer at une.net.co  Sun Mar 11 15:12:56 2018
From: krcabrer at une.net.co (KENNETH ROY CABRERA TORRES)
Date: Sun, 11 Mar 2018 09:12:56 -0500 (COT)
Subject: [R] Your browser do not suport oracle bi presentation services
Message-ID: <253139071.20663602.1520777576611.JavaMail.zimbra@une.net.co>

Hi dear R users: 


I'm trying the following code to download an information from the web. 

url1 <- "http://obieebr.banrep.gov.co/analytics/saw.dll?Go&Path=%2fshared%2fSeries%20Estad%C3%ADsticas_T%2f1.%20Tasa%20de%20Cambio%20Peso%20Colombiano%2f1.1%20TRM%20-%20Disponible%20desde%20el%2027%20de%20noviembre%20de%201991%2f1.1.1.TCM_Serie%20hist%C3%B3rica%20o%20por%20a%C3%B1o&Options=rdf&lang=es&NQUser=publico&NQPassword=publico" 

con <- url(url1, "r") 
x <- readLines(con) 
close(con) 

I obtain the folowing message: 

"Su explorador no es soportado por Oracle BI Presentation Services." 

Your browser do not support Oracle BI Presentation Sevices. 


How can I deal with this problem? 

Thank you very much for your help. 

Kenneth 



	[[alternative HTML version deleted]]


From chema at rinzewind.org  Sun Mar 11 15:25:51 2018
From: chema at rinzewind.org (=?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos)
Date: Sun, 11 Mar 2018 10:25:51 -0400
Subject: [R] Your browser do not suport oracle bi presentation services
In-Reply-To: <253139071.20663602.1520777576611.JavaMail.zimbra@une.net.co>
References: <253139071.20663602.1520777576611.JavaMail.zimbra@une.net.co>
Message-ID: <20180311142551.GA30469@equipaje>

On Sun, Mar 11, 2018 at 09:12:56AM -0500, KENNETH ROY CABRERA TORRES wrote:
> Hi dear R users: 
> 
> I'm trying the following code to download an information from the web. 
> 
> url1 <- "http://obieebr.banrep.gov.co/analytics/saw.dll?Go&Path=%2fshared%2fSeries%20Estad%C3%ADsticas_T%2f1.%20Tasa%20de%20Cambio%20Peso%20Colombiano%2f1.1%20TRM%20-%20Disponible%20desde%20el%2027%20de%20noviembre%20de%201991%2f1.1.1.TCM_Serie%20hist%C3%B3rica%20o%20por%20a%C3%B1o&Options=rdf&lang=es&NQUser=publico&NQPassword=publico" 
> 
> con <- url(url1, "r") 
> x <- readLines(con) 
> close(con) 
> 
> I obtain the folowing message: 
> 
> "Su explorador no es soportado por Oracle BI Presentation Services." 
> 
> Your browser do not support Oracle BI Presentation Sevices. 

I tried opening that URL with my browser and it worked (or at least I 
think it worked, it took me to a page where I could see a very long 
table titled "Tasa de cambio representativa del mercado (TRM)".

I tried obtaining the page using wget and I got the error you mentioned. 
When I forge wget to identify itself as Firefox, I get returned a 
different code (one that I suppose will redirect me to the page you are 
trying to scrape).

The problem could be solved by telling R to use a different user-agent, 
like Firefox or Chrome. Check 
https://stackoverflow.com/questions/4536835/changing-user-agent-string-in-a-http-request-in-r

However, I think the system that provides the HTML content you want 
relies heavily on JavaScript. You might need to end up using something 
like Selenium (https://www.r-bloggers.com/scraping-with-selenium/).

Cheers,

-- 
Jos? Mar?a (Chema) Mateos
https://rinzewind.org/blog-es || https://rinzewind.org/blog-en


From krcabrer at une.net.co  Sun Mar 11 17:36:46 2018
From: krcabrer at une.net.co (KENNETH ROY CABRERA TORRES)
Date: Sun, 11 Mar 2018 11:36:46 -0500 (COT)
Subject: [R] Your browser do not suport oracle bi presentation services
In-Reply-To: <20180311142551.GA30469@equipaje>
References: <253139071.20663602.1520777576611.JavaMail.zimbra@une.net.co>
 <20180311142551.GA30469@equipaje>
Message-ID: <951091185.20687049.1520786206640.JavaMail.zimbra@une.net.co>

Thank you Jos? Mar?a:

You are very kind.

I will study and use your advice.

The first step, takes more information,
but not what I want. (I want the whole data set of "TRM").

I'm going to try with Selenium (RSelenium).

Thank you very much for your help.

Kenneth

----- Mensaje original -----
De: "Jos? Mar?a Mateos" <chema at rinzewind.org>
Para: "r-help at r-project.org r-help at r-project.org" <r-help at r-project.org>
Enviados: Domingo, 11 de Marzo 2018 9:25:51
Asunto: Re: [R] Your browser do not suport oracle bi presentation services

On Sun, Mar 11, 2018 at 09:12:56AM -0500, KENNETH ROY CABRERA TORRES wrote:
> Hi dear R users: 
> 
> I'm trying the following code to download an information from the web. 
> 
> url1 <- "http://obieebr.banrep.gov.co/analytics/saw.dll?Go&Path=%2fshared%2fSeries%20Estad%C3%ADsticas_T%2f1.%20Tasa%20de%20Cambio%20Peso%20Colombiano%2f1.1%20TRM%20-%20Disponible%20desde%20el%2027%20de%20noviembre%20de%201991%2f1.1.1.TCM_Serie%20hist%C3%B3rica%20o%20por%20a%C3%B1o&Options=rdf&lang=es&NQUser=publico&NQPassword=publico" 
> 
> con <- url(url1, "r") 
> x <- readLines(con) 
> close(con) 
> 
> I obtain the folowing message: 
> 
> "Su explorador no es soportado por Oracle BI Presentation Services." 
> 
> Your browser do not support Oracle BI Presentation Sevices. 

I tried opening that URL with my browser and it worked (or at least I 
think it worked, it took me to a page where I could see a very long 
table titled "Tasa de cambio representativa del mercado (TRM)".

I tried obtaining the page using wget and I got the error you mentioned. 
When I forge wget to identify itself as Firefox, I get returned a 
different code (one that I suppose will redirect me to the page you are 
trying to scrape).

The problem could be solved by telling R to use a different user-agent, 
like Firefox or Chrome. Check 
https://stackoverflow.com/questions/4536835/changing-user-agent-string-in-a-http-request-in-r

However, I think the system that provides the HTML content you want 
relies heavily on JavaScript. You might need to end up using something 
like Selenium (https://www.r-bloggers.com/scraping-with-selenium/).

Cheers,

-- 
Jos? Mar?a (Chema) Mateos
https://rinzewind.org/blog-es || https://rinzewind.org/blog-en

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Sun Mar 11 19:45:03 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 12 Mar 2018 00:15:03 +0530
Subject: [R] Empirical density estimation
Message-ID: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>

Hi,

Let say I have below vector of data-points :

Dat = c(-0.444444444444444, -0.25, -0.237449799196787, -0.227467046669042,

-0.227454464682363, -0.22, -0.214876033057851, -0.211781206171108,

-0.199891067538126, -0.192920353982301, -0.192307692307692, -0.186046511627907,

-0.184418145956608, -0.181818181818182, -0.181818181818182, -0.181266261925412,

-0.181003118503119, -0.179064587973274, -0.178217821782178, -0.17809021675454,

-0.177685950413223, -0.177570093457944, -0.176470588235294, -0.176470588235294,

-0.174825741611282, -0.168021680216802, -0.166666666666667, -0.166666666666667,

-0.166380789022298, -0.164209115281501, -0.164011246485473, -0.162689804772234,

-0.162361623616236, -0.160161507402423, -0.16, -0.155038759689922,

-0.154172560113154, -0.15311004784689, -0.151515151515152, -0.151462994836489,

-0.151098901098901, -0.150537634408602, -0.150442477876106, -0.150406504065041,

-0.149904214559387, -0.149882903981265, -0.149797570850202, -0.148496240601504,

-0.148325358851675, -0.147540983606557, -0.147239263803681, -0.146989966555184,

-0.14622641509434, -0.146095717884131, -0.145994832041344, -0.14572864321608,

-0.145161290322581, -0.144292237442922, -0.144144144144144, -0.144021739130435,

-0.14375, -0.142212189616253, -0.141122913505311, -0.140324963072378,

-0.139344262295082, -0.13884007029877, -0.138356164383562, -0.137626262626263,

-0.137142857142857, -0.136690647482014, -0.136577708006279, -0.136363636363636,

-0.136094674556213, -0.135879774577332, -0.135586319218241, -0.135135135135135,

-0.132780082987552, -0.132209405501331, -0.132023755139333, -0.131233595800525,

-0.130434782608696, -0.130434782608696, -0.130268199233717, -0.128813559322034,

-0.1284046692607, -0.128205128205128, -0.128182616330114, -0.127937336814621,

-0.126283367556468, -0.125853658536585, -0.125448028673835, -0.125425564840607,

-0.125311203319502, -0.125, -0.124401913875598, -0.124248496993988,

-0.124031007751938, -0.123572170301142, -0.123188405797102, -0.122905027932961,

-0.121666666666667, -0.121573685907772, -0.120658135283364, -0.120540019286403,

-0.119858156028369, -0.11965811965812, -0.11965811965812, -0.119565217391304,

-0.118942731277533, -0.117820324005891, -0.116257947320618, -0.115789473684211,

-0.115683584819387, -0.115384615384615, -0.115281501340483, -0.114492753623188,

-0.114357262103506, -0.114285714285714, -0.114035087719298, -0.113181972212809,

-0.112790697674419, -0.112781954887218, -0.112195121951219, -0.112191473448018,

-0.111111111111111, -0.111111111111111, -0.110813226094727, -0.110384300899428,

-0.110147441457069, -0.110137672090113, -0.109913793103448, -0.109792284866469,

-0.109375, -0.10919540229885, -0.109112709832134, -0.10844250363901,

-0.107776617954071, -0.10752688172043, -0.107317073170732, -0.106674272675414,

-0.106382978723404, -0.106100795755968, -0.106060606060606, -0.10595160235448,

-0.105742474070326, -0.105263157894737, -0.104454685099846, -0.104283054003724,

-0.103916449086162, -0.103723404255319, -0.103448275862069, -0.102737680438029,

-0.10267471958585, -0.101696871753434, -0.100893997445721, -0.10041265474553,

-0.100042983021706, -0.1, -0.0995111731843576, -0.099502487562189,

-0.0994117647058824, -0.0991561181434598, -0.0989492119089317,

-0.0988372093023255, -0.0983908045977012, -0.0983050847457627,

-0.0977198697068404, -0.0974702380952382, -0.0973819695475956,

-0.097345132743363, -0.0971472629144179, -0.0971438645980254,

-0.0961538461538461, -0.096062667491239, -0.0957347238935687,

-0.0956521739130435, -0.0954773869346733, -0.0954115076474873,

-0.0952380952380952, -0.0951115834218915, -0.0950642007303569,

-0.0949423247559894, -0.0947368421052631, -0.0946291560102303,

-0.0945220193340494, -0.0944309927360775, -0.0943016759776536,

-0.0942720763723149, -0.0941770647653002, -0.0940298507462686,

-0.094017094017094, -0.0935672514619884, -0.0934579439252337,

-0.0930232558139535, -0.0929772502472798, -0.0929054054054054,

-0.0928778745255637, -0.0927700348432055, -0.0925266903914591,

-0.0922502666192677, -0.0918094218415418, -0.0915254237288135,

-0.0914774596906876, -0.0914662894860915, -0.0914285714285715,

-0.0912322274881517, -0.090909090909091, -0.0909090909090909,

-0.09079754601227, -0.0907071455016661, -0.0906593406593406,

-0.0903614457831325, -0.0903323548906352, -0.09, -0.0897243107769424,

-0.0896358543417368, -0.0895522388059702, -0.0895052902487847,

-0.0891719745222929, -0.0888888888888888, -0.0887227819304518,

-0.0887096774193548, -0.0886956521739131, -0.0884703196347032,

-0.0884450784593437, -0.0884413309982488, -0.0883577310155536,

-0.0883054892601431, -0.0882917466410749, -0.0881628999776236,

-0.0881193929739248, -0.0880681818181819, -0.0878186968838525,

-0.087719298245614, -0.0876010781671159, -0.0873634945397815,

-0.0872641509433961, -0.0871512228728901, -0.0871032050299035,

-0.0868133772309825, -0.0865384615384615, -0.0858895705521473,

-0.085742525327403, -0.0855766209280403, -0.0854700854700855,

-0.0853994490358125, -0.0853658536585365, -0.0851063829787235,

-0.085048426150121, -0.0849673202614379, -0.084862385321101,

-0.0843335637529065, -0.0843222985633979, -0.084315503173164,

-0.0842105263157896, -0.0841423948220064, -0.0838323353293414,

-0.0836501901140684, -0.083422459893048, -0.0833333333333334,

-0.0833333333333333, -0.0827236916150815, -0.0826723611958512,

-0.0826039387308535, -0.0824242424242424, -0.0821513002364065,

-0.0820932539682539, -0.0820713238886174, -0.0818181818181818,

-0.0816618911174786, -0.0816613868356214, -0.0816326530612244,

-0.081619937694704, -0.0813748531139835, -0.0811965811965812,

-0.0810372771474878, -0.0809095716552088, -0.0808823529411764,

-0.0808414831492295, -0.0807511737089201, -0.0805722891566266,

-0.0803474484256242, -0.0800000000000001, -0.0800000000000001,

-0.0799584631360333, -0.0795941847087125, -0.0795930580490723,

-0.0794701986754966, -0.0793650793650794, -0.0791855203619909,

-0.0790273556231002, -0.0790273556231002, -0.0789473684210527,

-0.0789473684210526, -0.0787545787545788, -0.0787461773700307,

-0.0786724031960664, -0.0782122905027933, -0.078177727784027,

-0.078125, -0.0778443113772455, -0.0776310524209684, -0.0775862068965517,

-0.0775577557755776, -0.0773930753564156, -0.0772686433063791,

-0.0771513353115727, -0.0771200000000001, -0.0770370370370371,

-0.076923076923077, -0.076923076923077, -0.0769039940461424,

-0.076592082616179, -0.0763425253991292, -0.0762886597938145,

-0.0762886597938145, -0.0761565836298932, -0.0760869565217391,

-0.07597645799893, -0.0758377425044092, -0.0757314974182444,

-0.0755148741418765, -0.0754814305364511, -0.0754189944134078,

-0.0752351097178683, -0.0750988142292491, -0.074935400516796,

-0.0748663101604277, -0.0748031496062992, -0.0747663551401868,

-0.0747295968534907, -0.0747028862478777, -0.0745967741935485,

-0.0741784037558686, -0.0740740740740741, -0.0740740740740741,

-0.0740740740740741, -0.073828125, -0.0736698499317872, -0.0735877862595421,

-0.0735824009102977, -0.0735632183908046, -0.0733944954128441,

-0.0728862973760932, -0.0728279386712096, -0.0726480203414457,

-0.0726329442282749, -0.072632190586868, -0.0725766664070006,

-0.0724137931034483, -0.0722664432341852, -0.0719257540603249,

-0.0717538461538461, -0.0716612377850163, -0.0715181932245923,

-0.0714285714285715, -0.0714285714285713, -0.0710646285867525,

-0.0708446866485014, -0.0708117443868739, -0.0708028321132845,

-0.0706436420722135, -0.0705325930495579, -0.0705128205128205,

-0.0705009276437847, -0.0704043019318861, -0.0702106318956871,

-0.0701663201663202, -0.0700661736084078, -0.0699999999999999,

-0.0695540857691487, -0.0692979983084297, -0.0691823899371069,

-0.0691244239631336, -0.0690335305719921, -0.0689655172413792,

-0.0688536409516944, -0.068450039339103, -0.0682332955832389,

-0.0682261208576998, -0.0681818181818182, -0.0679035250463822,

-0.0679012345679012, -0.0677966101694916, -0.0676384839650145,

-0.0675675675675676, -0.0675241157556271, -0.067463706233988,

-0.0674584323040379, -0.0668523676880222, -0.0666666666666667,

-0.066526455612132, -0.0664206642066421, -0.066321243523316,

-0.0662949194547709, -0.0662579580287669, -0.0662251655629139,

-0.0661764705882353, -0.0661478599221789, -0.0657894736842105,

-0.0657534246575342, -0.0654481924472518, -0.0652900974262034,

-0.0652225100070638, -0.0651126106388572, -0.0650887573964497,

-0.0650684931506849, -0.0650195058517555, -0.0649954627949184,

-0.0649081209247184, -0.064891846921797, -0.0648899188876013,

-0.0648148148148149, -0.0645962732919255, -0.0644599303135888,

-0.0644171779141105, -0.0643564356435644, -0.064327485380117,

-0.0642667310944672, -0.0641975308641976, -0.0641025641025641,

-0.0639197041732701, -0.0638436482084691, -0.0635245901639343,

-0.0634996041171813, -0.0632017594629008, -0.0631313131313131,

-0.0630434782608695, -0.0629405840886203, -0.0629155024568842,

-0.0628765060240964, -0.0628571428571429, -0.0625394819962098,

-0.062476757158795, -0.06203552416592, -0.0620347394540943, -0.0619971604354,

-0.0619946091644204, -0.0619469026548672, -0.0619235836627141,

-0.0618131868131868, -0.0617667356797793, -0.0617312601531677,

-0.0616740088105726, -0.0614161849710983, -0.0613026819923372,

-0.0612244897959185, -0.0610859728506788, -0.0610526315789473,

-0.0610399397136398, -0.0610169491525424, -0.0609659540775929,

-0.0608695652173912, -0.0606060606060606, -0.0606060606060606,

-0.0604929051530994, -0.0604204204204204, -0.0603636363636364,

-0.0602698650674663, -0.0602115541090318, -0.0599352051835853,

-0.0599001663893511, -0.0596379126730565, -0.0594227504244482,

-0.0587275693311581, -0.0587002096436059, -0.0586319218241041,

-0.0586046511627907, -0.0584174190122145, -0.0584011488750599,

-0.0583707504810776, -0.0579299691040165, -0.0579268292682926,

-0.0579050097592712, -0.057608079558922, -0.0574712643678161,

-0.0572450805008944, -0.0570958904109589, -0.0568263045032167,

-0.0568181818181818, -0.0568181818181818, -0.0568031704095112,

-0.0566301923974486, -0.0566037735849057, -0.0566037735849057,

-0.0566037735849056, -0.0564433866031963, -0.0562770562770562,

-0.0561576354679803, -0.0560928433268858, -0.0559006211180124,

-0.0558213716108453, -0.055689240288759, -0.0554101893181468,

-0.0553961597881263, -0.0553633217993079, -0.0553571428571429,

-0.0553481577665964, -0.0553158101216163, -0.0553108174253549,

-0.0548340548340548, -0.0546601261387525, -0.054590570719603,

-0.0545001187366422, -0.0544511668107173, -0.0544274300932089,

-0.0542372881355932, -0.0542168674698794, -0.0540540540540541,

-0.053763440860215, -0.0537513997760358, -0.0536343468615424,

-0.0535714285714286, -0.0534725518114223, -0.0529294274300931,

-0.0528846153846155, -0.0528756957328386, -0.0526458340386634,

-0.0526315789473684, -0.0525606469002696, -0.0525451559934318,

-0.0525227460711332, -0.051948051948052, -0.051792828685259,

-0.0517241379310345, -0.0513784461152881, -0.0513559322033898,

-0.0512610211195407, -0.0512437810945274, -0.051150895140665,

-0.0510695486616643, -0.0507726269315673, -0.0507377685736475,

-0.0506575742815391, -0.0506024096385543, -0.0505494505494506,

-0.0503194888178913, -0.0501567398119122, -0.05, -0.0499001996007984,

-0.0498214285714285, -0.0497737556561087, -0.0497470489038785,

-0.0494845360824741, -0.0493827160493827, -0.0492157923201731,

-0.0491192897035657, -0.0489642184557439, -0.0488200324265898,

-0.0488031366075114, -0.0485151426051161, -0.0483319076133448,

-0.0481220657276996, -0.0480897675661234, -0.0480599647266314,

-0.0480038022813688, -0.0479900280461202, -0.0479548660084627,

-0.0478449164776243, -0.0475638051044084, -0.0475342709631477,

-0.0473213579172271, -0.0472997462848857, -0.0472050636772667,

-0.046890780551147, -0.0467625899280576, -0.046753107010276,

-0.0466592011944754, -0.0465772759350741, -0.0465753424657535,

-0.0464333781965007, -0.0463888365076373, -0.0463215258855587,

-0.046281851274051, -0.0459946060208471, -0.0458715596330275,

-0.0458563535911603, -0.0457367549668873, -0.0456500165398611,

-0.0454373701114679, -0.0454265548766046, -0.0454183266932271,

-0.045213508233324, -0.045182571340902, -0.0451018428709989,

-0.0451018428709989, -0.044955044955045, -0.0444136016655101,

-0.0443722943722945, -0.0442996742671011, -0.0442477876106195,

-0.0442477876106195, -0.0441176470588236, -0.043982895540623,

-0.0438184663536776, -0.0436363636363636, -0.043261231281198,

-0.0432218514782339, -0.0431654676258993, -0.0424336600525938,

-0.0423429781227946, -0.0423387096774193, -0.0420711974110032,

-0.0420083118050095, -0.0420032310177707, -0.0417256011315418,

-0.0416842105263158, -0.0416141235813367, -0.0414593698175788,

-0.0413793103448276, -0.041320942582144, -0.0407865986890023,

-0.0406158747013539, -0.0405803571428572, -0.0405643738977073,

-0.040422053796998, -0.040268456375839, -0.0400500625782228,

-0.0400449101796407, -0.04, -0.0399718147460123, -0.0399137001078749,

-0.0399044464954666, -0.0398863290368415, -0.0398230088495575,

-0.0394736842105263, -0.0393401015228426, -0.0392720306513411,

-0.0392156862745098, -0.0388349514563106, -0.0386904761904763,

-0.0384615384615385, -0.0382457345700217, -0.0382293762575454,

-0.0381840048105834, -0.0380030474141795, -0.0379746835443038,

-0.0379247280777747, -0.0376432078559739, -0.0375494071146245,

-0.0375490837696336, -0.0373345788572318, -0.0372940156114484,

-0.0371871275327772, -0.037037037037037, -0.0368133174791915,

-0.0368098159509203, -0.0367231638418078, -0.0361445783132531,

-0.0360915492957746, -0.0357142857142857, -0.0356663184599313,

-0.0356413696552528, -0.035513103110458, -0.0353194103194103,

-0.0352112676056338, -0.0350119904076739, -0.0349794238683129,

-0.0349373764007909, -0.0349091600875106, -0.0347826086956522,

-0.0347728547392037, -0.0347682119205298, -0.0346083788706739,

-0.0344706296166022, -0.0344421548425081, -0.0341176470588236,

-0.0338983050847458, -0.033457249070632, -0.0334208223972004,

-0.0333333333333334, -0.0333333333333333, -0.0329670329670331,

-0.0329144225014961, -0.0326797385620915, -0.0323033707865168,

-0.0322118826055834, -0.0321750321750322, -0.0320890635232481,

-0.0318302387267905, -0.0316666666666666, -0.0315586914688903,

-0.0312606184165817, -0.030881017257039, -0.0308764940239045,

-0.0305419952434597, -0.030406198638178, -0.0299651567944252,

-0.029945999018164, -0.0298786181139121, -0.0295741147960329,

-0.0293917033546227, -0.029171528588098, -0.0291327913279132,

-0.0290497291974397, -0.0288721376760064, -0.0287704170466792,

-0.0286236297198539, -0.0285714285714286, -0.0277575837684224,

-0.0277085471338513, -0.0275897304892068, -0.0275526742301458,

-0.027027027027027, -0.0270270270270269, -0.0269087523277468,

-0.0268918695148203, -0.02676704307821, -0.026454253142356, -0.0263157894736842,

-0.0263157894736842, -0.0261660978384529, -0.025974025974026,

-0.0257503107796129, -0.0255319148936171, -0.0254237288135594,

-0.025297619047619, -0.0249174422095467, -0.0248888888888889,

-0.024767619719967, -0.0246053853296194, -0.0245269796776454,

-0.024390243902439, -0.0241935483870968, -0.0238907849829351,

-0.0238153295944078, -0.0234413496961306, -0.0232558139534884,

-0.0232558139534883, -0.0230392156862745, -0.0230360307147077,

-0.0228847365106026, -0.0225806451612903, -0.0224519940915805,

-0.0214786344110332, -0.0212360867018161, -0.0205245153933865,

-0.0204170602339606, -0.0200986321764215, -0.0200729927007299,

-0.0199828473413379, -0.0194174757281553, -0.0193536931818183,

-0.0192885771543086, -0.019222732971166, -0.0191414840759143,

-0.0189573459715641, -0.0188902007083826, -0.0186903321231681,

-0.0184456468273487, -0.0183066361556064, -0.0182166826462128,

-0.0181149908112366, -0.0179372197309418, -0.0179172441100772,

-0.0178571428571429, -0.0174672489082969, -0.0174216027874564,

-0.0171428571428572, -0.017017253604349, -0.0169252468265163,

-0.0165094339622642, -0.0158730158730158, -0.0158415841584159,

-0.0157247037374659, -0.0157089706490286, -0.0156250000000001,

-0.0153846153846153, -0.0151668351870576, -0.0151589242053789,

-0.0150489089541008, -0.0150262202501008, -0.0150081124932396,

-0.0148196281468128, -0.0144251166737377, -0.0142857142857142,

-0.0140638734251392, -0.0136986301369863, -0.0133333333333333,

-0.0129464285714286, -0.0129449838187702, -0.0127813811522321,

-0.0126030053320408, -0.0125721665147373, -0.0125, -0.0122160435399906,

-0.0122116689280869, -0.0121019108280255, -0.0118747750989563,

-0.0118277953189996, -0.0117107942973524, -0.0115172759138707,

-0.0114087997381585, -0.0113924050632912, -0.0111524163568772,

-0.0111248454882571, -0.0111111111111111, -0.0102570933795125,

-0.0102040816326532, -0.00963463463463469, -0.00958657878969439,

-0.00941028858218319, -0.00874453466583389, -0.00779588944011335,

-0.00713620850139625, -0.00710720027075056, -0.00709219858156026,

-0.00624999999999998, -0.00551977920883173, -0.00521499557217353,

-0.00453998797354176, -0.00444444444444444, -0.00166389351081533,

-0.00118483412322285, -0.00100704934541787, -0.000937500000000036,

0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,

0.000218031178458569, 0.000796495420151402, 0.00167130919220062,

0.00190476190476193, 0.00350058343057173, 0.00363914958820145,

0.00432900432900424, 0.00456037942356804, 0.00477446915441642,

0.0050825509873745, 0.00525691029336935, 0.00603318250377083,

0.00652173913043472, 0.00733192494097176, 0.00747663551401869,

0.00760456273764256, 0.00812529439472442, 0.00991231414410967,

0.0101685066821615, 0.0106182565507793, 0.0109070034443169, 0.0115183246073298,

0.0115442244823827, 0.0127659574468085, 0.0128076846107665, 0.0135135135135135,

0.0140845070422535, 0.0150730098916627, 0.0159362549800796, 0.0172413793103449,

0.0176899063475547, 0.0186954715413378, 0.0187765706188003, 0.0195757403189066,

0.019607843137255, 0.0199999999999999, 0.0210526315789473, 0.0221979621542939,

0.0239410681399632, 0.0239999999999999, 0.025149051490515, 0.0260869565217392,

0.0262475696694749, 0.028180542563143, 0.0285714285714286, 0.0303030303030302,

0.0315904139433552, 0.0341864716636198, 0.0375782881002089, 0.038479809976247,

0.0387596899224806, 0.0416666666666667, 0.0428100987925357, 0.0428134556574923,

0.0437201907790144, 0.0451127819548872, 0.0460251046025105, 0.0487779511180447,

0.048975188781014, 0.0529872938632063, 0.0562390158172233, 0.0589335827876521,

0.0617551462621885, 0.0628115653040877, 0.0671812464265294, 0.0721784776902887,

0.0736842105263157, 0.0833333333333334, 0.083862394802894, 0.0970464135021097,

0.0971168437025795, 0.102272727272727, 0.111111111111111, 0.117117117117117,

0.123532699832309, 0.141304347826087, 0.179487179487179, 0.191268191268191,

0.205128205128205, 0.219020172910663, 0.271590909090909, 0.333333333333333

)


Now I want to estimate empirical PDF for interval of (-1, 1) including
all points of Dat

I have looked into the density() function, however it appears that,
empirical density is estimated for equally distant points, which not
necessarily contains actual supplied points (in my case, Dat)

Is there any option to achieve the same?

Thanks for your pointer.


From bgunter.4567 at gmail.com  Sun Mar 11 23:19:32 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 11 Mar 2018 15:19:32 -0700
Subject: [R] Empirical density estimation
In-Reply-To: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>
References: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>
Message-ID: <CAGxFJbRmRo9Xcn+Vp1t2Y56QqJguGzqT7FAVd1qYhOkaT8NmMg@mail.gmail.com>

You need to re-read ?density and perhaps think again -- or do some study --
about how a (kernel) density estimate works. The points at which the
estimate is calculated are *not* the values given, nor should they be!

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Mar 11, 2018 at 11:45 AM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> Let say I have below vector of data-points :
>
> Dat = c(-0.444444444444444, -0.25, -0.237449799196787, -0.227467046669042,
>
> -0.227454464682363, -0.22, -0.214876033057851, -0.211781206171108,
>
> -0.199891067538126, -0.192920353982301, -0.192307692307692,
> -0.186046511627907,
>
> -0.184418145956608, -0.181818181818182, -0.181818181818182,
> -0.181266261925412,
>
> -0.181003118503119, -0.179064587973274, -0.178217821782178,
> -0.17809021675454,
>
> -0.177685950413223, -0.177570093457944, -0.176470588235294,
> -0.176470588235294,
>
> -0.174825741611282, -0.168021680216802, -0.166666666666667,
> -0.166666666666667,
>
> -0.166380789022298, -0.164209115281501, -0.164011246485473,
> -0.162689804772234,
>
> -0.162361623616236, -0.160161507402423, -0.16, -0.155038759689922,
>
> -0.154172560113154, -0.15311004784689, -0.151515151515152,
> -0.151462994836489,
>
> -0.151098901098901, -0.150537634408602, -0.150442477876106,
> -0.150406504065041,
>
> -0.149904214559387, -0.149882903981265, -0.149797570850202,
> -0.148496240601504,
>
> -0.148325358851675, -0.147540983606557, -0.147239263803681,
> -0.146989966555184,
>
> -0.14622641509434, -0.146095717884131, -0.145994832041344,
> -0.14572864321608,
>
> -0.145161290322581, -0.144292237442922, -0.144144144144144,
> -0.144021739130435,
>
> -0.14375, -0.142212189616253, -0.141122913505311, -0.140324963072378,
>
> -0.139344262295082, -0.13884007029877, -0.138356164383562,
> -0.137626262626263,
>
> -0.137142857142857, -0.136690647482014, -0.136577708006279,
> -0.136363636363636,
>
> -0.136094674556213, -0.135879774577332, -0.135586319218241,
> -0.135135135135135,
>
> -0.132780082987552, -0.132209405501331, -0.132023755139333,
> -0.131233595800525,
>
> -0.130434782608696, -0.130434782608696, -0.130268199233717,
> -0.128813559322034,
>
> -0.1284046692607, -0.128205128205128, -0.128182616330114,
> -0.127937336814621,
>
> -0.126283367556468, -0.125853658536585, -0.125448028673835,
> -0.125425564840607,
>
> -0.125311203319502, -0.125, -0.124401913875598, -0.124248496993988,
>
> -0.124031007751938, -0.123572170301142, -0.123188405797102,
> -0.122905027932961,
>
> -0.121666666666667, -0.121573685907772, -0.120658135283364,
> -0.120540019286403,
>
> -0.119858156028369, -0.11965811965812, -0.11965811965812,
> -0.119565217391304,
>
> -0.118942731277533, -0.117820324005891, -0.116257947320618,
> -0.115789473684211,
>
> -0.115683584819387, -0.115384615384615, -0.115281501340483,
> -0.114492753623188,
>
> -0.114357262103506, -0.114285714285714, -0.114035087719298,
> -0.113181972212809,
>
> -0.112790697674419, -0.112781954887218, -0.112195121951219,
> -0.112191473448018,
>
> -0.111111111111111, -0.111111111111111, -0.110813226094727,
> -0.110384300899428,
>
> -0.110147441457069, -0.110137672090113, -0.109913793103448,
> -0.109792284866469,
>
> -0.109375, -0.10919540229885, -0.109112709832134, -0.10844250363901,
>
> -0.107776617954071, -0.10752688172043, -0.107317073170732,
> -0.106674272675414,
>
> -0.106382978723404, -0.106100795755968, -0.106060606060606,
> -0.10595160235448,
>
> -0.105742474070326, -0.105263157894737, -0.104454685099846,
> -0.104283054003724,
>
> -0.103916449086162, -0.103723404255319, -0.103448275862069,
> -0.102737680438029,
>
> -0.10267471958585, -0.101696871753434, -0.100893997445721,
> -0.10041265474553,
>
> -0.100042983021706, -0.1, -0.0995111731843576, -0.099502487562189,
>
> -0.0994117647058824, -0.0991561181434598, -0.0989492119089317,
>
> -0.0988372093023255, -0.0983908045977012, -0.0983050847457627,
>
> -0.0977198697068404, -0.0974702380952382, -0.0973819695475956,
>
> -0.097345132743363, -0.0971472629144179, -0.0971438645980254,
>
> -0.0961538461538461, -0.096062667491239, -0.0957347238935687,
>
> -0.0956521739130435, -0.0954773869346733, -0.0954115076474873,
>
> -0.0952380952380952, -0.0951115834218915, -0.0950642007303569,
>
> -0.0949423247559894, -0.0947368421052631, -0.0946291560102303,
>
> -0.0945220193340494, -0.0944309927360775, -0.0943016759776536,
>
> -0.0942720763723149, -0.0941770647653002, -0.0940298507462686,
>
> -0.094017094017094, -0.0935672514619884, -0.0934579439252337,
>
> -0.0930232558139535, -0.0929772502472798, -0.0929054054054054,
>
> -0.0928778745255637, -0.0927700348432055, -0.0925266903914591,
>
> -0.0922502666192677, -0.0918094218415418, -0.0915254237288135,
>
> -0.0914774596906876, -0.0914662894860915, -0.0914285714285715,
>
> -0.0912322274881517, -0.090909090909091, -0.0909090909090909,
>
> -0.09079754601227, -0.0907071455016661, -0.0906593406593406,
>
> -0.0903614457831325, -0.0903323548906352, -0.09, -0.0897243107769424,
>
> -0.0896358543417368, -0.0895522388059702, -0.0895052902487847,
>
> -0.0891719745222929, -0.0888888888888888, -0.0887227819304518,
>
> -0.0887096774193548, -0.0886956521739131, -0.0884703196347032,
>
> -0.0884450784593437, -0.0884413309982488, -0.0883577310155536,
>
> -0.0883054892601431, -0.0882917466410749, -0.0881628999776236,
>
> -0.0881193929739248, -0.0880681818181819, -0.0878186968838525,
>
> -0.087719298245614, -0.0876010781671159, -0.0873634945397815,
>
> -0.0872641509433961, -0.0871512228728901, -0.0871032050299035,
>
> -0.0868133772309825, -0.0865384615384615, -0.0858895705521473,
>
> -0.085742525327403, -0.0855766209280403, -0.0854700854700855,
>
> -0.0853994490358125, -0.0853658536585365, -0.0851063829787235,
>
> -0.085048426150121, -0.0849673202614379, -0.084862385321101,
>
> -0.0843335637529065, -0.0843222985633979, -0.084315503173164,
>
> -0.0842105263157896, -0.0841423948220064, -0.0838323353293414,
>
> -0.0836501901140684, -0.083422459893048, -0.0833333333333334,
>
> -0.0833333333333333, -0.0827236916150815, -0.0826723611958512,
>
> -0.0826039387308535, -0.0824242424242424, -0.0821513002364065,
>
> -0.0820932539682539, -0.0820713238886174, -0.0818181818181818,
>
> -0.0816618911174786, -0.0816613868356214, -0.0816326530612244,
>
> -0.081619937694704, -0.0813748531139835, -0.0811965811965812,
>
> -0.0810372771474878, -0.0809095716552088, -0.0808823529411764,
>
> -0.0808414831492295, -0.0807511737089201, -0.0805722891566266,
>
> -0.0803474484256242, -0.0800000000000001, -0.0800000000000001,
>
> -0.0799584631360333, -0.0795941847087125, -0.0795930580490723,
>
> -0.0794701986754966, -0.0793650793650794, -0.0791855203619909,
>
> -0.0790273556231002, -0.0790273556231002, -0.0789473684210527,
>
> -0.0789473684210526, -0.0787545787545788, -0.0787461773700307,
>
> -0.0786724031960664, -0.0782122905027933, -0.078177727784027,
>
> -0.078125, -0.0778443113772455, -0.0776310524209684, -0.0775862068965517,
>
> -0.0775577557755776, -0.0773930753564156, -0.0772686433063791,
>
> -0.0771513353115727, -0.0771200000000001, -0.0770370370370371,
>
> -0.076923076923077, -0.076923076923077, -0.0769039940461424,
>
> -0.076592082616179, -0.0763425253991292, -0.0762886597938145,
>
> -0.0762886597938145, -0.0761565836298932, -0.0760869565217391,
>
> -0.07597645799893, -0.0758377425044092, -0.0757314974182444,
>
> -0.0755148741418765, -0.0754814305364511, -0.0754189944134078,
>
> -0.0752351097178683, -0.0750988142292491, -0.074935400516796,
>
> -0.0748663101604277, -0.0748031496062992, -0.0747663551401868,
>
> -0.0747295968534907, -0.0747028862478777, -0.0745967741935485,
>
> -0.0741784037558686, -0.0740740740740741, -0.0740740740740741,
>
> -0.0740740740740741, -0.073828125, -0.0736698499317872,
> -0.0735877862595421,
>
> -0.0735824009102977, -0.0735632183908046, -0.0733944954128441,
>
> -0.0728862973760932, -0.0728279386712096, -0.0726480203414457,
>
> -0.0726329442282749, -0.072632190586868, -0.0725766664070006,
>
> -0.0724137931034483, -0.0722664432341852, -0.0719257540603249,
>
> -0.0717538461538461, -0.0716612377850163, -0.0715181932245923,
>
> -0.0714285714285715, -0.0714285714285713, -0.0710646285867525,
>
> -0.0708446866485014, -0.0708117443868739, -0.0708028321132845,
>
> -0.0706436420722135, -0.0705325930495579, -0.0705128205128205,
>
> -0.0705009276437847, -0.0704043019318861, -0.0702106318956871,
>
> -0.0701663201663202, -0.0700661736084078, -0.0699999999999999,
>
> -0.0695540857691487, -0.0692979983084297, -0.0691823899371069,
>
> -0.0691244239631336, -0.0690335305719921, -0.0689655172413792,
>
> -0.0688536409516944, -0.068450039339103, -0.0682332955832389,
>
> -0.0682261208576998, -0.0681818181818182, -0.0679035250463822,
>
> -0.0679012345679012, -0.0677966101694916, -0.0676384839650145,
>
> -0.0675675675675676, -0.0675241157556271, -0.067463706233988,
>
> -0.0674584323040379, -0.0668523676880222, -0.0666666666666667,
>
> -0.066526455612132, -0.0664206642066421, -0.066321243523316,
>
> -0.0662949194547709, -0.0662579580287669, -0.0662251655629139,
>
> -0.0661764705882353, -0.0661478599221789, -0.0657894736842105,
>
> -0.0657534246575342, -0.0654481924472518, -0.0652900974262034,
>
> -0.0652225100070638, -0.0651126106388572, -0.0650887573964497,
>
> -0.0650684931506849, -0.0650195058517555, -0.0649954627949184,
>
> -0.0649081209247184, -0.064891846921797, -0.0648899188876013,
>
> -0.0648148148148149, -0.0645962732919255, -0.0644599303135888,
>
> -0.0644171779141105, -0.0643564356435644, -0.064327485380117,
>
> -0.0642667310944672, -0.0641975308641976, -0.0641025641025641,
>
> -0.0639197041732701, -0.0638436482084691, -0.0635245901639343,
>
> -0.0634996041171813, -0.0632017594629008, -0.0631313131313131,
>
> -0.0630434782608695, -0.0629405840886203, -0.0629155024568842,
>
> -0.0628765060240964, -0.0628571428571429, -0.0625394819962098,
>
> -0.062476757158795, -0.06203552416592, -0.0620347394540943,
> -0.0619971604354,
>
> -0.0619946091644204, -0.0619469026548672, -0.0619235836627141,
>
> -0.0618131868131868, -0.0617667356797793, -0.0617312601531677,
>
> -0.0616740088105726, -0.0614161849710983, -0.0613026819923372,
>
> -0.0612244897959185, -0.0610859728506788, -0.0610526315789473,
>
> -0.0610399397136398, -0.0610169491525424, -0.0609659540775929,
>
> -0.0608695652173912, -0.0606060606060606, -0.0606060606060606,
>
> -0.0604929051530994, -0.0604204204204204, -0.0603636363636364,
>
> -0.0602698650674663, -0.0602115541090318, -0.0599352051835853,
>
> -0.0599001663893511, -0.0596379126730565, -0.0594227504244482,
>
> -0.0587275693311581, -0.0587002096436059, -0.0586319218241041,
>
> -0.0586046511627907, -0.0584174190122145, -0.0584011488750599,
>
> -0.0583707504810776, -0.0579299691040165, -0.0579268292682926,
>
> -0.0579050097592712, -0.057608079558922, -0.0574712643678161,
>
> -0.0572450805008944, -0.0570958904109589, -0.0568263045032167,
>
> -0.0568181818181818, -0.0568181818181818, -0.0568031704095112,
>
> -0.0566301923974486, -0.0566037735849057, -0.0566037735849057,
>
> -0.0566037735849056, -0.0564433866031963, -0.0562770562770562,
>
> -0.0561576354679803, -0.0560928433268858, -0.0559006211180124,
>
> -0.0558213716108453, -0.055689240288759, -0.0554101893181468,
>
> -0.0553961597881263, -0.0553633217993079, -0.0553571428571429,
>
> -0.0553481577665964, -0.0553158101216163, -0.0553108174253549,
>
> -0.0548340548340548, -0.0546601261387525, -0.054590570719603,
>
> -0.0545001187366422, -0.0544511668107173, -0.0544274300932089,
>
> -0.0542372881355932, -0.0542168674698794, -0.0540540540540541,
>
> -0.053763440860215, -0.0537513997760358, -0.0536343468615424,
>
> -0.0535714285714286, -0.0534725518114223, -0.0529294274300931,
>
> -0.0528846153846155, -0.0528756957328386, -0.0526458340386634,
>
> -0.0526315789473684, -0.0525606469002696, -0.0525451559934318,
>
> -0.0525227460711332, -0.051948051948052, -0.051792828685259,
>
> -0.0517241379310345, -0.0513784461152881, -0.0513559322033898,
>
> -0.0512610211195407, -0.0512437810945274, -0.051150895140665,
>
> -0.0510695486616643, -0.0507726269315673, -0.0507377685736475,
>
> -0.0506575742815391, -0.0506024096385543, -0.0505494505494506,
>
> -0.0503194888178913, -0.0501567398119122, -0.05, -0.0499001996007984,
>
> -0.0498214285714285, -0.0497737556561087, -0.0497470489038785,
>
> -0.0494845360824741, -0.0493827160493827, -0.0492157923201731,
>
> -0.0491192897035657, -0.0489642184557439, -0.0488200324265898,
>
> -0.0488031366075114, -0.0485151426051161, -0.0483319076133448,
>
> -0.0481220657276996, -0.0480897675661234, -0.0480599647266314,
>
> -0.0480038022813688, -0.0479900280461202, -0.0479548660084627,
>
> -0.0478449164776243, -0.0475638051044084, -0.0475342709631477,
>
> -0.0473213579172271, -0.0472997462848857, -0.0472050636772667,
>
> -0.046890780551147, -0.0467625899280576, -0.046753107010276,
>
> -0.0466592011944754, -0.0465772759350741, -0.0465753424657535,
>
> -0.0464333781965007, -0.0463888365076373, -0.0463215258855587,
>
> -0.046281851274051, -0.0459946060208471, -0.0458715596330275,
>
> -0.0458563535911603, -0.0457367549668873, -0.0456500165398611,
>
> -0.0454373701114679, -0.0454265548766046, -0.0454183266932271,
>
> -0.045213508233324, -0.045182571340902, -0.0451018428709989,
>
> -0.0451018428709989, -0.044955044955045, -0.0444136016655101,
>
> -0.0443722943722945, -0.0442996742671011, -0.0442477876106195,
>
> -0.0442477876106195, -0.0441176470588236, -0.043982895540623,
>
> -0.0438184663536776, -0.0436363636363636, -0.043261231281198,
>
> -0.0432218514782339, -0.0431654676258993, -0.0424336600525938,
>
> -0.0423429781227946, -0.0423387096774193, -0.0420711974110032,
>
> -0.0420083118050095, -0.0420032310177707, -0.0417256011315418,
>
> -0.0416842105263158, -0.0416141235813367, -0.0414593698175788,
>
> -0.0413793103448276, -0.041320942582144, -0.0407865986890023,
>
> -0.0406158747013539, -0.0405803571428572, -0.0405643738977073,
>
> -0.040422053796998, -0.040268456375839, -0.0400500625782228,
>
> -0.0400449101796407, -0.04, -0.0399718147460123, -0.0399137001078749,
>
> -0.0399044464954666, -0.0398863290368415, -0.0398230088495575,
>
> -0.0394736842105263, -0.0393401015228426, -0.0392720306513411,
>
> -0.0392156862745098, -0.0388349514563106, -0.0386904761904763,
>
> -0.0384615384615385, -0.0382457345700217, -0.0382293762575454,
>
> -0.0381840048105834, -0.0380030474141795, -0.0379746835443038,
>
> -0.0379247280777747, -0.0376432078559739, -0.0375494071146245,
>
> -0.0375490837696336, -0.0373345788572318, -0.0372940156114484,
>
> -0.0371871275327772, -0.037037037037037, -0.0368133174791915,
>
> -0.0368098159509203, -0.0367231638418078, -0.0361445783132531,
>
> -0.0360915492957746, -0.0357142857142857, -0.0356663184599313,
>
> -0.0356413696552528, -0.035513103110458, -0.0353194103194103,
>
> -0.0352112676056338, -0.0350119904076739, -0.0349794238683129,
>
> -0.0349373764007909, -0.0349091600875106, -0.0347826086956522,
>
> -0.0347728547392037, -0.0347682119205298, -0.0346083788706739,
>
> -0.0344706296166022, -0.0344421548425081, -0.0341176470588236,
>
> -0.0338983050847458, -0.033457249070632, -0.0334208223972004,
>
> -0.0333333333333334, -0.0333333333333333, -0.0329670329670331,
>
> -0.0329144225014961, -0.0326797385620915, -0.0323033707865168,
>
> -0.0322118826055834, -0.0321750321750322, -0.0320890635232481,
>
> -0.0318302387267905, -0.0316666666666666, -0.0315586914688903,
>
> -0.0312606184165817, -0.030881017257039, -0.0308764940239045,
>
> -0.0305419952434597, -0.030406198638178, -0.0299651567944252,
>
> -0.029945999018164, -0.0298786181139121, -0.0295741147960329,
>
> -0.0293917033546227, -0.029171528588098, -0.0291327913279132,
>
> -0.0290497291974397, -0.0288721376760064, -0.0287704170466792,
>
> -0.0286236297198539, -0.0285714285714286, -0.0277575837684224,
>
> -0.0277085471338513, -0.0275897304892068, -0.0275526742301458,
>
> -0.027027027027027, -0.0270270270270269, -0.0269087523277468,
>
> -0.0268918695148203, -0.02676704307821, -0.026454253142356,
> -0.0263157894736842,
>
> -0.0263157894736842, -0.0261660978384529, -0.025974025974026,
>
> -0.0257503107796129, -0.0255319148936171, -0.0254237288135594,
>
> -0.025297619047619, -0.0249174422095467, -0.0248888888888889,
>
> -0.024767619719967, -0.0246053853296194, -0.0245269796776454,
>
> -0.024390243902439, -0.0241935483870968, -0.0238907849829351,
>
> -0.0238153295944078, -0.0234413496961306, -0.0232558139534884,
>
> -0.0232558139534883, -0.0230392156862745, -0.0230360307147077,
>
> -0.0228847365106026, -0.0225806451612903, -0.0224519940915805,
>
> -0.0214786344110332, -0.0212360867018161, -0.0205245153933865,
>
> -0.0204170602339606, -0.0200986321764215, -0.0200729927007299,
>
> -0.0199828473413379, -0.0194174757281553, -0.0193536931818183,
>
> -0.0192885771543086, -0.019222732971166, -0.0191414840759143,
>
> -0.0189573459715641, -0.0188902007083826, -0.0186903321231681,
>
> -0.0184456468273487, -0.0183066361556064, -0.0182166826462128,
>
> -0.0181149908112366, -0.0179372197309418, -0.0179172441100772,
>
> -0.0178571428571429, -0.0174672489082969, -0.0174216027874564,
>
> -0.0171428571428572, -0.017017253604349, -0.0169252468265163,
>
> -0.0165094339622642, -0.0158730158730158, -0.0158415841584159,
>
> -0.0157247037374659, -0.0157089706490286, -0.0156250000000001,
>
> -0.0153846153846153, -0.0151668351870576, -0.0151589242053789,
>
> -0.0150489089541008, -0.0150262202501008, -0.0150081124932396,
>
> -0.0148196281468128, -0.0144251166737377, -0.0142857142857142,
>
> -0.0140638734251392, -0.0136986301369863, -0.0133333333333333,
>
> -0.0129464285714286, -0.0129449838187702, -0.0127813811522321,
>
> -0.0126030053320408, -0.0125721665147373, -0.0125, -0.0122160435399906,
>
> -0.0122116689280869, -0.0121019108280255, -0.0118747750989563,
>
> -0.0118277953189996, -0.0117107942973524, -0.0115172759138707,
>
> -0.0114087997381585, -0.0113924050632912, -0.0111524163568772,
>
> -0.0111248454882571, -0.0111111111111111, -0.0102570933795125,
>
> -0.0102040816326532, -0.00963463463463469, -0.00958657878969439,
>
> -0.00941028858218319, -0.00874453466583389, -0.00779588944011335,
>
> -0.00713620850139625, -0.00710720027075056, -0.00709219858156026,
>
> -0.00624999999999998, -0.00551977920883173, -0.00521499557217353,
>
> -0.00453998797354176, -0.00444444444444444, -0.00166389351081533,
>
> -0.00118483412322285, -0.00100704934541787, -0.000937500000000036,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0.000218031178458569, 0.000796495420151402, 0.00167130919220062,
>
> 0.00190476190476193, 0.00350058343057173, 0.00363914958820145,
>
> 0.00432900432900424, 0.00456037942356804, 0.00477446915441642,
>
> 0.0050825509873745, 0.00525691029336935, 0.00603318250377083,
>
> 0.00652173913043472, 0.00733192494097176, 0.00747663551401869,
>
> 0.00760456273764256, 0.00812529439472442, 0.00991231414410967,
>
> 0.0101685066821615, 0.0106182565507793, 0.0109070034443169,
> 0.0115183246073298,
>
> 0.0115442244823827, 0.0127659574468085, 0.0128076846107665,
> 0.0135135135135135,
>
> 0.0140845070422535, 0.0150730098916627, 0.0159362549800796,
> 0.0172413793103449,
>
> 0.0176899063475547, 0.0186954715413378, 0.0187765706188003,
> 0.0195757403189066,
>
> 0.019607843137255, 0.0199999999999999, 0.0210526315789473,
> 0.0221979621542939,
>
> 0.0239410681399632, 0.0239999999999999, 0.025149051490515,
> 0.0260869565217392,
>
> 0.0262475696694749, 0.028180542563143, 0.0285714285714286,
> 0.0303030303030302,
>
> 0.0315904139433552, 0.0341864716636198, 0.0375782881002089,
> 0.038479809976247,
>
> 0.0387596899224806, 0.0416666666666667, 0.0428100987925357,
> 0.0428134556574923,
>
> 0.0437201907790144, 0.0451127819548872, 0.0460251046025105,
> 0.0487779511180447,
>
> 0.048975188781014, 0.0529872938632063, 0.0562390158172233,
> 0.0589335827876521,
>
> 0.0617551462621885, 0.0628115653040877, 0.0671812464265294,
> 0.0721784776902887,
>
> 0.0736842105263157, 0.0833333333333334, 0.083862394802894,
> 0.0970464135021097,
>
> 0.0971168437025795, 0.102272727272727, 0.111111111111111,
> 0.117117117117117,
>
> 0.123532699832309, 0.141304347826087, 0.179487179487179, 0.191268191268191,
>
> 0.205128205128205, 0.219020172910663, 0.271590909090909, 0.333333333333333
>
> )
>
>
> Now I want to estimate empirical PDF for interval of (-1, 1) including
> all points of Dat
>
> I have looked into the density() function, however it appears that,
> empirical density is estimated for equally distant points, which not
> necessarily contains actual supplied points (in my case, Dat)
>
> Is there any option to achieve the same?
>
> Thanks for your pointer.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Sun Mar 11 23:33:55 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 12 Mar 2018 09:33:55 +1100
Subject: [R] Empirical density estimation
In-Reply-To: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>
References: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>
Message-ID: <CA+8X3fVpYgLEDYrGazML4DnB+GwVpQ5L32Ph2XFKBzzBu4GnqA@mail.gmail.com>

Hi Christofer,
You may be looking for ecdf (stats) for a start, then working out a
way to translate the cumulative density values into probability
values.

Jim


On Mon, Mar 12, 2018 at 5:45 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hi,
>
> Let say I have below vector of data-points :
>
> Dat = c(-0.444444444444444, -0.25, -0.237449799196787, -0.227467046669042,
>
> -0.227454464682363, -0.22, -0.214876033057851, -0.211781206171108,
>
> -0.199891067538126, -0.192920353982301, -0.192307692307692, -0.186046511627907,
>
> -0.184418145956608, -0.181818181818182, -0.181818181818182, -0.181266261925412,
>
> -0.181003118503119, -0.179064587973274, -0.178217821782178, -0.17809021675454,
>
> -0.177685950413223, -0.177570093457944, -0.176470588235294, -0.176470588235294,
>
> -0.174825741611282, -0.168021680216802, -0.166666666666667, -0.166666666666667,
>
> -0.166380789022298, -0.164209115281501, -0.164011246485473, -0.162689804772234,
>
> -0.162361623616236, -0.160161507402423, -0.16, -0.155038759689922,
>
> -0.154172560113154, -0.15311004784689, -0.151515151515152, -0.151462994836489,
>
> -0.151098901098901, -0.150537634408602, -0.150442477876106, -0.150406504065041,
>
> -0.149904214559387, -0.149882903981265, -0.149797570850202, -0.148496240601504,
>
> -0.148325358851675, -0.147540983606557, -0.147239263803681, -0.146989966555184,
>
> -0.14622641509434, -0.146095717884131, -0.145994832041344, -0.14572864321608,
>
> -0.145161290322581, -0.144292237442922, -0.144144144144144, -0.144021739130435,
>
> -0.14375, -0.142212189616253, -0.141122913505311, -0.140324963072378,
>
> -0.139344262295082, -0.13884007029877, -0.138356164383562, -0.137626262626263,
>
> -0.137142857142857, -0.136690647482014, -0.136577708006279, -0.136363636363636,
>
> -0.136094674556213, -0.135879774577332, -0.135586319218241, -0.135135135135135,
>
> -0.132780082987552, -0.132209405501331, -0.132023755139333, -0.131233595800525,
>
> -0.130434782608696, -0.130434782608696, -0.130268199233717, -0.128813559322034,
>
> -0.1284046692607, -0.128205128205128, -0.128182616330114, -0.127937336814621,
>
> -0.126283367556468, -0.125853658536585, -0.125448028673835, -0.125425564840607,
>
> -0.125311203319502, -0.125, -0.124401913875598, -0.124248496993988,
>
> -0.124031007751938, -0.123572170301142, -0.123188405797102, -0.122905027932961,
>
> -0.121666666666667, -0.121573685907772, -0.120658135283364, -0.120540019286403,
>
> -0.119858156028369, -0.11965811965812, -0.11965811965812, -0.119565217391304,
>
> -0.118942731277533, -0.117820324005891, -0.116257947320618, -0.115789473684211,
>
> -0.115683584819387, -0.115384615384615, -0.115281501340483, -0.114492753623188,
>
> -0.114357262103506, -0.114285714285714, -0.114035087719298, -0.113181972212809,
>
> -0.112790697674419, -0.112781954887218, -0.112195121951219, -0.112191473448018,
>
> -0.111111111111111, -0.111111111111111, -0.110813226094727, -0.110384300899428,
>
> -0.110147441457069, -0.110137672090113, -0.109913793103448, -0.109792284866469,
>
> -0.109375, -0.10919540229885, -0.109112709832134, -0.10844250363901,
>
> -0.107776617954071, -0.10752688172043, -0.107317073170732, -0.106674272675414,
>
> -0.106382978723404, -0.106100795755968, -0.106060606060606, -0.10595160235448,
>
> -0.105742474070326, -0.105263157894737, -0.104454685099846, -0.104283054003724,
>
> -0.103916449086162, -0.103723404255319, -0.103448275862069, -0.102737680438029,
>
> -0.10267471958585, -0.101696871753434, -0.100893997445721, -0.10041265474553,
>
> -0.100042983021706, -0.1, -0.0995111731843576, -0.099502487562189,
>
> -0.0994117647058824, -0.0991561181434598, -0.0989492119089317,
>
> -0.0988372093023255, -0.0983908045977012, -0.0983050847457627,
>
> -0.0977198697068404, -0.0974702380952382, -0.0973819695475956,
>
> -0.097345132743363, -0.0971472629144179, -0.0971438645980254,
>
> -0.0961538461538461, -0.096062667491239, -0.0957347238935687,
>
> -0.0956521739130435, -0.0954773869346733, -0.0954115076474873,
>
> -0.0952380952380952, -0.0951115834218915, -0.0950642007303569,
>
> -0.0949423247559894, -0.0947368421052631, -0.0946291560102303,
>
> -0.0945220193340494, -0.0944309927360775, -0.0943016759776536,
>
> -0.0942720763723149, -0.0941770647653002, -0.0940298507462686,
>
> -0.094017094017094, -0.0935672514619884, -0.0934579439252337,
>
> -0.0930232558139535, -0.0929772502472798, -0.0929054054054054,
>
> -0.0928778745255637, -0.0927700348432055, -0.0925266903914591,
>
> -0.0922502666192677, -0.0918094218415418, -0.0915254237288135,
>
> -0.0914774596906876, -0.0914662894860915, -0.0914285714285715,
>
> -0.0912322274881517, -0.090909090909091, -0.0909090909090909,
>
> -0.09079754601227, -0.0907071455016661, -0.0906593406593406,
>
> -0.0903614457831325, -0.0903323548906352, -0.09, -0.0897243107769424,
>
> -0.0896358543417368, -0.0895522388059702, -0.0895052902487847,
>
> -0.0891719745222929, -0.0888888888888888, -0.0887227819304518,
>
> -0.0887096774193548, -0.0886956521739131, -0.0884703196347032,
>
> -0.0884450784593437, -0.0884413309982488, -0.0883577310155536,
>
> -0.0883054892601431, -0.0882917466410749, -0.0881628999776236,
>
> -0.0881193929739248, -0.0880681818181819, -0.0878186968838525,
>
> -0.087719298245614, -0.0876010781671159, -0.0873634945397815,
>
> -0.0872641509433961, -0.0871512228728901, -0.0871032050299035,
>
> -0.0868133772309825, -0.0865384615384615, -0.0858895705521473,
>
> -0.085742525327403, -0.0855766209280403, -0.0854700854700855,
>
> -0.0853994490358125, -0.0853658536585365, -0.0851063829787235,
>
> -0.085048426150121, -0.0849673202614379, -0.084862385321101,
>
> -0.0843335637529065, -0.0843222985633979, -0.084315503173164,
>
> -0.0842105263157896, -0.0841423948220064, -0.0838323353293414,
>
> -0.0836501901140684, -0.083422459893048, -0.0833333333333334,
>
> -0.0833333333333333, -0.0827236916150815, -0.0826723611958512,
>
> -0.0826039387308535, -0.0824242424242424, -0.0821513002364065,
>
> -0.0820932539682539, -0.0820713238886174, -0.0818181818181818,
>
> -0.0816618911174786, -0.0816613868356214, -0.0816326530612244,
>
> -0.081619937694704, -0.0813748531139835, -0.0811965811965812,
>
> -0.0810372771474878, -0.0809095716552088, -0.0808823529411764,
>
> -0.0808414831492295, -0.0807511737089201, -0.0805722891566266,
>
> -0.0803474484256242, -0.0800000000000001, -0.0800000000000001,
>
> -0.0799584631360333, -0.0795941847087125, -0.0795930580490723,
>
> -0.0794701986754966, -0.0793650793650794, -0.0791855203619909,
>
> -0.0790273556231002, -0.0790273556231002, -0.0789473684210527,
>
> -0.0789473684210526, -0.0787545787545788, -0.0787461773700307,
>
> -0.0786724031960664, -0.0782122905027933, -0.078177727784027,
>
> -0.078125, -0.0778443113772455, -0.0776310524209684, -0.0775862068965517,
>
> -0.0775577557755776, -0.0773930753564156, -0.0772686433063791,
>
> -0.0771513353115727, -0.0771200000000001, -0.0770370370370371,
>
> -0.076923076923077, -0.076923076923077, -0.0769039940461424,
>
> -0.076592082616179, -0.0763425253991292, -0.0762886597938145,
>
> -0.0762886597938145, -0.0761565836298932, -0.0760869565217391,
>
> -0.07597645799893, -0.0758377425044092, -0.0757314974182444,
>
> -0.0755148741418765, -0.0754814305364511, -0.0754189944134078,
>
> -0.0752351097178683, -0.0750988142292491, -0.074935400516796,
>
> -0.0748663101604277, -0.0748031496062992, -0.0747663551401868,
>
> -0.0747295968534907, -0.0747028862478777, -0.0745967741935485,
>
> -0.0741784037558686, -0.0740740740740741, -0.0740740740740741,
>
> -0.0740740740740741, -0.073828125, -0.0736698499317872, -0.0735877862595421,
>
> -0.0735824009102977, -0.0735632183908046, -0.0733944954128441,
>
> -0.0728862973760932, -0.0728279386712096, -0.0726480203414457,
>
> -0.0726329442282749, -0.072632190586868, -0.0725766664070006,
>
> -0.0724137931034483, -0.0722664432341852, -0.0719257540603249,
>
> -0.0717538461538461, -0.0716612377850163, -0.0715181932245923,
>
> -0.0714285714285715, -0.0714285714285713, -0.0710646285867525,
>
> -0.0708446866485014, -0.0708117443868739, -0.0708028321132845,
>
> -0.0706436420722135, -0.0705325930495579, -0.0705128205128205,
>
> -0.0705009276437847, -0.0704043019318861, -0.0702106318956871,
>
> -0.0701663201663202, -0.0700661736084078, -0.0699999999999999,
>
> -0.0695540857691487, -0.0692979983084297, -0.0691823899371069,
>
> -0.0691244239631336, -0.0690335305719921, -0.0689655172413792,
>
> -0.0688536409516944, -0.068450039339103, -0.0682332955832389,
>
> -0.0682261208576998, -0.0681818181818182, -0.0679035250463822,
>
> -0.0679012345679012, -0.0677966101694916, -0.0676384839650145,
>
> -0.0675675675675676, -0.0675241157556271, -0.067463706233988,
>
> -0.0674584323040379, -0.0668523676880222, -0.0666666666666667,
>
> -0.066526455612132, -0.0664206642066421, -0.066321243523316,
>
> -0.0662949194547709, -0.0662579580287669, -0.0662251655629139,
>
> -0.0661764705882353, -0.0661478599221789, -0.0657894736842105,
>
> -0.0657534246575342, -0.0654481924472518, -0.0652900974262034,
>
> -0.0652225100070638, -0.0651126106388572, -0.0650887573964497,
>
> -0.0650684931506849, -0.0650195058517555, -0.0649954627949184,
>
> -0.0649081209247184, -0.064891846921797, -0.0648899188876013,
>
> -0.0648148148148149, -0.0645962732919255, -0.0644599303135888,
>
> -0.0644171779141105, -0.0643564356435644, -0.064327485380117,
>
> -0.0642667310944672, -0.0641975308641976, -0.0641025641025641,
>
> -0.0639197041732701, -0.0638436482084691, -0.0635245901639343,
>
> -0.0634996041171813, -0.0632017594629008, -0.0631313131313131,
>
> -0.0630434782608695, -0.0629405840886203, -0.0629155024568842,
>
> -0.0628765060240964, -0.0628571428571429, -0.0625394819962098,
>
> -0.062476757158795, -0.06203552416592, -0.0620347394540943, -0.0619971604354,
>
> -0.0619946091644204, -0.0619469026548672, -0.0619235836627141,
>
> -0.0618131868131868, -0.0617667356797793, -0.0617312601531677,
>
> -0.0616740088105726, -0.0614161849710983, -0.0613026819923372,
>
> -0.0612244897959185, -0.0610859728506788, -0.0610526315789473,
>
> -0.0610399397136398, -0.0610169491525424, -0.0609659540775929,
>
> -0.0608695652173912, -0.0606060606060606, -0.0606060606060606,
>
> -0.0604929051530994, -0.0604204204204204, -0.0603636363636364,
>
> -0.0602698650674663, -0.0602115541090318, -0.0599352051835853,
>
> -0.0599001663893511, -0.0596379126730565, -0.0594227504244482,
>
> -0.0587275693311581, -0.0587002096436059, -0.0586319218241041,
>
> -0.0586046511627907, -0.0584174190122145, -0.0584011488750599,
>
> -0.0583707504810776, -0.0579299691040165, -0.0579268292682926,
>
> -0.0579050097592712, -0.057608079558922, -0.0574712643678161,
>
> -0.0572450805008944, -0.0570958904109589, -0.0568263045032167,
>
> -0.0568181818181818, -0.0568181818181818, -0.0568031704095112,
>
> -0.0566301923974486, -0.0566037735849057, -0.0566037735849057,
>
> -0.0566037735849056, -0.0564433866031963, -0.0562770562770562,
>
> -0.0561576354679803, -0.0560928433268858, -0.0559006211180124,
>
> -0.0558213716108453, -0.055689240288759, -0.0554101893181468,
>
> -0.0553961597881263, -0.0553633217993079, -0.0553571428571429,
>
> -0.0553481577665964, -0.0553158101216163, -0.0553108174253549,
>
> -0.0548340548340548, -0.0546601261387525, -0.054590570719603,
>
> -0.0545001187366422, -0.0544511668107173, -0.0544274300932089,
>
> -0.0542372881355932, -0.0542168674698794, -0.0540540540540541,
>
> -0.053763440860215, -0.0537513997760358, -0.0536343468615424,
>
> -0.0535714285714286, -0.0534725518114223, -0.0529294274300931,
>
> -0.0528846153846155, -0.0528756957328386, -0.0526458340386634,
>
> -0.0526315789473684, -0.0525606469002696, -0.0525451559934318,
>
> -0.0525227460711332, -0.051948051948052, -0.051792828685259,
>
> -0.0517241379310345, -0.0513784461152881, -0.0513559322033898,
>
> -0.0512610211195407, -0.0512437810945274, -0.051150895140665,
>
> -0.0510695486616643, -0.0507726269315673, -0.0507377685736475,
>
> -0.0506575742815391, -0.0506024096385543, -0.0505494505494506,
>
> -0.0503194888178913, -0.0501567398119122, -0.05, -0.0499001996007984,
>
> -0.0498214285714285, -0.0497737556561087, -0.0497470489038785,
>
> -0.0494845360824741, -0.0493827160493827, -0.0492157923201731,
>
> -0.0491192897035657, -0.0489642184557439, -0.0488200324265898,
>
> -0.0488031366075114, -0.0485151426051161, -0.0483319076133448,
>
> -0.0481220657276996, -0.0480897675661234, -0.0480599647266314,
>
> -0.0480038022813688, -0.0479900280461202, -0.0479548660084627,
>
> -0.0478449164776243, -0.0475638051044084, -0.0475342709631477,
>
> -0.0473213579172271, -0.0472997462848857, -0.0472050636772667,
>
> -0.046890780551147, -0.0467625899280576, -0.046753107010276,
>
> -0.0466592011944754, -0.0465772759350741, -0.0465753424657535,
>
> -0.0464333781965007, -0.0463888365076373, -0.0463215258855587,
>
> -0.046281851274051, -0.0459946060208471, -0.0458715596330275,
>
> -0.0458563535911603, -0.0457367549668873, -0.0456500165398611,
>
> -0.0454373701114679, -0.0454265548766046, -0.0454183266932271,
>
> -0.045213508233324, -0.045182571340902, -0.0451018428709989,
>
> -0.0451018428709989, -0.044955044955045, -0.0444136016655101,
>
> -0.0443722943722945, -0.0442996742671011, -0.0442477876106195,
>
> -0.0442477876106195, -0.0441176470588236, -0.043982895540623,
>
> -0.0438184663536776, -0.0436363636363636, -0.043261231281198,
>
> -0.0432218514782339, -0.0431654676258993, -0.0424336600525938,
>
> -0.0423429781227946, -0.0423387096774193, -0.0420711974110032,
>
> -0.0420083118050095, -0.0420032310177707, -0.0417256011315418,
>
> -0.0416842105263158, -0.0416141235813367, -0.0414593698175788,
>
> -0.0413793103448276, -0.041320942582144, -0.0407865986890023,
>
> -0.0406158747013539, -0.0405803571428572, -0.0405643738977073,
>
> -0.040422053796998, -0.040268456375839, -0.0400500625782228,
>
> -0.0400449101796407, -0.04, -0.0399718147460123, -0.0399137001078749,
>
> -0.0399044464954666, -0.0398863290368415, -0.0398230088495575,
>
> -0.0394736842105263, -0.0393401015228426, -0.0392720306513411,
>
> -0.0392156862745098, -0.0388349514563106, -0.0386904761904763,
>
> -0.0384615384615385, -0.0382457345700217, -0.0382293762575454,
>
> -0.0381840048105834, -0.0380030474141795, -0.0379746835443038,
>
> -0.0379247280777747, -0.0376432078559739, -0.0375494071146245,
>
> -0.0375490837696336, -0.0373345788572318, -0.0372940156114484,
>
> -0.0371871275327772, -0.037037037037037, -0.0368133174791915,
>
> -0.0368098159509203, -0.0367231638418078, -0.0361445783132531,
>
> -0.0360915492957746, -0.0357142857142857, -0.0356663184599313,
>
> -0.0356413696552528, -0.035513103110458, -0.0353194103194103,
>
> -0.0352112676056338, -0.0350119904076739, -0.0349794238683129,
>
> -0.0349373764007909, -0.0349091600875106, -0.0347826086956522,
>
> -0.0347728547392037, -0.0347682119205298, -0.0346083788706739,
>
> -0.0344706296166022, -0.0344421548425081, -0.0341176470588236,
>
> -0.0338983050847458, -0.033457249070632, -0.0334208223972004,
>
> -0.0333333333333334, -0.0333333333333333, -0.0329670329670331,
>
> -0.0329144225014961, -0.0326797385620915, -0.0323033707865168,
>
> -0.0322118826055834, -0.0321750321750322, -0.0320890635232481,
>
> -0.0318302387267905, -0.0316666666666666, -0.0315586914688903,
>
> -0.0312606184165817, -0.030881017257039, -0.0308764940239045,
>
> -0.0305419952434597, -0.030406198638178, -0.0299651567944252,
>
> -0.029945999018164, -0.0298786181139121, -0.0295741147960329,
>
> -0.0293917033546227, -0.029171528588098, -0.0291327913279132,
>
> -0.0290497291974397, -0.0288721376760064, -0.0287704170466792,
>
> -0.0286236297198539, -0.0285714285714286, -0.0277575837684224,
>
> -0.0277085471338513, -0.0275897304892068, -0.0275526742301458,
>
> -0.027027027027027, -0.0270270270270269, -0.0269087523277468,
>
> -0.0268918695148203, -0.02676704307821, -0.026454253142356, -0.0263157894736842,
>
> -0.0263157894736842, -0.0261660978384529, -0.025974025974026,
>
> -0.0257503107796129, -0.0255319148936171, -0.0254237288135594,
>
> -0.025297619047619, -0.0249174422095467, -0.0248888888888889,
>
> -0.024767619719967, -0.0246053853296194, -0.0245269796776454,
>
> -0.024390243902439, -0.0241935483870968, -0.0238907849829351,
>
> -0.0238153295944078, -0.0234413496961306, -0.0232558139534884,
>
> -0.0232558139534883, -0.0230392156862745, -0.0230360307147077,
>
> -0.0228847365106026, -0.0225806451612903, -0.0224519940915805,
>
> -0.0214786344110332, -0.0212360867018161, -0.0205245153933865,
>
> -0.0204170602339606, -0.0200986321764215, -0.0200729927007299,
>
> -0.0199828473413379, -0.0194174757281553, -0.0193536931818183,
>
> -0.0192885771543086, -0.019222732971166, -0.0191414840759143,
>
> -0.0189573459715641, -0.0188902007083826, -0.0186903321231681,
>
> -0.0184456468273487, -0.0183066361556064, -0.0182166826462128,
>
> -0.0181149908112366, -0.0179372197309418, -0.0179172441100772,
>
> -0.0178571428571429, -0.0174672489082969, -0.0174216027874564,
>
> -0.0171428571428572, -0.017017253604349, -0.0169252468265163,
>
> -0.0165094339622642, -0.0158730158730158, -0.0158415841584159,
>
> -0.0157247037374659, -0.0157089706490286, -0.0156250000000001,
>
> -0.0153846153846153, -0.0151668351870576, -0.0151589242053789,
>
> -0.0150489089541008, -0.0150262202501008, -0.0150081124932396,
>
> -0.0148196281468128, -0.0144251166737377, -0.0142857142857142,
>
> -0.0140638734251392, -0.0136986301369863, -0.0133333333333333,
>
> -0.0129464285714286, -0.0129449838187702, -0.0127813811522321,
>
> -0.0126030053320408, -0.0125721665147373, -0.0125, -0.0122160435399906,
>
> -0.0122116689280869, -0.0121019108280255, -0.0118747750989563,
>
> -0.0118277953189996, -0.0117107942973524, -0.0115172759138707,
>
> -0.0114087997381585, -0.0113924050632912, -0.0111524163568772,
>
> -0.0111248454882571, -0.0111111111111111, -0.0102570933795125,
>
> -0.0102040816326532, -0.00963463463463469, -0.00958657878969439,
>
> -0.00941028858218319, -0.00874453466583389, -0.00779588944011335,
>
> -0.00713620850139625, -0.00710720027075056, -0.00709219858156026,
>
> -0.00624999999999998, -0.00551977920883173, -0.00521499557217353,
>
> -0.00453998797354176, -0.00444444444444444, -0.00166389351081533,
>
> -0.00118483412322285, -0.00100704934541787, -0.000937500000000036,
>
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>
> 0.000218031178458569, 0.000796495420151402, 0.00167130919220062,
>
> 0.00190476190476193, 0.00350058343057173, 0.00363914958820145,
>
> 0.00432900432900424, 0.00456037942356804, 0.00477446915441642,
>
> 0.0050825509873745, 0.00525691029336935, 0.00603318250377083,
>
> 0.00652173913043472, 0.00733192494097176, 0.00747663551401869,
>
> 0.00760456273764256, 0.00812529439472442, 0.00991231414410967,
>
> 0.0101685066821615, 0.0106182565507793, 0.0109070034443169, 0.0115183246073298,
>
> 0.0115442244823827, 0.0127659574468085, 0.0128076846107665, 0.0135135135135135,
>
> 0.0140845070422535, 0.0150730098916627, 0.0159362549800796, 0.0172413793103449,
>
> 0.0176899063475547, 0.0186954715413378, 0.0187765706188003, 0.0195757403189066,
>
> 0.019607843137255, 0.0199999999999999, 0.0210526315789473, 0.0221979621542939,
>
> 0.0239410681399632, 0.0239999999999999, 0.025149051490515, 0.0260869565217392,
>
> 0.0262475696694749, 0.028180542563143, 0.0285714285714286, 0.0303030303030302,
>
> 0.0315904139433552, 0.0341864716636198, 0.0375782881002089, 0.038479809976247,
>
> 0.0387596899224806, 0.0416666666666667, 0.0428100987925357, 0.0428134556574923,
>
> 0.0437201907790144, 0.0451127819548872, 0.0460251046025105, 0.0487779511180447,
>
> 0.048975188781014, 0.0529872938632063, 0.0562390158172233, 0.0589335827876521,
>
> 0.0617551462621885, 0.0628115653040877, 0.0671812464265294, 0.0721784776902887,
>
> 0.0736842105263157, 0.0833333333333334, 0.083862394802894, 0.0970464135021097,
>
> 0.0971168437025795, 0.102272727272727, 0.111111111111111, 0.117117117117117,
>
> 0.123532699832309, 0.141304347826087, 0.179487179487179, 0.191268191268191,
>
> 0.205128205128205, 0.219020172910663, 0.271590909090909, 0.333333333333333
>
> )
>
>
> Now I want to estimate empirical PDF for interval of (-1, 1) including
> all points of Dat
>
> I have looked into the density() function, however it appears that,
> empirical density is estimated for equally distant points, which not
> necessarily contains actual supplied points (in my case, Dat)
>
> Is there any option to achieve the same?
>
> Thanks for your pointer.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bogaso.christofer at gmail.com  Sun Mar 11 23:35:17 2018
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 12 Mar 2018 04:05:17 +0530
Subject: [R] Empirical density estimation
In-Reply-To: <CAGxFJbRmRo9Xcn+Vp1t2Y56QqJguGzqT7FAVd1qYhOkaT8NmMg@mail.gmail.com>
References: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>
 <CAGxFJbRmRo9Xcn+Vp1t2Y56QqJguGzqT7FAVd1qYhOkaT8NmMg@mail.gmail.com>
Message-ID: <CA+dpOJ=MAN0Bt2DdgAzgoombzYqSW92=ATAC1EabXS3KxRap+Q@mail.gmail.com>

But for my reporting purpose, I need to generate a bell curve like
plot based on empirical PDF, that also contains original points.

Any idea would be helpful. Thanks,

On Mon, Mar 12, 2018 at 3:49 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> You need to re-read ?density and perhaps think again -- or do some study --
> about how a (kernel) density estimate works. The points at which the
> estimate is calculated are *not* the values given, nor should they be!
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Mar 11, 2018 at 11:45 AM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>>
>> Hi,
>>
>> Let say I have below vector of data-points :
>>
>> Dat = c(-0.444444444444444, -0.25, -0.237449799196787, -0.227467046669042,
>>
>> -0.227454464682363, -0.22, -0.214876033057851, -0.211781206171108,
>>
>> -0.199891067538126, -0.192920353982301, -0.192307692307692,
>> -0.186046511627907,
>>
>> -0.184418145956608, -0.181818181818182, -0.181818181818182,
>> -0.181266261925412,
>>
>> -0.181003118503119, -0.179064587973274, -0.178217821782178,
>> -0.17809021675454,
>>
>> -0.177685950413223, -0.177570093457944, -0.176470588235294,
>> -0.176470588235294,
>>
>> -0.174825741611282, -0.168021680216802, -0.166666666666667,
>> -0.166666666666667,
>>
>> -0.166380789022298, -0.164209115281501, -0.164011246485473,
>> -0.162689804772234,
>>
>> -0.162361623616236, -0.160161507402423, -0.16, -0.155038759689922,
>>
>> -0.154172560113154, -0.15311004784689, -0.151515151515152,
>> -0.151462994836489,
>>
>> -0.151098901098901, -0.150537634408602, -0.150442477876106,
>> -0.150406504065041,
>>
>> -0.149904214559387, -0.149882903981265, -0.149797570850202,
>> -0.148496240601504,
>>
>> -0.148325358851675, -0.147540983606557, -0.147239263803681,
>> -0.146989966555184,
>>
>> -0.14622641509434, -0.146095717884131, -0.145994832041344,
>> -0.14572864321608,
>>
>> -0.145161290322581, -0.144292237442922, -0.144144144144144,
>> -0.144021739130435,
>>
>> -0.14375, -0.142212189616253, -0.141122913505311, -0.140324963072378,
>>
>> -0.139344262295082, -0.13884007029877, -0.138356164383562,
>> -0.137626262626263,
>>
>> -0.137142857142857, -0.136690647482014, -0.136577708006279,
>> -0.136363636363636,
>>
>> -0.136094674556213, -0.135879774577332, -0.135586319218241,
>> -0.135135135135135,
>>
>> -0.132780082987552, -0.132209405501331, -0.132023755139333,
>> -0.131233595800525,
>>
>> -0.130434782608696, -0.130434782608696, -0.130268199233717,
>> -0.128813559322034,
>>
>> -0.1284046692607, -0.128205128205128, -0.128182616330114,
>> -0.127937336814621,
>>
>> -0.126283367556468, -0.125853658536585, -0.125448028673835,
>> -0.125425564840607,
>>
>> -0.125311203319502, -0.125, -0.124401913875598, -0.124248496993988,
>>
>> -0.124031007751938, -0.123572170301142, -0.123188405797102,
>> -0.122905027932961,
>>
>> -0.121666666666667, -0.121573685907772, -0.120658135283364,
>> -0.120540019286403,
>>
>> -0.119858156028369, -0.11965811965812, -0.11965811965812,
>> -0.119565217391304,
>>
>> -0.118942731277533, -0.117820324005891, -0.116257947320618,
>> -0.115789473684211,
>>
>> -0.115683584819387, -0.115384615384615, -0.115281501340483,
>> -0.114492753623188,
>>
>> -0.114357262103506, -0.114285714285714, -0.114035087719298,
>> -0.113181972212809,
>>
>> -0.112790697674419, -0.112781954887218, -0.112195121951219,
>> -0.112191473448018,
>>
>> -0.111111111111111, -0.111111111111111, -0.110813226094727,
>> -0.110384300899428,
>>
>> -0.110147441457069, -0.110137672090113, -0.109913793103448,
>> -0.109792284866469,
>>
>> -0.109375, -0.10919540229885, -0.109112709832134, -0.10844250363901,
>>
>> -0.107776617954071, -0.10752688172043, -0.107317073170732,
>> -0.106674272675414,
>>
>> -0.106382978723404, -0.106100795755968, -0.106060606060606,
>> -0.10595160235448,
>>
>> -0.105742474070326, -0.105263157894737, -0.104454685099846,
>> -0.104283054003724,
>>
>> -0.103916449086162, -0.103723404255319, -0.103448275862069,
>> -0.102737680438029,
>>
>> -0.10267471958585, -0.101696871753434, -0.100893997445721,
>> -0.10041265474553,
>>
>> -0.100042983021706, -0.1, -0.0995111731843576, -0.099502487562189,
>>
>> -0.0994117647058824, -0.0991561181434598, -0.0989492119089317,
>>
>> -0.0988372093023255, -0.0983908045977012, -0.0983050847457627,
>>
>> -0.0977198697068404, -0.0974702380952382, -0.0973819695475956,
>>
>> -0.097345132743363, -0.0971472629144179, -0.0971438645980254,
>>
>> -0.0961538461538461, -0.096062667491239, -0.0957347238935687,
>>
>> -0.0956521739130435, -0.0954773869346733, -0.0954115076474873,
>>
>> -0.0952380952380952, -0.0951115834218915, -0.0950642007303569,
>>
>> -0.0949423247559894, -0.0947368421052631, -0.0946291560102303,
>>
>> -0.0945220193340494, -0.0944309927360775, -0.0943016759776536,
>>
>> -0.0942720763723149, -0.0941770647653002, -0.0940298507462686,
>>
>> -0.094017094017094, -0.0935672514619884, -0.0934579439252337,
>>
>> -0.0930232558139535, -0.0929772502472798, -0.0929054054054054,
>>
>> -0.0928778745255637, -0.0927700348432055, -0.0925266903914591,
>>
>> -0.0922502666192677, -0.0918094218415418, -0.0915254237288135,
>>
>> -0.0914774596906876, -0.0914662894860915, -0.0914285714285715,
>>
>> -0.0912322274881517, -0.090909090909091, -0.0909090909090909,
>>
>> -0.09079754601227, -0.0907071455016661, -0.0906593406593406,
>>
>> -0.0903614457831325, -0.0903323548906352, -0.09, -0.0897243107769424,
>>
>> -0.0896358543417368, -0.0895522388059702, -0.0895052902487847,
>>
>> -0.0891719745222929, -0.0888888888888888, -0.0887227819304518,
>>
>> -0.0887096774193548, -0.0886956521739131, -0.0884703196347032,
>>
>> -0.0884450784593437, -0.0884413309982488, -0.0883577310155536,
>>
>> -0.0883054892601431, -0.0882917466410749, -0.0881628999776236,
>>
>> -0.0881193929739248, -0.0880681818181819, -0.0878186968838525,
>>
>> -0.087719298245614, -0.0876010781671159, -0.0873634945397815,
>>
>> -0.0872641509433961, -0.0871512228728901, -0.0871032050299035,
>>
>> -0.0868133772309825, -0.0865384615384615, -0.0858895705521473,
>>
>> -0.085742525327403, -0.0855766209280403, -0.0854700854700855,
>>
>> -0.0853994490358125, -0.0853658536585365, -0.0851063829787235,
>>
>> -0.085048426150121, -0.0849673202614379, -0.084862385321101,
>>
>> -0.0843335637529065, -0.0843222985633979, -0.084315503173164,
>>
>> -0.0842105263157896, -0.0841423948220064, -0.0838323353293414,
>>
>> -0.0836501901140684, -0.083422459893048, -0.0833333333333334,
>>
>> -0.0833333333333333, -0.0827236916150815, -0.0826723611958512,
>>
>> -0.0826039387308535, -0.0824242424242424, -0.0821513002364065,
>>
>> -0.0820932539682539, -0.0820713238886174, -0.0818181818181818,
>>
>> -0.0816618911174786, -0.0816613868356214, -0.0816326530612244,
>>
>> -0.081619937694704, -0.0813748531139835, -0.0811965811965812,
>>
>> -0.0810372771474878, -0.0809095716552088, -0.0808823529411764,
>>
>> -0.0808414831492295, -0.0807511737089201, -0.0805722891566266,
>>
>> -0.0803474484256242, -0.0800000000000001, -0.0800000000000001,
>>
>> -0.0799584631360333, -0.0795941847087125, -0.0795930580490723,
>>
>> -0.0794701986754966, -0.0793650793650794, -0.0791855203619909,
>>
>> -0.0790273556231002, -0.0790273556231002, -0.0789473684210527,
>>
>> -0.0789473684210526, -0.0787545787545788, -0.0787461773700307,
>>
>> -0.0786724031960664, -0.0782122905027933, -0.078177727784027,
>>
>> -0.078125, -0.0778443113772455, -0.0776310524209684, -0.0775862068965517,
>>
>> -0.0775577557755776, -0.0773930753564156, -0.0772686433063791,
>>
>> -0.0771513353115727, -0.0771200000000001, -0.0770370370370371,
>>
>> -0.076923076923077, -0.076923076923077, -0.0769039940461424,
>>
>> -0.076592082616179, -0.0763425253991292, -0.0762886597938145,
>>
>> -0.0762886597938145, -0.0761565836298932, -0.0760869565217391,
>>
>> -0.07597645799893, -0.0758377425044092, -0.0757314974182444,
>>
>> -0.0755148741418765, -0.0754814305364511, -0.0754189944134078,
>>
>> -0.0752351097178683, -0.0750988142292491, -0.074935400516796,
>>
>> -0.0748663101604277, -0.0748031496062992, -0.0747663551401868,
>>
>> -0.0747295968534907, -0.0747028862478777, -0.0745967741935485,
>>
>> -0.0741784037558686, -0.0740740740740741, -0.0740740740740741,
>>
>> -0.0740740740740741, -0.073828125, -0.0736698499317872,
>> -0.0735877862595421,
>>
>> -0.0735824009102977, -0.0735632183908046, -0.0733944954128441,
>>
>> -0.0728862973760932, -0.0728279386712096, -0.0726480203414457,
>>
>> -0.0726329442282749, -0.072632190586868, -0.0725766664070006,
>>
>> -0.0724137931034483, -0.0722664432341852, -0.0719257540603249,
>>
>> -0.0717538461538461, -0.0716612377850163, -0.0715181932245923,
>>
>> -0.0714285714285715, -0.0714285714285713, -0.0710646285867525,
>>
>> -0.0708446866485014, -0.0708117443868739, -0.0708028321132845,
>>
>> -0.0706436420722135, -0.0705325930495579, -0.0705128205128205,
>>
>> -0.0705009276437847, -0.0704043019318861, -0.0702106318956871,
>>
>> -0.0701663201663202, -0.0700661736084078, -0.0699999999999999,
>>
>> -0.0695540857691487, -0.0692979983084297, -0.0691823899371069,
>>
>> -0.0691244239631336, -0.0690335305719921, -0.0689655172413792,
>>
>> -0.0688536409516944, -0.068450039339103, -0.0682332955832389,
>>
>> -0.0682261208576998, -0.0681818181818182, -0.0679035250463822,
>>
>> -0.0679012345679012, -0.0677966101694916, -0.0676384839650145,
>>
>> -0.0675675675675676, -0.0675241157556271, -0.067463706233988,
>>
>> -0.0674584323040379, -0.0668523676880222, -0.0666666666666667,
>>
>> -0.066526455612132, -0.0664206642066421, -0.066321243523316,
>>
>> -0.0662949194547709, -0.0662579580287669, -0.0662251655629139,
>>
>> -0.0661764705882353, -0.0661478599221789, -0.0657894736842105,
>>
>> -0.0657534246575342, -0.0654481924472518, -0.0652900974262034,
>>
>> -0.0652225100070638, -0.0651126106388572, -0.0650887573964497,
>>
>> -0.0650684931506849, -0.0650195058517555, -0.0649954627949184,
>>
>> -0.0649081209247184, -0.064891846921797, -0.0648899188876013,
>>
>> -0.0648148148148149, -0.0645962732919255, -0.0644599303135888,
>>
>> -0.0644171779141105, -0.0643564356435644, -0.064327485380117,
>>
>> -0.0642667310944672, -0.0641975308641976, -0.0641025641025641,
>>
>> -0.0639197041732701, -0.0638436482084691, -0.0635245901639343,
>>
>> -0.0634996041171813, -0.0632017594629008, -0.0631313131313131,
>>
>> -0.0630434782608695, -0.0629405840886203, -0.0629155024568842,
>>
>> -0.0628765060240964, -0.0628571428571429, -0.0625394819962098,
>>
>> -0.062476757158795, -0.06203552416592, -0.0620347394540943,
>> -0.0619971604354,
>>
>> -0.0619946091644204, -0.0619469026548672, -0.0619235836627141,
>>
>> -0.0618131868131868, -0.0617667356797793, -0.0617312601531677,
>>
>> -0.0616740088105726, -0.0614161849710983, -0.0613026819923372,
>>
>> -0.0612244897959185, -0.0610859728506788, -0.0610526315789473,
>>
>> -0.0610399397136398, -0.0610169491525424, -0.0609659540775929,
>>
>> -0.0608695652173912, -0.0606060606060606, -0.0606060606060606,
>>
>> -0.0604929051530994, -0.0604204204204204, -0.0603636363636364,
>>
>> -0.0602698650674663, -0.0602115541090318, -0.0599352051835853,
>>
>> -0.0599001663893511, -0.0596379126730565, -0.0594227504244482,
>>
>> -0.0587275693311581, -0.0587002096436059, -0.0586319218241041,
>>
>> -0.0586046511627907, -0.0584174190122145, -0.0584011488750599,
>>
>> -0.0583707504810776, -0.0579299691040165, -0.0579268292682926,
>>
>> -0.0579050097592712, -0.057608079558922, -0.0574712643678161,
>>
>> -0.0572450805008944, -0.0570958904109589, -0.0568263045032167,
>>
>> -0.0568181818181818, -0.0568181818181818, -0.0568031704095112,
>>
>> -0.0566301923974486, -0.0566037735849057, -0.0566037735849057,
>>
>> -0.0566037735849056, -0.0564433866031963, -0.0562770562770562,
>>
>> -0.0561576354679803, -0.0560928433268858, -0.0559006211180124,
>>
>> -0.0558213716108453, -0.055689240288759, -0.0554101893181468,
>>
>> -0.0553961597881263, -0.0553633217993079, -0.0553571428571429,
>>
>> -0.0553481577665964, -0.0553158101216163, -0.0553108174253549,
>>
>> -0.0548340548340548, -0.0546601261387525, -0.054590570719603,
>>
>> -0.0545001187366422, -0.0544511668107173, -0.0544274300932089,
>>
>> -0.0542372881355932, -0.0542168674698794, -0.0540540540540541,
>>
>> -0.053763440860215, -0.0537513997760358, -0.0536343468615424,
>>
>> -0.0535714285714286, -0.0534725518114223, -0.0529294274300931,
>>
>> -0.0528846153846155, -0.0528756957328386, -0.0526458340386634,
>>
>> -0.0526315789473684, -0.0525606469002696, -0.0525451559934318,
>>
>> -0.0525227460711332, -0.051948051948052, -0.051792828685259,
>>
>> -0.0517241379310345, -0.0513784461152881, -0.0513559322033898,
>>
>> -0.0512610211195407, -0.0512437810945274, -0.051150895140665,
>>
>> -0.0510695486616643, -0.0507726269315673, -0.0507377685736475,
>>
>> -0.0506575742815391, -0.0506024096385543, -0.0505494505494506,
>>
>> -0.0503194888178913, -0.0501567398119122, -0.05, -0.0499001996007984,
>>
>> -0.0498214285714285, -0.0497737556561087, -0.0497470489038785,
>>
>> -0.0494845360824741, -0.0493827160493827, -0.0492157923201731,
>>
>> -0.0491192897035657, -0.0489642184557439, -0.0488200324265898,
>>
>> -0.0488031366075114, -0.0485151426051161, -0.0483319076133448,
>>
>> -0.0481220657276996, -0.0480897675661234, -0.0480599647266314,
>>
>> -0.0480038022813688, -0.0479900280461202, -0.0479548660084627,
>>
>> -0.0478449164776243, -0.0475638051044084, -0.0475342709631477,
>>
>> -0.0473213579172271, -0.0472997462848857, -0.0472050636772667,
>>
>> -0.046890780551147, -0.0467625899280576, -0.046753107010276,
>>
>> -0.0466592011944754, -0.0465772759350741, -0.0465753424657535,
>>
>> -0.0464333781965007, -0.0463888365076373, -0.0463215258855587,
>>
>> -0.046281851274051, -0.0459946060208471, -0.0458715596330275,
>>
>> -0.0458563535911603, -0.0457367549668873, -0.0456500165398611,
>>
>> -0.0454373701114679, -0.0454265548766046, -0.0454183266932271,
>>
>> -0.045213508233324, -0.045182571340902, -0.0451018428709989,
>>
>> -0.0451018428709989, -0.044955044955045, -0.0444136016655101,
>>
>> -0.0443722943722945, -0.0442996742671011, -0.0442477876106195,
>>
>> -0.0442477876106195, -0.0441176470588236, -0.043982895540623,
>>
>> -0.0438184663536776, -0.0436363636363636, -0.043261231281198,
>>
>> -0.0432218514782339, -0.0431654676258993, -0.0424336600525938,
>>
>> -0.0423429781227946, -0.0423387096774193, -0.0420711974110032,
>>
>> -0.0420083118050095, -0.0420032310177707, -0.0417256011315418,
>>
>> -0.0416842105263158, -0.0416141235813367, -0.0414593698175788,
>>
>> -0.0413793103448276, -0.041320942582144, -0.0407865986890023,
>>
>> -0.0406158747013539, -0.0405803571428572, -0.0405643738977073,
>>
>> -0.040422053796998, -0.040268456375839, -0.0400500625782228,
>>
>> -0.0400449101796407, -0.04, -0.0399718147460123, -0.0399137001078749,
>>
>> -0.0399044464954666, -0.0398863290368415, -0.0398230088495575,
>>
>> -0.0394736842105263, -0.0393401015228426, -0.0392720306513411,
>>
>> -0.0392156862745098, -0.0388349514563106, -0.0386904761904763,
>>
>> -0.0384615384615385, -0.0382457345700217, -0.0382293762575454,
>>
>> -0.0381840048105834, -0.0380030474141795, -0.0379746835443038,
>>
>> -0.0379247280777747, -0.0376432078559739, -0.0375494071146245,
>>
>> -0.0375490837696336, -0.0373345788572318, -0.0372940156114484,
>>
>> -0.0371871275327772, -0.037037037037037, -0.0368133174791915,
>>
>> -0.0368098159509203, -0.0367231638418078, -0.0361445783132531,
>>
>> -0.0360915492957746, -0.0357142857142857, -0.0356663184599313,
>>
>> -0.0356413696552528, -0.035513103110458, -0.0353194103194103,
>>
>> -0.0352112676056338, -0.0350119904076739, -0.0349794238683129,
>>
>> -0.0349373764007909, -0.0349091600875106, -0.0347826086956522,
>>
>> -0.0347728547392037, -0.0347682119205298, -0.0346083788706739,
>>
>> -0.0344706296166022, -0.0344421548425081, -0.0341176470588236,
>>
>> -0.0338983050847458, -0.033457249070632, -0.0334208223972004,
>>
>> -0.0333333333333334, -0.0333333333333333, -0.0329670329670331,
>>
>> -0.0329144225014961, -0.0326797385620915, -0.0323033707865168,
>>
>> -0.0322118826055834, -0.0321750321750322, -0.0320890635232481,
>>
>> -0.0318302387267905, -0.0316666666666666, -0.0315586914688903,
>>
>> -0.0312606184165817, -0.030881017257039, -0.0308764940239045,
>>
>> -0.0305419952434597, -0.030406198638178, -0.0299651567944252,
>>
>> -0.029945999018164, -0.0298786181139121, -0.0295741147960329,
>>
>> -0.0293917033546227, -0.029171528588098, -0.0291327913279132,
>>
>> -0.0290497291974397, -0.0288721376760064, -0.0287704170466792,
>>
>> -0.0286236297198539, -0.0285714285714286, -0.0277575837684224,
>>
>> -0.0277085471338513, -0.0275897304892068, -0.0275526742301458,
>>
>> -0.027027027027027, -0.0270270270270269, -0.0269087523277468,
>>
>> -0.0268918695148203, -0.02676704307821, -0.026454253142356,
>> -0.0263157894736842,
>>
>> -0.0263157894736842, -0.0261660978384529, -0.025974025974026,
>>
>> -0.0257503107796129, -0.0255319148936171, -0.0254237288135594,
>>
>> -0.025297619047619, -0.0249174422095467, -0.0248888888888889,
>>
>> -0.024767619719967, -0.0246053853296194, -0.0245269796776454,
>>
>> -0.024390243902439, -0.0241935483870968, -0.0238907849829351,
>>
>> -0.0238153295944078, -0.0234413496961306, -0.0232558139534884,
>>
>> -0.0232558139534883, -0.0230392156862745, -0.0230360307147077,
>>
>> -0.0228847365106026, -0.0225806451612903, -0.0224519940915805,
>>
>> -0.0214786344110332, -0.0212360867018161, -0.0205245153933865,
>>
>> -0.0204170602339606, -0.0200986321764215, -0.0200729927007299,
>>
>> -0.0199828473413379, -0.0194174757281553, -0.0193536931818183,
>>
>> -0.0192885771543086, -0.019222732971166, -0.0191414840759143,
>>
>> -0.0189573459715641, -0.0188902007083826, -0.0186903321231681,
>>
>> -0.0184456468273487, -0.0183066361556064, -0.0182166826462128,
>>
>> -0.0181149908112366, -0.0179372197309418, -0.0179172441100772,
>>
>> -0.0178571428571429, -0.0174672489082969, -0.0174216027874564,
>>
>> -0.0171428571428572, -0.017017253604349, -0.0169252468265163,
>>
>> -0.0165094339622642, -0.0158730158730158, -0.0158415841584159,
>>
>> -0.0157247037374659, -0.0157089706490286, -0.0156250000000001,
>>
>> -0.0153846153846153, -0.0151668351870576, -0.0151589242053789,
>>
>> -0.0150489089541008, -0.0150262202501008, -0.0150081124932396,
>>
>> -0.0148196281468128, -0.0144251166737377, -0.0142857142857142,
>>
>> -0.0140638734251392, -0.0136986301369863, -0.0133333333333333,
>>
>> -0.0129464285714286, -0.0129449838187702, -0.0127813811522321,
>>
>> -0.0126030053320408, -0.0125721665147373, -0.0125, -0.0122160435399906,
>>
>> -0.0122116689280869, -0.0121019108280255, -0.0118747750989563,
>>
>> -0.0118277953189996, -0.0117107942973524, -0.0115172759138707,
>>
>> -0.0114087997381585, -0.0113924050632912, -0.0111524163568772,
>>
>> -0.0111248454882571, -0.0111111111111111, -0.0102570933795125,
>>
>> -0.0102040816326532, -0.00963463463463469, -0.00958657878969439,
>>
>> -0.00941028858218319, -0.00874453466583389, -0.00779588944011335,
>>
>> -0.00713620850139625, -0.00710720027075056, -0.00709219858156026,
>>
>> -0.00624999999999998, -0.00551977920883173, -0.00521499557217353,
>>
>> -0.00453998797354176, -0.00444444444444444, -0.00166389351081533,
>>
>> -0.00118483412322285, -0.00100704934541787, -0.000937500000000036,
>>
>> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>>
>> 0.000218031178458569, 0.000796495420151402, 0.00167130919220062,
>>
>> 0.00190476190476193, 0.00350058343057173, 0.00363914958820145,
>>
>> 0.00432900432900424, 0.00456037942356804, 0.00477446915441642,
>>
>> 0.0050825509873745, 0.00525691029336935, 0.00603318250377083,
>>
>> 0.00652173913043472, 0.00733192494097176, 0.00747663551401869,
>>
>> 0.00760456273764256, 0.00812529439472442, 0.00991231414410967,
>>
>> 0.0101685066821615, 0.0106182565507793, 0.0109070034443169,
>> 0.0115183246073298,
>>
>> 0.0115442244823827, 0.0127659574468085, 0.0128076846107665,
>> 0.0135135135135135,
>>
>> 0.0140845070422535, 0.0150730098916627, 0.0159362549800796,
>> 0.0172413793103449,
>>
>> 0.0176899063475547, 0.0186954715413378, 0.0187765706188003,
>> 0.0195757403189066,
>>
>> 0.019607843137255, 0.0199999999999999, 0.0210526315789473,
>> 0.0221979621542939,
>>
>> 0.0239410681399632, 0.0239999999999999, 0.025149051490515,
>> 0.0260869565217392,
>>
>> 0.0262475696694749, 0.028180542563143, 0.0285714285714286,
>> 0.0303030303030302,
>>
>> 0.0315904139433552, 0.0341864716636198, 0.0375782881002089,
>> 0.038479809976247,
>>
>> 0.0387596899224806, 0.0416666666666667, 0.0428100987925357,
>> 0.0428134556574923,
>>
>> 0.0437201907790144, 0.0451127819548872, 0.0460251046025105,
>> 0.0487779511180447,
>>
>> 0.048975188781014, 0.0529872938632063, 0.0562390158172233,
>> 0.0589335827876521,
>>
>> 0.0617551462621885, 0.0628115653040877, 0.0671812464265294,
>> 0.0721784776902887,
>>
>> 0.0736842105263157, 0.0833333333333334, 0.083862394802894,
>> 0.0970464135021097,
>>
>> 0.0971168437025795, 0.102272727272727, 0.111111111111111,
>> 0.117117117117117,
>>
>> 0.123532699832309, 0.141304347826087, 0.179487179487179,
>> 0.191268191268191,
>>
>> 0.205128205128205, 0.219020172910663, 0.271590909090909, 0.333333333333333
>>
>> )
>>
>>
>> Now I want to estimate empirical PDF for interval of (-1, 1) including
>> all points of Dat
>>
>> I have looked into the density() function, however it appears that,
>> empirical density is estimated for equally distant points, which not
>> necessarily contains actual supplied points (in my case, Dat)
>>
>> Is there any option to achieve the same?
>>
>> Thanks for your pointer.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From aggarwalneha2000 at gmail.com  Sun Mar 11 23:32:37 2018
From: aggarwalneha2000 at gmail.com (Neha Aggarwal)
Date: Sun, 11 Mar 2018 18:32:37 -0400
Subject: [R] subsetting comparison problem
Message-ID: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>

Hello All,
I am facing a unique problem and am unable to find any help in R help pages
or online. I will appreciate your help for the following problem:
I have 2 data-frames, samples below and there is an expected output

R Dataframe1:
            C1              C2   C3         C4...... CN
R1       0                  1       0           1
R2        1                  0      1            1
R3        1                  0       0             0
.
.
.
RN

U Dataframe2 :
             C1         C2        C3         C4...... CN
U1         1           1            0            1
U2         1           1             1            1


Expected Output:
U1 satisfies R1, R3
U2 satisfies R1, R2, R3

So this is a comparison of dataframes problem, with a subset dimension.
There are 2 dataframe R and U. column names are same. There are certain
columns belonging to each row in dataframe 1, denoted as 1s, while there
are certain cols to each U denoted as 1s in each URow in dataframe2.

I have to find relationships between Rs and Us. So i start with each U row
in U dataframe (lets say U1 row) and try to find all the rows in R
dataframe, which are subset of U1 row.

I cant find a way to compare rows to see if one is subset of
another....what can I try, any pointers/ packages will be great help.
Please help.

Thanks
Neha

	[[alternative HTML version deleted]]


From djnordlund at gmail.com  Mon Mar 12 00:42:36 2018
From: djnordlund at gmail.com (Daniel Nordlund)
Date: Sun, 11 Mar 2018 16:42:36 -0700
Subject: [R] Empirical density estimation
In-Reply-To: <CA+dpOJ=MAN0Bt2DdgAzgoombzYqSW92=ATAC1EabXS3KxRap+Q@mail.gmail.com>
References: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>
 <CAGxFJbRmRo9Xcn+Vp1t2Y56QqJguGzqT7FAVd1qYhOkaT8NmMg@mail.gmail.com>
 <CA+dpOJ=MAN0Bt2DdgAzgoombzYqSW92=ATAC1EabXS3KxRap+Q@mail.gmail.com>
Message-ID: <e01af373-f9da-0522-c303-edb1f2515863@gmail.com>

On 3/11/2018 3:35 PM, Christofer Bogaso wrote:
> But for my reporting purpose, I need to generate a bell curve like
> plot based on empirical PDF, that also contains original points.
> 
> Any idea would be helpful. Thanks,
> 


Christofer,

something like the following may get you what you want:

## get the kernel density estimate
dens <- density(Dat)

## estimate the density at your original points
dnew <- approx(dens$x,dens$y,xout=Dat)

## plot kernel density estimate
plot(dx)

## add your original values with the estimated density
points(dnew, pch=1, cex=0.5, col="red")


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA

> On Mon, Mar 12, 2018 at 3:49 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>> You need to re-read ?density and perhaps think again -- or do some study --
>> about how a (kernel) density estimate works. The points at which the
>> estimate is calculated are *not* the values given, nor should they be!
>>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Sun, Mar 11, 2018 at 11:45 AM, Christofer Bogaso
>> <bogaso.christofer at gmail.com> wrote:
>>>
>>> Hi,
>>>
>>> Let say I have below vector of data-points :
>>>
>>> Dat = c(-0.444444444444444, -0.25, -0.237449799196787, -0.227467046669042,
>>>
>>> -0.227454464682363, -0.22, -0.214876033057851, -0.211781206171108,
>>>
>>> -0.199891067538126, -0.192920353982301, -0.192307692307692,
>>> -0.186046511627907,
>>>
>>> -0.184418145956608, -0.181818181818182, -0.181818181818182,
>>> -0.181266261925412,
>>>
>>> -0.181003118503119, -0.179064587973274, -0.178217821782178,
>>> -0.17809021675454,
>>>
>>> -0.177685950413223, -0.177570093457944, -0.176470588235294,
>>> -0.176470588235294,
>>>
>>> -0.174825741611282, -0.168021680216802, -0.166666666666667,
>>> -0.166666666666667,
>>>
>>> -0.166380789022298, -0.164209115281501, -0.164011246485473,
>>> -0.162689804772234,
>>>
>>> -0.162361623616236, -0.160161507402423, -0.16, -0.155038759689922,
>>>
>>> -0.154172560113154, -0.15311004784689, -0.151515151515152,
>>> -0.151462994836489,
>>>
>>> -0.151098901098901, -0.150537634408602, -0.150442477876106,
>>> -0.150406504065041,
>>>
>>> -0.149904214559387, -0.149882903981265, -0.149797570850202,
>>> -0.148496240601504,
>>>
>>> -0.148325358851675, -0.147540983606557, -0.147239263803681,
>>> -0.146989966555184,
>>>
>>> -0.14622641509434, -0.146095717884131, -0.145994832041344,
>>> -0.14572864321608,
>>>
>>> -0.145161290322581, -0.144292237442922, -0.144144144144144,
>>> -0.144021739130435,
>>>
>>> -0.14375, -0.142212189616253, -0.141122913505311, -0.140324963072378,
>>>
>>> -0.139344262295082, -0.13884007029877, -0.138356164383562,
>>> -0.137626262626263,
>>>
>>> -0.137142857142857, -0.136690647482014, -0.136577708006279,
>>> -0.136363636363636,
>>>
>>> -0.136094674556213, -0.135879774577332, -0.135586319218241,
>>> -0.135135135135135,
>>>
>>> -0.132780082987552, -0.132209405501331, -0.132023755139333,
>>> -0.131233595800525,
>>>
>>> -0.130434782608696, -0.130434782608696, -0.130268199233717,
>>> -0.128813559322034,
>>>
>>> -0.1284046692607, -0.128205128205128, -0.128182616330114,
>>> -0.127937336814621,
>>>
>>> -0.126283367556468, -0.125853658536585, -0.125448028673835,
>>> -0.125425564840607,
>>>
>>> -0.125311203319502, -0.125, -0.124401913875598, -0.124248496993988,
>>>
>>> -0.124031007751938, -0.123572170301142, -0.123188405797102,
>>> -0.122905027932961,
>>>
>>> -0.121666666666667, -0.121573685907772, -0.120658135283364,
>>> -0.120540019286403,
>>>
>>> -0.119858156028369, -0.11965811965812, -0.11965811965812,
>>> -0.119565217391304,
>>>
>>> -0.118942731277533, -0.117820324005891, -0.116257947320618,
>>> -0.115789473684211,
>>>
>>> -0.115683584819387, -0.115384615384615, -0.115281501340483,
>>> -0.114492753623188,
>>>
>>> -0.114357262103506, -0.114285714285714, -0.114035087719298,
>>> -0.113181972212809,
>>>
>>> -0.112790697674419, -0.112781954887218, -0.112195121951219,
>>> -0.112191473448018,
>>>
>>> -0.111111111111111, -0.111111111111111, -0.110813226094727,
>>> -0.110384300899428,
>>>
>>> -0.110147441457069, -0.110137672090113, -0.109913793103448,
>>> -0.109792284866469,
>>>
>>> -0.109375, -0.10919540229885, -0.109112709832134, -0.10844250363901,
>>>
>>> -0.107776617954071, -0.10752688172043, -0.107317073170732,
>>> -0.106674272675414,
>>>
>>> -0.106382978723404, -0.106100795755968, -0.106060606060606,
>>> -0.10595160235448,
>>>
>>> -0.105742474070326, -0.105263157894737, -0.104454685099846,
>>> -0.104283054003724,
>>>
>>> -0.103916449086162, -0.103723404255319, -0.103448275862069,
>>> -0.102737680438029,
>>>
>>> -0.10267471958585, -0.101696871753434, -0.100893997445721,
>>> -0.10041265474553,
>>>
>>> -0.100042983021706, -0.1, -0.0995111731843576, -0.099502487562189,
>>>
>>> -0.0994117647058824, -0.0991561181434598, -0.0989492119089317,
>>>
>>> -0.0988372093023255, -0.0983908045977012, -0.0983050847457627,
>>>
>>> -0.0977198697068404, -0.0974702380952382, -0.0973819695475956,
>>>
>>> -0.097345132743363, -0.0971472629144179, -0.0971438645980254,
>>>
>>> -0.0961538461538461, -0.096062667491239, -0.0957347238935687,
>>>
>>> -0.0956521739130435, -0.0954773869346733, -0.0954115076474873,
>>>
>>> -0.0952380952380952, -0.0951115834218915, -0.0950642007303569,
>>>
>>> -0.0949423247559894, -0.0947368421052631, -0.0946291560102303,
>>>
>>> -0.0945220193340494, -0.0944309927360775, -0.0943016759776536,
>>>
>>> -0.0942720763723149, -0.0941770647653002, -0.0940298507462686,
>>>
>>> -0.094017094017094, -0.0935672514619884, -0.0934579439252337,
>>>
>>> -0.0930232558139535, -0.0929772502472798, -0.0929054054054054,
>>>
>>> -0.0928778745255637, -0.0927700348432055, -0.0925266903914591,
>>>
>>> -0.0922502666192677, -0.0918094218415418, -0.0915254237288135,
>>>
>>> -0.0914774596906876, -0.0914662894860915, -0.0914285714285715,
>>>
>>> -0.0912322274881517, -0.090909090909091, -0.0909090909090909,
>>>
>>> -0.09079754601227, -0.0907071455016661, -0.0906593406593406,
>>>
>>> -0.0903614457831325, -0.0903323548906352, -0.09, -0.0897243107769424,
>>>
>>> -0.0896358543417368, -0.0895522388059702, -0.0895052902487847,
>>>
>>> -0.0891719745222929, -0.0888888888888888, -0.0887227819304518,
>>>
>>> -0.0887096774193548, -0.0886956521739131, -0.0884703196347032,
>>>
>>> -0.0884450784593437, -0.0884413309982488, -0.0883577310155536,
>>>
>>> -0.0883054892601431, -0.0882917466410749, -0.0881628999776236,
>>>
>>> -0.0881193929739248, -0.0880681818181819, -0.0878186968838525,
>>>
>>> -0.087719298245614, -0.0876010781671159, -0.0873634945397815,
>>>
>>> -0.0872641509433961, -0.0871512228728901, -0.0871032050299035,
>>>
>>> -0.0868133772309825, -0.0865384615384615, -0.0858895705521473,
>>>
>>> -0.085742525327403, -0.0855766209280403, -0.0854700854700855,
>>>
>>> -0.0853994490358125, -0.0853658536585365, -0.0851063829787235,
>>>
>>> -0.085048426150121, -0.0849673202614379, -0.084862385321101,
>>>
>>> -0.0843335637529065, -0.0843222985633979, -0.084315503173164,
>>>
>>> -0.0842105263157896, -0.0841423948220064, -0.0838323353293414,
>>>
>>> -0.0836501901140684, -0.083422459893048, -0.0833333333333334,
>>>
>>> -0.0833333333333333, -0.0827236916150815, -0.0826723611958512,
>>>
>>> -0.0826039387308535, -0.0824242424242424, -0.0821513002364065,
>>>
>>> -0.0820932539682539, -0.0820713238886174, -0.0818181818181818,
>>>
>>> -0.0816618911174786, -0.0816613868356214, -0.0816326530612244,
>>>
>>> -0.081619937694704, -0.0813748531139835, -0.0811965811965812,
>>>
>>> -0.0810372771474878, -0.0809095716552088, -0.0808823529411764,
>>>
>>> -0.0808414831492295, -0.0807511737089201, -0.0805722891566266,
>>>
>>> -0.0803474484256242, -0.0800000000000001, -0.0800000000000001,
>>>
>>> -0.0799584631360333, -0.0795941847087125, -0.0795930580490723,
>>>
>>> -0.0794701986754966, -0.0793650793650794, -0.0791855203619909,
>>>
>>> -0.0790273556231002, -0.0790273556231002, -0.0789473684210527,
>>>
>>> -0.0789473684210526, -0.0787545787545788, -0.0787461773700307,
>>>
>>> -0.0786724031960664, -0.0782122905027933, -0.078177727784027,
>>>
>>> -0.078125, -0.0778443113772455, -0.0776310524209684, -0.0775862068965517,
>>>
>>> -0.0775577557755776, -0.0773930753564156, -0.0772686433063791,
>>>
>>> -0.0771513353115727, -0.0771200000000001, -0.0770370370370371,
>>>
>>> -0.076923076923077, -0.076923076923077, -0.0769039940461424,
>>>
>>> -0.076592082616179, -0.0763425253991292, -0.0762886597938145,
>>>
>>> -0.0762886597938145, -0.0761565836298932, -0.0760869565217391,
>>>
>>> -0.07597645799893, -0.0758377425044092, -0.0757314974182444,
>>>
>>> -0.0755148741418765, -0.0754814305364511, -0.0754189944134078,
>>>
>>> -0.0752351097178683, -0.0750988142292491, -0.074935400516796,
>>>
>>> -0.0748663101604277, -0.0748031496062992, -0.0747663551401868,
>>>
>>> -0.0747295968534907, -0.0747028862478777, -0.0745967741935485,
>>>
>>> -0.0741784037558686, -0.0740740740740741, -0.0740740740740741,
>>>
>>> -0.0740740740740741, -0.073828125, -0.0736698499317872,
>>> -0.0735877862595421,
>>>
>>> -0.0735824009102977, -0.0735632183908046, -0.0733944954128441,
>>>
>>> -0.0728862973760932, -0.0728279386712096, -0.0726480203414457,
>>>
>>> -0.0726329442282749, -0.072632190586868, -0.0725766664070006,
>>>
>>> -0.0724137931034483, -0.0722664432341852, -0.0719257540603249,
>>>
>>> -0.0717538461538461, -0.0716612377850163, -0.0715181932245923,
>>>
>>> -0.0714285714285715, -0.0714285714285713, -0.0710646285867525,
>>>
>>> -0.0708446866485014, -0.0708117443868739, -0.0708028321132845,
>>>
>>> -0.0706436420722135, -0.0705325930495579, -0.0705128205128205,
>>>
>>> -0.0705009276437847, -0.0704043019318861, -0.0702106318956871,
>>>
>>> -0.0701663201663202, -0.0700661736084078, -0.0699999999999999,
>>>
>>> -0.0695540857691487, -0.0692979983084297, -0.0691823899371069,
>>>
>>> -0.0691244239631336, -0.0690335305719921, -0.0689655172413792,
>>>
>>> -0.0688536409516944, -0.068450039339103, -0.0682332955832389,
>>>
>>> -0.0682261208576998, -0.0681818181818182, -0.0679035250463822,
>>>
>>> -0.0679012345679012, -0.0677966101694916, -0.0676384839650145,
>>>
>>> -0.0675675675675676, -0.0675241157556271, -0.067463706233988,
>>>
>>> -0.0674584323040379, -0.0668523676880222, -0.0666666666666667,
>>>
>>> -0.066526455612132, -0.0664206642066421, -0.066321243523316,
>>>
>>> -0.0662949194547709, -0.0662579580287669, -0.0662251655629139,
>>>
>>> -0.0661764705882353, -0.0661478599221789, -0.0657894736842105,
>>>
>>> -0.0657534246575342, -0.0654481924472518, -0.0652900974262034,
>>>
>>> -0.0652225100070638, -0.0651126106388572, -0.0650887573964497,
>>>
>>> -0.0650684931506849, -0.0650195058517555, -0.0649954627949184,
>>>
>>> -0.0649081209247184, -0.064891846921797, -0.0648899188876013,
>>>
>>> -0.0648148148148149, -0.0645962732919255, -0.0644599303135888,
>>>
>>> -0.0644171779141105, -0.0643564356435644, -0.064327485380117,
>>>
>>> -0.0642667310944672, -0.0641975308641976, -0.0641025641025641,
>>>
>>> -0.0639197041732701, -0.0638436482084691, -0.0635245901639343,
>>>
>>> -0.0634996041171813, -0.0632017594629008, -0.0631313131313131,
>>>
>>> -0.0630434782608695, -0.0629405840886203, -0.0629155024568842,
>>>
>>> -0.0628765060240964, -0.0628571428571429, -0.0625394819962098,
>>>
>>> -0.062476757158795, -0.06203552416592, -0.0620347394540943,
>>> -0.0619971604354,
>>>
>>> -0.0619946091644204, -0.0619469026548672, -0.0619235836627141,
>>>
>>> -0.0618131868131868, -0.0617667356797793, -0.0617312601531677,
>>>
>>> -0.0616740088105726, -0.0614161849710983, -0.0613026819923372,
>>>
>>> -0.0612244897959185, -0.0610859728506788, -0.0610526315789473,
>>>
>>> -0.0610399397136398, -0.0610169491525424, -0.0609659540775929,
>>>
>>> -0.0608695652173912, -0.0606060606060606, -0.0606060606060606,
>>>
>>> -0.0604929051530994, -0.0604204204204204, -0.0603636363636364,
>>>
>>> -0.0602698650674663, -0.0602115541090318, -0.0599352051835853,
>>>
>>> -0.0599001663893511, -0.0596379126730565, -0.0594227504244482,
>>>
>>> -0.0587275693311581, -0.0587002096436059, -0.0586319218241041,
>>>
>>> -0.0586046511627907, -0.0584174190122145, -0.0584011488750599,
>>>
>>> -0.0583707504810776, -0.0579299691040165, -0.0579268292682926,
>>>
>>> -0.0579050097592712, -0.057608079558922, -0.0574712643678161,
>>>
>>> -0.0572450805008944, -0.0570958904109589, -0.0568263045032167,
>>>
>>> -0.0568181818181818, -0.0568181818181818, -0.0568031704095112,
>>>
>>> -0.0566301923974486, -0.0566037735849057, -0.0566037735849057,
>>>
>>> -0.0566037735849056, -0.0564433866031963, -0.0562770562770562,
>>>
>>> -0.0561576354679803, -0.0560928433268858, -0.0559006211180124,
>>>
>>> -0.0558213716108453, -0.055689240288759, -0.0554101893181468,
>>>
>>> -0.0553961597881263, -0.0553633217993079, -0.0553571428571429,
>>>
>>> -0.0553481577665964, -0.0553158101216163, -0.0553108174253549,
>>>
>>> -0.0548340548340548, -0.0546601261387525, -0.054590570719603,
>>>
>>> -0.0545001187366422, -0.0544511668107173, -0.0544274300932089,
>>>
>>> -0.0542372881355932, -0.0542168674698794, -0.0540540540540541,
>>>
>>> -0.053763440860215, -0.0537513997760358, -0.0536343468615424,
>>>
>>> -0.0535714285714286, -0.0534725518114223, -0.0529294274300931,
>>>
>>> -0.0528846153846155, -0.0528756957328386, -0.0526458340386634,
>>>
>>> -0.0526315789473684, -0.0525606469002696, -0.0525451559934318,
>>>
>>> -0.0525227460711332, -0.051948051948052, -0.051792828685259,
>>>
>>> -0.0517241379310345, -0.0513784461152881, -0.0513559322033898,
>>>
>>> -0.0512610211195407, -0.0512437810945274, -0.051150895140665,
>>>
>>> -0.0510695486616643, -0.0507726269315673, -0.0507377685736475,
>>>
>>> -0.0506575742815391, -0.0506024096385543, -0.0505494505494506,
>>>
>>> -0.0503194888178913, -0.0501567398119122, -0.05, -0.0499001996007984,
>>>
>>> -0.0498214285714285, -0.0497737556561087, -0.0497470489038785,
>>>
>>> -0.0494845360824741, -0.0493827160493827, -0.0492157923201731,
>>>
>>> -0.0491192897035657, -0.0489642184557439, -0.0488200324265898,
>>>
>>> -0.0488031366075114, -0.0485151426051161, -0.0483319076133448,
>>>
>>> -0.0481220657276996, -0.0480897675661234, -0.0480599647266314,
>>>
>>> -0.0480038022813688, -0.0479900280461202, -0.0479548660084627,
>>>
>>> -0.0478449164776243, -0.0475638051044084, -0.0475342709631477,
>>>
>>> -0.0473213579172271, -0.0472997462848857, -0.0472050636772667,
>>>
>>> -0.046890780551147, -0.0467625899280576, -0.046753107010276,
>>>
>>> -0.0466592011944754, -0.0465772759350741, -0.0465753424657535,
>>>
>>> -0.0464333781965007, -0.0463888365076373, -0.0463215258855587,
>>>
>>> -0.046281851274051, -0.0459946060208471, -0.0458715596330275,
>>>
>>> -0.0458563535911603, -0.0457367549668873, -0.0456500165398611,
>>>
>>> -0.0454373701114679, -0.0454265548766046, -0.0454183266932271,
>>>
>>> -0.045213508233324, -0.045182571340902, -0.0451018428709989,
>>>
>>> -0.0451018428709989, -0.044955044955045, -0.0444136016655101,
>>>
>>> -0.0443722943722945, -0.0442996742671011, -0.0442477876106195,
>>>
>>> -0.0442477876106195, -0.0441176470588236, -0.043982895540623,
>>>
>>> -0.0438184663536776, -0.0436363636363636, -0.043261231281198,
>>>
>>> -0.0432218514782339, -0.0431654676258993, -0.0424336600525938,
>>>
>>> -0.0423429781227946, -0.0423387096774193, -0.0420711974110032,
>>>
>>> -0.0420083118050095, -0.0420032310177707, -0.0417256011315418,
>>>
>>> -0.0416842105263158, -0.0416141235813367, -0.0414593698175788,
>>>
>>> -0.0413793103448276, -0.041320942582144, -0.0407865986890023,
>>>
>>> -0.0406158747013539, -0.0405803571428572, -0.0405643738977073,
>>>
>>> -0.040422053796998, -0.040268456375839, -0.0400500625782228,
>>>
>>> -0.0400449101796407, -0.04, -0.0399718147460123, -0.0399137001078749,
>>>
>>> -0.0399044464954666, -0.0398863290368415, -0.0398230088495575,
>>>
>>> -0.0394736842105263, -0.0393401015228426, -0.0392720306513411,
>>>
>>> -0.0392156862745098, -0.0388349514563106, -0.0386904761904763,
>>>
>>> -0.0384615384615385, -0.0382457345700217, -0.0382293762575454,
>>>
>>> -0.0381840048105834, -0.0380030474141795, -0.0379746835443038,
>>>
>>> -0.0379247280777747, -0.0376432078559739, -0.0375494071146245,
>>>
>>> -0.0375490837696336, -0.0373345788572318, -0.0372940156114484,
>>>
>>> -0.0371871275327772, -0.037037037037037, -0.0368133174791915,
>>>
>>> -0.0368098159509203, -0.0367231638418078, -0.0361445783132531,
>>>
>>> -0.0360915492957746, -0.0357142857142857, -0.0356663184599313,
>>>
>>> -0.0356413696552528, -0.035513103110458, -0.0353194103194103,
>>>
>>> -0.0352112676056338, -0.0350119904076739, -0.0349794238683129,
>>>
>>> -0.0349373764007909, -0.0349091600875106, -0.0347826086956522,
>>>
>>> -0.0347728547392037, -0.0347682119205298, -0.0346083788706739,
>>>
>>> -0.0344706296166022, -0.0344421548425081, -0.0341176470588236,
>>>
>>> -0.0338983050847458, -0.033457249070632, -0.0334208223972004,
>>>
>>> -0.0333333333333334, -0.0333333333333333, -0.0329670329670331,
>>>
>>> -0.0329144225014961, -0.0326797385620915, -0.0323033707865168,
>>>
>>> -0.0322118826055834, -0.0321750321750322, -0.0320890635232481,
>>>
>>> -0.0318302387267905, -0.0316666666666666, -0.0315586914688903,
>>>
>>> -0.0312606184165817, -0.030881017257039, -0.0308764940239045,
>>>
>>> -0.0305419952434597, -0.030406198638178, -0.0299651567944252,
>>>
>>> -0.029945999018164, -0.0298786181139121, -0.0295741147960329,
>>>
>>> -0.0293917033546227, -0.029171528588098, -0.0291327913279132,
>>>
>>> -0.0290497291974397, -0.0288721376760064, -0.0287704170466792,
>>>
>>> -0.0286236297198539, -0.0285714285714286, -0.0277575837684224,
>>>
>>> -0.0277085471338513, -0.0275897304892068, -0.0275526742301458,
>>>
>>> -0.027027027027027, -0.0270270270270269, -0.0269087523277468,
>>>
>>> -0.0268918695148203, -0.02676704307821, -0.026454253142356,
>>> -0.0263157894736842,
>>>
>>> -0.0263157894736842, -0.0261660978384529, -0.025974025974026,
>>>
>>> -0.0257503107796129, -0.0255319148936171, -0.0254237288135594,
>>>
>>> -0.025297619047619, -0.0249174422095467, -0.0248888888888889,
>>>
>>> -0.024767619719967, -0.0246053853296194, -0.0245269796776454,
>>>
>>> -0.024390243902439, -0.0241935483870968, -0.0238907849829351,
>>>
>>> -0.0238153295944078, -0.0234413496961306, -0.0232558139534884,
>>>
>>> -0.0232558139534883, -0.0230392156862745, -0.0230360307147077,
>>>
>>> -0.0228847365106026, -0.0225806451612903, -0.0224519940915805,
>>>
>>> -0.0214786344110332, -0.0212360867018161, -0.0205245153933865,
>>>
>>> -0.0204170602339606, -0.0200986321764215, -0.0200729927007299,
>>>
>>> -0.0199828473413379, -0.0194174757281553, -0.0193536931818183,
>>>
>>> -0.0192885771543086, -0.019222732971166, -0.0191414840759143,
>>>
>>> -0.0189573459715641, -0.0188902007083826, -0.0186903321231681,
>>>
>>> -0.0184456468273487, -0.0183066361556064, -0.0182166826462128,
>>>
>>> -0.0181149908112366, -0.0179372197309418, -0.0179172441100772,
>>>
>>> -0.0178571428571429, -0.0174672489082969, -0.0174216027874564,
>>>
>>> -0.0171428571428572, -0.017017253604349, -0.0169252468265163,
>>>
>>> -0.0165094339622642, -0.0158730158730158, -0.0158415841584159,
>>>
>>> -0.0157247037374659, -0.0157089706490286, -0.0156250000000001,
>>>
>>> -0.0153846153846153, -0.0151668351870576, -0.0151589242053789,
>>>
>>> -0.0150489089541008, -0.0150262202501008, -0.0150081124932396,
>>>
>>> -0.0148196281468128, -0.0144251166737377, -0.0142857142857142,
>>>
>>> -0.0140638734251392, -0.0136986301369863, -0.0133333333333333,
>>>
>>> -0.0129464285714286, -0.0129449838187702, -0.0127813811522321,
>>>
>>> -0.0126030053320408, -0.0125721665147373, -0.0125, -0.0122160435399906,
>>>
>>> -0.0122116689280869, -0.0121019108280255, -0.0118747750989563,
>>>
>>> -0.0118277953189996, -0.0117107942973524, -0.0115172759138707,
>>>
>>> -0.0114087997381585, -0.0113924050632912, -0.0111524163568772,
>>>
>>> -0.0111248454882571, -0.0111111111111111, -0.0102570933795125,
>>>
>>> -0.0102040816326532, -0.00963463463463469, -0.00958657878969439,
>>>
>>> -0.00941028858218319, -0.00874453466583389, -0.00779588944011335,
>>>
>>> -0.00713620850139625, -0.00710720027075056, -0.00709219858156026,
>>>
>>> -0.00624999999999998, -0.00551977920883173, -0.00521499557217353,
>>>
>>> -0.00453998797354176, -0.00444444444444444, -0.00166389351081533,
>>>
>>> -0.00118483412322285, -0.00100704934541787, -0.000937500000000036,
>>>
>>> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>>>
>>> 0.000218031178458569, 0.000796495420151402, 0.00167130919220062,
>>>
>>> 0.00190476190476193, 0.00350058343057173, 0.00363914958820145,
>>>
>>> 0.00432900432900424, 0.00456037942356804, 0.00477446915441642,
>>>
>>> 0.0050825509873745, 0.00525691029336935, 0.00603318250377083,
>>>
>>> 0.00652173913043472, 0.00733192494097176, 0.00747663551401869,
>>>
>>> 0.00760456273764256, 0.00812529439472442, 0.00991231414410967,
>>>
>>> 0.0101685066821615, 0.0106182565507793, 0.0109070034443169,
>>> 0.0115183246073298,
>>>
>>> 0.0115442244823827, 0.0127659574468085, 0.0128076846107665,
>>> 0.0135135135135135,
>>>
>>> 0.0140845070422535, 0.0150730098916627, 0.0159362549800796,
>>> 0.0172413793103449,
>>>
>>> 0.0176899063475547, 0.0186954715413378, 0.0187765706188003,
>>> 0.0195757403189066,
>>>
>>> 0.019607843137255, 0.0199999999999999, 0.0210526315789473,
>>> 0.0221979621542939,
>>>
>>> 0.0239410681399632, 0.0239999999999999, 0.025149051490515,
>>> 0.0260869565217392,
>>>
>>> 0.0262475696694749, 0.028180542563143, 0.0285714285714286,
>>> 0.0303030303030302,
>>>
>>> 0.0315904139433552, 0.0341864716636198, 0.0375782881002089,
>>> 0.038479809976247,
>>>
>>> 0.0387596899224806, 0.0416666666666667, 0.0428100987925357,
>>> 0.0428134556574923,
>>>
>>> 0.0437201907790144, 0.0451127819548872, 0.0460251046025105,
>>> 0.0487779511180447,
>>>
>>> 0.048975188781014, 0.0529872938632063, 0.0562390158172233,
>>> 0.0589335827876521,
>>>
>>> 0.0617551462621885, 0.0628115653040877, 0.0671812464265294,
>>> 0.0721784776902887,
>>>
>>> 0.0736842105263157, 0.0833333333333334, 0.083862394802894,
>>> 0.0970464135021097,
>>>
>>> 0.0971168437025795, 0.102272727272727, 0.111111111111111,
>>> 0.117117117117117,
>>>
>>> 0.123532699832309, 0.141304347826087, 0.179487179487179,
>>> 0.191268191268191,
>>>
>>> 0.205128205128205, 0.219020172910663, 0.271590909090909, 0.333333333333333
>>>
>>> )
>>>
>>>
>>> Now I want to estimate empirical PDF for interval of (-1, 1) including
>>> all points of Dat
>>>
>>> I have looked into the density() function, however it appears that,
>>> empirical density is estimated for equally distant points, which not
>>> necessarily contains actual supplied points (in my case, Dat)
>>>
>>> Is there any option to achieve the same?
>>>
>>> Thanks for your pointer.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Mon Mar 12 03:54:38 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 11 Mar 2018 19:54:38 -0700 (PDT)
Subject: [R] subsetting comparison problem
In-Reply-To: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>
References: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1803111913001.96545@pedal.dcn.davis.ca.us>

Responses inline.

On Sun, 11 Mar 2018, Neha Aggarwal wrote:

> Hello All,
> I am facing a unique problem and am unable to find any help in R help pages
> or online. I will appreciate your help for the following problem:
> I have 2 data-frames, samples below and there is an expected output
>
> R Dataframe1:
>            C1              C2   C3         C4...... CN
> R1       0                  1       0           1
> R2        1                  0      1            1
> R3        1                  0       0             0
> .
> .
> .
> RN
>
> U Dataframe2 :
>             C1         C2        C3         C4...... CN
> U1         1           1            0            1
> U2         1           1             1            1
>
>
> Expected Output:
> U1 satisfies R1, R3
> U2 satisfies R1, R2, R3
>
> So this is a comparison of dataframes problem, with a subset dimension.
> There are 2 dataframe R and U. column names are same. There are certain
> columns belonging to each row in dataframe 1, denoted as 1s, while there
> are certain cols to each U denoted as 1s in each URow in dataframe2.
>
> I have to find relationships between Rs and Us. So i start with each U row
> in U dataframe (lets say U1 row) and try to find all the rows in R
> dataframe, which are subset of U1 row.
>
> I cant find a way to compare rows to see if one is subset of
> another....what can I try, any pointers/ packages will be great help.
> Please help.
>
> Thanks
> Neha
>
> 	[[alternative HTML version deleted]]

As the Posting Guide says (you have read it, haven't you?), please post 
plain text... the mailing list mangles your code with varying levels of 
damage as it tries to fix this problem for you. It also helps if you can 
pose your question in R code rather than pseudo-code and formatted data 
tables.

Your problem appears to be an outer join of binary subsets... I don't 
think this is a very common problem structure (in most cases you want to 
avoid outer joins if you can because they are computationally expensive), 
but you can read ?outer and ?expand.grid to see some ways to pair up all 
possible row indexes.  If you know that the number of rows in both inputs 
is <32, this problem can be optimized for speed and memory with the bitops 
package, or for larger size problems you can use the bit package. The 
below code shows the skeleton of logic with no such optimizations, and is 
likely the most practical solution for a one-off analysis:

##############
r <- read.table( text=
"         C1   	C2     	C3  	C4
R1        0     1       0       1
R2        1     0       1       1
R3        1     0       0       0
", header=TRUE )

u <- read.table( text=
"       C1      C2      C3      C4
U1    	1       1       0       1
U2      1       1       1       1
", header=TRUE )

rmx <- as.matrix( r )
umx <- as.matrix( u )

result <- expand.grid( R = rownames( rmx )
                      , U = rownames( umx )
                      )

# see how:
1L - umx[ U, ]  # 1 for every 0 in u
rmx[ R, ]       # 1 for every 1 in r
( 1L - umx[ U, ] ) * rmx[ R, ] # 1 where both have 1

# do it:
# for every row, 0 where both conditions are true in any column
result$IN <- 1L - with( result
                       , apply(   ( 1L - umx[ U, ] ) # any 0 column
                                * rmx[ R, ]  # any 1 column
                              , 1  # by rows
                              , max
                              )
                       )
result
# show key pairings only
result[ as.logical( result$IN ), c( "U", "R" ) ]
##############

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From dwinsemius at comcast.net  Mon Mar 12 03:59:04 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 11 Mar 2018 19:59:04 -0700
Subject: [R] subsetting comparison problem
In-Reply-To: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>
References: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>
Message-ID: <03323972-4B82-448B-B207-CA08F91F74AD@comcast.net>


> On Mar 11, 2018, at 3:32 PM, Neha Aggarwal <aggarwalneha2000 at gmail.com> wrote:
> 
> Hello All,
> I am facing a unique problem and am unable to find any help in R help pages
> or online. I will appreciate your help for the following problem:
> I have 2 data-frames, samples below and there is an expected output
> 
> R Dataframe1:
>            C1              C2   C3         C4...... CN
> R1       0                  1       0           1
> R2        1                  0      1            1
> R3        1                  0       0             0
> .
> .
> .
> RN
> 
> U Dataframe2 :
>             C1         C2        C3         C4...... CN
> U1         1           1            0            1
> U2         1           1             1            1
> 
> 
> Expected Output:
> U1 satisfies R1, R3
> U2 satisfies R1, R2, R3
> 

I don't think you have communicated what sort of meaning is attached to the word "satisfies".

Here's a double loop that reports membership of the column names of each row of U (Dataframe2) in each row of R (Dataframe1):

 apply( Dataframe2, 1, function(x){ z <- which(x==1);
                                   z2 <- names(x)[z];  
                        zlist=apply(Dataframe1, 1, function(y){ z3 <- which(y==1); 
                                                                z4 <- names(y)[z3]; 
                                                                z4[ which(z4 %in% z2) ]}); 
                        zlist})
$U1
$U1$R1
[1] "C2" "C4"

$U1$R2
[1] "C1" "C4"

$U1$R3
[1] "C1"


$U2
$U2$R1
[1] "C2" "C4"

$U2$R2
[1] "C1" "C3" "C4"

$U2$R3
[1] "C1"

-- 
David.


> So this is a comparison of dataframes problem, with a subset dimension.
> There are 2 dataframe R and U. column names are same. There are certain
> columns belonging to each row in dataframe 1, denoted as 1s, while there
> are certain cols to each U denoted as 1s in each URow in dataframe2.
> 
> I have to find relationships between Rs and Us. So i start with each U row
> in U dataframe (lets say U1 row) and try to find all the rows in R
> dataframe, which are subset of U1 row.
> 
> I cant find a way to compare rows to see if one is subset of
> another....what can I try, any pointers/ packages will be great help.
> Please help.
> 
> Thanks
> Neha
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jdnewmil at dcn.davis.ca.us  Mon Mar 12 04:24:09 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 11 Mar 2018 20:24:09 -0700 (PDT)
Subject: [R] Empirical density estimation
In-Reply-To: <e01af373-f9da-0522-c303-edb1f2515863@gmail.com>
References: <CA+dpOJmThdxL-pfu0d4ijqDuiYtPSNhw+0d1xf=2LGoYdz6pcw@mail.gmail.com>
 <CAGxFJbRmRo9Xcn+Vp1t2Y56QqJguGzqT7FAVd1qYhOkaT8NmMg@mail.gmail.com>
 <CA+dpOJ=MAN0Bt2DdgAzgoombzYqSW92=ATAC1EabXS3KxRap+Q@mail.gmail.com>
 <e01af373-f9da-0522-c303-edb1f2515863@gmail.com>
Message-ID: <alpine.BSF.2.00.1803111957440.96545@pedal.dcn.davis.ca.us>

cwhmisc package provides essentially the algorithm outlined by Dan.

If you want answers outside your original data (extrapolation) then the 
following code at least won't give broken answers, though it is not 
necessarily any more "correct" for extrapolation than the approx solution 
is.

Regarding "needing this for reporting", do thoroughly read ?density as 
Bert suggested, because the bandwidth parameter affects your answers and 
there are various historical recommendations for choosing possible 
bandwidth values, and really no "right" answer.

############
smoothed.df2 <- function ( d ) {
     F <- cumsum( d$y )
     F <- F / F[ length( F ) ] * ( length( F ) - 0.5 ) / length( F )
     eF <- splinefun( d$x, qlogis( F ), "monoH.FC" )
     function( x ) {
         efx <- eF( x )
         plogis( efx )
     }
}

set.seed( 42 )
Dat <- c( rnorm( 100, 1 ), rnorm( 100, 5 ) )

d <- density( Dat )

CDF1 <- cwhmisc::smoothed.df( d )
plot( Dat, CDF1( Dat ) )

CDF2 <- smoothed.df2( d )
plot( Dat, CDF2( Dat ) )

CDF1( -5 ) # <0
CDF2( -5 ) # >0
############

On Sun, 11 Mar 2018, Daniel Nordlund wrote:

> On 3/11/2018 3:35 PM, Christofer Bogaso wrote:
>> But for my reporting purpose, I need to generate a bell curve like
>> plot based on empirical PDF, that also contains original points.
>> 
>> Any idea would be helpful. Thanks,
>> 
>
>
> Christofer,
>
> something like the following may get you what you want:
>
> ## get the kernel density estimate
> dens <- density(Dat)
>
> ## estimate the density at your original points
> dnew <- approx(dens$x,dens$y,xout=Dat)
>
> ## plot kernel density estimate
> plot(dx)
>
> ## add your original values with the estimated density
> points(dnew, pch=1, cex=0.5, col="red")
>
>
> Hope this is helpful,
>
> Dan
>
> -- 
> Daniel Nordlund
> Port Townsend, WA  USA
>
>> On Mon, Mar 12, 2018 at 3:49 AM, Bert Gunter <bgunter.4567 at gmail.com> 
>> wrote:
>>> You need to re-read ?density and perhaps think again -- or do some study 
>>> --
>>> about how a (kernel) density estimate works. The points at which the
>>> estimate is calculated are *not* the values given, nor should they be!
>>> 
>>> Cheers,
>>> Bert
>>> 
>>> 
>>> 
>>> Bert Gunter
>>> 
>>> "The trouble with having an open mind is that people keep coming along and
>>> sticking things into it."
>>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>> 
>>> On Sun, Mar 11, 2018 at 11:45 AM, Christofer Bogaso
>>> <bogaso.christofer at gmail.com> wrote:
>>>> 
>>>> Hi,
>>>> 
>>>> Let say I have below vector of data-points :
>>>> 
>>>> Dat = c(-0.444444444444444, -0.25, -0.237449799196787, 
>>>> -0.227467046669042,
>>>> 
>>>> -0.227454464682363, -0.22, -0.214876033057851, -0.211781206171108,
>>>> 
>>>> -0.199891067538126, -0.192920353982301, -0.192307692307692,
>>>> -0.186046511627907,
>>>> 
>>>> -0.184418145956608, -0.181818181818182, -0.181818181818182,
>>>> -0.181266261925412,
>>>> 
>>>> -0.181003118503119, -0.179064587973274, -0.178217821782178,
>>>> -0.17809021675454,
>>>> 
>>>> -0.177685950413223, -0.177570093457944, -0.176470588235294,
>>>> -0.176470588235294,
>>>> 
>>>> -0.174825741611282, -0.168021680216802, -0.166666666666667,
>>>> -0.166666666666667,
>>>> 
>>>> -0.166380789022298, -0.164209115281501, -0.164011246485473,
>>>> -0.162689804772234,
>>>> 
>>>> -0.162361623616236, -0.160161507402423, -0.16, -0.155038759689922,
>>>> 
>>>> -0.154172560113154, -0.15311004784689, -0.151515151515152,
>>>> -0.151462994836489,
>>>> 
>>>> -0.151098901098901, -0.150537634408602, -0.150442477876106,
>>>> -0.150406504065041,
>>>> 
>>>> -0.149904214559387, -0.149882903981265, -0.149797570850202,
>>>> -0.148496240601504,
>>>> 
>>>> -0.148325358851675, -0.147540983606557, -0.147239263803681,
>>>> -0.146989966555184,
>>>> 
>>>> -0.14622641509434, -0.146095717884131, -0.145994832041344,
>>>> -0.14572864321608,
>>>> 
>>>> -0.145161290322581, -0.144292237442922, -0.144144144144144,
>>>> -0.144021739130435,
>>>> 
>>>> -0.14375, -0.142212189616253, -0.141122913505311, -0.140324963072378,
>>>> 
>>>> -0.139344262295082, -0.13884007029877, -0.138356164383562,
>>>> -0.137626262626263,
>>>> 
>>>> -0.137142857142857, -0.136690647482014, -0.136577708006279,
>>>> -0.136363636363636,
>>>> 
>>>> -0.136094674556213, -0.135879774577332, -0.135586319218241,
>>>> -0.135135135135135,
>>>> 
>>>> -0.132780082987552, -0.132209405501331, -0.132023755139333,
>>>> -0.131233595800525,
>>>> 
>>>> -0.130434782608696, -0.130434782608696, -0.130268199233717,
>>>> -0.128813559322034,
>>>> 
>>>> -0.1284046692607, -0.128205128205128, -0.128182616330114,
>>>> -0.127937336814621,
>>>> 
>>>> -0.126283367556468, -0.125853658536585, -0.125448028673835,
>>>> -0.125425564840607,
>>>> 
>>>> -0.125311203319502, -0.125, -0.124401913875598, -0.124248496993988,
>>>> 
>>>> -0.124031007751938, -0.123572170301142, -0.123188405797102,
>>>> -0.122905027932961,
>>>> 
>>>> -0.121666666666667, -0.121573685907772, -0.120658135283364,
>>>> -0.120540019286403,
>>>> 
>>>> -0.119858156028369, -0.11965811965812, -0.11965811965812,
>>>> -0.119565217391304,
>>>> 
>>>> -0.118942731277533, -0.117820324005891, -0.116257947320618,
>>>> -0.115789473684211,
>>>> 
>>>> -0.115683584819387, -0.115384615384615, -0.115281501340483,
>>>> -0.114492753623188,
>>>> 
>>>> -0.114357262103506, -0.114285714285714, -0.114035087719298,
>>>> -0.113181972212809,
>>>> 
>>>> -0.112790697674419, -0.112781954887218, -0.112195121951219,
>>>> -0.112191473448018,
>>>> 
>>>> -0.111111111111111, -0.111111111111111, -0.110813226094727,
>>>> -0.110384300899428,
>>>> 
>>>> -0.110147441457069, -0.110137672090113, -0.109913793103448,
>>>> -0.109792284866469,
>>>> 
>>>> -0.109375, -0.10919540229885, -0.109112709832134, -0.10844250363901,
>>>> 
>>>> -0.107776617954071, -0.10752688172043, -0.107317073170732,
>>>> -0.106674272675414,
>>>> 
>>>> -0.106382978723404, -0.106100795755968, -0.106060606060606,
>>>> -0.10595160235448,
>>>> 
>>>> -0.105742474070326, -0.105263157894737, -0.104454685099846,
>>>> -0.104283054003724,
>>>> 
>>>> -0.103916449086162, -0.103723404255319, -0.103448275862069,
>>>> -0.102737680438029,
>>>> 
>>>> -0.10267471958585, -0.101696871753434, -0.100893997445721,
>>>> -0.10041265474553,
>>>> 
>>>> -0.100042983021706, -0.1, -0.0995111731843576, -0.099502487562189,
>>>> 
>>>> -0.0994117647058824, -0.0991561181434598, -0.0989492119089317,
>>>> 
>>>> -0.0988372093023255, -0.0983908045977012, -0.0983050847457627,
>>>> 
>>>> -0.0977198697068404, -0.0974702380952382, -0.0973819695475956,
>>>> 
>>>> -0.097345132743363, -0.0971472629144179, -0.0971438645980254,
>>>> 
>>>> -0.0961538461538461, -0.096062667491239, -0.0957347238935687,
>>>> 
>>>> -0.0956521739130435, -0.0954773869346733, -0.0954115076474873,
>>>> 
>>>> -0.0952380952380952, -0.0951115834218915, -0.0950642007303569,
>>>> 
>>>> -0.0949423247559894, -0.0947368421052631, -0.0946291560102303,
>>>> 
>>>> -0.0945220193340494, -0.0944309927360775, -0.0943016759776536,
>>>> 
>>>> -0.0942720763723149, -0.0941770647653002, -0.0940298507462686,
>>>> 
>>>> -0.094017094017094, -0.0935672514619884, -0.0934579439252337,
>>>> 
>>>> -0.0930232558139535, -0.0929772502472798, -0.0929054054054054,
>>>> 
>>>> -0.0928778745255637, -0.0927700348432055, -0.0925266903914591,
>>>> 
>>>> -0.0922502666192677, -0.0918094218415418, -0.0915254237288135,
>>>> 
>>>> -0.0914774596906876, -0.0914662894860915, -0.0914285714285715,
>>>> 
>>>> -0.0912322274881517, -0.090909090909091, -0.0909090909090909,
>>>> 
>>>> -0.09079754601227, -0.0907071455016661, -0.0906593406593406,
>>>> 
>>>> -0.0903614457831325, -0.0903323548906352, -0.09, -0.0897243107769424,
>>>> 
>>>> -0.0896358543417368, -0.0895522388059702, -0.0895052902487847,
>>>> 
>>>> -0.0891719745222929, -0.0888888888888888, -0.0887227819304518,
>>>> 
>>>> -0.0887096774193548, -0.0886956521739131, -0.0884703196347032,
>>>> 
>>>> -0.0884450784593437, -0.0884413309982488, -0.0883577310155536,
>>>> 
>>>> -0.0883054892601431, -0.0882917466410749, -0.0881628999776236,
>>>> 
>>>> -0.0881193929739248, -0.0880681818181819, -0.0878186968838525,
>>>> 
>>>> -0.087719298245614, -0.0876010781671159, -0.0873634945397815,
>>>> 
>>>> -0.0872641509433961, -0.0871512228728901, -0.0871032050299035,
>>>> 
>>>> -0.0868133772309825, -0.0865384615384615, -0.0858895705521473,
>>>> 
>>>> -0.085742525327403, -0.0855766209280403, -0.0854700854700855,
>>>> 
>>>> -0.0853994490358125, -0.0853658536585365, -0.0851063829787235,
>>>> 
>>>> -0.085048426150121, -0.0849673202614379, -0.084862385321101,
>>>> 
>>>> -0.0843335637529065, -0.0843222985633979, -0.084315503173164,
>>>> 
>>>> -0.0842105263157896, -0.0841423948220064, -0.0838323353293414,
>>>> 
>>>> -0.0836501901140684, -0.083422459893048, -0.0833333333333334,
>>>> 
>>>> -0.0833333333333333, -0.0827236916150815, -0.0826723611958512,
>>>> 
>>>> -0.0826039387308535, -0.0824242424242424, -0.0821513002364065,
>>>> 
>>>> -0.0820932539682539, -0.0820713238886174, -0.0818181818181818,
>>>> 
>>>> -0.0816618911174786, -0.0816613868356214, -0.0816326530612244,
>>>> 
>>>> -0.081619937694704, -0.0813748531139835, -0.0811965811965812,
>>>> 
>>>> -0.0810372771474878, -0.0809095716552088, -0.0808823529411764,
>>>> 
>>>> -0.0808414831492295, -0.0807511737089201, -0.0805722891566266,
>>>> 
>>>> -0.0803474484256242, -0.0800000000000001, -0.0800000000000001,
>>>> 
>>>> -0.0799584631360333, -0.0795941847087125, -0.0795930580490723,
>>>> 
>>>> -0.0794701986754966, -0.0793650793650794, -0.0791855203619909,
>>>> 
>>>> -0.0790273556231002, -0.0790273556231002, -0.0789473684210527,
>>>> 
>>>> -0.0789473684210526, -0.0787545787545788, -0.0787461773700307,
>>>> 
>>>> -0.0786724031960664, -0.0782122905027933, -0.078177727784027,
>>>> 
>>>> -0.078125, -0.0778443113772455, -0.0776310524209684, -0.0775862068965517,
>>>> 
>>>> -0.0775577557755776, -0.0773930753564156, -0.0772686433063791,
>>>> 
>>>> -0.0771513353115727, -0.0771200000000001, -0.0770370370370371,
>>>> 
>>>> -0.076923076923077, -0.076923076923077, -0.0769039940461424,
>>>> 
>>>> -0.076592082616179, -0.0763425253991292, -0.0762886597938145,
>>>> 
>>>> -0.0762886597938145, -0.0761565836298932, -0.0760869565217391,
>>>> 
>>>> -0.07597645799893, -0.0758377425044092, -0.0757314974182444,
>>>> 
>>>> -0.0755148741418765, -0.0754814305364511, -0.0754189944134078,
>>>> 
>>>> -0.0752351097178683, -0.0750988142292491, -0.074935400516796,
>>>> 
>>>> -0.0748663101604277, -0.0748031496062992, -0.0747663551401868,
>>>> 
>>>> -0.0747295968534907, -0.0747028862478777, -0.0745967741935485,
>>>> 
>>>> -0.0741784037558686, -0.0740740740740741, -0.0740740740740741,
>>>> 
>>>> -0.0740740740740741, -0.073828125, -0.0736698499317872,
>>>> -0.0735877862595421,
>>>> 
>>>> -0.0735824009102977, -0.0735632183908046, -0.0733944954128441,
>>>> 
>>>> -0.0728862973760932, -0.0728279386712096, -0.0726480203414457,
>>>> 
>>>> -0.0726329442282749, -0.072632190586868, -0.0725766664070006,
>>>> 
>>>> -0.0724137931034483, -0.0722664432341852, -0.0719257540603249,
>>>> 
>>>> -0.0717538461538461, -0.0716612377850163, -0.0715181932245923,
>>>> 
>>>> -0.0714285714285715, -0.0714285714285713, -0.0710646285867525,
>>>> 
>>>> -0.0708446866485014, -0.0708117443868739, -0.0708028321132845,
>>>> 
>>>> -0.0706436420722135, -0.0705325930495579, -0.0705128205128205,
>>>> 
>>>> -0.0705009276437847, -0.0704043019318861, -0.0702106318956871,
>>>> 
>>>> -0.0701663201663202, -0.0700661736084078, -0.0699999999999999,
>>>> 
>>>> -0.0695540857691487, -0.0692979983084297, -0.0691823899371069,
>>>> 
>>>> -0.0691244239631336, -0.0690335305719921, -0.0689655172413792,
>>>> 
>>>> -0.0688536409516944, -0.068450039339103, -0.0682332955832389,
>>>> 
>>>> -0.0682261208576998, -0.0681818181818182, -0.0679035250463822,
>>>> 
>>>> -0.0679012345679012, -0.0677966101694916, -0.0676384839650145,
>>>> 
>>>> -0.0675675675675676, -0.0675241157556271, -0.067463706233988,
>>>> 
>>>> -0.0674584323040379, -0.0668523676880222, -0.0666666666666667,
>>>> 
>>>> -0.066526455612132, -0.0664206642066421, -0.066321243523316,
>>>> 
>>>> -0.0662949194547709, -0.0662579580287669, -0.0662251655629139,
>>>> 
>>>> -0.0661764705882353, -0.0661478599221789, -0.0657894736842105,
>>>> 
>>>> -0.0657534246575342, -0.0654481924472518, -0.0652900974262034,
>>>> 
>>>> -0.0652225100070638, -0.0651126106388572, -0.0650887573964497,
>>>> 
>>>> -0.0650684931506849, -0.0650195058517555, -0.0649954627949184,
>>>> 
>>>> -0.0649081209247184, -0.064891846921797, -0.0648899188876013,
>>>> 
>>>> -0.0648148148148149, -0.0645962732919255, -0.0644599303135888,
>>>> 
>>>> -0.0644171779141105, -0.0643564356435644, -0.064327485380117,
>>>> 
>>>> -0.0642667310944672, -0.0641975308641976, -0.0641025641025641,
>>>> 
>>>> -0.0639197041732701, -0.0638436482084691, -0.0635245901639343,
>>>> 
>>>> -0.0634996041171813, -0.0632017594629008, -0.0631313131313131,
>>>> 
>>>> -0.0630434782608695, -0.0629405840886203, -0.0629155024568842,
>>>> 
>>>> -0.0628765060240964, -0.0628571428571429, -0.0625394819962098,
>>>> 
>>>> -0.062476757158795, -0.06203552416592, -0.0620347394540943,
>>>> -0.0619971604354,
>>>> 
>>>> -0.0619946091644204, -0.0619469026548672, -0.0619235836627141,
>>>> 
>>>> -0.0618131868131868, -0.0617667356797793, -0.0617312601531677,
>>>> 
>>>> -0.0616740088105726, -0.0614161849710983, -0.0613026819923372,
>>>> 
>>>> -0.0612244897959185, -0.0610859728506788, -0.0610526315789473,
>>>> 
>>>> -0.0610399397136398, -0.0610169491525424, -0.0609659540775929,
>>>> 
>>>> -0.0608695652173912, -0.0606060606060606, -0.0606060606060606,
>>>> 
>>>> -0.0604929051530994, -0.0604204204204204, -0.0603636363636364,
>>>> 
>>>> -0.0602698650674663, -0.0602115541090318, -0.0599352051835853,
>>>> 
>>>> -0.0599001663893511, -0.0596379126730565, -0.0594227504244482,
>>>> 
>>>> -0.0587275693311581, -0.0587002096436059, -0.0586319218241041,
>>>> 
>>>> -0.0586046511627907, -0.0584174190122145, -0.0584011488750599,
>>>> 
>>>> -0.0583707504810776, -0.0579299691040165, -0.0579268292682926,
>>>> 
>>>> -0.0579050097592712, -0.057608079558922, -0.0574712643678161,
>>>> 
>>>> -0.0572450805008944, -0.0570958904109589, -0.0568263045032167,
>>>> 
>>>> -0.0568181818181818, -0.0568181818181818, -0.0568031704095112,
>>>> 
>>>> -0.0566301923974486, -0.0566037735849057, -0.0566037735849057,
>>>> 
>>>> -0.0566037735849056, -0.0564433866031963, -0.0562770562770562,
>>>> 
>>>> -0.0561576354679803, -0.0560928433268858, -0.0559006211180124,
>>>> 
>>>> -0.0558213716108453, -0.055689240288759, -0.0554101893181468,
>>>> 
>>>> -0.0553961597881263, -0.0553633217993079, -0.0553571428571429,
>>>> 
>>>> -0.0553481577665964, -0.0553158101216163, -0.0553108174253549,
>>>> 
>>>> -0.0548340548340548, -0.0546601261387525, -0.054590570719603,
>>>> 
>>>> -0.0545001187366422, -0.0544511668107173, -0.0544274300932089,
>>>> 
>>>> -0.0542372881355932, -0.0542168674698794, -0.0540540540540541,
>>>> 
>>>> -0.053763440860215, -0.0537513997760358, -0.0536343468615424,
>>>> 
>>>> -0.0535714285714286, -0.0534725518114223, -0.0529294274300931,
>>>> 
>>>> -0.0528846153846155, -0.0528756957328386, -0.0526458340386634,
>>>> 
>>>> -0.0526315789473684, -0.0525606469002696, -0.0525451559934318,
>>>> 
>>>> -0.0525227460711332, -0.051948051948052, -0.051792828685259,
>>>> 
>>>> -0.0517241379310345, -0.0513784461152881, -0.0513559322033898,
>>>> 
>>>> -0.0512610211195407, -0.0512437810945274, -0.051150895140665,
>>>> 
>>>> -0.0510695486616643, -0.0507726269315673, -0.0507377685736475,
>>>> 
>>>> -0.0506575742815391, -0.0506024096385543, -0.0505494505494506,
>>>> 
>>>> -0.0503194888178913, -0.0501567398119122, -0.05, -0.0499001996007984,
>>>> 
>>>> -0.0498214285714285, -0.0497737556561087, -0.0497470489038785,
>>>> 
>>>> -0.0494845360824741, -0.0493827160493827, -0.0492157923201731,
>>>> 
>>>> -0.0491192897035657, -0.0489642184557439, -0.0488200324265898,
>>>> 
>>>> -0.0488031366075114, -0.0485151426051161, -0.0483319076133448,
>>>> 
>>>> -0.0481220657276996, -0.0480897675661234, -0.0480599647266314,
>>>> 
>>>> -0.0480038022813688, -0.0479900280461202, -0.0479548660084627,
>>>> 
>>>> -0.0478449164776243, -0.0475638051044084, -0.0475342709631477,
>>>> 
>>>> -0.0473213579172271, -0.0472997462848857, -0.0472050636772667,
>>>> 
>>>> -0.046890780551147, -0.0467625899280576, -0.046753107010276,
>>>> 
>>>> -0.0466592011944754, -0.0465772759350741, -0.0465753424657535,
>>>> 
>>>> -0.0464333781965007, -0.0463888365076373, -0.0463215258855587,
>>>> 
>>>> -0.046281851274051, -0.0459946060208471, -0.0458715596330275,
>>>> 
>>>> -0.0458563535911603, -0.0457367549668873, -0.0456500165398611,
>>>> 
>>>> -0.0454373701114679, -0.0454265548766046, -0.0454183266932271,
>>>> 
>>>> -0.045213508233324, -0.045182571340902, -0.0451018428709989,
>>>> 
>>>> -0.0451018428709989, -0.044955044955045, -0.0444136016655101,
>>>> 
>>>> -0.0443722943722945, -0.0442996742671011, -0.0442477876106195,
>>>> 
>>>> -0.0442477876106195, -0.0441176470588236, -0.043982895540623,
>>>> 
>>>> -0.0438184663536776, -0.0436363636363636, -0.043261231281198,
>>>> 
>>>> -0.0432218514782339, -0.0431654676258993, -0.0424336600525938,
>>>> 
>>>> -0.0423429781227946, -0.0423387096774193, -0.0420711974110032,
>>>> 
>>>> -0.0420083118050095, -0.0420032310177707, -0.0417256011315418,
>>>> 
>>>> -0.0416842105263158, -0.0416141235813367, -0.0414593698175788,
>>>> 
>>>> -0.0413793103448276, -0.041320942582144, -0.0407865986890023,
>>>> 
>>>> -0.0406158747013539, -0.0405803571428572, -0.0405643738977073,
>>>> 
>>>> -0.040422053796998, -0.040268456375839, -0.0400500625782228,
>>>> 
>>>> -0.0400449101796407, -0.04, -0.0399718147460123, -0.0399137001078749,
>>>> 
>>>> -0.0399044464954666, -0.0398863290368415, -0.0398230088495575,
>>>> 
>>>> -0.0394736842105263, -0.0393401015228426, -0.0392720306513411,
>>>> 
>>>> -0.0392156862745098, -0.0388349514563106, -0.0386904761904763,
>>>> 
>>>> -0.0384615384615385, -0.0382457345700217, -0.0382293762575454,
>>>> 
>>>> -0.0381840048105834, -0.0380030474141795, -0.0379746835443038,
>>>> 
>>>> -0.0379247280777747, -0.0376432078559739, -0.0375494071146245,
>>>> 
>>>> -0.0375490837696336, -0.0373345788572318, -0.0372940156114484,
>>>> 
>>>> -0.0371871275327772, -0.037037037037037, -0.0368133174791915,
>>>> 
>>>> -0.0368098159509203, -0.0367231638418078, -0.0361445783132531,
>>>> 
>>>> -0.0360915492957746, -0.0357142857142857, -0.0356663184599313,
>>>> 
>>>> -0.0356413696552528, -0.035513103110458, -0.0353194103194103,
>>>> 
>>>> -0.0352112676056338, -0.0350119904076739, -0.0349794238683129,
>>>> 
>>>> -0.0349373764007909, -0.0349091600875106, -0.0347826086956522,
>>>> 
>>>> -0.0347728547392037, -0.0347682119205298, -0.0346083788706739,
>>>> 
>>>> -0.0344706296166022, -0.0344421548425081, -0.0341176470588236,
>>>> 
>>>> -0.0338983050847458, -0.033457249070632, -0.0334208223972004,
>>>> 
>>>> -0.0333333333333334, -0.0333333333333333, -0.0329670329670331,
>>>> 
>>>> -0.0329144225014961, -0.0326797385620915, -0.0323033707865168,
>>>> 
>>>> -0.0322118826055834, -0.0321750321750322, -0.0320890635232481,
>>>> 
>>>> -0.0318302387267905, -0.0316666666666666, -0.0315586914688903,
>>>> 
>>>> -0.0312606184165817, -0.030881017257039, -0.0308764940239045,
>>>> 
>>>> -0.0305419952434597, -0.030406198638178, -0.0299651567944252,
>>>> 
>>>> -0.029945999018164, -0.0298786181139121, -0.0295741147960329,
>>>> 
>>>> -0.0293917033546227, -0.029171528588098, -0.0291327913279132,
>>>> 
>>>> -0.0290497291974397, -0.0288721376760064, -0.0287704170466792,
>>>> 
>>>> -0.0286236297198539, -0.0285714285714286, -0.0277575837684224,
>>>> 
>>>> -0.0277085471338513, -0.0275897304892068, -0.0275526742301458,
>>>> 
>>>> -0.027027027027027, -0.0270270270270269, -0.0269087523277468,
>>>> 
>>>> -0.0268918695148203, -0.02676704307821, -0.026454253142356,
>>>> -0.0263157894736842,
>>>> 
>>>> -0.0263157894736842, -0.0261660978384529, -0.025974025974026,
>>>> 
>>>> -0.0257503107796129, -0.0255319148936171, -0.0254237288135594,
>>>> 
>>>> -0.025297619047619, -0.0249174422095467, -0.0248888888888889,
>>>> 
>>>> -0.024767619719967, -0.0246053853296194, -0.0245269796776454,
>>>> 
>>>> -0.024390243902439, -0.0241935483870968, -0.0238907849829351,
>>>> 
>>>> -0.0238153295944078, -0.0234413496961306, -0.0232558139534884,
>>>> 
>>>> -0.0232558139534883, -0.0230392156862745, -0.0230360307147077,
>>>> 
>>>> -0.0228847365106026, -0.0225806451612903, -0.0224519940915805,
>>>> 
>>>> -0.0214786344110332, -0.0212360867018161, -0.0205245153933865,
>>>> 
>>>> -0.0204170602339606, -0.0200986321764215, -0.0200729927007299,
>>>> 
>>>> -0.0199828473413379, -0.0194174757281553, -0.0193536931818183,
>>>> 
>>>> -0.0192885771543086, -0.019222732971166, -0.0191414840759143,
>>>> 
>>>> -0.0189573459715641, -0.0188902007083826, -0.0186903321231681,
>>>> 
>>>> -0.0184456468273487, -0.0183066361556064, -0.0182166826462128,
>>>> 
>>>> -0.0181149908112366, -0.0179372197309418, -0.0179172441100772,
>>>> 
>>>> -0.0178571428571429, -0.0174672489082969, -0.0174216027874564,
>>>> 
>>>> -0.0171428571428572, -0.017017253604349, -0.0169252468265163,
>>>> 
>>>> -0.0165094339622642, -0.0158730158730158, -0.0158415841584159,
>>>> 
>>>> -0.0157247037374659, -0.0157089706490286, -0.0156250000000001,
>>>> 
>>>> -0.0153846153846153, -0.0151668351870576, -0.0151589242053789,
>>>> 
>>>> -0.0150489089541008, -0.0150262202501008, -0.0150081124932396,
>>>> 
>>>> -0.0148196281468128, -0.0144251166737377, -0.0142857142857142,
>>>> 
>>>> -0.0140638734251392, -0.0136986301369863, -0.0133333333333333,
>>>> 
>>>> -0.0129464285714286, -0.0129449838187702, -0.0127813811522321,
>>>> 
>>>> -0.0126030053320408, -0.0125721665147373, -0.0125, -0.0122160435399906,
>>>> 
>>>> -0.0122116689280869, -0.0121019108280255, -0.0118747750989563,
>>>> 
>>>> -0.0118277953189996, -0.0117107942973524, -0.0115172759138707,
>>>> 
>>>> -0.0114087997381585, -0.0113924050632912, -0.0111524163568772,
>>>> 
>>>> -0.0111248454882571, -0.0111111111111111, -0.0102570933795125,
>>>> 
>>>> -0.0102040816326532, -0.00963463463463469, -0.00958657878969439,
>>>> 
>>>> -0.00941028858218319, -0.00874453466583389, -0.00779588944011335,
>>>> 
>>>> -0.00713620850139625, -0.00710720027075056, -0.00709219858156026,
>>>> 
>>>> -0.00624999999999998, -0.00551977920883173, -0.00521499557217353,
>>>> 
>>>> -0.00453998797354176, -0.00444444444444444, -0.00166389351081533,
>>>> 
>>>> -0.00118483412322285, -0.00100704934541787, -0.000937500000000036,
>>>> 
>>>> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
>>>> 
>>>> 0.000218031178458569, 0.000796495420151402, 0.00167130919220062,
>>>> 
>>>> 0.00190476190476193, 0.00350058343057173, 0.00363914958820145,
>>>> 
>>>> 0.00432900432900424, 0.00456037942356804, 0.00477446915441642,
>>>> 
>>>> 0.0050825509873745, 0.00525691029336935, 0.00603318250377083,
>>>> 
>>>> 0.00652173913043472, 0.00733192494097176, 0.00747663551401869,
>>>> 
>>>> 0.00760456273764256, 0.00812529439472442, 0.00991231414410967,
>>>> 
>>>> 0.0101685066821615, 0.0106182565507793, 0.0109070034443169,
>>>> 0.0115183246073298,
>>>> 
>>>> 0.0115442244823827, 0.0127659574468085, 0.0128076846107665,
>>>> 0.0135135135135135,
>>>> 
>>>> 0.0140845070422535, 0.0150730098916627, 0.0159362549800796,
>>>> 0.0172413793103449,
>>>> 
>>>> 0.0176899063475547, 0.0186954715413378, 0.0187765706188003,
>>>> 0.0195757403189066,
>>>> 
>>>> 0.019607843137255, 0.0199999999999999, 0.0210526315789473,
>>>> 0.0221979621542939,
>>>> 
>>>> 0.0239410681399632, 0.0239999999999999, 0.025149051490515,
>>>> 0.0260869565217392,
>>>> 
>>>> 0.0262475696694749, 0.028180542563143, 0.0285714285714286,
>>>> 0.0303030303030302,
>>>> 
>>>> 0.0315904139433552, 0.0341864716636198, 0.0375782881002089,
>>>> 0.038479809976247,
>>>> 
>>>> 0.0387596899224806, 0.0416666666666667, 0.0428100987925357,
>>>> 0.0428134556574923,
>>>> 
>>>> 0.0437201907790144, 0.0451127819548872, 0.0460251046025105,
>>>> 0.0487779511180447,
>>>> 
>>>> 0.048975188781014, 0.0529872938632063, 0.0562390158172233,
>>>> 0.0589335827876521,
>>>> 
>>>> 0.0617551462621885, 0.0628115653040877, 0.0671812464265294,
>>>> 0.0721784776902887,
>>>> 
>>>> 0.0736842105263157, 0.0833333333333334, 0.083862394802894,
>>>> 0.0970464135021097,
>>>> 
>>>> 0.0971168437025795, 0.102272727272727, 0.111111111111111,
>>>> 0.117117117117117,
>>>> 
>>>> 0.123532699832309, 0.141304347826087, 0.179487179487179,
>>>> 0.191268191268191,
>>>> 
>>>> 0.205128205128205, 0.219020172910663, 0.271590909090909, 
>>>> 0.333333333333333
>>>> 
>>>> )
>>>> 
>>>> 
>>>> Now I want to estimate empirical PDF for interval of (-1, 1) including
>>>> all points of Dat
>>>> 
>>>> I have looked into the density() function, however it appears that,
>>>> empirical density is estimated for equally distant points, which not
>>>> necessarily contains actual supplied points (in my case, Dat)
>>>> 
>>>> Is there any option to achieve the same?
>>>> 
>>>> Thanks for your pointer.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From drjimlemon at gmail.com  Mon Mar 12 04:23:01 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Mon, 12 Mar 2018 14:23:01 +1100
Subject: [R] subsetting comparison problem
In-Reply-To: <03323972-4B82-448B-B207-CA08F91F74AD@comcast.net>
References: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>
 <03323972-4B82-448B-B207-CA08F91F74AD@comcast.net>
Message-ID: <CA+8X3fV5Gdewwx3YK=336F5V3UMXQjOuWaOtMKuQATZhU0a+Fg@mail.gmail.com>

Hi Neha,
This might help:

R<-read.table(text="C1 C2 C3 C4
R1 0 1 0 1
R2 1 0 1 1
R3 1 0 0 0",
header=TRUE)
U<-read.table(text="C1 C2 C3 C4
U1 1 1 0 1
U2 1 1 1 1",
header=TRUE)
# these are matrices - I think this will work for dataframes as well
for(ui in 1:dim(U)[1]) {
 for(ri in 1:dim(R)[1]) {
  if(sum(U[ui,]&R[ri,])==sum(R[ri,]))
   cat("R$",rownames(R)[ri]," subset of ","U$",rownames(U)[ui],"\n",sep="")
 }
}

Jim

On Mon, Mar 12, 2018 at 1:59 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Mar 11, 2018, at 3:32 PM, Neha Aggarwal <aggarwalneha2000 at gmail.com> wrote:
>>
>> Hello All,
>> I am facing a unique problem and am unable to find any help in R help pages
>> or online. I will appreciate your help for the following problem:
>> I have 2 data-frames, samples below and there is an expected output
>>
>> R Dataframe1:
>>            C1              C2   C3         C4...... CN
>> R1       0                  1       0           1
>> R2        1                  0      1            1
>> R3        1                  0       0             0
>> .
>> .
>> .
>> RN
>>
>> U Dataframe2 :
>>             C1         C2        C3         C4...... CN
>> U1         1           1            0            1
>> U2         1           1             1            1
>>
>>
>> Expected Output:
>> U1 satisfies R1, R3
>> U2 satisfies R1, R2, R3
>>
>
> I don't think you have communicated what sort of meaning is attached to the word "satisfies".
>
> Here's a double loop that reports membership of the column names of each row of U (Dataframe2) in each row of R (Dataframe1):
>
>  apply( Dataframe2, 1, function(x){ z <- which(x==1);
>                                    z2 <- names(x)[z];
>                         zlist=apply(Dataframe1, 1, function(y){ z3 <- which(y==1);
>                                                                 z4 <- names(y)[z3];
>                                                                 z4[ which(z4 %in% z2) ]});
>                         zlist})
> $U1
> $U1$R1
> [1] "C2" "C4"
>
> $U1$R2
> [1] "C1" "C4"
>
> $U1$R3
> [1] "C1"
>
>
> $U2
> $U2$R1
> [1] "C2" "C4"
>
> $U2$R2
> [1] "C1" "C3" "C4"
>
> $U2$R3
> [1] "C1"
>
> --
> David.
>
>
>> So this is a comparison of dataframes problem, with a subset dimension.
>> There are 2 dataframe R and U. column names are same. There are certain
>> columns belonging to each row in dataframe 1, denoted as 1s, while there
>> are certain cols to each U denoted as 1s in each URow in dataframe2.
>>
>> I have to find relationships between Rs and Us. So i start with each U row
>> in U dataframe (lets say U1 row) and try to find all the rows in R
>> dataframe, which are subset of U1 row.
>>
>> I cant find a way to compare rows to see if one is subset of
>> another....what can I try, any pointers/ packages will be great help.
>> Please help.
>>
>> Thanks
>> Neha
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From aggarwalneha2000 at gmail.com  Mon Mar 12 01:34:58 2018
From: aggarwalneha2000 at gmail.com (Neha Aggarwal)
Date: Sun, 11 Mar 2018 20:34:58 -0400
Subject: [R] Fwd: subsetting comparison problem
In-Reply-To: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>
References: <CAMe08vt=-APcdp7hqsMFw4u_yWmV50yOBwHRb2DH1DTOqb=avA@mail.gmail.com>
Message-ID: <CAMe08vsK7peuia7SOK2GM1LzLC6r-qK4GTQDor6+yZNcHGvjSA@mail.gmail.com>

Hello All,
I am facing a unique problem and am unable to find any help in R help pages
or online. I will appreciate your help for the following problem:
I have 2 data-frames, samples below and there is an expected output

R Dataframe1:
            C1              C2   C3         C4...... CN
R1       0                  1       0           1
R2        1                  0      1            1
R3        1                  0       0             0
.
.
.
RN

U Dataframe2 :
             C1         C2        C3         C4...... CN
U1         1           1            0            1
U2         1           1             1            1


Expected Output:
U1 satisfies R1, R3
U2 satisfies R1, R2, R3

So this is a comparison of dataframes problem, with a subset dimension.
There are 2 dataframe R and U. column names are same. There are certain
columns belonging to each row in dataframe 1, denoted as 1s, while there
are certain cols to each U denoted as 1s in each URow in dataframe2.

I have to find relationships between Rs and Us. So i start with each U row
in U dataframe (lets say U1 row) and try to find all the rows in R
dataframe, which are subset of U1 row.

I cant find a way to compare rows to see if one is subset of
another....what can I try, any pointers/ packages will be great help.
Please help.

Thanks
Neha

	[[alternative HTML version deleted]]


From aggarwalneha2000 at gmail.com  Mon Mar 12 01:38:29 2018
From: aggarwalneha2000 at gmail.com (Neha Aggarwal)
Date: Sun, 11 Mar 2018 20:38:29 -0400
Subject: [R] Subsetting comparison problem
Message-ID: <CAMe08vt3=u2f4V_Ea+RVW+2YBsrT4EbqkOjFW2-Gg3JtnTH6UQ@mail.gmail.com>

Hello All,
I am facing a unique problem and am unable to find any help in R help pages
or online. I will appreciate your help for the following problem:
I have 2 data-frames, samples below and there is an expected output

R Dataframe1:
            C1              C2   C3         C4...... CN
R1       0                  1       0           1
R2        1                  0      1            1
R3        1                  0       0             0
.
.
.
RN

U Dataframe2 :
             C1         C2        C3         C4...... CN
U1         1           1            0            1
U2         1           1             1            1


Expected Output:
U1 satisfies R1, R3
U2 satisfies R1, R2, R3

So this is a comparison of dataframes problem, with a subset dimension.
There are 2 dataframe R and U. column names are same. There are certain
columns belonging to each row in dataframe 1, denoted as 1s, while there
are certain cols to each U denoted as 1s in each URow in dataframe2.

I have to find relationships between Rs and Us. So i start with each U row
in U dataframe (lets say U1 row) and try to find all the rows in R
dataframe, which are subset of U1 row.

I cant find a way to compare rows to see if one is subset of
another....what can I try, any pointers/ packages will be great help.
Please help.

Thanks
Neha

	[[alternative HTML version deleted]]


From aggarwalneha2000 at gmail.com  Mon Mar 12 02:03:59 2018
From: aggarwalneha2000 at gmail.com (Neha Aggarwal)
Date: Sun, 11 Mar 2018 21:03:59 -0400
Subject: [R] Dataframe Subsetting comparison
Message-ID: <CAMe08vtE=hNw-Hau+ksQv8DBkdW_f5gthktu0f+nm4uPG8npoQ@mail.gmail.com>

Hello All,
I am facing a unique issue and am unable to find any help in R help pages
or online. I will appreciate your help for the following problem:
I have 2 data-frames, samples below and there is an expected output

R Dataframe1:
            C1              C2   C3         C4...... CN
R1       0                  1       0           1
R2        1                  0      1            1
R3        1                  0       0             0
.
.
.
RN

U Dataframe2 :
             C1         C2        C3         C4...... CN
U1         1           1            0            1
U2         1           1             1            1


Expected Output:
U1 satisfies R1, R3
U2 satisfies R1, R2, R3

So this is a comparison of dataframes problem, with a subset dimension.
There are 2 dataframe R and U. column names are same. There are certain
columns belonging to each row in dataframe 1, denoted as 1s, while there
are certain cols to each U denoted as 1s in each URow in dataframe2.

I have to find relationships between Rs and Us. So i start with each U row
in U dataframe (lets say U1 row) and try to find all the rows in R
dataframe, which are subset of U1 row.

I cant find a way to compare rows to see if one is subset of
another....what can I try, any pointers/ packages will be great help.
Please help.

Thanks
Neha

	[[alternative HTML version deleted]]


From sebastien.bihorel at cognigencorp.com  Mon Mar 12 05:15:42 2018
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Mon, 12 Mar 2018 00:15:42 -0400 (EDT)
Subject: [R] Equivalent of gtools::mixedsort in R base
Message-ID: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>

Hi,

Searching for functions that would order strings that mix characters and numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I found the mixedsort and mixedorder from the gtools package.

Problems: 
1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call like the order function does
2- gtools has not been updated in 2.5 years

Are you aware of an equivalent of this function in base R or a another contributed package (with correction of problem #1)?

Thanks


From bgunter.4567 at gmail.com  Mon Mar 12 05:57:00 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 11 Mar 2018 21:57:00 -0700
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbSqrE4Qktdku+ph9axscfJim+63R7y_9hqsHn4-0Dw6Vw@mail.gmail.com>

???

> y <- sort( c("a1","a2","a10","a12","a100"))
> y
[1] "a1"   "a10"  "a100" "a12"  "a2"
> mixedsort(y)
[1] "a1"   "a2"   "a10"  "a12"  "a100"

**Please read the docs!** They say that mixedsort() and mixedorder()  both
take a **single vector**  as the argument to be sorted or ordered and, as
the above indicates, they perform exactly as advertised. **Unlike
order()**. So of course your do.call() construction fails.

So presumably you have a data frame with multiple columns of mixed alpha
and numerics?  (A reproducible example would be most helpful here.)

If this is the case, one **possibly dumb** approach (you have been warned!)
would be to turn each column into an ordered factor and then call order()
on the data frame of ordered factors via do.call() as above. i.e.

> y1 <- ordered(y,lev = mixedsort(y))
> y1
[1] a1   a10  a100 a12  a2
Levels: a1 < a2 < a10 < a12 < a100
> order(y1)
[1] 1 5 2 4 3

(this is just for 1 vector to show how the idea would work).

Of course, if this is **not** what you want, you'll need to clarify,
hopefully with a reprex. Or hope that someone else has better insight than
I.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Mar 11, 2018 at 9:15 PM, Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

> Hi,
>
> Searching for functions that would order strings that mix characters and
> numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I
> found the mixedsort and mixedorder from the gtools package.
>
> Problems:
> 1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call
> like the order function does
> 2- gtools has not been updated in 2.5 years
>
> Are you aware of an equivalent of this function in base R or a another
> contributed package (with correction of problem #1)?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Mar 12 07:11:03 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 11 Mar 2018 23:11:03 -0700 (PDT)
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <CAGxFJbSqrE4Qktdku+ph9axscfJim+63R7y_9hqsHn4-0Dw6Vw@mail.gmail.com>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbSqrE4Qktdku+ph9axscfJim+63R7y_9hqsHn4-0Dw6Vw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1803112236210.4198@pedal.dcn.davis.ca.us>

x <- c( "a1", "a10", "a2" )
y <- c( "b10", "b2", "a12", "ca1" )

DF <- expand.grid( x = x, y = y )
# randomize
set.seed( 42 )
DF <- DF[ sample( nrow( DF ) ), ]

# missing from gtools
mixedrank <- function( x ) {
   seq.int( length( x ) )[ gtools::mixedorder(x) ]
}

o <- do.call( order, lapply( DF, mixedrank ) )
DF[ o, ]

# or, as Bert suggests:

myrank <- function( v ) {
   vu <- unique(v)
   vl <- regmatches( vu,regexec("^([A-Za-z]+)(\\d+)$",vu))
   alph <- sapply( vl, function(s) s[2] )
   digt <- as.integer( sapply( vl, function(s) s[3] ) )
   o <- order( alph, digt )
   vo <- ordered( v, levels=vu[ o ] )
}

o2 <- do.call( order, lapply( DF, myrank ) )
DF[ o2, ]

?order
?ordered
?rank

On Sun, 11 Mar 2018, Bert Gunter wrote:

> ???
>
>> y <- sort( c("a1","a2","a10","a12","a100"))
>> y
> [1] "a1"   "a10"  "a100" "a12"  "a2"
>> mixedsort(y)
> [1] "a1"   "a2"   "a10"  "a12"  "a100"
>
> **Please read the docs!** They say that mixedsort() and mixedorder()  both
> take a **single vector**  as the argument to be sorted or ordered and, as
> the above indicates, they perform exactly as advertised. **Unlike
> order()**. So of course your do.call() construction fails.
>
> So presumably you have a data frame with multiple columns of mixed alpha
> and numerics?  (A reproducible example would be most helpful here.)
>
> If this is the case, one **possibly dumb** approach (you have been warned!)
> would be to turn each column into an ordered factor and then call order()
> on the data frame of ordered factors via do.call() as above. i.e.
>
>> y1 <- ordered(y,lev = mixedsort(y))
>> y1
> [1] a1   a10  a100 a12  a2
> Levels: a1 < a2 < a10 < a12 < a100
>> order(y1)
> [1] 1 5 2 4 3
>
> (this is just for 1 vector to show how the idea would work).
>
> Of course, if this is **not** what you want, you'll need to clarify,
> hopefully with a reprex. Or hope that someone else has better insight than
> I.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Mar 11, 2018 at 9:15 PM, Sebastien Bihorel <
> sebastien.bihorel at cognigencorp.com> wrote:
>
>> Hi,
>>
>> Searching for functions that would order strings that mix characters and
>> numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I
>> found the mixedsort and mixedorder from the gtools package.
>>
>> Problems:
>> 1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call
>> like the order function does
>> 2- gtools has not been updated in 2.5 years
>>
>> Are you aware of an equivalent of this function in base R or a another
>> contributed package (with correction of problem #1)?
>>
>> Thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From emekadonn at gmail.com  Mon Mar 12 12:18:22 2018
From: emekadonn at gmail.com (Emeka Don)
Date: Mon, 12 Mar 2018 12:18:22 +0100
Subject: [R] Help on Aggregation
Message-ID: <CAJ3tmCrduGOop0fMYOxUFN=kODQBU-2ZPFx45wxMUJEP56mt6g@mail.gmail.com>

Dear All,
1.I have been trying to aggregate my data but I have not been getting it
correctly. In the data I want to convert hourly data into daily averages.
Here is a sample of the data:
Neph_no Date Time Temp_C   Pressure_kPa RH
9   2014/03/28  10:00:00 38.4 95.9 29.7
9   2014/03/28  11:00:00 37.8 95.8 29.2
9   2014/03/28  12:00:00 36.7 95.8 35.1
9   2014/03/28  13:00:00 35.4 95.8 38.9
9   2014/03/28  14:00:00 34.1 95.8 44
9   2014/03/28  15:00:00 32.7 95.9 52.9
9   2014/03/28  16:00:00 31.8 96 55.1
9   2014/03/28  17:00:00 31.2 96 57.8
9   2014/03/28  18:00:00 30.6 96.1 62.1
9   2014/03/28  19:00:00 29.8 96.1 68.1
9   2014/03/28  20:00:00 29.1 96.1 69.5
9   2014/03/28  21:00:00 28.6 96 68.3
9   2014/03/28  22:00:00 28 96 71.9
9   2014/03/28  23:00:00 27.4 95.9 76.4
9   2014/03/29  00:00:00 27 96 80.6
9   2014/03/29  01:00:00 27.1 96 80.4
9   2014/03/29  02:00:00 27 96.1 80.5
9   2014/03/29  03:00:00 27.8 96.1 78.1
9   2014/03/29  04:00:00 30.4 96.2 66.8
9   2014/03/29  05:00:00 33.7 96.3 54
9   2014/03/29  06:00:00 36.3 96.3 45
9   2014/03/29  07:00:00 37.7 96.3 38.8
9   2014/03/29  08:00:00 38.7 96.3 34.7
9   2014/03/29  09:00:00 38.9 96.1 32.6
9   2014/03/29  10:00:00 39.4 96 30.2
9   2014/03/29  11:00:00 38.9 95.9 31.5
9   2014/03/29  12:00:00 38.2 95.8 33.8
9   2014/03/29  13:00:00 37.4 95.8 35.4
9   2014/03/29  14:00:00 35.8 95.9 39.5
9   2014/03/29  15:00:00 33.9 96 46.9
9   2014/03/29  16:00:00 31.4 96.1 59.8
9   2014/03/29  17:00:00 29.4 96.3 72.9
9   2014/03/29  18:00:00 29 96.3 69.6
9   2014/03/29  19:00:00 26.5 96.2 81.7
9   2014/03/29  20:00:00 27 96.1 82.9
9   2014/03/29  21:00:00 27.5 96.1 81.7
9   2014/03/29  22:00:00 27.4 96 82.6
9   2014/03/29  23:00:00 27.3 96 83.1
9   2014/03/30  00:00:00 27.1 96 84.5
9   2014/03/30  01:00:00 27.6 96.1 81.8
9   2014/03/30  02:00:00 27.8 96.1 81

2. I have some data of about 6100 rows and 6 columns, but anytime i read it
into R, it removes the header and a large chunk of the data.( i:e it will
import from row 3550-6099). This is the code i used for it
"met_data=read.csv(file.choose(),header=TRUE)", so, how do I read the
entire data into R without missing some?
Thank you.

-- 
Onyeuwaoma Nnaemeka Dom

	[[alternative HTML version deleted]]


From petr.pikal at precheza.cz  Mon Mar 12 15:19:40 2018
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 12 Mar 2018 14:19:40 +0000
Subject: [R] Help on Aggregation
In-Reply-To: <CAJ3tmCrduGOop0fMYOxUFN=kODQBU-2ZPFx45wxMUJEP56mt6g@mail.gmail.com>
References: <CAJ3tmCrduGOop0fMYOxUFN=kODQBU-2ZPFx45wxMUJEP56mt6g@mail.gmail.com>
Message-ID: <54908013db584de4861bb55dd798032f@SRVEXCHCM1301.precheza.cz>

Hi

The first question is simple. You should use aggregate and cut but first you need to transfer your data to date/time format by strptime.

test<-read.table("clipboard", header=T)
test$cas<-strptime(paste(test$Date, test$Time), format="%Y/%m/%d %H:%M:%S")

Below is the data.

aggregate(test[,4:6], list(cut(test$cas, "days")), mean, na.rm=T)
     Group.1   Temp_C Pressure_kPa       RH
1 2014-03-28 32.25714     95.94286 54.21429
2 2014-03-29 32.23750     96.09167 59.29583
3 2014-03-30 27.35000     96.05000 83.15000

The second one is difficult if impossible to answer.

read.csv(file.choose(),header=TRUE)
This seems to be OK. So my guess is that the original file is not csv or that it has some hidden characters elsewhere.

Cheers
Petr

dput(test)
structure(list(Neph_no = c(9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L,
9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L, 9L
), Date = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 3L, 3L, 3L), .Label = c("2014/03/28",
"2014/03/29", "2014/03/30"), class = "factor"), Time = structure(c(11L,
12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L,
1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L,
15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 24L, 1L, 2L, 3L), .Label = c("00:00:00",
"01:00:00", "02:00:00", "03:00:00", "04:00:00", "05:00:00", "06:00:00",
"07:00:00", "08:00:00", "09:00:00", "10:00:00", "11:00:00", "12:00:00",
"13:00:00", "14:00:00", "15:00:00", "16:00:00", "17:00:00", "18:00:00",
"19:00:00", "20:00:00", "21:00:00", "22:00:00", "23:00:00"), class = "factor"),
    Temp_C = c(38.4, 37.8, 36.7, 35.4, 34.1, 32.7, 31.8, 31.2,
    30.6, 29.8, 29.1, 28.6, 28, 27.4, 27, 27.1, 27, 27.8, 30.4,
    33.7, 36.3, 37.7, 38.7, 38.9, 39.4, 38.9, 38.2, 37.4, 35.8,
    33.9, 31.4, 29.4, 29, 26.5, 27, 27.5, 27.4, 27.3, 27.1, 27.6,
    27.8), Pressure_kPa = c(95.9, 95.8, 95.8, 95.8, 95.8, 95.9,
    96, 96, 96.1, 96.1, 96.1, 96, 96, 95.9, 96, 96, 96.1, 96.1,
    96.2, 96.3, 96.3, 96.3, 96.3, 96.1, 96, 95.9, 95.8, 95.8,
    95.9, 96, 96.1, 96.3, 96.3, 96.2, 96.1, 96.1, 96, 96, 96,
    96.1, 96.1), RH = c(29.7, 29.2, 35.1, 38.9, 44, 52.9, 55.1,
    57.8, 62.1, 68.1, 69.5, 68.3, 71.9, 76.4, 80.6, 80.4, 80.5,
    78.1, 66.8, 54, 45, 38.8, 34.7, 32.6, 30.2, 31.5, 33.8, 35.4,
    39.5, 46.9, 59.8, 72.9, 69.6, 81.7, 82.9, 81.7, 82.6, 83.1,
    84.5, 81.8, 81), cas = structure(list(sec = c(0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0), min = c(0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L), hour = c(10L, 11L,
    12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L,
    0L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L,
    14L, 15L, 16L, 17L, 18L, 19L, 20L, 21L, 22L, 23L, 0L, 1L,
    2L), mday = c(28L, 28L, 28L, 28L, 28L, 28L, 28L, 28L, 28L,
    28L, 28L, 28L, 28L, 28L, 29L, 29L, 29L, 29L, 29L, 29L, 29L,
    29L, 29L, 29L, 29L, 29L, 29L, 29L, 29L, 29L, 29L, 29L, 29L,
    29L, 29L, 29L, 29L, 29L, 30L, 30L, 30L), mon = c(2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
    2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L), year = c(114L, 114L,
    114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L,
    114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L,
    114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L,
    114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L, 114L), wday = c(5L,
    5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L,
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L,
    6L, 6L, 6L, 6L, 6L, 6L, 6L, 0L, 0L, 0L), yday = c(86L, 86L,
    86L, 86L, 86L, 86L, 86L, 86L, 86L, 86L, 86L, 86L, 86L, 86L,
    87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
    87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L, 87L,
    88L, 88L, 88L), isdst = c(0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L, 0L,
    0L, 0L, -1L), zone = c("CET", "CET", "CET", "CET", "CET",
    "CET", "CET", "CET", "CET", "CET", "CET", "CET", "CET", "CET",
    "CET", "CET", "CET", "CET", "CET", "CET", "CET", "CET", "CET",
    "CET", "CET", "CET", "CET", "CET", "CET", "CET", "CET", "CET",
    "CET", "CET", "CET", "CET", "CET", "CET", "CET", "CET", ""
    ), gmtoff = c(NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_, NA_integer_, NA_integer_, NA_integer_,
    NA_integer_, NA_integer_)), class = c("POSIXlt", "POSIXt"
    ))), row.names = c(NA, -41L), class = "data.frame")
>


> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Emeka Don
> Sent: Monday, March 12, 2018 12:18 PM
> To: r-help at r-project.org
> Subject: [R] Help on Aggregation
>
> Dear All,
> 1.I have been trying to aggregate my data but I have not been getting it
> correctly. In the data I want to convert hourly data into daily averages.
> Here is a sample of the data:
> Neph_no Date Time Temp_C   Pressure_kPa RH
> 9   2014/03/28  10:00:00 38.4 95.9 29.7
> 9   2014/03/28  11:00:00 37.8 95.8 29.2
> 9   2014/03/28  12:00:00 36.7 95.8 35.1
> 9   2014/03/28  13:00:00 35.4 95.8 38.9
> 9   2014/03/28  14:00:00 34.1 95.8 44
> 9   2014/03/28  15:00:00 32.7 95.9 52.9
> 9   2014/03/28  16:00:00 31.8 96 55.1
> 9   2014/03/28  17:00:00 31.2 96 57.8
> 9   2014/03/28  18:00:00 30.6 96.1 62.1
> 9   2014/03/28  19:00:00 29.8 96.1 68.1
> 9   2014/03/28  20:00:00 29.1 96.1 69.5
> 9   2014/03/28  21:00:00 28.6 96 68.3
> 9   2014/03/28  22:00:00 28 96 71.9
> 9   2014/03/28  23:00:00 27.4 95.9 76.4
> 9   2014/03/29  00:00:00 27 96 80.6
> 9   2014/03/29  01:00:00 27.1 96 80.4
> 9   2014/03/29  02:00:00 27 96.1 80.5
> 9   2014/03/29  03:00:00 27.8 96.1 78.1
> 9   2014/03/29  04:00:00 30.4 96.2 66.8
> 9   2014/03/29  05:00:00 33.7 96.3 54
> 9   2014/03/29  06:00:00 36.3 96.3 45
> 9   2014/03/29  07:00:00 37.7 96.3 38.8
> 9   2014/03/29  08:00:00 38.7 96.3 34.7
> 9   2014/03/29  09:00:00 38.9 96.1 32.6
> 9   2014/03/29  10:00:00 39.4 96 30.2
> 9   2014/03/29  11:00:00 38.9 95.9 31.5
> 9   2014/03/29  12:00:00 38.2 95.8 33.8
> 9   2014/03/29  13:00:00 37.4 95.8 35.4
> 9   2014/03/29  14:00:00 35.8 95.9 39.5
> 9   2014/03/29  15:00:00 33.9 96 46.9
> 9   2014/03/29  16:00:00 31.4 96.1 59.8
> 9   2014/03/29  17:00:00 29.4 96.3 72.9
> 9   2014/03/29  18:00:00 29 96.3 69.6
> 9   2014/03/29  19:00:00 26.5 96.2 81.7
> 9   2014/03/29  20:00:00 27 96.1 82.9
> 9   2014/03/29  21:00:00 27.5 96.1 81.7
> 9   2014/03/29  22:00:00 27.4 96 82.6
> 9   2014/03/29  23:00:00 27.3 96 83.1
> 9   2014/03/30  00:00:00 27.1 96 84.5
> 9   2014/03/30  01:00:00 27.6 96.1 81.8
> 9   2014/03/30  02:00:00 27.8 96.1 81
>
> 2. I have some data of about 6100 rows and 6 columns, but anytime i read it
> into R, it removes the header and a large chunk of the data.( i:e it will import
> from row 3550-6099). This is the code i used for it
> "met_data=read.csv(file.choose(),header=TRUE)", so, how do I read the entire
> data into R without missing some?
> Thank you.
>
> --
> Onyeuwaoma Nnaemeka Dom
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

________________________________
Tento e-mail a jak?koliv k n?mu p?ipojen? dokumenty jsou d?v?rn? a jsou ur?eny pouze jeho adres?t?m.
Jestli?e jste obdr?el(a) tento e-mail omylem, informujte laskav? neprodlen? jeho odes?latele. Obsah tohoto emailu i s p??lohami a jeho kopie vyma?te ze sv?ho syst?mu.
Nejste-li zam??len?m adres?tem tohoto emailu, nejste opr?vn?ni tento email jakkoliv u??vat, roz?i?ovat, kop?rovat ?i zve?ej?ovat.
Odes?latel e-mailu neodpov?d? za eventu?ln? ?kodu zp?sobenou modifikacemi ?i zpo?d?n?m p?enosu e-mailu.

V p??pad?, ?e je tento e-mail sou??st? obchodn?ho jedn?n?:
- vyhrazuje si odes?latel pr?vo ukon?it kdykoliv jedn?n? o uzav?en? smlouvy, a to z jak?hokoliv d?vodu i bez uveden? d?vodu.
- a obsahuje-li nab?dku, je adres?t opr?vn?n nab?dku bezodkladn? p?ijmout; Odes?latel tohoto e-mailu (nab?dky) vylu?uje p?ijet? nab?dky ze strany p??jemce s dodatkem ?i odchylkou.
- trv? odes?latel na tom, ?e p??slu?n? smlouva je uzav?ena teprve v?slovn?m dosa?en?m shody na v?ech jej?ch n?le?itostech.
- odes?latel tohoto emailu informuje, ?e nen? opr?vn?n uzav?rat za spole?nost ??dn? smlouvy s v?jimkou p??pad?, kdy k tomu byl p?semn? zmocn?n nebo p?semn? pov??en a takov? pov??en? nebo pln? moc byly adres?tovi tohoto emailu p??padn? osob?, kterou adres?t zastupuje, p?edlo?eny nebo jejich existence je adres?tovi ?i osob? j?m zastoupen? zn?m?.

This e-mail and any documents attached to it may be confidential and are intended only for its intended recipients.
If you received this e-mail by mistake, please immediately inform its sender. Delete the contents of this e-mail with all attachments and its copies from your system.
If you are not the intended recipient of this e-mail, you are not authorized to use, disseminate, copy or disclose this e-mail in any manner.
The sender of this e-mail shall not be liable for any possible damage caused by modifications of the e-mail or by delay with transfer of the email.

In case that this e-mail forms part of business dealings:
- the sender reserves the right to end negotiations about entering into a contract in any time, for any reason, and without stating any reasoning.
- if the e-mail contains an offer, the recipient is entitled to immediately accept such offer; The sender of this e-mail (offer) excludes any acceptance of the offer on the part of the recipient containing any amendment or variation.
- the sender insists on that the respective contract is concluded only upon an express mutual agreement on all its aspects.
- the sender of this e-mail informs that he/she is not authorized to enter into any contracts on behalf of the company except for cases in which he/she is expressly authorized to do so in writing, and such authorization or power of attorney is submitted to the recipient or the person represented by the recipient, or the existence of such authorization is known to the recipient of the person represented by the recipient.

From ntuzov at beacon.partek.com  Mon Mar 12 15:28:00 2018
From: ntuzov at beacon.partek.com (Nik Tuzov)
Date: Mon, 12 Mar 2018 09:28:00 -0500 (CDT)
Subject: [R] Package gamlss used inside foreach() and %dopar% fails to find
 an object
In-Reply-To: <mailman.348840.1.1520766002.38671.r-help@r-project.org>
References: <mailman.348840.1.1520766002.38671.r-help@r-project.org>
Message-ID: <1688570614.905888.1520864880305.JavaMail.zimbra@beacon.partek.com>


Hello Mikis:

Thanks a lot, it worked. Could you tell me what the problem was?

Regards,
Nik


----- Original Message -----
From: r-help-request at r-project.org
To: "r-help" 
Sent: Sunday, March 11, 2018 6:00:02 AM
Subject: R-help Digest, Vol 181, Issue 11

Send R-help mailing list submissions to
        r-help at r-project.org

To subscribe or unsubscribe via the World Wide Web, visit
        https://stat.ethz.ch/mailman/listinfo/r-help
or, via email, send a message with subject or body 'help' to
        r-help-request at r-project.org

You can reach the person managing the list at
        r-help-owner at r-project.org

When replying, please edit your Subject line so it is more specific
than "Re: Contents of R-help digest..."


Today's Topics:

   1. . Package gamlss used inside foreach() and %dopar% fails to
      find an object (Nik Tuzov) (Dimitrios Stasinopoulos)
   2. error message from sqldf (Ding, Yuan Chun)
   3. Re: error message from sqldf
      (=?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos)

----------------------------------------------------------------------

Message: 1
Date: Sat, 10 Mar 2018 13:34:59 +0000
From: Dimitrios Stasinopoulos <dmh.stasinopoulos at gmail.com>
To: r-help at r-project.org
Cc: Nik ntuzov.com>
Subject: [R] . Package gamlss used inside foreach() and %dopar% fails
        to find an object (Nik Tuzov)
Message-ID:
        <424DC535-4CAF-4DD5-8BD5-EB19BF6F7247 at staff.londonmet.ac.uk>
Content-Type: text/plain; charset="utf-8"

Dear Nik 

Try the following code 


loo_predict.mu <- function(model.obj, input.data) {
  yhat <- foreach(i = 1 : nrow(input.data), .packages="gamlss", .combine = rbind) %dopar% {
    updated.model.obj <- update(model.obj, data = input.data[-i, ])
    predict(updated.model.obj, what = "mu", data = input.data[-i, ],
            newdata = input.data[i,], type = "response")
  }
  return(data.frame(result = yhat[, 1], row.names = NULL))
}

par.run <- loo_predict.mu(model3, input.processed.cut)

The predict command in this case also need the old data.

Thanks
Mikis 



Prof Dimitrios Mikis Stasinopoulos
stasinom at staff.londonmet.ac.uk




        [[alternative HTML version deleted]]




------------------------------

Message: 2
Date: Sat, 10 Mar 2018 21:30:42 +0000
From: "Ding, Yuan Chun" <ycding at coh.org>
To: "r-help at r-project.org" 
Subject: [R] error message from sqldf
Message-ID:
        coh.org>
Content-Type: text/plain; charset="utf-8"

Dear R users,

I got the following error message from running sqldf code in R.   do you know how to fix it?  I read the sqldf package instruction and did not find a solution.

Thank you,

Ding

chr10 <- sqldf("select * from manifest where CHR==10")

UCN3cpg <-  sqldf("select * from chr10 where MAPINFO between 5405573 and 5407594),
overwrite = TRUE")
Error: Table chr10 exists in database, and both overwrite and append are FALSE


>





---------------------------------------------------------------------
-SECURITY/CONFIDENTIALITY WARNING-
This message (and any attachments) are intended solely f...{{dropped:22}}




------------------------------

Message: 3
Date: Sat, 10 Mar 2018 16:53:35 -0500
From: =?iso-8859-1?Q?Jos=E9_Mar=EDa?= Mateos <chema at rinzewind.org>
To: r-help at r-project.org
Subject: Re: [R] error message from sqldf
Message-ID: <20180310215335.GD5049 at equipaje>
Content-Type: text/plain; charset="iso-8859-1"

On Sat, Mar 10, 2018 at 09:30:42PM +0000, Ding, Yuan Chun wrote:
> chr10 <- sqldf("select * from manifest where CHR==10")
> 
> UCN3cpg <-  sqldf("select * from chr10 where MAPINFO between 5405573 and 5407594),
> overwrite = TRUE")
> Error: Table chr10 exists in database, and both overwrite and append are FALSE

Could it be that `chr10` already exists when you try to run your code. 
What about rewriting it as:

chr10 <- sqldf("select * from manifest where CHR==10", overwrite = TRUE)

Also, it seems to me that the second line is not closing the quotes 
properly. Shouldn't this be correct instead?

UCN3cpg <-  sqldf("select * from chr10 where MAPINFO between 5405573 and 5407594",
                  overwrite = TRUE)

Cheers,

-- 
Jos? Mar?a (Chema) Mateos
https://rinzewind.org/blog-es || https://rinzewind.org/blog-en




------------------------------

Subject: Digest Footer

_______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


------------------------------

End of R-help Digest, Vol 181, Issue 11


From wdunlap at tibco.com  Mon Mar 12 15:56:43 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Mar 2018 07:56:43 -0700
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAF8bMcaSK14CCCVP3ATgwcBC6yK4b+eaXfkfhL=9HaBt5Se2bA@mail.gmail.com>

       1- mixedorder does not work in a "do.call(mixedorder, mydataframe)"
call like the order function does

This is tangential, but do.call(order, mydataframe) is not safe to use in a
general purpose function either - you need to remove the names from
the second argument:
  > d <- data.frame(method=c("New","New","Old","Old","Old"), result=5:1)
  > do.call(order, d)
  Error in match.arg(method) : 'arg' must be NULL or a character vector
  > do.call(order, unname(as.list(d)))
  [1] 2 1 5 4 3


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Sun, Mar 11, 2018 at 9:15 PM, Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

> Hi,
>
> Searching for functions that would order strings that mix characters and
> numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I
> found the mixedsort and mixedorder from the gtools package.
>
> Problems:
> 1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call
> like the order function does
> 2- gtools has not been updated in 2.5 years
>
> Are you aware of an equivalent of this function in base R or a another
> contributed package (with correction of problem #1)?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From kasal at ucw.cz  Mon Mar 12 16:15:07 2018
From: kasal at ucw.cz (Stepan Kasal)
Date: Mon, 12 Mar 2018 16:15:07 +0100
Subject: [R] Bug report: override stopifnot() ?
Message-ID: <20180312151507.GA31065@ucw.cz>

Hello,
I stumbled over a problem:
   stopifnot(m1 == m2)

It works with vector or matrix, but does not work for classes from Matrix package.

In the source of stopifnot(), there is all(m1 == m2) that would just work,
but there is also is.logical(m1 == m2) that id FALSE.

Would it be possible if Matrix package redefined stopifnot() ?

(If there is a bug tracking database for package Matrix, I would be happy to insert this report there.)

Thank you very much for the package,
    Stepan Kasal


From wdunlap at tibco.com  Mon Mar 12 17:30:59 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 12 Mar 2018 09:30:59 -0700
Subject: [R] Bug report: override stopifnot() ?
In-Reply-To: <20180312151507.GA31065@ucw.cz>
References: <20180312151507.GA31065@ucw.cz>
Message-ID: <CAF8bMcb5WNUqOgg6bQs=gqpym+9r0P3Tz_ZZ8svdkJ7SiBoOHg@mail.gmail.com>

Why don't you use
   stopifnot( all(m1 == m2) )
?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Mar 12, 2018 at 8:15 AM, Stepan Kasal <kasal at ucw.cz> wrote:

> Hello,
> I stumbled over a problem:
>    stopifnot(m1 == m2)
>
> It works with vector or matrix, but does not work for classes from Matrix
> package.
>
> In the source of stopifnot(), there is all(m1 == m2) that would just work,
> but there is also is.logical(m1 == m2) that id FALSE.
>
> Would it be possible if Matrix package redefined stopifnot() ?
>
> (If there is a bug tracking database for package Matrix, I would be happy
> to insert this report there.)
>
> Thank you very much for the package,
>     Stepan Kasal
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sebastien.bihorel at cognigencorp.com  Mon Mar 12 18:42:38 2018
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Mon, 12 Mar 2018 13:42:38 -0400 (EDT)
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <CAGxFJbSqrE4Qktdku+ph9axscfJim+63R7y_9hqsHn4-0Dw6Vw@mail.gmail.com>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbSqrE4Qktdku+ph9axscfJim+63R7y_9hqsHn4-0Dw6Vw@mail.gmail.com>
Message-ID: <928407333.2034171.1520876558519.JavaMail.zimbra@cognigencorp.com>


So I take this is a no to my initial question. 

Cheers too. 

PS: some users just ask questions to get straight answers not to get a solution to their problem :D 


From: "Bert Gunter" <bgunter.4567 at gmail.com> 
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
Cc: "R-help" <r-help at r-project.org> 
Sent: Monday, March 12, 2018 12:57:00 AM 
Subject: Re: [R] Equivalent of gtools::mixedsort in R base 

??? 

> y <- sort( c("a1","a2","a10","a12","a100")) 
> y 
[1] "a1" "a10" "a100" "a12" "a2" 
> mixedsort(y) 
[1] "a1" "a2" "a10" "a12" "a100" 

**Please read the docs!** They say that mixedsort() and mixedorder() both take a **single vector** as the argument to be sorted or ordered and, as the above indicates, they perform exactly as advertised. **Unlike order()**. So of course your do.call() construction fails. 

So presumably you have a data frame with multiple columns of mixed alpha and numerics? (A reproducible example would be most helpful here.) 

If this is the case, one **possibly dumb** approach (you have been warned!) would be to turn each column into an ordered factor and then call order() on the data frame of ordered factors via do.call() as above. i.e. 

> y1 <- ordered(y,lev = mixedsort(y)) 
> y1 
[1] a1 a10 a100 a12 a2 
Levels: a1 < a2 < a10 < a12 < a100 
> order(y1) 
[1] 1 5 2 4 3 

(this is just for 1 vector to show how the idea would work). 

Of course, if this is **not** what you want, you'll need to clarify, hopefully with a reprex. Or hope that someone else has better insight than I. 

Cheers, 
Bert 




Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Sun, Mar 11, 2018 at 9:15 PM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 


Hi, 

Searching for functions that would order strings that mix characters and numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I found the mixedsort and mixedorder from the gtools package. 

Problems: 
1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call like the order function does 
2- gtools has not been updated in 2.5 years 

Are you aware of an equivalent of this function in base R or a another contributed package (with correction of problem #1)? 

Thanks 

______________________________________________ 
[ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To UNSUBSCRIBE and more, see 
[ https://stat.ethz.ch/mailman/listinfo/r-help | https://stat.ethz.ch/mailman/listinfo/r-help ] 
PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html | http://www.R-project.org/posting-guide.html ] 
and provide commented, minimal, self-contained, reproducible code. 





	[[alternative HTML version deleted]]


From sebastien.bihorel at cognigencorp.com  Mon Mar 12 18:44:07 2018
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Mon, 12 Mar 2018 13:44:07 -0400 (EDT)
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <CAF8bMcaSK14CCCVP3ATgwcBC6yK4b+eaXfkfhL=9HaBt5Se2bA@mail.gmail.com>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
 <CAF8bMcaSK14CCCVP3ATgwcBC6yK4b+eaXfkfhL=9HaBt5Se2bA@mail.gmail.com>
Message-ID: <44127539.2034244.1520876647589.JavaMail.zimbra@cognigencorp.com>

Hi, 

Point taken... although this error is not returned in older version of R (3.1.2 does not have any issue with your test case... not sure when the added layer of check was introduced). 


From: "William Dunlap" <wdunlap at tibco.com> 
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
Cc: r-help at r-project.org 
Sent: Monday, March 12, 2018 10:56:43 AM 
Subject: Re: [R] Equivalent of gtools::mixedsort in R base 

1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call like the order function does 

This is tangential, but do.call(order, mydataframe) is not safe to use in a 
general purpose function either - you need to remove the names from 
the second argument: 
> d <- data.frame(method=c("New","New","Old","Old","Old"), result=5:1) 
> do.call(order, d) 
Error in match.arg(method) : 'arg' must be NULL or a character vector 
> do.call(order, unname(as.list(d))) 
[1] 2 1 5 4 3 


Bill Dunlap 
TIBCO Software 
wdunlap [ http://tibco.com/ | tibco.com ] 

On Sun, Mar 11, 2018 at 9:15 PM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 


Hi, 

Searching for functions that would order strings that mix characters and numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I found the mixedsort and mixedorder from the gtools package. 

Problems: 
1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call like the order function does 
2- gtools has not been updated in 2.5 years 

Are you aware of an equivalent of this function in base R or a another contributed package (with correction of problem #1)? 

Thanks 

______________________________________________ 
[ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To UNSUBSCRIBE and more, see 
[ https://stat.ethz.ch/mailman/listinfo/r-help | https://stat.ethz.ch/mailman/listinfo/r-help ] 
PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html | http://www.R-project.org/posting-guide.html ] 
and provide commented, minimal, self-contained, reproducible code. 





	[[alternative HTML version deleted]]


From sebastien.bihorel at cognigencorp.com  Mon Mar 12 18:46:17 2018
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Mon, 12 Mar 2018 13:46:17 -0400 (EDT)
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <alpine.BSF.2.00.1803112236210.4198@pedal.dcn.davis.ca.us>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbSqrE4Qktdku+ph9axscfJim+63R7y_9hqsHn4-0Dw6Vw@mail.gmail.com>
 <alpine.BSF.2.00.1803112236210.4198@pedal.dcn.davis.ca.us>
Message-ID: <1937144416.2034411.1520876777952.JavaMail.zimbra@cognigencorp.com>


Thanks for your reply. I take this is also a no to my question and appreciated the suggested mixedrank function and its usage with do.call.

Thanks


----- Original Message -----
From: "Jeff Newmiller" <jdnewmil at dcn.davis.ca.us>
To: "Bert Gunter" <bgunter.4567 at gmail.com>
Cc: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>, "R-help" <r-help at r-project.org>
Sent: Monday, March 12, 2018 2:11:03 AM
Subject: Re: [R] Equivalent of gtools::mixedsort in R base

x <- c( "a1", "a10", "a2" )
y <- c( "b10", "b2", "a12", "ca1" )

DF <- expand.grid( x = x, y = y )
# randomize
set.seed( 42 )
DF <- DF[ sample( nrow( DF ) ), ]

# missing from gtools
mixedrank <- function( x ) {
   seq.int( length( x ) )[ gtools::mixedorder(x) ]
}

o <- do.call( order, lapply( DF, mixedrank ) )
DF[ o, ]

# or, as Bert suggests:

myrank <- function( v ) {
   vu <- unique(v)
   vl <- regmatches( vu,regexec("^([A-Za-z]+)(\\d+)$",vu))
   alph <- sapply( vl, function(s) s[2] )
   digt <- as.integer( sapply( vl, function(s) s[3] ) )
   o <- order( alph, digt )
   vo <- ordered( v, levels=vu[ o ] )
}

o2 <- do.call( order, lapply( DF, myrank ) )
DF[ o2, ]

?order
?ordered
?rank

On Sun, 11 Mar 2018, Bert Gunter wrote:

> ???
>
>> y <- sort( c("a1","a2","a10","a12","a100"))
>> y
> [1] "a1"   "a10"  "a100" "a12"  "a2"
>> mixedsort(y)
> [1] "a1"   "a2"   "a10"  "a12"  "a100"
>
> **Please read the docs!** They say that mixedsort() and mixedorder()  both
> take a **single vector**  as the argument to be sorted or ordered and, as
> the above indicates, they perform exactly as advertised. **Unlike
> order()**. So of course your do.call() construction fails.
>
> So presumably you have a data frame with multiple columns of mixed alpha
> and numerics?  (A reproducible example would be most helpful here.)
>
> If this is the case, one **possibly dumb** approach (you have been warned!)
> would be to turn each column into an ordered factor and then call order()
> on the data frame of ordered factors via do.call() as above. i.e.
>
>> y1 <- ordered(y,lev = mixedsort(y))
>> y1
> [1] a1   a10  a100 a12  a2
> Levels: a1 < a2 < a10 < a12 < a100
>> order(y1)
> [1] 1 5 2 4 3
>
> (this is just for 1 vector to show how the idea would work).
>
> Of course, if this is **not** what you want, you'll need to clarify,
> hopefully with a reprex. Or hope that someone else has better insight than
> I.
>
> Cheers,
> Bert
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Sun, Mar 11, 2018 at 9:15 PM, Sebastien Bihorel <
> sebastien.bihorel at cognigencorp.com> wrote:
>
>> Hi,
>>
>> Searching for functions that would order strings that mix characters and
>> numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I
>> found the mixedsort and mixedorder from the gtools package.
>>
>> Problems:
>> 1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call
>> like the order function does
>> 2- gtools has not been updated in 2.5 years
>>
>> Are you aware of an equivalent of this function in base R or a another
>> contributed package (with correction of problem #1)?
>>
>> Thanks
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From kasal at ucw.cz  Mon Mar 12 18:53:00 2018
From: kasal at ucw.cz (Stepan Kasal)
Date: Mon, 12 Mar 2018 18:53:00 +0100
Subject: [R] Bug report: override stopifnot() ?
In-Reply-To: <CAF8bMcb5WNUqOgg6bQs=gqpym+9r0P3Tz_ZZ8svdkJ7SiBoOHg@mail.gmail.com>
References: <20180312151507.GA31065@ucw.cz>
 <CAF8bMcb5WNUqOgg6bQs=gqpym+9r0P3Tz_ZZ8svdkJ7SiBoOHg@mail.gmail.com>
Message-ID: <20180312175300.GA24063@ucw.cz>

Hello,

On Mon, Mar 12, 2018 at 09:30:59AM -0700, William Dunlap wrote:
> Why don't you use
>    stopifnot( all(m1 == m2) )
> ?

good question.  Even though I use
   aseert np.all(m1 == m2)
when working with NumPy, I got accustomed to the "handy shortcut"
that I can omit all() with R vectors and matrices.

Then I got trapped with the thing I reported.

On a second thought, omitting all() might have been bad idea from
the beginning; I should rather write all() routinely.
(It also reminds me that all.equal() is the right one in most cases.)

Is it true that using stopifnot() with non-scalar is considerd bad style?

If yes, could be perhaps stopifnot() enhanced to issue a warning to
teach new users of R, at least when they start using library(Matrix)?

If not, then enhancing stopifnot() to handle the case may be a good idea.

I also noticed the following:

> a <- Matrix(1)
> stopifnot(a == a)
Error: a == a is not TRUE
> if(a==a)print(1)
Error in if (a == a) print(1) : argument is not interpretable as logical

Neither does work, but the first error message is much more confusing.

When thinking about it, stopifnot() should really issue a better error
message in this case.  Patch attached.  But I should perhaps send
it also to R-devel.

Stepan Kasal


> On Mon, Mar 12, 2018 at 8:15 AM, Stepan Kasal <kasal at ucw.cz> wrote:
> 
> > Hello,
> > I stumbled over a problem:
> >    stopifnot(m1 == m2)
> >
> > It works with vector or matrix, but does not work for classes from Matrix
> > package.
> >
> > In the source of stopifnot(), there is all(m1 == m2) that would just work,
> > but there is also is.logical(m1 == m2) that id FALSE.
> >
> > Would it be possible if Matrix package redefined stopifnot() ?
> >
> > (If there is a bug tracking database for package Matrix, I would be happy
> > to insert this report there.)
> >
> > Thank you very much for the package,
> >     Stepan Kasal
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >


From kasal at ucw.cz  Mon Mar 12 18:56:40 2018
From: kasal at ucw.cz (Stepan Kasal)
Date: Mon, 12 Mar 2018 18:56:40 +0100
Subject: [R] Bug report: override stopifnot() ?
In-Reply-To: <20180312175300.GA24063@ucw.cz>
References: <20180312151507.GA31065@ucw.cz>
 <CAF8bMcb5WNUqOgg6bQs=gqpym+9r0P3Tz_ZZ8svdkJ7SiBoOHg@mail.gmail.com>
 <20180312175300.GA24063@ucw.cz>
Message-ID: <20180312175640.GB24063@ucw.cz>

Hello,
I'm sorry that I aswer to my own mail; I forgot to attach the patch.
Patch below,
   Stepan Kasal

On Mon, Mar 12, 2018 at 06:53:00PM +0100, Stepan Kasal wrote:
> When thinking about it, stopifnot() should really issue a better error
> message in this case.  Patch attached.  But I should perhaps send
> it also to R-devel.


--- stopifnot-orig.r	2018-03-12 18:49:01.439484100 +0100
+++ stopifnot.r	2018-03-12 18:48:55.721846700 +0100
@@ -1,16 +1,20 @@
-function (...)
+function (...) 
 {
   n <- length(ll <- list(...))
-  if (n == 0L)
+  if (n == 0L) 
     return(invisible())
   mc <- match.call()
-  for (i in 1L:n) if (!(is.logical(r <- ll[[i]]) && !anyNA(r) &&
+  for (i in 1L:n) if (!(is.logical(r <- ll[[i]]) && !anyNA(r) && 
     all(r))) {
     ch <- deparse(mc[[i + 1]], width.cutoff = 60L)
-    if (length(ch) > 1L)
+    if (length(ch) > 1L) 
       ch <- paste(ch[1L], "....")
-    stop(sprintf(ngettext(length(r), "%s is not TRUE", "%s are not all TRUE"),
-      ch), call. = FALSE, domain = NA)
+    if (is.logical(r)) {
+      msg <- ngettext(length(r), "%s is not TRUE", "%s are not all TRUE")
+    } else {
+      msg <- gettext("%s is not of type \"logical\"")
+    }
+    stop(sprintf(msg, ch), call. = FALSE, domain = NA)
   }
   invisible()
 }


From bgunter.4567 at gmail.com  Mon Mar 12 19:43:44 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 12 Mar 2018 11:43:44 -0700
Subject: [R] Bug report: override stopifnot() ?
In-Reply-To: <20180312175300.GA24063@ucw.cz>
References: <20180312151507.GA31065@ucw.cz>
 <CAF8bMcb5WNUqOgg6bQs=gqpym+9r0P3Tz_ZZ8svdkJ7SiBoOHg@mail.gmail.com>
 <20180312175300.GA24063@ucw.cz>
Message-ID: <CAGxFJbTFmafOgXbyj8MWmO=tR+LpMu6PeCPn++8-p1Dt=xuKmQ@mail.gmail.com>

Please stop this line of queries/"suggestions/speculations and read the
relevant docs **carefully**.

For example, from ?"=="

"Note

Do not use == and != for tests, such as in if expressions, where you must
get a single TRUE or FALSE. Unless you are absolutely sure that nothing
unusual can happen, you should use the identical
<http://127.0.0.1:22171/help/library/base/help/identical> function instead.
"

So you have already violated that specific warning, which led to the
confusion you evidence. Specifically:
> Matrix(1)== Matrix(1)
1 x 1 Matrix of class "lsyMatrix"
     [,1]
[1,] TRUE

That is, the result is not a logical but a (S4) object of class "lsyMatrix"
that contains a logical. Whence your (expected) error message.

Cheers,

Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 12, 2018 at 10:53 AM, Stepan Kasal <kasal at ucw.cz> wrote:

> Hello,
>
> On Mon, Mar 12, 2018 at 09:30:59AM -0700, William Dunlap wrote:
> > Why don't you use
> >    stopifnot( all(m1 == m2) )
> > ?
>
> good question.  Even though I use
>    aseert np.all(m1 == m2)
> when working with NumPy, I got accustomed to the "handy shortcut"
> that I can omit all() with R vectors and matrices.
>
> Then I got trapped with the thing I reported.
>
> On a second thought, omitting all() might have been bad idea from
> the beginning; I should rather write all() routinely.
> (It also reminds me that all.equal() is the right one in most cases.)
>
> Is it true that using stopifnot() with non-scalar is considerd bad style?
>
> If yes, could be perhaps stopifnot() enhanced to issue a warning to
> teach new users of R, at least when they start using library(Matrix)?
>
> If not, then enhancing stopifnot() to handle the case may be a good idea.
>
> I also noticed the following:
>
> > a <- Matrix(1)
> > stopifnot(a == a)
> Error: a == a is not TRUE
> > if(a==a)print(1)
> Error in if (a == a) print(1) : argument is not interpretable as logical
>
> Neither does work, but the first error message is much more confusing.
>
> When thinking about it, stopifnot() should really issue a better error
> message in this case.  Patch attached.  But I should perhaps send
> it also to R-devel.
>
> Stepan Kasal
>
>
> > On Mon, Mar 12, 2018 at 8:15 AM, Stepan Kasal <kasal at ucw.cz> wrote:
> >
> > > Hello,
> > > I stumbled over a problem:
> > >    stopifnot(m1 == m2)
> > >
> > > It works with vector or matrix, but does not work for classes from
> Matrix
> > > package.
> > >
> > > In the source of stopifnot(), there is all(m1 == m2) that would just
> work,
> > > but there is also is.logical(m1 == m2) that id FALSE.
> > >
> > > Would it be possible if Matrix package redefined stopifnot() ?
> > >
> > > (If there is a bug tracking database for package Matrix, I would be
> happy
> > > to insert this report there.)
> > >
> > > Thank you very much for the package,
> > >     Stepan Kasal
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> > >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From karthik.100 at gmail.com  Mon Mar 12 20:11:30 2018
From: karthik.100 at gmail.com (Karthiko S)
Date: Tue, 13 Mar 2018 00:41:30 +0530
Subject: [R] Error - PMML Conversion of a Random-Forest Model using the
 randomForest Package
Message-ID: <CAD-yskqv7636-wzzWk89LPz13HZmCDrLVqYpFQEgPeu9F3+gFw@mail.gmail.com>

Hi All,

I am trying to convert random forest model developed into a pmml file.
randomForest package was used to build the model. The input to the model is
in the form of a matrix (term frequency matrix used for text analytics).
While i try to convert the model into a pmml file  an error pops.

Error in names (field$class) <-var.names
attempt to set an attribute on NULL

Would be great if anyone could please help me in over-coming this error.

Thanks and Regards
Karthik

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Mon Mar 12 20:49:10 2018
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 12 Mar 2018 15:49:10 -0400
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAP01uRmaGpwQd3na9BrPDLpiLe1iMP5xCbzmNonvs+fNgiOg4w@mail.gmail.com>

split any mixed columns into letter and number columns
and then order can be used on that:

  DF <- data.frame(x = c("a10", "a2", "a1"))
  o <- do.call("order", transform(DF, let = gsub("\\d", "", x),
                                                         no =
as.numeric(gsub("\\D", "", x)),
                                                         x = NULL))
  DF[o,, drop = FALSE ]


On Mon, Mar 12, 2018 at 12:15 AM, Sebastien Bihorel
<sebastien.bihorel at cognigencorp.com> wrote:
> Hi,
>
> Searching for functions that would order strings that mix characters and numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I found the mixedsort and mixedorder from the gtools package.
>
> Problems:
> 1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call like the order function does
> 2- gtools has not been updated in 2.5 years
>
> Are you aware of an equivalent of this function in base R or a another contributed package (with correction of problem #1)?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From huertaya at protonmail.com  Mon Mar 12 21:28:13 2018
From: huertaya at protonmail.com (Yectli Huerta)
Date: Mon, 12 Mar 2018 16:28:13 -0400
Subject: [R] ggplot and boxplots
Message-ID: <Pd8GCAd6v2c6WkRi3YegvrlbL_M7cnUxqNZ6PmTFKzD-g4twA85BxtBQ9n4zBpX3S2LMU2Bb5iwOBEkJiiZw9hiZ0ziabD85pVlr_ifI4C8=@protonmail.com>

Hi,

I was wondering if someone could give me a hint or two. I'm having problems generating ggplot2 boxplots . The plot that is has dots but no boxplots. Below is the dataset

> testing_ggplot
    V1        V2     V3
1  256  Disabled 688.61
2  256  Disabled 698.63
3  256  Disabled 700.02
4  256  Disabled 693.36
5  256  Disabled  688.8
6  256  Disabled 697.72
7  256  Disabled 698.15
8  256  Disabled 693.98
9  256  Disabled 700.75
...
16 256   Enabled 698.35
17 256   Enabled 694.71
18 256   Enabled 705.53
19 256   Enabled 708.61
20 256   Enabled 693.33
...
32 272  Disabled 690.79

33 272  Disabled 687.14
34 272  Disabled 684.92
35 272  Disabled 687.87
36 272  Disabled 687.33
37 272   Enabled 696.22
38 272   Enabled 700.61
39 272   Enabled  695.2
40 272   Enabled 697.46
41 272   Enabled 696.83
...

This command for some reason, fails to generate a boxplot
> ggplot(testing_ggplot,aes(factor(V2),V3))+geom_boxplot() +facet_wrap(~as.factor(V1))

I don't seem to figure out what is wrong with the ggplot command I'm using. I attached a png with the generated plot

thanks,

yh
-------------- next part --------------
A non-text attachment was scrubbed...
Name: ggplot.png
Type: image/png
Size: 62358 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180312/0f630327/attachment.png>

From murdoch.duncan at gmail.com  Mon Mar 12 21:45:19 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 12 Mar 2018 16:45:19 -0400
Subject: [R] Bug report: override stopifnot() ?
In-Reply-To: <CAGxFJbTFmafOgXbyj8MWmO=tR+LpMu6PeCPn++8-p1Dt=xuKmQ@mail.gmail.com>
References: <20180312151507.GA31065@ucw.cz>
 <CAF8bMcb5WNUqOgg6bQs=gqpym+9r0P3Tz_ZZ8svdkJ7SiBoOHg@mail.gmail.com>
 <20180312175300.GA24063@ucw.cz>
 <CAGxFJbTFmafOgXbyj8MWmO=tR+LpMu6PeCPn++8-p1Dt=xuKmQ@mail.gmail.com>
Message-ID: <351c70f5-c224-9c63-ffd1-947aab63888c@gmail.com>

On 12/03/2018 2:43 PM, Bert Gunter wrote:
> Please stop this line of queries/"suggestions/speculations and read the
> relevant docs **carefully**.
> 
> For example, from ?"=="
> 
> "Note
> 
> Do not use == and != for tests, such as in if expressions, where you must
> get a single TRUE or FALSE. Unless you are absolutely sure that nothing
> unusual can happen, you should use the identical
> <http://127.0.0.1:22171/help/library/base/help/identical> function instead.
> "

But stopifnot(expr) is not a test where you must get a single TRUE or 
FALSE.  See the Details section on its help page, or read its 
Description carefully (where "all" is used in the technical sense of the 
all() function), ignoring the final few words which seem to suggest that 
c(TRUE, TRUE) is not okay.

Duncan Murdoch

> 
> So you have already violated that specific warning, which led to the
> confusion you evidence. Specifically:
>> Matrix(1)== Matrix(1)
> 1 x 1 Matrix of class "lsyMatrix"
>       [,1]
> [1,] TRUE
> 
> That is, the result is not a logical but a (S4) object of class "lsyMatrix"
> that contains a logical. Whence your (expected) error message.
> 
> Cheers,
> 
> Bert
> 
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Mon, Mar 12, 2018 at 10:53 AM, Stepan Kasal <kasal at ucw.cz> wrote:
> 
>> Hello,
>>
>> On Mon, Mar 12, 2018 at 09:30:59AM -0700, William Dunlap wrote:
>>> Why don't you use
>>>     stopifnot( all(m1 == m2) )
>>> ?
>>
>> good question.  Even though I use
>>     aseert np.all(m1 == m2)
>> when working with NumPy, I got accustomed to the "handy shortcut"
>> that I can omit all() with R vectors and matrices.
>>
>> Then I got trapped with the thing I reported.
>>
>> On a second thought, omitting all() might have been bad idea from
>> the beginning; I should rather write all() routinely.
>> (It also reminds me that all.equal() is the right one in most cases.)
>>
>> Is it true that using stopifnot() with non-scalar is considerd bad style?
>>
>> If yes, could be perhaps stopifnot() enhanced to issue a warning to
>> teach new users of R, at least when they start using library(Matrix)?
>>
>> If not, then enhancing stopifnot() to handle the case may be a good idea.
>>
>> I also noticed the following:
>>
>>> a <- Matrix(1)
>>> stopifnot(a == a)
>> Error: a == a is not TRUE
>>> if(a==a)print(1)
>> Error in if (a == a) print(1) : argument is not interpretable as logical
>>
>> Neither does work, but the first error message is much more confusing.
>>
>> When thinking about it, stopifnot() should really issue a better error
>> message in this case.  Patch attached.  But I should perhaps send
>> it also to R-devel.
>>
>> Stepan Kasal
>>
>>
>>> On Mon, Mar 12, 2018 at 8:15 AM, Stepan Kasal <kasal at ucw.cz> wrote:
>>>
>>>> Hello,
>>>> I stumbled over a problem:
>>>>     stopifnot(m1 == m2)
>>>>
>>>> It works with vector or matrix, but does not work for classes from
>> Matrix
>>>> package.
>>>>
>>>> In the source of stopifnot(), there is all(m1 == m2) that would just
>> work,
>>>> but there is also is.logical(m1 == m2) that id FALSE.
>>>>
>>>> Would it be possible if Matrix package redefined stopifnot() ?
>>>>
>>>> (If there is a bug tracking database for package Matrix, I would be
>> happy
>>>> to insert this report there.)
>>>>
>>>> Thank you very much for the package,
>>>>      Stepan Kasal
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/
>>>> posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rmh at temple.edu  Tue Mar 13 05:59:17 2018
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 13 Mar 2018 00:59:17 -0400
Subject: [R] ggplot and boxplots
In-Reply-To: <Pd8GCAd6v2c6WkRi3YegvrlbL_M7cnUxqNZ6PmTFKzD-g4twA85BxtBQ9n4zBpX3S2LMU2Bb5iwOBEkJiiZw9hiZ0ziabD85pVlr_ifI4C8=@protonmail.com>
References: <Pd8GCAd6v2c6WkRi3YegvrlbL_M7cnUxqNZ6PmTFKzD-g4twA85BxtBQ9n4zBpX3S2LMU2Bb5iwOBEkJiiZw9hiZ0ziabD85pVlr_ifI4C8=@protonmail.com>
Message-ID: <CAGx1TMBkh2wV=ioCVZ6xQ7dQOQccrstG2ynAK-sMe4gs848J0A@mail.gmail.com>

It looks like your V3 is a factor.

testing_ggplot <- data.frame(
  V1=factor(c(256, 256, 256, 272, 272, 272)),
  V2=c("Disabled", "Disabled", "Enabled", "Disabled", "Enabled", "Enabled"),
  V3=681:686)

library(ggplot2)
ggplot(testing_ggplot, aes(V2,        V3 )) + geom_boxplot() +
facet_wrap( ~ V1) + labs(title="what you want")
ggplot(testing_ggplot, aes(V2, factor(V3))) + geom_boxplot() +
facet_wrap( ~ V1) + labs(title="what you are getting")

On Mon, Mar 12, 2018 at 4:28 PM, Yectli Huerta via R-help
<r-help at r-project.org> wrote:
> Hi,
>
> I was wondering if someone could give me a hint or two. I'm having problems generating ggplot2 boxplots . The plot that is has dots but no boxplots. Below is the dataset
>
>> testing_ggplot
>     V1        V2     V3
> 1  256  Disabled 688.61
> 2  256  Disabled 698.63
> 3  256  Disabled 700.02
> 4  256  Disabled 693.36
> 5  256  Disabled  688.8
> 6  256  Disabled 697.72
> 7  256  Disabled 698.15
> 8  256  Disabled 693.98
> 9  256  Disabled 700.75
> ...
> 16 256   Enabled 698.35
> 17 256   Enabled 694.71
> 18 256   Enabled 705.53
> 19 256   Enabled 708.61
> 20 256   Enabled 693.33
> ...
> 32 272  Disabled 690.79
>
> 33 272  Disabled 687.14
> 34 272  Disabled 684.92
> 35 272  Disabled 687.87
> 36 272  Disabled 687.33
> 37 272   Enabled 696.22
> 38 272   Enabled 700.61
> 39 272   Enabled  695.2
> 40 272   Enabled 697.46
> 41 272   Enabled 696.83
> ...
>
> This command for some reason, fails to generate a boxplot
>> ggplot(testing_ggplot,aes(factor(V2),V3))+geom_boxplot() +facet_wrap(~as.factor(V1))
>
> I don't seem to figure out what is wrong with the ggplot command I'm using. I attached a png with the generated plot
>
> thanks,
>
> yh
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From manishmukherjee at hotmail.com  Tue Mar 13 04:47:39 2018
From: manishmukherjee at hotmail.com (Manish Mukherjee)
Date: Tue, 13 Mar 2018 03:47:39 +0000
Subject: [R] Need Help on Batch forecasting for multiple items at one go
Message-ID: <BM1PR0101MB19214DF859CECD4B55554CA9B9D20@BM1PR0101MB1921.INDPRD01.PROD.OUTLOOK.COM>

Hi All,


I have time series weekly data for number of servers for 62 weeks. i have to forecast for next 8 weeks on what will be the usage.  i have a challenge in the code where it is giving output for the last week value of  all the servers, instead i need the output for next 8 weeks . i am attaching the data and my r script for your reference.



Thanks & Regards
Manish Mukherjee

From egeulgen at gmail.com  Mon Mar 12 12:37:01 2018
From: egeulgen at gmail.com (Ege Ulgen)
Date: Mon, 12 Mar 2018 14:37:01 +0300
Subject: [R] [R-pkgs] pathfindR: An R Package for Pathway Enrichment
 Analysis Utilizing Active Subnetworks
Message-ID: <67AC3BB2-4594-4945-8C4B-E6DD6ACB591E@gmail.com>

Hello all,

I would like to introduce our group's new bioinformatics package to you: pathfindR <https://cran.r-project.org/package=pathfindR>
This tool is designed to improve pathway enrichment analysis by firstly identifying active subnetworksin differential expression/methylation data using a protein-protein interaction network. It then performs pathway enrichment analysis (Over-Representation Analysis). By utilizing the interaction information, the tool identifies most of the involved pathways.
pathfindR also creates pathway diagrams with the involved genes colored by change values. (this is achieved using the bioconductor package pathview)
Finally, the package allows for clustering of enriched pathways and establishment of representative pathways. This allows for further abstraction and reduces the complexity of analysis.
You can read more about the package and a case study in our pre-print <https://doi.org/10.1101/272450>
	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From sebastien.bihorel at cognigencorp.com  Tue Mar 13 13:58:55 2018
From: sebastien.bihorel at cognigencorp.com (Sebastien Bihorel)
Date: Tue, 13 Mar 2018 08:58:55 -0400 (EDT)
Subject: [R] Equivalent of gtools::mixedsort in R base
In-Reply-To: <CAP01uRmaGpwQd3na9BrPDLpiLe1iMP5xCbzmNonvs+fNgiOg4w@mail.gmail.com>
References: <1702770943.2015374.1520828142730.JavaMail.zimbra@cognigencorp.com>
 <CAP01uRmaGpwQd3na9BrPDLpiLe1iMP5xCbzmNonvs+fNgiOg4w@mail.gmail.com>
Message-ID: <1513997374.2056028.1520945935575.JavaMail.zimbra@cognigencorp.com>

Thanks.

----- Original Message -----
From: "Gabor Grothendieck" <ggrothendieck at gmail.com>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
Cc: r-help at r-project.org
Sent: Monday, March 12, 2018 3:49:10 PM
Subject: Re: [R] Equivalent of gtools::mixedsort in R base

split any mixed columns into letter and number columns
and then order can be used on that:

  DF <- data.frame(x = c("a10", "a2", "a1"))
  o <- do.call("order", transform(DF, let = gsub("\\d", "", x),
                                                         no =
as.numeric(gsub("\\D", "", x)),
                                                         x = NULL))
  DF[o,, drop = FALSE ]


On Mon, Mar 12, 2018 at 12:15 AM, Sebastien Bihorel
<sebastien.bihorel at cognigencorp.com> wrote:
> Hi,
>
> Searching for functions that would order strings that mix characters and numbers in a "natural" way (ie, "a1 a2 a10" instead of "a1 a10 a2"), I found the mixedsort and mixedorder from the gtools package.
>
> Problems:
> 1- mixedorder does not work in a "do.call(mixedorder, mydataframe)" call like the order function does
> 2- gtools has not been updated in 2.5 years
>
> Are you aware of an equivalent of this function in base R or a another contributed package (with correction of problem #1)?
>
> Thanks
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From HDoran at air.org  Tue Mar 13 14:23:34 2018
From: HDoran at air.org (Doran, Harold)
Date: Tue, 13 Mar 2018 13:23:34 +0000
Subject: [R] Possible Improvement to sapply
Message-ID: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>

While working with sapply, the documentation states that the simplify argument will yield a vector, matrix etc "when possible". I was curious how the code actually defined "as possible" and see this within the function

if (!identical(simplify, FALSE) && length(answer))

This seems superfluous to me, in particular this part:

!identical(simplify, FALSE)

The preceding code could be reduced to 

if (simplify && length(answer))

and it would not need to execute the call to identical in order to trigger the conditional execution, which is known from the user's simplify = TRUE or FALSE inputs. I *think* the extra call to identical is just unnecessary overhead in this instance.

Take for example, the following toy example code and benchmark results and a small modification to sapply:

myList <- list(a = rnorm(100), b = rnorm(100))

answer <- lapply(X = myList, FUN = length)
simplify = TRUE

library(microbenchmark)

mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
	FUN <- match.fun(FUN)
    answer <- lapply(X = X, FUN = FUN, ...)
    if (USE.NAMES && is.character(X) && is.null(names(answer))) 
        names(answer) <- X
    if (simplify && length(answer)) 
        simplify2array(answer, higher = (simplify == "array"))
    else answer
}


> microbenchmark(sapply(myList, length), times = 10000L)
Unit: microseconds
                   expr    min     lq     mean median     uq    max neval
 sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46 10000
> microbenchmark(mySapply(myList, length), times = 10000L)
Unit: microseconds
                     expr    min     lq     mean median     uq      max neval
 mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573 1671.804 10000

My benchmark timings show a timing improvement with only that small change made and it is seemingly nominal. In my actual work, the sapply function is called millions of times and this additional overhead propagates to some overall additional computing time.

I have done some limited testing on various real data to verify that the objects produced under both variants of the sapply (base R and my modified) yield identical objects when simply is both TRUE or FALSE.

Perhaps someone else sees a counterexample where my proposed fix does not cause for sapply to behave as expected.

Harold


From martin.morgan at roswellpark.org  Tue Mar 13 14:43:19 2018
From: martin.morgan at roswellpark.org (Martin Morgan)
Date: Tue, 13 Mar 2018 09:43:19 -0400
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
Message-ID: <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>



On 03/13/2018 09:23 AM, Doran, Harold wrote:
> While working with sapply, the documentation states that the simplify argument will yield a vector, matrix etc "when possible". I was curious how the code actually defined "as possible" and see this within the function
> 
> if (!identical(simplify, FALSE) && length(answer))
> 
> This seems superfluous to me, in particular this part:
> 
> !identical(simplify, FALSE)
> 
> The preceding code could be reduced to
> 
> if (simplify && length(answer))
> 
> and it would not need to execute the call to identical in order to trigger the conditional execution, which is known from the user's simplify = TRUE or FALSE inputs. I *think* the extra call to identical is just unnecessary overhead in this instance.
> 
> Take for example, the following toy example code and benchmark results and a small modification to sapply:
> 
> myList <- list(a = rnorm(100), b = rnorm(100))
> 
> answer <- lapply(X = myList, FUN = length)
> simplify = TRUE
> 
> library(microbenchmark)
> 
> mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
> 	FUN <- match.fun(FUN)
>      answer <- lapply(X = X, FUN = FUN, ...)
>      if (USE.NAMES && is.character(X) && is.null(names(answer)))
>          names(answer) <- X
>      if (simplify && length(answer))
>          simplify2array(answer, higher = (simplify == "array"))
>      else answer
> }
> 
> 
>> microbenchmark(sapply(myList, length), times = 10000L)
> Unit: microseconds
>                     expr    min     lq     mean median     uq    max neval
>   sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46 10000
>> microbenchmark(mySapply(myList, length), times = 10000L)
> Unit: microseconds
>                       expr    min     lq     mean median     uq      max neval
>   mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573 1671.804 10000
> 
> My benchmark timings show a timing improvement with only that small change made and it is seemingly nominal. In my actual work, the sapply function is called millions of times and this additional overhead propagates to some overall additional computing time.
> 
> I have done some limited testing on various real data to verify that the objects produced under both variants of the sapply (base R and my modified) yield identical objects when simply is both TRUE or FALSE.
> 
> Perhaps someone else sees a counterexample where my proposed fix does not cause for sapply to behave as expected.
> 

Check out ?sapply for possible values of `simplify=` to see why your 
proposal is not adequate.

For your example, lengths() is an order of magnitude faster than 
sapply(., length). This is a example of the advantages of vectorization 
(single call to an R function implemented in C) versus iteration (`for` 
loops but also the *apply family calling an R function many times). 
vapply() might also be relevant.

Often performance improvements come from looking one layer up from where 
the problem occurs and re-thinking the algorithm. Why would one need to 
call sapply() millions of times, in a situation where this becomes 
rate-limiting? Can the algorithm be re-implemented to avoid this step?

Martin Morgan

> Harold
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


This email message may contain legally privileged and/or...{{dropped:2}}


From HDoran at air.org  Tue Mar 13 15:06:39 2018
From: HDoran at air.org (Doran, Harold)
Date: Tue, 13 Mar 2018 14:06:39 +0000
Subject: [R] Possible Improvement to sapply
In-Reply-To: <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>
Message-ID: <CY1PR0501MB12736C801550165F43C15EE5CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>

Martin

In terms of context of the actual problem, sapply is called millions of times because the work involves scoring individual students who took a test. A score for student A is generated and then student B and such and there are millions of students. The psychometric process of scoring students is complex and our code makes use of sapply many times for each student.

The toy example used length just to illustrate, our actual code doesn't do that. But your point is well taken, there may be a very good counterexample why my proposal doesn't achieve the goal is a generalizable way.



-----Original Message-----
From: Martin Morgan [mailto:martin.morgan at roswellpark.org] 
Sent: Tuesday, March 13, 2018 9:43 AM
To: Doran, Harold <HDoran at air.org>; 'r-help at r-project.org' <r-help at r-project.org>
Subject: Re: [R] Possible Improvement to sapply



On 03/13/2018 09:23 AM, Doran, Harold wrote:
> While working with sapply, the documentation states that the simplify 
> argument will yield a vector, matrix etc "when possible". I was 
> curious how the code actually defined "as possible" and see this 
> within the function
> 
> if (!identical(simplify, FALSE) && length(answer))
> 
> This seems superfluous to me, in particular this part:
> 
> !identical(simplify, FALSE)
> 
> The preceding code could be reduced to
> 
> if (simplify && length(answer))
> 
> and it would not need to execute the call to identical in order to trigger the conditional execution, which is known from the user's simplify = TRUE or FALSE inputs. I *think* the extra call to identical is just unnecessary overhead in this instance.
> 
> Take for example, the following toy example code and benchmark results and a small modification to sapply:
> 
> myList <- list(a = rnorm(100), b = rnorm(100))
> 
> answer <- lapply(X = myList, FUN = length) simplify = TRUE
> 
> library(microbenchmark)
> 
> mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
> 	FUN <- match.fun(FUN)
>      answer <- lapply(X = X, FUN = FUN, ...)
>      if (USE.NAMES && is.character(X) && is.null(names(answer)))
>          names(answer) <- X
>      if (simplify && length(answer))
>          simplify2array(answer, higher = (simplify == "array"))
>      else answer
> }
> 
> 
>> microbenchmark(sapply(myList, length), times = 10000L)
> Unit: microseconds
>                     expr    min     lq     mean median     uq    max neval
>   sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46 
> 10000
>> microbenchmark(mySapply(myList, length), times = 10000L)
> Unit: microseconds
>                       expr    min     lq     mean median     uq      max neval
>   mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573 
> 1671.804 10000
> 
> My benchmark timings show a timing improvement with only that small change made and it is seemingly nominal. In my actual work, the sapply function is called millions of times and this additional overhead propagates to some overall additional computing time.
> 
> I have done some limited testing on various real data to verify that the objects produced under both variants of the sapply (base R and my modified) yield identical objects when simply is both TRUE or FALSE.
> 
> Perhaps someone else sees a counterexample where my proposed fix does not cause for sapply to behave as expected.
> 

Check out ?sapply for possible values of `simplify=` to see why your proposal is not adequate.

For your example, lengths() is an order of magnitude faster than sapply(., length). This is a example of the advantages of vectorization (single call to an R function implemented in C) versus iteration (`for` loops but also the *apply family calling an R function many times). 
vapply() might also be relevant.

Often performance improvements come from looking one layer up from where the problem occurs and re-thinking the algorithm. Why would one need to call sapply() millions of times, in a situation where this becomes rate-limiting? Can the algorithm be re-implemented to avoid this step?

Martin Morgan

> Harold
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.


From reichmanj at sbcglobal.net  Tue Mar 13 15:25:31 2018
From: reichmanj at sbcglobal.net (JEFFERY REICHMAN)
Date: Tue, 13 Mar 2018 14:25:31 +0000 (UTC)
Subject: [R] Understanding TS objects
References: <1154151976.526964.1520951131081.ref@mail.yahoo.com>
Message-ID: <1154151976.526964.1520951131081@mail.yahoo.com>

R Help Community

I'm trying to understand time series (TS) objects.  Thought I understood but recently have run into a series of error messages that I'm not sure how to handle.  I have 15 years of quarterly data and I typically create a TS object via something like...

data.ts <- ts(mydata, start = 2002, frequency = 4)

this create a matric as opposed to a vector object as I receive a univariate error when I try to decompose the data using the STL function

data.stl <- stl(data.ts, "periodic")
Error in stl(data.ts, "periodic") : only univariate series are allowed

ok so

is.vector(data.ts)
[1] FALSE

so to convert to a vector I'll use
data.ts <- as.vector(data.ts)

but then I lose the frequency as the periods as the data becomes frequency = 1
data.ts <- stl <- stl(data.ts, "periodic")
Error in stl(data.ts, "periodic") :
   series is not periodic or has less than two periods.

So am I missing a  parameter or is there a more general/proper way to create a time series object? First time I've run into this problem .  I can always decompose  via an alternative methods so there are work arounds.  But just trying to understand what I'm not doing programmatically at this point.

Jeff Reichman


From Achim.Zeileis at uibk.ac.at  Tue Mar 13 15:49:13 2018
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 13 Mar 2018 15:49:13 +0100 (CET)
Subject: [R] Understanding TS objects
In-Reply-To: <1154151976.526964.1520951131081@mail.yahoo.com>
References: <1154151976.526964.1520951131081.ref@mail.yahoo.com>
 <1154151976.526964.1520951131081@mail.yahoo.com>
Message-ID: <alpine.DEB.2.21.1803131543170.11684@paninaro>

On Tue, 13 Mar 2018, JEFFERY REICHMAN wrote:

> R Help Community
>
> I'm trying to understand time series (TS) objects.  Thought I understood 
> but recently have run into a series of error messages that I'm not sure 
> how to handle.  I have 15 years of quarterly data and I typically create 
> a TS object via something like...
>
> data.ts <- ts(mydata, start = 2002, frequency = 4)
>
> this create a matric as opposed to a vector object

This depends on what "mydata" is which you haven't shown...

If "mydata" is a univariate vector, everything works ok:

mydata <- rnorm(15 * 4)
data.ts <- ts(mydata, start = 2002, frequency = 4)
data.stl <- stl(data.ts, "periodic")

However, if "mydata" is a matrix, e.g., a 3-column matrix in the example 
below:

mydata <- matrix(rnorm(15 * 4 * 3), ncol = 3)

then the error occurs.

Furthermore, the same problem will occur if mydata is 1-column matrix or a 
1-column data frame.

> as I receive a univariate error when I try to decompose the data using 
> the STL function
>
> data.stl <- stl(data.ts, "periodic")
> Error in stl(data.ts, "periodic") : only univariate series are allowed
>
> ok so
>
> is.vector(data.ts)
> [1] FALSE

This is always FALSE for a "ts" object, even if it is univariate, because 
it has further attributes, namely the time-series properties (tsp).

> so to convert to a vector I'll use
> data.ts <- as.vector(data.ts)

This will drop the "ts" class.

The cleanest way is probably to create a vector "mydata" and then the 
univariate "data.ts".

hth,
Z

> but then I lose the frequency as the periods as the data becomes frequency = 1
> data.ts <- stl <- stl(data.ts, "periodic")
> Error in stl(data.ts, "periodic") :
>   series is not periodic or has less than two periods.
>
> So am I missing a  parameter or is there a more general/proper way to create a time series object? First time I've run into this problem .  I can always decompose  via an alternative methods so there are work arounds.  But just trying to understand what I'm not doing programmatically at this point.
>
> Jeff Reichman
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.ca.us  Tue Mar 13 15:52:51 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 13 Mar 2018 07:52:51 -0700
Subject: [R] Understanding TS objects
In-Reply-To: <1154151976.526964.1520951131081@mail.yahoo.com>
References: <1154151976.526964.1520951131081.ref@mail.yahoo.com>
 <1154151976.526964.1520951131081@mail.yahoo.com>
Message-ID: <C186E3B5-C86B-43B5-A225-9B9E0911561D@dcn.davis.ca.us>

Perhaps mydata is a matrix or matrix-like object, and you should create one ts object for each column?
-- 
Sent from my phone. Please excuse my brevity.

On March 13, 2018 7:25:31 AM PDT, JEFFERY REICHMAN <reichmanj at sbcglobal.net> wrote:
>R Help Community
>
>I'm trying to understand time series (TS) objects.  Thought I
>understood but recently have run into a series of error messages that
>I'm not sure how to handle.  I have 15 years of quarterly data and I
>typically create a TS object via something like...
>
>data.ts <- ts(mydata, start = 2002, frequency = 4)
>
>this create a matric as opposed to a vector object as I receive a
>univariate error when I try to decompose the data using the STL
>function
>
>data.stl <- stl(data.ts, "periodic")
>Error in stl(data.ts, "periodic") : only univariate series are allowed
>
>ok so
>
>is.vector(data.ts)
>[1] FALSE
>
>so to convert to a vector I'll use
>data.ts <- as.vector(data.ts)
>
>but then I lose the frequency as the periods as the data becomes
>frequency = 1
>data.ts <- stl <- stl(data.ts, "periodic")
>Error in stl(data.ts, "periodic") :
>   series is not periodic or has less than two periods.
>
>So am I missing a  parameter or is there a more general/proper way to
>create a time series object? First time I've run into this problem .  I
>can always decompose  via an alternative methods so there are work
>arounds.  But just trying to understand what I'm not doing
>programmatically at this point.
>
>Jeff Reichman
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Mar 13 17:10:55 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 13 Mar 2018 09:10:55 -0700
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
Message-ID: <CAF8bMcYsvfch0fU7zo5GuW6c0K2cescWTHsL8RYEE-23x92QzA@mail.gmail.com>

Wouldn't that change how simplify='array' is handled?

>  str(sapply(1:3, function(x)diag(x,5,2), simplify="array"))
 int [1:5, 1:2, 1:3] 1 0 0 0 0 0 1 0 0 0 ...
>  str(sapply(1:3, function(x)diag(x,5,2), simplify=TRUE))
 int [1:10, 1:3] 1 0 0 0 0 0 1 0 0 0 ...
>  str(sapply(1:3, function(x)diag(x,5,2), simplify=FALSE))
List of 3
 $ : int [1:5, 1:2] 1 0 0 0 0 0 1 0 0 0
 $ : int [1:5, 1:2] 2 0 0 0 0 0 2 0 0 0
 $ : int [1:5, 1:2] 3 0 0 0 0 0 3 0 0 0


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 13, 2018 at 6:23 AM, Doran, Harold <HDoran at air.org> wrote:

> While working with sapply, the documentation states that the simplify
> argument will yield a vector, matrix etc "when possible". I was curious how
> the code actually defined "as possible" and see this within the function
>
> if (!identical(simplify, FALSE) && length(answer))
>
> This seems superfluous to me, in particular this part:
>
> !identical(simplify, FALSE)
>
> The preceding code could be reduced to
>
> if (simplify && length(answer))
>
> and it would not need to execute the call to identical in order to trigger
> the conditional execution, which is known from the user's simplify = TRUE
> or FALSE inputs. I *think* the extra call to identical is just unnecessary
> overhead in this instance.
>
> Take for example, the following toy example code and benchmark results and
> a small modification to sapply:
>
> myList <- list(a = rnorm(100), b = rnorm(100))
>
> answer <- lapply(X = myList, FUN = length)
> simplify = TRUE
>
> library(microbenchmark)
>
> mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
>         FUN <- match.fun(FUN)
>     answer <- lapply(X = X, FUN = FUN, ...)
>     if (USE.NAMES && is.character(X) && is.null(names(answer)))
>         names(answer) <- X
>     if (simplify && length(answer))
>         simplify2array(answer, higher = (simplify == "array"))
>     else answer
> }
>
>
> > microbenchmark(sapply(myList, length), times = 10000L)
> Unit: microseconds
>                    expr    min     lq     mean median     uq    max neval
>  sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46 10000
> > microbenchmark(mySapply(myList, length), times = 10000L)
> Unit: microseconds
>                      expr    min     lq     mean median     uq      max
> neval
>  mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573 1671.804
> 10000
>
> My benchmark timings show a timing improvement with only that small change
> made and it is seemingly nominal. In my actual work, the sapply function is
> called millions of times and this additional overhead propagates to some
> overall additional computing time.
>
> I have done some limited testing on various real data to verify that the
> objects produced under both variants of the sapply (base R and my modified)
> yield identical objects when simply is both TRUE or FALSE.
>
> Perhaps someone else sees a counterexample where my proposed fix does not
> cause for sapply to behave as expected.
>
> Harold
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From HDoran at air.org  Tue Mar 13 17:14:19 2018
From: HDoran at air.org (Doran, Harold)
Date: Tue, 13 Mar 2018 16:14:19 +0000
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CAF8bMcYsvfch0fU7zo5GuW6c0K2cescWTHsL8RYEE-23x92QzA@mail.gmail.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAF8bMcYsvfch0fU7zo5GuW6c0K2cescWTHsL8RYEE-23x92QzA@mail.gmail.com>
Message-ID: <CY1PR0501MB1273ABA15A8672B720ABD056CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>

You?re right, it sure does. My suggestion causes it to fail when simplify = ?array?


From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Tuesday, March 13, 2018 12:11 PM
To: Doran, Harold <HDoran at air.org>
Cc: r-help at r-project.org
Subject: Re: [R] Possible Improvement to sapply

Wouldn't that change how simplify='array' is handled?

>  str(sapply(1:3, function(x)diag(x,5,2), simplify="array"))
 int [1:5, 1:2, 1:3] 1 0 0 0 0 0 1 0 0 0 ...
>  str(sapply(1:3, function(x)diag(x,5,2), simplify=TRUE))
 int [1:10, 1:3] 1 0 0 0 0 0 1 0 0 0 ...
>  str(sapply(1:3, function(x)diag(x,5,2), simplify=FALSE))
List of 3
 $ : int [1:5, 1:2] 1 0 0 0 0 0 1 0 0 0
 $ : int [1:5, 1:2] 2 0 0 0 0 0 2 0 0 0
 $ : int [1:5, 1:2] 3 0 0 0 0 0 3 0 0 0


Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Tue, Mar 13, 2018 at 6:23 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
While working with sapply, the documentation states that the simplify argument will yield a vector, matrix etc "when possible". I was curious how the code actually defined "as possible" and see this within the function

if (!identical(simplify, FALSE) && length(answer))

This seems superfluous to me, in particular this part:

!identical(simplify, FALSE)

The preceding code could be reduced to

if (simplify && length(answer))

and it would not need to execute the call to identical in order to trigger the conditional execution, which is known from the user's simplify = TRUE or FALSE inputs. I *think* the extra call to identical is just unnecessary overhead in this instance.

Take for example, the following toy example code and benchmark results and a small modification to sapply:

myList <- list(a = rnorm(100), b = rnorm(100))

answer <- lapply(X = myList, FUN = length)
simplify = TRUE

library(microbenchmark)

mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
        FUN <- match.fun(FUN)
    answer <- lapply(X = X, FUN = FUN, ...)
    if (USE.NAMES && is.character(X) && is.null(names(answer)))
        names(answer) <- X
    if (simplify && length(answer))
        simplify2array(answer, higher = (simplify == "array"))
    else answer
}


> microbenchmark(sapply(myList, length), times = 10000L)
Unit: microseconds
                   expr    min     lq     mean median     uq    max neval
 sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46 10000
> microbenchmark(mySapply(myList, length), times = 10000L)
Unit: microseconds
                     expr    min     lq     mean median     uq      max neval
 mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573 1671.804 10000

My benchmark timings show a timing improvement with only that small change made and it is seemingly nominal. In my actual work, the sapply function is called millions of times and this additional overhead propagates to some overall additional computing time.

I have done some limited testing on various real data to verify that the objects produced under both variants of the sapply (base R and my modified) yield identical objects when simply is both TRUE or FALSE.

Perhaps someone else sees a counterexample where my proposed fix does not cause for sapply to behave as expected.

Harold

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From HDoran at air.org  Tue Mar 13 17:21:11 2018
From: HDoran at air.org (Doran, Harold)
Date: Tue, 13 Mar 2018 16:21:11 +0000
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CAF8bMcZcBMKoiDpZ-5Z6q+NWC4c=eFJO8TXJAOpMLVRhjL1mKw@mail.gmail.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>
 <CY1PR0501MB12736C801550165F43C15EE5CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAF8bMcZcBMKoiDpZ-5Z6q+NWC4c=eFJO8TXJAOpMLVRhjL1mKw@mail.gmail.com>
Message-ID: <CY1PR0501MB1273F66CB451E69E45A5BEB4CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>

Quite possibly, and I?ll look into that. Aside from the work I was doing, however, I wonder if there is a way such that sapply could avoid the overhead of having to call the identical function to determine the conditional path.



From: William Dunlap [mailto:wdunlap at tibco.com]
Sent: Tuesday, March 13, 2018 12:14 PM
To: Doran, Harold <HDoran at air.org>
Cc: Martin Morgan <martin.morgan at roswellpark.org>; r-help at r-project.org
Subject: Re: [R] Possible Improvement to sapply

Could your code use vapply instead of sapply?  vapply forces you to declare the type and dimensions
of FUN's output and stops if any call to FUN does not match the declaration.  It can use much less
memory and time than sapply because it fills in the output array as it goes instead of calling lapply()
and seeing how it could be simplified.

Bill Dunlap
TIBCO Software
wdunlap tibco.com<http://tibco.com>

On Tue, Mar 13, 2018 at 7:06 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
Martin

In terms of context of the actual problem, sapply is called millions of times because the work involves scoring individual students who took a test. A score for student A is generated and then student B and such and there are millions of students. The psychometric process of scoring students is complex and our code makes use of sapply many times for each student.

The toy example used length just to illustrate, our actual code doesn't do that. But your point is well taken, there may be a very good counterexample why my proposal doesn't achieve the goal is a generalizable way.



-----Original Message-----
From: Martin Morgan [mailto:martin.morgan at roswellpark.org<mailto:martin.morgan at roswellpark.org>]
Sent: Tuesday, March 13, 2018 9:43 AM
To: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>; 'r-help at r-project.org<mailto:r-help at r-project.org>' <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Possible Improvement to sapply



On 03/13/2018 09:23 AM, Doran, Harold wrote:
> While working with sapply, the documentation states that the simplify
> argument will yield a vector, matrix etc "when possible". I was
> curious how the code actually defined "as possible" and see this
> within the function
>
> if (!identical(simplify, FALSE) && length(answer))
>
> This seems superfluous to me, in particular this part:
>
> !identical(simplify, FALSE)
>
> The preceding code could be reduced to
>
> if (simplify && length(answer))
>
> and it would not need to execute the call to identical in order to trigger the conditional execution, which is known from the user's simplify = TRUE or FALSE inputs. I *think* the extra call to identical is just unnecessary overhead in this instance.
>
> Take for example, the following toy example code and benchmark results and a small modification to sapply:
>
> myList <- list(a = rnorm(100), b = rnorm(100))
>
> answer <- lapply(X = myList, FUN = length) simplify = TRUE
>
> library(microbenchmark)
>
> mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
>       FUN <- match.fun(FUN)
>      answer <- lapply(X = X, FUN = FUN, ...)
>      if (USE.NAMES && is.character(X) && is.null(names(answer)))
>          names(answer) <- X
>      if (simplify && length(answer))
>          simplify2array(answer, higher = (simplify == "array"))
>      else answer
> }
>
>
>> microbenchmark(sapply(myList, length), times = 10000L)
> Unit: microseconds
>                     expr    min     lq     mean median     uq    max neval
>   sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46
> 10000
>> microbenchmark(mySapply(myList, length), times = 10000L)
> Unit: microseconds
>                       expr    min     lq     mean median     uq      max neval
>   mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573
> 1671.804 10000
>
> My benchmark timings show a timing improvement with only that small change made and it is seemingly nominal. In my actual work, the sapply function is called millions of times and this additional overhead propagates to some overall additional computing time.
>
> I have done some limited testing on various real data to verify that the objects produced under both variants of the sapply (base R and my modified) yield identical objects when simply is both TRUE or FALSE.
>
> Perhaps someone else sees a counterexample where my proposed fix does not cause for sapply to behave as expected.
>

Check out ?sapply for possible values of `simplify=` to see why your proposal is not adequate.

For your example, lengths() is an order of magnitude faster than sapply(., length). This is a example of the advantages of vectorization (single call to an R function implemented in C) versus iteration (`for` loops but also the *apply family calling an R function many times).
vapply() might also be relevant.

Often performance improvements come from looking one layer up from where the problem occurs and re-thinking the algorithm. Why would one need to call sapply() millions of times, in a situation where this becomes rate-limiting? Can the algorithm be re-implemented to avoid this step?

Martin Morgan

> Harold
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Tue Mar 13 17:22:23 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 13 Mar 2018 17:22:23 +0100
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CY1PR0501MB1273ABA15A8672B720ABD056CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAF8bMcYsvfch0fU7zo5GuW6c0K2cescWTHsL8RYEE-23x92QzA@mail.gmail.com>
 <CY1PR0501MB1273ABA15A8672B720ABD056CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
Message-ID: <23207.64191.378705.474579@stat.math.ethz.ch>

>>>>> Doran, Harold <HDoran at air.org>
>>>>>     on Tue, 13 Mar 2018 16:14:19 +0000 writes:

    > You?re right, it sure does. My suggestion causes it to fail when simplify = ?array?

    > From: William Dunlap [mailto:wdunlap at tibco.com]
    > Sent: Tuesday, March 13, 2018 12:11 PM
    > To: Doran, Harold <HDoran at air.org>
    > Cc: r-help at r-project.org
    > Subject: Re: [R] Possible Improvement to sapply

    > Wouldn't that change how simplify='array' is handled?

    >> str(sapply(1:3, function(x)diag(x,5,2), simplify="array"))
    > int [1:5, 1:2, 1:3] 1 0 0 0 0 0 1 0 0 0 ...
    >> str(sapply(1:3, function(x)diag(x,5,2), simplify=TRUE))
    > int [1:10, 1:3] 1 0 0 0 0 0 1 0 0 0 ...
    >> str(sapply(1:3, function(x)diag(x,5,2), simplify=FALSE))
    > List of 3
    > $ : int [1:5, 1:2] 1 0 0 0 0 0 1 0 0 0
    > $ : int [1:5, 1:2] 2 0 0 0 0 0 2 0 0 0
    > $ : int [1:5, 1:2] 3 0 0 0 0 0 3 0 0 0


    > Bill Dunlap
    > TIBCO Software
    > wdunlap tibco.com<http://tibco.com>

Yes, indeed, thank you Bill!

I sometimes marvel at how much the mental capacities of R core
are underestimated.  Of course, nobody is perfect, but the bugs
we produce are really more subtle than that ...  ;-)

Martin Maechler
R core  


    > On Tue, Mar 13, 2018 at 6:23 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
    > While working with sapply, the documentation states that the simplify argument will yield a vector, matrix etc "when possible". I was curious how the code actually defined "as possible" and see this within the function

    > if (!identical(simplify, FALSE) && length(answer))

    > This seems superfluous to me, in particular this part:

    > !identical(simplify, FALSE)

    > The preceding code could be reduced to

    > if (simplify && length(answer))

    > and it would not need to execute the call to identical in order to trigger the conditional execution, which is known from the user's simplify = TRUE or FALSE inputs. I *think* the extra call to identical is just unnecessary overhead in this instance.

    > Take for example, the following toy example code and benchmark results and a small modification to sapply:

    > myList <- list(a = rnorm(100), b = rnorm(100))

    > answer <- lapply(X = myList, FUN = length)
    > simplify = TRUE

    > library(microbenchmark)

    > mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
    > FUN <- match.fun(FUN)
    > answer <- lapply(X = X, FUN = FUN, ...)
    > if (USE.NAMES && is.character(X) && is.null(names(answer)))
    > names(answer) <- X
    > if (simplify && length(answer))
    > simplify2array(answer, higher = (simplify == "array"))
    > else answer
    > }


    >> microbenchmark(sapply(myList, length), times = 10000L)
    > Unit: microseconds
    > expr    min     lq     mean median     uq    max neval
    > sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46 10000
    >> microbenchmark(mySapply(myList, length), times = 10000L)
    > Unit: microseconds
    > expr    min     lq     mean median     uq      max neval
    > mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573 1671.804 10000

    > My benchmark timings show a timing improvement with only that small change made and it is seemingly nominal. In my actual work, the sapply function is called millions of times and this additional overhead propagates to some overall additional computing time.

    > I have done some limited testing on various real data to verify that the objects produced under both variants of the sapply (base R and my modified) yield identical objects when simply is both TRUE or FALSE.

    > Perhaps someone else sees a counterexample where my proposed fix does not cause for sapply to behave as expected.

    > Harold

    > ______________________________________________
    > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


    > [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Tue Mar 13 17:14:26 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 13 Mar 2018 09:14:26 -0700
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CY1PR0501MB12736C801550165F43C15EE5CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>
 <CY1PR0501MB12736C801550165F43C15EE5CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
Message-ID: <CAF8bMcZcBMKoiDpZ-5Z6q+NWC4c=eFJO8TXJAOpMLVRhjL1mKw@mail.gmail.com>

Could your code use vapply instead of sapply?  vapply forces you to declare
the type and dimensions
of FUN's output and stops if any call to FUN does not match the
declaration.  It can use much less
memory and time than sapply because it fills in the output array as it goes
instead of calling lapply()
and seeing how it could be simplified.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Mar 13, 2018 at 7:06 AM, Doran, Harold <HDoran at air.org> wrote:

> Martin
>
> In terms of context of the actual problem, sapply is called millions of
> times because the work involves scoring individual students who took a
> test. A score for student A is generated and then student B and such and
> there are millions of students. The psychometric process of scoring
> students is complex and our code makes use of sapply many times for each
> student.
>
> The toy example used length just to illustrate, our actual code doesn't do
> that. But your point is well taken, there may be a very good counterexample
> why my proposal doesn't achieve the goal is a generalizable way.
>
>
>
> -----Original Message-----
> From: Martin Morgan [mailto:martin.morgan at roswellpark.org]
> Sent: Tuesday, March 13, 2018 9:43 AM
> To: Doran, Harold <HDoran at air.org>; 'r-help at r-project.org' <
> r-help at r-project.org>
> Subject: Re: [R] Possible Improvement to sapply
>
>
>
> On 03/13/2018 09:23 AM, Doran, Harold wrote:
> > While working with sapply, the documentation states that the simplify
> > argument will yield a vector, matrix etc "when possible". I was
> > curious how the code actually defined "as possible" and see this
> > within the function
> >
> > if (!identical(simplify, FALSE) && length(answer))
> >
> > This seems superfluous to me, in particular this part:
> >
> > !identical(simplify, FALSE)
> >
> > The preceding code could be reduced to
> >
> > if (simplify && length(answer))
> >
> > and it would not need to execute the call to identical in order to
> trigger the conditional execution, which is known from the user's simplify
> = TRUE or FALSE inputs. I *think* the extra call to identical is just
> unnecessary overhead in this instance.
> >
> > Take for example, the following toy example code and benchmark results
> and a small modification to sapply:
> >
> > myList <- list(a = rnorm(100), b = rnorm(100))
> >
> > answer <- lapply(X = myList, FUN = length) simplify = TRUE
> >
> > library(microbenchmark)
> >
> > mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
> >       FUN <- match.fun(FUN)
> >      answer <- lapply(X = X, FUN = FUN, ...)
> >      if (USE.NAMES && is.character(X) && is.null(names(answer)))
> >          names(answer) <- X
> >      if (simplify && length(answer))
> >          simplify2array(answer, higher = (simplify == "array"))
> >      else answer
> > }
> >
> >
> >> microbenchmark(sapply(myList, length), times = 10000L)
> > Unit: microseconds
> >                     expr    min     lq     mean median     uq    max
> neval
> >   sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46
> > 10000
> >> microbenchmark(mySapply(myList, length), times = 10000L)
> > Unit: microseconds
> >                       expr    min     lq     mean median     uq      max
> neval
> >   mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573
> > 1671.804 10000
> >
> > My benchmark timings show a timing improvement with only that small
> change made and it is seemingly nominal. In my actual work, the sapply
> function is called millions of times and this additional overhead
> propagates to some overall additional computing time.
> >
> > I have done some limited testing on various real data to verify that the
> objects produced under both variants of the sapply (base R and my modified)
> yield identical objects when simply is both TRUE or FALSE.
> >
> > Perhaps someone else sees a counterexample where my proposed fix does
> not cause for sapply to behave as expected.
> >
>
> Check out ?sapply for possible values of `simplify=` to see why your
> proposal is not adequate.
>
> For your example, lengths() is an order of magnitude faster than sapply(.,
> length). This is a example of the advantages of vectorization (single call
> to an R function implemented in C) versus iteration (`for` loops but also
> the *apply family calling an R function many times).
> vapply() might also be relevant.
>
> Often performance improvements come from looking one layer up from where
> the problem occurs and re-thinking the algorithm. Why would one need to
> call sapply() millions of times, in a situation where this becomes
> rate-limiting? Can the algorithm be re-implemented to avoid this step?
>
> Martin Morgan
>
> > Harold
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
> This email message may contain legally privileged and/or confidential
> information.  If you are not the intended recipient(s), or the employee or
> agent responsible for the delivery of this message to the intended
> recipient(s), you are hereby notified that any disclosure, copying,
> distribution, or use of this email message is prohibited.  If you have
> received this message in error, please notify the sender immediately by
> e-mail and delete this email message from your computer. Thank you.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Tue Mar 13 18:12:55 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 13 Mar 2018 10:12:55 -0700
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CY1PR0501MB1273F66CB451E69E45A5BEB4CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>
 <CY1PR0501MB12736C801550165F43C15EE5CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAF8bMcZcBMKoiDpZ-5Z6q+NWC4c=eFJO8TXJAOpMLVRhjL1mKw@mail.gmail.com>
 <CY1PR0501MB1273F66CB451E69E45A5BEB4CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
Message-ID: <CAFDcVCSpunZ9HoDZznvYWY=+vA93fUdM=UFKz2hGY-SgE+K=Kw@mail.gmail.com>

FYI, in R devel (to become 3.5.0), there's isFALSE() which will cut
some corners compared to identical():

> microbenchmark::microbenchmark(identical(FALSE, FALSE), isFALSE(FALSE))
Unit: nanoseconds
                    expr min   lq    mean median     uq   max neval
 identical(FALSE, FALSE) 984 1138 1694.13 1218.0 1337.5 13584   100
          isFALSE(FALSE) 713  761 1133.53  809.5  871.5 18619   100

> microbenchmark::microbenchmark(identical(TRUE, FALSE), isFALSE(TRUE))
Unit: nanoseconds
                   expr  min     lq    mean median   uq   max neval
 identical(TRUE, FALSE) 1009 1103.5 2228.20 1170.5 1357 14346   100
          isFALSE(TRUE)  718  760.0 1298.98  798.0  898 17782   100

> microbenchmark::microbenchmark(identical("array", FALSE), isFALSE("array"))
Unit: nanoseconds
                      expr min     lq    mean median     uq  max neval
 identical("array", FALSE) 975 1058.5 1257.95 1119.5 1250.0 9299   100
          isFALSE("array") 409  433.5  658.76  446.0  476.5 9383   100

That could probably be used also is sapply().  The difference is that
isFALSE() is a bit more liberal than identical(x, FALSE), e.g.

> isFALSE(c(a = FALSE))
[1] TRUE
> identical(c(a = FALSE), FALSE)
[1] FALSE

Assuming the latter is not an issue, there are 69 places in base R
where isFALSE() could be used:

$ grep -E "identical[(][^,]+,[ ]*FALSE[)]" -r --include="*.R" | grep
-F "/R/" | wc
     69     326    5472

and another 59 where isTRUE() can be used:

$ grep -E "identical[(][^,]+,[ ]*TRUE[)]" -r --include="*.R" | grep -F
"/R/" | wc
     59     307    5021

/Henrik

On Tue, Mar 13, 2018 at 9:21 AM, Doran, Harold <HDoran at air.org> wrote:
> Quite possibly, and I?ll look into that. Aside from the work I was doing, however, I wonder if there is a way such that sapply could avoid the overhead of having to call the identical function to determine the conditional path.
>
>
>
> From: William Dunlap [mailto:wdunlap at tibco.com]
> Sent: Tuesday, March 13, 2018 12:14 PM
> To: Doran, Harold <HDoran at air.org>
> Cc: Martin Morgan <martin.morgan at roswellpark.org>; r-help at r-project.org
> Subject: Re: [R] Possible Improvement to sapply
>
> Could your code use vapply instead of sapply?  vapply forces you to declare the type and dimensions
> of FUN's output and stops if any call to FUN does not match the declaration.  It can use much less
> memory and time than sapply because it fills in the output array as it goes instead of calling lapply()
> and seeing how it could be simplified.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com<http://tibco.com>
>
> On Tue, Mar 13, 2018 at 7:06 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> Martin
>
> In terms of context of the actual problem, sapply is called millions of times because the work involves scoring individual students who took a test. A score for student A is generated and then student B and such and there are millions of students. The psychometric process of scoring students is complex and our code makes use of sapply many times for each student.
>
> The toy example used length just to illustrate, our actual code doesn't do that. But your point is well taken, there may be a very good counterexample why my proposal doesn't achieve the goal is a generalizable way.
>
>
>
> -----Original Message-----
> From: Martin Morgan [mailto:martin.morgan at roswellpark.org<mailto:martin.morgan at roswellpark.org>]
> Sent: Tuesday, March 13, 2018 9:43 AM
> To: Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>>; 'r-help at r-project.org<mailto:r-help at r-project.org>' <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] Possible Improvement to sapply
>
>
>
> On 03/13/2018 09:23 AM, Doran, Harold wrote:
>> While working with sapply, the documentation states that the simplify
>> argument will yield a vector, matrix etc "when possible". I was
>> curious how the code actually defined "as possible" and see this
>> within the function
>>
>> if (!identical(simplify, FALSE) && length(answer))
>>
>> This seems superfluous to me, in particular this part:
>>
>> !identical(simplify, FALSE)
>>
>> The preceding code could be reduced to
>>
>> if (simplify && length(answer))
>>
>> and it would not need to execute the call to identical in order to trigger the conditional execution, which is known from the user's simplify = TRUE or FALSE inputs. I *think* the extra call to identical is just unnecessary overhead in this instance.
>>
>> Take for example, the following toy example code and benchmark results and a small modification to sapply:
>>
>> myList <- list(a = rnorm(100), b = rnorm(100))
>>
>> answer <- lapply(X = myList, FUN = length) simplify = TRUE
>>
>> library(microbenchmark)
>>
>> mySapply <- function (X, FUN, ..., simplify = TRUE, USE.NAMES = TRUE){
>>       FUN <- match.fun(FUN)
>>      answer <- lapply(X = X, FUN = FUN, ...)
>>      if (USE.NAMES && is.character(X) && is.null(names(answer)))
>>          names(answer) <- X
>>      if (simplify && length(answer))
>>          simplify2array(answer, higher = (simplify == "array"))
>>      else answer
>> }
>>
>>
>>> microbenchmark(sapply(myList, length), times = 10000L)
>> Unit: microseconds
>>                     expr    min     lq     mean median     uq    max neval
>>   sapply(myList, length) 14.156 15.572 16.67603 15.926 16.634 650.46
>> 10000
>>> microbenchmark(mySapply(myList, length), times = 10000L)
>> Unit: microseconds
>>                       expr    min     lq     mean median     uq      max neval
>>   mySapply(myList, length) 13.095 14.864 16.02964 15.218 15.573
>> 1671.804 10000
>>
>> My benchmark timings show a timing improvement with only that small change made and it is seemingly nominal. In my actual work, the sapply function is called millions of times and this additional overhead propagates to some overall additional computing time.
>>
>> I have done some limited testing on various real data to verify that the objects produced under both variants of the sapply (base R and my modified) yield identical objects when simply is both TRUE or FALSE.
>>
>> Perhaps someone else sees a counterexample where my proposed fix does not cause for sapply to behave as expected.
>>
>
> Check out ?sapply for possible values of `simplify=` to see why your proposal is not adequate.
>
> For your example, lengths() is an order of magnitude faster than sapply(., length). This is a example of the advantages of vectorization (single call to an R function implemented in C) versus iteration (`for` loops but also the *apply family calling an R function many times).
> vapply() might also be relevant.
>
> Often performance improvements come from looking one layer up from where the problem occurs and re-thinking the algorithm. Why would one need to call sapply() millions of times, in a situation where this becomes rate-limiting? Can the algorithm be re-implemented to avoid this step?
>
> Martin Morgan
>
>> Harold
>>
>> ______________________________________________
>> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> This email message may contain legally privileged and/or confidential information.  If you are not the intended recipient(s), or the employee or agent responsible for the delivery of this message to the intended recipient(s), you are hereby notified that any disclosure, copying, distribution, or use of this email message is prohibited.  If you have received this message in error, please notify the sender immediately by e-mail and delete this email message from your computer. Thank you.
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Mar 13 19:11:00 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 13 Mar 2018 11:11:00 -0700
Subject: [R] Need Help on Batch forecasting for multiple items at one go
In-Reply-To: <BM1PR0101MB19214DF859CECD4B55554CA9B9D20@BM1PR0101MB1921.INDPRD01.PROD.OUTLOOK.COM>
References: <BM1PR0101MB19214DF859CECD4B55554CA9B9D20@BM1PR0101MB1921.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <28BFCB49-2346-48B4-B1C5-BBF7913F4234@comcast.net>


> On Mar 12, 2018, at 8:47 PM, Manish Mukherjee <manishmukherjee at hotmail.com> wrote:
> 
> Hi All,
> 
> 
> I have time series weekly data for number of servers for 62 weeks. i have to forecast for next 8 weeks on what will be the usage.  i have a challenge in the code where it is giving output for the last week value of  all the servers, instead i need the output for next 8 weeks . i am attaching the data and my r script for your reference.

Your attachment failed to come through. Your mail client failed to label it as an acceptable format.
> 
> 
> 
> Thanks & Regards
> Manish Mukherjee
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From milos.zarkovic at gmail.com  Tue Mar 13 21:21:39 2018
From: milos.zarkovic at gmail.com (=?UTF-8?B?TWlsb8WhIMW9YXJrb3ZpxIc=?=)
Date: Tue, 13 Mar 2018 21:21:39 +0100
Subject: [R] plot problem
Message-ID: <CANgWSHAKX4oX5FGR2ep3Moug4CDETxtrMrjM_er2izmyxDS6pA@mail.gmail.com>

Hi,

I am just curious why does this happen:

I use Goldencheetah to analyse my run. It can call R to do further analysis.
I run into interesting problem (for me at least).

If I plot data using plot(d$time,d$heart.rate) everything is OK
if I use plot(d$heart.rate~d$time) I got error:

Error in inDL(x, as.logical(local), as.logical(now), ...) :
unable to load shared object TC:/Programs/Sci/R/R-3.4.3/
library/stats/libs/x64/stats.dllr:
LoadLibrary failure: The specified module could not be found.
In addition: There were 18 warnings (use warnings() to see them)

if I use hist(d$heart.rate) I got the same error.

R works perfectly in Rstudio and in plain installation

Problem is solved (thanks to Goldencheetah users) by adding path
C:/Programs/Sci/R/R-3.4.3/bin/x64
I thought that plot(d$time,d$heart.rate)  and plot(d$heart.rate~d$time)
are actually the same.

regards

Milo?

Milo? ?arkovi?
Professor of Internal Medicine
School of Medicine, University of Belgrade
Clinic of Endocrinology, Clinical Centre of Serbia
11000 Belgrade
PAK 112113
Serbia
email milos.zarkovic at med.bg.ac.rs
        milos.zarkovic at gmail.com

	[[alternative HTML version deleted]]


From ntuzov at beacon.partek.com  Tue Mar 13 22:26:35 2018
From: ntuzov at beacon.partek.com (Nik Tuzov)
Date: Tue, 13 Mar 2018 16:26:35 -0500 (CDT)
Subject: [R] Learning advanced R
In-Reply-To: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
Message-ID: <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>


Hello:

Could you please suggest the best way to become an "advanced" R programmer.
I went through "R for dummies" by de Vries and Meys and I can see two ways
to proceed:

1) Get a more advanced textbook. E.g. could you recommend Gentleman, 
"R for Bioinformatics"?

2) Because textbooks are limited and become obsolete fast, I can focus on learning state-of-the-art packages, 
but for that I need to find a list of most useful general purpose packages (foreach, doParallel, etc) that is
updated in real time. Does such list exist?

Your recommendations are very welcome.

Thanks,
Nik


From markleeds2 at gmail.com  Tue Mar 13 22:31:02 2018
From: markleeds2 at gmail.com (Mark Leeds)
Date: Tue, 13 Mar 2018 17:31:02 -0400
Subject: [R] Learning advanced R
In-Reply-To: <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
Message-ID: <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>

See Hadley's advanced R along Thomas Mailund's books. I haven't gone
through them carefully but they both
seem  (from what I've looked at ) to be the best ones for that. Mentions of
others are appreciated.




On Tue, Mar 13, 2018 at 5:26 PM, Nik Tuzov <ntuzov at beacon.partek.com> wrote:

>
> Hello:
>
> Could you please suggest the best way to become an "advanced" R programmer.
> I went through "R for dummies" by de Vries and Meys and I can see two ways
> to proceed:
>
> 1) Get a more advanced textbook. E.g. could you recommend Gentleman,
> "R for Bioinformatics"?
>
> 2) Because textbooks are limited and become obsolete fast, I can focus on
> learning state-of-the-art packages,
> but for that I need to find a list of most useful general purpose packages
> (foreach, doParallel, etc) that is
> updated in real time. Does such list exist?
>
> Your recommendations are very welcome.
>
> Thanks,
> Nik
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar 13 22:49:50 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Tue, 13 Mar 2018 14:49:50 -0700
Subject: [R] Learning advanced R
In-Reply-To: <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
Message-ID: <CAGxFJbRZMrO2GW7H0qd4XU6MzHR7O4On1HOcMExuEQLTVNoEuA@mail.gmail.com>

See here for some suggestions:

https://www.rstudio.com/online-learning/#R

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Mar 13, 2018 at 2:31 PM, Mark Leeds <markleeds2 at gmail.com> wrote:

> See Hadley's advanced R along Thomas Mailund's books. I haven't gone
> through them carefully but they both
> seem  (from what I've looked at ) to be the best ones for that. Mentions of
> others are appreciated.
>
>
>
>
> On Tue, Mar 13, 2018 at 5:26 PM, Nik Tuzov <ntuzov at beacon.partek.com>
> wrote:
>
> >
> > Hello:
> >
> > Could you please suggest the best way to become an "advanced" R
> programmer.
> > I went through "R for dummies" by de Vries and Meys and I can see two
> ways
> > to proceed:
> >
> > 1) Get a more advanced textbook. E.g. could you recommend Gentleman,
> > "R for Bioinformatics"?
> >
> > 2) Because textbooks are limited and become obsolete fast, I can focus on
> > learning state-of-the-art packages,
> > but for that I need to find a list of most useful general purpose
> packages
> > (foreach, doParallel, etc) that is
> > updated in real time. Does such list exist?
> >
> > Your recommendations are very welcome.
> >
> > Thanks,
> > Nik
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Tue Mar 13 23:13:45 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 13 Mar 2018 15:13:45 -0700 (PDT)
Subject: [R] Learning advanced R
In-Reply-To: <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>

On Tue, 13 Mar 2018, Mark Leeds wrote:

> See Hadley's advanced R

   +1 A very well writte, highly useful book. Recommended.

Rich


From huertaya at protonmail.com  Wed Mar 14 03:47:56 2018
From: huertaya at protonmail.com (Yectli Huerta)
Date: Tue, 13 Mar 2018 22:47:56 -0400
Subject: [R] ggplot and boxplots
In-Reply-To: <CAGx1TMBkh2wV=ioCVZ6xQ7dQOQccrstG2ynAK-sMe4gs848J0A@mail.gmail.com>
References: <Pd8GCAd6v2c6WkRi3YegvrlbL_M7cnUxqNZ6PmTFKzD-g4twA85BxtBQ9n4zBpX3S2LMU2Bb5iwOBEkJiiZw9hiZ0ziabD85pVlr_ifI4C8=@protonmail.com>
 <CAGx1TMBkh2wV=ioCVZ6xQ7dQOQccrstG2ynAK-sMe4gs848J0A@mail.gmail.com>
Message-ID: <gfKPpwci77ufvGyQEVpo1e1_MEGiQ4hqtAf5WK3ouh0PUH1-RyV8DNAqfnqosQTukJtldZwFrZ6okuC72iKqqi14CW7vDWIq7vdBrqox0xE=@protonmail.com>


On March 12, 2018 11:59 PM, Richard M. Heiberger <rmh at temple.edu> wrote:

> It looks like your V3 is a factor.
> 
> testing_ggplot <- data.frame(
> 
> V1=factor(c(256, 256, 256, 272, 272, 272)),
> 
> V2=c("Disabled", "Disabled", "Enabled", "Disabled", "Enabled", "Enabled"),
> 
> V3=681:686)
> 

thanks for the explanation and solution. 

yah


From ericjberger at gmail.com  Wed Mar 14 09:13:00 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 14 Mar 2018 10:13:00 +0200
Subject: [R] Learning advanced R
In-Reply-To: <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
Message-ID: <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>

Bert's suggestion is good as a pointer to a variety of resources.
Sticking to the book format there are two of Hadley Wickham's books, which
have the advantage that they are freely available.
You can either read them online or download the source from github and
create your own copy (which you can then print, if desired.)
1. "R for Data Science"
     online: http://r4ds.had.co.nz/
     github: https://github.com/hadley/r4ds
2. "Advanced R"
     online: https://adv-r.hadley.nz/
     github: https://github.com/hadley/adv-r

Best,
Eric



On Wed, Mar 14, 2018 at 12:13 AM, Rich Shepard <rshepard at appl-ecosys.com>
wrote:

> On Tue, 13 Mar 2018, Mark Leeds wrote:
>
> See Hadley's advanced R
>>
>
>   +1 A very well writte, highly useful book. Recommended.
>
> Rich
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Mar 14 10:11:26 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Mar 2018 10:11:26 +0100
Subject: [R] Possible Improvement to sapply
In-Reply-To: <CAFDcVCSpunZ9HoDZznvYWY=+vA93fUdM=UFKz2hGY-SgE+K=Kw@mail.gmail.com>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>
 <CY1PR0501MB12736C801550165F43C15EE5CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAF8bMcZcBMKoiDpZ-5Z6q+NWC4c=eFJO8TXJAOpMLVRhjL1mKw@mail.gmail.com>
 <CY1PR0501MB1273F66CB451E69E45A5BEB4CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAFDcVCSpunZ9HoDZznvYWY=+vA93fUdM=UFKz2hGY-SgE+K=Kw@mail.gmail.com>
Message-ID: <23208.59198.42401.412959@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>     on Tue, 13 Mar 2018 10:12:55 -0700 writes:

> FYI, in R devel (to become 3.5.0), there's isFALSE() which will cut
> some corners compared to identical():

> > microbenchmark::microbenchmark(identical(FALSE, FALSE), isFALSE(FALSE))
> Unit: nanoseconds
>                     expr min   lq    mean median     uq   max neval
>  identical(FALSE, FALSE) 984 1138 1694.13 1218.0 1337.5 13584   100
>           isFALSE(FALSE) 713  761 1133.53  809.5  871.5 18619   100

> > microbenchmark::microbenchmark(identical(TRUE, FALSE), isFALSE(TRUE))
> Unit: nanoseconds
>                    expr  min     lq    mean median   uq   max neval
>  identical(TRUE, FALSE) 1009 1103.5 2228.20 1170.5 1357 14346   100
>           isFALSE(TRUE)  718  760.0 1298.98  798.0  898 17782   100

> > microbenchmark::microbenchmark(identical("array", FALSE), isFALSE("array"))
> Unit: nanoseconds
>                       expr min     lq    mean median     uq  max neval
>  identical("array", FALSE) 975 1058.5 1257.95 1119.5 1250.0 9299   100
>           isFALSE("array") 409  433.5  658.76  446.0  476.5 9383   100

Thank you Henrik!

The speed of the new isTRUE() and isFALSE() is indeed amazing
compared to identical() which was written to be fast itself.

Note that the new code goes back to a proposal by  Herv? Pag?s
(of Bioconductor fame) in a thread with R core in April 2017.
The goal of the new code actually *was*  to allow call like

  isTRUE(c(a = TRUE))   

to become TRUE rather than improving speed.
The new source code is at the end of  R/src/library/base/R/identical.R

## NB:  is.logical(.) will never dispatch:
## --                 base::is.logical(x)  <==>  typeof(x) == "logical"
isTRUE  <- function(x) is.logical(x) && length(x) == 1L && !is.na(x) && x
isFALSE <- function(x) is.logical(x) && length(x) == 1L && !is.na(x) && !x

and one *reason* this is so fast is that all  6  functions which
are called are primitives :

> sapply(codetools::findGlobals(isTRUE), function(fn) is.primitive(get(fn)))
         !         &&         == is.logical      is.na     length 
      TRUE       TRUE       TRUE       TRUE       TRUE       TRUE 

and a 2nd reason is probably with the many recent improvements of the
byte compiler.


> That could probably be used also is sapply().  The difference is that
> isFALSE() is a bit more liberal than identical(x, FALSE), e.g.

> > isFALSE(c(a = FALSE))
> [1] TRUE
> > identical(c(a = FALSE), FALSE)
> [1] FALSE

> Assuming the latter is not an issue, there are 69 places in base R
> where isFALSE() could be used:

> $ grep -E "identical[(][^,]+,[ ]*FALSE[)]" -r --include="*.R" | grep -F "/R/" | wc
>      69     326    5472

> and another 59 where isTRUE() can be used:

> $ grep -E "identical[(][^,]+,[ ]*TRUE[)]" -r --include="*.R" | grep -F "/R/" | wc
>      59     307    5021

Beautiful use of  'grep' -- thank you for those above, as well.
It does need a quick manual check, but if I use the above grep
from Emacs (via  'M-x grep')  or even better via a TAGS table
and M-x tags-query-replace  I should be able to do the changes
pretty quickly... and will start looking into that later today.

Interestingly and to my great pleasure, the first part of the
'Subject' of this mailing list thread, "Possible Improvement",
*has* become true after all --

-- thanks to Henrik !

Martin Maechler
ETH Zurich



> On Tue, Mar 13, 2018 at 9:21 AM, Doran, Harold <HDoran at air.org> wrote:
> > Quite possibly, and I?ll look into that. Aside from the work I was doing, however, I wonder if there is a way such that sapply could avoid the overhead of having to call the identical function to determine the conditional path.
> >
> >
> >
> > From: William Dunlap [mailto:wdunlap at tibco.com]
> > Sent: Tuesday, March 13, 2018 12:14 PM
> > To: Doran, Harold <HDoran at air.org>
> > Cc: Martin Morgan <martin.morgan at roswellpark.org>; r-help at r-project.org
> > Subject: Re: [R] Possible Improvement to sapply
> >
> > Could your code use vapply instead of sapply?  vapply forces you to declare the type and dimensions
> > of FUN's output and stops if any call to FUN does not match the declaration.  It can use much less
> > memory and time than sapply because it fills in the output array as it goes instead of calling lapply()
> > and seeing how it could be simplified.
> >
> > Bill Dunlap
> > TIBCO Software
> > wdunlap tibco.com<http://tibco.com>
> >
> > On Tue, Mar 13, 2018 at 7:06 AM, Doran, Harold <HDoran at air.org<mailto:HDoran at air.org>> wrote:
> > Martin
> >
> > In terms of context of the actual problem, sapply is called millions of times because the work involves scoring individual students who took a test. A score for student A is generated and then student B and such and there are millions of students. The psychometric process of scoring students is complex and our code makes use of sapply many times for each student.
> >
> > The toy example used length just to illustrate, our actual code doesn't do that. But your point is well taken, there may be a very good counterexample why my proposal doesn't achieve the goal is a generalizable way.
> >


[.................]


From HDoran at air.org  Wed Mar 14 10:14:57 2018
From: HDoran at air.org (Doran, Harold)
Date: Wed, 14 Mar 2018 09:14:57 +0000
Subject: [R] Possible Improvement to sapply
In-Reply-To: <23208.59198.42401.412959@stat.math.ethz.ch>
References: <CY1PR0501MB1273DFADC1C8F549911A173BCAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <aa09c6b8-62ec-2b8e-a328-db265a7ad1a1@roswellpark.org>
 <CY1PR0501MB12736C801550165F43C15EE5CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAF8bMcZcBMKoiDpZ-5Z6q+NWC4c=eFJO8TXJAOpMLVRhjL1mKw@mail.gmail.com>
 <CY1PR0501MB1273F66CB451E69E45A5BEB4CAD20@CY1PR0501MB1273.namprd05.prod.outlook.com>
 <CAFDcVCSpunZ9HoDZznvYWY=+vA93fUdM=UFKz2hGY-SgE+K=Kw@mail.gmail.com>
 <23208.59198.42401.412959@stat.math.ethz.ch>
Message-ID: <D6CE5FF7.4ED21%hdoran@air.org>

Well thanks, Martin, and glad to see there is some potential here. This
wasn?t reported as a bug, but as you note really as a question originally
and with an invitation to critique my code.

On 3/14/18, 5:11 AM, "Martin Maechler" <maechler at stat.math.ethz.ch> wrote:

>>>>>> Henrik Bengtsson <henrik.bengtsson at gmail.com>
>>>>>>     on Tue, 13 Mar 2018 10:12:55 -0700 writes:
>
>> FYI, in R devel (to become 3.5.0), there's isFALSE() which will cut
>> some corners compared to identical():
>
>> > microbenchmark::microbenchmark(identical(FALSE, FALSE),
>>isFALSE(FALSE))
>> Unit: nanoseconds
>>                     expr min   lq    mean median     uq   max neval
>>  identical(FALSE, FALSE) 984 1138 1694.13 1218.0 1337.5 13584   100
>>           isFALSE(FALSE) 713  761 1133.53  809.5  871.5 18619   100
>
>> > microbenchmark::microbenchmark(identical(TRUE, FALSE), isFALSE(TRUE))
>> Unit: nanoseconds
>>                    expr  min     lq    mean median   uq   max neval
>>  identical(TRUE, FALSE) 1009 1103.5 2228.20 1170.5 1357 14346   100
>>           isFALSE(TRUE)  718  760.0 1298.98  798.0  898 17782   100
>
>> > microbenchmark::microbenchmark(identical("array", FALSE),
>>isFALSE("array"))
>> Unit: nanoseconds
>>                       expr min     lq    mean median     uq  max neval
>>  identical("array", FALSE) 975 1058.5 1257.95 1119.5 1250.0 9299   100
>>           isFALSE("array") 409  433.5  658.76  446.0  476.5 9383   100
>
>Thank you Henrik!
>
>The speed of the new isTRUE() and isFALSE() is indeed amazing
>compared to identical() which was written to be fast itself.
>
>Note that the new code goes back to a proposal by  Herv? Pag?s
>(of Bioconductor fame) in a thread with R core in April 2017.
>The goal of the new code actually *was*  to allow call like
>
>  isTRUE(c(a = TRUE))
>
>to become TRUE rather than improving speed.
>The new source code is at the end of  R/src/library/base/R/identical.R
>
>## NB:  is.logical(.) will never dispatch:
>## --                 base::is.logical(x)  <==>  typeof(x) == "logical"
>isTRUE  <- function(x) is.logical(x) && length(x) == 1L && !is.na(x) && x
>isFALSE <- function(x) is.logical(x) && length(x) == 1L && !is.na(x) && !x
>
>and one *reason* this is so fast is that all  6  functions which
>are called are primitives :
>
>> sapply(codetools::findGlobals(isTRUE), function(fn)
>>is.primitive(get(fn)))
>         !         &&         == is.logical      is.na     length
>      TRUE       TRUE       TRUE       TRUE       TRUE       TRUE
>
>and a 2nd reason is probably with the many recent improvements of the
>byte compiler.
>
>
>> That could probably be used also is sapply().  The difference is that
>> isFALSE() is a bit more liberal than identical(x, FALSE), e.g.
>
>> > isFALSE(c(a = FALSE))
>> [1] TRUE
>> > identical(c(a = FALSE), FALSE)
>> [1] FALSE
>
>> Assuming the latter is not an issue, there are 69 places in base R
>> where isFALSE() could be used:
>
>> $ grep -E "identical[(][^,]+,[ ]*FALSE[)]" -r --include="*.R" | grep -F
>>"/R/" | wc
>>      69     326    5472
>
>> and another 59 where isTRUE() can be used:
>
>> $ grep -E "identical[(][^,]+,[ ]*TRUE[)]" -r --include="*.R" | grep -F
>>"/R/" | wc
>>      59     307    5021
>
>Beautiful use of  'grep' -- thank you for those above, as well.
>It does need a quick manual check, but if I use the above grep
>from Emacs (via  'M-x grep')  or even better via a TAGS table
>and M-x tags-query-replace  I should be able to do the changes
>pretty quickly... and will start looking into that later today.
>
>Interestingly and to my great pleasure, the first part of the
>'Subject' of this mailing list thread, "Possible Improvement",
>*has* become true after all --
>
>-- thanks to Henrik !
>
>Martin Maechler
>ETH Zurich
>
>
>
>> On Tue, Mar 13, 2018 at 9:21 AM, Doran, Harold <HDoran at air.org> wrote:
>> > Quite possibly, and I?ll look into that. Aside from the work I was
>>doing, however, I wonder if there is a way such that sapply could avoid
>>the overhead of having to call the identical function to determine the
>>conditional path.
>> >
>> >
>> >
>> > From: William Dunlap [mailto:wdunlap at tibco.com]
>> > Sent: Tuesday, March 13, 2018 12:14 PM
>> > To: Doran, Harold <HDoran at air.org>
>> > Cc: Martin Morgan <martin.morgan at roswellpark.org>;
>>r-help at r-project.org
>> > Subject: Re: [R] Possible Improvement to sapply
>> >
>> > Could your code use vapply instead of sapply?  vapply forces you to
>>declare the type and dimensions
>> > of FUN's output and stops if any call to FUN does not match the
>>declaration.  It can use much less
>> > memory and time than sapply because it fills in the output array as
>>it goes instead of calling lapply()
>> > and seeing how it could be simplified.
>> >
>> > Bill Dunlap
>> > TIBCO Software
>> > wdunlap tibco.com<http://tibco.com>
>> >
>> > On Tue, Mar 13, 2018 at 7:06 AM, Doran, Harold
>><HDoran at air.org<mailto:HDoran at air.org>> wrote:
>> > Martin
>> >
>> > In terms of context of the actual problem, sapply is called millions
>>of times because the work involves scoring individual students who took
>>a test. A score for student A is generated and then student B and such
>>and there are millions of students. The psychometric process of scoring
>>students is complex and our code makes use of sapply many times for each
>>student.
>> >
>> > The toy example used length just to illustrate, our actual code
>>doesn't do that. But your point is well taken, there may be a very good
>>counterexample why my proposal doesn't achieve the goal is a
>>generalizable way.
>> >
>
>
>[.................]
>


From marc_grt at yahoo.fr  Wed Mar 14 10:17:20 2018
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 14 Mar 2018 10:17:20 +0100
Subject: [R] Warning for LC_CTYPE when R is ran through ssh
Message-ID: <0244c784-ddcd-d824-daf2-f1235863caf0@yahoo.fr>

Dear member,

When I run a code on a computer B from a computer A through shh using 
for example:

system("ssh login at IPadress \"R -e 'print(1)'\"")
[Note that I don't need indicate password because ~/.ssh/authorized_keys 
is used]

I get a warning:
During startup - Warning message:
Setting LC_CTYPE failed, using "C"

The code is working (it prints 1) but I don't like get a warning.

R 3.4.3 is installed on the IPadress computer under Ubuntu 16.04

In this computer, I tried to add in .Rprofile this line:
Sys.setlocale(category = "LC_CTYPE", locale = "en_US.UTF-8")

it is recognized but I get always the same warning when the code is ran 
through ssh:

 > system("ssh login at IPadress \"R -e 'print(1)'\"")

R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

.... some messages are removed for simplicity

[1] "en_US.UTF-8"
[Previously saved workspace restored]

During startup - Warning message:
Setting LC_CTYPE failed, using "C"
 > print(1)
[1] 1

If I run the same in the local terminal, I don't get the warning:

~$ R -e "print(1)"

R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
Copyright (C) 2017 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

.... some messages are removed for simplicity


[1] "en_US.UTF-8"
[Previously saved workspace restored]

 > print(1)
[1] 1


Has someone a solution to not get this warning when a code is ran 
through ssh ?

Thanks

Marc Girondot


From styen at ntu.edu.tw  Wed Mar 14 11:10:12 2018
From: styen at ntu.edu.tw (Steven Yen)
Date: Wed, 14 Mar 2018 18:10:12 +0800
Subject: [R] Documenting R package with Rd file
Message-ID: <4faae1e4-5602-0f4a-a0e0-0c8f6cda77f5@ntu.edu.tw>

I have trouble documenting an R package. In my .Rd file (sixth line below), I have
uhat<-m%*%y

but when the package is built (successfully), the matrix multiplication part does not show up in the documentation. The line become (missing %*% y)

uhat<-m

===

\examples{
x<-c(1,2,3,4,5)
y<-c(1,1,2,2,4)
x<-cbind(1,x)
m<-mmat(x)
uhat<-m%*%y
dstat(uhat)
}

 ?--
styen at ntu.edu.tw (S.T. Yen)


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 14 12:03:00 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 14 Mar 2018 07:03:00 -0400
Subject: [R] Documenting R package with Rd file
In-Reply-To: <4faae1e4-5602-0f4a-a0e0-0c8f6cda77f5@ntu.edu.tw>
References: <4faae1e4-5602-0f4a-a0e0-0c8f6cda77f5@ntu.edu.tw>
Message-ID: <167c3f9e-8d85-04b8-3d91-b8a0921df5ae@gmail.com>

On 14/03/2018 6:10 AM, Steven Yen wrote:
> I have trouble documenting an R package. In my .Rd file (sixth line below), I have
> uhat<-m%*%y
> 
> but when the package is built (successfully), the matrix multiplication part does not show up in the documentation. The line become (missing %*% y)

Generally questions about writing packages should be in R-devel or 
R-package-devel, but this one is easy, so I'll answer here.

The % symbol marks a comment in an Rd file.  You need to escape them. 
See below...
> 
> uhat<-m
> 
> ===
> 
> \examples{
> x<-c(1,2,3,4,5)
> y<-c(1,1,2,2,4)
> x<-cbind(1,x)
> m<-mmat(x)
> uhat<-m%*%y

Should be "uhat <- m \%*\% y"

Duncan Murdoch

> dstat(uhat)
> }
> 
>   ?--
> styen at ntu.edu.tw (S.T. Yen)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From akshay_e4 at hotmail.com  Wed Mar 14 12:42:38 2018
From: akshay_e4 at hotmail.com (akshay kulkarni)
Date: Wed, 14 Mar 2018 11:42:38 +0000
Subject: [R] the same function returning different values when called
 differently..
Message-ID: <SL2P216MB0091BEF8A6CCF1BBE354D788C8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,

 I have a function ygrpc which acts on the daily price increments of a stock. It returns the following values:


 ygrpc(PFC.NS,"h")
 [1]  2.149997  1.875000  0.750000  0.349991  2.100006  0.199997  4.000000  2.574996  0.500000  0.349999  1.500000  0.700001
[13]  0.500000  1.300003  0.449997  2.800003  2.724998 66.150002  0.550003  0.050003  1.224991  4.899994  1.375000  1.574997
[25]  1.649994  0.449997  0.975006  2.475006  0.125000  2.625000  3.649994  0.399994  1.300003  2.074997  1.025001  0.125000
[37]  3.849999  0.025002  0.824997  1.750000  1.699997  1.750000  1.699997  0.275002  2.300003  0.349998  0.750000  0.224998
[49]  0.125000  1.475006  1.599998  0.125000  0.500000  0.700005  1.099998  0.225006  1.274997  1.300003  3.000000  0.300003
[61]  0.724999  3.699997  2.424995  8.425003  1.099991  2.025009  0.850006  4.000000  1.724991  0.949997  1.825012  2.799988
[73]  0.425003  1.799995  5.700005  2.125000  0.125000  4.000000  2.350006  1.524994  1.299995  0.300003  0.949997  0.449997
[85]  1.899994  1.700005  1.150009  0.849998  2.449997  5.300003  0.19999

I also have a list of stocks called "snl" with snl[[159]] pointing to PFC.NS (above):
tail(snl[[159]])
           PFC.NS.Open PFC.NS.High PFC.NS.Low PFC.NS.Close PFC.NS.Volume PFC.NS.Adjusted
2018-03-07       98.40       98.45       95.1        95.30       7854861           95.30
2018-03-08       94.90       94.95       89.3        91.90      12408061           91.90
2018-03-09       92.00       94.50       91.9        93.10       7680222           93.10
2018-03-12       93.40       93.85       86.1        88.25      12617833           88.25
2018-03-13       89.20       91.85       86.2        89.85      12792630           89.85
2018-03-14       88.65       89.30       86.1        86.70      16406495           86.70

But ygrpc(snl[[159]],"h") returns :
ygrpc(snl[[159]],"h")
[1] 1

Can you please shed some light on what is happening?

Very many thanks for your time and effort....

Yours sincerely
AKSHAY M KULKARNI







	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Mar 14 12:52:29 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 14 Mar 2018 13:52:29 +0200
Subject: [R] the same function returning different values when called
 differently..
In-Reply-To: <SL2P216MB0091BEF8A6CCF1BBE354D788C8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091BEF8A6CCF1BBE354D788C8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW76HqG=Bmx-38sjp63K55F44t4ic+Ngti1LTtdbNEfCBWA@mail.gmail.com>

Hi Akshay,
Presumably PFC.NS and snl[[159]] are not exactly the same.
You can start by trying to determine if (and then how) they differ.
e.g.
> identical(PFC.NS, snl[[159]])
presumably this will result in FALSE

then compare
> class(PFC.NS)
> class(snl[[159]])

etc

HTH,
Eric


On Wed, Mar 14, 2018 at 1:42 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>
>  I have a function ygrpc which acts on the daily price increments of a
> stock. It returns the following values:
>
>
>  ygrpc(PFC.NS,"h")
>  [1]  2.149997  1.875000  0.750000  0.349991  2.100006  0.199997
> 4.000000  2.574996  0.500000  0.349999  1.500000  0.700001
> [13]  0.500000  1.300003  0.449997  2.800003  2.724998 66.150002
> 0.550003  0.050003  1.224991  4.899994  1.375000  1.574997
> [25]  1.649994  0.449997  0.975006  2.475006  0.125000  2.625000
> 3.649994  0.399994  1.300003  2.074997  1.025001  0.125000
> [37]  3.849999  0.025002  0.824997  1.750000  1.699997  1.750000
> 1.699997  0.275002  2.300003  0.349998  0.750000  0.224998
> [49]  0.125000  1.475006  1.599998  0.125000  0.500000  0.700005
> 1.099998  0.225006  1.274997  1.300003  3.000000  0.300003
> [61]  0.724999  3.699997  2.424995  8.425003  1.099991  2.025009
> 0.850006  4.000000  1.724991  0.949997  1.825012  2.799988
> [73]  0.425003  1.799995  5.700005  2.125000  0.125000  4.000000
> 2.350006  1.524994  1.299995  0.300003  0.949997  0.449997
> [85]  1.899994  1.700005  1.150009  0.849998  2.449997  5.300003  0.19999
>
> I also have a list of stocks called "snl" with snl[[159]] pointing to
> PFC.NS (above):
> tail(snl[[159]])
>            PFC.NS.Open PFC.NS.High PFC.NS.Low PFC.NS.Close PFC.NS.Volume
> PFC.NS.Adjusted
> 2018-03-07       98.40       98.45       95.1        95.30       7854861
>          95.30
> 2018-03-08       94.90       94.95       89.3        91.90      12408061
>          91.90
> 2018-03-09       92.00       94.50       91.9        93.10       7680222
>          93.10
> 2018-03-12       93.40       93.85       86.1        88.25      12617833
>          88.25
> 2018-03-13       89.20       91.85       86.2        89.85      12792630
>          89.85
> 2018-03-14       88.65       89.30       86.1        86.70      16406495
>          86.70
>
> But ygrpc(snl[[159]],"h") returns :
> ygrpc(snl[[159]],"h")
> [1] 1
>
> Can you please shed some light on what is happening?
>
> Very many thanks for your time and effort....
>
> Yours sincerely
> AKSHAY M KULKARNI
>
>
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger at gmail.com  Wed Mar 14 13:23:37 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 14 Mar 2018 14:23:37 +0200
Subject: [R] R crashing with a segmentation fault: how to locate the cause
Message-ID: <CAGgJW74WAJXdyEH_aTWBe=T645dSuHsjQvpUMq+beN2kUE9gOA@mail.gmail.com>

I have a littler script which is crashing with a segmentation fault.
I tried to find out why by running it through valgrind, which produced the
output below.
I am not sure how to proceed from here (other than binary search with print
statements).
Any help would be appreciated.

Thanks,
Eric

==12589== Invalid read of size 1
==12589==    at 0x4C2F1B1: strcmp (in
/usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==12589==    by 0x4F71AC1: Rf_inherits (in /usr/lib/R/lib/libR.so)
==12589==    by 0x11AFED3A: dplyr::subset_visitor_vector(SEXPREC*)
(subset_visitor_impl.h:51)
==12589==    by 0x11AFF58C: dplyr::subset_visitor(SEXPREC*,
dplyr::SymbolString const&) (subset_visitor_impl.h:21)
==12589==    by 0x11AFEC18:
dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(Rcpp::DataFrame_Impl<Rcpp::PreserveStorage>
const&) (DataFrameSubsetVisitors.h:33)
==12589==    by 0x11B1F773: subset<Rcpp::Vector<10, Rcpp::PreserveStorage>
> (DataFrameSubsetVisitors.h:120)
==12589==    by 0x11B1F773:
filter_ungrouped(Rcpp::DataFrame_Impl<Rcpp::PreserveStorage>,
dplyr::NamedQuosure const&) (filter.cpp:89)
==12589==    by 0x11B1FD89:
filter_impl(Rcpp::DataFrame_Impl<Rcpp::PreserveStorage>,
dplyr::NamedQuosure) (filter.cpp:106)
==12589==    by 0x11AD45CB: _dplyr_filter_impl (RcppExports.cpp:192)
==12589==    by 0x4F0DBAC: ??? (in /usr/lib/R/lib/libR.so)
==12589==    by 0x4F50E50: Rf_eval (in /usr/lib/R/lib/libR.so)
==12589==    by 0x4F534FF: ??? (in /usr/lib/R/lib/libR.so)
==12589==    by 0x4F50C28: Rf_eval (in /usr/lib/R/lib/libR.so)
==12589==  Address 0x2c is not stack'd, malloc'd or (recently) free'd
==12589==
==12589==
==12589== Process terminating with default action of signal 11 (SIGSEGV)
==12589==  Access not within mapped region at address 0x2C
==12589==    at 0x4C2F1B1: strcmp (in
/usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==12589==    by 0x4F71AC1: Rf_inherits (in /usr/lib/R/lib/libR.so)
==12589==    by 0x11AFED3A: dplyr::subset_visitor_vector(SEXPREC*)
(subset_visitor_impl.h:51)
==12589==    by 0x11AFF58C: dplyr::subset_visitor(SEXPREC*,
dplyr::SymbolString const&) (subset_visitor_impl.h:21)
==12589==    by 0x11AFEC18:
dplyr::DataFrameSubsetVisitors::DataFrameSubsetVisitors(Rcpp::DataFrame_Impl<Rcpp::PreserveStorage>
const&) (DataFrameSubsetVisitors.h:33)
==12589==    by 0x11B1F773: subset<Rcpp::Vector<10, Rcpp::PreserveStorage>
> (DataFrameSubsetVisitors.h:120)
==12589==    by 0x11B1F773:
filter_ungrouped(Rcpp::DataFrame_Impl<Rcpp::PreserveStorage>,
dplyr::NamedQuosure const&) (filter.cpp:89)
==12589==    by 0x11B1FD89:
filter_impl(Rcpp::DataFrame_Impl<Rcpp::PreserveStorage>,
dplyr::NamedQuosure) (filter.cpp:106)
==12589==    by 0x11AD45CB: _dplyr_filter_impl (RcppExports.cpp:192)
==12589==    by 0x4F0DBAC: ??? (in /usr/lib/R/lib/libR.so)
==12589==    by 0x4F50E50: Rf_eval (in /usr/lib/R/lib/libR.so)
==12589==    by 0x4F534FF: ??? (in /usr/lib/R/lib/libR.so)
==12589==    by 0x4F50C28: Rf_eval (in /usr/lib/R/lib/libR.so)
==12589==  If you believe this happened as a result of a stack
==12589==  overflow in your program's main thread (unlikely but
==12589==  possible), you can try to increase the size of the
==12589==  main thread stack using the --main-stacksize= flag.
==12589==  The main thread stack size used in this run was 8388608.
==12589==
==12589== HEAP SUMMARY:
==12589==     in use at exit: 224,025,975 bytes in 111,522 blocks
==12589==   total heap usage: 1,104,400 allocs, 992,878 frees, 625,925,991
bytes allocated
==12589==
==12589== LEAK SUMMARY:
==12589==    definitely lost: 0 bytes in 0 blocks
==12589==    indirectly lost: 0 bytes in 0 blocks
==12589==      possibly lost: 18,724 bytes in 47 blocks
==12589==    still reachable: 224,007,251 bytes in 111,475 blocks
==12589==         suppressed: 0 bytes in 0 blocks
==12589== Rerun with --leak-check=full to see details of leaked memory
==12589==
==12589== For counts of detected and suppressed errors, rerun with: -v
==12589== ERROR SUMMARY: 1 errors from 1 contexts (suppressed: 0 from 0)
Segmentation fault (core dumped)

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Mar 14 14:53:11 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Mar 2018 06:53:11 -0700
Subject: [R] Warning for LC_CTYPE when R is ran through ssh
In-Reply-To: <0244c784-ddcd-d824-daf2-f1235863caf0@yahoo.fr>
References: <0244c784-ddcd-d824-daf2-f1235863caf0@yahoo.fr>
Message-ID: <03A7C366-95CB-497A-BA83-C8FC62E82205@dcn.davis.ca.us>

I don't think that warning is originating from R... LC_TYPE is an environment variable that the standard C library pays attention to, so could be either ssh on your local computer or ssh on the remote computer in response to something the local ssh is doing.

IMO this question belongs in a forum about Ubuntu or ssh, or possibly R-sig-debian.

-- 
Sent from my phone. Please excuse my brevity.

On March 14, 2018 2:17:20 AM PDT, Marc Girondot via R-help <r-help at r-project.org> wrote:
>Dear member,
>
>When I run a code on a computer B from a computer A through shh using 
>for example:
>
>system("ssh login at IPadress \"R -e 'print(1)'\"")
>[Note that I don't need indicate password because
>~/.ssh/authorized_keys 
>is used]
>
>I get a warning:
>During startup - Warning message:
>Setting LC_CTYPE failed, using "C"
>
>The code is working (it prints 1) but I don't like get a warning.
>
>R 3.4.3 is installed on the IPadress computer under Ubuntu 16.04
>
>In this computer, I tried to add in .Rprofile this line:
>Sys.setlocale(category = "LC_CTYPE", locale = "en_US.UTF-8")
>
>it is recognized but I get always the same warning when the code is ran
>
>through ssh:
>
> > system("ssh login at IPadress \"R -e 'print(1)'\"")
>
>R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
>Copyright (C) 2017 The R Foundation for Statistical Computing
>Platform: x86_64-pc-linux-gnu (64-bit)
>
>.... some messages are removed for simplicity
>
>[1] "en_US.UTF-8"
>[Previously saved workspace restored]
>
>During startup - Warning message:
>Setting LC_CTYPE failed, using "C"
> > print(1)
>[1] 1
>
>If I run the same in the local terminal, I don't get the warning:
>
>~$ R -e "print(1)"
>
>R version 3.4.3 (2017-11-30) -- "Kite-Eating Tree"
>Copyright (C) 2017 The R Foundation for Statistical Computing
>Platform: x86_64-pc-linux-gnu (64-bit)
>
>.... some messages are removed for simplicity
>
>
>[1] "en_US.UTF-8"
>[Previously saved workspace restored]
>
> > print(1)
>[1] 1
>
>
>Has someone a solution to not get this warning when a code is ran 
>through ssh ?
>
>Thanks
>
>Marc Girondot
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From b.rowlingson at lancaster.ac.uk  Wed Mar 14 16:56:55 2018
From: b.rowlingson at lancaster.ac.uk (Barry Rowlingson)
Date: Wed, 14 Mar 2018 15:56:55 +0000
Subject: [R] Learning advanced R
In-Reply-To: <52df2af9b43c43d4b8cdf55e86d17dfe@AM4PR0401MB1729.eurprd04.prod.outlook.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <52df2af9b43c43d4b8cdf55e86d17dfe@AM4PR0401MB1729.eurprd04.prod.outlook.com>
Message-ID: <CANVKczN0aT69=rfXpb_PAzOOHvszgakVZ6SaOHxDc2P5o64mQA@mail.gmail.com>

Depending on your application, I'm not sure there's much point in being an
"advanced R programmer" these days. Become an adequate R programmer, and
learn C++ and Rcpp. Do basic data mashing in R, then do all your intensive
stuff in C++ with Rcpp. Eventually you'll probably get to the point where
you can express yourself in C++ as fast as you can in interpreted R, with
the bonus of C++ speed, type-safety etc.

</controversial>

On Wed, Mar 14, 2018 at 8:13 AM, Eric Berger <ericjberger at gmail.com> wrote:

> Bert's suggestion is good as a pointer to a variety of resources.
> Sticking to the book format there are two of Hadley Wickham's books, which
> have the advantage that they are freely available.
> You can either read them online or download the source from github and
> create your own copy (which you can then print, if desired.)
> 1. "R for Data Science"
>      online: http://r4ds.had.co.nz/
>      github: https://github.com/hadley/r4ds
> 2. "Advanced R"
>      online: https://adv-r.hadley.nz/
>      github: https://github.com/hadley/adv-r
>
> Best,
> Eric
>
>
>
> On Wed, Mar 14, 2018 at 12:13 AM, Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
>
> > On Tue, 13 Mar 2018, Mark Leeds wrote:
> >
> > See Hadley's advanced R
> >>
> >
> >   +1 A very well writte, highly useful book. Recommended.
> >
> > Rich
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> > ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Wed Mar 14 17:07:32 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 14 Mar 2018 09:07:32 -0700 (PDT)
Subject: [R] Learning advanced R
In-Reply-To: <CANVKczN0aT69=rfXpb_PAzOOHvszgakVZ6SaOHxDc2P5o64mQA@mail.gmail.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <52df2af9b43c43d4b8cdf55e86d17dfe@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczN0aT69=rfXpb_PAzOOHvszgakVZ6SaOHxDc2P5o64mQA@mail.gmail.com>
Message-ID: <alpine.LNX.2.20.1803140902460.18676@salmo.appl-ecosys.com>

On Wed, 14 Mar 2018, Barry Rowlingson wrote:

> Depending on your application, I'm not sure there's much point in being an
> "advanced R programmer" these days. Become an adequate R programmer, and
> learn C++ and Rcpp. Do basic data mashing in R, then do all your intensive
> stuff in C++ with Rcpp. Eventually you'll probably get to the point where
> you can express yourself in C++ as fast as you can in interpreted R, with
> the bonus of C++ speed, type-safety etc.

Barry,

   Allow me to offer an alternative to C++: Python. Compiled languages are
faster than interpreted ones, but unless you're doing time-critical
computations it really does not matter. R and Python provide proven
abilities in a broad range of applications and with today's hardware the
analytical/modeling code is not likely to be the limiting factor.

Regards,

Rich


From murdoch.duncan at gmail.com  Wed Mar 14 17:13:31 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 14 Mar 2018 12:13:31 -0400
Subject: [R] Learning advanced R
In-Reply-To: <alpine.LNX.2.20.1803140902460.18676@salmo.appl-ecosys.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <52df2af9b43c43d4b8cdf55e86d17dfe@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczN0aT69=rfXpb_PAzOOHvszgakVZ6SaOHxDc2P5o64mQA@mail.gmail.com>
 <alpine.LNX.2.20.1803140902460.18676@salmo.appl-ecosys.com>
Message-ID: <d4ffb7d0-2ec2-d298-59e2-f6120ad14fcd@gmail.com>

On 14/03/2018 12:07 PM, Rich Shepard wrote:
> On Wed, 14 Mar 2018, Barry Rowlingson wrote:
> 
>> Depending on your application, I'm not sure there's much point in being an
>> "advanced R programmer" these days. Become an adequate R programmer, and
>> learn C++ and Rcpp. Do basic data mashing in R, then do all your intensive
>> stuff in C++ with Rcpp. Eventually you'll probably get to the point where
>> you can express yourself in C++ as fast as you can in interpreted R, with
>> the bonus of C++ speed, type-safety etc.
> 
> Barry,
> 
>     Allow me to offer an alternative to C++: Python. Compiled languages are
> faster than interpreted ones, but unless you're doing time-critical
> computations it really does not matter. R and Python provide proven
> abilities in a broad range of applications and with today's hardware the
> analytical/modeling code is not likely to be the limiting factor.
> 

I'm all for learning more languages and using the one that's best for 
each job, but for people who don't know Python, it would be helpful to 
list the aspects in which it excels.  When should an R user choose to 
write something in Python instead?

Duncan Murdoch


From ericjberger at gmail.com  Wed Mar 14 17:27:38 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 14 Mar 2018 18:27:38 +0200
Subject: [R] Fwd: the same function returning different values when called
 differently..
In-Reply-To: <SL2P216MB00916AD6445F55ECD79EDAABC8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091BEF8A6CCF1BBE354D788C8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <CAGgJW76HqG=Bmx-38sjp63K55F44t4ic+Ngti1LTtdbNEfCBWA@mail.gmail.com>
 <SL2P216MB00916AD6445F55ECD79EDAABC8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW77fsFewb6JOTb+Xe-GyQb45us24+rxbN9RXqVfv=vTLrg@mail.gmail.com>

Hi Akshay,

(Please include r-help when replying)

You have learned that PFC.NS and snl[[159]] are not identical. Now you have
to figure out why they differ. This could also point to a bug or a logic
error in your program.
Figuring out how two objects differ can be a bit tricky, but with
experience it becomes easier. (Some others may even have some suggestions
for good ways to do it.)
Basically you would work your way down. At the top level is the class of
each, which you already tested and they are identical.

Now try:

> str(PFC.NS)

and compare it to

> str(snl[[159]]

Look closely at the two outputs to try to detect differences. If they are
the same then you will have to examine the sub-objects described by str().
You didn't mention what type of objects they are. Suppose they are both
"numeric" vectors. Then you can check whether their lengths are equal.
And you can compare their values, etc. etc. No short cut that I can think
of without more information.

It definitely takes work to find discrepancies. Think of it as a challenge
and perhaps write functions that you can use to automate this kind of
comparison in the future.
(Again, other people on this list might be able to point to tools that help
with this for objects of specific type.)

Good luck,
Eric




dear Eric,

                   Bulls eye...! identical(PFC.NS, snl[[159]])) is
resulting false..but class(PFC.NS) and class(snl[[159]]) are same...

I want snl[[159]] to be equal to PFC.NS...how do I effect it? create a list
with some other element list... for example snl[[200]] == PFC.NS?


very many thanks for your time and effort...


yours sincerely,

AKSHAY M KULKARNI




------------------------------
*From:* Eric Berger <ericjberger at gmail.com>
*Sent:* Wednesday, March 14, 2018 5:22 PM
*To:* akshay kulkarni
*Cc:* R help Mailing list
*Subject:* Re: [R] the same function returning different values when called
differently..

Hi Akshay,
Presumably PFC.NS and snl[[159]] are not exactly the same.
You can start by trying to determine if (and then how) they differ.
e.g.
> identical(PFC.NS, snl[[159]])
presumably this will result in FALSE

then compare
> class(PFC.NS)
> class(snl[[159]])

etc

HTH,
Eric


On Wed, Mar 14, 2018 at 1:42 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

dear members,

 I have a function ygrpc which acts on the daily price increments of a
stock. It returns the following values:


 ygrpc(PFC.NS,"h")
 [1]  2.149997  1.875000  0.750000  0.349991  2.100006  0.199997  4.000000
2.574996  0.500000  0.349999  1.500000  0.700001
[13]  0.500000  1.300003  0.449997  2.800003  2.724998 66.150002  0.550003
0.050003  1.224991  4.899994  1.375000  1.574997
[25]  1.649994  0.449997  0.975006  2.475006  0.125000  2.625000  3.649994
0.399994  1.300003  2.074997  1.025001  0.125000
[37]  3.849999  0.025002  0.824997  1.750000  1.699997  1.750000  1.699997
0.275002  2.300003  0.349998  0.750000  0.224998
[49]  0.125000  1.475006  1.599998  0.125000  0.500000  0.700005  1.099998
0.225006  1.274997  1.300003  3.000000  0.300003
[61]  0.724999  3.699997  2.424995  8.425003  1.099991  2.025009  0.850006
4.000000  1.724991  0.949997  1.825012  2.799988
[73]  0.425003  1.799995  5.700005  2.125000  0.125000  4.000000  2.350006
1.524994  1.299995  0.300003  0.949997  0.449997
[85]  1.899994  1.700005  1.150009  0.849998  2.449997  5.300003  0.19999

I also have a list of stocks called "snl" with snl[[159]] pointing to
PFC.NS (above):
tail(snl[[159]])
           PFC.NS.Open PFC.NS.High PFC.NS.Low PFC.NS.Close PFC.NS.Volume
PFC.NS.Adjusted
2018-03-07       98.40       98.45       95.1        95.30       7854861
       95.30
2018-03-08       94.90       94.95       89.3        91.90      12408061
       91.90
2018-03-09       92.00       94.50       91.9        93.10       7680222
       93.10
2018-03-12       93.40       93.85       86.1        88.25      12617833
       88.25
2018-03-13       89.20       91.85       86.2        89.85      12792630
       89.85
2018-03-14       88.65       89.30       86.1        86.70      16406495
       86.70

But ygrpc(snl[[159]],"h") returns :
ygrpc(snl[[159]],"h")
[1] 1

Can you please shed some light on what is happening?

Very many thanks for your time and effort....

Yours sincerely
AKSHAY M KULKARNI







        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
R-help -- Main R Mailing List: Primary help - Homepage - SfS
<https://stat.ethz.ch/mailman/listinfo/r-help>
stat.ethz.ch
The main R mailing list, for announcements about the development of R and
the availability of new code, questions and answers about problems and
solutions using R ...


PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Wed Mar 14 17:38:02 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 14 Mar 2018 17:38:02 +0100
Subject: [R] 
 Fwd: the same function returning different values when called
 differently..
In-Reply-To: <CAGgJW77fsFewb6JOTb+Xe-GyQb45us24+rxbN9RXqVfv=vTLrg@mail.gmail.com>
References: <SL2P216MB0091BEF8A6CCF1BBE354D788C8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <CAGgJW76HqG=Bmx-38sjp63K55F44t4ic+Ngti1LTtdbNEfCBWA@mail.gmail.com>
 <SL2P216MB00916AD6445F55ECD79EDAABC8D10@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <CAGgJW77fsFewb6JOTb+Xe-GyQb45us24+rxbN9RXqVfv=vTLrg@mail.gmail.com>
Message-ID: <23209.20458.324154.738340@stat.math.ethz.ch>

>>>>> Eric Berger <ericjberger at gmail.com>
>>>>>     on Wed, 14 Mar 2018 18:27:38 +0200 writes:

    > Hi Akshay, (Please include r-help when replying)

    > You have learned that PFC.NS and snl[[159]] are not
    > identical. Now you have to figure out why they
    > differ. This could also point to a bug or a logic error in
    > your program.  Figuring out how two objects differ can be
    > a bit tricky, but with experience it becomes easier. (Some
    > others may even have some suggestions for good ways to do
    > it.)  Basically you would work your way down. At the top
    > level is the class of each, which you already tested and
    > they are identical.

    > Now try:

    >> str(PFC.NS)

    > and compare it to

    >> str(snl[[159]]

Note further the

     all.equal(obj1, obj2)

maybe a good start to find differences between R objects 'obj1' and 'obj2',
as all.equal() is generic and has a list method
(which works recursively) the "output may be huge, but then if there
is huge number of differences you would have found yourself
anyway, and will not need all.equal()

Martin Maechler
ETH Zurich and R Core


    > Look closely at the two outputs to try to detect
    > differences. If they are the same then you will have to
    > examine the sub-objects described by str().  You didn't
    > mention what type of objects they are. Suppose they are
    > both "numeric" vectors. Then you can check whether their
    > lengths are equal.  And you can compare their values,
    > etc. etc. No short cut that I can think of without more
    > information.

    > It definitely takes work to find discrepancies. Think of
    > it as a challenge and perhaps write functions that you can
    > use to automate this kind of comparison in the future.
    > (Again, other people on this list might be able to point
    > to tools that help with this for objects of specific
    > type.)

    > Good luck, Eric




    > dear Eric,

    >                    Bulls eye...! identical(PFC.NS,
    > snl[[159]])) is resulting false..but class(PFC.NS) and
    > class(snl[[159]]) are same...

    > I want snl[[159]] to be equal to PFC.NS...how do I effect
    > it? create a list with some other element list... for
    > example snl[[200]] == PFC.NS?


    > very many thanks for your time and effort...


    > yours sincerely,

    > AKSHAY M KULKARNI




    > ------------------------------
    > *From:* Eric Berger <ericjberger at gmail.com> *Sent:*
    > Wednesday, March 14, 2018 5:22 PM *To:* akshay kulkarni
    > *Cc:* R help Mailing list *Subject:* Re: [R] the same
    > function returning different values when called
    > differently..

    > Hi Akshay, Presumably PFC.NS and snl[[159]] are not
    > exactly the same.  You can start by trying to determine if
    > (and then how) they differ.  e.g.
    >> identical(PFC.NS, snl[[159]])
    > presumably this will result in FALSE

    > then compare
    >> class(PFC.NS) class(snl[[159]])

    > etc

    > HTH, Eric


    > On Wed, Mar 14, 2018 at 1:42 PM, akshay kulkarni
    > <akshay_e4 at hotmail.com> wrote:

    > dear members,

    >  I have a function ygrpc which acts on the daily price
    > increments of a stock. It returns the following values:


    >  ygrpc(PFC.NS,"h") [1] 2.149997 1.875000 0.750000 0.349991
    > 2.100006 0.199997 4.000000 2.574996 0.500000 0.349999
    > 1.500000 0.700001 [13] 0.500000 1.300003 0.449997 2.800003
    > 2.724998 66.150002 0.550003 0.050003 1.224991 4.899994
    > 1.375000 1.574997 [25] 1.649994 0.449997 0.975006 2.475006
    > 0.125000 2.625000 3.649994 0.399994 1.300003 2.074997
    > 1.025001 0.125000 [37] 3.849999 0.025002 0.824997 1.750000
    > 1.699997 1.750000 1.699997 0.275002 2.300003 0.349998
    > 0.750000 0.224998 [49] 0.125000 1.475006 1.599998 0.125000
    > 0.500000 0.700005 1.099998 0.225006 1.274997 1.300003
    > 3.000000 0.300003 [61] 0.724999 3.699997 2.424995 8.425003
    > 1.099991 2.025009 0.850006 4.000000 1.724991 0.949997
    > 1.825012 2.799988 [73] 0.425003 1.799995 5.700005 2.125000
    > 0.125000 4.000000 2.350006 1.524994 1.299995 0.300003
    > 0.949997 0.449997 [85] 1.899994 1.700005 1.150009 0.849998
    > 2.449997 5.300003 0.19999

    > I also have a list of stocks called "snl" with snl[[159]]
    > pointing to PFC.NS (above): tail(snl[[159]]) PFC.NS.Open
    > PFC.NS.High PFC.NS.Low PFC.NS.Close PFC.NS.Volume
    > PFC.NS.Adjusted 2018-03-07 98.40 98.45 95.1 95.30 7854861
    > 95.30 2018-03-08 94.90 94.95 89.3 91.90 12408061 91.90
    > 2018-03-09 92.00 94.50 91.9 93.10 7680222 93.10 2018-03-12
    > 93.40 93.85 86.1 88.25 12617833 88.25 2018-03-13 89.20
    > 91.85 86.2 89.85 12792630 89.85 2018-03-14 88.65 89.30
    > 86.1 86.70 16406495 86.70

    > But ygrpc(snl[[159]],"h") returns : ygrpc(snl[[159]],"h")
    > [1] 1

    > Can you please shed some light on what is happening?

    > Very many thanks for your time and effort....

    > Yours sincerely AKSHAY M KULKARNI







    >         [[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > R-help -- Main R Mailing List: Primary help - Homepage -
    > SfS <https://stat.ethz.ch/mailman/listinfo/r-help>
    > stat.ethz.ch The main R mailing list, for announcements
    > about the development of R and the availability of new
    > code, questions and answers about problems and solutions
    > using R ...


    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.

    > 	[[alternative HTML version deleted]]

    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and
    > more, see https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide
    > http://www.R-project.org/posting-guide.html and provide
    > commented, minimal, self-contained, reproducible code.


From ericjberger at gmail.com  Wed Mar 14 17:39:53 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Wed, 14 Mar 2018 18:39:53 +0200
Subject: [R] Fwd:  Learning advanced R
In-Reply-To: <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>
 <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
Message-ID: <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>

Hi Albrecht,
I am forwarding your reply to the full group.

It's been a while since I did this and I don't remember the details. Maybe
someone else can comment. (I am a bit busy at the moment.)
If no one supplies the information in a few days I will try to take a look.

In the meantime you can start your reading on-line. :-)

Regards,
Eric


Dear Eric,

I downloaded the material from   https://github.com/hadley/adv-r as a zip
file and decompressed it.  But, how to build the book from this? The
directory book contains a R-script buildbook.R. I downloaded all packages
that are required, but the script does not run. Is there an additional
script required?

Best,
Albrecht

--
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mi, 14. M?r 2018, um 09:13, schrieb Eric Berger:
> Bert's suggestion is good as a pointer to a variety of resources.
> Sticking to the book format there are two of Hadley Wickham's books, which
> have the advantage that they are freely available.
> You can either read them online or download the source from github and
> create your own copy (which you can then print, if desired.)
> 1. "R for Data Science"
>      online: http://r4ds.had.co.nz/
>      github: https://github.com/hadley/r4ds
> 2. "Advanced R"
>      online: https://adv-r.hadley.nz/
>      github: https://github.com/hadley/adv-r
>
> Best,
> Eric
>
>
>
> On Wed, Mar 14, 2018 at 12:13 AM, Rich Shepard <rshepard at appl-ecosys.com>
> wrote:
>
> > On Tue, 13 Mar 2018, Mark Leeds wrote:
> >
> > See Hadley's advanced R
> >>
> >
> >   +1 A very well writte, highly useful book. Recommended.
> >
> > Rich
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posti
> > ng-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Mar 14 17:50:33 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Mar 2018 09:50:33 -0700
Subject: [R] Fwd:  Learning advanced R
In-Reply-To: <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>
 <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
 <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>
Message-ID: <EC0F958E-BA6A-4ED6-B3BD-F1BB9A1CF3C7@dcn.davis.ca.us>

I recommend reading it directly via the website, or buying the book. 

If you are trying to build a PDF, then the "obvious" question is whether you have LaTeX installed, which is an operating-system-dependent procedure handled outside of R.
-- 
Sent from my phone. Please excuse my brevity.

On March 14, 2018 9:39:53 AM PDT, Eric Berger <ericjberger at gmail.com> wrote:
>Hi Albrecht,
>I am forwarding your reply to the full group.
>
>It's been a while since I did this and I don't remember the details.
>Maybe
>someone else can comment. (I am a bit busy at the moment.)
>If no one supplies the information in a few days I will try to take a
>look.
>
>In the meantime you can start your reading on-line. :-)
>
>Regards,
>Eric
>
>
>Dear Eric,
>
>I downloaded the material from   https://github.com/hadley/adv-r as a
>zip
>file and decompressed it.  But, how to build the book from this? The
>directory book contains a R-script buildbook.R. I downloaded all
>packages
>that are required, but the script does not run. Is there an additional
>script required?
>
>Best,
>Albrecht
>
>--
>  Albrecht Kauffmann
>  alkauffm at fastmail.fm
>
>Am Mi, 14. M?r 2018, um 09:13, schrieb Eric Berger:
>> Bert's suggestion is good as a pointer to a variety of resources.
>> Sticking to the book format there are two of Hadley Wickham's books,
>which
>> have the advantage that they are freely available.
>> You can either read them online or download the source from github
>and
>> create your own copy (which you can then print, if desired.)
>> 1. "R for Data Science"
>>      online: http://r4ds.had.co.nz/
>>      github: https://github.com/hadley/r4ds
>> 2. "Advanced R"
>>      online: https://adv-r.hadley.nz/
>>      github: https://github.com/hadley/adv-r
>>
>> Best,
>> Eric
>>
>>
>>
>> On Wed, Mar 14, 2018 at 12:13 AM, Rich Shepard
><rshepard at appl-ecosys.com>
>> wrote:
>>
>> > On Tue, 13 Mar 2018, Mark Leeds wrote:
>> >
>> > See Hadley's advanced R
>> >>
>> >
>> >   +1 A very well writte, highly useful book. Recommended.
>> >
>> > Rich
>> >
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posti
>> > ng-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Wed Mar 14 17:52:31 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 14 Mar 2018 09:52:31 -0700 (PDT)
Subject: [R] Learning advanced R
In-Reply-To: <d4ffb7d0-2ec2-d298-59e2-f6120ad14fcd@gmail.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <52df2af9b43c43d4b8cdf55e86d17dfe@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczN0aT69=rfXpb_PAzOOHvszgakVZ6SaOHxDc2P5o64mQA@mail.gmail.com>
 <alpine.LNX.2.20.1803140902460.18676@salmo.appl-ecosys.com>
 <d4ffb7d0-2ec2-d298-59e2-f6120ad14fcd@gmail.com>
Message-ID: <alpine.LNX.2.20.1803140938441.18676@salmo.appl-ecosys.com>

On Wed, 14 Mar 2018, Duncan Murdoch wrote:

> I'm all for learning more languages and using the one that's best for each
> job, but for people who don't know Python, it would be helpful to list the
> aspects in which it excels. When should an R user choose to write
> something in Python instead?

Duncan,

   "Best" is subjective, but my view is the language most comfortable and
familiar to the developer/analyst should be the one used.

   In my environmental consulting business I use both R and Python. While
Python has support for many statistical models I'm more comfortable with the
ones available in R. For spatial analyses (separate from spatial statistics)
I've used GRASS for > 20 years and it heavily uses Python. I also use Python
(along with emacs, awk, sed, and grep) for cleaning and organizing data. For
writing, I use LaTeX (a markup language) and the LyX GUI front end.

   Python has a lot of support for scientific and financial analyses, as does
R. Considering there are a gazillion programming languages available (and
used for essential applications, such as GnuCash (written in guile, a scheme
variant) which I use for business and personal bookkeeping, picking the
"best" one is strictly a personal matter. I prefer emacs, my system and
network admin friends prefer vi. In linux, at least, there are so many
options for doing a task that sometimes it's difficult to decide which to
use in a given situation.

   If the languages you know do all you need then learn a new one only if
it's to scratch an itch. :-)

Best regards,

Rich


From alkauffm at fastmail.fm  Wed Mar 14 17:58:38 2018
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Wed, 14 Mar 2018 17:58:38 +0100
Subject: [R] Fwd:  Learning advanced R
In-Reply-To: <EC0F958E-BA6A-4ED6-B3BD-F1BB9A1CF3C7@dcn.davis.ca.us>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>
 <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
 <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>
 <EC0F958E-BA6A-4ED6-B3BD-F1BB9A1CF3C7@dcn.davis.ca.us>
Message-ID: <1521046718.3356229.1303102592.573E2D8E@webmail.messagingengine.com>

Dear Jeff, 

Latex is also required for the R-manuals in the base R installation, and for this it works fine on my PC.

Best, 
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mi, 14. M?r 2018, um 17:50, schrieb Jeff Newmiller:
> I recommend reading it directly via the website, or buying the book. 
> 
> If you are trying to build a PDF, then the "obvious" question is whether 
> you have LaTeX installed, which is an operating-system-dependent 
> procedure handled outside of R.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 14, 2018 9:39:53 AM PDT, Eric Berger <ericjberger at gmail.com> wrote:
> >Hi Albrecht,
> >I am forwarding your reply to the full group.
> >
> >It's been a while since I did this and I don't remember the details.
> >Maybe
> >someone else can comment. (I am a bit busy at the moment.)
> >If no one supplies the information in a few days I will try to take a
> >look.
> >
> >In the meantime you can start your reading on-line. :-)
> >
> >Regards,
> >Eric
> >
> >
> >Dear Eric,
> >
> >I downloaded the material from   https://github.com/hadley/adv-r as a
> >zip
> >file and decompressed it.  But, how to build the book from this? The
> >directory book contains a R-script buildbook.R. I downloaded all
> >packages
> >that are required, but the script does not run. Is there an additional
> >script required?
> >
> >Best,
> >Albrecht
> >
> >--
> >  Albrecht Kauffmann
> >  alkauffm at fastmail.fm
> >
> >Am Mi, 14. M?r 2018, um 09:13, schrieb Eric Berger:
> >> Bert's suggestion is good as a pointer to a variety of resources.
> >> Sticking to the book format there are two of Hadley Wickham's books,
> >which
> >> have the advantage that they are freely available.
> >> You can either read them online or download the source from github
> >and
> >> create your own copy (which you can then print, if desired.)
> >> 1. "R for Data Science"
> >>      online: http://r4ds.had.co.nz/
> >>      github: https://github.com/hadley/r4ds
> >> 2. "Advanced R"
> >>      online: https://adv-r.hadley.nz/
> >>      github: https://github.com/hadley/adv-r
> >>
> >> Best,
> >> Eric
> >>
> >>
> >>
> >> On Wed, Mar 14, 2018 at 12:13 AM, Rich Shepard
> ><rshepard at appl-ecosys.com>
> >> wrote:
> >>
> >> > On Tue, 13 Mar 2018, Mark Leeds wrote:
> >> >
> >> > See Hadley's advanced R
> >> >>
> >> >
> >> >   +1 A very well writte, highly useful book. Recommended.
> >> >
> >> > Rich
> >> >
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide http://www.R-project.org/posti
> >> > ng-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >>
> >>       [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> >posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >	[[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Mar 14 18:47:25 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 14 Mar 2018 10:47:25 -0700
Subject: [R] Fwd:  Learning advanced R
In-Reply-To: <1521046718.3356229.1303102592.573E2D8E@webmail.messagingengine.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>
 <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
 <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>
 <EC0F958E-BA6A-4ED6-B3BD-F1BB9A1CF3C7@dcn.davis.ca.us>
 <1521046718.3356229.1303102592.573E2D8E@webmail.messagingengine.com>
Message-ID: <D52A9D91-8E09-461F-A344-67597502CADB@dcn.davis.ca.us>

Nothing you have said tells me you have LaTeX working (a binary install of R does not depend on it), but if you actually know it is installed and available to R then that isn't the problem. Since you have not said what you actually did or what errors you encountered I can only shrug and suggest that that the website is a complete rendering of the book and the for-sale version makes a worthwhile contribution to the author and the community.
-- 
Sent from my phone. Please excuse my brevity.

On March 14, 2018 9:58:38 AM PDT, Albrecht Kauffmann <alkauffm at fastmail.fm> wrote:
>Dear Jeff, 
>
>Latex is also required for the R-manuals in the base R installation,
>and for this it works fine on my PC.
>
>Best, 
>Albrecht


From spencer.graves at effectivedefense.org  Wed Mar 14 18:52:26 2018
From: spencer.graves at effectivedefense.org (Spencer Graves)
Date: Wed, 14 Mar 2018 12:52:26 -0500
Subject: [R] Learning advanced R
In-Reply-To: <alpine.LNX.2.20.1803140938441.18676@salmo.appl-ecosys.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <52df2af9b43c43d4b8cdf55e86d17dfe@AM4PR0401MB1729.eurprd04.prod.outlook.com>
 <CANVKczN0aT69=rfXpb_PAzOOHvszgakVZ6SaOHxDc2P5o64mQA@mail.gmail.com>
 <alpine.LNX.2.20.1803140902460.18676@salmo.appl-ecosys.com>
 <d4ffb7d0-2ec2-d298-59e2-f6120ad14fcd@gmail.com>
 <alpine.LNX.2.20.1803140938441.18676@salmo.appl-ecosys.com>
Message-ID: <e1062038-c64d-fbee-ca39-45ca2e75610c@effectivedefense.org>



On 2018-03-14 11:52, Rich Shepard wrote:
> On Wed, 14 Mar 2018, Duncan Murdoch wrote:
>
>> I'm all for learning more languages and using the one that's best for 
>> each
>> job, but for people who don't know Python, it would be helpful to 
>> list the
>> aspects in which it excels. When should an R user choose to write
>> something in Python instead?
>
> Duncan,
>
> ? "Best" is subjective, but my view is the language most comfortable and
> familiar to the developer/analyst should be the one used.
>
> ? In my environmental consulting business I use both R and Python. While
> Python has support for many statistical models I'm more comfortable 
> with the
> ones available in R. For spatial analyses (separate from spatial 
> statistics)
> I've used GRASS for > 20 years and it heavily uses Python. I also use 
> Python
> (along with emacs, awk, sed, and grep) for cleaning and organizing 
> data. For
> writing, I use LaTeX (a markup language) and the LyX GUI front end.
>
> ? Python has a lot of support for scientific and financial analyses, 
> as does
> R. Considering there are a gazillion programming languages available (and
> used for essential applications, such as GnuCash (written in guile, a 
> scheme
> variant) which I use for business and personal bookkeeping, picking the
> "best" one is strictly a personal matter. I prefer emacs, my system and
> network admin friends prefer vi. In linux, at least, there are so many
> options for doing a task that sometimes it's difficult to decide which to
> use in a given situation.
>
> ? If the languages you know do all you need then learn a new one only if
> it's to scratch an itch. :-)


 ????? My software development productivity increased by a factor of 
maybe 30 by using first S-Plus then R, including writing R packages, 
then RStudio and writing Rmarkdown vignettes.


 ??? ??????? 1.? I started writing Fortran in 1963.? I've written 
assembly language for multiple machines, Cobol, Lisp, and other 
language.? I started using S-Plus in the early 1990s and abandoned it 
for R when I needed "debug" for some S-Plus code.? Developing R packages 
improved my software development productivity by a factor of 10, because 
the discipline of creating unit tests in "\examples" made it so much 
easier to debug and maintain -- AND share with others.


 ??? ??????? 2.? I've also written some Python, though not much.? I used 
Emacs until I found RStudio.? Vi and Emacs are not tools you can give to 
someone, who is only marginally computer literate and expect them to be 
productive in a reasonable period of time.? By contrast, if someone 
knows enough to be able to install R and RStudio, I can give them some R 
code and be confident that they will get something useful from the 
experience in a relatively short period of time.? You can't do that with 
vi and Emacs unless they already know those applications.


 ??? ??????? 3.? Recently, I've started writing RMarkdown vignettes, and 
that further increased my productivity.


 ??? ??? ????????? 3.1.? Two years ago, I told I client I was going to 
prepare and Rmarkdown vignette to document what I did with their data.? 
My sales guy said absolutely, we were NOT going to give the client an 
Rmarkdown vignette.? I spent a week analyzing the data and 6 months 
answering questions from the team mostly by pointing them to certain 
lines in the vignette, occasionally by extending it.? In the middle of 
that, we learned that the client required our analysis to be 
verifiable.? After that, the vignette became a primary deliverable.


 ??? ??? ????????? 3.2.? More recently, another client asked me to 
explain principal components.? This client was moderately facile with 
software but not with R nor vector spaces.? I gave him an Rmarkdown 
vignette that included a principal components on some data he gave me 
done both with a single command and step by step supplemented with a 
simple discussion of a one-dimensional subspace of two-dimensional 
space.? He was happy.


 ??? ??????? 4.? I invite all to review and improve the discussion in 
the Wikipedia article on "Software repository".? This a table with a 
discussion of "Selected repositories", much of which I wrote 8 years 
ago.? It's heavily biased toward CRAN, because that's what I know the 
best, and I've so far been unable to find anyone with the expertise and 
interest in improving it.? This article averaged 290 views per day over 
the past 90 days, over 26,000 in the past 3 months.? If you can improve 
that article, an audience that size might be worth talking to.


 ?????? Spencer Graves

>
> Best regards,
>
> Rich
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rshepard at appl-ecosys.com  Wed Mar 14 18:56:08 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Wed, 14 Mar 2018 10:56:08 -0700 (PDT)
Subject: [R] Fwd:  Learning advanced R
In-Reply-To: <D52A9D91-8E09-461F-A344-67597502CADB@dcn.davis.ca.us>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>
 <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
 <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>
 <EC0F958E-BA6A-4ED6-B3BD-F1BB9A1CF3C7@dcn.davis.ca.us>
 <1521046718.3356229.1303102592.573E2D8E@webmail.messagingengine.com>
 <D52A9D91-8E09-461F-A344-67597502CADB@dcn.davis.ca.us>
Message-ID: <alpine.LNX.2.20.1803141052480.18676@salmo.appl-ecosys.com>

On Wed, 14 Mar 2018, Jeff Newmiller wrote:

> Nothing you have said tells me you have LaTeX working (a binary install of
> R does not depend on it), but if you actually know it is installed and
> available to R then that isn't the problem. Since you have not said what
> you actually did or what errors you encountered I can only shrug and
> suggest that that the website is a complete rendering of the book and the
> for-sale version makes a worthwhile contribution to the author and the
> community.

Jeff,

   Downloading the site as a .zip file and reading the README.md tells us
that pandoc is required. This is a format converter, apparently based on
Haskell given the large number of dependencies to build it. But, pandoc will
convert from markdown to LaTeX. I don't know the exact procedure as I've not
yet taken the time to install all dependencies to pandoc and build it. The
pandoc website has documentation.

Regards,

Rich


From alkauffm at fastmail.fm  Wed Mar 14 19:24:45 2018
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Wed, 14 Mar 2018 19:24:45 +0100
Subject: [R] Fwd:  Learning advanced R
In-Reply-To: <alpine.LNX.2.20.1803141052480.18676@salmo.appl-ecosys.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>
 <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
 <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>
 <EC0F958E-BA6A-4ED6-B3BD-F1BB9A1CF3C7@dcn.davis.ca.us>
 <1521046718.3356229.1303102592.573E2D8E@webmail.messagingengine.com>
 <D52A9D91-8E09-461F-A344-67597502CADB@dcn.davis.ca.us>
 <alpine.LNX.2.20.1803141052480.18676@salmo.appl-ecosys.com>
Message-ID: <1521051885.4112289.1303190768.51BB8200@webmail.messagingengine.com>

I've found two problems in interpreting adv-r-master/book/build-book.r:

1. All pathes in build-book.r refer to the starting-directory "adv-r-master". However, the script build-book.r is located in the directory "book", which is located in directory "adv-r-master". Therefore, pathes starting at "." are wrong (should start at "..").

2. Some file names have endings "Rmd", but e.g. in the line "chapters <- dir(".", pattern = "\\.rmd$")"  these endings are named "rmd". Therefore, the files (e.g. "base-types.Rmd") cannot be found.

Pandoc I have installed. Maybe there will arise further problems, but still I am experimenting with pathes.

Best,
Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mi, 14. M?r 2018, um 18:56, schrieb Rich Shepard:
> On Wed, 14 Mar 2018, Jeff Newmiller wrote:
> 
> > Nothing you have said tells me you have LaTeX working (a binary install of
> > R does not depend on it), but if you actually know it is installed and
> > available to R then that isn't the problem. Since you have not said what
> > you actually did or what errors you encountered I can only shrug and
> > suggest that that the website is a complete rendering of the book and the
> > for-sale version makes a worthwhile contribution to the author and the
> > community.
> 
> Jeff,
> 
>    Downloading the site as a .zip file and reading the README.md tells us
> that pandoc is required. This is a format converter, apparently based on
> Haskell given the large number of dependencies to build it. But, pandoc will
> convert from markdown to LaTeX. I don't know the exact procedure as I've not
> yet taken the time to install all dependencies to pandoc and build it. The
> pandoc website has documentation.
> 
> Regards,
> 
> Rich
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From thierry.onkelinx at inbo.be  Wed Mar 14 12:15:46 2018
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 14 Mar 2018 12:15:46 +0100
Subject: [R] Problem with reading data from an UTF-16 database
Message-ID: <CAJuCY5ybdCGTNhhbbCvSxUo0ibEVuJ9E5k7rs0Fxz+jwUNVnFA@mail.gmail.com>

Dear all,

We have a problem with reading some characters correctly from an UTF-16
encoded database. The code below givens the correct characters on Ubuntu
with the_driver = {ODBC Driver 13 for SQL Server}. On Windows (with
the_driver = {SQL Server}), special characters like '?' and '?' are
returned as '?'. I've added the sessionInfo() output from both machines.

Any suggestions on how to fix the problem?

Best regards,

Thierry

library(DBI)
con <- dbConnect(odbc::odbc(), .connection_string =
"Driver=the_drive;Server=our_server;Database=the_database;Trusted_Connection=Yes;")
dbGetQuery(con, sql_statement)


R version 3.4.2 (2017-09-28)
Platform: i386-w64-mingw32/i386 (32-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
[5] LC_TIME=Dutch_Belgium.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] RODBC_1.3-15 DBI_0.8

loaded via a namespace (and not attached):
 [1] Rcpp_0.12.14    R6_2.2.2        odbc_1.1.5      magrittr_1.5
pillar_1.1.0    rlang_0.2.0     testthat_2.0.0
 [8] blob_1.1.0      drat_0.1.3      fortunes_1.5-4  tools_3.4.2
 bit64_0.9-7     bit_1.1-12      hms_0.4.0
[15] yaml_2.1.14     compiler_3.4.2  pkgconfig_2.0.1 tibble_1.4.2


R version 3.4.3 (2017-11-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.4 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=nl_BE.UTF-8       LC_NUMERIC=C
 LC_TIME=nl_BE.UTF-8        LC_COLLATE=nl_BE.UTF-8
 [5] LC_MONETARY=nl_BE.UTF-8    LC_MESSAGES=nl_BE.UTF-8
LC_PAPER=nl_BE.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
 LC_MEASUREMENT=nl_BE.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] DBI_0.7

loaded via a namespace (and not attached):
 [1] drat_0.1.3     bit_1.1-12     odbc_1.1.2     compiler_3.4.3 hms_0.3
    tools_3.4.3    pillar_1.2.1   tibble_1.4.2
 [9] yaml_2.1.17    Rcpp_0.12.14   bit64_0.9-7    blob_1.1.0
 rlang_0.2.0    fortunes_1.5-4



ir. Thierry Onkelinx
Statisticus / Statistician

Vlaamse Overheid / Government of Flanders
INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
FOREST
Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
thierry.onkelinx at inbo.be
Havenlaan 88 bus 73, 1000 Brussel
www.inbo.be

///////////////////////////////////////////////////////////////////////////////////////////
To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey
///////////////////////////////////////////////////////////////////////////////////////////

<https://www.inbo.be>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 14 20:45:28 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 14 Mar 2018 15:45:28 -0400
Subject: [R] Problem with reading data from an UTF-16 database
In-Reply-To: <CAJuCY5ybdCGTNhhbbCvSxUo0ibEVuJ9E5k7rs0Fxz+jwUNVnFA@mail.gmail.com>
References: <CAJuCY5ybdCGTNhhbbCvSxUo0ibEVuJ9E5k7rs0Fxz+jwUNVnFA@mail.gmail.com>
Message-ID: <cfd9426f-da6a-9dae-eef1-564fc5edadc1@gmail.com>

On 14/03/2018 7:15 AM, Thierry Onkelinx wrote:
> Dear all,
> 
> We have a problem with reading some characters correctly from an UTF-16
> encoded database. The code below givens the correct characters on Ubuntu
> with the_driver = {ODBC Driver 13 for SQL Server}. On Windows (with
> the_driver = {SQL Server}), special characters like '?' and '?' are
> returned as '?'. I've added the sessionInfo() output from both machines.
> 
> Any suggestions on how to fix the problem?

I haven't tried it, but the RODBC package includes an argument 
DBMSencoding in the odbcDriverConnect function.  So maybe you could use 
that instead of DBI and odbc.

Duncan Murdoch
> 
> Best regards,
> 
> Thierry
> 
> library(DBI)
> con <- dbConnect(odbc::odbc(), .connection_string =
> "Driver=the_drive;Server=our_server;Database=the_database;Trusted_Connection=Yes;")
> dbGetQuery(con, sql_statement)
> 
> 
> R version 3.4.2 (2017-09-28)
> Platform: i386-w64-mingw32/i386 (32-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> [5] LC_TIME=Dutch_Belgium.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] RODBC_1.3-15 DBI_0.8
> 
> loaded via a namespace (and not attached):
>   [1] Rcpp_0.12.14    R6_2.2.2        odbc_1.1.5      magrittr_1.5
> pillar_1.1.0    rlang_0.2.0     testthat_2.0.0
>   [8] blob_1.1.0      drat_0.1.3      fortunes_1.5-4  tools_3.4.2
>   bit64_0.9-7     bit_1.1-12      hms_0.4.0
> [15] yaml_2.1.14     compiler_3.4.2  pkgconfig_2.0.1 tibble_1.4.2
> 
> 
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.4 LTS
> 
> Matrix products: default
> BLAS: /usr/lib/libblas/libblas.so.3.6.0
> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
> 
> locale:
>   [1] LC_CTYPE=nl_BE.UTF-8       LC_NUMERIC=C
>   LC_TIME=nl_BE.UTF-8        LC_COLLATE=nl_BE.UTF-8
>   [5] LC_MONETARY=nl_BE.UTF-8    LC_MESSAGES=nl_BE.UTF-8
> LC_PAPER=nl_BE.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>   LC_MEASUREMENT=nl_BE.UTF-8 LC_IDENTIFICATION=C
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] DBI_0.7
> 
> loaded via a namespace (and not attached):
>   [1] drat_0.1.3     bit_1.1-12     odbc_1.1.2     compiler_3.4.3 hms_0.3
>      tools_3.4.3    pillar_1.2.1   tibble_1.4.2
>   [9] yaml_2.1.17    Rcpp_0.12.14   bit64_0.9-7    blob_1.1.0
>   rlang_0.2.0    fortunes_1.5-4
> 
> 
> 
> ir. Thierry Onkelinx
> Statisticus / Statistician
> 
> Vlaamse Overheid / Government of Flanders
> INSTITUUT VOOR NATUUR- EN BOSONDERZOEK / RESEARCH INSTITUTE FOR NATURE AND
> FOREST
> Team Biometrie & Kwaliteitszorg / Team Biometrics & Quality Assurance
> thierry.onkelinx at inbo.be
> Havenlaan 88 bus 73, 1000 Brussel
> www.inbo.be
> 
> ///////////////////////////////////////////////////////////////////////////////////////////
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
> ///////////////////////////////////////////////////////////////////////////////////////////
> 
> <https://www.inbo.be>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From davidsmi at microsoft.com  Wed Mar 14 22:31:12 2018
From: davidsmi at microsoft.com (David Smith (CDA))
Date: Wed, 14 Mar 2018 21:31:12 +0000
Subject: [R] Revolutions blog: February 2018 roundup
Message-ID: <CY4PR21MB0790686892E08908B0837F77C8D10@CY4PR21MB0790.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of February:

The R Consortium opens a new round of grant applications for R-related user
groups and projects
http://blog.revolutionanalytics.com/2018/02/r-consortium-sponsorships.html and
has granted US$0.5M for projects to date
http://blog.revolutionanalytics.com/2018/02/r-consortium-milestone.html

Microsoft R Client 3.4.3 and Microsoft ML Server 9.3, both built with R 3.4.3,
have been released: http://blog.revolutionanalytics.com/2018/02/mrclient343.html

An 8-step, 5-minute tutorial for setting up a cluster in Azure for use with
the sparklyr package: http://blog.revolutionanalytics.com/2018/02/aztk-sparklyr.html

A smartphone app uses R and the keras package to identify "spells" using
accelerometer data
http://blog.revolutionanalytics.com/2018/02/accelerometers.html

"Machine Learning with R and Tensorflow", JJ Allaire's keynote presentation at
RStudio::conf http://blog.revolutionanalytics.com/2018/02/r-with-tensorflow.html

A guide to styling base graphics in R:
http://blog.revolutionanalytics.com/2018/02/pretty-base-graphics.html

A list of applications, open source projects, and extensions from Microsoft
related to R:
http://blog.revolutionanalytics.com/2018/02/what-does-microsoft-do-with-r.html

Several upcoming R conferences offer diversity scholarships:
http://blog.revolutionanalytics.com/2018/02/diversity-scholarships.html

Introducing the DataExplorer package, for quick data summaries and
visualizations: http://blog.revolutionanalytics.com/2018/02/dataexplorer.html

A video overview of the Data Science Virtual Machine, featuring R:
http://blog.revolutionanalytics.com/2018/02/dsvm-on-ai-show.html

"Asking the right questions about AI", an essay about the ethical implications
of predictions
http://blog.revolutionanalytics.com/2018/02/how-ai-works-and-fails.html

And some general interest stories (not necessarily related to R):

*  A sci-fi short about faster-than-light travel:
   http://blog.revolutionanalytics.com/2018/02/because-its-friday-faster-than-light.html

* A robot holds a door open so another robot can pass:
  http://blog.revolutionanalytics.com/2018/02/because-its-friday-hold-the-door.html

* SpaceX launches a car into space:
  http://blog.revolutionanalytics.com/2018/02/because-its-friday-bon-voyage-starman.html

* A bizarre CGI short film, Time for Sushi:
  http://blog.revolutionanalytics.com/2018/02/because-its-friday-time-for-sushi.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From alkauffm at fastmail.fm  Thu Mar 15 01:14:52 2018
From: alkauffm at fastmail.fm (Albrecht Kauffmann)
Date: Thu, 15 Mar 2018 01:14:52 +0100
Subject: [R] Fwd:  Learning advanced R
In-Reply-To: <1521051885.4112289.1303190768.51BB8200@webmail.messagingengine.com>
References: <mailman.348878.1.1520938802.58287.r-help@r-project.org>
 <190910163.940556.1520976395250.JavaMail.zimbra@beacon.partek.com>
 <CAHz+bWYbfwPJC-5sbv3reU4cwpV0-b6JzcjZHbXeTnhF+0Sn7g@mail.gmail.com>
 <alpine.LNX.2.20.1803131512570.28718@salmo.appl-ecosys.com>
 <CAGgJW75zyC_NN63mGiz5hPU8mK1NMxzZvTik3oNPYLDv+FikGw@mail.gmail.com>
 <1521045088.2621271.1303065608.5E48861C@webmail.messagingengine.com>
 <CAGgJW76ES6xf7YVUhJgwFyehH2deaTYsWdXy4B6UdiioDr7EGg@mail.gmail.com>
 <EC0F958E-BA6A-4ED6-B3BD-F1BB9A1CF3C7@dcn.davis.ca.us>
 <1521046718.3356229.1303102592.573E2D8E@webmail.messagingengine.com>
 <D52A9D91-8E09-461F-A344-67597502CADB@dcn.davis.ca.us>
 <alpine.LNX.2.20.1803141052480.18676@salmo.appl-ecosys.com>
 <1521051885.4112289.1303190768.51BB8200@webmail.messagingengine.com>
Message-ID: <1521072892.152327.1303575672.25963CDE@webmail.messagingengine.com>

I've found the solution to compile the adv-r-book from source: After doing some settings (see: 
https://travis-ci.org/hadley/adv-r/jobs/353347080/config ) 
and installation of netlify-cli, the command-line is:
Rscript -e 'bookdown::render_book("index.Rmd","bookdown::pdf_book")'

This works fine. Thank you for all hints!

Best, Albrecht

-- 
  Albrecht Kauffmann
  alkauffm at fastmail.fm

Am Mi, 14. M?r 2018, um 19:24, schrieb Albrecht Kauffmann:
> I've found two problems in interpreting adv-r-master/book/build-book.r:
> 
> 1. All pathes in build-book.r refer to the starting-directory "adv-r-
> master". However, the script build-book.r is located in the directory 
> "book", which is located in directory "adv-r-master". Therefore, pathes 
> starting at "." are wrong (should start at "..").
> 
> 2. Some file names have endings "Rmd", but e.g. in the line "chapters <- 
> dir(".", pattern = "\\.rmd$")"  these endings are named "rmd". 
> Therefore, the files (e.g. "base-types.Rmd") cannot be found.
> 
> Pandoc I have installed. Maybe there will arise further problems, but 
> still I am experimenting with pathes.
> 
> Best,
> Albrecht
> 
> -- 
>   Albrecht Kauffmann
>   alkauffm at fastmail.fm
> 
> Am Mi, 14. M?r 2018, um 18:56, schrieb Rich Shepard:
> > On Wed, 14 Mar 2018, Jeff Newmiller wrote:
> > 
> > > Nothing you have said tells me you have LaTeX working (a binary install of
> > > R does not depend on it), but if you actually know it is installed and
> > > available to R then that isn't the problem. Since you have not said what
> > > you actually did or what errors you encountered I can only shrug and
> > > suggest that that the website is a complete rendering of the book and the
> > > for-sale version makes a worthwhile contribution to the author and the
> > > community.
> > 
> > Jeff,
> > 
> >    Downloading the site as a .zip file and reading the README.md tells us
> > that pandoc is required. This is a format converter, apparently based on
> > Haskell given the large number of dependencies to build it. But, pandoc will
> > convert from markdown to LaTeX. I don't know the exact procedure as I've not
> > yet taken the time to install all dependencies to pandoc and build it. The
> > pandoc website has documentation.
> > 
> > Regards,
> > 
> > Rich
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jake.andrae at adelaide.edu.au  Thu Mar 15 05:14:21 2018
From: jake.andrae at adelaide.edu.au (Jake William Andrae)
Date: Thu, 15 Mar 2018 04:14:21 +0000
Subject: [R] Vary an equation using values from a sequence
Message-ID: <ME1PR01MB0932F9EE42BBD99446A16CD0A9D00@ME1PR01MB0932.ausprd01.prod.outlook.com>

Hi All,

I have a vector of data on which I am operating. The equation with which I want to operate on the vector has a value k. I want to run the equation and output a new vector, each time replacing k with each value from the sequence I defined. I have thought about using for loops and such, but this seems like overkill. I am wondering if there is a simple solution that would allow me to accomplish this.


The code I am using is outlined below.


Data <- c(1:10) #Data
value <- seq(from = 0, to = 100 , by = 0.01) #Sequence
Data - min(Data) + k # Equation

Thanks,
Jake


Jake Andrae
PhD Candidate
Geology & Geophysics ? Sprigg Geobiology Centre
Department of Earth Science
School of Physical Sciences
The University of Adelaide, AUSTRALIA 5005
Phone: 0407701565
Email: jake.andrae at adelaide.edu.au


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Mar 15 05:53:18 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 14 Mar 2018 21:53:18 -0700
Subject: [R] Vary an equation using values from a sequence
In-Reply-To: <ME1PR01MB0932F9EE42BBD99446A16CD0A9D00@ME1PR01MB0932.ausprd01.prod.outlook.com>
References: <ME1PR01MB0932F9EE42BBD99446A16CD0A9D00@ME1PR01MB0932.ausprd01.prod.outlook.com>
Message-ID: <CAGxFJbRi8rBi-_L0zd4CgPG4nkMgBn-rvXyOA4bt+PhGPhC9qA@mail.gmail.com>

I thnk what you want is ?outer. e.g.:

outer(Data -min(Data),value,FUN = "+")

Whether this works for your real task, however, may depend on details and
complexities that you have omitted.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 14, 2018 at 9:14 PM, Jake William Andrae <
jake.andrae at adelaide.edu.au> wrote:

> Hi All,
>
> I have a vector of data on which I am operating. The equation with which I
> want to operate on the vector has a value k. I want to run the equation and
> output a new vector, each time replacing k with each value from the
> sequence I defined. I have thought about using for loops and such, but this
> seems like overkill. I am wondering if there is a simple solution that
> would allow me to accomplish this.
>
>
> The code I am using is outlined below.
>
>
> Data <- c(1:10) #Data
> value <- seq(from = 0, to = 100 , by = 0.01) #Sequence
> Data - min(Data) + k # Equation
>
> Thanks,
> Jake
>
>
> Jake Andrae
> PhD Candidate
> Geology & Geophysics ? Sprigg Geobiology Centre
> Department of Earth Science
> School of Physical Sciences
> The University of Adelaide, AUSTRALIA 5005
> Phone: 0407701565
> Email: jake.andrae at adelaide.edu.au
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From jake.andrae at adelaide.edu.au  Thu Mar 15 06:11:32 2018
From: jake.andrae at adelaide.edu.au (Jake William Andrae)
Date: Thu, 15 Mar 2018 05:11:32 +0000
Subject: [R] Vary an equation using values from a sequence
In-Reply-To: <CAGxFJbRi8rBi-_L0zd4CgPG4nkMgBn-rvXyOA4bt+PhGPhC9qA@mail.gmail.com>
References: <ME1PR01MB0932F9EE42BBD99446A16CD0A9D00@ME1PR01MB0932.ausprd01.prod.outlook.com>,
 <CAGxFJbRi8rBi-_L0zd4CgPG4nkMgBn-rvXyOA4bt+PhGPhC9qA@mail.gmail.com>
Message-ID: <ME1PR01MB093203E4C1B1CA7DA12F496AA9D00@ME1PR01MB0932.ausprd01.prod.outlook.com>

Thank you, I?ll give it a try.
Jake

Get Outlook for iOS<https://aka.ms/o0ukef>
________________________________
From: Bert Gunter <bgunter.4567 at gmail.com>
Sent: Thursday, March 15, 2018 3:23:18 PM
To: Jake William Andrae
Cc: R-help
Subject: Re: [R] Vary an equation using values from a sequence

I thnk what you want is ?outer. e.g.:

outer(Data -min(Data),value,FUN = "+")

Whether this works for your real task, however, may depend on details and complexities that you have omitted.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 14, 2018 at 9:14 PM, Jake William Andrae <jake.andrae at adelaide.edu.au<mailto:jake.andrae at adelaide.edu.au>> wrote:
Hi All,

I have a vector of data on which I am operating. The equation with which I want to operate on the vector has a value k. I want to run the equation and output a new vector, each time replacing k with each value from the sequence I defined. I have thought about using for loops and such, but this seems like overkill. I am wondering if there is a simple solution that would allow me to accomplish this.


The code I am using is outlined below.


Data <- c(1:10) #Data
value <- seq(from = 0, to = 100 , by = 0.01) #Sequence
Data - min(Data) + k # Equation

Thanks,
Jake


Jake Andrae
PhD Candidate
Geology & Geophysics ? Sprigg Geobiology Centre
Department of Earth Science
School of Physical Sciences
The University of Adelaide, AUSTRALIA 5005
Phone: 0407701565
Email: jake.andrae at adelaide.edu.au<mailto:jake.andrae at adelaide.edu.au>


        [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



	[[alternative HTML version deleted]]


From cypayne at stanford.edu  Thu Mar 15 01:11:43 2018
From: cypayne at stanford.edu (Cheyenne Yancey Payne)
Date: Thu, 15 Mar 2018 00:11:43 +0000
Subject: [R] stats 'dist' euclidean distance calculation
Message-ID: <CY1PR02MB16281943A70A75E8840D5AEBCED10@CY1PR02MB1628.namprd02.prod.outlook.com>

Hello,

I am working with a matrix of multilocus genotypes for ~180 individual snail samples, with substantial missing data. I am trying to calculate the pairwise genetic distance between individuals using the stats package 'dist' function, using euclidean distance. I took a subset of this dataset (3 samples x 3 loci) to test how euclidean distance is calculated:

3x3 subset used
                         Locus1     Locus2         Locus3
Samp1               GG           <NA>           GG
Samp2               AG             CA              GA
Samp3               AG             CA              GG

The euclidean distance function is defined as: sqrt(sum((x_i - y_i)^2))
My assumption was that the difference between x_i and y_i would be the number of allelic differences at each base pair site between samples. For example, the euclidean distance between Samp1 and Samp2 would be:

euclidean distance = sqrt( S1_L1 - S2_L1)^2 + (S1_L2 - S2_L2)^2 + (S1_L3 - S2_L3)^2 )
at locus 1: GG - AG --> one basepair difference --> (1)^2 = 1
at locus 2: <NA> - CA --> two basepair differences --> (2)^2 = 4
at locus 3: GG - GA --> one basepair difference --> (1)^2 = 1

euclidean distance = sqrt( 1 + 4 + 1 ) = sqrt( 6 ) = 2.44940

Calculating euclidean distances this way, the distance matrix should be:
#                   Samp1               Samp2             Samp3
# Samp1       0.000000           2.449400          2.236068
# Samp2       2.449400           0.000000          1.000000
# Samp3       2.236068           1.000000          0.000000

However, this distance matrix differs from the one calculated by the R stats package 'dist' function:
#                   Samp1               Samp2             Samp3
# Samp1       0.000000           3.478652          2.659285
# Samp2       3.478652           0.000000          2.124787
# Samp3       2.659285           2.124787          0.000000

I used the following code (with intermediate output) to achieve the latter distance matrix:


>>>
setwd("~/Desktop/R_stuff")

### Data Prep: load and collect info from matrix file
infile<-'~/Desktop/R_stuff/good_conch_mplex_03052018.txt'
Mydata <- read.table(infile, header = TRUE, check.names = FALSE)
dim(Mydata) # dimensions of data.frame
ind <- as.character(Mydata$sample) # individual labels
population <- as.character(Mydata$region) # population labels
location <- Mydata$location

### Section 1: Convert data to usable format
# removes non-genotype data from matrix (i.e. lines 1-4)
# subset 3 samples, 3 loci for testing
SAMPS<-3
locus <- Mydata[c(1:SAMPS), -c(1, 2, 3, 4, 5+SAMPS:ncol(Mydata))]
locus
#                       Locus1     Locus2         Locus3
# Samp1               GG           <NA>           GG
# Samp2               AG             CA              GA
# Samp3               AG             CA              GG

# converts geno matrix to genind object (adegenet)
Mydata1 <- df2genind(locus, ploidy = 2, ind.names = ind[1:SAMPS], pop = population[1:SAMPS], sep="")
Mydata1$tab # get stats on newly created genind object
#                      Locus1.G     Locus1.A    Locus2.C    Locus2.A    Locus3.G    Locus3.A
# Samp1                  2                  0               NA             NA             2                 0
# Samp2                  1                  1                1                1               1                 1
# Samp3                  1                  1                1                1               2                 0

### Section 2: Individual genetic distance: euclidean distance (dist {adegenet})

# Test dist() function
# collect euclidean genetic distances
distgenEUCL <- dist(Mydata1, method = "euclidean", diag = FALSE, upper = FALSE, p = 2)
distgenEUCL
#                     Samp1              Samp2
# Samp2         2.449490
# Samp3         1.732051           1.414214

x<-as.matrix(dist(distgenEUCL))
x
#                   Samp1               Samp2             Samp3
# Samp1       0.000000           3.478652          2.659285
# Samp2       3.478652           0.000000          2.124787
# Samp3       2.659285           2.124787          0.000000
>>>



I have checked several forums and have been unable to resolve this discrepancy. Any and all help will be much appreciated!


Thank you!

Cheyenne


Cheyenne Payne

Bioinformatics Technician

Palumbi Lab | Hopkins Marine Station

(714) 200-5897

	[[alternative HTML version deleted]]


From pd.mes at cbs.dk  Thu Mar 15 09:59:19 2018
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Thu, 15 Mar 2018 08:59:19 +0000
Subject: [R] R 3.4.4 is released
Message-ID: <3A71D404-8C19-4393-858B-F219900855B5@cbs.dk>

The build system rolled up R-3.4.4.tar.gz (codename "Someone to Lean On") this morning.

This is intended to be the last of the 3.4.x release series. The list below details the changes.

You can get the source code from

http://cran.r-project.org/src/base/R-3/R-3.4.4.tar.gz

or wait for it to be mirrored at a CRAN site nearer to you.

Binaries for various platforms will appear in due course.


For the R Core Team,

Peter Dalgaard



These are the checksums (md5 and SHA-256) for the freshly created files, in case you wish
to check that they are uncorrupted:

MD5 (AUTHORS) = f12a9c3881197b20b08dd3d1f9d005e6
MD5 (COPYING) = eb723b61539feef013de476e68b5c50a
MD5 (COPYING.LIB) = a6f89e2100d9b6cdffcea4f398e37343
MD5 (FAQ) = 32a94aba902b293cf8b8dbbf4113f2ab
MD5 (INSTALL) = 7893f754308ca31f1ccf62055090ad7b
MD5 (NEWS) = f0ddf36639951987249a206fd4295da9
MD5 (NEWS.0) = bfcd7c147251b5474d96848c6f57e5a8
MD5 (NEWS.1) = eb78c4d053ec9c32b815cf0c2ebea801
MD5 (NEWS.2) = 591dcf615162127f904e4e461f330ce9
MD5 (R-latest.tar.gz) = 9d6f73be072531e95884c7965ff80cd8
MD5 (README) = f468f281c919665e276a1b691decbbe6
MD5 (RESOURCES) = 529223fd3ffef95731d0a87353108435
MD5 (THANKS) = f60d286bb7294cef00cb0eed4052a66f
MD5 (VERSION-INFO.dcf) = 00f5b3721b3b72360c92fbd9dc8c7411
MD5 (R-3/R-3.4.4.tar.gz) = 9d6f73be072531e95884c7965ff80cd8

6474d9791fff6a74936296bde3fcb569477f5958e4326189bd6e5ab878e0cd4f  AUTHORS
e6d6a009505e345fe949e1310334fcb0747f28dae2856759de102ab66b722cb4  COPYING
6095e9ffa777dd22839f7801aa845b31c9ed07f3d6bf8a26dc5d2dec8ccc0ef3  COPYING.LIB
7936facb07e752869342808b9c8879d0e270b1a9ec92b67ef4dd87496abfef0a  FAQ
f87461be6cbaecc4dce44ac58e5bd52364b0491ccdadaf846cb9b452e9550f31  INSTALL
6c231ff2da54f9a39ab1cf754c692d69b80f6004a6d28dbf29286b0d5bc0a109  NEWS
4e21b62f515b749f80997063fceab626d7258c7d650e81a662ba8e0640f12f62  NEWS.0
12b30c724117b1b2b11484673906a6dcd48a361f69fc420b36194f9218692d01  NEWS.1
ca04f78ffe54afa326fe3ed40e7e1411aca0000ed2fa5ead97ddf51c6aa5b7bc  NEWS.2
b3e97d2fab7256d1c655c4075934725ba1cd7cb9237240a11bb22ccdad960337  R-latest.tar.gz
2fdd3e90f23f32692d4b3a0c0452f2c219a10882033d1774f8cadf25886c3ddc  README
408737572ecc6e1135fdb2cf7a9dbb1a6cb27967c757f1771b8c39d1fd2f1ab9  RESOURCES
52f934a4e8581945cbc1ba234932749066b5744cbd3b1cb467ba6ef164975163  THANKS
03e5641c23de903c0a3c379bc0d4c5857805051954011da0d41271ab02a6db2f  VERSION-INFO.dcf
b3e97d2fab7256d1c655c4075934725ba1cd7cb9237240a11bb22ccdad960337  R-3/R-3.4.4.tar.gz


This is the relevant part of the NEWS file

CHANGES IN R 3.4.4:

  NEW FEATURES:

    * Sys.timezone() tries more heuristics on Unix-alikes and so is
      more likely to succeed (especially on Linux).  For the slowest
      method, a warning is given recommending that TZ is set to avoid
      the search.

    * The version of LAPACK included in the sources has been updated to
      3.8.0 (for the routines used by R, a very minor bug-fix change).

    * parallel::detectCores(logical = FALSE) is ignored on Linux
      systems, since the information is not available with virtualized
      OSes.

  INSTALLATION on a UNIX-ALIKE:

    * configure will use pkg-config to find the flags to link to jpeg
      if available (as it should be for the recently-released jpeg-9c
      and libjpeg-turbo).  (This amends the code added in R 3.3.0 as
      the module name in jpeg-9c is not what that tested for.)

  DEPRECATED AND DEFUNCT:

    * Sys.timezone(location = FALSE) (which was a stop-gap measure for
      Windows long ago) is deprecated.  It no longer returns the value
      of environment variable TZ (usually a location).

    * Legacy support of make macros such as CXX1X is formally
      deprecated: use the CXX11 forms instead.

  BUG FIXES:

    * power.prop.test() now warns when it cannot solve the problem,
      typically because of impossible constraints. (PR#17345)

    * removeSource() no longer erroneously removes NULL in certain
      cases, thanks to D'enes T'oth.

    * nls(`NO [mol/l]` ~ f(t)) and nls(y ~ a) now work.  (Partly from
      PR#17367)

    * R CMD build checks for GNU cp rather than assuming Linux has it.
      (PR#17370 says 'Alpine Linux' does not.)

    * Non-UTF-8 multibyte character handling fixed more permanently
      (PR#16732).

    * sum(<large ints>, <stuff>) is more consistent.  (PR#17372)

    * rf() and rbeta() now also work correctly when ncp is not scalar,
      notably when (partly) NA.  (PR#17375)

    * R CMD INSTALL now correctly sets C++ compiler flags when all
      source files are in sub-directories of src.
-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From ericbohlman at gmail.com  Wed Mar 14 23:14:26 2018
From: ericbohlman at gmail.com (Eric Bohlman)
Date: Wed, 14 Mar 2018 17:14:26 -0500
Subject: [R] [R-pkgs] New package ridittools
Message-ID: <8c8476aa-df85-5a33-6922-6138b83385fb@gmail.com>

A new package, ridittools, is available on CRAN

Description: Functions to compute ridit scores of vectors, compute mean
ridits and their standard errors for vectors compared to a reference 
vector,as described in Fleiss (1981, ISBN:0-471-06428-9), and compute
means/SEs for multiple groups in matrices. Data can be either
counts or proportions. Emphasis is on ridit analysis of ordered
categorical data such as Likert items and pain-rating scales.

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From ericjberger at gmail.com  Thu Mar 15 11:05:08 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 15 Mar 2018 12:05:08 +0200
Subject: [R] stats 'dist' euclidean distance calculation
In-Reply-To: <CY1PR02MB16281943A70A75E8840D5AEBCED10@CY1PR02MB1628.namprd02.prod.outlook.com>
References: <CY1PR02MB16281943A70A75E8840D5AEBCED10@CY1PR02MB1628.namprd02.prod.outlook.com>
Message-ID: <CAGgJW76nyt7MmxN=w_wrbbUrY6LayCV1Xpdw=tQ4kY9Vv_0ApA@mail.gmail.com>

Hi Cheyenne,

I noticed one thing that might be helpful to you.
First, I took a shortcut to the case of interest:

> m <- matrix(c(2,1,1,0,1,1,NA,1,1,NA,1,1,2,1,2,0,1,0),nrow=3)
> colnames(m) <- c("1.G","1.A","2.C","2.A","3.G","3.A")
> m
#       1.G  1.A  2.C  2.A  3.G  3.A
# [1,]   2    0     NA   NA   2     0
# [2,]   1   1      1      1      1     1
# [3,]   1   1      1      1      2     0

Computing the distance between the different rows by hand - TREATING THE
NA's AS ZERO -
would give:
dist(row1,row2) = sqrt( 1^2 + 1^2 + 1^2 + 1^2 + 1^2 + 1^2) = sqrt(6) = 2.45
dist(row1,row3) = sqrt(  1^2 + 1^2 + 1^2 + 1^2 + 0^2 + 0^2) = sqrt(4) = 2
dist(row2,row3) = sqrt(   0^2 + 0^2 + 0^2 + 0^2 + 1^2 + 1^2) = sqrt(2) =
1.414

Doing the same calculation with the dist() function gives
> dist(m)
#            1                  2
# 2        2.45
# 3        1.73              1.414

i.e. the results match with the manual calculation for dist(row1,row2) and
dist(row2,row3).
However for dist(row1,row3) which should be 2, the dist function gives 1.73
= sqrt(3).
Clearly sqrt(3) makes no sense since |1 - NA|^2 appears twice. Either both
times it should get a value of 1 or neither time. Why only once? Not clear
to me and I did not see any hints on ?dist.

However if you replace the NA's by actual 0's, which seems to be your
preferred methodology, then the problem is "solved", i.e.
> m2 <- m
> m2[1,][is.na(m2[1,])] <- 0
> dist(m2)
#            1                  2
# 2        2.45
# 3        2              1.414

HTH,
Eric



On Thu, Mar 15, 2018 at 2:11 AM, Cheyenne Yancey Payne <cypayne at stanford.edu
> wrote:

> Hello,
>
> I am working with a matrix of multilocus genotypes for ~180 individual
> snail samples, with substantial missing data. I am trying to calculate the
> pairwise genetic distance between individuals using the stats package
> 'dist' function, using euclidean distance. I took a subset of this dataset
> (3 samples x 3 loci) to test how euclidean distance is calculated:
>
> 3x3 subset used
>                          Locus1     Locus2         Locus3
> Samp1               GG           <NA>           GG
> Samp2               AG             CA              GA
> Samp3               AG             CA              GG
>
> The euclidean distance function is defined as: sqrt(sum((x_i - y_i)^2))
> My assumption was that the difference between x_i and y_i would be the
> number of allelic differences at each base pair site between samples. For
> example, the euclidean distance between Samp1 and Samp2 would be:
>
> euclidean distance = sqrt( S1_L1 - S2_L1)^2 + (S1_L2 - S2_L2)^2 + (S1_L3 -
> S2_L3)^2 )
> at locus 1: GG - AG --> one basepair difference --> (1)^2 = 1
> at locus 2: <NA> - CA --> two basepair differences --> (2)^2 = 4
> at locus 3: GG - GA --> one basepair difference --> (1)^2 = 1
>
> euclidean distance = sqrt( 1 + 4 + 1 ) = sqrt( 6 ) = 2.44940
>
> Calculating euclidean distances this way, the distance matrix should be:
> #                   Samp1               Samp2             Samp3
> # Samp1       0.000000           2.449400          2.236068
> # Samp2       2.449400           0.000000          1.000000
> # Samp3       2.236068           1.000000          0.000000
>
> However, this distance matrix differs from the one calculated by the R
> stats package 'dist' function:
> #                   Samp1               Samp2             Samp3
> # Samp1       0.000000           3.478652          2.659285
> # Samp2       3.478652           0.000000          2.124787
> # Samp3       2.659285           2.124787          0.000000
>
> I used the following code (with intermediate output) to achieve the latter
> distance matrix:
>
>
> >>>
> setwd("~/Desktop/R_stuff")
>
> ### Data Prep: load and collect info from matrix file
> infile<-'~/Desktop/R_stuff/good_conch_mplex_03052018.txt'
> Mydata <- read.table(infile, header = TRUE, check.names = FALSE)
> dim(Mydata) # dimensions of data.frame
> ind <- as.character(Mydata$sample) # individual labels
> population <- as.character(Mydata$region) # population labels
> location <- Mydata$location
>
> ### Section 1: Convert data to usable format
> # removes non-genotype data from matrix (i.e. lines 1-4)
> # subset 3 samples, 3 loci for testing
> SAMPS<-3
> locus <- Mydata[c(1:SAMPS), -c(1, 2, 3, 4, 5+SAMPS:ncol(Mydata))]
> locus
> #                       Locus1     Locus2         Locus3
> # Samp1               GG           <NA>           GG
> # Samp2               AG             CA              GA
> # Samp3               AG             CA              GG
>
> # converts geno matrix to genind object (adegenet)
> Mydata1 <- df2genind(locus, ploidy = 2, ind.names = ind[1:SAMPS], pop =
> population[1:SAMPS], sep="")
> Mydata1$tab # get stats on newly created genind object
> #                      Locus1.G     Locus1.A    Locus2.C    Locus2.A
> Locus3.G    Locus3.A
> # Samp1                  2                  0               NA
>  NA             2                 0
> # Samp2                  1                  1                1
>     1               1                 1
> # Samp3                  1                  1                1
>     1               2                 0
>
> ### Section 2: Individual genetic distance: euclidean distance (dist
> {adegenet})
>
> # Test dist() function
> # collect euclidean genetic distances
> distgenEUCL <- dist(Mydata1, method = "euclidean", diag = FALSE, upper =
> FALSE, p = 2)
> distgenEUCL
> #                     Samp1              Samp2
> # Samp2         2.449490
> # Samp3         1.732051           1.414214
>
> x<-as.matrix(dist(distgenEUCL))
> x
> #                   Samp1               Samp2             Samp3
> # Samp1       0.000000           3.478652          2.659285
> # Samp2       3.478652           0.000000          2.124787
> # Samp3       2.659285           2.124787          0.000000
> >>>
>
>
>
> I have checked several forums and have been unable to resolve this
> discrepancy. Any and all help will be much appreciated!
>
>
> Thank you!
>
> Cheyenne
>
>
> Cheyenne Payne
>
> Bioinformatics Technician
>
> Palumbi Lab | Hopkins Marine Station
>
> (714) 200-5897
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From joerodonnell at gmail.com  Thu Mar 15 12:16:06 2018
From: joerodonnell at gmail.com (Joe O)
Date: Thu, 15 Mar 2018 04:16:06 -0700
Subject: [R] Adjusting OHCL data via quantmod
Message-ID: <CA+BE2NO8yEu2Xkk_po-U4zAwVuTJKXxZ_gCEv_bmxrObKaWKYw@mail.gmail.com>

Hello,

I'm trying to do two things:
-1. Ensure that I understand how quantmod adjust's OHLC data
-2. Determine how I ought to adjust my data.

My overarching-goal is to adjust my OHLC data appropriately to minimize the
difference between my backtest returns, and the returns I would get if I
was trading for real (which I'll be doing shortly).

Background:
-1. I'm using Alpha Vantage's data, and quantmod's data adjustment tools.
-2: I used Joshua Ulrich's DataCamp guidance (
https://campus.datacamp.com/courses/importing-and-managing-financial-data-in-r/importing-text-data-and-adjusting-for-corporate-actions?ex=10)
(and quantmod documentation) to determine how Alpha Vantage's data is
adjusted.

Here are my findings:

-It seems that Alpha Vantage's OHLC data are unadjusted, and the adjusted
close column provided is adjusted for splits, and split-adjusted dividends.
-If I use AV's adjusted close column to adjust my OHCL data, my data will
be adjusted for splits, and split-adjusted dividends. (So, I can use
adjustOHLC(), with argument use.Adjusted = TRUE to adjust for splits, and
split-adjusted dividends)

Evidence:

###
library(quantmod)

#AV data
getSymbols("AAPL",src = "av" ,api.key = my_api_key
           , adjusted = TRUE, output.size = "full") #supply your own api key

#Manual adjustments for splits, and split-adjusted dividends
close_av <- Cl(AAPL)
splits <- getSplits("AAPL")
dividends <- getDividends("AAPL", split.adjust = TRUE)
ratios_av <- adjRatios(splits = splits, dividends = dividends, close =
close_av)
close_av_adj <- close_av * ratios_av[,"Div"] * ratios_av[,"Split"]
head(merge(close_av, close_av_adj, Ad(AAPL)))

#The leftmost column is the raw close data from Alpha Vantage,
#the middle column is the raw Alpha Vantage close column manually adjusted
#for splits and split-adjusted dividends, and the last column is the
adjusted close column returned by Alpha Vantage

#Adjust all data for splits, and split-adjusted dividends (I think)
AAPL_a <- adjustOHLC(AAPL, use.Adjusted = TRUE)
head(AAPL_a)
###

Two questions:
-1. Am I interpreting these adjustments correctly?
-2. What adjustment method minimizes the difference between backtesting and
live-trading?

p.s., I expect there is no "correct" method for adjusting data. I'm curious
if there is a "best-practice" or norm that is used. I'm curious if there is
a method which minimizes the difference between backtesting and
live-trading. Thanks you, -Joe

	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Thu Mar 15 13:11:18 2018
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 15 Mar 2018 12:11:18 +0000
Subject: [R] stats 'dist' euclidean distance calculation
In-Reply-To: <CY1PR02MB16281943A70A75E8840D5AEBCED10@CY1PR02MB1628.namprd02.prod.outlook.com>
References: <CY1PR02MB16281943A70A75E8840D5AEBCED10@CY1PR02MB1628.namprd02.prod.outlook.com>
Message-ID: <1A8C1289955EF649A09086A153E267240C42A1DB05@GBTEDVPEXCMB04.corp.lgc-group.com>

> 3x3 subset used
>                          Locus1     Locus2         Locus3
> Samp1               GG           <NA>           GG
> Samp2               AG             CA              GA
> Samp3               AG             CA              GG
> 
> The euclidean distance function is defined as: sqrt(sum((x_i - y_i)^2)) My
> assumption was that the difference between x_i and y_i would be the number
> of allelic differences at each base pair site between samples. 

Base R does not share your assumption, which (from a general purpose stats point of view) would be a completely outlandish interpretation of the data. As far as base R is concerned, these are just arbitrary character strings represented (by default) as factors. Since factors are, internally, integers assigned (by default) in increasing lexical order to the levels present, if you apply dist() to factors constructed from allele data, you will usually get complete nonsense in genetic terms. 

You should probably look at something like dist.gene in the ape package: see
https://www.rdocumentation.org/packages/ape/versions/5.0/topics/dist.gene

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From HaviM at gertner.health.gov.il  Thu Mar 15 13:18:07 2018
From: HaviM at gertner.health.gov.il (HaviM at gertner.health.gov.il)
Date: Thu, 15 Mar 2018 12:18:07 +0000
Subject: [R] jointModel error messages
Message-ID: <03A96F12D1883D438AA5D7E19309D402DF126CD1@gertner-ex10.MOH.HEALTH.GOV.IL>

Dear Graham.

Any updates regarding your message about JointModel error messages? I am encountering similar errors.

Thank you.
Havi

	[[alternative HTML version deleted]]


From rshepard at appl-ecosys.com  Thu Mar 15 13:51:07 2018
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Thu, 15 Mar 2018 05:51:07 -0700 (PDT)
Subject: [R] R 3.4.4 is released
In-Reply-To: <3A71D404-8C19-4393-858B-F219900855B5@cbs.dk>
References: <3A71D404-8C19-4393-858B-F219900855B5@cbs.dk>
Message-ID: <alpine.LNX.2.20.1803150549260.22137@salmo.appl-ecosys.com>

On Thu, 15 Mar 2018, Peter Dalgaard via R-help wrote:

> The build system rolled up R-3.4.4.tar.gz (codename "Someone to Lean On")
> this morning.

Peter,

   My thanks to all developers for the work you do.

Best regards,

Rich


From bgunter.4567 at gmail.com  Thu Mar 15 15:53:23 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Mar 2018 07:53:23 -0700
Subject: [R] stats 'dist' euclidean distance calculation
In-Reply-To: <1A8C1289955EF649A09086A153E267240C42A1DB05@GBTEDVPEXCMB04.corp.lgc-group.com>
References: <CY1PR02MB16281943A70A75E8840D5AEBCED10@CY1PR02MB1628.namprd02.prod.outlook.com>
 <1A8C1289955EF649A09086A153E267240C42A1DB05@GBTEDVPEXCMB04.corp.lgc-group.com>
Message-ID: <CAGxFJbQNe_bWeCT2bBhCay8tQvqE0AD8SaHvVhZxJyA7NQT9nA@mail.gmail.com>

.... and I believe this whole thread may fit better at the Bioconductor
list rather than here.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Mar 15, 2018 at 5:11 AM, S Ellison <S.Ellison at lgcgroup.com> wrote:

> > 3x3 subset used
> >                          Locus1     Locus2         Locus3
> > Samp1               GG           <NA>           GG
> > Samp2               AG             CA              GA
> > Samp3               AG             CA              GG
> >
> > The euclidean distance function is defined as: sqrt(sum((x_i - y_i)^2))
> My
> > assumption was that the difference between x_i and y_i would be the
> number
> > of allelic differences at each base pair site between samples.
>
> Base R does not share your assumption, which (from a general purpose stats
> point of view) would be a completely outlandish interpretation of the data.
> As far as base R is concerned, these are just arbitrary character strings
> represented (by default) as factors. Since factors are, internally,
> integers assigned (by default) in increasing lexical order to the levels
> present, if you apply dist() to factors constructed from allele data, you
> will usually get complete nonsense in genetic terms.
>
> You should probably look at something like dist.gene in the ape package:
> see
> https://www.rdocumentation.org/packages/ape/versions/5.0/topics/dist.gene
>
> S Ellison
>
>
> *******************************************************************
> This email and any attachments are confidential. Any u...{{dropped:13}}


From joerodonnell at gmail.com  Thu Mar 15 21:56:47 2018
From: joerodonnell at gmail.com (Joe O)
Date: Thu, 15 Mar 2018 13:56:47 -0700
Subject: [R] Adjusting OHCL data via quantmod
In-Reply-To: <CA+BE2NO8yEu2Xkk_po-U4zAwVuTJKXxZ_gCEv_bmxrObKaWKYw@mail.gmail.com>
References: <CA+BE2NO8yEu2Xkk_po-U4zAwVuTJKXxZ_gCEv_bmxrObKaWKYw@mail.gmail.com>
Message-ID: <CA+BE2NPYTdr2AQThgpSNFJ1DQqyoMcbyLYrAKKBOhOycYtQ9Ww@mail.gmail.com>

Took out snippet of problematic code:

###
library(quantmod)

#AV data. Supply your own api key
getSymbols("AAPL",src = "av" ,api.key = my_api_key
           , adjusted = TRUE, output.size = "full")

#Manual adjustments for splits, and split-adjusted dividends
close_av <- Cl(AAPL)
splits <- getSplits("AAPL")
dividends <- getDividends("AAPL", split.adjust = TRUE)
ratios_av <- adjRatios(splits = splits, dividends = dividends, close =
close_av)
close_av_adj <- close_av * ratios_av[,"Div"] * ratios_av[,"Split"]
head(merge(close_av, close_av_adj, Ad(AAPL)))

#Adjust all data for splits, and split-adjusted dividends (I think)
AAPL_a <- adjustOHLC(AAPL, use.Adjusted = TRUE)
head(AAPL_a)
###


On Thu, Mar 15, 2018 at 4:16 AM, Joe O <joerodonnell at gmail.com> wrote:

> Hello,
>
> I'm trying to do two things:
> -1. Ensure that I understand how quantmod adjust's OHLC data
> -2. Determine how I ought to adjust my data.
>
> My overarching-goal is to adjust my OHLC data appropriately to minimize
> the difference between my backtest returns, and the returns I would get if
> I was trading for real (which I'll be doing shortly).
>
> Background:
> -1. I'm using Alpha Vantage's data, and quantmod's data adjustment tools.
> -2: I used Joshua Ulrich's DataCamp guidance (https://campus.datacamp.com/
> courses/importing-and-managing-financial-data-in-r/
> importing-text-data-and-adjusting-for-corporate-actions?ex=10) (and
> quantmod documentation) to determine how Alpha Vantage's data is adjusted.
>
> Here are my findings:
>
> -It seems that Alpha Vantage's OHLC data are unadjusted, and the adjusted
> close column provided is adjusted for splits, and split-adjusted dividends.
> -If I use AV's adjusted close column to adjust my OHCL data, my data will
> be adjusted for splits, and split-adjusted dividends. (So, I can use
> adjustOHLC(), with argument use.Adjusted = TRUE to adjust for splits, and
> split-adjusted dividends)
>
> Evidence:
>
> ###
> library(quantmod)
>
> #AV data
> getSymbols("AAPL",src = "av" ,api.key = my_api_key
>            , adjusted = TRUE, output.size = "full") #supply your own api
> key
>
> #Manual adjustments for splits, and split-adjusted dividends
> close_av <- Cl(AAPL)
> splits <- getSplits("AAPL")
> dividends <- getDividends("AAPL", split.adjust = TRUE)
> ratios_av <- adjRatios(splits = splits, dividends = dividends, close =
> close_av)
> close_av_adj <- close_av * ratios_av[,"Div"] * ratios_av[,"Split"]
> head(merge(close_av, close_av_adj, Ad(AAPL)))
>
> #The leftmost column is the raw close data from Alpha Vantage,
> #the middle column is the raw Alpha Vantage close column manually adjusted
> #for splits and split-adjusted dividends, and the last column is the
> adjusted close column returned by Alpha Vantage
>
> #Adjust all data for splits, and split-adjusted dividends (I think)
> AAPL_a <- adjustOHLC(AAPL, use.Adjusted = TRUE)
> head(AAPL_a)
> ###
>
> Two questions:
> -1. Am I interpreting these adjustments correctly?
> -2. What adjustment method minimizes the difference between backtesting
> and live-trading?
>
> p.s., I expect there is no "correct" method for adjusting data. I'm
> curious if there is a "best-practice" or norm that is used. I'm curious if
> there is a method which minimizes the difference between backtesting and
> live-trading. Thanks you, -Joe
>

	[[alternative HTML version deleted]]


From manishmukherjee at hotmail.com  Thu Mar 15 23:18:32 2018
From: manishmukherjee at hotmail.com (Manish Mukherjee)
Date: Thu, 15 Mar 2018 22:18:32 +0000
Subject: [R] R code for Batch forecasting
Message-ID: <BM1PR0101MB1921C4985DBEAB0E3D214B29B9D00@BM1PR0101MB1921.INDPRD01.PROD.OUTLOOK.COM>

Hi All,


Is there was where we can predict the time series for multiple items in one go - i mean can we run the code for any time series model over multiple columns using for loop or something else . If someone can provide some example it will be helpfull.


Thanks & Regards
Manish Mukherjee

	[[alternative HTML version deleted]]


From klebyn at yahoo.com.br  Thu Mar 15 23:36:03 2018
From: klebyn at yahoo.com.br (Cleber N.Borges)
Date: Thu, 15 Mar 2018 19:36:03 -0300
Subject: [R] cubic complete Scheffe mixture models
Message-ID: <ecb3951d-36f8-3442-6424-33c18b191f70@yahoo.com.br>

Hello everyone
I'm trying to use Scheffe's complete cubic model (mixture design).
In the bibliographies, they indicate that the term is of the type: A * B 
* (A-B).

But I see that trying to adjust the three cubic terms results in 
singularities.

I know this implies not having the inverse matrix:
solve (t (X)% *% X) does not exist.
The bibliographies show all three cubic terms.

So my question:

How to circumvent the singularity and estimate the coefficients for 
these terms in Scheffe's complete cubic model in the modeling of 
Chemical Blends?

Thanks in advance for any help.
Thank you so much
Cleber Borges


####? MY_DATA:

 ???????? H2O TOL?????? MET????? Response
1? 1.0000000 0.0000000 0.0000000??? 0.39056923
2? 0.0000000 1.0000000 0.0000000?? -1.49611856
3? 0.0000000 0.0000000 1.0000000?? -0.33922649
4? 0.5000000 0.5000000 0.0000000?? -0.65517683
5? 0.5000000 0.0000000 0.5000000?? -1.23281158
6? 0.0000000 0.5000000 0.5000000??? 0.51523665
7? 0.3333333 0.3333333 0.3333333?? -0.93516022
8? 0.3333333 0.3333333 0.3333333?? -0.84429633
9? 0.6666667 0.1666667 0.1666667??? 0.55931646
10 0.6666667 0.1666667 0.1666667??? 0.47999083
11 0.1666667 0.6666667 0.1666667??? 0.07182446
12 0.1666667 0.6666667 0.1666667?? -0.01813801
13 0.1666667 0.1666667 0.6666667??? 1.79895957
14 0.1666667 0.1666667 0.6666667??? 1.70503083

#? my try:

reg <- lm( Response ~ -1 + H2O*TOL*MET + I(H2O*TOL*(H2O-TOL)) + 
I(H2O*MET*(H2O-MET)) + I(TOL*MET*(TOL-MET)), data=MY_DATA )

summary( reg )

##

Coefficients: (1 not defined because of singularities)
 ?????????????????????????? Estimate Std. Error t value Pr(>|t|)
H2O????????????????????????? 0.6279???? 1.1070?? 0.567 0.595
TOL???????????????????????? -1.2588???? 1.1070? -1.137 0.307
MET???????????????????????? -0.1019???? 1.1070? -0.092 0.930
I(H2O * TOL * (H2O - TOL))? 11.8720??? 13.8902?? 0.855 0.432
I(H2O * MET * (H2O - MET)) -15.7052??? 13.8902? -1.131 0.309
I(TOL * MET * (TOL - MET))?????? NA???????? NA????? NA NA
H2O:TOL????????????????????? 0.5398???? 5.4316?? 0.099 0.925
H2O:MET???????????????????? -4.0846???? 5.4316? -0.752 0.486
TOL:MET????????????????????? 6.6810???? 5.4316?? 1.230 0.273
H2O:TOL:MET????????????????? 2.0005??? 31.3024?? 0.064 0.952






---
Este email foi escaneado pelo Avast antiv?rus.
https://www.avast.com/antivirus

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Fri Mar 16 01:55:50 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 15 Mar 2018 17:55:50 -0700
Subject: [R] R code for Batch forecasting
In-Reply-To: <BM1PR0101MB1921C4985DBEAB0E3D214B29B9D00@BM1PR0101MB1921.INDPRD01.PROD.OUTLOOK.COM>
References: <BM1PR0101MB1921C4985DBEAB0E3D214B29B9D00@BM1PR0101MB1921.INDPRD01.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbRukKMfyHY1RnJ1oeQddpvLrzZJ=tyjbWkqiQ9D_XqeCA@mail.gmail.com>

Use a for loop or something else, e.g. lapply() with predict().

To get a better answer, read and follow the posting guide linked below.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Mar 15, 2018 at 3:18 PM, Manish Mukherjee <
manishmukherjee at hotmail.com> wrote:

> Hi All,
>
>
> Is there was where we can predict the time series for multiple items in
> one go - i mean can we run the code for any time series model over multiple
> columns using for loop or something else . If someone can provide some
> example it will be helpfull.
>
>
> Thanks & Regards
> Manish Mukherjee
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From adrian.friskin at qut.edu.au  Fri Mar 16 06:24:24 2018
From: adrian.friskin at qut.edu.au (Adrian Friskin)
Date: Fri, 16 Mar 2018 05:24:24 +0000
Subject: [R] R project global options file
Message-ID: <ME1PR01MB1809EAC0A5487BE3FCABBE41B7D70@ME1PR01MB1809.ausprd01.prod.outlook.com>

Hello R-help,
                         I currently have R-project 3.4.2 and R-studio 1.1.383 installed on some of our universities computer labs. Since the installation of Visual studio the default version of R installed has changed to the version installed by VS. Users can change the default R version: found in R studio global options but users need to do this every session. Is there a file or setting found on the pc where this information is kept? If so, where is it found.

Cheers,

Adrian

Adrian Friskin | Senior Technology Support Officer | Learning Environments - Labs Team | Learning Environments
and Technology Services | Queensland University of Technology | Synergy Building Level 3 - LETS, 88 Musk Avenue, Kelvin Grove 4059 |
ph +61 (07) 3138 3941 | adrian.friskin at qut.edu.au<mailto:adrian.friskin at qut.edu.au> | CRICOS No 00213J


	[[alternative HTML version deleted]]


From lies.henderickx at gmail.com  Fri Mar 16 11:20:16 2018
From: lies.henderickx at gmail.com (Lies Henderickx)
Date: Fri, 16 Mar 2018 10:20:16 +0000
Subject: [R] How to save the values of the factors of a CFA analysis in my
 dataset?
Message-ID: <CAKLBCQ+PCAZNSYOqxQz01U5jMLwi2n9=1t7rftDwFAySKWj4+A@mail.gmail.com>

I performed a CFA using the lavaan package

require('lavaan');

HS.model <- 'external_regulation_soc =~ JOBMOTIVATIE_extsoc1 +
                  JOBMOTIVATIE_extsoc2 + JOBMOTIVATIE_extsoc3
             external_regulation_mat =~ JOBMOTIVATIE_extmat1 +
                  JOBMOTIVATIE_extmat2 + JOBMOTIVATIE_extmat3
             introjected_regulation =~ JOBMOTIVATIE_introj1 +
                  JOBMOTIVATIE_introj2 + JOBMOTIVATIE_introj3 +
                  JOBMOTIVATIE_introj4
             identified_regulation =~ JOBMOTIVATIE_ident1 +
                  JOBMOTIVATIE_ident2 + JOBMOTIVATIE_ident3
             intrinsic_motivation =~ JOBMOTIVATIE_intrin1 +
                  JOBMOTIVATIE_intrin2 + JOBMOTIVATIE_intrin3'

fit <- cfa(HS.model, data = dataset, scores="regression")

summary(fit, fit.measures=TRUE, standardized=TRUE)

I managed to get the values for the five factors in a seperate dataset using

data_factor <- predict(fit)

But I need these 5 factors (as columns, as variables), added to my original
dataset. How can I achieve this?

I tried cbind, but got an error:

factorERS <- select(dataset, JOBMOTIVATIE_extsoc1 +
                   JOBMOTIVATIE_extsoc2 + JOBMOTIVATIE_extsoc3)

data_CFA <- cbind(dataset, fit$scores)
Error in fit$scores : $ operator not defined for this S4 class

Thanks for helping me out!

	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Fri Mar 16 13:49:01 2018
From: starskykwesi at gmail.com (Kwesi Quagraine)
Date: Fri, 16 Mar 2018 14:49:01 +0200
Subject: [R] Help on multi-line plot
Message-ID: <CAGD2cKeBj6uTpDqYMuzJJg9grL51w0h=HRQhkjteuytcT0VmDQ@mail.gmail.com>

Hello R-Users

I am struggling with this line plot, it might be simple but I am missing
something here.

First of all I want to make multiple line plots across seasons
(DJF,MAM,JJA,SON) for 12 variables (here, called nodes) and fill them with
the node.

So that season=x-axis, node=line col and freq=y-axis.

My plot currently links all DJFs, MAMs, JJAs and SONs, however I will like
them to be linked across seasons, so that for node 1, I should have a line
plot of DJF, MAM,JJA and SON with a particular color as a fill etc.

Any help will be much appreciated. Thanks in advance.

Below is my current code;


library(ggplot2)

?kay?
 <- data.frame(
  season =
factor(c("DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON",

 "DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON"),
levels=c("DJF","MAM","JJA","SON")),
  node = factor(c("1","2","3","4","5","6","7","8","9","10","11","12")),
   freq = c(1.075, 5.371, 16.944, 8.953,2.607, 7.257, 14.482, 8.856,5.637,
6.010, 9.239, 11.409,16.096, 6.074, 1.822, 7.498,
           1.597, 5.531, 14.290, 9.114,6.647, 6.394, 9.143, 9.761,10.003,
7.289, 3.964, 9.890,18.768, 7.960, 0.863, 4.590,
           3.943, 11.125, 15.633, 11.345,7.625, 12.500, 8.184, 9.890,12.414,
14.035, 4.508, 6.173,13.587, 10.454, 0.927, 2.521)
)

?kay?

# Map sex to different point shape, and use larger points
ggplot(data=
?kay?
, aes(x=season, y=freq, group=node, colour=node)) +
  geom_line() +
  geom_point()

-- 
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast | College of Agriculture and Natural Sciences |
Department of Physics |
Team Leader | Recycle Up! Ghana|Technology Without Borders |
Other emails: kwesi.quagraine at ucc.edu.gh | kwesi.quagraine at teog.de |
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

	[[alternative HTML version deleted]]


From starskykwesi at gmail.com  Fri Mar 16 18:55:01 2018
From: starskykwesi at gmail.com (Kwesi A. Quagraine)
Date: Fri, 16 Mar 2018 19:55:01 +0200
Subject: [R] Help on multi-line plot
In-Reply-To: <CAGD2cKeBj6uTpDqYMuzJJg9grL51w0h=HRQhkjteuytcT0VmDQ@mail.gmail.com>
References: <CAGD2cKeBj6uTpDqYMuzJJg9grL51w0h=HRQhkjteuytcT0VmDQ@mail.gmail.com>
Message-ID: <etPan.5aac04f5.85021b3.128@Kwesis-MacBook-Pro-2.local>

Thanks! I have been able to solve this!

Kwesi

On 16 March 2018 at 14:49:01, Kwesi Quagraine (starskykwesi at gmail.com) wrote:

Hello R-Users

I am struggling with this line plot, it might be simple but I am missing something here.

First of all I want to make multiple line plots across seasons (DJF,MAM,JJA,SON) for 12 variables (here, called nodes) and fill them with the node.

So that season=x-axis, node=line col and freq=y-axis.

My plot currently links all DJFs, MAMs, JJAs and SONs, however I will like them to be linked across seasons, so that for node 1, I should have a line plot of DJF, MAM,JJA and SON with a particular color as a fill etc.

Any help will be much appreciated. Thanks in advance.

Below is my current code;


library(ggplot2)

?kay? ?<- data.frame(
? season = factor(c("DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON",? ? ? ? ? ? ?"DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON","DJF","MAM","JJA","SON"), levels=c("DJF","MAM","JJA","SON")),
? node = factor(c("1","2","3","4","5","6","7","8","9","10","11","12")),
? ?freq = c(1.075, 5.371, 16.944, 8.953,2.607, 7.257, 14.482, 8.856,5.637, 6.010, 9.239, 11.409,16.096, 6.074, 1.822, 7.498,
? ? ? ? ? ?1.597, 5.531, 14.290, 9.114,6.647, 6.394, 9.143, 9.761,10.003, 7.289, 3.964, 9.890,18.768, 7.960, 0.863, 4.590,
? ? ? ? ? ?3.943, 11.125, 15.633, 11.345,7.625, 12.500, 8.184, 9.890,12.414, 14.035, 4.508, 6.173,13.587, 10.454, 0.927, 2.521)
)

?kay?

# Map sex to different point shape, and use larger points
ggplot(data= ?kay? , aes(x=season, y=freq, group=node, colour=node)) +
? geom_line() +
? geom_point()

--
Try not to become a man of success but rather a man of value-Albert Einstein

University of Cape Coast | College of Agriculture and Natural Sciences | Department of Physics |
Team Leader | Recycle Up! Ghana|Technology Without Borders |
Other emails:?kwesi.quagraine at ucc.edu.gh?|?kwesi.quagraine at teog.de?|
Mobile: +233266173582
Skype: quagraine_cwasi
Twitter: @Pkdilly

------------?
Try not to become a man of success but rather a man of value- Albert Einstein

Kwesi A. Quagraine
Department of Physics
School of?Physical Sciences
College of?Agriculture and Natural Sciences
University of Cape?Coast
Cape Coast, Ghana

Alt. Email:?kwesi at csag.uct.ac.za?
Web:?http://www.recycleupghana.org/?
Office: +27 21 650 3164
Skype: quagraine_cwasi
	[[alternative HTML version deleted]]


From faiz7r at gmail.com  Sat Mar 17 09:42:11 2018
From: faiz7r at gmail.com (faiz rasool)
Date: Sat, 17 Mar 2018 13:42:11 +0500
Subject: [R] How to Find the value of r-square change in hierarchical
 multiple linear regression
Message-ID: <CAFhDWBXvc1zURooSfxF_SJx1CNd2k9nw_AvFzWGpHfc1+=Dmqw@mail.gmail.com>

Dear list members,

I'd like to find the value of r-square change at each step of a
regression model.

I know that I can use anova () to compare to models, but, if I want to
find out that how much exactly r-square has  change from one model to
the next, how can I find that?

Regards, and thanks for any help.

Faiz


From shivipmp82 at gmail.com  Sat Mar 17 16:08:55 2018
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sat, 17 Mar 2018 20:38:55 +0530
Subject: [R] length of 'dimnames' [2] not equal to array extent- For
 Correlation Plot
Message-ID: <CAB=p7SrcmdPaaMo4bcd2Nd=4NZV8-VKYHaEuCbRYxVoza+JBRg@mail.gmail.com>

Created a new data set with 3 numeric variable to find correlation

CR1<- mar%>%  as_data_frame%>%  select(AGE, OLD_CAR_PURCHASE_YRS,
Total.Spend.With.AA)

had to convert it to a data frame, code:

as.matrix(as.data.frame(CR1))

Now i need to run a correlation plot for these 3 variables:

corrplot(CR1, method = "circle")

But i am getting this error:
Error in matrix(unlist(value, recursive = FALSE, use.names = FALSE), nrow =
nr, : length of 'dimnames' [2] not equal to array extent
Researched and found Correlation
<https://stackoverflow.com/questions/43362420/length-of-dimnames-2-not-equal-to-array-extent-when-using-corrplot-function>that
corrplot requires a matrix however the error is still the same.
Regards, Shivi

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat Mar 17 16:15:46 2018
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 17 Mar 2018 11:15:46 -0400
Subject: [R] length of 'dimnames' [2] not equal to array extent- For
 Correlation Plot
In-Reply-To: <CAB=p7SrcmdPaaMo4bcd2Nd=4NZV8-VKYHaEuCbRYxVoza+JBRg@mail.gmail.com>
References: <CAB=p7SrcmdPaaMo4bcd2Nd=4NZV8-VKYHaEuCbRYxVoza+JBRg@mail.gmail.com>
Message-ID: <CAM_vju=21LsEWfMfje=NWYXUZeKa9ChiazFaOOkUrGjJgQvgYw@mail.gmail.com>

I'm assuming you are using the corrplot package.

If so, your data object does need to be a matrix, not a data frame.
Since it's already a data frame, your line of code:

as.matrix(as.data.frame(CR1))

doesn't need the as.data.frame function, but more importantly, you
didn't assign the result to anything: as.matrix() does not work in
place.

CR1 <- as.matrix(CR1)

Now try.

If that doesn't work, then provide a reproducible example so we can
offer further advice.

Sarah

On Sat, Mar 17, 2018 at 11:08 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:
> Created a new data set with 3 numeric variable to find correlation
>
> CR1<- mar%>%  as_data_frame%>%  select(AGE, OLD_CAR_PURCHASE_YRS,
> Total.Spend.With.AA)
>
> had to convert it to a data frame, code:
>
> as.matrix(as.data.frame(CR1))
>
> Now i need to run a correlation plot for these 3 variables:
>
> corrplot(CR1, method = "circle")
>
> But i am getting this error:
> Error in matrix(unlist(value, recursive = FALSE, use.names = FALSE), nrow =
> nr, : length of 'dimnames' [2] not equal to array extent
> Researched and found Correlation
> <https://stackoverflow.com/questions/43362420/length-of-dimnames-2-not-equal-to-array-extent-when-using-corrplot-function>that
> corrplot requires a matrix however the error is still the same.
> Regards, Shivi
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From shivipmp82 at gmail.com  Sat Mar 17 17:00:31 2018
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sat, 17 Mar 2018 21:30:31 +0530
Subject: [R] length of 'dimnames' [2] not equal to array extent- For
 Correlation Plot
In-Reply-To: <CAM_vju=21LsEWfMfje=NWYXUZeKa9ChiazFaOOkUrGjJgQvgYw@mail.gmail.com>
References: <CAB=p7SrcmdPaaMo4bcd2Nd=4NZV8-VKYHaEuCbRYxVoza+JBRg@mail.gmail.com>
 <CAM_vju=21LsEWfMfje=NWYXUZeKa9ChiazFaOOkUrGjJgQvgYw@mail.gmail.com>
Message-ID: <CAB=p7SoLfVk4h3rdtV+j1zwft9mgQfx=QAqdh57_inBCapMGRg@mail.gmail.com>

Hi Sarah,
Thank you for your help.

I tried using CR1<-as.matrix(CR1) but gives error Error in corrplot(CR1,
method = "circle") : The matrix is not in [-1, 1]!. I am using a corrplot
library.

Please find the reproducible example:
dput(head(CR1,10))
structure(c(26L, 46L, 39L, 38L, 47L, 59L, 56L, 61L, 43L, 60L,
78L, 63L, 2L, 58L, 8L, 1L, 1L, 9L, 11L, 2L, 1037500L, 46747L,
346300L, 672000L, 729000L, 470800L, 423000L, 72184L, 368022L,
1037500L), .Dim = c(10L, 3L), .Dimnames = list(NULL, c("AGE",
"OLD_CAR_PURCHASE_YRS", "Total.Spend.With.Maruti")))

Please advice if this would help.

Thank you. Shivi

On Sat, Mar 17, 2018 at 8:45 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> I'm assuming you are using the corrplot package.
>
> If so, your data object does need to be a matrix, not a data frame.
> Since it's already a data frame, your line of code:
>
> as.matrix(as.data.frame(CR1))
>
> doesn't need the as.data.frame function, but more importantly, you
> didn't assign the result to anything: as.matrix() does not work in
> place.
>
> CR1 <- as.matrix(CR1)
>
> Now try.
>
> If that doesn't work, then provide a reproducible example so we can
> offer further advice.
>
> Sarah
>
> On Sat, Mar 17, 2018 at 11:08 AM, Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
> > Created a new data set with 3 numeric variable to find correlation
> >
> > CR1<- mar%>%  as_data_frame%>%  select(AGE, OLD_CAR_PURCHASE_YRS,
> > Total.Spend.With.AA)
> >
> > had to convert it to a data frame, code:
> >
> > as.matrix(as.data.frame(CR1))
> >
> > Now i need to run a correlation plot for these 3 variables:
> >
> > corrplot(CR1, method = "circle")
> >
> > But i am getting this error:
> > Error in matrix(unlist(value, recursive = FALSE, use.names = FALSE),
> nrow =
> > nr, : length of 'dimnames' [2] not equal to array extent
> > Researched and found Correlation
> > <https://stackoverflow.com/questions/43362420/length-of-
> dimnames-2-not-equal-to-array-extent-when-using-corrplot-function>that
> > corrplot requires a matrix however the error is still the same.
> > Regards, Shivi
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Mar 17 17:09:13 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 17 Mar 2018 09:09:13 -0700
Subject: [R] length of 'dimnames' [2] not equal to array extent- For
 Correlation Plot
In-Reply-To: <CAB=p7SoLfVk4h3rdtV+j1zwft9mgQfx=QAqdh57_inBCapMGRg@mail.gmail.com>
References: <CAB=p7SrcmdPaaMo4bcd2Nd=4NZV8-VKYHaEuCbRYxVoza+JBRg@mail.gmail.com>
 <CAM_vju=21LsEWfMfje=NWYXUZeKa9ChiazFaOOkUrGjJgQvgYw@mail.gmail.com>
 <CAB=p7SoLfVk4h3rdtV+j1zwft9mgQfx=QAqdh57_inBCapMGRg@mail.gmail.com>
Message-ID: <CAGxFJbQ9FsEtxb=uQxFs-7xcpoWxsTTfw7Ru6LmkJAOUoD5C7w@mail.gmail.com>

Hmmm....

The error message seems self-explanatory. Please re-read ?corrplot.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Mar 17, 2018 at 9:00 AM, Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Hi Sarah,
> Thank you for your help.
>
> I tried using CR1<-as.matrix(CR1) but gives error Error in corrplot(CR1,
> method = "circle") : The matrix is not in [-1, 1]!. I am using a corrplot
> library.
>
> Please find the reproducible example:
> dput(head(CR1,10))
> structure(c(26L, 46L, 39L, 38L, 47L, 59L, 56L, 61L, 43L, 60L,
> 78L, 63L, 2L, 58L, 8L, 1L, 1L, 9L, 11L, 2L, 1037500L, 46747L,
> 346300L, 672000L, 729000L, 470800L, 423000L, 72184L, 368022L,
> 1037500L), .Dim = c(10L, 3L), .Dimnames = list(NULL, c("AGE",
> "OLD_CAR_PURCHASE_YRS", "Total.Spend.With.Maruti")))
>
> Please advice if this would help.
>
> Thank you. Shivi
>
> On Sat, Mar 17, 2018 at 8:45 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
> > I'm assuming you are using the corrplot package.
> >
> > If so, your data object does need to be a matrix, not a data frame.
> > Since it's already a data frame, your line of code:
> >
> > as.matrix(as.data.frame(CR1))
> >
> > doesn't need the as.data.frame function, but more importantly, you
> > didn't assign the result to anything: as.matrix() does not work in
> > place.
> >
> > CR1 <- as.matrix(CR1)
> >
> > Now try.
> >
> > If that doesn't work, then provide a reproducible example so we can
> > offer further advice.
> >
> > Sarah
> >
> > On Sat, Mar 17, 2018 at 11:08 AM, Shivi Bhatia <shivipmp82 at gmail.com>
> > wrote:
> > > Created a new data set with 3 numeric variable to find correlation
> > >
> > > CR1<- mar%>%  as_data_frame%>%  select(AGE, OLD_CAR_PURCHASE_YRS,
> > > Total.Spend.With.AA)
> > >
> > > had to convert it to a data frame, code:
> > >
> > > as.matrix(as.data.frame(CR1))
> > >
> > > Now i need to run a correlation plot for these 3 variables:
> > >
> > > corrplot(CR1, method = "circle")
> > >
> > > But i am getting this error:
> > > Error in matrix(unlist(value, recursive = FALSE, use.names = FALSE),
> > nrow =
> > > nr, : length of 'dimnames' [2] not equal to array extent
> > > Researched and found Correlation
> > > <https://stackoverflow.com/questions/43362420/length-of-
> > dimnames-2-not-equal-to-array-extent-when-using-corrplot-function>that
> > > corrplot requires a matrix however the error is still the same.
> > > Regards, Shivi
> > >
> > >         [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From sarah.goslee at gmail.com  Sat Mar 17 17:58:24 2018
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Sat, 17 Mar 2018 16:58:24 +0000
Subject: [R] length of 'dimnames' [2] not equal to array extent- For
 Correlation Plot
In-Reply-To: <CAB=p7SoLfVk4h3rdtV+j1zwft9mgQfx=QAqdh57_inBCapMGRg@mail.gmail.com>
References: <CAB=p7SrcmdPaaMo4bcd2Nd=4NZV8-VKYHaEuCbRYxVoza+JBRg@mail.gmail.com>
 <CAM_vju=21LsEWfMfje=NWYXUZeKa9ChiazFaOOkUrGjJgQvgYw@mail.gmail.com>
 <CAB=p7SoLfVk4h3rdtV+j1zwft9mgQfx=QAqdh57_inBCapMGRg@mail.gmail.com>
Message-ID: <CAM_vjunN3oeGnYjxQ3RpAR-oVyDhFGUYT9NN9jkY0+__7SJRQg@mail.gmail.com>

That does clarify for me that you're missing a step: I didn't clearly
follow your description at first.

corrplot expects a correlation matrix, not your original data. You need to
use cor() first.

That's pretty clear in the documentation. See for instance the examples:

data(mtcars)
M <- cor(mtcars)
corrplot(M)

Sarah

On Sat, Mar 17, 2018 at 12:00 PM Shivi Bhatia <shivipmp82 at gmail.com> wrote:

> Hi Sarah,
> Thank you for your help.
>
> I tried using CR1<-as.matrix(CR1) but gives error Error in corrplot(CR1,
> method = "circle") : The matrix is not in [-1, 1]!. I am using a corrplot
> library.
>
> Please find the reproducible example:
> dput(head(CR1,10))
> structure(c(26L, 46L, 39L, 38L, 47L, 59L, 56L, 61L, 43L, 60L,
> 78L, 63L, 2L, 58L, 8L, 1L, 1L, 9L, 11L, 2L, 1037500L, 46747L,
> 346300L, 672000L, 729000L, 470800L, 423000L, 72184L, 368022L,
> 1037500L), .Dim = c(10L, 3L), .Dimnames = list(NULL, c("AGE",
> "OLD_CAR_PURCHASE_YRS", "Total.Spend.With.Maruti")))
>
> Please advice if this would help.
>
> Thank you. Shivi
>
> On Sat, Mar 17, 2018 at 8:45 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
>> I'm assuming you are using the corrplot package.
>>
>> If so, your data object does need to be a matrix, not a data frame.
>> Since it's already a data frame, your line of code:
>>
>> as.matrix(as.data.frame(CR1))
>>
>> doesn't need the as.data.frame function, but more importantly, you
>> didn't assign the result to anything: as.matrix() does not work in
>> place.
>>
>> CR1 <- as.matrix(CR1)
>>
>> Now try.
>>
>> If that doesn't work, then provide a reproducible example so we can
>> offer further advice.
>>
>> Sarah
>>
>> On Sat, Mar 17, 2018 at 11:08 AM, Shivi Bhatia <shivipmp82 at gmail.com>
>> wrote:
>> > Created a new data set with 3 numeric variable to find correlation
>> >
>> > CR1<- mar%>%  as_data_frame%>%  select(AGE, OLD_CAR_PURCHASE_YRS,
>> > Total.Spend.With.AA)
>> >
>> > had to convert it to a data frame, code:
>> >
>> > as.matrix(as.data.frame(CR1))
>> >
>> > Now i need to run a correlation plot for these 3 variables:
>> >
>> > corrplot(CR1, method = "circle")
>> >
>> > But i am getting this error:
>> > Error in matrix(unlist(value, recursive = FALSE, use.names = FALSE),
>> nrow =
>> > nr, : length of 'dimnames' [2] not equal to array extent
>> > Researched and found Correlation
>> > <
>> https://stackoverflow.com/questions/43362420/length-of-dimnames-2-not-equal-to-array-extent-when-using-corrplot-function
>> >that
>> > corrplot requires a matrix however the error is still the same.
>> > Regards, Shivi
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
> --
Sarah Goslee
http://www.stringpage.com
http://www.sarahgoslee.com
http://www.functionaldiversity.org

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Sat Mar 17 19:09:48 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 17 Mar 2018 11:09:48 -0700
Subject: [R] R project global options file
In-Reply-To: <ME1PR01MB1809EAC0A5487BE3FCABBE41B7D70@ME1PR01MB1809.ausprd01.prod.outlook.com>
References: <ME1PR01MB1809EAC0A5487BE3FCABBE41B7D70@ME1PR01MB1809.ausprd01.prod.outlook.com>
Message-ID: <C9DB3CD6-AACA-406C-B119-172FF4A10BE9@comcast.net>


> On Mar 15, 2018, at 10:24 PM, Adrian Friskin <adrian.friskin at qut.edu.au> wrote:
> 
> Hello R-help,
>                         I currently have R-project 3.4.2 and R-studio 1.1.383 installed on some of our universities computer labs. Since the installation of Visual studio the default version of R installed has changed to the version installed by VS. Users can change the default R version: found in R studio global options but users need to do this every session. Is there a file or setting found on the pc where this information is kept? If so, where is it found.

This appears to be a question for the vendor of VS (guessing this would be Microsoft).
> 
> Cheers,
> 
> Adrian
> 
> Adrian Friskin | Senior Technology Support Officer | Learning Environments - Labs Team | Learning Environments
> and Technology Services | Queensland University of Technology | Synergy Building Level 3 - LETS, 88 Musk Avenue, Kelvin Grove 4059 |
> ph +61 (07) 3138 3941 | adrian.friskin at qut.edu.au<mailto:adrian.friskin at qut.edu.au> | CRICOS No 00213J
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From shivipmp82 at gmail.com  Sat Mar 17 19:33:19 2018
From: shivipmp82 at gmail.com (Shivi Bhatia)
Date: Sun, 18 Mar 2018 00:03:19 +0530
Subject: [R] length of 'dimnames' [2] not equal to array extent- For
 Correlation Plot
In-Reply-To: <CAM_vjunN3oeGnYjxQ3RpAR-oVyDhFGUYT9NN9jkY0+__7SJRQg@mail.gmail.com>
References: <CAB=p7SrcmdPaaMo4bcd2Nd=4NZV8-VKYHaEuCbRYxVoza+JBRg@mail.gmail.com>
 <CAM_vju=21LsEWfMfje=NWYXUZeKa9ChiazFaOOkUrGjJgQvgYw@mail.gmail.com>
 <CAB=p7SoLfVk4h3rdtV+j1zwft9mgQfx=QAqdh57_inBCapMGRg@mail.gmail.com>
 <CAM_vjunN3oeGnYjxQ3RpAR-oVyDhFGUYT9NN9jkY0+__7SJRQg@mail.gmail.com>
Message-ID: <CAB=p7SrvC9_R0F_zPJ5zmZMbCuvE1OqC0L3hjA4b+u8QvKFqaw@mail.gmail.com>

Thank you Sarah, this is really helpful.

Have a nice day.

Regards, Shivi

On Sat, Mar 17, 2018 at 10:28 PM, Sarah Goslee <sarah.goslee at gmail.com>
wrote:

> That does clarify for me that you're missing a step: I didn't clearly
> follow your description at first.
>
> corrplot expects a correlation matrix, not your original data. You need to
> use cor() first.
>
> That's pretty clear in the documentation. See for instance the examples:
>
> data(mtcars)
> M <- cor(mtcars)
> corrplot(M)
>
> Sarah
>
> On Sat, Mar 17, 2018 at 12:00 PM Shivi Bhatia <shivipmp82 at gmail.com>
> wrote:
>
>> Hi Sarah,
>> Thank you for your help.
>>
>> I tried using CR1<-as.matrix(CR1) but gives error Error in corrplot(CR1,
>> method = "circle") : The matrix is not in [-1, 1]!. I am using a corrplot
>> library.
>>
>> Please find the reproducible example:
>> dput(head(CR1,10))
>> structure(c(26L, 46L, 39L, 38L, 47L, 59L, 56L, 61L, 43L, 60L,
>> 78L, 63L, 2L, 58L, 8L, 1L, 1L, 9L, 11L, 2L, 1037500L, 46747L,
>> 346300L, 672000L, 729000L, 470800L, 423000L, 72184L, 368022L,
>> 1037500L), .Dim = c(10L, 3L), .Dimnames = list(NULL, c("AGE",
>> "OLD_CAR_PURCHASE_YRS", "Total.Spend.With.Maruti")))
>>
>> Please advice if this would help.
>>
>> Thank you. Shivi
>>
>> On Sat, Mar 17, 2018 at 8:45 PM, Sarah Goslee <sarah.goslee at gmail.com>
>> wrote:
>>
>>> I'm assuming you are using the corrplot package.
>>>
>>> If so, your data object does need to be a matrix, not a data frame.
>>> Since it's already a data frame, your line of code:
>>>
>>> as.matrix(as.data.frame(CR1))
>>>
>>> doesn't need the as.data.frame function, but more importantly, you
>>> didn't assign the result to anything: as.matrix() does not work in
>>> place.
>>>
>>> CR1 <- as.matrix(CR1)
>>>
>>> Now try.
>>>
>>> If that doesn't work, then provide a reproducible example so we can
>>> offer further advice.
>>>
>>> Sarah
>>>
>>> On Sat, Mar 17, 2018 at 11:08 AM, Shivi Bhatia <shivipmp82 at gmail.com>
>>> wrote:
>>> > Created a new data set with 3 numeric variable to find correlation
>>> >
>>> > CR1<- mar%>%  as_data_frame%>%  select(AGE, OLD_CAR_PURCHASE_YRS,
>>> > Total.Spend.With.AA)
>>> >
>>> > had to convert it to a data frame, code:
>>> >
>>> > as.matrix(as.data.frame(CR1))
>>> >
>>> > Now i need to run a correlation plot for these 3 variables:
>>> >
>>> > corrplot(CR1, method = "circle")
>>> >
>>> > But i am getting this error:
>>> > Error in matrix(unlist(value, recursive = FALSE, use.names = FALSE),
>>> nrow =
>>> > nr, : length of 'dimnames' [2] not equal to array extent
>>> > Researched and found Correlation
>>> > <https://stackoverflow.com/questions/43362420/length-of-
>>> dimnames-2-not-equal-to-array-extent-when-using-corrplot-function>that
>>> > corrplot requires a matrix however the error is still the same.
>>> > Regards, Shivi
>>> >
>>> >         [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> > https://stat.ethz.ch/mailman/listinfo/r-help
>>> > PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> > and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>>
>>> --
>>> Sarah Goslee
>>> http://www.functionaldiversity.org
>>>
>> --
> Sarah Goslee
> http://www.stringpage.com
> http://www.sarahgoslee.com
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sat Mar 17 20:56:34 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 17 Mar 2018 12:56:34 -0700
Subject: [R] R project global options file
In-Reply-To: <C9DB3CD6-AACA-406C-B119-172FF4A10BE9@comcast.net>
References: <ME1PR01MB1809EAC0A5487BE3FCABBE41B7D70@ME1PR01MB1809.ausprd01.prod.outlook.com>
 <C9DB3CD6-AACA-406C-B119-172FF4A10BE9@comcast.net>
Message-ID: <A7FC2D2F-9825-419A-A730-E49568CB1C91@dcn.davis.ca.us>

Alternatively refer to the R Installation and Administration manual, which discusses the various user and site configuration files.

There may be a Windows registry entry also. 
-- 
Sent from my phone. Please excuse my brevity.

On March 17, 2018 11:09:48 AM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>> On Mar 15, 2018, at 10:24 PM, Adrian Friskin
><adrian.friskin at qut.edu.au> wrote:
>> 
>> Hello R-help,
>>                         I currently have R-project 3.4.2 and R-studio
>1.1.383 installed on some of our universities computer labs. Since the
>installation of Visual studio the default version of R installed has
>changed to the version installed by VS. Users can change the default R
>version: found in R studio global options but users need to do this
>every session. Is there a file or setting found on the pc where this
>information is kept? If so, where is it found.
>
>This appears to be a question for the vendor of VS (guessing this would
>be Microsoft).
>> 
>> Cheers,
>> 
>> Adrian
>> 
>> Adrian Friskin | Senior Technology Support Officer | Learning
>Environments - Labs Team | Learning Environments
>> and Technology Services | Queensland University of Technology |
>Synergy Building Level 3 - LETS, 88 Musk Avenue, Kelvin Grove 4059 |
>> ph +61 (07) 3138 3941 |
>adrian.friskin at qut.edu.au<mailto:adrian.friskin at qut.edu.au> | CRICOS No
>00213J
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA
>
>'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Sat Mar 17 21:15:05 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 17 Mar 2018 16:15:05 -0400
Subject: [R] R project global options file
In-Reply-To: <C9DB3CD6-AACA-406C-B119-172FF4A10BE9@comcast.net>
References: <ME1PR01MB1809EAC0A5487BE3FCABBE41B7D70@ME1PR01MB1809.ausprd01.prod.outlook.com>
 <C9DB3CD6-AACA-406C-B119-172FF4A10BE9@comcast.net>
Message-ID: <1d84cc26-d502-e94d-a5e0-a582cef5257f@gmail.com>

On 17/03/2018 2:09 PM, David Winsemius wrote:
> 
>> On Mar 15, 2018, at 10:24 PM, Adrian Friskin <adrian.friskin at qut.edu.au> wrote:
>>
>> Hello R-help,
>>                          I currently have R-project 3.4.2 and R-studio 1.1.383 installed on some of our universities computer labs. Since the installation of Visual studio the default version of R installed has changed to the version installed by VS. Users can change the default R version: found in R studio global options but users need to do this every session. Is there a file or setting found on the pc where this information is kept? If so, where is it found.
> 
> This appears to be a question for the vendor of VS (guessing this would be Microsoft).

Or the vendor of RStudio, which seems to have been messed up by VS.

If you hold down the Ctrl key as you're starting RStudio, you can choose 
which version of R to start.  For me, that choice persists; I don't know 
if it would for Adrian.

Duncan Murdoch


>>
>> Cheers,
>>
>> Adrian
>>
>> Adrian Friskin | Senior Technology Support Officer | Learning Environments - Labs Team | Learning Environments
>> and Technology Services | Queensland University of Technology | Synergy Building Level 3 - LETS, 88 Musk Avenue, Kelvin Grove 4059 |
>> ph +61 (07) 3138 3941 | adrian.friskin at qut.edu.au<mailto:adrian.friskin at qut.edu.au> | CRICOS No 00213J
>>
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From aggarwalneha2000 at gmail.com  Sun Mar 18 10:34:31 2018
From: aggarwalneha2000 at gmail.com (Neha Aggarwal)
Date: Sun, 18 Mar 2018 05:34:31 -0400
Subject: [R] Set Difference Problem
Message-ID: <CAMe08vvpT8TSctBm1UNhQmUE8y2==z7rdFKTSonNWo=MuhFPtw@mail.gmail.com>

 Hello All,

I am facing a problem and am unable to find much help online as sets
package in R is relatively new.
My problem is as follows:

Set R is made of 2 sets x and y
x<-{"P1", "P2", "P3", "P4"}
y<-{}
R<-set(x,y)
#R={{}, {"P1", "P2", "P3", "P4"}}

i need to use R in a recursive loop where i need to take set difference of
R and it 's elements.
Example:
for (r in R){
    print(r)
    R<-set_symdiff(r,R)
    print(R)
}

the program is unable to recognise the null set in the set R. I tried
various funtions and methods:
> R-r
#Output : {{}, {"P1", "P2", "P3", "P4"}}
> set_symdiff(r,R)
Output: {{}, {"P1", "P2", "P3", "P4"}}
> set_symdiff(R,r)
Output: {{}, {"P1", "P2", "P3", "P4"}}

i also tried with set_complement() .But they do not subtract the null set
from the bigger set. It seems they dont recognise it.
What can I try, any pointers/ packages will be great help.
Please help
.
Thanks,
Neha

	[[alternative HTML version deleted]]


From juratbupt at gmail.com  Sun Mar 18 13:29:26 2018
From: juratbupt at gmail.com (Jurat Shayidin)
Date: Sun, 18 Mar 2018 13:29:26 +0100
Subject: [R] rdwd package error: invalid file argument raised by readDWD
Message-ID: <CADrKe=xXN1gos5QBJ20gfBTua-b=j8pDobkTxcveJ+RUXV7AtQ@mail.gmail.com>

Hi:

I tried to download germany' historical weather data with rdwd package.
However, when I tried to read downloaded data (1080 txt file in total) with
readDWD function, but R raised an error down below:

library(rdwd)

ftpURL <- selectDWD(name = "", exactmatch = TRUE,
                    res="monthly",
                    var="kl", per="historical", current = TRUE)
ftpFile <- dataDWD(file = ftpURL, dir = "stella/input/",sleep = 0)


> fooDat <- readDWD(ftpFile,
+                   meta = substr(ftpFile, nchar(ftpFile) - 3, 10000) ==
".txt",
+                   fread = FALSE, minfo = FALSE, format = NA, tz = "GMT",
+                   progbar = TRUE)
*Error in file.exists(file) : invalid 'file' argument*


I want to read all txt file in R for further analysis. But I got an error
above. How to resolve this error? Any instance help? Thank you.

PS: here is my session information:

> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] rdwd_0.9.0

loaded via a namespace (and not attached):
[1] compiler_3.4.3        parallel_3.4.3        tools_3.4.3
[4] berryFunctions_1.16.3 RCurl_1.95-4.8        abind_1.4-5
[7] yaml_2.1.14           pbapply_1.3-4         bitops_1.0-6


-- 
Jurat Shahidin

Dipartimento di Elettronica, Informazione e Bioingegneria
Politecnico di Milano
Piazza Leonardo da Vinci 32 - 20133 Milano, Italy
Mobile : +39 327-859-7796

	[[alternative HTML version deleted]]


From aggarwalneha2000 at gmail.com  Sun Mar 18 16:00:11 2018
From: aggarwalneha2000 at gmail.com (Neha Aggarwal)
Date: Sun, 18 Mar 2018 11:00:11 -0400
Subject: [R] How to take difference of sets when there is an empty subset
 involved
Message-ID: <CAMe08vuyx2dk9R41fkHhpVqQSHsmP0JyYfuK5Z+tnTxesvxYdA@mail.gmail.com>

Hello,

Problem I am facing is as follows:

Set A is made of 2 sets x and y
x<-{"P1", "P2", "P3", "P4"}
y<-{}
A<-set(x,y)
#A={{}, {"P1", "P2", "P3", "P4"}}

i need to use A in a recursive loop where i need to take set difference of
A and it 's elements.
Example:
for (i in A){
    print(i)
    A<-set_symdiff(i,A)    ###Imp line i need help on
    print(A)
}

the program is unable to recognise the empty set in the set A. I tried
various  methods in Imp line above:
> A-i
#Output : {{}, {"P1", "P2", "P3", "P4"}}
> set_symdiff(i,A)
Output: {{}, {"P1", "P2", "P3", "P4"}}
> set_symdiff(A,i)
Output: {{}, {"P1", "P2", "P3", "P4"}}

i also tried with set_complement() .But it does not subtract the empty
subset from the bigger set. It seems it doesn't recognise it.
What else can I try ? any pointers/ packages will be great help.

.
Thanks in advance,
Neha

	[[alternative HTML version deleted]]


From amalraj.raja at abdn.ac.uk  Sun Mar 18 16:26:00 2018
From: amalraj.raja at abdn.ac.uk (Raja, Dr. Edwin Amalraj)
Date: Sun, 18 Mar 2018 15:26:00 +0000
Subject: [R] selectFGR - variable selection in fine gray model for competing
 risks
Message-ID: <VI1PR0402MB382232D9A0EDB5F6ECF4E32EA1D50@VI1PR0402MB3822.eurprd04.prod.outlook.com>

Dear All,

   I would like to use R function 'selectFGR' of fine gray model in competing risks model.  I used the 'Melanoma' data in 'riskRegression' package.  Some of the variables are factor.  I get solution for full model but not in variable selection model.  Any advice how to use factor variable in 'selectFGR' function.  The following R code is produced below for reproducibility.

library(riskRegression)
library(pec)
dat <-data(Melanoma,package="riskRegression")
Melanoma$logthick <- log(Melanoma$thick)
f1 <- Hist(time,status)~age+sex+epicel+ulcer
df1 <-FGR(f1,cause=1, data=Melanoma)
df1
df <-selectFGR(f1, data=Melanoma, rule ="BIC",  direction="backward")

Thanks in advice for your suggestion. Is there any alternative solution ?

Regards
Amalraj raja


The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

From murdoch.duncan at gmail.com  Sun Mar 18 17:05:08 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 18 Mar 2018 12:05:08 -0400
Subject: [R] 
 How to take difference of sets when there is an empty subset
 involved
In-Reply-To: <CAMe08vuyx2dk9R41fkHhpVqQSHsmP0JyYfuK5Z+tnTxesvxYdA@mail.gmail.com>
References: <CAMe08vuyx2dk9R41fkHhpVqQSHsmP0JyYfuK5Z+tnTxesvxYdA@mail.gmail.com>
Message-ID: <a5bf401c-745f-3159-e0c6-8f8d2a0a994a@gmail.com>

On 18/03/2018 11:00 AM, Neha Aggarwal wrote:
> Hello,
> 
> Problem I am facing is as follows:
> 
> Set A is made of 2 sets x and y
> x<-{"P1", "P2", "P3", "P4"}
> y<-{}

Those aren't R code. I think you meant

x <- set("P1", "P2", "P3", "P4")
y <- set()

> A<-set(x,y)
> #A={{}, {"P1", "P2", "P3", "P4"}}
> 
> i need to use A in a recursive loop where i need to take set difference of
> A and it 's elements.

This doesn't really make sense.  A is a set of sets.  Its elements are 
sets of character strings.  There is no intersection between A and 
either of its elements, so the symmetric difference is just the union. 
What do you really want?

> Example:
> for (i in A){
>      print(i)
>      A<-set_symdiff(i,A)    ###Imp line i need help on
>      print(A)
> }

That changes A each time through the loop.  Did you really want that?

> 
> the program is unable to recognise the empty set in the set A. I tried
> various  methods in Imp line above:
>> A-i
> #Output : {{}, {"P1", "P2", "P3", "P4"}}
>> set_symdiff(i,A)
> Output: {{}, {"P1", "P2", "P3", "P4"}}
>> set_symdiff(A,i)
> Output: {{}, {"P1", "P2", "P3", "P4"}}
> 
> i also tried with set_complement() .But it does not subtract the empty
> subset from the bigger set. It seems it doesn't recognise it.
> What else can I try ? any pointers/ packages will be great help.
> 

I'm not sure what you are after, but you might want something like

set_symdiff(set(i), A)

or

A - set(i)

Duncan Murdoch


From tag at biostat.ku.dk  Mon Mar 19 08:33:30 2018
From: tag at biostat.ku.dk (Thomas Alexander Gerds)
Date: Mon, 19 Mar 2018 08:33:30 +0100
Subject: [R] 
 selectFGR - variable selection in fine gray model for competing
 risks
In-Reply-To: <VI1PR0402MB382232D9A0EDB5F6ECF4E32EA1D50@VI1PR0402MB3822.eurprd04.prod.outlook.com>
 (Dr. Edwin Amalraj Raja's message of "Sun, 18 Mar 2018 15:26:00
 +0000")
References: <VI1PR0402MB382232D9A0EDB5F6ECF4E32EA1D50@VI1PR0402MB3822.eurprd04.prod.outlook.com>
Message-ID: <87woy8msdx.fsf@biostat.ku.dk>

Dear Raja

the technical problem is that the function crrstep does not communicate
the selected variables in a proper way. the function pec::selectFGR uses
rownames(crrstep.fit$coefficients). the other problem is that I don't
like and never use backward elemination -- so, I am not motivated to fix
this. However, I copy this email to Rob van Kruijsdijk who wrote the
function ... maybe he wants to fix. you can always fix this yourself by
copying the functions selectFGR, predictEventProb.selectFGR.

Best Thomas


"Raja, Dr. Edwin Amalraj" <amalraj.raja at abdn.ac.uk> writes:

> Dear All,
>
>    I would like to use R function 'selectFGR' of fine gray model in
> competing risks model.  I used the 'Melanoma' data in 'riskRegression'
> package.  Some of the variables are factor.  I get solution for full
> model but not in variable selection model.  Any advice how to use
> factor variable in 'selectFGR' function.  The following R code is
> produced below for reproducibility.
>
> library(riskRegression)
> library(pec)
> dat <-data(Melanoma,package="riskRegression")
> Melanoma$logthick <- log(Melanoma$thick)
> f1 <- Hist(time,status)~age+sex+epicel+ulcer
> df1 <-FGR(f1,cause=1, data=Melanoma)
> df1
> df <-selectFGR(f1, data=Melanoma, rule ="BIC",  direction="backward")
>
> Thanks in advice for your suggestion. Is there any alternative solution ?
>
> Regards
> Amalraj raja
>
>
> The University of Aberdeen is a charity registered in Scotland, No SC013683.
> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

-- 
7LL-4 No one is the reason for your happiness except you yourself.


From akshay_e4 at hotmail.com  Mon Mar 19 11:36:47 2018
From: akshay_e4 at hotmail.com (akshay kulkarni)
Date: Mon, 19 Mar 2018 10:36:47 +0000
Subject: [R] help needed on RcppEigen....
Message-ID: <SL2P216MB00913E36A464F38B1B832C4AC8D40@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,

               I am using R to model stock prices but a slow "for" loop has stifled my research.


I am using Rcpp to speed up my "for" loop. I am also using RcppEigen to implement block operations on xts objects.....


how do I use RcppEigen? If I just load it by:

> require(RcppEigen)

it is not recognising the .block method in C++.



If I include it inside the cppFunction:

> cppFunction(' include  <RcppEigen.h>  .....body')

I get the following error:

> error: "include doesn't name a type"


My question is : how do I manipulate the installed RcppEigen package for the cppFunction to recognize block operations that are part of the Eigen library in C++? If I have to use the "include" key word (something like this: include <RcppEigen.h> ), where exactly should i position it in order to work with cppFunction ( I want to use Eigen block operation methods or functions inside the body of the cppFunction)?


very many thanks for your time and effort.....


yours sincerely,

AKSHAY M KULKARNI


	[[alternative HTML version deleted]]


From S.Ellison at LGCGroup.com  Mon Mar 19 14:33:52 2018
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Mar 2018 13:33:52 +0000
Subject: [R] Set Difference Problem
In-Reply-To: <CAMe08vvpT8TSctBm1UNhQmUE8y2==z7rdFKTSonNWo=MuhFPtw@mail.gmail.com>
References: <CAMe08vvpT8TSctBm1UNhQmUE8y2==z7rdFKTSonNWo=MuhFPtw@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E267240C42A1DEEA@GBTEDVPEXCMB04.corp.lgc-group.com>

First, it _looks_ like you're not constructing your starting sets properly.
The sets package manual says that the set constructor is set()
There's no apparent overload for {}

Assuming your actual commands are
x<- set("P1", "P2", "P3", "P4")
y<-set()

There's a difference between z<-set(x,y). which correctly forms a set of sets, with two members, x and y,  and u<-set_union(x,y) which correctly returns a set identical to x, using the empty set as you'd expect.

I'm not sure what you wanted, but perhaps you wanted the union rather than the set of sets?

If you _did_ want the set of sets, z above, life is maybe more complicated than you expected. 
z is a set that contains an empty set and a populated set. The difference between that and the empty set is all of the members of z - including the empty set that is one of its members.

If you wanted something that returns a set of one set (that is, {x}, you'd have to compare z with set(y) (the latter being a non-empty set containing one member, the empty set):

> set_symdiff(z, set(y))

which correctly returns 
{{"P1", "P2", "P3", "P4"}}
Note the double parentheses ... this is still a set of sets with one member, not a set of character strings with four members.

Hope that helps ...

S Ellison

> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Neha
> Aggarwal
> Sent: 18 March 2018 09:35
> To: r-help at r-project.org
> Subject: [R] Set Difference Problem
> 
>  Hello All,
> 
> I am facing a problem and am unable to find much help online as sets package
> in R is relatively new.
> My problem is as follows:
> 
> Set R is made of 2 sets x and y
> x<-{"P1", "P2", "P3", "P4"}
> y<-{}
> R<-set(x,y)
> #R={{}, {"P1", "P2", "P3", "P4"}}
> 
> i need to use R in a recursive loop where i need to take set difference of R and
> it 's elements.
> Example:
> for (r in R){
>     print(r)
>     R<-set_symdiff(r,R)
>     print(R)
> }
> 
> the program is unable to recognise the null set in the set R. I tried various
> funtions and methods:
> > R-r
> #Output : {{}, {"P1", "P2", "P3", "P4"}}
> > set_symdiff(r,R)
> Output: {{}, {"P1", "P2", "P3", "P4"}}
> > set_symdiff(R,r)
> Output: {{}, {"P1", "P2", "P3", "P4"}}
> 
> i also tried with set_complement() .But they do not subtract the null set from
> the bigger set. It seems they dont recognise it.
> What can I try, any pointers/ packages will be great help.
> Please help
> .
> Thanks,
> Neha
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Mon Mar 19 14:45:53 2018
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 19 Mar 2018 13:45:53 +0000
Subject: [R] How to Find the value of r-square change in hierarchical
 multiple linear regression
In-Reply-To: <CAFhDWBXvc1zURooSfxF_SJx1CNd2k9nw_AvFzWGpHfc1+=Dmqw@mail.gmail.com>
References: <CAFhDWBXvc1zURooSfxF_SJx1CNd2k9nw_AvFzWGpHfc1+=Dmqw@mail.gmail.com>
Message-ID: <1A8C1289955EF649A09086A153E267240C42A1DEF3@GBTEDVPEXCMB04.corp.lgc-group.com>

> I'd like to find the value of r-square change at each step of a regression model.
> 
> I know that I can use anova () to compare to models, but, if I want to find out
> that how much exactly r-square has  change from one model to the next, how
> can I find that?

See ?summary.lm

For a linear model L
summary(L)$r.squared

gives R^2

and the adjusted R^2 is
summary(L)$adj.r.squared

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jdnewmil at dcn.davis.ca.us  Mon Mar 19 14:58:40 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 19 Mar 2018 06:58:40 -0700
Subject: [R] help needed on RcppEigen....
In-Reply-To: <SL2P216MB00913E36A464F38B1B832C4AC8D40@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00913E36A464F38B1B832C4AC8D40@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <54416A8A-DD84-4773-81F3-202A14D5B728@dcn.davis.ca.us>

For loops are not usually the primary cause of slow processing in R... poor memory handling is. 

But the closest you seem to come to asking a question in your email seems to be about Rcpp, which is off topic on this mailing list. Try reading all of the Rcpp vignettes, and then if needed ask on Rcpp-devel and mention which vignettes seemed most closely related to your question and give a reproducible example rather than snippets. 
-- 
Sent from my phone. Please excuse my brevity.

On March 19, 2018 3:36:47 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>
>I am using R to model stock prices but a slow "for" loop has stifled my
>research.
>
>
>I am using Rcpp to speed up my "for" loop. I am also using RcppEigen to
>implement block operations on xts objects.....
>
>
>how do I use RcppEigen? If I just load it by:
>
>> require(RcppEigen)
>
>it is not recognising the .block method in C++.
>
>
>
>If I include it inside the cppFunction:
>
>> cppFunction(' include  <RcppEigen.h>  .....body')
>
>I get the following error:
>
>> error: "include doesn't name a type"
>
>
>My question is : how do I manipulate the installed RcppEigen package
>for the cppFunction to recognize block operations that are part of the
>Eigen library in C++? If I have to use the "include" key word
>(something like this: include <RcppEigen.h> ), where exactly should i
>position it in order to work with cppFunction ( I want to use Eigen
>block operation methods or functions inside the body of the
>cppFunction)?
>
>
>very many thanks for your time and effort.....
>
>
>yours sincerely,
>
>AKSHAY M KULKARNI
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kenneth at kidscodejeunesse.org  Mon Mar 19 14:18:57 2018
From: kenneth at kidscodejeunesse.org (Kenneth Dyson)
Date: Mon, 19 Mar 2018 09:18:57 -0400
Subject: [R] Labelling a fortified GADM map plotted with ggplot and geom_map
Message-ID: <1ef4f384-518f-4f2c-9335-9035ef97ea5e@Spark>

I am having trouble getting data labels to display over the provinces in a GADM map of Canada.
Specifically, I need the variable "Number" from the data set "by_province", grouped by "region", to appear on the corresponding regions of the map.

The data set "by_province" looks like this:
long      lat          order  hole piece                   region                     group     Number
-110.37074 60.00006       1 FALSE     1                   Alberta                    Alberta.1    132
-110.36250 60.00006       2 FALSE     1                   Alberta                    Alberta.1    132
-110.35103 60.00006       3 FALSE     1                   Alberta                    Alberta.1    132
and the data set "tract" is the map data without the "Number" variable.
I looked into working this out from by researching the geom_map function here: http://ggplot2.tidyverse.org/reference/geom_map.html
my code looks like this:
# get the raw map data
can_map <- getData('GADM', country = "CAN", level = 1) # download map level with provinces
tract <- fortify(can_map, region = "NAME_1") # transforms data from shapefiles into a dataframe that ggplot can understand, from http://www.kevjohnson.org/making-maps-in-r/

# create subsets of the kcj data if needed, for example by year
kids_data_2017 <- subset(kids_data, year == 2017) # data for the year 2017
kids_data_2018 <- subset(kids_data, year == 2018) # data for the year 2018

# extract the needed data
kids_province_data <- data.table::data.table(kids_data_2017$Province_Territory__c, kids_data_2017$Number_of_kids__c)
names(kids_province_data)[1] <- "Province"
names(kids_province_data)[2] <- "Number"

# sum the data by province
kids_province_sums <- aggregate(.~Province, data = kids_province_data, sum)

# join the data to the map
names(tract)[6] <- "region"
names(kids_province_sums)[1] <- "region"
by_province <- left_join(tract, kids_province_sums)

# create the data map
kids_map <- ggplot(by_province, aes(map_id = region)) +              #plots the map in by_province separating by region
           geom_map(aes(fill = Number),                             #generates aestheticsa for the plot
                    map = tract,                                        #takes the data from tract
                    color = "#ffffff",                                  #makes the color of the borders between regions white
                    size = 0.15) +                                      #sets the thickness of the boarder lines
           coord_map("polyconic") +                                 #sets the coordinates to polyconic (rounded lat and long)
           scale_fill_gradient(name = "Children Reached",           #sets the gradient of the value scale: names the scale
                               low = grey_2,                            #color of the low end
                               high = orange_1) +                       #color of the high end
           expand_limits(x = tract$long,                            #ensure limits include all values for all plots
                         y = tract$lat) +
           labs(x = NULL,                                           #add labels, no x title
                y = NULL,                                               #no y title
                title = "Number of Children Reached by Province",       #map title
                subtitle = "2017") +                                    #map subtitle
           geom_text(data = by_province,                            #add a text layer
                     aes(long,                                          #aethetics for the text, x axis
                         lat,                                               #y axis
                         label = Number,                                    #the value to display
                         size=3)) +                                         #size of the text
           theme(axis.ticks = element_blank(),                      #theme of the graph, no axis ticks
                 axis.text = element_blank(),                           #no axis text
                 panel.background = element_blank(),                    #blank background
                 panel.border = element_blank())                        #blank border

# save as png
ggsave(kids_map, file = "kids_map.png", width = 6, height = 4.5, type = "cairo-png?)
I have asked this question on stack overflow, and was refered to this answer:

https://stackoverflow.com/questions/9441436/ggplot-centered-names-on-a-map
The solution there did not fix my problem, though it did get me closer.
The solution on that post is using a single vector of labels.

My post on stackoverflow has images of my output:
https://stackoverflow.com/questions/49118323/labelling-a-map-plotted-with-geom-map

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 19 16:28:44 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Mar 2018 08:28:44 -0700
Subject: [R] 
 Labelling a fortified GADM map plotted with ggplot and geom_map
In-Reply-To: <1ef4f384-518f-4f2c-9335-9035ef97ea5e@Spark>
References: <1ef4f384-518f-4f2c-9335-9035ef97ea5e@Spark>
Message-ID: <CAGxFJbRuiv9yYUYJanPg5oa0=uXoU_jYRD-KhND-n7LwW2c1HQ@mail.gmail.com>

The r-sig-geo list,

https://stat.ethz.ch/mailman/listinfo/r-sig-geo

is often a better place to post such geographically related queries.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 19, 2018 at 6:18 AM, Kenneth Dyson <kenneth at kidscodejeunesse.org
> wrote:

> I am having trouble getting data labels to display over the provinces in a
> GADM map of Canada.
> Specifically, I need the variable "Number" from the data set
> "by_province", grouped by "region", to appear on the corresponding regions
> of the map.
>
> The data set "by_province" looks like this:
> long      lat          order  hole piece                   region
>            group     Number
> -110.37074 60.00006       1 FALSE     1                   Alberta
>           Alberta.1    132
> -110.36250 60.00006       2 FALSE     1                   Alberta
>           Alberta.1    132
> -110.35103 60.00006       3 FALSE     1                   Alberta
>           Alberta.1    132
> and the data set "tract" is the map data without the "Number" variable.
> I looked into working this out from by researching the geom_map function
> here: http://ggplot2.tidyverse.org/reference/geom_map.html
> my code looks like this:
> # get the raw map data
> can_map <- getData('GADM', country = "CAN", level = 1) # download map
> level with provinces
> tract <- fortify(can_map, region = "NAME_1") # transforms data from
> shapefiles into a dataframe that ggplot can understand, from
> http://www.kevjohnson.org/making-maps-in-r/
>
> # create subsets of the kcj data if needed, for example by year
> kids_data_2017 <- subset(kids_data, year == 2017) # data for the year 2017
> kids_data_2018 <- subset(kids_data, year == 2018) # data for the year 2018
>
> # extract the needed data
> kids_province_data <- data.table::data.table(kids_
> data_2017$Province_Territory__c, kids_data_2017$Number_of_kids__c)
> names(kids_province_data)[1] <- "Province"
> names(kids_province_data)[2] <- "Number"
>
> # sum the data by province
> kids_province_sums <- aggregate(.~Province, data = kids_province_data, sum)
>
> # join the data to the map
> names(tract)[6] <- "region"
> names(kids_province_sums)[1] <- "region"
> by_province <- left_join(tract, kids_province_sums)
>
> # create the data map
> kids_map <- ggplot(by_province, aes(map_id = region)) +
> #plots the map in by_province separating by region
>            geom_map(aes(fill = Number),
>  #generates aestheticsa for the plot
>                     map = tract,
> #takes the data from tract
>                     color = "#ffffff",
> #makes the color of the borders between regions white
>                     size = 0.15) +
> #sets the thickness of the boarder lines
>            coord_map("polyconic") +                                 #sets
> the coordinates to polyconic (rounded lat and long)
>            scale_fill_gradient(name = "Children Reached",           #sets
> the gradient of the value scale: names the scale
>                                low = grey_2,
> #color of the low end
>                                high = orange_1) +
>  #color of the high end
>            expand_limits(x = tract$long,
> #ensure limits include all values for all plots
>                          y = tract$lat) +
>            labs(x = NULL,                                           #add
> labels, no x title
>                 y = NULL,
>  #no y title
>                 title = "Number of Children Reached by Province",
>  #map title
>                 subtitle = "2017") +
> #map subtitle
>            geom_text(data = by_province,                            #add a
> text layer
>                      aes(long,
> #aethetics for the text, x axis
>                          lat,
>  #y axis
>                          label = Number,
>   #the value to display
>                          size=3)) +
>  #size of the text
>            theme(axis.ticks = element_blank(),                      #theme
> of the graph, no axis ticks
>                  axis.text = element_blank(),
>  #no axis text
>                  panel.background = element_blank(),
> #blank background
>                  panel.border = element_blank())
> #blank border
>
> # save as png
> ggsave(kids_map, file = "kids_map.png", width = 6, height = 4.5, type =
> "cairo-png?)
> I have asked this question on stack overflow, and was refered to this
> answer:
>
> https://stackoverflow.com/questions/9441436/ggplot-centered-names-on-a-map
> The solution there did not fix my problem, though it did get me closer.
> The solution on that post is using a single vector of labels.
>
> My post on stackoverflow has images of my output:
> https://stackoverflow.com/questions/49118323/labelling-
> a-map-plotted-with-geom-map
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wmulimbi at email.uark.edu  Mon Mar 19 22:24:42 2018
From: wmulimbi at email.uark.edu (Willy Byamungu)
Date: Mon, 19 Mar 2018 16:24:42 -0500
Subject: [R] Struggling to compute marginal effects !
Message-ID: <CAPcX2crvLNgqgmuBVOhXwGxLwyGOPF9CTfHN4=iGwzDgf6+oEQ@mail.gmail.com>

Dear Oscar,
and any other R-project person,

Can you please help me to figure out the meaning of the following error
message in red ?

Error in eval(predvars, data, env) :
  numeric 'envir' arg not of length one

I computed ordered logit models using 'polr' in R (I just followed the
guidance a handout I found on princeton.edu about logit, probit and
multinomial logit models) . The summary results are obtained without any
problem. *However*, when I'm using the package 'erer' to compute the
marginal effects for the ordered logit models, I'm just getting the error
message above.

Please HELP !!!!

Willy


-- 
Willy Mulimbi B.
AEAB Grad Student & Fulbright Scholar
Tel. (+1) 479-316-5981
Fayetteville, AR

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 19 23:18:07 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Mar 2018 15:18:07 -0700
Subject: [R] Struggling to compute marginal effects !
In-Reply-To: <CAPcX2crvLNgqgmuBVOhXwGxLwyGOPF9CTfHN4=iGwzDgf6+oEQ@mail.gmail.com>
References: <CAPcX2crvLNgqgmuBVOhXwGxLwyGOPF9CTfHN4=iGwzDgf6+oEQ@mail.gmail.com>
Message-ID: <CAGxFJbQjhk5tmV4T4L7Jc3wzTQj9sTmfdCE3F6vtFogDWvPW_A@mail.gmail.com>

You are more likely to get a useful answer if you read **and follow** the
posting guide linked below. In particular, show us the code that elicited
the error. A small reproducible example would be even better, though may
not be needed.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 19, 2018 at 2:24 PM, Willy Byamungu <wmulimbi at email.uark.edu>
wrote:

> Dear Oscar,
> and any other R-project person,
>
> Can you please help me to figure out the meaning of the following error
> message in red ?
>
> Error in eval(predvars, data, env) :
>   numeric 'envir' arg not of length one
>
> I computed ordered logit models using 'polr' in R (I just followed the
> guidance a handout I found on princeton.edu about logit, probit and
> multinomial logit models) . The summary results are obtained without any
> problem. *However*, when I'm using the package 'erer' to compute the
> marginal effects for the ordered logit models, I'm just getting the error
> message above.
>
> Please HELP !!!!
>
> Willy
>
>
> --
> Willy Mulimbi B.
> AEAB Grad Student & Fulbright Scholar
> Tel. (+1) 479-316-5981
> Fayetteville, AR
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon at gmail.com  Mon Mar 19 23:33:56 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 20 Mar 2018 09:33:56 +1100
Subject: [R] Struggling to compute marginal effects !
In-Reply-To: <CAPcX2crvLNgqgmuBVOhXwGxLwyGOPF9CTfHN4=iGwzDgf6+oEQ@mail.gmail.com>
References: <CAPcX2crvLNgqgmuBVOhXwGxLwyGOPF9CTfHN4=iGwzDgf6+oEQ@mail.gmail.com>
Message-ID: <CA+8X3fXvPLkYse-CYtpt7_X1tN89zzUTjJf86kqkqYe0peXJ+Q@mail.gmail.com>

Hi Willy,
The error message may be due to passing an inappropriate environment.
I don't have the "erer" package, but if that function has a default
for the environment argument, perhaps passing just the "predvars" and
"data" arguments will work.

Jim

On Tue, Mar 20, 2018 at 8:24 AM, Willy Byamungu <wmulimbi at email.uark.edu> wrote:
> Dear Oscar,
> and any other R-project person,
>
> Can you please help me to figure out the meaning of the following error
> message in red ?
>
> Error in eval(predvars, data, env) :
>   numeric 'envir' arg not of length one
>
> I computed ordered logit models using 'polr' in R (I just followed the
> guidance a handout I found on princeton.edu about logit, probit and
> multinomial logit models) . The summary results are obtained without any
> problem. *However*, when I'm using the package 'erer' to compute the
> marginal effects for the ordered logit models, I'm just getting the error
> message above.
>
> Please HELP !!!!
>
> Willy
>
>
> --
> Willy Mulimbi B.
> AEAB Grad Student & Fulbright Scholar
> Tel. (+1) 479-316-5981
> Fayetteville, AR
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From drjimlemon at gmail.com  Tue Mar 20 01:20:51 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Tue, 20 Mar 2018 11:20:51 +1100
Subject: [R] Struggling to compute marginal effects !
In-Reply-To: <CAPcX2cokvz+x82ii7W0onoYxN6wQ0R4oBNbxeHfk9r61Dt5hXA@mail.gmail.com>
References: <CAPcX2crvLNgqgmuBVOhXwGxLwyGOPF9CTfHN4=iGwzDgf6+oEQ@mail.gmail.com>
 <CA+8X3fXvPLkYse-CYtpt7_X1tN89zzUTjJf86kqkqYe0peXJ+Q@mail.gmail.com>
 <CAPcX2cpuMDLF3WdbZOPTrfyHbt7RWF7NkRaWkhweE3S24oM4bw@mail.gmail.com>
 <CA+8X3fULrdHrHOM+U-u3KSmxFKqHaDxzxoAGuU-=xyPtK-ciDg@mail.gmail.com>
 <CAPcX2cokvz+x82ii7W0onoYxN6wQ0R4oBNbxeHfk9r61Dt5hXA@mail.gmail.com>
Message-ID: <CA+8X3fU44q3QWYuVdwM7dQVGeGoAdmxp-DZ0Jvap3XAwduar_w@mail.gmail.com>

In that case, I can't work out why the first model fails but not the
second. I would start looking at "Data" to see what it contains. if:

object2 <- polr(Inc ~ Training ,Data,Hess = T,method = "logistic" )

works, the problem may be with the "Adopt" variable.

Jim


On Tue, Mar 20, 2018 at 10:55 AM, Willy Byamungu
<wmulimbi at email.uark.edu> wrote:
> Sorry, do not read "Inc_reliable_fromNTA" I did a mistake in the email I
> sent you. It should be just "Inc".
>
> The situation looks like this
>
> Data$Inc <- ordered(Data$Inc =
> c("Not_reliable_at_all","Less_reliable","Somehow_reliable","Very reliable"))
>
> First model
> object1 <- polr(Inc ~ Adopt ,Data,Hess = T,method = "logistic")
>
> Marginal effect for object1:
> ocME(object1)
> Error in eval(predvars, data, env) :
>   numeric 'envir' arg not of length one
>
> Second model
> object2 <- polr(Inc ~ Adopt + Training ,Data,Hess = T,method = "logistic" )
>
> Marginal effect for object2:
> ocME(object2)
> effect.Not_reliable_at_all effect.Less_reliable effect.Somehow_reliable
> effect.Very reliable
> Adopt                       -0.073               -0.057
> -0.064                0.193
> Training                    -0.283               -0.135
> -0.051                0.469
>
>
> On Mon, Mar 19, 2018 at 6:46 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Willy,
>> I had a look at the "erer" manual, and it looks like a (somewhat)
>> misleading error message. I don't know where "Inc_reliable_fromNTA"
>> may be, but it looks like the ocME function can't find it, which leads
>> to the "environment" error message. You have defined "Inc" as an
>> element of "Data" and when that is used in the model, the ocME
>> function works. I suspect that  "Inc_reliable_fromNTA" is not an
>> element of "Data" and this is why ocME cannot find it.
>>
>> Jim
>>
>>
>> On Tue, Mar 20, 2018 at 10:26 AM, Willy Byamungu
>> <wmulimbi at email.uark.edu> wrote:
>> > Dear Jim,
>> >
>> > Thank you very much for your help.
>> >
>> > My R-coding looks like this:
>> >
>> > Data$Inc <- ordered(Data$Inc =
>> > c("Not_reliable_at_all","Less_reliable","Somehow_reliable","Very
>> > reliable"))
>> >
>> > First model
>> > object1 <- polr(Inc_reliable_fromNTA ~ Adopt ,Data,Hess = T,method =
>> > "logistic")
>> >
>> > Marginal effect for object1:
>> > ocME(object1)
>> > Error in eval(predvars, data, env) :
>> >   numeric 'envir' arg not of length one
>> >
>> > Second model
>> > object2 <- polr(Inc ~ Adopt + Training ,Data,Hess = T,method =
>> > "logistic" )
>> >
>> > Marginal effect for object2:
>> > ocME(object2)
>> > effect.Not_reliable_at_all effect.Less_reliable effect.Somehow_reliable
>> > effect.Very reliable
>> > Adopt                       -0.073               -0.057
>> > -0.064                0.193
>> > Training                    -0.283               -0.135
>> > -0.051                0.469
>> >>
>> >
>> > The model computing requires package "MASS" and marginal effects require
>> > "ERER". As you can see above, in the first case it succeed to provide
>> > results but in the first case NO.
>> >
>> > What do you think? By the way, what do you mean by inappropriate
>> > environment
>> > and predvars?
>> >
>> > Looking forward to hearing from you.
>> >
>> > Regards,
>> >
>> > Willy
>> >
>> > On Mon, Mar 19, 2018 at 5:33 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
>> >>
>> >> Hi Willy,
>> >> The error message may be due to passing an inappropriate environment.
>> >> I don't have the "erer" package, but if that function has a default
>> >> for the environment argument, perhaps passing just the "predvars" and
>> >> "data" arguments will work.
>> >>
>> >> Jim
>> >>
>> >> On Tue, Mar 20, 2018 at 8:24 AM, Willy Byamungu
>> >> <wmulimbi at email.uark.edu>
>> >> wrote:
>> >> > Dear Oscar,
>> >> > and any other R-project person,
>> >> >
>> >> > Can you please help me to figure out the meaning of the following
>> >> > error
>> >> > message in red ?
>> >> >
>> >> > Error in eval(predvars, data, env) :
>> >> >   numeric 'envir' arg not of length one
>> >> >
>> >> > I computed ordered logit models using 'polr' in R (I just followed
>> >> > the
>> >> > guidance a handout I found on princeton.edu about logit, probit and
>> >> > multinomial logit models) . The summary results are obtained without
>> >> > any
>> >> > problem. *However*, when I'm using the package 'erer' to compute the
>> >> > marginal effects for the ordered logit models, I'm just getting the
>> >> > error
>> >> > message above.
>> >> >
>> >> > Please HELP !!!!
>> >> >
>> >> > Willy
>> >> >
>> >> >
>> >> > --
>> >> > Willy Mulimbi B.
>> >> > AEAB Grad Student & Fulbright Scholar
>> >> > Tel. (+1) 479-316-5981
>> >> > Fayetteville, AR
>> >> >
>> >> >         [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> > http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> >
>> >
>> >
>> > --
>> > Willy Mulimbi B.
>> > AEAB Grad Student & Fulbright Scholar
>> > Tel. (+1) 479-316-5981
>> > Fayetteville, AR
>
>
>
>
> --
> Willy Mulimbi B.
> AEAB Grad Student & Fulbright Scholar
> Tel. (+1) 479-316-5981
> Fayetteville, AR


From aggarwalneha2000 at gmail.com  Tue Mar 20 04:24:27 2018
From: aggarwalneha2000 at gmail.com (Neha Aggarwal)
Date: Mon, 19 Mar 2018 23:24:27 -0400
Subject: [R] Elements of Sets as dataframe column names
Message-ID: <CAMe08vvyu_t_FCqkqaSdE90WMgx-CgjApKAX71m04xuFALT0JQ@mail.gmail.com>

Hello all,

I have a set B and a dataframe df. I want to name the columns of the
dataframe after the elements of the set B.
For example, for set B with elements {{"P1"}, {"P2"}, {"P3", "P4"}} I want
to create a new dataframe with 3  columns named {"P1"} and {"P2"} and
{"P3","P4"}.

I tried colnames(df)<-(B). But it shows the elements as list, see below:
> colnames(df)
[1] "list(\"P1\")"         "list(\"P2\")"         "list(\"P3\", \"P4\")"


Second part of my question is what is the bests command to extract the
elements of a set?


Thanks,
Neha

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Tue Mar 20 04:49:27 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 19 Mar 2018 20:49:27 -0700
Subject: [R] Elements of Sets as dataframe column names
In-Reply-To: <CAMe08vvyu_t_FCqkqaSdE90WMgx-CgjApKAX71m04xuFALT0JQ@mail.gmail.com>
References: <CAMe08vvyu_t_FCqkqaSdE90WMgx-CgjApKAX71m04xuFALT0JQ@mail.gmail.com>
Message-ID: <CAGxFJbSqgWYjuM0GNj4fKp8pfD+P9PMxs4QHMpHK5bab=YGT0Q@mail.gmail.com>

You have failed to tell us that you are using a package, presumably the
sets package.

What I believe you don't understand is that the underlying data structures
that represent sets are not what you think they are, but behave as you
expect through the package API. So unless the API gets you the names in the
form you want, you will have to write code to do this yourself.  Based on
what you show above, various string handling functionality -- see, e.g.
?regexp and ?gsub or ?strsplit in base R or the stringr or stringi packages
which are likely easier to learn and use --  are how you could go about
this. Effort would be required to climb the larning curve, but I suspect
you would find it time well spent.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Mar 19, 2018 at 8:24 PM, Neha Aggarwal <aggarwalneha2000 at gmail.com>
wrote:

> Hello all,
>
> I have a set B and a dataframe df. I want to name the columns of the
> dataframe after the elements of the set B.
> For example, for set B with elements {{"P1"}, {"P2"}, {"P3", "P4"}} I want
> to create a new dataframe with 3  columns named {"P1"} and {"P2"} and
> {"P3","P4"}.
>
> I tried colnames(df)<-(B). But it shows the elements as list, see below:
> > colnames(df)
> [1] "list(\"P1\")"         "list(\"P2\")"         "list(\"P3\", \"P4\")"
>
>
> Second part of my question is what is the bests command to extract the
> elements of a set?
>
>
> Thanks,
> Neha
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wmulimbi at email.uark.edu  Tue Mar 20 02:12:58 2018
From: wmulimbi at email.uark.edu (Willy Byamungu)
Date: Tue, 20 Mar 2018 01:12:58 +0000
Subject: [R] Struggling to compute marginal effects !
In-Reply-To: <CA+8X3fU44q3QWYuVdwM7dQVGeGoAdmxp-DZ0Jvap3XAwduar_w@mail.gmail.com>
References: <CAPcX2crvLNgqgmuBVOhXwGxLwyGOPF9CTfHN4=iGwzDgf6+oEQ@mail.gmail.com>
 <CA+8X3fXvPLkYse-CYtpt7_X1tN89zzUTjJf86kqkqYe0peXJ+Q@mail.gmail.com>
 <CAPcX2cpuMDLF3WdbZOPTrfyHbt7RWF7NkRaWkhweE3S24oM4bw@mail.gmail.com>
 <CA+8X3fULrdHrHOM+U-u3KSmxFKqHaDxzxoAGuU-=xyPtK-ciDg@mail.gmail.com>
 <CAPcX2cokvz+x82ii7W0onoYxN6wQ0R4oBNbxeHfk9r61Dt5hXA@mail.gmail.com>
 <CA+8X3fU44q3QWYuVdwM7dQVGeGoAdmxp-DZ0Jvap3XAwduar_w@mail.gmail.com>
Message-ID: <CAPcX2co0wJuhb4iYfA_REMQBTS53iDYSCdxaO5pT3XajQTxY9w@mail.gmail.com>

Thank you very much Jim.

On Mon, Mar 19, 2018, 7:20 PM Jim Lemon <drjimlemon at gmail.com> wrote:

> In that case, I can't work out why the first model fails but not the
> second. I would start looking at "Data" to see what it contains. if:
>
> object2 <- polr(Inc ~ Training ,Data,Hess = T,method = "logistic" )
>
> works, the problem may be with the "Adopt" variable.
>
> Jim
>
>
> On Tue, Mar 20, 2018 at 10:55 AM, Willy Byamungu
> <wmulimbi at email.uark.edu> wrote:
> > Sorry, do not read "Inc_reliable_fromNTA" I did a mistake in the email I
> > sent you. It should be just "Inc".
> >
> > The situation looks like this
> >
> > Data$Inc <- ordered(Data$Inc =
> > c("Not_reliable_at_all","Less_reliable","Somehow_reliable","Very
> reliable"))
> >
> > First model
> > object1 <- polr(Inc ~ Adopt ,Data,Hess = T,method = "logistic")
> >
> > Marginal effect for object1:
> > ocME(object1)
> > Error in eval(predvars, data, env) :
> >   numeric 'envir' arg not of length one
> >
> > Second model
> > object2 <- polr(Inc ~ Adopt + Training ,Data,Hess = T,method =
> "logistic" )
> >
> > Marginal effect for object2:
> > ocME(object2)
> > effect.Not_reliable_at_all effect.Less_reliable effect.Somehow_reliable
> > effect.Very reliable
> > Adopt                       -0.073               -0.057
> > -0.064                0.193
> > Training                    -0.283               -0.135
> > -0.051                0.469
> >
> >
> > On Mon, Mar 19, 2018 at 6:46 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> >>
> >> Hi Willy,
> >> I had a look at the "erer" manual, and it looks like a (somewhat)
> >> misleading error message. I don't know where "Inc_reliable_fromNTA"
> >> may be, but it looks like the ocME function can't find it, which leads
> >> to the "environment" error message. You have defined "Inc" as an
> >> element of "Data" and when that is used in the model, the ocME
> >> function works. I suspect that  "Inc_reliable_fromNTA" is not an
> >> element of "Data" and this is why ocME cannot find it.
> >>
> >> Jim
> >>
> >>
> >> On Tue, Mar 20, 2018 at 10:26 AM, Willy Byamungu
> >> <wmulimbi at email.uark.edu> wrote:
> >> > Dear Jim,
> >> >
> >> > Thank you very much for your help.
> >> >
> >> > My R-coding looks like this:
> >> >
> >> > Data$Inc <- ordered(Data$Inc =
> >> > c("Not_reliable_at_all","Less_reliable","Somehow_reliable","Very
> >> > reliable"))
> >> >
> >> > First model
> >> > object1 <- polr(Inc_reliable_fromNTA ~ Adopt ,Data,Hess = T,method =
> >> > "logistic")
> >> >
> >> > Marginal effect for object1:
> >> > ocME(object1)
> >> > Error in eval(predvars, data, env) :
> >> >   numeric 'envir' arg not of length one
> >> >
> >> > Second model
> >> > object2 <- polr(Inc ~ Adopt + Training ,Data,Hess = T,method =
> >> > "logistic" )
> >> >
> >> > Marginal effect for object2:
> >> > ocME(object2)
> >> > effect.Not_reliable_at_all effect.Less_reliable
> effect.Somehow_reliable
> >> > effect.Very reliable
> >> > Adopt                       -0.073               -0.057
> >> > -0.064                0.193
> >> > Training                    -0.283               -0.135
> >> > -0.051                0.469
> >> >>
> >> >
> >> > The model computing requires package "MASS" and marginal effects
> require
> >> > "ERER". As you can see above, in the first case it succeed to provide
> >> > results but in the first case NO.
> >> >
> >> > What do you think? By the way, what do you mean by inappropriate
> >> > environment
> >> > and predvars?
> >> >
> >> > Looking forward to hearing from you.
> >> >
> >> > Regards,
> >> >
> >> > Willy
> >> >
> >> > On Mon, Mar 19, 2018 at 5:33 PM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >> >>
> >> >> Hi Willy,
> >> >> The error message may be due to passing an inappropriate environment.
> >> >> I don't have the "erer" package, but if that function has a default
> >> >> for the environment argument, perhaps passing just the "predvars" and
> >> >> "data" arguments will work.
> >> >>
> >> >> Jim
> >> >>
> >> >> On Tue, Mar 20, 2018 at 8:24 AM, Willy Byamungu
> >> >> <wmulimbi at email.uark.edu>
> >> >> wrote:
> >> >> > Dear Oscar,
> >> >> > and any other R-project person,
> >> >> >
> >> >> > Can you please help me to figure out the meaning of the following
> >> >> > error
> >> >> > message in red ?
> >> >> >
> >> >> > Error in eval(predvars, data, env) :
> >> >> >   numeric 'envir' arg not of length one
> >> >> >
> >> >> > I computed ordered logit models using 'polr' in R (I just followed
> >> >> > the
> >> >> > guidance a handout I found on princeton.edu about logit, probit
> and
> >> >> > multinomial logit models) . The summary results are obtained
> without
> >> >> > any
> >> >> > problem. *However*, when I'm using the package 'erer' to compute
> the
> >> >> > marginal effects for the ordered logit models, I'm just getting the
> >> >> > error
> >> >> > message above.
> >> >> >
> >> >> > Please HELP !!!!
> >> >> >
> >> >> > Willy
> >> >> >
> >> >> >
> >> >> > --
> >> >> > Willy Mulimbi B.
> >> >> > AEAB Grad Student & Fulbright Scholar
> >> >> > Tel. (+1) 479-316-5981
> >> >> > Fayetteville, AR
> >> >> >
> >> >> >         [[alternative HTML version deleted]]
> >> >> >
> >> >> > ______________________________________________
> >> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> >> > PLEASE do read the posting guide
> >> >> > http://www.R-project.org/posting-guide.html
> >> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >> >
> >> >
> >> >
> >> > --
> >> > Willy Mulimbi B.
> >> > AEAB Grad Student & Fulbright Scholar
> >> > Tel. (+1) 479-316-5981
> >> > Fayetteville, AR
> >
> >
> >
> >
> > --
> > Willy Mulimbi B.
> > AEAB Grad Student & Fulbright Scholar
> > Tel. (+1) 479-316-5981
> > Fayetteville, AR
>

	[[alternative HTML version deleted]]


From nrcgeb at gmail.com  Tue Mar 20 16:00:21 2018
From: nrcgeb at gmail.com (Ali Mohammadian)
Date: Tue, 20 Mar 2018 19:30:21 +0430
Subject: [R] Problem with lvs Normalization
Message-ID: <CACbLoP7rKpAesx4=NzG=qrPNEpP225g0nEaQrn3Jf0JeZQZFsA@mail.gmail.com>

Hi!

Anyone can help how I can do LVS normalization starting from an
EList.raw created using:

data= read.maimages(files, green.only=T, columns=
list(E='gMedianSignal',Eb='gBGUsed'))

thanks in advance


From pd.mes at cbs.dk  Tue Mar 20 18:34:10 2018
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Tue, 20 Mar 2018 17:34:10 +0000
Subject: [R] R 3.5.0 scheduled for April 23
Message-ID: <120ED611-56F6-4465-998D-DAAF2CA5FA0C@cbs.dk>

Full schedule available on developer.r-project.org (pending auto-update from SVN)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From drjimlemon at gmail.com  Tue Mar 20 22:29:06 2018
From: drjimlemon at gmail.com (Jim Lemon)
Date: Wed, 21 Mar 2018 08:29:06 +1100
Subject: [R] Elements of Sets as dataframe column names
In-Reply-To: <CAMe08vvyu_t_FCqkqaSdE90WMgx-CgjApKAX71m04xuFALT0JQ@mail.gmail.com>
References: <CAMe08vvyu_t_FCqkqaSdE90WMgx-CgjApKAX71m04xuFALT0JQ@mail.gmail.com>
Message-ID: <CA+8X3fV7fEL5dProPSFyepNXyDhg-rbXYLFo5Pj1XV3+dih8PA@mail.gmail.com>

Hi Neha,
>From your message I think that you might get what you want with:

names(df)<-unlist(B)

However, the "sets" package might handle lists differently.

Jim

On Tue, Mar 20, 2018 at 2:24 PM, Neha Aggarwal
<aggarwalneha2000 at gmail.com> wrote:
> Hello all,
>
> I have a set B and a dataframe df. I want to name the columns of the
> dataframe after the elements of the set B.
> For example, for set B with elements {{"P1"}, {"P2"}, {"P3", "P4"}} I want
> to create a new dataframe with 3  columns named {"P1"} and {"P2"} and
> {"P3","P4"}.
>
> I tried colnames(df)<-(B). But it shows the elements as list, see below:
>> colnames(df)
> [1] "list(\"P1\")"         "list(\"P2\")"         "list(\"P3\", \"P4\")"
>
>
> Second part of my question is what is the bests command to extract the
> elements of a set?
>
>
> Thanks,
> Neha
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jsorkin at som.umaryland.edu  Wed Mar 21 02:27:23 2018
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Wed, 21 Mar 2018 01:27:23 +0000
Subject: [R] problem with rJAVA
Message-ID: <BN6PR03MB27058BA9758A480182F151B3E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>

I have installed rJava into my Windows 10 (64-bit) R instillation using the Tools > Install Packages command of my RStudion IDE. When I issued the R command in my R code

library(rJava)  I received the following error:


 library(rJava)
Error: package or namespace load failed for ?rJava? in get(Info[i, 1], envir = env):
 lazy-load database 'C:/Users/John Sorkin/Documents/R/win-library/3.4/rJava/R/rJava.rdb' is corrupt
In addition: Warning message:
In get(Info[i, 1], envir = env) : internal error -3 in R_decompress1


I hope someone can tell me what I need to do to get RJava work in my version of R. I tried to re-install RJava and the problem persisted.


Thank you

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Wed Mar 21 02:52:59 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 20 Mar 2018 18:52:59 -0700
Subject: [R] problem with rJAVA
In-Reply-To: <BN6PR03MB27058BA9758A480182F151B3E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>
References: <BN6PR03MB27058BA9758A480182F151B3E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>
Message-ID: <4801A4D5-4264-439E-BC78-A06255D8B76D@dcn.davis.ca.us>

Are you familiar with the sessionInfo function? 
-- 
Sent from my phone. Please excuse my brevity.

On March 20, 2018 6:27:23 PM PDT, "Sorkin, John" <jsorkin at som.umaryland.edu> wrote:
>I have installed rJava into my Windows 10 (64-bit) R instillation using
>the Tools > Install Packages command of my RStudion IDE. When I issued
>the R command in my R code
>
>library(rJava)  I received the following error:
>
>
> library(rJava)
>Error: package or namespace load failed for ?rJava? in get(Info[i, 1],
>envir = env):
>lazy-load database 'C:/Users/John
>Sorkin/Documents/R/win-library/3.4/rJava/R/rJava.rdb' is corrupt
>In addition: Warning message:
>In get(Info[i, 1], envir = env) : internal error -3 in R_decompress1
>
>
>I hope someone can tell me what I need to do to get RJava work in my
>version of R. I tried to re-install RJava and the problem persisted.
>
>
>Thank you
>
>John
>
>
>John David Sorkin M.D., Ph.D.
>Professor of Medicine
>Chief, Biostatistics and Informatics
>University of Maryland School of Medicine Division of Gerontology and
>Geriatric Medicine
>Baltimore VA Medical Center
>10 North Greene Street
>GRECC (BT/18/GR)
>Baltimore, MD 21201-1524
>(Phone) 410-605-7119
>(Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>	[[alternative HTML version deleted]]


From jsorkin at som.umaryland.edu  Wed Mar 21 03:18:46 2018
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Wed, 21 Mar 2018 02:18:46 +0000
Subject: [R] Mean of a row of a data frame
Message-ID: <BN6PR03MB270546543B12A12F7808E142E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>

I am trying to get the mean of a row of a data frame. My code follows:


roop <- data.frame(x=c(1,2,3),y=c(4,5,2),z=c(0,9,4))
roop
mean(roop[1,])
mean(roop[1,c("x","y","z")])


I get the following output:

> roop
  x y z
1 1 4 0
2 2 5 9
3 3 2 4
> mean(roop[1,])
[1] NA
Warning message:
In mean.default(roop[1, ]) :
  argument is not numeric or logical: returning NA
> mean(roop[1,c("x","y","z")])
[1] NA
Warning message:
In mean.default(roop[1, c("x", "y", "z")]) :
  argument is not numeric or logical: returning NA


It is clear the the mean function does not like the data I am passing to it. I do not know why. How might I correct my code?


As always,

Thank you,

John


Thank you,

John





John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From boris.steipe at utoronto.ca  Wed Mar 21 03:40:14 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Tue, 20 Mar 2018 22:40:14 -0400
Subject: [R] Mean of a row of a data frame
In-Reply-To: <BN6PR03MB270546543B12A12F7808E142E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>
References: <BN6PR03MB270546543B12A12F7808E142E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>
Message-ID: <FC6CDCE3-212A-4E29-A789-76D62E1ED2B5@utoronto.ca>

R > rowMeans(roop)
[1] 1.666667 5.333333 3.000000
R > mean(as.numeric(roop[1,]))
[1] 1.666667


:-)




> On Mar 20, 2018, at 10:18 PM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
> 
> I am trying to get the mean of a row of a data frame. My code follows:
> 
> 
> roop <- data.frame(x=c(1,2,3),y=c(4,5,2),z=c(0,9,4))
> roop
> mean(roop[1,])
> mean(roop[1,c("x","y","z")])
> 
> 
> I get the following output:
> 
>> roop
>  x y z
> 1 1 4 0
> 2 2 5 9
> 3 3 2 4
>> mean(roop[1,])
> [1] NA
> Warning message:
> In mean.default(roop[1, ]) :
>  argument is not numeric or logical: returning NA
>> mean(roop[1,c("x","y","z")])
> [1] NA
> Warning message:
> In mean.default(roop[1, c("x", "y", "z")]) :
>  argument is not numeric or logical: returning NA
> 
> 
> It is clear the the mean function does not like the data I am passing to it. I do not know why. How might I correct my code?
> 
> 
> As always,
> 
> Thank you,
> 
> John
> 
> 
> Thank you,
> 
> John
> 
> 
> 
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Mar 21 03:49:49 2018
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 20 Mar 2018 22:49:49 -0400
Subject: [R] Mean of a row of a data frame
In-Reply-To: <BN6PR03MB270546543B12A12F7808E142E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>
References: <BN6PR03MB270546543B12A12F7808E142E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>
Message-ID: <CAGx1TMCQAm_3qi8ucEciPhk5n0Su4i7JT4bY44r8SG1TExqa7A@mail.gmail.com>

> mean(list(1,4,0))
[1] NA
Warning message:
In mean.default(list(1, 4, 0)) :
  argument is not numeric or logical: returning NA
> mean(unlist(roop[1,]))
[1] 1.666667
> apply(roop, 1, mean)
[1] 1.666667 5.333333 3.000000

data.frame is a list with some matrix characteristics.
The list characteristics are winning in this example.

Look at the definition of apply.   It has an as.matrix in it that
removes the list behavior.

Rich


On Tue, Mar 20, 2018 at 10:18 PM, Sorkin, John
<jsorkin at som.umaryland.edu> wrote:
> I am trying to get the mean of a row of a data frame. My code follows:
>
>
> roop <- data.frame(x=c(1,2,3),y=c(4,5,2),z=c(0,9,4))
> roop
> mean(roop[1,])
> mean(roop[1,c("x","y","z")])
>
>
> I get the following output:
>
>> roop
>   x y z
> 1 1 4 0
> 2 2 5 9
> 3 3 2 4
>> mean(roop[1,])
> [1] NA
> Warning message:
> In mean.default(roop[1, ]) :
>   argument is not numeric or logical: returning NA
>> mean(roop[1,c("x","y","z")])
> [1] NA
> Warning message:
> In mean.default(roop[1, c("x", "y", "z")]) :
>   argument is not numeric or logical: returning NA
>
>
> It is clear the the mean function does not like the data I am passing to it. I do not know why. How might I correct my code?
>
>
> As always,
>
> Thank you,
>
> John
>
>
> Thank you,
>
> John
>
>
>
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Mar 21 04:01:15 2018
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 20 Mar 2018 23:01:15 -0400
Subject: [R] Mean of a row of a data frame
In-Reply-To: <FC6CDCE3-212A-4E29-A789-76D62E1ED2B5@utoronto.ca>
References: <BN6PR03MB270546543B12A12F7808E142E2AA0@BN6PR03MB2705.namprd03.prod.outlook.com>
 <FC6CDCE3-212A-4E29-A789-76D62E1ED2B5@utoronto.ca>
Message-ID: <CAGx1TMDN_7fKhxQM+3BA02qsnVVZYD9ZKzML0+Ks=2_Qe_aWeg@mail.gmail.com>

rowMeans is designed for speed.  It also has as.matrix inside it.

On Tue, Mar 20, 2018 at 10:40 PM, Boris Steipe <boris.steipe at utoronto.ca> wrote:
> R > rowMeans(roop)
> [1] 1.666667 5.333333 3.000000
> R > mean(as.numeric(roop[1,]))
> [1] 1.666667
>
>
> :-)
>
>
>
>
>> On Mar 20, 2018, at 10:18 PM, Sorkin, John <jsorkin at som.umaryland.edu> wrote:
>>
>> I am trying to get the mean of a row of a data frame. My code follows:
>>
>>
>> roop <- data.frame(x=c(1,2,3),y=c(4,5,2),z=c(0,9,4))
>> roop
>> mean(roop[1,])
>> mean(roop[1,c("x","y","z")])
>>
>>
>> I get the following output:
>>
>>> roop
>>  x y z
>> 1 1 4 0
>> 2 2 5 9
>> 3 3 2 4
>>> mean(roop[1,])
>> [1] NA
>> Warning message:
>> In mean.default(roop[1, ]) :
>>  argument is not numeric or logical: returning NA
>>> mean(roop[1,c("x","y","z")])
>> [1] NA
>> Warning message:
>> In mean.default(roop[1, c("x", "y", "z")]) :
>>  argument is not numeric or logical: returning NA
>>
>>
>> It is clear the the mean function does not like the data I am passing to it. I do not know why. How might I correct my code?
>>
>>
>> As always,
>>
>> Thank you,
>>
>> John
>>
>>
>> Thank you,
>>
>> John
>>
>>
>>
>>
>>
>> John David Sorkin M.D., Ph.D.
>> Professor of Medicine
>> Chief, Biostatistics and Informatics
>> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
>> Baltimore VA Medical Center
>> 10 North Greene Street
>> GRECC (BT/18/GR)
>> Baltimore, MD 21201-1524
>> (Phone) 410-605-7119
>> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From statistics at inter.nl.net  Wed Mar 21 05:00:42 2018
From: statistics at inter.nl.net (Ronald Geskus)
Date: Wed, 21 Mar 2018 05:00:42 +0100
Subject: [R] 
 selectFGR - variable selection in fine gray model for competing
 risks
Message-ID: <c26de060f9011ea50721acf015dcd98f.squirrel@webmail.internl.net>

Dear Raja,

A Fine and Gray model can be fitted using the standard coxph function with
weights that correct for right censoring and left truncation. Hence I
guess any function that allows to perform stepwise regression with coxph
should work. See e.g. my article in Biometrics
https://doi.org/10.1111/j.1541-0420.2010.01420.x, or the vignette
"Multi-state models and competing risks" in the survival package.

best regards,

Ronald Geskus, PhD
head of biostatistics group
Oxford University Clinical Research unit
Ho Chi Minh city, Vietnam
associate professor University of Oxford
http://www.oucru.org/dr-ronald-b-geskus/

"Raja, Dr. Edwin Amalraj" <amalraj.raja at abdn.ac.uk> writes:

> Dear All,
>
>    I would like to use R function 'selectFGR' of fine gray model in
> competing risks model.  I used the 'Melanoma' data in 'riskRegression'
> package.  Some of the variables are factor.  I get solution for full
> model but not in variable selection model.  Any advice how to use
> factor variable in 'selectFGR' function.  The following R code is
> produced below for reproducibility.
>
> library(riskRegression)
> library(pec)
> dat <-data(Melanoma,package="riskRegression")
> Melanoma$logthick <- log(Melanoma$thick)
> f1 <- Hist(time,status)~age+sex+epicel+ulcer
> df1 <-FGR(f1,cause=1, data=Melanoma)
> df1
> df <-selectFGR(f1, data=Melanoma, rule ="BIC",  direction="backward")
>
> Thanks in advice for your suggestion. Is there any alternative solution ?
>
> Regards
> Amalraj raja
>
>
> The University of Aberdeen is a charity registered in Scotland, No
SC013683.
> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir.
SC013683.


From english.server at gmail.com  Wed Mar 21 07:49:23 2018
From: english.server at gmail.com (Persian Irani)
Date: Wed, 21 Mar 2018 11:19:23 +0430
Subject: [R] Package 'pd.mirna.1.0.2xgain' was not found in the BioConductor
 repository
Message-ID: <CAP0cSCSmhmsBWo6bqO4XppC+eC123WXfAE-n3N9oS19v6iYO4g@mail.gmail.com>

Hi all!

While I am trying to read .cel files with oligo package:

afbatch=read.celfiles(list.celfiles())

I get an error:
Package 'pd.mirna.1.0.2xgain' was not found in the BioConductor repository

How can I overcome this?

Thank you in advance


From lawarde.ankita1 at gmail.com  Wed Mar 21 08:01:05 2018
From: lawarde.ankita1 at gmail.com (Ankita Lawarde)
Date: Wed, 21 Mar 2018 12:31:05 +0530
Subject: [R] Error in GDCprepare step of TCGAbiolinks
Message-ID: <CADXCfM1A_037jsy49_AsrAWy+VMFOS=MUuCWgz2Xdtn=++hz+Q@mail.gmail.com>

   Dear Sir/ma'am,

I'm using R-3.4.4 and TCGAbiolinks package for the analysis of GDC data.
Till today i have reintalled R and R studio for 5 times but one error comes
when i analyze the GDC data at the step GDCprepare. the data i am using is
not a legacy data of GDC data portal.

I think the problem is with my Laptop only because i have run the same
commands in another PC and there was no error. Thus i have uninstalled and
again installed the R but the error is not going.

Today i have installed the developer version of TCGAbiolinks. and the error
is still there.

I have attached the code used and the session info.

Every time i run this GDCprepare command this same error comes as biomart
service is not available. So i had contaced the Biomart people but they
said that the Biomart is working fine.

below is the complete R code i am usign with the corresponding error,

library(TCGAbiolinks)

query.exp <- GDCquery(project = "TCGA-LUAD",
                      data.category = "Transcriptome Profiling",
                      data.type = "Gene Expression Quantification",
                      workflow.type = "HTSeq - Counts",
                      experimental.strategy = "RNA-Seq")

query_load <- GDCdownload(query.exp)

luad.exp <- GDCprepare(query = query.exp, save = TRUE, save.filename =
"TCGA_LUAD_Exp.rda",
                       summarizedExperiment = TRUE)

|==================================================================================================|
100%    1 MB
|==================================================================================================|
100%    1 MB
|==================================================================================================|
100%    1 MB
|==================================================================================================|
100%    1 MB
|==================================================================================================|
100%    1 MB
|==================================================================================================|
100%    1 MB
|==================================================================================================|
100%    1 MB
|==================================================================================================|
100%    1 MB

|=======================================================================================================|
100%
Starting to add information to samples
 => Add clinical information to samples
Add FFPE information. More information at:
=> https://cancergenome.nih.gov/cancersselected/biospeccriteria
=>
http://gdac.broadinstitute.org/runs/sampleReports/latest/FPPP_FFPE_Cases.html
 => Adding subtype information to samples
luad subtype information from:doi:10.1038/nature13385
Request to BioMart web service failed.
The BioMart web service you're accessing may be down.
Check the following URL and see if this website is available:
http://www.ensembl.org:80/biomart/martservice?type=registry&requestid=biomaRt
Request to BioMart web service failed.
The BioMart web service you're accessing may be down.
Check the following URL and see if this website is available:
http://uswest.ensembl.org:80/biomart/martservice?type=registry&requestid=biomaRt&redirect=no
Error: $ operator is invalid for atomic vectors


 sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
States.1252
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C

[5] LC_TIME=English_United States.1252

attached base packages:
[1] parallel  stats4    stats     graphics  grDevices utils     datasets
methods   base

other attached packages:
 [1] TCGAbiolinks_2.7.21        SummarizedExperiment_1.8.1
DelayedArray_0.4.1         matrixStats_0.53.1
 [5] Biobase_2.38.0             GenomicRanges_1.30.0
 GenomeInfoDb_1.14.0        IRanges_2.12.0
 [9] S4Vectors_0.16.0           BiocGenerics_0.24.0
RColorBrewer_1.1-2         edgeR_3.20.9
[13] limma_3.34.9

loaded via a namespace (and not attached):
  [1] colorspace_1.3-2            selectr_0.3-2               rjson_0.2.15

  [4] hwriter_1.3.2               circlize_0.4.3
XVector_0.18.0
  [7] GlobalOptions_0.0.13        ggpubr_0.1.6                matlab_1.0.2

 [10] ggrepel_0.7.0               bit64_0.9-7
 AnnotationDbi_1.40.0
 [13] xml2_1.2.0                  codetools_0.2-15
splines_3.4.4
 [16] R.methodsS3_1.7.1           mnormt_1.5-5
doParallel_1.0.11
 [19] DESeq_1.30.0                geneplotter_1.56.0          knitr_1.20

 [22] jsonlite_1.5                Rsamtools_1.30.0            km.ci_0.5-2

 [25] broom_0.4.3                 annotate_1.56.1
 cluster_2.0.6
 [28] R.oo_1.21.0                 readr_1.1.1
 compiler_3.4.4
 [31] httr_1.3.1                  assertthat_0.2.0
Matrix_1.2-12
 [34] lazyeval_0.2.1              prettyunits_1.0.2           tools_3.4.4

 [37] bindrcpp_0.2                gtable_0.2.0                glue_1.2.0

 [40] GenomeInfoDbData_1.0.0      reshape2_1.4.3              dplyr_0.7.4

 [43] ggthemes_3.4.0              ShortRead_1.36.1            Rcpp_0.12.16

 [46] Biostrings_2.46.0           nlme_3.1-131.1
rtracklayer_1.38.3
 [49] iterators_1.0.9             psych_1.7.8
 stringr_1.3.0
 [52] rvest_0.3.2                 XML_3.98-1.10               zoo_1.8-1

 [55] zlibbioc_1.24.0             scales_0.5.0
aroma.light_3.8.0
 [58] hms_0.4.2                   curl_3.1
ComplexHeatmap_1.17.1
 [61] memoise_1.1.0               gridExtra_2.3               KMsurv_0.1-5

 [64] ggplot2_2.2.1               downloader_0.4
biomaRt_2.34.2
 [67] latticeExtra_0.6-28         stringi_1.1.7               RSQLite_2.0

 [70] genefilter_1.60.0           foreach_1.4.4
 RMySQL_0.10.14
 [73] GenomicFeatures_1.30.3      BiocParallel_1.12.0         shape_1.4.4

 [76] rlang_0.2.0                 pkgconfig_2.0.1             bitops_1.0-6

 [79] lattice_0.20-35             purrr_0.2.4                 bindr_0.1.1

 [82] GenomicAlignments_1.14.1    cmprsk_2.2-7                bit_1.1-12

 [85] plyr_1.8.4                  magrittr_1.5                R6_2.2.2

 [88] DBI_0.8                     mgcv_1.8-23                 pillar_1.2.1

 [91] foreign_0.8-69              survival_2.41-3
 RCurl_1.95-4.10
 [94] tibble_1.4.2                EDASeq_2.12.0
 survMisc_0.5.4
 [97] GetoptLong_0.1.6            progress_1.1.2
locfit_1.5-9.1
[100] grid_3.4.4                  sva_3.26.0
data.table_1.10.4-3
[103] blob_1.1.0                  ConsensusClusterPlus_1.42.0
digest_0.6.15
[106] xtable_1.8-2                tidyr_0.8.0
 R.utils_2.6.0
[109] munsell_0.4.3               survminer_0.4.2




I hope this helps to understand my problem.
 I look forward to hear from you



Regards,
Ankita

	[[alternative HTML version deleted]]


From Jin.Li at ga.gov.au  Wed Mar 21 00:57:01 2018
From: Jin.Li at ga.gov.au (Li Jin)
Date: Tue, 20 Mar 2018 23:57:01 +0000
Subject: [R] =?windows-1252?q?A_new_version_=281=2E1=2E0=29_of_the_=93spm?=
 =?windows-1252?q?=94_package_for_spatial_predictive_modelling_reelased_on?=
 =?windows-1252?q?_CRAN_=5BSEC=3DUNCLASSIFIED=5D?=
Message-ID: <094bd838b77241cbb33a98781023cb83@win-exch-prod03.prod.lan>

Dear R users,



A new version (1.1.0) of the ?spm? package for spatial predictive modelling  is now available on CRAN.



The introductory vignette is available here:

https://cran.rstudio.com/web/packages/spm/vignettes/spm.html



There are several new enhancements to the package including a fast version of random forest in using ranger (rg) library(ranger) and the ability to convert relevant error measures to accuracy measure (VEcv).  A full list of changes are shown below.



New Features:

1. Added eight functions to implement random forest using ranger (rg) in library(ranger).

2. Added a new function, tovecv, to convert relevant error measures to accuracy measure (VEcv).

3. Added some accuracy measures for categorical data and one further accuracy measure for numerical data in function pred.acc.

4. Added the variances of predictions to relevant prediction functions.

5. Revised RFcv etc. to use pred.acc.

6. Removed samples with missing values in data(hard).

6. Updated vignette accordingly.



Comments,  suggestions and contributions are welcome and much appreciated!.



Kind regards,

Jin Li, PhD | Spatial Modeller / Computational Statistician
National Earth and Marine Observations | Environmental Geoscience Division
t:  +61 2 6249 9899    www.ga.gov.au<http://www.ga.gov.au/>


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: mg_info.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180320/a8eca9da/attachment.txt>

From amalraj.raja at abdn.ac.uk  Wed Mar 21 10:11:43 2018
From: amalraj.raja at abdn.ac.uk (Raja, Dr. Edwin Amalraj)
Date: Wed, 21 Mar 2018 09:11:43 +0000
Subject: [R] selectFGR vs weighted coxph for internal validation and
 calibration curve- competing risks model
Message-ID: <VI1PR0402MB38229F1CE4DCC372C3A6DCCFA1AA0@VI1PR0402MB3822.eurprd04.prod.outlook.com>

Dear Geskus,

I want to develop a prediction model.  I followed your paper and analysed thro' weighted coxph approach.   I can develop nomogram based on the final model also.  But I do not know how to do internal validation of the model and subsequently obtain calibration plot.   Is it possible to use Wolbers et al Epid 2009 approach 9 (R code for internal validation and calibration) .  It is possible to get these measures after using R function 'crr' or 'FGR'. That is why I wanted to go in that route. At the same time,  I had this doubt because their approach assume a record per individual whereas weight coxph creates two or more records per individual.  I am new to R and could not modify the R code easily.   Any suggestion?   Has anyone done internal validation and calibration after  using weighted  coxph approach?  Can you kindly refer me to the reference which has R code?

Thank you very much for all your inputs and suggestions

Regards
Amalraj raja

-----Original Message-----
From: Ronald Geskus [mailto:statistics at inter.nl.net]
Sent: 21 March 2018 04:01
To: r-help at r-project.org
Cc: Raja, Dr. Edwin Amalraj <amalraj.raja at abdn.ac.uk>
Subject: Re: [R] selectFGR - variable selection in fine gray model for competing risks

Dear Raja,

A Fine and Gray model can be fitted using the standard coxph function with weights that correct for right censoring and left truncation. Hence I guess any function that allows to perform stepwise regression with coxph should work. See e.g. my article in Biometrics https://doi.org/10.1111/j.1541-0420.2010.01420.x, or the vignette "Multi-state models and competing risks" in the survival package.

best regards,

Ronald Geskus, PhD
head of biostatistics group
Oxford University Clinical Research unit Ho Chi Minh city, Vietnam associate professor University of Oxford http://www.oucru.org/dr-ronald-b-geskus/

"Raja, Dr. Edwin Amalraj" <amalraj.raja at abdn.ac.uk> writes:

> Dear All,
>
>    I would like to use R function 'selectFGR' of fine gray model in
> competing risks model.  I used the 'Melanoma' data in 'riskRegression'
> package.  Some of the variables are factor.  I get solution for full
> model but not in variable selection model.  Any advice how to use
> factor variable in 'selectFGR' function.  The following R code is
> produced below for reproducibility.
>
> library(riskRegression)
> library(pec)
> dat <-data(Melanoma,package="riskRegression")
> Melanoma$logthick <- log(Melanoma$thick)
> f1 <- Hist(time,status)~age+sex+epicel+ulcer
> df1 <-FGR(f1,cause=1, data=Melanoma)
> df1
> df <-selectFGR(f1, data=Melanoma, rule ="BIC",  direction="backward")
>
> Thanks in advice for your suggestion. Is there any alternative solution ?
>
> Regards
> Amalraj raja
>
>
> The University of Aberdeen is a charity registered in Scotland, No
SC013683.
> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir.
SC013683.



The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.


From dwinsemius at comcast.net  Wed Mar 21 10:33:43 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Mar 2018 02:33:43 -0700
Subject: [R] 
 Package 'pd.mirna.1.0.2xgain' was not found in the BioConductor
 repository
In-Reply-To: <CAP0cSCSmhmsBWo6bqO4XppC+eC123WXfAE-n3N9oS19v6iYO4g@mail.gmail.com>
References: <CAP0cSCSmhmsBWo6bqO4XppC+eC123WXfAE-n3N9oS19v6iYO4g@mail.gmail.com>
Message-ID: <A2B57E2B-8D35-409D-8FA8-DEA899B4F272@comcast.net>


> On Mar 20, 2018, at 11:49 PM, Persian Irani <english.server at gmail.com> wrote:
> 
> Hi all!
> 
> While I am trying to read .cel files with oligo package:
> 
> afbatch=read.celfiles(list.celfiles())
> 
> I get an error:
> Package 'pd.mirna.1.0.2xgain' was not found in the BioConductor repository
> 
> How can I overcome this?

I'm guessing that there is an error in the input file. That doesn't look like a valid package name. The BioC repo has a package names pd.mirna.1.0

Perhaps a comma or some other separator got misplaced along the way. At any rate the right place to go would be the BioC support pages, not Rhelp. I'm sure you will need to supply them with more information than you supplied here.

> 
> Thank you in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dcarlson at tamu.edu  Wed Mar 21 15:32:12 2018
From: dcarlson at tamu.edu (David L Carlson)
Date: Wed, 21 Mar 2018 14:32:12 +0000
Subject: [R] Vary an equation using values from a sequence
Message-ID: <b7ce1d39451b478abc4038afc948fcd1@exch-2p-mbx-w2.ads.tamu.edu>

It depends a bit on what you plan to do with the results. A loop would be easy and straightforward:

> k <- 1:5
> for(k in 1:5) print(Data - min(Data) + k)
 [1]  1  2  3  4  5  6  7  8  9 10
 [1]  2  3  4  5  6  7  8  9 10 11
 [1]  3  4  5  6  7  8  9 10 11 12
 [1]  4  5  6  7  8  9 10 11 12 13
 [1]  5  6  7  8  9 10 11 12 13 14

Or you can use sapply() to hide the loop:

> sapply(1:5, function(k) Data - min(Data) + k)
      [,1] [,2] [,3] [,4] [,5]
 [1,]    1    2    3    4    5
 [2,]    2    3    4    5    6
 [3,]    3    4    5    6    7
 [4,]    4    5    6    7    8
 [5,]    5    6    7    8    9
 [6,]    6    7    8    9   10
 [7,]    7    8    9   10   11
 [8,]    8    9   10   11   12
 [9,]    9   10   11   12   13
[10,]   10   11   12   13   14

This is more compact if you are planning to save the results, e.g.

> output <- sapply(1:5, function(k) Data - min(Data) + k)

As opposed to using the loop:

> output <- matrix(NA, length(k), length(Data)) for (i in seq_along(k)) 
> output[i, ] <- Data - min(Data) + k[i] output
     [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10]
[1,]    1    2    3    4    5    6    7    8    9    10
[2,]    2    3    4    5    6    7    8    9   10    11
[3,]    3    4    5    6    7    8    9   10   11    12
[4,]    4    5    6    7    8    9   10   11   12    13
[5,]    5    6    7    8    9   10   11   12   13    14

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jake William Andrae
Sent: Wednesday, March 14, 2018 11:14 PM
To: R-help <r-help at r-project.org>
Subject: [R] Vary an equation using values from a sequence

Hi All,

I have a vector of data on which I am operating. The equation with which I want to operate on the vector has a value k. I want to run the equation and output a new vector, each time replacing k with each value from the sequence I defined. I have thought about using for loops and such, but this seems like overkill. I am wondering if there is a simple solution that would allow me to accomplish this.


The code I am using is outlined below.


Data <- c(1:10) #Data
value <- seq(from = 0, to = 100 , by = 0.01) #Sequence Data - min(Data) + k # Equation

Thanks,
Jake


Jake Andrae
PhD Candidate
Geology & Geophysics   Sprigg Geobiology Centre Department of Earth Science School of Physical Sciences The University of Adelaide, AUSTRALIA 5005
Phone: 0407701565
Email: jake.andrae at adelaide.edu.au


	[[alternative HTML version deleted]]


From Holger.Taschenberger at mpibpc.mpg.de  Wed Mar 21 13:27:09 2018
From: Holger.Taschenberger at mpibpc.mpg.de (Holger Taschenberger)
Date: Wed, 21 Mar 2018 13:27:09 +0100
Subject: [R] R 3.4.4, internet access fails on Windows XP
Message-ID: <20180321132709.E224.C7C4B6F9@mpibpc.mpg.de>

I can install and run R 3.4.4 on Windows XP (32bit). However, calling "Update Packages..." or "Html help" from the RGui.exe main menu fails with a Windows MessageBox saying:

"The procedure entry point IdnToAscii could not be located in the dynamic link library KERNEL32.dll"

and the following text printed to the RGui console window:

"...
In addition: Warning message:
In download.file(url, destfile = f, quiet = TRUE) :
  unable to load shared object 'C:/R/R-3.4.4/modules/i386/internet.dll':
  LoadLibrary failure:  The specified procedure could not be found."

"IdnToAscii" is exported from "C:\WINDOWS\system32\normaliz.dll" on Windows XP. But apparently RGui cannot locate this procedure on Windows XP. 

Any advice? (except for "switch to a more recent windows version")

Thanks a lot,
--Holger


From gianfranco.lovison at unipa.it  Wed Mar 21 16:16:27 2018
From: gianfranco.lovison at unipa.it (Gianfranco Lovison)
Date: Wed, 21 Mar 2018 16:16:27 +0100
Subject: [R] Confidence intervals for the Instrumental Variable estimators
 of TWO causal effects
Message-ID: <20180321161627.Horde.B4mK8bamDBatSCvF4QoFs4I@webmail.unipa.it>

Dear all,

I am using the Instrumental Variable approach to estimate the causal
effects of TWO endogenous variables in a Mendelian Randomization study.
As long as point estimation is concerned, I have no problem: both "ivreg"
in library "AER" and "tsls" in library "sem" do the job perfectly. The  
problems begin
when I try to obtain confidence intervals for these two causal effects.

Of course, I can take the output from ivreg or tsls and compute the Wald-type
confidence intervals using a Normal approximation. But Wald-type confidence
interval are known to have poor coverage properties, and therefore I would
like to switch to more robust confidence intervals, like those provided by
inverting the Anderson-Rubin (AR) or the Conditional Ratio Likelihood  
(CLR) tests.
The library "ivpack" has the command "anderson.rubin.ci" which implements AR,
and the library "ivmodel" has the command "confint.ivmodel" which  
provides a rich choice of
alternative confidence intervals (OLS, Fuller, LIML, TSLS, AR, CLR).
But both assume that there is only ONE endogenous variable for which
a confidence interval for the causal effect is needed. If there are TWO, or
more, endogenous variables, they stop and give an error.
Any idea of other R libraries which provide commands overtaking this
limitation?

Any suggestion really appreciated. Thanks in advance!!

Gianfranco Lovison


From stefano.sofia at regione.marche.it  Wed Mar 21 16:44:56 2018
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Wed, 21 Mar 2018 15:44:56 +0000
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
Message-ID: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>

Dear list users,
let me ask you this trivial question. I worked on that for a long time, by now.
Suppose to have a data frame with NAs and to sum some columns with rowSums:

df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
df[1, ] <- NA
rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)

If all the elements of the selected columns are NA, rowSums returns 0 while I need NA.
Is there an easy and efficient way to use rowSums within a function like

function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?

or an equivalent function?

Thank you for your help
Stefano



         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Wed Mar 21 16:58:15 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 21 Mar 2018 11:58:15 -0400
Subject: [R] R 3.4.4, internet access fails on Windows XP
In-Reply-To: <20180321132709.E224.C7C4B6F9@mpibpc.mpg.de>
References: <20180321132709.E224.C7C4B6F9@mpibpc.mpg.de>
Message-ID: <cd2faf0a-f9ea-1f3d-17ce-b1fc854a6d0e@gmail.com>

On 21/03/2018 8:27 AM, Holger Taschenberger wrote:
> I can install and run R 3.4.4 on Windows XP (32bit). However, calling "Update Packages..." or "Html help" from the RGui.exe main menu fails with a Windows MessageBox saying:
> 
> "The procedure entry point IdnToAscii could not be located in the dynamic link library KERNEL32.dll"
> 
> and the following text printed to the RGui console window:
> 
> "...
> In addition: Warning message:
> In download.file(url, destfile = f, quiet = TRUE) :
>    unable to load shared object 'C:/R/R-3.4.4/modules/i386/internet.dll':
>    LoadLibrary failure:  The specified procedure could not be found."
> 
> "IdnToAscii" is exported from "C:\WINDOWS\system32\normaliz.dll" on Windows XP. But apparently RGui cannot locate this procedure on Windows XP.
> 
> Any advice? (except for "switch to a more recent windows version")


The Windows FAQ 2.2 says, "Windows XP is no longer supported", so I 
think you're out of luck.  XP went past "end-of-life" in 2014.

Other than switching to a more recent Windows version, your choices are 
switching to a completely different OS, or switching to an older version 
of R.

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Mar 21 17:01:39 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 21 Mar 2018 12:01:39 -0400
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
Message-ID: <63d60102-c80b-2423-b586-fbae033f2225@gmail.com>

On 21/03/2018 11:44 AM, Stefano Sofia wrote:
> Dear list users,
> let me ask you this trivial question. I worked on that for a long time, by now.
> Suppose to have a data frame with NAs and to sum some columns with rowSums:
> 
> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
> df[1, ] <- NA
> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
> 
> If all the elements of the selected columns are NA, rowSums returns 0 while I need NA.
> Is there an easy and efficient way to use rowSums within a function like
> 
> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
> 
> or an equivalent function?

Something like

apply(df[,c("A", "B")], 1, function(x) if (all(is.na(x))) NA else sum(x, 
na.rm = TRUE))

should do what you want.

Duncan Murdoch

> 
> Thank you for your help
> Stefano
> 
> 
> 
>           (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
> 
> ________________________________
> 
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> 
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From boris.steipe at utoronto.ca  Wed Mar 21 17:03:29 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 21 Mar 2018 12:03:29 -0400
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
Message-ID: <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>

Should not the result be NULL if you have removed the NA with na.rm=TRUE ?

B.



> On Mar 21, 2018, at 11:44 AM, Stefano Sofia <stefano.sofia at regione.marche.it> wrote:
> 
> Dear list users,
> let me ask you this trivial question. I worked on that for a long time, by now.
> Suppose to have a data frame with NAs and to sum some columns with rowSums:
> 
> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
> df[1, ] <- NA
> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
> 
> If all the elements of the selected columns are NA, rowSums returns 0 while I need NA.
> Is there an easy and efficient way to use rowSums within a function like
> 
> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
> 
> or an equivalent function?
> 
> Thank you for your help
> Stefano
> 
> 
> 
>         (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
> 
> ________________________________
> 
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
> 
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Wed Mar 21 17:58:33 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 21 Mar 2018 09:58:33 -0700
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
 <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
Message-ID: <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>

What do you mean by "should not"?

NULL means "missing object" in R. The result of the sum function is always expected to be numeric... so NA_real or NA_integer could make sense as possible return values. But you cannot compute on NULL so no, that doesn't work. 

See the note under the "Value" section of ?sum as to why zero is returned when all inputs are removed.
-- 
Sent from my phone. Please excuse my brevity.

On March 21, 2018 9:03:29 AM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>Should not the result be NULL if you have removed the NA with
>na.rm=TRUE ?
>
>B.
>
>
>
>> On Mar 21, 2018, at 11:44 AM, Stefano Sofia
><stefano.sofia at regione.marche.it> wrote:
>> 
>> Dear list users,
>> let me ask you this trivial question. I worked on that for a long
>time, by now.
>> Suppose to have a data frame with NAs and to sum some columns with
>rowSums:
>> 
>> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
>> df[1, ] <- NA
>> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>> 
>> If all the elements of the selected columns are NA, rowSums returns 0
>while I need NA.
>> Is there an easy and efficient way to use rowSums within a function
>like
>> 
>> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>> 
>> or an equivalent function?
>> 
>> Thank you for your help
>> Stefano
>> 
>> 
>> 
>>         (oo)
>> --oOO--( )--OOo----------------
>> Stefano Sofia PhD
>> Area Meteorologica e  Area nivologica - Centro Funzionale
>> Servizio Protezione Civile - Regione Marche
>> Via del Colle Ameno 5
>> 60126 Torrette di Ancona, Ancona
>> Uff: 071 806 7743
>> E-mail: stefano.sofia at regione.marche.it
>> ---Oo---------oO----------------
>> 
>> ________________________________
>> 
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>contenere informazioni confidenziali, pertanto ? destinato solo a
>persone autorizzate alla ricezione. I messaggi di posta elettronica per
>i client di Regione Marche possono contenere informazioni confidenziali
>e con privilegi legali. Se non si ? il destinatario specificato, non
>leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>eliminarlo completamente dal sistema del proprio computer. Ai sensi
>dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>by persons entitled to receive the confidential information it may
>contain. E-mail messages to clients of Regione Marche may contain
>information that is confidential and legally privileged. Please do not
>read, copy, forward, or store this message unless you are an intended
>recipient of it. If you have received this message in error, please
>forward it to the sender and delete it completely from your computer
>system.
>> 
>> --
>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>infetto.
>> This message was scanned by Libra ESVA and is believed to be clean.
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From boris.steipe at utoronto.ca  Wed Mar 21 18:05:21 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 21 Mar 2018 13:05:21 -0400
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
 <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
 <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
Message-ID: <A8A62A70-BA00-48F5-BF3E-EA8A01B72E28@utoronto.ca>

Surely the result of summation of non-existent values is not defined, is it not? And since the NA values have been _removed_, there's nothing left to sum over. In fact, pretending the the result in that case is zero would appear audacious, no?

Cheers,
Boris 





> On Mar 21, 2018, at 12:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> What do you mean by "should not"?
> 
> NULL means "missing object" in R. The result of the sum function is always expected to be numeric... so NA_real or NA_integer could make sense as possible return values. But you cannot compute on NULL so no, that doesn't work. 
> 
> See the note under the "Value" section of ?sum as to why zero is returned when all inputs are removed.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 21, 2018 9:03:29 AM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Should not the result be NULL if you have removed the NA with
>> na.rm=TRUE ?
>> 
>> B.
>> 
>> 
>> 
>>> On Mar 21, 2018, at 11:44 AM, Stefano Sofia
>> <stefano.sofia at regione.marche.it> wrote:
>>> 
>>> Dear list users,
>>> let me ask you this trivial question. I worked on that for a long
>> time, by now.
>>> Suppose to have a data frame with NAs and to sum some columns with
>> rowSums:
>>> 
>>> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
>>> df[1, ] <- NA
>>> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>>> 
>>> If all the elements of the selected columns are NA, rowSums returns 0
>> while I need NA.
>>> Is there an easy and efficient way to use rowSums within a function
>> like
>>> 
>>> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>>> 
>>> or an equivalent function?
>>> 
>>> Thank you for your help
>>> Stefano
>>> 
>>> 
>>> 
>>>        (oo)
>>> --oOO--( )--OOo----------------
>>> Stefano Sofia PhD
>>> Area Meteorologica e  Area nivologica - Centro Funzionale
>>> Servizio Protezione Civile - Regione Marche
>>> Via del Colle Ameno 5
>>> 60126 Torrette di Ancona, Ancona
>>> Uff: 071 806 7743
>>> E-mail: stefano.sofia at regione.marche.it
>>> ---Oo---------oO----------------
>>> 
>>> ________________________________
>>> 
>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>> contenere informazioni confidenziali, pertanto ? destinato solo a
>> persone autorizzate alla ricezione. I messaggi di posta elettronica per
>> i client di Regione Marche possono contenere informazioni confidenziali
>> e con privilegi legali. Se non si ? il destinatario specificato, non
>> leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>> ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>> eliminarlo completamente dal sistema del proprio computer. Ai sensi
>> dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>> ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>> essere visionata da persone estranee al destinatario.
>>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>> by persons entitled to receive the confidential information it may
>> contain. E-mail messages to clients of Regione Marche may contain
>> information that is confidential and legally privileged. Please do not
>> read, copy, forward, or store this message unless you are an intended
>> recipient of it. If you have received this message in error, please
>> forward it to the sender and delete it completely from your computer
>> system.
>>> 
>>> --
>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>> infetto.
>>> This message was scanned by Libra ESVA and is believed to be clean.
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Mar 21 18:22:40 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 21 Mar 2018 18:22:40 +0100
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <A8A62A70-BA00-48F5-BF3E-EA8A01B72E28@utoronto.ca>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
 <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
 <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
 <A8A62A70-BA00-48F5-BF3E-EA8A01B72E28@utoronto.ca>
Message-ID: <904D1306-9E88-4245-9118-79153F5ABD56@gmail.com>

No. The empty sum is zero. Adding it to another sum should not change it. Nothing audacious about that. This is consistent; other definitions just cause trouble.

-pd

> On 21 Mar 2018, at 18:05 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
> 
> Surely the result of summation of non-existent values is not defined, is it not? And since the NA values have been _removed_, there's nothing left to sum over. In fact, pretending the the result in that case is zero would appear audacious, no?
> 
> Cheers,
> Boris 
> 
> 
> 
> 
> 
>> On Mar 21, 2018, at 12:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>> 
>> What do you mean by "should not"?
>> 
>> NULL means "missing object" in R. The result of the sum function is always expected to be numeric... so NA_real or NA_integer could make sense as possible return values. But you cannot compute on NULL so no, that doesn't work. 
>> 
>> See the note under the "Value" section of ?sum as to why zero is returned when all inputs are removed.
>> -- 
>> Sent from my phone. Please excuse my brevity.
>> 
>> On March 21, 2018 9:03:29 AM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>> Should not the result be NULL if you have removed the NA with
>>> na.rm=TRUE ?
>>> 
>>> B.
>>> 
>>> 
>>> 
>>>> On Mar 21, 2018, at 11:44 AM, Stefano Sofia
>>> <stefano.sofia at regione.marche.it> wrote:
>>>> 
>>>> Dear list users,
>>>> let me ask you this trivial question. I worked on that for a long
>>> time, by now.
>>>> Suppose to have a data frame with NAs and to sum some columns with
>>> rowSums:
>>>> 
>>>> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
>>>> df[1, ] <- NA
>>>> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>>>> 
>>>> If all the elements of the selected columns are NA, rowSums returns 0
>>> while I need NA.
>>>> Is there an easy and efficient way to use rowSums within a function
>>> like
>>>> 
>>>> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>>>> 
>>>> or an equivalent function?
>>>> 
>>>> Thank you for your help
>>>> Stefano
>>>> 
>>>> 
>>>> 
>>>>       (oo)
>>>> --oOO--( )--OOo----------------
>>>> Stefano Sofia PhD
>>>> Area Meteorologica e  Area nivologica - Centro Funzionale
>>>> Servizio Protezione Civile - Regione Marche
>>>> Via del Colle Ameno 5
>>>> 60126 Torrette di Ancona, Ancona
>>>> Uff: 071 806 7743
>>>> E-mail: stefano.sofia at regione.marche.it
>>>> ---Oo---------oO----------------
>>>> 
>>>> ________________________________
>>>> 
>>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>>> contenere informazioni confidenziali, pertanto ? destinato solo a
>>> persone autorizzate alla ricezione. I messaggi di posta elettronica per
>>> i client di Regione Marche possono contenere informazioni confidenziali
>>> e con privilegi legali. Se non si ? il destinatario specificato, non
>>> leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>>> ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>>> eliminarlo completamente dal sistema del proprio computer. Ai sensi
>>> dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>>> ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>>> essere visionata da persone estranee al destinatario.
>>>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>>> by persons entitled to receive the confidential information it may
>>> contain. E-mail messages to clients of Regione Marche may contain
>>> information that is confidential and legally privileged. Please do not
>>> read, copy, forward, or store this message unless you are an intended
>>> recipient of it. If you have received this message in error, please
>>> forward it to the sender and delete it completely from your computer
>>> system.
>>>> 
>>>> --
>>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>>> infetto.
>>>> This message was scanned by Libra ESVA and is believed to be clean.
>>>> 
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From boris.steipe at utoronto.ca  Wed Mar 21 18:26:40 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Wed, 21 Mar 2018 13:26:40 -0400
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <904D1306-9E88-4245-9118-79153F5ABD56@gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
 <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
 <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
 <A8A62A70-BA00-48F5-BF3E-EA8A01B72E28@utoronto.ca>
 <904D1306-9E88-4245-9118-79153F5ABD56@gmail.com>
Message-ID: <A3BFC84A-B572-47E6-B485-CAD2291AEBDB@utoronto.ca>

I see: consistency with additive identity. That makes sense. Thanks.

B.


> On Mar 21, 2018, at 1:22 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> No. The empty sum is zero. Adding it to another sum should not change it. Nothing audacious about that. This is consistent; other definitions just cause trouble.
> 
> -pd
> 
>> On 21 Mar 2018, at 18:05 , Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> 
>> Surely the result of summation of non-existent values is not defined, is it not? And since the NA values have been _removed_, there's nothing left to sum over. In fact, pretending the the result in that case is zero would appear audacious, no?
>> 
>> Cheers,
>> Boris 
>> 
>> 
>> 
>> 
>> 
>>> On Mar 21, 2018, at 12:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>> 
>>> What do you mean by "should not"?
>>> 
>>> NULL means "missing object" in R. The result of the sum function is always expected to be numeric... so NA_real or NA_integer could make sense as possible return values. But you cannot compute on NULL so no, that doesn't work. 
>>> 
>>> See the note under the "Value" section of ?sum as to why zero is returned when all inputs are removed.
>>> -- 
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On March 21, 2018 9:03:29 AM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>> Should not the result be NULL if you have removed the NA with
>>>> na.rm=TRUE ?
>>>> 
>>>> B.
>>>> 
>>>> 
>>>> 
>>>>> On Mar 21, 2018, at 11:44 AM, Stefano Sofia
>>>> <stefano.sofia at regione.marche.it> wrote:
>>>>> 
>>>>> Dear list users,
>>>>> let me ask you this trivial question. I worked on that for a long
>>>> time, by now.
>>>>> Suppose to have a data frame with NAs and to sum some columns with
>>>> rowSums:
>>>>> 
>>>>> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
>>>>> df[1, ] <- NA
>>>>> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>>>>> 
>>>>> If all the elements of the selected columns are NA, rowSums returns 0
>>>> while I need NA.
>>>>> Is there an easy and efficient way to use rowSums within a function
>>>> like
>>>>> 
>>>>> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>>>>> 
>>>>> or an equivalent function?
>>>>> 
>>>>> Thank you for your help
>>>>> Stefano
>>>>> 
>>>>> 
>>>>> 
>>>>>      (oo)
>>>>> --oOO--( )--OOo----------------
>>>>> Stefano Sofia PhD
>>>>> Area Meteorologica e  Area nivologica - Centro Funzionale
>>>>> Servizio Protezione Civile - Regione Marche
>>>>> Via del Colle Ameno 5
>>>>> 60126 Torrette di Ancona, Ancona
>>>>> Uff: 071 806 7743
>>>>> E-mail: stefano.sofia at regione.marche.it
>>>>> ---Oo---------oO----------------
>>>>> 
>>>>> ________________________________
>>>>> 
>>>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>>>> contenere informazioni confidenziali, pertanto ? destinato solo a
>>>> persone autorizzate alla ricezione. I messaggi di posta elettronica per
>>>> i client di Regione Marche possono contenere informazioni confidenziali
>>>> e con privilegi legali. Se non si ? il destinatario specificato, non
>>>> leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>>>> ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>>>> eliminarlo completamente dal sistema del proprio computer. Ai sensi
>>>> dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>>>> ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>>>> essere visionata da persone estranee al destinatario.
>>>>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>>>> by persons entitled to receive the confidential information it may
>>>> contain. E-mail messages to clients of Regione Marche may contain
>>>> information that is confidential and legally privileged. Please do not
>>>> read, copy, forward, or store this message unless you are an intended
>>>> recipient of it. If you have received this message in error, please
>>>> forward it to the sender and delete it completely from your computer
>>>> system.
>>>>> 
>>>>> --
>>>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>>>> infetto.
>>>>> This message was scanned by Libra ESVA and is believed to be clean.
>>>>> 
>>>>> 
>>>>> 	[[alternative HTML version deleted]]
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 
> 


From wdunlap at tibco.com  Wed Mar 21 18:43:38 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 21 Mar 2018 10:43:38 -0700
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
Message-ID: <CAF8bMcZebpqq8Uh7yfVO82js7xmP7H9sHBKWzTQ2_d9WtsMyFg@mail.gmail.com>

Use rowSums(is.na(d))==ncol(d) to pick out the rows will no good values.
E.g.,

> d <- data.frame(x1=c(NA,2:4), x2=c(NA,NA,13:14), x3=c(NA,NA,NA,44))
> d
  x1 x2 x3
1 NA NA NA
2  2 NA NA
3  3 13 NA
4  4 14 44
> s <- rowSums(d, na.rm=TRUE)
> s
[1]  0  2 16 62
> s[ rowSums(is.na(d))==ncol(d) ] <- NA
> s
[1] NA  2 16 62


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, Mar 21, 2018 at 8:44 AM, Stefano Sofia <
stefano.sofia at regione.marche.it> wrote:

> Dear list users,
> let me ask you this trivial question. I worked on that for a long time, by
> now.
> Suppose to have a data frame with NAs and to sum some columns with rowSums:
>
> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
> df[1, ] <- NA
> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>
> If all the elements of the selected columns are NA, rowSums returns 0
> while I need NA.
> Is there an easy and efficient way to use rowSums within a function like
>
> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>
> or an equivalent function?
>
> Thank you for your help
> Stefano
>
>
>
>          (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere
> informazioni confidenziali, pertanto ? destinato solo a persone autorizzate
> alla ricezione. I messaggi di posta elettronica per i client di Regione
> Marche possono contenere informazioni confidenziali e con privilegi legali.
> Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o
> archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore,
> inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio
> computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in
> caso di necessit? ed urgenza, la risposta al presente messaggio di posta
> elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by
> persons entitled to receive the confidential information it may contain.
> E-mail messages to clients of Regione Marche may contain information that
> is confidential and legally privileged. Please do not read, copy, forward,
> or store this message unless you are an intended recipient of it. If you
> have received this message in error, please forward it to the sender and
> delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Wed Mar 21 18:57:27 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 21 Mar 2018 10:57:27 -0700
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
 <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
 <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
Message-ID: <C86D0DCC-7219-40F0-B2DF-50FD4D8DB0B4@comcast.net>


> On Mar 21, 2018, at 9:58 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> What do you mean by "should not"?
> 
> NULL means "missing object" in R. The result of the sum function is always expected to be numeric... so NA_real or NA_integer could make sense as possible return values. But you cannot compute on NULL so no, that doesn't work. 
> 
> See the note under the "Value" section of ?sum as to why zero is returned when all inputs are removed.

But your perspective above that sentence is at odds with the note in the Details section of the same document:

> sum(NULL)
[1] 0
> ?sum
starting httpd help server ... done
> sum( integer(0) )
[1] 0

Best;
David

> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 21, 2018 9:03:29 AM PDT, Boris Steipe <boris.steipe at utoronto.ca> wrote:
>> Should not the result be NULL if you have removed the NA with
>> na.rm=TRUE ?
>> 
>> B.
>> 
>> 
>> 
>>> On Mar 21, 2018, at 11:44 AM, Stefano Sofia
>> <stefano.sofia at regione.marche.it> wrote:
>>> 
>>> Dear list users,
>>> let me ask you this trivial question. I worked on that for a long
>> time, by now.
>>> Suppose to have a data frame with NAs and to sum some columns with
>> rowSums:
>>> 
>>> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
>>> df[1, ] <- NA
>>> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>>> 
>>> If all the elements of the selected columns are NA, rowSums returns 0
>> while I need NA.
>>> Is there an easy and efficient way to use rowSums within a function
>> like
>>> 
>>> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>>> 
>>> or an equivalent function?
>>> 
>>> Thank you for your help
>>> Stefano
>>> 
>>> 
>>> 
>>>        (oo)
>>> --oOO--( )--OOo----------------
>>> Stefano Sofia PhD
>>> Area Meteorologica e  Area nivologica - Centro Funzionale
>>> Servizio Protezione Civile - Regione Marche
>>> Via del Colle Ameno 5
>>> 60126 Torrette di Ancona, Ancona
>>> Uff: 071 806 7743
>>> E-mail: stefano.sofia at regione.marche.it
>>> ---Oo---------oO----------------
>>> 
>>> ________________________________
>>> 
>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>> contenere informazioni confidenziali, pertanto ? destinato solo a
>> persone autorizzate alla ricezione. I messaggi di posta elettronica per
>> i client di Regione Marche possono contenere informazioni confidenziali
>> e con privilegi legali. Se non si ? il destinatario specificato, non
>> leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
>> ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>> eliminarlo completamente dal sistema del proprio computer. Ai sensi
>> dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit?
>> ed urgenza, la risposta al presente messaggio di posta elettronica pu?
>> essere visionata da persone estranee al destinatario.
>>> IMPORTANT NOTICE: This e-mail message is intended to be received only
>> by persons entitled to receive the confidential information it may
>> contain. E-mail messages to clients of Regione Marche may contain
>> information that is confidential and legally privileged. Please do not
>> read, copy, forward, or store this message unless you are an intended
>> recipient of it. If you have received this message in error, please
>> forward it to the sender and delete it completely from your computer
>> system.
>>> 
>>> --
>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
>> infetto.
>>> This message was scanned by Libra ESVA and is believed to be clean.
>>> 
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From kydaviddoyle at gmail.com  Wed Mar 21 20:52:00 2018
From: kydaviddoyle at gmail.com (David Doyle)
Date: Wed, 21 Mar 2018 14:52:00 -0500
Subject: [R] Plotting Notched Box Plots Log Scale - Losing bottom portion of
 box plot
Message-ID: <CACftpvon7uweAwiKiDJRMz1AjFfE+-ZpV-JMCyDixL1mq6yHWg@mail.gmail.com>

Hello,

I'm using the code below to generate some notched box plots.  The issue is
whenever I use log scale, the sides of the bottom part of the box plots
don't plot.  I've tried it in RStudio Ver 1.1.419 and R version 3.4.3 and I
get the same result.

The code and link to my data is below.

Thank you for your time
David



MyData <- read.table("http://doylesdartden.com/ExampleIron.CSV",
header=TRUE, sep=",")

MyDataIronx <- c("Location", "Iron")

MyDataIron <- MyData[MyDataIronx]

plot(MyDataIron, notch=TRUE,log = "y",ylim=c(0.01, 100))

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Mar 21 21:06:46 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Mar 2018 13:06:46 -0700
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <A3BFC84A-B572-47E6-B485-CAD2291AEBDB@utoronto.ca>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
 <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
 <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
 <A8A62A70-BA00-48F5-BF3E-EA8A01B72E28@utoronto.ca>
 <904D1306-9E88-4245-9118-79153F5ABD56@gmail.com>
 <A3BFC84A-B572-47E6-B485-CAD2291AEBDB@utoronto.ca>
Message-ID: <CAGxFJbSB745UwhHa8BFdsSq2=VvH=JJrev8g2CXNbazSU7Msbw@mail.gmail.com>

"I see: consistency with additive identity. "

Ummm, well:

> 1+NULL
numeric(0)

> sum(1,NULL)
[1] 1

Of course, there could well be something here I don't get, but that doesn't
look very consistent to me. However, as I said privately, so long as the
corner case behavior is documented, which it is, I don't care.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 21, 2018 at 10:26 AM, Boris Steipe <boris.steipe at utoronto.ca>
wrote:

> I see: consistency with additive identity. That makes sense. Thanks.
>
> B.
>
>
> > On Mar 21, 2018, at 1:22 PM, peter dalgaard <pdalgd at gmail.com> wrote:
> >
> > No. The empty sum is zero. Adding it to another sum should not change
> it. Nothing audacious about that. This is consistent; other definitions
> just cause trouble.
> >
> > -pd
> >
> >> On 21 Mar 2018, at 18:05 , Boris Steipe <boris.steipe at utoronto.ca>
> wrote:
> >>
> >> Surely the result of summation of non-existent values is not defined,
> is it not? And since the NA values have been _removed_, there's nothing
> left to sum over. In fact, pretending the the result in that case is zero
> would appear audacious, no?
> >>
> >> Cheers,
> >> Boris
> >>
> >>
> >>
> >>
> >>
> >>> On Mar 21, 2018, at 12:58 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> wrote:
> >>>
> >>> What do you mean by "should not"?
> >>>
> >>> NULL means "missing object" in R. The result of the sum function is
> always expected to be numeric... so NA_real or NA_integer could make sense
> as possible return values. But you cannot compute on NULL so no, that
> doesn't work.
> >>>
> >>> See the note under the "Value" section of ?sum as to why zero is
> returned when all inputs are removed.
> >>> --
> >>> Sent from my phone. Please excuse my brevity.
> >>>
> >>> On March 21, 2018 9:03:29 AM PDT, Boris Steipe <
> boris.steipe at utoronto.ca> wrote:
> >>>> Should not the result be NULL if you have removed the NA with
> >>>> na.rm=TRUE ?
> >>>>
> >>>> B.
> >>>>
> >>>>
> >>>>
> >>>>> On Mar 21, 2018, at 11:44 AM, Stefano Sofia
> >>>> <stefano.sofia at regione.marche.it> wrote:
> >>>>>
> >>>>> Dear list users,
> >>>>> let me ask you this trivial question. I worked on that for a long
> >>>> time, by now.
> >>>>> Suppose to have a data frame with NAs and to sum some columns with
> >>>> rowSums:
> >>>>>
> >>>>> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
> >>>>> df[1, ] <- NA
> >>>>> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
> >>>>>
> >>>>> If all the elements of the selected columns are NA, rowSums returns 0
> >>>> while I need NA.
> >>>>> Is there an easy and efficient way to use rowSums within a function
> >>>> like
> >>>>>
> >>>>> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
> >>>>>
> >>>>> or an equivalent function?
> >>>>>
> >>>>> Thank you for your help
> >>>>> Stefano
> >>>>>
> >>>>>
> >>>>>
> >>>>>      (oo)
> >>>>> --oOO--( )--OOo----------------
> >>>>> Stefano Sofia PhD
> >>>>> Area Meteorologica e  Area nivologica - Centro Funzionale
> >>>>> Servizio Protezione Civile - Regione Marche
> >>>>> Via del Colle Ameno 5
> >>>>> 60126 Torrette di Ancona, Ancona
> >>>>> Uff: 071 806 7743
> >>>>> E-mail: stefano.sofia at regione.marche.it
> >>>>> ---Oo---------oO----------------
> >>>>>
> >>>>> ________________________________
> >>>>>
> >>>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
> >>>> contenere informazioni confidenziali, pertanto ? destinato solo a
> >>>> persone autorizzate alla ricezione. I messaggi di posta elettronica
> per
> >>>> i client di Regione Marche possono contenere informazioni
> confidenziali
> >>>> e con privilegi legali. Se non si ? il destinatario specificato, non
> >>>> leggere, copiare, inoltrare o archiviare questo messaggio. Se si ?
> >>>> ricevuto questo messaggio per errore, inoltrarlo al mittente ed
> >>>> eliminarlo completamente dal sistema del proprio computer. Ai sensi
> >>>> dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di
> necessit?
> >>>> ed urgenza, la risposta al presente messaggio di posta elettronica pu?
> >>>> essere visionata da persone estranee al destinatario.
> >>>>> IMPORTANT NOTICE: This e-mail message is intended to be received only
> >>>> by persons entitled to receive the confidential information it may
> >>>> contain. E-mail messages to clients of Regione Marche may contain
> >>>> information that is confidential and legally privileged. Please do not
> >>>> read, copy, forward, or store this message unless you are an intended
> >>>> recipient of it. If you have received this message in error, please
> >>>> forward it to the sender and delete it completely from your computer
> >>>> system.
> >>>>>
> >>>>> --
> >>>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non
> >>>> infetto.
> >>>>> This message was scanned by Libra ESVA and is believed to be clean.
> >>>>>
> >>>>>
> >>>>>   [[alternative HTML version deleted]]
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > --
> > Peter Dalgaard, Professor,
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Office: A 4.23
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> >
> >
> >
> >
> >
> >
> >
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Stephen.Bond at cibc.com  Wed Mar 21 21:25:02 2018
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Wed, 21 Mar 2018 20:25:02 +0000
Subject: [R] how to add a child to a child in XML
Message-ID: <624EC9773CAB044ABA65327271BED9B62189EF4E@CBMCC-X10-MB06.ad.cibc.com>

I am trying to add a child to a child using XML package in R. the following fails

library(XML)

node1 <- c("val1","val2","val3")

names(node1) <- c("att1","att2","att3")

root <- xmlNode("root", attrs=node1)

node2 <- LETTERS[1:3]

names(node2) <- paste("name",1:3,sep="")

root <- addChildren(root,xmlNode("child1",attrs=node2))

node3 <- letters[1:3]

names(node3) <- paste("name",4:6,sep="")

root <- addChildren(root$child1,xmlNode("child2",attrs=node3))



Error in UseMethod("addChildren") : no applicable method for 'addChildren' applied to an object of class "NULL"


Stephen B


	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Wed Mar 21 21:48:31 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 21 Mar 2018 13:48:31 -0700
Subject: [R] 
 Plotting Notched Box Plots Log Scale - Losing bottom portion of
 box plot
In-Reply-To: <CACftpvon7uweAwiKiDJRMz1AjFfE+-ZpV-JMCyDixL1mq6yHWg@mail.gmail.com>
References: <CACftpvon7uweAwiKiDJRMz1AjFfE+-ZpV-JMCyDixL1mq6yHWg@mail.gmail.com>
Message-ID: <CAGxFJbTA+zDFWRSxgc4yWqgZtk56kPZTd045_0OvGrOKGVMeeA@mail.gmail.com>

Note that:

> plot(Iron~Location,data=MyDataIron,log="y",notch=FALSE)
> plot(10+Iron~Location,data=MyDataIron,log="y",notch=TRUE)
Warning message:
In bxp(list(stats = c(10.66, 13.9, 24.9, 39, 60, 10.05, 10.07515,  :
  some notches went outside hinges ('box'): maybe set notch=FALSE

## Both work, but:

> plot(Iron~Location,data=MyDataIron,log="y",notch=TRUE)
Error in plot.window(xlim = xlim, ylim = ylim, log = log, yaxs = pars$yaxs)
:
  Logarithmic axis must have positive limits

So the problem is some of your notches want to extend to negative values.
Limiting the y range can't help: the notches can't be plotted on a log
scale.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Mar 21, 2018 at 12:52 PM, David Doyle <kydaviddoyle at gmail.com>
wrote:

> Hello,
>
> I'm using the code below to generate some notched box plots.  The issue is
> whenever I use log scale, the sides of the bottom part of the box plots
> don't plot.  I've tried it in RStudio Ver 1.1.419 and R version 3.4.3 and I
> get the same result.
>
> The code and link to my data is below.
>
> Thank you for your time
> David
>
>
>
> MyData <- read.table("http://doylesdartden.com/ExampleIron.CSV",
> header=TRUE, sep=",")
>
> MyDataIronx <- c("Location", "Iron")
>
> MyDataIron <- MyData[MyDataIronx]
>
> plot(MyDataIron, notch=TRUE,log = "y",ylim=c(0.01, 100))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From marc_grt at yahoo.fr  Wed Mar 21 22:10:35 2018
From: marc_grt at yahoo.fr (Marc Girondot)
Date: Wed, 21 Mar 2018 22:10:35 +0100
Subject: [R] R 3.4.4, internet access fails on Windows XP
In-Reply-To: <cd2faf0a-f9ea-1f3d-17ce-b1fc854a6d0e@gmail.com>
References: <20180321132709.E224.C7C4B6F9@mpibpc.mpg.de>
 <cd2faf0a-f9ea-1f3d-17ce-b1fc854a6d0e@gmail.com>
Message-ID: <2833a3b6-ce0d-0d89-17e7-db11641cc1bf@yahoo.fr>

To solve similar problem, I just install Lubuntu 17.10 on an old PC 
(i686) and I am astonished by the reactivity of the computer... it has a 
second life.
The main problem is that Rstudio Desktop 32 bits is no more supported 
for Ubuntu 32bits computers but the solution using Rstudio Server 32 
bits works very well.
Marc


Le 21/03/2018 ? 16:58, Duncan Murdoch a ?crit?:
> On 21/03/2018 8:27 AM, Holger Taschenberger wrote:
>> I can install and run R 3.4.4 on Windows XP (32bit). However, calling 
>> "Update Packages..." or "Html help" from the RGui.exe main menu fails 
>> with a Windows MessageBox saying:
>>
>> "The procedure entry point IdnToAscii could not be located in the 
>> dynamic link library KERNEL32.dll"
>>
>> and the following text printed to the RGui console window:
>>
>> "...
>> In addition: Warning message:
>> In download.file(url, destfile = f, quiet = TRUE) :
>> ?? unable to load shared object 
>> 'C:/R/R-3.4.4/modules/i386/internet.dll':
>> ?? LoadLibrary failure:? The specified procedure could not be found."
>>
>> "IdnToAscii" is exported from "C:\WINDOWS\system32\normaliz.dll" on 
>> Windows XP. But apparently RGui cannot locate this procedure on 
>> Windows XP.
>>
>> Any advice? (except for "switch to a more recent windows version")
>
>
> The Windows FAQ 2.2 says, "Windows XP is no longer supported", so I 
> think you're out of luck.? XP went past "end-of-life" in 2014.
>
> Other than switching to a more recent Windows version, your choices 
> are switching to a completely different OS, or switching to an older 
> version of R.
>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From btupper at bigelow.org  Wed Mar 21 23:17:51 2018
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 21 Mar 2018 18:17:51 -0400
Subject: [R] how to add a child to a child in XML
In-Reply-To: <624EC9773CAB044ABA65327271BED9B62189EF4E@CBMCC-X10-MB06.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B62189EF4E@CBMCC-X10-MB06.ad.cibc.com>
Message-ID: <6A5229DA-F319-4BD9-9A71-28D3D93B5637@bigelow.org>

Hi,

XML doesn't use the `$` to access child nodes.  Instead use either `[name]` to get a list of children of that name or `[[name]]` to get the just the first child of that name encountered in the genealogy.  Thus for your example...

> root$child1
NULL

> root[['child1']]
<child1 name1="A" name2="B" name3="C"/>


On the other hand, you might consider using newXMLNode() instead of xmlNode() as it accepts a "parent = " argument.  The alternative using newXMLNode() would look like...

atts_root <- c("val1","val2","val3")
names(atts_root) <- c("att1","att2","att3")
root <- newXMLNode("root", attrs = atts_root)

atts_child <- LETTERS[1:3]
names(atts_child) <- paste("name",1:3,sep="")
child <- newXMLNode("child",attrs = atts_child, parent = root)

atts_grandchild <- letters[1:3]
names(atts_grandchild) <- paste("name",4:6,sep="")
grandchild <- newXMLNode("grandchild",attrs = atts_grandchild, parent = child)

root
#<root att1="val1" att2="val2" att3="val3">
#  <child name1="A" name2="B" name3="C">
#    <grandchild name4="a" name5="b" name6="c"/>
#  </child>
#</root> 


Cheers,
Ben
 
> On Mar 21, 2018, at 4:25 PM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> 
> I am trying to add a child to a child using XML package in R. the following fails
> 
> library(XML)
> 
> node1 <- c("val1","val2","val3")
> 
> names(node1) <- c("att1","att2","att3")
> 
> root <- xmlNode("root", attrs=node1)
> 
> node2 <- LETTERS[1:3]
> 
> names(node2) <- paste("name",1:3,sep="")
> 
> root <- addChildren(root,xmlNode("child1",attrs=node2))
> 
> node3 <- letters[1:3]
> 
> names(node3) <- paste("name",4:6,sep="")
> 
> root <- addChildren(root$child1,xmlNode("child2",attrs=node3))
> 
> 
> 
> Error in UseMethod("addChildren") : no applicable method for 'addChildren' applied to an object of class "NULL"
> 
> 
> Stephen B
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/





	[[alternative HTML version deleted]]


From sasha_1891 at hotmail.com  Thu Mar 22 08:46:54 2018
From: sasha_1891 at hotmail.com (rosario scandurra)
Date: Thu, 22 Mar 2018 07:46:54 +0000
Subject: [R] exporting data to stata
Message-ID: <HE1PR0902MB1979C6E9695F60BE655DE244F9A90@HE1PR0902MB1979.eurprd09.prod.outlook.com>

Hi,

I am new to R and I want to export data into Stata. Could somebody help with that? Thanks a lot.

This is the code I am using:


> setwd("D:/datasets/Seg-bcn/ESBD")
> data1 <- readRDS("r17045_ESDB_Habitatges_BDD_V_1_0.rds")
> library(foreign)
> write.dta(data="data1", file = "D:/datasets/data1.dta")
Error in write.dta(data = "data1", file = "D:/datasets/data1.dta") :
  The object "dataframe" must have class data.frame
> class (data1)
[1] "survey.design2" "survey.design"


	[[alternative HTML version deleted]]


From amalraj.raja at abdn.ac.uk  Thu Mar 22 09:52:52 2018
From: amalraj.raja at abdn.ac.uk (Raja, Dr. Edwin Amalraj)
Date: Thu, 22 Mar 2018 08:52:52 +0000
Subject: [R] exporting data to stata
In-Reply-To: <HE1PR0902MB1979C6E9695F60BE655DE244F9A90@HE1PR0902MB1979.eurprd09.prod.outlook.com>
References: <HE1PR0902MB1979C6E9695F60BE655DE244F9A90@HE1PR0902MB1979.eurprd09.prod.outlook.com>
Message-ID: <VI1PR0402MB382227B3B5876AF7C9D39C69A1A90@VI1PR0402MB3822.eurprd04.prod.outlook.com>

Hi ,

library(foreign)
write.dta(data1,  "data1.dta")

should work. The file will be saved in the working directory.
Use
getwd()
to know the working directory.

Best wishes
Amalraj Raja

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of rosario scandurra
Sent: 22 March 2018 07:47
To: r-help at r-project.org
Subject: [R] exporting data to stata

Hi,

I am new to R and I want to export data into Stata. Could somebody help with that? Thanks a lot.

This is the code I am using:


> setwd("D:/datasets/Seg-bcn/ESBD")
> data1 <- readRDS("r17045_ESDB_Habitatges_BDD_V_1_0.rds")
> library(foreign)
> write.dta(data="data1", file = "D:/datasets/data1.dta")
Error in write.dta(data = "data1", file = "D:/datasets/data1.dta") :
  The object "dataframe" must have class data.frame
> class (data1)
[1] "survey.design2" "survey.design"


[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

From murdoch.duncan at gmail.com  Thu Mar 22 10:49:47 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 22 Mar 2018 05:49:47 -0400
Subject: [R] R 3.4.4, internet access fails on Windows XP
In-Reply-To: <20180322102848.308D.C7C4B6F9@mpibpc.mpg.de>
References: <20180321132709.E224.C7C4B6F9@mpibpc.mpg.de>
 <cd2faf0a-f9ea-1f3d-17ce-b1fc854a6d0e@gmail.com>
 <20180322102848.308D.C7C4B6F9@mpibpc.mpg.de>
Message-ID: <ef696cd8-6755-cffe-9ada-ad305c63914f@gmail.com>

On 22/03/2018 5:28 AM, Holger Taschenberger wrote:
> Dear Duncan,
> 
>          thank you for your reply.
> 
> On Wed, 21 Mar 2018 11:58:15 -0400
> Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>   
>> The Windows FAQ 2.2 says, "Windows XP is no longer supported", so I think you're out of luck.  XP went past "end-of-life" in 2014.
>>
> 
> on <https://cran.r-project.org/bin/windows/base/README.R-3.4.4> it says
> 
> "R 3.4.4 for Windows
> ===================
> 
> This distribution contains a binary distribution of R-3.4.4 to run on
> Windows XP and later (including 64-bit versions of Windows) on ix86
> and x86_64 chips."

Looks as though that file wasn't updated when the FAQ was.  I am the one 
responsible for that omission, but I can't fix it now, as I retired from 
the core team last year.  The file to fix is src/gnuwin32/CRAN/ReadMe.in.

> 
>> Other than switching to a more recent Windows version, your choices are switching to a completely different OS, or switching to an older version of R.
> 
> R i386 runs without problems on Windows XP up to and including version 3.4.2.
> Only R i386 3.4.3 & R i386 3.4.4 cannot access the internet on my Windows XP.
> I supposed this is not so much a problem with the OS (because "IdnToAscii" exists on WindowsXP SP3 as well), but rather with the header files and/or import libraries of the MinGW environment
> 
> Perhaps it does not take too much effort to restore WindowsXP compatibility. The described symptoms are at least easy to debug.
> 
> I know that WindowsXP is no longer supported by Microsoft. However, I work in an academic environment and we are stuck to Windows XP on some computers because some of our data acquisition devices are only properly supported on that OS.

In that case, I'd recommend leaving R 3.4.2 on those old machines, and 
doing your main work on different ones.

> Regardless of your conclusion, I'm thankful to the R developer team to make the R software freely available to the scientific community.


Duncan Murdoch


From stefano.sofia at regione.marche.it  Thu Mar 22 11:01:05 2018
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Thu, 22 Mar 2018 10:01:05 +0000
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <63d60102-c80b-2423-b586-fbae033f2225@gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>,
 <63d60102-c80b-2423-b586-fbae033f2225@gmail.com>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F54C79272@ESINO.regionemarche.intra>

Thank you.
Perfect solution.

Stefano

         (oo)
--oOO--( )--OOo----------------
Stefano Sofia PhD
Area Meteorologica e  Area nivologica - Centro Funzionale
Servizio Protezione Civile - Regione Marche
Via del Colle Ameno 5
60126 Torrette di Ancona, Ancona
Uff: 071 806 7743
E-mail: stefano.sofia at regione.marche.it
---Oo---------oO----------------
________________________________________
Da: Duncan Murdoch [murdoch.duncan at gmail.com]
Inviato: mercoled? 21 marzo 2018 17.01
A: Stefano Sofia; r-help at r-project.org
Oggetto: Re: [R] Sum of columns of a data frame equal to NA when all the elements are NA

On 21/03/2018 11:44 AM, Stefano Sofia wrote:
> Dear list users,
> let me ask you this trivial question. I worked on that for a long time, by now.
> Suppose to have a data frame with NAs and to sum some columns with rowSums:
>
> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
> df[1, ] <- NA
> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>
> If all the elements of the selected columns are NA, rowSums returns 0 while I need NA.
> Is there an easy and efficient way to use rowSums within a function like
>
> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>
> or an equivalent function?

Something like

apply(df[,c("A", "B")], 1, function(x) if (all(is.na(x))) NA else sum(x,
na.rm = TRUE))

should do what you want.

Duncan Murdoch

>
> Thank you for your help
> Stefano
>
>
>
>           (oo)
> --oOO--( )--OOo----------------
> Stefano Sofia PhD
> Area Meteorologica e  Area nivologica - Centro Funzionale
> Servizio Protezione Civile - Regione Marche
> Via del Colle Ameno 5
> 60126 Torrette di Ancona, Ancona
> Uff: 071 806 7743
> E-mail: stefano.sofia at regione.marche.it
> ---Oo---------oO----------------
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> --
> Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
> This message was scanned by Libra ESVA and is believed to be clean.
>
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>  https://urlsand.esvalabs.com/?u=https%3A%2F%2Fstat.ethz.ch%2Fmailman%2Flistinfo%2Fr-help&e=52342f8a&h=d46bc785&f=y&p=y
> PLEASE do read the posting guide  https://urlsand.esvalabs.com/?u=http%3A%2F%2Fwww.R-project.org%2Fposting-guide.html&e=52342f8a&h=9b25bfd5&f=y&p=y
> and provide commented, minimal, self-contained, reproducible code.
>


--

Questo messaggio  stato analizzato con Libra ESVA ed  risultato non infetto.


________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

--
Questo messaggio  stato analizzato da Libra ESVA ed  risultato non infetto.
This message was scanned by Libra ESVA and is believed to be clean.


From Holger.Taschenberger at mpibpc.mpg.de  Thu Mar 22 10:28:48 2018
From: Holger.Taschenberger at mpibpc.mpg.de (Holger Taschenberger)
Date: Thu, 22 Mar 2018 10:28:48 +0100
Subject: [R] R 3.4.4, internet access fails on Windows XP
In-Reply-To: <cd2faf0a-f9ea-1f3d-17ce-b1fc854a6d0e@gmail.com>
References: <20180321132709.E224.C7C4B6F9@mpibpc.mpg.de>
 <cd2faf0a-f9ea-1f3d-17ce-b1fc854a6d0e@gmail.com>
Message-ID: <20180322102848.308D.C7C4B6F9@mpibpc.mpg.de>

Dear Duncan,

        thank you for your reply.

On Wed, 21 Mar 2018 11:58:15 -0400
Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

 
> The Windows FAQ 2.2 says, "Windows XP is no longer supported", so I think you're out of luck.  XP went past "end-of-life" in 2014.
> 

on <https://cran.r-project.org/bin/windows/base/README.R-3.4.4> it says

"R 3.4.4 for Windows
===================

This distribution contains a binary distribution of R-3.4.4 to run on
Windows XP and later (including 64-bit versions of Windows) on ix86
and x86_64 chips."

> Other than switching to a more recent Windows version, your choices are switching to a completely different OS, or switching to an older version of R.

R i386 runs without problems on Windows XP up to and including version 3.4.2.
Only R i386 3.4.3 & R i386 3.4.4 cannot access the internet on my Windows XP.

I supposed this is not so much a problem with the OS (because "IdnToAscii" exists on WindowsXP SP3 as well), but rather with the header files and/or import libraries of the MinGW environment.

Perhaps it does not take too much effort to restore WindowsXP compatibility. The described symptoms are at least easy to debug.

I know that WindowsXP is no longer supported by Microsoft. However, I work in an academic environment and we are stuck to Windows XP on some computers because some of our data acquisition devices are only properly supported on that OS.

Regardless of your conclusion, I'm thankful to the R developer team to make the R software freely available to the scientific community.

With kind regards,
        Holger


From lists at dewey.myzen.co.uk  Thu Mar 22 13:12:02 2018
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 22 Mar 2018 12:12:02 +0000
Subject: [R] exporting data to stata
In-Reply-To: <HE1PR0902MB1979C6E9695F60BE655DE244F9A90@HE1PR0902MB1979.eurprd09.prod.outlook.com>
References: <HE1PR0902MB1979C6E9695F60BE655DE244F9A90@HE1PR0902MB1979.eurprd09.prod.outlook.com>
Message-ID: <68cf46f8-e877-abd4-f420-fabc7b3bcced@dewey.myzen.co.uk>

Dear Rosario

Your object called data1 is, as you showed us, of the wrong class. You 
therefore need to convert it in some way although i suspect you will 
then use the survey information.

Michael.

On 22/03/2018 07:46, rosario scandurra wrote:
> Hi,
> 
> I am new to R and I want to export data into Stata. Could somebody help with that? Thanks a lot.
> 
> This is the code I am using:
> 
> 
>> setwd("D:/datasets/Seg-bcn/ESBD")
>> data1 <- readRDS("r17045_ESDB_Habitatges_BDD_V_1_0.rds")
>> library(foreign)
>> write.dta(data="data1", file = "D:/datasets/data1.dta")
> Error in write.dta(data = "data1", file = "D:/datasets/data1.dta") :
>    The object "dataframe" must have class data.frame
>> class (data1)
> [1] "survey.design2" "survey.design"
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From istazahn at gmail.com  Thu Mar 22 13:32:48 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Thu, 22 Mar 2018 08:32:48 -0400
Subject: [R] exporting data to stata
In-Reply-To: <VI1PR0402MB382227B3B5876AF7C9D39C69A1A90@VI1PR0402MB3822.eurprd04.prod.outlook.com>
References: <HE1PR0902MB1979C6E9695F60BE655DE244F9A90@HE1PR0902MB1979.eurprd09.prod.outlook.com>
 <VI1PR0402MB382227B3B5876AF7C9D39C69A1A90@VI1PR0402MB3822.eurprd04.prod.outlook.com>
Message-ID: <CA+vqiLEho5F=BEKS6sAtGyquybYrSNvgctJfphnQtHdN6oTdUw@mail.gmail.com>

On Thu, Mar 22, 2018 at 4:52 AM, Raja, Dr. Edwin Amalraj
<amalraj.raja at abdn.ac.uk> wrote:
> Hi ,
>
> library(foreign)
> write.dta(data1,  "data1.dta")
>
> should work.


I don't think so:

> library(foreign)
> example(svydesign)
> write.dta(dstrat, "~/Downloads/foo.dta")
Error in write.dta(dstrat, "~/Downloads/foo.dta") :
  The object "dataframe" must have class data.frame


The file will be saved in the working directory.
> Use
> getwd()
> to know the working directory.
>
> Best wishes
> Amalraj Raja
>
> -----Original Message-----
> From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of rosario scandurra
> Sent: 22 March 2018 07:47
> To: r-help at r-project.org
> Subject: [R] exporting data to stata
>
> Hi,
>
> I am new to R and I want to export data into Stata. Could somebody help with that? Thanks a lot.
>
> This is the code I am using:
>
>
>> setwd("D:/datasets/Seg-bcn/ESBD")
>> data1 <- readRDS("r17045_ESDB_Habitatges_BDD_V_1_0.rds")
>> library(foreign)
>> write.dta(data="data1", file = "D:/datasets/data1.dta")
> Error in write.dta(data = "data1", file = "D:/datasets/data1.dta") :
>   The object "dataframe" must have class data.frame
>> class (data1)
> [1] "survey.design2" "survey.design"
>
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> The University of Aberdeen is a charity registered in Scotland, No SC013683.
> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ajdamico at gmail.com  Thu Mar 22 13:51:49 2018
From: ajdamico at gmail.com (Anthony Damico)
Date: Thu, 22 Mar 2018 08:51:49 -0400
Subject: [R] exporting data to stata
In-Reply-To: <CA+vqiLEho5F=BEKS6sAtGyquybYrSNvgctJfphnQtHdN6oTdUw@mail.gmail.com>
References: <HE1PR0902MB1979C6E9695F60BE655DE244F9A90@HE1PR0902MB1979.eurprd09.prod.outlook.com>
 <VI1PR0402MB382227B3B5876AF7C9D39C69A1A90@VI1PR0402MB3822.eurprd04.prod.outlook.com>
 <CA+vqiLEho5F=BEKS6sAtGyquybYrSNvgctJfphnQtHdN6oTdUw@mail.gmail.com>
Message-ID: <CAOwvMDzXmSFAc9Sjq6Uh5pQT1YRetqfv_zBezw3PL8UQOxkckg@mail.gmail.com>

hi, you can export the dataset from an R  survey design to stata with

install.packages('survey')
library(survey)
library(foreign)
write.dta( data1$variables , "c:/path/to/file.dta" )

then type "data1" into the R console to look at the weight, id/cluster,
strata, and fpc variables to use for the "svyset" command




On Thu, Mar 22, 2018, 12:33 PM Ista Zahn <istazahn at gmail.com> wrote:

> On Thu, Mar 22, 2018 at 4:52 AM, Raja, Dr. Edwin Amalraj
> <amalraj.raja at abdn.ac.uk> wrote:
> > Hi ,
> >
> > library(foreign)
> > write.dta(data1,  "data1.dta")
> >
> > should work.
>
>
> I don't think so:
>
> > library(foreign)
> > example(svydesign)
> > write.dta(dstrat, "~/Downloads/foo.dta")
> Error in write.dta(dstrat, "~/Downloads/foo.dta") :
>   The object "dataframe" must have class data.frame
>
>
> The file will be saved in the working directory.
> > Use
> > getwd()
> > to know the working directory.
> >
> > Best wishes
> > Amalraj Raja
> >
> > -----Original Message-----
> > From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of rosario
> scandurra
> > Sent: 22 March 2018 07:47
> > To: r-help at r-project.org
> > Subject: [R] exporting data to stata
> >
> > Hi,
> >
> > I am new to R and I want to export data into Stata. Could somebody help
> with that? Thanks a lot.
> >
> > This is the code I am using:
> >
> >
> >> setwd("D:/datasets/Seg-bcn/ESBD")
> >> data1 <- readRDS("r17045_ESDB_Habitatges_BDD_V_1_0.rds")
> >> library(foreign)
> >> write.dta(data="data1", file = "D:/datasets/data1.dta")
> > Error in write.dta(data = "data1", file = "D:/datasets/data1.dta") :
> >   The object "dataframe" must have class data.frame
> >> class (data1)
> > [1] "survey.design2" "survey.design"
> >
> >
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> > The University of Aberdeen is a charity registered in Scotland, No
> SC013683.
> > Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir.
> SC013683.
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jsorkin at som.umaryland.edu  Thu Mar 22 13:59:44 2018
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Thu, 22 Mar 2018 12:59:44 +0000
Subject: [R] How do I include a factor in a groupedData object? Meaning and
 use of inner and outer parameters
Message-ID: <BN6PR03MB27053EC3196E438E560BC5A2E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>

Windows 10 64-bit, R-Studio, R version 3.4.3


Several questions relating to groupedData:

(1) I am trying to create a groupedData object that can be used to run an analysis that I have been able to urn using lmer. When I include the interaction terms in the groupedData opbject I get an error message stating that + is not meaningful for factors. How do I include factors in my model? See code and error below.

(2) I have read the help file for groupedData multiple times. I am unable to understand the meaning or, or the use for the inner= and outer= parameters in the call to groupedData. Can someone either explain the meaning of these parameters or refer me to a source that give a clear explanation?


> fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(TimePtID)+(1|PatientID),data=smalldata)
> sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|PatientID,data=smalldata)
Warning messages:
1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors


Thank you,

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)


	[[alternative HTML version deleted]]


From Stephen.Bond at cibc.com  Thu Mar 22 14:19:35 2018
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Thu, 22 Mar 2018 13:19:35 +0000
Subject: [R] how to add a child to a child in XML
In-Reply-To: <6A5229DA-F319-4BD9-9A71-28D3D93B5637@bigelow.org>
References: <624EC9773CAB044ABA65327271BED9B62189EF4E@CBMCC-X10-MB06.ad.cibc.com>
 <6A5229DA-F319-4BD9-9A71-28D3D93B5637@bigelow.org>
Message-ID: <624EC9773CAB044ABA65327271BED9B62189F412@CBMCC-X10-MB06.ad.cibc.com>

Big thanks. newXMLNode works great. Wonder why it is not included in the documentation.
There is newXMLDoc and newXMLNamespace, but no mention of newXMLNode.

Stephen

From: Ben Tupper [mailto:btupper at bigelow.org]
Sent: Wednesday, March 21, 2018 6:18 PM
To: Bond, Stephen
Cc: r-help
Subject: Re: [R] how to add a child to a child in XML

Hi,

XML doesn't use the `$` to access child nodes.  Instead use either `[name]` to get a list of children of that name or `[[name]]` to get the just the first child of that name encountered in the genealogy.  Thus for your example...

> root$child1
NULL

> root[['child1']]
<child1 name1="A" name2="B" name3="C"/>


On the other hand, you might consider using newXMLNode() instead of xmlNode() as it accepts a "parent = " argument.  The alternative using newXMLNode() would look like...

atts_root <- c("val1","val2","val3")
names(atts_root) <- c("att1","att2","att3")
root <- newXMLNode("root", attrs = atts_root)

atts_child <- LETTERS[1:3]
names(atts_child) <- paste("name",1:3,sep="")
child <- newXMLNode("child",attrs = atts_child, parent = root)

atts_grandchild <- letters[1:3]
names(atts_grandchild) <- paste("name",4:6,sep="")
grandchild <- newXMLNode("grandchild",attrs = atts_grandchild, parent = child)

root
#<root att1="val1" att2="val2" att3="val3">
#  <child name1="A" name2="B" name3="C">
#    <grandchild name4="a" name5="b" name6="c"/>
#  </child>
#</root>


Cheers,
Ben

On Mar 21, 2018, at 4:25 PM, Bond, Stephen <Stephen.Bond at cibc.com<mailto:Stephen.Bond at cibc.com>> wrote:

I am trying to add a child to a child using XML package in R. the following fails

library(XML)

node1 <- c("val1","val2","val3")

names(node1) <- c("att1","att2","att3")

root <- xmlNode("root", attrs=node1)

node2 <- LETTERS[1:3]

names(node2) <- paste("name",1:3,sep="")

root <- addChildren(root,xmlNode("child1",attrs=node2))

node3 <- letters[1:3]

names(node3) <- paste("name",4:6,sep="")

root <- addChildren(root$child1,xmlNode("child2",attrs=node3))



Error in UseMethod("addChildren") : no applicable method for 'addChildren' applied to an object of class "NULL"


Stephen B


            [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/




	[[alternative HTML version deleted]]


From lists at dewey.myzen.co.uk  Thu Mar 22 15:30:16 2018
From: lists at dewey.myzen.co.uk (Michael Dewey)
Date: Thu, 22 Mar 2018 14:30:16 +0000
Subject: [R] 
 How do I include a factor in a groupedData object? Meaning and
 use of inner and outer parameters
In-Reply-To: <BN6PR03MB27053EC3196E438E560BC5A2E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
References: <BN6PR03MB27053EC3196E438E560BC5A2E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
Message-ID: <51049692-9cf4-a05e-4895-0452f9aca63c@dewey.myzen.co.uk>

Dear John

You are only allowed to have the primary covariate on the left hand side 
of the vertical bar. Other covariates go in inner or outer.

Michael

On 22/03/2018 12:59, Sorkin, John wrote:
> Windows 10 64-bit, R-Studio, R version 3.4.3
> 
> 
> Several questions relating to groupedData:
> 
> (1) I am trying to create a groupedData object that can be used to run an analysis that I have been able to urn using lmer. When I include the interaction terms in the groupedData opbject I get an error message stating that + is not meaningful for factors. How do I include factors in my model? See code and error below.
> 
> (2) I have read the help file for groupedData multiple times. I am unable to understand the meaning or, or the use for the inner= and outer= parameters in the call to groupedData. Can someone either explain the meaning of these parameters or refer me to a source that give a clear explanation?
> 
> 
>> fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(TimePtID)+(1|PatientID),data=smalldata)
>> sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|PatientID,data=smalldata)
> Warning messages:
> 1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
> 2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors
> 
> 
> Thank you,
> 
> John
> 
> 
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
> 
> 
> 	[[alternative HTML version deleted]]
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Michael
http://www.dewey.myzen.co.uk/home.html


From btupper at bigelow.org  Thu Mar 22 15:39:32 2018
From: btupper at bigelow.org (Ben Tupper)
Date: Thu, 22 Mar 2018 10:39:32 -0400
Subject: [R] how to add a child to a child in XML
In-Reply-To: <624EC9773CAB044ABA65327271BED9B62189F412@CBMCC-X10-MB06.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B62189EF4E@CBMCC-X10-MB06.ad.cibc.com>
 <6A5229DA-F319-4BD9-9A71-28D3D93B5637@bigelow.org>
 <624EC9773CAB044ABA65327271BED9B62189F412@CBMCC-X10-MB06.ad.cibc.com>
Message-ID: <A4374AEF-0BDB-4839-B319-161469AEB9DB@bigelow.org>

Hi,

It's a reasonable question. The answer is that it actually is included, but there are many instances across packages where multiple functions are documented on a single help page.  The following brings up such a page... (for XML_3.98-1.9)

> library(XML)
> ?newXMLNode

You can see the same on line...

https://www.rdocumentation.org/packages/XML/versions/3.98-1.9/topics/newXMLDoc

You have dig in to find it.  

If you are just starting out with XML, you might want to spend some time comparison shopping with the xml2 package. https://www.rdocumentation.org/packages/xml2/versions/1.2.0 <https://www.rdocumentation.org/packages/xml2/versions/1.2.0>  I like each one, and I use both XML and xml2 (not at the same time). I have been slowly migrating toward xml2 as I use more of the tidyverse stuff.

Cheers,
Ben

> On Mar 22, 2018, at 9:19 AM, Bond, Stephen <Stephen.Bond at cibc.com> wrote:
> 
> Big thanks. newXMLNode works great. Wonder why it is not included in the documentation.
> There is newXMLDoc and newXMLNamespace, but no mention of newXMLNode.
>  
> Stephen
>  
> From: Ben Tupper [mailto:btupper at bigelow.org] 
> Sent: Wednesday, March 21, 2018 6:18 PM
> To: Bond, Stephen
> Cc: r-help
> Subject: Re: [R] how to add a child to a child in XML
>  
> Hi,
>  
> XML doesn't use the `$` to access child nodes.  Instead use either `[name]` to get a list of children of that name or `[[name]]` to get the just the first child of that name encountered in the genealogy.  Thus for your example...
>  
> > root$child1
> NULL
>  
> > root[['child1']]
> <child1 name1="A" name2="B" name3="C"/>
>  
>  
> On the other hand, you might consider using newXMLNode() instead of xmlNode() as it accepts a "parent = " argument.  The alternative using newXMLNode() would look like...
>  
> atts_root <- c("val1","val2","val3")
> names(atts_root) <- c("att1","att2","att3")
> root <- newXMLNode("root", attrs = atts_root)
>  
> atts_child <- LETTERS[1:3]
> names(atts_child) <- paste("name",1:3,sep="")
> child <- newXMLNode("child",attrs = atts_child, parent = root)
>  
> atts_grandchild <- letters[1:3]
> names(atts_grandchild) <- paste("name",4:6,sep="")
> grandchild <- newXMLNode("grandchild",attrs = atts_grandchild, parent = child)
>  
> root
> #<root att1="val1" att2="val2" att3="val3">
> #  <child name1="A" name2="B" name3="C">
> #    <grandchild name4="a" name5="b" name6="c"/>
> #  </child>
> #</root> 
>  
>  
> Cheers,
> Ben
>  
> On Mar 21, 2018, at 4:25 PM, Bond, Stephen <Stephen.Bond at cibc.com <mailto:Stephen.Bond at cibc.com>> wrote:
>  
> I am trying to add a child to a child using XML package in R. the following fails
> 
> library(XML)
> 
> node1 <- c("val1","val2","val3")
> 
> names(node1) <- c("att1","att2","att3")
> 
> root <- xmlNode("root", attrs=node1)
> 
> node2 <- LETTERS[1:3]
> 
> names(node2) <- paste("name",1:3,sep="")
> 
> root <- addChildren(root,xmlNode("child1",attrs=node2))
> 
> node3 <- letters[1:3]
> 
> names(node3) <- paste("name",4:6,sep="")
> 
> root <- addChildren(root$child1,xmlNode("child2",attrs=node3))
> 
> 
> 
> Error in UseMethod("addChildren") : no applicable method for 'addChildren' applied to an object of class "NULL"
> 
> 
> Stephen B
> 
> 
>             [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> 
>  
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org <http://www.bigelow.org/>
>  
> Tick Forecasting: https://eco.bigelow.org/ <https://eco.bigelow.org/>
Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/





	[[alternative HTML version deleted]]


From Stephen.Bond at cibc.com  Thu Mar 22 15:50:51 2018
From: Stephen.Bond at cibc.com (Bond, Stephen)
Date: Thu, 22 Mar 2018 14:50:51 +0000
Subject: [R] how to add a child to a child in XML
In-Reply-To: <A4374AEF-0BDB-4839-B319-161469AEB9DB@bigelow.org>
References: <624EC9773CAB044ABA65327271BED9B62189EF4E@CBMCC-X10-MB06.ad.cibc.com>
 <6A5229DA-F319-4BD9-9A71-28D3D93B5637@bigelow.org>
 <624EC9773CAB044ABA65327271BED9B62189F412@CBMCC-X10-MB06.ad.cibc.com>
 <A4374AEF-0BDB-4839-B319-161469AEB9DB@bigelow.org>
Message-ID: <624EC9773CAB044ABA65327271BED9B6218A0502@CBMCC-X10-MB06.ad.cibc.com>

Just to clarify and hopefully catch the attention of the maintainer:

The newXMLNode function is not mentioned in:

https://cran.r-project.org/web/packages/XML/XML.pdf

which supposedly describes all functions in the package.


Stephen

From: Ben Tupper [mailto:btupper at bigelow.org]
Sent: Thursday, March 22, 2018 10:40 AM
To: Bond, Stephen
Cc: r-help
Subject: Re: [R] how to add a child to a child in XML

Hi,

It's a reasonable question. The answer is that it actually is included, but there are many instances across packages where multiple functions are documented on a single help page.  The following brings up such a page... (for XML_3.98-1.9)

> library(XML)
> ?newXMLNode

You can see the same on line...

https://www.rdocumentation.org/packages/XML/versions/3.98-1.9/topics/newXMLDoc

You have dig in to find it.

If you are just starting out with XML, you might want to spend some time comparison shopping with the xml2 package. https://www.rdocumentation.org/packages/xml2/versions/1.2.0  I like each one, and I use both XML and xml2 (not at the same time). I have been slowly migrating toward xml2 as I use more of the tidyverse stuff.

Cheers,
Ben

On Mar 22, 2018, at 9:19 AM, Bond, Stephen <Stephen.Bond at cibc.com<mailto:Stephen.Bond at cibc.com>> wrote:

Big thanks. newXMLNode works great. Wonder why it is not included in the documentation.
There is newXMLDoc and newXMLNamespace, but no mention of newXMLNode.

Stephen

From: Ben Tupper [mailto:btupper at bigelow.org]
Sent: Wednesday, March 21, 2018 6:18 PM
To: Bond, Stephen
Cc: r-help
Subject: Re: [R] how to add a child to a child in XML

Hi,

XML doesn't use the `$` to access child nodes.  Instead use either `[name]` to get a list of children of that name or `[[name]]` to get the just the first child of that name encountered in the genealogy.  Thus for your example...

> root$child1
NULL

> root[['child1']]
<child1 name1="A" name2="B" name3="C"/>


On the other hand, you might consider using newXMLNode() instead of xmlNode() as it accepts a "parent = " argument.  The alternative using newXMLNode() would look like...

atts_root <- c("val1","val2","val3")
names(atts_root) <- c("att1","att2","att3")
root <- newXMLNode("root", attrs = atts_root)

atts_child <- LETTERS[1:3]
names(atts_child) <- paste("name",1:3,sep="")
child <- newXMLNode("child",attrs = atts_child, parent = root)

atts_grandchild <- letters[1:3]
names(atts_grandchild) <- paste("name",4:6,sep="")
grandchild <- newXMLNode("grandchild",attrs = atts_grandchild, parent = child)

root
#<root att1="val1" att2="val2" att3="val3">
#  <child name1="A" name2="B" name3="C">
#    <grandchild name4="a" name5="b" name6="c"/>
#  </child>
#</root>


Cheers,
Ben

On Mar 21, 2018, at 4:25 PM, Bond, Stephen <Stephen.Bond at cibc.com<mailto:Stephen.Bond at cibc.com>> wrote:

I am trying to add a child to a child using XML package in R. the following fails

library(XML)

node1 <- c("val1","val2","val3")

names(node1) <- c("att1","att2","att3")

root <- xmlNode("root", attrs=node1)

node2 <- LETTERS[1:3]

names(node2) <- paste("name",1:3,sep="")

root <- addChildren(root,xmlNode("child1",attrs=node2))

node3 <- letters[1:3]

names(node3) <- paste("name",4:6,sep="")

root <- addChildren(root$child1,xmlNode("child2",attrs=node3))



Error in UseMethod("addChildren") : no applicable method for 'addChildren' applied to an object of class "NULL"


Stephen B


            [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org<http://www.bigelow.org/>

Tick Forecasting: https://eco.bigelow.org/

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/




	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Mar 22 15:52:53 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 22 Mar 2018 07:52:53 -0700
Subject: [R] 
 How do I include a factor in a groupedData object? Meaning and
 use of inner and outer parameters
In-Reply-To: <BN6PR03MB27053EC3196E438E560BC5A2E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
References: <BN6PR03MB27053EC3196E438E560BC5A2E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>
Message-ID: <CAGxFJbQPgy06WdjnUzJXX5CQoEoGxmiDM4UHzSP90k1QzuxCjQ@mail.gmail.com>

r-sig-mixed-models is likely to be a better list for such queries.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Mar 22, 2018 at 5:59 AM, Sorkin, John <jsorkin at som.umaryland.edu>
wrote:

> Windows 10 64-bit, R-Studio, R version 3.4.3
>
>
> Several questions relating to groupedData:
>
> (1) I am trying to create a groupedData object that can be used to run an
> analysis that I have been able to urn using lmer. When I include the
> interaction terms in the groupedData opbject I get an error message stating
> that + is not meaningful for factors. How do I include factors in my model?
> See code and error below.
>
> (2) I have read the help file for groupedData multiple times. I am unable
> to understand the meaning or, or the use for the inner= and outer=
> parameters in the call to groupedData. Can someone either explain the
> meaning of these parameters or refer me to a source that give a clear
> explanation?
>
>
> > fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(
> TimePtID)+(1|PatientID),data=smalldata)
> > sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|
> PatientID,data=smalldata)
> Warning messages:
> 1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
> 2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors
>
>
> Thank you,
>
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and
> Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From luiss.puerto at gmail.com  Thu Mar 22 14:48:25 2018
From: luiss.puerto at gmail.com (Luis Puerto)
Date: Thu, 22 Mar 2018 14:48:25 +0100
Subject: [R] Pin package/s
Message-ID: <B0A21232-9701-499C-BA3E-2405CA54969F@gmail.com>

Hi! 

I don?t know if you know package manager for macOS Homebrew. With Homebrew there is a way to stop update certain packages: 

brew pin <formula/package>

Does anyone know a way to do a similar thing with R packages? 

In the same way, it would be great to be able to receive a notification ?an email? when a new version of a package reach CRAN or any other repository. 

I would like to have something like this because the Data Table package has a certain makevars necessities when it?s built in a Homebrew R install. It isn?t really problematic since it the package hasn?t built correctly when you load it on R it will display a message. However, I?m thinking that perhaps something like this could be useful also for other packages. 

Thanks! 


	[[alternative HTML version deleted]]


From jsorkin at som.umaryland.edu  Thu Mar 22 16:08:11 2018
From: jsorkin at som.umaryland.edu (Sorkin, John)
Date: Thu, 22 Mar 2018 15:08:11 +0000
Subject: [R] 
 How do I include a factor in a groupedData object? Meaning and
 use of inner and outer parameters
In-Reply-To: <51049692-9cf4-a05e-4895-0452f9aca63c@dewey.myzen.co.uk>
References: <BN6PR03MB27053EC3196E438E560BC5A2E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>,
 <51049692-9cf4-a05e-4895-0452f9aca63c@dewey.myzen.co.uk>
Message-ID: <BN6PR03MB2705C962D6EDDD304A7E40A5E2A90@BN6PR03MB2705.namprd03.prod.outlook.com>

Michael,

I apprecate your response. The inner and outer parameters to do not affect the results produced by lme. I am still left with the same questions I had before;

(1) How does one include factors in groupData

(2) What is the meaning and use of the outer and inner parameters in groupData?

Thank you again,

John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing)



________________________________
From: Michael Dewey <lists at dewey.myzen.co.uk>
Sent: Thursday, March 22, 2018 10:30 AM
To: Sorkin, John; RHELP <R-help at stat.math.ethz.ch>
Subject: Re: [R] How do I include a factor in a groupedData object? Meaning and use of inner and outer parameters

CAUTION: This message originated from a non UMB, UMSOM, FPI, or UMMS email system. Whether the sender is known or not known, hover over any links before clicking and use caution opening attachments.



Dear John

You are only allowed to have the primary covariate on the left hand side
of the vertical bar. Other covariates go in inner or outer.

Michael

On 22/03/2018 12:59, Sorkin, John wrote:
> Windows 10 64-bit, R-Studio, R version 3.4.3
>
>
> Several questions relating to groupedData:
>
> (1) I am trying to create a groupedData object that can be used to run an analysis that I have been able to urn using lmer. When I include the interaction terms in the groupedData opbject I get an error message stating that + is not meaningful for factors. How do I include factors in my model? See code and error below.
>
> (2) I have read the help file for groupedData multiple times. I am unable to understand the meaning or, or the use for the inner= and outer= parameters in the call to groupedData. Can someone either explain the meaning of these parameters or refer me to a source that give a clear explanation?
>
>
>> fit0 <- lmer(THmean~INTRVNTN+factor(TimePtID)+INTRVNTN*factor(TimePtID)+(1|PatientID),data=smalldata)
>> sdgd <- groupedData(THmean~INTRVNTN+TimePtID+INTRVNTN*TimePtID|PatientID,data=smalldata)
> Warning messages:
> 1: In Ops.factor(INTRVNTN, TimePtID) : ?+? not meaningful for factors
> 2: In Ops.factor(INTRVNTN, TimePtID) : ?*? not meaningful for factors
>
>
> Thank you,
>
> John
>
>
> John David Sorkin M.D., Ph.D.
> Professor of Medicine
> Chief, Biostatistics and Informatics
> University of Maryland School of Medicine Division of Gerontology and Geriatric Medicine
> Baltimore VA Medical Center
> 10 North Greene Street
> GRECC (BT/18/GR)
> Baltimore, MD 21201-1524
> (Phone) 410-605-7119
> (Fax) 410-605-7913 (Please call phone number above prior to faxing)
>
>
>       [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

--
Michael
http://www.dewey.myzen.co.uk/home.html

	[[alternative HTML version deleted]]


From cri.alessandro at gmail.com  Thu Mar 22 16:43:27 2018
From: cri.alessandro at gmail.com (Cristiano Alessandro)
Date: Thu, 22 Mar 2018 10:43:27 -0500
Subject: [R] adjusted values
Message-ID: <CAHhX7Wj_pqUVHHxnhQkbuGuTKJd6Ww2UBCnS5LdaaSJpgWt96g@mail.gmail.com>

Hi all,

I am fitting a linear mixed model with lme4 in R. The model has a single
factor (des_days) with 4 levels (-1,1,14,48), and I am using random
intercept and slopes.

Fixed effects: data ~ des_days
                 Value   Std.Error  DF   t-value p-value
(Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
des_days48   0.0112579 0.005452614 962   2.06469  0.0392

I can clearly use the previous results to compare the estimations of each
"des_day" to the intercept, using the provided t-statistics. Alternatively,
I could use post-hoc tests (z-statistics):

> ph_conditional <- c("des_days1  = 0",
                      "des_days14  = 0",
                      "des_days48 = 0");
> lev.ph <- glht(lev.lm, linfct = ph_conditional);
> summary(lev.ph)

Simultaneous Tests for General Linear Hypotheses

Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
= ~des_days |
    ratID, method = "ML", na.action = na.omit, control = lCtr)

Linear Hypotheses:
                 Estimate Std. Error z value Pr(>|z|)
des_days1 == 0  -0.002632   0.007428  -0.354    0.971
des_days14 == 0 -0.001132   0.006622  -0.171    0.996
des_days48 == 0  0.011258   0.005441   2.069    0.101
(Adjusted p values reported -- single-step method)


The p-values of the coefficient estimates and those of the post-hoc tests
differ because the latter are adjusted with Bonferroni correction. I wonder
whether there is any form of correction in the coefficient estimated of the
LMM, and which p-values are more appropriate to use.

Thanks
Cristiano

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 22 17:00:34 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 22 Mar 2018 09:00:34 -0700
Subject: [R] Sum of columns of a data frame equal to NA when all the
 elements are NA
In-Reply-To: <CAGxFJbSB745UwhHa8BFdsSq2=VvH=JJrev8g2CXNbazSU7Msbw@mail.gmail.com>
References: <8B435C9568170B469AE31E8891E8CC4F54C7811A@ESINO.regionemarche.intra>
 <D28AC2D5-09DD-4475-BF9D-3F989A2E3F8E@utoronto.ca>
 <916BAEDF-E6FE-49DB-BB48-7D5949C53441@dcn.davis.ca.us>
 <A8A62A70-BA00-48F5-BF3E-EA8A01B72E28@utoronto.ca>
 <904D1306-9E88-4245-9118-79153F5ABD56@gmail.com>
 <A3BFC84A-B572-47E6-B485-CAD2291AEBDB@utoronto.ca>
 <CAGxFJbSB745UwhHa8BFdsSq2=VvH=JJrev8g2CXNbazSU7Msbw@mail.gmail.com>
Message-ID: <B04926BC-FECD-4E0F-84A1-1288CAE23CB6@dcn.davis.ca.us>

I can see that one might regard having

sum( sum( 1 ), sum( NULL ) ) == sum( 1 )

be TRUE as a necessary consistency, but going down that road one might expect Bert's

v+NULL == v

for all numeric vectors also. I have always avoided that construction as poor computing practice, but if NULL is supposed to represent the empty set mathematically [1] then this would seem to follow. 

[1] https://cran.r-project.org/doc/contrib/de_Jonge+van_der_Loo-Introduction_to_data_cleaning_with_R.pdf

-- 
Sent from my phone. Please excuse my brevity.

On March 21, 2018 1:06:46 PM PDT, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>"I see: consistency with additive identity. "
>
>Ummm, well:
>
>> 1+NULL
>numeric(0)
>
>> sum(1,NULL)
>[1] 1
>
>Of course, there could well be something here I don't get, but that
>doesn't
>look very consistent to me. However, as I said privately, so long as
>the
>corner case behavior is documented, which it is, I don't care.
>
>Cheers,
>Bert
>
>
>
>Bert Gunter
>
>"The trouble with having an open mind is that people keep coming along
>and
>sticking things into it."
>-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>On Wed, Mar 21, 2018 at 10:26 AM, Boris Steipe
><boris.steipe at utoronto.ca>
>wrote:
>
>> I see: consistency with additive identity. That makes sense. Thanks.
>>
>> B.
>>
>>
>> > On Mar 21, 2018, at 1:22 PM, peter dalgaard <pdalgd at gmail.com>
>wrote:
>> >
>> > No. The empty sum is zero. Adding it to another sum should not
>change
>> it. Nothing audacious about that. This is consistent; other
>definitions
>> just cause trouble.
>> >
>> > -pd
>> >
>> >> On 21 Mar 2018, at 18:05 , Boris Steipe <boris.steipe at utoronto.ca>
>> wrote:
>> >>
>> >> Surely the result of summation of non-existent values is not
>defined,
>> is it not? And since the NA values have been _removed_, there's
>nothing
>> left to sum over. In fact, pretending the the result in that case is
>zero
>> would appear audacious, no?
>> >>
>> >> Cheers,
>> >> Boris
>> >>
>> >>
>> >>
>> >>
>> >>
>> >>> On Mar 21, 2018, at 12:58 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>
>> wrote:
>> >>>
>> >>> What do you mean by "should not"?
>> >>>
>> >>> NULL means "missing object" in R. The result of the sum function
>is
>> always expected to be numeric... so NA_real or NA_integer could make
>sense
>> as possible return values. But you cannot compute on NULL so no, that
>> doesn't work.
>> >>>
>> >>> See the note under the "Value" section of ?sum as to why zero is
>> returned when all inputs are removed.
>> >>> --
>> >>> Sent from my phone. Please excuse my brevity.
>> >>>
>> >>> On March 21, 2018 9:03:29 AM PDT, Boris Steipe <
>> boris.steipe at utoronto.ca> wrote:
>> >>>> Should not the result be NULL if you have removed the NA with
>> >>>> na.rm=TRUE ?
>> >>>>
>> >>>> B.
>> >>>>
>> >>>>
>> >>>>
>> >>>>> On Mar 21, 2018, at 11:44 AM, Stefano Sofia
>> >>>> <stefano.sofia at regione.marche.it> wrote:
>> >>>>>
>> >>>>> Dear list users,
>> >>>>> let me ask you this trivial question. I worked on that for a
>long
>> >>>> time, by now.
>> >>>>> Suppose to have a data frame with NAs and to sum some columns
>with
>> >>>> rowSums:
>> >>>>>
>> >>>>> df <- data.frame(A = runif(10), B = runif(10), C = rnorm(10))
>> >>>>> df[1, ] <- NA
>> >>>>> rowSums(df[ , which(names(df) %in% c("A","B"))], na.rm=T)
>> >>>>>
>> >>>>> If all the elements of the selected columns are NA, rowSums
>returns 0
>> >>>> while I need NA.
>> >>>>> Is there an easy and efficient way to use rowSums within a
>function
>> >>>> like
>> >>>>>
>> >>>>> function(x) ifelse(all(is.na(x)), as.numeric(NA), rowSums...)?
>> >>>>>
>> >>>>> or an equivalent function?
>> >>>>>
>> >>>>> Thank you for your help
>> >>>>> Stefano
>> >>>>>
>> >>>>>
>> >>>>>
>> >>>>>      (oo)
>> >>>>> --oOO--( )--OOo----------------
>> >>>>> Stefano Sofia PhD
>> >>>>> Area Meteorologica e  Area nivologica - Centro Funzionale
>> >>>>> Servizio Protezione Civile - Regione Marche
>> >>>>> Via del Colle Ameno 5
>> >>>>> 60126 Torrette di Ancona, Ancona
>> >>>>> Uff: 071 806 7743
>> >>>>> E-mail: stefano.sofia at regione.marche.it
>> >>>>> ---Oo---------oO----------------
>> >>>>>
>> >>>>> ________________________________
>> >>>>>
>> >>>>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu?
>> >>>> contenere informazioni confidenziali, pertanto ? destinato solo
>a
>> >>>> persone autorizzate alla ricezione. I messaggi di posta
>elettronica
>> per
>> >>>> i client di Regione Marche possono contenere informazioni
>> confidenziali
>> >>>> e con privilegi legali. Se non si ? il destinatario specificato,
>non
>> >>>> leggere, copiare, inoltrare o archiviare questo messaggio. Se si
>?
>> >>>> ricevuto questo messaggio per errore, inoltrarlo al mittente ed
>> >>>> eliminarlo completamente dal sistema del proprio computer. Ai
>sensi
>> >>>> dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di
>> necessit?
>> >>>> ed urgenza, la risposta al presente messaggio di posta
>elettronica pu?
>> >>>> essere visionata da persone estranee al destinatario.
>> >>>>> IMPORTANT NOTICE: This e-mail message is intended to be
>received only
>> >>>> by persons entitled to receive the confidential information it
>may
>> >>>> contain. E-mail messages to clients of Regione Marche may
>contain
>> >>>> information that is confidential and legally privileged. Please
>do not
>> >>>> read, copy, forward, or store this message unless you are an
>intended
>> >>>> recipient of it. If you have received this message in error,
>please
>> >>>> forward it to the sender and delete it completely from your
>computer
>> >>>> system.
>> >>>>>
>> >>>>> --
>> >>>>> Questo messaggio  stato analizzato da Libra ESVA ed  risultato
>non
>> >>>> infetto.
>> >>>>> This message was scanned by Libra ESVA and is believed to be
>clean.
>> >>>>>
>> >>>>>
>> >>>>>   [[alternative HTML version deleted]]
>> >>>>>
>> >>>>> ______________________________________________
>> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>>>
>> >>>> ______________________________________________
>> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more,
>see
>> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
>> >>>> PLEASE do read the posting guide
>> >>>> http://www.R-project.org/posting-guide.html
>> >>>> and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >> ______________________________________________
>> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >> https://stat.ethz.ch/mailman/listinfo/r-help
>> >> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> >> and provide commented, minimal, self-contained, reproducible code.
>> >
>> > --
>> > Peter Dalgaard, Professor,
>> > Center for Statistics, Copenhagen Business School
>> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> > Phone: (+45)38153501
>> > Office: A 4.23
>> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>> >
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>


From dcarlson at tamu.edu  Thu Mar 22 17:07:07 2018
From: dcarlson at tamu.edu (David L Carlson)
Date: Thu, 22 Mar 2018 16:07:07 +0000
Subject: [R] how to add a child to a child in XML
In-Reply-To: <624EC9773CAB044ABA65327271BED9B6218A0502@CBMCC-X10-MB06.ad.cibc.com>
References: <624EC9773CAB044ABA65327271BED9B62189EF4E@CBMCC-X10-MB06.ad.cibc.com>
 <6A5229DA-F319-4BD9-9A71-28D3D93B5637@bigelow.org>
 <624EC9773CAB044ABA65327271BED9B62189F412@CBMCC-X10-MB06.ad.cibc.com>
 <A4374AEF-0BDB-4839-B319-161469AEB9DB@bigelow.org>
 <624EC9773CAB044ABA65327271BED9B6218A0502@CBMCC-X10-MB06.ad.cibc.com>
Message-ID: <7ea698646ccc4178847b43c2c042590f@exch-2p-mbx-w2.ads.tamu.edu>

It is not listed in the table of contents, but as Ben mentioned, it is documented with newXMLDoc (pages 52-58) along with newXMLDoc, newHTMLDoc, newXMLTextNode, newXMLCDataNode, newXMLCommentNoe, newXMLPINode, and newXMLDTDNode on page 53:

newXMLNode(name, ..., attrs = NULL, namespace = character(),
     namespaceDefinitions = character(),
     doc = NULL, .children = list(...), parent = NULL,
     at = NA, cdata = FALSE, suppressNamespaceWarning =
     getOption("suppressXMLNamespaceWarning", FALSE),
     sibling = NULL, addFinalizer = NA,
     noNamespace = length(namespace) == 0 && !missing(namespace),
     fixNamespaces = c(dummy = TRUE, default = TRUE))

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Bond, Stephen
Sent: Thursday, March 22, 2018 9:51 AM
To: 'Ben Tupper' <btupper at bigelow.org>
Cc: 'r-help' <r-help at R-project.org>
Subject: Re: [R] how to add a child to a child in XML

Just to clarify and hopefully catch the attention of the maintainer:

The newXMLNode function is not mentioned in:

https://cran.r-project.org/web/packages/XML/XML.pdf

which supposedly describes all functions in the package.


Stephen

From: Ben Tupper [mailto:btupper at bigelow.org]
Sent: Thursday, March 22, 2018 10:40 AM
To: Bond, Stephen
Cc: r-help
Subject: Re: [R] how to add a child to a child in XML

Hi,

It's a reasonable question. The answer is that it actually is included, but there are many instances across packages where multiple functions are documented on a single help page.  The following brings up such a page... (for XML_3.98-1.9)

> library(XML)
> ?newXMLNode

You can see the same on line...

https://www.rdocumentation.org/packages/XML/versions/3.98-1.9/topics/newXMLDoc

You have dig in to find it.

If you are just starting out with XML, you might want to spend some time comparison shopping with the xml2 package. https://www.rdocumentation.org/packages/xml2/versions/1.2.0  I like each one, and I use both XML and xml2 (not at the same time). I have been slowly migrating toward xml2 as I use more of the tidyverse stuff.

Cheers,
Ben

On Mar 22, 2018, at 9:19 AM, Bond, Stephen <Stephen.Bond at cibc.com<mailto:Stephen.Bond at cibc.com>> wrote:

Big thanks. newXMLNode works great. Wonder why it is not included in the documentation.
There is newXMLDoc and newXMLNamespace, but no mention of newXMLNode.

Stephen

From: Ben Tupper [mailto:btupper at bigelow.org]
Sent: Wednesday, March 21, 2018 6:18 PM
To: Bond, Stephen
Cc: r-help
Subject: Re: [R] how to add a child to a child in XML

Hi,

XML doesn't use the `$` to access child nodes.  Instead use either `[name]` to get a list of children of that name or `[[name]]` to get the just the first child of that name encountered in the genealogy.  Thus for your example...

> root$child1
NULL

> root[['child1']]
<child1 name1="A" name2="B" name3="C"/>


On the other hand, you might consider using newXMLNode() instead of xmlNode() as it accepts a "parent = " argument.  The alternative using newXMLNode() would look like...

atts_root <- c("val1","val2","val3")
names(atts_root) <- c("att1","att2","att3") root <- newXMLNode("root", attrs = atts_root)

atts_child <- LETTERS[1:3]
names(atts_child) <- paste("name",1:3,sep="") child <- newXMLNode("child",attrs = atts_child, parent = root)

atts_grandchild <- letters[1:3]
names(atts_grandchild) <- paste("name",4:6,sep="") grandchild <- newXMLNode("grandchild",attrs = atts_grandchild, parent = child)

root
#<root att1="val1" att2="val2" att3="val3"> #  <child name1="A" name2="B" name3="C">
#    <grandchild name4="a" name5="b" name6="c"/>
#  </child>
#</root>


Cheers,
Ben

On Mar 21, 2018, at 4:25 PM, Bond, Stephen <Stephen.Bond at cibc.com<mailto:Stephen.Bond at cibc.com>> wrote:

I am trying to add a child to a child using XML package in R. the following fails

library(XML)

node1 <- c("val1","val2","val3")

names(node1) <- c("att1","att2","att3")

root <- xmlNode("root", attrs=node1)

node2 <- LETTERS[1:3]

names(node2) <- paste("name",1:3,sep="")

root <- addChildren(root,xmlNode("child1",attrs=node2))

node3 <- letters[1:3]

names(node3) <- paste("name",4:6,sep="")

root <- addChildren(root$child1,xmlNode("child2",attrs=node3))



Error in UseMethod("addChildren") : no applicable method for 'addChildren' applied to an object of class "NULL"


Stephen B


            [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org<http://www.bigelow.org/>

Tick Forecasting: https://eco.bigelow.org/

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/




	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bgunter.4567 at gmail.com  Thu Mar 22 17:58:21 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 22 Mar 2018 09:58:21 -0700
Subject: [R] adjusted values
In-Reply-To: <CAHhX7Wj_pqUVHHxnhQkbuGuTKJd6Ww2UBCnS5LdaaSJpgWt96g@mail.gmail.com>
References: <CAHhX7Wj_pqUVHHxnhQkbuGuTKJd6Ww2UBCnS5LdaaSJpgWt96g@mail.gmail.com>
Message-ID: <CAGxFJbQ1+5cuCZJYVf_RQVDojxOqaZb1rcfGb1uJae4Bsu1-qw@mail.gmail.com>

Tis list is about R programming issues; statistical questons are generally
OT. The r-sig-mixed-models list would be a much better place to post your
queries.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Thu, Mar 22, 2018 at 8:43 AM, Cristiano Alessandro <
cri.alessandro at gmail.com> wrote:

> Hi all,
>
> I am fitting a linear mixed model with lme4 in R. The model has a single
> factor (des_days) with 4 levels (-1,1,14,48), and I am using random
> intercept and slopes.
>
> Fixed effects: data ~ des_days
>                  Value   Std.Error  DF   t-value p-value
> (Intercept)  0.8274313 0.007937938 962 104.23757  0.0000
> des_days1   -0.0026322 0.007443294 962  -0.35363  0.7237
> des_days14  -0.0011319 0.006635512 962  -0.17058  0.8646
> des_days48   0.0112579 0.005452614 962   2.06469  0.0392
>
> I can clearly use the previous results to compare the estimations of each
> "des_day" to the intercept, using the provided t-statistics. Alternatively,
> I could use post-hoc tests (z-statistics):
>
> > ph_conditional <- c("des_days1  = 0",
>                       "des_days14  = 0",
>                       "des_days48 = 0");
> > lev.ph <- glht(lev.lm, linfct = ph_conditional);
> > summary(lev.ph)
>
> Simultaneous Tests for General Linear Hypotheses
>
> Fit: lme.formula(fixed = data ~ des_days, data = data_red_trf, random
> = ~des_days |
>     ratID, method = "ML", na.action = na.omit, control = lCtr)
>
> Linear Hypotheses:
>                  Estimate Std. Error z value Pr(>|z|)
> des_days1 == 0  -0.002632   0.007428  -0.354    0.971
> des_days14 == 0 -0.001132   0.006622  -0.171    0.996
> des_days48 == 0  0.011258   0.005441   2.069    0.101
> (Adjusted p values reported -- single-step method)
>
>
> The p-values of the coefficient estimates and those of the post-hoc tests
> differ because the latter are adjusted with Bonferroni correction. I wonder
> whether there is any form of correction in the coefficient estimated of the
> LMM, and which p-values are more appropriate to use.
>
> Thanks
> Cristiano
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From haidaharis at gmail.com  Thu Mar 22 22:07:40 2018
From: haidaharis at gmail.com (Haida)
Date: Fri, 23 Mar 2018 05:07:40 +0800
Subject: [R] GlobalEnv error
Message-ID: <CABjPMZ3qgFs1f3vzfyvZ--x1_4oQwe=vXjA2M221268OtQUikA@mail.gmail.com>

Dear all

May I know how to solve this problem? I have encountered this problem after
I have logged out from Rstudio. Thank you

Warning: namespace ?caret? is not available and has been replaced
by .GlobalEnv when processing object ?fit.ann?
Warning: namespace ?ggplot2? is not available and has been replaced
by .GlobalEnv when processing object ?p1?
Warning: namespace ?plotly? is not available and has been replaced
by .GlobalEnv when processing object ?p?
Warning: namespace ?easyGgplot2? is not available and has been replaced
by .GlobalEnv when processing object ?plot?
Warning: namespace ?RSNNS? is not available and has been replaced
by .GlobalEnv when processing object ?fit.mlp?
Warning: namespace ?ipred? is not available and has been replaced
by .GlobalEnv when processing object ?fit.treebag?

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Fri Mar 23 00:10:05 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 22 Mar 2018 16:10:05 -0700
Subject: [R] GlobalEnv error
In-Reply-To: <CABjPMZ3qgFs1f3vzfyvZ--x1_4oQwe=vXjA2M221268OtQUikA@mail.gmail.com>
References: <CABjPMZ3qgFs1f3vzfyvZ--x1_4oQwe=vXjA2M221268OtQUikA@mail.gmail.com>
Message-ID: <D6CFC5DC-A52B-4826-B527-B617CFA8C008@dcn.davis.ca.us>

Error messages are useful, but without knowing what you did during your session it is hard to look more closely. It would also be helpful to see the output of the sessioInfo function, and the contents of your .Rprofile file in your home directory. Read the Posting Guide, which cautions you that this is a plain text-only mailing list... your "formatted" email gets damaged to some varying extent when it goes through the formatting stripper.

Also, this is an R support area, not an RStudio support area. You should confirm that these errors occur when you use R or RGui.
-- 
Sent from my phone. Please excuse my brevity.

On March 22, 2018 2:07:40 PM PDT, Haida <haidaharis at gmail.com> wrote:
>Dear all
>
>May I know how to solve this problem? I have encountered this problem
>after
>I have logged out from Rstudio. Thank you
>
>Warning: namespace ?caret? is not available and has been replaced
>by .GlobalEnv when processing object ?fit.ann?
>Warning: namespace ?ggplot2? is not available and has been replaced
>by .GlobalEnv when processing object ?p1?
>Warning: namespace ?plotly? is not available and has been replaced
>by .GlobalEnv when processing object ?p?
>Warning: namespace ?easyGgplot2? is not available and has been replaced
>by .GlobalEnv when processing object ?plot?
>Warning: namespace ?RSNNS? is not available and has been replaced
>by .GlobalEnv when processing object ?fit.mlp?
>Warning: namespace ?ipred? is not available and has been replaced
>by .GlobalEnv when processing object ?fit.treebag?
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Mar 23 00:58:35 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 22 Mar 2018 16:58:35 -0700
Subject: [R] GlobalEnv error
In-Reply-To: <CABjPMZ3qgFs1f3vzfyvZ--x1_4oQwe=vXjA2M221268OtQUikA@mail.gmail.com>
References: <CABjPMZ3qgFs1f3vzfyvZ--x1_4oQwe=vXjA2M221268OtQUikA@mail.gmail.com>
Message-ID: <CAF8bMcZpvc33mTVmo4T1mQ=TSEuoRz3dPD3fM_Fb90F9q1gJrA@mail.gmail.com>

You haven't given much context, but these error message can come from
load() when loading a *.RData file that contains objects reference packages
not installed in the current installation of R.  When R starts it will load
a ".RData" file if one exists, this file is typically created when R shuts
down
and you ask it to save the current session.  If you recently upgraded R you
the newly installed R may not have all the packages that were installed in
the version that you last used.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Mar 22, 2018 at 2:07 PM, Haida <haidaharis at gmail.com> wrote:

> Dear all
>
> May I know how to solve this problem? I have encountered this problem after
> I have logged out from Rstudio. Thank you
>
> Warning: namespace ?caret? is not available and has been replaced
> by .GlobalEnv when processing object ?fit.ann?
> Warning: namespace ?ggplot2? is not available and has been replaced
> by .GlobalEnv when processing object ?p1?
> Warning: namespace ?plotly? is not available and has been replaced
> by .GlobalEnv when processing object ?p?
> Warning: namespace ?easyGgplot2? is not available and has been replaced
> by .GlobalEnv when processing object ?plot?
> Warning: namespace ?RSNNS? is not available and has been replaced
> by .GlobalEnv when processing object ?fit.mlp?
> Warning: namespace ?ipred? is not available and has been replaced
> by .GlobalEnv when processing object ?fit.treebag?
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From haidaharis at gmail.com  Fri Mar 23 03:09:30 2018
From: haidaharis at gmail.com (Haida)
Date: Fri, 23 Mar 2018 10:09:30 +0800
Subject: [R] GlobalEnv error
In-Reply-To: <CAF8bMcZpvc33mTVmo4T1mQ=TSEuoRz3dPD3fM_Fb90F9q1gJrA@mail.gmail.com>
References: <CABjPMZ3qgFs1f3vzfyvZ--x1_4oQwe=vXjA2M221268OtQUikA@mail.gmail.com>
 <CAF8bMcZpvc33mTVmo4T1mQ=TSEuoRz3dPD3fM_Fb90F9q1gJrA@mail.gmail.com>
Message-ID: <CABjPMZ3WT_DVJiyLWqHNo-OUm-4ZAeU58CMxCLdznqcG5HC62g@mail.gmail.com>

Previously, the R software was perfectly run without error and I am not
sure why this happens. I have not installed any new R. If the *RData file
is the problem, what should I do?
Thank you

On Fri, Mar 23, 2018 at 7:58 AM, William Dunlap <wdunlap at tibco.com> wrote:

> You haven't given much context, but these error message can come from
> load() when loading a *.RData file that contains objects reference packages
> not installed in the current installation of R.  When R starts it will load
> a ".RData" file if one exists, this file is typically created when R shuts
> down
> and you ask it to save the current session.  If you recently upgraded R you
> the newly installed R may not have all the packages that were installed in
> the version that you last used.
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Thu, Mar 22, 2018 at 2:07 PM, Haida <haidaharis at gmail.com> wrote:
>
>> Dear all
>>
>> May I know how to solve this problem? I have encountered this problem
>> after
>> I have logged out from Rstudio. Thank you
>>
>> Warning: namespace ?caret? is not available and has been replaced
>> by .GlobalEnv when processing object ?fit.ann?
>> Warning: namespace ?ggplot2? is not available and has been replaced
>> by .GlobalEnv when processing object ?p1?
>> Warning: namespace ?plotly? is not available and has been replaced
>> by .GlobalEnv when processing object ?p?
>> Warning: namespace ?easyGgplot2? is not available and has been replaced
>> by .GlobalEnv when processing object ?plot?
>> Warning: namespace ?RSNNS? is not available and has been replaced
>> by .GlobalEnv when processing object ?fit.mlp?
>> Warning: namespace ?ipred? is not available and has been replaced
>> by .GlobalEnv when processing object ?fit.treebag?
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From michelle.ann.kline at gmail.com  Thu Mar 22 21:31:27 2018
From: michelle.ann.kline at gmail.com (Michelle Kline)
Date: Thu, 22 Mar 2018 13:31:27 -0700
Subject: [R] MCMCglmm multinomial model results
Message-ID: <CAHKF8+MR2qA8Kg-V5cgt5+9MngAazPbrQAN3ANGpA2=enHt9qQ@mail.gmail.com>

Hi,

Thanks in advance for any help on this question. I'm running multinomial
models using the MCMCglmm package. The models have 5 outcome variables
(each with count data), and an additional two random effects built into the
models. The issue is that when I use the following code, the summary only
gives me results for four of the outcome variables.

Here is the code for my model:

m3.random <- MCMCglmm(cbind(Opp_teacher , Dir_teacher, Enh_teacher,
SocTol_teacher, Eval_teacher) ~ trait -1,
               random = ~ us(trait):other + us(trait):focal,
               rcov = ~ us(trait):units,
               prior = list(
                 R = list(fix=1, V=0.5 * (I + J), n = 4),
                 G = list(
                   G1 = list(V = diag(4), n = 4),
                   G2 = list(V = diag(4), n = 4))),
               burnin = burn,
               nitt = iter,
               family = "multinomial5",
               data = data,
               pr=TRUE,
               pl=TRUE,
               DIC = TRUE,
               verbose = FALSE)

And the summary of the main effects:

post.mean  l-95% CI  u-95% CI eff.samp        pMCMC
traitOpp_teacher    -3.828752 -4.616731 -3.067424 184.4305 5.263158e-05
traitDir_teacher    -3.400481 -4.041069 -2.813063 259.1084 5.263158e-05
traitEnh_teacher    -1.779129 -2.197415 -1.366496 624.9759 5.263158e-05
traitSocTol_teacher -2.852684 -3.429799 -2.332909 468.7098 5.263158e-05


It is not an issue of the suppressing the intercept, since I'm already
doing that (see the -1 term. When I remove that term, the model solutions
includes an intercept and only 3 additional main effects).

The model does throw the following error, but after searching previous
messages on this list, I've concluded that this error message doesn't have
to do with  my current problem. Just in case: " observations with zero
weight not used for calculating dispersion"

I have also posted a similar question on stackoverflow about a week ago,
but with no response, so I thought I would try here. Link in case people
want to gain reputation points for a
response: https://stackoverflow.com/questions/49309027/missing-term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue
<https://stackoverflow.com/questions/49309027/missing-term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue>

And of course I've checked various other sources including the course
notes, but can't make sense of why the 5th term is dropped from the model.
Any help is much appreciated.

Best,

Michelle

-- 
Michelle A. Kline, PhD

Assistant Professor
Department of Psychology
Simon Fraser University

	[[alternative HTML version deleted]]


From Erich.Striessnig at oeaw.ac.at  Thu Mar 22 23:34:10 2018
From: Erich.Striessnig at oeaw.ac.at (Striessnig, Erich)
Date: Thu, 22 Mar 2018 22:34:10 +0000
Subject: [R] Calculate weighted proportions for several factors at once
Message-ID: <a017c2389b4645d7afddb5e6a812a8a7@oeaw.ac.at>

Hi,

I have a grouped data set and would like to calculate weighted proportions for a large number of factor variables within each group member. Rather than using dplyr::count() on each of these factors individually, the idea would be to do it for all factors at once. Does anyone know how this would work? Here is a reproducible example:

############################################################
# reproducible example
df1 <- data.frame(wt=rnorm(90),
                  group=paste0('reg', 1:5),
                  var1=rep(c('male','female'), times=45),
                  var2=rep(c('low','med','high'), each=30)) %>% tbl_df()

# instead of doing this separately for each factor ...
df2 <- df1 %>%
  group_by(group) %>%
  dplyr::count(var1, wt=wt) %>%
  mutate(prop1=n/sum(n))

df3 <- df1 %>%
  group_by(group) %>%
  dplyr::count(var2, wt=wt) %>%
  mutate(prop2=n/sum(n)) %>%
  left_join(df2, by='group')

# I would like to do something like the following (which does of course not work):
my_fun <- function(x,wt){
  freq1 <- dplyr::count(x, wt=wt)
  prop1 <- freq1 / sum(freq1)
  return(prop)
}

df1 %>%
  group_by(group) %>%
  summarise_all(.funs=my_fun(.), .vars=c('var1', 'var2'))
############################################################

Best regards,
Erich

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Fri Mar 23 05:00:22 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 22 Mar 2018 21:00:22 -0700
Subject: [R] GlobalEnv error
In-Reply-To: <CABjPMZ3WT_DVJiyLWqHNo-OUm-4ZAeU58CMxCLdznqcG5HC62g@mail.gmail.com>
References: <CABjPMZ3qgFs1f3vzfyvZ--x1_4oQwe=vXjA2M221268OtQUikA@mail.gmail.com>
 <CAF8bMcZpvc33mTVmo4T1mQ=TSEuoRz3dPD3fM_Fb90F9q1gJrA@mail.gmail.com>
 <CABjPMZ3WT_DVJiyLWqHNo-OUm-4ZAeU58CMxCLdznqcG5HC62g@mail.gmail.com>
Message-ID: <CAF8bMcbsNthJ22NfYHEaU9haY8na+VV7z3WmV6r5qp=twp7k3A@mail.gmail.com>

Find the .RData file and rename it to anything else.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Thu, Mar 22, 2018 at 7:09 PM, Haida <haidaharis at gmail.com> wrote:

> Previously, the R software was perfectly run without error and I am not
> sure why this happens. I have not installed any new R. If the *RData file
> is the problem, what should I do?
> Thank you
>
> On Fri, Mar 23, 2018 at 7:58 AM, William Dunlap <wdunlap at tibco.com> wrote:
>
>> You haven't given much context, but these error message can come from
>> load() when loading a *.RData file that contains objects reference
>> packages
>> not installed in the current installation of R.  When R starts it will
>> load
>> a ".RData" file if one exists, this file is typically created when R
>> shuts down
>> and you ask it to save the current session.  If you recently upgraded R
>> you
>> the newly installed R may not have all the packages that were installed in
>> the version that you last used.
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com
>>
>> On Thu, Mar 22, 2018 at 2:07 PM, Haida <haidaharis at gmail.com> wrote:
>>
>>> Dear all
>>>
>>> May I know how to solve this problem? I have encountered this problem
>>> after
>>> I have logged out from Rstudio. Thank you
>>>
>>> Warning: namespace ?caret? is not available and has been replaced
>>> by .GlobalEnv when processing object ?fit.ann?
>>> Warning: namespace ?ggplot2? is not available and has been replaced
>>> by .GlobalEnv when processing object ?p1?
>>> Warning: namespace ?plotly? is not available and has been replaced
>>> by .GlobalEnv when processing object ?p?
>>> Warning: namespace ?easyGgplot2? is not available and has been replaced
>>> by .GlobalEnv when processing object ?plot?
>>> Warning: namespace ?RSNNS? is not available and has been replaced
>>> by .GlobalEnv when processing object ?fit.mlp?
>>> Warning: namespace ?ipred? is not available and has been replaced
>>> by .GlobalEnv when processing object ?fit.treebag?
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>

	[[alternative HTML version deleted]]


From rubenarslan at gmail.com  Fri Mar 23 09:54:52 2018
From: rubenarslan at gmail.com (Ruben Arslan)
Date: Fri, 23 Mar 2018 08:54:52 +0000
Subject: [R] [R-pkgs] New package: codebook
Message-ID: <CALv3xzs8u1ynC3zvzAaM=wtTQmx6O+BuaQLzotvZifNHVU-3HQ@mail.gmail.com>

Dear R users,

codebook (v. 0.5.8) was just released on CRAN.
https://CRAN.R-project.org/package=codebook

It uses the metadata/attributes that some other packages add (item labels,
value labels, labelled missings) to automatically generate a codebook that
is both human- and machine-readable. It combines metadata about the
variables with data summaries. Many people will import this kind of
metadata already, when importing data from SPSS or Stata files using the
haven package.

My hope was to encourage people to share data and especially
machine-readable metadata more often by giving them something that is
useful (automating a common, tedious task), so that we can have something
even more useful in the future (searchable, machine-readable metadata).

A small example and more documentation is here:
https://rubenarslan.github.io/codebook/articles/codebook.html

codebook automates the following tasks:
* computing reliabilities (internal consistencies, retest, multilevel) for
psychological scales
* summarising the distributions of scales and items graphically and using
descriptive statistics
* combining this information with metadata (such as item labels and
labelled values) derived from attributes

To do so, the package relies on 'rmarkdown' partials, so you can generate
HTML, PDF, and Word documents, and embed the codebook in a larger document
providing context.

Codebooks are also generated as tables (CSV, Excel, etc.) and are invisibly
embedded as JSON-LD in generated HTML files. JSON-LD for datasets is not
yet supported by search engines, but hopefully will be.

Critiques, bug reports and enhancement requests are welcome as GitHub
issues. I'm a social scientist and tested this mostly on survey data. I'm
sure that shows in some design decisions. I'd be happy to find
collaborators who can e.g. fill in my knowledge gaps on metadata and
ontologies.
https://github.com/rubenarslan/codebook/issues

Best,

Ruben
-- 

Ruben C. Arslan

Center for Adaptive Rationality
Max Planck Institute for Human Development
Berlin, Germany
https://www.mpib-berlin.mpg.de/en/staff/ruben-arslan
https://formr.org
http://www.the100.ci

	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dwinsemius at comcast.net  Fri Mar 23 18:13:57 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 23 Mar 2018 10:13:57 -0700
Subject: [R] MCMCglmm multinomial model results
In-Reply-To: <CAHKF8+MR2qA8Kg-V5cgt5+9MngAazPbrQAN3ANGpA2=enHt9qQ@mail.gmail.com>
References: <CAHKF8+MR2qA8Kg-V5cgt5+9MngAazPbrQAN3ANGpA2=enHt9qQ@mail.gmail.com>
Message-ID: <64123A1D-5BB1-4060-B3EE-1F19328B9401@comcast.net>


> On Mar 22, 2018, at 1:31 PM, Michelle Kline <michelle.ann.kline at gmail.com> wrote:
> 
> Hi,
> 
> Thanks in advance for any help on this question. I'm running multinomial
> models using the MCMCglmm package. The models have 5 outcome variables
> (each with count data), and an additional two random effects built into the
> models. The issue is that when I use the following code, the summary only
> gives me results for four of the outcome variables.
> 
> Here is the code for my model:
> 
> m3.random <- MCMCglmm(cbind(Opp_teacher , Dir_teacher, Enh_teacher,
> SocTol_teacher, Eval_teacher) ~ trait -1,
>               random = ~ us(trait):other + us(trait):focal,
>               rcov = ~ us(trait):units,
>               prior = list(
>                 R = list(fix=1, V=0.5 * (I + J), n = 4),
>                 G = list(
>                   G1 = list(V = diag(4), n = 4),
>                   G2 = list(V = diag(4), n = 4))),
>               burnin = burn,
>               nitt = iter,
>               family = "multinomial5",
>               data = data,

We have no way to debug this without the data. Perhaps you should contact the maintainer and in your message attach the data?

 maintainer('MCMCglmm')
[1] "Jarrod Hadfield <j.hadfield at ed.ac.uk>"


An equally effective approach would be to post (again with data that reproduces the error)  on the R-SIG-mixed-models mailing list since Hadfield is a regular contributor on that list. (To me it suggests not an error since you got output but rather a warning. Generally warnings and errors are properly labeled so you may not have included the full output.) 

-- 
David.
>               pr=TRUE,
>               pl=TRUE,
>               DIC = TRUE,
>               verbose = FALSE)
> 
> And the summary of the main effects:
> 
> post.mean  l-95% CI  u-95% CI eff.samp        pMCMC
> traitOpp_teacher    -3.828752 -4.616731 -3.067424 184.4305 5.263158e-05
> traitDir_teacher    -3.400481 -4.041069 -2.813063 259.1084 5.263158e-05
> traitEnh_teacher    -1.779129 -2.197415 -1.366496 624.9759 5.263158e-05
> traitSocTol_teacher -2.852684 -3.429799 -2.332909 468.7098 5.263158e-05
> 
> 
> It is not an issue of the suppressing the intercept, since I'm already
> doing that (see the -1 term. When I remove that term, the model solutions
> includes an intercept and only 3 additional main effects).
> 
> The model does throw the following error, but after searching previous
> messages on this list, I've concluded that this error message doesn't have
> to do with  my current problem. Just in case: " observations with zero
> weight not used for calculating dispersion"
> 
> I have also posted a similar question on stackoverflow about a week ago,
> but with no response, so I thought I would try here. Link in case people
> want to gain reputation points for a
> response: https://stackoverflow.com/questions/49309027/missing-term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue
> <https://stackoverflow.com/questions/49309027/missing-term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue>
> 
> And of course I've checked various other sources including the course
> notes, but can't make sense of why the 5th term is dropped from the model.
> Any help is much appreciated.
> 
> Best,
> 
> Michelle
> 
> -- 
> Michelle A. Kline, PhD
> 
> Assistant Professor
> Department of Psychology
> Simon Fraser University
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From quesadavictor at uniovi.es  Fri Mar 23 14:23:34 2018
From: quesadavictor at uniovi.es (Victor Quesada)
Date: Fri, 23 Mar 2018 14:23:34 +0100
Subject: [R] [R-pkgs] New package nVennR
Message-ID: <00fb01d3c2aa$267e0be0$737a23a0$@uniovi.es>

A new package, nVennR, is available on CRAN

 

Description: Provides an interface for the nVenn algorithm (Perez-Silva et
al. 2018) <DOI:10.1093/bioinformatics/bty109> to create approximately
proportional, n-dimensional Venn and Euler diagrams. There is no limit to
the number of sets, although using more than seven takes a long time and is
hard to interpret. You can check an example for six sets at
<http://degradome.uniovi.es/cgi-bin/nVenn/nvenn.cgi?uid=2A916BED>.

 

 


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From dwinsemius at comcast.net  Fri Mar 23 21:40:12 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 23 Mar 2018 13:40:12 -0700
Subject: [R] Calculate weighted proportions for several factors at once
In-Reply-To: <a017c2389b4645d7afddb5e6a812a8a7@oeaw.ac.at>
References: <a017c2389b4645d7afddb5e6a812a8a7@oeaw.ac.at>
Message-ID: <F56B4FD5-C6B4-4A19-ACDD-3A20E5140671@comcast.net>


> On Mar 22, 2018, at 3:34 PM, Striessnig, Erich <Erich.Striessnig at oeaw.ac.at> wrote:
> 
> Hi,
> 
> I have a grouped data set and would like to calculate weighted proportions for a large number of factor variables within each group member. Rather than using dplyr::count() on each of these factors individually, the idea would be to do it for all factors at once. Does anyone know how this would work? Here is a reproducible example:
> 
> ############################################################
> # reproducible example
> df1 <- data.frame(wt=rnorm(90),
>                  group=paste0('reg', 1:5),
>                  var1=rep(c('male','female'), times=45),
>                  var2=rep(c('low','med','high'), each=30)) %>% tbl_df()
> 
> # instead of doing this separately for each factor ...
> df2 <- df1 %>%
>  group_by(group) %>%
>  dplyr::count(var1, wt=wt) %>%
>  mutate(prop1=n/sum(n))
> 
> df3 <- df1 %>%
>  group_by(group) %>%
>  dplyr::count(var2, wt=wt) %>%
>  mutate(prop2=n/sum(n)) %>%
>  left_join(df2, by='group')
> 
> # I would like to do something like the following (which does of course not work):
> my_fun <- function(x,wt){
>  freq1 <- dplyr::count(x, wt=wt)
>  prop1 <- freq1 / sum(freq1)
>  return(prop)
> }
> 
> df1 %>%
>  group_by(group) %>%
>  summarise_all(.funs=my_fun(.), .vars=c('var1', 'var2'))
> ############################################################

You might find useful functions in the ?freqweights? package. It appears from its description that it was design to fit into the tidyverse paradigm. I think the survey package might also be useful, but it is not particularly designed for use with tibbles and `%>%`. Might work. Might not.

HTH;
Dadid.
 
> 
> Best regards,
> Erich
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From amalraj.raja at abdn.ac.uk  Sat Mar 24 00:05:51 2018
From: amalraj.raja at abdn.ac.uk (Raja, Dr. Edwin Amalraj)
Date: Fri, 23 Mar 2018 23:05:51 +0000
Subject: [R] restricted cubic spline in FGR  function
Message-ID: <VI1PR0402MB3822851665B4B66B0B150750A1A80@VI1PR0402MB3822.eurprd04.prod.outlook.com>

Dear Thomas,

   I want to use evaluate effect of Age using restricted cubic form  in the  FGR function  as
Fgr.crr <- FGR(Hist(time, event) ~ rcs(Age_years), data=dat)

It provides error.  " Error in parse(text = termtext, keep.source = FALSE):  ....   1: response ~ rcs(Age_years

Do I need to change any of the R code?

Regards
Amalraj Raja



The University of Aberdeen is a charity registered in Scotland, No SC013683.
Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

	[[alternative HTML version deleted]]


From tag at biostat.ku.dk  Sat Mar 24 07:10:34 2018
From: tag at biostat.ku.dk (Thomas Alexander Gerds)
Date: Sat, 24 Mar 2018 07:10:34 +0100
Subject: [R] restricted cubic spline in FGR  function
In-Reply-To: <VI1PR0402MB3822851665B4B66B0B150750A1A80@VI1PR0402MB3822.eurprd04.prod.outlook.com>
 (Dr. Edwin Amalraj Raja's message of "Fri, 23 Mar 2018 23:05:51
 +0000")
References: <VI1PR0402MB3822851665B4B66B0B150750A1A80@VI1PR0402MB3822.eurprd04.prod.outlook.com>
Message-ID: <87k1u26m1x.fsf@biostat.ku.dk>


the problem is not in my package. you can probably see this with tracebach()

rcs is from rms and FGR is just a wrapper for cmprsk

it would be nice though to fix this and if you can I would be very happy
to include your contribution in my package.

"Raja, Dr. Edwin Amalraj" <amalraj.raja at abdn.ac.uk> writes:

> Dear Thomas,
>
>    I want to use evaluate effect of Age using restricted cubic form  in the  FGR function  as
> Fgr.crr <- FGR(Hist(time, event) ~ rcs(Age_years), data=dat)
>
> It provides error.  " Error in parse(text = termtext, keep.source = FALSE):  ....   1: response ~ rcs(Age_years
>
> Do I need to change any of the R code?
>
> Regards
> Amalraj Raja
>
>
>
> The University of Aberdeen is a charity registered in Scotland, No SC013683.
> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir. SC013683.

-- 
Thomas A. Gerds -- Department of Biostatistics Copenhagen
University of Copenhagen, Oester Farimagsgade 5, 1014 Copenhagen,
Denmark


From michelle.ann.kline at gmail.com  Sat Mar 24 19:15:45 2018
From: michelle.ann.kline at gmail.com (Michelle Kline)
Date: Sat, 24 Mar 2018 18:15:45 +0000
Subject: [R] MCMCglmm multinomial model results
In-Reply-To: <64123A1D-5BB1-4060-B3EE-1F19328B9401@comcast.net>
References: <CAHKF8+MR2qA8Kg-V5cgt5+9MngAazPbrQAN3ANGpA2=enHt9qQ@mail.gmail.com>
 <64123A1D-5BB1-4060-B3EE-1F19328B9401@comcast.net>
Message-ID: <CAHKF8+Mmv-yW7fRKvf18QYZB1xODwL1641P34QiLbNKXRX2nbA@mail.gmail.com>

Hi David,

Thanks for your comment. I haven't posted the data because they are
unpublished and include human subjects so there are issues with sharing on
a list serv, but I thought perhaps someone had encountered a similar
problem and would already know the answer.

I will reconsider whether my University's ethics approval would allow me to
post the data and update the question if I think it is allowable.

Michelle

On Fri, Mar 23, 2018, 10:13 AM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Mar 22, 2018, at 1:31 PM, Michelle Kline <
> michelle.ann.kline at gmail.com> wrote:
> >
> > Hi,
> >
> > Thanks in advance for any help on this question. I'm running multinomial
> > models using the MCMCglmm package. The models have 5 outcome variables
> > (each with count data), and an additional two random effects built into
> the
> > models. The issue is that when I use the following code, the summary only
> > gives me results for four of the outcome variables.
> >
> > Here is the code for my model:
> >
> > m3.random <- MCMCglmm(cbind(Opp_teacher , Dir_teacher, Enh_teacher,
> > SocTol_teacher, Eval_teacher) ~ trait -1,
> >               random = ~ us(trait):other + us(trait):focal,
> >               rcov = ~ us(trait):units,
> >               prior = list(
> >                 R = list(fix=1, V=0.5 * (I + J), n = 4),
> >                 G = list(
> >                   G1 = list(V = diag(4), n = 4),
> >                   G2 = list(V = diag(4), n = 4))),
> >               burnin = burn,
> >               nitt = iter,
> >               family = "multinomial5",
> >               data = data,
>
> We have no way to debug this without the data. Perhaps you should contact
> the maintainer and in your message attach the data?
>
>  maintainer('MCMCglmm')
> [1] "Jarrod Hadfield <j.hadfield at ed.ac.uk>"
>
>
> An equally effective approach would be to post (again with data that
> reproduces the error)  on the R-SIG-mixed-models mailing list since
> Hadfield is a regular contributor on that list. (To me it suggests not an
> error since you got output but rather a warning. Generally warnings and
> errors are properly labeled so you may not have included the full output.)
>
> --
> David.
> >               pr=TRUE,
> >               pl=TRUE,
> >               DIC = TRUE,
> >               verbose = FALSE)
> >
> > And the summary of the main effects:
> >
> > post.mean  l-95% CI  u-95% CI eff.samp        pMCMC
> > traitOpp_teacher    -3.828752 -4.616731 -3.067424 184.4305 5.263158e-05
> > traitDir_teacher    -3.400481 -4.041069 -2.813063 259.1084 5.263158e-05
> > traitEnh_teacher    -1.779129 -2.197415 -1.366496 624.9759 5.263158e-05
> > traitSocTol_teacher -2.852684 -3.429799 -2.332909 468.7098 5.263158e-05
> >
> >
> > It is not an issue of the suppressing the intercept, since I'm already
> > doing that (see the -1 term. When I remove that term, the model solutions
> > includes an intercept and only 3 additional main effects).
> >
> > The model does throw the following error, but after searching previous
> > messages on this list, I've concluded that this error message doesn't
> have
> > to do with  my current problem. Just in case: " observations with zero
> > weight not used for calculating dispersion"
> >
> > I have also posted a similar question on stackoverflow about a week ago,
> > but with no response, so I thought I would try here. Link in case people
> > want to gain reputation points for a
> > response:
> https://stackoverflow.com/questions/49309027/missing-term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue
> > <
> https://stackoverflow.com/questions/49309027/missing-term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue
> >
> >
> > And of course I've checked various other sources including the course
> > notes, but can't make sense of why the 5th term is dropped from the
> model.
> > Any help is much appreciated.
> >
> > Best,
> >
> > Michelle
> >
> > --
> > Michelle A. Kline, PhD
> >
> > Assistant Professor
> > Department of Psychology
> > Simon Fraser University
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sat Mar 24 20:22:03 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sat, 24 Mar 2018 12:22:03 -0700
Subject: [R] MCMCglmm multinomial model results
In-Reply-To: <CAHKF8+Mmv-yW7fRKvf18QYZB1xODwL1641P34QiLbNKXRX2nbA@mail.gmail.com>
References: <CAHKF8+MR2qA8Kg-V5cgt5+9MngAazPbrQAN3ANGpA2=enHt9qQ@mail.gmail.com>
 <64123A1D-5BB1-4060-B3EE-1F19328B9401@comcast.net>
 <CAHKF8+Mmv-yW7fRKvf18QYZB1xODwL1641P34QiLbNKXRX2nbA@mail.gmail.com>
Message-ID: <CAGxFJbR-Pf8Kmh0Mqno41Yvf7gGRUMkgJP5oiSao9Jkt2nRP+A@mail.gmail.com>

Does not the sum of probabilities (on the untransformed scale) = 1, whence
only 4 outcome categories to predict?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Mar 24, 2018 at 11:15 AM, Michelle Kline <
michelle.ann.kline at gmail.com> wrote:

> Hi David,
>
> Thanks for your comment. I haven't posted the data because they are
> unpublished and include human subjects so there are issues with sharing on
> a list serv, but I thought perhaps someone had encountered a similar
> problem and would already know the answer.
>
> I will reconsider whether my University's ethics approval would allow me to
> post the data and update the question if I think it is allowable.
>
> Michelle
>
> On Fri, Mar 23, 2018, 10:13 AM David Winsemius <dwinsemius at comcast.net>
> wrote:
>
> >
> > > On Mar 22, 2018, at 1:31 PM, Michelle Kline <
> > michelle.ann.kline at gmail.com> wrote:
> > >
> > > Hi,
> > >
> > > Thanks in advance for any help on this question. I'm running
> multinomial
> > > models using the MCMCglmm package. The models have 5 outcome variables
> > > (each with count data), and an additional two random effects built into
> > the
> > > models. The issue is that when I use the following code, the summary
> only
> > > gives me results for four of the outcome variables.
> > >
> > > Here is the code for my model:
> > >
> > > m3.random <- MCMCglmm(cbind(Opp_teacher , Dir_teacher, Enh_teacher,
> > > SocTol_teacher, Eval_teacher) ~ trait -1,
> > >               random = ~ us(trait):other + us(trait):focal,
> > >               rcov = ~ us(trait):units,
> > >               prior = list(
> > >                 R = list(fix=1, V=0.5 * (I + J), n = 4),
> > >                 G = list(
> > >                   G1 = list(V = diag(4), n = 4),
> > >                   G2 = list(V = diag(4), n = 4))),
> > >               burnin = burn,
> > >               nitt = iter,
> > >               family = "multinomial5",
> > >               data = data,
> >
> > We have no way to debug this without the data. Perhaps you should contact
> > the maintainer and in your message attach the data?
> >
> >  maintainer('MCMCglmm')
> > [1] "Jarrod Hadfield <j.hadfield at ed.ac.uk>"
> >
> >
> > An equally effective approach would be to post (again with data that
> > reproduces the error)  on the R-SIG-mixed-models mailing list since
> > Hadfield is a regular contributor on that list. (To me it suggests not an
> > error since you got output but rather a warning. Generally warnings and
> > errors are properly labeled so you may not have included the full
> output.)
> >
> > --
> > David.
> > >               pr=TRUE,
> > >               pl=TRUE,
> > >               DIC = TRUE,
> > >               verbose = FALSE)
> > >
> > > And the summary of the main effects:
> > >
> > > post.mean  l-95% CI  u-95% CI eff.samp        pMCMC
> > > traitOpp_teacher    -3.828752 -4.616731 -3.067424 184.4305 5.263158e-05
> > > traitDir_teacher    -3.400481 -4.041069 -2.813063 259.1084 5.263158e-05
> > > traitEnh_teacher    -1.779129 -2.197415 -1.366496 624.9759 5.263158e-05
> > > traitSocTol_teacher -2.852684 -3.429799 -2.332909 468.7098 5.263158e-05
> > >
> > >
> > > It is not an issue of the suppressing the intercept, since I'm already
> > > doing that (see the -1 term. When I remove that term, the model
> solutions
> > > includes an intercept and only 3 additional main effects).
> > >
> > > The model does throw the following error, but after searching previous
> > > messages on this list, I've concluded that this error message doesn't
> > have
> > > to do with  my current problem. Just in case: " observations with zero
> > > weight not used for calculating dispersion"
> > >
> > > I have also posted a similar question on stackoverflow about a week
> ago,
> > > but with no response, so I thought I would try here. Link in case
> people
> > > want to gain reputation points for a
> > > response:
> > https://stackoverflow.com/questions/49309027/missing-
> term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue
> > > <
> > https://stackoverflow.com/questions/49309027/missing-
> term-in-mcmcglmm-multinomial-model-results-not-in-intercept-issue
> > >
> > >
> > > And of course I've checked various other sources including the course
> > > notes, but can't make sense of why the 5th term is dropped from the
> > model.
> > > Any help is much appreciated.
> > >
> > > Best,
> > >
> > > Michelle
> > >
> > > --
> > > Michelle A. Kline, PhD
> > >
> > > Assistant Professor
> > > Department of Psychology
> > > Simon Fraser University
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
> >  -Gehm's Corollary to Clarke's Third Law
> >
> >
> >
> >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From lucam1968 at gmail.com  Sat Mar 24 22:03:42 2018
From: lucam1968 at gmail.com (Luca Meyer)
Date: Sat, 24 Mar 2018 22:03:42 +0100
Subject: [R] How to integrate a dynamic code within a R script?
Message-ID: <CABQyo84r2M8rVPCm=cvVqjxVr4K5prPLTmqkYh9SFzi7KEL=dg@mail.gmail.com>

Hi,

I am working on a script which should includes a dynamic listing, i.e.

# SCRIPT BEGINS

# some R procedures here

# DYNAMIC PART BEGINS
d1$X5 <-f1("AAA")
d1$X5 <-f1("AAa")
d1$X5 <-f1("ABa")
# etc...
d1$X6 <-f2("AAA")
d1$X6 <-f2("AAs")
d1$X6 <-f2("ABs")
# etc...
# DYNAMIC PART ENDS

# other procedures here

# SCRIPT ENDS

Basically I have an Excel page with a quite long listing of "AAA", "AAa",
"ABa", "ccc", "Ded", etc, one entry on each line. The listing is likely to
change over time and the script will run at least once a day.

My initial planning was to do something like

f1 <- read.xlsx("LIST.xlsx",1, startRow=2, colNames = F)
f1$X2 <- paste('d1$X5 <-f1("',f1$X1,'")', sep='')
f1$X3 <- paste('d1$X6 <-f2("',f1$X1,'")', sep='')

and I obtain something like
   X1               X2                X3
1 AAA d1$X5 <-f1("AAA") d1$X6 <-f2("AAA")
2 AAa d1$X5 <-f1("AAa") d1$X6 <-f2("AAs")
3 ABa d1$X5 <-f1("ABa") d1$X6 <-f2("ABs")

How can I integrate the above in the DYNAMIC PART of my script above? I am
sure there is a pretty simple solution but I seem not to get around to it.

Thanks,

Luca

	[[alternative HTML version deleted]]


From mscbuysell at gmail.com  Sun Mar 25 01:03:44 2018
From: mscbuysell at gmail.com (M Can)
Date: Sat, 24 Mar 2018 20:03:44 -0400
Subject: [R] Get Specific Records from Another DataFrame
Message-ID: <CAJS8sMP3xXHK=oA71yZkSk3_+qw1x1pwFiUEVBAO7A+7216ptQ@mail.gmail.com>

Hello
I have been struggling with this simple looking problem. I have two
dataframes. The first one contains ID, date, and revenue information for
specific suppliers.

id lastdate depvar
A 5/10/2017 10
B 8/16/2017 20
C 2/14/2017 30
D 9/5/2017 40
E 8/1/2017 50
F 11/4/2017 60
G 6/22/2017 70
The second dataframe contains timeseries data of each supplier in different
columns. For example Column A are the transaction dates of supplier A and
A_indvar is an independent variable value for each date.

A_date A_indvar B_date B_indvar ?
1/1/2017 49 2/5/2017 50
1/2/2017 42 2/6/2017 62
1/3/2017 10 2/7/2017 88
1/4/2017 37 2/8/2017 36
1/5/2017 84 2/9/2017 71
1/6/2017 47 2/10/2017 36
1/7/2017 91 2/11/2017 98
Now, I would like to run a regression equation using specific independent
variable values from the second dataset. For example, let say I want to
look at the independent variable values of each supplier 30 days before the
last date given in the first dataset. I want to locate those from the
second dataset and enter them into the first dataset. So that the first
dataset will look like:

id lastdate depvar indvar-30
A 5/10/2017 10 55
B 8/16/2017 20 62
C 2/14/2017 30 74
D 9/5/2017 40 45
E 8/1/2017 50 35
F 11/4/2017 60 56
G 6/22/2017 70 48
I am able to create an array that takes all last dates and then subtracts
30 from them. Then how can I go to the second table and grab the value of
the independent variables for those specific dates? Timeseries of the
suppliers have different start dates.

I feel like I need to use something similar to vlookup in Excel. But a
value in the first dataset (let's say Supplier A) becomes a variable name
in dataset two.

Any hint is appreciated.

Thank you.

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Sun Mar 25 08:25:47 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sat, 24 Mar 2018 23:25:47 -0700
Subject: [R] Get Specific Records from Another DataFrame
In-Reply-To: <CAJS8sMP3xXHK=oA71yZkSk3_+qw1x1pwFiUEVBAO7A+7216ptQ@mail.gmail.com>
References: <CAJS8sMP3xXHK=oA71yZkSk3_+qw1x1pwFiUEVBAO7A+7216ptQ@mail.gmail.com>
Message-ID: <5A25BD78-0926-455C-B480-D5885C4CEE36@dcn.davis.ca.us>

I suggest that you read the vignette for the data table package. That package uses some odd syntax compared to base R but has some features designed especially for these kinds of problems. 
-- 
Sent from my phone. Please excuse my brevity.

On March 24, 2018 5:03:44 PM PDT, M Can <mscbuysell at gmail.com> wrote:
>Hello
>I have been struggling with this simple looking problem. I have two
>dataframes. The first one contains ID, date, and revenue information
>for
>specific suppliers.
>
>id lastdate depvar
>A 5/10/2017 10
>B 8/16/2017 20
>C 2/14/2017 30
>D 9/5/2017 40
>E 8/1/2017 50
>F 11/4/2017 60
>G 6/22/2017 70
>The second dataframe contains timeseries data of each supplier in
>different
>columns. For example Column A are the transaction dates of supplier A
>and
>A_indvar is an independent variable value for each date.
>
>A_date A_indvar B_date B_indvar ?
>1/1/2017 49 2/5/2017 50
>1/2/2017 42 2/6/2017 62
>1/3/2017 10 2/7/2017 88
>1/4/2017 37 2/8/2017 36
>1/5/2017 84 2/9/2017 71
>1/6/2017 47 2/10/2017 36
>1/7/2017 91 2/11/2017 98
>Now, I would like to run a regression equation using specific
>independent
>variable values from the second dataset. For example, let say I want to
>look at the independent variable values of each supplier 30 days before
>the
>last date given in the first dataset. I want to locate those from the
>second dataset and enter them into the first dataset. So that the first
>dataset will look like:
>
>id lastdate depvar indvar-30
>A 5/10/2017 10 55
>B 8/16/2017 20 62
>C 2/14/2017 30 74
>D 9/5/2017 40 45
>E 8/1/2017 50 35
>F 11/4/2017 60 56
>G 6/22/2017 70 48
>I am able to create an array that takes all last dates and then
>subtracts
>30 from them. Then how can I go to the second table and grab the value
>of
>the independent variables for those specific dates? Timeseries of the
>suppliers have different start dates.
>
>I feel like I need to use something similar to vlookup in Excel. But a
>value in the first dataset (let's say Supplier A) becomes a variable
>name
>in dataset two.
>
>Any hint is appreciated.
>
>Thank you.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From milujisb at gmail.com  Sun Mar 25 16:48:25 2018
From: milujisb at gmail.com (Miluji Sb)
Date: Sun, 25 Mar 2018 16:48:25 +0200
Subject: [R] Take average of previous weeks
Message-ID: <CAMLwc7Pd2HGPRwe1PiOFPN56FkyfiCZdBUOwSK5GxfbVDzSL9g@mail.gmail.com>

Dear all,

I have weekly data by city (variable citycode). I would like to take the
average of the previous two, three, four weeks (without the current week)
of the variable called value.

This is what I have tried to compute the average of the two previous weeks;

df = df %>%
  mutate(value.lag1 = lag(value, n = 1)) %>%
  mutate(value .2.previous = rollapply(data = value.lag1,
                                     width = 2,
                                     FUN = mean,
                                     align = "right",
                                     fill = NA,
                                     na.rm = T))

I crated the lag of the variable first and then attempted to compute the
average but this does not seem to to what I want. What I am doing wrong?
Any help will be appreciated. The data is below. Thank you.

Sincerely,

Milu

dput(droplevels(head(df, 10)))
structure(list(year = c(1970L, 1970L, 1970L, 1970L, 1970L, 1970L,
1970L, 1970L, 1970L, 1970L), citycode = c(1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L), month = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
2L, 3L), week = c(1L, 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), date =
structure(c(1L,
2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), .Label = c("1970-01-10",
"1970-01-17", "1970-01-24", "1970-01-31", "1970-02-07", "1970-02-14",
"1970-02-21", "1970-02-28", "1970-03-07"), class = "factor"),
    value = c(-15.035, -20.478, -22.245, -23.576, -8.84099999999995,
    -18.497, -13.892, -18.974, -15.919, -13.576)), .Names = c("year",
"citycode", "month", "week", "date", "tmin"), row.names = c(NA,
10L), class = "data.frame")

	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Sun Mar 25 17:07:02 2018
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 25 Mar 2018 11:07:02 -0400
Subject: [R] Take average of previous weeks
In-Reply-To: <CAMLwc7Pd2HGPRwe1PiOFPN56FkyfiCZdBUOwSK5GxfbVDzSL9g@mail.gmail.com>
References: <CAMLwc7Pd2HGPRwe1PiOFPN56FkyfiCZdBUOwSK5GxfbVDzSL9g@mail.gmail.com>
Message-ID: <CAP01uRnrkZkk0ii6UueS0dr0dkvVeYwXEK-mp-bpRgxdNT5O5g@mail.gmail.com>

There is no  `value` column in the `dput` output shown in the
question so using `tmin` instead note that the `width=` argument
of `rollapply` can be a list containing a vector of offsets (-1 is prior
value, -2 is value before that, etc.) and that we can use `rollapplyr`
with an `r` on the end to get right alignment.  See `?rollapply`

  library(dplyr)
  library(zoo)

  roll <- function(x, k) rollapplyr(x, list(-seq(1:k)), mean, fill = NA)
  df %>%
      group_by(citycode) %>%
      mutate(mean2 = roll(tmin, 2), mean3 = roll(tmin, 3), mean4 =
roll(tmin, 4)) %>%
      ungroup

(The code above has been indented 2 spaces so you can
identify inadvertent line wrapping by the email system.)


On Sun, Mar 25, 2018 at 10:48 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear all,
>
> I have weekly data by city (variable citycode). I would like to take the
> average of the previous two, three, four weeks (without the current week)
> of the variable called value.
>
> This is what I have tried to compute the average of the two previous weeks;
>
> df = df %>%
>   mutate(value.lag1 = lag(value, n = 1)) %>%
>   mutate(value .2.previous = rollapply(data = value.lag1,
>                                      width = 2,
>                                      FUN = mean,
>                                      align = "right",
>                                      fill = NA,
>                                      na.rm = T))
>
> I crated the lag of the variable first and then attempted to compute the
> average but this does not seem to to what I want. What I am doing wrong?
> Any help will be appreciated. The data is below. Thank you.
>
> Sincerely,
>
> Milu
>
> dput(droplevels(head(df, 10)))
> structure(list(year = c(1970L, 1970L, 1970L, 1970L, 1970L, 1970L,
> 1970L, 1970L, 1970L, 1970L), citycode = c(1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L), month = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L, 3L), week = c(1L, 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), date =
> structure(c(1L,
> 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), .Label = c("1970-01-10",
> "1970-01-17", "1970-01-24", "1970-01-31", "1970-02-07", "1970-02-14",
> "1970-02-21", "1970-02-28", "1970-03-07"), class = "factor"),
>     value = c(-15.035, -20.478, -22.245, -23.576, -8.84099999999995,
>     -18.497, -13.892, -18.974, -15.919, -13.576)), .Names = c("year",
> "citycode", "month", "week", "date", "tmin"), row.names = c(NA,
> 10L), class = "data.frame")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ramesh.yapalparvi at icloud.com  Sun Mar 25 16:53:19 2018
From: ramesh.yapalparvi at icloud.com (Ramesh YAPALPARVI)
Date: Sun, 25 Mar 2018 14:53:19 +0000 (GMT)
Subject: [R] Medical risk package calculation RSI
Message-ID: <d5161cef-cbf5-4e4c-a1c0-6f077ef620b0@me.com>

Hi all,



I'm using the medical risk package to determine the risk stratification Index based on the ICD9 codes. Although, I have been successful in using it, I'm unable to interpret the output.



here is the sample code



# Calculate RSI for each patient ("id") in dataframe


cases <- data.frame(id=c(1,1,1,2,2,2,2,2),
+                     icd9cm=c("D4019","D25000","DV707","D71945","DV4365","D78079","D70909","D1958"))


library(plyr)
ddply(cases, .(id), function(x) { icd9cm_sessler_rsi(x$icd9cm) } )




Output:

id rsi_1yrpod rsi_30dlos rsi_30dpod rsi_inhosp
1  1 -0.2860474  1.2481208 -0.5722244 -0.2612804
2  2  0.1417417  0.9779779 -1.0318395  0.0000000

Could anyone please help me?

Thanks,
Ramesh

From dwinsemius at comcast.net  Sun Mar 25 18:37:03 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 25 Mar 2018 09:37:03 -0700
Subject: [R] Medical risk package calculation RSI
In-Reply-To: <d5161cef-cbf5-4e4c-a1c0-6f077ef620b0@me.com>
References: <d5161cef-cbf5-4e4c-a1c0-6f077ef620b0@me.com>
Message-ID: <FA8ED6C9-32C2-44BA-8D6F-1CB293061236@comcast.net>


> On Mar 25, 2018, at 7:53 AM, Ramesh YAPALPARVI <ramesh.yapalparvi at icloud.com> wrote:
> 
> Hi all,
> 
> 
> 
> I'm using the medical risk package to determine the risk stratification Index based on the ICD9 codes. Although, I have been successful in using it, I'm unable to interpret the output.
> 
> 
> 
> here is the sample code
> 
> 
> 
> # Calculate RSI for each patient ("id") in dataframe
> 
> 
> cases <- data.frame(id=c(1,1,1,2,2,2,2,2),
> +                     icd9cm=c("D4019","D25000","DV707","D71945","DV4365","D78079","D70909","D1958"))
> 
> 
> library(plyr)
> ddply(cases, .(id), function(x) { icd9cm_sessler_rsi(x$icd9cm) } )
> 
> 
> 
> 
> Output:
> 
> id rsi_1yrpod rsi_30dlos rsi_30dpod rsi_inhosp
> 1  1 -0.2860474  1.2481208 -0.5722244 -0.2612804
> 2  2  0.1417417  0.9779779 -1.0318395  0.0000000
> 
> Could anyone please help me?

That is just the code and error-free output from the help page for `icd9cm_sessler_rsi`.

Your posting does not actually conform to the rhelp mailing list standards since there is no illustrated problem with the use of the R language and rhelp is not designed to fill in gaps in your understanding of health services research methods. Have you read through and more importantly "worked through" the two vignettes that ship with that package? The readers of this list might be more motivated if you had presented evidence that you had made a good faith effort with the material that had been already made available to you.

vignette(pac='medicalrisk')

Vignettes in package ?medicalrisk?:

medicalrisk              medicalrisk: Calculating risk and comorbidities
                         from ICD-9-CM codes (source, html)
advanced                 medicalrisk: Correlating ICU days with mortality
                         risk and comorbidities (source, html)

Once you have made an effort to "do your own homework", you might be in a position to construct a more substantial and more specific question for a venue where this might be more on-topic, perhaps CrossValidated.com <https://stats.stackexchange.com/>
-- 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From nicholas.wray at ntlworld.com  Sun Mar 25 21:55:33 2018
From: nicholas.wray at ntlworld.com (WRAY NICHOLAS)
Date: Sun, 25 Mar 2018 20:55:33 +0100 (BST)
Subject: [R] Limit in Directory Hierarchy?
Message-ID: <1689416306.119940.1522007733212@mail2.virginmedia.com>

A quick question - is there a limit to the number of levels one can go down when setting the directory in R studio?
I ask because I have been trying to set the directory to a folder 8 levels down which R studio won't allow, and when I try to set the directory through Session/Set Working Directory, it won't even show the lowest level folder:

setwd("C:/Users/supermollusc/Desktop/151017 Shellfish/Mussel Months/Mussel Mar 18/0318.data")

but it's quite happy to set the directory at 7 levels

setwd("C:/Users/supermollusc/Desktop/151017 Shellfish/Mussel Months/Mussel Mar 18")

I can't see why it won't do this if there isn't a hierarchy level limit but I can't find reference to one on the net

Thanks

Nick Wray

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Sun Mar 25 22:05:11 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Sun, 25 Mar 2018 13:05:11 -0700
Subject: [R] Take average of previous weeks
In-Reply-To: <CAMLwc7Pd2HGPRwe1PiOFPN56FkyfiCZdBUOwSK5GxfbVDzSL9g@mail.gmail.com>
References: <CAMLwc7Pd2HGPRwe1PiOFPN56FkyfiCZdBUOwSK5GxfbVDzSL9g@mail.gmail.com>
Message-ID: <CAGxFJbTsFTEUinCjGFxOOumj8XWCe8CetsRDM1Ai9j3Ug6qCuw@mail.gmail.com>

I am sure that this sort of thing has been asked and answered before,
so in case my suggestions don't work for you, just search the archives
a bit more.
I am also sure that it can be handled directly by numerous functions
in numerous packages, e.g. via time series methods or by calculating
running means of suitably shifted series.

However, as it seems to be a straightforward task, I'll provide what I
think is a simple solution in base R. Adjust to your situation.

## First I need a little utility function to offset rows. Lots of ways
to do this,many nicer than this I'm sure.

> shift <- function(x,k)
+    ## x is a vector of values -- e.g. of a column in your df
+ {
+    sapply(seq_len(k),function(i)c(rep(NA,i),head(x,-i)))
+ }
>
>
> ## Testit
> x <- c(1,3,5,7,8:11)
> m <- shift(x,3) ## matrix of prior values up to lag 3
> m ## note rows have been omitted where lags don't exist
     [,1] [,2] [,3]
[1,]   NA   NA   NA
[2,]    1   NA   NA
[3,]    3    1   NA
[4,]    5    3    1
[5,]    7    5    3
[6,]    8    7    5
[7,]    9    8    7
[8,]   10    9    8
> rowMeans(m) ## means of previous 3
[1]       NA       NA       NA 3.000000 5.000000 6.666667 8.000000 9.000000
> rowMeans(m[,1:2]) ## means of previous 2
[1]  NA  NA 2.0 4.0 6.0 7.5 8.5 9.5


Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Sun, Mar 25, 2018 at 7:48 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear all,
>
> I have weekly data by city (variable citycode). I would like to take the
> average of the previous two, three, four weeks (without the current week)
> of the variable called value.
>
> This is what I have tried to compute the average of the two previous weeks;
>
> df = df %>%
>   mutate(value.lag1 = lag(value, n = 1)) %>%
>   mutate(value .2.previous = rollapply(data = value.lag1,
>                                      width = 2,
>                                      FUN = mean,
>                                      align = "right",
>                                      fill = NA,
>                                      na.rm = T))
>
> I crated the lag of the variable first and then attempted to compute the
> average but this does not seem to to what I want. What I am doing wrong?
> Any help will be appreciated. The data is below. Thank you.
>
> Sincerely,
>
> Milu
>
> dput(droplevels(head(df, 10)))
> structure(list(year = c(1970L, 1970L, 1970L, 1970L, 1970L, 1970L,
> 1970L, 1970L, 1970L, 1970L), citycode = c(1L, 1L, 1L, 1L, 1L,
> 1L, 1L, 1L, 1L, 1L), month = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> 2L, 3L), week = c(1L, 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), date =
> structure(c(1L,
> 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), .Label = c("1970-01-10",
> "1970-01-17", "1970-01-24", "1970-01-31", "1970-02-07", "1970-02-14",
> "1970-02-21", "1970-02-28", "1970-03-07"), class = "factor"),
>     value = c(-15.035, -20.478, -22.245, -23.576, -8.84099999999995,
>     -18.497, -13.892, -18.974, -15.919, -13.576)), .Names = c("year",
> "citycode", "month", "week", "date", "tmin"), row.names = c(NA,
> 10L), class = "data.frame")
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.ca.us  Mon Mar 26 03:32:36 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Sun, 25 Mar 2018 18:32:36 -0700
Subject: [R] Limit in Directory Hierarchy?
In-Reply-To: <1689416306.119940.1522007733212@mail2.virginmedia.com>
References: <1689416306.119940.1522007733212@mail2.virginmedia.com>
Message-ID: <B323C903-5150-4CEE-84B4-1365C7A83514@dcn.davis.ca.us>

This is the wrong place to ask what RStudio can or cannot do. However, if your question is about R you should try invoking your reproducible example in RGui or the command line R.exe before posting here. 

R has no directory depth limit. There is an operating system limit on returning paths more than 260 characters long, and this seems to create problems sometimes (Google it). You might also look at operating system permissions for the "0318.data" directory. 

-- 
Sent from my phone. Please excuse my brevity.

On March 25, 2018 12:55:33 PM PDT, WRAY NICHOLAS via R-help <r-help at r-project.org> wrote:
>A quick question - is there a limit to the number of levels one can go
>down when setting the directory in R studio?
>I ask because I have been trying to set the directory to a folder 8
>levels down which R studio won't allow, and when I try to set the
>directory through Session/Set Working Directory, it won't even show the
>lowest level folder:
>
>setwd("C:/Users/supermollusc/Desktop/151017 Shellfish/Mussel
>Months/Mussel Mar 18/0318.data")
>
>but it's quite happy to set the directory at 7 levels
>
>setwd("C:/Users/supermollusc/Desktop/151017 Shellfish/Mussel
>Months/Mussel Mar 18")
>
>I can't see why it won't do this if there isn't a hierarchy level limit
>but I can't find reference to one on the net
>
>Thanks
>
>Nick Wray
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ziad.elmously at kantar.com  Mon Mar 26 08:51:36 2018
From: ziad.elmously at kantar.com (Elmously, Ziad (TSHHM))
Date: Mon, 26 Mar 2018 06:51:36 +0000
Subject: [R] "dlm" Package: Calculating State Confidence Intervals
Message-ID: <VI1PR01MB108874FA2AD4E3518864B9CB96AD0@VI1PR01MB1088.eurprd01.prod.exchangelabs.com>

To Whom It May Concern,

I estimated a model with 6 states (3 time-varying Regression parameters and 3 quarterly seasonality trends).  The model is saved in the object titled "mod."

Following the example in the documentation and using the commands below, I am attempting to use the function "dlmSvd2var" to implement SVD and calculate the 90% confidence errors for each time-varying state.

outF <- dlmFilter(y,mod)
v <- unlist(dlmSvd2var(outF$U.C, outF$D.C))
pl <- dropFirst(outF$m) + qnorm(0.05, sd=sqrt(v[-1]))
pu <- dropFirst(outF$m) + qnorm(0.95, sd=sqrt(v[-1]))

Since the dataset has 100 observations, I end up with a vector v that comprises 3636 atomic components: (1 + 100) x (6 x 6).  If I discard the 1st 36 of them, then v comprises 3600 atomic components.  The question is how to extract the variance of each state (6 states) in the 36 atomic components representing each time (1:100).

Said differently, how do I extract the variance of each state (6 states) in the 6 x 6 matrix generated by the "dlmDvd2var" function in time t?  Is this information provided in the diagonal elements, element (1,1) for state 1, element (2,2) for state 2, and so on?

Thank you in advance.

Ziad Elmously



Kantar Disclaimer<http://www.kantar.com/disclaimer.html>

	[[alternative HTML version deleted]]


From milujisb at gmail.com  Mon Mar 26 15:22:36 2018
From: milujisb at gmail.com (Miluji Sb)
Date: Mon, 26 Mar 2018 15:22:36 +0200
Subject: [R] Take average of previous weeks
In-Reply-To: <CAGxFJbTsFTEUinCjGFxOOumj8XWCe8CetsRDM1Ai9j3Ug6qCuw@mail.gmail.com>
References: <CAMLwc7Pd2HGPRwe1PiOFPN56FkyfiCZdBUOwSK5GxfbVDzSL9g@mail.gmail.com>
 <CAGxFJbTsFTEUinCjGFxOOumj8XWCe8CetsRDM1Ai9j3Ug6qCuw@mail.gmail.com>
Message-ID: <CAMLwc7N8tugqOL4jxY_rDt4o2r5K6fm0k9ANRR-m4mvp20nfuw@mail.gmail.com>

Dear Bert,

Thank you very much.This works. I was wondering if the fact that I want to
create new variables (sorry for not stating that fact) makes any
difference? Thank you again.

Sincerely,

Milu

On Sun, Mar 25, 2018 at 10:05 PM, Bert Gunter <bgunter.4567 at gmail.com>
wrote:

> I am sure that this sort of thing has been asked and answered before,
> so in case my suggestions don't work for you, just search the archives
> a bit more.
> I am also sure that it can be handled directly by numerous functions
> in numerous packages, e.g. via time series methods or by calculating
> running means of suitably shifted series.
>
> However, as it seems to be a straightforward task, I'll provide what I
> think is a simple solution in base R. Adjust to your situation.
>
> ## First I need a little utility function to offset rows. Lots of ways
> to do this,many nicer than this I'm sure.
>
> > shift <- function(x,k)
> +    ## x is a vector of values -- e.g. of a column in your df
> + {
> +    sapply(seq_len(k),function(i)c(rep(NA,i),head(x,-i)))
> + }
> >
> >
> > ## Testit
> > x <- c(1,3,5,7,8:11)
> > m <- shift(x,3) ## matrix of prior values up to lag 3
> > m ## note rows have been omitted where lags don't exist
>      [,1] [,2] [,3]
> [1,]   NA   NA   NA
> [2,]    1   NA   NA
> [3,]    3    1   NA
> [4,]    5    3    1
> [5,]    7    5    3
> [6,]    8    7    5
> [7,]    9    8    7
> [8,]   10    9    8
> > rowMeans(m) ## means of previous 3
> [1]       NA       NA       NA 3.000000 5.000000 6.666667 8.000000 9.000000
> > rowMeans(m[,1:2]) ## means of previous 2
> [1]  NA  NA 2.0 4.0 6.0 7.5 8.5 9.5
>
>
> Cheers,
> Bert
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Sun, Mar 25, 2018 at 7:48 AM, Miluji Sb <milujisb at gmail.com> wrote:
> > Dear all,
> >
> > I have weekly data by city (variable citycode). I would like to take the
> > average of the previous two, three, four weeks (without the current week)
> > of the variable called value.
> >
> > This is what I have tried to compute the average of the two previous
> weeks;
> >
> > df = df %>%
> >   mutate(value.lag1 = lag(value, n = 1)) %>%
> >   mutate(value .2.previous = rollapply(data = value.lag1,
> >                                      width = 2,
> >                                      FUN = mean,
> >                                      align = "right",
> >                                      fill = NA,
> >                                      na.rm = T))
> >
> > I crated the lag of the variable first and then attempted to compute the
> > average but this does not seem to to what I want. What I am doing wrong?
> > Any help will be appreciated. The data is below. Thank you.
> >
> > Sincerely,
> >
> > Milu
> >
> > dput(droplevels(head(df, 10)))
> > structure(list(year = c(1970L, 1970L, 1970L, 1970L, 1970L, 1970L,
> > 1970L, 1970L, 1970L, 1970L), citycode = c(1L, 1L, 1L, 1L, 1L,
> > 1L, 1L, 1L, 1L, 1L), month = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
> > 2L, 3L), week = c(1L, 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), date =
> > structure(c(1L,
> > 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), .Label = c("1970-01-10",
> > "1970-01-17", "1970-01-24", "1970-01-31", "1970-02-07", "1970-02-14",
> > "1970-02-21", "1970-02-28", "1970-03-07"), class = "factor"),
> >     value = c(-15.035, -20.478, -22.245, -23.576, -8.84099999999995,
> >     -18.497, -13.892, -18.974, -15.919, -13.576)), .Names = c("year",
> > "citycode", "month", "week", "date", "tmin"), row.names = c(NA,
> > 10L), class = "data.frame")
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Mon Mar 26 16:37:06 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Mon, 26 Mar 2018 07:37:06 -0700
Subject: [R] Take average of previous weeks
In-Reply-To: <CAMLwc7N8tugqOL4jxY_rDt4o2r5K6fm0k9ANRR-m4mvp20nfuw@mail.gmail.com>
References: <CAMLwc7Pd2HGPRwe1PiOFPN56FkyfiCZdBUOwSK5GxfbVDzSL9g@mail.gmail.com>
 <CAGxFJbTsFTEUinCjGFxOOumj8XWCe8CetsRDM1Ai9j3Ug6qCuw@mail.gmail.com>
 <CAMLwc7N8tugqOL4jxY_rDt4o2r5K6fm0k9ANRR-m4mvp20nfuw@mail.gmail.com>
Message-ID: <CAGxFJbSs5xfm1bFaeaNtogTQ8kN-SdV3DzBk3_XVwj79ensXGg@mail.gmail.com>

The row means **are** new variables and can be put wherever you like.
But all columns in a data frame **must** have the same number of rows,
so you'll have to fill in missing values as appropriate. That's where
you need to "adjust as necessary to your needs."

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Mon, Mar 26, 2018 at 6:22 AM, Miluji Sb <milujisb at gmail.com> wrote:
> Dear Bert,
>
> Thank you very much.This works. I was wondering if the fact that I want to
> create new variables (sorry for not stating that fact) makes any difference?
> Thank you again.
>
> Sincerely,
>
> Milu
>
> On Sun, Mar 25, 2018 at 10:05 PM, Bert Gunter <bgunter.4567 at gmail.com>
> wrote:
>>
>> I am sure that this sort of thing has been asked and answered before,
>> so in case my suggestions don't work for you, just search the archives
>> a bit more.
>> I am also sure that it can be handled directly by numerous functions
>> in numerous packages, e.g. via time series methods or by calculating
>> running means of suitably shifted series.
>>
>> However, as it seems to be a straightforward task, I'll provide what I
>> think is a simple solution in base R. Adjust to your situation.
>>
>> ## First I need a little utility function to offset rows. Lots of ways
>> to do this,many nicer than this I'm sure.
>>
>> > shift <- function(x,k)
>> +    ## x is a vector of values -- e.g. of a column in your df
>> + {
>> +    sapply(seq_len(k),function(i)c(rep(NA,i),head(x,-i)))
>> + }
>> >
>> >
>> > ## Testit
>> > x <- c(1,3,5,7,8:11)
>> > m <- shift(x,3) ## matrix of prior values up to lag 3
>> > m ## note rows have been omitted where lags don't exist
>>      [,1] [,2] [,3]
>> [1,]   NA   NA   NA
>> [2,]    1   NA   NA
>> [3,]    3    1   NA
>> [4,]    5    3    1
>> [5,]    7    5    3
>> [6,]    8    7    5
>> [7,]    9    8    7
>> [8,]   10    9    8
>> > rowMeans(m) ## means of previous 3
>> [1]       NA       NA       NA 3.000000 5.000000 6.666667 8.000000
>> 9.000000
>> > rowMeans(m[,1:2]) ## means of previous 2
>> [1]  NA  NA 2.0 4.0 6.0 7.5 8.5 9.5
>>
>>
>> Cheers,
>> Bert
>>
>>
>>
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along
>> and sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>>
>> On Sun, Mar 25, 2018 at 7:48 AM, Miluji Sb <milujisb at gmail.com> wrote:
>> > Dear all,
>> >
>> > I have weekly data by city (variable citycode). I would like to take the
>> > average of the previous two, three, four weeks (without the current
>> > week)
>> > of the variable called value.
>> >
>> > This is what I have tried to compute the average of the two previous
>> > weeks;
>> >
>> > df = df %>%
>> >   mutate(value.lag1 = lag(value, n = 1)) %>%
>> >   mutate(value .2.previous = rollapply(data = value.lag1,
>> >                                      width = 2,
>> >                                      FUN = mean,
>> >                                      align = "right",
>> >                                      fill = NA,
>> >                                      na.rm = T))
>> >
>> > I crated the lag of the variable first and then attempted to compute the
>> > average but this does not seem to to what I want. What I am doing wrong?
>> > Any help will be appreciated. The data is below. Thank you.
>> >
>> > Sincerely,
>> >
>> > Milu
>> >
>> > dput(droplevels(head(df, 10)))
>> > structure(list(year = c(1970L, 1970L, 1970L, 1970L, 1970L, 1970L,
>> > 1970L, 1970L, 1970L, 1970L), citycode = c(1L, 1L, 1L, 1L, 1L,
>> > 1L, 1L, 1L, 1L, 1L), month = c(1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L,
>> > 2L, 3L), week = c(1L, 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), date =
>> > structure(c(1L,
>> > 2L, 3L, 4L, 5L, 5L, 6L, 7L, 8L, 9L), .Label = c("1970-01-10",
>> > "1970-01-17", "1970-01-24", "1970-01-31", "1970-02-07", "1970-02-14",
>> > "1970-02-21", "1970-02-28", "1970-03-07"), class = "factor"),
>> >     value = c(-15.035, -20.478, -22.245, -23.576, -8.84099999999995,
>> >     -18.497, -13.892, -18.974, -15.919, -13.576)), .Names = c("year",
>> > "citycode", "month", "week", "date", "tmin"), row.names = c(NA,
>> > 10L), class = "data.frame")
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>
>


From jocpaine at googlemail.com  Mon Mar 26 12:40:40 2018
From: jocpaine at googlemail.com (Jocelyn Ireson-Paine)
Date: Mon, 26 Mar 2018 11:40:40 +0100
Subject: [R] Using R and the Tidyverse for an economic model
Message-ID: <CAOdhVrFTGPi19d6KU9z249r_SHp+7AYLc114YR7aOFCUXuPu9w@mail.gmail.com>

I've been translating an economic model from Python into R, and I thought
members of the list would like to see a presentation I've written about it.
I've blogged this at
http://www.j-paine.org/blog/2018/03/r-taxben-a-microsimulation-economic-model-in-r.html
, and the presentation itself is a slideshow at
http://www.j-paine.org/rtaxben/R/reveal/rtaxben.html . The slideshow is
written as one side of a conversation which reveals R and the Tidyverse a
feature at a time to a colleague not familiar with R. Those who _are_
familar with R might prefer the version at
http://www.j-paine.org/rtaxben/R/reveal/rtaxben_anim.html . Exactly the
same material, but, as explained in my introduction, quicker to read. Read
the blog post first.

Our model, R-Taxben, is a microeconomic model, which simulates at the level
of individual people rather than bulk variables such as unemployment and
inflation. It works, roughly speaking, by reading survey data about actual
households, then applying taxes and benefits to calculate net income and
expenditure from gross. It has four main parts: (1) read and process
parameters which describe the taxes and benefits; (2) read the household
data from CSV files and transform into data frames usable by the model; (3)
apply the taxes and benefits, calculating such things as council tax, VAT,
child benefit, and pensions; (4) display the results.

My slides are mainly about (2) and (4), but do touch on the others. I
suggest, for example, that legible R code for (3) could be used as a
"reference standard" against which to describe the notoriously complex UK
benefits system. Organisations such as the Child Poverty Action Group have
written handbooks for benefits advisers which try to specify the system
precisely. We'd like to use R for an electronic version of these.

I've said quite a bit about R for probing and plotting data. Not only for
economists, but for students learning about economics, fiscal policy, and
statistics. And after a brief intro to base R, I've concentrated on the
Tidyverse, because of what I see as its advantages. There are lots of small
demos of the Tidyverse scattered around the web, but fewer of big projects
which use lots of different features from it. So my examples here might be
useful.

Reliability and accuracy are vital, which is why I have more slides about
testing than about anything else, with examples of "testthat".

Near the end, I show a web interface, built using Vis.js , which displays
dataflow in the model. The aim is to make it completely scrutable, so that
none of its economic assumptions are a mystery.

We're looking for funding to go beyond this prototype. There are places
where we'll probably need help with such things as efficiency (see the
section on representation-independent selectors), efficiency again
(multiple JOINs), and the best way to overcome lack of static typing. It
would be great to have R experts, even R implementors, who were willing to
advise on this, and even to collaborate on our grant applications.

	[[alternative HTML version deleted]]


From paul.lantos at duke.edu  Mon Mar 26 21:16:02 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Mon, 26 Mar 2018 19:16:02 +0000
Subject: [R] unable to move temporary installation of package
Message-ID: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>

I'm running Windows 10 / R Studio / R Open 3.4.3



Since getting a new computer recently I cannot install packages into my personal libpath directory, and I can't seem to update packages (it says all packages are up to date even if I manually install an old version). I've got 100% admin rights on the computer and in the library folder, I've set my R environment variable to specify the correct directory, I can freely move things manually in and out of the library if needed, and R can read and use any package that's already in there. But I can't install or I get the "unable to move" error.



I've uninstalled and reinstalled everything, tried this in non-Studio sessions using both R Open and regular R 3.4.4, and I get the same error.



Thanks for any help,

Paul Lantos


_____________________________________________
Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP
Associate Professor of Internal Medicine and Pediatrics
  Pediatric Infectious Diseases
  General Internal Medicine
Duke University School of Medicine
Duke Global Health Institute
_____________________________________________


	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Mon Mar 26 23:22:10 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 26 Mar 2018 14:22:10 -0700
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>

A) Don't try to "move" packages from one library (=directory of installed packages) to another. 

B) Although R Open is very close to CRAN R, it has some differences that you REALLY NEED TO READ about at their website. Pay particular attention to the checkpoint feature in this case. Note that troubles installing it or with the MKL are probably off-topic here, though R language questions should still be fair game. 

C) Having Administrator rights carries at least as much responsibility to know what you are doing BEFORE you do it as it bestows flexibility to get things done. If you used "Run As Administrator" to install R or any packages then you have probably set the permissions on your personal library inappropriately. If so, you need to use your superpowers judiciously to eliminate your personal library completely and then run R as a normal user to install/update R packages.
-- 
Sent from my phone. Please excuse my brevity.

On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>I'm running Windows 10 / R Studio / R Open 3.4.3
>
>
>
>Since getting a new computer recently I cannot install packages into my
>personal libpath directory, and I can't seem to update packages (it
>says all packages are up to date even if I manually install an old
>version). I've got 100% admin rights on the computer and in the library
>folder, I've set my R environment variable to specify the correct
>directory, I can freely move things manually in and out of the library
>if needed, and R can read and use any package that's already in there.
>But I can't install or I get the "unable to move" error.
>
>
>
>I've uninstalled and reinstalled everything, tried this in non-Studio
>sessions using both R Open and regular R 3.4.4, and I get the same
>error.
>
>
>
>Thanks for any help,
>
>Paul Lantos
>
>
>_____________________________________________
>Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP
>Associate Professor of Internal Medicine and Pediatrics
>  Pediatric Infectious Diseases
>  General Internal Medicine
>Duke University School of Medicine
>Duke Global Health Institute
>_____________________________________________
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From paul.lantos at duke.edu  Tue Mar 27 03:27:10 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Tue, 27 Mar 2018 01:27:10 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
Message-ID: <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>

Thanks Jeff,

 So I initially when I got the computer moved my old packages into the new directory rather than downloading and installing them again. That was fine. I then just did a test to see if I could write in the folder and indeed I can. Just not via R.

 I uninstalled R Open, installed R 3.4.4, and the problem persisted, including just running it from the R console rather than from R Studio.

 I haven't done anything (like installations) with administrator rights - I just have them. That said I've checked the permissions of the library folder and I have all permission. I don't run R in any special way.

 So I'm not sure where that leaves me... thanks for any suggestions.

Paul



-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Monday, March 26, 2018 5:22 PM
To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
Subject: Re: [R] unable to move temporary installation of package

A) Don't try to "move" packages from one library (=directory of installed packages) to another. 

B) Although R Open is very close to CRAN R, it has some differences that you REALLY NEED TO READ about at their website. Pay particular attention to the checkpoint feature in this case. Note that troubles installing it or with the MKL are probably off-topic here, though R language questions should still be fair game. 

C) Having Administrator rights carries at least as much responsibility to know what you are doing BEFORE you do it as it bestows flexibility to get things done. If you used "Run As Administrator" to install R or any packages then you have probably set the permissions on your personal library inappropriately. If so, you need to use your superpowers judiciously to eliminate your personal library completely and then run R as a normal user to install/update R packages.
--
Sent from my phone. Please excuse my brevity.

On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>I'm running Windows 10 / R Studio / R Open 3.4.3
>
>
>
>Since getting a new computer recently I cannot install packages into my 
>personal libpath directory, and I can't seem to update packages (it 
>says all packages are up to date even if I manually install an old 
>version). I've got 100% admin rights on the computer and in the library 
>folder, I've set my R environment variable to specify the correct 
>directory, I can freely move things manually in and out of the library 
>if needed, and R can read and use any package that's already in there.
>But I can't install or I get the "unable to move" error.
>
>
>
>I've uninstalled and reinstalled everything, tried this in non-Studio 
>sessions using both R Open and regular R 3.4.4, and I get the same 
>error.
>
>
>
>Thanks for any help,
>
>Paul Lantos
>
>
>_____________________________________________
>Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of 
>Internal Medicine and Pediatrics
>  Pediatric Infectious Diseases
>  General Internal Medicine
>Duke University School of Medicine
>Duke Global Health Institute
>_____________________________________________
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ
>4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjIS
>0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBII
>&e=
>PLEASE do read the posting guide
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>_posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9KM
>U&e= and provide commented, minimal, self-contained, reproducible code.

From statistics at inter.nl.net  Tue Mar 27 04:40:31 2018
From: statistics at inter.nl.net (Ronald Geskus)
Date: Tue, 27 Mar 2018 04:40:31 +0200
Subject: [R] selectFGR vs weighted coxph for internal validation and
 calibration curve- competing risks model
In-Reply-To: <VI1PR0402MB38229F1CE4DCC372C3A6DCCFA1AA0@VI1PR0402MB3822.eurprd04.prod.outlook.com>
References: <VI1PR0402MB38229F1CE4DCC372C3A6DCCFA1AA0@VI1PR0402MB3822.eurprd04.prod.outlook.com>
Message-ID: <48f7461149d80047f4c229c0d0eeac29.squirrel@webmail.internl.net>

Dear Raja,

I don't know of any out-of-the-box function to perform internal validation
with a Fine & Gray model. My suggestion is to tweak the validate.cph
function from the rms package. Within that function, you will need to
incorporate the crprep or finegray function to compute the weights and
then use a weighted Cox model.

best regards,

Ronald Geskus



Raja, Dr. Edwin Amalrajwrote:
> Dear Geskus,
>
> I want to develop a prediction model.  I followed your paper and analysed
> thro' weighted coxph approach.   I can develop nomogram based on the final
> model also.  But I do not know how to do internal validation of the model
> and subsequently obtain calibration plot.   Is it possible to use Wolbers
> et al Epid 2009 approach 9 (R code for internal validation and
> calibration) .  It is possible to get these measures after using R
> function 'crr' or 'FGR'. That is why I wanted to go in that route. At the
> same time,  I had this doubt because their approach assume a record per
> individual whereas weight coxph creates two or more records per
> individual.  I am new to R and could not modify the R code easily.   Any
> suggestion?   Has anyone done internal validation and calibration after
> using weighted  coxph approach?  Can you kindly refer me to the reference
> which has R code?
>
> Thank you very much for all your inputs and suggestions
>
> Regards
> Amalraj raja
>
> -----Original Message-----
> From: Ronald Geskus [mailto:statistics at inter.nl.net]
> Sent: 21 March 2018 04:01
> To: r-help at r-project.org
> Cc: Raja, Dr. Edwin Amalraj <amalraj.raja at abdn.ac.uk>
> Subject: Re: [R] selectFGR - variable selection in fine gray model for
> competing risks
>
> Dear Raja,
>
> A Fine and Gray model can be fitted using the standard coxph function with
> weights that correct for right censoring and left truncation. Hence I
> guess any function that allows to perform stepwise regression with coxph
> should work. See e.g. my article in Biometrics
> https://doi.org/10.1111/j.1541-0420.2010.01420.x, or the vignette
> "Multi-state models and competing risks" in the survival package.
>
> best regards,
>
> Ronald Geskus, PhD
> head of biostatistics group
> Oxford University Clinical Research unit Ho Chi Minh city, Vietnam
> associate professor University of Oxford
> http://www.oucru.org/dr-ronald-b-geskus/
>
> "Raja, Dr. Edwin Amalraj" <amalraj.raja at abdn.ac.uk> writes:
>
>> Dear All,
>>
>>    I would like to use R function 'selectFGR' of fine gray model in
>> competing risks model.  I used the 'Melanoma' data in 'riskRegression'
>> package.  Some of the variables are factor.  I get solution for full
>> model but not in variable selection model.  Any advice how to use
>> factor variable in 'selectFGR' function.  The following R code is
>> produced below for reproducibility.
>>
>> library(riskRegression)
>> library(pec)
>> dat <-data(Melanoma,package="riskRegression")
>> Melanoma$logthick <- log(Melanoma$thick)
>> f1 <- Hist(time,status)~age+sex+epicel+ulcer
>> df1 <-FGR(f1,cause=1, data=Melanoma)
>> df1
>> df <-selectFGR(f1, data=Melanoma, rule ="BIC",  direction="backward")
>>
>> Thanks in advice for your suggestion. Is there any alternative solution
>> ?
>>
>> Regards
>> Amalraj raja
>>
>>
>> The University of Aberdeen is a charity registered in Scotland, No
> SC013683.
>> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir.
> SC013683.
>
>
>
> The University of Aberdeen is a charity registered in Scotland, No
> SC013683.
> Tha Oilthigh Obar Dheathain na charthannas cl?raichte ann an Alba, ?ir.
> SC013683.
>


-- 
R.B. Geskus, PhD
head of biostatistics group
Oxford University Clinical Research unit
Ho Chi Minh city, Vietnam
associate professor University of Oxford
http://www.oucru.org/dr-ronald-b-geskus/


From jdnewmil at dcn.davis.ca.us  Tue Mar 27 07:15:54 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Mon, 26 Mar 2018 22:15:54 -0700
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>

Perhaps someone here will see something useful if you post the output of the following function calls:

sessionInfo()
.libPaths()
file.info(.libPaths())

and the verbatim (copied) error (in context) that you are seeing. 
-- 
Sent from my phone. Please excuse my brevity.

On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>Thanks Jeff,
>
>So I initially when I got the computer moved my old packages into the
>new directory rather than downloading and installing them again. That
>was fine. I then just did a test to see if I could write in the folder
>and indeed I can. Just not via R.
>
>I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>including just running it from the R console rather than from R Studio.
>
>I haven't done anything (like installations) with administrator rights
>- I just have them. That said I've checked the permissions of the
>library folder and I have all permission. I don't run R in any special
>way.
>
> So I'm not sure where that leaves me... thanks for any suggestions.
>
>Paul
>
>
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
>Sent: Monday, March 26, 2018 5:22 PM
>To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>r-help at r-project.org
>Subject: Re: [R] unable to move temporary installation of package
>
>A) Don't try to "move" packages from one library (=directory of
>installed packages) to another. 
>
>B) Although R Open is very close to CRAN R, it has some differences
>that you REALLY NEED TO READ about at their website. Pay particular
>attention to the checkpoint feature in this case. Note that troubles
>installing it or with the MKL are probably off-topic here, though R
>language questions should still be fair game. 
>
>C) Having Administrator rights carries at least as much responsibility
>to know what you are doing BEFORE you do it as it bestows flexibility
>to get things done. If you used "Run As Administrator" to install R or
>any packages then you have probably set the permissions on your
>personal library inappropriately. If so, you need to use your
>superpowers judiciously to eliminate your personal library completely
>and then run R as a normal user to install/update R packages.
>--
>Sent from my phone. Please excuse my brevity.
>
>On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>wrote:
>>I'm running Windows 10 / R Studio / R Open 3.4.3
>>
>>
>>
>>Since getting a new computer recently I cannot install packages into
>my 
>>personal libpath directory, and I can't seem to update packages (it 
>>says all packages are up to date even if I manually install an old 
>>version). I've got 100% admin rights on the computer and in the
>library 
>>folder, I've set my R environment variable to specify the correct 
>>directory, I can freely move things manually in and out of the library
>
>>if needed, and R can read and use any package that's already in there.
>>But I can't install or I get the "unable to move" error.
>>
>>
>>
>>I've uninstalled and reinstalled everything, tried this in non-Studio 
>>sessions using both R Open and regular R 3.4.4, and I get the same 
>>error.
>>
>>
>>
>>Thanks for any help,
>>
>>Paul Lantos
>>
>>
>>_____________________________________________
>>Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of 
>>Internal Medicine and Pediatrics
>>  Pediatric Infectious Diseases
>>  General Internal Medicine
>>Duke University School of Medicine
>>Duke Global Health Institute
>>_____________________________________________
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailm
>>an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ
>>4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjIS
>>0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBII
>>&e=
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org
>>_posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>>Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>>S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9KM
>>U&e= and provide commented, minimal, self-contained, reproducible
>code.


From eliza_botto at outlook.com  Tue Mar 27 16:14:06 2018
From: eliza_botto at outlook.com (Eliza Botto)
Date: Tue, 27 Mar 2018 14:14:06 +0000
Subject: [R] Shading specific region in R
Message-ID: <DB6PR0901MB1192EFDEDF1B631EE4B55A5E9AAC0@DB6PR0901MB1192.eurprd09.prod.outlook.com>

Dear useRs,

Following the given codes below, I generated a plot that has 6 regions around a center point (IL), with 5 regions containing

a point (L1, L2 to L5) and sixth vacant region. I want background of all the filled regions turned "green", while "red" for the

vacant region. Can it be done through a quicker way?

Thanks in advance

###Codes start from here################################

plot(1:10,col="white",xlab=expression("D"[a]),ylab=expression("D"[b]),cex.lab=1.3, mgp = c(2, 1, 0))

rect(par("usr")[1],par("usr")[3],par("usr")[2],par("usr")[4],col = "white")

points(5,5,pch=19,col="green",lwd=2)

points(5,9,pch=19,col="yellow",lwd=2)

points(5,1,pch=19,col="yellow",lwd=2)

points(2,7,pch=19,col="yellow",lwd=2)

points(9,4,pch=19,col="yellow",lwd=2)

points(8,8,pch=19,col="yellow",lwd=2)

text(5.7,9.5,expression("L"[1]),cex=1.2)

text(8.7,8.5,expression("L"[2]),cex=1.2)

text(9.6,4.5,expression("L"[3]),cex=1.2)

text(5.6,1.5,expression("L"[4]),cex=1.2)

text(2.4,7.7,expression("L"[5]),cex=1.2)

text(5.5,4.4,expression("I"[L]),cex=1.2)

X1<-5

Y1<-5

X2<-5*X1

Y2<-Y1

base<-sqrt((X1-X2)^2+(Y1-Y2)^2)

Hyp =base/cos(60*pi/180)

Pre= Hyp*sin(60*pi/180)

Y3<-Pre+Y2

X3<-X2

segments((X3), (Y3), (X1-base), (Y1-Pre),type="l",col="red")

segments((X1-base), (Y3), (X3), (Y1-Pre),type="l",col="red")

segments((X2), (Y2), (X1-base), (Y1),type="l",col="red")



regards,

Eliza



	[[alternative HTML version deleted]]


From paul.lantos at duke.edu  Tue Mar 27 16:23:09 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Tue, 27 Mar 2018 14:23:09 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
Message-ID: <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>

Ok, thanks --

> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252   
[3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C                          
[5] LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14   
> .libPaths()
[1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"       
> file.info(.libPaths())
                                          size isdir mode               mtime               ctime               atime
C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
                                          exe
C:/Users/pl39/Documents/R/win-library/3.4  no
C:/Program Files/R/R-3.4.4/library         no

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Tuesday, March 27, 2018 1:16 AM
To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
Subject: RE: [R] unable to move temporary installation of package

Perhaps someone here will see something useful if you post the output of the following function calls:

sessionInfo()
.libPaths()
file.info(.libPaths())

and the verbatim (copied) error (in context) that you are seeing. 
--
Sent from my phone. Please excuse my brevity.

On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>Thanks Jeff,
>
>So I initially when I got the computer moved my old packages into the 
>new directory rather than downloading and installing them again. That 
>was fine. I then just did a test to see if I could write in the folder 
>and indeed I can. Just not via R.
>
>I uninstalled R Open, installed R 3.4.4, and the problem persisted, 
>including just running it from the R console rather than from R Studio.
>
>I haven't done anything (like installations) with administrator rights
>- I just have them. That said I've checked the permissions of the 
>library folder and I have all permission. I don't run R in any special 
>way.
>
> So I'm not sure where that leaves me... thanks for any suggestions.
>
>Paul
>
>
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Monday, March 26, 2018 5:22 PM
>To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>; 
>r-help at r-project.org
>Subject: Re: [R] unable to move temporary installation of package
>
>A) Don't try to "move" packages from one library (=directory of 
>installed packages) to another.
>
>B) Although R Open is very close to CRAN R, it has some differences 
>that you REALLY NEED TO READ about at their website. Pay particular 
>attention to the checkpoint feature in this case. Note that troubles 
>installing it or with the MKL are probably off-topic here, though R 
>language questions should still be fair game.
>
>C) Having Administrator rights carries at least as much responsibility 
>to know what you are doing BEFORE you do it as it bestows flexibility 
>to get things done. If you used "Run As Administrator" to install R or 
>any packages then you have probably set the permissions on your 
>personal library inappropriately. If so, you need to use your 
>superpowers judiciously to eliminate your personal library completely 
>and then run R as a normal user to install/update R packages.
>--
>Sent from my phone. Please excuse my brevity.
>
>On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>wrote:
>>I'm running Windows 10 / R Studio / R Open 3.4.3
>>
>>
>>
>>Since getting a new computer recently I cannot install packages into
>my
>>personal libpath directory, and I can't seem to update packages (it 
>>says all packages are up to date even if I manually install an old 
>>version). I've got 100% admin rights on the computer and in the
>library
>>folder, I've set my R environment variable to specify the correct 
>>directory, I can freely move things manually in and out of the library
>
>>if needed, and R can read and use any package that's already in there.
>>But I can't install or I get the "unable to move" error.
>>
>>
>>
>>I've uninstalled and reinstalled everything, tried this in non-Studio 
>>sessions using both R Open and regular R 3.4.4, and I get the same 
>>error.
>>
>>
>>
>>Thanks for any help,
>>
>>Paul Lantos
>>
>>
>>_____________________________________________
>>Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of 
>>Internal Medicine and Pediatrics
>>  Pediatric Infectious Diseases
>>  General Internal Medicine
>>Duke University School of Medicine
>>Duke Global Health Institute
>>_____________________________________________
>>
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>m 
>>an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>>Z 
>>4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>>S 
>>0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBI
>>I
>>&e=
>>PLEASE do read the posting guide
>>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>g 
>>_posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_
>>g 
>>Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzj
>>I 
>>S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9K
>>M U&e= and provide commented, minimal, self-contained, reproducible
>code.

From S.Ellison at LGCGroup.com  Tue Mar 27 17:44:21 2018
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 27 Mar 2018 16:44:21 +0100
Subject: [R] Shading specific region in R
In-Reply-To: <DB6PR0901MB1192EFDEDF1B631EE4B55A5E9AAC0@DB6PR0901MB1192.eurprd09.prod.outlook.com>
References: <DB6PR0901MB1192EFDEDF1B631EE4B55A5E9AAC0@DB6PR0901MB1192.eurprd09.prod.outlook.com>
Message-ID: <1A8C1289955EF649A09086A153E267240C42AB2C6D@GBTEDVPEXCMB04.corp.lgc-group.com>

> Following the given codes below, I generated a plot that has 6 regions around a
> center point (IL), with 5 regions containing
> 
> a point (L1, L2 to L5) and sixth vacant region. I want background of all the filled
> regions turned "green", while "red" for the
> 
> vacant region. Can it be done through a quicker way?

You can certainly reduce the number of lines of code.
And you can shade a region using polygon()
Code to replace yours and add polygon below, as an example, commented.

#########
plot(1:10,type="n",xlab=expression("D"[a]),ylab=expression("D"[b]),cex.lab=1.3, mgp = c(2, 1, 0))
	#type="n" supporesses points - no need to draw them at all
pu <- par("usr") #saves typing later

#shading regions is easiest using polygon()
#You also need the shading first, to draw on top.
#since you're shading everything except one region, start with a single background colour.
rect(pu[1],pu[3],pu[2],pu[4],col = "lightgreen")

#construct and add the shaded region
xrange <- pu[3]-pu[1] 
yrange <- pu[4]-pu[2]

x0 <- 5
y0 <- 5

x.poly <- c(x0, pu[1], pu[1], x0 - (y0 - pu[3]) / tan(pi/3), x0) 
y.poly <- c(y0, y0, pu[3], pu[3], y0)

polygon(x.poly, y.poly, col="pink") #shaded region

#Then there are simplifications using vectorisation:
# points(), text() and segments() are vectorised so you only need one call to each.
px <- c(5,5,5,2,9,8)
py <- c(5,9,1,7,4,8)
p.cols <- c("green", rep("yellow", 5))

points(px, py, pch=19, col=p.cols)

# You can put text at the point locations with a simple offset
# You can also construct text expressions by substitution
for(i in 1:6)
         text(px[i]+0.5, py[i]+0.3, bquote(L[.(i)]), cex=1.2)

# segments() takes vectors too.
# The following is just an example, assuming you want equally spaced lines at 
# 60 degree intervals, all originating from a centre (x0=5, y0=5)

seglen <- 10 #arbitrary length, relying on clipping to the plot region

segments(x0, y0, x0+seglen * cos( (0:5) * pi/3), y0 +seglen * sin( (0:5) * pi/3)  )



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jdnewmil at dcn.davis.ca.us  Tue Mar 27 19:14:16 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 27 Mar 2018 10:14:16 -0700 (PDT)
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>

Nothing jumps out at me yet.

1) You missed including the text of your command (presumably 
install.packages) along with the actual text of the error.

2) What is the output of:

getOption("repos")

3) You might also consider looking at

system2( "cacls.exe", .libPaths()[1] )

though we may not be able to interpret the output appropriately in this 
venue if you are working on a managed computer... you might need local 
help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".

Note that your personal R library is not deleted when you uninstall R... 
if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
and let R re-create it then uninstalling would not have helped a 
permissions problem.

On Tue, 27 Mar 2018, Paul Lantos wrote:

> Ok, thanks --
>
>> sessionInfo()
> R version 3.4.4 (2018-03-15)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>> .libPaths()
> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>> file.info(.libPaths())
>                                          size isdir mode               mtime               ctime               atime
> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>                                          exe
> C:/Users/pl39/Documents/R/win-library/3.4  no
> C:/Program Files/R/R-3.4.4/library         no
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:16 AM
> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
>
> Perhaps someone here will see something useful if you post the output of the following function calls:
>
> sessionInfo()
> .libPaths()
> file.info(.libPaths())
>
> and the verbatim (copied) error (in context) that you are seeing.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>> Thanks Jeff,
>>
>> So I initially when I got the computer moved my old packages into the
>> new directory rather than downloading and installing them again. That
>> was fine. I then just did a test to see if I could write in the folder
>> and indeed I can. Just not via R.
>>
>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>> including just running it from the R console rather than from R Studio.
>>
>> I haven't done anything (like installations) with administrator rights
>> - I just have them. That said I've checked the permissions of the
>> library folder and I have all permission. I don't run R in any special
>> way.
>>
>> So I'm not sure where that leaves me... thanks for any suggestions.
>>
>> Paul
>>
>>
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Monday, March 26, 2018 5:22 PM
>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>> r-help at r-project.org
>> Subject: Re: [R] unable to move temporary installation of package
>>
>> A) Don't try to "move" packages from one library (=directory of
>> installed packages) to another.
>>
>> B) Although R Open is very close to CRAN R, it has some differences
>> that you REALLY NEED TO READ about at their website. Pay particular
>> attention to the checkpoint feature in this case. Note that troubles
>> installing it or with the MKL are probably off-topic here, though R
>> language questions should still be fair game.
>>
>> C) Having Administrator rights carries at least as much responsibility
>> to know what you are doing BEFORE you do it as it bestows flexibility
>> to get things done. If you used "Run As Administrator" to install R or
>> any packages then you have probably set the permissions on your
>> personal library inappropriately. If so, you need to use your
>> superpowers judiciously to eliminate your personal library completely
>> and then run R as a normal user to install/update R packages.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>> wrote:
>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>
>>>
>>>
>>> Since getting a new computer recently I cannot install packages into
>> my
>>> personal libpath directory, and I can't seem to update packages (it
>>> says all packages are up to date even if I manually install an old
>>> version). I've got 100% admin rights on the computer and in the
>> library
>>> folder, I've set my R environment variable to specify the correct
>>> directory, I can freely move things manually in and out of the library
>>
>>> if needed, and R can read and use any package that's already in there.
>>> But I can't install or I get the "unable to move" error.
>>>
>>>
>>>
>>> I've uninstalled and reinstalled everything, tried this in non-Studio
>>> sessions using both R Open and regular R 3.4.4, and I get the same
>>> error.
>>>
>>>
>>>
>>> Thanks for any help,
>>>
>>> Paul Lantos
>>>
>>>
>>> _____________________________________________
>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of
>>> Internal Medicine and Pediatrics
>>>  Pediatric Infectious Diseases
>>>  General Internal Medicine
>>> Duke University School of Medicine
>>> Duke Global Health Institute
>>> _____________________________________________
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>> m
>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>>> Z
>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>>> S
>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBI
>>> I
>>> &e=
>>> PLEASE do read the posting guide
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>> g
>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_
>>> g
>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzj
>>> I
>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9K
>>> M U&e= and provide commented, minimal, self-contained, reproducible
>> code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From paul.lantos at duke.edu  Tue Mar 27 19:14:46 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Tue, 27 Mar 2018 17:14:46 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
Message-ID: <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>

Thanks,

Here's the error, for example:

> install.packages("mgcv")
Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
(as 'lib' is unspecified)
trying URL 'https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/mgcv_1.8-23.zip'
Content type 'application/zip' length 2775362 bytes (2.6 MB)
downloaded 2.6 MB

package 'mgcv' successfully unpacked and MD5 sums checked
Warning in install.packages :
  unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'

The downloaded binary packages are in
	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>


> getOption("repos")
                                CRAN                            CRANextra 
"https://mirrors.nics.utk.edu/cran/" "http://www.stats.ox.ac.uk/pub/RWin" 
attr(,"RStudio")
[1] TRUE

I've used different CRAN mirrors though and gotten the same error.



Would you suggest deleting my personal directory and recreating it? I get the same error if I try and install packages to my documents, my desktop, wherever, so I sort of doubt that would fix the problem.

Paul


-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Tuesday, March 27, 2018 1:14 PM
To: Paul Lantos <paul.lantos at duke.edu>
Cc: r-help at r-project.org
Subject: RE: [R] unable to move temporary installation of package

Nothing jumps out at me yet.

1) You missed including the text of your command (presumably
install.packages) along with the actual text of the error.

2) What is the output of:

getOption("repos")

3) You might also consider looking at

system2( "cacls.exe", .libPaths()[1] )

though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".

Note that your personal R library is not deleted when you uninstall R... 
if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
and let R re-create it then uninstalling would not have helped a permissions problem.

On Tue, 27 Mar 2018, Paul Lantos wrote:

> Ok, thanks --
>
>> sessionInfo()
> R version 3.4.4 (2018-03-15)
> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8 
> x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United 
> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>> .libPaths()
> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>> file.info(.libPaths())
>                                          size isdir mode               mtime               ctime               atime
> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>                                          exe
> C:/Users/pl39/Documents/R/win-library/3.4  no
> C:/Program Files/R/R-3.4.4/library         no
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:16 AM
> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
>
> Perhaps someone here will see something useful if you post the output of the following function calls:
>
> sessionInfo()
> .libPaths()
> file.info(.libPaths())
>
> and the verbatim (copied) error (in context) that you are seeing.
> --
> Sent from my phone. Please excuse my brevity.
>
> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>> Thanks Jeff,
>>
>> So I initially when I got the computer moved my old packages into the 
>> new directory rather than downloading and installing them again. That 
>> was fine. I then just did a test to see if I could write in the 
>> folder and indeed I can. Just not via R.
>>
>> I uninstalled R Open, installed R 3.4.4, and the problem persisted, 
>> including just running it from the R console rather than from R Studio.
>>
>> I haven't done anything (like installations) with administrator 
>> rights
>> - I just have them. That said I've checked the permissions of the 
>> library folder and I have all permission. I don't run R in any 
>> special way.
>>
>> So I'm not sure where that leaves me... thanks for any suggestions.
>>
>> Paul
>>
>>
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Monday, March 26, 2018 5:22 PM
>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>; 
>> r-help at r-project.org
>> Subject: Re: [R] unable to move temporary installation of package
>>
>> A) Don't try to "move" packages from one library (=directory of 
>> installed packages) to another.
>>
>> B) Although R Open is very close to CRAN R, it has some differences 
>> that you REALLY NEED TO READ about at their website. Pay particular 
>> attention to the checkpoint feature in this case. Note that troubles 
>> installing it or with the MKL are probably off-topic here, though R 
>> language questions should still be fair game.
>>
>> C) Having Administrator rights carries at least as much 
>> responsibility to know what you are doing BEFORE you do it as it 
>> bestows flexibility to get things done. If you used "Run As 
>> Administrator" to install R or any packages then you have probably 
>> set the permissions on your personal library inappropriately. If so, 
>> you need to use your superpowers judiciously to eliminate your 
>> personal library completely and then run R as a normal user to install/update R packages.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>> wrote:
>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>
>>>
>>>
>>> Since getting a new computer recently I cannot install packages into
>> my
>>> personal libpath directory, and I can't seem to update packages (it 
>>> says all packages are up to date even if I manually install an old 
>>> version). I've got 100% admin rights on the computer and in the
>> library
>>> folder, I've set my R environment variable to specify the correct 
>>> directory, I can freely move things manually in and out of the 
>>> library
>>
>>> if needed, and R can read and use any package that's already in there.
>>> But I can't install or I get the "unable to move" error.
>>>
>>>
>>>
>>> I've uninstalled and reinstalled everything, tried this in 
>>> non-Studio sessions using both R Open and regular R 3.4.4, and I get 
>>> the same error.
>>>
>>>
>>>
>>> Thanks for any help,
>>>
>>> Paul Lantos
>>>
>>>
>>> _____________________________________________
>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of 
>>> Internal Medicine and Pediatrics  Pediatric Infectious Diseases  
>>> General Internal Medicine Duke University School of Medicine Duke 
>>> Global Health Institute 
>>> _____________________________________________
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>> m
>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>>> Z
>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>>> S
>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBI
>>> I
>>> &e=
>>> PLEASE do read the posting guide
>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>> g
>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_
>>> g
>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzj
>>> I
>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9K
>>> M U&e= and provide commented, minimal, self-contained, reproducible
>> code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Tue Mar 27 20:20:35 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 27 Mar 2018 11:20:35 -0700 (PDT)
Subject: [R] Using R and the Tidyverse for an economic model
In-Reply-To: <CAOdhVrFTGPi19d6KU9z249r_SHp+7AYLc114YR7aOFCUXuPu9w@mail.gmail.com>
References: <CAOdhVrFTGPi19d6KU9z249r_SHp+7AYLc114YR7aOFCUXuPu9w@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1803271037000.7457@pedal.dcn.davis.ca.us>

Looks like you have made an impressive start and some attractive 
introductions. I have no significant interest in your topic (sorry), but 
it seems that you are re-inventing the wheel a bit in regards to much of 
your documentation and modularization... R packages can help you solve 
these problems in a cross-platform way. You might try starting with [1] 
and referring to [2] as needed.

Regarding your representation-independent selectors... this looks to me 
like yet another representation (I think the term is "network database"), 
and subject to specific advantages and limitations that this 
representation imposes. For most work I do, tidy data frames have an 
excellent balance of speed and adaptability. For other types of analyses, 
multi-dimensional arrays would be better. Nested lists are extremely 
flexible, but not particularly fast (some would say quite slow, but that 
depends on your use case). Sometimes a relational database or the 
data.table package [3] can be used for increased performance, but your 
functional interface would not be compatible with _merging_ the 
information efficiently, while dplyr can theoretically support any data 
store that presents a tabular data interface with data merge capability.

R seems to work best when used in the functional paradigm operating on 
general-purpose objects... functions that transform, analyze, and present 
data. Having more general classes of objects means more re-use and ad-hoc 
analysis can occur. If I make an object of class "myspecial", only 
functions I write will be useful. Making it a subclass of a more general 
class is one way to make it more widely useful, but avoiding making it a 
subclass of the general class at all can be the most flexible design 
principle... which is what "tidy data" aspires to do with data frames.

That is, I think you should not be avoiding $ (or more generally the "[[" 
operator)... you should be embracing it and enabling users to use it as 
well. Just don't go all multi-level with it... prefer multi-column indexes 
in data frames in most cases (e.g [4]).

[1] http://r-pkgs.had.co.nz/
[2] https://cran.r-project.org/doc/manuals/R-exts.html
[3] https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html
[4] https://www.jstatsoft.org/article/view/v040i01/v40i01.pdf

On Mon, 26 Mar 2018, Jocelyn Ireson-Paine via R-help wrote:

> I've been translating an economic model from Python into R, and I thought
> members of the list would like to see a presentation I've written about it.
> I've blogged this at
> http://www.j-paine.org/blog/2018/03/r-taxben-a-microsimulation-economic-model-in-r.html
> , and the presentation itself is a slideshow at
> http://www.j-paine.org/rtaxben/R/reveal/rtaxben.html . The slideshow is
> written as one side of a conversation which reveals R and the Tidyverse a
> feature at a time to a colleague not familiar with R. Those who _are_
> familar with R might prefer the version at
> http://www.j-paine.org/rtaxben/R/reveal/rtaxben_anim.html . Exactly the
> same material, but, as explained in my introduction, quicker to read. Read
> the blog post first.
>
> Our model, R-Taxben, is a microeconomic model, which simulates at the level
> of individual people rather than bulk variables such as unemployment and
> inflation. It works, roughly speaking, by reading survey data about actual
> households, then applying taxes and benefits to calculate net income and
> expenditure from gross. It has four main parts: (1) read and process
> parameters which describe the taxes and benefits; (2) read the household
> data from CSV files and transform into data frames usable by the model; (3)
> apply the taxes and benefits, calculating such things as council tax, VAT,
> child benefit, and pensions; (4) display the results.
>
> My slides are mainly about (2) and (4), but do touch on the others. I
> suggest, for example, that legible R code for (3) could be used as a
> "reference standard" against which to describe the notoriously complex UK
> benefits system. Organisations such as the Child Poverty Action Group have
> written handbooks for benefits advisers which try to specify the system
> precisely. We'd like to use R for an electronic version of these.
>
> I've said quite a bit about R for probing and plotting data. Not only for
> economists, but for students learning about economics, fiscal policy, and
> statistics. And after a brief intro to base R, I've concentrated on the
> Tidyverse, because of what I see as its advantages. There are lots of small
> demos of the Tidyverse scattered around the web, but fewer of big projects
> which use lots of different features from it. So my examples here might be
> useful.
>
> Reliability and accuracy are vital, which is why I have more slides about
> testing than about anything else, with examples of "testthat".
>
> Near the end, I show a web interface, built using Vis.js , which displays
> dataflow in the model. The aim is to make it completely scrutable, so that
> none of its economic assumptions are a mystery.
>
> We're looking for funding to go beyond this prototype. There are places
> where we'll probably need help with such things as efficiency (see the
> section on representation-independent selectors), efficiency again
> (multiple JOINs), and the best way to overcome lack of static typing. It
> would be great to have R experts, even R implementors, who were willing to
> advise on this, and even to collaborate on our grant applications.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From kevin.thorpe at utoronto.ca  Tue Mar 27 20:15:29 2018
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Tue, 27 Mar 2018 14:15:29 -0400
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <888f8b55-cc32-75cf-ce0c-a50420f23772@utoronto.ca>

I have seen that error from students trying to install, usually from the 
Rcpp package.

One suggestion I received was to try disabling your virus scanner while 
doing the install. The reason being that the scanner has not completed 
its job by the time the installer wants to move stuff around.

Kevin

On 03/27/2018 01:14 PM, Paul Lantos wrote:
> Thanks,
> 
> Here's the error, for example:
> 
>> install.packages("mgcv")
> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
> (as 'lib' is unspecified)
> trying URL 'https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/mgcv_1.8-23.zip'
> Content type 'application/zip' length 2775362 bytes (2.6 MB)
> downloaded 2.6 MB
> 
> package 'mgcv' successfully unpacked and MD5 sums checked
> Warning in install.packages :
>    unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
> 
> The downloaded binary packages are in
> 	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>
> 
> 
>> getOption("repos")
>                                  CRAN                            CRANextra
> "https://mirrors.nics.utk.edu/cran/" "http://www.stats.ox.ac.uk/pub/RWin"
> attr(,"RStudio")
> [1] TRUE
> 
> I've used different CRAN mirrors though and gotten the same error.
> 
> 
> 
> Would you suggest deleting my personal directory and recreating it? I get the same error if I try and install packages to my documents, my desktop, wherever, so I sort of doubt that would fix the problem.
> 
> Paul
> 
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:14 PM
> To: Paul Lantos <paul.lantos at duke.edu>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
> 
> Nothing jumps out at me yet.
> 
> 1) You missed including the text of your command (presumably
> install.packages) along with the actual text of the error.
> 
> 2) What is the output of:
> 
> getOption("repos")
> 
> 3) You might also consider looking at
> 
> system2( "cacls.exe", .libPaths()[1] )
> 
> though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".
> 
> Note that your personal R library is not deleted when you uninstall R...
> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
> and let R re-create it then uninstalling would not have helped a permissions problem.
> 
> On Tue, 27 Mar 2018, Paul Lantos wrote:
> 
>> Ok, thanks --
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>> x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>> .libPaths()
>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>>> file.info(.libPaths())
>>                                           size isdir mode               mtime               ctime               atime
>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>                                           exe
>> C:/Users/pl39/Documents/R/win-library/3.4  no
>> C:/Program Files/R/R-3.4.4/library         no
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:16 AM
>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Perhaps someone here will see something useful if you post the output of the following function calls:
>>
>> sessionInfo()
>> .libPaths()
>> file.info(.libPaths())
>>
>> and the verbatim (copied) error (in context) that you are seeing.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>>> Thanks Jeff,
>>>
>>> So I initially when I got the computer moved my old packages into the
>>> new directory rather than downloading and installing them again. That
>>> was fine. I then just did a test to see if I could write in the
>>> folder and indeed I can. Just not via R.
>>>
>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>>> including just running it from the R console rather than from R Studio.
>>>
>>> I haven't done anything (like installations) with administrator
>>> rights
>>> - I just have them. That said I've checked the permissions of the
>>> library folder and I have all permission. I don't run R in any
>>> special way.
>>>
>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>
>>> Paul
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Monday, March 26, 2018 5:22 PM
>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>>> r-help at r-project.org
>>> Subject: Re: [R] unable to move temporary installation of package
>>>
>>> A) Don't try to "move" packages from one library (=directory of
>>> installed packages) to another.
>>>
>>> B) Although R Open is very close to CRAN R, it has some differences
>>> that you REALLY NEED TO READ about at their website. Pay particular
>>> attention to the checkpoint feature in this case. Note that troubles
>>> installing it or with the MKL are probably off-topic here, though R
>>> language questions should still be fair game.
>>>
>>> C) Having Administrator rights carries at least as much
>>> responsibility to know what you are doing BEFORE you do it as it
>>> bestows flexibility to get things done. If you used "Run As
>>> Administrator" to install R or any packages then you have probably
>>> set the permissions on your personal library inappropriately. If so,
>>> you need to use your superpowers judiciously to eliminate your
>>> personal library completely and then run R as a normal user to install/update R packages.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>>> wrote:
>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>
>>>>
>>>>
>>>> Since getting a new computer recently I cannot install packages into
>>> my
>>>> personal libpath directory, and I can't seem to update packages (it
>>>> says all packages are up to date even if I manually install an old
>>>> version). I've got 100% admin rights on the computer and in the
>>> library
>>>> folder, I've set my R environment variable to specify the correct
>>>> directory, I can freely move things manually in and out of the
>>>> library
>>>
>>>> if needed, and R can read and use any package that's already in there.
>>>> But I can't install or I get the "unable to move" error.
>>>>
>>>>
>>>>
>>>> I've uninstalled and reinstalled everything, tried this in
>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I get
>>>> the same error.
>>>>
>>>>
>>>>
>>>> Thanks for any help,
>>>>
>>>> Paul Lantos
>>>>
>>>>
>>>> _____________________________________________
>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of
>>>> Internal Medicine and Pediatrics  Pediatric Infectious Diseases
>>>> General Internal Medicine Duke University School of Medicine Duke
>>>> Global Health Institute
>>>> _____________________________________________
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>>> m
>>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>>>> Z
>>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>>>> S
>>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBI
>>>> I
>>>> &e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>>> g
>>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_
>>>> g
>>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzj
>>>> I
>>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9K
>>>> M U&e= and provide commented, minimal, self-contained, reproducible
>>> code.
>>
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                         Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> 


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From jdnewmil at dcn.davis.ca.us  Tue Mar 27 20:25:38 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 27 Mar 2018 11:25:38 -0700 (PDT)
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>

Do you have other instances of R open at the time you are doing this? Did 
you already have mgcv installed in your personal library when you tried 
installing it again?

There is clearly something preventing you from writing to your library, or 
at least to specific packages in your library.

On Tue, 27 Mar 2018, Paul Lantos wrote:

> Thanks,
>
> Here's the error, for example:
>
>> install.packages("mgcv")
> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
> (as 'lib' is unspecified)
> trying URL 'https://mirrors.nics.utk.edu/cran/bin/windows/contrib/3.4/mgcv_1.8-23.zip'
> Content type 'application/zip' length 2775362 bytes (2.6 MB)
> downloaded 2.6 MB
>
> package 'mgcv' successfully unpacked and MD5 sums checked
> Warning in install.packages :
>  unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
>
> The downloaded binary packages are in
> 	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>
>
>
>> getOption("repos")
>                                CRAN                            CRANextra
> "https://mirrors.nics.utk.edu/cran/" "http://www.stats.ox.ac.uk/pub/RWin"
> attr(,"RStudio")
> [1] TRUE
>
> I've used different CRAN mirrors though and gotten the same error.
>
>
>
> Would you suggest deleting my personal directory and recreating it? I 
> get the same error if I try and install packages to my documents, my 
> desktop, wherever, so I sort of doubt that would fix the problem.
>
> Paul
>
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:14 PM
> To: Paul Lantos <paul.lantos at duke.edu>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
>
> Nothing jumps out at me yet.
>
> 1) You missed including the text of your command (presumably
> install.packages) along with the actual text of the error.
>
> 2) What is the output of:
>
> getOption("repos")
>
> 3) You might also consider looking at
>
> system2( "cacls.exe", .libPaths()[1] )
>
> though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".
>
> Note that your personal R library is not deleted when you uninstall R...
> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
> and let R re-create it then uninstalling would not have helped a permissions problem.
>
> On Tue, 27 Mar 2018, Paul Lantos wrote:
>
>> Ok, thanks --
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>> x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>> .libPaths()
>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>>> file.info(.libPaths())
>>                                          size isdir mode               mtime               ctime               atime
>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>                                          exe
>> C:/Users/pl39/Documents/R/win-library/3.4  no
>> C:/Program Files/R/R-3.4.4/library         no
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:16 AM
>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Perhaps someone here will see something useful if you post the output of the following function calls:
>>
>> sessionInfo()
>> .libPaths()
>> file.info(.libPaths())
>>
>> and the verbatim (copied) error (in context) that you are seeing.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>>> Thanks Jeff,
>>>
>>> So I initially when I got the computer moved my old packages into the
>>> new directory rather than downloading and installing them again. That
>>> was fine. I then just did a test to see if I could write in the
>>> folder and indeed I can. Just not via R.
>>>
>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>>> including just running it from the R console rather than from R Studio.
>>>
>>> I haven't done anything (like installations) with administrator
>>> rights
>>> - I just have them. That said I've checked the permissions of the
>>> library folder and I have all permission. I don't run R in any
>>> special way.
>>>
>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>
>>> Paul
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Monday, March 26, 2018 5:22 PM
>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>>> r-help at r-project.org
>>> Subject: Re: [R] unable to move temporary installation of package
>>>
>>> A) Don't try to "move" packages from one library (=directory of
>>> installed packages) to another.
>>>
>>> B) Although R Open is very close to CRAN R, it has some differences
>>> that you REALLY NEED TO READ about at their website. Pay particular
>>> attention to the checkpoint feature in this case. Note that troubles
>>> installing it or with the MKL are probably off-topic here, though R
>>> language questions should still be fair game.
>>>
>>> C) Having Administrator rights carries at least as much
>>> responsibility to know what you are doing BEFORE you do it as it
>>> bestows flexibility to get things done. If you used "Run As
>>> Administrator" to install R or any packages then you have probably
>>> set the permissions on your personal library inappropriately. If so,
>>> you need to use your superpowers judiciously to eliminate your
>>> personal library completely and then run R as a normal user to install/update R packages.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>>> wrote:
>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>
>>>>
>>>>
>>>> Since getting a new computer recently I cannot install packages into
>>> my
>>>> personal libpath directory, and I can't seem to update packages (it
>>>> says all packages are up to date even if I manually install an old
>>>> version). I've got 100% admin rights on the computer and in the
>>> library
>>>> folder, I've set my R environment variable to specify the correct
>>>> directory, I can freely move things manually in and out of the
>>>> library
>>>
>>>> if needed, and R can read and use any package that's already in there.
>>>> But I can't install or I get the "unable to move" error.
>>>>
>>>>
>>>>
>>>> I've uninstalled and reinstalled everything, tried this in
>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I get
>>>> the same error.
>>>>
>>>>
>>>>
>>>> Thanks for any help,
>>>>
>>>> Paul Lantos
>>>>
>>>>
>>>> _____________________________________________
>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of
>>>> Internal Medicine and Pediatrics  Pediatric Infectious Diseases
>>>> General Internal Medicine Duke University School of Medicine Duke
>>>> Global Health Institute
>>>> _____________________________________________
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>>> m
>>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>>>> Z
>>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>>>> S
>>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBI
>>>> I
>>>> &e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>>> g
>>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_
>>>> g
>>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzj
>>>> I
>>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9K
>>>> M U&e= and provide commented, minimal, self-contained, reproducible
>>> code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From paul.lantos at duke.edu  Tue Mar 27 20:29:33 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Tue, 27 Mar 2018 18:29:33 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>,
 <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>
Message-ID: <CO2PR0501MB8373BB04F7B7BD620161FD792AC0@CO2PR0501MB837.namprd05.prod.outlook.com>

No other instances of R running, and I get the same error with any installation, new or old.


-------- Original message --------
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Date: 3/27/18 2:21 PM (GMT-05:00)
To: Paul Lantos <paul.lantos at duke.edu>
Cc: r-help at r-project.org
Subject: RE: [R] unable to move temporary installation of package

Do you have other instances of R open at the time you are doing this? Did
you already have mgcv installed in your personal library when you tried
installing it again?

There is clearly something preventing you from writing to your library, or
at least to specific packages in your library.

On Tue, 27 Mar 2018, Paul Lantos wrote:

> Thanks,
>
> Here's the error, for example:
>
>> install.packages("mgcv")
> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
> (as 'lib' is unspecified)
> trying URL 'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=WY21_BHbK9IkP-8et8jU7l6Pm7_pSyImUZruBbgoX3Y&e='
> Content type 'application/zip' length 2775362 bytes (2.6 MB)
> downloaded 2.6 MB
>
> package 'mgcv' successfully unpacked and MD5 sums checked
> Warning in install.packages :
>  unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
>
> The downloaded binary packages are in
>        C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>
>
>
>> getOption("repos")
>                                CRAN                            CRANextra
> "https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=MWGJrHQcUlS2AM48C7B_HqF-Lb5TFwTCfan__4KRZ44&e=" "https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=IO53ger_SKjv4l1y9s2_ZsB8_KlSNeQ_eN9Coj9coNY&e="
> attr(,"RStudio")
> [1] TRUE
>
> I've used different CRAN mirrors though and gotten the same error.
>
>
>
> Would you suggest deleting my personal directory and recreating it? I
> get the same error if I try and install packages to my documents, my
> desktop, wherever, so I sort of doubt that would fix the problem.
>
> Paul
>
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:14 PM
> To: Paul Lantos <paul.lantos at duke.edu>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
>
> Nothing jumps out at me yet.
>
> 1) You missed including the text of your command (presumably
> install.packages) along with the actual text of the error.
>
> 2) What is the output of:
>
> getOption("repos")
>
> 3) You might also consider looking at
>
> system2( "cacls.exe", .libPaths()[1] )
>
> though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".
>
> Note that your personal R library is not deleted when you uninstall R...
> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
> and let R re-create it then uninstalling would not have helped a permissions problem.
>
> On Tue, 27 Mar 2018, Paul Lantos wrote:
>
>> Ok, thanks --
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>> x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>> .libPaths()
>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>>> file.info(.libPaths())
>>                                          size isdir mode               mtime               ctime               atime
>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>                                          exe
>> C:/Users/pl39/Documents/R/win-library/3.4  no
>> C:/Program Files/R/R-3.4.4/library         no
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:16 AM
>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Perhaps someone here will see something useful if you post the output of the following function calls:
>>
>> sessionInfo()
>> .libPaths()
>> file.info(.libPaths())
>>
>> and the verbatim (copied) error (in context) that you are seeing.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>>> Thanks Jeff,
>>>
>>> So I initially when I got the computer moved my old packages into the
>>> new directory rather than downloading and installing them again. That
>>> was fine. I then just did a test to see if I could write in the
>>> folder and indeed I can. Just not via R.
>>>
>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>>> including just running it from the R console rather than from R Studio.
>>>
>>> I haven't done anything (like installations) with administrator
>>> rights
>>> - I just have them. That said I've checked the permissions of the
>>> library folder and I have all permission. I don't run R in any
>>> special way.
>>>
>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>
>>> Paul
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Monday, March 26, 2018 5:22 PM
>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>>> r-help at r-project.org
>>> Subject: Re: [R] unable to move temporary installation of package
>>>
>>> A) Don't try to "move" packages from one library (=directory of
>>> installed packages) to another.
>>>
>>> B) Although R Open is very close to CRAN R, it has some differences
>>> that you REALLY NEED TO READ about at their website. Pay particular
>>> attention to the checkpoint feature in this case. Note that troubles
>>> installing it or with the MKL are probably off-topic here, though R
>>> language questions should still be fair game.
>>>
>>> C) Having Administrator rights carries at least as much
>>> responsibility to know what you are doing BEFORE you do it as it
>>> bestows flexibility to get things done. If you used "Run As
>>> Administrator" to install R or any packages then you have probably
>>> set the permissions on your personal library inappropriately. If so,
>>> you need to use your superpowers judiciously to eliminate your
>>> personal library completely and then run R as a normal user to install/update R packages.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>>> wrote:
>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>
>>>>
>>>>
>>>> Since getting a new computer recently I cannot install packages into
>>> my
>>>> personal libpath directory, and I can't seem to update packages (it
>>>> says all packages are up to date even if I manually install an old
>>>> version). I've got 100% admin rights on the computer and in the
>>> library
>>>> folder, I've set my R environment variable to specify the correct
>>>> directory, I can freely move things manually in and out of the
>>>> library
>>>
>>>> if needed, and R can read and use any package that's already in there.
>>>> But I can't install or I get the "unable to move" error.
>>>>
>>>>
>>>>
>>>> I've uninstalled and reinstalled everything, tried this in
>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I get
>>>> the same error.
>>>>
>>>>
>>>>
>>>> Thanks for any help,
>>>>
>>>> Paul Lantos
>>>>
>>>>
>>>> _____________________________________________
>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor of
>>>> Internal Medicine and Pediatrics  Pediatric Infectious Diseases
>>>> General Internal Medicine Duke University School of Medicine Duke
>>>> Global Health Institute
>>>> _____________________________________________
>>>>
>>>>
>>>>     [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mail
>>>> m
>>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_g
>>>> Z
>>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzjI
>>>> S
>>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6cuBI
>>>> I
>>>> &e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.or
>>>> g
>>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_
>>>> g
>>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuRzj
>>>> I
>>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DFg9K
>>>> M U&e= and provide commented, minimal, self-contained, reproducible
>>> code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From luiss.puerto at gmail.com  Tue Mar 27 21:25:33 2018
From: luiss.puerto at gmail.com (Luis Puerto)
Date: Tue, 27 Mar 2018 22:25:33 +0300
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
Message-ID: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>

Hi! 

I?m on macOS 10.13.3 and just installed the new Java 10 using Homebrew Cask. I also have installed R with Homebrew. Everything seems to work fine, however I just get different outputs if I run sudo R CMD javareconf or R CMD javareconf. With sudo I get pointed to Java 9 and without sudo I get pointed to Java 10. I really don?t know why. 

Without sudo:

$ R CMD javareconf                                                                        
Java interpreter : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/java
Java version     : 10
Java home path   : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
Java compiler    : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javac
Java headers gen.: /usr/bin/javah
Java archive tool: /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jar
Non-system Java on macOS

trying to compile and link a JNI program
detected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
/usr/local/opt/llvm/bin/clang  -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o
/usr/local/opt/llvm/bin/clang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundation


JAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
Java library path: $(JAVA_HOME)/lib/server
JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
override rw-r--r--  root/admin for /usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
override rw-r--r--  root/admin for /usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
Done.
With sudo:

$ sudo R CMD javareconf                                                                   
Java interpreter : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/java
Java version     : 9.0.4
Java home path   : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
Java compiler    : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javac
Java headers gen.: /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javah
Java archive tool: /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/jar
Non-system Java on macOS

trying to compile and link a JNI program
detected JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
/usr/local/opt/llvm/bin/clang  -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include/darwin  -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC  -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o conftest.o
/usr/local/opt/llvm/bin/clang++ -dynamiclib -Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o conftest.so conftest.o -L/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/lib/server -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework -Wl,CoreFoundation


JAVA_HOME        : /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
Java library path: $(JAVA_HOME)/lib/server
JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
Done.
The result of be pointed to Java 10 is rJava package not be able to build. 

warning: [options] bootstrap class path not set in conjunction with -source 6
warning: [options] source value 6 is obsolete and will be removed in a future release
warning: [options] target value 1.6 is obsolete and will be removed in a future release
warning: [options] To suppress warnings about obsolete options, use -Xlint:-options.
Note: Some input files use or override a deprecated API.
Note: Recompile with -Xlint:deprecation for details.
Note: Some input files use unchecked or unsafe operations.
Note: Recompile with -Xlint:unchecked for details.
4 warnings
/usr/bin/javah -d . -classpath . org.rosuda.JRI.Rengine
Unable to locate an executable at "/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah" (-1)
make[2]: *** [org_rosuda_JRI_Rengine.h] Error 2
make[1]: *** [src/JRI.jar] Error 2
make: *** [jri] Error 2
ERROR: compilation failed for package ?rJava?
* removing ?/Users/lpuerto/Library/R/3.x/library/rJava?
* restoring previous ?/Users/lpuerto/Library/R/3.x/library/rJava?

The downloaded source packages are in
    ?/private/var/folders/wf/41gjf2mx7m7fmvfd8dr22_5h0000gn/T/RtmpT2kJMY/downloaded_packages?
Warning message:
In install.packages("rJava", repos = "cloud.r-project.org") :
  installation of package ?rJava? had non-zero exit status
I've checked and there isn't a javah on /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah as in Java 9. Which make me think that either R CMD javareconf isn?t working properly with Java 10 or rJava is not yet compatible with Java 10. 

Does anyone know what is going on? 

Thanks! 

PS/ I?ve opened an issue <https://github.com/s-u/rJava/issues/137> in rJava?s github and a question in stackoverflow <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10>. 


Best Regards
Luis Puerto
http://luisspuerto.net


	[[alternative HTML version deleted]]


From paul.lantos at duke.edu  Tue Mar 27 23:31:31 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Tue, 27 Mar 2018 21:31:31 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>
Message-ID: <CO2PR0501MB83750ACF9F27445D969D6F792AC0@CO2PR0501MB837.namprd05.prod.outlook.com>

I deleted my library, reinstalled R, and had the same issue -- couldn't install anything into its newly created library.

-----Original Message-----
From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
Sent: Tuesday, March 27, 2018 2:26 PM
To: Paul Lantos <paul.lantos at duke.edu>
Cc: r-help at r-project.org
Subject: RE: [R] unable to move temporary installation of package

Do you have other instances of R open at the time you are doing this? Did you already have mgcv installed in your personal library when you tried installing it again?

There is clearly something preventing you from writing to your library, or at least to specific packages in your library.

On Tue, 27 Mar 2018, Paul Lantos wrote:

> Thanks,
>
> Here's the error, for example:
>
>> install.packages("mgcv")
> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
> (as 'lib' is unspecified)
> trying URL 'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=WY21_BHbK9IkP-8et8jU7l6Pm7_pSyImUZruBbgoX3Y&e='
> Content type 'application/zip' length 2775362 bytes (2.6 MB) 
> downloaded 2.6 MB
>
> package 'mgcv' successfully unpacked and MD5 sums checked Warning in 
> install.packages :
>  unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
>
> The downloaded binary packages are in
> 	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>
>
>
>> getOption("repos")
>                                CRAN                            CRANextra
> "https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=MWGJrHQcUlS2AM48C7B_HqF-Lb5TFwTCfan__4KRZ44&e=" "https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=IO53ger_SKjv4l1y9s2_ZsB8_KlSNeQ_eN9Coj9coNY&e="
> attr(,"RStudio")
> [1] TRUE
>
> I've used different CRAN mirrors though and gotten the same error.
>
>
>
> Would you suggest deleting my personal directory and recreating it? I 
> get the same error if I try and install packages to my documents, my 
> desktop, wherever, so I sort of doubt that would fix the problem.
>
> Paul
>
>
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:14 PM
> To: Paul Lantos <paul.lantos at duke.edu>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
>
> Nothing jumps out at me yet.
>
> 1) You missed including the text of your command (presumably
> install.packages) along with the actual text of the error.
>
> 2) What is the output of:
>
> getOption("repos")
>
> 3) You might also consider looking at
>
> system2( "cacls.exe", .libPaths()[1] )
>
> though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".
>
> Note that your personal R library is not deleted when you uninstall R...
> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
> and let R re-create it then uninstalling would not have helped a permissions problem.
>
> On Tue, 27 Mar 2018, Paul Lantos wrote:
>
>> Ok, thanks --
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>> x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>> .libPaths()
>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>>> file.info(.libPaths())
>>                                          size isdir mode               mtime               ctime               atime
>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>                                          exe
>> C:/Users/pl39/Documents/R/win-library/3.4  no
>> C:/Program Files/R/R-3.4.4/library         no
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:16 AM
>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Perhaps someone here will see something useful if you post the output of the following function calls:
>>
>> sessionInfo()
>> .libPaths()
>> file.info(.libPaths())
>>
>> and the verbatim (copied) error (in context) that you are seeing.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>>> Thanks Jeff,
>>>
>>> So I initially when I got the computer moved my old packages into 
>>> the new directory rather than downloading and installing them again. 
>>> That was fine. I then just did a test to see if I could write in the 
>>> folder and indeed I can. Just not via R.
>>>
>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted, 
>>> including just running it from the R console rather than from R Studio.
>>>
>>> I haven't done anything (like installations) with administrator 
>>> rights
>>> - I just have them. That said I've checked the permissions of the 
>>> library folder and I have all permission. I don't run R in any 
>>> special way.
>>>
>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>
>>> Paul
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Monday, March 26, 2018 5:22 PM
>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>; 
>>> r-help at r-project.org
>>> Subject: Re: [R] unable to move temporary installation of package
>>>
>>> A) Don't try to "move" packages from one library (=directory of 
>>> installed packages) to another.
>>>
>>> B) Although R Open is very close to CRAN R, it has some differences 
>>> that you REALLY NEED TO READ about at their website. Pay particular 
>>> attention to the checkpoint feature in this case. Note that troubles 
>>> installing it or with the MKL are probably off-topic here, though R 
>>> language questions should still be fair game.
>>>
>>> C) Having Administrator rights carries at least as much 
>>> responsibility to know what you are doing BEFORE you do it as it 
>>> bestows flexibility to get things done. If you used "Run As 
>>> Administrator" to install R or any packages then you have probably 
>>> set the permissions on your personal library inappropriately. If so, 
>>> you need to use your superpowers judiciously to eliminate your 
>>> personal library completely and then run R as a normal user to install/update R packages.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos 
>>> <paul.lantos at duke.edu>
>>> wrote:
>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>
>>>>
>>>>
>>>> Since getting a new computer recently I cannot install packages 
>>>> into
>>> my
>>>> personal libpath directory, and I can't seem to update packages (it 
>>>> says all packages are up to date even if I manually install an old 
>>>> version). I've got 100% admin rights on the computer and in the
>>> library
>>>> folder, I've set my R environment variable to specify the correct 
>>>> directory, I can freely move things manually in and out of the 
>>>> library
>>>
>>>> if needed, and R can read and use any package that's already in there.
>>>> But I can't install or I get the "unable to move" error.
>>>>
>>>>
>>>>
>>>> I've uninstalled and reinstalled everything, tried this in 
>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I 
>>>> get the same error.
>>>>
>>>>
>>>>
>>>> Thanks for any help,
>>>>
>>>> Paul Lantos
>>>>
>>>>
>>>> _____________________________________________
>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor 
>>>> of Internal Medicine and Pediatrics  Pediatric Infectious Diseases 
>>>> General Internal Medicine Duke University School of Medicine Duke 
>>>> Global Health Institute 
>>>> _____________________________________________
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>> ail
>>>> m
>>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0S
>>>> j_g
>>>> Z
>>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuR
>>>> zjI
>>>> S
>>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6c
>>>> uBI
>>>> I
>>>> &e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>> .or
>>>> g
>>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0
>>>> Sj_
>>>> g
>>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQu
>>>> Rzj
>>>> I
>>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DF
>>>> g9K M U&e= and provide commented, minimal, self-contained, 
>>>> reproducible
>>> code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ----------------------------------------------------------------------
> -----
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From jdnewmil at dcn.davis.ca.us  Tue Mar 27 23:57:22 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 27 Mar 2018 14:57:22 -0700
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB83750ACF9F27445D969D6F792AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB83750ACF9F27445D969D6F792AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <D0ABAE23-4F11-4F3D-9C74-6F36F2CDBF25@dcn.davis.ca.us>

Have you investigated the issue Kevin Thorpe suggested? 
-- 
Sent from my phone. Please excuse my brevity.

On March 27, 2018 2:31:31 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>I deleted my library, reinstalled R, and had the same issue -- couldn't
>install anything into its newly created library.
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us] 
>Sent: Tuesday, March 27, 2018 2:26 PM
>To: Paul Lantos <paul.lantos at duke.edu>
>Cc: r-help at r-project.org
>Subject: RE: [R] unable to move temporary installation of package
>
>Do you have other instances of R open at the time you are doing this?
>Did you already have mgcv installed in your personal library when you
>tried installing it again?
>
>There is clearly something preventing you from writing to your library,
>or at least to specific packages in your library.
>
>On Tue, 27 Mar 2018, Paul Lantos wrote:
>
>> Thanks,
>>
>> Here's the error, for example:
>>
>>> install.packages("mgcv")
>> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
>> (as 'lib' is unspecified)
>> trying URL
>'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=WY21_BHbK9IkP-8et8jU7l6Pm7_pSyImUZruBbgoX3Y&e='
>> Content type 'application/zip' length 2775362 bytes (2.6 MB) 
>> downloaded 2.6 MB
>>
>> package 'mgcv' successfully unpacked and MD5 sums checked Warning in 
>> install.packages :
>>  unable to move temporary installation
>'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to
>'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
>>
>> The downloaded binary packages are in
>> 	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>>
>>
>>
>>> getOption("repos")
>>                                CRAN                           
>CRANextra
>>
>"https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=MWGJrHQcUlS2AM48C7B_HqF-Lb5TFwTCfan__4KRZ44&e="
>"https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=IO53ger_SKjv4l1y9s2_ZsB8_KlSNeQ_eN9Coj9coNY&e="
>> attr(,"RStudio")
>> [1] TRUE
>>
>> I've used different CRAN mirrors though and gotten the same error.
>>
>>
>>
>> Would you suggest deleting my personal directory and recreating it? I
>
>> get the same error if I try and install packages to my documents, my 
>> desktop, wherever, so I sort of doubt that would fix the problem.
>>
>> Paul
>>
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:14 PM
>> To: Paul Lantos <paul.lantos at duke.edu>
>> Cc: r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Nothing jumps out at me yet.
>>
>> 1) You missed including the text of your command (presumably
>> install.packages) along with the actual text of the error.
>>
>> 2) What is the output of:
>>
>> getOption("repos")
>>
>> 3) You might also consider looking at
>>
>> system2( "cacls.exe", .libPaths()[1] )
>>
>> though we may not be able to interpret the output appropriately in
>this venue if you are working on a managed computer... you might need
>local help. I would guess you would need
>"yourdomain\youruser:(OI)(CI)F".
>>
>> Note that your personal R library is not deleted when you uninstall
>R...
>> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
>> and let R re-create it then uninstalling would not have helped a
>permissions problem.
>>
>> On Tue, 27 Mar 2018, Paul Lantos wrote:
>>
>>> Ok, thanks --
>>>
>>>> sessionInfo()
>>> R version 3.4.4 (2018-03-15)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >=
>8
>>> x64 (build 9200)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>>> .libPaths()
>>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program
>Files/R/R-3.4.4/library"
>>>> file.info(.libPaths())
>>>                                          size isdir mode            
>  mtime               ctime               atime
>>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27
>10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25
>21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>>                                          exe
>>> C:/Users/pl39/Documents/R/win-library/3.4  no
>>> C:/Program Files/R/R-3.4.4/library         no
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Tuesday, March 27, 2018 1:16 AM
>>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>>> Subject: RE: [R] unable to move temporary installation of package
>>>
>>> Perhaps someone here will see something useful if you post the
>output of the following function calls:
>>>
>>> sessionInfo()
>>> .libPaths()
>>> file.info(.libPaths())
>>>
>>> and the verbatim (copied) error (in context) that you are seeing.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>wrote:
>>>> Thanks Jeff,
>>>>
>>>> So I initially when I got the computer moved my old packages into 
>>>> the new directory rather than downloading and installing them
>again. 
>>>> That was fine. I then just did a test to see if I could write in
>the 
>>>> folder and indeed I can. Just not via R.
>>>>
>>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>
>>>> including just running it from the R console rather than from R
>Studio.
>>>>
>>>> I haven't done anything (like installations) with administrator 
>>>> rights
>>>> - I just have them. That said I've checked the permissions of the 
>>>> library folder and I have all permission. I don't run R in any 
>>>> special way.
>>>>
>>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>>
>>>> Paul
>>>>
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>>> Sent: Monday, March 26, 2018 5:22 PM
>>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>; 
>>>> r-help at r-project.org
>>>> Subject: Re: [R] unable to move temporary installation of package
>>>>
>>>> A) Don't try to "move" packages from one library (=directory of 
>>>> installed packages) to another.
>>>>
>>>> B) Although R Open is very close to CRAN R, it has some differences
>
>>>> that you REALLY NEED TO READ about at their website. Pay particular
>
>>>> attention to the checkpoint feature in this case. Note that
>troubles 
>>>> installing it or with the MKL are probably off-topic here, though R
>
>>>> language questions should still be fair game.
>>>>
>>>> C) Having Administrator rights carries at least as much 
>>>> responsibility to know what you are doing BEFORE you do it as it 
>>>> bestows flexibility to get things done. If you used "Run As 
>>>> Administrator" to install R or any packages then you have probably 
>>>> set the permissions on your personal library inappropriately. If
>so, 
>>>> you need to use your superpowers judiciously to eliminate your 
>>>> personal library completely and then run R as a normal user to
>install/update R packages.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos 
>>>> <paul.lantos at duke.edu>
>>>> wrote:
>>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>>
>>>>>
>>>>>
>>>>> Since getting a new computer recently I cannot install packages 
>>>>> into
>>>> my
>>>>> personal libpath directory, and I can't seem to update packages
>(it 
>>>>> says all packages are up to date even if I manually install an old
>
>>>>> version). I've got 100% admin rights on the computer and in the
>>>> library
>>>>> folder, I've set my R environment variable to specify the correct 
>>>>> directory, I can freely move things manually in and out of the 
>>>>> library
>>>>
>>>>> if needed, and R can read and use any package that's already in
>there.
>>>>> But I can't install or I get the "unable to move" error.
>>>>>
>>>>>
>>>>>
>>>>> I've uninstalled and reinstalled everything, tried this in 
>>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I 
>>>>> get the same error.
>>>>>
>>>>>
>>>>>
>>>>> Thanks for any help,
>>>>>
>>>>> Paul Lantos
>>>>>
>>>>>
>>>>> _____________________________________________
>>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor 
>>>>> of Internal Medicine and Pediatrics  Pediatric Infectious Diseases
>
>>>>> General Internal Medicine Duke University School of Medicine Duke 
>>>>> Global Health Institute 
>>>>> _____________________________________________
>>>>>
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>>>
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>>> ail
>>>>> m
>>>>>
>an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0S
>>>>> j_g
>>>>> Z
>>>>>
>4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuR
>>>>> zjI
>>>>> S
>>>>>
>0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6c
>>>>> uBI
>>>>> I
>>>>> &e=
>>>>> PLEASE do read the posting guide
>>>>>
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>>> .or
>>>>> g
>>>>>
>_posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0
>>>>> Sj_
>>>>> g
>>>>>
>Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQu
>>>>> Rzj
>>>>> I
>>>>>
>S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DF
>>>>> g9K M U&e= and provide commented, minimal, self-contained, 
>>>>> reproducible
>>>> code.
>>>
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>----------------------------------------------------------------------
>> -----
>>
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>---------------------------------------------------------------------------


From paul.lantos at duke.edu  Wed Mar 28 01:32:54 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Tue, 27 Mar 2018 23:32:54 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <D0ABAE23-4F11-4F3D-9C74-6F36F2CDBF25@dcn.davis.ca.us>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB83750ACF9F27445D969D6F792AC0@CO2PR0501MB837.namprd05.prod.outlook.com>,
 <D0ABAE23-4F11-4F3D-9C74-6F36F2CDBF25@dcn.davis.ca.us>
Message-ID: <CO2PR0501MB837BCB10AF1E35C5887A0BE92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>

I don't believe I've gotten a reply from a Kevin Thorpe.


-------- Original message --------
From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Date: 3/27/18 5:57 PM (GMT-05:00)
To: Paul Lantos <paul.lantos at duke.edu>
Cc: r-help at r-project.org
Subject: RE: [R] unable to move temporary installation of package

Have you investigated the issue Kevin Thorpe suggested?
--
Sent from my phone. Please excuse my brevity.

On March 27, 2018 2:31:31 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>I deleted my library, reinstalled R, and had the same issue -- couldn't
>install anything into its newly created library.
>
>-----Original Message-----
>From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>Sent: Tuesday, March 27, 2018 2:26 PM
>To: Paul Lantos <paul.lantos at duke.edu>
>Cc: r-help at r-project.org
>Subject: RE: [R] unable to move temporary installation of package
>
>Do you have other instances of R open at the time you are doing this?
>Did you already have mgcv installed in your personal library when you
>tried installing it again?
>
>There is clearly something preventing you from writing to your library,
>or at least to specific packages in your library.
>
>On Tue, 27 Mar 2018, Paul Lantos wrote:
>
>> Thanks,
>>
>> Here's the error, for example:
>>
>>> install.packages("mgcv")
>> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
>> (as 'lib' is unspecified)
>> trying URL
>'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=WY21_BHbK9IkP-8et8jU7l6Pm7_pSyImUZruBbgoX3Y&e='
>> Content type 'application/zip' length 2775362 bytes (2.6 MB)
>> downloaded 2.6 MB
>>
>> package 'mgcv' successfully unpacked and MD5 sums checked Warning in
>> install.packages :
>>  unable to move temporary installation
>'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to
>'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
>>
>> The downloaded binary packages are in
>>       C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>>
>>
>>
>>> getOption("repos")
>>                                CRAN
>CRANextra
>>
>"https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=MWGJrHQcUlS2AM48C7B_HqF-Lb5TFwTCfan__4KRZ44&e="
>"https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=IO53ger_SKjv4l1y9s2_ZsB8_KlSNeQ_eN9Coj9coNY&e="
>> attr(,"RStudio")
>> [1] TRUE
>>
>> I've used different CRAN mirrors though and gotten the same error.
>>
>>
>>
>> Would you suggest deleting my personal directory and recreating it? I
>
>> get the same error if I try and install packages to my documents, my
>> desktop, wherever, so I sort of doubt that would fix the problem.
>>
>> Paul
>>
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:14 PM
>> To: Paul Lantos <paul.lantos at duke.edu>
>> Cc: r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Nothing jumps out at me yet.
>>
>> 1) You missed including the text of your command (presumably
>> install.packages) along with the actual text of the error.
>>
>> 2) What is the output of:
>>
>> getOption("repos")
>>
>> 3) You might also consider looking at
>>
>> system2( "cacls.exe", .libPaths()[1] )
>>
>> though we may not be able to interpret the output appropriately in
>this venue if you are working on a managed computer... you might need
>local help. I would guess you would need
>"yourdomain\youruser:(OI)(CI)F".
>>
>> Note that your personal R library is not deleted when you uninstall
>R...
>> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
>> and let R re-create it then uninstalling would not have helped a
>permissions problem.
>>
>> On Tue, 27 Mar 2018, Paul Lantos wrote:
>>
>>> Ok, thanks --
>>>
>>>> sessionInfo()
>>> R version 3.4.4 (2018-03-15)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >=
>8
>>> x64 (build 9200)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>>> .libPaths()
>>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program
>Files/R/R-3.4.4/library"
>>>> file.info(.libPaths())
>>>                                          size isdir mode
>  mtime               ctime               atime
>>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27
>10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25
>21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>>                                          exe
>>> C:/Users/pl39/Documents/R/win-library/3.4  no
>>> C:/Program Files/R/R-3.4.4/library         no
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Tuesday, March 27, 2018 1:16 AM
>>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>>> Subject: RE: [R] unable to move temporary installation of package
>>>
>>> Perhaps someone here will see something useful if you post the
>output of the following function calls:
>>>
>>> sessionInfo()
>>> .libPaths()
>>> file.info(.libPaths())
>>>
>>> and the verbatim (copied) error (in context) that you are seeing.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>wrote:
>>>> Thanks Jeff,
>>>>
>>>> So I initially when I got the computer moved my old packages into
>>>> the new directory rather than downloading and installing them
>again.
>>>> That was fine. I then just did a test to see if I could write in
>the
>>>> folder and indeed I can. Just not via R.
>>>>
>>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>
>>>> including just running it from the R console rather than from R
>Studio.
>>>>
>>>> I haven't done anything (like installations) with administrator
>>>> rights
>>>> - I just have them. That said I've checked the permissions of the
>>>> library folder and I have all permission. I don't run R in any
>>>> special way.
>>>>
>>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>>
>>>> Paul
>>>>
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>>> Sent: Monday, March 26, 2018 5:22 PM
>>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>>>> r-help at r-project.org
>>>> Subject: Re: [R] unable to move temporary installation of package
>>>>
>>>> A) Don't try to "move" packages from one library (=directory of
>>>> installed packages) to another.
>>>>
>>>> B) Although R Open is very close to CRAN R, it has some differences
>
>>>> that you REALLY NEED TO READ about at their website. Pay particular
>
>>>> attention to the checkpoint feature in this case. Note that
>troubles
>>>> installing it or with the MKL are probably off-topic here, though R
>
>>>> language questions should still be fair game.
>>>>
>>>> C) Having Administrator rights carries at least as much
>>>> responsibility to know what you are doing BEFORE you do it as it
>>>> bestows flexibility to get things done. If you used "Run As
>>>> Administrator" to install R or any packages then you have probably
>>>> set the permissions on your personal library inappropriately. If
>so,
>>>> you need to use your superpowers judiciously to eliminate your
>>>> personal library completely and then run R as a normal user to
>install/update R packages.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos
>>>> <paul.lantos at duke.edu>
>>>> wrote:
>>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>>
>>>>>
>>>>>
>>>>> Since getting a new computer recently I cannot install packages
>>>>> into
>>>> my
>>>>> personal libpath directory, and I can't seem to update packages
>(it
>>>>> says all packages are up to date even if I manually install an old
>
>>>>> version). I've got 100% admin rights on the computer and in the
>>>> library
>>>>> folder, I've set my R environment variable to specify the correct
>>>>> directory, I can freely move things manually in and out of the
>>>>> library
>>>>
>>>>> if needed, and R can read and use any package that's already in
>there.
>>>>> But I can't install or I get the "unable to move" error.
>>>>>
>>>>>
>>>>>
>>>>> I've uninstalled and reinstalled everything, tried this in
>>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I
>>>>> get the same error.
>>>>>
>>>>>
>>>>>
>>>>> Thanks for any help,
>>>>>
>>>>> Paul Lantos
>>>>>
>>>>>
>>>>> _____________________________________________
>>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor
>>>>> of Internal Medicine and Pediatrics  Pediatric Infectious Diseases
>
>>>>> General Internal Medicine Duke University School of Medicine Duke
>>>>> Global Health Institute
>>>>> _____________________________________________
>>>>>
>>>>>
>>>>>    [[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>
>https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>>> ail
>>>>> m
>>>>>
>an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0S
>>>>> j_g
>>>>> Z
>>>>>
>4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuR
>>>>> zjI
>>>>> S
>>>>>
>0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6c
>>>>> uBI
>>>>> I
>>>>> &e=
>>>>> PLEASE do read the posting guide
>>>>>
>https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>>> .or
>>>>> g
>>>>>
>_posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0
>>>>> Sj_
>>>>> g
>>>>>
>Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQu
>>>>> Rzj
>>>>> I
>>>>>
>S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DF
>>>>> g9K M U&e= and provide commented, minimal, self-contained,
>>>>> reproducible
>>>> code.
>>>
>>
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>>                                       Live:   OO#.. Dead: OO#..
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>rocks...1k
>>
>----------------------------------------------------------------------
>> -----
>>
>
>---------------------------------------------------------------------------
>Jeff Newmiller                        The     .....       .....  Go
>Live...
>DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>Go...
>                                     Live:   OO#.. Dead: OO#..  Playing
>Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>/Software/Embedded Controllers)               .OO#.       .OO#.
>rocks...1k
>---------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Wed Mar 28 01:38:59 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 28 Mar 2018 01:38:59 +0200
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB837BCB10AF1E35C5887A0BE92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803271121060.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB83750ACF9F27445D969D6F792AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <D0ABAE23-4F11-4F3D-9C74-6F36F2CDBF25@dcn.davis.ca.us>
 <CO2PR0501MB837BCB10AF1E35C5887A0BE92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <0294CE56-5BF1-4660-B887-F51DD5ECD643@gmail.com>

Everyone else did, and you were on the list of recipients... Check your spam folder and/or the list archive.

-pd

> On 28 Mar 2018, at 01:32 , Paul Lantos <paul.lantos at duke.edu> wrote:
> 
> I don't believe I've gotten a reply from a Kevin Thorpe.
> 
> 
> -------- Original message --------
> From: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Date: 3/27/18 5:57 PM (GMT-05:00)
> To: Paul Lantos <paul.lantos at duke.edu>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
> 
> Have you investigated the issue Kevin Thorpe suggested?
> --
> Sent from my phone. Please excuse my brevity.
> 
> On March 27, 2018 2:31:31 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>> I deleted my library, reinstalled R, and had the same issue -- couldn't
>> install anything into its newly created library.
>> 
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 2:26 PM
>> To: Paul Lantos <paul.lantos at duke.edu>
>> Cc: r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>> 
>> Do you have other instances of R open at the time you are doing this?
>> Did you already have mgcv installed in your personal library when you
>> tried installing it again?
>> 
>> There is clearly something preventing you from writing to your library,
>> or at least to specific packages in your library.
>> 
>> On Tue, 27 Mar 2018, Paul Lantos wrote:
>> 
>>> Thanks,
>>> 
>>> Here's the error, for example:
>>> 
>>>> install.packages("mgcv")
>>> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
>>> (as 'lib' is unspecified)
>>> trying URL
>> 'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=WY21_BHbK9IkP-8et8jU7l6Pm7_pSyImUZruBbgoX3Y&e='
>>> Content type 'application/zip' length 2775362 bytes (2.6 MB)
>>> downloaded 2.6 MB
>>> 
>>> package 'mgcv' successfully unpacked and MD5 sums checked Warning in
>>> install.packages :
>>> unable to move temporary installation
>> 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to
>> 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
>>> 
>>> The downloaded binary packages are in
>>>      C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>>> 
>>> 
>>> 
>>>> getOption("repos")
>>>                               CRAN
>> CRANextra
>>> 
>> "https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=MWGJrHQcUlS2AM48C7B_HqF-Lb5TFwTCfan__4KRZ44&e="
>> "https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwIBAg&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=cnrBOleGliiFa8hOlBIzbkSfykST3IYxYCJFIogIDYg&s=IO53ger_SKjv4l1y9s2_ZsB8_KlSNeQ_eN9Coj9coNY&e="
>>> attr(,"RStudio")
>>> [1] TRUE
>>> 
>>> I've used different CRAN mirrors though and gotten the same error.
>>> 
>>> 
>>> 
>>> Would you suggest deleting my personal directory and recreating it? I
>> 
>>> get the same error if I try and install packages to my documents, my
>>> desktop, wherever, so I sort of doubt that would fix the problem.
>>> 
>>> Paul
>>> 
>>> 
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Tuesday, March 27, 2018 1:14 PM
>>> To: Paul Lantos <paul.lantos at duke.edu>
>>> Cc: r-help at r-project.org
>>> Subject: RE: [R] unable to move temporary installation of package
>>> 
>>> Nothing jumps out at me yet.
>>> 
>>> 1) You missed including the text of your command (presumably
>>> install.packages) along with the actual text of the error.
>>> 
>>> 2) What is the output of:
>>> 
>>> getOption("repos")
>>> 
>>> 3) You might also consider looking at
>>> 
>>> system2( "cacls.exe", .libPaths()[1] )
>>> 
>>> though we may not be able to interpret the output appropriately in
>> this venue if you are working on a managed computer... you might need
>> local help. I would guess you would need
>> "yourdomain\youruser:(OI)(CI)F".
>>> 
>>> Note that your personal R library is not deleted when you uninstall
>> R...
>>> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
>>> and let R re-create it then uninstalling would not have helped a
>> permissions problem.
>>> 
>>> On Tue, 27 Mar 2018, Paul Lantos wrote:
>>> 
>>>> Ok, thanks --
>>>> 
>>>>> sessionInfo()
>>>> R version 3.4.4 (2018-03-15)
>>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >=
>> 8
>>>> x64 (build 9200)
>>>> 
>>>> Matrix products: default
>>>> 
>>>> locale:
>>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>>> [5] LC_TIME=English_United States.1252
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>>>> .libPaths()
>>>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program
>> Files/R/R-3.4.4/library"
>>>>> file.info(.libPaths())
>>>>                                         size isdir mode
>> mtime               ctime               atime
>>>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27
>> 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>>>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25
>> 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>>>                                         exe
>>>> C:/Users/pl39/Documents/R/win-library/3.4  no
>>>> C:/Program Files/R/R-3.4.4/library         no
>>>> 
>>>> -----Original Message-----
>>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>>> Sent: Tuesday, March 27, 2018 1:16 AM
>>>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>>>> Subject: RE: [R] unable to move temporary installation of package
>>>> 
>>>> Perhaps someone here will see something useful if you post the
>> output of the following function calls:
>>>> 
>>>> sessionInfo()
>>>> .libPaths()
>>>> file.info(.libPaths())
>>>> 
>>>> and the verbatim (copied) error (in context) that you are seeing.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>> 
>>>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu>
>> wrote:
>>>>> Thanks Jeff,
>>>>> 
>>>>> So I initially when I got the computer moved my old packages into
>>>>> the new directory rather than downloading and installing them
>> again.
>>>>> That was fine. I then just did a test to see if I could write in
>> the
>>>>> folder and indeed I can. Just not via R.
>>>>> 
>>>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>> 
>>>>> including just running it from the R console rather than from R
>> Studio.
>>>>> 
>>>>> I haven't done anything (like installations) with administrator
>>>>> rights
>>>>> - I just have them. That said I've checked the permissions of the
>>>>> library folder and I have all permission. I don't run R in any
>>>>> special way.
>>>>> 
>>>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>>> 
>>>>> Paul
>>>>> 
>>>>> 
>>>>> 
>>>>> -----Original Message-----
>>>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>>>> Sent: Monday, March 26, 2018 5:22 PM
>>>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>>>>> r-help at r-project.org
>>>>> Subject: Re: [R] unable to move temporary installation of package
>>>>> 
>>>>> A) Don't try to "move" packages from one library (=directory of
>>>>> installed packages) to another.
>>>>> 
>>>>> B) Although R Open is very close to CRAN R, it has some differences
>> 
>>>>> that you REALLY NEED TO READ about at their website. Pay particular
>> 
>>>>> attention to the checkpoint feature in this case. Note that
>> troubles
>>>>> installing it or with the MKL are probably off-topic here, though R
>> 
>>>>> language questions should still be fair game.
>>>>> 
>>>>> C) Having Administrator rights carries at least as much
>>>>> responsibility to know what you are doing BEFORE you do it as it
>>>>> bestows flexibility to get things done. If you used "Run As
>>>>> Administrator" to install R or any packages then you have probably
>>>>> set the permissions on your personal library inappropriately. If
>> so,
>>>>> you need to use your superpowers judiciously to eliminate your
>>>>> personal library completely and then run R as a normal user to
>> install/update R packages.
>>>>> --
>>>>> Sent from my phone. Please excuse my brevity.
>>>>> 
>>>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos
>>>>> <paul.lantos at duke.edu>
>>>>> wrote:
>>>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Since getting a new computer recently I cannot install packages
>>>>>> into
>>>>> my
>>>>>> personal libpath directory, and I can't seem to update packages
>> (it
>>>>>> says all packages are up to date even if I manually install an old
>> 
>>>>>> version). I've got 100% admin rights on the computer and in the
>>>>> library
>>>>>> folder, I've set my R environment variable to specify the correct
>>>>>> directory, I can freely move things manually in and out of the
>>>>>> library
>>>>> 
>>>>>> if needed, and R can read and use any package that's already in
>> there.
>>>>>> But I can't install or I get the "unable to move" error.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> I've uninstalled and reinstalled everything, tried this in
>>>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I
>>>>>> get the same error.
>>>>>> 
>>>>>> 
>>>>>> 
>>>>>> Thanks for any help,
>>>>>> 
>>>>>> Paul Lantos
>>>>>> 
>>>>>> 
>>>>>> _____________________________________________
>>>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor
>>>>>> of Internal Medicine and Pediatrics  Pediatric Infectious Diseases
>> 
>>>>>> General Internal Medicine Duke University School of Medicine Duke
>>>>>> Global Health Institute
>>>>>> _____________________________________________
>>>>>> 
>>>>>> 
>>>>>>   [[alternative HTML version deleted]]
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>>> 
>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>>>> ail
>>>>>> m
>>>>>> 
>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0S
>>>>>> j_g
>>>>>> Z
>>>>>> 
>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuR
>>>>>> zjI
>>>>>> S
>>>>>> 
>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6c
>>>>>> uBI
>>>>>> I
>>>>>> &e=
>>>>>> PLEASE do read the posting guide
>>>>>> 
>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>>>> .or
>>>>>> g
>>>>>> 
>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0
>>>>>> Sj_
>>>>>> g
>>>>>> 
>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQu
>>>>>> Rzj
>>>>>> I
>>>>>> 
>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DF
>>>>>> g9K M U&e= and provide commented, minimal, self-contained,
>>>>>> reproducible
>>>>> code.
>>>> 
>>> 
>>> 
>> ---------------------------------------------------------------------------
>>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>>                                      Live:   OO#.. Dead: OO#..
>> Playing
>>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>>> 
>> ----------------------------------------------------------------------
>>> -----
>>> 
>> 
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>> Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                    Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.
>> rocks...1k
>> ---------------------------------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From paul.lantos at duke.edu  Wed Mar 28 02:34:37 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Wed, 28 Mar 2018 00:34:37 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <888f8b55-cc32-75cf-ce0c-a50420f23772@utoronto.ca>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <888f8b55-cc32-75cf-ce0c-a50420f23772@utoronto.ca>
Message-ID: <CO2PR0501MB83761B34BED60B8577BA01392A30@CO2PR0501MB837.namprd05.prod.outlook.com>

Thanks, Kevin. I have done that but no luck.
Paul

-----Original Message-----
From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca] 
Sent: Tuesday, March 27, 2018 2:15 PM
To: Paul Lantos <paul.lantos at duke.edu>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Cc: r-help at r-project.org
Subject: Re: [R] unable to move temporary installation of package

I have seen that error from students trying to install, usually from the Rcpp package.

One suggestion I received was to try disabling your virus scanner while doing the install. The reason being that the scanner has not completed its job by the time the installer wants to move stuff around.

Kevin

On 03/27/2018 01:14 PM, Paul Lantos wrote:
> Thanks,
> 
> Here's the error, for example:
> 
>> install.packages("mgcv")
> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
> (as 'lib' is unspecified)
> trying URL 'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=_oH3hPXmUvvElYCBZg_LBSX0-ZF3XUqACxmRdV1Gzso&e='
> Content type 'application/zip' length 2775362 bytes (2.6 MB) 
> downloaded 2.6 MB
> 
> package 'mgcv' successfully unpacked and MD5 sums checked Warning in 
> install.packages :
>    unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
> 
> The downloaded binary packages are in
> 	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>
> 
> 
>> getOption("repos")
>                                  CRAN                            CRANextra
> "https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=vmRVCTk6BWFZihnxWmmt3Y-Jiz-XaemOdukRPfySpEY&e=" "https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=BUJFWakLtQSrcVuTuqJ-PPtwzHo5pfFje9q2D18Fs-Y&e="
> attr(,"RStudio")
> [1] TRUE
> 
> I've used different CRAN mirrors though and gotten the same error.
> 
> 
> 
> Would you suggest deleting my personal directory and recreating it? I get the same error if I try and install packages to my documents, my desktop, wherever, so I sort of doubt that would fix the problem.
> 
> Paul
> 
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:14 PM
> To: Paul Lantos <paul.lantos at duke.edu>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
> 
> Nothing jumps out at me yet.
> 
> 1) You missed including the text of your command (presumably
> install.packages) along with the actual text of the error.
> 
> 2) What is the output of:
> 
> getOption("repos")
> 
> 3) You might also consider looking at
> 
> system2( "cacls.exe", .libPaths()[1] )
> 
> though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".
> 
> Note that your personal R library is not deleted when you uninstall R...
> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
> and let R re-create it then uninstalling would not have helped a permissions problem.
> 
> On Tue, 27 Mar 2018, Paul Lantos wrote:
> 
>> Ok, thanks --
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>> x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>> .libPaths()
>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>>> file.info(.libPaths())
>>                                           size isdir mode               mtime               ctime               atime
>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>                                           exe
>> C:/Users/pl39/Documents/R/win-library/3.4  no
>> C:/Program Files/R/R-3.4.4/library         no
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:16 AM
>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Perhaps someone here will see something useful if you post the output of the following function calls:
>>
>> sessionInfo()
>> .libPaths()
>> file.info(.libPaths())
>>
>> and the verbatim (copied) error (in context) that you are seeing.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>>> Thanks Jeff,
>>>
>>> So I initially when I got the computer moved my old packages into 
>>> the new directory rather than downloading and installing them again. 
>>> That was fine. I then just did a test to see if I could write in the 
>>> folder and indeed I can. Just not via R.
>>>
>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted, 
>>> including just running it from the R console rather than from R Studio.
>>>
>>> I haven't done anything (like installations) with administrator 
>>> rights
>>> - I just have them. That said I've checked the permissions of the 
>>> library folder and I have all permission. I don't run R in any 
>>> special way.
>>>
>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>
>>> Paul
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Monday, March 26, 2018 5:22 PM
>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>; 
>>> r-help at r-project.org
>>> Subject: Re: [R] unable to move temporary installation of package
>>>
>>> A) Don't try to "move" packages from one library (=directory of 
>>> installed packages) to another.
>>>
>>> B) Although R Open is very close to CRAN R, it has some differences 
>>> that you REALLY NEED TO READ about at their website. Pay particular 
>>> attention to the checkpoint feature in this case. Note that troubles 
>>> installing it or with the MKL are probably off-topic here, though R 
>>> language questions should still be fair game.
>>>
>>> C) Having Administrator rights carries at least as much 
>>> responsibility to know what you are doing BEFORE you do it as it 
>>> bestows flexibility to get things done. If you used "Run As 
>>> Administrator" to install R or any packages then you have probably 
>>> set the permissions on your personal library inappropriately. If so, 
>>> you need to use your superpowers judiciously to eliminate your 
>>> personal library completely and then run R as a normal user to install/update R packages.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos 
>>> <paul.lantos at duke.edu>
>>> wrote:
>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>
>>>>
>>>>
>>>> Since getting a new computer recently I cannot install packages 
>>>> into
>>> my
>>>> personal libpath directory, and I can't seem to update packages (it 
>>>> says all packages are up to date even if I manually install an old 
>>>> version). I've got 100% admin rights on the computer and in the
>>> library
>>>> folder, I've set my R environment variable to specify the correct 
>>>> directory, I can freely move things manually in and out of the 
>>>> library
>>>
>>>> if needed, and R can read and use any package that's already in there.
>>>> But I can't install or I get the "unable to move" error.
>>>>
>>>>
>>>>
>>>> I've uninstalled and reinstalled everything, tried this in 
>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I 
>>>> get the same error.
>>>>
>>>>
>>>>
>>>> Thanks for any help,
>>>>
>>>> Paul Lantos
>>>>
>>>>
>>>> _____________________________________________
>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor 
>>>> of Internal Medicine and Pediatrics  Pediatric Infectious Diseases 
>>>> General Internal Medicine Duke University School of Medicine Duke 
>>>> Global Health Institute 
>>>> _____________________________________________
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>> ail
>>>> m
>>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0S
>>>> j_g
>>>> Z
>>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuR
>>>> zjI
>>>> S
>>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6c
>>>> uBI
>>>> I
>>>> &e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>> .or
>>>> g
>>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0
>>>> Sj_
>>>> g
>>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQu
>>>> Rzj
>>>> I
>>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DF
>>>> g9K M U&e= and provide commented, minimal, self-contained, 
>>>> reproducible
>>> code.
>>
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                         Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> 


--
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC) Li Ka Shing Knowledge Institute of St. Michael's Hospital Assistant Professor, Dalla Lana School of Public Health University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

From paul.lantos at duke.edu  Wed Mar 28 03:22:55 2018
From: paul.lantos at duke.edu (Paul Lantos)
Date: Wed, 28 Mar 2018 01:22:55 +0000
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB83761B34BED60B8577BA01392A30@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <888f8b55-cc32-75cf-ce0c-a50420f23772@utoronto.ca>
 <CO2PR0501MB83761B34BED60B8577BA01392A30@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <CO2PR0501MB8374BA5F74582987B876C7F92A30@CO2PR0501MB837.namprd05.prod.outlook.com>

I think MalwareBytes may have been the culprit. I disabled it and it's working now (even with my regular antivirus running).

Thanks all for the advice!
Paul

-----Original Message-----
From: Paul Lantos 
Sent: Tuesday, March 27, 2018 8:35 PM
To: Kevin E. Thorpe <kevin.thorpe at utoronto.ca>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Cc: r-help at r-project.org
Subject: RE: [R] unable to move temporary installation of package

Thanks, Kevin. I have done that but no luck.
Paul

-----Original Message-----
From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
Sent: Tuesday, March 27, 2018 2:15 PM
To: Paul Lantos <paul.lantos at duke.edu>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
Cc: r-help at r-project.org
Subject: Re: [R] unable to move temporary installation of package

I have seen that error from students trying to install, usually from the Rcpp package.

One suggestion I received was to try disabling your virus scanner while doing the install. The reason being that the scanner has not completed its job by the time the installer wants to move stuff around.

Kevin

On 03/27/2018 01:14 PM, Paul Lantos wrote:
> Thanks,
> 
> Here's the error, for example:
> 
>> install.packages("mgcv")
> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
> (as 'lib' is unspecified)
> trying URL 'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=_oH3hPXmUvvElYCBZg_LBSX0-ZF3XUqACxmRdV1Gzso&e='
> Content type 'application/zip' length 2775362 bytes (2.6 MB) 
> downloaded 2.6 MB
> 
> package 'mgcv' successfully unpacked and MD5 sums checked Warning in 
> install.packages :
>    unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
> 
> The downloaded binary packages are in
> 	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>
> 
> 
>> getOption("repos")
>                                  CRAN                            CRANextra
> "https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=vmRVCTk6BWFZihnxWmmt3Y-Jiz-XaemOdukRPfySpEY&e=" "https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=BUJFWakLtQSrcVuTuqJ-PPtwzHo5pfFje9q2D18Fs-Y&e="
> attr(,"RStudio")
> [1] TRUE
> 
> I've used different CRAN mirrors though and gotten the same error.
> 
> 
> 
> Would you suggest deleting my personal directory and recreating it? I get the same error if I try and install packages to my documents, my desktop, wherever, so I sort of doubt that would fix the problem.
> 
> Paul
> 
> 
> -----Original Message-----
> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
> Sent: Tuesday, March 27, 2018 1:14 PM
> To: Paul Lantos <paul.lantos at duke.edu>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
> 
> Nothing jumps out at me yet.
> 
> 1) You missed including the text of your command (presumably
> install.packages) along with the actual text of the error.
> 
> 2) What is the output of:
> 
> getOption("repos")
> 
> 3) You might also consider looking at
> 
> system2( "cacls.exe", .libPaths()[1] )
> 
> though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".
> 
> Note that your personal R library is not deleted when you uninstall R...
> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
> and let R re-create it then uninstalling would not have helped a permissions problem.
> 
> On Tue, 27 Mar 2018, Paul Lantos wrote:
> 
>> Ok, thanks --
>>
>>> sessionInfo()
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>> x64 (build 9200)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>> .libPaths()
>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>>> file.info(.libPaths())
>>                                           size isdir mode               mtime               ctime               atime
>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>                                           exe
>> C:/Users/pl39/Documents/R/win-library/3.4  no
>> C:/Program Files/R/R-3.4.4/library         no
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:16 AM
>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Perhaps someone here will see something useful if you post the output of the following function calls:
>>
>> sessionInfo()
>> .libPaths()
>> file.info(.libPaths())
>>
>> and the verbatim (copied) error (in context) that you are seeing.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>>> Thanks Jeff,
>>>
>>> So I initially when I got the computer moved my old packages into 
>>> the new directory rather than downloading and installing them again.
>>> That was fine. I then just did a test to see if I could write in the 
>>> folder and indeed I can. Just not via R.
>>>
>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted, 
>>> including just running it from the R console rather than from R Studio.
>>>
>>> I haven't done anything (like installations) with administrator 
>>> rights
>>> - I just have them. That said I've checked the permissions of the 
>>> library folder and I have all permission. I don't run R in any 
>>> special way.
>>>
>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>
>>> Paul
>>>
>>>
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Monday, March 26, 2018 5:22 PM
>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>; 
>>> r-help at r-project.org
>>> Subject: Re: [R] unable to move temporary installation of package
>>>
>>> A) Don't try to "move" packages from one library (=directory of 
>>> installed packages) to another.
>>>
>>> B) Although R Open is very close to CRAN R, it has some differences 
>>> that you REALLY NEED TO READ about at their website. Pay particular 
>>> attention to the checkpoint feature in this case. Note that troubles 
>>> installing it or with the MKL are probably off-topic here, though R 
>>> language questions should still be fair game.
>>>
>>> C) Having Administrator rights carries at least as much 
>>> responsibility to know what you are doing BEFORE you do it as it 
>>> bestows flexibility to get things done. If you used "Run As 
>>> Administrator" to install R or any packages then you have probably 
>>> set the permissions on your personal library inappropriately. If so, 
>>> you need to use your superpowers judiciously to eliminate your 
>>> personal library completely and then run R as a normal user to install/update R packages.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos 
>>> <paul.lantos at duke.edu>
>>> wrote:
>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>
>>>>
>>>>
>>>> Since getting a new computer recently I cannot install packages 
>>>> into
>>> my
>>>> personal libpath directory, and I can't seem to update packages (it 
>>>> says all packages are up to date even if I manually install an old 
>>>> version). I've got 100% admin rights on the computer and in the
>>> library
>>>> folder, I've set my R environment variable to specify the correct 
>>>> directory, I can freely move things manually in and out of the 
>>>> library
>>>
>>>> if needed, and R can read and use any package that's already in there.
>>>> But I can't install or I get the "unable to move" error.
>>>>
>>>>
>>>>
>>>> I've uninstalled and reinstalled everything, tried this in 
>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I 
>>>> get the same error.
>>>>
>>>>
>>>>
>>>> Thanks for any help,
>>>>
>>>> Paul Lantos
>>>>
>>>>
>>>> _____________________________________________
>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor 
>>>> of Internal Medicine and Pediatrics  Pediatric Infectious Diseases 
>>>> General Internal Medicine Duke University School of Medicine Duke 
>>>> Global Health Institute 
>>>> _____________________________________________
>>>>
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>> ail
>>>> m
>>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0S
>>>> j_g
>>>> Z
>>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuR
>>>> zjI
>>>> S
>>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6c
>>>> uBI
>>>> I
>>>> &e=
>>>> PLEASE do read the posting guide
>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>> .or
>>>> g
>>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0
>>>> Sj_
>>>> g
>>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQu
>>>> Rzj
>>>> I
>>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DF
>>>> g9K M U&e= and provide commented, minimal, self-contained, 
>>>> reproducible
>>> code.
>>
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                         Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> 


--
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC) Li Ka Shing Knowledge Institute of St. Michael's Hospital Assistant Professor, Dalla Lana School of Public Health University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016

From jdnewmil at dcn.davis.ca.us  Wed Mar 28 03:39:10 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Tue, 27 Mar 2018 18:39:10 -0700
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
In-Reply-To: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
References: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
Message-ID: <A07DA58D-3C3A-452E-B0FA-2DB2ED737DC5@dcn.davis.ca.us>

I am not a Mac user, but I do use Linux and I would recommend not running R with sudo unless you are an admin ninja. That defensive practice would render the answer to your question moot.

It is possible that your problem may have started with inappropriate use of sudo in configuring java, but configuring Java is not on-topic here.
-- 
Sent from my phone. Please excuse my brevity.

On March 27, 2018 12:25:33 PM PDT, Luis Puerto <luiss.puerto at gmail.com> wrote:
>Hi! 
>
>I?m on macOS 10.13.3 and just installed the new Java 10 using Homebrew
>Cask. I also have installed R with Homebrew. Everything seems to work
>fine, however I just get different outputs if I run sudo R CMD
>javareconf or R CMD javareconf. With sudo I get pointed to Java 9 and
>without sudo I get pointed to Java 10. I really don?t know why. 
>
>Without sudo:
>
>$ R CMD javareconf                                                     
>                  
>Java interpreter :
>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/java
>Java version     : 10
>Java home path   :
>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>Java compiler    :
>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javac
>Java headers gen.: /usr/bin/javah
>Java archive tool:
>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jar
>Non-system Java on macOS
>
>trying to compile and link a JNI program
>detected JNI cpp flags    : -I$(JAVA_HOME)/include
>-I$(JAVA_HOME)/include/darwin
>detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>/usr/local/opt/llvm/bin/clang 
>-I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>-I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include
>-I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin
>-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC 
>-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>conftest.o
>/usr/local/opt/llvm/bin/clang++ -dynamiclib
>-Wl,-headerpad_max_install_names -undefined dynamic_lookup
>-single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>-L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>conftest.so conftest.o
>-L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server
>-ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>-Wl,CoreFoundation
>
>
>JAVA_HOME        :
>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>Java library path: $(JAVA_HOME)/lib/server
>JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>override rw-r--r--  root/admin for
>/usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
>override rw-r--r--  root/admin for
>/usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
>Done.
>With sudo:
>
>$ sudo R CMD javareconf                                                
>                  
>Java interpreter :
>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/java
>Java version     : 9.0.4
>Java home path   :
>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>Java compiler    :
>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javac
>Java headers gen.:
>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javah
>Java archive tool:
>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/jar
>Non-system Java on macOS
>
>trying to compile and link a JNI program
>detected JNI cpp flags    : -I$(JAVA_HOME)/include
>-I$(JAVA_HOME)/include/darwin
>detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>/usr/local/opt/llvm/bin/clang 
>-I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>-I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include
>-I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include/darwin
>-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC 
>-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>conftest.o
>/usr/local/opt/llvm/bin/clang++ -dynamiclib
>-Wl,-headerpad_max_install_names -undefined dynamic_lookup
>-single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>-L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>conftest.so conftest.o
>-L/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/lib/server
>-ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>-Wl,CoreFoundation
>
>
>JAVA_HOME        :
>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>Java library path: $(JAVA_HOME)/lib/server
>JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>Done.
>The result of be pointed to Java 10 is rJava package not be able to
>build. 
>
>warning: [options] bootstrap class path not set in conjunction with
>-source 6
>warning: [options] source value 6 is obsolete and will be removed in a
>future release
>warning: [options] target value 1.6 is obsolete and will be removed in
>a future release
>warning: [options] To suppress warnings about obsolete options, use
>-Xlint:-options.
>Note: Some input files use or override a deprecated API.
>Note: Recompile with -Xlint:deprecation for details.
>Note: Some input files use unchecked or unsafe operations.
>Note: Recompile with -Xlint:unchecked for details.
>4 warnings
>/usr/bin/javah -d . -classpath . org.rosuda.JRI.Rengine
>Unable to locate an executable at
>"/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
>(-1)
>make[2]: *** [org_rosuda_JRI_Rengine.h] Error 2
>make[1]: *** [src/JRI.jar] Error 2
>make: *** [jri] Error 2
>ERROR: compilation failed for package ?rJava?
>* removing ?/Users/lpuerto/Library/R/3.x/library/rJava?
>* restoring previous ?/Users/lpuerto/Library/R/3.x/library/rJava?
>
>The downloaded source packages are in
>?/private/var/folders/wf/41gjf2mx7m7fmvfd8dr22_5h0000gn/T/RtmpT2kJMY/downloaded_packages?
>Warning message:
>In install.packages("rJava", repos = "cloud.r-project.org") :
>  installation of package ?rJava? had non-zero exit status
>I've checked and there isn't a javah on
>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah as
>in Java 9. Which make me think that either R CMD javareconf isn?t
>working properly with Java 10 or rJava is not yet compatible with Java
>10. 
>
>Does anyone know what is going on? 
>
>Thanks! 
>
>PS/ I?ve opened an issue <https://github.com/s-u/rJava/issues/137> in
>rJava?s github and a question in stackoverflow
><https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10>.
>
>
>
>Best Regards
>Luis Puerto
>http://luisspuerto.net
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From luiss.puerto at gmail.com  Wed Mar 28 09:56:39 2018
From: luiss.puerto at gmail.com (Luis Puerto)
Date: Wed, 28 Mar 2018 10:56:39 +0300
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
In-Reply-To: <A07DA58D-3C3A-452E-B0FA-2DB2ED737DC5@dcn.davis.ca.us>
References: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
 <A07DA58D-3C3A-452E-B0FA-2DB2ED737DC5@dcn.davis.ca.us>
Message-ID: <9B731A70-5A4E-4D4E-84AC-F104D8A20A2B@gmail.com>

Hi Jeff!! 

I really don?t know if running R CMD javareconf with sudo has posed a problem here, now or in the past. What I know is sometimes it?s the only way to really config it, if I don?t run with sudo, in the end it asks me if I want to overwrite the configuration from root 

override rw-r--r--  root/admin for
/usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
override rw-r--r--  root/admin for
/usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y

So I really don?t know if this is the problem here or not. 

I really think the problem for R is and rJava is there is no longer a javah file. 

Unable to locate an executable at
"/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
(-1)

Anyhow? I?m still puzzle by the fact that R CMD javareconf with sudo and without has different outcome. 

> configuring Java is not on-topic here

I can't understand why. The problem isn?t java itself but the tool to configure R to use it with a new version. 

Reading the released notes for Java 10: 

> tools/javah
>  <http://www.oracle.com/technetwork/java/javase/10-relnote-issues-4108729.html#JDK-8182758> JEP 313 Remove the Native-Header Generation Tool (javah) 
> As previously announced, the native-header tool, javah, has been removed.
> 
> Native headers can now be generated by using the Java compiler, javac, with the -h option.
> 
> See JDK-8182758 <http://bugs.java.com/view_bug.do?bug_id=JDK-8182758>

I don?t know if this can be fixed parsing an option in R CMD javareconf that points JAVAH to JAVAC -h 



> On 28 Mar 2018, at 04:39, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> 
> I am not a Mac user, but I do use Linux and I would recommend not running R with sudo unless you are an admin ninja. That defensive practice would render the answer to your question moot.
> 
> It is possible that your problem may have started with inappropriate use of sudo in configuring java, but configuring Java is not on-topic here.
> -- 
> Sent from my phone. Please excuse my brevity.
> 
> On March 27, 2018 12:25:33 PM PDT, Luis Puerto <luiss.puerto at gmail.com <mailto:luiss.puerto at gmail.com>> wrote:
>> Hi! 
>> 
>> I?m on macOS 10.13.3 and just installed the new Java 10 using Homebrew
>> Cask. I also have installed R with Homebrew. Everything seems to work
>> fine, however I just get different outputs if I run sudo R CMD
>> javareconf or R CMD javareconf. With sudo I get pointed to Java 9 and
>> without sudo I get pointed to Java 10. I really don?t know why. 
>> 
>> Without sudo:
>> 
>> $ R CMD javareconf                                                     
>> 
>> Java interpreter :
>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/java
>> Java version     : 10
>> Java home path   :
>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>> Java compiler    :
>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javac
>> Java headers gen.: /usr/bin/javah
>> Java archive tool:
>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jar
>> Non-system Java on macOS
>> 
>> trying to compile and link a JNI program
>> detected JNI cpp flags    : -I$(JAVA_HOME)/include
>> -I$(JAVA_HOME)/include/darwin
>> detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>> /usr/local/opt/llvm/bin/clang 
>> -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>> -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include
>> -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin
>> -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC 
>> -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>> conftest.o
>> /usr/local/opt/llvm/bin/clang++ -dynamiclib
>> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
>> -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>> -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>> conftest.so conftest.o
>> -L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server
>> -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>> -Wl,CoreFoundation
>> 
>> 
>> JAVA_HOME        :
>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>> Java library path: $(JAVA_HOME)/lib/server
>> JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>> JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>> Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>> override rw-r--r--  root/admin for
>> /usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
>> override rw-r--r--  root/admin for
>> /usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
>> Done.
>> With sudo:
>> 
>> $ sudo R CMD javareconf                                                
>> 
>> Java interpreter :
>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/java
>> Java version     : 9.0.4
>> Java home path   :
>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>> Java compiler    :
>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javac
>> Java headers gen.:
>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javah
>> Java archive tool:
>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/jar
>> Non-system Java on macOS
>> 
>> trying to compile and link a JNI program
>> detected JNI cpp flags    : -I$(JAVA_HOME)/include
>> -I$(JAVA_HOME)/include/darwin
>> detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>> /usr/local/opt/llvm/bin/clang 
>> -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>> -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include
>> -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include/darwin
>> -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC 
>> -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>> conftest.o
>> /usr/local/opt/llvm/bin/clang++ -dynamiclib
>> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
>> -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>> -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>> conftest.so conftest.o
>> -L/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/lib/server
>> -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>> -Wl,CoreFoundation
>> 
>> 
>> JAVA_HOME        :
>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>> Java library path: $(JAVA_HOME)/lib/server
>> JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>> JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>> Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>> Done.
>> The result of be pointed to Java 10 is rJava package not be able to
>> build. 
>> 
>> warning: [options] bootstrap class path not set in conjunction with
>> -source 6
>> warning: [options] source value 6 is obsolete and will be removed in a
>> future release
>> warning: [options] target value 1.6 is obsolete and will be removed in
>> a future release
>> warning: [options] To suppress warnings about obsolete options, use
>> -Xlint:-options.
>> Note: Some input files use or override a deprecated API.
>> Note: Recompile with -Xlint:deprecation for details.
>> Note: Some input files use unchecked or unsafe operations.
>> Note: Recompile with -Xlint:unchecked for details.
>> 4 warnings
>> /usr/bin/javah -d . -classpath . org.rosuda.JRI.Rengine
>> Unable to locate an executable at
>> "/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
>> (-1)
>> make[2]: *** [org_rosuda_JRI_Rengine.h] Error 2
>> make[1]: *** [src/JRI.jar] Error 2
>> make: *** [jri] Error 2
>> ERROR: compilation failed for package ?rJava?
>> * removing ?/Users/lpuerto/Library/R/3.x/library/rJava?
>> * restoring previous ?/Users/lpuerto/Library/R/3.x/library/rJava?
>> 
>> The downloaded source packages are in
>> ?/private/var/folders/wf/41gjf2mx7m7fmvfd8dr22_5h0000gn/T/RtmpT2kJMY/downloaded_packages?
>> Warning message:
>> In install.packages("rJava", repos = "cloud.r-project.org") :
>> installation of package ?rJava? had non-zero exit status
>> I've checked and there isn't a javah on
>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah as
>> in Java 9. Which make me think that either R CMD javareconf isn?t
>> working properly with Java 10 or rJava is not yet compatible with Java
>> 10. 
>> 
>> Does anyone know what is going on? 
>> 
>> Thanks! 
>> 
>> PS/ I?ve opened an issue <https://github.com/s-u/rJava/issues/137 <https://github.com/s-u/rJava/issues/137>> in
>> rJava?s github and a question in stackoverflow
>> <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10 <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10>>.
>> 
>> 
>> 
>> Best Regards
>> Luis Puerto
>> http://luisspuerto.net <http://luisspuerto.net/>
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>> and provide commented, minimal, self-contained, reproducible code.


From kevin.thorpe at utoronto.ca  Wed Mar 28 14:32:53 2018
From: kevin.thorpe at utoronto.ca (Kevin E. Thorpe)
Date: Wed, 28 Mar 2018 08:32:53 -0400
Subject: [R] unable to move temporary installation of package
In-Reply-To: <CO2PR0501MB8374BA5F74582987B876C7F92A30@CO2PR0501MB837.namprd05.prod.outlook.com>
References: <CO2PR0501MB8375CB985F1A3B7E6513F7392AD0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <04CEA19F-B86E-4614-AE01-8F5036DAE67B@dcn.davis.ca.us>
 <CO2PR0501MB837C879924F629ADF48559F92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <3BFA8AEF-FFC9-4281-B1DE-C57F67367F9E@dcn.davis.ca.us>
 <CO2PR0501MB8379223CC175B27AE900E8292AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <alpine.BSF.2.00.1803270955370.7457@pedal.dcn.davis.ca.us>
 <CO2PR0501MB8378F83798FF4817ABBAE3D92AC0@CO2PR0501MB837.namprd05.prod.outlook.com>
 <888f8b55-cc32-75cf-ce0c-a50420f23772@utoronto.ca>
 <CO2PR0501MB83761B34BED60B8577BA01392A30@CO2PR0501MB837.namprd05.prod.outlook.com>
 <CO2PR0501MB8374BA5F74582987B876C7F92A30@CO2PR0501MB837.namprd05.prod.outlook.com>
Message-ID: <4810ced2-b8c7-27e6-4c29-2837b9f985b0@utoronto.ca>

I am glad you found the culprit. I will tuck that additional piece of 
info away for the next time my students have trouble.

Kevin

On 03/27/2018 09:22 PM, Paul Lantos wrote:
> I think MalwareBytes may have been the culprit. I disabled it and it's working now (even with my regular antivirus running).
> 
> Thanks all for the advice!
> Paul
> 
> -----Original Message-----
> From: Paul Lantos
> Sent: Tuesday, March 27, 2018 8:35 PM
> To: Kevin E. Thorpe <kevin.thorpe at utoronto.ca>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help at r-project.org
> Subject: RE: [R] unable to move temporary installation of package
> 
> Thanks, Kevin. I have done that but no luck.
> Paul
> 
> -----Original Message-----
> From: Kevin E. Thorpe [mailto:kevin.thorpe at utoronto.ca]
> Sent: Tuesday, March 27, 2018 2:15 PM
> To: Paul Lantos <paul.lantos at duke.edu>; Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
> Cc: r-help at r-project.org
> Subject: Re: [R] unable to move temporary installation of package
> 
> I have seen that error from students trying to install, usually from the Rcpp package.
> 
> One suggestion I received was to try disabling your virus scanner while doing the install. The reason being that the scanner has not completed its job by the time the installer wants to move stuff around.
> 
> Kevin
> 
> On 03/27/2018 01:14 PM, Paul Lantos wrote:
>> Thanks,
>>
>> Here's the error, for example:
>>
>>> install.packages("mgcv")
>> Installing package into 'C:/Users/pl39/Documents/R/win-library/3.4'
>> (as 'lib' is unspecified)
>> trying URL 'https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_bin_windows_contrib_3.4_mgcv-5F1.8-2D23.zip&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=_oH3hPXmUvvElYCBZg_LBSX0-ZF3XUqACxmRdV1Gzso&e='
>> Content type 'application/zip' length 2775362 bytes (2.6 MB)
>> downloaded 2.6 MB
>>
>> package 'mgcv' successfully unpacked and MD5 sums checked Warning in
>> install.packages :
>>     unable to move temporary installation 'C:\Users\pl39\Documents\R\win-library\3.4\file1f287a90e67\mgcv' to 'C:\Users\pl39\Documents\R\win-library\3.4\mgcv'
>>
>> The downloaded binary packages are in
>> 	C:\Users\pl39\AppData\Local\Temp\RtmpWorMmU\downloaded_packages
>>>
>>
>>
>>> getOption("repos")
>>                                   CRAN                            CRANextra
>> "https://urldefense.proofpoint.com/v2/url?u=https-3A__mirrors.nics.utk.edu_cran_&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=vmRVCTk6BWFZihnxWmmt3Y-Jiz-XaemOdukRPfySpEY&e=" "https://urldefense.proofpoint.com/v2/url?u=http-3A__www.stats.ox.ac.uk_pub_RWin&d=DwICaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0Sj_gZ4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=5-qaO5WU1pkjvRmIviMw3IowdsiGfP6AgLhJVhucBw8&s=BUJFWakLtQSrcVuTuqJ-PPtwzHo5pfFje9q2D18Fs-Y&e="
>> attr(,"RStudio")
>> [1] TRUE
>>
>> I've used different CRAN mirrors though and gotten the same error.
>>
>>
>>
>> Would you suggest deleting my personal directory and recreating it? I get the same error if I try and install packages to my documents, my desktop, wherever, so I sort of doubt that would fix the problem.
>>
>> Paul
>>
>>
>> -----Original Message-----
>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>> Sent: Tuesday, March 27, 2018 1:14 PM
>> To: Paul Lantos <paul.lantos at duke.edu>
>> Cc: r-help at r-project.org
>> Subject: RE: [R] unable to move temporary installation of package
>>
>> Nothing jumps out at me yet.
>>
>> 1) You missed including the text of your command (presumably
>> install.packages) along with the actual text of the error.
>>
>> 2) What is the output of:
>>
>> getOption("repos")
>>
>> 3) You might also consider looking at
>>
>> system2( "cacls.exe", .libPaths()[1] )
>>
>> though we may not be able to interpret the output appropriately in this venue if you are working on a managed computer... you might need local help. I would guess you would need "yourdomain\youruser:(OI)(CI)F".
>>
>> Note that your personal R library is not deleted when you uninstall R...
>> if you have not yet deleted C:\Users\pl39\Documents\R\win-library\3.4
>> and let R re-create it then uninstalling would not have helped a permissions problem.
>>
>> On Tue, 27 Mar 2018, Paul Lantos wrote:
>>
>>> Ok, thanks --
>>>
>>>> sessionInfo()
>>> R version 3.4.4 (2018-03-15)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit) Running under: Windows >= 8
>>> x64 (build 9200)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.4 tools_3.4.4    yaml_2.1.14
>>>> .libPaths()
>>> [1] "C:/Users/pl39/Documents/R/win-library/3.4" "C:/Program Files/R/R-3.4.4/library"
>>>> file.info(.libPaths())
>>>                                            size isdir mode               mtime               ctime               atime
>>> C:/Users/pl39/Documents/R/win-library/3.4    0  TRUE  777 2018-03-27 10:21:39 2017-12-28 22:20:55 2018-03-27 10:21:39
>>> C:/Program Files/R/R-3.4.4/library           0  TRUE  777 2018-03-25 21:23:45 2018-03-25 21:23:08 2018-03-25 21:23:45
>>>                                            exe
>>> C:/Users/pl39/Documents/R/win-library/3.4  no
>>> C:/Program Files/R/R-3.4.4/library         no
>>>
>>> -----Original Message-----
>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>> Sent: Tuesday, March 27, 2018 1:16 AM
>>> To: Paul Lantos <paul.lantos at duke.edu>; r-help at r-project.org
>>> Subject: RE: [R] unable to move temporary installation of package
>>>
>>> Perhaps someone here will see something useful if you post the output of the following function calls:
>>>
>>> sessionInfo()
>>> .libPaths()
>>> file.info(.libPaths())
>>>
>>> and the verbatim (copied) error (in context) that you are seeing.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>>
>>> On March 26, 2018 6:27:10 PM PDT, Paul Lantos <paul.lantos at duke.edu> wrote:
>>>> Thanks Jeff,
>>>>
>>>> So I initially when I got the computer moved my old packages into
>>>> the new directory rather than downloading and installing them again.
>>>> That was fine. I then just did a test to see if I could write in the
>>>> folder and indeed I can. Just not via R.
>>>>
>>>> I uninstalled R Open, installed R 3.4.4, and the problem persisted,
>>>> including just running it from the R console rather than from R Studio.
>>>>
>>>> I haven't done anything (like installations) with administrator
>>>> rights
>>>> - I just have them. That said I've checked the permissions of the
>>>> library folder and I have all permission. I don't run R in any
>>>> special way.
>>>>
>>>> So I'm not sure where that leaves me... thanks for any suggestions.
>>>>
>>>> Paul
>>>>
>>>>
>>>>
>>>> -----Original Message-----
>>>> From: Jeff Newmiller [mailto:jdnewmil at dcn.davis.ca.us]
>>>> Sent: Monday, March 26, 2018 5:22 PM
>>>> To: r-help at r-project.org; Paul Lantos <paul.lantos at duke.edu>;
>>>> r-help at r-project.org
>>>> Subject: Re: [R] unable to move temporary installation of package
>>>>
>>>> A) Don't try to "move" packages from one library (=directory of
>>>> installed packages) to another.
>>>>
>>>> B) Although R Open is very close to CRAN R, it has some differences
>>>> that you REALLY NEED TO READ about at their website. Pay particular
>>>> attention to the checkpoint feature in this case. Note that troubles
>>>> installing it or with the MKL are probably off-topic here, though R
>>>> language questions should still be fair game.
>>>>
>>>> C) Having Administrator rights carries at least as much
>>>> responsibility to know what you are doing BEFORE you do it as it
>>>> bestows flexibility to get things done. If you used "Run As
>>>> Administrator" to install R or any packages then you have probably
>>>> set the permissions on your personal library inappropriately. If so,
>>>> you need to use your superpowers judiciously to eliminate your
>>>> personal library completely and then run R as a normal user to install/update R packages.
>>>> --
>>>> Sent from my phone. Please excuse my brevity.
>>>>
>>>> On March 26, 2018 12:16:02 PM PDT, Paul Lantos
>>>> <paul.lantos at duke.edu>
>>>> wrote:
>>>>> I'm running Windows 10 / R Studio / R Open 3.4.3
>>>>>
>>>>>
>>>>>
>>>>> Since getting a new computer recently I cannot install packages
>>>>> into
>>>> my
>>>>> personal libpath directory, and I can't seem to update packages (it
>>>>> says all packages are up to date even if I manually install an old
>>>>> version). I've got 100% admin rights on the computer and in the
>>>> library
>>>>> folder, I've set my R environment variable to specify the correct
>>>>> directory, I can freely move things manually in and out of the
>>>>> library
>>>>
>>>>> if needed, and R can read and use any package that's already in there.
>>>>> But I can't install or I get the "unable to move" error.
>>>>>
>>>>>
>>>>>
>>>>> I've uninstalled and reinstalled everything, tried this in
>>>>> non-Studio sessions using both R Open and regular R 3.4.4, and I
>>>>> get the same error.
>>>>>
>>>>>
>>>>>
>>>>> Thanks for any help,
>>>>>
>>>>> Paul Lantos
>>>>>
>>>>>
>>>>> _____________________________________________
>>>>> Paul M. Lantos, MD, MS GIS, FIDSA, FAAP, FACP Associate Professor
>>>>> of Internal Medicine and Pediatrics  Pediatric Infectious Diseases
>>>>> General Internal Medicine Duke University School of Medicine Duke
>>>>> Global Health Institute
>>>>> _____________________________________________
>>>>>
>>>>>
>>>>> 	[[alternative HTML version deleted]]
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_m
>>>>> ail
>>>>> m
>>>>> an_listinfo_r-2Dhelp&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0S
>>>>> j_g
>>>>> Z
>>>>> 4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQuR
>>>>> zjI
>>>>> S
>>>>> 0GBC710QPtmpe1rDy5PNvS-GI&s=OtjN9-16IbB6IqUW1THCx-YX8wccZgBEQmfZY6c
>>>>> uBI
>>>>> I
>>>>> &e=
>>>>> PLEASE do read the posting guide
>>>>> https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject
>>>>> .or
>>>>> g
>>>>> _posting-2Dguide.html&d=DwIFaQ&c=imBPVzF25OnBgGmVOlcsiEgHoG1i6YHLR0
>>>>> Sj_
>>>>> g
>>>>> Z4adc&r=pCiIbVPBNWU0azo0D48ChUH_fawb-FalNVOf1sUn1r4&m=twuFRS-tVJfQu
>>>>> Rzj
>>>>> I
>>>>> S0GBC710QPtmpe1rDy5PNvS-GI&s=sY7Wm-L9iESeuqa2CevDBwLsBx06RewTYq2-DF
>>>>> g9K M U&e= and provide commented, minimal, self-contained,
>>>>> reproducible
>>>> code.
>>>
>>


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From istazahn at gmail.com  Wed Mar 28 15:55:46 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 28 Mar 2018 09:55:46 -0400
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
In-Reply-To: <A07DA58D-3C3A-452E-B0FA-2DB2ED737DC5@dcn.davis.ca.us>
References: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
 <A07DA58D-3C3A-452E-B0FA-2DB2ED737DC5@dcn.davis.ca.us>
Message-ID: <CA+vqiLFWbaeMCHoXwDS_=X3kNZ05Kk2XCEEjyavTMZ+-2ONEBw@mail.gmail.com>

On Tue, Mar 27, 2018 at 9:39 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> I am not a Mac user, but I do use Linux and I would recommend not running R with sudo unless you are an admin ninja. That defensive practice would render the answer to your question moot.

I don't think this is reasonable advice, given that both R CMD
javareconf and the rJava package makefile explicitly instruct you to
run R CMD javareconf as root.


>
> It is possible that your problem may have started with inappropriate use of sudo in configuring java, but configuring Java is not on-topic here.

I also disagree with this. You don't have to answer if you don't want
to, but the question is about getting the rJava package to work with
Java JDK 10, and I for one consider that to be on-topic here.


Best,
Ista

> --
> Sent from my phone. Please excuse my brevity.
>
> On March 27, 2018 12:25:33 PM PDT, Luis Puerto <luiss.puerto at gmail.com> wrote:
>>Hi!
>>
>>I?m on macOS 10.13.3 and just installed the new Java 10 using Homebrew
>>Cask. I also have installed R with Homebrew. Everything seems to work
>>fine, however I just get different outputs if I run sudo R CMD
>>javareconf or R CMD javareconf. With sudo I get pointed to Java 9 and
>>without sudo I get pointed to Java 10. I really don?t know why.
>>
>>Without sudo:
>>
>>$ R CMD javareconf
>>
>>Java interpreter :
>>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/java
>>Java version     : 10
>>Java home path   :
>>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>>Java compiler    :
>>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javac
>>Java headers gen.: /usr/bin/javah
>>Java archive tool:
>>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jar
>>Non-system Java on macOS
>>
>>trying to compile and link a JNI program
>>detected JNI cpp flags    : -I$(JAVA_HOME)/include
>>-I$(JAVA_HOME)/include/darwin
>>detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>/usr/local/opt/llvm/bin/clang
>>-I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>>-I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include
>>-I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin
>>-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC
>>-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>>conftest.o
>>/usr/local/opt/llvm/bin/clang++ -dynamiclib
>>-Wl,-headerpad_max_install_names -undefined dynamic_lookup
>>-single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>>-L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>>conftest.so conftest.o
>>-L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server
>>-ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>>-Wl,CoreFoundation
>>
>>
>>JAVA_HOME        :
>>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>>Java library path: $(JAVA_HOME)/lib/server
>>JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>>JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>>override rw-r--r--  root/admin for
>>/usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
>>override rw-r--r--  root/admin for
>>/usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
>>Done.
>>With sudo:
>>
>>$ sudo R CMD javareconf
>>
>>Java interpreter :
>>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/java
>>Java version     : 9.0.4
>>Java home path   :
>>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>>Java compiler    :
>>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javac
>>Java headers gen.:
>>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javah
>>Java archive tool:
>>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/jar
>>Non-system Java on macOS
>>
>>trying to compile and link a JNI program
>>detected JNI cpp flags    : -I$(JAVA_HOME)/include
>>-I$(JAVA_HOME)/include/darwin
>>detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>/usr/local/opt/llvm/bin/clang
>>-I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>>-I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include
>>-I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include/darwin
>>-I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC
>>-g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>>conftest.o
>>/usr/local/opt/llvm/bin/clang++ -dynamiclib
>>-Wl,-headerpad_max_install_names -undefined dynamic_lookup
>>-single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>>-L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>>-L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>>conftest.so conftest.o
>>-L/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/lib/server
>>-ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>>-Wl,CoreFoundation
>>
>>
>>JAVA_HOME        :
>>/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>>Java library path: $(JAVA_HOME)/lib/server
>>JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>>JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>>Done.
>>The result of be pointed to Java 10 is rJava package not be able to
>>build.
>>
>>warning: [options] bootstrap class path not set in conjunction with
>>-source 6
>>warning: [options] source value 6 is obsolete and will be removed in a
>>future release
>>warning: [options] target value 1.6 is obsolete and will be removed in
>>a future release
>>warning: [options] To suppress warnings about obsolete options, use
>>-Xlint:-options.
>>Note: Some input files use or override a deprecated API.
>>Note: Recompile with -Xlint:deprecation for details.
>>Note: Some input files use unchecked or unsafe operations.
>>Note: Recompile with -Xlint:unchecked for details.
>>4 warnings
>>/usr/bin/javah -d . -classpath . org.rosuda.JRI.Rengine
>>Unable to locate an executable at
>>"/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
>>(-1)
>>make[2]: *** [org_rosuda_JRI_Rengine.h] Error 2
>>make[1]: *** [src/JRI.jar] Error 2
>>make: *** [jri] Error 2
>>ERROR: compilation failed for package ?rJava?
>>* removing ?/Users/lpuerto/Library/R/3.x/library/rJava?
>>* restoring previous ?/Users/lpuerto/Library/R/3.x/library/rJava?
>>
>>The downloaded source packages are in
>>?/private/var/folders/wf/41gjf2mx7m7fmvfd8dr22_5h0000gn/T/RtmpT2kJMY/downloaded_packages?
>>Warning message:
>>In install.packages("rJava", repos = "cloud.r-project.org") :
>>  installation of package ?rJava? had non-zero exit status
>>I've checked and there isn't a javah on
>>/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah as
>>in Java 9. Which make me think that either R CMD javareconf isn?t
>>working properly with Java 10 or rJava is not yet compatible with Java
>>10.
>>
>>Does anyone know what is going on?
>>
>>Thanks!
>>
>>PS/ I?ve opened an issue <https://github.com/s-u/rJava/issues/137> in
>>rJava?s github and a question in stackoverflow
>><https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10>.
>>
>>
>>
>>Best Regards
>>Luis Puerto
>>http://luisspuerto.net
>>
>>
>>       [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Wed Mar 28 16:07:40 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 28 Mar 2018 10:07:40 -0400
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
In-Reply-To: <9B731A70-5A4E-4D4E-84AC-F104D8A20A2B@gmail.com>
References: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
 <A07DA58D-3C3A-452E-B0FA-2DB2ED737DC5@dcn.davis.ca.us>
 <9B731A70-5A4E-4D4E-84AC-F104D8A20A2B@gmail.com>
Message-ID: <CA+vqiLHnASq1om0YBjsnbGE+SH-949kQo8oYgdPbqgZ+MCLKKQ@mail.gmail.com>

On Wed, Mar 28, 2018 at 3:56 AM, Luis Puerto <luiss.puerto at gmail.com> wrote:
> Hi Jeff!!
>
> I really don?t know if running R CMD javareconf with sudo has posed a problem here, now or in the past. What I know is sometimes it?s the only way to really config it, if I don?t run with sudo, in the end it asks me if I want to overwrite the configuration from root
>
> override rw-r--r--  root/admin for
> /usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
> override rw-r--r--  root/admin for
> /usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
>
> So I really don?t know if this is the problem here or not.
>
> I really think the problem for R is and rJava is there is no longer a javah file.
>
> Unable to locate an executable at
> "/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
> (-1)
>
> Anyhow? I?m still puzzle by the fact that R CMD javareconf with sudo and without has different outcome.

Why does this puzzle you? There is no reason to expect the root user's
environment to be the same as your user environment. You can look at

env > me.txt
sudo env > root.txt
diff me.txt root.txt

to see the differences.

>
>> configuring Java is not on-topic here
>
> I can't understand why. The problem isn?t java itself but the tool to configure R to use it with a new version.
>
> Reading the released notes for Java 10:
>
>> tools/javah
>>  <http://www.oracle.com/technetwork/java/javase/10-relnote-issues-4108729.html#JDK-8182758> JEP 313 Remove the Native-Header Generation Tool (javah)
>> As previously announced, the native-header tool, javah, has been removed.
>>
>> Native headers can now be generated by using the Java compiler, javac, with the -h option.
>>
>> See JDK-8182758 <http://bugs.java.com/view_bug.do?bug_id=JDK-8182758>
>
> I don?t know if this can be fixed parsing an option in R CMD javareconf that points JAVAH to JAVAC -h

I think you're on the right track here. I tried building rJava with R
configured to use openJDK 10 and got the same error you did. It
appears that rJava does not currently build under openJDK 10. You did
the right thing by opening an issue at
https://github.com/s-u/rJava/issues/137 -- now you just wait to see
what the rJava developers have to say about it. In the meantime, use
JDK 9.

Best,
Ista

>
>
>
>> On 28 Mar 2018, at 04:39, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>>
>> I am not a Mac user, but I do use Linux and I would recommend not running R with sudo unless you are an admin ninja. That defensive practice would render the answer to your question moot.
>>
>> It is possible that your problem may have started with inappropriate use of sudo in configuring java, but configuring Java is not on-topic here.
>> --
>> Sent from my phone. Please excuse my brevity.
>>
>> On March 27, 2018 12:25:33 PM PDT, Luis Puerto <luiss.puerto at gmail.com <mailto:luiss.puerto at gmail.com>> wrote:
>>> Hi!
>>>
>>> I?m on macOS 10.13.3 and just installed the new Java 10 using Homebrew
>>> Cask. I also have installed R with Homebrew. Everything seems to work
>>> fine, however I just get different outputs if I run sudo R CMD
>>> javareconf or R CMD javareconf. With sudo I get pointed to Java 9 and
>>> without sudo I get pointed to Java 10. I really don?t know why.
>>>
>>> Without sudo:
>>>
>>> $ R CMD javareconf
>>>
>>> Java interpreter :
>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/java
>>> Java version     : 10
>>> Java home path   :
>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>>> Java compiler    :
>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javac
>>> Java headers gen.: /usr/bin/javah
>>> Java archive tool:
>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jar
>>> Non-system Java on macOS
>>>
>>> trying to compile and link a JNI program
>>> detected JNI cpp flags    : -I$(JAVA_HOME)/include
>>> -I$(JAVA_HOME)/include/darwin
>>> detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>> /usr/local/opt/llvm/bin/clang
>>> -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>>> -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include
>>> -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin
>>> -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC
>>> -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>>> conftest.o
>>> /usr/local/opt/llvm/bin/clang++ -dynamiclib
>>> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
>>> -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>>> -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>>> conftest.so conftest.o
>>> -L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server
>>> -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>>> -Wl,CoreFoundation
>>>
>>>
>>> JAVA_HOME        :
>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>>> Java library path: $(JAVA_HOME)/lib/server
>>> JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>>> JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>> Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>>> override rw-r--r--  root/admin for
>>> /usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
>>> override rw-r--r--  root/admin for
>>> /usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
>>> Done.
>>> With sudo:
>>>
>>> $ sudo R CMD javareconf
>>>
>>> Java interpreter :
>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/java
>>> Java version     : 9.0.4
>>> Java home path   :
>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>>> Java compiler    :
>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javac
>>> Java headers gen.:
>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javah
>>> Java archive tool:
>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/jar
>>> Non-system Java on macOS
>>>
>>> trying to compile and link a JNI program
>>> detected JNI cpp flags    : -I$(JAVA_HOME)/include
>>> -I$(JAVA_HOME)/include/darwin
>>> detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>> /usr/local/opt/llvm/bin/clang
>>> -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>>> -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include
>>> -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include/darwin
>>> -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC
>>> -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>>> conftest.o
>>> /usr/local/opt/llvm/bin/clang++ -dynamiclib
>>> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
>>> -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>>> -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>>> conftest.so conftest.o
>>> -L/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/lib/server
>>> -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>>> -Wl,CoreFoundation
>>>
>>>
>>> JAVA_HOME        :
>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>>> Java library path: $(JAVA_HOME)/lib/server
>>> JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>>> JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>> Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>>> Done.
>>> The result of be pointed to Java 10 is rJava package not be able to
>>> build.
>>>
>>> warning: [options] bootstrap class path not set in conjunction with
>>> -source 6
>>> warning: [options] source value 6 is obsolete and will be removed in a
>>> future release
>>> warning: [options] target value 1.6 is obsolete and will be removed in
>>> a future release
>>> warning: [options] To suppress warnings about obsolete options, use
>>> -Xlint:-options.
>>> Note: Some input files use or override a deprecated API.
>>> Note: Recompile with -Xlint:deprecation for details.
>>> Note: Some input files use unchecked or unsafe operations.
>>> Note: Recompile with -Xlint:unchecked for details.
>>> 4 warnings
>>> /usr/bin/javah -d . -classpath . org.rosuda.JRI.Rengine
>>> Unable to locate an executable at
>>> "/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
>>> (-1)
>>> make[2]: *** [org_rosuda_JRI_Rengine.h] Error 2
>>> make[1]: *** [src/JRI.jar] Error 2
>>> make: *** [jri] Error 2
>>> ERROR: compilation failed for package ?rJava?
>>> * removing ?/Users/lpuerto/Library/R/3.x/library/rJava?
>>> * restoring previous ?/Users/lpuerto/Library/R/3.x/library/rJava?
>>>
>>> The downloaded source packages are in
>>> ?/private/var/folders/wf/41gjf2mx7m7fmvfd8dr22_5h0000gn/T/RtmpT2kJMY/downloaded_packages?
>>> Warning message:
>>> In install.packages("rJava", repos = "cloud.r-project.org") :
>>> installation of package ?rJava? had non-zero exit status
>>> I've checked and there isn't a javah on
>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah as
>>> in Java 9. Which make me think that either R CMD javareconf isn?t
>>> working properly with Java 10 or rJava is not yet compatible with Java
>>> 10.
>>>
>>> Does anyone know what is going on?
>>>
>>> Thanks!
>>>
>>> PS/ I?ve opened an issue <https://github.com/s-u/rJava/issues/137 <https://github.com/s-u/rJava/issues/137>> in
>>> rJava?s github and a question in stackoverflow
>>> <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10 <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10>>.
>>>
>>>
>>>
>>> Best Regards
>>> Luis Puerto
>>> http://luisspuerto.net <http://luisspuerto.net/>
>>>
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From luiss.puerto at gmail.com  Wed Mar 28 16:15:52 2018
From: luiss.puerto at gmail.com (Luis Puerto)
Date: Wed, 28 Mar 2018 17:15:52 +0300
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
In-Reply-To: <CA+vqiLG+VqzTt=wpkPqWge0ocpgjcNriBzH6FdzidUwNyND1-g@mail.gmail.com>
References: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
 <A07DA58D-3C3A-452E-B0FA-2DB2ED737DC5@dcn.davis.ca.us>
 <9B731A70-5A4E-4D4E-84AC-F104D8A20A2B@gmail.com>
 <CA+vqiLG+VqzTt=wpkPqWge0ocpgjcNriBzH6FdzidUwNyND1-g@mail.gmail.com>
Message-ID: <95F837E1-182B-4B03-8100-F547F6F7669A@gmail.com>

Hi Ista! 

Thanks a lot for your support!! 

It puzzles me because it?s the first time that something like this happens to me. I?m aware that root and user don?t have the same environmental variables here. However, I don?t know why root chooses Java 9 and my user chooses Java 10. Isn?t Java 10 ready to be used as a root? 

It seems that we are going to have to wait until rJava releases a new version and use Java 9 till then. I don?t have any problem with this. To be honest, I found out that Java jumped a version 10 because my wife was running out of space in her MacBook Air and checking for things to delete find she has 4 different versions of Java 1.8, 9.0.1, 9.0.4 and 10. Then just it occurred to me that perhaps I could config R with Java 10 and delete all the other version. Also in my computer? Then was when I came across all of these. 

Again, thanks a lot for your support! 

Best Regards
Luis Puerto
http://luisspuerto.net <http://luisspuerto.net/>
> On 28 Mar 2018, at 17:04, Ista Zahn <istazahn at gmail.com <mailto:istazahn at gmail.com>> wrote:
> 
> On Wed, Mar 28, 2018 at 3:56 AM, Luis Puerto <luiss.puerto at gmail.com <mailto:luiss.puerto at gmail.com>> wrote:
>> Hi Jeff!!
>> 
>> I really don?t know if running R CMD javareconf with sudo has posed a problem here, now or in the past. What I know is sometimes it?s the only way to really config it, if I don?t run with sudo, in the end it asks me if I want to overwrite the configuration from root
>> 
>> override rw-r--r--  root/admin for
>> /usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
>> override rw-r--r--  root/admin for
>> /usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
>> 
>> So I really don?t know if this is the problem here or not.
>> 
>> I really think the problem for R is and rJava is there is no longer a javah file.
>> 
>> Unable to locate an executable at
>> "/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
>> (-1)
>> 
>> Anyhow? I?m still puzzle by the fact that R CMD javareconf with sudo and without has different outcome.
> 
> Why does this puzzle you? There is no reason to expect the root user's
> environment to be the same as your user environment. You can look at
> 
> env > me.txt
> sudo env ? root.txt
> diff me.txt root.txt
> 
> to see the differences.
> 
>> 
>>> configuring Java is not on-topic here
>> 
>> I can't understand why. The problem isn?t java itself but the tool to configure R to use it with a new version.
>> 
>> Reading the released notes for Java 10:
>> 
>>> tools/javah
>>> <http://www.oracle.com/technetwork/java/javase/10-relnote-issues-4108729.html#JDK-8182758 <http://www.oracle.com/technetwork/java/javase/10-relnote-issues-4108729.html#JDK-8182758>> JEP 313 Remove the Native-Header Generation Tool (javah)
>>> As previously announced, the native-header tool, javah, has been removed.
>>> 
>>> Native headers can now be generated by using the Java compiler, javac, with the -h option.
>>> 
>>> See JDK-8182758 <http://bugs.java.com/view_bug.do?bug_id=JDK-8182758 <http://bugs.java.com/view_bug.do?bug_id=JDK-8182758>>
>> 
>> I don?t know if this can be fixed parsing an option in R CMD javareconf that points JAVAH to JAVAC -h
> 
> I think you're on the right track here. I tried building rJava with R
> configured to use openJDK 10 and got the same error you did. It
> appears that rJava does not currently build under openJDK 10. You did
> the right thing by opening an issue at
> https://github.com/s-u/rJava/issues/137 <https://github.com/s-u/rJava/issues/137> -- now you just wait to see
> what the rJava developers have to say about it. In the meantime, use
> JDK 9.
> 
> Best,
> Ista
> 
> 
>> 
>> 
>> 
>>> On 28 Mar 2018, at 04:39, Jeff Newmiller <jdnewmil at dcn.davis.ca.us <mailto:jdnewmil at dcn.davis.ca.us>> wrote:
>>> 
>>> I am not a Mac user, but I do use Linux and I would recommend not running R with sudo unless you are an admin ninja. That defensive practice would render the answer to your question moot.
>>> 
>>> It is possible that your problem may have started with inappropriate use of sudo in configuring java, but configuring Java is not on-topic here.
>>> --
>>> Sent from my phone. Please excuse my brevity.
>>> 
>>> On March 27, 2018 12:25:33 PM PDT, Luis Puerto <luiss.puerto at gmail.com <mailto:luiss.puerto at gmail.com> <mailto:luiss.puerto at gmail.com <mailto:luiss.puerto at gmail.com>>> wrote:
>>>> Hi!
>>>> 
>>>> I?m on macOS 10.13.3 and just installed the new Java 10 using Homebrew
>>>> Cask. I also have installed R with Homebrew. Everything seems to work
>>>> fine, however I just get different outputs if I run sudo R CMD
>>>> javareconf or R CMD javareconf. With sudo I get pointed to Java 9 and
>>>> without sudo I get pointed to Java 10. I really don?t know why.
>>>> 
>>>> Without sudo:
>>>> 
>>>> $ R CMD javareconf
>>>> 
>>>> Java interpreter :
>>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/java
>>>> Java version     : 10
>>>> Java home path   :
>>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>>>> Java compiler    :
>>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javac
>>>> Java headers gen.: /usr/bin/javah
>>>> Java archive tool:
>>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/jar
>>>> Non-system Java on macOS
>>>> 
>>>> trying to compile and link a JNI program
>>>> detected JNI cpp flags    : -I$(JAVA_HOME)/include
>>>> -I$(JAVA_HOME)/include/darwin
>>>> detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>>> /usr/local/opt/llvm/bin/clang
>>>> -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>>>> -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include
>>>> -I/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/include/darwin
>>>> -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC
>>>> -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>>>> conftest.o
>>>> /usr/local/opt/llvm/bin/clang++ -dynamiclib
>>>> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
>>>> -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>>>> -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>>>> conftest.so conftest.o
>>>> -L/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/lib/server
>>>> -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>>>> -Wl,CoreFoundation
>>>> 
>>>> 
>>>> JAVA_HOME        :
>>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home
>>>> Java library path: $(JAVA_HOME)/lib/server
>>>> JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>>>> JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>>> Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>>>> override rw-r--r--  root/admin for
>>>> /usr/local/Cellar/r/3.4.4/lib/R/etc/Makeconf? (y/n [n]) y
>>>> override rw-r--r--  root/admin for
>>>> /usr/local/Cellar/r/3.4.4/lib/R/etc/ldpaths? (y/n [n]) y
>>>> Done.
>>>> With sudo:
>>>> 
>>>> $ sudo R CMD javareconf
>>>> 
>>>> Java interpreter :
>>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/java
>>>> Java version     : 9.0.4
>>>> Java home path   :
>>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>>>> Java compiler    :
>>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javac
>>>> Java headers gen.:
>>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/javah
>>>> Java archive tool:
>>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/bin/jar
>>>> Non-system Java on macOS
>>>> 
>>>> trying to compile and link a JNI program
>>>> detected JNI cpp flags    : -I$(JAVA_HOME)/include
>>>> -I$(JAVA_HOME)/include/darwin
>>>> detected JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>>> /usr/local/opt/llvm/bin/clang
>>>> -I/usr/local/Cellar/r/3.4.4/lib/R/include -DNDEBUG
>>>> -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include
>>>> -I/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/include/darwin
>>>> -I/usr/local/opt/gettext/include -I/usr/local/opt/llvm/include   -fPIC
>>>> -g -O3 -Wall -pedantic -std=gnu99 -mtune=native -pipe -c conftest.c -o
>>>> conftest.o
>>>> /usr/local/opt/llvm/bin/clang++ -dynamiclib
>>>> -Wl,-headerpad_max_install_names -undefined dynamic_lookup
>>>> -single_module -multiply_defined suppress -L/usr/local/opt/gettext/lib
>>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib
>>>> -L/usr/local/Cellar/r/3.4.4/lib/R/lib -L/usr/local/opt/gettext/lib
>>>> -L/usr/local/opt/llvm/lib -Wl,-rpath,/usr/local/opt/llvm/lib -o
>>>> conftest.so conftest.o
>>>> -L/Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home/lib/server
>>>> -ljvm -L/usr/local/Cellar/r/3.4.4/lib/R/lib -lR -lintl -Wl,-framework
>>>> -Wl,CoreFoundation
>>>> 
>>>> 
>>>> JAVA_HOME        :
>>>> /Library/Java/JavaVirtualMachines/jdk-9.0.4.jdk/Contents/Home
>>>> Java library path: $(JAVA_HOME)/lib/server
>>>> JNI cpp flags    : -I$(JAVA_HOME)/include -I$(JAVA_HOME)/include/darwin
>>>> JNI linker flags : -L$(JAVA_HOME)/lib/server -ljvm
>>>> Updating Java configuration in /usr/local/Cellar/r/3.4.4/lib/R
>>>> Done.
>>>> The result of be pointed to Java 10 is rJava package not be able to
>>>> build.
>>>> 
>>>> warning: [options] bootstrap class path not set in conjunction with
>>>> -source 6
>>>> warning: [options] source value 6 is obsolete and will be removed in a
>>>> future release
>>>> warning: [options] target value 1.6 is obsolete and will be removed in
>>>> a future release
>>>> warning: [options] To suppress warnings about obsolete options, use
>>>> -Xlint:-options.
>>>> Note: Some input files use or override a deprecated API.
>>>> Note: Recompile with -Xlint:deprecation for details.
>>>> Note: Some input files use unchecked or unsafe operations.
>>>> Note: Recompile with -Xlint:unchecked for details.
>>>> 4 warnings
>>>> /usr/bin/javah -d . -classpath . org.rosuda.JRI.Rengine
>>>> Unable to locate an executable at
>>>> "/Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah"
>>>> (-1)
>>>> make[2]: *** [org_rosuda_JRI_Rengine.h] Error 2
>>>> make[1]: *** [src/JRI.jar] Error 2
>>>> make: *** [jri] Error 2
>>>> ERROR: compilation failed for package ?rJava?
>>>> * removing ?/Users/lpuerto/Library/R/3.x/library/rJava?
>>>> * restoring previous ?/Users/lpuerto/Library/R/3.x/library/rJava?
>>>> 
>>>> The downloaded source packages are in
>>>> ?/private/var/folders/wf/41gjf2mx7m7fmvfd8dr22_5h0000gn/T/RtmpT2kJMY/downloaded_packages?
>>>> Warning message:
>>>> In install.packages("rJava", repos = "cloud.r-project.org <http://cloud.r-project.org/>") :
>>>> installation of package ?rJava? had non-zero exit status
>>>> I've checked and there isn't a javah on
>>>> /Library/Java/JavaVirtualMachines/jdk-10.jdk/Contents/Home/bin/javah as
>>>> in Java 9. Which make me think that either R CMD javareconf isn?t
>>>> working properly with Java 10 or rJava is not yet compatible with Java
>>>> 10.
>>>> 
>>>> Does anyone know what is going on?
>>>> 
>>>> Thanks!
>>>> 
>>>> PS/ I?ve opened an issue <https://github.com/s-u/rJava/issues/137 <https://github.com/s-u/rJava/issues/137> <https://github.com/s-u/rJava/issues/137 <https://github.com/s-u/rJava/issues/137>>> in
>>>> rJava?s github and a question in stackoverflow
>>>> <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10 <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10> <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10 <https://stackoverflow.com/questions/49519007/sudo-r-cmd-javareconf-and-r-cmd-javareconf-produce-different-output-with-java-10>>>.
>>>> 
>>>> 
>>>> 
>>>> Best Regards
>>>> Luis Puerto
>>>> http://luisspuerto.net <http://luisspuerto.net/> <http://luisspuerto.net/ <http://luisspuerto.net/>>
>>>> 
>>>> 
>>>>     [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org <mailto:R-help at r-project.org> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help> <https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>>
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html> <http://www.r-project.org/posting-guide.html <http://www.r-project.org/posting-guide.html>>
>>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org <mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help <https://stat.ethz.ch/mailman/listinfo/r-help>
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From ahmedatia80 at gmail.com  Wed Mar 28 16:37:27 2018
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Wed, 28 Mar 2018 11:37:27 -0300
Subject: [R] Fwd: netCDF to GeoTIFF by layer in r
In-Reply-To: <CAG6S0O=KYQ_gqnmha2z2nnNFr8do0C6YgAk9JG5G8KvdnJrOSw@mail.gmail.com>
References: <CAG6S0O=KYQ_gqnmha2z2nnNFr8do0C6YgAk9JG5G8KvdnJrOSw@mail.gmail.com>
Message-ID: <CAG6S0Onr-w+ku_683n+UHjfP0eSeHNaxTJjwVr9G1qbiyZ31Yw@mail.gmail.com>

Hi

I have a netCDF file of volumetric soil water content at four
different soil layers and want to convert each soil layer in the
netCDF file to a GeoTIFF layer. This code converts the netCDF file to
one GeoTIFF layer, i.e. unclear which soil depth.

file.nc <- "C:/Soil_Weather_data/Agro/VMC21/VMC21.nc"

file.tiff <- "C:/Soil_Weather_data/Agro /VMC21/VMC21"

importnetcdf <- raster(file.nc)

> importnetcdf
class       : RasterLayer
band        : 1  (of  4  bands)
#the bands here are the four soil layers
dimensions  : 16800, 43200, 725760000  (nrow, ncol, ncell)
resolution  : 0.00833333, 0.00833333  (x, y)
extent      : -180, 179.9998, -56, 83.99995  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source :
C:\FAPSEP_Eucalyptus\FAPSEP\Soil_Weather_data\Agro_IBIS_Eucalipto\VMC21\VMC21.nc
names       : Volumetric.water.content.at..33.kPa
z-value     : 4.5
zvar        : VMC2



VMC1<-writeRaster(importnetcdf,filename="file.tiff",format="GTiff",overwrite=TRUE,bylayer=TRUE,suffix="1:4")
   #bylayer=TRUE, did not work.

> VMC1
class       : RasterLayer
dimensions  : 16800, 43200, 725760000  (nrow, ncol, ncell)
resolution  : 0.00833333, 0.00833333  (x, y)
extent      : -180, 179.9998, -56, 83.99995  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
+towgs84=0,0,0
data source : C:\Users\Ahmed\Documents\file.tif
names       : file
values      : 2, 80  (min, max)

Any help!


Ahmed Attia, Ph.D.
Agronomist & Soil Scientist

	[[alternative HTML version deleted]]


From ziad.elmously at kantar.com  Wed Mar 28 15:55:43 2018
From: ziad.elmously at kantar.com (Elmously, Ziad (TSHHM))
Date: Wed, 28 Mar 2018 13:55:43 +0000
Subject: [R] "dlm" Package: Calculating State Confidence Intervals
Message-ID: <VI1PR01MB10886F24BB7EE257E13E8A2796A30@VI1PR01MB1088.eurprd01.prod.exchangelabs.com>

To Whom It May Concern,

I estimated a model with 6 states (3 time-varying Regression parameters and 3 quarterly seasonality trends).  The model is saved in the object titled "mod."

Following the example in the documentation and using the commands below, I am attempting to use the function "dlmSvd2var" to implement SVD and calculate the 90% confidence errors for each time-varying state.

outF <- dlmFilter(y,mod)
v <- unlist(dlmSvd2var(outF$U.C, outF$D.C))
pl <- dropFirst(outF$m) + qnorm(0.05, sd=sqrt(v[-1]))
pu <- dropFirst(outF$m) + qnorm(0.95, sd=sqrt(v[-1]))

Since the dataset has 100 observations, I end up with a vector v that comprises 3636 atomic components: (1 + 100) x (6 x 6).  If I discard the 1st 36 of them, then v comprises 3600 atomic components.  The question is how to extract the variance of each state (6 states) in the 36 atomic components representing each time (1:100).

Said differently, how do I extract the variance of each state (6 states) in the 6 x 6 matrix generated by the "dlmDvd2var" function in time t?  Is this information provided in the diagonal elements, element (1,1) for state 1, element (2,2) for state 2, and so on?

Thank you in advance.

Ziad Elmously



Kantar Disclaimer<http://www.kantar.com/disclaimer.html>

	[[alternative HTML version deleted]]


From btupper at bigelow.org  Wed Mar 28 16:53:08 2018
From: btupper at bigelow.org (Ben Tupper)
Date: Wed, 28 Mar 2018 10:53:08 -0400
Subject: [R] netCDF to GeoTIFF by layer in r
In-Reply-To: <CAG6S0Onr-w+ku_683n+UHjfP0eSeHNaxTJjwVr9G1qbiyZ31Yw@mail.gmail.com>
References: <CAG6S0O=KYQ_gqnmha2z2nnNFr8do0C6YgAk9JG5G8KvdnJrOSw@mail.gmail.com>
 <CAG6S0Onr-w+ku_683n+UHjfP0eSeHNaxTJjwVr9G1qbiyZ31Yw@mail.gmail.com>
Message-ID: <83F329F7-B98D-4224-9663-9EAFB919B3C6@bigelow.org>

Hi Ahmed,

When reading from a ncdf file you can use the 'varname', 'lvar' and 'level' arguments - see the 'Details' section in the docs

https://www.rdocumentation.org/packages/raster/versions/2.6-7/topics/raster <https://www.rdocumentation.org/packages/raster/versions/2.6-7/topics/raster>

We can't tell what is in the ncdf file from what you report other than it has 4 bands (layers) and that the first is called 'Volumetric.water.content.at..33.kPa' If you want to know more about the what is in the file, then I suggest you use the ncdf4 package to open the file and explore it's contents - you should get a clear picture of it's contents from that.  Something like this (untested)...

library(ncdf4)
x <- nc_open(file.nc)
x
nc_close(x)

While print lots of info about the file.

Ben

> On Mar 28, 2018, at 10:37 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
> 
> Hi
> 
> I have a netCDF file of volumetric soil water content at four
> different soil layers and want to convert each soil layer in the
> netCDF file to a GeoTIFF layer. This code converts the netCDF file to
> one GeoTIFF layer, i.e. unclear which soil depth.
> 
> file.nc <- "C:/Soil_Weather_data/Agro/VMC21/VMC21.nc"
> 
> file.tiff <- "C:/Soil_Weather_data/Agro /VMC21/VMC21"
> 
> importnetcdf <- raster(file.nc)
> 
>> importnetcdf
> class       : RasterLayer
> band        : 1  (of  4  bands)
> #the bands here are the four soil layers
> dimensions  : 16800, 43200, 725760000  (nrow, ncol, ncell)
> resolution  : 0.00833333, 0.00833333  (x, y)
> extent      : -180, 179.9998, -56, 83.99995  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
> C:\FAPSEP_Eucalyptus\FAPSEP\Soil_Weather_data\Agro_IBIS_Eucalipto\VMC21\VMC21.nc
> names       : Volumetric.water.content.at..33.kPa
> z-value     : 4.5
> zvar        : VMC2
> 
> 
> 
> VMC1<-writeRaster(importnetcdf,filename="file.tiff",format="GTiff",overwrite=TRUE,bylayer=TRUE,suffix="1:4")
>   #bylayer=TRUE, did not work.
> 
>> VMC1
> class       : RasterLayer
> dimensions  : 16800, 43200, 725760000  (nrow, ncol, ncell)
> resolution  : 0.00833333, 0.00833333  (x, y)
> extent      : -180, 179.9998, -56, 83.99995  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
> +towgs84=0,0,0
> data source : C:\Users\Ahmed\Documents\file.tif
> names       : file
> values      : 2, 80  (min, max)
> 
> Any help!
> 
> 
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Tick Forecasting: https://eco.bigelow.org/





	[[alternative HTML version deleted]]


From ahmedatia80 at gmail.com  Wed Mar 28 17:38:14 2018
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Wed, 28 Mar 2018 12:38:14 -0300
Subject: [R] netCDF to GeoTIFF by layer in r
In-Reply-To: <83F329F7-B98D-4224-9663-9EAFB919B3C6@bigelow.org>
References: <CAG6S0O=KYQ_gqnmha2z2nnNFr8do0C6YgAk9JG5G8KvdnJrOSw@mail.gmail.com>
 <CAG6S0Onr-w+ku_683n+UHjfP0eSeHNaxTJjwVr9G1qbiyZ31Yw@mail.gmail.com>
 <83F329F7-B98D-4224-9663-9EAFB919B3C6@bigelow.org>
Message-ID: <CAG6S0OmkzVMqZEJgfYS265Z21U3CoXSVV_MV42D2GQEj_s=3uQ@mail.gmail.com>

Hi Ben,

Adding 'band' to raster provided what I want;

importnetcdf <- raster(file.nc,band=4)
writeRaster(importnetcdf,file.tiff,"GTiff",overwrite=FALSE)

Thanks for your help.

Ahmed



Ahmed Attia, Ph.D.
Agronomist & Soil Scientist





On Wed, Mar 28, 2018 at 11:53 AM, Ben Tupper <btupper at bigelow.org> wrote:

> Hi Ahmed,
>
> When reading from a ncdf file you can use the 'varname', 'lvar' and
> 'level' arguments - see the 'Details' section in the docs
>
> https://www.rdocumentation.org/packages/raster/versions/2.6-
> 7/topics/raster
>
> We can't tell what is in the ncdf file from what you report other than it
> has 4 bands (layers) and that the first is called '
> Volumetric.water.content.at..33.kPa' If you want to know more about the
> what is in the file, then I suggest you use the ncdf4 package to open the
> file and explore it's contents - you should get a clear picture of it's
> contents from that.  Something like this (untested)...
>
> library(ncdf4)
> x <- nc_open(file.nc)
> x
> nc_close(x)
>
> While print lots of info about the file.
>
> Ben
>
> On Mar 28, 2018, at 10:37 AM, Ahmed Attia <ahmedatia80 at gmail.com> wrote:
>
> Hi
>
> I have a netCDF file of volumetric soil water content at four
> different soil layers and want to convert each soil layer in the
> netCDF file to a GeoTIFF layer. This code converts the netCDF file to
> one GeoTIFF layer, i.e. unclear which soil depth.
>
> file.nc <- "C:/Soil_Weather_data/Agro/VMC21/VMC21.nc"
>
> file.tiff <- "C:/Soil_Weather_data/Agro /VMC21/VMC21"
>
> importnetcdf <- raster(file.nc)
>
> importnetcdf
>
> class       : RasterLayer
> band        : 1  (of  4  bands)
> #the bands here are the four soil layers
> dimensions  : 16800, 43200, 725760000  (nrow, ncol, ncell)
> resolution  : 0.00833333, 0.00833333  (x, y)
> extent      : -180, 179.9998, -56, 83.99995  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
> C:\FAPSEP_Eucalyptus\FAPSEP\Soil_Weather_data\Agro_IBIS_Euca
> lipto\VMC21\VMC21.nc
> names       : Volumetric.water.content.at..33.kPa
> z-value     : 4.5
> zvar        : VMC2
>
>
>
> VMC1<-writeRaster(importnetcdf,filename="file.tiff",format="
> GTiff",overwrite=TRUE,bylayer=TRUE,suffix="1:4")
>   #bylayer=TRUE, did not work.
>
> VMC1
>
> class       : RasterLayer
> dimensions  : 16800, 43200, 725760000  (nrow, ncol, ncell)
> resolution  : 0.00833333, 0.00833333  (x, y)
> extent      : -180, 179.9998, -56, 83.99995  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +no_defs +ellps=WGS84
> +towgs84=0,0,0
> data source : C:\Users\Ahmed\Documents\file.tif
> names       : file
> values      : 2, 80  (min, max)
>
> Any help!
>
>
> Ahmed Attia, Ph.D.
> Agronomist & Soil Scientist
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive
> <https://maps.google.com/?q=60+Bigelow+Drive&entry=gmail&source=g>, P.O.
> Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Tick Forecasting: https://eco.bigelow.org/
>
>
>
>
>

	[[alternative HTML version deleted]]


From orlin_mitov at yahoo.com  Wed Mar 28 18:32:33 2018
From: orlin_mitov at yahoo.com (orlin mitov)
Date: Wed, 28 Mar 2018 16:32:33 +0000 (UTC)
Subject: [R] Creating the right table from lapply list
References: <61612798.671079.1522254753438.ref@mail.yahoo.com>
Message-ID: <61612798.671079.1522254753438@mail.yahoo.com>

Hello,
  I have no previous experience with R, but had to learn on the fly in the past couple of weeks. Basically, what I am trying to do is read a certain variable from a series of files and save it as csv-table. The variable has an hourly value for each month in a year for the past 20 years and has to be read for different geographical locations. So there will be 12 files per year (1 for each month) and the values for the variable from each file will be 696 to 744 (depending on how many days x 24 hours there were in the month).What I achieved is to to read the values from all 12 files stored in directory with a function and add them as vectors to a lapply-list:



Myfunction <- function(filename) {
 nc <- nc_open(filename)
 lon <- ncvar_get(nc, "lon")
 lat <- ncvar_get(nc, "lat")
 RW <- ncvar_get(nc, "X")
 HW <- ncvar_get(nc, "Y")
 pt.geo <- c(8.6810 , 50.1143)
 dist <- sqrt( (lon - pt.geo[1])^2 + (lat - pt.geo[2])^2 )
 ind <- which(dist==min(dist, na.rm=TRUE),arr.ind=TRUE)
 sis <- ncvar_get(nc, "SIS", start=c(ind[1],ind[2],1), count=c(1,1,-1))
 vec <- c(sis)
}

filenames <- list.files(path = "C:/Users/Desktop/VD/Solardaten/NC", pattern = "nc", full.names = TRUE)
 output <- lapply(filenames, Myfunction)



And here start my problems with saving "output" as a csv table. Output would contain 12 vectors of different lenght.I want to have them as 12 columns (1x per month) in Excel and each column should have as many row-entries as there are values for this month.Whatever I tried with write.table I was not able to achieve this (tried converting the output to a matrix, also no successes).Please help! Or should I be trying to have the 12 elements as data frames and not vectors?
This is how I want the table for each year to look - 12 columns and all the respective values in the rows (column names I can add by myself):
Best regardsOrlin


-------------- next part --------------
A non-text attachment was scrubbed...
Name: grafik.png
Type: image/png
Size: 120645 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180328/424b655c/attachment.png>

From alexander.pate at manchester.ac.uk  Wed Mar 28 19:27:16 2018
From: alexander.pate at manchester.ac.uk (Alexander Pate)
Date: Wed, 28 Mar 2018 17:27:16 +0000
Subject: [R] coxme in R underestimates variance of random effect,
 when random effect is on observation level
Message-ID: <1FBFD3C651590248A8EE6C86B93BE4173318D9AA@MBXP01.ds.man.ac.uk>

Hello,



I have a question concerning fitting a cox model with a random intercept, also known as a frailty model. I am using both the coxme package, and the frailty statement in coxph. Often 'shared' frailty models are implemented in practice, to group people who are from a cluster to account for homogeneity in outcomes for people from the same cluster. I am more interested in the classic frailty model, 'Early frailty models incorporated subject-specific random effects to account for unmeasured subject characteristics that influenced the hazard of the occurrence of the outcome'. This is because I have data where I would like to estimate the amount of variation between patients risks that has not been accounted for by adjusting for the variables that I have.



I initially ran some simulations to check that I could estimate the variance of such random effects consistently with no bias. When the random effect is applied on the group level (shared frailty model), the variance of the random effect can be calculated. When the random effect is on an observation level, it is consistently underestimated. This happens when using both the coxme<https://cran.r-project.org/web/packages/coxme/coxme.pdf> package, and the and frailty<https://www.rdocumentation.org/packages/survival/versions/2.11-4/topics/frailty> statement in coxph.



Questions:

1) Why is variance of the random effect underestimating when the random effect is on an individual level, is this a mathematical problem or a coding issue?

2) Is there any literature/R packages that look specifically at random effects applied on the observation level?



Many thanks for any solutions/or references which may be helpful.

Reproducible example here (using coxme):
setwd("/mnt/ja01-home01/mbrxsap3/phd_risk/R/p4_run_analysis/")

  library(coxme)
  library(survival)

  ### Create data with a group level random effect
  simulWeib.group <- function(N, lambda, rho, beta1, beta2, beta3, beta4, rateC, sigma, M)
  {
    # covariate --> N Bernoulli trials
    x1 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))
    x2 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))
    x3 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))
    x4 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))


    # Now create random effect stuff
    # Create vector of groups
    re.group <- sample(x=1:M, size=N, replace=TRUE, prob=rep(1/M, M))

    # Create vector of r.e effects
    re.effect <- rnorm(M,0,sigma)

    # Now create a vector which assigns the re.effect depending on the group
    re.group.effect <- re.effect[re.group]

    # Weibull latent event times
    v <- runif(n=N)
    Tlat <- round((- log(v) / (lambda * exp(x1 * beta1 + x2 * beta2 + x3 * beta3 + x4 * beta4 + re.group.effect)))^(1 / rho))

    # censoring times
    #C <-rep(100000,N)
    C <- rexp(n=N, rate=rateC)

    # follow-up times and event indicators
    time <- pmin(Tlat, C)
    #status <- as.numeric(rep(1,N))
    status <- as.numeric(Tlat <= C)

    # data set
    data.frame(id=1:N,
               time=time,
               status=status,
              x1 = x1,
               x2 = x2,
               x3 = x3,
               x4 = x4,
               group=re.group)
  }


  ### Create data with an individual level random effect
  simulWeib <- function(N, lambda, rho, beta1, beta2, beta3, beta4, rateC, sigma)
  {
    # covariate --> N Bernoulli trials
    x1 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))
    x2 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))
    x3 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))
    x4 <- sample(x=c(0, 1), size=N, replace=TRUE, prob=c(0.5, 0.5))


    # Now create random effect stuff
    # Create one vector of length N, all drawn from same normal distribution
    rand.effect <- rnorm(N,0,sigma)

    # Weibull latent event times
    v <- runif(n=N)
    Tlat <- round((- log(v) / (lambda * exp(x1 * beta1 + x2 * beta2 + x3 * beta3 + x4 * beta4 + rand.effect)))^(1 / rho))

    # censoring times
    #C <-rep(100000,N)
    C <- rexp(n=N, rate=rateC)

    # follow-up times and event indicators
    time <- pmin(Tlat, C)
    #status <- as.numeric(rep(1,N))
    status <- as.numeric(Tlat <= C)

    # data set
    data.frame(id=1:N,
               time=time,
               status=status,
               x1 = x1,
               x2 = x2,
               x3 = x3,
               x4 = x4)
  }


  set.seed(101)

  ### Individual random effects (frailty).
  sd.2<-rep(0,50)
  for (i in 1:50){
    data2<-simulWeib(25000,lambda=0.0001,rho=2,beta1=0.33,beta2=5,beta3=0.25,beta4=0,rateC=0.0000000001, sigma = 0.25)
    data2$id<-as.factor(data2$id)
    fit.cox2<-coxme(Surv(time,status) ~ x1 + x2 + x3 + (1 | id), data=data2)
    sd.2[i]<-sqrt(as.numeric(fit.cox2$vcoef))
    print(i)
  }

  print("model 2 done")


  ### Same as previous example, but patients are grouped

  sd.10<-rep(0,50)
  for (i in 1:50){
    data10<-simulWeib.group(25000,lambda=0.0001,rho=2,beta1=0.33,beta2=5,beta3=0.25,beta4=0,rateC=0.0000000001, sigma = 0.25, M=40)
    data10$group<-as.factor(data10$group)
    fit.cox10<-coxme(Surv(time,status) ~ x1 + x2 + x3 + (1 | group), data=data10)
    sd.10[i]<-sqrt(as.numeric(fit.cox10$vcoef))
    print(i)
  }

  print("model 10 done")



PhD student
Health e-Research Centre ? Farr Institute
Rm 2.006 ? Vaughan House ? Portsmouth Street ? University of Manchester ? M13 9GB


	[[alternative HTML version deleted]]


From jocpaine at googlemail.com  Wed Mar 28 20:27:58 2018
From: jocpaine at googlemail.com (Jocelyn Ireson-Paine)
Date: Wed, 28 Mar 2018 19:27:58 +0100
Subject: [R] Using R and the Tidyverse for an economic model
In-Reply-To: <alpine.BSF.2.00.1803271037000.7457@pedal.dcn.davis.ca.us>
References: <CAOdhVrFTGPi19d6KU9z249r_SHp+7AYLc114YR7aOFCUXuPu9w@mail.gmail.com>
 <alpine.BSF.2.00.1803271037000.7457@pedal.dcn.davis.ca.us>
Message-ID: <CAOdhVrG5Ea=xumTb8T=AFZ-t3Q5DLFja5yQ3R4iw2Mv6qdBi1Q@mail.gmail.com>

Jeff, thanks for taking the time to read and comment.

About the points you raise:

1) Packages. I do understand the advantages of packages. But I'm still
prototyping, and it seemed too complicated to make every source file a
separate package, when I'm still often moving source code from one to
another. At the moment, one directory full of source files is simpler
to experiment with and test.

2) Documentation. What I'm concerned with here is not so much where to
put the documentation, as what to write. I follow the
abstract-datatype approach (
https://www.geeksforgeeks.org/abstract-data-types/ ), which is that
the internal structure of a value should be hidden. What's important
is its behaviour: the functions one can call on it, and the types of
result they return. The implementor should be free to change
representation as radically as he or she desires, as long as those
calls remain the same. That is, the _interface_ is not affected. (See
the cartoon I drew at
http://www.j-paine.org/dobbs/engineers_honouring_the_uniform_referent_principle_708.png
.)

But $ and [[ are pervasive in R, and as you say, there are times when
I shouldn't avoid them. On the other hand, I know that I'm likely to
make big changes to some structures while experimenting with
efficiency. I want to proof the rest of the program against those
changes, and I want to proof the rest of my _documentation_ against
those changes. So that means I have to document in a
representation-independent way.

There are also some very R-specific things that I need to think about.
For example, I need to say whether every function is vectorised, don't
I? And I need to say whether NA can occur in every value, and if so,
what it means. These are the documentation-related things I've been
thinking about.

3) Classes. I agree with you, and I have not used any of R's object
systems. Most of my data is, in fact, lists (possibly
tree-structured), vectors, or tibbles.

4) Representation-independent selectors. See 2. It's the
abstract-datatype thing again, wanting to proof code and documentation
outside a module against changes to how the data defined by that
module is stored.

Thanks again. I do welcome comment on these points, because there are
lots of trade-offs to consider, and I know I may be overlooking all
kinds of things I should know.

Jocelyn

On Tue, Mar 27, 2018 at 7:20 PM, Jeff Newmiller
<jdnewmil at dcn.davis.ca.us> wrote:
> Looks like you have made an impressive start and some attractive
> introductions. I have no significant interest in your topic (sorry), but it
> seems that you are re-inventing the wheel a bit in regards to much of your
> documentation and modularization... R packages can help you solve these
> problems in a cross-platform way. You might try starting with [1] and
> referring to [2] as needed.
>
> Regarding your representation-independent selectors... this looks to me like
> yet another representation (I think the term is "network database"), and
> subject to specific advantages and limitations that this representation
> imposes. For most work I do, tidy data frames have an excellent balance of
> speed and adaptability. For other types of analyses, multi-dimensional
> arrays would be better. Nested lists are extremely flexible, but not
> particularly fast (some would say quite slow, but that depends on your use
> case). Sometimes a relational database or the data.table package [3] can be
> used for increased performance, but your functional interface would not be
> compatible with _merging_ the information efficiently, while dplyr can
> theoretically support any data store that presents a tabular data interface
> with data merge capability.
>
> R seems to work best when used in the functional paradigm operating on
> general-purpose objects... functions that transform, analyze, and present
> data. Having more general classes of objects means more re-use and ad-hoc
> analysis can occur. If I make an object of class "myspecial", only functions
> I write will be useful. Making it a subclass of a more general class is one
> way to make it more widely useful, but avoiding making it a subclass of the
> general class at all can be the most flexible design principle... which is
> what "tidy data" aspires to do with data frames.
>
> That is, I think you should not be avoiding $ (or more generally the "[["
> operator)... you should be embracing it and enabling users to use it as
> well. Just don't go all multi-level with it... prefer multi-column indexes
> in data frames in most cases (e.g [4]).
>
> [1] http://r-pkgs.had.co.nz/
> [2] https://cran.r-project.org/doc/manuals/R-exts.html
> [3]
> https://cran.r-project.org/web/packages/data.table/vignettes/datatable-intro.html
> [4] https://www.jstatsoft.org/article/view/v040i01/v40i01.pdf
>
> On Mon, 26 Mar 2018, Jocelyn Ireson-Paine via R-help wrote:
>
>> I've been translating an economic model from Python into R, and I thought
>> members of the list would like to see a presentation I've written about
>> it.
>> I've blogged this at
>>
>> http://www.j-paine.org/blog/2018/03/r-taxben-a-microsimulation-economic-model-in-r.html
>> , and the presentation itself is a slideshow at
>> http://www.j-paine.org/rtaxben/R/reveal/rtaxben.html . The slideshow is
>> written as one side of a conversation which reveals R and the Tidyverse a
>> feature at a time to a colleague not familiar with R. Those who _are_
>> familar with R might prefer the version at
>> http://www.j-paine.org/rtaxben/R/reveal/rtaxben_anim.html . Exactly the
>> same material, but, as explained in my introduction, quicker to read. Read
>> the blog post first.
>>
>> Our model, R-Taxben, is a microeconomic model, which simulates at the
>> level
>> of individual people rather than bulk variables such as unemployment and
>> inflation. It works, roughly speaking, by reading survey data about actual
>> households, then applying taxes and benefits to calculate net income and
>> expenditure from gross. It has four main parts: (1) read and process
>> parameters which describe the taxes and benefits; (2) read the household
>> data from CSV files and transform into data frames usable by the model;
>> (3)
>> apply the taxes and benefits, calculating such things as council tax, VAT,
>> child benefit, and pensions; (4) display the results.
>>
>> My slides are mainly about (2) and (4), but do touch on the others. I
>> suggest, for example, that legible R code for (3) could be used as a
>> "reference standard" against which to describe the notoriously complex UK
>> benefits system. Organisations such as the Child Poverty Action Group have
>> written handbooks for benefits advisers which try to specify the system
>> precisely. We'd like to use R for an electronic version of these.
>>
>> I've said quite a bit about R for probing and plotting data. Not only for
>> economists, but for students learning about economics, fiscal policy, and
>> statistics. And after a brief intro to base R, I've concentrated on the
>> Tidyverse, because of what I see as its advantages. There are lots of
>> small
>> demos of the Tidyverse scattered around the web, but fewer of big projects
>> which use lots of different features from it. So my examples here might be
>> useful.
>>
>> Reliability and accuracy are vital, which is why I have more slides about
>> testing than about anything else, with examples of "testthat".
>>
>> Near the end, I show a web interface, built using Vis.js , which displays
>> dataflow in the model. The aim is to make it completely scrutable, so that
>> none of its economic assumptions are a mystery.
>>
>> We're looking for funding to go beyond this prototype. There are places
>> where we'll probably need help with such things as efficiency (see the
>> section on representation-independent selectors), efficiency again
>> (multiple JOINs), and the best way to overcome lack of static typing. It
>> would be great to have R experts, even R implementors, who were willing to
>> advise on this, and even to collaborate on our grant applications.
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ---------------------------------------------------------------------------


From bgunter.4567 at gmail.com  Wed Mar 28 22:05:50 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Wed, 28 Mar 2018 13:05:50 -0700
Subject: [R] Creating the right table from lapply list
In-Reply-To: <61612798.671079.1522254753438@mail.yahoo.com>
References: <61612798.671079.1522254753438.ref@mail.yahoo.com>
 <61612798.671079.1522254753438@mail.yahoo.com>
Message-ID: <CAGxFJbSLW03T6Wbaj5XKRdb-cTTQRGCbwzX7RKPxBw_boAwSPw@mail.gmail.com>

If I understand correctly, this query is really about how to organize
your data, not how to use R code to do it, though that may come later.
Of course, the first question is why mess with Excel at all? But I
shall assume you have good reason to get your data into Excel and do
what you want to with it there rather than in R.  That being the case,
the next question is why mess with your data in R ?-- I assume Excel
has tools to extract data from files and organize it for analysis --
that, presumably, is its purpose!

However, as the kids say, whatever...

I assume the tables you describe come one per location. If I were
doing this in R, I would organize the data ("tidyverse" style to use
Hadley's phrase) for each location into a data frame of 3 columns:
Year  Month  Value  . I would then combine all columns into one data
frame with columns  Location  Year   Month Value which could then be
exported as a CSV if you like.

But this likely depends on what you wish/need to do with the data in
Excel and possibly also your Excel skills in creating/converting the
data structures you need there, about which, of course, you have given
no information. So you may need to provide further detail to get
useful help. Or wait for someone smarter to reply.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Wed, Mar 28, 2018 at 9:32 AM, orlin mitov via R-help
<r-help at r-project.org> wrote:
> Hello,
>   I have no previous experience with R, but had to learn on the fly in the past couple of weeks. Basically, what I am trying to do is read a certain variable from a series of files and save it as csv-table. The variable has an hourly value for each month in a year for the past 20 years and has to be read for different geographical locations. So there will be 12 files per year (1 for each month) and the values for the variable from each file will be 696 to 744 (depending on how many days x 24 hours there were in the month).What I achieved is to to read the values from all 12 files stored in directory with a function and add them as vectors to a lapply-list:
>
>
>
> Myfunction <- function(filename) {
>  nc <- nc_open(filename)
>  lon <- ncvar_get(nc, "lon")
>  lat <- ncvar_get(nc, "lat")
>  RW <- ncvar_get(nc, "X")
>  HW <- ncvar_get(nc, "Y")
>  pt.geo <- c(8.6810 , 50.1143)
>  dist <- sqrt( (lon - pt.geo[1])^2 + (lat - pt.geo[2])^2 )
>  ind <- which(dist==min(dist, na.rm=TRUE),arr.ind=TRUE)
>  sis <- ncvar_get(nc, "SIS", start=c(ind[1],ind[2],1), count=c(1,1,-1))
>  vec <- c(sis)
> }
>
> filenames <- list.files(path = "C:/Users/Desktop/VD/Solardaten/NC", pattern = "nc", full.names = TRUE)
>  output <- lapply(filenames, Myfunction)
>
>
>
> And here start my problems with saving "output" as a csv table. Output would contain 12 vectors of different lenght.I want to have them as 12 columns (1x per month) in Excel and each column should have as many row-entries as there are values for this month.Whatever I tried with write.table I was not able to achieve this (tried converting the output to a matrix, also no successes).Please help! Or should I be trying to have the 12 elements as data frames and not vectors?
> This is how I want the table for each year to look - 12 columns and all the respective values in the rows (column names I can add by myself):
> Best regardsOrlin
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From varinsacha at yahoo.fr  Thu Mar 29 00:27:44 2018
From: varinsacha at yahoo.fr (varin sacha)
Date: Wed, 28 Mar 2018 22:27:44 +0000 (UTC)
Subject: [R] can not install package "matie"
References: <1336347725.936971.1522276064897.ref@mail.yahoo.com>
Message-ID: <1336347725.936971.1522276064897@mail.yahoo.com>

Dear R-experts,

I can not install the package "matie". If somebody can tell me where the problem is.

> install.packages("matie")
Installing package into ?/Users/Caro/Library/R/3.3/library?
(as ?lib? is unspecified)
essai de l'URL 'https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/matie_1.2.tgz'
Content type 'application/x-gzip' length 80151 bytes (78 KB)
==================================================
downloaded 78 KB


The downloaded binary packages are in
?? ?/var/folders/hj/11q7wt055rg83y2vj45whdmw0000gn/T//RtmpqjqsFe/downloaded_packages

> library(matie)
Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) : 
? aucun package nomm? ?proxy? n'est trouv?
Erreur : le chargement du package ou de l'espace de noms a ?chou? pour ?matie?

Here is my sessionInfo

> sessionInfo()
R version 3.3.2 (2016-10-31)
Platform: x86_64-apple-darwin13.4.0 (64-bit)
Running under: macOS Sierra 10.12.4

locale:
[1] fr_CH.UTF-8/fr_CH.UTF-8/fr_CH.UTF-8/C/fr_CH.UTF-8/fr_CH.UTF-8

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base??? ?

loaded via a namespace (and not attached):
?[1] Rcpp_0.12.7??????? DEoptimR_1.0-6???? plyr_1.8.4???????? viridis_0.3.4????? class_7.3-14???? ?
?[6] bitops_1.0-6?????? iterators_1.0.8??? tools_3.3.2??????? prabclus_2.2-6???? dendextend_1.7.0 ?
[11] mclust_5.4???????? tibble_1.2???????? gtable_0.2.0?????? lattice_0.20-34??? pkgconfig_2.0.1? ?
[16] igraph_1.1.2?????? foreach_1.4.3????? registry_0.5?????? mvtnorm_1.0-5????? seriation_1.2-2? ?
[21] TSP_1.1-5????????? gridExtra_2.2.1??? trimcluster_0.1-2? cluster_2.0.5????? gtools_3.5.0???? ?
[26] caTools_1.17.1???? fpc_2.1-11???????? diptest_0.75-7???? stats4_3.3.2?????? grid_3.3.2?????? ?
[31] nnet_7.3-12??????? robustbase_0.92-8? flexmix_2.3-14???? dfoptim_2017.12-1? gdata_2.18.0???? ?
[36] kernlab_0.9-25???? ggplot2_2.2.1????? magrittr_1.5?????? whisker_0.3-2????? scales_0.4.1???? ?
[41] gplots_3.0.1?????? codetools_0.2-15?? gclus_1.3.1??????? modeltools_0.2-21? MASS_7.3-48????? ?
[46] assertthat_0.1???? colorspace_1.2-7?? KernSmooth_2.23-15 lazyeval_0.2.0???? munsell_0.4.3??? ?


From murdoch.duncan at gmail.com  Thu Mar 29 00:38:27 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 28 Mar 2018 18:38:27 -0400
Subject: [R] can not install package "matie"
In-Reply-To: <1336347725.936971.1522276064897@mail.yahoo.com>
References: <1336347725.936971.1522276064897.ref@mail.yahoo.com>
 <1336347725.936971.1522276064897@mail.yahoo.com>
Message-ID: <c16e7af6-2856-f7fe-9461-fb490ab10d08@gmail.com>

On 28/03/2018 6:27 PM, varin sacha via R-help wrote:
> Dear R-experts,
> 
> I can not install the package "matie". If somebody can tell me where the problem is.
> 
>> install.packages("matie")
> Installing package into ?/Users/Caro/Library/R/3.3/library?
> (as ?lib? is unspecified)
> essai de l'URL 'https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/matie_1.2.tgz'
> Content type 'application/x-gzip' length 80151 bytes (78 KB)
> ==================================================
> downloaded 78 KB
> 
> 
> The downloaded binary packages are in
>  ?? ?/var/folders/hj/11q7wt055rg83y2vj45whdmw0000gn/T//RtmpqjqsFe/downloaded_packages
> 
>> library(matie)
> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck = vI[[i]]) :
>  ? aucun package nomm? ?proxy? n'est trouv?
> Erreur : le chargement du package ou de l'espace de noms a ?chou? pour ?matie?

The 'matie' package depends on 'proxy', and 'proxy' depends on R version 
3.4.0 or more.  You could try installing 'proxy' using 
install.pacakges("proxy"), but I'm guessing it will fail unless you 
update your R version first.

Duncan Murdoch


> 
> Here is my sessionInfo
> 
>> sessionInfo()
> R version 3.3.2 (2016-10-31)
> Platform: x86_64-apple-darwin13.4.0 (64-bit)
> Running under: macOS Sierra 10.12.4
> 
> locale:
> [1] fr_CH.UTF-8/fr_CH.UTF-8/fr_CH.UTF-8/C/fr_CH.UTF-8/fr_CH.UTF-8
> 
> attached base packages:
> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
> 
> loaded via a namespace (and not attached):
>  ?[1] Rcpp_0.12.7??????? DEoptimR_1.0-6???? plyr_1.8.4???????? viridis_0.3.4????? class_7.3-14
>  ?[6] bitops_1.0-6?????? iterators_1.0.8??? tools_3.3.2??????? prabclus_2.2-6???? dendextend_1.7.0
> [11] mclust_5.4???????? tibble_1.2???????? gtable_0.2.0?????? lattice_0.20-34??? pkgconfig_2.0.1
> [16] igraph_1.1.2?????? foreach_1.4.3????? registry_0.5?????? mvtnorm_1.0-5????? seriation_1.2-2
> [21] TSP_1.1-5????????? gridExtra_2.2.1??? trimcluster_0.1-2? cluster_2.0.5????? gtools_3.5.0
> [26] caTools_1.17.1???? fpc_2.1-11???????? diptest_0.75-7???? stats4_3.3.2?????? grid_3.3.2
> [31] nnet_7.3-12??????? robustbase_0.92-8? flexmix_2.3-14???? dfoptim_2017.12-1? gdata_2.18.0
> [36] kernlab_0.9-25???? ggplot2_2.2.1????? magrittr_1.5?????? whisker_0.3-2????? scales_0.4.1
> [41] gplots_3.0.1?????? codetools_0.2-15?? gclus_1.3.1??????? modeltools_0.2-21? MASS_7.3-48
> [46] assertthat_0.1???? colorspace_1.2-7?? KernSmooth_2.23-15 lazyeval_0.2.0???? munsell_0.4.3
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From macqueen1 at llnl.gov  Thu Mar 29 02:18:21 2018
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Thu, 29 Mar 2018 00:18:21 +0000
Subject: [R] Creating the right table from lapply list
In-Reply-To: <61612798.671079.1522254753438@mail.yahoo.com>
References: <61612798.671079.1522254753438.ref@mail.yahoo.com>
 <61612798.671079.1522254753438@mail.yahoo.com>
Message-ID: <9D964B4E-2C67-4699-B70C-764F9A7E6B26@llnl.gov>

Perhaps this toy example will help:

## example data
output <- list(1:5, 1:7, 1:4)

lens <- lapply(output, length)
maxlen <- max(unlist(lens))
outputmod <- lapply(output, function(x, maxl) c(x, rep(NA, maxl-length(x))), maxl=maxlen)
outputmat <- do.call(cbind, outputmod)
write.csv(outputmat, na='')

The idea is to pad the shorter vectors with NA (missing) before converting to a matrix structure.

I don't really need to know where the data came from, or that it's ncdf data, or how many months or years, etc. But I do need to know the structure of your "output" list. I'm assuming each element is a simple vector of numbers, and that the vectors' lengths are not all the same. If that's correct, then my example may be what you need.

This uses only base R methods, which I generally prefer. And no doubt it can be done more cleverly, or in a way that needs fewer intermediate variables ... but I don't really care.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 
?On 3/28/18, 9:32 AM, "R-help on behalf of orlin mitov via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    Hello,
      I have no previous experience with R, but had to learn on the fly in the past couple of weeks. Basically, what I am trying to do is read a certain variable from a series of files and save it as csv-table. The variable has an hourly value for each month in a year for the past 20 years and has to be read for different geographical locations. So there will be 12 files per year (1 for each month) and the values for the variable from each file will be 696 to 744 (depending on how many days x 24 hours there were in the month).What I achieved is to to read the values from all 12 files stored in directory with a function and add them as vectors to a lapply-list:
    
    
    
    Myfunction <- function(filename) {
     nc <- nc_open(filename)
     lon <- ncvar_get(nc, "lon")
     lat <- ncvar_get(nc, "lat")
     RW <- ncvar_get(nc, "X")
     HW <- ncvar_get(nc, "Y")
     pt.geo <- c(8.6810 , 50.1143)
     dist <- sqrt( (lon - pt.geo[1])^2 + (lat - pt.geo[2])^2 )
     ind <- which(dist==min(dist, na.rm=TRUE),arr.ind=TRUE)
     sis <- ncvar_get(nc, "SIS", start=c(ind[1],ind[2],1), count=c(1,1,-1))
     vec <- c(sis)
    }
    
    filenames <- list.files(path = "C:/Users/Desktop/VD/Solardaten/NC", pattern = "nc", full.names = TRUE)
     output <- lapply(filenames, Myfunction)
    
    
    
    And here start my problems with saving "output" as a csv table. Output would contain 12 vectors of different lenght.I want to have them as 12 columns (1x per month) in Excel and each column should have as many row-entries as there are values for this month.Whatever I tried with write.table I was not able to achieve this (tried converting the output to a matrix, also no successes).Please help! Or should I be trying to have the 12 elements as data frames and not vectors?
    This is how I want the table for each year to look - 12 columns and all the respective values in the rows (column names I can add by myself):
    Best regardsOrlin
    
    


From jdnewmil at dcn.davis.ca.us  Thu Mar 29 02:36:52 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Mar 2018 17:36:52 -0700
Subject: [R] can not install package "matie"
In-Reply-To: <c16e7af6-2856-f7fe-9461-fb490ab10d08@gmail.com>
References: <1336347725.936971.1522276064897.ref@mail.yahoo.com>
 <1336347725.936971.1522276064897@mail.yahoo.com>
 <c16e7af6-2856-f7fe-9461-fb490ab10d08@gmail.com>
Message-ID: <428DAA57-E187-4261-A903-4275BE62D23C@dcn.davis.ca.us>

Varin

In the teaching you to fish department, you can find those dependencies Duncan appeared to pull out of thin air by looking at the CRAN contributed packages web pages, which can easily be found with Google. Start at the matie page and follow the dependency links and look at dependencies. In particular the error message mentioning the proxy package is a clue that dependencies might be a problem. 
-- 
Sent from my phone. Please excuse my brevity.

On March 28, 2018 3:38:27 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 28/03/2018 6:27 PM, varin sacha via R-help wrote:
>> Dear R-experts,
>> 
>> I can not install the package "matie". If somebody can tell me where
>the problem is.
>> 
>>> install.packages("matie")
>> Installing package into ?/Users/Caro/Library/R/3.3/library?
>> (as ?lib? is unspecified)
>> essai de l'URL
>'https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/matie_1.2.tgz'
>> Content type 'application/x-gzip' length 80151 bytes (78 KB)
>> ==================================================
>> downloaded 78 KB
>> 
>> 
>> The downloaded binary packages are in
>>  ??
>?/var/folders/hj/11q7wt055rg83y2vj45whdmw0000gn/T//RtmpqjqsFe/downloaded_packages
>> 
>>> library(matie)
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>vI[[i]]) :
>>  ? aucun package nomm? ?proxy? n'est trouv?
>> Erreur : le chargement du package ou de l'espace de noms a ?chou?
>pour ?matie?
>
>The 'matie' package depends on 'proxy', and 'proxy' depends on R
>version 
>3.4.0 or more.  You could try installing 'proxy' using 
>install.pacakges("proxy"), but I'm guessing it will fail unless you 
>update your R version first.
>
>Duncan Murdoch
>
>
>> 
>> Here is my sessionInfo
>> 
>>> sessionInfo()
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: macOS Sierra 10.12.4
>> 
>> locale:
>> [1] fr_CH.UTF-8/fr_CH.UTF-8/fr_CH.UTF-8/C/fr_CH.UTF-8/fr_CH.UTF-8
>> 
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>> 
>> loaded via a namespace (and not attached):
>>  ?[1] Rcpp_0.12.7??????? DEoptimR_1.0-6???? plyr_1.8.4????????
>viridis_0.3.4????? class_7.3-14
>>  ?[6] bitops_1.0-6?????? iterators_1.0.8??? tools_3.3.2???????
>prabclus_2.2-6???? dendextend_1.7.0
>> [11] mclust_5.4???????? tibble_1.2???????? gtable_0.2.0??????
>lattice_0.20-34??? pkgconfig_2.0.1
>> [16] igraph_1.1.2?????? foreach_1.4.3????? registry_0.5??????
>mvtnorm_1.0-5????? seriation_1.2-2
>> [21] TSP_1.1-5????????? gridExtra_2.2.1??? trimcluster_0.1-2?
>cluster_2.0.5????? gtools_3.5.0
>> [26] caTools_1.17.1???? fpc_2.1-11???????? diptest_0.75-7????
>stats4_3.3.2?????? grid_3.3.2
>> [31] nnet_7.3-12??????? robustbase_0.92-8? flexmix_2.3-14????
>dfoptim_2017.12-1? gdata_2.18.0
>> [36] kernlab_0.9-25???? ggplot2_2.2.1????? magrittr_1.5??????
>whisker_0.3-2????? scales_0.4.1
>> [41] gplots_3.0.1?????? codetools_0.2-15?? gclus_1.3.1???????
>modeltools_0.2-21? MASS_7.3-48
>> [46] assertthat_0.1???? colorspace_1.2-7?? KernSmooth_2.23-15
>lazyeval_0.2.0???? munsell_0.4.3
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tea3rd at gmail.com  Thu Mar 29 05:44:43 2018
From: tea3rd at gmail.com (Thomas Adams)
Date: Wed, 28 Mar 2018 23:44:43 -0400
Subject: [R] Problem with my function using as.POSIXct
Message-ID: <CAGxgkWi2LJAKeGn_5M_dRZXfbRKm4_G4aHG9aWk-+ZY9Vt_T+w@mail.gmail.com>

Hello all:

I wrote a function:

my.bastimeToSynoptic <- function(x) {
    f<-unlist(strsplit(as.character(x), " "))
    hr<-unlist(strsplit(f[2], ":"))
    if(as.numeric(hr[1])<6) {
        synoptic<-"00"
    }
    else {
        synoptic<-as.integer(as.numeric(hr[1])/6)*6
    }
    tdate<-paste(c(f[1]," ",as.character(synoptic),":00:00"),collapse="")
    d<-as.POSIXct(tdate, tz="EST")
    return(d)
}

This works as expected:

> my.bastimeToSynoptic("2010-12-01 14:05:00")
[1] "2010-12-01 12:00:00 EST"

This does not:
> my.bastimeToSynoptic("2010-12-01 05:05:00")
[1] "2010-12-01 EST"

I expect to get:
"2010-12-01 00:00:00 EST"

I've tried explicitly forcing the format with d<-as.POSIXct(tdate,
tz="EST", format = "%Y-%m-%d %H:%M:%S") and I have checked online, finding
examples showing what I'm doing with as.POSIXct should work. I'm at an
impasse.

I'm running R version 3.4.0 (2017-04-21) on Ubuntu 16.04 LTS

Thank you,
Tom


--

	[[alternative HTML version deleted]]


From jdnewmil at dcn.davis.ca.us  Thu Mar 29 06:45:11 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Wed, 28 Mar 2018 21:45:11 -0700
Subject: [R] Problem with my function using as.POSIXct
In-Reply-To: <CAGxgkWi2LJAKeGn_5M_dRZXfbRKm4_G4aHG9aWk-+ZY9Vt_T+w@mail.gmail.com>
References: <CAGxgkWi2LJAKeGn_5M_dRZXfbRKm4_G4aHG9aWk-+ZY9Vt_T+w@mail.gmail.com>
Message-ID: <875B3BA4-FF8F-40E4-9918-B2A2FC7400C6@dcn.davis.ca.us>

You have succeeded, but you just don't know it. The POSIXct object is representing that instant of time internally... you are just complaining about how it is printing it. So convert it to character explicitly with the desired format when you want to print it.

as.character( my.bastimeToSynoptic("2010-12-01 05:05:00"), format="%Y-%m-%d %H:%M:%S" )
-- 
Sent from my phone. Please excuse my brevity.

On March 28, 2018 8:44:43 PM PDT, Thomas Adams <tea3rd at gmail.com> wrote:
>Hello all:
>
>I wrote a function:
>
>my.bastimeToSynoptic <- function(x) {
>    f<-unlist(strsplit(as.character(x), " "))
>    hr<-unlist(strsplit(f[2], ":"))
>    if(as.numeric(hr[1])<6) {
>        synoptic<-"00"
>    }
>    else {
>        synoptic<-as.integer(as.numeric(hr[1])/6)*6
>    }
>  tdate<-paste(c(f[1]," ",as.character(synoptic),":00:00"),collapse="")
>    d<-as.POSIXct(tdate, tz="EST")
>    return(d)
>}
>
>This works as expected:
>
>> my.bastimeToSynoptic("2010-12-01 14:05:00")
>[1] "2010-12-01 12:00:00 EST"
>
>This does not:
>> my.bastimeToSynoptic("2010-12-01 05:05:00")
>[1] "2010-12-01 EST"
>
>I expect to get:
>"2010-12-01 00:00:00 EST"
>
>I've tried explicitly forcing the format with d<-as.POSIXct(tdate,
>tz="EST", format = "%Y-%m-%d %H:%M:%S") and I have checked online,
>finding
>examples showing what I'm doing with as.POSIXct should work. I'm at an
>impasse.
>
>I'm running R version 3.4.0 (2017-04-21) on Ubuntu 16.04 LTS
>
>Thank you,
>Tom
>
>
>--
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ericjberger at gmail.com  Thu Mar 29 10:56:09 2018
From: ericjberger at gmail.com (Eric Berger)
Date: Thu, 29 Mar 2018 10:56:09 +0200
Subject: [R] Creating the right table from lapply list
In-Reply-To: <9D964B4E-2C67-4699-B70C-764F9A7E6B26@llnl.gov>
References: <61612798.671079.1522254753438.ref@mail.yahoo.com>
 <61612798.671079.1522254753438@mail.yahoo.com>
 <9D964B4E-2C67-4699-B70C-764F9A7E6B26@llnl.gov>
Message-ID: <CAGgJW74zp3d=gH6C9ncKBB4v0Wdg3_5ZKiya__nzYKGub1620g@mail.gmail.com>

I like Don's answer which is clean and clear. A frequently useful
alternative to lapply() is sapply().
Taking the sapply() route also avoids the need for do.call(). So a modified
version of Don's code would be:

## example data
output <- list(1:5, 1:7, 1:4)

maxlen <- max( sapply(output, length) )
outputmat <-  sapply(output, function(x, maxl) c(x, rep(NA,
maxl-length(x))), maxl=maxlen)
write.csv(outputmat, na='')


On Thu, Mar 29, 2018 at 2:18 AM, MacQueen, Don <macqueen1 at llnl.gov> wrote:

> Perhaps this toy example will help:
>
> ## example data
> output <- list(1:5, 1:7, 1:4)
>
> lens <- lapply(output, length)
> maxlen <- max(unlist(lens))
> outputmod <- lapply(output, function(x, maxl) c(x, rep(NA,
> maxl-length(x))), maxl=maxlen)
> outputmat <- do.call(cbind, outputmod)
> write.csv(outputmat, na='')
>
> The idea is to pad the shorter vectors with NA (missing) before converting
> to a matrix structure.
>
> I don't really need to know where the data came from, or that it's ncdf
> data, or how many months or years, etc. But I do need to know the structure
> of your "output" list. I'm assuming each element is a simple vector of
> numbers, and that the vectors' lengths are not all the same. If that's
> correct, then my example may be what you need.
>
> This uses only base R methods, which I generally prefer. And no doubt it
> can be done more cleverly, or in a way that needs fewer intermediate
> variables ... but I don't really care.
>
> -Don
>
> --
> Don MacQueen
> Lawrence Livermore National Laboratory
> 7000 East Ave., L-627
> Livermore, CA 94550
> 925-423-1062
> Lab cell 925-724-7509
>
>
> ?On 3/28/18, 9:32 AM, "R-help on behalf of orlin mitov via R-help" <
> r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:
>
>     Hello,
>       I have no previous experience with R, but had to learn on the fly in
> the past couple of weeks. Basically, what I am trying to do is read a
> certain variable from a series of files and save it as csv-table. The
> variable has an hourly value for each month in a year for the past 20 years
> and has to be read for different geographical locations. So there will be
> 12 files per year (1 for each month) and the values for the variable from
> each file will be 696 to 744 (depending on how many days x 24 hours there
> were in the month).What I achieved is to to read the values from all 12
> files stored in directory with a function and add them as vectors to a
> lapply-list:
>
>
>
>     Myfunction <- function(filename) {
>      nc <- nc_open(filename)
>      lon <- ncvar_get(nc, "lon")
>      lat <- ncvar_get(nc, "lat")
>      RW <- ncvar_get(nc, "X")
>      HW <- ncvar_get(nc, "Y")
>      pt.geo <- c(8.6810 , 50.1143)
>      dist <- sqrt( (lon - pt.geo[1])^2 + (lat - pt.geo[2])^2 )
>      ind <- which(dist==min(dist, na.rm=TRUE),arr.ind=TRUE)
>      sis <- ncvar_get(nc, "SIS", start=c(ind[1],ind[2],1), count=c(1,1,-1))
>      vec <- c(sis)
>     }
>
>     filenames <- list.files(path = "C:/Users/Desktop/VD/Solardaten/NC",
> pattern = "nc", full.names = TRUE)
>      output <- lapply(filenames, Myfunction)
>
>
>
>     And here start my problems with saving "output" as a csv table. Output
> would contain 12 vectors of different lenght.I want to have them as 12
> columns (1x per month) in Excel and each column should have as many
> row-entries as there are values for this month.Whatever I tried with
> write.table I was not able to achieve this (tried converting the output to
> a matrix, also no successes).Please help! Or should I be trying to have the
> 12 elements as data frames and not vectors?
>     This is how I want the table for each year to look - 12 columns and
> all the respective values in the rows (column names I can add by myself):
>     Best regardsOrlin
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ecjbosu at aol.com  Thu Mar 29 13:56:45 2018
From: ecjbosu at aol.com (Joe W. Byers)
Date: Thu, 29 Mar 2018 07:56:45 -0400
Subject: [R] LINUX gfortran.so.3 missing
In-Reply-To: <mailman.349099.1.1522317602.23467.r-help@r-project.org>
References: <mailman.349099.1.1522317602.23467.r-help@r-project.org>
Message-ID: <7873892e-f08a-3c1f-5bd1-8a3e9c7c4f42@aol.com>

All,

I wanted to share this with the users.? I have been having periodic 
issues with packages loading with a missing gfortran.so.3 file.? I have 
found this is due to system upgrades to my fedora linux computers to a? 
newer version of gfortran. I am not sure if other linux flavors have 
this issue or not, but I expect if you do a major version upgrade it 
will happen.

The fix is to re-install the packages that was linked to gfortran.so.3.? 
This is a real simple fix, only I don't know what packages are at issue 
to re-install all at one time, so periodically I have this issue appears 
much to my exasperation.

If anyone knows how to determine all installed packages with a gfortran 
dependencies, then we could submit a short update script for this.

Thanks
Joe


From lucasmation at gmail.com  Thu Mar 29 15:56:52 2018
From: lucasmation at gmail.com (Lucas Ferreira Mation)
Date: Thu, 29 Mar 2018 10:56:52 -0300
Subject: [R] Is it good practice to have a package depend on Rtools(for
 unziping of .7z and.rar files)? Crab legal?
Message-ID: <CAA+7z9ERbjhfgqs9AEJDQueiuqMGST1gR3rU2YRyPHmmMQTP4Q@mail.gmail.com>

I created this package,

https://github.com/lucasmation/microdadosBrasil

which we are preparing for Cran submission. The package facilitates
downloading and reading most of the microdatasets (household surveys,
Census, etc). For each dataset it:

(a) downloads the data from  the data providers
(b) "unzip" the necessary files
(c) imports the data into R.

For  (b), some of the datasets come in .7z and .rar format which ideally
the package should unzip (or whatever the correct them for uncompacting
these file types is) so that the underlying .txt or .csv files can be
imported into R.

Not being able to find a solution within R (R only deals with .zip files),
we added a Rtools dependency, in order to use Rtools expanded
unzipping capabilities on the .7z and .rar  files.

Is adding a Rtools dependency a bad practice for an R package? Is it even
allowed by cran? I mean, it changes requires the installation of a
standalone software (Rtools), which does not seem very user-friendly.

Is there any alternative for unzipping .rar and .7z files that only depends
on R packages and works independently of the OS, etc?

If the Rtools is a big problem, I could also revert to our initial strategy
that did not support .7z and .rar "unzipping", requesting the user to
manually unpack those files.

regards
Lucas

	[[alternative HTML version deleted]]


From bgunter.4567 at gmail.com  Thu Mar 29 16:30:26 2018
From: bgunter.4567 at gmail.com (Bert Gunter)
Date: Thu, 29 Mar 2018 07:30:26 -0700
Subject: [R] Is it good practice to have a package depend on Rtools(for
 unziping of .7z and.rar files)? Crab legal?
In-Reply-To: <CAA+7z9ERbjhfgqs9AEJDQueiuqMGST1gR3rU2YRyPHmmMQTP4Q@mail.gmail.com>
References: <CAA+7z9ERbjhfgqs9AEJDQueiuqMGST1gR3rU2YRyPHmmMQTP4Q@mail.gmail.com>
Message-ID: <CAGxFJbQ7OVLSwwokfaXbvzW5FOW4tL7uDZ+9RuqCkSkiriSTYg@mail.gmail.com>

r-package-devel is the right mailing list for your query, not here.


Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along
and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )


On Thu, Mar 29, 2018 at 6:56 AM, Lucas Ferreira Mation
<lucasmation at gmail.com> wrote:
> I created this package,
>
> https://github.com/lucasmation/microdadosBrasil
>
> which we are preparing for Cran submission. The package facilitates
> downloading and reading most of the microdatasets (household surveys,
> Census, etc). For each dataset it:
>
> (a) downloads the data from  the data providers
> (b) "unzip" the necessary files
> (c) imports the data into R.
>
> For  (b), some of the datasets come in .7z and .rar format which ideally
> the package should unzip (or whatever the correct them for uncompacting
> these file types is) so that the underlying .txt or .csv files can be
> imported into R.
>
> Not being able to find a solution within R (R only deals with .zip files),
> we added a Rtools dependency, in order to use Rtools expanded
> unzipping capabilities on the .7z and .rar  files.
>
> Is adding a Rtools dependency a bad practice for an R package? Is it even
> allowed by cran? I mean, it changes requires the installation of a
> standalone software (Rtools), which does not seem very user-friendly.
>
> Is there any alternative for unzipping .rar and .7z files that only depends
> on R packages and works independently of the OS, etc?
>
> If the Rtools is a big problem, I could also revert to our initial strategy
> that did not support .7z and .rar "unzipping", requesting the user to
> manually unpack those files.
>
> regards
> Lucas
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From lucasmation at gmail.com  Thu Mar 29 16:30:49 2018
From: lucasmation at gmail.com (Lucas Ferreira Mation)
Date: Thu, 29 Mar 2018 11:30:49 -0300
Subject: [R] Is it good practice to have a package depend on Rtools(for
 unziping of .7z and.rar files)? Crab legal?
In-Reply-To: <CAGxFJbQ7OVLSwwokfaXbvzW5FOW4tL7uDZ+9RuqCkSkiriSTYg@mail.gmail.com>
References: <CAA+7z9ERbjhfgqs9AEJDQueiuqMGST1gR3rU2YRyPHmmMQTP4Q@mail.gmail.com>
 <CAGxFJbQ7OVLSwwokfaXbvzW5FOW4tL7uDZ+9RuqCkSkiriSTYg@mail.gmail.com>
Message-ID: <CAA+7z9Gu+RvhULmaFvs+fRo+ztyYYikLrkLTpN34XQGq96qZdQ@mail.gmail.com>

ok, tks

2018-03-29 11:30 GMT-03:00 Bert Gunter <bgunter.4567 at gmail.com>:

> r-package-devel is the right mailing list for your query, not here.
>
>
> Cheers,
> Bert
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
>
> On Thu, Mar 29, 2018 at 6:56 AM, Lucas Ferreira Mation
> <lucasmation at gmail.com> wrote:
> > I created this package,
> >
> > https://github.com/lucasmation/microdadosBrasil
> >
> > which we are preparing for Cran submission. The package facilitates
> > downloading and reading most of the microdatasets (household surveys,
> > Census, etc). For each dataset it:
> >
> > (a) downloads the data from  the data providers
> > (b) "unzip" the necessary files
> > (c) imports the data into R.
> >
> > For  (b), some of the datasets come in .7z and .rar format which ideally
> > the package should unzip (or whatever the correct them for uncompacting
> > these file types is) so that the underlying .txt or .csv files can be
> > imported into R.
> >
> > Not being able to find a solution within R (R only deals with .zip
> files),
> > we added a Rtools dependency, in order to use Rtools expanded
> > unzipping capabilities on the .7z and .rar  files.
> >
> > Is adding a Rtools dependency a bad practice for an R package? Is it even
> > allowed by cran? I mean, it changes requires the installation of a
> > standalone software (Rtools), which does not seem very user-friendly.
> >
> > Is there any alternative for unzipping .rar and .7z files that only
> depends
> > on R packages and works independently of the OS, etc?
> >
> > If the Rtools is a big problem, I could also revert to our initial
> strategy
> > that did not support .7z and .rar "unzipping", requesting the user to
> > manually unpack those files.
> >
> > regards
> > Lucas
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From f.harrell at vanderbilt.edu  Thu Mar 29 21:38:14 2018
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Thu, 29 Mar 2018 14:38:14 -0500
Subject: [R] Regression Modeling Strategies and the rms Package 4-Day Short
 Course May 2018
Message-ID: <CAMO-wTbi=krP7g-Y0j1pZn_NyjvVPWuQGXRtVYnx+8y5ctazFQ@mail.gmail.com>

*RMS Short Course 2018*
Frank E. Harrell, Jr., Ph.D., Professor
Department of Biostatistics, Vanderbilt University School of Medicine
fharrell.com     @f2harrell

*May 15-18, 2018* With Optional R Workshop May 14
9:00am - 4:00pm
Alumni Hall
Vanderbilt University
Nashville Tennessee USA

See http://biostat.mc.vanderbilt.edu/RMSShortCourse2018 for details.

The course includes statistical methodology, case studies, and use of the R
rms package.

Please email interest to Jill Shell <jill.shell at vanderbilt.edu>

------------------------------
Frank E Harrell Jr      Professor      School of Medicine

Department of *Biostatistics*      *Vanderbilt University*

	[[alternative HTML version deleted]]


From maitra at email.com  Fri Mar 30 03:48:32 2018
From: maitra at email.com (Ranjan Maitra)
Date: Thu, 29 Mar 2018 20:48:32 -0500
Subject: [R] getting all circular arrangements without accounting for order
Message-ID: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>

Dear friends,

I would like to get all possible arrangements of n objects listed 1:n on a circle.

Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.

However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.

Is there an easy way to list these (n-1)!/2 arrangements? 

I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.

Many thanks in advance for any help. and best wishes,
Ranjan


From boris.steipe at utoronto.ca  Fri Mar 30 04:20:19 2018
From: boris.steipe at utoronto.ca (Boris Steipe)
Date: Thu, 29 Mar 2018 22:20:19 -0400
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
Message-ID: <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>

If one is equal to the reverse of another, keep only one of the pair.

B.



> On Mar 29, 2018, at 9:48 PM, Ranjan Maitra <maitra at email.com> wrote:
> 
> Dear friends,
> 
> I would like to get all possible arrangements of n objects listed 1:n on a circle.
> 
> Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
> 
> However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
> 
> Is there an easy way to list these (n-1)!/2 arrangements? 
> 
> I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.
> 
> Many thanks in advance for any help. and best wishes,
> Ranjan
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From maitra at email.com  Fri Mar 30 05:10:05 2018
From: maitra at email.com (Ranjan Maitra)
Date: Thu, 29 Mar 2018 22:10:05 -0500
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
 <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>
Message-ID: <20180329221005.2eb70fa252c6a70ac12dc615@email.com>

Thanks!

Yes, however, this seems a bit wasteful. Just wondering if there are other, more efficient options possible.

Best wishes,
Ranjan


On Thu, 29 Mar 2018 22:20:19 -0400 Boris Steipe <boris.steipe at utoronto.ca> wrote:

> If one is equal to the reverse of another, keep only one of the pair.
> 
> B.
> 
> 
> 
> > On Mar 29, 2018, at 9:48 PM, Ranjan Maitra <maitra at email.com> wrote:
> > 
> > Dear friends,
> > 
> > I would like to get all possible arrangements of n objects listed 1:n on a circle.
> > 
> > Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
> > 
> > However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
> > 
> > Is there an easy way to list these (n-1)!/2 arrangements? 
> > 
> > I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.
> > 
> > Many thanks in advance for any help. and best wishes,
> > Ranjan
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From jdnewmil at dcn.davis.ca.us  Fri Mar 30 08:26:12 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Thu, 29 Mar 2018 23:26:12 -0700
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <20180329221005.2eb70fa252c6a70ac12dc615@email.com>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
 <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>
 <20180329221005.2eb70fa252c6a70ac12dc615@email.com>
Message-ID: <alpine.BSF.2.00.1803292321060.48868@pedal.dcn.davis.ca.us>

I don't know if this is more efficient than enumerating with distinct 
directions and weeding... it seems kind of heavyweight to me:

#######
library(gtools)
directionless_circular_permutations <- function( n ) {
   v <- seq.int( n-1 )
   ix <- combinations( n-1, 2 )
   jx <- permutations( n-3, n-3 )
   x <- lapply( seq.int( nrow( ix ) )
              , function( i ) {
                 cbind( ix[ i, 1 ]
                      , permutations( n-3
                                    , n-3
                                    , v[ -ix[ i, ] ]
                                    )
                      , ix[ i, 2 ]
                      )
                }
              )
   cbind( do.call( rbind, x ), n )
}
#######

For more speed, perhaps use Rcpp with [1]?

[1] http://howardhinnant.github.io/combinations.html

On Thu, 29 Mar 2018, Ranjan Maitra wrote:

> Thanks!
>
> Yes, however, this seems a bit wasteful. Just wondering if there are 
> other, more efficient options possible.
>
> Best wishes,
> Ranjan
>
>
> On Thu, 29 Mar 2018 22:20:19 -0400 Boris Steipe <boris.steipe at utoronto.ca> wrote:
>
>> If one is equal to the reverse of another, keep only one of the pair.
>>
>> B.
>>
>>
>>
>>> On Mar 29, 2018, at 9:48 PM, Ranjan Maitra <maitra at email.com> wrote:
>>>
>>> Dear friends,
>>>
>>> I would like to get all possible arrangements of n objects listed 1:n on a circle.
>>>
>>> Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
>>>
>>> However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
>>>
>>> Is there an easy way to list these (n-1)!/2 arrangements?
>>>
>>> I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.
>>>
>>> Many thanks in advance for any help. and best wishes,
>>> Ranjan
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> -- 
> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From maitra at email.com  Fri Mar 30 11:03:21 2018
From: maitra at email.com (Ranjan Maitra)
Date: Fri, 30 Mar 2018 04:03:21 -0500
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <alpine.BSF.2.00.1803292321060.48868@pedal.dcn.davis.ca.us>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
 <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>
 <20180329221005.2eb70fa252c6a70ac12dc615@email.com>
 <alpine.BSF.2.00.1803292321060.48868@pedal.dcn.davis.ca.us>
Message-ID: <20180330040321.548253cdc7f7afe42db0b284@email.com>

Thanks! 

It is not clear to me that the weeding step is straightforward to do efficiently. Comparing using rev appears to me to be an operation on the order of O(n^3).

I guess one way would be to include everything with all 1's in the first slot (taking them out of consideration for future operations) and eliminate everything with 1's in the last slot. Then go for the 2's and so on, perhaps ending until nothing left. This looks like an O(n) operation, however I do not know if I will be missing something.

Many thanks again and best wishes,
Ranjan


On Thu, 29 Mar 2018 23:26:12 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> I don't know if this is more efficient than enumerating with distinct 
> directions and weeding... it seems kind of heavyweight to me:
> 
> #######
> library(gtools)
> directionless_circular_permutations <- function( n ) {
>    v <- seq.int( n-1 )
>    ix <- combinations( n-1, 2 )
>    jx <- permutations( n-3, n-3 )
>    x <- lapply( seq.int( nrow( ix ) )
>               , function( i ) {
>                  cbind( ix[ i, 1 ]
>                       , permutations( n-3
>                                     , n-3
>                                     , v[ -ix[ i, ] ]
>                                     )
>                       , ix[ i, 2 ]
>                       )
>                 }
>               )
>    cbind( do.call( rbind, x ), n )
> }
> #######
> 
> For more speed, perhaps use Rcpp with [1]?
> 
> [1] http://howardhinnant.github.io/combinations.html
> 
> On Thu, 29 Mar 2018, Ranjan Maitra wrote:
> 
> > Thanks!
> >
> > Yes, however, this seems a bit wasteful. Just wondering if there are 
> > other, more efficient options possible.
> >
> > Best wishes,
> > Ranjan
> >
> >
> > On Thu, 29 Mar 2018 22:20:19 -0400 Boris Steipe <boris.steipe at utoronto.ca> wrote:
> >
> >> If one is equal to the reverse of another, keep only one of the pair.
> >>
> >> B.
> >>
> >>
> >>
> >>> On Mar 29, 2018, at 9:48 PM, Ranjan Maitra <maitra at email.com> wrote:
> >>>
> >>> Dear friends,
> >>>
> >>> I would like to get all possible arrangements of n objects listed 1:n on a circle.
> >>>
> >>> Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
> >>>
> >>> However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
> >>>
> >>> Is there an easy way to list these (n-1)!/2 arrangements?
> >>>
> >>> I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.
> >>>
> >>> Many thanks in advance for any help. and best wishes,
> >>> Ranjan
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> > -- 
> > Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From ccberry at ucsd.edu  Fri Mar 30 18:46:53 2018
From: ccberry at ucsd.edu (Berry, Charles)
Date: Fri, 30 Mar 2018 16:46:53 +0000
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
Message-ID: <0C14246C-D763-4B64-8484-1B7B70B8EF08@ucsd.edu>



> On Mar 29, 2018, at 6:48 PM, Ranjan Maitra <maitra at email.com> wrote:
> 
> Dear friends,
> 
> I would like to get all possible arrangements of n objects listed 1:n on a circle.
> 
> Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
> 
> However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
> 
> Is there an easy way to list these (n-1)!/2 arrangements? 
> 

Well half of these arrangements will be of the form 

	`k, ... , j, n' 

and half will be of the form 

	`j, ...,  k, n'

So fix n in position n, select (k,j), and require that the first position is min(k,j) and position n-1 is max(k,j). 

There are choose(n-1,2) choices for {(k,j):k<j!=n}. Then you have (n-3)! ways to fill the rest. 

That gives (n-1)!/((n-3)! * 2!) * (n-3)! = (n-1)!/2 arrangements.

HTH,

Chuck


From maitra at email.com  Fri Mar 30 20:45:37 2018
From: maitra at email.com (Ranjan Maitra)
Date: Fri, 30 Mar 2018 13:45:37 -0500
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <alpine.BSF.2.00.1803292321060.48868@pedal.dcn.davis.ca.us>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
 <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>
 <20180329221005.2eb70fa252c6a70ac12dc615@email.com>
 <alpine.BSF.2.00.1803292321060.48868@pedal.dcn.davis.ca.us>
Message-ID: <20180330134537.caa4194598b59de933dbce60@email.com>

Jeff,

I wanted to let you know that your function is faster than generating the directional circular permutations and weeding. 

Here is the time for n = 10. I compared with just doing the permutations, there is no point in proceeding further with the weeding since it is slower at the start itself.


system.time(directionless_circular_permutations(10))
   user  system elapsed 
  1.576   0.000   1.579 

system.time(permutations(9,9))
   user  system elapsed 
  3.030   0.000   3.037 

Repeats keep the values similar. All computations on a 10-core processor @3.1GHz with 20 threads  (using only one thread) and running the  Fedora 27 with 4.15.9 kernel.

I have to say that I was surprised to see the difference at n = 10 itself. 

Thanks again!

Best wishes,
Ranjan

On Thu, 29 Mar 2018 23:26:12 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> I don't know if this is more efficient than enumerating with distinct 
> directions and weeding... it seems kind of heavyweight to me:
> 
> #######
> library(gtools)
> directionless_circular_permutations <- function( n ) {
>    v <- seq.int( n-1 )
>    ix <- combinations( n-1, 2 )
>    jx <- permutations( n-3, n-3 )
>    x <- lapply( seq.int( nrow( ix ) )
>               , function( i ) {
>                  cbind( ix[ i, 1 ]
>                       , permutations( n-3
>                                     , n-3
>                                     , v[ -ix[ i, ] ]
>                                     )
>                       , ix[ i, 2 ]
>                       )
>                 }
>               )
>    cbind( do.call( rbind, x ), n )
> }
> #######
> 
> For more speed, perhaps use Rcpp with [1]?
> 
> [1] http://howardhinnant.github.io/combinations.html
> 
> On Thu, 29 Mar 2018, Ranjan Maitra wrote:
> 
> > Thanks!
> >
> > Yes, however, this seems a bit wasteful. Just wondering if there are 
> > other, more efficient options possible.
> >
> > Best wishes,
> > Ranjan
> >
> >
> > On Thu, 29 Mar 2018 22:20:19 -0400 Boris Steipe <boris.steipe at utoronto.ca> wrote:
> >
> >> If one is equal to the reverse of another, keep only one of the pair.
> >>
> >> B.
> >>
> >>
> >>
> >>> On Mar 29, 2018, at 9:48 PM, Ranjan Maitra <maitra at email.com> wrote:
> >>>
> >>> Dear friends,
> >>>
> >>> I would like to get all possible arrangements of n objects listed 1:n on a circle.
> >>>
> >>> Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
> >>>
> >>> However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
> >>>
> >>> Is there an easy way to list these (n-1)!/2 arrangements?
> >>>
> >>> I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.
> >>>
> >>> Many thanks in advance for any help. and best wishes,
> >>> Ranjan
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> > -- 
> > Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From jdnewmil at dcn.davis.ca.us  Fri Mar 30 22:49:01 2018
From: jdnewmil at dcn.davis.ca.us (Jeff Newmiller)
Date: Fri, 30 Mar 2018 13:49:01 -0700
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <20180330134537.caa4194598b59de933dbce60@email.com>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
 <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>
 <20180329221005.2eb70fa252c6a70ac12dc615@email.com>
 <alpine.BSF.2.00.1803292321060.48868@pedal.dcn.davis.ca.us>
 <20180330134537.caa4194598b59de933dbce60@email.com>
Message-ID: <alpine.BSF.2.00.1803301257380.79090@pedal.dcn.davis.ca.us>

New function below is a bit faster due to more efficent memory handling.

for-loop FTW!

directionless_circular_permutations2 <- function( n ) {
   n1 <- n - 1L
   v <- seq.int( n1 )
   ix <- combinations( n1, 2L )
   jx <- permutations( n-3L, n-3L )
   jxrows <- nrow( jx )
   jxoffsets <- seq.int( jxrows )
   result <- matrix( n, nrow = factorial( n1 )/2L, ncol = n )
   k <- seq( 2L, n - 2L )
   for ( i in seq.int( nrow( ix ) ) ) {
     result[ ( i - 1L ) * jxrows + jxoffsets, k ] <-
         matrix( v[ -ix[ i, ] ][ jx ], nrow = jxrows )
   }
   result[ , 1L ] <- rep( ix[ , 1L ], each = jxrows )
   result[ , n1 ] <- rep( ix[ , 2L ], each = jxrows )
   result
}


On Fri, 30 Mar 2018, Ranjan Maitra wrote:

> Jeff,
>
> I wanted to let you know that your function is faster than generating 
> the directional circular permutations and weeding.
>
> Here is the time for n = 10. I compared with just doing the 
> permutations, there is no point in proceeding further with the weeding 
> since it is slower at the start itself.
>
>
> system.time(directionless_circular_permutations(10))
>   user  system elapsed
>  1.576   0.000   1.579
>
> system.time(permutations(9,9))
>   user  system elapsed
>  3.030   0.000   3.037
>
> Repeats keep the values similar. All computations on a 10-core processor 
> @3.1GHz with 20 threads (using only one thread) and running the Fedora 
> 27 with 4.15.9 kernel.
>
> I have to say that I was surprised to see the difference at n = 10 itself.
>
> Thanks again!
>
> Best wishes,
> Ranjan
>
> On Thu, 29 Mar 2018 23:26:12 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>
>> I don't know if this is more efficient than enumerating with distinct
>> directions and weeding... it seems kind of heavyweight to me:
>>
>> #######
>> library(gtools)
>> directionless_circular_permutations <- function( n ) {
>>    v <- seq.int( n-1 )
>>    ix <- combinations( n-1, 2 )
>>    jx <- permutations( n-3, n-3 )
>>    x <- lapply( seq.int( nrow( ix ) )
>>               , function( i ) {
>>                  cbind( ix[ i, 1 ]
>>                       , permutations( n-3
>>                                     , n-3
>>                                     , v[ -ix[ i, ] ]
>>                                     )
>>                       , ix[ i, 2 ]
>>                       )
>>                 }
>>               )
>>    cbind( do.call( rbind, x ), n )
>> }
>> #######
>>
>> For more speed, perhaps use Rcpp with [1]?
>>
>> [1] http://howardhinnant.github.io/combinations.html
>>
>> On Thu, 29 Mar 2018, Ranjan Maitra wrote:
>>
>>> Thanks!
>>>
>>> Yes, however, this seems a bit wasteful. Just wondering if there are
>>> other, more efficient options possible.
>>>
>>> Best wishes,
>>> Ranjan
>>>
>>>
>>> On Thu, 29 Mar 2018 22:20:19 -0400 Boris Steipe <boris.steipe at utoronto.ca> wrote:
>>>
>>>> If one is equal to the reverse of another, keep only one of the pair.
>>>>
>>>> B.
>>>>
>>>>
>>>>
>>>>> On Mar 29, 2018, at 9:48 PM, Ranjan Maitra <maitra at email.com> wrote:
>>>>>
>>>>> Dear friends,
>>>>>
>>>>> I would like to get all possible arrangements of n objects listed 1:n on a circle.
>>>>>
>>>>> Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
>>>>>
>>>>> However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
>>>>>
>>>>> Is there an easy way to list these (n-1)!/2 arrangements?
>>>>>
>>>>> I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.
>>>>>
>>>>> Many thanks in advance for any help. and best wishes,
>>>>> Ranjan
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>> --
>>> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                        Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> -- 
> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From varinsacha at yahoo.fr  Fri Mar 30 22:54:33 2018
From: varinsacha at yahoo.fr (varin sacha)
Date: Fri, 30 Mar 2018 20:54:33 +0000 (UTC)
Subject: [R] can not install package "matie"
In-Reply-To: <428DAA57-E187-4261-A903-4275BE62D23C@dcn.davis.ca.us>
References: <1336347725.936971.1522276064897.ref@mail.yahoo.com>
 <1336347725.936971.1522276064897@mail.yahoo.com>
 <c16e7af6-2856-f7fe-9461-fb490ab10d08@gmail.com>
 <428DAA57-E187-4261-A903-4275BE62D23C@dcn.davis.ca.us>
Message-ID: <203981218.2428046.1522443273983@mail.yahoo.com>

Dear Jeff & Duncan,

May thanks, the R update was necessary...

Best,



Le jeudi 29 mars 2018 ? 02:37:01 UTC+2, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> a ?crit : 





Varin

In the teaching you to fish department, you can find those dependencies Duncan appeared to pull out of thin air by looking at the CRAN contributed packages web pages, which can easily be found with Google. Start at the matie page and follow the dependency links and look at dependencies. In particular the error message mentioning the proxy package is a clue that dependencies might be a problem. 
-- 
Sent from my phone. Please excuse my brevity.

On March 28, 2018 3:38:27 PM PDT, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>On 28/03/2018 6:27 PM, varin sacha via R-help wrote:
>> Dear R-experts,
>> 
>> I can not install the package "matie". If somebody can tell me where
>the problem is.
>> 
>>> install.packages("matie")
>> Installing package into ?/Users/Caro/Library/R/3.3/library?
>> (as ?lib? is unspecified)
>> essai de l'URL
>'https://cran.rstudio.com/bin/macosx/mavericks/contrib/3.3/matie_1.2.tgz'
>> Content type 'application/x-gzip' length 80151 bytes (78 KB)
>> ==================================================
>> downloaded 78 KB
>> 
>> 
>> The downloaded binary packages are in
>>? ??
>?/var/folders/hj/11q7wt055rg83y2vj45whdmw0000gn/T//RtmpqjqsFe/downloaded_packages
>> 
>>> library(matie)
>> Error in loadNamespace(i, c(lib.loc, .libPaths()), versionCheck =
>vI[[i]]) :
>>? ? aucun package nomm? ?proxy? n'est trouv?
>> Erreur : le chargement du package ou de l'espace de noms a ?chou?
>pour ?matie?
>
>The 'matie' package depends on 'proxy', and 'proxy' depends on R
>version 
>3.4.0 or more.? You could try installing 'proxy' using 
>install.pacakges("proxy"), but I'm guessing it will fail unless you 
>update your R version first.
>
>Duncan Murdoch
>
>
>> 
>> Here is my sessionInfo
>> 
>>> sessionInfo()
>> R version 3.3.2 (2016-10-31)
>> Platform: x86_64-apple-darwin13.4.0 (64-bit)
>> Running under: macOS Sierra 10.12.4
>> 
>> locale:
>> [1] fr_CH.UTF-8/fr_CH.UTF-8/fr_CH.UTF-8/C/fr_CH.UTF-8/fr_CH.UTF-8
>> 
>> attached base packages:
>> [1] stats???? graphics? grDevices utils???? datasets? methods?? base
>> 
>> loaded via a namespace (and not attached):
>>? ?[1] Rcpp_0.12.7??????? DEoptimR_1.0-6???? plyr_1.8.4????????
>viridis_0.3.4????? class_7.3-14
>>? ?[6] bitops_1.0-6?????? iterators_1.0.8??? tools_3.3.2???????
>prabclus_2.2-6???? dendextend_1.7.0
>> [11] mclust_5.4???????? tibble_1.2???????? gtable_0.2.0??????
>lattice_0.20-34??? pkgconfig_2.0.1
>> [16] igraph_1.1.2?????? foreach_1.4.3????? registry_0.5??????
>mvtnorm_1.0-5????? seriation_1.2-2
>> [21] TSP_1.1-5????????? gridExtra_2.2.1??? trimcluster_0.1-2?
>cluster_2.0.5????? gtools_3.5.0
>> [26] caTools_1.17.1???? fpc_2.1-11???????? diptest_0.75-7????
>stats4_3.3.2?????? grid_3.3.2
>> [31] nnet_7.3-12??????? robustbase_0.92-8? flexmix_2.3-14????
>dfoptim_2017.12-1? gdata_2.18.0
>> [36] kernlab_0.9-25???? ggplot2_2.2.1????? magrittr_1.5??????
>whisker_0.3-2????? scales_0.4.1
>> [41] gplots_3.0.1?????? codetools_0.2-15?? gclus_1.3.1???????
>modeltools_0.2-21? MASS_7.3-48
>> [46] assertthat_0.1???? colorspace_1.2-7?? KernSmooth_2.23-15
>lazyeval_0.2.0???? munsell_0.4.3
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

>>
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From maitra at email.com  Fri Mar 30 23:13:40 2018
From: maitra at email.com (Ranjan Maitra)
Date: Fri, 30 Mar 2018 16:13:40 -0500
Subject: [R] 
 getting all circular arrangements without accounting for order
In-Reply-To: <alpine.BSF.2.00.1803301257380.79090@pedal.dcn.davis.ca.us>
References: <20180329204832.bf152d60cdebb7ec49fb0719@email.com>
 <8EB3F2A5-F16B-466F-99F0-9A4DCC0265DA@utoronto.ca>
 <20180329221005.2eb70fa252c6a70ac12dc615@email.com>
 <alpine.BSF.2.00.1803292321060.48868@pedal.dcn.davis.ca.us>
 <20180330134537.caa4194598b59de933dbce60@email.com>
 <alpine.BSF.2.00.1803301257380.79090@pedal.dcn.davis.ca.us>
Message-ID: <20180330161340.a785696373854234086b4b3a@email.com>

Jeff,

Thanks! This one is much faster, no doubt!


system.time(directionless_circular_permutations2(12))
   user  system elapsed 
  5.331   0.745   6.089 

system.time(directionless_circular_permutations(12))
   user  system elapsed 
173.659   0.890 174.946 

However, from n = 13, things start becoming slow. 

system.time(directionless_circular_permutations2(13))
   user  system elapsed 
60.588  14.933  75.864 

Perhaps the loop can be parallelized using doMC or doSNOW, etc. but most likely it is best to do a .Call or .C or Rcpp as you suggested earlier. This may be a consequence of the permutations function itself being slow.

Thanks again!
Ranjan





On Fri, 30 Mar 2018 13:49:01 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> New function below is a bit faster due to more efficent memory handling.
> 
> for-loop FTW!
> 
> directionless_circular_permutations2 <- function( n ) {
>    n1 <- n - 1L
>    v <- seq.int( n1 )
>    ix <- combinations( n1, 2L )
>    jx <- permutations( n-3L, n-3L )
>    jxrows <- nrow( jx )
>    jxoffsets <- seq.int( jxrows )
>    result <- matrix( n, nrow = factorial( n1 )/2L, ncol = n )
>    k <- seq( 2L, n - 2L )
>    for ( i in seq.int( nrow( ix ) ) ) {
>      result[ ( i - 1L ) * jxrows + jxoffsets, k ] <-
>          matrix( v[ -ix[ i, ] ][ jx ], nrow = jxrows )
>    }
>    result[ , 1L ] <- rep( ix[ , 1L ], each = jxrows )
>    result[ , n1 ] <- rep( ix[ , 2L ], each = jxrows )
>    result
> }
> 
> 
> On Fri, 30 Mar 2018, Ranjan Maitra wrote:
> 
> > Jeff,
> >
> > I wanted to let you know that your function is faster than generating 
> > the directional circular permutations and weeding.
> >
> > Here is the time for n = 10. I compared with just doing the 
> > permutations, there is no point in proceeding further with the weeding 
> > since it is slower at the start itself.
> >
> >
> > system.time(directionless_circular_permutations(10))
> >   user  system elapsed
> >  1.576   0.000   1.579
> >
> > system.time(permutations(9,9))
> >   user  system elapsed
> >  3.030   0.000   3.037
> >
> > Repeats keep the values similar. All computations on a 10-core processor 
> > @3.1GHz with 20 threads (using only one thread) and running the Fedora 
> > 27 with 4.15.9 kernel.
> >
> > I have to say that I was surprised to see the difference at n = 10 itself.
> >
> > Thanks again!
> >
> > Best wishes,
> > Ranjan
> >
> > On Thu, 29 Mar 2018 23:26:12 -0700 Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
> >
> >> I don't know if this is more efficient than enumerating with distinct
> >> directions and weeding... it seems kind of heavyweight to me:
> >>
> >> #######
> >> library(gtools)
> >> directionless_circular_permutations <- function( n ) {
> >>    v <- seq.int( n-1 )
> >>    ix <- combinations( n-1, 2 )
> >>    jx <- permutations( n-3, n-3 )
> >>    x <- lapply( seq.int( nrow( ix ) )
> >>               , function( i ) {
> >>                  cbind( ix[ i, 1 ]
> >>                       , permutations( n-3
> >>                                     , n-3
> >>                                     , v[ -ix[ i, ] ]
> >>                                     )
> >>                       , ix[ i, 2 ]
> >>                       )
> >>                 }
> >>               )
> >>    cbind( do.call( rbind, x ), n )
> >> }
> >> #######
> >>
> >> For more speed, perhaps use Rcpp with [1]?
> >>
> >> [1] http://howardhinnant.github.io/combinations.html
> >>
> >> On Thu, 29 Mar 2018, Ranjan Maitra wrote:
> >>
> >>> Thanks!
> >>>
> >>> Yes, however, this seems a bit wasteful. Just wondering if there are
> >>> other, more efficient options possible.
> >>>
> >>> Best wishes,
> >>> Ranjan
> >>>
> >>>
> >>> On Thu, 29 Mar 2018 22:20:19 -0400 Boris Steipe <boris.steipe at utoronto.ca> wrote:
> >>>
> >>>> If one is equal to the reverse of another, keep only one of the pair.
> >>>>
> >>>> B.
> >>>>
> >>>>
> >>>>
> >>>>> On Mar 29, 2018, at 9:48 PM, Ranjan Maitra <maitra at email.com> wrote:
> >>>>>
> >>>>> Dear friends,
> >>>>>
> >>>>> I would like to get all possible arrangements of n objects listed 1:n on a circle.
> >>>>>
> >>>>> Now this is easy to do in R. Keep the last spot fixed at n and fill in the rest using permuations(n-1, n-1) from the gtools package.
> >>>>>
> >>>>> However, what if clockwise or counterclockwise arrangements are the same? I know that half of the above (n - 1)! arrangements are redundant.
> >>>>>
> >>>>> Is there an easy way to list these (n-1)!/2 arrangements?
> >>>>>
> >>>>> I thought of only listing the first half from a call to permuations(n - 1, n - 1), but while this holds for n = 4, it does not for n = 5. So, I am wondering if there is another function or tweak which would easily do this.
> >>>>>
> >>>>> Many thanks in advance for any help. and best wishes,
> >>>>> Ranjan
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>>
> >>> --
> >>> Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >> ---------------------------------------------------------------------------
> >> Jeff Newmiller                        The     .....       .....  Go Live...
> >> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
> >>                                        Live:   OO#.. Dead: OO#..  Playing
> >> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> >> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >
> >
> > -- 
> > Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                        Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be deleted on receipt. Please respond to the mailing list if appropriate. For those needing to send personal or professional e-mail, please use appropriate addresses.


From jwd at surewest.net  Sat Mar 31 10:22:43 2018
From: jwd at surewest.net (John)
Date: Sat, 31 Mar 2018 01:22:43 -0700
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
In-Reply-To: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
References: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
Message-ID: <20180331012243.18f6b947@Draco.localdomain>

On Tue, 27 Mar 2018 22:25:33 +0300
Luis Puerto <luiss.puerto at gmail.com> wrote:

I don't run a Mac so this may not help.  Did you install java 10 as
user or as root?  Using linux, applications installed as user will be
inserted into your user space under /home/<user-name>.  As root the
application will located where any user of the system with permission
to run the application can access it.  I ran into a problem similar to
this with packages, some installed as root and some installed locally
in my user directory.  

JWDougherty


From pdalgd at gmail.com  Sat Mar 31 16:03:26 2018
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 31 Mar 2018 16:03:26 +0200
Subject: [R] =?utf-8?q?R_and_Java_10_=E2=9E=9C_rJava_not_able_to_build?=
In-Reply-To: <20180331012243.18f6b947@Draco.localdomain>
References: <5528AE93-6DF5-4DD8-8D73-8A95BEFF6830@gmail.com>
 <20180331012243.18f6b947@Draco.localdomain>
Message-ID: <CE1E021E-42D7-43F5-945A-B88B3D5D6003@gmail.com>

Don't waste too much time on this. It is due to a change introduced in Java 10 at short notice. I believe the rJava maintainers are working on a fix/workaround.

-pd

> On 31 Mar 2018, at 10:22 , John <jwd at surewest.net> wrote:
> 
> On Tue, 27 Mar 2018 22:25:33 +0300
> Luis Puerto <luiss.puerto at gmail.com> wrote:
> 
> I don't run a Mac so this may not help.  Did you install java 10 as
> user or as root?  Using linux, applications installed as user will be
> inserted into your user space under /home/<user-name>.  As root the
> application will located where any user of the system with permission
> to run the application can access it.  I ran into a problem similar to
> this with packages, some installed as root and some installed locally
> in my user directory.  
> 
> JWDougherty
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From moolman.henri at gmail.com  Sat Mar 31 15:45:24 2018
From: moolman.henri at gmail.com (Henri Moolman)
Date: Sat, 31 Mar 2018 15:45:24 +0200
Subject: [R] R help
Message-ID: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>

Could you please provide help with something from R that I find rather
puzzling? In the small program below x[1]=1, .  .  .  , x[5]=5. R also
finds that x[1]<=5 is TRUE. Yet when you attempt to execute while, R does
not seem to recognize the condition. Any thoughts on why this happens?

Regards

Henri Moolman

> x=c(1,2,3,4,5)
> x[1]
[1] 1
> i=1
> x[1]<=5
[1] TRUE
> while(x[i]<=5){
+     i=i+1
+ }
Error in while (x[i] <= 5) { : missing value where TRUE/FALSE needed

	[[alternative HTML version deleted]]


From thomas.mailund at gmail.com  Sat Mar 31 17:34:43 2018
From: thomas.mailund at gmail.com (Thomas Mailund)
Date: Sat, 31 Mar 2018 17:34:43 +0200
Subject: [R] R help
In-Reply-To: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
References: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
Message-ID: <ed2d8c57-f088-43a4-a963-e9dd3338aa5c@Spark>

The condition is true all the way until you index outside the vector...

Cheers

On 31 Mar 2018, 17.29 +0200, Henri Moolman <moolman.henri at gmail.com>, wrote:
> Could you please provide help with something from R that I find rather
> puzzling? In the small program below x[1]=1, . . . , x[5]=5. R also
> finds that x[1]<=5 is TRUE. Yet when you attempt to execute while, R does
> not seem to recognize the condition. Any thoughts on why this happens?
>
> Regards
>
> Henri Moolman
>
> > x=c(1,2,3,4,5)
> > x[1]
> [1] 1
> > i=1
> > x[1]<=5
> [1] TRUE
> > while(x[i]<=5){
> + i=i+1
> + }
> Error in while (x[i] <= 5) { : missing value where TRUE/FALSE needed
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From mrguilfoyle at gmail.com  Sat Mar 31 17:41:36 2018
From: mrguilfoyle at gmail.com (Mathew Guilfoyle)
Date: Sat, 31 Mar 2018 16:41:36 +0100
Subject: [R] R help
In-Reply-To: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
References: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
Message-ID: <B5C7C52B-5DB7-40DB-81D5-CD48267E8EEE@gmail.com>

When i increments to 6 (during the fifth iteration) the subsequent test of x[i]<=5 will produce an error since x has only five elements.

> On 31 Mar 2018, at 14:45, Henri Moolman <moolman.henri at gmail.com> wrote:
> 
> Could you please provide help with something from R that I find rather
> puzzling? In the small program below x[1]=1, .  .  .  , x[5]=5. R also
> finds that x[1]<=5 is TRUE. Yet when you attempt to execute while, R does
> not seem to recognize the condition. Any thoughts on why this happens?
> 
> Regards
> 
> Henri Moolman
> 
>> x=c(1,2,3,4,5)
>> x[1]
> [1] 1
>> i=1
>> x[1]<=5
> [1] TRUE
>> while(x[i]<=5){
> +     i=i+1
> + }
> Error in while (x[i] <= 5) { : missing value where TRUE/FALSE needed
> 
>   [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Sat Mar 31 17:51:11 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 31 Mar 2018 16:51:11 +0100
Subject: [R] R help
In-Reply-To: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
References: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
Message-ID: <75a51c17-8560-f5a6-94a4-28c9baee5859@sapo.pt>

Hello,

Maybe you want

while(x[i] < 5)

not <=

Hope this helps,

Rui Barradas

On 3/31/2018 2:45 PM, Henri Moolman wrote:
> Could you please provide help with something from R that I find rather
> puzzling? In the small program below x[1]=1, .  .  .  , x[5]=5. R also
> finds that x[1]<=5 is TRUE. Yet when you attempt to execute while, R does
> not seem to recognize the condition. Any thoughts on why this happens?
> 
> Regards
> 
> Henri Moolman
> 
>> x=c(1,2,3,4,5)
>> x[1]
> [1] 1
>> i=1
>> x[1]<=5
> [1] TRUE
>> while(x[i]<=5){
> +     i=i+1
> + }
> Error in while (x[i] <= 5) { : missing value where TRUE/FALSE needed
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ted.harding at wlandres.net  Sat Mar 31 17:54:05 2018
From: ted.harding at wlandres.net (Ted Harding)
Date: Sat, 31 Mar 2018 16:54:05 +0100
Subject: [R] R help
In-Reply-To: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
References: <CAL4BQizMhgkYBp3ozhaUP4CnqEHMzGesyMgB-7JFmg8vjURA7g@mail.gmail.com>
Message-ID: <1522511645.3833.10.camel@deb2.fort.knox.uk>

     A. On Sat, 2018-03-31 at 15:45 +0200, Henri Moolman wrote:
> Could you please provide help with something from R that I find rather
> puzzling? In the small program below x[1]=1, .  .  .  , x[5]=5. R also
> finds that x[1]<=5 is TRUE. Yet when you attempt to execute while, R does
> not seem to recognize the condition. Any thoughts on why this happens?
> 
> Regards
> 
> Henri Moolman
> 
> > x=c(1,2,3,4,5)
> > x[1]
> [1] 1
> > i=1
> > x[1]<=5
> [1] TRUE
> > while(x[i]<=5){
> +     i=i+1
> + }
> Error in while (x[i] <= 5) { : missing value where TRUE/FALSE needed

If you run the following you should understand why (the only
change is to include "print(i)" in the loop, so you can see
what is happening):

  x=c(1,2,3,4,5)
  x[1]
# [1] 1
  i=1
  x[1]<=5
# [1] TRUE
  while(x[i]<=5){
  i = i+1 ; print(i)
  }
# [1] 3
# [1] 4
# [1] 5
# [1] 6
# Error in while (x[i] <= 5) { : missing value where TRUE/FALSE needed

So everything is fine so long as i <= 5 (i.e. x[i] <= 5),
but then the loop sets i = 6. and then:

  i
# [1] 6
  x[i]
# [1] NA
  x[i] <= 5
# [1] NA

Helpful?
Best wishes,
Ted.


From varinsacha at yahoo.fr  Sat Mar 31 17:57:24 2018
From: varinsacha at yahoo.fr (varin sacha)
Date: Sat, 31 Mar 2018 15:57:24 +0000 (UTC)
Subject: [R] Fast tau-estimator line does ot appear on the plot
References: <1786914412.210328.1522511844686.ref@mail.yahoo.com>
Message-ID: <1786914412.210328.1522511844686@mail.yahoo.com>

Dear R-experts,

Here below my reproducible R code. I want to add many straight lines to a plot using "abline"
The last fit (fast Tau-estimator, color yellow) will not appear on the plot. What is going wrong ?
Many thanks for your reply.

##########

Y=c(2,4,5,4,3,4,2,3,56,5,4,3,4,5,6,5,4,5,34,21,12,13,12,8,9,7,43,12,19,21)
Z=c(43,2,1,2,34,4,3,4,5,30,4,5,4,3,4,5,56,6,43,21,34,19,12,11,9,34,21,23,2,19)
reg1<-lm(Z ~ Y)
plot(Y,Z)
abline(reg1, col="black")

install.packages("robustbase")
library?(robustbase)
reg=lmrob(Z ~ Y, data = Dataset)
abline(reg, col="green")

install.packages("MASS")? 
library(MASS)
Huber=rlm(Z ~ Y, data = Dataset)
abline(Huber,col="red")

Tukey=rlm(Z ~ Y, data = Dataset,psi=psi.bisquare)
abline(Tukey,col="purple")
?
install.packages("quantreg")
library(quantreg)
L1=rq(Z ~ Y, data = Dataset,tau=0.5)
abline(L1,col="blue")
?
install.packages("RobPer")
library(RobPer)
FastTau(Z,Y)
fast=FastTau(Z,Y)
abline(fast, col="yellow")

##########
?


From bendix.carstensen at regionh.dk  Sat Mar 31 17:48:07 2018
From: bendix.carstensen at regionh.dk (Bendix Carstensen)
Date: Sat, 31 Mar 2018 15:48:07 +0000
Subject: [R] Names of variables needed in newdata for predict.glm
In-Reply-To: <a70c15d9-651b-4f8d-dbbb-46b790cdb2a1@yahoo.fr>
References: <1520400001495.13693@regionh.dk>,
 <a70c15d9-651b-4f8d-dbbb-46b790cdb2a1@yahoo.fr>
Message-ID: <1522511287164.49476@regionh.dk>

all.vars works fine, EXCEPT, it give a bit too much.
I only want the regression variables, but in the following example I also get "k" the variable holding the chosen knots. Any machinery to find only "real" regression variables?
cheers, Bendix

library( splines )
y <- rnorm(100)
x <- rnorm(100)
k <- -1:1
ml <-  lm( y ~ bs(x,knots=k) )
mg <- glm( y ~ bs(x,knots=k) )
all.vars(ml$terms)
all.vars(mg$terms)
all.vars(mg$formula)

________________________________________
Fra: Marc Girondot <marc_grt at yahoo.fr>
Sendt: 8. marts 2018 06:26
Til: Bendix Carstensen; r-help at r-project.org
Emne: Re: [R] Names of variables needed in newdata for predict.glm

Hi,

Some try:
 > names(mi$xlevels)
[1] "f"
 > all.vars(mi$formula)
[1] "D" "x" "f" "Y"
 > names(mx$xlevels)
[1] "f"
 > all.vars(mx$formula)
[1] "D" "x" "f"

When offset is indicated out of the formula, it does not work...

Marc

Le 07/03/2018 ? 06:20, Bendix Carstensen a ?crit :
> I would like to extract the names, modes [numeric/factor] and levels
> of variables needed in a data frame supplied as newdata= argument to
> predict.glm()
>
> Here is a small example illustrating my troubles; what I want from
> (both of) the glm objects is the vector c("x","f","Y") and an
> indication that f is a factor:
>
> library( splines )
> dd <- data.frame( D = sample(0:1,200,rep=T),
>                    x = abs(rnorm(200)),
>                    f = factor(sample(letters[1:4],200,rep=T)),
>                    Y = runif(200,0.5,10) )
> mx <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) , offset=log(Y) , family=poisson, data=dd)
> mi <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) + offset(log(Y)), family=poisson, data=dd)
>
> attr(mx$terms,"dataClasses")
> attr(mi$terms,"dataClasses")
> mi$xlevels
> mx$xlevels
>
> ...so far not quite there.
>
> Regards,
>
> Bendix Carstensen
>
> Senior Statistician
> Steno Diabetes Center
> Clinical Epidemiology
> Niels Steensens Vej 2-4
> DK-2820 Gentofte, Denmark
> b at bxc.dk
> bendix.carstensen at regionh.dk
> http://BendixCarstensen.com
>
> ________________________________
>
>
> Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


________________________________


Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.


From murdoch.duncan at gmail.com  Sat Mar 31 18:05:50 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 31 Mar 2018 12:05:50 -0400
Subject: [R] Fast tau-estimator line does ot appear on the plot
In-Reply-To: <1786914412.210328.1522511844686@mail.yahoo.com>
References: <1786914412.210328.1522511844686.ref@mail.yahoo.com>
 <1786914412.210328.1522511844686@mail.yahoo.com>
Message-ID: <e1158856-10fd-ed66-904d-2c1d76f1c7a7@gmail.com>

On 31/03/2018 11:57 AM, varin sacha via R-help wrote:
> Dear R-experts,
> 
> Here below my reproducible R code. I want to add many straight lines to a plot using "abline"
> The last fit (fast Tau-estimator, color yellow) will not appear on the plot. What is going wrong ?
> Many thanks for your reply.
> 

It's not quite reproducible:  you forgot the line to create Dataset. 
It's probably something like

Dataset <- data.frame(Y, Z)

> ##########
> 
> Y=c(2,4,5,4,3,4,2,3,56,5,4,3,4,5,6,5,4,5,34,21,12,13,12,8,9,7,43,12,19,21)
> Z=c(43,2,1,2,34,4,3,4,5,30,4,5,4,3,4,5,56,6,43,21,34,19,12,11,9,34,21,23,2,19)
> reg1<-lm(Z ~ Y)
> plot(Y,Z)
> abline(reg1, col="black")
> 
> install.packages("robustbase")
> library?(robustbase)
> reg=lmrob(Z ~ Y, data = Dataset)
> abline(reg, col="green")
> 
> install.packages("MASS")
> library(MASS)
> Huber=rlm(Z ~ Y, data = Dataset)
> abline(Huber,col="red")
> 
> Tukey=rlm(Z ~ Y, data = Dataset,psi=psi.bisquare)
> abline(Tukey,col="purple")
>   
> install.packages("quantreg")
> library(quantreg)
> L1=rq(Z ~ Y, data = Dataset,tau=0.5)
> abline(L1,col="blue")
>   
> install.packages("RobPer")
> library(RobPer)
> FastTau(Z,Y)
> fast=FastTau(Z,Y)
> abline(fast, col="yellow")

abline() doesn't know what to do with the "fast" object.  It isn't a 
vector containing intercept and slope, it's a list containing them.  So 
you'll need something like

abline(unlist(fast), col="yellow")

Duncan Murdoch

> 
> ##########
>   
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sat Mar 31 19:50:01 2018
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 31 Mar 2018 10:50:01 -0700
Subject: [R] Names of variables needed in newdata for predict.glm
In-Reply-To: <1522511287164.49476@regionh.dk>
References: <1520400001495.13693@regionh.dk>
 <a70c15d9-651b-4f8d-dbbb-46b790cdb2a1@yahoo.fr>
 <1522511287164.49476@regionh.dk>
Message-ID: <1D7A81AC-3F9A-4FEF-97CB-2190A36E5754@comcast.net>


> On Mar 31, 2018, at 8:48 AM, Bendix Carstensen <bendix.carstensen at regionh.dk> wrote:
> 
> all.vars works fine, EXCEPT, it give a bit too much.
> I only want the regression variables, but in the following example I also get "k" the variable holding the chosen knots. Any machinery to find only "real" regression variables?
> cheers, Bendix
> 
> library( splines )
> y <- rnorm(100)
> x <- rnorm(100)
> k <- -1:1
> ml <-  lm( y ~ bs(x,knots=k) )
> mg <- glm( y ~ bs(x,knots=k) )
> all.vars(ml$terms)
> all.vars(mg$terms)
> all.vars(mg$formula)

If you allowed a requirement that "real" regression variables have been passed in a data argument, then this might succeed:

> ml <-  lm( y ~ bs(x,knots=k), data=dat )
> all.vars(ml$terms)
[1] "y" "x" "k"
> all.vars(ml$formula)
character(0)
> all.vars(ml$terms)[ all.vars(ml$terms) %in% names(dat)]
[1] "y" "x"

-- 
David.
> 

> ________________________________________
> Fra: Marc Girondot <marc_grt at yahoo.fr>
> Sendt: 8. marts 2018 06:26
> Til: Bendix Carstensen; r-help at r-project.org
> Emne: Re: [R] Names of variables needed in newdata for predict.glm
> 
> Hi,
> 
> Some try:
>> names(mi$xlevels)
> [1] "f"
>> all.vars(mi$formula)
> [1] "D" "x" "f" "Y"
>> names(mx$xlevels)
> [1] "f"
>> all.vars(mx$formula)
> [1] "D" "x" "f"
> 
> When offset is indicated out of the formula, it does not work...
> 
> Marc
> 
> Le 07/03/2018 ? 06:20, Bendix Carstensen a ?crit :
>> I would like to extract the names, modes [numeric/factor] and levels
>> of variables needed in a data frame supplied as newdata= argument to
>> predict.glm()
>> 
>> Here is a small example illustrating my troubles; what I want from
>> (both of) the glm objects is the vector c("x","f","Y") and an
>> indication that f is a factor:
>> 
>> library( splines )
>> dd <- data.frame( D = sample(0:1,200,rep=T),
>>                   x = abs(rnorm(200)),
>>                   f = factor(sample(letters[1:4],200,rep=T)),
>>                   Y = runif(200,0.5,10) )
>> mx <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) , offset=log(Y) , family=poisson, data=dd)
>> mi <- glm( D ~ ns(x,knots=1:2,Bo=c(0,5)) + f:I(x^2) + offset(log(Y)), family=poisson, data=dd)
>> 
>> attr(mx$terms,"dataClasses")
>> attr(mi$terms,"dataClasses")
>> mi$xlevels
>> mx$xlevels
>> 
>> ...so far not quite there.
>> 
>> Regards,
>> 
>> Bendix Carstensen
>> 
>> Senior Statistician
>> Steno Diabetes Center
>> Clinical Epidemiology
>> Niels Steensens Vej 2-4
>> DK-2820 Gentofte, Denmark
>> b at bxc.dk
>> bendix.carstensen at regionh.dk
>> http://BendixCarstensen.com
>> 
>> ________________________________
>> 
>> 
>> Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> ________________________________
> 
> 
> Denne e-mail indeholder fortrolig information. Hvis du ikke er den rette modtager af denne e-mail eller hvis du modtager den ved en fejltagelse, beder vi dig venligst informere afsender om fejlen ved at bruge svarfunktionen. Samtidig bedes du slette e-mailen med det samme uden at videresende eller kopiere den.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From varinsacha at yahoo.fr  Sat Mar 31 21:52:18 2018
From: varinsacha at yahoo.fr (varin sacha)
Date: Sat, 31 Mar 2018 19:52:18 +0000 (UTC)
Subject: [R] Fast tau-estimator line does ot appear on the plot
In-Reply-To: <e1158856-10fd-ed66-904d-2c1d76f1c7a7@gmail.com>
References: <1786914412.210328.1522511844686.ref@mail.yahoo.com>
 <1786914412.210328.1522511844686@mail.yahoo.com>
 <e1158856-10fd-ed66-904d-2c1d76f1c7a7@gmail.com>
Message-ID: <687478916.36477.1522525938910@mail.yahoo.com>

Many thanks Duncun,

Best,





Le samedi 31 mars 2018 ? 18:05:53 UTC+2, Duncan Murdoch <murdoch.duncan at gmail.com> a ?crit : 





On 31/03/2018 11:57 AM, varin sacha via R-help wrote:
> Dear R-experts,
> 
> Here below my reproducible R code. I want to add many straight lines to a plot using "abline"
> The last fit (fast Tau-estimator, color yellow) will not appear on the plot. What is going wrong ?
> Many thanks for your reply.
> 

It's not quite reproducible:? you forgot the line to create Dataset. 
It's probably something like

Dataset <- data.frame(Y, Z)

> ##########
> 
> Y=c(2,4,5,4,3,4,2,3,56,5,4,3,4,5,6,5,4,5,34,21,12,13,12,8,9,7,43,12,19,21)
> Z=c(43,2,1,2,34,4,3,4,5,30,4,5,4,3,4,5,56,6,43,21,34,19,12,11,9,34,21,23,2,19)
> reg1<-lm(Z ~ Y)
> plot(Y,Z)
> abline(reg1, col="black")
> 
> install.packages("robustbase")
> library?(robustbase)
> reg=lmrob(Z ~ Y, data = Dataset)
> abline(reg, col="green")
> 
> install.packages("MASS")
> library(MASS)
> Huber=rlm(Z ~ Y, data = Dataset)
> abline(Huber,col="red")
> 
> Tukey=rlm(Z ~ Y, data = Dataset,psi=psi.bisquare)
> abline(Tukey,col="purple")
>? 
> install.packages("quantreg")
> library(quantreg)
> L1=rq(Z ~ Y, data = Dataset,tau=0.5)
> abline(L1,col="blue")
>? 
> install.packages("RobPer")
> library(RobPer)
> FastTau(Z,Y)
> fast=FastTau(Z,Y)
> abline(fast, col="yellow")

abline() doesn't know what to do with the "fast" object.? It isn't a 
vector containing intercept and slope, it's a list containing them.? So 
you'll need something like

abline(unlist(fast), col="yellow")

Duncan Murdoch


> 
> ##########
>? 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


