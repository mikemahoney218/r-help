From istazahn at gmail.com  Mon Jul  1 00:11:01 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sun, 30 Jun 2013 18:11:01 -0400
Subject: [R] interpreting GLM results and plotting fits
In-Reply-To: <CACYeG1hqLdGoitRs0uEX+FweXZZMze6+2E80yn89qN0sHcsSrA@mail.gmail.com>
References: <CACYeG1hqLdGoitRs0uEX+FweXZZMze6+2E80yn89qN0sHcsSrA@mail.gmail.com>
Message-ID: <CA+vqiLE0Q+-sQkkrRWGzuvSazTvChY0hJfKL41y_jWMqDwHMKQ@mail.gmail.com>

Hi Robert,

On Sun, Jun 30, 2013 at 1:40 AM, Robert Lynch <robert.b.lynch at gmail.com> wrote:
> I am trying to interpret the output of GLM and I am not sure how it is
> treating the factor GENDER with levels G-M and G-F.

Probably using dummy codes (or "treatment contrasts" as useRs refer to
them) unless you've changed the defaults. See

getOption("contrasts")
contr.treatment
contrasts(master1$Gender)

>
> Below is the output of summary(GPA.lm)
>
>
> Call:
> glm(formula = zGPA ~ Units.Bfr.7A * GENDER, data = Master1)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -1.1432  -0.3285  -0.1061   0.2283   1.8286
>
> Coefficients:
>                          Estimate Std. Error t value Pr(>|t|)
> (Intercept)            -2.513e-01  2.238e-02 -11.230  < 2e-16 ***
> Units.Bfr.7A            2.297e-05  2.851e-04   0.081    0.936
> GENDERG-M               3.183e-01  4.536e-02   7.018 2.56e-12 ***
> Units.Bfr.7A:GENDERG-M -3.073e-03  5.975e-04  -5.142 2.82e-07 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for gaussian family taken to be 0.2432662)
>
>     Null deviance: 1204.2  on 4875  degrees of freedom
> Residual deviance: 1185.2  on 4872  degrees of freedom
>   (106 observations deleted due to missingness)
> AIC: 6950.8
>
> Number of Fisher Scoring iterations: 2
>
>
>
> second I would like to draw two lines w/ confidince intervals on the
> scatter plot.  One for G-M and the other for G-F
>
> I think I am doing this with
> stat_smooth(aes(group=GENDER), method="glm", fullrange=TRUE)
>  but again am not sure quite what is being outputted.

I think this runs separate regressions for each level of group. That's
probably not quite what you want, though it may be close enough. A
better option would be to calculate predicted values and standard
errors from the model. You can do this several ways; here are two of
them:

## Option 1: create a data.frame containing the x values for which you
want predictions, and calculate predicted falues using predict()
m1PredData <- expand.grid(GENDER=levels(Master1$GENDER),
                          Units.Bfr.7A = with(Master1, {
                              seq(min(Units.Bfr.7A),
                                  max(Units.Bfr.7A),
                                  by=1)
                          }))

m1PredData <- cbind(m1PredData,
                    predict(GPA.lm,
                            se.fit=TRUE,
                            newdata=m1PredData))

## Option 2: Use the effects package:

library(effects)
m1Effects <- effect("Units.Bfr.7A:GENDER", GPA.lm, se=TRUE)
plot(m1Effects)


Hope this helps,

Ista
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Mon Jul  1 00:44:35 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Jun 2013 18:44:35 -0400
Subject: [R] Vignettes do not appear on CRAN if files are placed in
 /vignette subdirectory - but they do appear if placed in /inst/doc
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C393102592@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>
	<51D09E71.3010009@fhcrc.org>
	<7E8037094A0C2146AA3E6F94DAE621C393102592@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51D0B4D3.4090200@gmail.com>

On 13-06-30 5:28 PM, S?ren H?jsgaard wrote:
> Sorry, yes it is plural - but changing to plural has no effect.

CRAN has had some problems building vignettes in cases where the 
vignette depends on packages that are not installed on CRAN.  Could that 
be the problem?  (They are working on fixing this.)

My tables package has a vignette in the vignettes directory, and it 
shows up on CRAN, so if it is not the above, there may be other problems.

I am currently involved in redoing the build/INSTALL code for vignettes 
(which is currently somewhat inconsistent), but I don't know when the 
new code will be ready.

Duncan Murdoch

> Regards
> S?ren
>
> -----Original Message-----
> From: Martin Morgan [mailto:mtmorgan at fhcrc.org]
> Sent: 30. juni 2013 23:09
> To: S?ren H?jsgaard
> Cc: R hELP (r-help at stat.math.ethz.ch)
> Subject: Re: [R] Vignettes do not appear on CRAN if files are placed in /vignette subdirectory - but they do appear if placed in /inst/doc
>
> On 06/30/2013 01:31 PM, S?ren H?jsgaard wrote:
>> Dear all,
>>
>> In my gRbase package there are 3 vignettes placed in the /vignette subdirectory. These vignettes do not appear on http://cran.r-project.org/web/packages/gRbase/index.html and neither do they appear if I open a browser with help("gRbase").
>>
>
>
> the directory name is plural -- vignettes.
>
> Martin
>
>> However, if instead I place the vignettes in /inst/doc then they will appear in the browser opened with help("gRbase") - and they also appear on CRAN.
>>
>> Is this how it should be or am I missing something?
>>
>> Best regards
>> S?ren
>>
>>
>>
>>> sessionInfo()
>> R version 3.0.1 Patched (2013-06-11 r62941)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252 [3]
>> LC_MONETARY=Danish_Denmark.1252 LC_NUMERIC=C [5]
>> LC_TIME=Danish_Denmark.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>    [1] gRain_1.1-2             gRbase_1.6-10           graph_1.38.0
>>    [4] igraph_0.6.5-2          RcppArmadillo_0.3.900.0 RcppEigen_0.3.1.2.1
>>    [7] Matrix_1.0-12           lattice_0.20-15         Rcpp_0.10.3
>> [10] MASS_7.3-26             shTools_1.0             markdown_0.5.4
>> [13] knitr_1.2
>>
>> loaded via a namespace (and not attached):
>>    [1] BiocGenerics_0.6.0 digest_0.6.3       evaluate_0.4.3     formatR_0.7
>>    [5] grid_3.0.1         parallel_3.0.1     RBGL_1.36.2        stats4_3.0.1
>>    [9] stringr_0.6.2      tools_3.0.1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sorenh at math.aau.dk  Mon Jul  1 01:54:18 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Sun, 30 Jun 2013 23:54:18 +0000
Subject: [R] Vignettes do not appear on CRAN if files are placed in
 /vignette subdirectory - but they do appear if placed in /inst/doc
In-Reply-To: <51D0B4D3.4090200@gmail.com>
References: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>
	<51D09E71.3010009@fhcrc.org>
	<7E8037094A0C2146AA3E6F94DAE621C393102592@AD-EXCHMBX2-1.aau.dk>
	<51D0B4D3.4090200@gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C393102624@AD-EXCHMBX2-1.aau.dk>

gRbase use graph, RBGL and Rgraphviz from bioconductor. My understanding is that if I put vignettes into /vignettes then R CMD build will build the vignettes and put them into /inst/doc and this works:

gRbase/inst/
gRbase/inst/CITATION
gRbase/inst/doc/
gRbase/inst/doc/gRbase-arrayops1.R
gRbase/inst/doc/gRbase-arrayops1.Rnw
gRbase/inst/doc/gRbase-arrayops1.pdf
gRbase/inst/doc/gRbase-arrayops2.R
gRbase/inst/doc/gRbase-arrayops2.Rnw
gRbase/inst/doc/gRbase-arrayops2.pdf
gRbase/inst/doc/gRbase-graphs.R
gRbase/inst/doc/gRbase-graphs.Rnw
gRbase/inst/doc/gRbase-graphs.pdf

After installing I then get
> vignette(package="gRbase")
no vignettes found

sorenh at sorenh:~/docs/stat/Rdevel/gmwR-DEVEL/gRbaseDEVEL$ R --version
R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

However, Martin Morgan reports that it works for him. I don't know what to make of this. 

Regards
S?ren




-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: 1. juli 2013 00:45
To: S?ren H?jsgaard
Cc: Martin Morgan; R hELP (r-help at stat.math.ethz.ch)
Subject: Re: [R] Vignettes do not appear on CRAN if files are placed in /vignette subdirectory - but they do appear if placed in /inst/doc

On 13-06-30 5:28 PM, S?ren H?jsgaard wrote:
> Sorry, yes it is plural - but changing to plural has no effect.

CRAN has had some problems building vignettes in cases where the vignette depends on packages that are not installed on CRAN.  Could that be the problem?  (They are working on fixing this.)

My tables package has a vignette in the vignettes directory, and it shows up on CRAN, so if it is not the above, there may be other problems.

I am currently involved in redoing the build/INSTALL code for vignettes (which is currently somewhat inconsistent), but I don't know when the new code will be ready.

Duncan Murdoch

> Regards
> S?ren
>
> -----Original Message-----
> From: Martin Morgan [mailto:mtmorgan at fhcrc.org]
> Sent: 30. juni 2013 23:09
> To: S?ren H?jsgaard
> Cc: R hELP (r-help at stat.math.ethz.ch)
> Subject: Re: [R] Vignettes do not appear on CRAN if files are placed 
> in /vignette subdirectory - but they do appear if placed in /inst/doc
>
> On 06/30/2013 01:31 PM, S?ren H?jsgaard wrote:
>> Dear all,
>>
>> In my gRbase package there are 3 vignettes placed in the /vignette subdirectory. These vignettes do not appear on http://cran.r-project.org/web/packages/gRbase/index.html and neither do they appear if I open a browser with help("gRbase").
>>
>
>
> the directory name is plural -- vignettes.
>
> Martin
>
>> However, if instead I place the vignettes in /inst/doc then they will appear in the browser opened with help("gRbase") - and they also appear on CRAN.
>>
>> Is this how it should be or am I missing something?
>>
>> Best regards
>> S?ren
>>
>>
>>
>>> sessionInfo()
>> R version 3.0.1 Patched (2013-06-11 r62941)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>
>> locale:
>> [1] LC_COLLATE=Danish_Denmark.1252  LC_CTYPE=Danish_Denmark.1252 [3]
>> LC_MONETARY=Danish_Denmark.1252 LC_NUMERIC=C [5]
>> LC_TIME=Danish_Denmark.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> other attached packages:
>>    [1] gRain_1.1-2             gRbase_1.6-10           graph_1.38.0
>>    [4] igraph_0.6.5-2          RcppArmadillo_0.3.900.0 RcppEigen_0.3.1.2.1
>>    [7] Matrix_1.0-12           lattice_0.20-15         Rcpp_0.10.3
>> [10] MASS_7.3-26             shTools_1.0             markdown_0.5.4
>> [13] knitr_1.2
>>
>> loaded via a namespace (and not attached):
>>    [1] BiocGenerics_0.6.0 digest_0.6.3       evaluate_0.4.3     formatR_0.7
>>    [5] grid_3.0.1         parallel_3.0.1     RBGL_1.36.2        stats4_3.0.1
>>    [9] stringr_0.6.2      tools_3.0.1
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From murdoch.duncan at gmail.com  Mon Jul  1 01:59:14 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 30 Jun 2013 19:59:14 -0400
Subject: [R] Vignettes do not appear on CRAN if files are placed in
 /vignette subdirectory - but they do appear if placed in /inst/doc
In-Reply-To: <7E8037094A0C2146AA3E6F94DAE621C393102624@AD-EXCHMBX2-1.aau.dk>
References: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>
	<51D09E71.3010009@fhcrc.org>
	<7E8037094A0C2146AA3E6F94DAE621C393102592@AD-EXCHMBX2-1.aau.dk>
	<51D0B4D3.4090200@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C393102624@AD-EXCHMBX2-1.aau.dk>
Message-ID: <51D0C652.1020800@gmail.com>

On 13-06-30 7:54 PM, S?ren H?jsgaard wrote:
> gRbase use graph, RBGL and Rgraphviz from bioconductor. My understanding is that if I put vignettes into /vignettes then R CMD build will build the vignettes and put them into /inst/doc and this works:
>
> gRbase/inst/
> gRbase/inst/CITATION
> gRbase/inst/doc/
> gRbase/inst/doc/gRbase-arrayops1.R
> gRbase/inst/doc/gRbase-arrayops1.Rnw
> gRbase/inst/doc/gRbase-arrayops1.pdf
> gRbase/inst/doc/gRbase-arrayops2.R
> gRbase/inst/doc/gRbase-arrayops2.Rnw
> gRbase/inst/doc/gRbase-arrayops2.pdf
> gRbase/inst/doc/gRbase-graphs.R
> gRbase/inst/doc/gRbase-graphs.Rnw
> gRbase/inst/doc/gRbase-graphs.pdf
>
> After installing I then get
>> vignette(package="gRbase")
> no vignettes found
>
> sorenh at sorenh:~/docs/stat/Rdevel/gmwR-DEVEL/gRbaseDEVEL$ R --version
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> However, Martin Morgan reports that it works for him. I don't know what to make of this.

Do you have all of those packages installed at the time you install 
gRbase?  If so, it may be a bug.  As I said, installation code is being 
worked on.

Duncan Murdoch


From sorenh at math.aau.dk  Mon Jul  1 02:05:05 2013
From: sorenh at math.aau.dk (=?iso-8859-1?Q?S=F8ren_H=F8jsgaard?=)
Date: Mon, 1 Jul 2013 00:05:05 +0000
Subject: [R] Vignettes do not appear on CRAN if files are placed in
 /vignette subdirectory - but they do appear if placed in /inst/doc
In-Reply-To: <51D0C652.1020800@gmail.com>
References: <7E8037094A0C2146AA3E6F94DAE621C39310255D@AD-EXCHMBX2-1.aau.dk>
	<51D09E71.3010009@fhcrc.org>
	<7E8037094A0C2146AA3E6F94DAE621C393102592@AD-EXCHMBX2-1.aau.dk>
	<51D0B4D3.4090200@gmail.com>
	<7E8037094A0C2146AA3E6F94DAE621C393102624@AD-EXCHMBX2-1.aau.dk>
	<51D0C652.1020800@gmail.com>
Message-ID: <7E8037094A0C2146AA3E6F94DAE621C393102652@AD-EXCHMBX2-1.aau.dk>

Yes, these packages are all installed.
S?ren

-----Original Message-----
From: Duncan Murdoch [mailto:murdoch.duncan at gmail.com] 
Sent: 1. juli 2013 01:59
To: S?ren H?jsgaard
Cc: Martin Morgan; R hELP (r-help at stat.math.ethz.ch)
Subject: Re: [R] Vignettes do not appear on CRAN if files are placed in /vignette subdirectory - but they do appear if placed in /inst/doc

On 13-06-30 7:54 PM, S?ren H?jsgaard wrote:
> gRbase use graph, RBGL and Rgraphviz from bioconductor. My understanding is that if I put vignettes into /vignettes then R CMD build will build the vignettes and put them into /inst/doc and this works:
>
> gRbase/inst/
> gRbase/inst/CITATION
> gRbase/inst/doc/
> gRbase/inst/doc/gRbase-arrayops1.R
> gRbase/inst/doc/gRbase-arrayops1.Rnw
> gRbase/inst/doc/gRbase-arrayops1.pdf
> gRbase/inst/doc/gRbase-arrayops2.R
> gRbase/inst/doc/gRbase-arrayops2.Rnw
> gRbase/inst/doc/gRbase-arrayops2.pdf
> gRbase/inst/doc/gRbase-graphs.R
> gRbase/inst/doc/gRbase-graphs.Rnw
> gRbase/inst/doc/gRbase-graphs.pdf
>
> After installing I then get
>> vignette(package="gRbase")
> no vignettes found
>
> sorenh at sorenh:~/docs/stat/Rdevel/gmwR-DEVEL/gRbaseDEVEL$ R --version R 
> version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> However, Martin Morgan reports that it works for him. I don't know what to make of this.

Do you have all of those packages installed at the time you install gRbase?  If so, it may be a bug.  As I said, installation code is being worked on.

Duncan Murdoch


From emily.l.weiser at gmail.com  Mon Jul  1 04:19:12 2013
From: emily.l.weiser at gmail.com (Emily Weiser)
Date: Mon, 1 Jul 2013 14:19:12 +1200
Subject: [R] Male and female signs as subscript in plot
Message-ID: <CAEc29rt4yyrs3XAG82aUj_Vn4F47q3e8P+yHzz42E6NE6QQKhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130701/c2587007/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Jul  1 09:40:07 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 01 Jul 2013 08:40:07 +0100
Subject: [R] Male and female signs as subscript in plot
In-Reply-To: <CAEc29rt4yyrs3XAG82aUj_Vn4F47q3e8P+yHzz42E6NE6QQKhg@mail.gmail.com>
References: <CAEc29rt4yyrs3XAG82aUj_Vn4F47q3e8P+yHzz42E6NE6QQKhg@mail.gmail.com>
Message-ID: <51D13257.2080301@stats.ox.ac.uk>

On 01/07/2013 03:19, Emily Weiser wrote:
> Hello,
>
> I'd like to add labels to my plot that include a male or female symbol as
> subscript.
> I'm working in Windows Vista and R 3.0.0.
> I am able to add the male symbol to the plot as regular text (NOT as
> subscript), e.g. with:
> mtext("Male\u2642")
> This displays the word "Male" followed by the male symbol on the plot.
>
> But "\u2642" does not work when I try to put it as a subscript.
> For example,
> mtext(expression("Male"["\u2217"]))
> successfully adds an asterisk as a subscript after the word "Male".
> However,
> mtext(expression("Male"["\u2642"]))
> displays the word "Male" followed by a subscript of "<U+2642>", i.e. the
> symbol is not displayed.
>
> How can I make the male symbol show as a subscript?

You cannot use non-native text with plotmath.  The issue is not that you 
used a subscript but that you passed an expression() call and hence 
invoked plotmath.  And the help does say

      In non-UTF-8 locales there is normally no support for symbols not
      in the languages for which the current encoding was intended.

> Many thanks for any suggestions!

Read all of ?plotmath.

>
> Cheers,
> Emily
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

No HTML postings please.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwinsemius at comcast.net  Mon Jul  1 10:03:21 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Jul 2013 01:03:21 -0700
Subject: [R] Male and female signs as subscript in plot
In-Reply-To: <51D13257.2080301@stats.ox.ac.uk>
References: <CAEc29rt4yyrs3XAG82aUj_Vn4F47q3e8P+yHzz42E6NE6QQKhg@mail.gmail.com>
	<51D13257.2080301@stats.ox.ac.uk>
Message-ID: <06428FEF-50BB-4BE3-A1AF-C78C9B120164@comcast.net>


On Jul 1, 2013, at 12:40 AM, Prof Brian Ripley wrote:

> On 01/07/2013 03:19, Emily Weiser wrote:
>> Hello,
>> 
>> I'd like to add labels to my plot that include a male or female symbol as
>> subscript.
>> I'm working in Windows Vista and R 3.0.0.
>> I am able to add the male symbol to the plot as regular text (NOT as
>> subscript), e.g. with:
>> mtext("Male\u2642")
>> This displays the word "Male" followed by the male symbol on the plot.
>> 
>> But "\u2642" does not work when I try to put it as a subscript.
>> For example,
>> mtext(expression("Male"["\u2217"]))
>> successfully adds an asterisk as a subscript after the word "Male".
>> However,
>> mtext(expression("Male"["\u2642"]))
>> displays the word "Male" followed by a subscript of "<U+2642>", i.e. the
>> symbol is not displayed.
>> 
>> How can I make the male symbol show as a subscript?
> 
> You cannot use non-native text with plotmath.  The issue is not that you used a subscript but that you passed an expression() call and hence invoked plotmath.  And the help does say
> 
>     In non-UTF-8 locales there is normally no support for symbols not
>     in the languages for which the current encoding was intended.

After discovering in the documentation for ?points, ?plotmath, and ?Hershey that Hershey fonts which do support astrologic symbols cannot be used in plotmath expressions, my suggestion for a work-around is to use plotmath with a phantom() call ofappropriate length in the expression and then two calls to text with xpd=TRUE:

text( locator(1), "\\VE", vfont=c("sans serif","bold"), xpd=TRUE)  # Venus
text( locator(1), "\\MA", vfont=c("sans serif","bold"), xpd=TRUE)  # Mars

I suppose this might work with approapriate modifications to the positioned parameters of that function.

> 
>> Many thanks for any suggestions!
> 
> Read all of ?plotmath.
> 

Agree with Prof Ripley. If you are a bit slow as am I, it may take 3 or 4 readings.
--

David Winsemius
Alameda, CA, USA


From rguy at 123mail.org  Mon Jul  1 10:07:24 2013
From: rguy at 123mail.org (Rguy)
Date: Mon, 1 Jul 2013 09:07:24 +0100
Subject: [R] Parallel processing random 'save' error
Message-ID: <CAEorq2O3Q37DJHV9hevNujcfM1jbnTaPkdbd9xcp+Oz1gpAFYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130701/0bd78aee/attachment.pl>

From pdalgd at gmail.com  Mon Jul  1 10:27:35 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 Jul 2013 10:27:35 +0200
Subject: [R] Lexical scoping is not what I expect
In-Reply-To: <51D0261F.1020107@gmail.com>
References: <51C8CBCE.3040903@gmail.com> <1372123341449.dc8da696@Nodemailer>
	<51C97A30.7050802@gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F091C5@GOLD.corp.lgc-group.com>
	<CABdHhvEtL0s87GSnn8MFyHtz2CdC-_65iJ6U19mfgs3YkYSC+A@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F09BD9@GOLD.corp.lgc-group.com>
	<51CD9242.2090707@gmail.com>
	<001701ce740f$61154b40$233fe1c0$@mcmaster.ca>
	<51CE38C4.7020601@xtra.co.nz>
	<CAFEqCdxErdeA35i9pqDCvwV1G+fAUq_CLGF7y3LPjp0GJVBfSA@mail.gmail.com>
	<51D0261F.1020107@gmail.com>
Message-ID: <B1F66F2F-1FBF-45A2-BD3A-822769DBC5BA@gmail.com>


On Jun 30, 2013, at 14:35 , Duncan Murdoch wrote:

> On 13-06-29 11:58 PM, Greg Snow wrote:
>> If you want to write really confusing code it is possible to do:
>> 
>> `1` <- 2
>> 
>> `1` + 1
>> 
>> and things like that, but it is probably a good idea not to.
> 
> This is actually pretty simple, as the White Knight could tell you.  `1` is what the name of 2 is called.  The name really is "2".  It's called "two", but that's only what it's called.  It really is two.
> 
> Duncan Murdoch
> 

Don't you mean "1" and "one"? As in

> as.name("1")
`1`



-pd


>> 
>> 
>> On Fri, Jun 28, 2013 at 7:30 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
>> 
>>> On 29/06/13 02:54, John Fox wrote:
>>> 
>>>> Dear Duncan and Steve,
>>>> 
>>>> Since Steve's example raises it, I've never understood why it's legal to
>>>> change the built-in global "constants" in R, including T and F. That just
>>>> seems to me to set a trap for users. Why not treat these as reserved
>>>> symbols, like TRUE, Inf, etc.?
>>>> 
>>> 
>>> I rather enjoy being able to set
>>> 
>>>     pi <- 3
>>> 
>>> :-)
>>> 
>>>     cheers,
>>> 
>>>         Rolf Turner
>>> 
>>> 
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Mon Jul  1 10:34:57 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 01 Jul 2013 09:34:57 +0100
Subject: [R] Male and female signs as subscript in plot
In-Reply-To: <06428FEF-50BB-4BE3-A1AF-C78C9B120164@comcast.net>
References: <CAEc29rt4yyrs3XAG82aUj_Vn4F47q3e8P+yHzz42E6NE6QQKhg@mail.gmail.com>
	<51D13257.2080301@stats.ox.ac.uk>
	<06428FEF-50BB-4BE3-A1AF-C78C9B120164@comcast.net>
Message-ID: <51D13F31.2010905@stats.ox.ac.uk>

On 01/07/2013 09:03, David Winsemius wrote:
>
> On Jul 1, 2013, at 12:40 AM, Prof Brian Ripley wrote:
>
>> On 01/07/2013 03:19, Emily Weiser wrote:
>>> Hello,
>>>
>>> I'd like to add labels to my plot that include a male or female symbol as
>>> subscript.
>>> I'm working in Windows Vista and R 3.0.0.
>>> I am able to add the male symbol to the plot as regular text (NOT as
>>> subscript), e.g. with:
>>> mtext("Male\u2642")
>>> This displays the word "Male" followed by the male symbol on the plot.
>>>
>>> But "\u2642" does not work when I try to put it as a subscript.
>>> For example,
>>> mtext(expression("Male"["\u2217"]))
>>> successfully adds an asterisk as a subscript after the word "Male".
>>> However,
>>> mtext(expression("Male"["\u2642"]))
>>> displays the word "Male" followed by a subscript of "<U+2642>", i.e. the
>>> symbol is not displayed.
>>>
>>> How can I make the male symbol show as a subscript?
>>
>> You cannot use non-native text with plotmath.  The issue is not that you used a subscript but that you passed an expression() call and hence invoked plotmath.  And the help does say
>>
>>      In non-UTF-8 locales there is normally no support for symbols not
>>      in the languages for which the current encoding was intended.
>
> After discovering in the documentation for ?points, ?plotmath, and ?Hershey that Hershey fonts which do support astrologic symbols cannot be used in plotmath expressions, my suggestion for a work-around is to use plotmath with a phantom() call ofappropriate length in the expression and then two calls to text with xpd=TRUE:
>
> text( locator(1), "\\VE", vfont=c("sans serif","bold"), xpd=TRUE)  # Venus
> text( locator(1), "\\MA", vfont=c("sans serif","bold"), xpd=TRUE)  # Mars
>
> I suppose this might work with approapriate modifications to the positioned parameters of that function.

Yes, you could use text() in the margin, in which case (at least on 
windows()) you can use \uxxxx notation and don't need Hershey fonts.  I 
considered mentioning that, but the positioning is going to be really 
tricky to do programatically.

>>
>>> Many thanks for any suggestions!
>>
>> Read all of ?plotmath.
>>
>
> Agree with Prof Ripley. If you are a bit slow as am I, it may take 3 or 4 readings.
> --
>
> David Winsemius
> Alameda, CA, USA
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dizem.uerek at alumni.fh-aachen.de  Mon Jul  1 10:47:36 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Mon, 1 Jul 2013 01:47:36 -0700 (PDT)
Subject: [R] Distance Measurement between probability distributions
Message-ID: <1372668456615-4670646.post@n4.nabble.com>

Dear R -Users,

I wanted to know about some existing functions (despite of euclidiean) to
compute the distance between multiple histograms.
I have found some examples like "kullbakc -Leibler DIvergenz" but the syntax
for this is not available?

Does anybody have an idea?
Thanks



--
View this message in context: http://r.789695.n4.nabble.com/Distance-Measurement-between-probability-distributions-tp4670646.html
Sent from the R help mailing list archive at Nabble.com.


From adrian at trapletti.org  Mon Jul  1 14:35:07 2013
From: adrian at trapletti.org (Adrian Trapletti)
Date: Mon, 1 Jul 2013 14:35:07 +0200
Subject: [R] Empty pdf
Message-ID: <51D1777B.2010108@trapletti.org>

Dear all,

I am comparing "R CMD BATCH script.R" with running the following code 
snippet within R:

pdf("Rplots.pdf")
source("script.R")
dev.off()
q(save="no")

Among other things, one difference is that the former produces no 
Rplots.pdf while the latter produces an empty Rplots.pdf, if script.R 
does not contain "plotting" commands (R version 3.0.1, i486-pc-linux-gnu 
(32-bit)). What is the difference between the two with respect to pdf 
plotting?

Best regards
Adrian

-- 
Dr. Adrian Trapletti
Steinstrasse 9b
CH-8610 Uster
Switzerland

Phone : +41 (0) 44 9945630
Mobile : +41 (0) 79 1037131

Email : adrian at trapletti.org
WWW : www.trapletti.org


From pdalgd at gmail.com  Mon Jul  1 15:04:01 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 1 Jul 2013 15:04:01 +0200
Subject: [R] Empty pdf
In-Reply-To: <51D1777B.2010108@trapletti.org>
References: <51D1777B.2010108@trapletti.org>
Message-ID: <DC4877A3-4DD5-4065-A09A-CF019E6BBFFD@gmail.com>


On Jul 1, 2013, at 14:35 , Adrian Trapletti wrote:

> Dear all,
> 
> I am comparing "R CMD BATCH script.R" with running the following code snippet within R:
> 
> pdf("Rplots.pdf")
> source("script.R")
> dev.off()
> q(save="no")
> 
> Among other things, one difference is that the former produces no Rplots.pdf while the latter produces an empty Rplots.pdf, if script.R does not contain "plotting" commands (R version 3.0.1, i486-pc-linux-gnu (32-bit)). What is the difference between the two with respect to pdf plotting?


Same as on the command line: If you type quartz() (or whatever is the default device for you), you get an empty window if no plotting follows. If you type plot(0:9), the quartz() device is opened for you and plotted into.

You could try

options(device=pdf)
source("script.R")
q(save="no") 

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From adrian at trapletti.org  Mon Jul  1 15:24:10 2013
From: adrian at trapletti.org (Adrian Trapletti)
Date: Mon, 1 Jul 2013 15:24:10 +0200
Subject: [R] Empty pdf
In-Reply-To: <DC4877A3-4DD5-4065-A09A-CF019E6BBFFD@gmail.com>
References: <51D1777B.2010108@trapletti.org>
	<DC4877A3-4DD5-4065-A09A-CF019E6BBFFD@gmail.com>
Message-ID: <51D182FA.9000100@trapletti.org>

Thank you
Adrian

On 07/01/2013 03:04 PM, peter dalgaard wrote:
> On Jul 1, 2013, at 14:35 , Adrian Trapletti wrote:
>
>> Dear all,
>>
>> I am comparing "R CMD BATCH script.R" with running the following code snippet within R:
>>
>> pdf("Rplots.pdf")
>> source("script.R")
>> dev.off()
>> q(save="no")
>>
>> Among other things, one difference is that the former produces no Rplots.pdf while the latter produces an empty Rplots.pdf, if script.R does not contain "plotting" commands (R version 3.0.1, i486-pc-linux-gnu (32-bit)). What is the difference between the two with respect to pdf plotting?
>
> Same as on the command line: If you type quartz() (or whatever is the default device for you), you get an empty window if no plotting follows. If you type plot(0:9), the quartz() device is opened for you and plotted into.
>
> You could try
>
> options(device=pdf)
> source("script.R")
> q(save="no")
>

-- 
Dr. Adrian Trapletti
Steinstrasse 9b
CH-8610 Uster
Switzerland

Phone : +41 (0) 44 9945630
Mobile : +41 (0) 79 1037131

Email : adrian at trapletti.org
WWW : www.trapletti.org


From james.whanger at gmail.com  Mon Jul  1 15:37:20 2013
From: james.whanger at gmail.com (James C. Whanger)
Date: Mon, 1 Jul 2013 09:37:20 -0400
Subject: [R] Gene expression clustering using several dependent samples
In-Reply-To: <CAJox6VDtoackHjokcjunsPOUQ6JG=LYyPYDdKUCyskxCX7Mz8g@mail.gmail.com>
References: <CAJox6VDtoackHjokcjunsPOUQ6JG=LYyPYDdKUCyskxCX7Mz8g@mail.gmail.com>
Message-ID: <CAGG=QuFFSCyU==gnbe=5WW+oOBRK3obQUvCLUy7eS=T7HqV6Tw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130701/22967c3f/attachment.pl>

From meyners.m at pg.com  Mon Jul  1 15:37:41 2013
From: meyners.m at pg.com (Meyners, Michael)
Date: Mon, 1 Jul 2013 13:37:41 +0000
Subject: [R] Add constraints to rbinom
In-Reply-To: <CALv--dbHvmMRgDobxhY8y1uAzUapKrS5ADiSNhcY5Le1OHLawA@mail.gmail.com>
References: <CALv--dbHvmMRgDobxhY8y1uAzUapKrS5ADiSNhcY5Le1OHLawA@mail.gmail.com>
Message-ID: <AE85F2AAC98B094483D12EEA72230EBD4FC1EF29@GADC-EMB019.na.pg.com>

You don't need a constraint (rbinom won't give x>n), but you need to make sure you are using the n you want to use: try
 x <- cbind(x,rbinom(300,n[i],p[i]))	# mind the "[i]" after the n
at the respective line. Furthermore, you need to remove one transformation of x to make sure you divide by the right n, try
rate <- t(x/n)

I think that should do the trick. I didn't check the remainder of the code, though.

HTH, Michael


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Anamika Chaudhuri
> Sent: Freitag, 28. Juni 2013 04:06
> To: r-help at r-project.org
> Subject: [R] Add constraints to rbinom
> 
> Hi:
> 
> I am trying to generate Beta-Binomial random variables and then calculate
> Binomial exact confidence intervals to the rate..I was wondering if I needed
> to add a constraint such that x<=n to it, how do I go about it. The reason is I
> am getting data where x>n which is giving a rate>1. Heres my code:
> 
> set.seed(111)
> k<-63
> x<-NULL
> p<-rbeta(k,3,3)# so that the mean nausea rate is alpha/(alpha+beta)
> min<-10
> max<-60
> n<-as.integer(runif(k,min,max))
> for(i in 1:k)
> x<-cbind(x,rbinom(300,n,p[i]))
> x<-t(x)
> rate<-t(t(x)/n)
> se_rate<-sqrt(rate*(1-rate)/n)
> 
> 
> 
> # Exact Confidence Interval
> 
> l_cl_exact<-qbeta(.025,x,n-x+1)
> u_cl_exact<-qbeta(.975,x+1,n-x)
> 
> for (i in 1:63){
> 
> for (j in 1:300)
> {
> 
> if (x[i,j]==0)
> {
> l_cl_exact[i,j]<-0
> u_cl_exact[i,j]<-u_cl_exact[i,j]
> }
> else if (x[i,j]==n[i])
> {
> l_cl_exact[i,j]<-l_cl_exact[i,j]
> u_cl_exact[i,j]<-1
> }
> else
> l_cl_exact[i,j]<-l_cl_exact[i,j]
> u_cl_exact[i,j]<-u_cl_exact[i,j]
> 
> #print(c(i,j))
> 
> }
> }
> 
> 
> Really appreciate any help.
> Thanks
> Anamika
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Mon Jul  1 16:57:30 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 1 Jul 2013 14:57:30 +0000
Subject: [R] Parallel processing random 'save' error
In-Reply-To: <CAEorq2O3Q37DJHV9hevNujcfM1jbnTaPkdbd9xcp+Oz1gpAFYA@mail.gmail.com>
References: <CAEorq2O3Q37DJHV9hevNujcfM1jbnTaPkdbd9xcp+Oz1gpAFYA@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C308BE1@PA-MBX01.na.tibco.com>

> Error in checkForRemoteErrors(val) :
>   one node produced an error: (converted from warning)
> 'D:\_pgf\quantile_analysis2_f13\_save\dbz084_nump48\bins' already exists

That warning looks like it comes from dir.create().  Do you have
code that looks like:
   if (!file.exists(tempDir)) {
      dir.create(tempDir)
   }
If so that could be the problem.  The directory may not exist when file.exists()
is called but by the time dir.create is called another process may have created
it.  Try replacing such code with
    suppressWarnings(dir.create(tempDir))
    if (!isTRUE(file.info(tempDir)$isdir)) {
        stop("Cannot create tempDir=", tempDir)
    }


Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Rguy
> Sent: Monday, July 01, 2013 1:07 AM
> To: r-help at r-project.org
> Subject: [R] Parallel processing random 'save' error
> 
> Platform: Windows 7
> Package: parallel
> Function: parLapply
> 
> I am running a lengthy program with 8 parallel processes running in main
> memory.
> The processes save data using the 'save' function, to distinct files so
> that no conflicts writing to the same file are possible.
> I have been getting errors like the one shown below on a random basis,
> i.e., sometimes at one point in the execution, sometimes at another,
> sometimes no error at all.
> I should note that the directory referred to in the error message
> ( 'D:\_pgf\quantile_analysis2_f13\_save\dbz084_nump48\bins') contains, as I
> write, 124 files saved to it by the program without any error; which
> underscores the point that most of the time the saves occur with no problem.
> 
> Error in checkForRemoteErrors(val) :
>   one node produced an error: (converted from warning)
> 'D:\_pgf\quantile_analysis2_f13\_save\dbz084_nump48\bins' already exists
> 
> Enter a frame number, or 0 to exit
> 
>  1: main_top(9)
>  2: main_top.r#26: eval(call_me)
>  3: eval(expr, envir, enclos)
>  4: quantile_analysis(2)
>  5: quantile_analysis.r#69: run_all(layr, prjp, np, rules_tb, pctiles_tb,
> parx, logdir, logg)
>  6: run_all.r#73: parLapply(cl, ctrl_all$vn, qa1, prjp, dfr1, "iu__bool",
> parx, logdir, tstamp)
>  7: do.call(c, clusterApply(cl, x = splitList(X, length(cl)), fun = lapply,
> fun, ...), quote = TRUE)
>  8: clusterApply(cl, x = splitList(X, length(cl)), fun = lapply, fun, ...)
>  9: staticClusterApply(cl, fun, length(x), argfun)
> 10: checkForRemoteErrors(val)
> 11: stop("one node produced an error: ", firstmsg, domain = NA)
> 12: (function ()
> {
>     error()
>     utils::recover()
> })()
> 
> Following the latest error I checked the system's connections as follows:
> 
> Browse[1]> showConnections()
>    description             class      mode  text     isopen   can read can
> write
> 3  "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> 4  "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> 5  "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> 6  "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> 7  "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> 8  "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> 9  "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> 10 "<-LAPTOP_32G_01:11741" "sockconn" "a+b" "binary" "opened" "yes"
>  "yes"
> Browse[1]>
> 
> It seems that the parallel processes might be sharing the same
> connection--or is it that they are utilizing connections that have the same
> name but are actually distinct because they are running in parallel?
> If the connections are the problem, how can I force each parallel process
> to use a different connection?
> If the connections are not the problem, then can someone suggest a
> diagnostic I might apply to tease out what is going wrong? Or perhaps some
> program setting that I may have neglected to consider?
> 
> Thanks in advance for your help.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From t.jones at smd11.qmul.ac.uk  Mon Jul  1 19:57:04 2013
From: t.jones at smd11.qmul.ac.uk (tfj24)
Date: Mon, 1 Jul 2013 10:57:04 -0700 (PDT)
Subject: [R] Missing data problem and ROC curves
Message-ID: <1372701424254-4670661.post@n4.nabble.com>

Hello all,

Trying to get this piece of code to work on my data set. It is from
http://www.itc.nl/personal/rossiter.

logit.roc <- function(model, steps=100)
		{
		field.name <- attr(attr(terms(formula(model)), "factors"),
"dimnames")[[1]][1]
		eval(parse(text=paste("tmp <- ", ifelse(class(model$data) == "data.frame",
"model$data$", ""), field.name, sep="")))
		r <- data.frame(pts = seq(0, 1-(1/steps), by=1/steps), sens = 0, spec=0);
for (i in 0:steps)
		{
		      thresh <- i/steps;
		      r$sens[i] <- sum((fitted(model) >= thresh) & tmp)/sum(tmp);
		      r$spec[i] <- sum((fitted(model) < thresh) & !tmp)/sum(!tmp)
		}
		return(r)}

where model is the output of a glm.

The problem is the "sum((fitted(model) >= thresh) & tmp)" bit. The lengths
of fitted(model) and tmp are not equal because some of the cases were
deleted from the model due to missing data! fitted(model) is a set of named
numbers while tmp is a set of integers.

My question is:
- How do I determine which cases were deleted from the model and then delete
the associated cases from tmp?

I hope this makes sense and would really appreciate any help that people may
have.

Thanks,
Tim



--
View this message in context: http://r.789695.n4.nabble.com/Missing-data-problem-and-ROC-curves-tp4670661.html
Sent from the R help mailing list archive at Nabble.com.


From smak at gfz-potsdam.de  Mon Jul  1 14:45:01 2013
From: smak at gfz-potsdam.de (Sam Mak)
Date: Mon, 1 Jul 2013 05:45:01 -0700 (PDT)
Subject: [R] Dunnett's T3 test (DTK package) problem
Message-ID: <1372682701912-4670649.post@n4.nabble.com>

Hello,

I would like to ask a question about using DTK.test() to do the T3 test.

The data file is downloadable here:
http://ubuntuone.com/0zBl8QgUg1lAG6iK1CUicD

My question is: in the result of T3 test, is it possible for the following
three statements to hold without conflict?
1. m_a and m_b to be significantly different
2. m_a and m_c are not significantly different.
3. (m_c - m_a) >= (m_c- m_b)
where m_i is the mean value of group i.

I know that for Tukey test, the above three statements can't hold without
conflict.


The code to run the test is:

======== BEGIN ============
library(DTK)
df <- read.csv("./tmpData.csv")
DTK_result <- DTK.test(df$measurement, df$model, .05)
print(DTK_result)
======== END ============

Part of the result is displayed below. It says model05 and model01 are
significantly different, while model04 and model01 are not.

======== BEGIN ============
                       Diff    Lower CI  Upper CI
model02-model01 0.068468884 -0.04765040 0.1845882
model03-model01 0.143238920 -0.05589008 0.3423679
model04-model01 0.149002642  0.02900301 0.2690023
model05-model01 0.151504289 -0.04775209 0.3507607
model06-model01 0.193093625  0.07023934 0.3159479
...
======== END ============


The mean value of the groups are shown below. It shows (m_5 - m_1) > (m_4 -
m_1), where m_i is the mean value of model i.

======== BEGIN ============
library(plyr)
ddply(df, ~model, summarise, mean=mean(measurement))

     model      mean
1  model01 0.5352273
2  model02 0.6036962
3  model03 0.6784662
4  model04 0.6842300
5  model05 0.6867316
6  model06 0.7283210
7  model07 0.7489938
8  model08 0.7941213
9  model09 0.7944798
10 model10 1.1399370
11 model11 1.2582504
12 model12 1.2928783
13 model13 1.5789970
======== END ============




--
View this message in context: http://r.789695.n4.nabble.com/Dunnett-s-T3-test-DTK-package-problem-tp4670649.html
Sent from the R help mailing list archive at Nabble.com.


From ntamjo2003 at yahoo.fr  Mon Jul  1 17:35:46 2013
From: ntamjo2003 at yahoo.fr (ntamjo achille)
Date: Mon, 1 Jul 2013 16:35:46 +0100 (BST)
Subject: [R] Lee carter model
Message-ID: <1372692946.68698.YahooMailNeo@web172805.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130701/8ce523e0/attachment.pl>

From jamilnaser79 at gmail.com  Mon Jul  1 19:37:38 2013
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Mon, 1 Jul 2013 18:37:38 +0100
Subject: [R] functions and matrices
Message-ID: <CAJK=5Ym5aL_yd_pj9mBW4wAWHODCPtnA1MVT1B8ENk=zCtux-A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130701/c639a768/attachment.pl>

From thomasgrzybowski at gmail.com  Mon Jul  1 20:23:13 2013
From: thomasgrzybowski at gmail.com (Thomas Grzybowski)
Date: Mon, 01 Jul 2013 14:23:13 -0400
Subject: [R] writing to the screen and extra "0"
Message-ID: <51D1C911.6020303@gmail.com>


I am using the "write" function like so (R 3.0.1 on linux):

"wrt" <-
function()
{
     write(system("ls *"),file="")
}

When the files are listed to the screen with wrt(), there is a "0" 
character prepended to the output on the screen.  Worse, when I remove 
the 'file=""' argument to "write", a file named "data" is created in my 
default directory, with a zero in it.

All I am trying to do is output the "ls" of files in my directory, 
without any extra characters or type-attribute information.  Thanks for 
your help!

Thomas Grzybowski


From ruipbarradas at sapo.pt  Mon Jul  1 20:55:21 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 01 Jul 2013 19:55:21 +0100
Subject: [R] writing to the screen and extra "0"
In-Reply-To: <51D1C911.6020303@gmail.com>
References: <51D1C911.6020303@gmail.com>
Message-ID: <51D1D099.8040109@sapo.pt>

Hello,

Try instead


list.files(pattern = "*")


Hope this helps,

Rui Barradas

Em 01-07-2013 19:23, Thomas Grzybowski escreveu:
>
> I am using the "write" function like so (R 3.0.1 on linux):
>
> "wrt" <-
> function()
> {
>      write(system("ls *"),file="")
> }
>
> When the files are listed to the screen with wrt(), there is a "0"
> character prepended to the output on the screen.  Worse, when I remove
> the 'file=""' argument to "write", a file named "data" is created in my
> default directory, with a zero in it.
>
> All I am trying to do is output the "ls" of files in my directory,
> without any extra characters or type-attribute information.  Thanks for
> your help!
>
> Thomas Grzybowski
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Mon Jul  1 20:56:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Jul 2013 11:56:33 -0700
Subject: [R] Missing data problem and ROC curves
In-Reply-To: <1372701424254-4670661.post@n4.nabble.com>
References: <1372701424254-4670661.post@n4.nabble.com>
Message-ID: <454015B6-EC23-4583-9EC3-481A3CFE0DEB@comcast.net>


On Jul 1, 2013, at 10:57 AM, tfj24 wrote:

> Hello all,
> 
> Trying to get this piece of code to work on my data set. It is from
> http://www.itc.nl/personal/rossiter.
> 
> logit.roc <- function(model, steps=100)
> 		{
> 		field.name <- attr(attr(terms(formula(model)), "factors"),
> "dimnames")[[1]][1]
> 		eval(parse(text=paste("tmp <- ", ifelse(class(model$data) == "data.frame",
> "model$data$", ""), field.name, sep="")))
> 		r <- data.frame(pts = seq(0, 1-(1/steps), by=1/steps), sens = 0, spec=0);
> for (i in 0:steps)
> 		{
> 		      thresh <- i/steps;
> 		      r$sens[i] <- sum((fitted(model) >= thresh) & tmp)/sum(tmp);
> 		      r$spec[i] <- sum((fitted(model) < thresh) & !tmp)/sum(!tmp)
> 		}
> 		return(r)}
> 
> where model is the output of a glm.

> 
> The problem is the "sum((fitted(model) >= thresh) & tmp)" bit. The lengths
> of fitted(model) and tmp are not equal because some of the cases were
> deleted from the model due to missing data! fitted(model) is a set of named
> numbers while tmp is a set of integers.
> 
> My question is:
> - How do I determine which cases were deleted from the model and then delete
> the associated cases from tmp?
> 

?glm
model$na.action

-- 
David.

> I hope this makes sense and would really appreciate any help that people may
> have.
> 
> Thanks,
> Tim
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Missing-data-problem-and-ROC-curves-tp4670661.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From thomasgrzybowski at gmail.com  Mon Jul  1 21:03:18 2013
From: thomasgrzybowski at gmail.com (Thomas Grzybowski)
Date: Mon, 01 Jul 2013 15:03:18 -0400
Subject: [R] writing to the screen and extra "0"
In-Reply-To: <51D1D099.8040109@sapo.pt>
References: <51D1C911.6020303@gmail.com> <51D1D099.8040109@sapo.pt>
Message-ID: <51D1D276.8080409@gmail.com>

Hi.

list.files(pattern = "*")

gives me output with the R list indices at the left of each line on the 
screen.  I want only file names.

Thanks!
Tom Grzybowski


On 07/01/2013 02:55 PM, Rui Barradas wrote:
> Hello,
>
> Try instead
>
>
> list.files(pattern = "*")
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 01-07-2013 19:23, Thomas Grzybowski escreveu:
>>
>> I am using the "write" function like so (R 3.0.1 on linux):
>>
>> "wrt" <-
>> function()
>> {
>>      write(system("ls *"),file="")
>> }
>>
>> When the files are listed to the screen with wrt(), there is a "0"
>> character prepended to the output on the screen.  Worse, when I remove
>> the 'file=""' argument to "write", a file named "data" is created in my
>> default directory, with a zero in it.
>>
>> All I am trying to do is output the "ls" of files in my directory,
>> without any extra characters or type-attribute information. Thanks for
>> your help!
>>
>> Thomas Grzybowski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From deter088 at umn.edu  Mon Jul  1 21:09:43 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Mon, 1 Jul 2013 14:09:43 -0500
Subject: [R] writing to the screen and extra "0"
In-Reply-To: <51D1D276.8080409@gmail.com>
References: <51D1C911.6020303@gmail.com> <51D1D099.8040109@sapo.pt>
	<51D1D276.8080409@gmail.com>
Message-ID: <CAOLJphk2jtfJv-ikYyKSi4VFMaSmPP2nn483b6OZ-YUaDsYLBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130701/4ebf88dd/attachment.pl>

From bhh at xs4all.nl  Mon Jul  1 21:10:44 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 1 Jul 2013 21:10:44 +0200
Subject: [R] writing to the screen and extra "0"
In-Reply-To: <51D1D276.8080409@gmail.com>
References: <51D1C911.6020303@gmail.com> <51D1D099.8040109@sapo.pt>
	<51D1D276.8080409@gmail.com>
Message-ID: <6B183F15-A05F-478A-A00F-C2A345C98159@xs4all.nl>


On 01-07-2013, at 21:03, Thomas Grzybowski <thomasgrzybowski at gmail.com> wrote:

> Hi.
> 
> list.files(pattern = "*")
> 
> gives me output with the R list indices at the left of each line on the screen.  I want only file names.
> 

cat(list.files(pattern = "*"),sep="\n")

Berend

> Thanks!
> Tom Grzybowski
> 
> 
> On 07/01/2013 02:55 PM, Rui Barradas wrote:
>> Hello,
>> 
>> Try instead
>> 
>> 
>> list.files(pattern = "*")
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> Em 01-07-2013 19:23, Thomas Grzybowski escreveu:
>>> 
>>> I am using the "write" function like so (R 3.0.1 on linux):
>>> 
>>> "wrt" <-
>>> function()
>>> {
>>>     write(system("ls *"),file="")
>>> }
>>> 
>>> When the files are listed to the screen with wrt(), there is a "0"
>>> character prepended to the output on the screen.  Worse, when I remove
>>> the 'file=""' argument to "write", a file named "data" is created in my
>>> default directory, with a zero in it.
>>> 
>>> All I am trying to do is output the "ls" of files in my directory,
>>> without any extra characters or type-attribute information. Thanks for
>>> your help!
>>> 
>>> Thomas Grzybowski
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dizem.uerek at alumni.fh-aachen.de  Mon Jul  1 22:47:56 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Mon, 1 Jul 2013 13:47:56 -0700 (PDT)
Subject: [R] Bhattacharyya in R
Message-ID: <1372711676368-4670671.post@n4.nabble.com>

Dear R-user,
I am trying to apply bhattacharyya-distance function to my data. Did anybody
use it before ?

My code is the following

#Bhattacharya Distance measure
#a and b are vectors 
a <- (1,2,3,4,2,2,2,2,2,2,2,1,4,5,6,-1,-1,-1,-1,-1,-3,-3,-3)
b <-
(1.1,1.1,1.2,1.2,1.2,1.2,1.2,2.1,2.1,2.2,2.2,2,0,0,0,0,2,2,2,2,2,3.1,3.1)

dist <- bhattacharyya.matrix(a,b,missclasification = TRUE)
plot(dist)


Could somebody give me a guide on the syntax ?

Thanks
Dizem





--
View this message in context: http://r.789695.n4.nabble.com/Bhattacharyya-in-R-tp4670671.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Mon Jul  1 23:35:39 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 01 Jul 2013 14:35:39 -0700
Subject: [R] Bhattacharyya in R
In-Reply-To: <1372711676368-4670671.post@n4.nabble.com>
References: <1372711676368-4670671.post@n4.nabble.com>
Message-ID: <4e03ba9d-d473-454c-a62d-db1b624a0793@email.android.com>

There is a built-in guide to syntax called the help system. If you have read it you should be able to be mitre specific with your questions.

I had never heard of this function. Your example code is not reproducible, nor does it indicate what result you got from running it.

I used

RSiteSearch("bhattacharya")

and there appears to be a function bhattacharyya.matrix in the fpc package. The syntax indicated in the help for that function mentions wanting input matrices, not vectors. It also mentions another function bhattacharyya.dist which does accept vectors, but it does not accept the misclassification.bound argument.

You should read the help file and ask more specific questions and provide reproducible examples per the Posting Guide recommendations.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Dzu <dizem.uerek at alumni.fh-aachen.de> wrote:

>Dear R-user,
>I am trying to apply bhattacharyya-distance function to my data. Did
>anybody
>use it before ?
>
>My code is the following
>
>#Bhattacharya Distance measure
>#a and b are vectors 
>a <- (1,2,3,4,2,2,2,2,2,2,2,1,4,5,6,-1,-1,-1,-1,-1,-3,-3,-3)
>b <-
>(1.1,1.1,1.2,1.2,1.2,1.2,1.2,2.1,2.1,2.2,2.2,2,0,0,0,0,2,2,2,2,2,3.1,3.1)
>
>dist <- bhattacharyya.matrix(a,b, misclassification.bound = TRUE)
>plot(dist)
>
>
>Could somebody give me a guide on the syntax ?
>
>Thanks
>Dizem
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Bhattacharyya-in-R-tp4670671.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Jul  1 23:49:04 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 01 Jul 2013 14:49:04 -0700
Subject: [R] Lee carter model
In-Reply-To: <1372692946.68698.YahooMailNeo@web172805.mail.ir2.yahoo.com>
References: <1372692946.68698.YahooMailNeo@web172805.mail.ir2.yahoo.com>
Message-ID: <1a07caa8-1a4a-44fc-8f11-3e1614e729fa@email.android.com>

The Posting Guide warns you to not post in HTML format (it messes up R code examples). It also warns you to supply reproducible examples (we should be able to paste your code into a fresh R session and see essentially what you see). 

The warning message means you have given the function a factor where it expected a numeric value (max does not work on factors). I suggest that you learn how to use the str() function on your data so you know that you have imported it successfully before you give it to analysis functions. You may need to review the "Introduction to R" and "R Data Import/Export" PDF files that come with R if you don't know what a factor is or how to import numeric data.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

ntamjo achille <ntamjo2003 at yahoo.fr> wrote:

>Hi everybody,
>
>I'm running codes for for a Lee carter modeling. I compute the
>demogdata function in the package demography.?
>Age is a class of factor
>
>Base<-demogdata(data=x,pop=y,ages=AGE,years=YEAR,type="mortality",label="City",name="Hommes",lambda=1)
>?
>Now, I try to run codes for lee carter model, and i always get the
>following message:
>Error in Summary.factor(c(1L, 2L, 24L, 35L, 46L, 57L, 68L, 79L, 90L,
>101L, ?:?
>? max not meaningful for factors
>
>Please can you help to understand what means this message.?
>
>Many Thanks
>
>Achille
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ben_thompson at talk21.com  Mon Jul  1 23:13:26 2013
From: ben_thompson at talk21.com (ben1983)
Date: Mon, 1 Jul 2013 14:13:26 -0700 (PDT)
Subject: [R] Optimum of lm
Message-ID: <1372713206484-4670674.post@n4.nabble.com>

Hi All, 
          I am trying to do some D o E. I would like to find the optima
(maxima) of a 2 dimensional lm with quadratic terms.
I'm sure there is a really simple solution but i can't find it.
Also would there be any way to find some sort of confidence limits on these
optima?
Any help most appreciated!
Cheers,
Ben



--
View this message in context: http://r.789695.n4.nabble.com/Optimum-of-lm-tp4670674.html
Sent from the R help mailing list archive at Nabble.com.


From rolf.turner at xtra.co.nz  Tue Jul  2 00:32:00 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Tue, 02 Jul 2013 10:32:00 +1200
Subject: [R] functions and matrices
In-Reply-To: <CAJK=5Ym5aL_yd_pj9mBW4wAWHODCPtnA1MVT1B8ENk=zCtux-A@mail.gmail.com>
References: <CAJK=5Ym5aL_yd_pj9mBW4wAWHODCPtnA1MVT1B8ENk=zCtux-A@mail.gmail.com>
Message-ID: <51D20360.6030909@xtra.co.nz>


Basically R does things *numerically* and what you want to do really
amounts to symbolic manipulation.  Of course R could be cajoled into
doing it --- see fortune("Yoda") --- but probably only with a great deal of
effort and code-writing.

OTOH you could quite easily write a function that would calculate
det(u%*%v)(x) for any given numerical value of x:

foo <- function(a,b,x){
     a1 <- apply(a,c(1,2),function(m,x){m[[1]](x)},x=x)
     b1 <- apply(b,c(1,2),function(m,x){m[[1]](x)},x=x)
     det(a1%*%b1)
}

Then doing

     foo(u,v,2)

gives 0.  (In fact foo(u,v,anything) gives 0 for your collection of 
functions;
the matrix "u(x)" is singular for any x --- the second row is x^2 times the
first row.)

Perhaps this is good enough for your purposes?  If not, you should probably
be looking at a symbolic manipulation package.  The R package "Ryacas" has
some capabilities in this regard, but I have no experience with it and 
cannot
advise.

     cheers,

         Rolf Turner

On 02/07/13 05:37, Naser Jamil wrote:
> Dear R-user,
> May I seek your help, please. I have two matrices, u and v, elements of
> which are some functions
> of x. I just want to multiply them and express the determinant of the
> resulting matrix as a function of
> x and of course, this is for some reason. Actually the original problem has
> more matrices to multiply and I'm just wondering whether I can simplify it
> anyway through the R codes. It may even be non-sense, but just want to hear
> from you. The below is the code.
>
> ---------------------------------------------------------------------------------------------
>
> f1<-function(x) {x}
> f2<-function(x) {x^2}
> f3<-function(x) {x^3}
> f4<-function(x) {x^4}
>
> f5<-function(x) {x^2+7}
> f6<-function(x) {x^3+14*x}
> f7<-function(x) {x^2+2*x}
> f8<-function(x) {x^4+10*x}
>
> u<-matrix(c(f1,f2,f3,f4), nrow=2, ncol=2, byrow=TRUE)
> v<-matrix(c(f5,f6,f7,f8), nrow=2, ncol=2, byrow=TRUE)
>
> det(u %*% v) # Is that possible?
>
> ------------------------------------------------------------------------------------------------
>
> Any suggestion will be more than great!


From swiftaw at gmail.com  Mon Jul  1 21:44:48 2013
From: swiftaw at gmail.com (Andrew W. Swift)
Date: Mon, 1 Jul 2013 14:44:48 -0500
Subject: [R] Trying to predict from a time series with Additive Outliers:
	Error in as.matrix(newxreg) %*% coefs[-(1L:narma)] :
	non-conformable arguments
Message-ID: <669C70B0-A6ED-4CD5-BF5E-386BD2DCC1C2@gmail.com>

Hi,

I am trying to work through an example in Cryer & Chan's book with regards to an ARIMA model with Interventions and Outliers

The model fit is:

m=arimax(log(airmiles),order=c(0,1,1),seasonal=list(order=c(0,1,1),period=12),xtransf=data.frame(I911=1*(seq(airmiles)==69), I911a=1*(seq(airmiles)==69)),transfer=list(c(0,0),c(1,0)),xreg=data.frame(I12=1*(seq(airmiles)==12),I25=1*(seq(airmiles)==25),I84=1*(seq(airmiles)==84)),io=c(81),method='ML')

I now want to predict from this model.  I understand that since we use xreg in the model fit, I have to specify newxreg in the predict statement.  Since xreg only contains information about additive outliers, the vectors provided in newxreg should all be zeros. 

I thus try the following

nxr=data.frame(I12=seq(0,0,length=5),I25=seq(0,0,length=5),I84=seq(0,0,length=5))
predict(m,na.ahead=5,newxreg=nxr)

But I get the following error:

Error in as.matrix(newxreg) %*% coefs[-(1L:narma)] : 
  non-conformable arguments


Any thoughts?

Thanks. 


From viton.1 at osu.edu  Mon Jul  1 19:36:41 2013
From: viton.1 at osu.edu (Philip A. Viton)
Date: Mon, 1 Jul 2013 14:36:41 -0300
Subject: [R] subset of factors in a regression
Message-ID: <b1b8ff37-2617-4ab7-8b03-3b76d9289c2e@CIO-TNC-HT07.osuad.osu.edu>


suppose "state" is a variable in a dataframe containing abbreviations 
of the US states, as a factor. What I'd like to do is to include 
dummy variables for a few of the states, (say, CA and MA) among the 
independent variables in my regression formula. (This would be the 
equivalent of, creating, eg, ca<-state=="CA") and then including 
that). I know I can create all the necessary dummy variables by using 
the "outer" function on the factor and then renaming them 
appropriately; but is there a solution that's more direct, ie that 
doesn't involve a lot of new variables?

Thanks!


------------------------
Philip A. Viton
City Planning, Ohio State University
275 West Woodruff Avenue, Columbus OH 43210
viton.1 at osu.edu


From dwinsemius at comcast.net  Tue Jul  2 01:37:26 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Jul 2013 16:37:26 -0700
Subject: [R] functions and matrices
In-Reply-To: <51D20360.6030909@xtra.co.nz>
References: <CAJK=5Ym5aL_yd_pj9mBW4wAWHODCPtnA1MVT1B8ENk=zCtux-A@mail.gmail.com>
	<51D20360.6030909@xtra.co.nz>
Message-ID: <A0CDD8D7-2539-4D24-9B91-18F0466FD4A6@comcast.net>


On Jul 1, 2013, at 3:32 PM, Rolf Turner wrote:

> 
> Basically R does things *numerically* and what you want to do really
> amounts to symbolic manipulation.  Of course R could be cajoled into
> doing it --- see fortune("Yoda") --- but probably only with a great deal of
> effort and code-writing.
> 
> OTOH you could quite easily write a function that would calculate
> det(u%*%v)(x) for any given numerical value of x:
> 
> foo <- function(a,b,x){
>    a1 <- apply(a,c(1,2),function(m,x){m[[1]](x)},x=x)
>    b1 <- apply(b,c(1,2),function(m,x){m[[1]](x)},x=x)
>    det(a1%*%b1)
> }
> 
> Then doing
> 
>    foo(u,v,2)

I would have thought that (u %*% v) would be:

      u[1,1]( v[1,1](x) ) + u[1,2]( v[2,1](x) )   u[1,1]( v[1,2](x) ) + u[1,2]( v[2,2](x) )  
      u[2,1]( v[1,1](x) ) + u[2,2]( v[2,1](x) )   u[2,1]( v[2,1](x) ) + u[2,2]( v[2,2](x) )

(Crossing my fingers that I got the row and column conventions correct for matrix multiplication.)


> 
> gives 0.  (In fact foo(u,v,anything) gives 0 for your collection of functions;
> the matrix "u(x)" is singular for any x --- the second row is x^2 times the
> first row.)
> 
> Perhaps this is good enough for your purposes?  If not, you should probably
> be looking at a symbolic manipulation package.  The R package "Ryacas" has
> some capabilities in this regard, but I have no experience with it and cannot
> advise.
> 
>    cheers,
> 
>        Rolf Turner
> 
> On 02/07/13 05:37, Naser Jamil wrote:
>> Dear R-user,
>> May I seek your help, please. I have two matrices, u and v, elements of
>> which are some functions
>> of x. I just want to multiply them and express the determinant of the
>> resulting matrix as a function of
>> x and of course, this is for some reason. Actually the original problem has
>> more matrices to multiply and I'm just wondering whether I can simplify it
>> anyway through the R codes. It may even be non-sense, but just want to hear
>> from you. The below is the code.
>> 
>> ---------------------------------------------------------------------------------------------
>> 
>> f1<-function(x) {x}
>> f2<-function(x) {x^2}
>> f3<-function(x) {x^3}
>> f4<-function(x) {x^4}
>> 
>> f5<-function(x) {x^2+7}
>> f6<-function(x) {x^3+14*x}
>> f7<-function(x) {x^2+2*x}
>> f8<-function(x) {x^4+10*x}
>> 
>> u<-matrix(c(f1,f2,f3,f4), nrow=2, ncol=2, byrow=TRUE)
>> v<-matrix(c(f5,f6,f7,f8), nrow=2, ncol=2, byrow=TRUE)
>> 
>> det(u %*% v) # Is that possible?
>> 
>> ------------------------------------------------------------------------------------------------
>> 
>> Any suggestion will be more than great!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From khasroinerbil at yahoo.com  Tue Jul  2 01:46:23 2013
From: khasroinerbil at yahoo.com (Khasro Abdulrahman Ismael)
Date: Mon, 1 Jul 2013 16:46:23 -0700 (PDT)
Subject: [R] similarity and dissimilarity index
Message-ID: <1372722383.34183.YahooMailNeo@web121204.mail.ne1.yahoo.com>

Hallo every one
I have this table and tried to find similarity and dissimilarity index in r by vegan package but I couldn't. I really don't know why I couldn't as I spend a lot of time working on it, so would you be so kind to calculate or give me some advise about my problem?
?
Ismael, Khasro Abdulrahman?
Bremen University
Mary-Astell-Stra?e 25
Wohnung 149
28539 Bremen
Germany?

From rolf.turner at xtra.co.nz  Tue Jul  2 02:12:32 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Tue, 02 Jul 2013 12:12:32 +1200
Subject: [R] similarity and dissimilarity index
In-Reply-To: <1372722383.34183.YahooMailNeo@web121204.mail.ne1.yahoo.com>
References: <1372722383.34183.YahooMailNeo@web121204.mail.ne1.yahoo.com>
Message-ID: <51D21AF0.9020904@xtra.co.nz>

On 02/07/13 11:46, Khasro Abdulrahman Ismael wrote:
> Hallo every one
> I have this table and tried to find similarity and dissimilarity index in r by vegan package but I couldn't. I really don't know why I couldn't as I spend a lot of time working on it, so would you be so kind to calculate or give me some advise about my problem?

Another nominee for the "Obtuse Question of the Month" award.

     cheers,

         Rolf Turner

P.S.  I.e. read the <expletive deleted> posting guide.

         R. T.


From dwinsemius at comcast.net  Tue Jul  2 03:56:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 1 Jul 2013 18:56:33 -0700
Subject: [R] Fwd:  functions and matrices
References: <97227B01-4E25-4C3D-836A-158A755125A0@comcast.net>
Message-ID: <C900193D-1B99-46C3-A41C-60A26B852F9B@comcast.net>


With permission I offer this exchange. Rolf and I have different notions of what u %*% v should mean, but the arbiter is obviously the original poster:

Begin forwarded message:

> From: David Winsemius <dwinsemius at comcast.net>
> Subject: Re: [R] functions and matrices
> Date: July 1, 2013 6:21:09 PM PDT
> To: Rolf Turner <rolf.turner at xtra.co.nz>
> 
> 
> On Jul 1, 2013, at 5:09 PM, Rolf Turner wrote:
> 
>> On 02/07/13 11:37, David Winsemius wrote:
>>> On Jul 1, 2013, at 3:32 PM, Rolf Turner wrote:
>>> 
>>>> Basically R does things *numerically* and what you want to do really
>>>> amounts to symbolic manipulation.  Of course R could be cajoled into
>>>> doing it --- see fortune("Yoda") --- but probably only with a great deal of
>>>> effort and code-writing.
>>>> 
>>>> OTOH you could quite easily write a function that would calculate
>>>> det(u%*%v)(x) for any given numerical value of x:
>>>> 
>>>> foo <- function(a,b,x){
>>>>   a1 <- apply(a,c(1,2),function(m,x){m[[1]](x)},x=x)
>>>>   b1 <- apply(b,c(1,2),function(m,x){m[[1]](x)},x=x)
>>>>   det(a1%*%b1)
>>>> }
>>>> 
>>>> Then doing
>>>> 
>>>>   foo(u,v,2)
>>> I would have thought that (u %*% v) would be:
>>> 
>>>      u[1,1]( v[1,1](x) ) + u[1,2]( v[2,1](x) )   u[1,1]( v[1,2](x) ) + u[1,2]( v[2,2](x) )
>>>      u[2,1]( v[1,1](x) ) + u[2,2]( v[2,1](x) )   u[2,1]( v[2,1](x) ) + u[2,2]( v[2,2](x) )
>>> 
>>> (Crossing my fingers that I got the row and column conventions correct for matrix multiplication.)
>>> 
>> <SNIP>
>> 
>> Not quite sure what you're getting at here.  It looks to me that you are
>> calculating the *composition* of the functions rather than their *product*.
> 
> Exactly. That is how I understood successive application of functions embedded in matrices . The symbol used in my differential topology course lo those 40 years ago was an open circle, but I assumed the OP wanted something along those lines to perform a composite mapping:
> 
> compose <- function(u, v, x) matrix( c(
>       u[1,1][[1]]( v[1,1][[1]](x) ) + u[1,2][[1]]( v[2,1][[1]](x) ) ,  
>       u[1,1][[1]]( v[1,2][[1]](x) ) + u[1,2][[1]]( v[2,2][[1]](x) ),
>       u[2,1][[1]]( v[1,1][[1]](x) ) + u[2,2][[1]]( v[2,1][[1]](x) ),  
>       u[2,1][[1]]( v[2,1][[1]](x) ) + u[2,2][[1]]( v[2,2][[1]](x) ) ), 2,2,byrow=TRUE)
> 
> compose(u,v,2)
>     [,1]    [,2]
> [1,]   75    1332
> [2,] 5427 1680128
> 
> (Noting that I may have reversed the roles of u and v.)
> 
>> 
>> I.e. you are taking the (i,j)th entry of "u%*%v" (evaluated at x) to be the
>> sum over k of
>> 
>>       u[i,k](v[k,j](x))
>> 
>> This is not what I understood the OP to want.  I assumed he wanted the
>> product of the function values rather than the composition of the functions,
>> i.e. that he wanted the (i,j)th entry to be the sum over k of
>> 
>>       u[i,k](x) * v[k,j](x)
>> 
>> which is what my function provides.  This seems to me to be the most
>> "reasonable" interpretation, but I could be wrong.
>> 
>> BTW --- you cannot actually do u[i,k](x).  E.g.
>> 
>>   u[1,2](2)
>> 
>> gives "Error: attempt to apply non-function".  One needs to do u[1,2][[1]](2)
>> (which gives 4, as it should).
> 
> Yes. I was playing fast and loose with notation. I didn't think the code would really run as offered.I was a bit surprise that this worked, but I suppose you bear credit (and blame?) for pushing my program closer to completion.
> 
>> v[1,1][[1]]( u[1,1][[1]]( 2 ))
> [1] 11
> 
> Any problem with me copying this to the list?
> 
> 
>> 
>>   cheers,
>> 
>>       Rolf
> 
> Best;
> 
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From gpetris at uark.edu  Tue Jul  2 04:11:02 2013
From: gpetris at uark.edu (Giovanni Petris)
Date: Tue, 2 Jul 2013 02:11:02 +0000
Subject: [R] KalmanForecast (stats)
In-Reply-To: <7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>
References: <2567036.28410.1372418702794.JavaMail.root@blade10.met.hu>,
	<7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>
Message-ID: <A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5B940@ex-mbx2.uark.edu>


Gabriella,

There is no function "KalmanForecast" in package stats, so I am not quite sure about what you are talking about. That said, it may help a review paper that I wrote a couple of years ago about the different packages available in R for state space modeling (Petris & Petrone, State space models in R, Journal of Statistical Software 41, 2011). Another good review paper is Tusell, Kalman filtering in R, JSS 39, 2011.

Hope this helps you to get started.

Best,
Giovanni 

________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of Csima Gabriella [csima.g at met.hu]
Sent: Friday, June 28, 2013 6:27 AM
To: r-help at r-project.org
Subject: [R] KalmanForecast (stats)

Dear List members,

I would like to use the Kalman-filter program for forecasting - namely for postprocessing numerical model results of 2m temperature. I have looked through the help of the Kalman-filtering programs, mainly the KalmanForecast and I have read about the newer packages like KFAS as well.

I always uderstand and use new R programs that first I try out the example(s), it makes me a base for my new program. My problem is that there is no any example (with data that I can run immediately), and I do not understand, or cannot imagine how - e.g. the "mod" - have to be as the input of the program.

Could you send me a simple example of KalmanForecast (with input data) that I can run and can see how it works exactly?

Cheers,
Gabriella



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gpetris at uark.edu  Tue Jul  2 04:24:03 2013
From: gpetris at uark.edu (Giovanni Petris)
Date: Tue, 2 Jul 2013 02:24:03 +0000
Subject: [R] KalmanForecast (stats)
In-Reply-To: <7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>
References: <2567036.28410.1372418702794.JavaMail.root@blade10.met.hu>,
	<7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>
Message-ID: <A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5C988@ex-mbx2.uark.edu>


Oops...

Correction: The function KalmanForecast does exist in package stats.

The references that I gave in my other reply are still valid, though. It is my impression that Kalman filtering facilities in stats are not meant to be used directly by the end user of R, but their main purpose is to serve as workhorses for other model fitting and forecasting functions (e.g., StructTS). 

Best,
Giovanni 

________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of Csima Gabriella [csima.g at met.hu]
Sent: Friday, June 28, 2013 6:27 AM
To: r-help at r-project.org
Subject: [R] KalmanForecast (stats)

Dear List members,

I would like to use the Kalman-filter program for forecasting - namely for postprocessing numerical model results of 2m temperature. I have looked through the help of the Kalman-filtering programs, mainly the KalmanForecast and I have read about the newer packages like KFAS as well.

I always uderstand and use new R programs that first I try out the example(s), it makes me a base for my new program. My problem is that there is no any example (with data that I can run immediately), and I do not understand, or cannot imagine how - e.g. the "mod" - have to be as the input of the program.

Could you send me a simple example of KalmanForecast (with input data) that I can run and can see how it works exactly?

Cheers,
Gabriella



        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hasan.diwan at gmail.com  Tue Jul  2 05:22:05 2013
From: hasan.diwan at gmail.com (Hasan Diwan)
Date: Mon, 1 Jul 2013 20:22:05 -0700
Subject: [R] KalmanForecast (stats)
In-Reply-To: <A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5C988@ex-mbx2.uark.edu>
References: <2567036.28410.1372418702794.JavaMail.root@blade10.met.hu>
	<7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>
	<A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5C988@ex-mbx2.uark.edu>
Message-ID: <CAP+bYWC9hDD11V3kZ2_8aEG+avEsekDOC3M+jPTzZEiFLnw89w@mail.gmail.com>

On 1 July 2013 19:24, Giovanni Petris <gpetris at uark.edu> wrote:
> Could you send me a simple example of KalmanForecast (with input data) that I can run and can see how it works exactly?

There's an explanation of the Kalman Filter available at
http://www.swarthmore.edu/NatSci/echeeve1/Ref/Kalman/ScalarKalman.html
-- I've summarised it below:
The kalman filter is used to reduce the noise in an indirectly
measured signal, s, approximated by the formula -- x[t] = a*x[t-1] +
b*u[t], to which a random amount of white noise is added, making the
equation x[t] = a*x[t-1]+b*u[t] + w[t]. The white noise varies with
time, hence it's a series. Each measure of x[t] brings you closer to
the actual signal. I hope this helps... -- H
-- 
Sent from my mobile device
Envoy? de mon portable


From gunter.berton at gene.com  Tue Jul  2 05:25:27 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 1 Jul 2013 20:25:27 -0700
Subject: [R] KalmanForecast (stats)
In-Reply-To: <A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5C988@ex-mbx2.uark.edu>
References: <2567036.28410.1372418702794.JavaMail.root@blade10.met.hu>
	<7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>
	<A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5C988@ex-mbx2.uark.edu>
Message-ID: <CACk-te0Af8jj7vpqpNHUW0OjAOMFTQZrpodwWeptwvaz8Vc1Dw@mail.gmail.com>

Below...

On Mon, Jul 1, 2013 at 7:24 PM, Giovanni Petris <gpetris at uark.edu> wrote:
>
> Oops...
>
> Correction: The function KalmanForecast does exist in package stats.
>
> The references that I gave in my other reply are still valid, though. It is my impression that Kalman filtering facilities in stats are not meant to be used directly by the end user of R,

... and on what, pray tell, do you base **that**  strange pronouncement??

-- Bert




but their main purpose is to serve as workhorses for other model
fitting and forecasting functions (e.g., StructTS).
>
> Best,
> Giovanni
>
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of Csima Gabriella [csima.g at met.hu]
> Sent: Friday, June 28, 2013 6:27 AM
> To: r-help at r-project.org
> Subject: [R] KalmanForecast (stats)
>
> Dear List members,
>
> I would like to use the Kalman-filter program for forecasting - namely for postprocessing numerical model results of 2m temperature. I have looked through the help of the Kalman-filtering programs, mainly the KalmanForecast and I have read about the newer packages like KFAS as well.
>
> I always uderstand and use new R programs that first I try out the example(s), it makes me a base for my new program. My problem is that there is no any example (with data that I can run immediately), and I do not understand, or cannot imagine how - e.g. the "mod" - have to be as the input of the program.
>
> Could you send me a simple example of KalmanForecast (with input data) that I can run and can see how it works exactly?
>
> Cheers,
> Gabriella
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From bbolker at gmail.com  Tue Jul  2 06:39:59 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 2 Jul 2013 04:39:59 +0000
Subject: [R] subset of factors in a regression
References: <b1b8ff37-2617-4ab7-8b03-3b76d9289c2e@CIO-TNC-HT07.osuad.osu.edu>
Message-ID: <loom.20130702T063339-702@post.gmane.org>

Philip A. Viton <viton.1 <at> osu.edu> writes:

> suppose "state" is a variable in a dataframe containing abbreviations 
> of the US states, as a factor. What I'd like to do is to include 
> dummy variables for a few of the states, (say, CA and MA) among the 
> independent variables in my regression formula. (This would be the 
> equivalent of, creating, eg, ca<-state=="CA") and then including 
> that). I know I can create all the necessary dummy variables by using 
> the "outer" function on the factor and then renaming them 
> appropriately; but is there a solution that's more direct, ie that 
> doesn't involve a lot of new variables?
> 
> Thanks!

  You could use model.matrix(~state-1) and select the columns
you want, e.g.

state <- state.abb; m <- model.matrix(~state-1)
m[,colnames(m) %in% c("stateCA","stateMA")]

 -- but this will actually create a bunch of vectors you
want before throwing them away.

more compactly:

m <- sapply(cstates,"==",state)
storage.mode(m) <- "numeric"
## or m[] <- as.numeric(m)


From canamika at gmail.com  Tue Jul  2 06:31:39 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Tue, 2 Jul 2013 00:31:39 -0400
Subject: [R] Automating the running of MVLN model in R using R2WinBUGS
Message-ID: <CALv--dabmWjpR2_AhKx_+sE3rOEfpmXYLMaWbHwTEDMjp4C08A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/b622a31b/attachment.pl>

From teotjunk at gmail.com  Tue Jul  2 09:49:06 2013
From: teotjunk at gmail.com (Tjun Kiat Teo)
Date: Tue, 2 Jul 2013 15:49:06 +0800
Subject: [R] Generalized Cholesky Inverse
In-Reply-To: <CAAcyNCz0cYcypT3bgxpOb53KRx4kFQq1a2fWQae6tT5mW7xYrg@mail.gmail.com>
References: <CAH=5_TXdXUY9w66WtKGvo1pNtzdjzoqX09y26ecpNAgfRzb=mg@mail.gmail.com>
	<CAAcyNCz0cYcypT3bgxpOb53KRx4kFQq1a2fWQae6tT5mW7xYrg@mail.gmail.com>
Message-ID: <CAH=5_TW1aQmbxUYFyMvKdRGSmcAQAMQaqVJkPBqiAmM7LYka0A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/b77b3152/attachment.pl>

From eddieatr at gmail.com  Tue Jul  2 10:25:58 2013
From: eddieatr at gmail.com (Eddie Smith)
Date: Tue, 2 Jul 2013 09:25:58 +0100
Subject: [R] Cross validation in R
Message-ID: <CABaJH78x0K93hQZKqchxT84fqKfG1AaEy4jRQWxyN+21_o2VSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/f0f0d794/attachment.pl>

From kridox at ymail.com  Tue Jul  2 10:51:05 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 2 Jul 2013 17:51:05 +0900
Subject: [R] Generalized Cholesky Inverse
In-Reply-To: <CAH=5_TW1aQmbxUYFyMvKdRGSmcAQAMQaqVJkPBqiAmM7LYka0A@mail.gmail.com>
References: <CAH=5_TXdXUY9w66WtKGvo1pNtzdjzoqX09y26ecpNAgfRzb=mg@mail.gmail.com>
	<CAAcyNCz0cYcypT3bgxpOb53KRx4kFQq1a2fWQae6tT5mW7xYrg@mail.gmail.com>
	<CAH=5_TW1aQmbxUYFyMvKdRGSmcAQAMQaqVJkPBqiAmM7LYka0A@mail.gmail.com>
Message-ID: <CAAcyNCzHJTdfahFsfbLsXJrRrpCmPR_64cd9zaswmyOo9axo6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/3b45a94d/attachment.pl>

From S.Ellison at lgcgroup.com  Tue Jul  2 11:28:13 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 2 Jul 2013 10:28:13 +0100
Subject: [R] Optimum of lm
In-Reply-To: <1372713206484-4670674.post@n4.nabble.com>
References: <1372713206484-4670674.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9F86724@GOLD.corp.lgc-group.com>

 
>           I am trying to do some D o E. I would like to find 
> the optima
> (maxima) of a 2 dimensional lm with quadratic terms.
> I'm sure there is a really simple solution but i can't find it.
At least part of this problem is solved by the rsm package; that fits a quadratic response surface and provides the location of the maximum together with some diagnostics.

Steve Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From jvadams at usgs.gov  Tue Jul  2 14:30:37 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 2 Jul 2013 07:30:37 -0500
Subject: [R] Cross validation in R
In-Reply-To: <CABaJH78x0K93hQZKqchxT84fqKfG1AaEy4jRQWxyN+21_o2VSA@mail.gmail.com>
References: <CABaJH78x0K93hQZKqchxT84fqKfG1AaEy4jRQWxyN+21_o2VSA@mail.gmail.com>
Message-ID: <CAN5YmCHdXTp27ojqWy7WjO8GbiO5hPEuAX5rt8DyNGBN4xmhDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/eb02c0f4/attachment.pl>

From jeremy.ng.wk1990 at gmail.com  Tue Jul  2 14:31:37 2013
From: jeremy.ng.wk1990 at gmail.com (Jeremy Ng)
Date: Tue, 2 Jul 2013 20:31:37 +0800
Subject: [R] Replacing strings to numbers
Message-ID: <CAL93JYvf0zpN1_RuMx5NqPEAyj_Ggxk1Kr42Kpy5_wff9zrcmA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/3d168225/attachment.pl>

From jvadams at usgs.gov  Tue Jul  2 14:47:20 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 2 Jul 2013 07:47:20 -0500
Subject: [R] Comparing each level of a factor to the global mean
In-Reply-To: <CADX6M3qZFSAQ0nAypJnzMUtQ0jfDGmPdvHcoEbeFSy6KK1=COg@mail.gmail.com>
References: <CADX6M3rzg9ryM62eRLzci8WtfXLPcxMMa_yV_QEc3Q7C1d9j7A@mail.gmail.com>
	<CAN5YmCHK0-txj28HOiP8SwjjRGZPTZ47yDezP25HsR=pq4h4pA@mail.gmail.com>
	<CADX6M3qZFSAQ0nAypJnzMUtQ0jfDGmPdvHcoEbeFSy6KK1=COg@mail.gmail.com>
Message-ID: <CAN5YmCGn-Vh=bx8csfGnyXyqN+PsEX8Q3PaHMFwEZWuicOntsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/91094c85/attachment.pl>

From algerant at gmail.com  Tue Jul  2 12:31:26 2013
From: algerant at gmail.com (Bembi Prima)
Date: Tue, 2 Jul 2013 17:31:26 +0700
Subject: [R] Word occurrence rate in a tweet
Message-ID: <CAC5DFuBuuSvbtiSxC7ufcn5x3DN=hOgPVyPXmLPzoN=XtsK8Lw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/bb3c9f69/attachment.pl>

From benedettigoe at gmail.com  Tue Jul  2 09:58:14 2013
From: benedettigoe at gmail.com (giulia benedetti)
Date: Tue, 2 Jul 2013 09:58:14 +0200
Subject: [R] ComBat: Error in solve.default(t(des) %*% des) : Lapack routine
 dgesv: system is exactly singular
Message-ID: <CAGWMiy9Hd6EV4zcWyFf7xSf6E0rqajqwqkr0mPQZN-=ROh-5Ew@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/1d272548/attachment.pl>

From jamilnaser79 at gmail.com  Tue Jul  2 11:40:15 2013
From: jamilnaser79 at gmail.com (Naser Jamil)
Date: Tue, 2 Jul 2013 10:40:15 +0100
Subject: [R] functions and matrices
In-Reply-To: <C900193D-1B99-46C3-A41C-60A26B852F9B@comcast.net>
References: <97227B01-4E25-4C3D-836A-158A755125A0@comcast.net>
	<C900193D-1B99-46C3-A41C-60A26B852F9B@comcast.net>
Message-ID: <CAJK=5YnCXnFnw2n9VCdv9nw5zs5oTLzCck-6Si=r_ph0q_moQQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/63729cb6/attachment.pl>

From laurent.franckx at vito.be  Tue Jul  2 10:59:41 2013
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Tue, 2 Jul 2013 08:59:41 +0000
Subject: [R] passing of longitude and lattitude arguments to read URL in
 Google Maps and extract routes
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF870DA11D64@vitomail4.vito.local>

Dear all

I try to use Google Maps to calculate travel times per transit between an origin an destination.

The guidelines for the search can be found at: https://developers.google.com/maps/documentation/directions/#TravelModes

When I submit the latitude and the longitude of the origin and destination as literals, things work fine.

For instance, the following code executes correctly and we obtain the distance and trip duration (the output of the search is in JSON format and is converted to an R object with fromJSON)

        library(rjson)
        library(gooJSON)
        route <- url('http://maps.googleapis.com/maps/api/directions/json?                                      origin=51.13854,4.384575&destination=51.13156,4.387118&region=be&sensor=false&mode=transit&departure_time=1372665319')
        route_file  <- file("route_file.json")
        L <- readLines(route,-1)
        writeLines(L, route_file)
        close(route)
        routesR_zone1_to_zone20 <- fromJSON( file = route_file )
        routesR_zone1_to_zone20$routes[[1]][[3]][[1]]$distance$value/1000
        routesR_zone1_to_zone20$routes[[1]][[3]][[1]]$duration$value/60


However, what I am really interested in is to repeat this operation for thousands of origin-destination pairs. The longitude and the latitude of the origins and destinations then become variables.

For instance:

        > lat_or
        [1] 51.13854
        > long_or
        [1] 4.384575
        > lat_des
        [1] 51.13156
        > long_des
        [1] 4.387118
        > route <- url('http://maps.googleapis.com/maps/api/directions/json?            origin=lat_or,long_or&destination=lat_des,long_des&region=be&sensor=false&mode=transit&departure_time=1372665319')
        > route_file  <- file("route_file.json")
        > L <- readLines(route,-1)
        > writeLines(L, route_file)
        > close(route)
        > routesR_zone1_to_zone20 <- fromJSON( file = route_file )
        > routesR_zone1_to_zone20
        $routes
        list()

        $status
        [1] "NOT_FOUND"

Thus, although the coordinates are the same as in the previous example, this time, no route is found.

I suppose that the problem is that, when the url is accessed, lat_or etc are not "translated" in the corresponding numeric values, and that Google tries to calculate the route between the literals " lat_or,long_or" and " lat_des,long_des".

Does anyone have a suggestion on how to circumvent the problem?




Laurent Franckx, PhD
VITO NV
Boeretang 200, 2400 MOL, Belgium
Tel. + 32 14 33 58 22
Skype: laurent.franckx
laurent.franckx at vito.be
Visit our website: www.vito.be/english and http://www.vito.be/transport











[http://www.vito.be/e-maildisclaimer/vito.png]


Ontdek hoe VITO de transitie naar een duurzame maatschappij op gang trekt: www.vito.be/duurzaamheidsverslag2012<http://www.vito.be/duurzaamheidsverslag2012>
Discover how VITO initiates the transition towards a sustainable society: www.vito.be/sustainabilityreport2012<http://www.vito.be/sustainabilityreport2012>


VITO Disclaimer: http://www.vito.be/e-maildisclaimer


From ripley at stats.ox.ac.uk  Tue Jul  2 15:24:44 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 02 Jul 2013 14:24:44 +0100
Subject: [R] Replacing strings to numbers
In-Reply-To: <CAL93JYvf0zpN1_RuMx5NqPEAyj_Ggxk1Kr42Kpy5_wff9zrcmA@mail.gmail.com>
References: <CAL93JYvf0zpN1_RuMx5NqPEAyj_Ggxk1Kr42Kpy5_wff9zrcmA@mail.gmail.com>
Message-ID: <51D2D49C.2010901@stats.ox.ac.uk>

On 02/07/2013 13:31, Jeremy Ng wrote:
> Hi guys,
>
> I was wondering if any one is able to help me on a problem that I was stuck
> with for a long time. It involves the replacement of character strings with
> numbers. The character string can take on only 3 possible values, for
> instance:
>
> AA
> AT
> TT
>
> I would want R to replace AT with 0. Between AA and TT, I want to compare
> the frequency of either value, and then for the one which occurs more, I
> want it to be replaced with 1, and the other with -1. So using the same
> example, say, I have
>
> AA - 50
> AT-34
> TT- 57
>
> I would want R to substitute it in this way:
> AA= -1
> AT=0
> TT = 1
>
> The strings are not necessarily AA,AT, or TT.

If not, how are we to know which one is to be replaced by 0?  And does 
'more' mean 'greater than' or 'greater than or equal to'?

Adapt the following depending on your answers

 > set.seed(1)
 > x <- sample(c(rep("AA", 2), "AT", rep("TT", 3)))
 > fr <- table(x)
 > recode <- if(fr[1] < fr[3]) c(-1, 0, 1) else c(1, 0, -1)  # or <=
 > x
[1] "AA" "TT" "AT" "TT" "AA" "TT"
 > recode[match(x, names(fr))]  # or however the strings are arranged.
[1] -1  1  0  1 -1  1


>
> Any ideas?
>
> Thanks!
> Jeremy
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From paquiydeleite at hotmail.com  Tue Jul  2 12:00:55 2013
From: paquiydeleite at hotmail.com (Paqui GG)
Date: Tue, 2 Jul 2013 10:00:55 +0000
Subject: [R] Linear mixed effect model doubt:
Message-ID: <DUB115-W1383F8578BAAEEEA4FED86BBA720@phx.gbl>

We have a doubt on whether we are applying a lme model correctly.



Our experimental/sampling design is as follows:



We are studying the relationship between two quantitative and continuous

variables at different sampling stations along a transect in the ocean. At each

station, we take three water samples (fReplica) and we experimentally measured

the dependent variable (Var1) for three different values of the independent one

(Var2). So, for each station (fstation) we have 3 replicates with 3 paired

observations of Var1 and Var2 each (this is all that was logistically possible).

Our data frame looks like:



Var1,Var2,fstation,fReplica

0.9 ,0.2,1,1

1.9 ,0.4,1,1

10.9,0.6,1,1

0.5, 0.3,1,2

0.9, 0.5,1,2

20.1,0.7,1,2

0.2, 0.1,1,3

1.3, 0.6,1,3???

40.1,0.9,1,3

... (for 32 stations)



We want to test whether the slopes and intercepts of the relationship between

Var1 and Var2 vary between stations.



We have been studying how to make a correct test. We believe our design is

similarly to the model that Zuur et al 2009 apply to an example of Zuur et al

2007. In their case, they used species richness as dependent variable and NAP

(the height of a sampling station compared to mean tidal level) as the

independent one. This variables were measured for nine beaches and 5 replicates

were taken for each beach. The main difference Zuur et al and our study is that

they have one point per replica and we have a "regression" of 3 points per replica.





We are applying this model to our data:



## Mlme <- lme(Var1~Var2, random=~1|fstation/fReplica ,data=Data)

## summary(Mlme)





but we are not sure if we are doing the correct test.

Any help or pointers to bibliography with similar analysis will be much appreciated. 		 	   		  

From robbie.weterings at gmail.com  Tue Jul  2 14:01:55 2013
From: robbie.weterings at gmail.com (Robbie Weterings)
Date: Tue, 2 Jul 2013 19:01:55 +0700
Subject: [R] Non-linear modelling with several variables including a
	categorical variable
Message-ID: <CAFe5dHZRM+BpG1v77EzHun+tacV64J_9pnSFGh_xne5CSZ9qdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/421899a7/attachment.pl>

From s.sadozai16 at gmail.com  Tue Jul  2 11:19:56 2013
From: s.sadozai16 at gmail.com (sara sadozai)
Date: Tue, 2 Jul 2013 11:19:56 +0200
Subject: [R] Help with heatmap & hclust
Message-ID: <CAJ0K_2XiTXD+YWQ__zx-SoY0nsLyuoMQN5YSKEOMFb80jZNwvA@mail.gmail.com>

hello i have a problem since days with the heatmap function and my own
cluster function...

i try to put it like this but it is not working :

heatmap(data, hclustfun=function(x)myclust(x))

where myclust is a simple fonction

myclust= function(data){

#D=dist(data)
hc=hclust(D)

#mclust= as.mclust(hc$merge)
#m=reorder.mclust(data)

mc=hc
mc$order=leaf

return(mc=mc)

}


and it returns Error in heatmap(data, hclustfun = function(x) myclust(x)) :
  column dendrogram ordering gave index of wrong length


Actually it is working with other cluster fonction like diana() or
pam() but not with my own function...

Any help ???


From smartpink111 at yahoo.com  Tue Jul  2 15:02:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 2 Jul 2013 06:02:46 -0700 (PDT)
Subject: [R] Replacing strings to numbers
In-Reply-To: <CAL93JYvf0zpN1_RuMx5NqPEAyj_Ggxk1Kr42Kpy5_wff9zrcmA@mail.gmail.com>
References: <CAL93JYvf0zpN1_RuMx5NqPEAyj_Ggxk1Kr42Kpy5_wff9zrcmA@mail.gmail.com>
Message-ID: <1372770166.63631.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

Not sure how your data looks like.? May be this helps.
dat1<- read.table(text="
col1
AA-50
AT-34
TT-57
TT-45
TA-42
",sep="",header=TRUE,stringsAsFactors=FALSE)
vec1<-gsub("\\-.*","",dat1[,1])

vec2<- ifelse(vec1=="AA",-1,ifelse(vec1=="AT",0, ifelse(vec1=="TT",1,NA)))
library(stringr)
?abs(vec2-as.numeric(unlist( str_extract_all(dat1[,1],"[0-9]+"))))
#[1] 51 34 56 44 NA
A.K.





----- Original Message -----
From: Jeremy Ng <jeremy.ng.wk1990 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, July 2, 2013 8:31 AM
Subject: [R] Replacing strings to numbers

Hi guys,

I was wondering if any one is able to help me on a problem that I was stuck
with for a long time. It involves the replacement of character strings with
numbers. The character string can take on only 3 possible values, for
instance:

AA
AT
TT

I would want R to replace AT with 0. Between AA and TT, I want to compare
the frequency of either value, and then for the one which occurs more, I
want it to be replaced with 1, and the other with -1. So using the same
example, say, I have

AA - 50
AT-34
TT- 57

I would want R to substitute it in this way:
AA= -1
AT=0
TT = 1

The strings are not necessarily AA,AT, or TT.

Any ideas?

Thanks!
Jeremy

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From vigibos at eio.upv.es  Tue Jul  2 11:31:31 2013
From: vigibos at eio.upv.es (Vicent Giner-Bosch)
Date: Tue, 2 Jul 2013 11:31:31 +0200
Subject: [R] Recursive partitioning on censored data
Message-ID: <CAHfSo7ia8kdaB3LTm8mDU4FCUe-u8FScbqZw8gbok+enV+kxLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/6f3e2223/attachment.pl>

From toates19 at gmail.com  Tue Jul  2 15:29:19 2013
From: toates19 at gmail.com (Tom Oates)
Date: Tue, 2 Jul 2013 14:29:19 +0100
Subject: [R] Multiple Comparison Kruskal-Wallis Test on a dataframe
Message-ID: <CAGUdn1AEpdq5WmZHsbu=8SQCZDfnsqCfX+4dNnsNM-wi_P5Esg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/b3259944/attachment.pl>

From Achim.Zeileis at uibk.ac.at  Tue Jul  2 15:34:35 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Tue, 2 Jul 2013 15:34:35 +0200 (CEST)
Subject: [R] Recursive partitioning on censored data
In-Reply-To: <CAHfSo7ia8kdaB3LTm8mDU4FCUe-u8FScbqZw8gbok+enV+kxLg@mail.gmail.com>
References: <CAHfSo7ia8kdaB3LTm8mDU4FCUe-u8FScbqZw8gbok+enV+kxLg@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1307021534050.25939@paninaro.uibk.ac.at>

On Tue, 2 Jul 2013, Vicent Giner-Bosch wrote:

> I am interested in applying a "classification tree" analysis where the
> response variable is a censored variable (survival data).
>
> I've discovered the package 'party' through this page:
> http://www.statmethods.net/advstats/cart.html. However, as my sample is not
> very big I would like to apply 'bootstrap' and use 'random forests', but
> with my censored response variable.
>
> Are there any packages for that??

cforest() in the same package. See citation("party") for the corresponding 
references.

Best,
Z

> Looking forward to your answer,
>
>
> --
> vicent
> @vginer_upv
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From naik.raghu at gmail.com  Tue Jul  2 15:42:13 2013
From: naik.raghu at gmail.com (Raghu Naik)
Date: Tue, 2 Jul 2013 09:42:13 -0400
Subject: [R] Creating DAGS with plate notation in R
Message-ID: <CAPZcNLYCvAdJ+ymBEMuem59SvmwbeByuTLC2Ur_S4yvMkPpt1Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/7c3ccc87/attachment.pl>

From gpetris at uark.edu  Tue Jul  2 15:50:16 2013
From: gpetris at uark.edu (Giovanni Petris)
Date: Tue, 2 Jul 2013 13:50:16 +0000
Subject: [R] KalmanForecast (stats)
In-Reply-To: <CACk-te0Af8jj7vpqpNHUW0OjAOMFTQZrpodwWeptwvaz8Vc1Dw@mail.gmail.com>
References: <2567036.28410.1372418702794.JavaMail.root@blade10.met.hu>
	<7894370.28427.1372418849775.JavaMail.root@blade10.met.hu>
	<A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5C988@ex-mbx2.uark.edu>,
	<CACk-te0Af8jj7vpqpNHUW0OjAOMFTQZrpodwWeptwvaz8Vc1Dw@mail.gmail.com>
Message-ID: <A1F1A2DDE4BBE14F8DD8B25666C9D5A024B5CA7A@ex-mbx2.uark.edu>


If you read the 'Warning' section of the help page for KalmanLike, it explicitely says that

begin quote

     These functions are designed to be called from other functions
     which check the validity of the arguments passed, so very little
     checking is done.

end quote

So, (1) these functions are not intended to be used directly and, (2) writing other functions to call them after checking the validity of the arguments is _probably_ not something the typical/average R end user would be comfortable with. Of course, (2) just reflects my perception of the larger R users community.

Best,
Giovanni
 
________________________________________
From: Bert Gunter [gunter.berton at gene.com]
Sent: Monday, July 01, 2013 10:25 PM
To: Giovanni Petris
Cc: Csima Gabriella; r-help at r-project.org
Subject: Re: [R] KalmanForecast (stats)

Below...

On Mon, Jul 1, 2013 at 7:24 PM, Giovanni Petris <gpetris at uark.edu> wrote:
>
> Oops...
>
> Correction: The function KalmanForecast does exist in package stats.
>
> The references that I gave in my other reply are still valid, though. It is my impression that Kalman filtering facilities in stats are not meant to be used directly by the end user of R,

... and on what, pray tell, do you base **that**  strange pronouncement??

-- Bert




but their main purpose is to serve as workhorses for other model
fitting and forecasting functions (e.g., StructTS).
>
> Best,
> Giovanni
>
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] on behalf of Csima Gabriella [csima.g at met.hu]
> Sent: Friday, June 28, 2013 6:27 AM
> To: r-help at r-project.org
> Subject: [R] KalmanForecast (stats)
>
> Dear List members,
>
> I would like to use the Kalman-filter program for forecasting - namely for postprocessing numerical model results of 2m temperature. I have looked through the help of the Kalman-filtering programs, mainly the KalmanForecast and I have read about the newer packages like KFAS as well.
>
> I always uderstand and use new R programs that first I try out the example(s), it makes me a base for my new program. My problem is that there is no any example (with data that I can run immediately), and I do not understand, or cannot imagine how - e.g. the "mod" - have to be as the input of the program.
>
> Could you send me a simple example of KalmanForecast (with input data) that I can run and can see how it works exactly?
>
> Cheers,
> Gabriella
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



--

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dwinsemius at comcast.net  Tue Jul  2 15:55:54 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Jul 2013 06:55:54 -0700
Subject: [R] passing of longitude and lattitude arguments to read URL in
	Google Maps and extract routes
In-Reply-To: <3FA7C532AA08284AB2ACA7B0AB56EF870DA11D64@vitomail4.vito.local>
References: <3FA7C532AA08284AB2ACA7B0AB56EF870DA11D64@vitomail4.vito.local>
Message-ID: <1C64B918-99F3-48BA-A46C-297CBA438072@comcast.net>


On Jul 2, 2013, at 1:59 AM, Franckx Laurent wrote:

> Dear all
> 
> I try to use Google Maps to calculate travel times per transit between an origin an destination.
> 
> The guidelines for the search can be found at: https://developers.google.com/maps/documentation/directions/#TravelModes
> 
> When I submit the latitude and the longitude of the origin and destination as literals, things work fine.
> 
> For instance, the following code executes correctly and we obtain the distance and trip duration (the output of the search is in JSON format and is converted to an R object with fromJSON)
> 
>        library(rjson)
>        library(gooJSON)
>        route <- url('http://maps.googleapis.com/maps/api/directions/json?                                      origin=51.13854,4.384575&destination=51.13156,4.387118&region=be&sensor=false&mode=transit&departure_time=1372665319')
>        route_file  <- file("route_file.json")
>        L <- readLines(route,-1)
>        writeLines(L, route_file)
>        close(route)
>        routesR_zone1_to_zone20 <- fromJSON( file = route_file )
>        routesR_zone1_to_zone20$routes[[1]][[3]][[1]]$distance$value/1000
>        routesR_zone1_to_zone20$routes[[1]][[3]][[1]]$duration$value/60
> 
> 
> However, what I am really interested in is to repeat this operation for thousands of origin-destination pairs. The longitude and the latitude of the origins and destinations then become variables.
> 
> For instance:
> 
>> lat_or
>        [1] 51.13854
>> long_or
>        [1] 4.384575
>> lat_des
>        [1] 51.13156
>> long_des
>        [1] 4.387118
>> route <- url('http://maps.googleapis.com/maps/api/directions/json?            origin=lat_or,long_or&destination=lat_des,long_des&region=be&sensor=false&mode=transit&departure_time=1372665319')
>> route_file  <- file("route_file.json")
>> L <- readLines(route,-1)
>> writeLines(L, route_file)
>> close(route)
>> routesR_zone1_to_zone20 <- fromJSON( file = route_file )
>> routesR_zone1_to_zone20
>        $routes
>        list()
> 
>        $status
>        [1] "NOT_FOUND"
> 
> Thus, although the coordinates are the same as in the previous example, this time, no route is found.
> 
> I suppose that the problem is that, when the url is accessed, lat_or etc are not "translated" in the corresponding numeric values, and that Google tries to calculate the route between the literals " lat_or,long_or" and " lat_des,long_des".

Yes. That seems likely. R would not interpret a text literal. I don't understand why you are not using the ordinary text handling function 'paste0'.

?paste0

> lat_or <- 51.13854
long_or <- 4.384575
lat_des <-  51.13156
long_des <- 4.387118

> paste0("origin=",lat_or,",",long_or,"&destination=",lat_des,",",long_des) 
[1] "origin=51.13854,4.384575&destination=51.13156,4.387118"


(Also tested on Mac with R 3.0.0 RC using Google JSON Data Interpreter for R, Version: 1.0.01.)

-- 
David.
> 
> Does anyone have a suggestion on how to circumvent the problem?
> 
> 
> 
> 
> Laurent Franckx, PhD
> VITO NV
> Boeretang 200, 2400 MOL, Belgium
> 
-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Jul  2 16:01:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Jul 2013 07:01:07 -0700
Subject: [R] subset of factors in a regression
In-Reply-To: <loom.20130702T063339-702@post.gmane.org>
References: <b1b8ff37-2617-4ab7-8b03-3b76d9289c2e@CIO-TNC-HT07.osuad.osu.edu>
	<loom.20130702T063339-702@post.gmane.org>
Message-ID: <1F213C6C-F634-4340-B263-65E42E82AAE6@comcast.net>


On Jul 1, 2013, at 9:39 PM, Ben Bolker wrote:

> Philip A. Viton <viton.1 <at> osu.edu> writes:
> 
>> suppose "state" is a variable in a dataframe containing abbreviations 
>> of the US states, as a factor. What I'd like to do is to include 
>> dummy variables for a few of the states, (say, CA and MA) among the 
>> independent variables in my regression formula. (This would be the 
>> equivalent of, creating, eg, ca<-state=="CA") and then including 
>> that). I know I can create all the necessary dummy variables by using 
>> the "outer" function on the factor and then renaming them 
>> appropriately; but is there a solution that's more direct, ie that 
>> doesn't involve a lot of new variables?
>> 
>> Thanks!
> 
>  You could use model.matrix(~state-1) and select the columns
> you want, e.g.
> 
> state <- state.abb; m <- model.matrix(~state-1)
> m[,colnames(m) %in% c("stateCA","stateMA")]
> 
> -- but this will actually create a bunch of vectors you
> want before throwing them away.
> 
> more compactly:
> 
> m <- sapply(cstates,"==",state)
> storage.mode(m) <- "numeric"
> ## or m[] <- as.numeric(m)


Couldn't this be achieved with "I"?:

lm(Y ~ I(state=="CA") + I(state=="MA") + covariates, data=dfrm)

-- 
David Winsemius
Alameda, CA, USA


From vigibos at eio.upv.es  Tue Jul  2 16:02:03 2013
From: vigibos at eio.upv.es (Vicent Giner-Bosch)
Date: Tue, 2 Jul 2013 16:02:03 +0200
Subject: [R] Recursive partitioning on censored data
In-Reply-To: <alpine.DEB.2.02.1307021534050.25939@paninaro.uibk.ac.at>
References: <CAHfSo7ia8kdaB3LTm8mDU4FCUe-u8FScbqZw8gbok+enV+kxLg@mail.gmail.com>
	<alpine.DEB.2.02.1307021534050.25939@paninaro.uibk.ac.at>
Message-ID: <CAHfSo7iZCWWdvDV7oeMGBDyGPFtof=NoHNjMgAWxUGVVRQ2sfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/7ad2ba36/attachment.pl>

From mario.lavezzi at unipa.it  Tue Jul  2 16:22:52 2013
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Tue, 2 Jul 2013 16:22:52 +0200
Subject: [R] matching similar character strings
In-Reply-To: <1371828336.16438.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>
	<1371821358.6821.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<51C46C83.4030001@unipa.it>
	<1371828336.16438.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAOZPQW6OG7yO_-ssKa+Axr=CsDrJiEaN7SkaCY9RFPz3tLiRyw@mail.gmail.com>

Dear Arun,
please excuse me for this late reply, we had to stop working on this
temporaririly.

Let me reproduce here two examples of rows from F1 and F2 (sorry, but
with dput() I am not able to produce a clear example)

> F1_ex
        Nome.azienda                   Indirizzo
17     Alterego             Via Edmondo De Amicis, 18

On row 17 of F1 we have a firm named ("Nome.azienda") 'Alterego' whose
address ("indirizzo") is  'Via Edmondo de Amicis, 18'

Below I reproduce the portion of F2 with information on the street
mentioned in F1_ex$Indirizzo.

> F2_ex

  CODICE    STRADA       AREADICIRCOLAZIONE          NUMBER1 BARRATO1
NUMBER2 BARRATO2 SECTION
1  15620        VIA            DE AMICIS EDMONDO                     1
                          5                                 1288
2  15620        VIA            DE AMICIS EDMONDO                     2
                         34                                 1261
3  15620        VIA            DE AMICIS EDMONDO                     7
                         17                                 1287
4  15620        VIA            DE AMICIS EDMONDO                    36
                         62                                1264
5  15620        VIA            DE AMICIS EDMONDO                    37
                         37                                1287
6  15620        VIA            DE AMICIS EDMONDO                    64
                         84                                1262


Line 1 says that the portion of VIA DE AMICIS EDMONDO
("STRADA"+"AREADICIRCOLAZIONE"), with street numbers between 1 and 5
belongs to SECTION 1288 (these are census sections). ("BARRATO1" and
"BARRATO2" refer to the letter in street numbers such as 12/A, 28/D,
etc. In the present example they are empty)

Line 2 says that the portion of VIA DE AMICIS EDMONDO, with street
numbers between 2 and 34 belongs to SECTION 1261,

etc.

Our problem is to assign SECTION 1261 to 'Alterego', exploting the
information on its address. The problem is that the syntax of the
street address in F1 is different from the syntax in F2.

Hope I have clarified the issue

thanks a lot
Mario








On Fri, Jun 21, 2013 at 5:25 PM, arun <smartpink111 at yahoo.com> wrote:
> Dear Mario,
> I didn't find any difference between 1st and 2nd row of F2, except for the last three columns.  Question is that why should F1 1st row should be merged to 2nd row of F2 instead of 1st row of F2. In your previous example, you mentioned about A1, A2, ... and B1, B2, etc.  Here, it is not provided.  As I mentioned before, it is better to provide the output of ?dput() from a subset of dataset.
> dput(head(F1,20))
>
> dput(head(F2,20))
>
> #so that there would be atleast some matching pairs within the example dataset.  Also, please post it to r-help as I will be able to check only after a couple of hours
> Tx.
> Arun
>
>
>
> ----- Original Message -----
> From: Mario Lavezzi <mario.lavezzi at unipa.it>
> To: arun <smartpink111 at yahoo.com>
> Cc:
> Sent: Friday, June 21, 2013 11:08 AM
> Subject: Re: [R] matching similar character strings
>
> dear Arun
> thank you very much. Let me explain the problem:
>
> Imagine that a portion of the row in F1 is:
>
> ----------------------------
> F1
>
> 1) Street | J.F. Kennedy | 30
> ----------------------------
>
> it means that our unit of interest (a firm) has address: J.F. Kennedy Street, 30
>
>
> The F2 database contains the list of all the streets of the city, with additional variables characterizing that street (Census data). The database
> contains sometimes street divided in some parts, according to the street number. For example:
>
>
> Example of three rows of F2 concerning Kennedy street and Kennedy Road:
>
> F2
>
> 1) Street | Kennedy John Fitzgerald  | 1  | 20 | A12
> 2) Street | Kennedy John Fitzgerald  | 20 | 50 | A15
> 3) Road   | Kennedy John             | 1  | 50 | A23
>
>
> We'd like to have an algorithm able to understand that, notwithstanding the name is slightly different, element A15 should be added to row 1) of F1,
> producing an output such as:
>
> 1) Street | J.F. Kennedy | 30 | A15
>
>
> hope this clarifies the issue.
>
> thanks a lot! Mario
>
>
>
> Il 21/06/2013 15:29, arun ha scritto:
>> HI,
>> Could you dput() your example datasets and also your expected result?  The Census section is not clear.
>> A.K.
>>
>>
>>
>>
>> ----- Original Message -----
>> From: A M Lavezzi <mario.lavezzi at unipa.it>
>> To: r-help <r-help at r-project.org>
>> Cc:
>> Sent: Friday, June 21, 2013 5:56 AM
>> Subject: [R] matching similar character strings
>>
>> Hello everybody
>>
>> I have this problem: I need to match an addresses database F1 with the
>> information contained in a toponymic database F2.
>>
>> The format of F1 is given by three columns and 800 rows, with the
>> columns being:
>>
>> A1. Street/Road/Avenue
>> A2. Name
>> A3. Number
>>
>> Consider for instance Avenue J. Kennedy , 3011. In F1 this is:
>>
>> A1. Avenue
>> A2. J. Kennedy
>> A3. 3011
>>
>> The format of F2 file is instead given by 20000 rows and five columns:
>>
>> B1. Street/Road/Avenue
>> B2. Name
>> B3. Starting Street Number
>> B4. Ending Street Number
>> B5. Census section
>>
>> So my problem is attributing the  B5 Census section to every
>> observation of F1 if: A1=B1, A2=B2, and A3 is comprised between B3 and
>> B4.
>>
>> The problem is that while the information in A2 is irregularly
>> recorded, B2 has a given format that is Family name (space) Given
>> name.
>>
>> So I could have that while in B2 the information is:
>>
>> Kennedy John
>>
>> In A2 it could be:
>>
>> John Kennedy
>> JF Kennedy
>> J. Kennedy
>>
>> and so on.
>>
>> Thanks,
>>
>> Mario
>>
>
> --
> PLEASE NOTICE NEW EMAIL ADDRESS AND HOME PAGE URL
>
> Andrea Mario Lavezzi
> Dipartimento di Studi su Politica, Diritto e Societ?
> Universit? di Palermo
> Piazza Bologni 8
> 90134 Palermo, Italy
> tel. ++39 091 23892208
> fax ++39 091 6111268
> skype: lavezzimario
> email: mario.lavezzi (at) unipa.it
> web: http://www.unipa.it/~mario.lavezzi



-- 
Andrea Mario Lavezzi
Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi


From mxkuhn at gmail.com  Tue Jul  2 16:24:49 2013
From: mxkuhn at gmail.com (Max Kuhn)
Date: Tue, 2 Jul 2013 10:24:49 -0400
Subject: [R] Cross validation in R
In-Reply-To: <CABaJH78x0K93hQZKqchxT84fqKfG1AaEy4jRQWxyN+21_o2VSA@mail.gmail.com>
References: <CABaJH78x0K93hQZKqchxT84fqKfG1AaEy4jRQWxyN+21_o2VSA@mail.gmail.com>
Message-ID: <CAJ9CoWmxcj1kBUj8-491Rw3vCjZ2KS2UR7FjTQEA4Uy46pRd9g@mail.gmail.com>

> How do i make a loop so that the process could be repeated several time,
> producing randomly ROC curve and under ROC values?


Using the caret package

http://caret.r-forge.r-project.org/

--

Max


From laurent.franckx at vito.be  Tue Jul  2 16:45:35 2013
From: laurent.franckx at vito.be (Franckx Laurent)
Date: Tue, 2 Jul 2013 14:45:35 +0000
Subject: [R] passing of longitude and lattitude arguments to read URL in
 Google Maps and extract routes
In-Reply-To: <1C64B918-99F3-48BA-A46C-297CBA438072@comcast.net>
References: <3FA7C532AA08284AB2ACA7B0AB56EF870DA11D64@vitomail4.vito.local>
	<1C64B918-99F3-48BA-A46C-297CBA438072@comcast.net>
Message-ID: <3FA7C532AA08284AB2ACA7B0AB56EF870DA1819A@vitomail4.vito.local>

Dear David

Thank you for the suggestion.
The following works fine:

        or_dest <- paste0("origin=",lat_or,",",long_or,"&destination=",lat_des,",",long_des)
        url_to_google <- paste( "http://maps.googleapis.com/maps/api/directions/json?",or_dest,"&sensor=false&mode=transit&departure_time=1372665319",sep="" )
        route <- url(url_to_google)

Problem solved, thus.

-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net]
Sent: dinsdag 2 juli 2013 15:56
To: Franckx Laurent
Cc: 'r-help'
Subject: Re: [R] passing of longitude and lattitude arguments to read URL in Google Maps and extract routes


On Jul 2, 2013, at 1:59 AM, Franckx Laurent wrote:

> Dear all
>
> I try to use Google Maps to calculate travel times per transit between an origin an destination.
>
> The guidelines for the search can be found at:
> https://developers.google.com/maps/documentation/directions/#TravelMod
> es
>
> When I submit the latitude and the longitude of the origin and destination as literals, things work fine.
>
> For instance, the following code executes correctly and we obtain the
> distance and trip duration (the output of the search is in JSON format
> and is converted to an R object with fromJSON)
>
>        library(rjson)
>        library(gooJSON)
>        route <- url('http://maps.googleapis.com/maps/api/directions/json?                                      origin=51.13854,4.384575&destination=51.13156,4.387118&region=be&sensor=false&mode=transit&departure_time=1372665319')
>        route_file  <- file("route_file.json")
>        L <- readLines(route,-1)
>        writeLines(L, route_file)
>        close(route)
>        routesR_zone1_to_zone20 <- fromJSON( file = route_file )
>        routesR_zone1_to_zone20$routes[[1]][[3]][[1]]$distance$value/1000
>        routesR_zone1_to_zone20$routes[[1]][[3]][[1]]$duration$value/60
>
>
> However, what I am really interested in is to repeat this operation for thousands of origin-destination pairs. The longitude and the latitude of the origins and destinations then become variables.
>
> For instance:
>
>> lat_or
>        [1] 51.13854
>> long_or
>        [1] 4.384575
>> lat_des
>        [1] 51.13156
>> long_des
>        [1] 4.387118
>> route <- url('http://maps.googleapis.com/maps/api/directions/json?            origin=lat_or,long_or&destination=lat_des,long_des&region=be&sensor=false&mode=transit&departure_time=1372665319')
>> route_file  <- file("route_file.json") L <- readLines(route,-1)
>> writeLines(L, route_file)
>> close(route)
>> routesR_zone1_to_zone20 <- fromJSON( file = route_file )
>> routesR_zone1_to_zone20
>        $routes
>        list()
>
>        $status
>        [1] "NOT_FOUND"
>
> Thus, although the coordinates are the same as in the previous example, this time, no route is found.
>
> I suppose that the problem is that, when the url is accessed, lat_or etc are not "translated" in the corresponding numeric values, and that Google tries to calculate the route between the literals " lat_or,long_or" and " lat_des,long_des".

Yes. That seems likely. R would not interpret a text literal. I don't understand why you are not using the ordinary text handling function 'paste0'.

?paste0

> lat_or <- 51.13854
long_or <- 4.384575
lat_des <-  51.13156
long_des <- 4.387118

> paste0("origin=",lat_or,",",long_or,"&destination=",lat_des,",",long_d
> es)
[1] "origin=51.13854,4.384575&destination=51.13156,4.387118"


(Also tested on Mac with R 3.0.0 RC using Google JSON Data Interpreter for R, Version: 1.0.01.)

--
David.
>
> Does anyone have a suggestion on how to circumvent the problem?
>
>
>
>
> Laurent Franckx, PhD
> VITO NV
> Boeretang 200, 2400 MOL, Belgium
>
--

David Winsemius
Alameda, CA, USA

[http://www.vito.be/e-maildisclaimer/vito.png]


Ontdek hoe VITO de transitie naar een duurzame maatschappij op gang trekt: www.vito.be/duurzaamheidsverslag2012<http://www.vito.be/duurzaamheidsverslag2012>
Discover how VITO initiates the transition towards a sustainable society: www.vito.be/sustainabilityreport2012<http://www.vito.be/sustainabilityreport2012>


VITO Disclaimer: http://www.vito.be/e-maildisclaimer


From naik.raghu at gmail.com  Tue Jul  2 17:31:47 2013
From: naik.raghu at gmail.com (Raghu Naik)
Date: Tue, 2 Jul 2013 11:31:47 -0400
Subject: [R] Creating DAGS with plate notation in R
In-Reply-To: <CAPZcNLYCvAdJ+ymBEMuem59SvmwbeByuTLC2Ur_S4yvMkPpt1Q@mail.gmail.com>
References: <CAPZcNLYCvAdJ+ymBEMuem59SvmwbeByuTLC2Ur_S4yvMkPpt1Q@mail.gmail.com>
Message-ID: <CAPZcNLbLnK9ipTw6RmHRAymE7Z2wT36i+_5hDGs0UemmOBcZYw@mail.gmail.com>

The image did not come through as pointed out by a list member. I have
attached a pdf image file; the link is
http://stackoverflow.com/questions/3461931/software-to-draw-graphical-models-in-plate-notation
.

Cheers.

Raghu


On Tue, Jul 2, 2013 at 9:42 AM, Raghu Naik <naik.raghu at gmail.com> wrote:

> I am trying to create a directed graph with plate notation (like the one
> shown below) in R.
>
> [image: The output image]
> Could someone direct to me an example code that will get me started.
>
> I could not see any reference to plate notations in igraph, qgraph
> packages though I may be wrong.
>
> The above figure made in graphviz by a poster on stackoverflow.
>
> I am not sure if this can be replicated in Rgraphviz - I was not able to
> get there.
>
> I would appreciate any help.
>
> Thanks.
>
> Raghu
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: graphics - Software to draw graphical models in plate notation - Stack Overflow _2013-07-02_11-23-35.pdf
Type: application/pdf
Size: 6004 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/e39611a5/attachment.pdf>

From tmrsg11 at gmail.com  Tue Jul  2 17:33:38 2013
From: tmrsg11 at gmail.com (C W)
Date: Tue, 2 Jul 2013 11:33:38 -0400
Subject: [R] What package to use to download pictures and its description
	from server?
Message-ID: <CAE2FW2=TZ+ZseR+a3LyM_8vYneCz7d6znEdqJ2BhxykZEYiCSA@mail.gmail.com>

Hi R community,
What package would you recommend to download pictures and descriptions
of the pictures?

I have looked at package XML and RCurl so far.  Is this what everyone uses?

Thanks,
Mike


From dizem.uerek at alumni.fh-aachen.de  Tue Jul  2 18:52:29 2013
From: dizem.uerek at alumni.fh-aachen.de (Dzu)
Date: Tue, 2 Jul 2013 09:52:29 -0700 (PDT)
Subject: [R] Outer function in R
Message-ID: <1372783949258-4670738.post@n4.nabble.com>

Dear members 

I am trying to apply the function kl.dist (Kullback-Leibler Distance
measure) to multiple matrixes.

I tried the following : 

veckldist <- Vectorize(kl.dist)
distancematrix <- outer (matrix1,matrix2, "veckldist")


But the code is complaining that the list of the object does not match. The
lengths of my matrixes are same 

How could I fix the error?

Thanks





--
View this message in context: http://r.789695.n4.nabble.com/Outer-function-in-R-tp4670738.html
Sent from the R help mailing list archive at Nabble.com.


From gocanon at yahoo.com  Tue Jul  2 18:21:01 2013
From: gocanon at yahoo.com (Venkatesh Nagarajan)
Date: Tue, 2 Jul 2013 09:21:01 -0700 (PDT)
Subject: [R] acf question...
Message-ID: <1372782061.37244.YahooMailNeo@web140504.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/0991333e/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Jul  2 19:25:20 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 02 Jul 2013 10:25:20 -0700
Subject: [R] Outer function in R
In-Reply-To: <1372783949258-4670738.post@n4.nabble.com>
References: <1372783949258-4670738.post@n4.nabble.com>
Message-ID: <db64972c-986c-48a9-8077-ae5a0d7318f5@email.android.com>

Read the Posting Guide. The example you provide below is not reproducible [1], so we cannot tell what you're giving to the outer() function.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Dzu <dizem.uerek at alumni.fh-aachen.de> wrote:

>Dear members 
>
>I am trying to apply the function kl.dist (Kullback-Leibler Distance
>measure) to multiple matrixes.
>
>I tried the following : 
>
>veckldist <- Vectorize(kl.dist)
>distancematrix <- outer (matrix1,matrix2, "veckldist")
>
>
>But the code is complaining that the list of the object does not match.
>The
>lengths of my matrixes are same 
>
>How could I fix the error?
>
>Thanks
>
>
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Outer-function-in-R-tp4670738.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From sguallar at yahoo.com  Tue Jul  2 19:47:15 2013
From: sguallar at yahoo.com (Santiago Guallar)
Date: Tue, 2 Jul 2013 10:47:15 -0700 (PDT)
Subject: [R] spped up a function
Message-ID: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>

Hi,

I have written a function to assign the values of a certain variable 'wd' from a dataset to another dataset. Both contain data from the same?time period but differ in the length of their time intervals: 'GPS' has regular 10-minute intervals whereas 'xact' has irregular intervals. I attached simplified text versions from write.table. You can also get a dput of 'xact' in this address: http://www.megafileupload.com/en/file/431569/xact-dput.html).
The original objects are large and the function takes almost one hour to finish.
Here's the function:

fxG= function(xact, GPS){
l <- rep( 'A', nrow(GPS) )
v <- unique(GPS$Ring) # the process is carried out for several individuals identified by 'Ring'
for(k in 1:length(v) ){
I = v[k]
df <- xact[xact$Ring == I,]
for(i in 1:nrow(GPS)){
if(GPS[i,]$Ring== I){# the code runs along the whole data.frame for each i; it'd save time to make it stop with the last record of each i instead
u <- df$timepos <= GPS[i,]$timepos
# fill vector l for each interval t from xact <= each interval from GPS (take the max if there's > 1 interval)
l[i] <- df[max( which(u == TRUE) ),]$wd
}
}
}
return(l)}

vwd <- fxG(xact, GPS)


My question is: how can I speed up (optimize) this function?

Thank you for your help

From dwinsemius at comcast.net  Tue Jul  2 20:24:28 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Jul 2013 11:24:28 -0700
Subject: [R] spped up a function
In-Reply-To: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
Message-ID: <0AAF7102-A731-4E8F-8A6B-4E931191CB09@comcast.net>


On Jul 2, 2013, at 10:47 AM, Santiago Guallar wrote:

> Hi,
> 
> I have written a function to assign the values of a certain variable 'wd' from a dataset to another dataset. Both contain data from the same time period but differ in the length of their time intervals: 'GPS' has regular 10-minute intervals whereas 'xact' has irregular intervals. I attached simplified text versions from write.table. You can also get a dput of 'xact' in this address: http://www.megafileupload.com/en/file/431569/xact-dput.html).
> The original objects are large and the function takes almost one hour to finish.
> Here's the function:
> 
> fxG= function(xact, GPS){
> l <- rep( 'A', nrow(GPS) )
> v <- unique(GPS$Ring) # the process is carried out for several individuals identified by 'Ring'
> for(k in v ){
>    
>    df <- xact[xact$Ring == v,]

Simplified a bit , this is starting to look like a case for the split function:

>    for(i in 1:nrow(GPS)){
>          if(GPS[i,]$Ring== v){# the code runs along the whole data.frame for each i;

                   # After doing the simplification I must ask how GPS[i,]$Ring could not == v ( or I)

                      
> 
>           u <- df$timepos <= GPS[i,]$timepos
>                              # fill vector l for each interval t from xact <= each interval from GPS (take the max if there's > 1 interval)
>           l[i] <- df[max( which(u == TRUE) ),]$wd

                 #perhaps tail(df[which(u), 'wd'],1)?
>                               }
>                         }
>                      }
> return(l)}
> 
This looks like it will be overwriting the l-object with every iteration of 'k'

> vwd <- fxG(xact, GPS)
> 
> 
> My question is: how can I speed up (optimize) this function?

The first thing you should do is describe in natural language what is desired to be done with objects: 'xact' and 'GPS' not yet described .... rather than asking for simplification of obscure nested  for-loops with probably redundant assignments and extraneous conditions. Make a simple example of such objects and repost.

-- 

David Winsemius
Alameda, CA, USA


From jdnewmil at dcn.davis.CA.us  Tue Jul  2 20:59:13 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 02 Jul 2013 11:59:13 -0700
Subject: [R] What package to use to download pictures and its
	description	from server?
In-Reply-To: <CAE2FW2=TZ+ZseR+a3LyM_8vYneCz7d6znEdqJ2BhxykZEYiCSA@mail.gmail.com>
References: <CAE2FW2=TZ+ZseR+a3LyM_8vYneCz7d6znEdqJ2BhxykZEYiCSA@mail.gmail.com>
Message-ID: <637727a0-c9a6-47a8-8282-a7100a3f2a05@email.android.com>

Wouldn't this be highly dependent on how the pictures and descriptions were formatted online, as well as what you planned to do with them? I generally find that a web browser is quite sufficient for my needs.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

C W <tmrsg11 at gmail.com> wrote:

>Hi R community,
>What package would you recommend to download pictures and descriptions
>of the pictures?
>
>I have looked at package XML and RCurl so far.  Is this what everyone
>uses?
>
>Thanks,
>Mike
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From lucianolasala at yahoo.com.ar  Tue Jul  2 21:21:07 2013
From: lucianolasala at yahoo.com.ar (Luciano La Sala)
Date: Tue, 2 Jul 2013 16:21:07 -0300
Subject: [R] Multinomial model and p-values
Message-ID: <002e01ce7759$4f289f20$ed79dd60$@com.ar>

Hello everyone, 

I have a dataset which consists of "Pathology scores" (Absent, Mild, Severe)
as outcome variable, and two main effects: Age (two factors: twenty / thirty
days old) and Treatment Group (four factors: infected without ATB; infected
+ ATB1; infected + ATB2; infected + ATB3).

First I tried to fit an ordinal regression model, which seems more
appropriate given the characteristics of my dependent variable (ordinal).
However, the assumption of odds proportionality was severely violated
(graphically), which prompted me to use a multinomial model instead, using
the "nnet" package.  


First I chose the outcome level that I need to use as baseline category: 

Data$Path <- relevel(Data$Path, ref = "Absent")

Then, I needed to set baseline categories for the independent variables:

Data$Age <- relevel(Data$Age, ref = "Twenty") 
Data$Treat <- relevel(Data$Treat, ref = "infected without ATB") 

The model:

test <- multinom(Path ~ Treat + Age, data = Data)
# weights:  18 (10 variable)
initial  value 128.537638 
iter  10 value 80.623608
final  value 80.619911 
converged

> summary1 <- summary(test1)
> summary1

Call:
multinom(formula = Jej_fact ~ Treat + Age, data = Data)

Coefficients:
         (Intercept)   infected+ATB1   infected+ATB2   infected+ATB3
AgeThirty
Moderate   -2.238106   -1.1738540      -1.709608       -1.599301
2.684677
Severe     -1.544361   -0.8696531      -2.991307       -1.506709
1.810771

Std. Errors:
         (Intercept)    infected+ATB1   infected+ATB2   infected+ATB3
AgeThirty
Moderate   0.7880046    0.8430368       0.7731359       0.7718480
0.8150993
Severe     0.6110903    0.7574311       1.1486203       0.7504781
0.6607360

Residual Deviance: 161.2398 
AIC: 181.2398

For a while, I could not find a way to get the p-values for the model and
estimates when using nnet:multinom. Yesterday I came across a post where the
author put forward a similar issue regarding estimation of p-values for
coefficients
(http://stats.stackexchange.com/questions/9715/how-to-set-up-and-estimate-a-
multinomial-logit-model-in-r).

There, one blogger suggested that getting p-values from the summary() result
of multinom() is pretty easy, by first getting the t values as follows: 

pt(abs(summary1$coefficients / summary1$standard.errors), df=nrow(Data)-10,
lower=FALSE) 

         (Intercept)   infected+ATB1   infected+ATB2   infected+ATB3
AgeThirty
Moderate 0.002670340   0.08325396      0.014506395     0.02025858
0.0006587898
Severe   0.006433581   0.12665278      0.005216581     0.02352202
0.0035612114

I AM NOT a statistician, so don't be baffled by a silly question! I this
procedure correct?  

Cheers for now, 

Luciano


From k.askland at gmail.com  Tue Jul  2 22:46:59 2013
From: k.askland at gmail.com (kathleen askland)
Date: Tue, 2 Jul 2013 16:46:59 -0400
Subject: [R] Recoding variables based on reference values in data frame
Message-ID: <CAFpPP=zzXSSAUhZv36K5Qg7jFVyqHaY6LHWFQWPSb97MtfWNDQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130702/0b95cd95/attachment.pl>

From ruipbarradas at sapo.pt  Tue Jul  2 23:15:20 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 02 Jul 2013 22:15:20 +0100
Subject: [R] Recoding variables based on reference values in data frame
In-Reply-To: <CAFpPP=zzXSSAUhZv36K5Qg7jFVyqHaY6LHWFQWPSb97MtfWNDQ@mail.gmail.com>
References: <CAFpPP=zzXSSAUhZv36K5Qg7jFVyqHaY6LHWFQWPSb97MtfWNDQ@mail.gmail.com>
Message-ID: <51D342E8.2090002@sapo.pt>

Hello,

I'm not sure I understood, but try the following.


Kgeno <- read.table(text = "
SNP_ID SNP1 SNP2 SNP3 SNP4
Maj_Allele C G  C  A
Min_Allele T A T G
ID1 CC     GG     CT     AA
ID2 CC     GG     CC AA
ID3 CC     GG    nc    AA
ID4 _ _ _ _
ID5 CC     GG     CC     AA
ID6 CC     GG     CC     AA
ID7 CC     GG     CT     AA
ID8 _ _ _ _
ID9 CT     GG     CC AG
ID10 CC     GG     CC     AA
ID11 CC     GG     CT     AA
ID12 _ _ _ _
ID13 CC     GG     CC     AA
", header = TRUE, stringsAsFactors = FALSE)

dat

fun <- function(x){
	x[x %in% c("nc", "_")] <- NA
	MM <- paste0(x[1], x[1])  # Major Major
	Mm <- paste0(x[1], x[2])  # Major minor
	mm <- paste0(x[2], x[2])  # minor minor
	x[x == MM] <- 0
	x[x == Mm] <- 1
	x[x == mm] <- 2
	x
}

Kgeno[, -1] <- sapply(Kgeno[, -1], fun)
Kgeno


Also, the best way to post data is by using ?dput.

dput(head(Kgeno[, 1:5], 30))  # post the output of this


Hope this helps,

Rui Barradas

Em 02-07-2013 21:46, kathleen askland escreveu:
> I'm new to R (previously used SAS primarily) and I have a genetics data
> frame consisting of genotypes for each of 300+ subjects (ID1, ID2, ID3,
> ...) at 3000+ genetic locations (SNP1, SNP2, SNP3...). A small subset of
> the data is shown below:
>    SNP_ID SNP1 SNP2 SNP3 SNP4  Maj_Allele C G  C  A  Min_Allele T A T G  ID1
> CC     GG     CT     AA      ID2 CC     GG     CC AA      ID3 CC     GG
> nc
> AA      ID4 _ _ _ _  ID5 CC     GG     CC     AA      ID6 CC     GG     CC
>       AA      ID7 CC     GG     CT     AA      ID8 _ _ _ _  ID9 CT     GG
> CC AG      ID10 CC     GG     CC     AA      ID11 CC     GG     CT     AA
>        ID12 _ _ _ _  ID13 CC     GG     CC     AA
> The name of the data file is Kgeno.
> What I would like to do is recode all of the genotype values to standard
> integer notation, based on their values relative to the reference rows
> (Maj_Allele and Min_Allele). Standard notation sums the total of minor
> alleles in the genotype, so values can be 0, 1 or 2.
>
> Here are the changes I want to make:
> 1. If the genotype= "nc" or '_" then set equal to NA.
> 2. If genotype value = a character string comprised of two consecutive
> major allele values -- c(Maj_Allele, Maj_Allele) -- then set equal to 0.
> 3. If genotype  value= c(Maj_Allele, Min_Allele) then set equal to 1.
> 4. If genotype  value = c(Min_Allele, Min_Allele) then set equal to 2.
>
> I've tried the following ifelse processing but get error (Warning: Executed
> script did not end with R session at the top-level prompt.  Top-level state
> will be restored) and can't seem to fix the code properly. I've counted the
> parentheses. Also, not sure if it would execute properly if I could fix it.
>
> # change 'nc' and '_' to NA, else leave as is:
> Kgeno[,2] <- ifelse(Kgeno[,2] == "nc", "NA", Kgeno[,2])
> Kgeno[,2] <- ifelse(Kgeno[,2] == "_", "NA", Kgeno[,2])
>
> #convert genotype strings in the first data column to numeric values #(two
> major alleles=0, 1 minor and 1 major=1, 2 minor alleles=2), else #leave as
> is (to preserve NA values).
>
> Kgeno[,2] <-
>
> ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[1,2]), as.character(
> Kgeno[1,2]), sep=""), 0,
>
> ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[1,2]), as.character(
> Kgeno[2,2]), sep=""), 1,
>
> ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[2,2]), as.character(
> Kgeno[2,2]), sep=""), 2,
>              Kgeno[,2])))
>
>
> Finally, if above code were corrected, this would only change the first
> column of data, but I would like to change all 3000+ columns in the same
> way.
>
> I would greatly appreciate some suggestions on how to proceed.
>
> Thank you,
>
> Kathleen
>
> ---
> Kathleen Askland, MD
> Assistant Professor
> Department of Psychiatry & Human Behavior
> The Warren Alpert School of Medicine
> Brown University/Butler Hospital
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Tue Jul  2 23:21:38 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 02 Jul 2013 22:21:38 +0100
Subject: [R] Recoding variables based on reference values in data frame
In-Reply-To: <51D342E8.2090002@sapo.pt>
References: <CAFpPP=zzXSSAUhZv36K5Qg7jFVyqHaY6LHWFQWPSb97MtfWNDQ@mail.gmail.com>
	<51D342E8.2090002@sapo.pt>
Message-ID: <51D34462.4030107@sapo.pt>

Hello,

If you have read in the data as factors (stringsAsFactors = TRUE, the 
default), change the function to the following.


fun <- function(x){
	x[x %in% c("nc", "_")] <- NA
	MM <- paste0(as.character(x[1]), as.character(x[1]))  # Major Major
	Mm <- paste0(as.character(x[1]), as.character(x[2]))  # Major minor
	mm <- paste0(as.character(x[2]), as.character(x[2]))  # minor minor
	x[x == MM] <- 0
	x[x == Mm] <- 1
	x[x == mm] <- 2
	x
}



Rui Barradas

Em 02-07-2013 22:15, Rui Barradas escreveu:
> Hello,
>
> I'm not sure I understood, but try the following.
>
>
> Kgeno <- read.table(text = "
> SNP_ID SNP1 SNP2 SNP3 SNP4
> Maj_Allele C G  C  A
> Min_Allele T A T G
> ID1 CC     GG     CT     AA
> ID2 CC     GG     CC AA
> ID3 CC     GG    nc    AA
> ID4 _ _ _ _
> ID5 CC     GG     CC     AA
> ID6 CC     GG     CC     AA
> ID7 CC     GG     CT     AA
> ID8 _ _ _ _
> ID9 CT     GG     CC AG
> ID10 CC     GG     CC     AA
> ID11 CC     GG     CT     AA
> ID12 _ _ _ _
> ID13 CC     GG     CC     AA
> ", header = TRUE, stringsAsFactors = FALSE)
>
> dat
>
> fun <- function(x){
>      x[x %in% c("nc", "_")] <- NA
>      MM <- paste0(x[1], x[1])  # Major Major
>      Mm <- paste0(x[1], x[2])  # Major minor
>      mm <- paste0(x[2], x[2])  # minor minor
>      x[x == MM] <- 0
>      x[x == Mm] <- 1
>      x[x == mm] <- 2
>      x
> }
>
> Kgeno[, -1] <- sapply(Kgeno[, -1], fun)
> Kgeno
>
>
> Also, the best way to post data is by using ?dput.
>
> dput(head(Kgeno[, 1:5], 30))  # post the output of this
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 02-07-2013 21:46, kathleen askland escreveu:
>> I'm new to R (previously used SAS primarily) and I have a genetics data
>> frame consisting of genotypes for each of 300+ subjects (ID1, ID2, ID3,
>> ...) at 3000+ genetic locations (SNP1, SNP2, SNP3...). A small subset of
>> the data is shown below:
>>    SNP_ID SNP1 SNP2 SNP3 SNP4  Maj_Allele C G  C  A  Min_Allele T A T
>> G  ID1
>> CC     GG     CT     AA      ID2 CC     GG     CC AA      ID3 CC     GG
>> nc
>> AA      ID4 _ _ _ _  ID5 CC     GG     CC     AA      ID6 CC
>> GG     CC
>>       AA      ID7 CC     GG     CT     AA      ID8 _ _ _ _  ID9 CT     GG
>> CC AG      ID10 CC     GG     CC     AA      ID11 CC     GG     CT     AA
>>        ID12 _ _ _ _  ID13 CC     GG     CC     AA
>> The name of the data file is Kgeno.
>> What I would like to do is recode all of the genotype values to standard
>> integer notation, based on their values relative to the reference rows
>> (Maj_Allele and Min_Allele). Standard notation sums the total of minor
>> alleles in the genotype, so values can be 0, 1 or 2.
>>
>> Here are the changes I want to make:
>> 1. If the genotype= "nc" or '_" then set equal to NA.
>> 2. If genotype value = a character string comprised of two consecutive
>> major allele values -- c(Maj_Allele, Maj_Allele) -- then set equal to 0.
>> 3. If genotype  value= c(Maj_Allele, Min_Allele) then set equal to 1.
>> 4. If genotype  value = c(Min_Allele, Min_Allele) then set equal to 2.
>>
>> I've tried the following ifelse processing but get error (Warning:
>> Executed
>> script did not end with R session at the top-level prompt.  Top-level
>> state
>> will be restored) and can't seem to fix the code properly. I've
>> counted the
>> parentheses. Also, not sure if it would execute properly if I could
>> fix it.
>>
>> # change 'nc' and '_' to NA, else leave as is:
>> Kgeno[,2] <- ifelse(Kgeno[,2] == "nc", "NA", Kgeno[,2])
>> Kgeno[,2] <- ifelse(Kgeno[,2] == "_", "NA", Kgeno[,2])
>>
>> #convert genotype strings in the first data column to numeric values
>> #(two
>> major alleles=0, 1 minor and 1 major=1, 2 minor alleles=2), else
>> #leave as
>> is (to preserve NA values).
>>
>> Kgeno[,2] <-
>>
>> ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[1,2]), as.character(
>> Kgeno[1,2]), sep=""), 0,
>>
>> ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[1,2]), as.character(
>> Kgeno[2,2]), sep=""), 1,
>>
>> ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[2,2]), as.character(
>> Kgeno[2,2]), sep=""), 2,
>>              Kgeno[,2])))
>>
>>
>> Finally, if above code were corrected, this would only change the first
>> column of data, but I would like to change all 3000+ columns in the same
>> way.
>>
>> I would greatly appreciate some suggestions on how to proceed.
>>
>> Thank you,
>>
>> Kathleen
>>
>> ---
>> Kathleen Askland, MD
>> Assistant Professor
>> Department of Psychiatry & Human Behavior
>> The Warren Alpert School of Medicine
>> Brown University/Butler Hospital
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Wed Jul  3 00:35:27 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 02 Jul 2013 15:35:27 -0700
Subject: [R] acf question...
In-Reply-To: <1372782061.37244.YahooMailNeo@web140504.mail.bf1.yahoo.com>
References: <1372782061.37244.YahooMailNeo@web140504.mail.bf1.yahoo.com>
Message-ID: <692b7b29-add5-4fc6-bc81-0393f13d813c@email.android.com>

Then you are posting in the wrong forum, since this is a forum about getting R to do things for which you already understand the theory.

As to the results you are getting, I highly recommend reading the details section of ?ccf.

BTW The Posting Guide indicates that you should post in text format because HTML mutilates R code. This is a setting in your email program.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Venkatesh Nagarajan <gocanon at yahoo.com> wrote:

>I am trying to understand lagged correlations. 
>?
>x= 1:100; 
>y = c(rep(NA,40), 1:60)ccf(x = x, y = y, lag.max=100,
>na.action=na.pass, type = "correlation") 
>?
>I was hoping to see max cor at lag = 40. But I am not. What am I doing
>wrong?
>?
>Thanks
>VN
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Wed Jul  3 01:26:38 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Wed, 03 Jul 2013 11:26:38 +1200
Subject: [R] acf question...
In-Reply-To: <1372782061.37244.YahooMailNeo@web140504.mail.bf1.yahoo.com>
References: <1372782061.37244.YahooMailNeo@web140504.mail.bf1.yahoo.com>
Message-ID: <51D361AE.2050307@xtra.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/24a3eb6d/attachment.pl>

From dboyce at dal.ca  Wed Jul  3 01:29:55 2013
From: dboyce at dal.ca (garth)
Date: Tue, 2 Jul 2013 16:29:55 -0700 (PDT)
Subject: [R] Deviance explained by individual terms in GAM
Message-ID: <1372807795707-4670756.post@n4.nabble.com>

Hello,

I am fitting GAMs using mgcv. My models have both linear and functional
effects, for instance:

b<-gam(y~s(x0)+s(x1)+s(x2)+s(x3) + x4 + as.factor(x5),data=dat)

I would like to extract the proportion of deviance explained by a single
term in the model, for instance, s(x1). 
Having read through some R help posts I realize that if all terms in the
model are functional (i.e. ?smooth?) that this is achievable by calculating
the difference in deviance explained between models with s(x1), and without
it, provided that the model parameters in both models are held fixed (i.e.
are identical). For instance, if all model covariates are functional this
would be achieved (according to a post by Simon Wood;
http://r.789695.n4.nabble.com/Re-variance-explained-by-each-predictor-in-GAM-td896222.html#a896223)
with:

dat <- gamSim(1,n=400,dist="normal",scale=2) 
b<-gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat) 
b2<-gam(y~s(x0)+s(x1)+s(x3),sp=b$sp[-3],data=dat) 
summary(b2)$dev.expl 
summary(b)$dev.expl

This works great, and the ?sp=? option in the above code holds the smoothing
parameters fixed. I?m looking to extend this so as to also hold any
non-smooth parameters fixed. Does anyone know how/if this would be possible?

Thanks so much.




--
View this message in context: http://r.789695.n4.nabble.com/Deviance-explained-by-individual-terms-in-GAM-tp4670756.html
Sent from the R help mailing list archive at Nabble.com.


From mackay at northnet.com.au  Wed Jul  3 01:40:30 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Wed, 03 Jul 2013 09:40:30 +1000
Subject: [R] Multinomial model and p-values
In-Reply-To: <002e01ce7759$4f289f20$ed79dd60$@com.ar>
References: <002e01ce7759$4f289f20$ed79dd60$@com.ar>
Message-ID: <201307022340.r62NeWiC030460@mail15.tpg.com.au>

Hi Luciano

There are a number of types of ordinal regression and you need to be 
specific about that.
There are a number of ordinal packages to do ordinal regression.

MASS::polr
arm::bayespolr
ordinal
VGAM
repolr
geepack
etc

Each of them has specific requirements about coding of the variables 
and these MUST be adhered to.

polr may be better suited to your dataset. -- No data: cannot say.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

At 05:21 3/07/2013, you wrote:
>Hello everyone,
>
>I have a dataset which consists of "Pathology scores" (Absent, Mild, Severe)
>as outcome variable, and two main effects: Age (two factors: twenty / thirty
>days old) and Treatment Group (four factors: infected without ATB; infected
>+ ATB1; infected + ATB2; infected + ATB3).
>
>First I tried to fit an ordinal regression model, which seems more
>appropriate given the characteristics of my dependent variable (ordinal).
>However, the assumption of odds proportionality was severely violated
>(graphically), which prompted me to use a multinomial model instead, using
>the "nnet" package.
>
>
>First I chose the outcome level that I need to use as baseline category:
>
>Data$Path <- relevel(Data$Path, ref = "Absent")
>
>Then, I needed to set baseline categories for the independent variables:
>
>Data$Age <- relevel(Data$Age, ref = "Twenty")
>Data$Treat <- relevel(Data$Treat, ref = "infected without ATB")
>
>The model:
>
>test <- multinom(Path ~ Treat + Age, data = Data)
># weights:  18 (10 variable)
>initial  value 128.537638
>iter  10 value 80.623608
>final  value 80.619911
>converged
>
> > summary1 <- summary(test1)
> > summary1
>
>Call:
>multinom(formula = Jej_fact ~ Treat + Age, data = Data)
>
>Coefficients:
>          (Intercept)   infected+ATB1   infected+ATB2   infected+ATB3
>AgeThirty
>Moderate   -2.238106   -1.1738540      -1.709608       -1.599301
>2.684677
>Severe     -1.544361   -0.8696531      -2.991307       -1.506709
>1.810771
>
>Std. Errors:
>          (Intercept)    infected+ATB1   infected+ATB2   infected+ATB3
>AgeThirty
>Moderate   0.7880046    0.8430368       0.7731359       0.7718480
>0.8150993
>Severe     0.6110903    0.7574311       1.1486203       0.7504781
>0.6607360
>
>Residual Deviance: 161.2398
>AIC: 181.2398
>
>For a while, I could not find a way to get the p-values for the model and
>estimates when using nnet:multinom. Yesterday I came across a post where the
>author put forward a similar issue regarding estimation of p-values for
>coefficients
>(http://stats.stackexchange.com/questions/9715/how-to-set-up-and-estimate-a-
>multinomial-logit-model-in-r).
>
>There, one blogger suggested that getting p-values from the summary() result
>of multinom() is pretty easy, by first getting the t values as follows:
>
>pt(abs(summary1$coefficients / summary1$standard.errors), df=nrow(Data)-10,
>lower=FALSE)
>
>          (Intercept)   infected+ATB1   infected+ATB2   infected+ATB3
>AgeThirty
>Moderate 0.002670340   0.08325396      0.014506395     0.02025858
>0.0006587898
>Severe   0.006433581   0.12665278      0.005216581     0.02352202
>0.0035612114
>
>I AM NOT a statistician, so don't be baffled by a silly question! I this
>procedure correct?
>
>Cheers for now,
>
>Luciano
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From suparna.mitra.sm at gmail.com  Wed Jul  3 03:59:37 2013
From: suparna.mitra.sm at gmail.com (Suparna Mitra)
Date: Wed, 3 Jul 2013 09:59:37 +0800
Subject: [R] Changing legend to fill colour in ggplot
In-Reply-To: <E5BA65CAFB491A4DBB1370F6C97216550744586DCE@EX-MB05.ohsu.edu>
References: <CAFdg=fWJuCY2dwyJzq4ocRccrUHfmAWZ7KTr9y2yJSC54iKBSA@mail.gmail.com>
	<E5BA65CAFB491A4DBB1370F6C97216550744586DCE@EX-MB05.ohsu.edu>
Message-ID: <CAFdg=fU1QBLK3gsx_rw9jmEA57Zcne_Cqhar1GyfrcJO7iPS+A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/144dcf25/attachment.pl>

From sachin.abeywardana at gmail.com  Wed Jul  3 05:11:31 2013
From: sachin.abeywardana at gmail.com (Sachinthaka Abeywardana)
Date: Wed, 3 Jul 2013 13:11:31 +1000
Subject: [R] nth root of matrix
Message-ID: <CAGuusR86Om3y04fTKLi=EXWWkiy1A5tmaLaMvuVhFRrvOA1ndw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/3e0ac748/attachment.pl>

From dwinsemius at comcast.net  Wed Jul  3 06:24:59 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 2 Jul 2013 21:24:59 -0700
Subject: [R] nth root of matrix
In-Reply-To: <CAGuusR86Om3y04fTKLi=EXWWkiy1A5tmaLaMvuVhFRrvOA1ndw@mail.gmail.com>
References: <CAGuusR86Om3y04fTKLi=EXWWkiy1A5tmaLaMvuVhFRrvOA1ndw@mail.gmail.com>
Message-ID: <331109CC-EE6A-4637-BF45-9797FFEC8C3D@comcast.net>


On Jul 2, 2013, at 8:11 PM, Sachinthaka Abeywardana wrote:

> Hi all,
> 
> I want to do the following:
> 
> a=matrix(c(-1,-2,-3))
> a^(1/3) #get 3rd root of numbers[,1]
> 
> [1,]  NaN
> [2,]  NaN
> [3,]  NaN
> 
> 
> All I get is NaNs, what is the proper way of doing this? Would like to
> retain the fact that it is a matrix if possible (not a requirement
> though).

?complex

 a=matrix(c(-1+0i,-2+0i,-3+0i))


David Winsemius
Alameda, CA, USA


From ivo.welch at anderson.ucla.edu  Wed Jul  3 07:52:10 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Tue, 2 Jul 2013 22:52:10 -0700
Subject: [R] advice on big panel operations with mclapply?
Message-ID: <CAPr7RtWOLTVAQ-tX9Q2AgjYsWChj+1cNsjBX-nnE1ciwfCOozg@mail.gmail.com>

dear R experts:  I have a very large panel data set, about 2-8GB.  think

NU <- 30000;NT <- 3000
ds <- data.frame( unit= rep(1:NU, each=NT ), time=NA,  x=NA)
ds$time <- rep( 1:NT, NU )
ds$x <- rnorm(nrow(ds))

I want to do a couple of operations within each unit first, and then
do some list operations at each time.  not difficult in principle.
think

  ds <- merge back in results of  mclapply( split(1:nrow(x), ds$unit),
function( ids ) { work on ds[ids,] } )  # same unit
  ds <- merge back in results of  mclapply( split(1:nrow(x), ds$time),
function( ids ) { work on ds[ids,] } )  # same time

the problem is that ds is big.  I can store 1 copy, but not 4.  what I
really want is to declare ds "read-only shared memory" before the
mclapply() and have the spawned processes access the same ds.  right
now, each core wants its own private duplicate of ds, which then runs
out of memory.  I don't think shared data is possible in R across
mclapply.

* I could just run my code single-threaded.  this loses the
parallelism of the task, but the code remains parsimonious and the
memory footprint is still ok.

* I could just throw 120GB of SSD as swapfile.  for $100 or so, this
ain't a bad solution.  its slower than RAM but faster and safer than
coding more complex R solutions.  it's still likely faster than
single-threaded operations on quad-core machines.  if the swap
algorithm is efficient, it shouldn't be so bad.

* I could pre-split the data before and merge after the mclapply.
within each chunk, I could then use mclapply.  the code would be
uglier and have a layer of extra complexity ( = bugs ), but RAM
consumption drops by orders of magnitude.  I am thinking something
roughly like

## first operation
mclapply( split(1:nrow(x), ds$units), function(di) save( ds[di,],
file=paste0("@", di, ".Rdata") )
rm(ds)  ## make space for the mclapply
results <- mclapply( Sys.glob("*.Rdata"), function( ids ) { load(ids);
...do whatever... }  ## run many many happysmall-mem processes
system("rm @*.Rdata")  ## temporary files
load("ds.Rdata")  ## since we deleted it, we have to reload the original data
## combine results of the full ds
ds <- data.frame( ds, results )
## now run the second operation on the time units

* I could dump the data into a data base, but then every access (like
the split() or the mclapply()) would also have to query and reload the
data again, just like my .Rdata files.  is it really faster/better
than abusing the file system and R's native file formats?  I doubt it,
but I don't know for sure.

this is a reasonably common problem with large data sets.  I saw some
specific solutions on stackoverflow, a couple requiring even less
parsimonious user code.  is everyone using bigmemory?  or SQL? or ...
?  I am leaning towards the SSD solution.  am I overlooking some
simpler recommended solution?

/iaw

----
Ivo Welch (ivo.welch at gmail.com)


From spencer.graves at structuremonitoring.com  Wed Jul  3 08:30:01 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Tue, 02 Jul 2013 23:30:01 -0700
Subject: [R] nth root of matrix
In-Reply-To: <331109CC-EE6A-4637-BF45-9797FFEC8C3D@comcast.net>
References: <CAGuusR86Om3y04fTKLi=EXWWkiy1A5tmaLaMvuVhFRrvOA1ndw@mail.gmail.com>
	<331109CC-EE6A-4637-BF45-9797FFEC8C3D@comcast.net>
Message-ID: <51D3C4E9.2010807@structuremonitoring.com>



On 7/2/2013 9:24 PM, David Winsemius wrote:
> On Jul 2, 2013, at 8:11 PM, Sachinthaka Abeywardana wrote:
>
>> Hi all,
>>
>> I want to do the following:
>>
>> a=matrix(c(-1,-2,-3))
>> a^(1/3) #get 3rd root of numbers[,1]
>>
>> [1,]  NaN
>> [2,]  NaN
>> [3,]  NaN
>>
>>
>> All I get is NaNs, what is the proper way of doing this? Would like to
>> retain the fact that it is a matrix if possible (not a requirement
>> though).
> ?complex
>
>   a=matrix(c(-1+0i,-2+0i,-3+0i))


       I tried that.  The problem is that there are 3 different cube 
roots in the complex plane, and a^(1/3) only gives one of them.  See 
Wikipedia, "roots of unity" or the examples in the help file for 
"newton_raphson {elliptic}".


       I assume that Sachinthaka wants the real roots.  Try the following:


n <- 3 # n must be an odd integer for this to work
a=matrix(c(-1,-2,-3))
as <- sign(a)
ab <- abs(a)
cr <- as*(ab^(1/n))
 > cr
           [,1]
[1,] -1.000000
[2,] -1.259921
[3,] -1.442250
cr^n


       Hope this helps.  Spencer Graves

> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul  3 01:30:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 2 Jul 2013 16:30:38 -0700 (PDT)
Subject: [R] Recoding variables based on reference values in data frame
In-Reply-To: <CAFpPP=zzXSSAUhZv36K5Qg7jFVyqHaY6LHWFQWPSb97MtfWNDQ@mail.gmail.com>
References: <CAFpPP=zzXSSAUhZv36K5Qg7jFVyqHaY6LHWFQWPSb97MtfWNDQ@mail.gmail.com>
Message-ID: <1372807838.55277.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:
Kgeno<- read.table(text="
SNP_ID SNP1 SNP2 SNP3 SNP4
Maj_Allele C G? C? A
Min_Allele T A T G? 
ID1 CC??? GG??? CT??? AA
ID2 CC??? GG??? CC AA
ID3 CC??? GG nc? AA
ID4? _? _? _? _ 
ID5 CC??? GG??? CC??? AA
ID6 CC??? GG??? CC? AA
ID7 CC??? GG??? CT??? AA
ID8 _ _ _ _? 
ID9 CT??? GG? CC AG
ID10 CC??? GG??? CC??? AA
ID11 CC??? GG??? CT??? AA
ID12 _ _ _ _? 
ID13 CC??? GG??? CC??? AA
",sep="",header=TRUE,stringsAsFactors=FALSE)

library(stringr)
library(car)

fun1<- function(x){
?MajMin<- paste0(x[1],x[2])
?MajMaj<-str_dup(x[1],2)
?MinMin<-str_dup(x[2],2)
?recode(x,"'nc'=NA;'_'=NA;MajMaj=0;MajMin=1;MinMin=2")}
sapply(Kgeno[,-1],fun1)

#or

?mat1<-sapply(Kgeno[1:2,-1],function(x) {c(str_dup(x,2),paste(x,collapse=""))})[c(1,3,2),]
sapply(seq_len(ncol(Kgeno[,-1])),function(i) {x<-Kgeno[-c(1:2),-1][,i];as.numeric(factor(x,levels=mat1[,i]))-1})


#Speed comparison
KgenoNew<- rbind(Kgeno[c(1:2),-1],sapply(Kgeno[-c(1:2),-1],rep,1e4))
?system.time(res1<- sapply(KgenoNew,fun1))
#?? user? system elapsed 
?#0.672?? 0.000?? 0.674 


system.time({
mat1<-sapply(Kgeno[1:2,-1],function(x) {c(str_dup(x,2),paste(x,collapse=""))})[c(1,3,2),]
res2<- sapply(seq_len(ncol(KgenoNew)),function(i){ x<- KgenoNew[-c(1:2),][,i];as.numeric(factor(x,levels=mat1[,i]))-1})
})
#user? system elapsed 
#? 0.212?? 0.000?? 0.214 
res1New<- res1[-c(1:2),]
res1New1<- as.numeric(res1New)
?dim(res1New1)<- dim(res1New)
identical(res1New1,res2)
#[1] TRUE
A.K.







----- Original Message -----
From: kathleen askland <k.askland at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, July 2, 2013 4:46 PM
Subject: [R] Recoding variables based on reference values in data frame

I'm new to R (previously used SAS primarily) and I have a genetics data
frame consisting of genotypes for each of 300+ subjects (ID1, ID2, ID3,
...) at 3000+ genetic locations (SNP1, SNP2, SNP3...). A small subset of
the data is shown below:
? SNP_ID SNP1 SNP2 SNP3 SNP4? Maj_Allele C G? C? A? Min_Allele T A T G? ID1
CC? ?  GG? ?  CT? ?  AA? ? ? ID2 CC? ?  GG? ?  CC AA? ? ? ID3 CC? ?  GG
nc
AA? ? ? ID4 _ _ _ _? ID5 CC? ?  GG? ?  CC? ?  AA? ? ? ID6 CC? ?  GG? ?  CC
? ?  AA? ? ? ID7 CC? ?  GG? ?  CT? ?  AA? ? ? ID8 _ _ _ _? ID9 CT? ?  GG
CC AG? ? ? ID10 CC? ?  GG? ?  CC? ?  AA? ? ? ID11 CC? ?  GG? ?  CT? ?  AA
? ? ? ID12 _ _ _ _? ID13 CC? ?  GG? ?  CC? ?  AA
The name of the data file is Kgeno.
What I would like to do is recode all of the genotype values to standard
integer notation, based on their values relative to the reference rows
(Maj_Allele and Min_Allele). Standard notation sums the total of minor
alleles in the genotype, so values can be 0, 1 or 2.

Here are the changes I want to make:
1. If the genotype= "nc" or '_" then set equal to NA.
2. If genotype value = a character string comprised of two consecutive
major allele values -- c(Maj_Allele, Maj_Allele) -- then set equal to 0.
3. If genotype? value= c(Maj_Allele, Min_Allele) then set equal to 1.
4. If genotype? value = c(Min_Allele, Min_Allele) then set equal to 2.

I've tried the following ifelse processing but get error (Warning: Executed
script did not end with R session at the top-level prompt.? Top-level state
will be restored) and can't seem to fix the code properly. I've counted the
parentheses. Also, not sure if it would execute properly if I could fix it.

# change 'nc' and '_' to NA, else leave as is:
Kgeno[,2] <- ifelse(Kgeno[,2] == "nc", "NA", Kgeno[,2])
Kgeno[,2] <- ifelse(Kgeno[,2] == "_", "NA", Kgeno[,2])

#convert genotype strings in the first data column to numeric values #(two
major alleles=0, 1 minor and 1 major=1, 2 minor alleles=2), else #leave as
is (to preserve NA values).

Kgeno[,2] <-

ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[1,2]), as.character(
Kgeno[1,2]), sep=""), 0,

ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[1,2]), as.character(
Kgeno[2,2]), sep=""), 1,

ifelse(Kgeno[,2] == noquote(paste(as.character(Kgeno[2,2]), as.character(
Kgeno[2,2]), sep=""), 2,
? ? ? ? ? ? Kgeno[,2])))


Finally, if above code were corrected, this would only change the first
column of data, but I would like to change all 3000+ columns in the same
way.

I would greatly appreciate some suggestions on how to proceed.

Thank you,

Kathleen

---
Kathleen Askland, MD
Assistant Professor
Department of Psychiatry & Human Behavior
The Warren Alpert School of Medicine
Brown University/Butler Hospital

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Jul  3 05:22:52 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 2 Jul 2013 20:22:52 -0700 (PDT)
Subject: [R] nth root of matrix
In-Reply-To: <CAGuusR86Om3y04fTKLi=EXWWkiy1A5tmaLaMvuVhFRrvOA1ndw@mail.gmail.com>
References: <CAGuusR86Om3y04fTKLi=EXWWkiy1A5tmaLaMvuVhFRrvOA1ndw@mail.gmail.com>
Message-ID: <1372821772.11320.YahooMailNeo@web142602.mail.bf1.yahoo.com>

?sign(a)*abs(a)^(1/3)
#????????? [,1]
#[1,] -1.000000
#[2,] -1.259921
#[3,] -1.442250
A.K. 




----- Original Message -----
From: Sachinthaka Abeywardana <sachin.abeywardana at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 2, 2013 11:11 PM
Subject: [R] nth root of matrix

Hi all,

I want to do the following:

a=matrix(c(-1,-2,-3))
a^(1/3) #get 3rd root of numbers[,1]

[1,]? NaN
[2,]? NaN
[3,]? NaN


All I get is NaNs, what is the proper way of doing this? Would like to
retain the fact that it is a matrix if possible (not a requirement
though).


Thanks,

Sachin

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Jul  3 06:47:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 2 Jul 2013 21:47:35 -0700 (PDT)
Subject: [R] matching similar character strings
In-Reply-To: <CAOZPQW6OG7yO_-ssKa+Axr=CsDrJiEaN7SkaCY9RFPz3tLiRyw@mail.gmail.com>
References: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>
	<1371821358.6821.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<51C46C83.4030001@unipa.it>
	<1371828336.16438.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOZPQW6OG7yO_-ssKa+Axr=CsDrJiEaN7SkaCY9RFPz3tLiRyw@mail.gmail.com>
Message-ID: <1372826855.77040.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Dear Mario,
Not sure if this is what you wanted:
F1_ex<- read.table(text="
?? Nome.azienda;Indirizzo
17;Alterego;Via Edmondo De Amicis, 18
18;Alterego;Via Edmondo De Amicis, 65
",sep=";",header=TRUE,stringsAsFactors=FALSE)

F2_ex<- read.table(text="
?? CODICE;STRADA;AREADICIRCOLAZIONE;NUMBER1;BARRATO1;NUMBER2;BARRATO2;SECTION
1;15620;VIA;DE AMICIS EDMONDO;1;;5;;1288 
2;15620;VIA;DE AMICIS EDMONDO;2;;34;;1261
3;15620;VIA;DE AMICIS EDMONDO;7;;17;;1287
4;15620;VIA;DE AMICIS EDMONDO;36;;62;;1264
5;15620;VIA;DE AMICIS EDMONDO;37;;37;;1287
6;15620;VIA;DE AMICIS EDMONDO;64;;84;;1262
",sep=";",header=TRUE,stringsAsFactors=FALSE)
library(stringr)
?vec1<-sapply(lapply(toupper(str_trim(gsub("[0-9,]","",F1_ex[,2]))),word,c(1,3,4,2)),paste,collapse=" ")
?vec2<- as.numeric(gsub("\\D+","",F1_ex[,2]))
?F1_ex[,1]<-F2_ex[sapply(vec2,function(x) which((x>F2_ex[,4] & x< F2_ex[,6]) & paste(F2_ex[,2],F2_ex[,3])%in%vec1)),"SECTION"]
?F1_ex
#?? Nome.azienda???????????????? Indirizzo
#17???????? 1261 Via Edmondo De Amicis, 18
#18???????? 1262 Via Edmondo De Amicis, 65
A.K.





----- Original Message -----
From: A M Lavezzi <mario.lavezzi at unipa.it>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 2, 2013 10:22 AM
Subject: Re: [R] matching similar character strings

Dear Arun,
please excuse me for this late reply, we had to stop working on this
temporaririly.

Let me reproduce here two examples of rows from F1 and F2 (sorry, but
with dput() I am not able to produce a clear example)

> F1_ex
? ? ? ? Nome.azienda? ? ? ? ? ? ? ? ?  Indirizzo
17? ?  Alterego? ? ? ? ? ?  Via Edmondo De Amicis, 18

On row 17 of F1 we have a firm named ("Nome.azienda") 'Alterego' whose
address ("indirizzo") is? 'Via Edmondo de Amicis, 18'

Below I reproduce the portion of F2 with information on the street
mentioned in F1_ex$Indirizzo.

> F2_ex

? CODICE? ? STRADA? ? ?  AREADICIRCOLAZIONE? ? ? ? ? NUMBER1 BARRATO1
NUMBER2 BARRATO2 SECTION
1? 15620? ? ? ? VIA? ? ? ? ? ? DE AMICIS EDMONDO? ? ? ? ? ? ? ? ? ?  1
? ? ? ? ? ? ? ? ? ? ? ? ? 5? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  1288
2? 15620? ? ? ? VIA? ? ? ? ? ? DE AMICIS EDMONDO? ? ? ? ? ? ? ? ? ?  2
? ? ? ? ? ? ? ? ? ? ? ?  34? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  1261
3? 15620? ? ? ? VIA? ? ? ? ? ? DE AMICIS EDMONDO? ? ? ? ? ? ? ? ? ?  7
? ? ? ? ? ? ? ? ? ? ? ?  17? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?  1287
4? 15620? ? ? ? VIA? ? ? ? ? ? DE AMICIS EDMONDO? ? ? ? ? ? ? ? ? ? 36
? ? ? ? ? ? ? ? ? ? ? ?  62? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1264
5? 15620? ? ? ? VIA? ? ? ? ? ? DE AMICIS EDMONDO? ? ? ? ? ? ? ? ? ? 37
? ? ? ? ? ? ? ? ? ? ? ?  37? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1287
6? 15620? ? ? ? VIA? ? ? ? ? ? DE AMICIS EDMONDO? ? ? ? ? ? ? ? ? ? 64
? ? ? ? ? ? ? ? ? ? ? ?  84? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1262


Line 1 says that the portion of VIA DE AMICIS EDMONDO
("STRADA"+"AREADICIRCOLAZIONE"), with street numbers between 1 and 5
belongs to SECTION 1288 (these are census sections). ("BARRATO1" and
"BARRATO2" refer to the letter in street numbers such as 12/A, 28/D,
etc. In the present example they are empty)

Line 2 says that the portion of VIA DE AMICIS EDMONDO, with street
numbers between 2 and 34 belongs to SECTION 1261,

etc.

Our problem is to assign SECTION 1261 to 'Alterego', exploting the
information on its address. The problem is that the syntax of the
street address in F1 is different from the syntax in F2.

Hope I have clarified the issue

thanks a lot
Mario








On Fri, Jun 21, 2013 at 5:25 PM, arun <smartpink111 at yahoo.com> wrote:
> Dear Mario,
> I didn't find any difference between 1st and 2nd row of F2, except for the last three columns.? Question is that why should F1 1st row should be merged to 2nd row of F2 instead of 1st row of F2. In your previous example, you mentioned about A1, A2, ... and B1, B2, etc.? Here, it is not provided.? As I mentioned before, it is better to provide the output of ?dput() from a subset of dataset.
> dput(head(F1,20))
>
> dput(head(F2,20))
>
> #so that there would be atleast some matching pairs within the example dataset.? Also, please post it to r-help as I will be able to check only after a couple of hours
> Tx.
> Arun
>
>
>
> ----- Original Message -----
> From: Mario Lavezzi <mario.lavezzi at unipa.it>
> To: arun <smartpink111 at yahoo.com>
> Cc:
> Sent: Friday, June 21, 2013 11:08 AM
> Subject: Re: [R] matching similar character strings
>
> dear Arun
> thank you very much. Let me explain the problem:
>
> Imagine that a portion of the row in F1 is:
>
> ----------------------------
> F1
>
> 1) Street | J.F. Kennedy | 30
> ----------------------------
>
> it means that our unit of interest (a firm) has address: J.F. Kennedy Street, 30
>
>
> The F2 database contains the list of all the streets of the city, with additional variables characterizing that street (Census data). The database
> contains sometimes street divided in some parts, according to the street number. For example:
>
>
> Example of three rows of F2 concerning Kennedy street and Kennedy Road:
>
> F2
>
> 1) Street | Kennedy John Fitzgerald? | 1? | 20 | A12
> 2) Street | Kennedy John Fitzgerald? | 20 | 50 | A15
> 3) Road?  | Kennedy John? ? ? ? ? ?  | 1? | 50 | A23
>
>
> We'd like to have an algorithm able to understand that, notwithstanding the name is slightly different, element A15 should be added to row 1) of F1,
> producing an output such as:
>
> 1) Street | J.F. Kennedy | 30 | A15
>
>
> hope this clarifies the issue.
>
> thanks a lot! Mario
>
>
>
> Il 21/06/2013 15:29, arun ha scritto:
>> HI,
>> Could you dput() your example datasets and also your expected result?? The Census section is not clear.
>> A.K.
>>
>>
>>
>>
>> ----- Original Message -----
>> From: A M Lavezzi <mario.lavezzi at unipa.it>
>> To: r-help <r-help at r-project.org>
>> Cc:
>> Sent: Friday, June 21, 2013 5:56 AM
>> Subject: [R] matching similar character strings
>>
>> Hello everybody
>>
>> I have this problem: I need to match an addresses database F1 with the
>> information contained in a toponymic database F2.
>>
>> The format of F1 is given by three columns and 800 rows, with the
>> columns being:
>>
>> A1. Street/Road/Avenue
>> A2. Name
>> A3. Number
>>
>> Consider for instance Avenue J. Kennedy , 3011. In F1 this is:
>>
>> A1. Avenue
>> A2. J. Kennedy
>> A3. 3011
>>
>> The format of F2 file is instead given by 20000 rows and five columns:
>>
>> B1. Street/Road/Avenue
>> B2. Name
>> B3. Starting Street Number
>> B4. Ending Street Number
>> B5. Census section
>>
>> So my problem is attributing the? B5 Census section to every
>> observation of F1 if: A1=B1, A2=B2, and A3 is comprised between B3 and
>> B4.
>>
>> The problem is that while the information in A2 is irregularly
>> recorded, B2 has a given format that is Family name (space) Given
>> name.
>>
>> So I could have that while in B2 the information is:
>>
>> Kennedy John
>>
>> In A2 it could be:
>>
>> John Kennedy
>> JF Kennedy
>> J. Kennedy
>>
>> and so on.
>>
>> Thanks,
>>
>> Mario
>>
>
> --
> PLEASE NOTICE NEW EMAIL ADDRESS AND HOME PAGE URL
>
> Andrea Mario Lavezzi
> Dipartimento di Studi su Politica, Diritto e Societ?
> Universit? di Palermo
> Piazza Bologni 8
> 90134 Palermo, Italy
> tel. ++39 091 23892208
> fax ++39 091 6111268
> skype: lavezzimario
> email: mario.lavezzi (at) unipa.it
> web: http://www.unipa.it/~mario.lavezzi



-- 
Andrea Mario Lavezzi
Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Wed Jul  3 09:44:35 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 3 Jul 2013 09:44:35 +0200
Subject: [R] Multinomial model and p-values
In-Reply-To: <002e01ce7759$4f289f20$ed79dd60$@com.ar>
References: <002e01ce7759$4f289f20$ed79dd60$@com.ar>
Message-ID: <87760D0D-6B6A-4908-BD5C-AAFA36CFDBD4@gmail.com>


On Jul 2, 2013, at 21:21 , Luciano La Sala wrote:

> Hello everyone, 
> 
> I have a dataset which consists of "Pathology scores" (Absent, Mild, Severe)
> as outcome variable, and two main effects: Age (two factors: twenty / thirty
> days old) and Treatment Group (four factors: infected without ATB; infected
> + ATB1; infected + ATB2; infected + ATB3).
> 
> First I tried to fit an ordinal regression model, which seems more
> appropriate given the characteristics of my dependent variable (ordinal).
> However, the assumption of odds proportionality was severely violated
> (graphically), which prompted me to use a multinomial model instead, using
> the "nnet" package.  
> 
> 
> First I chose the outcome level that I need to use as baseline category: 
> 
> Data$Path <- relevel(Data$Path, ref = "Absent")
> 
> Then, I needed to set baseline categories for the independent variables:
> 
> Data$Age <- relevel(Data$Age, ref = "Twenty") 
> Data$Treat <- relevel(Data$Treat, ref = "infected without ATB") 
> 
> The model:
> 
> test <- multinom(Path ~ Treat + Age, data = Data)
> # weights:  18 (10 variable)
> initial  value 128.537638 
> iter  10 value 80.623608
> final  value 80.619911 
> converged
> 
>> summary1 <- summary(test1)
>> summary1
> 
> Call:
> multinom(formula = Jej_fact ~ Treat + Age, data = Data)
> 
> Coefficients:
>         (Intercept)   infected+ATB1   infected+ATB2   infected+ATB3
> AgeThirty
> Moderate   -2.238106   -1.1738540      -1.709608       -1.599301
> 2.684677
> Severe     -1.544361   -0.8696531      -2.991307       -1.506709
> 1.810771
> 
> Std. Errors:
>         (Intercept)    infected+ATB1   infected+ATB2   infected+ATB3
> AgeThirty
> Moderate   0.7880046    0.8430368       0.7731359       0.7718480
> 0.8150993
> Severe     0.6110903    0.7574311       1.1486203       0.7504781
> 0.6607360
> 
> Residual Deviance: 161.2398 
> AIC: 181.2398
> 
> For a while, I could not find a way to get the p-values for the model and
> estimates when using nnet:multinom. Yesterday I came across a post where the
> author put forward a similar issue regarding estimation of p-values for
> coefficients
> (http://stats.stackexchange.com/questions/9715/how-to-set-up-and-estimate-a-
> multinomial-logit-model-in-r).
> 
> There, one blogger suggested that getting p-values from the summary() result
> of multinom() is pretty easy, by first getting the t values as follows: 
> 
> pt(abs(summary1$coefficients / summary1$standard.errors), df=nrow(Data)-10,
> lower=FALSE) 
> 
>         (Intercept)   infected+ATB1   infected+ATB2   infected+ATB3
> AgeThirty
> Moderate 0.002670340   0.08325396      0.014506395     0.02025858
> 0.0006587898
> Severe   0.006433581   0.12665278      0.005216581     0.02352202
> 0.0035612114
> 
> I AM NOT a statistician, so don't be baffled by a silly question! I this
> procedure correct?

There's at least a factor of 2 missing for a two-tailed p value. It is usually a mistake to use the t-distribution for what is really a z-statistic; for aggregated data, it can be a very bad mistake. However, it's not really an R question, and you obviously know where to find stackexchange... (local, professional advice would be even better, though.) 


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From katarzyna.kulma at gmail.com  Wed Jul  3 10:22:23 2013
From: katarzyna.kulma at gmail.com (Katarzyna Kulma)
Date: Wed, 3 Jul 2013 10:22:23 +0200
Subject: [R] MuMIn package: plotting averaged model estimates with CI
Message-ID: <CAHJzXMCO-mfg-iRkLqh8Tn2tqVq-qX+VMjUaywA1BoGAajb5wQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/cd882c6a/attachment.pl>

From eliano.m.marques at gmail.com  Wed Jul  3 10:53:51 2013
From: eliano.m.marques at gmail.com (Eliano Marques)
Date: Wed, 3 Jul 2013 09:53:51 +0100
Subject: [R] Package PLM
Message-ID: <CALeKeQ6j2auEPx2on35i9w_bXLeY6BiAOouFap0p88OCDzGxGg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/dd050b6b/attachment.pl>

From jholtman at gmail.com  Wed Jul  3 11:42:28 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Wed, 3 Jul 2013 05:42:28 -0400
Subject: [R] spped up a function
In-Reply-To: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
Message-ID: <C8B4CB13-E132-4D2F-8582-F0CD95A39AB4@gmail.com>

first thing to do when trying to speed up a function is to see where it is spending its time.  take a subset of the data and use Rprof to profile the code.  my guess is that a lot of time is taken up in the use of dataframes.  see if you can use matrices instead.

Sent from my iPad

On Jul 2, 2013, at 13:47, Santiago Guallar <sguallar at yahoo.com> wrote:

> Hi,
> 
> I have written a function to assign the values of a certain variable 'wd' from a dataset to another dataset. Both contain data from the same time period but differ in the length of their time intervals: 'GPS' has regular 10-minute intervals whereas 'xact' has irregular intervals. I attached simplified text versions from write.table. You can also get a dput of 'xact' in this address: http://www.megafileupload.com/en/file/431569/xact-dput.html).
> The original objects are large and the function takes almost one hour to finish.
> Here's the function:
> 
> fxG= function(xact, GPS){
> l <- rep( 'A', nrow(GPS) )
> v <- unique(GPS$Ring) # the process is carried out for several individuals identified by 'Ring'
> for(k in 1:length(v) ){
> I = v[k]
> df <- xact[xact$Ring == I,]
> for(i in 1:nrow(GPS)){
> if(GPS[i,]$Ring== I){# the code runs along the whole data.frame for each i; it'd save time to make it stop with the last record of each i instead
> u <- df$timepos <= GPS[i,]$timepos
> # fill vector l for each interval t from xact <= each interval from GPS (take the max if there's > 1 interval)
> l[i] <- df[max( which(u == TRUE) ),]$wd
> }
> }
> }
> return(l)}
> 
> vwd <- fxG(xact, GPS)
> 
> 
> My question is: how can I speed up (optimize) this function?
> 
> Thank you for your help
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tchen10 at qub.ac.uk  Wed Jul  3 13:37:08 2013
From: tchen10 at qub.ac.uk (tong)
Date: Wed, 3 Jul 2013 04:37:08 -0700 (PDT)
Subject: [R] nlrq with normal copula
Message-ID: <1372851428359-4670779.post@n4.nabble.com>

Dear all,

I want to run a nomal copula based quantile regression with XLS data.

I've worked out how to load xls data in r. 

the regression fumula is simply: y= a+bx+e  and the quantile curve is 

<http://r.789695.n4.nabble.com/file/n4670779/%E6%97%A0%E6%A0%87%E9%A2%98.png> 
 

I use:

> excel.file<-file.path("D:/dailyvix.xls")
> dailyvix<-readWorksheetFromFile(excel.file, sheet=1)
> names(dailyvix)
[1] "y" "x"
> fit1<-nlrq(y~qnorm(pnorm(mu*qnorm(pnorm(x))+sqrt(1-mu*mu)*qnorm(tau))),
> tau=0.5, data=dailyvix)

However, I get
Error in getInitial.default(func, data, mCall = as.list(match.call(func,  : 
  no 'getInitial' method found for "function" objects


I am a greenhand. I don't know how to deal with such error.

I really need help

Looking forward to any reply

Yours,

Tong



--
View this message in context: http://r.789695.n4.nabble.com/nlrq-with-normal-copula-tp4670779.html
Sent from the R help mailing list archive at Nabble.com.


From rnieuws at gmail.com  Wed Jul  3 13:55:01 2013
From: rnieuws at gmail.com (=?ISO-8859-1?Q?Andr=E9_de_Boer?=)
Date: Wed, 3 Jul 2013 13:55:01 +0200
Subject: [R] merge dataframes
Message-ID: <CAO06FDfecTOe_1S_EV37n2ZAhMPear+vUYbEHPXqzCYrezvLYw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/67722b82/attachment.pl>

From jholtman at gmail.com  Wed Jul  3 14:22:12 2013
From: jholtman at gmail.com (jim holtman)
Date: Wed, 3 Jul 2013 08:22:12 -0400
Subject: [R] merge dataframes
In-Reply-To: <CAO06FDfecTOe_1S_EV37n2ZAhMPear+vUYbEHPXqzCYrezvLYw@mail.gmail.com>
References: <CAO06FDfecTOe_1S_EV37n2ZAhMPear+vUYbEHPXqzCYrezvLYw@mail.gmail.com>
Message-ID: <CAAxdm-64tv_XhHBwXYRCym3E4+d5UcWYNENcZS7UDqRXXEq=iA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/20a476c7/attachment.pl>

From nashjc at uottawa.ca  Wed Jul  3 15:51:52 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 03 Jul 2013 09:51:52 -0400
Subject: [R] Non-linear modelling with several variables including a
 categorical variable
In-Reply-To: <mailman.25.1372845609.8485.r-help@r-project.org>
References: <mailman.25.1372845609.8485.r-help@r-project.org>
Message-ID: <51D42C78.50907@uottawa.ca>

If preytype is an independent variable, then models based on it should 
be OK. If preytype comes into the parameters you are trying to estimate, 
then the easiest way is often to generate all the possible combinations 
(integers --> fairly modest number of these) and run all the least 
squares minimizations. Crude but effective. nlxb from nlmrt or nlsLM 
from minpack.lm may be more robust in doing this, but less efficient if 
nls works OK.

JN

On 13-07-03 06:00 AM, r-help-request at r-project.org wrote:
> Message: 10
> Date: Tue, 2 Jul 2013 19:01:55 +0700
> From: Robbie Weterings<robbie.weterings at gmail.com>
> To:r-help at r-project.org
> Subject: [R] Non-linear modelling with several variables including a
> 	categorical variable
> Message-ID:
> 	<CAFe5dHZRM+BpG1v77EzHun+tacV64J_9pnSFGh_xne5CSZ9qdQ at mail.gmail.com>
> Content-Type: text/plain
>
> Hello everyone,
>
> I am trying to model some data regarding a predator prey interaction
> experiment (n=26). Predation rate is my response variable and I have 4
> explanatory variables: predator density (1,2,3,4 5), predator size, prey
> density (5,10,15,20,25,30) and prey type (3 categories). I started with
> several linear models (glm) and found (as expected) that prey and predator
> density were non-linear related to predation rates. If I use a log
> transformation on these variables I get really nice curves and an adjusted
> R2 of 0.82, but it is not really the right approach for modelling
> non-linear relationships. Therefore I switched to non-linear least square
> regression (nls). I have several predator-prey models based on existing
> ecological literature e.g.:
>
> model1 <- nls(rates ~ (a * prey)/(1 + b * prey), start = list(a = 0.27,b =
> 0.13), trace = TRUE) ### Holling's type II functional response
>
> model2 <- nls(rates ~ (a*prey)/(1+ (b * prey) + c * (pred -1 )), start =
> list(a=0.22451, b=-0.18938, c=1.06941), trace=TRUE, subset=I1) ###
> Beddington-**DeAngelis functional response
>
> These models work perfectly, but now I want to add prey type as well. In
> the linear models prey type was the most important variable so I don't want
> to leave it out. I understand that you can't add categorical variables in
> nls, so I thought I try a generalized additive model (gam).
>
> The problem with the gam models is that the smoothers (both spline and
> loess) don't work on both variables because there are only a very
> restricted number of values for prey density and predator density. I can
> manage to get a model with a single variable smoothed using loess. But for
> two variables it is simply not working. The spline function does not work
> at all because I have so few values (5) for my variables (see model 4).
>
> model3 <- gam(rates~ lo(pred, span=0.9)+prey) ## this one is actually
> working but does not include a smoother for prey.
>
> model4 <- gam(rates~ s(pred)+prey) ## this one gives problems:
> *A term has fewer unique covariate combinations than specified maximum
> degrees of freedom*
>
> My question is: are there any other possibilities to model data with 2
> non-linear related variables in which I can also include a categorical
> variable. I would prefer to use nls (model2) with for example different
> intercepts for each category but I'm not sure how to get this sorted, if it
> is possible at all. The dataset is too small to split it up into the three
> categories, moreover, one of the categories only contains 5 data points.
>
> Any help would be really appreciated.
>
> With kind regards,
> -- Robbie Weterings *Project Manager Cat Drop Thailand ** Tel:
> +66(0)890176087 * 65/13 Mooban Chakangrao, Naimuang Muang Kamphaeng Phet
> 62000, Thailand ?????? 65/13 ?.???????? ??? ??????????2 ??????? ??????/
> ??? ???????????????? ??????? ??????????? 62000
> <http://www.catdropfoundation.org>
> <http://www.catdropfoundation.org/facebook/Facebook.html>
> *www.catdropfoundation.org* <http://www.catdropfoundation.org/>
> *www.facebook.com/catdropfoundation*<http://www.facebook.com/catdropfoundation>
> *Boorn 45, 9204 AZ, Drachten, The Netherlands* [[alternative HTML
> version deleted]]


From birdada85 at gmail.com  Wed Jul  3 16:07:55 2013
From: birdada85 at gmail.com (Birdada Simret)
Date: Wed, 3 Jul 2013 16:07:55 +0200
Subject: [R] One-parameter fitting
Message-ID: <CA+YeWVsbYDiX=rMaYUHBhCrzGwfODE1mhvAUP35_-tLGh12_VQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/6ac8329c/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jul  3 16:17:44 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 03 Jul 2013 15:17:44 +0100
Subject: [R] One-parameter fitting
In-Reply-To: <CA+YeWVsbYDiX=rMaYUHBhCrzGwfODE1mhvAUP35_-tLGh12_VQ@mail.gmail.com>
References: <CA+YeWVsbYDiX=rMaYUHBhCrzGwfODE1mhvAUP35_-tLGh12_VQ@mail.gmail.com>
Message-ID: <51D43288.3090908@sapo.pt>

Hello,

Try ?mean

abline(h = mean(y), col = "blue")

Hope this helps,

Rui Barradas



Em 03-07-2013 15:07, Birdada Simret escreveu:
> Greetings to every body.
>
> we know that for linear regression: two-parameter fitting in R: (for a and
> b as slope and intercept)
>
> [a] for y=ax+b type models we use: lm(y~x)
> [b] for y=ax    type models we use:  lm(y~0+x)  => forced to pass through
> origin
>
> Now I have question:   what about y=b  fitting?  is there any model to
> force or  impose the ax to be zero
>
> Let say
>
> x <- c(1,2,3,4,5,6,7,8,9)
> y <- c( 0.853,0.852, 0.854, 0.858, 0.862, 0.856, 0.858, 0.857, 0.863)
> plot(y~x, xlim=c(0,10), ylim=c(0,1))
> abline(lm(y~x),col="blue")  # this doesn't give exact horizontal  but
> slightly inclined.
>
> or is it as simple as, just find the intercept using the lm(y~x) , then
> abline(h=intercept,col="red") ?
>
> any comment or advice is greatly appreciated ;)
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Wed Jul  3 16:18:07 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 3 Jul 2013 09:18:07 -0500
Subject: [R] merge dataframes
In-Reply-To: <CAAxdm-64tv_XhHBwXYRCym3E4+d5UcWYNENcZS7UDqRXXEq=iA@mail.gmail.com>
References: <CAO06FDfecTOe_1S_EV37n2ZAhMPear+vUYbEHPXqzCYrezvLYw@mail.gmail.com>
	<CAAxdm-64tv_XhHBwXYRCym3E4+d5UcWYNENcZS7UDqRXXEq=iA@mail.gmail.com>
Message-ID: <0eb801ce77f8$2384bee0$6a8e3ca0$@tamu.edu>

In addition to reading Frequently Asked Questions Section 7.31, you
should always run your own code before posting. Yours does not work.
Spend some time reading one or more of the R tutorials and learn
about vectorization. It will save you time and typing. There are
many to choose from at

http://cran.r-project.org/other-docs.html

Do not try to match decimal values. Instead create an index value
that is a character string. Then you can match the character
strings:

> dat1<-data.frame(x=c(1.0,1.2,3.2,4.0,5.1),y=c(23,17,12,27,8))
> dat2 <- data.frame(x=seq(0.1,6,by=0.1),y=rep(0,60)) # Errors in
your code corrected here
> dat1$xc <- sprintf("%1.1f", dat1$x, 1) # Create dat1 index value
as character
> dat2$xc <- sprintf("%1.1f", dat2$x, 1) # Create dat2 index value
as character
> dat2[match(dat1$xc, dat2$xc),] <- dat1 # update dat2 with dat1
> dat2[dat2$y>0,] # Check the results
     x  y  xc
10 1.0 23 1.0
12 1.2 17 1.2
32 3.2 12 3.2
40 4.0 27 4.0
51 5.1  8 5.1
> dat1
    x  y  xc
1 1.0 23 1.0
2 1.2 17 1.2
3 3.2 12 3.2
4 4.0 27 4.0
5 5.1  8 5.1

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of jim holtman
Sent: Wednesday, July 3, 2013 7:22 AM
To: Andr? de Boer
Cc: R mailing list
Subject: Re: [R] merge dataframes

FAQ 7.31


On Wed, Jul 3, 2013 at 7:55 AM, Andri de Boer <rnieuws at gmail.com>
wrote:

> Hello,
>
> I have two dataframes:
> dat1<-data.frame(x=c(1.0,1.2,3.2,4.0,5.1),y=c(23,17,12,27,8))
> dat2<-data.frame(x=seq(0,6,by=0.1),y=rep(0,60)))
>
> I want to replace the corresponding rows of dat2 with the ones of
dat1.
> I tried:
>
> for(i in 1:nrow(dat1))
> {
>   dat2[dat2$x==dat1[i,1],2]<-dat1[i,2]
> }
>
> But I discovered that not every 5.1 is equal:
>
> > dat2[52,1][1] 5.1> dat1[5,1][1] 5.1> dat2[52,1]==dat1[5,1][1]
FALSE
>
>
>
> How to solve this?
>
>
>
> Regards,
>
> Andri
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Wed Jul  3 16:25:16 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 03 Jul 2013 15:25:16 +0100
Subject: [R] merge dataframes
In-Reply-To: <0eb801ce77f8$2384bee0$6a8e3ca0$@tamu.edu>
References: <CAO06FDfecTOe_1S_EV37n2ZAhMPear+vUYbEHPXqzCYrezvLYw@mail.gmail.com>
	<CAAxdm-64tv_XhHBwXYRCym3E4+d5UcWYNENcZS7UDqRXXEq=iA@mail.gmail.com>
	<0eb801ce77f8$2384bee0$6a8e3ca0$@tamu.edu>
Message-ID: <51D4344C.6080709@sapo.pt>

Hello,

Or use ?all.equal.

all.equal(dat2[52, 1], dat1[5, 1])  # TRUE


Hope this helps,

Rui Barradas

Em 03-07-2013 15:18, David Carlson escreveu:
> In addition to reading Frequently Asked Questions Section 7.31, you
> should always run your own code before posting. Yours does not work.
> Spend some time reading one or more of the R tutorials and learn
> about vectorization. It will save you time and typing. There are
> many to choose from at
>
> http://cran.r-project.org/other-docs.html
>
> Do not try to match decimal values. Instead create an index value
> that is a character string. Then you can match the character
> strings:
>
>> dat1<-data.frame(x=c(1.0,1.2,3.2,4.0,5.1),y=c(23,17,12,27,8))
>> dat2 <- data.frame(x=seq(0.1,6,by=0.1),y=rep(0,60)) # Errors in
> your code corrected here
>> dat1$xc <- sprintf("%1.1f", dat1$x, 1) # Create dat1 index value
> as character
>> dat2$xc <- sprintf("%1.1f", dat2$x, 1) # Create dat2 index value
> as character
>> dat2[match(dat1$xc, dat2$xc),] <- dat1 # update dat2 with dat1
>> dat2[dat2$y>0,] # Check the results
>       x  y  xc
> 10 1.0 23 1.0
> 12 1.2 17 1.2
> 32 3.2 12 3.2
> 40 4.0 27 4.0
> 51 5.1  8 5.1
>> dat1
>      x  y  xc
> 1 1.0 23 1.0
> 2 1.2 17 1.2
> 3 3.2 12 3.2
> 4 4.0 27 4.0
> 5 5.1  8 5.1
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of jim holtman
> Sent: Wednesday, July 3, 2013 7:22 AM
> To: Andr? de Boer
> Cc: R mailing list
> Subject: Re: [R] merge dataframes
>
> FAQ 7.31
>
>
> On Wed, Jul 3, 2013 at 7:55 AM, Andri de Boer <rnieuws at gmail.com>
> wrote:
>
>> Hello,
>>
>> I have two dataframes:
>> dat1<-data.frame(x=c(1.0,1.2,3.2,4.0,5.1),y=c(23,17,12,27,8))
>> dat2<-data.frame(x=seq(0,6,by=0.1),y=rep(0,60)))
>>
>> I want to replace the corresponding rows of dat2 with the ones of
> dat1.
>> I tried:
>>
>> for(i in 1:nrow(dat1))
>> {
>>    dat2[dat2$x==dat1[i,1],2]<-dat1[i,2]
>> }
>>
>> But I discovered that not every 5.1 is equal:
>>
>>> dat2[52,1][1] 5.1> dat1[5,1][1] 5.1> dat2[52,1]==dat1[5,1][1]
> FALSE
>>
>>
>>
>> How to solve this?
>>
>>
>>
>> Regards,
>>
>> Andri
>>
>>          [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>


From S.Ellison at LGCGroup.com  Wed Jul  3 16:28:30 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 3 Jul 2013 15:28:30 +0100
Subject: [R] One-parameter fitting
In-Reply-To: <CA+YeWVsbYDiX=rMaYUHBhCrzGwfODE1mhvAUP35_-tLGh12_VQ@mail.gmail.com>
References: <CA+YeWVsbYDiX=rMaYUHBhCrzGwfODE1mhvAUP35_-tLGh12_VQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9F86F03@GOLD.corp.lgc-group.com>

> Now I have question:   what about y=b  fitting?  is there any model to
> force or  impose the ax to be zero

Rui Barradas has answered correctly for a simple lm case.

You can also do 
lm(y~1) to obtain an estimated mean.
 
That formulation happens to be quite useful if you are interested in a purely random-effects model* fitted using, say, lme, though you won't generally get a simple mean for unbalanced data in such a case.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From birdada85 at gmail.com  Wed Jul  3 16:36:28 2013
From: birdada85 at gmail.com (Birdada Simret)
Date: Wed, 3 Jul 2013 16:36:28 +0200
Subject: [R] One-parameter fitting
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4AC9F86F03@GOLD.corp.lgc-group.com>
References: <CA+YeWVsbYDiX=rMaYUHBhCrzGwfODE1mhvAUP35_-tLGh12_VQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F86F03@GOLD.corp.lgc-group.com>
Message-ID: <CA+YeWVsbVv_9spXkRHzcYXpzxHX2c7m7spD=YZAdwvS4GziHNg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/c2348954/attachment.pl>

From sds at gnu.org  Wed Jul  3 17:33:47 2013
From: sds at gnu.org (Sam Steingold)
Date: Wed, 03 Jul 2013 11:33:47 -0400
Subject: [R] promise already under evaluation
Message-ID: <87obajfyjo.fsf@gnu.org>

Hi, I asked this question on SO but got no answers:
http://stackoverflow.com/questions/17310825/r-promise-already-under-evaluation

I understand that you are probably sick and tired of answering the same question again, 
but I am still getting the error discussed in several other questions:

>>> promise already under evaluation: recursive default argument reference or earlier problems?

even though I did follow the "cumbersome" advice of prepending ".":

--8<---------------cut here---------------start------------->8---
show.large.objects.threshold <- 100000
show.large.objects.exclude <- c("closure")
show.large.objects <- function (.envir = sys.frame(),
                                threshold = show.large.objects.threshold,
                                exclude = show.large.objects.exclude) {
  for (n in print(ls(.envir, all.names = TRUE))) tryCatch({
    o <- get(n,envir = .envir)
    s <- object.size(o)
    if (s > threshold && !(typeof(o) %in% exclude)) {
      cat(n,": ")
      print(s,units="auto")
    }
  }, error = function(e) { cat("n=",n,"\n"); print(e) })
}
show.large.objects.stack <- function (threshold = show.large.objects.threshold,
                                      skip.levels = 1,# do not examine the last level - this function
                                      exclude = show.large.objects.exclude) {
  for (level in 1:(sys.nframe()-skip.levels)) {
    cat("*** show.large.objects.stack(",level,") ")
    print(sys.call(level))
    show.large.objects(.envir = sys.frame(level))
  }
}
--8<---------------cut here---------------end--------------->8---

but I still get errors:

--8<---------------cut here---------------start------------->8---
> f <- function () { c <- 1:1e7; d <- 1:1e6; print(system.time(show.large.objects.stack())) }
> f()
*** show.large.objects.stack( 1 ) f()
[1] "c" "d"
c : 38.1 Mb
d : 3.8 Mb
*** show.large.objects.stack( 2 ) print(system.time(show.large.objects.stack()))
[1] "..." "x"  
n= ... 
<simpleError in get(n, envir = .envir): argument "..." is missing, with no default>
n= x 
<simpleError in get(n, envir = .envir): promise already under evaluation: recursive default argument reference or earlier problems?>
*** show.large.objects.stack( 3 ) system.time(show.large.objects.stack())
[1] "expr"    "gcFirst" "ppt"     "time"   
n= expr 
<simpleError in get(n, envir = .envir): promise already under evaluation: recursive default argument reference or earlier problems?>
          user         system        elapsed 
    0 (0.00ms)     0 (0.00ms) 0.002 (2.00ms) 
--8<---------------cut here---------------end--------------->8---

So, what am I still doing wrong?
Do I really need the . in .envir?
Why do I get the [[argument "..." is missing, with no default]] error?
Why do I get the [[promise already under evaluation]] error?
What is the right way to pass threshold and exclude from
show.large.objects.stack to show.large.objects?

Thanks!

PS. I would prefer an answer on SO, but please feel free to reply using any
venue you like and I will copy your explanation to the other venues.

-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://iris.org.il http://mideasttruth.com
http://honestreporting.com http://openvotingconsortium.org
Linux - find out what you've been missing while you've been rebooting Windows.


From sds at gnu.org  Wed Jul  3 19:12:58 2013
From: sds at gnu.org (Sam Steingold)
Date: Wed, 03 Jul 2013 13:12:58 -0400
Subject: [R] promise already under evaluation
In-Reply-To: <87obajfyjo.fsf@gnu.org> (Sam Steingold's message of "Wed, 03 Jul
	2013 11:33:47 -0400")
References: <87obajfyjo.fsf@gnu.org>
Message-ID: <87bo6jftyd.fsf@gnu.org>

> * Sam Steingold <fqf at tah.bet> [2013-07-03 11:33:47 -0400]:
>
> Hi, I asked this question on SO but got no answers:
> http://stackoverflow.com/questions/17310825/r-promise-already-under-evaluation

Backlin explained on SO that the errors are to be expected: "..." is a
formal argument which was not supplied and "expr" and "x" were actually
being evaluated at the time of get() call.

The bottom line is that I must catch and ignore errors.

The remaining problem is: how do I pass the same arguments down?

e.g.,

--8<---------------cut here---------------start------------->8---
f <- function (... verbose=FALSE ...) { ... }
g <- function (... verbose=FALSE ...) { ... f(... verbose=verbose ...) ... }
--8<---------------cut here---------------end--------------->8---

results in "promise already under evaluation" (and, yes, I do understand
why).

is there anything better than

--8<---------------cut here---------------start------------->8---
f <- function ( ... f.verbose=FALSE ... ) { ... }
g <- function ( ... g.verbose=FALSE ... ) { ... f(... f.verbose=g.verbose ...) ... }
--8<---------------cut here---------------end--------------->8---


-- 
Sam Steingold (http://sds.podval.org/) on Ubuntu 13.04 (raring) X 11.0.11303000
http://www.childpsy.net/ http://www.memritv.org http://mideasttruth.com
http://honestreporting.com http://think-israel.org http://jihadwatch.org
Incorrect time synchronization.


From chiefmurphy at gmail.com  Wed Jul  3 19:38:02 2013
From: chiefmurphy at gmail.com (Dan Murphy)
Date: Wed, 3 Jul 2013 10:38:02 -0700
Subject: [R] Splitting a string expression into components
Message-ID: <CAHgH9_Gn+mzJF7vM0PgWDYEZPVG1=2QCTY2BjWLHJVAHwJ2OWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/4c21e5e5/attachment.pl>

From wdunlap at tibco.com  Wed Jul  3 19:55:01 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 3 Jul 2013 17:55:01 +0000
Subject: [R] Splitting a string expression into components
In-Reply-To: <CAHgH9_Gn+mzJF7vM0PgWDYEZPVG1=2QCTY2BjWLHJVAHwJ2OWg@mail.gmail.com>
References: <CAHgH9_Gn+mzJF7vM0PgWDYEZPVG1=2QCTY2BjWLHJVAHwJ2OWg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C30FAFF@PA-MBX01.na.tibco.com>

If your syntax is like R's syntax then parse() can help.
  R> p <- parse(text="z = 1 + 2")
  R> p[[1]] # the first (& only) expression in "z = 1 + 2"
  z = 1 + 2
  R> as.list(p[[1]]) # the 'function' called (`=`) and its 'arguments'
  [[1]]
  `=`
  
  [[2]]
  z
  
  [[3]]
  1 + 2
  
  R> as.list(p[[1]][[3]]) # ditto for the 2nd argument above
  [[1]]
  `+`

  [[2]]
  [1] 1
  
  [[3]]
  [1] 2

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Dan Murphy
> Sent: Wednesday, July 03, 2013 10:38 AM
> To: R-help at r-project.org
> Subject: [R] Splitting a string expression into components
> 
> I have a vector of strings that contain mathematical expressions. E.g.,
> x <- c("5 <= 7", "z = 1+2")
> and I would like to decompose each expression into its left- and
> right-hand-side components etc., output something like
> 
> "5" "<=" "7"
> "z" "=" "1" "+" "2"
> 
> Is there something built into the R language to accomplish this?
> Thanks for advance.
> Dan
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Wed Jul  3 20:13:15 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 3 Jul 2013 11:13:15 -0700
Subject: [R] Splitting a string expression into components
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C30FAFF@PA-MBX01.na.tibco.com>
References: <CAHgH9_Gn+mzJF7vM0PgWDYEZPVG1=2QCTY2BjWLHJVAHwJ2OWg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C30FAFF@PA-MBX01.na.tibco.com>
Message-ID: <CACk-te1VRn8rr27CCLOHPQ6OMNjTej-X16v539V2LXauTKCuxg@mail.gmail.com>

Alternatively, perhaps strsplit() with an appropriate regex argument.

See ?strsplit ?regexp

e.g.

strsplit ("z<=5",split = "[<>=]+")
[[1]]
[1] "z" "5"

This of course will only work if you know what the characters are that
define "left" and "right", how complex the expressions might be, etc.
-- i.e. the simple case.

-- Bert

On Wed, Jul 3, 2013 at 10:55 AM, William Dunlap <wdunlap at tibco.com> wrote:
> If your syntax is like R's syntax then parse() can help.
>   R> p <- parse(text="z = 1 + 2")
>   R> p[[1]] # the first (& only) expression in "z = 1 + 2"
>   z = 1 + 2
>   R> as.list(p[[1]]) # the 'function' called (`=`) and its 'arguments'
>   [[1]]
>   `=`
>
>   [[2]]
>   z
>
>   [[3]]
>   1 + 2
>
>   R> as.list(p[[1]][[3]]) # ditto for the 2nd argument above
>   [[1]]
>   `+`
>
>   [[2]]
>   [1] 1
>
>   [[3]]
>   [1] 2
>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
>> Of Dan Murphy
>> Sent: Wednesday, July 03, 2013 10:38 AM
>> To: R-help at r-project.org
>> Subject: [R] Splitting a string expression into components
>>
>> I have a vector of strings that contain mathematical expressions. E.g.,
>> x <- c("5 <= 7", "z = 1+2")
>> and I would like to decompose each expression into its left- and
>> right-hand-side components etc., output something like
>>
>> "5" "<=" "7"
>> "z" "=" "1" "+" "2"
>>
>> Is there something built into the R language to accomplish this?
>> Thanks for advance.
>> Dan
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From A.Serebrenik at tue.nl  Wed Jul  3 21:24:26 2013
From: A.Serebrenik at tue.nl (aserebrenik)
Date: Wed, 3 Jul 2013 12:24:26 -0700 (PDT)
Subject: [R] Academic study of R users and developers
Message-ID: <1372879466908-4670797.post@n4.nabble.com>

Dear all,

A group of researchers from Eindhoven Univ of Technology (The Netherlands)
and UC Davis (USA) is conducting a study of support activities in R. In this
study, our goal is to understand how R user support activities have been
evolving over time, in the presence of different information exchange media,
such as mailing lists, forums, blogs or question&answer websites. 

Your participation is voluntary and confidential. If you agree to
participate, you will be asked to complete self-report measures that tell us
a bit about your information seeking and information providing experiences
related to R. Participation in this study is expected to take about 10
minutes of your time.

We thank you in advance for your participation in this study. We plan to
include the results of this survey in a scientific publication. Individual
responses cannot be traced back to an individual respondent.

https://docs.google.com/forms/d/14dXaSdy2NJ94Fq50fAbmEr3_GK8XfbRdys9qPLMMZ-c/viewform
<https://docs.google.com/forms/d/14dXaSdy2NJ94Fq50fAbmEr3_GK8XfbRdys9qPLMMZ-c/viewform>  

Best regards,
Alexander Serebrenik
Eindhoven Univ Technology
The Netherlands



--
View this message in context: http://r.789695.n4.nabble.com/Academic-study-of-R-users-and-developers-tp4670797.html
Sent from the R help mailing list archive at Nabble.com.


From Hadley.Wickham at r-project.org  Tue Jul  2 20:32:01 2013
From: Hadley.Wickham at r-project.org (Hadley Wickham)
Date: Tue, 2 Jul 2013 13:32:01 -0500
Subject: [R] The R Journal, Volume 5, Issue 1
Message-ID: <CABdHhvHVCeB6d9P=UFHHmSER7e-8mY7ObQmiP2XHpEw1Pw6CNg@mail.gmail.com>

Dear all,

The latest issue of The R Journal is now available at
http://journal.r-project.org/archive/2013-1/

Many thanks to all contributors.

Hadley

--
Editor-in-chief, The R Journal

_______________________________________________
R-announce at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-announce


From schaefe9 at informatik.uni-bonn.de  Wed Jul  3 16:16:37 2013
From: schaefe9 at informatik.uni-bonn.de (schaefe9 at informatik.uni-bonn.de)
Date: Wed, 3 Jul 2013 16:16:37 +0200
Subject: [R] qtlnet mcmc.qtlnet sample genetic architeture and QTL network
Message-ID: <37b80d6c560bd1f00369f7270fcea0b1.squirrel@webmail.iai.uni-bonn.de>

Im working with the "qtlnet" package and want to sample the genetic
architecture and QTL network. I aiming to do this with the function
qtlnet:::mcmc.qtlnet. So far so good. However I cant do it with my own
cross dataset. data(Pscdbp) works fine, but not my own. I mean it is from
class "cross". However, I receive the error:

Error in dimnames(geno.dat)[[2]] <- tmp : 'dimnames' must be a list

Can anybody help me out? I uploaded my crossdata here:

http://www.risclab.com/cross_gpsm.RData

Would be awesome if somebody could help me out


From smartpink111 at yahoo.com  Wed Jul  3 13:37:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 3 Jul 2013 04:37:13 -0700 (PDT)
Subject: [R] Subsetting multiple rows of a data frame at once
Message-ID: <1372851433.26315.YahooMailNeo@web142605.mail.bf1.yahoo.com>


Hi,
Try this:

set.seed(24)
df<- data.frame(x=sample(seq(0.25,4.25,by=.05),1e5,replace=TRUE),y= sample(seq(0.10,1.05,by=.05),1e5,replace=TRUE),z=rnorm(1e5))

#Used a shorter vector 
x1<- c(1.05,2.85,3.40,4.25,0.25)
y1<- c(0.25,0.10,0.90,0.25,1.05)

res<-do.call(rbind,lapply(seq_along(x1),function(i) subset(df,x==x1[i]&y==y1[i])))
head(res,2)
#??????? x??? y????????? z
#466? 1.05 0.25? 0.7865224
#4119 1.05 0.25 -1.5679096
?tail(res,2)
#???????? x??? y????????? z
#98120 0.25 1.05 -2.1239596
#98178 0.25 1.05? 0.3321464


A.K.

Hi Everyone, 

First time poster so any posting rules i should know about feel free to advise... 

I've got a data frame of 250 000 rows in columns of x y and z. 

i need to extract 20-30 rows from the data frame with specific x
 and y values, such that i can find the z value that corresponds. There 
is no repeated data. (its actually 250 000 squares in a 5x5m grid) 

to find them individually i can use subset successfully 

result<-subset(df,x==1.05 & y==c0.25) 

gives me the row in the dataframe with that x and y value. 

so if i have 

x = 1.05 2.85 3.40 4.25 0.25 3.05 3.70 0.20 0.30 0.70 1.05 1.20 
1.40 1.90 2.70 3.25 3.55 4.60 2.05 2.15 3.70 4.85 4.90 1.60 2.45 3.20 
3.90 4.45 

and 

y= 0.25 0.10 0.90 0.25 1.05 1.70 2.05 2.90 2.35 2.60 2.55 2.15 
2.75 2.05 2.70 2.25 2.55 2.05 3.65 3.05 3.00 3.50 3.75 4.85 4.50 4.50 
3.35 4.90 

then how can i retrieve the rows for all those values at once. 

if i name x=xt and y=yt and then 

result<-subset(df,x==xt & y==yt) 

then i get 

result 
[1] x ? ? ?y ? ? ?Height 
<0 rows> (or 0-length row.names) 

i dont understand why zero rows are selected. obviously im 
applying the vectors inappropriately, but i cant seem to find anything 
on this method of subsetting online. 

Thanks for any replies!   



From m.w.heerdink at uva.nl  Wed Jul  3 14:15:18 2013
From: m.w.heerdink at uva.nl (Marc Heerdink)
Date: Wed, 03 Jul 2013 14:15:18 +0200
Subject: [R] Meta-analysis on a repeated measures design with multiple
 trials per subject using metafor
Message-ID: <51D415D6.5070201@uva.nl>

Hi all,

I am currently attempting to compile a summary of a series of five 
psychological experiments, and I am trying to do this using the metafor 
package. However, I am quite unsure which of the scenarios described in 
the metafor help pages applies to these data, because it is a repeated 
measures design, with multiple trials in each condition.

Assume that for every participant, I have a basic contingency table such 
as this one:

		treatment
		1   	2
response	
1		10 	20
2		20	10

(if this ASCII version does not work, I have 30 trials in each 
treatment, and participants give either response 1 or 2; the exact 
numbers don't matter)

The problem that I am trying to solve is how to convert these numbers to 
an effect size estimate that I can use with metafor.

As far as I understand it, I can only use it to get an effect size for 
outcomes that are dichotomous; i.e., either 1 or 0 for any subject. 
However, I have proportion data for every participant.

I have considered and tried these strategies:

1. Base the effect size on within-participant proportion differences. 
That is, in the table above, the treatment effect would be 
(20/30)-(10/30) = 1/3; and I would take the M and SD of these values to 
estimate a study-level effect ("MN" measure in metafor).

2. Use the overall treatment * response contingency table, ignoring the 
fact that these counts come from different participants ("PHI" or "OR" 
measures in metafor). In a study with 10 participants, I would get cell 
counts around 150.

However, from the research I've done into this topic, I know that 1) is 
not applicable to (as far as I understand) an odds ratio, and I suspect 
2) overestimates the effect.

A third method would be to use the regression coefficients, that I can 
easily obtain since I have all the raw data that I need. However, it is 
unclear to me whether and if yes, how I can use these in the metafor 
package.

 From my understanding of another message about this topic I found on 
this list (1), I understand that having access to the raw data is an 
advantage, but I am not sure whether the scenario mentioned applies to 
my situation.

1: 
http://r.789695.n4.nabble.com/meta-analysis-with-repeated-measure-designs-td2252644.html

I would very much appreciate any suggestions or hints on this topic.

Regards,
Marc


From Thomas.deMarchin at ulg.ac.be  Wed Jul  3 14:51:13 2013
From: Thomas.deMarchin at ulg.ac.be (Thomas de Marchin)
Date: Wed, 03 Jul 2013 14:51:13 +0200
Subject: [R]  nls.profile
In-Reply-To: <1301562136.3212.8.camel@dkubuntu-laptop>
References: <1301562136.3212.8.camel@dkubuntu-laptop>
Message-ID: <51D41E41.70004@ulg.ac.be>

Hello Daniel,

I have the same problem than you : i use nls.profile to compute 
confidence intervals of estimated parameters but it fails and stop...
I tried to increase alphamax value as Douglas suggested that it should 
work but it's not...

Did you find a method to tell nls.profile to ignore errors and proceed 
to the next parameter value ?

Thank you very much!


-- 
Thomas de Marchin
PhD Student
Laboratory of Bioenergetics
University of Li?ge, Institute of Botany (B.22-P.70)
Bld du Rectorat, 27
Sart Tilman, 4000 Li?ge, Belgium
Tel: +32 (0)4 366 38 08
http://www.biophoto.ulg.ac.be


From zsurzsalaszlo at gmail.com  Wed Jul  3 16:27:31 2013
From: zsurzsalaszlo at gmail.com (Zsurzsa Laszlo)
Date: Wed, 3 Jul 2013 16:27:31 +0200
Subject: [R] String based chemical name identification
Message-ID: <CAF4U=Vm+5Yv3pEgMV6eKNVKSSOriCrz6xE694_YKLDFP3beZpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/93fdcdbb/attachment.pl>

From zhyjiang2006 at hotmail.com  Wed Jul  3 23:27:05 2013
From: zhyjiang2006 at hotmail.com (JiangZhengyu)
Date: Thu, 4 Jul 2013 05:27:05 +0800
Subject: [R] change cell values
Message-ID: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/f7a569a3/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jul  3 23:38:37 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 03 Jul 2013 22:38:37 +0100
Subject: [R] change cell values
In-Reply-To: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>
References: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>
Message-ID: <51D499DD.4060500@sapo.pt>

Hello,

It's not working because you are changing mat1 before the second 
condition is evaluated, and so mat1 is full of NA values. Try the following.



tmp <- mat1  # Make a copy
tmp[mat1 < 1 & mat2 < 1] <- NA  # And change that copy
mat2[mat1 < 1 & mat2 < 1] <- NA
mat1 <- tmp
rm(tmp)


Hope this helps,

Rui Barradas

Em 03-07-2013 22:27, JiangZhengyu escreveu:
>
>
>
> Dear R experts,
>
> I have two  matrices (mat1 & mat2) with the same dimension & the cells (row and column) are corresponding to each other.
>
> I want to change cell values to NA given values of the corresponding cells in mat1 and mat2 are both <1.
>
> E.g. both mat1[2,3] and mat2[2,3] are <1, I will put mat1[2,3]=NA, and mat2[2,3]=NA; if either mat1[2,3]>=1 or  mat2[2,3]>=1, I will save both cells.
>
> I tried the code, but not working. Could anyone can help fix the problem?
>
> mat1[mat1<1&mat2<1]=NA
> mat2[mat1<1&mat2<1]=NA
>
>
>> mat1=matrix(rnorm(12),3)
>> mat2=matrix(rnorm(12),3)
>> mat1
>             [,1]       [,2]       [,3]       [,4]
> [1,] -1.3387075 -0.7142333 -0.5614211  0.1846955
> [2,] -0.7936087 -0.2215797 -0.3686067  0.7328731
> [3,]  0.6505082  0.1826019  1.5577883 -1.5580384
>> mat2
>             [,1]       [,2]       [,3]       [,4]
> [1,]  0.4331573 -1.8086826 -1.7688123 -1.4278934
> [2,] -0.1841451  0.1738648 -1.1086942  1.3065109
> [3,] -1.0827245 -0.4143808 -0.6889405  0.4046203
>
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From zhyjiang2006 at hotmail.com  Wed Jul  3 23:43:54 2013
From: zhyjiang2006 at hotmail.com (JiangZhengyu)
Date: Thu, 4 Jul 2013 05:43:54 +0800
Subject: [R] change cell values
In-Reply-To: <51D499DD.4060500@sapo.pt>
References: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>,
	<51D499DD.4060500@sapo.pt>
Message-ID: <SNT135-W65DD865F9AA5A164F75038CB730@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/d115077b/attachment.pl>

From yelin at lbl.gov  Wed Jul  3 23:45:16 2013
From: yelin at lbl.gov (Ye Lin)
Date: Wed, 3 Jul 2013 14:45:16 -0700
Subject: [R] modify timestemp
Message-ID: <CAAvu=bmyXVW3gmTFQbG7fLKvLeDFPW_sSkFBXO23jG0nuDyc+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/e4d68ccd/attachment.pl>

From dwinsemius at comcast.net  Wed Jul  3 23:48:33 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 3 Jul 2013 14:48:33 -0700
Subject: [R] change cell values
In-Reply-To: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>
References: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>
Message-ID: <7FE36EAF-9017-423D-8F0D-EBC3AB2C2512@comcast.net>


On Jul 3, 2013, at 2:27 PM, JiangZhengyu wrote:

> 
> 
> 
> Dear R experts,
> 
> I have two  matrices (mat1 & mat2) with the same dimension & the cells (row and column) are corresponding to each other.
> 
> I want to change cell values to NA given values of the corresponding cells in mat1 and mat2 are both <1.
> 
> E.g. both mat1[2,3] and mat2[2,3] are <1, I will put mat1[2,3]=NA, and mat2[2,3]=NA; if either mat1[2,3]>=1 or  mat2[2,3]>=1, I will save both cells.
> 
> I tried the code, but not working. Could anyone can help fix the problem?
> 
> mat1[mat1<1&mat2<1]=NA
> mat2[mat1<1&mat2<1]=NA

I beleive the problem is that after the first NA assignment that mat1 will have changed. You need to record the status of both mat1 and mat2 before the change:

> both <- mat1<1&mat2<1  
>  both
      [,1]  [,2]  [,3] [,4]
[1,] FALSE FALSE  TRUE TRUE
[2,]  TRUE FALSE  TRUE TRUE
[3,] FALSE  TRUE FALSE TRUE
> 
> mat1[both] <- NA
> mat2[both] <- NA
> mat1
           [,1]      [,2]     [,3] [,4]
[1,]  1.5599872  2.209537       NA   NA
[2,]         NA -1.144140       NA   NA
[3,] -0.8516326        NA 1.000368   NA
> mat2
          [,1]       [,2]     [,3] [,4]
[1,] 0.8863107 -0.3863741       NA   NA
[2,]        NA  1.3185811       NA   NA
[3,] 1.4487338         NA 1.051689   NA

There is also formalism:

is.na(object) <- logical.vector so it could have been:

is.na(mat1) <- both
is.na(mat2) <- both


> 
> 
>> mat1=matrix(rnorm(12),3)
>> mat2=matrix(rnorm(12),3)
>> mat1
>           [,1]       [,2]       [,3]       [,4]
> [1,] -1.3387075 -0.7142333 -0.5614211  0.1846955
> [2,] -0.7936087 -0.2215797 -0.3686067  0.7328731
> [3,]  0.6505082  0.1826019  1.5577883 -1.5580384
>> mat2
>           [,1]       [,2]       [,3]       [,4]
> [1,]  0.4331573 -1.8086826 -1.7688123 -1.4278934
> [2,] -0.1841451  0.1738648 -1.1086942  1.3065109
> [3,] -1.0827245 -0.4143808 -0.6889405  0.4046203
> 
> 		 	   		  
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From friendly at yorku.ca  Wed Jul  3 23:55:50 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 03 Jul 2013 17:55:50 -0400
Subject: [R] converting a list of loglin terms to a model formula
Message-ID: <51D49DE6.8010103@yorku.ca>

I'm developing some functions to create symbolic specifications for 
loglinear models of different types.
I don't really know how to 'compute' with model formulas, so I've done 
this in the notation
for stats::loglin(), which is a list of high-order terms in the model.

What I'd like is a function to turn the results of these into a model 
formula, suitable for
MASS::loglm.  That's the reverse of what loglm does.

For example, the simplest versions of models for 3-way tables for joint,
  conditional, and marginal independence can be computed as follows. 
After each, I indicated
the WANTED model formula I'd like from the result

 > joint(3)
$term1
[1] 1 2

$term2
[1] 3

WANTED:  ~ 1:2 + 3

 > condit(3)
$term1
[1] 1 3

$term2
[1] 2 3

WANTED: ~ 1:2 + 2:3

 > mutual(3)
$term1
[1] 1

$term2
[1] 2

$term3
[1] 3

WANTED: ~ 1 + 2 + 3

In case anyone want to play with the code, here are the current, not too 
elegant definitions
of the functions, and some further test cases,

# models of joint independence
   joint <- function(nf, factors=1:nf, with=nf) {
     if (nf == 1) return (list(term1=factors[1]))
     if (nf == 2) return (list(term1=factors[1], term2=factors[2]))
     others <- setdiff(1:nf, with)
     result <- list(term1=factors[others], term2=factors[with])
     result
   }
# conditional independence
   condit <- function(nf, factors=1:nf, with=nf) {
     if (nf == 1) return (list(term1=factors[1]))
     if (nf == 2) return (list(term1=factors[1], term2=factors[2]))
     main <- setdiff(1:nf, with)
     others <- matrix(factors[with], length(with), length(main))
     result <- rbind(factors[main], others)
     result <- as.list(as.data.frame(result, stringsAsFactors=FALSE))
     names(result) <- paste('term', 1:length(result), sep='')
     result
   }
# mutual independence
   mutual <- function(nf, factors=1:nf) {
     result <- sapply(factors[1:nf], list)
     names(result) <- paste('term', 1:length(result), sep='')
     result
   }

### some comparisons

loglin(HairEyeColor, list(c(1, 2), c(1, 3), c(2, 3)))$lrt
loglm(~1:2 + 1:3 +2:3, HairEyeColor)

# use factor names
joint(3, factors=names(dimnames(HairEyeColor)))
condit(3, factors=names(dimnames(HairEyeColor)))

loglin(HairEyeColor, joint(3))$lrt
loglm(~1:2 + 3, HairEyeColor)

loglin(HairEyeColor, condit(3))$lrt
loglm(~1:3 + 2:3, HairEyeColor)



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From Jason.Law at portlandoregon.gov  Thu Jul  4 00:21:59 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Wed, 3 Jul 2013 15:21:59 -0700
Subject: [R] String based chemical name identification
In-Reply-To: <CAF4U=Vm+5Yv3pEgMV6eKNVKSSOriCrz6xE694_YKLDFP3beZpA@mail.gmail.com>
References: <CAF4U=Vm+5Yv3pEgMV6eKNVKSSOriCrz6xE694_YKLDFP3beZpA@mail.gmail.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184E53F197A@MAIL2.rose.portland.local>

Might be better off using a web service like ChemSpider to do the matching for you <http://www.chemspider.com/AboutServices.aspx?>.  The idea that you can identify the synonyms by name is probably optimistic unless they are exact matches.

Here's some python code that seems to make it pretty easy: https://github.com/mcs07/ChemSpiPy.  Search the names, extract the InChI for the best match and then you can match them in R via the InChI.  Might require some fixing by hand afterwards.

HTH,

Jason Law

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Zsurzsa Laszlo
Sent: Wednesday, July 03, 2013 7:28 AM
To: r-help at r-project.org
Subject: [R] String based chemical name identification

The problem is the following:

I have two big databases one look like this:

  2-Methyl-4-trimethylsilyloxyoct-5-yne   Benzoic acid, methyl ester   Benzoic
acid, 2-methyl-, methyl ester   Acetic acid, phenylmethyl ester
 2,7-Dimethyl-4-trimethylsilyloxyoct-7-en-5-yne   etc.

The second one looks like this:

 Name: D-Tagatose 1,6-bisphosphate  Name: 1-Phosphatidyl-D-myo-inositol;:
1-Phosphatidyl-1D-myo-inositol;: 1-Phosphatidyl-myo-inositol;:
Phosphatidyl-1D-myo-inositol;: (3-Phosphatidyl)-1-D-inositol;:
1,2-Diacyl-sn-glycero-3-phosphoinositol;: Phosphatidylinositol  Name:
Androstenedione;: Androst-4-ene-3,17-dione;: 4-Androstene-3,17-dione  Name:
Spermine;: N,N'-Bis(3-aminopropyl)-1,4-butanediamine  Name: H+;: Hydron  Name:
3-Iodo-L-tyrosine  etc.

Both of them have more then 3000 lines. Matching their name by hand is not an option because I don't know chemistry.

*Possible solution I came up with*:

Go through all the names of the first database and then try to match with the other one. I'm using *regexec *and *strsplit *functions for the matching. Basically I split the name into small chunks and try to get some hit in the other database.

I can supply code If needed but I did not want to spam in the first mail.


Any solution is welcome! It can be in pseudo-cod also or in any type of logical arguing. It does not matter.


Laszlo-Andras Zsurzsa

Msc. Informatics, Technical University Munchen

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul  3 23:48:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 3 Jul 2013 14:48:14 -0700 (PDT)
Subject: [R] change cell values
In-Reply-To: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>
References: <SNT135-W414A9BD1C5C0E85AF050E4CB730@phx.gbl>
Message-ID: <1372888094.14328.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

set.seed(24) 
mat1=matrix(rnorm(12),3)
set.seed(28)
mat2=matrix(rnorm(12),3)
?indx<- mat1<1 & mat2<1
mat1[indx]<-NA
?mat2[indx]<-NA
?mat1
#???? [,1] [,2] [,3]??????? [,4]
#[1,]?? NA?? NA?? NA 0.002311942
#[2,]?? NA?? NA?? NA????????? NA
#[3,]?? NA?? NA?? NA 0.598269113
?mat2
#???? [,1] [,2] [,3]???? [,4]
#[1,]?? NA?? NA?? NA 1.841481
#[2,]?? NA?? NA?? NA?????? NA
#[3,]?? NA?? NA?? NA 1.520367
A.K.

----- Original Message -----
From: JiangZhengyu <zhyjiang2006 at hotmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Wednesday, July 3, 2013 5:27 PM
Subject: [R] change cell values




Dear R experts,

I have two? matrices (mat1 & mat2) with the same dimension & the cells (row and column) are corresponding to each other.

I want to change cell values to NA given values of the corresponding cells in mat1 and mat2 are both <1.

E.g. both mat1[2,3] and mat2[2,3] are <1, I will put mat1[2,3]=NA, and mat2[2,3]=NA; if either mat1[2,3]>=1 or? mat2[2,3]>=1, I will save both cells.

I tried the code, but not working. Could anyone can help fix the problem?

mat1[mat1<1&mat2<1]=NA
mat2[mat1<1&mat2<1]=NA


> mat1=matrix(rnorm(12),3)
> mat2=matrix(rnorm(12),3)
> mat1
? ? ? ? ?  [,1]? ? ?  [,2]? ? ?  [,3]? ? ?  [,4]
[1,] -1.3387075 -0.7142333 -0.5614211? 0.1846955
[2,] -0.7936087 -0.2215797 -0.3686067? 0.7328731
[3,]? 0.6505082? 0.1826019? 1.5577883 -1.5580384
> mat2
? ? ? ? ?  [,1]? ? ?  [,2]? ? ?  [,3]? ? ?  [,4]
[1,]? 0.4331573 -1.8086826 -1.7688123 -1.4278934
[2,] -0.1841451? 0.1738648 -1.1086942? 1.3065109
[3,] -1.0827245 -0.4143808 -0.6889405? 0.4046203

??? ???  ??? ?  ??? ??? ? 
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Wed Jul  3 23:57:20 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 3 Jul 2013 14:57:20 -0700 (PDT)
Subject: [R] modify timestemp
Message-ID: <1372888640.69431.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:

dat1# dataset
dat1[,2]<-gsub("\\d+$","00",dat1[,2])
?dat1
#???????? Date???? Time
#1? 01/01/2013 00:09:00
#2? 01/02/2013 00:10:00
#3? 01/03/2013 00:11:00
#4? 01/04/2013 00:12:00
#5? 01/05/2013 00:13:00
#6? 01/06/2013 00:15:00
#7? 01/07/2013 00:16:00
#8? 01/08/2013 00:17:00
#9? 01/09/2013 00:18:00
#10 01/10/2013 00:19:00
A.K.


Hey All, 

I want to standardize my timestamp which is formatted as hh:mm:ss 

?My data looks like this: 

? ? ?Date ? ? Time 
01/01/2013 00:09:01 
01/02/2013 00:10:14 
01/03/2013 00:11:27 
01/04/2013 00:12:40 
01/05/2013 00:13:53 
01/06/2013 00:15:06 
01/07/2013 00:16:19 
01/08/2013 00:17:32 
01/09/2013 00:18:45 
01/10/2013 00:19:58 

Dataset <- structure(list(Date = c("01/01/2013", "01/02/2013", 
"01/03/2013", 
"01/04/2013", "01/05/2013", "01/06/2013", "01/07/2013", "01/08/2013", 
"01/09/2013", "01/10/2013"), Time = c("00:09:01", "00:10:14", 
"00:11:27", "00:12:40", "00:13:53", "00:15:06", "00:16:19", "00:17:32", 
"00:18:45", "00:19:58")), .Names = c("Date", "Time"), class = "data.frame", 
row.names = c(NA, 
-10L)) 

I would like to change all the records in "Time" column uniformed as 
hh:mm:00, then the output would be this: 

Date ? ? Time 
01/01/2013 00:09:00 
01/02/2013 00:10:00 
01/03/2013 00:11:00 
01/04/2013 00:12:00 
01/05/2013 00:13:00 
01/06/2013 00:15:00 
01/07/2013 00:16:00 
01/08/2013 00:17:00 
01/09/2013 00:18:00 
01/10/2013 00:19:00 

Thanks for your help!


From wwwhsd at gmail.com  Thu Jul  4 00:38:43 2013
From: wwwhsd at gmail.com (Henrique Dallazuanna)
Date: Wed, 3 Jul 2013 19:38:43 -0300
Subject: [R] converting a list of loglin terms to a model formula
In-Reply-To: <51D49DE6.8010103@yorku.ca>
References: <51D49DE6.8010103@yorku.ca>
Message-ID: <CAPvBnPFK7eW0Ev_TUxCXfHcUAm6OEMevdU7USQDG0yNnS+GYEA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/cbf4c08f/attachment.pl>

From erinm.hodgess at gmail.com  Thu Jul  4 01:54:07 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Wed, 3 Jul 2013 18:54:07 -0500
Subject: [R] setClass confusion
Message-ID: <CACxE24mnKwt4kyfHoCX+MSj3P9J0czhEbL90faDXPeEpHMLYNA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130703/a4174f9c/attachment.pl>

From murdoch.duncan at gmail.com  Thu Jul  4 02:07:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 3 Jul 2013 20:07:06 -0400
Subject: [R] setClass confusion
In-Reply-To: <CACxE24mnKwt4kyfHoCX+MSj3P9J0czhEbL90faDXPeEpHMLYNA@mail.gmail.com>
References: <CACxE24mnKwt4kyfHoCX+MSj3P9J0czhEbL90faDXPeEpHMLYNA@mail.gmail.com>
Message-ID: <51D4BCAA.7030404@gmail.com>

On 13-07-03 7:54 PM, Erin Hodgess wrote:
> Dear R People:
>
>
> I am experimenting with S4 classes and methods but am having trouble with
> setting up a class.
>
> Here is an example:
>
>> buzz <- setClass("buzz",slots=c(x="matrix"),
> + validity <- function(object) {
> + if(is.matrix(object)==FALSE)stop("Input must be a matrix")
> + TRUE
> + })
> Error in setClass("buzz", slots = c(x = "matrix"), validity <-
> function(object) { :
>    Argument "representation" cannot be used if argument "slots" is supplied
>>
>
> I know that there is something simple that I'm just not seeing.

Since you used <-, your third argument uses the positional name 
"representation", not "validity", which is presumably what you intended.

Duncan Murdoch


From gallon.li at gmail.com  Thu Jul  4 08:31:01 2013
From: gallon.li at gmail.com (Gallon Li)
Date: Thu, 4 Jul 2013 14:31:01 +0800
Subject: [R] how to choose dates data?
Message-ID: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/4dc6cd7d/attachment.pl>

From solcita.lago at gmail.com  Thu Jul  4 04:19:31 2013
From: solcita.lago at gmail.com (Sol Lago)
Date: Wed, 3 Jul 2013 22:19:31 -0400
Subject: [R] bootstrapping respecting subject level information
Message-ID: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>

Hi there,

This is the first time I use this forum, and I want to say from the start I am not a skilled programmer. So please let me know if the question or code were unclear!
 
I am trying to bootstrap an interaction (that is my test statistic) using the package "boot". My problem is that for every resample, I would like the randomization to be done within subjects, so that observations from different subjects are not mixed. Here is the code to generate a dataframe similar to mine:

Subject = rep(c("S1","S2","S3","S4"),4)
Num     = rep(c("singular","plural"),8) 
Gram    = rep(c("gram","gram","ungram","ungram"),4)
RT      = c(657,775,678,895,887,235,645,916,930,768,890,1016,590,978,450,920)
data    = data.frame(Subject,Num,Gram,RT) 

This is the code I used to get the empirical interaction value:

summary(lm(RT ~ Num*Gram, data=data))

As you can see, the interaction between my two factors is -348. I want to get a bootstrap confidence interval for this statistic, which I can generate using the "boot" package:

#Function to create the statistic to be boostrapped
boot.huber <- function(data, indices) {
data <- data[indices, ] #select obs. in bootstrap sample
mod <- lm(RT ~ Num*Gram, data=data)
coefficients(mod)       #return coefficient vector
}

#Generate bootstrap estimate
data.boot <- boot(data, boot.huber, 1999)

#Get confidence interval
boot.ci(data.boot, index=4, type=c("norm", "perc", "bca"),conf=0.95) #4 gets the CI for the interaction

My problem is that I think the resamples should be generated without mixing the individual subjects observations: that is, to generate the new resamples, the observations from subject 1 (S1) should be shuffled within subject 1, not mixing them with the observations from subjects 2, etc... I don't know how "boot" is doing the resampling (I read the documentation but don't understand how the function is doing it)

Does anyone know how I could make sure that the resampling procedure used by "boot" respects the subject level information?

Thanks a lot for your help/advice!

From smartpink111 at yahoo.com  Thu Jul  4 06:22:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 3 Jul 2013 21:22:02 -0700 (PDT)
Subject: [R] Subsetting multiple rows of a data frame at once
In-Reply-To: <1372851433.26315.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1372851433.26315.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1372911722.23983.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Possibly, FAQ 7.31
Using the same example:
set.seed(24)
df<- data.frame(x=sample(seq(0.25,4.25,by=.05),1e5,replace=TRUE),y= sample(seq(0.10,1.05,by=.05),1e5,replace=TRUE),z=rnorm(1e5)) 
dfOld<- df
?df[,1:2]<- lapply(df[,1:2],function(x) sprintf("%.2f",x))
x1<- c(1.05,2.85,3.40,4.25,0.25)
y1<- c(0.25,0.10,0.90,0.25,1.05) 
?x1New<-sprintf("%.2f",x1)
?y1New<- sprintf("%.2f",y1)
res1<-do.call(rbind,lapply(seq_along(x1New),function(i) subset(df,x==x1New[i]&y==y1New[i]))) 

res<-do.call(rbind,lapply(seq_along(x1),function(i) subset(dfOld,x==x1[i]&y==y1[i]))) 
dim(res1)
#[1] 318?? 3
? dim(res)
#[1] 250?? 3
?res1[,1:2]<- lapply(res1[,1:2],as.numeric)
str(res1)
#'data.frame':??? 318 obs. of? 3 variables:
# $ x: num? 1.05 1.05 1.05 1.05 1.05 1.05 1.05 1.05 1.05 1.05 ...
# $ y: num? 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 0.25 ...
# $ z: num? 0.787 -1.568 -1.626 -0.221 -0.7 ...
A.K.


nevermind.... error on my behalf got it going. 

I have another issue, it leaves some values out. ive seperately 
searched the df and theyre definitely in there... so it there some sort 
of exclusion rule? there are about 8 of the 28 missing... the first row 
missing is 3.05,1.70 . i looked up the documentation for subset but i 
cant see why it would skip ones... 

thanks 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, July 3, 2013 7:37 AM
Subject: Re: Subsetting multiple rows of a data frame at once


Hi,
Try this:

set.seed(24)
df<- data.frame(x=sample(seq(0.25,4.25,by=.05),1e5,replace=TRUE),y= sample(seq(0.10,1.05,by=.05),1e5,replace=TRUE),z=rnorm(1e5))

#Used a shorter vector 
x1<- c(1.05,2.85,3.40,4.25,0.25)
y1<- c(0.25,0.10,0.90,0.25,1.05)

res<-do.call(rbind,lapply(seq_along(x1),function(i) subset(df,x==x1[i]&y==y1[i])))
head(res,2)
#??????? x??? y????????? z
#466? 1.05 0.25? 0.7865224
#4119 1.05 0.25 -1.5679096
?tail(res,2)
#???????? x??? y????????? z
#98120 0.25 1.05 -2.1239596
#98178 0.25 1.05? 0.3321464


A.K.

Hi Everyone, 

First time poster so any posting rules i should know about feel free to advise... 

I've got a data frame of 250 000 rows in columns of x y and z. 

i need to extract 20-30 rows from the data frame with specific x
and y values, such that i can find the z value that corresponds. There 
is no repeated data. (its actually 250 000 squares in a 5x5m grid) 

to find them individually i can use subset successfully 

result<-subset(df,x==1.05 & y==c0.25) 

gives me the row in the dataframe with that x and y value. 

so if i have 

x = 1.05 2.85 3.40 4.25 0.25 3.05 3.70 0.20 0.30 0.70 1.05 1.20 
1.40 1.90 2.70 3.25 3.55 4.60 2.05 2.15 3.70 4.85 4.90 1.60 2.45 3.20 
3.90 4.45 

and 

y= 0.25 0.10 0.90 0.25 1.05 1.70 2.05 2.90 2.35 2.60 2.55 2.15 
2.75 2.05 2.70 2.25 2.55 2.05 3.65 3.05 3.00 3.50 3.75 4.85 4.50 4.50 
3.35 4.90 

then how can i retrieve the rows for all those values at once. 

if i name x=xt and y=yt and then 

result<-subset(df,x==xt & y==yt) 

then i get 

result 
[1] x ? ? ?y ? ? ?Height 
<0 rows> (or 0-length row.names) 

i dont understand why zero rows are selected. obviously im 
applying the vectors inappropriately, but i cant seem to find anything 
on this method of subsetting online. 

Thanks for any replies!? 



From smartpink111 at yahoo.com  Thu Jul  4 07:14:39 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 3 Jul 2013 22:14:39 -0700 (PDT)
Subject: [R] Subsetting multiple rows of a data frame at once
In-Reply-To: <BAY167-W646E5535CADE996C808532837C0@phx.gbl>
References: <25563192.156234.1372907812821.JavaMail.nabble@joe.nabble.com>
	<BAY167-W646E5535CADE996C808532837C0@phx.gbl>
Message-ID: <1372914879.51445.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,

carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
?dim(carbon.fit)
#[1] 251001????? 2


?xtNew<-sprintf("%.2f",xt)
?ytNew<- sprintf("%.2f",yt)
?carbon.fit[]<- lapply(carbon.fit,function(x) sprintf("%.2f",x))
res<-do.call(rbind,lapply(seq_along(xtNew),function(i) subset(carbon.fit,x==xtNew[i]&y==ytNew[i])))
?nrow(res)
#[1] 28
res
#????????? x??? y
#12631? 1.05 0.25
#5296?? 2.85 0.10
#45431? 3.40 0.90
#12951? 4.25 0.25
#52631? 0.25 1.05
#85476? 3.05 1.70
#103076 3.70 2.05
#145311 0.20 2.90
#117766 0.30 2.35
#130331 0.70 2.60
#127861 1.05 2.55
#107836 1.20 2.15
#137916 1.40 2.75
#102896 1.90 2.05
#135541 2.70 2.70
#113051 3.25 2.25
#128111 3.55 2.55
#103166 4.60 2.05
#183071 2.05 3.65
#153021 2.15 3.05
#150671 3.70 3.00
#175836 4.85 3.50
#188366 4.90 3.75
#243146 1.60 4.85
#225696 2.45 4.50
#225771 3.20 4.50
#168226 3.90 3.35
#245936 4.45 4.90
A.K.


________________________________
From: Shaun ? Anika <pro_patto at hotmail.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Thursday, July 4, 2013 12:08 AM
Subject: RE: Subsetting multiple rows of a data frame at once




Hi There,
i can give you the data needed to perform this task...

library(akima)
library(fields)

xt<- c(1.05, 2.85, 3.40, 4.25, 0.25, 3.05, 3.70, 0.20, 0.30, 0.70, 1.05, 1.20, 1.40, 1.90, 2.70, 3.25, 3.55, 4.60, 2.05, 2.15,?3.70, 4.85, 4.90, 1.60, 2.45, 3.20, 3.90, 4.45)

yt<- c(0.25, 0.10, 0.90, 0.25, 1.05, 1.70, 2.05, 2.90, 2.35, 2.60, 2.55, 2.15, 2.75, 2.05, 2.70, 2.25, 2.55, 2.05, 3.65, 3.05,?3.00, 3.50, 3.75, 4.85, 4.50, 4.50, 3.35, 4.90)

xs<- c(0.45, 1.05, 2.75, 3.30, 4.95, 0.40, 1.05, 2.30, 3.45, 4.60, 0.05, 1.95, 2.95, 3.70, 4.55, 0.75, 1.60, 2.10, 3.60, 4.90,?0.05, 1.35, 2.60, 3.40, 4.25)

ys<- c(0.45, 0.95, 0.75, 0.95, 0.10, 1.90, 1.45, 1.25, 1.45, 1.05, 2.85, 2.60, 2.05, 2.60, 2.55, 3.75, 3.30, 3.95, 3.45, 3.70,?4.95, 4.35, 4.55, 4.40, 4.95)

carbon<- c(1.43, 1.82, 1.40, 1.43, 1.96, 1.61, 1.91, 1.53, 1.17, 1.83, 2.43, 2.02, 1.66, 2.45, 2.46, 1.39, 1.10, 1.38, 1.91, 2.13,?1.88, 1.26, 2.15, 1.89, 1.69)

carbon.df=data.frame(x=xs,y=ys,z=carbon)
carbon.loess= loess(z~x*y, data= carbon.df, degree= 2)
carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
z=predict(carbon.loess, newdata= carbon.fit)
carbon.fit$Height=as.numeric(z)
image.plot(seq(0,5,0.01,), seq(0,5,0.01), z, xlab = "", ylab="",main = "Carbon")

trees<-do.call(rbind,lapply(seq_along(xt),function(i) subset(carbon.fit,x==xt[i]&y==yt[i])))

## xt is 28 integers long and when i run the above code it only returns the values of 18 out of the 28 (xt,yt) pairs that i want.?

thanks for your help!!


From ekelson2002 at yahoo.com  Thu Jul  4 08:14:45 2013
From: ekelson2002 at yahoo.com (Ekele Alih)
Date: Thu, 4 Jul 2013 07:14:45 +0100 (BST)
Subject: [R] cluster analysis
Message-ID: <1372918485.94304.YahooMailNeo@web172206.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/b0878e76/attachment.pl>

From xiangduxiuzy at gmail.com  Thu Jul  4 09:04:27 2013
From: xiangduxiuzy at gmail.com (Dante.py)
Date: Thu, 4 Jul 2013 15:04:27 +0800
Subject: [R] how to choose dates data?
In-Reply-To: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
References: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
Message-ID: <CADrtQZwyL_xPH3G2x6ccBodHdT4+_woj0d6YQrmF8VEjawS8Rw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/f2d6424b/attachment.pl>

From es at enricoschumann.net  Thu Jul  4 11:34:03 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Thu, 04 Jul 2013 11:34:03 +0200
Subject: [R] modify timestemp
In-Reply-To: <CAAvu=bmyXVW3gmTFQbG7fLKvLeDFPW_sSkFBXO23jG0nuDyc+w@mail.gmail.com>
	(Ye Lin's message of "Wed, 3 Jul 2013 14:45:16 -0700")
References: <CAAvu=bmyXVW3gmTFQbG7fLKvLeDFPW_sSkFBXO23jG0nuDyc+w@mail.gmail.com>
Message-ID: <87a9m23bzo.fsf@vipag.com>

On Wed, 03 Jul 2013, Ye Lin <yelin at lbl.gov> writes:

> Hey All,
>
> I want to standardize my timestamp which is formatted as hh:mm:ss
>
>  My data looks like this:
>
>      Date     Time
> 01/01/2013 00:09:01
> 01/02/2013 00:10:14
> 01/03/2013 00:11:27
> 01/04/2013 00:12:40
> 01/05/2013 00:13:53
> 01/06/2013 00:15:06
> 01/07/2013 00:16:19
> 01/08/2013 00:17:32
> 01/09/2013 00:18:45
> 01/10/2013 00:19:58
>
> Dataset <- structure(list(Date = c("01/01/2013", "01/02/2013",
> "01/03/2013",
> "01/04/2013", "01/05/2013", "01/06/2013", "01/07/2013", "01/08/2013",
> "01/09/2013", "01/10/2013"), Time = c("00:09:01", "00:10:14",
> "00:11:27", "00:12:40", "00:13:53", "00:15:06", "00:16:19", "00:17:32",
> "00:18:45", "00:19:58")), .Names = c("Date", "Time"), class = "data.frame",
> row.names = c(NA,
> -10L))
>
> I would like to change all the records in "Time" column uniformed as
> hh:mm:00, then the output would be this:
>
> Date     Time
> 01/01/2013 00:09:00
> 01/02/2013 00:10:00
> 01/03/2013 00:11:00
> 01/04/2013 00:12:00
> 01/05/2013 00:13:00
> 01/06/2013 00:15:00
> 01/07/2013 00:16:00
> 01/08/2013 00:17:00
> 01/09/2013 00:18:00
> 01/10/2013 00:19:00
>
> Thanks for your help!

Since your dates and times are character vectors, you can do this:
 
  substr(Dataset$Time, 7, 8) <- "00"

If you want to treat them as actual dates and times, you need to convert
them into one of R's date/time classes (see ?DateTimeClasses):

  timestamp <- as.POSIXlt(paste(Dataset$Date, Dataset$Time), 
                          format = "%m/%d/%Y %H:%M:%S")

  timestamp$sec

  ## [1]  1 14 27 40 53  6 19 32 45 58

  timestamp$sec <- 0


>
> 	[[alternative HTML version deleted]]
>

Please send only plain-text mails to this list.



-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ripley at stats.ox.ac.uk  Thu Jul  4 11:47:54 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 Jul 2013 10:47:54 +0100
Subject: [R] how to choose dates data?
In-Reply-To: <CADrtQZwyL_xPH3G2x6ccBodHdT4+_woj0d6YQrmF8VEjawS8Rw@mail.gmail.com>
References: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
	<CADrtQZwyL_xPH3G2x6ccBodHdT4+_woj0d6YQrmF8VEjawS8Rw@mail.gmail.com>
Message-ID: <51D544CA.3020102@stats.ox.ac.uk>

On 04/07/2013 08:04, Dante.py wrote:
> I have a method which is not so smart --use grep to match the pattern.
> for example:
> dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92", "02/01/91")
> day <- as.Date(dates, "%m/%d/%y")
> day:
> [1] "1992-02-27" "1992-02-27" "1992-01-14" "1992-02-28" "1991-02-01"
> If I want to search for 1991, I can use:
> grep("1991-*", day)
>
>
> Hope for a better solution.

Here are 2.  The first is quite obvious, the second is faster but needs 
more knowledge.

x <- format(day, "%Y")
day[x >= "2007" & x <= "2009"]

x <- as.POSIXlt(day)$year + 1900
day[x >= 2007 & x <= 2009]

>
>
> 2013/7/4 Gallon Li <gallon.li at gmail.com>
>
>> i have converted my data into date format like below:
>>
>>> day=as.Date(originaldate,"%m/%d/%Y")
>>> day[1:5]
>> [1] "2008-04-12" "2011-07-02" "2011-09-02" "2008-04-12" "2008-04-12"
>>
>> I wish to select only those observations from 2007 to 2009, how can I
>> select from this list?
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From lorenzo.isella at gmail.com  Thu Jul  4 12:00:12 2013
From: lorenzo.isella at gmail.com (Lorenzo Isella)
Date: Thu, 4 Jul 2013 12:00:12 +0200
Subject: [R] Binomial Regression and nnet
Message-ID: <CAE-ioUykyTWuN=g1F61zYwV1r_k4-Nsuskr6bBt5d81PNoH9YQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/b87a490f/attachment.pl>

From xiangduxiuzy at gmail.com  Thu Jul  4 12:36:11 2013
From: xiangduxiuzy at gmail.com (Dante.py)
Date: Thu, 4 Jul 2013 18:36:11 +0800
Subject: [R] how to choose dates data?
In-Reply-To: <51D544CA.3020102@stats.ox.ac.uk>
References: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
	<CADrtQZwyL_xPH3G2x6ccBodHdT4+_woj0d6YQrmF8VEjawS8Rw@mail.gmail.com>
	<51D544CA.3020102@stats.ox.ac.uk>
Message-ID: <CADrtQZxXGyUJ9bbQwt2s9au=MU5TUmz5-ycouz8_pHYNWrvykQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/59289383/attachment.pl>

From robbie.weterings at gmail.com  Thu Jul  4 12:40:51 2013
From: robbie.weterings at gmail.com (Robbie Weterings)
Date: Thu, 4 Jul 2013 17:40:51 +0700
Subject: [R] Non-linear modelling with several variables including a
 categorical variable
In-Reply-To: <51D42C78.50907@uottawa.ca>
References: <mailman.25.1372845609.8485.r-help@r-project.org>
	<51D42C78.50907@uottawa.ca>
Message-ID: <CAFe5dHYpkPkEOfDePwxZth=9wvwQuRF1-gxzv8T6-Q2H9pjd9A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/c4a10461/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Jul  4 13:08:42 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 Jul 2013 12:08:42 +0100
Subject: [R] how to choose dates data?
In-Reply-To: <CADrtQZxXGyUJ9bbQwt2s9au=MU5TUmz5-ycouz8_pHYNWrvykQ@mail.gmail.com>
References: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
	<CADrtQZwyL_xPH3G2x6ccBodHdT4+_woj0d6YQrmF8VEjawS8Rw@mail.gmail.com>
	<51D544CA.3020102@stats.ox.ac.uk>
	<CADrtQZxXGyUJ9bbQwt2s9au=MU5TUmz5-ycouz8_pHYNWrvykQ@mail.gmail.com>
Message-ID: <51D557BA.50304@stats.ox.ac.uk>

On 04/07/2013 11:36, Dante.py wrote:
> They are really good methods. Thank you very much.
> Could I ask one more question. Is there obvious difference between these 
> two methods?

Yes.  It is obvious that the type of x differs.

> 
> 
> 2013/7/4 Prof Brian Ripley <ripley at stats.ox.ac.uk 
> <mailto:ripley at stats.ox.ac.uk>>
> 
>     On 04/07/2013 08:04, Dante.py wrote:
> 
>         I have a method which is not so smart --use grep to match the
>         pattern.
>         for example:
>         dates <- c("02/27/92", "02/27/92", "01/14/92", "02/28/92",
>         "02/01/91")
>         day <- as.Date(dates, "%m/%d/%y")
>         day:
>         [1] "1992-02-27" "1992-02-27" "1992-01-14" "1992-02-28" "1991-02-01"
>         If I want to search for 1991, I can use:
>         grep("1991-*", day)
> 
> 
>         Hope for a better solution.
> 
> 
>     Here are 2.  The first is quite obvious, the second is faster but
>     needs more knowledge.
> 
>     x <- format(day, "%Y")
>     day[x >= "2007" & x <= "2009"]
> 
>     x <- as.POSIXlt(day)$year + 1900
>     day[x >= 2007 & x <= 2009]
> 
> 
> 
> 
>         2013/7/4 Gallon Li <gallon.li at gmail.com
>         <mailto:gallon.li at gmail.com>>
> 
>             i have converted my data into date format like below:
> 
>                 day=as.Date(originaldate,"%m/%__d/%Y")
>                 day[1:5]
> 
>             [1] "2008-04-12" "2011-07-02" "2011-09-02" "2008-04-12"
>             "2008-04-12"
> 
>             I wish to select only those observations from 2007 to 2009,
>             how can I
>             select from this list?
> 
>                       [[alternative HTML version deleted]]
> 
>             ________________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>             https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
> 
> 
> 
> 
> 
> 
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
>     -- 
>     Brian D. Ripley, ripley at stats.ox.ac.uk <mailto:ripley at stats.ox.ac.uk>
>     Professor of Applied Statistics,
>     http://www.stats.ox.ac.uk/~__ripley/
>     <http://www.stats.ox.ac.uk/~ripley/>
>     University of Oxford,             Tel: +44 1865 272861
>     <tel:%2B44%201865%20272861> (self)
>     1 South Parks Road, +44 1865 272866 <tel:%2B44%201865%20272866> (PA)
>     Oxford OX1 3TG, UK                Fax: +44 1865 272595
>     <tel:%2B44%201865%20272595>
> 
> 
> 
> 
> -- 
> ?? Dante.py
> ????09??????????
> ?????http://dantepy.yslsg.org/


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From Patrick.Aboagye-Sarfo at health.wa.gov.au  Thu Jul  4 10:33:58 2013
From: Patrick.Aboagye-Sarfo at health.wa.gov.au (Aboagye-sarfo, Patrick)
Date: Thu, 4 Jul 2013 16:33:58 +0800
Subject: [R] Help
Message-ID: <F5B944E50D3656499D652210B3A1271E123E9C@WSC281PEVS.hdwa.health.wa.gov.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/2af840d2/attachment.pl>

From S.Ellison at lgcgroup.com  Thu Jul  4 13:55:57 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Thu, 4 Jul 2013 12:55:57 +0100
Subject: [R] Help
In-Reply-To: <F5B944E50D3656499D652210B3A1271E123E9C@WSC281PEVS.hdwa.health.wa.gov.au>
References: <F5B944E50D3656499D652210B3A1271E123E9C@WSC281PEVS.hdwa.health.wa.gov.au>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9F872A3@GOLD.corp.lgc-group.com>

> I am trying to download packages and the message I get is as follows
>  
> Warning: unable to access index for repository 
> http://cran.ms.unimelb.edu.au/bin/windows/contrib/3.0 

Your internet connection is probably either not working or (more likely) blocked by firewall or site access policies.

Under windows, that problem sometimes goes away if you install R using the 'use Internet2' option or, _before attempting any connections_, you  use 
setInternet2()

If that does not work you will need to contact your local network administrator to permit access to the repositories.

In our case that was a bit of a faff because we had to log the http request (that is, the raw http request, not the url) and then update (remote) proxies to recognise the structure of a CRAN repository request as an allowed site. Organisations are increasingly using such off-site 'site filtering', so it's become more of a problem.

It may help you or your administrator to try simply reading direct from the URL, for example with
readLines(url("http://cran.ms.unimelb.edu.au/"))
If your internet connection is working, that should return html lines (I see 24 lines at that url, today) containing the html header and the <frameset> for a CRAN front page. But if your proxy or firewall are returning an error the text returned can be informative as to where the problem is.

Failing all that, you could download the zip or tar.gz from CRAN) and install 'from a local zip file'.

S


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From kehld at ktk.pte.hu  Thu Jul  4 13:59:32 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Thu, 4 Jul 2013 11:59:32 +0000
Subject: [R] polr?
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B832E5B@EMAIL.ktkdom.pte.hu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/41c3f5a3/attachment.pl>

From doorz at xs4all.nl  Thu Jul  4 14:04:47 2013
From: doorz at xs4all.nl (Alex van der Spek)
Date: Thu, 4 Jul 2013 14:04:47 +0200
Subject: [R] list construction with automatic names
Message-ID: <1c8c09d8979274ab425ae9e48346cd49.squirrel@webmail.xs4all.nl>

I often find myself (wanting t)o constructing lists or data.frames like so:

#Find files in subdirs
ii <- 0
for (ix in id) {
	ii <- ii + 1
	if (ii == 1) {
		fl <- list(basename(ix) = list.files(ix))
	} else {
		fl <- c(fl, list(basename(ix) = list.files(ix)))
	}
}

The above is for list construction. It does not work as the argument name
is not accepted. In python this would be legal but I can't find how to
modify the name argument in R to make this legal.

Furthermore the use of a separate counter is not very elegant. Would there
be a better way? Again, in python appending to a list is very easy but
seems to be available in R only for vectors not lists?

Any help much appreciated!
Alex van der Spek


From ripley at stats.ox.ac.uk  Thu Jul  4 14:14:03 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 4 Jul 2013 13:14:03 +0100
Subject: [R] polr?
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D0B832E5B@EMAIL.ktkdom.pte.hu>
References: <33D76D77E9AC4B438DA38B348ED6890D0B832E5B@EMAIL.ktkdom.pte.hu>
Message-ID: <51D5670B.8050300@stats.ox.ac.uk>

On 04/07/2013 12:59, D?niel Kehl wrote:
> Dear R users,
>
> I have a dataset with two ordered variables, tr_x1 and tr_y1. A crosstable of them can bee seen below.
>
>       tr_x1
> tr_y1   -1    0    1
>     -1  629  100  629
>     0  1396 4353 1443
>     1   668  126  655
>
> It is clear that if tr_x1 is 0, it has an effect on tr_y1. A chi-square statistic is clearly showing this with a low p-value.
> Is there a regression-based method you would offer? I tried polr from MASS package but without finding a significant coefficient, because the columns for tr_x1 and tr_y1 are similar.

Your mistake is testing coefficients, not overall fit.

> Thank you for your help!
>
> daniel
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From S.Ellison at LGCGroup.com  Thu Jul  4 14:18:54 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 4 Jul 2013 13:18:54 +0100
Subject: [R] list construction with automatic names
In-Reply-To: <1c8c09d8979274ab425ae9e48346cd49.squirrel@webmail.xs4all.nl>
References: <1c8c09d8979274ab425ae9e48346cd49.squirrel@webmail.xs4all.nl>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9F872D5@GOLD.corp.lgc-group.com>

> I often find myself (wanting t)o constructing lists or 
> data.frames
 
Apologies; previous post should have said "Read R inforno on 'Growing Objects'" and should have added the URL:

http://www.burns-stat.com/pages/Tutor/R_inferno.pdf

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at lgcgroup.com  Thu Jul  4 14:17:00 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Thu, 4 Jul 2013 13:17:00 +0100
Subject: [R] list construction with automatic names
In-Reply-To: <1c8c09d8979274ab425ae9e48346cd49.squirrel@webmail.xs4all.nl>
References: <1c8c09d8979274ab425ae9e48346cd49.squirrel@webmail.xs4all.nl>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9F872D0@GOLD.corp.lgc-group.com>

> I often find myself (wanting t)o constructing lists or 
> data.frames:

Try something like

fl<-list()
for (ix in id) {
	fl[[basename(ix)]] <- list.files(ix)
}
But read R Inferno on inrementing objects first. It isn't efficient in memory terms (unless that's improved in recent versions of R)
 
Rather more elegantly you can get the same list with

sapply(id, function(ix) list.files(ix))



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From kehld at ktk.pte.hu  Thu Jul  4 14:38:31 2013
From: kehld at ktk.pte.hu (=?iso-8859-2?Q?D=E1niel_Kehl?=)
Date: Thu, 4 Jul 2013 12:38:31 +0000
Subject: [R] polr?
In-Reply-To: <51D5670B.8050300@stats.ox.ac.uk>
References: <33D76D77E9AC4B438DA38B348ED6890D0B832E5B@EMAIL.ktkdom.pte.hu>,
	<51D5670B.8050300@stats.ox.ac.uk>
Message-ID: <33D76D77E9AC4B438DA38B348ED6890D0B832E96@EMAIL.ktkdom.pte.hu>

Dear Prof Ripley,

could you be just a little more specific?

Thanks a lot
daniel
________________________________________
Felad?: Prof Brian Ripley [ripley at stats.ox.ac.uk]
K?ldve: 2013. j?lius 4. 14:14
To: D?niel Kehl
Cc: r-help
T?rgy: Re: [R] polr?

On 04/07/2013 12:59, D?niel Kehl wrote:
> Dear R users,
>
> I have a dataset with two ordered variables, tr_x1 and tr_y1. A crosstable of them can bee seen below.
>
>       tr_x1
> tr_y1   -1    0    1
>     -1  629  100  629
>     0  1396 4353 1443
>     1   668  126  655
>
> It is clear that if tr_x1 is 0, it has an effect on tr_y1. A chi-square statistic is clearly showing this with a low p-value.
> Is there a regression-based method you would offer? I tried polr from MASS package but without finding a significant coefficient, because the columns for tr_x1 and tr_y1 are similar.

Your mistake is testing coefficients, not overall fit.

> Thank you for your help!
>
> daniel
>
>       [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


--
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From doorz at xs4all.nl  Thu Jul  4 14:43:50 2013
From: doorz at xs4all.nl (Alex van der Spek)
Date: Thu, 4 Jul 2013 14:43:50 +0200
Subject: [R] list construction with automatic names
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4AC9F872D5@GOLD.corp.lgc-group.com>
References: <1c8c09d8979274ab425ae9e48346cd49.squirrel@webmail.xs4all.nl>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F872D5@GOLD.corp.lgc-group.com>
Message-ID: <d96e4314e0b590761e5c9800bca1d77f.squirrel@webmail.xs4all.nl>

>> I often find myself (wanting t)o constructing lists or
>> data.frames
>
> Apologies; previous post should have said "Read R inforno on 'Growing
> Objects'" and should have added the URL:
>
> http://www.burns-stat.com/pages/Tutor/R_inferno.pdf
>
> S Ellison
>
>
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

Thank you! That was very helpful. The R-Inferno pdf makes nice reading too!


From pdalgd at gmail.com  Thu Jul  4 15:11:42 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Jul 2013 15:11:42 +0200
Subject: [R] polr?
In-Reply-To: <33D76D77E9AC4B438DA38B348ED6890D0B832E96@EMAIL.ktkdom.pte.hu>
References: <33D76D77E9AC4B438DA38B348ED6890D0B832E5B@EMAIL.ktkdom.pte.hu>,
	<51D5670B.8050300@stats.ox.ac.uk>
	<33D76D77E9AC4B438DA38B348ED6890D0B832E96@EMAIL.ktkdom.pte.hu>
Message-ID: <36A278ED-F3A1-4833-A432-DA0940A99C8C@gmail.com>


On Jul 4, 2013, at 14:38 , D?niel Kehl wrote:

> Dear Prof Ripley,
> 
> could you be just a little more specific?

He'll likely find that difficult.

It's sort of like if you had data like this

25 75
75 25
25 75 

and did a trend test. The trend test _assumes_ that the effect is increasing, and constructs a test based on the slope. Since it it isn't increasing, the effect isn't found:

> prop.trend.test(c(25,75,25),c(100,100,100))

	Chi-squared Test for Trend in Proportions

data:  c(25, 75, 25) out of c(100, 100, 100) ,
 using scores: 1 2 3 
X-squared = 0, df = 1, p-value = 1

However, if you fit the implied model, you get

> score <- 1:3
> summary(glm(cbind(c(25,75,25),c(75,25,75)) ~ score, binomial))

Call:
glm(formula = cbind(c(25, 75, 25), c(75, 25, 75)) ~ score, family = binomial)

Deviance Residuals: 
     1       2       3  
-3.486   6.768  -3.486  

Coefficients:
              Estimate Std. Error z value Pr(>|z|)
(Intercept) -3.365e-01  3.098e-01  -1.086    0.277
score       -2.548e-16  1.434e-01   0.000    1.000

(Dispersion parameter for binomial family taken to be 1)

    Null deviance: 70.115  on 2  degrees of freedom
Residual deviance: 70.115  on 1  degrees of freedom
AIC: 88.444

Number of Fisher Scoring iterations: 3

where the z-value for the score coefficient is 0, but the residual deviance reveals that the model doesn't fit the data.

> 
> Thanks a lot
> daniel
> ________________________________________
> Felad?: Prof Brian Ripley [ripley at stats.ox.ac.uk]
> K?ldve: 2013. j?lius 4. 14:14
> To: D?niel Kehl
> Cc: r-help
> T?rgy: Re: [R] polr?
> 
> On 04/07/2013 12:59, D?niel Kehl wrote:
>> Dear R users,
>> 
>> I have a dataset with two ordered variables, tr_x1 and tr_y1. A crosstable of them can bee seen below.
>> 
>>      tr_x1
>> tr_y1   -1    0    1
>>    -1  629  100  629
>>    0  1396 4353 1443
>>    1   668  126  655
>> 
>> It is clear that if tr_x1 is 0, it has an effect on tr_y1. A chi-square statistic is clearly showing this with a low p-value.
>> Is there a regression-based method you would offer? I tried polr from MASS package but without finding a significant coefficient, because the columns for tr_x1 and tr_y1 are similar.
> 
> Your mistake is testing coefficients, not overall fit.
> 
>> Thank you for your help!
>> 
>> daniel
>> 
>>      [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From alexandre.piche at mail.mcgill.ca  Thu Jul  4 16:00:10 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Thu, 4 Jul 2013 07:00:10 -0700 (PDT)
Subject: [R] ggplot2
Message-ID: <1372946410534-4670852.post@n4.nabble.com>

Hello Folks,

I have a database of 2000+ days with 35 observations each. I am trying to
modeling a time series by day, but it seems a problem that I don<t have the
time of the observation. I achieve something interesting by using the
barplot function, but I`d rather working with ggplot2, since I have the book
by Hadley Wickham in hands. 


I start by transforming my data into a dataframe, but since I have even more
problems working with my data, since all my observations are plot on the
same day.

> str(last(dezdiff))
An ?xts? object on 2013-07-04/2013-07-04 containing:
  Data: num [1, 1:35] 1.9016 0.7545 0.225 0.0727 0.1357 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:35] "1" "2" "3" "4" ...
  Indexed by objects of class: [Date] TZ: UTC
  xts Attributes:  
 NULL

>barplot(last(dezdiff), beside = TRUE)

<http://r.789695.n4.nabble.com/file/n4670852/barplot.bmp> 

> str(dezdiff.dt)
'data.frame':   2741 obs. of  36 variables:
 $ datetime: Date, format: "2003-01-02" "2003-01-03" "2003-01-06"
"2003-01-07" ...
 $ X1      : num  5.63 -1.42 -6.8 -1.9 -6.17 ...
 $ X2      : num  7.748 -0.296 -5.333 -2.348 -5.323 ...
 $ X3      : num  9.075 0.454 -4.294 -2.557 -5 ...
 $ X4      : num  9.863 0.966 -3.542 -2.629 -4.978 ...
...
 $ X32     : num  11.21 1.38 2.44 -3.48 -6.04 ...
 $ X33     : num  11.26 1.24 2.52 -3.47 -6.05 ...
 $ X34     : num  11.3 1.1 2.59 -3.45 -6.06 ...
 $ X35     : num  11.337 0.956 2.658 -3.436 -6.075 ...

qplot(datetime, c(X1:X35), data=dezdiff.dt[nrow(dezdiff.dt),])

<http://r.789695.n4.nabble.com/file/n4670852/ggplot2.bmp> 

Anyone know how I could reshape my data or just how I would be able to plot
all my observations on the same graph at different position on the x-axis.

Thank you for your time, and let me know if you have any question.

Regards,

Alex



--
View this message in context: http://r.789695.n4.nabble.com/ggplot2-tp4670852.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Thu Jul  4 16:28:34 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 4 Jul 2013 07:28:34 -0700 (PDT)
Subject: [R] how to choose dates data?
In-Reply-To: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
References: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
Message-ID: <1372948114.22446.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You could try:
day<-as.Date(c("2008-04-12","2011-07-02","2011-09-02","2008-04-12","2008-04-12"))
?indx<-gsub("-.*","",day)
?day[indx>="2007" & indx<="2009"]
#[1] "2008-04-12" "2008-04-12" "2008-04-12"

#or
library(xts)
xt1<- xts(seq_along(day),day)
index(xt1["2007/2009"])
#[1] "2008-04-12" "2008-04-12" "2008-04-12"

#or
library(chron)
yr1<-month.day.year(unclass(day))$year
day[yr1>=2007 & yr1<=2009]
#[1] "2008-04-12" "2008-04-12" "2008-04-12"
A.K.




----- Original Message -----
From: Gallon Li <gallon.li at gmail.com>
To: r-help <r-help at stat.math.ethz.ch>
Cc: 
Sent: Thursday, July 4, 2013 2:31 AM
Subject: [R] how to choose dates data?

i have converted my data into date format like below:

> day=as.Date(originaldate,"%m/%d/%Y")
> day[1:5]
[1] "2008-04-12" "2011-07-02" "2011-09-02" "2008-04-12" "2008-04-12"

I wish to select only those observations from 2007 to 2009, how can I
select from this list?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Thu Jul  4 16:36:51 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 4 Jul 2013 06:36:51 -0800
Subject: [R] ggplot2
In-Reply-To: <1372946410534-4670852.post@n4.nabble.com>
Message-ID: <698006CF9DB.00000ABAjrkrideau@inbox.com>

I think we need to see some of the original data. See ?dput for how to supply data in a email.  

We probably don't need all the data, I'd suggest perhaps 100 rows or so.  Try dput(head(yourdata, 100))

BTW what is "last"?

John Kane
Kingston ON Canada


> -----Original Message-----
> From: alexandre.piche at mail.mcgill.ca
> Sent: Thu, 4 Jul 2013 07:00:10 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] ggplot2
> 
> Hello Folks,
> 
> I have a database of 2000+ days with 35 observations each. I am trying to
> modeling a time series by day, but it seems a problem that I don<t have
> the
> time of the observation. I achieve something interesting by using the
> barplot function, but I`d rather working with ggplot2, since I have the
> book
> by Hadley Wickham in hands.
> 
> 
> I start by transforming my data into a dataframe, but since I have even
> more
> problems working with my data, since all my observations are plot on the
> same day.
> 
>> str(last(dezdiff))
> An ?xts? object on 2013-07-04/2013-07-04 containing:
>   Data: num [1, 1:35] 1.9016 0.7545 0.225 0.0727 0.1357 ...
>  - attr(*, "dimnames")=List of 2
>   ..$ : NULL
>   ..$ : chr [1:35] "1" "2" "3" "4" ...
>   Indexed by objects of class: [Date] TZ: UTC
>   xts Attributes:
>  NULL
> 
> >barplot(last(dezdiff), beside = TRUE)
> 
> <http://r.789695.n4.nabble.com/file/n4670852/barplot.bmp>
> 
>> str(dezdiff.dt)
> 'data.frame':   2741 obs. of  36 variables:
>  $ datetime: Date, format: "2003-01-02" "2003-01-03" "2003-01-06"
> "2003-01-07" ...
>  $ X1      : num  5.63 -1.42 -6.8 -1.9 -6.17 ...
>  $ X2      : num  7.748 -0.296 -5.333 -2.348 -5.323 ...
>  $ X3      : num  9.075 0.454 -4.294 -2.557 -5 ...
>  $ X4      : num  9.863 0.966 -3.542 -2.629 -4.978 ...
> ...
>  $ X32     : num  11.21 1.38 2.44 -3.48 -6.04 ...
>  $ X33     : num  11.26 1.24 2.52 -3.47 -6.05 ...
>  $ X34     : num  11.3 1.1 2.59 -3.45 -6.06 ...
>  $ X35     : num  11.337 0.956 2.658 -3.436 -6.075 ...
> 
> qplot(datetime, c(X1:X35), data=dezdiff.dt[nrow(dezdiff.dt),])
> 
> <http://r.789695.n4.nabble.com/file/n4670852/ggplot2.bmp>
> 
> Anyone know how I could reshape my data or just how I would be able to
> plot
> all my observations on the same graph at different position on the
> x-axis.
> 
> Thank you for your time, and let me know if you have any question.
> 
> Regards,
> 
> Alex
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/ggplot2-tp4670852.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From alexandre.piche at mail.mcgill.ca  Thu Jul  4 16:40:31 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Thu, 4 Jul 2013 07:40:31 -0700 (PDT)
Subject: [R] ggplot2
In-Reply-To: <1372946410534-4670852.post@n4.nabble.com>
References: <1372946410534-4670852.post@n4.nabble.com>
Message-ID: <1372948831106-4670857.post@n4.nabble.com>

Here<s the function last

> last
function (x, ...) 
{
    UseMethod("last")
}
<environment: namespace:xts>

I can share 100 rows if you want, but I don`t you will find it useful, since
I want to perform my time-series on a single row. Here`s one:

dezdiff.dt[nrow(dezdiff.dt),]
             datetime       X1        X2        X3         X4        X5       
X6        X7        X8        X9
2013-07-04 2013-07-04 1.901595 0.7545192 0.2250272 0.07266123 0.1356831
0.3078896 0.5217937 0.7365071 0.9290817
               X10      X11     X12      X13     X14      X15      X16     
X17      X18      X19      X20     X21
2013-07-04 1.08838 1.210787 1.29725 1.351279 1.37761 1.381366 1.367526
1.340636 1.304659 1.262931 1.218168 1.17252
                X22      X23      X24      X25       X26       X27       X28      
X29       X30       X31
2013-07-04 1.127627 1.084698 1.044577 1.007814 0.9747219 0.9454289 0.9199254
0.8980989 0.8797653 0.8646931
                 X32       X33       X34       X35
2013-07-04 0.8526222 0.8432792 0.8363881 0.8316789 




--
View this message in context: http://r.789695.n4.nabble.com/ggplot2-tp4670852p4670857.html
Sent from the R help mailing list archive at Nabble.com.


From jrkrideau at inbox.com  Thu Jul  4 16:55:54 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 4 Jul 2013 06:55:54 -0800
Subject: [R] ggplot2
In-Reply-To: <1372948831106-4670857.post@n4.nabble.com>
References: <1372946410534-4670852.post@n4.nabble.com>
Message-ID: <69AA9703BF2.00000AE3jrkrideau@inbox.com>

Thanks Alex but the idea is to use dput() for the data so that readers can simply copy and paste it into R and have a working dataset.  I have a very small data.frame called dd.

  Var1 Var2
1     A    1
2     B    1
3     C    1
4     A    2
5     B    2
6     C    2
7     A    3
8     B    3
9     C    3
10    A    4
11    B    4
12    C    4

Here it is the  output using dput(). If you copy it and paste it into R you will have an exact duplicate of my dataset which makes working on a problem much easier.

dd  <-  structure(list(Var1 = structure(c(1L, 2L, 3L, 1L, 2L, 3L, 1L, 
2L, 3L, 1L, 2L, 3L), .Label = c("A", "B", "C"), class = "factor"), 
    Var2 = c(1L, 1L, 1L, 2L, 2L, 2L, 3L, 3L, 3L, 4L, 4L, 4L)), .Names = c("Var1", 
"Var2"), out.attrs = structure(list(dim = 3:4, dimnames = structure(list(
    Var1 = c("Var1=A", "Var1=B", "Var1=C"), Var2 = c("Var2=1", 
    "Var2=2", "Var2=3", "Var2=4")), .Names = c("Var1", "Var2"
))), .Names = c("dim", "dimnames")), class = "data.frame", row.names = c(NA, 
-12L))

It's also a good idea to list any packages you have loaded so that we know what non-basic functions you may be using. 

>I can share 100 rows if you want, but I don`t you will find it useful, >since I want to perform my time-series on a single row. Here`s one:

I won't  know if it would be useful or not without seeing it.  Generally seeing the original data is helpful as is seeing your basic code.

Have a look at one or the other of these for some suggestions on writing to the R-help list
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: alexandre.piche at mail.mcgill.ca
> Sent: Thu, 4 Jul 2013 07:40:31 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] ggplot2
> 
> Here<s the function last
> 
>> last
> function (x, ...)
> {
>     UseMethod("last")
> }
> <environment: namespace:xts>
> 
> I can share 100 rows if you want, but I don`t you will find it useful,
> since
> I want to perform my time-series on a single row. Here`s one:
> 
> dezdiff.dt[nrow(dezdiff.dt),]
>              datetime       X1        X2        X3         X4        X5
> X6        X7        X8        X9
> 2013-07-04 2013-07-04 1.901595 0.7545192 0.2250272 0.07266123 0.1356831
> 0.3078896 0.5217937 0.7365071 0.9290817
>                X10      X11     X12      X13     X14      X15      X16
> X17      X18      X19      X20     X21
> 2013-07-04 1.08838 1.210787 1.29725 1.351279 1.37761 1.381366 1.367526
> 1.340636 1.304659 1.262931 1.218168 1.17252
>                 X22      X23      X24      X25       X26       X27
> X28
> X29       X30       X31
> 2013-07-04 1.127627 1.084698 1.044577 1.007814 0.9747219 0.9454289
> 0.9199254
> 0.8980989 0.8797653 0.8646931
>                  X32       X33       X34       X35
> 2013-07-04 0.8526222 0.8432792 0.8363881 0.8316789
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/ggplot2-tp4670852p4670857.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From dcarlson at tamu.edu  Thu Jul  4 16:58:27 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 4 Jul 2013 09:58:27 -0500
Subject: [R] how to choose dates data?
In-Reply-To: <1372948114.22446.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAKO0DpjV3o7QUQu-6DxMv0GGXRMG458bVXCoLw36e28mhcY30w@mail.gmail.com>
	<1372948114.22446.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <0f9101ce78c6$f0558fc0$d100af40$@tamu.edu>

Also

> yrs <- as.Date(c("2007-01-01", "2009-12-31"))
> day[day>=yrs[1] & day<=yrs[2]]
[1] "2008-04-12" "2008-04-12" "2008-04-12"

Should be fast if there are many days to process since it converts
the search criteria, not the data.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of arun
Sent: Thursday, July 4, 2013 9:29 AM
To: Gallon Li
Cc: R help
Subject: Re: [R] how to choose dates data?

Hi,
You could try:
day<-as.Date(c("2008-04-12","2011-07-02","2011-09-02","2008-04-12","
2008-04-12"))
?indx<-gsub("-.*","",day)
?day[indx>="2007" & indx<="2009"]
#[1] "2008-04-12" "2008-04-12" "2008-04-12"

#or
library(xts)
xt1<- xts(seq_along(day),day)
index(xt1["2007/2009"])
#[1] "2008-04-12" "2008-04-12" "2008-04-12"

#or
library(chron)
yr1<-month.day.year(unclass(day))$year
day[yr1>=2007 & yr1<=2009]
#[1] "2008-04-12" "2008-04-12" "2008-04-12"
A.K.




----- Original Message -----
From: Gallon Li <gallon.li at gmail.com>
To: r-help <r-help at stat.math.ethz.ch>
Cc: 
Sent: Thursday, July 4, 2013 2:31 AM
Subject: [R] how to choose dates data?

i have converted my data into date format like below:

> day=as.Date(originaldate,"%m/%d/%Y")
> day[1:5]
[1] "2008-04-12" "2011-07-02" "2011-09-02" "2008-04-12" "2008-04-12"

I wish to select only those observations from 2007 to 2009, how can
I
select from this list?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jannetta at henning.org  Thu Jul  4 17:15:33 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Thu, 4 Jul 2013 16:15:33 +0100
Subject: [R] R and MatLab implementations of the same model differs
Message-ID: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/15466958/attachment.pl>

From bhh at xs4all.nl  Thu Jul  4 17:48:50 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 4 Jul 2013 17:48:50 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
Message-ID: <5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>


On 04-07-2013, at 17:15, Jannetta Steyn <jannetta at henning.org> wrote:

> Hi folks
> 
> I have implemented a model of a neuron using Hodgkin Huxley equations in
> both R and MatLab. My preference is to work with R but R is not giving me
> the correct results. I also can't use ode45 as it just seems to go into an
> indefinite loop. However, the MatLab implementation work fine with the same
> equations, parameters and initial values and ode45. Below is my R and
> MatLab implementations.
> 

No problem in running your R file. Have plot.
(Mac mini Core2Duo 2.66Ghz running R 3.0.1 Patched (2013-06-19 r62992) on Mac OS X 10.8.4:  16.5 seconds.)

Trying to run your Matlab file in Octave. No success yet because of unavailable ode45.

Berend

> I'd really appreciate any help.
> 
> R
> ==
> 
> rm(list=ls())
> 
> library(deSolve)
> 
> ST <-  function(time, init, parms) {
>  with(as.list(c(init, parms)),{
> 
>    #functions to calculate activation m and inactivation h of the currents
>    #Axon
>    mNax <- function(v) 1/(1+exp(-(v+24.7)/5.29))
>    taumNa <- function(v) 1.32-(1.26/(1+exp(-(v+120)/25)))
>    hNax <- function(v) 1/(1+exp((v+48.9)/5.18))
>    tauhNa <- function(v)
> 0.67/(1+exp(-(v+62.9)/10))*(1.5+(1/(1+exp((v+34.9)/3.6))));
>    mKx <- function(v) 1/(1+exp(-(v+14.2)/11.8))
>    taumK <- function(v) 7.2-(6.4/(1+exp(-(v+28.3)/19.2)))
> 
> 
>    # Currents as product of maximal conducatance(g), activation(m) and
> inactivation(h)
>    # Driving force (v-E) where E is the reversal potential of the
> particular ion
> 
>    # AB axon
>    iNa_axon_AB <-
> gNa_axon_AB*mNa_axon_AB^3*hNa_axon_AB*(v_axon_AB-ENa_axon_AB)
>    iK_axon_AB <- gK_axon_AB*mK_axon_AB^4*(v_axon_AB-EK_axon_AB)
>    iLeak_axon_AB <- gLeak_axon_AB*(v_axon_AB-ELeak_axon_AB)
> 
>    # AB Axon equations
>    dv_axon_AB <- (0 -iNa_axon_AB -iK_axon_AB -iLeak_axon_AB)/C_axon_AB
>    dmNa_axon_AB <- (mNax(v_axon_AB)-mNa_axon_AB)/taumNa(v_axon_AB)
>    dhNa_axon_AB <- (hNax(v_axon_AB)-hNa_axon_AB)/tauhNa(v_axon_AB)
>    dmK_axon_AB <- (mKx(v_axon_AB)-mK_axon_AB)/taumK(v_axon_AB)
> 
>    list(c(dv_axon_AB,dmNa_axon_AB, dhNa_axon_AB, dmK_axon_AB
> ))
> 
>  })}
> ## Set initial state
> init = c(v_axon_AB=-55,mNa_axon_AB=1,hNa_axon_AB=0,mK_axon_AB=1
> )
> ## Set parameters
> # AB
> 
> gNa_axon_AB=300e-3
> gK_axon_AB=52.5-3
> gLeak_axon_AB=0.0018e-3
> 
> # AB Axon Reversal potentials
> ENa_axon_AB=50
> EK_axon_AB=-80
> ELeak_axon_AB=-60
> 
> C_axon_AB=1.5e-3
> 
> 
> I=0
> 
> parms =
> c(ENa_axon_AB,EK_axon_AB,ELeak_axon_AB,gNa_axon_AB,gK_axon_AB,gLeak_axon_AB,C_axon_AB)
> ## Set integrations times
> times = seq(from=0, to=5000, by = 0.05);
> 
> out<-ode(y=init, times=times, func=ST, parms=parms, method="lsoda")
> plot(out)
> o<-data.frame(out)
> 
> plot(o$v_axon_AB,type='l')
> 
> 
> MatLab
> ======
> 
> File: init.m
> clear all
> close all
> clc
> 
> global c_axon_AB ...
>    gNa_axon_AB gK_axon_AB gLeak_axon_AB ...
>    ENa_axon_AB EK_axon_AB ELeak_axon_AB I
> 
> T_MAX = 5000; % ms
> step = 0.05;
> 
> gNa_axon_AB=300e-3;
> gK_axon_AB=52.5-3;
> gLeak_axon_AB=0.0018e-3;
> 
> % AB Axon Reversal potentials
> ENa_axon_AB=50;
> EK_axon_AB=-80;
> ELeak_axon_AB=-60;
> 
> c_axon_AB=1.5e-3;
> 
> I=0;
> 
> x0 = [-55, 0, 1, 0];
> 
> simulate(T_MAX, step, x0)
> % c_axon_AB, gNa_axon_AB, gK_axon_AB, gLeak_axon_AB, ENa_axon_AB,
> EK_axon_AB, ELeak_axon_AB, I,
> 
> 
> 
> File: simulate.m
> ============
> 
> function[] = simulate(T_MAX, step,  x0)
> %c_axon_AB, gNa_axon_AB, gK_axon_AB, gLeak_axon_AB, ENa_axon_AB,
> EK_axon_AB, ELeak_axon_AB, I,
> close all
> clc
> global c_axon_AB ...
>    gNa_axon_AB gK_axon_AB gLeak_axon_AB ...
>    ENa_axon_AB EK_axon_AB ELeak_axon_AB I
> 
> tspan=0:step:T_MAX;
> 
> %Sx0 = [-55, 0, 1, 0];
> % x0 = [v_axon_AB mNa_axon_AB hNa_axon_AB mK_axon_AB]
> 
> [t,x] = ode45(@integrate, tspan, x0);
> 
> v_axon_AB = x(1);
> 
> vars = getVariables(t,x0);
> 
> 
> figure
> set(gcf,'numbertitle','off','name','AB - Membrane potential')
> plot(t,v_axon_AB)
> title('v axon')
> 
> 
> function out = mNax(v)
> out = 1/(1+exp(-(v+24.7)/5.29));
> 
> function out = taumNa(v)
> out = 1.32-(1.26/(1+exp(-(v+120)/25)));
> 
> function out = hNax(v)
> out = 1/(1+exp((v+48.9)/5.18));
> 
> function out = tauhNa(v)
> out = 0.67/(1+exp(-(v+62.9)/10))*(1.5+(1/(1+exp((v+34.9)/3.6))));
> 
> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
> 
> function out = mKx(v)
> out = 1/(1+exp(-(v+14.2)/11.8));
> 
> function out = taumK(v)
> out = 7.2-(6.4/(1+exp(-(v+28.3)/19.2)));
> 
> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
> 
> function xdot = integrate(t,x)
> global c_axon_AB ...
>    gNa_axon_AB gK_axon_AB gLeak_axon_AB ...
>    ENa_axon_AB EK_axon_AB ELeak_axon_AB I
> 
> v_axon_AB = x(1);
> mNa_axon_AB = x(2);
> hNa_axon_AB = x(3);
> mK_axon_AB = x(4);
> 
> iNa_axon = gNa_axon_AB*mNa_axon_AB^3*hNa_axon_AB*(v_axon_AB-ENa_axon_AB);
> iK_axon = gK_axon_AB*mK_axon_AB^4*(v_axon_AB-EK_axon_AB);
> iLeak_axon = ELeak_axon_AB*(v_axon_AB-ELeak_axon_AB);
> 
> dv_axon_AB = (0 -iNa_axon -iK_axon -iLeak_axon)/c_axon_AB;
> 
> dmNa_axon_AB = (mNax(v_axon_AB)-mNa_axon_AB)/taumNa(v_axon_AB);
> dhNa_axon_AB = (hNax(v_axon_AB)-hNa_axon_AB)/tauhNa(v_axon_AB);
> dmK_axon_AB = (mKx(v_axon_AB)-mK_axon_AB)/taumK(v_axon_AB);
> 
> xdot = [dv_axon_AB dmNa_axon_AB dhNa_axon_AB dmK_axon_AB]';
> 
> %%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
> 
> function out = getVariables(t,x)
> global c_axon_AB ...
>    gNa_axon_AB gK_axon_AB gLeak_axon_AB ...
>    ENa_axon_AB EK_axon_AB ELeak_axon_AB I
> 
> 
> v_axon_AB = x(1);
> mNa_axon_AB = x(2);
> hNa_axon_AB = x(3);
> mK_axon_AB = x(4);
> 
> iNa_axon =
> gNa_axon_AB.*mNa_axon_AB.^3.*hNa_axon_AB.*(v_axon_AB-ENa_axon_AB);
> iK_axon = gK_axon_AB.*mK_axon_AB.^4.*(v_axon_AB-EK_axon_AB);
> iLeak_axon = gLeak_axon_AB.*(v_axon_AB-ELeak_axon_AB);
> 
> out = [iNa_axon iK_axon iLeak_axon ];
> 
> 
> 
> Regards
> Jannetta
> 
> -- 
> 
> ===================================
> Web site: http://www.jannetta.com
> Email: jannetta at henning.org
> ===================================
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Thu Jul  4 17:52:51 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 4 Jul 2013 15:52:51 +0000
Subject: [R] R and MatLab implementations of the same model differs
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
Message-ID: <loom.20130704T175131-611@post.gmane.org>

Berend Hasselman <bhh <at> xs4all.nl> writes:

> 
> 
> On 04-07-2013, at 17:15, Jannetta Steyn <jannetta <at> henning.org> wrote:
> 
> > Hi folks
> > 
> > I have implemented a model of a neuron using Hodgkin Huxley equations in
> > both R and MatLab. My preference is to work with R but R is not giving me
> > the correct results. I also can't use ode45 as it just seems to go into an
> > indefinite loop. However, the MatLab implementation work fine with
> >  the same
> > equations, parameters and initial values and ode45. Below is my R and
> > MatLab implementations.
> > 
> 
> No problem in running your R file. Have plot.
> (Mac mini Core2Duo 2.66Ghz running R 3.0.1 Patched 
> (2013-06-19 r62992) on Mac OS X 10.8.4:  16.5 seconds.)
> 
> Trying to run your Matlab file in Octave.
>  No success yet because of unavailable ode45.

   I'm impressed that you (BH) went to the trouble of checking
on this vague "doesn't work" question.  If you want to go farther
I think you can get ode45 for octave by installing the odepkg
package:

http://octave.sourceforge.net/odepkg/index.html


From jrkrideau at inbox.com  Thu Jul  4 18:09:54 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 4 Jul 2013 08:09:54 -0800
Subject: [R] ggplot2
In-Reply-To: <29857041.179793.1372952032608.JavaMail.nabble@joe.nabble.com>
Message-ID: <6A4FFFE2F6E.00000B9Ejrkrideau@inbox.com>

Thanks Alex,
 I have a working data set (See below) Hopefully this makes the list since what I know about time-series analysis you can write on the back of a stamp.

Now what exactly are you trying to do?  It was not clear from your initial description what exactly you were trying to plot.  Nor was clear to me if the barchart was doing what you wanted or not. Obviously the ggplot chart was not working

Can you set out what steps you are taking (with code) and what you hope to get.  

It is also a good idea to leave in earlier messages as this gives the reader a history to follow. I have included them below 

#==================Earlier messages================#
I have a database of 2000+ days with 35 observations each. I am trying to
modeling a time series by day, but it seems a problem that I don<t have the
time of the observation. I achieve something interesting by using the
barplot function, but I`d rather working with ggplot2, since I have the book
by Hadley Wickham in hands.


I start by transforming my data into a dataframe, but since I have even more
problems working with my data, since all my observations are plot on the
same day.

> str(last(dezdiff))
An ?xts? object on 2013-07-04/2013-07-04 containing:
  Data: num [1, 1:35] 1.9016 0.7545 0.225 0.0727 0.1357 ...
 - attr(*, "dimnames")=List of 2
  ..$ : NULL
  ..$ : chr [1:35] "1" "2" "3" "4" ...
  Indexed by objects of class: [Date] TZ: UTC
  xts Attributes:
 NULL

>barplot(last(dezdiff), beside = TRUE)

<http://r.789695.n4.nabble.com/file/n4670852/barplot.bmp>

> str(dezdiff.dt)
'data.frame':   2741 obs. of  36 variables:
 $ datetime: Date, format: "2003-01-02" "2003-01-03" "2003-01-06"
"2003-01-07" ...
 $ X1      : num  5.63 -1.42 -6.8 -1.9 -6.17 ...
 $ X2      : num  7.748 -0.296 -5.333 -2.348 -5.323 ...
 $ X3      : num  9.075 0.454 -4.294 -2.557 -5 ...
 $ X4      : num  9.863 0.966 -3.542 -2.629 -4.978 ...
...
 $ X32     : num  11.21 1.38 2.44 -3.48 -6.04 ...
 $ X33     : num  11.26 1.24 2.52 -3.47 -6.05 ...
 $ X34     : num  11.3 1.1 2.59 -3.45 -6.06 ...
 $ X35     : num  11.337 0.956 2.658 -3.436 -6.075 ...

qplot(datetime, c(X1:X35), data=dezdiff.dt[nrow(dezdiff.dt),])

<http://r.789695.n4.nabble.com/file/n4670852/ggplot2.bmp>

Anyone know how I could reshape my data or just how I would be able to plot
all my observations on the same graph at different position on the x-axis.

Thank you for your time, and let me know if you have any question.

##==============Alex's Data=================#
dezdiff.dt <-
structure(list(datetime = structure(c(12054, 12055, 12058, 12059,
12060, 12061, 12062, 12065, 12066, 12067, 12068, 12069, 12072,
12073, 12074, 12075, 12076, 12079, 12080, 12081, 12082, 12083,
12086, 12087, 12088, 12089, 12090, 12093, 12094, 12095, 12096,
12097, 12100, 12101, 12102, 12103, 12104, 12107, 12108, 12109,
12110, 12111, 12114, 12115, 12116, 12117, 12118, 12121, 12122,
12123, 12124, 12125, 12128, 12129, 12130, 12131, 12132, 12135,
12136, 12137, 12138, 12139, 12142, 12143, 12144, 12145, 12146,
12149, 12150, 12151, 12152, 12153, 12156, 12157, 12158, 12159,
12160, 12163, 12164, 12165, 12166, 12167, 12170, 12171, 12172,
12173, 12174, 12177, 12178, 12179, 12180, 12181, 12184, 12185,
12186, 12187, 12188, 12191, 12192, 12193), class = "Date"), X1 = c(5.63340992439501,
-1.41565642244369, -6.79925676670176, -1.90002133667107, -6.17055219864562,
5.13460503429066, -1.68101296436827, 1.40984788014491, -1.66215976809637,
-0.91051023948921, 3.74527525211818, -12.9021280212811, -2.72073460043553,
2.14060881898268, -4.61816633756794, 0.0744860772522102, 6.87890468837479,
3.31062883679092, 0.247181974141267, -2.82514915886396, 1.63685535388959,
-0.00393829663658529, 3.51459617274934, -2.01758040450428, -1.95486424887422,
-1.30624514384434, -4.34156509919795, -2.05213952041622, 2.81464674844883,
1.12714701477112, -4.76044437296205, 2.9751732461342, 1.12563500511788,
-2.23730784687626, -2.29796311261802, 1.90893093720054, -3.09715972865953,
-8.0379459841556, 1.97772072939712, -5.02570924723309, 3.51238972300109,
-6.68712297950062, 3.14913921935268, -2.55539815296409, 0.41323556306979,
2.85348735750784, -6.07451177797993, -2.503378275449, 2.36584091871009,
1.83200262891418, 16.8630506013139, 1.47744542565959, 6.88521405532435,
-3.38655801221152, 6.30333826181582, -2.7823646867647, 3.76044205652456,
-3.25908731078833, -1.45339750879301, 1.180662415898, -4.38868161438188,
-4.41998134837116, -3.50639155244942, -2.01872869205186, 3.3143896364151,
1.10024578829027, -2.58592210640347, 10.2799650481528, -2.58475362660521,
-0.0771368859494789, -7.08964329650428, 6.05806311892089, 8.13013594528518,
0.72238031641296, 0.772712826895561, -5.5510157273456, 1.27268035381975,
1.71655448261823, -6.11391418939698, 1.9126338728985, -3.94250141779972,
-3.64609005713688, 0.93907988398808, 0.714198474232736, -3.48872852483296,
-1.3416735474564, 0.0138578284692922, 0.108379180289442, -1.78476034598925,
-5.93566756825627, 3.09908295556962, 1.19269469974342, -4.34027643316012,
-3.17734236713989, 1.15234007941726, -3.29418654825282, -0.470965143050742,
-4.29439015673928, 1.3578516718037, 5.42610503057039e-05), X2 = c(7.74814601001997,
-0.296328951317898, -5.33280241585748, -2.34844486847109, -5.32265983423864,
3.69107739608403, -2.3346868154716, 2.34149220321271, -1.49283160293605,
-0.800997949928078, 2.52384156463146, -9.16655192489766, -2.30448953297321,
1.30210644267797, -3.07785519253471, -0.448939049589384, -0.342583107230954,
2.8755966646778, 0.712162607077148, -1.60556422386184, 2.01137957690535,
-0.971127367640212, 2.39757163040606, -3.97725241811881, -0.876045882583915,
-1.47633264277598, -4.51718354971216, -0.613551317398368, 0.608175805318981,
-3.40881842846138, -4.82539373430287, 3.67069411180108, 1.40721210628185,
-0.487894695318722, -4.38620674026148, 0.383019272843094, -0.176470161069586,
-6.84846324783852, -0.75987617559347, -2.62986779213544, 5.26903113362277,
-6.33670343779917, 0.285291855931999, -0.892472378335694, 0.295023107777272,
0.103359440148248, -4.03922724767029, -2.17014345133805, 2.66449963574014,
2.36955015400726, 17.5475586351432, 3.44477727570246, 10.7310051010041,
-1.83465667403338, 8.4548458932936, -4.07076291174244, 5.17573174181503,
-4.90185625109288, -1.55405837527916, 0.118696535474222, -4.63593737727905,
-3.92618682499228, -6.95322342701109, -1.84045145689763, 6.77962020064,
2.71891429246454, -1.9604622794608, 8.88807481056616, -2.37588080654195,
-2.31317731674733, -6.07020144621051, 7.60269671021538, 7.34286047251197,
-1.48323542327529, -0.3171925077948, -3.79392091121113, 1.66463009610162,
1.30534543605603, -6.84291056828431, 2.17634083888061, -5.49611763410063,
-2.84244162248048, 1.86736613078286, 1.40785997123905, -5.24890524596804,
-2.10981289477608, 0.937521427344032, 0.438207791248826, -0.884115947236072,
-8.87623013628998, 0.235226045732784, -0.196103426458386, -3.10029318163447,
-2.54530539810158, -0.831528418824834, -2.19855552832226, -2.45723240933762,
-4.82435111808018, 0.566497858012528, -0.42388696179195), X3 = c(9.07455039287925,
0.453764766579177, -4.29444783772118, -2.55653313346791, -5.00017271336622,
2.9503147777616, -2.55239865052964, 2.82011836073889, -1.35964650850168,
-0.819841535736852, 1.57544933281552, -7.61161106225806, -2.07788528044026,
0.565267703790256, -2.13433208947799, -0.848694226313861, -4.34689949524929,
2.51522002036722, 1.23311537226042, -1.27630359940137, 2.34058518845382,
-1.4746272559309, 1.70581203255474, -5.19308016612124, -0.171598933120555,
-1.44518501489957, -4.42164374677614, 0.340140035663301, -0.566368158253158,
-5.80902954627302, -4.76768308138111, 4.16517311721813, 1.56308049995606,
0.593188127162234, -5.73523207989302, -0.700541117868228, 1.75057386199846,
-6.12215871074805, -2.20168797450498, -0.995154606921421, 5.99770504468772,
-5.93583313587179, -1.27246362963747, -0.13164321181737, 0.0899324472660584,
-1.33773568276395, -2.89605555335755, -2.17472250010883, 2.71525464254397,
2.54493617999042, 17.5538966014819, 4.70989171131995, 12.8598046804392,
-1.03823035389767, 9.62682991187874, -4.65048792797119, 6.223829841976,
-5.92000294180658, -1.53946352217684, -0.484570148278421, -4.75343506890262,
-3.54208820298369, -8.78908967689912, -1.6730943320142, 8.65670698735669,
3.84307892809996, -1.25525278423674, 8.26850980251041, -2.44265459435629,
-3.223911172942, -5.91819223680609, 8.20305350119097, 6.52589146897521,
-2.74305134611432, -1.27930062324397, -2.72295864633697, 1.87547953208272,
1.00817677169383, -7.01278423445913, 2.45582491762587, -6.2523042064614,
-2.3090260526562, 2.32230480839684, 1.85099708337411, -6.14484567274337,
-2.07098422259966, 1.02057841863339, 0.545825130034497, -0.295863461178165,
-10.5741697496096, -1.46674303787283, -1.03692782626796, -2.43153257983391,
-2.03157573195438, -1.57896657470197, -1.72721727349379, -3.68263490993732,
-5.19192857620102, 0.0551546178346671, -0.834026456719844), X4 = c(9.86312420627793,
0.965859773708611, -3.54193853670241, -2.62907451786823, -4.97751029035487,
2.60928602183817, -2.5174735502486, 3.01303286410502, -1.29004813926692,
-0.88513741693573, 0.874574869783179, -7.21337817363173, -1.98175178991414,
-0.0770717878608579, -1.59044690046843, -1.16018701660663, -6.39039885661181,
2.17728801791738, 1.73594615626788, -1.3020771117736, 2.63492925974232,
-1.67465375868418, 1.30086783580858, -5.90271698292427, 0.278592059002707,
-1.2889488860246, -4.16655840360689, 0.961965774399741, -1.0892361755337,
-6.86133698696585, -4.61776957677913, 4.49403556734507, 1.6180525290858,
1.21222430483688, -6.55953830515817, -1.42848306530989, 2.9472289390953,
-5.64345652444193, -2.80090821435614, 0.0786270150225296, 6.14693010918464,
-5.55128427672712, -2.01848711348644, 0.135194063153599, -0.164736058317246,
-1.97978040966697, -2.35114364598523, -2.32313422855832, 2.61662555201415,
2.49349814148068, 17.162618778488, 5.46482383988998, 13.8988855687715,
-0.741053190780119, 10.1611524368953, -4.78092458414681, 6.95155398786042,
-6.50378783083064, -1.4112895258428, -0.781820839658998, -4.77745691720009,
-3.25077884521855, -9.58486567906855, -1.51445078957198, 9.49935510654434,
4.60962003144015, -0.613379839497635, 8.02613059219033, -2.61518569692941,
-3.39353712874475, -6.14588504425133, 8.24594862634621, 5.71642258959754,
-3.3897765900464, -2.06879772751044, -2.10291097685104, 1.97613721064541,
0.793815813583745, -6.84695692515031, 2.71927324189708, -6.50491614134427,
-1.93687224803323, 2.48992137619593, 2.12067601699142, -6.48523883403959,
-1.70374375977753, 0.767536356142857, 0.502966007121346, 0.0790041871326017,
-11.4476687624616, -2.42901149363529, -1.49940227139083, -2.08808540153694,
-1.61816951104898, -1.64554212880457, -1.66613417984591, -4.40859101082009,
-5.45650066057085, -0.262623675069511, -1.21938898921391), X5 = c(10.2930275100371,
1.326811696266, -2.97773202573515, -2.6331812588113, -5.10998688347197,
2.47549540459815, -2.35164605905731, 3.03407818947103, -1.29252557817913,
-0.948872803580997, 0.388730632240666, -7.35337139147529, -1.97342573071573,
-0.633374464276207, -1.30875441544727, -1.40834769077884, -7.28109891098568,
1.83662946938619, 2.18199188529417, -1.3956221968682, 2.90156124930246,
-1.6817049105404, 1.08599000808923, -6.27159958163086, 0.558378647109309,
-1.05951207470097, -3.82652035535093, 1.35893248182729, -1.21497374728045,
-7.09014094831303, -4.40067688887755, 4.68744593058748, 1.59363834515779,
1.51846415624435, -7.01632879406264, -1.87343792251202, 3.61363339385426,
-5.28366866946274, -2.86503810462715, 0.74169706764271, 5.99806056725379,
-5.213773191277, -2.28034438959305, 0.159842467045319, -0.443724825067646,
-2.15318415287206, -2.19861437229199, -2.50583214773895, 2.43476501157004,
2.30733066304768, 16.5603507262523, 5.85467793049063, 14.2673384447397,
-0.765144285344993, 10.2920555273781, -4.63907370942145, 7.4158077258106,
-6.79249247903739, -1.18577408143132, -0.879149075382613, -4.73343216598622,
-3.03766048419363, -9.73183437101954, -1.3627379157892, 9.68811574194199,
5.11615925109996, -0.0983617708665702, 7.92956473083528, -2.79782515205301,
-3.19194978271632, -6.47049696576515, 7.9800565253707, 4.93998857313861,
-3.64779536783086, -2.68294540146388, -1.77093034883766, 2.014227111189,
0.639681779388071, -6.49365244510695, 2.95142747398787, -6.45000342186522,
-1.65915194200762, 2.49240268492365, 2.27087890082932, -6.48124865167916,
-1.27215413150944, 0.458605104920809, 0.359951535372285, 0.309807164421347,
-11.7842473183418, -2.92806024981482, -1.70591674114817, -1.91557067750887,
-1.28988646945927, -1.37580341180905, -1.86518167990278, -4.81468493445436,
-5.65816138338268, -0.449766817458216, -1.5737056835044), X6 = c(10.4911242443098,
1.59288874268027, -2.53574351338555, -2.61032778934307, -5.30772125181669,
2.43108206939027, -2.13337414303773, 2.9591460447103, -1.36408831400509,
-0.985626609970522, 0.0833838646701474, -7.67426767940553, -2.02231572433306,
-1.11239729491855, -1.19403470790209, -1.6107052192315, -7.52939037381405,
1.48438307010591, 2.55507707074741, -1.42131602624156, 3.14537596802417,
-1.57136929191538, 0.993948567584724, -6.41437486611517, 0.725986011677685,
-0.791827048783264, -3.45051364516187, 1.60553020661244, -1.11213444530051,
-6.83984809655959, -4.13682993661325, 4.77102500143267, 1.50836480857314,
1.61893117977659, -7.22017910650297, -2.09600550483489, 3.9016022655184,
-4.97004356178853, -2.60094322709931, 1.10679623557708, 5.7223301541999,
-4.93312234640518, -2.27113297215475, 0.0917111646767804, -0.730188378329499,
-2.06811036254639, -2.29543701653678, -2.66576541487325, 2.21339138974055,
2.0483472957103, 15.8688273468632, 5.98810633642824, 14.2421207157571,
-0.987714046445792, 10.1785771147912, -4.3443591070294, 7.67320480795815,
-6.88710786157266, -0.884669856503692, -0.849814881942121, -4.63927825697236,
-2.89019080547417, -9.4955310796245, -1.21656046845713, 9.48219725843552,
5.43247873845722, 0.271970525404994, 7.85169816485715, -2.94185632359376,
-2.84516935282385, -6.74072106013876, 7.56207232902338, 4.21320372289848,
-3.66713225990876, -3.1401089251807, -1.61523267376736, 2.0211956930756,
0.529427679796315, -6.04964876092968, 3.14674511166513, -6.21692970547115,
-1.43586252123358, 2.40878426897129, 2.33932207717849, -6.27584575748276,
-0.907712833425542, 0.234675061256476, 0.15198459061061, 0.444860341144993,
-11.7802494293145, -3.1430873286175, -1.74419145030545, -1.81949114198249,
-1.03385899048562, -0.976291762665171, -2.22012087366531, -5.02263181229812,
-5.82329493652542, -0.55155061633394, -1.89403767616024), X7 = c(10.5461402750304,
1.79955406523637, -2.17185609035782, -2.58481031236067, -5.5174145322813,
2.40774297624043, -1.91109017943794, 2.8374679645625, -1.49534356965346,
-0.984617787046574, -0.075037190295224, -7.98367222956314, -2.106639029077,
-1.52262026175166, -1.18086288112974, -1.77956846159066, -7.45007263639262,
1.12095557860188, 2.85272273921978, -1.33257427042538, 3.36974202243628,
-1.39480254977307, 0.978365761500136, -6.41005554570445, 0.821570799744084,
-0.509073090891529, -3.06991509364071, 1.75332313573924, -0.890715862116725,
-6.33280305381935, -3.84277172031225, 4.76647402790471, 1.37807775846967,
1.58953384966819, -7.25405577708699, -2.14653813826793, 3.92595556064336,
-4.66499155347168, -2.14637056823445, 1.25854474079118, 5.41943754967966,
-4.70776917996463, -2.12613741699091, 0.0142733424587926, -1.01313047045526,
-1.85501610940608, -2.54325608076221, -2.7775868484417, 1.98075942357927,
1.75748996829622, 15.1652653920693, 5.94571310326364, 14.0036377406533,
-1.32480471875814, 9.92740597931363, -3.97613256077768, 7.77486303992013,
-6.86003775498815, -0.530227275371067, -0.743997828527992, -4.50772297568403,
-2.79763106705196, -9.0537809466492, -1.07486173207598, 9.05607646564929,
5.60862150157659, 0.504361310402074, 7.73012843450493, -3.02730255378372,
-2.48414050304638, -6.88730136171885, 7.0880331419778, 3.54599033548571,
-3.54699936318696, -3.46733061699495, -1.55995700563176, 2.01731415159515,
0.45120129286029, -5.57673759027717, 3.30511364870903, -5.88983060568572,
-1.24381480644947, 2.28911520557866, 2.35228150511843, -5.96450806216342,
-0.662756975302048, 0.152877901872309, -0.096390516933012, 0.517644810899137,
-11.5686021884921, -3.18878499361408, -1.67657360577597, -1.74408728931277,
-0.839172609724478, -0.564674187896741, -2.65949856474663, -5.11353582813741,
-5.96865835920606, -0.600080076132645, -2.17974628146489), X8 = c(10.5191559288358,
1.96835037428206, -1.85715876990372, -2.56964278656381, -5.70972774782151,
2.36937254592236, -1.71272427742127, 2.69978381143184, -1.67386766663391,
-0.944177431638771, -0.117432182109439, -8.19060865653892, -2.21102376881784,
-1.87194644521806, -1.22477839408122, -1.92357123157523, -7.23100403687685,
0.751501873437616, 3.0802718022048, -1.13191115725553, 3.57700337934447,
-1.18612758773881, 1.00755556786271, -6.31272452217647, 0.872585038278542,
-0.226287498148042, -2.70408913685065, 1.83775167557992, -0.621066298783085,
-5.70931553850282, -3.53177804249899, 4.69211750342924, 1.2162258576992,
1.48338032016228, -7.17757381838352, -2.06667680978684, 3.77319254351617,
-4.35231022638045, -1.5919008018489, 1.26044738643694, 5.14344411023958,
-4.53058914429066, -1.92836758483132, -0.0304947194091493, -1.28559870858108,
-1.59218489179241, -2.87529537865143, -2.83430974591173, 1.75453973757012,
1.46120877030191, 14.4966098061449, 5.78670370342205, 13.6671094212969,
-1.7196952261031, 9.60896380767705, -3.58600193277644, 7.76426338840827,
-6.76247744234824, -0.142642018204214, -0.595703098049682, -4.34791342328822,
-2.75080794565175, -8.52352071309438, -0.936870534676074, 8.52532406675731,
5.68063324577393, 0.617296132445488, 7.54121916808959, -3.05098494729789,
-2.17825798524064, -6.89021298530317, 6.61444988686109, 2.94335340905186,
-3.3520739916517, -3.69329906603856, -1.55442011809656, 2.0151905310694,
0.396394014219037, -5.11309678173102, 3.42921902173422, -5.52236400517242,
-1.07015209051084, 2.16412460559728, 2.32800337915118, -5.60980167713797,
-0.544725111155386, 0.222367653333333, -0.368132188059145, 0.551190837140003,
-11.2382956515439, -3.13742078666059, -1.54690487077933, -1.65829952423945,
-0.696548548692541, -0.202527327900631, -3.13515565995758, -5.1402602445727,
-6.10435200966271, -0.617705589114406, -2.43172926937305), X9 = c(10.4513548464166,
2.11170055556487, -1.57315470151589, -2.57062570517483, -5.87062397588454,
2.3001742402718, -1.55249430392634, 2.56421057102545, -1.88637579766102,
-0.867964356981582, -0.0711769932931067, -8.26414892530186, -2.32474982754506,
-2.1675689915282, -1.29601907396262, -2.04876543995411, -6.97894882471704,
0.383110488990993, 3.24704558503655, -0.846055011363422, 3.76882276533194,
-0.967652010603962, 1.06014959294472, -6.15908277151994, 0.897578085330766,
0.0470863769282126, -2.36428649088877, 1.8829507433199, -0.346875926086759,
-5.05516684058009, -3.21438387764078, 4.5633748813638, 1.03412500126861,
1.33697969459945, -7.03316859498669, -1.89067249129482, 3.50813484307086,
-4.02819023518582, -0.996164969108981, 1.1601352791852, 4.91999260152379,
-4.39234507662728, -1.72623650277925, -0.0259106468406683, -1.54341593673002,
-1.32428981922179, -3.24695523698494, -2.83890098433173, 1.54522414490349,
1.17600980806515, 13.889457036878, 5.55408855399744, 13.3040833000082,
-2.13469448633805, 9.26869497619776, -3.20649304842678, 7.6768468854186,
-6.62999450072033, 0.261033623754278, -0.427644321479848, -4.16652708446541,
-2.74189673470308, -7.97967097452584, -0.802049838753496, 7.96478417286063,
5.67462931523162, 0.633466999197876, 7.28335226236436, -3.01883019087158,
-1.95816346843319, -6.75722567132213, 6.17246931075011, 2.40676848486936,
-3.12371427386229, -3.84465853203876, -1.56550141047013, 2.02222822357011,
0.35874030132603, -4.68112012208775, 3.52297399496014, -5.1478123843466,
-0.908204473917471, 2.0517923934938, 2.27911125613975, -5.25162772807654,
-0.537684496504098, 0.426913990659375, -0.65147095119053, 0.561187056092385,
-10.8480239351369, -3.0336314719856, -1.38558485336428, -1.54652171760125,
-0.598079239575375, 0.0830130133006729, -3.61537264626337, -5.13624594341157,
-6.23596404503782, -0.619615273199092, -2.65186058058385), X10 = c(10.3697238501942,
2.23621789841963, -1.30838708995204, -2.58912003375758, -5.99550109592339,
2.19662796854189, -1.43570108306582, 2.44042439354435, -2.12005593191705,
-0.762425058815006, 0.0401730332863504, -8.20691191220323, -2.44046038472244,
-2.41593731256907, -1.37508133620783, -2.15939342403458, -6.74992364725326,
0.0231267800830659, 3.36390063051889, -0.510949240569228, 3.94641517007063,
-0.75353846810268, 1.1219955019913, -5.97376120566991, 0.908887326994123,
0.305416355586008, -2.05634962690458, 1.90515780879176, -0.0940727550173548,
-4.42039097725368, -2.89883336296232, 4.39317020417544, 0.841202886300366,
1.17484983074838, -6.85069551826838, -1.6465214132471, 3.17901533117997,
-3.69545849949665, -0.396334631577455, 0.993287986608346, 4.75762260854842,
-4.2836315143549, -1.54570197231002, 0.0300072841580984, -1.78429142909227,
-1.07479931479117, -3.62908992110784, -2.799112584944, 1.35849333562497,
0.911637592916487, 13.3569341882921, 5.27871602379243, 12.9571317257536,
-2.5453427668147, 8.93497005203303, -2.85711854563012, 7.5405280148403,
-6.48672766775965, 0.667146564313978, -0.254689811430217, -3.96853624251708,
-2.76422863877336, -7.46838056578394, -0.670049786191534, 7.42133996563768,
5.60967311158025, 0.575574830864803, 6.96634387816003, -2.94103966439439,
-1.83105082188696, -6.51020338350961, 5.77728900472162, 1.93524939048798,
-2.88765770025519, -3.94433114776604, -1.57225586962927, 2.04234063164117,
0.333669126926228, -4.29278519473338, 3.5906161716736, -4.78597223280253,
-0.7548758032494, 1.96179488114033, 2.21430212586311, -4.91440353262623,
-0.615477728147934, 0.738792796058443, -0.938334934104598, 0.558183151366173,
-10.4357139291036, -2.90427157815909, -1.21329673022662, -1.40256825353138,
-0.537008583645915, 0.285139094387751, -4.07993800758219, -5.12175862742728,
-6.36610422894729, -0.615792846974869, -2.84258475349942), X11 = c(10.291226504711,
2.34495736865431, -1.0560810395379, -2.62390973938181, -6.08527523484434,
2.06215449300606, -1.36207552302689, 2.33261144090981, -2.36333031405592,
-0.635133655366438, 0.196835473377788, -8.03845756130753, -2.55321982141302,
-2.62277942345013, -1.44957984412275, -2.25843273443389, -6.56906650531801,
-0.321778238705217, 3.44173882539864, -0.163148208920799, 4.11070529134236,
-0.552379759533039, 1.18396133121673, -5.77305047450599, 0.914538918165078,
0.545638469505033, -1.78258069806134, 1.91511923192701, 0.123110496361711,
-3.8319999223823, -2.59146382181205, 4.19228752701617, 0.645223809843526,
1.01292657593975, -6.65084716291016, -1.35693931642381, 2.82137787342748,
-3.35999123214283, 0.184691416177316, 0.786569195308576, 4.65509741823203,
-4.19588388093646, -1.39852648977853, 0.131340428897522, -2.00720041493248,
-0.85417833449529, -4.00322445857942, -2.72441161384425, 1.19685563955266,
0.67329385083123, 12.9034398750252, 4.98237191193192, 12.6498456083672,
-2.93632277337912, 8.62460022302544, -2.54861544787675, 7.37662952130201,
-6.34852949003013, 1.06525627316362, -0.0862897414400515, -3.75773180646861,
-2.81212229617842, -7.01629216519284, -0.540666491626943, 6.9228510982438,
5.49981182939412, 0.46418945651841, 6.60494588203241, -2.82916142159646,
-1.79077712984796, -6.1766055384755, 5.43435546246786, 1.52615711321344,
-2.65928227877736, -4.01100643254326, -1.56211157594829, 2.0771416277978,
0.317836633742241, -3.95331429104369, 3.6362214901748, -4.44782855678831,
-0.609027299818821, 1.89849546688825, 2.1395392079878, -4.61207856468672,
-0.749428011087155, 1.12700676864863, -1.22324004956473, 0.549147820762472,
-10.0251618147231, -2.76492048728656, -1.04374205856253, -1.22578368493546,
-0.507549640583055, 0.408322787927851, -4.51661537077486, -5.10828168947458,
-6.49548858940703, -0.61248830391783, -3.0066282981174), X12 = c(10.225842930016,
2.43892019602482, -0.812509978023804, -2.67242790352673, -6.14381673613419,
1.90364971377796, -1.32808110467141, 2.24152506016789, -2.60623289099898,
-0.493747099872405, 0.382552209540546, -7.78519404925827, -2.65982620753717,
-2.79315345630637, -1.51203101608231, -2.34797969422197, -6.44346990602576,
-0.646061454145364, 3.4906563788846, 0.164729534194163, 4.26243258711018,
-0.368999674028661, 1.24038416960286, -5.56751294763048, 0.919587498613983,
0.76639405626619, -1.54302305213454, 1.91978576185636, 0.298019337151567,
-3.30252540804321, -2.29703286842471, 3.96967903868006, 0.452494113799135,
0.861073850524016, -6.44768295277584, -1.04019644149564, 2.46106730547514,
-3.02856284248761, 0.733398747302244, 0.5598255272702, 4.60605766212423,
-4.12182245233379, -1.28783004833197, 0.268528447971567, -2.21195282709877,
-0.6652367830811, -4.35817016318785, -2.62424844018581, 1.06077486377788,
0.463177611308291, 12.527887468634, 4.68014329128033, 12.3935914997675,
-3.298583389117, 8.34666924646586, -2.28589168081515, 7.20095109011033,
-6.22530587980841, 1.44774107292953, 0.0718187190987263, -3.53708076380639,
-2.88073819378482, -6.6369994970069, -0.413806918771187, 6.48438825055483,
5.35551525804347, 0.316841784635882, 6.21501834248285, -2.69440829115057,
-1.82440251499917, -5.78443959438041, 5.14339472112414, 1.17580313581486,
-2.44718335239071, -4.05926883678777, -1.52819300421853, 2.12676736974678,
0.308789122793265, -3.66365508618641, 3.66346942047631, -4.1387072273795,
-0.470502253436325, 1.86294256718636, 2.05888899647622, -4.35162379009778,
-0.912572140390824, 1.56187189442436, -1.5025089978471, 0.53856862521573,
-9.63063898466073, -2.62414320237409, -0.885642889007429, -1.0185711628214,
-0.504733433743867, 0.462640136079454, -4.91862527160575, -5.10157785430267,
-6.62369570282477, -0.613315672865558, -3.14679884610661), X13 = c(10.1787701326951,
2.51803673327361, -0.575876075562046, -2.73154268457733, -6.17631476224068,
1.72930158227717, -1.32846827475296, 2.16589846841565, -2.84053605864976,
-0.345384570701462, 0.584235735175062, -7.47451210490545, -2.7583106568748,
-2.93151189082311, -1.55829270681106, -2.42951884981128, -6.37032625698336,
-0.945464931178391, 3.51951219330487, 0.446040550116308, 4.40222044012728,
-0.205707373344827, 1.28797677291077, -5.3638061400782, 0.927057911159629,
0.967433855018004, -1.3363334013728, 1.92350416074662, 0.428800553217076,
-2.83568680985585, -2.01899645367314, 3.73273192531609, 0.268048955613595,
0.724921203283518, -6.25049461569001, -0.710832165672984, 2.11652329149201,
-2.70762971751978, 1.24235959283903, 0.327735400199661, 4.60190073418548,
-4.0555679699851, -1.21176693842678, 0.430943930917471, -2.39889520030796,
-0.506556914910763, -4.68764515105906, -2.50716124720461, 0.949440958487591,
0.281548260541789, 12.2259031055946, 4.38220848288068, 12.1920484751522,
-3.62732244508578, 8.10518302942882, -2.07006424568293, 7.02481410554012,
-6.12274803275983, 1.80933433431056, 0.216417193305146, -3.30896905518116,
-2.9659538986257, -6.33552597135711, -0.289459621682503, 6.11256288462918,
5.18469214888656, 0.147823353740043, 5.81141806989247, -2.54677585990723,
-1.91629970846569, -5.35946504173462, 4.9009927400636, 0.879892098733376,
-2.25559025346669, -4.10003951118676, -1.46744325758605, 2.19043951848949,
0.304719824767222, -3.42214790497855, 3.67555564035414, -3.8603849972612,
-0.339557466332296, 1.85419265579467, 1.97510719713238, -4.13544679557218,
-1.08172819146622, 2.01732432334886, -1.77372264369043, 0.529226627309781,
-9.26007509516859, -2.48624983693713, -0.74420292254275, -0.784852641925321,
-0.524283498888473, 0.46031813062751, -5.28286063856763, -5.10380009299864,
-6.74968458446619, -0.620066375408082, -3.26584963073931), X14 = c(10.1520029679974,
2.58178877008061, -0.345552997843765, -2.79804242595362, -6.1882718834097,
1.54727524848616, -1.35729777003317, 2.10339618871805, -3.05972014877691,
-0.196294069270408, 0.791572949092392, -7.13161375281927, -2.84757365876909,
-3.04176879879166, -1.58646940421461, -2.50411176926667, -6.34197938251625,
-1.21699785055301, 3.53576397025941, 0.660663318355764, 4.53062090998733,
-0.0631668427643339, 1.32505926211564, -5.16595087770223, 0.938604942327184,
1.1492091920548, -1.16036928613658, 1.92885211766018, 0.516543399126865,
-2.43009770234691, -1.75974467396499, 3.48749926942504, 0.0958212674286724,
0.607200029475868, -6.06517587376169, -0.380265710989494, 1.80054141654611,
-2.40270985557754, 1.70802947542563, 0.101047638931331, 4.63349690992793,
-3.99257797207571, -1.16591243081075, 0.608367091789394, -2.56870602339809,
-0.37463907728609, -4.98861391835803, -2.38038863757353, 0.861291789703081,
0.127454176793024, 11.9912972312728, 4.09518323740393, 12.044227769495,
-3.92057714816693, 7.90089036442641, -1.89985985847844, 6.85600403649157,
-6.04360675685894, 2.14666599730393, 0.345972858916549, -3.07536591677357,
-3.06425774268718, -6.11141250451308, -0.167670841322368, 5.80851749800763,
4.99340795375461, -0.0316343575620937, 5.40696442228171, -2.39466022053519,
-2.05063066075359, -4.92383331404639, 4.70221337579027, 0.633840581754641,
-2.08598682567382, -4.14114040813908, -1.37931248439555, 2.26684760376294,
0.304293184731283, -3.22563455583763, 3.67518692484484, -3.61248874285208,
-0.216548356807289, 1.870176538213, 1.89004771712638, -3.96305286306638,
-1.23825559962008, 2.47183919569904, -2.03533538549391, 0.522740433531454,
-8.9172463913461, -2.35305863951832, -0.62216997856801, -0.529134950722071,
-0.562511660606793, 0.413725674896226, -5.60863100957577, -5.11492765094129,
-6.87214094776158, -0.633306570565345, -3.36639209930052), X15 = c(10.1454599947767,
2.62958606887291, -0.121582212491422, -2.86891813009997, -6.18491966656164,
1.36497612241292, -1.40859091498968, 2.05123837571715, -3.2588501701461,
-0.0517088851761244, 0.996625871405449, -6.77801741426336, -2.92712167117619,
-3.127364683446, -1.59614722474104, -2.57252892254436, -6.34895779210436,
-1.45882236495115, 3.54546850780423, 0.794706827125236, 4.64814301993924,
0.059004188126266, 1.35102129978172, -4.97620931031423, 0.954973592526068,
1.31259386009067, -1.01257938604604, 1.93722101829698, 0.564047474129886,
-2.08164447241657, -1.52080126077828, 3.23889961600744, -0.0612061099426048,
0.508707487725871, -5.89522325820775, -0.0573171834829245, 1.52162636852526,
-2.11813134933909, 2.12929149740353, -0.112485864868297, 4.6921544700361,
-3.92949553336193, -1.14477054105146, 0.791755495115898, -2.72225648522507,
-0.265202105693488, -5.26013892891343, -2.24977873608971, 0.794362139689281,
-0.000772348125246958, 11.8170337988983, 3.82312634864518, 11.9464601522729,
-4.1782436208878, 7.73252435941542, -1.7725694190978, 6.69957903529028,
-5.98862380633572, 2.45784724036434, 0.460059778999017, -2.83793469102865,
-3.17265857783827, -5.96083027243947, -0.0485253190896789, 5.56997631239307,
4.78639169527603, -0.213000446161113, 5.01206002489756, -2.24477616948798,
-2.21274348160778, -4.49561534426095, 4.54158412374749, 0.433001589726853,
-1.93818798296941, -4.18787223454821, -1.2648468589848, 2.35440537348613,
0.306517774384188, -3.07018556998315, 3.66461822308574, -3.39341241384225,
-0.101768709317787, 1.90825812715158, 1.80494720211019, -3.83217823535405,
-1.36806242052812, 2.90854029361909, -2.2864060786993, 0.519946949282743,
-8.60327050448882, -2.22500300720914, -0.520605198756283, -0.255964965415537,
-0.616231275395313, 0.334286666394054, -5.89678625081982, -5.13372639890583,
-6.98970113616991, -0.652811196410197, -3.45084354719111), X16 = c(10.1577764864091,
2.66097824053534, 0.0956548157991788, -2.94151202408249, -6.17091018827877,
1.18868919358299, -1.47672132254514, 2.00659571891276, -3.43440356103931,
0.0841745385114084, 1.19345285247742, -6.43107101473382, -2.99687698822035,
-3.19132615745024, -1.58786216940668, -2.63534146575567, -6.38171059460978,
-1.67009410673949, 3.55337655775466, 0.839794010545, 4.75527005785188,
0.161824932614837, 1.36594741670923, -4.79568946909835, 0.976318500519671,
1.45869695885606, -0.89025803951967, 1.94922080386073, 0.575016435853601,
-1.78497450909774, -1.30299187986668, 2.99088925798746, -0.200864056033451,
0.428995143157904, -5.74246340227402, 0.251348683804262, 1.28503262209201,
-1.85699971325996, 2.50650729342987, -0.30740568532521, 4.77010978656441,
-3.8639650396919, -1.14268998255215, 0.973573464032804, -2.86051681235175,
-0.173934184556773, -5.50259476944801, -2.11986069037946, 0.746513339989555,
-0.105182912404009, 11.6958542724026, 3.56828573049806, 11.8936847314782,
-4.40139885816877, 7.59764040712728, -1.68469132295151, 6.55853997998009,
-5.95720731497593, 2.74211381884687, 0.558959374356363, -2.59810737842522,
-3.28860934943984, -5.87801206305492, 0.0678688411310385, 5.39263894462995,
4.56739411646312, -0.390022406367638, 4.63469116172614, -2.10224558160749,
-2.38987048601737, -4.08885306445152, 4.41367173851709, 0.272818152337387,
-1.81104648660821, -4.24354948731505, -1.12606037271465, 2.45141973435448,
0.310654250211678, -2.95156817078333, 3.64570806318139, -3.20090865464084,
0.00461817582175783, 1.96558753815246, 1.72062223473136, -3.73955520597401,
-1.46121200205095, 3.31486985474187, -2.52641024089312, 0.521166694088943,
-8.31761927534536, -2.10181086777492, -0.439437005519822, 0.0303692266977185,
-0.682684830554392, 0.231968107950661, -6.1491114226412, -5.15837675245094,
-7.10108994230997, -0.677875218323479, -3.52139983534054), X17 = c(10.1868553366511,
2.67575879466159, 0.305643697310759, -3.01357986332088, -6.15018372761275,
1.02345598636561, -1.55663029431014, 1.96682564089362, -3.58407792961681,
0.208144888620837, 1.37776316082382, -6.10404078581851, -3.05704106989012,
-3.23631931572046, -1.56273302913117, -2.69298483937072, -6.43152523174637,
-1.85078877884673, 3.56307633040731, 0.792173462296278, 4.8524696486632,
0.246674686529558, 1.37035761203302, -4.62475872346289, 1.00242413694371,
1.58873876100252, -0.790706857943108, 1.96495956608131, 0.553539511966086,
-1.53439449318754, -1.10658568227624, 2.74661078453739, -0.321675462327045,
0.366855098837063, -5.60757828762817, 0.540845353802499, 1.09356553066119,
-1.62128658960071, 2.84090806369548, -0.48001068632543, 4.8607252093117,
-3.79444603557454, -1.15438753920741, 1.14785651229452, -2.98449425203108,
-0.0968931646984361, -5.71713740865731, -1.99399551046739, 0.715580915747888,
-0.187993588693786, 11.6206662760107, 3.33164798437313, 11.880268063813,
-4.59183529754457, 7.493174366884, -1.63235869534248, 6.43437120969502,
-5.94791722381832, 2.9995309440458, 0.643386634483489, -2.35713480960645,
-3.40994244463287, -5.85620930639887, 0.181391904540001, 5.27111634431678,
4.33944107033436, -0.558306918164928, 4.28063178255403, -1.97077256801979,
-2.57138676627564, -3.71389771103472, 4.3133960897046, 0.148924311612619,
-1.70290986043653, -4.30996701967779, -0.965505793606852, 2.55619940516774,
0.316148586937126, -2.86553933262407, 3.6199786340485, -3.0324625466726,
0.102596707148989, 2.03931770422959, 1.63760539594902, -3.68142146115503,
-1.51134713949931, 3.68204874887222, -2.75510931954596, 0.52638766000139,
-8.0587979163, -1.98290867443586, -0.377857470179599, 0.325984841609769,
-0.759483339293834, 0.115115090848564, -6.36791434808187, -5.18687165092749,
-7.20519874850424, -0.707533119337148, -3.5800257073134), X18 = c(10.2302429841824,
2.6740007650345, 0.507862387910674, -3.08329963605358, -6.12594486577488,
0.873095076282943, -1.64392463789201, 1.92960062541464, -3.70659733956398,
0.317882907668182, 1.54661079378747, -5.80650148051455, -3.10799680642182,
-3.26469659850358, -1.52221022368428, -2.74580260199692, -6.49094235260945,
-2.00153337923413, 3.57715616606906, 0.651808568387438, 4.94019915777265,
0.315108121205568, 1.36502921267441, -4.46332415587267, 1.03285527353641,
1.70397000758167, -0.711333311102028, 1.98423517315228, 0.503766224822025,
-1.32438382936223, -0.931413951247573, 2.50852098996647, -0.422747077039459,
0.320658015594347, -5.49048187258337, 0.8077445742357, 0.94819853714477,
-1.41197790197528, 3.13421128340922, -0.627951072164554, 4.95851436865924,
-3.72004145821947, -1.17521608546341, 1.31012529883838, -3.0951929004245,
-0.0306889179066405, -5.90535160688709, -1.87455641446427, 0.699466329202869,
-0.251443231974388, 11.5847733798263, 3.1133400905211, 11.9005099852337,
-4.75174442989286, 7.41580774134269, -1.61161736334313, 6.3274676066237,
-5.95881034390303, 3.23075589322687, 0.714304309683139, -2.11612056422776,
-3.53481500841399, -5.88832051669506, 0.291921416782498, 5.19954928575324,
4.10501320749379, -0.714937226663423, 3.95374129029347, -1.85285352671642,
-2.74880383207193, -3.37788382731109, 4.23618050192261, 0.0572075908839703,
-1.61190969973656, -4.38779072764378, -0.785985450369869, 2.66712228655569,
0.322583554476161, -2.80802189716767, 3.58867322166785, -2.88552072059564,
0.192289112781741, 2.12673133659004, 1.55623865626363, -3.65385268581424,
-1.51506199352475, 4.00446587754219, -2.97245993199496, 0.535391824615233,
-7.82479426459197, -1.86765075705364, -0.334603631779382, 0.627459244634671,
-0.844555434132629, -0.00951518665248674, -6.55574928151603,
-5.21725750591458, -7.30112314174379, -0.740710325531357, -3.62845711512356
), X19 = c(10.2853798276442, 2.65605086926642, 0.701851941106169,
-3.14924874669338, -6.10070161922154, 0.740303356062608, -1.73489839629073,
1.89296491455403, -3.80152844518679, 0.411848704704731, 1.69812885399016,
-5.54485848842753, -3.15023907840169, -3.27853745512315, -1.46790602475771,
-2.79407644615537, -6.55387275987587, -2.12345216443595, 3.59736814648376,
0.421526196567601, 5.01890815460364, 0.368734373194443, 1.35087585282648,
-4.31102064570824, 1.06705862179139, 1.80562092574763, -0.649707016500481,
2.00666531037758, 0.429709748868898, -1.14986198708492, -0.77696916861221,
2.27850084984473, -0.503673806883584, 0.288583553090527, -5.39058791825288,
1.04980567662408, 0.848549083075634, -1.22924330150292, 3.38838511797473,
-0.749916666299144, 5.05907189205963, -3.64034761520013, -1.20127091842878,
1.45722245618471, -3.19358850826533, 0.0274649893047818, -6.06902163503682,
-1.76311016321692, 0.696190968614493, -0.297704969659043, 11.5819990446271,
2.91292048589957, 11.9489425977657, -4.88350451351607, 7.36220058104059,
-1.61860139799942, 6.23746565580292, -5.98768229266772, 3.43685145836679,
0.772798432244134, -1.87604416035915, -3.66166265964224, -5.96729346885122,
0.399338812429595, 5.17200794732088, 3.86617387397391, -0.858141486685185,
3.65628995538554, -1.74999109298225, -2.91561390098859, -3.08524570576681,
4.17800296389173, -0.00615630434130932, -1.5361395509516, -4.47687488590073,
-0.590359792354972, 2.78267482129016, 0.329643375410887, -2.77520340867442,
3.55280750558302, -2.75762553031231, 0.273933136349241, 2.22530975787803,
1.47673708819809, -3.65297382184306, -1.4712954684723, 4.27907654753527,
-3.1785510371056, 0.547841405831861, -7.6133705222655, -1.7554401076765,
-0.308155102788088, 0.931831885922912, -0.93610444375794, -0.136614383750913,
-6.71523598785778, -5.24776963503164, -7.38817375856495, -0.776324581735766,
-3.6682114160231), X20 = c(10.3497614402533, 2.62250034457213,
0.887251699084254, -3.21036433458079, -6.07633780334536, 0.626797000051957,
-1.82650747129066, 1.85534515072173, -3.86911280977301, 0.489163587738817,
1.83130308473618, -5.32290094725198, -3.18432583151264, -3.27968337194819,
-1.40148169372439, -2.83804658773444, -6.61554752114359, -2.21803204977555,
3.62478201592437, 0.106264970216943, 5.08903909261955, 0.409140025450852,
1.32886646396255, -4.16733527358333, 1.10443041271772, 1.89487041186459,
-0.603588052134757, 2.03177457110404, 0.335134991035838, -1.00630273160908,
-0.642487371614667, 2.05794992834241, -0.564454409540671, 0.26877331530499,
-5.30699858413926, 1.2657471123248, 0.793245772272577, -1.07260444604143,
3.60550788509093, -0.845396659524683, 5.15895604510812, -3.55532801339938,
-1.22939761190939, 1.5871180657643, -3.28061346648111, 0.0797737134839577,
-6.20998643487115, -1.66058428441501, 0.703924953507351, -0.328833750199639,
11.6067412806286, 2.72958789670603, 12.0204944709031, -4.98954068274618,
7.32913448428622, -1.64963895441211, 6.16349566165172, -6.0322341225006,
3.61914234982379, 0.819996389388039, -1.63777724071119, -3.78916026476814,
-6.08637275273639, 0.503534166323219, 5.18274159883064, 3.62466065584301,
-0.987015342008707, 3.38927418357719, -1.66289463439419, -3.06705979889521,
-2.83822139357105, 4.13538984910075, -0.0446884395314401, -1.47375953644995,
-4.57651357370067, -0.381423979940315, 2.90147258251598, 0.337087915621148,
-2.76358466385102, 3.51321345940223, -2.6464878045511, 0.34785579672035,
2.33276470319697, 1.3992320193093, -3.67508768980965, -1.38078400456342,
4.50485202655261, -3.37356057123442, 0.563336950775706, -7.42224784785236,
-1.6457834764963, -0.296871001634405, 1.2365776737859, -1.03257205416672,
-0.26213726450966, -6.84894510712471, -5.27689828861491, -7.46587013342119,
-0.813350913318051, -3.70060241317582), X21 = c(10.4210371040835,
2.57414440524129, 1.06381196064424, -3.26589622644966, -6.05419954635492,
0.533466069765551, -1.91631708699666, 1.81553279141183, -3.91011840457429,
0.549495234320047, 1.94578159581411, -5.14232918207479, -3.21084398289768,
-3.26976792441744, -1.32457423183741, -2.87792547805435, -6.67238337911567,
-2.28700879255229, 3.65992381523413, -0.287562508388753, 5.15102696873222,
0.437842047098375, 1.29997216682831, -4.03168805914865, 1.1443603417953,
1.972828743253, -0.570937125975168, 2.05905173627875, 0.223501687453553,
-0.889756775769163, -0.527016277605263, 1.84786728046026, -0.605417552539123,
0.259428528584724, -5.23863567338453, 1.45505419371299, 0.780211696554123,
-0.941089836033332, 3.78768738711642, -0.91449319389432, 5.25555396675169,
-3.46521024065558, -1.25714343753081, 1.69871127678668, -3.35714863337423,
0.127921684326196, -6.33005185013726, -1.56741331977114, 0.720999421486568,
-0.346738048750753, 11.6539830511073, 2.56232939463655, 12.1105685423061,
-5.07223512260069, 7.31359513570493, -1.70131119711585, 6.10437063957935,
-6.09018433494396, 3.77910682898844, 0.857014348434673, -1.40209524623292,
-3.91618863147682, -6.23924270097262, 0.604409464924974, 5.22632658935041,
3.38195142707297, -1.10129600423906, 3.15270194002938, -1.59165864548644,
-3.19987771646026, -2.63731441099133, 4.10537862926337, -0.0616051981595228,
-1.42305351052648, -4.68563555302205, -0.161831503991544, 3.02226848847009,
0.344733778990594, -2.76999623340851, 3.47057584142517, -2.55002062362474,
0.414447816774327, 2.44704709863833, 1.32380001085834, -3.71674793192847,
-1.2455897634709, 4.68229923713252, -3.5577256063208, 0.581455802593431,
-7.24921871366475, -1.5383082282424, -0.299083117174526, 1.53956674017575,
-1.13260741350381, -0.38310410163396, -6.95932905936142, -5.30341033175521,
-7.53392440299365, -0.850860440953713, -3.72675805747687), X22 = c(10.4970649259072,
2.51193795614502, 1.23139297992278, -3.31535847415444, -6.03518417214552,
0.460526908609427, -2.00243556205182, 1.77265053125097, -3.92571110800419,
0.592951348719617, 2.04171703967755, -5.00322774406092, -3.23038601466943,
-3.25024251915447, -1.23875053226613, -2.91390690839499, -6.72181347349504,
-2.3322733266163, 3.70289688516809, -0.752594063848089, 5.2052984566868,
0.456260972777969, 1.26513251171502, -3.90348298530838, 1.18625921883879,
2.04052923166741, -0.54991430630584, 2.08798648489786, 0.097942540157811,
-0.796822925041574, -0.429471312245536, 1.64892064980798, -0.627157264698266,
0.258868791897238, -5.18433064907696, 1.61781782668895, 0.806882995790584,
-0.833370386636653, 3.93701692834425, -0.95777569379403, 5.34694686871208,
-3.37040364504701, -1.28267979428956, 1.79164362711558, -3.42401969105184,
0.173149057734329, -6.43094079896676, -1.48366210095834, 0.745908233001219,
-0.353167497544327, 11.7192754156226, 2.41002383383683, 12.2150660954624,
-5.13387162505513, 7.31281475083688, -1.77048010704214, 6.05872525751817,
-6.15934160654613, 3.91829657525412, 0.884924780377647, -1.16968622291859,
-4.04180616468443, -6.42010043867117, 0.701880712237202, 5.29774615491127,
3.13931252219894, -1.20118220966046, 2.94583984296493, -1.53591579897437,
-3.31204139192492, -2.48169927816129, 4.08546604439147, -0.0598259455353994,
-1.38245604070185, -4.80295218610788, 0.0659499581539408, 3.14395305060312,
0.352440409763718, -2.7915952045704, 3.42546189385347, -2.46634902712477,
0.474140971364889, 2.56634203466027, 1.25048211968203, -3.77479496722628,
-1.06870719943357, 4.81305565036706, -3.73132186989047, 0.601776969866921,
-7.09221112830651, -1.43275823365339, -0.313157679928816, 1.83901949870773,
-1.23504075101942, -0.497410974716755, -7.04868379861771, -5.326343770342,
-7.59221958981239, -0.888040731771983, -3.74763926560252), X23 = c(10.5759374327404,
2.4369522338992, 1.38995621313663, -3.3584830228138, -6.01982456882574,
0.407663312193135, -2.08344325521415, 1.72611095831575, -3.91734565959298,
0.619984471008569, 2.11963723819153, -4.90447247739174, -3.24353423702711,
-3.22239845028209, -1.14548033691202, -2.94617195583928, -6.76211259194259,
-2.35579654020976, 3.75348492532811, -1.28093763813522, 5.25227082734343,
0.465707570287133, 1.22523503779434, -3.78213899888243, 1.22957547691385,
2.09892566694257, -0.538870842371128, 2.11809201973924, -0.0387369393974046,
-0.724593267628429, -0.348681380116234, 1.46150553222056, -0.630476862238522,
0.265563838266272, -5.14288524393301, 1.75459973135589, 0.870377273406997,
-0.747873879612948, 4.05555298953808, -0.976166222651786, 5.43178467485764,
-3.27143497102909, -1.30471309870588, 1.86613197419493, -3.48199643865156,
0.216330867810061, -6.5142681371598, -1.40912678745275, 0.777303129537096,
-0.349710780120013, 11.7987048265773, 2.27151276194978, 12.3303782326328,
-5.17660354199957, 7.32428843645869, -1.85429606059356, 6.02511598739079,
-6.23764952453067, 4.03827875594898, 0.904737615068513, -0.94115783408906,
-4.16522468322654, -6.62368308681126, 0.795879129608171, 5.39242524969973,
2.89783437371009, -1.28719339004713, 2.76742013122083, -1.49496461952552,
-3.40252389838043, -2.36956678298435, 4.0735516467106, -0.0419865406924014,
-1.35056071202663, -4.92706731044581, 0.299660839144927, 3.26554966852216,
0.360099833546582, -2.82585027987267, 3.37834513827733, -2.39380544414226,
0.527389219252619, 2.68905592648569, 1.17929654439894, -3.84636784839625,
-0.853743791233708, 4.89955658152019, -3.89464972222607, 0.623896637241272,
-6.9493212731634, -1.32897942249424, -0.337534774573073, 2.13346205021572,
-1.33886075217242, -0.603658113538727, -7.11913108212524, -5.34498673250026,
-7.64078564875814, -0.924203395811229, -3.76405878776569), X24 = c(10.6559875965941,
2.35033504273813, 1.5395516863214, -3.39517744936742, -6.00836538577891,
0.374151950671142, -2.15832231097661, 1.6755728262452, -3.8866747203279,
0.631308963148711, 2.18034031899857, -4.84407015621864, -3.25085052794799,
-3.18738582954642, -1.04612196249229, -2.97489278127172, -6.79223293152217,
-2.35957029011073, 3.81123799595019, -1.86449870255109, 5.2923508469651,
0.467378330739343, 1.1811039131622, -3.6671076857344, 1.27380414788721,
2.14889340120233, -0.536337099727099, 2.14891814330292, -0.184045695843654,
-0.670588234145605, -0.283425959205705, 1.28579547388201, -0.616340490822848,
0.278146969057494, -5.11311128692765, 1.86632026477111, 0.96762309277007,
-0.682878758124089, 4.14530502703035, -0.970848634210819, 5.50917462220635,
-3.16889902680556, -1.32239482883829, 1.92282416853706, -3.53179393338975,
0.25805151277189, -6.58153113312097, -1.34341578662427, 0.813985061388495,
-0.337799925543697, 11.8888521359897, 2.14564780856352, 12.4533588416605,
-5.20243746890039, 7.34577403566548, -1.95019263827881, 6.00209155734492,
-6.32321161939391, 4.14059526948576, 0.917390526446529, -0.717043264162817,
-4.28578872854968, -6.84526563724273, 0.886351661018581, 5.50623636947051,
2.65845834763946, -1.36006138937939, 2.61580947409579, -1.46787352616258,
-3.47108515695527, -2.29841070608777, 4.06788241580761, -0.0104563413445141,
-1.32611731571544, -5.05655691277661, 0.537257400379867, 3.38620701331054,
0.367629047760276, -2.87052056427331, 3.32962421712067, -2.33091718956926,
0.574653708039288, 2.81379969625357, 1.11024680457671, -3.92890084956375,
-0.604667120847543, 4.94476804597195, -4.04802456884179, 0.64743729092244,
-6.8188258442204, -1.22690133157535, -0.370751969188815, 2.42168459363673,
-1.44319507114674, -0.70100052501007, -7.17261404462467, -5.35884859627814,
-7.67977535660568, -0.958783133619898, -3.77669941427551), X25 = c(10.735782343582,
2.25327592311704, 1.68030394815846, -3.42548766469788, -6.00082947517913,
0.358970387322952, -2.22639058393759, 1.6208983255437, -3.83547427012895,
0.627830150559672, 2.22481066630878, -4.81943481895751, -3.25286995892585,
-3.1462298779935, -0.941916573700824, -3.00023498200679, -6.81165811604892,
-2.34556230482692, 3.87554299880986, -2.49522900737223, 5.32593376399645,
0.462356577325476, 1.13349468601323, -3.55788222387424, 1.31849081957763,
2.19123262099885, -0.54100859849332, 2.18005794316772, -0.335787263036486,
-0.632690917877904, -0.232464877589142, 1.12178479615567, -0.585831485327079,
0.295416391765668, -5.09385599922849, 1.95416549522091, 1.09545918879329,
-0.636588981781303, 4.2082315203152, -0.943196126726581, 5.57858533256406,
-3.06342164117734, -1.33523690478213, 1.96267773287531, -3.5740747414563,
0.298670908640761, -6.63410941580483, -1.28601324954999, 0.854893489487668,
-0.318718390179412, 11.9867482200764, 2.03132121734867, 12.5812880616653,
-5.21322733281898, 7.37528193586856, -2.05587372558415, 5.98824097161131,
-6.41430273924458, 4.22673506989671, 0.923745229147108, -0.497806442454687,
-4.4029578089709, -7.08064076473926, 0.973260954988189, 5.63548727629468,
2.42199738176428, -1.42064859263248, 2.48914349900806, -1.4535638584811,
-3.51808820224966, -2.26526085726611, 4.06700147048564, 0.0326429682349222,
-1.30802282606125, -5.19002524374659, 0.776909937155942, 3.50518986566281,
0.374964346042325, -2.92363147363139, 3.27963768213008, -2.27639006139792,
0.616391340730812, 2.93937037890754, 1.04332693433025, -4.02011078165503,
-0.325609109083497, 4.95197663840478, -4.19177030591612, 0.672052538154763,
-6.69918174213129, -1.12651824974261, -0.411456929840515, 2.70270404280286,
-1.5472934748946, -0.78902163562572, -7.21090109683568, -5.36762822352953,
-7.70944134305916, -0.9913313015876, -3.7861310716112), X26 = c(10.8141084915615,
2.14697673377312, 1.81239811277899, -3.44956581064704, -5.99707428032455,
0.360887797813542, -2.28724158551366, 1.56211335349161, -3.76558340584678,
0.61058496360844, 2.25415233515325, -4.8276076657907, -3.25009715591275,
-3.09984499623057, -0.833988062842184, -3.02235898488483, -6.8202782487678,
-2.31568270121024, 3.94568046334837, -3.16530996555826, 5.35340244225628,
0.451617010366126, 1.08309307491679, -3.4540007562877, 1.36323231902193,
2.22667283747077, -0.551731433752894, 2.21115027701918, -0.492036466179513,
-0.609085860550293, -0.194561937311918, 0.969324784978673, -0.5401168096697,
0.316328896888263, -5.0840172612493, 2.01951064192914, 1.25071005103047,
-0.607192238979773, 4.2462387885623, -0.894713165494748, 5.6397661156958,
-2.95563247850385, -1.34303563192391, 1.98686018651147, -3.60945180439158,
0.338380920205869, -6.6732703145235, -1.23632793471433, 0.899094839132697,
-0.293611182409156, 12.0898293229127, 1.92748442984364, 12.7118319163332,
-5.21067520417327, 7.41105917535317, -2.16929630472741, 5.98222481716121,
-6.50937114734122, 4.2981163079981, 0.924587638688468, -0.283846846082791,
-4.51629111707999, -7.32608818255806, 1.05658496033667, 5.7768980074361,
2.18915223905845, -1.46988710359341, 2.38543167482404, -1.45087480760024,
-3.54434413077559, -2.26686873052113, 4.06970225097794, 0.0854178880572293,
-1.29530928841888, -5.32614284796964, 1.01699497731395, 3.62186930851244,
0.38205705840344, -2.98344992063042, 3.22867553016901, -2.22909054120667,
0.653046416852418, 3.06473261090644, 0.978524705826239, -4.1179790636045,
-0.0207181373654275, 4.92462759234778, -4.32621483002889, 0.697429068285266,
-6.58901823166184, -1.02787185685793, -0.458412463899618, 2.9757311949883,
-1.65051320413584, -0.867628724089686, -7.23559474906627, -5.37118237894242,
-7.73011501563302, -1.02150620252123, -3.79282654864761), X27 = c(10.889954529774,
2.03262759637675, 1.93606685437206, -3.46764318366707, -5.99683863042148,
0.378539509847398, -2.34069127080634, 1.4993718402323, -3.6788565986634,
0.580693071803098, 2.26953696293102, -4.86542838650295, -3.24300456509129,
-3.04904696519434, -0.72334649935106, -3.0414208138492, -6.81828592235104,
-2.2717600261609, 4.02086952773793, -3.86728285135245, 5.37512666501226,
0.436032217670732, 1.03051635996589, -3.35504630884775, 1.40767532435006,
2.25587795716797, -0.567487876126926, 2.2418795667313, -0.651115019452836,
-0.598204843856726, -0.168503383180738, 0.828154247699275, -0.480416898476083,
0.339988990994133, -5.08255206638081, 2.06385739680563, 1.43024302320459,
-0.592903980219731, 4.2611806366899, -0.826988739486487, 5.69268032606089,
-2.84614563316674, -1.34580554234119, 1.99666882988857, -3.63849159487221,
0.377252020047694, -6.70017693621315, -1.19373007148302, 0.945770855618894,
-0.263495884495341, 12.1958940004232, 1.83315831244077, 12.8430015743725,
-5.19633630632503, 7.45157070641447, -2.28865118508149, 5.98279429834467,
-6.60703449544713, 4.35607572593318, 0.920630427064598, -0.0755040313721311,
-4.62543433615667, -7.57833860994934, 1.13631624498151, 5.92757210360693,
1.96052463504556, -1.50873444065981, 2.30263727379096, -1.45861314531169,
-3.55098389724542, -2.29985249698222, 4.07498855806536, 0.146183739602179,
-1.28713055746028, -5.46367092888106, 1.25608388399909, 3.73571285302396,
0.388870331317487, -3.04846008332992, 3.17698816764252, -2.18802809314717,
0.685044814506333, 3.18900084726591, 0.915823573813673, -4.22073121602751,
0.305949590433882, 4.86620264501372, -4.45168694623889, 0.723286758032779,
-6.48712495682019, -0.931036216792261, -0.510496465875934, 3.24014232237949,
-1.7523062107045, -0.936967939102265, -7.24814307671094, -5.3694961355772,
-7.74218775621283, -1.04906166497942, -3.79717572926652), X28 = c(10.9624905515921,
1.91138784189852, 2.05157879283609, -3.48000779299397, -5.99978080906401,
0.410487006622245, -2.38673181817792, 1.43292456247522, -3.57712656478514,
0.539317340940634, 2.27216360073806, -4.92966577307963, -3.23203202630969,
-2.99456357172108, -0.610893748850122, -3.05757245996019, -6.80609158574527,
-2.21552497619112, 4.10030293238807, -4.59413652195095, 5.39146261374565,
0.416380172341274, 0.976316383141176, -3.26064467496348, 1.45151372744304,
2.27945152388338, -0.58738262714568, 2.27197393374054, -0.811567434805607,
-0.598680581483171, -0.153112069496142, 0.697925222266013, -0.407980279924156,
0.365635640625084, -5.08848043682487, 2.08878299365181, 1.63101090824319,
-0.591999662078804, 4.25485785599873, -0.741658655165831, 5.73745116210722,
-2.73554627263049, -1.34372330186906, 1.99346747921485, -3.66171735133897,
0.415270864144862, -6.71589730439952, -1.15757856959574, 0.994207322055005,
-0.229273836316463, 12.3030627317837, 1.74743763744489, 12.9731142505422,
-5.17162650474912, 7.49547966025624, -2.41234312869654, 5.98880140694938,
-6.70607192166862, 4.40186332045858, 0.912516979736169, 0.126938026303175,
-4.73010821640127, -7.83453566868708, 1.21246112388028, 6.08496530152589,
1.73662811118788, -1.53814201708589, 2.23873684486099, -1.47559043413924,
-3.53935422459269, -2.36080785514237, 4.08204027527656, 0.213445944781121,
-1.28274904688072, -5.60147555540361, 1.49292950309993, 3.84627485797637,
0.395376674701409, -3.11734050122282, 3.12479336670626, -2.1523384041941,
0.712790202896593, 3.31142275908504, 0.855203807428248, -4.32681550755279,
0.65050712954047, 4.78013018614283, -4.56851421916246, 0.749377610866214,
-6.39243801157978, -0.836105376553833, -0.566698531787937, 3.49545481771962,
-1.85220799048015, -0.997356317149617, -7.24985232541567, -5.36265621610126,
-7.74609451643753, -1.07383499541293, -3.79949830230056), X29 = c(11.0310478640408,
1.78437143583669, 2.15922843942097, -3.48698605273361, -6.00550894562145,
0.455265245115424, -2.42549214110474, 1.36309247332385, -3.46217605441484,
0.487632404101157, 2.26322825743482, -5.01711490825035, -3.21758722643138,
-2.93704390362824, -0.497430307892233, -3.07096200795304, -6.78425596956252,
-2.14860020415909, 4.18317369590547, -5.33936180448051, 5.40275251326307,
0.39335208017223, 0.920983480075452, -3.17046120403841, 1.49448530360696,
2.29794187643788, -0.610629989516373, 2.30120237469274, -0.972138060638117,
-0.609308235055978, -0.147258052762417, 0.578224520603535, -0.324062414264609,
0.392628084223551, -5.1008863939786, 2.09589919227961, 1.85008318248699,
-0.602837388403096, 4.22901718654431, -0.640375114229902, 5.77431816989396,
-2.6243819164664, -1.33708116667464, 1.97863761625387, -3.6796122595964,
0.452369828976631, -6.7214135463993, -1.12724059016835, 1.04378340556224,
-0.191741024997347, 12.4097407306351, 1.66949170203455, 13.1007568278819,
-5.13783112042247, 7.54162776992286, -2.53897128707034, 5.99920281259547,
-6.80541385963095, 4.43664075763038, 0.900826089483414, 0.32324674695744,
-4.83009865543199, -8.09219782499093, 1.28503866346143, 6.24685377557922,
1.51789725757558, -1.55903338821498, 2.19176315654594, -1.50065010227601,
-3.51093454505097, -2.44639072575374, 4.09018430893332, 0.285882266372744,
-1.28152314721783, -5.73853445302419, 1.7264519569523, 3.95318745465487,
0.401556077040816, -3.18894288037413, 3.07228166855043, -2.12126799294415,
0.73666183148989, 3.43136401642949, 0.796643120374932, -4.43488184454853,
1.00928892500712, 4.66972117226662, -4.67702145765456, 0.775484001152293,
-6.30402546049895, -0.743183486991358, -0.626114493042298, 3.74130642640365,
-1.94982777967, -1.04922818743365, -7.24189969551738, -5.35082766408068,
-7.74229977688112, -1.09573503315648, -3.80005498390276), X30 = c(11.0950992408655,
1.65263629387055, 2.25932770496741, -3.48892807230841, -6.01360481989867,
0.511419151983869, -2.45720463288641, 1.29024432974204, -3.33571704185687,
0.426800174914838, 2.24390128938497, -5.12466739742097, -3.20004672774293,
-2.87706651705528, -0.383662712840419, -3.08173362225793, -6.75343706589802,
-2.07249487159028, 4.26869496032156, -6.09698018183682, 5.40932442825298,
0.367560171655179, 0.864950885260743, -3.08419709923652, 1.53636805924805,
2.31184707128948, -0.636542072518509, 2.32937144452112, -1.1317496834528,
-0.629014144723286, -0.149866230535131, 0.468591698006351, -0.229908234816931,
0.420431668297916, -5.11891708312173, 2.08681960630633, 2.08466824325328,
-0.623872873684039, 4.18534968113296, -0.524782223507297, 5.80360276139079,
-2.51315721695886, -1.32624910833469, 1.9535415641013, -3.69262250259829,
0.488449677662553, -6.71763055591294, -1.10210516381826, 1.09396176985042,
-0.151598412532483, 12.5145841449435, 1.59856243270244, 13.2247526920204,
-5.09611430257385, 7.58901664351004, -2.66731049982587, 6.01305941277587,
-6.90413066379847, 4.46148239268786, 0.88607695036054, 0.513236902443814,
-4.92524806180478, -8.34918167664421, 1.35407961466522, 6.41130322330721,
1.30469570178392, -1.5722898648745, 2.15983502525836, -1.53268643952514,
-3.46727187731384, -2.55337709279262, 4.09887015451534, 0.362326190816095,
-1.28289564713051, -5.87393849604732, 1.95572431028322, 4.05615209066568,
0.407394543644815, -3.26227275863858, 3.01962059553532, -2.09416035612538,
0.757013510888777, 3.5482945102875, 0.740117004171606, -4.54376156224609,
1.37888353371647, 4.53812530057919, -4.77752962440792, 0.801416540645306,
-6.22107316152656, -0.652377191585757, -0.687939747232788, 3.9774375794583,
-2.04483992158555, -1.09309351731923, -7.22534571708663, -5.33423389050609,
-7.73128573545404, -1.11473077947823, -3.79905732903363), X31 = c(11.1542403968739,
1.51717689458451, 2.35219887694434, -3.48619601979169, -6.0236421279139,
0.577531056880215, -2.48217752365179, 1.21477825946958, -3.19937598511386,
0.357951214046068, 2.21531107263848, -5.2493602031975, -3.17975735546878,
-2.8151466438233, -0.270211098830214, -3.09002746011151, -6.71434923101358,
-1.98860283427159, 4.35611429876727, -6.86155303791187, 5.41149219336796,
0.339545191737831, 0.8085993061447, -3.00158560501085, 1.57697650016081,
2.32161948779022, -0.664518063771269, 2.35632175363022, -1.28948388113455,
-0.656830911415704, -0.15992155354673, 0.368533961798284, -0.126737927474418,
0.448604308029912, -5.14178079959154, 2.06313402929412, 2.33212859122832,
-0.653668376615971, 4.12548858419952, -0.396496382604125, 5.82568119928295,
-2.40233134269338, -1.3116445667713, 1.9194955323782, -3.70116013500947,
0.523396508416013, -6.70538384481757, -1.08159223686483, 1.14427950907957,
-0.109461558512117, 12.6164696203986, 1.53396092932606, 13.3441319058638,
-5.04752846536137, 7.63679027125937, -2.79629376158726, 6.02953298105391,
-7.00142080669798, 4.47737803956315, 0.868734171494343, 0.696766716302005,
-5.01544781678534, -8.60364733563941, 1.41962531448159, 6.57663955670969,
1.09732315206022, -1.57874160796656, 2.14117690395706, -1.57065724804714,
-3.40993072603366, -2.67870456243796, 4.10764946930257, 0.441751537511303,
-1.28638329377324, -6.00688951462071, 2.17995857396111, 4.15493174128659,
0.412882951951118, -3.33647203994987, 2.96695795558438, -2.07044366711338,
0.774173469767769, 3.66177597867244, 0.685598896639564, -4.65244848583811,
1.75615149885906, 4.38830288343468, -4.87035503088984, 0.827011778390674,
-6.14287138277714, -0.563789961749092, -0.751461993376279, 4.20367636774596,
-2.13697624306404, -1.12950601215224, -7.20114587840312, -5.31313993199056,
-7.71354253439903, -1.1308408849927, -3.7966762338084), X32 = c(11.2081729937537,
1.37891962712432, 2.43816892122425, -3.47915506850448, -6.03520016842725,
0.652240659108419, -2.50077218574708, 1.13710684182311, -3.05468400432191,
0.282170965651765, 2.17853266047056, -5.38840775053596, -3.15703779266131,
-2.75174257764348, -0.15761663543945, -3.0959795552065, -6.66773219582001,
-1.8982035522988, 4.4447235899811, -7.62817651899089, 5.40955545815874,
0.309783446694398, 0.752261468075083, -2.92238831365463, 1.61615797462114,
2.32767007883085, -0.694034543947258, 2.3819244754808, -1.44456316575066,
-0.69187788633629, -0.176472258153829, 0.277538463977697, -0.0157355307824764,
0.476783922941579, -5.16874441379593, 2.02638860907718, 2.58999044586844,
-0.690896984559611, 4.05100691344695, -0.257090716044711, 5.84096368283785,
-2.29231726179675, -1.29370875863802, 1.87775064252001, -3.70560576229979,
0.557094049863857, -6.68544647881547, -1.06515825822058, 1.194339905497,
-0.0658694766683676, 12.7144670753023, 1.47506311601056, 13.4581046392091,
-4.99302347762701, 7.6842189483127, -2.9249960025321, 6.04788096751997,
-7.09659915278556, 4.48523685933483, 0.849212637176189, 0.87373411483925,
-5.10063167969123, -8.8540262919444, 1.48172658608441, 6.74142160677738,
0.896021694505658, -1.57916274149031, 2.13413060315415, -1.61359158387636,
-3.34045537133169, -2.81949950393136, 4.11615905743908, 0.523258312812303,
-1.29156750804903, -6.13669563153278, 2.39849233285835, 4.24934379542288,
0.41801614602488, -3.41080332323433, 2.91442445825692, -2.0496199528406,
0.788444835792476, 3.7714509533688, 0.633060268908289, -4.76008143955757,
2.13823207156918, 4.22300870878266, -4.95580872516485, 0.852129871429103,
-6.06880246897937, -0.477518046864411, -0.816053785092224, 4.41992574450892,
-2.22601930579172, -1.15903907725534, -7.17016133779912, -5.28783864262472,
-7.68956030896904, -1.14412414681971, -3.79304924364485), X33 = c(11.2566893073438,
1.23872036257799, 2.51756494395572, -3.46816648618631, -6.04787380047073,
0.734258933595897, -2.51338472990428, 1.05764525697688, -2.90307099772083,
0.200489995333467, 2.13458035872437, -5.53922115072915, -3.13218027693615,
-2.68726135423884, -0.0463486693936394, -3.09972169890385, -6.61432804706354,
-1.80246499178208, 4.53386538883549, -8.39246604050325, 5.40379982872881,
0.278693337784769, 0.696226505547889, -2.84639171988559, 1.65378918506383,
2.33037225817523, -0.724636789260769, 2.40607798549702, -1.59633486445321,
-0.733346143067456, -0.198631497241308, 0.195082362783663, 0.101960018582883,
0.504677026235203, -5.19913051735307, 1.9780708885804, 2.85594897974716,
-0.734343385400543, 3.96341494814961, -0.108082882216559, 5.84987836234389,
-2.18348238038193, -1.27288851289625, 1.82948031419598, -3.70631101896814,
0.589432244034738, -6.65853510074373, -1.05229919072448, 1.24380498161075,
-0.0212927159607551, 12.8078154655426, 1.42130495780268, 13.5660376501811,
-4.93345542022731, 7.73068466594522, -3.05261922451977, 6.06745021341358,
-7.18908563461684, 4.48589190905076, 0.827882111709768, 1.04407313936489,
-5.1807700068919, -9.09899190641571, 1.54044265986725, 6.90441601677277,
0.700981483353486, -1.5742693610471, 2.13716106984167, -1.66059376073398,
-3.2603422381107, -2.97309298482533, 4.12410672739956, 0.606059783297419,
-1.2980862024236, -6.26276503197694, 2.61077616178787, 4.33925359749475,
0.422792212910889, -3.4846359061512, 2.86213581062338, -2.03125563015764,
0.800106543630483, 3.87703292048673, 0.582470681507324, -4.86592825888955,
2.52254173141064, 4.04478490085042, -5.03419601204619, 0.876652313053367,
-5.99832966186709, -0.393647728314239, -0.881165176489229, 4.6261525974918,
-2.31179641909773, -1.1822680419573, -7.13316865717351, -5.25863948899065,
-7.65982283433803, -1.15467107425112, -3.78828678694418), X34 = c(11.2996585683307,
1.09736379764538, 2.5907106467353, -3.45358247989973, -6.06128040705547,
0.822377187953832, -2.5204312708927, 0.976802068483468, -2.74586286771662,
0.113877475627772, 2.08440334688413, -5.69941766858713, -3.10545232669684,
-2.62206382102136, 0.0631885246450692, -3.10138133498401, -6.55486453302018,
-1.7024479346342, 4.62293656477847, -9.15053360862679, 5.3944970892892,
0.246641357005278, 0.640744125517678, -2.77340408715826, 1.68977292127823,
2.33006543328584, -0.755930989892392, 2.42870470131544, -1.74425663756431,
-0.780487082868014, -0.225577688524256, 0.120640986042975, 0.225261730577506,
0.532048530593188, -5.23231449171976, 1.91959887671428, 3.12787011505201,
-0.782902048076031, 3.86415781157883, 0.0490742835795172, 5.8528592951574,
-2.07615011922416, -1.2496226909893, 1.77577264942927, -3.7036008496754,
0.620312923082511, -6.62531510666344, -1.04255164007548, 1.2923887996661,
0.0238593111843294, 12.8959012862963, 1.37217755265942, 13.6674335586327,
-4.86959480957422, 7.77566794447931, -3.17847897006347, 6.08767012177443,
-7.27839453046331, 4.480105022742, 0.805071535460444, 1.20775052903012,
-5.25586467500665, -9.33743253016185, 1.59584013151505, 7.06457435178325,
0.512345922231774, -1.56471958456077, 2.14885776543487, -1.71084455945873,
-3.1710203611679, -3.13702813497359, 4.1312595469585, 0.689470715302121,
-1.30562661378668, -6.38459882830678, 2.81636191099548, 4.42456861147245,
0.427211898428453, -3.55743332289452, 2.81019442061214, -2.01497326386482,
0.809414519364129, 3.97829758006667, 0.533797838625089, -4.96937128431851,
2.9067668342652, 3.85596041026143, -5.10581606641171, 0.900479770838403,
-5.93098708451506, -0.312253602352611, -0.946316637075451, 4.82237838574311,
-2.39417431827309, -1.199757316439, -7.09086856336673, -5.22585960484864,
-7.62480255342673, -1.16259651888932, -3.78247745305593), X35 = c(11.3370149142115,
0.955564180884008, 2.65792361693502, -3.43574246353992, -6.07506448869373,
0.915472296884809, -2.52233629423657, 0.894972231832158, -2.58428116638787,
0.023237273755472, 2.02888363754643, -5.86682293614596, -3.07709844819412,
-2.55646917610451, 0.170649436433204, -3.10108147659791, -6.49004332424603,
-1.5991112374069, 4.71138984225627, -9.89896041847176, 5.38190548844471,
0.213947549022112, 0.586028502593608, -2.70325264786334, 1.72403504080237,
2.32705820256959, -0.787577305557813, 2.44974816042708, -1.88788350875525,
-0.832603924849837, -0.256553848412625, 0.0536943837828319, 0.353139596076524,
0.55871275767852, -5.2677216185721, 1.85231343810974, 3.40378963584562,
-0.835573548279636, 3.75461330276848, 0.212999739252623, 5.85033752531834,
-1.97060211274525, -1.2243323539584, 1.71762668245985, -3.69777560245747,
0.649653254162219, -6.58640507004024, -1.0354926386736, 1.33985145224384,
0.0692317123869579, 12.9782395488856, 1.32722230116657, 13.7619126324906,
-4.80213424162476, 7.81873603446961, -3.30199206298773, 6.10804566185945,
-7.36412445423995, 4.46857179425934, 0.781072989955583, 1.36476248191526,
-5.3259446157293, -9.56842715581566, 1.64799196842057, 7.2210123609899,
0.330216406384046, -1.55111500352106, 2.16793286037749, -1.7636003935486,
-3.07383827120485, -3.30906107332531, 4.13743408743693, 0.772896711446758,
-1.31391904911023, -6.50178349714592, 3.01489188794669, 4.50523316526223,
0.431278130877677, -3.62874226948175, 2.75869080399074, -2.00044440569237,
0.816603028202245, 4.07507509118547, 0.487007655718963, -5.06989426927742,
3.28885220251998, 3.65865527207777, -5.17096161468951, 0.923530063397168,
-5.86637084352359, -0.23339765728346, -1.01109234271236, 5.00867108587745,
-2.47305442684788, -1.21205139298475, -7.04389378394898, -5.18981677311417,
-7.58495678210708, -1.16803332427876, -3.77569242848048)), .Names = c("datetime",
"X1", "X2", "X3", "X4", "X5", "X6", "X7", "X8", "X9", "X10",
"X11", "X12", "X13", "X14", "X15", "X16", "X17", "X18", "X19",
"X20", "X21", "X22", "X23", "X24", "X25", "X26", "X27", "X28",
"X29", "X30", "X31", "X32", "X33", "X34", "X35"), row.names = c("2003-01-02",
"2003-01-03", "2003-01-06", "2003-01-07", "2003-01-08", "2003-01-09",
"2003-01-10", "2003-01-13", "2003-01-14", "2003-01-15", "2003-01-16",
"2003-01-17", "2003-01-20", "2003-01-21", "2003-01-22", "2003-01-23",
"2003-01-24", "2003-01-27", "2003-01-28", "2003-01-29", "2003-01-30",
"2003-01-31", "2003-02-03", "2003-02-04", "2003-02-05", "2003-02-06",
"2003-02-07", "2003-02-10", "2003-02-11", "2003-02-12", "2003-02-13",
"2003-02-14", "2003-02-17", "2003-02-18", "2003-02-19", "2003-02-20",
"2003-02-21", "2003-02-24", "2003-02-25", "2003-02-26", "2003-02-27",
"2003-02-28", "2003-03-03", "2003-03-04", "2003-03-05", "2003-03-06",
"2003-03-07", "2003-03-10", "2003-03-11", "2003-03-12", "2003-03-13",
"2003-03-14", "2003-03-17", "2003-03-18", "2003-03-19", "2003-03-20",
"2003-03-21", "2003-03-24", "2003-03-25", "2003-03-26", "2003-03-27",
"2003-03-28", "2003-03-31", "2003-04-01", "2003-04-02", "2003-04-03",
"2003-04-04", "2003-04-07", "2003-04-08", "2003-04-09", "2003-04-10",
"2003-04-11", "2003-04-14", "2003-04-15", "2003-04-16", "2003-04-17",
"2003-04-18", "2003-04-21", "2003-04-22", "2003-04-23", "2003-04-24",
"2003-04-25", "2003-04-28", "2003-04-29", "2003-04-30", "2003-05-01",
"2003-05-02", "2003-05-05", "2003-05-06", "2003-05-07", "2003-05-08",
"2003-05-09", "2003-05-12", "2003-05-13", "2003-05-14", "2003-05-15",
"2003-05-16", "2003-05-19", "2003-05-20", "2003-05-21"), class = "data.frame")

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From jannetta at henning.org  Thu Jul  4 18:42:18 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Thu, 4 Jul 2013 17:42:18 +0100
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <loom.20130704T175131-611@post.gmane.org>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
Message-ID: <CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>

 Hi Ben and others

I don't quite know how to explain the "doesn't work" in more detail without
any visual aid. When you run the two scripts it is easy to see the
difference. MatLab produces a line on x= -55. This is what I expect - a
more or less straight line. R on the other hand the result drops from -55
(the initial value) to -80 and then goes up to -71.37092.

The two scripts have exactly the same equations. I have even named the
variables the same in the two scripts and copied the equations across to
make sure I haven't made any typos.

Can one attach images to posts? I'll try. The flatline image is the plot
from MatLab and the other is the plot from R.

Thanks
Jannetta


On 4 July 2013 16:52, Ben Bolker <bbolker at gmail.com> wrote:

> Berend Hasselman <bhh <at> xs4all.nl> writes:
>
> >
> >
> > On 04-07-2013, at 17:15, Jannetta Steyn <jannetta <at> henning.org>
> wrote:
> >
> > > Hi folks
> > >
> > > I have implemented a model of a neuron using Hodgkin Huxley equations
> in
> > > both R and MatLab. My preference is to work with R but R is not giving
> me
> > > the correct results. I also can't use ode45 as it just seems to go
> into an
> > > indefinite loop. However, the MatLab implementation work fine with
> > >  the same
> > > equations, parameters and initial values and ode45. Below is my R and
> > > MatLab implementations.
> > >
> >
> > No problem in running your R file. Have plot.
> > (Mac mini Core2Duo 2.66Ghz running R 3.0.1 Patched
> > (2013-06-19 r62992) on Mac OS X 10.8.4:  16.5 seconds.)
> >
> > Trying to run your Matlab file in Octave.
> >  No success yet because of unavailable ode45.
>
>    I'm impressed that you (BH) went to the trouble of checking
> on this vague "doesn't work" question.  If you want to go farther
> I think you can get ode45 for octave by installing the odepkg
> package:
>
> http://octave.sourceforge.net/odepkg/index.html
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

===================================
Web site: http://www.jannetta.com
Email: jannetta at henning.org
===================================
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot01.png
Type: image/png
Size: 3877 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/bd9b8f59/attachment.png>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: MatPlot01.png
Type: image/png
Size: 30618 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/bd9b8f59/attachment-0001.png>

From catalinroibu at gmail.com  Thu Jul  4 18:59:52 2013
From: catalinroibu at gmail.com (catalin roibu)
Date: Thu, 4 Jul 2013 19:59:52 +0300
Subject: [R] iterative methods
Message-ID: <CAEW+BDKDmgkV-aBO8-Wjr1DGEsL1vXMfQiB42ZZxfUZFpoVduw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/a07d75b0/attachment.pl>

From bhh at xs4all.nl  Thu Jul  4 19:11:06 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 4 Jul 2013 19:11:06 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
Message-ID: <C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>


On 04-07-2013, at 18:42, Jannetta Steyn <jannetta at henning.org> wrote:

> Hi Ben and others
> 
> I don't quite know how to explain the "doesn't work" in more detail without
> any visual aid.

You said that R got into an indefinite loop, whatever that maybe.

> When you run the two scripts it is easy to see the
> difference. MatLab produces a line on x= -55. This is what I expect - a
> more or less straight line. R on the other hand the result drops from -55
> (the initial value) to -80 and then goes up to -71.37092.
> 
> The two scripts have exactly the same equations.


I don't think so.
In the R script you have

init = c(v_axon_AB=-55,mNa_axon_AB=1,hNa_axon_AB=0,mK_axon_AB=1)

That is not the same as in your Matlab script. To make them the same you should replace the line with

init = c(v_axon_AB=-55,mNa_axon_AB=0,hNa_axon_AB=1,mK_axon_AB=0)

Using this line gives quite different results. But not the same as Matlab.

It seems that you ought to carefully check all your equations.
I don't know enough about Matlab/Octave syntax to determine if the results of the two systems  are identical.

Berend

> I have even named the
> variables the same in the two scripts and copied the equations across to
> make sure I haven't made any typos.
> 
> Can one attach images to posts? I'll try. The flatline image is the plot
> from MatLab and the other is the plot from R.
> 
> Thanks
> Jannetta
> 
> 
> On 4 July 2013 16:52, Ben Bolker <bbolker at gmail.com> wrote:
> 
>> Berend Hasselman <bhh <at> xs4all.nl> writes:
>> 
>>> 
>>> 
>>> On 04-07-2013, at 17:15, Jannetta Steyn <jannetta <at> henning.org>
>> wrote:
>>> 
>>>> Hi folks
>>>> 
>>>> I have implemented a model of a neuron using Hodgkin Huxley equations
>> in
>>>> both R and MatLab. My preference is to work with R but R is not giving
>> me
>>>> the correct results. I also can't use ode45 as it just seems to go
>> into an
>>>> indefinite loop. However, the MatLab implementation work fine with
>>>> the same
>>>> equations, parameters and initial values and ode45. Below is my R and
>>>> MatLab implementations.
>>>> 
>>> 
>>> No problem in running your R file. Have plot.
>>> (Mac mini Core2Duo 2.66Ghz running R 3.0.1 Patched
>>> (2013-06-19 r62992) on Mac OS X 10.8.4:  16.5 seconds.)
>>> 
>>> Trying to run your Matlab file in Octave.
>>> No success yet because of unavailable ode45.
>> 
>>   I'm impressed that you (BH) went to the trouble of checking
>> on this vague "doesn't work" question.  If you want to go farther
>> I think you can get ode45 for octave by installing the odepkg
>> package:
>> 
>> http://octave.sourceforge.net/odepkg/index.html
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> 
> ===================================
> Web site: http://www.jannetta.com
> Email: jannetta at henning.org
> ===================================
> <Rplot01.png><MatPlot01.png>______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Jul  4 19:56:06 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Jul 2013 19:56:06 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
Message-ID: <F64107C5-FA5B-48AC-B712-52FB8BA91AFE@gmail.com>


On Jul 4, 2013, at 19:11 , Berend Hasselman wrote:

> 
> On 04-07-2013, at 18:42, Jannetta Steyn <jannetta at henning.org> wrote:
> 
>> Hi Ben and others
>> 
>> I don't quite know how to explain the "doesn't work" in more detail without
>> any visual aid.
> 
> You said that R got into an indefinite loop, whatever that maybe.
> 
>> When you run the two scripts it is easy to see the
>> difference. MatLab produces a line on x= -55. This is what I expect - a
>> more or less straight line. R on the other hand the result drops from -55
>> (the initial value) to -80 and then goes up to -71.37092.
>> 
>> The two scripts have exactly the same equations.
> 
> 
> I don't think so.
> In the R script you have
> 
> init = c(v_axon_AB=-55,mNa_axon_AB=1,hNa_axon_AB=0,mK_axon_AB=1)
> 
> That is not the same as in your Matlab script. To make them the same you should replace the line with
> 
> init = c(v_axon_AB=-55,mNa_axon_AB=0,hNa_axon_AB=1,mK_axon_AB=0)
> 
> Using this line gives quite different results. But not the same as Matlab.
> 
> It seems that you ought to carefully check all your equations.
> I don't know enough about Matlab/Octave syntax to determine if the results of the two systems  are identical.

Also, the line

  iLeak_axon_AB <- gLeak_axon_AB*(v_axon_AB-ELeak_axon_AB)

differs from the Matlab code. Changing it gave me all-NA results, though. And the with() construct assumes that init and parms are named vectors; parms is not, so the values are taken from the global environment. It is not clear whether that makes a difference.



> 
> Berend
> 
>> I have even named the
>> variables the same in the two scripts and copied the equations across to
>> make sure I haven't made any typos.
>> 
>> Can one attach images to posts? I'll try. The flatline image is the plot
>> from MatLab and the other is the plot from R.
>> 
>> Thanks
>> Jannetta
>> 
>> 
>> On 4 July 2013 16:52, Ben Bolker <bbolker at gmail.com> wrote:
>> 
>>> Berend Hasselman <bhh <at> xs4all.nl> writes:
>>> 
>>>> 
>>>> 
>>>> On 04-07-2013, at 17:15, Jannetta Steyn <jannetta <at> henning.org>
>>> wrote:
>>>> 
>>>>> Hi folks
>>>>> 
>>>>> I have implemented a model of a neuron using Hodgkin Huxley equations
>>> in
>>>>> both R and MatLab. My preference is to work with R but R is not giving
>>> me
>>>>> the correct results. I also can't use ode45 as it just seems to go
>>> into an
>>>>> indefinite loop. However, the MatLab implementation work fine with
>>>>> the same
>>>>> equations, parameters and initial values and ode45. Below is my R and
>>>>> MatLab implementations.
>>>>> 
>>>> 
>>>> No problem in running your R file. Have plot.
>>>> (Mac mini Core2Duo 2.66Ghz running R 3.0.1 Patched
>>>> (2013-06-19 r62992) on Mac OS X 10.8.4:  16.5 seconds.)
>>>> 
>>>> Trying to run your Matlab file in Octave.
>>>> No success yet because of unavailable ode45.
>>> 
>>>  I'm impressed that you (BH) went to the trouble of checking
>>> on this vague "doesn't work" question.  If you want to go farther
>>> I think you can get ode45 for octave by installing the odepkg
>>> package:
>>> 
>>> http://octave.sourceforge.net/odepkg/index.html
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> 
>> 
>> -- 
>> 
>> ===================================
>> Web site: http://www.jannetta.com
>> Email: jannetta at henning.org
>> ===================================
>> <Rplot01.png><MatPlot01.png>______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From motyocska at yahoo.com  Thu Jul  4 20:09:09 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Thu, 4 Jul 2013 11:09:09 -0700 (PDT)
Subject: [R] help on selecting values of an object
Message-ID: <1372961349.58343.YahooMailClassic@web140406.mail.bf1.yahoo.com>

Dear List,

please provide some input on the following:
we have

a <-c(0,1,2,3)
b <-c(4,5,6,7)
d <-cbind(a,b)
k <-c(0,0,2,2,3,3,2)

"k" in this case consists of some values of "d[,1]" in a random sequence. What I am trying to do is to create an object "f" that would have the values of "d[,2]" in it based on "k", and again, "k" here is a vector that consists of some values of "d[,1]". Basically I am trying to match the values in "k" with their corresponding pairs in "d[,2]". So the result should look like:

f <-c(4,4,6,6,7,7,6)

appreciate your input

Andras


From bhh at xs4all.nl  Thu Jul  4 20:14:34 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 4 Jul 2013 20:14:34 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <F64107C5-FA5B-48AC-B712-52FB8BA91AFE@gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<F64107C5-FA5B-48AC-B712-52FB8BA91AFE@gmail.com>
Message-ID: <938E1CEA-0DC6-4CE0-8756-8BD2A75B2DE7@xs4all.nl>


On 04-07-2013, at 19:56, peter dalgaard <pdalgd at gmail.com> wrote:

> 
> On Jul 4, 2013, at 19:11 , Berend Hasselman wrote:
> 
>> 
>> On 04-07-2013, at 18:42, Jannetta Steyn <jannetta at henning.org> wrote:
>> 
>>> Hi Ben and others
>>> 
>>> I don't quite know how to explain the "doesn't work" in more detail without
>>> any visual aid.
>> 
>> You said that R got into an indefinite loop, whatever that maybe.
>> 
>>> When you run the two scripts it is easy to see the
>>> difference. MatLab produces a line on x= -55. This is what I expect - a
>>> more or less straight line. R on the other hand the result drops from -55
>>> (the initial value) to -80 and then goes up to -71.37092.
>>> 
>>> The two scripts have exactly the same equations.
>> 
>> 
>> I don't think so.
>> In the R script you have
>> 
>> init = c(v_axon_AB=-55,mNa_axon_AB=1,hNa_axon_AB=0,mK_axon_AB=1)
>> 
>> That is not the same as in your Matlab script. To make them the same you should replace the line with
>> 
>> init = c(v_axon_AB=-55,mNa_axon_AB=0,hNa_axon_AB=1,mK_axon_AB=0)
>> 
>> Using this line gives quite different results. But not the same as Matlab.
>> 
>> It seems that you ought to carefully check all your equations.
>> I don't know enough about Matlab/Octave syntax to determine if the results of the two systems  are identical.
> 
> Also, the line
> 
>  iLeak_axon_AB <- gLeak_axon_AB*(v_axon_AB-ELeak_axon_AB)
> 
> differs from the Matlab code. Changing it gave me all-NA results, though. And the with() construct assumes that init and parms are named vectors; parms is not, so the values are taken from the global environment. It is not clear whether that makes a difference.
> 

Same NA results here. Making parms a named vector makes no difference but is is certainly necessary to do that.

In that case there is probably an inconsistency in the file simulate.m near the end:
The last non empty line before the line out = ?  reads

iLeak_axon = gLeak_axon_AB.*(v_axon_AB-ELeak_axon_AB);

and this doesn't agree with the line

iLeak_axon = ELeak_axon_AB*(v_axon_AB-ELeak_axon_AB);

in the function xdot.

Final question for the OP: if the model is supposed to be dynamic, isn't it suspicious that Matlab gives a constant result?

Berend

> 
>> 
>> Berend
>> 
>>> I have even named the
>>> variables the same in the two scripts and copied the equations across to
>>> make sure I haven't made any typos.
>>> 
>>> Can one attach images to posts? I'll try. The flatline image is the plot
>>> from MatLab and the other is the plot from R.
>>> 
>>> Thanks
>>> Jannetta
>>> 
>>> 
>>> On 4 July 2013 16:52, Ben Bolker <bbolker at gmail.com> wrote:
>>> 
>>>> Berend Hasselman <bhh <at> xs4all.nl> writes:
>>>> 
>>>>> 
>>>>> 
>>>>> On 04-07-2013, at 17:15, Jannetta Steyn <jannetta <at> henning.org>
>>>> wrote:
>>>>> 
>>>>>> Hi folks
>>>>>> 
>>>>>> I have implemented a model of a neuron using Hodgkin Huxley equations
>>>> in
>>>>>> both R and MatLab. My preference is to work with R but R is not giving
>>>> me
>>>>>> the correct results. I also can't use ode45 as it just seems to go
>>>> into an
>>>>>> indefinite loop. However, the MatLab implementation work fine with
>>>>>> the same
>>>>>> equations, parameters and initial values and ode45. Below is my R and
>>>>>> MatLab implementations.
>>>>>> 
>>>>> 
>>>>> No problem in running your R file. Have plot.
>>>>> (Mac mini Core2Duo 2.66Ghz running R 3.0.1 Patched
>>>>> (2013-06-19 r62992) on Mac OS X 10.8.4:  16.5 seconds.)
>>>>> 
>>>>> Trying to run your Matlab file in Octave.
>>>>> No success yet because of unavailable ode45.
>>>> 
>>>> I'm impressed that you (BH) went to the trouble of checking
>>>> on this vague "doesn't work" question.  If you want to go farther
>>>> I think you can get ode45 for octave by installing the odepkg
>>>> package:
>>>> 
>>>> http://octave.sourceforge.net/odepkg/index.html
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>>> 
>>> -- 
>>> 
>>> ===================================
>>> Web site: http://www.jannetta.com
>>> Email: jannetta at henning.org
>>> ===================================
>>> <Rplot01.png><MatPlot01.png>______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 
> 
> 
> 
> 
> 


From dcarlson at tamu.edu  Thu Jul  4 20:23:11 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 4 Jul 2013 13:23:11 -0500
Subject: [R] help on selecting values of an object
In-Reply-To: <1372961349.58343.YahooMailClassic@web140406.mail.bf1.yahoo.com>
References: <1372961349.58343.YahooMailClassic@web140406.mail.bf1.yahoo.com>
Message-ID: <0fae01ce78e3$8a6335b0$9f29a110$@tamu.edu>

I think this is what you are looking for

> f <- d[match(k, d[,1]), 2]
> f
[1] 4 4 6 6 7 7 6


-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Andras Farkas
Sent: Thursday, July 4, 2013 1:09 PM
To: r-help at r-project.org
Subject: [R] help on selecting values of an object

Dear List,

please provide some input on the following:
we have

a <-c(0,1,2,3)
b <-c(4,5,6,7)
d <-cbind(a,b)
k <-c(0,0,2,2,3,3,2)

"k" in this case consists of some values of "d[,1]" in a random
sequence. What I am trying to do is to create an object "f" that
would have the values of "d[,2]" in it based on "k", and again, "k"
here is a vector that consists of some values of "d[,1]". Basically
I am trying to match the values in "k" with their corresponding
pairs in "d[,2]". So the result should look like:

f <-c(4,4,6,6,7,7,6)

appreciate your input

Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jul  4 20:49:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 4 Jul 2013 11:49:03 -0700 (PDT)
Subject: [R] help on selecting values of an object
In-Reply-To: <1372961349.58343.YahooMailClassic@web140406.mail.bf1.yahoo.com>
References: <1372961349.58343.YahooMailClassic@web140406.mail.bf1.yahoo.com>
Message-ID: <1372963743.17796.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You could use:
d1<- data.frame(a,b)
k1<-data.frame(a=k)
library(plyr)
join(k1,d1,by="a")[,2]
#[1] 4 4 6 6 7 7 6
A.K.




----- Original Message -----
From: Andras Farkas <motyocska at yahoo.com>
To: r-help at r-project.org
Cc: 
Sent: Thursday, July 4, 2013 2:09 PM
Subject: [R] help on selecting values of an object

Dear List,

please provide some input on the following:
we have

a <-c(0,1,2,3)
b <-c(4,5,6,7)
d <-cbind(a,b)
k <-c(0,0,2,2,3,3,2)

"k" in this case consists of some values of "d[,1]" in a random sequence. What I am trying to do is to create an object "f" that would have the values of "d[,2]" in it based on "k", and again, "k" here is a vector that consists of some values of "d[,1]". Basically I am trying to match the values in "k" with their corresponding pairs in "d[,2]". So the result should look like:

f <-c(4,4,6,6,7,7,6)

appreciate your input

Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Thu Jul  4 23:21:46 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Thu, 4 Jul 2013 23:21:46 +0200
Subject: [R] Meta-analysis on a repeated measures design with multiple
 trials per subject using metafor
In-Reply-To: <51D415D6.5070201@uva.nl>
References: <51D415D6.5070201@uva.nl>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D833E9764@UM-MAIL4112.unimaas.nl>

Dear Marc,

Let me see if I understand the type of data you have. You say that you have 5 experiments. And within each experiment, you have n subjects and for each subject, you have data in the form described in your post. Now for each subject, you want to calculate some kind of measure that quantifies how much more likely it was that subjects gave/chose response 2 under treatment 2 versus treatment 1. So, you would have n such values. And then you want to pool those values over the n subjects within a particular experiment and then ultimately over the 5 experiments. Is that correct so far?

Assuming I got this right, let me ask you about those data that you have for each subject. In particular, are these paired data? In other words, is there are 1:1 relationship between the 30 trials under treatment 1 versus treatment 2? Or phrased yet another way, can you construct a table like this for every subject:

                trt 2
             ------------
             resp1 resp2                  
trt 1 resp1  a     b      10
      resp2  c     d      20
             20    10     30

Note that I added the marginal counts based on your example data, but this is not sufficient to reconstruct how often response 1 was chosen for the same trial under both treatment 1 and treatment 2 (cell "a"). And so on for the other 3 cells.

If all of this applies, then essentially you are dealing with dependent proportions and you can calculate the difference y = (20/30)-(10/30) as you have done. The corresponding sampling variance can be estimated with v = var(y) = (a+b)*(c+d)/t^3 + (a+c)*(b+d)/t^3 - 2*(a*d/t^3 - b*c/t^3) (where t is the number of trials, i.e., 30 in the example above). See, for example, section 10.1.1. in Agresti (2002) (Categorical data analysis, 2nd ed.).

So, ultimately, you will have n values of y and v for a particular experiment and then the same thing for all 5 experiments. You can then pool those values with rma(yi, vi) in metafor (yi and vi being the vectors of the y and v values). You probably want to add a factor to the model that indicates which experiment those values came from. So, something like: rma(yi, vi, mods = ~ factor(experiment)).

Well, I hope that I understood your data correctly.

Best,
Wolfgang

--
Wolfgang Viechtbauer, Ph.D., Statistician
Department of Psychiatry and Psychology
School for Mental Health and Neuroscience
Faculty of Health, Medicine, and Life Sciences
Maastricht University, P.O. Box 616 (VIJV1)
6200 MD Maastricht, The Netherlands
+31 (43) 388-4170 | http://www.wvbauer.com
________________________________________
From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf Of Marc Heerdink [m.w.heerdink at uva.nl]
Sent: Wednesday, July 03, 2013 2:15 PM
To: r-help at r-project.org
Subject: [R] Meta-analysis on a repeated measures design with multiple trials per subject using metafor

Hi all,

I am currently attempting to compile a summary of a series of five
psychological experiments, and I am trying to do this using the metafor
package. However, I am quite unsure which of the scenarios described in
the metafor help pages applies to these data, because it is a repeated
measures design, with multiple trials in each condition.

Assume that for every participant, I have a basic contingency table such
as this one:

                treatment
                1       2
response
1               10      20
2               20      10

(if this ASCII version does not work, I have 30 trials in each
treatment, and participants give either response 1 or 2; the exact
numbers don't matter)

The problem that I am trying to solve is how to convert these numbers to
an effect size estimate that I can use with metafor.

As far as I understand it, I can only use it to get an effect size for
outcomes that are dichotomous; i.e., either 1 or 0 for any subject.
However, I have proportion data for every participant.

I have considered and tried these strategies:

1. Base the effect size on within-participant proportion differences.
That is, in the table above, the treatment effect would be
(20/30)-(10/30) = 1/3; and I would take the M and SD of these values to
estimate a study-level effect ("MN" measure in metafor).

2. Use the overall treatment * response contingency table, ignoring the
fact that these counts come from different participants ("PHI" or "OR"
measures in metafor). In a study with 10 participants, I would get cell
counts around 150.

However, from the research I've done into this topic, I know that 1) is
not applicable to (as far as I understand) an odds ratio, and I suspect
2) overestimates the effect.

A third method would be to use the regression coefficients, that I can
easily obtain since I have all the raw data that I need. However, it is
unclear to me whether and if yes, how I can use these in the metafor
package.

 From my understanding of another message about this topic I found on
this list (1), I understand that having access to the raw data is an
advantage, but I am not sure whether the scenario mentioned applies to
my situation.

1:
http://r.789695.n4.nabble.com/meta-analysis-with-repeated-measure-designs-td2252644.html

I would very much appreciate any suggestions or hints on this topic.

Regards,
Marc
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Thu Jul  4 23:25:04 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 4 Jul 2013 23:25:04 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <938E1CEA-0DC6-4CE0-8756-8BD2A75B2DE7@xs4all.nl>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<F64107C5-FA5B-48AC-B712-52FB8BA91AFE@gmail.com>
	<938E1CEA-0DC6-4CE0-8756-8BD2A75B2DE7@xs4all.nl>
Message-ID: <EFDBF7BF-CAA3-4977-A13E-BA5FE679FB5C@gmail.com>


On Jul 4, 2013, at 20:14 , Berend Hasselman wrote:

> 
> On 04-07-2013, at 19:56, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> On Jul 4, 2013, at 19:11 , Berend Hasselman wrote:
>> 
>>> 
>>> On 04-07-2013, at 18:42, Jannetta Steyn <jannetta at henning.org> wrote:
>>> 
>>>> Hi Ben and others
>>>> 
>>>> I don't quite know how to explain the "doesn't work" in more detail without
>>>> any visual aid.
>>> 
>>> You said that R got into an indefinite loop, whatever that maybe.
>>> 
>>>> When you run the two scripts it is easy to see the
>>>> difference. MatLab produces a line on x= -55. This is what I expect - a
>>>> more or less straight line. R on the other hand the result drops from -55
>>>> (the initial value) to -80 and then goes up to -71.37092.
>>>> 
>>>> The two scripts have exactly the same equations.
>>> 
>>> 
>>> I don't think so.
>>> In the R script you have
>>> 
>>> init = c(v_axon_AB=-55,mNa_axon_AB=1,hNa_axon_AB=0,mK_axon_AB=1)
>>> 
>>> That is not the same as in your Matlab script. To make them the same you should replace the line with
>>> 
>>> init = c(v_axon_AB=-55,mNa_axon_AB=0,hNa_axon_AB=1,mK_axon_AB=0)
>>> 
>>> Using this line gives quite different results. But not the same as Matlab.
>>> 
>>> It seems that you ought to carefully check all your equations.
>>> I don't know enough about Matlab/Octave syntax to determine if the results of the two systems  are identical.
>> 
>> Also, the line
>> 
>> iLeak_axon_AB <- gLeak_axon_AB*(v_axon_AB-ELeak_axon_AB)
>> 
>> differs from the Matlab code. Changing it gave me all-NA results, though. And the with() construct assumes that init and parms are named vectors; parms is not, so the values are taken from the global environment. It is not clear whether that makes a difference.
>> 
> 
> Same NA results here. Making parms a named vector makes no difference but is is certainly necessary to do that.
> 
> In that case there is probably an inconsistency in the file simulate.m near the end:
> The last non empty line before the line out = ?  reads
> 
> iLeak_axon = gLeak_axon_AB.*(v_axon_AB-ELeak_axon_AB);
> 
> and this doesn't agree with the line
> 
> iLeak_axon = ELeak_axon_AB*(v_axon_AB-ELeak_axon_AB);
> 
> in the function xdot.
> 
> Final question for the OP: if the model is supposed to be dynamic, isn't it suspicious that Matlab gives a constant result?

Also, in this block

gNa_axon_AB=300e-3
gK_axon_AB=52.5-3
gLeak_axon_AB=0.0018e-3

the middle line looks like a typo for 52.5e-3 and the 3rd line looks very low -- googling suggests values like (120, 36, 0.3) mS/cm^3, which would be more consistent with a value around 1e-3.


> 
> Berend
> 
>> 
>>> 
>>> Berend
>>> 
>>>> I have even named the
>>>> variables the same in the two scripts and copied the equations across to
>>>> make sure I haven't made any typos.
>>>> 
>>>> Can one attach images to posts? I'll try. The flatline image is the plot
>>>> from MatLab and the other is the plot from R.
>>>> 
>>>> Thanks
>>>> Jannetta
>>>> 
>>>> 
>>>> On 4 July 2013 16:52, Ben Bolker <bbolker at gmail.com> wrote:
>>>> 
>>>>> Berend Hasselman <bhh <at> xs4all.nl> writes:
>>>>> 
>>>>>> 
>>>>>> 
>>>>>> On 04-07-2013, at 17:15, Jannetta Steyn <jannetta <at> henning.org>
>>>>> wrote:
>>>>>> 
>>>>>>> Hi folks
>>>>>>> 
>>>>>>> I have implemented a model of a neuron using Hodgkin Huxley equations
>>>>> in
>>>>>>> both R and MatLab. My preference is to work with R but R is not giving
>>>>> me
>>>>>>> the correct results. I also can't use ode45 as it just seems to go
>>>>> into an
>>>>>>> indefinite loop. However, the MatLab implementation work fine with
>>>>>>> the same
>>>>>>> equations, parameters and initial values and ode45. Below is my R and
>>>>>>> MatLab implementations.
>>>>>>> 
>>>>>> 
>>>>>> No problem in running your R file. Have plot.
>>>>>> (Mac mini Core2Duo 2.66Ghz running R 3.0.1 Patched
>>>>>> (2013-06-19 r62992) on Mac OS X 10.8.4:  16.5 seconds.)
>>>>>> 
>>>>>> Trying to run your Matlab file in Octave.
>>>>>> No success yet because of unavailable ode45.
>>>>> 
>>>>> I'm impressed that you (BH) went to the trouble of checking
>>>>> on this vague "doesn't work" question.  If you want to go farther
>>>>> I think you can get ode45 for octave by installing the odepkg
>>>>> package:
>>>>> 
>>>>> http://octave.sourceforge.net/odepkg/index.html
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>> 
>>>> 
>>>> 
>>>> -- 
>>>> 
>>>> ===================================
>>>> Web site: http://www.jannetta.com
>>>> Email: jannetta at henning.org
>>>> ===================================
>>>> <Rplot01.png><MatPlot01.png>______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> -- 
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ejoffe at hotmail.com  Thu Jul  4 23:52:05 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Thu, 4 Jul 2013 16:52:05 -0500
Subject: [R] coxph doesn't converge when including factor variables
In-Reply-To: <001d01ce78fd$02bad220$08307660$@hotmail.com>
References: <001d01ce78fd$02bad220$08307660$@hotmail.com>
Message-ID: <DUB114-DS4CC0716F31CB044E5C775CA7C0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/27e70ebd/attachment.pl>

From sjackman at gmail.com  Thu Jul  4 23:53:24 2013
From: sjackman at gmail.com (Shaun Jackman)
Date: Thu, 4 Jul 2013 14:53:24 -0700
Subject: [R] Lattice barchart with error bars
Message-ID: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>

Hi,

I'd like to draw a lattice barchart of means with error bars to show
the standard deviation. I have the barchart, how do I add the error
bars?

require(datasets)
require(lattice)
x <- aggregate(weight ~ Diet, ChickWeight, function(x) c(mean=mean(x),
sd=sd(x)))
barchart(weight[,'mean'] ~ Diet, x)

Thanks,
Shaun


From rolf.turner at xtra.co.nz  Thu Jul  4 23:59:34 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 05 Jul 2013 09:59:34 +1200
Subject: [R] Help
In-Reply-To: <F5B944E50D3656499D652210B3A1271E123E9C@WSC281PEVS.hdwa.health.wa.gov.au>
References: <F5B944E50D3656499D652210B3A1271E123E9C@WSC281PEVS.hdwa.health.wa.gov.au>
Message-ID: <51D5F046.1060605@xtra.co.nz>


Please (for crying out loud!) use a meaningful subject line!!! This
list is called "r-help"!!!  Using a subject line of "Help" is completely
vacuous.

     cheers,

         Rolf Turner

On 04/07/13 20:33, Aboagye-sarfo, Patrick wrote:
> I am trying to download packages and the message I get is as follows
>

     <SNIP>


From jwiley.psych at gmail.com  Fri Jul  5 00:17:36 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 4 Jul 2013 15:17:36 -0700
Subject: [R] Help
In-Reply-To: <51D5F046.1060605@xtra.co.nz>
References: <F5B944E50D3656499D652210B3A1271E123E9C@WSC281PEVS.hdwa.health.wa.gov.au>
	<51D5F046.1060605@xtra.co.nz>
Message-ID: <CANz9Z_J3_47ozUv=LUzsd8if0tymXSfBHWcVFP7f8jnB8EFjNA@mail.gmail.com>

Well, it implies either 2help or help^2, right?  In this case, it
seems oddly appropriate, as really needing help getting packages is
sort of greater in a "need hierarchy" than coding help, as the latter
is largely useless without the former.

At one point, I seem to recall discussion of whether there was use for
a sort of "beginners" R help and a more "advanced" one (part of the
discussion was that R-devel is kind of advanced), but perhaps there is
implicit sorting, by virtue of subjects, yes, even one as simple as
"Help" as that allows seasoned veterans to distinguish a new asker
from someone who has been through the ropes here many times.

Cheers,

Josh


On Thu, Jul 4, 2013 at 2:59 PM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
>
> Please (for crying out loud!) use a meaningful subject line!!! This
> list is called "r-help"!!!  Using a subject line of "Help" is completely
> vacuous.
>
>     cheers,
>
>         Rolf Turner
>
>
> On 04/07/13 20:33, Aboagye-sarfo, Patrick wrote:
>>
>> I am trying to download packages and the message I get is as follows
>>
>
>     <SNIP>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From gunter.berton at gene.com  Fri Jul  5 00:30:14 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 4 Jul 2013 15:30:14 -0700
Subject: [R] Lattice barchart with error bars
In-Reply-To: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
Message-ID: <CACk-te3dd3WUFpturf2rKHJkUKHHV8Uwrh4aM6yxd=9O9q1Erg@mail.gmail.com>

Shaun:

I understand that this type of plot is standard in many disciplines,
but it really is awful (google on 'Dynamite plots' for some more
erudite perspectives). Have you considered bwplot() for your
unaggregated data instead?

(No need to reply. It's July 4, and I'm just waving a little flag for
better graphs).

Cheers,
Bert

On Thu, Jul 4, 2013 at 2:53 PM, Shaun Jackman <sjackman at gmail.com> wrote:
> Hi,
>
> I'd like to draw a lattice barchart of means with error bars to show
> the standard deviation. I have the barchart, how do I add the error
> bars?
>
> require(datasets)
> require(lattice)
> x <- aggregate(weight ~ Diet, ChickWeight, function(x) c(mean=mean(x),
> sd=sd(x)))
> barchart(weight[,'mean'] ~ Diet, x)
>
> Thanks,
> Shaun
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From jannetta at henning.org  Fri Jul  5 00:41:46 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Thu, 4 Jul 2013 23:41:46 +0100
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <EFDBF7BF-CAA3-4977-A13E-BA5FE679FB5C@gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<F64107C5-FA5B-48AC-B712-52FB8BA91AFE@gmail.com>
	<938E1CEA-0DC6-4CE0-8756-8BD2A75B2DE7@xs4all.nl>
	<EFDBF7BF-CAA3-4977-A13E-BA5FE679FB5C@gmail.com>
Message-ID: <CAGR4ry42jPRcDnrA-415vkZn_ZWh0paxiyhnukR5JJSAtYLQTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/8d288044/attachment.pl>

From dwinsemius at comcast.net  Fri Jul  5 01:30:10 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Jul 2013 16:30:10 -0700
Subject: [R] setClass confusion
In-Reply-To: <CACxE24mnKwt4kyfHoCX+MSj3P9J0czhEbL90faDXPeEpHMLYNA@mail.gmail.com>
References: <CACxE24mnKwt4kyfHoCX+MSj3P9J0czhEbL90faDXPeEpHMLYNA@mail.gmail.com>
Message-ID: <931B5F07-8C69-493F-9D8E-55D51651A973@comcast.net>


On Jul 3, 2013, at 4:54 PM, Erin Hodgess wrote:

> Dear R People:
> 
> 
> I am experimenting with S4 classes and methods but am having trouble with
> setting up a class.
> 
> Here is an example:
> 
>> buzz <- setClass("buzz",slots=c(x="matrix"),
> + validity <- function(object) {
> + if(is.matrix(object)==FALSE)stop("Input must be a matrix")
> + TRUE
> + })
> Error in setClass("buzz", slots = c(x = "matrix"), validity <-
> function(object) { :
>  Argument "representation" cannot be used if argument "slots" is supplied
>> 
> 
> I know that there is something simple that I'm just not seeing.

If you take the validity argument out it doesnot throw an error and the help page for setClass refers you to ?validObject for details.

> 
> This is R-3.0.1 for Windows.
> Thanks for any help.
> 
> Sincerely,
> Erin
> 

David Winsemius
Alameda, CA, USA


From pdalgd at gmail.com  Fri Jul  5 01:38:16 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 5 Jul 2013 01:38:16 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <CAGR4ry42jPRcDnrA-415vkZn_ZWh0paxiyhnukR5JJSAtYLQTw@mail.gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<F64107C5-FA5B-48AC-B712-52FB8BA91AFE@gmail.com>
	<938E1CEA-0DC6-4CE0-8756-8BD2A75B2DE7@xs4all.nl>
	<EFDBF7BF-CAA3-4977-A13E-BA5FE679FB5C@gmail.com>
	<CAGR4ry42jPRcDnrA-415vkZn_ZWh0paxiyhnukR5JJSAtYLQTw@mail.gmail.com>
Message-ID: <A3DB8865-E146-44D4-A10C-DF4F6D11C470@gmail.com>


On Jul 5, 2013, at 00:41 , Jannetta Steyn wrote:

> Hi All
> 
> Thanks for all the comments. I have looked at everything you have pointed
> out and this is the situation at the moment:
> 
>> I don't think so.
>> In the R script you have
>> 
>> init = c(v_axon_AB=-55,mNa_axon_AB=1,hNa_axon_AB=0,mK_axon_AB=1)
>> 
>> That is not the same as in your Matlab script. To make them the same you
> should replace the line with
>> 
>> init = c(v_axon_AB=-55,mNa_axon_AB=0,hNa_axon_AB=1,mK_axon_AB=0)
>> 
>> Using this line gives quite different results. But not the same as Matlab.
> 
> You are right. I have to admit when I referred to equations I referred to
> those in the ST function, and not the initialisation and parameter
> equations. I fixed the line, but look you said it still doesn't produce the
> same results as MatLab.
> 
>> In that case there is probably an inconsistency in the file simulate.m
> near the end:
>> The last non empty line before the line out = ?  reads
>> 
>> iLeak_axon = gLeak_axon_AB.*(v_axon_AB-ELeak_axon_AB);
>> 
>> and this doesn't agree with the line
>> 
>> iLeak_axon = ELeak_axon_AB*(v_axon_AB-ELeak_axon_AB);
>> 
>> in the function xdot.
> 
> The correct equation is:
> 
> iLeak_axon = gLeak_axon_AB.*(v_axon_AB-ELeak_axon_AB);
> 
> I think this error was the result of a variable name change at some point
> to make the to scripts the same. I have fixed the MatLab script but it is
> not making any difference.
> 
>> 
>> Final question for the OP: if the model is supposed to be dynamic, isn't
> it suspicious that Matlab gives a constant result?
> 
> Now this is true ... I'll chat to my MatLab expert about this. I was hoping
> that it is not a constant but that it has small variations in the value
> that I can't see on the graph. However, I did not know how to check the
> values ... another question for my MatLab expert tomorrow.
> 
>> Also, in this block
>> 
>> gNa_axon_AB=300e-3
>> gK_axon_AB=52.5-3
>> gLeak_axon_AB=0.0018e-3
>> 
>> the middle line looks like a typo for 52.5e-3 and the 3rd line looks very
> low -- googling suggests values like (120, 36, 0.3) mS/cm^3, which would be
> more consistent with a value around 1e-3.
> 
> Yes you are right. 52.5-3 should be 52.5e-3. I made the change but still no
> luck.
> 
> With regards to the value of gLeak_axon_AB, the values I'm using for the
> model are from a paper. I tried changing it to what you suggested, but that
> seems to result in a constant value of -60.00006

But isn't -60 = ELeak_axon_AB exactly the right steady-state value for the system with both the K and Na channels closed?

> 
> More late night staring ahead for me ...
> 
> Regards
> Jannetta
> 
> 
> -- 
> 
> ===================================
> Web site: http://www.jannetta.com
> Email: jannetta at henning.org
> ===================================
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From dwinsemius at comcast.net  Fri Jul  5 01:38:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Jul 2013 16:38:53 -0700
Subject: [R] bootstrapping respecting subject level information
In-Reply-To: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
References: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
Message-ID: <46A08D35-7E3A-4647-A1B6-C39155E15F0C@comcast.net>


On Jul 3, 2013, at 7:19 PM, Sol Lago wrote:

> Hi there,
> 
> This is the first time I use this forum, and I want to say from the start I am not a skilled programmer. So please let me know if the question or code were unclear!
> 
> I am trying to bootstrap an interaction (that is my test statistic) using the package "boot". My problem is that for every resample, I would like the randomization to be done within subjects, so that observations from different subjects are not mixed. Here is the code to generate a dataframe similar to mine:
> 
> Subject = rep(c("S1","S2","S3","S4"),4)
> Num     = rep(c("singular","plural"),8) 
> Gram    = rep(c("gram","gram","ungram","ungram"),4)
> RT      = c(657,775,678,895,887,235,645,916,930,768,890,1016,590,978,450,920)
> data    = data.frame(Subject,Num,Gram,RT) 
> 
> This is the code I used to get the empirical interaction value:
> 
> summary(lm(RT ~ Num*Gram, data=data))
> 
> As you can see, the interaction between my two factors is -348.

That depends on what you mean by "the interaction between my two factors". It is almost never a good idea to attempt interpretation of interaction coefficients, and is always preferable to check the predictions of hte model.

> I want to get a bootstrap confidence interval for this statistic, which I can generate using the "boot" package:
> 
> #Function to create the statistic to be boostrapped
> boot.huber <- function(data, indices) {
> data <- data[indices, ] #select obs. in bootstrap sample
> mod <- lm(RT ~ Num*Gram, data=data)
> coefficients(mod)       #return coefficient vector
> }
> 
> #Generate bootstrap estimate
> data.boot <- boot(data, boot.huber, 1999)
> 
> #Get confidence interval
> boot.ci(data.boot, index=4, type=c("norm", "perc", "bca"),conf=0.95) #4 gets the CI for the interaction
> 
> My problem is that I think the resamples should be generated without mixing the individual subjects observations: that is, to generate the new resamples, the observations from subject 1 (S1) should be shuffled within subject 1,

What does that mean?

> not mixing them with the observations from subjects 2, etc... I don't know how "boot" is doing the resampling (I read the documentation but don't understand how the function is doing it)

It's doing it by selecting randomly entire rows. It is not "shuffling within rows" for selected subjects.
> 
> Does anyone know how I could make sure that the resampling procedure used by "boot" respects the subject level information?

It would be doing so because that is the way you set up the indexing. The column ordering tof the data within subjects is not permuted.

I do think you are beyond your understanding of the statstical principles that you are attempting to use and would be safer to consult with a statsitician.


-- 
David Winsemius
Alameda, CA, USA


From wdunlap at tibco.com  Fri Jul  5 02:02:18 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Jul 2013 00:02:18 +0000
Subject: [R] Subsetting multiple rows of a data frame at once
In-Reply-To: <1372914879.51445.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <25563192.156234.1372907812821.JavaMail.nabble@joe.nabble.com>
	<BAY167-W646E5535CADE996C808532837C0@phx.gbl>
	<1372914879.51445.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C317763@PA-MBX01.na.tibco.com>

> xt<- c(1.05, 2.85, 3.40, 4.25, 0.25, 3.05, 3.70, 0.20, 0.30, 0.70, 1.05, 1.20, 1.40, 1.90,
> 2.70, 3.25, 3.55, 4.60, 2.05, 2.15, 3.70, 4.85, 4.90, 1.60, 2.45, 3.20, 3.90, 4.45)
> 
> yt<- c(0.25, 0.10, 0.90, 0.25, 1.05, 1.70, 2.05, 2.90, 2.35, 2.60, 2.55, 2.15, 2.75, 2.05,
> 2.70, 2.25, 2.55, 2.05, 3.65, 3.05, 3.00, 3.50, 3.75, 4.85, 4.50, 4.50, 3.35, 4.90)
> carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
> trees<-do.call(rbind,lapply(seq_along(xt),function(i) subset(carbon.fit,x==xt[i]&y==yt[i])))
> 
> ## xt is 28 integers long and when i run the above code it only returns the values of 18
> out of the 28 (xt,yt) pairs that i want.

You are running into the problem that two different computational methods that give
the same result when applied to real numbers often give different results when applied
to 64-bit floating point numbers.  (In your case you expect seq(0,5,.01) to contain, e.g.,
the floating point number generate by parsing the string "3.05".)   Hence x==y is not true
when you expect it to be.  Here is where your 18 came from:
   R> table(xt %in% carbon.fit$x, yt %in% carbon.fit$y)
          
           FALSE TRUE
     FALSE     1    6
     TRUE      3   18
Round your number to the nearest 10^-10 and you get
  > table(round(xt,10) %in% round(carbon.fit$x,10), round(yt,10) %in% round(carbon.fit$y,10))
        
         TRUE
    TRUE   28

By the way, you may prefer using the merge() function rather than the do.call(rbind,lapply(...)))
business.  I think the following call to merge will do about what you want (the row names differ -
if they are important it is possible to get them with some minor trickery):
    merge(data.frame(x=xt,y=yt), carbon.fit)
(You still want to round your numbers as before.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Wednesday, July 03, 2013 10:15 PM
> To: Shaun ? Anika
> Cc: R help
> Subject: Re: [R] Subsetting multiple rows of a data frame at once
> 
> Hi,
> 
> carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
> ?dim(carbon.fit)
> #[1] 251001????? 2
> 
> 
> ?xtNew<-sprintf("%.2f",xt)
> ?ytNew<- sprintf("%.2f",yt)
> ?carbon.fit[]<- lapply(carbon.fit,function(x) sprintf("%.2f",x))
> res<-do.call(rbind,lapply(seq_along(xtNew),function(i)
> subset(carbon.fit,x==xtNew[i]&y==ytNew[i])))
> ?nrow(res)
> #[1] 28
> res
> #????????? x??? y
> #12631? 1.05 0.25
> #5296?? 2.85 0.10
> #45431? 3.40 0.90
> #12951? 4.25 0.25
> #52631? 0.25 1.05
> #85476? 3.05 1.70
> #103076 3.70 2.05
> #145311 0.20 2.90
> #117766 0.30 2.35
> #130331 0.70 2.60
> #127861 1.05 2.55
> #107836 1.20 2.15
> #137916 1.40 2.75
> #102896 1.90 2.05
> #135541 2.70 2.70
> #113051 3.25 2.25
> #128111 3.55 2.55
> #103166 4.60 2.05
> #183071 2.05 3.65
> #153021 2.15 3.05
> #150671 3.70 3.00
> #175836 4.85 3.50
> #188366 4.90 3.75
> #243146 1.60 4.85
> #225696 2.45 4.50
> #225771 3.20 4.50
> #168226 3.90 3.35
> #245936 4.45 4.90
> A.K.
> 
> 
> ________________________________
> From: Shaun ? Anika <pro_patto at hotmail.com>
> To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
> Sent: Thursday, July 4, 2013 12:08 AM
> Subject: RE: Subsetting multiple rows of a data frame at once
> 
> 
> 
> 
> Hi There,
> i can give you the data needed to perform this task...
> 
> library(akima)
> library(fields)
> 
> xt<- c(1.05, 2.85, 3.40, 4.25, 0.25, 3.05, 3.70, 0.20, 0.30, 0.70, 1.05, 1.20, 1.40, 1.90,
> 2.70, 3.25, 3.55, 4.60, 2.05, 2.15,?3.70, 4.85, 4.90, 1.60, 2.45, 3.20, 3.90, 4.45)
> 
> yt<- c(0.25, 0.10, 0.90, 0.25, 1.05, 1.70, 2.05, 2.90, 2.35, 2.60, 2.55, 2.15, 2.75, 2.05,
> 2.70, 2.25, 2.55, 2.05, 3.65, 3.05,?3.00, 3.50, 3.75, 4.85, 4.50, 4.50, 3.35, 4.90)
> 
> xs<- c(0.45, 1.05, 2.75, 3.30, 4.95, 0.40, 1.05, 2.30, 3.45, 4.60, 0.05, 1.95, 2.95, 3.70,
> 4.55, 0.75, 1.60, 2.10, 3.60, 4.90,?0.05, 1.35, 2.60, 3.40, 4.25)
> 
> ys<- c(0.45, 0.95, 0.75, 0.95, 0.10, 1.90, 1.45, 1.25, 1.45, 1.05, 2.85, 2.60, 2.05, 2.60,
> 2.55, 3.75, 3.30, 3.95, 3.45, 3.70,?4.95, 4.35, 4.55, 4.40, 4.95)
> 
> carbon<- c(1.43, 1.82, 1.40, 1.43, 1.96, 1.61, 1.91, 1.53, 1.17, 1.83, 2.43, 2.02, 1.66,
> 2.45, 2.46, 1.39, 1.10, 1.38, 1.91, 2.13,?1.88, 1.26, 2.15, 1.89, 1.69)
> 
> carbon.df=data.frame(x=xs,y=ys,z=carbon)
> carbon.loess= loess(z~x*y, data= carbon.df, degree= 2)
> carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
> z=predict(carbon.loess, newdata= carbon.fit)
> carbon.fit$Height=as.numeric(z)
> image.plot(seq(0,5,0.01,), seq(0,5,0.01), z, xlab = "", ylab="",main = "Carbon")
> 
> trees<-do.call(rbind,lapply(seq_along(xt),function(i) subset(carbon.fit,x==xt[i]&y==yt[i])))
> 
> ## xt is 28 integers long and when i run the above code it only returns the values of 18
> out of the 28 (xt,yt) pairs that i want.
> 
> thanks for your help!!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From A.Robinson at ms.unimelb.edu.au  Fri Jul  5 02:38:36 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 5 Jul 2013 10:38:36 +1000
Subject: [R] bootstrapping respecting subject level information
In-Reply-To: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
References: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
Message-ID: <CAHyGmd55_yzx5SaY8t6VqJaY5m99v80bAq0bk_csyaDxu0ncKQ@mail.gmail.com>

I'd like to preface this answer by suggesting that if you have multiple
measurements within subjects then you should possibly be thinking about
using mixed-effects models.  Here you have a balanced design and seem
to be thinking about a constrained bootstrap, but I don't know whether
the resulting distribution will have the right properties - others on
the list may.

That said, I think that this needs the 'strata' argument of the boot function.
See the help.  Something like

data.boot <- boot(data, boot.huber, 1999, strata = Subject)

(not tested)

Cheers

Andrew

On Thu, Jul 4, 2013 at 12:19 PM, Sol Lago <solcita.lago at gmail.com> wrote:
> Hi there,
>
> This is the first time I use this forum, and I want to say from the start I am not a skilled programmer. So please let me know if the question or code were unclear!
>
> I am trying to bootstrap an interaction (that is my test statistic) using the package "boot". My problem is that for every resample, I would like the randomization to be done within subjects, so that observations from different subjects are not mixed. Here is the code to generate a dataframe similar to mine:
>
> Subject = rep(c("S1","S2","S3","S4"),4)
> Num     = rep(c("singular","plural"),8)
> Gram    = rep(c("gram","gram","ungram","ungram"),4)
> RT      = c(657,775,678,895,887,235,645,916,930,768,890,1016,590,978,450,920)
> data    = data.frame(Subject,Num,Gram,RT)
>
> This is the code I used to get the empirical interaction value:
>
> summary(lm(RT ~ Num*Gram, data=data))
>
> As you can see, the interaction between my two factors is -348. I want to get a bootstrap confidence interval for this statistic, which I can generate using the "boot" package:
>
> #Function to create the statistic to be boostrapped
> boot.huber <- function(data, indices) {
> data <- data[indices, ] #select obs. in bootstrap sample
> mod <- lm(RT ~ Num*Gram, data=data)
> coefficients(mod)       #return coefficient vector
> }
>
> #Generate bootstrap estimate
> data.boot <- boot(data, boot.huber, 1999)
>
> #Get confidence interval
> boot.ci(data.boot, index=4, type=c("norm", "perc", "bca"),conf=0.95) #4 gets the CI for the interaction
>
> My problem is that I think the resamples should be generated without mixing the individual subjects observations: that is, to generate the new resamples, the observations from subject 1 (S1) should be shuffled within subject 1, not mixing them with the observations from subjects 2, etc... I don't know how "boot" is doing the resampling (I read the documentation but don't understand how the function is doing it)
>
> Does anyone know how I could make sure that the resampling procedure used by "boot" respects the subject level information?
>
> Thanks a lot for your help/advice!
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Andrew Robinson
Deputy Director, CEBRA
Senior Lecturer in Applied Statistics                      Tel: +61-3-8344-6410
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au

FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/


From A.Robinson at ms.unimelb.edu.au  Fri Jul  5 02:48:19 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 5 Jul 2013 10:48:19 +1000
Subject: [R] bootstrapping respecting subject level information
In-Reply-To: <46A08D35-7E3A-4647-A1B6-C39155E15F0C@comcast.net>
References: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
	<46A08D35-7E3A-4647-A1B6-C39155E15F0C@comcast.net>
Message-ID: <CAHyGmd7B8mQ-YwVHtLMqvxRUvL4F_2SxbS6Jp1OeWGxoq47W7w@mail.gmail.com>

I think that in the case of a 2*2 balanced, replicated design such as
this one, interpreting the interaction should be safe.

Cheers

Andrew

On Fri, Jul 5, 2013 at 9:38 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jul 3, 2013, at 7:19 PM, Sol Lago wrote:
>
>> Hi there,
>>
>> This is the first time I use this forum, and I want to say from the start I am not a skilled programmer. So please let me know if the question or code were unclear!
>>
>> I am trying to bootstrap an interaction (that is my test statistic) using the package "boot". My problem is that for every resample, I would like the randomization to be done within subjects, so that observations from different subjects are not mixed. Here is the code to generate a dataframe similar to mine:
>>
>> Subject = rep(c("S1","S2","S3","S4"),4)
>> Num     = rep(c("singular","plural"),8)
>> Gram    = rep(c("gram","gram","ungram","ungram"),4)
>> RT      = c(657,775,678,895,887,235,645,916,930,768,890,1016,590,978,450,920)
>> data    = data.frame(Subject,Num,Gram,RT)
>>
>> This is the code I used to get the empirical interaction value:
>>
>> summary(lm(RT ~ Num*Gram, data=data))
>>
>> As you can see, the interaction between my two factors is -348.
>
> That depends on what you mean by "the interaction between my two factors". It is almost never a good idea to attempt interpretation of interaction coefficients, and is always preferable to check the predictions of hte model.
>
>> I want to get a bootstrap confidence interval for this statistic, which I can generate using the "boot" package:
>>
>> #Function to create the statistic to be boostrapped
>> boot.huber <- function(data, indices) {
>> data <- data[indices, ] #select obs. in bootstrap sample
>> mod <- lm(RT ~ Num*Gram, data=data)
>> coefficients(mod)       #return coefficient vector
>> }
>>
>> #Generate bootstrap estimate
>> data.boot <- boot(data, boot.huber, 1999)
>>
>> #Get confidence interval
>> boot.ci(data.boot, index=4, type=c("norm", "perc", "bca"),conf=0.95) #4 gets the CI for the interaction
>>
>> My problem is that I think the resamples should be generated without mixing the individual subjects observations: that is, to generate the new resamples, the observations from subject 1 (S1) should be shuffled within subject 1,
>
> What does that mean?
>
>> not mixing them with the observations from subjects 2, etc... I don't know how "boot" is doing the resampling (I read the documentation but don't understand how the function is doing it)
>
> It's doing it by selecting randomly entire rows. It is not "shuffling within rows" for selected subjects.
>>
>> Does anyone know how I could make sure that the resampling procedure used by "boot" respects the subject level information?
>
> It would be doing so because that is the way you set up the indexing. The column ordering tof the data within subjects is not permuted.
>
> I do think you are beyond your understanding of the statstical principles that you are attempting to use and would be safer to consult with a statsitician.
>
>
> --
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Andrew Robinson
Deputy Director, CEBRA
Senior Lecturer in Applied Statistics                      Tel: +61-3-8344-6410
Department of Mathematics and Statistics            Fax: +61-3-8344 4599
University of Melbourne, VIC 3010 Australia
Email: a.robinson at ms.unimelb.edu.au    Website: http://www.ms.unimelb.edu.au

FAwR: http://www.ms.unimelb.edu.au/~andrewpr/FAwR/
SPuR: http://www.ms.unimelb.edu.au/spuRs/


From jwiley.psych at gmail.com  Fri Jul  5 02:53:58 2013
From: jwiley.psych at gmail.com (Joshua Wiley)
Date: Thu, 4 Jul 2013 17:53:58 -0700
Subject: [R] bootstrapping respecting subject level information
In-Reply-To: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
References: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
Message-ID: <CANz9Z_LYmuYqLA+h5fQMn7nYaJy6vNR=1sidJ5viZcHLctCBAA@mail.gmail.com>

Hi,

It is not the easiest to follow code, but when I was working at UCLA,
I wrote a page demonstrating a multilevel bootstrap, where I use a two
stage sampler, (re)sampling at each level.  In your case, could be
first draw subjects, then draw observations within subjects.  A strata
only option does not resample all sources of variability, which are:

1) which subjects you get and
2) which observations within those

The page is here: http://www.ats.ucla.edu/stat/r/dae/melogit.htm

As a side note, it demonstrates a mixed effects model in R, although
as I mentioned it is not geared for beginners.

Cheers,

Josh



On Wed, Jul 3, 2013 at 7:19 PM, Sol Lago <solcita.lago at gmail.com> wrote:
> Hi there,
>
> This is the first time I use this forum, and I want to say from the start I am not a skilled programmer. So please let me know if the question or code were unclear!
>
> I am trying to bootstrap an interaction (that is my test statistic) using the package "boot". My problem is that for every resample, I would like the randomization to be done within subjects, so that observations from different subjects are not mixed. Here is the code to generate a dataframe similar to mine:
>
> Subject = rep(c("S1","S2","S3","S4"),4)
> Num     = rep(c("singular","plural"),8)
> Gram    = rep(c("gram","gram","ungram","ungram"),4)
> RT      = c(657,775,678,895,887,235,645,916,930,768,890,1016,590,978,450,920)
> data    = data.frame(Subject,Num,Gram,RT)
>
> This is the code I used to get the empirical interaction value:
>
> summary(lm(RT ~ Num*Gram, data=data))
>
> As you can see, the interaction between my two factors is -348. I want to get a bootstrap confidence interval for this statistic, which I can generate using the "boot" package:
>
> #Function to create the statistic to be boostrapped
> boot.huber <- function(data, indices) {
> data <- data[indices, ] #select obs. in bootstrap sample
> mod <- lm(RT ~ Num*Gram, data=data)
> coefficients(mod)       #return coefficient vector
> }
>
> #Generate bootstrap estimate
> data.boot <- boot(data, boot.huber, 1999)
>
> #Get confidence interval
> boot.ci(data.boot, index=4, type=c("norm", "perc", "bca"),conf=0.95) #4 gets the CI for the interaction
>
> My problem is that I think the resamples should be generated without mixing the individual subjects observations: that is, to generate the new resamples, the observations from subject 1 (S1) should be shuffled within subject 1, not mixing them with the observations from subjects 2, etc... I don't know how "boot" is doing the resampling (I read the documentation but don't understand how the function is doing it)
>
> Does anyone know how I could make sure that the resampling procedure used by "boot" respects the subject level information?
>
> Thanks a lot for your help/advice!
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Joshua Wiley
Ph.D. Student, Health Psychology
University of California, Los Angeles
http://joshuawiley.com/
Senior Analyst - Elkhart Group Ltd.
http://elkhartgroup.com


From A.Robinson at ms.unimelb.edu.au  Fri Jul  5 03:09:07 2013
From: A.Robinson at ms.unimelb.edu.au (Andrew Robinson)
Date: Fri, 5 Jul 2013 11:09:07 +1000
Subject: [R] bootstrapping respecting subject level information
In-Reply-To: <CANz9Z_LYmuYqLA+h5fQMn7nYaJy6vNR=1sidJ5viZcHLctCBAA@mail.gmail.com>
References: <AE20B15B-FBE8-4F4D-894F-5C649BD893AD@gmail.com>
	<CANz9Z_LYmuYqLA+h5fQMn7nYaJy6vNR=1sidJ5viZcHLctCBAA@mail.gmail.com>
Message-ID: <20130705010907.GU1640@ms.unimelb.edu.au>

Josh's comment prompted me to check mty go-to reference. Davison and
Hinckley (1997 Section 3.8) recommend sampling the Subjects, but not
within the Subjects.

Cheers

Andrew

On Thu, Jul 04, 2013 at 05:53:58PM -0700, Joshua Wiley wrote:
> Hi,
> 
> It is not the easiest to follow code, but when I was working at UCLA,
> I wrote a page demonstrating a multilevel bootstrap, where I use a two
> stage sampler, (re)sampling at each level.  In your case, could be
> first draw subjects, then draw observations within subjects.  A strata
> only option does not resample all sources of variability, which are:
> 
> 1) which subjects you get and
> 2) which observations within those
> 
> The page is here: http://www.ats.ucla.edu/stat/r/dae/melogit.htm
> 
> As a side note, it demonstrates a mixed effects model in R, although
> as I mentioned it is not geared for beginners.
> 
> Cheers,
> 
> Josh
> 
> 
> 
> On Wed, Jul 3, 2013 at 7:19 PM, Sol Lago <solcita.lago at gmail.com> wrote:
> > Hi there,
> >
> > This is the first time I use this forum, and I want to say from the start I am not a skilled programmer. So please let me know if the question or code were unclear!
> >
> > I am trying to bootstrap an interaction (that is my test statistic) using the package "boot". My problem is that for every resample, I would like the randomization to be done within subjects, so that observations from different subjects are not mixed. Here is the code to generate a dataframe similar to mine:
> >
> > Subject = rep(c("S1","S2","S3","S4"),4)
> > Num     = rep(c("singular","plural"),8)
> > Gram    = rep(c("gram","gram","ungram","ungram"),4)
> > RT      = c(657,775,678,895,887,235,645,916,930,768,890,1016,590,978,450,920)
> > data    = data.frame(Subject,Num,Gram,RT)
> >
> > This is the code I used to get the empirical interaction value:
> >
> > summary(lm(RT ~ Num*Gram, data=data))
> >
> > As you can see, the interaction between my two factors is -348. I want to get a bootstrap confidence interval for this statistic, which I can generate using the "boot" package:
> >
> > #Function to create the statistic to be boostrapped
> > boot.huber <- function(data, indices) {
> > data <- data[indices, ] #select obs. in bootstrap sample
> > mod <- lm(RT ~ Num*Gram, data=data)
> > coefficients(mod)       #return coefficient vector
> > }
> >
> > #Generate bootstrap estimate
> > data.boot <- boot(data, boot.huber, 1999)
> >
> > #Get confidence interval
> > boot.ci(data.boot, index=4, type=c("norm", "perc", "bca"),conf=0.95) #4 gets the CI for the interaction
> >
> > My problem is that I think the resamples should be generated without mixing the individual subjects observations: that is, to generate the new resamples, the observations from subject 1 (S1) should be shuffled within subject 1, not mixing them with the observations from subjects 2, etc... I don't know how "boot" is doing the resampling (I read the documentation but don't understand how the function is doing it)
> >
> > Does anyone know how I could make sure that the resampling procedure used by "boot" respects the subject level information?
> >
> > Thanks a lot for your help/advice!
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> -- 
> Joshua Wiley
> Ph.D. Student, Health Psychology
> University of California, Los Angeles
> http://joshuawiley.com/
> Senior Analyst - Elkhart Group Ltd.
> http://elkhartgroup.com
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Andrew Robinson  
Deputy Director, ACERA 
Department of Mathematics and Statistics            Tel: +61-3-8344-6410
University of Melbourne, VIC 3010 Australia               (prefer email)
http://www.ms.unimelb.edu.au/~andrewpr              Fax: +61-3-8344-4599
http://www.acera.unimelb.edu.au/

Methods of Statistical Model Estimation (CRC, 2013)
http://www.crcpress.com/product/isbn/9781439858028
Forest Analytics with R (Springer, 2011) 
http://www.ms.unimelb.edu.au/FAwR/
Introduction to Scientific Programming and Simulation using R (CRC, 2009): 
http://www.ms.unimelb.edu.au/spuRs/


From robbie.weterings at gmail.com  Fri Jul  5 03:30:39 2013
From: robbie.weterings at gmail.com (Robbie Weterings)
Date: Fri, 5 Jul 2013 08:30:39 +0700
Subject: [R] Non-linear modelling with several variables including a
 categorical variable
In-Reply-To: <51D59033.1040301@uottawa.ca>
References: <mailman.25.1372845609.8485.r-help@r-project.org>
	<51D42C78.50907@uottawa.ca>
	<CAFe5dHYpkPkEOfDePwxZth=9wvwQuRF1-gxzv8T6-Q2H9pjd9A@mail.gmail.com>
	<51D59033.1040301@uottawa.ca>
Message-ID: <CAFe5dHZdXFbFtwKmTE1_QPi1rqNGsd+=82TPrOYfs6mg6zmiCg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/b4c840bc/attachment.pl>

From fernando.marmolejoramos at adelaide.edu.au  Fri Jul  5 04:43:17 2013
From: fernando.marmolejoramos at adelaide.edu.au (Fernando Marmolejo Ramos)
Date: Fri, 5 Jul 2013 02:43:17 +0000
Subject: [R] g2 test...
Message-ID: <11127DAC1FAA054FA549DC326B89A640BCF42F9D@MAILMB02.ad.adelaide.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/2d6f5464/attachment.pl>

From eric.archer at noaa.gov  Fri Jul  5 05:14:30 2013
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Thu, 4 Jul 2013 20:14:30 -0700
Subject: [R] Substituting Greek symbols in some tick labels
Message-ID: <CAGrYeXgGy7NuSCtft8aDcCUp_KJ8+ihmvRBEA6+G5BDhTDU+4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/321dfcd6/attachment.pl>

From dwinsemius at comcast.net  Fri Jul  5 08:31:19 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 4 Jul 2013 23:31:19 -0700
Subject: [R] Substituting Greek symbols in some tick labels
In-Reply-To: <CAGrYeXgGy7NuSCtft8aDcCUp_KJ8+ihmvRBEA6+G5BDhTDU+4A@mail.gmail.com>
References: <CAGrYeXgGy7NuSCtft8aDcCUp_KJ8+ihmvRBEA6+G5BDhTDU+4A@mail.gmail.com>
Message-ID: <1FE05EC3-F67E-49E8-88FB-B9B9421920C1@comcast.net>


On Jul 4, 2013, at 8:14 PM, Eric Archer - NOAA Federal wrote:

> I have a character vector that I'm using to label ticks in a  
> dotchart. Some
> of the elements in the vector have an asterisk (*) where a Greek Delta
> needs to be placed when the plot is generated. Here's a simple  
> example:
>
> x <- 1:4
> x.lab <- c("a*a", "bbb", "c*c", "ddd")
> dotchart(x, labels = x.lab)
>
> The first and third labels should be 'a<Delta>a' and 'c<Delta>c'. I've
> tried things like,
>
> x.lab <- strsplit(x.lab, "[*]")
> x.lab <- lapply(x.lab, function(y) expression(paste(y, sep = Delta)))

The plotmath function paste has no sep argument.

Do you want to do this "by hand"? (Since you have not offered values  
of 'y'.)

x.lab <- expression( a*Delta*a, bbb, c*Delta*c, ddd)

#   Note use of "*" and no quotes in an expression vector.

  x <- 1:4
dotchart(x, labels = x.lab)

-- 
David.

>
> but because 'y' is unevaluated, the resulting list elements won't  
> work as
> tick labels. I've tried to modify it by using bquote and substitute,  
> but
> couldn't get anything closer. Any suggestions? Thanks!
>
> Cheers,
> eric
>
> -- 
>
> Eric Archer, Ph.D.
> Southwest Fisheries Science Center
> NMFS, NOAA
> 8901 La Jolla Shores Drive
> La Jolla, CA 92037 USA
> 858-546-7121 (work)
> 858-546-7003 (FAX)
>
> Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
>
> "The universe doesn't care what you believe.
> The wonderful thing about science is that it
>   doesn't ask for your faith, it just asks
>   for your eyes."  - Randall Munroe
>
> "Lighthouses are more helpful than churches."
>   - Benjamin Franklin
>
>   "...but I'll take a GPS over either one."
>       - John C. "Craig" George
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius, MD
Alameda, CA, USA


From eric.archer at noaa.gov  Fri Jul  5 08:39:15 2013
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Thu, 4 Jul 2013 23:39:15 -0700
Subject: [R] Substituting Greek symbols in some tick labels
In-Reply-To: <1FE05EC3-F67E-49E8-88FB-B9B9421920C1@comcast.net>
References: <CAGrYeXgGy7NuSCtft8aDcCUp_KJ8+ihmvRBEA6+G5BDhTDU+4A@mail.gmail.com>
	<1FE05EC3-F67E-49E8-88FB-B9B9421920C1@comcast.net>
Message-ID: <CAGrYeXiO4pNx4BQAS-s0DpDTSsBzenfwkjE74cPhYCzjK8Ev8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/0ecc5b7c/attachment.pl>

From bbolker at gmail.com  Fri Jul  5 08:49:51 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 5 Jul 2013 06:49:51 +0000
Subject: [R] g2 test...
References: <11127DAC1FAA054FA549DC326B89A640BCF42F9D@MAILMB02.ad.adelaide.edu.au>
Message-ID: <loom.20130705T084928-375@post.gmane.org>

Fernando Marmolejo Ramos <fernando.marmolejoramos <at> adelaide.edu.au> writes:

> 

 [snip]

> is it appropriate to use a Log likelihood ratio (G-test) test of
independence when dealing with repeated
> categorical responses (e.g. 2 by 2 table) instead of the McNemar test?

 [snip]

  Not an R question.  Try http://stats.stackexchange.com instead?


From pdalgd at gmail.com  Fri Jul  5 09:01:13 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 5 Jul 2013 09:01:13 +0200
Subject: [R] g2 test...
In-Reply-To: <loom.20130705T084928-375@post.gmane.org>
References: <11127DAC1FAA054FA549DC326B89A640BCF42F9D@MAILMB02.ad.adelaide.edu.au>
	<loom.20130705T084928-375@post.gmane.org>
Message-ID: <B080DB87-899B-4730-807C-609EC832B784@gmail.com>


On Jul 5, 2013, at 08:49 , Ben Bolker wrote:

> Fernando Marmolejo Ramos <fernando.marmolejoramos <at> adelaide.edu.au> writes:
> 
>> 
> 
> [snip]
> 
>> is it appropriate to use a Log likelihood ratio (G-test) test of
> independence when dealing with repeated
>> categorical responses (e.g. 2 by 2 table) instead of the McNemar test?
> 
> [snip]
> 
>  Not an R question.  Try http://stats.stackexchange.com instead?

It probably has a no-homework rule too, though....

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From cvo at delta.dk  Thu Jul  4 18:12:50 2013
From: cvo at delta.dk (cvo)
Date: Thu, 4 Jul 2013 09:12:50 -0700 (PDT)
Subject: [R] Error when building a custom package
Message-ID: <1372954370691-4670866.post@n4.nabble.com>

Hi

I'm have trouble building a custom package in R. Building the package on my
colleagues computer (who made the R code content) has been (and is still)
working fine for a long time, but I simply can't duplicate the setup right
somehow (even with his help)

I have installed the same versions of software as my colleague: Windows 7, R
2.13.1 (with the required additional packages), Rtools 2.13, Miktex 2.9. All
of which are included in the Windows PATH variable as instructed by him (and
in various online tutorials)

I only get an error message, when trying to build a binary file (or runnning
/R CMD check <package name>/), not the standard tar.gz. Here is what the
output looks like in the command prompt:
/  * installing *source* package 'slo' ...
  ** R
  ** inst
  ** preparing package for lazy loading
  Loading required package: car
  Warning: package 'car' was built under R version 2.13.2
  Loading required package: MASS
  Loading required package: nnet
  Loading required package: survival
  Loading required package: splines
  Creating a new generic function for "plot" in "slo"
  Error in file(file, "r", encoding = encoding) : 
    cannot open the connection
  ERROR: lazy loading failed for package 'slo'
  * removing 'C:/Users/CVO/workspace/slo.Rcheck/slo'/

These are the lines which follow, when my colleague run the build
successfully:
/Creating a new generic function for "plot" in "slo" in ".GlobalEnv"
** help
...
/
I have tried following a tutorial to see if the trouble was with building
packages in general, but that does not seem to be the case, as I could get
the same outputs as described in this tutorial:  
http://stevemosher.wordpress.com/ten-steps-to-building-an-r-package-under-windows/
<http://stevemosher.wordpress.com/ten-steps-to-building-an-r-package-under-windows/>  
(which builds a simple package using the skeleton package).

I have gotten the impression that generally the error with the  "Error in
file..." is a problem with a wrong path or problems with permissions, but am
unable to find a solution. I'm running the commands in the Command prompt
with Administrator rights and have Admin right on the computer.

Any suggestions on how I can solve this issue or simply get more detailed
information about the error will be greatly appreciated.

Thanks,
Christer V., DK



--
View this message in context: http://r.789695.n4.nabble.com/Error-when-building-a-custom-package-tp4670866.html
Sent from the R help mailing list archive at Nabble.com.


From jeffrey.stratford at wilkes.edu  Thu Jul  4 21:00:51 2013
From: jeffrey.stratford at wilkes.edu (Stratford, Jeffrey)
Date: Thu, 4 Jul 2013 15:00:51 -0400
Subject: [R] coding variables which are independent or grouped
Message-ID: <CAP5kizRTjBShcNEgKAFfHcwH1cjW1jM=-Vf5LJEi-SpqR+1R0Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/c43bd785/attachment.pl>

From rodriguez.victor at inifap.gob.mx  Thu Jul  4 23:08:57 2013
From: rodriguez.victor at inifap.gob.mx (RODRIGUEZ MORENO VICTOR MANUEL)
Date: Thu, 4 Jul 2013 16:08:57 -0500
Subject: [R] problem on reading many files
Message-ID: <F142DC4E-EC35-4B7F-BCAB-F05248FDD6A4@mimectl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130704/008a2757/attachment.pl>

From smartpink111 at yahoo.com  Fri Jul  5 02:46:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 4 Jul 2013 17:46:08 -0700 (PDT)
Subject: [R] Subsetting multiple rows of a data frame at once
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C317763@PA-MBX01.na.tibco.com>
References: <25563192.156234.1372907812821.JavaMail.nabble@joe.nabble.com>
	<BAY167-W646E5535CADE996C808532837C0@phx.gbl>
	<1372914879.51445.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<E66794E69CFDE04D9A70842786030B931C317763@PA-MBX01.na.tibco.com>
Message-ID: <1372985168.13798.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Anika,
?merge() is a better solution.

To get the row.names intact, you could do:
carbon.fit<- within(carbon.fit,{x<-round(x,10);y<- round(y,10)}) #Using Bill's solution

dat1<- data.frame(x=round(xt,10),y=round(yt,10))
carbon.fit1<- data.frame(carbon.fit,rNames=row.names(carbon.fit),stringsAsFactors=FALSE) #changed here
?res1<-merge(dat1,carbon.fit1,by=c("x","y"))
?row.names(res1)<- res1[,3]
?res1<- res1[,-3]
A.K.



----- Original Message -----
From: William Dunlap <wdunlap at tibco.com>
To: arun <smartpink111 at yahoo.com>; Shaun ? Anika <pro_patto at hotmail.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, July 4, 2013 8:02 PM
Subject: RE: [R] Subsetting multiple rows of a data frame at once

> xt<- c(1.05, 2.85, 3.40, 4.25, 0.25, 3.05, 3.70, 0.20, 0.30, 0.70, 1.05, 1.20, 1.40, 1.90,
> 2.70, 3.25, 3.55, 4.60, 2.05, 2.15, 3.70, 4.85, 4.90, 1.60, 2.45, 3.20, 3.90, 4.45)
> 
> yt<- c(0.25, 0.10, 0.90, 0.25, 1.05, 1.70, 2.05, 2.90, 2.35, 2.60, 2.55, 2.15, 2.75, 2.05,
> 2.70, 2.25, 2.55, 2.05, 3.65, 3.05, 3.00, 3.50, 3.75, 4.85, 4.50, 4.50, 3.35, 4.90)
> carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
> trees<-do.call(rbind,lapply(seq_along(xt),function(i) subset(carbon.fit,x==xt[i]&y==yt[i])))
> 
> ## xt is 28 integers long and when i run the above code it only returns the values of 18
> out of the 28 (xt,yt) pairs that i want.

You are running into the problem that two different computational methods that give
the same result when applied to real numbers often give different results when applied
to 64-bit floating point numbers.? (In your case you expect seq(0,5,.01) to contain, e.g.,
the floating point number generate by parsing the string "3.05".)?  Hence x==y is not true
when you expect it to be.? Here is where your 18 came from:
?  R> table(xt %in% carbon.fit$x, yt %in% carbon.fit$y)
? ? ? ? ? 
? ? ? ? ?  FALSE TRUE
? ?  FALSE? ?  1? ? 6
? ?  TRUE? ? ? 3?  18
Round your number to the nearest 10^-10 and you get
? > table(round(xt,10) %in% round(carbon.fit$x,10), round(yt,10) %in% round(carbon.fit$y,10))
? ? ? ? 
? ? ? ?  TRUE
? ? TRUE?  28

By the way, you may prefer using the merge() function rather than the do.call(rbind,lapply(...)))
business.? I think the following call to merge will do about what you want (the row names differ -
if they are important it is possible to get them with some minor trickery):
? ? merge(data.frame(x=xt,y=yt), carbon.fit)
(You still want to round your numbers as before.)

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Wednesday, July 03, 2013 10:15 PM
> To: Shaun ? Anika
> Cc: R help
> Subject: Re: [R] Subsetting multiple rows of a data frame at once
> 
> Hi,
> 
> carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
> ?dim(carbon.fit)
> #[1] 251001????? 2
> 
> 
> ?xtNew<-sprintf("%.2f",xt)
> ?ytNew<- sprintf("%.2f",yt)
> ?carbon.fit[]<- lapply(carbon.fit,function(x) sprintf("%.2f",x))
> res<-do.call(rbind,lapply(seq_along(xtNew),function(i)
> subset(carbon.fit,x==xtNew[i]&y==ytNew[i])))
> ?nrow(res)
> #[1] 28
> res
> #????????? x??? y
> #12631? 1.05 0.25
> #5296?? 2.85 0.10
> #45431? 3.40 0.90
> #12951? 4.25 0.25
> #52631? 0.25 1.05
> #85476? 3.05 1.70
> #103076 3.70 2.05
> #145311 0.20 2.90
> #117766 0.30 2.35
> #130331 0.70 2.60
> #127861 1.05 2.55
> #107836 1.20 2.15
> #137916 1.40 2.75
> #102896 1.90 2.05
> #135541 2.70 2.70
> #113051 3.25 2.25
> #128111 3.55 2.55
> #103166 4.60 2.05
> #183071 2.05 3.65
> #153021 2.15 3.05
> #150671 3.70 3.00
> #175836 4.85 3.50
> #188366 4.90 3.75
> #243146 1.60 4.85
> #225696 2.45 4.50
> #225771 3.20 4.50
> #168226 3.90 3.35
> #245936 4.45 4.90
> A.K.
> 
> 
> ________________________________
> From: Shaun ? Anika <pro_patto at hotmail.com>
> To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com>
> Sent: Thursday, July 4, 2013 12:08 AM
> Subject: RE: Subsetting multiple rows of a data frame at once
> 
> 
> 
> 
> Hi There,
> i can give you the data needed to perform this task...
> 
> library(akima)
> library(fields)
> 
> xt<- c(1.05, 2.85, 3.40, 4.25, 0.25, 3.05, 3.70, 0.20, 0.30, 0.70, 1.05, 1.20, 1.40, 1.90,
> 2.70, 3.25, 3.55, 4.60, 2.05, 2.15,?3.70, 4.85, 4.90, 1.60, 2.45, 3.20, 3.90, 4.45)
> 
> yt<- c(0.25, 0.10, 0.90, 0.25, 1.05, 1.70, 2.05, 2.90, 2.35, 2.60, 2.55, 2.15, 2.75, 2.05,
> 2.70, 2.25, 2.55, 2.05, 3.65, 3.05,?3.00, 3.50, 3.75, 4.85, 4.50, 4.50, 3.35, 4.90)
> 
> xs<- c(0.45, 1.05, 2.75, 3.30, 4.95, 0.40, 1.05, 2.30, 3.45, 4.60, 0.05, 1.95, 2.95, 3.70,
> 4.55, 0.75, 1.60, 2.10, 3.60, 4.90,?0.05, 1.35, 2.60, 3.40, 4.25)
> 
> ys<- c(0.45, 0.95, 0.75, 0.95, 0.10, 1.90, 1.45, 1.25, 1.45, 1.05, 2.85, 2.60, 2.05, 2.60,
> 2.55, 3.75, 3.30, 3.95, 3.45, 3.70,?4.95, 4.35, 4.55, 4.40, 4.95)
> 
> carbon<- c(1.43, 1.82, 1.40, 1.43, 1.96, 1.61, 1.91, 1.53, 1.17, 1.83, 2.43, 2.02, 1.66,
> 2.45, 2.46, 1.39, 1.10, 1.38, 1.91, 2.13,?1.88, 1.26, 2.15, 1.89, 1.69)
> 
> carbon.df=data.frame(x=xs,y=ys,z=carbon)
> carbon.loess= loess(z~x*y, data= carbon.df, degree= 2)
> carbon.fit = expand.grid(list(x=seq(0, 5, 0.01), y=seq(0, 5, 0.01)))
> z=predict(carbon.loess, newdata= carbon.fit)
> carbon.fit$Height=as.numeric(z)
> image.plot(seq(0,5,0.01,), seq(0,5,0.01), z, xlab = "", ylab="",main = "Carbon")
> 
> trees<-do.call(rbind,lapply(seq_along(xt),function(i) subset(carbon.fit,x==xt[i]&y==yt[i])))
> 
> ## xt is 28 integers long and when i run the above code it only returns the values of 18
> out of the 28 (xt,yt) pairs that i want.
> 
> thanks for your help!!
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From cxg040 at email.uark.edu  Fri Jul  5 08:22:14 2013
From: cxg040 at email.uark.edu (Chirag Gupta)
Date: Fri, 5 Jul 2013 01:22:14 -0500
Subject: [R] Subscript out of bound error
Message-ID: <CADESCNx4qfs4qFo5AS1hb1k-5zfeR1PbWpgK9-UmruQREFaNxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/ccf72f06/attachment.pl>

From kridox at ymail.com  Fri Jul  5 10:04:19 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 5 Jul 2013 17:04:19 +0900
Subject: [R] problem on reading many files
In-Reply-To: <F142DC4E-EC35-4B7F-BCAB-F05248FDD6A4@mimectl>
References: <F142DC4E-EC35-4B7F-BCAB-F05248FDD6A4@mimectl>
Message-ID: <CAAcyNCw6fM6knNQKx=1169mZhmEG4m3UXRYqn+SWi2hfiYhhTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/03dd35e4/attachment.pl>

From bhh at xs4all.nl  Fri Jul  5 10:44:28 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 5 Jul 2013 10:44:28 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <CAGR4ry6WWWMjqyVf5m9jMh8tiSQ7J8dtNvcP5+vTeJK9BymJSA@mail.gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<CAGR4ry4+H4pOx2vE=asJrOtZH=exsD1sWrT=VMib0yHdRREJjw@mail.gmail.com>
	<CAGR4ry6WWWMjqyVf5m9jMh8tiSQ7J8dtNvcP5+vTeJK9BymJSA@mail.gmail.com>
Message-ID: <1F09F328-6DD5-4224-B194-B6AB21A008A2@xs4all.nl>


On 05-07-2013, at 09:53, Jannetta Steyn <jannetta at henning.org> wrote:

> 
> 
> >
> > I don't quite know how to explain the "doesn't work" in more detail without
> > any visual aid.
> 
> You said that R got into an indefinite loop, whatever that maybe.
> 
> 
> > When I change the solver to ode45 the script never stops running. I have even left it over night at one stage but the next day it was still busy. Is there a way to see what it is doing and to determine why it seems to be in an 
> > "infinite loop"?
> 
> The script just ran using ode45!! For the first time ever.
> 

Please keep the conversation on R-help.
Don't reply to me personally.

Which script?
With the corrections suggested by me and Peter? (gK_axon_AB=52.5-3 ==> gK_axon_AB=52.5e-3)

For what it's worth: lsdoda seems quicker.
Variable v_acon_AB now converges to -60 (the equilibrium state?)

Berend


From p.mulongeni at namibia.pharmaccess.org  Fri Jul  5 11:28:44 2013
From: p.mulongeni at namibia.pharmaccess.org (Pancho Mulongeni)
Date: Fri, 5 Jul 2013 09:28:44 +0000
Subject: [R] Unique in discerning missing values NA
Message-ID: <9EA364B2FAFC264A86CED5A4404A19DB4EDE56F0@AMXPRD0310MB366.eurprd03.prod.outlook.com>

Hi,
I am trying to remove duplicate Patient numbers in a clinical record, I used unique
menPatients[1:40,1]
 [1] abr1160(C)/001 ABR1363(A)/001 ABR1363(A)/001 ABR1363(A)/001 abr1772(B)/001
 [6] AFR0003/001    AFR0003/001    afr0290(C)/001 afr1861(B)/001 Aga0007/001   
[11] AGA1548(A)/001 AGA1548(A)/001 AGA1548(A)/001 AGU1680(A)/001 AGU1680(A)/001
[16] AIS0492/001    AIS0492/001    AKO4268(C)/001 AKO4268(C)/001 AKT0042(B)/001
[21] AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001
[26] AKT0042(B)/001 alb4423(C)/001 ALF1651(A)/001 alf1722(B)/001 ALF1735(A)/001
[31] ALF1735(A)/001 ALP4321(C)/001 <NA>           <NA>           ALU4262(B)/001
[36] ALV4286(C)/001 ALW2579(C)/001 <NA>           ALW4330(B)/001 AMA0011/001   
3886 Levels: 0750/002 0751/001 0984/002 ABE2560(C)/001 ... zul1737(B)/001

testData<-menPatients[1:40,1]

I then used unique, please note the NA at position 32 in testData
testUnique<-unique(testData)
testUnique
 [1] abr1160(C)/001 ABR1363(A)/001 abr1772(B)/001 AFR0003/001    afr0290(C)/001
 [6] afr1861(B)/001 Aga0007/001    AGA1548(A)/001 AGU1680(A)/001 AIS0492/001   
[11] AKO4268(C)/001 AKT0042(B)/001 alb4423(C)/001 ALF1651(A)/001 alf1722(B)/001
[16] ALF1735(A)/001 ALP4321(C)/001 <NA>           ALU4262(B)/001 ALV4286(C)/001
[21] ALW2579(C)/001 ALW4330(B)/001 AMA0011/001   

The missing value NA originally at position 32 in testdata is still there, it is in position 18. Why is this? How can I prevent this?
I tried using incomprables=c(NA), but this did not work.

Thanks


Pancho Mulongeni
Research Assistant
PharmAccess Foundation
1 Fouch? Street
Windhoek West
Windhoek
Namibia
?
Tel:?? +264 61 419 000
Fax:? +264 61 419 001/2
Mob: +264 81 4456 286


From jholtman at gmail.com  Fri Jul  5 11:57:47 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Fri, 5 Jul 2013 05:57:47 -0400
Subject: [R] Subscript out of bound error
In-Reply-To: <CADESCNx4qfs4qFo5AS1hb1k-5zfeR1PbWpgK9-UmruQREFaNxg@mail.gmail.com>
References: <CADESCNx4qfs4qFo5AS1hb1k-5zfeR1PbWpgK9-UmruQREFaNxg@mail.gmail.com>
Message-ID: <34CC53F8-45EC-4DB6-9CBE-21E32AAA6AB9@gmail.com>

use 'match' to convert the names to column indices and then use that for indexing

indx <- match(subCols, names(yourMatrix)
mySubset <- yourMatrix[, indx]

Sent from my iPad

On Jul 5, 2013, at 2:22, Chirag Gupta <cxg040 at email.uark.edu> wrote:

> Hi All
> 
> I have a huge matrix m (10276 X 10276) dimension with same column name and
> row names. (its a gene correlation matrix). I have another text file which
> has 2700 names, basically locus ID of genes, which are also
> rownames/colnames in m. Now I want to select all those columns from m whose
> names match with the names in the text file and return ONLY those columns
> and ALL the rows in a matrix format.
> That is, the output should a matrix of dimension 10276 X 2700.
> 
> I have played around with subset and also tried all different methods like
> reading the text file, converting to matrix and character and DF and tried
> all possible ways I found on the web. The problem is that some of them work
> on a smaller simulated dataset but says "Subscript out of bounds"  when I
> try on the bigger matrix(m).
> 
> Please help.. :(
> 
> Thanks!
> 
> 
> 
> -- 
> *Chirag Gupta*
> Department of Crop, Soil, and Environmental Sciences,
> 115 Plant Sciences Building, Fayetteville, Arkansas 72701
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From david at revolutionanalytics.com  Fri Jul  5 12:03:33 2013
From: david at revolutionanalytics.com (David Smith)
Date: Fri, 5 Jul 2013 03:03:33 -0700
Subject: [R] Revolutions blog: June roundup
Message-ID: <CABgvEC___vDuj--EcBrJ7hopzzaDA+L9A9EvigSfDJqTExvMag@mail.gmail.com>

Revolution Analytics staff write about R every weekday at the Revolutions blog:
 http://blog.revolutionanalytics.com
and every month I post a summary of articles from the previous month
of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of June:

You can create a Word document from a template and an R script with
the R2DOCX package: http://bit.ly/17XigAJ

Joe Rickert reviews books and other resources for learning about time
series analysis in R: http://bit.ly/17Xiisn

Timely Portfolio covers 15 years of history of time series plotting
with R: http://bit.ly/17Xiisp

An online beer recommendation application serves as an in-depth
example of building a recommendation system with R:
http://bit.ly/17XigAK

Software company SAP says that "skills around the open source R
programming language and advanced analytics are rapidly shifting from
'niche' to 'standard' requirements": http://bit.ly/17Xiiso

A primer on maximum likelihood estimation in R with the bbmle package:
http://bit.ly/17XigAI

American Century Investments describe how they created their own R
package to optimize investments and model supplier relationships in a
video presentation: http://bit.ly/17Xiisq

How to draw attractive decision trees using the rpart.plot package:
http://bit.ly/17Xiisr

What is a data scientist, what skills should they have, and how is the
practice evolving? My take: http://bit.ly/17XigAL

Computerworld's 6-part beginner's guide to R: http://bit.ly/17XigAM

RStudio has made CRAN download statistics available, enabling a
ranking of the top R packages by downloads: http://bit.ly/17XigAN

Big Data and statistical modeling is changing video games: helping to
identify bottlenecks for new players, detect fraud, and maximize
in-app purchases. Details in this webinar replay:
http://bit.ly/17Xiiss

A mini-tutorial on using the Quandl package to import public financial
data sets into R: http://bit.ly/17Xiist

Dirk Eddelbuettel's book, Seamless R and C++ Integration with Rcpp, is
now available: http://bit.ly/17XigAO

An interactive application based on R and Shiny maps dialect
differences across the USA: http://bit.ly/17XigAP

Generating parallel random number streams with the RevoScaleR package:
http://bit.ly/17Xiisu

R again shows strong growth in the annual KDNuggets software poll:
http://bit.ly/17XigAQ

Some very useful guidelines for setting up a reproducible R project:
http://bit.ly/17Xiisv

Some non-R stories in the past month included: A new Hadoop appliance
from Teradata (http://bit.ly/17XigAT), a new Big Data Innovation
Center in Singapore (http://bit.ly/17XigAU), a drum/keyboard Billie
Jean cover (http://bit.ly/17XigAW), women in movies
(http://bit.ly/17XigAV), a Daft Punk / Soul Train mashup
(http://bit.ly/17Xiisw), and It Gets Better at NASA
(http://bit.ly/17Xiisx).

Meeting times for local R user groups
(http://blog.revolutionanalytics.com/local-r-groups.html) can be found
on the updated R Community Calendar at:
http://blog.revolutionanalytics.com/calendar.html

If you're looking for more articles about R, you can find summaries
from previous months at http://blog.revolutionanalytics.com/roundups/.
Join the Revolution mailing list at
http://revolutionanalytics.com/newsletter to be alerted to new
articles on a monthly basis.

As always, thanks for the comments and please keep sending suggestions
to me at david at revolutionanalytics.com . Don't forget you can also
follow the blog using an RSS reader, or by following me on Twitter
(I'm @revodavid).

Cheers,
# David

--
David M Smith <david at revolutionanalytics.com>
VP of Marketing, Revolution Analytics  http://blog.revolutionanalytics.com
Tel: +1 (650) 646-9523 (Seattle WA, USA)
Twitter: @revodavid
We're hiring! www.revolutionanalytics.com/careers


From m.w.heerdink at uva.nl  Fri Jul  5 12:15:55 2013
From: m.w.heerdink at uva.nl (Marc Heerdink)
Date: Fri, 05 Jul 2013 12:15:55 +0200
Subject: [R] Meta-analysis on a repeated measures design with multiple
 trials per subject using metafor
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730D833E9764@UM-MAIL4112.unimaas.nl>
References: <51D415D6.5070201@uva.nl>
	<077E31A57DA26E46AB0D493C9966AC730D833E9764@UM-MAIL4112.unimaas.nl>
Message-ID: <51D69CDB.8010506@uva.nl>

Dear Wolfgang and other readers of the r-help list,

Thank you very much for your suggestion. Unfortunately, the data that I 
have can not be described with a table such as the one you have made, 
because there's no identical trial under both treatment 1 and treatment 
2. To explain, let me explain a bit more about the experiments:

* All subjects were presented with the same number of trials
* Half of these trials were preceded by a prime from category 1 
(treatment 1) and half of these trials with a prime from category 2 
(treatment 2)
* Subjects were asked to respond to these trials (a unique stimulus for 
each trial) by pressing one of two keys on the keyboard.

Because everything was randomized, I can only calculate the total number 
of times a certain response was used under each type of trial. There is 
no pairing of trials under two treatments, so I am forced to use the 
marginal totals from your table.

I have uploaded a simplified version of the data for one experiment to 
illustrate this (the actual experiments have five treatments and some 
have moderators):
https://www.dropbox.com/s/rhgo12cm1asl6x8/exampledata.csv

This is the script that I used to generate the data:
https://www.dropbox.com/s/7uyeaexhnqiiy55/exampledata.R

The problem thus appears to lie mainly in estimating the variance of the 
proportion difference from only the marginal totals, is that correct? Is 
there a way to calculate it from only the marginal totals?

One alternative that I have tried over the last few days, is to use the 
b parameter of interest and it's corresponding standard error from the 
lme4 regression output that I use to analyse the individual experiments. 
Then, I use rma(yi, sei) to do a meta-analysis on these parameters. I am 
not sure this is correct though, since it takes into account 
between-subjects variance (through a random effect for subject), and it 
is sensitive to the covariates/moderators I include in the models that I 
get the b parameters from.

Thanks again for your help, and for any suggestions for solving this 
problem!

Regards,
Marc


On 07/04/2013 11:21 PM, Viechtbauer Wolfgang (STAT) wrote:
> Dear Marc,
>
> Let me see if I understand the type of data you have. You say that you have 5 experiments. And within each experiment, you have n subjects and for each subject, you have data in the form described in your post. Now for each subject, you want to calculate some kind of measure that quantifies how much more likely it was that subjects gave/chose response 2 under treatment 2 versus treatment 1. So, you would have n such values. And then you want to pool those values over the n subjects within a particular experiment and then ultimately over the 5 experiments. Is that correct so far?
>
> Assuming I got this right, let me ask you about those data that you have for each subject. In particular, are these paired data? In other words, is there are 1:1 relationship between the 30 trials under treatment 1 versus treatment 2? Or phrased yet another way, can you construct a table like this for every subject:
>
>                  trt 2
>               ------------
>               resp1 resp2
> trt 1 resp1  a     b      10
>        resp2  c     d      20
>               20    10     30
>
> Note that I added the marginal counts based on your example data, but this is not sufficient to reconstruct how often response 1 was chosen for the same trial under both treatment 1 and treatment 2 (cell "a"). And so on for the other 3 cells.
>
> If all of this applies, then essentially you are dealing with dependent proportions and you can calculate the difference y = (20/30)-(10/30) as you have done. The corresponding sampling variance can be estimated with v = var(y) = (a+b)*(c+d)/t^3 + (a+c)*(b+d)/t^3 - 2*(a*d/t^3 - b*c/t^3) (where t is the number of trials, i.e., 30 in the example above). See, for example, section 10.1.1. in Agresti (2002) (Categorical data analysis, 2nd ed.).
>
> So, ultimately, you will have n values of y and v for a particular experiment and then the same thing for all 5 experiments. You can then pool those values with rma(yi, vi) in metafor (yi and vi being the vectors of the y and v values). You probably want to add a factor to the model that indicates which experiment those values came from. So, something like: rma(yi, vi, mods = ~ factor(experiment)).
>
> Well, I hope that I understood your data correctly.
>
> Best,
> Wolfgang
>
> --
> Wolfgang Viechtbauer, Ph.D., Statistician
> Department of Psychiatry and Psychology
> School for Mental Health and Neuroscience
> Faculty of Health, Medicine, and Life Sciences
> Maastricht University, P.O. Box 616 (VIJV1)
> 6200 MD Maastricht, The Netherlands
> +31 (43) 388-4170 | http://www.wvbauer.com
> ________________________________________
> From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] On Behalf Of Marc Heerdink [m.w.heerdink at uva.nl]
> Sent: Wednesday, July 03, 2013 2:15 PM
> To: r-help at r-project.org
> Subject: [R] Meta-analysis on a repeated measures design with multiple trials per subject using metafor
>
> Hi all,
>
> I am currently attempting to compile a summary of a series of five
> psychological experiments, and I am trying to do this using the metafor
> package. However, I am quite unsure which of the scenarios described in
> the metafor help pages applies to these data, because it is a repeated
> measures design, with multiple trials in each condition.
>
> Assume that for every participant, I have a basic contingency table such
> as this one:
>
>                  treatment
>                  1       2
> response
> 1               10      20
> 2               20      10
>
> (if this ASCII version does not work, I have 30 trials in each
> treatment, and participants give either response 1 or 2; the exact
> numbers don't matter)
>
> The problem that I am trying to solve is how to convert these numbers to
> an effect size estimate that I can use with metafor.
>
> As far as I understand it, I can only use it to get an effect size for
> outcomes that are dichotomous; i.e., either 1 or 0 for any subject.
> However, I have proportion data for every participant.
>
> I have considered and tried these strategies:
>
> 1. Base the effect size on within-participant proportion differences.
> That is, in the table above, the treatment effect would be
> (20/30)-(10/30) = 1/3; and I would take the M and SD of these values to
> estimate a study-level effect ("MN" measure in metafor).
>
> 2. Use the overall treatment * response contingency table, ignoring the
> fact that these counts come from different participants ("PHI" or "OR"
> measures in metafor). In a study with 10 participants, I would get cell
> counts around 150.
>
> However, from the research I've done into this topic, I know that 1) is
> not applicable to (as far as I understand) an odds ratio, and I suspect
> 2) overestimates the effect.
>
> A third method would be to use the regression coefficients, that I can
> easily obtain since I have all the raw data that I need. However, it is
> unclear to me whether and if yes, how I can use these in the metafor
> package.
>
>   From my understanding of another message about this topic I found on
> this list (1), I understand that having access to the raw data is an
> advantage, but I am not sure whether the scenario mentioned applies to
> my situation.
>
> 1:
> http://r.789695.n4.nabble.com/meta-analysis-with-repeated-measure-designs-td2252644.html
>
> I would very much appreciate any suggestions or hints on this topic.
>
> Regards,
> Marc
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Marc Heerdink, MSc. (PhD. candidate)
Dept. of Social Psychology
University of Amsterdam
http://home.medewerker.uva.nl/m.w.heerdink/
http://www.easi-lab.nl/


From fsantos at ujaen.es  Fri Jul  5 10:08:06 2013
From: fsantos at ujaen.es (fsantos at ujaen.es)
Date: Fri, 5 Jul 2013 10:08:06 +0200 (CEST)
Subject: [R] To approach time series using a data set
Message-ID: <43dc61a86cc2b52f0e17053213b4c0fc.squirrel@webmail.ujaen.es>

Dear R community,

I have to approach a time serie as a linear combination of many time
series in a dataset. Of course, I would like that this linear combination
is optimal (I would like to use the minimal number of times series)
although I can loose some information.  Moreover, each variable of the
dataset has associated a "cost" which range from 0 to 9. I also would like
to find this optimal combination and to make minimal de sum of this
"cost". Could you give to me some suggestions? Do your know some
interesting reference for starting?

Thanks in advance


From kridox at ymail.com  Fri Jul  5 12:36:57 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 5 Jul 2013 19:36:57 +0900
Subject: [R] Unique in discerning missing values NA
In-Reply-To: <9EA364B2FAFC264A86CED5A4404A19DB4EDE56F0@AMXPRD0310MB366.eurprd03.prod.outlook.com>
References: <9EA364B2FAFC264A86CED5A4404A19DB4EDE56F0@AMXPRD0310MB366.eurprd03.prod.outlook.com>
Message-ID: <CAAcyNCzM88yishU3nOQEAKguoa417L3YyB3vQFkcorT+A89AfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/b8f918ce/attachment.pl>

From humber.andrade at gmail.com  Fri Jul  5 12:38:24 2013
From: humber.andrade at gmail.com (Humber Andrade)
Date: Fri, 5 Jul 2013 07:38:24 -0300
Subject: [R] kruskal.test followed by kruskalmc
Message-ID: <CANwQX80GaMpY+qYFU9dVEY3ihMrisDm7SjxPX57arn0jcodANA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/844a6234/attachment.pl>

From ruipbarradas at sapo.pt  Fri Jul  5 12:38:46 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 05 Jul 2013 11:38:46 +0100
Subject: [R] Unique in discerning missing values NA
In-Reply-To: <9EA364B2FAFC264A86CED5A4404A19DB4EDE56F0@AMXPRD0310MB366.eurprd03.prod.outlook.com>
References: <9EA364B2FAFC264A86CED5A4404A19DB4EDE56F0@AMXPRD0310MB366.eurprd03.prod.outlook.com>
Message-ID: <51D6A236.70603@sapo.pt>

Hello,

Your data example is difficult to read into an R session. Next time, 
post the output of ?dput. Like this:

dput(menPatients[1:40, 1])  # post the output of this


The help page for unique says that "Missing values are regarded as 
equal"  so you should expect one NA to still be present in the final result.
If you want to remove NAs, use ?is.na. With fake data,

x1 <- c(1:3, NA, 4, NA, 2:9)
x2 <- unique(x1)
x3 <- x2[!is.na(x2)]
x3


Hope this helps,

Rui Barradas


Em 05-07-2013 10:28, Pancho Mulongeni escreveu:
> Hi,
> I am trying to remove duplicate Patient numbers in a clinical record, I used unique
> menPatients[1:40,1]
>   [1] abr1160(C)/001 ABR1363(A)/001 ABR1363(A)/001 ABR1363(A)/001 abr1772(B)/001
>   [6] AFR0003/001    AFR0003/001    afr0290(C)/001 afr1861(B)/001 Aga0007/001
> [11] AGA1548(A)/001 AGA1548(A)/001 AGA1548(A)/001 AGU1680(A)/001 AGU1680(A)/001
> [16] AIS0492/001    AIS0492/001    AKO4268(C)/001 AKO4268(C)/001 AKT0042(B)/001
> [21] AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001
> [26] AKT0042(B)/001 alb4423(C)/001 ALF1651(A)/001 alf1722(B)/001 ALF1735(A)/001
> [31] ALF1735(A)/001 ALP4321(C)/001 <NA>           <NA>           ALU4262(B)/001
> [36] ALV4286(C)/001 ALW2579(C)/001 <NA>           ALW4330(B)/001 AMA0011/001
> 3886 Levels: 0750/002 0751/001 0984/002 ABE2560(C)/001 ... zul1737(B)/001
>
> testData<-menPatients[1:40,1]
>
> I then used unique, please note the NA at position 32 in testData
> testUnique<-unique(testData)
> testUnique
>   [1] abr1160(C)/001 ABR1363(A)/001 abr1772(B)/001 AFR0003/001    afr0290(C)/001
>   [6] afr1861(B)/001 Aga0007/001    AGA1548(A)/001 AGU1680(A)/001 AIS0492/001
> [11] AKO4268(C)/001 AKT0042(B)/001 alb4423(C)/001 ALF1651(A)/001 alf1722(B)/001
> [16] ALF1735(A)/001 ALP4321(C)/001 <NA>           ALU4262(B)/001 ALV4286(C)/001
> [21] ALW2579(C)/001 ALW4330(B)/001 AMA0011/001
>
> The missing value NA originally at position 32 in testdata is still there, it is in position 18. Why is this? How can I prevent this?
> I tried using incomprables=c(NA), but this did not work.
>
> Thanks
>
>
> Pancho Mulongeni
> Research Assistant
> PharmAccess Foundation
> 1 Fouch? Street
> Windhoek West
> Windhoek
> Namibia
>
> Tel:   +264 61 419 000
> Fax:  +264 61 419 001/2
> Mob: +264 81 4456 286
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p.mulongeni at namibia.pharmaccess.org  Fri Jul  5 12:40:34 2013
From: p.mulongeni at namibia.pharmaccess.org (Pancho Mulongeni)
Date: Fri, 5 Jul 2013 10:40:34 +0000
Subject: [R] Unique in discerning missing values NA
In-Reply-To: <51D6A236.70603@sapo.pt>
References: <9EA364B2FAFC264A86CED5A4404A19DB4EDE56F0@AMXPRD0310MB366.eurprd03.prod.outlook.com>
	<51D6A236.70603@sapo.pt>
Message-ID: <9EA364B2FAFC264A86CED5A4404A19DB4EDE571D@AMXPRD0310MB366.eurprd03.prod.outlook.com>

Yes thanks, this is what I ended up doing, but I though there would be a 'internal' way to disregard NAs in unique.
Thanks for the tip on dput

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: 05 July 2013 11:39
To: Pancho Mulongeni
Cc: r-help at r-project.org
Subject: Re: [R] Unique in discerning missing values NA

Hello,

Your data example is difficult to read into an R session. Next time, post the output of ?dput. Like this:

dput(menPatients[1:40, 1])  # post the output of this


The help page for unique says that "Missing values are regarded as equal"  so you should expect one NA to still be present in the final result.
If you want to remove NAs, use ?is.na. With fake data,

x1 <- c(1:3, NA, 4, NA, 2:9)
x2 <- unique(x1)
x3 <- x2[!is.na(x2)]
x3


Hope this helps,

Rui Barradas


Em 05-07-2013 10:28, Pancho Mulongeni escreveu:
> Hi,
> I am trying to remove duplicate Patient numbers in a clinical record, 
> I used unique menPatients[1:40,1]
>   [1] abr1160(C)/001 ABR1363(A)/001 ABR1363(A)/001 ABR1363(A)/001 abr1772(B)/001
>   [6] AFR0003/001    AFR0003/001    afr0290(C)/001 afr1861(B)/001 Aga0007/001
> [11] AGA1548(A)/001 AGA1548(A)/001 AGA1548(A)/001 AGU1680(A)/001 AGU1680(A)/001
> [16] AIS0492/001    AIS0492/001    AKO4268(C)/001 AKO4268(C)/001 AKT0042(B)/001
> [21] AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001 AKT0042(B)/001 
> AKT0042(B)/001 [26] AKT0042(B)/001 alb4423(C)/001 ALF1651(A)/001 alf1722(B)/001 ALF1735(A)/001
> [31] ALF1735(A)/001 ALP4321(C)/001 <NA>           <NA>           ALU4262(B)/001
> [36] ALV4286(C)/001 ALW2579(C)/001 <NA>           ALW4330(B)/001 AMA0011/001
> 3886 Levels: 0750/002 0751/001 0984/002 ABE2560(C)/001 ... 
> zul1737(B)/001
>
> testData<-menPatients[1:40,1]
>
> I then used unique, please note the NA at position 32 in testData
> testUnique<-unique(testData)
> testUnique
>   [1] abr1160(C)/001 ABR1363(A)/001 abr1772(B)/001 AFR0003/001    afr0290(C)/001
>   [6] afr1861(B)/001 Aga0007/001    AGA1548(A)/001 AGU1680(A)/001 AIS0492/001
> [11] AKO4268(C)/001 AKT0042(B)/001 alb4423(C)/001 ALF1651(A)/001 alf1722(B)/001
> [16] ALF1735(A)/001 ALP4321(C)/001 <NA>           ALU4262(B)/001 ALV4286(C)/001
> [21] ALW2579(C)/001 ALW4330(B)/001 AMA0011/001
>
> The missing value NA originally at position 32 in testdata is still there, it is in position 18. Why is this? How can I prevent this?
> I tried using incomprables=c(NA), but this did not work.
>
> Thanks
>
>
> Pancho Mulongeni
> Research Assistant
> PharmAccess Foundation
> 1 Fouch? Street
> Windhoek West
> Windhoek
> Namibia
>
> Tel:   +264 61 419 000
> Fax:  +264 61 419 001/2
> Mob: +264 81 4456 286
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From Jose.Iparraguirre at ageuk.org.uk  Fri Jul  5 13:06:44 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Fri, 5 Jul 2013 12:06:44 +0100
Subject: [R] kruskal.test followed by kruskalmc
In-Reply-To: <CANwQX80GaMpY+qYFU9dVEY3ihMrisDm7SjxPX57arn0jcodANA@mail.gmail.com>
References: <CANwQX80GaMpY+qYFU9dVEY3ihMrisDm7SjxPX57arn0jcodANA@mail.gmail.com>
Message-ID: <E0807BF04F0D0C419BF2B39803E98582010E3BB3C0DC@AGEPXCH002C.uk.age.local>

Humber,
Have a look at this: http://r.789695.n4.nabble.com/Multiple-Comparisons-Kruskal-Wallis-Test-kruskal-agricolae-and-kruskalmc-pgirmess-don-t-yield-the-sa-td4639004.html
Hope it helps.
Kind regards,

Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Humber Andrade
Sent: 05 July 2013 11:38
To: r-help at r-project.org
Subject: [R] kruskal.test followed by kruskalmc

Hi all,

After running kruskal.test I have got results (p<0,005) pointing to reject the hypothesis that the samples were draw from the same population.
Howerver when I run the kruskalmc there are no significant differences in any of the multiple comparisons. Is that possible? Some clarification?

Thanks, Humber


<https://sites.google.com/site/humberandrade>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From jannetta at henning.org  Fri Jul  5 13:11:17 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Fri, 5 Jul 2013 12:11:17 +0100
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <1F09F328-6DD5-4224-B194-B6AB21A008A2@xs4all.nl>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<CAGR4ry4+H4pOx2vE=asJrOtZH=exsD1sWrT=VMib0yHdRREJjw@mail.gmail.com>
	<CAGR4ry6WWWMjqyVf5m9jMh8tiSQ7J8dtNvcP5+vTeJK9BymJSA@mail.gmail.com>
	<1F09F328-6DD5-4224-B194-B6AB21A008A2@xs4all.nl>
Message-ID: <CAGR4ry4hPLeoExU11juh=JW0hp-bgAE8AsoKZvcDTXT7kh2f0Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/caa4e544/attachment.pl>

From S.Ellison at LGCGroup.com  Fri Jul  5 14:22:32 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 5 Jul 2013 13:22:32 +0100
Subject: [R] iterative methods
In-Reply-To: <CAEW+BDKDmgkV-aBO8-Wjr1DGEsL1vXMfQiB42ZZxfUZFpoVduw@mail.gmail.com>
References: <CAEW+BDKDmgkV-aBO8-Wjr1DGEsL1vXMfQiB42ZZxfUZFpoVduw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9FEEB6C@GOLD.corp.lgc-group.com>

 > Dear R users,
> Please help me with some documentation for newbie about R 
> programming, algorithms, create iterative C++ function (like 
> for, while, if , etc).
Start at  
http://www.R-project.org/posting-guide.html

and especiallly the resources cited towards the end of that page, just after the bit titled  "Do your homework before posting". It lists useful links. "Introduction to R" and the "R language definition" (sec 3.2 especially) seem relevant.

For books, browse Google for 'R programming books'; there are lots. Some are aimed at particular types of problem, but you know your problem best.

S Ellison

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at lgcgroup.com  Fri Jul  5 14:49:02 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Fri, 5 Jul 2013 13:49:02 +0100
Subject: [R] Error when building a custom package
In-Reply-To: <1372954370691-4670866.post@n4.nabble.com>
References: <1372954370691-4670866.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9FEEB8F@GOLD.corp.lgc-group.com>

 
> I only get an error message, when trying to build a binary 
> file (or runnning /R CMD check <package name>/), not the 
> standard tar.gz. Here is what the output looks like in the 
> command prompt:
> ...
> I have gotten the impression that generally the error with 
> the  "Error in file..." is a problem with a wrong path or 
> problems with permissions, 

Not sure whether it will solve your problem, but specifying a writeable location for R CMD INSTALL --build (as described in 1.3.3 "Building binary packages" in "Writing R extensions") should dodge a permission problem if that is the issue. Personally I prefer to do that anyway to avoid overwriting an existing (working) package installation.

As an aside - probably unrelated and apparently not a warning anyway - I don't see why you would need to be be creating a new plot generic. Isn't the existing plot generic sufficient? 

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From humber.andrade at gmail.com  Fri Jul  5 15:00:33 2013
From: humber.andrade at gmail.com (Humber Andrade)
Date: Fri, 5 Jul 2013 10:00:33 -0300
Subject: [R] kruskal.test followed by kruskalmc
In-Reply-To: <E0807BF04F0D0C419BF2B39803E98582010E3BB3C0DC@AGEPXCH002C.uk.age.local>
References: <CANwQX80GaMpY+qYFU9dVEY3ihMrisDm7SjxPX57arn0jcodANA@mail.gmail.com>
	<E0807BF04F0D0C419BF2B39803E98582010E3BB3C0DC@AGEPXCH002C.uk.age.local>
Message-ID: <CANwQX80=htwxdQ2yETzOUF_KqdLwwkAv76yhe_z1OaZC41KqRQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/3b79f4f5/attachment.pl>

From alexandre.piche at mail.mcgill.ca  Fri Jul  5 15:01:58 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Fri, 5 Jul 2013 06:01:58 -0700 (PDT)
Subject: [R] ggplot2
In-Reply-To: <1372946410534-4670852.post@n4.nabble.com>
References: <1372946410534-4670852.post@n4.nabble.com>
Message-ID: <1373029318123-4670931.post@n4.nabble.com>

Thank you Mr. Kane for your time, I finally achieve my objective with the
package reshape2

n5dt<-last(dezdiff,5)
n5dt <- as.data.frame(t(n5dt))
n5dt$id <- c(1:35)


subm5dt<-melt(n5dt, id="id", c("2013-06-28", "2013-07-01", "2013-07-02",
"2013-07-03", "2013-07-04") )
 names(subm5dt) <- c("Observations", "variable","BasisPoints")
ggplot(subm5dt, aes(Observations, BasisPoints, col=variable, group=2)) +
geom_line() + facet_grid(variable~., scale="fixed") + geom_point()

Have a nice day!



--
View this message in context: http://r.789695.n4.nabble.com/ggplot2-tp4670852p4670931.html
Sent from the R help mailing list archive at Nabble.com.


From torvon at gmail.com  Fri Jul  5 15:17:23 2013
From: torvon at gmail.com (Torvon)
Date: Fri, 5 Jul 2013 15:17:23 +0200
Subject: [R] repolr: multivariate repeated analysis possible?
Message-ID: <CACm_P7oXmtgyu85=tXd+1DvsuQCCXGcVcYthgNA93qpHN1e_Kg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/c0b6db18/attachment.pl>

From cvo at delta.dk  Fri Jul  5 15:55:10 2013
From: cvo at delta.dk (cvo)
Date: Fri, 5 Jul 2013 06:55:10 -0700 (PDT)
Subject: [R] Error when building a custom package
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4AC9FEEB8F@GOLD.corp.lgc-group.com>
References: <1372954370691-4670866.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9FEEB8F@GOLD.corp.lgc-group.com>
Message-ID: <1D12B7DCCF7AF749812D4783BB7019A0016DB5A0@frej.deltams.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/e602944d/attachment.pl>

From pdalgd at gmail.com  Fri Jul  5 16:04:25 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 5 Jul 2013 16:04:25 +0200
Subject: [R] kruskal.test followed by kruskalmc
In-Reply-To: <CANwQX80=htwxdQ2yETzOUF_KqdLwwkAv76yhe_z1OaZC41KqRQ@mail.gmail.com>
References: <CANwQX80GaMpY+qYFU9dVEY3ihMrisDm7SjxPX57arn0jcodANA@mail.gmail.com>
	<E0807BF04F0D0C419BF2B39803E98582010E3BB3C0DC@AGEPXCH002C.uk.age.local>
	<CANwQX80=htwxdQ2yETzOUF_KqdLwwkAv76yhe_z1OaZC41KqRQ@mail.gmail.com>
Message-ID: <1179B7A3-7229-490C-A1AD-70C16051AB8D@gmail.com>


On Jul 5, 2013, at 15:00 , Humber Andrade wrote:

> Thank you Prof. Jos? Iparraguirre. Maybe I am wrong but I think the issues
> are not the same. His data doesn't showed significant differences after
> kruskal.test(), that was not my case. Anyway follow below my the results
> I've got and the database.
> 

This can happen. It is a matter of probability theory, not of R. The following is a simplified paraphrase of what is going on:

# 15 random normals, compare range test to variance test
# Simulate everything for simplicity


# Null distribution
M0 <- replicate(10000, rnorm(15))
vv <- apply(M0,2,var)
rg <- apply(M0,2,range)
rr <- apply(rg,2,diff)
r.95  <- quantile(rr, .95)
v.95  <- quantile(vv, .95)
v.995 <- quantile(vv, .995)

# Distribution at quadrupled variance
M <- replicate(10000, rnorm(15,sd=2))
vv <- apply(M,2,var)
rg <- apply(M,2,range)
rr <- apply(rg,2,diff)
plot(rr,vv)
abline(h=c(v.95,v.995),v=r.95, col="red")

Notice that the two statistics are correlated, but not equivalent. There are cases where one value is beyond the .95 level and the other is not. Since it is theoretically optimal to use the variance as the test statistic in this model, there are quite a few more cases where  rr is below the cutoff and vv is above than the other way around. There are even a sizable number of cases where vv is beyond v.995 and rr does not reach r.95.

(The theoretical optimality applies only because I use an increased variance alternative. For specific alternatives, the picture can change. Try it, for instance with a single mean substantially different from the others:

M <- replicate(10000, rnorm(15,mean=rep(c(4,0),c(1,14))))

)


> Thank you,
> 
> #################
>> kruskal.test(data$resp,data$group)
> 
>    Kruskal-Wallis rank sum test
> 
> data:  data$resp and data$group
> Kruskal-Wallis chi-squared = 32.3546, df = 14, p-value = 0.003566
> ################
>> kruskalmc(data$resp,data$group)
> Multiple comparison test after Kruskal-Wallis
> p.value: 0.05
> Comparisons
>       obs.dif critical.dif difference
> A-B  4.8303571     62.37688      FALSE
> A-C  3.8928571     62.37688      FALSE
> A-D  0.4821429     62.37688      FALSE
> .............................................................
> .............................................................
> .............................................................
> M-P 14.2500000     60.26179      FALSE
> N-O  1.3750000     60.26179      FALSE
> N-P  6.1250000     60.26179      FALSE
> O-P  4.7500000     60.26179      FALSE
> 
> ############# database
>   group resp  A 0.1  A 581.8  A 90.5  A 70.1  A 820.1  A 1159.2  A 2478.1
> A 2475.3  B 351.8  B 370.1  B 326.1  B 751.9  B 931  B 588.2  B 70.1  B
> 1754.9  C 289.8  C 254.1  C 370.3  C 459.8  C 412.5  C 591.5  C 986.9  C 890
> D 425.6  D 397.4  D 464  D 370.9  D 417.3  D 455  D 568.2  D 599.4  E 405.1
> E 626.2  E 299  E 493.8  E 362.6  E 309.8  E 522.7  E 433.3  F 698.6  F 42.5
> F 7.4  F 10.6  F 95.8  F 497.5  F 987.9  F 925.1  G 492.9  G 376  G 413  G
> 278.3  G 344.2  G 292.2  G 429.4  G 368  H 241.6  H 230.5  H 310.4  H 372.5
> H 366.1  H 307.9  H 480  H 529.8  I 296  I 288.8  I 302.1  I 300.8  I 150.1
> I 381.9  I 583.1  I 489.4  J 1.2  J 18.6  J 7.7  J 11.6  J 48.1  J 121.8  J
> 1284.1  J 944.7  L 0.5  L 44.4  L 80.9  L 15.3  L 80  L 379.9  L 940.6  L
> 829.3  M 323.6  M 401.5  M 162.1  M 136.5  M 139.4  M 363.3  M 280.7  M
> 356.5  N 197.6  N 245.9  N 221.5  N 224.3  N 185.4  N 265.3  N 304.8  N
> 351.9  O 189.9  O 237.3  O 247.1  O 230.4  O 272.2  O 155.1  O 270.7  O
> 315.2  P 48.4  P 15.5  P 53.1  P 72.8  P 74.8  P 132.3  P 550  P 478.7
> 
> 
> On Fri, Jul 5, 2013 at 8:06 AM, Jose Iparraguirre <
> Jose.Iparraguirre at ageuk.org.uk> wrote:
> 
>> Humber,
>> Have a look at this:
>> http://r.789695.n4.nabble.com/Multiple-Comparisons-Kruskal-Wallis-Test-kruskal-agricolae-and-kruskalmc-pgirmess-don-t-yield-the-sa-td4639004.html
>> Hope it helps.
>> Kind regards,
>> 
>> Jos?
>> 
>> Prof. Jos? Iparraguirre
>> Chief Economist
>> Age UK
>> 
>> 
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>> On Behalf Of Humber Andrade
>> Sent: 05 July 2013 11:38
>> To: r-help at r-project.org
>> Subject: [R] kruskal.test followed by kruskalmc
>> 
>> Hi all,
>> 
>> After running kruskal.test I have got results (p<0,005) pointing to reject
>> the hypothesis that the samples were draw from the same population.
>> Howerver when I run the kruskalmc there are no significant differences in
>> any of the multiple comparisons. Is that possible? Some clarification?
>> 
>> Thanks, Humber
>> 
>> 
>> <https://sites.google.com/site/humberandrade>
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> The Wireless from Age UK | Radio for grown-ups.
>> 
>> www.ageuk.org.uk/thewireless
>> 
>> 
>> If you?re looking for a radio station that offers real variety, tune in to
>> The Wireless from Age UK.
>> Whether you choose to listen through the website at
>> www.ageuk.org.uk/thewireless, on digital radio (currently available in
>> London and Yorkshire) or through our TuneIn Radio app, you can look forward
>> to an inspiring mix of music, conversation and useful information 24 hours
>> a day.
>> 
>> 
>> 
>> 
>> -------------------------------
>> Age UK is a registered charity and company limited by guarantee,
>> (registered charity number 1128267, registered company number 6825798).
>> Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.
>> 
>> For the purposes of promoting Age UK Insurance, Age UK is an Appointed
>> Representative of Age UK Enterprises Limited, Age UK is an Introducer
>> Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth
>> Access for the purposes of introducing potential annuity and health
>> cash plans customers respectively.  Age UK Enterprises Limited, JLT
>> Benefit Solutions Limited and Simplyhealth Access are all authorised and
>> regulated by the Financial Services Authority.
>> ------------------------------
>> 
>> This email and any files transmitted with it are confidential and intended
>> solely for the use of the individual or entity to whom they are
>> addressed. If you receive a message in error, please advise the sender and
>> delete immediately.
>> 
>> Except where this email is sent in the usual course of our business, any
>> opinions expressed in this email are those of the author and do not
>> necessarily reflect the opinions of Age UK or its subsidiaries and
>> associated companies. Age UK monitors all e-mail transmissions passing
>> through its network and may block or modify mails which are deemed to be
>> unsuitable.
>> 
>> Age Concern England (charity number 261794) and Help the Aged (charity
>> number 272786) and their trading and other associated companies merged
>> on 1st April 2009.  Together they have formed the Age UK Group, dedicated
>> to improving the lives of people in later life.  The three national
>> Age Concerns in Scotland, Northern Ireland and Wales have also merged with
>> Help the Aged in these nations to form three registered charities:
>> Age Scotland, Age NI, Age Cymru.
>> 
>> 
>> 
>> 
>> 
> 
> 
> -- 
> Humber Agrelli Andrade
> Universidade Federal Rural de Pernambuco - UFRPE
> Depto. Pesca e Aq?icultura - DEPAq
> Lab. Modelagem Estat?stica Aplicada - MOE
> Av. Dom Manoel de Medeiros s/n
> Dois Irm?os
> 52171-030    Recife-PE   Brazil
> Tel: (81) 3320-6530
> humber.andrade at gmail.com
> https://sites.google.com/site/humberandrade
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From humber.andrade at gmail.com  Fri Jul  5 16:34:52 2013
From: humber.andrade at gmail.com (Humber Andrade)
Date: Fri, 5 Jul 2013 11:34:52 -0300
Subject: [R] kruskal.test followed by kruskalmc
In-Reply-To: <1179B7A3-7229-490C-A1AD-70C16051AB8D@gmail.com>
References: <CANwQX80GaMpY+qYFU9dVEY3ihMrisDm7SjxPX57arn0jcodANA@mail.gmail.com>
	<E0807BF04F0D0C419BF2B39803E98582010E3BB3C0DC@AGEPXCH002C.uk.age.local>
	<CANwQX80=htwxdQ2yETzOUF_KqdLwwkAv76yhe_z1OaZC41KqRQ@mail.gmail.com>
	<1179B7A3-7229-490C-A1AD-70C16051AB8D@gmail.com>
Message-ID: <CANwQX83rE6dQzhr_miQ=iF2-iWNHu7eP49=FRo5Tu1z_XffBmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/2a34f459/attachment.pl>

From S.Ellison at LGCGroup.com  Fri Jul  5 16:52:25 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 5 Jul 2013 15:52:25 +0100
Subject: [R] Error when building a custom package
In-Reply-To: <1D12B7DCCF7AF749812D4783BB7019A0016DB5A0@frej.deltams.local>
References: <1372954370691-4670866.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9FEEB8F@GOLD.corp.lgc-group.com>
	<1D12B7DCCF7AF749812D4783BB7019A0016DB5A0@frej.deltams.local>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9FEEC70@GOLD.corp.lgc-group.com>

 
> Thanks for the reply. The test package build I did using the 
> skeleton package was in the same folder as the one I'm using 
> now for the custom 'slo' package, so that is not the problem.
> 
Have you checked the detailed logs to see exactly which file is causing the trouble?


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From g.rudge at bham.ac.uk  Fri Jul  5 17:06:45 2013
From: g.rudge at bham.ac.uk (Gavin Rudge)
Date: Fri, 5 Jul 2013 16:06:45 +0100
Subject: [R] Obtaining predicted values from a zero-inflated poisson
 regression model
Message-ID: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B0431812A@mds-exch-02.adf.bham.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/c0ad8325/attachment.pl>

From dwinsemius at comcast.net  Fri Jul  5 17:20:37 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Jul 2013 08:20:37 -0700
Subject: [R] Substituting Greek symbols in some tick labels
In-Reply-To: <CAGrYeXgGy7NuSCtft8aDcCUp_KJ8+ihmvRBEA6+G5BDhTDU+4A@mail.gmail.com>
References: <CAGrYeXgGy7NuSCtft8aDcCUp_KJ8+ihmvRBEA6+G5BDhTDU+4A@mail.gmail.com>
Message-ID: <C0468648-F898-4BDA-B6CF-E643CF67ACF9@comcast.net>


On Jul 4, 2013, at 8:14 PM, Eric Archer - NOAA Federal wrote:

> I have a character vector that I'm using to label ticks in a dotchart. Some
> of the elements in the vector have an asterisk (*) where a Greek Delta
> needs to be placed when the plot is generated. Here's a simple example:
> 
> x <- 1:4
> x.lab <- c("a*a", "bbb", "c*c", "ddd")
> dotchart(x, labels = x.lab)
> 
> The first and third labels should be 'a<Delta>a' and 'c<Delta>c'. I've
> tried things like,
> 
> x.lab <- strsplit(x.lab, "[*]")
> x.lab <- lapply(x.lab, function(y) expression(paste(y, sep = Delta)))
> 
> but because 'y' is unevaluated, the resulting list elements won't work as
> tick labels. I've tried to modify it by using bquote and substitute, but
> couldn't get anything closer. Any suggestions? Thanks!

Right. I would not throw away the "*" but rather change it to an inline Delta:

x.lab <- gsub("\\*", "*Delta*", x.lab)

# parse(text=x.lab)
# returns: expression(a*Delta*a, bbb, c*Delta*c, ddd)# 

Then parse it:

dotchart(x, labels = parse(text=x.lab) )


> 
> Cheers,
> eric
> 
> -- 
> 
> Eric Archer, Ph.D.
> Southwest Fisheries Science Center
> NMFS, NOAA
> 8901 La Jolla Shores Drive
> La Jolla, CA 92037 USA
> 858-546-7121 (work)
> 858-546-7003 (FAX)
> 
> Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
> 
> "The universe doesn't care what you believe.
> The wonderful thing about science is that it
>   doesn't ask for your faith, it just asks
>   for your eyes."  - Randall Munroe
> 
> "Lighthouses are more helpful than churches."
>   - Benjamin Franklin
> 
>   "...but I'll take a GPS over either one."
>       - John C. "Craig" George
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From eric.archer at noaa.gov  Fri Jul  5 17:29:42 2013
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Fri, 5 Jul 2013 08:29:42 -0700
Subject: [R] Substituting Greek symbols in some tick labels
In-Reply-To: <C0468648-F898-4BDA-B6CF-E643CF67ACF9@comcast.net>
References: <CAGrYeXgGy7NuSCtft8aDcCUp_KJ8+ihmvRBEA6+G5BDhTDU+4A@mail.gmail.com>
	<C0468648-F898-4BDA-B6CF-E643CF67ACF9@comcast.net>
Message-ID: <CAGrYeXh-7S49gUTjs7vqJWUoJpGVSk0uLemT-B+g+y1YWivGoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/cadd78e1/attachment.pl>

From dwinsemius at comcast.net  Fri Jul  5 17:33:54 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Jul 2013 08:33:54 -0700
Subject: [R] problem on reading many files
In-Reply-To: <CAAcyNCw6fM6knNQKx=1169mZhmEG4m3UXRYqn+SWi2hfiYhhTQ@mail.gmail.com>
References: <F142DC4E-EC35-4B7F-BCAB-F05248FDD6A4@mimectl>
	<CAAcyNCw6fM6knNQKx=1169mZhmEG4m3UXRYqn+SWi2hfiYhhTQ@mail.gmail.com>
Message-ID: <512318DD-1E47-406C-8021-AD5D48B46249@comcast.net>


On Jul 5, 2013, at 1:04 AM, Pascal Oettli wrote:

> Hello,
> 
> I'm not sure whether it is dur to the HTML version or not, but there is a
> problem with quotation marks in your first line.

I'm guessing the OP was using Word as an editor, a practice that is doomed to frustration.

-- 
David.
> 
> Regards,
> Pascal
> 
> 
> 2013/7/5 RODRIGUEZ MORENO VICTOR MANUEL <rodriguez.victor at inifap.gob.mx>
> 
>> Hi, I have to run almost 120 stations files of temperatura (mx and min),
>> separated, and rain. I am following the instructions on RHtests tutorial as
>> on http://www.cmc.org.ve/mediawiki/index.php?title=Preparando_los_datoslink. Bit I have no success on running on multiple files. I have the .ls
>> file which include the names of the file station, which I include on this
>> msg for your consideration.
>> The instruction that I wrote on the console is
>> 
>> listatmn <- readLines (?tmaxcopia.ls?, warn=false)
>> for(ifile in listatmn)
>> FindU(paste("./",ifile,sep=""),paste("salidas/",ifile,sep=""),"-999.9")
>> 
>> 
>> 
>> 
>> 
>> Of course the tmaxcopia.ls is the list of stations for tmax data. But
>> once running on the console, this is the error msg I got
>> 
>>> listatmn <- readLines (?tmaxcopia.ls?, warn=false)
>> Error: inesperado entrada in "listatmn <- readLines (?"
>>> for(ifile in listatmn)
>> FindU(paste("./",ifile,sep=""),paste("salidas/",ifile,sep=""),"-999.9")
>>> Error: objeto 'ifnames' no encontrado
>> 
>> What I'd like to do is to make easier and fast running the RHtest
>> 
>> Thank's a lot in advance for your help.
>> 
>> 
>> 
>> 
>> Dr Victor M Rodr?guez M
>> Doctor en Ciencias, en Ciencias de la Tierra / Geociencias Ambientales
>> INIFAP. CEPAB. (465) 9580167 y 86 Ext 108 y 220
>> 
>> 
>> /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
>> Este msg y su(s) atado(s) tiene car?cter de "CONFIDENCIAL" y solo es para
>> los fines descritos en su contenido. Queda expresamente prohibida bajo la
>> ley de protecci?n de datos del Gobierno de los Estados Unidos Mexicanos y
>> para su difusion o extensi?n a terceros, se requiere del consentimiento
>> expresso del titular de la cuenta de correo electr?nico y/o del
>> administrador del sitio en extenso de sus responsabilidades .
>> 
>> /////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////
>> 
>>        [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From jannetta at henning.org  Fri Jul  5 17:37:54 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Fri, 5 Jul 2013 16:37:54 +0100
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <CAGR4ry4hPLeoExU11juh=JW0hp-bgAE8AsoKZvcDTXT7kh2f0Q@mail.gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<CAGR4ry4+H4pOx2vE=asJrOtZH=exsD1sWrT=VMib0yHdRREJjw@mail.gmail.com>
	<CAGR4ry6WWWMjqyVf5m9jMh8tiSQ7J8dtNvcP5+vTeJK9BymJSA@mail.gmail.com>
	<1F09F328-6DD5-4224-B194-B6AB21A008A2@xs4all.nl>
	<CAGR4ry4hPLeoExU11juh=JW0hp-bgAE8AsoKZvcDTXT7kh2f0Q@mail.gmail.com>
Message-ID: <CAGR4ry57fZqZdCZyHLJEptcxU175F5cposzDBFTbkYW=g6XQcQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/f7339935/attachment.pl>

From bhh at xs4all.nl  Fri Jul  5 18:18:06 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 5 Jul 2013 18:18:06 +0200
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <CAGR4ry57fZqZdCZyHLJEptcxU175F5cposzDBFTbkYW=g6XQcQ@mail.gmail.com>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<CAGR4ry4+H4pOx2vE=asJrOtZH=exsD1sWrT=VMib0yHdRREJjw@mail.gmail.com>
	<CAGR4ry6WWWMjqyVf5m9jMh8tiSQ7J8dtNvcP5+vTeJK9BymJSA@mail.gmail.com>
	<1F09F328-6DD5-4224-B194-B6AB21A008A2@xs4all.nl>
	<CAGR4ry4hPLeoExU11juh=JW0hp-bgAE8AsoKZvcDTXT7kh2f0Q@mail.gmail.com>
	<CAGR4ry57fZqZdCZyHLJEptcxU175F5cposzDBFTbkYW=g6XQcQ@mail.gmail.com>
Message-ID: <BC1547E3-6756-4E2D-B621-2702B0686062@xs4all.nl>


On 05-07-2013, at 17:37, Jannetta Steyn <jannetta at henning.org> wrote:

> Thank you very much to all of you for your help. This model now works as it
> should (I believe). This is the final code:
> 
> rm(list=ls())
> 
> library(deSolve)
> 
> ST <-  function(time, init, parms) {
>  with(as.list(c(init, parms)),{
> 
>    #functions to calculate activation m and inactivation h of the currents
>    #Axon
>    mNax <- function(v) 1/(1+exp(-(v+24.7)/5.29))
>    taumNa <- function(v) 1.32-(1.26/(1+exp(-(v+120)/25)))
>    hNax <- function(v) 1/(1+exp((v+48.9)/5.18))
>    tauhNa <- function(v)
> 0.67/(1+exp(-(v+62.9)/10))*(1.5+(1/(1+exp((v+34.9)/3.6))))
>    mKx <- function(v) 1/(1+exp(-(v+14.2)/11.8))
>    taumK <- function(v) 7.2-(6.4/(1+exp(-(v+28.3)/19.2)))
> 
> 
>    # Currents as product of maximal conducatance(g), activation(m) and
> inactivation(h)
>    # Driving force (v-E) where E is the reversal potential of the
> particular ion
> 
>    # AB axon
>    iNa_axon_AB <-
> gNa_axon_AB*mNa_axon_AB^3*hNa_axon_AB*(v_axon_AB-ENa_axon_AB)
>    iK_axon_AB <- gK_axon_AB*mK_axon_AB^4*(v_axon_AB-EK_axon_AB)
>    iLeak_axon_AB <- gLeak_axon_AB*(v_axon_AB-ELeak_axon_AB)
> 
>    # AB Axon equations
>    dv_axon_AB <- (0 -iNa_axon_AB -iK_axon_AB -iLeak_axon_AB)/C_axon_AB
>    dmNa_axon_AB <- (mNax(v_axon_AB)-mNa_axon_AB)/taumNa(v_axon_AB)
>    dhNa_axon_AB <- (hNax(v_axon_AB)-hNa_axon_AB)/tauhNa(v_axon_AB)
>    dmK_axon_AB <- (mKx(v_axon_AB)-mK_axon_AB)/taumK(v_axon_AB)
> 
>    list(c(dv_axon_AB,dmNa_axon_AB, dhNa_axon_AB, dmK_axon_AB
>    ))
> 
>  })}
> ## Set initial state
> init = c(v_axon_AB=-55,mNa_axon_AB=0,hNa_axon_AB=1,mK_axon_AB=0)
> ## Set parameters
> # AB
> 
> gNa_axon_AB=300e-3
> gK_axon_AB=52.5e-3
> gLeak_axon_AB=0.0018e-3
> 
> # AB Axon Reversal potentials
> ENa_axon_AB=50
> EK_axon_AB=-80
> ELeak_axon_AB=-60
> 
> C_axon_AB=1.5e-3
> 
> 
> I=0
> 
> parms =
> c(ENa_axon_AB,EK_axon_AB,ELeak_axon_AB,gNa_axon_AB,gK_axon_AB,gLeak_axon_AB,C_axon_AB)
> ## Set integrations times
> times = seq(from=0, to=5000, by = 0.05);
> 
> out<-ode(y=init, times=times, func=ST, parms=parms, method="ode45")
> 
> o<-data.frame(out)
> 
> plot(o$v_axon_AB~o$time,type='l')
> 

You must make the parms vector a named vector because the with(.. in your function ST is not using the global values for those entities available in the global environment.

You can check this by inserting this line after the line with times =  and before the line out <- ode(?

rm(list=c("ENa_axon_AB","EK_axon_AB","ELeak_axon_AB","gNa_axon_AB","gK_axon_AB","gLeak_axon_AB","C_axon_AB"))

You will get an error.

So create the parms vector like this

parms =
c(ENa_axon_AB=ENa_axon_AB,EK_axon_AB=EK_axon_AB,ELeak_axon_AB=ELeak_axon_AB,gNa_axon_AB=gNa_axon_AB,
    gK_axon_AB=gK_axon_AB,gLeak_axon_AB=gLeak_axon_AB,C_axon_AB=C_axon_AB)

or better

parms <- c(ENa_axon_AB=50,EK_axon_AB=-80,ELeak_axon_AB=-60,gNa_axon_AB=300e-3,
                  gK_axon_AB=52.5e-3,gLeak_axon_AB=0.0018e-3,C_axon_AB=1.5e-3)

and remove the expressions with the separate assignments to the variables.


And use <- !!

Berend


From jannetta at henning.org  Fri Jul  5 18:27:17 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Fri, 5 Jul 2013 17:27:17 +0100
Subject: [R] R and MatLab implementations of the same model differs
In-Reply-To: <BC1547E3-6756-4E2D-B621-2702B0686062@xs4all.nl>
References: <CAGR4ry4utJi6-2d7BkP-B_YqbvuCwU5mMRqycZecST6n_F1Oog@mail.gmail.com>
	<5840DF50-EC0D-4D59-BE09-7855C6D341E7@xs4all.nl>
	<loom.20130704T175131-611@post.gmane.org>
	<CAGR4ry4xznGavFx5t6JzfBGZJV_eY-Y8iST+3oeo9wmA_X5-kg@mail.gmail.com>
	<C9CDE4E2-C2AB-439E-B901-CFC2E2708057@xs4all.nl>
	<CAGR4ry4+H4pOx2vE=asJrOtZH=exsD1sWrT=VMib0yHdRREJjw@mail.gmail.com>
	<CAGR4ry6WWWMjqyVf5m9jMh8tiSQ7J8dtNvcP5+vTeJK9BymJSA@mail.gmail.com>
	<1F09F328-6DD5-4224-B194-B6AB21A008A2@xs4all.nl>
	<CAGR4ry4hPLeoExU11juh=JW0hp-bgAE8AsoKZvcDTXT7kh2f0Q@mail.gmail.com>
	<CAGR4ry57fZqZdCZyHLJEptcxU175F5cposzDBFTbkYW=g6XQcQ@mail.gmail.com>
	<BC1547E3-6756-4E2D-B621-2702B0686062@xs4all.nl>
Message-ID: <CAGR4ry5DZCjuWvFWnz0avxD49qggbbMc+Ys0aYmpA4TNyB7sZQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/6049736b/attachment.pl>

From simon.tragust at uni-bayreuth.de  Fri Jul  5 18:55:38 2013
From: simon.tragust at uni-bayreuth.de (Simon Tragust)
Date: Fri, 05 Jul 2013 18:55:38 +0200
Subject: [R] multcomp on significant interaction in coxme model
Message-ID: <51D6FA8A.6030209@uni-bayreuth.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/ec6ff24a/attachment.pl>

From pdalgd at gmail.com  Fri Jul  5 20:07:54 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 5 Jul 2013 20:07:54 +0200
Subject: [R] kruskal.test followed by kruskalmc
In-Reply-To: <CANwQX83rE6dQzhr_miQ=iF2-iWNHu7eP49=FRo5Tu1z_XffBmw@mail.gmail.com>
References: <CANwQX80GaMpY+qYFU9dVEY3ihMrisDm7SjxPX57arn0jcodANA@mail.gmail.com>
	<E0807BF04F0D0C419BF2B39803E98582010E3BB3C0DC@AGEPXCH002C.uk.age.local>
	<CANwQX80=htwxdQ2yETzOUF_KqdLwwkAv76yhe_z1OaZC41KqRQ@mail.gmail.com>
	<1179B7A3-7229-490C-A1AD-70C16051AB8D@gmail.com>
	<CANwQX83rE6dQzhr_miQ=iF2-iWNHu7eP49=FRo5Tu1z_XffBmw@mail.gmail.com>
Message-ID: <FD68759B-9791-4E43-8B1A-193366661A88@gmail.com>


On Jul 5, 2013, at 16:34 , Humber Andrade wrote:

> Thank you Dr. Dalgaard. I understood. I know that this list is not to discuss statistics but I would be very glad if you or someone else can give me some opinion on how to proceed. The kruskal.test says there are differences but the multiple comparisons do not point out what are the differences. Can you suggest a suitable way (maybe paired wilcoxon) to infer what are the differences? I am asking for the hint because I am sure the journal editor/reviewer will ask me to point out which groups differ from each other.
> 

I'm afraid it can't be done. You really can be in a situation where you reject the global null hypothesis that all groups are the same, yet cannot point out any two groups that differ from eachother. 

-pd

> Regards, Humber
> 
> 
> On Fri, Jul 5, 2013 at 11:04 AM, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> On Jul 5, 2013, at 15:00 , Humber Andrade wrote:
> 
> > Thank you Prof. Jos? Iparraguirre. Maybe I am wrong but I think the issues
> > are not the same. His data doesn't showed significant differences after
> > kruskal.test(), that was not my case. Anyway follow below my the results
> > I've got and the database.
> >
> 
> This can happen. It is a matter of probability theory, not of R. The following is a simplified paraphrase of what is going on:
> 
> # 15 random normals, compare range test to variance test
> # Simulate everything for simplicity
> 
> 
> # Null distribution
> M0 <- replicate(10000, rnorm(15))
> vv <- apply(M0,2,var)
> rg <- apply(M0,2,range)
> rr <- apply(rg,2,diff)
> r.95  <- quantile(rr, .95)
> v.95  <- quantile(vv, .95)
> v.995 <- quantile(vv, .995)
> 
> # Distribution at quadrupled variance
> M <- replicate(10000, rnorm(15,sd=2))
> vv <- apply(M,2,var)
> rg <- apply(M,2,range)
> rr <- apply(rg,2,diff)
> plot(rr,vv)
> abline(h=c(v.95,v.995),v=r.95, col="red")
> 
> Notice that the two statistics are correlated, but not equivalent. There are cases where one value is beyond the .95 level and the other is not. Since it is theoretically optimal to use the variance as the test statistic in this model, there are quite a few more cases where  rr is below the cutoff and vv is above than the other way around. There are even a sizable number of cases where vv is beyond v.995 and rr does not reach r.95.
> 
> (The theoretical optimality applies only because I use an increased variance alternative. For specific alternatives, the picture can change. Try it, for instance with a single mean substantially different from the others:
> 
> M <- replicate(10000, rnorm(15,mean=rep(c(4,0),c(1,14))))
> 
> )
> 
> 
> > Thank you,
> >
> > #################
> >> kruskal.test(data$resp,data$group)
> >
> >    Kruskal-Wallis rank sum test
> >
> > data:  data$resp and data$group
> > Kruskal-Wallis chi-squared = 32.3546, df = 14, p-value = 0.003566
> > ################
> >> kruskalmc(data$resp,data$group)
> > Multiple comparison test after Kruskal-Wallis
> > p.value: 0.05
> > Comparisons
> >       obs.dif critical.dif difference
> > A-B  4.8303571     62.37688      FALSE
> > A-C  3.8928571     62.37688      FALSE
> > A-D  0.4821429     62.37688      FALSE
> > .............................................................
> > .............................................................
> > .............................................................
> > M-P 14.2500000     60.26179      FALSE
> > N-O  1.3750000     60.26179      FALSE
> > N-P  6.1250000     60.26179      FALSE
> > O-P  4.7500000     60.26179      FALSE
> >
> > ############# database
> >   group resp  A 0.1  A 581.8  A 90.5  A 70.1  A 820.1  A 1159.2  A 2478.1
> > A 2475.3  B 351.8  B 370.1  B 326.1  B 751.9  B 931  B 588.2  B 70.1  B
> > 1754.9  C 289.8  C 254.1  C 370.3  C 459.8  C 412.5  C 591.5  C 986.9  C 890
> > D 425.6  D 397.4  D 464  D 370.9  D 417.3  D 455  D 568.2  D 599.4  E 405.1
> > E 626.2  E 299  E 493.8  E 362.6  E 309.8  E 522.7  E 433.3  F 698.6  F 42.5
> > F 7.4  F 10.6  F 95.8  F 497.5  F 987.9  F 925.1  G 492.9  G 376  G 413  G
> > 278.3  G 344.2  G 292.2  G 429.4  G 368  H 241.6  H 230.5  H 310.4  H 372.5
> > H 366.1  H 307.9  H 480  H 529.8  I 296  I 288.8  I 302.1  I 300.8  I 150.1
> > I 381.9  I 583.1  I 489.4  J 1.2  J 18.6  J 7.7  J 11.6  J 48.1  J 121.8  J
> > 1284.1  J 944.7  L 0.5  L 44.4  L 80.9  L 15.3  L 80  L 379.9  L 940.6  L
> > 829.3  M 323.6  M 401.5  M 162.1  M 136.5  M 139.4  M 363.3  M 280.7  M
> > 356.5  N 197.6  N 245.9  N 221.5  N 224.3  N 185.4  N 265.3  N 304.8  N
> > 351.9  O 189.9  O 237.3  O 247.1  O 230.4  O 272.2  O 155.1  O 270.7  O
> > 315.2  P 48.4  P 15.5  P 53.1  P 72.8  P 74.8  P 132.3  P 550  P 478.7
> >
> >
> > On Fri, Jul 5, 2013 at 8:06 AM, Jose Iparraguirre <
> > Jose.Iparraguirre at ageuk.org.uk> wrote:
> >
> >> Humber,
> >> Have a look at this:
> >> http://r.789695.n4.nabble.com/Multiple-Comparisons-Kruskal-Wallis-Test-kruskal-agricolae-and-kruskalmc-pgirmess-don-t-yield-the-sa-td4639004.html
> >> Hope it helps.
> >> Kind regards,
> >>
> >> Jos?
> >>
> >> Prof. Jos? Iparraguirre
> >> Chief Economist
> >> Age UK
> >>
> >>
> >>
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> >> On Behalf Of Humber Andrade
> >> Sent: 05 July 2013 11:38
> >> To: r-help at r-project.org
> >> Subject: [R] kruskal.test followed by kruskalmc
> >>
> >> Hi all,
> >>
> >> After running kruskal.test I have got results (p<0,005) pointing to reject
> >> the hypothesis that the samples were draw from the same population.
> >> Howerver when I run the kruskalmc there are no significant differences in
> >> any of the multiple comparisons. Is that possible? Some clarification?
> >>
> >> Thanks, Humber
> >>
> >>
> >> <https://sites.google.com/site/humberandrade>
> >>
> >>        [[alternative HTML version deleted]]
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> The Wireless from Age UK | Radio for grown-ups.
> >>
> >> www.ageuk.org.uk/thewireless
> >>
> >>
> >> If you?re looking for a radio station that offers real variety, tune in to
> >> The Wireless from Age UK.
> >> Whether you choose to listen through the website at
> >> www.ageuk.org.uk/thewireless, on digital radio (currently available in
> >> London and Yorkshire) or through our TuneIn Radio app, you can look forward
> >> to an inspiring mix of music, conversation and useful information 24 hours
> >> a day.
> >>
> >>
> >>
> >>
> >> -------------------------------
> >> Age UK is a registered charity and company limited by guarantee,
> >> (registered charity number 1128267, registered company number 6825798).
> >> Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.
> >>
> >> For the purposes of promoting Age UK Insurance, Age UK is an Appointed
> >> Representative of Age UK Enterprises Limited, Age UK is an Introducer
> >> Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth
> >> Access for the purposes of introducing potential annuity and health
> >> cash plans customers respectively.  Age UK Enterprises Limited, JLT
> >> Benefit Solutions Limited and Simplyhealth Access are all authorised and
> >> regulated by the Financial Services Authority.
> >> ------------------------------
> >>
> >> This email and any files transmitted with it are confidential and intended
> >> solely for the use of the individual or entity to whom they are
> >> addressed. If you receive a message in error, please advise the sender and
> >> delete immediately.
> >>
> >> Except where this email is sent in the usual course of our business, any
> >> opinions expressed in this email are those of the author and do not
> >> necessarily reflect the opinions of Age UK or its subsidiaries and
> >> associated companies. Age UK monitors all e-mail transmissions passing
> >> through its network and may block or modify mails which are deemed to be
> >> unsuitable.
> >>
> >> Age Concern England (charity number 261794) and Help the Aged (charity
> >> number 272786) and their trading and other associated companies merged
> >> on 1st April 2009.  Together they have formed the Age UK Group, dedicated
> >> to improving the lives of people in later life.  The three national
> >> Age Concerns in Scotland, Northern Ireland and Wales have also merged with
> >> Help the Aged in these nations to form three registered charities:
> >> Age Scotland, Age NI, Age Cymru.
> >>
> >>
> >>
> >>
> >>
> >
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> --
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> 
> 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sjackman at gmail.com  Fri Jul  5 20:15:46 2013
From: sjackman at gmail.com (Shaun Jackman)
Date: Fri, 5 Jul 2013 11:15:46 -0700
Subject: [R] Lattice barchart with error bars
In-Reply-To: <CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
	<CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
Message-ID: <CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/420e2c4f/attachment.pl>

From dwinsemius at comcast.net  Fri Jul  5 20:28:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 5 Jul 2013 11:28:35 -0700
Subject: [R] Lattice barchart with error bars
In-Reply-To: <CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
	<CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
	<CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>
Message-ID: <7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>


On Jul 5, 2013, at 11:15 AM, Shaun Jackman wrote:

> Hi Bert, Dennis,
> 
> I'll agree that using a barchart was a poor choice. I was in fact using a
> notched bwplot to show the median and confidence interval of the median. In
> this case it's the median and confidence interval that I want to highlight,
> and I find that the visual noise of the box and whiskers is detracting from
> the focus, and those wee notches are not much to focus on. So, I'd like to
> draw a stripplot with error bars, preferably in Lattice. Let's call this a
> TIE fighter plot. Any suggestions?
> 

I like the TIE fighter label. Try this:

library(latticeExtra)
data(USCancerRates)
segplot(reorder(factor(county), rate.male) ~ LCL95.male + UCL95.male,
        data = subset(USCancerRates, state == "Washington"),
        draw.bands = FALSE, centers = rate.male, 
        segments.fun = panel.arrows, ends = "both", 
        angle = 90, length = 1, unit = "mm")

It's what Sarkar has recommended in the past when this request has been posted.

-- 
David


> Cheers,
> Shaun
> 
> On 4 July 2013 18:00, Dennis Murphy <djmuser at gmail.com> wrote:
> 
>> If you consult the lattice package help, you'll discover there is no
>> panel_errorbar() function, which would imply the package developers
>> have a distaste for that type of graphic. If you fish around the
>> R-help archives, though, you might be able to find someone who wrote a
>> function to do error bars in lattice. (Use a searchable archive such
>> as Nabble to hunt for it.)
>> 
>> Error bar plots are easier to do in the ggplot2 package, since there
>> is a specific function to generate the error bar 'geometry'
>> (geom_errorbar). See http://docs.ggplot2.org/current/ for an expanded
>> version of the package help pages, which include the graphs generated
>> by the code. I believe there's also a base graphics version that you
>> can get from the gplots package, but I don't know a lot about it.
>> 
>> Dennis
>> 
>> On Thu, Jul 4, 2013 at 2:53 PM, Shaun Jackman <sjackman at gmail.com> wrote:
>>> Hi,
>>> 
>>> I'd like to draw a lattice barchart of means with error bars to show
>>> the standard deviation. I have the barchart, how do I add the error
>>> bars?
>>> 
>>> require(datasets)
>>> require(lattice)
>>> x <- aggregate(weight ~ Diet, ChickWeight, function(x) c(mean=mean(x),
>>> sd=sd(x)))
>>> barchart(weight[,'mean'] ~ Diet, x)
>>> 
>>> Thanks,
>>> Shaun
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Fri Jul  5 20:48:46 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 5 Jul 2013 11:48:46 -0700
Subject: [R] Lattice barchart with error bars
In-Reply-To: <7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
	<CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
	<CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>
	<7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>
Message-ID: <CACk-te0+K7AbPXnHN1QvvLaqUr+5p2DdA6Dnza+nd=10NsaT-A@mail.gmail.com>

Be careful!

You are talking about 2 different varieties of apples here. As I read
it, the CI's in the  cancer data, which I know is just for example
purposes, are CI's for the **individual means**; the notches in
boxplots are nonparametric and for 2 groups with roughly equal sample
sizes, "The idea appears to be to give roughly a 95% confidence
interval for the **difference** in two medians." (from
?boxplot.stats). So I'm not sure which you want, but they are
certainly different (by a factor of around sqrt(2),right?), even if
both are for the mean or both are for the median.

Cheers,
Bert

On Fri, Jul 5, 2013 at 11:28 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jul 5, 2013, at 11:15 AM, Shaun Jackman wrote:
>
>> Hi Bert, Dennis,
>>
>> I'll agree that using a barchart was a poor choice. I was in fact using a
>> notched bwplot to show the median and confidence interval of the median. In
>> this case it's the median and confidence interval that I want to highlight,
>> and I find that the visual noise of the box and whiskers is detracting from
>> the focus, and those wee notches are not much to focus on. So, I'd like to
>> draw a stripplot with error bars, preferably in Lattice. Let's call this a
>> TIE fighter plot. Any suggestions?
>>
>
> I like the TIE fighter label. Try this:
>
> library(latticeExtra)
> data(USCancerRates)
> segplot(reorder(factor(county), rate.male) ~ LCL95.male + UCL95.male,
>         data = subset(USCancerRates, state == "Washington"),
>         draw.bands = FALSE, centers = rate.male,
>         segments.fun = panel.arrows, ends = "both",
>         angle = 90, length = 1, unit = "mm")
>
> It's what Sarkar has recommended in the past when this request has been posted.
>
> --
> David
>
>
>> Cheers,
>> Shaun
>>
>> On 4 July 2013 18:00, Dennis Murphy <djmuser at gmail.com> wrote:
>>
>>> If you consult the lattice package help, you'll discover there is no
>>> panel_errorbar() function, which would imply the package developers
>>> have a distaste for that type of graphic. If you fish around the
>>> R-help archives, though, you might be able to find someone who wrote a
>>> function to do error bars in lattice. (Use a searchable archive such
>>> as Nabble to hunt for it.)
>>>
>>> Error bar plots are easier to do in the ggplot2 package, since there
>>> is a specific function to generate the error bar 'geometry'
>>> (geom_errorbar). See http://docs.ggplot2.org/current/ for an expanded
>>> version of the package help pages, which include the graphs generated
>>> by the code. I believe there's also a base graphics version that you
>>> can get from the gplots package, but I don't know a lot about it.
>>>
>>> Dennis
>>>
>>> On Thu, Jul 4, 2013 at 2:53 PM, Shaun Jackman <sjackman at gmail.com> wrote:
>>>> Hi,
>>>>
>>>> I'd like to draw a lattice barchart of means with error bars to show
>>>> the standard deviation. I have the barchart, how do I add the error
>>>> bars?
>>>>
>>>> require(datasets)
>>>> require(lattice)
>>>> x <- aggregate(weight ~ Diet, ChickWeight, function(x) c(mean=mean(x),
>>>> sd=sd(x)))
>>>> barchart(weight[,'mean'] ~ Diet, x)
>>>>
>>>> Thanks,
>>>> Shaun
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From sjackman at gmail.com  Fri Jul  5 21:11:29 2013
From: sjackman at gmail.com (Shaun Jackman)
Date: Fri, 5 Jul 2013 12:11:29 -0700
Subject: [R] Lattice barchart with error bars
In-Reply-To: <7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
	<CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
	<CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>
	<7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>
Message-ID: <CADX6M3rE8xj1aH9zLxAp1bvVpX0jJi60CNRYV_EebeT98GhFnw@mail.gmail.com>

Yes! Thank you, David. That's exactly what I'm I'm looking for. For
the record, here's a couple pages leading to this answer:

http://www.hep.by/gnu/r-patched/r-faq/R-FAQ_89.html
http://latticeextra.r-forge.r-project.org/man/segplot.html
http://rgm3.lab.nig.ac.jp/RGM/r_function?p=latticeExtra&f=segplot

For a related question, what's the tidiest way to calculate the
medians and confidence intervals? Currently I'm using `boxplot`:

require(datasets)
ci <- with(boxplot(weight ~ Diet, ChickWeight), data.frame(
  Diet = names,
  median = stats[3,],
  lower = conf[1,],
  upper = conf[2,]))

Cheers,
Shaun

On 5 July 2013 11:28, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jul 5, 2013, at 11:15 AM, Shaun Jackman wrote:
>
>> Hi Bert, Dennis,
>>
>> I'll agree that using a barchart was a poor choice. I was in fact using a
>> notched bwplot to show the median and confidence interval of the median. In
>> this case it's the median and confidence interval that I want to highlight,
>> and I find that the visual noise of the box and whiskers is detracting from
>> the focus, and those wee notches are not much to focus on. So, I'd like to
>> draw a stripplot with error bars, preferably in Lattice. Let's call this a
>> TIE fighter plot. Any suggestions?
>>
>
> I like the TIE fighter label. Try this:
>
> library(latticeExtra)
> data(USCancerRates)
> segplot(reorder(factor(county), rate.male) ~ LCL95.male + UCL95.male,
>         data = subset(USCancerRates, state == "Washington"),
>         draw.bands = FALSE, centers = rate.male,
>         segments.fun = panel.arrows, ends = "both",
>         angle = 90, length = 1, unit = "mm")
>
> It's what Sarkar has recommended in the past when this request has been posted.
>
> --
> David
>
>
>> Cheers,
>> Shaun
>>
>> On 4 July 2013 18:00, Dennis Murphy <djmuser at gmail.com> wrote:
>>
>>> If you consult the lattice package help, you'll discover there is no
>>> panel_errorbar() function, which would imply the package developers
>>> have a distaste for that type of graphic. If you fish around the
>>> R-help archives, though, you might be able to find someone who wrote a
>>> function to do error bars in lattice. (Use a searchable archive such
>>> as Nabble to hunt for it.)
>>>
>>> Error bar plots are easier to do in the ggplot2 package, since there
>>> is a specific function to generate the error bar 'geometry'
>>> (geom_errorbar). See http://docs.ggplot2.org/current/ for an expanded
>>> version of the package help pages, which include the graphs generated
>>> by the code. I believe there's also a base graphics version that you
>>> can get from the gplots package, but I don't know a lot about it.
>>>
>>> Dennis
>>>
>>> On Thu, Jul 4, 2013 at 2:53 PM, Shaun Jackman <sjackman at gmail.com> wrote:
>>>> Hi,
>>>>
>>>> I'd like to draw a lattice barchart of means with error bars to show
>>>> the standard deviation. I have the barchart, how do I add the error
>>>> bars?
>>>>
>>>> require(datasets)
>>>> require(lattice)
>>>> x <- aggregate(weight ~ Diet, ChickWeight, function(x) c(mean=mean(x),
>>>> sd=sd(x)))
>>>> barchart(weight[,'mean'] ~ Diet, x)
>>>>
>>>> Thanks,
>>>> Shaun
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>


From sjackman at gmail.com  Fri Jul  5 21:15:13 2013
From: sjackman at gmail.com (Shaun Jackman)
Date: Fri, 5 Jul 2013 12:15:13 -0700
Subject: [R] Lattice barchart with error bars
In-Reply-To: <CACk-te0+K7AbPXnHN1QvvLaqUr+5p2DdA6Dnza+nd=10NsaT-A@mail.gmail.com>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
	<CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
	<CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>
	<7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>
	<CACk-te0+K7AbPXnHN1QvvLaqUr+5p2DdA6Dnza+nd=10NsaT-A@mail.gmail.com>
Message-ID: <CADX6M3p9viLrmHB4ygZanwL8U4ZD9VwvsZn5cJhj8y5RDgoVyQ@mail.gmail.com>

Hmm. Interesting point, Bert. I don't know whether the notches show
the 95% confidence interval or the median, or the 95% confidence
interval that two non-overlapping notches have different medians.
You're saying it's the latter? Anyone know what the 95% confidence
interval of the median would be?

Cheers,
Shaun

> The notches (if requested) extend to +/-1.58 IQR/sqrt(n). This seems to be based on the same calculations as the formula with 1.57 in Chambers et al. (1983, p. 62), given in McGill et al. (1978, p. 16). They are based on asymptotic normality of the median and roughly equal sample sizes for the two medians being compared, and are said to be rather insensitive to the underlying distributions of the samples. The idea appears to be to give roughly a 95% confidence interval for the difference in two medians.


On 5 July 2013 11:48, Bert Gunter <gunter.berton at gene.com> wrote:
> Be careful!
>
> You are talking about 2 different varieties of apples here. As I read
> it, the CI's in the  cancer data, which I know is just for example
> purposes, are CI's for the **individual means**; the notches in
> boxplots are nonparametric and for 2 groups with roughly equal sample
> sizes, "The idea appears to be to give roughly a 95% confidence
> interval for the **difference** in two medians." (from
> ?boxplot.stats). So I'm not sure which you want, but they are
> certainly different (by a factor of around sqrt(2),right?), even if
> both are for the mean or both are for the median.
>
> Cheers,
> Bert
>
> On Fri, Jul 5, 2013 at 11:28 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On Jul 5, 2013, at 11:15 AM, Shaun Jackman wrote:
>>
>>> Hi Bert, Dennis,
>>>
>>> I'll agree that using a barchart was a poor choice. I was in fact using a
>>> notched bwplot to show the median and confidence interval of the median. In
>>> this case it's the median and confidence interval that I want to highlight,
>>> and I find that the visual noise of the box and whiskers is detracting from
>>> the focus, and those wee notches are not much to focus on. So, I'd like to
>>> draw a stripplot with error bars, preferably in Lattice. Let's call this a
>>> TIE fighter plot. Any suggestions?
>>>
>>
>> I like the TIE fighter label. Try this:
>>
>> library(latticeExtra)
>> data(USCancerRates)
>> segplot(reorder(factor(county), rate.male) ~ LCL95.male + UCL95.male,
>>         data = subset(USCancerRates, state == "Washington"),
>>         draw.bands = FALSE, centers = rate.male,
>>         segments.fun = panel.arrows, ends = "both",
>>         angle = 90, length = 1, unit = "mm")
>>
>> It's what Sarkar has recommended in the past when this request has been posted.
>>
>> --
>> David
>>
>>
>>> Cheers,
>>> Shaun
>>>
>>> On 4 July 2013 18:00, Dennis Murphy <djmuser at gmail.com> wrote:
>>>
>>>> If you consult the lattice package help, you'll discover there is no
>>>> panel_errorbar() function, which would imply the package developers
>>>> have a distaste for that type of graphic. If you fish around the
>>>> R-help archives, though, you might be able to find someone who wrote a
>>>> function to do error bars in lattice. (Use a searchable archive such
>>>> as Nabble to hunt for it.)
>>>>
>>>> Error bar plots are easier to do in the ggplot2 package, since there
>>>> is a specific function to generate the error bar 'geometry'
>>>> (geom_errorbar). See http://docs.ggplot2.org/current/ for an expanded
>>>> version of the package help pages, which include the graphs generated
>>>> by the code. I believe there's also a base graphics version that you
>>>> can get from the gplots package, but I don't know a lot about it.
>>>>
>>>> Dennis
>>>>
>>>> On Thu, Jul 4, 2013 at 2:53 PM, Shaun Jackman <sjackman at gmail.com> wrote:
>>>>> Hi,
>>>>>
>>>>> I'd like to draw a lattice barchart of means with error bars to show
>>>>> the standard deviation. I have the barchart, how do I add the error
>>>>> bars?
>>>>>
>>>>> require(datasets)
>>>>> require(lattice)
>>>>> x <- aggregate(weight ~ Diet, ChickWeight, function(x) c(mean=mean(x),
>>>>> sd=sd(x)))
>>>>> barchart(weight[,'mean'] ~ Diet, x)
>>>>>
>>>>> Thanks,
>>>>> Shaun
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>       [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Fri Jul  5 21:16:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 5 Jul 2013 12:16:40 -0700 (PDT)
Subject: [R] Filter Dataframe for Alarm for particular column(s).
Message-ID: <1373051800.36586.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps:
If you had showed your solution, it would be easier to compare.

res<-data.frame(lapply(sapply(MyDF[,c(2,4)],function(x) {x1<-which(c(0,diff(x))<0);x1[length(x1)==0]<-0;x1}),`[`,1))
?res
#? TNH BIX
#1?? 3?? 9


#Speed

?set.seed(24)
?MyDFNew<- data.frame(TNH=sample(0:1,1e6,replace=TRUE),BIX=sample(0:1,1e6,replace=TRUE))
system.time(res1<-data.frame(lapply(sapply(MyDFNew,function(x) {x1<-which(c(0,diff(x))<0);x1[length(x1)==0]<-0;x1}),`[`,1)))
#?? user? system elapsed 
#? 0.364?? 0.000?? 0.363 

?res1
#? TNH BIX
#1?? 7?? 2
?MyDFNew[1:10,]
#?? TNH BIX
#1??? 0?? 1
#2??? 0?? 0
#3??? 1?? 1
#4??? 1?? 1
#5??? 1?? 0
#6??? 1?? 0
#7??? 0?? 1
#8??? 1?? 1
#9??? 1?? 1
#10?? 0?? 0


A.K.


Hi,


Hi here i have a dataframe called MyDF. 

a<-c(1,1,1,1,1,0,0,0,1,1) 
b<-c(1,1,0,1,1,0,0,0,1,1) 
c<-c(1,1,1,1,1,1,1,0,1,1) 
d<-c(1,1,1,1,1,1,1,1,0,1) 
MyDF<-data.frame(DWATT=a,TNH=b,CSGV=c,BIX=d) 

My requirement is, here i need a function - to get for a 
particular row number(s), when particular column(s) value change from 
one-to-zero ?(for the first change). Suppose there is no change is 
happening then it should return "Zero" 

For example, ?Using MyDF, 

DWATT TNH CSGV BIX 
1 ? 1 ? ?1 ? 1 
1 ? 1 ? ?1 ? 1 
1 ? 0 ? ?1 ? 1 
1 ? 1 ? ?1 ? 1 
1 ? 1 ? ?1 ? 1 
0 ? 0 ? ?1 ? 1 
0 ? 0 ? ?1 ? 1 
0 ? 0 ? ?0 ? 1 
1 ? 1 ? ?1 ? 0 
1 ? 1 ? ?1 ? 1 

Here i want to know, the row number where TNH-column and BIX-column values change happening from one-to-zero for the first time. 

Note:- Suppose there is no change is happening then it should return "Zero" 

Answer should be ?a dataframe with single row. 
So here answer should return a dataframe like this. 

TNH ?BIX 
---- ? ?------ 
3 ? ? ?9 


i used some ways to get a solution using loops. But there is a bulk files with bulk rows to process. 
So performace is most important. Could someone please suggest better ideas ? 

Thanks, 
Antony.


From friendly at yorku.ca  Fri Jul  5 21:20:50 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 05 Jul 2013 15:20:50 -0400
Subject: [R] converting a list of loglin terms to a model formula
In-Reply-To: <CAPvBnPFK7eW0Ev_TUxCXfHcUAm6OEMevdU7USQDG0yNnS+GYEA@mail.gmail.com>
References: <51D49DE6.8010103@yorku.ca>
	<CAPvBnPFK7eW0Ev_TUxCXfHcUAm6OEMevdU7USQDG0yNnS+GYEA@mail.gmail.com>
Message-ID: <51D71C92.4000906@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/77f5af79/attachment.pl>

From noahsilverman at ucla.edu  Fri Jul  5 21:33:46 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Fri, 5 Jul 2013 12:33:46 -0700
Subject: [R] Subset and order
Message-ID: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/0b67c5d6/attachment.pl>

From ruipbarradas at sapo.pt  Fri Jul  5 21:43:55 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 05 Jul 2013 20:43:55 +0100
Subject: [R] Subset and order
In-Reply-To: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>
References: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>
Message-ID: <51D721FB.1050800@sapo.pt>

Hello,

Maybe like this?

subset(x[order(x$a), ], b == 3)


Hope this helps,

Rui Barradas

Em 05-07-2013 20:33, Noah Silverman escreveu:
> Hello,
>
> I have a data frame with several columns.
>
> I'd like to select some subset *and* order by another field at the same time.
>
> Example:
>
> a	b	c
> 1	2	3
> 3	3	4
> 2	4	5
> 1	3	4
> etc?
>
>
> I want to select all rows where b=3 and then order by a.
>
> To subset is easy:  x[x$b==3,]
> To order is easy: x[order(x$a),]
>
> Is there a way to do both in a single efficient statement?
>
> Thanks,
>
>
>
> --
> Noah Silverman, M.S., C.Phil
> UCLA Department of Statistics
> 8117 Math Sciences Building
> Los Angeles, CA 90095
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From noahsilverman at ucla.edu  Fri Jul  5 21:47:18 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Fri, 5 Jul 2013 12:47:18 -0700
Subject: [R] Subset and order
In-Reply-To: <51D721FB.1050800@sapo.pt>
References: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>
	<51D721FB.1050800@sapo.pt>
Message-ID: <A01F0E9C-31F4-4F61-B517-127F641BFF92@ucla.edu>

That would work, but is painfully slow.  It forces a new sort of the data with every query.  I have 200,000 rows and need almost a hundred queries.

Thanks,

-N


On Jul 5, 2013, at 12:43 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:

> Hello,
> 
> Maybe like this?
> 
> subset(x[order(x$a), ], b == 3)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 05-07-2013 20:33, Noah Silverman escreveu:
>> Hello,
>> 
>> I have a data frame with several columns.
>> 
>> I'd like to select some subset *and* order by another field at the same time.
>> 
>> Example:
>> 
>> a	b	c
>> 1	2	3
>> 3	3	4
>> 2	4	5
>> 1	3	4
>> etc?
>> 
>> 
>> I want to select all rows where b=3 and then order by a.
>> 
>> To subset is easy:  x[x$b==3,]
>> To order is easy: x[order(x$a),]
>> 
>> Is there a way to do both in a single efficient statement?
>> 
>> Thanks,
>> 
>> 
>> 
>> --
>> Noah Silverman, M.S., C.Phil
>> UCLA Department of Statistics
>> 8117 Math Sciences Building
>> Los Angeles, CA 90095
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 


From ruipbarradas at sapo.pt  Fri Jul  5 21:51:40 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 05 Jul 2013 20:51:40 +0100
Subject: [R] Subset and order
In-Reply-To: <A01F0E9C-31F4-4F61-B517-127F641BFF92@ucla.edu>
References: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>
	<51D721FB.1050800@sapo.pt>
	<A01F0E9C-31F4-4F61-B517-127F641BFF92@ucla.edu>
Message-ID: <51D723CC.40004@sapo.pt>

Hello,

If time is one of the problems, precompute an ordered index, and use it 
every time you want the df sorted. But that would mean you can't do it 
in a single operation.

iord <- order(x$a)
subset(x[iord, ], b == 3)


Rui Barradas

Em 05-07-2013 20:47, Noah Silverman escreveu:
> That would work, but is painfully slow.  It forces a new sort of the data with every query.  I have 200,000 rows and need almost a hundred queries.
>
> Thanks,
>
> -N
>
>
> On Jul 5, 2013, at 12:43 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Maybe like this?
>>
>> subset(x[order(x$a), ], b == 3)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 05-07-2013 20:33, Noah Silverman escreveu:
>>> Hello,
>>>
>>> I have a data frame with several columns.
>>>
>>> I'd like to select some subset *and* order by another field at the same time.
>>>
>>> Example:
>>>
>>> a	b	c
>>> 1	2	3
>>> 3	3	4
>>> 2	4	5
>>> 1	3	4
>>> etc?
>>>
>>>
>>> I want to select all rows where b=3 and then order by a.
>>>
>>> To subset is easy:  x[x$b==3,]
>>> To order is easy: x[order(x$a),]
>>>
>>> Is there a way to do both in a single efficient statement?
>>>
>>> Thanks,
>>>
>>>
>>>
>>> --
>>> Noah Silverman, M.S., C.Phil
>>> UCLA Department of Statistics
>>> 8117 Math Sciences Building
>>> Los Angeles, CA 90095
>>>
>>>
>>>
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>


From dcarlson at tamu.edu  Fri Jul  5 21:56:34 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 5 Jul 2013 14:56:34 -0500
Subject: [R] Subset and order
In-Reply-To: <A01F0E9C-31F4-4F61-B517-127F641BFF92@ucla.edu>
References: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>	<51D721FB.1050800@sapo.pt>
	<A01F0E9C-31F4-4F61-B517-127F641BFF92@ucla.edu>
Message-ID: <10d901ce79b9$c034cec0$409e6c40$@tamu.edu>

It may be that single and efficient are opposing goals. Two steps
lets you create the subset and then just order each query.
Alternatively, if the data do not change often, create an ordered
version and query that.


David Carlson

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Noah Silverman
Sent: Friday, July 5, 2013 2:47 PM
To: Rui Barradas
Cc: R-help at r-project.org
Subject: Re: [R] Subset and order

That would work, but is painfully slow.  It forces a new sort of the
data with every query.  I have 200,000 rows and need almost a
hundred queries.

Thanks,

-N


On Jul 5, 2013, at 12:43 PM, Rui Barradas <ruipbarradas at sapo.pt>
wrote:

> Hello,
> 
> Maybe like this?
> 
> subset(x[order(x$a), ], b == 3)
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 05-07-2013 20:33, Noah Silverman escreveu:
>> Hello,
>> 
>> I have a data frame with several columns.
>> 
>> I'd like to select some subset *and* order by another field at
the same time.
>> 
>> Example:
>> 
>> a	b	c
>> 1	2	3
>> 3	3	4
>> 2	4	5
>> 1	3	4
>> etc.
>> 
>> 
>> I want to select all rows where b=3 and then order by a.
>> 
>> To subset is easy:  x[x$b==3,]
>> To order is easy: x[order(x$a),]
>> 
>> Is there a way to do both in a single efficient statement?
>> 
>> Thanks,
>> 
>> 
>> 
>> --
>> Noah Silverman, M.S., C.Phil
>> UCLA Department of Statistics
>> 8117 Math Sciences Building
>> Los Angeles, CA 90095
>> 
>> 
>> 
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible
code.
>> 

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From wdunlap at tibco.com  Fri Jul  5 22:41:26 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Fri, 5 Jul 2013 20:41:26 +0000
Subject: [R] converting a list of loglin terms to a model formula
In-Reply-To: <51D71C92.4000906@yorku.ca>
References: <51D49DE6.8010103@yorku.ca>
	<CAPvBnPFK7eW0Ev_TUxCXfHcUAm6OEMevdU7USQDG0yNnS+GYEA@mail.gmail.com>
	<51D71C92.4000906@yorku.ca>
Message-ID: <E66794E69CFDE04D9A70842786030B931C31A17B@PA-MBX01.na.tibco.com>

> Call:
> loglm(formula = form, data = x)       ### I want formula = ~Hair:Eye + Sex here

Since your function made the call
   loglm(form, data=x)
the 'call' component of output is going to show 'form', not '~ Hair:Eye + Sex'.
You can use bquote to pre-evaluate the formula=form argument to get the call
to look nicer, as in:
  form <- mpg ~ wt + hp
  eval(bquote(lm(.(form), data=mtcars)))
instead of
   lm(form, data=mtcars)

In your loglin2formula, I would make by environment of the generated formula
the environment of the caller of loglin2formula (or somewhere else if the user wishes)
by adding the argument
   env = parent.frame()
and replacing
   as.formula( sprintf(...) )
with
   formula( sprintf(...), env=env)
(I don't think you've run into any problems related to having an irrelevant
environment attached to the formula, but they will happen if the formula
involves any variable names that happen to be in loglin2formula.)

I would also change the loglin2formula so it worked with non-syntactic names.
Wrapping them with backquotes would probably do it, but I may have missed
something in the back and forth between character strings and formula.

As for loglin2string, you complain that it works when given a list of character
vectors but not when is given a formula.  That is not surprising.  Did you mean
for test_loglm to pass it 'margins' instead of 'form'?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Michael Friendly
> Sent: Friday, July 05, 2013 12:21 PM
> To: Henrique Dallazuanna
> Cc: R-help
> Subject: Re: [R] converting a list of loglin terms to a model formula
> 
> 
> On 7/3/2013 6:38 PM, Henrique Dallazuanna wrote:
> > Try this:
> >
> >  as.formula(sprintf(" ~ %s", do.call(paste, c(lapply(mutual(3), paste,
> > collapse = ":"), sep = "+"))))
> >
> Thanks for this.  I encapsulated this as a function, loglin2formula()
> and a related function,
> loglin2string() to give a character string representation.
> They seem to work when used from the command line, but don't give
> what I need when I use it in another function.  I think it has something
> to do with the environment
> for the formula or how I pass it to MASS::loglm in my function
> test_loglm (below).
> 
> I'll demonstrate the problem first, then give the functions & test cases
> I'm using as
> runnable code.
> 
>  > joint(3, table=HairEyeColor)
> $term1
> [1] "Hair" "Eye"
> 
> $term2
> [1] "Sex"
> 
>  > loglin2formula(joint(3, table=HairEyeColor))
> ~Hair:Eye + Sex
> <environment: 0x0884a640>
>  > loglin2string(joint(3, table=HairEyeColor))
> [1] "[Hair,Eye] [Sex]"
> 
> These look like what I want, more or less; but, when I use these in the
> function test_loglm
> (also below) , the formula doesn't get resolved when I call loglm (it
> appears as
> formula = form), and the result of loglin2string gets garbled. The
> numerical results are
> correct; I'm concerned about the labeling in the computed loglm object.
> 
>  > test_loglm(HairEyeColor, type='joint')
> formula:
> ~Hair:Eye + Sex
> <environment: 0x08842de0>
> model.string:
> [1] "[~] [+,Hair:Eye,Sex]"                   ### I want "[Hair,Eye]
> [Sex]" here
> model:
> Call:
> loglm(formula = form, data = x)       ### I want formula = ~Hair:Eye +
> Sex here
> 
> Statistics:
>                        X^2 df  P(> X^2)
> Likelihood Ratio 19.85656 15 0.1775045
> Pearson          19.56712 15 0.1891745
>  >
> 
> ## --- functions and test cases, should be runnable (mod line folding)
> --- ###
> 
> #' convert a loglin model to a model formula for loglm
> 
> #' @param  x a list of terms in a loglinear model, such as returned by
> \code{joint}, \code{conditional}, \dots
> #' @source Code from Henrique Dallazuanna, <wwwhsd at gmail.com>, R-help
> 7-4-2013
> 
> loglin2formula <- function(x) {
>      terms <- lapply(x, paste, collapse = ":")
>      as.formula(sprintf(" ~ %s", do.call(paste, c(terms, sep = "+"))))
> }
> 
> #' convert a loglin model to a string, using bracket notation for the
> high-order terms
> 
> #' @param x a list of terms in a loglinear model, such as returned by
> \code{joint}, \code{conditional}, \dots
> #' @param brackets characters to use to surround model terms.
> #' @param sep characters used to separate factor names within a term
> #' @param collapse  characters used to separate terms
> #' @param abbrev
> 
> loglin2string <- function(x, brackets = c('[', ']'), sep=',', collapse='
> ', abbrev) {
>      if (length(brackets)==1 && (nchar(brackets)>1)) brackets <-
> unlist(strsplit(brackets, ""))
>      terms <- lapply(x, paste, collapse=sep)
>      terms <- paste(brackets[1], terms, brackets[2], sep='')
>      paste(terms, collapse= ' ')
> }
> 
> #' models of joint independence, of some factors wrt one or more other
> factors
> 
> #' @param nf number of factors for which to generate model
> #' @param table a contingency table used for factor names, typically the
> output from \code{\link[base]{table}}
> #' @param factors names of factors used in the model when \code{table}
> is not specified
> #' @param with    indices of the factors against which others are
> considered jointly independent
> #' @export
> 
> joint <- function(nf, table=NULL, factors=1:nf, with=nf) {
>      if (!is.null(table)) factors <- names(dimnames(table))
>      if (nf == 1) return (list(term1=factors[1]))
>      if (nf == 2) return (list(term1=factors[1], term2=factors[2]))
>      others <- setdiff(1:nf, with)
>      result <- list(term1=factors[others], term2=factors[with])
>      result
>    }
> 
> ### Test using these in another function
> 
> test_loglm <- function(
>      x, type = c("joint", "conditional"),
>      ...)
> {
>      nf <- length(dim(x))
>      factors <- names(dimnames(x))
>      type <- match.arg(type)
>      margins <- switch(type,
>        "joint" = joint(nf, factors=factors),
>        "conditional" = conditional(nf, factors=factors)
>        )
> 
>    form <- loglin2formula(margins);
>    cat("formula:\n"); print(form)
>    model.string <- loglin2string(form)
>    cat("model.string:\n"); print(model.string)
>    mod <- loglm(formula=form, data=x)
>    cat("model:\n"); print(mod)
>    invisible(list(form=form, model.string=model.string, mod=mod))
> }
> 
> ## tests
> 
> loglin2formula(joint(3, table=HairEyeColor))
> loglin2string(joint(3, table=HairEyeColor))
> test_loglm(HairEyeColor, type='joint')
> 
> 
> >
> >
> > On Wed, Jul 3, 2013 at 6:55 PM, Michael Friendly <friendly at yorku.ca
> > <mailto:friendly at yorku.ca>> wrote:
> >
> >     I'm developing some functions to create symbolic specifications
> >     for loglinear models of different types.
> >     I don't really know how to 'compute' with model formulas, so I've
> >     done this in the notation
> >     for stats::loglin(), which is a list of high-order terms in the model.
> >
> >     What I'd like is a function to turn the results of these into a
> >     model formula, suitable for
> >     MASS::loglm.  That's the reverse of what loglm does.
> >
> >     For example, the simplest versions of models for 3-way tables for
> >     joint,
> >      conditional, and marginal independence can be computed as
> >     follows. After each, I indicated
> >     the WANTED model formula I'd like from the result
> >
> >     > joint(3)
> >     $term1
> >     [1] 1 2
> >
> >     $term2
> >     [1] 3
> >
> >     WANTED:  ~ 1:2 + 3
> >
> >     > condit(3)
> >     $term1
> >     [1] 1 3
> >
> >     $term2
> >     [1] 2 3
> >
> >     WANTED: ~ 1:2 + 2:3
> >
> >     > mutual(3)
> >     $term1
> >     [1] 1
> >
> >     $term2
> >     [1] 2
> >
> >     $term3
> >     [1] 3
> >
> >     WANTED: ~ 1 + 2 + 3
> >
> >     In case anyone want to play with the code, here are the current,
> >     not too elegant definitions
> >     of the functions, and some further test cases,
> >
> >     # models of joint independence
> >       joint <- function(nf, factors=1:nf, with=nf) {
> >         if (nf == 1) return (list(term1=factors[1]))
> >         if (nf == 2) return (list(term1=factors[1], term2=factors[2]))
> >         others <- setdiff(1:nf, with)
> >         result <- list(term1=factors[others], term2=factors[with])
> >         result
> >       }
> >     # conditional independence
> >       condit <- function(nf, factors=1:nf, with=nf) {
> >         if (nf == 1) return (list(term1=factors[1]))
> >         if (nf == 2) return (list(term1=factors[1], term2=factors[2]))
> >         main <- setdiff(1:nf, with)
> >         others <- matrix(factors[with], length(with), length(main))
> >         result <- rbind(factors[main], others)
> >         result <- as.list(as.data.frame(result, stringsAsFactors=FALSE))
> >         names(result) <- paste('term', 1:length(result), sep='')
> >         result
> >       }
> >     # mutual independence
> >       mutual <- function(nf, factors=1:nf) {
> >         result <- sapply(factors[1:nf], list)
> >         names(result) <- paste('term', 1:length(result), sep='')
> >         result
> >       }
> >
> >     ### some comparisons
> >
> >     loglin(HairEyeColor, list(c(1, 2), c(1, 3), c(2, 3)))$lrt
> >     loglm(~1:2 + 1:3 +2:3, HairEyeColor)
> >
> >     # use factor names
> >     joint(3, factors=names(dimnames(HairEyeColor)))
> >     condit(3, factors=names(dimnames(HairEyeColor)))
> >
> >     loglin(HairEyeColor, joint(3))$lrt
> >     loglm(~1:2 + 3, HairEyeColor)
> >
> >     loglin(HairEyeColor, condit(3))$lrt
> >     loglm(~1:3 + 2:3, HairEyeColor)
> >
> >
> >
> >     --
> >     Michael Friendly     Email: friendly AT yorku DOT ca
> >     Professor, Psychology Dept. & Chair, Quantitative Methods
> >     York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> >     4700 Keele Street    Web: http://www.datavis.ca
> >     Toronto, ONT  M3J 1P3 CANADA
> >
> >     ______________________________________________
> >     R-help at r-project.org <mailto:R-help at r-project.org> mailing list
> >     https://stat.ethz.ch/mailman/listinfo/r-help
> >     PLEASE do read the posting guide
> >     http://www.R-project.org/posting-guide.html
> >     and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> > --
> > Henrique Dallazuanna
> > Curitiba-Paran?-Brasil
> > 25? 25' 40" S 49? 16' 22" O
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> 
> 	[[alternative HTML version deleted]]


From gunter.berton at gene.com  Fri Jul  5 23:30:57 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 5 Jul 2013 14:30:57 -0700
Subject: [R] Lattice barchart with error bars
In-Reply-To: <CADX6M3p9viLrmHB4ygZanwL8U4ZD9VwvsZn5cJhj8y5RDgoVyQ@mail.gmail.com>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
	<CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
	<CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>
	<7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>
	<CACk-te0+K7AbPXnHN1QvvLaqUr+5p2DdA6Dnza+nd=10NsaT-A@mail.gmail.com>
	<CADX6M3p9viLrmHB4ygZanwL8U4ZD9VwvsZn5cJhj8y5RDgoVyQ@mail.gmail.com>
Message-ID: <C117B96E-A475-4072-9EDA-22D5F7821EFE@gene.com>

This is not an R question.  Read the references.

Bert

Sent from my iPhone -- please excuse typos.

On Jul 5, 2013, at 12:15 PM, Shaun Jackman <sjackman at gmail.com> wrote:

> Hmm. Interesting point, Bert. I don't know whether the notches show
> the 95% confidence interval or the median, or the 95% confidence
> interval that two non-overlapping notches have different medians.
> You're saying it's the latter? Anyone know what the 95% confidence
> interval of the median would be?
> 
> Cheers,
> Shaun
> 
>> The notches (if requested) extend to +/-1.58 IQR/sqrt(n). This seems to be based on the same calculations as the formula with 1.57 in Chambers et al. (1983, p. 62), given in McGill et al. (1978, p. 16). They are based on asymptotic normality of the median and roughly equal sample sizes for the two medians being compared, and are said to be rather insensitive to the underlying distributions of the samples. The idea appears to be to give roughly a 95% confidence interval for the difference in two medians.
> 
> 
> On 5 July 2013 11:48, Bert Gunter <gunter.berton at gene.com> wrote:
>> Be careful!
>> 
>> You are talking about 2 different varieties of apples here. As I read
>> it, the CI's in the  cancer data, which I know is just for example
>> purposes, are CI's for the **individual means**; the notches in
>> boxplots are nonparametric and for 2 groups with roughly equal sample
>> sizes, "The idea appears to be to give roughly a 95% confidence
>> interval for the **difference** in two medians." (from
>> ?boxplot.stats). So I'm not sure which you want, but they are
>> certainly different (by a factor of around sqrt(2),right?), even if
>> both are for the mean or both are for the median.
>> 
>> Cheers,
>> Bert
>> 
>> On Fri, Jul 5, 2013 at 11:28 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>> 
>>> On Jul 5, 2013, at 11:15 AM, Shaun Jackman wrote:
>>> 
>>>> Hi Bert, Dennis,
>>>> 
>>>> I'll agree that using a barchart was a poor choice. I was in fact using a
>>>> notched bwplot to show the median and confidence interval of the median. In
>>>> this case it's the median and confidence interval that I want to highlight,
>>>> and I find that the visual noise of the box and whiskers is detracting from
>>>> the focus, and those wee notches are not much to focus on. So, I'd like to
>>>> draw a stripplot with error bars, preferably in Lattice. Let's call this a
>>>> TIE fighter plot. Any suggestions?
>>> 
>>> I like the TIE fighter label. Try this:
>>> 
>>> library(latticeExtra)
>>> data(USCancerRates)
>>> segplot(reorder(factor(county), rate.male) ~ LCL95.male + UCL95.male,
>>>        data = subset(USCancerRates, state == "Washington"),
>>>        draw.bands = FALSE, centers = rate.male,
>>>        segments.fun = panel.arrows, ends = "both",
>>>        angle = 90, length = 1, unit = "mm")
>>> 
>>> It's what Sarkar has recommended in the past when this request has been posted.
>>> 
>>> --
>>> David
>>> 
>>> 
>>>> Cheers,
>>>> Shaun
>>>> 
>>>> On 4 July 2013 18:00, Dennis Murphy <djmuser at gmail.com> wrote:
>>>> 
>>>>> If you consult the lattice package help, you'll discover there is no
>>>>> panel_errorbar() function, which would imply the package developers
>>>>> have a distaste for that type of graphic. If you fish around the
>>>>> R-help archives, though, you might be able to find someone who wrote a
>>>>> function to do error bars in lattice. (Use a searchable archive such
>>>>> as Nabble to hunt for it.)
>>>>> 
>>>>> Error bar plots are easier to do in the ggplot2 package, since there
>>>>> is a specific function to generate the error bar 'geometry'
>>>>> (geom_errorbar). See http://docs.ggplot2.org/current/ for an expanded
>>>>> version of the package help pages, which include the graphs generated
>>>>> by the code. I believe there's also a base graphics version that you
>>>>> can get from the gplots package, but I don't know a lot about it.
>>>>> 
>>>>> Dennis
>>>>> 
>>>>> On Thu, Jul 4, 2013 at 2:53 PM, Shaun Jackman <sjackman at gmail.com> wrote:
>>>>>> Hi,
>>>>>> 
>>>>>> I'd like to draw a lattice barchart of means with error bars to show
>>>>>> the standard deviation. I have the barchart, how do I add the error
>>>>>> bars?
>>>>>> 
>>>>>> require(datasets)
>>>>>> require(lattice)
>>>>>> x <- aggregate(weight ~ Diet, ChickWeight, function(x) c(mean=mean(x),
>>>>>> sd=sd(x)))
>>>>>> barchart(weight[,'mean'] ~ Diet, x)
>>>>>> 
>>>>>> Thanks,
>>>>>> Shaun
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>>      [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> David Winsemius
>>> Alameda, CA, USA
>> 
>> 
>> 
>> --
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> 
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From nt1006 at mun.ca  Fri Jul  5 15:40:17 2013
From: nt1006 at mun.ca (nt1006)
Date: Fri, 5 Jul 2013 06:40:17 -0700 (PDT)
Subject: [R] geeglm
Message-ID: <1373031617844-4670936.post@n4.nabble.com>

How to extract the Std.err and the alpha estimated value from the geeglm
function in R.



--
View this message in context: http://r.789695.n4.nabble.com/geeglm-tp4670936.html
Sent from the R help mailing list archive at Nabble.com.


From ac331 at le.ac.uk  Fri Jul  5 12:44:02 2013
From: ac331 at le.ac.uk (alR)
Date: Fri, 5 Jul 2013 03:44:02 -0700 (PDT)
Subject: [R] save rds as text
Message-ID: <1373021042683-4670925.post@n4.nabble.com>

I created a table like this:

Analysis of Variance Table
 
 Response: dati
 Df Sum Sq Mean Sq F value Pr(>F)    
 groups     2    114   57.00      76 4.134e-11 ***
   Residuals 24     18    0.75                      
---
   Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1 

and saved it to a variable called k.

When I tried to save the variable to txt file using

 dput(k, file = "..\\Readouts\\anova_spike_number.txt")

or

 lapply(k, write, "..\\Readouts\\anova_spike_number.txt", append=TRUE)  

 it destroys the formatting.

Then I saved to rds using

 saveRDS(k, "..\\Readouts\\anova_spike_number.rds")


and the format was preserved.

I would like to convert the rds to txt preserving the table format. Or save
it as excel file or pdf would also be fine.
(If there is a way to avoid passing through rds file better, but  still OK
using rds).

Thank you very much.

Best regards,


Alberto
 
 



--
View this message in context: http://r.789695.n4.nabble.com/save-rds-as-text-tp4670925.html
Sent from the R help mailing list archive at Nabble.com.


From nashjc at uottawa.ca  Fri Jul  5 15:16:59 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Fri, 05 Jul 2013 09:16:59 -0400
Subject: [R] Non-linear modelling with several variables including a
 categorical variable
In-Reply-To: <51D6C6C9.7020700@uottawa.ca>
References: <51D6C6C9.7020700@uottawa.ca>
Message-ID: <51D6C74B.9010703@uottawa.ca>

Off list I sent the OP a note that wrapnls() from nlmrt calls nls after
nlxb finishes. This is not, of course, super-efficient, but returns the
nls-structured answer.

JN

On 13-07-05 06:00 AM, r-help-request at r-project.org wrote:
> Message: 49
> Date: Fri, 5 Jul 2013 08:30:39 +0700
> From: Robbie Weterings<robbie.weterings at gmail.com>
> To: "Prof J C Nash (U30A)"<nashjc at uottawa.ca>,r-help at r-project.org
> Subject: Re: [R] Non-linear modelling with several variables including
> 	a categorical variable
> Message-ID:
> 	<CAFe5dHZdXFbFtwKmTE1_QPi1rqNGsd+=82TPrOYfs6mg6zmiCg at mail.gmail.com>
> Content-Type: text/plain
>
> Dear Prof. Nash,
>
> I tried to run nls with the nlxb function and as you mention it is fairly
> slower in terms of running the code. However, if I would have used this
> function earlier I would have saved a lot of time trying to find the start
> values. The output looks a little bit sloppy but I think it is very usefull
> to use in combination with nls.
>
> Thanks
> Robbie


From y_refai at hotmail.com  Fri Jul  5 15:35:32 2013
From: y_refai at hotmail.com (Yasmine Refai)
Date: Fri, 5 Jul 2013 13:35:32 +0000
Subject: [R] Data Package Query
In-Reply-To: <29D67F767D9.000002A6jrkrideau@inbox.com>
References: <a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>,
	<1371725996.86004.yahoomailneo@web122106.mail.ne1.yahoo.com>,
	<dub405-eas306523ef12f1c6c0f82988d90750@phx.gbl>,
	<1371711263.96641.yahoomailneo@web122105.mail.ne1.yahoo.com>,
	<1371633615.23367.yahoomailneo@web160101.mail.bf1.yahoo.com>,
	<51ccbcc1.6040508@xtra.co.nz>,
	<29D67F767D9.000002A6jrkrideau@inbox.com>
Message-ID: <DUB118-W3F74D4ECAF8FD5B2093EE907D0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/b76c660e/attachment.pl>

From antony.akkara at ge.com  Fri Jul  5 17:38:12 2013
From: antony.akkara at ge.com (R_Antony)
Date: Fri, 5 Jul 2013 08:38:12 -0700 (PDT)
Subject: [R] Filter Dataframe for Alarm for each column.
Message-ID: <1373038692448-4670950.post@n4.nabble.com>

Hi here i have a dataframe called MyDF.

a<-c(1,1,1,1,1,0,0,0,1,1)
b<-c(1,1,0,1,1,0,0,0,1,1)
c<-c(1,1,1,1,1,1,1,0,1,1)
d<-c(1,1,1,1,1,1,1,1,0,1)
MyDF<-data.frame(DWATT=a,TNH=b,CSGV=c,BIX=d)

My requirement is, here i need a function - to get for a particular row
number(s), when particular column(s) value change from zero to one  (for the
first change).

For example,  Using MyDF,

DWATT TNH CSGV BIX
1   1    1   1
1   1    1   1
1   0    1   1
1   1    1   1
1   1    1   1
0   0    1   1
0   0    1   1
0   0    0   1
1   1    1   0
1   1    1   1

Here i want to know, the row number where TNH-column and BIX-column values
change happening from one-to-zero for the first time.

Answer should be  a dataframe with single row.
So here answer should return a dataframe like this.

TNH  BIX
----    ------
3      9


i used some ways to get a solution using loops. But there is a bulk files
with bulk rows to process.
So performace is most important. Could someone please suggest better ideas ?

Thanks,
Antony.





--
View this message in context: http://r.789695.n4.nabble.com/Filter-Dataframe-for-Alarm-for-each-column-tp4670950.html
Sent from the R help mailing list archive at Nabble.com.


From 538280 at gmail.com  Fri Jul  5 23:39:47 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 5 Jul 2013 15:39:47 -0600
Subject: [R] list construction with automatic names
In-Reply-To: <d96e4314e0b590761e5c9800bca1d77f.squirrel@webmail.xs4all.nl>
References: <1c8c09d8979274ab425ae9e48346cd49.squirrel@webmail.xs4all.nl>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9F872D5@GOLD.corp.lgc-group.com>
	<d96e4314e0b590761e5c9800bca1d77f.squirrel@webmail.xs4all.nl>
Message-ID: <CAFEqCdy3N2W1CdYU8oA8abb1y84EXKk_GyxadfxxKzCLgjMfEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/110f6360/attachment.pl>

From eric.archer at noaa.gov  Fri Jul  5 23:47:50 2013
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Fri, 5 Jul 2013 14:47:50 -0700
Subject: [R] Transferring commas in character vector to expression
Message-ID: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/7d6114cd/attachment.pl>

From bbolker at gmail.com  Sat Jul  6 00:12:24 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 5 Jul 2013 22:12:24 +0000
Subject: [R] Subset and order
References: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>	<51D721FB.1050800@sapo.pt>
	<A01F0E9C-31F4-4F61-B517-127F641BFF92@ucla.edu>
	<10d901ce79b9$c034cec0$409e6c40$@tamu.edu>
Message-ID: <loom.20130706T001150-235@post.gmane.org>

David Carlson <dcarlson <at> tamu.edu> writes:

> 
> It may be that single and efficient are opposing goals. Two steps
> lets you create the subset and then just order each query.
> Alternatively, if the data do not change often, create an ordered
> version and query that.
> 

   I don't know the data.table package well, but it seems as though 
this might be an appropriate job for it.


From smartpink111 at yahoo.com  Sat Jul  6 00:24:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 5 Jul 2013 15:24:41 -0700 (PDT)
Subject: [R] Operations on a big data frame
Message-ID: <1373063081.28105.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
dat1<- read.table(text="
?? P1_prom Nom
1 -6.17 Pt_00187
2 -6.17 Pt_00187
3 -6.17 Pt_00187
4 -6.17 Pt_00187
5 -6.17 Pt_00187
6 -6.17 Pt_01418
7 -5.77 Pt_01418
8 -5.37 Pt_01418
9 -4.97 Pt_01418
10 -4.57 Pt_01418
",sep="",header=TRUE,stringsAsFactors=FALSE) 

library(zoo)
?dat1$PT_promMean<-rollmean(dat1$P1_prom,5,fill=NA,align="left")
?dat1
#?? P1_prom????? Nom PT_promMean
#1??? -6.17 Pt_00187?????? -6.17
#2??? -6.17 Pt_00187?????? -6.17
#3??? -6.17 Pt_00187?????? -6.09
#4??? -6.17 Pt_00187?????? -5.93
#5??? -6.17 Pt_00187?????? -5.69
#6??? -6.17 Pt_01418?????? -5.37
#7??? -5.77 Pt_01418????????? NA
#8??? -5.37 Pt_01418????????? NA
#9??? -4.97 Pt_01418????????? NA
#10?? -4.57 Pt_01418????????? NA
A.K.


Hello all, 

I have a big data frame that looks like this: 
? ? ? ? P1_prom	Nom 
1	-6.17	Pt_00187 
2	-6.17	Pt_00187 
3	-6.17	Pt_00187 
4	-6.17	Pt_00187 
5	-6.17	Pt_00187 
6	-6.17	Pt_01418 
7	-5.77	Pt_01418 
8	-5.37	Pt_01418 
9	-4.97	Pt_01418 
10	-4.57	Pt_01418 
- 
- 
- 
25000 

where Nom represents a point in a map, and P1_prom represents 
the value of an operation we perfomed on each point (note that we 
performed 5 repetitions for each point, hence, each point has 5 values). 
What I am trying to do, with no success, is to create a new column, 
in which each row corresponds to the mean value of P1_prom for each 
point. So basically what I need the program to do is to write in the 
first row of the new column the average of the first five values of 
P1_prom, in the second row the average of the next five values, and so 
on. 
Could anybody guide me on how to do this. 
Thank you very much, 
Veronica


From smartpink111 at yahoo.com  Sat Jul  6 00:51:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 5 Jul 2013 15:51:21 -0700 (PDT)
Subject: [R] IF function
Message-ID: <1373064681.51600.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
May be this helps.? 

dat1<- read.table(text="
Col1,Col2
High value,9
Low value,0
High value,7
Low value,0
Low value,0
No data,0
High value,8
No data,0
",sep=",",header=TRUE,stringsAsFactors=FALSE)
dat1$Col2[dat1$Col1=="No data"]<- NA
?dat1
#??????? Col1 Col2
#1 High value??? 9
#2? Low value??? 0
#3 High value??? 7
#4? Low value??? 0
#5? Low value??? 0
#6??? No data?? NA
#7 High value??? 8
#8??? No data?? NA

A.K.


Hello, 

I am an R novice so excuse me if this is woefully straight forward, but I have tried the help files to no avail. 

I am trying to identify cells in 1 column with the value of 'No data', so I can change the values in the next column to 'Null'. 

Currently I am struggling with the data set, as it assigns both 'No data' and 'Low values' as zero which skews my analysis. 

I've tried a number of different attempts but just get the error unexpected symbol ? 



From ejoffe at hotmail.com  Sat Jul  6 02:16:25 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Fri, 5 Jul 2013 19:16:25 -0500
Subject: [R] problem with BootCV for coxph in pec after feature selection
	with glmnet (lasso)
Message-ID: <DUB114-DS1F100CBC06DECF52D62DBCA7E0@phx.gbl>

Hi,

I am attempting to evaluate the prediction error of a coxph model that was
built after feature selection with glmnet.

In the preprocessing stage I used na.omit (dataset) to remove NAs.
I reconstructed all my factor variables into binary variables with dummies
(using model.matrix)
I then used glmnet lasso to fit a cox model and select the best performing
features.
Then I fit a coxph model using only these feature.

When I try to evaluate the model using pec and a bootstrap I get an error
that the prediction matrix has wrong dimensions.
Suddenly the cox object has 318 variables instead of 356 variables in the
dataset.
I don't know why this is happening.
The cox object I assign to pec and the dataframe are both of the same size.
However, once pec refits the model its size changes (356 -> 318 variables).
Apparently something is happening during the bootstrap sampling that removes
some variables.
As mentioned, I used na.omit in the preprocessing so there should not be any
NAs.

Here are some details from my workspace:
Reformat_dataSet: 368 obs. Of 356 variables
print (glmnet.cox) ----> 354 df, p=1  n= 368, number of events= 288 (354 df
= 354 variables + time and status => 356 variables)

Here is the pec function and the error:
pec.f <- as.formula(Hist(time,status) ~ 1)
brierGlmnet <- pec(list(glmnet.cox), data = reformat_Dataset,
splitMethod="BootCV", B=50, formula = pec.f)

>  Error in predictSurvProb.coxph(object = structure(list(coefficients =
structure(c(-4.27787223119601,  : 
    Prediction matrix has wrong dimensions:
   368 rows and 318 columns.
    But requested are predicted probabilities for
   118 subjects (rows) in newdata and 356 time points (columns)
   This may happen when some covariate values are missing in newdata!?
 
Here are the relevant sections of the code:

trainSet <- na.omit (dataset)
  
#creat Y (survival matrix) for glmnet
  surv_obj <- Surv(trainSet$time,trainSet$status) 
  
    
  ## tranform categorical variables into binary variables with dummy for
trainSet
  predict_matrix <- model.matrix(~ ., data=trainSet, 
                                 contrasts.arg = lapply
(trainSet[,sapply(trainSet, is.factor)], contrasts, contrasts=FALSE))
  
 
 ## remove the statu/time variables from the predictor matrix (x) for glmnet
  predict_matrix <- subset (predict_matrix, select=c(-time,-status))
  
  
## create a glmnet cox object using lasso regularization
  glmnet.obj <- glmnet (predict_matrix, surv_obj, family="cox")
  
  
# find lambda for which dev.ratio is max 
  max.dev.index <- which.max(glmnet.obj$dev.ratio) 
  optimal.lambda <- glmnet.obj$lambda[max.dev.index] 
  
 
 # take beta for optimal lambda 
  optimal.beta  <- glmnet.obj$beta[,max.dev.index] 
  
  
# find non zero beta coef 
  nonzero.coef <- abs(optimal.beta)>0 
  selectedBeta <- optimal.beta[nonzero.coef] 
  
  # take only covariates for which beta is not zero 
  selectedVar   <- predict_matrix[,nonzero.coef] 
  
  # create a dataframe for trainSet with time, status and selected variables
in binary representation for evaluation in pec
  reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
  
  # create coxph object with pre-defined coefficients 
  glmnet.cox <- coxph(surv_obj ~ selectedVar, init=selectedBeta,iter=0)

## Brier score for the cox-glmnet model
  brierGlmnet <- pec(list(glmnet.cox), data = reformat_Dataset,
splitMethod="BootCV", B=50,
                     formula = pec.f)

Thank you !!!


From cvo at delta.dk  Sat Jul  6 10:31:26 2013
From: cvo at delta.dk (cvo)
Date: Sat, 6 Jul 2013 01:31:26 -0700 (PDT)
Subject: [R] Error when building a custom package
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4AC9FEEC70@GOLD.corp.lgc-group.com>
References: <1372954370691-4670866.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9FEEB8F@GOLD.corp.lgc-group.com>
	<1D12B7DCCF7AF749812D4783BB7019A0016DB5A0@frej.deltams.local>
	<A4E5A0B016B8CB41A485FC629B633CED4AC9FEEC70@GOLD.corp.lgc-group.com>
Message-ID: <1D12B7DCCF7AF749812D4783BB7019A0016E0037@frej.deltams.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130706/6fada1e2/attachment.pl>

From patrickjoyce82 at gmail.com  Fri Jul  5 23:55:51 2013
From: patrickjoyce82 at gmail.com (Patrick Joyce)
Date: Fri, 5 Jul 2013 17:55:51 -0400
Subject: [R] surface plots using wireframe, color at high res,
	grid at low res?
Message-ID: <CDA3D5F2-C69C-4D10-8C31-C56F6B027758@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130705/ccb1e853/attachment.pl>

From smartpink111 at yahoo.com  Sat Jul  6 00:03:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 5 Jul 2013 15:03:55 -0700 (PDT)
Subject: [R] geeglm
In-Reply-To: <1373031617844-4670936.post@n4.nabble.com>
References: <1373031617844-4670936.post@n4.nabble.com>
Message-ID: <1373061835.19520.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,

Using the example from ?geeglm()
?summary(gee1)$corr
?# ??? Estimate Std.err
#alpha??? 0.957 0.00979
A.K.

----- Original Message -----
From: nt1006 <nt1006 at mun.ca>
To: r-help at r-project.org
Cc: 
Sent: Friday, July 5, 2013 9:40 AM
Subject: [R] geeglm

How to extract the Std.err and the alpha estimated value from the geeglm
function in R.



--
View this message in context: http://r.789695.n4.nabble.com/geeglm-tp4670936.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ejoffe at hotmail.com  Sat Jul  6 14:04:46 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Sat, 6 Jul 2013 07:04:46 -0500
Subject: [R] coxph won't converge when including categorical (factor)
	variables
Message-ID: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130706/141a2fe1/attachment.pl>

From friendly at yorku.ca  Sat Jul  6 14:30:56 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 6 Jul 2013 08:30:56 -0400
Subject: [R] fitting the null loglinear model with MASS::loglm??
Message-ID: <51D80E00.4010007@yorku.ca>

The null loglinear model is an intercept-only model for log frequency, 
log(f) = \mu
For a one-way table the test of the null model is the same as the 
chisq.test.
This can be fit using loglin(), but I don't think there is any way to 
specify this using MASS::loglm

 > t1<- margin.table(Titanic,1)
 > t1
Class
  1st  2nd  3rd Crew
  325  285  706  885

 > loglin(t1, NULL)
0 iterations: deviation
$lrt
[1] 475.8113

$pearson
[1] 467.8069

$df
[1] 3

$margin
NULL

 > chisq.test(t1)

         Chi-squared test for given probabilities

data:  t1
X-squared = 467.8069, df = 3, p-value < 2.2e-16

The problem is that loglm() allows the 'convenience' of using integers 
rather than names to specify
terms in the model, e.g., 1+2+3, so there is no way AFAICS to specify an 
intercept-only model.
That is, below, the model ~1 is actually the saturated model for the 
one-way table.


 > loglm(~NULL, t1)
Error in denumerate.formula(formula) : node stack overflow
 > loglm(~0, t1)
Error in double(nmar) : vector size cannot be NA/NaN
 > loglm(~1, t1)
Call:
loglm(formula = ~1, data = t1)

Statistics:
                  X^2 df P(> X^2)
Likelihood Ratio   0  0        1
Pearson            0  0        1
 >

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From mario.lavezzi at unipa.it  Sat Jul  6 14:36:15 2013
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Sat, 6 Jul 2013 14:36:15 +0200
Subject: [R] matching similar character strings
In-Reply-To: <1372826855.77040.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>
	<1371821358.6821.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<51C46C83.4030001@unipa.it>
	<1371828336.16438.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOZPQW6OG7yO_-ssKa+Axr=CsDrJiEaN7SkaCY9RFPz3tLiRyw@mail.gmail.com>
	<1372826855.77040.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <CAOZPQW6Hieh_4zRAnXEs+VD7LM9mjZ=_yXW0XCirhZyhLF-=-w@mail.gmail.com>

Dear Arun,

thank you so much! The code you suggest captures what we have in mind.
However, what we are looking for is something a bit more general
(sorry: I realised that maybe this was not so clear from the
beginning).

In particular:

- in F1_ex the address in the "Indirizzo" field could be spelled more
irregularly (ex: "Via De Amicis 18", "V. De Amicis 18", "Via E. De
Amicis 18", etc.)

- in F2 the classification of the portions of the street is based on
odd and even numbers. For example, if we had number "15" in F1 it
should be matched to row 3 and not to row 2 of F2 (I actually provided
a wrong example with number 65: row 2 of F1_ex is currently matched to
row 6 of F2_ex which contains even numbers. Moreover, there are no odd
street numbers in this street higher than 37)

Thank you very much once again

Mario


On Wed, Jul 3, 2013 at 6:47 AM, arun <smartpink111 at yahoo.com> wrote:
> Dear Mario,
> Not sure if this is what you wanted:
> F1_ex<- read.table(text="
>    Nome.azienda;Indirizzo
> 17;Alterego;Via Edmondo De Amicis, 18
> 18;Alterego;Via Edmondo De Amicis, 65
> ",sep=";",header=TRUE,stringsAsFactors=FALSE)
>
> F2_ex<- read.table(text="
>    CODICE;STRADA;AREADICIRCOLAZIONE;NUMBER1;BARRATO1;NUMBER2;BARRATO2;SECTION
> 1;15620;VIA;DE AMICIS EDMONDO;1;;5;;1288
> 2;15620;VIA;DE AMICIS EDMONDO;2;;34;;1261
> 3;15620;VIA;DE AMICIS EDMONDO;7;;17;;1287
> 4;15620;VIA;DE AMICIS EDMONDO;36;;62;;1264
> 5;15620;VIA;DE AMICIS EDMONDO;37;;37;;1287
> 6;15620;VIA;DE AMICIS EDMONDO;64;;84;;1262
> ",sep=";",header=TRUE,stringsAsFactors=FALSE)
> library(stringr)
>  vec1<-sapply(lapply(toupper(str_trim(gsub("[0-9,]","",F1_ex[,2]))),word,c(1,3,4,2)),paste,collapse=" ")
>  vec2<- as.numeric(gsub("\\D+","",F1_ex[,2]))
>  F1_ex[,1]<-F2_ex[sapply(vec2,function(x) which((x>F2_ex[,4] & x< F2_ex[,6]) & paste(F2_ex[,2],F2_ex[,3])%in%vec1)),"SECTION"]
>  F1_ex
> #   Nome.azienda                 Indirizzo
> #17         1261 Via Edmondo De Amicis, 18
> #18         1262 Via Edmondo De Amicis, 65
> A.K.
>
>
>
>
>
> ----- Original Message -----
> From: A M Lavezzi <mario.lavezzi at unipa.it>
> To: r-help <r-help at r-project.org>
> Cc:
> Sent: Tuesday, July 2, 2013 10:22 AM
> Subject: Re: [R] matching similar character strings
>
> Dear Arun,
> please excuse me for this late reply, we had to stop working on this
> temporaririly.
>
> Let me reproduce here two examples of rows from F1 and F2 (sorry, but
> with dput() I am not able to produce a clear example)
>
>> F1_ex
>         Nome.azienda                   Indirizzo
> 17     Alterego             Via Edmondo De Amicis, 18
>
> On row 17 of F1 we have a firm named ("Nome.azienda") 'Alterego' whose
> address ("indirizzo") is  'Via Edmondo de Amicis, 18'
>
> Below I reproduce the portion of F2 with information on the street
> mentioned in F1_ex$Indirizzo.
>
>> F2_ex
>
>   CODICE    STRADA       AREADICIRCOLAZIONE          NUMBER1 BARRATO1
> NUMBER2 BARRATO2 SECTION
> 1  15620        VIA            DE AMICIS EDMONDO                     1
>                           5                                 1288
> 2  15620        VIA            DE AMICIS EDMONDO                     2
>                          34                                 1261
> 3  15620        VIA            DE AMICIS EDMONDO                     7
>                          17                                 1287
> 4  15620        VIA            DE AMICIS EDMONDO                    36
>                          62                                1264
> 5  15620        VIA            DE AMICIS EDMONDO                    37
>                          37                                1287
> 6  15620        VIA            DE AMICIS EDMONDO                    64
>                          84                                1262
>
>
> Line 1 says that the portion of VIA DE AMICIS EDMONDO
> ("STRADA"+"AREADICIRCOLAZIONE"), with street numbers between 1 and 5
> belongs to SECTION 1288 (these are census sections). ("BARRATO1" and
> "BARRATO2" refer to the letter in street numbers such as 12/A, 28/D,
> etc. In the present example they are empty)
>
> Line 2 says that the portion of VIA DE AMICIS EDMONDO, with street
> numbers between 2 and 34 belongs to SECTION 1261,
>
> etc.
>
> Our problem is to assign SECTION 1261 to 'Alterego', exploting the
> information on its address. The problem is that the syntax of the
> street address in F1 is different from the syntax in F2.
>
> Hope I have clarified the issue
>
> thanks a lot
> Mario
>
>
>
>
>
>
>
>
> On Fri, Jun 21, 2013 at 5:25 PM, arun <smartpink111 at yahoo.com> wrote:
>> Dear Mario,
>> I didn't find any difference between 1st and 2nd row of F2, except for the last three columns.  Question is that why should F1 1st row should be merged to 2nd row of F2 instead of 1st row of F2. In your previous example, you mentioned about A1, A2, ... and B1, B2, etc.  Here, it is not provided.  As I mentioned before, it is better to provide the output of ?dput() from a subset of dataset.
>> dput(head(F1,20))
>>
>> dput(head(F2,20))
>>
>> #so that there would be atleast some matching pairs within the example dataset.  Also, please post it to r-help as I will be able to check only after a couple of hours
>> Tx.
>> Arun
>>
>>
>>
>> ----- Original Message -----
>> From: Mario Lavezzi <mario.lavezzi at unipa.it>
>> To: arun <smartpink111 at yahoo.com>
>> Cc:
>> Sent: Friday, June 21, 2013 11:08 AM
>> Subject: Re: [R] matching similar character strings
>>
>> dear Arun
>> thank you very much. Let me explain the problem:
>>
>> Imagine that a portion of the row in F1 is:
>>
>> ----------------------------
>> F1
>>
>> 1) Street | J.F. Kennedy | 30
>> ----------------------------
>>
>> it means that our unit of interest (a firm) has address: J.F. Kennedy Street, 30
>>
>>
>> The F2 database contains the list of all the streets of the city, with additional variables characterizing that street (Census data). The database
>> contains sometimes street divided in some parts, according to the street number. For example:
>>
>>
>> Example of three rows of F2 concerning Kennedy street and Kennedy Road:
>>
>> F2
>>
>> 1) Street | Kennedy John Fitzgerald  | 1  | 20 | A12
>> 2) Street | Kennedy John Fitzgerald  | 20 | 50 | A15
>> 3) Road   | Kennedy John             | 1  | 50 | A23
>>
>>
>> We'd like to have an algorithm able to understand that, notwithstanding the name is slightly different, element A15 should be added to row 1) of F1,
>> producing an output such as:
>>
>> 1) Street | J.F. Kennedy | 30 | A15
>>
>>
>> hope this clarifies the issue.
>>
>> thanks a lot! Mario
>>
>>
>>
>> Il 21/06/2013 15:29, arun ha scritto:
>>> HI,
>>> Could you dput() your example datasets and also your expected result?  The Census section is not clear.
>>> A.K.
>>>
>>>
>>>
>>>
>>> ----- Original Message -----
>>> From: A M Lavezzi <mario.lavezzi at unipa.it>
>>> To: r-help <r-help at r-project.org>
>>> Cc:
>>> Sent: Friday, June 21, 2013 5:56 AM
>>> Subject: [R] matching similar character strings
>>>
>>> Hello everybody
>>>
>>> I have this problem: I need to match an addresses database F1 with the
>>> information contained in a toponymic database F2.
>>>
>>> The format of F1 is given by three columns and 800 rows, with the
>>> columns being:
>>>
>>> A1. Street/Road/Avenue
>>> A2. Name
>>> A3. Number
>>>
>>> Consider for instance Avenue J. Kennedy , 3011. In F1 this is:
>>>
>>> A1. Avenue
>>> A2. J. Kennedy
>>> A3. 3011
>>>
>>> The format of F2 file is instead given by 20000 rows and five columns:
>>>
>>> B1. Street/Road/Avenue
>>> B2. Name
>>> B3. Starting Street Number
>>> B4. Ending Street Number
>>> B5. Census section
>>>
>>> So my problem is attributing the  B5 Census section to every
>>> observation of F1 if: A1=B1, A2=B2, and A3 is comprised between B3 and
>>> B4.
>>>
>>> The problem is that while the information in A2 is irregularly
>>> recorded, B2 has a given format that is Family name (space) Given
>>> name.
>>>
>>> So I could have that while in B2 the information is:
>>>
>>> Kennedy John
>>>
>>> In A2 it could be:
>>>
>>> John Kennedy
>>> JF Kennedy
>>> J. Kennedy
>>>
>>> and so on.
>>>
>>> Thanks,
>>>
>>> Mario
>>>
>>
>> --
>> PLEASE NOTICE NEW EMAIL ADDRESS AND HOME PAGE URL
>>
>> Andrea Mario Lavezzi
>> Dipartimento di Studi su Politica, Diritto e Societ?
>> Universit? di Palermo
>> Piazza Bologni 8
>> 90134 Palermo, Italy
>> tel. ++39 091 23892208
>> fax ++39 091 6111268
>> skype: lavezzimario
>> email: mario.lavezzi (at) unipa.it
>> web: http://www.unipa.it/~mario.lavezzi
>
>
>
> --
> Andrea Mario Lavezzi
> Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
> Sezione Diritto e Societ?
> Universit? di Palermo
> Piazza Bologni 8
> 90134 Palermo, Italy
> tel. ++39 091 23892208
> fax ++39 091 6111268
> skype: lavezzimario
> email: mario.lavezzi (at) unipa.it
> web: http://www.unipa.it/~mario.lavezzi
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Andrea Mario Lavezzi
Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi


From info at aghmed.fsnet.co.uk  Sat Jul  6 14:56:10 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Sat, 06 Jul 2013 13:56:10 +0100
Subject: [R] Meta-analysis on a repeated measures design with multiple
 trials per subject using metafor
In-Reply-To: <51D69CDB.8010506@uva.nl>
References: <51D415D6.5070201@uva.nl>
	<077E31A57DA26E46AB0D493C9966AC730D833E9764@UM-MAIL4112.unimaas.nl>
	<51D69CDB.8010506@uva.nl>
Message-ID: <Zen-1UvS2F-0008KR-PL@smarthost01a.mail.zen.net.uk>

At 11:15 05/07/2013, Marc Heerdink wrote:
>Dear Wolfgang and other readers of the r-help list,
>
>Thank you very much for your suggestion. Unfortunately, the data 
>that I have can not be described with a table such as the one you 
>have made, because there's no identical trial under both treatment 1 
>and treatment 2. To explain, let me explain a bit more about the experiments:
>
>* All subjects were presented with the same number of trials
>* Half of these trials were preceded by a prime from category 1 
>(treatment 1) and half of these trials with a prime from category 2 
>(treatment 2)
>* Subjects were asked to respond to these trials (a unique stimulus 
>for each trial) by pressing one of two keys on the keyboard.
>
>Because everything was randomized, I can only calculate the total 
>number of times a certain response was used under each type of 
>trial. There is no pairing of trials under two treatments, so I am 
>forced to use the marginal totals from your table.

But presumably you could calculate some statistic suitable for 
summarising the relevant features here? Difference in proportions, 
odds ratio, ...


>I have uploaded a simplified version of the data for one experiment 
>to illustrate this (the actual experiments have five treatments and 
>some have moderators):
>https://www.dropbox.com/s/rhgo12cm1asl6x8/exampledata.csv
>
>This is the script that I used to generate the data:
>https://www.dropbox.com/s/7uyeaexhnqiiy55/exampledata.R
>
>The problem thus appears to lie mainly in estimating the variance of 
>the proportion difference from only the marginal totals, is that 
>correct? Is there a way to calculate it from only the marginal totals?
>
>One alternative that I have tried over the last few days, is to use 
>the b parameter of interest and it's corresponding standard error 
>from the lme4 regression output that I use to analyse the individual 
>experiments. Then, I use rma(yi, sei) to do a meta-analysis on these 
>parameters. I am not sure this is correct though, since it takes 
>into account between-subjects variance (through a random effect for 
>subject), and it is sensitive to the covariates/moderators I include 
>in the models that I get the b parameters from.

So you end up with 5 values of b? The fact that they adjust for 
different moderators does not seem an issue to me, indeed it could be 
argued to be an advantage of the meta-analytic approach here.


>Thanks again for your help, and for any suggestions for solving this problem!

I think we are all assuming you have different participants in each 
experiment but I thought I would raise that as a question.

>Regards,
>Marc
>
>
>On 07/04/2013 11:21 PM, Viechtbauer Wolfgang (STAT) wrote:
>>Dear Marc,
>>
>>Let me see if I understand the type of data you have. You say that 
>>you have 5 experiments. And within each experiment, you have n 
>>subjects and for each subject, you have data in the form described 
>>in your post. Now for each subject, you want to calculate some kind 
>>of measure that quantifies how much more likely it was that 
>>subjects gave/chose response 2 under treatment 2 versus treatment 
>>1. So, you would have n such values. And then you want to pool 
>>those values over the n subjects within a particular experiment and 
>>then ultimately over the 5 experiments. Is that correct so far?
>>
>>Assuming I got this right, let me ask you about those data that you 
>>have for each subject. In particular, are these paired data? In 
>>other words, is there are 1:1 relationship between the 30 trials 
>>under treatment 1 versus treatment 2? Or phrased yet another way, 
>>can you construct a table like this for every subject:
>>
>>                  trt 2
>>               ------------
>>               resp1 resp2
>>trt 1 resp1  a     b      10
>>        resp2  c     d      20
>>               20    10     30
>>
>>Note that I added the marginal counts based on your example data, 
>>but this is not sufficient to reconstruct how often response 1 was 
>>chosen for the same trial under both treatment 1 and treatment 2 
>>(cell "a"). And so on for the other 3 cells.
>>
>>If all of this applies, then essentially you are dealing with 
>>dependent proportions and you can calculate the difference y = 
>>(20/30)-(10/30) as you have done. The corresponding sampling 
>>variance can be estimated with v = var(y) = (a+b)*(c+d)/t^3 + 
>>(a+c)*(b+d)/t^3 - 2*(a*d/t^3 - b*c/t^3) (where t is the number of 
>>trials, i.e., 30 in the example above). See, for example, section 
>>10.1.1. in Agresti (2002) (Categorical data analysis, 2nd ed.).
>>
>>So, ultimately, you will have n values of y and v for a particular 
>>experiment and then the same thing for all 5 experiments. You can 
>>then pool those values with rma(yi, vi) in metafor (yi and vi being 
>>the vectors of the y and v values). You probably want to add a 
>>factor to the model that indicates which experiment those values 
>>came from. So, something like: rma(yi, vi, mods = ~ factor(experiment)).
>>
>>Well, I hope that I understood your data correctly.
>>
>>Best,
>>Wolfgang
>>
>>--
>>Wolfgang Viechtbauer, Ph.D., Statistician
>>Department of Psychiatry and Psychology
>>School for Mental Health and Neuroscience
>>Faculty of Health, Medicine, and Life Sciences
>>Maastricht University, P.O. Box 616 (VIJV1)
>>6200 MD Maastricht, The Netherlands
>>+31 (43) 388-4170 | http://www.wvbauer.com
>>________________________________________
>>From: r-help-bounces at r-project.org [r-help-bounces at r-project.org] 
>>On Behalf Of Marc Heerdink [m.w.heerdink at uva.nl]
>>Sent: Wednesday, July 03, 2013 2:15 PM
>>To: r-help at r-project.org
>>Subject: [R] Meta-analysis on a repeated measures design with 
>>multiple trials per subject using metafor
>>
>>Hi all,
>>
>>I am currently attempting to compile a summary of a series of five
>>psychological experiments, and I am trying to do this using the metafor
>>package. However, I am quite unsure which of the scenarios described in
>>the metafor help pages applies to these data, because it is a repeated
>>measures design, with multiple trials in each condition.
>>
>>Assume that for every participant, I have a basic contingency table such
>>as this one:
>>
>>                  treatment
>>                  1       2
>>response
>>1               10      20
>>2               20      10
>>
>>(if this ASCII version does not work, I have 30 trials in each
>>treatment, and participants give either response 1 or 2; the exact
>>numbers don't matter)
>>
>>The problem that I am trying to solve is how to convert these numbers to
>>an effect size estimate that I can use with metafor.
>>
>>As far as I understand it, I can only use it to get an effect size for
>>outcomes that are dichotomous; i.e., either 1 or 0 for any subject.
>>However, I have proportion data for every participant.
>>
>>I have considered and tried these strategies:
>>
>>1. Base the effect size on within-participant proportion differences.
>>That is, in the table above, the treatment effect would be
>>(20/30)-(10/30) = 1/3; and I would take the M and SD of these values to
>>estimate a study-level effect ("MN" measure in metafor).
>>
>>2. Use the overall treatment * response contingency table, ignoring the
>>fact that these counts come from different participants ("PHI" or "OR"
>>measures in metafor). In a study with 10 participants, I would get cell
>>counts around 150.
>>
>>However, from the research I've done into this topic, I know that 1) is
>>not applicable to (as far as I understand) an odds ratio, and I suspect
>>2) overestimates the effect.
>>
>>A third method would be to use the regression coefficients, that I can
>>easily obtain since I have all the raw data that I need. However, it is
>>unclear to me whether and if yes, how I can use these in the metafor
>>package.
>>
>>   From my understanding of another message about this topic I found on
>>this list (1), I understand that having access to the raw data is an
>>advantage, but I am not sure whether the scenario mentioned applies to
>>my situation.
>>
>>1:
>>http://r.789695.n4.nabble.com/meta-analysis-with-repeated-measure-designs-td2252644.html
>>
>>I would very much appreciate any suggestions or hints on this topic.
>>
>>Regards,
>>Marc
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>--
>Marc Heerdink, MSc. (PhD. candidate)
>Dept. of Social Psychology
>University of Amsterdam
>http://home.medewerker.uva.nl/m.w.heerdink/
>http://www.easi-lab.nl/
>
>

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From gunter.berton at gene.com  Sat Jul  6 15:42:15 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 6 Jul 2013 06:42:15 -0700
Subject: [R] coxph won't converge when including categorical (factor)
	variables
In-Reply-To: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
References: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
Message-ID: <CACk-te2G50+QHZ3tB_RMMxhrvNd0Lrt-Kgg8uCfePhHaWuO72Q@mail.gmail.com>

Hint: Why do you think no one replied?

1. That it converged with one model/fitting algorithm and not with
another is useless.

2. This cannot possibly be answered without your data.

3. A guess: you are overfitting -- glmnet regularizes and will
therefore fit (highly) correlated regressors coxph won't. .

-- Bert

On Sat, Jul 6, 2013 at 5:04 AM, E Joffe <ejoffe at hotmail.com> wrote:
> Hello,
>
>
>
> [rephrasing and reposting  of a previous question (that was not answered)
> with new information]
>
>
>
> I have a dataset of 371 observations.
>
> When I run coxph with numeric variables it works fine.
>
> However, when I try to add factor (categorical) variables it returns "Ran
> out of iterations and the model did not converge"
>
>
>
> Of note, when I restructure all factors to binary variables with dummy and
> use glmnet-lasso the model converges.
>
>
>
> Here are examples of the code and output (including summary description of
> the variables):
>
>> maxSTree.cox <- coxph (Surv(time,status)~Chemo_Simple, data=dataset)
>
>
>
> Warning message:
>
> In fitter(X, Y, strats, offset, init, control, weights = weights,  :
>
>   Ran out of iterations and did not converge
>
>
>
>> summary (dataset$Chemo_Simple)
>
>                         Anthra_HDAC       Anthra_Plus       ArsenicAtra
> ATRA           ATRA_GO
>
>                 0               163                 2                12
> 0                 2
>
>          ATRA_IDA Demeth_HistoneDAC          Flu_HDAC     Flu_HDAC_plus
> HDAC_Clof         HDAC_only
>
>                 0                34                37                 4
> 24                 1
>
>         HDAC_Plus        LowArac       LowDAC_Clof         MYLO_IL11
> Phase1
>
>                 4                 8                30                 5
> 5
>
>               SCT    StdARAC_Anthra      StdAraC_Plus          Targeted
> VNP40101M
>
>                 0                 0                 0                13
> 23
>
>
>
>
>
> HELP !!!!
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From marc_schwartz at me.com  Sat Jul  6 15:46:06 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sat, 06 Jul 2013 08:46:06 -0500
Subject: [R] coxph won't converge when including categorical
	(factor)	variables
In-Reply-To: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
References: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
Message-ID: <80F175FF-1DBF-49C6-A295-E20CA112DE2E@me.com>

On Jul 6, 2013, at 7:04 AM, E Joffe <ejoffe at hotmail.com> wrote:

> Hello,
> 
> 
> 
> [rephrasing and reposting  of a previous question (that was not answered)
> with new information]
> 
> 
> 
> I have a dataset of 371 observations.
> 
> When I run coxph with numeric variables it works fine.
> 
> However, when I try to add factor (categorical) variables it returns "Ran
> out of iterations and the model did not converge"
> 
> 
> 
> Of note, when I restructure all factors to binary variables with dummy and
> use glmnet-lasso the model converges.
> 
> 
> 
> Here are examples of the code and output (including summary description of
> the variables):
> 
>> maxSTree.cox <- coxph (Surv(time,status)~Chemo_Simple, data=dataset)
> 
> 
> 
> Warning message:
> 
> In fitter(X, Y, strats, offset, init, control, weights = weights,  :
> 
>  Ran out of iterations and did not converge
> 
> 
> 
>> summary (dataset$Chemo_Simple)
> 
>                        Anthra_HDAC       Anthra_Plus       ArsenicAtra
> ATRA           ATRA_GO 
> 
>                0               163                 2                12
> 0                 2 
> 
>         ATRA_IDA Demeth_HistoneDAC          Flu_HDAC     Flu_HDAC_plus
> HDAC_Clof         HDAC_only 
> 
>                0                34                37                 4
> 24                 1 
> 
>        HDAC_Plus        LowArac       LowDAC_Clof         MYLO_IL11
> Phase1 
> 
>                4                 8                30                 5
> 5 
> 
>              SCT    StdARAC_Anthra      StdAraC_Plus          Targeted
> VNP40101M 
> 
>                0                 0                 0                13
> 23 
> 
> 
> 
> 
> 
> HELP !!!!
> 


You have 371 observations, but did not indicate how many events you have in that dataset. A cross tabulation of the 'status' factor with Chemo_Simple is likely to be enlightening to get a sense of the distribution of events for each level of Chemo_Simple.

Chemo_Simple has a number of levels with rather low counts (ignoring the levels with 0's for the moment), which is likely to be a part of the problem. There is likely to be an issue fitting the model for some of these levels, bearing in mind that your "reference level" of Anthra_HDAC has a large proportion of the observations and with the default treatment contrasts, each of the other levels will be compared to it.

You should also run:

  dataset$Chemo_Simple <- factor(dataset$Chemo_Simple)

to get rid of the unused factor levels. A quick check of the coxph() code versus, for example, lm()/glm(), reveals that while the latter will drop unused factor levels when creating the internal model dataframe, the former will not. A check of some test output here with coxph() suggests that the unused factor levels will simply appear as NA's in the coxph() output without affecting the levels that are present, but it will be cleaner to remove them a priori.

It is also likely that you don't have enough events to handle the effective covariate degrees of freedom that this single factor model will have. By my count (the formatting above is corrupted), you have 16 non-zero factor levels, which would be 15 covariate degrees of freedom consumed by this single factor. A general rule of thumb for Cox models (and logistic regression) is to have 20 events per covariate degree of freedom to avoid overfitting, which means that you would really need 300 "events". In this context, events are the smaller count of the two possible levels of "status". Since you only have 371 total observations, there is no way that you could have 300 events, since you would need to have at least 600 observations. Thus, it is likely that you are attempting to overfit the model to the data as well.

The issue of using glmnet on a matrix of separate dummy variables and it working is likely to be an outcome of the LASSO method penalizing/shrinking the factor levels that are irrelevant to have coefficients of 0. Thus, I would envision that the effective number of your factor levels is reduced as a consequence, allowing the model to be fit.

You likely need to consider collapsing some of the low count factor levels into an "Other" category, if it makes contextual sense to do so for your data. 

Regards,

Marc Schwartz


From tchen10 at qub.ac.uk  Sat Jul  6 16:33:46 2013
From: tchen10 at qub.ac.uk (tong)
Date: Sat, 6 Jul 2013 07:33:46 -0700 (PDT)
Subject: [R] Missing value or an infinity produced when evaluating the model
Message-ID: <1373121226402-4671010.post@n4.nabble.com>

Dear all,

I want to estimate a nlrq using normal copula.The model is

 
<http://r.789695.n4.nabble.com/file/n4671010/%E6%97%A0%E6%A0%87%E9%A2%98.png> 

I want to estimate the  delta in the above formula.

The full codes I use are as following:

> NormModel<-function(x, delta, mu, sigma, tau){
+ z<-qnorm(pnorm(delta*qnorm(pnorm(x))+sqrt((1-delta*delta)*qnorm(tau)))
+ mu+sigma*z
+ }

> fit<-nlrq(y~NormModel(x, delta, mu, sigma, tau=0.5), data=dailyvix,
> tau=0.5,
+ start=list(delta=-0.5, mu=0, sigma=0.1),
+ trace=TRUE)

However,  I get:

127.2531 :  -0.5  0.0  0.1 
Error in numericDeriv(form[[3]], names(ind), env) : 
  Missing value or an infinity produced when evaluating the model
In addition: Warning message:
In sqrt(1 - delta * delta) : NaNs produced
Error in nlrq.calc(m, ctrl, trace) : optim unable to find valid step size


I think I do sth wrong with the  "start=list".
I try different initial values but fail to find proper ones.

In addition,  the coefficient delta is expected to range from (-1,1).
how can I deal with the "In sqrt(1 - delta * delta) : NaNs produced"?

thanks,

Tong



--
View this message in context: http://r.789695.n4.nabble.com/Missing-value-or-an-infinity-produced-when-evaluating-the-model-tp4671010.html
Sent from the R help mailing list archive at Nabble.com.


From ubuntu.diego at gmail.com  Sat Jul  6 17:08:49 2013
From: ubuntu.diego at gmail.com (Diego Ubuntu)
Date: Sat, 6 Jul 2013 12:08:49 -0300
Subject: [R] Kriging Package Cryptic Error Message
Message-ID: <CAH03yymJyccOr-ZFGMJ==T86S0UiGxGH9krtZ2dhuhbJ=UaGEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130706/1ef74e84/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sat Jul  6 17:25:51 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 06 Jul 2013 08:25:51 -0700
Subject: [R] matching similar character strings
In-Reply-To: <CAOZPQW6Hieh_4zRAnXEs+VD7LM9mjZ=_yXW0XCirhZyhLF-=-w@mail.gmail.com>
References: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>
	<1371821358.6821.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<51C46C83.4030001@unipa.it>
	<1371828336.16438.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOZPQW6OG7yO_-ssKa+Axr=CsDrJiEaN7SkaCY9RFPz3tLiRyw@mail.gmail.com>
	<1372826855.77040.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOZPQW6Hieh_4zRAnXEs+VD7LM9mjZ=_yXW0XCirhZyhLF-=-w@mail.gmail.com>
Message-ID: <0d7acfdc-c4ed-432c-ad88-270a8810a791@email.android.com>

The intent of this list is to help you help yourself. If you spend the time to take Arun's ideas and run with therm, then you will do us and yourself a favor. We will benefit because you can then help others with similar problems, and you will benefit because you don't need to worry about failure to communicate out delays from us. Even if you cannot completely figure it out on your own yet, giving us your attempt every tone you post can demonstrate your participation and help clarify what your intent is. But asking us to just "do it" for you is not in the spirit of this list.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

A M Lavezzi <mario.lavezzi at unipa.it> wrote:

>Dear Arun,
>
>thank you so much! The code you suggest captures what we have in mind.
>However, what we are looking for is something a bit more general
>(sorry: I realised that maybe this was not so clear from the
>beginning).
>
>In particular:
>
>- in F1_ex the address in the "Indirizzo" field could be spelled more
>irregularly (ex: "Via De Amicis 18", "V. De Amicis 18", "Via E. De
>Amicis 18", etc.)
>
>- in F2 the classification of the portions of the street is based on
>odd and even numbers. For example, if we had number "15" in F1 it
>should be matched to row 3 and not to row 2 of F2 (I actually provided
>a wrong example with number 65: row 2 of F1_ex is currently matched to
>row 6 of F2_ex which contains even numbers. Moreover, there are no odd
>street numbers in this street higher than 37)
>
>Thank you very much once again
>
>Mario
>
>
>On Wed, Jul 3, 2013 at 6:47 AM, arun <smartpink111 at yahoo.com> wrote:
>> Dear Mario,
>> Not sure if this is what you wanted:
>> F1_ex<- read.table(text="
>>    Nome.azienda;Indirizzo
>> 17;Alterego;Via Edmondo De Amicis, 18
>> 18;Alterego;Via Edmondo De Amicis, 65
>> ",sep=";",header=TRUE,stringsAsFactors=FALSE)
>>
>> F2_ex<- read.table(text="
>>   
>CODICE;STRADA;AREADICIRCOLAZIONE;NUMBER1;BARRATO1;NUMBER2;BARRATO2;SECTION
>> 1;15620;VIA;DE AMICIS EDMONDO;1;;5;;1288
>> 2;15620;VIA;DE AMICIS EDMONDO;2;;34;;1261
>> 3;15620;VIA;DE AMICIS EDMONDO;7;;17;;1287
>> 4;15620;VIA;DE AMICIS EDMONDO;36;;62;;1264
>> 5;15620;VIA;DE AMICIS EDMONDO;37;;37;;1287
>> 6;15620;VIA;DE AMICIS EDMONDO;64;;84;;1262
>> ",sep=";",header=TRUE,stringsAsFactors=FALSE)
>> library(stringr)
>> 
>vec1<-sapply(lapply(toupper(str_trim(gsub("[0-9,]","",F1_ex[,2]))),word,c(1,3,4,2)),paste,collapse="
>")
>>  vec2<- as.numeric(gsub("\\D+","",F1_ex[,2]))
>>  F1_ex[,1]<-F2_ex[sapply(vec2,function(x) which((x>F2_ex[,4] & x<
>F2_ex[,6]) & paste(F2_ex[,2],F2_ex[,3])%in%vec1)),"SECTION"]
>>  F1_ex
>> #   Nome.azienda                 Indirizzo
>> #17         1261 Via Edmondo De Amicis, 18
>> #18         1262 Via Edmondo De Amicis, 65
>> A.K.
>>
>>
>>
>>
>>
>> ----- Original Message -----
>> From: A M Lavezzi <mario.lavezzi at unipa.it>
>> To: r-help <r-help at r-project.org>
>> Cc:
>> Sent: Tuesday, July 2, 2013 10:22 AM
>> Subject: Re: [R] matching similar character strings
>>
>> Dear Arun,
>> please excuse me for this late reply, we had to stop working on this
>> temporaririly.
>>
>> Let me reproduce here two examples of rows from F1 and F2 (sorry, but
>> with dput() I am not able to produce a clear example)
>>
>>> F1_ex
>>         Nome.azienda                   Indirizzo
>> 17     Alterego             Via Edmondo De Amicis, 18
>>
>> On row 17 of F1 we have a firm named ("Nome.azienda") 'Alterego'
>whose
>> address ("indirizzo") is  'Via Edmondo de Amicis, 18'
>>
>> Below I reproduce the portion of F2 with information on the street
>> mentioned in F1_ex$Indirizzo.
>>
>>> F2_ex
>>
>>   CODICE    STRADA       AREADICIRCOLAZIONE          NUMBER1 BARRATO1
>> NUMBER2 BARRATO2 SECTION
>> 1  15620        VIA            DE AMICIS EDMONDO                    
>1
>>                           5                                 1288
>> 2  15620        VIA            DE AMICIS EDMONDO                    
>2
>>                          34                                 1261
>> 3  15620        VIA            DE AMICIS EDMONDO                    
>7
>>                          17                                 1287
>> 4  15620        VIA            DE AMICIS EDMONDO                   
>36
>>                          62                                1264
>> 5  15620        VIA            DE AMICIS EDMONDO                   
>37
>>                          37                                1287
>> 6  15620        VIA            DE AMICIS EDMONDO                   
>64
>>                          84                                1262
>>
>>
>> Line 1 says that the portion of VIA DE AMICIS EDMONDO
>> ("STRADA"+"AREADICIRCOLAZIONE"), with street numbers between 1 and 5
>> belongs to SECTION 1288 (these are census sections). ("BARRATO1" and
>> "BARRATO2" refer to the letter in street numbers such as 12/A, 28/D,
>> etc. In the present example they are empty)
>>
>> Line 2 says that the portion of VIA DE AMICIS EDMONDO, with street
>> numbers between 2 and 34 belongs to SECTION 1261,
>>
>> etc.
>>
>> Our problem is to assign SECTION 1261 to 'Alterego', exploting the
>> information on its address. The problem is that the syntax of the
>> street address in F1 is different from the syntax in F2.
>>
>> Hope I have clarified the issue
>>
>> thanks a lot
>> Mario
>>
>>
>>
>>
>>
>>
>>
>>
>> On Fri, Jun 21, 2013 at 5:25 PM, arun <smartpink111 at yahoo.com> wrote:
>>> Dear Mario,
>>> I didn't find any difference between 1st and 2nd row of F2, except
>for the last three columns.  Question is that why should F1 1st row
>should be merged to 2nd row of F2 instead of 1st row of F2. In your
>previous example, you mentioned about A1, A2, ... and B1, B2, etc. 
>Here, it is not provided.  As I mentioned before, it is better to
>provide the output of ?dput() from a subset of dataset.
>>> dput(head(F1,20))
>>>
>>> dput(head(F2,20))
>>>
>>> #so that there would be atleast some matching pairs within the
>example dataset.  Also, please post it to r-help as I will be able to
>check only after a couple of hours
>>> Tx.
>>> Arun
>>>
>>>
>>>
>>> ----- Original Message -----
>>> From: Mario Lavezzi <mario.lavezzi at unipa.it>
>>> To: arun <smartpink111 at yahoo.com>
>>> Cc:
>>> Sent: Friday, June 21, 2013 11:08 AM
>>> Subject: Re: [R] matching similar character strings
>>>
>>> dear Arun
>>> thank you very much. Let me explain the problem:
>>>
>>> Imagine that a portion of the row in F1 is:
>>>
>>> ----------------------------
>>> F1
>>>
>>> 1) Street | J.F. Kennedy | 30
>>> ----------------------------
>>>
>>> it means that our unit of interest (a firm) has address: J.F.
>Kennedy Street, 30
>>>
>>>
>>> The F2 database contains the list of all the streets of the city,
>with additional variables characterizing that street (Census data). The
>database
>>> contains sometimes street divided in some parts, according to the
>street number. For example:
>>>
>>>
>>> Example of three rows of F2 concerning Kennedy street and Kennedy
>Road:
>>>
>>> F2
>>>
>>> 1) Street | Kennedy John Fitzgerald  | 1  | 20 | A12
>>> 2) Street | Kennedy John Fitzgerald  | 20 | 50 | A15
>>> 3) Road   | Kennedy John             | 1  | 50 | A23
>>>
>>>
>>> We'd like to have an algorithm able to understand that,
>notwithstanding the name is slightly different, element A15 should be
>added to row 1) of F1,
>>> producing an output such as:
>>>
>>> 1) Street | J.F. Kennedy | 30 | A15
>>>
>>>
>>> hope this clarifies the issue.
>>>
>>> thanks a lot! Mario
>>>
>>>
>>>
>>> Il 21/06/2013 15:29, arun ha scritto:
>>>> HI,
>>>> Could you dput() your example datasets and also your expected
>result?  The Census section is not clear.
>>>> A.K.
>>>>
>>>>
>>>>
>>>>
>>>> ----- Original Message -----
>>>> From: A M Lavezzi <mario.lavezzi at unipa.it>
>>>> To: r-help <r-help at r-project.org>
>>>> Cc:
>>>> Sent: Friday, June 21, 2013 5:56 AM
>>>> Subject: [R] matching similar character strings
>>>>
>>>> Hello everybody
>>>>
>>>> I have this problem: I need to match an addresses database F1 with
>the
>>>> information contained in a toponymic database F2.
>>>>
>>>> The format of F1 is given by three columns and 800 rows, with the
>>>> columns being:
>>>>
>>>> A1. Street/Road/Avenue
>>>> A2. Name
>>>> A3. Number
>>>>
>>>> Consider for instance Avenue J. Kennedy , 3011. In F1 this is:
>>>>
>>>> A1. Avenue
>>>> A2. J. Kennedy
>>>> A3. 3011
>>>>
>>>> The format of F2 file is instead given by 20000 rows and five
>columns:
>>>>
>>>> B1. Street/Road/Avenue
>>>> B2. Name
>>>> B3. Starting Street Number
>>>> B4. Ending Street Number
>>>> B5. Census section
>>>>
>>>> So my problem is attributing the  B5 Census section to every
>>>> observation of F1 if: A1=B1, A2=B2, and A3 is comprised between B3
>and
>>>> B4.
>>>>
>>>> The problem is that while the information in A2 is irregularly
>>>> recorded, B2 has a given format that is Family name (space) Given
>>>> name.
>>>>
>>>> So I could have that while in B2 the information is:
>>>>
>>>> Kennedy John
>>>>
>>>> In A2 it could be:
>>>>
>>>> John Kennedy
>>>> JF Kennedy
>>>> J. Kennedy
>>>>
>>>> and so on.
>>>>
>>>> Thanks,
>>>>
>>>> Mario
>>>>
>>>
>>> --
>>> PLEASE NOTICE NEW EMAIL ADDRESS AND HOME PAGE URL
>>>
>>> Andrea Mario Lavezzi
>>> Dipartimento di Studi su Politica, Diritto e Societ?
>>> Universit? di Palermo
>>> Piazza Bologni 8
>>> 90134 Palermo, Italy
>>> tel. ++39 091 23892208
>>> fax ++39 091 6111268
>>> skype: lavezzimario
>>> email: mario.lavezzi (at) unipa.it
>>> web: http://www.unipa.it/~mario.lavezzi
>>
>>
>>
>> --
>> Andrea Mario Lavezzi
>> Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
>> Sezione Diritto e Societ?
>> Universit? di Palermo
>> Piazza Bologni 8
>> 90134 Palermo, Italy
>> tel. ++39 091 23892208
>> fax ++39 091 6111268
>> skype: lavezzimario
>> email: mario.lavezzi (at) unipa.it
>> web: http://www.unipa.it/~mario.lavezzi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From pensterfuzzer at yahoo.de  Sat Jul  6 17:37:22 2013
From: pensterfuzzer at yahoo.de (Werner W.)
Date: Sat, 6 Jul 2013 16:37:22 +0100
Subject: [R] R book or other materials for teaching a one week class on data
	analysis
Message-ID: <1373125042.43428.YahooMailNeo@web172306.mail.ir2.yahoo.com>

Dear Rusers,

I am starting to develop a one week course in which I want to cover an R programming introduction and go over data analysis / statistics / econometrics incl. visualization and maybe reproducible research as an extra. The goal is to give research students a kick start with R so that they can use it productively for their thesis work and add or refresh some statistics / analysis / econometrics skills.


I have collected some materials from the web etc. which will be helpful but it probably would be good to have one main book or other reference which the students can hold on to as a reference or guideline over the course.

Would anyone have a good suggestion what book to use or even experience with using one in a similar course?

Thank you very much for any ideas!
Werner



From jrkrideau at inbox.com  Sat Jul  6 18:06:09 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 6 Jul 2013 08:06:09 -0800
Subject: [R] save rds as text
In-Reply-To: <1373021042683-4670925.post@n4.nabble.com>
Message-ID: <836CE9D8128.000003A4jrkrideau@inbox.com>

You might want to have a look at the xtable package 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ac331 at le.ac.uk
> Sent: Fri, 5 Jul 2013 03:44:02 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] save rds as text
> 
> I created a table like this:
> 
> Analysis of Variance Table
> 
>  Response: dati
>  Df Sum Sq Mean Sq F value Pr(>F)
>  groups     2    114   57.00      76 4.134e-11 ***
>    Residuals 24     18    0.75
> ---
>    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> 
> and saved it to a variable called k.
> 
> When I tried to save the variable to txt file using
> 
>  dput(k, file = "..\\Readouts\\anova_spike_number.txt")
> 
> or
> 
>  lapply(k, write, "..\\Readouts\\anova_spike_number.txt", append=TRUE)
> 
>  it destroys the formatting.
> 
> Then I saved to rds using
> 
>  saveRDS(k, "..\\Readouts\\anova_spike_number.rds")
> 
> 
> and the format was preserved.
> 
> I would like to convert the rds to txt preserving the table format. Or
> save
> it as excel file or pdf would also be fine.
> (If there is a way to avoid passing through rds file better, but  still
> OK
> using rds).
> 
> Thank you very much.
> 
> Best regards,
> 
> 
> Alberto
> 
> 
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/save-rds-as-text-tp4670925.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From friendly at yorku.ca  Sat Jul  6 18:16:10 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Sat, 6 Jul 2013 12:16:10 -0400
Subject: [R] R book or other materials for teaching a one week class on
 data analysis
In-Reply-To: <1373125042.43428.YahooMailNeo@web172306.mail.ir2.yahoo.com>
References: <1373125042.43428.YahooMailNeo@web172306.mail.ir2.yahoo.com>
Message-ID: <51D842CA.8050403@yorku.ca>

How about Fox & Weisberg Companion to Applied Regression (& the car 
package).  John also has some short course materials on his web site

On 7/6/2013 11:37 AM, Werner W. wrote:
> Dear Rusers,
>
> I am starting to develop a one week course in which I want to cover an R programming introduction and go over data analysis / statistics / econometrics incl. visualization and maybe reproducible research as an extra. The goal is to give research students a kick start with R so that they can use it productively for their thesis work and add or refresh some statistics / analysis / econometrics skills.
>
>
> I have collected some materials from the web etc. which will be helpful but it probably would be good to have one main book or other reference which the students can hold on to as a reference or guideline over the course.
>
> Would anyone have a good suggestion what book to use or even experience with using one in a similar course?
>
> Thank you very much for any ideas!
> Werner
>
>


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From jdnewmil at dcn.davis.CA.us  Sat Jul  6 18:26:35 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 06 Jul 2013 09:26:35 -0700
Subject: [R] coxph won't converge when including categorical
	(factor)	variables
In-Reply-To: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
References: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
Message-ID: <5adc3d5d-3fd5-4bf7-8517-e2f9f545ceac@email.android.com>

I don't know much about your problem, but if you want help you are going to need to learn to communicate effectively. This may help:

http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

E Joffe <ejoffe at hotmail.com> wrote:

>Hello,
>
> 
>
>[rephrasing and reposting  of a previous question (that was not
>answered)
>with new information]
>
> 
>
>I have a dataset of 371 observations.
>
>When I run coxph with numeric variables it works fine.
>
>However, when I try to add factor (categorical) variables it returns
>"Ran
>out of iterations and the model did not converge"
>
> 
>
>Of note, when I restructure all factors to binary variables with dummy
>and
>use glmnet-lasso the model converges.
>
> 
>
>Here are examples of the code and output (including summary description
>of
>the variables):
>
>> maxSTree.cox <- coxph (Surv(time,status)~Chemo_Simple, data=dataset)
>
> 
>
>Warning message:
>
>In fitter(X, Y, strats, offset, init, control, weights = weights,  :
>
>  Ran out of iterations and did not converge
>
> 
>
>> summary (dataset$Chemo_Simple)
>
>                        Anthra_HDAC       Anthra_Plus       ArsenicAtra
>ATRA           ATRA_GO 
>
>                0               163                 2                12
>0                 2 
>
>         ATRA_IDA Demeth_HistoneDAC          Flu_HDAC     Flu_HDAC_plus
>HDAC_Clof         HDAC_only 
>
>                0                34                37                 4
>24                 1 
>
>        HDAC_Plus        LowArac       LowDAC_Clof         MYLO_IL11
>Phase1 
>
>                4                 8                30                 5
>5 
>
>              SCT    StdARAC_Anthra      StdAraC_Plus          Targeted
>VNP40101M 
>
>                0                 0                 0                13
>23 
>
> 
>
> 
>
>HELP !!!!
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Jul  6 18:39:30 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 6 Jul 2013 08:39:30 -0800
Subject: [R] Data Package Query
In-Reply-To: <DUB118-W3F74D4ECAF8FD5B2093EE907D0@phx.gbl>
References: <1371725996.86004.yahoomailneo@web122106.mail.ne1.yahoo.com>
	<29d67f767d9.000002a6jrkrideau@inbox.com>
	<1371711263.96641.yahoomailneo@web122105.mail.ne1.yahoo.com>
	<1371633615.23367.yahoomailneo@web160101.mail.bf1.yahoo.com>
	<dub405-eas306523ef12f1c6c0f82988d90750@phx.gbl>
	<51ccbcc1.6040508@xtra.co.nz>
	<a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>
Message-ID: <83B778F9281.000003D8jrkrideau@inbox.com>

John Kane
Kingston ON Canada

-----Original Message-----
From: y_refai at hotmail.com
Sent: Fri, 5 Jul 2013 13:35:32 +0000
To: jrkrideau at inbox.com, rolf.turner at xtra.co.nz, jdnewmil at dcn.davis.ca.us
Subject: RE: [R] Data Package Query

Hello,

When I run the below syntax:
Trial<-read.table("Trial.txt",header=TRUE)
Trial
save.image(file="Trial.RData")
load("Trial.RData")
fit<-logistf(data=Trial, y~x1+x2)
summary(fit)
AIC(fit)

I am getting the below error:
> AIC(fit)
Error in UseMethod("logLik") : 
? no applicable method for 'logLik' applied to an object of class "logistf"

Can you please help with that?

Regards,
Yasmine

> Date: Sat, 29 Jun 2013 05:05:28 -0800
> From: jrkrideau at inbox.com
> Subject: Re: [R] Data Package Query
> To: y_refai at hotmail.com; rolf.turner at xtra.co.nz; jdnewmil at dcn.davis.ca.us
> CC: r-help at r-project.org
> 
> 
> I don't know what you think data(Trial) is doing but what it in fact is doing is trying to load a stored data set called Trial and it does not exist. Have a look at ?data to see what I mean.
> 
> In your program data(Trial) is redundant, well actually closer to meaningless. 
> 
> Trial is already loaded since you created it in the read statement
> 
> John Kane
> Kingston ON Canada
> 

Well, currently not.  We have no idea of what your data looks like and you have not told us what packages you are loading , especially where the function logistf() is coming from. 

We need a better constructed question to be able to help.

Please read https://github.com/hadley/devtools/wiki/Reproducibility and
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

In particular I suspect that we need to see some sample data.  Use dput() to supply some. That is issue the command dput(Trial) and copy the results into your email.

Also list any require() or library() calls.

> 
> > -----Original Message-----
> > From: y_refai at hotmail.com
> > Sent: Fri, 28 Jun 2013 12:31:11 +0000
> > To: rolf.turner at xtra.co.nz, jdnewmil at dcn.davis.ca.us
> > Subject: Re: [R] Data Package Query
> > 
> > hello,
> > 
> > please advice what is wrong at the below syntax:
> > "Trial<-read.table("Trial.txt",header=TRUE)
> > Trial
> > save.image(file="Trial.RData")
> > data(Trial)
> > fit<-logistf(data=Trial, y~x1+x2)
> > "
> > 
> > and here is the error I get:
> > "Warning message:
> > In data(Trial) : data set ?Trial? not found
> > "
> > 
> > regards,
> > yasmine
> > 
> > 
> >> Date: Fri, 28 Jun 2013 10:29:21 +1200
> >> From: rolf.turner at xtra.co.nz
> >> To: jdnewmil at dcn.davis.ca.us
> >> CC: y_refai at hotmail.com; r-help at r-project.org
> >> Subject: Re: [R] Data Package Query
> >> 
> >> On 28/06/13 04:47, Jeff Newmiller wrote:
> >> 
> >> <SNIP>
> >>> A common error by beginners (which may or may not be your problem in
> >>> this case) is to create a variable called "data". Unfortunately this
> >>> hides the function named "data" and from that time forward that R
> >>> session doesn't work when you type example code that uses the data
> >>> function.
> >> 
> >> <SNIP>
> >> 
> >> This is simply not true. I believe it *used* to be true, sometime
> >> waaaaayyyy back,
> >> but hasn't been true for years. The R language is much cleverer now.
> >> If there
> >> is a function "melvin()" somewhere on the search path and also a data
> >> object
> >> "melvin" (earlier on the search path) then doing
> >> 
> >> melvin(<whatever>)
> >> 
> >> will correctly call the function melvin() with no complaints. The R
> >> language
> >> "can tell" by the parentheses that you mean the *function* melvin and
> >> not the
> >> data object "melvin".
> >> 
> >> E.g.
> >> 
> >> data <- 42
> >> require(akima)
> >> akima
> >> Error: object 'akima' not found
> >> data(akima) # No error message, nor nothin'!
> >> akima
> >> # The data set "akima" is displayed.
> >> 
> >> All that being said it is ***BAD PRACTICE***, just in terms of
> >> comprehensibility
> >> and avoiding confusion, to give a data set set the same name as a
> >> function
> >> (either built in, or one of your own).
> >> 
> >> fortune("dog")
> >> 
> >> is relevant.
> >> 
> >> cheers,
> >> 
> >> Rolf Turner
> >> 
> > 
> > [[alternative HTML version deleted]]
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ____________________________________________________________
> FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!
> Check it out at http://www.inbox.com/marineaquarium
> 
>

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From gunter.berton at gene.com  Sat Jul  6 18:56:38 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 6 Jul 2013 09:56:38 -0700
Subject: [R] R book or other materials for teaching a one week class on
 data analysis
In-Reply-To: <51D842CA.8050403@yorku.ca>
References: <1373125042.43428.YahooMailNeo@web172306.mail.ir2.yahoo.com>
	<51D842CA.8050403@yorku.ca>
Message-ID: <CACk-te2XCU=_JRa3gQxGikWo7gVYdN+ek2yAW=FPmH5qhkDKQQ@mail.gmail.com>

Have you looked at:

http://www.r-project.org/

under the "Books" page?

-- Bert

On Sat, Jul 6, 2013 at 9:16 AM, Michael Friendly <friendly at yorku.ca> wrote:
> How about Fox & Weisberg Companion to Applied Regression (& the car
> package).  John also has some short course materials on his web site
>
> On 7/6/2013 11:37 AM, Werner W. wrote:
>>
>> Dear Rusers,
>>
>> I am starting to develop a one week course in which I want to cover an R
>> programming introduction and go over data analysis / statistics /
>> econometrics incl. visualization and maybe reproducible research as an
>> extra. The goal is to give research students a kick start with R so that
>> they can use it productively for their thesis work and add or refresh some
>> statistics / analysis / econometrics skills.
>>
>>
>> I have collected some materials from the web etc. which will be helpful
>> but it probably would be good to have one main book or other reference which
>> the students can hold on to as a reference or guideline over the course.
>>
>> Would anyone have a good suggestion what book to use or even experience
>> with using one in a similar course?
>>
>> Thank you very much for any ideas!
>> Werner
>>
>>
>
>
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From francois.rousset at univ-montp2.fr  Sat Jul  6 21:42:31 2013
From: francois.rousset at univ-montp2.fr (Francois Rousset)
Date: Sat, 06 Jul 2013 21:42:31 +0200
Subject: [R] getNativeSymbolInfo for stats on R>=3.0.0
Message-ID: <51D87327.2090506@univ-montp2.fr>

Dear R users,

Problems with a .Call("logit_link",...) led me to the following test on 
virgin sessions of R2.15.2, R2.15.3, R3.0.0, R3.0.1 (Precompiled windows 
binaries in all cases)
==== begin code ==========
getNativeSymbolInfo("logit_link")
==== end code ==========
This works as expected on R2.15.2 and R2.15.3, but not on R3.0.0 and 
R3.0.1 where I get the message
Erreur dans FUN("logit_link"[[1L]], ...) : no such symbol logit_link

Adding the argument PACKAGE="stats" has no effect. Same error message 
for other functions from the stats DLL, but not for functions from the 
base package [e.g. getNativeSymbolInfo("dqrqy")].

I see that the examples in ?getNativeSymbolInfo have disappeared after 
R2.15.3, but I see no other changes in that documentation that could 
explain the change in the results.

Other information (similar for all versions of R):
==========
 > sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=French_France.1252  LC_CTYPE=French_France.1252 
LC_MONETARY=French_France.1252
[4] LC_NUMERIC=C                   LC_TIME=French_France.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

loaded via a namespace (and not attached):
[1] tools_3.0.1
===========

Any insight ?

Thanks in advance,

Francois Rousset
Institut des Sciences de l'?volution de Montpellier


From mackay at northnet.com.au  Sat Jul  6 23:38:56 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sun, 07 Jul 2013 07:38:56 +1000
Subject: [R] save rds as text
In-Reply-To: <836CE9D8128.000003A4jrkrideau@inbox.com>
References: <1373021042683-4670925.post@n4.nabble.com>
	<836CE9D8128.000003A4jrkrideau@inbox.com>
Message-ID: <201307062138.r66Lcumf018915@mail14.tpg.com.au>

In addition or perhaps better suited to text are the e... functions 
in the TeachingDemos package

txtStart
txtComment
commands ..
etxtStop

or something of that ilk


HTH

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

At 02:06 7/07/2013, you wrote:
>You might want to have a look at the xtable package
>
>John Kane
>Kingston ON Canada
>
>
> > -----Original Message-----
> > From: ac331 at le.ac.uk
> > Sent: Fri, 5 Jul 2013 03:44:02 -0700 (PDT)
> > To: r-help at r-project.org
> > Subject: [R] save rds as text
> >
> > I created a table like this:
> >
> > Analysis of Variance Table
> >
> >  Response: dati
> >  Df Sum Sq Mean Sq F value Pr(>F)
> >  groups     2    114   57.00      76 4.134e-11 ***
> >    Residuals 24     18    0.75
> > ---
> >    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
> >
> > and saved it to a variable called k.
> >
> > When I tried to save the variable to txt file using
> >
> >  dput(k, file = "..\\Readouts\\anova_spike_number.txt")
> >
> > or
> >
> >  lapply(k, write, "..\\Readouts\\anova_spike_number.txt", append=TRUE)
> >
> >  it destroys the formatting.
> >
> > Then I saved to rds using
> >
> >  saveRDS(k, "..\\Readouts\\anova_spike_number.rds")
> >
> >
> > and the format was preserved.
> >
> > I would like to convert the rds to txt preserving the table format. Or
> > save
> > it as excel file or pdf would also be fine.
> > (If there is a way to avoid passing through rds file better, but  still
> > OK
> > using rds).
> >
> > Thank you very much.
> >
> > Best regards,
> >
> >
> > Alberto
> >
> >
> >
> >
> >
> > --
> > View this message in context:
> > http://r.789695.n4.nabble.com/save-rds-as-text-tp4670925.html
> > Sent from the R help mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>FREE ONLINE PHOTOSHARING - Share your photos online with your 
>friends and family!
>Visit http://www.inbox.com/photosharing to find out more!
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Sun Jul  7 00:01:06 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sun, 07 Jul 2013 10:01:06 +1200
Subject: [R] The logistf() function from the logistf package. (Was:
 "Data Package Query")
In-Reply-To: <DUB118-W3F74D4ECAF8FD5B2093EE907D0@phx.gbl>
References: <a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>,
	<1371725996.86004.yahoomailneo@web122106.mail.ne1.yahoo.com>,
	<dub405-eas306523ef12f1c6c0f82988d90750@phx.gbl>,
	<1371711263.96641.yahoomailneo@web122105.mail.ne1.yahoo.com>,
	<1371633615.23367.yahoomailneo@web160101.mail.bf1.yahoo.com>,
	<51ccbcc1.6040508@xtra.co.nz>,
	<29D67F767D9.000002A6jrkrideau@inbox.com>
	<DUB118-W3F74D4ECAF8FD5B2093EE907D0@phx.gbl>
Message-ID: <51D893A2.7070603@xtra.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130707/afdf1b2e/attachment.pl>

From mackay at northnet.com.au  Sun Jul  7 00:04:18 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sun, 07 Jul 2013 08:04:18 +1000
Subject: [R] surface plots using wireframe, color at high res,
 grid  at low res?
In-Reply-To: <CDA3D5F2-C69C-4D10-8C31-C56F6B027758@gmail.com>
References: <CDA3D5F2-C69C-4D10-8C31-C56F6B027758@gmail.com>
Message-ID: <201307062204.r66M4IKi009026@mail16.tpgi.com.au>

Hi Patrick

You should do better by using a specific graphic device and then send 
the file to the printer

...
n.cuts=300
u1.corrd=(1:n.cuts-.5)/n.cuts
u2.corrd=(1:n.cuts-.5)/n.cuts
shareframe=data.frame(expand.grid(u1.corrd,u2.corrd))
shareframe$z.dir=normal.copula(shareframe$Var1,shareframe$Var2,rho.boat)
names(shareframe)=c("u1.dir","u2.dir","z.dir")

trellis.device(device = postscript,
                file = "copula1.ps",
                title = "",
                colormodel = "srgb")

wireframe(shareframe$z.dir~ shareframe$u1.dir*shareframe$u2.dir,
   scales = list(arrows=FALSE,col=1),
   drape = c(TRUE),
   par.settings=list(axis.line=list(col="transparent")),
   col="transparent",
   colorkey = FALSE,
   paper = "special",
   horizontal = "FALSE",
   height = 18,
   width =18,
   screen = list(z = 195,y=180, x = 105),
   col.regions = census.color.function((1:10000-.5)/10000),
   xlab = expression(U[1]), ylab = expression(U[2]), zlab="Density",main=" "
   )

dev.off()

see ?trellis.device and ?Devices

You will have to modify the arguments to suit the graph and your device.
If you use a device like png use a high resolution value

HTH

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au



At 07:55 6/07/2013, you wrote:
>Hello,
>
>I'm working on some simple copula plots for a poster presentation, 
>and by simple I mean simple, gaussian, etc., etc., etc.
>
>I know I might be taking this a bit too far but I'm trying to see if 
>I can overlay one surface plot over another.  I want to use color 
>but I like the addition of a black wireframe to hold together a 
>better sense of shape.
>
>Right now, I have it set up to create a 300x300 colored surface 
>using col="transparent", and I'd like to add a n x n (10, 20, 
>whatever) on top of this.  Right now I'm using wireframe and I'm 
>using my employer's official colors for gradient coloring.  My code 
>is below.  I apologize for the code length but it does execute the 
>way I want from a new session.
>
>I'm also curious as to why I'm some grid effects or lighting effects 
>(unsure of which) that I'm using on my personal 3.0.1 copy on 
>Mountain Lion OSX, that I wasn't getting on 2.14.1 on Windows XP... 
>something to figure out for another time.  This is a much more 
>secondary concern for which I have a solution (compile the final 
>graphic at work).  For now I'm just trying to see if its possible to 
>lay a smaller resolution grid over the colored high resolution grid.
>
>I will say that other help documents have been very useful to get 
>the code along to this point.
>
>Sincerely,
>
>Patrick Joyce
>
>Work e-mail:  patrick.m.joyce at census.gov
>
>
>library(RColorBrewer)
>library(colorspace)
>
>
>library(lattice)
>
>normal.copula=function(u1,u2,rho){
>
>x1=qnorm(u1)
>x2=qnorm(u2)
>
>1/(2*pi)/sqrt(1-rho^2)*exp(-1/2*(x1^2+x2^2-rho*x1*x2)/(1-rho^2))/dnorm(x1)/dnorm(x2)
>
>}
>
>new.census.red="#AB0537"
>new.census.blue="#0A6FB7"
>
>ncred=hex2RGB(new.census.red)
>ncblue=hex2RGB(new.census.blue)
>ncwhite=hex2RGB("#FFFFFF")
>
>census.color.function=function(alpha.cen){
>out.hex=ifelse(alpha.cen<.5,hex(mixcolor(2*alpha.cen,ncblue,ncwhite),fixup=TRUE),ifelse(alpha.cen==.5,"#FFFFFF",hex(mixcolor(2*alpha.cen-1,ncwhite,ncred),fixup=TRUE)))
>
>out.hex
>
>}
>
>rho.boat=.7
>
>n.cuts=300
>u1.corrd=(1:n.cuts-.5)/n.cuts
>u2.corrd=(1:n.cuts-.5)/n.cuts
>shareframe=data.frame(expand.grid(u1.corrd,u2.corrd))
>shareframe$z.dir=normal.copula(shareframe$Var1,shareframe$Var2,rho.boat)
>names(shareframe)=c("u1.dir","u2.dir","z.dir")
>
>plot.new()
>wireframe(shareframe$z.dir~ shareframe$u1.dir*shareframe$u2.dir,
>   xlab = expression(U[1]), ylab = expression(U[2]), zlab="Density",main=" ",
>
>scales = list(arrows=FALSE,col=1),
>   drape = c(TRUE),
>
>par.settings=list(axis.line=list(col="transparent")),col="transparent",colorkey 
>= FALSE,
>   screen = list(z = 195,y=180, x = 105),col.regions = 
> census.color.function((1:10000-.5)/10000))
>
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mackay at northnet.com.au  Sun Jul  7 00:33:46 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sun, 07 Jul 2013 08:33:46 +1000
Subject: [R] Transferring commas in character vector to expression
In-Reply-To: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.g
	mail.com>
References: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>
Message-ID: <201307062233.r66MXkNo028982@mail16.tpgi.com.au>

Hi Eric

I have not been following the thread but following on what David has 
said on previous occasions

try for example

plot(1,1, ylab =  expression("aa aaa,aa bb"*Delta*"b cccc"*Delta*"cc, c") )

Below is from a partly saved previous post of David's several months 
ago which may give you some ideas

DATA_names<-c(
"A mg kg",
"B mg kg",
"C mg kg",
"D mg kg",
"E mg kg",
"F mg kg",
"G mg kg",
"H mg kg")

pos <- barplot(1:length(DATA_names))
text(x=pos,y=-1, xpd=TRUE, srt=45,
                    labels= sapply( gsub("mg kg", "(mg kg)^-1", DATA_names),
                                    as.expression))

HTH

Duncan


Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au




At 07:47 6/07/2013, you wrote:
>I'm trying to format a given character vector as an expression with Greek
>symbols to be used in labeling axis ticks. Thanks to some help from David
>Winsemius, I've learned how to make the substitution and place the Greek
>symbols in, however I've run into another problem: Some of my labels have
>commas in them, so when the parse command is executed, there is an
>unexpected symbol error. For example:
>
> > x <- c("aa", "aaa,aa", "bb*Delta*b", "cccc*Delta*cc,c")
> > parse(text = x)
>Error in parse(text = x) : <text>:2:4: unexpected ','
>1: aa
>2: aaa,
>      ^
>
>I've tried various iterations of wrapping the commas in interior quotes
>("aaa\",\"aa"), but then the error shifts to the quote. I see in plotmath
>that 'list(a,b,c)' gives me comma separated values, but I haven't been able
>to work out how to get this construction for elements that have a comma.
>
>Is this possible?
>
>--
>
>Eric Archer, Ph.D.
>Southwest Fisheries Science Center
>NMFS, NOAA
>8901 La Jolla Shores Drive
>La Jolla, CA 92037 USA
>858-546-7121 (work)
>858-546-7003 (FAX)
>
>Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
>ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
>
>"The universe doesn't care what you believe.
>  The wonderful thing about science is that it
>    doesn't ask for your faith, it just asks
>    for your eyes."  - Randall Munroe
>
>"Lighthouses are more helpful than churches."
>    - Benjamin Franklin
>
>    "...but I'll take a GPS over either one."
>        - John C. "Craig" George
>
>         [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From istazahn at gmail.com  Sun Jul  7 01:41:12 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Sat, 6 Jul 2013 19:41:12 -0400
Subject: [R] save rds as text
In-Reply-To: <1373021042683-4670925.post@n4.nabble.com>
References: <1373021042683-4670925.post@n4.nabble.com>
Message-ID: <CA+vqiLGzQmRRBc_V79uvTGwzE+T08NX0crDmhapgfR9kW+Bg2A@mail.gmail.com>

Perhaps

sink(file="mytable.txt")
print(k)
sink()

gives the desired result.

Best,
Ista

On Fri, Jul 5, 2013 at 6:44 AM, alR <ac331 at le.ac.uk> wrote:
> I created a table like this:
>
> Analysis of Variance Table
>
>  Response: dati
>  Df Sum Sq Mean Sq F value Pr(>F)
>  groups     2    114   57.00      76 4.134e-11 ***
>    Residuals 24     18    0.75
> ---
>    Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1
>
> and saved it to a variable called k.
>
> When I tried to save the variable to txt file using
>
>  dput(k, file = "..\\Readouts\\anova_spike_number.txt")
>
> or
>
>  lapply(k, write, "..\\Readouts\\anova_spike_number.txt", append=TRUE)
>
>  it destroys the formatting.
>
> Then I saved to rds using
>
>  saveRDS(k, "..\\Readouts\\anova_spike_number.rds")
>
>
> and the format was preserved.
>
> I would like to convert the rds to txt preserving the table format. Or save
> it as excel file or pdf would also be fine.
> (If there is a way to avoid passing through rds file better, but  still OK
> using rds).
>
> Thank you very much.
>
> Best regards,
>
>
> Alberto
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/save-rds-as-text-tp4670925.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From eric.archer at noaa.gov  Sun Jul  7 03:57:29 2013
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Sat, 6 Jul 2013 18:57:29 -0700
Subject: [R] Transferring commas in character vector to expression
In-Reply-To: <201307062233.r66MXkNo028982@mail16.tpgi.com.au>
References: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>
	<201307062233.r66MXkNo028982@mail16.tpgi.com.au>
Message-ID: <CAGrYeXh02OG+6rQ2meBpVEAdTVe9=9tE4nDSaGpg5=A62wJ+2w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130706/ed1b96f4/attachment.pl>

From spencer.graves at structuremonitoring.com  Sun Jul  7 05:07:53 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sat, 06 Jul 2013 20:07:53 -0700
Subject: [R] Installing R on Fedora 18 Linux?
Message-ID: <51D8DB89.8080007@structuremonitoring.com>

Hello:


       I'm trying to install R under Fedora 18 Linux, and I'm confused. 
  The "R Installation and Administration" manual, sec. 1.1, says, "The 
simplest way is to download the most recent R-x.y.z.tar.gz file". 
However, I don't know how to get that.  My favorite CRAN mirror offers a 
"Precombiled binary" via "Download R for Linux".  That takes me to an 
index with options debian, redhat, suse, and ubuntu.  Redhat gives me an 
index with options el4, el5, fedora10, and fedora11.  I don't think I 
want any of those.


       Suggestions?
       Thanks,
       Spencer


From peter.langfelder at gmail.com  Sun Jul  7 05:22:13 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Sat, 6 Jul 2013 20:22:13 -0700
Subject: [R] Installing R on Fedora 18 Linux?
In-Reply-To: <51D8DB89.8080007@structuremonitoring.com>
References: <51D8DB89.8080007@structuremonitoring.com>
Message-ID: <CA+hbrhUCVJPwDvUV5pzh9Kxy9XeD_gJKFKwZN_h_hLaDZ09t4w@mail.gmail.com>

You have several options. You can use theF18  package manager to
install R directly from a Fedora software repository but the R may be
slightly out of date (IIRC Fedora 19 provides R-3.0.0; not sure about
F18).

Or, on your CRAN mirror page, ignore the "Download and install R"
section and go straight to "Source code for all platforms". There you
can choose R-3.0.1.tar.gz or (my personal preference) go to "Daily
snapshots of current patched and development versions". There choose
the link R-patched.tar.gz (without a date; it is a link to the newest
patched release).

Once you downloaded the tar.gz bundle, proceed as described in the manual.

HTH,

Peter

On Sat, Jul 6, 2013 at 8:07 PM, Spencer Graves
<spencer.graves at structuremonitoring.com> wrote:
> Hello:
>
>
>       I'm trying to install R under Fedora 18 Linux, and I'm confused.  The
> "R Installation and Administration" manual, sec. 1.1, says, "The simplest
> way is to download the most recent R-x.y.z.tar.gz file". However, I don't
> know how to get that.  My favorite CRAN mirror offers a "Precombiled binary"
> via "Download R for Linux".  That takes me to an index with options debian,
> redhat, suse, and ubuntu.  Redhat gives me an index with options el4, el5,
> fedora10, and fedora11.  I don't think I want any of those.
>
>
>       Suggestions?
>       Thanks,
>       Spencer
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Sun Jul  7 06:17:44 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 6 Jul 2013 21:17:44 -0700
Subject: [R] Transferring commas in character vector to expression
In-Reply-To: <CAGrYeXh02OG+6rQ2meBpVEAdTVe9=9tE4nDSaGpg5=A62wJ+2w@mail.gmail.com>
References: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>
	<201307062233.r66MXkNo028982@mail16.tpgi.com.au>
	<CAGrYeXh02OG+6rQ2meBpVEAdTVe9=9tE4nDSaGpg5=A62wJ+2w@mail.gmail.com>
Message-ID: <CACk-te08_yNwG2U4PP=ctKVFXhGEAFEPxfGSHJNjtUTGLjdF7A@mail.gmail.com>

I have not followed this thread, so I am only responding to your last
remark, and therefore the following may be useless to you (how's that
for for a caveat!!) ....  but maybe

plot(1:10,main=expression(delta*","*alpha))

might be helpful.

Alternatively:

x <- "delta"
y <- "alpha"
plot(1:10,   main = bquote(.(as.name(x))*","*.(as.name(y)))  )

produces the same result.

Again, if this is all irrelevant, just ignore.
If not, ?bquote and ?plotmath  contain all necessary explanation.

Cheers,
Bert


On Sat, Jul 6, 2013 at 6:57 PM, Eric Archer - NOAA Federal
<eric.archer at noaa.gov> wrote:
> Duncan,
>
> Thanks for the suggestion, but that won't work for my situation. I'm trying
> to use a character vector to label some axis ticks. There are some elements
> in the vector that have either a comma, or both Greek symbols and a comma,
> like the the third and fourth elements in x.lab below:
>
>> x <- 1:4
>> x.lab <- c("a*a", "bbb", "c,cc*c", "d,dd")
>> x.lab <- gsub("\\*", "*Delta*", x.lab)
>> x.lab <- parse(text = x.lab)
> Error in parse(text = x.lab) : <text>:3:2: unexpected ','
> 2: bbb
> 3: c,
>    ^
>> dotchart(x, labels = x.lab)
>
> The root problem that I'm stumped on is how to either:
> 1) insert a comma into an expression and have it be read as a valid
> character, or
> 2) replace the comma in the character string with 'list(a, b, c)' as in the
> help for plotmath and have it interpreted correctly.
>
> Cheers,
> eric
>
>
> On Sat, Jul 6, 2013 at 3:33 PM, Duncan Mackay <mackay at northnet.com.au>wrote:
>
>> Hi Eric
>>
>> I have not been following the thread but following on what David has said
>> on previous occasions
>>
>> try for example
>>
>> plot(1,1, ylab =  expression("aa aaa,aa bb"*Delta*"b cccc"*Delta*"cc, c") )
>>
>> Below is from a partly saved previous post of David's several months ago
>> which may give you some ideas
>>
>> DATA_names<-c(
>> "A mg kg",
>> "B mg kg",
>> "C mg kg",
>> "D mg kg",
>> "E mg kg",
>> "F mg kg",
>> "G mg kg",
>> "H mg kg")
>>
>> pos <- barplot(1:length(DATA_names))
>> text(x=pos,y=-1, xpd=TRUE, srt=45,
>>                    labels= sapply( gsub("mg kg", "(mg kg)^-1", DATA_names),
>>                                    as.expression))
>>
>> HTH
>>
>> Duncan
>>
>>
>> Duncan Mackay
>> Department of Agronomy and Soil Science
>> University of New England
>> Armidale NSW 2351
>> Email: home: mackay at northnet.com.au
>>
>>
>>
>>
>> At 07:47 6/07/2013, you wrote:
>>
>>> I'm trying to format a given character vector as an expression with Greek
>>> symbols to be used in labeling axis ticks. Thanks to some help from David
>>> Winsemius, I've learned how to make the substitution and place the Greek
>>> symbols in, however I've run into another problem: Some of my labels have
>>> commas in them, so when the parse command is executed, there is an
>>> unexpected symbol error. For example:
>>>
>>> > x <- c("aa", "aaa,aa", "bb*Delta*b", "cccc*Delta*cc,c")
>>> > parse(text = x)
>>> Error in parse(text = x) : <text>:2:4: unexpected ','
>>> 1: aa
>>> 2: aaa,
>>>      ^
>>>
>>> I've tried various iterations of wrapping the commas in interior quotes
>>> ("aaa\",\"aa"), but then the error shifts to the quote. I see in plotmath
>>> that 'list(a,b,c)' gives me comma separated values, but I haven't been
>>> able
>>> to work out how to get this construction for elements that have a comma.
>>>
>>> Is this possible?
>>>
>>> --
>>>
>>> Eric Archer, Ph.D.
>>> Southwest Fisheries Science Center
>>> NMFS, NOAA
>>> 8901 La Jolla Shores Drive
>>> La Jolla, CA 92037 USA
>>> 858-546-7121 (work)
>>> 858-546-7003 (FAX)
>>>
>>> Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
>>> ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
>>>
>>> "The universe doesn't care what you believe.
>>>  The wonderful thing about science is that it
>>>    doesn't ask for your faith, it just asks
>>>    for your eyes."  - Randall Munroe
>>>
>>> "Lighthouses are more helpful than churches."
>>>    - Benjamin Franklin
>>>
>>>    "...but I'll take a GPS over either one."
>>>        - John C. "Craig" George
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>>
>
>
> --
>
> Eric Archer, Ph.D.
> Southwest Fisheries Science Center
> NMFS, NOAA
> 8901 La Jolla Shores Drive
> La Jolla, CA 92037 USA
> 858-546-7121 (work)
> 858-546-7003 (FAX)
>
> Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
>
> "The universe doesn't care what you believe.
>  The wonderful thing about science is that it
>    doesn't ask for your faith, it just asks
>    for your eyes."  - Randall Munroe
>
> "Lighthouses are more helpful than churches."
>    - Benjamin Franklin
>
>    "...but I'll take a GPS over either one."
>        - John C. "Craig" George
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From maitra.mbox.ignored at inbox.com  Sun Jul  7 06:53:24 2013
From: maitra.mbox.ignored at inbox.com (Ranjan Maitra)
Date: Sat, 6 Jul 2013 23:53:24 -0500
Subject: [R] Installing R on Fedora 18 Linux?
In-Reply-To: <CA+hbrhUCVJPwDvUV5pzh9Kxy9XeD_gJKFKwZN_h_hLaDZ09t4w@mail.gmail.com>
References: <51D8DB89.8080007@structuremonitoring.com>
	<CA+hbrhUCVJPwDvUV5pzh9Kxy9XeD_gJKFKwZN_h_hLaDZ09t4w@mail.gmail.com>
Message-ID: <20130706235324.40210001737907ac599c5b86@inbox.com>

Fedora does have the latest (both Fedora 18/19) R in the repos. (They
are pretty good about this).

To install R, try:

sudo yum install R-core

That will do it.

To update, rather than install:

try 

sudo yum update R-core

HTH,
Ranjan

On Sat, 6 Jul 2013 20:22:13 -0700 Peter Langfelder
<peter.langfelder at gmail.com> wrote:

> You have several options. You can use theF18  package manager to
> install R directly from a Fedora software repository but the R may be
> slightly out of date (IIRC Fedora 19 provides R-3.0.0; not sure about
> F18).
> 
> Or, on your CRAN mirror page, ignore the "Download and install R"
> section and go straight to "Source code for all platforms". There you
> can choose R-3.0.1.tar.gz or (my personal preference) go to "Daily
> snapshots of current patched and development versions". There choose
> the link R-patched.tar.gz (without a date; it is a link to the newest
> patched release).
> 
> Once you downloaded the tar.gz bundle, proceed as described in the manual.
> 
> HTH,
> 
> Peter
> 
> On Sat, Jul 6, 2013 at 8:07 PM, Spencer Graves
> <spencer.graves at structuremonitoring.com> wrote:
> > Hello:
> >
> >
> >       I'm trying to install R under Fedora 18 Linux, and I'm confused.  The
> > "R Installation and Administration" manual, sec. 1.1, says, "The simplest
> > way is to download the most recent R-x.y.z.tar.gz file". However, I don't
> > know how to get that.  My favorite CRAN mirror offers a "Precombiled binary"
> > via "Download R for Linux".  That takes me to an index with options debian,
> > redhat, suse, and ubuntu.  Redhat gives me an index with options el4, el5,
> > fedora10, and fedora11.  I don't think I want any of those.
> >
> >
> >       Suggestions?
> >       Thanks,
> >       Spencer
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Important Notice: This mailbox is ignored: e-mails are set to be
deleted on receipt. For those needing to send personal or professional
e-mail, please use appropriate addresses.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From mackay at northnet.com.au  Sun Jul  7 07:19:13 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Sun, 07 Jul 2013 15:19:13 +1000
Subject: [R] Transferring commas in character vector to expression
In-Reply-To: <CACk-te08_yNwG2U4PP=ctKVFXhGEAFEPxfGSHJNjtUTGLjdF7A@mail.g
	mail.com>
References: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>
	<201307062233.r66MXkNo028982@mail16.tpgi.com.au>
	<CAGrYeXh02OG+6rQ2meBpVEAdTVe9=9tE4nDSaGpg5=A62wJ+2w@mail.gmail.com>
	<CACk-te08_yNwG2U4PP=ctKVFXhGEAFEPxfGSHJNjtUTGLjdF7A@mail.gmail.com>
Message-ID: <201307070519.r675JDlQ032005@mail16.tpgi.com.au>

Bert

It must be a case of Sod's law - I tried to do it earlier but got an 
error message.

it works with :

plot(1:4,axes=F)
  axis(1, at = 1:4,label=rep(expression(dd*Delta*","*dd),4))
box()

Something akin to what Eric wanted

Duncan

At 14:17 7/07/2013, you wrote:
>I have not followed this thread, so I am only responding to your last
>remark, and therefore the following may be useless to you (how's that
>for for a caveat!!) ....  but maybe
>
>plot(1:10,main=expression(delta*","*alpha))
>
>might be helpful.
>
>Alternatively:
>
>x <- "delta"
>y <- "alpha"
>plot(1:10,   main = bquote(.(as.name(x))*","*.(as.name(y)))  )
>
>produces the same result.
>
>Again, if this is all irrelevant, just ignore.
>If not, ?bquote and ?plotmath  contain all necessary explanation.
>
>Cheers,
>Bert
>
>
>On Sat, Jul 6, 2013 at 6:57 PM, Eric Archer - NOAA Federal
><eric.archer at noaa.gov> wrote:
> > Duncan,
> >
> > Thanks for the suggestion, but that won't work for my situation. I'm trying
> > to use a character vector to label some axis ticks. There are some elements
> > in the vector that have either a comma, or both Greek symbols and a comma,
> > like the the third and fourth elements in x.lab below:
> >
> >> x <- 1:4
> >> x.lab <- c("a*a", "bbb", "c,cc*c", "d,dd")
> >> x.lab <- gsub("\\*", "*Delta*", x.lab)
> >> x.lab <- parse(text = x.lab)
> > Error in parse(text = x.lab) : <text>:3:2: unexpected ','
> > 2: bbb
> > 3: c,
> >    ^
> >> dotchart(x, labels = x.lab)
> >
> > The root problem that I'm stumped on is how to either:
> > 1) insert a comma into an expression and have it be read as a valid
> > character, or
> > 2) replace the comma in the character string with 'list(a, b, c)' as in the
> > help for plotmath and have it interpreted correctly.
> >
> > Cheers,
> > eric
> >
> >
> > On Sat, Jul 6, 2013 at 3:33 PM, Duncan Mackay 
> <mackay at northnet.com.au>wrote:
> >
> >> Hi Eric
> >>
> >> I have not been following the thread but following on what David has said
> >> on previous occasions
> >>
> >> try for example
> >>
> >> plot(1,1, ylab =  expression("aa aaa,aa bb"*Delta*"b 
> cccc"*Delta*"cc, c") )
> >>
> >> Below is from a partly saved previous post of David's several months ago
> >> which may give you some ideas
> >>
> >> DATA_names<-c(
> >> "A mg kg",
> >> "B mg kg",
> >> "C mg kg",
> >> "D mg kg",
> >> "E mg kg",
> >> "F mg kg",
> >> "G mg kg",
> >> "H mg kg")
> >>
> >> pos <- barplot(1:length(DATA_names))
> >> text(x=pos,y=-1, xpd=TRUE, srt=45,
> >>                    labels= sapply( gsub("mg kg", "(mg kg)^-1", 
> DATA_names),
> >>                                    as.expression))
> >>
> >> HTH
> >>
> >> Duncan
> >>
> >>
> >> Duncan Mackay
> >> Department of Agronomy and Soil Science
> >> University of New England
> >> Armidale NSW 2351
> >> Email: home: mackay at northnet.com.au
> >>
> >>
> >>
> >>
> >> At 07:47 6/07/2013, you wrote:
> >>
> >>> I'm trying to format a given character vector as an expression with Greek
> >>> symbols to be used in labeling axis ticks. Thanks to some help from David
> >>> Winsemius, I've learned how to make the substitution and place the Greek
> >>> symbols in, however I've run into another problem: Some of my labels have
> >>> commas in them, so when the parse command is executed, there is an
> >>> unexpected symbol error. For example:
> >>>
> >>> > x <- c("aa", "aaa,aa", "bb*Delta*b", "cccc*Delta*cc,c")
> >>> > parse(text = x)
> >>> Error in parse(text = x) : <text>:2:4: unexpected ','
> >>> 1: aa
> >>> 2: aaa,
> >>>      ^
> >>>
> >>> I've tried various iterations of wrapping the commas in interior quotes
> >>> ("aaa\",\"aa"), but then the error shifts to the quote. I see in plotmath
> >>> that 'list(a,b,c)' gives me comma separated values, but I haven't been
> >>> able
> >>> to work out how to get this construction for elements that have a comma.
> >>>
> >>> Is this possible?
> >>>
> >>> --
> >>>
> >>> Eric Archer, Ph.D.
> >>> Southwest Fisheries Science Center
> >>> NMFS, NOAA
> >>> 8901 La Jolla Shores Drive
> >>> La Jolla, CA 92037 USA
> >>> 858-546-7121 (work)
> >>> 858-546-7003 (FAX)
> >>>
> >>> Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> >>> ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
> >>>
> >>> "The universe doesn't care what you believe.
> >>>  The wonderful thing about science is that it
> >>>    doesn't ask for your faith, it just asks
> >>>    for your eyes."  - Randall Munroe
> >>>
> >>> "Lighthouses are more helpful than churches."
> >>>    - Benjamin Franklin
> >>>
> >>>    "...but I'll take a GPS over either one."
> >>>        - John C. "Craig" George
> >>>
> >>>         [[alternative HTML version deleted]]
> >>>
> >>> ______________________________**________________
> >>> R-help at r-project.org mailing list
> >>> 
> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> >>> PLEASE do read the posting guide http://www.R-project.org/**
> >>> posting-guide.html <http://www.R-project.org/posting-guide.html>
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>
> >>
> >>
> >
> >
> > --
> >
> > Eric Archer, Ph.D.
> > Southwest Fisheries Science Center
> > NMFS, NOAA
> > 8901 La Jolla Shores Drive
> > La Jolla, CA 92037 USA
> > 858-546-7121 (work)
> > 858-546-7003 (FAX)
> >
> > Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> > ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
> >
> > "The universe doesn't care what you believe.
> >  The wonderful thing about science is that it
> >    doesn't ask for your faith, it just asks
> >    for your eyes."  - Randall Munroe
> >
> > "Lighthouses are more helpful than churches."
> >    - Benjamin Franklin
> >
> >    "...but I'll take a GPS over either one."
> >        - John C. "Craig" George
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>
>
>--
>
>Bert Gunter
>Genentech Nonclinical Biostatistics
>
>Internal Contact Info:
>Phone: 467-7374
>Website:
>http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From eric.archer at noaa.gov  Sun Jul  7 07:54:52 2013
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Sat, 6 Jul 2013 22:54:52 -0700
Subject: [R] Transferring commas in character vector to expression
In-Reply-To: <201307070438.r674cbqq012554@mail15.tpg.com.au>
References: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>
	<201307062233.r66MXkNo028982@mail16.tpgi.com.au>
	<CAGrYeXh02OG+6rQ2meBpVEAdTVe9=9tE4nDSaGpg5=A62wJ+2w@mail.gmail.com>
	<201307070438.r674cbqq012554@mail15.tpg.com.au>
Message-ID: <CAGrYeXi-saL2SGPfO_qSx15RB3=S9KOQ5W1ie1tuJSH1a92Dkg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130706/c04e5018/attachment.pl>

From cxg040 at email.uark.edu  Sun Jul  7 08:01:51 2013
From: cxg040 at email.uark.edu (Chirag Gupta)
Date: Sun, 7 Jul 2013 01:01:51 -0500
Subject: [R] Check a list of genes for a specific GO term
Message-ID: <CADESCNzSqrnZ1GS9BH8VNuP2kVVqF9yyTkRprEqo8Xurhd9sfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130707/db5abcc8/attachment.pl>

From brecht.devleesschauwer at ugent.be  Sat Jul  6 17:57:03 2013
From: brecht.devleesschauwer at ugent.be (brechtdv)
Date: Sat, 6 Jul 2013 08:57:03 -0700 (PDT)
Subject: [R] Bayesian estimate of prevalence with an imperfect test
In-Reply-To: <1325835194084-4268526.post@n4.nabble.com>
References: <1325772586848-4265595.post@n4.nabble.com>
	<1325835194084-4268526.post@n4.nabble.com>
Message-ID: <1373126223409-4671014.post@n4.nabble.com>

Dear Lian,

You might be interested to hear that a new package is available on CRAN to
perform Bayesian estimation of true prevalence from apparent prevalence: 
http://cran.r-project.org/package=prevalence
<http://cran.r-project.org/package=prevalence>  

The function 'truePrev()', that estimates true prevalence from individual
samples, is also implemented as an online Shiny application: 
http://users.ugent.be/~bdvleess/R/prevalence/shiny/
<http://users.ugent.be/~bdvleess/R/prevalence/shiny/>  

Best wishes,
Brecht


LianD wrote
> Thanks Bert 
> 
> I've been through my variables again and have managed to get the code
> working - shouldn't have tried to deal with it at the end of the day
> yesterday!
> 
> all the best
> 
> Lian





--
View this message in context: http://r.789695.n4.nabble.com/Bayesian-estimate-of-prevalence-with-an-imperfect-test-tp4265595p4671014.html
Sent from the R help mailing list archive at Nabble.com.


From qixiang109 at gmail.com  Sat Jul  6 16:26:05 2013
From: qixiang109 at gmail.com (qixiang)
Date: Sat, 6 Jul 2013 22:26:05 +0800
Subject: [R] how to turn off "buffered output" in R mac os?
Message-ID: <F398EB71-C27A-4FDE-980B-447A0ED61A08@gmail.com>

hi everyone,
I am writing R with textmate2.0 on my mac book. Today when I want to add a progress bar in a loop, i find the textmate bundle fails to  "print" or "cat" anything until the loop is completed. 
I search for this problem in Google and some says that this is because the "buffers output" setting of R and can be solved by unchoosing Rconsole->Misc->buffered output. However, doesn't anyone notice that the Mac OS R even doesn't have this "buffered output" option?
I have tried the flush.console() but it doesn't work, neither.
Anyone has get into such a problem and can give me a help?

From s.hoffmann85 at outlook.com  Sat Jul  6 19:21:22 2013
From: s.hoffmann85 at outlook.com (sarah hoffmann)
Date: Sat, 6 Jul 2013 18:21:22 +0100
Subject: [R] (lme4) p-values for single terms in mixed models involved in
 sig interactions
Message-ID: <BAY172-W42912A7EB359701F474D5A877E0@phx.gbl>

I am using lme4 to fit a mixed effects model to my data. I have a significant interaction between two variables. My question is what is the correct way to get p-values for single terms involved in that interaction. 
I have been using stepwise backwards deletion and model comparisons to get p-values,and refitting the model using a REML approach to get estimates.However, presumably to get the p values for single terms, I also have to remove the interaction as well, and therefore inaccurate. 
I have confused myself with this now, as to whether in this case you should compare a model with the interaction and the single term of interest removed to the minimum adequate model (in which case the p values are over inflated for the single terms), or whether to remove the interaction from the minimum adequate model, and then compare this to an updated model, with the single term removed.
This is an example of what the model would look like:
library(lme4)
minadequatemodel<-lmer(sq_rate~(day+temp+brood_size+weight+weight:brood_size+(1|ident),data=prov,REML=FALSE)

##to get p values for e.g. temp
pvalmodtemp<-update(minadequatemodel,~.+temp)
anova(modelfin,modeltemp)

###but what's the correct way to get p value for brood_size or weight?

Your help would be greatly appreciated...thanks! 		 	   		  

From bhh at xs4all.nl  Sun Jul  7 08:25:33 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 7 Jul 2013 08:25:33 +0200
Subject: [R] how to turn off "buffered output" in R mac os?
In-Reply-To: <F398EB71-C27A-4FDE-980B-447A0ED61A08@gmail.com>
References: <F398EB71-C27A-4FDE-980B-447A0ED61A08@gmail.com>
Message-ID: <764C0581-3E16-46B8-B7AF-C0EFA0C21188@xs4all.nl>


On 06-07-2013, at 16:26, qixiang <qixiang109 at gmail.com> wrote:

> hi everyone,
> I am writing R with textmate2.0 on my mac book. Today when I want to add a progress bar in a loop, i find the textmate bundle fails to  "print" or "cat" anything until the loop is completed. 
> I search for this problem in Google and some says that this is because the "buffers output" setting of R and can be solved by unchoosing Rconsole->Misc->buffered output. However, doesn't anyone notice that the Mac OS R even doesn't have this "buffered output" option?
> I have tried the flush.console() but it doesn't work, neither.
> Anyone has get into such a problem and can give me a help?

This is not a matter for the R-help list.
It belongs on the TextMate-Users mailing list.

Berend


> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Sun Jul  7 08:59:33 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 07 Jul 2013 07:59:33 +0100
Subject: [R] The logistf() function from the logistf package. (Was:
 "Data Package Query")
In-Reply-To: <51D893A2.7070603@xtra.co.nz>
References: <a12164e5-fef5-4963-8159-e891210e7dbc@email.android.com>,
	<1371725996.86004.yahoomailneo@web122106.mail.ne1.yahoo.com>,
	<dub405-eas306523ef12f1c6c0f82988d90750@phx.gbl>,
	<1371711263.96641.yahoomailneo@web122105.mail.ne1.yahoo.com>,
	<1371633615.23367.yahoomailneo@web160101.mail.bf1.yahoo.com>,
	<51ccbcc1.6040508@xtra.co.nz>,
	<29D67F767D9.000002A6jrkrideau@inbox.com>
	<DUB118-W3F74D4ECAF8FD5B2093EE907D0@phx.gbl>
	<51D893A2.7070603@xtra.co.nz>
Message-ID: <51D911D5.4000602@stats.ox.ac.uk>

On 06/07/2013 23:01, Rolf Turner wrote:
> On 06/07/13 01:35, Yasmine Refai wrote:
>> Hello,
>>
>> When I run the below syntax:
>> *Trial<-read.table("Trial.txt",header=TRUE)*
>> *Trial*
>> *save.image(file="Trial.RData")*
>> *load("Trial.RData")
>> fit<-logistf(data=Trial, y~x1+x2)
>> summary(fit)
>> AIC(fit)*
>>
>> I am getting the below error:
>> *> AIC(fit)
>> Error in UseMethod("logLik") :
>>    no applicable method for 'logLik' applied to an object of class
>> "logistf"
>> *
>> Can you please help with that?
>
> You need to learn to crawl before you start trying to learn to walk.
>
> (1) Your convoluted code is filled with redundancies and circularity.
> Acquire some understanding of how R works before you plunge into
> a modelling exercise.
>
> (2) The logistf() function comes from the logistf package.  This needs to
> be mentioned when you are asking for help with the function.
>
> (3) The error message seems to me to be quite clear.  To calculate the AIC
> one needs the log likelihood and this cannot be calculated.  This could
> be due
> to the fact that log likelihood is not applicable to the model used by
> logistf(),

Small clarifcation: one needs the maximized log-likelihood.

More abstractly: AIC is only applicable to models fitted by maximum 
likelihood.  Biased-reduced fits (by Firth or anyone else) are not. 
This is one reason why there are many extensions to AIC to compare other 
sorts of fits.

> or simply to the fact that the package maintainer has not (yet?) written a
> method logLik.logistf().  I don't know, not being familiar with "Firth's
> bias
> reduced logistic regression" which is what the logistf package is about.
>
> It is incumbent upon ***you*** to know since you are invoking the logistf
> package.  If you don't know, do some study and find out.  You could also
> try to contact the package maintainer.
>
> (4) Your subject line is misleading.  You are simply replying to replies to
> a previous query (which has really nothing to do with the current one)
> and are apparently too lazy to start a new thread.
>
>       cheers,
>
>           Rolf Turner
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ruipbarradas at sapo.pt  Sun Jul  7 11:28:29 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 07 Jul 2013 10:28:29 +0100
Subject: [R] Check a list of genes for a specific GO term
In-Reply-To: <CADESCNzSqrnZ1GS9BH8VNuP2kVVqF9yyTkRprEqo8Xurhd9sfA@mail.gmail.com>
References: <CADESCNzSqrnZ1GS9BH8VNuP2kVVqF9yyTkRprEqo8Xurhd9sfA@mail.gmail.com>
Message-ID: <51D934BD.7060904@sapo.pt>

Hello,

Your question is not very clear, maybe if you post a data example.
To do so, use ?dput. If your data frame is named 'dat', use the following.

dput(head(dat, 50))  # paste the output of this in a post


If you want to get the rownames matching a certain pattern, maybe 
something like the following.


idx <- grep("GO:0006355", rownames(dat))
dat[idx, ]


Hope this helps,

Rui Barradas


Em 07-07-2013 07:01, Chirag Gupta escreveu:
> Hello everyone
>
> I have a dataframe with rows as probeset ID and columns as samples
> I want to check the rownames and find which are those probes are
> transcription factors. (GO:0006355 )
>
> Any suggestions?
>
> Thanks!
>


From catalinroibu at gmail.com  Sun Jul  7 12:12:39 2013
From: catalinroibu at gmail.com (catalin roibu)
Date: Sun, 7 Jul 2013 13:12:39 +0300
Subject: [R] spatstat output
Message-ID: <CAEW+BDKqRgQzsf_f1NYfTET-LsYN6cSG9M8cNzREiKz+kg2Tdw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130707/814ac3eb/attachment.pl>

From rolf.turner at xtra.co.nz  Sun Jul  7 13:05:28 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sun, 07 Jul 2013 23:05:28 +1200
Subject: [R] spatstat output
In-Reply-To: <CAEW+BDKqRgQzsf_f1NYfTET-LsYN6cSG9M8cNzREiKz+kg2Tdw@mail.gmail.com>
References: <CAEW+BDKqRgQzsf_f1NYfTET-LsYN6cSG9M8cNzREiKz+kg2Tdw@mail.gmail.com>
Message-ID: <51D94B78.9020100@xtra.co.nz>

On 07/07/13 22:12, catalin roibu wrote:
> Dear R users,
> Is there a possibility to extract only the r, CI's envelope and L function
> from the output of spatstat?
> I use this code
> E <- alltypes(df1, Kest, nsim = 100, envelope =
> TRUE,savepatterns=TRUE,correction="isotropic")
> And second question, is there a possibility to modify the margin of plot in
> spatstat?
>
> plot(E, sqrt(./pi) - r ~ r, ylab = "L(r)-r",main=NULL,sub=NULL,las=1)
>
> Thank you very much for your help!
(1) This is a question about the spatstat package and as such should be
in the first instance directed to the authors of this package.

(2) Your example is *not reproducible* since we have no access to "df1".

(3) Your use of the expression "CI's envelope" indicates that you are 
confused.
The abbreviation "CI" would appear to denote "confidence interval". The 
envelopes
do ***NOT*** consist of confidence intervals.  They are ***critical 
envelopes***.
(Repeat after me, 50 times: "Critical envelope, critical envelope, 
.....").   See the help
for envelope().

(4)  The use of nsim=100, while not incorrect, is bizarre.  The 
envelopes yield
p-values equal to fractions whose denominator is (nsim+1).  Hence nsim=99
(the default) is usually a much better choice than nsim=100.

(5) The object E returned by your code is of class "fasp" (function 
array for
spatial processes).  It is thus a list whose first entry is names 
"fns".  In turn
"fns" is a list whose entries correspond to the marks of the pattern to 
which
you applied alltypes().  Each entry is an object of class "fv".  See the 
help for
fv.object.  If you examine the names of these objects --- which are data 
frames
with extra attributes --- you should easily be able to see how to 
extract the
items that you desire.

(6) In respect of changing the margins, see the help for plot.fasp. Does
the argument mar.panel do what you want?

     cheers,

         Rolf Turner


From mtmorgan at fhcrc.org  Sun Jul  7 13:55:35 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 7 Jul 2013 04:55:35 -0700 (PDT)
Subject: [R] Check a list of genes for a specific GO term
In-Reply-To: <51D934BD.7060904@sapo.pt>
Message-ID: <1025527908.579684.1373198135756.JavaMail.root@fhcrc.org>

In Bioconductor, install the annotation package

  http://bioconductor.org/packages/release/BiocViews.html#___AnnotationData

corresponding to your chip, e.g.,

  source("http://bioconductor.org/biocLite.R")
  biocLite("hgu95av2.db")

then load it and select the GO terms corresponding to your probes

  library(hgu95av2.db)
  lkup <- select(hgu95av2.db, rownames(dat), "GO")
  
then use standard R commands to find the probesets that have the GO id you're interested in

  keep = lkup$GO %in% "GO:0006355"
  unique(lkup$PROBEID[keep])

Ask follow-up questions about Bioconductor packages on the Bioconductor mailing list

  http://bioconductor.org/help/mailing-list/mailform/

Martin
----- Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
> 
> Your question is not very clear, maybe if you post a data example.
> To do so, use ?dput. If your data frame is named 'dat', use the following.
> 
> dput(head(dat, 50))  # paste the output of this in a post
> 
> 
> If you want to get the rownames matching a certain pattern, maybe 
> something like the following.
> 
> 
> idx <- grep("GO:0006355", rownames(dat))
> dat[idx, ]
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> 
> Em 07-07-2013 07:01, Chirag Gupta escreveu:
> > Hello everyone
> >
> > I have a dataframe with rows as probeset ID and columns as samples
> > I want to check the rownames and find which are those probes are
> > transcription factors. (GO:0006355 )
> >
> > Any suggestions?
> >
> > Thanks!
> >
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Jul  7 16:51:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 7 Jul 2013 07:51:05 -0700 (PDT)
Subject: [R] Subset and order
In-Reply-To: <51D723CC.40004@sapo.pt>
References: <204A9695-C21C-4EE0-B16B-DC8D988F7C4D@ucla.edu>
	<51D721FB.1050800@sapo.pt>
	<A01F0E9C-31F4-4F61-B517-127F641BFF92@ucla.edu>
	<51D723CC.40004@sapo.pt> 
Message-ID: <1373208665.95053.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You could also try ?data.table()
x<- read.table(text="a??? b??? c
1??? 2??? 3
3??? 3??? 4
2??? 4??? 5
1??? 3??? 4
",sep="",header=TRUE)

library(data.table)

xt<- data.table(xt)
?setkey(xt,a)
?subset(xt,b==3)
#?? a b c
#1: 1 3 4
#2: 3 3 4



?iord <- order(x$a)
?subset(x[iord, ], b == 3) 
#? a b c
#4 1 3 4
#2 3 3 4


Speed comparison:
set.seed(12345)
dat1<- as.data.frame(matrix(sample(1:10,3*1e7,replace=TRUE),ncol=3))
colnames(dat1)<-letters[1:3]
system.time({
iord <- order(dat1$a)
res1<-subset(dat1[iord, ], b == 3)
})
#? user? system elapsed 
#? 6.888?? 0.296?? 7.202 

dt1<- data.table(dat1)
system.time({setkey(dt1,a)
??? resdt1<-subset(dt1,b==3)})
# user? system elapsed 
#?? 0.72??? 0.06??? 0.78?

head(resdt1)
#?? a b? c
#1: 1 3? 6
#2: 1 3? 4
#3: 1 3 10
#4: 1 3? 2
#5: 1 3? 9
#6: 1 3? 8
?head(res1)
#??? a b? c
#75? 1 3? 6
#93? 1 3? 4
#300 1 3 10
#301 1 3? 2
#437 1 3? 9
#672 1 3? 8

A.K.
----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Noah Silverman <noahsilverman at ucla.edu>
Cc: "R-help at r-project.org" <r-help at r-project.org>
Sent: Friday, July 5, 2013 3:51 PM
Subject: Re: [R] Subset and order

Hello,

If time is one of the problems, precompute an ordered index, and use it 
every time you want the df sorted. But that would mean you can't do it 
in a single operation.

iord <- order(x$a)
subset(x[iord, ], b == 3)


Rui Barradas

Em 05-07-2013 20:47, Noah Silverman escreveu:
> That would work, but is painfully slow.? It forces a new sort of the data with every query.? I have 200,000 rows and need almost a hundred queries.
>
> Thanks,
>
> -N
>
>
> On Jul 5, 2013, at 12:43 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Maybe like this?
>>
>> subset(x[order(x$a), ], b == 3)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 05-07-2013 20:33, Noah Silverman escreveu:
>>> Hello,
>>>
>>> I have a data frame with several columns.
>>>
>>> I'd like to select some subset *and* order by another field at the same time.
>>>
>>> Example:
>>>
>>> a??? b??? c
>>> 1??? 2??? 3
>>> 3??? 3??? 4
>>> 2??? 4??? 5
>>> 1??? 3??? 4
>>> etc?
>>>
>>>
>>> I want to select all rows where b=3 and then order by a.
>>>
>>> To subset is easy:? x[x$b==3,]
>>> To order is easy: x[order(x$a),]
>>>
>>> Is there a way to do both in a single efficient statement?
>>>
>>> Thanks,
>>>
>>>
>>>
>>> --
>>> Noah Silverman, M.S., C.Phil
>>> UCLA Department of Statistics
>>> 8117 Math Sciences Building
>>> Los Angeles, CA 90095
>>>
>>>
>>>
>>>
>>> ??? [[alternative HTML version deleted]]
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ejoffe at hotmail.com  Sun Jul  7 17:01:52 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Sun, 7 Jul 2013 10:01:52 -0500
Subject: [R] coxph won't converge when including categorical
	(factor)	variables
In-Reply-To: <80F175FF-1DBF-49C6-A295-E20CA112DE2E@me.com>
References: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
	<80F175FF-1DBF-49C6-A295-E20CA112DE2E@me.com>
Message-ID: <DUB114-DS19550858003C6577ECF62CA7F0@phx.gbl>

Hello all,

I have posted a reply to Mark and Jeff out of my own fault sent it to them personally and not the group.
I will re-post the question and Mark's answer so that the community can benefit from his comments.
It seems that my posts are not in accordance with the guidelines and I will try to remedy that as well.
I apologize for the mess I have made !!!
I am afraid I can't post the actual data (as it is Protected Health Information).


In any case here are the question, code, output and Mark's comment (which can be summarized that there is very little information about the pec package within the community and that the best solution would be to try and contact the author of the package - which I will and then repost the answer):


I am attempting to evaluate the prediction error of a coxph model that was built after feature selection with glmnet.

In the preprocessing stage I used na.omit (dataset) to remove NAs. I reconstructed all my factor variables into binary variables with dummies (using model.matrix) I then used glmnet lasso to fit a cox model and select the best performing features. Then I fit a coxph model using only these feature.

When I try to evaluate the model using pec and a bootstrap I get an error that the prediction matrix has wrong dimensions.

In the original dataset there are 313 variables. In the coxph model (glmnet.cox in my code) there are 313 df. However when I run pec the prediction matrix is noted as having 318 variables and therefore doesn't fit the testset which has 313 variables (+the status and time variables).

It seems that pec does something to the variables while retraining the coxph model on the bootstrap samples. I tried setting singular.ok=FALSE in the coxph model without avail.

Here is a summary of key variables (prior to restructuring for glmnet) Followed by the code I ran and the errors:

> summary (trainSet)
     time              status         Age_at_Dx       CREATININE   
 Min.   :  0.1429   Min.   :0.0000   Min.   :14.81   Min.   :0.400  
 1st Qu.: 22.0714   1st Qu.:1.0000   1st Qu.:52.51   1st Qu.:0.800  
 Median : 52.9286   Median :1.0000   Median :63.79   Median :0.900  
 Mean   : 96.5415   Mean   :0.7826   Mean   :61.01   Mean   :1.042  
 3rd Qu.:154.6071   3rd Qu.:1.0000   3rd Qu.:73.01   3rd Qu.:1.125  
 Max.   :437.7143   Max.   :1.0000   Max.   :87.23   Max.   :6.000  
 Performance_Status    ALBUMIN          Cyto             WBC        
 Min.   :0.0000     Min.   :0.70   Min.   : 1.000   Min.   :  0.60  
 1st Qu.:1.0000     1st Qu.:3.00   1st Qu.: 4.000   1st Qu.:  3.20  
     Median :1.0000     Median :3.60   Median : 4.000   Median :  9.20  
 Mean   :0.9728     Mean   :3.48   Mean   : 6.802   Mean   : 28.35  
 3rd Qu.:1.0000     3rd Qu.:4.00   3rd Qu.:11.000   3rd Qu.: 33.10  
 Max.   :4.0000     Max.   :5.20   Max.   :17.000   Max.   :373.00  
  PRKCD_pT507             HGB            Maxblast          CD19       
 Min.   :-2.429605   Min.   : 5.400   Min.   : 0.00   Min.   : 0.000  
  1st Qu.:-0.627005   1st Qu.: 8.500   1st Qu.:24.00   1st Qu.: 1.000  
 Median :-0.013117   Median : 9.550   Median :40.00   Median : 2.000  
 Mean   : 0.006432   Mean   : 9.689   Mean   :43.74   Mean   : 6.312  
 3rd Qu.: 0.559782   3rd Qu.:10.800   3rd Qu.:65.25   3rd Qu.: 5.000  
 Max.   : 2.963658   Max.   :14.300   Max.   :98.00   Max.   :98.000  
     GAPDH                CD74              TP53               Fli1          
 Min.   :-2.391021   Min.   :-1.7902   Min.   :-1.64244   Min.   :-3.723143  
 1st Qu.:-0.662164   1st Qu.:-0.5502   1st Qu.:-0.53685   1st Qu.:-0.559783  
 Median : 0.003236   Median :-0.1546   Median :-0.10928   Median :-0.002154  
 Mean   : 0.015759   Mean   : 0.0235   Mean   :-0.02285   Mean   :-0.016555  
 3rd Qu.: 0.632472   3rd Qu.: 0.4759   3rd Qu.: 0.29869   3rd Qu.: 0.554521  
 Max.   : 3.512741   Max.   : 3.7226   Max.   : 5.39242   Max.   : 4.415324  
      LDH              SQSTM0            BM_BLAST         CCND3         
 Min.   :    8.4   Min.   :-1.56639   Min.   : 0.00   Min.   :-2.44772  
 1st Qu.:  562.8   1st Qu.:-0.48762   1st Qu.:31.00   1st Qu.:-0.59042  
 Median :  952.5   Median :-0.05746   Median :46.50   Median :-0.08412  
 Mean   : 1617.9   Mean   :-0.02272   Mean   :50.64   Mean   :-0.02506  
 3rd Qu.: 1596.8   3rd Qu.: 0.33718   3rd Qu.:72.00   3rd Qu.: 0.48353  
 Max.   :36708.0   Max.   : 3.59456   Max.   :98.00   Max.   : 3.58761  
      GAB2                BAX               ABS_BLST           PRKAA1_2       
 Min.   :-3.201564   Min.   :-3.230737   Min.   :     0.0   Min.   :-1.90671  
 1st Qu.:-0.640279   1st Qu.:-0.593174   1st Qu.:    99.8   1st Qu.:-0.66896  
 Median : 0.007018   Median :-0.106097   Median :  1836.5   Median :-0.10586  
 Mean   :-0.013284   Mean   :-0.007051   Mean   : 15024.1   Mean   :-0.03531  
  3rd Qu.: 0.635609   3rd Qu.: 0.588098   3rd Qu.: 11178.0   3rd Qu.: 0.44906  
 Max.   : 2.396419   Max.   : 3.439942   Max.   :358080.0   Max.   : 3.60037  
    RPS6KB1              SPP1               MAPT                ARC          
 Min.   :-2.05490   Min.   :-1.39728   Min.   :-1.826101   Min.   :-2.67081  
 1st Qu.:-0.65736   1st Qu.:-0.55249   1st Qu.:-0.573470   1st Qu.:-0.63908  
 Median :-0.12007   Median :-0.15156   Median :-0.046306   Median :-0.07845  
 Mean   :-0.06115   Mean   : 0.02759   Mean   : 0.009604   Mean   :-0.01082  
 3rd Qu.: 0.49055   3rd Qu.: 0.35195   3rd Qu.: 0.495406   3rd Qu.: 0.63638  
  Max.   : 3.54709   Max.   : 4.44919   Max.   : 4.063568   Max.   : 2.52810  
  FOXO1_pT24_FOXO3_pT32      ATG7               SMAD5           RPS6_pS235_236     
  Min.   :-2.2506       Min.   :-2.916018   Min.   :-2.321250   Min.   :-3.229642  
  1st Qu.:-0.5590       1st Qu.:-0.621408   1st Qu.:-0.480924   1st Qu.:-0.633143  
  Median :-0.1281       Median : 0.003795   Median : 0.003186   Median :-0.003345  
  Mean   :-0.0121       Mean   :-0.029199   Mean   : 0.010663   Mean   :-0.015028  
  3rd Qu.: 0.4415       3rd Qu.: 0.590721   3rd Qu.: 0.502824   3rd Qu.: 0.660224  
  Max.   : 3.1239       Max.   : 2.757525   Max.   : 2.238310   Max.   : 2.816105  
      LSD1             HDAC2               SFN           
  Min.   :-4.5434   Min.   :-2.40682   Min.   :-2.082592  
  1st Qu.:-0.5654   1st Qu.:-0.49165   1st Qu.:-0.554862  
  Median : 0.0477   Median : 0.02828   Median :-0.116248  
  Mean   :-0.0165   Mean   : 0.04641   Mean   : 0.006255  
  3rd Qu.: 0.6044   3rd Qu.: 0.47826   3rd Qu.: 0.506527  
  Max.   : 1.8736   Max.   : 4.22724   Max.   : 3.733445


library (survival)
library (pec)
library (glmnet)

  ##-----------------------------------------------------------------------------------         -------------------
   ##                                    FEATURE SELECTION BY GLMNET-LASSO
   ##----------------------------------------------------------------------------------     ---------------------
   ## 
   ## This function takes a predictor matrix and a Surv obj and uses the glmnet lasso      regularization 
   ## method to select the most predictive features and create a coxph object
   ## predict_matrix is the 'dataset' reformated to replace categorical variables to     binary with dummy

#creat Y (survival matrix) for glmnet
  surv_obj <- Surv(trainSet$time,trainSet$status) 


 ## tranform categorical variables into binary variables with dummy for trainSet
  predict_matrix <- model.matrix(~ ., data=trainSet, 
                                 contrasts.arg = lapply (trainSet[,sapply(trainSet,     is.factor)], contrasts, contrasts=FALSE))

  ## remove the status/time variables from the predictor matrix (x) for glmnet
  predict_matrix <- subset (predict_matrix, select=c(-time,-status))

  ## create a glmnet cox object using lasso regularization
  glmnet.obj <- glmnet (predict_matrix, surv_obj, family="cox")

  # find lambda for which dev.ratio is max 
  max.dev.index <- which.max(glmnet.obj$dev.ratio) 
      optimal.lambda <- glmnet.obj$lambda[max.dev.index] 

  # take beta for optimal lambda 
  optimal.beta  <- glmnet.obj$beta[,max.dev.index] 

  # find non zero beta coef 
  nonzero.coef <- abs(optimal.beta)>0 
  selectedBeta <- optimal.beta[nonzero.coef] 

  # take only covariates for which beta is not zero 
  selectedVar   <- predict_matrix[,nonzero.coef] 

 # create a dataframe for trainSet with time, status and selected variables in binary      representation for evaluation in pec
 reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))

  # create coxph object with pre-defined coefficients 
   glmnet.cox <- coxph(surv_obj ~ selectedVar,data = reformat_dataSet,model=TRUE,      singular.ok=FALSE,init=selectedBeta,iter=0)


 ##------------------------------------------------------------------------------------   -------------------
  ##                                    MODEL PERFORMANCE
  ##-----------------------------------------------------------------------------------    --------------------
  ## 
  set.seed(17743)
  pec.f <- as.formula(Hist(time,status) ~ 1)

   ## Brier score for the cox-glmnet model
   brierGlmnet <- pec(list(glmnet.cox), data= reformat_dataSet , splitMethod="BootCV",  B=50)


Here is the result:

Prediction matrix has wrong dimensions:
368 rows and 318 columns.           --->(but there are only 313 predicting vars     in the dataset)
 But requested are predicted probabilities for
 138 subjects (rows) in newdata and 315 time points (columns) ---? (315=313 predicting     vars+status+time)
This may happen when some covariate values are missing in newdata!?
Warning in FUN(1:2[[2L]], ...) :

Oddly, when I call print on the glmnet.cox object I get that it has 313 variables and not as pec outputs (318) print(glmnet.cox) Likelihood ratio test=0 on 313 df, p=1 n= 368, number of events= 288


Here is Mark's response:

I suspect that you are going to need to contact the author/maintainer of the pec package for detailed assistance. From a search of the R list archives, there are not that many posts pertaining to the package, which is generally an indication of the breadth of usage within the community. The lack of relevant posts would likely correlate to the low number of users who may be in a position to assist you. Thus, the package author/maintainer in this case, will likely be the best and most expedient resource.

I hope that you find the above useful in some manner.

Regards,



Marc

-----Original Message-----
From: Marc Schwartz [mailto:marc_schwartz at me.com] 
Sent: Saturday, July 06, 2013 8:46 AM
To: E Joffe
Cc: r-help at r-project.org
Subject: Re: [R] coxph won't converge when including categorical (factor) variables

On Jul 6, 2013, at 7:04 AM, E Joffe <ejoffe at hotmail.com> wrote:

> Hello,
> 
> 
> 
> [rephrasing and reposting  of a previous question (that was not 
> answered) with new information]
> 
> 
> 
> I have a dataset of 371 observations.
> 
> When I run coxph with numeric variables it works fine.
> 
> However, when I try to add factor (categorical) variables it returns 
> "Ran out of iterations and the model did not converge"
> 
> 
> 
> Of note, when I restructure all factors to binary variables with dummy 
> and use glmnet-lasso the model converges.
> 
> 
> 
> Here are examples of the code and output (including summary 
> description of the variables):
> 
>> maxSTree.cox <- coxph (Surv(time,status)~Chemo_Simple, data=dataset)
> 
> 
> 
> Warning message:
> 
> In fitter(X, Y, strats, offset, init, control, weights = weights,  :
> 
>  Ran out of iterations and did not converge
> 
> 
> 
>> summary (dataset$Chemo_Simple)
> 
>                        Anthra_HDAC       Anthra_Plus       ArsenicAtra
> ATRA           ATRA_GO 
> 
>                0               163                 2                12
> 0                 2 
> 
>         ATRA_IDA Demeth_HistoneDAC          Flu_HDAC     Flu_HDAC_plus
> HDAC_Clof         HDAC_only 
> 
>                0                34                37                 4
> 24                 1 
> 
>        HDAC_Plus        LowArac       LowDAC_Clof         MYLO_IL11
> Phase1
> 
>                4                 8                30                 5
> 5
> 
>              SCT    StdARAC_Anthra      StdAraC_Plus          Targeted
> VNP40101M
> 
>                0                 0                 0                13
> 23
> 
> 
> 
> 
> 
> HELP !!!!
> 


You have 371 observations, but did not indicate how many events you have in that dataset. A cross tabulation of the 'status' factor with Chemo_Simple is likely to be enlightening to get a sense of the distribution of events for each level of Chemo_Simple.


Chemo_Simple has a number of levels with rather low counts (ignoring the levels with 0's for the moment), which is likely to be a part of the problem. There is likely to be an issue fitting the model for some of these levels, bearing in mind that your "reference level" of Anthra_HDAC has a large proportion of the observations and with the default treatment contrasts, each of the other levels will be compared to it.

You should also run:

  dataset$Chemo_Simple <- factor(dataset$Chemo_Simple)

to get rid of the unused factor levels. A quick check of the coxph() code versus, for example, lm()/glm(), reveals that while the latter will drop unused factor levels when creating the internal model dataframe, the former will not. A check of some test output here with coxph() suggests that the unused factor levels will simply appear as NA's in the coxph() output without affecting the levels that are present, but it will be cleaner to remove them a priori.

It is also likely that you don't have enough events to handle the effective covariate degrees of freedom that this single factor model will have. By my count (the formatting above is corrupted), you have 16 non-zero factor levels, which would be 15 covariate degrees of freedom consumed by this single factor. A general rule of thumb for Cox models (and logistic regression) is to have 20 events per covariate degree of freedom to avoid overfitting, which means that you would really need 300 "events". In this context, events are the smaller count of the two possible levels of "status". Since you only have 371 total observations, there is no way that you could have 300 events, since you would need to have at least 600 observations. Thus, it is likely that you are attempting to overfit the model to the data as well.

The issue of using glmnet on a matrix of separate dummy variables and it working is likely to be an outcome of the LASSO method penalizing/shrinking the factor levels that are irrelevant to have coefficients of 0. Thus, I would envision that the effective number of your factor levels is reduced as a consequence, allowing the model to be fit.

You likely need to consider collapsing some of the low count factor levels into an "Other" category, if it makes contextual sense to do so for your data. 

Regards,

Marc Schwartz


From wdunlap at tibco.com  Sun Jul  7 19:22:57 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 7 Jul 2013 17:22:57 +0000
Subject: [R] Transferring commas in character vector to expression
In-Reply-To: <CAGrYeXi-saL2SGPfO_qSx15RB3=S9KOQ5W1ie1tuJSH1a92Dkg@mail.gmail.com>
References: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>
	<201307062233.r66MXkNo028982@mail16.tpgi.com.au>
	<CAGrYeXh02OG+6rQ2meBpVEAdTVe9=9tE4nDSaGpg5=A62wJ+2w@mail.gmail.com>
	<201307070438.r674cbqq012554@mail15.tpg.com.au>
	<CAGrYeXi-saL2SGPfO_qSx15RB3=S9KOQ5W1ie1tuJSH1a92Dkg@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C31A45C@PA-MBX01.na.tibco.com>

> x.lab <- gsub(",","*symbol(\"\\\\54\")*", x.lab)

Wouldn't using just
   "*\",\"*"
instead of
   "*symbol(\"\\\\54\")*"
as the replacement do the same thing?
To me it is simpler to understand.

Note that this fails if the comma is the first or last
character in the input because '*something*' is
not a valid expression.  Another problem is that '**'
is parsed the same as "^", so "a**d" is displayed as
"a Delta superscript Delta d".  One way to deal with that
problem is to strip possible '*'s from the ends of
x.lab and convert '**'s to '*'s before giving it to the parser.
   x.lab <- gsub("^\\*|\\*$", "", x.lab)
   x.lab <- gsub("\\*\\*", "*", x.lab)
as in
f1 <- function (x.lab) 
{
    x.lab <- gsub("\\*", "*Delta*", x.lab)
    x.lab <- gsub(",", "*\",\"*", x.lab)
    x.lab <- gsub("^\\*|\\*$", "", x.lab)
    x.lab <- gsub("\\*\\*", "*", x.lab)
    parse(text = x.lab, keep.source = FALSE)
}
where the code in your mail corresponds to the function f0:
f0 <- function (x.lab) 
{
    x.lab <- gsub("\\*", "*Delta*", x.lab)
    x.lab <- gsub(",", "*symbol(\"\\\\54\")*", x.lab)
    parse(text = x.lab, keep.source = FALSE)
}

Another approach is not to turn the commas into strings, but
turn anything that is not a '*' into a string.  Then you don't have
to change your code when you discover that the inputs might
contain semicolons or something else.
f2 <- function (x.lab) 
{
    x.lab <- gsub("([^*]+)", " \"\\1\" ", x.lab)
    # I put spaces around things to make it a little more readable;
    # they may not be very readable in some fonts.
    x.lab <- gsub("\\*", " * Delta * ", x.lab)
    x.lab <- gsub("^ \\*|\\* $", "", x.lab)
    x.lab <- gsub("\\*  \\*", "*", x.lab)
    parse(text = x.lab, keep.source = FALSE)
}

Use it as in
   dotchart(1:4, labels=f2(c("***d", ",,c*", "a,*d", "****")))
This code gets ugly pretty quickly so you should bury it in a function.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Eric Archer - NOAA Federal
> Sent: Saturday, July 06, 2013 10:55 PM
> To: Duncan Mackay; r-help-r-project.org
> Subject: Re: [R] Transferring commas in character vector to expression
> 
> Duncan,
> 
> Thanks! That was the tip I needed. With that, I was able to get this to
> work perfectly:
> 
> x.lab <- c("a*a", "bbb", "c,cc*c", "d,dd")
> x.lab <- gsub("\\*", "*Delta*", x.lab)
> x.lab <- gsub(",", "*symbol(\"\\\\54\")*", x.lab)
> dotchart(1:length(x.lab), labels = parse(text = x.lab))
> 
> 
> 
> On Sat, Jul 6, 2013 at 9:38 PM, Duncan Mackay <mackay at northnet.com.au>wrote:
> 
> >  Eric
> >
> > How does this look - (you might have to add a few symbol("\54")  where
> > needed for me this give a comma on windows7  ver 3.1
> >
> >  xyplot(1:4 ~ 1:4, scales = list(x=list(at = 1:4, labels =
> >
> c(expression(a*a),expression(bbb),expression(c*Delta*cc*c),expression(d*Delta*symbol(
> "\54")*dd)
> > ) ) ) )
> >
> > I mostly use lattice and have forgotten how to do labels in basic plot so
> > have used lattice. should be similar and you can modify to suit.
> >
> > It was trial and error in going up through the numbers  from about 38
> >
> >
> > Duncan
> >
> > At 11:57 7/07/2013, you wrote:
> >
> > Duncan,
> >
> > Thanks for the suggestion, but that won't work for my situation. I'm
> > trying to use a character vector to label some axis ticks. There are some
> > elements in the vector that have either a comma, or both Greek symbols and
> > a comma, like the the third and fourth elements in x.lab below:
> >
> > > x <- 1:4
> > > x.lab <- c("a*a", "bbb", "c,cc*c", "d,dd")
> > > x.lab <- gsub("\\*", "*Delta*", x.lab)
> > > x.lab <- parse(text = x.lab)
> > Error in parse(text = x.lab) : <text>:3:2: unexpected ','
> > 2: bbb
> > 3: c,
> >    ^
> > > dotchart(x, labels = x.lab)
> >
> > The root problem that I'm stumped on is how to either:
> > 1) insert a comma into an expression and have it be read as a valid
> > character, or
> > 2) replace the comma in the character string with 'list(a, b, c)' as in
> > the help for plotmath and have it interpreted correctly.
> >
> > Cheers,
> > eric
> >
> >
> > On Sat, Jul 6, 2013 at 3:33 PM, Duncan Mackay <mackay at northnet.com.au >
> > wrote:
> >  Hi Eric
> >
> > I have not been following the thread but following on what David has said
> > on previous occasions
> >
> > try for example
> >
> > plot(1,1, ylab =  expression("aa aaa,aa bb"*Delta*"b cccc"*Delta*"cc, c") )
> >
> > Below is from a partly saved previous post of David's several months ago
> > which may give you some ideas
> >
> > DATA_names<-c(
> > "A mg kg",
> > "B mg kg",
> > "C mg kg",
> > "D mg kg",
> > "E mg kg",
> > "F mg kg",
> > "G mg kg",
> > "H mg kg")
> >
> > pos <- barplot(1:length(DATA_names))
> > text(x=pos,y=-1, xpd=TRUE, srt=45,
> >                     labels= sapply( gsub("mg kg", "(mg kg)^-1",
> > DATA_names),
> >                                     as.expression))
> >
> > HTH
> >
> > Duncan
> >
> >
> > Duncan Mackay
> > Department of Agronomy and Soil Science
> > University of New England
> > Armidale NSW 2351
> > Email: home: mackay at northnet.com.au
> >
> >
> >
> >
> > At 07:47 6/07/2013, you wrote:
> >  I'm trying to format a given character vector as an expression with Greek
> > symbols to be used in labeling axis ticks. Thanks to some help from David
> > Winsemius, I've learned how to make the substitution and place the Greek
> > symbols in, however I've run into another problem: Some of my labels have
> > commas in them, so when the parse command is executed, there is an
> > unexpected symbol error. For example:
> >
> > > x <- c("aa", "aaa,aa", "bb*Delta*b", "cccc*Delta*cc,c")
> > > parse(text = x)
> > Error in parse(text = x) : <text>:2:4: unexpected ','
> > 1: aa
> > 2: aaa,
> >      ^
> >
> > I've tried various iterations of wrapping the commas in interior quotes
> > ("aaa\",\"aa"), but then the error shifts to the quote. I see in plotmath
> > that 'list(a,b,c)' gives me comma separated values, but I haven't been able
> > to work out how to get this construction for elements that have a comma.
> >
> > Is this possible?
> >
> > --
> >
> > Eric Archer, Ph.D.
> > Southwest Fisheries Science Center
> > NMFS, NOAA
> > 8901 La Jolla Shores Drive
> > La Jolla, CA 92037 USA
> > 858-546-7121 (work)
> > 858-546-7003 (FAX)
> >
> > Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> > ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
> >
> > "The universe doesn't care what you believe.
> >  The wonderful thing about science is that it
> >    doesn't ask for your faith, it just asks
> >    for your eyes."  - Randall Munroe
> >
> > "Lighthouses are more helpful than churches."
> >    - Benjamin Franklin
> >
> >    "...but I'll take a GPS over either one."
> >        - John C. "Craig" George
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> >  https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> >
> >
> >
> >
> >
> > --
> >
> > Eric Archer, Ph.D.
> > Southwest Fisheries Science Center
> > NMFS, NOAA
> > 8901 La Jolla Shores Drive
> > La Jolla, CA 92037 USA
> > 858-546-7121 (work)
> > 858-546-7003 (FAX)
> >
> > Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> > ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
> >
> > "The universe doesn't care what you believe.
> >  The wonderful thing about science is that it
> >    doesn't ask for your faith, it just asks
> >    for your eyes."  - Randall Munroe
> >
> > "Lighthouses are more helpful than churches."
> >    - Benjamin Franklin
> >
> >    "...but I'll take a GPS over either one."
> >        - John C. "Craig" George
> >
> >
> 
> 
> --
> 
> Eric Archer, Ph.D.
> Southwest Fisheries Science Center
> NMFS, NOAA
> 8901 La Jolla Shores Drive
> La Jolla, CA 92037 USA
> 858-546-7121 (work)
> 858-546-7003 (FAX)
> 
> Marine Mammal Genetics Group: swfsc.noaa.gov/prd-mmgenetics
> ETP Cetacean Assessment Program: swfsc.noaa.gov/prd-etp
> 
> "The universe doesn't care what you believe.
>  The wonderful thing about science is that it
>    doesn't ask for your faith, it just asks
>    for your eyes."  - Randall Munroe
> 
> "Lighthouses are more helpful than churches."
>    - Benjamin Franklin
> 
>    "...but I'll take a GPS over either one."
>        - John C. "Craig" George
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stgries at gmail.com  Sun Jul  7 22:14:08 2013
From: stgries at gmail.com (Stefan Th. Gries)
Date: Sun, 7 Jul 2013 16:14:08 -0400
Subject: [R] Hierarchical multi-level model with lmer: why are the
 highest-level random adjustments 0?
Message-ID: <CAFrBz2ngQ6Keyu1NGQhn8K8k+q8Oh26F5+bSvCcsR67jT=P0ZA@mail.gmail.com>

Hi all

I have a hopefully not too stupid question about multi-level /
mixed-effects modeling. I was trying to test a strategy from Crawley's
2013 R Book on a data set with the following structure:

- dependent variable: CONSTRUCTION (a factor with 2 levels)
- independent fixed effect: LENGTH (an integer in the interval [1, 61])
- random effects with the following hierarchical structure: MODE >
REGISTER > SUBREGISTER > FILE. Specifically:

MODE: S
  REGISTER: monolog
    SUBREGISTER: scripted
    SUBREGISTER: unscripted
  REGISTER: dialog
    SUBREGISTER: private
    SUBREGISTER: public
  REGISTER: mix
    SUBREGISTER: broadcast
MODE: W
  REGISTER: printed
    SUBREGISTER: academic
    SUBREGISTER: creative
    SUBREGISTER: instructional
    SUBREGISTER: nonacademic
    SUBREGISTER: persuasive
    SUBREGISTER: reportage
  REGISTER: nonprinted
    SUBREGISTER: letters
    SUBREGISTER: nonprofessional

with various levels of FILE in each level of SUBREGISTER. Here's the
head of the relevant data frame (best viewed with a non-proportional
font):

  CASE MODE   REGISTER     SUBREGISTER    FILE CONSTRUCTION LENGTH
1    1    W    printed       reportage W2C-002 V_P_DO       11
2    2    W    printed     nonacademic W2B-035 V_P_DO        8
3    3    W nonprinted nonprofessional W1A-014 V_P_DO        8
4    4    W    printed       reportage W2C-005 V_P_DO        6
5    5    S     dialog         private S1A-073 V_DO_P        2
6    6    S     dialog         private S1A-073 V_DO_P        2

And here's the unique-types distribution of FILE in the design:
tapply(FILE, list(SUBREGISTER, REGISTER, MODE), function (qwe)
length(unique(qwe)))

, , S
                dialog mix monolog nonprinted printed
academic             .   .       .          .       .
broadcast            .  20       .          .       .
creative             .   .       .          .       .
instructional        .   .       .          .       .
letters              .   .       .          .       .
nonacademic          .   .       .          .       .
nonprofessional      .   .       .          .       .
persuasive           .   .       .          .       .
private             96   .       .          .       .
public              77   .       .          .       .
reportage            .   .       .          .       .
scripted             .   .      25          .       .
unscripted           .   .      66          .       .

, , W
                dialog mix monolog nonprinted printed
academic             .   .       .          .      26
broadcast            .   .       .          .       .
creative             .   .       .          .      20
instructional        .   .       .          .      19
letters              .   .       .         28       .
nonacademic          .   .       .          .      37
nonprofessional      .   .       .         17       .
persuasive           .   .       .          .       9
private              .   .       .          .       .
public               .   .       .          .       .
reportage            .   .       .          .      20
scripted             .   .       .          .       .
unscripted           .   .       .          .       .

# I would usually have done this (using lme4)
model.1.tog <- lmer(CONSTRUCTION ~ LENGTH +
(1|MODE/REGISTER/SUBREGISTER), family=binomial)

# but Crawley (2013:692ff.) suggests this:
LEVEL2 <- MODE:REGISTER
LEVEL3 <- MODE:REGISTER:SUBREGISTER
model.1.sep <- lmer(CONSTRUCTION ~ LENGTH + (1|MODE) + (1|LEVEL2) +
(1|LEVEL3), family=binomial)

The results are the same for fixed and random effects, ok, but what I
don't understand in this case is why the random adjustments to
intercepts at the highest level of hierarchical organization (MODE)
are 0:

ranef(model.1.sep)
$LEVEL3
                             (Intercept)
S:dialog:private              -0.9482442
S:dialog:public                0.1216021
[...]

$LEVEL2
             (Intercept)
S:dialog      -0.4746389
[...]

$MODE
  (Intercept)
S           0
W           0

I am guessing that's got something to do with the fact that what the
random adjustments to intercepts at the level of MODE would do is
already taken care of by the random adjustments to intercepts on the
lower levels of the hierarchical organization of the data - but when I
run the code from Crawley on his data (a linear mixed-effects model,
not a generalized linear mixed-effects model as mine), the highest
hierarchical level of organization does not return 0 as random
adjustment. What am I missing?

Thanks for any input you may have!
STG


From gunter.berton at gene.com  Mon Jul  8 00:50:13 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 7 Jul 2013 15:50:13 -0700
Subject: [R] Hierarchical multi-level model with lmer: why are the
 highest-level random adjustments 0?
In-Reply-To: <CAFrBz2ngQ6Keyu1NGQhn8K8k+q8Oh26F5+bSvCcsR67jT=P0ZA@mail.gmail.com>
References: <CAFrBz2ngQ6Keyu1NGQhn8K8k+q8Oh26F5+bSvCcsR67jT=P0ZA@mail.gmail.com>
Message-ID: <CACk-te0u-e4QoqKi8rEt24jy7-WHecfbWbQmq=afbS3uWeVSeA@mail.gmail.com>

I think this is much better posted on r-sig-mixed-models rather than r-help.

-- Bert

On Sun, Jul 7, 2013 at 1:14 PM, Stefan Th. Gries <stgries at gmail.com> wrote:
> Hi all
>
> I have a hopefully not too stupid question about multi-level /
> mixed-effects modeling. I was trying to test a strategy from Crawley's
> 2013 R Book on a data set with the following structure:
>
> - dependent variable: CONSTRUCTION (a factor with 2 levels)
> - independent fixed effect: LENGTH (an integer in the interval [1, 61])
> - random effects with the following hierarchical structure: MODE >
> REGISTER > SUBREGISTER > FILE. Specifically:
>
> MODE: S
>   REGISTER: monolog
>     SUBREGISTER: scripted
>     SUBREGISTER: unscripted
>   REGISTER: dialog
>     SUBREGISTER: private
>     SUBREGISTER: public
>   REGISTER: mix
>     SUBREGISTER: broadcast
> MODE: W
>   REGISTER: printed
>     SUBREGISTER: academic
>     SUBREGISTER: creative
>     SUBREGISTER: instructional
>     SUBREGISTER: nonacademic
>     SUBREGISTER: persuasive
>     SUBREGISTER: reportage
>   REGISTER: nonprinted
>     SUBREGISTER: letters
>     SUBREGISTER: nonprofessional
>
> with various levels of FILE in each level of SUBREGISTER. Here's the
> head of the relevant data frame (best viewed with a non-proportional
> font):
>
>   CASE MODE   REGISTER     SUBREGISTER    FILE CONSTRUCTION LENGTH
> 1    1    W    printed       reportage W2C-002 V_P_DO       11
> 2    2    W    printed     nonacademic W2B-035 V_P_DO        8
> 3    3    W nonprinted nonprofessional W1A-014 V_P_DO        8
> 4    4    W    printed       reportage W2C-005 V_P_DO        6
> 5    5    S     dialog         private S1A-073 V_DO_P        2
> 6    6    S     dialog         private S1A-073 V_DO_P        2
>
> And here's the unique-types distribution of FILE in the design:
> tapply(FILE, list(SUBREGISTER, REGISTER, MODE), function (qwe)
> length(unique(qwe)))
>
> , , S
>                 dialog mix monolog nonprinted printed
> academic             .   .       .          .       .
> broadcast            .  20       .          .       .
> creative             .   .       .          .       .
> instructional        .   .       .          .       .
> letters              .   .       .          .       .
> nonacademic          .   .       .          .       .
> nonprofessional      .   .       .          .       .
> persuasive           .   .       .          .       .
> private             96   .       .          .       .
> public              77   .       .          .       .
> reportage            .   .       .          .       .
> scripted             .   .      25          .       .
> unscripted           .   .      66          .       .
>
> , , W
>                 dialog mix monolog nonprinted printed
> academic             .   .       .          .      26
> broadcast            .   .       .          .       .
> creative             .   .       .          .      20
> instructional        .   .       .          .      19
> letters              .   .       .         28       .
> nonacademic          .   .       .          .      37
> nonprofessional      .   .       .         17       .
> persuasive           .   .       .          .       9
> private              .   .       .          .       .
> public               .   .       .          .       .
> reportage            .   .       .          .      20
> scripted             .   .       .          .       .
> unscripted           .   .       .          .       .
>
> # I would usually have done this (using lme4)
> model.1.tog <- lmer(CONSTRUCTION ~ LENGTH +
> (1|MODE/REGISTER/SUBREGISTER), family=binomial)
>
> # but Crawley (2013:692ff.) suggests this:
> LEVEL2 <- MODE:REGISTER
> LEVEL3 <- MODE:REGISTER:SUBREGISTER
> model.1.sep <- lmer(CONSTRUCTION ~ LENGTH + (1|MODE) + (1|LEVEL2) +
> (1|LEVEL3), family=binomial)
>
> The results are the same for fixed and random effects, ok, but what I
> don't understand in this case is why the random adjustments to
> intercepts at the highest level of hierarchical organization (MODE)
> are 0:
>
> ranef(model.1.sep)
> $LEVEL3
>                              (Intercept)
> S:dialog:private              -0.9482442
> S:dialog:public                0.1216021
> [...]
>
> $LEVEL2
>              (Intercept)
> S:dialog      -0.4746389
> [...]
>
> $MODE
>   (Intercept)
> S           0
> W           0
>
> I am guessing that's got something to do with the fact that what the
> random adjustments to intercepts at the level of MODE would do is
> already taken care of by the random adjustments to intercepts on the
> lower levels of the hierarchical organization of the data - but when I
> run the code from Crawley on his data (a linear mixed-effects model,
> not a generalized linear mixed-effects model as mine), the highest
> hierarchical level of organization does not return 0 as random
> adjustment. What am I missing?
>
> Thanks for any input you may have!
> STG
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Mon Jul  8 03:01:42 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 7 Jul 2013 18:01:42 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
Message-ID: <1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
I am not sure how your dataset looks like.? If it is like the one below: (otherwise, please provide a reproducible example using ?dput())

dat1<- read.table(text="
datetime
10/02/2010
02:30
11/02/2010
04:00
14/02/2010
06:30
",sep="",header=TRUE,stringsAsFactors=FALSE)

lst1<-split(dat1,(seq_along(dat1$datetime)-1)%%2+1)
?dat2<- data.frame(datetime=as.POSIXct(paste(lst1[[1]][,1],lst1[[2]][,1]),format="%d/%m/%Y %H:%M"))
?str(dat2)
#'data.frame':??? 3 obs. of? 1 variable:
# $ datetime: POSIXct, format: "2010-02-10 02:30:00" "2010-02-11 04:00:00" ...
?dat2
#???????????? datetime
#1 2010-02-10 02:30:00
#2 2010-02-11 04:00:00
#3 2010-02-14 06:30:00


#or
data.frame(datetime=as.POSIXct(paste(dat1[seq(1,nrow(dat1),by=2),1],? dat1[seq(2,nrow(dat1),by=2),1]),format="%d/%m/%Y %H:%M"))
#???????????? datetime
#1 2010-02-10 02:30:00
#2 2010-02-11 04:00:00
#3 2010-02-14 06:30:00



A.K.



Hey everybody, 

I am a new user of R software. I don't know how I can merge two rows in 
one. In fact, I have one row with the date(dd/mm/yyyy) and another with the 
time (hh:mm) and I would like to get one row with date time in order to 
convert to POSIXct. How can I do it??


From cxg040 at email.uark.edu  Mon Jul  8 03:54:58 2013
From: cxg040 at email.uark.edu (Chirag Gupta)
Date: Sun, 7 Jul 2013 20:54:58 -0500
Subject: [R] Check a list of genes for a specific GO term
In-Reply-To: <1025527908.579684.1373198135756.JavaMail.root@fhcrc.org>
References: <51D934BD.7060904@sapo.pt>
	<1025527908.579684.1373198135756.JavaMail.root@fhcrc.org>
Message-ID: <CADESCNzytZ+gUqXO1mqNdLx9UUOQN-SDp1nmHhE5Brp+CujVhw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130707/6aa2468e/attachment.pl>

From bbolker at gmail.com  Mon Jul  8 06:19:02 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 8 Jul 2013 04:19:02 +0000
Subject: [R] (lme4) p-values for single terms in mixed models involved
	in sig interactions
References: <BAY172-W42912A7EB359701F474D5A877E0@phx.gbl>
Message-ID: <loom.20130708T060246-952@post.gmane.org>

sarah hoffmann <s.hoffmann85 <at> outlook.com> writes:

> I am using lme4 to fit a mixed effects model to my data. I have a
> significant interaction between two variables. My question is what
> is the correct way to get p-values for single terms involved in that
> interaction.  I have been using stepwise backwards deletion and
> model comparisons to get p-values,and refitting the model using a
> REML approach to get estimates.However, presumably to get the p
> values for single terms, I also have to remove the interaction as
> well, and therefore inaccurate.  I have confused myself with this
> now, as to whether in this case you should compare a model with the
> interaction and the single term of interest removed to the minimum
> adequate model (in which case the p values are over inflated for the
> single terms), or whether to remove the interaction from the minimum
> adequate model, and then compare this to an updated model, with the
> single term removed.

> This is an example of what the model would look like:
> library(lme4)
> minadequatemodel<-lmer(sq_rate~(day+temp+
>  brood_size+weight+weight:brood_size+(1|ident),data=prov,REML=FALSE)
> 
> ##to get p values for e.g. temp
> pvalmodtemp<-update(minadequatemodel,~.+temp)
> anova(modelfin,modeltemp)
> 
> ###but what's the correct way to get p value for brood_size or weight?
> 
> Your help would be greatly appreciated...thanks! 

  There are a variety of issues involved here, and most of  them are
not lme4-related.  In fact, you'll have an even bigger problem with
lme4 since by default it doesn't give p-values at all (see
http://glmm.wikidot.com/faq for a description of why not, and some
things you can do about that).

 * stepwards backwards deletion is almost always a bad idea
(see e.g. Harrell _Regression Modeling Strategies_ 2001, or google
'"stepwise regression" problems')

* violating marginality (i.e. testing the significance of main effects
in the presence of an interaction containing the main effect) is
almost always a bad idea: e.g. google "Venables exegesis". There are
_very_ occasionally reasons you would want to consider a model with
an interaction term but with one of the main effects missing/removed (e.g.
if you know based on an experimental design that all the treatments
in an experiment start at the same time, you might want to set the
intercepts the same, which would give you (time + treatment:time).
It's hard to specify this case for two categorical variables; you
pretty much have to construct the dummy variables yourself.

  Ben Bolker


From mtmorgan at fhcrc.org  Mon Jul  8 09:12:49 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 8 Jul 2013 00:12:49 -0700 (PDT)
Subject: [R] Check a list of genes for a specific GO term
In-Reply-To: <CADESCNzytZ+gUqXO1mqNdLx9UUOQN-SDp1nmHhE5Brp+CujVhw@mail.gmail.com>
Message-ID: <1694824509.625608.1373267569277.JavaMail.root@fhcrc.org>

Please ask follow-up questions about Bioconductor packages on the Bioconductor mailing list.

  http://bioconductor.org/help/mailing-list/mailform/

If you are interested in organisms rather than chips, use the organism package, e.g., for Homo sapiens

  library(org.Hs.eg.db)
  df0 = select(org.Hs.eg.db, keys(org.Hs.eg.db), "GO")

giving

  > head(df)
    ENTREZID         GO EVIDENCE ONTOLOGY
  1        1 GO:0003674       ND       MF
  2        1 GO:0005576      IDA       CC
  3        1 GO:0008150       ND       BP
  4       10 GO:0004060      IEA       MF
  5       10 GO:0005829      TAS       CC
  6       10 GO:0006805      TAS       BP

from which you might

  df = unique(df0[df0$ONTOLOGY == "BP", c("ENTREZID", "GO")])
  len = tapply(df$ENTREZID, df$GO, length)
  keep = len[len < 1000]

to get a vector of counts, with names being GO ids. Remember that the GO is a directed acyclic graph, so terms are nested; you'll likely want to give some thought to what you're actually wanting.

The vignettes in the AnnotationDbi and Category packages

  http://bioconductor.org/packages/release/bioc/html/AnnotationDbi.html
  http://bioconductor.org/packages/release/bioc/html/Category.html

are two useful sources of information, as is the annotation work flow

  http://bioconductor.org/help/workflows/annotation/

Martin

----- Chirag Gupta <cxg040 at email.uark.edu> wrote:
> Hi
> I think I asked the wrong question. Apologies.
> 
> Actually I want all the GO BP annotations for my organism and from them I
> want to retain only those annotations which annotate less than a specified
> number of genes. (say <1000 genes)
> 
> I hope I have put it clearly.
> 
> sorry again.
> 
> Thanks!
> 
> 
> On Sun, Jul 7, 2013 at 6:55 AM, Martin Morgan <mtmorgan at fhcrc.org> wrote:
> 
> > In Bioconductor, install the annotation package
> >
> >
> > http://bioconductor.org/packages/release/BiocViews.html#___AnnotationData
> >
> > corresponding to your chip, e.g.,
> >
> >   source("http://bioconductor.org/biocLite.R")
> >   biocLite("hgu95av2.db")
> >
> > then load it and select the GO terms corresponding to your probes
> >
> >   library(hgu95av2.db)
> >   lkup <- select(hgu95av2.db, rownames(dat), "GO")
> >
> > then use standard R commands to find the probesets that have the GO id
> > you're interested in
> >
> >   keep = lkup$GO %in% "GO:0006355"
> >   unique(lkup$PROBEID[keep])
> >
> > Ask follow-up questions about Bioconductor packages on the Bioconductor
> > mailing list
> >
> >   http://bioconductor.org/help/mailing-list/mailform/
> >
> > Martin
> > ----- Rui Barradas <ruipbarradas at sapo.pt> wrote:
> > > Hello,
> > >
> > > Your question is not very clear, maybe if you post a data example.
> > > To do so, use ?dput. If your data frame is named 'dat', use the
> > following.
> > >
> > > dput(head(dat, 50))  # paste the output of this in a post
> > >
> > >
> > > If you want to get the rownames matching a certain pattern, maybe
> > > something like the following.
> > >
> > >
> > > idx <- grep("GO:0006355", rownames(dat))
> > > dat[idx, ]
> > >
> > >
> > > Hope this helps,
> > >
> > > Rui Barradas
> > >
> > >
> > > Em 07-07-2013 07:01, Chirag Gupta escreveu:
> > > > Hello everyone
> > > >
> > > > I have a dataframe with rows as probeset ID and columns as samples
> > > > I want to check the rownames and find which are those probes are
> > > > transcription factors. (GO:0006355 )
> > > >
> > > > Any suggestions?
> > > >
> > > > Thanks!
> > > >
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > > and provide commented, minimal, self-contained, reproducible code.
> >
> 
> 
> 
> -- 
> *Chirag Gupta*
> Department of Crop, Soil, and Environmental Sciences,
> 115 Plant Sciences Building, Fayetteville, Arkansas 72701


From yuliya.rmail at gmail.com  Mon Jul  8 09:46:08 2013
From: yuliya.rmail at gmail.com (Yuliya Matveyeva)
Date: Mon, 8 Jul 2013 11:46:08 +0400
Subject: [R] Splitting a string expression into components
In-Reply-To: <CAHgH9_Gn+mzJF7vM0PgWDYEZPVG1=2QCTY2BjWLHJVAHwJ2OWg@mail.gmail.com>
References: <CAHgH9_Gn+mzJF7vM0PgWDYEZPVG1=2QCTY2BjWLHJVAHwJ2OWg@mail.gmail.com>
Message-ID: <CAOE1P1EZT7_-L-BBcOo+bGJXkxLjqRHtXYiwtKBe5GyzMVkpVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/b8f8b930/attachment.pl>

From HodgessE at uhd.edu  Sun Jul  7 14:05:25 2013
From: HodgessE at uhd.edu (Hodgess, Erin)
Date: Sun, 7 Jul 2013 12:05:25 +0000
Subject: [R] [R-sig-Geo] spatstat output
In-Reply-To: <CAEW+BDKqRgQzsf_f1NYfTET-LsYN6cSG9M8cNzREiKz+kg2Tdw@mail.gmail.com>
References: <CAEW+BDKqRgQzsf_f1NYfTET-LsYN6cSG9M8cNzREiKz+kg2Tdw@mail.gmail.com>
Message-ID: <FF9DB805FC41CC4E95825A50F680630217A13CB0@columbia.uhd.campus>

Hello!

For the first question, here is an example:

> E <- alltypes(bramblecanes, Kest, nsim = 100, envelope =
+ TRUE,savepatterns=TRUE,correction="isotropic")
> E$fns[[1]]$r
> E$fns[[1]]$obs


________________________________________
From: r-sig-geo-bounces at r-project.org [r-sig-geo-bounces at r-project.org] on behalf of catalin roibu [catalinroibu at gmail.com]
Sent: Sunday, July 07, 2013 5:12 AM
To: r-sig-geo at stat.math.ethz.ch
Cc: r-help at r-project.org
Subject: [R-sig-Geo] spatstat output

Dear R users,
Is there a possibility to extract only the r, CI's envelope and L function
from the output of spatstat?
I use this code
E <- alltypes(df1, Kest, nsim = 100, envelope =
TRUE,savepatterns=TRUE,correction="isotropic")
And second question, is there a possibility to modify the margin of plot in
spatstat?

plot(E, sqrt(./pi) - r ~ r, ylab = "L(r)-r",main=NULL,sub=NULL,las=1)

Thank you very much for your help!

CR

--
---
Catalin-Constantin ROIBU
Lecturer PhD, Forestry engineer
Forestry Faculty of Suceava
Str. Universitatii no. 13, Suceava, 720229, Romania
office phone     +4 0230 52 29 78, ext. 531
mobile phone   +4 0745 53 18 01
                       +4 0766 71 76 58
FAX:                +4 0230 52 16 64
silvic.usv.ro

        [[alternative HTML version deleted]]

_______________________________________________
R-sig-Geo mailing list
R-sig-Geo at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-sig-geo


From m.w.heerdink at uva.nl  Sun Jul  7 23:51:27 2013
From: m.w.heerdink at uva.nl (Marc Heerdink)
Date: Sun, 07 Jul 2013 23:51:27 +0200
Subject: [R] Meta-analysis on a repeated measures design with multiple
 trials per subject using metafor
In-Reply-To: <Zen-1UvS2F-0008KR-PL@smarthost01a.mail.zen.net.uk>
References: <51D415D6.5070201@uva.nl>
	<077E31A57DA26E46AB0D493C9966AC730D833E9764@UM-MAIL4112.unimaas.nl>
	<51D69CDB.8010506@uva.nl>
	<Zen-1UvS2F-0008KR-PL@smarthost01a.mail.zen.net.uk>
Message-ID: <51D9E2DF.3050204@uva.nl>

Dear Michael and other readers,

Please see below for my answers to your questions about my data.

On 07/06/2013 02:56 PM, Michael Dewey wrote:
[..]
>> Because everything was randomized, I can only calculate the total
>> number of times a certain response was used under each type of trial.
>> There is no pairing of trials under two treatments, so I am forced to
>> use the marginal totals from your table.
>
> But presumably you could calculate some statistic suitable for
> summarising the relevant features here? Difference in proportions, odds
> ratio, ...

Using the totals, it is indeed easy to calculate the difference in 
proportions or odds ratio based on these totals. However, I am not sure 
how I should calculate a study-level statistic suitable for 
meta-analysis on the basis of these participant-level proportion 
differences.

So, for instance, I have the following table;

pp	proportion_difference
1	0.1
2	0.05
3	0.08
4	0.02
..
N	..

Can I just calculate the mean and standard deviation of these proportion 
differences -- mean(proportion_difference) and sd(proportion_difference) 
-- and use these for meta-analysis? If yes, what escalc measure should I 
use?

[..]
>> One alternative that I have tried over the last few days, is to use
>> the b parameter of interest and it's corresponding standard error from
>> the lme4 regression output that I use to analyse the individual
>> experiments. Then, I use rma(yi, sei) to do a meta-analysis on these
>> parameters. I am not sure this is correct though, since it takes into
>> account between-subjects variance (through a random effect for
>> subject), and it is sensitive to the covariates/moderators I include
>> in the models that I get the b parameters from.
>
> So you end up with 5 values of b? The fact that they adjust for
> different moderators does not seem an issue to me, indeed it could be
> argued to be an advantage of the meta-analytic approach here.

OK, thank you for your comment on this one. I think the results of a 
meta-analysis using these 5 b values are indeed more or less sensible, 
which is encouraging. I think I will go this way if it turns out I 
cannot find a simpler approach, as a simpler approach would be easier to 
sell to potential reviewers.

[..
> I think we are all assuming you have different participants in each
> experiment but I thought I would raise that as a question.

You are right in assuming this, I have different participants in all 5 
experiments.

Thanks all for the help so far, your suggestions are highly appreciated!

Regards,
Marc


From Lucy.Leigh at newcastle.edu.au  Mon Jul  8 02:15:52 2013
From: Lucy.Leigh at newcastle.edu.au (Lucy Leigh)
Date: Mon, 08 Jul 2013 10:15:52 +1000
Subject: [R] Help with installing a .tar.gz package on windows
Message-ID: <51DA915A.ECEB.009F.0@newcastle.edu.au>

Hi, 
I have a source package that isn't available as a windows zip file. Can
anyone explain to me how I can install this on my windows R platform?
When I use the following code: 
 install.packages("PReMiuM_3.0.21.tar.gz", type = "source") 


I get this error message: 



* installing *source* package 'PReMiuM' ... 
** libs 

*** arch - i386 
ERROR: compilation failed for package 'PReMiuM' 
* removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM' 
Warning messages: 
1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL -l
"C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had status
1 
2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") : 
  installation of package ?PReMiuM_3.0.21.tar.gz? had non-zero exit
status 
> 

Thanks for any help anyone can give me, 
Lucy


From Michael.Riechert at the-klu.org  Mon Jul  8 09:21:01 2013
From: Michael.Riechert at the-klu.org (Michael Riechert)
Date: Mon, 8 Jul 2013 07:21:01 +0000
Subject: [R] ChoiceModelR
Message-ID: <0A511BFF87BC3147B5F91EA884F122FB23C7C598@KLU-MAIL-01.KLU.klu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/93b8d71e/attachment.pl>

From zsurzsalaszlo at gmail.com  Mon Jul  8 10:29:10 2013
From: zsurzsalaszlo at gmail.com (Zsurzsa Laszlo)
Date: Mon, 8 Jul 2013 10:29:10 +0200
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DA915A.ECEB.009F.0@newcastle.edu.au>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
Message-ID: <CAF4U=Vmv1TR-Wio0JTtOuQDNVwNVt6jaxegUr_OozzDi6YYyGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/30aa04da/attachment.pl>

From bhh at xs4all.nl  Mon Jul  8 10:38:37 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 8 Jul 2013 10:38:37 +0200
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DA915A.ECEB.009F.0@newcastle.edu.au>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
Message-ID: <154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>


On 08-07-2013, at 02:15, "Lucy Leigh" <Lucy.Leigh at newcastle.edu.au> wrote:

> Hi, 
> I have a source package that isn't available as a windows zip file. Can
> anyone explain to me how I can install this on my windows R platform?
> When I use the following code: 
> install.packages("PReMiuM_3.0.21.tar.gz", type = "source") 
> 
> 

Where did you get that version from?
CRAN has version 3.0.20 and that is available as a binary Windows package (.zip).

As for the error message: you have to have Rtools installed to compile source packages.

Berend

> I get this error message: 
> 
> 
> 
> * installing *source* package 'PReMiuM' ... 
> ** libs 
> 
> *** arch - i386 
> ERROR: compilation failed for package 'PReMiuM' 
> * removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM' 
> Warning messages: 
> 1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had status
> 1 
> 2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") : 
>  installation of package ?PReMiuM_3.0.21.tar.gz? had non-zero exit
> status 
>> 
> 
> Thanks for any help anyone can give me, 
> Lucy
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Mon Jul  8 10:46:25 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 08 Jul 2013 09:46:25 +0100
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DA915A.ECEB.009F.0@newcastle.edu.au>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
Message-ID: <51DA7C61.1080907@stats.ox.ac.uk>

On 08/07/2013 01:15, Lucy Leigh wrote:
> Hi,
> I have a source package that isn't available as a windows zip file. Can
> anyone explain to me how I can install this on my windows R platform?

I am surprised that is all you saw, but running

Rcmd INSTALL PReMiuM_3.0.21.tar.gz

at a shell command line should show you more.

Note that version 3.0.20 does install on Windows: see 
http://cran.r-project.org/web/checks/check_results_PReMiuM.html .  But 
it does need BOOSTLIB set to your local boost installation (and I 
suspect you do not have one).  The suggests that using the winbuilder 
service might well work.

Package-specific questions are best addressed to the maintainer.

> When I use the following code:
>   install.packages("PReMiuM_3.0.21.tar.gz", type = "source")
>
>
> I get this error message:
>
>
>
> * installing *source* package 'PReMiuM' ...
> ** libs
>
> *** arch - i386
> ERROR: compilation failed for package 'PReMiuM'
> * removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM'
> Warning messages:
> 1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL -l
> "C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had status
> 1
> 2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") :
>    installation of package ?PReMiuM_3.0.21.tar.gz? had non-zero exit
> status
>>
>
> Thanks for any help anyone can give me,
> Lucy
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petr.pikal at precheza.cz  Mon Jul  8 11:34:27 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 8 Jul 2013 09:34:27 +0000
Subject: [R] spped up a function
In-Reply-To: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CB97@SRVEXCHMBX.precheza.cz>

Hi

It seems to me, that you basically want merge, but I can miss the point. Try post

dput(head(xact))
dput(head(GPS))

and what shall be desired result based on those 2 datasets.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Santiago Guallar
> Sent: Tuesday, July 02, 2013 7:47 PM
> To: r-help
> Subject: [R] spped up a function
> 
> Hi,
> 
> I have written a function to assign the values of a certain variable
> 'wd' from a dataset to another dataset. Both contain data from the
> same?time period but differ in the length of their time intervals:
> 'GPS' has regular 10-minute intervals whereas 'xact' has irregular
> intervals. I attached simplified text versions from write.table. You
> can also get a dput of 'xact' in this address:
> http://www.megafileupload.com/en/file/431569/xact-dput.html).
> The original objects are large and the function takes almost one hour
> to finish.
> Here's the function:
> 
> fxG= function(xact, GPS){
> l <- rep( 'A', nrow(GPS) )
> v <- unique(GPS$Ring) # the process is carried out for several
> individuals identified by 'Ring'
> for(k in 1:length(v) ){
> I = v[k]
> df <- xact[xact$Ring == I,]
> for(i in 1:nrow(GPS)){
> if(GPS[i,]$Ring== I){# the code runs along the whole data.frame for
> each i; it'd save time to make it stop with the last record of each i
> instead u <- df$timepos <= GPS[i,]$timepos # fill vector l for each
> interval t from xact <= each interval from GPS (take the max if there's
> > 1 interval) l[i] <- df[max( which(u == TRUE) ),]$wd } } } return(l)}
> 
> vwd <- fxG(xact, GPS)
> 
> 
> My question is: how can I speed up (optimize) this function?
> 
> Thank you for your help


From wolfgang.viechtbauer at maastrichtuniversity.nl  Mon Jul  8 12:10:00 2013
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Mon, 8 Jul 2013 12:10:00 +0200
Subject: [R] Meta-analysis on a repeated measures design with multiple
 trials per subject using metafor
In-Reply-To: <51D9E2DF.3050204@uva.nl>
References: <51D415D6.5070201@uva.nl>
	<077E31A57DA26E46AB0D493C9966AC730D833E9764@UM-MAIL4112.unimaas.nl>
	<51D69CDB.8010506@uva.nl>
	<Zen-1UvS2F-0008KR-PL@smarthost01a.mail.zen.net.uk>
	<51D9E2DF.3050204@uva.nl>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730D835A2F16@UM-MAIL4112.unimaas.nl>

It seems to me that the most straightforward approach would be to pool the b coefficients directly. I assume you used some kind of mixed-effects logistic model to analyze those data for each study with random effects for subjects and a dummy variable for treatment (besides possibly some other covariates) and the coefficient of interest is the one corresponding to the dummy for treatment. Given those 5 coefficients and the corresponding standard errors, you can then pool them with rma(b, sei=se), where 'b' is the vector with the coefficients and 'se' is the vector with the corresponding standard errors.

Careful: rma(b, se) would not be correct, since the second argument is assumed to represent the *sampling variances*:

> library(metafor)
> args(rma)
function (yi, vi, sei, [SNIP])

So, due to positional matching of arguments, rma(b, se) would be treated as rma(yi=b, vi=se), which is not what you want (you would not be the first person to fall into that trap). 

And yes, if you include additional covariates in the mixed-effects logistic model, then of course the b's and se's will change, but I see no issue here. It's just a question of whether you want to pool raw or adjusted coefficients (if you do adjust though, it would be best to adjust for the same covariates, so that the adjusted coefficients are directly comparable).

Aside from all of that, there is another approach you could take. Since you have the raw data from all 5 studies, you could just as well pool the raw data into one dataset and analyze that. This is essentially an "individual person (or patient) data meta-analysis" (IPDMA). You would then include either fixed or random effects for studies and you probably would also want the treatment effect to vary randomly across studies. That approach should give you similar results as pooling the 5 coefficients (which is a sort of two-step approach).

Best,
Wolfgang

--   
Wolfgang Viechtbauer, Ph.D., Statistician   
Department of Psychiatry and Psychology   
School for Mental Health and Neuroscience   
Faculty of Health, Medicine, and Life Sciences   
Maastricht University, P.O. Box 616 (VIJV1)   
6200 MD Maastricht, The Netherlands   
+31 (43) 388-4170 | http://www.wvbauer.com   


> -----Original Message-----
> From: Marc Heerdink [mailto:m.w.heerdink at uva.nl]
> Sent: Sunday, July 07, 2013 23:51
> To: Michael Dewey
> Cc: Viechtbauer Wolfgang (STAT); r-help at r-project.org
> Subject: Re: [R] Meta-analysis on a repeated measures design with multiple
> trials per subject using metafor
> 
> Dear Michael and other readers,
> 
> Please see below for my answers to your questions about my data.
> 
> On 07/06/2013 02:56 PM, Michael Dewey wrote:
> [..]
> >> Because everything was randomized, I can only calculate the total
> >> number of times a certain response was used under each type of trial.
> >> There is no pairing of trials under two treatments, so I am forced to
> >> use the marginal totals from your table.
> >
> > But presumably you could calculate some statistic suitable for
> > summarising the relevant features here? Difference in proportions, odds
> > ratio, ...
> 
> Using the totals, it is indeed easy to calculate the difference in
> proportions or odds ratio based on these totals. However, I am not sure
> how I should calculate a study-level statistic suitable for
> meta-analysis on the basis of these participant-level proportion
> differences.
> 
> So, for instance, I have the following table;
> 
> pp	proportion_difference
> 1	0.1
> 2	0.05
> 3	0.08
> 4	0.02
> ..
> N	..
> 
> Can I just calculate the mean and standard deviation of these proportion
> differences -- mean(proportion_difference) and sd(proportion_difference)
> -- and use these for meta-analysis? If yes, what escalc measure should I
> use?
> 
> [..]
> >> One alternative that I have tried over the last few days, is to use
> >> the b parameter of interest and it's corresponding standard error from
> >> the lme4 regression output that I use to analyse the individual
> >> experiments. Then, I use rma(yi, sei) to do a meta-analysis on these
> >> parameters. I am not sure this is correct though, since it takes into
> >> account between-subjects variance (through a random effect for
> >> subject), and it is sensitive to the covariates/moderators I include
> >> in the models that I get the b parameters from.
> >
> > So you end up with 5 values of b? The fact that they adjust for
> > different moderators does not seem an issue to me, indeed it could be
> > argued to be an advantage of the meta-analytic approach here.
> 
> OK, thank you for your comment on this one. I think the results of a
> meta-analysis using these 5 b values are indeed more or less sensible,
> which is encouraging. I think I will go this way if it turns out I
> cannot find a simpler approach, as a simpler approach would be easier to
> sell to potential reviewers.
> 
> [..
> > I think we are all assuming you have different participants in each
> > experiment but I thought I would raise that as a question.
> 
> You are right in assuming this, I have different participants in all 5
> experiments.
> 
> Thanks all for the help so far, your suggestions are highly appreciated!
> 
> Regards,
> Marc


From alexandre.piche at mail.mcgill.ca  Mon Jul  8 14:54:07 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Mon, 8 Jul 2013 05:54:07 -0700 (PDT)
Subject: [R] ggplot2
Message-ID: <1373288047623-4671087.post@n4.nabble.com>

Hello Folks,

I have an other problem with ggplot2. This is what I got so far.


levels(xmelt$Var2) <- c("Outright", "Market Move Adjusted")

ggplot(xmelt, aes(x=factor(Var1),value, row=L1, col=Var2, group=Var2)) + 
geom_bar(stat="identity") + facet_grid(Var2~L1, scale="free") + 
xlab("Maturities") + ylab("Basis Points Move") + theme(legend.position =
"none")


<http://r.789695.n4.nabble.com/file/n4671087/greygraph.bmp> 


And I would like to add something like

 + scale_colour_manual(breaks=c(30,20,15,10,7,5,3,2),
values=c("30"=gray(0.8),"20"=gray(0.75),"15"=gray(0.7),
 "10"=gray(0.65),"7"=gray(0.6),"5"=gray(0.55),"3"=gray(0.5),"2"=gray(0.45)))

to set different color of grey to different maturity.

Anyone know how I could do this?

Thank you for your time,

Alex



--
View this message in context: http://r.789695.n4.nabble.com/ggplot2-tp4671087.html
Sent from the R help mailing list archive at Nabble.com.


From p.mulongeni at namibia.pharmaccess.org  Mon Jul  8 15:49:49 2013
From: p.mulongeni at namibia.pharmaccess.org (Pancho Mulongeni)
Date: Mon, 8 Jul 2013 13:49:49 +0000
Subject: [R] Splitting coordinates into two
Message-ID: <9EA364B2FAFC264A86CED5A4404A19DB4EDE5866@AMXPRD0310MB366.eurprd03.prod.outlook.com>

Hi users,
I have a simple vector of five coordinates in form of ('lat1, long1','lat2,long2',...,'latn,longn')
And I would like to create two vectors, one just with the first coordinate
G1<-c('lat1,'lat2',..,'latn')
G2<-c('long1,'long2',...,'longn')

I am trying to apply strsplit(x=g,split=',') on my object g, but it is not working, any help?
I struggle to understand how to use the regular expressions.
structure(c(32L, 38L, 40L, 34L, 27L), .Label = c("-17.394217,15.886574", 
"-17.406994,14.393463", "-17.491495,14.992905", "-17.5005,24.274635", 
"-17.776151,15.765724", "-17.779911,15.699806", "-17.905569,15.977211", 
"-17.921576,19.758911", "-18.607204,17.166481", "-18.804918,17.046661", 
"-18.805731,16.940403", "-19.030476,16.467304", "-19.12441,13.616567", 
"-19.163006,15.916443", "-19.243736,17.710304", "-19.562702,18.11697", 
"-19.6303,17.342606", "-19.939787,13.013306", "-20.107201,16.154966", 
"-20.363618,14.965954", "-20.460469,16.652012", "-20.484914,17.233429", 
"-21.256102,17.869263", "-21.418555,15.949402", "-21.491128,17.853234", 
"-21.943046,17.363892", "-21.980459,16.91328", "-22.000992,15.582733", 
"-22.084367,16.750031", "-22.182318,17.072754", "-22.447841,18.962746", 
"-22.576608,17.07859", "-22.649502,14.532166", "-22.832516,17.183304", 
"-22.934365,14.521008", "-22.947328,14.508991", "-24.477775,15.801086", 
"-24.621739,17.959728", "-25.460983,19.438198", "-26.567955,18.134651", 
"-26.645292,15.153944", "-27.915553,17.490921", "-28.017742,18.745594"
), class = "factor")

Pancho Mulongeni
Research Assistant
PharmAccess Foundation
1 Fouch? Street
Windhoek West
Windhoek
Namibia
?
Tel:?? +264 61 419 000
Fax:? +264 61 419 001/2
Mob: +264 81 4456 286


From smartpink111 at yahoo.com  Mon Jul  8 16:04:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 8 Jul 2013 07:04:28 -0700 (PDT)
Subject: [R] Splitting coordinates into two
In-Reply-To: <9EA364B2FAFC264A86CED5A4404A19DB4EDE5866@AMXPRD0310MB366.eurprd03.prod.outlook.com>
References: <9EA364B2FAFC264A86CED5A4404A19DB4EDE5866@AMXPRD0310MB366.eurprd03.prod.outlook.com>
Message-ID: <1373292268.47137.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi,
vec1<- structure(c(.....

vec1
#[1] -22.576608,17.07859? -24.621739,17.959728 -26.567955,18.134651
#[4] -22.832516,17.183304 -21.980459,16.91328 
#43 Levels: -17.394217,15.886574 -17.406994,14.393463 ... -28.017742,18.745594
G1<-sapply(strsplit(as.character(vec1),","),`[`,1)
?G2<-sapply(strsplit(as.character(vec1),","),`[`,2)
G1
#[1] "-22.576608" "-24.621739" "-26.567955" "-22.832516" "-21.980459"
A.K.

----- Original Message -----
From: Pancho Mulongeni <p.mulongeni at namibia.pharmaccess.org>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Monday, July 8, 2013 9:49 AM
Subject: [R] Splitting coordinates into two

Hi users,
I have a simple vector of five coordinates in form of ('lat1, long1','lat2,long2',...,'latn,longn')
And I would like to create two vectors, one just with the first coordinate
G1<-c('lat1,'lat2',..,'latn')
G2<-c('long1,'long2',...,'longn')

I am trying to apply strsplit(x=g,split=',') on my object g, but it is not working, any help?
I struggle to understand how to use the regular expressions.
structure(c(32L, 38L, 40L, 34L, 27L), .Label = c("-17.394217,15.886574", 
"-17.406994,14.393463", "-17.491495,14.992905", "-17.5005,24.274635", 
"-17.776151,15.765724", "-17.779911,15.699806", "-17.905569,15.977211", 
"-17.921576,19.758911", "-18.607204,17.166481", "-18.804918,17.046661", 
"-18.805731,16.940403", "-19.030476,16.467304", "-19.12441,13.616567", 
"-19.163006,15.916443", "-19.243736,17.710304", "-19.562702,18.11697", 
"-19.6303,17.342606", "-19.939787,13.013306", "-20.107201,16.154966", 
"-20.363618,14.965954", "-20.460469,16.652012", "-20.484914,17.233429", 
"-21.256102,17.869263", "-21.418555,15.949402", "-21.491128,17.853234", 
"-21.943046,17.363892", "-21.980459,16.91328", "-22.000992,15.582733", 
"-22.084367,16.750031", "-22.182318,17.072754", "-22.447841,18.962746", 
"-22.576608,17.07859", "-22.649502,14.532166", "-22.832516,17.183304", 
"-22.934365,14.521008", "-22.947328,14.508991", "-24.477775,15.801086", 
"-24.621739,17.959728", "-25.460983,19.438198", "-26.567955,18.134651", 
"-26.645292,15.153944", "-27.915553,17.490921", "-28.017742,18.745594"
), class = "factor")

Pancho Mulongeni
Research Assistant
PharmAccess Foundation
1 Fouch? Street
Windhoek West
Windhoek
Namibia
?
Tel:?? +264 61 419 000
Fax:? +264 61 419 001/2
Mob: +264 81 4456 286

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From alexandre.piche at mail.mcgill.ca  Mon Jul  8 16:07:51 2013
From: alexandre.piche at mail.mcgill.ca (AlexPiche)
Date: Mon, 8 Jul 2013 07:07:51 -0700 (PDT)
Subject: [R] ggplot2
In-Reply-To: <1373288047623-4671087.post@n4.nabble.com>
References: <1373288047623-4671087.post@n4.nabble.com>
Message-ID: <1373292471316-4671090.post@n4.nabble.com>

if anyone was interested

ggplot(xmelt, aes(x=factor(Var1),value, row=L1, col=Var2, group=Var2,
fill=factor(Var1))) + 
geom_bar(stat="identity")+ facet_grid(Var2~L1, scale="free") + 
xlab("Maturities") + ylab("Basis Points Move") + theme(legend.position =
"none") +
scale_fill_grey(start=0.8,end=0.3)

<http://r.789695.n4.nabble.com/file/n4671090/greygraph.bmp> 



--
View this message in context: http://r.789695.n4.nabble.com/ggplot2-tp4671087p4671090.html
Sent from the R help mailing list archive at Nabble.com.


From therneau at mayo.edu  Mon Jul  8 16:12:08 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 08 Jul 2013 09:12:08 -0500
Subject: [R] multcomp on significant interaction in coxme model
Message-ID: <51DAC8B8.6030301@mayo.edu>

--- most of the message deleted....

Performing exactly the same routine with the same data on a logistic
model with family=binomial does not give this error message.
So my question is, what am I missing here?

Thanks, for any possible input

------------

I'm not a user of multcomp, so will follow with one question.  Results from coxph and 
coxme do not contain an intercept column.  Could this be the problem?

  A second possiblity is that coxme will in some cases return a bdsmatrix object as the 
variance matrix (to save space).  In such a case  "fit$var <- as.matrix(fit$var)" might 
correct the problem.

Terry Therneau


From ruipbarradas at sapo.pt  Mon Jul  8 16:54:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 08 Jul 2013 15:54:41 +0100
Subject: [R] Splitting coordinates into two
In-Reply-To: <9EA364B2FAFC264A86CED5A4404A19DB4EDE5866@AMXPRD0310MB366.eurprd03.prod.outlook.com>
References: <9EA364B2FAFC264A86CED5A4404A19DB4EDE5866@AMXPRD0310MB366.eurprd03.prod.outlook.com>
Message-ID: <51DAD2B1.3040801@sapo.pt>

Hello,

Try the following

x <- structure(...)


sp <- strsplit(as.character(x), ",")
G1 <- sapply(sp, `[`, 1)
G2 <- sapply(sp, `[`, 2)


Hope this helps,

Rui Barradas

Em 08-07-2013 14:49, Pancho Mulongeni escreveu:
> Hi users,
> I have a simple vector of five coordinates in form of ('lat1, long1','lat2,long2',...,'latn,longn')
> And I would like to create two vectors, one just with the first coordinate
> G1<-c('lat1,'lat2',..,'latn')
> G2<-c('long1,'long2',...,'longn')
>
> I am trying to apply strsplit(x=g,split=',') on my object g, but it is not working, any help?
> I struggle to understand how to use the regular expressions.
> structure(c(32L, 38L, 40L, 34L, 27L), .Label = c("-17.394217,15.886574",
> "-17.406994,14.393463", "-17.491495,14.992905", "-17.5005,24.274635",
> "-17.776151,15.765724", "-17.779911,15.699806", "-17.905569,15.977211",
> "-17.921576,19.758911", "-18.607204,17.166481", "-18.804918,17.046661",
> "-18.805731,16.940403", "-19.030476,16.467304", "-19.12441,13.616567",
> "-19.163006,15.916443", "-19.243736,17.710304", "-19.562702,18.11697",
> "-19.6303,17.342606", "-19.939787,13.013306", "-20.107201,16.154966",
> "-20.363618,14.965954", "-20.460469,16.652012", "-20.484914,17.233429",
> "-21.256102,17.869263", "-21.418555,15.949402", "-21.491128,17.853234",
> "-21.943046,17.363892", "-21.980459,16.91328", "-22.000992,15.582733",
> "-22.084367,16.750031", "-22.182318,17.072754", "-22.447841,18.962746",
> "-22.576608,17.07859", "-22.649502,14.532166", "-22.832516,17.183304",
> "-22.934365,14.521008", "-22.947328,14.508991", "-24.477775,15.801086",
> "-24.621739,17.959728", "-25.460983,19.438198", "-26.567955,18.134651",
> "-26.645292,15.153944", "-27.915553,17.490921", "-28.017742,18.745594"
> ), class = "factor")
>
> Pancho Mulongeni
> Research Assistant
> PharmAccess Foundation
> 1 Fouch? Street
> Windhoek West
> Windhoek
> Namibia
>
> Tel:   +264 61 419 000
> Fax:  +264 61 419 001/2
> Mob: +264 81 4456 286
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From p.mulongeni at namibia.pharmaccess.org  Mon Jul  8 17:59:05 2013
From: p.mulongeni at namibia.pharmaccess.org (Pancho Mulongeni)
Date: Mon, 8 Jul 2013 15:59:05 +0000
Subject: [R] Splitting coordinates into two
In-Reply-To: <51DAD2B1.3040801@sapo.pt>
References: <9EA364B2FAFC264A86CED5A4404A19DB4EDE5866@AMXPRD0310MB366.eurprd03.prod.outlook.com>
	<51DAD2B1.3040801@sapo.pt>
Message-ID: <9EA364B2FAFC264A86CED5A4404A19DB4EDE58A8@AMXPRD0310MB366.eurprd03.prod.outlook.com>

Thank you,
So my mistake was my data was a factor and not character,for strsplit
Thanks so much 

-----Original Message-----
From: Rui Barradas [mailto:ruipbarradas at sapo.pt] 
Sent: 08 July 2013 15:55
To: Pancho Mulongeni
Cc: r-help at r-project.org
Subject: Re: [R] Splitting coordinates into two

Hello,

Try the following

x <- structure(...)


sp <- strsplit(as.character(x), ",")
G1 <- sapply(sp, `[`, 1)
G2 <- sapply(sp, `[`, 2)


Hope this helps,

Rui Barradas

Em 08-07-2013 14:49, Pancho Mulongeni escreveu:
> Hi users,
> I have a simple vector of five coordinates in form of ('lat1, 
> long1','lat2,long2',...,'latn,longn')
> And I would like to create two vectors, one just with the first 
> coordinate
> G1<-c('lat1,'lat2',..,'latn')
> G2<-c('long1,'long2',...,'longn')
>
> I am trying to apply strsplit(x=g,split=',') on my object g, but it is not working, any help?
> I struggle to understand how to use the regular expressions.
> structure(c(32L, 38L, 40L, 34L, 27L), .Label = 
> c("-17.394217,15.886574", "-17.406994,14.393463", 
> "-17.491495,14.992905", "-17.5005,24.274635", "-17.776151,15.765724", 
> "-17.779911,15.699806", "-17.905569,15.977211", 
> "-17.921576,19.758911", "-18.607204,17.166481", 
> "-18.804918,17.046661", "-18.805731,16.940403", 
> "-19.030476,16.467304", "-19.12441,13.616567", "-19.163006,15.916443", 
> "-19.243736,17.710304", "-19.562702,18.11697", "-19.6303,17.342606", 
> "-19.939787,13.013306", "-20.107201,16.154966", 
> "-20.363618,14.965954", "-20.460469,16.652012", 
> "-20.484914,17.233429", "-21.256102,17.869263", 
> "-21.418555,15.949402", "-21.491128,17.853234", 
> "-21.943046,17.363892", "-21.980459,16.91328", "-22.000992,15.582733", 
> "-22.084367,16.750031", "-22.182318,17.072754", 
> "-22.447841,18.962746", "-22.576608,17.07859", "-22.649502,14.532166", "-22.832516,17.183304", "-22.934365,14.521008", "-22.947328,14.508991", "-24.477775,15.801086", "-24.621739,17.959728", "-25.460983,19.438198", "-26.567955,18.134651", "-26.645292,15.153944", "-27.915553,17.490921", "-28.017742,18.745594"
> ), class = "factor")
>
> Pancho Mulongeni
> Research Assistant
> PharmAccess Foundation
> 1 Fouch? Street
> Windhoek West
> Windhoek
> Namibia
>
> Tel:   +264 61 419 000
> Fax:  +264 61 419 001/2
> Mob: +264 81 4456 286
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From plalehzari at platinumlp.com  Mon Jul  8 19:21:55 2013
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Mon, 8 Jul 2013 17:21:55 +0000
Subject: [R] xts zoo "cannot remove prior installation of package"
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC8E269@EX02.platinum.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/f6a162d0/attachment.pl>

From S.Ellison at LGCGroup.com  Mon Jul  8 19:28:35 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 8 Jul 2013 18:28:35 +0100
Subject: [R] Lattice barchart with error bars
In-Reply-To: <C117B96E-A475-4072-9EDA-22D5F7821EFE@gene.com>
References: <CADX6M3rix++5_FvS3HNXXHJuA_fxeaZx9XkGF0YMvn8SohkwTQ@mail.gmail.com>
	<CADv2QyF-AruYEambPDbtC8hkMDCPEN9hvku_rhOmFaub9RRNCA@mail.gmail.com>
	<CADX6M3pgw8LRqjdRAey-48y9+5ON=P3x5SOa58-XJhoSq1igWg@mail.gmail.com>
	<7508610A-35BD-42C8-BC58-8AA1EDF90027@comcast.net>
	<CACk-te0+K7AbPXnHN1QvvLaqUr+5p2DdA6Dnza+nd=10NsaT-A@mail.gmail.com>
	<CADX6M3p9viLrmHB4ygZanwL8U4ZD9VwvsZn5cJhj8y5RDgoVyQ@mail.gmail.com>
	<C117B96E-A475-4072-9EDA-22D5F7821EFE@gene.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4AC9FEF23C@GOLD.corp.lgc-group.com>

> > Anyone know what the 95% confidence 
> > interval of the median would be?
For an R answer you could get one for each group from wilcox.test( .... , conf.int =TRUE ) and build that into an alternative boxplot stats function which you could specify in your bwplot call.

Steve Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ripley at stats.ox.ac.uk  Mon Jul  8 19:30:43 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 08 Jul 2013 18:30:43 +0100
Subject: [R] xts zoo "cannot remove prior installation of package"
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC8E269@EX02.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC8E269@EX02.platinum.com>
Message-ID: <51DAF743.3090706@stats.ox.ac.uk>

On 08/07/2013 18:21, Pooya Lalehzari wrote:
> Hello,
> Some how, my xts/zoo package ran into trouble. I tried to re-install the packages, I get an error that it cannot remove the prior installation.
> I uninstalled R and the deleted all the libraries and reinstalled everything fresh. It still complains the same thing. I try to remove.packages("zoo"), it tells me there is no such package. I am really baffled. Does anyone know how to fix this problem?
>
> Thank you,
> Pooya.
>
>
> THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED
> RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND
> PRIVILEGED INFORMATION.
>
> ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR
> DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE
> INTENDED RECIPIENT, PLEASE CONTACT THE SENDER
> BY REPLY E-MAIL AND DESTROY ALL COPIES
> OF THE ORIGINAL E-MAIL.
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Please do: we cannot answer this without the information we asked for.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From friendly at yorku.ca  Mon Jul  8 19:36:28 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Mon, 08 Jul 2013 13:36:28 -0400
Subject: [R] abbreviating words in a model formula
Message-ID: <51DAF89C.9070202@yorku.ca>

For an application, I need to get a character string representation of 
the formula or
model call for glm objects, but also, for labeling output and plots, I 
want to be able
to abbreviate the words (variables) in model terms.  This requires some 
formula
magic that I can't quite get, in particular extracting the terms from a 
formula and
then the words in each term.

Perhaps there is some code for something similar
I haven't found yet, or someone can suggest how to do this.

A runnable example to show what I mean:

Freq <- c(68,42,42,30, 37,52,24,43,
     66,50,33,23, 47,55,23,47,
     63,53,29,27, 57,49,19,29)

Temperature <- gl(2, 2, 24, labels = c("Low", "High"))
Softness <- gl(3, 8, 24, labels = c("Hard","Medium","Soft"))
M.user <- gl(2, 4, 24, labels = c("N", "Y"))
Brand <- gl(2, 1, 24, labels = c("X", "M"))

detg <- data.frame(Freq,Temperature, Softness, M.user, Brand)
detg.m0 <- glm(Freq ~ M.user*Temperature*Softness + 
Brand*M.user*Temperature,
        family = poisson, data = detg)

detg.m1 <- glm(Freq ~ (M.user + Temperature + Softness + Brand),
        family = poisson, data=detg)

detg.m2 <- glm(Freq ~ (M.user + Temperature + Softness + Brand)^2,
        family = poisson, data=detg)

detg.m2a <- update(detg.m1, . ~ .^2)

In plot.lm, I found the following code to extract the model call from a 
glm object as
a string and abbreviate it to a total length <=75.  I need shorter total 
length,
by abbreviating individual words in the model call, so the approach has to
at least extract the terms in the model and then abbreviate the words in 
each term.

# from plot.lm: get model call as a string
# TODO: how to use abbreviate to abbreviate the words in the model terms???
mod.call <- function(x, max.len=75) {
         cal <- x$call
         if (!is.na(m.f <- match("formula", names(cal)))) {
             cal <- cal[c(1, m.f)]
             names(cal)[2L] <- ""
         }
         cc <- deparse(cal, max.len+5)
         nc <- nchar(cc[1L], "c")
         abbr <- length(cc) > 1 || nc > max.len
         cap <- if (abbr)
             paste(substr(cc[1L], 1L, min(max.len, nc)), "...")
         else cc[1L]
         cap
}

Tests, & WANTED, say with max length of each word in the string <= 6 & 
maximum total
length <= 40

 > mod.call(detg.m0)
[1] "glm(Freq ~ M.user * Temperature * Softness + Brand * M.user * 
Temperature)"

WANTED, somthing like:
"glm(Freq ~ M.user * Temp * Softne + Brand * M.user * Temp)"

 > mod.call(detg.m2a)
[1] "glm(Freq ~ M.user + Temperature + Softness + Brand + 
M.user:Temperature + M ..."
 >
 > mod.call(detg.m2a, max.len=200)
[1] "glm(Freq ~ M.user + Temperature + Softness + Brand + 
M.user:Temperature + M.user:Softness + M.user:Brand + 
Temperature:Softness + Temperature:Brand + Softness:Brand)"
 >

WANTED, somthing closer to
"glm(Freq ~ M + Tmp + Sft + Brnd + M:Tmp + M.:Sft + M.us:Brnd + Tmp:Sft 
+ Tmp:Brnd + Sft:Brnd)"

TIA
-Michael



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From wdunlap at tibco.com  Mon Jul  8 20:02:27 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Jul 2013 18:02:27 +0000
Subject: [R] abbreviating words in a model formula
In-Reply-To: <51DAF89C.9070202@yorku.ca>
References: <51DAF89C.9070202@yorku.ca>
Message-ID: <E66794E69CFDE04D9A70842786030B931C31AA91@PA-MBX01.na.tibco.com>

Try using all.names() to get all the names in the formula.  E.g.,

f <- function (formula, minNameLength = 2, abbreviateFunctionNames = FALSE)
{
    names <- all.names(formula, functions = abbreviateFunctionNames)
    abbrNames <- lapply(abbreviate(names, minlength = minNameLength),
        as.name)
    deparse(do.call("substitute", list(formula, abbrNames)))
}

used as
  > f(MyResponse ~ log(FirstPredictor) + sqrt(SecondPredictor))
  [1] "MR ~ log(FP) + sqrt(SP)"
  > f(MyResponse ~ log(FirstPredictor) + sqrt(SecondPredictor), min=4)
  [1] "MyRs ~ log(FrsP) + sqrt(ScnP)"
  > f(MyResponse ~ log(FirstPredictor) + sqrt(SecondPredictor), abbreviateFunctionNames=TRUE)
  [1] "MR ~ lg(FP) + sq(SP)"

You could put that in a loop that stopped when nchar(f(...)) got small enough.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Michael Friendly
> Sent: Monday, July 08, 2013 10:36 AM
> To: R-help
> Subject: [R] abbreviating words in a model formula
> 
> For an application, I need to get a character string representation of
> the formula or
> model call for glm objects, but also, for labeling output and plots, I
> want to be able
> to abbreviate the words (variables) in model terms.  This requires some
> formula
> magic that I can't quite get, in particular extracting the terms from a
> formula and
> then the words in each term.
> 
> Perhaps there is some code for something similar
> I haven't found yet, or someone can suggest how to do this.
> 
> A runnable example to show what I mean:
> 
> Freq <- c(68,42,42,30, 37,52,24,43,
>      66,50,33,23, 47,55,23,47,
>      63,53,29,27, 57,49,19,29)
> 
> Temperature <- gl(2, 2, 24, labels = c("Low", "High"))
> Softness <- gl(3, 8, 24, labels = c("Hard","Medium","Soft"))
> M.user <- gl(2, 4, 24, labels = c("N", "Y"))
> Brand <- gl(2, 1, 24, labels = c("X", "M"))
> 
> detg <- data.frame(Freq,Temperature, Softness, M.user, Brand)
> detg.m0 <- glm(Freq ~ M.user*Temperature*Softness +
> Brand*M.user*Temperature,
>         family = poisson, data = detg)
> 
> detg.m1 <- glm(Freq ~ (M.user + Temperature + Softness + Brand),
>         family = poisson, data=detg)
> 
> detg.m2 <- glm(Freq ~ (M.user + Temperature + Softness + Brand)^2,
>         family = poisson, data=detg)
> 
> detg.m2a <- update(detg.m1, . ~ .^2)
> 
> In plot.lm, I found the following code to extract the model call from a
> glm object as
> a string and abbreviate it to a total length <=75.  I need shorter total
> length,
> by abbreviating individual words in the model call, so the approach has to
> at least extract the terms in the model and then abbreviate the words in
> each term.
> 
> # from plot.lm: get model call as a string
> # TODO: how to use abbreviate to abbreviate the words in the model terms???
> mod.call <- function(x, max.len=75) {
>          cal <- x$call
>          if (!is.na(m.f <- match("formula", names(cal)))) {
>              cal <- cal[c(1, m.f)]
>              names(cal)[2L] <- ""
>          }
>          cc <- deparse(cal, max.len+5)
>          nc <- nchar(cc[1L], "c")
>          abbr <- length(cc) > 1 || nc > max.len
>          cap <- if (abbr)
>              paste(substr(cc[1L], 1L, min(max.len, nc)), "...")
>          else cc[1L]
>          cap
> }
> 
> Tests, & WANTED, say with max length of each word in the string <= 6 &
> maximum total
> length <= 40
> 
>  > mod.call(detg.m0)
> [1] "glm(Freq ~ M.user * Temperature * Softness + Brand * M.user *
> Temperature)"
> 
> WANTED, somthing like:
> "glm(Freq ~ M.user * Temp * Softne + Brand * M.user * Temp)"
> 
>  > mod.call(detg.m2a)
> [1] "glm(Freq ~ M.user + Temperature + Softness + Brand +
> M.user:Temperature + M ..."
>  >
>  > mod.call(detg.m2a, max.len=200)
> [1] "glm(Freq ~ M.user + Temperature + Softness + Brand +
> M.user:Temperature + M.user:Softness + M.user:Brand +
> Temperature:Softness + Temperature:Brand + Softness:Brand)"
>  >
> 
> WANTED, somthing closer to
> "glm(Freq ~ M + Tmp + Sft + Brnd + M:Tmp + M.:Sft + M.us:Brnd + Tmp:Sft
> + Tmp:Brnd + Sft:Brnd)"
> 
> TIA
> -Michael
> 
> 
> 
> --
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Mon Jul  8 20:22:35 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 08 Jul 2013 11:22:35 -0700
Subject: [R] abbreviating words in a model formula
In-Reply-To: <51DAF89C.9070202@yorku.ca>
References: <51DAF89C.9070202@yorku.ca>
Message-ID: <fa172f57-74c0-4c09-8c76-090dc80e684e@email.android.com>

Your cart is stuck in front of your horse. This will be WAY easier to accomplish if you rename your columns in your input data frame before fitting the model.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Michael Friendly <friendly at yorku.ca> wrote:

>For an application, I need to get a character string representation of 
>the formula or
>model call for glm objects, but also, for labeling output and plots, I 
>want to be able
>to abbreviate the words (variables) in model terms.  This requires some
>
>formula
>magic that I can't quite get, in particular extracting the terms from a
>
>formula and
>then the words in each term.
>
>Perhaps there is some code for something similar
>I haven't found yet, or someone can suggest how to do this.
>
>A runnable example to show what I mean:
>
>Freq <- c(68,42,42,30, 37,52,24,43,
>     66,50,33,23, 47,55,23,47,
>     63,53,29,27, 57,49,19,29)
>
>Temperature <- gl(2, 2, 24, labels = c("Low", "High"))
>Softness <- gl(3, 8, 24, labels = c("Hard","Medium","Soft"))
>M.user <- gl(2, 4, 24, labels = c("N", "Y"))
>Brand <- gl(2, 1, 24, labels = c("X", "M"))
>
>detg <- data.frame(Freq,Temperature, Softness, M.user, Brand)
>detg.m0 <- glm(Freq ~ M.user*Temperature*Softness + 
>Brand*M.user*Temperature,
>        family = poisson, data = detg)
>
>detg.m1 <- glm(Freq ~ (M.user + Temperature + Softness + Brand),
>        family = poisson, data=detg)
>
>detg.m2 <- glm(Freq ~ (M.user + Temperature + Softness + Brand)^2,
>        family = poisson, data=detg)
>
>detg.m2a <- update(detg.m1, . ~ .^2)
>
>In plot.lm, I found the following code to extract the model call from a
>
>glm object as
>a string and abbreviate it to a total length <=75.  I need shorter
>total 
>length,
>by abbreviating individual words in the model call, so the approach has
>to
>at least extract the terms in the model and then abbreviate the words
>in 
>each term.
>
># from plot.lm: get model call as a string
># TODO: how to use abbreviate to abbreviate the words in the model
>terms???
>mod.call <- function(x, max.len=75) {
>         cal <- x$call
>         if (!is.na(m.f <- match("formula", names(cal)))) {
>             cal <- cal[c(1, m.f)]
>             names(cal)[2L] <- ""
>         }
>         cc <- deparse(cal, max.len+5)
>         nc <- nchar(cc[1L], "c")
>         abbr <- length(cc) > 1 || nc > max.len
>         cap <- if (abbr)
>             paste(substr(cc[1L], 1L, min(max.len, nc)), "...")
>         else cc[1L]
>         cap
>}
>
>Tests, & WANTED, say with max length of each word in the string <= 6 & 
>maximum total
>length <= 40
>
> > mod.call(detg.m0)
>[1] "glm(Freq ~ M.user * Temperature * Softness + Brand * M.user * 
>Temperature)"
>
>WANTED, somthing like:
>"glm(Freq ~ M.user * Temp * Softne + Brand * M.user * Temp)"
>
> > mod.call(detg.m2a)
>[1] "glm(Freq ~ M.user + Temperature + Softness + Brand + 
>M.user:Temperature + M ..."
> >
> > mod.call(detg.m2a, max.len=200)
>[1] "glm(Freq ~ M.user + Temperature + Softness + Brand + 
>M.user:Temperature + M.user:Softness + M.user:Brand + 
>Temperature:Softness + Temperature:Brand + Softness:Brand)"
> >
>
>WANTED, somthing closer to
>"glm(Freq ~ M + Tmp + Sft + Brnd + M:Tmp + M.:Sft + M.us:Brnd + Tmp:Sft
>
>+ Tmp:Brnd + Sft:Brnd)"
>
>TIA
>-Michael


From wdunlap at tibco.com  Mon Jul  8 20:54:54 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 8 Jul 2013 18:54:54 +0000
Subject: [R] abbreviating words in a model formula
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C31AA91@PA-MBX01.na.tibco.com>
References: <51DAF89C.9070202@yorku.ca>
	<E66794E69CFDE04D9A70842786030B931C31AA91@PA-MBX01.na.tibco.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C31AAFC@PA-MBX01.na.tibco.com>

The call to all.names() below probably should have the unique=TRUE argument.
It doesn't make any difference in this particular code, but having repeated names
could cause problems in related code.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of William Dunlap
> Sent: Monday, July 08, 2013 11:02 AM
> To: Michael Friendly; R-help
> Subject: Re: [R] abbreviating words in a model formula
> 
> Try using all.names() to get all the names in the formula.  E.g.,
> 
> f <- function (formula, minNameLength = 2, abbreviateFunctionNames = FALSE)
> {
>     names <- all.names(formula, functions = abbreviateFunctionNames)
>     abbrNames <- lapply(abbreviate(names, minlength = minNameLength),
>         as.name)
>     deparse(do.call("substitute", list(formula, abbrNames)))
> }
> 
> used as
>   > f(MyResponse ~ log(FirstPredictor) + sqrt(SecondPredictor))
>   [1] "MR ~ log(FP) + sqrt(SP)"
>   > f(MyResponse ~ log(FirstPredictor) + sqrt(SecondPredictor), min=4)
>   [1] "MyRs ~ log(FrsP) + sqrt(ScnP)"
>   > f(MyResponse ~ log(FirstPredictor) + sqrt(SecondPredictor),
> abbreviateFunctionNames=TRUE)
>   [1] "MR ~ lg(FP) + sq(SP)"
> 
> You could put that in a loop that stopped when nchar(f(...)) got small enough.
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of Michael Friendly
> > Sent: Monday, July 08, 2013 10:36 AM
> > To: R-help
> > Subject: [R] abbreviating words in a model formula
> >
> > For an application, I need to get a character string representation of
> > the formula or
> > model call for glm objects, but also, for labeling output and plots, I
> > want to be able
> > to abbreviate the words (variables) in model terms.  This requires some
> > formula
> > magic that I can't quite get, in particular extracting the terms from a
> > formula and
> > then the words in each term.
> >
> > Perhaps there is some code for something similar
> > I haven't found yet, or someone can suggest how to do this.
> >
> > A runnable example to show what I mean:
> >
> > Freq <- c(68,42,42,30, 37,52,24,43,
> >      66,50,33,23, 47,55,23,47,
> >      63,53,29,27, 57,49,19,29)
> >
> > Temperature <- gl(2, 2, 24, labels = c("Low", "High"))
> > Softness <- gl(3, 8, 24, labels = c("Hard","Medium","Soft"))
> > M.user <- gl(2, 4, 24, labels = c("N", "Y"))
> > Brand <- gl(2, 1, 24, labels = c("X", "M"))
> >
> > detg <- data.frame(Freq,Temperature, Softness, M.user, Brand)
> > detg.m0 <- glm(Freq ~ M.user*Temperature*Softness +
> > Brand*M.user*Temperature,
> >         family = poisson, data = detg)
> >
> > detg.m1 <- glm(Freq ~ (M.user + Temperature + Softness + Brand),
> >         family = poisson, data=detg)
> >
> > detg.m2 <- glm(Freq ~ (M.user + Temperature + Softness + Brand)^2,
> >         family = poisson, data=detg)
> >
> > detg.m2a <- update(detg.m1, . ~ .^2)
> >
> > In plot.lm, I found the following code to extract the model call from a
> > glm object as
> > a string and abbreviate it to a total length <=75.  I need shorter total
> > length,
> > by abbreviating individual words in the model call, so the approach has to
> > at least extract the terms in the model and then abbreviate the words in
> > each term.
> >
> > # from plot.lm: get model call as a string
> > # TODO: how to use abbreviate to abbreviate the words in the model terms???
> > mod.call <- function(x, max.len=75) {
> >          cal <- x$call
> >          if (!is.na(m.f <- match("formula", names(cal)))) {
> >              cal <- cal[c(1, m.f)]
> >              names(cal)[2L] <- ""
> >          }
> >          cc <- deparse(cal, max.len+5)
> >          nc <- nchar(cc[1L], "c")
> >          abbr <- length(cc) > 1 || nc > max.len
> >          cap <- if (abbr)
> >              paste(substr(cc[1L], 1L, min(max.len, nc)), "...")
> >          else cc[1L]
> >          cap
> > }
> >
> > Tests, & WANTED, say with max length of each word in the string <= 6 &
> > maximum total
> > length <= 40
> >
> >  > mod.call(detg.m0)
> > [1] "glm(Freq ~ M.user * Temperature * Softness + Brand * M.user *
> > Temperature)"
> >
> > WANTED, somthing like:
> > "glm(Freq ~ M.user * Temp * Softne + Brand * M.user * Temp)"
> >
> >  > mod.call(detg.m2a)
> > [1] "glm(Freq ~ M.user + Temperature + Softness + Brand +
> > M.user:Temperature + M ..."
> >  >
> >  > mod.call(detg.m2a, max.len=200)
> > [1] "glm(Freq ~ M.user + Temperature + Softness + Brand +
> > M.user:Temperature + M.user:Softness + M.user:Brand +
> > Temperature:Softness + Temperature:Brand + Softness:Brand)"
> >  >
> >
> > WANTED, somthing closer to
> > "glm(Freq ~ M + Tmp + Sft + Brnd + M:Tmp + M.:Sft + M.us:Brnd + Tmp:Sft
> > + Tmp:Brnd + Sft:Brnd)"
> >
> > TIA
> > -Michael
> >
> >
> >
> > --
> > Michael Friendly     Email: friendly AT yorku DOT ca
> > Professor, Psychology Dept. & Chair, Quantitative Methods
> > York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> > 4700 Keele Street    Web:   http://www.datavis.ca
> > Toronto, ONT  M3J 1P3 CANADA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From julian.bothe at elitepartner.de  Mon Jul  8 11:02:17 2013
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Mon, 8 Jul 2013 11:02:17 +0200 (CEST)
Subject: [R] error in "predict.gam" used with "bam"
Message-ID: <ef19394e.000011bc.0000000f@FIW7PC12.ELITEMEDIANET>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/d384b8de/attachment.pl>

From laila_zgz at hotmail.com  Mon Jul  8 11:52:50 2013
From: laila_zgz at hotmail.com (laila)
Date: Mon, 8 Jul 2013 02:52:50 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
In-Reply-To: <1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1373238668238-4671059.post@n4.nabble.com>
	<1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <DUB116-W5914520FB86D7D17F860709E780@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/ba963701/attachment.pl>

From enigma1414 at msn.com  Mon Jul  8 21:10:58 2013
From: enigma1414 at msn.com (Mary Huynh)
Date: Mon, 8 Jul 2013 15:10:58 -0400
Subject: [R] "error setting certificate" issue in R-studio
Message-ID: <BLU170-W93E9F87F786DDBB10F8ECACC780@phx.gbl>

Hi all,

I'm a newbie to R and I can't figure out how to fix this error I keep getting in R-studio:


> "error setting certificate verify locations:\n CAfile: \n CApath: none\n"
Error in twInterfaceObj$doAPICall(cmd,params,"GET",...) :
Error: error setting certificate verify locations:
CAfile:
CApath: none


I'm trying to use the twitteR package to gather tweets from the below 
function. It was working fine before, but I can't find a way to fix 
the certificate issue.I tried using 
>download.file(url="curl.haxx.se/ca/cacert.pem",
 destfile="cacert.pem") with>credential$handshake(cainfo = 
system.file("CurlSSL", "cacert.pem", package = "RCurl")) I saw 
recommended on Stack Overflow but it didn't fix the issue.


>TweetFrame <- function(searchTerm, maxTweets)? 
??? {
????? twtList<-searchTwitter(searchTerm,n=maxTweets)
????? #twtList is involved in ?variable? scoping so it only exists within the? 
??????? function? 
????? # searchTerm needs to be a string so use "#hashtag"
? 
????? twtTempFrame<- do.call("rbind", lapply(twtList,as.data.frame))
????? # as.data.frame() coerces each list element into a row
????? # lapply() applies this to all of the elements in twtList
????? # rbind() takes all the rows and puts them together
????? # do.call() gives rbind() all the rows as individual elements
? 
????? return(twtTempFrame[order(as.integer(twtTempFrame$created)), ])
? 
??? }


Thanks in advance for any help!
M 		 	   		  

From asanramzan at yahoo.com  Mon Jul  8 21:19:37 2013
From: asanramzan at yahoo.com (Asan Ramzan)
Date: Mon, 8 Jul 2013 12:19:37 -0700 (PDT)
Subject: [R] (no subject)
Message-ID: <1373311177.39135.YahooMailNeo@web125904.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/632ec312/attachment.pl>

From wewolski at gmail.com  Mon Jul  8 21:20:34 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 8 Jul 2013 21:20:34 +0200
Subject: [R] disabling vignette creation in R CMD build
Message-ID: <CAAjnpdjK1NkdRgaye5E0vGNcpJqm0pmXB4piTz7R4nQbvYQz6w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/01a7ea7f/attachment.pl>

From sridhar2bioinfo at gmail.com  Mon Jul  8 11:42:23 2013
From: sridhar2bioinfo at gmail.com (sridhar srinivasan)
Date: Mon, 8 Jul 2013 15:12:23 +0530
Subject: [R] R installation Problem
Message-ID: <CAE5FLRX6USxHJ1TsH_b2ahKgbhO0vCDTgm0pDtqG3PPSCpcJdA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/3a3947d4/attachment.pl>

From hnorpois at gmail.com  Mon Jul  8 13:57:22 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Mon, 8 Jul 2013 13:57:22 +0200
Subject: [R] retrieve data from summary output
Message-ID: <CAKyZeBtmpcBjvbm3M+RQF6HZcD_gWJBE+rw11=ahQgTDgoctkw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/aee158c4/attachment.pl>

From jia2.xu at citi.com  Mon Jul  8 14:45:03 2013
From: jia2.xu at citi.com (Xu, Jia2 )
Date: Mon, 8 Jul 2013 12:45:03 +0000
Subject: [R] A question on the abline function
Message-ID: <0F1A1373F93B1C44ABC51B71BC757E6327BB2614@EXNJMB21.nam.nsroot.net>

Dear whom it may concerns,

I am Jia Xu, a summer intern analyst at Citi Research. I am also a graduate student studying Financial Engineering at Cornell. I am running regression analysis with Rstudio now. I have been experiencing difficulty with the abline function. No matter I call it directly in linear regression or call it through residual plots, or plot results from lasso regression, it produces the same error as the following:

Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...) :
  object 'C_abline' not found

Could you please help me check what is this problem?

Thanks for your time!

Best,

Jia Xu

Citi Research


From sarah.goslee at gmail.com  Mon Jul  8 21:32:30 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 8 Jul 2013 15:32:30 -0400
Subject: [R] retrieve data from summary output
In-Reply-To: <CAKyZeBtmpcBjvbm3M+RQF6HZcD_gWJBE+rw11=ahQgTDgoctkw@mail.gmail.com>
References: <CAKyZeBtmpcBjvbm3M+RQF6HZcD_gWJBE+rw11=ahQgTDgoctkw@mail.gmail.com>
Message-ID: <CAM_vjumW5Lbm3mSOOjpoXqw9bvCcCJMODpg4kLZ2sLvV0Q+usg@mail.gmail.com>

Try

names(summary (plasma_glm_1))

You can extract named components individually, just as you would for
any other R object.

Sarah

On Mon, Jul 8, 2013 at 7:57 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
> Hello,
>
> how can I retrieve electively data from a summary file, for instance I
> would like to get the Pr of Coefficients
> Thanks
>> summary (plasma_glm_1)
>
> Call:
> glm(formula = ESR ~ fibrinogen, family = binomial(), data = plasma)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -0.9298  -0.5399  -0.4382  -0.3356   2.4794
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -6.8451     2.7703  -2.471   0.0135 *
> fibrinogen    1.8271     0.9009   2.028   0.0425 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>     Null deviance: 30.885  on 31  degrees of freedom
> Residual deviance: 24.840  on 30  degrees of freedom
> AIC: 28.84
>
> Number of Fisher Scoring iterations: 5
>
>         [[alternative HTML version deleted]]
>
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From ripley at stats.ox.ac.uk  Mon Jul  8 21:39:56 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 08 Jul 2013 20:39:56 +0100
Subject: [R] disabling vignette creation in R CMD build
In-Reply-To: <CAAjnpdjK1NkdRgaye5E0vGNcpJqm0pmXB4piTz7R4nQbvYQz6w@mail.gmail.com>
References: <CAAjnpdjK1NkdRgaye5E0vGNcpJqm0pmXB4piTz7R4nQbvYQz6w@mail.gmail.com>
Message-ID: <51DB158C.9050302@stats.ox.ac.uk>

On 08/07/2013 20:20, Witold E Wolski wrote:
> While developing a package I would like to disable vignette creation
> when executing R CMD build. The vignette creation is costly so I would
> prefer not to have to regenerate it every time.

Why not read the documentation?

As the exact answer depends on the version of R, we will not write the 
manuals out here.  But

R CMD build --help

should give you enough of a clue ....  Otherwise read 'Writing R 
Extensions' ?1.4, for your version of R.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From gunter.berton at gene.com  Mon Jul  8 21:40:47 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 8 Jul 2013 12:40:47 -0700
Subject: [R] retrieve data from summary output
In-Reply-To: <CAKyZeBtmpcBjvbm3M+RQF6HZcD_gWJBE+rw11=ahQgTDgoctkw@mail.gmail.com>
References: <CAKyZeBtmpcBjvbm3M+RQF6HZcD_gWJBE+rw11=ahQgTDgoctkw@mail.gmail.com>
Message-ID: <CACk-te3tab1h1jSyiFKKe3OcN9i1__XffWUwUjVByU8HnqvVMg@mail.gmail.com>

1. It's a summary **object**, not a file.

2. ?summary.glm

3. Read "An Introduction to R" and ?"[" to learn how to work with
lists and extraction functions, which are essential.

4. Also
methods(print)
stats:::print.summary.glm  ## for code of how object is printed



Cheers,
Bert

On Mon, Jul 8, 2013 at 4:57 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
> Hello,
>
> how can I retrieve electively data from a summary file, for instance I
> would like to get the Pr of Coefficients
> Thanks
>> summary (plasma_glm_1)
>
> Call:
> glm(formula = ESR ~ fibrinogen, family = binomial(), data = plasma)
>
> Deviance Residuals:
>     Min       1Q   Median       3Q      Max
> -0.9298  -0.5399  -0.4382  -0.3356   2.4794
>
> Coefficients:
>             Estimate Std. Error z value Pr(>|z|)
> (Intercept)  -6.8451     2.7703  -2.471   0.0135 *
> fibrinogen    1.8271     0.9009   2.028   0.0425 *
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
>
> (Dispersion parameter for binomial family taken to be 1)
>
>     Null deviance: 30.885  on 31  degrees of freedom
> Residual deviance: 24.840  on 30  degrees of freedom
> AIC: 28.84
>
> Number of Fisher Scoring iterations: 5
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From dcarlson at tamu.edu  Mon Jul  8 22:03:13 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 8 Jul 2013 15:03:13 -0500
Subject: [R] A question on the abline function
In-Reply-To: <0F1A1373F93B1C44ABC51B71BC757E6327BB2614@EXNJMB21.nam.nsroot.net>
References: <0F1A1373F93B1C44ABC51B71BC757E6327BB2614@EXNJMB21.nam.nsroot.net>
Message-ID: <124701ce7c16$2d560560$88021020$@tamu.edu>

PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

First read the instructions for posting. You gave us no data, no
code, no example. Just an error message out of context.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Xu, Jia2 
Sent: Monday, July 8, 2013 7:45 AM
To: 'r-help at r-project.org'
Subject: [R] A question on the abline function

Dear whom it may concerns,

I am Jia Xu, a summer intern analyst at Citi Research. I am also a
graduate student studying Financial Engineering at Cornell. I am
running regression analysis with Rstudio now. I have been
experiencing difficulty with the abline function. No matter I call
it directly in linear regression or call it through residual plots,
or plot results from lasso regression, it produces the same error as
the following:

Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...) :
  object 'C_abline' not found

Could you please help me check what is this problem?

Thanks for your time!

Best,

Jia Xu

Citi Research

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From patze003 at umn.edu  Mon Jul  8 22:15:19 2013
From: patze003 at umn.edu (Edward Patzelt)
Date: Mon, 8 Jul 2013 15:15:19 -0500
Subject: [R] Constructing a matrix of outputs from loop
Message-ID: <CADgQx8Pk=3hptmshFR-HA8_LrT8gcKBCRKQ-7esL8q9WpGmyMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/5404a716/attachment.pl>

From dwinsemius at comcast.net  Mon Jul  8 22:26:09 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 8 Jul 2013 13:26:09 -0700
Subject: [R] xts zoo "cannot remove prior installation of package"
In-Reply-To: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC8E269@EX02.platinum.com>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC8E269@EX02.platinum.com>
Message-ID: <6E724FD0-D41A-4D88-9670-843439A40F1A@comcast.net>


On Jul 8, 2013, at 10:21 AM, Pooya Lalehzari wrote:

> Hello,
> Some how, my xts/zoo package ran into trouble. I tried to re-install the packages, I get an error that it cannot remove the prior installation.
> I uninstalled R and the deleted all the libraries and reinstalled everything fresh. It still complains the same thing. I try to remove.packages("zoo"), it tells me there is no such package. I am really baffled. Does anyone know how to fix this problem?

If you look at the help page for remove.packages(), it states that the second argument is taken to be the first element in .libPaths(). You have not told us what .libPaths() is returning and you should do so (even though it wasn't mentioned in the Posting Guide.)  It seems possible that you set up an additonal library location which your new installation of R is "finding" but which is not the first item in the list of directories with library entries. 

I have found that having two locations for libraries is an annoyance, and have removed all "user library" locations.

> 	[[alternative HTML version deleted]]

> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Let me second Prof. Ripley's suggestion that you do more reading of the /listinfo/ page and the  Posting Guide.

-- 

David Winsemius
Alameda, CA, USA


From plalehzari at platinumlp.com  Mon Jul  8 22:55:40 2013
From: plalehzari at platinumlp.com (Pooya Lalehzari)
Date: Mon, 8 Jul 2013 20:55:40 +0000
Subject: [R] xts zoo "cannot remove prior installation of package"
In-Reply-To: <6E724FD0-D41A-4D88-9670-843439A40F1A@comcast.net>
References: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC8E269@EX02.platinum.com>
	<6E724FD0-D41A-4D88-9670-843439A40F1A@comcast.net>
Message-ID: <92FD11F467D9CA41A8AEA01FE4D76DEB0AC8E32F@EX02.platinum.com>

Thank you for your help.
It seems like there was an issue with the libPath. The path is setup to reference a cached copy of a shared drive and somehow the cache and the shared drive were not synching. I finally located the real place (i.e. the cached area) where R was looking and manually removed everything.

Thanks again,
Pooya.


-----Original Message-----
From: David Winsemius [mailto:dwinsemius at comcast.net] 
Sent: Monday, July 08, 2013 4:26 PM
To: Pooya Lalehzari
Cc: r-help at r-project.org
Subject: Re: [R] xts zoo "cannot remove prior installation of package"


On Jul 8, 2013, at 10:21 AM, Pooya Lalehzari wrote:

> Hello,
> Some how, my xts/zoo package ran into trouble. I tried to re-install the packages, I get an error that it cannot remove the prior installation.
> I uninstalled R and the deleted all the libraries and reinstalled everything fresh. It still complains the same thing. I try to remove.packages("zoo"), it tells me there is no such package. I am really baffled. Does anyone know how to fix this problem?

If you look at the help page for remove.packages(), it states that the second argument is taken to be the first element in .libPaths(). You have not told us what .libPaths() is returning and you should do so (even though it wasn't mentioned in the Posting Guide.)  It seems possible that you set up an additonal library location which your new installation of R is "finding" but which is not the first item in the list of directories with library entries. 

I have found that having two locations for libraries is an annoyance, and have removed all "user library" locations.

> 	[[alternative HTML version deleted]]

> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Let me second Prof. Ripley's suggestion that you do more reading of the /listinfo/ page and the  Posting Guide.

-- 

David Winsemius
Alameda, CA, USA

THIS E-MAIL IS FOR THE SOLE USE OF THE INTENDED
RECIPIENT(S) AND MAY CONTAIN CONFIDENTIAL AND
PRIVILEGED INFORMATION.

ANY UNAUTHORIZED REVIEW, USE, DISCLOSURE OR
DISTRIBUTION IS PROHIBITED. IF YOU ARE NOT THE
INTENDED RECIPIENT, PLEASE CONTACT THE SENDER
BY REPLY E-MAIL AND DESTROY ALL COPIES
OF THE ORIGINAL E-MAIL.






From olga.musayev at gmail.com  Mon Jul  8 23:02:37 2013
From: olga.musayev at gmail.com (Olga Musayev)
Date: Mon, 8 Jul 2013 17:02:37 -0400
Subject: [R] Complex Association Plots
Message-ID: <CA+RDsenEhBQ7RsbEYsuLfStLj4H=eD99usASxeZAE5iKMkgc5w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/5ba49530/attachment.pl>

From dcarlson at tamu.edu  Mon Jul  8 23:06:44 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 8 Jul 2013 16:06:44 -0500
Subject: [R] Constructing a matrix of outputs from loop
In-Reply-To: <CADgQx8Pk=3hptmshFR-HA8_LrT8gcKBCRKQ-7esL8q9WpGmyMg@mail.gmail.com>
References: <CADgQx8Pk=3hptmshFR-HA8_LrT8gcKBCRKQ-7esL8q9WpGmyMg@mail.gmail.com>
Message-ID: <127e01ce7c1f$0d0031b0$27009510$@tamu.edu>

?outer

e.g. output <- outer(ap, am, func)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Edward Patzelt
Sent: Monday, July 8, 2013 3:15 PM
To: r-help at r-project.org
Subject: [R] Constructing a matrix of outputs from loop

R -

I would like to construct a matrix from the output of a loop that
has 2
values it varies over the course of the loop creating a 20x20 matrix
of
output values:

 ap = logspace(-3, 0, 20)

 am = logspace(-3, .7, 20)
  for (ap in apList)
  {
   for (am in amList)
   {

 output = func(ap, am)
}
}

i.e. cell 1x1 is -3,-3 and the value is 45 or something

-- 
*Edward H Patzelt | Research Assistant
Psychology | University of Minnesota  | Elliott Hall, 75 East River
Road |
Minneapolis, MN 55455
Email: patze003 at umn.edu  |
Main: 612.626.0072
|
Mobile: 651.315.3410
| Office: S355
**

*

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Mon Jul  8 23:14:47 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 8 Jul 2013 14:14:47 -0700
Subject: [R] Constructing a matrix of outputs from loop
In-Reply-To: <127e01ce7c1f$0d0031b0$27009510$@tamu.edu>
References: <CADgQx8Pk=3hptmshFR-HA8_LrT8gcKBCRKQ-7esL8q9WpGmyMg@mail.gmail.com>
	<127e01ce7c1f$0d0031b0$27009510$@tamu.edu>
Message-ID: <CACk-te18fn9O7d1zuiXoBp00NdWu2b4PzM=o4By+Fw0=KQj7PA@mail.gmail.com>

David:

Perhaps not. func() must be vectorized for this to work.

-- Bert


On Mon, Jul 8, 2013 at 2:06 PM, David Carlson <dcarlson at tamu.edu> wrote:
> ?outer
>
> e.g. output <- outer(ap, am, func)
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of Edward Patzelt
> Sent: Monday, July 8, 2013 3:15 PM
> To: r-help at r-project.org
> Subject: [R] Constructing a matrix of outputs from loop
>
> R -
>
> I would like to construct a matrix from the output of a loop that
> has 2
> values it varies over the course of the loop creating a 20x20 matrix
> of
> output values:
>
>  ap = logspace(-3, 0, 20)
>
>  am = logspace(-3, .7, 20)
>   for (ap in apList)
>   {
>    for (am in amList)
>    {
>
>  output = func(ap, am)
> }
> }
>
> i.e. cell 1x1 is -3,-3 and the value is 45 or something
>
> --
> *Edward H Patzelt | Research Assistant
> Psychology | University of Minnesota  | Elliott Hall, 75 East River
> Road |
> Minneapolis, MN 55455
> Email: patze003 at umn.edu  |
> Main: 612.626.0072
> |
> Mobile: 651.315.3410
> | Office: S355
> **
>
> *
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From matzke at berkeley.edu  Tue Jul  9 00:05:23 2013
From: matzke at berkeley.edu (Nick Matzke)
Date: Mon, 08 Jul 2013 15:05:23 -0700
Subject: [R] simple Rcpp function produces: "AddressSanitizer: attempting
 free on address which was not malloc"
Message-ID: <51DB37A3.8030608@berkeley.edu>

I have an R package, cladoRcpp, which is up on CRAN.  After 
a minor update, which compiled without errors on R CMD check 
on my machine, I submitted the update.

Brian Ripley got an error that I didn't get:


==================================================================
We still see

 > Rcpp_combn_zerostart(n_to_choose_from=4, k_to_choose=2, 
maxlim=1e+07)
=================================================================
==14369== ERROR: AddressSanitizer: attempting free on 
address which was not malloc()-ed: 0x0000040541d0
     #0 0x7fe61090caca in ?? ??:0
     #1 0x7fe6138ba858 in 
_ZN9__gnu_cxx13new_allocatorIiE10deallocateEPim 
/usr/local/gcc48x/include/c++/4.8.1/ext/new_allocator.h:110
     #2 0x7fe613896fd4 in cpp_combn_zerostart 
/data/gannet2/ripley/R/packages/incoming/cladoRcpp.Rcheck/00_pkg_src/cladoRcpp/src/calc_anclikes_sp.cpp:75
     #3 0x472b5f in do_dotcall 
/data/gannet/ripley/R/svn/R-devel/src/main/dotcode.c:587

using AddressSanitizer, as before.
==================================================================


I gather that this is from him using the new gcc4.8 and the 
AddressSanitizer option on compile:

http://r.789695.n4.nabble.com/Linux-distribution-with-gcc-4-8-and-AddressSanitizer-td4664629.html

http://cran.r-project.org/doc/manuals/r-devel/R-exts.html#Using-gctorture-and-memory-access


I will attempt to download/install gcc48 and reproduce the 
error, although this is a somewhat major project.


The C++ function, though, is quite simple -- I wonder if 
anyone might be able to spot easily what is going on?





R function which calls C++ function:

======================================
Rcpp_combn_zerostart <- function(n_to_choose_from, 
k_to_choose, maxlim=1e+07)
	{
	n = n_to_choose_from
	m = k_to_choose
	
	# HEAD OFF ERROR
	predicted_number_of_cells_to_fill = choose(n,m)
	
	if (predicted_number_of_cells_to_fill > maxlim)
		{
		txt = paste("ERROR: n=", n_to_choose_from, ", k=", 
k_to_choose, ", n choose k=", 
predicted_number_of_cells_to_fill, " > maxlim=", maxlim, 
"\nCalculating something this big may crash your computer!", 
sep="")
		stop(txt)
		}
	
	
	outarray = .Call("cpp_combn_zerostart", as.integer(n), 
as.integer(m), as.double(maxlim))

	#R_states_list <- matrix(out$res,nrow=m,byrow=F)

	return(outarray)
	}
======================================



C++ function:
======================================

RcppExport SEXP cpp_combn_zerostart(SEXP R_n, SEXP R_m, SEXP 
R_maxval)
	{
	using namespace std;
	
	// Convert to plain C++
	int cpp_nval = Rcpp::as<int>(R_n);
	int cpp_mval = Rcpp::as<int>(R_m);
	double cpp_maxval = Rcpp::as<double>(R_maxval);
	
	// Create pointer variables to hold the addresses to each
	int* n = &cpp_nval;
	int* m = &cpp_mval;
	
	// Choose n by m; calculate from the values stored at 
addresses n and m
	double Cnm;
	Cnm = nChoosek(*n, *m);
	
	// Error check
	if (Cnm > cpp_maxval)
		{
		//cout << "\nERROR: n=" << cpp_nval << ", k=" << cpp_mval 
<< ", n choose k=" << Cnm << " > maxval=", cpp_maxval;
		//cout << "\nCalculating something this big may crash your 
computer!  Returning 0.";
		return 0;
		}
	
	
	// Declare and populate empty array of addresses to hold 
the combn results
	// Addresses for a 10x3 array; 30 total
	int* combmat;
	combmat = new int[(int)Cnm**(m+0)];
	
	// Run moncombn_zerostart; this will update the stuff in 
the addresses
	// stored in combmat
	moncombn_zerostart(combmat,n,m);
	
	// Write the contents of each of the Cnm times *m addresses 
to cout
	// convert double (float) Cnm to int
	int nrows;
	int ncols;
	nrows = *m;
	ncols = (int)Cnm;
	int vecsize;
	vecsize = nrows * ncols;
	//int combmat_vals[nrows * ncols];
	
	//Rcpp::NumericVector combmat_vals(vecsize);	// vector of 
size vecsize filled with 0s
	Rcpp::NumericMatrix combmat_vals(nrows,ncols);	// vector of 
size vecsize filled with 0s

	// initialize row & column numbers, and the temporary number	
	int rownum = 0;
	int colnum = 0;
	int tmpnum = 0;
	
	//cout << nrows << " rows, " << ncols << "cols...\n";
	
	for (int j = 1; j <= Cnm**(m+0); j++)
		{
		//cout << "\n";
		//cout << *(combmat+j-1) << " ";
		//combmat_vals[rownum][colnum] = *(combmat+j-1);
		//tmpnum = Rcpp::as<int>(*(combmat+j-1));
		tmpnum = *(combmat+j-1);
		//combmat_vals[j-1] = tmpnum;

		//cout << "\n" << rownum << "," << colnum << ", ncols=" << 
ncols << ": " << tmpnum;
		combmat_vals(rownum, colnum) = tmpnum;
		
		// Increment column
		rownum++;
		
		// Reset column when you reach the end; increment the row.
		// Reset of rows is not necessary
		if (rownum >= (nrows))
			{
			rownum = 0;
			colnum++;
			}
		} // end forloop

	// Convert to an int
	//Rcpp::Matrix outcombs(combmat_vals);
	
	// example use Armadillo matrix
	// http://dirk.eddelbuettel.com/blog/2011/04/23/
	//arma::mat outcombs = Rcpp::as<arma::mat>(combmat_vals);
	
	return Rcpp::wrap(combmat_vals);
	}
======================================
	

Thanks for any and all help!  These memory errors are tough 
for us biologists!!

Cheers, Nick




-- 
====================================================
Nicholas J. Matzke
Ph.D. Candidate, Graduate Student Researcher

Huelsenbeck Lab
Center for Theoretical Evolutionary Genomics
4151 VLSB (Valley Life Sciences Building)
Department of Integrative Biology
University of California, Berkeley

Graduate Student Instructor, IB200B
Principles of Phylogenetics: Ecology and Evolution
http://ib.berkeley.edu/courses/ib200b/
http://phylo.wikidot.com/


Lab websites:
http://ib.berkeley.edu/people/lab_detail.php?lab=54
http://fisher.berkeley.edu/cteg/hlab.html
Dept. personal page: 
http://ib.berkeley.edu/people/students/person_detail.php?person=370
Lab personal page: 
http://fisher.berkeley.edu/cteg/members/matzke.html
Lab phone: 510-643-6299
Dept. fax: 510-643-6264

Cell phone: 510-301-0179
Email: matzke at berkeley.edu

Mailing address:
Department of Integrative Biology
1005 Valley Life Sciences Building #3140
Berkeley, CA 94720-3140

-----------------------------------------------------
"[W]hen people thought the earth was flat, they were wrong. 
When people thought the earth was spherical, they were 
wrong. But if you think that thinking the earth is spherical 
is just as wrong as thinking the earth is flat, then your 
view is wronger than both of them put together."

Isaac Asimov (1989). "The Relativity of Wrong." The 
Skeptical Inquirer, 14(1), 35-44. Fall 1989.
http://chem.tufts.edu/AnswersInScience/RelativityofWrong.htm


From dwinsemius at comcast.net  Tue Jul  9 02:43:17 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 8 Jul 2013 17:43:17 -0700
Subject: [R] Constructing a matrix of outputs from loop
In-Reply-To: <CACk-te18fn9O7d1zuiXoBp00NdWu2b4PzM=o4By+Fw0=KQj7PA@mail.gmail.com>
References: <CADgQx8Pk=3hptmshFR-HA8_LrT8gcKBCRKQ-7esL8q9WpGmyMg@mail.gmail.com>
	<127e01ce7c1f$0d0031b0$27009510$@tamu.edu>
	<CACk-te18fn9O7d1zuiXoBp00NdWu2b4PzM=o4By+Fw0=KQj7PA@mail.gmail.com>
Message-ID: <39D71C36-0984-4A36-AE08-D5709E955A9D@comcast.net>


On Jul 8, 2013, at 2:14 PM, Bert Gunter wrote:

> David:
> 
> Perhaps not. func() must be vectorized for this to work.
> 
> -- Bert
> 
> 
> On Mon, Jul 8, 2013 at 2:06 PM, David Carlson <dcarlson at tamu.edu> wrote:
>> ?outer
>> 
>> e.g. output <- outer(ap, am, func)
>> 
>> -------------------------------------
>> David L Carlson
>> Associate Professor of Anthropology
>> Texas A&M University
>> College Station, TX 77840-4352
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>> [mailto:r-help-bounces at r-project.org] On Behalf Of Edward Patzelt
>> Sent: Monday, July 8, 2013 3:15 PM
>> To: r-help at r-project.org
>> Subject: [R] Constructing a matrix of outputs from loop
>> 
>> R -
>> 
>> I would like to construct a matrix from the output of a loop that
>> has 2
>> values it varies over the course of the loop creating a 20x20 matrix
>> of
>> output values:
>> 
>> ap = logspace(-3, 0, 20)
>> 
>> am = logspace(-3, .7, 20)
>>  for (ap in apList)
>>  {
>>   for (am in amList)
>>   {
>> 
>> output = func(ap, am)
>> }
>> }
>> 

You are overwriting each prior value of "output" since you are not indexing your assignments into a matrix. (You also didn't tell us where `logspace` comes from:

> ?logspace
No documentation for ?logspace? in specified packages and libraries:
you could try ???logspace?

Nonetheless:

apVec = logspace(-3, 0, 20)
amVec = logspace(-3, .7, 20)
output <- matrix(NA, ncol=length(apVec), nrow=length(amVec) )
 for (ap in seq_along( apVec)) {
   for (am in seq_along(amVec) ) {
     output[am, ap]  = func( apVec[ap], amVec[am] )
  }  
 }


>> i.e. cell 1x1 is -3,-3 and the value is 45 or something
>> 
>> --
>> *Edward H Patzelt | Research Assistant


David Winsemius
Alameda, CA, USA


From Lucy.Leigh at newcastle.edu.au  Tue Jul  9 05:18:45 2013
From: Lucy.Leigh at newcastle.edu.au (Lucy Leigh)
Date: Tue, 09 Jul 2013 13:18:45 +1000
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
Message-ID: <51DC0DB6.ECEB.009F.0@newcastle.edu.au>

Great thank you - are there any resources that step through how to use
RTools to compile the
source package and install it in R on (64-bit windows) ?

>>> Berend Hasselman <bhh at xs4all.nl> 8/07/2013 6:38 pm >>>

On 08-07-2013, at 02:15, "Lucy Leigh" <Lucy.Leigh at newcastle.edu.au>
wrote:

> Hi, 
> I have a source package that isn't available as a windows zip file.
Can
> anyone explain to me how I can install this on my windows R
platform?
> When I use the following code: 
> install.packages("PReMiuM_3.0.21.tar.gz", type = "source") 
> 
> 

Where did you get that version from?
CRAN has version 3.0.20 and that is available as a binary Windows
package (.zip).

As for the error message: you have to have Rtools installed to compile
source packages.

Berend

> I get this error message: 
> 
> 
> 
> * installing *source* package 'PReMiuM' ... 
> ** libs 
> 
> *** arch - i386 
> ERROR: compilation failed for package 'PReMiuM' 
> * removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM' 
> Warning messages: 
> 1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL
-l
> "C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had
status
> 1 
> 2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") : 
>  installation of package ?PReMiuM_3.0.21.tar.gz? had non-zero
exit
> status 
>> 
> 
> Thanks for any help anyone can give me, 
> Lucy
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.


From spencer.graves at structuremonitoring.com  Tue Jul  9 07:03:51 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Mon, 8 Jul 2013 22:03:51 -0700
Subject: [R] Installing R on Fedora 18 Linux?
In-Reply-To: <20130706235324.40210001737907ac599c5b86@inbox.com>
References: <51D8DB89.8080007@structuremonitoring.com>
	<CA+hbrhUCVJPwDvUV5pzh9Kxy9XeD_gJKFKwZN_h_hLaDZ09t4w@mail.gmail.com>
	<20130706235324.40210001737907ac599c5b86@inbox.com>
Message-ID: <51DB99B7.8020505@structuremonitoring.com>

       Thanks for the replies from Peter Langfelder and Ranjan Maitra.


       I tried su, "yum install R-core".  That installed R 3.0.1. To 
install packages like zoo and RCurl, I had to install other software, 
but with the help of a friend, Google, and previous replies to similar 
questions on R-Help, R-Devel and stackoverflow, I got past all those.


       Thanks again to Peter and Ranjan.


       Best Wishes,
       Spencer Graves


On 7/6/2013 9:53 PM, Ranjan Maitra wrote:
> Fedora does have the latest (both Fedora 18/19) R in the repos. (They
> are pretty good about this).
>
> To install R, try:
>
> sudo yum install R-core
>
> That will do it.
>
> To update, rather than install:
>
> try
>
> sudo yum update R-core
>
> HTH,
> Ranjan
>
> On Sat, 6 Jul 2013 20:22:13 -0700 Peter Langfelder
> <peter.langfelder at gmail.com>  wrote:
>
>> You have several options. You can use theF18  package manager to
>> install R directly from a Fedora software repository but the R may be
>> slightly out of date (IIRC Fedora 19 provides R-3.0.0; not sure about
>> F18).
>>
>> Or, on your CRAN mirror page, ignore the "Download and install R"
>> section and go straight to "Source code for all platforms". There you
>> can choose R-3.0.1.tar.gz or (my personal preference) go to "Daily
>> snapshots of current patched and development versions". There choose
>> the link R-patched.tar.gz (without a date; it is a link to the newest
>> patched release).
>>
>> Once you downloaded the tar.gz bundle, proceed as described in the manual.
>>
>> HTH,
>>
>> Peter
>>
>> On Sat, Jul 6, 2013 at 8:07 PM, Spencer Graves
>> <spencer.graves at structuremonitoring.com>  wrote:
>>> Hello:
>>>
>>>
>>>        I'm trying to install R under Fedora 18 Linux, and I'm confused.  The
>>> "R Installation and Administration" manual, sec. 1.1, says, "The simplest
>>> way is to download the most recent R-x.y.z.tar.gz file". However, I don't
>>> know how to get that.  My favorite CRAN mirror offers a "Precombiled binary"
>>> via "Download R for Linux".  That takes me to an index with options debian,
>>> redhat, suse, and ubuntu.  Redhat gives me an index with options el4, el5,
>>> fedora10, and fedora11.  I don't think I want any of those.
>>>
>>>
>>>        Suggestions?
>>>        Thanks,
>>>        Spencer
>>>
>>> ______________________________________________
>>> R-help at r-project.org  mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guidehttp://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Jul  9 08:18:44 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 9 Jul 2013 06:18:44 +0000
Subject: [R] A question on the abline function
In-Reply-To: <0F1A1373F93B1C44ABC51B71BC757E6327BB2614@EXNJMB21.nam.nsroot.net>
References: <0F1A1373F93B1C44ABC51B71BC757E6327BB2614@EXNJMB21.nam.nsroot.net>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CDBB@SRVEXCHMBX.precheza.cz>

Hi

you did not provide enough info for resolving your error (at least not enough for myself).

How did you call abline?

Standard way of calling abline is:

fit <- lm(...)
abline(fit) 

So please provide code you used, R version maybe OS and probably some data to play with.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Xu, Jia2
> Sent: Monday, July 08, 2013 2:45 PM
> To: 'r-help at r-project.org'
> Subject: [R] A question on the abline function
> 
> Dear whom it may concerns,
> 
> I am Jia Xu, a summer intern analyst at Citi Research. I am also a
> graduate student studying Financial Engineering at Cornell. I am
> running regression analysis with Rstudio now. I have been experiencing
> difficulty with the abline function. No matter I call it directly in
> linear regression or call it through residual plots, or plot results
> from lasso regression, it produces the same error as the following:
> 
> Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...) :
>   object 'C_abline' not found
> 
> Could you please help me check what is this problem?
> 
> Thanks for your time!
> 
> Best,
> 
> Jia Xu
> 
> Citi Research
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sguallar at yahoo.com  Tue Jul  9 08:52:46 2013
From: sguallar at yahoo.com (Santiago Guallar)
Date: Mon, 8 Jul 2013 23:52:46 -0700 (PDT)
Subject: [R] spped up a function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CB97@SRVEXCHMBX.precheza.cz>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CB97@SRVEXCHMBX.precheza.cz>
Message-ID: <1373352766.36843.YahooMailNeo@web160805.mail.bf1.yahoo.com>

Hi Petr, yes the function basically consists on merging two time series with different time intervals: one regular 'GPS' and one irregular 'xact' (the latter containing the binomial variable 'wd' that I want to add to 'GPS'.
Apparently my attachments did not go through. Here you have the dputs you requested plus the desired result based on them:

head(xact)
Ringjul ? timepos ? actwd
6106933 15135 2011-06-10 04:36:15 ?3822 dry
6106933 15135 2011-06-10 05:39:57 ? ?27 wet
6106933 15135 2011-06-10 05:40:24 ? ?60 dry
6106933 15135 2011-06-10 05:41:24 ? ? 6 wet
6106933 15135 2011-06-10 05:41:30 ? 753 dry
6106933 15135 2011-06-10 05:54:03 ? ?78 wet
6106933 15135 2011-06-10 05:55:21 ? ?15 dry
6106933 15135 2011-06-10 05:55:36 ? ?18 wet

head(GPS1, 16) and desired result (added column wd)?

? ? ? Ring ? jul ? ? ? ? ? ? timeposwd
5 ?6106933 15135 2011-06-10 04:39:00dry
6 ?6106933 15135 2011-06-10 04:44:00dry
7 ?6106933 15135 2011-06-10 04:49:00dry
8 ?6106933 15135 2011-06-10 04:54:00dry
9 ?6106933 15135 2011-06-10 04:59:00dry
10 6106933 15135 2011-06-10 05:04:00dry
11 6106933 15135 2011-06-10 05:09:00dry
12 6106933 15135 2011-06-10 05:13:00dry
13 6106933 15135 2011-06-10 05:18:00dry
14 6106933 15135 2011-06-10 05:23:00dry
15 6106933 15135 2011-06-10 05:28:00dry
16 6106933 15135 2011-06-10 05:33:00dry
17 6106933 15135 2011-06-10 05:38:00dry
18 6106933 15135 2011-06-10 05:43:00dry
19 6106933 15135 2011-06-10 05:48:00dry
20 6106933 15135 2011-06-10 05:53:00dry

Santi


>________________________________
> From: PIKAL Petr <petr.pikal at precheza.cz>
>To: Santiago Guallar <sguallar at yahoo.com>; r-help <r-help at r-project.org> 
>Sent: Monday, July 8, 2013 11:34 AM
>Subject: RE: [R] spped up a function
> 
>
>Hi
>
>It seems to me, that you basically want merge, but I can miss the point. Try post
>
>dput(head(xact))
>dput(head(GPS))
>
>and what shall be desired result based on those 2 datasets.
>
>Regards
>Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Santiago Guallar
>> Sent: Tuesday, July 02, 2013 7:47 PM
>> To: r-help
>> Subject: [R] spped up a function
>> 
>> Hi,
>> 
>> I have written a function to assign the values of a certain variable
>> 'wd' from a dataset to another dataset. Both contain data from the
>> same?time period but differ in the length of their time intervals:
>> 'GPS' has regular 10-minute intervals whereas 'xact' has
 irregular
>> intervals. I attached simplified text versions from write.table. You
>> can also get a dput of 'xact' in this address:
>> http://www.megafileupload.com/en/file/431569/xact-dput.html).
>> The original objects are large and the function takes almost one hour
>> to finish.
>> Here's the function:
>> 
>> fxG= function(xact, GPS){
>> l <- rep( 'A', nrow(GPS) )
>> v <- unique(GPS$Ring) # the process is carried out for several
>> individuals identified by 'Ring'
>> for(k in 1:length(v) ){
>> I = v[k]
>> df <- xact[xact$Ring == I,]
>> for(i in 1:nrow(GPS)){
>> if(GPS[i,]$Ring== I){# the code runs along the whole data.frame for
>> each i; it'd save time to make it stop with the last record of each i
>> instead u <- df$timepos <= GPS[i,]$timepos # fill vector l for each
>> interval t from xact <= each interval from GPS (take the max if
 there's
>> > 1 interval) l[i] <- df[max( which(u == TRUE) ),]$wd } } } return(l)}
>> 
>> vwd <- fxG(xact, GPS)
>> 
>> 
>> My question is: how can I speed up (optimize) this function?
>> 
>> Thank you for your help
>
>
>

From s.wood at bath.ac.uk  Tue Jul  9 09:07:12 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Tue, 09 Jul 2013 08:07:12 +0100
Subject: [R] error in "predict.gam" used with "bam"
In-Reply-To: <ef19394e.000011bc.0000000f@FIW7PC12.ELITEMEDIANET>
References: <ef19394e.000011bc.0000000f@FIW7PC12.ELITEMEDIANET>
Message-ID: <51DBB6A0.5060604@bath.ac.uk>

Hi Julian,

Any chance you could send me (offline) a short version of your data, 
which reproduces the problem? I can't reproduce it in a quick attempt 
(but it is quite puzzling, given that bam calls predict.gam internally 
in pretty much the same way that you are doing here).

btw (and nothing to do with the error) given that you are using R 3.0.1 
it's a good idea to upgrade to mgcv_1.7-23 or above, for the following 
reason (taken from the mgcv changeLog)

1.7-23
------

*** Fix of severe bug introduced with R 2.15.2 LAPACK change. The 
shipped version of dsyevr can fail to produce orthogonal eigenvectors 
when uplo='U' (upper triangle of symmetric matrix used), as opposed to 
'L'. This led to a substantial number of gam smoothing parameter 
estimation convergence failures, as the key stabilizing 
re-parameterization was substantially degraded. The issue did not affect 
gaussian additive models with GCV model selection. Other models could 
fail to converge any further as soon as any smoothing parameter became 
`large', as happens when a smooth is estimated as a straight line. 
check.gam reported the lack of full convergence, but the issue could 
also generate complete fit failures. Picked up late as full test suite 
had only been run on R > 2.15.1 with an external LAPACK.

best,
Simon


On 08/07/13 10:02, julian.bothe at elitepartner.de wrote:
> Hello everyone.
>
>
>
> I am doing a logistic gam (package mgcv) on a pretty large dataframe
> (130.000 cases with 100 variables).
>
> Because of that, the gam is fitted on a random subset of 10000. Now when I
> want to predict the values for the rest of the data, I get the following
> error:
>
>
>
>
>
>> gam.basis_alleakti.1.pr=predict(gam.basis_alleakti.1,
>
> +
> newdata=activisale_join[gam.basis_alleakti.1.complete_cases,all.vars(gam.b
> asis_alleakti.1.formula)],type="response")
>
> Error in predict.gam(gam.basis_alleakti.1, newdata =
> activisale_join[gam.basis_alleakti.1.complete_cases,  :
>
>    number of items to replace is not a multiple of replacement length
>
>
>
>
>
> The following is the code:
>
> #formula with some factors and a lot of variables to be fitted
>
> gam.basis_alleakti.1.formula=as.formula( paste("verl?ngerung ~?,
>
>        paste( names(activisale_join)[c(2:10)], collapse="+"), ##factors
>
>
> paste("s(",names(activisale_join)[c(17,19:29,31:42,44)],")",
> collapse="+")) # numeric variables, all count data
>
> )
>
>
>
> # complete cases
>
> gam.basis_alleakti.1.complete_cases =
> complete.cases(activisale_join[,all.vars(gam.basis_alleakti.1.formula) ])
>
>
>
> # modell fitting works on random subset
>
> gam.basis_alleakti.1=bam(gam.basis_alleakti.1.formula,
>
>                           data = activisale_join[subset.10000, ], family=
> "binomial")
>
>
>
> # error, no idea why
>
> gam.basis_alleakti.1.pr=predict(gam.basis_alleakti.1,
> newdata=activisale_join[gam.basis_alleakti.1.complete_cases,
> ],type="response")
>
>
>
>
>
> the prediction on the same subset (subset.10000) works.
>
>
>
>
>
> It could be that this error is somewhat similar to that described as
> sidequestion in
>
> http://r.789695.n4.nabble.com/gamm-tensor-product-and-interaction-td452618
> 8.html, where simon answered the following:
>
>
>
> ?>  Here is the error message I obtain:
>>
> vis.gam(gm1$gam,plot.type="contour",n.grid=200,color="heat",zlim=c(0,4))
>>   Error in predict.gam(x, newdata = newd, se.fit = TRUE, type = type) :
> number of items to replace is not a multiple of replacement length
> - hmm, possibly a bug. I'll look into it.
>
> best,
> Simon?
>
>
>
> All the best
>
>
>
> Julian
>
>
>
> Ps.: > version
>                 _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          0.1
> year           2013
> month          05
> day            16
> svn rev        62743
> language       R
> version.string R version 3.0.1 (2013-05-16)
> nickname       Good Sport
>
>
>
> package mgcv version 1.7-22
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From webb.elizabeth.e at gmail.com  Tue Jul  9 04:27:24 2013
From: webb.elizabeth.e at gmail.com (Elizabeth Webb)
Date: Mon, 8 Jul 2013 18:27:24 -0800
Subject: [R] fitting log function: errors using nls and nlxb
Message-ID: <CAJ4DX-tLSWE7EdC49o0X3OkpGn=8uCX_q31237MGrD7HM1-ZRA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130708/9c3710ad/attachment.pl>

From erinm.hodgess at gmail.com  Tue Jul  9 09:30:08 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 9 Jul 2013 02:30:08 -0500
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DC0DB6.ECEB.009F.0@newcastle.edu.au>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
Message-ID: <CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/547e9f2f/attachment.pl>

From dialvac-r at yahoo.de  Tue Jul  9 10:20:09 2013
From: dialvac-r at yahoo.de (D. Alain)
Date: Tue, 9 Jul 2013 09:20:09 +0100 (BST)
Subject: [R] results of robust regression vs. OLS regression
Message-ID: <1373358009.16020.YahooMailNeo@web172703.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/27bec037/attachment.pl>

From smartpink111 at yahoo.com  Mon Jul  8 22:53:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 8 Jul 2013 13:53:38 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
In-Reply-To: <DUB116-W108D9A22BF7209ACEE8E229E780@phx.gbl>
References: <1373238668238-4671059.post@n4.nabble.com>,
	<1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<DUB116-W5914520FB86D7D17F860709E780@phx.gbl>,
	<1373311601.77868.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<DUB116-W108D9A22BF7209ACEE8E229E780@phx.gbl>
Message-ID: <1373316818.12350.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi Laila,
There is only one column from the dput() output.
time1<- structure(list(date....
str(time1)
#'data.frame':??? 20 obs. of? 1 variable:
# $ date: Factor w/ 582 levels "01/01/2009 01:58",..: 370 389 390 409 410 429 430 450 451 471 ..
?time1[,1]<-as.POSIXct(time1[,1],format="%d/%m/%Y %H:%M")
head(time1)
?# ?????????????? date
#1 2008-11-20 12:23:00
#2 2008-11-21 00:33:00
#3 2008-11-21 12:29:00
#4 2008-11-22 00:29:00
#5 2008-11-22 12:39:00
#6 2008-11-23 00:50:00


A.K.





________________________________
From: laila Aranda Romero <laila_zgz at hotmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Monday, July 8, 2013 4:29 PM
Subject: RE: [R] Need hep for converting date data in POSIXct




Arun,

?When I type dput(head(time,20), it appears this:

structure(list(date = structure(c(370L, 389L, 390L, 409L, 410L, 
429L, 430L, 450L, 451L, 471L, 472L, 491L, 492L, 511L, 512L, 531L, 
532L, 549L, 550L, 567L), .Label = c("01/01/2009 01:58", "01/01/2009 13:57", 
"01/02/2009 03:49", "01/02/2009 15:51", "01/03/2009 04:40", "01/03/2009 16:37", 
"01/04/2009 04:21", "01/04/2009 16:33", "01/05/2009 04:33", "01/05/2009 16:31", 
"01/06/2009 03:11", "01/06/2009 15:10", "01/07/2009 02:49", "01/07/2009 14:46", 
"01/08/2009 02:44", "01/08/2009 14:44", "01/09/2009 01:05", "01/09/2009 13:14", 
"01/12/2008 00:58", "01/12/2008 12:53", "02/01/2009 02:01", "02/01/2009 13:58", 
"02/02/2009 03:59", "02/02/2009 15:58", "02/03/2009 04:37", "02/03/2009 16:25", 
"02/04/2009 04:30", "02/04/2009 16:30", "02/05/2009 04:33", "02/05/2009 16:31", 
"02/06/2009 02:52", "02/06/2009 14:57", "02/07/2009 02:47", "02/07/2009 14:51", 
"02/08/2009 02:42", "02/08/2009 14:42", "02/09/2009 01:14", "02/09/2009 13:19", 
"03/01/2009 01:52", "03/01/2009 13:57", "03/02/2009 03:55", "03/02/2009 15:56", 
"03/03/2009 04:21", "03/03/2009 16:29", "03/04/2009 04:39", "03/04/2009 16:29", 
"03/05/2009 04:27", "03/05/2009 16:24", "03/06/2009 02:53", "03/06/2009 14:48", 
"03/07/2009 02:55", "03/07/2009 14:54", "03/08/2009 02:36", "03/08/2009 14:28", 
"03/09/2009 01:32", "03/09/2009 13:37", "04/01/2009 01:57", "04/01/2009 13:57", 
"04/02/2009 03:55", "04/02/2009 15:50", "04/03/2009 04:35", "04/03/2009 16:35", 
"04/04/2009 04:28", "04/04/2009 16:36", "04/05/2009 04:43", "04/05/2009 16:43", 
"04/06/2009 02:36", "04/06/2009 14:40", "04/07/2009 02:49", "04/07/2009 14:48", 
"04/08/2009 02:40", "04/08/2009 14:38", "04/09/2009 01:45", "04/09/2009 13:54", 
"05/01/2009 02:02", "05/01/2009 14:01", "05/02/2009 03:51", "05/02/2009 15:49", 
"05/03/2009 04:35", "05/03/2009 16:40", "05/04/2009 04:36", "05/04/2009 16:29", 
"05/05/2009 04:18", "05/05/2009 16:13", "05/06/2009 02:41", "05/06/2009 14:22", 
"05/07/2009 02:50", "05/07/2009 14:57", "05/08/2009 02:31", "05/08/2009 14:28", 
"05/09/2009 02:08", "05/09/2009 14:13", "06/01/2009 01:55", "06/01/2009 13:52", 
"06/02/2009 03:54", "06/02/2009 15:55", "06/03/2009 04:39", "06/03/2009 16:40", 
"06/04/2009 04:20", "06/04/2009 16:19", "06/05/2009 03:56", "06/05/2009 15:49", 
"06/06/2009 02:20", "06/06/2009 14:26", "06/07/2009 03:10", "06/07/2009 15:05", 
"06/08/2009 02:35", "06/08/2009 14:35", "06/09/2009 02:10", "06/09/2009 14:01", 
"06/12/2008 12:27", "07/01/2009 01:54", "07/01/2009 13:38", "07/02/2009 03:49", 
"07/02/2009 15:50", "07/03/2009 04:53", "07/03/2009 16:33", "07/04/2009 04:23", 
"07/04/2009 16:22", "07/05/2009 03:33", "07/05/2009 15:34", "07/06/2009 02:40", 
"07/06/2009 14:59", "07/07/2009 02:52", "07/07/2009 14:55", "07/08/2009 02:34", 
"07/08/2009 14:37", "07/09/2009 01:59", "07/09/2009 13:45", "07/12/2008 00:28", 
"07/12/2008 12:33", "08/01/2009 01:23", "08/01/2009 13:09", "08/02/2009 03:52", 
"08/02/2009 15:51", "08/03/2009 04:33", "08/03/2009 16:47", "08/04/2009 04:26", 
"08/04/2009 16:27", "08/05/2009 03:29", "08/05/2009 15:28", "08/06/2009 03:08", 
"08/06/2009 14:58", "08/07/2009 03:02", "08/07/2009 15:01", "08/08/2009 02:38", 
"08/08/2009 14:31", "08/09/2009 01:32", "08/09/2009 13:19", "08/12/2008 00:27", 
"08/12/2008 12:29", "09/01/2009 00:57", "09/01/2009 12:52", "09/02/2009 03:45", 
"09/02/2009 15:46", "09/03/2009 04:33", "09/03/2009 16:38", "09/04/2009 04:34", 
"09/04/2009 16:25", "09/05/2009 03:27", "09/05/2009 15:13", "09/06/2009 02:50", 
"09/06/2009 14:32", "09/07/2009 03:01", "09/07/2009 15:08", "09/08/2009 02:35", 
"09/08/2009 14:31", "09/09/2009 01:08", "09/09/2009 13:05", "09/12/2008 00:34", 
"09/12/2008 12:32", "10/01/2009 00:54", "10/01/2009 12:48", "10/02/2009 03:51", 
"10/02/2009 15:45", "10/03/2009 04:41", "10/03/2009 16:30", "10/04/2009 04:21", 
"10/04/2009 16:33", "10/05/2009 03:28", "10/05/2009 15:39", "10/06/2009 02:31", 
"10/06/2009 14:50", "10/07/2009 03:03", "10/07/2009 15:03", "10/08/2009 02:43", 
"10/08/2009 14:45", "10/09/2009 00:58", "10/09/2009 12:59", "10/12/2008 00:26", 
"10/12/2008 12:30", "11/02/2009 03:54", "11/02/2009 15:59", "11/03/2009 04:32", 
"11/03/2009 16:36", "11/04/2009 04:38", "11/04/2009 16:35", "11/05/2009 03:29", 
"11/05/2009 15:19", "11/06/2009 02:56", "11/06/2009 14:55", "11/07/2009 02:57", 
"11/07/2009 14:57", "11/08/2009 02:35", "11/08/2009 14:36", "11/09/2009 01:03", 
"11/09/2009 13:08", "12/02/2009 03:54", "12/02/2009 15:55", "12/03/2009 04:36", 
"12/03/2009 16:37", "12/04/2009 04:34", "12/04/2009 16:36", "12/05/2009 03:19", 
"12/05/2009 15:17", "12/06/2009 02:36", "12/06/2009 14:36", "12/07/2009 03:07", 
"12/07/2009 15:14", "12/08/2009 02:38", "12/08/2009 14:35", "12/09/2009 01:04", 
"12/09/2009 13:06", "12/12/2008 12:33", "13/02/2009 04:00", "13/02/2009 15:56", 
"13/03/2009 04:48", "13/03/2009 16:49", "13/04/2009 04:34", "13/04/2009 16:08", 
"13/05/2009 03:02", "13/05/2009 14:55", "13/06/2009 02:31", "13/06/2009 14:30", 
"13/07/2009 03:10", "13/07/2009 15:05", "13/08/2009 02:38", "13/08/2009 14:42", 
"13/09/2009 01:05", "13/09/2009 12:59", "13/12/2008 00:28", "13/12/2008 12:28", 
"14/02/2009 03:56", "14/02/2009 15:56", "14/03/2009 04:46", "14/03/2009 16:41", 
"14/04/2009 04:10", "14/04/2009 16:34", "14/05/2009 02:57", "14/05/2009 15:00", 
"14/06/2009 02:32", "14/06/2009 14:21", "14/07/2009 03:04", "14/07/2009 15:08", 
"14/08/2009 02:45", "14/08/2009 14:43", "14/09/2009 00:59", "14/09/2009 13:03", 
"14/12/2008 00:28", "14/12/2008 12:37", "15/02/2009 03:52", "15/02/2009 16:07", 
"15/03/2009 04:37", "15/03/2009 16:37", "15/04/2009 04:36", "15/04/2009 16:28", 
"15/05/2009 02:58", "15/05/2009 14:58", "15/06/2009 02:23", "15/06/2009 14:22", 
"15/07/2009 03:12", "15/07/2009 15:04", "15/08/2009 02:39", "15/08/2009 14:40", 
"15/09/2009 00:58", "15/09/2009 12:57", "15/12/2008 00:18", "15/12/2008 12:19", 
"16/02/2009 04:26", "16/02/2009 16:29", "16/03/2009 04:48", "16/03/2009 16:42", 
"16/04/2009 04:22", "16/04/2009 16:27", "16/05/2009 02:38", "16/05/2009 14:28", 
"16/06/2009 02:17", "16/06/2009 14:31", "16/07/2009 03:06", "16/07/2009 14:59", 
"16/08/2009 02:37", "16/08/2009 14:37", "16/09/2009 00:56", "16/09/2009 12:55", 
"16/12/2008 00:20", "16/12/2008 12:17", "17/02/2009 04:19", "17/02/2009 16:20", 
"17/03/2009 04:35", "17/03/2009 16:41", "17/04/2009 04:30", "17/04/2009 16:24", 
"17/05/2009 02:20", "17/05/2009 14:21", "17/06/2009 02:46", "17/06/2009 14:46", 
"17/07/2009 02:59", "17/07/2009 15:06", "17/08/2009 02:39", "17/08/2009 14:38", 
"17/09/2009 00:55", "17/09/2009 12:49", "17/12/2008 00:20", "17/12/2008 12:22", 
"18/02/2009 04:22", "18/02/2009 16:18", "18/03/2009 04:48", "18/03/2009 16:43", 
"18/04/2009 04:29", "18/04/2009 16:30", "18/05/2009 02:10", "18/05/2009 14:18", 
"18/06/2009 02:37", "18/06/2009 14:47", "18/07/2009 03:09", "18/07/2009 15:11", 
"18/08/2009 02:40", "18/08/2009 14:19", "18/09/2009 00:51", "18/09/2009 12:49", 
"18/12/2008 00:20", "18/12/2008 12:15", "19/01/2009 13:00", "19/02/2009 04:16", 
"19/02/2009 16:15", "19/03/2009 04:46", "19/03/2009 16:41", "19/04/2009 04:25", 
"19/04/2009 16:28", "19/05/2009 02:14", "19/05/2009 14:16", "19/06/2009 02:41", 
"19/06/2009 14:47", "19/07/2009 03:09", "19/07/2009 15:03", "19/08/2009 02:34", 
"19/08/2009 14:24", "19/09/2009 00:45", "19/09/2009 12:42", "19/12/2008 00:16", 
"19/12/2008 12:16", "20/01/2009 01:23", "20/01/2009 13:53", "20/02/2009 04:24", 
"20/02/2009 16:20", "20/03/2009 04:40", "20/03/2009 16:39", "20/04/2009 04:38", 
"20/04/2009 16:38", "20/05/2009 02:15", "20/05/2009 14:18", "20/06/2009 02:50", 
"20/06/2009 14:46", "20/07/2009 03:05", "20/07/2009 15:06", "20/08/2009 02:29", 
"20/08/2009 14:18", "20/09/2009 00:37", "20/09/2009 12:35", "20/11/2008 12:23", 
"21/01/2009 01:57", "21/01/2009 14:02", "21/02/2009 04:08", "21/02/2009 16:07", 
"21/03/2009 04:34", "21/03/2009 16:34", "21/04/2009 04:33", "21/04/2009 16:29", 
"21/05/2009 02:19", "21/05/2009 14:28", "21/06/2009 02:44", "21/06/2009 14:51", 
"21/07/2009 03:05", "21/07/2009 15:03", "21/08/2009 02:19", "21/08/2009 14:21", 
"21/09/2009 00:30", "21/09/2009 12:32", "21/11/2008 00:33", "21/11/2008 12:29", 
"22/01/2009 02:00", "22/01/2009 14:14", "22/02/2009 04:07", "22/02/2009 15:59", 
"22/03/2009 04:34", "22/03/2009 16:37", "22/04/2009 04:49", "22/04/2009 16:44", 
"22/05/2009 02:29", "22/05/2009 14:44", "22/06/2009 02:50", "22/06/2009 14:47", 
"22/07/2009 02:58", "22/07/2009 14:58", "22/08/2009 02:20", "22/08/2009 14:10", 
"22/09/2009 00:29", "22/09/2009 12:31", "22/11/2008 00:29", "22/11/2008 12:39", 
"23/01/2009 02:36", "23/01/2009 14:52", "23/02/2009 03:56", "23/02/2009 16:01", 
"23/03/2009 04:52", "23/03/2009 16:52", "23/04/2009 04:25", "23/04/2009 16:30", 
"23/05/2009 02:57", "23/05/2009 15:12", "23/06/2009 02:52", "23/06/2009 14:46", 
"23/07/2009 02:55", "23/07/2009 14:49", "23/08/2009 02:04", "23/08/2009 13:53", 
"23/09/2009 00:29", "23/09/2009 12:24", "23/11/2008 00:50", "23/11/2008 12:51", 
"23/12/2008 12:45", "24/01/2009 03:04", "24/01/2009 15:11", "24/02/2009 04:10", 
"24/02/2009 16:08", "24/03/2009 04:41", "24/03/2009 16:32", "24/04/2009 04:34", 
"24/04/2009 16:19", "24/05/2009 03:14", "24/05/2009 15:25", "24/06/2009 02:38", 
"24/06/2009 14:48", "24/07/2009 02:47", "24/07/2009 14:46", "24/08/2009 01:51", 
"24/08/2009 13:48", "24/09/2009 00:21", "24/09/2009 12:16", "24/11/2008 00:44", 
"24/11/2008 12:45", "24/12/2008 01:10", "24/12/2008 13:24", "25/01/2009 03:15", 
"25/01/2009 15:24", "25/02/2009 04:08", "25/02/2009 16:17", "25/03/2009 04:28", 
"25/03/2009 16:30", "25/04/2009 04:13", "25/04/2009 16:19", "25/05/2009 03:21", 
"25/05/2009 15:30", "25/06/2009 02:45", "25/06/2009 14:49", "25/07/2009 02:42", 
"25/07/2009 14:39", "25/08/2009 01:50", "25/08/2009 13:47", "25/09/2009 00:10", 
"25/11/2008 00:40", "25/11/2008 12:40", "25/12/2008 01:18", "25/12/2008 13:39", 
"26/01/2009 03:40", "26/01/2009 15:32", "26/02/2009 04:22", "26/02/2009 16:29", 
"26/03/2009 04:30", "26/03/2009 16:26", "26/04/2009 04:19", "26/04/2009 16:14", 
"26/05/2009 03:26", "26/05/2009 15:32", "26/06/2009 02:48", "26/06/2009 14:45", 
"26/07/2009 02:35", "26/07/2009 14:43", "26/08/2009 01:48", "26/08/2009 13:33", 
"26/11/2008 00:47", "26/11/2008 12:50", "26/12/2008 01:59", "26/12/2008 14:12", 
"27/01/2009 03:31", "27/01/2009 15:44", "27/02/2009 04:36", "27/02/2009 16:43", 
"27/03/2009 04:30", "27/03/2009 16:19", "27/04/2009 04:19", "27/04/2009 16:30", 
"27/05/2009 03:32", "27/05/2009 15:32", "27/06/2009 02:44", "27/06/2009 14:49", 
"27/07/2009 02:42", "27/07/2009 14:30", "27/08/2009 01:29", "27/08/2009 13:21", 
"27/11/2008 00:45", "27/11/2008 12:45", "27/12/2008 02:06", "27/12/2008 14:11", 
"28/01/2009 03:53", "28/01/2009 15:48", "28/02/2009 04:41", "28/02/2009 16:37", 
"28/03/2009 04:15", "28/03/2009 16:14", "28/04/2009 04:33", "28/04/2009 16:32", 
"28/05/2009 03:32", "28/05/2009 15:33", "28/06/2009 02:49", "28/06/2009 14:43", 
"28/07/2009 02:30", "28/07/2009 14:30", "28/08/2009 01:19", "28/08/2009 13:18", 
"28/11/2008 00:48", "28/11/2008 12:48", "28/12/2008 02:01", "28/12/2008 13:54", 
"29/01/2009 03:52", "29/01/2009 16:05", "29/03/2009 04:15", "29/03/2009 16:21", 
"29/04/2009 04:28", "29/04/2009 16:28", "29/05/2009 03:32", "29/05/2009 15:41", 
"29/06/2009 02:46", "29/06/2009 14:49", "29/07/2009 02:27", "29/07/2009 14:43", 
"29/08/2009 01:26", "29/08/2009 13:19", "29/11/2008 00:49", "29/11/2008 12:50", 
"29/12/2008 02:01", "29/12/2008 13:50", "30/01/2009 04:15", "30/01/2009 16:03", 
"30/03/2009 04:30", "30/03/2009 16:33", "30/04/2009 04:29", "30/04/2009 16:26", 
"30/05/2009 03:40", "30/05/2009 15:40", "30/06/2009 02:46", "30/06/2009 14:51", 
"30/07/2009 02:51", "30/07/2009 14:43", "30/08/2009 01:25", "30/08/2009 13:23", 
"30/11/2008 00:50", "30/11/2008 12:53", "30/12/2008 01:50", "30/12/2008 14:03", 
"31/01/2009 04:08", "31/01/2009 16:01", "31/03/2009 04:33", "31/03/2009 16:23", 
"31/05/2009 03:31", "31/05/2009 15:27", "31/07/2009 02:42", "31/07/2009 14:39", 
"31/08/2009 01:22", "31/08/2009 13:08", "31/12/2008 01:56", "31/12/2008 13:53"
), class = "factor")), .Names = "date", row.names = c(NA, 20L
), class = "data.frame")?

I hope?that you're asking for this!!!!! :)
Laila


> Date: Mon, 8 Jul 2013 12:26:41 -0700
> From: smartpink111 at yahoo.com
> Subject: Re: [R] Need hep for converting date data in POSIXct
> To: laila_zgz at hotmail.com
> 
> Hi laila,
> 
> You need to provide the full dput() output.? As I mentioned in my earlier email in Nabble ( which I am not sure you got it), use dput() for a smaller dataset. 
> For eg.
> dput(head(dataset,20))
> 
> 
> 
> 
> 
> ----- Original Message -----
> From: laila <laila_zgz at hotmail.com>
> To: r-help at r-project.org
> Cc: 
> Sent: Monday, July 8, 2013 5:52 AM
> Subject: Re: [R] Need hep for converting date data in POSIXct
> 
> Hi Arun,
> I think that my data has another format. When I type the comand dput(time), it appears the following information:
> structure(list(date = structure(c(696L, 18L, 19L, 43L, 44L, 45L, 
> 67L, 68L, 94L, 95L, 117L, 118L, 141L, 142L, 167L, 168L, 193L.......), .Label = c("01/01/2011 12:32", "01/02/2011 00:49", "01/02/2011 12:54",....), class = "factor")), .Names = "date", row.names = c(NA, 
> 716L), class = "data.frame").? When I tried to convert to POSIXct , it gives me this thing:structure(c(NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real_, NA_real,NA_real_), class = c("POSIXct", "POSIXt"), tzone = "") Script I have done is: library(argosfilter)
> setwd("C:/Users/Usuario/Dropbox/Laila Aranda/PUFGRA")
> Geo =? read.table("2370001_PUFGRA_2009_Gough_000_retarded10_both.trj",header=FALSE,sep = ",", col.names= c("type", "date", "secs", "Trans1",? "Trans2", "lat.sta",? "lat.comp", "long",? "dist", "rumbo", "velocidad",? "confianza"))
> location=subset(Geo, select= c(lat.comp,long))
> time=subset(Geo, select =c(date))
> k<-as.POSIXct( ?time, format= "%d/%m/%y %H:%M") Laila? PS: I've just realised that I made a mistake, because I want to merge two columns not rows. In fact, I have one column: dd/mm/yyyy mm:hh and another column(secs): 40567,87.? I send you a picture of my database.? 
> 
> 
> Date: Sun, 7 Jul 2013 18:10:09 -0700
> From: ml-node+s789695n4671066h81 at n4.nabble.com
> To: laila_zgz at hotmail.com
> Subject: Re: Need hep for converting date data in POSIXct
> 
> 
> 
> ??? Hi,
> 
> I am not sure how your dataset looks like.? If it is like the one below: (otherwise, please provide a reproducible example using ?dput())
> 
> 
> dat1<- read.table(text="
> 
> datetime
> 
> 10/02/2010
> 
> 02:30
> 
> 11/02/2010
> 
> 04:00
> 
> 14/02/2010
> 
> 06:30
> 
> ",sep="",header=TRUE,stringsAsFactors=FALSE)
> 
> 
> lst1<-split(dat1,(seq_along(dat1$datetime)-1)%%2+1)
> 
> dat2<- data.frame(datetime=as.POSIXct(paste(lst1[[1]][,1],lst1[[2]][,1]),format="%d/%m/%Y %H:%M"))
> 
> str(dat2)
> 
> #'data.frame':? ? 3 obs. of? 1 variable:
> 
> # $ datetime: POSIXct, format: "2010-02-10 02:30:00" "2010-02-11 04:00:00" ...
> 
> dat2
> 
> #? ? ? ? ? ???datetime
> 
> #1 2010-02-10 02:30:00
> 
> #2 2010-02-11 04:00:00
> 
> #3 2010-02-14 06:30:00
> 
> 
> 
> #or
> 
> data.frame(datetime=as.POSIXct(paste(dat1[seq(1,nrow(dat1),by=2),1],? dat1[seq(2,nrow(dat1),by=2),1]),format="%d/%m/%Y %H:%M"))
> 
> #? ? ? ? ? ???datetime
> 
> #1 2010-02-10 02:30:00
> 
> #2 2010-02-11 04:00:00
> 
> #3 2010-02-14 06:30:00
> 
> 
> 
> 
> A.K.
> 
> 
> 
> 
> Hey everybody, 
> 
> 
> I am a new user of R software. I don't know how I can merge two rows in 
> 
> one. In fact, I have one row with the date(dd/mm/yyyy) and another with the 
> 
> time (hh:mm) and I would like to get one row with date time in order to 
> 
> convert to POSIXct. How can I do it??
> 
> 
> ______________________________________________
> 
> [hidden email] mailing list
> 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> ??? 
> ??? 
> ??? 
> ??? 
> 
> ??? 
> 
> ??? 
> ??? 
> ??? ??? If you reply to this email, your message will be added to the discussion below:
> ??? ??? http://r.789695.n4.nabble.com/Need-hep-for-converting-date-data-in-POSIXct-tp4671059p4671066.html
> ??? 
> ??? 
> ??? ??? 
> ??? ??? To unsubscribe from Need hep for converting date data in POSIXct, click here.
> 
> ??? ??? NAML
> ???????? ???????? ?????? ??? ? 
> 
> data.docx (213K) <http://r.789695.n4.nabble.com/attachment/4671084/0/data.docx>
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Need-hep-for-converting-date-data-in-POSIXct-tp4671059p4671084.html
> Sent from the R help mailing list archive at Nabble.com.
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ????


From smriti.sebastuan at gmail.com  Tue Jul  9 07:30:43 2013
From: smriti.sebastuan at gmail.com (smriti Sebastian)
Date: Tue, 9 Jul 2013 11:00:43 +0530
Subject: [R] find 2D corelation coefficient
Message-ID: <CAKpT9Hsah7xvoca7kvRxFwGAxnvG_r_hLgGFiJWx63J4MT-Wgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/eb3985ca/attachment.pl>

From xhl860728 at 163.com  Tue Jul  9 08:57:48 2013
From: xhl860728 at 163.com (=?GBK?B?us7BwQ==?=)
Date: Tue, 9 Jul 2013 14:57:48 +0800 (CST)
Subject: [R] wrong when use the function fast99 in package "Sensitivity"
Message-ID: <76a33c96.9d87.13fc238c611.Coremail.xhl860728@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/fe9d018c/attachment.pl>

From pdalgd at gmail.com  Tue Jul  9 10:57:09 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 9 Jul 2013 10:57:09 +0200
Subject: [R] find 2D corelation coefficient
In-Reply-To: <CAKpT9Hsah7xvoca7kvRxFwGAxnvG_r_hLgGFiJWx63J4MT-Wgw@mail.gmail.com>
References: <CAKpT9Hsah7xvoca7kvRxFwGAxnvG_r_hLgGFiJWx63J4MT-Wgw@mail.gmail.com>
Message-ID: <59080B21-B285-4013-987D-F13BB49B6116@gmail.com>


On Jul 9, 2013, at 07:30 , smriti Sebastian wrote:

> I need to find the 2d corelation betwee two datasets which are having
> common x-values.Is there any way to find 2D corelation in R?


If you can tell us what the definition is....

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From petr.pikal at precheza.cz  Tue Jul  9 11:19:07 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 9 Jul 2013 09:19:07 +0000
Subject: [R] spped up a function
In-Reply-To: <1373352766.36843.YahooMailNeo@web160805.mail.bf1.yahoo.com>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CB97@SRVEXCHMBX.precheza.cz>
	<1373352766.36843.YahooMailNeo@web160805.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE20@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/5cd47536/attachment.pl>

From petr.pikal at precheza.cz  Tue Jul  9 11:45:55 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 9 Jul 2013 09:45:55 +0000
Subject: [R] regular expression strikes again
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>

Dear experts in regexpr.

I have this

dput(test[500:510])
c("pH 9,36 2", "pH 9,36 3", "pH 9,66 1", "pH 9,66 2", "pH 9,66 3", 
"pH 10,04 1", "pH 10,04 2", "pH 10,04 3", "RGLP 144006 pH 6,13 1", 
"RGLP 144006 pH 6,13 2", "RGLP 144006 pH 6,13 3")

and I want something like this

gsub("^.*([[:digit:]],[[:digit:]]*).*$", "\\1", test[500:510])
 [1] "9,36" "9,36" "9,66" "9,66" "9,66" "0,04" "0,04" "0,04" "6,13" "6,13"
[11] "6,13"

but with 10,04 values instead of 0,04.

I tried
gsub("^.*([[:digit:]]+,[[:digit:]]*).*$", "\\1", test[500:510])

or other variations but without any success.

Please help.

Regards
Petr


From pdalgd at gmail.com  Tue Jul  9 11:58:33 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 9 Jul 2013 11:58:33 +0200
Subject: [R] regular expression strikes again
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
Message-ID: <A137B40C-23BE-4EC8-AE4A-393AC1B6BF07@gmail.com>


On Jul 9, 2013, at 11:45 , PIKAL Petr wrote:

> Dear experts in regexpr.
> 
> I have this
> 
> dput(test[500:510])
> c("pH 9,36 2", "pH 9,36 3", "pH 9,66 1", "pH 9,66 2", "pH 9,66 3", 
> "pH 10,04 1", "pH 10,04 2", "pH 10,04 3", "RGLP 144006 pH 6,13 1", 
> "RGLP 144006 pH 6,13 2", "RGLP 144006 pH 6,13 3")
> 
> and I want something like this
> 
> gsub("^.*([[:digit:]],[[:digit:]]*).*$", "\\1", test[500:510])
> [1] "9,36" "9,36" "9,66" "9,66" "9,66" "0,04" "0,04" "0,04" "6,13" "6,13"
> [11] "6,13"
> 
> but with 10,04 values instead of 0,04.
> 
> I tried
> gsub("^.*([[:digit:]]+,[[:digit:]]*).*$", "\\1", test[500:510])
> 
> or other variations but without any success.
> 


Presumably the ^.* is too greedy. Perhaps add a space? I.e.,

gsub("^.* ([[:di......


-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jttkim at googlemail.com  Tue Jul  9 13:16:07 2013
From: jttkim at googlemail.com (Jan Kim)
Date: Tue, 9 Jul 2013 12:16:07 +0100
Subject: [R] regular expression strikes again
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
Message-ID: <20130709111605.GA31375@LIN-2F308X1>

On Tue, Jul 09, 2013 at 09:45:55AM +0000, PIKAL Petr wrote:
> Dear experts in regexpr.
> 
> I have this
> 
> dput(test[500:510])
> c("pH 9,36 2", "pH 9,36 3", "pH 9,66 1", "pH 9,66 2", "pH 9,66 3", 
> "pH 10,04 1", "pH 10,04 2", "pH 10,04 3", "RGLP 144006 pH 6,13 1", 
> "RGLP 144006 pH 6,13 2", "RGLP 144006 pH 6,13 3")
> 
> and I want something like this
> 
> gsub("^.*([[:digit:]],[[:digit:]]*).*$", "\\1", test[500:510])
>  [1] "9,36" "9,36" "9,66" "9,66" "9,66" "0,04" "0,04" "0,04" "6,13" "6,13"
> [11] "6,13"
> 
> but with 10,04 values instead of 0,04.
> 
> I tried
> gsub("^.*([[:digit:]]+,[[:digit:]]*).*$", "\\1", test[500:510])
> 
> or other variations but without any success.
> 
> Please help.

The "1" in "10,04" is matched by ".*". In your example, all floating
comma numbers you're trying to extract are preceded by "pH ", so
replacing ".*" with ".*pH " should do what you want.

I'd be wary about that variation of having "RGLP 144006" in some
cases, though, it might be better to clean up this rubbish earlier
on (and it would be ideal to never have it generated in the first
place). Regular expressions can be useful to separate some chaff
from the wheat, but relying on that too much comes with a risk of
extracting something that is valid in some syntactic / technical
sense but not correct semantically. If you can't be 100% certain
that the number you want is (1) always preceded by "pH ", (2)
always a floating comma number and (3) will always contain an
integer and a fractional part (i.e. you'll never get ",09" rather
than "0,09", or "10" rather than "10,0"), you have to be prepared
for more difficulties, and you may want to consider a more systematic
approach to parsing your input.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From petr.pikal at precheza.cz  Tue Jul  9 12:19:23 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 9 Jul 2013 10:19:23 +0000
Subject: [R] regular expression strikes again
In-Reply-To: <A137B40C-23BE-4EC8-AE4A-393AC1B6BF07@gmail.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
	<A137B40C-23BE-4EC8-AE4A-393AC1B6BF07@gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE9F@SRVEXCHMBX.precheza.cz>

Thanks, it works to some extent. 

The test comes from some file which is not filled propperly. If I use your suggestion I get correct values for those 2 digit numbers before "," but I get some other values which do not have space before numbers.

> dput(test[c(1:10,500:510)])
c("Cl Tio2 ph 5,8 1", "Cl Tio2 ph 5,8 2", "Cl Tio2 ph 5,8 3", 
"pH5,57 1", "pH5,57 2", "pH5,57 3", "pH4,8 1", "pH4,8 2", "pH4,8 3", 
"pH4,12 1", "pH 9,36 2", "pH 9,36 3", "pH 9,66 1", "pH 9,66 2", 
"pH 9,66 3", "pH 10,04 1", "pH 10,04 2", "pH 10,04 3", "RGLP 144006 pH 6,13 1", 
"RGLP 144006 pH 6,13 2", "RGLP 144006 pH 6,13 3")

> gsub("^.* ([[:digit:]]+,[[:digit:]]*).*$", "\\1", test[c(1:10,500:510)])
 [1] "5,8"      "5,8"      "5,8"      "pH5,57 1" "pH5,57 2" "pH5,57 3"
 [7] "pH4,8 1"  "pH4,8 2"  "pH4,8 3"  "pH4,12 1" "9,36"     "9,36"    
[13] "9,66"     "9,66"     "9,66"     "10,04"    "10,04"    "10,04"   
[19] "6,13"     "6,13"     "6,13"    
>

Basically I would like to get one or two digits before comma and two digits after comma.

Thanks anyway
Petr

> -----Original Message-----
> From: peter dalgaard [mailto:pdalgd at gmail.com]
> Sent: Tuesday, July 09, 2013 11:59 AM
> To: PIKAL Petr
> Cc: r-help
> Subject: Re: [R] regular expression strikes again
> 
> 
> On Jul 9, 2013, at 11:45 , PIKAL Petr wrote:
> 
> > Dear experts in regexpr.
> >
> > I have this
> >
> > dput(test[500:510])
> > c("pH 9,36 2", "pH 9,36 3", "pH 9,66 1", "pH 9,66 2", "pH 9,66 3",
> "pH
> > 10,04 1", "pH 10,04 2", "pH 10,04 3", "RGLP 144006 pH 6,13 1", "RGLP
> > 144006 pH 6,13 2", "RGLP 144006 pH 6,13 3")
> >
> > and I want something like this
> >
> > gsub("^.*([[:digit:]],[[:digit:]]*).*$", "\\1", test[500:510]) [1]
> > "9,36" "9,36" "9,66" "9,66" "9,66" "0,04" "0,04" "0,04" "6,13" "6,13"
> > [11] "6,13"
> >
> > but with 10,04 values instead of 0,04.
> >
> > I tried
> > gsub("^.*([[:digit:]]+,[[:digit:]]*).*$", "\\1", test[500:510])
> >
> > or other variations but without any success.
> >
> 
> 
> Presumably the ^.* is too greedy. Perhaps add a space? I.e.,
> 
> gsub("^.* ([[:di......
> 
> 
> --
> Peter Dalgaard, Professor
> Center for Statistics, Copenhagen Business School Solbjerg Plads 3,
> 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mario.lavezzi at unipa.it  Tue Jul  9 13:19:48 2013
From: mario.lavezzi at unipa.it (A M Lavezzi)
Date: Tue, 9 Jul 2013 13:19:48 +0200
Subject: [R] matching similar character strings
In-Reply-To: <1373115310.24297.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAOZPQW7F3iT4rCP3z2dAJJm32uoBaDmNpPf9tgkruGdBvvNkOw@mail.gmail.com>
	<1371821358.6821.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<51C46C83.4030001@unipa.it>
	<1371828336.16438.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOZPQW6OG7yO_-ssKa+Axr=CsDrJiEaN7SkaCY9RFPz3tLiRyw@mail.gmail.com>
	<1372826855.77040.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOZPQW6Hieh_4zRAnXEs+VD7LM9mjZ=_yXW0XCirhZyhLF-=-w@mail.gmail.com>
	<1373115310.24297.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAOZPQW6WxqzZ4vUpV5+aaT5QKHKis2suEovrhEfDBBN7ueZ19Q@mail.gmail.com>

Dear Arun

below I present the issue in dput(). Sorry for not being able to do it before.

In particular, following your previous suggestions, the databases are
as simplified as possible (all capital letters, the issue odd/even
solved by adding an additional 0-1 variable).

Now F2 contains all possible cases of street definition (there cannot
be overlapping odd or even number intervals), and the examples in F1
should cover all possible cases (there cannot be numbers not included
in any number interval of a given street in F2).

The table "expected" contains the way we would like to add the
variable "SECTION" to the items in F1.

It is not difficult to proceed with the matching through some of the variables:
- F1$Tipo vs F2$STRADA
- F1$Numero vs the interval (F2$NUMBER1, F2$NUMBER2)
- F1$Barrato vs the interval (F2$BARRATO1, F2$BARRATO2)

The problem I am unable to solve is how to compare and match
F1$Indirizzo and F2?$AREADICIRCOLAZIONE

F2?$AREADICIRCOLAZIONE has a regular structure, while F1$Indirizzo has
not. I tried various ways (grep, etc.), with no success.

Thanks for your time and patience, Mario
=============================================================
F1 <-
structure(list(
Nome.azienda = c("Rossi", "Verdi","Bianchi","Viola","Neri","Gialli"),
Tipo = c("VIA","PIAZZA", "V.","VIA","LARGO","VIA"),
Indirizzo = c("E DE AMICIS", "DE AMICIS E.", "DE AMICIS","EDMONDO DE
AMICIS","EUROPA","G. GARIBALDI"),
Numero = c("5","18","65","40","10","5"),
Barrato = c("","","","","D",""),
Odd = c("1","0","1","0","0","1")),
.Names = c("Nome.azienda","Tipo","Indirizzo","Numero","Barrato","Odd"),
class = "data.frame",row.names = c("17","18","19","20","21","22"))

F2 <-
structure(list(
CODICE = c(15620L, 15620L, 15620L, 15620L,
15620L,15620L,15800L,15800L,17450L,17450L,17450L,18000L,18000L),
STRADA = c("VIA", "VIA", "VIA", "VIA", "VIA",
"VIA","PIAZZA","PIAZZA","LARGO","LARGO","LARGO","VIA","VIA"),
AREADICIRCOLAZIONE = c("DE AMICIS EDMONDO", "DE AMICIS EDMONDO",
"DE AMICIS EDMONDO", "DE AMICIS EDMONDO", "DE AMICIS EDMONDO",
"DE AMICIS EDMONDO","DE AMICIS EDMONDO", "DE AMICIS
EDMONDO","EUROPA","EUROPA","EUROPA","GARIBALDI GIUSEPPE","GARIBALDI
GIUSEPPE"),
NUMBER1 = c(1L, 2L, 7L, 36L, 37L, 64L,2L,3L,2L,10L,3L,3L,4L),
BARRATO1 = c("", "", "", "", "", "","","","","B","","",""),
NUMBER2 = c(5L,34L, 17L, 62L, 67L, 84L,20L,25L,10L,30L,37L,13L,26L),
BARRATO2 = c("", "", "", "", "","","","","A","","","",""),
ODD = c("1","0","1","0","1","0","0","1","0","0","1","1","0"),
SECTION = c(1288, 1261, 1287, 1264, 1287,
1262,1500,1505,1510,1520,1530,1610,1615)),
.Names = c("CODICE","STRADA", "AREADICIRCOLAZIONE", "NUMBER1",
"BARRATO1", "NUMBER2","BARRATO2","ODD","SECTION"),
class = "data.frame",row.names = c("1","2", "3", "4", "5",
"6","7","8","9","10","11","12","13"))

expected <-
structure(list(
Nome.azienda = c("Rossi", "Verdi","Bianchi","Viola","Neri","Gialli"),
Tipo = c("VIA","PIAZZA", "V.","VIA","LARGO","VIA"),
Indirizzo = c("E DE AMICIS", "DE AMICIS E.", "DE AMICIS","EDMONDO DE
AMICIS","EUROPA","G. GARIBALDI"),
Numero = c("5","18","65","40","10","5"),
Barrato = c("","","","","D",""),
Odd = c("1","0","1","0","0","1"),
SECTION = c("1288","1500","1287","1264","1520","1610")),
.Names = c("Nome.azienda","Tipo","Indirizzo","Numero","Barrato","Odd","SECTION"),
class = "data.frame",row.names = c("17","18","19","20","21","22"))



On Sat, Jul 6, 2013 at 2:55 PM, arun <smartpink111 at yahoo.com> wrote:
> Dear Mario,
>
> It would be better if you post the examples using dput() and also the expected outcome.  Also, suppose your F1_ex has 65, but F2_ex doesn't have any odd number in that range but only even number from 38 to 72.  In that case, it should return NA? Another possibility is overlapping ranges, using the same example, if there are multiple ranges ex: 37 to 77 and 57 to 67, which one do you use?
>   Arun
>
>
>
>
> ----- Original Message -----
> From: A M Lavezzi <mario.lavezzi at unipa.it>
> To: r-help <r-help at r-project.org>
> Cc:
> Sent: Saturday, July 6, 2013 8:36 AM
> Subject: Re: [R] matching similar character strings
>
> Dear Arun,
>
> thank you so much! The code you suggest captures what we have in mind.
> However, what we are looking for is something a bit more general
> (sorry: I realised that maybe this was not so clear from the
> beginning).
>
> In particular:
>
> - in F1_ex the address in the "Indirizzo" field could be spelled more
> irregularly (ex: "Via De Amicis 18", "V. De Amicis 18", "Via E. De
> Amicis 18", etc.)
>
> - in F2 the classification of the portions of the street is based on
> odd and even numbers. For example, if we had number "15" in F1 it
> should be matched to row 3 and not to row 2 of F2 (I actually provided
> a wrong example with number 65: row 2 of F1_ex is currently matched to
> row 6 of F2_ex which contains even numbers. Moreover, there are no odd
> street numbers in this street higher than 37)
>
> Thank you very much once again
>
> Mario
>
>
> On Wed, Jul 3, 2013 at 6:47 AM, arun <smartpink111 at yahoo.com> wrote:
>> Dear Mario,
>> Not sure if this is what you wanted:
>> F1_ex<- read.table(text="
>>    Nome.azienda;Indirizzo
>> 17;Alterego;Via Edmondo De Amicis, 18
>> 18;Alterego;Via Edmondo De Amicis, 65
>> ",sep=";",header=TRUE,stringsAsFactors=FALSE)
>>
>> F2_ex<- read.table(text="
>>    CODICE;STRADA;AREADICIRCOLAZIONE;NUMBER1;BARRATO1;NUMBER2;BARRATO2;SECTION
>> 1;15620;VIA;DE AMICIS EDMONDO;1;;5;;1288
>> 2;15620;VIA;DE AMICIS EDMONDO;2;;34;;1261
>> 3;15620;VIA;DE AMICIS EDMONDO;7;;17;;1287
>> 4;15620;VIA;DE AMICIS EDMONDO;36;;62;;1264
>> 5;15620;VIA;DE AMICIS EDMONDO;37;;37;;1287
>> 6;15620;VIA;DE AMICIS EDMONDO;64;;84;;1262
>> ",sep=";",header=TRUE,stringsAsFactors=FALSE)
>> library(stringr)
>>  vec1<-sapply(lapply(toupper(str_trim(gsub("[0-9,]","",F1_ex[,2]))),word,c(1,3,4,2)),paste,collapse=" ")
>>  vec2<- as.numeric(gsub("\\D+","",F1_ex[,2]))
>>  F1_ex[,1]<-F2_ex[sapply(vec2,function(x) which((x>F2_ex[,4] & x< F2_ex[,6]) & paste(F2_ex[,2],F2_ex[,3])%in%vec1)),"SECTION"]
>>  F1_ex
>> #   Nome.azienda                 Indirizzo
>> #17         1261 Via Edmondo De Amicis, 18
>> #18         1262 Via Edmondo De Amicis, 65
>> A.K.
>>
>>
>>
>>
>>
>> ----- Original Message -----
>> From: A M Lavezzi <mario.lavezzi at unipa.it>
>> To: r-help <r-help at r-project.org>
>> Cc:
>> Sent: Tuesday, July 2, 2013 10:22 AM
>> Subject: Re: [R] matching similar character strings
>>
>> Dear Arun,
>> please excuse me for this late reply, we had to stop working on this
>> temporaririly.
>>
>> Let me reproduce here two examples of rows from F1 and F2 (sorry, but
>> with dput() I am not able to produce a clear example)
>>
>>> F1_ex
>>         Nome.azienda                   Indirizzo
>> 17     Alterego             Via Edmondo De Amicis, 18
>>
>> On row 17 of F1 we have a firm named ("Nome.azienda") 'Alterego' whose
>> address ("indirizzo") is  'Via Edmondo de Amicis, 18'
>>
>> Below I reproduce the portion of F2 with information on the street
>> mentioned in F1_ex$Indirizzo.
>>
>>> F2_ex
>>
>>   CODICE    STRADA       AREADICIRCOLAZIONE          NUMBER1 BARRATO1
>> NUMBER2 BARRATO2 SECTION
>> 1  15620        VIA            DE AMICIS EDMONDO                     1
>>                           5                                 1288
>> 2  15620        VIA            DE AMICIS EDMONDO                     2
>>                          34                                 1261
>> 3  15620        VIA            DE AMICIS EDMONDO                     7
>>                          17                                 1287
>> 4  15620        VIA            DE AMICIS EDMONDO                    36
>>                          62                                1264
>> 5  15620        VIA            DE AMICIS EDMONDO                    37
>>                          37                                1287
>> 6  15620        VIA            DE AMICIS EDMONDO                    64
>>                          84                                1262
>>
>>
>> Line 1 says that the portion of VIA DE AMICIS EDMONDO
>> ("STRADA"+"AREADICIRCOLAZIONE"), with street numbers between 1 and 5
>> belongs to SECTION 1288 (these are census sections). ("BARRATO1" and
>> "BARRATO2" refer to the letter in street numbers such as 12/A, 28/D,
>> etc. In the present example they are empty)
>>
>> Line 2 says that the portion of VIA DE AMICIS EDMONDO, with street
>> numbers between 2 and 34 belongs to SECTION 1261,
>>
>> etc.
>>
>> Our problem is to assign SECTION 1261 to 'Alterego', exploting the
>> information on its address. The problem is that the syntax of the
>> street address in F1 is different from the syntax in F2.
>>
>> Hope I have clarified the issue
>>
>> thanks a lot
>> Mario
>>
>>
>>
>>
>>
>>
>>
>>
>> On Fri, Jun 21, 2013 at 5:25 PM, arun <smartpink111 at yahoo.com> wrote:
>>> Dear Mario,
>>> I didn't find any difference between 1st and 2nd row of F2, except for the last three columns.  Question is that why should F1 1st row should be merged to 2nd row of F2 instead of 1st row of F2. In your previous example, you mentioned about A1, A2, ... and B1, B2, etc.  Here, it is not provided.  As I mentioned before, it is better to provide the output of ?dput() from a subset of dataset.
>>> dput(head(F1,20))
>>>
>>> dput(head(F2,20))
>>>
>>> #so that there would be atleast some matching pairs within the example dataset.  Also, please post it to r-help as I will be able to check only after a couple of hours
>>> Tx.
>>> Arun
>>>
>>>
>>>
>>> ----- Original Message -----
>>> From: Mario Lavezzi <mario.lavezzi at unipa.it>
>>> To: arun <smartpink111 at yahoo.com>
>>> Cc:
>>> Sent: Friday, June 21, 2013 11:08 AM
>>> Subject: Re: [R] matching similar character strings
>>>
>>> dear Arun
>>> thank you very much. Let me explain the problem:
>>>
>>> Imagine that a portion of the row in F1 is:
>>>
>>> ----------------------------
>>> F1
>>>
>>> 1) Street | J.F. Kennedy | 30
>>> ----------------------------
>>>
>>> it means that our unit of interest (a firm) has address: J.F. Kennedy Street, 30
>>>
>>>
>>> The F2 database contains the list of all the streets of the city, with additional variables characterizing that street (Census data). The database
>>> contains sometimes street divided in some parts, according to the street number. For example:
>>>
>>>
>>> Example of three rows of F2 concerning Kennedy street and Kennedy Road:
>>>
>>> F2
>>>
>>> 1) Street | Kennedy John Fitzgerald  | 1  | 20 | A12
>>> 2) Street | Kennedy John Fitzgerald  | 20 | 50 | A15
>>> 3) Road   | Kennedy John             | 1  | 50 | A23
>>>
>>>
>>> We'd like to have an algorithm able to understand that, notwithstanding the name is slightly different, element A15 should be added to row 1) of F1,
>>> producing an output such as:
>>>
>>> 1) Street | J.F. Kennedy | 30 | A15
>>>
>>>
>>> hope this clarifies the issue.
>>>
>>> thanks a lot! Mario
>>>
>>>
>>>
>>> Il 21/06/2013 15:29, arun ha scritto:
>>>> HI,
>>>> Could you dput() your example datasets and also your expected result?  The Census section is not clear.
>>>> A.K.
>>>>
>>>>
>>>>
>>>>
>>>> ----- Original Message -----
>>>> From: A M Lavezzi <mario.lavezzi at unipa.it>
>>>> To: r-help <r-help at r-project.org>
>>>> Cc:
>>>> Sent: Friday, June 21, 2013 5:56 AM
>>>> Subject: [R] matching similar character strings
>>>>
>>>> Hello everybody
>>>>
>>>> I have this problem: I need to match an addresses database F1 with the
>>>> information contained in a toponymic database F2.
>>>>
>>>> The format of F1 is given by three columns and 800 rows, with the
>>>> columns being:
>>>>
>>>> A1. Street/Road/Avenue
>>>> A2. Name
>>>> A3. Number
>>>>
>>>> Consider for instance Avenue J. Kennedy , 3011. In F1 this is:
>>>>
>>>> A1. Avenue
>>>> A2. J. Kennedy
>>>> A3. 3011
>>>>
>>>> The format of F2 file is instead given by 20000 rows and five columns:
>>>>
>>>> B1. Street/Road/Avenue
>>>> B2. Name
>>>> B3. Starting Street Number
>>>> B4. Ending Street Number
>>>> B5. Census section
>>>>
>>>> So my problem is attributing the  B5 Census section to every
>>>> observation of F1 if: A1=B1, A2=B2, and A3 is comprised between B3 and
>>>> B4.
>>>>
>>>> The problem is that while the information in A2 is irregularly
>>>> recorded, B2 has a given format that is Family name (space) Given
>>>> name.
>>>>
>>>> So I could have that while in B2 the information is:
>>>>
>>>> Kennedy John
>>>>
>>>> In A2 it could be:
>>>>
>>>> John Kennedy
>>>> JF Kennedy
>>>> J. Kennedy
>>>>
>>>> and so on.
>>>>
>>>> Thanks,
>>>>
>>>> Mario
>>>>
>>>
>>> --
>>> PLEASE NOTICE NEW EMAIL ADDRESS AND HOME PAGE URL
>>>
>>> Andrea Mario Lavezzi
>>> Dipartimento di Studi su Politica, Diritto e Societ?
>>> Universit? di Palermo
>>> Piazza Bologni 8
>>> 90134 Palermo, Italy
>>> tel. ++39 091 23892208
>>> fax ++39 091 6111268
>>> skype: lavezzimario
>>> email: mario.lavezzi (at) unipa.it
>>> web: http://www.unipa.it/~mario.lavezzi
>>
>>
>>
>> --
>> Andrea Mario Lavezzi
>> Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
>> Sezione Diritto e Societ?
>> Universit? di Palermo
>> Piazza Bologni 8
>> 90134 Palermo, Italy
>> tel. ++39 091 23892208
>> fax ++39 091 6111268
>> skype: lavezzimario
>> email: mario.lavezzi (at) unipa.it
>> web: http://www.unipa.it/~mario.lavezzi
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Andrea Mario Lavezzi
> Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
> Sezione Diritto e Societ?
> Universit? di Palermo
> Piazza Bologni 8
> 90134 Palermo, Italy
> tel. ++39 091 23892208
> fax ++39 091 6111268
> skype: lavezzimario
> email: mario.lavezzi (at) unipa.it
> web: http://www.unipa.it/~mario.lavezzi
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Andrea Mario Lavezzi
Dipartimento di Scienze Giuridiche, della Societ? e dello Sport
Sezione Diritto e Societ?
Universit? di Palermo
Piazza Bologni 8
90134 Palermo, Italy
tel. ++39 091 23892208
fax ++39 091 6111268
skype: lavezzimario
email: mario.lavezzi (at) unipa.it
web: http://www.unipa.it/~mario.lavezzi


From careyshan at gmail.com  Tue Jul  9 13:20:32 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 9 Jul 2013 12:20:32 +0100
Subject: [R] Labelling
Message-ID: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/7b74e811/attachment.pl>

From smriti.sebastuan at gmail.com  Tue Jul  9 12:13:15 2013
From: smriti.sebastuan at gmail.com (smriti Sebastian)
Date: Tue, 9 Jul 2013 15:43:15 +0530
Subject: [R] find 2D corelation coefficient
In-Reply-To: <59080B21-B285-4013-987D-F13BB49B6116@gmail.com>
References: <CAKpT9Hsah7xvoca7kvRxFwGAxnvG_r_hLgGFiJWx63J4MT-Wgw@mail.gmail.com>
	<59080B21-B285-4013-987D-F13BB49B6116@gmail.com>
Message-ID: <CAKpT9Ht4RUhMdYdNht1ed=nhXq-eoF=qa5V97Lada34+CjCoLw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/28d22f32/attachment.pl>

From alok.jadhav at credit-suisse.com  Tue Jul  9 11:41:38 2013
From: alok.jadhav at credit-suisse.com (Jadhav, Alok)
Date: Tue, 9 Jul 2013 17:41:38 +0800
Subject: [R] Sending carbon copy mails from R
Message-ID: <CEE8C35195DB944D9C75ABB15A04193B24CA5961@EHKG17P32001A.csfb.cs-group.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/f5f6b1d3/attachment.pl>

From pdalgd at gmail.com  Tue Jul  9 13:50:14 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 9 Jul 2013 13:50:14 +0200
Subject: [R] regular expression strikes again
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE9F@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
	<A137B40C-23BE-4EC8-AE4A-393AC1B6BF07@gmail.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE9F@SRVEXCHMBX.precheza.cz>
Message-ID: <6792F694-C63C-4F37-97B9-A455E5178F03@gmail.com>


On Jul 9, 2013, at 12:19 , PIKAL Petr wrote:

> Thanks, it works to some extent. 
> 
> The test comes from some file which is not filled propperly. If I use your suggestion I get correct values for those 2 digit numbers before "," but I get some other values which do not have space before numbers.
> 
>> dput(test[c(1:10,500:510)])
> c("Cl Tio2 ph 5,8 1", "Cl Tio2 ph 5,8 2", "Cl Tio2 ph 5,8 3", 
> "pH5,57 1", "pH5,57 2", "pH5,57 3", "pH4,8 1", "pH4,8 2", "pH4,8 3", 
> "pH4,12 1", "pH 9,36 2", "pH 9,36 3", "pH 9,66 1", "pH 9,66 2", 
> "pH 9,66 3", "pH 10,04 1", "pH 10,04 2", "pH 10,04 3", "RGLP 144006 pH 6,13 1", 
> "RGLP 144006 pH 6,13 2", "RGLP 144006 pH 6,13 3")
> 
>> gsub("^.* ([[:digit:]]+,[[:digit:]]*).*$", "\\1", test[c(1:10,500:510)])
> [1] "5,8"      "5,8"      "5,8"      "pH5,57 1" "pH5,57 2" "pH5,57 3"
> [7] "pH4,8 1"  "pH4,8 2"  "pH4,8 3"  "pH4,12 1" "9,36"     "9,36"    
> [13] "9,66"     "9,66"     "9,66"     "10,04"    "10,04"    "10,04"   
> [19] "6,13"     "6,13"     "6,13"    
>> 
> 
> Basically I would like to get one or two digits before comma and two digits after comma.

Then maybe

> gsub("^.*[^[:digit:]]([[:digit:]]+,[[:digit:]]*).*$", "\\1", x)
 [1] "5,8"   "5,8"   "5,8"   "5,57"  "5,57"  "5,57"  "4,8"   "4,8"   "4,8"  
[10] "4,12"  "9,36"  "9,36"  "9,66"  "9,66"  "9,66"  "10,04" "10,04" "10,04"
[19] "6,13"  "6,13"  "6,13" 

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From careyshan at gmail.com  Tue Jul  9 13:51:04 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 9 Jul 2013 12:51:04 +0100
Subject: [R] Labelling- I figured it out
Message-ID: <CA+jRDxB4AnGga5kbgTLSLOU9ezoByVpVsw-gLavWXDJuAyYf1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/794cf273/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul  9 14:05:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 9 Jul 2013 05:05:35 -0700 (PDT)
Subject: [R] regular expression strikes again
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
Message-ID: <1373371535.34224.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this helps:

? gsub(".*\\w+\\s+(.*)\\s+.*","\\1",test)
?#[1] "9,36"? "9,36"? "9,66"? "9,66"? "9,66"? "10,04" "10,04" "10,04" "6,13" 
#[10] "6,13"? "6,13" 

A.K.

----- Original Message -----
From: PIKAL Petr <petr.pikal at precheza.cz>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 9, 2013 5:45 AM
Subject: [R] regular expression strikes again

Dear experts in regexpr.

I have this

dput(test[500:510])
c("pH 9,36 2", "pH 9,36 3", "pH 9,66 1", "pH 9,66 2", "pH 9,66 3", 
"pH 10,04 1", "pH 10,04 2", "pH 10,04 3", "RGLP 144006 pH 6,13 1", 
"RGLP 144006 pH 6,13 2", "RGLP 144006 pH 6,13 3")

and I want something like this

gsub("^.*([[:digit:]],[[:digit:]]*).*$", "\\1", test[500:510])
[1] "9,36" "9,36" "9,66" "9,66" "9,66" "0,04" "0,04" "0,04" "6,13" "6,13"
[11] "6,13"

but with 10,04 values instead of 0,04.

I tried
gsub("^.*([[:digit:]]+,[[:digit:]]*).*$", "\\1", test[500:510])

or other variations but without any success.

Please help.

Regards
Petr

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jvadams at usgs.gov  Tue Jul  9 14:28:15 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 9 Jul 2013 07:28:15 -0500
Subject: [R] Labelling
In-Reply-To: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>
References: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>
Message-ID: <CAN5YmCEvZ8JFsRcSyM=uLXcox7D+kRmQHV8S58hEJHP_rzv-iA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/964b50ba/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul  9 14:48:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 9 Jul 2013 05:48:26 -0700 (PDT)
Subject: [R] Labelling
In-Reply-To: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>
References: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>
Message-ID: <1373374106.29337.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
May be this helps:

?gsub("_"," ",gsub("(.*)_.*","\\1",DATA_names))
#[1] "A ugkg"? "S mgkg"? "Cl mgkg"
sapply(gsub("_"," ",gsub("(.*)_.*","\\1",DATA_names)),f)
$`A ugkg`
A ~ (mu * g ~ kg^{
??? -1
})

$`S mgkg`
S ~ (mg ~ kg^{
??? -1
})

$`Cl mgkg`
Cl ~ (mg ~ kg^{
??? -1
})


A.K.

----- Original Message -----
From: Shane Carey <careyshan at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 9, 2013 7:20 AM
Subject: [R] Labelling

Hi,

I have the following data as labels:

DATA_names<-c("A_ugkg_FA","S_mgkg_XRF" ,"Cl_mgkg_XR")

and I need to convert to


? ? ? ? ? ?  -1
A (ug kg? ?  )

? ? ? ? ? ?  -1
S (mg kg? ? )

? ? ? ? ? ? ? -1
Cl (mg kg? ? )


I used the following piece of code to convert the following labels in the
past, but cant get it to work for the new labels:

f <- function (name)
{
? # add other suffices and their corresponding plotmath expressions to the
list
? env <- list2env(list(mgkg = bquote(mg ~ kg^{-1}),
? ? ? ? ? ? ? ? ? ? ?  ugkg = bquote(mu * g ~ kg^{-1})),
? ? ? ? ? ? ? ? ? parent = emptyenv())
? pattern <- paste0("(", paste(objects(env), collapse="|"), ")")
? bquoteExpr <- parse(text=gsub(pattern,
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "~(.(\\1))",
? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? name))[[1]]
? # I use do.call() to work around the fact that bquote's first argument is
not evaluated.
? do.call(bquote, list(bquoteExpr, env))
}

The labels in the past were:
DATA_names<-c("A_ugkg","S_mgkg" ,"Cl_mgkg")

Thanks

-- 
Shane

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From careyshan at gmail.com  Tue Jul  9 14:57:00 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 9 Jul 2013 13:57:00 +0100
Subject: [R] Labelling
In-Reply-To: <1373374106.29337.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>
	<1373374106.29337.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CA+jRDxAY5CHCH=7mJ=vFZk=T1xOp6ZPEWPDG6xjAdvfWPogTig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/c73b8e46/attachment.pl>

From jvadams at usgs.gov  Tue Jul  9 14:16:20 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 9 Jul 2013 07:16:20 -0500
Subject: [R] fitting log function: errors using nls and nlxb
In-Reply-To: <CAJ4DX-tLSWE7EdC49o0X3OkpGn=8uCX_q31237MGrD7HM1-ZRA@mail.gmail.com>
References: <CAJ4DX-tLSWE7EdC49o0X3OkpGn=8uCX_q31237MGrD7HM1-ZRA@mail.gmail.com>
Message-ID: <CAN5YmCF_=gxNxCz2hbvO8DjkLNBOrUeef3dLaG+OtFC3ts5aeA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/8156d035/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul  9 15:36:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 9 Jul 2013 06:36:58 -0700 (PDT)
Subject: [R] Labelling
In-Reply-To: <CA+jRDxAY5CHCH=7mJ=vFZk=T1xOp6ZPEWPDG6xjAdvfWPogTig@mail.gmail.com>
References: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>
	<1373374106.29337.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CA+jRDxAY5CHCH=7mJ=vFZk=T1xOp6ZPEWPDG6xjAdvfWPogTig@mail.gmail.com>
Message-ID: <1373377018.6835.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try this:
f1<- function(name)
{
env <- list2env(list(mgkg = bquote(mg ~ kg^{-1}),
????????????????????? ugkg = bquote(mu * g ~ kg^{-1})),
??? ??? parent = emptyenv())
pattern <- paste0("(", paste(objects(env), collapse="|"), ")")??? 
bquoteExpr<-parse(text=gsub("_"," ",gsub(pattern,"~(.(\\1))~",name)))[[1]]
do.call(bquote, list(bquoteExpr, env))
}
sapply(DATA_names,f1)
$A_ugkg_FA
A ~ (mu * g ~ kg^{
??? -1
}) ~ FA

$S_mgkg_XRF
S ~ (mg ~ kg^{
??? -1
}) ~ XRF

$Cl_mgkg_XR
Cl ~ (mg ~ kg^{
??? -1
}) ~ XR

A.K.






________________________________
From: Shane Carey <careyshan at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org> 
Sent: Tuesday, July 9, 2013 8:57 AM
Subject: Re: [R] Labelling



Initially, I wanted to remove the suffixes, but now I want to end up with the following?

c("A_ugkg_FA","S_mgkg_XRF" ,"Cl_mgkg_XR")


? ? ? ? ? ? ?-1
A (ug kg ? ?) FA


? ? ? ? ? ? ?-1
S (mg kg ? ) XRF


? ? ? ? ? ? ? -1
Cl (mg kg ? ) XR

Thanks all



On Tue, Jul 9, 2013 at 1:48 PM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>May be this helps:
>
>?gsub("_"," ",gsub("(.*)_.*","\\1",DATA_names))
>#[1] "A ugkg"? "S mgkg"? "Cl mgkg"
>sapply(gsub("_"," ",gsub("(.*)_.*","\\1",DATA_names)),f)
>$`A ugkg`
>A ~ (mu * g ~ kg^{
>??? -1
>})
>
>$`S mgkg`
>S ~ (mg ~ kg^{
>??? -1
>})
>
>$`Cl mgkg`
>Cl ~ (mg ~ kg^{
>??? -1
>})
>
>
>A.K.
>
>
>----- Original Message -----
>From: Shane Carey <careyshan at gmail.com>
>To: "r-help at r-project.org" <r-help at r-project.org>
>Cc:
>Sent: Tuesday, July 9, 2013 7:20 AM
>Subject: [R] Labelling
>
>Hi,
>
>I have the following data as labels:
>
>DATA_names<-c("A_ugkg_FA","S_mgkg_XRF" ,"Cl_mgkg_XR")
>
>and I need to convert to
>
>
>? ? ? ? ? ? ?-1
>A (ug kg? ? ?)
>
>? ? ? ? ? ? ?-1
>S (mg kg? ? )
>
>? ? ? ? ? ? ? -1
>Cl (mg kg? ? )
>
>
>I used the following piece of code to convert the following labels in the
>past, but cant get it to work for the new labels:
>
>f <- function (name)
>{
>? # add other suffices and their corresponding plotmath expressions to the
>list
>? env <- list2env(list(mgkg = bquote(mg ~ kg^{-1}),
>? ? ? ? ? ? ? ? ? ? ? ?ugkg = bquote(mu * g ~ kg^{-1})),
>? ? ? ? ? ? ? ? ? parent = emptyenv())
>? pattern <- paste0("(", paste(objects(env), collapse="|"), ")")
>? bquoteExpr <- parse(text=gsub(pattern,
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? "~(.(\\1))",
>? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? name))[[1]]
>? # I use do.call() to work around the fact that bquote's first argument is
>not evaluated.
>? do.call(bquote, list(bquoteExpr, env))
>}
>
>The labels in the past were:
>DATA_names<-c("A_ugkg","S_mgkg" ,"Cl_mgkg")
>
>Thanks
>
>--
>Shane
>
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


-- 
Shane


From jvadams at usgs.gov  Tue Jul  9 15:35:30 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 9 Jul 2013 08:35:30 -0500
Subject: [R] fitting log function: errors using nls and nlxb
In-Reply-To: <CAJ4DX-sUhSdDQ_-ay0sugzNbJYxLOvrYfKg9eoTmFiNrucrFbg@mail.gmail.com>
References: <CAJ4DX-tLSWE7EdC49o0X3OkpGn=8uCX_q31237MGrD7HM1-ZRA@mail.gmail.com>
	<CAN5YmCF_=gxNxCz2hbvO8DjkLNBOrUeef3dLaG+OtFC3ts5aeA@mail.gmail.com>
	<CAJ4DX-sUhSdDQ_-ay0sugzNbJYxLOvrYfKg9eoTmFiNrucrFbg@mail.gmail.com>
Message-ID: <CAN5YmCEkZVRruou=34GN1YFnhkgEfUxLTezbG9++uL-1O8QZXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/4e9732b8/attachment.pl>

From jim at mail.bitwrit.com.au  Tue Jul  9 14:03:32 2013
From: jim at mail.bitwrit.com.au (Jim Lemon)
Date: Tue, 9 Jul 2013 22:03:32 +1000 (EST)
Subject: [R] Complex Association Plots
In-Reply-To: <CA+RDsenEhBQ7RsbEYsuLfStLj4H=eD99usASxeZAE5iKMkgc5w@mail.gmail.com>
References: <CA+RDsenEhBQ7RsbEYsuLfStLj4H=eD99usASxeZAE5iKMkgc5w@mail.gmail.com>
Message-ID: <41524.64.134.162.190.1373371412.squirrel@www.bitwrit.com.au>

Hi Olga,
One possibility is a nested bar plot of proportions. This can be done with
the barNest function in the plotrix package. Check the Titanic example.

Jim

> I'm new to R plotting, so please be gentle.
>
> I want to make a large association plot, showing whether each combination
> of variables averages more or less than the whole for proportion in a
> certain category.
>
> So, for example:
>
> Dependent Variable: eye color (30% green, 45% brown, 25% blue on average)
>
> Independent Variables: hair color, skin color, hair type
>
> How would I generate a block for each of those combinations of variables
> and show the average distribution of eye color compared to the average?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From gunter.berton at gene.com  Tue Jul  9 15:51:45 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 9 Jul 2013 06:51:45 -0700
Subject: [R] fitting log function: errors using nls and nlxb
In-Reply-To: <CAN5YmCEkZVRruou=34GN1YFnhkgEfUxLTezbG9++uL-1O8QZXw@mail.gmail.com>
References: <CAJ4DX-tLSWE7EdC49o0X3OkpGn=8uCX_q31237MGrD7HM1-ZRA@mail.gmail.com>
	<CAN5YmCF_=gxNxCz2hbvO8DjkLNBOrUeef3dLaG+OtFC3ts5aeA@mail.gmail.com>
	<CAJ4DX-sUhSdDQ_-ay0sugzNbJYxLOvrYfKg9eoTmFiNrucrFbg@mail.gmail.com>
	<CAN5YmCEkZVRruou=34GN1YFnhkgEfUxLTezbG9++uL-1O8QZXw@mail.gmail.com>
Message-ID: <CACk-te2XKVveMCzMbTfm2-=YvQQuK+txpnRdQFAQ=YRGZ1z0kQ@mail.gmail.com>

1. This is a statistical, not an R issue. So I am keeping this offlist.

2. Without a prior family of  models, you should **not** be fitting a
parametric nonlinear model.

3. An interpolating smooth is what is wanted. FIt one (e.g. splines,
kernel smooth, etc.)

4. You are out of your depth statistically, Elizabeth. FInd someone
local to work with.

Cheers,
Bert

On Tue, Jul 9, 2013 at 6:35 AM, Adams, Jean <jvadams at usgs.gov> wrote:
> Elizabeth,
>
> You should cc rhelp on all correspondence so other readers can follow the
> thread of conversation.
>
> Now that I have some data to play with, I see where I went wrong in my
> previous e-mail.
>
> First of all, you can't fit a model
>      CO2 ~ log(a*Time) + b
> because log(a*Time) can be rewritten as log(a) + log(Time) and there's no
> way that the two parameters, log(a) and b, can be uniquely estimated.
>
> You could change your model to
>      CO2 ~ a*log(Time) + b
> I did this and fit the model using both the base 10 and base e logs ...
> same result.  So the base of the logs doesn't matter.  However, this model
> doesn't do a great job of fitting the curve.
>
> I tried another model
>      CO2 ~ a*(1-exp(-b*Time))
> which seemed to do better.  Still not great, though.  So, I tried it with
> one more parameter
>     CO2 ~ c + a*(1-exp(-b*Time))
> and that improved it further.
>
> Jean
>
>
> fit1 <- nls(CO2 ~ a*log(Time) + b, start=c(a=68, b=400), data=FG2)
> plot(FG2$Time, FG2$CO2)
> lines(FG2$Time, predict(fit1), col="red")
>
> fit2 <- nls(CO2 ~ a*log10(Time) + b, start=c(a=68, b=400), data=FG2)
> lines(FG2$Time, predict(fit1), col="blue", lty=2, lwd=2)
>
> fit3 <- nls(CO2 ~ a*(1-exp(-b*Time)), start=c(a=500, b=0.03), data=FG2)
> lines(FG2$Time, predict(fit3), col="green", lwd=2)
>
> fit4 <- nls(CO2 ~ c + a*(1-exp(-b*Time)), start=c(a=500, b=0.03, c=0),
> data=FG2)
> lines(FG2$Time, predict(fit4), col="brown", lwd=2)
>
>
>
>
>
> On Tue, Jul 9, 2013 at 8:10 AM, Elizabeth Webb
> <webb.elizabeth.e at gmail.com>wrote:
>
>> Hi Jean-
>> Thanks for responding.  Below I have provided dput(FG2[1:50, ]).  I have
>> also attached a graph of my data.
>> Thanks for the hint on working a third parameter into my model.  I will
>> certainly try that once I get the model working.
>> Elizabeth
>>
>> dput(FG2[1:50, ])
>> structure(list(CO2 = c(383.29, 392, 394.38, 392.85, 413.14, 394.56,
>> 405.83, 409.61, 408.15, 412.63, 414.62, 423.19, 422.39, 426.81,
>> 433.34, 433.95, 438.02, 438.21, 442.84, 441.81, 444.09, 444.59,
>> 446.35, 447.11, 450.03, 452.03, 452.69, 453.7, 455.17, 456.65,
>> 458.72, 458.88, 459.25, 459.88, 464.06, 461.34, 464.66, 465.19,
>> 466.96, 466.86, 468.41, 469.49, 471.08, 471.61, 472.95, 473.94,
>> 474.63, 475.79, 477.07, 476.53), Time = c(53, 54, 55, 56, 57,
>> 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73,
>> 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89,
>> 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102)), .Names = c("CO2",
>> "Time"), row.names = c(NA, 50L), class = "data.frame")
>>
>>
>> On Tue, Jul 9, 2013 at 4:16 AM, Adams, Jean <jvadams at usgs.gov> wrote:
>>
>>> Elizabeth,
>>>
>>> It's difficult to troubleshoot without the data.  Could you provide the
>>> output from
>>>      dput(FG2)
>>> or if your data set is quite large, perhaps
>>>      dput(FG2[1:50, ])
>>>
>>> If you want to fit a third parameter to represent the base of the log,
>>> you could use
>>>      nls(CO2 ~ log(a*Time) / log(c) + b, start=c(a=68, b=400, c=10),
>>> data=FG2)
>>> where c represents the base of the log in this relation:
>>> CO2 = log_c(a*Time) + b
>>>
>>> Jean
>>>
>>>
>>>
>>>
>>> On Mon, Jul 8, 2013 at 9:27 PM, Elizabeth Webb <
>>> webb.elizabeth.e at gmail.com> wrote:
>>>
>>>> Hi-
>>>> I am trying to fit a log function to my data, with the ultimate goal of
>>>> finding the second derivative of the function.  However, I am stalled on
>>>> the first step of fitting a curve.
>>>>
>>>> When I use the following code:
>>>> FG2.model<-(nls((CO2~log(a*Time)+b), start=setNames(coef(lm(CO2 ~
>>>> log(Time), data=FG2)), c("a", "b")),data=FG2))
>>>> I get the following error:
>>>> Error in numericDeriv(form[[3L]], names(ind), env) :
>>>>   Missing value or an infinity produced when evaluating the model
>>>> In addition: Warning messages:
>>>> 1: In min(x) : no non-missing arguments to min; returning Inf
>>>> 2: In max(x) : no non-missing arguments to max; returning -Inf
>>>> 3: In log(a * Time) : NaNs produced
>>>> 4: In log(a * Time) : NaNs produced
>>>>
>>>> When I fit the curve in Plot and use the coefficients as starting values:
>>>> start=c(a=68,b=400)
>>>> FG2.model<-(nls((CO2~log(a*Time)+b), start=start,data=FG2))
>>>> I get the following error:
>>>> Error in nls((CO2 ~ log(a * Time) + b), start = start, data = FG2) :
>>>>   singular gradient
>>>> In addition: Warning messages:
>>>> 1: In min(x) : no non-missing arguments to min; returning Inf
>>>> 2: In max(x) : no non-missing arguments to max; returning -Inf
>>>>
>>>> So then when I substituded nlxb for nls in the above two models, I got
>>>> this
>>>> error:
>>>> Error in nlxb((CO2 ~ log(a * Time) + b), start = start, data = FG2) :
>>>>   NaN in Jacobian
>>>>
>>>>
>>>> A few questions:
>>>> 1.) How can I get R to fit my curve without returning errors?
>>>>
>>>> 2.) I am not sure that this data is log base 10.  Is there a way I can
>>>> ask
>>>> R to try for logs of different functions?  For example,
>>>>
>>>> FG2.model<-(nlxb((CO2~log(a*Time,c)+b), start=start,data=FG2)), where c
>>>> is
>>>> an additional variable.  When I try this, R tells me Non-numeric argument
>>>> to mathematical function
>>>>
>>>> Thank you in advance,
>>>> Elizabeth
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From careyshan at gmail.com  Tue Jul  9 16:03:03 2013
From: careyshan at gmail.com (Shane Carey)
Date: Tue, 9 Jul 2013 15:03:03 +0100
Subject: [R] Labelling
In-Reply-To: <1373377018.6835.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CA+jRDxC9psJuZJVuP=-KHfCQn_WT8w4OHB=jzmBSc=zuAWRXwg@mail.gmail.com>
	<1373374106.29337.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CA+jRDxAY5CHCH=7mJ=vFZk=T1xOp6ZPEWPDG6xjAdvfWPogTig@mail.gmail.com>
	<1373377018.6835.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CA+jRDxBc0O8k=Z3+kqSmZpXup10cQ5uEuaCyu1pc7zzEmNpkXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/1b2e2c31/attachment.pl>

From jrkrideau at inbox.com  Tue Jul  9 16:46:32 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 9 Jul 2013 06:46:32 -0800
Subject: [R] A question on the abline function
In-Reply-To: <0F1A1373F93B1C44ABC51B71BC757E6327BB2614@EXNJMB21.nam.nsroot.net>
Message-ID: <A872E7A602D.00000149jrkrideau@inbox.com>

https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: jia2.xu at citi.com
> Sent: Mon, 8 Jul 2013 12:45:03 +0000
> To: r-help at r-project.org
> Subject: [R] A question on the abline function
> 
> Dear whom it may concerns,
> 
> I am Jia Xu, a summer intern analyst at Citi Research. I am also a
> graduate student studying Financial Engineering at Cornell. I am running
> regression analysis with Rstudio now. I have been experiencing difficulty
> with the abline function. No matter I call it directly in linear
> regression or call it through residual plots, or plot results from lasso
> regression, it produces the same error as the following:
> 
> Error in int_abline(a = a, b = b, h = h, v = v, untf = untf, ...) :
>   object 'C_abline' not found
> 
> Could you please help me check what is this problem?
> 
> Thanks for your time!
> 
> Best,
> 
> Jia Xu
> 
> Citi Research
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From NordlDJ at dshs.wa.gov  Tue Jul  9 18:14:59 2013
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Tue, 9 Jul 2013 16:14:59 +0000
Subject: [R] find 2D corelation coefficient
In-Reply-To: <CAKpT9Ht4RUhMdYdNht1ed=nhXq-eoF=qa5V97Lada34+CjCoLw@mail.gmail.com>
References: <CAKpT9Hsah7xvoca7kvRxFwGAxnvG_r_hLgGFiJWx63J4MT-Wgw@mail.gmail.com>
	<59080B21-B285-4013-987D-F13BB49B6116@gmail.com>
	<CAKpT9Ht4RUhMdYdNht1ed=nhXq-eoF=qa5V97Lada34+CjCoLw@mail.gmail.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27660F994F89@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of smriti Sebastian
> Sent: Tuesday, July 09, 2013 3:13 AM
> To: peter dalgaard
> Cc: r-help at r-project.org
> Subject: Re: [R] find 2D corelation coefficient
> 
> Two dimensional corelation coefficient-2D corelation between (x,y) and
> (x1,y1) where x and x1 are same.
> 
> 
> On Tue, Jul 9, 2013 at 2:27 PM, peter dalgaard <pdalgd at gmail.com>
> wrote:
> 
> >
> > On Jul 9, 2013, at 07:30 , smriti Sebastian wrote:
> >
> > > I need to find the 2d corelation betwee two datasets which are
> having
> > > common x-values.Is there any way to find 2D corelation in R?
> >
> >
> > If you can tell us what the definition is....
> >
> > --
> > Peter Dalgaard, Professor
> > Center for Statistics, Copenhagen Business School
> > Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> > Phone: (+45)38153501
> > Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> >
> >
> 

You still haven't defined what you mean by "2D correlation."  Can you define it, or point to some online source which describes/defines it?

Dan

Daniel J. Nordlund
Washington State Department of Social and Health Services
Planning, Performance, and Accountability
Research and Data Analysis Division
Olympia, WA 98504-5204


From jholtman at gmail.com  Tue Jul  9 18:33:18 2013
From: jholtman at gmail.com (jim holtman)
Date: Tue, 9 Jul 2013 12:33:18 -0400
Subject: [R] regular expression strikes again
In-Reply-To: <1373371535.34224.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE42@SRVEXCHMBX.precheza.cz>
	<1373371535.34224.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAAxdm-6m2Bd4GNC4Fq-Q=KMKZUqY-T6h1Mxo9pP-KTjo-N1UTQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/2b8716d2/attachment.pl>

From rshepard at appl-ecosys.com  Tue Jul  9 18:32:41 2013
From: rshepard at appl-ecosys.com (Rich Shepard)
Date: Tue, 9 Jul 2013 09:32:41 -0700 (PDT)
Subject: [R] Applying PLS-PM to Environmental Regulations
Message-ID: <alpine.LNX.2.00.1307090930080.2395@salmo.appl-ecosys.com>

   Since I posted this a couple of weeks ago on r-sig-networks there has been
neither a response nor any other posts to that mail list so I'm reposting it
here in my quest for assistance with the proper application of plspm for my
need as described below.

   I'm brand new to PLS-PM but think that it's the most appropriate approach
for my analytical need: developing indices of beneficial uses of water
bodies. I've read Gaston Sanchez's excellent book on 'PLS Path Modeling With
R' and am going through it again. I believe that I understand how to
structure the network of manifest and latent variables and set up the R data
structures; time will tell if my understanding is sufficiently complete.

   The few relevant references to PLS-PM (or each part separately) suggest
that use of this analytical approach has focused on marketing and economic
research rather than applied environmental science. This is not a problem.
What I would appreciate are pointers to examples of PLS-PM applied to highly
complex concepts that I can use to support using this approach in a
different context.

Thanks in advance,

Rich

-- 
Richard B. Shepard, Ph.D.          |      Have knowledge, will travel.
Applied Ecosystem Services, Inc.   |
<http://www.appl-ecosys.com>     Voice: 503-667-4517      Fax: 503-667-8863


From dwinsemius at comcast.net  Tue Jul  9 19:08:50 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 Jul 2013 10:08:50 -0700
Subject: [R] wrong when use the function fast99 in package "Sensitivity"
In-Reply-To: <76a33c96.9d87.13fc238c611.Coremail.xhl860728@163.com>
References: <76a33c96.9d87.13fc238c611.Coremail.xhl860728@163.com>
Message-ID: <D7F2761D-0BBF-4BB6-B9A7-5CB711B5560B@comcast.net>


On Jul 8, 2013, at 11:57 PM, ?? wrote:

> 
> 
> Pn_I<-function(x){
> 
>  I<-1000
>  Rp<-x[4]*(1-x[5]*I)*I/(1+x[6]*I)
>  Pn<-x[1]*(1-x[2]*I)*I/(1+x[3]*I)-Rp-x[7]
>  return(Pn)
> 
> }
> 
> 
> 
> 
> Pn_I_sensitivity <- fast99(model = Pn_I, factors=c("alpha","beta","gamma","delta","lammda","omiga","Rd"),
>                           n = 3000,q =rep("qunif",7), q.arg = list(alpha=list(min=0,max=1),
>                           beta=list(min=0,max=1),gamma=list(min=0,max=1),delta=list(min=0,max=1),
>                           lammda=list(min=0,max=1),omiga=list(min=0,max=1), Rd=list(min=0,max=4)))
> 
> 
> print(Pn_I_sensitivity)
> plot(Pn_I_sensitivity)
> 
> 
> the results as follow
> 
> Error in response(x, ...) : 
>  (list) object cannot be coerced to type 'double'

Generally that error message means you are not using the correct extraction function. Try using "[[" instead of "["

-- 
David.
> 
> 
> does anybody know where is wrong in my code?
> --
> ????
> ?????????????? ???????????????????? ??????????????????????????????
> ?????? ?????? ????????11??
> ??????13651318417
> Liang He
> Institute of Geographic Sciences and Natural resource research
> Chinese Academy of Science,
> No.11, Datun Road, Chaoyang District,
> Beijing 100101, China
> Email: xhl860728 at 163.com
> Tel: +86(10) 6488 9513
> Mob:+86 0 13651318417
> 
> 
> 
> 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From sjkiss at gmail.com  Tue Jul  9 19:28:22 2013
From: sjkiss at gmail.com (Simon Kiss)
Date: Tue, 9 Jul 2013 13:28:22 -0400
Subject: [R] Goodness of fit statistics for cfa are missing (sem package)
Message-ID: <0003E792-BCD7-46DF-84BC-1D19B0262E04@gmail.com>

Dear colleagues,
I'm working on a confirmatory factor analysis and the model is not returning most of the usual goodness-of-fit statistics. 

I'm testing whether this survey data confirms a hypothesized two-factor uncorrelated structure that has theoretical and empirical support from another case.

Below is (hopefully!) reproducible code which creates ff.cov a replica of the covariance matrix from my own data, the model that I have specified and am testing (cfa.mod.1) and the sem test of that model (cfa) and then a summary of the model fit (summary(cfa1)). 

The problem is that many of the usual measures o goodness-of-fit do not appear after summary(cfa1).  I only get a chi-square statistic, degrees of freedom and a BIC.  

I saw a previous question on the R-mailing list that raised a similar issue and it was suggested that the problem lay in the specification of the model and that the degrees of freedom there were 0.  Here, though, the df is 77.  Unfortunately I can't find that question in the archives again or I would have linked to it.

The data set includes 376 observations and has 14 variables.  Seven (coded with an h in the variable name, as in cc.h.varname.e or h) are hypothesized to load on one factor uncorrelated with the second factor, coded with a c (as in cc.c.varname.c or i). 
I used this for guidance http://vimeo.com/38941937
Yours, Simon Kiss


#Load Libraries
library(sem)

#Create Covariance Matrix
ff.cov <-
  structure(c(0.0925407885304659, 0.0296839426523298, 0.00787168458781362, 
              0.0261784946236559, 0.0031878853046595, 0.0261837275985663, 0.00847584229390681, 
              -0.00106, -0.00600867383512545, -0.010714623655914, -0.0123756272401434, 
              -0.00528007168458781, -0.00116, 0.000812186379928316, 0.0296839426523298, 
              0.0665810023041475, 0.00836764592933948, 0.0281491359447005, 
              0.00793406810035842, 0.0169870865335381, 0.00258921786994368, 
              0.000712720174091142, -0.00318649385560676, -0.0083643253968254, 
              -0.0133228366615463, -0.00557817844342038, -0.00224328341013825, 
              -0.000821018945212493, 0.00787168458781362, 0.00836764592933948, 
              0.0804340181771633, 0.00589630696364567, 0.0201758960573477, 
              0.012536866359447, 0.000343669994879673, 0.00425544674859191, 
              -0.00838453020993344, 0.00563975294418843, 0.00256180235535074, 
              0.00609073860727087, -0.00659535970302099, 0.00495727086533538, 
              0.0261784946236559, 0.0281491359447005, 0.00589630696364567, 
              0.0716310995903738, 0.00856442652329749, 0.0175328725038402, 
              0.0104401625704045, 0.0074095942140297, 0.00455983742959549, 
              -0.0123115783410138, -0.0192821300563236, -0.0166337109575013, 
              0.00623943292370712, -0.0114852790578597, 0.0031878853046595, 
              0.00793406810035842, 0.0201758960573477, 0.00856442652329749, 
              0.0550506451612903, 0.00998831541218638, -0.000462311827956989, 
              -0.0019576523297491, -0.0053855017921147, 0.00893281362007168, 
              8.10035842293904e-05, 0.00704324372759857, -0.00593381720430108, 
              -0.00112867383512545, 0.0261837275985663, 0.0169870865335381, 
              0.012536866359447, 0.0175328725038402, 0.00998831541218638, 0.050779846390169, 
              0.00705281105990783, -0.00306167946748592, -0.00736291858678955, 
              0.00135779825908858, -0.00280025601638505, 0.00161077316948285, 
              -0.00899035330261137, 0.00921536098310292, 0.00847584229390681, 
              0.00258921786994368, 0.000343669994879673, 0.0104401625704045, 
              -0.000462311827956989, 0.00705281105990783, 0.0475710074244752, 
              -0.0101174718381976, -0.0102886418330773, -0.0175483013312852, 
              -0.0107030209933436, -0.00982140168970814, -0.00959551843317972, 
              -0.00663934971838198, -0.00106, 0.000712720174091142, 0.00425544674859191, 
              0.0074095942140297, -0.0019576523297491, -0.00306167946748592, 
              -0.0101174718381976, 0.0572903110599078, 0.0148363965693804, 
              0.0134899987199181, 0.0172146441372248, 0.00366528545826933, 
              0.0148914759344598, 0.00469321556579621, -0.00600867383512545, 
              -0.00318649385560676, -0.00838453020993344, 0.00455983742959549, 
              -0.0053855017921147, -0.00736291858678955, -0.0102886418330773, 
              0.0148363965693804, 0.0650389644137225, 0.00571948412698413, 
              0.00671484895033282, -0.000752505120327701, 0.0295244790066564, 
              -0.00901979006656426, -0.010714623655914, -0.0083643253968254, 
              0.00563975294418843, -0.0123115783410138, 0.00893281362007168, 
              0.00135779825908858, -0.0175483013312852, 0.0134899987199181, 
              0.00571948412698413, 0.0839045558115719, 0.0463349206349206, 
              0.0350310253456221, 0.00760227470558116, 0.035818561187916, -0.0123756272401434, 
              -0.0133228366615463, 0.00256180235535074, -0.0192821300563236, 
              8.10035842293904e-05, -0.00280025601638505, -0.0107030209933436, 
              0.0172146441372248, 0.00671484895033282, 0.0463349206349206, 
              0.073641986687148, 0.0295747055811572, 0.00827306707629288, 0.0317729134664619, 
              -0.00528007168458781, -0.00557817844342038, 0.00609073860727087, 
              -0.0166337109575013, 0.00704324372759857, 0.00161077316948285, 
              -0.00982140168970814, 0.00366528545826933, -0.000752505120327701, 
              0.0350310253456221, 0.0295747055811572, 0.0607050576036866, 0.00305336789554532, 
              0.0243178443420379, -0.00116, -0.00224328341013825, -0.00659535970302099, 
              0.00623943292370712, -0.00593381720430108, -0.00899035330261137, 
              -0.00959551843317972, 0.0148914759344598, 0.0295244790066564, 
              0.00760227470558116, 0.00827306707629288, 0.00305336789554532, 
              0.0525731067588326, 0.000673143881208398, 0.000812186379928316, 
              -0.000821018945212493, 0.00495727086533538, -0.0114852790578597, 
              -0.00112867383512545, 0.00921536098310292, -0.00663934971838198, 
              0.00469321556579621, -0.00901979006656426, 0.035818561187916, 
              0.0317729134664619, 0.0243178443420379, 0.000673143881208398, 
              0.0749327188940092), .Dim = c(14L, 14L), .Dimnames = list(c("cc.c.protect.i", 
                                                                          "cc.c.privacy.i", "cc.c.limchoi.c", "cc.c.interests.i", "cc.c.goals.c", 
                                                                          "cc.c.harm.c", "cc.c.needs.c", "cc.h.discrim.e", "cc.h.wealth.e", 
                                                                          "cc.h.revdis2.h", "cc.h.equal.h", "cc.h.feminine.h", "cc.h.radeq.e", 
                                                                          "cc.h.tradfam.h"), c("cc.c.protect.i", "cc.c.privacy.i", "cc.c.limchoi.c", 
                                                                                               "cc.c.interests.i", "cc.c.goals.c", "cc.c.harm.c", "cc.c.needs.c", 
                                                                                               "cc.h.discrim.e", "cc.h.wealth.e", "cc.h.revdis2.h", "cc.h.equal.h", 
                                                                                               "cc.h.feminine.h", "cc.h.radeq.e", "cc.h.tradfam.h")))
#Specify Model
cfa.mod1<-specifyModel()
HE -> cc.h.discrim.e, he0
HE -> cc.h.wealth.e, he1
HE -> cc.h.revdis2.h, he2
HE -> cc.h.equal.h, he3
HE -> cc.h.radeq.e, he4
HE -> cc.h.tradfam.h, he5
HE -> cc.h.feminine.h, he6
IC -> cc.c.protect.i, ic0
IC -> cc.c.privacy.i, ic1
IC -> cc.c.limchoi.c, ic2
IC -> cc.c.interests.i, ic3
IC -> cc.c.goals.c, ic4
IC -> cc.c.harm.c, ic5
IC -> cc.c.needs.c, ic6
HE <-> HE, NA, 1
IC <-> IC, NA, 1
cc.h.discrim.e <-> cc.h.discrim.e, error1
cc.h.wealth.e <->  cc.h.wealth.e, error2
cc.h.revdis2.h <-> cc.h.revdis2.h, error3
cc.h.equal.h <-> cc.h.equal.h, error4
cc.h.radeq.e <-> cc.h.radeq.e, error5
cc.h.tradfam.h <-> cc.h.tradfam.h, error6
cc.h.feminine.h <-> cc.h.feminine.h, error7
cc.c.protect.i <-> cc.c.protect.i, error8
cc.c.privacy.i <-> cc.c.privacy.i, error9
cc.c.limchoi.c <-> cc.c.limchoi.c, error10
cc.c.interests.i<-> cc.c.interests.i, error11
cc.c.goals.c <-> cc.c.goals.c, error12
cc.c.harm.c <-> cc.c.harm.c, error13
cc.c.needs.c <-> cc.c.needs.c, error14

#Test Model

cfa1<-sem(cfa.mod1, S=ff.cov, N=376)
#Examine Model
cfa1
summary(cfa1)
stdCoef(cfa1)

#First few lies of my output
Model Chisquare =  414.2874   Df =  77 Pr(>Chisq) = 1.142376e-47
 AIC =  470.2874
 BIC =  -42.29101

*********************************
Simon J. Kiss, PhD
Assistant Professor, Wilfrid Laurier University
73 George Street
Brantford, Ontario, Canada
N3T 2C9


From smartpink111 at yahoo.com  Tue Jul  9 19:48:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 9 Jul 2013 10:48:25 -0700 (PDT)
Subject: [R] Kruskal.test
Message-ID: <1373392105.17499.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
?kruskal.test()
?a<- c(2,4,5,2,7)
?b<- c(2,2,6)
?c<- c(3,7,9,3)
?kruskal.test(list(a,b,c))
#
?#? Kruskal-Wallis rank sum test
#
#data:? list(a, b, c)
#Kruskal-Wallis chi-squared = 2.003, df = 2, p-value = 0.3673
A.K.


Hi 

I need an expression in R to apply a kruskal.test to this data (for example). 
a ? a ? a ? a ? ?a ? ?b ? b ? ?b ? ?c ? ?c ? c ? ?c 
2 ?4 ? ?5 ? 2 ? ?7 ? ?2 ? 2 ? ?6 ? ?3 ? ?7 ? 9 ? ?3 
a, b and c could be consider different vectors. How can I apply this
 test to this data? (probably the data isn't good to this test, but I 
onlu need the expression). 

Thank you very much


From asanramzan at yahoo.com  Tue Jul  9 20:17:14 2013
From: asanramzan at yahoo.com (Asan Ramzan)
Date: Tue, 9 Jul 2013 11:17:14 -0700 (PDT)
Subject: [R] Global fit analysis
Message-ID: <1373393834.5259.YahooMailNeo@web125902.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/9147b083/attachment.pl>

From gunter.berton at gene.com  Tue Jul  9 20:27:23 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 9 Jul 2013 11:27:23 -0700
Subject: [R] Global fit analysis
In-Reply-To: <1373393834.5259.YahooMailNeo@web125902.mail.ne1.yahoo.com>
References: <1373393834.5259.YahooMailNeo@web125902.mail.ne1.yahoo.com>
Message-ID: <CACk-te04haPCvZjPTVE_egwibutsg4dXBst-Y9EY0-_Qsbseig@mail.gmail.com>

I suspect you received no reply as no one knows what you mean by
"global fit analysis." If you have some specific technical definition
in mind, provide a reference. Better yet, SEARCH (see CRAN's Task
Views).

If you are merely mis-referring to "goodness of fit" measures, than
all R's modeling functions in all packages provide such measures, this
is a statistics-- not an R -- question, and you need to do some
reading or consult a local statistician, not pester this list further.

Cheers,
Bert

On Tue, Jul 9, 2013 at 11:17 AM, Asan Ramzan <asanramzan at yahoo.com> wrote:
> I sending this again as I forgot to add a subject
>
>
> Hello R-help
>
> Does anyone know if there is a package for global
> fit analysis and if so how to use it.  I am trying to calculate the Kd
> value of a protein interacting with its ligand (When protein interacts
> with ligand this effect a number of residues). The table below
> shows with increasing concentration of ligand changes in three different
>  residues.
>
> Concentration  res1 res2  res3
> 0 0 0  0
> 1.99167E-05 0.012978 0.020862  0.03032
> 3.95847E-05 0.019562 0.032288  0.048266
> 7.82652E-05 0.021842 0.036  0.05521
> 0.000115656 0.025274 0.043862  0.06398
> 0.000151801 0.029896 0.048762  0.075302
> 0.000186741 0.033544 0.053556  0.084334
> 0.000220516 0.035676 0.058964 0.0914
> 0.000274932 0.037834 0.061818  0.097096
> 0.000352021 0.040694 0.066216  0.100024
> 0.000422686 0.04329 0.070414  0.109974
> 0.000552238 0.045482 0.074646  0.116072
> 0.000777155 0.047062 0.07671  0.118722
> 0.0012 0.05345 0.08602 0.130344
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ruipbarradas at sapo.pt  Tue Jul  9 20:32:14 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 09 Jul 2013 19:32:14 +0100
Subject: [R] Kruskal.test
In-Reply-To: <1373392105.17499.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1373392105.17499.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <51DC572E.2080801@sapo.pt>

Hello,

Another possibility is to use the formula interface.


x <- scan(what = "character", text = "
a   a   a   a    a    b   b    b    c    c   c    c")
y <- scan(text = "
2  4    5   2    7    2   2    6    3    7   9    3")

kruskal.test(y ~ factor(x))

dat <-
structure(list(x = structure(c(1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L,
3L, 3L, 3L, 3L), .Label = c("a", "b", "c"), class = "factor"),
     y = c(2, 4, 5, 2, 7, 2, 2, 6, 3, 7, 9, 3)), .Names = c("x",
"y"), row.names = c(NA, -12L), class = "data.frame")

kruskal.test(y ~ x, data = dat)


Hope this helps,

Rui Barradas

Em 09-07-2013 18:48, arun escreveu:
> Hi,
> ?kruskal.test()
>   a<- c(2,4,5,2,7)
>   b<- c(2,2,6)
>   c<- c(3,7,9,3)
>   kruskal.test(list(a,b,c))
> #
>   #  Kruskal-Wallis rank sum test
> #
> #data:  list(a, b, c)
> #Kruskal-Wallis chi-squared = 2.003, df = 2, p-value = 0.3673
> A.K.
>
>
> Hi
>
> I need an expression in R to apply a kruskal.test to this data (for example).
> a   a   a   a    a    b   b    b    c    c   c    c
> 2  4    5   2    7    2   2    6    3    7   9    3
> a, b and c could be consider different vectors. How can I apply this
>   test to this data? (probably the data isn't good to this test, but I
> onlu need the expression).
>
> Thank you very much
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jpayne at s-3.com  Tue Jul  9 19:37:31 2013
From: jpayne at s-3.com (juliannecpayne)
Date: Tue, 9 Jul 2013 10:37:31 -0700 (PDT)
Subject: [R] Trouble defining breaks for weighted histogram
Message-ID: <1373391451053-4671176.post@n4.nabble.com>

Hello R users,

I am in the process of creating weighted histograms using NHANES data. I
developed the following language to output my results:

wtd.hist(NHANES$LBXTHG,breaks="Sturges",weight=weight,freq=FALSE,main='Mercury
Histogram (Weighted)',xlab='Blood Mercury',col=200,na.rm=TRUE)

Each time I submit the language, I get an error back stating:

Error in wtd.hist(NHANES$LBXTHG, breaks = "Sturges", weight = weight,  : 
some 'x' not counted; maybe 'breaks' do not span range of 'x'

I'm a bit unclear on why this might be, given that the documentation on
Sturges led me to believe that the breaks would be determined by the range
of the data. Can anyone advise?

I suppose it may be worth mentioning that I am a new R user. I usually
program in SAS.

Best,
Jules




--
View this message in context: http://r.789695.n4.nabble.com/Trouble-defining-breaks-for-weighted-histogram-tp4671176.html
Sent from the R help mailing list archive at Nabble.com.


From ac331 at le.ac.uk  Tue Jul  9 17:49:03 2013
From: ac331 at le.ac.uk (alR)
Date: Tue, 9 Jul 2013 08:49:03 -0700 (PDT)
Subject: [R] save rds as text
In-Reply-To: <CA+vqiLGzQmRRBc_V79uvTGwzE+T08NX0crDmhapgfR9kW+Bg2A@mail.gmail.com>
References: <1373021042683-4670925.post@n4.nabble.com>
	<CA+vqiLGzQmRRBc_V79uvTGwzE+T08NX0crDmhapgfR9kW+Bg2A@mail.gmail.com>
Message-ID: <1373384943074-4671168.post@n4.nabble.com>

Dear Ista,

This worked fine, and it does not require any specific package.  I was
trying sink but with cat instead of print and it was not working.  This was
very helpful, thanks a lot.

Alberto



--
View this message in context: http://r.789695.n4.nabble.com/save-rds-as-text-tp4670925p4671168.html
Sent from the R help mailing list archive at Nabble.com.


From laila_zgz at hotmail.com  Tue Jul  9 18:34:17 2013
From: laila_zgz at hotmail.com (laila)
Date: Tue, 9 Jul 2013 09:34:17 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
In-Reply-To: <1373316818.12350.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1373238668238-4671059.post@n4.nabble.com>
	<1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<DUB116-W5914520FB86D7D17F860709E780@phx.gbl>
	<1373316818.12350.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <DUB116-W7077C1A830A1EFC6FCFD5E9E790@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/08e2274d/attachment.pl>

From dcarlson at tamu.edu  Tue Jul  9 21:02:06 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 9 Jul 2013 14:02:06 -0500
Subject: [R] Trouble defining breaks for weighted histogram
In-Reply-To: <1373391451053-4671176.post@n4.nabble.com>
References: <1373391451053-4671176.post@n4.nabble.com>
Message-ID: <137601ce7cd6$cdef7130$69ce5390$@tamu.edu>

Hard to say without a reproducible example, perhaps by using dput()
to include a subset of the data. You should indicate where
wtd.hist() comes from since it is not in base R. Perhaps the weights
package? It is not clear what weight=weight is unless you have
created a variable called weight. If you are referring to a variable
in NHANES it should be NHANES$weight.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of juliannecpayne
Sent: Tuesday, July 9, 2013 12:38 PM
To: r-help at r-project.org
Subject: [R] Trouble defining breaks for weighted histogram

Hello R users,

I am in the process of creating weighted histograms using NHANES
data. I
developed the following language to output my results:

wtd.hist(NHANES$LBXTHG,breaks="Sturges",weight=weight,freq=FALSE,mai
n='Mercury
Histogram (Weighted)',xlab='Blood Mercury',col=200,na.rm=TRUE)

Each time I submit the language, I get an error back stating:

Error in wtd.hist(NHANES$LBXTHG, breaks = "Sturges", weight =
weight,  : 
some 'x' not counted; maybe 'breaks' do not span range of 'x'

I'm a bit unclear on why this might be, given that the documentation
on
Sturges led me to believe that the breaks would be determined by the
range
of the data. Can anyone advise?

I suppose it may be worth mentioning that I am a new R user. I
usually
program in SAS.

Best,
Jules




--
View this message in context:
http://r.789695.n4.nabble.com/Trouble-defining-breaks-for-weighted-h
istogram-tp4671176.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ebbarayuga at ups.com  Tue Jul  9 21:28:26 2013
From: ebbarayuga at ups.com (ebbarayuga at ups.com)
Date: Tue, 9 Jul 2013 15:28:26 -0400
Subject: [R] Help in installing R
Message-ID: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/4d145e97/attachment.pl>

From marc_schwartz at me.com  Tue Jul  9 21:53:34 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 09 Jul 2013 14:53:34 -0500
Subject: [R] Help in installing R
In-Reply-To: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
References: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
Message-ID: <66F313FF-53A8-40A7-BE24-719E6F2375E2@me.com>

On Jul 9, 2013, at 2:28 PM, ebbarayuga at ups.com wrote:

> I am trying to set-up R in our LINUX Redhat server so that I can use R in LINUX
> Here is what I did:
> 
> 1.       Downloaded the newest version of R
> 
> 2.       Run ./configure after I untar the files
> 
> 3.       Had an issue while installing:
> 
> 4.       [flexapp at njrarltcda000d1 R-3.0.1]$ ./configure
> 
> 5.       checking build system type... x86_64-unknown-linux-gnu
> 
> 6.       checking host system type... x86_64-unknown-linux-gnu
> 
> 7.       loading site script './config.site'
> 
> 8.       loading build-specific script './config.site'
> 
> 9.       checking for pwd... /bin/pwd
> 
> 10.   checking whether builddir is srcdir... yes
> 
> 11.   checking for working aclocal... missing
> 
> 12.   checking for working autoconf... missing
> 
> 13.   checking for working automake... missing
> 
> 14.   checking for working autoheader... missing
> 
> 15.   checking for gawk... gawk
> 
> 16.   checking whether ln -s works... yes
> 
> 17.   checking for bison... no
> 
> 18.   checking for byacc... no
> 
> 19.   checking for ar... ar
> 
> 20.   checking for a BSD-compatible install... /usr/bin/install -c
> 
> 21.   checking for sed... /bin/sed
> 
> 22.   checking for which... /usr/bin/which
> 
> 23.   checking for less... /usr/bin/less
> 
> 24.   checking for gtar... /bin/gtar
> 
> 25.   checking for tex... no
> 
> 26.   checking for pdftex... no
> 
> 27.   configure: WARNING: you cannot build PDF versions of the R manuals
> 
> 28.   checking for pdflatex... no
> 
> 29.   configure: WARNING: you cannot build PDF versions of vignettes and help pages
> 
> 30.   checking for makeindex... no
> 
> 31.   checking for makeinfo... no
> 
> 32.   configure: WARNING: you cannot build info or HTML versions of the R manuals
> 
> 33.   checking for texi2dvi... no
> 
> 34.   checking for kpsewhich... no
> 
> 35.   checking for unzip... /usr/bin/unzip
> 
> 36.   checking for zip... /usr/bin/zip
> 
> 37.   checking for gzip... /bin/gzip
> 
> 38.   checking for bzip2... /usr/bin/bzip2
> 
> 39.   checking for firefox... no
> 
> 40.   checking for mozilla... no
> 
> 41.   checking for galeon... no
> 
> 42.   checking for opera... no
> 
> 43.   checking for xdg-open... no
> 
> 44.   checking for kfmclient... no
> 
> 45.   checking for gnome-moz-remote... no
> 
> 46.   checking for open... /usr/bin/open
> 
> 47.   using default browser ... /usr/bin/open
> 
> 48.   checking for acroread... no
> 
> 49.   checking for acroread4... no
> 
> 50.   checking for xdg-open... no
> 
> 51.   checking for evince... no
> 
> 52.   checking for xpdf... no
> 
> 53.   checking for gv... no
> 
> 54.   checking for gnome-gv... no
> 
> 55.   checking for ggv... no
> 
> 56.   checking for okular... no
> 
> 57.   checking for kpdf... no
> 
> 58.   checking for open... /usr/bin/open
> 
> 59.   checking for notangle... false
> 
> 60.   checking for pkg-config... /usr/bin/pkg-config
> 
> 61.   checking for gcc... gcc
> 
> 62.   checking whether the C compiler works... yes
> 
> 63.   checking for C compiler default output file name... a.out
> 
> 64.   checking for suffix of executables...
> 
> 65.   checking whether we are cross compiling... no
> 
> 66.   checking for suffix of object files... o
> 
> 67.   checking whether we are using the GNU C compiler... yes
> 
> 68.   checking whether gcc accepts -g... yes
> 
> 69.   checking for gcc option to accept ISO C89... none needed
> 
> 70.   checking how to run the C preprocessor... gcc -E
> 
> 71.   checking for grep that handles long lines and -e... /bin/grep
> 
> 72.   checking for egrep... /bin/grep -E
> 
> 73.   checking whether gcc needs -traditional... no
> 
> 74.   checking how to run the C preprocessor... gcc -E
> 
> 75.   checking for gfortran... no
> 
> 76.   checking for f95... no
> 
> 77.   checking for fort... no
> 
> 78.   checking for xlf95... no
> 
> 79.   checking for ifort... no
> 
> 80.   checking for ifc... no
> 
> 81.   checking for efc... no
> 
> 82.   checking for pgf95... no
> 
> 83.   checking for lf95... no
> 
> 84.   checking for gfortran... no
> 
> 85.   checking for ftn... no
> 
> 86.   checking for g95... no
> 
> 87.   checking for f90... no
> 
> 88.   checking for xlf90... no
> 
> 89.   checking for pgf90... no
> 
> 90.   checking for pghpf... no
> 
> 91.   checking for epcf90... no
> 
> 92.   checking for g77... no
> 
> 93.   checking for f77... no
> 
> 94.   checking for xlf... no
> 
> 95.   checking for frt... no
> 
> 96.   checking for pgf77... no
> 
> 97.   checking for cf77... no
> 
> 98.   checking for fort77... no
> 
> 99.   checking for fl32... no
> 
> 100.                        checking for af77... no
> 
> 101.                        checking for fc... no
> 
> 102.                        configure: error: No F77 compiler found
> 
> 
> Im thinking I would need to install some compiler in our DVLP environment.. can you verify which one is this..
> 
> Newbie,
> Elizabeth


If you are running a version of RHEL, there are pre-compiled binary RPMs of R available via the EPEL:

  http://fedoraproject.org/wiki/EPEL

You just need to install the appropriate repo configuration for your version of RHEL and then use:

  yum install R

as root (eg. via sudo) from the terminal, which will install R and take care of any additional RPM dependencies. If you don't have SysAdmin privileges, you will need to get a SysAdmin to assist you.

If there is a particular reason that you really need to compile R from source, you are better off starting out by reading the R Installation and Administration Manual, which is available online at:

  http://cran.r-project.org/manuals.html

The output you have above is certainly indicative of missing required development related tools, which are addressed in the above manual, including the Appendix. You will need SysAdmin privileges or a SysAdmin to assist you in installing the required RPMs to fulfill the requirements.

Any additional related follow up questions that you may have should really be directed to the R-SIG-Fedora e-mail list, which is focused on R related questions specific to RH based distributions (eg. RHEL, Fedora, CentOS, etc.). More info on subscribing is here:

  https://stat.ethz.ch/mailman/listinfo/r-sig-fedora

Regards,

Marc Schwartz


From sarah.goslee at gmail.com  Tue Jul  9 22:05:14 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 9 Jul 2013 16:05:14 -0400
Subject: [R] Help in installing R
In-Reply-To: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
References: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
Message-ID: <CAM_vjukaHE9TN4ciJzR-2hrFHD8KK6eqB_6414XSGi+VgrpwPg@mail.gmail.com>

Hi,

It sounds like you really ought to read the installation manual:
http://www.cran.r-project.org/doc/manuals/R-admin.html
and especially
http://www.cran.r-project.org/doc/manuals/R-admin.html#Essential-and-useful-other-programs-under-a-Unix_002dalike

But do note that if you have no compelling reason to install from
source, there's probably a RedHat RPM available. You didn't give
details of your OS, so I can't say for certain.

Sarah

On Tue, Jul 9, 2013 at 3:28 PM,  <ebbarayuga at ups.com> wrote:
> I am trying to set-up R in our LINUX Redhat server so that I can use R in LINUX
> Here is what I did:
>
> 1.       Downloaded the newest version of R
>
> 2.       Run ./configure after I untar the files
>
> 3.       Had an issue while installing:
>
> 4.       [flexapp at njrarltcda000d1 R-3.0.1]$ ./configure
>
> 5.       checking build system type... x86_64-unknown-linux-gnu
>
> 6.       checking host system type... x86_64-unknown-linux-gnu
>
> 7.       loading site script './config.site'
>
> 8.       loading build-specific script './config.site'
>
> 9.       checking for pwd... /bin/pwd
>
> 10.   checking whether builddir is srcdir... yes
>
> 11.   checking for working aclocal... missing
>
> 12.   checking for working autoconf... missing
>
> 13.   checking for working automake... missing
>
> 14.   checking for working autoheader... missing
>
> 15.   checking for gawk... gawk
>
> 16.   checking whether ln -s works... yes
>
> 17.   checking for bison... no
>
> 18.   checking for byacc... no
>
> 19.   checking for ar... ar
>
> 20.   checking for a BSD-compatible install... /usr/bin/install -c
>
> 21.   checking for sed... /bin/sed
>
> 22.   checking for which... /usr/bin/which
>
> 23.   checking for less... /usr/bin/less
>
> 24.   checking for gtar... /bin/gtar
>
> 25.   checking for tex... no
>
> 26.   checking for pdftex... no
>
> 27.   configure: WARNING: you cannot build PDF versions of the R manuals
>
> 28.   checking for pdflatex... no
>
> 29.   configure: WARNING: you cannot build PDF versions of vignettes and help pages
>
> 30.   checking for makeindex... no
>
> 31.   checking for makeinfo... no
>
> 32.   configure: WARNING: you cannot build info or HTML versions of the R manuals
>
> 33.   checking for texi2dvi... no
>
> 34.   checking for kpsewhich... no
>
> 35.   checking for unzip... /usr/bin/unzip
>
> 36.   checking for zip... /usr/bin/zip
>
> 37.   checking for gzip... /bin/gzip
>
> 38.   checking for bzip2... /usr/bin/bzip2
>
> 39.   checking for firefox... no
>
> 40.   checking for mozilla... no
>
> 41.   checking for galeon... no
>
> 42.   checking for opera... no
>
> 43.   checking for xdg-open... no
>
> 44.   checking for kfmclient... no
>
> 45.   checking for gnome-moz-remote... no
>
> 46.   checking for open... /usr/bin/open
>
> 47.   using default browser ... /usr/bin/open
>
> 48.   checking for acroread... no
>
> 49.   checking for acroread4... no
>
> 50.   checking for xdg-open... no
>
> 51.   checking for evince... no
>
> 52.   checking for xpdf... no
>
> 53.   checking for gv... no
>
> 54.   checking for gnome-gv... no
>
> 55.   checking for ggv... no
>
> 56.   checking for okular... no
>
> 57.   checking for kpdf... no
>
> 58.   checking for open... /usr/bin/open
>
> 59.   checking for notangle... false
>
> 60.   checking for pkg-config... /usr/bin/pkg-config
>
> 61.   checking for gcc... gcc
>
> 62.   checking whether the C compiler works... yes
>
> 63.   checking for C compiler default output file name... a.out
>
> 64.   checking for suffix of executables...
>
> 65.   checking whether we are cross compiling... no
>
> 66.   checking for suffix of object files... o
>
> 67.   checking whether we are using the GNU C compiler... yes
>
> 68.   checking whether gcc accepts -g... yes
>
> 69.   checking for gcc option to accept ISO C89... none needed
>
> 70.   checking how to run the C preprocessor... gcc -E
>
> 71.   checking for grep that handles long lines and -e... /bin/grep
>
> 72.   checking for egrep... /bin/grep -E
>
> 73.   checking whether gcc needs -traditional... no
>
> 74.   checking how to run the C preprocessor... gcc -E
>
> 75.   checking for gfortran... no
>
> 76.   checking for f95... no
>
> 77.   checking for fort... no
>
> 78.   checking for xlf95... no
>
> 79.   checking for ifort... no
>
> 80.   checking for ifc... no
>
> 81.   checking for efc... no
>
> 82.   checking for pgf95... no
>
> 83.   checking for lf95... no
>
> 84.   checking for gfortran... no
>
> 85.   checking for ftn... no
>
> 86.   checking for g95... no
>
> 87.   checking for f90... no
>
> 88.   checking for xlf90... no
>
> 89.   checking for pgf90... no
>
> 90.   checking for pghpf... no
>
> 91.   checking for epcf90... no
>
> 92.   checking for g77... no
>
> 93.   checking for f77... no
>
> 94.   checking for xlf... no
>
> 95.   checking for frt... no
>
> 96.   checking for pgf77... no
>
> 97.   checking for cf77... no
>
> 98.   checking for fort77... no
>
> 99.   checking for fl32... no
>
> 100.                        checking for af77... no
>
> 101.                        checking for fc... no
>
> 102.                        configure: error: No F77 compiler found
>
>
> Im thinking I would need to install some compiler in our DVLP environment.. can you verify which one is this..
>
> Newbie,
> Elizabeth
> Elizabeth B. Barayuga
> Lead Applications Developer
> Enterprise BI
> EBBarayuga at ups.com<mailto:EBBarayuga at ups.com>
> 201-828-7890
> Atlas 283-7890
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From deter088 at umn.edu  Tue Jul  9 22:18:48 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Tue, 9 Jul 2013 15:18:48 -0500
Subject: [R] Power of Kruskal-Wallis Test?
Message-ID: <CAOLJphmxHNnMawwmzcZv47sE_dQ8TmGgg7d+a0dv7GPhPjVA_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/e81e3e0b/attachment.pl>

From bhh at xs4all.nl  Tue Jul  9 22:34:40 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 9 Jul 2013 22:34:40 +0200
Subject: [R] Help in installing R
In-Reply-To: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
References: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
Message-ID: <383B2001-CE2C-41E9-BEF9-13EC9A2C5F6A@xs4all.nl>


I don't know anything about your Redhat machine.
But you could carefully inspect the list you gave.

Item 102 says that you don't have an F77 compiler installed. I.e. no fortran compiler.
Since you have gcc installed, installing gfortran (item 75) would certainly help.

Berend

On 09-07-2013, at 21:28, ebbarayuga at ups.com wrote:

> I am trying to set-up R in our LINUX Redhat server so that I can use R in LINUX
> Here is what I did:
> 
> 1.       Downloaded the newest version of R
> 
> 2.       Run ./configure after I untar the files
> 
> 3.       Had an issue while installing:
> 
> 4.       [flexapp at njrarltcda000d1 R-3.0.1]$ ./configure
> 
> 5.       checking build system type... x86_64-unknown-linux-gnu
> 
> 6.       checking host system type... x86_64-unknown-linux-gnu
> 
> 7.       loading site script './config.site'
> 
> 8.       loading build-specific script './config.site'
> 
> 9.       checking for pwd... /bin/pwd
> 
> 10.   checking whether builddir is srcdir... yes
> 
> 11.   checking for working aclocal... missing
> 
> 12.   checking for working autoconf... missing
> 
> 13.   checking for working automake... missing
> 
> 14.   checking for working autoheader... missing
> 
> 15.   checking for gawk... gawk
> 
> 16.   checking whether ln -s works... yes
> 
> 17.   checking for bison... no
> 
> 18.   checking for byacc... no
> 
> 19.   checking for ar... ar
> 
> 20.   checking for a BSD-compatible install... /usr/bin/install -c
> 
> 21.   checking for sed... /bin/sed
> 
> 22.   checking for which... /usr/bin/which
> 
> 23.   checking for less... /usr/bin/less
> 
> 24.   checking for gtar... /bin/gtar
> 
> 25.   checking for tex... no
> 
> 26.   checking for pdftex... no
> 
> 27.   configure: WARNING: you cannot build PDF versions of the R manuals
> 
> 28.   checking for pdflatex... no
> 
> 29.   configure: WARNING: you cannot build PDF versions of vignettes and help pages
> 
> 30.   checking for makeindex... no
> 
> 31.   checking for makeinfo... no
> 
> 32.   configure: WARNING: you cannot build info or HTML versions of the R manuals
> 
> 33.   checking for texi2dvi... no
> 
> 34.   checking for kpsewhich... no
> 
> 35.   checking for unzip... /usr/bin/unzip
> 
> 36.   checking for zip... /usr/bin/zip
> 
> 37.   checking for gzip... /bin/gzip
> 
> 38.   checking for bzip2... /usr/bin/bzip2
> 
> 39.   checking for firefox... no
> 
> 40.   checking for mozilla... no
> 
> 41.   checking for galeon... no
> 
> 42.   checking for opera... no
> 
> 43.   checking for xdg-open... no
> 
> 44.   checking for kfmclient... no
> 
> 45.   checking for gnome-moz-remote... no
> 
> 46.   checking for open... /usr/bin/open
> 
> 47.   using default browser ... /usr/bin/open
> 
> 48.   checking for acroread... no
> 
> 49.   checking for acroread4... no
> 
> 50.   checking for xdg-open... no
> 
> 51.   checking for evince... no
> 
> 52.   checking for xpdf... no
> 
> 53.   checking for gv... no
> 
> 54.   checking for gnome-gv... no
> 
> 55.   checking for ggv... no
> 
> 56.   checking for okular... no
> 
> 57.   checking for kpdf... no
> 
> 58.   checking for open... /usr/bin/open
> 
> 59.   checking for notangle... false
> 
> 60.   checking for pkg-config... /usr/bin/pkg-config
> 
> 61.   checking for gcc... gcc
> 
> 62.   checking whether the C compiler works... yes
> 
> 63.   checking for C compiler default output file name... a.out
> 
> 64.   checking for suffix of executables...
> 
> 65.   checking whether we are cross compiling... no
> 
> 66.   checking for suffix of object files... o
> 
> 67.   checking whether we are using the GNU C compiler... yes
> 
> 68.   checking whether gcc accepts -g... yes
> 
> 69.   checking for gcc option to accept ISO C89... none needed
> 
> 70.   checking how to run the C preprocessor... gcc -E
> 
> 71.   checking for grep that handles long lines and -e... /bin/grep
> 
> 72.   checking for egrep... /bin/grep -E
> 
> 73.   checking whether gcc needs -traditional... no
> 
> 74.   checking how to run the C preprocessor... gcc -E
> 
> 75.   checking for gfortran... no
> 
> 76.   checking for f95... no
> 
> 77.   checking for fort... no
> 
> 78.   checking for xlf95... no
> 
> 79.   checking for ifort... no
> 
> 80.   checking for ifc... no
> 
> 81.   checking for efc... no
> 
> 82.   checking for pgf95... no
> 
> 83.   checking for lf95... no
> 
> 84.   checking for gfortran... no
> 
> 85.   checking for ftn... no
> 
> 86.   checking for g95... no
> 
> 87.   checking for f90... no
> 
> 88.   checking for xlf90... no
> 
> 89.   checking for pgf90... no
> 
> 90.   checking for pghpf... no
> 
> 91.   checking for epcf90... no
> 
> 92.   checking for g77... no
> 
> 93.   checking for f77... no
> 
> 94.   checking for xlf... no
> 
> 95.   checking for frt... no
> 
> 96.   checking for pgf77... no
> 
> 97.   checking for cf77... no
> 
> 98.   checking for fort77... no
> 
> 99.   checking for fl32... no
> 
> 100.                        checking for af77... no
> 
> 101.                        checking for fc... no
> 
> 102.                        configure: error: No F77 compiler found
> 
> 
> Im thinking I would need to install some compiler in our DVLP environment.. can you verify which one is this..
> 
> Newbie,
> Elizabeth
> Elizabeth B. Barayuga
> Lead Applications Developer
> Enterprise BI
> EBBarayuga at ups.com<mailto:EBBarayuga at ups.com>
> 201-828-7890
> Atlas 283-7890
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ebbarayuga at ups.com  Tue Jul  9 22:07:08 2013
From: ebbarayuga at ups.com (ebbarayuga at ups.com)
Date: Tue, 9 Jul 2013 16:07:08 -0400
Subject: [R] Help in installing R
In-Reply-To: <CAM_vjukaHE9TN4ciJzR-2hrFHD8KK6eqB_6414XSGi+VgrpwPg@mail.gmail.com>
References: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
	<CAM_vjukaHE9TN4ciJzR-2hrFHD8KK6eqB_6414XSGi+VgrpwPg@mail.gmail.com>
Message-ID: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5AB8@njrarsvr3bf7.us.ups.com>

Hi sarah
I am installing using Redhat LINUX 5.5 
-----Original Message-----
From: Sarah Goslee [mailto:sarah.goslee at gmail.com] 
Sent: Tuesday, July 09, 2013 4:05 PM
To: Barayuga Elizabeth (app1ebb)
Cc: r-help at r-project.org
Subject: Re: [R] Help in installing R

Hi,

It sounds like you really ought to read the installation manual:
http://www.cran.r-project.org/doc/manuals/R-admin.html
and especially
http://www.cran.r-project.org/doc/manuals/R-admin.html#Essential-and-useful-other-programs-under-a-Unix_002dalike

But do note that if you have no compelling reason to install from source, there's probably a RedHat RPM available. You didn't give details of your OS, so I can't say for certain.

Sarah

On Tue, Jul 9, 2013 at 3:28 PM,  <ebbarayuga at ups.com> wrote:
> I am trying to set-up R in our LINUX Redhat server so that I can use R 
> in LINUX Here is what I did:
>
> 1.       Downloaded the newest version of R
>
> 2.       Run ./configure after I untar the files
>
> 3.       Had an issue while installing:
>
> 4.       [flexapp at njrarltcda000d1 R-3.0.1]$ ./configure
>
> 5.       checking build system type... x86_64-unknown-linux-gnu
>
> 6.       checking host system type... x86_64-unknown-linux-gnu
>
> 7.       loading site script './config.site'
>
> 8.       loading build-specific script './config.site'
>
> 9.       checking for pwd... /bin/pwd
>
> 10.   checking whether builddir is srcdir... yes
>
> 11.   checking for working aclocal... missing
>
> 12.   checking for working autoconf... missing
>
> 13.   checking for working automake... missing
>
> 14.   checking for working autoheader... missing
>
> 15.   checking for gawk... gawk
>
> 16.   checking whether ln -s works... yes
>
> 17.   checking for bison... no
>
> 18.   checking for byacc... no
>
> 19.   checking for ar... ar
>
> 20.   checking for a BSD-compatible install... /usr/bin/install -c
>
> 21.   checking for sed... /bin/sed
>
> 22.   checking for which... /usr/bin/which
>
> 23.   checking for less... /usr/bin/less
>
> 24.   checking for gtar... /bin/gtar
>
> 25.   checking for tex... no
>
> 26.   checking for pdftex... no
>
> 27.   configure: WARNING: you cannot build PDF versions of the R manuals
>
> 28.   checking for pdflatex... no
>
> 29.   configure: WARNING: you cannot build PDF versions of vignettes and help pages
>
> 30.   checking for makeindex... no
>
> 31.   checking for makeinfo... no
>
> 32.   configure: WARNING: you cannot build info or HTML versions of the R manuals
>
> 33.   checking for texi2dvi... no
>
> 34.   checking for kpsewhich... no
>
> 35.   checking for unzip... /usr/bin/unzip
>
> 36.   checking for zip... /usr/bin/zip
>
> 37.   checking for gzip... /bin/gzip
>
> 38.   checking for bzip2... /usr/bin/bzip2
>
> 39.   checking for firefox... no
>
> 40.   checking for mozilla... no
>
> 41.   checking for galeon... no
>
> 42.   checking for opera... no
>
> 43.   checking for xdg-open... no
>
> 44.   checking for kfmclient... no
>
> 45.   checking for gnome-moz-remote... no
>
> 46.   checking for open... /usr/bin/open
>
> 47.   using default browser ... /usr/bin/open
>
> 48.   checking for acroread... no
>
> 49.   checking for acroread4... no
>
> 50.   checking for xdg-open... no
>
> 51.   checking for evince... no
>
> 52.   checking for xpdf... no
>
> 53.   checking for gv... no
>
> 54.   checking for gnome-gv... no
>
> 55.   checking for ggv... no
>
> 56.   checking for okular... no
>
> 57.   checking for kpdf... no
>
> 58.   checking for open... /usr/bin/open
>
> 59.   checking for notangle... false
>
> 60.   checking for pkg-config... /usr/bin/pkg-config
>
> 61.   checking for gcc... gcc
>
> 62.   checking whether the C compiler works... yes
>
> 63.   checking for C compiler default output file name... a.out
>
> 64.   checking for suffix of executables...
>
> 65.   checking whether we are cross compiling... no
>
> 66.   checking for suffix of object files... o
>
> 67.   checking whether we are using the GNU C compiler... yes
>
> 68.   checking whether gcc accepts -g... yes
>
> 69.   checking for gcc option to accept ISO C89... none needed
>
> 70.   checking how to run the C preprocessor... gcc -E
>
> 71.   checking for grep that handles long lines and -e... /bin/grep
>
> 72.   checking for egrep... /bin/grep -E
>
> 73.   checking whether gcc needs -traditional... no
>
> 74.   checking how to run the C preprocessor... gcc -E
>
> 75.   checking for gfortran... no
>
> 76.   checking for f95... no
>
> 77.   checking for fort... no
>
> 78.   checking for xlf95... no
>
> 79.   checking for ifort... no
>
> 80.   checking for ifc... no
>
> 81.   checking for efc... no
>
> 82.   checking for pgf95... no
>
> 83.   checking for lf95... no
>
> 84.   checking for gfortran... no
>
> 85.   checking for ftn... no
>
> 86.   checking for g95... no
>
> 87.   checking for f90... no
>
> 88.   checking for xlf90... no
>
> 89.   checking for pgf90... no
>
> 90.   checking for pghpf... no
>
> 91.   checking for epcf90... no
>
> 92.   checking for g77... no
>
> 93.   checking for f77... no
>
> 94.   checking for xlf... no
>
> 95.   checking for frt... no
>
> 96.   checking for pgf77... no
>
> 97.   checking for cf77... no
>
> 98.   checking for fort77... no
>
> 99.   checking for fl32... no
>
> 100.                        checking for af77... no
>
> 101.                        checking for fc... no
>
> 102.                        configure: error: No F77 compiler found
>
>
> Im thinking I would need to install some compiler in our DVLP environment.. can you verify which one is this..
>
> Newbie,
> Elizabeth
> Elizabeth B. Barayuga
> Lead Applications Developer
> Enterprise BI
> EBBarayuga at ups.com<mailto:EBBarayuga at ups.com>
> 201-828-7890
> Atlas 283-7890
>

--
Sarah Goslee
http://www.functionaldiversity.org


From kridox at ymail.com  Tue Jul  9 23:26:18 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 10 Jul 2013 06:26:18 +0900
Subject: [R] Help in installing R
In-Reply-To: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
References: <B54CAD83E9E13C428A0D8D7EDE40B05501EFFC5A8A@njrarsvr3bf7.us.ups.com>
Message-ID: <CAAcyNCyFOL5=44v7k0-g7W+SvLJR7+s1jav5G6QJb7gfRmzZUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/e655f56f/attachment.pl>

From charliethebrown77 at gmail.com  Wed Jul 10 00:23:04 2013
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Tue, 9 Jul 2013 17:23:04 -0500
Subject: [R] Same plot size with mfrow()
Message-ID: <CABnkouqh+gZ61sPJc8mYeOppaqzO5TH1Qqqfk8vuqiYdReOHiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/16ad8489/attachment.pl>

From gunter.berton at gene.com  Wed Jul 10 01:33:57 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 9 Jul 2013 16:33:57 -0700
Subject: [R] Same plot size with mfrow()
In-Reply-To: <CABnkouqh+gZ61sPJc8mYeOppaqzO5TH1Qqqfk8vuqiYdReOHiw@mail.gmail.com>
References: <CABnkouqh+gZ61sPJc8mYeOppaqzO5TH1Qqqfk8vuqiYdReOHiw@mail.gmail.com>
Message-ID: <CACk-te0R1Ar38Oxiw_n0Qf5o7hxO-_h9TmZsO+4LzcUrW6AG2A@mail.gmail.com>

It is hard to know what to recommend, as you don't give us any context.

If the plots are interrelated in certain ways, lattice and ggplot both
provide conditioning plots.Check vignettes and documentation for these
packages.

For base graphics, ?layout may be what you want.

Cheers,
Bert

On Tue, Jul 9, 2013 at 3:23 PM, Charlie Brown
<charliethebrown77 at gmail.com> wrote:
> Hello,
>
> I want to plot similar to the example below.  I want to remove the X and Y
> axis labels to avoid redundancy, but then want to make the spaces between
> plots smaller.  When I do this (see below), I end up with plots of
> different sizes (I want the plots to be exactly the same dimensions).
>  Could someone help me with this multiple plot setup, I'm sure this is way
> too complicated and simpler code will accomplish my goals.  Thanks, Charlie
>
>
> png("example.png", height=1000, width=1500)
>
> par(mfrow=c(2, 2), cex=2, cex.lab=1.5, cex.axis=1.5, cex.main=2, mgp=c(3,
> 1, 0), omi=c(3, 5, 2, 1))
>
> par(mar=c(1, 5, 2, 1)+0.1)
> plot(c(1:100), c(1:100), xaxt="n", ylab="Y-label 1")
>
> par(mar=c(1, 1, 2, 1)+0.1)
> plot(c(1:100), c(1:100), xaxt="n", yaxt="n")
>
> par(mar=c(5, 5, 1, 1)+0.1)
> plot(c(1:100), c(1:100), xlab="X-label", ylab="Y-label 2")
>
> par(mar=c(5, 1, 1, 1)+0.1)
> plot(c(1:100), c(1:100), yaxt="n", xlab="X-label 2")
>
> dev.off()
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From charliethebrown77 at gmail.com  Wed Jul 10 01:57:13 2013
From: charliethebrown77 at gmail.com (Charlie Brown)
Date: Tue, 9 Jul 2013 18:57:13 -0500
Subject: [R] Same plot size with mfrow()
In-Reply-To: <CACk-te0R1Ar38Oxiw_n0Qf5o7hxO-_h9TmZsO+4LzcUrW6AG2A@mail.gmail.com>
References: <CABnkouqh+gZ61sPJc8mYeOppaqzO5TH1Qqqfk8vuqiYdReOHiw@mail.gmail.com>
	<CACk-te0R1Ar38Oxiw_n0Qf5o7hxO-_h9TmZsO+4LzcUrW6AG2A@mail.gmail.com>
Message-ID: <CABnkouqOAwO2MtgvYXyvnRncsXCaq71wGON6PXbCeur_U-pxDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/a4ba29a1/attachment.pl>

From dwinsemius at comcast.net  Wed Jul 10 02:12:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 Jul 2013 17:12:46 -0700
Subject: [R] Same plot size with mfrow()
In-Reply-To: <CABnkouqh+gZ61sPJc8mYeOppaqzO5TH1Qqqfk8vuqiYdReOHiw@mail.gmail.com>
References: <CABnkouqh+gZ61sPJc8mYeOppaqzO5TH1Qqqfk8vuqiYdReOHiw@mail.gmail.com>
Message-ID: <0823AD20-5020-46EF-A9C4-3CB730C17E90@comcast.net>


On Jul 9, 2013, at 3:23 PM, Charlie Brown wrote:

> Hello,
> 
> I want to plot similar to the example below.  I want to remove the X and Y
> axis labels to avoid redundancy, but then want to make the spaces between
> plots smaller.  When I do this (see below), I end up with plots of
> different sizes (I want the plots to be exactly the same dimensions).
> Could someone help me with this multiple plot setup, I'm sure this is way
> too complicated and simpler code will accomplish my goals.  Thanks, Charlie
> 
> 
> png("example.png", height=1000, width=1500)
> 
> par(mfrow=c(2, 2), cex=2, cex.lab=1.5, cex.axis=1.5, cex.main=2, mgp=c(3,
> 1, 0), omi=c(3, 5, 2, 1))

Those omi values aRE TOO LARGE.
> 
> par(mar=c(1, 5, 2, 1)+0.1)
> plot(c(1:100), c(1:100), xaxt="n", ylab="Y-label 1")
> 
> par(mar=c(1, 1, 2, 1)+0.1)
> plot(c(1:100), c(1:100), xaxt="n", yaxt="n")
> 
> par(mar=c(5, 5, 1, 1)+0.1)
> plot(c(1:100), c(1:100), xlab="X-label", ylab="Y-label 2")
> 
> par(mar=c(5, 1, 1, 1)+0.1)
> plot(c(1:100), c(1:100), yaxt="n", xlab="X-label 2")
> 
> dev.off()

png("example.png", height=1000, width=1500)

par(mfrow=c(2, 2), cex=2, cex.lab=1.5, cex.axis=1.5, cex.main=2, mgp=c(3,
1, 0), omi=c(2,1,1, 1), pin=c(5,4) )  # attempting to force equal sized plot dimensions
plot(c(1:100), c(1:100), xaxt="n", ylab="Y-label 1")
plot(c(1:100), c(1:100), xaxt="n", yaxt="n", ylab="")
plot(c(1:100), c(1:100), xlab="X-label", ylab="Y-label 2")
plot(c(1:100), c(1:100), yaxt="n", xlab="X-label 2", ylab="")

dev.off()


Closer, but if you wnat control over the axis labeling to avoid the irregular gaps, you need to use the `axis` function.


> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dtenenba at fhcrc.org  Wed Jul 10 02:02:41 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 9 Jul 2013 17:02:41 -0700
Subject: [R] install.packages umask configuration
Message-ID: <CAF42j22VE=bpyVfFPqoikEb73Q6pNR14tTZB+5tAoPjJvLYuvg@mail.gmail.com>

Hi,

The R-admin manual says:

"If installing packages on a Unix-alike to be used by other users,
ensure that the system umask is set to give sufficient permissions
(see also Sys.umask in R). (To a large extent this is unnecessary in
recent versions of R, which install packages as if umask = 022.)"

I want install.packages() to honor my umask which is 002. I can't find
a way to do that; is it possible?

My goal is for any user in a specific group to be able to update
packages installed by any other user in that group. (This is on an
Ubuntu machine.)

I've also tried setting a recursive acl on $R_HOME/library in which
group write permission is always set, but install.packages() does not
seem to honor that.

(For the record, this question was asked before
(https://stat.ethz.ch/pipermail/r-help/2012-August/321839.html) but
not answered.)

Thanks,
Dan


From david.stevens at usu.edu  Wed Jul 10 06:36:26 2013
From: david.stevens at usu.edu (David Stevens)
Date: Tue, 09 Jul 2013 22:36:26 -0600
Subject: [R] Axis scaling for pairs plots
In-Reply-To: <9EB6C747-1762-4907-9B38-53BC194F69A5@comcast.net>
References: <1372189250.21293.YahooMailNeo@web171501.mail.ir2.yahoo.com>
	<9EB6C747-1762-4907-9B38-53BC194F69A5@comcast.net>
Message-ID: <51DCE4CA.3090404@usu.edu>

I have a question concerning axis scaling for pairs plots. My data set 
has columns with differing units and I want a pairs plot with scatter+an 
lm line+a correlation confidence ellipse for each lower panel. The 95% 
confidence ellipse (using the ellipse package+a polygon) gives me an 
ellipse that can extend well beyond the axis limits. At times I'll want 
the entire ellipse in the panel with the points range squeezed 
accordingly. The panel.ellipse function I wrote looks like this:

panel.ellipse <- function (x, y, col = par("col"), bg = NA, pch = 
par("pch"),
     cex = 1, ...)
{
     points(x, y, pch = pch, col = col, bg = bg, cex = cex)
     ok <- is.finite(x) & is.finite(y)
     if (any(ok)) {
       xy.lm <- lm(y~x)
       abline(xy.lm,col='lightgrey')
       require(ellipse)
       ell <- ellipse(cor(x,y), level = 0.95, scale = c(sd(x),sd(y)), 
centre = c(mean(x),mean(y)))
       polygon(ell,border='red')
     }
}

with the pairs command:
   pairs(df.c,pch=19,
     lower.panel=panel.ellipse,
     diag.panel=panel.hist,upper.panel=panel.cor)

Is this possible to do?

(R 15.2)

Regards

David S

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From dwinsemius at comcast.net  Wed Jul 10 06:50:00 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 9 Jul 2013 21:50:00 -0700
Subject: [R] Same plot size with mfrow()
In-Reply-To: <0823AD20-5020-46EF-A9C4-3CB730C17E90@comcast.net>
References: <CABnkouqh+gZ61sPJc8mYeOppaqzO5TH1Qqqfk8vuqiYdReOHiw@mail.gmail.com>
	<0823AD20-5020-46EF-A9C4-3CB730C17E90@comcast.net>
Message-ID: <3EF95F7C-FA72-44C1-96DF-4AFA8FFE9C12@comcast.net>


On Jul 9, 2013, at 5:12 PM, David Winsemius wrote:

> 
> On Jul 9, 2013, at 3:23 PM, Charlie Brown wrote:
> 
>> Hello,
>> 
>> I want to plot similar to the example below.  I want to remove the X and Y
>> axis labels to avoid redundancy, but then want to make the spaces between
>> plots smaller.  When I do this (see below), I end up with plots of
>> different sizes (I want the plots to be exactly the same dimensions).
>> Could someone help me with this multiple plot setup, I'm sure this is way
>> too complicated and simpler code will accomplish my goals.  Thanks, Charlie
>> 
>> 
>> png("example.png", height=1000, width=1500)
>> 
>> par(mfrow=c(2, 2), cex=2, cex.lab=1.5, cex.axis=1.5, cex.main=2, mgp=c(3,
>> 1, 0), omi=c(3, 5, 2, 1))
> 
> Those omi values aRE TOO LARGE.
>> 
>> par(mar=c(1, 5, 2, 1)+0.1)
>> plot(c(1:100), c(1:100), xaxt="n", ylab="Y-label 1")
>> 
>> par(mar=c(1, 1, 2, 1)+0.1)
>> plot(c(1:100), c(1:100), xaxt="n", yaxt="n")
>> 
>> par(mar=c(5, 5, 1, 1)+0.1)
>> plot(c(1:100), c(1:100), xlab="X-label", ylab="Y-label 2")
>> 
>> par(mar=c(5, 1, 1, 1)+0.1)
>> plot(c(1:100), c(1:100), yaxt="n", xlab="X-label 2")
>> 
>> dev.off()
> 
> png("example.png", height=1000, width=1500)
> 
> par(mfrow=c(2, 2), cex=2, cex.lab=1.5, cex.axis=1.5, cex.main=2, mgp=c(3,
> 1, 0), omi=c(2,1,1, 1), pin=c(5,4) )  # attempting to force equal sized plot dimensions
> plot(c(1:100), c(1:100), xaxt="n", ylab="Y-label 1")
> plot(c(1:100), c(1:100), xaxt="n", yaxt="n", ylab="")
> plot(c(1:100), c(1:100), xlab="X-label", ylab="Y-label 2")
> plot(c(1:100), c(1:100), yaxt="n", xlab="X-label 2", ylab="")
> 
> dev.off()

Another effort, using varying mar parameters.

png("example.png", height=1000, width=1500)
 par(mfrow=c(2, 2), cex=2, cex.lab=1.3, cex.axis=1.3, cex.main=2,
    omi=c(.5,.5,.5,.5), mar=c(4,4,0,.2), xpd=TRUE )
 plot(c(1:100), c(1:100), xaxt="n", ylab="Y-label 1", xlab="")
 plot(c(1:100), c(1:100), xaxt="n", yaxt="n", ylab="",xlab="");par(mar=c(4,4,0,0))
 plot(c(1:100), c(1:100), xlab="X-label", ylab="Y-label 2");par(mar=c(4,4,0,0))
 plot(c(1:100), c(1:100), yaxt="n", xlab="X-label 2", ylab="")
 dev.off()


-- 
David Winsemius
Alameda, CA, USA


From petr.pikal at precheza.cz  Wed Jul 10 08:35:26 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 10 Jul 2013 06:35:26 +0000
Subject: [R] spped up a function
In-Reply-To: <1373400143.37646.YahooMailNeo@web160805.mail.bf1.yahoo.com>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CB97@SRVEXCHMBX.precheza.cz>
	<1373352766.36843.YahooMailNeo@web160805.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE20@SRVEXCHMBX.precheza.cz>
	<1373400143.37646.YahooMailNeo@web160805.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7D11A@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/a72e148e/attachment.pl>

From gundalav at gmail.com  Wed Jul 10 09:02:33 2013
From: gundalav at gmail.com (Gundala Viswanath)
Date: Wed, 10 Jul 2013 16:02:33 +0900
Subject: [R] Replacing part of delimited string with R's regex
Message-ID: <CADVKSzz=eMkmJq18dWDDxdE3GB8UuWAvTxYNGYvRS-oPHZZsMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/a1c34d2c/attachment.pl>

From dwinsemius at comcast.net  Wed Jul 10 10:05:37 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jul 2013 01:05:37 -0700
Subject: [R] Replacing part of delimited string with R's regex
In-Reply-To: <CADVKSzz=eMkmJq18dWDDxdE3GB8UuWAvTxYNGYvRS-oPHZZsMQ@mail.gmail.com>
References: <CADVKSzz=eMkmJq18dWDDxdE3GB8UuWAvTxYNGYvRS-oPHZZsMQ@mail.gmail.com>
Message-ID: <50008A75-E381-4DE4-9D5A-26D037D6D930@comcast.net>


On Jul 10, 2013, at 12:02 AM, Gundala Viswanath wrote:

> I have the following list of strings:
> 
> name <- c("hsa-miR-555p","hsa-miR-519b-3p","hsa-let-7a")
> 
> What I want to do is for each of the above strings
> replace the text after second delimiter with "zzz".
> Yielding:
> 
> hsa-miR-zzz
> hsa-miR-zzz
> hsa-let-zzz

?regex

Look at sections on character classe, repetition quantifiers, and back references.

> sub("(^[^-]*-[^-]*-)(.*$)", "\\1zzz", name)
[1] "hsa-miR-zzz" "hsa-miR-zzz" "hsa-let-zzz"

-- 
David Winsemius
Alameda, CA, USA


From antony.akkara at ge.com  Wed Jul 10 07:48:25 2013
From: antony.akkara at ge.com (R_Antony)
Date: Tue, 9 Jul 2013 22:48:25 -0700 (PDT)
Subject: [R] Filter Dataframe for Alarm for particular column(s).
In-Reply-To: <1373051800.36586.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1373038692448-4670950.post@n4.nabble.com>
	<1373051800.36586.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <5A52F9658B4B8C4B83D50A7BAD38F5D602C3515F@BANMLVEM04.e2k.ad.ge.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130709/a15e77f8/attachment.pl>

From lbajuk at tibco.com  Wed Jul 10 11:42:04 2013
From: lbajuk at tibco.com (Louis Bajuk-Yorgan)
Date: Wed, 10 Jul 2013 09:42:04 +0000
Subject: [R] Announcing TIBCO Enterprise Runtime for R
Message-ID: <46AAEC13-6D0D-4DF8-A4F0-F90546E0F28B@tibco.com>

In honor of the kickoff of useR 2013 today, I'm proud to announce the availability of TIBCO Enterprise Runtime for R (or TERR for short), our new enterprise-grade, high-performance statistical engine, fully compatible with the R language.

For more information on TERR, and a link to download the free Developer's Edition via the TERR Community site, check out http://spotfire.tibco.com/terr--or come to my talk at useR on Thursday morning.

As part of our development of TERR, we have also contributed new packages to CRAN: sjdbc (a JDBC driver interface, previously developed for S-PLUS) and tibbrConnector (an R interface to tibbr, TIBCO's Social Network for the Enterprise).

----------------------------------
Lou Bajuk-Yorgan
@loubajuk
TIBCO Spotfire


From S.Ellison at lgcgroup.com  Wed Jul 10 12:39:10 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 10 Jul 2013 11:39:10 +0100
Subject: [R] Kriging Package Cryptic Error Message
In-Reply-To: <CAH03yymJyccOr-ZFGMJ==T86S0UiGxGH9krtZ2dhuhbJ=UaGEw@mail.gmail.com>
References: <CAH03yymJyccOr-ZFGMJ==T86S0UiGxGH9krtZ2dhuhbJ=UaGEw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACB8A62F3@GOLD.corp.lgc-group.com>

Try initial fitting with fewer lags; I get a fit to your data with lags=3.

S Ellison
 

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Diego Ubuntu
> Sent: 06 July 2013 16:09
> To: r-help at r-project.org
> Subject: [R] Kriging Package Cryptic Error Message
> 
> I'm trying to get a kriging surface using these data, but I 
> only get this error message. Any ideas on why or how to solve it.
> >d
>           x       y      e
> 1  551595.2 1804062    2.0
> 2  599591.7 1820823    2.0
> 3  615604.7 1820903    2.0
> 4  612337.6 1770989    2.1
> 5  614203.6 1761816    3.0
> 6  514248.6 1739406   26.0
> 7  448250.4 1737691    3.0
> 8  399904.6 1708316   31.0
> 9  487431.4 1676800  670.0
> 10 614769.4 1647540  442.0
> 11 485710.4 1673041    0.0
> 12 308095.1 1635087 1079.0
> 13 374141.7 1583102 1674.0
> 14 483754.7 1472197   48.0
> 15 433475.7 1588404  628.0
> 16 476571.0 1553267 1007.0
> 17 433480.4 1590174  628.0
> 18 264654.0 1596733  626.0
> 19 431438.7 1470399    5.0
> 20 429587.9 1466754    5.0
> 
> >kriging(d$x,d$y,d$e)
> Error in krig.fit(D, nugget, range, sill, model, n) :
>   NA/NaN/Inf in foreign function call (arg 3)
> 
> Thanks
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From smriti.sebastuan at gmail.com  Wed Jul 10 13:13:30 2013
From: smriti.sebastuan at gmail.com (smriti Sebastian)
Date: Wed, 10 Jul 2013 16:43:30 +0530
Subject: [R] find 2D corelation coefficient
Message-ID: <CAKpT9HvboDvFfwj-p=8s-Z0HG15xWWScmwYfNcDRJ5jUWOYZEQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/1c8a00c1/attachment.pl>

From sid.arun91 at gmail.com  Wed Jul 10 13:49:54 2013
From: sid.arun91 at gmail.com (siddharth arun)
Date: Wed, 10 Jul 2013 17:19:54 +0530
Subject: [R] Handling large R objects and limitation by RAM
Message-ID: <CADym=9UA-cPgcwhmaVeZ45LD86XCBOwk=FeTxeo9yOvmWD=faQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/5c8e9b1c/attachment.pl>

From sid.arun91 at gmail.com  Wed Jul 10 13:49:54 2013
From: sid.arun91 at gmail.com (siddharth arun)
Date: Wed, 10 Jul 2013 17:19:54 +0530
Subject: [R] Handling large R objects and limitation by RAM
Message-ID: <CADym=9UA-cPgcwhmaVeZ45LD86XCBOwk=FeTxeo9yOvmWD=faQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/5c8e9b1c/attachment-0001.pl>

From smartpink111 at yahoo.com  Wed Jul 10 13:52:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 10 Jul 2013 04:52:28 -0700 (PDT)
Subject: [R] Replacing part of delimited string with R's regex
In-Reply-To: <CADVKSzz=eMkmJq18dWDDxdE3GB8UuWAvTxYNGYvRS-oPHZZsMQ@mail.gmail.com>
References: <CADVKSzz=eMkmJq18dWDDxdE3GB8UuWAvTxYNGYvRS-oPHZZsMQ@mail.gmail.com>
Message-ID: <1373457148.4175.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi
You could use:
?gsub("([[:alnum:]]+-)([[:alnum:]]+-)(.*)","\\1\\2zzz",name)
#[1] "hsa-miR-zzz" "hsa-miR-zzz" "hsa-let-zzz"
A.K.




----- Original Message -----
From: Gundala Viswanath <gundalav at gmail.com>
To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Cc: 
Sent: Wednesday, July 10, 2013 3:02 AM
Subject: [R] Replacing part of delimited string with R's regex

I have the following list of strings:

name <- c("hsa-miR-555p","hsa-miR-519b-3p","hsa-let-7a")

What I want to do is for each of the above strings
replace the text after second delimiter with "zzz".
Yielding:

hsa-miR-zzz
hsa-miR-zzz
hsa-let-zzz

What's the way to do it?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pdalgd at gmail.com  Wed Jul 10 13:52:25 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 10 Jul 2013 13:52:25 +0200
Subject: [R] find 2D corelation coefficient
In-Reply-To: <CAKpT9HvboDvFfwj-p=8s-Z0HG15xWWScmwYfNcDRJ5jUWOYZEQ@mail.gmail.com>
References: <CAKpT9HvboDvFfwj-p=8s-Z0HG15xWWScmwYfNcDRJ5jUWOYZEQ@mail.gmail.com>
Message-ID: <C6E834AC-DF1F-4DCE-B0F9-3E31123467C5@gmail.com>


On Jul 10, 2013, at 13:13 , smriti Sebastian wrote:

> Plz c this link
> http://www.mathworks.in/help/images/ref/corr2.html
> 

That's for comparing images. Are your data images?


> 
> On Tue, Jul 9, 2013 at 3:43 PM, smriti Sebastian <smriti.sebastuan at gmail.com
>> wrote:
> 
>> Two dimensional corelation coefficient-2D corelation between (x,y) and
>> (x1,y1) where x and x1 are same.
>> 
>> 
>> On Tue, Jul 9, 2013 at 2:27 PM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>>> 
>>> On Jul 9, 2013, at 07:30 , smriti Sebastian wrote:
>>> 
>>>> I need to find the 2d corelation betwee two datasets which are having
>>>> common x-values.Is there any way to find 2D corelation in R?
>>> 
>>> 
>>> If you can tell us what the definition is....
>>> 
>>> --
>>> Peter Dalgaard, Professor
>>> Center for Statistics, Copenhagen Business School
>>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>>> Phone: (+45)38153501
>>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>> 
>>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smartpink111 at yahoo.com  Wed Jul 10 14:24:27 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 10 Jul 2013 05:24:27 -0700 (PDT)
Subject: [R] Kruskal.test
In-Reply-To: <CAHc7oGHA=f9mORssrU5YEh+aoRzX1+fWQPsgDRm4FxE9O9mQiA@mail.gmail.com>
References: <11494491.311764.1373393429407.JavaMail.nabble@joe.nabble.com>
	<CAHc7oGGZ==Us=-tV6qQ4h2wn93r3CmgsFbndycLL4DPW2XaFnA@mail.gmail.com>
	<1373394564.51384.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAHc7oGFXjv-5ubDOocy-bWXQcWm4vr969RTmENv7xc2pxSjP+w@mail.gmail.com>
	<1373395191.25374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAHc7oGG3KrPA3oc6z13+fjQg+vYFcurnQ0PgSeLG6PTUSAcCNw@mail.gmail.com>
	<1373395739.56187.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAHc7oGFV-+p00ET4aM02maCAxK0KkEbU+h4Wfh3t3Rt0MAp_Yw@mail.gmail.com>
	<1373397473.79930.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAHc7oGHA=f9mORssrU5YEh+aoRzX1+fWQPsgDRm4FxE9O9mQiA@mail.gmail.com>
Message-ID: <1373459067.39099.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
Please dput() your example dataset.

dat1<- read.table(text="a?? a?? a?? a??? a??? b?? b??? b??? c??? c?? c??? c
2? 4??? 5?? 2??? 7??? 2?? 2??? 6??? 3??? 7?? 9??? 3
3? 3?? 4?? 1???? 6??? 8?? 1??? 3??? 5??? 2??? 6??? 3",sep="",header=FALSE,stringsAsFactors=FALSE)
library(reshape)
?dat2<-melt(as.data.frame(t(dat1)),id.var="V1")[,-2]
kruskal.test(value~V1,data=dat2)
#
#??? Kruskal-Wallis rank sum test
#
#data:? value by V1
#Kruskal-Wallis chi-squared = 1.2888, df = 2, p-value = 0.525

#I guess you wanted for each row:
lapply(split(dat2,(seq_len(nrow(dat2))-1)%/%ncol(dat1)+1),function(x) kruskal.test(value~V1,data=x))
#$`1`
#
#??? Kruskal-Wallis rank sum test
#
#data:? value by V1
#Kruskal-Wallis chi-squared = 2.003, df = 2, p-value = 0.3673
#

#$`2`

#??? Kruskal-Wallis rank sum test

#data:? value by V1
#Kruskal-Wallis chi-squared = 0.1231, df = 2, p-value = 0.9403



A.K.

________________________________
From: Vera Costa <veracosta.rt at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, July 10, 2013 6:38 AM
Subject: Re: Kruskal.test



Thank you. 
And if I have 

a ? a ? a ? a ? ?a ? ?b ? b ? ?b ? ?c ? ?c ? c ? ?c
2 ?4 ? ?5 ? 2 ? ?7 ? ?2 ? 2 ? ?6 ? ?3 ? ?7 ? 9 ? ?3
3??3?? 4?? 1???? 6??? 8???1??? 3??? 5??? 2??? 6??? 3?? ?

How can I apply the test by row?

Thank you


From raindrop2bird at gmail.com  Wed Jul 10 12:29:59 2013
From: raindrop2bird at gmail.com (Xiaoyu Lu)
Date: Wed, 10 Jul 2013 11:29:59 +0100
Subject: [R] find a function for a random curve
Message-ID: <CAObCoN6GuCeOKgK3-WH6XsjnO=Jky1oJLir4g=zXVcA92Lyzjw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/3bad10b8/attachment.pl>

From fsantos at ujaen.es  Wed Jul 10 15:10:05 2013
From: fsantos at ujaen.es (fsantos at ujaen.es)
Date: Wed, 10 Jul 2013 15:10:05 +0200 (CEST)
Subject: [R] Canonical Correlation Analysis for three fields
Message-ID: <d86eb331f47529e6bcc315fc384c21ba.squirrel@webmail.ujaen.es>

Dear R community,

I was wondering if it is possible to adapt the CCA methodology for three
set of variables. Could you give me some suggestions?

Regards,

Francisco


From S.Ellison at lgcgroup.com  Wed Jul 10 15:51:10 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 10 Jul 2013 14:51:10 +0100
Subject: [R] find a function for a random curve
In-Reply-To: <CAObCoN6GuCeOKgK3-WH6XsjnO=Jky1oJLir4g=zXVcA92Lyzjw@mail.gmail.com>
References: <CAObCoN6GuCeOKgK3-WH6XsjnO=Jky1oJLir4g=zXVcA92Lyzjw@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACB8A648B@GOLD.corp.lgc-group.com>

> I want to find a functional form for my data. I have tried 
> smoothing and obtained a kinda perfect fit.
> However, I can only draw it but cannot call it.
You'll need to apply the smoothing function to the data separately, store that and plot the curve (?) fom that.

You can plot a line for many model fits using the associated predict() method and if necessary specifying a newdata data frame containing neatly-spaced predictors; look up the generic ?predict and predict.lm for a typical case. predict.nlm and predict.loess also exist and work much the same way. 

S Ellison 


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From canamika at gmail.com  Wed Jul 10 15:52:36 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Wed, 10 Jul 2013 09:52:36 -0400
Subject: [R] Bivariate Tolerance Region
Message-ID: <CALv--dbDu_1k5WOV=OQDeioTnY0LCQApq4gGK-cvbTnxVER-zw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/6b6678a6/attachment.pl>

From ashz at walla.co.il  Wed Jul 10 15:09:00 2013
From: ashz at walla.co.il (ashz)
Date: Wed, 10 Jul 2013 06:09:00 -0700 (PDT)
Subject: [R] PCA and gglot2
Message-ID: <1373461740917-4671225.post@n4.nabble.com>

Hi,

I was trying as well as looking for an answer without success (a bit strange
since it should be an easy problem) and therefore I will appreciate you
help:

My simple script is:
# Loadings data of 5 columns and 100 rows of data
data1<-read.csv("C:/?/MyPCA.csv")
pairs(data1[,1:4])
pca1 <- princomp(data1[,1:4], score=TRUE, cor=TRUE)
biplot(pca1)

The biplot present the data points as numbers. How can I present the data
point in color (depends on their group-column 5). I was thinking about doing
it using ggplot2 but I can not succeed. Any idea how to do it?

Thanks 



--
View this message in context: http://r.789695.n4.nabble.com/PCA-and-gglot2-tp4671225.html
Sent from the R help mailing list archive at Nabble.com.


From ema.belli93 at gmail.com  Wed Jul 10 16:04:10 2013
From: ema.belli93 at gmail.com (Emanuele Belli)
Date: Wed, 10 Jul 2013 16:04:10 +0200
Subject: [R] Error message
Message-ID: <1C30E1F5-3D7B-432C-9C8D-8FB0120C8BD4@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/17f35f30/attachment.pl>

From ripley at stats.ox.ac.uk  Wed Jul 10 16:40:28 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 10 Jul 2013 15:40:28 +0100
Subject: [R] Error message
In-Reply-To: <1C30E1F5-3D7B-432C-9C8D-8FB0120C8BD4@gmail.com>
References: <1C30E1F5-3D7B-432C-9C8D-8FB0120C8BD4@gmail.com>
Message-ID: <51DD725C.1060200@stats.ox.ac.uk>

On 10/07/2013 15:04, Emanuele Belli wrote:
> Hello,
> I'm an italian student, I've got some problems using R:
> After calculating a dbinom() function, my  "help.start()" started not to work.
> If I type on the console "Help.start", it says me "starting httpd help server ...Errore in stats::runif(10) :
>    .Random.seed is not an integer vector but of type 'double'"
>
> I tried to upgrade, unistall, but anything, it was impossible to solve this problem.
> Can you help me?

Try

rm(.Random.seed)

Looks like you saved an object of the wrong type under than name.

> Thank you in advance,
>
> Emanuele
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From nashjc at uottawa.ca  Wed Jul 10 16:55:42 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Wed, 10 Jul 2013 10:55:42 -0400
Subject: [R] fitting log function: errors using nls and nlxb
In-Reply-To: <mailman.21.1373450407.8310.r-help@r-project.org>
References: <mailman.21.1373450407.8310.r-help@r-project.org>
Message-ID: <51DD75EE.3050209@uottawa.ca>

This reply only addresses the NaN in Jacobian matter. I believe it is a 
result of getting a perfect fit (0 sum of squares). I have amended the 
r-forge version of nlmrt package in routines nlfb and nlxb and did not 
get the error running Elizabeth's example. This only answers the 
software issue, of course, not the statistical one.

Use the version of nlmrt from the SCM repository on
https://r-forge.r-project.org/R/?group_id=395

or email me for a tarball of this.

JN


On 13-07-10 06:00 AM, r-help-request at r-project.org wrote:
> On Mon, Jul 8, 2013 at 9:27 PM, Elizabeth Webb
> <webb.elizabeth.e at gmail.com>wrote:
>> >Hi-
>> >I am trying to fit a log function to my data, with the ultimate goal of
>> >finding the second derivative of the function.  However, I am stalled on
>> >the first step of fitting a curve.
>> >
>> >When I use the following code:
>> >FG2.model<-(nls((CO2~log(a*Time)+b), start=setNames(coef(lm(CO2 ~
>> >log(Time), data=FG2)), c("a", "b")),data=FG2))
>> >I get the following error:
>> >Error in numericDeriv(form[[3L]], names(ind), env) :
>> >   Missing value or an infinity produced when evaluating the model
>> >In addition: Warning messages:
>> >1: In min(x) : no non-missing arguments to min; returning Inf
>> >2: In max(x) : no non-missing arguments to max; returning -Inf
>> >3: In log(a * Time) : NaNs produced
>> >4: In log(a * Time) : NaNs produced
>> >
>> >When I fit the curve in Plot and use the coefficients as starting values:
>> >start=c(a=68,b=400)
>> >FG2.model<-(nls((CO2~log(a*Time)+b), start=start,data=FG2))
>> >I get the following error:
>> >Error in nls((CO2 ~ log(a * Time) + b), start = start, data = FG2) :
>> >   singular gradient
>> >In addition: Warning messages:
>> >1: In min(x) : no non-missing arguments to min; returning Inf
>> >2: In max(x) : no non-missing arguments to max; returning -Inf
>> >
>> >So then when I substituded nlxb for nls in the above two models, I got this
>> >error:
>> >Error in nlxb((CO2 ~ log(a * Time) + b), start = start, data = FG2) :
>> >   NaN in Jacobian
>> >


From jrkrideau at inbox.com  Wed Jul 10 17:09:59 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Jul 2013 07:09:59 -0800
Subject: [R] PCA and gglot2
In-Reply-To: <1373461740917-4671225.post@n4.nabble.com>
Message-ID: <B539FAE48D0.00001165jrkrideau@inbox.com>

It looks like you can if I understand properly. Try this
dat1  <-  data.frame(dat1$scores)
dat1$items  <-  rownames(data1)
ggplot(dat1, aes(Comp.1, Comp.2, colour = items)) + geom_point() +
   theme(legend.position="none")


John Kane
Kingston ON Canada


> -----Original Message-----
> From: ashz at walla.co.il
> Sent: Wed, 10 Jul 2013 06:09:00 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] PCA and gglot2
> 
> Hi,
> 
> I was trying as well as looking for an answer without success (a bit
> strange
> since it should be an easy problem) and therefore I will appreciate you
> help:
> 
> My simple script is:
> # Loadings data of 5 columns and 100 rows of data
> data1<-read.csv("C:/?/MyPCA.csv")
> pairs(data1[,1:4])
> pca1 <- princomp(data1[,1:4], score=TRUE, cor=TRUE)
> biplot(pca1)
> 
> The biplot present the data points as numbers. How can I present the data
> point in color (depends on their group-column 5). I was thinking about
> doing
> it using ggplot2 but I can not succeed. Any idea how to do it?
> 
> Thanks
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/PCA-and-gglot2-tp4671225.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From HDoran at air.org  Wed Jul 10 17:42:11 2013
From: HDoran at air.org (Doran, Harold)
Date: Wed, 10 Jul 2013 15:42:11 +0000
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6862453A833@DC1VEX10MB001.air.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/4c2743cf/attachment.pl>

From S.Ellison at LGCGroup.com  Wed Jul 10 18:49:42 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 10 Jul 2013 17:49:42 +0100
Subject: [R] PCA and gglot2
In-Reply-To: <B539FAE48D0.00001165jrkrideau@inbox.com>
References: <1373461740917-4671225.post@n4.nabble.com>
	<B539FAE48D0.00001165jrkrideau@inbox.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACB8A65E8@GOLD.corp.lgc-group.com>

> > The biplot present the data points as numbers. How can I 
> present the 
> > data point in color (depends on their group-column 5). I 
> was thinking 
> > about doing it using ggplot2 but I can not succeed. Any 
> idea how to do 
> > it?

Perhaps the post at
http://www.codesofmylife.com/2012/06/07/plotting-pca-results-with-ggplot2/

would help?
 
(as would googling "biplot in ggplot2", which is how I found it...)

Incidentally, if you want base graphics biplots with points and colour coding, you'd need to modify the biplot code a bit or roll your own. 

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From geyu625 at gmail.com  Wed Jul 10 17:37:56 2013
From: geyu625 at gmail.com (yu ge)
Date: Wed, 10 Jul 2013 10:37:56 -0500
Subject: [R] output ggplot2 graph from asp.net?
Message-ID: <CABzXcyhUhrsQ=VgtYqivOGDi=A+xVUHjPimgk=UGkdR9d7YPDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/46ae0182/attachment.pl>

From raphaelle.carraud at oc-metalchem.com  Wed Jul 10 16:21:56 2013
From: raphaelle.carraud at oc-metalchem.com (=?iso-8859-1?Q?Rapha=EBlle_Carraud?=)
Date: Wed, 10 Jul 2013 16:21:56 +0200
Subject: [R] Recherche de fonction
Message-ID: <4565B2277456ED4EB03CD34B21283B472067BE80DC@EXH01001.hmc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/9ea486a8/attachment.pl>

From f.harrell at Vanderbilt.Edu  Wed Jul 10 20:29:12 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Wed, 10 Jul 2013 13:29:12 -0500
Subject: [R] Appropriate forum for announcing R package updates
Message-ID: <51DDA7F8.5070309@vanderbilt.edu>

I have been confused about the appropriate e-mail address to use to make 
announcements to r-help for major package update.  In the past I've 
submitted to R-packages at lists.r-project.org without seeing the 
announcement appear on r-help.

Thanks for any guidance.
Frank

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From HDoran at air.org  Wed Jul 10 20:38:36 2013
From: HDoran at air.org (Doran, Harold)
Date: Wed, 10 Jul 2013 18:38:36 +0000
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6862453A833@DC1VEX10MB001.air.org>
References: <B08B6AF0CF8CA44F81B9983EEBDCD6862453A833@DC1VEX10MB001.air.org>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6862453AA2E@DC1VEX10MB001.air.org>

I have zero'd in on what appears to be the issue. This seems to be a bug in Matrix, but I am not sure yet. I am attaching files that would allow others to replicate this with my toy data.

Notice the elements of D1 in the attached data are all integers. It is a sparse, diagonal matrix.

> library(Matrix)
> class(D1)
[1] "ddiMatrix"
attr(,"package")
[1] "Matrix"

Now, I find the inverse of the matrix A as follows:
> A <- Ir + ZtZ %*% D1
> A.Inv <- solve(A, Ir)

Notice now the inverse of A remains a dgCMatrix and it is relatively small in size, only 33424 bytes.
> class(A.Inv)
[1] "dgCMatrix"
attr(,"package")
[1] "Matrix"

> object.size(A.Inv)
33424 bytes

Now, if I change an element of the matrix D1 to be non-integer, D1 still has the same class as it did before

> D1[1] <- 1.2

> class(D1)
[1] "ddiMatrix"
attr(,"package")
[1] "Matrix"

Now, if I use this new version of D1 in the same calculations as above, notice that A.Inv is no longer a dgCMatrix but instead becomes a dgeMatrix. It then increases from an object of size 33424 bytes to an object of size 2001112 bytes!

> A <- Ir + ZtZ %*% D1
> A.Inv <- solve(A, Ir)
> class(A.Inv)
[1] "dgeMatrix"
attr(,"package")
[1] "Matrix"
> object.size(A.Inv)
2001112 bytes

What I desire is that the object A.Inv remain sparse at all times and not become dense. But, perhaps there is a reason this change occurs that I don't fully understand.

I can of course coerce it back to a sparse matrix and it reduces back in size.
>  object.size(as(A.Inv, 'sparseMatrix'))
33424 bytes

I of course recognize it requires more memory to store floating points than integers, but is this large increase on the order of magnitude that seems about right? 

Is there a reason the floating point in D1 causes for A.Inv to no longer remain sparse?

Thank you for your help,
Harold





-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: Wednesday, July 10, 2013 11:42 AM
To: r-help at r-project.org
Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
Subject: [R] Sparse matrix no longer sparse (Matrix Package)

I have a large function computing an iterative algorithm for fitting mixed linear models. Almost all code relies on functions from the Matrix package. I've come across an issue that I do not believe previously occurred in earlier versions of R or Matrix.

I have a large, sparse matrix, A as

> class(A);dim(A)
[1] "dgCMatrix"
attr(,"package")
[1] "Matrix"
[1] 12312 12312

I am in a position where I must find its inverse.  I realize this is less than ideal, and I have two ways of doing this

A.Inv <- solve(A, Ir) or just solve(A)

Where Ir is an identity matrix with the same dimensions as A and it is also sparse

> class(Ir)
[1] "ddiMatrix"
attr(,"package")
[1] "Matrix"

The issue, however, is that the inverse of A is converted into a dense matrix and this becomes a huge memory hog, causing the rest of the algorithm to fail. In prior versions this remained as a sparse matrix.

> A.Inv[1:5, 1:5]
5 x 5 Matrix of class "dgeMatrix"
          [,1]      [,2]      [,3]      [,4]      [,5]
[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,] 0.0000000 0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000 0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000 0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000 0.2139975

I could coerce this matrix to become sparse such as

> AA <- as(A.Inv, 'sparseMatrix')
> class(AA)
[1] "dgCMatrix"
attr(,"package")
[1] "Matrix"

> AA[1:5, 1:5]
5 x 5 sparse Matrix of class "dgCMatrix"

[1,] 0.6878713 .         .         .         .
[2,] .         0.6718767 .         .         .
[3,] .         .         0.5076945 .         .
[4,] .         .         .         0.2324122 .
[5,] .         .         .         .         0.2139975

But I don't think this is best.

So, my question is why is a matrix that is sparse turning into a dense matrix? Can I avoid that and keep it sparse without having to coerce it to be sparse after it is created?

Thank you very much
Harold


> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C [5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15

loaded via a namespace (and not attached):
[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From bhh at xs4all.nl  Wed Jul 10 20:42:11 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 10 Jul 2013 20:42:11 +0200
Subject: [R] Recherche de fonction
In-Reply-To: <4565B2277456ED4EB03CD34B21283B472067BE80DC@EXH01001.hmc.local>
References: <4565B2277456ED4EB03CD34B21283B472067BE80DC@EXH01001.hmc.local>
Message-ID: <DF22D4DD-A6CD-4D07-97E5-1C352AA24B29@xs4all.nl>


On 10-07-2013, at 16:21, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Bonjour,
> 
> Je souhaite  r?soudre le couple d'?quation diff?rentielles suivant :
> 
>    0 = -dA + dB + 2*dC - 2*r1 - 2*r5
>    0 = dA + dD + r1 + r4
>    0 = K2 - C/B^2
>    0 = K3 - D/(A*B)
> 
>    0 = r5 + 2*r4 - dE
>    0 = r5 -dI
>    0 = -r5 - r4 - dG
>    0 = -r1/2 - dH
> 
> en ayant connaissance des valeurs initiales de dA, dB, dC, dE, dI, dG, dH, r1, r2, r4, r5, K2, K3, A, B, C et D.
> 

If all initial values are known then plugging the values in the system will give 0 or not 0. There is nothing to "solve".

> J'ai essay? plusieurs fonctions mais comme je ne peux pas lui faire calculer une des d?riv?e de laquelle d?coulerait les autre, il n'arrive pas ? me fournir la solution.
> Je n'ai pas vu d'exemple qui pourrai s'assimiler ? celui-ci dans la documentation.
> 

You will have to redo your query in English. Questions in French won't receive many replies.
My French is rudimentary but I'll try.

You have 8 equations and 17 variables.
So how do you propose to "solve" the system?

Assuming that the d? variables are differentials and that you want to solve for those:
you have 7 of these and 8 equations. So how to solve?

But the third and fourth equations have no d? variables, so the may even be inconsistent given the values of K2, K3, C, B, A, D.
So you have 6 equations for 7 d? variables. So how do you propose to solve for the d? variables?

Finally your system seems to be linear in the d? variables. You would be able to use R's solve()  if you can get your system to be a square system.

If your system is not square and underdetermined then you can use a Moore Penrose inverse to get a minimum norm solution 
(http://en.wikipedia.org/wiki/Moore?Penrose_pseudoinverse#Minimum-norm_solution_to_a_linear_system).
package MASS provides a function ginv().

Berend

> Est-il possible de r?soudre ce probl?me sur R ?
> 
> Merci
> 
> Cordialement,
> Rapha?lle Carraud
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From marc_schwartz at me.com  Wed Jul 10 20:42:32 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 10 Jul 2013 13:42:32 -0500
Subject: [R] Appropriate forum for announcing R package updates
In-Reply-To: <51DDA7F8.5070309@vanderbilt.edu>
References: <51DDA7F8.5070309@vanderbilt.edu>
Message-ID: <0FFEB3A6-0730-408F-8D44-1F8623DD0635@me.com>

On Jul 10, 2013, at 1:29 PM, Frank Harrell <f.harrell at vanderbilt.edu> wrote:

> I have been confused about the appropriate e-mail address to use to make announcements to r-help for major package update.  In the past I've submitted to R-packages at lists.r-project.org without seeing the announcement appear on r-help.
> 
> Thanks for any guidance.
> Frank



Hi Frank,

R-packages (https://stat.ethz.ch/mailman/listinfo/r-packages) should be the correct list for those announcements.

A quick check of a few recent posts shows that they are being forwarded to R-Help as well.

It is however a low volume list. 116 posts in 2010, 77 in 2011, 72 in 2012 and 25 so far in 2013. The trend would seem to be downward.

Regards,

Marc Schwartz


From f.harrell at vanderbilt.edu  Wed Jul 10 20:46:51 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Wed, 10 Jul 2013 11:46:51 -0700 (PDT)
Subject: [R] Appropriate forum for announcing R package updates
In-Reply-To: <0FFEB3A6-0730-408F-8D44-1F8623DD0635@me.com>
References: <51DDA7F8.5070309@vanderbilt.edu>
	<0FFEB3A6-0730-408F-8D44-1F8623DD0635@me.com>
Message-ID: <1373482011901-4671242.post@n4.nabble.com>

Thank you Marc
Frank

Marc Schwartz-3 wrote
> On Jul 10, 2013, at 1:29 PM, Frank Harrell &lt;

> f.harrell@

> &gt; wrote:
> 
>> I have been confused about the appropriate e-mail address to use to make
>> announcements to r-help for major package update.  In the past I've
>> submitted to 

> R-packages at .r-project

>  without seeing the announcement appear on r-help.
>> 
>> Thanks for any guidance.
>> Frank
> 
> 
> 
> Hi Frank,
> 
> R-packages (https://stat.ethz.ch/mailman/listinfo/r-packages) should be
> the correct list for those announcements.
> 
> A quick check of a few recent posts shows that they are being forwarded to
> R-Help as well.
> 
> It is however a low volume list. 116 posts in 2010, 77 in 2011, 72 in 2012
> and 25 so far in 2013. The trend would seem to be downward.
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





-----
Frank Harrell
Department of Biostatistics, Vanderbilt University
--
View this message in context: http://r.789695.n4.nabble.com/Appropriate-forum-for-announcing-R-package-updates-tp4671238p4671242.html
Sent from the R help mailing list archive at Nabble.com.


From h.mamaysky at gmail.com  Wed Jul 10 20:47:50 2013
From: h.mamaysky at gmail.com (Harry Mamaysky)
Date: Wed, 10 Jul 2013 14:47:50 -0400
Subject: [R] replacement functions for subsets
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
Message-ID: <6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/83082a4c/attachment.pl>

From ashz at walla.co.il  Wed Jul 10 20:02:11 2013
From: ashz at walla.co.il (ashz)
Date: Wed, 10 Jul 2013 11:02:11 -0700 (PDT)
Subject: [R] PCA and gglot2
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4ACB8A65E8@GOLD.corp.lgc-group.com>
References: <1373461740917-4671225.post@n4.nabble.com>
	<B539FAE48D0.00001165jrkrideau@inbox.com>
	<A4E5A0B016B8CB41A485FC629B633CED4ACB8A65E8@GOLD.corp.lgc-group.com>
Message-ID: <1373479331548-4671237.post@n4.nabble.com>

Hi,

Thanks. Fig 4 in the link you provided is what I am looking for.

I still do not know how to implement my data1 and pca1 in the script you
provided as I think it is only a part of a full script.
"
data1<-read.csv("C:/?/MyPCA.csv")
pca1 <- princomp(data1[,1:4], score=TRUE, cor=TRUE) 
"

Am I right, how can I implement my data.frames?

Thanks again



--
View this message in context: http://r.789695.n4.nabble.com/PCA-and-gglot2-tp4671225p4671237.html
Sent from the R help mailing list archive at Nabble.com.


From bhh at xs4all.nl  Wed Jul 10 21:02:28 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 10 Jul 2013 21:02:28 +0200
Subject: [R] Recherche de fonction
In-Reply-To: <DF22D4DD-A6CD-4D07-97E5-1C352AA24B29@xs4all.nl>
References: <4565B2277456ED4EB03CD34B21283B472067BE80DC@EXH01001.hmc.local>
	<DF22D4DD-A6CD-4D07-97E5-1C352AA24B29@xs4all.nl>
Message-ID: <CBB68FC6-ACAB-4CEF-983B-462F5FE4E96A@xs4all.nl>


On 10-07-2013, at 20:42, Berend Hasselman <bhh at xs4all.nl> wrote:

> 
> On 10-07-2013, at 16:21, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:
> 
>> Bonjour,
>> 
>> Je souhaite  r?soudre le couple d'?quation diff?rentielles suivant :
>> 
>>   0 = -dA + dB + 2*dC - 2*r1 - 2*r5
>>   0 = dA + dD + r1 + r4
>>   0 = K2 - C/B^2
>>   0 = K3 - D/(A*B)
>> 
>>   0 = r5 + 2*r4 - dE
>>   0 = r5 -dI
>>   0 = -r5 - r4 - dG
>>   0 = -r1/2 - dH
>> 
>> en ayant connaissance des valeurs initiales de dA, dB, dC, dE, dI, dG, dH, r1, r2, r4, r5, K2, K3, A, B, C et D.
>> 
> 
> If all initial values are known then plugging the values in the system will give 0 or not 0. There is nothing to "solve".
> 
>> J'ai essay? plusieurs fonctions mais comme je ne peux pas lui faire calculer une des d?riv?e de laquelle d?coulerait les autre, il n'arrive pas ? me fournir la solution.
>> Je n'ai pas vu d'exemple qui pourrai s'assimiler ? celui-ci dans la documentation.
>> 
> 
> You will have to redo your query in English. Questions in French won't receive many replies.
> My French is rudimentary but I'll try.
> 
> You have 8 equations and 17 variables.
> So how do you propose to "solve" the system?
> 
> Assuming that the d? variables are differentials and that you want to solve for those:
> you have 7 of these and 8 equations. So how to solve?
> 
> But the third and fourth equations have no d? variables, so the may even be inconsistent given the values of K2, K3, C, B, A, D.
> So you have 6 equations for 7 d? variables. So how do you propose to solve for the d? variables?
> 
> Finally your system seems to be linear in the d? variables. You would be able to use R's solve()  if you can get your system to be a square system.
> 
> If your system is not square and underdetermined then you can use a Moore Penrose inverse to get a minimum norm solution 
> (http://en.wikipedia.org/wiki/Moore?Penrose_pseudoinverse#Minimum-norm_solution_to_a_linear_system).
> package MASS provides a function ginv().


And to make matters simple: since your lefthand sides are 0 the minimum norm solution of your system is 0.

Berend


From dwinsemius at comcast.net  Wed Jul 10 21:05:36 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jul 2013 12:05:36 -0700
Subject: [R] replacement functions for subsets
In-Reply-To: <6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
	<6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
Message-ID: <3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>


On Jul 10, 2013, at 11:47 AM, Harry Mamaysky wrote:

> I know how to define replacement functions in R (i.e. ?foo<-? <- function(x,value) x<-value, etc.), but how do you define replacement functions that operate on subsets of arrays (i.e. how do you pass an index into foo)?
> For example, why does the following use of ?rownames? work?

`rownames` of a dataframe is a vector, so indexing with "[" and a single vector of indices is adequate. I cannot really tell what your conceptual "why"-difficulty might be. This is just assignment within a vector. That is not really a "replacement function operating on a subset of an array" since rownames are not values of the dataframe .... and it's not an "array". (Careful use of terms is needed here.)


> 
>> aa <- data.frame( a=1:10,b=101:110 )
> 
>> aa
> 
>    a   b
> 
> 1   1 101
> 
> 2   2 102
> 
> 3   3 103
> 
> 4   4 104
> 
> 5   5 105
> 
> 6   6 106
> 
> 7   7 107
> 
> 8   8 108
> 
> 9   9 109
> 
> 10 10 110
> 
>> rownames(aa)[2:4] <- c('row2','row3','row4')
> 
>> aa
> 
>      a   b
> 
> 1     1 101
> 
> row2  2 102
> 
> row3  3 103
> 
> row4  4 104
> 
> 5     5 105
> 
> 6     6 106
> 
> 7     7 107
> 
> 8     8 108
> 
> 9     9 109
> 
> 10   10 110
> 
>> 
> 
> 
> 
> Thanks,
> 
> Harry
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From przeczek at unbc.ca  Wed Jul 10 21:06:26 2013
From: przeczek at unbc.ca (Kara Przeczek)
Date: Wed, 10 Jul 2013 19:06:26 +0000
Subject: [R] how to adjust the x axis range based on y axis data
Message-ID: <08A14F008A8F8D45B58D7F78181AA29B609F427C@pg-adr-exch-11.adr.unbc.ca>

I am using R studio version 0.97.336.



I am trying to produce multiple figures based on a large data set (98010 rows). I am creating a plot for each TITLE (related to a variable/station combination).



#Create a plot for each Title. Save all plots as jpegs in folder named "SkeenaQfigs"
for(i in 1:nlevels(dt$TITLE)){
  tmp.title <- subset(dt, TITLE == levels(dt$TITLE)[i])
  #save plot to file
  setwd("H:/R stuff/SJackson/SkeenaQfigs")
  options(show.error.messages = FALSE)
  result <- try(plot(tmp.title$YEAR, tmp.title$VALUE, xlab = "Year", ylab="", main = tmp.title$TITLE[1]))
  if(class(result) == 'try-error')
    {
    print(paste("error", tmp.title$TITLE[1], sep=" "))
    }
    else {
    jpeg(file = paste(tmp.title$TITLE[1],".jpg",sep=""))
    plot(tmp.title$YEAR, tmp.title$VALUE, xlab = "Year", ylab="", main = tmp.title$TITLE[1])
    dev.off()
         }
}

The range of YEAR is the same for every station, but there is not always data for every year (and some stations have no data). I would like each plot to adjust the x-axis to start at the first occurrence of a y value.

I used



tmp.title <- tmp.title[!is.na(tmp.title$VALUE),]



to remove all the rows where VALUE = NA. However, there are some years later on in the data set that are missing data, but I want those to be included. I only want to remove the first empty rows.



I then tried,



xmin <- min(tmp.title$YEAR[tmp.title$VALUE>0], na.rm=T)
xmax <- max(tmp.title$YEAR, na.rm=T)

plot(tmp.title$YEAR, tmp.title$VALUE, xlab = "Year", ylab="", xlim=c(xmin,xmax), main = tmp.title$TITLE[1])



This works, but is there a simpler way to do this within the plot command?



Thank you very much for your help!

Kara


From smartpink111 at yahoo.com  Wed Jul 10 21:02:26 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 10 Jul 2013 12:02:26 -0700 (PDT)
Subject: [R] Filter Dataframe for Alarm for particular column(s).
In-Reply-To: <5A52F9658B4B8C4B83D50A7BAD38F5D602C3515F@BANMLVEM04.e2k.ad.ge.com>
References: <1373038692448-4670950.post@n4.nabble.com>
	<1373051800.36586.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<5A52F9658B4B8C4B83D50A7BAD38F5D602C3515F@BANMLVEM04.e2k.ad.ge.com>
Message-ID: <1373482946.220.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
You could try ?data.table() to further increase the speed:



#Same example:
dt2<- data.table(MyDFNew)
system.time(resNew<- dt2[,lapply(.SD,function(x) {x1<-which(c(0,diff(x))<0);x1[length(x1)==0]<-0;x1})][1] )
?# user? system elapsed 
?# 0.144?? 0.004?? 0.148 
resNew
#?? TNH BIX
#1:?? 7?? 2


According to this link (http://stackoverflow.com/questions/9236438/how-do-i-run-apply-on-a-data-table), using for loop should improve the speed

Regarding the use of ts() in this case, I am not very sure.

A.K.



----- Original Message -----
From: R_Antony <antony.akkara at ge.com>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 10, 2013 1:48 AM
Subject: Re: [R] Filter Dataframe for Alarm for particular column(s).

Hi Arun,



Thanks for the solution it? really works !. But how can we avoid even lappy() and? sappy().

Actually any way to do with ts() ?

Thanks,

Antony.



From: arun kirshna [via R] [mailto:ml-node+s789695n4670970h8 at n4.nabble.com] 
Sent: Saturday, July 06, 2013 12:54 AM
To: Akkara, Antony (GE Power & Water, Non-GE)
Subject: Re: Filter Dataframe for Alarm for particular column(s).



Hi, 
May be this helps: 
If you had showed your solution, it would be easier to compare. 

res<-data.frame(lapply(sapply(MyDF[,c(2,4)],function(x) {x1<-which(c(0,diff(x))<0);x1[length(x1)==0]<-0;x1}),`[`,1)) 
res 
#? TNH BIX 
#1?  3?  9 


#Speed 

set.seed(24) 
MyDFNew<- data.frame(TNH=sample(0:1,1e6,replace=TRUE),BIX=sample(0:1,1e6,replace=TRUE)) 
system.time(res1<-data.frame(lapply(sapply(MyDFNew,function(x) {x1<-which(c(0,diff(x))<0);x1[length(x1)==0]<-0;x1}),`[`,1))) 
#?  user? system elapsed 
#? 0.364?  0.000?  0.363 

res1 
#? TNH BIX 
#1?  7?  2 
MyDFNew[1:10,] 
#?  TNH BIX 
#1? ? 0?  1 
#2? ? 0?  0 
#3? ? 1?  1 
#4? ? 1?  1 
#5? ? 1?  0 
#6? ? 1?  0 
#7? ? 0?  1 
#8? ? 1?  1 
#9? ? 1?  1 
#10?  0?  0 


A.K. 


Hi, 


Hi here i have a dataframe called MyDF. 

a<-c(1,1,1,1,1,0,0,0,1,1) 
b<-c(1,1,0,1,1,0,0,0,1,1) 
c<-c(1,1,1,1,1,1,1,0,1,1) 
d<-c(1,1,1,1,1,1,1,1,0,1) 
MyDF<-data.frame(DWATT=a,TNH=b,CSGV=c,BIX=d) 

My requirement is, here i need a function - to get for a 
particular row number(s), when particular column(s) value change from 
one-to-zero? (for the first change). Suppose there is no change is 
happening then it should return "Zero" 

For example,? Using MyDF, 

DWATT TNH CSGV BIX 
1?  1? ? 1?  1 
1?  1? ? 1?  1 
1?  0? ? 1?  1 
1?  1? ? 1?  1 
1?  1? ? 1?  1 
0?  0? ? 1?  1 
0?  0? ? 1?  1 
0?  0? ? 0?  1 
1?  1? ? 1?  0 
1?  1? ? 1?  1 

Here i want to know, the row number where TNH-column and BIX-column values change happening from one-to-zero for the first time. 

Note:- Suppose there is no change is happening then it should return "Zero" 

Answer should be? a dataframe with single row. 
So here answer should return a dataframe like this. 

TNH? BIX 
----? ? ------ 
3? ? ? 9 


i used some ways to get a solution using loops. But there is a bulk files with bulk rows to process. 
So performace is most important. Could someone please suggest better ideas ? 

Thanks, 
Antony. 

______________________________________________ 
[hidden email] mailing list 
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code. 



________________________________

If you reply to this email, your message will be added to the discussion below:

http://r.789695.n4.nabble.com/Filter-Dataframe-for-Alarm-for-particular-column-s-tp4670950p4670970.html 

To unsubscribe from Filter Dataframe for Alarm for particular column(s)., click here <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4670950&code=YW50b255LmFra2FyYUBnZS5jb218NDY3MDk1MHwxNTUxOTQzMDI5> .
NAML <http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>? 





--
View this message in context: http://r.789695.n4.nabble.com/Filter-Dataframe-for-Alarm-for-particular-column-s-tp4670950p4671203.html
Sent from the R help mailing list archive at Nabble.com.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Wed Jul 10 21:13:13 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 10 Jul 2013 11:13:13 -0800
Subject: [R] PCA and gglot2
In-Reply-To: <1373479331548-4671237.post@n4.nabble.com>
References: <b539fae48d0.00001165jrkrideau@inbox.com>
	<1373461740917-4671225.post@n4.nabble.com>
	<a4e5a0b016b8cb41a485fc629b633ced4acb8a65e8@gold.corp.lgc-group.com>
Message-ID: <B759A6E991F.00000177jrkrideau@inbox.com>

'Sorry I made a mistake .  I was using some data of my own and didn't make some key changes to the script to match your variables.


dat1  <-  data.frame(pca1 $scores)  # creates the data.frame
dat1$items  <-  rownames(data1pca1 ) # adds item names
ggplot(dat1, aes(Comp.1, Comp.2, colour = items)) + geom_point() +
   theme(legend.position="none")

A quick look suggests that this is roughly the same plot as in the example Fig 4 but there the author is using geom_segment to add the lines but I have not looked at it all that carefully.





John Kane
Kingston ON Canada


> -----Original Message-----
> From: ashz at walla.co.il
> Sent: Wed, 10 Jul 2013 11:02:11 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] PCA and gglot2
> 
> Hi,
> 
> Thanks. Fig 4 in the link you provided is what I am looking for.
> 
> I still do not know how to implement my data1 and pca1 in the script you
> provided as I think it is only a part of a full script.
> "
> data1<-read.csv("C:/?/MyPCA.csv")
> pca1 <- princomp(data1[,1:4], score=TRUE, cor=TRUE)
> "
> 
> Am I right, how can I implement my data.frames?
> 
> Thanks again
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/PCA-and-gglot2-tp4671225p4671237.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From h.mamaysky at gmail.com  Wed Jul 10 21:17:15 2013
From: h.mamaysky at gmail.com (Harry Mamaysky)
Date: Wed, 10 Jul 2013 15:17:15 -0400
Subject: [R] replacement functions for subsets
In-Reply-To: <3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
	<6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
	<3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>
Message-ID: <FA828FF6-2881-49A2-BF5F-92EB1FAC2696@gmail.com>

As I understand it rownames(aa) returns a copy of an attribute of aa. So changing the value of this vector should make the change to the copy of the row.names attribute. I would then have to set the original row.names equal to this copy to effect the change.

So my question is why "rownames(aa)[2:4] <-" changes the original attribute rather than its copy?

And the follow on question is whether it's possible to have "f(x)[2:4] <-" operate in the same way for some user defined replacement function f. 

Sent from my iPhone

On Jul 10, 2013, at 3:05 PM, David Winsemius <dwinsemius at comcast.net> wrote:


On Jul 10, 2013, at 11:47 AM, Harry Mamaysky wrote:

> I know how to define replacement functions in R (i.e. ?foo<-? <- function(x,value) x<-value, etc.), but how do you define replacement functions that operate on subsets of arrays (i.e. how do you pass an index into foo)?
> For example, why does the following use of ?rownames? work?

`rownames` of a dataframe is a vector, so indexing with "[" and a single vector of indices is adequate. I cannot really tell what your conceptual "why"-difficulty might be. This is just assignment within a vector. That is not really a "replacement function operating on a subset of an array" since rownames are not values of the dataframe .... and it's not an "array". (Careful use of terms is needed here.)


> 
>> aa <- data.frame( a=1:10,b=101:110 )
> 
>> aa
> 
>   a   b
> 
> 1   1 101
> 
> 2   2 102
> 
> 3   3 103
> 
> 4   4 104
> 
> 5   5 105
> 
> 6   6 106
> 
> 7   7 107
> 
> 8   8 108
> 
> 9   9 109
> 
> 10 10 110
> 
>> rownames(aa)[2:4] <- c('row2','row3','row4')
> 
>> aa
> 
>     a   b
> 
> 1     1 101
> 
> row2  2 102
> 
> row3  3 103
> 
> row4  4 104
> 
> 5     5 105
> 
> 6     6 106
> 
> 7     7 107
> 
> 8     8 108
> 
> 9     9 109
> 
> 10   10 110
> 
> 
> 
> 
> Thanks,
> 
> Harry
> 
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From ssefick at gmail.com  Wed Jul 10 21:18:08 2013
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 10 Jul 2013 14:18:08 -0500
Subject: [R] PCA and gglot2
In-Reply-To: <B759A6E991F.00000177jrkrideau@inbox.com>
References: <b539fae48d0.00001165jrkrideau@inbox.com>
	<1373461740917-4671225.post@n4.nabble.com>
	<a4e5a0b016b8cb41a485fc629b633ced4acb8a65e8@gold.corp.lgc-group.com>
	<1373479331548-4671237.post@n4.nabble.com>
	<B759A6E991F.00000177jrkrideau@inbox.com>
Message-ID: <CADKEMqjE64crdZs_yXdYD7df2PN7ZkRcHH6jBOq_fT3xCSesoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/05bd11de/attachment.pl>

From ssefick at gmail.com  Wed Jul 10 21:21:03 2013
From: ssefick at gmail.com (stephen sefick)
Date: Wed, 10 Jul 2013 14:21:03 -0500
Subject: [R] PCA and gglot2
In-Reply-To: <B759A6E991F.00000177jrkrideau@inbox.com>
References: <b539fae48d0.00001165jrkrideau@inbox.com>
	<1373461740917-4671225.post@n4.nabble.com>
	<a4e5a0b016b8cb41a485fc629b633ced4acb8a65e8@gold.corp.lgc-group.com>
	<1373479331548-4671237.post@n4.nabble.com>
	<B759A6E991F.00000177jrkrideau@inbox.com>
Message-ID: <CADKEMqgDrZiYoYeE3d5YOBMZMUK_dEdzjMQQeNh=n=M5ThZqng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/cffb327a/attachment.pl>

From deleeuw at stat.ucla.edu  Wed Jul 10 21:50:54 2013
From: deleeuw at stat.ucla.edu (Jan de Leeuw)
Date: Wed, 10 Jul 2013 12:50:54 -0700
Subject: [R] FOAS and Use R! 2014
Message-ID: <976399B7-B7DE-4471-B8F3-68111A08E199@stat.ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/dc1504ee/attachment.pl>

From dwinsemius at comcast.net  Wed Jul 10 21:51:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jul 2013 12:51:07 -0700
Subject: [R] replacement functions for subsets
In-Reply-To: <FA828FF6-2881-49A2-BF5F-92EB1FAC2696@gmail.com>
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
	<6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
	<3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>
	<FA828FF6-2881-49A2-BF5F-92EB1FAC2696@gmail.com>
Message-ID: <561A2E87-A273-488B-8A9E-7231BFC7CA63@comcast.net>


On Jul 10, 2013, at 12:17 PM, Harry Mamaysky wrote:

> As I understand it rownames(aa) returns a copy of an attribute of aa. So changing the value of this vector should make the change to the copy of the row.names attribute. I would then have to set the original row.names equal to this copy to effect the change.
> 
> So my question is why "rownames(aa)[2:4] <-" changes the original attribute rather than its copy?

I'm not sure how you decide that was happening. Your first paragraph seemed correct:

aa <- data.frame( a=1:10,b=101:110 )
str(aa)
attributes(aa)
dput(aa)
`rownames<-`

> trace(`rownames<-`)
> rownames(aa)[2:4] <- c('row2','row3','row4')
trace: `rownames<-`(`*tmp*`, value = c("1", "row2", "row3", "row4", 
"5", "6", "7", "8", "9", "10"))

You can see that R first builds a full length vector with the second argumens to `rownames<-` fully expanded before doing the assignment to the 'row.names' attribute.

> 
> And the follow on question is whether it's possible to have "f(x)[2:4] <-" operate in the same way for some user defined replacement function f. 

Take a look at the code:

`row.names<-.data.frame`

-- 
David.
> 
> Sent from my iPhone
> 
> On Jul 10, 2013, at 3:05 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
> On Jul 10, 2013, at 11:47 AM, Harry Mamaysky wrote:
> 
>> I know how to define replacement functions in R (i.e. ?foo<-? <- function(x,value) x<-value, etc.), but how do you define replacement functions that operate on subsets of arrays (i.e. how do you pass an index into foo)?
>> For example, why does the following use of ?rownames? work?
> 
> `rownames` of a dataframe is a vector, so indexing with "[" and a single vector of indices is adequate. I cannot really tell what your conceptual "why"-difficulty might be. This is just assignment within a vector. That is not really a "replacement function operating on a subset of an array" since rownames are not values of the dataframe .... and it's not an "array". (Careful use of terms is needed here.)
> 
> 
>> 
>>> aa <- data.frame( a=1:10,b=101:110 )
>> 
>>> aa
>> 
>>  a   b
>> 
>> 1   1 101
>> 
>> 2   2 102
>> 
>> 3   3 103
>> 
>> 4   4 104
>> 
>> 5   5 105
>> 
>> 6   6 106
>> 
>> 7   7 107
>> 
>> 8   8 108
>> 
>> 9   9 109
>> 
>> 10 10 110
>> 
>>> rownames(aa)[2:4] <- c('row2','row3','row4')
>> 
>>> aa
>> 
>>    a   b
>> 
>> 1     1 101
>> 
>> row2  2 102
>> 
>> row3  3 103
>> 
>> row4  4 104
>> 
>> 5     5 105
>> 
>> 6     6 106
>> 
>> 7     7 107
>> 
>> 8     8 108
>> 
>> 9     9 109
>> 
>> 10   10 110
>> 
>> 
>> 
>> 
>> Thanks,
>> 
>> Harry
>> 
>> 
>>   [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Wed Jul 10 22:10:50 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 10 Jul 2013 13:10:50 -0700
Subject: [R] replacement functions for subsets
In-Reply-To: <561A2E87-A273-488B-8A9E-7231BFC7CA63@comcast.net>
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
	<6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
	<3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>
	<FA828FF6-2881-49A2-BF5F-92EB1FAC2696@gmail.com>
	<561A2E87-A273-488B-8A9E-7231BFC7CA63@comcast.net>
Message-ID: <CACk-te3gei1y8gcYBUJUHHjnBaft3vMRcHwH9KsNEYmt-8x5Mw@mail.gmail.com>

I think the OP may perhaps want to define a method for "[<-" .

e.g. try:

methods("[<-")

If this is not it ... ??

Cheers,
Bert

On Wed, Jul 10, 2013 at 12:51 PM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Jul 10, 2013, at 12:17 PM, Harry Mamaysky wrote:
>
>> As I understand it rownames(aa) returns a copy of an attribute of aa. So changing the value of this vector should make the change to the copy of the row.names attribute. I would then have to set the original row.names equal to this copy to effect the change.
>>
>> So my question is why "rownames(aa)[2:4] <-" changes the original attribute rather than its copy?
>
> I'm not sure how you decide that was happening. Your first paragraph seemed correct:
>
> aa <- data.frame( a=1:10,b=101:110 )
> str(aa)
> attributes(aa)
> dput(aa)
> `rownames<-`
>
>> trace(`rownames<-`)
>> rownames(aa)[2:4] <- c('row2','row3','row4')
> trace: `rownames<-`(`*tmp*`, value = c("1", "row2", "row3", "row4",
> "5", "6", "7", "8", "9", "10"))
>
> You can see that R first builds a full length vector with the second argumens to `rownames<-` fully expanded before doing the assignment to the 'row.names' attribute.
>
>>
>> And the follow on question is whether it's possible to have "f(x)[2:4] <-" operate in the same way for some user defined replacement function f.
>
> Take a look at the code:
>
> `row.names<-.data.frame`
>
> --
> David.
>>
>> Sent from my iPhone
>>
>> On Jul 10, 2013, at 3:05 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>>
>> On Jul 10, 2013, at 11:47 AM, Harry Mamaysky wrote:
>>
>>> I know how to define replacement functions in R (i.e. ?foo<-? <- function(x,value) x<-value, etc.), but how do you define replacement functions that operate on subsets of arrays (i.e. how do you pass an index into foo)?
>>> For example, why does the following use of ?rownames? work?
>>
>> `rownames` of a dataframe is a vector, so indexing with "[" and a single vector of indices is adequate. I cannot really tell what your conceptual "why"-difficulty might be. This is just assignment within a vector. That is not really a "replacement function operating on a subset of an array" since rownames are not values of the dataframe .... and it's not an "array". (Careful use of terms is needed here.)
>>
>>
>>>
>>>> aa <- data.frame( a=1:10,b=101:110 )
>>>
>>>> aa
>>>
>>>  a   b
>>>
>>> 1   1 101
>>>
>>> 2   2 102
>>>
>>> 3   3 103
>>>
>>> 4   4 104
>>>
>>> 5   5 105
>>>
>>> 6   6 106
>>>
>>> 7   7 107
>>>
>>> 8   8 108
>>>
>>> 9   9 109
>>>
>>> 10 10 110
>>>
>>>> rownames(aa)[2:4] <- c('row2','row3','row4')
>>>
>>>> aa
>>>
>>>    a   b
>>>
>>> 1     1 101
>>>
>>> row2  2 102
>>>
>>> row3  3 103
>>>
>>> row4  4 104
>>>
>>> 5     5 105
>>>
>>> 6     6 106
>>>
>>> 7     7 107
>>>
>>> 8     8 108
>>>
>>> 9     9 109
>>>
>>> 10   10 110
>>>
>>>
>>>
>>>
>>> Thanks,
>>>
>>> Harry
>>>
>>>
>>>   [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From h.mamaysky at gmail.com  Wed Jul 10 22:23:03 2013
From: h.mamaysky at gmail.com (Harry Mamaysky)
Date: Wed, 10 Jul 2013 16:23:03 -0400
Subject: [R] replacement functions for subsets
In-Reply-To: <CACk-te3gei1y8gcYBUJUHHjnBaft3vMRcHwH9KsNEYmt-8x5Mw@mail.gmail.com>
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
	<6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
	<3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>
	<FA828FF6-2881-49A2-BF5F-92EB1FAC2696@gmail.com>
	<561A2E87-A273-488B-8A9E-7231BFC7CA63@comcast.net>
	<CACk-te3gei1y8gcYBUJUHHjnBaft3vMRcHwH9KsNEYmt-8x5Mw@mail.gmail.com>
Message-ID: <E8F42D7A-2642-4422-ABCD-9F06DF501AC2@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/d2eb37da/attachment.pl>

From jimmycloud at gmail.com  Wed Jul 10 22:29:03 2013
From: jimmycloud at gmail.com (Jie)
Date: Wed, 10 Jul 2013 16:29:03 -0400
Subject: [R]  alternative of package parallel for R 3.0
Message-ID: <CACXG3GhT899cd4JhAiuAPC6oa8PZ-6s+S9QgxBq+sWkvnLbUxg@mail.gmail.com>

Dear All,

I would like to use parApply in "parallel" to do parallel computing.
But after I updated to the new version of R, I got the message like
"Warning message: package ?parallel? is not available (for R version 3.0.0) "
Any people has the same issue? I know there are some other packages
but which has a similar way to implement it? Thank you.

Best wishes,
Jie


From marc_schwartz at me.com  Wed Jul 10 22:43:10 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 10 Jul 2013 15:43:10 -0500
Subject: [R] alternative of package parallel for R 3.0
In-Reply-To: <CACXG3GhT899cd4JhAiuAPC6oa8PZ-6s+S9QgxBq+sWkvnLbUxg@mail.gmail.com>
References: <CACXG3GhT899cd4JhAiuAPC6oa8PZ-6s+S9QgxBq+sWkvnLbUxg@mail.gmail.com>
Message-ID: <2D1B720C-4EB2-4C92-91BB-6AC859A2FFB0@me.com>

On Jul 10, 2013, at 3:29 PM, Jie <jimmycloud at gmail.com> wrote:

> Dear All,
> 
> I would like to use parApply in "parallel" to do parallel computing.
> But after I updated to the new version of R, I got the message like
> "Warning message: package ?parallel? is not available (for R version 3.0.0) "
> Any people has the same issue? I know there are some other packages
> but which has a similar way to implement it? Thank you.
> 
> Best wishes,
> Jie
> 


parallel is part of the standard R distribution and has been since R version 2.14.0, almost two years ago. You just need:

> require(parallel)
Loading required package: parallel


Regards,

Marc Schwartz


From wdunlap at tibco.com  Wed Jul 10 23:09:15 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Wed, 10 Jul 2013 21:09:15 +0000
Subject: [R] replacement functions for subsets
In-Reply-To: <E8F42D7A-2642-4422-ABCD-9F06DF501AC2@gmail.com>
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
	<6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
	<3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>
	<FA828FF6-2881-49A2-BF5F-92EB1FAC2696@gmail.com>
	<561A2E87-A273-488B-8A9E-7231BFC7CA63@comcast.net>
	<CACk-te3gei1y8gcYBUJUHHjnBaft3vMRcHwH9KsNEYmt-8x5Mw@mail.gmail.com>
	<E8F42D7A-2642-4422-ABCD-9F06DF501AC2@gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C31B1FD@PA-MBX01.na.tibco.com>

If you define a function 'foo<-'  to replace a part of an object you need
to have a corresponding function 'foo' that extracts that same part.
If 'foo' does not exist or if 'foo' extracts something other than what 'foo<-'
alters, then nested replacements will not work.

The expression
   bar(foo(x)) <- newValue
is evaluated as
   tmp <- foo(x) # extract the part of x you want to alter
   bar(tmp) <- newValue # alter the extracted stuff
   foo(x) <- tmp # put the altered extracted stuff back where it came from
   # tmp is then discarded
('tmp' is chosen to be a name like '*tmp*'; you will see that in the traceback
after an error.)

Sometimes the 'extracted part' is not really a part of an object but something
more abstract, but the it is still true that foo<- and foo need to be paired.  E.g.,
  > twoTimes <- function(x) {
  +     cat("Calling twoTimes: x=", deparse(x), "\n")
  +     x * 2
  + }
  > `twoTimes<-` <- function(x, value) {
  +     cat("Calling twoTimes<-: x=", deparse(x), "\n")
  +     x[] <- value/2
  +     x
  + }
  > p <- 1:5
  > twoTimes(p)
  Calling twoTimes: x= 1:5 
  [1]  2  4  6  8 10
  > twoTimes(p)[1:2] <- c(100,102)
  Calling twoTimes: x= 1:5 
  Calling twoTimes<-: x= 1:5 
  > p
  [1] 50 51  3  4  5
  > 
  > p <- 1:5
  > twoTimes(p[1:2]) <- c(100,102)
  Calling twoTimes<-: x= 1:2 
  > p
  [1] 50 51  3  4  5
 
 
Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Harry Mamaysky
> Sent: Wednesday, July 10, 2013 1:23 PM
> To: Bert Gunter
> Cc: r-help at r-project.org
> Subject: Re: [R] replacement functions for subsets
> 
> So how would I get the following to work?
> 
> > aa<-1
> > aa
> [1] 1
> > 'foo<-' <- function(x,value) x<-value
> > foo(aa)<-1:10
> > aa
> [1]  1  2  3  4  5  6  7  8  9 10
> > # This doesn't work:
> > foo(aa)[4:5] <- c(101,102)
> Error in foo(aa)[4:5] <- c(101, 102) : could not find function "foo"
> > # What I would like to see is: aa becomes 1 2 3 101 102 6 7 8 9 10
> > # Is it possible to define such a function 'foo'?
> 
> 
> Sent from my iPhone
> 
> On Jul 10, 2013, at 4:10 PM, Bert Gunter <gunter.berton at gene.com> wrote:
> 
> I think the OP may perhaps want to define a method for "[<-" .
> 
> e.g. try:
> 
> methods("[<-")
> 
> If this is not it ... ??
> 
> Cheers,
> Bert
> 
> On Wed, Jul 10, 2013 at 12:51 PM, David Winsemius
> <dwinsemius at comcast.net> wrote:
> >
> > On Jul 10, 2013, at 12:17 PM, Harry Mamaysky wrote:
> >
> >> As I understand it rownames(aa) returns a copy of an attribute of aa. So changing the
> value of this vector should make the change to the copy of the row.names attribute. I
> would then have to set the original row.names equal to this copy to effect the change.
> >>
> >> So my question is why "rownames(aa)[2:4] <-" changes the original attribute rather
> than its copy?
> >
> > I'm not sure how you decide that was happening. Your first paragraph seemed correct:
> >
> > aa <- data.frame( a=1:10,b=101:110 )
> > str(aa)
> > attributes(aa)
> > dput(aa)
> > `rownames<-`
> >
> >> trace(`rownames<-`)
> >> rownames(aa)[2:4] <- c('row2','row3','row4')
> > trace: `rownames<-`(`*tmp*`, value = c("1", "row2", "row3", "row4",
> > "5", "6", "7", "8", "9", "10"))
> >
> > You can see that R first builds a full length vector with the second argumens to
> `rownames<-` fully expanded before doing the assignment to the 'row.names' attribute.
> >
> >>
> >> And the follow on question is whether it's possible to have "f(x)[2:4] <-" operate in the
> same way for some user defined replacement function f.
> >
> > Take a look at the code:
> >
> > `row.names<-.data.frame`
> >
> > --
> > David.
> >>
> >> Sent from my iPhone
> >>
> >> On Jul 10, 2013, at 3:05 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> >>
> >>
> >> On Jul 10, 2013, at 11:47 AM, Harry Mamaysky wrote:
> >>
> >>> I know how to define replacement functions in R (i.e. ?foo<-? <- function(x,value) x<-
> value, etc.), but how do you define replacement functions that operate on subsets of
> arrays (i.e. how do you pass an index into foo)?
> >>> For example, why does the following use of ?rownames? work?
> >>
> >> `rownames` of a dataframe is a vector, so indexing with "[" and a single vector of
> indices is adequate. I cannot really tell what your conceptual "why"-difficulty might be.
> This is just assignment within a vector. That is not really a "replacement function
> operating on a subset of an array" since rownames are not values of the dataframe ....
> and it's not an "array". (Careful use of terms is needed here.)
> >>
> >>
> >>>
> >>>> aa <- data.frame( a=1:10,b=101:110 )
> >>>
> >>>> aa
> >>>
> >>> a   b
> >>>
> >>> 1   1 101
> >>>
> >>> 2   2 102
> >>>
> >>> 3   3 103
> >>>
> >>> 4   4 104
> >>>
> >>> 5   5 105
> >>>
> >>> 6   6 106
> >>>
> >>> 7   7 107
> >>>
> >>> 8   8 108
> >>>
> >>> 9   9 109
> >>>
> >>> 10 10 110
> >>>
> >>>> rownames(aa)[2:4] <- c('row2','row3','row4')
> >>>
> >>>> aa
> >>>
> >>>   a   b
> >>>
> >>> 1     1 101
> >>>
> >>> row2  2 102
> >>>
> >>> row3  3 103
> >>>
> >>> row4  4 104
> >>>
> >>> 5     5 105
> >>>
> >>> 6     6 106
> >>>
> >>> 7     7 107
> >>>
> >>> 8     8 108
> >>>
> >>> 9     9 109
> >>>
> >>> 10   10 110
> >>>
> >>>
> >>>
> >>>
> >>> Thanks,
> >>>
> >>> Harry
> >>>
> >>>
> >>>  [[alternative HTML version deleted]]
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> David Winsemius
> >> Alameda, CA, USA
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> --
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-
> biostatistics/pdb-ncb-home.htm
> 
> 	[[alternative HTML version deleted]]


From smartpink111 at yahoo.com  Wed Jul 10 23:09:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 10 Jul 2013 14:09:32 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
Message-ID: <1373490572.95835.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
You could try:
?mat1<-matrix(dat3[rowSums(dat3[,2:3])!=dat3[,4],1],ncol=1,dimnames=list(NULL,"MW_EEsDue_ERRORS"))
?mat1
#???? MW_EEsDue_ERRORS
#[1,]???????????? 1882
#[2,]???????????? 1884
#[3,]???????????? 1885
A.K.


#Let's say I have the following data set: 

dat3 = data.frame(A_CaseID = c(1881, 1882, 1883, 1884, 1885), 
? ? ? ? ? ? ? ? ? B_MW_EEsDue1 = c(2, 2, 1, 4, 6), 
? ? ? ? ? ? ? ? ? C_MW_EEsDue2 = c(5, 5, 4, 1, 6), 
? ? ? ? ? ? ? ? ? D_MW_EEsDueTotal = c(7, 9, 5, 6, 112)) 
dat3 
# A_CaseID B_MW_EEsDue1 C_MW_EEsDue2 D_MW_EEsDueTotal 
# 1 ? ? 1881 ? ? ? ? ? ?2 ? ? ? ? ? ?5 ? ? ? ? ? ? ? ?7 
# 2 ? ? 1882 ? ? ? ? ? ?2 ? ? ? ? ? ?5 ? ? ? ? ? ? ? ?9 
# 3 ? ? 1883 ? ? ? ? ? ?1 ? ? ? ? ? ?4 ? ? ? ? ? ? ? ?5 
# 4 ? ? 1884 ? ? ? ? ? ?4 ? ? ? ? ? ?1 ? ? ? ? ? ? ? ?6 
# 5 ? ? 1885 ? ? ? ? ? ?6 ? ? ? ? ? ?6 ? ? ? ? ? ? ?112 

# I want to: 
#CREATE A NEW 1-COLUMN MATRIX (of unknown #rows) LISTING ONLY "A"'s WHERE "D != B + C" 
#THIS COLUMN CAN BE LABELED "MW_EEsDue_ERRORS", and output for this example should be: 

# MW_EEsDue_ERRORS 
# 1 1882 
# 2 1884 
# 3 1885 

#What is the best way to do this? ?Thanks for your time. ?BNC


From ashz at walla.co.il  Wed Jul 10 21:49:55 2013
From: ashz at walla.co.il (ashz)
Date: Wed, 10 Jul 2013 12:49:55 -0700 (PDT)
Subject: [R] PCA and gglot2
In-Reply-To: <B759A6E991F.00000177jrkrideau@inbox.com>
References: <1373461740917-4671225.post@n4.nabble.com>
	<B539FAE48D0.00001165jrkrideau@inbox.com>
	<A4E5A0B016B8CB41A485FC629B633CED4ACB8A65E8@GOLD.corp.lgc-group.com>
	<1373479331548-4671237.post@n4.nabble.com>
	<B759A6E991F.00000177jrkrideau@inbox.com>
Message-ID: <1373485795196-4671253.post@n4.nabble.com>

Dear John,

Thanks for the help.

I did some minor modifications to your script as I had some problems:
... 
pca = PCA(data[,1:4], scale.unit=T, graph=F)
dat1  <-  data.frame(pca$scores)  # creates the data.frame
dat1$items  <-  rownames(data$group) # adds item names
ggplot(dat1, aes(pca$ind$coord[,1], pca$ind$coord[,2], colour = dat1$item))
+ geom_point() + theme(legend.position="none")

I still do not get separation by color by group (column 5 of csv file) as
the  dat1 is empty (data frame with 0 columns and 0 rows).

Any reason why?

Thanks again.



--
View this message in context: http://r.789695.n4.nabble.com/PCA-and-gglot2-tp4671225p4671253.html
Sent from the R help mailing list archive at Nabble.com.


From bcrombie at utk.edu  Wed Jul 10 21:18:58 2013
From: bcrombie at utk.edu (bcrombie)
Date: Wed, 10 Jul 2013 12:18:58 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
Message-ID: <1373483938637-4671250.post@n4.nabble.com>

#Let's say I have the following data set:

dat3 = data.frame(A_CaseID = c(1881, 1882, 1883, 1884, 1885),
                  B_MW_EEsDue1 = c(2, 2, 1, 4, 6),
                  C_MW_EEsDue2 = c(5, 5, 4, 1, 6),
                  D_MW_EEsDueTotal = c(7, 9, 5, 6, 112))
dat3
# A_CaseID B_MW_EEsDue1 C_MW_EEsDue2 D_MW_EEsDueTotal
# 1     1881            2            5                7
# 2     1882            2            5                9
# 3     1883            1            4                5
# 4     1884            4            1                6
# 5     1885            6            6              112

# I want to:
#CREATE A NEW 1-COLUMN MATRIX (of unknown #rows) LISTING ONLY "A"'s WHERE "D
!= B + C"
#THIS COLUMN CAN BE LABELED "MW_EEsDue_ERRORS", and output for this example
should be:

# MW_EEsDue_ERRORS 
# 1 1882
# 2 1884
# 3 1885

#What is the best way to do this?  Thanks for your time.  BNC



--
View this message in context: http://r.789695.n4.nabble.com/create-new-matrix-from-user-defined-function-tp4671250.html
Sent from the R help mailing list archive at Nabble.com.


From ashz at walla.co.il  Wed Jul 10 22:14:07 2013
From: ashz at walla.co.il (ashz)
Date: Wed, 10 Jul 2013 13:14:07 -0700 (PDT)
Subject: [R] PCA and gglot2
In-Reply-To: <CADKEMqgDrZiYoYeE3d5YOBMZMUK_dEdzjMQQeNh=n=M5ThZqng@mail.gmail.com>
References: <1373461740917-4671225.post@n4.nabble.com>
	<B539FAE48D0.00001165jrkrideau@inbox.com>
	<A4E5A0B016B8CB41A485FC629B633CED4ACB8A65E8@GOLD.corp.lgc-group.com>
	<1373479331548-4671237.post@n4.nabble.com>
	<B759A6E991F.00000177jrkrideau@inbox.com>
	<CADKEMqgDrZiYoYeE3d5YOBMZMUK_dEdzjMQQeNh=n=M5ThZqng@mail.gmail.com>
Message-ID: <1373487247664-4671258.post@n4.nabble.com>

Hi,

Thanks to ssefick for the ggbiplot tip.

It works fine so I submit a general script thats works for future users.

library(ggbiplot)
data<-read.csv("C:/?/MyPCA.csv") 
data1<-data[,1:4] 
my.pca <- prcomp(data1, scale. = TRUE)
my.class<- data$Group  
g <- ggbiplot(my.pca, obs.scale = 1, var.scale = 1,groups = my.class,
ellipse = TRUE, circle = TRUE)
g <- g + scale_color_discrete(name = '')
g <- g + theme(legend.direction = 'horizontal', 
               legend.position = 'top')
print(g)

BTW
Installation:
library(devtools)
install_github("ggbiplot", "vqv")

you will need to instal before Rtools
(http://cran.r-project.org/bin/windows/Rtools/)

Thanks a lot for the help.




--
View this message in context: http://r.789695.n4.nabble.com/PCA-and-gglot2-tp4671225p4671258.html
Sent from the R help mailing list archive at Nabble.com.


From elizabethbeck0 at gmail.com  Wed Jul 10 23:28:32 2013
From: elizabethbeck0 at gmail.com (Elizabeth Beck)
Date: Wed, 10 Jul 2013 15:28:32 -0600
Subject: [R] permanova for multivariate repeat measures toxicology data set
Message-ID: <CAEWzS+H2sT05Y05Qa=A1PR3orP=+Bt8Kigm4zBBgasALkBUwNQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/a1c84da2/attachment.pl>

From NordlDJ at dshs.wa.gov  Wed Jul 10 23:42:05 2013
From: NordlDJ at dshs.wa.gov (Nordlund, Dan (DSHS/RDA))
Date: Wed, 10 Jul 2013 21:42:05 +0000
Subject: [R] create new matrix from user-defined function
In-Reply-To: <1373483938637-4671250.post@n4.nabble.com>
References: <1373483938637-4671250.post@n4.nabble.com>
Message-ID: <F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of bcrombie
> Sent: Wednesday, July 10, 2013 12:19 PM
> To: r-help at r-project.org
> Subject: [R] create new matrix from user-defined function
> 
> #Let's say I have the following data set:
> 
> dat3 = data.frame(A_CaseID = c(1881, 1882, 1883, 1884, 1885),
>                   B_MW_EEsDue1 = c(2, 2, 1, 4, 6),
>                   C_MW_EEsDue2 = c(5, 5, 4, 1, 6),
>                   D_MW_EEsDueTotal = c(7, 9, 5, 6, 112))
> dat3
> # A_CaseID B_MW_EEsDue1 C_MW_EEsDue2 D_MW_EEsDueTotal
> # 1     1881            2            5                7
> # 2     1882            2            5                9
> # 3     1883            1            4                5
> # 4     1884            4            1                6
> # 5     1885            6            6              112
> 
> # I want to:
> #CREATE A NEW 1-COLUMN MATRIX (of unknown #rows) LISTING ONLY "A"'s
> WHERE "D
> != B + C"
> #THIS COLUMN CAN BE LABELED "MW_EEsDue_ERRORS", and output for this
> example
> should be:
> 
> # MW_EEsDue_ERRORS
> # 1 1882
> # 2 1884
> # 3 1885
> 
> #What is the best way to do this?  Thanks for your time.  BNC
> 
> 

Here is one option, there are many others.  Only you can decide what is "best".

data.frame(MW_EEsDue_ERRORS=dat3[dat3[[4]] != dat3[[2]]+dat3[[3]],][[1]])


Hope this is helpful,

Dan

Daniel J. Nordlund
Washington State Department of Social and Health Services
Planning, Performance, and Accountability
Research and Data Analysis Division
Olympia, WA 98504-5204


From rolf.turner at xtra.co.nz  Thu Jul 11 00:03:12 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 11 Jul 2013 10:03:12 +1200
Subject: [R] find a function for a random curve
In-Reply-To: <CAObCoN6GuCeOKgK3-WH6XsjnO=Jky1oJLir4g=zXVcA92Lyzjw@mail.gmail.com>
References: <CAObCoN6GuCeOKgK3-WH6XsjnO=Jky1oJLir4g=zXVcA92Lyzjw@mail.gmail.com>
Message-ID: <51DDDA20.3040102@xtra.co.nz>


Your question is very vague, so it's hard to know what to suggest.
Please note the exhortation that appears at the bottom of every
r-help message:
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

It is possible that splinefun() is what you are looking for.

     cheers,

         Rolf Turner

On 10/07/13 22:29, Xiaoyu Lu wrote:
> Hi,
>
> I want to find a functional form for my data. I have tried smoothing and
> obtained a kinda perfect fit.
> However, I can only draw it but cannot call it.
>
> I am wondering that is there a way that I can store the fit as a function
> and apply it when needed. e.g. tranformation etc.


From Lucy.Leigh at newcastle.edu.au  Thu Jul 11 01:37:38 2013
From: Lucy.Leigh at newcastle.edu.au (Lucy Leigh)
Date: Thu, 11 Jul 2013 09:37:38 +1000
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
Message-ID: <51DE7CE2.ECEB.009F.0@newcastle.edu.au>

Hi,
I have had a look at the manual but it makes no sense to me. I have
downloaded RTools, and the InnoSetup,
but I don't understand how to use these to install my package? Am I
meant to be writing commands
in R itself, or in these other things I've downloaded?
Lucy

>>> Erin Hodgess <erinm.hodgess at gmail.com> 9/07/2013 5:30 pm >>>
Hi Lucy:

Did you look at the R Installation and Administration manuals?  There's
a
good section about installing on Windows via Rtools.



On Mon, Jul 8, 2013 at 10:18 PM, Lucy Leigh
<Lucy.Leigh at newcastle.edu.au>wrote:

> Great thank you - are there any resources that step through how to
use
> RTools to compile the
> source package and install it in R on (64-bit windows) ?
>
> >>> Berend Hasselman <bhh at xs4all.nl> 8/07/2013 6:38 pm >>>
>
> On 08-07-2013, at 02:15, "Lucy Leigh" <Lucy.Leigh at newcastle.edu.au>
> wrote:
>
> > Hi,
> > I have a source package that isn't available as a windows zip
file.
> Can
> > anyone explain to me how I can install this on my windows R
> platform?
> > When I use the following code:
> > install.packages("PReMiuM_3.0.21.tar.gz", type = "source")
> >
> >
>
> Where did you get that version from?
> CRAN has version 3.0.20 and that is available as a binary Windows
> package (.zip).
>
> As for the error message: you have to have Rtools installed to
compile
> source packages.
>
> Berend
>
> > I get this error message:
> >
> >
> >
> > * installing *source* package 'PReMiuM' ...
> > ** libs
> >
> > *** arch - i386
> > ERROR: compilation failed for package 'PReMiuM'
> > * removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM'
> > Warning messages:
> > 1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL
> -l
> > "C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had
> status
> > 1
> > 2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") :
> >  installation of package ?PReMiuM_3.0.21.tar.gz? had non-zero
> exit
> > status
> >>
> >
> > Thanks for any help anyone can give me,
> > Lucy
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help 
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html 
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help 
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html 
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Erin Hodgess
Associate Professor
Department of Computer and Mathematical Sciences
University of Houston - Downtown
mailto: erinm.hodgess at gmail.com


From jdnewmil at dcn.davis.CA.us  Thu Jul 11 02:20:06 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 10 Jul 2013 17:20:06 -0700
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DE7CE2.ECEB.009F.0@newcastle.edu.au>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
Message-ID: <1a1ffe55-42e3-4d80-8b08-2c4337ca6d2d@email.android.com>

Lucy, you have stepped into something of a mess. Although you just want to install the package to use it, installing from source often (but not always) requires the ability to compile C, C++, or Fortran, and discussions about development really belong on the R-devel mailing list. The steps needed may be extremely simple, or quite complex depending on how that package is constructed. They are automatic on most operating systems, but on Windows you have to learn a bit more than you appear comfortable with to make the conversion to binary.

In short, if you cannot utilize the documentation to build it yourself, you should wait for it to get through the review process at CRAN so you can install a binary version from a repository, or ask the library developer to create a "preview" binary version for you. If you want to pursue the compile it yourself approach further you are going to have to take your questions to R-devel and be prepared to read the documentation more carefully so you can ask specific questions rather than open-ended ones.

Your question about writing commands in R is an example of an open-ended question, since you did not say which commands you are thinking of. You do have to use the operating system command line ("cmd") in several cases, and you have to get the environment variables setup properly before those commands will work (which is operating-system specific and not about R) but the R team cannot reproduce documentation for every operating system so you need to learn that with Google.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Lucy Leigh <Lucy.Leigh at newcastle.edu.au> wrote:

>Hi,
>I have had a look at the manual but it makes no sense to me. I have
>downloaded RTools, and the InnoSetup,
>but I don't understand how to use these to install my package? Am I
>meant to be writing commands
>in R itself, or in these other things I've downloaded?
>Lucy
>
>>>> Erin Hodgess <erinm.hodgess at gmail.com> 9/07/2013 5:30 pm >>>
>Hi Lucy:
>
>Did you look at the R Installation and Administration manuals?  There's
>a
>good section about installing on Windows via Rtools.
>
>
>
>On Mon, Jul 8, 2013 at 10:18 PM, Lucy Leigh
><Lucy.Leigh at newcastle.edu.au>wrote:
>
>> Great thank you - are there any resources that step through how to
>use
>> RTools to compile the
>> source package and install it in R on (64-bit windows) ?
>>
>> >>> Berend Hasselman <bhh at xs4all.nl> 8/07/2013 6:38 pm >>>
>>
>> On 08-07-2013, at 02:15, "Lucy Leigh" <Lucy.Leigh at newcastle.edu.au>
>> wrote:
>>
>> > Hi,
>> > I have a source package that isn't available as a windows zip
>file.
>> Can
>> > anyone explain to me how I can install this on my windows R
>> platform?
>> > When I use the following code:
>> > install.packages("PReMiuM_3.0.21.tar.gz", type = "source")
>> >
>> >
>>
>> Where did you get that version from?
>> CRAN has version 3.0.20 and that is available as a binary Windows
>> package (.zip).
>>
>> As for the error message: you have to have Rtools installed to
>compile
>> source packages.
>>
>> Berend
>>
>> > I get this error message:
>> >
>> >
>> >
>> > * installing *source* package 'PReMiuM' ...
>> > ** libs
>> >
>> > *** arch - i386
>> > ERROR: compilation failed for package 'PReMiuM'
>> > * removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM'
>> > Warning messages:
>> > 1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL
>> -l
>> > "C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had
>> status
>> > 1
>> > 2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") :
>> >  installation of package ?PReMiuM_3.0.21.tar.gz? had non-zero
>> exit
>> > status
>> >>
>> >
>> > Thanks for any help anyone can give me,
>> > Lucy
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help 
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html 
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help 
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html 
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>
>
>-- 
>Erin Hodgess
>Associate Professor
>Department of Computer and Mathematical Sciences
>University of Houston - Downtown
>mailto: erinm.hodgess at gmail.com
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jul 11 02:22:28 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 10 Jul 2013 17:22:28 -0700
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DE7CE2.ECEB.009F.0@newcastle.edu.au>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
Message-ID: <EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>


On Jul 10, 2013, at 4:37 PM, Lucy Leigh wrote:

> Hi,
> I have had a look at the manual but it makes no sense to me. I have
> downloaded RTools, and the InnoSetup,
> but I don't understand how to use these to install my package? Am I
> meant to be writing commands
> in R itself, or in these other things I've downloaded?

Since you are clearly out of your league with respect to compiling from source, now is the time to ask (again), why are you not installing the binary package?

At the R command line just type:

install.packages("PReMiuM")  # should default to type="win.binary" and use a CRAN mirror

-- 
David


> Lucy
> 
>>>> Erin Hodgess <erinm.hodgess at gmail.com> 9/07/2013 5:30 pm >>>
> Hi Lucy:
> 
> Did you look at the R Installation and Administration manuals?  There's
> a
> good section about installing on Windows via Rtools.
> 
> 
> 
> On Mon, Jul 8, 2013 at 10:18 PM, Lucy Leigh
> <Lucy.Leigh at newcastle.edu.au>wrote:
> 
>> Great thank you - are there any resources that step through how to
> use
>> RTools to compile the
>> source package and install it in R on (64-bit windows) ?
>> 
>>>>> Berend Hasselman <bhh at xs4all.nl> 8/07/2013 6:38 pm >>>
>> 
>> On 08-07-2013, at 02:15, "Lucy Leigh" <Lucy.Leigh at newcastle.edu.au>
>> wrote:
>> 
>>> Hi,
>>> I have a source package that isn't available as a windows zip
> file.
>> Can
>>> anyone explain to me how I can install this on my windows R
>> platform?
>>> When I use the following code:
>>> install.packages("PReMiuM_3.0.21.tar.gz", type = "source")
>>> 
>>> 
>> 
>> Where did you get that version from?
>> CRAN has version 3.0.20 and that is available as a binary Windows
>> package (.zip).
>> 
>> As for the error message: you have to have Rtools installed to
> compile
>> source packages.
>> 
>> Berend
>> 
>>> I get this error message:
>>> 
>>> 
>>> 
>>> * installing *source* package 'PReMiuM' ...
>>> ** libs
>>> 
>>> *** arch - i386
>>> ERROR: compilation failed for package 'PReMiuM'
>>> * removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM'
>>> Warning messages:
>>> 1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL
>> -l
>>> "C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had
>> status
>>> 1
>>> 2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") :
>>> installation of package ?PReMiuM_3.0.21.tar.gz? had non-zero
>> exit
>>> status
>>>> 
>>> 
>>> Thanks for any help anyone can give me,
>>> Lucy
>>> 
>>> ______

David Winsemius
Alameda, CA, USA


From mark.dalphin at pacificedge.co.nz  Thu Jul 11 03:13:33 2013
From: mark.dalphin at pacificedge.co.nz (Mark Dalphin)
Date: Thu, 11 Jul 2013 13:13:33 +1200
Subject: [R] Problem building R-2.15.3 from source
Message-ID: <51DE06BD.2050802@pacificedge.co.nz>

Hi,

I have for many years build R from source for Linux. I have just run 
into my first problem with this in ... I don't know how long.

uname -a
Linux douglas 3.2.0-4-686-pae #1 SMP Debian 3.2.46-1 i686 GNU/Linux

cat /etc/issue
Debian GNU/Linux 7 \n \l


The version of R is 2.15.3. I know it is old, but we are in a regulated 
environment and changes to R versions are painful. I have built R 2.15.3 
elsewhere and have it running on multiple Linux boxes around here, both 
32-bit and 64-bit; Ubuntu distributions, however, not Debian.

This build is on a virtual machine under OpenBox. The host is a 64-bit 
Debian; the guest is a 32-bit Debian installation.

The symptoms are strange (to me). I get segfaults during the 
byte-compiling phase of libraries. If I re-run 'make', the make proceeds 
as if it finished the previous seg-faulted step, and then segfaults on 
the next byte-compile. The "permissions" makes me wonder about file 
permissions, but the whole 'make' is under my HOME. Furthermore, I have 
scanned the unpacked tar-gz package for something I don't "own" and it 
isn't there. I also think segfaults are usually in memory, though I 
don't know what "permission" I have there (don't I own the RAM I request?).

I have attached a section of the 'make' output  below, followed by a the 
next "make" output:
----------------------------------------------------------------------------------------------------------
make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/splines'
make[4]: Entering directory 
`/home/mdalphin/src/R-2.15.3/src/library/splines'
byte-compiling package 'splines'

 *** caught segfault ***
address 0x403ac3dc, cause 'invalid permissions'

Traceback:
 1: fun(libname, pkgname)
 2: doTryCatch(return(expr), name, parentenv, handler)
 3: tryCatchOne(expr, names, parentenv, handlers[[1L]])
 4: tryCatchList(expr, classes, parentenv, handlers)
 5: tryCatch(fun(libname, pkgname), error = identity)
 6: runHook(".onLoad", env, package.lib, package)
 7: loadNamespace(name)
 8: doTryCatch(return(expr), name, parentenv, handler)
 9: tryCatchOne(expr, names, parentenv, handlers[[1L]])
10: tryCatchList(expr, classes, parentenv, handlers)
11: tryCatch(loadNamespace(name), error = function(e) stop(e))
12: getNamespace(ns)
13: asNamespace(pkg)
14: get(name, envir = asNamespace(pkg), inherits = FALSE)
15: compiler:::tryCmpfun
16: .Call("R_lazyLoadDBinsertValue", x[[1L]], file, ascii, compress,     
hook, PACKAGE = "base")
17: lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, 
compress,     envhook)
18: makeLazyLoadDB(ns, dbbase, compress = compress)
19: code2LazyLoadDB(package, lib.loc = lib.loc, keep.source = 
keep.source,     compress = compress)
20: tools:::makeLazyLoading("splines")
aborting ...
/bin/bash: line 8: 18709 Done                    echo 
"tools:::makeLazyLoading(\"splines\")"
     18710 Segmentation fault      | R_COMPILE_PKGS=1 
R_COMPILER_SUPPRESS_ALL=1 R_DEFAULT_PACKAGES=NULL LC_ALL=C 
../../../bin/R --vanilla --slave > /dev/null
make[4]: *** [../../../library/splines/R/splines.rdb] Error 139
make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/splines'
make[3]: *** [all] Error 2
make[3]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/splines'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/mdalphin/src/R-2.15.3/src'
make: *** [R] Error 1
-------------------------------------------------------------------------------------------
make[4]: Entering directory 
`/home/mdalphin/src/R-2.15.3/src/library/splines'
make[4]: Nothing to be done for `mklazycomp'.
make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/splines'
make[3]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/splines'
make[3]: Entering directory `/home/mdalphin/src/R-2.15.3/src/library/stats4'
building package 'stats4'
mkdir -p -- ../../../library/stats4
make[4]: Entering directory `/home/mdalphin/src/R-2.15.3/src/library/stats4'
mkdir -p -- ../../../library/stats4/R
mkdir -p -- ../../../library/stats4/po
make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/stats4'
make[4]: Entering directory `/home/mdalphin/src/R-2.15.3/src/library/stats4'
byte-compiling package 'stats4'

 *** caught segfault ***
address 0x403ac3dc, cause 'invalid permissions'

Traceback:
 1: fun(libname, pkgname)
 2: doTryCatch(return(expr), name, parentenv, handler)
 3: tryCatchOne(expr, names, parentenv, handlers[[1L]])
 4: tryCatchList(expr, classes, parentenv, handlers)
 5: tryCatch(fun(libname, pkgname), error = identity)
 6: runHook(".onLoad", env, package.lib, package)
 7: loadNamespace(name)
 8: doTryCatch(return(expr), name, parentenv, handler)
 9: tryCatchOne(expr, names, parentenv, handlers[[1L]])
10: tryCatchList(expr, classes, parentenv, handlers)
11: tryCatch(loadNamespace(name), error = function(e) stop(e))
12: getNamespace(ns)
13: asNamespace(pkg)
14: get(name, envir = asNamespace(pkg), inherits = FALSE)
15: compiler:::tryCmpfun
16: .Call("R_lazyLoadDBinsertValue", x[[1L]], file, ascii, compress,     
hook, PACKAGE = "base")
17: lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, 
compress,     envhook)
18: makeLazyLoadDB(ns, dbbase, compress = compress)
19: code2LazyLoadDB(package, lib.loc = lib.loc, keep.source = 
keep.source,     compress = compress)
20: tools:::makeLazyLoading("stats4")
aborting ...
/bin/bash: line 8: 19554 Done                    echo 
"tools:::makeLazyLoading(\"stats4\")"
     19555 Segmentation fault      | R_COMPILE_PKGS=1 
R_COMPILER_SUPPRESS_ALL=1 R_DEFAULT_PACKAGES="methods,graphics,stats" 
LC_ALL=C ../../../bin/R --vanilla --slave > /dev/null
make[4]: *** [../../../library/stats4/R/stats4.rdb] Error 139
make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/stats4'
make[3]: *** [all] Error 2
make[3]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library/stats4'
make[2]: *** [R] Error 1
make[2]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library'
make[1]: *** [R] Error 1
make[1]: Leaving directory `/home/mdalphin/src/R-2.15.3/src'
make: *** [R] Error 1


-- 
	


    Mark Dalphin Ph.D.

Director of Bioinformatics

mark.dalphin at pacificedge.co.nz <mailto:mark.dalphin at pacificedge.co.nz>
*Ph:* +64-3-479-5805
*Cell:* +64-21-156-7625
*Skype:* mark.dalphin.pel
<http://www.facebook.com/pages/Pacific-Edge/111356775582456> 
<http://twitter.com/#%21/pacificEdgeLtd> 
<http://www.youtube.com/PacificEdgeLtd>

87 St David St, PO Box 56, Dunedin, New Zealand 9016www.pacificedge.co.nz


From smartpink111 at yahoo.com  Thu Jul 11 04:27:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 10 Jul 2013 19:27:32 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
In-Reply-To: <DUB116-W1175EDA485FCBCC1D4C94849E7A0@phx.gbl>
References: <1373238668238-4671059.post@n4.nabble.com>,
	<1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>,
	<DUB116-W5914520FB86D7D17F860709E780@phx.gbl>,
	<1373316818.12350.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<DUB116-W7077C1A830A1EFC6FCFD5E9E790@phx.gbl>
	<1373416561.33329.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<1373492568.37688.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<DUB116-W1175EDA485FCBCC1D4C94849E7A0@phx.gbl>
Message-ID: <1373509652.33022.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
I guess the error message:
> vmask(lat,lon,time,vmax=25)
Error en vmask(lat, lon,
time, vmax = 25) : objeto 'lat' no encontrado

says that you have not defined the object 'lat'.

time<-subset(Geo, select =date)
time[,1]<-? as.POSIXct(time[,1],format="%d/%m/%Y %H:%M")
location<- subset(Geo,select=c(lat.comp,long))
?time1<- time[,1]
?lat<- location[,1]
?long<- location[,2]
library(argosfilter)
?vmask(lat,long,time1,25)
#[1] "end_location" "end_location" "not"????????? "not"????????? "end_location"
#[6] "end_location"

A.K.
________________________________
From: laila Aranda Romero <laila_zgz at hotmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Wednesday, July 10, 2013 6:21 PM
Subject: RE: [R] Need hep for converting date data in POSIXct





Hi,

The code: 

library(argosfilter)
setwd("C:/Users/Usuario/Dropbox/Laila Aranda/PUFGRA")
Geo =?
read.table("2370001_PUFGRA_2009_Gough_000_retarded10_both.trj",header=FALSE,sep
= ",", col.names= c("type", "date",
"secs", "Trans1",? "Trans2",
"lat.sta",? "lat.comp", "long",?
"dist", "rumbo", "velocidad",?
"confianza"))
View(Geo)
location=subset(Geo, select= c(lat.comp,long))
time=subset(Geo, select =c(date))
time[,1]<-as.POSIXct(time[,1],format="%d/%m/%Y
%H:%M")???
vmask(lat,lon,time,vmax=25)




The example: library(argosfilter)
> setwd("C:/Users/Usuario/Dropbox/LailaAranda/PUFGRA")
> Geo =?read.table("2370001_PUFGRA_2009_Gough_000_retarded10_both.trj",header=FALSE,sep
= ",", col.names= c("type", "date","secs", "Trans1",?"Trans2", "lat.sta",?"lat.comp", "long",?"dist", "rumbo", "velocidad",? "confianza"))
> str(Geo)

'data.frame':? 582
obs. of? 12 variables:?$
type???? : Factor w/ 2 levels
"midnight","noon": 2 1 2 1 2 1 2 1 2 1 ...
?$
date???? : Factor w/ 582 levels
"01/01/2009 01:58",..: 370 389 390 409 410 429 430 450 451 471 ...

?$
secs???? : num? 39773 39773 39774 39774 39775 ...?$
Trans1?? : Factor w/ 186 levels
"04:06","04:08",..: 14 17 17 16 16 28 28 19 19 15 ...
?$
Trans2?? : Factor w/ 159 levels
"00:01","00:03",..: 30 30 28 28 34 34 35 35 36 36 ...
?$
lat.sta? : num? -42.7 -39.1 -37.8 -37.9 -41.2 ...
?$
lat.comp : num? -42.7 -40.6 -38.6 -37.9
-39 ...

?$
long???? : num? 9.31 11.66 10.88 10.72 13.06 ...
?$ dist???? : num?
0 0 127 45 131 ...
?$ rumbo???
: num? 0 0 -16.49 -9.64 -57.22 ...
?$ velocidad: num? 0 0 10.64 3.75 10.75 ...?$ confianza: int? 3 9 9 9 9 6 6 9 9 9
...
> head(Geo)
type???????????? date???? secs Trans1 Trans2 lat.sta lat.comp? long??
dist
1?noon 20/11/2008 12:23 39772.52?
04:59? 19:47? -42.72??
-42.72? 9.31?? 0.00
2 midnight 21/11/2008 00:33 39773.02? 05:18?
19:47? -39.14?? -40.63 11.66?? 0.00
3?noon 21/11/2008 12:29 39773.52?
05:18? 19:41? -37.82??
-38.60 10.88 127.02
4 midnight 22/11/2008 00:29 39774.02? 05:17?
19:41? -37.86?? -37.86 10.72?
45.04
5 noon 22/11/2008 12:39 39774.53?
05:17 ?20:00? -41.21??
-39.04 13.06 130.78
6 midnight 23/11/2008 00:50 39775.03? 05:41?
20:00? -36.56?? -38.51 16.02 142.06
?? rumbo
velocidad confianza
1??
0.00????? 0.00???????? 3
2??
0.00????? 0.00???????? 9
3 -16.49????
10.64???????? 9
4?
-9.64????? 3.75??? ?????9
5 -57.22????
10.75???????? 9
6?
77.07???? 11.66???????? 6
> location=subset(Geo, select=
c(lat.comp,long))

> str(location)
'data.frame':? 582
obs. of? 2 variables:
?$lat.comp: num? -42.7 -40.6 -38.6 -37.9 -39 ...
?$long??? : num? 9.31 11.66 10.88 10.72 13.06 ...
> head(location)

lat.comp? long
1??
-42.72? 9.31
2??
-40.63 11.66
3??
-38.60 10.88
4??
-37.86 10.72
5??
-39.04 13.06
6??
-38.51 16.02

> time=subset(Geo, select =c(date))
> time[,1]<-as.POSIXct(time[,1],format="%d/%m/%Y
%H:%M")
> str(time)
'data.frame':? 582
obs. of? 1 variable:
?$ date:
POSIXct, format: "2008-11-20 12:23:00" "2008-11-21
00:33:00" ...
> head(time)
???????????????? date
1 2008-11-20 12:23:00
2 2008-11-21 00:33:00
3 2008-11-21 12:29:00
4 2008-11-22 00:29:00
5 2008-11-22 12:39:00
6 2008-11-23 00:50:00
> vmask(lat,lon,time,vmax=25)
Error en vmask(lat, lon,
time, vmax = 25) : objeto 'lat' no encontrado


From h.mamaysky at gmail.com  Thu Jul 11 04:50:29 2013
From: h.mamaysky at gmail.com (Harry Mamaysky)
Date: Wed, 10 Jul 2013 22:50:29 -0400
Subject: [R] replacement functions for subsets
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C31B1FD@PA-MBX01.na.tibco.com>
References: <EA4DA008FDF38144A3E6F19B7E62C44D16312A90@EXTXMB41.nam.nsroot.net>
	<6AC1BA5B-D161-4C02-96C1-A8B45A61B198@gmail.com>
	<3B82DFC3-E6B7-4B85-97F7-F3E2ECFE4E30@comcast.net>
	<FA828FF6-2881-49A2-BF5F-92EB1FAC2696@gmail.com>
	<561A2E87-A273-488B-8A9E-7231BFC7CA63@comcast.net>
	<CACk-te3gei1y8gcYBUJUHHjnBaft3vMRcHwH9KsNEYmt-8x5Mw@mail.gmail.com>
	<E8F42D7A-2642-4422-ABCD-9F06DF501AC2@gmail.com>
	<E66794E69CFDE04D9A70842786030B931C31B1FD@PA-MBX01.na.tibco.com>
Message-ID: <CADb-Y1b6gAPv6f2A8my=k2cmmVYO1Ewy6ooAG_YKRni3Y+b7EQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130710/661d68d9/attachment.pl>

From miaojpm at gmail.com  Thu Jul 11 04:53:20 2013
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 11 Jul 2013 10:53:20 +0800
Subject: [R] Reserve word "in" could not be used it as a "dimname"?
Message-ID: <CABcx46Dm=gYHtktU_ueYujp+zz0_AyimLRsBuK7pE0RemFsRoA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/a30bc9de/attachment.pl>

From kridox at ymail.com  Thu Jul 11 05:03:48 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 11 Jul 2013 12:03:48 +0900
Subject: [R] Reserve word "in" could not be used it as a "dimname"?
In-Reply-To: <CABcx46Dm=gYHtktU_ueYujp+zz0_AyimLRsBuK7pE0RemFsRoA@mail.gmail.com>
References: <CABcx46Dm=gYHtktU_ueYujp+zz0_AyimLRsBuK7pE0RemFsRoA@mail.gmail.com>
Message-ID: <CAAcyNCyuNEwssfYZLPm9S6tzV1UmfddsOBf4ogABBr2whnnFdw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/684ebb70/attachment.pl>

From miaojpm at gmail.com  Thu Jul 11 05:37:01 2013
From: miaojpm at gmail.com (jpm miao)
Date: Thu, 11 Jul 2013 11:37:01 +0800
Subject: [R] Reserve word "in" could not be used it as a "dimname"?
In-Reply-To: <CAAcyNCyuNEwssfYZLPm9S6tzV1UmfddsOBf4ogABBr2whnnFdw@mail.gmail.com>
References: <CABcx46Dm=gYHtktU_ueYujp+zz0_AyimLRsBuK7pE0RemFsRoA@mail.gmail.com>
	<CAAcyNCyuNEwssfYZLPm9S6tzV1UmfddsOBf4ogABBr2whnnFdw@mail.gmail.com>
Message-ID: <CABcx46DUGo1i0fEh2_zY69Ze+__c33Hg=fq-Lq_3amU3rTwyXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/7a11d7cc/attachment.pl>

From kridox at ymail.com  Thu Jul 11 05:49:12 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 11 Jul 2013 12:49:12 +0900
Subject: [R] Reserve word "in" could not be used it as a "dimname"?
In-Reply-To: <CABcx46DUGo1i0fEh2_zY69Ze+__c33Hg=fq-Lq_3amU3rTwyXw@mail.gmail.com>
References: <CABcx46Dm=gYHtktU_ueYujp+zz0_AyimLRsBuK7pE0RemFsRoA@mail.gmail.com>
	<CAAcyNCyuNEwssfYZLPm9S6tzV1UmfddsOBf4ogABBr2whnnFdw@mail.gmail.com>
	<CABcx46DUGo1i0fEh2_zY69Ze+__c33Hg=fq-Lq_3amU3rTwyXw@mail.gmail.com>
Message-ID: <CAAcyNCyK5ecYfQ1bST4gWAynrSSVVmAkOsveke1O8xZ=x5XnUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/3ac5c30f/attachment.pl>

From mark.dalphin at pacificedge.co.nz  Thu Jul 11 06:59:15 2013
From: mark.dalphin at pacificedge.co.nz (Mark Dalphin)
Date: Thu, 11 Jul 2013 16:59:15 +1200
Subject: [R] [SOLVED] Problem building R-2.15.3 from source
In-Reply-To: <51DE06BD.2050802@pacificedge.co.nz>
References: <51DE06BD.2050802@pacificedge.co.nz>
Message-ID: <51DE3BA3.9070906@pacificedge.co.nz>

I have found a solution to the repeated seg-faults below.

If I set environment variables:
    setenv CFLAGS -O2
    setenv FFLAGS -O2
rather than the default -O3, then R builds and "checks" successfully.

A few more details about the Debian system on which I have been building:
     gcc (Debian 4.7.2-5) 4.7.2

My "configure" command is:
./configure                 \
    --prefix=$my_R_path \
    --with-readline     \
    --without-x         \
    --enable-R-shlib    \
    --enable-BLAS-shlib \
    --with-system-zlib  \
    --with-system-bzlib \
     --with-system-pcre

So, I'm good for the time being and hope this helps others who have 
trouble building from source.

Cheers,
Mark

Mark Dalphin wrote:
> Hi,
>
> I have for many years build R from source for Linux. I have just run 
> into my first problem with this in ... I don't know how long.
>
> uname -a
> Linux douglas 3.2.0-4-686-pae #1 SMP Debian 3.2.46-1 i686 GNU/Linux
>
> cat /etc/issue
> Debian GNU/Linux 7 \n \l
>
>
> The version of R is 2.15.3. I know it is old, but we are in a 
> regulated environment and changes to R versions are painful. I have 
> built R 2.15.3 elsewhere and have it running on multiple Linux boxes 
> around here, both 32-bit and 64-bit; Ubuntu distributions, however, 
> not Debian.
>
> This build is on a virtual machine under OpenBox. The host is a 64-bit 
> Debian; the guest is a 32-bit Debian installation.
>
> The symptoms are strange (to me). I get segfaults during the 
> byte-compiling phase of libraries. If I re-run 'make', the make 
> proceeds as if it finished the previous seg-faulted step, and then 
> segfaults on the next byte-compile. The "permissions" makes me wonder 
> about file permissions, but the whole 'make' is under my HOME. 
> Furthermore, I have scanned the unpacked tar-gz package for something 
> I don't "own" and it isn't there. I also think segfaults are usually 
> in memory, though I don't know what "permission" I have there (don't I 
> own the RAM I request?).
>
> I have attached a section of the 'make' output  below, followed by a 
> the next "make" output:
> ---------------------------------------------------------------------------------------------------------- 
>
> make[4]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/splines'
> make[4]: Entering directory 
> `/home/mdalphin/src/R-2.15.3/src/library/splines'
> byte-compiling package 'splines'
>
> *** caught segfault ***
> address 0x403ac3dc, cause 'invalid permissions'
>
> Traceback:
> 1: fun(libname, pkgname)
> 2: doTryCatch(return(expr), name, parentenv, handler)
> 3: tryCatchOne(expr, names, parentenv, handlers[[1L]])
> 4: tryCatchList(expr, classes, parentenv, handlers)
> 5: tryCatch(fun(libname, pkgname), error = identity)
> 6: runHook(".onLoad", env, package.lib, package)
> 7: loadNamespace(name)
> 8: doTryCatch(return(expr), name, parentenv, handler)
> 9: tryCatchOne(expr, names, parentenv, handlers[[1L]])
> 10: tryCatchList(expr, classes, parentenv, handlers)
> 11: tryCatch(loadNamespace(name), error = function(e) stop(e))
> 12: getNamespace(ns)
> 13: asNamespace(pkg)
> 14: get(name, envir = asNamespace(pkg), inherits = FALSE)
> 15: compiler:::tryCmpfun
> 16: .Call("R_lazyLoadDBinsertValue", x[[1L]], file, ascii, 
> compress,     hook, PACKAGE = "base")
> 17: lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, 
> compress,     envhook)
> 18: makeLazyLoadDB(ns, dbbase, compress = compress)
> 19: code2LazyLoadDB(package, lib.loc = lib.loc, keep.source = 
> keep.source,     compress = compress)
> 20: tools:::makeLazyLoading("splines")
> aborting ...
> /bin/bash: line 8: 18709 Done                    echo 
> "tools:::makeLazyLoading(\"splines\")"
>     18710 Segmentation fault      | R_COMPILE_PKGS=1 
> R_COMPILER_SUPPRESS_ALL=1 R_DEFAULT_PACKAGES=NULL LC_ALL=C 
> ../../../bin/R --vanilla --slave > /dev/null
> make[4]: *** [../../../library/splines/R/splines.rdb] Error 139
> make[4]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/splines'
> make[3]: *** [all] Error 2
> make[3]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/splines'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/mdalphin/src/R-2.15.3/src'
> make: *** [R] Error 1
> ------------------------------------------------------------------------------------------- 
>
> make[4]: Entering directory 
> `/home/mdalphin/src/R-2.15.3/src/library/splines'
> make[4]: Nothing to be done for `mklazycomp'.
> make[4]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/splines'
> make[3]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/splines'
> make[3]: Entering directory 
> `/home/mdalphin/src/R-2.15.3/src/library/stats4'
> building package 'stats4'
> mkdir -p -- ../../../library/stats4
> make[4]: Entering directory 
> `/home/mdalphin/src/R-2.15.3/src/library/stats4'
> mkdir -p -- ../../../library/stats4/R
> mkdir -p -- ../../../library/stats4/po
> make[4]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/stats4'
> make[4]: Entering directory 
> `/home/mdalphin/src/R-2.15.3/src/library/stats4'
> byte-compiling package 'stats4'
>
> *** caught segfault ***
> address 0x403ac3dc, cause 'invalid permissions'
>
> Traceback:
> 1: fun(libname, pkgname)
> 2: doTryCatch(return(expr), name, parentenv, handler)
> 3: tryCatchOne(expr, names, parentenv, handlers[[1L]])
> 4: tryCatchList(expr, classes, parentenv, handlers)
> 5: tryCatch(fun(libname, pkgname), error = identity)
> 6: runHook(".onLoad", env, package.lib, package)
> 7: loadNamespace(name)
> 8: doTryCatch(return(expr), name, parentenv, handler)
> 9: tryCatchOne(expr, names, parentenv, handlers[[1L]])
> 10: tryCatchList(expr, classes, parentenv, handlers)
> 11: tryCatch(loadNamespace(name), error = function(e) stop(e))
> 12: getNamespace(ns)
> 13: asNamespace(pkg)
> 14: get(name, envir = asNamespace(pkg), inherits = FALSE)
> 15: compiler:::tryCmpfun
> 16: .Call("R_lazyLoadDBinsertValue", x[[1L]], file, ascii, 
> compress,     hook, PACKAGE = "base")
> 17: lazyLoadDBinsertVariable(vars[i], from, datafile, ascii, 
> compress,     envhook)
> 18: makeLazyLoadDB(ns, dbbase, compress = compress)
> 19: code2LazyLoadDB(package, lib.loc = lib.loc, keep.source = 
> keep.source,     compress = compress)
> 20: tools:::makeLazyLoading("stats4")
> aborting ...
> /bin/bash: line 8: 19554 Done                    echo 
> "tools:::makeLazyLoading(\"stats4\")"
>     19555 Segmentation fault      | R_COMPILE_PKGS=1 
> R_COMPILER_SUPPRESS_ALL=1 R_DEFAULT_PACKAGES="methods,graphics,stats" 
> LC_ALL=C ../../../bin/R --vanilla --slave > /dev/null
> make[4]: *** [../../../library/stats4/R/stats4.rdb] Error 139
> make[4]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/stats4'
> make[3]: *** [all] Error 2
> make[3]: Leaving directory 
> `/home/mdalphin/src/R-2.15.3/src/library/stats4'
> make[2]: *** [R] Error 1
> make[2]: Leaving directory `/home/mdalphin/src/R-2.15.3/src/library'
> make[1]: *** [R] Error 1
> make[1]: Leaving directory `/home/mdalphin/src/R-2.15.3/src'
> make: *** [R] Error 1
>
>
> ------------------------------------------------------------------------
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>   

-- 
	


    Mark Dalphin Ph.D.

Director of Bioinformatics

mark.dalphin at pacificedge.co.nz <mailto:mark.dalphin at pacificedge.co.nz>
*Ph:* +64-3-479-5805
*Cell:* +64-21-156-7625
*Skype:* mark.dalphin.pel
<http://www.facebook.com/pages/Pacific-Edge/111356775582456> 
<http://twitter.com/#%21/pacificEdgeLtd> 
<http://www.youtube.com/PacificEdgeLtd>

87 St David St, PO Box 56, Dunedin, New Zealand 9016www.pacificedge.co.nz


From kridox at ymail.com  Thu Jul 11 07:44:46 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 11 Jul 2013 14:44:46 +0900
Subject: [R] [SOLVED] Problem building R-2.15.3 from source
In-Reply-To: <51DE3BA3.9070906@pacificedge.co.nz>
References: <51DE06BD.2050802@pacificedge.co.nz>
	<51DE3BA3.9070906@pacificedge.co.nz>
Message-ID: <CAAcyNCysb2cxkQPD_64d+W8bLHpgAXcgQJo4EqVkQ9sJCxg29Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/8d31caf1/attachment.pl>

From algerant at gmail.com  Thu Jul 11 07:49:27 2013
From: algerant at gmail.com (Bembi Prima)
Date: Thu, 11 Jul 2013 12:49:27 +0700
Subject: [R] Word occurrence rate in a tweet
Message-ID: <CAC5DFuCrdSR-drG=ppAS1vQ==XeR=kdyzQ6zup9P8gS+W2ydUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/c8d2c8b3/attachment.pl>

From ripley at stats.ox.ac.uk  Thu Jul 11 07:57:24 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Jul 2013 06:57:24 +0100
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
	<EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
Message-ID: <51DE4944.9030106@stats.ox.ac.uk>

On 11/07/2013 01:22, David Winsemius wrote:
>
> On Jul 10, 2013, at 4:37 PM, Lucy Leigh wrote:
>
>> Hi,
>> I have had a look at the manual but it makes no sense to me. I have
>> downloaded RTools, and the InnoSetup,
>> but I don't understand how to use these to install my package? Am I
>> meant to be writing commands
>> in R itself, or in these other things I've downloaded?
>
> Since you are clearly out of your league with respect to compiling from source, now is the time to ask (again), why are you not installing the binary package?
>
> At the R command line just type:
>
> install.packages("PReMiuM")  # should default to type="win.binary" and use a CRAN mirror
>

Or as she seems to want to use a later version than on CRAN, to ask 
again why she does not use winbuilder.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ripley at stats.ox.ac.uk  Thu Jul 11 08:05:41 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Jul 2013 07:05:41 +0100
Subject: [R] [SOLVED] Problem building R-2.15.3 from source
In-Reply-To: <CAAcyNCysb2cxkQPD_64d+W8bLHpgAXcgQJo4EqVkQ9sJCxg29Q@mail.gmail.com>
References: <51DE06BD.2050802@pacificedge.co.nz>
	<51DE3BA3.9070906@pacificedge.co.nz>
	<CAAcyNCysb2cxkQPD_64d+W8bLHpgAXcgQJo4EqVkQ9sJCxg29Q@mail.gmail.com>
Message-ID: <51DE4B35.5090404@stats.ox.ac.uk>

On 11/07/2013 06:44, Pascal Oettli wrote:
> Hello,
>
> Maybe the reason why:
>
> http://www.cran.r-project.org/doc/manuals/R-admin.html#Compilation-flags

And since this is a ix86 system, you really should be using -mtune=native.

I do not believe the default in 2.15.3 was -O3: it is not in current R, 
and it certainly included -g .


>
> Regards,
> Pascal
>
>
>
> 2013/7/11 Mark Dalphin <mark.dalphin at pacificedge.co.nz>
>
>> I have found a solution to the repeated seg-faults below.
>>
>> If I set environment variables:
>>     setenv CFLAGS -O2
>>     setenv FFLAGS -O2
>> rather than the default -O3, then R builds and "checks" successfully.
>>
>> A few more details about the Debian system on which I have been building:
>>      gcc (Debian 4.7.2-5) 4.7.2
>>
>> My "configure" command is:
>> ./configure                 \
>>     --prefix=$my_R_path \
>>     --with-readline     \
>>     --without-x         \
>>     --enable-R-shlib    \
>>     --enable-BLAS-shlib \
>>     --with-system-zlib  \
>>     --with-system-bzlib \
>>      --with-system-pcre
>>
>> So, I'm good for the time being and hope this helps others who have
>> trouble building from source.

Others who do not follow the instructions?  As the manual says at the end

'Beware of using high levels of optimization, at least initially. On 
many compilers these reduce the degree of compliance to the IEEE model.'



>>
>> Cheers,
>> Mark
>>
>> Mark Dalphin wrote:
>>
>>> Hi,
>>>
>>> I have for many years build R from source for Linux. I have just run into
>>> my first problem with this in ... I don't know how long.
>>>
>>> uname -a
>>> Linux douglas 3.2.0-4-686-pae #1 SMP Debian 3.2.46-1 i686 GNU/Linux
>>>
>>> cat /etc/issue
>>> Debian GNU/Linux 7 \n \l
>>>
>>>
>>> The version of R is 2.15.3. I know it is old, but we are in a regulated
>>> environment and changes to R versions are painful. I have built R 2.15.3
>>> elsewhere and have it running on multiple Linux boxes around here, both
>>> 32-bit and 64-bit; Ubuntu distributions, however, not Debian.
>>>
>>> This build is on a virtual machine under OpenBox. The host is a 64-bit
>>> Debian; the guest is a 32-bit Debian installation.
>>>
>>> The symptoms are strange (to me). I get segfaults during the
>>> byte-compiling phase of libraries. If I re-run 'make', the make proceeds as
>>> if it finished the previous seg-faulted step, and then segfaults on the
>>> next byte-compile. The "permissions" makes me wonder about file
>>> permissions, but the whole 'make' is under my HOME. Furthermore, I have
>>> scanned the unpacked tar-gz package for something I don't "own" and it
>>> isn't there. I also think segfaults are usually in memory, though I don't
>>> know what "permission" I have there (don't I own the RAM I request?).
>>>
>>> I have attached a section of the 'make' output  below, followed by a the
>>> next "make" output:
>>> ------------------------------**------------------------------**
>>> ------------------------------**----------------
>>> make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/splines'
>>> make[4]: Entering directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/splines'
>>> byte-compiling package 'splines'
>>>
>>> *** caught segfault ***
>>> address 0x403ac3dc, cause 'invalid permissions'
>>>
>>> Traceback:
>>> 1: fun(libname, pkgname)
>>> 2: doTryCatch(return(expr), name, parentenv, handler)
>>> 3: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>> 4: tryCatchList(expr, classes, parentenv, handlers)
>>> 5: tryCatch(fun(libname, pkgname), error = identity)
>>> 6: runHook(".onLoad", env, package.lib, package)
>>> 7: loadNamespace(name)
>>> 8: doTryCatch(return(expr), name, parentenv, handler)
>>> 9: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>> 10: tryCatchList(expr, classes, parentenv, handlers)
>>> 11: tryCatch(loadNamespace(name), error = function(e) stop(e))
>>> 12: getNamespace(ns)
>>> 13: asNamespace(pkg)
>>> 14: get(name, envir = asNamespace(pkg), inherits = FALSE)
>>> 15: compiler:::tryCmpfun
>>> 16: .Call("R_**lazyLoadDBinsertValue", x[[1L]], file, ascii, compress,
>>>    hook, PACKAGE = "base")
>>> 17: lazyLoadDBinsertVariable(vars[**i], from, datafile, ascii, compress,
>>>      envhook)
>>> 18: makeLazyLoadDB(ns, dbbase, compress = compress)
>>> 19: code2LazyLoadDB(package, lib.loc = lib.loc, keep.source =
>>> keep.source,     compress = compress)
>>> 20: tools:::makeLazyLoading("**splines")
>>> aborting ...
>>> /bin/bash: line 8: 18709 Done                    echo
>>> "tools:::makeLazyLoading(\"**splines\")"
>>>      18710 Segmentation fault      | R_COMPILE_PKGS=1
>>> R_COMPILER_SUPPRESS_ALL=1 R_DEFAULT_PACKAGES=NULL LC_ALL=C ../../../bin/R
>>> --vanilla --slave > /dev/null
>>> make[4]: *** [../../../library/splines/R/**splines.rdb] Error 139
>>> make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/splines'
>>> make[3]: *** [all] Error 2
>>> make[3]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/splines'
>>> make[2]: *** [R] Error 1
>>> make[2]: Leaving directory `/home/mdalphin/src/R-2.15.3/**src/library'
>>> make[1]: *** [R] Error 1
>>> make[1]: Leaving directory `/home/mdalphin/src/R-2.15.3/**src'
>>> make: *** [R] Error 1
>>> ------------------------------**------------------------------**
>>> ------------------------------**-
>>> make[4]: Entering directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/splines'
>>> make[4]: Nothing to be done for `mklazycomp'.
>>> make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/splines'
>>> make[3]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/splines'
>>> make[3]: Entering directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/stats4'
>>> building package 'stats4'
>>> mkdir -p -- ../../../library/stats4
>>> make[4]: Entering directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/stats4'
>>> mkdir -p -- ../../../library/stats4/R
>>> mkdir -p -- ../../../library/stats4/po
>>> make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/stats4'
>>> make[4]: Entering directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/stats4'
>>> byte-compiling package 'stats4'
>>>
>>> *** caught segfault ***
>>> address 0x403ac3dc, cause 'invalid permissions'
>>>
>>> Traceback:
>>> 1: fun(libname, pkgname)
>>> 2: doTryCatch(return(expr), name, parentenv, handler)
>>> 3: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>> 4: tryCatchList(expr, classes, parentenv, handlers)
>>> 5: tryCatch(fun(libname, pkgname), error = identity)
>>> 6: runHook(".onLoad", env, package.lib, package)
>>> 7: loadNamespace(name)
>>> 8: doTryCatch(return(expr), name, parentenv, handler)
>>> 9: tryCatchOne(expr, names, parentenv, handlers[[1L]])
>>> 10: tryCatchList(expr, classes, parentenv, handlers)
>>> 11: tryCatch(loadNamespace(name), error = function(e) stop(e))
>>> 12: getNamespace(ns)
>>> 13: asNamespace(pkg)
>>> 14: get(name, envir = asNamespace(pkg), inherits = FALSE)
>>> 15: compiler:::tryCmpfun
>>> 16: .Call("R_**lazyLoadDBinsertValue", x[[1L]], file, ascii, compress,
>>>    hook, PACKAGE = "base")
>>> 17: lazyLoadDBinsertVariable(vars[**i], from, datafile, ascii, compress,
>>>      envhook)
>>> 18: makeLazyLoadDB(ns, dbbase, compress = compress)
>>> 19: code2LazyLoadDB(package, lib.loc = lib.loc, keep.source =
>>> keep.source,     compress = compress)
>>> 20: tools:::makeLazyLoading("**stats4")
>>> aborting ...
>>> /bin/bash: line 8: 19554 Done                    echo
>>> "tools:::makeLazyLoading(\"**stats4\")"
>>>      19555 Segmentation fault      | R_COMPILE_PKGS=1
>>> R_COMPILER_SUPPRESS_ALL=1 R_DEFAULT_PACKAGES="methods,**graphics,stats"
>>> LC_ALL=C ../../../bin/R --vanilla --slave > /dev/null
>>> make[4]: *** [../../../library/stats4/R/**stats4.rdb] Error 139
>>> make[4]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/stats4'
>>> make[3]: *** [all] Error 2
>>> make[3]: Leaving directory `/home/mdalphin/src/R-2.15.3/**
>>> src/library/stats4'
>>> make[2]: *** [R] Error 1
>>> make[2]: Leaving directory `/home/mdalphin/src/R-2.15.3/**src/library'
>>> make[1]: *** [R] Error 1
>>> make[1]: Leaving directory `/home/mdalphin/src/R-2.15.3/**src'
>>> make: *** [R] Error 1
>>>
>>>
>>> ------------------------------**------------------------------**
>>> ------------
>>>
>>> ______________________________**________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/**listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
>>> PLEASE do read the posting guide http://www.R-project.org/**
>>> posting-guide.html <http://www.R-project.org/posting-guide.html>
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>
>> --
>>
>>
>>
>>     Mark Dalphin Ph.D.
>>
>> Director of Bioinformatics
>>
>> mark.dalphin at pacificedge.co.nz <mailto:mark.dalphin@**pacificedge.co.nz<mark.dalphin at pacificedge.co.nz>
>>>
>> *Ph:* +64-3-479-5805
>> *Cell:* +64-21-156-7625
>> *Skype:* mark.dalphin.pel
>> <http://www.facebook.com/**pages/Pacific-Edge/**111356775582456<http://www.facebook.com/pages/Pacific-Edge/111356775582456>>
>> <http://twitter.com/#%21/**pacificEdgeLtd<http://twitter.com/#%21/pacificEdgeLtd>>
>> <http://www.youtube.com/**PacificEdgeLtd<http://www.youtube.com/PacificEdgeLtd>
>>>
>>
>> 87 St David St, PO Box 56, Dunedin, New Zealand 9016www.pacificedge.co.nz
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bogaso.christofer at gmail.com  Thu Jul 11 08:36:38 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Thu, 11 Jul 2013 12:21:38 +0545
Subject: [R] Installing OpenBLAS in R
Message-ID: <CA+dpOJ=RGcw=EH4qDyvaa_DETrC3g1469sbVUvo3w+tPQNE5Qw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/8b67ce2f/attachment.pl>

From andy at 4ecap.com  Thu Jul 11 07:55:37 2013
From: andy at 4ecap.com (Andy Pranata)
Date: Thu, 11 Jul 2013 13:55:37 +0800
Subject: [R] Override setClass and setMethod in a package R 3.0.1
Message-ID: <CAAqat_Cef8-EWZq0JKRFmbV4xDmqw1A7verewMj_o5Eex+WxDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/114caa26/attachment.pl>

From Franz.Tscheikner-Gratl at uibk.ac.at  Thu Jul 11 08:53:19 2013
From: Franz.Tscheikner-Gratl at uibk.ac.at (ElSiebo)
Date: Wed, 10 Jul 2013 23:53:19 -0700 (PDT)
Subject: [R] GIS in R?
Message-ID: <1373525599493-4671296.post@n4.nabble.com>

Hi
Iam quite new to R and Iam trying to use it for GIS application.
I used the maptools package to load a shapefile 
WVA<-readShapeLines("WVA")

and now I would like to fill gaps in the shape file (missing numbers) with
the numbers from intersecting lines
I have tried with gintersect but I can only get true or false for answer and
not the numbers of the intersected lines...
For example for the first line....
gIntersects(WVA[1,],WVA, byid=TRUE)

Is there another possibility to do this?

Best regards
Franz



--
View this message in context: http://r.789695.n4.nabble.com/GIS-in-R-tp4671296.html
Sent from the R help mailing list archive at Nabble.com.


From bhh at xs4all.nl  Thu Jul 11 09:32:27 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 11 Jul 2013 09:32:27 +0200
Subject: [R] Recherche de fonction
In-Reply-To: <4565B2277456ED4EB03CD34B21283B472067BE8151@EXH01001.hmc.local>
References: <4565B2277456ED4EB03CD34B21283B472067BE80DC@EXH01001.hmc.local>
	<DF22D4DD-A6CD-4D07-97E5-1C352AA24B29@xs4all.nl>
	<CBB68FC6-ACAB-4CEF-983B-462F5FE4E96A@xs4all.nl>
	<4565B2277456ED4EB03CD34B21283B472067BE8151@EXH01001.hmc.local>
Message-ID: <BD5CCA84-F2D1-4B0F-8625-B97B1682DC11@xs4all.nl>


On 11-07-2013, at 09:04, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Hello,
> 
> Thank you for your reply, even though I wrote in French.
> 
> In reality, the variables r1, r4, r5 are expressed as functions of A, B, C, D, E, I and H, which are the variables I wish to calculate with the program. Those are expressed as functions of their derivatives in 6 of the 8 equation at my disposal. The two other equations are equilibrium that must be respected, and I found a publication in which they are solving this type of problem. Unfortunately, they did not say how.
> 
> Considering those two algebraic equation, I considered my problem to be an algebraic differential equation system, which is said, according to R deSolve package documentation, to be possibly solved by the function daspk or radau. But I can't seem to make it work.
> 
> For the initial values, the only ones I know for sure are A, B, C, D, E, I, G and H. Their derivatives are only approximations.  I used them because the R documentation seems to say it was necessary (in the exemple) and because the function told me it didn't know dA, which is the first differential variable. 
> 


1. You should keep replies on the list so that others can follow the discussion and offer advice. I am sending this reply to the list.

2. Let's see if my analysis of your problem is correct.
You have a system of differential equations with dA,dB,dC,dD,dE,dI,dG,dH (8 in stead of the 7 I mentioned previously. I missed dD).
You have two equilibrium equations with K2 and K3 which describe a relation between A,B,C and D which must always be true?

These differentials are expressed as a system of linear equations in terms of the state variables.
You can write this as

Matrix %*% column-vector(dA,dB,?) = vector depending on state variables

where the matrix is 6 x 8 and the d-vector  is 8x1.
That is an underdetermined system.

You could take the differential of the two equilibrium equations to get additional relationships between dA,dB,dC, and dD.
That should give you a square system of linear equations that you could solve with R's solve() assuming it is not singular or ill-conditioned.

I feel that you should try very hard to find out how such a system is solved in the paper you mention.

Before using deSolve you should first get the function that computes the d? variables in terms of the state variables working correctly.

Berend

> I will look at the link you proposed and see if I can make it work.
> 
> Rapha?lle Carraud
> 
> -----Message d'origine-----
> De : Berend Hasselman [mailto:bhh at xs4all.nl] 
> Envoy? : mercredi 10 juillet 2013 21:02
> ? : Rapha?lle Carraud
> Cc : r-help at r-project.org
> Objet : Re: [R] Recherche de fonction
> 
> 
> On 10-07-2013, at 20:42, Berend Hasselman <bhh at xs4all.nl> wrote:
> 
>> 
>> On 10-07-2013, at 16:21, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:
>> 
>>> Bonjour,
>>> 
>>> Je souhaite  r?soudre le couple d'?quation diff?rentielles suivant :
>>> 
>>>  0 = -dA + dB + 2*dC - 2*r1 - 2*r5
>>>  0 = dA + dD + r1 + r4
>>>  0 = K2 - C/B^2
>>>  0 = K3 - D/(A*B)
>>> 
>>>  0 = r5 + 2*r4 - dE
>>>  0 = r5 -dI
>>>  0 = -r5 - r4 - dG
>>>  0 = -r1/2 - dH
>>> 
>>> en ayant connaissance des valeurs initiales de dA, dB, dC, dE, dI, dG, dH, r1, r2, r4, r5, K2, K3, A, B, C et D.
>>> 
>> 
>> If all initial values are known then plugging the values in the system will give 0 or not 0. There is nothing to "solve".
>> 
>>> J'ai essay? plusieurs fonctions mais comme je ne peux pas lui faire calculer une des d?riv?e de laquelle d?coulerait les autre, il n'arrive pas ? me fournir la solution.
>>> Je n'ai pas vu d'exemple qui pourrai s'assimiler ? celui-ci dans la documentation.
>>> 
>> 
>> You will have to redo your query in English. Questions in French won't receive many replies.
>> My French is rudimentary but I'll try.
>> 
>> You have 8 equations and 17 variables.
>> So how do you propose to "solve" the system?
>> 
>> Assuming that the d? variables are differentials and that you want to solve for those:
>> you have 7 of these and 8 equations. So how to solve?
>> 
>> But the third and fourth equations have no d? variables, so the may even be inconsistent given the values of K2, K3, C, B, A, D.
>> So you have 6 equations for 7 d? variables. So how do you propose to solve for the d? variables?
>> 
>> Finally your system seems to be linear in the d? variables. You would be able to use R's solve()  if you can get your system to be a square system.
>> 
>> If your system is not square and underdetermined then you can use a 
>> Moore Penrose inverse to get a minimum norm solution (http://en.wikipedia.org/wiki/Moore-Penrose_pseudoinverse#Minimum-norm_solution_to_a_linear_system).
>> package MASS provides a function ginv().
> 
> 
> And to make matters simple: since your lefthand sides are 0 the minimum norm solution of your system is 0.
> 
> Berend
> 


From lath at energidanmark.dk  Thu Jul 11 09:04:45 2013
From: lath at energidanmark.dk (Lasse Thorst)
Date: Thu, 11 Jul 2013 07:04:45 +0000
Subject: [R] Saving forecast.Arima as data
Message-ID: <4DF642A8A770C24090F37AC3560BBA14F18115@EDAEXCH02A.local.energidanmark.dk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/b684cbf3/attachment.pl>

From raphaelle.carraud at oc-metalchem.com  Thu Jul 11 09:13:36 2013
From: raphaelle.carraud at oc-metalchem.com (=?iso-8859-1?Q?Rapha=EBlle_Carraud?=)
Date: Thu, 11 Jul 2013 09:13:36 +0200
Subject: [R] Differential problem
Message-ID: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/0a8b3275/attachment.pl>

From laila_zgz at hotmail.com  Thu Jul 11 09:36:35 2013
From: laila_zgz at hotmail.com (laila)
Date: Thu, 11 Jul 2013 00:36:35 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
In-Reply-To: <1373509652.33022.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1373238668238-4671059.post@n4.nabble.com>
	<1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<DUB116-W5914520FB86D7D17F860709E780@phx.gbl>
	<1373316818.12350.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<DUB116-W7077C1A830A1EFC6FCFD5E9E790@phx.gbl>
	<1373509652.33022.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <DUB116-W544E530BC0BAD5B4EF396E9E7B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/4ab8a511/attachment.pl>

From laila_zgz at hotmail.com  Thu Jul 11 09:38:11 2013
From: laila_zgz at hotmail.com (laila)
Date: Thu, 11 Jul 2013 00:38:11 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
In-Reply-To: <1373509652.33022.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1373238668238-4671059.post@n4.nabble.com>
	<1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<DUB116-W5914520FB86D7D17F860709E780@phx.gbl>
	<1373316818.12350.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<DUB116-W7077C1A830A1EFC6FCFD5E9E790@phx.gbl>
	<1373509652.33022.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <DUB116-W542B3F2886147D4110EE889E7B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/cbc0c7fa/attachment.pl>

From rolf.turner at xtra.co.nz  Thu Jul 11 10:37:53 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 11 Jul 2013 20:37:53 +1200
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DE4944.9030106@stats.ox.ac.uk>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
	<EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
	<51DE4944.9030106@stats.ox.ac.uk>
Message-ID: <51DE6EE1.4050608@xtra.co.nz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/706c6ce4/attachment.pl>

From ruipbarradas at sapo.pt  Thu Jul 11 10:41:44 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 11 Jul 2013 09:41:44 +0100
Subject: [R] Saving forecast.Arima as data
In-Reply-To: <4DF642A8A770C24090F37AC3560BBA14F18115@EDAEXCH02A.local.energidanmark.dk>
References: <4DF642A8A770C24090F37AC3560BBA14F18115@EDAEXCH02A.local.energidanmark.dk>
Message-ID: <51DE6FC8.3080607@sapo.pt>

Hello,

Try the following.

fr <- forecast.Arima(y0,h=3)
fr[["mean"]]


Hope this helps,

Rui Barradas

Em 11-07-2013 08:04, Lasse Thorst escreveu:
> Hi
>
> I am setting up a simple time series model, and I need the forecast to be saved in a format I later easily can work with/load into a database. The model will run once a day on new input and hence I want how it has performed to be easy to work with. The output for forecast.Arima(ts) or for example predict(ts) gives something that is easy to read, but I haven't been able to get it into a data.frame or as a vector or something similar.
>
> Example: forecasting 2 variables:
>
>> forecast.Arima(y0,h=3)
>
>        Point Forecast Lo 80 Hi 80 Lo 95 Hi 95
> 80.71          30.96 27.98 33.95 26.40 35.53
> 80.86          30.71 26.88 34.55 24.84 36.58
> 81.00          30.76 26.41 35.10 24.11 37.40
>
>> forecast.Arima(y1,h=3)
>
>        Point Forecast Lo 80 Hi 80 Lo 95 Hi 95
> 80.71          27.98 24.63 31.33 22.85 33.11
> 80.86          28.07 23.79 32.36 21.52 34.63
> 81.00          28.09 23.27 32.90 20.72 35.45
>
> Now I want to just extract the forecast (ex. 30.96, 30.71, 30.76) - How can I do that?
>
> Kind Regards,
> Lasse Thorst
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bhh at xs4all.nl  Thu Jul 11 11:17:54 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 11 Jul 2013 11:17:54 +0200
Subject: [R] Differential problem
In-Reply-To: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>
References: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>
Message-ID: <55BF8118-322D-4F61-8088-C79334D7108D@xs4all.nl>


On 11-07-2013, at 09:13, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Hello,
> 
> I have the following differential equation system to solve, the variables I wish to obtain being A, B, C, D, E, I, G and H.
> 
>    0 = -dA + dB + 2*dC - 2*r1 - 2*r5
>    0 = dA + dD + r1 + r4
>    0 = K2 - C/B^2
>    0 = K3 - D/(A*B)
> 
>    0 = r5 + 2*r4 - dE
>    0 = r5 -dI
>    0 = -r5 - r4 - dG
>    0 = -r1/2 - dH
> 
> r1, r4 and r5 are variables expressed as functions of A, B, C, D, I, G and H, calculated previously in the integrated function. K2 and K3 are parameters.
> 
> As I have two algebraic equations, I think this system is a DAE (Algebraic differential equation). I found in the package deSolve two functions that resolve DAE but I didn't manage to obtain a solution; it says that the variable dA cannot be found.
> 

Show us your script where you define the function and run the DAE solver. Without that nobody can provide an answer.

Berend.

> Does anyone know how to solve this problem?
> 
> Thank you
> 
> Rapha?lle Carraud
> 
> 
> Rapha?lle Carraud
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From HDoran at air.org  Thu Jul 11 11:53:40 2013
From: HDoran at air.org (Doran, Harold)
Date: Thu, 11 Jul 2013 09:53:40 +0000
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6862453AA2E@DC1VEX10MB001.air.org>
Message-ID: <CE03F873.ACF3%hdoran@air.org>

I sent this message yesterday with an attachment allowing for reproduction
of the issue. But I think the attachment is preventing the message from
coming through. If anyone is interested I will forward the attachment
directly allowing for you to reproduce the issue I observe.

On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:

>I have zero'd in on what appears to be the issue. This seems to be a bug
>in Matrix, but I am not sure yet. I am attaching files that would allow
>others to replicate this with my toy data.
>
>Notice the elements of D1 in the attached data are all integers. It is a
>sparse, diagonal matrix.
>
>> library(Matrix)
>> class(D1)
>[1] "ddiMatrix"
>attr(,"package")
>[1] "Matrix"
>
>Now, I find the inverse of the matrix A as follows:
>> A <- Ir + ZtZ %*% D1
>> A.Inv <- solve(A, Ir)
>
>Notice now the inverse of A remains a dgCMatrix and it is relatively
>small in size, only 33424 bytes.
>> class(A.Inv)
>[1] "dgCMatrix"
>attr(,"package")
>[1] "Matrix"
>
>> object.size(A.Inv)
>33424 bytes
>
>Now, if I change an element of the matrix D1 to be non-integer, D1 still
>has the same class as it did before
>
>> D1[1] <- 1.2
>
>> class(D1)
>[1] "ddiMatrix"
>attr(,"package")
>[1] "Matrix"
>
>Now, if I use this new version of D1 in the same calculations as above,
>notice that A.Inv is no longer a dgCMatrix but instead becomes a
>dgeMatrix. It then increases from an object of size 33424 bytes to an
>object of size 2001112 bytes!
>
>> A <- Ir + ZtZ %*% D1
>> A.Inv <- solve(A, Ir)
>> class(A.Inv)
>[1] "dgeMatrix"
>attr(,"package")
>[1] "Matrix"
>> object.size(A.Inv)
>2001112 bytes
>
>What I desire is that the object A.Inv remain sparse at all times and not
>become dense. But, perhaps there is a reason this change occurs that I
>don't fully understand.
>
>I can of course coerce it back to a sparse matrix and it reduces back in
>size.
>>  object.size(as(A.Inv, 'sparseMatrix'))
>33424 bytes
>
>I of course recognize it requires more memory to store floating points
>than integers, but is this large increase on the order of magnitude that
>seems about right?
>
>Is there a reason the floating point in D1 causes for A.Inv to no longer
>remain sparse?
>
>Thank you for your help,
>Harold
>
>
>
>
>
>-----Original Message-----
>From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
>On Behalf Of Doran, Harold
>Sent: Wednesday, July 10, 2013 11:42 AM
>To: r-help at r-project.org
>Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
>Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>
>I have a large function computing an iterative algorithm for fitting
>mixed linear models. Almost all code relies on functions from the Matrix
>package. I've come across an issue that I do not believe previously
>occurred in earlier versions of R or Matrix.
>
>I have a large, sparse matrix, A as
>
>> class(A);dim(A)
>[1] "dgCMatrix"
>attr(,"package")
>[1] "Matrix"
>[1] 12312 12312
>
>I am in a position where I must find its inverse.  I realize this is less
>than ideal, and I have two ways of doing this
>
>A.Inv <- solve(A, Ir) or just solve(A)
>
>Where Ir is an identity matrix with the same dimensions as A and it is
>also sparse
>
>> class(Ir)
>[1] "ddiMatrix"
>attr(,"package")
>[1] "Matrix"
>
>The issue, however, is that the inverse of A is converted into a dense
>matrix and this becomes a huge memory hog, causing the rest of the
>algorithm to fail. In prior versions this remained as a sparse matrix.
>
>> A.Inv[1:5, 1:5]
>5 x 5 Matrix of class "dgeMatrix"
>          [,1]      [,2]      [,3]      [,4]      [,5]
>[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,] 0.0000000
>0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
>0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
>0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000 0.2139975
>
>I could coerce this matrix to become sparse such as
>
>> AA <- as(A.Inv, 'sparseMatrix')
>> class(AA)
>[1] "dgCMatrix"
>attr(,"package")
>[1] "Matrix"
>
>> AA[1:5, 1:5]
>5 x 5 sparse Matrix of class "dgCMatrix"
>
>[1,] 0.6878713 .         .         .         .
>[2,] .         0.6718767 .         .         .
>[3,] .         .         0.5076945 .         .
>[4,] .         .         .         0.2324122 .
>[5,] .         .         .         .         0.2139975
>
>But I don't think this is best.
>
>So, my question is why is a matrix that is sparse turning into a dense
>matrix? Can I avoid that and keep it sparse without having to coerce it
>to be sparse after it is created?
>
>Thank you very much
>Harold
>
>
>> sessionInfo()
>R version 3.0.1 (2013-05-16)
>Platform: x86_64-w64-mingw32/x64 (64-bit)
>
>locale:
>[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C [5]
>LC_TIME=English_United States.1252
>
>attached base packages:
>[1] stats     graphics  grDevices utils     datasets  methods   base
>
>other attached packages:
>[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
>
>loaded via a namespace (and not attached):
>[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From gallon.li at gmail.com  Thu Jul 11 11:56:51 2013
From: gallon.li at gmail.com (Gallon Li)
Date: Thu, 11 Jul 2013 17:56:51 +0800
Subject: [R] calculate time from dates
Message-ID: <CAKO0Dpi0u4ckOGxLECcztLKm_AeTGvmgPqADX3gAuB_D8bDO1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/4f8a5a72/attachment.pl>

From djandrija at gmail.com  Thu Jul 11 12:03:50 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Thu, 11 Jul 2013 12:03:50 +0200
Subject: [R] calculate time from dates
In-Reply-To: <CAKO0Dpi0u4ckOGxLECcztLKm_AeTGvmgPqADX3gAuB_D8bDO1w@mail.gmail.com>
References: <CAKO0Dpi0u4ckOGxLECcztLKm_AeTGvmgPqADX3gAuB_D8bDO1w@mail.gmail.com>
Message-ID: <CABcwgRRqXjwujB9EeELfLMu1qJBRSOHJkNM_P7ZNjsvWF_gtkA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/6facaa40/attachment.pl>

From S.Ellison at LGCGroup.com  Thu Jul 11 12:07:02 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 11 Jul 2013 11:07:02 +0100
Subject: [R] Reserve word "in" could not be used it as a "dimname"?
In-Reply-To: <CAAcyNCyK5ecYfQ1bST4gWAynrSSVVmAkOsveke1O8xZ=x5XnUg@mail.gmail.com>
References: <CABcx46Dm=gYHtktU_ueYujp+zz0_AyimLRsBuK7pE0RemFsRoA@mail.gmail.com>
	<CAAcyNCyuNEwssfYZLPm9S6tzV1UmfddsOBf4ogABBr2whnnFdw@mail.gmail.com>
	<CABcx46DUGo1i0fEh2_zY69Ze+__c33Hg=fq-Lq_3amU3rTwyXw@mail.gmail.com>
	<CAAcyNCyK5ecYfQ1bST4gWAynrSSVVmAkOsveke1O8xZ=x5XnUg@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACB8A67CA@GOLD.corp.lgc-group.com>

 

> -----Original Message-----
> "Reserved words outside quotes are always parsed to be 
> references to the objects linked to in the 'Description', and 
> hence they are not allowed as syntactic names (see 
> make.names). They are allowed as non-syntactic names, e.g. 
> inside backtick quotes."
> 
> You should prefer the use of "[" rather than "$".

The magic of $ also allows dat$"in" or dat$'in'

But you may have a happier time if you rename the columns to "In" and "Out", neither of which is reserved.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From bhh at xs4all.nl  Thu Jul 11 12:32:33 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 11 Jul 2013 12:32:33 +0200
Subject: [R] Differential problem
In-Reply-To: <4565B2277456ED4EB03CD34B21283B472067BE81CA@EXH01001.hmc.local>
References: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>
	<55BF8118-322D-4F61-8088-C79334D7108D@xs4all.nl>
	<4565B2277456ED4EB03CD34B21283B472067BE81CA@EXH01001.hmc.local>
Message-ID: <E7CBAAC6-131F-4CAC-BD6C-3DFDBBE5825C@xs4all.nl>


On 11-07-2013, at 12:05, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Sorry,
> 
> Here is the program I have until now:
> 
> reaction<-function(z, state, dval, parameters) {
>  with(as.list(c(state)),{
> 
>    K2 <- 10^(2993/Tr-9.226)*(10^-3)       
>    K3 <- 10^(2072/Tr-7.234)*(10^-3)
>    K4 <- 10^(-20.83/Tr-0.5012)
>    K5 <- 10^(-965.5/Tr-1.481)
>    k1 <- (10^(652.1/Tr-0.7356))*(8.314*Tr/P)^2
>    kf2 <- 1.4*10^-33*(Tr/300)^(-3.8)*6.022*10^23*10^-6
>    kb2 <- kf2/K2*P/(8.314*Tr)
>    kf3 <- 3.1*10^-34*(Tr/300)^(-7.7)*10^(-6)*6.022*10^23
>    kb3 <- kf3/K3*P/(8.314*Tr)
>    kf4 <- 41
>    kf5 <- 0.25
> 
>    r1 <- k1*A^2*H
>    r4 <- kf4*D*G - kf4/K4*E^2
>    r5 <- kf5*C*G - kf5/K5*E*I
> 
>    res1 <- -dA + dB + 2*dC - 2*r1 - 2*r5          
>    res2 <- dA + dD + r1 + r4                     
>    res3 <- K2 - C/B^2                             
>    res4 <- K3 - D/(A*B)                           
>    res5 <- r5 + 2*r4 - dE           
>    res6 <- r5 -dI                 
>    res7 <- -r5 - r4 - dG             
>    res8 <- -r1/2 - dH                
> 
>    list(c(res1, res2, res3, res4, res5, res6, res7, res8))
>  })   # end with(as.list ...
> }
> 
> Ti <- 273+90      #K
> Pt <- 0.98*10^5   #Pa
> 
> xi <- c(0.3,   #x_NO
>        0.1,   #x_NO2
>        0,     #x_N2O4
>        0,     #x_N2O3
>        0.05,  #x_HNO2
>        0.05,  #x_HNO3
>        0.2,   #x_H2O
>        0.3)   #x_O2
> 
> state <- c(A = xi[1]*Pt,
>           B = xi[2]*Pt,
>           C = xi[3]*Pt,
>           D = xi[4]*Pt,
>           E = xi[5]*Pt,
>           I = xi[6]*Pt,
>           G = xi[7]*Pt,
>           H = xi[8]*Pt)
> 
> dval <- c(dA = 1,
>          dB = 1,
>          dC = 0.5,
>          dD = 0.2,
>          dE = 0,
>          dI = 0,
>          dG = 0,
>          dH = 0)
> 
> parameters <- c(Pt = 0.98*10^5)
> 
> z <- seq(0, 1, by = 0.01)  
> 
> library(deSolve)
> out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 0)
> head(out)
> plot(out)
> 


When I run this I get this error message:

Error in eval(expr, envir, enclos) : object 'Tr' not found

And shouldn't the first line of the reaction function be this

with(as.list(c(state,dval,parameters)),{

in stead of this

with(as.list(c(state)),{

The call of daspk also seems incorrect; shouldn't it be

out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = parameters)

And finally: where does variable P come from? Not defined anywhere!

Berend


> -----Message d'origine-----
> De : Berend Hasselman [mailto:bhh at xs4all.nl] 
> Envoy? : jeudi 11 juillet 2013 11:18
> ? : Rapha?lle Carraud
> Cc : r-help at r-project.org
> Objet : Re: [R] Differential problem
> 
> 
> On 11-07-2013, at 09:13, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:
> 
>> Hello,
>> 
>> I have the following differential equation system to solve, the variables I wish to obtain being A, B, C, D, E, I, G and H.
>> 
>>   0 = -dA + dB + 2*dC - 2*r1 - 2*r5
>>   0 = dA + dD + r1 + r4
>>   0 = K2 - C/B^2
>>   0 = K3 - D/(A*B)
>> 
>>   0 = r5 + 2*r4 - dE
>>   0 = r5 -dI
>>   0 = -r5 - r4 - dG
>>   0 = -r1/2 - dH
>> 
>> r1, r4 and r5 are variables expressed as functions of A, B, C, D, I, G and H, calculated previously in the integrated function. K2 and K3 are parameters.
>> 
>> As I have two algebraic equations, I think this system is a DAE (Algebraic differential equation). I found in the package deSolve two functions that resolve DAE but I didn't manage to obtain a solution; it says that the variable dA cannot be found.
>> 
> 
> Show us your script where you define the function and run the DAE solver. Without that nobody can provide an answer.
> 
> Berend.
> 
>> Does anyone know how to solve this problem?
>> 
>> Thank you
>> 
>> Rapha?lle Carraud
>> 
>> 
>> Rapha?lle Carraud
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From smartpink111 at yahoo.com  Thu Jul 11 12:51:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 03:51:19 -0700 (PDT)
Subject: [R] calculate time from dates
In-Reply-To: <CAKO0Dpi0u4ckOGxLECcztLKm_AeTGvmgPqADX3gAuB_D8bDO1w@mail.gmail.com>
References: <CAKO0Dpi0u4ckOGxLECcztLKm_AeTGvmgPqADX3gAuB_D8bDO1w@mail.gmail.com>
Message-ID: <1373539879.89934.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
May be this helps:


dat1<- read.table(text="
ID date
1 4/12/2008
1 4/13/2008
1 5/11/2008
2 3/21/2009
2 4/22/2009
2 8/05/2009
",sep="",header=TRUE,stringsAsFactors=FALSE)
library(mondate)
M1<- mondate(dat1[,2])
M2<- mondate("01/01/2008")
dat1$month<-as.numeric(abs(floor(MonthsBetween(M1,M2))))
?dat1
#? ID????? date month
#1? 1 4/12/2008???? 4
#2? 1 4/13/2008???? 4
#3? 1 5/11/2008???? 5
#4? 2 3/21/2009??? 15
#5? 2 4/22/2009??? 16
#6? 2 8/05/2009??? 20
A.K.



----- Original Message -----
From: Gallon Li <gallon.li at gmail.com>
To: r-help <r-help at stat.math.ethz.ch>
Cc: 
Sent: Thursday, July 11, 2013 5:56 AM
Subject: [R] calculate time from dates

My data are from 2008 to 2010, with repeated measures for same subjects. I
wish to compute number of months since january 2008.

The data are like the following:

ID date
1 4/12/2008
1 4/13/2008
1 5/11/2008
2 3/21/2009
2 4/22/2009
2 8/05/2009
...

the date column are in the format "%m/%d/%y". i wish to obtain

ID month
1 4
1 4
1 5
2 15
2 16
2 20
...

also, for the same ID with two identical month, I only want to keep the
last one. can any expert help with this question?

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From A.Serebrenik at tue.nl  Thu Jul 11 12:56:19 2013
From: A.Serebrenik at tue.nl (aserebrenik)
Date: Thu, 11 Jul 2013 03:56:19 -0700 (PDT)
Subject: [R] ** REMINDER ** Academic study of R users and developers
Message-ID: <1373540179269-4671315.post@n4.nabble.com>

Dear all,

A group of researchers from Eindhoven Univ of Technology (The Netherlands)
and UC Davis (USA) is conducting a study of support activities in R. In this
study, our goal is to understand how R user support activities have been
evolving over time, in the presence of different information exchange media,
such as mailing lists, forums, blogs or question&answer websites. 

Your participation is voluntary and confidential. If you agree to
participate, you will be asked to complete self-report measures that tell us
a bit about your information seeking and information providing experiences
related to R. Participation in this study is expected to take about 10
minutes of your time.

We thank you in advance for your participation in this study. We plan to
include the results of this survey in a scientific publication. Individual
responses cannot be traced back to an individual respondent.

survey
<https://docs.google.com/forms/d/14dXaSdy2NJ94Fq50fAbmEr3_GK8XfbRdys9qPLMMZ-c/viewform>    

Best regards,
Alexander Serebrenik
Eindhoven Univ Technology
The Netherlands



--
View this message in context: http://r.789695.n4.nabble.com/REMINDER-Academic-study-of-R-users-and-developers-tp4671315.html
Sent from the R help mailing list archive at Nabble.com.


From kamil at czarnogorski.pl  Thu Jul 11 11:58:11 2013
From: kamil at czarnogorski.pl (=?ISO-8859-1?Q?Kamil_Czarnog=F3rski?=)
Date: Thu, 11 Jul 2013 10:58:11 +0100
Subject: [R] Lda - topic inference of new document
Message-ID: <CAFtQcFr9fyVVxYk6SUhyVPpjKiDHaOJ13_+SAN1W6m6rL0SeLQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/e5083269/attachment.pl>

From l.roca at gmx.us  Thu Jul 11 11:54:20 2013
From: l.roca at gmx.us (Lluis)
Date: Thu, 11 Jul 2013 02:54:20 -0700 (PDT)
Subject: [R] LDA and confidence ellipse
Message-ID: <1373536460259-4671308.post@n4.nabble.com>

Hi,

I wish to add confidence ellipse on my LDA result of the iris data set.
Therefore:
Is there statistical logic to do that as I only wish it to make the species
separation more visable?
How can I add it to the script below  (ggplot): 
require(MASS)
require(ggplot2)
iris.lda<-lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length +
Petal.Width,  data = iris)
LD1<-predict(iris.lda)$x[,1]
LD2<-predict(iris.lda)$x[,2]
ggplot(iris, aes(x=LD1, y=LD2, col=iris$Species) ) + geom_point( size = 4,
aes(color = iris$Species))+theme_bw()   

Could someone please help me. Thank you very much.



--
View this message in context: http://r.789695.n4.nabble.com/LDA-and-confidence-ellipse-tp4671308.html
Sent from the R help mailing list archive at Nabble.com.


From raphaelle.carraud at oc-metalchem.com  Thu Jul 11 12:05:32 2013
From: raphaelle.carraud at oc-metalchem.com (=?iso-8859-1?Q?Rapha=EBlle_Carraud?=)
Date: Thu, 11 Jul 2013 12:05:32 +0200
Subject: [R] Differential problem
In-Reply-To: <55BF8118-322D-4F61-8088-C79334D7108D@xs4all.nl>
References: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>
	<55BF8118-322D-4F61-8088-C79334D7108D@xs4all.nl>
Message-ID: <4565B2277456ED4EB03CD34B21283B472067BE81CA@EXH01001.hmc.local>

Sorry,

Here is the program I have until now:

reaction<-function(z, state, dval, parameters) {
  with(as.list(c(state)),{

    K2 <- 10^(2993/Tr-9.226)*(10^-3)       
    K3 <- 10^(2072/Tr-7.234)*(10^-3)
    K4 <- 10^(-20.83/Tr-0.5012)
    K5 <- 10^(-965.5/Tr-1.481)
    k1 <- (10^(652.1/Tr-0.7356))*(8.314*Tr/P)^2
    kf2 <- 1.4*10^-33*(Tr/300)^(-3.8)*6.022*10^23*10^-6
    kb2 <- kf2/K2*P/(8.314*Tr)
    kf3 <- 3.1*10^-34*(Tr/300)^(-7.7)*10^(-6)*6.022*10^23
    kb3 <- kf3/K3*P/(8.314*Tr)
    kf4 <- 41
    kf5 <- 0.25

    r1 <- k1*A^2*H
    r4 <- kf4*D*G - kf4/K4*E^2
    r5 <- kf5*C*G - kf5/K5*E*I
    
    res1 <- -dA + dB + 2*dC - 2*r1 - 2*r5          
    res2 <- dA + dD + r1 + r4                     
    res3 <- K2 - C/B^2                             
    res4 <- K3 - D/(A*B)                           
    res5 <- r5 + 2*r4 - dE           
    res6 <- r5 -dI                 
    res7 <- -r5 - r4 - dG             
    res8 <- -r1/2 - dH                

    list(c(res1, res2, res3, res4, res5, res6, res7, res8))
  })   # end with(as.list ...
}

Ti <- 273+90      #K
Pt <- 0.98*10^5   #Pa

xi <- c(0.3,   #x_NO
        0.1,   #x_NO2
        0,     #x_N2O4
        0,     #x_N2O3
        0.05,  #x_HNO2
        0.05,  #x_HNO3
        0.2,   #x_H2O
        0.3)   #x_O2

state <- c(A = xi[1]*Pt,
           B = xi[2]*Pt,
           C = xi[3]*Pt,
           D = xi[4]*Pt,
           E = xi[5]*Pt,
           I = xi[6]*Pt,
           G = xi[7]*Pt,
           H = xi[8]*Pt)

dval <- c(dA = 1,
          dB = 1,
          dC = 0.5,
          dD = 0.2,
          dE = 0,
          dI = 0,
          dG = 0,
          dH = 0)

parameters <- c(Pt = 0.98*10^5)

z <- seq(0, 1, by = 0.01)  

library(deSolve)
out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 0)
head(out)
plot(out)

-----Message d'origine-----
De?: Berend Hasselman [mailto:bhh at xs4all.nl] 
Envoy??: jeudi 11 juillet 2013 11:18
??: Rapha?lle Carraud
Cc?: r-help at r-project.org
Objet?: Re: [R] Differential problem


On 11-07-2013, at 09:13, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Hello,
> 
> I have the following differential equation system to solve, the variables I wish to obtain being A, B, C, D, E, I, G and H.
> 
>    0 = -dA + dB + 2*dC - 2*r1 - 2*r5
>    0 = dA + dD + r1 + r4
>    0 = K2 - C/B^2
>    0 = K3 - D/(A*B)
> 
>    0 = r5 + 2*r4 - dE
>    0 = r5 -dI
>    0 = -r5 - r4 - dG
>    0 = -r1/2 - dH
> 
> r1, r4 and r5 are variables expressed as functions of A, B, C, D, I, G and H, calculated previously in the integrated function. K2 and K3 are parameters.
> 
> As I have two algebraic equations, I think this system is a DAE (Algebraic differential equation). I found in the package deSolve two functions that resolve DAE but I didn't manage to obtain a solution; it says that the variable dA cannot be found.
> 

Show us your script where you define the function and run the DAE solver. Without that nobody can provide an answer.

Berend.

> Does anyone know how to solve this problem?
> 
> Thank you
> 
> Rapha?lle Carraud
> 
> 
> Rapha?lle Carraud
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Thu Jul 11 13:00:07 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 11 Jul 2013 12:00:07 +0100
Subject: [R] calculate time from dates
In-Reply-To: <CABcwgRRqXjwujB9EeELfLMu1qJBRSOHJkNM_P7ZNjsvWF_gtkA@mail.gmail.com>
References: <CAKO0Dpi0u4ckOGxLECcztLKm_AeTGvmgPqADX3gAuB_D8bDO1w@mail.gmail.com>
	<CABcwgRRqXjwujB9EeELfLMu1qJBRSOHJkNM_P7ZNjsvWF_gtkA@mail.gmail.com>
Message-ID: <51DE9037.2090603@sapo.pt>

Hello,

The functions in stackoverflow need a date 'format' argument.



# Functions from
# 
http://stackoverflow.com/questions/1995933/number-of-months-between-two-dates
# with a 'format' argument added
#
# turn a date into a 'monthnumber' relative to an origin
monnb <- function(d, format = "%Y-%m-%d") {
	lt <- as.POSIXlt(as.Date(d, origin="1900-01-01", format = format))
	lt$year*12 + lt$mon
}
# compute a month difference as a difference between two monnb's
mondf <- function(d1, d2, format = "%Y-%m-%d") {
	monnb(d2, format = format) - monnb(d1, format = format)
}


dat1 <- read.table(text = "
ID date
1 4/12/2008
1 4/13/2008
1 5/11/2008
2 3/21/2009
2 4/22/2009
2 8/05/2009
", header = TRUE)

dat2 <- data.frame(ID = dat1$ID, month = mondf("01/01/2008", dat1$date, 
format = "%m/%d/%Y") + 1)

# Now keep just the last one if month diffs are equal
result <- with(dat2, aggregate(month, list(ID, month), FUN = tail, 1))[1:2]
names(result) <- names(dat2)
result


Hope this helps,

Rui Barradas

Em 11-07-2013 11:03, andrija djurovic escreveu:
> Hi.
>
> See
> http://stackoverflow.com/questions/1995933/number-of-months-between-two-dates
>
> Andrija
>
>
> On Thu, Jul 11, 2013 at 11:56 AM, Gallon Li <gallon.li at gmail.com> wrote:
>
>> My data are from 2008 to 2010, with repeated measures for same subjects. I
>> wish to compute number of months since january 2008.
>>
>> The data are like the following:
>>
>> ID date
>> 1 4/12/2008
>> 1 4/13/2008
>> 1 5/11/2008
>> 2 3/21/2009
>> 2 4/22/2009
>> 2 8/05/2009
>> ...
>>
>> the date column are in the format "%m/%d/%y". i wish to obtain
>>
>> ID month
>> 1 4
>> 1 4
>> 1 5
>> 2 15
>> 2 16
>> 2 20
>> ...
>>
>> also, for the same ID with two identical month, I only want to keep the
>> last one. can any expert help with this question?
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jannetta at henning.org  Thu Jul 11 13:18:41 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Thu, 11 Jul 2013 12:18:41 +0100
Subject: [R] Error in read.table
Message-ID: <CAGR4ry60EPr08PiBo0JYGAmmP0yH12R9+PG+=uscdNbfSuYdDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/1e03b20c/attachment.pl>

From xiangduxiuzy at gmail.com  Thu Jul 11 13:50:45 2013
From: xiangduxiuzy at gmail.com (Dante.py)
Date: Thu, 11 Jul 2013 19:50:45 +0800
Subject: [R] Error in read.table
In-Reply-To: <CAGR4ry60EPr08PiBo0JYGAmmP0yH12R9+PG+=uscdNbfSuYdDg@mail.gmail.com>
References: <CAGR4ry60EPr08PiBo0JYGAmmP0yH12R9+PG+=uscdNbfSuYdDg@mail.gmail.com>
Message-ID: <CADrtQZz5++hH-+TprXYuObWLvLGuUvi326yw654DK9OSDOfmDw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/17a27f13/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 11 13:54:13 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 04:54:13 -0700 (PDT)
Subject: [R] Read a txt file as numeric
Message-ID: <1373543653.60894.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:
dat1<- read.table(text="
142,QUANTIZE_CAL_MIN_BAND_10,1
143,QUANTIZE_CAL_MAX_BAND_11,65535
144,QUANTIZE_CAL_MIN_BAND_11,1
145,END_GROUP,MIN_MAX_PIXEL_VALUE
146,GROUP,RADIOMETRIC_RESCALING
147,RADIANCE_MULT_BAND_1,1.2483E-02
148,RADIANCE_MULT_BAND_2,1.2730E-02
",sep=",",header=FALSE,stringsAsFactors=FALSE,row.names=1)

#Assuming that 142, 143, etc are row.names.
#You could create a new column with just the numeric values leaving the strings in the 2nd column.
dat1$NewCol<-as.numeric(ifelse(grepl("\\d+",dat1[,2]),dat1[,2],NA))
dat1[,2][grepl("\\d+",dat1[,2])]<-NA
dat1
#????????????????????????? V2??????????????????? V3???? NewCol
#142 QUANTIZE_CAL_MIN_BAND_10????????????????? <NA> 1.0000e+00
#143 QUANTIZE_CAL_MAX_BAND_11????????????????? <NA> 6.5535e+04
#144 QUANTIZE_CAL_MIN_BAND_11????????????????? <NA> 1.0000e+00
#145??????????????? END_GROUP?? MIN_MAX_PIXEL_VALUE???????? NA
#146??????????????????? GROUP RADIOMETRIC_RESCALING???????? NA
#147???? RADIANCE_MULT_BAND_1????????????????? <NA> 1.2483e-02
#148???? RADIANCE_MULT_BAND_2????????????????? <NA> 1.2730e-02
?str(dat1)
#'data.frame':??? 7 obs. of? 3 variables:
# $ V2??? : chr? "QUANTIZE_CAL_MIN_BAND_10" "QUANTIZE_CAL_MAX_BAND_11" "QUANTIZE_CAL_MIN_BAND_11" "END_GROUP" ...
# $ V3??? : chr? NA NA NA "MIN_MAX_PIXEL_VALUE" ...
# $ NewCol: num? 1 65535 1 NA NA ...

A.K.


Hello, 

I am relatively new to the R community. 
I have a .txt file containing the metafile with informations 
regarding landsat calibration parameters. This contains 2 columns: one 
with the description of the parameter and the other one with the value 
of the parameter. The problem is that the column with the values 
contains also words in some cases, which I believe makes the 
read.table() read the column not as a numeric value. 
This is an example of how it looks like: 

142 ? ? ? ? ? QUANTIZE_CAL_MIN_BAND_10 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1 142 
143 ? ? ? ? ? QUANTIZE_CAL_MAX_BAND_11 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?65535 143 
144 ? ? ? ? ? QUANTIZE_CAL_MIN_BAND_11 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?1 144 
145 ? ? ? ? ? ? ? ? ? ? ? ? ?END_GROUP ? ? ? ? ? ? ? ? ? ? ? ? ? ?MIN_MAX_PIXEL_VALUE 145 
146 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ?GROUP ? ? ? ? ? ? ? ? ? ? ? ? ?RADIOMETRIC_RESCALING 146 
147 ? ? ? ? ? ? ? RADIANCE_MULT_BAND_1 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1.2483E-02 147 
148 ? ? ? ? ? ? ? RADIANCE_MULT_BAND_2 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1.2730E-02 148 
149 ? ? ? ? ? ? ? RADIANCE_MULT_BAND_3 ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? ? 1.1656E-02 149 

I need the left column to be read as numeric, does anyone have some good suggestion on how to approach this problem? 

Thank you in advance. 

Stefano


From bhh at xs4all.nl  Thu Jul 11 14:12:33 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 11 Jul 2013 14:12:33 +0200
Subject: [R] Differential problem
In-Reply-To: <4565B2277456ED4EB03CD34B21283B472067BE81E6@EXH01001.hmc.local>
References: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>
	<55BF8118-322D-4F61-8088-C79334D7108D@xs4all.nl>
	<4565B2277456ED4EB03CD34B21283B472067BE81CA@EXH01001.hmc.local>
	<E7CBAAC6-131F-4CAC-BD6C-3DFDBBE5825C@xs4all.nl>
	<4565B2277456ED4EB03CD34B21283B472067BE81E6@EXH01001.hmc.local>
Message-ID: <933AD69C-1C62-45A2-BF88-7D6A50664DFD@xs4all.nl>


On 11-07-2013, at 13:53, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Sorry for the bug, I had eliminated some lines to avoid making the program too big. Here is the version that works :
> 
> reaction<-function(z, state, dval, parameters) {
>  with(as.list(c(state)),{
>    # rate of change
> 
>    Tr <- 273+90
>    P <- 0.98*10^5
> 
>    K2 <- 10^(2993/Tr-9.226)*(10^-3)       
>    K3 <- 10^(2072/Tr-7.234)*(10^-3)
>    K4 <- 10^(-20.83/Tr-0.5012)
>    K5 <- 10^(-965.5/Tr-1.481)
>    k1 <- (10^(652.1/Tr-0.7356))*(8.314*Tr/P)^2
>    kf2 <- 1.4*10^-33*(Tr/300)^(-3.8)*6.022*10^23*10^-6
>    kb2 <- kf2/K2*P/(8.314*Tr)
>    kf3 <- 3.1*10^-34*(Tr/300)^(-7.7)*10^(-6)*6.022*10^23
>    kb3 <- kf3/K3*P/(8.314*Tr)
>    kf4 <- 41
>    kf5 <- 0.25
> 
>    r1 <- k1*A^2*H
>    r4 <- kf4*D*G - kf4/K4*E^2
>    r5 <- kf5*C*G - kf5/K5*E*I
> 
>    res1 <- -dA + dB + 2*dC - 2*r1 - 2*r5          #
>    res2 <- dA + dD + r1 + r4                     #
>    res3 <- K2 - C/B^2                             #
>    res4 <- K3 - D/(A*B)                           #
>    res5 <- r5 + 2*r4 - dE             #dHNO2/dz
>    res6 <- r5 -dI                   #dHNO3/dz
>    res7 <- -r5 - r4 - dG             #dH2O/dz
>    res8 <- -r1/2 - dH                #dO2/dz
> 
>    list(c(res1, res2, res3, res4, res5, res6, res7, res8))
>  })   # end with(as.list ...
> }
> 
> xi <- c(0.3,   #x_NO
>        0.1,   #x_NO2
>        0,     #x_N2O4
>        0,     #x_N2O3
>        0.05,  #x_HNO2
>        0.05,  #x_HNO3
>        0.2,   #x_H2O
>        0.3)   #x_O2
> 
> 
> state <- c(A = xi[1]*Pt,
>           B = xi[2]*Pt,
>           C = xi[3]*Pt,
>           D = xi[4]*Pt,
>           E = xi[5]*Pt,
>           I = xi[6]*Pt,
>           G = xi[7]*Pt,
>           H = xi[8]*Pt)
> 
> dval <- c(dA = 1,
>          dB = 1,
>          dC = 0.5,
>          dD = 0.2,
>          dE = 0,
>          dI = 0,
>          dG = 0,
>          dH = 0)
> 
> parameters <- c(Pt = 0.98*10^5)
> 

Doesn't run.
Since variable Pt is not defined when you calculate vector state. So define Pt <- ?. before xi as in the original example.

In the function reaction isn't variable P just Pt from the parameter vector?
If so then either do P <- Pt or just use Pt directly (but see next remark).


> z <- seq(0, 1, by = 0.01)  # en seconde
> 
> library(deSolve)
> #out <- ode(y = state, times = z, func = reaction, parameters)
> 
> out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 0)
> head(out)
> plot(out)
> 
> I obtain the following message:
> 
>> library(deSolve)
>> #out <- ode(y = state, times = z, func = reaction, parameters)
>> 
>> out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 0)
> Error in eval(expr, envir, enclos) : object 'dA' not found.
> 

Obviously since dA  isn't defined outside of dval when the functions was defined.
And do parms=parameters if you want to use Pt (as I told you in the previous post).

> I tried adding the dval and parameters as you said:
> with(as.list(c(state,dval,parameters)),{
> 
> I get the following message:
> 
> Warning messages:
> 1: In daspk(y = state, dy = dval, times = z, res = reaction, parms = 0) :
>  matrix of partial derivatives is singular with direct method-some equations redundant
> 2: In daspk(y = state, dy = dval, times = z, res = reaction, parms = 0) :
>  Returning early. Results are accurate, as far as they go
> 

These are warning messages.
You get plots.
So now is the time to start looking at initial values etc.

Since I know next to nothing about DAE's you are on your own here unless someone else comes up with suggestions.

> For the calling of the daspk function, I followed the documentation, where you have the same inversion:
> 
> daefun <- function(t, y, dy, parameters) {
> + res1 <- dy[1] + y[1] - y[2]
> + res2 <- y[2] * y[1] - t
> +
> + list(c(res1, res2))
> + }
>> library(deSolve)
>> yini <- c(1, 0)
>> dyini <- c(1, 0)
>> times <- seq(0, 10, 0.1)
>> ## solver
>> system.time(out <- daspk(y = yini, dy = dyini, times = times, res = daefun, parms = 0))
> 
> Is it wrong? When I modify the order, I obtain again that object dA is not found, so I guessed the doc was right.
> 

Of course see above.

Berend


From raphaelle.carraud at oc-metalchem.com  Thu Jul 11 13:53:29 2013
From: raphaelle.carraud at oc-metalchem.com (=?iso-8859-1?Q?Rapha=EBlle_Carraud?=)
Date: Thu, 11 Jul 2013 13:53:29 +0200
Subject: [R] Differential problem
In-Reply-To: <E7CBAAC6-131F-4CAC-BD6C-3DFDBBE5825C@xs4all.nl>
References: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>
	<55BF8118-322D-4F61-8088-C79334D7108D@xs4all.nl>
	<4565B2277456ED4EB03CD34B21283B472067BE81CA@EXH01001.hmc.local>
	<E7CBAAC6-131F-4CAC-BD6C-3DFDBBE5825C@xs4all.nl>
Message-ID: <4565B2277456ED4EB03CD34B21283B472067BE81E6@EXH01001.hmc.local>

Sorry for the bug, I had eliminated some lines to avoid making the program too big. Here is the version that works :

reaction<-function(z, state, dval, parameters) {
  with(as.list(c(state)),{
    # rate of change

    Tr <- 273+90
    P <- 0.98*10^5
    
    K2 <- 10^(2993/Tr-9.226)*(10^-3)       
    K3 <- 10^(2072/Tr-7.234)*(10^-3)
    K4 <- 10^(-20.83/Tr-0.5012)
    K5 <- 10^(-965.5/Tr-1.481)
    k1 <- (10^(652.1/Tr-0.7356))*(8.314*Tr/P)^2
    kf2 <- 1.4*10^-33*(Tr/300)^(-3.8)*6.022*10^23*10^-6
    kb2 <- kf2/K2*P/(8.314*Tr)
    kf3 <- 3.1*10^-34*(Tr/300)^(-7.7)*10^(-6)*6.022*10^23
    kb3 <- kf3/K3*P/(8.314*Tr)
    kf4 <- 41
    kf5 <- 0.25

    r1 <- k1*A^2*H
    r4 <- kf4*D*G - kf4/K4*E^2
    r5 <- kf5*C*G - kf5/K5*E*I
    
    res1 <- -dA + dB + 2*dC - 2*r1 - 2*r5          #
    res2 <- dA + dD + r1 + r4                     #
    res3 <- K2 - C/B^2                             #
    res4 <- K3 - D/(A*B)                           #
    res5 <- r5 + 2*r4 - dE             #dHNO2/dz
    res6 <- r5 -dI                   #dHNO3/dz
    res7 <- -r5 - r4 - dG             #dH2O/dz
    res8 <- -r1/2 - dH                #dO2/dz

    list(c(res1, res2, res3, res4, res5, res6, res7, res8))
  })   # end with(as.list ...
}

xi <- c(0.3,   #x_NO
        0.1,   #x_NO2
        0,     #x_N2O4
        0,     #x_N2O3
        0.05,  #x_HNO2
        0.05,  #x_HNO3
        0.2,   #x_H2O
        0.3)   #x_O2


state <- c(A = xi[1]*Pt,
           B = xi[2]*Pt,
           C = xi[3]*Pt,
           D = xi[4]*Pt,
           E = xi[5]*Pt,
           I = xi[6]*Pt,
           G = xi[7]*Pt,
           H = xi[8]*Pt)

dval <- c(dA = 1,
          dB = 1,
          dC = 0.5,
          dD = 0.2,
          dE = 0,
          dI = 0,
          dG = 0,
          dH = 0)

parameters <- c(Pt = 0.98*10^5)

z <- seq(0, 1, by = 0.01)  # en seconde

library(deSolve)
#out <- ode(y = state, times = z, func = reaction, parameters)

out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 0)
head(out)
plot(out)

I obtain the following message:

> library(deSolve)
> #out <- ode(y = state, times = z, func = reaction, parameters)
> 
> out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 0)
Error in eval(expr, envir, enclos) : object 'dA' not found.

I tried adding the dval and parameters as you said:
with(as.list(c(state,dval,parameters)),{

 I get the following message:

Warning messages:
1: In daspk(y = state, dy = dval, times = z, res = reaction, parms = 0) :
  matrix of partial derivatives is singular with direct method-some equations redundant
2: In daspk(y = state, dy = dval, times = z, res = reaction, parms = 0) :
  Returning early. Results are accurate, as far as they go

For the calling of the daspk function, I followed the documentation, where you have the same inversion:

daefun <- function(t, y, dy, parameters) {
+ res1 <- dy[1] + y[1] - y[2]
+ res2 <- y[2] * y[1] - t
+
+ list(c(res1, res2))
+ }
> library(deSolve)
> yini <- c(1, 0)
> dyini <- c(1, 0)
> times <- seq(0, 10, 0.1)
> ## solver
> system.time(out <- daspk(y = yini, dy = dyini, times = times, res = daefun, parms = 0))

Is it wrong? When I modify the order, I obtain again that object dA is not found, so I guessed the doc was right.


-----Message d'origine-----
De?: Berend Hasselman [mailto:bhh at xs4all.nl] 
Envoy??: jeudi 11 juillet 2013 12:33
??: Rapha?lle Carraud
Cc?: r-help at r-project.org
Objet?: Re: [R] Differential problem


On 11-07-2013, at 12:05, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Sorry,
> 
> Here is the program I have until now:
> 
> reaction<-function(z, state, dval, parameters) {  
> with(as.list(c(state)),{
> 
>    K2 <- 10^(2993/Tr-9.226)*(10^-3)       
>    K3 <- 10^(2072/Tr-7.234)*(10^-3)
>    K4 <- 10^(-20.83/Tr-0.5012)
>    K5 <- 10^(-965.5/Tr-1.481)
>    k1 <- (10^(652.1/Tr-0.7356))*(8.314*Tr/P)^2
>    kf2 <- 1.4*10^-33*(Tr/300)^(-3.8)*6.022*10^23*10^-6
>    kb2 <- kf2/K2*P/(8.314*Tr)
>    kf3 <- 3.1*10^-34*(Tr/300)^(-7.7)*10^(-6)*6.022*10^23
>    kb3 <- kf3/K3*P/(8.314*Tr)
>    kf4 <- 41
>    kf5 <- 0.25
> 
>    r1 <- k1*A^2*H
>    r4 <- kf4*D*G - kf4/K4*E^2
>    r5 <- kf5*C*G - kf5/K5*E*I
> 
>    res1 <- -dA + dB + 2*dC - 2*r1 - 2*r5          
>    res2 <- dA + dD + r1 + r4                     
>    res3 <- K2 - C/B^2                             
>    res4 <- K3 - D/(A*B)                           
>    res5 <- r5 + 2*r4 - dE           
>    res6 <- r5 -dI                 
>    res7 <- -r5 - r4 - dG             
>    res8 <- -r1/2 - dH                
> 
>    list(c(res1, res2, res3, res4, res5, res6, res7, res8))
>  })   # end with(as.list ...
> }
> 
> Ti <- 273+90      #K
> Pt <- 0.98*10^5   #Pa
> 
> xi <- c(0.3,   #x_NO
>        0.1,   #x_NO2
>        0,     #x_N2O4
>        0,     #x_N2O3
>        0.05,  #x_HNO2
>        0.05,  #x_HNO3
>        0.2,   #x_H2O
>        0.3)   #x_O2
> 
> state <- c(A = xi[1]*Pt,
>           B = xi[2]*Pt,
>           C = xi[3]*Pt,
>           D = xi[4]*Pt,
>           E = xi[5]*Pt,
>           I = xi[6]*Pt,
>           G = xi[7]*Pt,
>           H = xi[8]*Pt)
> 
> dval <- c(dA = 1,
>          dB = 1,
>          dC = 0.5,
>          dD = 0.2,
>          dE = 0,
>          dI = 0,
>          dG = 0,
>          dH = 0)
> 
> parameters <- c(Pt = 0.98*10^5)
> 
> z <- seq(0, 1, by = 0.01)
> 
> library(deSolve)
> out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 
> 0)
> head(out)
> plot(out)
> 


When I run this I get this error message:

Error in eval(expr, envir, enclos) : object 'Tr' not found

And shouldn't the first line of the reaction function be this

with(as.list(c(state,dval,parameters)),{

in stead of this

with(as.list(c(state)),{

The call of daspk also seems incorrect; shouldn't it be

out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = parameters)

And finally: where does variable P come from? Not defined anywhere!

Berend


> -----Message d'origine-----
> De : Berend Hasselman [mailto:bhh at xs4all.nl] Envoy? : jeudi 11 juillet 
> 2013 11:18 ? : Rapha?lle Carraud Cc : r-help at r-project.org Objet : Re: 
> [R] Differential problem
> 
> 
> On 11-07-2013, at 09:13, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:
> 
>> Hello,
>> 
>> I have the following differential equation system to solve, the variables I wish to obtain being A, B, C, D, E, I, G and H.
>> 
>>   0 = -dA + dB + 2*dC - 2*r1 - 2*r5
>>   0 = dA + dD + r1 + r4
>>   0 = K2 - C/B^2
>>   0 = K3 - D/(A*B)
>> 
>>   0 = r5 + 2*r4 - dE
>>   0 = r5 -dI
>>   0 = -r5 - r4 - dG
>>   0 = -r1/2 - dH
>> 
>> r1, r4 and r5 are variables expressed as functions of A, B, C, D, I, G and H, calculated previously in the integrated function. K2 and K3 are parameters.
>> 
>> As I have two algebraic equations, I think this system is a DAE (Algebraic differential equation). I found in the package deSolve two functions that resolve DAE but I didn't manage to obtain a solution; it says that the variable dA cannot be found.
>> 
> 
> Show us your script where you define the function and run the DAE solver. Without that nobody can provide an answer.
> 
> Berend.
> 
>> Does anyone know how to solve this problem?
>> 
>> Thank you
>> 
>> Rapha?lle Carraud
>> 
>> 
>> Rapha?lle Carraud
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From jriley at usgs.gov  Thu Jul 11 13:48:49 2013
From: jriley at usgs.gov (Riley, Jeffrey)
Date: Thu, 11 Jul 2013 07:48:49 -0400
Subject: [R] GIS in R?
In-Reply-To: <1373525599493-4671296.post@n4.nabble.com>
References: <1373525599493-4671296.post@n4.nabble.com>
Message-ID: <CAGOhUxa6nLgNSgLC3dtDv2K5o=POFJ=mFVTSfz99wNSXdw0tvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/2ef618d0/attachment.pl>

From t.pieterek at googlemail.com  Thu Jul 11 13:46:01 2013
From: t.pieterek at googlemail.com (Tonio Pieterek)
Date: Thu, 11 Jul 2013 13:46:01 +0200
Subject: [R] Differences between glmmPQL and lmer and AIC calculation
Message-ID: <CAN9sA6GUJU5U+LV8o76_iyyUja79_Fh==A4WbEH1bma61phnDg@mail.gmail.com>

Dear R Community,



I?m relatively new in the field of R and I hope someone of you can
help me to solve my nerv-racking problem.



For my Master thesis I collected some behavioral data of fish using
acoustic telemetry. The aim of the study is to compare two different
groups of fish (coded as 0 and 1 which should be the dependent
variable) based on their swimming activity, habitat choice, etc.
(independent variables). Each fish has several observations over time
(repeated measurements) which I included as random factor in my models
using library glmmPQL (package MASS). Because I have a binary data
structure, I am using generalized linear mixed models.

Using library glmmPQL the results reflect my descriptive analyses and
the results are sound. However, we also want to rank several candidate
models using AIC. And this is where the problems start. Because
glmmPQL does not provide AIC values or comparable measures, I also
tried to calculate the same models using function lmer. Against
expectations, I got completely different results from these two
libraries (glmmPQL = highly significant; lmer = far away from being
significant with p = 0.9xx).


I used the following codes:


cal1=glmmPQL(y ~ activity, random=~1|id, data=data, family=binomial,
na.action=na.omit)

> WORKS FINE



cal1 = lmer(y ? activity + (1 | id ), family = binomial, data=data,
na.action=na.omit)

> PRODUCED misleading and totally different results compared to glmmPQL (e.g. sometimes error message occurs: In mer_finalize(ans) : false convergence (8); even for very simple models)



A glmmML did not work since we got the following failure message, for
which we were not able to find out the reason and therefore could not
go on with this model:



?[glmmml] fail = 1

                               Max. No. of iterations reached without
convergence

Warnmeldungen:

                               1: In model.response(mf, "numeric") :

                               using type="numeric" with a factor
response will be ignored

                               2: In glmmML.fit(X, Y, weights,
cluster.weights, start.coef, start.sigma,  :
                3: In glmmML(y ~ activity,  :

                               'vmmin' did not converge. Increase 'maxit'??



The questions are:



1) Why did glmmPQL and lmer produce completely different results and
how can I solve this problem? Following Zuur et al. 2009* the models
should provide very similar results, but they didn`t.



2) Can I calculate AIC values (or something comparable) using library glmmPQL?



 3) Is there any other option (library) to analyze my data including an AIC?



If something remained unclear or if you have any question about
details, please let me know.

I would really appreciate any kind of help referring to my problem(s).



Many thanks in advance!


All the best,

Tonio




*Alain F. Zuur,  Elena N. Ieno,  Neil J. Walker, Anatoly A. Saveliev,
Graham M. Smith. (2009). Mixed Effects Models and Extensions in
Ecology with R. Springer Science+Business Media, New York, USA.



ISSN 1431-8776

ISBN 978-0-387-87457-9

DOI 10.1007/978-0-387-87458-6


From katha.mibi at web.de  Thu Jul 11 13:21:02 2013
From: katha.mibi at web.de (Kathrinchen)
Date: Thu, 11 Jul 2013 04:21:02 -0700 (PDT)
Subject: [R] Testing for weak exogeneity in a SUR ECM
Message-ID: <1373541662853-4671321.post@n4.nabble.com>

Dear all,

I have set up a Labour Demand Error Correction Model for some German federal
states.

As I expect the labour markets to be correlated I used a Seemingly Unrelated
Regression using systemfit in R.

My Model  is:

d(emp)_it = c + alpha*ln(emp)_i,t-1 + beta_1*ln(gdp)_i,t-1 + +
beta_2*ln(wage)_i,t-1 + + beta_1*ln(i)_i,t-1 + gamma_1*d(gdp)_it +
gamma_2*d(wage)_it

with emp_it being the employment in state i at time t, i stands for the real
interest rate, ln() is the logarithmed data, while d() stands for the
difference operator.

I would like to test now for weak exogeneity and I am not quite sure what
kind of regression to run.  If I run: 
d(gdp)_it = c + alpha*ln(emp)_i,t-1 + beta_1*ln(gdp)_i,t-1 + +
beta_2*ln(wage)_i,t-1 + + beta_1*ln(i)_i,t-1 + gamma_1*d(emp)_it +
gamma_2*d(wage)_it

with Systemfit, alpha is statistically significant, so I have to reject the
hypothesis of weak exogeneity...Literature is in my opinion not so clear on
what to test!

I use data from an application, they conclude that endogeneity is not a
problem: they regress the possible endogenous variables "on the presumed
equilibrium relation, a constant and one autoregressive lag" - here I am not
sure, what they mean.

I would very much appreciate your help!

Thanks a lot!





--
View this message in context: http://r.789695.n4.nabble.com/Testing-for-weak-exogeneity-in-a-SUR-ECM-tp4671321.html
Sent from the R help mailing list archive at Nabble.com.


From pdalgd at gmail.com  Thu Jul 11 14:27:48 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 11 Jul 2013 14:27:48 +0200
Subject: [R] Error in read.table
In-Reply-To: <CADrtQZz5++hH-+TprXYuObWLvLGuUvi326yw654DK9OSDOfmDw@mail.gmail.com>
References: <CAGR4ry60EPr08PiBo0JYGAmmP0yH12R9+PG+=uscdNbfSuYdDg@mail.gmail.com>
	<CADrtQZz5++hH-+TprXYuObWLvLGuUvi326yw654DK9OSDOfmDw@mail.gmail.com>
Message-ID: <567D856E-4400-400B-9C46-A2C6C69EE1DF@gmail.com>


On Jul 11, 2013, at 13:50 , Dante.py wrote:

> Maybe you should set parameter "as.is" in read.csv to be false.

TRUE more likely... However, there's another issue: files[i,] is a data frame, therefore so is f[1] (a telltale sign is that it has rows and column labels). So f[[1]] is probably needed.

> 
> 
> 2013/7/11 Jannetta Steyn <jannetta at henning.org>
> 
>> Hi Folks
>> 
>> I can't see what I have done wrong in this piece of code.
>> 
>> # Read filenames from csv file
>> files <- read.csv(file="files.csv",head=FALSE,sep=",")
>> 
>> # for each filename read the file
>> for (i in 1:length(files)) {
>>  # f becomes the next row inthe file
>>  f<-files[i,]
>>  # the header to be used for the graph is in column 2 of f
>>  head=f[2]
>>  par(mfrow=c(4,2))
>>  # the filename to be used is in column 1 of f
>>  con<-read.csv(file=f[1], header=TRUE, sep=',')
>>  tmp<-con$value2
>>  data<-normalize_js(tmp,-1,1)
>>  time<-con$time
>>  # run the waveform analyser
>>  waveformanalyser(data,time,head)
>> }
>> 
>> I get an error:
>> Error in read.table(file = file, header = header, sep = sep, quote = quote,
>> :
>>  'file' must be a character string or connection
>> 
>> When the error occurs f equals:
>>> f
>>                                     V1     V2
>> 1 ANA110915004A_3PERIOD_TmAvg-rdata.csv Pre-DA
>> 
>> and f[1] equals:
>> 
>>> f[1]
>>                                     V1
>> 1 ANA110915004A_3PERIOD_TmAvg-rdata.csv
>> 
>> 
>> Why won't it use the value of f[1] as a string for the file parameter in
>> the read.csv line?
>> 
>> All help would be apprecitated.
>> Regards
>> Jannetta
>> 
>> 
>> 
>> --
>> 
>> ===================================
>> Web site: http://www.jannetta.com
>> Email: jannetta at henning.org
>> ===================================
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> 
> -- 
> ???? Dante.py
> ????????09????????????????????
> ??????????http://dantepy.yslsg.org/
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From f.harrell at vanderbilt.edu  Thu Jul 11 14:33:28 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Thu, 11 Jul 2013 07:33:28 -0500
Subject: [R] [R-pkgs] Major Update to rms package
Message-ID: <51DEA618.2030205@vanderbilt.edu>

The rms ("Regression Modeling Strategies") package has undergone a 
massive update.  The entire list of updates is at the bottom of this 
note.  CRAN has the update for linux and will soon have it for Windows 
and Mac - check http://cran.r-project.org/web/packages/rms/ for 
availability.  This rms update relies on a major update of the Hmisc 
package.

The most user-visible changes are:
   * Addition of a major new modeling function orm ("ordinal regression 
model") that supports 5 distribution families (one being the logistic, 
for proportional odds models) and is meant for continuous Y.  Sparse 
matrix operations (helped greatly by the SparseM package) allows 
thousands of intercepts to be fitted when there are thousands of unique 
Y values.  New function generators Mean, Quantile, and ExProb 
(exceedance probability distribution) have been added.  A detailed case 
study is in http://biostat.mc.vanderbilt.edu/CourseBios330 Chapter 15. 
Ordinal regression is now a direct competitor to linear models, and far 
more robust, even allowing spikes in the distribution of Y.
    * More generality and ease of obtaining bootstrap confidence limits 
for all estimands (predictions, contrasts).  The basic bootstrap is now 
implemented and tends to work better than the percentile bootstrap in 
terms of confidence coverage.
    * Change of Surv to Srv
    * Added tk/tcl progress bars for bootstrap and other repeated 
calculations.  This can be turned off by specifying 
options(showprogress=FALSE) or options(showprogress='console') to use 
cat().  Use options(showevery=50) to update the progress bar only every 
50 iterations.
    * Made all design matrices stored in model fits exclude any 
intercepts, with columns of ones added as needed with Predict() etc.
    * Dxy and c-index are now calculated with Therneau's survival 
package survConcordance functions which is blazing fast so can be used 
routinely in all model validations that used Dxy
    * plot.summary.rms now produces cleaner output with fewer confidence 
levels
    * Several bug corrections

---------------------------------------------------------------------

Changes in version 4.0-0 (2013-07-10)
    * Cleaned up label logic in Surv, made it work with interval2 
(thanks:Chris Andrews)
    * Fixed bug in val.prob - wrong denominator for Brier score if obs 
removed for logistic calibration
    * Fixed inconsistency in predictrms where predict() for Cox models 
used a design matrix that was centered on medians and modes rather than 
means (thanks: David van Klaveren <d.vanklaveren.1 at erasmusmc.nl>)
    * Added mean absolute prediction error to Rq output
    * Made pr argument passed to predab.resample more encompassing
    * Fixed logLik method for ols
    * Made contrast.rms and summary.rms automatically compute bootstrap 
nonparametric confidence limits if fit was run through bootcov
    * Fixed bug in Predict where conf.type='simultaneous' was being 
ignored if bootstrap coefficients were present
    * For plot.Predict made default gray scale shaded confidence bands 
darker
    * For bootcov exposed eps argument to fitters and default to lower value
    * Fixed bug in plot.pentrace regarding effective.df plotting
    * Added setPb function for pop-up progress bars for simulations; 
turn off using options(showprogress=FALSE) or 
options(showprogress='console')
    * Added progress bars for predab.resample (for validate, calibrate) 
and bootcov
    * Added bootBCa function
    * Added seed to bootcov object
    * Added boot.type='bca' to Predict, contrast.rms, summary.rms
    * Improved summary.rms to use t critical values if df.residual defined
    * Added simultaneous contrasts to summary.rms
    * Fixed calculation of Brier score, g, gp in lrm.fit by handling 
special case of computing linear predictor when there are no predictors 
in the model
    * Fixed bug in prModFit preventing successful latex'ing of penalized 
lrms
    * Removed \synopsis from two Rd files
    * Added prmodsel argument to predab.resample
    * Correct Rd files to change Design to rms
    * Restricted NAMESPACE to functions expected to be called by users
    * Improved Fortran code to use better dimensions for array declarations
    * Added the basic bootstrap for confidence limits for bootBCa, 
contrast, Predict, summary
    * Fixed bug in latex.pphsm, neatened pphsm code
    * Neatened code in rms.s
    * Improved code for bootstrapping ranks of variables in anova.rms 
help file
    * Fixed bug in Function.rms - undefined Nam[[i]] if strat.  Thanks: 
douglaswilkins at yahoo.com
    * Made quantreg be loaded at end of search list in Rq so it doesn't 
override latex generic in Hmisc
    * Improved plot.summary.rms to use blue of varying transparency 
instead of polygons to show confidence intervals, and to use only three 
confidence levels by default: 0.9 0.95 0.99
    * Changed Surv to Srv; use of Surv in fitting functions will result 
in lack of time labels and assumption of Day as time unit; no longer 
override Surv in survival
    * Changed calculation of Dxy (and c-index) to use survival package 
survConcordance service function when analyzing (censored) survival 
time; very fast
    * Changed default dxy to TRUE in validate.cph, validate.psm
    * Dxy is now negated if correlating Cox model log relative hazard 
with survival time
    * Removed dxy argument from validate.bj as it always computed
    * Added Dxy to standard output of cph, psm
    * Added help file for Srv
    * Removed reference to ps.slide from survplot help page
    * Added the general ordinal regression fitting function orm (and 
orm.fit) which efficiently handles thousands of intercepts because of 
sparse matrix representation of the information matrix; implements 5 
distribution families
    * Added associated functions print.orm, vcov.orm, predict.orm, 
Mean.orm, Quantile.orm, latex.orm, validate.orm
    * Changed predab.resample to allow number of intercepts from 
resample to resample
    * Fixed bug in Mean.cph (thanks: Komal Kapoor <komal.bitsgoa at gmail.com>)
    * Removed incl.non.slopes and non.slopes arguments from all predict 
methods
    * Changed all functions to expect predict(..., type='x') to not 
return intercept columns, and all fitting functions to not store column 
of ones if x=TRUE
    * Changed nomogram argument intercept to kint, used default as 
fit$interceptRef
    * Made bootcov behave in a special way for orm, to use linear 
interpolation to select a single intercept targeted at median Y
    * Revamped all of rms to never store intercepts in design matrices 
in fit objects and to add intercepts on demand inside predictrms
    * Added new function generator ExProb to compute exceedance 
probabilities from orm fits

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From jannetta at henning.org  Thu Jul 11 14:40:21 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Thu, 11 Jul 2013 13:40:21 +0100
Subject: [R] Fwd:  Error in read.table
In-Reply-To: <CAGR4ry6FuvWbG=mDbXi6WhoURPgG4VxORDAW55gD24nZrEL3yg@mail.gmail.com>
References: <CAGR4ry60EPr08PiBo0JYGAmmP0yH12R9+PG+=uscdNbfSuYdDg@mail.gmail.com>
	<CADrtQZz5++hH-+TprXYuObWLvLGuUvi326yw654DK9OSDOfmDw@mail.gmail.com>
	<567D856E-4400-400B-9C46-A2C6C69EE1DF@gmail.com>
	<CAGR4ry6FuvWbG=mDbXi6WhoURPgG4VxORDAW55gD24nZrEL3yg@mail.gmail.com>
Message-ID: <CAGR4ry4iKFfdb7+90pygU92ZT_Pg65m+0m84p3PUoYizBvAewQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/b2fa43da/attachment.pl>

From raphaelle.carraud at oc-metalchem.com  Thu Jul 11 14:19:02 2013
From: raphaelle.carraud at oc-metalchem.com (=?iso-8859-1?Q?Rapha=EBlle_Carraud?=)
Date: Thu, 11 Jul 2013 14:19:02 +0200
Subject: [R] Differential problem
In-Reply-To: <933AD69C-1C62-45A2-BF88-7D6A50664DFD@xs4all.nl>
References: <4565B2277456ED4EB03CD34B21283B472067BE8156@EXH01001.hmc.local>
	<55BF8118-322D-4F61-8088-C79334D7108D@xs4all.nl>
	<4565B2277456ED4EB03CD34B21283B472067BE81CA@EXH01001.hmc.local>
	<E7CBAAC6-131F-4CAC-BD6C-3DFDBBE5825C@xs4all.nl>
	<4565B2277456ED4EB03CD34B21283B472067BE81E6@EXH01001.hmc.local>
	<933AD69C-1C62-45A2-BF88-7D6A50664DFD@xs4all.nl>
Message-ID: <4565B2277456ED4EB03CD34B21283B472067BE81F1@EXH01001.hmc.local>

Ok, now it's good (Pt was in my workplace so it worked for me, I am not used to R using these value to make the program run so I hadn't looked...)

reaction<-function(z, state, dval, parameters) {
  with(as.list(c(state,dval,parameters)),{
    # rate of change

    Tr <- 273+90
    P <- 0.98*10^5
    
    K2 <- 10^(2993/Tr-9.226)*(10^-3)       
    K3 <- 10^(2072/Tr-7.234)*(10^-3)
    K4 <- 10^(-20.83/Tr-0.5012)
    K5 <- 10^(-965.5/Tr-1.481)
    k1 <- (10^(652.1/Tr-0.7356))*(8.314*Tr/P)^2
    kf2 <- 1.4*10^-33*(Tr/300)^(-3.8)*6.022*10^23*10^-6
    kb2 <- kf2/K2*P/(8.314*Tr)
    kf3 <- 3.1*10^-34*(Tr/300)^(-7.7)*10^(-6)*6.022*10^23
    kb3 <- kf3/K3*P/(8.314*Tr)
    kf4 <- 41
    kf5 <- 0.25

    r1 <- k1*A^2*H
    r4 <- kf4*D*G - kf4/K4*E^2
    r5 <- kf5*C*G - kf5/K5*E*I
    
    res1 <- -dA + dB + 2*dC - 2*r1 - 2*r5          #
    res2 <- dA + dD + r1 + r4                     #
    res3 <- K2 - C/B^2                             #
    res4 <- K3 - D/(A*B)                           #
    res5 <- r5 + 2*r4 - dE             #dHNO2/dz
    res6 <- r5 -dI                   #dHNO3/dz
    res7 <- -r5 - r4 - dG             #dH2O/dz
    res8 <- -r1/2 - dH                #dO2/dz

    list(c(res1, res2, res3, res4, res5, res6, res7, res8))
  })   # end with(as.list ...
}

xi <- c(0.3,   #x_NO
        0.1,   #x_NO2
        0,     #x_N2O4
        0,     #x_N2O3
        0.05,  #x_HNO2
        0.05,  #x_HNO3
        0.2,   #x_H2O
        0.3)   #x_O2

Pt <- 0.98*10^5
state <- c(A = xi[1]*Pt,
           B = xi[2]*Pt,
           C = xi[3]*Pt,
           D = xi[4]*Pt,
           E = xi[5]*Pt,
           I = xi[6]*Pt,
           G = xi[7]*Pt,
           H = xi[8]*Pt)

dval <- c(dA = 1,
          dB = 1,
          dC = 0.5,
          dD = 0.2,
          dE = 0,
          dI = 0,
          dG = 0,
          dH = 0)

parameters <- c(Pt = 0.98*10^5)

z <- seq(0, 1, by = 0.01)  # en seconde

library(deSolve)
#out <- ode(y = state, times = z, func = reaction, parameters)

out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 0)
head(out)
plot(out)


-----Message d'origine-----
De?: Berend Hasselman [mailto:bhh at xs4all.nl] 
Envoy??: jeudi 11 juillet 2013 14:13
??: Rapha?lle Carraud
Cc?: r-help at r-project.org
Objet?: Re: [R] Differential problem


On 11-07-2013, at 13:53, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Sorry for the bug, I had eliminated some lines to avoid making the program too big. Here is the version that works :
> 
> reaction<-function(z, state, dval, parameters) {  
> with(as.list(c(state)),{
>    # rate of change
> 
>    Tr <- 273+90
>    P <- 0.98*10^5
> 
>    K2 <- 10^(2993/Tr-9.226)*(10^-3)       
>    K3 <- 10^(2072/Tr-7.234)*(10^-3)
>    K4 <- 10^(-20.83/Tr-0.5012)
>    K5 <- 10^(-965.5/Tr-1.481)
>    k1 <- (10^(652.1/Tr-0.7356))*(8.314*Tr/P)^2
>    kf2 <- 1.4*10^-33*(Tr/300)^(-3.8)*6.022*10^23*10^-6
>    kb2 <- kf2/K2*P/(8.314*Tr)
>    kf3 <- 3.1*10^-34*(Tr/300)^(-7.7)*10^(-6)*6.022*10^23
>    kb3 <- kf3/K3*P/(8.314*Tr)
>    kf4 <- 41
>    kf5 <- 0.25
> 
>    r1 <- k1*A^2*H
>    r4 <- kf4*D*G - kf4/K4*E^2
>    r5 <- kf5*C*G - kf5/K5*E*I
> 
>    res1 <- -dA + dB + 2*dC - 2*r1 - 2*r5          #
>    res2 <- dA + dD + r1 + r4                     #
>    res3 <- K2 - C/B^2                             #
>    res4 <- K3 - D/(A*B)                           #
>    res5 <- r5 + 2*r4 - dE             #dHNO2/dz
>    res6 <- r5 -dI                   #dHNO3/dz
>    res7 <- -r5 - r4 - dG             #dH2O/dz
>    res8 <- -r1/2 - dH                #dO2/dz
> 
>    list(c(res1, res2, res3, res4, res5, res6, res7, res8))
>  })   # end with(as.list ...
> }
> 
> xi <- c(0.3,   #x_NO
>        0.1,   #x_NO2
>        0,     #x_N2O4
>        0,     #x_N2O3
>        0.05,  #x_HNO2
>        0.05,  #x_HNO3
>        0.2,   #x_H2O
>        0.3)   #x_O2
> 
> 
> state <- c(A = xi[1]*Pt,
>           B = xi[2]*Pt,
>           C = xi[3]*Pt,
>           D = xi[4]*Pt,
>           E = xi[5]*Pt,
>           I = xi[6]*Pt,
>           G = xi[7]*Pt,
>           H = xi[8]*Pt)
> 
> dval <- c(dA = 1,
>          dB = 1,
>          dC = 0.5,
>          dD = 0.2,
>          dE = 0,
>          dI = 0,
>          dG = 0,
>          dH = 0)
> 
> parameters <- c(Pt = 0.98*10^5)
> 

Doesn't run.
Since variable Pt is not defined when you calculate vector state. So define Pt <- .. before xi as in the original example.

In the function reaction isn't variable P just Pt from the parameter vector?
If so then either do P <- Pt or just use Pt directly (but see next remark).


> z <- seq(0, 1, by = 0.01)  # en seconde
> 
> library(deSolve)
> #out <- ode(y = state, times = z, func = reaction, parameters)
> 
> out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 
> 0)
> head(out)
> plot(out)
> 
> I obtain the following message:
> 
>> library(deSolve)
>> #out <- ode(y = state, times = z, func = reaction, parameters)
>> 
>> out <- daspk(y = state, dy = dval, times = z, res = reaction, parms = 
>> 0)
> Error in eval(expr, envir, enclos) : object 'dA' not found.
> 

Obviously since dA  isn't defined outside of dval when the functions was defined.
And do parms=parameters if you want to use Pt (as I told you in the previous post).

> I tried adding the dval and parameters as you said:
> with(as.list(c(state,dval,parameters)),{
> 
> I get the following message:
> 
> Warning messages:
> 1: In daspk(y = state, dy = dval, times = z, res = reaction, parms = 0) :
>  matrix of partial derivatives is singular with direct method-some 
> equations redundant
> 2: In daspk(y = state, dy = dval, times = z, res = reaction, parms = 0) :
>  Returning early. Results are accurate, as far as they go
> 

These are warning messages.
You get plots.
So now is the time to start looking at initial values etc.

Since I know next to nothing about DAE's you are on your own here unless someone else comes up with suggestions.

> For the calling of the daspk function, I followed the documentation, where you have the same inversion:
> 
> daefun <- function(t, y, dy, parameters) {
> + res1 <- dy[1] + y[1] - y[2]
> + res2 <- y[2] * y[1] - t
> +
> + list(c(res1, res2))
> + }
>> library(deSolve)
>> yini <- c(1, 0)
>> dyini <- c(1, 0)
>> times <- seq(0, 10, 0.1)
>> ## solver
>> system.time(out <- daspk(y = yini, dy = dyini, times = times, res = 
>> daefun, parms = 0))
> 
> Is it wrong? When I modify the order, I obtain again that object dA is not found, so I guessed the doc was right.
> 

Of course see above.

Berend


From jannetta at henning.org  Thu Jul 11 14:58:49 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Thu, 11 Jul 2013 13:58:49 +0100
Subject: [R] Error in read.table
In-Reply-To: <CAGR4ry4iKFfdb7+90pygU92ZT_Pg65m+0m84p3PUoYizBvAewQ@mail.gmail.com>
References: <CAGR4ry60EPr08PiBo0JYGAmmP0yH12R9+PG+=uscdNbfSuYdDg@mail.gmail.com>
	<CADrtQZz5++hH-+TprXYuObWLvLGuUvi326yw654DK9OSDOfmDw@mail.gmail.com>
	<567D856E-4400-400B-9C46-A2C6C69EE1DF@gmail.com>
	<CAGR4ry6FuvWbG=mDbXi6WhoURPgG4VxORDAW55gD24nZrEL3yg@mail.gmail.com>
	<CAGR4ry4iKFfdb7+90pygU92ZT_Pg65m+0m84p3PUoYizBvAewQ@mail.gmail.com>
Message-ID: <CAGR4ry7GWXLtgNPzexBGJm4S=GymQ5Er23giXn4nLvDFNNhcLg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/d50ac5ef/attachment.pl>

From jannetta at henning.org  Thu Jul 11 15:01:20 2013
From: jannetta at henning.org (Jannetta Steyn)
Date: Thu, 11 Jul 2013 14:01:20 +0100
Subject: [R] Reading a list of filenames from a csv file
Message-ID: <CAGR4ry4Qp5y1WNzBJEBO3TyUgaCMYKSKjBfmJnmKNS=S4Bh8RA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/723ef6f1/attachment.pl>

From ejoffe at hotmail.com  Thu Jul 11 15:13:52 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Thu, 11 Jul 2013 08:13:52 -0500
Subject: [R] problem with BootCV for coxph in pec after feature
	selection with glmnet (lasso)
In-Reply-To: <014c01ce79de$0f52ac60$2df80520$@hotmail.com>
References: <014c01ce79de$0f52ac60$2df80520$@hotmail.com>
Message-ID: <DUB114-DS66105BE1693CBC6C9C4A9CA7B0@phx.gbl>

pec accepts only R-objects for which a predictSurvProb method exists and
glmnet is not such an object.

    Currently, predictSurvProb methods are available for the following
R-objects:
    matrix
    aalen, cox.aalen from library(timereg)
    mfp from library(mfp)
    phnnet, survnnet from library(survnnet)
    rpart (from library(rpart))
    coxph, survfit from library(survival)
    cph, psm from library(rms)
    prodlim from library(prodlim)
    glm from library(stats)

For calculating the brier score for glmnet one needs to use the peperr
package with the c060 library that wraps glmnet as an object suitable for
peperr.

    peperr_glmnet_noerror <- peperr(response=Surv(time, status), x=x, 
                        fit.fun=fit.glmnet, args.fit=list(family="cox"),
 
complexity=complexity.glmnet,args.complexity=list(family="cox"),
                        indices=resample.indices(n=length(time),
method="boot", sample.n=10))

To get the integrated brier score for the entire model it seems one needs to
use the ipec function but I still need to research that.

Many thanks to Thomas Hielscher who authored the c060 package and was
extremely kind to help me with this.

-----Original Message-----
From: E Joffe [mailto:ejoffe at hotmail.com] 
Sent: Friday, July 05, 2013 7:16 PM
To: 'r-help at R-project.org'
Subject: problem with BootCV for coxph in pec after feature selection with
glmnet (lasso)

Hi,

I am attempting to evaluate the prediction error of a coxph model that was
built after feature selection with glmnet.

In the preprocessing stage I used na.omit (dataset) to remove NAs.
I reconstructed all my factor variables into binary variables with dummies
(using model.matrix) I then used glmnet lasso to fit a cox model and select
the best performing features.
Then I fit a coxph model using only these feature.

When I try to evaluate the model using pec and a bootstrap I get an error
that the prediction matrix has wrong dimensions.
Suddenly the cox object has 318 variables instead of 356 variables in the
dataset.
I don't know why this is happening.
The cox object I assign to pec and the dataframe are both of the same size.
However, once pec refits the model its size changes (356 -> 318 variables).
Apparently something is happening during the bootstrap sampling that removes
some variables.
As mentioned, I used na.omit in the preprocessing so there should not be any
NAs.

Here are some details from my workspace:
Reformat_dataSet: 368 obs. Of 356 variables print (glmnet.cox) ----> 354 df,
p=1  n= 368, number of events= 288 (354 df = 354 variables + time and status
=> 356 variables)

Here is the pec function and the error:
pec.f <- as.formula(Hist(time,status) ~ 1) brierGlmnet <-
pec(list(glmnet.cox), data = reformat_Dataset, splitMethod="BootCV", B=50,
formula = pec.f)

>  Error in predictSurvProb.coxph(object = structure(list(coefficients =
structure(c(-4.27787223119601,  : 
    Prediction matrix has wrong dimensions:
   368 rows and 318 columns.
    But requested are predicted probabilities for
   118 subjects (rows) in newdata and 356 time points (columns)
   This may happen when some covariate values are missing in newdata!?
 
Here are the relevant sections of the code:

trainSet <- na.omit (dataset)
  
#creat Y (survival matrix) for glmnet
  surv_obj <- Surv(trainSet$time,trainSet$status) 
  
    
  ## tranform categorical variables into binary variables with dummy for
trainSet
  predict_matrix <- model.matrix(~ ., data=trainSet, 
                                 contrasts.arg = lapply
(trainSet[,sapply(trainSet, is.factor)], contrasts, contrasts=FALSE))
  
 
 ## remove the statu/time variables from the predictor matrix (x) for glmnet
  predict_matrix <- subset (predict_matrix, select=c(-time,-status))
  
  
## create a glmnet cox object using lasso regularization
  glmnet.obj <- glmnet (predict_matrix, surv_obj, family="cox")
  
  
# find lambda for which dev.ratio is max
  max.dev.index <- which.max(glmnet.obj$dev.ratio)
  optimal.lambda <- glmnet.obj$lambda[max.dev.index] 
  
 
 # take beta for optimal lambda 
  optimal.beta  <- glmnet.obj$beta[,max.dev.index] 
  
  
# find non zero beta coef 
  nonzero.coef <- abs(optimal.beta)>0 
  selectedBeta <- optimal.beta[nonzero.coef] 
  
  # take only covariates for which beta is not zero 
  selectedVar   <- predict_matrix[,nonzero.coef] 
  
  # create a dataframe for trainSet with time, status and selected variables
in binary representation for evaluation in pec
  reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))
  
  # create coxph object with pre-defined coefficients 
  glmnet.cox <- coxph(surv_obj ~ selectedVar, init=selectedBeta,iter=0)

## Brier score for the cox-glmnet model
  brierGlmnet <- pec(list(glmnet.cox), data = reformat_Dataset,
splitMethod="BootCV", B=50,
                     formula = pec.f)

Thank you !!!


From ejoffe at hotmail.com  Thu Jul 11 15:16:34 2013
From: ejoffe at hotmail.com (E Joffe)
Date: Thu, 11 Jul 2013 08:16:34 -0500
Subject: [R] coxph won't converge when including categorical
	(factor)	variables
In-Reply-To: <024c01ce7b22$ec2e39c0$c48aad40$@hotmail.com>
References: <DUB114-DS4408663B0D1ECBD9D473DCA7E0@phx.gbl>
	<80F175FF-1DBF-49C6-A295-E20CA112DE2E@me.com>
	<024c01ce7b22$ec2e39c0$c48aad40$@hotmail.com>
Message-ID: <DUB114-DS126C2D9AA12C81DCBBE3EDCA7B0@phx.gbl>

I have found the answer for my second question and am posting here for the benefit of the community:

pec accepts only R-objects for which a predictSurvProb method exists and glmnet is not such an object.

    Currently, predictSurvProb methods are available for the following R-objects:
    matrix
    aalen, cox.aalen from library(timereg)
    mfp from library(mfp)
    phnnet, survnnet from library(survnnet)
    rpart (from library(rpart))
    coxph, survfit from library(survival)
    cph, psm from library(rms)
    prodlim from library(prodlim)
    glm from library(stats)

For calculating the brier score for glmnet one needs to use the peperr package with the c060 library that wraps glmnet as an object suitable for peperr.

    peperr_glmnet_noerror <- peperr(response=Surv(time, status), x=x, 
                        fit.fun=fit.glmnet, args.fit=list(family="cox"),
                        complexity=complexity.glmnet,args.complexity=list(family="cox"),
                        indices=resample.indices(n=length(time), method="boot", sample.n=10))

To get the integrated brier score for the entire model it seems one needs to use the ipec function but I still need to research that.

Many thanks to Thomas Hielscher who authored the c060 package and was extremely kind to help me with this.

-----Original Message-----
From: E Joffe [mailto:ejoffe at hotmail.com] 
Sent: Sunday, July 07, 2013 10:02 AM
To: 'Marc Schwartz'
Cc: 'r-help at r-project.org'
Subject: RE: [R] coxph won't converge when including categorical (factor) variables

Hello all,

I have posted a reply to Mark and Jeff out of my own fault sent it to them personally and not the group.
I will re-post the question and Mark's answer so that the community can benefit from his comments.
It seems that my posts are not in accordance with the guidelines and I will try to remedy that as well.
I apologize for the mess I have made !!!
I am afraid I can't post the actual data (as it is Protected Health Information).


In any case here are the question, code, output and Mark's comment (which can be summarized that there is very little information about the pec package within the community and that the best solution would be to try and contact the author of the package - which I will and then repost the answer):


I am attempting to evaluate the prediction error of a coxph model that was built after feature selection with glmnet.

In the preprocessing stage I used na.omit (dataset) to remove NAs. I reconstructed all my factor variables into binary variables with dummies (using model.matrix) I then used glmnet lasso to fit a cox model and select the best performing features. Then I fit a coxph model using only these feature.

When I try to evaluate the model using pec and a bootstrap I get an error that the prediction matrix has wrong dimensions.

In the original dataset there are 313 variables. In the coxph model (glmnet.cox in my code) there are 313 df. However when I run pec the prediction matrix is noted as having 318 variables and therefore doesn't fit the testset which has 313 variables (+the status and time variables).

It seems that pec does something to the variables while retraining the coxph model on the bootstrap samples. I tried setting singular.ok=FALSE in the coxph model without avail.

Here is a summary of key variables (prior to restructuring for glmnet) Followed by the code I ran and the errors:

> summary (trainSet)
     time              status         Age_at_Dx       CREATININE   
 Min.   :  0.1429   Min.   :0.0000   Min.   :14.81   Min.   :0.400  
 1st Qu.: 22.0714   1st Qu.:1.0000   1st Qu.:52.51   1st Qu.:0.800  
 Median : 52.9286   Median :1.0000   Median :63.79   Median :0.900  
 Mean   : 96.5415   Mean   :0.7826   Mean   :61.01   Mean   :1.042  
 3rd Qu.:154.6071   3rd Qu.:1.0000   3rd Qu.:73.01   3rd Qu.:1.125  
 Max.   :437.7143   Max.   :1.0000   Max.   :87.23   Max.   :6.000  
 Performance_Status    ALBUMIN          Cyto             WBC        
 Min.   :0.0000     Min.   :0.70   Min.   : 1.000   Min.   :  0.60  
 1st Qu.:1.0000     1st Qu.:3.00   1st Qu.: 4.000   1st Qu.:  3.20  
     Median :1.0000     Median :3.60   Median : 4.000   Median :  9.20  
 Mean   :0.9728     Mean   :3.48   Mean   : 6.802   Mean   : 28.35  
 3rd Qu.:1.0000     3rd Qu.:4.00   3rd Qu.:11.000   3rd Qu.: 33.10  
 Max.   :4.0000     Max.   :5.20   Max.   :17.000   Max.   :373.00  
  PRKCD_pT507             HGB            Maxblast          CD19       
 Min.   :-2.429605   Min.   : 5.400   Min.   : 0.00   Min.   : 0.000  
  1st Qu.:-0.627005   1st Qu.: 8.500   1st Qu.:24.00   1st Qu.: 1.000  
 Median :-0.013117   Median : 9.550   Median :40.00   Median : 2.000  
 Mean   : 0.006432   Mean   : 9.689   Mean   :43.74   Mean   : 6.312  
 3rd Qu.: 0.559782   3rd Qu.:10.800   3rd Qu.:65.25   3rd Qu.: 5.000  
 Max.   : 2.963658   Max.   :14.300   Max.   :98.00   Max.   :98.000  
     GAPDH                CD74              TP53               Fli1          
 Min.   :-2.391021   Min.   :-1.7902   Min.   :-1.64244   Min.   :-3.723143  
 1st Qu.:-0.662164   1st Qu.:-0.5502   1st Qu.:-0.53685   1st Qu.:-0.559783  
 Median : 0.003236   Median :-0.1546   Median :-0.10928   Median :-0.002154  
 Mean   : 0.015759   Mean   : 0.0235   Mean   :-0.02285   Mean   :-0.016555  
 3rd Qu.: 0.632472   3rd Qu.: 0.4759   3rd Qu.: 0.29869   3rd Qu.: 0.554521  
 Max.   : 3.512741   Max.   : 3.7226   Max.   : 5.39242   Max.   : 4.415324  
      LDH              SQSTM0            BM_BLAST         CCND3         
 Min.   :    8.4   Min.   :-1.56639   Min.   : 0.00   Min.   :-2.44772  
 1st Qu.:  562.8   1st Qu.:-0.48762   1st Qu.:31.00   1st Qu.:-0.59042  
 Median :  952.5   Median :-0.05746   Median :46.50   Median :-0.08412  
 Mean   : 1617.9   Mean   :-0.02272   Mean   :50.64   Mean   :-0.02506  
 3rd Qu.: 1596.8   3rd Qu.: 0.33718   3rd Qu.:72.00   3rd Qu.: 0.48353  
 Max.   :36708.0   Max.   : 3.59456   Max.   :98.00   Max.   : 3.58761  
      GAB2                BAX               ABS_BLST           PRKAA1_2       
 Min.   :-3.201564   Min.   :-3.230737   Min.   :     0.0   Min.   :-1.90671  
 1st Qu.:-0.640279   1st Qu.:-0.593174   1st Qu.:    99.8   1st Qu.:-0.66896  
 Median : 0.007018   Median :-0.106097   Median :  1836.5   Median :-0.10586  
 Mean   :-0.013284   Mean   :-0.007051   Mean   : 15024.1   Mean   :-0.03531  
  3rd Qu.: 0.635609   3rd Qu.: 0.588098   3rd Qu.: 11178.0   3rd Qu.: 0.44906  
 Max.   : 2.396419   Max.   : 3.439942   Max.   :358080.0   Max.   : 3.60037  
    RPS6KB1              SPP1               MAPT                ARC          
 Min.   :-2.05490   Min.   :-1.39728   Min.   :-1.826101   Min.   :-2.67081  
 1st Qu.:-0.65736   1st Qu.:-0.55249   1st Qu.:-0.573470   1st Qu.:-0.63908  
 Median :-0.12007   Median :-0.15156   Median :-0.046306   Median :-0.07845  
 Mean   :-0.06115   Mean   : 0.02759   Mean   : 0.009604   Mean   :-0.01082  
 3rd Qu.: 0.49055   3rd Qu.: 0.35195   3rd Qu.: 0.495406   3rd Qu.: 0.63638  
  Max.   : 3.54709   Max.   : 4.44919   Max.   : 4.063568   Max.   : 2.52810  
  FOXO1_pT24_FOXO3_pT32      ATG7               SMAD5           RPS6_pS235_236     
  Min.   :-2.2506       Min.   :-2.916018   Min.   :-2.321250   Min.   :-3.229642  
  1st Qu.:-0.5590       1st Qu.:-0.621408   1st Qu.:-0.480924   1st Qu.:-0.633143  
  Median :-0.1281       Median : 0.003795   Median : 0.003186   Median :-0.003345  
  Mean   :-0.0121       Mean   :-0.029199   Mean   : 0.010663   Mean   :-0.015028  
  3rd Qu.: 0.4415       3rd Qu.: 0.590721   3rd Qu.: 0.502824   3rd Qu.: 0.660224  
  Max.   : 3.1239       Max.   : 2.757525   Max.   : 2.238310   Max.   : 2.816105  
      LSD1             HDAC2               SFN           
  Min.   :-4.5434   Min.   :-2.40682   Min.   :-2.082592  
  1st Qu.:-0.5654   1st Qu.:-0.49165   1st Qu.:-0.554862  
  Median : 0.0477   Median : 0.02828   Median :-0.116248  
  Mean   :-0.0165   Mean   : 0.04641   Mean   : 0.006255  
  3rd Qu.: 0.6044   3rd Qu.: 0.47826   3rd Qu.: 0.506527  
  Max.   : 1.8736   Max.   : 4.22724   Max.   : 3.733445


library (survival)
library (pec)
library (glmnet)

  ##-----------------------------------------------------------------------------------         -------------------
   ##                                    FEATURE SELECTION BY GLMNET-LASSO
   ##----------------------------------------------------------------------------------     ---------------------
   ## 
   ## This function takes a predictor matrix and a Surv obj and uses the glmnet lasso      regularization 
   ## method to select the most predictive features and create a coxph object
   ## predict_matrix is the 'dataset' reformated to replace categorical variables to     binary with dummy

#creat Y (survival matrix) for glmnet
  surv_obj <- Surv(trainSet$time,trainSet$status) 


 ## tranform categorical variables into binary variables with dummy for trainSet
  predict_matrix <- model.matrix(~ ., data=trainSet, 
                                 contrasts.arg = lapply (trainSet[,sapply(trainSet,     is.factor)], contrasts, contrasts=FALSE))

  ## remove the status/time variables from the predictor matrix (x) for glmnet
  predict_matrix <- subset (predict_matrix, select=c(-time,-status))

  ## create a glmnet cox object using lasso regularization
  glmnet.obj <- glmnet (predict_matrix, surv_obj, family="cox")

  # find lambda for which dev.ratio is max
  max.dev.index <- which.max(glmnet.obj$dev.ratio) 
      optimal.lambda <- glmnet.obj$lambda[max.dev.index] 

  # take beta for optimal lambda
  optimal.beta  <- glmnet.obj$beta[,max.dev.index] 

  # find non zero beta coef
  nonzero.coef <- abs(optimal.beta)>0
  selectedBeta <- optimal.beta[nonzero.coef] 

  # take only covariates for which beta is not zero 
  selectedVar   <- predict_matrix[,nonzero.coef] 

 # create a dataframe for trainSet with time, status and selected variables in binary      representation for evaluation in pec
 reformat_dataSet <- as.data.frame(cbind(surv_obj,selectedVar))

  # create coxph object with pre-defined coefficients 
   glmnet.cox <- coxph(surv_obj ~ selectedVar,data = reformat_dataSet,model=TRUE,      singular.ok=FALSE,init=selectedBeta,iter=0)


 ##------------------------------------------------------------------------------------   -------------------
  ##                                    MODEL PERFORMANCE
  ##-----------------------------------------------------------------------------------    --------------------
  ##
  set.seed(17743)
  pec.f <- as.formula(Hist(time,status) ~ 1)

   ## Brier score for the cox-glmnet model
   brierGlmnet <- pec(list(glmnet.cox), data= reformat_dataSet , splitMethod="BootCV",  B=50)


Here is the result:

Prediction matrix has wrong dimensions:
368 rows and 318 columns.           --->(but there are only 313 predicting vars     in the dataset)
 But requested are predicted probabilities for
 138 subjects (rows) in newdata and 315 time points (columns) ---? (315=313 predicting     vars+status+time)
This may happen when some covariate values are missing in newdata!?
Warning in FUN(1:2[[2L]], ...) :

Oddly, when I call print on the glmnet.cox object I get that it has 313 variables and not as pec outputs (318) print(glmnet.cox) Likelihood ratio test=0 on 313 df, p=1 n= 368, number of events= 288


Here is Mark's response:

I suspect that you are going to need to contact the author/maintainer of the pec package for detailed assistance. From a search of the R list archives, there are not that many posts pertaining to the package, which is generally an indication of the breadth of usage within the community. The lack of relevant posts would likely correlate to the low number of users who may be in a position to assist you. Thus, the package author/maintainer in this case, will likely be the best and most expedient resource.

I hope that you find the above useful in some manner.

Regards,



Marc

-----Original Message-----
From: Marc Schwartz [mailto:marc_schwartz at me.com]
Sent: Saturday, July 06, 2013 8:46 AM
To: E Joffe
Cc: r-help at r-project.org
Subject: Re: [R] coxph won't converge when including categorical (factor) variables

On Jul 6, 2013, at 7:04 AM, E Joffe <ejoffe at hotmail.com> wrote:

> Hello,
> 
> 
> 
> [rephrasing and reposting  of a previous question (that was not
> answered) with new information]
> 
> 
> 
> I have a dataset of 371 observations.
> 
> When I run coxph with numeric variables it works fine.
> 
> However, when I try to add factor (categorical) variables it returns 
> "Ran out of iterations and the model did not converge"
> 
> 
> 
> Of note, when I restructure all factors to binary variables with dummy 
> and use glmnet-lasso the model converges.
> 
> 
> 
> Here are examples of the code and output (including summary 
> description of the variables):
> 
>> maxSTree.cox <- coxph (Surv(time,status)~Chemo_Simple, data=dataset)
> 
> 
> 
> Warning message:
> 
> In fitter(X, Y, strats, offset, init, control, weights = weights,  :
> 
>  Ran out of iterations and did not converge
> 
> 
> 
>> summary (dataset$Chemo_Simple)
> 
>                        Anthra_HDAC       Anthra_Plus       ArsenicAtra
> ATRA           ATRA_GO 
> 
>                0               163                 2                12
> 0                 2 
> 
>         ATRA_IDA Demeth_HistoneDAC          Flu_HDAC     Flu_HDAC_plus
> HDAC_Clof         HDAC_only 
> 
>                0                34                37                 4
> 24                 1 
> 
>        HDAC_Plus        LowArac       LowDAC_Clof         MYLO_IL11
> Phase1
> 
>                4                 8                30                 5
> 5
> 
>              SCT    StdARAC_Anthra      StdAraC_Plus          Targeted
> VNP40101M
> 
>                0                 0                 0                13
> 23
> 
> 
> 
> 
> 
> HELP !!!!
> 


You have 371 observations, but did not indicate how many events you have in that dataset. A cross tabulation of the 'status' factor with Chemo_Simple is likely to be enlightening to get a sense of the distribution of events for each level of Chemo_Simple.



Chemo_Simple has a number of levels with rather low counts (ignoring the levels with 0's for the moment), which is likely to be a part of the problem. There is likely to be an issue fitting the model for some of these levels, bearing in mind that your "reference level" of Anthra_HDAC has a large proportion of the observations and with the default treatment contrasts, each of the other levels will be compared to it.

You should also run:

  dataset$Chemo_Simple <- factor(dataset$Chemo_Simple)

to get rid of the unused factor levels. A quick check of the coxph() code versus, for example, lm()/glm(), reveals that while the latter will drop unused factor levels when creating the internal model dataframe, the former will not. A check of some test output here with coxph() suggests that the unused factor levels will simply appear as NA's in the coxph() output without affecting the levels that are present, but it will be cleaner to remove them a priori.

It is also likely that you don't have enough events to handle the effective covariate degrees of freedom that this single factor model will have. By my count (the formatting above is corrupted), you have 16 non-zero factor levels, which would be 15 covariate degrees of freedom consumed by this single factor. A general rule of thumb for Cox models (and logistic regression) is to have 20 events per covariate degree of freedom to avoid overfitting, which means that you would really need 300 "events". In this context, events are the smaller count of the two possible levels of "status". Since you only have 371 total observations, there is no way that you could have 300 events, since you would need to have at least 600 observations. Thus, it is likely that you are attempting to overfit the model to the data as well.

The issue of using glmnet on a matrix of separate dummy variables and it working is likely to be an outcome of the LASSO method penalizing/shrinking the factor levels that are irrelevant to have coefficients of 0. Thus, I would envision that the effective number of your factor levels is reduced as a consequence, allowing the model to be fit.

You likely need to consider collapsing some of the low count factor levels into an "Other" category, if it makes contextual sense to do so for your data. 

Regards,

Marc Schwartz


From sarah.goslee at gmail.com  Thu Jul 11 15:49:04 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Thu, 11 Jul 2013 09:49:04 -0400
Subject: [R] Reading a list of filenames from a csv file
In-Reply-To: <CAGR4ry4Qp5y1WNzBJEBO3TyUgaCMYKSKjBfmJnmKNS=S4Bh8RA@mail.gmail.com>
References: <CAGR4ry4Qp5y1WNzBJEBO3TyUgaCMYKSKjBfmJnmKNS=S4Bh8RA@mail.gmail.com>
Message-ID: <CAM_vjunt2W0KEE01_odjAAErcKc9pJheJ44E9sJFmpsULFvFcw@mail.gmail.com>

Hi Janetta,

At a first guess, you need:

 files <- read.csv(file="files.csv",head=FALSE,sep=",", stringsAsFactors=FALSE)

str(files)

would clear up any confusion as to whether the contents of the first
column of files are character or not.

If that doesn't help, then setting i <- 1 and running each line of
code in the loop individually (copy and paste) will give you a clearer
idea of where problems arise.

Sarah

On Thu, Jul 11, 2013 at 9:01 AM, Jannetta Steyn <jannetta at henning.org> wrote:
> What would be the best way to read a list of filenames and headings from a
> csv file?
>
> The CSV file is structured as two columns, with column one being the
> filename and column two being a heading e.g.:
> ANA110915004A_3PERIOD_TmAvg-rdata.csv,Pre-DA
> ANA110915006A_3PERIOD_TmAvg-rdata.csv,DA-10^-6
> ANA110915012A_3PERIOD_TmAvg-rdata.csv,DA-10^-4
> ANA110915016A_3PERIOD_TmAvg-rdata.csv,Washout
>
>
> I want to be able to open the file using read.csv and use the heading as
> the header of a graph.
>
> Reading the filenames from the directory with list.files() works but then I
> don't have the headings that go with the file e.g.:
> filenames<-list.files(pattern="*.csv")
> for (i in seq_along(filenames)) {
>   con<-read.csv(filenames[i], headers=TRUE, sep=',')
> }
>
> I tried the code below (which I posted in a different thread) but the
> solutions that people offered me didn't get it to work. The code results in
>  'Error in read.table(file = file, header = header, sep = sep, quote =
> quote,  :
>   'file' must be a character string or connection
>
> # Read filenames from csv file
> files <- read.csv(file="files.csv",head=FALSE,sep=",")
>
> # for each filename read the file
> for (i in 1:length(files)) {
>   # f becomes the next row inthe file
>   f<-files[i,]
>   # the header to be used for the graph is in column 2 of f
>   head=f[2]
>   par(mfrow=c(4,2))
>   # the filename to be used is in column 1 of f
>   con<-read.csv(file=f[1], header=TRUE, sep=',')
>   tmp<-con$value2
>   data<-normalize_js(tmp,-1,1)
>   time<-con$time
>   # run the waveform analyser
>   waveformanalyser(data,time,head)
> }
>
> Regards
> Jannetta
>
> --
>
> ===================================
> Web site: http://www.jannetta.com
> Email: jannetta at henning.org
> ===================================
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Sarah Goslee
http://www.functionaldiversity.org


From pdalgd at gmail.com  Thu Jul 11 16:56:02 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 11 Jul 2013 16:56:02 +0200
Subject: [R] Fwd:  Error in read.table
In-Reply-To: <CAGR4ry4iKFfdb7+90pygU92ZT_Pg65m+0m84p3PUoYizBvAewQ@mail.gmail.com>
References: <CAGR4ry60EPr08PiBo0JYGAmmP0yH12R9+PG+=uscdNbfSuYdDg@mail.gmail.com>
	<CADrtQZz5++hH-+TprXYuObWLvLGuUvi326yw654DK9OSDOfmDw@mail.gmail.com>
	<567D856E-4400-400B-9C46-A2C6C69EE1DF@gmail.com>
	<CAGR4ry6FuvWbG=mDbXi6WhoURPgG4VxORDAW55gD24nZrEL3yg@mail.gmail.com>
	<CAGR4ry4iKFfdb7+90pygU92ZT_Pg65m+0m84p3PUoYizBvAewQ@mail.gmail.com>
Message-ID: <3CBEBE66-5FFD-43C4-BC08-026DECCD13FB@gmail.com>


On Jul 11, 2013, at 14:40 , Jannetta Steyn wrote:

> Maybe I should rephrase my question. What would be the best way to read a
> list of filenames and headings from a csv file?

Just follow the hints already given, I think. E.g

files <- read.csv(file="files.csv", head=FALSE, sep=",", as.is=TRUE)

# for each filename read the file
for (i in 1:length(files)) {
   fn <- files[i,1] # Alias files[i,][[1]]
   head <- files[i,2]
   con<-read.csv(file=fn, header=TRUE, sep=',')
...

You can get fancy and do things with apply(files, 1, FUN=.....), but it's probably not necessary.


> The CSV file is structured as two columns, with column one being the
> filename and column two being a heading e.g.:
> ANA110915004A_3PERIOD_TmAvg-rdata.csv,Pre-DA
> ANA110915006A_3PERIOD_TmAvg-rdata.csv,DA-10^-6
> ANA110915012A_3PERIOD_TmAvg-rdata.csv,DA-10^-4
> ANA110915016A_3PERIOD_TmAvg-rdata.csv,Washout
> 
> 
> I want to be able to open the file using read.csv and use the heading as
> the header of a graph.
> 
> Reading the filenames from the directory with list.files() works but then I
> don't have the headings that go with the file e.g.:
> filenames<-list.files(pattern="*.csv")
> for (i in seq_along(filenames)) {
>  con<-read.csv(filenames[i], headers=TRUE, sep=',')
> }
> 
> Regards
> Jannetta
> 
> 
> On 11 July 2013 13:27, peter dalgaard <pdalgd at gmail.com> wrote:
> 
>> 
>> On Jul 11, 2013, at 13:50 , Dante.py wrote:
>> 
>>> Maybe you should set parameter "as.is" in read.csv to be false.
>> 
>> TRUE more likely... However, there's another issue: files[i,] is a data
>> frame, therefore so is f[1] (a telltale sign is that it has rows and column
>> labels). So f[[1]] is probably needed.
>> 
>>> 
>>> 
>>> 2013/7/11 Jannetta Steyn <jannetta at henning.org>
>>> 
>>>> Hi Folks
>>>> 
>>>> I can't see what I have done wrong in this piece of code.
>>>> 
>>>> # Read filenames from csv file
>>>> files <- read.csv(file="files.csv",head=FALSE,sep=",")
>>>> 
>>>> # for each filename read the file
>>>> for (i in 1:length(files)) {
>>>> # f becomes the next row inthe file
>>>> f<-files[i,]
>>>> # the header to be used for the graph is in column 2 of f
>>>> head=f[2]
>>>> par(mfrow=c(4,2))
>>>> # the filename to be used is in column 1 of f
>>>> con<-read.csv(file=f[1], header=TRUE, sep=',')
>>>> tmp<-con$value2
>>>> data<-normalize_js(tmp,-1,1)
>>>> time<-con$time
>>>> # run the waveform analyser
>>>> waveformanalyser(data,time,head)
>>>> }
>>>> 
>>>> I get an error:
>>>> Error in read.table(file = file, header = header, sep = sep, quote =
>> quote,
>>>> :
>>>> 'file' must be a character string or connection
>>>> 
>>>> When the error occurs f equals:
>>>>> f
>>>>                                    V1     V2
>>>> 1 ANA110915004A_3PERIOD_TmAvg-rdata.csv Pre-DA
>>>> 
>>>> and f[1] equals:
>>>> 
>>>>> f[1]
>>>>                                    V1
>>>> 1 ANA110915004A_3PERIOD_TmAvg-rdata.csv
>>>> 
>>>> 
>>>> Why won't it use the value of f[1] as a string for the file parameter in
>>>> the read.csv line?
>>>> 
>>>> All help would be apprecitated.
>>>> Regards
>>>> Jannetta
>>>> 
>>>> 
>>>> 
>>>> --
>>>> 
>>>> ===================================
>>>> Web site: http://www.jannetta.com
>>>> Email: jannetta at henning.org
>>>> ===================================
>>>> 
>>>>       [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> 
>>> 
>>> --
>>> ???? Dante.py
>>> ????????09????????????????????
>>> ??????????http://dantepy.yslsg.org/
>>> 
>>>      [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
>> 
> 
> 
> -- 
> 
> ===================================
> Web site: http://www.jannetta.com
> Email: jannetta at henning.org
> ===================================
> 
> 
> 
> -- 
> 
> ===================================
> Web site: http://www.jannetta.com
> Email: jannetta at henning.org
> ===================================
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From smartpink111 at yahoo.com  Thu Jul 11 16:56:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 07:56:17 -0700 (PDT)
Subject: [R] Reading a list of filenames from a csv file
In-Reply-To: <CAGR4ry4Qp5y1WNzBJEBO3TyUgaCMYKSKjBfmJnmKNS=S4Bh8RA@mail.gmail.com>
References: <CAGR4ry4Qp5y1WNzBJEBO3TyUgaCMYKSKjBfmJnmKNS=S4Bh8RA@mail.gmail.com>
Message-ID: <1373554577.48273.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try this:
files1<-read.csv("files.csv",header=TRUE,stringsAsFactors=FALSE)
?str(files1)
#'data.frame':??? 2 obs. of? 2 variables:
# $ Col1: chr? "ANA110915004A_3PERIOD_TmAvg-rdata.csv" "ANA110915006A_3PERIOD_TmAvg-rdata.csv"
# $ Col2: chr? "Pre-DA" "DA-10^-6"
files1
#?????????????????????????????????? Col1???? Col2
#1 ANA110915004A_3PERIOD_TmAvg-rdata.csv?? Pre-DA
#2 ANA110915006A_3PERIOD_TmAvg-rdata.csv DA-10^-6

#Using some fake data

lapply(seq_len(nrow(files1)),function(i) {x1<-read.csv(file=files1[i,1],header=TRUE,sep="",check.names=FALSE);x1[files1[i,2]]})
[[1]]
#? Pre-DA
#1????? 2
#2????? 3
#3????? 6
#4????? 4

#[[2]]
?# DA-10^-6
#1??????? 9
#2?????? 14
#3?????? 13
#4?????? 21


Hope this helps.
A.K.



----- Original Message -----
From: Jannetta Steyn <jannetta at henning.org>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Thursday, July 11, 2013 9:01 AM
Subject: [R] Reading a list of filenames from a csv file

What would be the best way to read a list of filenames and headings from a
csv file?

The CSV file is structured as two columns, with column one being the
filename and column two being a heading e.g.:
ANA110915004A_3PERIOD_TmAvg-rdata.csv,Pre-DA
ANA110915006A_3PERIOD_TmAvg-rdata.csv,DA-10^-6
ANA110915012A_3PERIOD_TmAvg-rdata.csv,DA-10^-4
ANA110915016A_3PERIOD_TmAvg-rdata.csv,Washout


I want to be able to open the file using read.csv and use the heading as
the header of a graph.

Reading the filenames from the directory with list.files() works but then I
don't have the headings that go with the file e.g.:
filenames<-list.files(pattern="*.csv")
for (i in seq_along(filenames)) {
? con<-read.csv(filenames[i], headers=TRUE, sep=',')
}

I tried the code below (which I posted in a different thread) but the
solutions that people offered me didn't get it to work. The code results in
'Error in read.table(file = file, header = header, sep = sep, quote =
quote,? :
? 'file' must be a character string or connection

# Read filenames from csv file
files <- read.csv(file="files.csv",head=FALSE,sep=",")

# for each filename read the file
for (i in 1:length(files)) {
? # f becomes the next row inthe file
? f<-files[i,]
? # the header to be used for the graph is in column 2 of f
? head=f[2]
? par(mfrow=c(4,2))
? # the filename to be used is in column 1 of f
? con<-read.csv(file=f[1], header=TRUE, sep=',')
? tmp<-con$value2
? data<-normalize_js(tmp,-1,1)
? time<-con$time
? # run the waveform analyser
? waveformanalyser(data,time,head)
}

Regards
Jannetta

-- 

===================================
Web site: http://www.jannetta.com
Email: jannetta at henning.org
===================================

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Thu Jul 11 16:56:55 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 11 Jul 2013 06:56:55 -0800
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <CE03F873.ACF3%hdoran@air.org>
References: <b08b6af0cf8ca44f81b9983eebdcd6862453aa2e@dc1vex10mb001.air.org>
Message-ID: <C1AF72363AF.0000023Djrkrideau@inbox.com>

The message got through but not the attachment. The R help list tends to strip off attachements for security reasons.  Files of types  txt, png, & pdf should get through.

In most cases the accepted method of sending data is to use the dput() function to output a file in the console and then copy and paste the results into your email.

So for file "dat1" one would just use dput(dat1) and paste the results into an email. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: hdoran at air.org
> Sent: Thu, 11 Jul 2013 09:53:40 +0000
> To: r-help at r-project.org
> Subject: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> I sent this message yesterday with an attachment allowing for
> reproduction
> of the issue. But I think the attachment is preventing the message from
> coming through. If anyone is interested I will forward the attachment
> directly allowing for you to reproduce the issue I observe.
> 
> On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:
> 
> >I have zero'd in on what appears to be the issue. This seems to be a bug
> >in Matrix, but I am not sure yet. I am attaching files that would allow
> >others to replicate this with my toy data.
>> 
> >Notice the elements of D1 in the attached data are all integers. It is a
> >sparse, diagonal matrix.
>> 
>>> library(Matrix)
>>> class(D1)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >Now, I find the inverse of the matrix A as follows:
>>> A <- Ir + ZtZ %*% D1
>>> A.Inv <- solve(A, Ir)
>> 
> >Notice now the inverse of A remains a dgCMatrix and it is relatively
> >small in size, only 33424 bytes.
>>> class(A.Inv)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
>>> object.size(A.Inv)
> >33424 bytes
>> 
> >Now, if I change an element of the matrix D1 to be non-integer, D1 still
> >has the same class as it did before
>> 
>>> D1[1] <- 1.2
>> 
>>> class(D1)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >Now, if I use this new version of D1 in the same calculations as above,
> >notice that A.Inv is no longer a dgCMatrix but instead becomes a
> >dgeMatrix. It then increases from an object of size 33424 bytes to an
> >object of size 2001112 bytes!
>> 
>>> A <- Ir + ZtZ %*% D1
>>> A.Inv <- solve(A, Ir)
>>> class(A.Inv)
> >[1] "dgeMatrix"
> >attr(,"package")
> >[1] "Matrix"
>>> object.size(A.Inv)
> >2001112 bytes
>> 
> >What I desire is that the object A.Inv remain sparse at all times and
> not
> >become dense. But, perhaps there is a reason this change occurs that I
> >don't fully understand.
>> 
> >I can of course coerce it back to a sparse matrix and it reduces back in
> >size.
>>>  object.size(as(A.Inv, 'sparseMatrix'))
> >33424 bytes
>> 
> >I of course recognize it requires more memory to store floating points
> >than integers, but is this large increase on the order of magnitude that
> >seems about right?
>> 
> >Is there a reason the floating point in D1 causes for A.Inv to no longer
> >remain sparse?
>> 
> >Thank you for your help,
> >Harold
>> 
>> 
>> 
>> 
>> 
> >-----Original Message-----
> >From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> >On Behalf Of Doran, Harold
> >Sent: Wednesday, July 10, 2013 11:42 AM
> >To: r-help at r-project.org
> >Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
> >Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
> >I have a large function computing an iterative algorithm for fitting
> >mixed linear models. Almost all code relies on functions from the Matrix
> >package. I've come across an issue that I do not believe previously
> >occurred in earlier versions of R or Matrix.
>> 
> >I have a large, sparse matrix, A as
>> 
>>> class(A);dim(A)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
> >[1] 12312 12312
>> 
> >I am in a position where I must find its inverse.  I realize this is
> less
> >than ideal, and I have two ways of doing this
>> 
> >A.Inv <- solve(A, Ir) or just solve(A)
>> 
> >Where Ir is an identity matrix with the same dimensions as A and it is
> >also sparse
>> 
>>> class(Ir)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >The issue, however, is that the inverse of A is converted into a dense
> >matrix and this becomes a huge memory hog, causing the rest of the
> >algorithm to fail. In prior versions this remained as a sparse matrix.
>> 
>>> A.Inv[1:5, 1:5]
> >5 x 5 Matrix of class "dgeMatrix"
>>          [,1]      [,2]      [,3]      [,4]      [,5]
> >[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,] 0.0000000
> >0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
> >0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
> >0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000
> 0.2139975
>> 
> >I could coerce this matrix to become sparse such as
>> 
>>> AA <- as(A.Inv, 'sparseMatrix')
>>> class(AA)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
>>> AA[1:5, 1:5]
> >5 x 5 sparse Matrix of class "dgCMatrix"
>> 
> >[1,] 0.6878713 .         .         .         .
> >[2,] .         0.6718767 .         .         .
> >[3,] .         .         0.5076945 .         .
> >[4,] .         .         .         0.2324122 .
> >[5,] .         .         .         .         0.2139975
>> 
> >But I don't think this is best.
>> 
> >So, my question is why is a matrix that is sparse turning into a dense
> >matrix? Can I avoid that and keep it sparse without having to coerce it
> >to be sparse after it is created?
>> 
> >Thank you very much
> >Harold
>> 
>> 
>>> sessionInfo()
> >R version 3.0.1 (2013-05-16)
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
>> 
> >locale:
> >[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> >States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C [5]
> >LC_TIME=English_United States.1252
>> 
> >attached base packages:
> >[1] stats     graphics  grDevices utils     datasets  methods   base
>> 
> >other attached packages:
> >[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
>> 
> >loaded via a namespace (and not attached):
> >[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
>> 
> >	[[alternative HTML version deleted]]
>> 
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Thu Jul 11 17:15:40 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 11 Jul 2013 07:15:40 -0800
Subject: [R] PCA and gglot2
In-Reply-To: <1373485795196-4671253.post@n4.nabble.com>
References: <b539fae48d0.00001165jrkrideau@inbox.com>
	<b759a6e991f.00000177jrkrideau@inbox.com>
	<1373461740917-4671225.post@n4.nabble.com>
	<1373479331548-4671237.post@n4.nabble.com>
	<a4e5a0b016b8cb41a485fc629b633ced4acb8a65e8@gold.corp.lgc-group.com>
Message-ID: <C1D9595711C.00000270jrkrideau@inbox.com>

Not sure why the problem. I think I'd need see your actual data and give it a try.  If you want to supply your data or a sample of it see ?dput for a convenient way to do so.

I see thought that you've found a dedicated ggplot biplot  so if may not be worth your while.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: ashz at walla.co.il
> Sent: Wed, 10 Jul 2013 12:49:55 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] PCA and gglot2
> 
> Dear John,
> 
> Thanks for the help.
> 
> I did some minor modifications to your script as I had some problems:
> ...
> pca = PCA(data[,1:4], scale.unit=T, graph=F)
> dat1  <-  data.frame(pca$scores)  # creates the data.frame
> dat1$items  <-  rownames(data$group) # adds item names
> ggplot(dat1, aes(pca$ind$coord[,1], pca$ind$coord[,2], colour =
> dat1$item))
> + geom_point() + theme(legend.position="none")
> 
> I still do not get separation by color by group (column 5 of csv file) as
> the  dat1 is empty (data frame with 0 columns and 0 rows).
> 
> Any reason why?
> 
> Thanks again.
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/PCA-and-gglot2-tp4671225p4671253.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From HDoran at air.org  Thu Jul 11 17:35:44 2013
From: HDoran at air.org (Doran, Harold)
Date: Thu, 11 Jul 2013 15:35:44 +0000
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <C1AF72363AF.0000023Djrkrideau@inbox.com>
References: <b08b6af0cf8ca44f81b9983eebdcd6862453aa2e@dc1vex10mb001.air.org>
	<C1AF72363AF.0000023Djrkrideau@inbox.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6862453B3F6@DC1VEX10MB001.air.org>

Thank you, John. I originally used dput() but the output is huge. However, here is a reproducible example of what I think very unexpected behavior of some matrix functions.

> ### Create a symmetric matrix of class dsCMatrix
> A <- as(diag(5, 10), 'dsCMatrix')
> A[1, 5] <- A[5,1] <- 2
> 
> ### Create a diagonal matrix of class ddi
> D <- Diagonal(10, 1)
> 
> ### This works as it should
> aa <- Cholesky(A %*% D)
> 
> ### Now, let's only change one element of D to be non-integer
> D[1] <- 1.5
> 
> ### AD is still symmetric, but here the Cholesky function complains that it is not
> aa <- Cholesky(A %*% D)
Error in Cholesky(as(A, "symmetricMatrix"), perm = perm, LDL = LDL, super = super,  : 
  error in evaluating the argument 'A' in selecting a method for function 'Cholesky': Error in asMethod(object) : 
  not a symmetric matrix; consider forceSymmetric() or symmpart()

### For fun try this

> L <- update(aa, as(A %*% D, 'symmetricMatrix'))
Error in asMethod(object) : 
  not a symmetric matrix; consider forceSymmetric() or symmpart()

### This does indeed work, but should I need to implement this step?

Cholesky(forceSymmetric(A %*% D))

So, there is something about changing the elements of a ddi matrix that causes subsequent problems. Is there a good reason this occurs and something I should be doing differently, or is this a bug?

Thanks

-----Original Message-----
From: John Kane [mailto:jrkrideau at inbox.com] 
Sent: Thursday, July 11, 2013 10:57 AM
To: Doran, Harold; r-help at r-project.org
Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)

The message got through but not the attachment. The R help list tends to strip off attachements for security reasons.  Files of types  txt, png, & pdf should get through.

In most cases the accepted method of sending data is to use the dput() function to output a file in the console and then copy and paste the results into your email.

So for file "dat1" one would just use dput(dat1) and paste the results into an email. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: hdoran at air.org
> Sent: Thu, 11 Jul 2013 09:53:40 +0000
> To: r-help at r-project.org
> Subject: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> I sent this message yesterday with an attachment allowing for 
> reproduction of the issue. But I think the attachment is preventing 
> the message from coming through. If anyone is interested I will 
> forward the attachment directly allowing for you to reproduce the 
> issue I observe.
> 
> On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:
> 
> >I have zero'd in on what appears to be the issue. This seems to be a 
> >bug in Matrix, but I am not sure yet. I am attaching files that would 
> >allow others to replicate this with my toy data.
>> 
> >Notice the elements of D1 in the attached data are all integers. It 
> >is a sparse, diagonal matrix.
>> 
>>> library(Matrix)
>>> class(D1)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >Now, I find the inverse of the matrix A as follows:
>>> A <- Ir + ZtZ %*% D1
>>> A.Inv <- solve(A, Ir)
>> 
> >Notice now the inverse of A remains a dgCMatrix and it is relatively 
> >small in size, only 33424 bytes.
>>> class(A.Inv)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
>>> object.size(A.Inv)
> >33424 bytes
>> 
> >Now, if I change an element of the matrix D1 to be non-integer, D1 
> >still has the same class as it did before
>> 
>>> D1[1] <- 1.2
>> 
>>> class(D1)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >Now, if I use this new version of D1 in the same calculations as 
> >above, notice that A.Inv is no longer a dgCMatrix but instead becomes 
> >a dgeMatrix. It then increases from an object of size 33424 bytes to 
> >an object of size 2001112 bytes!
>> 
>>> A <- Ir + ZtZ %*% D1
>>> A.Inv <- solve(A, Ir)
>>> class(A.Inv)
> >[1] "dgeMatrix"
> >attr(,"package")
> >[1] "Matrix"
>>> object.size(A.Inv)
> >2001112 bytes
>> 
> >What I desire is that the object A.Inv remain sparse at all times and
> not
> >become dense. But, perhaps there is a reason this change occurs that 
> >I don't fully understand.
>> 
> >I can of course coerce it back to a sparse matrix and it reduces back 
> >in size.
>>>  object.size(as(A.Inv, 'sparseMatrix'))
> >33424 bytes
>> 
> >I of course recognize it requires more memory to store floating 
> >points than integers, but is this large increase on the order of 
> >magnitude that seems about right?
>> 
> >Is there a reason the floating point in D1 causes for A.Inv to no 
> >longer remain sparse?
>> 
> >Thank you for your help,
> >Harold
>> 
>> 
>> 
>> 
>> 
> >-----Original Message-----
> >From: r-help-bounces at r-project.org 
> >[mailto:r-help-bounces at r-project.org]
> >On Behalf Of Doran, Harold
> >Sent: Wednesday, July 10, 2013 11:42 AM
> >To: r-help at r-project.org
> >Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
> >Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
> >I have a large function computing an iterative algorithm for fitting 
> >mixed linear models. Almost all code relies on functions from the 
> >Matrix package. I've come across an issue that I do not believe 
> >previously occurred in earlier versions of R or Matrix.
>> 
> >I have a large, sparse matrix, A as
>> 
>>> class(A);dim(A)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
> >[1] 12312 12312
>> 
> >I am in a position where I must find its inverse.  I realize this is
> less
> >than ideal, and I have two ways of doing this
>> 
> >A.Inv <- solve(A, Ir) or just solve(A)
>> 
> >Where Ir is an identity matrix with the same dimensions as A and it 
> >is also sparse
>> 
>>> class(Ir)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >The issue, however, is that the inverse of A is converted into a 
> >dense matrix and this becomes a huge memory hog, causing the rest of 
> >the algorithm to fail. In prior versions this remained as a sparse matrix.
>> 
>>> A.Inv[1:5, 1:5]
> >5 x 5 Matrix of class "dgeMatrix"
>>          [,1]      [,2]      [,3]      [,4]      [,5]
> >[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,] 0.0000000
> >0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
> >0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
> >0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000
> 0.2139975
>> 
> >I could coerce this matrix to become sparse such as
>> 
>>> AA <- as(A.Inv, 'sparseMatrix')
>>> class(AA)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
>>> AA[1:5, 1:5]
> >5 x 5 sparse Matrix of class "dgCMatrix"
>> 
> >[1,] 0.6878713 .         .         .         .
> >[2,] .         0.6718767 .         .         .
> >[3,] .         .         0.5076945 .         .
> >[4,] .         .         .         0.2324122 .
> >[5,] .         .         .         .         0.2139975
>> 
> >But I don't think this is best.
>> 
> >So, my question is why is a matrix that is sparse turning into a 
> >dense matrix? Can I avoid that and keep it sparse without having to 
> >coerce it to be sparse after it is created?
>> 
> >Thank you very much
> >Harold
>> 
>> 
>>> sessionInfo()
> >R version 3.0.1 (2013-05-16)
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
>> 
> >locale:
> >[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> >States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
> >[5] LC_TIME=English_United States.1252
>> 
> >attached base packages:
> >[1] stats     graphics  grDevices utils     datasets  methods   base
>> 
> >other attached packages:
> >[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
>> 
> >loaded via a namespace (and not attached):
> >[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
>> 
> >	[[alternative HTML version deleted]]
>> 
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From patili_buergi at hotmail.com  Thu Jul 11 17:48:20 2013
From: patili_buergi at hotmail.com (=?iso-8859-1?B?TGluZGEgQvxyZ2k=?=)
Date: Thu, 11 Jul 2013 08:48:20 -0700
Subject: [R] FW: Nested and/or crossed and 2 level random factor
In-Reply-To: <BLU175-W43B159A15FE5EA015E1B3E977B0@phx.gbl>
References: <BLU175-W43B159A15FE5EA015E1B3E977B0@phx.gbl>
Message-ID: <BLU175-W2EED9F6AF69AEE543158E977B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/8f032633/attachment.pl>

From wdunlap at tibco.com  Thu Jul 11 18:40:52 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 11 Jul 2013 16:40:52 +0000
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
	<EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
Message-ID: <E66794E69CFDE04D9A70842786030B931C31B462@PA-MBX01.na.tibco.com>

> Since you are clearly out of your league with respect to compiling from source

We are all beginners at something.  Telling Windows users that building packages
from source is beyond them is walling them off from a very productive area.

Here is how I set things up to build R packages from either a source directory
or a tar.gz file on Windows.

(a) Download Rtools for your version of R from Duncan Murdoch's site (or whereever
it is) and install it.  I install it into C:\Rtools\Rtools-i.j.k (where i.j.k is currently 3.0.x).
I select 'no' if the installer asks whether I want to update my global PATH variable
because I need to be able to compile packages for various version and dialects of S (R, S+, TERR).

(b) Make a text file in C:\Rtools\Rtools-3.0.x called SETPATH.bat containing the following
::: start of file 
: You should set the following 2 variables to say where you installed Rtools and R itself
set RTOOLS_HOME=C:\Rtools\Rtools-3.0.x
set R_HOME=C:\Program Files\R\R-3.0.1

: You may have to change gcc-4.6.3 to something else as the version supplied
: in Rtools-x.y.z changes, but the following works now.
set RTOOLS_PATH=%RTOOLS_HOME%\bin;%RTOOLS_HOME%\MinGW\bin;%RTOOLS_HOME%\gcc-4.6.3\bin
set R_PATH=%R_HOME%\bin

set PATH=%RTOOLS_PATH%;%R_PATH%;%PATH%
::: end of file

You only have to do steps (a) and (b) once for a given version of R.

(c) When you want to compile a package, make a new DOS commands window (run cmd.exe)  and type
     C:\Rtools\Rtools-3.0.x\SETPATH.bat
at the DOS prompt to run the bat file that you created in (b).  cd to the directory containing the package source and type (still at the DOS prompt)
    R CMD INSTALL myPackage.tar.gz
or
    R CMD INSTALL myPackage
depending on if you have a tar.gz file or a directory containing the package source.

Test the package by typing
    R
and when you get the R prompt
    library(myPackage)

If you want to use things like MiKTeX or InnovSetup add their bin directories to PATH
in that SETPATH.bat file.

There are other paths to build a package from source, but see if this one works.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of David Winsemius
> Sent: Wednesday, July 10, 2013 5:22 PM
> To: Lucy Leigh
> Cc: r-help at r-project.org
> Subject: Re: [R] Help with installing a .tar.gz package on windows
> 
> 
> On Jul 10, 2013, at 4:37 PM, Lucy Leigh wrote:
> 
> > Hi,
> > I have had a look at the manual but it makes no sense to me. I have
> > downloaded RTools, and the InnoSetup,
> > but I don't understand how to use these to install my package? Am I
> > meant to be writing commands
> > in R itself, or in these other things I've downloaded?
> 
> Since you are clearly out of your league with respect to compiling from source, now is
> the time to ask (again), why are you not installing the binary package?
> 
> At the R command line just type:
> 
> install.packages("PReMiuM")  # should default to type="win.binary" and use a CRAN
> mirror
> 
> --
> David
> 
> 
> > Lucy
> >
> >>>> Erin Hodgess <erinm.hodgess at gmail.com> 9/07/2013 5:30 pm >>>
> > Hi Lucy:
> >
> > Did you look at the R Installation and Administration manuals?  There's
> > a
> > good section about installing on Windows via Rtools.
> >
> >
> >
> > On Mon, Jul 8, 2013 at 10:18 PM, Lucy Leigh
> > <Lucy.Leigh at newcastle.edu.au>wrote:
> >
> >> Great thank you - are there any resources that step through how to
> > use
> >> RTools to compile the
> >> source package and install it in R on (64-bit windows) ?
> >>
> >>>>> Berend Hasselman <bhh at xs4all.nl> 8/07/2013 6:38 pm >>>
> >>
> >> On 08-07-2013, at 02:15, "Lucy Leigh" <Lucy.Leigh at newcastle.edu.au>
> >> wrote:
> >>
> >>> Hi,
> >>> I have a source package that isn't available as a windows zip
> > file.
> >> Can
> >>> anyone explain to me how I can install this on my windows R
> >> platform?
> >>> When I use the following code:
> >>> install.packages("PReMiuM_3.0.21.tar.gz", type = "source")
> >>>
> >>>
> >>
> >> Where did you get that version from?
> >> CRAN has version 3.0.20 and that is available as a binary Windows
> >> package (.zip).
> >>
> >> As for the error message: you have to have Rtools installed to
> > compile
> >> source packages.
> >>
> >> Berend
> >>
> >>> I get this error message:
> >>>
> >>>
> >>>
> >>> * installing *source* package 'PReMiuM' ...
> >>> ** libs
> >>>
> >>> *** arch - i386
> >>> ERROR: compilation failed for package 'PReMiuM'
> >>> * removing 'C:/Program Files/R/R-3.0.1/library/PReMiuM'
> >>> Warning messages:
> >>> 1: running command '"C:/PROGRA~1/R/R-30~1.1/bin/x64/R" CMD INSTALL
> >> -l
> >>> "C:\Program Files\R\R-3.0.1\library" "PReMiuM_3.0.21.tar.gz"' had
> >> status
> >>> 1
> >>> 2: In install.packages("PReMiuM_3.0.21.tar.gz", type = "source") :
> >>> installation of package 'PReMiuM_3.0.21.tar.gz' had non-zero
> >> exit
> >>> status
> >>>>
> >>>
> >>> Thanks for any help anyone can give me,
> >>> Lucy
> >>>
> >>> ______
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gunter.berton at gene.com  Thu Jul 11 18:47:39 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Thu, 11 Jul 2013 09:47:39 -0700
Subject: [R] FW: Nested and/or crossed and 2 level random factor
In-Reply-To: <BLU175-W2EED9F6AF69AEE543158E977B0@phx.gbl>
References: <BLU175-W43B159A15FE5EA015E1B3E977B0@phx.gbl>
	<BLU175-W2EED9F6AF69AEE543158E977B0@phx.gbl>
Message-ID: <CACk-te1S79g7DuL2WLPfKQv9d+=YBD2_-xzMCyKcRG-SQV-W9Q@mail.gmail.com>

This is not the best place for this post.

Post instead to r-sig-mixed-models or r-sig-ecology .

Cheers,
Bert

On Thu, Jul 11, 2013 at 8:48 AM, Linda B?rgi <patili_buergi at thotmail.com> wrote:
>
>
>
>
> Dear All,
>
> I have two quick questions about my study design. For 4 years, once every season, we destructively sampled larvae on bushes (the same bushes every time) and measured parasitism on these larvae. We had 10 bushes per location and two locations.
> We are interested in whether parasitism changed over the years and varied with season. With repeated measures on bushes, and bushes nested in location, my model looks like this:
>
> model<-glmmPQL(parasitism ~ year:season + year + season, random=~1|location/bush, family=binomial)
>
> Question 1: A reviewer of our paper suggested that seasons are nested
> within years and that we should include this in the model. However, I
> think seasons are crossed with years, not nested. If that's the case,
> can I leave the model as is (as far as season and years are concerned)?
>
> Question 2: I know it is ridiculous to have location as a random factor since it only has two levels. I've read a lot in the archives and people usually suggest to leave that factor out altogether. But leaving it out is not an option because levels of parasitism
> vary significantly with location (but that is of no interest to us,
> hence not really a fixed factor). Could I just include it as a covariate?  glmmPQL(parasitism ~ year:season + year + season + location, random=~1|bush, family=binomial)?
>
> Thank you already for any answers and suggestions!
>
> PS. I used glmmPQL instead of lmer because without the over-/underdispersion function in lmer everything was highly significant, whereas with glmmPQL it is not.
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From cmarker1 at uwyo.edu  Thu Jul 11 17:49:15 2013
From: cmarker1 at uwyo.edu (Cohner Gene Marker)
Date: Thu, 11 Jul 2013 15:49:15 +0000
Subject: [R] Cannot access PDF manuals from R console
Message-ID: <71fe0b44af5a4ecab1c8895a1fb36fe7@BN1PR05MB220.namprd05.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/9d564849/attachment.pl>

From katveie at hotmail.com  Thu Jul 11 16:46:52 2013
From: katveie at hotmail.com (Kathrine Veie)
Date: Thu, 11 Jul 2013 16:46:52 +0200
Subject: [R] mgcv: GAM with clustered standard errors
Message-ID: <BLU0-SMTP372CBE9495283623DFD582AE7B0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/e724120d/attachment.pl>

From HDoran at air.org  Thu Jul 11 19:10:54 2013
From: HDoran at air.org (Doran, Harold)
Date: Thu, 11 Jul 2013 17:10:54 +0000
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6862453B3F6@DC1VEX10MB001.air.org>
References: <b08b6af0cf8ca44f81b9983eebdcd6862453aa2e@dc1vex10mb001.air.org>
	<C1AF72363AF.0000023Djrkrideau@inbox.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD6862453B3F6@DC1VEX10MB001.air.org>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6862453B4C6@DC1VEX10MB001.air.org>

This is a terrible example as I didn't realize my code actually does create a non-symmetric matrix and in this case the function behaves as expected. Nonetheless, my original issue stands and that issue still does not make sense. 

Apologies for bad example code.

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
Sent: Thursday, July 11, 2013 11:36 AM
To: 'John Kane'; r-help at r-project.org
Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)

Thank you, John. I originally used dput() but the output is huge. However, here is a reproducible example of what I think very unexpected behavior of some matrix functions.

> ### Create a symmetric matrix of class dsCMatrix A <- as(diag(5, 10), 
> 'dsCMatrix') A[1, 5] <- A[5,1] <- 2
> 
> ### Create a diagonal matrix of class ddi D <- Diagonal(10, 1)
> 
> ### This works as it should
> aa <- Cholesky(A %*% D)
> 
> ### Now, let's only change one element of D to be non-integer D[1] <- 
> 1.5
> 
> ### AD is still symmetric, but here the Cholesky function complains 
> that it is not aa <- Cholesky(A %*% D)
Error in Cholesky(as(A, "symmetricMatrix"), perm = perm, LDL = LDL, super = super,  : 
  error in evaluating the argument 'A' in selecting a method for function 'Cholesky': Error in asMethod(object) : 
  not a symmetric matrix; consider forceSymmetric() or symmpart()

### For fun try this

> L <- update(aa, as(A %*% D, 'symmetricMatrix'))
Error in asMethod(object) : 
  not a symmetric matrix; consider forceSymmetric() or symmpart()

### This does indeed work, but should I need to implement this step?

Cholesky(forceSymmetric(A %*% D))

So, there is something about changing the elements of a ddi matrix that causes subsequent problems. Is there a good reason this occurs and something I should be doing differently, or is this a bug?

Thanks

-----Original Message-----
From: John Kane [mailto:jrkrideau at inbox.com]
Sent: Thursday, July 11, 2013 10:57 AM
To: Doran, Harold; r-help at r-project.org
Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)

The message got through but not the attachment. The R help list tends to strip off attachements for security reasons.  Files of types  txt, png, & pdf should get through.

In most cases the accepted method of sending data is to use the dput() function to output a file in the console and then copy and paste the results into your email.

So for file "dat1" one would just use dput(dat1) and paste the results into an email. 

John Kane
Kingston ON Canada


> -----Original Message-----
> From: hdoran at air.org
> Sent: Thu, 11 Jul 2013 09:53:40 +0000
> To: r-help at r-project.org
> Subject: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> I sent this message yesterday with an attachment allowing for 
> reproduction of the issue. But I think the attachment is preventing 
> the message from coming through. If anyone is interested I will 
> forward the attachment directly allowing for you to reproduce the 
> issue I observe.
> 
> On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:
> 
> >I have zero'd in on what appears to be the issue. This seems to be a 
> >bug in Matrix, but I am not sure yet. I am attaching files that would 
> >allow others to replicate this with my toy data.
>> 
> >Notice the elements of D1 in the attached data are all integers. It 
> >is a sparse, diagonal matrix.
>> 
>>> library(Matrix)
>>> class(D1)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >Now, I find the inverse of the matrix A as follows:
>>> A <- Ir + ZtZ %*% D1
>>> A.Inv <- solve(A, Ir)
>> 
> >Notice now the inverse of A remains a dgCMatrix and it is relatively 
> >small in size, only 33424 bytes.
>>> class(A.Inv)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
>>> object.size(A.Inv)
> >33424 bytes
>> 
> >Now, if I change an element of the matrix D1 to be non-integer, D1 
> >still has the same class as it did before
>> 
>>> D1[1] <- 1.2
>> 
>>> class(D1)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >Now, if I use this new version of D1 in the same calculations as 
> >above, notice that A.Inv is no longer a dgCMatrix but instead becomes 
> >a dgeMatrix. It then increases from an object of size 33424 bytes to 
> >an object of size 2001112 bytes!
>> 
>>> A <- Ir + ZtZ %*% D1
>>> A.Inv <- solve(A, Ir)
>>> class(A.Inv)
> >[1] "dgeMatrix"
> >attr(,"package")
> >[1] "Matrix"
>>> object.size(A.Inv)
> >2001112 bytes
>> 
> >What I desire is that the object A.Inv remain sparse at all times and
> not
> >become dense. But, perhaps there is a reason this change occurs that 
> >I don't fully understand.
>> 
> >I can of course coerce it back to a sparse matrix and it reduces back 
> >in size.
>>>  object.size(as(A.Inv, 'sparseMatrix'))
> >33424 bytes
>> 
> >I of course recognize it requires more memory to store floating 
> >points than integers, but is this large increase on the order of 
> >magnitude that seems about right?
>> 
> >Is there a reason the floating point in D1 causes for A.Inv to no 
> >longer remain sparse?
>> 
> >Thank you for your help,
> >Harold
>> 
>> 
>> 
>> 
>> 
> >-----Original Message-----
> >From: r-help-bounces at r-project.org
> >[mailto:r-help-bounces at r-project.org]
> >On Behalf Of Doran, Harold
> >Sent: Wednesday, July 10, 2013 11:42 AM
> >To: r-help at r-project.org
> >Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
> >Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
> >I have a large function computing an iterative algorithm for fitting 
> >mixed linear models. Almost all code relies on functions from the 
> >Matrix package. I've come across an issue that I do not believe 
> >previously occurred in earlier versions of R or Matrix.
>> 
> >I have a large, sparse matrix, A as
>> 
>>> class(A);dim(A)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
> >[1] 12312 12312
>> 
> >I am in a position where I must find its inverse.  I realize this is
> less
> >than ideal, and I have two ways of doing this
>> 
> >A.Inv <- solve(A, Ir) or just solve(A)
>> 
> >Where Ir is an identity matrix with the same dimensions as A and it 
> >is also sparse
>> 
>>> class(Ir)
> >[1] "ddiMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
> >The issue, however, is that the inverse of A is converted into a 
> >dense matrix and this becomes a huge memory hog, causing the rest of 
> >the algorithm to fail. In prior versions this remained as a sparse matrix.
>> 
>>> A.Inv[1:5, 1:5]
> >5 x 5 Matrix of class "dgeMatrix"
>>          [,1]      [,2]      [,3]      [,4]      [,5]
> >[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,] 0.0000000
> >0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
> >0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
> >0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000
> 0.2139975
>> 
> >I could coerce this matrix to become sparse such as
>> 
>>> AA <- as(A.Inv, 'sparseMatrix')
>>> class(AA)
> >[1] "dgCMatrix"
> >attr(,"package")
> >[1] "Matrix"
>> 
>>> AA[1:5, 1:5]
> >5 x 5 sparse Matrix of class "dgCMatrix"
>> 
> >[1,] 0.6878713 .         .         .         .
> >[2,] .         0.6718767 .         .         .
> >[3,] .         .         0.5076945 .         .
> >[4,] .         .         .         0.2324122 .
> >[5,] .         .         .         .         0.2139975
>> 
> >But I don't think this is best.
>> 
> >So, my question is why is a matrix that is sparse turning into a 
> >dense matrix? Can I avoid that and keep it sparse without having to 
> >coerce it to be sparse after it is created?
>> 
> >Thank you very much
> >Harold
>> 
>> 
>>> sessionInfo()
> >R version 3.0.1 (2013-05-16)
> >Platform: x86_64-w64-mingw32/x64 (64-bit)
>> 
> >locale:
> >[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> >States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
> >[5] LC_TIME=English_United States.1252
>> 
> >attached base packages:
> >[1] stats     graphics  grDevices utils     datasets  methods   base
>> 
> >other attached packages:
> >[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
>> 
> >loaded via a namespace (and not attached):
> >[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
>> 
> >	[[alternative HTML version deleted]]
>> 
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Thu Jul 11 19:50:36 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 11 Jul 2013 10:50:36 -0700
Subject: [R] Cannot access PDF manuals from R console
In-Reply-To: <71fe0b44af5a4ecab1c8895a1fb36fe7@BN1PR05MB220.namprd05.prod.outlook.com>
References: <71fe0b44af5a4ecab1c8895a1fb36fe7@BN1PR05MB220.namprd05.prod.outlook.com>
Message-ID: <1b44b604-7aa3-4fb6-890d-e90e7c122e1a@email.android.com>

No, have not encountered this.

If you want further help, you will have to be quite a bit more specific about the steps you have taken, version of R, source of install files. and the operating system used and configuration thereof. Carefully read the footer on this or any other list email and follow the directions there.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Cohner Gene Marker <cmarker1 at uwyo.edu> wrote:

>Hello,
>
>We are currently using R for an enterprise build here on campus.
>However after install we noticed an issue when testing the program.
>
>We cannot access the PDF manuals from the console. Instead we get the
>following error:
>Error: Access to 'doc\manual\R-intro.pdf' denied.
>
>The same error occurs for all of the manuals.
>
>We have tested this with admin privileges and also user privileges.
>There is no reason to believe that the NTFS permissions or anything are
>blocking access to the manuals. We have tried elevated privileges as
>well but with no luck.
>
>I was wondering if you have had this issue before and if there is a
>work around.
>
>Thank you,
>Cohner Marker
>Information Technology
>University of Wyoming
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Thu Jul 11 19:53:43 2013
From: jrkrideau at inbox.com (John Kane)
Date: Thu, 11 Jul 2013 09:53:43 -0800
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <B08B6AF0CF8CA44F81B9983EEBDCD6862453B4C6@DC1VEX10MB001.air.org>
References: <b08b6af0cf8ca44f81b9983eebdcd6862453b3f6@dc1vex10mb001.air.org>
	<b08b6af0cf8ca44f81b9983eebdcd6862453aa2e@dc1vex10mb001.air.org>
	<c1af72363af.0000023djrkrideau@inbox.com>
Message-ID: <C33A9CA1089.0000041Ajrkrideau@inbox.com>

Just about anything I knew about matrices, I forgot years ago so I'm no help here but I'd suggest putting the matrix on something like Mediafire http://www.mediafire.com/ or Dropbox https://www.dropbox.com so people can download it and have a look.  

I agree that dput() is not really good for "big" data sets.  

Kingston ON Canada


> -----Original Message-----
> From: hdoran at air.org
> Sent: Thu, 11 Jul 2013 17:10:54 +0000
> To: hdoran at air.org, jrkrideau at inbox.com, r-help at r-project.org
> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> This is a terrible example as I didn't realize my code actually does
> create a non-symmetric matrix and in this case the function behaves as
> expected. Nonetheless, my original issue stands and that issue still does
> not make sense.
> 
> Apologies for bad example code.
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org]
> On Behalf Of Doran, Harold
> Sent: Thursday, July 11, 2013 11:36 AM
> To: 'John Kane'; r-help at r-project.org
> Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
> Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> Thank you, John. I originally used dput() but the output is huge.
> However, here is a reproducible example of what I think very unexpected
> behavior of some matrix functions.
> 
>> ### Create a symmetric matrix of class dsCMatrix A <- as(diag(5, 10),
>> 'dsCMatrix') A[1, 5] <- A[5,1] <- 2
>> 
>> ### Create a diagonal matrix of class ddi D <- Diagonal(10, 1)
>> 
>> ### This works as it should
>> aa <- Cholesky(A %*% D)
>> 
>> ### Now, let's only change one element of D to be non-integer D[1] <-
>> 1.5
>> 
>> ### AD is still symmetric, but here the Cholesky function complains
>> that it is not aa <- Cholesky(A %*% D)
> Error in Cholesky(as(A, "symmetricMatrix"), perm = perm, LDL = LDL, super
> = super,  :
>   error in evaluating the argument 'A' in selecting a method for function
> 'Cholesky': Error in asMethod(object) :
>   not a symmetric matrix; consider forceSymmetric() or symmpart()
> 
> ### For fun try this
> 
>> L <- update(aa, as(A %*% D, 'symmetricMatrix'))
> Error in asMethod(object) :
>   not a symmetric matrix; consider forceSymmetric() or symmpart()
> 
> ### This does indeed work, but should I need to implement this step?
> 
> Cholesky(forceSymmetric(A %*% D))
> 
> So, there is something about changing the elements of a ddi matrix that
> causes subsequent problems. Is there a good reason this occurs and
> something I should be doing differently, or is this a bug?
> 
> Thanks
> 
> -----Original Message-----
> From: John Kane [mailto:jrkrideau at inbox.com]
> Sent: Thursday, July 11, 2013 10:57 AM
> To: Doran, Harold; r-help at r-project.org
> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> The message got through but not the attachment. The R help list tends to
> strip off attachements for security reasons.  Files of types  txt, png, &
> pdf should get through.
> 
> In most cases the accepted method of sending data is to use the dput()
> function to output a file in the console and then copy and paste the
> results into your email.
> 
> So for file "dat1" one would just use dput(dat1) and paste the results
> into an email.
> 
> John Kane
> Kingston ON Canada
> 
> 
>> -----Original Message-----
>> From: hdoran at air.org
>> Sent: Thu, 11 Jul 2013 09:53:40 +0000
>> To: r-help at r-project.org
>> Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
>> I sent this message yesterday with an attachment allowing for
>> reproduction of the issue. But I think the attachment is preventing
>> the message from coming through. If anyone is interested I will
>> forward the attachment directly allowing for you to reproduce the
>> issue I observe.
>> 
>> On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:
>> 
>> >I have zero'd in on what appears to be the issue. This seems to be a
>> >bug in Matrix, but I am not sure yet. I am attaching files that would
>> >allow others to replicate this with my toy data.
>>> 
>> >Notice the elements of D1 in the attached data are all integers. It
>> >is a sparse, diagonal matrix.
>>> 
>>>> library(Matrix)
>>>> class(D1)
>> >[1] "ddiMatrix"
>> >attr(,"package")
>> >[1] "Matrix"
>>> 
>> >Now, I find the inverse of the matrix A as follows:
>>>> A <- Ir + ZtZ %*% D1
>>>> A.Inv <- solve(A, Ir)
>>> 
>> >Notice now the inverse of A remains a dgCMatrix and it is relatively
>> >small in size, only 33424 bytes.
>>>> class(A.Inv)
>> >[1] "dgCMatrix"
>> >attr(,"package")
>> >[1] "Matrix"
>>> 
>>>> object.size(A.Inv)
>> >33424 bytes
>>> 
>> >Now, if I change an element of the matrix D1 to be non-integer, D1
>> >still has the same class as it did before
>>> 
>>>> D1[1] <- 1.2
>>> 
>>>> class(D1)
>> >[1] "ddiMatrix"
>> >attr(,"package")
>> >[1] "Matrix"
>>> 
>> >Now, if I use this new version of D1 in the same calculations as
>> >above, notice that A.Inv is no longer a dgCMatrix but instead becomes
>> >a dgeMatrix. It then increases from an object of size 33424 bytes to
>> >an object of size 2001112 bytes!
>>> 
>>>> A <- Ir + ZtZ %*% D1
>>>> A.Inv <- solve(A, Ir)
>>>> class(A.Inv)
>> >[1] "dgeMatrix"
>> >attr(,"package")
>> >[1] "Matrix"
>>>> object.size(A.Inv)
>> >2001112 bytes
>>> 
>> >What I desire is that the object A.Inv remain sparse at all times and
>> not
>> >become dense. But, perhaps there is a reason this change occurs that
>> >I don't fully understand.
>>> 
>> >I can of course coerce it back to a sparse matrix and it reduces back
>> >in size.
>>>>  object.size(as(A.Inv, 'sparseMatrix'))
>> >33424 bytes
>>> 
>> >I of course recognize it requires more memory to store floating
>> >points than integers, but is this large increase on the order of
>> >magnitude that seems about right?
>>> 
>> >Is there a reason the floating point in D1 causes for A.Inv to no
>> >longer remain sparse?
>>> 
>> >Thank you for your help,
>> >Harold
>>> 
>>> 
>>> 
>>> 
>>> 
>> >-----Original Message-----
>> >From: r-help-bounces at r-project.org
>> >[mailto:r-help-bounces at r-project.org]
>> >On Behalf Of Doran, Harold
>> >Sent: Wednesday, July 10, 2013 11:42 AM
>> >To: r-help at r-project.org
>> >Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
>> >Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>>> 
>> >I have a large function computing an iterative algorithm for fitting
>> >mixed linear models. Almost all code relies on functions from the
>> >Matrix package. I've come across an issue that I do not believe
>> >previously occurred in earlier versions of R or Matrix.
>>> 
>> >I have a large, sparse matrix, A as
>>> 
>>>> class(A);dim(A)
>> >[1] "dgCMatrix"
>> >attr(,"package")
>> >[1] "Matrix"
>> >[1] 12312 12312
>>> 
>> >I am in a position where I must find its inverse.  I realize this is
>> less
>> >than ideal, and I have two ways of doing this
>>> 
>> >A.Inv <- solve(A, Ir) or just solve(A)
>>> 
>> >Where Ir is an identity matrix with the same dimensions as A and it
>> >is also sparse
>>> 
>>>> class(Ir)
>> >[1] "ddiMatrix"
>> >attr(,"package")
>> >[1] "Matrix"
>>> 
>> >The issue, however, is that the inverse of A is converted into a
>> >dense matrix and this becomes a huge memory hog, causing the rest of
>> >the algorithm to fail. In prior versions this remained as a sparse
>> matrix.
>>> 
>>>> A.Inv[1:5, 1:5]
>> >5 x 5 Matrix of class "dgeMatrix"
>>>          [,1]      [,2]      [,3]      [,4]      [,5]
>> >[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,] 0.0000000
>> >0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
>> >0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
>> >0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000
>> 0.2139975
>>> 
>> >I could coerce this matrix to become sparse such as
>>> 
>>>> AA <- as(A.Inv, 'sparseMatrix')
>>>> class(AA)
>> >[1] "dgCMatrix"
>> >attr(,"package")
>> >[1] "Matrix"
>>> 
>>>> AA[1:5, 1:5]
>> >5 x 5 sparse Matrix of class "dgCMatrix"
>>> 
>> >[1,] 0.6878713 .         .         .         .
>> >[2,] .         0.6718767 .         .         .
>> >[3,] .         .         0.5076945 .         .
>> >[4,] .         .         .         0.2324122 .
>> >[5,] .         .         .         .         0.2139975
>>> 
>> >But I don't think this is best.
>>> 
>> >So, my question is why is a matrix that is sparse turning into a
>> >dense matrix? Can I avoid that and keep it sparse without having to
>> >coerce it to be sparse after it is created?
>>> 
>> >Thank you very much
>> >Harold
>>> 
>>> 
>>>> sessionInfo()
>> >R version 3.0.1 (2013-05-16)
>> >Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> 
>> >locale:
>> >[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>> >States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>> >[5] LC_TIME=English_United States.1252
>>> 
>> >attached base packages:
>> >[1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>> >other attached packages:
>> >[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
>>> 
>> >loaded via a namespace (and not attached):
>> >[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
>>> 
>> >	[[alternative HTML version deleted]]
>>> 
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From smartpink111 at yahoo.com  Thu Jul 11 20:25:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 11:25:19 -0700 (PDT)
Subject: [R] LDA and confidence ellipse
Message-ID: <1373567119.48817.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
May be this helps:
require(MASS)
require(ggplot2)
iris.lda<-lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width,? data = iris) 
datPred<-data.frame(Species=predict(iris.lda)$class,predict(iris.lda)$x)

library(ellipse)
dat_ell <- data.frame()
for(g in levels(datPred$Species)){
dat_ell <- rbind(dat_ell, cbind(as.data.frame(with(datPred[datPred$Species==g,], ellipse(cor(LD1, LD2), 
???????????????????????????????????????? scale=c(sd(LD1),sd(LD2)), 
???????????????????????????????????????? centre=c(mean(LD1),mean(LD2))))),Species=g))
}

ggplot(datPred, aes(x=LD1, y=LD2, col=Species) ) + geom_point( size = 4, aes(color = Species))+theme_bw()+geom_path(data=dat_ell,aes(x=x,y=y,color=Species),size=1,linetype=2)? 


A.K.


Hi, 

I wish to add confidence ellipse on my LDA result of the iris data set. 
Therefore: 
Is there statistical logic to do that as I only wish it to make the species separation more visable? 
How can I add it to the script below ?(ggplot): 
require(MASS) 
require(ggplot2) 
iris.lda<-lda(Species ~ Sepal.Length + Sepal.Width + Petal.Length + Petal.Width, ?data = iris) 
LD1<-predict(iris.lda)$x[,1] 
LD2<-predict(iris.lda)$x[,2] 
ggplot(iris, aes(x=LD1, y=LD2, col=iris$Species) ) + geom_point( size = 4, aes(color = iris$Species))+theme_bw() ? 

Could someone please help me. Thank you very much.


From peter.langfelder at gmail.com  Thu Jul 11 20:26:47 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 11 Jul 2013 11:26:47 -0700
Subject: [R] Installing OpenBLAS in R
In-Reply-To: <CA+hbrhV+MtJJYrh8wMZLb+8gRn2sKu=JkxXAZ8xh-GtsGBjTtw@mail.gmail.com>
References: <CA+dpOJ=RGcw=EH4qDyvaa_DETrC3g1469sbVUvo3w+tPQNE5Qw@mail.gmail.com>
	<CA+hbrhV+MtJJYrh8wMZLb+8gRn2sKu=JkxXAZ8xh-GtsGBjTtw@mail.gmail.com>
Message-ID: <CA+hbrhVMts1cMickF_x2-yBYMygNU6KjXRtcoW41VKTJWBeTMg@mail.gmail.com>

[cc-ing the list]

On Wed, Jul 10, 2013 at 11:36 PM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Hello again,
>
> I was wondering if it is possible to install OpenBLAS linear algebra
> library in R running under windows.

You will have to re-compile R from source and re-install it.

http://cran.r-project.org/doc/manuals/r-devel/R-admin.html

and in particular

http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#BLAS

For what it's worth, on my Core i5 processor running linux I found
that ATLAS BLAS is somewhat faster than OpenBLAS.

HTH,

Peter


From s.wood at bath.ac.uk  Thu Jul 11 20:50:48 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Thu, 11 Jul 2013 19:50:48 +0100
Subject: [R] mgcv: GAM with clustered standard errors
In-Reply-To: <BLU0-SMTP372CBE9495283623DFD582AE7B0@phx.gbl>
References: <BLU0-SMTP372CBE9495283623DFD582AE7B0@phx.gbl>
Message-ID: <51DEFE88.2020902@bath.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/fa12b1b6/attachment.pl>

From l.roca at gmx.us  Thu Jul 11 21:15:53 2013
From: l.roca at gmx.us (Lluis)
Date: Thu, 11 Jul 2013 12:15:53 -0700 (PDT)
Subject: [R] LDA and confidence ellipse
In-Reply-To: <1373567119.48817.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1373536460259-4671308.post@n4.nabble.com>
	<1373567119.48817.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1373570153514-4671357.post@n4.nabble.com>

Hi,

Thanks works like magic.

BTW
What is the confidence ellipses probability used?



--
View this message in context: http://r.789695.n4.nabble.com/LDA-and-confidence-ellipse-tp4671308p4671357.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Thu Jul 11 21:21:14 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 11 Jul 2013 12:21:14 -0700
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DE6EE1.4050608@xtra.co.nz>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
	<EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
	<51DE4944.9030106@stats.ox.ac.uk> <51DE6EE1.4050608@xtra.co.nz>
Message-ID: <42CC959C-DC3D-453E-BECB-9FAD718B6430@comcast.net>


On Jul 11, 2013, at 1:37 AM, Rolf Turner wrote:

> On 11/07/13 17:57, Prof Brian Ripley wrote:
>> On 11/07/2013 01:22, David Winsemius wrote: 
>>> 
>>> On Jul 10, 2013, at 4:37 PM, Lucy Leigh wrote: 
>>> 
>>>> Hi, 
>>>> I have had a look at the manual but it makes no sense to me. I have 
>>>> downloaded RTools, and the InnoSetup, 
>>>> but I don't understand how to use these to install my package? Am I 
>>>> meant to be writing commands 
>>>> in R itself, or in these other things I've downloaded? 
>>> 
>>> Since you are clearly out of your league with respect to compiling from source, now is the time to ask (again), why are you not installing the binary package? 
>>> 
>>> At the R command line just type: 
>>> 
>>> install.packages("PReMiuM")  # should default to type="win.binary" and use a CRAN mirror 
>>> 
>> 
>> Or as she seems to want to use a later version than on CRAN, to ask again why she does not use winbuilder.       
>> 
>> 
> But the winbuilder web page explicitly says:
> 
>> Please do not upload packages of other maintainers (particularly not without changing the Maintainer field to your own e-mail address, if you have permissions to do that), because the maintainer indicated in the maintainer field of the DESCRIPTION file get response from us. Please do not upload BioConductor packages or CRAN packages. Both BioConductor and CRAN do have build systems. If BioConductor or CRAN packages are not available for Windows, there is a certainly a reason and also this service won't be able to build the package properly.
> 
> So it would appear that it is *not* advisable for Ms. Leigh to use winbuilder.

I read that paragraph as saying that if a specific package , i.e. a particular numbered version, is already on CRAN or the BioC server, then do not duplicate effort. Also do not submit if a CRAN compilation resulted in an error. Especially in light of Prof. Ripley's (reiterated) advice, I did not read it as saying that a pre-release update to an existing package should not be submitted (after suitable alterations of the DESCRIPTION file.)

-- 
David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Thu Jul 11 21:20:06 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 12:20:06 -0700 (PDT)
Subject: [R] LDA and confidence ellipse
In-Reply-To: <1373570153514-4671357.post@n4.nabble.com>
References: <1373536460259-4671308.post@n4.nabble.com>
	<1373567119.48817.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1373570153514-4671357.post@n4.nabble.com>
Message-ID: <1373570406.56520.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
No problem.
The default should be 0.95
?ellipse()
level: The confidence level of a pairwise confidence region.? The
????????? default is 0.95, for a 95% region.? This is used to control
????????? the size of the ellipse being plotted.? A vector of levels
????????? may be used.

A.K.




----- Original Message -----
From: Lluis <l.roca at gmx.us>
To: r-help at r-project.org
Cc: 
Sent: Thursday, July 11, 2013 3:15 PM
Subject: Re: [R] LDA and confidence ellipse

Hi,

Thanks works like magic.

BTW
What is the confidence ellipses probability used?



--
View this message in context: http://r.789695.n4.nabble.com/LDA-and-confidence-ellipse-tp4671308p4671357.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jdnewmil at dcn.davis.CA.us  Thu Jul 11 21:22:09 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Thu, 11 Jul 2013 12:22:09 -0700
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <C33A9CA1089.0000041Ajrkrideau@inbox.com>
References: <b08b6af0cf8ca44f81b9983eebdcd6862453b3f6@dc1vex10mb001.air.org>
	<b08b6af0cf8ca44f81b9983eebdcd6862453aa2e@dc1vex10mb001.air.org>
	<c1af72363af.0000023djrkrideau@inbox.com>
	<C33A9CA1089.0000041Ajrkrideau@inbox.com>
Message-ID: <a124906d-c46b-489b-bc76-a754a1b0fc16@email.android.com>

It seems to me that this issue should be reproducible with a small matrix, since the concern is the representation rather than the values.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

John Kane <jrkrideau at inbox.com> wrote:

>Just about anything I knew about matrices, I forgot years ago so I'm no
>help here but I'd suggest putting the matrix on something like
>Mediafire http://www.mediafire.com/ or Dropbox https://www.dropbox.com
>so people can download it and have a look.  
>
>I agree that dput() is not really good for "big" data sets.  
>
>Kingston ON Canada
>
>
>> -----Original Message-----
>> From: hdoran at air.org
>> Sent: Thu, 11 Jul 2013 17:10:54 +0000
>> To: hdoran at air.org, jrkrideau at inbox.com, r-help at r-project.org
>> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
>> This is a terrible example as I didn't realize my code actually does
>> create a non-symmetric matrix and in this case the function behaves
>as
>> expected. Nonetheless, my original issue stands and that issue still
>does
>> not make sense.
>> 
>> Apologies for bad example code.
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org]
>> On Behalf Of Doran, Harold
>> Sent: Thursday, July 11, 2013 11:36 AM
>> To: 'John Kane'; r-help at r-project.org
>> Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
>> Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
>> Thank you, John. I originally used dput() but the output is huge.
>> However, here is a reproducible example of what I think very
>unexpected
>> behavior of some matrix functions.
>> 
>>> ### Create a symmetric matrix of class dsCMatrix A <- as(diag(5,
>10),
>>> 'dsCMatrix') A[1, 5] <- A[5,1] <- 2
>>> 
>>> ### Create a diagonal matrix of class ddi D <- Diagonal(10, 1)
>>> 
>>> ### This works as it should
>>> aa <- Cholesky(A %*% D)
>>> 
>>> ### Now, let's only change one element of D to be non-integer D[1]
><-
>>> 1.5
>>> 
>>> ### AD is still symmetric, but here the Cholesky function complains
>>> that it is not aa <- Cholesky(A %*% D)
>> Error in Cholesky(as(A, "symmetricMatrix"), perm = perm, LDL = LDL,
>super
>> = super,  :
>>   error in evaluating the argument 'A' in selecting a method for
>function
>> 'Cholesky': Error in asMethod(object) :
>>   not a symmetric matrix; consider forceSymmetric() or symmpart()
>> 
>> ### For fun try this
>> 
>>> L <- update(aa, as(A %*% D, 'symmetricMatrix'))
>> Error in asMethod(object) :
>>   not a symmetric matrix; consider forceSymmetric() or symmpart()
>> 
>> ### This does indeed work, but should I need to implement this step?
>> 
>> Cholesky(forceSymmetric(A %*% D))
>> 
>> So, there is something about changing the elements of a ddi matrix
>that
>> causes subsequent problems. Is there a good reason this occurs and
>> something I should be doing differently, or is this a bug?
>> 
>> Thanks
>> 
>> -----Original Message-----
>> From: John Kane [mailto:jrkrideau at inbox.com]
>> Sent: Thursday, July 11, 2013 10:57 AM
>> To: Doran, Harold; r-help at r-project.org
>> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
>> The message got through but not the attachment. The R help list tends
>to
>> strip off attachements for security reasons.  Files of types  txt,
>png, &
>> pdf should get through.
>> 
>> In most cases the accepted method of sending data is to use the
>dput()
>> function to output a file in the console and then copy and paste the
>> results into your email.
>> 
>> So for file "dat1" one would just use dput(dat1) and paste the
>results
>> into an email.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: hdoran at air.org
>>> Sent: Thu, 11 Jul 2013 09:53:40 +0000
>>> To: r-help at r-project.org
>>> Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>>> 
>>> I sent this message yesterday with an attachment allowing for
>>> reproduction of the issue. But I think the attachment is preventing
>>> the message from coming through. If anyone is interested I will
>>> forward the attachment directly allowing for you to reproduce the
>>> issue I observe.
>>> 
>>> On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:
>>> 
>>> >I have zero'd in on what appears to be the issue. This seems to be
>a
>>> >bug in Matrix, but I am not sure yet. I am attaching files that
>would
>>> >allow others to replicate this with my toy data.
>>>> 
>>> >Notice the elements of D1 in the attached data are all integers. It
>>> >is a sparse, diagonal matrix.
>>>> 
>>>>> library(Matrix)
>>>>> class(D1)
>>> >[1] "ddiMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>> >Now, I find the inverse of the matrix A as follows:
>>>>> A <- Ir + ZtZ %*% D1
>>>>> A.Inv <- solve(A, Ir)
>>>> 
>>> >Notice now the inverse of A remains a dgCMatrix and it is
>relatively
>>> >small in size, only 33424 bytes.
>>>>> class(A.Inv)
>>> >[1] "dgCMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>>>> object.size(A.Inv)
>>> >33424 bytes
>>>> 
>>> >Now, if I change an element of the matrix D1 to be non-integer, D1
>>> >still has the same class as it did before
>>>> 
>>>>> D1[1] <- 1.2
>>>> 
>>>>> class(D1)
>>> >[1] "ddiMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>> >Now, if I use this new version of D1 in the same calculations as
>>> >above, notice that A.Inv is no longer a dgCMatrix but instead
>becomes
>>> >a dgeMatrix. It then increases from an object of size 33424 bytes
>to
>>> >an object of size 2001112 bytes!
>>>> 
>>>>> A <- Ir + ZtZ %*% D1
>>>>> A.Inv <- solve(A, Ir)
>>>>> class(A.Inv)
>>> >[1] "dgeMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>>> object.size(A.Inv)
>>> >2001112 bytes
>>>> 
>>> >What I desire is that the object A.Inv remain sparse at all times
>and
>>> not
>>> >become dense. But, perhaps there is a reason this change occurs
>that
>>> >I don't fully understand.
>>>> 
>>> >I can of course coerce it back to a sparse matrix and it reduces
>back
>>> >in size.
>>>>>  object.size(as(A.Inv, 'sparseMatrix'))
>>> >33424 bytes
>>>> 
>>> >I of course recognize it requires more memory to store floating
>>> >points than integers, but is this large increase on the order of
>>> >magnitude that seems about right?
>>>> 
>>> >Is there a reason the floating point in D1 causes for A.Inv to no
>>> >longer remain sparse?
>>>> 
>>> >Thank you for your help,
>>> >Harold
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>> >-----Original Message-----
>>> >From: r-help-bounces at r-project.org
>>> >[mailto:r-help-bounces at r-project.org]
>>> >On Behalf Of Doran, Harold
>>> >Sent: Wednesday, July 10, 2013 11:42 AM
>>> >To: r-help at r-project.org
>>> >Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
>>> >Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>>>> 
>>> >I have a large function computing an iterative algorithm for
>fitting
>>> >mixed linear models. Almost all code relies on functions from the
>>> >Matrix package. I've come across an issue that I do not believe
>>> >previously occurred in earlier versions of R or Matrix.
>>>> 
>>> >I have a large, sparse matrix, A as
>>>> 
>>>>> class(A);dim(A)
>>> >[1] "dgCMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>> >[1] 12312 12312
>>>> 
>>> >I am in a position where I must find its inverse.  I realize this
>is
>>> less
>>> >than ideal, and I have two ways of doing this
>>>> 
>>> >A.Inv <- solve(A, Ir) or just solve(A)
>>>> 
>>> >Where Ir is an identity matrix with the same dimensions as A and it
>>> >is also sparse
>>>> 
>>>>> class(Ir)
>>> >[1] "ddiMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>> >The issue, however, is that the inverse of A is converted into a
>>> >dense matrix and this becomes a huge memory hog, causing the rest
>of
>>> >the algorithm to fail. In prior versions this remained as a sparse
>>> matrix.
>>>> 
>>>>> A.Inv[1:5, 1:5]
>>> >5 x 5 Matrix of class "dgeMatrix"
>>>>          [,1]      [,2]      [,3]      [,4]      [,5]
>>> >[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,]
>0.0000000
>>> >0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
>>> >0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
>>> >0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000
>>> 0.2139975
>>>> 
>>> >I could coerce this matrix to become sparse such as
>>>> 
>>>>> AA <- as(A.Inv, 'sparseMatrix')
>>>>> class(AA)
>>> >[1] "dgCMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>>>> AA[1:5, 1:5]
>>> >5 x 5 sparse Matrix of class "dgCMatrix"
>>>> 
>>> >[1,] 0.6878713 .         .         .         .
>>> >[2,] .         0.6718767 .         .         .
>>> >[3,] .         .         0.5076945 .         .
>>> >[4,] .         .         .         0.2324122 .
>>> >[5,] .         .         .         .         0.2139975
>>>> 
>>> >But I don't think this is best.
>>>> 
>>> >So, my question is why is a matrix that is sparse turning into a
>>> >dense matrix? Can I avoid that and keep it sparse without having to
>>> >coerce it to be sparse after it is created?
>>>> 
>>> >Thank you very much
>>> >Harold
>>>> 
>>>> 
>>>>> sessionInfo()
>>> >R version 3.0.1 (2013-05-16)
>>> >Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> 
>>> >locale:
>>> >[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> >States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
>>> >[5] LC_TIME=English_United States.1252
>>>> 
>>> >attached base packages:
>>> >[1] stats     graphics  grDevices utils     datasets  methods  
>base
>>>> 
>>> >other attached packages:
>>> >[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
>>>> 
>>> >loaded via a namespace (and not attached):
>>> >[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
>>>> 
>>> >	[[alternative HTML version deleted]]
>>>> 
>>> >______________________________________________
>>> >R-help at r-project.org mailing list
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at
>http://www.inbox.com/smileys
>Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk?
>and most webmails
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ripley at stats.ox.ac.uk  Thu Jul 11 21:52:09 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 11 Jul 2013 20:52:09 +0100
Subject: [R] Installing OpenBLAS in R
In-Reply-To: <CA+hbrhVMts1cMickF_x2-yBYMygNU6KjXRtcoW41VKTJWBeTMg@mail.gmail.com>
References: <CA+dpOJ=RGcw=EH4qDyvaa_DETrC3g1469sbVUvo3w+tPQNE5Qw@mail.gmail.com>
	<CA+hbrhV+MtJJYrh8wMZLb+8gRn2sKu=JkxXAZ8xh-GtsGBjTtw@mail.gmail.com>
	<CA+hbrhVMts1cMickF_x2-yBYMygNU6KjXRtcoW41VKTJWBeTMg@mail.gmail.com>
Message-ID: <51DF0CE9.6060305@stats.ox.ac.uk>

On 11/07/2013 19:26, Peter Langfelder wrote:
> [cc-ing the list]
>
> On Wed, Jul 10, 2013 at 11:36 PM, Christofer Bogaso
> <bogaso.christofer at gmail.com> wrote:
>> Hello again,
>>
>> I was wondering if it is possible to install OpenBLAS linear algebra
>> library in R running under windows.
>
> You will have to re-compile R from source and re-install it.

No, all you need to do on Windows is to replace Rblas.dll.  On Linux you 
most likely only need to link to libRblas.so.

However

- GotoBLAS contained alignment bugs (he called them bugs in R ...) that 
stopped 32-bit versions working (or working well). OpenBLAS is a 
descendant, and I have not heard this has been fixed.

- I suspect any Windows user who needs to ask does not know enough to do 
this.  In any case, the posting guide makes clear this is an R-devel topic.

> http://cran.r-project.org/doc/manuals/r-devel/R-admin.html
>
> and in particular
>
> http://cran.r-project.org/doc/manuals/r-devel/R-admin.html#BLAS
>
> For what it's worth, on my Core i5 processor running linux I found
> that ATLAS BLAS is somewhat faster than OpenBLAS.

Depends on the precise CPU and the task.  For SandyBridge Core i7's (and 
Xeons) MKL seems better than anything else (and IvyBridge ones are similar).

Now we commonly have systems with 16 cores (and 32 virtual CPUs) the 
game can be very different from a dual-core Core i5.  We do need to know 
what sort of system we are talking about.

>
> HTH,
>
> Peter



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From bcrombie at utk.edu  Thu Jul 11 21:54:07 2013
From: bcrombie at utk.edu (bcrombie)
Date: Thu, 11 Jul 2013 12:54:07 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
In-Reply-To: <F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/e062cd82/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 11 22:28:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 13:28:32 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
Message-ID: <1373574512.14425.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Not sure I understand you correctly.
I found it easier to index using number than replace it by lengthy column names.
You could do it similar to the one below.

matNew<-matrix(dat3[rowSums(dat3[c("B_MW_EEsDue1","C_MW_EEsDue2")])!=dat3["D_MW_EEsDueTotal"],1],ncol=1,dimnames=list(NULL,"MW_EEsDue_ERRORS"))

?matNew
#???? MW_EEsDue_ERRORS
#[1,]???????????? 1882
#[2,]???????????? 1884
#[3,]???????????? 1885

If you have very large dataset, you could also check ?data.table().


library(data.table)
dt3<- data.table(dat3)
dtNew<-subset(dt3[D_MW_EEsDueTotal!=B_MW_EEsDue1+C_MW_EEsDue2],select=1)
?dtNew
#?? A_CaseID
#1:???? 1882
#2:???? 1884
#3:???? 1885


#Some speed comparisons:
set.seed(1254)
datTest<- data.frame(A=sample(1000:15000,1e7,replace=TRUE),B= sample(1:10,1e7,replace=TRUE),C=sample(5:15,1e7,replace=TRUE),D=sample(5:25,1e7,replace=TRUE))

system.time(res1<- data.frame(MW_EEsDue_ERRORS=datTest[datTest[[4]] != datTest[[2]]+datTest[[3]],][[1]]))
# user? system elapsed 
#? 2.256?? 0.000?? 2.145 

system.time(mat1<-matrix(datTest[rowSums(datTest[,2:3])!=datTest[,4],1],ncol=1,dimnames=list(NULL,"MW_EEsDue_ERRORS")))
?#? user? system elapsed 
?# 0.756?? 0.088?? 0.849 

system.time(res2<- data.frame(MW_EEsDue_ERRORS=datTest[addmargins(as.matrix(datTest[,2:3]),2)[,3]!=datTest[,4],1]))
#?? user? system elapsed 
#115.740?? 0.000 105.778 

dtTest<- data.table(datTest)
system.time(res3<- subset(dtTest[D!=B+C],select=1))
?# user? system elapsed 
?# 0.508?? 0.000?? 0.477 

identical(res1,res2)
#[1] TRUE
setnames(res3,"A","MW_EEsDue_ERRORS")
?identical(res1,as.data.frame(res3))
#[1] TRUE
A.K.




----- Original Message -----
From: bcrombie <bcrombie at utk.edu>
To: r-help at r-project.org
Cc: 
Sent: Thursday, July 11, 2013 3:54 PM
Subject: Re: [R] create new matrix from user-defined function

Dan and Arun, thank you very much for your replies.? They are both very helpful and I love to get different versions of an answer so I can learn more R code.? You both used indexing to refer to the columns needed in the function, but since my real data frame will be much larger I'm assuming I can replace the index numbers with the names of the columns in quotes instead??  I'll try this on my own if you're busy with other forum questions.? Thanks, again.

From: Nordlund, Dan (DSHS/RDA) [via R] [mailto:ml-node+s789695n4671267h89 at n4.nabble.com]
Sent: Wednesday, July 10, 2013 5:46 PM
To: Crombie, Burnette N
Subject: Re: create new matrix from user-defined function

> -----Original Message-----
> From: [hidden email]</user/SendEmail.jtp?type=node&node=4671267&i=0> [mailto:r-help-bounces at r-
> project.org<mailto:r-help-bounces at r-%20%0b%3e%20project.org>] On Behalf Of bcrombie
> Sent: Wednesday, July 10, 2013 12:19 PM
> To: [hidden email]</user/SendEmail.jtp?type=node&node=4671267&i=1>
> Subject: [R] create new matrix from user-defined function
>
> #Let's say I have the following data set:
>
> dat3 = data.frame(A_CaseID = c(1881, 1882, 1883, 1884, 1885),
>? ? ? ? ? ? ? ? ?  B_MW_EEsDue1 = c(2, 2, 1, 4, 6),
>? ? ? ? ? ? ? ? ?  C_MW_EEsDue2 = c(5, 5, 4, 1, 6),
>? ? ? ? ? ? ? ? ?  D_MW_EEsDueTotal = c(7, 9, 5, 6, 112))
> dat3
> # A_CaseID B_MW_EEsDue1 C_MW_EEsDue2 D_MW_EEsDueTotal
> # 1? ?  1881? ? ? ? ? ? 2? ? ? ? ? ? 5? ? ? ? ? ? ? ? 7
> # 2? ?  1882? ? ? ? ? ? 2? ? ? ? ? ? 5? ? ? ? ? ? ? ? 9
> # 3? ?  1883? ? ? ? ? ? 1? ? ? ? ? ? 4? ? ? ? ? ? ? ? 5
> # 4? ?  1884? ? ? ? ? ? 4? ? ? ? ? ? 1? ? ? ? ? ? ? ? 6
> # 5? ?  1885? ? ? ? ? ? 6? ? ? ? ? ? 6? ? ? ? ? ? ? 112
>
> # I want to:
> #CREATE A NEW 1-COLUMN MATRIX (of unknown #rows) LISTING ONLY "A"'s
> WHERE "D
> != B + C"
> #THIS COLUMN CAN BE LABELED "MW_EEsDue_ERRORS", and output for this
> example
> should be:
>
> # MW_EEsDue_ERRORS
> # 1 1882
> # 2 1884
> # 3 1885
>
> #What is the best way to do this?? Thanks for your time.? BNC
>
>

Here is one option, there are many others.? Only you can decide what is "best".

data.frame(MW_EEsDue_ERRORS=dat3[dat3[[4]] != dat3[[2]]+dat3[[3]],][[1]])


Hope this is helpful,

Dan

Daniel J. Nordlund
Washington State Department of Social and Health Services
Planning, Performance, and Accountability
Research and Data Analysis Division
Olympia, WA 98504-5204

______________________________________________
[hidden email]</user/SendEmail.jtp?type=node&node=4671267&i=2> mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
If you reply to this email, your message will be added to the discussion below:
http://r.789695.n4.nabble.com/create-new-matrix-from-user-defined-function-tp4671250p4671267.html
To unsubscribe from create new matrix from user-defined function, click here<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4671250&code=YmNyb21iaWVAdXRrLmVkdXw0NjcxMjUwfC0xMzI5MzM0NzI3>.
NAML<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>




--
View this message in context: http://r.789695.n4.nabble.com/create-new-matrix-from-user-defined-function-tp4671250p4671361.html
Sent from the R help mailing list archive at Nabble.com.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From bcrombie at utk.edu  Thu Jul 11 22:43:06 2013
From: bcrombie at utk.edu (Crombie, Burnette N)
Date: Thu, 11 Jul 2013 20:43:06 +0000
Subject: [R] create new matrix from user-defined function
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
	<1373574512.14425.YahooMailNeo@web142602.mail.bf1.yahoo.com> 
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE7F3B9030@kmbx3.utk.tennessee.edu>

Oh, also thanks for the speed comparisons.  Missed that in my first read-through.  Very interesting and informative.  BNC

-----Original Message-----
From: Crombie, Burnette N 
Sent: Thursday, July 11, 2013 4:40 PM
To: 'arun'
Cc: R help
Subject: RE: [R] create new matrix from user-defined function

You understood me perfectly, and I agree is it easier to index using numbers than names.  I'm just afraid if my dataset gets too big I'll mess up which index numbers I'm supposed to be using.  "data.table()" looks very useful and a good way to approach the issue.  Thanks.  I really appreciate your (everyone's) help.  BNC


From smartpink111 at yahoo.com  Thu Jul 11 22:45:21 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 13:45:21 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CE7F3B9019@kmbx3.utk.tennessee.edu>
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
	<1373574512.14425.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B9019@kmbx3.utk.tennessee.edu>
Message-ID: <1373575521.34142.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi BNC,
No problem.
You could also use ?with() 

data.frame(MW_EEsDue_ERRORS=with(dat3,A_CaseID[D_MW_EEsDueTotal!=rowSums(cbind(B_MW_EEsDue1,C_MW_EEsDue2))]))
#? MW_EEsDue_ERRORS
#1???????????? 1882
#2???????????? 1884
#3???????????? 1885
A.K.



----- Original Message -----
From: "Crombie, Burnette N" <bcrombie at utk.edu>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Thursday, July 11, 2013 4:40 PM
Subject: RE: [R] create new matrix from user-defined function

You understood me perfectly, and I agree is it easier to index using numbers than names.? I'm just afraid if my dataset gets too big I'll mess up which index numbers I'm supposed to be using.? "data.table()" looks very useful and a good way to approach the issue.? Thanks.? I really appreciate your (everyone's) help.? BNC

-----Original Message-----
From: arun [mailto:smartpink111 at yahoo.com] 
Sent: Thursday, July 11, 2013 4:29 PM
To: Crombie, Burnette N
Cc: R help
Subject: Re: [R] create new matrix from user-defined function

Hi,
Not sure I understand you correctly.
I found it easier to index using number than replace it by lengthy column names.
You could do it similar to the one below.

matNew<-matrix(dat3[rowSums(dat3[c("B_MW_EEsDue1","C_MW_EEsDue2")])!=dat3["D_MW_EEsDueTotal"],1],ncol=1,dimnames=list(NULL,"MW_EEsDue_ERRORS"))

?matNew
#???? MW_EEsDue_ERRORS
#[1,]???????????? 1882
#[2,]???????????? 1884
#[3,]???????????? 1885

If you have very large dataset, you could also check ?data.table().


library(data.table)
dt3<- data.table(dat3)
dtNew<-subset(dt3[D_MW_EEsDueTotal!=B_MW_EEsDue1+C_MW_EEsDue2],select=1)
?dtNew
#?? A_CaseID
#1:???? 1882
#2:???? 1884
#3:???? 1885


#Some speed comparisons:
set.seed(1254)
datTest<- data.frame(A=sample(1000:15000,1e7,replace=TRUE),B= sample(1:10,1e7,replace=TRUE),C=sample(5:15,1e7,replace=TRUE),D=sample(5:25,1e7,replace=TRUE))

system.time(res1<- data.frame(MW_EEsDue_ERRORS=datTest[datTest[[4]] != datTest[[2]]+datTest[[3]],][[1]]))
# user? system elapsed
#? 2.256?? 0.000?? 2.145 

system.time(mat1<-matrix(datTest[rowSums(datTest[,2:3])!=datTest[,4],1],ncol=1,dimnames=list(NULL,"MW_EEsDue_ERRORS")))
?#? user? system elapsed
?# 0.756?? 0.088?? 0.849 

system.time(res2<- data.frame(MW_EEsDue_ERRORS=datTest[addmargins(as.matrix(datTest[,2:3]),2)[,3]!=datTest[,4],1]))
#?? user? system elapsed
#115.740?? 0.000 105.778 

dtTest<- data.table(datTest)
system.time(res3<- subset(dtTest[D!=B+C],select=1))
?# user? system elapsed
?# 0.508?? 0.000?? 0.477 

identical(res1,res2)
#[1] TRUE
setnames(res3,"A","MW_EEsDue_ERRORS")
?identical(res1,as.data.frame(res3))
#[1] TRUE
A.K.




----- Original Message -----
From: bcrombie <bcrombie at utk.edu>
To: r-help at r-project.org
Cc: 
Sent: Thursday, July 11, 2013 3:54 PM
Subject: Re: [R] create new matrix from user-defined function

Dan and Arun, thank you very much for your replies.? They are both very helpful and I love to get different versions of an answer so I can learn more R code.? You both used indexing to refer to the columns needed in the function, but since my real data frame will be much larger I'm assuming I can replace the index numbers with the names of the columns in quotes instead??? I'll try this on my own if you're busy with other forum questions.? Thanks, again.

From: Nordlund, Dan (DSHS/RDA) [via R] [mailto:ml-node+s789695n4671267h89 at n4.nabble.com]
Sent: Wednesday, July 10, 2013 5:46 PM
To: Crombie, Burnette N
Subject: Re: create new matrix from user-defined function

> -----Original Message-----
> From: [hidden email]</user/SendEmail.jtp?type=node&node=4671267&i=0> 
> [mailto:r-help-bounces at r- 
> project.org<mailto:r-help-bounces at r-%20%0b%3e%20project.org>] On 
> Behalf Of bcrombie
> Sent: Wednesday, July 10, 2013 12:19 PM
> To: [hidden email]</user/SendEmail.jtp?type=node&node=4671267&i=1>
> Subject: [R] create new matrix from user-defined function
>
> #Let's say I have the following data set:
>
> dat3 = data.frame(A_CaseID = c(1881, 1882, 1883, 1884, 1885),
>? ? ? ? ? ? ? ? ?? B_MW_EEsDue1 = c(2, 2, 1, 4, 6),
>? ? ? ? ? ? ? ? ?? C_MW_EEsDue2 = c(5, 5, 4, 1, 6),
>? ? ? ? ? ? ? ? ?? D_MW_EEsDueTotal = c(7, 9, 5, 6, 112))
> dat3
> # A_CaseID B_MW_EEsDue1 C_MW_EEsDue2 D_MW_EEsDueTotal? # 1? ?? 1881? ? ? ? ? ? 
>2? ? ? ? ? ? 5? ? ? ? ? ? ? ? 7? # 2? ?? 1882? ? ? ? ? ? 2? ? ? ? ? ? 5? ? ? ? ? ? ? ? 
>9? # 3? ?? 1883? ? ? ? ? ? 1? ? ? ? ? ? 4? ? ? ? ? ? ? ? 5? # 4? ?? 
>1884? ? ? ? ? ? 4? ? ? ? ? ? 1? ? ? ? ? ? ? ? 6? # 5? ?? 1885? ? ? ? ? ? 
>6? ? ? ? ? ? 6? ? ? ? ? ? ? 112
>
> # I want to:
> #CREATE A NEW 1-COLUMN MATRIX (of unknown #rows) LISTING ONLY "A"'s 
> WHERE "D != B + C"
> #THIS COLUMN CAN BE LABELED "MW_EEsDue_ERRORS", and output for this 
> example should be:
>
> # MW_EEsDue_ERRORS
> # 1 1882
> # 2 1884
> # 3 1885
>
> #What is the best way to do this?? Thanks for your time.? BNC
>
>

Here is one option, there are many others.? Only you can decide what is "best".

data.frame(MW_EEsDue_ERRORS=dat3[dat3[[4]] != dat3[[2]]+dat3[[3]],][[1]])


Hope this is helpful,

Dan

Daniel J. Nordlund
Washington State Department of Social and Health Services Planning, Performance, and Accountability Research and Data Analysis Division Olympia, WA 98504-5204

______________________________________________
[hidden email]</user/SendEmail.jtp?type=node&node=4671267&i=2> mailing list https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

________________________________
If you reply to this email, your message will be added to the discussion below:
http://r.789695.n4.nabble.com/create-new-matrix-from-user-defined-function-tp4671250p4671267.html
To unsubscribe from create new matrix from user-defined function, click here<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=unsubscribe_by_code&node=4671250&code=YmNyb21iaWVAdXRrLmVkdXw0NjcxMjUwfC0xMzI5MzM0NzI3>.
NAML<http://r.789695.n4.nabble.com/template/NamlServlet.jtp?macro=macro_viewer&id=instant_html%21nabble%3Aemail.naml&base=nabble.naml.namespaces.BasicNamespace-nabble.view.web.template.NabbleNamespace-nabble.view.web.template.NodeNamespace&breadcrumbs=notify_subscribers%21nabble%3Aemail.naml-instant_emails%21nabble%3Aemail.naml-send_instant_email%21nabble%3Aemail.naml>




--
View this message in context: http://r.789695.n4.nabble.com/create-new-matrix-from-user-defined-function-tp4671250p4671361.html
Sent from the R help mailing list archive at Nabble.com.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From michael.weylandt at gmail.com  Thu Jul 11 22:58:40 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Thu, 11 Jul 2013 15:58:40 -0500
Subject: [R] Announcing TIBCO Enterprise Runtime for R
In-Reply-To: <46AAEC13-6D0D-4DF8-A4F0-F90546E0F28B@tibco.com>
References: <46AAEC13-6D0D-4DF8-A4F0-F90546E0F28B@tibco.com>
Message-ID: <CAAmySGPdMGCun-Ypcy8MX0pDNxmbfmur2HrGix4riArCDKy0dw@mail.gmail.com>

Hi Louis,

I apologize in advance if this isn't the right forum; feel free to
direct me elsewhere.

Can you say a bit more about what exactly constitute the advantages of
TERR over R as most readers of this list know it? Some random points
of interest to me:

1. Do you have concrete benchmarks of what sorts of operations are
faster? In particular, are you, like Revolution, licensing MKL?
2. Your white-paper boasts of superior memory management; can you give
more details? Are we now reference counting, or abandoning
copy-on-write to play better with fork(), or running concurrently? In
turn, does this mean the C-API is not kept as is and any package with
compiled code isn't usable?
3. You speak of being more robust: is this at a language level
(i.e.,something simpler to use than try()/tryCatch()) or an
implementation level? If the latter, what non-robustnesses are being
addressed?
4. What are y'all's plans for supporting TERR as 'regular R' evolves?
Will it track or will things diverge over time?
5. Known (and not intended to change) differences?
6. Is the whole R-level API exposed or only a selected subset? I'm
thinking in particular of (1) things like .colMeans() which seem
rather tied to the implementation; (2) graphics devices; (3) the
promise mechanism and copy-on-write semantics?

Cheers,
Michael

On Wed, Jul 10, 2013 at 4:42 AM, Louis Bajuk-Yorgan <lbajuk at tibco.com> wrote:
> In honor of the kickoff of useR 2013 today, I'm proud to announce the availability of TIBCO Enterprise Runtime for R (or TERR for short), our new enterprise-grade, high-performance statistical engine, fully compatible with the R language.
>
> For more information on TERR, and a link to download the free Developer's Edition via the TERR Community site, check out http://spotfire.tibco.com/terr--or come to my talk at useR on Thursday morning.
>
> As part of our development of TERR, we have also contributed new packages to CRAN: sjdbc (a JDBC driver interface, previously developed for S-PLUS) and tibbrConnector (an R interface to tibbr, TIBCO's Social Network for the Enterprise).
>
> ----------------------------------
> Lou Bajuk-Yorgan
> @loubajuk
> TIBCO Spotfire
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From 538280 at gmail.com  Thu Jul 11 23:35:01 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 11 Jul 2013 15:35:01 -0600
Subject: [R] results of robust regression vs. OLS regression
In-Reply-To: <1373358009.16020.YahooMailNeo@web172703.mail.ir2.yahoo.com>
References: <1373358009.16020.YahooMailNeo@web172703.mail.ir2.yahoo.com>
Message-ID: <CAFEqCdwVdm+FHnW+_ehdQcQoKcwr8vP9cUqybeW-PAiOBEgLjQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/df1ec7bb/attachment.pl>

From 538280 at gmail.com  Thu Jul 11 23:37:21 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 11 Jul 2013 15:37:21 -0600
Subject: [R] results of robust regression vs. OLS regression
In-Reply-To: <CAFEqCdwVdm+FHnW+_ehdQcQoKcwr8vP9cUqybeW-PAiOBEgLjQ@mail.gmail.com>
References: <1373358009.16020.YahooMailNeo@web172703.mail.ir2.yahoo.com>
	<CAFEqCdwVdm+FHnW+_ehdQcQoKcwr8vP9cUqybeW-PAiOBEgLjQ@mail.gmail.com>
Message-ID: <CAFEqCdzJLF6gJc_p0mxm6_3jUh23VxuRdfr5KdeJXoh=VAuvVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/af68474f/attachment.pl>

From 538280 at gmail.com  Thu Jul 11 23:56:12 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 11 Jul 2013 15:56:12 -0600
Subject: [R] Power of Kruskal-Wallis Test?
In-Reply-To: <CAOLJphmxHNnMawwmzcZv47sE_dQ8TmGgg7d+a0dv7GPhPjVA_w@mail.gmail.com>
References: <CAOLJphmxHNnMawwmzcZv47sE_dQ8TmGgg7d+a0dv7GPhPjVA_w@mail.gmail.com>
Message-ID: <CAFEqCdxXfWHAZQP0FbqikHk54KKGLce1SU5JmPq4NxCNDHxDdQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130711/7d3fea75/attachment.pl>

From Lucy.Leigh at newcastle.edu.au  Fri Jul 12 00:49:51 2013
From: Lucy.Leigh at newcastle.edu.au (Lucy Leigh)
Date: Fri, 12 Jul 2013 08:49:51 +1000
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DF0F92.5090003@stats.ox.ac.uk>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
	<EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
	<51DE4944.9030106@stats.ox.ac.uk> <51DE6EE1.4050608@xtra.co.nz>
	<42CC959C-DC3D-453E-BECB-9FAD718B6430@comcast.net>
	<51DF0F92.5090003@stats.ox.ac.uk>
Message-ID: <51DFC330.ECEB.009F.0@newcastle.edu.au>


Hi everyone,

Thanks to everyone for all the advice. I should have been clearer in my first email, the version of 'PReMiuM' I have is not
the one available on CRAN at the moment, but a version I was sent by one of the authors, Silvia Liveriani, with a small bug fixed.
I don't know if this is the same as the next version to be released, or whether the next will be different again. I asked about
compiling it myself because I didn't want to bother the authors again if doing so was going to be a simple task I could
do myself, which I now realise is not the case. 

I think the best option seems to me to be to contact the authors again and request permission to send the version to
winbuilder to be compiled for me. 

Thank you also Bill Dunlap for your detailed instructions on how to use RTools, I am sure this will come in handy for me
in the future too, and I appreciate you taking the time to write it all out for me.

Regards,
Lucy Leigh


>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 12/07/2013 6:03 am >>>
On 11/07/2013 20:21, David Winsemius wrote:
>
> On Jul 11, 2013, at 1:37 AM, Rolf Turner wrote:
>
>> On 11/07/13 17:57, Prof Brian Ripley wrote:
>>> On 11/07/2013 01:22, David Winsemius wrote:
>>>>
>>>> On Jul 10, 2013, at 4:37 PM, Lucy Leigh wrote:
>>>>
>>>>> Hi,
>>>>> I have had a look at the manual but it makes no sense to me. I have
>>>>> downloaded RTools, and the InnoSetup,
>>>>> but I don't understand how to use these to install my package? Am I
>>>>> meant to be writing commands
>>>>> in R itself, or in these other things I've downloaded?
>>>>
>>>> Since you are clearly out of your league with respect to compiling from source, now is the time to ask (again), why are you not installing the binary package?
>>>>
>>>> At the R command line just type:
>>>>
>>>> install.packages("PReMiuM")  # should default to type="win.binary" and use a CRAN mirror
>>>>
>>>
>>> Or as she seems to want to use a later version than on CRAN, to ask again why she does not use winbuilder.
>>>
>>>
>> But the winbuilder web page explicitly says:
>>
>>> Please do not upload packages of other maintainers (particularly not without changing the Maintainer field to your own e-mail address, if you have permissions to do that), because the maintainer indicated in the maintainer field of the DESCRIPTION file get response from us. Please do not upload BioConductor packages or CRAN packages. Both BioConductor and CRAN do have build systems. If BioConductor or CRAN packages are not available for Windows, there is a certainly a reason and also this service won't be able to build the package properly.
>>
>> So it would appear that it is *not* advisable for Ms. Leigh to use winbuilder.
>
> I read that paragraph as saying that if a specific package , i.e. a particular numbered version, is already on CRAN or the BioC server, then do not duplicate effort. Also do not submit if a CRAN compilation resulted in an error. Especially in light of Prof. Ripley's (reiterated) advice, I did not read it as saying that a pre-release update to an existing package should not be submitted (after suitable alterations of the DESCRIPTION file.)

You read correctly, and indeed this is what the R manuals and the rw-FAQ 
say.  This is all assuming that Lucy does have Silvia's (the author of 
PReMiuM) permission, but given that she has a unreleased version, that 
seems eminently reasonable.

I am CCing Uwe Ligges (the provider of the winbuilder service) in case 
he wants to expand the statement.  Although winbuilder does not have a 
large capacity, new hardware was acquired fairly recently and it is not 
as hard-pressed as it was.

In the particular case of PReMiuM compiling is tricky (it needs the 
right version of Boost).  And because we've been here before, I know 
that winbuilder has a suitable version of Boost.

An alternative would be for Silvia to submit that version to winbuilder 
and send the link to Lucy to download.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk 
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/ 
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From thomaswiesner at gmx.net  Fri Jul 12 00:52:41 2013
From: thomaswiesner at gmx.net (TomW87)
Date: Thu, 11 Jul 2013 15:52:41 -0700 (PDT)
Subject: [R] Standardize GLS coefficients in R
Message-ID: <1373583161160-4671371.post@n4.nabble.com>

Hello,

I have estimated the coefficients for my model using the 'pggls' function
from the 'plm' package. Now I want to see the relative influence of those
X's. How can some please tell me how to standardize those my results in R?

Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/Standardize-GLS-coefficients-in-R-tp4671371.html
Sent from the R help mailing list archive at Nabble.com.


From bbolker at gmail.com  Fri Jul 12 02:42:47 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Jul 2013 00:42:47 +0000
Subject: [R] Differences between glmmPQL and lmer and AIC calculation
References: <CAN9sA6GUJU5U+LV8o76_iyyUja79_Fh==A4WbEH1bma61phnDg@mail.gmail.com>
Message-ID: <loom.20130712T014302-757@post.gmane.org>

Tonio Pieterek <t.pieterek <at> googlemail.com> writes:

>

[snip]

This is really more appropriate for r-sig-mixed-models at r-project.org :
please refer any followup questions there.

> For my Master thesis I collected some behavioral data of fish using
> acoustic telemetry. The aim of the study is to compare two different
> groups of fish (coded as 0 and 1 which should be the dependent
> variable) based on their swimming activity, habitat choice, etc.
> (independent variables). 

  I don't quite understand this part.  You're trying to figure out
whether a particular observation falls into one category or
another (0/1)?  Do individual fish (id in the formula below)
always fall into one category or the other?

> Each fish has several observations over time
> (repeated measurements) which I included as random factor in my models
> using library glmmPQL (package MASS). Because I have a binary data
> structure, I am using generalized linear mixed models.

  For what it's worth, penalized quasi-likelihood (used by glmmPQL)
is generally considered to be a bit dicey with binary responses
(see e.g. Bolker et al 2008 TREE paper).

> Using library glmmPQL the results reflect my descriptive analyses and
> the results are sound. However, we also want to rank several candidate
> models using AIC. And this is where the problems start. Because
> glmmPQL does not provide AIC values or comparable measures, I also
> tried to calculate the same models using function lmer. Against
> expectations, I got completely different results from these two
> libraries (glmmPQL = highly significant; lmer = far away from being
> significant with p = 0.9xx).
> 
> I used the following codes:
> 
> cal1=glmmPQL(y ~ activity, random=~1|id, data=data, family=binomial,
> na.action=na.omit)
> 
> > WORKS FINE
> 
> cal1 = lmer(y ? activity + (1 | id ), family = binomial, data=data,
> na.action=na.omit)
> 
> > PRODUCED misleading and totally different results compared to glmmPQL
>  (e.g. sometimes error message
> occurs: In mer_finalize(ans) : false convergence (8); even 
> for very simple models)

  Do you possibly have complete separation, i.e. some individuals
with all-zero responses?

  Have you tried the development version of lme4?

> 
> A glmmML did not work since we got the following failure message, for
> which we were not able to find out the reason and therefore could not
> go on with this model:
> 
> ?[glmmml] fail = 1

 [snip]
 
> The questions are:
> 
> 1) Why did glmmPQL and lmer produce completely different results and
> how can I solve this problem? Following Zuur et al. 2009* the models
> should provide very similar results, but they didn`t.

  I strongly suspect that there's something wrong with your setup.
In particular, if the response variable cal1 (0/1) only varies at
the level of individuals (id), and not within id, then you should
probably just calculate the mean activity per individual id and
run a simple logistic regression.  My guess would be that glmmPQL
may have papered over some cracks for you ...

> 2) Can I calculate AIC values (or something comparable) 
> using library glmmPQL?

  No, not without a great deal of difficulty.
> 
>  3) Is there any other option (library) to analyze my data including an AIC?

  You can use JAGS/WinBUGS with data cloning (the dclone package), or
glmmADMB.  

> 
> If something remained unclear or if you have any question about
> details, please let me know.
> 
> I would really appreciate any kind of help referring to my problem(s).
> 
> 
> *Alain F. Zuur,  Elena N. Ieno,  Neil J. Walker, Anatoly A. Saveliev,
> Graham M. Smith. (2009). Mixed Effects Models and Extensions in
> Ecology with R. Springer Science+Business Media, New York, USA.
> 
> ISSN 1431-8776
> ISBN 978-0-387-87457-9
> DOI 10.1007/978-0-387-87458-6


   I suspect


From smartpink111 at yahoo.com  Fri Jul 12 03:21:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 11 Jul 2013 18:21:01 -0700 (PDT)
Subject: [R] Help with IF command strings
Message-ID: <1373592061.44090.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
Try this:
set.seed(485)
dat1<- as.data.frame(matrix(sample(0:10,26*10,replace=TRUE),ncol=26))
mean(dat1$V21[dat1$V2==1|dat1$V2==0])
#[1] 3.8
#or
with(dat1,mean(V21[V2==1|V2==0]))
#[1] 3.8


A.K.


I have data in 26 columns, I'm trying to get a mean for column 21 only for the participants that are either 0 or 1 in column 2. 

One of the commands I tried looked something like this 

mean(data1$V21, if(V2 = 1)) ? 

So basically I need to have the program run a mean (and later 
other forms of analysis) on participants based on their condition. 
either 0 or 1. 

Help is greatly appreciated. 

Thanks


From elaine.kuo.tw at gmail.com  Fri Jul 12 05:55:47 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Fri, 12 Jul 2013 11:55:47 +0800
Subject: [R] error of betadiver in vegan
Message-ID: <CAGJhoDwusVFqBXZuSNuMZpTWiq3+=5hGMwWeJbtFJSdTyQchiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/331ef035/attachment.pl>

From alok.jadhav at credit-suisse.com  Fri Jul 12 03:48:48 2013
From: alok.jadhav at credit-suisse.com (Alok Jadhav)
Date: Thu, 11 Jul 2013 18:48:48 -0700 (PDT)
Subject: [R] Sending carbon copy mails from R
In-Reply-To: <CEE8C35195DB944D9C75ABB15A04193B24CA5961@EHKG17P32001A.csfb.cs-group.com>
References: <CEE8C35195DB944D9C75ABB15A04193B24CA5961@EHKG17P32001A.csfb.cs-group.com>
Message-ID: <1373593728556-4671376.post@n4.nabble.com>

updated code pasted here. So I guess CC is not an option at all? In that case
is there any other package that would be useful?

require(sendmailR)
to <- c("v.n at abc.com")
header <- list(cc=c("a.j at abc.com"))
x <- sendmail("toto at abc.com", to, "test", "testing",
header=header,control=list(smtpServer=server,verbose=TRUE))
<< 220 equity.xyz.com ESMTP Sendmail 8.11.7p1+Sun/8.11.7; Thu, 11 Jul 2013
21:31:43 -0400 (EDT)
>> HELO  HKD03836654
<< 250 equity.xyz.com Hello HKD03836654.gbl.ad.net [169.34.175.142], pleased
to meet you
>> MAIL FROM:  toto at abc.com
<< 250 2.1.0 toto at abc.com... Sender ok
>> RCPT TO:  v.n at abc.com
<< 250 2.1.5 v.n at abc.com... Recipient ok
>> DATA
<< 354 Enter mail, end with "." on a line by itself
>> <message data>
<< 250 2.0.0 r6C1Vh101169 Message accepted for delivery
>> QUIT
<< 221 2.0.0 equity.csfb.com closing connection



--
View this message in context: http://r.789695.n4.nabble.com/Sending-carbon-copy-mails-from-R-tp4671153p4671376.html
Sent from the R help mailing list archive at Nabble.com.


From xhl860728 at 163.com  Fri Jul 12 03:40:24 2013
From: xhl860728 at 163.com (=?GBK?B?us7BwQ==?=)
Date: Fri, 12 Jul 2013 09:40:24 +0800 (CST)
Subject: [R] [XML packages] how to get the sub-node according to the
 sub-node's attribute?
Message-ID: <6c3f7c98.10535.13fd089449d.Coremail.xhl860728@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/431cb66e/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Jul 12 07:41:07 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 12 Jul 2013 06:41:07 +0100
Subject: [R] Sending carbon copy mails from R
In-Reply-To: <1373593728556-4671376.post@n4.nabble.com>
References: <CEE8C35195DB944D9C75ABB15A04193B24CA5961@EHKG17P32001A.csfb.cs-group.com>
	<1373593728556-4671376.post@n4.nabble.com>
Message-ID: <51DF96F3.5020104@stats.ox.ac.uk>

Note that sendmailR is not 'from R'.  There are other possibilities, and 
  I use create.post() from R itself, modified as I need.

On 12/07/2013 02:48, Alok Jadhav wrote:
> updated code pasted here. So I guess CC is not an option at all? In that case
> is there any other package that would be useful?
>
> require(sendmailR)
> to <- c("v.n at abc.com")
> header <- list(cc=c("a.j at abc.com"))
> x <- sendmail("toto at abc.com", to, "test", "testing",
> header=header,control=list(smtpServer=server,verbose=TRUE))
> << 220 equity.xyz.com ESMTP Sendmail 8.11.7p1+Sun/8.11.7; Thu, 11 Jul 2013
> 21:31:43 -0400 (EDT)
>>> HELO  HKD03836654
> << 250 equity.xyz.com Hello HKD03836654.gbl.ad.net [169.34.175.142], pleased
> to meet you
>>> MAIL FROM:  toto at abc.com
> << 250 2.1.0 toto at abc.com... Sender ok
>>> RCPT TO:  v.n at abc.com
> << 250 2.1.5 v.n at abc.com... Recipient ok
>>> DATA
> << 354 Enter mail, end with "." on a line by itself
>>> <message data>
> << 250 2.0.0 r6C1Vh101169 Message accepted for delivery
>>> QUIT
> << 221 2.0.0 equity.csfb.com closing connection
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Sending-carbon-copy-mails-from-R-tp4671153p4671376.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jari.oksanen at oulu.fi  Fri Jul 12 08:13:58 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Fri, 12 Jul 2013 06:13:58 +0000
Subject: [R] error of betadiver in vegan
References: <CAGJhoDwusVFqBXZuSNuMZpTWiq3+=5hGMwWeJbtFJSdTyQchiQ@mail.gmail.com>
Message-ID: <loom.20130712T081014-325@post.gmane.org>

Elaine Kuo <elaine.kuo.tw <at> gmail.com> writes:

> 
> Hello,
> 
> I am using betadiver (vegan) to calculate beta diversity.
> However, an error message shows
> 
> Error in ifelse(x > 0, 1, 0) :
>   (list) object cannot be coerced to type 'double'
...snip...

>   ##  Raw  data
>   R  <-  betadiver(dataR)
> 
>   ##  The  indices
>   betadiver(help=TRUE)
> 
>   ##  The  beta sim  index (Lennon 2001)
>   d  <-  betadiver(R,  "sim")
> 
Elaine,

Look carefully what you do here: betadiver needs data as input -- not beta
diversities. Your last command is equal to this oneliner:

d <- betadiver(betadiver(dataR), "sim")

This is guaranteed to fail. Use instead

d <- betadiver(dataR, "sim")

Cheers, Jari Oksanen


From alok.jadhav at credit-suisse.com  Fri Jul 12 08:14:51 2013
From: alok.jadhav at credit-suisse.com (Jadhav, Alok)
Date: Fri, 12 Jul 2013 14:14:51 +0800
Subject: [R] Sending carbon copy mails from R
In-Reply-To: <51DF96F3.5020104@stats.ox.ac.uk>
References: <CEE8C35195DB944D9C75ABB15A04193B24CA5961@EHKG17P32001A.csfb.cs-group.com>
	<1373593728556-4671376.post@n4.nabble.com>
	<51DF96F3.5020104@stats.ox.ac.uk>
Message-ID: <CEE8C35195DB944D9C75ABB15A04193B24F24BD2@EHKG17P32001A.csfb.cs-group.com>

Thanks prof. Ripley. I looked into create.post function. Unfortunately
this is not useful in my case. I want to send emails programmatically
from a server machine (error notifications etc.)
I am able to send emails from my workstation using Outlook com object
without any issues. However, on server machine I don't have access to
outlook object (or any other email client). Hence the need to explore
SMTP clients to be able to send mails from server. 


Regards,
Alok


-----Original Message-----
From: Prof Brian Ripley [mailto:ripley at stats.ox.ac.uk] 
Sent: Friday, July 12, 2013 1:41 PM
To: Jadhav, Alok
Cc: r-help at r-project.org
Subject: Re: [R] Sending carbon copy mails from R

Note that sendmailR is not 'from R'.  There are other possibilities, and

  I use create.post() from R itself, modified as I need.

On 12/07/2013 02:48, Alok Jadhav wrote:
> updated code pasted here. So I guess CC is not an option at all? In
that case
> is there any other package that would be useful?
>
> require(sendmailR)
> to <- c("v.n at abc.com")
> header <- list(cc=c("a.j at abc.com"))
> x <- sendmail("toto at abc.com", to, "test", "testing",
> header=header,control=list(smtpServer=server,verbose=TRUE))
> << 220 equity.xyz.com ESMTP Sendmail 8.11.7p1+Sun/8.11.7; Thu, 11 Jul
2013
> 21:31:43 -0400 (EDT)
>>> HELO  HKD03836654
> << 250 equity.xyz.com Hello HKD03836654.gbl.ad.net [169.34.175.142],
pleased
> to meet you
>>> MAIL FROM:  toto at abc.com
> << 250 2.1.0 toto at abc.com... Sender ok
>>> RCPT TO:  v.n at abc.com
> << 250 2.1.5 v.n at abc.com... Recipient ok
>>> DATA
> << 354 Enter mail, end with "." on a line by itself
>>> <message data>
> << 250 2.0.0 r6C1Vh101169 Message accepted for delivery
>>> QUIT
> << 221 2.0.0 equity.csfb.com closing connection
>
>
>
> --
> View this message in context:
http://r.789695.n4.nabble.com/Sending-carbon-copy-mails-from-R-tp4671153
p4671376.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595

=============================================================================== 
Please access the attached hyperlink for an important el...{{dropped:4}}


From sheldon.qiu at okstate.edu  Fri Jul 12 08:15:07 2013
From: sheldon.qiu at okstate.edu (nntx)
Date: Thu, 11 Jul 2013 23:15:07 -0700 (PDT)
Subject: [R] Use R for data aggregation
Message-ID: <1373609707288-4671384.post@n4.nabble.com>

I have a set of evaluation variables (n) for each sample (sample size is
large enough) and I am trying to use R (nnet package) to aggregate the data.
However, I don't know the weight for each variable (I am sure the weight
shouldn't be equally assigned). Specifically, I have 12 indices (CO2, SO2,
TSP...) for 100 cities and I want to calculate weight for each and finally
obtain a comprehensive index and rankings for the cities. 

Could anyone give me an idea how can I realize this? Thank you very much.  



--
View this message in context: http://r.789695.n4.nabble.com/Use-R-for-data-aggregation-tp4671384.html
Sent from the R help mailing list archive at Nabble.com.


From jdnewmil at dcn.davis.CA.us  Fri Jul 12 09:41:24 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 12 Jul 2013 00:41:24 -0700
Subject: [R] Use R for data aggregation
In-Reply-To: <1373609707288-4671384.post@n4.nabble.com>
References: <1373609707288-4671384.post@n4.nabble.com>
Message-ID: <eb2a8ba3-f7eb-4978-88dd-2ae3dca58b43@email.android.com>

This is off-topic here... you are looking for statistical advice, if not problem-domain-specific help. Please read the Posting Guide.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

nntx <sheldon.qiu at okstate.edu> wrote:

>I have a set of evaluation variables (n) for each sample (sample size
>is
>large enough) and I am trying to use R (nnet package) to aggregate the
>data.
>However, I don't know the weight for each variable (I am sure the
>weight
>shouldn't be equally assigned). Specifically, I have 12 indices (CO2,
>SO2,
>TSP...) for 100 cities and I want to calculate weight for each and
>finally
>obtain a comprehensive index and rankings for the cities. 
>
>Could anyone give me an idea how can I realize this? Thank you very
>much.  
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/Use-R-for-data-aggregation-tp4671384.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From elaine.kuo.tw at gmail.com  Fri Jul 12 10:47:50 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Fri, 12 Jul 2013 16:47:50 +0800
Subject: [R] error of betadiver in vegan
In-Reply-To: <loom.20130712T081014-325@post.gmane.org>
References: <CAGJhoDwusVFqBXZuSNuMZpTWiq3+=5hGMwWeJbtFJSdTyQchiQ@mail.gmail.com>
	<loom.20130712T081014-325@post.gmane.org>
Message-ID: <CAGJhoDyMK=uYjmgNEHsBGLvvUcCcR1BHFpajzx61gzf8L10xVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/78e721d2/attachment.pl>

From ruipbarradas at sapo.pt  Fri Jul 12 12:42:41 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 12 Jul 2013 11:42:41 +0100
Subject: [R] calculate time from dates
In-Reply-To: <CAKO0DpimWfudHVqh+ABb=1-9DQJn2ZTY82P9asLG9mBOufsfjQ@mail.gmail.com>
References: <CAKO0Dpi0u4ckOGxLECcztLKm_AeTGvmgPqADX3gAuB_D8bDO1w@mail.gmail.com>
	<CABcwgRRqXjwujB9EeELfLMu1qJBRSOHJkNM_P7ZNjsvWF_gtkA@mail.gmail.com>
	<51DE9037.2090603@sapo.pt>
	<CAKO0DpimWfudHVqh+ABb=1-9DQJn2ZTY82P9asLG9mBOufsfjQ@mail.gmail.com>
Message-ID: <51DFDDA1.4090600@sapo.pt>

Hello,

It's better if you keep it on the list, the odds of getting more and 
better answers is greater.

As for your question, I've made up a dat2 with an extra column. Try the 
following, it's independent of the number of columns.



dat2 <- data.frame(ID = dat1$ID,
	month = mondf("01/01/2008", dat1$date, format = "%m/%d/%Y") + 1,
	other = rnorm(6))

dat2

sp <- split(dat2, list(dat2$ID, dat2$month))
result <- do.call(rbind, lapply(sp, tail, 1))
rownames(result) <- seq_len(nrow(result))
result


Hope this helps,

Rui Barradas


Em 12-07-2013 09:04, Gallon Li escreveu:
> Dear Rui, I think your solution is the best. however, to keep only the
> last one if month diff are equal part: because my data also have other
> variables besides ID and month, your code doesn't work. where should i
> modify it? in another word, my "dat2" contains more than 2 columns.i
> tried to modify [1:2] to [1:p] where p is the total number of columns in
> dat2 but it still doesn't work.
>
> Best, Gallon
>
>
> On Thu, Jul 11, 2013 at 7:00 PM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Hello,
>
>     The functions in stackoverflow need a date 'format' argument.
>
>
>
>     # Functions from
>     #
>     http://stackoverflow.com/__questions/1995933/number-of-__months-between-two-dates
>     <http://stackoverflow.com/questions/1995933/number-of-months-between-two-dates>
>     # with a 'format' argument added
>     #
>     # turn a date into a 'monthnumber' relative to an origin
>     monnb <- function(d, format = "%Y-%m-%d") {
>              lt <- as.POSIXlt(as.Date(d, origin="1900-01-01", format =
>     format))
>              lt$year*12 + lt$mon
>     }
>     # compute a month difference as a difference between two monnb's
>     mondf <- function(d1, d2, format = "%Y-%m-%d") {
>              monnb(d2, format = format) - monnb(d1, format = format)
>     }
>
>
>     dat1 <- read.table(text = "
>
>     ID date
>     1 4/12/2008
>     1 4/13/2008
>     1 5/11/2008
>     2 3/21/2009
>     2 4/22/2009
>     2 8/05/2009
>     ", header = TRUE)
>
>     dat2 <- data.frame(ID = dat1$ID, month = mondf("01/01/2008",
>     dat1$date, format = "%m/%d/%Y") + 1)
>
>     # Now keep just the last one if month diffs are equal
>     result <- with(dat2, aggregate(month, list(ID, month), FUN = tail,
>     1))[1:2]
>     names(result) <- names(dat2)
>     result
>
>
>     Hope this helps,
>
>     Rui Barradas
>
>     Em 11-07-2013 11:03, andrija djurovic escreveu:
>
>         Hi.
>
>         See
>         http://stackoverflow.com/__questions/1995933/number-of-__months-between-two-dates
>         <http://stackoverflow.com/questions/1995933/number-of-months-between-two-dates>
>
>         Andrija
>
>
>         On Thu, Jul 11, 2013 at 11:56 AM, Gallon Li <gallon.li at gmail.com
>         <mailto:gallon.li at gmail.com>> wrote:
>
>             My data are from 2008 to 2010, with repeated measures for
>             same subjects. I
>             wish to compute number of months since january 2008.
>
>             The data are like the following:
>
>             ID date
>             1 4/12/2008
>             1 4/13/2008
>             1 5/11/2008
>             2 3/21/2009
>             2 4/22/2009
>             2 8/05/2009
>             ...
>
>             the date column are in the format "%m/%d/%y". i wish to obtain
>
>             ID month
>             1 4
>             1 4
>             1 5
>             2 15
>             2 16
>             2 20
>             ...
>
>             also, for the same ID with two identical month, I only want
>             to keep the
>             last one. can any expert help with this question?
>
>                       [[alternative HTML version deleted]]
>
>             ________________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>             https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>
>                  [[alternative HTML version deleted]]
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>


From smartpink111 at yahoo.com  Fri Jul 12 14:21:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 12 Jul 2013 05:21:59 -0700 (PDT)
Subject: [R] Help with IF command strings
In-Reply-To: <1373592061.44090.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1373592061.44090.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1373631719.84292.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

Not sure I understand your question.
Suppose `data1` is your real data, but if the column names are different, change "V21", "V2" by those in the real data. Based on your initial post, the column names seemed to be the same.
mean(data1$V21[data1$V2==1|data1$V2==0])

A.K.? 


What values would I substitute by real data. ?I did everything the way 
you posted, and I got 3.8 as well. ?So I'm curious what values I would 
change to get the mean for the actual data? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, July 11, 2013 9:21 PM
Subject: Re: Help with IF command strings

HI,
Try this:
set.seed(485)
dat1<- as.data.frame(matrix(sample(0:10,26*10,replace=TRUE),ncol=26))
mean(dat1$V21[dat1$V2==1|dat1$V2==0])
#[1] 3.8
#or
with(dat1,mean(V21[V2==1|V2==0]))
#[1] 3.8


A.K.


I have data in 26 columns, I'm trying to get a mean for column 21 only for the participants that are either 0 or 1 in column 2. 

One of the commands I tried looked something like this 

mean(data1$V21, if(V2 = 1)) ? 

So basically I need to have the program run a mean (and later 
other forms of analysis) on participants based on their condition. 
either 0 or 1. 

Help is greatly appreciated. 

Thanks


From smartpink111 at yahoo.com  Fri Jul 12 14:42:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 12 Jul 2013 05:42:47 -0700 (PDT)
Subject: [R] Replicating Rows
Message-ID: <1373632967.80799.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

apple<- read.table(text="
Fam.name,Item,AMT.SALE.NET.PROMO,X.CY..QTY.SALE.TOT
9475,Imported Fruits,22110276001,0,436
9499,Imported Fruits,22110277001,0,236
9523,Imported Fruits,22110278001,0,71 
",sep=",",header=TRUE,stringsAsFactors=FALSE)
str(apple)
#'data.frame':??? 3 obs. of? 4 variables:
# $ Fam.name????????? : chr? "Imported Fruits" "Imported Fruits" "Imported Fruits"
# $ Item????????????? : num? 2.21e+10 2.21e+10 2.21e+10
# $ AMT.SALE.NET.PROMO: int? 0 0 0
# $ X.CY..QTY.SALE.TOT: num? 436 236 71

Here, it changed the class of some of the variables.
new<-sapply(apple[,-4],rep,apple[,4]) 
str(as.data.frame(new,stringsAsFactors=FALSE))
#'data.frame':??? 743 obs. of? 3 variables:
# $ Fam.name????????? : chr? "Imported Fruits" "Imported Fruits" "Imported Fruits" "Imported Fruits" ...
# $ Item????????????? : chr? "22110276001" "22110276001" "22110276001" "22110276001" ...
# $ AMT.SALE.NET.PROMO: chr? "0" "0" "0" "0" ...



new1<-apple[rep(seq_len(nrow(apple)),apple[,4]),-4]
?row.names(new1)<- 1:nrow(new1)
?str(new1)
#'data.frame':??? 743 obs. of? 3 variables:
# $ Fam.name????????? : chr? "Imported Fruits" "Imported Fruits" "Imported Fruits" "Imported Fruits" ...
# $ Item????????????? : num? 2.21e+10 2.21e+10 2.21e+10 2.21e+10 2.21e+10 ...
# $ AMT.SALE.NET.PROMO: int? 0 0 0 0 0 0 0 0 0 0 ..
A.K.




I try to replicate the rows according to the number of quantity 
occurred. Its row should be be sum of the quantity. is there any wrong 
with my code? thanks. 

apple 
? ? ? ? ? ? Fam.name ? ? ? ?Item AMT.SALE.NET.PROMO X.CY..QTY.SALE.TOT 
9475 Imported Fruits 22110276001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ?436 
9499 Imported Fruits 22110277001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ?236 
9523 Imported Fruits 22110278001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? 71 
9552 Imported Fruits 22110306001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? 69 
9571 Imported Fruits 22110314001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? 20 
9579 Imported Fruits 22110315001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? 80 
9604 Imported Fruits 22110317001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? 61 
9635 Imported Fruits 22110321001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? 1026 
9697 Imported Fruits 22110334001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ?223 
9720 Imported Fruits 22110335001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ?214 
9744 Imported Fruits 22110336001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ?102 
9768 Imported Fruits 22110337001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ?146 
9868 Imported Fruits 22110354001 ? ? ? ? ? ? ?118.8 ? ? ? ? ? ? ? ? 17 
9893 Imported Fruits 22110360001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? 43 
9904 Imported Fruits 22110363001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? 49 
9920 Imported Fruits 22110364001 ? ? ? ? ? ? ? ? ?0 ? ? ? ? ? ? ? ? ?1 
9938 Imported Fruits 22110365001 ? ? ? ? ? ? ?205.4 ? ? ? ? ? ? ? ? 33 

new<-sapply(apple[,-4],rep,apple[,4]) 
nrow(new) 
[1] 33572


From deter088 at umn.edu  Fri Jul 12 14:57:43 2013
From: deter088 at umn.edu (Charles Determan Jr)
Date: Fri, 12 Jul 2013 07:57:43 -0500
Subject: [R] Power of Kruskal-Wallis Test?
In-Reply-To: <CAFEqCdxXfWHAZQP0FbqikHk54KKGLce1SU5JmPq4NxCNDHxDdQ@mail.gmail.com>
References: <CAOLJphmxHNnMawwmzcZv47sE_dQ8TmGgg7d+a0dv7GPhPjVA_w@mail.gmail.com>
	<CAFEqCdxXfWHAZQP0FbqikHk54KKGLce1SU5JmPq4NxCNDHxDdQ@mail.gmail.com>
Message-ID: <CAOLJphnKKGkD9EGp=yvU8KKvTaOi0Fd3EcrWpsWTuAsYY-QaAw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/eddf4291/attachment.pl>

From zsurzsalaszlo at gmail.com  Fri Jul 12 15:04:44 2013
From: zsurzsalaszlo at gmail.com (Zsurzsa Laszlo)
Date: Fri, 12 Jul 2013 15:04:44 +0200
Subject: [R] readLines() problem-error
Message-ID: <CAF4U=VkmLfjYM7Snvi4riuuAv=b+DH5ZEjbxAgPY==wYqOnj2g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/e5b0b5b9/attachment.pl>

From HDoran at air.org  Fri Jul 12 15:24:28 2013
From: HDoran at air.org (Doran, Harold)
Date: Fri, 12 Jul 2013 13:24:28 +0000
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <a124906d-c46b-489b-bc76-a754a1b0fc16@email.android.com>
References: <b08b6af0cf8ca44f81b9983eebdcd6862453b3f6@dc1vex10mb001.air.org>
	<b08b6af0cf8ca44f81b9983eebdcd6862453aa2e@dc1vex10mb001.air.org>
	<c1af72363af.0000023djrkrideau@inbox.com>
	<C33A9CA1089.0000041Ajrkrideau@inbox.com>
	<a124906d-c46b-489b-bc76-a754a1b0fc16@email.android.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6862453BEDE@DC1VEX10MB001.air.org>

Here is code to completely replicate the issue with comments. I remain confused why simply changing one element of the ddi matrix to be non-integer changes two things: 1) It changes the class of the object I need (A Inverse) and it increases its memory. 

Ideally, A inverse will remain stored as a sparse matrix no matter what (as it is sparse in my real world problem). When it is converted to a dense object, it blows up in memory and my R program halts.

library(Matrix)

### Create a symmetric matrix of class dsCMatrix
A <- diag(5, 10)
A[1, 5] <- A[5,1] <- 2

### Create a diagonal matrix of class ddi
D <- Diagonal(10, 50)

### This returns the inverse of A stored as a sparse matrix 
### In my real world problem it consumes almost no memory at all
### this is the ideal type
A <- A %*%D
(aa <- solve(A))
class(aa)
object.size(aa)

### Now, let's only change one element of D to be non-integer
D[1] <- 1.5

### Notice here the inverse of the matrix A
### is now stored as a different object class than before
### even though the pattern of 0s and non-zeros remains the same
### It also increases in memory size
### In my real world problem, the matrix increases from 
### about .03 megabytes to almost 2 megabytes and this causes R to choke and die

A <- A %*% D
(aa <- solve(A))
class(aa)
object.size(aa)

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Newmiller
Sent: Thursday, July 11, 2013 3:22 PM
To: John Kane; r-help at r-project.org
Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)

It seems to me that this issue should be reproducible with a small matrix, since the concern is the representation rather than the values.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------
Sent from my phone. Please excuse my brevity.

John Kane <jrkrideau at inbox.com> wrote:

>Just about anything I knew about matrices, I forgot years ago so I'm no 
>help here but I'd suggest putting the matrix on something like 
>Mediafire http://www.mediafire.com/ or Dropbox https://www.dropbox.com 
>so people can download it and have a look.
>
>I agree that dput() is not really good for "big" data sets.  
>
>Kingston ON Canada
>
>
>> -----Original Message-----
>> From: hdoran at air.org
>> Sent: Thu, 11 Jul 2013 17:10:54 +0000
>> To: hdoran at air.org, jrkrideau at inbox.com, r-help at r-project.org
>> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
>> This is a terrible example as I didn't realize my code actually does 
>> create a non-symmetric matrix and in this case the function behaves
>as
>> expected. Nonetheless, my original issue stands and that issue still
>does
>> not make sense.
>> 
>> Apologies for bad example code.
>> 
>> -----Original Message-----
>> From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org]
>> On Behalf Of Doran, Harold
>> Sent: Thursday, July 11, 2013 11:36 AM
>> To: 'John Kane'; r-help at r-project.org
>> Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
>> Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
>> Thank you, John. I originally used dput() but the output is huge.
>> However, here is a reproducible example of what I think very
>unexpected
>> behavior of some matrix functions.
>> 
>>> ### Create a symmetric matrix of class dsCMatrix A <- as(diag(5,
>10),
>>> 'dsCMatrix') A[1, 5] <- A[5,1] <- 2
>>> 
>>> ### Create a diagonal matrix of class ddi D <- Diagonal(10, 1)
>>> 
>>> ### This works as it should
>>> aa <- Cholesky(A %*% D)
>>> 
>>> ### Now, let's only change one element of D to be non-integer D[1]
><-
>>> 1.5
>>> 
>>> ### AD is still symmetric, but here the Cholesky function complains 
>>> that it is not aa <- Cholesky(A %*% D)
>> Error in Cholesky(as(A, "symmetricMatrix"), perm = perm, LDL = LDL,
>super
>> = super,  :
>>   error in evaluating the argument 'A' in selecting a method for
>function
>> 'Cholesky': Error in asMethod(object) :
>>   not a symmetric matrix; consider forceSymmetric() or symmpart()
>> 
>> ### For fun try this
>> 
>>> L <- update(aa, as(A %*% D, 'symmetricMatrix'))
>> Error in asMethod(object) :
>>   not a symmetric matrix; consider forceSymmetric() or symmpart()
>> 
>> ### This does indeed work, but should I need to implement this step?
>> 
>> Cholesky(forceSymmetric(A %*% D))
>> 
>> So, there is something about changing the elements of a ddi matrix
>that
>> causes subsequent problems. Is there a good reason this occurs and 
>> something I should be doing differently, or is this a bug?
>> 
>> Thanks
>> 
>> -----Original Message-----
>> From: John Kane [mailto:jrkrideau at inbox.com]
>> Sent: Thursday, July 11, 2013 10:57 AM
>> To: Doran, Harold; r-help at r-project.org
>> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
>> 
>> The message got through but not the attachment. The R help list tends
>to
>> strip off attachements for security reasons.  Files of types  txt,
>png, &
>> pdf should get through.
>> 
>> In most cases the accepted method of sending data is to use the
>dput()
>> function to output a file in the console and then copy and paste the 
>> results into your email.
>> 
>> So for file "dat1" one would just use dput(dat1) and paste the
>results
>> into an email.
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: hdoran at air.org
>>> Sent: Thu, 11 Jul 2013 09:53:40 +0000
>>> To: r-help at r-project.org
>>> Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>>> 
>>> I sent this message yesterday with an attachment allowing for 
>>> reproduction of the issue. But I think the attachment is preventing 
>>> the message from coming through. If anyone is interested I will 
>>> forward the attachment directly allowing for you to reproduce the 
>>> issue I observe.
>>> 
>>> On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:
>>> 
>>> >I have zero'd in on what appears to be the issue. This seems to be
>a
>>> >bug in Matrix, but I am not sure yet. I am attaching files that
>would
>>> >allow others to replicate this with my toy data.
>>>> 
>>> >Notice the elements of D1 in the attached data are all integers. It 
>>> >is a sparse, diagonal matrix.
>>>> 
>>>>> library(Matrix)
>>>>> class(D1)
>>> >[1] "ddiMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>> >Now, I find the inverse of the matrix A as follows:
>>>>> A <- Ir + ZtZ %*% D1
>>>>> A.Inv <- solve(A, Ir)
>>>> 
>>> >Notice now the inverse of A remains a dgCMatrix and it is
>relatively
>>> >small in size, only 33424 bytes.
>>>>> class(A.Inv)
>>> >[1] "dgCMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>>>> object.size(A.Inv)
>>> >33424 bytes
>>>> 
>>> >Now, if I change an element of the matrix D1 to be non-integer, D1 
>>> >still has the same class as it did before
>>>> 
>>>>> D1[1] <- 1.2
>>>> 
>>>>> class(D1)
>>> >[1] "ddiMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>> >Now, if I use this new version of D1 in the same calculations as 
>>> >above, notice that A.Inv is no longer a dgCMatrix but instead
>becomes
>>> >a dgeMatrix. It then increases from an object of size 33424 bytes
>to
>>> >an object of size 2001112 bytes!
>>>> 
>>>>> A <- Ir + ZtZ %*% D1
>>>>> A.Inv <- solve(A, Ir)
>>>>> class(A.Inv)
>>> >[1] "dgeMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>>> object.size(A.Inv)
>>> >2001112 bytes
>>>> 
>>> >What I desire is that the object A.Inv remain sparse at all times
>and
>>> not
>>> >become dense. But, perhaps there is a reason this change occurs
>that
>>> >I don't fully understand.
>>>> 
>>> >I can of course coerce it back to a sparse matrix and it reduces
>back
>>> >in size.
>>>>>  object.size(as(A.Inv, 'sparseMatrix'))
>>> >33424 bytes
>>>> 
>>> >I of course recognize it requires more memory to store floating 
>>> >points than integers, but is this large increase on the order of 
>>> >magnitude that seems about right?
>>>> 
>>> >Is there a reason the floating point in D1 causes for A.Inv to no 
>>> >longer remain sparse?
>>>> 
>>> >Thank you for your help,
>>> >Harold
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>> >-----Original Message-----
>>> >From: r-help-bounces at r-project.org
>>> >[mailto:r-help-bounces at r-project.org]
>>> >On Behalf Of Doran, Harold
>>> >Sent: Wednesday, July 10, 2013 11:42 AM
>>> >To: r-help at r-project.org
>>> >Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
>>> >Subject: [R] Sparse matrix no longer sparse (Matrix Package)
>>>> 
>>> >I have a large function computing an iterative algorithm for
>fitting
>>> >mixed linear models. Almost all code relies on functions from the 
>>> >Matrix package. I've come across an issue that I do not believe 
>>> >previously occurred in earlier versions of R or Matrix.
>>>> 
>>> >I have a large, sparse matrix, A as
>>>> 
>>>>> class(A);dim(A)
>>> >[1] "dgCMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>> >[1] 12312 12312
>>>> 
>>> >I am in a position where I must find its inverse.  I realize this
>is
>>> less
>>> >than ideal, and I have two ways of doing this
>>>> 
>>> >A.Inv <- solve(A, Ir) or just solve(A)
>>>> 
>>> >Where Ir is an identity matrix with the same dimensions as A and it 
>>> >is also sparse
>>>> 
>>>>> class(Ir)
>>> >[1] "ddiMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>> >The issue, however, is that the inverse of A is converted into a 
>>> >dense matrix and this becomes a huge memory hog, causing the rest
>of
>>> >the algorithm to fail. In prior versions this remained as a sparse
>>> matrix.
>>>> 
>>>>> A.Inv[1:5, 1:5]
>>> >5 x 5 Matrix of class "dgeMatrix"
>>>>          [,1]      [,2]      [,3]      [,4]      [,5]
>>> >[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,]
>0.0000000
>>> >0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
>>> >0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
>>> >0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000
>>> 0.2139975
>>>> 
>>> >I could coerce this matrix to become sparse such as
>>>> 
>>>>> AA <- as(A.Inv, 'sparseMatrix')
>>>>> class(AA)
>>> >[1] "dgCMatrix"
>>> >attr(,"package")
>>> >[1] "Matrix"
>>>> 
>>>>> AA[1:5, 1:5]
>>> >5 x 5 sparse Matrix of class "dgCMatrix"
>>>> 
>>> >[1,] 0.6878713 .         .         .         .
>>> >[2,] .         0.6718767 .         .         .
>>> >[3,] .         .         0.5076945 .         .
>>> >[4,] .         .         .         0.2324122 .
>>> >[5,] .         .         .         .         0.2139975
>>>> 
>>> >But I don't think this is best.
>>>> 
>>> >So, my question is why is a matrix that is sparse turning into a 
>>> >dense matrix? Can I avoid that and keep it sparse without having to 
>>> >coerce it to be sparse after it is created?
>>>> 
>>> >Thank you very much
>>> >Harold
>>>> 
>>>> 
>>>>> sessionInfo()
>>> >R version 3.0.1 (2013-05-16)
>>> >Platform: x86_64-w64-mingw32/x64 (64-bit)
>>>> 
>>> >locale:
>>> >[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
>>> >States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
>>> >[5] LC_TIME=English_United States.1252
>>>> 
>>> >attached base packages:
>>> >[1] stats     graphics  grDevices utils     datasets  methods  
>base
>>>> 
>>> >other attached packages:
>>> >[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
>>>> 
>>> >loaded via a namespace (and not attached):
>>> >[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
>>>> 
>>> >	[[alternative HTML version deleted]]
>>>> 
>>> >______________________________________________
>>> >R-help at r-project.org mailing list
>>> >https://stat.ethz.ch/mailman/listinfo/r-help
>>> >PLEASE do read the posting guide
>>> >http://www.R-project.org/posting-guide.html
>>> >and provide commented, minimal, self-contained, reproducible code.
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>____________________________________________________________
>GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at 
>http://www.inbox.com/smileys Works with AIM?, MSN? Messenger, Yahoo!? 
>Messenger, ICQ?, Google Talk? and most webmails
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

From info at aghmed.fsnet.co.uk  Fri Jul 12 15:26:01 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Fri, 12 Jul 2013 14:26:01 +0100
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <51DFC330.ECEB.009F.0@newcastle.edu.au>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
	<EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
	<51DE4944.9030106@stats.ox.ac.uk> <51DE6EE1.4050608@xtra.co.nz>
	<42CC959C-DC3D-453E-BECB-9FAD718B6430@comcast.net>
	<51DF0F92.5090003@stats.ox.ac.uk>
	<51DFC330.ECEB.009F.0@newcastle.edu.au>
Message-ID: <Zen-1UxdMP-0009U0-Py@smarthost01c.mail.zen.net.uk>

At 23:49 11/07/2013, Lucy Leigh wrote:

>Hi everyone,
>
>Thanks to everyone for all the advice. I should have been clearer in 
>my first email, the version of 'PReMiuM' I have is not
>the one available on CRAN at the moment, but a version I was sent by 
>one of the authors, Silvia Liveriani, with a small bug fixed.
>I don't know if this is the same as the next version to be released, 
>or whether the next will be different again. I asked about
>compiling it myself because I didn't want to bother the authors 
>again if doing so was going to be a simple task I could
>do myself, which I now realise is not the case.
>
>I think the best option seems to me to be to contact the authors 
>again and request permission to send the version to
>winbuilder to be compiled for me.

Lucy
The advantage of following Bill's instructions is that you will then 
know how to install your own packages. Eventually when you have been 
using R for a while you will have all sorts of useful functions and 
one day you will think 'What I need is to make a package lucytools to 
keep them together and documented.' This is easier than it looks, I 
wish I had done it much earlier (except obviously I did not call mine 
lucytools).


>Thank you also Bill Dunlap for your detailed instructions on how to 
>use RTools, I am sure this will come in handy for me
>in the future too, and I appreciate you taking the time to write it 
>all out for me.
>
>Regards,
>Lucy Leigh
>
>
> >>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 12/07/2013 6:03 am >>>
>On 11/07/2013 20:21, David Winsemius wrote:
> >
> > On Jul 11, 2013, at 1:37 AM, Rolf Turner wrote:
> >
> >> On 11/07/13 17:57, Prof Brian Ripley wrote:
> >>> On 11/07/2013 01:22, David Winsemius wrote:
> >>>>
> >>>> On Jul 10, 2013, at 4:37 PM, Lucy Leigh wrote:
> >>>>
> >>>>> Hi,
> >>>>> I have had a look at the manual but it makes no sense to me. I have
> >>>>> downloaded RTools, and the InnoSetup,
> >>>>> but I don't understand how to use these to install my package? Am I
> >>>>> meant to be writing commands
> >>>>> in R itself, or in these other things I've downloaded?
> >>>>
> >>>> Since you are clearly out of your league with respect to 
> compiling from source, now is the time to ask (again), why are you 
> not installing the binary package?
> >>>>
> >>>> At the R command line just type:
> >>>>
> >>>> install.packages("PReMiuM")  # should default to 
> type="win.binary" and use a CRAN mirror
> >>>>
> >>>
> >>> Or as she seems to want to use a later version than on CRAN, to 
> ask again why she does not use winbuilder.
> >>>
> >>>
> >> But the winbuilder web page explicitly says:
> >>
> >>> Please do not upload packages of other maintainers 
> (particularly not without changing the Maintainer field to your own 
> e-mail address, if you have permissions to do that), because the 
> maintainer indicated in the maintainer field of the DESCRIPTION 
> file get response from us. Please do not upload BioConductor 
> packages or CRAN packages. Both BioConductor and CRAN do have build 
> systems. If BioConductor or CRAN packages are not available for 
> Windows, there is a certainly a reason and also this service won't 
> be able to build the package properly.
> >>
> >> So it would appear that it is *not* advisable for Ms. Leigh to 
> use winbuilder.
> >
> > I read that paragraph as saying that if a specific package , i.e. 
> a particular numbered version, is already on CRAN or the BioC 
> server, then do not duplicate effort. Also do not submit if a CRAN 
> compilation resulted in an error. Especially in light of Prof. 
> Ripley's (reiterated) advice, I did not read it as saying that a 
> pre-release update to an existing package should not be submitted 
> (after suitable alterations of the DESCRIPTION file.)
>
>You read correctly, and indeed this is what the R manuals and the rw-FAQ
>say.  This is all assuming that Lucy does have Silvia's (the author of
>PReMiuM) permission, but given that she has a unreleased version, that
>seems eminently reasonable.
>
>I am CCing Uwe Ligges (the provider of the winbuilder service) in case
>he wants to expand the statement.  Although winbuilder does not have a
>large capacity, new hardware was acquired fairly recently and it is not
>as hard-pressed as it was.
>
>In the particular case of PReMiuM compiling is tricky (it needs the
>right version of Boost).  And because we've been here before, I know
>that winbuilder has a suitable version of Boost.
>
>An alternative would be for Silvia to submit that version to winbuilder
>and send the link to Lucy to download.
>
>--
>Brian D. Ripley,                  ripley at stats.ox.ac.uk
>Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>University of Oxford,             Tel:  +44 1865 272861 (self)
>1 South Parks Road,                     +44 1865 272866 (PA)
>Oxford OX1 3TG, UK                Fax:  +44 1865 272595

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From olivier.charansonney at orange.fr  Fri Jul 12 12:06:21 2013
From: olivier.charansonney at orange.fr (Olivier Charansonney)
Date: Fri, 12 Jul 2013 12:06:21 +0200
Subject: [R] Needing help for excluding vector elements
Message-ID: <004f01ce7ee7$758d6930$60a83b90$@orange.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/b5a4bbee/attachment.pl>

From amen.alyaari at Bordeaux.inra.fr  Fri Jul 12 13:02:04 2013
From: amen.alyaari at Bordeaux.inra.fr (Jonsson)
Date: Fri, 12 Jul 2013 04:02:04 -0700 (PDT)
Subject: [R] What is the maximum limit for an array?
Message-ID: <1373626924487-4671395.post@n4.nabble.com>

Hello All,
I am having a problem with this:

file<-array(dim=c(1440,720,700,3))
      Error in array(dim = c(1440, 720, 700, 3)) : 
       'dim' specifies too large an array

I have a memory of 20GB, But I do not know where is the problem!Any help

When I replaced 700 by any number bellow like( 600,500),it worked without
any problem.



--
View this message in context: http://r.789695.n4.nabble.com/What-is-the-maximum-limit-for-an-array-tp4671395.html
Sent from the R help mailing list archive at Nabble.com.


From bcrombie at utk.edu  Fri Jul 12 15:17:05 2013
From: bcrombie at utk.edu (bcrombie)
Date: Fri, 12 Jul 2013 06:17:05 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
In-Reply-To: <1373575521.34142.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
	<1373574512.14425.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1373575521.34142.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE7F3B908D@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/6897fb25/attachment.pl>

From amen.alyaari at bordeaux.inra.fr  Fri Jul 12 15:20:28 2013
From: amen.alyaari at bordeaux.inra.fr (Amen Alyaari)
Date: Fri, 12 Jul 2013 15:20:28 +0200
Subject: [R] apply problem
Message-ID: <51E0029C.9020408@bordeaux.inra.fr>

I will try to explain my problem. There are 600 (global map)files (1440 
sample * 720 lines)in two directories dir1 and dir2, which have the same 
format ,byte,extend,etc. I computed the `bias` between two datasets 
using the function and code given below as follows:

Function:

         bias <-function(pred,obs,na.rm=TRUE){
                      mean((pred - obs), na.rm = na.rm)}

read files:

          dir1 <- list.files("/donnees/notghi", "*.img", full.names = TRUE)
          dir2 <- list.files("/donnees/baieSt", "*.img", full.names = TRUE)

for each x,y location, I would read it into a multi-dimensional array 
with dimensions:

           file_tot<-array(dim=c(1440,720,600,2))

Apply the code:

       for(i in 1:length(dir1)){
       file_tot[,,i,1] <- readBin(dir1[i], double(), size = 4 ,n = 1440* 
720 , signed = T)
       file_tot[,,i,2] <- readBin(dir2[i], double(), size = 4 ,n = 1440 
* 720, signed = T)
      }
calculate the `bias`:

         result<-apply(file_tot,c(1,2),function(x){bias(x[,1],x[,2])})
This worked correctly and no problem with that.

now I want to modify the function and add third part(mod in the function 
which should come from different data (dir3) other than dir1 and dir2):
  function:

        err<-function(pred,obs,mod,na.rm=TRUE){
             sqrt(mean(((pred-obs)*(pred-mod)), na.rm = na.rm))}

read the files(note that now dir3 is added and files have the same 
attributes):

         dir1 <- list.files("/donnees/notghi", "*.img", full.names = TRUE)
         dir2 <- list.files("/donnees/baieSt", "*.img", full.names = TRUE)
         dir3 <- list.files("/donnees/modt", "*.img", full.names = TRUE)
  code:
I tried to do this,I put `3` instead of `2`:

         file_tot<-array(dim=c(1440,720,600,3))## worked well

   and then change this line accordingly:
from:

        result<-apply(file_tot,c(1,2),function(x){bias(x[,1],x[,2])})

to :

       result<-apply(file_tot,c(1,3),function(x){err(x[,1],x[,2],x[,3])})
          ## not 3 instead of 2 and I added x[,3]
               Is that right?

This worked without errors but I checked the results and they were crap.

-- 
Amen Alyaari, UPMC
PhD student
Unit of Functional Ecology&  Environmental Physics [EPHYSE]
National Institute of Agricultural Research [INRA].
71, Avenue Edouard Bourlaux
33140 Villenave d'Ornon
T?l?phone : +33(0) 5 57 12 24 27
Fax : +33 (0)5 57 12 24 20
FRANCE


From bbolker at gmail.com  Fri Jul 12 15:42:39 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Jul 2013 13:42:39 +0000
Subject: [R] What is the maximum limit for an array?
References: <1373626924487-4671395.post@n4.nabble.com>
Message-ID: <loom.20130712T154056-229@post.gmane.org>

Jonsson <amen.alyaari <at> Bordeaux.inra.fr> writes:

> 
> Hello All,
> I am having a problem with this:
> 
> file<-array(dim=c(1440,720,700,3))
>       Error in array(dim = c(1440, 720, 700, 3)) : 
>        'dim' specifies too large an array
> 
> I have a memory of 20GB, But I do not know where is the problem!Any help
> 
> When I replaced 700 by any number bellow like( 600,500),it worked without
> any problem.

From

http://stat.ethz.ch/R-manual/R-devel/library/base/html/LongVectors.html :

Prior to R 3.0.0, all vectors in R were restricted to at most 2^31 - 1 

> 1440*720*700*3
[1] 2177280000
> 2^31-1
[1] 2147483647

  So you need R>=3.0.0 (on a 64-bit system).

 Ben Bolker


From gunter.berton at gene.com  Fri Jul 12 15:44:24 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 12 Jul 2013 06:44:24 -0700
Subject: [R] Needing help for excluding vector elements
In-Reply-To: <004f01ce7ee7$758d6930$60a83b90$@orange.fr>
References: <004f01ce7ee7$758d6930$60a83b90$@orange.fr>
Message-ID: <CACk-te2AUd9KOU3LWP0axAZYHipN3Qz4dgtb3vmV_v15n9xvCg@mail.gmail.com>

Make an effort to learn R. Read "An Introduction to R" -- at least the
beginning where you will learn about basic R structures and indexing.

Cheers,
Bert

On Fri, Jul 12, 2013 at 3:06 AM, Olivier Charansonney
<olivier.charansonney at orange.fr> wrote:
> Hello,
>
> R for Dummies.
>
> How can I exclude the first 1000 values of a vector (length 12000)? More
> generally all the values up to the ith?
>
> Thanks for your help,
>
>
>
> Dr Olivier Charansonney
>
> Cardiologue
>
> Centre Hospitalier Sud-Francilien, Corbeil-Essonnes, France
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From Jose.Iparraguirre at ageuk.org.uk  Fri Jul 12 15:47:31 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Fri, 12 Jul 2013 13:47:31 +0000
Subject: [R] Needing help for excluding vector elements
In-Reply-To: <004f01ce7ee7$758d6930$60a83b90$@orange.fr>
References: <004f01ce7ee7$758d6930$60a83b90$@orange.fr>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2011788@AGEPXMB006.uk.age.local>

Dear Olivier,

Perhaps you're looking for this?

> yourvector[-(1:1000)]



Kind regards,

Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK

Age UK
Tavis House, 1- 6 Tavistock Square
London, WC1H 9NB

T 020 303 31482
E Jose.Iparraguirre at ageuk.org.uk
Twitter @jose.iparraguirre at ageuk

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Olivier Charansonney
Sent: 12 July 2013 11:06
To: r-help at r-project.org
Subject: [R] Needing help for excluding vector elements

Hello,

R for Dummies.

How can I exclude the first 1000 values of a vector (length 12000)? More generally all the values up to the ith?

Thanks for your help,

 

Dr Olivier Charansonney

Cardiologue

Centre Hospitalier Sud-Francilien, Corbeil-Essonnes, France

 


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From smartpink111 at yahoo.com  Fri Jul 12 16:10:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 12 Jul 2013 07:10:46 -0700 (PDT)
Subject: [R] Needing help for excluding vector elements
In-Reply-To: <004f01ce7ee7$758d6930$60a83b90$@orange.fr>
References: <004f01ce7ee7$758d6930$60a83b90$@orange.fr>
Message-ID: <1373638246.37502.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Try:
set.seed(41)
vec1<- sample(1:50,12000,replace=TRUE)
tail(vec1,-1000)
length(tail(vec1,-1000))
#[1] 11000


A.K.




----- Original Message -----
From: Olivier Charansonney <olivier.charansonney at orange.fr>
To: r-help at r-project.org
Cc: 
Sent: Friday, July 12, 2013 6:06 AM
Subject: [R] Needing help for excluding vector elements

Hello,

R for Dummies.

How can I exclude the first 1000 values of a vector (length 12000)? More
generally all the values up to the ith?

Thanks for your help,



Dr Olivier Charansonney

Cardiologue

Centre Hospitalier Sud-Francilien, Corbeil-Essonnes, France




??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pdalgd at gmail.com  Fri Jul 12 17:02:16 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 12 Jul 2013 17:02:16 +0200
Subject: [R] readLines() problem-error
In-Reply-To: <CAF4U=VkmLfjYM7Snvi4riuuAv=b+DH5ZEjbxAgPY==wYqOnj2g@mail.gmail.com>
References: <CAF4U=VkmLfjYM7Snvi4riuuAv=b+DH5ZEjbxAgPY==wYqOnj2g@mail.gmail.com>
Message-ID: <33D36C86-83FB-4FEB-A095-DDE18910DF4D@gmail.com>

It's not really a problem or error, just a message that the system is closing a connection for you. Presumably, you have several previous instances of opening a connection and naming it "con".  

To avoid the message, just close(con) when you are done reading from it.

-pd

On Jul 12, 2013, at 15:04 , Zsurzsa Laszlo wrote:

> Hello everyone,
> 
> I have my program like this:
> 
> 
> while (length(oneLine <- readLines(con, n = 1, warn = FALSE)) > 0)  {
>   # here I process the line I read
> }
> 
> 
> The problem is it gives me different output every time. I get a problem/
> error like:
> 
> "Closing unused connection (con)". Sadly I can't provide the file because
> it's ,ore then a GB.
> 
> Thank you in advance,
> -----------------------------------------------------------------------
> - L?szl?-Andr?s Zsurzsa,                                  -
> - Msc. Infromatics, Technical University Munich, -
> -----------------------------------------------------------------------
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From 538280 at gmail.com  Fri Jul 12 17:13:48 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 12 Jul 2013 09:13:48 -0600
Subject: [R] Standardize GLS coefficients in R
In-Reply-To: <1373583161160-4671371.post@n4.nabble.com>
References: <1373583161160-4671371.post@n4.nabble.com>
Message-ID: <CAFEqCdwVbAPrqTZHX3ugH9JE0oZKWk6+giBTGHcqOLS9i=JQBw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/52d2351c/attachment.pl>

From 538280 at gmail.com  Fri Jul 12 17:36:14 2013
From: 538280 at gmail.com (Greg Snow)
Date: Fri, 12 Jul 2013 09:36:14 -0600
Subject: [R] Power of Kruskal-Wallis Test?
In-Reply-To: <CAOLJphnKKGkD9EGp=yvU8KKvTaOi0Fd3EcrWpsWTuAsYY-QaAw@mail.gmail.com>
References: <CAOLJphmxHNnMawwmzcZv47sE_dQ8TmGgg7d+a0dv7GPhPjVA_w@mail.gmail.com>
	<CAFEqCdxXfWHAZQP0FbqikHk54KKGLce1SU5JmPq4NxCNDHxDdQ@mail.gmail.com>
	<CAOLJphnKKGkD9EGp=yvU8KKvTaOi0Fd3EcrWpsWTuAsYY-QaAw@mail.gmail.com>
Message-ID: <CAFEqCdxQ-iAjjjFcDe1w0AhXg-A9K0+DmJgtUjxjA2EBHxX6bg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/bdce93ad/attachment.pl>

From murdoch.duncan at gmail.com  Fri Jul 12 17:38:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 12 Jul 2013 17:38:43 +0200
Subject: [R] Help with installing a .tar.gz package on windows
In-Reply-To: <Zen-1UxdMP-0009U0-Py@smarthost01c.mail.zen.net.uk>
References: <51DA915A.ECEB.009F.0@newcastle.edu.au>
	<154893A2-9559-4E48-A644-10BE408BF477@xs4all.nl>
	<51DC0DB6.ECEB.009F.0@newcastle.edu.au>
	<CACxE24=mhP6PGdHS2zK+BKgwktRspoTgiNskw2bS8Q_ux8CmvA@mail.gmail.com>
	<51DE7CE2.ECEB.009F.0@newcastle.edu.au>
	<EE680CE6-9F8F-436E-967F-E26874A9F14E@comcast.net>
	<51DE4944.9030106@stats.ox.ac.uk> <51DE6EE1.4050608@xtra.co.nz>
	<42CC959C-DC3D-453E-BECB-9FAD718B6430@comcast.net>
	<51DF0F92.5090003@stats.ox.ac.uk>
	<51DFC330.ECEB.009F.0@newcastle.edu.au>
	<Zen-1UxdMP-0009U0-Py@smarthost01c.mail.zen.net.uk>
Message-ID: <51E02303.8020204@gmail.com>

On 13-07-12 3:26 PM, Michael Dewey wrote:
> At 23:49 11/07/2013, Lucy Leigh wrote:
>
>> Hi everyone,
>>
>> Thanks to everyone for all the advice. I should have been clearer in
>> my first email, the version of 'PReMiuM' I have is not
>> the one available on CRAN at the moment, but a version I was sent by
>> one of the authors, Silvia Liveriani, with a small bug fixed.
>> I don't know if this is the same as the next version to be released,
>> or whether the next will be different again. I asked about
>> compiling it myself because I didn't want to bother the authors
>> again if doing so was going to be a simple task I could
>> do myself, which I now realise is not the case.
>>
>> I think the best option seems to me to be to contact the authors
>> again and request permission to send the version to
>> winbuilder to be compiled for me.
>
> Lucy
> The advantage of following Bill's instructions is that you will then
> know how to install your own packages. Eventually when you have been
> using R for a while you will have all sorts of useful functions and
> one day you will think 'What I need is to make a package lucytools to
> keep them together and documented.' This is easier than it looks, I
> wish I had done it much earlier (except obviously I did not call mine
> lucytools).
>


I just want to add here that you don't need Rtools to install simple 
packages.  If they contain only R code, you can install them without the 
tools.  This advice would likely apply to lucytools (or maybe michaeltools).

My advice doesn't apply to PReMiuM, because that package has C++ code in 
it.  For compiling C, C++, or Fortran code, you need the Rtools, so 
following something like Brian Ripley's or Bill Dunlap's advice is needed.

Duncan Murdoch


>
>> Thank you also Bill Dunlap for your detailed instructions on how to
>> use RTools, I am sure this will come in handy for me
>> in the future too, and I appreciate you taking the time to write it
>> all out for me.
>>
>> Regards,
>> Lucy Leigh
>>
>>
>>>>> Prof Brian Ripley <ripley at stats.ox.ac.uk> 12/07/2013 6:03 am >>>
>> On 11/07/2013 20:21, David Winsemius wrote:
>>>
>>> On Jul 11, 2013, at 1:37 AM, Rolf Turner wrote:
>>>
>>>> On 11/07/13 17:57, Prof Brian Ripley wrote:
>>>>> On 11/07/2013 01:22, David Winsemius wrote:
>>>>>>
>>>>>> On Jul 10, 2013, at 4:37 PM, Lucy Leigh wrote:
>>>>>>
>>>>>>> Hi,
>>>>>>> I have had a look at the manual but it makes no sense to me. I have
>>>>>>> downloaded RTools, and the InnoSetup,
>>>>>>> but I don't understand how to use these to install my package? Am I
>>>>>>> meant to be writing commands
>>>>>>> in R itself, or in these other things I've downloaded?
>>>>>>
>>>>>> Since you are clearly out of your league with respect to
>> compiling from source, now is the time to ask (again), why are you
>> not installing the binary package?
>>>>>>
>>>>>> At the R command line just type:
>>>>>>
>>>>>> install.packages("PReMiuM")  # should default to
>> type="win.binary" and use a CRAN mirror
>>>>>>
>>>>>
>>>>> Or as she seems to want to use a later version than on CRAN, to
>> ask again why she does not use winbuilder.
>>>>>
>>>>>
>>>> But the winbuilder web page explicitly says:
>>>>
>>>>> Please do not upload packages of other maintainers
>> (particularly not without changing the Maintainer field to your own
>> e-mail address, if you have permissions to do that), because the
>> maintainer indicated in the maintainer field of the DESCRIPTION
>> file get response from us. Please do not upload BioConductor
>> packages or CRAN packages. Both BioConductor and CRAN do have build
>> systems. If BioConductor or CRAN packages are not available for
>> Windows, there is a certainly a reason and also this service won't
>> be able to build the package properly.
>>>>
>>>> So it would appear that it is *not* advisable for Ms. Leigh to
>> use winbuilder.
>>>
>>> I read that paragraph as saying that if a specific package , i.e.
>> a particular numbered version, is already on CRAN or the BioC
>> server, then do not duplicate effort. Also do not submit if a CRAN
>> compilation resulted in an error. Especially in light of Prof.
>> Ripley's (reiterated) advice, I did not read it as saying that a
>> pre-release update to an existing package should not be submitted
>> (after suitable alterations of the DESCRIPTION file.)
>>
>> You read correctly, and indeed this is what the R manuals and the rw-FAQ
>> say.  This is all assuming that Lucy does have Silvia's (the author of
>> PReMiuM) permission, but given that she has a unreleased version, that
>> seems eminently reasonable.
>>
>> I am CCing Uwe Ligges (the provider of the winbuilder service) in case
>> he wants to expand the statement.  Although winbuilder does not have a
>> large capacity, new hardware was acquired fairly recently and it is not
>> as hard-pressed as it was.
>>
>> In the particular case of PReMiuM compiling is tricky (it needs the
>> right version of Boost).  And because we've been here before, I know
>> that winbuilder has a suitable version of Boost.
>>
>> An alternative would be for Silvia to submit that version to winbuilder
>> and send the link to Lucy to download.
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> Michael Dewey
> info at aghmed.fsnet.co.uk
> http://www.aghmed.fsnet.co.uk/home.html
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Fri Jul 12 17:53:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 12 Jul 2013 08:53:28 -0700 (PDT)
Subject: [R] Help with IF command strings
In-Reply-To: <1373631719.84292.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1373592061.44090.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1373631719.84292.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1373644408.29686.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Regarding the 2nd issue of mean=3.8 being "too high", could you explain it.
#Using the same example:
?dat1$V21[dat1$V2==1|dat1$V2==0]
#[1]? 6? 2? 1 10? 0
?(6+2+1+10+0)/5
#[1] 3.8
?mean(dat1$V21[dat1$V2==1|dat1$V2==0])
#[1] 3.8

About missing data:
set.seed(55)
dat2<- as.data.frame(matrix(sample(c(NA,0:4),26*10,replace=TRUE),ncol=26))? ####new example dataset
?dat2$V2
?#[1]? 4 NA? 0? 0? 1? 3? 2? 4? 2? 1
dat2$V21
?#[1] NA? 3? 0? 0? 2? 0? 4? 0? 3 NA
(dat2$V2==1|dat2$V2==0) &!is.na(dat2$V2)
# [1] FALSE FALSE? TRUE? TRUE? TRUE FALSE FALSE FALSE FALSE? TRUE
?dat2$V21[(dat2$V2==1|dat2$V2==0) &!is.na(dat2$V2)]
#[1]? 0? 0? 2 NA
mean(dat2$V21[(dat2$V2==1|dat2$V2==0) &!is.na(dat2$V2)],na.rm=TRUE)
#[1] 0.6666667
?(0+0+2)/3
#[1] 0.6666667


If this doesn't solve the problem, please provide a reproducible example using ?dput() 
ex:
dput(head(dataset,20))

A.K.



When I enter that formula I get "NA" or NaN" as an answer. ?I have some 
missing data, which was entered in as NA, so I'm not sure if that is the
 problem. ?Originally I thought I would need to do the entire set of 
equations you posted, but that gave me 3.8 as a mean, which I know is 
too high to be the mean for this data set. 

Thanks 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Friday, July 12, 2013 8:21 AM
Subject: Re: Help with IF command strings

Hi,

Not sure I understand your question.
Suppose `data1` is your real data, but if the column names are different, change "V21", "V2" by those in the real data. Based on your initial post, the column names seemed to be the same.
mean(data1$V21[data1$V2==1|data1$V2==0])

A.K.? 


What values would I substitute by real data. ?I did everything the way 
you posted, and I got 3.8 as well. ?So I'm curious what values I would 
change to get the mean for the actual data? 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Thursday, July 11, 2013 9:21 PM
Subject: Re: Help with IF command strings

HI,
Try this:
set.seed(485)
dat1<- as.data.frame(matrix(sample(0:10,26*10,replace=TRUE),ncol=26))
mean(dat1$V21[dat1$V2==1|dat1$V2==0])
#[1] 3.8
#or
with(dat1,mean(V21[V2==1|V2==0]))
#[1] 3.8


A.K.


I have data in 26 columns, I'm trying to get a mean for column 21 only for the participants that are either 0 or 1 in column 2. 

One of the commands I tried looked something like this 

mean(data1$V21, if(V2 = 1)) ? 

So basically I need to have the program run a mean (and later 
other forms of analysis) on participants based on their condition. 
either 0 or 1. 

Help is greatly appreciated. 

Thanks


From HDoran at air.org  Fri Jul 12 17:59:20 2013
From: HDoran at air.org (Doran, Harold)
Date: Fri, 12 Jul 2013 15:59:20 +0000
Subject: [R] Sparse matrix no longer sparse (Matrix Package)
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C31B761@PA-MBX01.na.tibco.com>
References: <b08b6af0cf8ca44f81b9983eebdcd6862453b3f6@dc1vex10mb001.air.org>
	<b08b6af0cf8ca44f81b9983eebdcd6862453aa2e@dc1vex10mb001.air.org>
	<c1af72363af.0000023djrkrideau@inbox.com>
	<C33A9CA1089.0000041Ajrkrideau@inbox.com>
	<a124906d-c46b-489b-bc76-a754a1b0fc16@email.android.com>
	<B08B6AF0CF8CA44F81B9983EEBDCD6862453BEDE@DC1VEX10MB001.air.org>
	<E66794E69CFDE04D9A70842786030B931C31B761@PA-MBX01.na.tibco.com>
Message-ID: <B08B6AF0CF8CA44F81B9983EEBDCD6862453C089@DC1VEX10MB001.air.org>

It could be done that way, but when you do the part A %*% D it returns an object of class dsCmatrix. What I see happening here, in plain English is as follows:

If you take the inverse of an object of class dsCMatrix, you get in return a matrix of class dgCMatrix. 

But, if you take the inverse of an object of class dgCMatrix, you get in return an object of class dgeMatrix and this is a huge memory hog even though it retains its sparseness and I think should be stored as a sparse matrix of some form. 

Example,

A1 <- as(diag(5, 10), 'dgCMatrix')
A2 <- as(diag(5, 10), 'dsCMatrix')

> object.size(solve(A2))
1640 bytes
> object.size(solve(A1))
1912 bytes




-----Original Message-----
From: William Dunlap [mailto:wdunlap at tibco.com] 
Sent: Friday, July 12, 2013 11:49 AM
To: Doran, Harold
Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)

> ### Create a symmetric matrix of class dsCMatrix A <- diag(5, 10) A[1, 
> 5] <- A[5,1] <- 2

Did you mean the first command to be
   A <- as(diag(5, 10), "dsCMatrix")
?

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Doran, Harold
> Sent: Friday, July 12, 2013 6:24 AM
> To: 'Jeff Newmiller'; John Kane; r-help at r-project.org
> Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
> Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> Here is code to completely replicate the issue with comments. I remain 
> confused why simply changing one element of the ddi matrix to be 
> non-integer changes two things: 1) It changes the class of the object I need (A Inverse) and it increases its memory.
> 
> Ideally, A inverse will remain stored as a sparse matrix no matter 
> what (as it is sparse in my real world problem). When it is converted 
> to a dense object, it blows up in memory and my R program halts.
> 
> library(Matrix)
> 
> ### Create a symmetric matrix of class dsCMatrix A <- diag(5, 10) A[1, 
> 5] <- A[5,1] <- 2
> 
> ### Create a diagonal matrix of class ddi D <- Diagonal(10, 50)
> 
> ### This returns the inverse of A stored as a sparse matrix ### In my 
> real world problem it consumes almost no memory at all ### this is the 
> ideal type A <- A %*%D (aa <- solve(A))
> class(aa)
> object.size(aa)
> 
> ### Now, let's only change one element of D to be non-integer D[1] <- 
> 1.5
> 
> ### Notice here the inverse of the matrix A ### is now stored as a 
> different object class than before ### even though the pattern of 0s 
> and non-zeros remains the same ### It also increases in memory size 
> ### In my real world problem, the matrix increases from ### about .03 
> megabytes to almost 2 megabytes and this causes R to choke and die
> 
> A <- A %*% D
> (aa <- solve(A))
> class(aa)
> object.size(aa)
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Newmiller
> Sent: Thursday, July 11, 2013 3:22 PM
> To: John Kane; r-help at r-project.org
> Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
> Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)
> 
> It seems to me that this issue should be reproducible with a small 
> matrix, since the concern is the representation rather than the values.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                       Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> ----------------------------------------------------------------------
> ----- Sent from my phone. Please excuse my brevity.
> 
> John Kane <jrkrideau at inbox.com> wrote:
> 
> >Just about anything I knew about matrices, I forgot years ago so I'm 
> >no help here but I'd suggest putting the matrix on something like 
> >Mediafire http://www.mediafire.com/ or Dropbox 
> >https://www.dropbox.com so people can download it and have a look.
> >
> >I agree that dput() is not really good for "big" data sets.
> >
> >Kingston ON Canada
> >
> >
> >> -----Original Message-----
> >> From: hdoran at air.org
> >> Sent: Thu, 11 Jul 2013 17:10:54 +0000
> >> To: hdoran at air.org, jrkrideau at inbox.com, r-help at r-project.org
> >> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
> >>
> >> This is a terrible example as I didn't realize my code actually 
> >> does create a non-symmetric matrix and in this case the function 
> >> behaves
> >as
> >> expected. Nonetheless, my original issue stands and that issue 
> >> still
> >does
> >> not make sense.
> >>
> >> Apologies for bad example code.
> >>
> >> -----Original Message-----
> >> From: r-help-bounces at r-project.org
> >[mailto:r-help-bounces at r-project.org]
> >> On Behalf Of Doran, Harold
> >> Sent: Thursday, July 11, 2013 11:36 AM
> >> To: 'John Kane'; r-help at r-project.org
> >> Cc: dmbates at gmail.com; maechler at stat.math.ethz.ch
> >> Subject: Re: [R] Sparse matrix no longer sparse (Matrix Package)
> >>
> >> Thank you, John. I originally used dput() but the output is huge.
> >> However, here is a reproducible example of what I think very
> >unexpected
> >> behavior of some matrix functions.
> >>
> >>> ### Create a symmetric matrix of class dsCMatrix A <- as(diag(5,
> >10),
> >>> 'dsCMatrix') A[1, 5] <- A[5,1] <- 2
> >>>
> >>> ### Create a diagonal matrix of class ddi D <- Diagonal(10, 1)
> >>>
> >>> ### This works as it should
> >>> aa <- Cholesky(A %*% D)
> >>>
> >>> ### Now, let's only change one element of D to be non-integer D[1]
> ><-
> >>> 1.5
> >>>
> >>> ### AD is still symmetric, but here the Cholesky function 
> >>> complains that it is not aa <- Cholesky(A %*% D)
> >> Error in Cholesky(as(A, "symmetricMatrix"), perm = perm, LDL = LDL,
> >super
> >> = super,  :
> >>   error in evaluating the argument 'A' in selecting a method for
> >function
> >> 'Cholesky': Error in asMethod(object) :
> >>   not a symmetric matrix; consider forceSymmetric() or symmpart()
> >>
> >> ### For fun try this
> >>
> >>> L <- update(aa, as(A %*% D, 'symmetricMatrix'))
> >> Error in asMethod(object) :
> >>   not a symmetric matrix; consider forceSymmetric() or symmpart()
> >>
> >> ### This does indeed work, but should I need to implement this step?
> >>
> >> Cholesky(forceSymmetric(A %*% D))
> >>
> >> So, there is something about changing the elements of a ddi matrix
> >that
> >> causes subsequent problems. Is there a good reason this occurs and 
> >> something I should be doing differently, or is this a bug?
> >>
> >> Thanks
> >>
> >> -----Original Message-----
> >> From: John Kane [mailto:jrkrideau at inbox.com]
> >> Sent: Thursday, July 11, 2013 10:57 AM
> >> To: Doran, Harold; r-help at r-project.org
> >> Subject: RE: [R] Sparse matrix no longer sparse (Matrix Package)
> >>
> >> The message got through but not the attachment. The R help list 
> >> tends
> >to
> >> strip off attachements for security reasons.  Files of types  txt,
> >png, &
> >> pdf should get through.
> >>
> >> In most cases the accepted method of sending data is to use the
> >dput()
> >> function to output a file in the console and then copy and paste 
> >> the results into your email.
> >>
> >> So for file "dat1" one would just use dput(dat1) and paste the
> >results
> >> into an email.
> >>
> >> John Kane
> >> Kingston ON Canada
> >>
> >>
> >>> -----Original Message-----
> >>> From: hdoran at air.org
> >>> Sent: Thu, 11 Jul 2013 09:53:40 +0000
> >>> To: r-help at r-project.org
> >>> Subject: [R] Sparse matrix no longer sparse (Matrix Package)
> >>>
> >>> I sent this message yesterday with an attachment allowing for 
> >>> reproduction of the issue. But I think the attachment is 
> >>> preventing the message from coming through. If anyone is 
> >>> interested I will forward the attachment directly allowing for you 
> >>> to reproduce the issue I observe.
> >>>
> >>> On 7/10/13 2:38 PM, "Doran, Harold" <HDoran at air.org> wrote:
> >>>
> >>> >I have zero'd in on what appears to be the issue. This seems to 
> >>> >be
> >a
> >>> >bug in Matrix, but I am not sure yet. I am attaching files that
> >would
> >>> >allow others to replicate this with my toy data.
> >>>>
> >>> >Notice the elements of D1 in the attached data are all integers. 
> >>> >It is a sparse, diagonal matrix.
> >>>>
> >>>>> library(Matrix)
> >>>>> class(D1)
> >>> >[1] "ddiMatrix"
> >>> >attr(,"package")
> >>> >[1] "Matrix"
> >>>>
> >>> >Now, I find the inverse of the matrix A as follows:
> >>>>> A <- Ir + ZtZ %*% D1
> >>>>> A.Inv <- solve(A, Ir)
> >>>>
> >>> >Notice now the inverse of A remains a dgCMatrix and it is
> >relatively
> >>> >small in size, only 33424 bytes.
> >>>>> class(A.Inv)
> >>> >[1] "dgCMatrix"
> >>> >attr(,"package")
> >>> >[1] "Matrix"
> >>>>
> >>>>> object.size(A.Inv)
> >>> >33424 bytes
> >>>>
> >>> >Now, if I change an element of the matrix D1 to be non-integer, 
> >>> >D1 still has the same class as it did before
> >>>>
> >>>>> D1[1] <- 1.2
> >>>>
> >>>>> class(D1)
> >>> >[1] "ddiMatrix"
> >>> >attr(,"package")
> >>> >[1] "Matrix"
> >>>>
> >>> >Now, if I use this new version of D1 in the same calculations as 
> >>> >above, notice that A.Inv is no longer a dgCMatrix but instead
> >becomes
> >>> >a dgeMatrix. It then increases from an object of size 33424 bytes
> >to
> >>> >an object of size 2001112 bytes!
> >>>>
> >>>>> A <- Ir + ZtZ %*% D1
> >>>>> A.Inv <- solve(A, Ir)
> >>>>> class(A.Inv)
> >>> >[1] "dgeMatrix"
> >>> >attr(,"package")
> >>> >[1] "Matrix"
> >>>>> object.size(A.Inv)
> >>> >2001112 bytes
> >>>>
> >>> >What I desire is that the object A.Inv remain sparse at all times
> >and
> >>> not
> >>> >become dense. But, perhaps there is a reason this change occurs
> >that
> >>> >I don't fully understand.
> >>>>
> >>> >I can of course coerce it back to a sparse matrix and it reduces
> >back
> >>> >in size.
> >>>>>  object.size(as(A.Inv, 'sparseMatrix'))
> >>> >33424 bytes
> >>>>
> >>> >I of course recognize it requires more memory to store floating 
> >>> >points than integers, but is this large increase on the order of 
> >>> >magnitude that seems about right?
> >>>>
> >>> >Is there a reason the floating point in D1 causes for A.Inv to no 
> >>> >longer remain sparse?
> >>>>
> >>> >Thank you for your help,
> >>> >Harold
> >>>>
> >>>>
> >>>>
> >>>>
> >>>>
> >>> >-----Original Message-----
> >>> >From: r-help-bounces at r-project.org 
> >>> >[mailto:r-help-bounces at r-project.org]
> >>> >On Behalf Of Doran, Harold
> >>> >Sent: Wednesday, July 10, 2013 11:42 AM
> >>> >To: r-help at r-project.org
> >>> >Cc: dmbates at gmail.com; 'maechler at stat.math.ethz.ch'
> >>> >Subject: [R] Sparse matrix no longer sparse (Matrix Package)
> >>>>
> >>> >I have a large function computing an iterative algorithm for
> >fitting
> >>> >mixed linear models. Almost all code relies on functions from the 
> >>> >Matrix package. I've come across an issue that I do not believe 
> >>> >previously occurred in earlier versions of R or Matrix.
> >>>>
> >>> >I have a large, sparse matrix, A as
> >>>>
> >>>>> class(A);dim(A)
> >>> >[1] "dgCMatrix"
> >>> >attr(,"package")
> >>> >[1] "Matrix"
> >>> >[1] 12312 12312
> >>>>
> >>> >I am in a position where I must find its inverse.  I realize this
> >is
> >>> less
> >>> >than ideal, and I have two ways of doing this
> >>>>
> >>> >A.Inv <- solve(A, Ir) or just solve(A)
> >>>>
> >>> >Where Ir is an identity matrix with the same dimensions as A and 
> >>> >it is also sparse
> >>>>
> >>>>> class(Ir)
> >>> >[1] "ddiMatrix"
> >>> >attr(,"package")
> >>> >[1] "Matrix"
> >>>>
> >>> >The issue, however, is that the inverse of A is converted into a 
> >>> >dense matrix and this becomes a huge memory hog, causing the rest
> >of
> >>> >the algorithm to fail. In prior versions this remained as a 
> >>> >sparse
> >>> matrix.
> >>>>
> >>>>> A.Inv[1:5, 1:5]
> >>> >5 x 5 Matrix of class "dgeMatrix"
> >>>>          [,1]      [,2]      [,3]      [,4]      [,5]
> >>> >[1,] 0.6878713 0.0000000 0.0000000 0.0000000 0.0000000 [2,]
> >0.0000000
> >>> >0.6718767 0.0000000 0.0000000 0.0000000 [3,] 0.0000000 0.0000000
> >>> >0.5076945 0.0000000 0.0000000 [4,] 0.0000000 0.0000000 0.0000000
> >>> >0.2324122 0.0000000 [5,] 0.0000000 0.0000000 0.0000000 0.0000000
> >>> 0.2139975
> >>>>
> >>> >I could coerce this matrix to become sparse such as
> >>>>
> >>>>> AA <- as(A.Inv, 'sparseMatrix')
> >>>>> class(AA)
> >>> >[1] "dgCMatrix"
> >>> >attr(,"package")
> >>> >[1] "Matrix"
> >>>>
> >>>>> AA[1:5, 1:5]
> >>> >5 x 5 sparse Matrix of class "dgCMatrix"
> >>>>
> >>> >[1,] 0.6878713 .         .         .         .
> >>> >[2,] .         0.6718767 .         .         .
> >>> >[3,] .         .         0.5076945 .         .
> >>> >[4,] .         .         .         0.2324122 .
> >>> >[5,] .         .         .         .         0.2139975
> >>>>
> >>> >But I don't think this is best.
> >>>>
> >>> >So, my question is why is a matrix that is sparse turning into a 
> >>> >dense matrix? Can I avoid that and keep it sparse without having 
> >>> >to coerce it to be sparse after it is created?
> >>>>
> >>> >Thank you very much
> >>> >Harold
> >>>>
> >>>>
> >>>>> sessionInfo()
> >>> >R version 3.0.1 (2013-05-16)
> >>> >Platform: x86_64-w64-mingw32/x64 (64-bit)
> >>>>
> >>> >locale:
> >>> >[1] LC_COLLATE=English_United States.1252  
> >>> >LC_CTYPE=English_United
> >>> >States.1252 [3] LC_MONETARY=English_United States.1252 
> >>> >LC_NUMERIC=C [5] LC_TIME=English_United States.1252
> >>>>
> >>> >attached base packages:
> >>> >[1] stats     graphics  grDevices utils     datasets  methods
> >base
> >>>>
> >>> >other attached packages:
> >>> >[1] lme4_0.999999-2 Matrix_1.0-12   lattice_0.20-15
> >>>>
> >>> >loaded via a namespace (and not attached):
> >>> >[1] grid_3.0.1   nlme_3.1-109 stats4_3.0.1 tools_3.0.1
> >>>>
> >>> >	[[alternative HTML version deleted]]
> >>>>
> >>> >______________________________________________
> >>> >R-help at r-project.org mailing list 
> >>> >https://stat.ethz.ch/mailman/listinfo/r-help
> >>> >PLEASE do read the posting guide
> >>> >http://www.R-project.org/posting-guide.html
> >>> >and provide commented, minimal, self-contained, reproducible code.
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> >> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> >____________________________________________________________
> >GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at 
> >http://www.inbox.com/smileys Works with AIM?, MSN? Messenger, Yahoo!? 
> >Messenger, ICQ?, Google Talk? and most webmails
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

From dwinsemius at comcast.net  Fri Jul 12 18:02:56 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Jul 2013 09:02:56 -0700
Subject: [R] error of betadiver in vegan
In-Reply-To: <CAGJhoDyMK=uYjmgNEHsBGLvvUcCcR1BHFpajzx61gzf8L10xVw@mail.gmail.com>
References: <CAGJhoDwusVFqBXZuSNuMZpTWiq3+=5hGMwWeJbtFJSdTyQchiQ@mail.gmail.com>
	<loom.20130712T081014-325@post.gmane.org>
	<CAGJhoDyMK=uYjmgNEHsBGLvvUcCcR1BHFpajzx61gzf8L10xVw@mail.gmail.com>
Message-ID: <1461CD29-7D91-4DF2-9026-2F3540349337@comcast.net>


On Jul 12, 2013, at 1:47 AM, Elaine Kuo wrote:

> Hello,
> 
> Thanks for Jari's comment.
> It worked well after correction.
> However, an error jumped out for the code below.
> "Error: cannot allocate vector of size 90.6 Mb"
> 
> Please kindly advise how to modify it.

Elaine;

This problem has literally been addressed hundreds of times on R-help:

http://markmail.org/search/?q=list%3Aorg.r-project.r-help+%22Error%3A+cannot+allocate+vector+of+size%22

And it's either been asked or answered 54 times on StackOverflow:

http://stackoverflow.com/search?q=[r]+%22Error%3A+cannot+allocate+vector+of+size%22

Th lack of contiguous RAM is small enought that the problem should be manageable after reading a few of the solutions offered.

-- 
David.


> Thank you.
> 
> Elaine
> 
> Code
> # Non-Passerine table
> dataNP_1 <-read.dbf("H:/temp_D/stage_4_R_2748/NP_1-10.dbf", as.is = FALSE)
> dataNP_2 <-read.dbf("H:/temp_D/stage_4_R_2748/NP_11-19.dbf", as.is = FALSE)
> dataNP<-merge(dataNP_1,dataNP_2,by=c("GID"),all=T)
> 
> .. skip...
> 
> # Non-Passerine and Passerine table (2748 species)
> dataR<-merge(dataP,dataNP,by=c("GID"),all=T)
> dim(dataR)
> str(dataR)
> 
> library(vegan)
> 
>  ##  The  beta sim  index (Lennon 2001)
>  d  <-  betadiver(dataR,  "sim")
> 
> 
> On Fri, Jul 12, 2013 at 2:13 PM, Jari Oksanen <jari.oksanen at oulu.fi> wrote:
> 
>> Elaine Kuo <elaine.kuo.tw <at> gmail.com> writes:
>> 
>>> 
>>> Hello,
>>> 
>>> I am using betadiver (vegan) to calculate beta diversity.
>>> However, an error message shows
>>> 
>>> Error in ifelse(x > 0, 1, 0) :
>>>  (list) object cannot be coerced to type 'double'
>> ...snip...
>> 
>>>  ##  Raw  data
>>>  R  <-  betadiver(dataR)
>>> 
>>>  ##  The  indices
>>>  betadiver(help=TRUE)
>>> 
>>>  ##  The  beta sim  index (Lennon 2001)
>>>  d  <-  betadiver(R,  "sim")
>>> 
>> Elaine,
>> 
>> Look carefully what you do here: betadiver needs data as input -- not beta
>> diversities. Your last command is equal to this oneliner:
>> 
>> d <- betadiver(betadiver(dataR), "sim")
>> 
>> This is guaranteed to fail. Use instead
>> 
>> d <- betadiver(dataR, "sim")
>> 
>> Cheers, Jari Oksanen
-- 

David Winsemius
Alameda, CA, USA


From amen.alyaari at Bordeaux.inra.fr  Fri Jul 12 16:06:25 2013
From: amen.alyaari at Bordeaux.inra.fr (Jonsson)
Date: Fri, 12 Jul 2013 07:06:25 -0700 (PDT)
Subject: [R] What is the maximum limit for an array?
In-Reply-To: <loom.20130712T154056-229@post.gmane.org>
References: <1373626924487-4671395.post@n4.nabble.com>
	<loom.20130712T154056-229@post.gmane.org>
Message-ID: <1373637985600-4671409.post@n4.nabble.com>

So If download R 3,my problem will be gone?



--
View this message in context: http://r.789695.n4.nabble.com/What-is-the-maximum-limit-for-an-array-tp4671395p4671409.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Jul 12 18:21:14 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Jul 2013 09:21:14 -0700
Subject: [R] What is the maximum limit for an array?
In-Reply-To: <loom.20130712T154056-229@post.gmane.org>
References: <1373626924487-4671395.post@n4.nabble.com>
	<loom.20130712T154056-229@post.gmane.org>
Message-ID: <9F7FB7AF-F016-4ED1-B07D-19EE14FCFD16@comcast.net>


On Jul 12, 2013, at 6:42 AM, Ben Bolker wrote:

> Jonsson <amen.alyaari <at> Bordeaux.inra.fr> writes:
> 
>> 
>> Hello All,
>> I am having a problem with this:
>> 
>> file<-array(dim=c(1440,720,700,3))
>>      Error in array(dim = c(1440, 720, 700, 3)) : 
>>       'dim' specifies too large an array
>> 
>> I have a memory of 20GB, But I do not know where is the problem!Any help
>> 
>> When I replaced 700 by any number bellow like( 600,500),it worked without
>> any problem.
> 
> From
> 
> http://stat.ethz.ch/R-manual/R-devel/library/base/html/LongVectors.html :
> 
> Prior to R 3.0.0, all vectors in R were restricted to at most 2^31 - 1 
> 
>> 1440*720*700*3
> [1] 2177280000
>> 2^31-1
> [1] 2147483647
> 
>  So you need R>=3.0.0 (on a 64-bit system).

And (unfortunately) perhaps three times the currently installed RAM will be needed for productive use of such an R data-object. The memory requirements of a numeric array are roughly 10 times the product of the dimensions:

10*prod( c(1440,720,700,3))
#[1] 21772800000     
#     G  M  K

So the hardware limitations are now a constraint. I am a bit surprised that object with those lower dimensions could be handled "without any problem." Generally an object of dim =c(1440,720,700,3) will not be able to be productively used for anything except read access. Copying it or even assigning new values to it, which of necessity creates a copy,  would generally overflow installed RAM and push your session into "virtual memory" at which point my system starts to display molasses-like behavior. Occassionally waiting on the order of 5-20 minutes allows the process to complete, but in many instances terminating the session is needed.

-- 
David Winsemius
Alameda, CA, USA


From armel.kaptue at sdstate.edu  Fri Jul 12 18:39:58 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Fri, 12 Jul 2013 16:39:58 +0000
Subject: [R] How to determine the pdf of a gamma distribution using the
 estimated parameters?
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FD2BB9@sdsu-ex01.jacks.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/49d7925a/attachment.pl>

From bbolker at gmail.com  Fri Jul 12 18:57:56 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Jul 2013 16:57:56 +0000
Subject: [R] How to determine the pdf of a gamma distribution using the
	estimated parameters?
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FD2BB9@sdsu-ex01.jacks.local>
Message-ID: <loom.20130712T185630-723@post.gmane.org>

Kaptue Tchuente, Armel <armel.kaptue <at> sdstate.edu> writes:

> 

[snip]

> With th bar histogram (number of occurrences)
>  hist<-c(24,7,4,1,2,1,1) of seven equally spaces classes
> ]1-4], ]5-8], ]9-12], ]13-16], ]17-20], ]21-24], ]25-28], 
> I obtained shape=0.8276 and rate=0.1448.
> 
> I would like to know how to build the continuous pdf of a this
> gamma distribution knowing these two estimated
> parameters such that I will be able to predict the pdf of any
> positive value.

  Are you talking about dgamma(x,shape=0.8276,rate=0.1448),
where x is the value you are trying to predict for?  dgamma gives
probability density, pgamma gives cumulative density/distribution
function.


From cxg040 at email.uark.edu  Fri Jul 12 18:58:33 2013
From: cxg040 at email.uark.edu (Chirag Gupta)
Date: Fri, 12 Jul 2013 11:58:33 -0500
Subject: [R] Upgrade from R 2.11 to R 3.0.1
Message-ID: <CADESCNwCom3+Z_muTuysUk2CJ4UmHSs=5ex05FUFhz5HLFAvcA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/bb3cd9ed/attachment.pl>

From stubben at lanl.gov  Fri Jul 12 19:01:29 2013
From: stubben at lanl.gov (Chris Stubben)
Date: Fri, 12 Jul 2013 11:01:29 -0600
Subject: [R] [XML packages] how to get the sub-node according to the
 sub-node's attribute?
In-Reply-To: <6c3f7c98.10535.13fd089449d.Coremail.xhl860728@163.com>
References: <6c3f7c98.10535.13fd089449d.Coremail.xhl860728@163.com>
Message-ID: <51E03669.907@lanl.gov>

>My question is:
>Is there a function that can get the sub-node according to the sub-node's attribute ?
>like that,in the mtcar.xml ,there is sub-node as follow:
><record id="Lotus Europa">        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2</record>
>I want to get the specific sub-node according to the attribute "id="Lotus Europa".
>Is there a simple function in the xml package?


Just use xpathSApply with brackets to specify the specific id...

 doc <- xmlParse(system.file("exampleData", "mtcars.xml", package="XML"))

xpathSApply(doc, "//record[@id='Lotus Europa']", xmlValue)
[1] "        30.4   4  95.1 113 3.77 1.513 16.90  1  1    5    2"

#OR?
xpathSApply(doc, "//record[@id='Lotus Europa']")
getNodeSet(doc, "//record[@id='Lotus Europa']")

# And to list all Ids...

xpathSApply(doc, "//record", xmlGetAttr, "id")
 [1] "Mazda RX4"           "Mazda RX4 Wag"       "Datsun 710"   .....   

-- 

Chris Stubben

Los Alamos National Lab
Bioscience Division
MS M888
Los Alamos, NM 87545


From l.roca at gmx.us  Fri Jul 12 19:10:27 2013
From: l.roca at gmx.us (Lluis)
Date: Fri, 12 Jul 2013 10:10:27 -0700 (PDT)
Subject: [R] LDA and confidence ellipse
In-Reply-To: <1373570406.56520.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1373536460259-4671308.post@n4.nabble.com>
	<1373567119.48817.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<1373570153514-4671357.post@n4.nabble.com>
	<1373570406.56520.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1373649027156-4671427.post@n4.nabble.com>

Thanks again



--
View this message in context: http://r.789695.n4.nabble.com/LDA-and-confidence-ellipse-tp4671308p4671427.html
Sent from the R help mailing list archive at Nabble.com.


From marc_schwartz at me.com  Fri Jul 12 19:12:43 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 12 Jul 2013 12:12:43 -0500
Subject: [R] Upgrade from R 2.11 to R 3.0.1
In-Reply-To: <CADESCNwCom3+Z_muTuysUk2CJ4UmHSs=5ex05FUFhz5HLFAvcA@mail.gmail.com>
References: <CADESCNwCom3+Z_muTuysUk2CJ4UmHSs=5ex05FUFhz5HLFAvcA@mail.gmail.com>
Message-ID: <9E679450-D02A-46F1-9741-269D6D67BA2F@me.com>

On Jul 12, 2013, at 11:58 AM, Chirag Gupta <cxg040 at email.uark.edu> wrote:

> Hi
> 
> I am trying to upgrade R version 2.11 to 3.0.1 on Linux server.
> I downloaded the latest version it installed correctly. Now when I run R
> and check the version, it still shows an older version.
> I am new to Linux. If anyone can tell me how to remove/uninstall R
> completely from the server, I can try and re-install the newer version and
> try.
> 
> Thanks.


What Linux server? RHEL?

Do you have root access to the server?

How did you download and install R? Did you download and install a binary RPM locally, install a binary using a package manager like yum or did you download the source tarball, compile and install?

Need more information.

Regards,

Marc Schwartz


From bbolker at gmail.com  Fri Jul 12 19:14:20 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Jul 2013 17:14:20 +0000
Subject: [R] What is the maximum limit for an array?
References: <1373626924487-4671395.post@n4.nabble.com>
	<loom.20130712T154056-229@post.gmane.org>
	<1373637985600-4671409.post@n4.nabble.com>
Message-ID: <loom.20130712T191336-381@post.gmane.org>

Jonsson <amen.alyaari <at> Bordeaux.inra.fr> writes:

> 
> So If download R 3,my problem will be gone?

  If you also install it :-)  and if you have a 64-bit OS and if
you have enough memory to handle the resulting object (see David
Winsemius's response).


From canamika at gmail.com  Fri Jul 12 19:34:47 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Fri, 12 Jul 2013 13:34:47 -0400
Subject: [R] How to find the probability of falling in a bivariate ellipse
Message-ID: <CALv--dadZGrud5RnNfxkHE93Gd8TB+r7Z=iu3jnjEWwuEqUACQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/938582cb/attachment.pl>

From ravi.varadhan at jhu.edu  Fri Jul 12 18:04:33 2013
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Fri, 12 Jul 2013 16:04:33 +0000
Subject: [R] While using R CMD check: LaTex error: File `inconsolata.sty'
 not found
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/933aa4d3/attachment.pl>

From armel.kaptue at sdstate.edu  Fri Jul 12 19:38:33 2013
From: armel.kaptue at sdstate.edu (Kaptue Tchuente, Armel)
Date: Fri, 12 Jul 2013 17:38:33 +0000
Subject: [R] How to determine the pdf of a gamma distribution using the
 estimated parameters?
Message-ID: <9879AF1F439EF943BDEE22D3AAA5C3F683FD2D2D@sdsu-ex01.jacks.local>

Sorry not to be more precise in my previous message.
My question is how to use dgamma with the obtained shape and scale parameters in order to approximate the observed pdf since the results of dgamma (seq(4,28,4), shape,rate) are very different from the observed pdf [pdf obs_pdf<-c(0.600, 0.175, 0.100, 0.025, 0.050, 0.025, 0.025)]?
Armel

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
Sent: Friday, July 12, 2013 11:58 AM
To: r-help at stat.math.ethz.ch
Subject: Re: [R] How to determine the pdf of a gamma distribution using the estimated parameters?

Kaptue Tchuente, Armel <armel.kaptue <at> sdstate.edu> writes:

> 

[snip]

> With th bar histogram (number of occurrences)
>  hist<-c(24,7,4,1,2,1,1) of seven equally spaces classes ]1-4], ]5-8], 
> ]9-12], ]13-16], ]17-20], ]21-24], ]25-28], I obtained shape=0.8276 
> and rate=0.1448.
> 
> I would like to know how to build the continuous pdf of a this gamma 
> distribution knowing these two estimated parameters such that I will 
> be able to predict the pdf of any positive value.

  Are you talking about dgamma(x,shape=0.8276,rate=0.1448),
where x is the value you are trying to predict for?  dgamma gives probability density, pgamma gives cumulative density/distribution function.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Fri Jul 12 19:45:18 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Fri, 12 Jul 2013 13:45:18 -0400
Subject: [R] How to determine the pdf of a gamma distribution using the
 estimated parameters?
In-Reply-To: <9879AF1F439EF943BDEE22D3AAA5C3F683FD2D2D@sdsu-ex01.jacks.local>
References: <9879AF1F439EF943BDEE22D3AAA5C3F683FD2D2D@sdsu-ex01.jacks.local>
Message-ID: <51E040AE.5060700@gmail.com>

On 13-07-12 01:38 PM, Kaptue Tchuente, Armel wrote:

> Sorry not to be more precise in my previous message.

> My question is how to use dgamma with the obtained shape and scale
  parameters in order to approximate the observed pdf since the
  results of dgamma (seq(4,28,4), shape,rate) are very different from
  the observed pdf [pdf obs_pdf<-c(0.600, 0.175, 0.100, 0.025, 0.050,
  0.025, 0.025)]?

You need to compute the integral of the relevant sections of the
CDF.  What I've done here is not exactly the same as your classes
((1-4),(5-8),(9-12),...), you'll need to sort that out (what happens
to values between 4 and 5?  If your data are discrete, then the
Gamma distribution isn't a perfect match -- it might be a reasonable
approximation, but you'll have to figure out for yourself how
you want to make the correspondence between your discrete data
and a continuous distribution ... maybe your ranges should be (0.5-4.5),
(4.5-8.5), ... ?)

This looks _reasonably_ close ...
obs_pdf<-c(0.600, 0.175, 0.100, 0.025, 0.050, 0.025, 0.025)
pred_pdf <- diff(pgamma(seq(0,28,4),shape=0.8276,rate=0.1448))
plot(obs_pdf,pred_pdf)
abline(a=0,b=1)

> Armel
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ben Bolker
> Sent: Friday, July 12, 2013 11:58 AM
> To: r-help at stat.math.ethz.ch
> Subject: Re: [R] How to determine the pdf of a gamma distribution using the estimated parameters?
> 
> Kaptue Tchuente, Armel <armel.kaptue <at> sdstate.edu> writes:
> 
>>
> 
> [snip]
> 
>> With th bar histogram (number of occurrences)
>>  hist<-c(24,7,4,1,2,1,1) of seven equally spaces classes ]1-4], ]5-8], 
>> ]9-12], ]13-16], ]17-20], ]21-24], ]25-28], I obtained shape=0.8276 
>> and rate=0.1448.
>>
>> I would like to know how to build the continuous pdf of a this gamma 
>> distribution knowing these two estimated parameters such that I will 
>> be able to predict the pdf of any positive value.
> 
>   Are you talking about dgamma(x,shape=0.8276,rate=0.1448),
> where x is the value you are trying to predict for?  dgamma gives probability density, pgamma gives cumulative density/distribution function.
>


From bhh at xs4all.nl  Fri Jul 12 19:49:05 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 12 Jul 2013 19:49:05 +0200
Subject: [R] While using R CMD check: LaTex error: File
	`inconsolata.sty' not found
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
Message-ID: <12F955D2-CF20-4C32-9AB4-AA1A32093EE9@xs4all.nl>


On 12-07-2013, at 18:04, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:

> Hi,
> While using R CMD check I get the following Latex error message which occurs when creating PDF version of manual:
> LaTex error:  File `inconsolata.sty' not found
> I am using Windows 7 (64-bit) and R 3.0.1.  I have MikTex 2.9.
> I see that the incosolata.sty is present under \doc\fonts folder.  How can I eliminate this problem?

See http://r.789695.n4.nabble.com/inconsolata-sty-is-liable-to-disappear-texinfo-5-1-td4669976.html

Get R-patched.

Berend


From dwinsemius at comcast.net  Fri Jul 12 19:56:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Jul 2013 10:56:55 -0700
Subject: [R] While using R CMD check: LaTex error: File
	`inconsolata.sty' not found
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
Message-ID: <53C9AF5E-05A0-4054-8BE2-61D3F75C4FC4@comcast.net>


On Jul 12, 2013, at 9:04 AM, Ravi Varadhan wrote:

> Hi,
> While using R CMD check I get the following Latex error message which occurs when creating PDF version of manual:
> LaTex error:  File `inconsolata.sty' not found
> I am using Windows 7 (64-bit) and R 3.0.1.  I have MikTex 2.9.
> I see that the incosolata.sty is present under \doc\fonts folder.  How can I eliminate this problem?

I seem to remember that this was described in a posting in the last month ortwo on r-devel and that  workaround or two were described:

http://markmail.org/search/?q=list%3Aorg.r-project.r-devel+inconsolata.sty

-- 


David Winsemius
Alameda, CA, USA


From bhh at xs4all.nl  Fri Jul 12 20:02:58 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 12 Jul 2013 20:02:58 +0200
Subject: [R] While using R CMD check: LaTex error: File
	`inconsolata.sty' not found
In-Reply-To: <12F955D2-CF20-4C32-9AB4-AA1A32093EE9@xs4all.nl>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
	<12F955D2-CF20-4C32-9AB4-AA1A32093EE9@xs4all.nl>
Message-ID: <0E3C1A81-531A-4CF4-AAA8-736971721C28@xs4all.nl>



On 12-07-2013, at 19:49, Berend Hasselman <bhh at xs4all.nl> wrote:

> 
> On 12-07-2013, at 18:04, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:
> 
>> Hi,
>> While using R CMD check I get the following Latex error message which occurs when creating PDF version of manual:
>> LaTex error:  File `inconsolata.sty' not found
>> I am using Windows 7 (64-bit) and R 3.0.1.  I have MikTex 2.9.
>> I see that the incosolata.sty is present under \doc\fonts folder.  How can I eliminate this problem?
> 

MiKTeX search path corrupted? Filename databse problem?

> See http://r.789695.n4.nabble.com/inconsolata-sty-is-liable-to-disappear-texinfo-5-1-td4669976.html
> 
> Get R-patched.
> 

Other option:

Try another MiKTeX update.

I've just had a look at what TeX Live Utility would want to update in MacTeX 2013 and it appears that inconsolata is back.
And it's also on CTAN: http://www.ctan.org/pkg/inconsolata (dated 2013-07-03).

Berend

> Berend
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bhh at xs4all.nl  Fri Jul 12 20:30:01 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 12 Jul 2013 20:30:01 +0200
Subject: [R] While using R CMD check: LaTex error: File
	`inconsolata.sty' not found
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
References: <2F9EA67EF9AE1C48A147CB41BE2E15C3480E41@DOM-EB-MAIL1.win.ad.jhu.edu>
Message-ID: <E7DFBFF7-0037-41FE-B864-FF41563D7E05@xs4all.nl>


On 12-07-2013, at 18:04, Ravi Varadhan <ravi.varadhan at jhu.edu> wrote:

> Hi,
> While using R CMD check I get the following Latex error message which occurs when creating PDF version of manual:
> LaTex error:  File `inconsolata.sty' not found
> I am using Windows 7 (64-bit) and R 3.0.1.  I have MikTex 2.9.
> I see that the incosolata.sty is present under \doc\fonts folder.  How can I eliminate this problem?

I've just now updated MacTeX 2013.

After the update kpsewhich inconsolata.sty gives:

/usr/local/texlive/2013/texmf-dist/tex/latex/inconsolata/inconsolata.sty

and  kpsewhich zi4.sty gives

/usr/local/texlive/2013/texmf-dist/tex/latex/inconsolata/zi4.sty

These are essentially identical.

In the package itself there is no tex/inconsolata.sty
The README of the inconsolata package tells you what you could do with doc/fonts/inconsolata.sty

See http://www.ctan.org/tex-archive/fonts/inconsolata

It appears that the MacTeX update has automatically taken care of the inconsolata.sty and zi4.sty issue.

Berend


From michel.arnaud at cirad.fr  Fri Jul 12 21:45:06 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Fri, 12 Jul 2013 21:45:06 +0200
Subject: [R] simplify a dataframe
Message-ID: <51E05CC2.3020202@cirad.fr>

Hello

I have the following problem : group the lines of a dataframe when no 
information change (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays) 
and when the value of Debut of lines i = value Fin of lines i-1
I can obtain it with a do loop. Is it possible to avoid the loop ?

The dataframe initial is df1
dput(df1)
structure(list(Matricule = c(1L, 1L, 1L, 6L, 6L, 6L, 6L, 6L,
6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L), Nom = c("VERON", "VERON", "VERON", "BENARD",
"BENARD", "BENARD", "BENARD", "BENARD", "BENARD", "DALNIC", "DALNIC",
"DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI"), Sexe = c("F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin"), DateNaissance = c("02/09/1935",
"02/09/1935", "02/09/1935", "01/04/1935", "01/04/1935", "01/04/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961"), contrat = c("CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun"), Pays = c("France", "France", "France", "Philippines",
"Philippines", "Philippines", "France", "France", "France", "France",
"France", "Martinique", "Martinique", "Martinique", "Martinique",
"Martinique", "Martinique", "Martinique", "Cameroun", "Cameroun",
"Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun",
"Cameroun", "France", "France", "France", "France", "France",
"France", "France", "Congo", "Congo", "Congo", "Congo", "Congo",
"Congo", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon",
"Congo", "Congo"), Debut = c("24/01/1995", "01/05/1997", "31/12/1997",
"02/02/1995", "28/02/1995", "01/03/1995", "13/03/1995", "01/01/1996",
"31/01/1996", "24/01/1995", "01/07/1995", "01/09/1995", "01/07/1997",
"01/01/1998", "01/08/1998", "01/01/2000", "17/01/2000", "29/02/2000",
"26/01/1995", "01/07/1996", "16/09/1997", "01/01/1998", "01/07/1998",
"04/11/1999", "01/01/2001", "01/04/2001", "31/08/2001", "01/09/2001",
"02/09/2001", "01/12/2001", "01/02/2003", "01/04/2003", "01/01/2004",
"01/03/2004", "01/09/2004", "01/01/2005", "01/04/2005", "28/10/2006",
"01/01/2007", "01/04/2007", "01/09/2007", "01/01/2009", "01/04/2009",
"01/01/2010", "01/01/2011", "01/04/2011", "05/09/2012", "01/01/2013"
), Fin = c("30/04/1997", "30/12/1997", "31/12/1997", "27/02/1995",
"28/02/1995", "12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996",
"30/06/1995", "31/08/1995", "30/06/1997", "31/12/1997", "31/07/1998",
"31/12/1999", "16/01/2000", "28/02/2000", "29/02/2000", "30/06/1996",
"15/09/1997", "31/12/1997", "30/06/1998", "03/11/1999", "31/12/2000",
"31/03/2001", "30/08/2001", "31/08/2001", "01/09/2001", "30/11/2001",
"31/01/2003", "31/03/2003", "31/12/2003", "29/02/2004", "31/08/2004",
"31/12/2004", "31/03/2005", "27/10/2006", "31/12/2006", "31/03/2007",
"31/08/2007", "31/12/2008", "31/03/2009", "31/12/2009", "31/12/2010",
"31/03/2011", "04/09/2012", "31/12/2012", "31/12/4712")), .Names = 
c("Matricule",
"Nom", "Sexe", "DateNaissance", "contrat", "Pays", "Debut", "Fin"
), class = "data.frame", row.names = c(NA, -48L))

The dataframe to be obtained is df2
dput(df2)
structure(list(Mat = c(1L, 6L, 6L, 6L, 8L, 8L, 934L, 934L, 934L,
934L, 934L), Nom = c("VERON", "BENARD", "BENARD", "BENARD", "DALNIC",
"DALNIC", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI"), Sexe = c("F?minin",
"Masculin", "Masculin", "Masculin", "F?minin", "F?minin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin"), DateNaissance = 
c("02/09/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961"
), contrat = c("CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDD d?tach? ext. Cirad", "CDI D?tach?s 
Autres",
"CDI D?tach?s Autres", "CDI commun", "CDI commun"), Pays = c("France",
"Philippines", "France", "France", "France", "Martinique", "Cameroun",
"France", "Congo", "Gabon", "Congo"), Debut = c("24/01/1995",
"02/02/1995", "13/03/1995", "01/01/1996", "24/01/1995", "01/09/1995",
"26/01/1995", "01/09/2001", "01/09/2004", "01/09/2007", "05/09/2012"
), Fin = c("31/12/1997", "12/03/1995", "30/06/1995", "31/01/1996",
"31/08/1995", "29/02/2000", "31/08/2001", "31/08/2004", "31/08/2007",
"04/09/2012", "31/12/4712")), .Names = c("Mat", "Nom", "Sexe",
"DateNaissance", "contrat", "Pays", "Debut", "Fin"), class = 
"data.frame", row.names = c(NA,
-11L))

Thank you for your help

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From marc_schwartz at me.com  Fri Jul 12 21:51:42 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 12 Jul 2013 14:51:42 -0500
Subject: [R] Upgrade from R 2.11 to R 3.0.1
In-Reply-To: <CADESCNwioPOXU2j=hH1U5ntR_uM29TUMP9SQrREod6PqKuGqYQ@mail.gmail.com>
References: <CADESCNwCom3+Z_muTuysUk2CJ4UmHSs=5ex05FUFhz5HLFAvcA@mail.gmail.com>
	<9E679450-D02A-46F1-9741-269D6D67BA2F@me.com>
	<CADESCNwioPOXU2j=hH1U5ntR_uM29TUMP9SQrREod6PqKuGqYQ@mail.gmail.com>
Message-ID: <AEFFF653-9796-4CA5-8D70-947C0939CD8E@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/ef330aad/attachment.pl>

From ruipbarradas at sapo.pt  Fri Jul 12 22:17:50 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 12 Jul 2013 21:17:50 +0100
Subject: [R] simplify a dataframe
In-Reply-To: <51E05CC2.3020202@cirad.fr>
References: <51E05CC2.3020202@cirad.fr>
Message-ID: <51E0646E.8090101@sapo.pt>

Hello,

My solution is missing a row, but maybe you can find some inspiration.


cols <- c("Matricule", "Nom", "Sexe", "DateNaissance", "contrat", "Pays")
irow1 <- duplicated(df1[, cols])
irow2 <- c(FALSE, df1$Debut[-1] == df1$Fin[-nrow(df1)])

df3 <- df1[!irow1 & !irow2, ]

dim(df2); dim(df3)  # df3 has one row less
df2; df3


Hope this helps,

Rui Barradas

Em 12-07-2013 20:45, Arnaud Michel escreveu:
> Hello
>
> I have the following problem : group the lines of a dataframe when no
> information change (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays)
> and when the value of Debut of lines i = value Fin of lines i-1
> I can obtain it with a do loop. Is it possible to avoid the loop ?
>
> The dataframe initial is df1
> dput(df1)
> structure(list(Matricule = c(1L, 1L, 1L, 6L, 6L, 6L, 6L, 6L,
> 6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 934L, 934L, 934L, 934L,
> 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
> 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
> 934L, 934L, 934L, 934L), Nom = c("VERON", "VERON", "VERON", "BENARD",
> "BENARD", "BENARD", "BENARD", "BENARD", "BENARD", "DALNIC", "DALNIC",
> "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI"), Sexe = c("F?minin", "F?minin", "F?minin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin"), DateNaissance = c("02/09/1935",
> "02/09/1935", "02/09/1935", "01/04/1935", "01/04/1935", "01/04/1935",
> "01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
> "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940",
> "19/02/1940", "19/02/1940", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961"), contrat = c("CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad",
> "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext.
> Cirad",
> "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext.
> Cirad",
> "CDD d?tach? ext. Cirad", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun"), Pays = c("France", "France", "France", "Philippines",
> "Philippines", "Philippines", "France", "France", "France", "France",
> "France", "Martinique", "Martinique", "Martinique", "Martinique",
> "Martinique", "Martinique", "Martinique", "Cameroun", "Cameroun",
> "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun",
> "Cameroun", "France", "France", "France", "France", "France",
> "France", "France", "Congo", "Congo", "Congo", "Congo", "Congo",
> "Congo", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon",
> "Congo", "Congo"), Debut = c("24/01/1995", "01/05/1997", "31/12/1997",
> "02/02/1995", "28/02/1995", "01/03/1995", "13/03/1995", "01/01/1996",
> "31/01/1996", "24/01/1995", "01/07/1995", "01/09/1995", "01/07/1997",
> "01/01/1998", "01/08/1998", "01/01/2000", "17/01/2000", "29/02/2000",
> "26/01/1995", "01/07/1996", "16/09/1997", "01/01/1998", "01/07/1998",
> "04/11/1999", "01/01/2001", "01/04/2001", "31/08/2001", "01/09/2001",
> "02/09/2001", "01/12/2001", "01/02/2003", "01/04/2003", "01/01/2004",
> "01/03/2004", "01/09/2004", "01/01/2005", "01/04/2005", "28/10/2006",
> "01/01/2007", "01/04/2007", "01/09/2007", "01/01/2009", "01/04/2009",
> "01/01/2010", "01/01/2011", "01/04/2011", "05/09/2012", "01/01/2013"
> ), Fin = c("30/04/1997", "30/12/1997", "31/12/1997", "27/02/1995",
> "28/02/1995", "12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996",
> "30/06/1995", "31/08/1995", "30/06/1997", "31/12/1997", "31/07/1998",
> "31/12/1999", "16/01/2000", "28/02/2000", "29/02/2000", "30/06/1996",
> "15/09/1997", "31/12/1997", "30/06/1998", "03/11/1999", "31/12/2000",
> "31/03/2001", "30/08/2001", "31/08/2001", "01/09/2001", "30/11/2001",
> "31/01/2003", "31/03/2003", "31/12/2003", "29/02/2004", "31/08/2004",
> "31/12/2004", "31/03/2005", "27/10/2006", "31/12/2006", "31/03/2007",
> "31/08/2007", "31/12/2008", "31/03/2009", "31/12/2009", "31/12/2010",
> "31/03/2011", "04/09/2012", "31/12/2012", "31/12/4712")), .Names =
> c("Matricule",
> "Nom", "Sexe", "DateNaissance", "contrat", "Pays", "Debut", "Fin"
> ), class = "data.frame", row.names = c(NA, -48L))
>
> The dataframe to be obtained is df2
> dput(df2)
> structure(list(Mat = c(1L, 6L, 6L, 6L, 8L, 8L, 934L, 934L, 934L,
> 934L, 934L), Nom = c("VERON", "BENARD", "BENARD", "BENARD", "DALNIC",
> "DALNIC", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI"), Sexe = c("F?minin",
> "Masculin", "Masculin", "Masculin", "F?minin", "F?minin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin"), DateNaissance =
> c("02/09/1935",
> "01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961"
> ), contrat = c("CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDD d?tach? ext. Cirad", "CDI D?tach?s
> Autres",
> "CDI D?tach?s Autres", "CDI commun", "CDI commun"), Pays = c("France",
> "Philippines", "France", "France", "France", "Martinique", "Cameroun",
> "France", "Congo", "Gabon", "Congo"), Debut = c("24/01/1995",
> "02/02/1995", "13/03/1995", "01/01/1996", "24/01/1995", "01/09/1995",
> "26/01/1995", "01/09/2001", "01/09/2004", "01/09/2007", "05/09/2012"
> ), Fin = c("31/12/1997", "12/03/1995", "30/06/1995", "31/01/1996",
> "31/08/1995", "29/02/2000", "31/08/2001", "31/08/2004", "31/08/2007",
> "04/09/2012", "31/12/4712")), .Names = c("Mat", "Nom", "Sexe",
> "DateNaissance", "contrat", "Pays", "Debut", "Fin"), class =
> "data.frame", row.names = c(NA,
> -11L))
>
> Thank you for your help
>


From gysc at leeds.ac.uk  Fri Jul 12 22:22:00 2013
From: gysc at leeds.ac.uk (Stephen Clark)
Date: Fri, 12 Jul 2013 21:22:00 +0100
Subject: [R] Optimisation does not optimise!
Message-ID: <928C4F7877280844B906D12D63A3F15B01145E5B5C24@HERMES8.ds.leeds.ac.uk>

Hello, 

I have the following code and data. I am basically trying to select individuals in a sample (by setting some weights) to match known counts for a zone. This is been done by matching gender and age bands. I have tested the function to be optimised and it does behave as I would expect when the weights are changed. However when I run the optimisation I get the following output 

> optout<-optim(weights0, func_opt, control=list(REPORT=1))
[1] 27164
[1] 27163.8
[1] 27163.8
[1] 27163.8
[1] 27163.8
[1] 27163.8
[1] 27163.8
[1] 27163.8
[1] 27163.8
etc

which suggest an initial change but thereafter the optimisation does not appear to adapt the weights at all. Can anyone see what this is happening and how to make the problem optimise?

sample<-read.csv(file="C:\\sample.csv")
cons1<-read.csv(file="C:\\Gender.csv")
cons2<-read.csv(file="C:\\Age9.csv")
weights0 <- array(dim = c(nrow(sample)))

for (zone in 1:2){
weights0 <- rep(1, nrow(sample))
	optout<-optim(weights0, func_opt, control=list(REPORT=1))
	optout.value
} 

func_opt<-function(weights){
TAE <- 0.0
sumMale <- sum(weights[sample[1:nrow(sample),2]=="Male"])
	sumFemale <- sum(weights[sample[1:nrow(sample),2]=="Female"])

sumAged50to54 <-sum(weights[sample[1:nrow(sample),3]=="Aged 50 to 54"])
sumAged55to59 <-sum(weights[sample[1:nrow(sample),3]=="Aged 55 to 59"])
sumAged60to64 <-sum(weights[sample[1:nrow(sample),3]=="Aged 60 to 64"])
sumAged65to69 <-sum(weights[sample[1:nrow(sample),3]=="Aged 65 to 69"])
sumAged70to74 <-sum(weights[sample[1:nrow(sample),3]=="Aged 70 to 74"])
sumAged75to79 <-sum(weights[sample[1:nrow(sample),3]=="Aged 75 to 79"])
sumAged80to84 <-sum(weights[sample[1:nrow(sample),3]=="Aged 80 to 84"])
sumAged85to89 <-sum(weights[sample[1:nrow(sample),3]=="Aged 85 to 89"])
sumAged90andolder <-sum(weights[sample[1:nrow(sample),3]=="Aged90 and older"])

	TAE <- abs(cons1[zone, 2] - sumMale)
	TAE <- TAE + abs(cons1[zone, 3] - sumFemale)

TAE <- TAE + abs(cons2[zone, 2] - sumAged50to54)
TAE <- TAE + abs(cons2[zone, 3] - sumAged55to59)
TAE <- TAE + abs(cons2[zone, 4] - sumAged60to64)
TAE <- TAE + abs(cons2[zone, 5] - sumAged65to69)
TAE <- TAE + abs(cons2[zone, 6] - sumAged70to74)
TAE <- TAE + abs(cons2[zone, 7] - sumAged75to79)
TAE <- TAE + abs(cons2[zone, 8] - sumAged80to84)
TAE <- TAE + abs(cons2[zone, 9] - sumAged85to89)
TAE <- TAE + abs(cons2[zone, 10] - sumAged90andolder)

print(TAE)
return(TAE)
}

sample.csv
id	sex	        Age10
103712	Female	Aged 50 to 54
103713	Male	Aged 65 to 69
103715	Female	Aged 60 to 64
103716	Male	Aged 65 to 69
103717	Male	Aged 70 to 74
103718	Female	Aged 80 to 84
103721	Female	Aged 65 to 69
103722	Male	Aged 70 to 74
103723	Male	Aged 65 to 69
103724	Female	Aged 60 to 64
103728	Male	Aged 65 to 69
103729	Female	Aged 50 to 54
103730	Male	Aged 75 to 79
103731	Female	Aged 50 to 54
103733	Female	Aged 55 to 59
(this goes on for 10000 individuals)

Gender.csv
Zone	Male	Female
Z1	10547	13234
Z2	16393	18759
Z3	5713		6462
Z4	19651	21834
Z5	26918	33992
Z6	17596	19665

Age9.csv
LA	Aged50to54	Aged55to59	Aged60to64	Aged65to69	Aged70to74	Aged75to79	Aged80to84	Aged85to89	Aged90andolder
Z1	4274	3852	3307	3096	3123	2728	1896	1056	449
Z2	7416	6015	5402	4852	4304	3405	2270	1047	441
Z3	2425	2093	1864	1757	1520	1218	766	376	156
Z4	9236	7713	6013	5257	4696	4072	2702	1293	503
Z5	9655	8841	8199	8252	8375	7559	5511	3198	1320
Z6	7797	7210	5754	4851	4216	3664	2376	994	399


From kay.cichini at gmail.com  Fri Jul 12 22:44:59 2013
From: kay.cichini at gmail.com (Kay Cichini)
Date: Fri, 12 Jul 2013 22:44:59 +0200
Subject: [R] syntactical meaning of fullstop in R functions
Message-ID: <CADcQ+RqmZ5isrmqNJA3u3KDfP2SytE1VqL_iu_5QTmxeUyo8ng@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/af078333/attachment.pl>

From kay.cichini at gmail.com  Fri Jul 12 22:57:24 2013
From: kay.cichini at gmail.com (Kay Cichini)
Date: Fri, 12 Jul 2013 22:57:24 +0200
Subject: [R] syntactical meaning of fullstop in R functions
In-Reply-To: <CADcQ+RqmZ5isrmqNJA3u3KDfP2SytE1VqL_iu_5QTmxeUyo8ng@mail.gmail.com>
References: <CADcQ+RqmZ5isrmqNJA3u3KDfP2SytE1VqL_iu_5QTmxeUyo8ng@mail.gmail.com>
Message-ID: <CADcQ+RpJMOudu3gXGQccdCwuqNJp_ZO-CU_UDwLoacH1h=N3Mw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/ca87b717/attachment.pl>

From zj29 at cornell.edu  Fri Jul 12 22:58:41 2013
From: zj29 at cornell.edu (Zhao Jin)
Date: Fri, 12 Jul 2013 13:58:41 -0700
Subject: [R] vegan capscale 'subscript out of bounds' error
Message-ID: <CAGD4NNKiTandAtWZRMcZOe3ZeRbMvNUXBzmwu7t0=JHAX6+W4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/4a62aead/attachment.pl>

From davies.trevor at gmail.com  Fri Jul 12 23:18:36 2013
From: davies.trevor at gmail.com (Trevor Davies)
Date: Fri, 12 Jul 2013 14:18:36 -0700
Subject: [R] replace multiple values in vector at once
Message-ID: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/adb81575/attachment.pl>

From davies.trevor at gmail.com  Fri Jul 12 23:56:33 2013
From: davies.trevor at gmail.com (Trevor Davies)
Date: Fri, 12 Jul 2013 14:56:33 -0700
Subject: [R] replace multiple values in vector at once
In-Reply-To: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>
References: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>
Message-ID: <CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/945e69da/attachment.pl>

From bcrombie at utk.edu  Fri Jul 12 22:45:22 2013
From: bcrombie at utk.edu (bcrombie)
Date: Fri, 12 Jul 2013 13:45:22 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
In-Reply-To: <1373575521.34142.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
	<1373574512.14425.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1373575521.34142.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE7F3BA142@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/310c5c31/attachment.pl>

From ntamjo2003 at yahoo.fr  Fri Jul 12 22:47:13 2013
From: ntamjo2003 at yahoo.fr (ntamjo achille)
Date: Fri, 12 Jul 2013 21:47:13 +0100 (BST)
Subject: [R] Testing of Diagnostic residuals in R
In-Reply-To: <1373295509.85105.YahooMailNeo@web172806.mail.ir2.yahoo.com>
References: <1372692946.68698.YahooMailNeo@web172805.mail.ir2.yahoo.com>
	<1373295509.85105.YahooMailNeo@web172806.mail.ir2.yahoo.com>
Message-ID: <1373662033.87055.YahooMailNeo@web172803.mail.ir2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/344530c4/attachment.pl>

From dwinsemius at comcast.net  Sat Jul 13 00:05:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 12 Jul 2013 15:05:52 -0700
Subject: [R] replace multiple values in vector at once
In-Reply-To: <CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
References: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>
	<CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
Message-ID: <D82CB24C-566E-47A2-8D79-C95EF39EDE80@comcast.net>


On Jul 12, 2013, at 2:56 PM, Trevor Davies wrote:

> I always think that replying to your own r-help feels silly but it's good
> to close these things out.
> 
> here's my hack solution:
> 
> x1<-merge(data.frame(A=x),data.frame(A=c('x','y','z'),B=c(1,2,2)),by='A')[,2]

That fairly tortured compared with:

x <- c(rep('x',3),rep('y',3),rep('z',3))

x1b <- as.character(1:3)[ match(x, c("x","y","z") ) ]
x1b

Furthermore, your solution does not deliver the answer you expected.

-- 
David.

> 
> Well that works and should for my more complex situation.  If anyone has
> something a little less heavy handed I'd live to hear it.
> 
> Have a great weekend.
> 
> 
> On Fri, Jul 12, 2013 at 2:18 PM, Trevor Davies <davies.trevor at gmail.com>wrote:
> 
>> 
>> I'm trying to find a function that can replace multiple instances of
>> values or characters in a vector in a one step operation.  As an example,
>> the vector:
>> 
>> x <- c(rep('x',3),rep('y',3),rep('z',3))
>> 
>>> x
>> [1] "x" "x" "x" "y" "y" "y" "z" "z" "z"
>> 
>> I would simply like to replace all of the x's with 1's, y:2 & z:3 (or
>> other characters).
>> i.e:
>>> x
>> [1] "1" "1" "1" "2" "2" "2" "3" "3" "3"
>> 
>> Of course, I'm aware of the replace function but this obviously gets a
>> little unwieldy when there are :
>> x<-replace(x,x=='x',1)
>> x<-replace(x,y=='x',2)
>> x<-replace(x,z=='x',3)
>> 
>> but I can't figure out how to do it in a one stop operation.  My real
>> needs is more complex obviously.  This is one of those seemingly simple
>> r-operations that should be obvious but I'm coming up empty on this one.
>> 
>> Thanks for the help.
>> Trevor
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From davies.trevor at gmail.com  Sat Jul 13 00:12:47 2013
From: davies.trevor at gmail.com (Trevor Davies)
Date: Fri, 12 Jul 2013 15:12:47 -0700
Subject: [R] replace multiple values in vector at once
In-Reply-To: <D82CB24C-566E-47A2-8D79-C95EF39EDE80@comcast.net>
References: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>
	<CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
	<D82CB24C-566E-47A2-8D79-C95EF39EDE80@comcast.net>
Message-ID: <CAJhyqViXmYGmAZSnaL1MtZjpT=z12wyhQuqet0yQuvbM4T6gsw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/74cbe17e/attachment.pl>

From elaine.kuo.tw at gmail.com  Sat Jul 13 00:15:49 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Sat, 13 Jul 2013 06:15:49 +0800
Subject: [R] memory problem of betadiver of vegan
Message-ID: <CAGJhoDzFr6bM3bZ=sE3Ti6oV7f-+vuJdweau5CkkN5bDArr-ww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130713/145fca5f/attachment.pl>

From smartpink111 at yahoo.com  Sat Jul 13 00:25:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 12 Jul 2013 15:25:15 -0700 (PDT)
Subject: [R] replace multiple values in vector at once
In-Reply-To: <CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
References: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>
	<CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
Message-ID: <1373667915.61008.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
library(car)
?recode(x,"'x'=1;'y'=2;'z'=3")
#[1] 1 1 1 2 2 2 3 3 3
#or
as.numeric(factor(x))
#[1] 1 1 1 2 2 2 3 3 3
A.K.




----- Original Message -----
From: Trevor Davies <davies.trevor at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Friday, July 12, 2013 5:56 PM
Subject: Re: [R] replace multiple values in vector at once

I always think that replying to your own r-help feels silly but it's good
to close these things out.

here's my hack solution:

x1<-merge(data.frame(A=x),data.frame(A=c('x','y','z'),B=c(1,2,2)),by='A')[,2]

Well that works and should for my more complex situation.? If anyone has
something a little less heavy handed I'd live to hear it.

Have a great weekend.


On Fri, Jul 12, 2013 at 2:18 PM, Trevor Davies <davies.trevor at gmail.com>wrote:

>
> I'm trying to find a function that can replace multiple instances of
> values or characters in a vector in a one step operation.? As an example,
> the vector:
>
> x <- c(rep('x',3),rep('y',3),rep('z',3))
>
> > x
> [1] "x" "x" "x" "y" "y" "y" "z" "z" "z"
>
> I would simply like to replace all of the x's with 1's, y:2 & z:3 (or
> other characters).
> i.e:
> > x
> [1] "1" "1" "1" "2" "2" "2" "3" "3" "3"
>
> Of course, I'm aware of the replace function but this obviously gets a
> little unwieldy when there are :
> x<-replace(x,x=='x',1)
> x<-replace(x,y=='x',2)
> x<-replace(x,z=='x',3)
>
> but I can't figure out how to do it in a one stop operation.? My real
> needs is more complex obviously.? This is one of those seemingly simple
> r-operations that should be obvious but I'm coming up empty on this one.
>
> Thanks for the help.
> Trevor
>

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Sat Jul 13 00:38:30 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 12 Jul 2013 15:38:30 -0700
Subject: [R] replace multiple values in vector at once
In-Reply-To: <D82CB24C-566E-47A2-8D79-C95EF39EDE80@comcast.net>
References: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>
	<CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
	<D82CB24C-566E-47A2-8D79-C95EF39EDE80@comcast.net>
Message-ID: <CACk-te1g0QQMHX1bQzUtZwYfBCdasNmZtHPum2CpUooY+f-Svw@mail.gmail.com>

David is right, but it's trivial if x is a factor (which is the
default when you create character columns in a data frame).

(Note also how to use rep() properly -- read the docs: ?rep)

x <- factor(rep(LETTERS[1:3],e=3))
x
[1] A A A B B B C C C
Levels: A B C

levels(x) <- 1:3
x
[1] 1 1 1 2 2 2 3 3 3
Levels: 1 2 3

Cheers,
Bert
On Fri, Jul 12, 2013 at 3:05 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jul 12, 2013, at 2:56 PM, Trevor Davies wrote:
>
>> I always think that replying to your own r-help feels silly but it's good
>> to close these things out.
>>
>> here's my hack solution:
>>
>> x1<-merge(data.frame(A=x),data.frame(A=c('x','y','z'),B=c(1,2,2)),by='A')[,2]
>
> That fairly tortured compared with:
>
> x <- c(rep('x',3),rep('y',3),rep('z',3))
>
> x1b <- as.character(1:3)[ match(x, c("x","y","z") ) ]
> x1b
>
> Furthermore, your solution does not deliver the answer you expected.
>
> --
> David.
>
>>
>> Well that works and should for my more complex situation.  If anyone has
>> something a little less heavy handed I'd live to hear it.
>>
>> Have a great weekend.
>>
>>
>> On Fri, Jul 12, 2013 at 2:18 PM, Trevor Davies <davies.trevor at gmail.com>wrote:
>>
>>>
>>> I'm trying to find a function that can replace multiple instances of
>>> values or characters in a vector in a one step operation.  As an example,
>>> the vector:
>>>
>>> x <- c(rep('x',3),rep('y',3),rep('z',3))
>>>
>>>> x
>>> [1] "x" "x" "x" "y" "y" "y" "z" "z" "z"
>>>
>>> I would simply like to replace all of the x's with 1's, y:2 & z:3 (or
>>> other characters).
>>> i.e:
>>>> x
>>> [1] "1" "1" "1" "2" "2" "2" "3" "3" "3"
>>>
>>> Of course, I'm aware of the replace function but this obviously gets a
>>> little unwieldy when there are :
>>> x<-replace(x,x=='x',1)
>>> x<-replace(x,y=='x',2)
>>> x<-replace(x,z=='x',3)
>>>
>>> but I can't figure out how to do it in a one stop operation.  My real
>>> needs is more complex obviously.  This is one of those seemingly simple
>>> r-operations that should be obvious but I'm coming up empty on this one.
>>>
>>> Thanks for the help.
>>> Trevor
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From vahab.pourfaraj at yahoo.ca  Sat Jul 13 00:13:41 2013
From: vahab.pourfaraj at yahoo.ca (Vahab Pourfaraj)
Date: Fri, 12 Jul 2013 15:13:41 -0700 (PDT)
Subject: [R] SH test results
In-Reply-To: <1373664793.71959.YahooMailNeo@web162005.mail.bf1.yahoo.com>
References: <1373660417.8566.YahooMailNeo@web162004.mail.bf1.yahoo.com>
	<1373661431.75225.YahooMailNeo@web162003.mail.bf1.yahoo.com>
	<1373664055.16520.YahooMailNeo@web162003.mail.bf1.yahoo.com>
	<1373664793.71959.YahooMailNeo@web162005.mail.bf1.yahoo.com>
Message-ID: <1373667221.45890.YahooMailNeo@web162006.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130712/0ed3f12f/attachment.pl>

From Jason.Law at portlandoregon.gov  Sat Jul 13 01:03:23 2013
From: Jason.Law at portlandoregon.gov (Law, Jason)
Date: Fri, 12 Jul 2013 16:03:23 -0700
Subject: [R] replace multiple values in vector at once
In-Reply-To: <CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
References: <CAJhyqVhiaXT3LQtyaOrQMaVHVdUzkSxZ5FuseshFR_YTnEzzjg@mail.gmail.com>
	<CAJhyqViXzmC81CnjNq4B42DGewERXhH0Lqt=9s_JAzVd1qKjJw@mail.gmail.com>
Message-ID: <0EFBC7C31DB4F24F8CAC48136A1762D70184E54FD9C4@MAIL2.rose.portland.local>

In the plyr package there are also the functions revalue and mapvalues:

library(plyr)
x <- c("a", "b", "c")
revalue(x, c(a = "A", c = "C"))
mapvalues(x, c("a", "c"), c("A", "C"))

mapvalues works on numeric, character and factor.

Jason

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Trevor Davies
Sent: Friday, July 12, 2013 2:57 PM
To: r-help at r-project.org
Subject: Re: [R] replace multiple values in vector at once

I always think that replying to your own r-help feels silly but it's good to close these things out.

here's my hack solution:

x1<-merge(data.frame(A=x),data.frame(A=c('x','y','z'),B=c(1,2,2)),by='A')[,2]

Well that works and should for my more complex situation.  If anyone has something a little less heavy handed I'd live to hear it.

Have a great weekend.


On Fri, Jul 12, 2013 at 2:18 PM, Trevor Davies <davies.trevor at gmail.com>wrote:

>
> I'm trying to find a function that can replace multiple instances of 
> values or characters in a vector in a one step operation.  As an 
> example, the vector:
>
> x <- c(rep('x',3),rep('y',3),rep('z',3))
>
> > x
> [1] "x" "x" "x" "y" "y" "y" "z" "z" "z"
>
> I would simply like to replace all of the x's with 1's, y:2 & z:3 (or 
> other characters).
> i.e:
> > x
> [1] "1" "1" "1" "2" "2" "2" "3" "3" "3"
>
> Of course, I'm aware of the replace function but this obviously gets a 
> little unwieldy when there are :
> x<-replace(x,x=='x',1)
> x<-replace(x,y=='x',2)
> x<-replace(x,z=='x',3)
>
> but I can't figure out how to do it in a one stop operation.  My real 
> needs is more complex obviously.  This is one of those seemingly 
> simple r-operations that should be obvious but I'm coming up empty on this one.
>
> Thanks for the help.
> Trevor
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From elaine.kuo.tw at gmail.com  Sat Jul 13 01:04:06 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Sat, 13 Jul 2013 07:04:06 +0800
Subject: [R] memory problem of betadiver of vegan
In-Reply-To: <CAGJhoDzFr6bM3bZ=sE3Ti6oV7f-+vuJdweau5CkkN5bDArr-ww@mail.gmail.com>
References: <CAGJhoDzFr6bM3bZ=sE3Ti6oV7f-+vuJdweau5CkkN5bDArr-ww@mail.gmail.com>
Message-ID: <CAGJhoDyJK6d+8UANYh-9cav8Y8vf2wSmJmgVYYAXiz6_iKJ0kA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130713/f3ca6901/attachment.pl>

From rolf.turner at xtra.co.nz  Sat Jul 13 01:47:19 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sat, 13 Jul 2013 11:47:19 +1200
Subject: [R] syntactical meaning of fullstop in R functions
In-Reply-To: <CADcQ+RpJMOudu3gXGQccdCwuqNJp_ZO-CU_UDwLoacH1h=N3Mw@mail.gmail.com>
References: <CADcQ+RqmZ5isrmqNJA3u3KDfP2SytE1VqL_iu_5QTmxeUyo8ng@mail.gmail.com>
	<CADcQ+RpJMOudu3gXGQccdCwuqNJp_ZO-CU_UDwLoacH1h=N3Mw@mail.gmail.com>
Message-ID: <51E09587.40905@xtra.co.nz>

On 13/07/13 08:57, Kay Cichini wrote:
> just found it myself:
>
> in '.GADM' the leading period designates an internal function - the source
> can be viewed with:
> getAnywhere('.GADM')

I think that's a bit misleading.  In general, the names of functions (or 
other objects) which
are "internal" to a package need *not* begin with a full stop.  That is 
just a convention that
the author of the "dismo" package is using.  What makes an object 
"internal" really is
not being exported in the NAMESPACE of the package.

The general impact of beginning the name of an object with a full stop 
is to make that
object "invisible" to ls().  I.e. if you do an ls() of the environment 
in which that object
"lives" then you will *not* see the name of that object unless you do

     ls(.....,all.names=TRUE)

See help(ls).

     cheers,

         Rolf Turner


From smartpink111 at yahoo.com  Sat Jul 13 04:43:17 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 12 Jul 2013 19:43:17 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
In-Reply-To: <559C998F7039D84C9793AE43D9BBE9CE7F3BA142@kmbx3.utk.tennessee.edu>
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
	<1373574512.14425.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1373575521.34142.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE7F3BA142@kmbx3.utk.tennessee.edu>
Message-ID: <1373683397.96477.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
One alternative would be to change colnames:

colnames(dat3)<-1:4

?data.frame(MW_EEsDue_ERRORS=with(dat3,`1`[`4`!=rowSums(cbind(`2`,`3`))]))
? #MW_EEsDue_ERRORS
#1???????????? 1882
#2???????????? 1884
#3???????????? 1885


Also, check these:
with(dat3,4)
#[1] 4
?with(dat3,`4`)
#[1]?? 7?? 9?? 5?? 6 112
with(dat3,7)
#[1] 7
?with(dat3,`7`)
#Error in eval(expr, envir, enclos) : object '7' not found


A.K.

----- Original Message -----
From: bcrombie <bcrombie at utk.edu>
To: r-help at r-project.org
Cc: 
Sent: Friday, July 12, 2013 4:45 PM
Subject: Re: [R] create new matrix from user-defined function

AK, I decided to convert your ?with? statement back to index-by-number, and I did look up the ?with help info, but I?m confused about my replacement code below.? I got the wrong answer (R didn?t apply the function to my column 1 variable ?A_CaseID?).? What am I doing wrong?? Do I need to change my function code re: index ?4? (otherwise known as ?D_MW_EEsDueTotal? --- my attempts at that have failed also)?? thanks.

#this is your correct code

> data.frame(MW_EEsDue_ERRORS=with(dat3,A_CaseID[D_MW_EEsDueTotal!=rowSums(cbind(B_MW_EEsDue1,C_MW_EEsDue2))]))

#? MW_EEsDue_ERRORS

#1? ? ? ? ? ?  1882

#2? ? ? ? ? ?  1884

#3? ? ? ? ? ?  1885

#these are my incorrect scripts
> data.frame(MW_EEsDue_ERRORS=with(dat3,A_CaseID[4!=rowSums(cbind(2,3))]))
#? MW_EEsDue_ERRORS
#1? ? ? ? ? ?  1881
#2? ? ? ? ? ?  1882
#3? ? ? ? ? ?  1883
#4? ? ? ? ? ?  1884
#5? ? ? ? ? ?  1885


> data.frame(MW_EEsDue_ERRORS=with(dat3,dat3[[1]][4!=rowSums(cbind(2,3))]))

#? MW_EEsDue_ERRORS

#1? ? ? ? ? ?  1881

#2? ? ? ? ? ?  1882

#3? ? ? ? ? ?  1883

#4? ? ? ? ? ?  1884

#5? ? ? ? ? ?  1885


> data.frame(MW_EEsDue_ERRORS=with(dat3,1[4!=rowSums(cbind(2,3))]))

#? MW_EEsDue_ERRORS

#1? ? ? ? ? ? ? ? 1

Original database:
dat3 = data.frame(A_CaseID = c(1881, 1882, 1883, 1884, 1885),
? ? ? ? ? ? ? ? ? B_MW_EEsDue1 = c(2, 2, 1, 4, 6),
? ? ? ? ? ? ? ? ? C_MW_EEsDue2 = c(5, 5, 4, 1, 6),
? ? ? ? ? ? ? ? ? D_MW_EEsDueTotal = c(7, 9, 5, 6, 112))
dat3
# A_CaseID B_MW_EEsDue1 C_MW_EEsDue2 D_MW_EEsDueTotal
# 1? ?  1881? ? ? ? ? ? 2? ? ? ? ? ? 5? ? ? ? ? ? ? ? 7
# 2? ?  1882? ? ? ? ? ? 2? ? ? ? ? ? 5? ? ? ? ? ? ? ? 9
# 3? ?  1883? ? ? ? ? ? 1? ? ? ? ? ? 4? ? ? ? ? ? ? ? 5
# 4? ?  1884? ? ? ? ? ? 4? ? ? ? ? ? 1? ? ? ? ? ? ? ? 6
# 5? ?  1885? ? ? ? ? ? 6? ? ? ? ? ? 6? ? ? ? ? ? ? 112


From: arun kirshna [via R] [mailto:ml-node+s789695n4671365h27 at n4.nabble.com]
Sent: Thursday, July 11, 2013 4:55 PM
To: Crombie, Burnette N
Subject: Re: create new matrix from user-defined function

Hi BNC,
No problem.
You could also use ?with()

data.frame(MW_EEsDue_ERRORS=with(dat3,A_CaseID[D_MW_EEsDueTotal!=rowSums(cbind(B_MW_EEsDue1,C_MW_EEsDue2))]))
#? MW_EEsDue_ERRORS
#1? ? ? ? ? ?  1882
#2? ? ? ? ? ?  1884
#3? ? ? ? ? ?  1885
A.K.






--
View this message in context: http://r.789695.n4.nabble.com/create-new-matrix-from-user-defined-function-tp4671250p4671445.html
Sent from the R help mailing list archive at Nabble.com.
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Jul 13 06:08:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 12 Jul 2013 21:08:10 -0700 (PDT)
Subject: [R] multi-condition summing puzzle
Message-ID: <1373688490.25411.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:

dat1<- read.table(text="
ID county date company 
1?????? x????? 1?????? comp1
2?????? y????? 1?????? comp3
3?????? y????? 2?????? comp1
4?????? y????? 3?????? comp1
5??????? x????? 2????? comp2
",sep="",header=TRUE,stringsAsFactors=FALSE)
dat2<- dat1
dat1$answer<-unsplit(lapply(split(dat1,dat1$county),function(x) do.call(rbind,lapply(seq_len(nrow(x)),function(i) {x1<-x[1:i,]; x2<-table(x1$company)/sum(table(x1$company));sum(x2^2)}))),dat1$county)
?dat1
#? ID county date company??? answer
#1? 1????? x??? 1?? comp1 1.0000000
#2? 2????? y??? 1?? comp3 1.0000000
#3? 3????? y??? 2?? comp1 0.5000000
#4? 4????? y??? 3?? comp1 0.5555556
#5? 5????? x??? 2?? comp2 0.5000000

#or
dat2$answer<-with(dat2,unlist(ave(company,county,FUN=function(x) lapply(seq_along(x),function(i) {x1<-table(x[1:i]);sum((x1/sum(x1))^2)}))))
?dat2
#? ID county date company??? answer
#1? 1????? x??? 1?? comp1 1.0000000
#2? 2????? y??? 1?? comp3 1.0000000
#3? 3????? y??? 2?? comp1 0.5000000
#4? 4????? y??? 3?? comp1 0.5555556
#5? 5????? x??? 2?? comp2 0.5000000

A.K.

Hi - 

I have a seemingly complex data summarizing problem that I am having a hard time wrapping my mind around. 

What I'm trying to do is sum the square of all company market 
shares ?in a given county, UP TO that corresponding time. Sum of market 
share is defined as: Number of company observations/ Total observations. 

Here is example data and desired answer: 

ID	county	date	company answer
1	 ? ? ? x	 ? ? ?1	 ? ? ? comp1	 ? ? ? ? ? 1
2	 ? ? ? y	 ? ? ?1	 ? ? ? comp3	 ? ? ? ? ? 1
3	 ? ? ? y	 ? ? ?2	 ? ? ? comp1	 ? ? ? ? ? 0.5
4	 ? ? ? y	 ? ? ?3	 ? ? ? comp1	 ? ? ? ? ? 0.55556
5	 ? ? ? ?x	 ? ? ?2	 ? ? ?comp2	 ? ? ? ? ?0.5

For example, to get the answer for ID 4, we look at county y, dates 1, 2, 3 and sum: ?[(2/3)comp1]^2 +[(1/3)comp3]^2 = 0.55556 

I've tried cumsum, but am simply stuck given all of the 
different conditions. ?I have a large matrix of data for this with 
several hundred companies, tens of counties and unique dates. 

Any help would be extremely appreciated. 

Thank you,


From arne.henningsen at gmail.com  Sat Jul 13 11:25:16 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sat, 13 Jul 2013 11:25:16 +0200
Subject: [R] Testing for weak exogeneity in a SUR ECM
In-Reply-To: <1373541662853-4671321.post@n4.nabble.com>
References: <1373541662853-4671321.post@n4.nabble.com>
Message-ID: <CAMTWbJhbVUAv1UJ3ZDjZNbJs4=vA6pL+A3+DON_yoLCsjy2N_Q@mail.gmail.com>

Dear Kathrinchen

It seems to me that your question is about statistics rather than
about R and systemfit. If you find out how the statistical test should
be conducted theoretically, I can probably advise you how to implement
the test in R (systemfit).

Best wishes,
Arne


On 11 July 2013 13:21, Kathrinchen <katha.mibi at web.de> wrote:
> Dear all,
>
> I have set up a Labour Demand Error Correction Model for some German federal
> states.
>
> As I expect the labour markets to be correlated I used a Seemingly Unrelated
> Regression using systemfit in R.
>
> My Model  is:
>
> d(emp)_it = c + alpha*ln(emp)_i,t-1 + beta_1*ln(gdp)_i,t-1 + +
> beta_2*ln(wage)_i,t-1 + + beta_1*ln(i)_i,t-1 + gamma_1*d(gdp)_it +
> gamma_2*d(wage)_it
>
> with emp_it being the employment in state i at time t, i stands for the real
> interest rate, ln() is the logarithmed data, while d() stands for the
> difference operator.
>
> I would like to test now for weak exogeneity and I am not quite sure what
> kind of regression to run.  If I run:
> d(gdp)_it = c + alpha*ln(emp)_i,t-1 + beta_1*ln(gdp)_i,t-1 + +
> beta_2*ln(wage)_i,t-1 + + beta_1*ln(i)_i,t-1 + gamma_1*d(emp)_it +
> gamma_2*d(wage)_it
>
> with Systemfit, alpha is statistically significant, so I have to reject the
> hypothesis of weak exogeneity...Literature is in my opinion not so clear on
> what to test!
>
> I use data from an application, they conclude that endogeneity is not a
> problem: they regress the possible endogenous variables "on the presumed
> equilibrium relation, a constant and one autoregressive lag" - here I am not
> sure, what they mean.
>
> I would very much appreciate your help!
>
> Thanks a lot!
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Testing-for-weak-exogeneity-in-a-SUR-ECM-tp4671321.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Arne Henningsen
http://www.arne-henningsen.name


From jari.oksanen at oulu.fi  Sat Jul 13 11:52:12 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Sat, 13 Jul 2013 09:52:12 +0000
Subject: [R] vegan capscale 'subscript out of bounds' error
References: <CAGD4NNKiTandAtWZRMcZOe3ZeRbMvNUXBzmwu7t0=JHAX6+W4w@mail.gmail.com>
Message-ID: <loom.20130713T114621-378@post.gmane.org>

Zhao Jin <zj29 <at> cornell.edu> writes:

> I am using the capscale function in vegan_2.0-7 to do a constrained
> principal coordinates analysis, and I kept getting the following error
> message:
> Error in Y.r[, oo, drop = FALSE] : subscript out of bounds
> 
> I googled but I couldn't find an answer. Could anyone tell me why this
> error msg and what to do?
> 
> Here is the command I used:
> mod=capscale(as.dist(dist)~mydataset$Var1+Condition(mydataset$Var2))
> 
> My dataset looks like the output of column-binding the 'varespec' and
> 'varechem' datasets, and has 92 rows and about 3500 columns. I also fed
> capscale a similarity matrix in the formula.

Dear Zhao Jin,

This is irreproducible. I have tried several ways of giving wrong data or 
definition to capscale() and have been able to generate several different 
error messages, but not this one. We need more hints. 

Moreover, if 'dist' are distances (dissimilarities), you do not need as.dist() 
for them, and the formula takes a 'data' argument, so that you can write:

capscale(dist ~ Var1 + Condition(Var2), mydataset)

I would start at looking how 'dist' and 'mydataset' look like, and what are 
'Var1' and 'Var2'.

Cheers, Jari Oksanen


From nashjc at uottawa.ca  Sat Jul 13 14:06:54 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Sat, 13 Jul 2013 08:06:54 -0400
Subject: [R]  Optimisation does not optimise!
In-Reply-To: <mailman.29.1373709610.15244.r-help@r-project.org>
References: <mailman.29.1373709610.15244.r-help@r-project.org>
Message-ID: <51E142DE.4060803@uottawa.ca>

Considering that I devised the code initially on a computer with only 8K 
bytes for program and data, and it appears that your problem has 10000 
parameters, I'm surprised you got any output. I suspect the printout is 
the BUILD phase where each weight is being adjusted in turn by the same 
shift.

Don't try to move the Titanic on a pram.

If you work out a gradient function, you can likely use Rcgmin (even 
though I wrote original CG in optim(), not recommended). spg from BB may 
also work OK.

This problem is near linear, so there are other approaches.

JN


On 13-07-13 06:00 AM, r-help-request at r-project.org wrote:
> Date: Fri, 12 Jul 2013 21:22:00 +0100
> From: Stephen Clark<gysc at leeds.ac.uk>
> To:"r-help at R-project.org"  <r-help at R-project.org>
> Subject: [R] Optimisation does not optimise!
> Message-ID:
> 	<928C4F7877280844B906D12D63A3F15B01145E5B5C24 at HERMES8.ds.leeds.ac.uk>
> Content-Type: text/plain; charset="us-ascii"
>
> Hello,
>
> I have the following code and data. I am basically trying to select individuals in a sample (by setting some weights) to match known counts for a zone. This is been done by matching gender and age bands. I have tested the function to be optimised and it does behave as I would expect when the weights are changed. However when I run the optimisation I get the following output
>
>> >optout<-optim(weights0, func_opt, control=list(REPORT=1))
> [1] 27164
> [1] 27163.8
> [1] 27163.8
> [1] 27163.8
> [1] 27163.8
> [1] 27163.8
> [1] 27163.8
> [1] 27163.8
> [1] 27163.8
> etc
>
> which suggest an initial change but thereafter the optimisation does not appear to adapt the weights at all. Can anyone see what this is happening and how to make the problem optimise?


From serenamasino at gmail.com  Sat Jul 13 13:30:34 2013
From: serenamasino at gmail.com (serena masino)
Date: Sat, 13 Jul 2013 12:30:34 +0100
Subject: [R] Help on np package - how to set the data into a panel format
Message-ID: <CADgF0yRYR0c4GTODwFfLsV_TWg2s4ebXQ20DhBeLpfL7nA3h4A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130713/82eb428c/attachment.pl>

From szehnder at uni-bonn.de  Sat Jul 13 13:33:30 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sat, 13 Jul 2013 13:33:30 +0200
Subject: [R] Set window title for plot on any OS
Message-ID: <7F081E1D-3562-4B03-A38A-E9A5F3DA00EE@uni-bonn.de>

Dear R-Users,

I am writing a package using S4 classes. In the generic method "plot" I want to set the title for the plotting window as I will have several windows and window titles help the users to distinguish the graphics without putting a title into the plot itself (this can be done by users whenever they want) 

So I created a helper function .setDeviceTitle which I called after the plot has been done:

".setDeviceTitle" <- function(title = "title", dev = dev.cur()) {
	dev <- names(dev)[1]
	
	## check for OS ##
	if (dev == "windows") {
		windows(title = title)
	} else if (dev == "X11") {
		X11(title = title)
	} else {
		quartz(title = title)
	}
}

The result is a new device with the title in addition to the old. Is it possible to give a window a title after the plot has been done? If not: Before I plot the device I cannot know what device it will be, so I thought about a check via capabilities():

if (any(names(capabilities()) == "X11")) {
	X11(title = title)
}
else if (any(names(capabilities)) == "windows") {
	windows(title = title)
} else {
	quartz(title = title)
}

I want to have a safe method, which works on each OS R can run. How would you solve the problem? 


Best 

Simon


From murdoch.duncan at gmail.com  Sat Jul 13 14:40:37 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 13 Jul 2013 14:40:37 +0200
Subject: [R] Set window title for plot on any OS
In-Reply-To: <7F081E1D-3562-4B03-A38A-E9A5F3DA00EE@uni-bonn.de>
References: <7F081E1D-3562-4B03-A38A-E9A5F3DA00EE@uni-bonn.de>
Message-ID: <51E14AC5.2010004@gmail.com>

On 13-07-13 1:33 PM, Simon Zehnder wrote:
> Dear R-Users,
>
> I am writing a package using S4 classes. In the generic method "plot" I want to set the title for the plotting window as I will have several windows and window titles help the users to distinguish the graphics without putting a title into the plot itself (this can be done by users whenever they want)
>
> So I created a helper function .setDeviceTitle which I called after the plot has been done:
>
> ".setDeviceTitle" <- function(title = "title", dev = dev.cur()) {
> 	dev <- names(dev)[1]
> 	
> 	## check for OS ##
> 	if (dev == "windows") {
> 		windows(title = title)
> 	} else if (dev == "X11") {
> 		X11(title = title)
> 	} else {
> 		quartz(title = title)
> 	}
> }
>
> The result is a new device with the title in addition to the old. Is it possible to give a window a title after the plot has been done? If not: Before I plot the device I cannot know what device it will be, so I thought about a check via capabilities():
>
> if (any(names(capabilities()) == "X11")) {
> 	X11(title = title)
> }
> else if (any(names(capabilities)) == "windows") {
> 	windows(title = title)
> } else {
> 	quartz(title = title)
> }
>
> I want to have a safe method, which works on each OS R can run. How would you solve the problem?

Use dev.new() rather than picking a particular device.  If all the 
possible devices support the "title" argument, then

dev.new(title=title)

will be fine.  If you might need more customization (or want to protect 
against a user who chooses a device that doesn't have "title" as an 
argument), use getOption("device") to examine the call that will be used.

Duncan Murdoch


From ruipbarradas at sapo.pt  Sat Jul 13 15:55:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 13 Jul 2013 14:55:36 +0100
Subject: [R] Help on np package - how to set the data into a panel format
In-Reply-To: <CADgF0yRYR0c4GTODwFfLsV_TWg2s4ebXQ20DhBeLpfL7nA3h4A@mail.gmail.com>
References: <CADgF0yRYR0c4GTODwFfLsV_TWg2s4ebXQ20DhBeLpfL7nA3h4A@mail.gmail.com>
Message-ID: <51E15C58.7010606@sapo.pt>

Hello,

It would be better if you post a data example. Like this, I will make up 
one. I'm not sure I understand the question, but if you want to change 
your data from long to wide format there are several ways of doing it.


# Make up some data
dat <- data.frame(
	year = rep(1:2, each = 3),
	country = rep(letters[1:3], 2),
	value = rnorm(6))

# Now in wide format
reshape(dat, idvar = "year", timevar = "country", direction = "wide")

# Using package reshape2
#install.packages("reshape2", dependencies = TRUE)  # do this only once

library(reshape2)  # load it into the R session
dcast(dat, year ~ country)


Hope this helps,

Rui Barradas

Em 13-07-2013 12:30, serena masino escreveu:
> Hi,
>
> I am new to R and am a STATA user. I am using R as I need the np package to
> perform a local linear non parametric regression on a panel data of
> countries. My data contains 138 countries, each observed for 31 years, from
> 1981 to 2011.
>
> I am aware of the panel package in R which sets the data in panel format
> telling R which one is the "id" and which one is the "time" variable. I am
> not sure however what to use to set the data into a panel format when using
> the np package.
>
> What I have done so far was to
>
> read.csv ("C:/folder/filename.csv")
>
> then i explore it
> str(filename)
>
> and my country variable appears as a "factor", which I think is good right?
> Because it means that is a string to which R has attached a value.Year
> instead appears as "int".
>
> Now, how can I tell R that the data has repeated country cross sections for
> 31 years and so that the data should be treated as a panel of 138 countries
> observed each for 31 consecutive years?
>
> Many Thanks in advance for your help, and apologies if this is a very basic
> question, I have tried looking it up in a number of places but all I came
> by was the panel package instructions and I am not sure whether they can
> transfer to the np package too.
>
> Best,
> Serena
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jholtman at gmail.com  Sat Jul 13 16:45:50 2013
From: jholtman at gmail.com (jim holtman)
Date: Sat, 13 Jul 2013 10:45:50 -0400
Subject: [R] simplify a dataframe
In-Reply-To: <51E05CC2.3020202@cirad.fr>
References: <51E05CC2.3020202@cirad.fr>
Message-ID: <CAAxdm-6Zp-a+T0c3KDRJXwcGheEcN7FeSsjwEbq8qnRCkrtTgw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130713/91ea5bbb/attachment.pl>

From jrkrideau at inbox.com  Sat Jul 13 17:30:38 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 13 Jul 2013 07:30:38 -0800
Subject: [R] Help on np package - how to set the data into a panel format
In-Reply-To: <CADgF0yRYR0c4GTODwFfLsV_TWg2s4ebXQ20DhBeLpfL7nA3h4A@mail.gmail.com>
Message-ID: <DB201CC53D4.00000292jrkrideau@inbox.com>

We really need to see the data, I think.

You can use the function dput(), see ?dput

dput(filename) will give you a formatted output that you can just  copy and paste into an e-mail. An R-help reader can just copy and paste that into R and have an exact copy of your data set.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: serenamasino at gmail.com
> Sent: Sat, 13 Jul 2013 12:30:34 +0100
> To: r-help at r-project.org
> Subject: [R] Help on np package - how to set the data into a panel format
> 
> Hi,
> 
> I am new to R and am a STATA user. I am using R as I need the np package
> to
> perform a local linear non parametric regression on a panel data of
> countries. My data contains 138 countries, each observed for 31 years,
> from
> 1981 to 2011.
> 
> I am aware of the panel package in R which sets the data in panel format
> telling R which one is the "id" and which one is the "time" variable. I
> am
> not sure however what to use to set the data into a panel format when
> using
> the np package.
> 
> What I have done so far was to
> 
> read.csv ("C:/folder/filename.csv")
> 
> then i explore it
> str(filename)
> 
> and my country variable appears as a "factor", which I think is good
> right?
> Because it means that is a string to which R has attached a value.Year
> instead appears as "int".
> 
> Now, how can I tell R that the data has repeated country cross sections
> for
> 31 years and so that the data should be treated as a panel of 138
> countries
> observed each for 31 consecutive years?
> 
> Many Thanks in advance for your help, and apologies if this is a very
> basic
> question, I have tried looking it up in a number of places but all I came
> by was the panel package instructions and I am not sure whether they can
> transfer to the np package too.
> 
> Best,
> Serena
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From ruipbarradas at sapo.pt  Sat Jul 13 18:04:48 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sat, 13 Jul 2013 17:04:48 +0100
Subject: [R] How to set panel data format
In-Reply-To: <12216303.443334.1373726304932.JavaMail.nabble@joe.nabble.com>
References: <12216303.443334.1373726304932.JavaMail.nabble@joe.nabble.com>
Message-ID: <51E17AA0.8060305@sapo.pt>

Hello,

It's better if you keep this on the list, the odds of getting more and 
better answers is greater.

Inline.

Em 13-07-2013 15:38, serenamasino at gmail.com escreveu:
> Hi Rui,
> thanks for your reply.
>
> No, my problem isn't one of reshaping. It is just that I want R to know I have a panel and not just cross sections or time series.
>
> In other words If I had cross section data:
>
> COUNTRY   YEAR   GDP
> Albania        1999     3
> Barbados    1999     5
> Congo          1999     1
> Denmark    1999     11
> etc.                ..             ..
>
> My ID here is country, but every observation is a new cluster independent of each other, so I don't care to let R know because the ID is a unique identifier.
>
> Whereas if I have a panel
>
> COUNTRY   YEAR   GDP
> Albania        1999      3
> Albania        2000      3.5
> Albania        2001      3.7
> Albania        2002      4
> Albania        2003      4.5
> Barbados   1999       5
> Barbados   2000       5
> Barbados   2001       5.1
> Barbados   2002       4
> Barbados   2003       3
> Congo         1999      1
> Congo         2000      2
> Congo         2001      2
> Congo         2002      3
> Congo         2003      4
> Denmark    1999     11
> Denmark    2000     12
> Denmark    2001     13
> Denmark    2002     10
> Denmark    2003     10
> etc.                ..             ..
>
> How am I going to tell R that Albania is one same ID for all the 5 years I have in the panel, in other words, Albania has to be identified by the same number in the "factor" vector which R codes it with. Then Barbados is ID 2 in all its years, Congo has ID 3 and so on.

R already does that, factors are coded as integers:

as.integer(dat$COUNTRY) # Albania is 1, etc


> In STATA, you sort 'by country year' and the program knows it is a panel of entities observed more than once over time.  But I am not sure how to let R know the same.
>
> In practice the reason why it is important to define where a country ends and where a new begins is because
>
> 1) if one creates lags of variables and the program doesn't know where the boundaries between countries are, the lag for the first year of Barbados in my previous example will be calculated using the last year of Albania, that is, the preceding country.

A way of doing this, equivalent to the previous line of code if the 
countries are grouped consecutively, is

cumsum(c(TRUE, dat$COUNTRY[-nrow(dat)] != dat$COUNTRY[-1L]))
>
> 2) I need to create countrydummies that take the value of 1 whenever a country ID is equal to 1, so if Albania has 5 years of observations and each of the year observations appears with a different ID, the country dummies will not be created. Instead if Albania has the same country identifier (1) for all the years in which it is observed, the country dummy will be the same and ==1 whenever Albania is the country observed

I doubt you need to create dummuies, R does it for you when you create a 
factor. internally, factors are coded as integers, so all you need is to 
coerce them to integer like I've said earlier.

Rui Barradas

>
> Hope this makes it clearer,
> Thanks,
> Serena
>
> _____________________________________
> Sent from http://r.789695.n4.nabble.com
>


From thiem at sipo.gess.ethz.ch  Sat Jul 13 15:45:05 2013
From: thiem at sipo.gess.ethz.ch (Thiem  Alrik)
Date: Sat, 13 Jul 2013 13:45:05 +0000
Subject: [R] Test for column equality across matrices
Message-ID: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>

Dear list,

I have two matrices

A <- matrix(t(expand.grid(c(1,2,3,4,5), 15, 16)), nrow = 3)
B <- combn(16, 3)

Now I would like to exclude all columns from the 560 columns in B which are identical to any 1 of the 6 columns in A. How could I do this?

Many thanks and best wishes,

Alrik


From szehnder at uni-bonn.de  Sat Jul 13 15:45:58 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sat, 13 Jul 2013 15:45:58 +0200
Subject: [R] Set window title for plot on any OS
In-Reply-To: <51E14AC5.2010004@gmail.com>
References: <7F081E1D-3562-4B03-A38A-E9A5F3DA00EE@uni-bonn.de>
	<51E14AC5.2010004@gmail.com>
Message-ID: <1AD963C5-3D00-4186-A020-31338C6FC1A4@uni-bonn.de>

Hi Duncan,

thank you very much for your advice! That makes it all work. 

I check in addition for a "title" argument in the device via

if (any(names(getOption("device")) == TRUE)) {
	dev.new(title = "title")
} 

Thanks again!

Simon

On Jul 13, 2013, at 2:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13-07-13 1:33 PM, Simon Zehnder wrote:
>> Dear R-Users,
>> 
>> I am writing a package using S4 classes. In the generic method "plot" I want to set the title for the plotting window as I will have several windows and window titles help the users to distinguish the graphics without putting a title into the plot itself (this can be done by users whenever they want)
>> 
>> So I created a helper function .setDeviceTitle which I called after the plot has been done:
>> 
>> ".setDeviceTitle" <- function(title = "title", dev = dev.cur()) {
>> 	dev <- names(dev)[1]
>> 	
>> 	## check for OS ##
>> 	if (dev == "windows") {
>> 		windows(title = title)
>> 	} else if (dev == "X11") {
>> 		X11(title = title)
>> 	} else {
>> 		quartz(title = title)
>> 	}
>> }
>> 
>> The result is a new device with the title in addition to the old. Is it possible to give a window a title after the plot has been done? If not: Before I plot the device I cannot know what device it will be, so I thought about a check via capabilities():
>> 
>> if (any(names(capabilities()) == "X11")) {
>> 	X11(title = title)
>> }
>> else if (any(names(capabilities)) == "windows") {
>> 	windows(title = title)
>> } else {
>> 	quartz(title = title)
>> }
>> 
>> I want to have a safe method, which works on each OS R can run. How would you solve the problem?
> 
> Use dev.new() rather than picking a particular device.  If all the possible devices support the "title" argument, then
> 
> dev.new(title=title)
> 
> will be fine.  If you might need more customization (or want to protect against a user who chooses a device that doesn't have "title" as an argument), use getOption("device") to examine the call that will be used.
> 
> Duncan Murdoch
> 


From smartpink111 at yahoo.com  Sat Jul 13 17:18:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 13 Jul 2013 08:18:43 -0700 (PDT)
Subject: [R] simplify a dataframe
In-Reply-To: <51E05CC2.3020202@cirad.fr>
References: <51E05CC2.3020202@cirad.fr>
Message-ID: <1373728723.14308.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
"when the value of Debut of lines i = value Fin of lines i-1"
That part is not clear esp. when it is looked upon with the expected output (df2).? Also, in your example dataset:

df1$contrat[grep("^CDD",df1$contrat)]
#[1] "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad"
#[4] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"? "CDD d?tach? ext. Cirad"
#[7] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"? "CDD d?tach? ext. Cirad"
##Looks like there are extra spaces in some of them.? I guess these are the same
df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad"


I tried this:
indx<-as.numeric(interaction(df1[,1:6],drop=FALSE))

?df1New<- df1
res2<-unique(within(df1New,{Debut<-ave(seq_along(indx),indx,FUN=function(x) Debut[head(x,1)]);Fin<- ave(seq_along(indx),indx,FUN=function(x) Fin[tail(x,1)])}))
?row.names(res2)<- 1:nrow(res2)

res2[,c(1,2,7:8)]
?? Matricule??? Nom????? Debut??????? Fin
1????????? 1? VERON 24/01/1995 31/12/1997
2????????? 6 BENARD 02/02/1995 12/03/1995
3????????? 6 BENARD 13/03/1995 31/01/1996 ###here not correct
4????????? 8 DALNIC 24/01/1995 31/08/1995
5????????? 8 DALNIC 01/09/1995 29/02/2000
6??????? 934? FORNI 26/01/1995 31/08/2001
7??????? 934? FORNI 01/09/2001 31/08/2004
8??????? 934? FORNI 01/09/2004 31/08/2007
9??????? 934? FORNI 01/09/2007 04/09/2012
10?????? 934? FORNI 05/09/2012 31/12/4712


df2[,c(1,2,7:8)]
?? Mat??? Nom????? Debut??????? Fin
1??? 1? VERON 24/01/1995 31/12/1997
2??? 6 BENARD 02/02/1995 12/03/1995
3??? 6 BENARD 13/03/1995 30/06/1995
4??? 6 BENARD 01/01/1996 31/01/1996 #missing this row 
5??? 8 DALNIC 24/01/1995 31/08/1995
6??? 8 DALNIC 01/09/1995 29/02/2000
7? 934? FORNI 26/01/1995 31/08/2001
8? 934? FORNI 01/09/2001 31/08/2004
9? 934? FORNI 01/09/2004 31/08/2007
10 934? FORNI 01/09/2007 04/09/2012
11 934? FORNI 05/09/2012 31/12/4712


Here, the dates look similar to the ones on df2 except for one row in df2.

A.K.




----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: R help <r-help at r-project.org>
Cc: 
Sent: Friday, July 12, 2013 3:45 PM
Subject: [R] simplify a dataframe

Hello

I have the following problem : group the lines of a dataframe when no 
information change (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays) 
and when the value of Debut of lines i = value Fin of lines i-1
I can obtain it with a do loop. Is it possible to avoid the loop ?

The dataframe initial is df1
dput(df1)
structure(list(Matricule = c(1L, 1L, 1L, 6L, 6L, 6L, 6L, 6L,
6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L), Nom = c("VERON", "VERON", "VERON", "BENARD",
"BENARD", "BENARD", "BENARD", "BENARD", "BENARD", "DALNIC", "DALNIC",
"DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI"), Sexe = c("F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin"), DateNaissance = c("02/09/1935",
"02/09/1935", "02/09/1935", "01/04/1935", "01/04/1935", "01/04/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961"), contrat = c("CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun"), Pays = c("France", "France", "France", "Philippines",
"Philippines", "Philippines", "France", "France", "France", "France",
"France", "Martinique", "Martinique", "Martinique", "Martinique",
"Martinique", "Martinique", "Martinique", "Cameroun", "Cameroun",
"Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun",
"Cameroun", "France", "France", "France", "France", "France",
"France", "France", "Congo", "Congo", "Congo", "Congo", "Congo",
"Congo", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon",
"Congo", "Congo"), Debut = c("24/01/1995", "01/05/1997", "31/12/1997",
"02/02/1995", "28/02/1995", "01/03/1995", "13/03/1995", "01/01/1996",
"31/01/1996", "24/01/1995", "01/07/1995", "01/09/1995", "01/07/1997",
"01/01/1998", "01/08/1998", "01/01/2000", "17/01/2000", "29/02/2000",
"26/01/1995", "01/07/1996", "16/09/1997", "01/01/1998", "01/07/1998",
"04/11/1999", "01/01/2001", "01/04/2001", "31/08/2001", "01/09/2001",
"02/09/2001", "01/12/2001", "01/02/2003", "01/04/2003", "01/01/2004",
"01/03/2004", "01/09/2004", "01/01/2005", "01/04/2005", "28/10/2006",
"01/01/2007", "01/04/2007", "01/09/2007", "01/01/2009", "01/04/2009",
"01/01/2010", "01/01/2011", "01/04/2011", "05/09/2012", "01/01/2013"
), Fin = c("30/04/1997", "30/12/1997", "31/12/1997", "27/02/1995",
"28/02/1995", "12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996",
"30/06/1995", "31/08/1995", "30/06/1997", "31/12/1997", "31/07/1998",
"31/12/1999", "16/01/2000", "28/02/2000", "29/02/2000", "30/06/1996",
"15/09/1997", "31/12/1997", "30/06/1998", "03/11/1999", "31/12/2000",
"31/03/2001", "30/08/2001", "31/08/2001", "01/09/2001", "30/11/2001",
"31/01/2003", "31/03/2003", "31/12/2003", "29/02/2004", "31/08/2004",
"31/12/2004", "31/03/2005", "27/10/2006", "31/12/2006", "31/03/2007",
"31/08/2007", "31/12/2008", "31/03/2009", "31/12/2009", "31/12/2010",
"31/03/2011", "04/09/2012", "31/12/2012", "31/12/4712")), .Names = 
c("Matricule",
"Nom", "Sexe", "DateNaissance", "contrat", "Pays", "Debut", "Fin"
), class = "data.frame", row.names = c(NA, -48L))

The dataframe to be obtained is df2
dput(df2)
structure(list(Mat = c(1L, 6L, 6L, 6L, 8L, 8L, 934L, 934L, 934L,
934L, 934L), Nom = c("VERON", "BENARD", "BENARD", "BENARD", "DALNIC",
"DALNIC", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI"), Sexe = c("F?minin",
"Masculin", "Masculin", "Masculin", "F?minin", "F?minin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin"), DateNaissance = 
c("02/09/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961"
), contrat = c("CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDD d?tach? ext. Cirad", "CDI D?tach?s 
Autres",
"CDI D?tach?s Autres", "CDI commun", "CDI commun"), Pays = c("France",
"Philippines", "France", "France", "France", "Martinique", "Cameroun",
"France", "Congo", "Gabon", "Congo"), Debut = c("24/01/1995",
"02/02/1995", "13/03/1995", "01/01/1996", "24/01/1995", "01/09/1995",
"26/01/1995", "01/09/2001", "01/09/2004", "01/09/2007", "05/09/2012"
), Fin = c("31/12/1997", "12/03/1995", "30/06/1995", "31/01/1996",
"31/08/1995", "29/02/2000", "31/08/2001", "31/08/2004", "31/08/2007",
"04/09/2012", "31/12/4712")), .Names = c("Mat", "Nom", "Sexe",
"DateNaissance", "contrat", "Pays", "Debut", "Fin"), class = 
"data.frame", row.names = c(NA,
-11L))

Thank you for your help

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Jul 13 18:47:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 13 Jul 2013 09:47:48 -0700 (PDT)
Subject: [R] How to set panel data format
In-Reply-To: <51E17AA0.8060305@sapo.pt>
References: <12216303.443334.1373726304932.JavaMail.nabble@joe.nabble.com>
	<51E17AA0.8060305@sapo.pt>
Message-ID: <1373734068.52955.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,

as.integer(dat$COUNTRY) # would be the easiest (Rui's solution).

Other options could be also used:
library(plyr)
?as.integer(mapvalues(dat$COUNTRY,levels(dat$COUNTRY),seq(length(levels(dat$COUNTRY)))))
# [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4
#or
match(dat$COUNTRY,levels(dat$COUNTRY))
# [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4


#if `COUNTRY` is not factor

dat$COUNTRY<- as.character(dat$COUNTRY)
?as.integer(mapvalues(dat$COUNTRY,unique(dat$COUNTRY),seq(length(unique(dat$COUNTRY)))))
# [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4

#or (if it is sorted already)
?(seq_along(dat$COUNTRY)-1)%/%as.vector(table(dat$COUNTRY))+1
# [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 4 4 4 4 4
A.K.


----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: serenamasino at gmail.com
Cc: 'r-help' <r-help at r-project.org>
Sent: Saturday, July 13, 2013 12:04 PM
Subject: Re: [R] How to set panel data format

Hello,

It's better if you keep this on the list, the odds of getting more and 
better answers is greater.

Inline.

Em 13-07-2013 15:38, serenamasino at gmail.com escreveu:
> Hi Rui,
> thanks for your reply.
>
> No, my problem isn't one of reshaping. It is just that I want R to know I have a panel and not just cross sections or time series.
>
> In other words If I had cross section data:
>
> COUNTRY?  YEAR?  GDP
> Albania? ? ? ? 1999? ?  3
> Barbados? ? 1999? ?  5
> Congo? ? ? ? ? 1999? ?  1
> Denmark? ? 1999? ?  11
> etc.? ? ? ? ? ? ? ? ..? ? ? ? ? ?  ..
>
> My ID here is country, but every observation is a new cluster independent of each other, so I don't care to let R know because the ID is a unique identifier.
>
> Whereas if I have a panel
>
> COUNTRY?  YEAR?  GDP
> Albania? ? ? ? 1999? ? ? 3
> Albania? ? ? ? 2000? ? ? 3.5
> Albania? ? ? ? 2001? ? ? 3.7
> Albania? ? ? ? 2002? ? ? 4
> Albania? ? ? ? 2003? ? ? 4.5
> Barbados?  1999? ? ?  5
> Barbados?  2000? ? ?  5
> Barbados?  2001? ? ?  5.1
> Barbados?  2002? ? ?  4
> Barbados?  2003? ? ?  3
> Congo? ? ? ?  1999? ? ? 1
> Congo? ? ? ?  2000? ? ? 2
> Congo? ? ? ?  2001? ? ? 2
> Congo? ? ? ?  2002? ? ? 3
> Congo? ? ? ?  2003? ? ? 4
> Denmark? ? 1999? ?  11
> Denmark? ? 2000? ?  12
> Denmark? ? 2001? ?  13
> Denmark? ? 2002? ?  10
> Denmark? ? 2003? ?  10
> etc.? ? ? ? ? ? ? ? ..? ? ? ? ? ?  ..
>
> How am I going to tell R that Albania is one same ID for all the 5 years I have in the panel, in other words, Albania has to be identified by the same number in the "factor" vector which R codes it with. Then Barbados is ID 2 in all its years, Congo has ID 3 and so on.

R already does that, factors are coded as integers:

as.integer(dat$COUNTRY) # Albania is 1, etc


> In STATA, you sort 'by country year' and the program knows it is a panel of entities observed more than once over time.? But I am not sure how to let R know the same.
>
> In practice the reason why it is important to define where a country ends and where a new begins is because
>
> 1) if one creates lags of variables and the program doesn't know where the boundaries between countries are, the lag for the first year of Barbados in my previous example will be calculated using the last year of Albania, that is, the preceding country.

A way of doing this, equivalent to the previous line of code if the 
countries are grouped consecutively, is

cumsum(c(TRUE, dat$COUNTRY[-nrow(dat)] != dat$COUNTRY[-1L]))
>
> 2) I need to create countrydummies that take the value of 1 whenever a country ID is equal to 1, so if Albania has 5 years of observations and each of the year observations appears with a different ID, the country dummies will not be created. Instead if Albania has the same country identifier (1) for all the years in which it is observed, the country dummy will be the same and ==1 whenever Albania is the country observed

I doubt you need to create dummuies, R does it for you when you create a 
factor. internally, factors are coded as integers, so all you need is to 
coerce them to integer like I've said earlier.

Rui Barradas

>
> Hope this makes it clearer,
> Thanks,
> Serena
>
> _____________________________________
> Sent from http://r.789695.n4.nabble.com
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From wdunlap at tibco.com  Sat Jul 13 19:30:11 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sat, 13 Jul 2013 17:30:11 +0000
Subject: [R] Test for column equality across matrices
In-Reply-To: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>
References: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>
Message-ID: <E66794E69CFDE04D9A70842786030B931C321B26@PA-MBX01.na.tibco.com>

Try
   columnsOf <- function(mat) split(mat, col(mat))
   newB <- B[ , !is.element(columnsOf(B), columnsOf(A))]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Thiem Alrik
> Sent: Saturday, July 13, 2013 6:45 AM
> To: mailman, r-help
> Subject: [R] Test for column equality across matrices
> 
> Dear list,
> 
> I have two matrices
> 
> A <- matrix(t(expand.grid(c(1,2,3,4,5), 15, 16)), nrow = 3)
> B <- combn(16, 3)
> 
> Now I would like to exclude all columns from the 560 columns in B which are identical to
> any 1 of the 6 columns in A. How could I do this?
> 
> Many thanks and best wishes,
> 
> Alrik
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sat Jul 13 19:35:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 13 Jul 2013 10:35:28 -0700 (PDT)
Subject: [R] Test for column equality across matrices
In-Reply-To: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>
References: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>
Message-ID: <1373736928.76965.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
One way would be:
?which(apply(t(B),1,paste,collapse="")%in%apply(t(A),1,paste,collapse=""))
#[1] 105 196 274 340 395
B[,105]
#[1]? 1 15 16
?B[,196]
#[1]? 2 15 16
?B1<-B[,!apply(t(B),1,paste,collapse="")%in%apply(t(A),1,paste,collapse="")]
?dim(B1)
#[1]?? 3 555
?dim(B)
#[1]?? 3 560

#or
B2<-B[,is.na(match(interaction(as.data.frame(t(B))),interaction(as.data.frame(t(A)))))]
?identical(B1,B2)
#[1] TRUE


A.K.





----- Original Message -----
From: Thiem Alrik <thiem at sipo.gess.ethz.ch>
To: "mailman, r-help" <r-help at r-project.org>
Cc: 
Sent: Saturday, July 13, 2013 9:45 AM
Subject: [R] Test for column equality across matrices

Dear list,

I have two matrices

A <- matrix(t(expand.grid(c(1,2,3,4,5), 15, 16)), nrow = 3)
B <- combn(16, 3)

Now I would like to exclude all columns from the 560 columns in B which are identical to any 1 of the 6 columns in A. How could I do this?

Many thanks and best wishes,

Alrik

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Jul 13 19:56:33 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 13 Jul 2013 10:56:33 -0700 (PDT)
Subject: [R] Test for column equality across matrices
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C321B26@PA-MBX01.na.tibco.com>
References: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>
	<E66794E69CFDE04D9A70842786030B931C321B26@PA-MBX01.na.tibco.com>
Message-ID: <1373738193.31239.YahooMailNeo@web142603.mail.bf1.yahoo.com>

I tried it on a slightly bigger dataset:
A1 <- matrix(t(expand.grid(1:90, 15, 16)), nrow = 3)
B1 <- combn(90, 3)
which(is.element(columnsOf(B1), columnsOf(A1)))
# [1]? 1067? 4895? 8636 12291 15861 19347 22750 26071 29311 32471 35552 38555
#[13] 41481


which(apply(t(B1),1,paste,collapse="")%in%apply(t(A1),1,paste,collapse=""))
# [1]? 1067? 4895? 8636 12291 15861 19347 22750 26071 29311 32471 35552 38555
#[13] 41481 44331


B1[,44331]
#[1] 14 15 16


which(apply(t(A1),1,paste,collapse="")=="141516")
#[1] 14

B1New<-B1[,!apply(t(B1),1,paste,collapse="")%in%apply(t(A1),1,paste,collapse="")]
newB <- B1[ , !is.element(columnsOf(B1), columnsOf(A1))]
?identical(B1New,newB)
#[1] FALSE

?is.element(B1[,44331],A1[,14])
#[1] TRUE TRUE TRUE


?B1Sp<-columnsOf(B1)
B1Sp[[44331]]
#[1] 14 15 16
?A1Sp<- columnsOf(A1)
?A1Sp[[14]]
#[1] 14 15 16
?is.element(B1Sp[[44331]],A1Sp[[14]])
#[1] TRUE TRUE TRUE


A.K.



----- Original Message -----
From: William Dunlap <wdunlap at tibco.com>
To: Thiem Alrik <thiem at sipo.gess.ethz.ch>; "mailman, r-help" <r-help at r-project.org>
Cc: 
Sent: Saturday, July 13, 2013 1:30 PM
Subject: Re: [R] Test for column equality across matrices

Try
?  columnsOf <- function(mat) split(mat, col(mat))
?  newB <- B[ , !is.element(columnsOf(B), columnsOf(A))]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Thiem Alrik
> Sent: Saturday, July 13, 2013 6:45 AM
> To: mailman, r-help
> Subject: [R] Test for column equality across matrices
> 
> Dear list,
> 
> I have two matrices
> 
> A <- matrix(t(expand.grid(c(1,2,3,4,5), 15, 16)), nrow = 3)
> B <- combn(16, 3)
> 
> Now I would like to exclude all columns from the 560 columns in B which are identical to
> any 1 of the 6 columns in A. How could I do this?
> 
> Many thanks and best wishes,
> 
> Alrik
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From vesco.miloushev at gmail.com  Sat Jul 13 22:12:05 2013
From: vesco.miloushev at gmail.com (Vesco Miloushev)
Date: Sat, 13 Jul 2013 16:12:05 -0400
Subject: [R] "not all duplicated" question
Message-ID: <CAOQUD8nCR3UVRpSbJ_EmoriSB5U8b9ZLtm7UvrKdWAiFh7Y_jA@mail.gmail.com>

Hi,

I want to select elements which have duplicates by are not all duplicated.

Here is what I mean. Suppose I have a two column matrix with columns
"Country" and "Pet"


Country, Pet
------------------
France, Dog
France, Cat
France, Dog
Canada, Cat
Canada, Cat
Japan, Dog
Japan, Cat
Italy, Cat

I want to extract all the entries that are duplicated in column
"Country" but not ALL duplicated in column "Pet".

In this case I want

Country, Pet
------------------
France, Dog
France, Cat
France, Dog
Japan, Dog
Japan, Cat

Notice that I keep France, because not all are duplicated. If there
was no entry "France, Cat" then it all of the entries with "France"
would be eliminated.

Thanks for your help.


From jholtman at gmail.com  Sun Jul 14 00:32:36 2013
From: jholtman at gmail.com (jim holtman)
Date: Sat, 13 Jul 2013 18:32:36 -0400
Subject: [R] "not all duplicated" question
In-Reply-To: <CAOQUD8nCR3UVRpSbJ_EmoriSB5U8b9ZLtm7UvrKdWAiFh7Y_jA@mail.gmail.com>
References: <CAOQUD8nCR3UVRpSbJ_EmoriSB5U8b9ZLtm7UvrKdWAiFh7Y_jA@mail.gmail.com>
Message-ID: <CAAxdm-5n6j31u-DC02b8sYR3WA6yO-g9=Xh6Ra6sPhga-fcSfw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130713/23cfe08c/attachment.pl>

From rolf.turner at xtra.co.nz  Sun Jul 14 01:02:19 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sun, 14 Jul 2013 11:02:19 +1200
Subject: [R] Set window title for plot on any OS
In-Reply-To: <1AD963C5-3D00-4186-A020-31338C6FC1A4@uni-bonn.de>
References: <7F081E1D-3562-4B03-A38A-E9A5F3DA00EE@uni-bonn.de>
	<51E14AC5.2010004@gmail.com>
	<1AD963C5-3D00-4186-A020-31338C6FC1A4@uni-bonn.de>
Message-ID: <51E1DC7B.6040806@xtra.co.nz>



I think you ought to take a look at

     fortune("Lewis Carroll")

     cheers,

         Rolf Turner

On 14/07/13 01:45, Simon Zehnder wrote:
> Hi Duncan,
>
> thank you very much for your advice! That makes it all work.
>
> I check in addition for a "title" argument in the device via
>
> if (any(names(getOption("device")) == TRUE)) {
> 	dev.new(title = "title")
> }
>
> Thanks again!
>
> Simon
>
> On Jul 13, 2013, at 2:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 13-07-13 1:33 PM, Simon Zehnder wrote:
>>> Dear R-Users,
>>>
>>> I am writing a package using S4 classes. In the generic method "plot" I want to set the title for the plotting window as I will have several windows and window titles help the users to distinguish the graphics without putting a title into the plot itself (this can be done by users whenever they want)
>>>
>>> So I created a helper function .setDeviceTitle which I called after the plot has been done:
>>>
>>> ".setDeviceTitle" <- function(title = "title", dev = dev.cur()) {
>>> 	dev <- names(dev)[1]
>>> 	
>>> 	## check for OS ##
>>> 	if (dev == "windows") {
>>> 		windows(title = title)
>>> 	} else if (dev == "X11") {
>>> 		X11(title = title)
>>> 	} else {
>>> 		quartz(title = title)
>>> 	}
>>> }
>>>
>>> The result is a new device with the title in addition to the old. Is it possible to give a window a title after the plot has been done? If not: Before I plot the device I cannot know what device it will be, so I thought about a check via capabilities():
>>>
>>> if (any(names(capabilities()) == "X11")) {
>>> 	X11(title = title)
>>> }
>>> else if (any(names(capabilities)) == "windows") {
>>> 	windows(title = title)
>>> } else {
>>> 	quartz(title = title)
>>> }
>>>
>>> I want to have a safe method, which works on each OS R can run. How would you solve the problem?
>> Use dev.new() rather than picking a particular device.  If all the possible devices support the "title" argument, then
>>
>> dev.new(title=title)
>>
>> will be fine.  If you might need more customization (or want to protect against a user who chooses a device that doesn't have "title" as an argument), use getOption("device") to examine the call that will be used.
>>
>> Duncan Murdoch
>>


From smartpink111 at yahoo.com  Sun Jul 14 03:08:59 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 13 Jul 2013 18:08:59 -0700 (PDT)
Subject: [R] "not all duplicated" question
In-Reply-To: <CAOQUD8nCR3UVRpSbJ_EmoriSB5U8b9ZLtm7UvrKdWAiFh7Y_jA@mail.gmail.com>
References: <CAOQUD8nCR3UVRpSbJ_EmoriSB5U8b9ZLtm7UvrKdWAiFh7Y_jA@mail.gmail.com>
Message-ID: <1373764139.53671.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:
dat1<- read.table(text="
Country, Pet
France, Dog
France, Cat
France, Dog
Canada, Cat
Canada, Cat
Japan, Dog
Japan, Cat
Italy, Cat
",sep=",",header=TRUE,stringsAsFactors=FALSE)


?dat1[with(dat1,as.numeric(ave(Pet,Country,FUN=function(x) length(unique(x)))))>1,]
#? Country? Pet
#1? France? Dog
#2? France? Cat
#3? France? Dog
#6?? Japan? Dog
#7?? Japan? Cat
A.K.



----- Original Message -----
From: Vesco Miloushev <vesco.miloushev at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Saturday, July 13, 2013 4:12 PM
Subject: [R] "not all duplicated" question

Hi,

I want to select elements which have duplicates by are not all duplicated.

Here is what I mean. Suppose I have a two column matrix with columns
"Country" and "Pet"


Country, Pet
------------------
France, Dog
France, Cat
France, Dog
Canada, Cat
Canada, Cat
Japan, Dog
Japan, Cat
Italy, Cat

I want to extract all the entries that are duplicated in column
"Country" but not ALL duplicated in column "Pet".

In this case I want

Country, Pet
------------------
France, Dog
France, Cat
France, Dog
Japan, Dog
Japan, Cat

Notice that I keep France, because not all are duplicated. If there
was no entry "France, Cat" then it all of the entries with "France"
would be eliminated.

Thanks for your help.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From arne.henningsen at gmail.com  Sun Jul 14 07:59:47 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Sun, 14 Jul 2013 07:59:47 +0200
Subject: [R] 2SLS / TSLS / SEM non-linear
In-Reply-To: <1372611200313-4670619.post@n4.nabble.com>
References: <1371997068977-4670123.post@n4.nabble.com>
	<alpine.DEB.2.02.1306231951350.27866@paninaro.uibk.ac.at>
	<1372519144070-4670595.post@n4.nabble.com>
	<000101ce74e4$59393550$0bab9ff0$@mcmaster.ca>
	<CAErODj-Qdr_jAZeq2K2vXH865=qRCeRniU7k9UFfMXHNthq9gA@mail.gmail.com>
	<1372589483248-4670612.post@n4.nabble.com>
	<CAMTWbJgjtL6u8ftPSqTfbJcbTKOkf6qURHra3fvpnqC-oYF4Rg@mail.gmail.com>
	<1372611200313-4670619.post@n4.nabble.com>
Message-ID: <CAMTWbJj+VP62qAXy_zbvU_YBUs_TQfQabVZGv0x3+5f=GbnWuQ@mail.gmail.com>

Dear HC

On 30 June 2013 18:53, hck <hans-christian.krumholz at uni-ulm.de> wrote:
> Generally I would have the following equations X_i = IV3_i + IV4_i * Y_i
> applying for every company (i). In a first step, I am interested in
> estimating the relationship between X and Y: Y_i = a + b * X_i + u to
> ultimatly estimate X_i by substituting the Y_i and solving for X_i to be
> able to estimate the X_i by just IV3_i, IV4_i, and the a and b.
>
> Now, let's construct values from a sample of listed companies. In the
> capital market, I can observe IV3_i, IV4_i, and X_i. With these I calculate
> Y_i: Y_i = IV1_i + IV2_i * X_i (note: IV3 and IV4 are just a transformation
> of IV1 and IV2). Of course, I could rewrite this equation as Y_i = c + d *
> IV1_i + e * IV2_i * X_i + v. For a couple of observations, I have now
> combinations of X_i and Y_i to get the a and b coefficient by estimating Y_i
> = a + b * X_i + u.

It seems to me that this estimation is very simple:

myModel <- lm( Y ~ X )

but perhaps I did not completely understand your model specification.

Best,
Arne

--
Arne Henningsen
http://www.arne-henningsen.name


From waqas1518 at gmail.com  Sun Jul 14 07:49:56 2013
From: waqas1518 at gmail.com (waqas shafqat)
Date: Sun, 14 Jul 2013 10:49:56 +0500
Subject: [R] diallel analysis
Message-ID: <CADHyn5jqp9_HQy0EXR2+W3WXt4=s8CgRxH4MgM7eauF7AOJx1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/119cab38/attachment.pl>

From ruipbarradas at sapo.pt  Sun Jul 14 12:20:04 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 14 Jul 2013 11:20:04 +0100
Subject: [R] diallel analysis
In-Reply-To: <CADHyn5jqp9_HQy0EXR2+W3WXt4=s8CgRxH4MgM7eauF7AOJx1w@mail.gmail.com>
References: <CADHyn5jqp9_HQy0EXR2+W3WXt4=s8CgRxH4MgM7eauF7AOJx1w@mail.gmail.com>
Message-ID: <51E27B54.6090807@sapo.pt>

Hello,

Which package is it?
Maybe you need to install it. And after installing it, you need to load 
it in the R session. You do this with the following commands.


install.package(pkgname)  # do this only once

library(pkgname)  # do this every new R session


Hope this helps,

Rui Barradas

Em 14-07-2013 06:49, waqas shafqat escreveu:
> sir i could not find the plant breeding libraray in Rgui3.0.0
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Sun Jul 14 12:26:50 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 14 Jul 2013 11:26:50 +0100
Subject: [R] diallel analysis
In-Reply-To: <51E27B54.6090807@sapo.pt>
References: <CADHyn5jqp9_HQy0EXR2+W3WXt4=s8CgRxH4MgM7eauF7AOJx1w@mail.gmail.com>
	<51E27B54.6090807@sapo.pt>
Message-ID: <51E27CEA.8030609@sapo.pt>

Sorry,

It's the plural:

install.packages(pkgname)

Rui Barradas

Em 14-07-2013 11:20, Rui Barradas escreveu:
> Hello,
>
> Which package is it?
> Maybe you need to install it. And after installing it, you need to load
> it in the R session. You do this with the following commands.
>
>
> install.package(pkgname)  # do this only once
>
> library(pkgname)  # do this every new R session
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 14-07-2013 06:49, waqas shafqat escreveu:
>> sir i could not find the plant breeding libraray in Rgui3.0.0
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Sun Jul 14 12:42:35 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sun, 14 Jul 2013 12:42:35 +0200
Subject: [R] Set window title for plot on any OS
In-Reply-To: <51E1DC7B.6040806@xtra.co.nz>
References: <7F081E1D-3562-4B03-A38A-E9A5F3DA00EE@uni-bonn.de>
	<51E14AC5.2010004@gmail.com>
	<1AD963C5-3D00-4186-A020-31338C6FC1A4@uni-bonn.de>
	<51E1DC7B.6040806@xtra.co.nz>
Message-ID: <A196A512-F45C-41D8-8416-90608AFB7FF7@uni-bonn.de>

Haha, good point!

So, the correct code is:

any(names(formals(getOption("device"))) == "title") {
	dev.new(title = "title")
}

Thanks for correcting my approach Rolf!


Best 

Simon

On Jul 14, 2013, at 1:02 AM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:

> 
> 
> I think you ought to take a look at
> 
>    fortune("Lewis Carroll")
> 
>    cheers,
> 
>        Rolf Turner
> 
> On 14/07/13 01:45, Simon Zehnder wrote:
>> Hi Duncan,
>> 
>> thank you very much for your advice! That makes it all work.
>> 
>> I check in addition for a "title" argument in the device via
>> 
>> if (any(names(getOption("device")) == TRUE)) {
>> 	dev.new(title = "title")
>> }
>> 
>> Thanks again!
>> 
>> Simon
>> 
>> On Jul 13, 2013, at 2:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>>> On 13-07-13 1:33 PM, Simon Zehnder wrote:
>>>> Dear R-Users,
>>>> 
>>>> I am writing a package using S4 classes. In the generic method "plot" I want to set the title for the plotting window as I will have several windows and window titles help the users to distinguish the graphics without putting a title into the plot itself (this can be done by users whenever they want)
>>>> 
>>>> So I created a helper function .setDeviceTitle which I called after the plot has been done:
>>>> 
>>>> ".setDeviceTitle" <- function(title = "title", dev = dev.cur()) {
>>>> 	dev <- names(dev)[1]
>>>> 	
>>>> 	## check for OS ##
>>>> 	if (dev == "windows") {
>>>> 		windows(title = title)
>>>> 	} else if (dev == "X11") {
>>>> 		X11(title = title)
>>>> 	} else {
>>>> 		quartz(title = title)
>>>> 	}
>>>> }
>>>> 
>>>> The result is a new device with the title in addition to the old. Is it possible to give a window a title after the plot has been done? If not: Before I plot the device I cannot know what device it will be, so I thought about a check via capabilities():
>>>> 
>>>> if (any(names(capabilities()) == "X11")) {
>>>> 	X11(title = title)
>>>> }
>>>> else if (any(names(capabilities)) == "windows") {
>>>> 	windows(title = title)
>>>> } else {
>>>> 	quartz(title = title)
>>>> }
>>>> 
>>>> I want to have a safe method, which works on each OS R can run. How would you solve the problem?
>>> Use dev.new() rather than picking a particular device.  If all the possible devices support the "title" argument, then
>>> 
>>> dev.new(title=title)
>>> 
>>> will be fine.  If you might need more customization (or want to protect against a user who chooses a device that doesn't have "title" as an argument), use getOption("device") to examine the call that will be used.
>>> 
>>> Duncan Murdoch
>>> 


From anupmenon at gmail.com  Sun Jul 14 13:30:27 2013
From: anupmenon at gmail.com (Anup Nandialath)
Date: Sun, 14 Jul 2013 15:30:27 +0400
Subject: [R] creating dummy variables based on conditions
Message-ID: <CA+toJsQoDCYbq-vkjYLasMjxVhZfsQeZzeiJvq5fS2zW+Yq-VQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/141cea24/attachment.pl>

From thiem at sipo.gess.ethz.ch  Sun Jul 14 15:32:22 2013
From: thiem at sipo.gess.ethz.ch (Thiem  Alrik)
Date: Sun, 14 Jul 2013 13:32:22 +0000
Subject: [R] Test for column equality across matrices
In-Reply-To: <1373738193.31239.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>
	<E66794E69CFDE04D9A70842786030B931C321B26@PA-MBX01.na.tibco.com>
	<1373738193.31239.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <11CF903D5D22CD42AF2157C898E05EB21D941573@MBX22.d.ethz.ch>

Dear William,

thanks a lot. I've found another nice alternative:

A <- matrix(t(expand.grid(c(1,2,3,4,5), 15, 16)), nrow = 3)
B <- combn(16, 3)

B.n <- B[, -which(duplicated(t(cbind(A, B)))) - ncol(A)]

Best wishes,
Alrik


-----Urspr?ngliche Nachricht-----
Von: arun [mailto:smartpink111 at yahoo.com] 
Gesendet: Samstag, 13. Juli 2013 19:57
An: William Dunlap
Cc: mailman, r-help; Thiem Alrik
Betreff: Re: [R] Test for column equality across matrices

I tried it on a slightly bigger dataset:
A1 <- matrix(t(expand.grid(1:90, 15, 16)), nrow = 3)
B1 <- combn(90, 3)
which(is.element(columnsOf(B1), columnsOf(A1)))
# [1]? 1067? 4895? 8636 12291 15861 19347 22750 26071 29311 32471 35552 38555
#[13] 41481


which(apply(t(B1),1,paste,collapse="")%in%apply(t(A1),1,paste,collapse=""))
# [1]? 1067? 4895? 8636 12291 15861 19347 22750 26071 29311 32471 35552 38555
#[13] 41481 44331


B1[,44331]
#[1] 14 15 16


which(apply(t(A1),1,paste,collapse="")=="141516")
#[1] 14

B1New<-B1[,!apply(t(B1),1,paste,collapse="")%in%apply(t(A1),1,paste,collapse="")]
newB <- B1[ , !is.element(columnsOf(B1), columnsOf(A1))]
?identical(B1New,newB)
#[1] FALSE

?is.element(B1[,44331],A1[,14])
#[1] TRUE TRUE TRUE


?B1Sp<-columnsOf(B1)
B1Sp[[44331]]
#[1] 14 15 16
?A1Sp<- columnsOf(A1)
?A1Sp[[14]]
#[1] 14 15 16
?is.element(B1Sp[[44331]],A1Sp[[14]])
#[1] TRUE TRUE TRUE


A.K.



----- Original Message -----
From: William Dunlap <wdunlap at tibco.com>
To: Thiem Alrik <thiem at sipo.gess.ethz.ch>; "mailman, r-help" <r-help at r-project.org>
Cc: 
Sent: Saturday, July 13, 2013 1:30 PM
Subject: Re: [R] Test for column equality across matrices

Try
?  columnsOf <- function(mat) split(mat, col(mat))
?  newB <- B[ , !is.element(columnsOf(B), columnsOf(A))]

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Thiem Alrik
> Sent: Saturday, July 13, 2013 6:45 AM
> To: mailman, r-help
> Subject: [R] Test for column equality across matrices
> 
> Dear list,
> 
> I have two matrices
> 
> A <- matrix(t(expand.grid(c(1,2,3,4,5), 15, 16)), nrow = 3)
> B <- combn(16, 3)
> 
> Now I would like to exclude all columns from the 560 columns in B which are identical to
> any 1 of the 6 columns in A. How could I do this?
> 
> Many thanks and best wishes,
> 
> Alrik
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From thiem at sipo.gess.ethz.ch  Sun Jul 14 15:48:10 2013
From: thiem at sipo.gess.ethz.ch (Thiem  Alrik)
Date: Sun, 14 Jul 2013 13:48:10 +0000
Subject: [R] Matrix column flip when recycled
Message-ID: <11CF903D5D22CD42AF2157C898E05EB21D941597@MBX22.d.ethz.ch>

Dear list,

I have a matrix M.1 (30x2) into which I would like to paste another matrix M.2 (10x2) three times. However, the columns get flipped in every odd-numbered recycle run. How can I avoid this behavior?

M.1 <- matrix(numeric(30*2), ncol = 2)
M.2 <- t(combn(1:5, 2))
M.1[, 1:2] <- M.2

Many thanks for help,

Alrik


From j.e.kelly at student.liv.ac.uk  Sun Jul 14 15:30:53 2013
From: j.e.kelly at student.liv.ac.uk (JenPool)
Date: Sun, 14 Jul 2013 06:30:53 -0700 (PDT)
Subject: [R] nls power law help
Message-ID: <1373808653512-4671526.post@n4.nabble.com>

Hi,

I am trying to use a power law y=bx^a as a nls model as below, however I
keep getting 'singular gradient' error. I have tried multiple different
starting values but always get an error. 

> x2 <-
> c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,
> 31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63)
> y2 <- 
> c(2326.0,2635.5,2875.0,3096.0,3265.5,3455.0,3618.0,3785.0,3936.0,4087.0,4214.0,4355.0,
> 4488.0,4615.0,4735.5,4866.0,4981.5,5089.5,5202.5,5318.0,5438.0,5537.0,5636.5,5748.0,5853.0,
> 5967.0,6042.5,6166.0,6259.5,6358.0,6452.0,6551.5,6645.0,6742.5,6839.0,6930.0,7026.0,7123.0,
> 7207.0,7300.0,7387.5,7481.5,7574.5,7663.0,7752.0,7831.5,7915.0,8005.0,
> 8091.5,8183.5,8260.0,8360.0,8441.0,8525.5,8606.0,8691.5,8779.0,8863.5,8941.5,9030.0,9108.0,9195.0,9271.0)


> df <- dataframe(x=x2,y=y2)
> model <- nls(y2~b*x2*exp(a),data=data2,start=list(a=0.7,b=3000))
Error in nlsModel(formula, mf, start, wts) : 
  singular gradient matrix at initial parameter estimates
In addition: Warning messages:
1: In min(x) : no non-missing arguments to min; returning Inf
2: In max(x) : no non-missing arguments to max; returning -Inf

Any ideas?

Thanks,
Jen



--
View this message in context: http://r.789695.n4.nabble.com/nls-power-law-help-tp4671526.html
Sent from the R help mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Sun Jul 14 16:01:38 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 14 Jul 2013 15:01:38 +0100
Subject: [R] creating dummy variables based on conditions
In-Reply-To: <CA+toJsQoDCYbq-vkjYLasMjxVhZfsQeZzeiJvq5fS2zW+Yq-VQ@mail.gmail.com>
References: <CA+toJsQoDCYbq-vkjYLasMjxVhZfsQeZzeiJvq5fS2zW+Yq-VQ@mail.gmail.com>
Message-ID: <51E2AF42.1010708@sapo.pt>

Hello,

Your data seems to be of class 'matrix'. The following code needs it to 
be a data.frame.

dat <- as.data.frame(your input matrix)

res <- do.call(rbind, lapply(split(dat, list(dat$id, dat$year)), 
function(x){
	x$ans <- if(any(x$var == 1)) 1 else 0
	x}))
rownames(res) <- NULL
res


Hope this helps,

Rui Barradas

Em 14-07-2013 12:30, Anup Nandialath escreveu:
> Hello everyone,
>
> I have a dataset which includes the first three variables from the demo
> data below (year, id and var). I need to create the new variable ans as
> follows
>
> If var=1, then for each year (where var=1), i need to create a new dummy
> ans which takes the value of 1 for all corresponding id's where an instance
> of one was recorded. Sample data with the output is shown below.
>
>      year    id var ans
> [1,] 2010  1   1   1
> [2,] 2010  2   0   0
> [3,] 2010  1   0   1
> [4,] 2010  1   0   1
> [5,] 2011  2   1   1
> [6,] 2011  2   0   1
> [7,] 2011  1   0   0
> [8,] 2011  1   0   0
>
> Any help on how to achieve this is much appreciated.
>
> Thanks
> Anup
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Sun Jul 14 17:11:40 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sun, 14 Jul 2013 16:11:40 +0100
Subject: [R] nls power law help
In-Reply-To: <1373808653512-4671526.post@n4.nabble.com>
References: <1373808653512-4671526.post@n4.nabble.com>
Message-ID: <51E2BFAC.1010008@stats.ox.ac.uk>

On 14/07/2013 14:30, JenPool wrote:
> Hi,
>
> I am trying to use a power law y=bx^a as a nls model as below, however I
> keep getting 'singular gradient' error. I have tried multiple different
> starting values but always get an error.

That is not the model you tried to fit. b*x*exp(a) is always 
over-parametrized.

There are lots of errors in your code: please do try it before posting. 
  Maybe you intended

 > df <- data.frame(x=x2,y=y2)
 > nls(y ~ b*x^a, data = df, start = list(a=0.7,b=3000))
Nonlinear regression model
   model: y ~ b * x^a
    data: df
         a         b
    0.4312 1506.0120

I've no idea where you got your starting values from: taking logs

 > lm(log(y) ~ log(x), data = df)

Call:
lm(formula = log(y) ~ log(x), data = df)

Coefficients:
(Intercept)       log(x)
      7.4999       0.3776

suggests a=0.38 and b=exp(7.5)=1800


>
>> x2 <-
>> c(1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,
>> 31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63)
>> y2 <-
>> c(2326.0,2635.5,2875.0,3096.0,3265.5,3455.0,3618.0,3785.0,3936.0,4087.0,4214.0,4355.0,
>> 4488.0,4615.0,4735.5,4866.0,4981.5,5089.5,5202.5,5318.0,5438.0,5537.0,5636.5,5748.0,5853.0,
>> 5967.0,6042.5,6166.0,6259.5,6358.0,6452.0,6551.5,6645.0,6742.5,6839.0,6930.0,7026.0,7123.0,
>> 7207.0,7300.0,7387.5,7481.5,7574.5,7663.0,7752.0,7831.5,7915.0,8005.0,
>> 8091.5,8183.5,8260.0,8360.0,8441.0,8525.5,8606.0,8691.5,8779.0,8863.5,8941.5,9030.0,9108.0,9195.0,9271.0)
>
>
>> df <- dataframe(x=x2,y=y2)
>> model <- nls(y2~b*x2*exp(a),data=data2,start=list(a=0.7,b=3000))
> Error in nlsModel(formula, mf, start, wts) :
>    singular gradient matrix at initial parameter estimates
> In addition: Warning messages:
> 1: In min(x) : no non-missing arguments to min; returning Inf
> 2: In max(x) : no non-missing arguments to max; returning -Inf
>
> Any ideas?
>
> Thanks,
> Jen
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/nls-power-law-help-tp4671526.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smartpink111 at yahoo.com  Sun Jul 14 17:23:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 14 Jul 2013 08:23:15 -0700 (PDT)
Subject: [R] Matrix column flip when recycled
In-Reply-To: <11CF903D5D22CD42AF2157C898E05EB21D941597@MBX22.d.ethz.ch>
References: <11CF903D5D22CD42AF2157C898E05EB21D941597@MBX22.d.ethz.ch>
Message-ID: <1373815395.27480.YahooMailNeo@web142604.mail.bf1.yahoo.com>


library(plyr)
M.1[,1:2]<-do.call(rbind,alply(replicate(3,M.2),3,function(x) x))
#or

M.1[,1:2]<-matrix(aperm(replicate(3,M.2),c(1,3,2)),ncol=2)

A.K.




----- Original Message -----
From: Thiem Alrik <thiem at sipo.gess.ethz.ch>
To: "mailman, r-help" <r-help at r-project.org>
Cc: 
Sent: Sunday, July 14, 2013 9:48 AM
Subject: [R] Matrix column flip when recycled

Dear list,

I have a matrix M.1 (30x2) into which I would like to paste another matrix M.2 (10x2) three times. However, the columns get flipped in every odd-numbered recycle run. How can I avoid this behavior?

M.1 <- matrix(numeric(30*2), ncol = 2)
M.2 <- t(combn(1:5, 2))
M.1[, 1:2] <- M.2

Many thanks for help,

Alrik

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sun Jul 14 17:49:19 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 14 Jul 2013 08:49:19 -0700
Subject: [R] Matrix column flip when recycled
In-Reply-To: <11CF903D5D22CD42AF2157C898E05EB21D941597@MBX22.d.ethz.ch>
References: <11CF903D5D22CD42AF2157C898E05EB21D941597@MBX22.d.ethz.ch>
Message-ID: <6af44187-2d56-4294-8bb6-bfddfc0f2eaf@email.android.com>

Only vectors recycle. If you don't want the behaviour if the matrix to reflect that of the underlying vector then don't use recycling. Instead use indexing.

M.1 <- M.2[rep(1:5,3),]
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Thiem  Alrik <thiem at sipo.gess.ethz.ch> wrote:

>Dear list,
>
>I have a matrix M.1 (30x2) into which I would like to paste another
>matrix M.2 (10x2) three times. However, the columns get flipped in
>every odd-numbered recycle run. How can I avoid this behavior?
>
>M.1 <- matrix(numeric(30*2), ncol = 2)
>M.2 <- t(combn(1:5, 2))
>M.1[, 1:2] <- M.2
>
>Many thanks for help,
>
>Alrik
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Jul 14 18:07:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 14 Jul 2013 09:07:25 -0700 (PDT)
Subject: [R] creating dummy variables based on conditions
In-Reply-To: <CA+toJsQoDCYbq-vkjYLasMjxVhZfsQeZzeiJvq5fS2zW+Yq-VQ@mail.gmail.com>
References: <CA+toJsQoDCYbq-vkjYLasMjxVhZfsQeZzeiJvq5fS2zW+Yq-VQ@mail.gmail.com>
Message-ID: <1373818045.64757.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
You could try this: (if I understand it correctly)
dat1<- read.table(text="
year??? id var ans
?2010? 1? 1? 1
?2010? 2? 0? 0
?2010? 1? 0? 1
2010? 1? 0? 1
?2011? 2? 1? 1
?2011? 2? 0? 1
?2011? 1? 0? 0
2011? 1? 0? 0
",sep="",header=TRUE,stringsAsFactors=FALSE)

dat1$newres<-with(dat1,ave(var,id,year,FUN=function(x) any(x==1)*1))
?dat1
#? year id var ans newres
#1 2010? 1?? 1?? 1????? 1
#2 2010? 2?? 0?? 0????? 0
#3 2010? 1?? 0?? 1????? 1
#4 2010? 1?? 0?? 1????? 1
#5 2011? 2?? 1?? 1????? 1
#6 2011? 2?? 0?? 1????? 1
#7 2011? 1?? 0?? 0????? 0
#8 2011? 1?? 0?? 0????? 0

A.K.

----- Original Message -----
From: Anup Nandialath <anupmenon at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Sunday, July 14, 2013 7:30 AM
Subject: [R] creating dummy variables based on conditions

Hello everyone,

I have a dataset which includes the first three variables from the demo
data below (year, id and var). I need to create the new variable ans as
follows

If var=1, then for each year (where var=1), i need to create a new dummy
ans which takes the value of 1 for all corresponding id's where an instance
of one was recorded. Sample data with the output is shown below.

? ? year? ? id var ans
[1,] 2010? 1?  1?  1
[2,] 2010? 2?  0?  0
[3,] 2010? 1?  0?  1
[4,] 2010? 1?  0?  1
[5,] 2011? 2?  1?  1
[6,] 2011? 2?  0?  1
[7,] 2011? 1?  0?  0
[8,] 2011? 1?  0?  0

Any help on how to achieve this is much appreciated.

Thanks
Anup

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From michel.arnaud at cirad.fr  Sun Jul 14 18:17:50 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sun, 14 Jul 2013 18:17:50 +0200
Subject: [R] simplify a dataframe
In-Reply-To: <1373728723.14308.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <51E05CC2.3020202@cirad.fr>
	<1373728723.14308.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <51E2CF2E.1070704@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/8d3dc8ca/attachment.pl>

From dwinsemius at comcast.net  Sun Jul 14 18:24:44 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Jul 2013 09:24:44 -0700
Subject: [R] Set window title for plot on any OS
In-Reply-To: <A196A512-F45C-41D8-8416-90608AFB7FF7@uni-bonn.de>
References: <7F081E1D-3562-4B03-A38A-E9A5F3DA00EE@uni-bonn.de>
	<51E14AC5.2010004@gmail.com>
	<1AD963C5-3D00-4186-A020-31338C6FC1A4@uni-bonn.de>
	<51E1DC7B.6040806@xtra.co.nz>
	<A196A512-F45C-41D8-8416-90608AFB7FF7@uni-bonn.de>
Message-ID: <39E25325-537D-4ABF-B2C0-32BF41CF2664@comcast.net>


On Jul 14, 2013, at 3:42 AM, Simon Zehnder wrote:

> Haha, good point!
> 
> So, the correct code is:
> 
> any(names(formals(getOption("device"))) == "title") {
> 	dev.new(title = "title")
> }
> 

This might be easier to read:

"title" %in% names(formals(getOption("device")) )

-- 

David.
> Thanks for correcting my approach Rolf!
> 
> 
> Best 
> 
> Simon
> 
> On Jul 14, 2013, at 1:02 AM, Rolf Turner <rolf.turner at xtra.co.nz> wrote:
> 
>> 
>> 
>> I think you ought to take a look at
>> 
>>   fortune("Lewis Carroll")
>> 
>>   cheers,
>> 
>>       Rolf Turner
>> 
>> On 14/07/13 01:45, Simon Zehnder wrote:
>>> Hi Duncan,
>>> 
>>> thank you very much for your advice! That makes it all work.
>>> 
>>> I check in addition for a "title" argument in the device via
>>> 
>>> if (any(names(getOption("device")) == TRUE)) {
>>> 	dev.new(title = "title")
>>> }
>>> 
>>> Thanks again!
>>> 
>>> Simon
>>> 
>>> On Jul 13, 2013, at 2:40 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> 
>>>> On 13-07-13 1:33 PM, Simon Zehnder wrote:
>>>>> Dear R-Users,
>>>>> 
>>>>> I am writing a package using S4 classes. In the generic method "plot" I want to set the title for the plotting window as I will have several windows and window titles help the users to distinguish the graphics without putting a title into the plot itself (this can be done by users whenever they want)
>>>>> 
>>>>> So I created a helper function .setDeviceTitle which I called after the plot has been done:
>>>>> 
>>>>> ".setDeviceTitle" <- function(title = "title", dev = dev.cur()) {
>>>>> 	dev <- names(dev)[1]
>>>>> 	
>>>>> 	## check for OS ##
>>>>> 	if (dev == "windows") {
>>>>> 		windows(title = title)
>>>>> 	} else if (dev == "X11") {
>>>>> 		X11(title = title)
>>>>> 	} else {
>>>>> 		quartz(title = title)
>>>>> 	}
>>>>> }
>>>>> 
>>>>> The result is a new device with the title in addition to the old. Is it possible to give a window a title after the plot has been done? If not: Before I plot the device I cannot know what device it will be, so I thought about a check via capabilities():
>>>>> 
>>>>> if (any(names(capabilities()) == "X11")) {
>>>>> 	X11(title = title)
>>>>> }
>>>>> else if (any(names(capabilities)) == "windows") {
>>>>> 	windows(title = title)
>>>>> } else {
>>>>> 	quartz(title = title)
>>>>> }
>>>>> 
>>>>> I want to have a safe method, which works on each OS R can run. How would you solve the problem?
>>>> Use dev.new() rather than picking a particular device.  If all the possible devices support the "title" argument, then
>>>> 
>>>> dev.new(title=title)
>>>> 
>>>> will be fine.  If you might need more customization (or want to protect against a user who chooses a device that doesn't have "title" as an argument), use getOption("device") to examine the call that will be used.
>>>> 
>>>> Duncan Murdoch
>>>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From lidarfly at yahoo.com  Sun Jul 14 18:48:22 2013
From: lidarfly at yahoo.com (Houhou Li)
Date: Sun, 14 Jul 2013 09:48:22 -0700 (PDT)
Subject: [R] Need help to read the data file like this
Message-ID: <1373820502.67991.YahooMailBasic@web162506.mail.bf1.yahoo.com>

Hi,

I have several really big data files in csv format like this: the first line is the header, the second to fourth lines have info about the file and are the lines I need to skip (data in 2-4th lines are not correspoding to variable names in the hearder), from the fifth line, real data begins, but the last line is not a data line, it's the string "Done" instead of normal EOF character. All data is numeric. I tried to use read.table(), read.csv() with colClasses="numeric" and scan(), but couldn't make them work. Can anyone help me? How can I get rid of the last line "Done" automatically? I would like to use R script to do it automatically, not to do formatting in Excel then read back to R. Thank you very much, here is an example of the data:

Tag,X,Y,BlobRegion,swaths,fr_int_20,fr_int_60,i60,RawTothgt,RawHtlc,RawRad20,RawRad40,RawRad60,RawRad80,CCV,BlobPerim,n_pts,n_pts_i255,vts,vts2,vtg,home,sum_ht,sum_ht_sq,dcch,dcch2,nb_ccv,n_nb,nb_sum_hts,nb_sum_hts2,z_tip_dist,nb_MassLen,n_f_rtns20,n_f_rtns60,max_fl_pt_count,loreyrawht,p00ile_cm,p25ile_cm,p50ile_cm,p75ile_cm,iq25,iq50,iq75,mean_intns
01_24_2013.001,SF12
? ? ? ? 5413
???509627.82,? 4869704.98,???509999.83,? 4869999.98
123,509692.55,4869856.64,18,0,80.53,81.03,84,36.2100,17.1521,4.0359,4.0359,3.8881,2.9217,1737.13,31.42,210,210,0.828,0.955,0.281,28.50,5746.46,163727.12,0.764,1.000,1147.23,33,769.16,19024.42,0.01,0.09,174,163,174,34.90,140,2369,2849,3157,33,81,110,71.59
159,509679.19,4869855.54,18,0,77.62,78.97,75,30.4000,11.2000,2.5319,2.5129,2.3365,1.8315,3248.82,21.42,90,90,0.877,0.936,0.589,22.91,2000.74,46861.45,0.691,0.999,1772.06,14,365.47,10233.32,0.04,0.68,81,66,81,33.29,905,1869,2272,2633,55,82,98,71.62
.......

Done

Yuzhen


From ligges at statistik.tu-dortmund.de  Sun Jul 14 19:09:17 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 14 Jul 2013 19:09:17 +0200
Subject: [R] R installation Problem
In-Reply-To: <CAE5FLRX6USxHJ1TsH_b2ahKgbhO0vCDTgm0pDtqG3PPSCpcJdA@mail.gmail.com>
References: <CAE5FLRX6USxHJ1TsH_b2ahKgbhO0vCDTgm0pDtqG3PPSCpcJdA@mail.gmail.com>
Message-ID: <51E2DB3D.4010408@statistik.tu-dortmund.de>



On 08.07.2013 11:42, sridhar srinivasan wrote:
> Dear R Developers,
>
> I have two doubts related to R
>
> 1. i try to install R package 3.0 in my linux system ./configure.
> it gives Error as
> configure: error: --with-readline=yes (default) and headers/libs are not
> available

Read the R Installation manual and procive libreadline.


> 2. This is related to library
> i am trying to install the library(cummeRbund) in differeent R version in
> another system
> it shows Error as
>
>> source("http://bioconductor.org/biocLite.R")
> Error in file(con, "r") : cannot open the connection
> In addition: Warning message:
> In file(con, "r") : unable to resolve 'bioconductor.org'
>> biocLite("cummeRbund")
> Error: could not find function "biocLite"

No proper internet connection?

best,
Uwe Ligges




> Could anybody suggest on the same..
>
> Thanks
> Sridhar
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From anupmenon at gmail.com  Sun Jul 14 19:02:03 2013
From: anupmenon at gmail.com (Anup Nandialath)
Date: Sun, 14 Jul 2013 21:02:03 +0400
Subject: [R] creating dummy variables based on conditions
In-Reply-To: <1373818045.64757.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CA+toJsQoDCYbq-vkjYLasMjxVhZfsQeZzeiJvq5fS2zW+Yq-VQ@mail.gmail.com>
	<1373818045.64757.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CA+toJsRc5t=AvkOGJ1T76G7m7omuYiU+FSP-H+nXxMJckvXvjg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/41b52925/attachment.pl>

From dwinsemius at comcast.net  Sun Jul 14 19:57:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Jul 2013 10:57:46 -0700
Subject: [R] Need help to read the data file like this
In-Reply-To: <1373820502.67991.YahooMailBasic@web162506.mail.bf1.yahoo.com>
References: <1373820502.67991.YahooMailBasic@web162506.mail.bf1.yahoo.com>
Message-ID: <5C79F2E0-6F69-41D4-A4C3-69AD78C666BC@comcast.net>


On Jul 14, 2013, at 9:48 AM, Houhou Li wrote:

> Hi,
> 
> I have several really big data files in csv format like this: the first line is the header, the second to fourth lines have info about the file and are the lines I need to skip (data in 2-4th lines are not correspoding to variable names in the hearder), from the fifth line, real data begins, but the last line is not a data line, it's the string "Done" instead of normal EOF character. All data is numeric. I tried to use read.table(), read.csv() with colClasses="numeric" and scan(), but couldn't make them work. Can anyone help me? How can I get rid of the last line "Done" automatically? I would like to use R script to do it automatically, not to do formatting in Excel then read back to R. Thank you very much, here is an example of the data:

Deleting the last line in Excel would not make sense unless this is already data in Excel. Better would be to sue a text editor. Less likely to corrupt the data.

> 
> Tag,X,Y,BlobRegion,swaths,fr_int_20,fr_int_60,i60,RawTothgt,RawHtlc,RawRad20,RawRad40,RawRad60,RawRad80,CCV,BlobPerim,n_pts,n_pts_i255,vts,vts2,vtg,home,sum_ht,sum_ht_sq,dcch,dcch2,nb_ccv,n_nb,nb_sum_hts,nb_sum_hts2,z_tip_dist,nb_MassLen,n_f_rtns20,n_f_rtns60,max_fl_pt_count,loreyrawht,p00ile_cm,p25ile_cm,p50ile_cm,p75ile_cm,iq25,iq50,iq75,mean_intns
> 01_24_2013.001,SF12
>         5413
>    509627.82,  4869704.98,   509999.83,  4869999.98
> 123,509692.55,4869856.64,18,0,80.53,81.03,84,36.2100,17.1521,4.0359,4.0359,3.8881,2.9217,1737.13,31.42,210,210,0.828,0.955,0.281,28.50,5746.46,163727.12,0.764,1.000,1147.23,33,769.16,19024.42,0.01,0.09,174,163,174,34.90,140,2369,2849,3157,33,81,110,71.59
> 159,509679.19,4869855.54,18,0,77.62,78.97,75,30.4000,11.2000,2.5319,2.5129,2.3365,1.8315,3248.82,21.42,90,90,0.877,0.936,0.589,22.91,2000.74,46861.45,0.691,0.999,1772.06,14,365.47,10233.32,0.04,0.68,81,66,81,33.29,905,1869,2272,2633,55,82,98,71.62

Read the first line with readLines using n=1 saving as 'colnams'
Read the dat <- read.table( ...  with skip=4, sep=",", and fill = TRUE
Delete last line holding "Done" and a large number of NA's
names(dat) <- scan(text=colnams, what=character(0), sep="," )

(Tested. Expected results achieved.)
-- 
David


David Winsemius
Alameda, CA, USA


From michel.arnaud at cirad.fr  Sun Jul 14 20:19:25 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Sun, 14 Jul 2013 20:19:25 +0200
Subject: [R] simplify a dataframe
In-Reply-To: <51E2CF2E.1070704@cirad.fr>
References: <51E05CC2.3020202@cirad.fr>
	<1373728723.14308.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<51E2CF2E.1070704@cirad.fr>
Message-ID: <51E2EBAD.8020806@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/01d1e647/attachment.pl>

From wdunlap at tibco.com  Sun Jul 14 20:22:23 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 14 Jul 2013 18:22:23 +0000
Subject: [R] Test for column equality across matrices
In-Reply-To: <1373738193.31239.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <11CF903D5D22CD42AF2157C898E05EB21D93E407@MBX22.d.ethz.ch>
	<E66794E69CFDE04D9A70842786030B931C321B26@PA-MBX01.na.tibco.com>
	<1373738193.31239.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C323C78@PA-MBX01.na.tibco.com>

It looks like match() (and relatives like %in% and is.element) act a bit unpredictably
on lists when the list elements are vectors of numbers of different types.  If you match
integers to integers or doubles to doubles it works as expected, but when the types
don't match the results vary.  I would expect the following to give either c(1,2) or
c(NA,NA) but not c(1,NA):

> match( list( c(13L,15L,16L), c(14L,15L,16L)), list( c(13.,15.,16.), c(14.,15.,16.) ))
[1]  1 NA

It works when the list elements have the same type

> match( list( c(13L,15L,16L), c(14L,15L,16L)), list( c(13L,15L,16L), c(14L,15L,16L) ))
[1] 1 2
> match( list( c(13.,15.,16.), c(14.,15.,16.)), list( c(13.,15.,16.), c(14.,15.,16.) ))
[1] 1 2
> match( list( c(13.,15.,16.), c(14L,15L,16L)), list( c(13.,15.,16.), c(14L,15L,16L) ))
[1] 1 2

So - A and B should be coerced to have a common type ('storage.mode') before
comparing them.

By the way, the discrepency might happen because match() applied to lists might
be implemented by calling deparse on each element of each list and then using
the character method of match.  For sequential integers deparse uses colon notation;
e.g., c(14L,15L,16L) becomes the string "14:16".  But usually deparse puts an 'L' after
integers so they would never match with a double of the same value.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: arun [mailto:smartpink111 at yahoo.com]
> Sent: Saturday, July 13, 2013 10:57 AM
> To: William Dunlap
> Cc: R help; Thiem Alrik
> Subject: Re: [R] Test for column equality across matrices
> 
> I tried it on a slightly bigger dataset:
> A1 <- matrix(t(expand.grid(1:90, 15, 16)), nrow = 3)
> B1 <- combn(90, 3)
> which(is.element(columnsOf(B1), columnsOf(A1)))
> # [1]? 1067? 4895? 8636 12291 15861 19347 22750 26071 29311 32471 35552 38555
> #[13] 41481
> 
> 
> which(apply(t(B1),1,paste,collapse="")%in%apply(t(A1),1,paste,collapse=""))
> # [1]? 1067? 4895? 8636 12291 15861 19347 22750 26071 29311 32471 35552 38555
> #[13] 41481 44331
> 
> 
> B1[,44331]
> #[1] 14 15 16
> 
> 
> which(apply(t(A1),1,paste,collapse="")=="141516")
> #[1] 14
> 
> B1New<-B1[,!apply(t(B1),1,paste,collapse="")%in%apply(t(A1),1,paste,collapse="")]
> newB <- B1[ , !is.element(columnsOf(B1), columnsOf(A1))]
> ?identical(B1New,newB)
> #[1] FALSE
> 
> ?is.element(B1[,44331],A1[,14])
> #[1] TRUE TRUE TRUE
> 
> 
> ?B1Sp<-columnsOf(B1)
> B1Sp[[44331]]
> #[1] 14 15 16
> ?A1Sp<- columnsOf(A1)
> ?A1Sp[[14]]
> #[1] 14 15 16
> ?is.element(B1Sp[[44331]],A1Sp[[14]])
> #[1] TRUE TRUE TRUE
> 
> 
> A.K.
> 
> 
> 
> ----- Original Message -----
> From: William Dunlap <wdunlap at tibco.com>
> To: Thiem Alrik <thiem at sipo.gess.ethz.ch>; "mailman, r-help" <r-help at r-project.org>
> Cc:
> Sent: Saturday, July 13, 2013 1:30 PM
> Subject: Re: [R] Test for column equality across matrices
> 
> Try
> ?  columnsOf <- function(mat) split(mat, col(mat))
> ?  newB <- B[ , !is.element(columnsOf(B), columnsOf(A))]
> 
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
> 
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> > Of Thiem Alrik
> > Sent: Saturday, July 13, 2013 6:45 AM
> > To: mailman, r-help
> > Subject: [R] Test for column equality across matrices
> >
> > Dear list,
> >
> > I have two matrices
> >
> > A <- matrix(t(expand.grid(c(1,2,3,4,5), 15, 16)), nrow = 3)
> > B <- combn(16, 3)
> >
> > Now I would like to exclude all columns from the 560 columns in B which are identical
> to
> > any 1 of the 6 columns in A. How could I do this?
> >
> > Many thanks and best wishes,
> >
> > Alrik
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Sun Jul 14 20:34:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Jul 2013 11:34:35 -0700
Subject: [R] Need help to read the data file like this
In-Reply-To: <5C79F2E0-6F69-41D4-A4C3-69AD78C666BC@comcast.net>
References: <1373820502.67991.YahooMailBasic@web162506.mail.bf1.yahoo.com>
	<5C79F2E0-6F69-41D4-A4C3-69AD78C666BC@comcast.net>
Message-ID: <5DF8B1E2-A1D1-4F0C-A6ED-D96D8BC1E794@comcast.net>


On Jul 14, 2013, at 10:57 AM, David Winsemius wrote:

> 
> On Jul 14, 2013, at 9:48 AM, Houhou Li wrote:
> 
>> Hi,
>> 
>> I have several really big data files in csv format like this: the first line is the header, the second to fourth lines have info about the file and are the lines I need to skip (data in 2-4th lines are not correspoding to variable names in the hearder), from the fifth line, real data begins, but the last line is not a data line, it's the string "Done" instead of normal EOF character. All data is numeric. I tried to use read.table(), read.csv() with colClasses="numeric" and scan(), but couldn't make them work. Can anyone help me? How can I get rid of the last line "Done" automatically? I would like to use R script to do it automatically, not to do formatting in Excel then read back to R. Thank you very much, here is an example of the data:
> 
> Deleting the last line in Excel would not make sense unless this is already data in Excel. Better would be to sue a text editor. Less likely to corrupt the data.
> 
>> 
>> Tag,X,Y,BlobRegion,swaths,fr_int_20,fr_int_60,i60,RawTothgt,RawHtlc,RawRad20,RawRad40,RawRad60,RawRad80,CCV,BlobPerim,n_pts,n_pts_i255,vts,vts2,vtg,home,sum_ht,sum_ht_sq,dcch,dcch2,nb_ccv,n_nb,nb_sum_hts,nb_sum_hts2,z_tip_dist,nb_MassLen,n_f_rtns20,n_f_rtns60,max_fl_pt_count,loreyrawht,p00ile_cm,p25ile_cm,p50ile_cm,p75ile_cm,iq25,iq50,iq75,mean_intns
>> 01_24_2013.001,SF12
>>        5413
>>   509627.82,  4869704.98,   509999.83,  4869999.98
>> 123,509692.55,4869856.64,18,0,80.53,81.03,84,36.2100,17.1521,4.0359,4.0359,3.8881,2.9217,1737.13,31.42,210,210,0.828,0.955,0.281,28.50,5746.46,163727.12,0.764,1.000,1147.23,33,769.16,19024.42,0.01,0.09,174,163,174,34.90,140,2369,2849,3157,33,81,110,71.59
>> 159,509679.19,4869855.54,18,0,77.62,78.97,75,30.4000,11.2000,2.5319,2.5129,2.3365,1.8315,3248.82,21.42,90,90,0.877,0.936,0.589,22.91,2000.74,46861.45,0.691,0.999,1772.06,14,365.47,10233.32,0.04,0.68,81,66,81,33.29,905,1869,2272,2633,55,82,98,71.62
> 
> Read the first line with readLines using n=1 saving as 'colnams'
> Read the dat <- read.table( ...  with skip=4, sep=",", and fill = TRUE
> Delete last line holding "Done" and a large number of NA's
> names(dat) <- scan(text=colnams, what=character(0), sep="," )
> 
> (Tested. Expected results achieved.)

 Lines <- "Tag,X,Y,BlobRegion,swaths,fr_int_20,fr_int_60,i60,RawTothgt,RawHtlc,RawRad20, RawRad40,RawRad60,RawRad80,CCV,BlobPerim,n_pts,n_pts_i255,vts,vts2,vtg,home,sum_ht, sum_ht_sq,dcch,dcch2,nb_ccv,n_nb,nb_sum_hts,nb_sum_hts2,z_tip_dist,nb_MassLen, n_f_rtns20,n_f_rtns60,max_fl_pt_count,loreyrawht,p00ile_cm,p25ile_cm,p50ile_cm, p75ile_cm,iq25,iq50,iq75,mean_intns
 01_24_2013.001,SF12
         5413
    509627.82,  4869704.98,   509999.83,  4869999.98
 123,509692.55,4869856.64,18,0,80.53,81.03,84,36.2100,17.1521,4.0359,4.0359,3.8881, 2.9217,1737.13,31.42,210,210,0.828,0.955,0.281,28.50,5746.46,163727.12,0.764,1.000, 1147.23,33,769.16,19024.42,0.01,0.09,174,163,174,34.90,140,2369,2849,3157,33,81, 110,71.59
 159,509679.19,4869855.54,18,0,77.62,78.97,75,30.4000,11.2000,2.5319,2.5129,2.3365, 1.8315,3248.82,21.42,90,90,0.877,0.936,0.589,22.91,2000.74,46861.45,0.691,0.999, 1772.06,14,365.47,10233.32,0.04,0.68,81,66,81,33.29,905,1869,2272,2633,55,82,98,71.62
 Done"
 colnams <- readLines(textConnection(Lines), n=1)
 scan(text=colnams, what=character(0), sep="," ) # check scan code
# snipped
 dat <- read.table( text=Lines, skip=4, sep=",", fill = TRUE)
 dat <- dat[-NROW(dat), ]
 names(dat) <- scan(text=colnams, what=character(0), sep="," )
# Read 44 items
 dat

> -- 
> David
> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Sun Jul 14 20:39:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 14 Jul 2013 11:39:43 -0700 (PDT)
Subject: [R] simplify a dataframe
In-Reply-To: <51E2CF2E.1070704@cirad.fr>
References: <51E05CC2.3020202@cirad.fr>
	<1373728723.14308.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<51E2CF2E.1070704@cirad.fr>
Message-ID: <1373827183.17866.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
May be this helps you.
df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad" 
df1[48,8]
[1] "31/12/4712" #strange value

df1[48,8]<- "31/12/2013"? #changed

indx<-as.numeric(interaction(df1[,1:6],drop=TRUE))
res<-do.call(rbind,lapply(split(df1,indx),function(x) {x1<- as.Date(x$Debut,format="%d/%m/%Y");x2<- as.Date(x$Fin,format="%d/%m/%Y");do.call(rbind,lapply(split(x,cumsum(c(FALSE,(x1[-1]-x2[-nrow(x)])!=1))),function(x) data.frame(x[1,1:6],Debut=head(x$Debut,1),Fin=tail(x$Fin,1),stringsAsFactors=FALSE)))}))

?res[order(res$Matricule),]? #the order of rows is a bit different than df2.
??? Matricule??? Nom???? Sexe DateNaissance??????????????? contrat??????? Pays
5?????????? 1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France
4.0???????? 6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France
4.1???????? 6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France
10????????? 6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines
6?????????? 8 DALNIC? F?minin??? 19/02/1940???????????? CDI commun????? France
9?????????? 8 DALNIC? F?minin??? 19/02/1940???????????? CDI commun? Martinique
1???????? 934? FORNI Masculin??? 10/07/1961 CDD d?tach? ext. Cirad??? Cameroun
2???????? 934? FORNI Masculin??? 10/07/1961???????????? CDI commun?????? Congo
3???????? 934? FORNI Masculin??? 10/07/1961??? CDI D?tach?s Autres?????? Congo
7???????? 934? FORNI Masculin??? 10/07/1961??? CDI D?tach?s Autres????? France
8???????? 934? FORNI Masculin??? 10/07/1961???????????? CDI commun?????? Gabon
???????? Debut??????? Fin
5?? 24/01/1995 31/12/1997
4.0 13/03/1995 30/06/1995
4.1 01/01/1996 31/01/1996
10? 02/02/1995 12/03/1995
6?? 24/01/1995 31/08/1995
9?? 01/09/1995 29/02/2000
1?? 26/01/1995 31/08/2001
2?? 05/09/2012 31/12/2013
3?? 01/09/2004 31/08/2007
7?? 01/09/2001 31/08/2004
8?? 01/09/2007 04/09/2012


A.K.



________________________________
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org>; jholtman at gmail.com; Rui Barradas <ruipbarradas at sapo.pt> 
Sent: Sunday, July 14, 2013 12:17 PM
Subject: Re: [R] simplify a dataframe



Hi,
Excuse me for the indistinctness

Le 13/07/2013 17:18, arun a ?crit?:

Hi,
"when the value of Debut of lines i = value Fin of lines i-1"
That part is not clear esp. when it is looked upon with the expected output (df2).
I want to group the lines which have the same caracteristics (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays) and with period of time (Debut/start and Fin/end) without interruption of time.
For exemple :
The following three lines
????:?????????????????????????????????????????????????????????????????
????Debut/Start? Fin/End? 
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France 24/01/1995 30/04/1997
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France
????01/05/1997 30/12/1997
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France
????31/12/1997 31/12/1997
are transformed into 1 line
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France 24/01/1995 31/12/1997
because same caracteristicsand period of time without interruption
????of time (from 24/01/1995 to 31/12/1997)

The following six lines :
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines 02/02/1995 27/02/1995? 
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines
????28/02/1995 28/02/1995 
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines
????01/03/1995 12/03/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 13/03/1995 30/06/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 01/01/1996 30/01/1996
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France
????31/01/1996 31/01/1996
are transformed into
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines 02/02/1995 12/03/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 13/03/1995 30/06/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 01/01/1996 31/01/1996
because
lines 1-3 identical for caracteristics and without interruption in
????time
lines 4 and lines 5-6 are not grouped because there is an
????interruption in time beetween 30/06/1995 and 01/01/1996

Thank you for your help
Michel


? Also, in your example dataset: df1$contrat[grep("^CDD",df1$contrat)]
#[1] "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad"
#[4] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"? "CDD d?tach? ext. Cirad"
#[7] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"? "CDD d?tach? ext. Cirad"
##Looks like there are extra spaces in some of them.? I guess these are the same
df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad" I tried this:
indx<-as.numeric(interaction(df1[,1:6],drop=FALSE)) ?df1New<- df1
res2<-unique(within(df1New,{Debut<-ave(seq_along(indx),indx,FUN=function(x) Debut[head(x,1)]);Fin<- ave(seq_along(indx),indx,FUN=function(x) Fin[tail(x,1)])}))
?row.names(res2)<- 1:nrow(res2) res2[,c(1,2,7:8)]
?? Matricule??? Nom????? Debut??????? Fin
1????????? 1? VERON 24/01/1995 31/12/1997
2????????? 6 BENARD 02/02/1995 12/03/1995
3????????? 6 BENARD 13/03/1995 31/01/1996 ###here not correct
4????????? 8 DALNIC 24/01/1995 31/08/1995
5????????? 8 DALNIC 01/09/1995 29/02/2000
6??????? 934? FORNI 26/01/1995 31/08/2001
7??????? 934? FORNI 01/09/2001 31/08/2004
8??????? 934? FORNI 01/09/2004 31/08/2007
9??????? 934? FORNI 01/09/2007 04/09/2012
10?????? 934? FORNI 05/09/2012 31/12/4712 df2[,c(1,2,7:8)]
?? Mat??? Nom????? Debut??????? Fin
1??? 1? VERON 24/01/1995 31/12/1997
2??? 6 BENARD 02/02/1995 12/03/1995
3??? 6 BENARD 13/03/1995 30/06/1995
4??? 6 BENARD 01/01/1996 31/01/1996 #missing this row 
5??? 8 DALNIC 24/01/1995 31/08/1995
6??? 8 DALNIC 01/09/1995 29/02/2000
7? 934? FORNI 26/01/1995 31/08/2001
8? 934? FORNI 01/09/2001 31/08/2004
9? 934? FORNI 01/09/2004 31/08/2007
10 934? FORNI 01/09/2007 04/09/2012
11 934? FORNI 05/09/2012 31/12/4712 Here, the dates look similar to the ones on df2 except for one row in df2. A.K. ----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr> To: R help <r-help at r-project.org> Cc: 
Sent: Friday, July 12, 2013 3:45 PM
Subject: [R] simplify a dataframe Hello I have the following problem : group the lines of a dataframe when no 
information change (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays) 
and when the value of Debut of lines i = value Fin of lines i-1
I can obtain it with a do loop. Is it possible to avoid the loop ? The dataframe initial is df1
dput(df1)
structure(list(Matricule = c(1L, 1L, 1L, 6L, 6L, 6L, 6L, 6L,
6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L), Nom = c("VERON", "VERON", "VERON", "BENARD",
"BENARD", "BENARD", "BENARD", "BENARD", "BENARD", "DALNIC", "DALNIC",
"DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI"), Sexe = c("F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin"), DateNaissance = c("02/09/1935",
"02/09/1935", "02/09/1935", "01/04/1935", "01/04/1935", "01/04/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961"), contrat = c("CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun"), Pays = c("France", "France", "France", "Philippines",
"Philippines", "Philippines", "France", "France", "France", "France",
"France", "Martinique", "Martinique", "Martinique", "Martinique",
"Martinique", "Martinique", "Martinique", "Cameroun", "Cameroun",
"Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun",
"Cameroun", "France", "France", "France", "France", "France",
"France", "France", "Congo", "Congo", "Congo", "Congo", "Congo",
"Congo", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon",
"Congo", "Congo"), Debut = c("24/01/1995", "01/05/1997", "31/12/1997",
"02/02/1995", "28/02/1995", "01/03/1995", "13/03/1995", "01/01/1996",
"31/01/1996", "24/01/1995", "01/07/1995", "01/09/1995", "01/07/1997",
"01/01/1998", "01/08/1998", "01/01/2000", "17/01/2000", "29/02/2000",
"26/01/1995", "01/07/1996", "16/09/1997", "01/01/1998", "01/07/1998",
"04/11/1999", "01/01/2001", "01/04/2001", "31/08/2001", "01/09/2001",
"02/09/2001", "01/12/2001", "01/02/2003", "01/04/2003", "01/01/2004",
"01/03/2004", "01/09/2004", "01/01/2005", "01/04/2005", "28/10/2006",
"01/01/2007", "01/04/2007", "01/09/2007", "01/01/2009", "01/04/2009",
"01/01/2010", "01/01/2011", "01/04/2011", "05/09/2012", "01/01/2013"
), Fin = c("30/04/1997", "30/12/1997", "31/12/1997", "27/02/1995",
"28/02/1995", "12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996",
"30/06/1995", "31/08/1995", "30/06/1997", "31/12/1997", "31/07/1998",
"31/12/1999", "16/01/2000", "28/02/2000", "29/02/2000", "30/06/1996",
"15/09/1997", "31/12/1997", "30/06/1998", "03/11/1999", "31/12/2000",
"31/03/2001", "30/08/2001", "31/08/2001", "01/09/2001", "30/11/2001",
"31/01/2003", "31/03/2003", "31/12/2003", "29/02/2004", "31/08/2004",
"31/12/2004", "31/03/2005", "27/10/2006", "31/12/2006", "31/03/2007",
"31/08/2007", "31/12/2008", "31/03/2009", "31/12/2009", "31/12/2010",
"31/03/2011", "04/09/2012", "31/12/2012", "31/12/4712")), .Names = 
c("Matricule",
"Nom", "Sexe", "DateNaissance", "contrat", "Pays", "Debut", "Fin"
), class = "data.frame", row.names = c(NA, -48L)) The dataframe to be obtained is df2
dput(df2)
structure(list(Mat = c(1L, 6L, 6L, 6L, 8L, 8L, 934L, 934L, 934L,
934L, 934L), Nom = c("VERON", "BENARD", "BENARD", "BENARD", "DALNIC",
"DALNIC", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI"), Sexe = c("F?minin",
"Masculin", "Masculin", "Masculin", "F?minin", "F?minin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin"), DateNaissance = 
c("02/09/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961"
), contrat = c("CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDD d?tach? ext. Cirad", "CDI D?tach?s 
Autres",
"CDI D?tach?s Autres", "CDI commun", "CDI commun"), Pays = c("France",
"Philippines", "France", "France", "France", "Martinique", "Cameroun",
"France", "Congo", "Gabon", "Congo"), Debut = c("24/01/1995",
"02/02/1995", "13/03/1995", "01/01/1996", "24/01/1995", "01/09/1995",
"26/01/1995", "01/09/2001", "01/09/2004", "01/09/2007", "05/09/2012"
), Fin = c("31/12/1997", "12/03/1995", "30/06/1995", "31/01/1996",
"31/08/1995", "29/02/2000", "31/08/2001", "31/08/2004", "31/08/2007",
"04/09/2012", "31/12/4712")), .Names = c("Mat", "Nom", "Sexe",
"DateNaissance", "contrat", "Pays", "Debut", "Fin"), class = 
"data.frame", row.names = c(NA,
-11L)) Thank you for your help 

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38??
fax : 04.67.61.57.87
port: 06.47.43.55.31


From marcelolaia at gmail.com  Sun Jul 14 21:56:10 2013
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Sun, 14 Jul 2013 16:56:10 -0300
Subject: [R] Book recomendation: Repeated Measurements
Message-ID: <CAEEYVUBcYD=kS4s=nDJRZveLfnVSb6yg=+Q=SuwvvkccQDLz5Q@mail.gmail.com>

Dear,

I need a book about repeated measurements analisys with R.

In Amazon, I found this one:

Models for Repeated Measurements (Oxford Statistical Science Series)
J. K. Lindsey 1999 2ed.

I would like a book with examples, data and R code. I work with trees
(forest breeding).

Could you recomend a book to me?

Thank you very much!

--
Laia, M. L.


From gunter.berton at gene.com  Sun Jul 14 22:19:16 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 14 Jul 2013 13:19:16 -0700
Subject: [R] Book recomendation: Repeated Measurements
In-Reply-To: <CAEEYVUBcYD=kS4s=nDJRZveLfnVSb6yg=+Q=SuwvvkccQDLz5Q@mail.gmail.com>
References: <CAEEYVUBcYD=kS4s=nDJRZveLfnVSb6yg=+Q=SuwvvkccQDLz5Q@mail.gmail.com>
Message-ID: <CACk-te3qA8FiaSZPqiF21Re3cqJiJR6NnmZYd4h3d4f812ZT9w@mail.gmail.com>

Look before you post -- specifically at the "Books" subpage of CRAN's
R homepage:

http://www.r-project.org/

-- Bert

On Sun, Jul 14, 2013 at 12:56 PM, Marcelo Laia <marcelolaia at gmail.com> wrote:
> Dear,
>
> I need a book about repeated measurements analisys with R.
>
> In Amazon, I found this one:
>
> Models for Repeated Measurements (Oxford Statistical Science Series)
> J. K. Lindsey 1999 2ed.
>
> I would like a book with examples, data and R code. I work with trees
> (forest breeding).
>
> Could you recomend a book to me?
>
> Thank you very much!
>
> --
> Laia, M. L.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From marcelolaia at gmail.com  Sun Jul 14 22:20:29 2013
From: marcelolaia at gmail.com (Marcelo Laia)
Date: Sun, 14 Jul 2013 17:20:29 -0300
Subject: [R] Book recomendation: Repeated Measurements
In-Reply-To: <CACk-te3qA8FiaSZPqiF21Re3cqJiJR6NnmZYd4h3d4f812ZT9w@mail.gmail.com>
References: <CAEEYVUBcYD=kS4s=nDJRZveLfnVSb6yg=+Q=SuwvvkccQDLz5Q@mail.gmail.com>
	<CACk-te3qA8FiaSZPqiF21Re3cqJiJR6NnmZYd4h3d4f812ZT9w@mail.gmail.com>
Message-ID: <CAEEYVUC3UpZ2VoBi1Cu9woxRJbn4p3LowDb3dqbJMiYGGBD-8g@mail.gmail.com>

Yes!

I have a look there before I post!

Thank you very much!

2013/7/14 Bert Gunter <gunter.berton at gene.com>:
> Look before you post -- specifically at the "Books" subpage of CRAN's
> R homepage:
>
> http://www.r-project.org/
>
> -- Bert
>
> On Sun, Jul 14, 2013 at 12:56 PM, Marcelo Laia <marcelolaia at gmail.com> wrote:
>> Dear,
>>
>> I need a book about repeated measurements analisys with R.
>>
>> In Amazon, I found this one:
>>
>> Models for Repeated Measurements (Oxford Statistical Science Series)
>> J. K. Lindsey 1999 2ed.
>>
>> I would like a book with examples, data and R code. I work with trees
>> (forest breeding).
>>
>> Could you recomend a book to me?
>>
>> Thank you very much!
>>
>> --
>> Laia, M. L.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
>
> Bert Gunter
> Genentech Nonclinical Biostatistics
>
> Internal Contact Info:
> Phone: 467-7374
> Website:
> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm



-- 
Laia, M. L.


From spencer.graves at structuremonitoring.com  Sun Jul 14 22:57:51 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 14 Jul 2013 13:57:51 -0700
Subject: [R] Book recomendation: Repeated Measurements
In-Reply-To: <CAEEYVUC3UpZ2VoBi1Cu9woxRJbn4p3LowDb3dqbJMiYGGBD-8g@mail.gmail.com>
References: <CAEEYVUBcYD=kS4s=nDJRZveLfnVSb6yg=+Q=SuwvvkccQDLz5Q@mail.gmail.com>
	<CACk-te3qA8FiaSZPqiF21Re3cqJiJR6NnmZYd4h3d4f812ZT9w@mail.gmail.com>
	<CAEEYVUC3UpZ2VoBi1Cu9woxRJbn4p3LowDb3dqbJMiYGGBD-8g@mail.gmail.com>
Message-ID: <51E310CF.30501@structuremonitoring.com>

On 7/14/2013 1:20 PM, Marcelo Laia wrote:
> Yes!
>
> I have a look there before I post!


       You may know that "mixed effects" is another term for "repeated 
measurements".


       Spencer Graves
>
> Thank you very much!
>
> 2013/7/14 Bert Gunter <gunter.berton at gene.com>:
>> Look before you post -- specifically at the "Books" subpage of CRAN's
>> R homepage:
>>
>> http://www.r-project.org/
>>
>> -- Bert
>>
>> On Sun, Jul 14, 2013 at 12:56 PM, Marcelo Laia <marcelolaia at gmail.com> wrote:
>>> Dear,
>>>
>>> I need a book about repeated measurements analisys with R.
>>>
>>> In Amazon, I found this one:
>>>
>>> Models for Repeated Measurements (Oxford Statistical Science Series)
>>> J. K. Lindsey 1999 2ed.
>>>
>>> I would like a book with examples, data and R code. I work with trees
>>> (forest breeding).
>>>
>>> Could you recomend a book to me?
>>>
>>> Thank you very much!
>>>
>>> --
>>> Laia, M. L.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>
>


-- 
Spencer Graves, PE, PhD
President and Chief Technology Officer
Structure Inspection and Monitoring, Inc.
751 Emerson Ct.
San Jos?, CA 95126
ph:  408-655-4567
web:  www.structuremonitoring.com


From losedaghat at gmail.com  Sun Jul 14 23:40:14 2013
From: losedaghat at gmail.com (L S)
Date: Sun, 14 Jul 2013 17:40:14 -0400
Subject: [R] Does R ever stop responding without a message?
Message-ID: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/284aec8f/attachment.pl>

From rolf.turner at xtra.co.nz  Mon Jul 15 00:05:22 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Mon, 15 Jul 2013 10:05:22 +1200
Subject: [R] Book recomendation: Repeated Measurements
In-Reply-To: <51E310CF.30501@structuremonitoring.com>
References: <CAEEYVUBcYD=kS4s=nDJRZveLfnVSb6yg=+Q=SuwvvkccQDLz5Q@mail.gmail.com>
	<CACk-te3qA8FiaSZPqiF21Re3cqJiJR6NnmZYd4h3d4f812ZT9w@mail.gmail.com>
	<CAEEYVUC3UpZ2VoBi1Cu9woxRJbn4p3LowDb3dqbJMiYGGBD-8g@mail.gmail.com>
	<51E310CF.30501@structuremonitoring.com>
Message-ID: <51E320A2.1010109@xtra.co.nz>

On 15/07/13 08:57, Spencer Graves wrote:

<SNIP>
>
>       You may know that "mixed effects" is another term for "repeated 
> measurements".

<SNIP>

I must of course preface this comment with an "I am no expert" 
disclaimer, but I do not
believe that this assertion is correct.  It would be more correct, I 
believe, to say that
repeated measurement models form a particular sub-class of mixed effects 
models.

Those who *are* experts may well correct me if I am wrong about this.

     cheers,

         Rolf


From smartpink111 at yahoo.com  Sun Jul 14 22:15:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 14 Jul 2013 13:15:54 -0700 (PDT)
Subject: [R] Need hep for converting date data in POSIXct
In-Reply-To: <DUB116-W26E452C92557278B61F4DE9E660@phx.gbl>
References: <1373238668238-4671059.post@n4.nabble.com>,
	<1373245302.11936.YahooMailNeo@web142602.mail.bf1.yahoo.com>,
	<DUB116-W5914520FB86D7D17F860709E780@phx.gbl>,
	<1373316818.12350.YahooMailNeo@web142601.mail.bf1.yahoo.com>,
	<DUB116-W7077C1A830A1EFC6FCFD5E9E790@phx.gbl>,
	<1373509652.33022.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<DUB116-W542B3F2886147D4110EE889E7B0@phx.gbl>,
	<1373537440.91387.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<DUB116-W26E452C92557278B61F4DE9E660@phx.gbl>
Message-ID: <1373832954.55223.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
Try this:
Geo<- read.table(text="
long??? lat.comp confianza
?9.31?????? -42.72???????? 3
11.66????? -40.63???????? 9
10.88????? -38.60???????? 9
10.72???? -37.86???????? 9
13.06???? -39.04???????? 9
16.02???? -38.51???????? 6
",sep="",header=TRUE) 
?col1<- as.numeric(factor(Geo$confianza))
?with(Geo, plot(long,lat.comp,col=col1))
A.K.






________________________________
From: laila Aranda Romero <laila_zgz at hotmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Sunday, July 14, 2013 3:28 PM
Subject: RE: [R] Need hep for converting date data in POSIXct




Arun, 

I?contact you again because I have another difficulty with R.? I posted the following message but it hasn't been accepted by the f?rum filter. So I'm not sure if you can see it!!!!?

I have the following database: 

head(Geo) 
long ? ?lat.comp confianza 
?9.31 ? ? ? -42.72 ? ? ? ? 3 
11.66 ? ? ?-40.63 ? ? ? ? 9 
10.88 ? ? ?-38.60 ? ? ? ? 9 
10.72 ? ? -37.86 ? ? ? ? 9 
13.06 ? ? -39.04 ? ? ? ? 9 
16.02 ? ? -38.51 ? ? ? ? 6 

I am trying to plot ? Geo$ long versus Geo$lat.comp with diferent colours regarding the number of Geo$confianza. I don't know how to make the palette and tell R to plot the points using this palette in the same graph.
Regards,
Laila


> Date: Thu, 11 Jul 2013 03:10:40 -0700
> From: smartpink111 at yahoo.com
> Subject: Re: [R] Need hep for converting date data in POSIXct
> To: laila_zgz at hotmail.com
> 
> Hi Laila,
> No problem.
> Regards,
> Arun
> 
> 
> 
> 
> ----- Original Message -----
> From: laila <laila_zgz at hotmail.com>
> To: r-help at r-project.org
> Cc: 
> Sent: Thursday, July 11, 2013 3:38 AM
> Subject: Re: [R] Need hep for converting date data in POSIXct
> 
> Arun, the last email has been sent it by itself. I have just found the problem and it works. Thank very much!!!! 
> 
> Date: Wed, 10 Jul 2013 19:36:43 -0700
> From: ml-node+s789695n4671274h29 at n4.nabble.com
> To: laila_zgz at hotmail.com
> Subject: Re: Need hep for converting date data in POSIXct
> 
> 
> 
> ??? 
> 
> Hi,
> 
> I guess the error message:
> 
> > vmask(lat,lon,time,vmax=25)
> 
> Error en vmask(lat, lon,
> 
> time, vmax = 25) : objeto 'lat' no encontrado
> 
> 
> says that you have not defined the object 'lat'.
> 
> 
> time<-subset(Geo, select =date)
> 
> time[,1]<-? as.POSIXct(time[,1],format="%d/%m/%Y %H:%M")
> 
> location<- subset(Geo,select=c(lat.comp,long))
> 
> time1<- time[,1]
> 
> lat<- location[,1]
> 
> long<- location[,2]
> 
> library(argosfilter)
> 
> vmask(lat,long,time1,25)
> 
> #[1] "end_location" "end_location" "not"? ? ? ? ? "not"? ? ? ? ? "end_location"
> 
> #[6] "end_location"
> 
> 
> A.K.
> 
> ________________________________
> 
> From: laila Aranda Romero <[hidden email]>
> 
> To: arun <[hidden email]> 
> 
> Sent: Wednesday, July 10, 2013 6:21 PM
> 
> Subject: RE: [R] Need hep for converting date data in POSIXct
> 
> 
> 
> 
> 
> 
> Hi,
> 
> 
> The code: 
> 
> 
> library(argosfilter)
> 
> setwd("C:/Users/Usuario/Dropbox/Laila Aranda/PUFGRA")
> 
> Geo = 
> 
> read.table("2370001_PUFGRA_2009_Gough_000_retarded10_both.trj",header=FALSE,sep
> 
> = ",", col.names= c("type", "date",
> 
> "secs", "Trans1",? "Trans2",
> 
> "lat.sta",? "lat.comp", "long", 
> 
> "dist", "rumbo", "velocidad", 
> 
> "confianza"))
> 
> View(Geo)
> 
> location=subset(Geo, select= c(lat.comp,long))
> 
> time=subset(Geo, select =c(date))
> 
> time[,1]<-as.POSIXct(time[,1],format="%d/%m/%Y
> 
> %H:%M")? 
> 
> vmask(lat,lon,time,vmax=25)
> 
> 
> 
> 
> 
> The example: library(argosfilter)
> 
> > setwd("C:/Users/Usuario/Dropbox/LailaAranda/PUFGRA")
> 
> > Geo = read.table("2370001_PUFGRA_2009_Gough_000_retarded10_both.trj",header=FALSE,sep
> 
> = ",", col.names= c("type", "date","secs", "Trans1", "Trans2", "lat.sta", "lat.comp", "long", "dist", "rumbo", "velocidad",? "confianza"))
> 
> > str(Geo)
> 
> 
> 'data.frame':? 582
> 
> obs. of? 12 variables: $
> 
> type? ???: Factor w/ 2 levels
> 
> "midnight","noon": 2 1 2 1 2 1 2 1 2 1 ...
> 
> $
> 
> date? ???: Factor w/ 582 levels
> 
> "01/01/2009 01:58",..: 370 389 390 409 410 429 430 450 451 471 ...
> 
> 
> $
> 
> secs? ???: num? 39773 39773 39774 39774 39775 ... $
> 
> Trans1???: Factor w/ 186 levels
> 
> "04:06","04:08",..: 14 17 17 16 16 28 28 19 19 15 ...
> 
> $
> 
> Trans2???: Factor w/ 159 levels
> 
> "00:01","00:03",..: 30 30 28 28 34 34 35 35 36 36 ...
> 
> $
> 
> lat.sta? : num? -42.7 -39.1 -37.8 -37.9 -41.2 ...
> 
> $
> 
> lat.comp : num? -42.7 -40.6 -38.6 -37.9
> 
> -39 ...
> 
> 
> $
> 
> long? ???: num? 9.31 11.66 10.88 10.72 13.06 ...
> 
> $ dist? ???: num 
> 
> 0 0 127 45 131 ...
> 
> $ rumbo? 
> 
> : num? 0 0 -16.49 -9.64 -57.22 ...
> 
> $ velocidad: num? 0 0 10.64 3.75 10.75 ... $ confianza: int? 3 9 9 9 9 6 6 9 9 9
> 
> ...
> 
> > head(Geo)
> 
> type? ? ? ? ? ???date? ???secs Trans1 Trans2 lat.sta lat.comp? long? 
> 
> dist
> 
> 1 noon 20/11/2008 12:23 39772.52 
> 
> 04:59? 19:47? -42.72? 
> 
> -42.72? 9.31???0.00
> 
> 2 midnight 21/11/2008 00:33 39773.02? 05:18 
> 
> 19:47? -39.14???-40.63 11.66???0.00
> 
> 3 noon 21/11/2008 12:29 39773.52 
> 
> 05:18? 19:41? -37.82? 
> 
> -38.60 10.88 127.02
> 
> 4 midnight 22/11/2008 00:29 39774.02? 05:17 
> 
> 19:41? -37.86???-37.86 10.72 
> 
> 45.04
> 
> 5 noon 22/11/2008 12:39 39774.53 
> 
> 05:17? 20:00? -41.21? 
> 
> -39.04 13.06 130.78
> 
> 6 midnight 23/11/2008 00:50 39775.03? 05:41 
> 
> 20:00? -36.56???-38.51 16.02 142.06
> 
> ???rumbo
> 
> velocidad confianza
> 
> 1? 
> 
> 0.00? ? ? 0.00? ? ? ???3
> 
> 2? 
> 
> 0.00? ? ? 0.00? ? ? ???9
> 
> 3 -16.49? ? 
> 
> 10.64? ? ? ???9
> 
> 4 
> 
> -9.64? ? ? 3.75? ? ? ???9
> 
> 5 -57.22? ? 
> 
> 10.75? ? ? ???9
> 
> 6 
> 
> 77.07? ???11.66? ? ? ???6
> 
> > location=subset(Geo, select=
> 
> c(lat.comp,long))
> 
> 
> > str(location)
> 
> 'data.frame':? 582
> 
> obs. of? 2 variables:
> 
> $lat.comp: num? -42.7 -40.6 -38.6 -37.9 -39 ...
> 
> $long? ? : num? 9.31 11.66 10.88 10.72 13.06 ...
> 
> > head(location)
> 
> 
> lat.comp? long
> 
> 1? 
> 
> -42.72? 9.31
> 
> 2? 
> 
> -40.63 11.66
> 
> 3? 
> 
> -38.60 10.88
> 
> 4? 
> 
> -37.86 10.72
> 
> 5? 
> 
> -39.04 13.06
> 
> 6? 
> 
> -38.51 16.02
> 
> 
> > time=subset(Geo, select =c(date))
> 
> > time[,1]<-as.POSIXct(time[,1],format="%d/%m/%Y
> 
> %H:%M")
> 
> > str(time)
> 
> 'data.frame':? 582
> 
> obs. of? 1 variable:
> 
> $ date:
> 
> POSIXct, format: "2008-11-20 12:23:00" "2008-11-21
> 
> 00:33:00" ...
> 
> > head(time)
> 
> ? ? ? ? ? ? ? ???date
> 
> 1 2008-11-20 12:23:00
> 
> 2 2008-11-21 00:33:00
> 
> 3 2008-11-21 12:29:00
> 
> 4 2008-11-22 00:29:00
> 
> 5 2008-11-22 12:39:00
> 
> 6 2008-11-23 00:50:00
> 
> > vmask(lat,lon,time,vmax=25)
> 
> Error en vmask(lat, lon,
> 
> time, vmax = 25) : objeto 'lat' no encontrado
> 
> 
> ______________________________________________
> 
> [hidden email] mailing list
> 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 
> 
> ??? 
> ??? 
> ??? 
> ??? 
> 
> ??? 
> 
> ??? 
> ??? 
> ??? ??? If you reply to this email, your message will be added to the discussion below:
> ??? ??? http://r.789695.n4.nabble.com/Need-hep-for-converting-date-data-in-POSIXct-tp4671059p4671274.html
> ??? 
> ??? 
> ??? ??? 
> ??? ??? To unsubscribe from Need hep for converting date data in POSIXct, click here.
> 
> ??? ??? NAML
> ???????? ???????? ?????? ??? ? 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Need-hep-for-converting-date-data-in-POSIXct-tp4671059p4671301.html
> Sent from the R help mailing list archive at Nabble.com.
> ??? [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> ??


From dwinsemius at comcast.net  Mon Jul 15 00:42:23 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Jul 2013 15:42:23 -0700
Subject: [R] Does R ever stop responding without a message?
In-Reply-To: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>
References: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>
Message-ID: <8DE4C748-9EA2-4D20-A70B-DFEEA076C455@comcast.net>


On Jul 14, 2013, at 2:40 PM, L S wrote:

> Hi,
> 
> Have any of you ever encountered a situation where R stops processing an
> instruction but does not give a "not responding" message?
> 
> The reason I ask is I am working in RStudio (Mac OS/X 10.7, 1.8 Ghz i7, 4
> GB DDR3) and the instruction I entered in the command line pane is still
> being processed since last night around 7 PM.  I expected it to take on the
> order of 8-12 hours to complete, but I'm nearing 24 hours with no progress,
> no messages, etc.
> 
> The command is essentially splitting the a ppp (marked point pattern) into
> a tessellation/grid.  There are about a couple million points in the
> pattern and each has a vector of four marks.  That said, I processed a
> similar command with 700,000 points in the pattern (each point with a
> vector of two marks) yesterday and it took only around 3 hours.
> 
> Is there anyway I can be certain the command is being processed?

Well, this answer only addresses whether the R program is "active": Use the Activity Monitor.app looking at teh CPU panel. The process name is R and, this being a Mac, you even get a micro-R-logo. At "idling speed" it will only display 1% or so. When it is active the cpu-%-age will "bounce around" near 100%.


>  I don't
> want to abort prematurely if I know it will go to completion.  How long
> would you give it before you knew for certain it would not complete?

If you have pushed your process over the bounds of available RAM and it is now using "virtual memory", there is really no way to estimate the complettion time. I generally give up after about 15 or 20 minutes. 

This does mean that the best practice will have been to make sure you have saved you work before terminating the session. The R GUI is helpful in this regard because it automatically backs up open source documents at intervals. Unfortunately that is not also true for the history session, which is only updated at a normal termination of a session.
> 
> Any guidance you could offer would be much appreciated.
> 
> Thanks,
> Lily
> 
> 	[[alternative HTML version deleted]]

This is not the correct mailing list for this question, and you should also read what the Posting Guide says about not using HTML format.

--  

David Winsemius
Alameda, CA, USA


From jholtman at gmail.com  Mon Jul 15 00:46:05 2013
From: jholtman at gmail.com (jim holtman)
Date: Sun, 14 Jul 2013 18:46:05 -0400
Subject: [R] Does R ever stop responding without a message?
In-Reply-To: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>
References: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>
Message-ID: <CAAxdm-6-dafYecJ+EKGefS8X+6kWyqPTfqpuNsCi2B6_WHhdhA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/4afb260e/attachment.pl>

From spencer.graves at structuremonitoring.com  Mon Jul 15 01:38:08 2013
From: spencer.graves at structuremonitoring.com (Spencer Graves)
Date: Sun, 14 Jul 2013 16:38:08 -0700
Subject: [R] Book recomendation: Repeated Measurements
In-Reply-To: <51E320A2.1010109@xtra.co.nz>
References: <CAEEYVUBcYD=kS4s=nDJRZveLfnVSb6yg=+Q=SuwvvkccQDLz5Q@mail.gmail.com>
	<CACk-te3qA8FiaSZPqiF21Re3cqJiJR6NnmZYd4h3d4f812ZT9w@mail.gmail.com>
	<CAEEYVUC3UpZ2VoBi1Cu9woxRJbn4p3LowDb3dqbJMiYGGBD-8g@mail.gmail.com>
	<51E310CF.30501@structuremonitoring.com>
	<51E320A2.1010109@xtra.co.nz>
Message-ID: <51E33660.8020608@structuremonitoring.com>

On 7/14/2013 3:05 PM, Rolf Turner wrote:
> On 15/07/13 08:57, Spencer Graves wrote:
>
> <SNIP>
>>
>>       You may know that "mixed effects" is another term for "repeated 
>> measurements".
>
> <SNIP>
>
> I must of course preface this comment with an "I am no expert" 
> disclaimer, but I do not
> believe that this assertion is correct.  It would be more correct, I 
> believe, to say that
> repeated measurement models form a particular sub-class of mixed 
> effects models.
>
> Those who *are* experts may well correct me if I am wrong about this.


       Thanks for the clarification, Rolf.  You are absolutely correct.  
"Repeated measurements" refers to the sampling plan. "Mixed effects" 
describes a form of mathematical modeling.  There are balanced repeated 
measures data sets where people do not have to worry about the 
subtleties of mixed-effects modeling.  An experiment with multiple 
litters with several mice in at least some of the litters would call for 
mixed-effects modeling.  This would include "repeated measures" on the 
litters but not the mice.


       However, "I am no expert" on repeated measures / mixed-effects, 
either


        Spencer

>
>     cheers,
>
>         Rolf


From smartpink111 at yahoo.com  Mon Jul 15 03:47:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 14 Jul 2013 18:47:00 -0700 (PDT)
Subject: [R] simplify a dataframe
In-Reply-To: <1373827183.17866.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <51E05CC2.3020202@cirad.fr>
	<1373728723.14308.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<51E2CF2E.1070704@cirad.fr>
	<1373827183.17866.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1373852820.26254.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI Michel,
This gives the same order as that of df2.
df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad"
df1[48,8]<- "31/12/2013"
indx<-as.numeric(interaction(df1[,1:6],drop=TRUE))
lst1<-split(df1,indx)
?lst2<-lst1[match(unique(indx),names(lst1))]
res<-do.call(rbind,lapply(lst2,function(x){x1<- as.Date(x$Debut,format="%d/%m/%Y");x2<- as.Date(x$Fin,format="%d/%m/%Y");do.call(rbind,lapply(split(x,cumsum(c(FALSE,(x1[-1]-x2[-nrow(x)])!=1))),function(x) data.frame(x[1,1:6],Debut=head(x$Debut,1),Fin=tail(x$Fin,1),stringsAsFactors=FALSE)))}))
?row.names(res)<- 1:nrow(res)
?df2[11,8]<- "31/12/2013"
?names(res)[1]<- "Mat"
?identical(res,df2)
#[1] TRUE


A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Arnaud Michel <michel.arnaud at cirad.fr>
Cc: R help <r-help at r-project.org>
Sent: Sunday, July 14, 2013 2:39 PM
Subject: Re: [R] simplify a dataframe

Hi,
May be this helps you.
df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad" 
df1[48,8]
[1] "31/12/4712" #strange value

df1[48,8]<- "31/12/2013"? #changed

indx<-as.numeric(interaction(df1[,1:6],drop=TRUE))
res<-do.call(rbind,lapply(split(df1,indx),function(x) {x1<- as.Date(x$Debut,format="%d/%m/%Y");x2<- as.Date(x$Fin,format="%d/%m/%Y");do.call(rbind,lapply(split(x,cumsum(c(FALSE,(x1[-1]-x2[-nrow(x)])!=1))),function(x) data.frame(x[1,1:6],Debut=head(x$Debut,1),Fin=tail(x$Fin,1),stringsAsFactors=FALSE)))}))

?res[order(res$Matricule),]? #the order of rows is a bit different than df2.
??? Matricule??? Nom???? Sexe DateNaissance??????????????? contrat??????? Pays
5?????????? 1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France
4.0???????? 6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France
4.1???????? 6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France
10????????? 6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines
6?????????? 8 DALNIC? F?minin??? 19/02/1940???????????? CDI commun????? France
9?????????? 8 DALNIC? F?minin??? 19/02/1940???????????? CDI commun? Martinique
1???????? 934? FORNI Masculin??? 10/07/1961 CDD d?tach? ext. Cirad??? Cameroun
2???????? 934? FORNI Masculin??? 10/07/1961???????????? CDI commun?????? Congo
3???????? 934? FORNI Masculin??? 10/07/1961??? CDI D?tach?s Autres?????? Congo
7???????? 934? FORNI Masculin??? 10/07/1961??? CDI D?tach?s Autres????? France
8???????? 934? FORNI Masculin??? 10/07/1961???????????? CDI commun?????? Gabon
???????? Debut??????? Fin
5?? 24/01/1995 31/12/1997
4.0 13/03/1995 30/06/1995
4.1 01/01/1996 31/01/1996
10? 02/02/1995 12/03/1995
6?? 24/01/1995 31/08/1995
9?? 01/09/1995 29/02/2000
1?? 26/01/1995 31/08/2001
2?? 05/09/2012 31/12/2013
3?? 01/09/2004 31/08/2007
7?? 01/09/2001 31/08/2004
8?? 01/09/2007 04/09/2012


A.K.



________________________________
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: arun <smartpink111 at yahoo.com> 
Cc: R help <r-help at r-project.org>; jholtman at gmail.com; Rui Barradas <ruipbarradas at sapo.pt> 
Sent: Sunday, July 14, 2013 12:17 PM
Subject: Re: [R] simplify a dataframe



Hi,
Excuse me for the indistinctness

Le 13/07/2013 17:18, arun a ?crit?:

Hi,
"when the value of Debut of lines i = value Fin of lines i-1"
That part is not clear esp. when it is looked upon with the expected output (df2).
I want to group the lines which have the same caracteristics (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays) and with period of time (Debut/start and Fin/end) without interruption of time.
For exemple :
The following three lines
????:?????????????????????????????????????????????????????????????????
????Debut/Start? Fin/End? 
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France 24/01/1995 30/04/1997
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France
????01/05/1997 30/12/1997
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France
????31/12/1997 31/12/1997
are transformed into 1 line
1? VERON? F?minin??? 02/09/1935???????????? CDI commun????? France 24/01/1995 31/12/1997
because same caracteristicsand period of time without interruption
????of time (from 24/01/1995 to 31/12/1997)

The following six lines :
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines 02/02/1995 27/02/1995? 
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines
????28/02/1995 28/02/1995 
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines
????01/03/1995 12/03/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 13/03/1995 30/06/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 01/01/1996 30/01/1996
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France
????31/01/1996 31/01/1996
are transformed into
6 BENARD Masculin??? 01/04/1935???????????? CDI commun Philippines 02/02/1995 12/03/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 13/03/1995 30/06/1995
6 BENARD Masculin??? 01/04/1935???????????? CDI commun????? France 01/01/1996 31/01/1996
because
lines 1-3 identical for caracteristics and without interruption in
????time
lines 4 and lines 5-6 are not grouped because there is an
????interruption in time beetween 30/06/1995 and 01/01/1996

Thank you for your help
Michel


? Also, in your example dataset: df1$contrat[grep("^CDD",df1$contrat)]
#[1] "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad"
#[4] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"? "CDD d?tach? ext. Cirad"
#[7] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"? "CDD d?tach? ext. Cirad"
##Looks like there are extra spaces in some of them.? I guess these are the same
df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad" I tried this:
indx<-as.numeric(interaction(df1[,1:6],drop=FALSE)) ?df1New<- df1
res2<-unique(within(df1New,{Debut<-ave(seq_along(indx),indx,FUN=function(x) Debut[head(x,1)]);Fin<- ave(seq_along(indx),indx,FUN=function(x) Fin[tail(x,1)])}))
?row.names(res2)<- 1:nrow(res2) res2[,c(1,2,7:8)]
?? Matricule??? Nom????? Debut??????? Fin
1????????? 1? VERON 24/01/1995 31/12/1997
2????????? 6 BENARD 02/02/1995 12/03/1995
3????????? 6 BENARD 13/03/1995 31/01/1996 ###here not correct
4????????? 8 DALNIC 24/01/1995 31/08/1995
5????????? 8 DALNIC 01/09/1995 29/02/2000
6??????? 934? FORNI 26/01/1995 31/08/2001
7??????? 934? FORNI 01/09/2001 31/08/2004
8??????? 934? FORNI 01/09/2004 31/08/2007
9??????? 934? FORNI 01/09/2007 04/09/2012
10?????? 934? FORNI 05/09/2012 31/12/4712 df2[,c(1,2,7:8)]
?? Mat??? Nom????? Debut??????? Fin
1??? 1? VERON 24/01/1995 31/12/1997
2??? 6 BENARD 02/02/1995 12/03/1995
3??? 6 BENARD 13/03/1995 30/06/1995
4??? 6 BENARD 01/01/1996 31/01/1996 #missing this row 
5??? 8 DALNIC 24/01/1995 31/08/1995
6??? 8 DALNIC 01/09/1995 29/02/2000
7? 934? FORNI 26/01/1995 31/08/2001
8? 934? FORNI 01/09/2001 31/08/2004
9? 934? FORNI 01/09/2004 31/08/2007
10 934? FORNI 01/09/2007 04/09/2012
11 934? FORNI 05/09/2012 31/12/4712 Here, the dates look similar to the ones on df2 except for one row in df2. A.K. ----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr> To: R help <r-help at r-project.org> Cc: 
Sent: Friday, July 12, 2013 3:45 PM
Subject: [R] simplify a dataframe Hello I have the following problem : group the lines of a dataframe when no 
information change (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays) 
and when the value of Debut of lines i = value Fin of lines i-1
I can obtain it with a do loop. Is it possible to avoid the loop ? The dataframe initial is df1
dput(df1)
structure(list(Matricule = c(1L, 1L, 1L, 6L, 6L, 6L, 6L, 6L,
6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
934L, 934L, 934L, 934L), Nom = c("VERON", "VERON", "VERON", "BENARD",
"BENARD", "BENARD", "BENARD", "BENARD", "BENARD", "DALNIC", "DALNIC",
"DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
"FORNI", "FORNI"), Sexe = c("F?minin", "F?minin", "F?minin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
"F?minin", "F?minin", "F?minin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
"Masculin", "Masculin", "Masculin"), DateNaissance = c("02/09/1935",
"02/09/1935", "02/09/1935", "01/04/1935", "01/04/1935", "01/04/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940",
"19/02/1940", "19/02/1940", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
"10/07/1961", "10/07/1961"), contrat = c("CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. 
Cirad",
"CDD d?tach? ext. Cirad", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
"CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun"), Pays = c("France", "France", "France", "Philippines",
"Philippines", "Philippines", "France", "France", "France", "France",
"France", "Martinique", "Martinique", "Martinique", "Martinique",
"Martinique", "Martinique", "Martinique", "Cameroun", "Cameroun",
"Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun",
"Cameroun", "France", "France", "France", "France", "France",
"France", "France", "Congo", "Congo", "Congo", "Congo", "Congo",
"Congo", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon",
"Congo", "Congo"), Debut = c("24/01/1995", "01/05/1997", "31/12/1997",
"02/02/1995", "28/02/1995", "01/03/1995", "13/03/1995", "01/01/1996",
"31/01/1996", "24/01/1995", "01/07/1995", "01/09/1995", "01/07/1997",
"01/01/1998", "01/08/1998", "01/01/2000", "17/01/2000", "29/02/2000",
"26/01/1995", "01/07/1996", "16/09/1997", "01/01/1998", "01/07/1998",
"04/11/1999", "01/01/2001", "01/04/2001", "31/08/2001", "01/09/2001",
"02/09/2001", "01/12/2001", "01/02/2003", "01/04/2003", "01/01/2004",
"01/03/2004", "01/09/2004", "01/01/2005", "01/04/2005", "28/10/2006",
"01/01/2007", "01/04/2007", "01/09/2007", "01/01/2009", "01/04/2009",
"01/01/2010", "01/01/2011", "01/04/2011", "05/09/2012", "01/01/2013"
), Fin = c("30/04/1997", "30/12/1997", "31/12/1997", "27/02/1995",
"28/02/1995", "12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996",
"30/06/1995", "31/08/1995", "30/06/1997", "31/12/1997", "31/07/1998",
"31/12/1999", "16/01/2000", "28/02/2000", "29/02/2000", "30/06/1996",
"15/09/1997", "31/12/1997", "30/06/1998", "03/11/1999", "31/12/2000",
"31/03/2001", "30/08/2001", "31/08/2001", "01/09/2001", "30/11/2001",
"31/01/2003", "31/03/2003", "31/12/2003", "29/02/2004", "31/08/2004",
"31/12/2004", "31/03/2005", "27/10/2006", "31/12/2006", "31/03/2007",
"31/08/2007", "31/12/2008", "31/03/2009", "31/12/2009", "31/12/2010",
"31/03/2011", "04/09/2012", "31/12/2012", "31/12/4712")), .Names = 
c("Matricule",
"Nom", "Sexe", "DateNaissance", "contrat", "Pays", "Debut", "Fin"
), class = "data.frame", row.names = c(NA, -48L)) The dataframe to be obtained is df2
dput(df2)
structure(list(Mat = c(1L, 6L, 6L, 6L, 8L, 8L, 934L, 934L, 934L,
934L, 934L), Nom = c("VERON", "BENARD", "BENARD", "BENARD", "DALNIC",
"DALNIC", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI"), Sexe = c("F?minin",
"Masculin", "Masculin", "Masculin", "F?minin", "F?minin", "Masculin",
"Masculin", "Masculin", "Masculin", "Masculin"), DateNaissance = 
c("02/09/1935",
"01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
"10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961"
), contrat = c("CDI commun", "CDI commun", "CDI commun", "CDI commun",
"CDI commun", "CDI commun", "CDD d?tach? ext. Cirad", "CDI D?tach?s 
Autres",
"CDI D?tach?s Autres", "CDI commun", "CDI commun"), Pays = c("France",
"Philippines", "France", "France", "France", "Martinique", "Cameroun",
"France", "Congo", "Gabon", "Congo"), Debut = c("24/01/1995",
"02/02/1995", "13/03/1995", "01/01/1996", "24/01/1995", "01/09/1995",
"26/01/1995", "01/09/2001", "01/09/2004", "01/09/2007", "05/09/2012"
), Fin = c("31/12/1997", "12/03/1995", "30/06/1995", "31/01/1996",
"31/08/1995", "29/02/2000", "31/08/2001", "31/08/2004", "31/08/2007",
"04/09/2012", "31/12/4712")), .Names = c("Mat", "Nom", "Sexe",
"DateNaissance", "contrat", "Pays", "Debut", "Fin"), class = 
"data.frame", row.names = c(NA,
-11L)) Thank you for your help 

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38??
fax : 04.67.61.57.87
port: 06.47.43.55.31


From losedaghat at gmail.com  Mon Jul 15 05:24:11 2013
From: losedaghat at gmail.com (L S)
Date: Sun, 14 Jul 2013 23:24:11 -0400
Subject: [R] Does R ever stop responding without a message?
In-Reply-To: <CAAxdm-6-dafYecJ+EKGefS8X+6kWyqPTfqpuNsCi2B6_WHhdhA@mail.gmail.com>
References: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>
	<CAAxdm-6-dafYecJ+EKGefS8X+6kWyqPTfqpuNsCi2B6_WHhdhA@mail.gmail.com>
Message-ID: <CAMgNocvhTQXqn8GfqLCwKQ59G7LTBdZF8-a_m0JpPEuMhmD71g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/bc9bd03f/attachment.pl>

From michel.arnaud at cirad.fr  Mon Jul 15 06:56:02 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 15 Jul 2013 06:56:02 +0200
Subject: [R] simplify a dataframe
In-Reply-To: <1373852820.26254.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <51E05CC2.3020202@cirad.fr>
	<1373728723.14308.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<51E2CF2E.1070704@cirad.fr>
	<1373827183.17866.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<1373852820.26254.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <51E380E2.5030203@cirad.fr>

Super !!!
Thank you very much Arun
Michel
Le 15/07/2013 03:47, arun a ?crit :
> HI Michel,
> This gives the same order as that of df2.
> df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad"
> df1[48,8]<- "31/12/2013"
> indx<-as.numeric(interaction(df1[,1:6],drop=TRUE))
> lst1<-split(df1,indx)
>   lst2<-lst1[match(unique(indx),names(lst1))]
> res<-do.call(rbind,lapply(lst2,function(x){x1<- as.Date(x$Debut,format="%d/%m/%Y");x2<- as.Date(x$Fin,format="%d/%m/%Y");do.call(rbind,lapply(split(x,cumsum(c(FALSE,(x1[-1]-x2[-nrow(x)])!=1))),function(x) data.frame(x[1,1:6],Debut=head(x$Debut,1),Fin=tail(x$Fin,1),stringsAsFactors=FALSE)))}))
>   row.names(res)<- 1:nrow(res)
>   df2[11,8]<- "31/12/2013"
>   names(res)[1]<- "Mat"
>   identical(res,df2)
> #[1] TRUE
>
>
> A.K.
>
>
>
> ----- Original Message -----
> From: arun <smartpink111 at yahoo.com>
> To: Arnaud Michel <michel.arnaud at cirad.fr>
> Cc: R help <r-help at r-project.org>
> Sent: Sunday, July 14, 2013 2:39 PM
> Subject: Re: [R] simplify a dataframe
>
> Hi,
> May be this helps you.
> df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad"
> df1[48,8]
> [1] "31/12/4712" #strange value
>
> df1[48,8]<- "31/12/2013"  #changed
>
> indx<-as.numeric(interaction(df1[,1:6],drop=TRUE))
> res<-do.call(rbind,lapply(split(df1,indx),function(x) {x1<- as.Date(x$Debut,format="%d/%m/%Y");x2<- as.Date(x$Fin,format="%d/%m/%Y");do.call(rbind,lapply(split(x,cumsum(c(FALSE,(x1[-1]-x2[-nrow(x)])!=1))),function(x) data.frame(x[1,1:6],Debut=head(x$Debut,1),Fin=tail(x$Fin,1),stringsAsFactors=FALSE)))}))
>
>   res[order(res$Matricule),]  #the order of rows is a bit different than df2.
>      Matricule    Nom     Sexe DateNaissance                contrat        Pays
> 5           1  VERON  F?minin    02/09/1935             CDI commun      France
> 4.0         6 BENARD Masculin    01/04/1935             CDI commun      France
> 4.1         6 BENARD Masculin    01/04/1935             CDI commun      France
> 10          6 BENARD Masculin    01/04/1935             CDI commun Philippines
> 6           8 DALNIC  F?minin    19/02/1940             CDI commun      France
> 9           8 DALNIC  F?minin    19/02/1940             CDI commun  Martinique
> 1         934  FORNI Masculin    10/07/1961 CDD d?tach? ext. Cirad    Cameroun
> 2         934  FORNI Masculin    10/07/1961             CDI commun       Congo
> 3         934  FORNI Masculin    10/07/1961    CDI D?tach?s Autres       Congo
> 7         934  FORNI Masculin    10/07/1961    CDI D?tach?s Autres      France
> 8         934  FORNI Masculin    10/07/1961             CDI commun       Gabon
>           Debut        Fin
> 5   24/01/1995 31/12/1997
> 4.0 13/03/1995 30/06/1995
> 4.1 01/01/1996 31/01/1996
> 10  02/02/1995 12/03/1995
> 6   24/01/1995 31/08/1995
> 9   01/09/1995 29/02/2000
> 1   26/01/1995 31/08/2001
> 2   05/09/2012 31/12/2013
> 3   01/09/2004 31/08/2007
> 7   01/09/2001 31/08/2004
> 8   01/09/2007 04/09/2012
>
>
> A.K.
>
>
>
> ________________________________
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>; jholtman at gmail.com; Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Sunday, July 14, 2013 12:17 PM
> Subject: Re: [R] simplify a dataframe
>
>
>
> Hi,
> Excuse me for the indistinctness
>
> Le 13/07/2013 17:18, arun a ?crit :
>
> Hi,
> "when the value of Debut of lines i = value Fin of lines i-1"
> That part is not clear esp. when it is looked upon with the expected output (df2).
> I want to group the lines which have the same caracteristics (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays) and with period of time (Debut/start and Fin/end) without interruption of time.
> For exemple :
> The following three lines
>      :
>      Debut/Start  Fin/End
> 1  VERON  F?minin    02/09/1935             CDI commun      France 24/01/1995 30/04/1997
> 1  VERON  F?minin    02/09/1935             CDI commun      France
>      01/05/1997 30/12/1997
> 1  VERON  F?minin    02/09/1935             CDI commun      France
>      31/12/1997 31/12/1997
> are transformed into 1 line
> 1  VERON  F?minin    02/09/1935             CDI commun      France 24/01/1995 31/12/1997
> because same caracteristicsand period of time without interruption
>      of time (from 24/01/1995 to 31/12/1997)
>
> The following six lines :
> 6 BENARD Masculin    01/04/1935             CDI commun Philippines 02/02/1995 27/02/1995
> 6 BENARD Masculin    01/04/1935             CDI commun Philippines
>      28/02/1995 28/02/1995
> 6 BENARD Masculin    01/04/1935             CDI commun Philippines
>      01/03/1995 12/03/1995
> 6 BENARD Masculin    01/04/1935             CDI commun      France 13/03/1995 30/06/1995
> 6 BENARD Masculin    01/04/1935             CDI commun      France 01/01/1996 30/01/1996
> 6 BENARD Masculin    01/04/1935             CDI commun      France
>      31/01/1996 31/01/1996
> are transformed into
> 6 BENARD Masculin    01/04/1935             CDI commun Philippines 02/02/1995 12/03/1995
> 6 BENARD Masculin    01/04/1935             CDI commun      France 13/03/1995 30/06/1995
> 6 BENARD Masculin    01/04/1935             CDI commun      France 01/01/1996 31/01/1996
> because
> lines 1-3 identical for caracteristics and without interruption in
>      time
> lines 4 and lines 5-6 are not grouped because there is an
>      interruption in time beetween 30/06/1995 and 01/01/1996
>
> Thank you for your help
> Michel
>
>
>    Also, in your example dataset: df1$contrat[grep("^CDD",df1$contrat)]
> #[1] "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad" "CDD d?tach? ext. Cirad"
> #[4] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"  "CDD d?tach? ext. Cirad"
> #[7] "CDD d?tach? ext. Cirad" "CDD d?tach? ext.Cirad"  "CDD d?tach? ext. Cirad"
> ##Looks like there are extra spaces in some of them.  I guess these are the same
> df1$contrat[grep("^CDD",df1$contrat)]<- "CDD d?tach? ext. Cirad" I tried this:
> indx<-as.numeric(interaction(df1[,1:6],drop=FALSE))  df1New<- df1
> res2<-unique(within(df1New,{Debut<-ave(seq_along(indx),indx,FUN=function(x) Debut[head(x,1)]);Fin<- ave(seq_along(indx),indx,FUN=function(x) Fin[tail(x,1)])}))
>   row.names(res2)<- 1:nrow(res2) res2[,c(1,2,7:8)]
>     Matricule    Nom      Debut        Fin
> 1          1  VERON 24/01/1995 31/12/1997
> 2          6 BENARD 02/02/1995 12/03/1995
> 3          6 BENARD 13/03/1995 31/01/1996 ###here not correct
> 4          8 DALNIC 24/01/1995 31/08/1995
> 5          8 DALNIC 01/09/1995 29/02/2000
> 6        934  FORNI 26/01/1995 31/08/2001
> 7        934  FORNI 01/09/2001 31/08/2004
> 8        934  FORNI 01/09/2004 31/08/2007
> 9        934  FORNI 01/09/2007 04/09/2012
> 10       934  FORNI 05/09/2012 31/12/4712 df2[,c(1,2,7:8)]
>     Mat    Nom      Debut        Fin
> 1    1  VERON 24/01/1995 31/12/1997
> 2    6 BENARD 02/02/1995 12/03/1995
> 3    6 BENARD 13/03/1995 30/06/1995
> 4    6 BENARD 01/01/1996 31/01/1996 #missing this row
> 5    8 DALNIC 24/01/1995 31/08/1995
> 6    8 DALNIC 01/09/1995 29/02/2000
> 7  934  FORNI 26/01/1995 31/08/2001
> 8  934  FORNI 01/09/2001 31/08/2004
> 9  934  FORNI 01/09/2004 31/08/2007
> 10 934  FORNI 01/09/2007 04/09/2012
> 11 934  FORNI 05/09/2012 31/12/4712 Here, the dates look similar to the ones on df2 except for one row in df2. A.K. ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr> To: R help <r-help at r-project.org> Cc:
> Sent: Friday, July 12, 2013 3:45 PM
> Subject: [R] simplify a dataframe Hello I have the following problem : group the lines of a dataframe when no
> information change (Matricule, Nom, Sexe, DateNaissance, Contrat, Pays)
> and when the value of Debut of lines i = value Fin of lines i-1
> I can obtain it with a do loop. Is it possible to avoid the loop ? The dataframe initial is df1
> dput(df1)
> structure(list(Matricule = c(1L, 1L, 1L, 6L, 6L, 6L, 6L, 6L,
> 6L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 8L, 934L, 934L, 934L, 934L,
> 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
> 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L, 934L,
> 934L, 934L, 934L, 934L), Nom = c("VERON", "VERON", "VERON", "BENARD",
> "BENARD", "BENARD", "BENARD", "BENARD", "BENARD", "DALNIC", "DALNIC",
> "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC", "DALNIC",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI",
> "FORNI", "FORNI"), Sexe = c("F?minin", "F?minin", "F?minin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "F?minin", "F?minin", "F?minin", "F?minin", "F?minin", "F?minin",
> "F?minin", "F?minin", "F?minin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin", "Masculin", "Masculin",
> "Masculin", "Masculin", "Masculin"), DateNaissance = c("02/09/1935",
> "02/09/1935", "02/09/1935", "01/04/1935", "01/04/1935", "01/04/1935",
> "01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
> "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940", "19/02/1940",
> "19/02/1940", "19/02/1940", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961",
> "10/07/1961", "10/07/1961"), contrat = c("CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad",
> "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext.
> Cirad",
> "CDD d?tach? ext. Cirad", "CDD d?tach? ext. Cirad", "CDD d?tach? ext.
> Cirad",
> "CDD d?tach? ext. Cirad", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI D?tach?s Autres",
> "CDI D?tach?s Autres", "CDI D?tach?s Autres", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun"), Pays = c("France", "France", "France", "Philippines",
> "Philippines", "Philippines", "France", "France", "France", "France",
> "France", "Martinique", "Martinique", "Martinique", "Martinique",
> "Martinique", "Martinique", "Martinique", "Cameroun", "Cameroun",
> "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun", "Cameroun",
> "Cameroun", "France", "France", "France", "France", "France",
> "France", "France", "Congo", "Congo", "Congo", "Congo", "Congo",
> "Congo", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon", "Gabon",
> "Congo", "Congo"), Debut = c("24/01/1995", "01/05/1997", "31/12/1997",
> "02/02/1995", "28/02/1995", "01/03/1995", "13/03/1995", "01/01/1996",
> "31/01/1996", "24/01/1995", "01/07/1995", "01/09/1995", "01/07/1997",
> "01/01/1998", "01/08/1998", "01/01/2000", "17/01/2000", "29/02/2000",
> "26/01/1995", "01/07/1996", "16/09/1997", "01/01/1998", "01/07/1998",
> "04/11/1999", "01/01/2001", "01/04/2001", "31/08/2001", "01/09/2001",
> "02/09/2001", "01/12/2001", "01/02/2003", "01/04/2003", "01/01/2004",
> "01/03/2004", "01/09/2004", "01/01/2005", "01/04/2005", "28/10/2006",
> "01/01/2007", "01/04/2007", "01/09/2007", "01/01/2009", "01/04/2009",
> "01/01/2010", "01/01/2011", "01/04/2011", "05/09/2012", "01/01/2013"
> ), Fin = c("30/04/1997", "30/12/1997", "31/12/1997", "27/02/1995",
> "28/02/1995", "12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996",
> "30/06/1995", "31/08/1995", "30/06/1997", "31/12/1997", "31/07/1998",
> "31/12/1999", "16/01/2000", "28/02/2000", "29/02/2000", "30/06/1996",
> "15/09/1997", "31/12/1997", "30/06/1998", "03/11/1999", "31/12/2000",
> "31/03/2001", "30/08/2001", "31/08/2001", "01/09/2001", "30/11/2001",
> "31/01/2003", "31/03/2003", "31/12/2003", "29/02/2004", "31/08/2004",
> "31/12/2004", "31/03/2005", "27/10/2006", "31/12/2006", "31/03/2007",
> "31/08/2007", "31/12/2008", "31/03/2009", "31/12/2009", "31/12/2010",
> "31/03/2011", "04/09/2012", "31/12/2012", "31/12/4712")), .Names =
> c("Matricule",
> "Nom", "Sexe", "DateNaissance", "contrat", "Pays", "Debut", "Fin"
> ), class = "data.frame", row.names = c(NA, -48L)) The dataframe to be obtained is df2
> dput(df2)
> structure(list(Mat = c(1L, 6L, 6L, 6L, 8L, 8L, 934L, 934L, 934L,
> 934L, 934L), Nom = c("VERON", "BENARD", "BENARD", "BENARD", "DALNIC",
> "DALNIC", "FORNI", "FORNI", "FORNI", "FORNI", "FORNI"), Sexe = c("F?minin",
> "Masculin", "Masculin", "Masculin", "F?minin", "F?minin", "Masculin",
> "Masculin", "Masculin", "Masculin", "Masculin"), DateNaissance =
> c("02/09/1935",
> "01/04/1935", "01/04/1935", "01/04/1935", "19/02/1940", "19/02/1940",
> "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961", "10/07/1961"
> ), contrat = c("CDI commun", "CDI commun", "CDI commun", "CDI commun",
> "CDI commun", "CDI commun", "CDD d?tach? ext. Cirad", "CDI D?tach?s
> Autres",
> "CDI D?tach?s Autres", "CDI commun", "CDI commun"), Pays = c("France",
> "Philippines", "France", "France", "France", "Martinique", "Cameroun",
> "France", "Congo", "Gabon", "Congo"), Debut = c("24/01/1995",
> "02/02/1995", "13/03/1995", "01/01/1996", "24/01/1995", "01/09/1995",
> "26/01/1995", "01/09/2001", "01/09/2004", "01/09/2007", "05/09/2012"
> ), Fin = c("31/12/1997", "12/03/1995", "30/06/1995", "31/01/1996",
> "31/08/1995", "29/02/2000", "31/08/2001", "31/08/2004", "31/08/2007",
> "04/09/2012", "31/12/4712")), .Names = c("Mat", "Nom", "Sexe",
> "DateNaissance", "contrat", "Pays", "Debut", "Fin"), class =
> "data.frame", row.names = c(NA,
> -11L)) Thank you for your help
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From cisneros32 at gmail.com  Mon Jul 15 03:09:03 2013
From: cisneros32 at gmail.com (Laura Cisneros)
Date: Sun, 14 Jul 2013 21:09:03 -0400
Subject: [R] Replacing values of a matrix with values from corresponding
 rows of another matrix
Message-ID: <CAHC96XF5B8KXecV+_4CTxFk9Bb9HTyeDrdnKXbWM5QzniUk8mg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/0f549a4a/attachment.pl>

From keasans at gmail.com  Mon Jul 15 04:50:36 2013
From: keasans at gmail.com (kiran subedi)
Date: Sun, 14 Jul 2013 22:50:36 -0400
Subject: [R] (no subject)
Message-ID: <CANQ7S+n+JunGg6DBRcTy8rEwRw6UiUgdb3Mgw9mDBbGDGgVvCw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130714/4f9afb13/attachment.pl>

From dwinsemius at comcast.net  Mon Jul 15 08:27:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 14 Jul 2013 23:27:25 -0700
Subject: [R] Does R ever stop responding without a message?
In-Reply-To: <CAMgNocvhTQXqn8GfqLCwKQ59G7LTBdZF8-a_m0JpPEuMhmD71g@mail.gmail.com>
References: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>
	<CAAxdm-6-dafYecJ+EKGefS8X+6kWyqPTfqpuNsCi2B6_WHhdhA@mail.gmail.com>
	<CAMgNocvhTQXqn8GfqLCwKQ59G7LTBdZF8-a_m0JpPEuMhmD71g@mail.gmail.com>
Message-ID: <496C97B9-4EE5-40A8-93BE-19F3844C0453@comcast.net>


On Jul 14, 2013, at 8:24 PM, L S wrote:

> Thanks Jim and David for your helpful feedback.  I still have not terminated RStudio (and it still has not gone to completion).  A few observations I forgot to mention is that the red "stop" icon is showing in RStudio so I am unable to enter any new commands.  Also there is a blinking cursor under the "> command" I ran with no > before the cursor.
> 

 I thought I mentioned that these questions are off-topic on Rhelp. They should be directed to a different mailing list, either the Mac-SIG-mailing list or the RStudio list.

> David--Looking at the activity monitor, RStudio is using anywhere from 0.4-1% of CPU while another process called rsession is using anywhere from 17-23% CPU.  Does this mean it has given up processing the R command?

No. In fact the opposite, but you obviously have a great deal more patience than I do. I would long ago have shutdown R (using the force-quit functions from the "Apple menu" and then restarted.) I generally notice around 100%  in the % "CPU column" in the table whin R is active, although the scrolling "CPU Usage" graphic at teh bottom of thepage will max out at 25% because the R process is not distributed across all 4 cores.

>   If so, is there anything I can do to ensure this won't happen next time I try to run the command with my data?

If you do not tell us exactly what the command was _and_ the size and structure of the data involved, it is unlikely that we can tell you much of anything. 

> 
> (Also, how can you tell if the process is using virtual memory?)

One of the columns in the CPU activity monitor is labeled "Virtual Mem". If it is being used the number will change.

> 
> Jim--What I'm running now is just a single instruction using the split function, so I would not be able to put in the progress messages.  But, that's a great idea! I will keep that in mind if I run into problems with scripts in the future.
> 
> Thank you.
> 
> 
> On Sun, Jul 14, 2013 at 6:46 PM, jim holtman <jholtman at gmail.com> wrote:
> If you are writing a script that you know will take a long time to process, "pepper" it with "progress" reports so you know what part of the script it is in and when it is going around loop.  On some of my long scripts, I will print out a message every n'th time through the loop so that I know if it making progress.  I position them so that I get out a message every minute or so.  Also make sure the GUI is not buffered, or better, follow each status with a 'flush.console()' to put the message out to the screen.  This will give you a feeling of what progress you are making.  
> 
> 
> On Sun, Jul 14, 2013 at 5:40 PM, L S <losedaghat at gmail.com> wrote:
> Hi,
> 
> Have any of you ever encountered a situation where R stops processing an
> instruction but does not give a "not responding" message?
> 
> The reason I ask is I am working in RStudio (Mac OS/X 10.7, 1.8 Ghz i7, 4
> GB DDR3) and the instruction I entered in the command line pane is still
> being processed since last night around 7 PM.  I expected it to take on the
> order of 8-12 hours to complete, but I'm nearing 24 hours with no progress,
> no messages, etc.
> 
> The command is essentially splitting the a ppp (marked point pattern) into
> a tessellation/grid.  There are about a couple million points in the
> pattern and each has a vector of four marks.  That said, I processed a
> similar command with 700,000 points in the pattern (each point with a
> vector of two marks) yesterday and it took only around 3 hours.
> 
> Is there anyway I can be certain the command is being processed?  I don't
> want to abort prematurely if I know it will go to completion.  How long
> would you give it before you knew for certain it would not complete?
> 
> Any guidance you could offer would be much appreciated.
> 
> Thanks,
> Lily
> 


David Winsemius
Alameda, CA, USA


From nblaser at ispm.unibe.ch  Mon Jul 15 08:40:14 2013
From: nblaser at ispm.unibe.ch (Blaser Nello)
Date: Mon, 15 Jul 2013 06:40:14 +0000
Subject: [R] Replacing values of a matrix with values from corresponding
 rows of another matrix
In-Reply-To: <CAHC96XF5B8KXecV+_4CTxFk9Bb9HTyeDrdnKXbWM5QzniUk8mg@mail.gmail.com>
References: <CAHC96XF5B8KXecV+_4CTxFk9Bb9HTyeDrdnKXbWM5QzniUk8mg@mail.gmail.com>
Message-ID: <91AB1D950BA285438A9873CCC9B61C12017CC8@mx02.ispm.unibe.ch>

For small matrix you could use a for-loop.

for (i in 1:nrow(randomized)){
  randomized[i,randomized[i,]!=0] <- sample(original[i,original[i,]!=0])
}
randomized

If you have a larger matrix sapply is probably faster
randomized <- t(sapply(1:nrow(randomized), function(i) {
  randomized[i,randomized[i,]!=0] <- sample(original[i,original[i,]!=0])
  randomized[i,]
}))
randomized

Best, 
Nello

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Laura Cisneros
Sent: Montag, 15. Juli 2013 03:09
To: r-help at r-project.org
Subject: [R] Replacing values of a matrix with values from corresponding rows of another matrix

Hello all,

I have been trying to figure out how to replace non-zero values of a matrix with non-zero values from corresponding rows from another matrix. More specifically, let say we have the following original matrix:

original <-
matrix(c(0,0,4,0,0,1,2,2,12,1,0,2,0,5,0,0,10,1,3,1,0,5,0,4),byrow=TRUE,nrow=4,ncol=6)
> original
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    0    4    0    0    1
[2,]    2    2   12    1    0    2
[3,]    0    5    0    0   10    1
[4,]    3    1    0    5    0    4

And we randomize this matrix such that the total of occurrences of non-zero values in each row and column are maintained in the randomized matrix:

randomized <-
matrix(c(0,0,12,0,0,1,2,2,0,5,10,2,0,1,4,0,0,1,3,5,0,1,0,4),byrow=TRUE,nrow=4,ncol=6)
> randomized
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    0   12    0    0    1
[2,]    2    2    0    5   10    2
[3,]    0    1    4    0    0    1
[4,]    3    5    0    1    0    4

What I would like to do now is replace (in a random fashion) the non-zero values in each row of the randomized matrix using the non-zero values from the corresponding rows in the original matrix. For example, for row 1 I would like to randomly replace 12 and 1 (from the randomized matrix) with 4 and 1 (from the original matrix). Then do this for each row.

Any suggestions on how I may be able to accomplish this would be greatly appreciated.

Laura
--
Laura Cisneros, Doctoral Candidate
Dept. of Ecology and Evolutionary Biology University of Connecticut
75 N. Eagleville Road, U-3043
Storrs, CT 06269-3043

Tel: (860) 486-1772
Fax: (860) 486-5488
Alternative Email: laura.cisneros at uconn.edu

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Jul 15 09:28:33 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 15 Jul 2013 07:28:33 +0000
Subject: [R] (no subject)
In-Reply-To: <CANQ7S+n+JunGg6DBRcTy8rEwRw6UiUgdb3Mgw9mDBbGDGgVvCw@mail.gmail.com>
References: <CANQ7S+n+JunGg6DBRcTy8rEwRw6UiUgdb3Mgw9mDBbGDGgVvCw@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7DC89@SRVEXCHMBX.precheza.cz>

Hi

Most methods can somehow deal with NA values. You can find many packages regarding discriminant analysis by simply searching CRAN. 

discriminant analysis site:r-project.org

Or you can look to CRAN task view Multivariate statistics

maybe package pls or DiscriMiner does what you want.

You can also get rid of NA values by using

?complete.cases

function.

However I am a bit worried by your number of variables.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of kiran subedi
> Sent: Monday, July 15, 2013 4:51 AM
> To: r-help at r-project.org
> Subject: [R] (no subject)
> 
> Hi,
> I am a researcher in chemistry. I have to do pls-da for some of my
> samples.
> The number of variables for my sample is 4000 . The categorical
> variable has two classes. Some of the values are missing (cant find
> out).
> I s there any package for R (or any illustration that would be helpful)
> to perform PLS-DA in R by ignoring the missing values.
> 
> 
> Thank you
> kiran
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gysc at leeds.ac.uk  Mon Jul 15 09:46:44 2013
From: gysc at leeds.ac.uk (Stephen Clark)
Date: Mon, 15 Jul 2013 08:46:44 +0100
Subject: [R] Optimisation does not optimise!
In-Reply-To: <51E142DE.4060803@uottawa.ca>
References: <mailman.29.1373709610.15244.r-help@r-project.org>
	<51E142DE.4060803@uottawa.ca>
Message-ID: <928C4F7877280844B906D12D63A3F15B01145E64C555@HERMES8.ds.leeds.ac.uk>

Thanks for this guidance. 

In light of your advice I have reduced the titanic to a dingy by reducing the size of my sample to just 100 instances, making this an optimisation of 100 parameters. I am, however, seeing similar output when I output the function value at each evaluation. This is the tail of the information in the optout results structure

[1] 70104.64
[1] 70104.67
[1] 70104.64
[1] 70104.67
[1] 70104.64
[1] 70104.67
[1] 70104.64
[1] 70104.66
[1] 70104.64
[1] 70104.66
> optout
$par
  [1] 1.003 1.003 1.003 1.003 1.003 1.003 1.003 1.003 1.003 1.003 1.003 1.003
[13] ...
[97] 1.003 1.003 1.003 1.003

$value
[1] 70104.4

$counts
function gradient 
     501       NA 

$convergence
[1] 1

$message
NULL

Can you or anyone suggest another optimisation routine I can use? I initially coded this into EXCEL and used the solver addin to do an optimisation of 200 parameters. R was my attempt to increase this number of parameters. I do not, unfortunately, have any derivative information.

-- 
Stephen Clark, 
Second year PhD,  School of Geography
Tel : 0113 343 6707
Email : gysc at leeds.ac.uk 
Web : http://www.geog.leeds.ac.uk/people/s.clark

-----Original Message-----
From: Prof J C Nash (U30A) [mailto:nashjc at uottawa.ca] 
Sent: 13 July 2013 13:07
To: r-help at r-project.org; Stephen Clark
Subject: [R] Optimisation does not optimise!

Considering that I devised the code initially on a computer with only 8K bytes for program and data, and it appears that your problem has 10000 parameters, I'm surprised you got any output. I suspect the printout is the BUILD phase where each weight is being adjusted in turn by the same shift.

Don't try to move the Titanic on a pram.

If you work out a gradient function, you can likely use Rcgmin (even though I wrote original CG in optim(), not recommended). spg from BB may also work OK.

This problem is near linear, so there are other approaches.

JN


From ligges at statistik.tu-dortmund.de  Mon Jul 15 10:12:45 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 15 Jul 2013 10:12:45 +0200
Subject: [R] CRAN and www.r-project.org with limited availability today
Message-ID: <51E3AEFD.1040108@statistik.tu-dortmund.de>

The CRAN master machines are being moved to the new WU campus in Vienna 
today.  The services will be partially or completely unavailable, 
including www.r-project.org, ftp uploads for packages and the web 
submission form. We expect services to be available again this evening 
European time.

The CRAN team


From helios.derosario at ibv.upv.es  Mon Jul 15 11:27:38 2013
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Mon, 15 Jul 2013 11:27:38 +0200
Subject: [R] Change R options only inside a package
Message-ID: <51E3DCAA0200000C00016EE4@mailhost.biomec.upv.es>

Hi,

What should I do if I want to use "non-default" R-options for the
functions inside a package, but not affect the options of the rest of
the session? Specifically, I'm thinking of using "sum contrasts" instead
of the default, in functions like "lm", etc. when they are called by
other functions in a package.

I can think on the following solutions:

1) Quick-and-dirty solution: use options() to modify the default
contrasts before calling my functions. If I don't want to affect the
rest of the session, I should reset the options before returning,
preferably with exception handling to avoid that the options are not
reset if my function fails.

2) Complex-but-tidier solution: Use function-specific arguments to tell
the contrasts of the factors that I'm using. E.g., I should create a
named list of contrasts and pass it as the argument "contrasts" every
time I call "lm":

mod <- lm(form, contrasts=list(factor1="contr.sum",
factor2="contr.sum"))


3) Encapsulated solution: create package-specific (unexported) versions
of "lm" and other functions, that already implement #2, e.g.:

lm <- function(...)
{
# Code that examines dots, to get the factors of the model, and create
the list of contrasts
# Then call the stats lm (be sure that dots did not already include a
"contrasts" element).
stats::lm(..., contrasts = list.of.factors.with.sum.contrasts)
}

I don't like #1, because changing the options back and forth may be
error-prone and lead to unexpected behaviour.

#2 is better, but prone to programmer errors: I should be careful of
not forgetting to set the "contrasts" argument every time I call "lm".

I prefer #3, because it avoids the disadvantages of the previous
solutions, but perhaps it is overkill, hence my question: Is there a
"clean" way of setting the R-session options in such a way that they
only affect the functions and data inside a package?

Thanks and best regards

Helios De Rosario

INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
www.ibv.org

  Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From jholtman at gmail.com  Mon Jul 15 11:50:45 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Mon, 15 Jul 2013 05:50:45 -0400
Subject: [R] Does R ever stop responding without a message?
In-Reply-To: <CAMgNocvhTQXqn8GfqLCwKQ59G7LTBdZF8-a_m0JpPEuMhmD71g@mail.gmail.com>
References: <CAMgNocsH=e_=qMS_fgoCV=d2dDS+QArhnFnJ47EJ_j94t4YGAg@mail.gmail.com>
	<CAAxdm-6-dafYecJ+EKGefS8X+6kWyqPTfqpuNsCi2B6_WHhdhA@mail.gmail.com>
	<CAMgNocvhTQXqn8GfqLCwKQ59G7LTBdZF8-a_m0JpPEuMhmD71g@mail.gmail.com>
Message-ID: <968B4069-319D-4440-9D0A-FCF2A0D6B7F1@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/149698ed/attachment.pl>

From S.Ellison at LGCGroup.com  Mon Jul 15 12:55:55 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 15 Jul 2013 11:55:55 +0100
Subject: [R] Sending carbon copy mails from R
In-Reply-To: <1373593728556-4671376.post@n4.nabble.com>
References: <CEE8C35195DB944D9C75ABB15A04193B24CA5961@EHKG17P32001A.csfb.cs-group.com>
	<1373593728556-4671376.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACBB58334@GOLD.corp.lgc-group.com>


> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Alok Jadhav
> updated code pasted here. So I guess CC is not an option at 
> all? In that case is there any other package that would be useful?

I'm guessing here (based on experience of PHP's sendmail interface), but CC is just another header field for sendmail. The package sendmailR has a headers= argument to its sendmail function that accepts 'other headers' and therefore ought to accept  CC addresses. Since that argument's a list and the sendmailR code simply pastes names and list contents before sending, I'd guess that something of the form list(CC=cc.recipient at example.com) might work, though the documentation is not very helpful on the format of the list. 

S Ellison

> -----Original Message-----
> From: r-help-bounces at r-project.org 
> [mailto:r-help-bounces at r-project.org] On Behalf Of Alok Jadhav
> Sent: 12 July 2013 02:49
> To: r-help at r-project.org
> Subject: Re: [R] Sending carbon copy mails from R
> 
> updated code pasted here. So I guess CC is not an option at 
> all? In that case is there any other package that would be useful?
> 
> require(sendmailR)
> to <- c("v.n at abc.com")
> header <- list(cc=c("a.j at abc.com"))
> x <- sendmail("toto at abc.com", to, "test", "testing",
> header=header,control=list(smtpServer=server,verbose=TRUE))
> << 220 equity.xyz.com ESMTP Sendmail 8.11.7p1+Sun/8.11.7; 
> Thu, 11 Jul 2013
> 21:31:43 -0400 (EDT)
> >> HELO  HKD03836654
> << 250 equity.xyz.com Hello HKD03836654.gbl.ad.net 
> [169.34.175.142], pleased to meet you
> >> MAIL FROM:  toto at abc.com
> << 250 2.1.0 toto at abc.com... Sender ok
> >> RCPT TO:  v.n at abc.com
> << 250 2.1.5 v.n at abc.com... Recipient ok
> >> DATA
> << 354 Enter mail, end with "." on a line by itself
> >> <message data>
> << 250 2.0.0 r6C1Vh101169 Message accepted for delivery
> >> QUIT
> << 221 2.0.0 equity.csfb.com closing connection
> 
> 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Sending-carbon-copy-mails-from-R
> -tp4671153p4671376.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From andreas.leha at med.uni-goettingen.de  Mon Jul 15 13:11:11 2013
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Mon, 15 Jul 2013 13:11:11 +0200
Subject: [R] suppress startup messages from default packages
Message-ID: <87oba43wog.fsf@med.uni-goettingen.de>

Hi all,

several packages print messages during loading.  How do I avoid to see
them when the packages are in the defaultPackages?

Here is an example.

With this in ~/.Rprofile
,----[ ~/.Rprofile ]
| old <- getOption("defaultPackages")
| options(defaultPackages = c(old, "filehash"))
| rm(old)
`----

I get as last line when starting R:
,----
| filehash: Simple key-value database (2.2-1 2012-03-12)
`----

Another package with (even more) prints during startup is tikzDevice.

How can I avoid to get these messages?

Regards,
Andreas


From hanson at depauw.edu  Mon Jul 15 13:18:49 2013
From: hanson at depauw.edu (Bryan Hanson)
Date: Mon, 15 Jul 2013 07:18:49 -0400
Subject: [R] (no subject)
In-Reply-To: <CANQ7S+n+JunGg6DBRcTy8rEwRw6UiUgdb3Mgw9mDBbGDGgVvCw@mail.gmail.com>
References: <CANQ7S+n+JunGg6DBRcTy8rEwRw6UiUgdb3Mgw9mDBbGDGgVvCw@mail.gmail.com>
Message-ID: <A9046783-C6FF-42B8-8F1D-F32D862B9398@depauw.edu>

Look at the package chemometrics, it can certainly handle your number of variables (p > n is what that's called and it requires special considerations).  I don't recall about missing values.  The authors of that package also have a very helpful text.  Good Luck. Bryan

On Jul 14, 2013, at 10:50 PM, kiran subedi <keasans at gmail.com> wrote:

> Hi,
> I am a researcher in chemistry. I have to do pls-da for some of my samples.
> The number of variables for my sample is 4000 . The categorical variable
> has two classes. Some of the values are missing (cant find out).
> I s there any package for R (or any illustration that would be helpful) to
> perform PLS-DA in R by ignoring the missing values.
> 
> 
> Thank you
> kiran
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch.duncan at gmail.com  Mon Jul 15 13:30:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 15 Jul 2013 07:30:25 -0400
Subject: [R] Change R options only inside a package
In-Reply-To: <51E3DCAA0200000C00016EE4@mailhost.biomec.upv.es>
References: <51E3DCAA0200000C00016EE4@mailhost.biomec.upv.es>
Message-ID: <51E3DD51.4040300@gmail.com>

On 13-07-15 5:27 AM, Helios de Rosario wrote:
> Hi,
>
> What should I do if I want to use "non-default" R-options for the
> functions inside a package, but not affect the options of the rest of
> the session? Specifically, I'm thinking of using "sum contrasts" instead
> of the default, in functions like "lm", etc. when they are called by
> other functions in a package.
>
> I can think on the following solutions:
>
> 1) Quick-and-dirty solution: use options() to modify the default
> contrasts before calling my functions. If I don't want to affect the
> rest of the session, I should reset the options before returning,
> preferably with exception handling to avoid that the options are not
> reset if my function fails.
>
> 2) Complex-but-tidier solution: Use function-specific arguments to tell
> the contrasts of the factors that I'm using. E.g., I should create a
> named list of contrasts and pass it as the argument "contrasts" every
> time I call "lm":
>
> mod <- lm(form, contrasts=list(factor1="contr.sum",
> factor2="contr.sum"))
>
>
> 3) Encapsulated solution: create package-specific (unexported) versions
> of "lm" and other functions, that already implement #2, e.g.:
>
> lm <- function(...)
> {
> # Code that examines dots, to get the factors of the model, and create
> the list of contrasts
> # Then call the stats lm (be sure that dots did not already include a
> "contrasts" element).
> stats::lm(..., contrasts = list.of.factors.with.sum.contrasts)
> }
>
> I don't like #1, because changing the options back and forth may be
> error-prone and lead to unexpected behaviour.
>
> #2 is better, but prone to programmer errors: I should be careful of
> not forgetting to set the "contrasts" argument every time I call "lm".
>
> I prefer #3, because it avoids the disadvantages of the previous
> solutions, but perhaps it is overkill, hence my question: Is there a
> "clean" way of setting the R-session options in such a way that they
> only affect the functions and data inside a package?
>

I'd recommend that in your own functions that need this, you put this at 
the beginning:

  saveOpts <- options(contrasts = c("contr.sum", "contr.sum"))
  on.exit(options(saveOpts))

This means that the options will be changed just for the duration of the 
call.  If there are situations where users might not want this new 
default, make the new value a default of a function argument.

Duncan Murdoch



> Thanks and best regards
>
> Helios De Rosario
>
> INSTITUTO DE BIOMEC?NICA DE VALENCIA
> Universidad Polit?cnica de Valencia ? Edificio 9C
> Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
> Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
> www.ibv.org
>
>    Antes de imprimir este e-mail piense bien si es necesario hacerlo.
> En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
> de Datos de Car?cter Personal, le informamos de que el presente mensaje
> contiene informaci?n confidencial, siendo para uso exclusivo del
> destinatario arriba indicado. En caso de no ser usted el destinatario
> del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
> o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
> rog?ndole lo notifique al remitente.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From sascha at cognition.uni-freiburg.de  Mon Jul 15 13:41:04 2013
From: sascha at cognition.uni-freiburg.de (Sascha Wolfer)
Date: Mon, 15 Jul 2013 13:41:04 +0200
Subject: [R] Weird 'xmlEventParse' encoding issue
Message-ID: <51E3DFD0.1000302@cognition.uni-freiburg.de>

Dear list,

I have got a weird encoding problem with the xmlEventParse() function 
from the 'XML' package.

I tried finding an answer on the web for several hours and a Stack 
Exchange question came back without success :(

So here's the problem. I created a small XML test file, which looks like 
this:

<?xml version="1.0" encoding="iso-8859-1"?>
<!DOCTYPE testFile>
<s type="manual">auch der Schulleiter steht daf?r zur Verf?gung. Das ist 
se?haft mit ? und ?...</s>

This file is encoded with the iso-8859-1 encoding which is also defined 
in its header.

I have 3 handler functions, definitions as follows:

sE2 <- function (name, attrs) {
   if (name == "s") {
     get.text <<- T }
}

eE2 <- function (name, attrs) {
   if (name == "s") {
     get.text <<- F
   }
}

tS2 <- function (content, ...) {
   if (get.text & nchar(content) > 0) {
     collected.text <<- c(collected.text, content)
   }
}

I have one wrapper function around xmlEventParse(), definition as follows:

get.all.text <- function (file) {
   t1 <- Sys.time()
   read.file <- paste(readLines(file, encoding = ""), collapse = " ")
   print(read.file)
   assign("collected.text", c(), env = .GlobalEnv)
   assign("get.text", F, env = .GlobalEnv)
   xmlEventParse(read.file, asText = T, list(startElement = sE2,
                                            endElement = eE2,
                                            text = tS2),
                error = function (...) { },
                saxVersion = 1)
   t2 <- Sys.time()
   cat("That took", round(difftime(t2,t1, units="secs"), 1), "seconds.\n")
   cat("Result of reading is in variable 'collected.text'.\n")
   collected.text
}

The output of calling get.all.text(<test file>) is as follows:
[1] "<?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <!DOCTYPE testFile> 
<s type=\"manual\">auch der Schulleiter steht daf?r zur Verf?gung. Das 
ist se?haft mit ? und ?...</s> "
That took 0 seconds.
Result of reading is in variable 'collected.text'.
[1] "auch der Schulleiter steht daf"                        "??r zur 
Verf??gung. Das ist se??haft mit ?? und ??..."

Now the REALLY weird thing (for me) is that R obviously reads in the 
file correctly (first output) with 'readLines()'. Then this output is 
passed to xmlEventParse. Afterwards the output is broken and it 
sometimes also inserts weird breaks were special characters occur.

Do you have any ideas how to solve this problem?

I cannot use the xmlParse() function because I need the SAX 
functionality of xmlEventParse(). I also tried reading the file with 
xmlEventParse() directly (with asText = F). No changes...

Thanks a lot,
Sascha W.


From ruipbarradas at sapo.pt  Mon Jul 15 13:44:47 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 15 Jul 2013 12:44:47 +0100
Subject: [R] diallel analysis
In-Reply-To: <CADHyn5jkDiD-9Gw0u+ppmWJTBudA5P4_Q1g1pr=BhjXGEPd-4Q@mail.gmail.com>
References: <CADHyn5jqp9_HQy0EXR2+W3WXt4=s8CgRxH4MgM7eauF7AOJx1w@mail.gmail.com>
	<51E27B54.6090807@sapo.pt> <51E27CEA.8030609@sapo.pt>
	<CADHyn5jkDiD-9Gw0u+ppmWJTBudA5P4_Q1g1pr=BhjXGEPd-4Q@mail.gmail.com>
Message-ID: <51E3E0AF.5090108@sapo.pt>

Hello,

You should Cc the list.
What I meant is that, at an R prompt you should type

install.packages(pkgname)

substituting 'pkgname' by the name of the package you're using.

Rui Barradas

Em 15-07-2013 12:01, waqas shafqat escreveu:
> Sorry sir
>
> i could not find the install.packages(pkgname) in RGui3.0.0. i m using
> the CRAN mirror UK(London). i want to perform diallel analysis in R.
>
>
> On Sun, Jul 14, 2013 at 3:26 PM, Rui Barradas <ruipbarradas at sapo.pt
> <mailto:ruipbarradas at sapo.pt>> wrote:
>
>     Sorry,
>
>     It's the plural:
>
>     install.packages(pkgname)
>
>     Rui Barradas
>
>     Em 14-07-2013 11:20, Rui Barradas escreveu:
>
>         Hello,
>
>         Which package is it?
>         Maybe you need to install it. And after installing it, you need
>         to load
>         it in the R session. You do this with the following commands.
>
>
>         install.package(pkgname)  # do this only once
>
>         library(pkgname)  # do this every new R session
>
>
>         Hope this helps,
>
>         Rui Barradas
>
>         Em 14-07-2013 06:49, waqas shafqat escreveu:
>
>             sir i could not find the plant breeding libraray in Rgui3.0.0
>
>                  [[alternative HTML version deleted]]
>
>             ________________________________________________
>             R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>             https://stat.ethz.ch/mailman/__listinfo/r-help
>             <https://stat.ethz.ch/mailman/listinfo/r-help>
>             PLEASE do read the posting guide
>             http://www.R-project.org/__posting-guide.html
>             <http://www.R-project.org/posting-guide.html>
>             and provide commented, minimal, self-contained, reproducible
>             code.
>
>
>         ________________________________________________
>         R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/__listinfo/r-help
>         <https://stat.ethz.ch/mailman/listinfo/r-help>
>         PLEASE do read the posting guide
>         http://www.R-project.org/__posting-guide.html
>         <http://www.R-project.org/posting-guide.html>
>         and provide commented, minimal, self-contained, reproducible code.
>
>


From helios.derosario at ibv.upv.es  Mon Jul 15 13:47:35 2013
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Mon, 15 Jul 2013 13:47:35 +0200
Subject: [R] Change R options only inside a package
In-Reply-To: <51E3DD51.4040300@gmail.com>
References: <51E3DCAA0200000C00016EE4@mailhost.biomec.upv.es>
	<51E3DD51.4040300@gmail.com>
Message-ID: <51E3FD770200000C00016F26@mailhost.biomec.upv.es>

>>> El d?a 15/07/2013 a las 13:30, Duncan Murdoch
<murdoch.duncan at gmail.com> escribi?:
> On 13-07-15 5:27 AM, Helios de Rosario wrote:
>> Hi,
>>
>> What should I do if I want to use "non-default" R-options for the
>> functions inside a package, but not affect the options of the rest
of
>> the session? Specifically, I'm thinking of using "sum contrasts"
instead
>> of the default, in functions like "lm", etc. when they are called
by
>> other functions in a package.

[...]

> I'd recommend that in your own functions that need this, you put this
at 
> the beginning:
> 
>   saveOpts <- options(contrasts = c("contr.sum", "contr.sum"))
>   on.exit(options(saveOpts))
> 
> This means that the options will be changed just for the duration of
the 
> call.  If there are situations where users might not want this new 
> default, make the new value a default of a function argument.

Thank you very much. I was not aware of the on.exit function.

Helios De Rosario

INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
www.ibv.org

  Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From helios.derosario at ibv.upv.es  Mon Jul 15 14:39:03 2013
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Mon, 15 Jul 2013 14:39:03 +0200
Subject: [R] suppress startup messages from default packages
Message-ID: <51E409870200000C00016F39@mailhost.biomec.upv.es>

> Hi all,
> 
> several packages print messages during loading.  How do I avoid to
see
> them when the packages are in the defaultPackages?
> 
> Here is an example.
> 
> With this in ~/.Rprofile
> ,----[ ~/.Rprofile ]
> | old <- getOption("defaultPackages")
> | options(defaultPackages = c(old, "filehash"))
> | rm(old)
> `----
> 
> I get as last line when starting R:
> ,----
> | filehash: Simple key-value database (2.2-1 2012-03-12)
> `----
> 
> Another package with (even more) prints during startup is
tikzDevice.
> 
>How can I avoid to get these messages?


There are several options in ?library to control the messages that are
displayed when loading packages. However, this does not seem be able to
supress all the messages. Some messages are defined by the package
authors, because they feel necessary that the user reads them.

Helios De Rosario

> Regards,
> Andreas


INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
www.ibv.org

  Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From andreas.leha at med.uni-goettingen.de  Mon Jul 15 14:49:48 2013
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Mon, 15 Jul 2013 14:49:48 +0200
Subject: [R] suppress startup messages from default packages
References: <51E409870200000C00016F39@mailhost.biomec.upv.es>
Message-ID: <87k3ks3s43.fsf@med.uni-goettingen.de>

Hi Helios,

"Helios de Rosario" <helios.derosario at ibv.upv.es> writes:

>> Hi all,
>> 
>> several packages print messages during loading.  How do I avoid to
> see
>> them when the packages are in the defaultPackages?
>> 
>> Here is an example.
>> 
>> With this in ~/.Rprofile
>> ,----[ ~/.Rprofile ]
>> | old <- getOption("defaultPackages")
>> | options(defaultPackages = c(old, "filehash"))
>> | rm(old)
>> `----
>> 
>> I get as last line when starting R:
>> ,----
>> | filehash: Simple key-value database (2.2-1 2012-03-12)
>> `----
>> 
>> Another package with (even more) prints during startup is
> tikzDevice.
>> 
>>How can I avoid to get these messages?
>
>
> There are several options in ?library to control the messages that are
> displayed when loading packages. However, this does not seem be able to
> supress all the messages. Some messages are defined by the package
> authors, because they feel necessary that the user reads them.
>


Thanks for your answer.  When I actually call library() or require()
myself I can avoid all messages.  There are hacks to do that even for
the very persistent messages [fn:1].

My question is how to suppress these messages, when it is not me who
calls library() or require(), but when the package is loaded during R's
startup through the defaultPackages option.

Regards,
Andreas

Footnotes:

[fn:1] http://stackoverflow.com/a/8143671/1844418


From nashjc at uottawa.ca  Mon Jul 15 14:50:49 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Mon, 15 Jul 2013 08:50:49 -0400
Subject: [R] nls power law help
In-Reply-To: <mailman.17.1373882407.16795.r-help@r-project.org>
References: <mailman.17.1373882407.16795.r-help@r-project.org>
Message-ID: <51E3F029.3070004@uottawa.ca>

With minor corrections, the original problem can be "solved" with nlxb 
from nlmrt package.

 > coef(modeln)
           a           b
  -0.8470857 409.5190808

ssquares =  145585533

but since

 > svd(modeln$jacobian)$d
[1] 5.128345e+04 6.049076e-14
 >

I may have made nlmrt too robust.

JN



On 13-07-15 06:00 AM, r-help-request at r-project.org wrote:
> Message: 9
> Date: Sun, 14 Jul 2013 16:11:40 +0100
> From: Prof Brian Ripley<ripley at stats.ox.ac.uk>
> To:r-help at r-project.org
> Subject: Re: [R] nls power law help
> Message-ID:<51E2BFAC.1010008 at stats.ox.ac.uk>
> Content-Type: text/plain; charset=ISO-8859-1; format=flowed
>
> On 14/07/2013 14:30, JenPool wrote:
>> >Hi,
>> >
>> >I am trying to use a power law y=bx^a as a nls model as below, however I
>> >keep getting 'singular gradient' error. I have tried multiple different
>> >starting values but always get an error.
> That is not the model you tried to fit. b*x*exp(a) is always
> over-parametrized.


From zhqc2000 at gmail.com  Mon Jul 15 11:39:43 2013
From: zhqc2000 at gmail.com (Zhiqiang Cui)
Date: Mon, 15 Jul 2013 10:39:43 +0100
Subject: [R] ANOVA for mixture experiment
Message-ID: <CA+47UUCABe_NF1PsCAKS-FxeRGn1S0WAfvxf2tvRrygXPsFLiQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/5362d829/attachment.pl>

From bcrombie at utk.edu  Mon Jul 15 14:29:06 2013
From: bcrombie at utk.edu (bcrombie)
Date: Mon, 15 Jul 2013 05:29:06 -0700 (PDT)
Subject: [R] create new matrix from user-defined function
In-Reply-To: <1373683397.96477.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <1373483938637-4671250.post@n4.nabble.com>
	<F7E6D18CC2877149AB5296CE54EA27660F995461@WAXMXOLYMB025.WAX.wa.lcl>
	<559C998F7039D84C9793AE43D9BBE9CE7F3B8FA5@kmbx3.utk.tennessee.edu>
	<1373574512.14425.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1373575521.34142.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<559C998F7039D84C9793AE43D9BBE9CE7F3BA142@kmbx3.utk.tennessee.edu>
	<1373683397.96477.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE7F3BB1C1@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/74b9d1b8/attachment.pl>

From murdoch.duncan at gmail.com  Mon Jul 15 15:25:09 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 15 Jul 2013 09:25:09 -0400
Subject: [R] suppress startup messages from default packages
In-Reply-To: <87k3ks3s43.fsf@med.uni-goettingen.de>
References: <51E409870200000C00016F39@mailhost.biomec.upv.es>
	<87k3ks3s43.fsf@med.uni-goettingen.de>
Message-ID: <51E3F835.5090102@gmail.com>

On 15/07/2013 8:49 AM, Andreas Leha wrote:
> Hi Helios,
>
> "Helios de Rosario" <helios.derosario at ibv.upv.es> writes:
>
> >> Hi all,
> >>
> >> several packages print messages during loading.  How do I avoid to
> > see
> >> them when the packages are in the defaultPackages?
> >>
> >> Here is an example.
> >>
> >> With this in ~/.Rprofile
> >> ,----[ ~/.Rprofile ]
> >> | old <- getOption("defaultPackages")
> >> | options(defaultPackages = c(old, "filehash"))
> >> | rm(old)
> >> `----
> >>
> >> I get as last line when starting R:
> >> ,----
> >> | filehash: Simple key-value database (2.2-1 2012-03-12)
> >> `----
> >>
> >> Another package with (even more) prints during startup is
> > tikzDevice.
> >>
> >>How can I avoid to get these messages?
> >
> >
> > There are several options in ?library to control the messages that are
> > displayed when loading packages. However, this does not seem be able to
> > supress all the messages. Some messages are defined by the package
> > authors, because they feel necessary that the user reads them.
> >
>
>
> Thanks for your answer.  When I actually call library() or require()
> myself I can avoid all messages.  There are hacks to do that even for
> the very persistent messages [fn:1].
>
> My question is how to suppress these messages, when it is not me who
> calls library() or require(), but when the package is loaded during R's
> startup through the defaultPackages option.

You could try the --slave command line option on startup.  If that isn't 
sufficient, try getting the maintainer to change the package behaviour, 
or do it yourself.

Duncan Murdoch


From cisneros32 at gmail.com  Mon Jul 15 15:31:07 2013
From: cisneros32 at gmail.com (Laura Cisneros)
Date: Mon, 15 Jul 2013 09:31:07 -0400
Subject: [R] Replacing values of a matrix with values from corresponding
 rows of another matrix
In-Reply-To: <91AB1D950BA285438A9873CCC9B61C12017CC8@mx02.ispm.unibe.ch>
References: <CAHC96XF5B8KXecV+_4CTxFk9Bb9HTyeDrdnKXbWM5QzniUk8mg@mail.gmail.com>
	<91AB1D950BA285438A9873CCC9B61C12017CC8@mx02.ispm.unibe.ch>
Message-ID: <CAHC96XFhP42fSY0PN3PsPF3sMsdLGB7m5xqR6SB0BfT-m1hJvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/ab1fd253/attachment.pl>

From mtmorgan at fhcrc.org  Mon Jul 15 15:59:59 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 15 Jul 2013 06:59:59 -0700
Subject: [R] suppress startup messages from default packages
In-Reply-To: <51E3F835.5090102@gmail.com>
References: <51E409870200000C00016F39@mailhost.biomec.upv.es>
	<87k3ks3s43.fsf@med.uni-goettingen.de> <51E3F835.5090102@gmail.com>
Message-ID: <51E4005F.1000305@fhcrc.org>

On 07/15/2013 06:25 AM, Duncan Murdoch wrote:
> On 15/07/2013 8:49 AM, Andreas Leha wrote:
>> Hi Helios,
>>
>> "Helios de Rosario" <helios.derosario at ibv.upv.es> writes:
>>
>> >> Hi all,
>> >>
>> >> several packages print messages during loading.  How do I avoid to
>> > see
>> >> them when the packages are in the defaultPackages?
>> >>
>> >> Here is an example.
>> >>
>> >> With this in ~/.Rprofile
>> >> ,----[ ~/.Rprofile ]
>> >> | old <- getOption("defaultPackages")
>> >> | options(defaultPackages = c(old, "filehash"))
>> >> | rm(old)
>> >> `----
>> >>
>> >> I get as last line when starting R:
>> >> ,----
>> >> | filehash: Simple key-value database (2.2-1 2012-03-12)
>> >> `----
>> >>
>> >> Another package with (even more) prints during startup is
>> > tikzDevice.
>> >>
>> >>How can I avoid to get these messages?
>> >
>> >
>> > There are several options in ?library to control the messages that are
>> > displayed when loading packages. However, this does not seem be able to
>> > supress all the messages. Some messages are defined by the package
>> > authors, because they feel necessary that the user reads them.
>> >
>>
>>
>> Thanks for your answer.  When I actually call library() or require()
>> myself I can avoid all messages.  There are hacks to do that even for
>> the very persistent messages [fn:1].
>>
>> My question is how to suppress these messages, when it is not me who
>> calls library() or require(), but when the package is loaded during R's
>> startup through the defaultPackages option.
>
> You could try the --slave command line option on startup.  If that isn't
> sufficient, try getting the maintainer to change the package behaviour, or do it
> yourself.

In a hack-y way ?setHook and ?sink seem to work

 > setHook(packageEvent("filehash", "onLoad"), function(...) 
sink(file(tempfile(), "w"), type="message"))
 > setHook(packageEvent("filehash", "attach"), function(...) sink(file=NULL, 
type="message"), "append")
 > library(filehash)
 >

Martin

>
> Duncan Murdoch
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From S.Ellison at LGCGroup.com  Mon Jul 15 16:18:19 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Mon, 15 Jul 2013 15:18:19 +0100
Subject: [R] ANOVA for mixture experiment
In-Reply-To: <CA+47UUCABe_NF1PsCAKS-FxeRGn1S0WAfvxf2tvRrygXPsFLiQ@mail.gmail.com>
References: <CA+47UUCABe_NF1PsCAKS-FxeRGn1S0WAfvxf2tvRrygXPsFLiQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACBB584D2@GOLD.corp.lgc-group.com>

> But the ANOVA results is incorrect when I use
> 
> aov.out = aov(Response~-1+x1*x2*x3).
First, this doesn't work at all. Your variables are in upper case and your data environment is not specified, so you must have done something else. I can get an answer using something like
anova(lm(Response~-1+X1*X2*X3-I(X1*X2*X3), data=d))
(I dropped the indetyerminable 3-way product explicitly)

Second, your answer differs from that listed by 'the original paper' at least partly because you have done something different from what has been done in the paper. You have asked for anova using Type I sums of squares. The paper has apparently calculated something other than a Type I sums of squares ANOVA.
 
Try calculating using Type 3 sums of squares using Anova from the car package. I did that using
Anova(lm(Response~-1+X1+X2+X3+I(X1*X2)+I(X1*X3)+I(X2*X3), data=d), type=3)

Then read the help page - especially the "Warning" section - for ?Anova very carefully ...


S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From wewolski at gmail.com  Mon Jul 15 16:23:27 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 15 Jul 2013 16:23:27 +0200
Subject: [R] file.stem?
Message-ID: <CAAjnpdgk6b22YaxW_omsv-croyptL4X91xWdQQAgpXg=uPT2jA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/30d16697/attachment.pl>

From sguallar at yahoo.com  Mon Jul 15 16:29:01 2013
From: sguallar at yahoo.com (Santiago Guallar)
Date: Mon, 15 Jul 2013 07:29:01 -0700 (PDT)
Subject: [R] speed up a function
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7D11A@SRVEXCHMBX.precheza.cz>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CB97@SRVEXCHMBX.precheza.cz>
	<1373352766.36843.YahooMailNeo@web160805.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE20@SRVEXCHMBX.precheza.cz>
	<1373400143.37646.YahooMailNeo@web160805.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7D11A@SRVEXCHMBX.precheza.cz>
Message-ID: <1373898541.26482.YahooMailNeo@web160806.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/8c3815eb/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Jul 15 16:31:26 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 15 Jul 2013 07:31:26 -0700
Subject: [R] file.stem?
In-Reply-To: <CAAjnpdgk6b22YaxW_omsv-croyptL4X91xWdQQAgpXg=uPT2jA@mail.gmail.com>
References: <CAAjnpdgk6b22YaxW_omsv-croyptL4X91xWdQQAgpXg=uPT2jA@mail.gmail.com>
Message-ID: <f6e1e117-0afd-4095-9c72-acb74552a0bb@email.android.com>

Read the Posting Guide... use plain text email.

help.search("file")

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Witold E Wolski <wewolski at gmail.com> wrote:

>Looking for a function which returns the stem of the filename given a
>path.
>i.e.
>> file.stem("/the/path/to/afile.txt")
>> afile
>
>regards


From ruipbarradas at sapo.pt  Mon Jul 15 16:32:42 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 15 Jul 2013 15:32:42 +0100
Subject: [R] file.stem?
In-Reply-To: <CAAjnpdgk6b22YaxW_omsv-croyptL4X91xWdQQAgpXg=uPT2jA@mail.gmail.com>
References: <CAAjnpdgk6b22YaxW_omsv-croyptL4X91xWdQQAgpXg=uPT2jA@mail.gmail.com>
Message-ID: <51E4080A.90508@sapo.pt>

Hello,

You can use ?basename to write a file.stem function:


basename("/the/path/to/afile.txt")

file.stem <- function(x){
	bn <- basename(x)
	gsub("\\..*$", "", bn)
}
file.stem("/the/path/to/afile.txt")



Hope this helps,

Rui Barradas

Em 15-07-2013 15:23, Witold E Wolski escreveu:
> Looking for a function which returns the stem of the filename given a path.
> i.e.
>> file.stem("/the/path/to/afile.txt")
>> afile
>
> regards
>


From rodriguez.victor at inifap.gob.mx  Mon Jul 15 16:42:31 2013
From: rodriguez.victor at inifap.gob.mx (RODRIGUEZ MORENO VICTOR MANUEL)
Date: Mon, 15 Jul 2013 09:42:31 -0500
Subject: [R] choose many files
Message-ID: <7FE7553A-2DB9-4197-BA48-4C6F06126CCA@mimectl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/b89e28fe/attachment.pl>

From wewolski at gmail.com  Mon Jul 15 16:53:05 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Mon, 15 Jul 2013 16:53:05 +0200
Subject: [R] file.stem?
In-Reply-To: <51E4080A.90508@sapo.pt>
References: <CAAjnpdgk6b22YaxW_omsv-croyptL4X91xWdQQAgpXg=uPT2jA@mail.gmail.com>
	<51E4080A.90508@sapo.pt>
Message-ID: <CAAjnpdiQtHcxcW1WLZbRwKGy7Qhw=VbV9CyJcDPcucs8BaxNUA@mail.gmail.com>

Rui, Thank you

On 15 July 2013 16:32, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> You can use ?basename to write a file.stem function:
>
>
> basename("/the/path/to/afile.txt")
>
> file.stem <- function(x){
>         bn <- basename(x)
>         gsub("\\..*$", "", bn)
> }
> file.stem("/the/path/to/afile.txt")
>
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 15-07-2013 15:23, Witold E Wolski escreveu:
>
>> Looking for a function which returns the stem of the filename given a
>> path.
>> i.e.
>>>
>>> file.stem("/the/path/to/afile.txt")
>>> afile
>>
>>
>> regards
>>
>



-- 
Witold Eryk Wolski


From dcarlson at tamu.edu  Mon Jul 15 17:19:42 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 15 Jul 2013 10:19:42 -0500
Subject: [R] Replacing values of a matrix with values from corresponding
	rows of another matrix
In-Reply-To: <CAHC96XFhP42fSY0PN3PsPF3sMsdLGB7m5xqR6SB0BfT-m1hJvw@mail.gmail.com>
References: <CAHC96XF5B8KXecV+_4CTxFk9Bb9HTyeDrdnKXbWM5QzniUk8mg@mail.gmail.com>	<91AB1D950BA285438A9873CCC9B61C12017CC8@mx02.ispm.unibe.ch>
	<CAHC96XFhP42fSY0PN3PsPF3sMsdLGB7m5xqR6SB0BfT-m1hJvw@mail.gmail.com>
Message-ID: <051a01ce816e$bad41550$307c3ff0$@tamu.edu>

This should also work:

> mask <- randomized > 0
> mask
      [,1]  [,2]  [,3]  [,4]  [,5] [,6]
[1,] FALSE FALSE  TRUE FALSE FALSE TRUE
[2,]  TRUE  TRUE FALSE  TRUE  TRUE TRUE
[3,] FALSE  TRUE  TRUE FALSE FALSE TRUE
[4,]  TRUE  TRUE FALSE  TRUE FALSE TRUE
> randomized[mask] <- original[mask]
> randomized
     [,1] [,2] [,3] [,4] [,5] [,6]
[1,]    0    0    4    0    0    1
[2,]    2    2    0    1    0    2
[3,]    0    5    0    0    0    1
[4,]    3    1    0    5    0    4

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Laura Cisneros
Sent: Monday, July 15, 2013 8:31 AM
To: Blaser Nello
Cc: r-help at r-project.org
Subject: Re: [R] Replacing values of a matrix with values from
corresponding rows of another matrix

Great! Thank you, Nello. It works on my larger matrices.


On Mon, Jul 15, 2013 at 2:40 AM, Blaser Nello
<nblaser at ispm.unibe.ch> wrote:

> For small matrix you could use a for-loop.
>
> for (i in 1:nrow(randomized)){
>   randomized[i,randomized[i,]!=0] <-
sample(original[i,original[i,]!=0])
> }
> randomized
>
> If you have a larger matrix sapply is probably faster
> randomized <- t(sapply(1:nrow(randomized), function(i) {
>   randomized[i,randomized[i,]!=0] <-
sample(original[i,original[i,]!=0])
>   randomized[i,]
> }))
> randomized
>
> Best,
> Nello
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org]
> On Behalf Of Laura Cisneros
> Sent: Montag, 15. Juli 2013 03:09
> To: r-help at r-project.org
> Subject: [R] Replacing values of a matrix with values from
corresponding
> rows of another matrix
>
> Hello all,
>
> I have been trying to figure out how to replace non-zero values of
a
> matrix with non-zero values from corresponding rows from another
matrix.
> More specifically, let say we have the following original matrix:
>
> original <-
>
>
matrix(c(0,0,4,0,0,1,2,2,12,1,0,2,0,5,0,0,10,1,3,1,0,5,0,4),byrow=TR
UE,nrow=4,ncol=6)
> > original
>      [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]    0    0    4    0    0    1
> [2,]    2    2   12    1    0    2
> [3,]    0    5    0    0   10    1
> [4,]    3    1    0    5    0    4
>
> And we randomize this matrix such that the total of occurrences of
> non-zero values in each row and column are maintained in the
randomized
> matrix:
>
> randomized <-
>
>
matrix(c(0,0,12,0,0,1,2,2,0,5,10,2,0,1,4,0,0,1,3,5,0,1,0,4),byrow=TR
UE,nrow=4,ncol=6)
> > randomized
>      [,1] [,2] [,3] [,4] [,5] [,6]
> [1,]    0    0   12    0    0    1
> [2,]    2    2    0    5   10    2
> [3,]    0    1    4    0    0    1
> [4,]    3    5    0    1    0    4
>
> What I would like to do now is replace (in a random fashion) the
non-zero
> values in each row of the randomized matrix using the non-zero
values from
> the corresponding rows in the original matrix. For example, for
row 1 I
> would like to randomly replace 12 and 1 (from the randomized
matrix) with 4
> and 1 (from the original matrix). Then do this for each row.
>
> Any suggestions on how I may be able to accomplish this would be
greatly
> appreciated.
>
> Laura
> --
> Laura Cisneros, Doctoral Candidate
> Dept. of Ecology and Evolutionary Biology University of
Connecticut
> 75 N. Eagleville Road, U-3043
> Storrs, CT 06269-3043
>
> Tel: (860) 486-1772
> Fax: (860) 486-5488
> Alternative Email: laura.cisneros at uconn.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
>


-- 
Laura Cisneros, Doctoral Candidate
Dept. of Ecology and Evolutionary Biology
University of Connecticut
75 N. Eagleville Road, U-3043
Storrs, CT 06269-3043

Tel: (860) 486-1772
Fax: (860) 486-5488
Alternative Email: laura.cisneros at uconn.edu

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Mon Jul 15 17:39:15 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 15 Jul 2013 15:39:15 +0000
Subject: [R] speed up a function
In-Reply-To: <1373898541.26482.YahooMailNeo@web160806.mail.bf1.yahoo.com>
References: <1372787235.19754.YahooMailNeo@web160804.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CB97@SRVEXCHMBX.precheza.cz>
	<1373352766.36843.YahooMailNeo@web160805.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7CE20@SRVEXCHMBX.precheza.cz>
	<1373400143.37646.YahooMailNeo@web160805.mail.bf1.yahoo.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7D11A@SRVEXCHMBX.precheza.cz>
	<1373898541.26482.YahooMailNeo@web160806.mail.bf1.yahoo.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7DE9E@SRVEXCHMBX.precheza.cz>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/5d0da6ad/attachment.pl>

From nicomet80 at gmail.com  Mon Jul 15 17:50:01 2013
From: nicomet80 at gmail.com (Nico Met)
Date: Mon, 15 Jul 2013 17:50:01 +0200
Subject: [R] t-test across columns
Message-ID: <CAMMD=S7NdUzgVof5-CyEedGyC2gBwq6zSFdQSQ5Xo3_yuRFuzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/53eff2e6/attachment.pl>

From alice.julien-laferriere at univ-lyon1.fr  Mon Jul 15 16:59:31 2013
From: alice.julien-laferriere at univ-lyon1.fr (=?ISO-8859-1?Q?Alice_Julien-Laferri=E8re?=)
Date: Mon, 15 Jul 2013 16:59:31 +0200
Subject: [R] Problem with plot in several cases, font issue?
In-Reply-To: <51E40DF7.1030901@univ-lyon1.fr>
References: <51E40DF7.1030901@univ-lyon1.fr>
Message-ID: <51E40E53.2030900@univ-lyon1.fr>

Dear all,

I am having problem on plots in R for some cases.

For example:

> plot( 1:10 )
> text( 1:10, letters[1:10], cex = 1)

works well but :

> plot(1:10)
> text(1:10, letters[1:10], cex = 0.9)

returns :
Erreur dans text.default(1:10, letters[1:10], cex = 0.9) :
   impossible de charger la police X11
-adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, de face 1 et de taille 11

(sorry for the french).
In this message, for other cases the function may changed (it can be
axis( ) for example) but it always a font problem.

I encountered this issue various times (with more complicated graphics).

I'm working on ubuntu 12.04 with R 3.0.1 (2013-05-16).


The capabilities function returns me:
   jpeg      png     tiff    tcltk      X11     aqua http/ftp sockets
TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
  libxml     fifo   cledit    iconv      NLS  profmem    cairo
  TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE


I think this may be an issue with my installation, but I could not
figured out what was the missing package.
I tried this on other computers. I did not see the same bug.


Thanks in advance for the help,

Alice


From eric.archer at noaa.gov  Mon Jul 15 18:11:59 2013
From: eric.archer at noaa.gov (Eric Archer - NOAA Federal)
Date: Mon, 15 Jul 2013 09:11:59 -0700
Subject: [R] Transferring commas in character vector to expression
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C31A45C@PA-MBX01.na.tibco.com>
References: <CAGrYeXjduaHxSKJ9Oq56WHNHTd+NtKXAktDNA+YMoUf+g-gC0g@mail.gmail.com>
	<201307062233.r66MXkNo028982@mail16.tpgi.com.au>
	<CAGrYeXh02OG+6rQ2meBpVEAdTVe9=9tE4nDSaGpg5=A62wJ+2w@mail.gmail.com>
	<201307070438.r674cbqq012554@mail15.tpg.com.au>
	<CAGrYeXi-saL2SGPfO_qSx15RB3=S9KOQ5W1ie1tuJSH1a92Dkg@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C31A45C@PA-MBX01.na.tibco.com>
Message-ID: <CAGrYeXjzfpvj4FPVeh+D6vGLXjUMBkvQqPCAiyE--RLQyh1v6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/158409af/attachment.pl>

From jholtman at gmail.com  Mon Jul 15 18:16:44 2013
From: jholtman at gmail.com (jim holtman)
Date: Mon, 15 Jul 2013 12:16:44 -0400
Subject: [R] choose many files
In-Reply-To: <7FE7553A-2DB9-4197-BA48-4C6F06126CCA@mimectl>
References: <7FE7553A-2DB9-4197-BA48-4C6F06126CCA@mimectl>
Message-ID: <CAAxdm-66f8N3T9tWrytBFr4ZseY+BPP4m5=hiqbA3H9cCA6i0g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/df6430f1/attachment.pl>

From ripley at stats.ox.ac.uk  Mon Jul 15 18:17:11 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 15 Jul 2013 17:17:11 +0100
Subject: [R] Problem with plot in several cases, font issue?
In-Reply-To: <51E40E53.2030900@univ-lyon1.fr>
References: <51E40DF7.1030901@univ-lyon1.fr> <51E40E53.2030900@univ-lyon1.fr>
Message-ID: <51E42087.5060302@stats.ox.ac.uk>

On 15/07/2013 15:59, Alice Julien-Laferri?re wrote:
> Dear all,
>
> I am having problem on plots in R for some cases.

Your machine has Cairo: Cairo-based X11 devices do not use those fonts. 
  So it seems you have done something you have not shown us.

The fix is to use the Cairo-based X11 devices.  See the R-admin manual 
for more details.

>
> For example:
>
>> plot( 1:10 )
>> text( 1:10, letters[1:10], cex = 1)
>
> works well but :
>
>> plot(1:10)
>> text(1:10, letters[1:10], cex = 0.9)
>
> returns :
> Erreur dans text.default(1:10, letters[1:10], cex = 0.9) :
>    impossible de charger la police X11
> -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, de face 1 et de taille 11
>
> (sorry for the french).

But it is very easy to set LANGUAGE=en to get American English messages ....

> In this message, for other cases the function may changed (it can be
> axis( ) for example) but it always a font problem.
>
> I encountered this issue various times (with more complicated graphics).
>
> I'm working on ubuntu 12.04 with R 3.0.1 (2013-05-16).
>
>
> The capabilities function returns me:
>    jpeg      png     tiff    tcltk      X11     aqua http/ftp sockets
> TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
>   libxml     fifo   cledit    iconv      NLS  profmem    cairo
>   TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE
>
>
> I think this may be an issue with my installation, but I could not
> figured out what was the missing package.
> I tried this on other computers. I did not see the same bug.
>
>
> Thanks in advance for the help,
>
> Alice
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From macqueen1 at llnl.gov  Mon Jul 15 18:34:25 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 15 Jul 2013 16:34:25 +0000
Subject: [R] Does R ever stop responding without a message?
In-Reply-To: <968B4069-319D-4440-9D0A-FCF2A0D6B7F1@gmail.com>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A5219149C16C@PRDEXMBX-08.the-lab.llnl.gov>

It is a (very) large marked point process object that is being split (see
original post), and that is some other kind of structure. So I think all
bets are off, in terms of what kind of duration to expect.

The folks on r-sig-geo might be able to help with suggestions for faster
approaches.

In terms of monitoring the process, I have a couple of suggestions.

The first is to turn on profiling (see ?Rprof). Unless things changed in R
3.x.x, Rprof writes to a file as it profiles, and one could watch the file
grow to determine that processing is still taking place. Admittedly, it's
a cheap trick, and runs the risk of slowing the process, especially if the
profile file gets big.

The other is to do the split manually with a loop. This way, one could
insert cat() statements to track the progress. This is probably what I
would do first. Indeed, one could also write timestamps and track the rate
at which splitting is taking place (i.e., is it getting slower and slower).

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/15/13 2:50 AM, "Jim Holtman" <jholtman at gmail.com> wrote:

>a 'split' function should not take hours to complete.  I will not even
>wait a couple of minutes for one until I look at other approaches.  Can
>you at least show what the command looks like and what the structure of
>the data is.  Are you trying to split a dataframe on multiple criteria?
>I tend to use 'data.table' for some of these operation, or split the
>indices of a dataframe instead of the data.  My own criteria is that if a
>single base function call is taking more than a minute, I see if there
>are options.
>
>This is also a case of "tell me what you want to do, not how you want to
>do it".
>
>Sent from my iPad
>
>On Jul 14, 2013, at 23:24, L S <losedaghat at gmail.com> wrote:
>
>> Thanks Jim and David for your helpful feedback.  I still have not
>>terminated RStudio (and it still has not gone to completion).  A few
>>observations I forgot to mention is that the red "stop" icon is showing
>>in RStudio so I am unable to enter any new commands.  Also there is a
>>blinking cursor under the "> command" I ran with no > before the cursor.
>> 
>> David--Looking at the activity monitor, RStudio is using anywhere from
>>0.4-1% of CPU while another process called rsession is using anywhere
>>from 17-23% CPU.  Does this mean it has given up processing the R
>>command?  If so, is there anything I can do to ensure this won't happen
>>next time I try to run the command with my data?
>> 
>> (Also, how can you tell if the process is using virtual memory?)
>> 
>> Jim--What I'm running now is just a single instruction using the split
>>function, so I would not be able to put in the progress messages.  But,
>>that's a great idea! I will keep that in mind if I run into problems
>>with scripts in the future.
>> 
>> Thank you.
>> 
>> 
>> On Sun, Jul 14, 2013 at 6:46 PM, jim holtman <jholtman at gmail.com> wrote:
>> If you are writing a script that you know will take a long time to
>>process, "pepper" it with "progress" reports so you know what part of
>>the script it is in and when it is going around loop.  On some of my
>>long scripts, I will print out a message every n'th time through the
>>loop so that I know if it making progress.  I position them so that I
>>get out a message every minute or so.  Also make sure the GUI is not
>>buffered, or better, follow each status with a 'flush.console()' to put
>>the message out to the screen.  This will give you a feeling of what
>>progress you are making.
>> 
>> 
>> On Sun, Jul 14, 2013 at 5:40 PM, L S <losedaghat at gmail.com> wrote:
>> Hi,
>> 
>> Have any of you ever encountered a situation where R stops processing an
>> instruction but does not give a "not responding" message?
>> 
>> The reason I ask is I am working in RStudio (Mac OS/X 10.7, 1.8 Ghz i7,
>>4
>> GB DDR3) and the instruction I entered in the command line pane is still
>> being processed since last night around 7 PM.  I expected it to take on
>>the
>> order of 8-12 hours to complete, but I'm nearing 24 hours with no
>>progress,
>> no messages, etc.
>> 
>> The command is essentially splitting the a ppp (marked point pattern)
>>into
>> a tessellation/grid.  There are about a couple million points in the
>> pattern and each has a vector of four marks.  That said, I processed a
>> similar command with 700,000 points in the pattern (each point with a
>> vector of two marks) yesterday and it took only around 3 hours.
>> 
>> Is there anyway I can be certain the command is being processed?  I
>>don't
>> want to abort prematurely if I know it will go to completion.  How long
>> would you give it before you knew for certain it would not complete?
>> 
>> Any guidance you could offer would be much appreciated.
>> 
>> Thanks,
>> Lily
>> 
>>         [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> -- 
>> Jim Holtman
>> Data Munger Guru
>>  
>> What is the problem that you are trying to solve?
>> Tell me what you want to do, not how you want to do it.
>> 
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Jul 15 18:58:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 15 Jul 2013 09:58:40 -0700 (PDT)
Subject: [R] t-test across columns
In-Reply-To: <CAMMD=S7NdUzgVof5-CyEedGyC2gBwq6zSFdQSQ5Xo3_yuRFuzg@mail.gmail.com>
References: <CAMMD=S7NdUzgVof5-CyEedGyC2gBwq6zSFdQSQ5Xo3_yuRFuzg@mail.gmail.com>
Message-ID: <1373907520.99173.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Not sure about the format for the 2nd part.
df1<- ##data

library(plyr)
df2<-ddply(df1,.(name,cat),summarize, cbind(t.test(val,df1$val)$statistic,t.test(val,df1$val)$p.value))
?df3<-cbind(df2[,1:2],data.frame(df2[,3]))
?colnames(df3)[3:4]<- c("t-val","p.val")
library(reshape2)
df3m<-? melt(df3,id.var=c("name","cat"))
xtabs(value~name+cat+variable,data=df3m)
, , variable = t-val

????? cat
name????? p178266580??? p178269196??? p178316310??? p191287337??? p195158904
? 12.2 -1.1697701975 -5.2812696387 -1.2740973341? 2.1926665883? 0.1529759080
? 15.9 -2.5063901671? 0.0000000000 -0.2169806106? 1.5455008954 -1.6574358795
????? cat
name????? p196921846??? p197427158??? p238921966
? 12.2? 0.2260409495 -0.3320635130? 3.3659689025
? 15.9? 6.6278680348? 0.0000000000? 0.0000000000

, , variable = p.val

????? cat
name????? p178266580??? p178269196??? p178316310??? p191287337??? p195158904
? 12.2? 0.3092408498? 0.0003382099? 0.3762474897? 0.0419925673? 0.8812900356
? 15.9? 0.0147796276? 0.0000000000? 0.8365830321? 0.1822041450? 0.1096087365
????? cat
name????? p196921846??? p197427158??? p238921966
? 12.2? 0.8226135494? 0.7435688987? 0.0071990164
? 15.9? 0.0005489640? 0.0000000000? 0.0000000000

#or
res<-dcast(df3m,name~cat+variable,value.var="value")
row.names(res)<- res[,1]
?res1<- res[,-1]
res1
???? p178266580_t-val p178266580_p.val p178269196_t-val p178269196_p.val
12.2???????? -1.16977?????? 0.30924085???????? -5.28127???? 0.0003382099
15.9???????? -2.50639?????? 0.01477963?????????????? NA?????????????? NA
???? p178316310_t-val p178316310_p.val p191287337_t-val p191287337_p.val
12.2?????? -1.2740973??????? 0.3762475???????? 2.192667?????? 0.04199257
15.9?????? -0.2169806??????? 0.8365830???????? 1.545501?????? 0.18220414
???? p195158904_t-val p195158904_p.val p196921846_t-val p196921846_p.val
12.2??????? 0.1529759??????? 0.8812900??????? 0.2260409????? 0.822613549
15.9?????? -1.6574359??????? 0.1096087??????? 6.6278680????? 0.000548964
???? p197427158_t-val p197427158_p.val p238921966_t-val p238921966_p.val
12.2?????? -0.3320635??????? 0.7435689???????? 3.365969????? 0.007199016
15.9?????????????? NA?????????????? NA?????????????? NA?????????????? NA

A.K.


----- Original Message -----
From: Nico Met <nicomet80 at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Monday, July 15, 2013 11:50 AM
Subject: [R] t-test across columns

Dear all,

I would like to do t-test across two columns "name" with different "cat"
with overall mean ("val").

(Removing if there is a single observation)

And finally, make a matrix with t-value and p-value associated with a name
(in rows) and cat (in columns)

dput(x)
structure(list(name = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("12.2", "15.9"
), class = "factor"), cat = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 1L, 1L, 1L, 3L, 1L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label = c("p178266580",
"p178269196", "p178316310", "p191287337", "p195158904", "p196921846",
"p197427158", "p238921966"), class = "factor"), val = c(148.90772,
184.253375, 183.974866666667, 191.868125, 173.30515, 187.876975,
177.453775, 184.799525, 212.39065, 205.504525, 186.152025, 194.337075,
193.2703, 204.71665, 211.4452, 202.609175, 203.72918, 193.7261,
196.1186, 202.79556, 203.48818, 191.13744, 205.23315, 198.66842,
196.81032, 200.90512, 206.13564, 205.372225, 196.22835, 211.04686,
219.977133333333, 224.7602, 231.6596, 211.105816666667, 215.44474,
210.83514, 228.173125, 224.09034, 212.96026, 239.0085, 213.5407,
227.12115, 209.24888, 232.8964, 232.22146, 228.1643, 236.43082,
232.20792, 238.49192, 224.64014, 233.75898, 207.06138, 215.3649,
211.14802, 201.86854, 200.52278, 199.05752, 194.90904, 214.44334,
249.357266666667, 239.98525, 234.508483333333, 243.865083333333,
233.595816666667, 248.1219, 225.289416666667, 248.220883333333,
193.69566, 198.43578, 205.06055, 208.525975, 198.28692, 206.88496,
201.60162, 205.7943, 210.5117, 196.69886, 193.58288, 198.86094,
201.81676, 225.8266, 205.879725, 218.370475, 214.006125, 198.74038,
206.00314, 198.37446, 225.5357, 216.721025, 226.543925, 158.1011,
158.15674, 166.07518, 179.942225, 158.16046, 165.0685, 159.56146
)), .Names = c("name", "cat", "val"), class = "data.frame", row.names = c(
NA,
97L))

Thanks

Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Thorn.Thaler at rdls.nestle.com  Mon Jul 15 19:08:35 2013
From: Thorn.Thaler at rdls.nestle.com (Thaler,Thorn,LAUSANNE,Applied Mathematics)
Date: Mon, 15 Jul 2013 17:08:35 +0000
Subject: [R] ggplot2: Remove geom
Message-ID: <EDB44DA865211646A192A94DF3C6FA6707785C@DEMDCE0057.nestle.com>

Dear all,

Is there a possibility to remove a geom from a ggplot? Background suppose I have a function which returns a ggplot object after some data re-formatting and aggregation. While this ggplot object is fine in 90% of the cases it turns out that for some cases I want to suppress one of the layers which was added to the plot.

I could look at the source code of the function and write a new one, which has an additional flag parameter, with which I could ask the function to add or not to add the geom, but this sounds a bit of overkill to me and it would be nice, if I could just remove the particular layer?

An example is in order to make my point clearer:

library(ggplot2)
d <- data.frame(x=rep(1:10, each = 10), y = rnorm(100), grp = rep(1:10, 10))

makePlot <- function() {
  ggplot(d, aes(x = x, y = y)) + stat_summary(fun.data = "mean_cl_normal", color = "red") + geom_point() 
}

(p <- makePlot())

## Now I want to have lines instead of points, but of course the points are still there
p + geom_line(aes(group = grp, color = grp))

Again, it would not be difficult to rewrite makePlot to deal with that, but for me this seems to be error prone / duplication. So ideally, I would like to do something like:

p %-% geom_point()

which is ambiguous of course, as there can be several point layers in the plot. Looking at 

str(p)

I see that there is a layers slot, so I can do

q <- p
q$layers <- q$layers[-2]	
q + geom_line(aes(group = grp, color = grp))

which does actually what I want.

However, is there a way to do that in a more automated way? For now I have to inspect the object and to decide which layer I want to delete, otherwise I can get something like this:

makePlot2 <- function() {
  ggplot(d, aes(x = x, y = y)) + geom_point() + stat_summary(fun.data = "mean_cl_normal", color = "red")
}
q <- makePlot2()
q$layers <- q$layers[-2]	
q + geom_line(aes(group = grp, color = grp))

which removes the error bars but not the points (as the order in layers changed). So any ideas how to proceed in this case? If there is a nice way, I could even think of overloading %-% which would fit nicely in the idea of a plot which can not only be added layer by layer, but where I also could remove certain layers.

Maybe (and even probable) there is a very good idea why I should not do that at all and I would be curious to hear these things as well. For now I am yet interested to know how I can remove layers of a plot conveniently. 

Thanks for your help!

Kind Regards,

Thorn Thaler 


From dcarlson at tamu.edu  Mon Jul 15 19:33:03 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 15 Jul 2013 12:33:03 -0500
Subject: [R] t-test across columns
In-Reply-To: <CAMMD=S7NdUzgVof5-CyEedGyC2gBwq6zSFdQSQ5Xo3_yuRFuzg@mail.gmail.com>
References: <CAMMD=S7NdUzgVof5-CyEedGyC2gBwq6zSFdQSQ5Xo3_yuRFuzg@mail.gmail.com>
Message-ID: <05d201ce8181$5c4e4240$14eac6c0$@tamu.edu>

This may be close to what you want:

> t.val <- by(x, x$cat, function(y) if (min(table(y$name)>1)) {
+      t.test(val~name, y)})
> t.out <- do.call(rbind, sapply(t.val, function(y) c(y$statistic, 
+       p.value=y$p.value)))
> t.out
                    t      p.value
p178266580 -0.1156475 0.9144054453
p178316310 -1.0874356 0.4143944591
p191287337 -0.6776053 0.5315717871
p195158904  1.1522850 0.2769290728
p196921846 -4.2342996 0.0003925339

But I'm not sure what you mean about columns for each cat unless you
want the frequencies: 

> freq.out <- xtabs(~cat+name, x)
> freq.out <- freq.out[apply(freq.out, 1, function(y) min(y) > 1),]
> freq.out
            name
cat          12.2 15.9
  p178266580    4   11
  p178316310    2    3
  p191287337    3    5
  p195158904    8    7
  p196921846   26    5
> results <- cbind(freq.out, t.out)
> results
           12.2 15.9          t      p.value
p178266580    4   11 -0.1156475 0.9144054453
p178316310    2    3 -1.0874356 0.4143944591
p191287337    3    5 -0.6776053 0.5315717871
p195158904    8    7  1.1522850 0.2769290728
p196921846   26    5 -4.2342996 0.0003925339

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Nico Met
Sent: Monday, July 15, 2013 10:50 AM
To: R help
Subject: [R] t-test across columns

Dear all,

I would like to do t-test across two columns "name" with different
"cat"
with overall mean ("val").

(Removing if there is a single observation)

And finally, make a matrix with t-value and p-value associated with
a name
(in rows) and cat (in columns)

dput(x)
structure(list(name = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("12.2", "15.9"
), class = "factor"), cat = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 1L, 1L, 1L, 3L, 1L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label =
c("p178266580",
"p178269196", "p178316310", "p191287337", "p195158904",
"p196921846",
"p197427158", "p238921966"), class = "factor"), val = c(148.90772,
184.253375, 183.974866666667, 191.868125, 173.30515, 187.876975,
177.453775, 184.799525, 212.39065, 205.504525, 186.152025,
194.337075,
193.2703, 204.71665, 211.4452, 202.609175, 203.72918, 193.7261,
196.1186, 202.79556, 203.48818, 191.13744, 205.23315, 198.66842,
196.81032, 200.90512, 206.13564, 205.372225, 196.22835, 211.04686,
219.977133333333, 224.7602, 231.6596, 211.105816666667, 215.44474,
210.83514, 228.173125, 224.09034, 212.96026, 239.0085, 213.5407,
227.12115, 209.24888, 232.8964, 232.22146, 228.1643, 236.43082,
232.20792, 238.49192, 224.64014, 233.75898, 207.06138, 215.3649,
211.14802, 201.86854, 200.52278, 199.05752, 194.90904, 214.44334,
249.357266666667, 239.98525, 234.508483333333, 243.865083333333,
233.595816666667, 248.1219, 225.289416666667, 248.220883333333,
193.69566, 198.43578, 205.06055, 208.525975, 198.28692, 206.88496,
201.60162, 205.7943, 210.5117, 196.69886, 193.58288, 198.86094,
201.81676, 225.8266, 205.879725, 218.370475, 214.006125, 198.74038,
206.00314, 198.37446, 225.5357, 216.721025, 226.543925, 158.1011,
158.15674, 166.07518, 179.942225, 158.16046, 165.0685, 159.56146
)), .Names = c("name", "cat", "val"), class = "data.frame",
row.names = c(
NA,
97L))

Thanks

Nico

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ggrothendieck at gmail.com  Mon Jul 15 19:40:20 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Mon, 15 Jul 2013 13:40:20 -0400
Subject: [R] ggplot2: Remove geom
In-Reply-To: <EDB44DA865211646A192A94DF3C6FA6707785C@DEMDCE0057.nestle.com>
References: <EDB44DA865211646A192A94DF3C6FA6707785C@DEMDCE0057.nestle.com>
Message-ID: <CAP01uR=tXH1C9jTqMYMTRccbiwSgpdRMOCSwbnnda=hD9YSboA@mail.gmail.com>

On Mon, Jul 15, 2013 at 1:08 PM, Thaler,Thorn,LAUSANNE,Applied
Mathematics <Thorn.Thaler at rdls.nestle.com> wrote:
> Dear all,
>
> Is there a possibility to remove a geom from a ggplot? Background suppose I have a function which returns a ggplot object after some data re-formatting and aggregation. While this ggplot object is fine in 90% of the cases it turns out that for some cases I want to suppress one of the layers which was added to the plot.
>
> I could look at the source code of the function and write a new one, which has an additional flag parameter, with which I could ask the function to add or not to add the geom, but this sounds a bit of overkill to me and it would be nice, if I could just remove the particular layer?
>
> An example is in order to make my point clearer:
>
> library(ggplot2)
> d <- data.frame(x=rep(1:10, each = 10), y = rnorm(100), grp = rep(1:10, 10))
>
> makePlot <- function() {
>   ggplot(d, aes(x = x, y = y)) + stat_summary(fun.data = "mean_cl_normal", color = "red") + geom_point()
> }
>
> (p <- makePlot())
>
> ## Now I want to have lines instead of points, but of course the points are still there
> p + geom_line(aes(group = grp, color = grp))
>
> Again, it would not be difficult to rewrite makePlot to deal with that, but for me this seems to be error prone / duplication. So ideally, I would like to do something like:
>
> p %-% geom_point()
>
> which is ambiguous of course, as there can be several point layers in the plot. Looking at
>
> str(p)
>
> I see that there is a layers slot, so I can do
>
> q <- p
> q$layers <- q$layers[-2]
> q + geom_line(aes(group = grp, color = grp))
>
> which does actually what I want.
>
> However, is there a way to do that in a more automated way? For now I have to inspect the object and to decide which layer I want to delete, otherwise I can get something like this:
>
> makePlot2 <- function() {
>   ggplot(d, aes(x = x, y = y)) + geom_point() + stat_summary(fun.data = "mean_cl_normal", color = "red")
> }
> q <- makePlot2()
> q$layers <- q$layers[-2]
> q + geom_line(aes(group = grp, color = grp))
>
> which removes the error bars but not the points (as the order in layers changed). So any ideas how to proceed in this case? If there is a nice way, I could even think of overloading %-% which would fit nicely in the idea of a plot which can not only be added layer by layer, but where I also could remove certain layers.
>
> Maybe (and even probable) there is a very good idea why I should not do that at all and I would be curious to hear these things as well. For now I am yet interested to know how I can remove layers of a plot conveniently.
>

This seems to show which layer is which:

> sapply(p$layers, function(x) x$geom$objname)
[1] "pointrange" "point"


--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From vokey at uleth.ca  Mon Jul 15 19:41:59 2013
From: vokey at uleth.ca (Vokey, John)
Date: Mon, 15 Jul 2013 17:41:59 +0000
Subject: [R] Book recomendation: Repeated Measurements
In-Reply-To: <mailman.17.1373882407.16795.r-help@r-project.org>
References: <mailman.17.1373882407.16795.r-help@r-project.org>
Message-ID: <FDE928BE-CF09-4636-8D88-C816F1FCFEDB@uleth.ca>


On 2013-07-15, at 4:00 AM, r-help-request at r-project.org wrote:

> On 7/14/2013 3:05 PM, Rolf Turner wrote:
>> On 15/07/13 08:57, Spencer Graves wrote:
>> 
>> <SNIP>
>>> 
>>>      You may know that "mixed effects" is another term for "repeated 
>>> measurements".
>> 
>> <SNIP>
>> 
>> I must of course preface this comment with an "I am no expert" 
>> disclaimer, but I do not
>> believe that this assertion is correct.  It would be more correct, I 
>> believe, to say that
>> repeated measurement models form a particular sub-class of mixed 
>> effects models.
>> 
>> Those who *are* experts may well correct me if I am wrong about this.
> 
> 
>       Thanks for the clarification, Rolf.  You are absolutely correct.  
> "Repeated measurements" refers to the sampling plan. "Mixed effects" 
> describes a form of mathematical modeling.  There are balanced repeated 
> measures data sets where people do not have to worry about the 
> subtleties of mixed-effects modeling.  An experiment with multiple 
> litters with several mice in at least some of the litters would call for 
> mixed-effects modeling.  This would include "repeated measures" on the 
> litters but not the mice.
> 
> 
>       However, "I am no expert" on repeated measures / mixed-effects, 
> either

And you could have repeated measures within matched blocks (e.g., litters as the matched blocks, and some repeated measure---say trials---on the individual mice in each litter).  H. D. Kimmel promoted such designs in the 1960s in a slim volume describing the analysis of two such designs.

--
Please avoid sending me Word or PowerPoint attachments.
See <http://www.gnu.org/philosophy/no-word-attachments.html>

-Dr. John R. Vokey


From dwinsemius at comcast.net  Mon Jul 15 19:44:22 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 15 Jul 2013 10:44:22 -0700
Subject: [R] suppress startup messages from default packages
In-Reply-To: <87oba43wog.fsf@med.uni-goettingen.de>
References: <87oba43wog.fsf@med.uni-goettingen.de>
Message-ID: <14322641-9406-4705-AE2B-8A380A2C9590@comcast.net>


On Jul 15, 2013, at 4:11 AM, Andreas Leha wrote:

> Hi all,
> 
> several packages print messages during loading.  How do I avoid to see
> them when the packages are in the defaultPackages?

I'm pretty sure this has been asked before (although the wrinkle of adding a package to default packages may not have been part of that discussion.)  Have you done any searching of the Archives?
> 
> Here is an example.
> 
> With this in ~/.Rprofile
> ,----[ ~/.Rprofile ]
> | old <- getOption("defaultPackages")
> | options(defaultPackages = c(old, "filehash"))
> | rm(old)
> `----
> 
> I get as last line when starting R:
> ,----
> | filehash: Simple key-value database (2.2-1 2012-03-12)
> `----
> 
> Another package with (even more) prints during startup is tikzDevice.
> 
> How can I avoid to get these messages?

On my machine typing suppress<tab> brings up an option of:

 suppressPackageStartupMessages

You should append a leading "?" and read further.

-- 
David Winsemius
Alameda, CA, USA


From bogaso.christofer at gmail.com  Mon Jul 15 20:00:52 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Mon, 15 Jul 2013 23:45:52 +0545
Subject: [R] Question on plotting with googleVis
Message-ID: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/7e9dd8d0/attachment.pl>

From smartpink111 at yahoo.com  Mon Jul 15 20:13:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 15 Jul 2013 11:13:29 -0700 (PDT)
Subject: [R] t-test across columns
In-Reply-To: <05d201ce8181$5c4e4240$14eac6c0$@tamu.edu>
References: <CAMMD=S7NdUzgVof5-CyEedGyC2gBwq6zSFdQSQ5Xo3_yuRFuzg@mail.gmail.com>
	<05d201ce8181$5c4e4240$14eac6c0$@tamu.edu>
Message-ID: <1373912009.69683.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be I misunderstood ur question.
The output David got could be also obtained by:
#df1 dataset

library(plyr)

df2<-ddply(df1,.(cat),function(x) if(min(table(x$name))>1){x1<- t.test(val~name,x);cbind(t=x1$statistic,p.value=x1$p.value)})
?df2
#???????? cat????????? t????? p.value
#1 p178266580 -0.1156475 0.9144054453
#2 p178316310 -1.0874356 0.4143944591
#3 p191287337 -0.6776053 0.5315717871
#4 p195158904? 1.1522850 0.2769290728
#5 p196921846 -4.2342996 0.0003925339

But, the second part is still unclear.

A.K.


----- Original Message -----
From: David Carlson <dcarlson at tamu.edu>
To: 'Nico Met' <nicomet80 at gmail.com>; 'R help' <r-help at r-project.org>
Cc: 
Sent: Monday, July 15, 2013 1:33 PM
Subject: Re: [R] t-test across columns

This may be close to what you want:

> t.val <- by(x, x$cat, function(y) if (min(table(y$name)>1)) {
+? ? ? t.test(val~name, y)})
> t.out <- do.call(rbind, sapply(t.val, function(y) c(y$statistic, 
+? ? ?  p.value=y$p.value)))
> t.out
? ? ? ? ? ? ? ? ? ? t? ? ? p.value
p178266580 -0.1156475 0.9144054453
p178316310 -1.0874356 0.4143944591
p191287337 -0.6776053 0.5315717871
p195158904? 1.1522850 0.2769290728
p196921846 -4.2342996 0.0003925339

But I'm not sure what you mean about columns for each cat unless you
want the frequencies: 

> freq.out <- xtabs(~cat+name, x)
> freq.out <- freq.out[apply(freq.out, 1, function(y) min(y) > 1),]
> freq.out
? ? ? ? ? ? name
cat? ? ? ? ? 12.2 15.9
? p178266580? ? 4?  11
? p178316310? ? 2? ? 3
? p191287337? ? 3? ? 5
? p195158904? ? 8? ? 7
? p196921846?  26? ? 5
> results <- cbind(freq.out, t.out)
> results
? ? ? ? ?  12.2 15.9? ? ? ? ? t? ? ? p.value
p178266580? ? 4?  11 -0.1156475 0.9144054453
p178316310? ? 2? ? 3 -1.0874356 0.4143944591
p191287337? ? 3? ? 5 -0.6776053 0.5315717871
p195158904? ? 8? ? 7? 1.1522850 0.2769290728
p196921846?  26? ? 5 -4.2342996 0.0003925339

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352



-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Nico Met
Sent: Monday, July 15, 2013 10:50 AM
To: R help
Subject: [R] t-test across columns

Dear all,

I would like to do t-test across two columns "name" with different
"cat"
with overall mean ("val").

(Removing if there is a single observation)

And finally, make a matrix with t-value and p-value associated with
a name
(in rows) and cat (in columns)

dput(x)
structure(list(name = structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("12.2", "15.9"
), class = "factor"), cat = structure(c(2L, 2L, 2L, 2L, 2L, 2L,
2L, 2L, 1L, 1L, 1L, 3L, 1L, 3L, 3L, 3L, 3L, 1L, 1L, 1L, 1L, 1L,
1L, 1L, 1L, 1L, 1L, 1L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 8L, 8L,
8L, 8L, 8L, 8L, 8L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 7L, 7L, 7L,
7L, 7L, 7L, 7L, 7L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 6L, 5L, 5L, 5L,
5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L,
6L, 6L, 6L, 5L, 6L, 6L, 6L, 6L, 6L, 6L, 6L), .Label =
c("p178266580",
"p178269196", "p178316310", "p191287337", "p195158904",
"p196921846",
"p197427158", "p238921966"), class = "factor"), val = c(148.90772,
184.253375, 183.974866666667, 191.868125, 173.30515, 187.876975,
177.453775, 184.799525, 212.39065, 205.504525, 186.152025,
194.337075,
193.2703, 204.71665, 211.4452, 202.609175, 203.72918, 193.7261,
196.1186, 202.79556, 203.48818, 191.13744, 205.23315, 198.66842,
196.81032, 200.90512, 206.13564, 205.372225, 196.22835, 211.04686,
219.977133333333, 224.7602, 231.6596, 211.105816666667, 215.44474,
210.83514, 228.173125, 224.09034, 212.96026, 239.0085, 213.5407,
227.12115, 209.24888, 232.8964, 232.22146, 228.1643, 236.43082,
232.20792, 238.49192, 224.64014, 233.75898, 207.06138, 215.3649,
211.14802, 201.86854, 200.52278, 199.05752, 194.90904, 214.44334,
249.357266666667, 239.98525, 234.508483333333, 243.865083333333,
233.595816666667, 248.1219, 225.289416666667, 248.220883333333,
193.69566, 198.43578, 205.06055, 208.525975, 198.28692, 206.88496,
201.60162, 205.7943, 210.5117, 196.69886, 193.58288, 198.86094,
201.81676, 225.8266, 205.879725, 218.370475, 214.006125, 198.74038,
206.00314, 198.37446, 225.5357, 216.721025, 226.543925, 158.1011,
158.15674, 166.07518, 179.942225, 158.16046, 165.0685, 159.56146
)), .Names = c("name", "cat", "val"), class = "data.frame",
row.names = c(
NA,
97L))

Thanks

Nico

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From kw.stat at gmail.com  Mon Jul 15 20:27:54 2013
From: kw.stat at gmail.com (Kevin Wright)
Date: Mon, 15 Jul 2013 13:27:54 -0500
Subject: [R] diallel analysis
In-Reply-To: <CADHyn5jqp9_HQy0EXR2+W3WXt4=s8CgRxH4MgM7eauF7AOJx1w@mail.gmail.com>
References: <CADHyn5jqp9_HQy0EXR2+W3WXt4=s8CgRxH4MgM7eauF7AOJx1w@mail.gmail.com>
Message-ID: <CAKFxdiSJMmeGuF4K2tCuvcFz55kfsiqhbB1LyNrnV+Y9qRUBaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/f90394c1/attachment.pl>

From smartpink111 at yahoo.com  Mon Jul 15 20:33:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 15 Jul 2013 11:33:47 -0700 (PDT)
Subject: [R] file.stem?
In-Reply-To: <51E4080A.90508@sapo.pt>
References: <CAAjnpdgk6b22YaxW_omsv-croyptL4X91xWdQQAgpXg=uPT2jA@mail.gmail.com>
	<51E4080A.90508@sapo.pt>
Message-ID: <1373913227.5438.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
May be this also works.
basename(file_path_sans_ext("/the/path/to/afile.txt"))
#[1] "afile"
A.K.




----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Witold E Wolski <wewolski at gmail.com>
Cc: r-help at r-project.org
Sent: Monday, July 15, 2013 10:32 AM
Subject: Re: [R] file.stem?

Hello,

You can use ?basename to write a file.stem function:


basename("/the/path/to/afile.txt")

file.stem <- function(x){
??? bn <- basename(x)
??? gsub("\\..*$", "", bn)
}
file.stem("/the/path/to/afile.txt")



Hope this helps,

Rui Barradas

Em 15-07-2013 15:23, Witold E Wolski escreveu:
> Looking for a function which returns the stem of the filename given a path.
> i.e.
>> file.stem("/the/path/to/afile.txt")
>> afile
>
> regards
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Mon Jul 15 20:47:11 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 15 Jul 2013 11:47:11 -0700 (PDT)
Subject: [R] converting numeric to character and using character pattern
Message-ID: <1373914031.12764.YahooMailNeo@web142604.mail.bf1.yahoo.com>

HI Irucka,
May be this is what you wanted:?pat<-paste(paste0("http://www.",siter[,1],"......rdb"),collapse="|")
?pat
[1] "http://www.02437100......rdb|http://www.02439500......rdb|http://www.02441500......rdb|http://www.02446500......rdb|http://www.02467000......rdb|

----------------------------------------------------------------------------------------
A.K.



Hi, I am having a problem with my data set and conversion from numeric to character. 

Below is my code with comments on the specific problem below: 

hydraulicsites <- read.table("hydraulic_geometry_sites.csv", 
header = TRUE, sep = "\t", as.is = TRUE, stringsAsFactors = FALSE, 
colClasses = c("character",NA)) 
siter <- hydraulicsites[1] 

dput(siter) 
structure(list(site_no = c("02437100", "02439500", "02441500", 
"02446500", "02467000", "02470050", "03217500", "03219500", "03220510", 
"03227500", "03230700", "03231500", "03455000", "03497000", "03439000", 
"03439500", "03440000", "03441000", "03454500", "03479000", "03513500", 
"04177500", "04183500", "04185000", "04185500", "04186500", "04187500", 
"04188000", "04189000", "04189500", "04190000", "04191500", "04192500", 
"04193500", "06191500", "06214500", "06218500", "06222000", "06225500", 
"06228000", "06235500", "06259500", "06262000", "06264000", "06266000", 
"06269500", "06273000", "06276500", "06277500", "06279500", "06287000", 
"06288500", "06288500", "06289000", "06290500", "06293500", "06294700", 
"06329500", "06310000", "06309500", "06312500", "06311000", "06311500", 
"06313000", "06313500", "06315500", "06314000", "06315000", "06316500", 
"06317000", "06317500", "06318500", "06319500", "06320000", "06320500", 
"06323000", "06323500", "06324000", "06325500", "06324500", "06326500", 
"06426500", "06428000", "06428500", "06436000", "06437000", "06438000", 
"06821500", "06830000", "06850500", "06856600", "06860000", "06862500", 
"06864000", "06864500", "06865500", "06866000", "06877600", "06879500", 
"06887500", "06889000", "06891000", "06892500", "06342500", "06440000", 
"06818000", "06893000", "06934500", "05587500", "07010000", "07032000", 
"07289000")), .Names = "site_no", class = "data.frame", row.names = c(NA, 
-112L)) 

pat <- paste("http://www.", siter, "......rdb", sep="", collapse = "|") 
str(pat) 
?chr "www.c(\"02437100\", \"02439500\", \"02441500\", \"02446500\", \"02467000\""| __truncated__ 


OK, the problem is with pat. I need for pat to be the same 
as patter. I have a list of sites in .csv files that I need to process 
so I would like a more efficient way of doing the process than is shown 
below. 

Is there a way to get the results in pat to resemble those in patter? 

sites3 <- c("07103990", "402114105350101", "05056215") 
patter <- paste("www.", sites3, "......rdb", sep="", collapse = "|") 
dput(patter) 
"www.07103990......rdb|www.402114105350101......rdb|www.05056215......rdb" 


Thank you. 

Irucka Embry


From smartpink111 at yahoo.com  Mon Jul 15 20:50:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 15 Jul 2013 11:50:18 -0700 (PDT)
Subject: [R] converting numeric to character and using character pattern
In-Reply-To: <1373914031.12764.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <1373914031.12764.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <1373914218.31010.YahooMailNeo@web142606.mail.bf1.yahoo.com>

#or
pat1<-paste("http://www.", siter[,1], "......rdb", sep="", collapse = "|") 
?identical(pat,pat1)
#[1] TRUE
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Irucka Embry <iruckaE at mail2world.com>
Cc: R help <r-help at r-project.org>
Sent: Monday, July 15, 2013 2:47 PM
Subject: Re: converting numeric to character and using character pattern

HI Irucka,
May be this is what you wanted:?pat<-paste(paste0("http://www.",siter[,1],"......rdb"),collapse="|")
?pat
[1] "http://www.02437100......rdb|http://www.02439500......rdb|http://www.02441500......rdb|http://www.02446500......rdb|http://www.02467000......rdb|

----------------------------------------------------------------------------------------
A.K.



Hi, I am having a problem with my data set and conversion from numeric to character. 

Below is my code with comments on the specific problem below: 

hydraulicsites <- read.table("hydraulic_geometry_sites.csv", 
header = TRUE, sep = "\t", as.is = TRUE, stringsAsFactors = FALSE, 
colClasses = c("character",NA)) 
siter <- hydraulicsites[1] 

dput(siter) 
structure(list(site_no = c("02437100", "02439500", "02441500", 
"02446500", "02467000", "02470050", "03217500", "03219500", "03220510", 
"03227500", "03230700", "03231500", "03455000", "03497000", "03439000", 
"03439500", "03440000", "03441000", "03454500", "03479000", "03513500", 
"04177500", "04183500", "04185000", "04185500", "04186500", "04187500", 
"04188000", "04189000", "04189500", "04190000", "04191500", "04192500", 
"04193500", "06191500", "06214500", "06218500", "06222000", "06225500", 
"06228000", "06235500", "06259500", "06262000", "06264000", "06266000", 
"06269500", "06273000", "06276500", "06277500", "06279500", "06287000", 
"06288500", "06288500", "06289000", "06290500", "06293500", "06294700", 
"06329500", "06310000", "06309500", "06312500", "06311000", "06311500", 
"06313000", "06313500", "06315500", "06314000", "06315000", "06316500", 
"06317000", "06317500", "06318500", "06319500", "06320000", "06320500", 
"06323000", "06323500", "06324000", "06325500", "06324500", "06326500", 
"06426500", "06428000", "06428500", "06436000", "06437000", "06438000", 
"06821500", "06830000", "06850500", "06856600", "06860000", "06862500", 
"06864000", "06864500", "06865500", "06866000", "06877600", "06879500", 
"06887500", "06889000", "06891000", "06892500", "06342500", "06440000", 
"06818000", "06893000", "06934500", "05587500", "07010000", "07032000", 
"07289000")), .Names = "site_no", class = "data.frame", row.names = c(NA, 
-112L)) 

pat <- paste("http://www.", siter, "......rdb", sep="", collapse = "|") 
str(pat) 
?chr "www.c(\"02437100\", \"02439500\", \"02441500\", \"02446500\", \"02467000\""| __truncated__ 


OK, the problem is with pat. I need for pat to be the same 
as patter. I have a list of sites in .csv files that I need to process 
so I would like a more efficient way of doing the process than is shown 
below. 

Is there a way to get the results in pat to resemble those in patter? 

sites3 <- c("07103990", "402114105350101", "05056215") 
patter <- paste("www.", sites3, "......rdb", sep="", collapse = "|") 
dput(patter) 
"www.07103990......rdb|www.402114105350101......rdb|www.05056215......rdb" 


Thank you. 

Irucka Embry


From hnorpois at gmail.com  Mon Jul 15 19:45:28 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Mon, 15 Jul 2013 19:45:28 +0200
Subject: [R] glm - change offset to avoid NA?
Message-ID: <CAKyZeBubh0t9GDTkDtpBGQ8iuvsN=QVHE8vboEzkzKwVFaUfQA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/f9d4bb10/attachment.pl>

From gunter.berton at gene.com  Mon Jul 15 22:05:55 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 15 Jul 2013 13:05:55 -0700
Subject: [R] glm - change offset to avoid NA?
In-Reply-To: <CAKyZeBubh0t9GDTkDtpBGQ8iuvsN=QVHE8vboEzkzKwVFaUfQA@mail.gmail.com>
References: <CAKyZeBubh0t9GDTkDtpBGQ8iuvsN=QVHE8vboEzkzKwVFaUfQA@mail.gmail.com>
Message-ID: <CACk-te06ydAbPPW0uuDb-KPu3ntBx82wxUw-g7R47MG8uNkCQQ@mail.gmail.com>

I think what you want is

?try  ##or
?tryCatch

## The second is more flexible but slightly more complicated.

to trap the error and perhaps refit the model without interaction?

Cheers,
Bert

On Mon, Jul 15, 2013 at 10:45 AM, Hermann Norpois <hnorpois at gmail.com> wrote:
> Hello,
>
> I use glm within a function testing for the appearence of the coexistence
> of (minor allels in a subset of)  snps. And then I extract the
> Pr(>|z|)-value for the interaction. Principally it works but sometimes the
> function stops because this "value for the interaction"  is NA. For
> instance, this is the case in the following example:
>
> lz <- glm(trait~rs7572685*rs10520302, data=mus, family=binomial)
>> summary (lz)
> ...
> Coefficients: (1 not defined because of singularities)
>                      Estimate Std. Error z value Pr(>|z|)
> (Intercept)           0.05614    0.16782   0.335    0.738
> rs7572685             0.49041    0.41437   1.183    0.237
> rs10520302            0.49269    0.43514   1.132    0.258
> rs7572685:rs10520302       NA         NA      NA       NA
> ...
>
> I would prefer some values instead of NA (though it does not make any sense
> in terms of interpretation) for the sake of the smooth running of my
> function. How is this done? I guess I have to change the offset but I dont
> understand how.
> Thanks
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From andreas.leha at med.uni-goettingen.de  Mon Jul 15 22:27:11 2013
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Mon, 15 Jul 2013 22:27:11 +0200
Subject: [R] suppress startup messages from default packages
References: <87oba43wog.fsf@med.uni-goettingen.de>
	<14322641-9406-4705-AE2B-8A380A2C9590@comcast.net>
Message-ID: <87fvvf4li8.fsf@med.uni-goettingen.de>

Hi David,

David Winsemius <dwinsemius at comcast.net> writes:

> On Jul 15, 2013, at 4:11 AM, Andreas Leha wrote:
>
>> Hi all,
>> 
>> several packages print messages during loading.  How do I avoid to see
>> them when the packages are in the defaultPackages?
>
> I'm pretty sure this has been asked before (although the wrinkle of
> adding a package to default packages may not have been part of that
> discussion.)  Have you done any searching of the Archives?
>> 
>> Here is an example.
>> 
>> With this in ~/.Rprofile
>> ,----[ ~/.Rprofile ]
>> | old <- getOption("defaultPackages")
>> | options(defaultPackages = c(old, "filehash"))
>> | rm(old)
>> `----
>> 
>> I get as last line when starting R:
>> ,----
>> | filehash: Simple key-value database (2.2-1 2012-03-12)
>> `----
>> 
>> Another package with (even more) prints during startup is tikzDevice.
>> 
>> How can I avoid to get these messages?
>
> On my machine typing suppress<tab> brings up an option of:
>
>  suppressPackageStartupMessages
>
> You should append a leading "?" and read further.

I have only just now gotten your answer.  Thanks for responding.

As I already said in response to another message [fn:1] the 'wrinkle of
adding a package to default packages' is what my question really is
about.  Sorry if I was unclear.

Thanks to a very helpful answer proposing a solution using hooks [fn:2],
I was actually able to solve my 'problem' with the filehash package.

Regards,
Andreas


Footnotes:

[fn:1] http://permalink.gmane.org/gmane.comp.lang.r.general/296275

[fn:2] http://permalink.gmane.org/gmane.comp.lang.r.general/296281


From andreas.leha at med.uni-goettingen.de  Mon Jul 15 22:29:47 2013
From: andreas.leha at med.uni-goettingen.de (Andreas Leha)
Date: Mon, 15 Jul 2013 22:29:47 +0200
Subject: [R] suppress startup messages from default packages
References: <51E409870200000C00016F39@mailhost.biomec.upv.es>
	<87k3ks3s43.fsf@med.uni-goettingen.de> <51E3F835.5090102@gmail.com>
	<51E4005F.1000305@fhcrc.org>
Message-ID: <87bo634ldw.fsf@med.uni-goettingen.de>

Hi Martin,

Martin Morgan <mtmorgan at fhcrc.org> writes:

> On 07/15/2013 06:25 AM, Duncan Murdoch wrote:
>> On 15/07/2013 8:49 AM, Andreas Leha wrote:
>>> Hi Helios,
>>>
>>> "Helios de Rosario" <helios.derosario at ibv.upv.es> writes:
>>>
>>> >> Hi all,
>>> >>
>>> >> several packages print messages during loading.  How do I avoid to
>>> > see
>>> >> them when the packages are in the defaultPackages?
>>> >>
>>> >> Here is an example.
>>> >>
>>> >> With this in ~/.Rprofile
>>> >> ,----[ ~/.Rprofile ]
>>> >> | old <- getOption("defaultPackages")
>>> >> | options(defaultPackages = c(old, "filehash"))
>>> >> | rm(old)
>>> >> `----
>>> >>
>>> >> I get as last line when starting R:
>>> >> ,----
>>> >> | filehash: Simple key-value database (2.2-1 2012-03-12)
>>> >> `----
>>> >>
>>> >> Another package with (even more) prints during startup is
>>> > tikzDevice.
>>> >>
>>> >>How can I avoid to get these messages?
>>> >
>>> >
>>> > There are several options in ?library to control the messages that are
>>> > displayed when loading packages. However, this does not seem be able to
>>> > supress all the messages. Some messages are defined by the package
>>> > authors, because they feel necessary that the user reads them.
>>> >
>>>
>>>
>>> Thanks for your answer.  When I actually call library() or require()
>>> myself I can avoid all messages.  There are hacks to do that even for
>>> the very persistent messages [fn:1].
>>>
>>> My question is how to suppress these messages, when it is not me who
>>> calls library() or require(), but when the package is loaded during R's
>>> startup through the defaultPackages option.
>>
>> You could try the --slave command line option on startup.  If that isn't
>> sufficient, try getting the maintainer to change the package behaviour, or do it
>> yourself.
>
> In a hack-y way ?setHook and ?sink seem to work
>
>> setHook(packageEvent("filehash", "onLoad"), function(...) 
> sink(file(tempfile(), "w"), type="message"))
>> setHook(packageEvent("filehash", "attach"), function(...)
>> sink(file=NULL, 
> type="message"), "append")
>> library(filehash)
>>
>
> Martin


Thanks a lot for this really helpful answer!  Even if that is hack-y, I
am using this now and it solves my 'problem' with the filehash package.

Regards,
Andreas


From zj29 at cornell.edu  Mon Jul 15 22:42:22 2013
From: zj29 at cornell.edu (Zhao Jin)
Date: Mon, 15 Jul 2013 20:42:22 +0000
Subject: [R] vegan capscale 'subscript out of bounds' error
Message-ID: <28C1F3BA5C00D04A80F0FA88E776FF440DABCE6C@BY2PRD0411MB417.namprd04.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/c83b688a/attachment.pl>

From suzanne.mertens at gmail.com  Mon Jul 15 22:57:30 2013
From: suzanne.mertens at gmail.com (Suzanne Mertens)
Date: Mon, 15 Jul 2013 16:57:30 -0400
Subject: [R] deidentification for FCS files
Message-ID: <CAEBQn-jfdTBeepFCLC2t6cbR1BEO0auJrQS3AoetMgS6CXdN5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/cfed779c/attachment.pl>

From szehnder at uni-bonn.de  Mon Jul 15 23:43:18 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 15 Jul 2013 23:43:18 +0200
Subject: [R] Serialize data.frame to database
Message-ID: <89A18CA7-09C7-4545-8128-366FF12251E9@uni-bonn.de>

Dear R-Users,

I need a very fast and reliable database solution so I try to serialize a data.frame (to binary data) and to store this data to an SQLite database. 

This is what I tried to do:

library(RSQLite)
con <- dbDriver("SQLite")
db <- dbConnect(con, "test")
dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" BLOB)')
data.bin <- serialize(iris, NULL, ascii = FALSE)
dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.bin, "')", sep = ""))
data.bin2 <- dbGetQuery(db, "SELECT DATA FROM frames WHERE simID = 1")
data.bin2
  data
1   58

So, only the first entry of data.bin is saved to the database. I tried to first convert the binary data to raw data:
data.raw <- rawToChar(data.bin)
Error in rawToChar(data.bin) :
  embedded nul in string: 'X\n\0\0\0\002\0\003\0\001\0\002\003\0\0\0\003\023\0\0\0\005\0\0\0\016\0\0\0\x96@\024ffffff@\023\x99\x99\x99\x99\x99\x9a@\022\xcc\xcc\xcc\xcc\xcc\xcd@\022ffffff@\024\0\0\0\0\0\0@\025\x99\x99\x99\x99\x99\x9a@\022ffffff@\024\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\023\x99\x99\x99\x99\x99\x9a@\025\x99\x99\x99\x99\x99\x9a@\023333333@\023333333@\021333333@\027333333@\026\xcc\xcc\xcc\xcc\xcc\xcd@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\026\xcc\xcc\xcc\xcc\xcc\xcd@\024ffffff@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\022ffffff@\024ffffff@\023333333@\024\0\0\0\0\0\0@\024\0\0\0\0\0\0@\024\xcc\xcc\xcc\xcc\xcc\xcd@\024\xcc\xcc\xcc\xcc\xcc\xcd@\022\xcc\xcc\xcc\xcc\xcc\xcd@\023333333@\025\x99\x99\x99\x99\x99\x9a@\024\xcc\xcc\xcc\xcc\xcc\xcd@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\0\0@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\021\x99\x99\x99\x99\x99\x9a@\024ffffff@\024\0\0\0\0\0\0@\022\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\0\0

I don't know what this error should tell me. Then I tried to use the ASCII format

data.ascii <- serialize(iris, NULL, ascii = TRUE)
data.raw <- rawToChar(data.ascii)
dbSendQuery(db, "DELETE FROM frames")
dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.raw, "')", sep = ""))
Error in sqliteExecStatement(conn, statement, ...) :
  RS-DBI driver: (error in statement: unrecognized token: "X'A

This also does not work. It seems the driver does not deal that nicely with the regular INSERT query for BLOB objects in SQLite. Then I used a simpler way:

dbSendQuery(db, "DELETE FROM frames")
dbSendQuery(db, "DROP TABLE frames")
dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" TEXT DEFAULT NULL)')
dbSendQuery(db, paste("INSERT INTO frames VALUES(1, '", data.raw, "')", sep = ""))
data.bin2 <- dbGetQuery(db, "SELECT data FROM frames WHERE simID = 1")

Nice, that worked. Now I want to unserialize the data:

unserialize(data.bin2)
Error in unserialize(data.bin2) : 'connection' must be a connection

unserialize(data.bin2[1, 'data'])
Error in unserialize(data.bin2[1, "data"]) :
  character vectors are no longer accepted by unserialize()

I feel a little stuck here, but I am very sure, that converting data.frames to binary data and storing them to a database is not that unusual. So I hope somebody has already done this and could give me the missing piece.


Best

Simon


From david.stevens at usu.edu  Mon Jul 15 23:51:19 2013
From: david.stevens at usu.edu (David Stevens)
Date: Mon, 15 Jul 2013 15:51:19 -0600
Subject: [R] cluster package - Installation problems
Message-ID: <51E46ED7.3000704@usu.edu>

Group - I'm having problems with the 'cluster' package. Installation 
appears successful but attempts to load it with either library() or 
require() result in the error message

Error in library(cluster) : there is no package called ?cluster?

All that appears to be installed is cluster.dll in the 
library/cluster/libs/x64 folder. Several reinstallation attempts haven't 
helped. I'm using R-3.0.1 under windows 7. Any help is appreciated.

Regards

David

-- 
David K Stevens, P.E., Ph.D.
Professor and Head, Environmental Engineering
Civil and Environmental Engineering
Utah Water Research Laboratory
8200 Old Main Hill
Logan, UT  84322-8200
435 797 3229 - voice
435 797 1363 - fax
david.stevens at usu.edu


From ligges at statistik.tu-dortmund.de  Tue Jul 16 00:31:08 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 16 Jul 2013 00:31:08 +0200
Subject: [R] cluster package - Installation problems
In-Reply-To: <51E46ED7.3000704@usu.edu>
References: <51E46ED7.3000704@usu.edu>
Message-ID: <51E4782C.1010303@statistik.tu-dortmund.de>



On 15.07.2013 23:51, David Stevens wrote:
> Group - I'm having problems with the 'cluster' package. Installation
> appears successful but attempts to load it with either library() or
> require() result in the error message
>
> Error in library(cluster) : there is no package called ?cluster?
>
> All that appears to be installed is cluster.dll in the
> library/cluster/libs/x64 folder. Several reinstallation attempts haven't
> helped. I'm using R-3.0.1 under windows 7. Any help is appreciated.

Restart your R (and close other R processes) and try again, probably the 
dll was locked by an(other) R process when you tried to update.

best,
Uwe Ligges


>
> Regards
>
> David
>


From ivo.welch at anderson.ucla.edu  Tue Jul 16 00:50:38 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Mon, 15 Jul 2013 15:50:38 -0700
Subject: [R] memory allocation and management question
Message-ID: <CAPr7RtWdz3Y4-Die__b8DuViGJPYWHBPAskize5vsA0iaV1+xw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/00d013c2/attachment.pl>

From nservant at curie.fr  Mon Jul 15 23:55:57 2013
From: nservant at curie.fr (Nicolas Servant)
Date: Mon, 15 Jul 2013 23:55:57 +0200
Subject: [R] image versus levelplot
Message-ID: <51E46FED.8080506@curie.fr>

Dear R users,

I'm currently using the Graphics package to display several hundred of 
matrix objects, using a layout and the image() function.
It works well except for large matrices (> 1000*1000) or for a large 
number of matrices (there is a limitation around 400 if I remember well)
To solve these issues, I move to the Matrix package which is much more 
efficient for large sparse matrix, and to the grid package for the plot 
(using image from Matrix)
However, the levelplot() is much more slow than the graphics image() 
function !!
Basically, with the image() from graphics, I'm able to plot 360 matrices 
in 30 sec, against more than 10 minutes with levelplot().
I would appreciate if anyone has some experience on that, and could give 
me some advice to efficiently use the grid package !?
Regards
Nicolas

 > i=1000
 > M1 <- Matrix(rnorm(i*i), ncol=i)
 > system.time(print(Matrix::image(M1)))
    user  system elapsed
  11.320   0.064  11.406
 > M2 <- matrix(rnorm(i*i), ncol=i)
 > system.time(image(as.matrix(M2)))
    user  system elapsed
   0.837   0.004   0.844





-- 
Nicolas Servant
Plateforme de Bioinformatique
Unit? 900 : Institut Curie - Inserm - Mines ParisTech
26, rue d'Ulm - 75248 Paris Cedex 05 - FRANCE

Email: Nicolas.Servant at curie.fr
Tel: 01 56 24 69 85
http://bioinfo.curie.fr/


From jholtman at gmail.com  Tue Jul 16 01:26:00 2013
From: jholtman at gmail.com (jim holtman)
Date: Mon, 15 Jul 2013 19:26:00 -0400
Subject: [R] memory allocation and management question
In-Reply-To: <CAPr7RtWdz3Y4-Die__b8DuViGJPYWHBPAskize5vsA0iaV1+xw@mail.gmail.com>
References: <CAPr7RtWdz3Y4-Die__b8DuViGJPYWHBPAskize5vsA0iaV1+xw@mail.gmail.com>
Message-ID: <CAAxdm-5dCj4UkCAwsaCijBytheHidO7cy+ZBJ_e4n=wTfb0JRg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/c7314317/attachment.pl>

From azam.peyvand at gmail.com  Tue Jul 16 02:06:05 2013
From: azam.peyvand at gmail.com (Azam Peyvand)
Date: Mon, 15 Jul 2013 17:06:05 -0700
Subject: [R] An error in the "Package JGL"
Message-ID: <CAOkAhB-fPyH60fNGci5hR4gtg7pi_Q=Nb520MyRBJasVSGuuzg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/55ab2a33/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Tue Jul 16 02:34:50 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 15 Jul 2013 17:34:50 -0700
Subject: [R] Serialize data.frame to database
In-Reply-To: <89A18CA7-09C7-4545-8128-366FF12251E9@uni-bonn.de>
References: <89A18CA7-09C7-4545-8128-366FF12251E9@uni-bonn.de>
Message-ID: <8a267d97-3cb7-4c7b-a693-9542b58785de@email.android.com>

I could be wrong, but I would guess that doing what you are describing is very unusual. Most of the time the data frame is mapped to a table in the database so the rows can be searched. Storing data frames as BLOBs really seems odd.

Note that there is an R-sig-db mailing list for questions of this type.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Simon Zehnder <szehnder at uni-bonn.de> wrote:

>Dear R-Users,
>
>I need a very fast and reliable database solution so I try to serialize
>a data.frame (to binary data) and to store this data to an SQLite
>database. 
>
>This is what I tried to do:
>
>library(RSQLite)
>con <- dbDriver("SQLite")
>db <- dbConnect(con, "test")
>dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" BLOB)')
>data.bin <- serialize(iris, NULL, ascii = FALSE)
>dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.bin,
>"')", sep = ""))
>data.bin2 <- dbGetQuery(db, "SELECT DATA FROM frames WHERE simID = 1")
>data.bin2
>  data
>1   58
>
>So, only the first entry of data.bin is saved to the database. I tried
>to first convert the binary data to raw data:
>data.raw <- rawToChar(data.bin)
>Error in rawToChar(data.bin) :
>embedded nul in string:
>'X\n\0\0\0\002\0\003\0\001\0\002\003\0\0\0\003\023\0\0\0\005\0\0\0\016\0\0\0\x96@\024ffffff@\023\x99\x99\x99\x99\x99\x9a@\022\xcc\xcc\xcc\xcc\xcc\xcd@\022ffffff@\024\0\0\0\0\0\0@\025\x99\x99\x99\x99\x99\x9a@\022ffffff@\024\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\023\x99\x99\x99\x99\x99\x9a@\025\x99\x99\x99\x99\x99\x9a@\023333333@\023333333@\021333333@\027333333@\026\xcc\xcc\xcc\xcc\xcc\xcd@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\026\xcc\xcc\xcc\xcc\xcc\xcd@\024ffffff@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\022ffffff@\024ffffff@\023333333@\024\0\0\0\0\0\0@\024\0\0\0\0\0\0@\024\xcc\xcc\xcc\xcc\xcc\xcd@\024\xcc\xcc\xcc\xcc\xcc\xcd@\022\xcc\xcc\xcc\xcc\xcc\xcd@\023333333@\025\x99\x99\x99\x99\x99\x9a@\024\xcc\xcc\xcc\xcc\xcc\xcd@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\0\0@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\021\x99\x99\x99\x99\x99\x9a@\024ffffff@\024\0\0\0\0\0\0@\022\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\!
> 
> 
> 0\0
>
>I don't know what this error should tell me. Then I tried to use the
>ASCII format
>
>data.ascii <- serialize(iris, NULL, ascii = TRUE)
>data.raw <- rawToChar(data.ascii)
>dbSendQuery(db, "DELETE FROM frames")
>dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.raw,
>"')", sep = ""))
>Error in sqliteExecStatement(conn, statement, ...) :
>  RS-DBI driver: (error in statement: unrecognized token: "X'A
>
>This also does not work. It seems the driver does not deal that nicely
>with the regular INSERT query for BLOB objects in SQLite. Then I used a
>simpler way:
>
>dbSendQuery(db, "DELETE FROM frames")
>dbSendQuery(db, "DROP TABLE frames")
>dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" TEXT DEFAULT
>NULL)')
>dbSendQuery(db, paste("INSERT INTO frames VALUES(1, '", data.raw, "')",
>sep = ""))
>data.bin2 <- dbGetQuery(db, "SELECT data FROM frames WHERE simID = 1")
>
>Nice, that worked. Now I want to unserialize the data:
>
>unserialize(data.bin2)
>Error in unserialize(data.bin2) : 'connection' must be a connection
>
>unserialize(data.bin2[1, 'data'])
>Error in unserialize(data.bin2[1, "data"]) :
>  character vectors are no longer accepted by unserialize()
>
>I feel a little stuck here, but I am very sure, that converting
>data.frames to binary data and storing them to a database is not that
>unusual. So I hope somebody has already done this and could give me the
>missing piece.
>
>
>Best
>
>Simon
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From cxg040 at email.uark.edu  Tue Jul 16 03:10:48 2013
From: cxg040 at email.uark.edu (Chirag Gupta)
Date: Mon, 15 Jul 2013 20:10:48 -0500
Subject: [R] Deleting specific rows from a dataframe
Message-ID: <CADESCNyDGZMwvHBiWxA0rOx8ApFo4eS=itq4ryddWLjSkJVLaQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/d0555b3d/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 16 03:23:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 15 Jul 2013 18:23:51 -0700 (PDT)
Subject: [R] Deleting specific rows from a dataframe
In-Reply-To: <CADESCNyDGZMwvHBiWxA0rOx8ApFo4eS=itq4ryddWLjSkJVLaQ@mail.gmail.com>
References: <CADESCNyDGZMwvHBiWxA0rOx8ApFo4eS=itq4ryddWLjSkJVLaQ@mail.gmail.com>
Message-ID: <1373937831.85878.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
If I understand it correctly,
df1<- read.table(text="
sample1 sample2 sample3 sample4 sample5? 
?a P P I P P
?b P A P P A
?c P P P P P
?d P P P P P
?e M P M A P
?f P P P P P
?g P P P A P
?h P P P P P
",sep="",header=TRUE,stringsAsFactors=FALSE)
df1[rowSums(df1=="P")==ncol(df1),]
#? sample1 sample2 sample3 sample4 sample5
#c?????? P?????? P?????? P?????? P?????? P
#d?????? P?????? P?????? P?????? P?????? P
#f ????? P?????? P?????? P?????? P?????? P
#h?????? P?????? P?????? P?????? P?????? P
A.K.



----- Original Message -----
From: Chirag Gupta <cxg040 at email.uark.edu>
To: r-help at r-project.org
Cc: 
Sent: Monday, July 15, 2013 9:10 PM
Subject: [R] Deleting specific rows from a dataframe

I have a data frame like shown below

? sample1 sample2 sample3 sample4 sample5? a P P I P P? b P A P P A? c P P P
P P? d P P P P P? e M P M A P? f P P P P P? g P P P A P? h P P P P P

I want to keep only those rows which have all "P" across all the columns.

Since the matrix is large (about 20,000 rows), I cannot do it in excel

Any special function that i can use?
-- 
*Chirag Gupta*

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ivo.welch at gmail.com  Tue Jul 16 03:55:55 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Mon, 15 Jul 2013 18:55:55 -0700
Subject: [R] memory allocation and management question
In-Reply-To: <CAAxdm-5dCj4UkCAwsaCijBytheHidO7cy+ZBJ_e4n=wTfb0JRg@mail.gmail.com>
References: <CAPr7RtWdz3Y4-Die__b8DuViGJPYWHBPAskize5vsA0iaV1+xw@mail.gmail.com>
	<CAAxdm-5dCj4UkCAwsaCijBytheHidO7cy+ZBJ_e4n=wTfb0JRg@mail.gmail.com>
Message-ID: <CAPr7RtUu_KY-JCh945VkmR7kxyG9VbyZFttWr2gkJVSKf2+3yg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/22196bbe/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 16 05:00:54 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 15 Jul 2013 20:00:54 -0700 (PDT)
Subject: [R] Deleting specific rows from a dataframe
In-Reply-To: <1373937831.85878.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <CADESCNyDGZMwvHBiWxA0rOx8ApFo4eS=itq4ryddWLjSkJVLaQ@mail.gmail.com>
	<1373937831.85878.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1373943654.23427.YahooMailNeo@web142604.mail.bf1.yahoo.com>

You mentioned data.frame at one place and matrix at another.? Matrix would be faster.

#Speed comparison
#Speed
set.seed(1454)
dfTest<- as.data.frame(matrix(sample(LETTERS[15:18],5*1e6,replace=TRUE),ncol=5))

system.time(res<-dfTest[rowSums(dfTest=="P")==ncol(dfTest),])
#?? user? system elapsed 
#? 0.628?? 0.020?? 0.649 
?dim(res)
#[1] 952?? 5


set.seed(1454)
mat1<- matrix(sample(LETTERS[15:18],5*1e6,replace=TRUE),ncol=5)
system.time(res1<-mat1[rowSums(mat1=="P")==ncol(mat1),])
# user? system elapsed 
#? 0.188?? 0.004?? 0.194 
dim(res1)
#[1] 952?? 5

#Other options include
system.time(res3<- dfTest[apply(sweep(dfTest,1,"P","=="),1,all),])
#?? user? system elapsed 
#? 5.988?? 0.120?? 6.120 
?identical(res,res3)
#[1] TRUE



system.time(res2<- dfTest[apply(dfTest,1, function(x) all(length(table(x))==ncol(dfTest) | names(table(x))=="P")? ), ])
#?? user? system elapsed 
#351.492?? 0.040 352.164?
row.names(res2)<- row.names(res3)
attr(res3,"row.names")<- attr(res2,"row.names")
?identical(res2,res3)
#[1] TRUE


A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Chirag Gupta <cxg040 at email.uark.edu>
Cc: R help <r-help at r-project.org>
Sent: Monday, July 15, 2013 9:23 PM
Subject: Re: [R] Deleting specific rows from a dataframe

Hi,
If I understand it correctly,
df1<- read.table(text="
sample1 sample2 sample3 sample4 sample5? 
?a P P I P P
?b P A P P A
?c P P P P P
?d P P P P P
?e M P M A P
?f P P P P P
?g P P P A P
?h P P P P P
",sep="",header=TRUE,stringsAsFactors=FALSE)
df1[rowSums(df1=="P")==ncol(df1),]
#? sample1 sample2 sample3 sample4 sample5
#c?????? P?????? P?????? P?????? P?????? P
#d?????? P?????? P?????? P?????? P?????? P
#f ????? P?????? P?????? P?????? P?????? P
#h?????? P?????? P?????? P?????? P?????? P
A.K.



----- Original Message -----
From: Chirag Gupta <cxg040 at email.uark.edu>
To: r-help at r-project.org
Cc: 
Sent: Monday, July 15, 2013 9:10 PM
Subject: [R] Deleting specific rows from a dataframe

I have a data frame like shown below

? sample1 sample2 sample3 sample4 sample5? a P P I P P? b P A P P A? c P P P
P P? d P P P P P? e M P M A P? f P P P P P? g P P P A P? h P P P P P

I want to keep only those rows which have all "P" across all the columns.

Since the matrix is large (about 20,000 rows), I cannot do it in excel

Any special function that i can use?
-- 
*Chirag Gupta*

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From alok.jadhav at credit-suisse.com  Tue Jul 16 02:39:48 2013
From: alok.jadhav at credit-suisse.com (Alok Jadhav)
Date: Mon, 15 Jul 2013 17:39:48 -0700 (PDT)
Subject: [R] Sending carbon copy mails from R
In-Reply-To: <CEE8C35195DB944D9C75ABB15A04193B24F24BD2@EHKG17P32001A.csfb.cs-group.com>
References: <CEE8C35195DB944D9C75ABB15A04193B24CA5961@EHKG17P32001A.csfb.cs-group.com>
	<1373593728556-4671376.post@n4.nabble.com>
	<51DF96F3.5020104@stats.ox.ac.uk>
	<CEE8C35195DB944D9C75ABB15A04193B24F24BD2@EHKG17P32001A.csfb.cs-group.com>
Message-ID: <1373935188960-4671655.post@n4.nabble.com>

There was a small typo in my sendmail command. I was passing header=header
instead of headers=header. This argument was accepted because of `...`
argument which is not the last argument as one would except. A minor mistake
caused me a bit of frustration. This issue is resolved now. Thanks everyone.



--
View this message in context: http://r.789695.n4.nabble.com/Sending-carbon-copy-mails-from-R-tp4671153p4671655.html
Sent from the R help mailing list archive at Nabble.com.


From azam.peyvand at gmail.com  Tue Jul 16 06:36:11 2013
From: azam.peyvand at gmail.com (Azam Peyvand)
Date: Mon, 15 Jul 2013 21:36:11 -0700
Subject: [R] An error in the "Package JGL"
Message-ID: <CAOkAhB-oU=suVaDNifBaekAUPGTaFbBmO0WSaZaTo7ozyBFqPQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130715/8d1f76fa/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Jul 16 08:52:48 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 16 Jul 2013 07:52:48 +0100
Subject: [R] An error in the "Package JGL"
In-Reply-To: <CAOkAhB-oU=suVaDNifBaekAUPGTaFbBmO0WSaZaTo7ozyBFqPQ@mail.gmail.com>
References: <CAOkAhB-oU=suVaDNifBaekAUPGTaFbBmO0WSaZaTo7ozyBFqPQ@mail.gmail.com>
Message-ID: <51E4EDC0.3090108@stats.ox.ac.uk>

Please do not multiple-post.

What did the maintainer say when you asked him (see the posting guide)?

On 16/07/2013 05:36, Azam Peyvand wrote:
> I am currently working with the package JGL.
> I tried to run JGL function "JGL(Y,penalty="fused",...)" over my data, but
> there is the following error which makes it stop:
>
> "Error in while ((iter==0)|| (iter < maxiter && diff_value>tol))
> missing value where TRUE/FALSE needed. "
>
> Any special idea for fixing such error?
>
> 	[[alternative HTML version deleted]]

The posting guide asked you not to send HTML.

> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
We don't have anything reproducible here.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From szehnder at uni-bonn.de  Tue Jul 16 10:34:10 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 16 Jul 2013 10:34:10 +0200
Subject: [R] Serialize data.frame to database
In-Reply-To: <8a267d97-3cb7-4c7b-a693-9542b58785de@email.android.com>
References: <89A18CA7-09C7-4545-8128-366FF12251E9@uni-bonn.de>
	<8a267d97-3cb7-4c7b-a693-9542b58785de@email.android.com>
Message-ID: <3D6B2DDB-0174-4E18-9382-7BB110F0C79F@uni-bonn.de>

Hi Jeff,

I think you are more right than me. I have not much experience with R-specific objects and Databases. I just know, that for languages like Java, C, etc. this process is a usual one for storing for example matrices (in case of course that I do not have to access specific elements inside of the matrix but only the matrix as a whole).

Thank you for the tip with the R-sig-DB list. I switch over to this list.

Best

Simon

On Jul 16, 2013, at 2:34 AM, Jeff Newmiller <jdnewmil at dcn.davis.CA.us> wrote:

> I could be wrong, but I would guess that doing what you are describing is very unusual. Most of the time the data frame is mapped to a table in the database so the rows can be searched. Storing data frames as BLOBs really seems odd.
> 
> Note that there is an R-sig-db mailing list for questions of this type.
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Simon Zehnder <szehnder at uni-bonn.de> wrote:
> 
>> Dear R-Users,
>> 
>> I need a very fast and reliable database solution so I try to serialize
>> a data.frame (to binary data) and to store this data to an SQLite
>> database. 
>> 
>> This is what I tried to do:
>> 
>> library(RSQLite)
>> con <- dbDriver("SQLite")
>> db <- dbConnect(con, "test")
>> dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" BLOB)')
>> data.bin <- serialize(iris, NULL, ascii = FALSE)
>> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.bin,
>> "')", sep = ""))
>> data.bin2 <- dbGetQuery(db, "SELECT DATA FROM frames WHERE simID = 1")
>> data.bin2
>> data
>> 1   58
>> 
>> So, only the first entry of data.bin is saved to the database. I tried
>> to first convert the binary data to raw data:
>> data.raw <- rawToChar(data.bin)
>> Error in rawToChar(data.bin) :
>> embedded nul in string:
>> 'X\n\0\0\0\002\0\003\0\001\0\002\003\0\0\0\003\023\0\0\0\005\0\0\0\016\0\0\0\x96@\024ffffff@\023\x99\x99\x99\x99\x99\x9a@\022\xcc\xcc\xcc\xcc\xcc\xcd@\022ffffff@\024\0\0\0\0\0\0@\025\x99\x99\x99\x99\x99\x9a@\022ffffff@\024\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\023\x99\x99\x99\x99\x99\x9a@\025\x99\x99\x99\x99\x99\x9a@\023333333@\023333333@\021333333@\027333333@\026\xcc\xcc\xcc\xcc\xcc\xcd@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\026\xcc\xcc\xcc\xcc\xcc\xcd@\024ffffff@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\022ffffff@\024ffffff@\023333333@\024\0\0\0\0\0\0@\024\0\0\0\0\0\0@\024\xcc\xcc\xcc\xcc\xcc\xcd@\024\xcc\xcc\xcc\xcc\xcc\xcd@\022\xcc\xcc\xcc\xcc\xcc\xcd@\023333333@\025\x99\x99\x99\x99\x99\x9a@\024\xcc\xcc\xcc\xcc\xcc\xcd@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\0\0@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\021\x99\x99\x99\x99\x99\x9a@\024ffffff@\024\0\0\0\0\0\0@\022\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\!
>> 
>> 
>> 0\0
>> 
>> I don't know what this error should tell me. Then I tried to use the
>> ASCII format
>> 
>> data.ascii <- serialize(iris, NULL, ascii = TRUE)
>> data.raw <- rawToChar(data.ascii)
>> dbSendQuery(db, "DELETE FROM frames")
>> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.raw,
>> "')", sep = ""))
>> Error in sqliteExecStatement(conn, statement, ...) :
>> RS-DBI driver: (error in statement: unrecognized token: "X'A
>> 
>> This also does not work. It seems the driver does not deal that nicely
>> with the regular INSERT query for BLOB objects in SQLite. Then I used a
>> simpler way:
>> 
>> dbSendQuery(db, "DELETE FROM frames")
>> dbSendQuery(db, "DROP TABLE frames")
>> dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" TEXT DEFAULT
>> NULL)')
>> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, '", data.raw, "')",
>> sep = ""))
>> data.bin2 <- dbGetQuery(db, "SELECT data FROM frames WHERE simID = 1")
>> 
>> Nice, that worked. Now I want to unserialize the data:
>> 
>> unserialize(data.bin2)
>> Error in unserialize(data.bin2) : 'connection' must be a connection
>> 
>> unserialize(data.bin2[1, 'data'])
>> Error in unserialize(data.bin2[1, "data"]) :
>> character vectors are no longer accepted by unserialize()
>> 
>> I feel a little stuck here, but I am very sure, that converting
>> data.frames to binary data and storing them to a database is not that
>> unusual. So I hope somebody has already done this and could give me the
>> missing piece.
>> 
>> 
>> Best
>> 
>> Simon
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From alice.julien-laferriere at univ-lyon1.fr  Tue Jul 16 10:26:30 2013
From: alice.julien-laferriere at univ-lyon1.fr (=?ISO-8859-1?Q?Alice_Julien-Laferri=E8re?=)
Date: Tue, 16 Jul 2013 10:26:30 +0200
Subject: [R] Problem with plot in several cases, font issue?
In-Reply-To: <51E42087.5060302@stats.ox.ac.uk>
References: <51E40DF7.1030901@univ-lyon1.fr> <51E40E53.2030900@univ-lyon1.fr>
	<51E42087.5060302@stats.ox.ac.uk>
Message-ID: <51E503B6.90405@univ-lyon1.fr>

Thanks for the help.

As  indicated into the R-admin manual, it was an ubuntu install problem.
But it only shows in R, as I do not use special fonts usually.





Le 15/07/2013 18:17, Prof Brian Ripley a ?crit :
> On 15/07/2013 15:59, Alice Julien-Laferri?re wrote:
>> Dear all,
>>
>> I am having problem on plots in R for some cases.
>
> Your machine has Cairo: Cairo-based X11 devices do not use those 
> fonts.  So it seems you have done something you have not shown us.
>
> The fix is to use the Cairo-based X11 devices.  See the R-admin manual 
> for more details.
>
>>
>> For example:
>>
>>> plot( 1:10 )
>>> text( 1:10, letters[1:10], cex = 1)
>>
>> works well but :
>>
>>> plot(1:10)
>>> text(1:10, letters[1:10], cex = 0.9)
>>
>> returns :
>> Erreur dans text.default(1:10, letters[1:10], cex = 0.9) :
>>    impossible de charger la police X11
>> -adobe-helvetica-%s-%s-*-*-%d-*-*-*-*-*-*-*, de face 1 et de taille 11
>>
>> (sorry for the french).
>
> But it is very easy to set LANGUAGE=en to get American English 
> messages ....
>
>> In this message, for other cases the function may changed (it can be
>> axis( ) for example) but it always a font problem.
>>
>> I encountered this issue various times (with more complicated graphics).
>>
>> I'm working on ubuntu 12.04 with R 3.0.1 (2013-05-16).
>>
>>
>> The capabilities function returns me:
>>    jpeg      png     tiff    tcltk      X11     aqua http/ftp sockets
>> TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE TRUE
>>   libxml     fifo   cledit    iconv      NLS  profmem    cairo
>>   TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE
>>
>>
>> I think this may be an issue with my installation, but I could not
>> figured out what was the missing package.
>> I tried this on other computers. I did not see the same bug.
>>
>>
>> Thanks in advance for the help,
>>
>> Alice
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>


From jjimenez at oapn.es  Tue Jul 16 09:34:55 2013
From: jjimenez at oapn.es (Jose Jimenez)
Date: Tue, 16 Jul 2013 00:34:55 -0700 (PDT)
Subject: [R] Program SPACECAP help
In-Reply-To: <1372406194239-4670514.post@n4.nabble.com>
References: <1372406194239-4670514.post@n4.nabble.com>
Message-ID: <1373960095337-4671667.post@n4.nabble.com>

Please, could you post the the R code and the head of your data? Are you
usuing the csv template?

Jose



--
View this message in context: http://r.789695.n4.nabble.com/Program-SPACECAP-help-tp4670514p4671667.html
Sent from the R help mailing list archive at Nabble.com.


From mjbae at khu.ac.kr  Tue Jul 16 09:18:43 2013
From: mjbae at khu.ac.kr (whialy)
Date: Tue, 16 Jul 2013 00:18:43 -0700 (PDT)
Subject: [R] About Detrended Fluctuation Analysis
Message-ID: <1373959123362-4671666.post@n4.nabble.com>

Hello~

I am just beginner in R program
During my research, I should analyze my data using "detrended fluctuation
analysis"
But it is difficult to find package in R
I found the package named "fractal" to calcuate "DFA" but in new version in
R, that package does not work any more
So...would you tell my some tools or packages to calcuated DFA?

Thank you for reading this post~





--
View this message in context: http://r.789695.n4.nabble.com/About-Detrended-Fluctuation-Analysis-tp4671666.html
Sent from the R help mailing list archive at Nabble.com.


From raphaelle.carraud at oc-metalchem.com  Tue Jul 16 10:07:08 2013
From: raphaelle.carraud at oc-metalchem.com (=?iso-8859-1?Q?Rapha=EBlle_Carraud?=)
Date: Tue, 16 Jul 2013 10:07:08 +0200
Subject: [R] Ode error message
Message-ID: <4565B2277456ED4EB03CD34B21283B472067BE84D1@EXH01001.hmc.local>

Hello,

I am creating a program with R to solve a differential equation system. However, I get the following message I do not understand :

> out <- ode(y = state, times = z, func = liquide, parms = 0, atol = 0)
DLSODA-  EWT(I1) is R1 .le. 0.0
In above message, I1 = 1
 
In above message, R1 = 0
 
Error in lsoda(y, times, func, parms, ...) : 
  illegal input detected before taking any integration steps - see written message

or this one when I tried modifying the atoll value :

> out <- ode(y = state, times = z, func = liquide, parms = 0, atol = 10^-14)
DLSODA-  Warning..Internal T (=R1) and H (=R2) are
      such that in the machine, T + H = T on the next step
     (H = step size). Solver will continue anyway.
In above message, R1 = 0, R2 = 0
 
DINTDY-  T (=R1) illegal
In above message, R1 = 1
 
      T not in interval TCUR - HU (= R1) to TCUR (=R2)
In above message, R1 = 0, R2 = 0
 
DINTDY-  T (=R1) illegal
In above message, R1 = 2
 
      T not in interval TCUR - HU (= R1) to TCUR (=R2)
In above message, R1 = 0, R2 = 0
 
DLSODA-  Trouble in DINTDY.  ITASK = I1, TOUT = R1
In above message, I1 = 1
 
In above message, R1 = 2

Here is my program. I also tried changing the initial values but it does not work well.

liquide <- function(z, state, parameters) {
  with(as.list(c(state,parameters)),{
    # rate of change
      
    Tr <- 273+90
    C <- CA + CB + CC + CD + CE + CI + CG + CJ + CK + CH
    
    K32 <- 6.54*10^4      
    K33 <- 1.37*10^4      
    K34 <- 330                 
    K35 <- 5.81*10^4      
    kf2 <- 1.37*10^3      
    kf3 <- 1.37*10^3     
    kf4 <- 8.68*10^5      
    kf5 <- 157.2
    
    K2 <- 10^1.37        
    K3 <- 10^(-3.35)     
    
    r1 <- kf4*CD - kf4/K34*CE^2
    r2 <- kf3*CA*CB - kf3/K33*CD
    r3 <- kf2*CA^2 - kf2/K32*CC
    r4 <- kf5*CC - kf5/K35*CE*CI^2 
    
    
    dCA <- -r2                                                      # dNO/dt
    dCB <- -r3 - r2                                               # dNO2/dt
    dCC <- r3/2 - r4                                             # dN2O4/dt
    dCD <- r2 - r1                                                # dN2O3/dt
    dCE <- 2*r1 + r4                                            # dHNO2/dt
    dCI <- r4                                                         # dHNO3/dt
    dCG <- -r4 - r1                                               # dH2O/dz
    dCH <- (dCE + dCI)/((K2 + K3)*(CE + CI))      # dH/dz
    dCJ <-  (CH*dCI - CI*dCH)/(K3*CH^2)          # dNO3-/dz
    dCK <-  (CH*dCE - CE*dCH)/(K2*CH^2)        # dNO2-/dz
    
   
    
    list(c(dCA, dCB, dCC, dCD, dCE, dCI, dCG, dCH, dCJ, dCK))
  })   # end with(as.list ...
}


Ti <- 273+90       # K
Ct <- 5100   # mol/m^3

state <-c(CA = 0,           # mol/m^3 NO2
          CB = 0,               # mol/m^3 NO
          CC = 0,                # mol/m^3 N2O4
          CD = 0,              # mol/m^3 N2O3
          CE = 50,              # mol/m^3 HNO2
          CI = 50,             # mol/m^3 HNO3
          CG = 5000,         # mol/m^3 H2O
          CH = 0,             # mol/m^3 H+
          CJ = 0,                # mol/m^3 NO3-
          CK = 0)             # mol/m^3 NO2-
          
parameters <- c(Ct = 5100)

z <- seq(0, 15, by = 1)  # en seconde

library(deSolve)
out <- ode(y = state, times = z, func = liquide, parms = 0, atol = 10^-14)
head(out)
plot(out)

Thank you


From Christoph.Scherber at agr.uni-goettingen.de  Tue Jul 16 10:52:50 2013
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 16 Jul 2013 10:52:50 +0200
Subject: [R] MGCV: overlay fitted (marginal) curves over a plot of the
 original data
Message-ID: <51E509E2.9020600@agr.uni-goettingen.de>

Dear R users,

I?ve stumbled over a problem that can be easily seen from the R code below:

- When I use plot.gam() on a fitted model object, I get a nice and well-looking smooth curve for all
terms in the model.

- However, when I use predict(model) for a given predictor, with values of all other predictors set
to their means, the resulting curve doesn?t fit well at all.

Is there a way to "overlay" the curve produced by plot.gam() over a plot of the original data?

Here?s some reproducible code with mgcv version 1.7-22 on R3.0.1 (Windows 7):

##

library(mgcv)
set.seed(2)
dat <- gamSim(1,n=400,dist="normal",scale=2)
b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
plot(b,select=1)

plot(y~x0,dat)
mydata=data.frame(x0=0:1,x1=mean(dat$x1),x2=mean(dat$x2),x3=mean(dat$x3))
lines(0:1,predict(b,mydata,type="response"))

##

Best wishes,
Christoph


-- 
PD Dr Christoph Scherber
Georg-August University Goettingen
Department of Crop Science
Agroecology
Grisebachstrasse 6
D-37077 Goettingen
Germany
phone 0049 (0)551 39 8807
fax 0049 (0)551 39 8806
http://www.gwdg.de/~cscherb1


From s.wood at bath.ac.uk  Tue Jul 16 11:04:21 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Tue, 16 Jul 2013 10:04:21 +0100
Subject: [R] MGCV: overlay fitted (marginal) curves over a plot of the
 original data
In-Reply-To: <51E509E2.9020600@agr.uni-goettingen.de>
References: <51E509E2.9020600@agr.uni-goettingen.de>
Message-ID: <51E50C95.6060909@bath.ac.uk>

Probably you didn't want to set x0=0:1? Here is some code, to do what you want.
(The CI shape is not identical to the plot(b) version as the uncertainty includes
the uncertainty in the other smooths and the intercept now.)

library(mgcv)
set.seed(2)
dat <- gamSim(1,n=400,dist="normal",scale=2)
b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
plot(b,select=1)

plot(y~x0,dat)
mydata=data.frame(x0=0:200/200,x1=mean(dat$x1),x2=mean(dat$x2),x3=mean(dat$x3))
pv <- predict(b,mydata,type="response",se=TRUE)
lines(mydata$x0,pv$fit)
lines(mydata$x0,pv$fit+2*pv$se.fit,lty=2)
lines(mydata$x0,pv$fit-2*pv$se.fit,lty=2)


  

On 16/07/13 09:52, Christoph Scherber wrote:
> Dear R users,
>
> I?ve stumbled over a problem that can be easily seen from the R code below:
>
> - When I use plot.gam() on a fitted model object, I get a nice and well-looking smooth curve for all
> terms in the model.
>
> - However, when I use predict(model) for a given predictor, with values of all other predictors set
> to their means, the resulting curve doesn?t fit well at all.
>
> Is there a way to "overlay" the curve produced by plot.gam() over a plot of the original data?
>
> Here?s some reproducible code with mgcv version 1.7-22 on R3.0.1 (Windows 7):
>
> ##
>
> library(mgcv)
> set.seed(2)
> dat <- gamSim(1,n=400,dist="normal",scale=2)
> b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
> plot(b,select=1)
>
> plot(y~x0,dat)
> mydata=data.frame(x0=0:1,x1=mean(dat$x1),x2=mean(dat$x2),x3=mean(dat$x3))
> lines(0:1,predict(b,mydata,type="response"))
>
> ##
>
> Best wishes,
> Christoph
>
>


From Christoph.Scherber at agr.uni-goettingen.de  Tue Jul 16 11:11:28 2013
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 16 Jul 2013 11:11:28 +0200
Subject: [R] MGCV: overlay fitted (marginal) curves over a plot of the
 original data
In-Reply-To: <51E50C95.6060909@bath.ac.uk>
References: <51E509E2.9020600@agr.uni-goettingen.de>
	<51E50C95.6060909@bath.ac.uk>
Message-ID: <51E50E40.7020301@agr.uni-goettingen.de>

Thanks, the sequence of x0 values was clearly too short.

However, is there a way to overlay the (marginal) curve from plot.gam() over a plot of (x,y) values?

Best wishes
Christoph



Am 16/07/2013 11:04, schrieb Simon Wood:
> Probably you didn't want to set x0=0:1? Here is some code, to do what you want.
> (The CI shape is not identical to the plot(b) version as the uncertainty includes
> the uncertainty in the other smooths and the intercept now.)
> 
> library(mgcv)
> set.seed(2)
> dat <- gamSim(1,n=400,dist="normal",scale=2)
> b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
> plot(b,select=1)
> 
> plot(y~x0,dat)
> mydata=data.frame(x0=0:200/200,x1=mean(dat$x1),x2=mean(dat$x2),x3=mean(dat$x3))
> pv <- predict(b,mydata,type="response",se=TRUE)
> lines(mydata$x0,pv$fit)
> lines(mydata$x0,pv$fit+2*pv$se.fit,lty=2)
> lines(mydata$x0,pv$fit-2*pv$se.fit,lty=2)
> 
> 
>   
> 
> On 16/07/13 09:52, Christoph Scherber wrote:
>> Dear R users,
>>
>> I?ve stumbled over a problem that can be easily seen from the R code below:
>>
>> - When I use plot.gam() on a fitted model object, I get a nice and well-looking smooth curve for all
>> terms in the model.
>>
>> - However, when I use predict(model) for a given predictor, with values of all other predictors set
>> to their means, the resulting curve doesn?t fit well at all.
>>
>> Is there a way to "overlay" the curve produced by plot.gam() over a plot of the original data?
>>
>> Here?s some reproducible code with mgcv version 1.7-22 on R3.0.1 (Windows 7):
>>
>> ##
>>
>> library(mgcv)
>> set.seed(2)
>> dat <- gamSim(1,n=400,dist="normal",scale=2)
>> b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
>> plot(b,select=1)
>>
>> plot(y~x0,dat)
>> mydata=data.frame(x0=0:1,x1=mean(dat$x1),x2=mean(dat$x2),x3=mean(dat$x3))
>> lines(0:1,predict(b,mydata,type="response"))
>>
>> ##
>>
>> Best wishes,
>> Christoph
>>
>>
> 
> 
> 


From Christoph.Scherber at agr.uni-goettingen.de  Tue Jul 16 11:36:45 2013
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 16 Jul 2013 11:36:45 +0200
Subject: [R] MGCV: overlay fitted (marginal) curves over a plot of the
 original data
In-Reply-To: <51E50C95.6060909@bath.ac.uk>
References: <51E509E2.9020600@agr.uni-goettingen.de>
	<51E50C95.6060909@bath.ac.uk>
Message-ID: <51E5142D.2090504@agr.uni-goettingen.de>

Meanwhile, I found the solution myself:

using plot.gam() with shift=intercept and trans=exp (for a poisson model) does the job. I can then
add the original data using points()

Thanks again for your help, which is greatly appreciated!

Best wishes
Christoph

Am 16/07/2013 11:04, schrieb Simon Wood:
> Probably you didn't want to set x0=0:1? Here is some code, to do what you want.
> (The CI shape is not identical to the plot(b) version as the uncertainty includes
> the uncertainty in the other smooths and the intercept now.)
> 
> library(mgcv)
> set.seed(2)
> dat <- gamSim(1,n=400,dist="normal",scale=2)
> b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
> plot(b,select=1)
> 
> plot(y~x0,dat)
> mydata=data.frame(x0=0:200/200,x1=mean(dat$x1),x2=mean(dat$x2),x3=mean(dat$x3))
> pv <- predict(b,mydata,type="response",se=TRUE)
> lines(mydata$x0,pv$fit)
> lines(mydata$x0,pv$fit+2*pv$se.fit,lty=2)
> lines(mydata$x0,pv$fit-2*pv$se.fit,lty=2)
> 
> 
>   
> 
> On 16/07/13 09:52, Christoph Scherber wrote:
>> Dear R users,
>>
>> I?ve stumbled over a problem that can be easily seen from the R code below:
>>
>> - When I use plot.gam() on a fitted model object, I get a nice and well-looking smooth curve for all
>> terms in the model.
>>
>> - However, when I use predict(model) for a given predictor, with values of all other predictors set
>> to their means, the resulting curve doesn?t fit well at all.
>>
>> Is there a way to "overlay" the curve produced by plot.gam() over a plot of the original data?
>>
>> Here?s some reproducible code with mgcv version 1.7-22 on R3.0.1 (Windows 7):
>>
>> ##
>>
>> library(mgcv)
>> set.seed(2)
>> dat <- gamSim(1,n=400,dist="normal",scale=2)
>> b <- gam(y~s(x0)+s(x1)+s(x2)+s(x3),data=dat)
>> plot(b,select=1)
>>
>> plot(y~x0,dat)
>> mydata=data.frame(x0=0:1,x1=mean(dat$x1),x2=mean(dat$x2),x3=mean(dat$x3))
>> lines(0:1,predict(b,mydata,type="response"))
>>
>> ##
>>
>> Best wishes,
>> Christoph
>>
>>
> 
> 
> 


From michel.arnaud at cirad.fr  Tue Jul 16 11:52:15 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Tue, 16 Jul 2013 11:52:15 +0200
Subject: [R] Question on plotting with googleVis
In-Reply-To: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>
References: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>
Message-ID: <51E517CF.9060807@cirad.fr>

You can try with list options :

plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2"),
options=list(width=1200,height=1500)))



Le 15/07/2013 20:00, Christofer Bogaso a ?crit :
> Hello again,
>
> Let say I have following data-frame:
>
> MyData <- data.frame(Names1 = paste("XXX", 1:150), Values1 = 1:150 + 10,
> Values2 = 1:150)
>
> Now I want to plot this data-frame with googleVis. Therefore I run
> following codes:
>
> library(googleVis)
> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2")))
>
> However the problem is that, hardly this plot can be read. However if I
> plot a fraction of my data-frame then the underlying plot is clearly
> visible:
>
> plot(gvisBarChart(MyData[1:15,], xvar="Names1", yvar=c("Values1",
> "Values2")))  ## This is clearly visible.
>
>
> I would really appreciate if someone gives me some pointer how I can
> clearly plot my data-frame with googleVis. I understand that there are many
> other plotting methods available with R like ggplot, however here I want to
> use googleVis because of its strength in showing the values within the plot
> area itself if you hover your mouse.
>
> Thanks and regards,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From chrisege at stud.ntnu.no  Tue Jul 16 11:42:36 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Tue, 16 Jul 2013 02:42:36 -0700 (PDT)
Subject: [R] Finding parameters for residuals using GAMLSS and a lognormal
	dist.
Message-ID: <1373967756940-4671674.post@n4.nabble.com>

Hi everyone!

First of all: I am new to the forum, so please excuse my lack of knowledge
on how to post a question...

I am working on a project where I need to use the GAMLSS package, and the
boss have asked me to try using the lognormal distribution. 
The regression goes as planned, but when evaluating the residuals and using
the coef() function, I get multiple coefficients as theory says, but I?m not
sure if they can be used as parameters.

My question is: How can I model the residuals? Do I have to assume a
lognormal distribution of these, or can I assume a distribution of choice? 
I have plotted the kernel density of the residuals and they do seem to fit a
lognormal distribution, but as I am not entirely sure how to find
parameters, I do not know how... I guess this is an easy question, but I
just cant seem to find a solution to this.

A section of the code:
tmpformula = as.formula(paste(logvarnames[i]," ~ ",
paste(logvarnames[1:i-1], collapse= "+")))
res = gamlss(tmpformula, family = LOGNO(), data = myall )

where logvarnames[] is a vector containing the names of columns  from the
dataset I use called "myall". 





--
View this message in context: http://r.789695.n4.nabble.com/Finding-parameters-for-residuals-using-GAMLSS-and-a-lognormal-dist-tp4671674.html
Sent from the R help mailing list archive at Nabble.com.


From wil.louise at gmail.com  Tue Jul 16 13:17:21 2013
From: wil.louise at gmail.com (Louise Wilson)
Date: Tue, 16 Jul 2013 21:17:21 +1000
Subject: [R] Masking oceans using polypath
Message-ID: <CAMxjYa3RDKOcSk7Ms3vrWRaKiNMpek_i=nMawjQmAN3gv4eesA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/6b465957/attachment.pl>

From rainer.schuermann at gmx.net  Tue Jul 16 15:05:04 2013
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Tue, 16 Jul 2013 15:05:04 +0200
Subject: [R] Serialize data.frame to database
In-Reply-To: <89A18CA7-09C7-4545-8128-366FF12251E9@uni-bonn.de>
References: <89A18CA7-09C7-4545-8128-366FF12251E9@uni-bonn.de>
Message-ID: <1981651.DHoIGLLRtU@augeatur>

Maybe a simple

dbWriteTable( db, "frames", iris )

does what you want?



On Monday 15 July 2013 23:43:18 Simon Zehnder wrote:
> Dear R-Users,
> 
> I need a very fast and reliable database solution so I try to serialize a data.frame (to binary data) and to store this data to an SQLite database. 
> 
> This is what I tried to do:
> 
> library(RSQLite)
> con <- dbDriver("SQLite")
> db <- dbConnect(con, "test")
> dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" BLOB)')
> data.bin <- serialize(iris, NULL, ascii = FALSE)
> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.bin, "')", sep = ""))
> data.bin2 <- dbGetQuery(db, "SELECT DATA FROM frames WHERE simID = 1")
> data.bin2
>   data
> 1   58
> 
> So, only the first entry of data.bin is saved to the database. I tried to first convert the binary data to raw data:
> data.raw <- rawToChar(data.bin)
> Error in rawToChar(data.bin) :
>   embedded nul in string: 'X\n\0\0\0\002\0\003\0\001\0\002\003\0\0\0\003\023\0\0\0\005\0\0\0\016\0\0\0\x96@\024ffffff@\023\x99\x99\x99\x99\x99\x9a@\022\xcc\xcc\xcc\xcc\xcc\xcd@\022ffffff@\024\0\0\0\0\0\0@\025\x99\x99\x99\x99\x99\x9a@\022ffffff@\024\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\023\x99\x99\x99\x99\x99\x9a@\025\x99\x99\x99\x99\x99\x9a@\023333333@\023333333@\021333333@\027333333@\026\xcc\xcc\xcc\xcc\xcc\xcd@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\026\xcc\xcc\xcc\xcc\xcc\xcd@\024ffffff@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\022ffffff@\024ffffff@\023333333@\024\0\0\0\0\0\0@\024\0\0\0\0\0\0@\024\xcc\xcc\xcc\xcc\xcc\xcd@\024\xcc\xcc\xcc\xcc\xcc\xcd@\022\xcc\xcc\xcc\xcc\xcc\xcd@\023333333@\025\x99\x99\x99\x99\x99\x9a@\024\xcc\xcc\xcc\xcc\xcc\xcd@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\0\0@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\021\x99\x99\x99\x99\x99\x9a@\024ffffff@\024\0\0\0\0\0\0@\022\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\!
>  0\0
> 
> I don't know what this error should tell me. Then I tried to use the ASCII format
> 
> data.ascii <- serialize(iris, NULL, ascii = TRUE)
> data.raw <- rawToChar(data.ascii)
> dbSendQuery(db, "DELETE FROM frames")
> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.raw, "')", sep = ""))
> Error in sqliteExecStatement(conn, statement, ...) :
>   RS-DBI driver: (error in statement: unrecognized token: "X'A
> 
> This also does not work. It seems the driver does not deal that nicely with the regular INSERT query for BLOB objects in SQLite. Then I used a simpler way:
> 
> dbSendQuery(db, "DELETE FROM frames")
> dbSendQuery(db, "DROP TABLE frames")
> dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" TEXT DEFAULT NULL)')
> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, '", data.raw, "')", sep = ""))
> data.bin2 <- dbGetQuery(db, "SELECT data FROM frames WHERE simID = 1")
> 
> Nice, that worked. Now I want to unserialize the data:
> 
> unserialize(data.bin2)
> Error in unserialize(data.bin2) : 'connection' must be a connection
> 
> unserialize(data.bin2[1, 'data'])
> Error in unserialize(data.bin2[1, "data"]) :
>   character vectors are no longer accepted by unserialize()
> 
> I feel a little stuck here, but I am very sure, that converting data.frames to binary data and storing them to a database is not that unusual. So I hope somebody has already done this and could give me the missing piece.
> 
> 
> Best
> 
> Simon
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
- - - - -

Der NSA keine Chance: e-mail verschluesseln!
http://www.gpg4win.org/


From dtemplelang at ucdavis.edu  Tue Jul 16 15:46:25 2013
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Tue, 16 Jul 2013 06:46:25 -0700
Subject: [R] Weird 'xmlEventParse' encoding issue
In-Reply-To: <51E3DFD0.1000302@cognition.uni-freiburg.de>
References: <51E3DFD0.1000302@cognition.uni-freiburg.de>
Message-ID: <51E54EB1.7070101@ucdavis.edu>

Hi Sascha

 Your code gives the correct results on my machine (OS X),
either reading from the file directly or via readLines() and passing
the text to xmlEventParse().

 The problem might be the version of the XML package or your environment
settings.  And it is important to report the session information.
So you should provide the output from

   sessionInfo()
   Sys.getenv()
   libxmlVersion()


 D

On 7/15/13 4:41 AM, Sascha Wolfer wrote:
> Dear list,
> 
> I have got a weird encoding problem with the xmlEventParse() function from the 'XML' package.
> 
> I tried finding an answer on the web for several hours and a Stack Exchange question came back without success :(
> 
> So here's the problem. I created a small XML test file, which looks like this:
> 
> <?xml version="1.0" encoding="iso-8859-1"?>
> <!DOCTYPE testFile>
> <s type="manual">auch der Schulleiter steht daf?r zur Verf?gung. Das ist se?haft mit ? und ?...</s>
> 
> This file is encoded with the iso-8859-1 encoding which is also defined in its header.
> 
> I have 3 handler functions, definitions as follows:
> 
> sE2 <- function (name, attrs) {
>   if (name == "s") {
>     get.text <<- T }
> }
> 
> eE2 <- function (name, attrs) {
>   if (name == "s") {
>     get.text <<- F
>   }
> }
> 
> tS2 <- function (content, ...) {
>   if (get.text & nchar(content) > 0) {
>     collected.text <<- c(collected.text, content)
>   }
> }
> 
> I have one wrapper function around xmlEventParse(), definition as follows:
> 
> get.all.text <- function (file) {
>   t1 <- Sys.time()
>   read.file <- paste(readLines(file, encoding = ""), collapse = " ")
>   print(read.file)
>   assign("collected.text", c(), env = .GlobalEnv)
>   assign("get.text", F, env = .GlobalEnv)
>   xmlEventParse(read.file, asText = T, list(startElement = sE2,
>                                            endElement = eE2,
>                                            text = tS2),
>                error = function (...) { },
>                saxVersion = 1)
>   t2 <- Sys.time()
>   cat("That took", round(difftime(t2,t1, units="secs"), 1), "seconds.\n")
>   cat("Result of reading is in variable 'collected.text'.\n")
>   collected.text
> }
> 
> The output of calling get.all.text(<test file>) is as follows:
> [1] "<?xml version=\"1.0\" encoding=\"iso-8859-1\"?> <!DOCTYPE testFile> <s type=\"manual\">auch der Schulleiter steht
> daf?r zur Verf?gung. Das ist se?haft mit ? und ?...</s> "
> That took 0 seconds.
> Result of reading is in variable 'collected.text'.
> [1] "auch der Schulleiter steht daf"                        "??r zur Verf??gung. Das ist se??haft mit ?? und ??..."
> 
> Now the REALLY weird thing (for me) is that R obviously reads in the file correctly (first output) with 'readLines()'.
> Then this output is passed to xmlEventParse. Afterwards the output is broken and it sometimes also inserts weird breaks
> were special characters occur.
> 
> Do you have any ideas how to solve this problem?
> 
> I cannot use the xmlParse() function because I need the SAX functionality of xmlEventParse(). I also tried reading the
> file with xmlEventParse() directly (with asText = F). No changes...
> 
> Thanks a lot,
> Sascha W.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Tue Jul 16 17:43:52 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 16 Jul 2013 17:43:52 +0200
Subject: [R] Serialize data.frame to database
In-Reply-To: <1981651.DHoIGLLRtU@augeatur>
References: <89A18CA7-09C7-4545-8128-366FF12251E9@uni-bonn.de>
	<1981651.DHoIGLLRtU@augeatur>
Message-ID: <1B6930A0-7A9A-4692-A3C1-D170D8DFF6D9@uni-bonn.de>

Hi Rainer,

dbWriteTable is a nice function but in my case I need something that can actually save a dataframe in one row of a table. That is why I want to serialize my data.frame. 


Best

Simon


On Jul 16, 2013, at 3:05 PM, Rainer Schuermann <rainer.schuermann at gmx.net> wrote:

> Maybe a simple
> 
> dbWriteTable( db, "frames", iris )
> 
> does what you want?
> 
> 
> 
> On Monday 15 July 2013 23:43:18 Simon Zehnder wrote:
>> Dear R-Users,
>> 
>> I need a very fast and reliable database solution so I try to serialize a data.frame (to binary data) and to store this data to an SQLite database. 
>> 
>> This is what I tried to do:
>> 
>> library(RSQLite)
>> con <- dbDriver("SQLite")
>> db <- dbConnect(con, "test")
>> dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" BLOB)')
>> data.bin <- serialize(iris, NULL, ascii = FALSE)
>> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.bin, "')", sep = ""))
>> data.bin2 <- dbGetQuery(db, "SELECT DATA FROM frames WHERE simID = 1")
>> data.bin2
>>  data
>> 1   58
>> 
>> So, only the first entry of data.bin is saved to the database. I tried to first convert the binary data to raw data:
>> data.raw <- rawToChar(data.bin)
>> Error in rawToChar(data.bin) :
>>  embedded nul in string: 'X\n\0\0\0\002\0\003\0\001\0\002\003\0\0\0\003\023\0\0\0\005\0\0\0\016\0\0\0\x96@\024ffffff@\023\x99\x99\x99\x99\x99\x9a@\022\xcc\xcc\xcc\xcc\xcc\xcd@\022ffffff@\024\0\0\0\0\0\0@\025\x99\x99\x99\x99\x99\x9a@\022ffffff@\024\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\023\x99\x99\x99\x99\x99\x9a@\025\x99\x99\x99\x99\x99\x9a@\023333333@\023333333@\021333333@\027333333@\026\xcc\xcc\xcc\xcc\xcc\xcd@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\026\xcc\xcc\xcc\xcc\xcc\xcd@\024ffffff@\025\x99\x99\x99\x99\x99\x9a@\024ffffff@\022ffffff@\024ffffff@\023333333@\024\0\0\0\0\0\0@\024\0\0\0\0\0\0@\024\xcc\xcc\xcc\xcc\xcc\xcd@\024\xcc\xcc\xcc\xcc\xcc\xcd@\022\xcc\xcc\xcc\xcc\xcc\xcd@\023333333@\025\x99\x99\x99\x99\x99\x9a@\024\xcc\xcc\xcc\xcc\xcc\xcd@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\024\0\0\0\0\0\0@\026\0\0\0\0\0\0@\023\x99\x99\x99\x99\x99\x9a@\021\x99\x99\x99\x99\x99\x9a@\024ffffff@\024\0\0\0\0\0\0@\022\0\0\0\0\0\0@\021\x99\x99\x99\x99\x99\x9a@\024\0\0\0\!
> 0\!
>> 0\0
>> 
>> I don't know what this error should tell me. Then I tried to use the ASCII format
>> 
>> data.ascii <- serialize(iris, NULL, ascii = TRUE)
>> data.raw <- rawToChar(data.ascii)
>> dbSendQuery(db, "DELETE FROM frames")
>> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, X'", data.raw, "')", sep = ""))
>> Error in sqliteExecStatement(conn, statement, ...) :
>>  RS-DBI driver: (error in statement: unrecognized token: "X'A
>> 
>> This also does not work. It seems the driver does not deal that nicely with the regular INSERT query for BLOB objects in SQLite. Then I used a simpler way:
>> 
>> dbSendQuery(db, "DELETE FROM frames")
>> dbSendQuery(db, "DROP TABLE frames")
>> dbSendQuery(db, 'CREATE TABLE frames("simID" INT, "data" TEXT DEFAULT NULL)')
>> dbSendQuery(db, paste("INSERT INTO frames VALUES(1, '", data.raw, "')", sep = ""))
>> data.bin2 <- dbGetQuery(db, "SELECT data FROM frames WHERE simID = 1")
>> 
>> Nice, that worked. Now I want to unserialize the data:
>> 
>> unserialize(data.bin2)
>> Error in unserialize(data.bin2) : 'connection' must be a connection
>> 
>> unserialize(data.bin2[1, 'data'])
>> Error in unserialize(data.bin2[1, "data"]) :
>>  character vectors are no longer accepted by unserialize()
>> 
>> I feel a little stuck here, but I am very sure, that converting data.frames to binary data and storing them to a database is not that unusual. So I hope somebody has already done this and could give me the missing piece.
>> 
>> 
>> Best
>> 
>> Simon
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> - - - - -
> 
> Der NSA keine Chance: e-mail verschluesseln!
> http://www.gpg4win.org/
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From canamika at gmail.com  Tue Jul 16 17:52:00 2013
From: canamika at gmail.com (Anamika Chaudhuri)
Date: Tue, 16 Jul 2013 11:52:00 -0400
Subject: [R] Error from running R2WinBUGS in R
Message-ID: <CALv--dY4fbRH-ngsCcbCSUEwzyj4ZKkKJVxY0oHJ=8dYQOZk4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/deced3a7/attachment.pl>

From stephen.creamer at nhs.net  Tue Jul 16 15:36:59 2013
From: stephen.creamer at nhs.net (Steve Creamer)
Date: Tue, 16 Jul 2013 06:36:59 -0700 (PDT)
Subject: [R] Setting Derived Class Slots
Message-ID: <1373981819489-4671683.post@n4.nabble.com>

Dear All....I am really struggling with oo in R. Trying to set attributes of
the base class in a derived class method but the slot is only populated in
the method itself, not when I try to print out the object from the console.

Code is  

library(RODBC)
#
# -----------------------------------------------------
# Define a medical event class. This is abstract (VIRTUAL)
# -----------------------------------------------------
#
setClass("Medical_Event",
         representation(
            Event_Name="character",
            Capacity_Profile="numeric",
            Delay_Profile="numeric",
            "VIRTUAL"),
         prototype(Event_Name="An
Event",Capacity_Profile=c(.2,.2,.2,.2,.2,0,0)))

setGeneric("getDelayProfile",function(object){standardGeneric("getDelayProfile")},simpleInheritanceOnly=T)

# ------------------------------------------
# Now define a derived class called GP_Event
# ------------------------------------------

setClass("GP_Event",representation(Surgery_Name="character"),contains=c("Medical_Event"),prototype(Surgery_Name="Unknown"))

# -----------------------------------------
# Now define a derived class called OP_Appt
# -----------------------------------------

setClass("OP_Appt",representation(Clinic_Name="character"),contains=c("Medical_Event"),prototype(Clinic_Name="Unknown"))


setMethod(f="getDelayProfile",signature("OP_Appt"),definition=function(object)
   {
      OpTablesDB<-odbcDriverConnect("DRIVER=Microsoft Access Driver (*.mdb,
*.accdb);
                                     DBQ=Z:\\srp\\Development
Code\\Projects\\CancerPathwaySimulation\\Database\\CancerPathway.accdb")
      strQuery<-"select * from op_profile"
      odbcQuery(OpTablesDB,strQuery)
      dfQuery<-odbcFetchRows(OpTablesDB)
      odbcClose(OpTablesDB)
      delay<-dfQuery$data[[1]][1:70]
      prob<-dfQuery$data[[2]][1:70]
#      as(object,"Medical_Event")@Delay_Profile<-prob
      object at Delay_Profile <- prob
       object
   }
)

if I instantiate a new instance of the derived class 

*aTest<-new("OPP_Appt")*and then try and populate the attribute
Delay_Profile by 

*getDelayProfile(aTest) *

the object slot seems to be populated in the method because I can print it
out, viz

An object of class "OP_Appt"
Slot "Clinic_Name":
[1] "Unknown"

Slot "Event_Name":
[1] "An Event"

Slot "Capacity_Profile":
[1] 0.2 0.2 0.2 0.2 0.2 0.0 0.0

*Slot "Delay_Profile":
 [1]  14  21  25  29  27  49  72  71  43  65 102 134 223 358  24  14  21  25 
35  31  38  43  31  23  21  26  46  54  42  26
[31]  34  24  25  41  48  33  30  17  18  31  24  35  35  24  16  32  36  39 
46  36  26  16  27  21  30  32  33  27   7   5
[61]   9  10   9  11   8   6   1  11  14  10*

but when the method returns and I type

*aTest*

I get 

An object of class "OP_Appt"
Slot "Clinic_Name":
[1] "Unknown"

Slot "Event_Name":
[1] "An Event"

Slot "Capacity_Profile":
[1] 0.2 0.2 0.2 0.2 0.2 0.0 0.0

*Slot "Delay_Profile":
numeric(0)*

ie the Delay_Profile slot is empty????

What haven't I done - can anybody help me please?
Many Thanks

Steve Creamer




--
View this message in context: http://r.789695.n4.nabble.com/Setting-Derived-Class-Slots-tp4671683.html
Sent from the R help mailing list archive at Nabble.com.


From jgibbons at hsph.harvard.edu  Tue Jul 16 16:43:35 2013
From: jgibbons at hsph.harvard.edu (jgibbons1)
Date: Tue, 16 Jul 2013 07:43:35 -0700 (PDT)
Subject: [R] Errors using large numbers ((i) all entries of 'x' must be
 nonnegative and finite and (ii) NAs introduced by coercion)
Message-ID: <1373985815789-4671685.post@n4.nabble.com>

Hello,
I am fairly new to R, so please forgive me if this is a fairly easy
solution.

I am trying to perform multiple Fisher's Exact tests or Pearson's
Chi-squared contingency tests from a datamatrix in which data from each row
is data for an independent test.

My data is formatted as such:

AAA 75533 4756922556 88210 6715122129
BBB 14869 4756983220 16384 6715193955
CCC  7230 4756990859  8559 6715201780
DDD 18332 4756979757 23336 6715187003
EEE 14733 4756983356 16826 6715193513
FFF  2918 4756995171  3433 6715206906
GGG  3726 4756994363  4038 6715206301
HHH  6196 4756991893  7011 6715203328
III  7925 4756990164  9130 6715201209
JJJ  1434 4756996655  1602 6715208737

Where the 1st column is the identifier, the 2nd column = observations 1, the
3rd column = background counts 1, the 4th column = observations 2 and the
5th column = background counts 2.

I am loading my data as such:

     > data=read.table("My.File", header=FALSE)

And I am looping through each row to perform a test like this:

     > pvalues=c("pvalue")
     > for(i in 1:10){
     + datamatrix=matrix(c(as.integer(data[i,2:5])),nrow=2)
     + fisherresult=fisher.test(datamatrix)
     + pvalues=cbind(pvalues,fisherresult[1])
     + }

Here is the Error I am Getting:

Error in fisher.test(datamatrix) : 
  all entries of 'x' must be nonnegative and finite
In addition: Warning messages:
1: In matrix(c(as.integer(data[i, 2:5])), nrow = 2) :
  NAs introduced by coercion
2: In matrix(c(as.integer(data[i, 2:5])), nrow = 2) :
  NAs introduced by coercion
 

When I replace the large number in the 3rd and 5th column with smaller
numbers, the statistical calculation works fine.

Any ideas? Any help would be GREATLY appreciated!



--
View this message in context: http://r.789695.n4.nabble.com/Errors-using-large-numbers-i-all-entries-of-x-must-be-nonnegative-and-finite-and-ii-NAs-introduced-b-tp4671685.html
Sent from the R help mailing list archive at Nabble.com.


From hnorpois at gmail.com  Tue Jul 16 17:52:59 2013
From: hnorpois at gmail.com (Hermann Norpois)
Date: Tue, 16 Jul 2013 17:52:59 +0200
Subject: [R] glm - change offset to avoid NA?
In-Reply-To: <CACk-te06ydAbPPW0uuDb-KPu3ntBx82wxUw-g7R47MG8uNkCQQ@mail.gmail.com>
References: <CAKyZeBubh0t9GDTkDtpBGQ8iuvsN=QVHE8vboEzkzKwVFaUfQA@mail.gmail.com>
	<CACk-te06ydAbPPW0uuDb-KPu3ntBx82wxUw-g7R47MG8uNkCQQ@mail.gmail.com>
Message-ID: <CAKyZeBvyXbTZRACPG4-f=piEGt=WyQZAUM2=Sq-Bx2to4WsWBQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/adbf4e7b/attachment.pl>

From dwinsemius at comcast.net  Tue Jul 16 18:20:45 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 16 Jul 2013 09:20:45 -0700
Subject: [R] glm - change offset to avoid NA?
In-Reply-To: <CAKyZeBvyXbTZRACPG4-f=piEGt=WyQZAUM2=Sq-Bx2to4WsWBQ@mail.gmail.com>
References: <CAKyZeBubh0t9GDTkDtpBGQ8iuvsN=QVHE8vboEzkzKwVFaUfQA@mail.gmail.com>
	<CACk-te06ydAbPPW0uuDb-KPu3ntBx82wxUw-g7R47MG8uNkCQQ@mail.gmail.com>
	<CAKyZeBvyXbTZRACPG4-f=piEGt=WyQZAUM2=Sq-Bx2to4WsWBQ@mail.gmail.com>
Message-ID: <9ABB6140-1277-440F-80E0-835F868E2320@comcast.net>


On Jul 16, 2013, at 8:52 AM, Hermann Norpois wrote:

> I did not think of something like "try". I thouht that there should always
> be a value if I do a logistic regression but sometimes the values are far
> from being meaningful. So there is a cut-off.

That seems implausilbe. I think you are just seeing the effect of a random selection creating a data situation where the interaction term is aliased with the others, in which case `glm` will set the coefficient to NA.

> My plan was to change the
> cut-off.

You said there was an "error", but you should have said that the results were unexpected. You can create an "error-condition" when this occurs with the `stop` function. And then do whatever remedial work is needed.

-- 
David.

> Thanks
> Johannes
> 
> 
> 2013/7/15 Bert Gunter <gunter.berton at gene.com>
> 
>> I think what you want is
>> 
>> ?try  ##or
>> ?tryCatch
>> 
>> ## The second is more flexible but slightly more complicated.
>> 
>> to trap the error and perhaps refit the model without interaction?
>> 
>> Cheers,
>> Bert
>> 
>> On Mon, Jul 15, 2013 at 10:45 AM, Hermann Norpois <hnorpois at gmail.com>
>> wrote:
>>> Hello,
>>> 
>>> I use glm within a function testing for the appearence of the coexistence
>>> of (minor allels in a subset of)  snps. And then I extract the
>>> Pr(>|z|)-value for the interaction. Principally it works but sometimes
>> the
>>> function stops because this "value for the interaction"  is NA. For
>>> instance, this is the case in the following example:
>>> 
>>> lz <- glm(trait~rs7572685*rs10520302, data=mus, family=binomial)
>>>> summary (lz)
>>> ...
>>> Coefficients: (1 not defined because of singularities)
>>>                     Estimate Std. Error z value Pr(>|z|)
>>> (Intercept)           0.05614    0.16782   0.335    0.738
>>> rs7572685             0.49041    0.41437   1.183    0.237
>>> rs10520302            0.49269    0.43514   1.132    0.258
>>> rs7572685:rs10520302       NA         NA      NA       NA
>>> ...
>>> 
>>> I would prefer some values instead of NA (though it does not make any
>> sense
>>> in terms of interpretation) for the sake of the smooth running of my
>>> function. How is this done? I guess I have to change the offset but I
>> dont
>>> understand how.
>>> Thanks
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> 
>> --
>> 
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>> 
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>> 
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From mtmorgan at fhcrc.org  Tue Jul 16 18:40:27 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 16 Jul 2013 09:40:27 -0700
Subject: [R] Setting Derived Class Slots
In-Reply-To: <1373981819489-4671683.post@n4.nabble.com>
References: <1373981819489-4671683.post@n4.nabble.com>
Message-ID: <51E5777B.9020106@fhcrc.org>

On 07/16/2013 06:36 AM, Steve Creamer wrote:
> Dear All....I am really struggling with oo in R. Trying to set attributes of
> the base class in a derived class method but the slot is only populated in
> the method itself, not when I try to print out the object from the console.
>
> Code is
>
> library(RODBC)
> #
> # -----------------------------------------------------
> # Define a medical event class. This is abstract (VIRTUAL)
> # -----------------------------------------------------
> #
> setClass("Medical_Event",
>           representation(
>              Event_Name="character",
>              Capacity_Profile="numeric",
>              Delay_Profile="numeric",
>              "VIRTUAL"),
>           prototype(Event_Name="An
> Event",Capacity_Profile=c(.2,.2,.2,.2,.2,0,0)))
>
> setGeneric("getDelayProfile",function(object){standardGeneric("getDelayProfile")},simpleInheritanceOnly=T)
>
> # ------------------------------------------
> # Now define a derived class called GP_Event
> # ------------------------------------------
>
> setClass("GP_Event",representation(Surgery_Name="character"),contains=c("Medical_Event"),prototype(Surgery_Name="Unknown"))
>
> # -----------------------------------------
> # Now define a derived class called OP_Appt
> # -----------------------------------------
>
> setClass("OP_Appt",representation(Clinic_Name="character"),contains=c("Medical_Event"),prototype(Clinic_Name="Unknown"))
>
>
> setMethod(f="getDelayProfile",signature("OP_Appt"),definition=function(object)
>     {
>        OpTablesDB<-odbcDriverConnect("DRIVER=Microsoft Access Driver (*.mdb,
> *.accdb);
>                                       DBQ=Z:\\srp\\Development
> Code\\Projects\\CancerPathwaySimulation\\Database\\CancerPathway.accdb")
>        strQuery<-"select * from op_profile"
>        odbcQuery(OpTablesDB,strQuery)
>        dfQuery<-odbcFetchRows(OpTablesDB)
>        odbcClose(OpTablesDB)
>        delay<-dfQuery$data[[1]][1:70]
>        prob<-dfQuery$data[[2]][1:70]
> #      as(object,"Medical_Event")@Delay_Profile<-prob
>        object at Delay_Profile <- prob
>         object
>     }
> )
>
> if I instantiate a new instance of the derived class
>
> *aTest<-new("OPP_Appt")*and then try and populate the attribute
> Delay_Profile by
>
> *getDelayProfile(aTest) *
>
> the object slot seems to be populated in the method because I can print it
> out, viz
>
> An object of class "OP_Appt"
> Slot "Clinic_Name":
> [1] "Unknown"
>
> Slot "Event_Name":
> [1] "An Event"
>
> Slot "Capacity_Profile":
> [1] 0.2 0.2 0.2 0.2 0.2 0.0 0.0
>
> *Slot "Delay_Profile":
>   [1]  14  21  25  29  27  49  72  71  43  65 102 134 223 358  24  14  21  25
> 35  31  38  43  31  23  21  26  46  54  42  26
> [31]  34  24  25  41  48  33  30  17  18  31  24  35  35  24  16  32  36  39
> 46  36  26  16  27  21  30  32  33  27   7   5
> [61]   9  10   9  11   8   6   1  11  14  10*
>
> but when the method returns and I type
>
> *aTest*
>
> I get
>
> An object of class "OP_Appt"
> Slot "Clinic_Name":
> [1] "Unknown"
>
> Slot "Event_Name":
> [1] "An Event"
>
> Slot "Capacity_Profile":
> [1] 0.2 0.2 0.2 0.2 0.2 0.0 0.0
>
> *Slot "Delay_Profile":
> numeric(0)*
>
> ie the Delay_Profile slot is empty????
>
> What haven't I done - can anybody help me please?

It helps to provide a more minimal example, preferably reproducible (no data 
base queries needed to illustrate your problem); I'm guessing that, just as with

f = funtion(l) { l$a = 1; l }
lst = list(a=0, b=1)

one would 'update' lst with

   lst = f(lst)

and not

   f(lst)

you need to assign the return value to the original object

   aTest <- getDelayProfile(aTest)

Martin

> Many Thanks
>
> Steve Creamer
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Setting-Derived-Class-Slots-tp4671683.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From szehnder at uni-bonn.de  Tue Jul 16 18:42:04 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 16 Jul 2013 18:42:04 +0200
Subject: [R] Setting Derived Class Slots
In-Reply-To: <1373981819489-4671683.post@n4.nabble.com>
References: <1373981819489-4671683.post@n4.nabble.com>
Message-ID: <D7EC1BAF-5620-4DDB-AA5D-32E9C0837869@uni-bonn.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/18d4b0ad/attachment.pl>

From bhh at xs4all.nl  Tue Jul 16 18:44:51 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 16 Jul 2013 18:44:51 +0200
Subject: [R] Ode error message
In-Reply-To: <4565B2277456ED4EB03CD34B21283B472067BE84D1@EXH01001.hmc.local>
References: <4565B2277456ED4EB03CD34B21283B472067BE84D1@EXH01001.hmc.local>
Message-ID: <B71BDF5C-6AD5-4F0E-A7FB-93634BEA12AB@xs4all.nl>



See inline remarks.

On 16-07-2013, at 10:07, Rapha?lle Carraud <raphaelle.carraud at oc-metalchem.com> wrote:

> Hello,
> 
> I am creating a program with R to solve a differential equation system. However, I get the following message I do not understand :
> 
>> out <- ode(y = state, times = z, func = liquide, parms = 0, atol = 0)
> DLSODA-  EWT(I1) is R1 .le. 0.0
> In above message, I1 = 1
> 
> In above message, R1 = 0
> 
> Error in lsoda(y, times, func, parms, ...) : 
>  illegal input detected before taking any integration steps - see written message
> 
> or this one when I tried modifying the atoll value :
> 
>> out <- ode(y = state, times = z, func = liquide, parms = 0, atol = 10^-14)
> DLSODA-  Warning..Internal T (=R1) and H (=R2) are
>      such that in the machine, T + H = T on the next step
>     (H = step size). Solver will continue anyway.
> In above message, R1 = 0, R2 = 0
> 
> DINTDY-  T (=R1) illegal
> In above message, R1 = 1
> 
>      T not in interval TCUR - HU (= R1) to TCUR (=R2)
> In above message, R1 = 0, R2 = 0
> 
> DINTDY-  T (=R1) illegal
> In above message, R1 = 2
> 
>      T not in interval TCUR - HU (= R1) to TCUR (=R2)
> In above message, R1 = 0, R2 = 0
> 
> DLSODA-  Trouble in DINTDY.  ITASK = I1, TOUT = R1
> In above message, I1 = 1
> 
> In above message, R1 = 2
> 
> Here is my program. I also tried changing the initial values but it does not work well.
> 
> liquide <- function(z, state, parameters) {
>  with(as.list(c(state,parameters)),{
>    # rate of change
> 
>    Tr <- 273+90

Why are you defining Tr? It is not used anywhere

>    C <- CA + CB + CC + CD + CE + CI + CG + CJ + CK + CH
> 

Same thing. Not used.

>    K32 <- 6.54*10^4      
>    K33 <- 1.37*10^4      
>    K34 <- 330                 
>    K35 <- 5.81*10^4      
>    kf2 <- 1.37*10^3      
>    kf3 <- 1.37*10^3     
>    kf4 <- 8.68*10^5      
>    kf5 <- 157.2
> 
>    K2 <- 10^1.37        
>    K3 <- 10^(-3.35)     
> 
>    r1 <- kf4*CD - kf4/K34*CE^2
>    r2 <- kf3*CA*CB - kf3/K33*CD
>    r3 <- kf2*CA^2 - kf2/K32*CC
>    r4 <- kf5*CC - kf5/K35*CE*CI^2 
> 
> 
>    dCA <- -r2                                                      # dNO/dt
>    dCB <- -r3 - r2                                               # dNO2/dt
>    dCC <- r3/2 - r4                                             # dN2O4/dt
>    dCD <- r2 - r1                                                # dN2O3/dt
>    dCE <- 2*r1 + r4                                            # dHNO2/dt
>    dCI <- r4                                                         # dHNO3/dt
>    dCG <- -r4 - r1                                               # dH2O/dz
>    dCH <- (dCE + dCI)/((K2 + K3)*(CE + CI))      # dH/dz
>    dCJ <-  (CH*dCI - CI*dCH)/(K3*CH^2)          # dNO3-/dz

You are dividing by CH, which is 0 initially. So what value does dCH  then get?
>    dCK <-  (CH*dCE - CE*dCH)/(K2*CH^2)        # dNO2-/dz
> 

Same thing.
> 
> 
>    list(c(dCA, dCB, dCC, dCD, dCE, dCI, dCG, dCH, dCJ, dCK))
>  })   # end with(as.list ...
> }
> 
> 
> Ti <- 273+90       # K

You are not using Ti.
> Ct <- 5100   # mol/m^3
> 

And Ct is also not used.

> state <-c(CA = 0,           # mol/m^3 NO2
>          CB = 0,               # mol/m^3 NO
>          CC = 0,                # mol/m^3 N2O4
>          CD = 0,              # mol/m^3 N2O3
>          CE = 50,              # mol/m^3 HNO2
>          CI = 50,             # mol/m^3 HNO3
>          CG = 5000,         # mol/m^3 H2O
>          CH = 0,             # mol/m^3 H+

0!!

>          CJ = 0,                # mol/m^3 NO3-
>          CK = 0)             # mol/m^3 NO2-
> 
> parameters <- c(Ct = 5100)
> 

Why not parameters <- c(Ct = Ct)?

> z <- seq(0, 15, by = 1)  # en seconde
> 
> library(deSolve)
> out <- ode(y = state, times = z, func = liquide, parms = 0, atol = 10^-14)
> head(out)
> plot(out)
> 
You will still get messages.
You should really learn to de elementary debugging.
Such as inserting

liquide(0,state,parameters)

after defining state and parameters to check and test.

Berend

> Thank you
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From petr.pikal at precheza.cz  Tue Jul 16 18:54:26 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Tue, 16 Jul 2013 16:54:26 +0000
Subject: [R] Errors using large numbers ((i) all entries of 'x' must be
 nonnegative and finite and (ii) NAs introduced by coercion)
In-Reply-To: <1373985815789-4671685.post@n4.nabble.com>
References: <1373985815789-4671685.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7E1A5@SRVEXCHMBX.precheza.cz>

Well,

You could find it yourself,

as.integer(c(75533, 4756922556, 88210, 6715122129))
[1] 75533    NA 88210    NA
Warning message:
NAs introduced by coercion 
> matrix(c(75533, 4756922556, 88210, 6715122129), nrow=2)
           [,1]       [,2]
[1,]      75533      88210
[2,] 4756922556 6715122129

Using as.integer inputs NA as integer type has limited size.

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of jgibbons1
> Sent: Tuesday, July 16, 2013 4:44 PM
> To: r-help at r-project.org
> Subject: [R] Errors using large numbers ((i) all entries of 'x' must be
> nonnegative and finite and (ii) NAs introduced by coercion)
> 
> Hello,
> I am fairly new to R, so please forgive me if this is a fairly easy
> solution.
> 
> I am trying to perform multiple Fisher's Exact tests or Pearson's Chi-
> squared contingency tests from a datamatrix in which data from each row
> is data for an independent test.
> 
> My data is formatted as such:
> 
> AAA 75533 4756922556 88210 6715122129
> BBB 14869 4756983220 16384 6715193955
> CCC  7230 4756990859  8559 6715201780
> DDD 18332 4756979757 23336 6715187003
> EEE 14733 4756983356 16826 6715193513
> FFF  2918 4756995171  3433 6715206906
> GGG  3726 4756994363  4038 6715206301
> HHH  6196 4756991893  7011 6715203328
> III  7925 4756990164  9130 6715201209
> JJJ  1434 4756996655  1602 6715208737
> 
> Where the 1st column is the identifier, the 2nd column = observations
> 1, the 3rd column = background counts 1, the 4th column = observations
> 2 and the 5th column = background counts 2.
> 
> I am loading my data as such:
> 
>      > data=read.table("My.File", header=FALSE)
> 
> And I am looping through each row to perform a test like this:
> 
>      > pvalues=c("pvalue")
>      > for(i in 1:10){
>      + datamatrix=matrix(c(as.integer(data[i,2:5])),nrow=2)
>      + fisherresult=fisher.test(datamatrix)
>      + pvalues=cbind(pvalues,fisherresult[1])
>      + }
> 
> Here is the Error I am Getting:
> 
> Error in fisher.test(datamatrix) :
>   all entries of 'x' must be nonnegative and finite In addition:
> Warning messages:
> 1: In matrix(c(as.integer(data[i, 2:5])), nrow = 2) :
>   NAs introduced by coercion
> 2: In matrix(c(as.integer(data[i, 2:5])), nrow = 2) :
>   NAs introduced by coercion
> 
> 
> When I replace the large number in the 3rd and 5th column with smaller
> numbers, the statistical calculation works fine.
> 
> Any ideas? Any help would be GREATLY appreciated!
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Errors-
> using-large-numbers-i-all-entries-of-x-must-be-nonnegative-and-finite-
> and-ii-NAs-introduced-b-tp4671685.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mnshdtt0 at gmail.com  Tue Jul 16 19:23:56 2013
From: mnshdtt0 at gmail.com (Dia)
Date: Tue, 16 Jul 2013 10:23:56 -0700 (PDT)
Subject: [R] help
Message-ID: <CAGZ4UQsZW-r0aZ38g-j8drQvVpDYfrAtUBT4WMGEsg_zrKwJFQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/45068099/attachment.pl>

From josh.m.ulrich at gmail.com  Tue Jul 16 19:47:38 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 16 Jul 2013 12:47:38 -0500
Subject: [R] help
In-Reply-To: <CAGZ4UQsZW-r0aZ38g-j8drQvVpDYfrAtUBT4WMGEsg_zrKwJFQ@mail.gmail.com>
References: <CAGZ4UQsZW-r0aZ38g-j8drQvVpDYfrAtUBT4WMGEsg_zrKwJFQ@mail.gmail.com>
Message-ID: <CAPPM_gQWhiKM4_JghuqDvmnpUtKK4J5_02Ljs3Pb1haJ_0vw6g@mail.gmail.com>

On Tue, Jul 16, 2013 at 12:23 PM, Dia <mnshdtt0 at gmail.com> wrote:
> Hi, i am tring to learn R own my own. From where can i download data for R
> (creating a subset). Right now i'm using
>  (http://finance.yahoo.com/q/hp?s=MCD+Historical+Prices) this link for data
> but unable to create subset.
>
> Can someone help me using this data or help me to download different data?
>
Use quantmod::getSymbols.

library(quantmod)
getSymbols("MCD")
str(MCD)

And read ?xts for ways to subset the MCD object.

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From belen.cillero at hotmail.com  Tue Jul 16 19:28:45 2013
From: belen.cillero at hotmail.com (=?iso-8859-1?B?QmVs6W4gQ2lsbGVybw==?=)
Date: Tue, 16 Jul 2013 19:28:45 +0200
Subject: [R] pxR
Message-ID: <DUB114-W52B187A4D060964F249F5DF3600@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/be19a559/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 16 19:38:28 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 16 Jul 2013 10:38:28 -0700 (PDT)
Subject: [R] Errors using large numbers ((i) all entries of 'x' must be
	nonnegative and finite and (ii) NAs introduced by coercion)
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7E1A5@SRVEXCHMBX.precheza.cz>
References: <1373985815789-4671685.post@n4.nabble.com>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7E1A5@SRVEXCHMBX.precheza.cz>
Message-ID: <1373996308.49153.YahooMailNeo@web142605.mail.bf1.yahoo.com>



HI,
?as.integer() #documentation
Note that current implementations of R use 32-bit integers for
???? integer vectors, so the range of representable integers is
???? restricted to about +/-2*10^9: ?double?s can hold much larger
???? integers exactly.
as.numeric(c(75533, 4756922556, 88210, 6715122129))
#[1]????? 75533 4756922556????? 88210 6715122129
#or
?as.double(c(75533, 4756922556, 88210, 6715122129))
#[1]????? 75533 4756922556????? 88210 6715122129
A.K.





----- Original Message -----
From: PIKAL Petr <petr.pikal at precheza.cz>
To: jgibbons1 <jgibbons at hsph.harvard.edu>; "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 16, 2013 12:54 PM
Subject: Re: [R] Errors using large numbers ((i) all entries of 'x' must be nonnegative and finite and (ii) NAs introduced by coercion)

Well,

You could find it yourself,

as.integer(c(75533, 4756922556, 88210, 6715122129))
[1] 75533? ? NA 88210? ? NA
Warning message:
NAs introduced by coercion 
> matrix(c(75533, 4756922556, 88210, 6715122129), nrow=2)
? ? ? ? ?  [,1]? ? ?  [,2]
[1,]? ? ? 75533? ? ? 88210
[2,] 4756922556 6715122129

Using as.integer inputs NA as integer type has limited size.

Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of jgibbons1
> Sent: Tuesday, July 16, 2013 4:44 PM
> To: r-help at r-project.org
> Subject: [R] Errors using large numbers ((i) all entries of 'x' must be
> nonnegative and finite and (ii) NAs introduced by coercion)
> 
> Hello,
> I am fairly new to R, so please forgive me if this is a fairly easy
> solution.
> 
> I am trying to perform multiple Fisher's Exact tests or Pearson's Chi-
> squared contingency tests from a datamatrix in which data from each row
> is data for an independent test.
> 
> My data is formatted as such:
> 
> AAA 75533 4756922556 88210 6715122129
> BBB 14869 4756983220 16384 6715193955
> CCC? 7230 4756990859? 8559 6715201780
> DDD 18332 4756979757 23336 6715187003
> EEE 14733 4756983356 16826 6715193513
> FFF? 2918 4756995171? 3433 6715206906
> GGG? 3726 4756994363? 4038 6715206301
> HHH? 6196 4756991893? 7011 6715203328
> III? 7925 4756990164? 9130 6715201209
> JJJ? 1434 4756996655? 1602 6715208737
> 
> Where the 1st column is the identifier, the 2nd column = observations
> 1, the 3rd column = background counts 1, the 4th column = observations
> 2 and the 5th column = background counts 2.
> 
> I am loading my data as such:
> 
>? ? ? > data=read.table("My.File", header=FALSE)
> 
> And I am looping through each row to perform a test like this:
> 
>? ? ? > pvalues=c("pvalue")
>? ? ? > for(i in 1:10){
>? ? ? + datamatrix=matrix(c(as.integer(data[i,2:5])),nrow=2)
>? ? ? + fisherresult=fisher.test(datamatrix)
>? ? ? + pvalues=cbind(pvalues,fisherresult[1])
>? ? ? + }
> 
> Here is the Error I am Getting:
> 
> Error in fisher.test(datamatrix) :
>?  all entries of 'x' must be nonnegative and finite In addition:
> Warning messages:
> 1: In matrix(c(as.integer(data[i, 2:5])), nrow = 2) :
>?  NAs introduced by coercion
> 2: In matrix(c(as.integer(data[i, 2:5])), nrow = 2) :
>?  NAs introduced by coercion
> 
> 
> When I replace the large number in the 3rd and 5th column with smaller
> numbers, the statistical calculation works fine.
> 
> Any ideas? Any help would be GREATLY appreciated!
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Errors-
> using-large-numbers-i-all-entries-of-x-must-be-nonnegative-and-finite-
> and-ii-NAs-introduced-b-tp4671685.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jul 16 20:10:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 16 Jul 2013 11:10:10 -0700 (PDT)
Subject: [R] (1 - 0.7) == 0.3
Message-ID: <1373998210.85006.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,
2-0.7==0.3
#[1] FALSE
##May be u meant
?2-0.7==1.3
#[1] TRUE


Possibly R FAQ 7.31
Also, check
http://rwiki.sciviews.org/doku.php?id=misc:r_accuracy

all.equal(2-0.7,1.3)
#[1] TRUE
?all.equal(1-0.7,0.3)
#[1] TRUE
(1-0.7)<(0.3+.Machine$double.eps^0.5)
#[1] TRUE



?p <- c(0.2, 0.4, 0.6, 0.8, 1) 
round((1-p)*5,1)+1
#[1] 5 4 3 2 1


In your second example,
?p <- c(0.8, 0.6, 0.4, 0.2, 0)
floor((1 - p) * 5) + 1 
#[1] 1 3 4 5 6? 
((1-0.8)*5) +1
#[1] 2


?round((1-p)*5,1)+1
#[1] 2 3 4 5 6

A.K.

...is false :( However (2 - 0.7) == 0.3 is true. 

Is there any way to get around this? ? 

The end goal is for this to work: 

p <- c(0.2, 0.4, 0.6, 0.8, 1) 
floor((1 - p) * 5) + 1 

> ?5 4 3 1 1 

whereas the correct result would have been 5 4 3 2 1. If I set p <- c(0.8, 0.6, 0.4, 0.2, 0) then it works as expected.


From 538280 at gmail.com  Tue Jul 16 20:10:15 2013
From: 538280 at gmail.com (Greg Snow)
Date: Tue, 16 Jul 2013 12:10:15 -0600
Subject: [R] Question on plotting with googleVis
In-Reply-To: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>
References: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>
Message-ID: <CAFEqCdyJUPUiGqXgxnjWVysc+KcvqePLv8VXRuBB4Z7odvCKxg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/26145b34/attachment.pl>

From ahmedatia80 at gmail.com  Tue Jul 16 20:25:28 2013
From: ahmedatia80 at gmail.com (Ahmed Attia)
Date: Tue, 16 Jul 2013 11:25:28 -0700
Subject: [R] Importing data by odbcConnectExcel in 64 bit
Message-ID: <CAG6S0Ok4SPcqF2ELmNB27aEytNwrZt-HPBc+oyvC0hDW+rEvOw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/ad844e8e/attachment.pl>

From jvadams at usgs.gov  Tue Jul 16 20:44:14 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 16 Jul 2013 13:44:14 -0500
Subject: [R] Importing data by odbcConnectExcel in 64 bit
In-Reply-To: <CAG6S0Ok4SPcqF2ELmNB27aEytNwrZt-HPBc+oyvC0hDW+rEvOw@mail.gmail.com>
References: <CAG6S0Ok4SPcqF2ELmNB27aEytNwrZt-HPBc+oyvC0hDW+rEvOw@mail.gmail.com>
Message-ID: <CAN5YmCEk6YUmY2OwyF3FgFkbUUye9RkCuFBpLNgorExfOxqZwg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/00fbb26e/attachment.pl>

From xidddw at gmail.com  Tue Jul 16 21:43:59 2013
From: xidddw at gmail.com (Rafael Robledo)
Date: Tue, 16 Jul 2013 14:43:59 -0500
Subject: [R] pxR
In-Reply-To: <DUB114-W52B187A4D060964F249F5DF3600@phx.gbl>
References: <DUB114-W52B187A4D060964F249F5DF3600@phx.gbl>
Message-ID: <CA+MEk0uOSsaVdOBz1dmmVA-9KoyMOdh3mLoQ_fiQ5VFLzLaTiQ@mail.gmail.com>

Hola,

creo que la funci?n que buscas es write.px, que te permite guardar un
objeto de tipo 'px' a un archivo.

Por ejemplo:

opx1 <- read.px( system.file( "extdata", "example.px", package = "pxR") )
write.px ( opx1, file = ?opx.px?) # write a copy
opx2 <- read.px (?opx.px?) # read the copy

con el que lees un archivo px y su contenido lo guardas en otro lugar.

Si tienes m?s dudas, puedes revisar el manual del paquete pxR, que
est? en http://cran.r-project.org/web/packages/pxR/pxR.pdf

Recuerda que esta lista de correos es principalmente para personas que
hablan en ingl?s, por lo que si preguntas en ese idioma, habr? m?s
posibilidades de que te respondan.

Saludos :)


2013/7/16 Bel?n Cillero <belen.cillero at hotmail.com>:
> Buenas tardes
> Una vez que he le?do las variables, sexo, edad, estado civil y nacionalidad, ?c?mo genero un px para realizar las distintas consultas?. De momento lo ?nico que he podido hacer con pxR es leer archivos de extensi?n px pero no s? escribirlos.
> Muchas gracias
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



--
Rafael Robledo J.


From tmrsg11 at gmail.com  Tue Jul 16 21:59:19 2013
From: tmrsg11 at gmail.com (C W)
Date: Tue, 16 Jul 2013 15:59:19 -0400
Subject: [R] How to remove attributes from scale() in a matrix?
Message-ID: <CAE2FW2kMPO59zaATJ5Dj5X+MA+f2tEqZN17i3metn8eu2g8-FQ@mail.gmail.com>

Hi list,

I am using scale() to standardize a distribution?  But why does it
give me attributes attached to the data?  I just want a standardized
matrix, that is all.

library(mvtnorm)
> x <- rmvnorm(15, mean=rep(50, 10))
> x
          [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
  [,8]     [,9]
 [1,] 51.17519 52.34341 49.63084 47.99234 51.63113 50.91391 49.36819
49.23901 51.17377
 [2,] 50.57039 49.17210 48.64395 49.03940 49.65761 49.93840 49.94883
50.69044 49.57632
 [3,] 50.64811 50.21503 50.13786 49.15879 48.51550 50.19444 50.23710
50.98040 51.37032
 [4,] 49.22797 49.66445 49.93287 48.63681 50.49457 50.33302 52.29552
49.98424 51.04724
 [5,] 49.72099 50.84510 50.60976 49.60883 53.59509 49.14728 50.23134
49.09141 49.23780
 [6,] 49.49126 50.90938 49.67140 50.08951 49.79854 49.03711 50.26037
50.24975 48.26958
 [7,] 51.12384 47.92778 50.60112 49.01554 49.47515 50.12756 51.65216
49.21998 49.63808
 [8,] 51.45123 50.44037 50.01039 50.27511 49.97658 51.63002 50.37156
50.02685 48.95423
 [9,] 51.16989 50.16200 51.17724 50.71678 50.79565 50.27128 51.05608
49.61165 47.81732
[10,] 49.54263 49.93501 49.71762 49.33378 51.44935 51.53775 50.54346
49.98333 49.59422
[11,] 51.16497 49.82914 49.08821 51.02918 49.67663 49.53498 50.26647
49.48569 50.94504
[12,] 51.16827 50.50244 49.13003 49.00155 50.26457 48.85465 49.11593
50.58031 51.14926
[13,] 48.26216 49.94866 48.62526 49.11995 50.40082 49.25359 48.57677
50.66760 49.44108
[14,] 49.82530 49.17352 50.05588 50.51265 51.04926 50.32474 49.78180
50.48349 49.92431
[15,] 50.55772 49.84691 47.95021 50.24911 49.85335 50.73062 51.48718
51.36693 50.18307
         [,10]
 [1,] 50.13859
 [2,] 51.54920
 [3,] 49.23230
 [4,] 50.92683
 [5,] 50.97708
 [6,] 50.78799
 [7,] 50.53913
 [8,] 49.30832
 [9,] 49.43606
[10,] 49.42060
[11,] 50.21002
[12,] 51.94848
[13,] 49.41352
[14,] 52.24064
[15,] 51.19474
> scale(x, center=TRUE, scale=TRUE)
            [,1]       [,2]         [,3]        [,4]        [,5]
 [,6]        [,7]
 [1,]  0.8890317  2.3390090 -0.040395734 -1.86089754  1.00159470
0.92533476 -0.99715965
 [2,]  0.2452502 -0.9109703 -1.190404546 -0.63771097 -0.66104313
-0.21446975 -0.40514793
 [3,]  0.3279747  0.1578297  0.550427419 -0.49823662 -1.62323564
0.08468695 -0.11121941
 [4,] -1.1837031 -0.4064112  0.311551281 -1.10802250  0.04407804
0.24660932  1.98754311
 [5,] -0.6589074  0.8035298  1.100314901  0.02749734  2.65618150
-1.13883336 -0.11709623
 [6,] -0.9034419  0.8694088  0.006865424  0.58904255 -0.54231158
-1.26755243 -0.08749646
 [7,]  0.8343705 -2.1861602  1.090250934 -0.66558751 -0.81476108
0.00655050  1.33157578
 [8,]  1.1828615  0.3887665  0.401888014  0.80585326 -0.39231482
1.76205433  0.02587038
 [9,]  0.8833860  0.1034854  1.761589113  1.32181395  0.29773018
0.17447101  0.72381232
[10,] -0.8487569 -0.1291363  0.060728488 -0.29381647  0.84844800
1.65423826  0.20113824
[11,]  0.8781560 -0.2376361 -0.672712386  1.68676651 -0.64501776
-0.68583461 -0.08127647
[12,]  0.8816611  0.4523675 -0.623990804 -0.68193230 -0.14968994
-1.48074503 -1.25436403
[13,] -2.2117715 -0.1151423 -1.212190165 -0.54361597 -0.03490809
-1.01461386 -1.80409304
[14,] -0.5478718 -0.9095198  0.454889973  1.08335795  0.51138447
0.23693367 -0.57544865
[15,]  0.2317608 -0.2194204 -1.998811911  0.77548830 -0.49613484
0.71117025  1.16336204
            [,8]        [,9]       [,10]
 [1,] -1.2666791  1.17934107 -0.35061189
 [2,]  0.8423439 -0.28600703  1.06389274
 [3,]  1.2636749  1.35963155 -1.25940610
 [4,] -0.1838111  1.06327078  0.43980595
 [5,] -1.4811512 -0.59653247  0.49019839
 [6,]  0.2019965 -1.48467432  0.30058779
 [7,] -1.2943281 -0.22935616  0.05103467
 [8,] -0.1218950 -0.85664924 -1.18316969
 [9,] -0.7252082 -1.89953387 -1.05507780
[10,] -0.1851315 -0.26958168 -1.07058564
[11,] -0.9082374  0.96952049 -0.27897948
[12,]  0.6823136  1.15685832  1.46428187
[13,]  0.8091562 -0.41005981 -1.07768018
[14,]  0.5416286  0.03320871  1.75724879
[15,]  1.8253278  0.27056365  0.70846058
attr(,"scaled:center")
 [1] 50.33999 50.06102 49.66551 49.58529 50.44225 50.12196 50.34618
50.11074 49.88811
[10] 50.48823
attr(,"scaled:scale")
 [1] 0.9394453 0.9757930 0.8581604 0.8560117 1.1869812 0.8558562
0.9807762 0.6882016
 [9] 1.0901550 0.9972455


Also,
> attributes(x) <- NULL
will not work since this is matrix not vector.

Thanks,
Mike


From smartpink111 at yahoo.com  Tue Jul 16 22:07:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 16 Jul 2013 13:07:22 -0700 (PDT)
Subject: [R] How to remove attributes from scale() in a matrix?
In-Reply-To: <CAE2FW2kMPO59zaATJ5Dj5X+MA+f2tEqZN17i3metn8eu2g8-FQ@mail.gmail.com>
References: <CAE2FW2kMPO59zaATJ5Dj5X+MA+f2tEqZN17i3metn8eu2g8-FQ@mail.gmail.com>
Message-ID: <1374005242.62939.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
Try:
x1<-scale(x,center=TRUE,scale=TRUE)
str(x1)
# num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
# - attr(*, "scaled:center")= num [1:10] 50.2 50 49.8 49.8 50.3 ...
?#- attr(*, "scaled:scale")= num [1:10] 1.109 0.956 0.817 0.746 1.019 ...

?attr(x1,"scaled:center")<-NULL
?attr(x1,"scaled:scale")<-NULL
str(x1)
?#num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
A.K.




----- Original Message -----
From: C W <tmrsg11 at gmail.com>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 16, 2013 3:59 PM
Subject: [R] How to remove attributes from scale() in a matrix?

Hi list,

I am using scale() to standardize a distribution?? But why does it
give me attributes attached to the data?? I just want a standardized
matrix, that is all.

library(mvtnorm)
> x <- rmvnorm(15, mean=rep(50, 10))
> x
? ? ? ? ? [,1]? ?  [,2]? ?  [,3]? ?  [,4]? ?  [,5]? ?  [,6]? ?  [,7]
? [,8]? ?  [,9]
[1,] 51.17519 52.34341 49.63084 47.99234 51.63113 50.91391 49.36819
49.23901 51.17377
[2,] 50.57039 49.17210 48.64395 49.03940 49.65761 49.93840 49.94883
50.69044 49.57632
[3,] 50.64811 50.21503 50.13786 49.15879 48.51550 50.19444 50.23710
50.98040 51.37032
[4,] 49.22797 49.66445 49.93287 48.63681 50.49457 50.33302 52.29552
49.98424 51.04724
[5,] 49.72099 50.84510 50.60976 49.60883 53.59509 49.14728 50.23134
49.09141 49.23780
[6,] 49.49126 50.90938 49.67140 50.08951 49.79854 49.03711 50.26037
50.24975 48.26958
[7,] 51.12384 47.92778 50.60112 49.01554 49.47515 50.12756 51.65216
49.21998 49.63808
[8,] 51.45123 50.44037 50.01039 50.27511 49.97658 51.63002 50.37156
50.02685 48.95423
[9,] 51.16989 50.16200 51.17724 50.71678 50.79565 50.27128 51.05608
49.61165 47.81732
[10,] 49.54263 49.93501 49.71762 49.33378 51.44935 51.53775 50.54346
49.98333 49.59422
[11,] 51.16497 49.82914 49.08821 51.02918 49.67663 49.53498 50.26647
49.48569 50.94504
[12,] 51.16827 50.50244 49.13003 49.00155 50.26457 48.85465 49.11593
50.58031 51.14926
[13,] 48.26216 49.94866 48.62526 49.11995 50.40082 49.25359 48.57677
50.66760 49.44108
[14,] 49.82530 49.17352 50.05588 50.51265 51.04926 50.32474 49.78180
50.48349 49.92431
[15,] 50.55772 49.84691 47.95021 50.24911 49.85335 50.73062 51.48718
51.36693 50.18307
? ? ? ?  [,10]
[1,] 50.13859
[2,] 51.54920
[3,] 49.23230
[4,] 50.92683
[5,] 50.97708
[6,] 50.78799
[7,] 50.53913
[8,] 49.30832
[9,] 49.43606
[10,] 49.42060
[11,] 50.21002
[12,] 51.94848
[13,] 49.41352
[14,] 52.24064
[15,] 51.19474
> scale(x, center=TRUE, scale=TRUE)
? ? ? ? ? ? [,1]? ? ?  [,2]? ? ? ?  [,3]? ? ? ? [,4]? ? ? ? [,5]
[,6]? ? ? ? [,7]
[1,]? 0.8890317? 2.3390090 -0.040395734 -1.86089754? 1.00159470
0.92533476 -0.99715965
[2,]? 0.2452502 -0.9109703 -1.190404546 -0.63771097 -0.66104313
-0.21446975 -0.40514793
[3,]? 0.3279747? 0.1578297? 0.550427419 -0.49823662 -1.62323564
0.08468695 -0.11121941
[4,] -1.1837031 -0.4064112? 0.311551281 -1.10802250? 0.04407804
0.24660932? 1.98754311
[5,] -0.6589074? 0.8035298? 1.100314901? 0.02749734? 2.65618150
-1.13883336 -0.11709623
[6,] -0.9034419? 0.8694088? 0.006865424? 0.58904255 -0.54231158
-1.26755243 -0.08749646
[7,]? 0.8343705 -2.1861602? 1.090250934 -0.66558751 -0.81476108
0.00655050? 1.33157578
[8,]? 1.1828615? 0.3887665? 0.401888014? 0.80585326 -0.39231482
1.76205433? 0.02587038
[9,]? 0.8833860? 0.1034854? 1.761589113? 1.32181395? 0.29773018
0.17447101? 0.72381232
[10,] -0.8487569 -0.1291363? 0.060728488 -0.29381647? 0.84844800
1.65423826? 0.20113824
[11,]? 0.8781560 -0.2376361 -0.672712386? 1.68676651 -0.64501776
-0.68583461 -0.08127647
[12,]? 0.8816611? 0.4523675 -0.623990804 -0.68193230 -0.14968994
-1.48074503 -1.25436403
[13,] -2.2117715 -0.1151423 -1.212190165 -0.54361597 -0.03490809
-1.01461386 -1.80409304
[14,] -0.5478718 -0.9095198? 0.454889973? 1.08335795? 0.51138447
0.23693367 -0.57544865
[15,]? 0.2317608 -0.2194204 -1.998811911? 0.77548830 -0.49613484
0.71117025? 1.16336204
? ? ? ? ? ? [,8]? ? ? ? [,9]? ? ?  [,10]
[1,] -1.2666791? 1.17934107 -0.35061189
[2,]? 0.8423439 -0.28600703? 1.06389274
[3,]? 1.2636749? 1.35963155 -1.25940610
[4,] -0.1838111? 1.06327078? 0.43980595
[5,] -1.4811512 -0.59653247? 0.49019839
[6,]? 0.2019965 -1.48467432? 0.30058779
[7,] -1.2943281 -0.22935616? 0.05103467
[8,] -0.1218950 -0.85664924 -1.18316969
[9,] -0.7252082 -1.89953387 -1.05507780
[10,] -0.1851315 -0.26958168 -1.07058564
[11,] -0.9082374? 0.96952049 -0.27897948
[12,]? 0.6823136? 1.15685832? 1.46428187
[13,]? 0.8091562 -0.41005981 -1.07768018
[14,]? 0.5416286? 0.03320871? 1.75724879
[15,]? 1.8253278? 0.27056365? 0.70846058
attr(,"scaled:center")
[1] 50.33999 50.06102 49.66551 49.58529 50.44225 50.12196 50.34618
50.11074 49.88811
[10] 50.48823
attr(,"scaled:scale")
[1] 0.9394453 0.9757930 0.8581604 0.8560117 1.1869812 0.8558562
0.9807762 0.6882016
[9] 1.0901550 0.9972455


Also,
> attributes(x) <- NULL
will not work since this is matrix not vector.

Thanks,
Mike

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Peter.Alspach at plantandfood.co.nz  Tue Jul 16 22:35:38 2013
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Wed, 17 Jul 2013 08:35:38 +1200
Subject: [R] Importing data by odbcConnectExcel in 64 bit
In-Reply-To: <CAG6S0Ok4SPcqF2ELmNB27aEytNwrZt-HPBc+oyvC0hDW+rEvOw@mail.gmail.com>
References: <CAG6S0Ok4SPcqF2ELmNB27aEytNwrZt-HPBc+oyvC0hDW+rEvOw@mail.gmail.com>
Message-ID: <3CD374BF2C285940A54C0A71225AF7DB03576781AC@AKLEXM01.PFR.CO.NZ>

Tena koe

Perhaps the help file will give you some ideas:

"odbcConnectAccess, odbcConnectDbase and odbcConnectExcel are convenience wrappers to generate connection strings for those file types. The files given can be relative to the R working directory or absolute paths (and it seems also relative to the user's home directory). The file name can be omitted, which will on Rgui bring up a dialog box to search for a file.

Note: they will only work with English-language 32-bit versions of the Microsoft drivers, which may or may not be installed in other locales, and are not usable from 64-bit R. The 2007 versions work with the drivers which are installed with Office 2007/2010 and give access to formats such as '*.xlsx' and '*.accdb'. These drivers are also available separately and there is a 64-bit version: see the package manual. (You must have the 32-bit drivers when using 32-bit R and the 64-bit drivers when using 64-bit R: otherwise there will be a cryptic message about a driver not being found. And the 64-bit drivers cannot be installed alongside 32-bit Microsoft Office, and vice versa.

See the package manual for some of the peculiarities of the Excel drivers. readOnly = TRUE may allow very limited changes (to insert and update rows)."

HTH ....

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ahmed Attia
Sent: Wednesday, 17 July 2013 6:25 a.m.
To: r-help at r-project.org
Subject: [R] Importing data by odbcConnectExcel in 64 bit

I have probably an old question.

I have R.3.0.1 installed in 64 bit windows 7. The odbcConnectExcel in RODBC library does not work. Tried odbcConnectExcel2007 still does not work.


Any ideas.

Thanks

Melissa<-sqlFetch(odbcConnectExcel2007("F:\\Cotton2012\\validation.xlsx"),sqtable
= "Sheet3",
+                     na.strings = "NA", as.is = TRUE)
Error in sqlFetch(odbcConnectExcel2007("F:\\Cotton2012\\validation.xlsx"),
 :
  first argument is not an open RODBC channel In addition: Warning messages:
1: In odbcDriverConnect(con, tabQuote = c("[", "]"), ...) :
  [RODBC] ERROR: state IM002, code 0, message [Microsoft][ODBC Driver Manager] Data source name not found and no default driver specified
2: In odbcDriverConnect(con, tabQuote = c("[", "]"), ...) :
  ODBC connection failed
>
Melissa<-sqlFetch(odbcConnectExcel("F:\\Cotton2012\\validation.xlsx"),sqtable
= "Sheet3",
+                     na.strings = "NA", as.is = TRUE)
Error in odbcConnectExcel("F:\\Cotton2012\\validation.xlsx") :
  odbcConnectExcel is only usable with 32-bit Windows

--
Ahmed M. Attia


Research Assistant
Dept. Of Soil&Crop Sciences
Texas A&M University
ahmed <ahmedatia at zu.edu.eg>.attia at ag.tamu.edu
Cell phone: 001-979-248-5215

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The contents of this e-mail are confidential and may be ...{{dropped:14}}


From teotjunk at gmail.com  Tue Jul 16 22:59:38 2013
From: teotjunk at gmail.com (Tjun Kiat Teo)
Date: Wed, 17 Jul 2013 04:59:38 +0800
Subject: [R] Fitting Mixture distributions
Message-ID: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/571aef4a/attachment.pl>

From ruipbarradas at sapo.pt  Tue Jul 16 23:26:44 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 16 Jul 2013 22:26:44 +0100
Subject: [R] Fitting Mixture distributions
In-Reply-To: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
Message-ID: <51E5BA94.6090605@sapo.pt>

Hello,

Try the following.


library(sos)
findFn('fitting mixture distribution')


It found several other packages.

Hope this helps,

Rui Barradas

Em 16-07-2013 21:59, Tjun Kiat Teo escreveu:
> I was trying to use the normixEM in mixtools and I got this error message.
>
> And I got this error message
>
> One of the variances is going to zero;  trying new starting values.
> Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too many tries!
>
> Are there any other packages for fitting mixture distributions  ?
>
>
> Tjun Kiat Teo
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From szehnder at uni-bonn.de  Tue Jul 16 23:53:09 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 16 Jul 2013 23:53:09 +0200
Subject: [R] Fitting Mixture distributions
In-Reply-To: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
References: <CAH=5_TUs8bbKXJcBFjYypbFL+i+9_u8BN0Zk-icgN3Ly=24Zcg@mail.gmail.com>
Message-ID: <E574747D-1081-4194-92B9-2057FBE43D02@uni-bonn.de>

Hi Tjun Kiat Teo,

you try to fit a Normal mixture to some data. The Normal mixture is very delicate when it comes to parameter search: If the variance gets closer and closer to zero, the log Likelihood becomes larger and larger for any values of the remaining parameters. Furthermore for the EM algorithm it is known, that it takes sometimes very long until convergence is reached. 

Try the following: 

Use as starting values for the component parameters:

start.par <- mean(your.data, na.rm = TRUE) + sd(your.data, na.rm = TRUE) * runif(K)

For the weights just use either 1/K or the R cluster function with K clusters

Here K is the number of components. Further enlarge the maximum number of iterations. What you could also try is to randomize start parameters and run an SEM (Stochastic EM). In my opinion the better method is in this case a Bayesian method: MCMC.


Best

Simon


On Jul 16, 2013, at 10:59 PM, Tjun Kiat Teo <teotjunk at gmail.com> wrote:

> I was trying to use the normixEM in mixtools and I got this error message.
> 
> And I got this error message
> 
> One of the variances is going to zero;  trying new starting values.
> Error in normalmixEM(as.matrix(temp[[gc]][, -(f + 1)])) : Too many tries!
> 
> Are there any other packages for fitting mixture distributions  ?
> 
> 
> Tjun Kiat Teo
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Wed Jul 17 00:58:00 2013
From: tmrsg11 at gmail.com (C W)
Date: Tue, 16 Jul 2013 18:58:00 -0400
Subject: [R] How to remove attributes from scale() in a matrix?
In-Reply-To: <1374005242.62939.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAE2FW2kMPO59zaATJ5Dj5X+MA+f2tEqZN17i3metn8eu2g8-FQ@mail.gmail.com>
	<1374005242.62939.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CAE2FW2kY-p590RwxReLooskZVR-FFMNWoZJPG+BnJe0rtSo7uA@mail.gmail.com>

Arun, thanks for the quick response.  That helps.

Why does scale() give attributes?  What's the point of that?  I don't
see apply() or any similar functions do it.  Just for my curiosity.

Mike

On Tue, Jul 16, 2013 at 4:07 PM, arun <smartpink111 at yahoo.com> wrote:
> HI,
> Try:
> x1<-scale(x,center=TRUE,scale=TRUE)
> str(x1)
> # num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
> # - attr(*, "scaled:center")= num [1:10] 50.2 50 49.8 49.8 50.3 ...
>  #- attr(*, "scaled:scale")= num [1:10] 1.109 0.956 0.817 0.746 1.019 ...
>
>  attr(x1,"scaled:center")<-NULL
>  attr(x1,"scaled:scale")<-NULL
> str(x1)
>  #num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
> A.K.
>
>
>
>
> ----- Original Message -----
> From: C W <tmrsg11 at gmail.com>
> To: r-help <r-help at r-project.org>
> Cc:
> Sent: Tuesday, July 16, 2013 3:59 PM
> Subject: [R] How to remove attributes from scale() in a matrix?
>
> Hi list,
>
> I am using scale() to standardize a distribution?  But why does it
> give me attributes attached to the data?  I just want a standardized
> matrix, that is all.
>
> library(mvtnorm)
>> x <- rmvnorm(15, mean=rep(50, 10))
>> x
>           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
>   [,8]     [,9]
> [1,] 51.17519 52.34341 49.63084 47.99234 51.63113 50.91391 49.36819
> 49.23901 51.17377
> [2,] 50.57039 49.17210 48.64395 49.03940 49.65761 49.93840 49.94883
> 50.69044 49.57632
> [3,] 50.64811 50.21503 50.13786 49.15879 48.51550 50.19444 50.23710
> 50.98040 51.37032
> [4,] 49.22797 49.66445 49.93287 48.63681 50.49457 50.33302 52.29552
> 49.98424 51.04724
> [5,] 49.72099 50.84510 50.60976 49.60883 53.59509 49.14728 50.23134
> 49.09141 49.23780
> [6,] 49.49126 50.90938 49.67140 50.08951 49.79854 49.03711 50.26037
> 50.24975 48.26958
> [7,] 51.12384 47.92778 50.60112 49.01554 49.47515 50.12756 51.65216
> 49.21998 49.63808
> [8,] 51.45123 50.44037 50.01039 50.27511 49.97658 51.63002 50.37156
> 50.02685 48.95423
> [9,] 51.16989 50.16200 51.17724 50.71678 50.79565 50.27128 51.05608
> 49.61165 47.81732
> [10,] 49.54263 49.93501 49.71762 49.33378 51.44935 51.53775 50.54346
> 49.98333 49.59422
> [11,] 51.16497 49.82914 49.08821 51.02918 49.67663 49.53498 50.26647
> 49.48569 50.94504
> [12,] 51.16827 50.50244 49.13003 49.00155 50.26457 48.85465 49.11593
> 50.58031 51.14926
> [13,] 48.26216 49.94866 48.62526 49.11995 50.40082 49.25359 48.57677
> 50.66760 49.44108
> [14,] 49.82530 49.17352 50.05588 50.51265 51.04926 50.32474 49.78180
> 50.48349 49.92431
> [15,] 50.55772 49.84691 47.95021 50.24911 49.85335 50.73062 51.48718
> 51.36693 50.18307
>          [,10]
> [1,] 50.13859
> [2,] 51.54920
> [3,] 49.23230
> [4,] 50.92683
> [5,] 50.97708
> [6,] 50.78799
> [7,] 50.53913
> [8,] 49.30832
> [9,] 49.43606
> [10,] 49.42060
> [11,] 50.21002
> [12,] 51.94848
> [13,] 49.41352
> [14,] 52.24064
> [15,] 51.19474
>> scale(x, center=TRUE, scale=TRUE)
>             [,1]       [,2]         [,3]        [,4]        [,5]
> [,6]        [,7]
> [1,]  0.8890317  2.3390090 -0.040395734 -1.86089754  1.00159470
> 0.92533476 -0.99715965
> [2,]  0.2452502 -0.9109703 -1.190404546 -0.63771097 -0.66104313
> -0.21446975 -0.40514793
> [3,]  0.3279747  0.1578297  0.550427419 -0.49823662 -1.62323564
> 0.08468695 -0.11121941
> [4,] -1.1837031 -0.4064112  0.311551281 -1.10802250  0.04407804
> 0.24660932  1.98754311
> [5,] -0.6589074  0.8035298  1.100314901  0.02749734  2.65618150
> -1.13883336 -0.11709623
> [6,] -0.9034419  0.8694088  0.006865424  0.58904255 -0.54231158
> -1.26755243 -0.08749646
> [7,]  0.8343705 -2.1861602  1.090250934 -0.66558751 -0.81476108
> 0.00655050  1.33157578
> [8,]  1.1828615  0.3887665  0.401888014  0.80585326 -0.39231482
> 1.76205433  0.02587038
> [9,]  0.8833860  0.1034854  1.761589113  1.32181395  0.29773018
> 0.17447101  0.72381232
> [10,] -0.8487569 -0.1291363  0.060728488 -0.29381647  0.84844800
> 1.65423826  0.20113824
> [11,]  0.8781560 -0.2376361 -0.672712386  1.68676651 -0.64501776
> -0.68583461 -0.08127647
> [12,]  0.8816611  0.4523675 -0.623990804 -0.68193230 -0.14968994
> -1.48074503 -1.25436403
> [13,] -2.2117715 -0.1151423 -1.212190165 -0.54361597 -0.03490809
> -1.01461386 -1.80409304
> [14,] -0.5478718 -0.9095198  0.454889973  1.08335795  0.51138447
> 0.23693367 -0.57544865
> [15,]  0.2317608 -0.2194204 -1.998811911  0.77548830 -0.49613484
> 0.71117025  1.16336204
>             [,8]        [,9]       [,10]
> [1,] -1.2666791  1.17934107 -0.35061189
> [2,]  0.8423439 -0.28600703  1.06389274
> [3,]  1.2636749  1.35963155 -1.25940610
> [4,] -0.1838111  1.06327078  0.43980595
> [5,] -1.4811512 -0.59653247  0.49019839
> [6,]  0.2019965 -1.48467432  0.30058779
> [7,] -1.2943281 -0.22935616  0.05103467
> [8,] -0.1218950 -0.85664924 -1.18316969
> [9,] -0.7252082 -1.89953387 -1.05507780
> [10,] -0.1851315 -0.26958168 -1.07058564
> [11,] -0.9082374  0.96952049 -0.27897948
> [12,]  0.6823136  1.15685832  1.46428187
> [13,]  0.8091562 -0.41005981 -1.07768018
> [14,]  0.5416286  0.03320871  1.75724879
> [15,]  1.8253278  0.27056365  0.70846058
> attr(,"scaled:center")
> [1] 50.33999 50.06102 49.66551 49.58529 50.44225 50.12196 50.34618
> 50.11074 49.88811
> [10] 50.48823
> attr(,"scaled:scale")
> [1] 0.9394453 0.9757930 0.8581604 0.8560117 1.1869812 0.8558562
> 0.9807762 0.6882016
> [9] 1.0901550 0.9972455
>
>
> Also,
>> attributes(x) <- NULL
> will not work since this is matrix not vector.
>
> Thanks,
> Mike
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Wed Jul 17 01:08:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 16 Jul 2013 16:08:44 -0700 (PDT)
Subject: [R] How to remove attributes from scale() in a matrix?
In-Reply-To: <CAE2FW2kY-p590RwxReLooskZVR-FFMNWoZJPG+BnJe0rtSo7uA@mail.gmail.com>
References: <CAE2FW2kMPO59zaATJ5Dj5X+MA+f2tEqZN17i3metn8eu2g8-FQ@mail.gmail.com>
	<1374005242.62939.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAE2FW2kY-p590RwxReLooskZVR-FFMNWoZJPG+BnJe0rtSo7uA@mail.gmail.com>
Message-ID: <1374016124.47327.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi Mike,
If you check ?scale

For ?scale.default?, the centered, scaled matrix.? The numeric
???? centering and scalings used (if any) are returned as attributes
???? ?"scaled:center"? and ?"scaled:scale"?

By checking the source code:
methods(scale)

getAnywhere('scale.default')

function (x, center = TRUE, scale = TRUE) 
{
??? x <- as.matrix(x)
??? nc <- ncol(x)
??? if (is.logical(center)) {
??????? if (center) {
??????????? center <- colMeans(x, na.rm = TRUE)
??????????? x <- sweep(x, 2L, center, check.margin = FALSE)
??????? }
??? }
??? else if (is.numeric(center) && (length(center) == nc)) 
??????? x <- sweep(x, 2L, center, check.margin = FALSE)
??? else stop("length of 'center' must equal the number of columns of 'x'")
??? if (is.logical(scale)) {
??????? if (scale) {
??????????? f <- function(v) {
??????????????? v <- v[!is.na(v)]
??????????????? sqrt(sum(v^2)/max(1, length(v) - 1L))
??????????? }
??????????? scale <- apply(x, 2L, f)
??????????? x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
??????? }
??? }
??? else if (is.numeric(scale) && length(scale) == nc) 
??????? x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
??? else stop("length of 'scale' must equal the number of columns of 'x'")
??? if (is.numeric(center)) 
??????? attr(x, "scaled:center") <- center
??? if (is.numeric(scale)) 
??????? attr(x, "scaled:scale") <- scale
??? x
}

#You can comment out the last few lines:

scale1<- function (x, center = TRUE, scale = TRUE) 
{
??? x <- as.matrix(x)
??? nc <- ncol(x)
??? if (is.logical(center)) {
??????? if (center) {
??????????? center <- colMeans(x, na.rm = TRUE)
??????????? x <- sweep(x, 2L, center, check.margin = FALSE)
??????? }
??? }
??? else if (is.numeric(center) && (length(center) == nc)) 
??????? x <- sweep(x, 2L, center, check.margin = FALSE)
??? else stop("length of 'center' must equal the number of columns of 'x'")
??? if (is.logical(scale)) {
??????? if (scale) {
??????????? f <- function(v) {
??????????????? v <- v[!is.na(v)]
??????????????? sqrt(sum(v^2)/max(1, length(v) - 1L))
??????????? }
??????????? scale <- apply(x, 2L, f)
??????????? x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
??????? }
??? }
??? else if (is.numeric(scale) && length(scale) == nc) 
??????? x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
??? else stop("length of 'scale' must equal the number of columns of 'x'")
??? #if (is.numeric(center)) 
??? #??? attr(x, "scaled:center") <- center
??? #if (is.numeric(scale)) 
??? #??? attr(x, "scaled:scale") <- scale
??? x
}
?x2<-scale1(x,center=TRUE,scale=TRUE)
?str(x2)
# num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...

identical(x1,x2)
#[1] TRUE
A.K.



----- Original Message -----
From: C W <tmrsg11 at gmail.com>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, July 16, 2013 6:58 PM
Subject: Re: [R] How to remove attributes from scale() in a matrix?

Arun, thanks for the quick response.? That helps.

Why does scale() give attributes?? What's the point of that?? I don't
see apply() or any similar functions do it.? Just for my curiosity.

Mike

On Tue, Jul 16, 2013 at 4:07 PM, arun <smartpink111 at yahoo.com> wrote:
> HI,
> Try:
> x1<-scale(x,center=TRUE,scale=TRUE)
> str(x1)
> # num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
> # - attr(*, "scaled:center")= num [1:10] 50.2 50 49.8 49.8 50.3 ...
>? #- attr(*, "scaled:scale")= num [1:10] 1.109 0.956 0.817 0.746 1.019 ...
>
>? attr(x1,"scaled:center")<-NULL
>? attr(x1,"scaled:scale")<-NULL
> str(x1)
>? #num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
> A.K.
>
>
>
>
> ----- Original Message -----
> From: C W <tmrsg11 at gmail.com>
> To: r-help <r-help at r-project.org>
> Cc:
> Sent: Tuesday, July 16, 2013 3:59 PM
> Subject: [R] How to remove attributes from scale() in a matrix?
>
> Hi list,
>
> I am using scale() to standardize a distribution?? But why does it
> give me attributes attached to the data?? I just want a standardized
> matrix, that is all.
>
> library(mvtnorm)
>> x <- rmvnorm(15, mean=rep(50, 10))
>> x
>? ? ? ? ?  [,1]? ?  [,2]? ?  [,3]? ?  [,4]? ?  [,5]? ?  [,6]? ?  [,7]
>?  [,8]? ?  [,9]
> [1,] 51.17519 52.34341 49.63084 47.99234 51.63113 50.91391 49.36819
> 49.23901 51.17377
> [2,] 50.57039 49.17210 48.64395 49.03940 49.65761 49.93840 49.94883
> 50.69044 49.57632
> [3,] 50.64811 50.21503 50.13786 49.15879 48.51550 50.19444 50.23710
> 50.98040 51.37032
> [4,] 49.22797 49.66445 49.93287 48.63681 50.49457 50.33302 52.29552
> 49.98424 51.04724
> [5,] 49.72099 50.84510 50.60976 49.60883 53.59509 49.14728 50.23134
> 49.09141 49.23780
> [6,] 49.49126 50.90938 49.67140 50.08951 49.79854 49.03711 50.26037
> 50.24975 48.26958
> [7,] 51.12384 47.92778 50.60112 49.01554 49.47515 50.12756 51.65216
> 49.21998 49.63808
> [8,] 51.45123 50.44037 50.01039 50.27511 49.97658 51.63002 50.37156
> 50.02685 48.95423
> [9,] 51.16989 50.16200 51.17724 50.71678 50.79565 50.27128 51.05608
> 49.61165 47.81732
> [10,] 49.54263 49.93501 49.71762 49.33378 51.44935 51.53775 50.54346
> 49.98333 49.59422
> [11,] 51.16497 49.82914 49.08821 51.02918 49.67663 49.53498 50.26647
> 49.48569 50.94504
> [12,] 51.16827 50.50244 49.13003 49.00155 50.26457 48.85465 49.11593
> 50.58031 51.14926
> [13,] 48.26216 49.94866 48.62526 49.11995 50.40082 49.25359 48.57677
> 50.66760 49.44108
> [14,] 49.82530 49.17352 50.05588 50.51265 51.04926 50.32474 49.78180
> 50.48349 49.92431
> [15,] 50.55772 49.84691 47.95021 50.24911 49.85335 50.73062 51.48718
> 51.36693 50.18307
>? ? ? ? ? [,10]
> [1,] 50.13859
> [2,] 51.54920
> [3,] 49.23230
> [4,] 50.92683
> [5,] 50.97708
> [6,] 50.78799
> [7,] 50.53913
> [8,] 49.30832
> [9,] 49.43606
> [10,] 49.42060
> [11,] 50.21002
> [12,] 51.94848
> [13,] 49.41352
> [14,] 52.24064
> [15,] 51.19474
>> scale(x, center=TRUE, scale=TRUE)
>? ? ? ? ? ?  [,1]? ? ?  [,2]? ? ? ?  [,3]? ? ? ? [,4]? ? ? ? [,5]
> [,6]? ? ? ? [,7]
> [1,]? 0.8890317? 2.3390090 -0.040395734 -1.86089754? 1.00159470
> 0.92533476 -0.99715965
> [2,]? 0.2452502 -0.9109703 -1.190404546 -0.63771097 -0.66104313
> -0.21446975 -0.40514793
> [3,]? 0.3279747? 0.1578297? 0.550427419 -0.49823662 -1.62323564
> 0.08468695 -0.11121941
> [4,] -1.1837031 -0.4064112? 0.311551281 -1.10802250? 0.04407804
> 0.24660932? 1.98754311
> [5,] -0.6589074? 0.8035298? 1.100314901? 0.02749734? 2.65618150
> -1.13883336 -0.11709623
> [6,] -0.9034419? 0.8694088? 0.006865424? 0.58904255 -0.54231158
> -1.26755243 -0.08749646
> [7,]? 0.8343705 -2.1861602? 1.090250934 -0.66558751 -0.81476108
> 0.00655050? 1.33157578
> [8,]? 1.1828615? 0.3887665? 0.401888014? 0.80585326 -0.39231482
> 1.76205433? 0.02587038
> [9,]? 0.8833860? 0.1034854? 1.761589113? 1.32181395? 0.29773018
> 0.17447101? 0.72381232
> [10,] -0.8487569 -0.1291363? 0.060728488 -0.29381647? 0.84844800
> 1.65423826? 0.20113824
> [11,]? 0.8781560 -0.2376361 -0.672712386? 1.68676651 -0.64501776
> -0.68583461 -0.08127647
> [12,]? 0.8816611? 0.4523675 -0.623990804 -0.68193230 -0.14968994
> -1.48074503 -1.25436403
> [13,] -2.2117715 -0.1151423 -1.212190165 -0.54361597 -0.03490809
> -1.01461386 -1.80409304
> [14,] -0.5478718 -0.9095198? 0.454889973? 1.08335795? 0.51138447
> 0.23693367 -0.57544865
> [15,]? 0.2317608 -0.2194204 -1.998811911? 0.77548830 -0.49613484
> 0.71117025? 1.16336204
>? ? ? ? ? ?  [,8]? ? ? ? [,9]? ? ?  [,10]
> [1,] -1.2666791? 1.17934107 -0.35061189
> [2,]? 0.8423439 -0.28600703? 1.06389274
> [3,]? 1.2636749? 1.35963155 -1.25940610
> [4,] -0.1838111? 1.06327078? 0.43980595
> [5,] -1.4811512 -0.59653247? 0.49019839
> [6,]? 0.2019965 -1.48467432? 0.30058779
> [7,] -1.2943281 -0.22935616? 0.05103467
> [8,] -0.1218950 -0.85664924 -1.18316969
> [9,] -0.7252082 -1.89953387 -1.05507780
> [10,] -0.1851315 -0.26958168 -1.07058564
> [11,] -0.9082374? 0.96952049 -0.27897948
> [12,]? 0.6823136? 1.15685832? 1.46428187
> [13,]? 0.8091562 -0.41005981 -1.07768018
> [14,]? 0.5416286? 0.03320871? 1.75724879
> [15,]? 1.8253278? 0.27056365? 0.70846058
> attr(,"scaled:center")
> [1] 50.33999 50.06102 49.66551 49.58529 50.44225 50.12196 50.34618
> 50.11074 49.88811
> [10] 50.48823
> attr(,"scaled:scale")
> [1] 0.9394453 0.9757930 0.8581604 0.8560117 1.1869812 0.8558562
> 0.9807762 0.6882016
> [9] 1.0901550 0.9972455
>
>
> Also,
>> attributes(x) <- NULL
> will not work since this is matrix not vector.
>
> Thanks,
> Mike
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From tmrsg11 at gmail.com  Wed Jul 17 01:17:21 2013
From: tmrsg11 at gmail.com (C W)
Date: Tue, 16 Jul 2013 19:17:21 -0400
Subject: [R] How to remove attributes from scale() in a matrix?
In-Reply-To: <1374016124.47327.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAE2FW2kMPO59zaATJ5Dj5X+MA+f2tEqZN17i3metn8eu2g8-FQ@mail.gmail.com>
	<1374005242.62939.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAE2FW2kY-p590RwxReLooskZVR-FFMNWoZJPG+BnJe0rtSo7uA@mail.gmail.com>
	<1374016124.47327.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAE2FW2=qjgFwc07ktftC-jbgKoVf7EA3UjeEEDmCz7ik7um2cA@mail.gmail.com>

Thanks, very clear!

On Tue, Jul 16, 2013 at 7:08 PM, arun <smartpink111 at yahoo.com> wrote:
> Hi Mike,
> If you check ?scale
>
> For ?scale.default?, the centered, scaled matrix.  The numeric
>      centering and scalings used (if any) are returned as attributes
>      ?"scaled:center"? and ?"scaled:scale"?
>
> By checking the source code:
> methods(scale)
>
> getAnywhere('scale.default')
>
> function (x, center = TRUE, scale = TRUE)
> {
>     x <- as.matrix(x)
>     nc <- ncol(x)
>     if (is.logical(center)) {
>         if (center) {
>             center <- colMeans(x, na.rm = TRUE)
>             x <- sweep(x, 2L, center, check.margin = FALSE)
>         }
>     }
>     else if (is.numeric(center) && (length(center) == nc))
>         x <- sweep(x, 2L, center, check.margin = FALSE)
>     else stop("length of 'center' must equal the number of columns of 'x'")
>     if (is.logical(scale)) {
>         if (scale) {
>             f <- function(v) {
>                 v <- v[!is.na(v)]
>                 sqrt(sum(v^2)/max(1, length(v) - 1L))
>             }
>             scale <- apply(x, 2L, f)
>             x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
>         }
>     }
>     else if (is.numeric(scale) && length(scale) == nc)
>         x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
>     else stop("length of 'scale' must equal the number of columns of 'x'")
>     if (is.numeric(center))
>         attr(x, "scaled:center") <- center
>     if (is.numeric(scale))
>         attr(x, "scaled:scale") <- scale
>     x
> }
>
> #You can comment out the last few lines:
>
> scale1<- function (x, center = TRUE, scale = TRUE)
> {
>     x <- as.matrix(x)
>     nc <- ncol(x)
>     if (is.logical(center)) {
>         if (center) {
>             center <- colMeans(x, na.rm = TRUE)
>             x <- sweep(x, 2L, center, check.margin = FALSE)
>         }
>     }
>     else if (is.numeric(center) && (length(center) == nc))
>         x <- sweep(x, 2L, center, check.margin = FALSE)
>     else stop("length of 'center' must equal the number of columns of 'x'")
>     if (is.logical(scale)) {
>         if (scale) {
>             f <- function(v) {
>                 v <- v[!is.na(v)]
>                 sqrt(sum(v^2)/max(1, length(v) - 1L))
>             }
>             scale <- apply(x, 2L, f)
>             x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
>         }
>     }
>     else if (is.numeric(scale) && length(scale) == nc)
>         x <- sweep(x, 2L, scale, "/", check.margin = FALSE)
>     else stop("length of 'scale' must equal the number of columns of 'x'")
>     #if (is.numeric(center))
>     #    attr(x, "scaled:center") <- center
>     #if (is.numeric(scale))
>     #    attr(x, "scaled:scale") <- scale
>     x
> }
>  x2<-scale1(x,center=TRUE,scale=TRUE)
>  str(x2)
> # num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
>
> identical(x1,x2)
> #[1] TRUE
> A.K.
>
>
>
> ----- Original Message -----
> From: C W <tmrsg11 at gmail.com>
> To: arun <smartpink111 at yahoo.com>
> Cc: R help <r-help at r-project.org>
> Sent: Tuesday, July 16, 2013 6:58 PM
> Subject: Re: [R] How to remove attributes from scale() in a matrix?
>
> Arun, thanks for the quick response.  That helps.
>
> Why does scale() give attributes?  What's the point of that?  I don't
> see apply() or any similar functions do it.  Just for my curiosity.
>
> Mike
>
> On Tue, Jul 16, 2013 at 4:07 PM, arun <smartpink111 at yahoo.com> wrote:
>> HI,
>> Try:
>> x1<-scale(x,center=TRUE,scale=TRUE)
>> str(x1)
>> # num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
>> # - attr(*, "scaled:center")= num [1:10] 50.2 50 49.8 49.8 50.3 ...
>>  #- attr(*, "scaled:scale")= num [1:10] 1.109 0.956 0.817 0.746 1.019 ...
>>
>>  attr(x1,"scaled:center")<-NULL
>>  attr(x1,"scaled:scale")<-NULL
>> str(x1)
>>  #num [1:15, 1:10] -0.2371 -0.5606 -0.8242 1.5985 -0.0164 ...
>> A.K.
>>
>>
>>
>>
>> ----- Original Message -----
>> From: C W <tmrsg11 at gmail.com>
>> To: r-help <r-help at r-project.org>
>> Cc:
>> Sent: Tuesday, July 16, 2013 3:59 PM
>> Subject: [R] How to remove attributes from scale() in a matrix?
>>
>> Hi list,
>>
>> I am using scale() to standardize a distribution?  But why does it
>> give me attributes attached to the data?  I just want a standardized
>> matrix, that is all.
>>
>> library(mvtnorm)
>>> x <- rmvnorm(15, mean=rep(50, 10))
>>> x
>>           [,1]     [,2]     [,3]     [,4]     [,5]     [,6]     [,7]
>>   [,8]     [,9]
>> [1,] 51.17519 52.34341 49.63084 47.99234 51.63113 50.91391 49.36819
>> 49.23901 51.17377
>> [2,] 50.57039 49.17210 48.64395 49.03940 49.65761 49.93840 49.94883
>> 50.69044 49.57632
>> [3,] 50.64811 50.21503 50.13786 49.15879 48.51550 50.19444 50.23710
>> 50.98040 51.37032
>> [4,] 49.22797 49.66445 49.93287 48.63681 50.49457 50.33302 52.29552
>> 49.98424 51.04724
>> [5,] 49.72099 50.84510 50.60976 49.60883 53.59509 49.14728 50.23134
>> 49.09141 49.23780
>> [6,] 49.49126 50.90938 49.67140 50.08951 49.79854 49.03711 50.26037
>> 50.24975 48.26958
>> [7,] 51.12384 47.92778 50.60112 49.01554 49.47515 50.12756 51.65216
>> 49.21998 49.63808
>> [8,] 51.45123 50.44037 50.01039 50.27511 49.97658 51.63002 50.37156
>> 50.02685 48.95423
>> [9,] 51.16989 50.16200 51.17724 50.71678 50.79565 50.27128 51.05608
>> 49.61165 47.81732
>> [10,] 49.54263 49.93501 49.71762 49.33378 51.44935 51.53775 50.54346
>> 49.98333 49.59422
>> [11,] 51.16497 49.82914 49.08821 51.02918 49.67663 49.53498 50.26647
>> 49.48569 50.94504
>> [12,] 51.16827 50.50244 49.13003 49.00155 50.26457 48.85465 49.11593
>> 50.58031 51.14926
>> [13,] 48.26216 49.94866 48.62526 49.11995 50.40082 49.25359 48.57677
>> 50.66760 49.44108
>> [14,] 49.82530 49.17352 50.05588 50.51265 51.04926 50.32474 49.78180
>> 50.48349 49.92431
>> [15,] 50.55772 49.84691 47.95021 50.24911 49.85335 50.73062 51.48718
>> 51.36693 50.18307
>>          [,10]
>> [1,] 50.13859
>> [2,] 51.54920
>> [3,] 49.23230
>> [4,] 50.92683
>> [5,] 50.97708
>> [6,] 50.78799
>> [7,] 50.53913
>> [8,] 49.30832
>> [9,] 49.43606
>> [10,] 49.42060
>> [11,] 50.21002
>> [12,] 51.94848
>> [13,] 49.41352
>> [14,] 52.24064
>> [15,] 51.19474
>>> scale(x, center=TRUE, scale=TRUE)
>>             [,1]       [,2]         [,3]        [,4]        [,5]
>> [,6]        [,7]
>> [1,]  0.8890317  2.3390090 -0.040395734 -1.86089754  1.00159470
>> 0.92533476 -0.99715965
>> [2,]  0.2452502 -0.9109703 -1.190404546 -0.63771097 -0.66104313
>> -0.21446975 -0.40514793
>> [3,]  0.3279747  0.1578297  0.550427419 -0.49823662 -1.62323564
>> 0.08468695 -0.11121941
>> [4,] -1.1837031 -0.4064112  0.311551281 -1.10802250  0.04407804
>> 0.24660932  1.98754311
>> [5,] -0.6589074  0.8035298  1.100314901  0.02749734  2.65618150
>> -1.13883336 -0.11709623
>> [6,] -0.9034419  0.8694088  0.006865424  0.58904255 -0.54231158
>> -1.26755243 -0.08749646
>> [7,]  0.8343705 -2.1861602  1.090250934 -0.66558751 -0.81476108
>> 0.00655050  1.33157578
>> [8,]  1.1828615  0.3887665  0.401888014  0.80585326 -0.39231482
>> 1.76205433  0.02587038
>> [9,]  0.8833860  0.1034854  1.761589113  1.32181395  0.29773018
>> 0.17447101  0.72381232
>> [10,] -0.8487569 -0.1291363  0.060728488 -0.29381647  0.84844800
>> 1.65423826  0.20113824
>> [11,]  0.8781560 -0.2376361 -0.672712386  1.68676651 -0.64501776
>> -0.68583461 -0.08127647
>> [12,]  0.8816611  0.4523675 -0.623990804 -0.68193230 -0.14968994
>> -1.48074503 -1.25436403
>> [13,] -2.2117715 -0.1151423 -1.212190165 -0.54361597 -0.03490809
>> -1.01461386 -1.80409304
>> [14,] -0.5478718 -0.9095198  0.454889973  1.08335795  0.51138447
>> 0.23693367 -0.57544865
>> [15,]  0.2317608 -0.2194204 -1.998811911  0.77548830 -0.49613484
>> 0.71117025  1.16336204
>>             [,8]        [,9]       [,10]
>> [1,] -1.2666791  1.17934107 -0.35061189
>> [2,]  0.8423439 -0.28600703  1.06389274
>> [3,]  1.2636749  1.35963155 -1.25940610
>> [4,] -0.1838111  1.06327078  0.43980595
>> [5,] -1.4811512 -0.59653247  0.49019839
>> [6,]  0.2019965 -1.48467432  0.30058779
>> [7,] -1.2943281 -0.22935616  0.05103467
>> [8,] -0.1218950 -0.85664924 -1.18316969
>> [9,] -0.7252082 -1.89953387 -1.05507780
>> [10,] -0.1851315 -0.26958168 -1.07058564
>> [11,] -0.9082374  0.96952049 -0.27897948
>> [12,]  0.6823136  1.15685832  1.46428187
>> [13,]  0.8091562 -0.41005981 -1.07768018
>> [14,]  0.5416286  0.03320871  1.75724879
>> [15,]  1.8253278  0.27056365  0.70846058
>> attr(,"scaled:center")
>> [1] 50.33999 50.06102 49.66551 49.58529 50.44225 50.12196 50.34618
>> 50.11074 49.88811
>> [10] 50.48823
>> attr(,"scaled:scale")
>> [1] 0.9394453 0.9757930 0.8581604 0.8560117 1.1869812 0.8558562
>> 0.9807762 0.6882016
>> [9] 1.0901550 0.9972455
>>
>>
>> Also,
>>> attributes(x) <- NULL
>> will not work since this is matrix not vector.
>>
>> Thanks,
>> Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


From lbajuk at tibco.com  Wed Jul 17 02:06:34 2013
From: lbajuk at tibco.com (Louis Bajuk-Yorgan)
Date: Wed, 17 Jul 2013 00:06:34 +0000
Subject: [R] Announcing TIBCO Enterprise Runtime for R
In-Reply-To: <CAAmySGPdMGCun-Ypcy8MX0pDNxmbfmur2HrGix4riArCDKy0dw@mail.gmail.com>
References: <46AAEC13-6D0D-4DF8-A4F0-F90546E0F28B@tibco.com>
	<CAAmySGPdMGCun-Ypcy8MX0pDNxmbfmur2HrGix4riArCDKy0dw@mail.gmail.com>
Message-ID: <B6B83B4D8B4C5B48A81903EC3EB874EA1C97766A@PA-MBX01.na.tibco.com>

Hi Michael

Thanks for your questions. Posting them here is fine, or you can also post them on the TERR Community site: https://www.tibcommunity.com/community/products/analytics/terr.

Initial answers below--feel free to ask follow ups:

> 1. Do you have concrete benchmarks of what sorts of operations are faster? In particular, are you, like Revolution, licensing MKL?

Yes we have benchmarks, and yes we license MKL. It's challenging to come up with comprehensive, meaningful benchmarks, and so we are looking to the community for benchmarks they'd like to see. Feel free to post anything you are interested in on the community site, or email me directly. 
- Generally we will be much faster for pure R language operations (e.g., for loops), since we have written a new, R-compatible interpreter from the ground up. The performance ratio will tend to improve with larger data sets, since we have implemented highly efficient memory management.
- Since we license MKL (and distribute it in the free Developer's Edition), we will have all the related matrix-operation speed advantages.
- For more detailed info and some benchmarks, see the presentation that Michael Sannella (the chief architect for TERR) gave at useR 2013. It's now available on slideshare: http://www.slideshare.net/loubajukyorgan/sannella-use-r2013terrmemorymanagement 

> 2. Your white-paper boasts of superior memory management; can you give more details? Are we now reference counting, or abandoning copy-on-write to play better with fork(), or running concurrently? In turn, does this mean the C-API is not kept as is and any package with compiled code isn't usable?

See Michael's presentation "Memory Management in TERR", referenced above for full details. In particular, yes, full reference counting has been implemented. 

Our goal is to have packages with compiled code work as-is, without modification. To do this, since the internals of our engine are different, we need to emulate the APIs for these packages to work. We have done this for many APIs and packages so far. See the Community site for a list of packages known to run successfully. 

> 3. You speak of being more robust: is this at a language level (i.e.,something simpler to use than try()/tryCatch()) or an implementation level? If the latter, what non-robustnesses are being addressed?

Primarily, the greater robustness comes from the improvements to memory management. Beyond that, we do extensive automated testing (using the deep array of tests we have built up over the years for S+ development) to ensure reliability, and we have done some work at the language level (around improvements to signal handling, throwing and catching errors, etc.). If you'd like more info the last point, email me directly and I can get you in touch with Michael.

> 4. What are y'all's plans for supporting TERR as 'regular R' evolves? Will it track or will things diverge over time?

Our intent is to keep up with current R as closely as possible. In talking to our customers, we have heard loud and clear that they love the idea of an enterprise R engine, but they don't want to be locked into a proprietary flavor of R. 

> 5. Known (and not intended to change) differences?

Very minor items. Full list on the Community Site. 

> 6. Is the whole R-level API exposed or only a selected subset? I'm thinking in particular of (1) things like .colMeans() which seem rather tied to the implementation; (2) graphics devices; (3) the promise mechanism and copy-on-write semantics?

As mentioned in #2 above, we are implementing the R APIs over time. For a full list of what we have and haven't yet implemented, check out the community site, and feel free to leave comments about what you'd like us to prioritize next. 

Regards, and thanks again for your interest.
Lou


-----Original Message-----
From: R. Michael Weylandt [mailto:michael.weylandt at gmail.com] 
Sent: Thursday, July 11, 2013 1:59 PM
To: Louis Bajuk-Yorgan
Cc: r-help
Subject: Re: [R] Announcing TIBCO Enterprise Runtime for R

Hi Louis,

I apologize in advance if this isn't the right forum; feel free to direct me elsewhere.

Can you say a bit more about what exactly constitute the advantages of TERR over R as most readers of this list know it? Some random points of interest to me:

1. Do you have concrete benchmarks of what sorts of operations are faster? In particular, are you, like Revolution, licensing MKL?
2. Your white-paper boasts of superior memory management; can you give more details? Are we now reference counting, or abandoning copy-on-write to play better with fork(), or running concurrently? In turn, does this mean the C-API is not kept as is and any package with compiled code isn't usable?
3. You speak of being more robust: is this at a language level (i.e.,something simpler to use than try()/tryCatch()) or an implementation level? If the latter, what non-robustnesses are being addressed?
4. What are y'all's plans for supporting TERR as 'regular R' evolves?
Will it track or will things diverge over time?
5. Known (and not intended to change) differences?
6. Is the whole R-level API exposed or only a selected subset? I'm thinking in particular of (1) things like .colMeans() which seem rather tied to the implementation; (2) graphics devices; (3) the promise mechanism and copy-on-write semantics?

Cheers,
Michael

On Wed, Jul 10, 2013 at 4:42 AM, Louis Bajuk-Yorgan <lbajuk at tibco.com> wrote:
> In honor of the kickoff of useR 2013 today, I'm proud to announce the availability of TIBCO Enterprise Runtime for R (or TERR for short), our new enterprise-grade, high-performance statistical engine, fully compatible with the R language.
>
> For more information on TERR, and a link to download the free Developer's Edition via the TERR Community site, check out http://spotfire.tibco.com/terr--or come to my talk at useR on Thursday morning.
>
> As part of our development of TERR, we have also contributed new packages to CRAN: sjdbc (a JDBC driver interface, previously developed for S-PLUS) and tibbrConnector (an R interface to tibbr, TIBCO's Social Network for the Enterprise).
>
> ----------------------------------
> Lou Bajuk-Yorgan
> @loubajuk
> TIBCO Spotfire
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From daisy.duursma at gmail.com  Wed Jul 17 03:21:53 2013
From: daisy.duursma at gmail.com (Daisy Englert Duursma)
Date: Wed, 17 Jul 2013 11:21:53 +1000
Subject: [R] interfacing with website
Message-ID: <CAFf2dDHY4sAFZ-wOy2XBW_YsOosZQj3eg4+s2DSwRPQ8mszttw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/efa31e26/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 17 04:53:31 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 16 Jul 2013 19:53:31 -0700 (PDT)
Subject: [R] writing multiple lines to a file
Message-ID: <1374029611.38676.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
May be this helps:
printer1<- file("out1.txt","w")
write(sprintf("This is line %d.\n",1),printer1,append=TRUE) 
write("This is line 2",printer1,append=TRUE)
close(printer1)

#or


?printer1<- file("out1.txt","w")
writeLines("This is line",con=printer1,sep="\n")
writeLines("This is line 2",con=printer1)
?close(printer1)
A.K.


Hello, I am trying to wrote multiple lines to a file, but I only seem to be able to write the last line. 

printer = file("out.txt") 
write(sprintf("This is line %d.\n",1),printer,append=T) 
write("This is line 2.",printer,append=T) 
close(printer) 

How can I fix this? I would like to be able to do this in a for-loop with hundreds of elements.


From arthers5 at hotmail.com  Wed Jul 17 05:41:08 2013
From: arthers5 at hotmail.com (labib obaid)
Date: Wed, 17 Jul 2013 03:41:08 +0000
Subject: [R] (no subject)
Message-ID: <DUB404-EAS3343A4066DF517E04953F3A91610@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/516f39e7/attachment.pl>

From yitus_14 at hotmail.com  Tue Jul 16 23:29:15 2013
From: yitus_14 at hotmail.com (Lee Jejen)
Date: Tue, 16 Jul 2013 21:29:15 +0000
Subject: [R] ERROR: missing value where TRUE/FALSE needed
Message-ID: <BAY159-W224AB875DC5FE90B228184F7600@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: no disponible
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130716/4042ce26/attachment.pl>

From paul at stat.auckland.ac.nz  Tue Jul 16 23:42:45 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Wed, 17 Jul 2013 09:42:45 +1200
Subject: [R] Masking oceans using polypath
In-Reply-To: <CAMxjYa3RDKOcSk7Ms3vrWRaKiNMpek_i=nMawjQmAN3gv4eesA@mail.gmail.com>
References: <CAMxjYa3RDKOcSk7Ms3vrWRaKiNMpek_i=nMawjQmAN3gv4eesA@mail.gmail.com>
Message-ID: <51E5BE55.5010909@stat.auckland.ac.nz>

Hi

There are a couple of problems:

1.
Your 'outline' is much bigger than it needs to be.  For example, the 
following produces just Australia ...

outline <- map("worldHires", regions="Australia", exact=TRUE,
                plot=FALSE) # returns a list of x/y coords

2.
The outline you get still has NA values in it (the coastline of 
Australia in this database is a series of distinct lines;  I don't know 
why that is).  Fortunately, you can stitch Australia back together again 
like this ...

subset <- !is.na(outline$x)
polypath(c(outline$x[subset], NA, c(xbox, rev(xbox))),
          c(outline$y[subset], NA, rep(ybox, each=2)),
          col="light blue", rule="evenodd")

With those two changes, I get a much better result.  You may want to 
fiddle a bit more to add Tasmania and bits of PNG and Indonesia back in 
the picture OR you could replace these problems with a different 
approach and use a more sophisticated map outline via a "shapefile" (see 
the 'sp' package and the 'maptools' package and possibly the R-sig-geo 
mailing list).

Hope that helps.

Paul

On 07/16/13 23:17, Louise Wilson wrote:
> library(mapdata)
>
> image(x=110:155, y =-40:-10, z = outer(1:45, 1:30, "+"),
>
>        xlab = "lon", ylab = "lat")
>
> outline <- map("worldHires", plot=FALSE) # returns a list of x/y coords
>
> xrange <- range(outline$x, na.rm=TRUE) # get bounding box
>
> yrange <- range(outline$y, na.rm=TRUE)
>
> xbox <- xrange + c(-2, 2)
>
> ybox <- yrange + c(-2, 2)
>
> # create the grid path in the current device
>
> polypath(c(outline$x, NA, c(xbox, rev(xbox))),
>
>       c(outline$y, NA, rep(ybox, each=2)),
>
>       col="light blue", rule="evenodd")

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From totangjie at gmail.com  Wed Jul 17 08:02:25 2013
From: totangjie at gmail.com (Jie Tang)
Date: Wed, 17 Jul 2013 14:02:25 +0800
Subject: [R] how to resolve the install problem in redhat linux
Message-ID: <CAMUSh4oLw=_=S_iPhXWHsjRJ7rkR9xN3Dgtf2W3gDmW42p_dTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/4b988ca0/attachment.pl>

From jim at bitwrit.com.au  Wed Jul 17 08:01:17 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 17 Jul 2013 16:01:17 +1000
Subject: [R] (no subject)
In-Reply-To: <DUB404-EAS3343A4066DF517E04953F3A91610@phx.gbl>
References: <DUB404-EAS3343A4066DF517E04953F3A91610@phx.gbl>
Message-ID: <51E6332D.9090900@bitwrit.com.au>

On 07/17/2013 01:41 PM, labib obaid wrote:
> hi
>
> I need to use boxplot for two subsets at the same page
>
Hi labib obaid,
Try this:

test.df<-data.frame(a=rnorm(80)+4,b=rnorm(80)+4,
  c=rep(LETTERS[1:4],each=20),
  d=rep(rep(letters[1:4],each=4),5))
boxplot(test.df$a[test.df$c %in% c("A","B")],
  test.df$a[test.df$c %in% c("C","D")])

That should get you started.

Jim


From ripley at stats.ox.ac.uk  Wed Jul 17 08:25:54 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 17 Jul 2013 07:25:54 +0100
Subject: [R] how to resolve the install problem in redhat linux
In-Reply-To: <CAMUSh4oLw=_=S_iPhXWHsjRJ7rkR9xN3Dgtf2W3gDmW42p_dTw@mail.gmail.com>
References: <CAMUSh4oLw=_=S_iPhXWHsjRJ7rkR9xN3Dgtf2W3gDmW42p_dTw@mail.gmail.com>
Message-ID: <51E638F2.1060904@stats.ox.ac.uk>

On 17/07/2013 07:02, Jie Tang wrote:
> I try to install a R resource package (in R.2.15 or R 3.0)

There are no such versions of R: see the posting guide.

> But when I run the command "configure",the Makefile does not
>
> generated succefully as error information shown as below
>
> --with-readline=yes (default) and headers/libs are not available
>
> my linux sysem is "Red Hat Enterprise Linux Client release 5.3 (Tikanga)"
>
> How could I install R?
>

As the INSTALL file says

The main source of information on installation is the `R Installation
and Administration Manual', an HTML copy of which is available as file
`doc/html/R-admin.html'.  Please read that before installing R.  But
if you are impatient, read on but please refer to the manual to
resolve any problems.

The exact part is

http://cran.r-project.org/doc/manuals/r-release/R-admin.html#Essential-programs-and-libraries

and the para just above

'Remember that some package management systems (such as RPM and deb) 
make a distinction between the user version of a package and the 
development version. The latter usually has the same name but with the 
extension ?-devel? or ?-dev?: you need both versions installed. '

put please read all of the manual as you were asked to: it is likely 
other pieces of your OS also need to be installed.

I believe there are also binary packages available for R from RedHat: 
but for that, ask on R-sig-fedora.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petr.pikal at precheza.cz  Wed Jul 17 08:45:48 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Wed, 17 Jul 2013 06:45:48 +0000
Subject: [R] ERROR: missing value where TRUE/FALSE needed
In-Reply-To: <BAY159-W224AB875DC5FE90B228184F7600@phx.gbl>
References: <BAY159-W224AB875DC5FE90B228184F7600@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7E2A0@SRVEXCHMBX.precheza.cz>

Hi

What is mctp?
Why do you think your data are well defined? Did you try str(Datos)?
Where you get this error? When you do call mctp or summary?

The main problem is that you do not follow posting guide, do not provide reproducible code and/or at least some info about your data. 

Without that I wonder if anybody can resolve your problem.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Lee Jejen
> Sent: Tuesday, July 16, 2013 11:29 PM
> To: r-help at r-project.org
> Subject: [R] ERROR: missing value where TRUE/FALSE needed
> 
> Hello, I have a problem... I tried using a function and I get the
> error: "ERROR: missing value where TRUE/FALSE needed"
> Here is my code:
> a<-mctp(Ecoli~Fecha, data=Datos, type = "Tukey", alternative =
> "two.sided", asy.method = "mult.t", plot.simci = TRUE)summary(a) Ecoli,
> Fecha and Datos are well defined. I don't know what is the problem...
> THANKS
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stephen.creamer at nhs.net  Wed Jul 17 09:24:48 2013
From: stephen.creamer at nhs.net (Steve Creamer)
Date: Wed, 17 Jul 2013 00:24:48 -0700 (PDT)
Subject: [R] Setting Derived Class Slots
In-Reply-To: <51E5777B.9020106@fhcrc.org>
References: <1373981819489-4671683.post@n4.nabble.com>
	<51E5777B.9020106@fhcrc.org>
Message-ID: <1374045888060-4671737.post@n4.nabble.com>

Doh....so simple when you know how! That worked straightaway! Thank you
Martin!



--
View this message in context: http://r.789695.n4.nabble.com/Setting-Derived-Class-Slots-tp4671683p4671737.html
Sent from the R help mailing list archive at Nabble.com.


From stephen.creamer at nhs.net  Wed Jul 17 09:31:10 2013
From: stephen.creamer at nhs.net (Steve Creamer)
Date: Wed, 17 Jul 2013 00:31:10 -0700 (PDT)
Subject: [R] Setting Derived Class Slots
In-Reply-To: <D7EC1BAF-5620-4DDB-AA5D-32E9C0837869@uni-bonn.de>
References: <1373981819489-4671683.post@n4.nabble.com>
	<D7EC1BAF-5620-4DDB-AA5D-32E9C0837869@uni-bonn.de>
Message-ID: <1374046270368-4671738.post@n4.nabble.com>

Hi Simon.....many thanks to you for your explanation. - I'll check out
setReplaceMethod. Point taken on nomenclature too... 



--
View this message in context: http://r.789695.n4.nabble.com/Setting-Derived-Class-Slots-tp4671683p4671738.html
Sent from the R help mailing list archive at Nabble.com.


From zroslina at yahoo.com  Wed Jul 17 11:33:46 2013
From: zroslina at yahoo.com (Roslina Zakaria)
Date: Wed, 17 Jul 2013 02:33:46 -0700 (PDT)
Subject: [R] error message in gev
Message-ID: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/c9ac30e1/attachment.pl>

From elaine.kuo.tw at gmail.com  Wed Jul 17 11:50:51 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Wed, 17 Jul 2013 17:50:51 +0800
Subject: [R] extract beta.sim from dist type data (package betapart)
Message-ID: <CAGJhoDxNK7DS=HyogMOmDsVDrUzCTuMnhNJXAjkPqNqua8HxVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/f6525458/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jul 17 11:51:19 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Jul 2013 10:51:19 +0100
Subject: [R] error message in gev
In-Reply-To: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>
References: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>
Message-ID: <51E66917.6090905@sapo.pt>

Hello,

You should say which package is gev() coming from. I believe it's from 
evir, and what follows assumes that.
The problem is that 'dat' is a data.frame, a special type of list. It is 
a list of vectors and gev is expecting just one vector. You could try 
instead, to fit generalized extreme value distributions to each of the 
vectors in the data.frame,

out.list <- lapply(dat, gev, block = 20)


to get a list of 10 objects of class gev, like the help page says.

Hope this helps,

Rui Barradas

Em 17-07-2013 10:33, Roslina Zakaria escreveu:
>
> Hi r-users,
>
> I would like to use gev and my data (annual rainfall ) is as follows:
>
>> head(dat,20)  A    B    C    D    E    F    G    H    I     J
> 1  45.1 41.5 58.5 50.1 46.0 49.1 37.7 49.1 59.8  54.0
> 2  50.3 39.8 49.4 56.4 49.4 48.8 42.1 49.8 49.4  58.3
> 3  41.7 39.3 44.6 39.1 35.7 41.5 40.8 40.8 38.5  45.6
> 4  50.7 33.9 48.4 28.2 35.5 39.1 61.4 17.0 30.7  38.3
> 5  39.3 30.6 46.9 23.8 25.8 17.1 37.9 40.1 35.4  30.1
> 6  50.2 43.6 55.5 26.7 36.6 20.6 35.2 46.0 52.2  30.5
> 7  46.0 37.0 55.3 36.3 51.9 50.6 43.2 44.9 38.2  45.4
> 8  46.0 15.4 35.7 27.3 40.2 21.2 41.1 65.7 35.7  28.7
> 9  52.0 36.5 49.6 55.0 38.3 32.0 43.8 43.8 50.3  36.5
> 10 57.5 51.0 47.0 63.0 43.0 46.5 41.5 82.8 50.5  38.5
> 11 71.0 48.0 59.5 48.5 47.0 57.5 55.8 64.5 60.0  43.4
> 12 57.5 52.5 58.5 42.0 62.0 44.0 47.5 59.5 45.0  51.5
> 13 47.0 38.0 49.9 50.5 55.0 57.5 51.5 54.5 45.0  49.7
> 14 66.5 44.4 60.0 99.5 54.5 41.3 57.0 69.5 33.0  58.4
> 15 61.5 43.6 68.5 50.7 48.0 50.5 50.5 58.8 53.2  47.0
> 16 55.5 58.5 55.5 45.8 48.0 57.0 52.0 48.5 58.5 437.5
> 17 96.7 96.7 96.7 45.5 65.1 46.5 51.0 96.7 61.3 310.5
> 18 71.5 55.5 63.0 52.5 59.0 55.5 55.5 51.1 47.0  49.5
> 19 71.5 42.5 64.0 56.5 61.0 54.0 46.5 53.7 43.0  44.0
> 20 57.5 51.5 51.3 34.0 55.0 61.0 55.5 51.3 51.3  44.5
>
> When I apply the gev function, I have the following error message:
>
> out <- gev(dat, 20) Error in gev(dat, 20) : (list) object cannot be coerced to type 'double'
>
> Can anybody explain to me what does it means.  I tried to read the package manual but could not understand about the block.
>
> Thank you so much for any help given.
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From goelaf at gmx.net  Wed Jul 17 11:14:10 2013
From: goelaf at gmx.net (Olaf)
Date: Wed, 17 Jul 2013 02:14:10 -0700 (PDT)
Subject: [R] Box plot with 5th and 95th percentiles instead of 1.5 *
 IQR: problems implementing an existing solution...
In-Reply-To: <BANLkTikk-zio0prag4m7XQucwTpGyPHvKw@mail.gmail.com>
References: <BANLkTikk-zio0prag4m7XQucwTpGyPHvKw@mail.gmail.com>
Message-ID: <1374052450639-4671739.post@n4.nabble.com>

Hello, 
you may just first change the boxplot.stats directly:

boxplot.stats <-  function (x, coef = NULL, do.conf = TRUE, do.out =
                                 TRUE)
{
  nna <- !is.na(x)
  n <- sum(nna)
  stats <- quantile(x, c(.05,.25,.5,.75,.95), na.rm = TRUE)
  iqr <- diff(stats[c(2, 4)])
  out <- x < stats[1] | x > stats[5]
  conf <- if (do.conf)
    stats[3] + c(-1.58, 1.58) * diff(stats[c(2, 4)])/sqrt(n)
  list(stats = stats, n = n, conf = conf, out = x[out & nna])
} 


then use it plotting your data. 
And after that change them back :

boxplot.stats <- function (x, coef = 1.5, do.conf = TRUE, do.out = TRUE) 
{
  if (coef < 0) 
    stop("'coef' must not be negative")
  nna <- !is.na(x)
  n <- sum(nna)
  stats <- stats::fivenum(x, na.rm = TRUE)
  iqr <- diff(stats[c(2, 4)])
  if (coef == 0) 
    do.out <- FALSE
  else {
    out <- if (!is.na(iqr)) {
      x < (stats[2L] - coef * iqr) | x > (stats[4L] + coef * 
                                            iqr)
    }
    else !is.finite(x)
    if (any(out[nna], na.rm = TRUE)) 
      stats[c(1, 5)] <- range(x[!out], na.rm = TRUE)
  }
  conf <- if (do.conf) 
    stats[3L] + c(-1.58, 1.58) * iqr/sqrt(n)
  list(stats = stats, n = n, conf = conf, out = if (do.out) x[out & 
                                                                nna] else
numeric())
}


it works fine for me.





--
View this message in context: http://r.789695.n4.nabble.com/Box-plot-with-5th-and-95th-percentiles-instead-of-1-5-IQR-problems-implementing-an-existing-solution-tp3456123p4671739.html
Sent from the R help mailing list archive at Nabble.com.


From luandex at cn.ibm.com  Wed Jul 17 11:51:11 2013
From: luandex at cn.ibm.com (De Xin Luan)
Date: Wed, 17 Jul 2013 17:51:11 +0800
Subject: [R] Help: Error when installing R 2.8.1 in IBM AIX system from
	source code
Message-ID: <OF2C981413.D6A8B470-ON48257BAB.00336AFA-48257BAB.00364FC8@cn.ibm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/49637ba0/attachment.pl>

From g.rudge at bham.ac.uk  Wed Jul 17 12:58:39 2013
From: g.rudge at bham.ac.uk (Gavin Rudge)
Date: Wed, 17 Jul 2013 11:58:39 +0100
Subject: [R] Some problems with back to back bar plots in ggplot2
Message-ID: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06D9F6EB@mds-exch-02.adf.bham.ac.uk>

Hi, I'm making a simple population pyramid using two back-to-back bar plots for 18 different age groups with totals for males and females.

Yesterday I achieved a fairly serviceable plot using the following.

library(ggplot2)
library(reshape2)
library(plyr)
#make sample data
df<-data.frame(ag=c(1:18),males=sample(100:200,18),females=sample(100:200,18))
#melted as per original data set
df<-melt(df,id="ag")
df
#my plot
ggplot(data=df,aes(x=ag))+geom_bar(subset=.(variable=="males"),aes(y=value),stat="identity",fill="#330099")+
  geom_bar(subset=.(variable=="females"),aes(y=-value),stat="identity",fill="#FF9333")+
  scale_y_continuous(breaks=seq(-200,200,50),labels=abs(seq(-200,200,50)))+
  scale_x_continuous(breaks=seq(1,18,1),labels=abs(seq(1,18,1)))+coord_flip()+
  theme_bw()+xlab("age group")+ylab("population")

Today it threw errors. I updated to R studio 0.97.551.  I also made sure I had the latest R 3.0.1, and reinstalled the packages I was using. This is all running on Windows 7.

It still threw errors. So I tried specifying all of the variables with their full names, which got me a plot.

ggplot(data=df,aes(x=df$ag))+geom_bar(subset=.(df$variable=="males"),aes(y=df$value),stat="identity",fill="#330099")+
  geom_bar(subset=.(df$variable=="females"),aes(y=-df$value),stat="identity",fill="#FF9333")+
  scale_y_continuous(breaks=seq(-200,200,50),labels=abs(seq(-200,200,50)))+
  scale_x_continuous(breaks=seq(1,18,1),labels=abs(seq(1,18,1)))+coord_flip()+
  theme_bw()+xlab("age group")+ylab("population")

But now my y axis (which in my case is horizontal as I flipped the co-ords) won't scale properly.  From what I recall, it looked fine yesterday.

I'm trying to get back to a properly scaled population pyramid, which apart from some cosmetics, was what I needed.

Any help appreciated.

GavinR


From ruipbarradas at sapo.pt  Wed Jul 17 14:49:15 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Jul 2013 13:49:15 +0100
Subject: [R] error message in gev
In-Reply-To: <1374064426.75463.YahooMailNeo@web120605.mail.ne1.yahoo.com>
References: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>
	<51E66917.6090905@sapo.pt>
	<1374064426.75463.YahooMailNeo@web120605.mail.ne1.yahoo.com>
Message-ID: <51E692CB.7010303@sapo.pt>

Hello,

It's better if you Cc the list, the odds of getting more and better 
answers are greater.

Have you tried with different block values?

Rui Barradas

Em 17-07-2013 13:33, Roslina Zakaria escreveu:
> Hi Rui,
> Yes, I am using gev from 'evir'
> install.packages("evir")
> library(evir)
> I have tried your suggestion and follow are what I got.
>
>>out.list <- lapply(dat, gev, block = 20)
> Error in optim(theta, negloglik, hessian = TRUE, ..., tmp = data) :
>    non-finite finite-difference value [1]
> In addition:Warning messages:
> 1: In FUN(X[[7L]], ...) : optimization may not have succeeded
> 2: In FUN(X[[7L]], ...) : optimization may not have succeeded
> 3: In sqrt(diag(varcov)) : NaNs produced
> 4: In FUN(X[[7L]], ...) : optimization may not have succeeded
> 5: In FUN(X[[7L]], ...) : optimization may not have succeeded
> 6: In FUN(X[[7L]], ...) : optimization may not have succeeded
> 7: In FUN(X[[7L]], ...) : optimization may not have succeeded
>
>
>
> Thank you.
>
>
> *From:* Rui Barradas <ruipbarradas at sapo.pt>
> *To:* Roslina Zakaria <zroslina at yahoo.com>
> *Cc:* "r-help at r-project.org" <r-help at r-project.org>
> *Sent:* Wednesday, July 17, 2013 5:51 PM
> *Subject:* Re: [R] error message in gev
>
> Hello,
>
> You should say which package is gev() coming from. I believe it's from
> evir, and what follows assumes that.
> The problem is that 'dat' is a data.frame, a special type of list. It is
> a list of vectors and gev is expecting just one vector. You could try
> instead, to fit generalized extreme value distributions to each of the
> vectors in the data.frame,
>
> out.list <- lapply(dat, gev, block = 20)
>
>
> to get a list of 10 objects of class gev, like the help page says.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 17-07-2013 10:33, Roslina Zakaria escreveu:
>  >
>  > Hi r-users,
>  >
>  > I would like to use gev and my data (annual rainfall ) is as follows:
>  >
>  >> head(dat,20)  A    B    C    D    E    F    G    H    I    J
>  > 1  45.1 41.5 58.5 50.1 46.0 49.1 37.7 49.1 59.8 54.0
>  > 2  50.3 39.8 49.4 56.4 49.4 48.8 42.1 49.8 49.4  58.3
>  > 3  41.7 39.3 44.6 39.1 35.7 41.5 40.8 40.8 38.5  45.6
>  > 4  50.7 33.9 48.4 28.2 35.5 39.1 61.4 17.0 30.7  38.3
>  > 5  39.3 30.6 46.9 23.8 25.8 17.1 37.9 40.1 35.4  30.1
>  > 6  50.2 43.6 55.5 26.7 36.6 20.6 35.2 46.0 52.2  30.5
>  > 7  46.0 37.0 55.3 36.3 51.9 50.6 43.2 44.9 38.2  45.4
>  > 8  46.0 15.4 35.7 27.3 40.2 21.2 41.1 65.7 35.7  28.7
>  > 9  52.0 36.5 49.6 55.0 38.3 32.0 43.8 43.8 50.3  36.5
>  > 10 57.5 51.0 47.0 63.0 43.0 46.5 41.5 82.8 50.5  38.5
>  > 11 71.0 48.0 59.5 48.5 47.0 57.5 55.8 64.5 60.0  43.4
>  > 12 57.5 52.5 58.5 42.0 62.0 44.0 47.5 59.5 45.0  51.5
>  > 13 47.0 38.0 49.9 50.5 55.0 57.5 51.5 54.5 45.0  49.7
>  > 14 66.5 44.4 60.0 99.5 54.5 41.3 57.0 69.5 33.0  58.4
>  > 15 61.5 43.6 68.5 50.7 48.0 50.5 50.5 58.8 53.2  47.0
>  > 16 55.5 58.5 55.5 45.8 48.0 57.0 52.0 48.5 58.5 437.5
>  > 17 96.7 96.7 96.7 45.5 65.1 46.5 51.0 96.7 61.3 310.5
>  > 18 71.5 55.5 63.0 52.5 59.0 55.5 55.5 51.1 47.0  49.5
>  > 19 71.5 42.5 64.0 56.5 61.0 54.0 46.5 53.7 43.0  44.0
>  > 20 57.5 51.5 51.3 34.0 55.0 61.0 55.5 51.3 51.3  44.5
>  >
>  > When I apply the gev function, I have the following error message:
>  >
>  > out <- gev(dat, 20) Error in gev(dat, 20) : (list) object cannot be
> coerced to type 'double'
>  >
>  > Can anybody explain to me what does it means.  I tried to read the
> package manual but could not understand about the block.
>  >
>  > Thank you so much for any help given.
>  >     [[alternative HTML version deleted]]
>  >
>  >
>  >
>  > ______________________________________________
>  > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>  > https://stat.ethz.ch/mailman/listinfo/r-help
>  > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
>  > and provide commented, minimal, self-contained, reproducible code.
>  >
>
>


From julian.bothe at elitepartner.de  Wed Jul 17 15:11:51 2013
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Wed, 17 Jul 2013 15:11:51 +0200 (CEST)
Subject: [R] error in "predict.gam" used with "bam"
In-Reply-To: <51DBB6A0.5060604@bath.ac.uk>
References: <ef19394e.000011bc.0000000f@FIW7PC12.ELITEMEDIANET>
	<51DBB6A0.5060604@bath.ac.uk>
Message-ID: <33808e34.00001380.0000000a@FIW7PC12.ELITEMEDIANET>

Solved it!! ;)

The problem was that the test-data contained factor-levels the
training-data didn't.
So when trying to fit this new factor-levels to a model which didn't have
this levels, the error occurred.

When excluding the factor-levels not used when fitting the model or when
taking care all levels are used for modell-fitting, everything is fine.

All the best

Julian

-----Urspr?ngliche Nachricht-----
Von: Simon Wood [mailto:s.wood at bath.ac.uk]
Gesendet: Dienstag, 9. Juli 2013 09:07
An: julian.bothe at elitepartner.de
Cc: r-help at r-project.org
Betreff: Re: [R] error in "predict.gam" used with "bam"

Hi Julian,

Any chance you could send me (offline) a short version of your data, which
reproduces the problem? I can't reproduce it in a quick attempt (but it is
quite puzzling, given that bam calls predict.gam internally in pretty much
the same way that you are doing here).

btw (and nothing to do with the error) given that you are using R 3.0.1
it's a good idea to upgrade to mgcv_1.7-23 or above, for the following
reason (taken from the mgcv changeLog)

1.7-23
------

*** Fix of severe bug introduced with R 2.15.2 LAPACK change. The shipped
version of dsyevr can fail to produce orthogonal eigenvectors when
uplo='U' (upper triangle of symmetric matrix used), as opposed to 'L'.
This led to a substantial number of gam smoothing parameter estimation
convergence failures, as the key stabilizing re-parameterization was
substantially degraded. The issue did not affect gaussian additive models
with GCV model selection. Other models could fail to converge any further
as soon as any smoothing parameter became `large', as happens when a
smooth is estimated as a straight line.
check.gam reported the lack of full convergence, but the issue could also
generate complete fit failures. Picked up late as full test suite had only
been run on R > 2.15.1 with an external LAPACK.

best,
Simon


On 08/07/13 10:02, julian.bothe at elitepartner.de wrote:
> Hello everyone.
>
>
>
> I am doing a logistic gam (package mgcv) on a pretty large dataframe
> (130.000 cases with 100 variables).
>
> Because of that, the gam is fitted on a random subset of 10000. Now
> when I want to predict the values for the rest of the data, I get the
> following
> error:
>
>
>
>
>
>> gam.basis_alleakti.1.pr=predict(gam.basis_alleakti.1,
>
> +
> newdata=activisale_join[gam.basis_alleakti.1.complete_cases,all.vars(g
> am.b
> asis_alleakti.1.formula)],type="response")
>
> Error in predict.gam(gam.basis_alleakti.1, newdata =
> activisale_join[gam.basis_alleakti.1.complete_cases,  :
>
>    number of items to replace is not a multiple of replacement length
>
>
>
>
>
> The following is the code:
>
> #formula with some factors and a lot of variables to be fitted
>
> gam.basis_alleakti.1.formula=as.formula( paste("verl?ngerung ~?,
>
>        paste( names(activisale_join)[c(2:10)], collapse="+"),
> ##factors
>
>
> paste("s(",names(activisale_join)[c(17,19:29,31:42,44)],")",
> collapse="+")) # numeric variables, all count data
>
> )
>
>
>
> # complete cases
>
> gam.basis_alleakti.1.complete_cases =
> complete.cases(activisale_join[,all.vars(gam.basis_alleakti.1.formula)
> ])
>
>
>
> # modell fitting works on random subset
>
> gam.basis_alleakti.1=bam(gam.basis_alleakti.1.formula,
>
>                           data = activisale_join[subset.10000, ],
> family=
> "binomial")
>
>
>
> # error, no idea why
>
> gam.basis_alleakti.1.pr=predict(gam.basis_alleakti.1,
> newdata=activisale_join[gam.basis_alleakti.1.complete_cases,
> ],type="response")
>
>
>
>
>
> the prediction on the same subset (subset.10000) works.
>
>
>
>
>
> It could be that this error is somewhat similar to that described as
> sidequestion in
>
> http://r.789695.n4.nabble.com/gamm-tensor-product-and-interaction-td45
> 2618 8.html, where simon answered the following:
>
>
>
> ?>  Here is the error message I obtain:
>>
> vis.gam(gm1$gam,plot.type="contour",n.grid=200,color="heat",zlim=c(0,4
> ))
>>   Error in predict.gam(x, newdata = newd, se.fit = TRUE, type = type) :
> number of items to replace is not a multiple of replacement length
> - hmm, possibly a bug. I'll look into it.
>
> best,
> Simon?
>
>
>
> All the best
>
>
>
> Julian
>
>
>
> Ps.: > version
>                 _
> platform       x86_64-w64-mingw32
> arch           x86_64
> os             mingw32
> system         x86_64, mingw32
> status
> major          3
> minor          0.1
> year           2013
> month          05
> day            16
> svn rev        62743
> language       R
> version.string R version 3.0.1 (2013-05-16)
> nickname       Good Sport
>
>
>
> package mgcv version 1.7-22
>
>
>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


--
Simon Wood, Mathematical Science, University of Bath BA2 7AY UK
+44 (0)1225 386603               http://people.bath.ac.uk/sw283


From zroslina at yahoo.com  Wed Jul 17 15:49:00 2013
From: zroslina at yahoo.com (Roslina Zakaria)
Date: Wed, 17 Jul 2013 06:49:00 -0700 (PDT)
Subject: [R] Fw:  error message in gev
In-Reply-To: <51E692CB.7010303@sapo.pt>
References: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>
	<51E66917.6090905@sapo.pt>
	<1374064426.75463.YahooMailNeo@web120605.mail.ne1.yahoo.com>
	<51E692CB.7010303@sapo.pt>
Message-ID: <1374068940.41148.YahooMailNeo@web120602.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/c56017c5/attachment.pl>

From zroslina at yahoo.com  Wed Jul 17 15:53:43 2013
From: zroslina at yahoo.com (Roslina Zakaria)
Date: Wed, 17 Jul 2013 06:53:43 -0700 (PDT)
Subject: [R] error message in gev
In-Reply-To: <51E692CB.7010303@sapo.pt>
References: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>
	<51E66917.6090905@sapo.pt>
	<1374064426.75463.YahooMailNeo@web120605.mail.ne1.yahoo.com>
	<51E692CB.7010303@sapo.pt>
Message-ID: <1374069223.16671.YahooMailNeo@web120606.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/d9d22d0a/attachment.pl>

From bogaso.christofer at gmail.com  Wed Jul 17 15:57:28 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 17 Jul 2013 19:27:28 +0530
Subject: [R] Question on plotting with googleVis
In-Reply-To: <51E517CF.9060807@cirad.fr>
References: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>
	<51E517CF.9060807@cirad.fr>
Message-ID: <CA+dpOJnzY7NSvC2NR7qSn63GG2ELTuLh57a1Nu=gd=RpeLzM+Q@mail.gmail.com>

Hello Arnaud,

Thank you for your pointer. However I need to more clarification.

I want to control the max. and min. values for the x-axis, as well as
number of vertical gridlines to be displayed. I tried the following:


MyData <- data.frame(Names1 = paste("XXX", 1:150), Values1 = 1:150 +
10, Values2 = 1:150)
library(googleVis)
plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1",
"Values2"),options=list(width=1200,height=1500,hAxis.gridlines =
"{count: 10}",hAxis.minValue = 0, hAxis.maxValue = 100)))

However this is not clearly working. Can someone point me what went wrong?

Thanks and regards,




On 7/16/13, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
> You can try with list options :
>
> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2"),
> options=list(width=1200,height=1500)))
>
>
>
> Le 15/07/2013 20:00, Christofer Bogaso a ?crit :
>> Hello again,
>>
>> Let say I have following data-frame:
>>
>> MyData <- data.frame(Names1 = paste("XXX", 1:150), Values1 = 1:150 + 10,
>> Values2 = 1:150)
>>
>> Now I want to plot this data-frame with googleVis. Therefore I run
>> following codes:
>>
>> library(googleVis)
>> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2")))
>>
>> However the problem is that, hardly this plot can be read. However if I
>> plot a fraction of my data-frame then the underlying plot is clearly
>> visible:
>>
>> plot(gvisBarChart(MyData[1:15,], xvar="Names1", yvar=c("Values1",
>> "Values2")))  ## This is clearly visible.
>>
>>
>> I would really appreciate if someone gives me some pointer how I can
>> clearly plot my data-frame with googleVis. I understand that there are
>> many
>> other plotting methods available with R like ggplot, however here I want
>> to
>> use googleVis because of its strength in showing the values within the
>> plot
>> area itself if you hover your mouse.
>>
>> Thanks and regards,
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
>


From sarah.goslee at gmail.com  Wed Jul 17 16:20:50 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Wed, 17 Jul 2013 10:20:50 -0400
Subject: [R] [R-sig-eco] extract beta.sim from dist type data (package
	betapart)
In-Reply-To: <CAGJhoDxNK7DS=HyogMOmDsVDrUzCTuMnhNJXAjkPqNqua8HxVQ@mail.gmail.com>
References: <CAGJhoDxNK7DS=HyogMOmDsVDrUzCTuMnhNJXAjkPqNqua8HxVQ@mail.gmail.com>
Message-ID: <CAM_vjukO74ohEKMO0hxE-c=6ryu9G18__n=6gfXGd9th=7oU1A@mail.gmail.com>

Replied to on the R-sig-ecology list, with a request not to cross-post.

Briefly, the output is a list with named components, so can be
extracted as usual.

Sarah

On Wed, Jul 17, 2013 at 5:50 AM, Elaine Kuo <elaine.kuo.tw at gmail.com> wrote:
> Dear List,
>
> This is Elaine.
> I am using beta.part to calculate the beta diversity index.
> The function of beta.part can generate three kinds of beta diversity indice
> at one time.
> However, it is Simpson index that I want.
>
> The calculation result is composed of three rows and N/A columns (dist
> class).
> I do not know how to extract one of the indice in the form of dist class.
> No relevant example is found the manual.
> (I tried as.vector as below but failed.)
>
> Please kindly help and thank you in advance.
>
> Elaine
>
> Code
>  library(betapart)
>   dist.sim<-beta.pair(dataR, index.family="sor")
>
> # Unfold distance matrices into vectors
>   data.sim<-data.frame(as.vector(dist.sim))
>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From S.Ellison at lgcgroup.com  Wed Jul 17 16:53:23 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Wed, 17 Jul 2013 15:53:23 +0100
Subject: [R] Some problems with back to back bar plots in ggplot2
In-Reply-To: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06D9F6EB@mds-exch-02.adf.bham.ac.uk>
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06D9F6EB@mds-exch-02.adf.bham.ac.uk>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACBBF85C5@GOLD.corp.lgc-group.com>

> Hi, I'm making a simple population pyramid using two 
> back-to-back bar plots for 18 different age groups with 
> totals for males and females.

I can run both variants without error, though both throw the same warning regarding stacking beein 'not well defined ..'

However, the axis scaling in your second variant appears to work if you add a limits=(c(-200,200) statement to the y scale, as in

ggplot(data=df,aes(x=df$ag))+geom_bar(subset=.(df$variable=="males"),aes(y=df$value),stat="identity",fill="#330099")+
  geom_bar(subset=.(df$variable=="females"),aes(y=-df$value),stat="identity",fill="#FF9333")+
  scale_y_continuous(limits=c(-200,200), breaks=seq(-200,200,50),labels=abs(seq(-200,200,50)))+
  scale_x_continuous(breaks=seq(1,18,1),labels=abs(seq(1,18,1)))+coord_flip()+
  theme_bw()+xlab("age group")+ylab("population")


I suspect that by specifying the bar values separately from the data supplied in the data statement, you've confused ggplot's automatic scaling somewhere. But you may have to wait on hadley Wickam's input to find out exactly why.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From michel.arnaud at cirad.fr  Wed Jul 17 17:00:25 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 17 Jul 2013 17:00:25 +0200
Subject: [R] Question on plotting with googleVis
In-Reply-To: <CA+dpOJnzY7NSvC2NR7qSn63GG2ELTuLh57a1Nu=gd=RpeLzM+Q@mail.gmail.com>
References: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>
	<51E517CF.9060807@cirad.fr>
	<CA+dpOJnzY7NSvC2NR7qSn63GG2ELTuLh57a1Nu=gd=RpeLzM+Q@mail.gmail.com>
Message-ID: <51E6B189.2090407@cirad.fr>

Hi
You can do a rotation and use gvisColumnChart instead gvisBarChart
plot(gvisColumnChart(MyData, xvar="Names1", yvar=c("Values1",
"Values2"),options=list(width=2500,height=1000)))
Michel



Le 17/07/2013 15:57, Christofer Bogaso a ?crit :
> Hello Arnaud,
>
> Thank you for your pointer. However I need to more clarification.
>
> I want to control the max. and min. values for the x-axis, as well as
> number of vertical gridlines to be displayed. I tried the following:
>
>
> MyData <- data.frame(Names1 = paste("XXX", 1:150), Values1 = 1:150 +
> 10, Values2 = 1:150)
> library(googleVis)
> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1",
> "Values2"),options=list(width=1200,height=1500,hAxis.gridlines =
> "{count: 10}",hAxis.minValue = 0, hAxis.maxValue = 100)))
>
> However this is not clearly working. Can someone point me what went wrong?
>
> Thanks and regards,
>
>
>
>
> On 7/16/13, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>> You can try with list options :
>>
>> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2"),
>> options=list(width=1200,height=1500)))
>>
>>
>>
>> Le 15/07/2013 20:00, Christofer Bogaso a ?crit :
>>> Hello again,
>>>
>>> Let say I have following data-frame:
>>>
>>> MyData <- data.frame(Names1 = paste("XXX", 1:150), Values1 = 1:150 + 10,
>>> Values2 = 1:150)
>>>
>>> Now I want to plot this data-frame with googleVis. Therefore I run
>>> following codes:
>>>
>>> library(googleVis)
>>> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2")))
>>>
>>> However the problem is that, hardly this plot can be read. However if I
>>> plot a fraction of my data-frame then the underlying plot is clearly
>>> visible:
>>>
>>> plot(gvisBarChart(MyData[1:15,], xvar="Names1", yvar=c("Values1",
>>> "Values2")))  ## This is clearly visible.
>>>
>>>
>>> I would really appreciate if someone gives me some pointer how I can
>>> clearly plot my data-frame with googleVis. I understand that there are
>>> many
>>> other plotting methods available with R like ggplot, however here I want
>>> to
>>> use googleVis because of its strength in showing the values within the
>>> plot
>>> area itself if you hover your mouse.
>>>
>>> Thanks and regards,
>>>
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>> --
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From jdnewmil at dcn.davis.CA.us  Wed Jul 17 17:02:27 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 17 Jul 2013 08:02:27 -0700
Subject: [R] Help: Error when installing R 2.8.1 in IBM AIX system
	from	source code
In-Reply-To: <OF2C981413.D6A8B470-ON48257BAB.00336AFA-48257BAB.00364FC8@cn.ibm.com>
References: <OF2C981413.D6A8B470-ON48257BAB.00336AFA-48257BAB.00364FC8@cn.ibm.com>
Message-ID: <effbf650-568b-48c9-bf82-bf709d826e3d@email.android.com>

Help with outdated versions of R, and particularly with nonstandard patch files, are not really on topic here. Posting in HTML format is not advised (see posting guide) since it actually makes it harder to read R code, so text coloring doesn't come through.

It appears to me that your patch failed to make necessary changes to the R source code to be compatible your operating system in step 3. It is possible that you were using an incompatible version of the patch program. You may need to obtain the version of GNU compilers and other toolchain components that were used in developing that particular version of R. You probably need help from a programmer who is familiar with AIX and Unix development to help you interpret the compiler errors and warnings.

With appropriate local technical support for composing questions, you may be able to get more focused answers on the R-devel mailing list rather than here. However, the issue of asking questions about an old version of the R source code may still prove unpopular, so it may be better to study the intent of your existing patch files and try to adapt them to a v3.0.x version before asking for help there.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

De Xin Luan <luandex at cn.ibm.com> wrote:

>
>Hi R-Help,
>
>When we tried to install R 2.8.1 in our AIX system, we faced some
>error,
>please help.
>
>OS level: AIX 7.1 64 bit
>R 2.8.1
>
>We had a guide about How to install R 2.8.1 in AIX from R source code.
>Here
>is what I did:
>
>1.??Download the R source file, for example R-2.8.1.tar.gz , from
>http://www.r-project.org/ (or
>ftp://ftp.stat.math.ethz.ch/Software/CRAN/src/base/R-2/) and save it to
>the
>temporary directory.
>
>2. cd /spss/src
>tar xzf R-2.8.1.tar.gz
>cd R-2.8.1
>
>3.??Download and install the patch from
>http://prs.ism.ac.jp/~nakama/AIX/AIX_R-2.8.1_fix.patch.
>
>mv??AIX_R-2.8.1_fix.patch??/spss/src/R-2.8.1
>chown -R root:system??/spss/src/R-2.8.1
>chmod -R 775??/spss/src/R-2.8.1
>
>zspssdb2was5:/spss/src/R-2.8.1# patch -p1 < AIX_R-2.8.1_fix.patch
>Hmm... ??Looks like a unified context diff to me...
>The text leading up to this was:
>--------------------------
>|diff -ruN R-2.8.1.orig/Makeconf.in R-2.8.1/Makeconf.in
>|--- R-2.8.1.orig/Makeconf.in ?? 2008-10-17 11:05:02.000000000 +0900
>|+++ R-2.8.1/Makeconf.in ?? ?? ?? ??2009-02-19 17:48:17.000000000 +0900
>--------------------------
>Patching file Makeconf.in using Plan A...
>Malformed patch at line 5: ??MAIN_CFLAGS = @MAIN_CFLAGS@
>
>4. Set parameters
>
>export ICONVINC=-I/opt/freeware/include
>export PNGINC=-I/opt/freeware/include
>export JPEGINC=-I/opt/freeware/include
>export ZLIBINC=-I/opt/freeware/include
>export ICONVLIB=-L/opt/freeware/lib
>export PNGLIB=-L/opt/freeware/lib
>export JPEGLIB=-L/opt/freeware/lib
>export ZLIBLIB=-L/opt/freeware/lib
>
>export CC="xlc_r -q64"
>export CXX="xlC_r -q64"
>export CXXFLAGS="-O -qstrict"
>export CFLAGS="-O -qstrict"
>export F77="xlf_r -q64"
>export AR="ar -X64"
>export CPPFLAGS="$ICONVINC $PNGINC $JPEGINC $ZLIBINC
>-I/usr/lpp/X11/include/X11"
>export LDFLAGS="$ICONVLIB $PNGLIB $JPEGLIB $ZLIBLIB -L/usr/lib
>-L/usr/X11R6/lib"
>export OBJECT_MODE="64"
>
>
>
>5. ./configure --prefix=/opt/R-2.8.1??--enable-R-shlib
>--enable-BLAS-shlib
>--with-x --with-readline=no
>
>R is now configured for rs6000-ibm-aix
>
>?? Source directory: ?? ?? ?? ?? ??.
>?? Installation directory: ?? ??/opt/R-2.8.1
>
>?? C compiler: ?? ?? ?? ?? ?? ?? ?? ??xlc_r -q64 ??-O -qstrict
>?? Fortran 77 compiler: ?? ?? ?? xlf_r -q64 ??-g
>
>?? C++ compiler: ?? ?? ?? ?? ?? ?? ??xlC_r -q64 ??-O -qstrict
>?? Fortran 90/95 compiler: ?? ??gfortran
>?? Obj-C compiler:
>
>?? Interfaces supported: ?? ?? ??X11, tcltk
>?? External libraries:
>?? Additional capabilities: ?? TIFF, iconv, MBCS, NLS
>?? Options enabled: ?? ?? ?? ?? ?? shared R library, shared BLAS, R
>profiling,
>Java
>
>?? Recommended packages: ?? ?? ??yes
>
>configure: WARNING: you cannot build DVI versions of the R manuals
>configure: WARNING: you cannot build info or HTML versions of the R
>manuals
>configure: WARNING: you cannot build PDF versions of the R manuals
>configure: WARNING: I could not determine a browser
>configure: WARNING: I could not determine a PDF viewer
>
>
>Issue1: during "configure" step, I faced below error in red, and I take
>below action in blue:
>./configure[20510]: "${}": bad substitution
>at line 20510 of ./configure file, add below line:
>shlibpath_var=LD_LIBRARY_PATH
>
>
>6. make
>
>Issue: during "make" step, I faced the below error in red, I don't know
>how
>to fix it.
>../../../bin/R[206]: "${}": bad substitution
>make: The error code from the last command is 1.
>
>
>Stop.
>
>
>
>Thanks and Best Regards.
>
>
>                                                                       
>De Xin Luan (??? ??????)                                               
>                                     
>Application Developer-- Business Intelligence &      =  What is BAO?   
>                                  
>Performance Management                               = Global BAO Wiki 
>                                  
>BAO Service Line,  As Delivery                       =  China GDC BAO
>Wiki                                
>China Global Delivery                                =  Japan BAO Wiki 
>                                  
>Office: +86,411,88151485 T/L: 61901 Mobile:          =  GCG BAO Wiki   
>                                  
>+86,186,4342,5156                                    =  Sales &
>Delivery                                  
>E-mail: luandex at cn.ibm.com                           =  BOSS (BAO
>Offerings and Solutions Store)          
>                  =  GBS Solutions and Assets                          
>BAO can provide you below products and services:     =  BAO University 
>                                  
>BAO-BIPM: Cognos, BI Reporting Tools, TM1,           =  BAO University
>Virtual Campus                     
>OpenPages, Algorithmic                               =  Smarter
>Analytics University                      
>BAO-EIM: DataStage, Informatica, MDM, Netezza,       =  BAO Tube       
>                                  
>Data Modeler                                         =  Practitioner
>Portal                               
>BAO-DBA: DB2 DBA, Oracle DBA, Sybase DBA             =  IBM CareerSmart
>                                  
>BAO-Advanced Analytics & ECM: SPSS, iLog, BigData                      
>                                  
>and FileNet                                                            
>                                  
>BAO-Strategy & CoC : BAO Strategy, BAO CoC, and                        
>                                  
>BAO Consulting Community                                               
>                                  
>                                                                       
>                                                                       
>                                                                       
>Click here for BAO Service Area contact point.                         
>                                  
>                                                                       
>
>
>
>
>
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul 17 17:06:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 08:06:09 -0700 (PDT)
Subject: [R] Splitting dataframes and cleaning extraneous characters
Message-ID: <1374073569.36658.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,
YOu could try.
?split()
split(ats,ats$Project_NBR)
You also mentioned about two columns.

split(ats,list(ats$col1, ats$col2))

You should have provided an example dataset using ?dput() ( dput(head(data,10)) ) for testing.
Also,

gsub("^-[^-]*-","","-005-190")
#[1] "190"
A.K.




Problem: I have a large data set and need to separate based on factors 
in 2 columns. The final output would be a collection of dataframes 
renamed to 

the corresponding factor levels. ? 

So far I know that for each corresponding factor I can execute 

x190<-ats[which(Project_NBR=='-005-190'),] 

However there are about 400 factors needing to be separated. 
Also, I would like to remove the "-005-". ?Any guidance will be greatly 
appreciated. ?


From ruipbarradas at sapo.pt  Wed Jul 17 17:28:32 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Jul 2013 16:28:32 +0100
Subject: [R] error message in gev
In-Reply-To: <1374069223.16671.YahooMailNeo@web120606.mail.ne1.yahoo.com>
References: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>
	<51E66917.6090905@sapo.pt>
	<1374064426.75463.YahooMailNeo@web120605.mail.ne1.yahoo.com>
	<51E692CB.7010303@sapo.pt>
	<1374069223.16671.YahooMailNeo@web120606.mail.ne1.yahoo.com>
Message-ID: <51E6B820.9030003@sapo.pt>

Hello,

And what if you try it without a block value?

out.list <- lapply(dat, gev)

Rui Barradas

Em 17-07-2013 14:53, Roslina Zakaria escreveu:
> Hi Rui,
> I have tried different block values and below are the error message I got:
>
>>out <- gev(dat, "A")
> Error in as.POSIXlt.default(attributes(data)$times) :
>
>    do not know how to convert 'attributes(data)$times' to class ?POSIXlt?
>
>
>
> out.list <- lapply(dat, gev, block = 10)
> Error in optim(theta, negloglik, hessian = TRUE, ..., tmp = data) :
>    non-finite finite-difference value [2]
>
>
> *From:* Rui Barradas <ruipbarradas at sapo.pt>
> *To:* Roslina Zakaria <zroslina at yahoo.com>
> *Cc:* 'r-help' <r-help at r-project.org>
> *Sent:* Wednesday, July 17, 2013 8:49 PM
> *Subject:* Re: [R] error message in gev
>
> Hello,
>
> It's better if you Cc the list, the odds of getting more and better
> answers are greater.
>
> Have you tried with different block values?
>
> Rui Barradas
>
> Em 17-07-2013 13:33, Roslina Zakaria escreveu:
>  > Hi Rui,
>  > Yes, I am using gev from 'evir'
>  > install.packages("evir")
>  > library(evir)
>  > I have tried your suggestion and follow are what I got.
>  >
>  >>out.list <- lapply(dat, gev, block = 20)
>  > Error in optim(theta, negloglik, hessian = TRUE, ..., tmp = data) :
>  >    non-finite finite-difference value [1]
>  > In addition:Warning messages:
>  > 1: In FUN(X[[7L]], ...) : optimization may not have succeeded
>  > 2: In FUN(X[[7L]], ...) : optimization may not have succeeded
>  > 3: In sqrt(diag(varcov)) : NaNs produced
>  > 4: In FUN(X[[7L]], ...) : optimization may not have succeeded
>  > 5: In FUN(X[[7L]], ...) : optimization may not have succeeded
>  > 6: In FUN(X[[7L]], ...) : optimization may not have succeeded
>  > 7: In FUN(X[[7L]], ...) : optimization may not have succeeded
>  >
>  >
>  >
>  > Thank you.
>  >
>  >
>  > *From:* Rui Barradas <ruipbarradas at sapo.pt <mailto:ruipbarradas at sapo.pt>>
>  > *To:* Roslina Zakaria <zroslina at yahoo.com <mailto:zroslina at yahoo.com>>
>  > *Cc:* "r-help at r-project.org <mailto:r-help at r-project.org>"
> <r-help at r-project.org <mailto:r-help at r-project.org>>
>  > *Sent:* Wednesday, July 17, 2013 5:51 PM
>  > *Subject:* Re: [R] error message in gev
>  >
>  > Hello,
>  >
>  > You should say which package is gev() coming from. I believe it's from
>  > evir, and what follows assumes that.
>  > The problem is that 'dat' is a data.frame, a special type of list. It is
>  > a list of vectors and gev is expecting just one vector. You could try
>  > instead, to fit generalized extreme value distributions to each of the
>  > vectors in the data.frame,
>  >
>  > out.list <- lapply(dat, gev, block = 20)
>  >
>  >
>  > to get a list of 10 objects of class gev, like the help page says.
>  >
>  > Hope this helps,
>  >
>  > Rui Barradas
>  >
>  > Em 17-07-2013 10:33, Roslina Zakaria escreveu:
>  >  >
>  >  > Hi r-users,
>  >  >
>  >  > I would like to use gev and my data (annual rainfall ) is as follows:
>  >  >
>  >  >> head(dat,20)  A    B    C    D    E    F    G    H    I J
>  >  > 1  45.1 41.5 58.5 50.1 46.0 49.1 37.7 49.1 59.8 54.0
>  >  > 2  50.3 39.8 49.4 56.4 49.4 48.8 42.1 49.8 49.4  58.3
>  >  > 3  41.7 39.3 44.6 39.1 35.7 41.5 40.8 40.8 38.5  45.6
>  >  > 4  50.7 33.9 48.4 28.2 35.5 39.1 61.4 17.0 30.7  38.3
>  >  > 5  39.3 30.6 46.9 23.8 25.8 17.1 37.9 40.1 35.4  30.1
>  >  > 6  50.2 43.6 55.5 26.7 36.6 20.6 35.2 46.0 52.2  30.5
>  >  > 7  46.0 37.0 55.3 36.3 51.9 50.6 43.2 44.9 38.2  45.4
>  >  > 8  46.0 15.4 35.7 27.3 40.2 21.2 41.1 65.7 35.7  28.7
>  >  > 9  52.0 36.5 49.6 55.0 38.3 32.0 43.8 43.8 50.3  36.5
>  >  > 10 57.5 51.0 47.0 63.0 43.0 46.5 41.5 82.8 50.5  38.5
>  >  > 11 71.0 48.0 59.5 48.5 47.0 57.5 55.8 64.5 60.0  43.4
>  >  > 12 57.5 52.5 58.5 42.0 62.0 44.0 47.5 59.5 45.0  51.5
>  >  > 13 47.0 38.0 49.9 50.5 55.0 57.5 51.5 54.5 45.0  49.7
>  >  > 14 66.5 44.4 60.0 99.5 54.5 41.3 57.0 69.5 33.0  58.4
>  >  > 15 61.5 43.6 68.5 50.7 48.0 50.5 50.5 58.8 53.2  47.0
>  >  > 16 55.5 58.5 55.5 45.8 48.0 57.0 52.0 48.5 58.5 437.5
>  >  > 17 96.7 96.7 96.7 45.5 65.1 46.5 51.0 96.7 61.3 310.5
>  >  > 18 71.5 55.5 63.0 52.5 59.0 55.5 55.5 51.1 47.0  49.5
>  >  > 19 71.5 42.5 64.0 56.5 61.0 54.0 46.5 53.7 43.0  44.0
>  >  > 20 57.5 51.5 51.3 34.0 55.0 61.0 55.5 51.3 51.3  44.5
>  >  >
>  >  > When I apply the gev function, I have the following error message:
>  >  >
>  >  > out <- gev(dat, 20) Error in gev(dat, 20) : (list) object cannot be
>  > coerced to type 'double'
>  >  >
>  >  > Can anybody explain to me what does it means. I tried to read the
>  > package manual but could not understand about the block.
>  >  >
>  >  > Thank you so much for any help given.
>  >  >    [[alternative HTML version deleted]]
>  >  >
>  >  >
>  >  >
>  >  > ______________________________________________
>  >  > R-help at r-project.org <mailto:R-help at r-project.org>
> <mailto:R-help at r-project.org <mailto:R-help at r-project.org>> mailing list
>  >  > https://stat.ethz.ch/mailman/listinfo/r-help
>  >  > PLEASE do read the posting guide
>  > http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
>  >  > and provide commented, minimal, self-contained, reproducible code.
>  >  >
>  >
>  >
>
>


From g.rudge at bham.ac.uk  Wed Jul 17 17:36:20 2013
From: g.rudge at bham.ac.uk (gavinr)
Date: Wed, 17 Jul 2013 08:36:20 -0700 (PDT)
Subject: [R] Some problems with back to back bar plots in ggplot2
In-Reply-To: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06D9F6EB@mds-exch-02.adf.bham.ac.uk>
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06D9F6EB@mds-exch-02.adf.bham.ac.uk>
Message-ID: <1374075380685-4671765.post@n4.nabble.com>

Thanks, I've now got the plot I was after.  No idea what the stacking warning
is about, but it does not seem to compromise my output.

Gavin.



--
View this message in context: http://r.789695.n4.nabble.com/Some-problems-with-back-to-back-bar-plots-in-ggplot2-tp4671744p4671765.html
Sent from the R help mailing list archive at Nabble.com.


From bogaso.christofer at gmail.com  Wed Jul 17 17:48:01 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Wed, 17 Jul 2013 21:18:01 +0530
Subject: [R] Question on plotting with googleVis
In-Reply-To: <51E6B189.2090407@cirad.fr>
References: <CA+dpOJkcJrXSr6SGkGMvm88U4Ss2_aUqz4fiFSob8zEOyrD7jQ@mail.gmail.com>
	<51E517CF.9060807@cirad.fr>
	<CA+dpOJnzY7NSvC2NR7qSn63GG2ELTuLh57a1Nu=gd=RpeLzM+Q@mail.gmail.com>
	<51E6B189.2090407@cirad.fr>
Message-ID: <CA+dpOJkGjiFUED+hsLtqu_qt9+eyAw08nBKvf0dKbb1kvNTjpg@mail.gmail.com>

Hi Arnaud,

Thanks for your answer.

However I prefer to have Horizontal bar chart, because length of the
strings for x-axis are quite large, therefore it would be better to
put them vertically one-below-another instead horizontally.

Therefore I would really appreciate if someone points me how to
control the max and min values for x-axis.

Thanks and regards,

On 7/17/13, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
> Hi
> You can do a rotation and use gvisColumnChart instead gvisBarChart
> plot(gvisColumnChart(MyData, xvar="Names1", yvar=c("Values1",
> "Values2"),options=list(width=2500,height=1000)))
> Michel
>
>
>
> Le 17/07/2013 15:57, Christofer Bogaso a ?crit :
>> Hello Arnaud,
>>
>> Thank you for your pointer. However I need to more clarification.
>>
>> I want to control the max. and min. values for the x-axis, as well as
>> number of vertical gridlines to be displayed. I tried the following:
>>
>>
>> MyData <- data.frame(Names1 = paste("XXX", 1:150), Values1 = 1:150 +
>> 10, Values2 = 1:150)
>> library(googleVis)
>> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1",
>> "Values2"),options=list(width=1200,height=1500,hAxis.gridlines =
>> "{count: 10}",hAxis.minValue = 0, hAxis.maxValue = 100)))
>>
>> However this is not clearly working. Can someone point me what went
>> wrong?
>>
>> Thanks and regards,
>>
>>
>>
>>
>> On 7/16/13, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>>> You can try with list options :
>>>
>>> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2"),
>>> options=list(width=1200,height=1500)))
>>>
>>>
>>>
>>> Le 15/07/2013 20:00, Christofer Bogaso a ?crit :
>>>> Hello again,
>>>>
>>>> Let say I have following data-frame:
>>>>
>>>> MyData <- data.frame(Names1 = paste("XXX", 1:150), Values1 = 1:150 +
>>>> 10,
>>>> Values2 = 1:150)
>>>>
>>>> Now I want to plot this data-frame with googleVis. Therefore I run
>>>> following codes:
>>>>
>>>> library(googleVis)
>>>> plot(gvisBarChart(MyData, xvar="Names1", yvar=c("Values1", "Values2")))
>>>>
>>>> However the problem is that, hardly this plot can be read. However if I
>>>> plot a fraction of my data-frame then the underlying plot is clearly
>>>> visible:
>>>>
>>>> plot(gvisBarChart(MyData[1:15,], xvar="Names1", yvar=c("Values1",
>>>> "Values2")))  ## This is clearly visible.
>>>>
>>>>
>>>> I would really appreciate if someone gives me some pointer how I can
>>>> clearly plot my data-frame with googleVis. I understand that there are
>>>> many
>>>> other plotting methods available with R like ggplot, however here I
>>>> want
>>>> to
>>>> use googleVis because of its strength in showing the values within the
>>>> plot
>>>> area itself if you hover your mouse.
>>>>
>>>> Thanks and regards,
>>>>
>>>> 	[[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>> --
>>> Michel ARNAUD
>>> Charg? de mission aupr?s du DRH
>>> DGDRD-Drh - TA 174/04
>>> Av Agropolis 34398 Montpellier cedex 5
>>> tel : 04.67.61.75.38
>>> fax : 04.67.61.57.87
>>> port: 06.47.43.55.31
>>>
>>>
>
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
>
>


From Yan_Li at ibi.com  Wed Jul 17 17:56:48 2013
From: Yan_Li at ibi.com (Li, Yan)
Date: Wed, 17 Jul 2013 11:56:48 -0400
Subject: [R] R Package License
Message-ID: <A29EC196EE32C64389369F6BF03B66C86F90DCBF7E@IBIUSMBSB.ibi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/9a4d17a2/attachment.pl>

From wil.louise at gmail.com  Wed Jul 17 15:05:46 2013
From: wil.louise at gmail.com (Louise Wilson)
Date: Wed, 17 Jul 2013 23:05:46 +1000
Subject: [R] Masking oceans using polypath
In-Reply-To: <51E5BE55.5010909@stat.auckland.ac.nz>
References: <CAMxjYa3RDKOcSk7Ms3vrWRaKiNMpek_i=nMawjQmAN3gv4eesA@mail.gmail.com>
	<51E5BE55.5010909@stat.auckland.ac.nz>
Message-ID: <CAMxjYa10ddJtS3SQfLLoQiFJK_hmL3ouo9WQS=WNpkNAdTR97g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/1633d9ae/attachment.pl>

From chrisege at stud.ntnu.no  Wed Jul 17 16:36:42 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Wed, 17 Jul 2013 07:36:42 -0700 (PDT)
Subject: [R] R-squared and GLM
Message-ID: <1374071802773-4671754.post@n4.nabble.com>

Dear users,

I want to compute r-squared values from a glm regression using a gamma
distribution and an "identity" link-function, but find no such thing when
using the summary() or names() function. My next guess was to calculate it
by "hand", i.e.

r2 = (sum((estimate - xbar)^2) /sum((x-xbar)^2)) 

but I am unsure if this is even allowed...

Chris





--
View this message in context: http://r.789695.n4.nabble.com/R-squared-and-GLM-tp4671754.html
Sent from the R help mailing list archive at Nabble.com.


From marc_schwartz at me.com  Wed Jul 17 18:13:02 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 17 Jul 2013 11:13:02 -0500
Subject: [R] R Package License
In-Reply-To: <A29EC196EE32C64389369F6BF03B66C86F90DCBF7E@IBIUSMBSB.ibi.com>
References: <A29EC196EE32C64389369F6BF03B66C86F90DCBF7E@IBIUSMBSB.ibi.com>
Message-ID: <39784593-6E57-4B25-BE84-F26C25CA8087@me.com>

On Jul 17, 2013, at 10:56 AM, "Li, Yan" <Yan_Li at ibi.com> wrote:

> HI Helpers,
> 
> How could we use R and R packages licensed under GPL into commercial products? Is it allowed to load a library and get the results from it and using the results for commercial use? Thank you so much!
> 
> Regards,
> Yan


For R itself:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#Can-I-use-R-for-commercial-purposes_003f

With respect to the GPL more generally, you should review:

  http://www.gnu.org/licenses/gpl-faq.html

and if you still have any questions, consult a lawyer. You will not get definitive legal advice here.

That being said, the GPL does not restrict the *use* of software or source code. It really only comes into play when copying/distributing GPL licensed software and if that is the scenario you are considering, then you should definitely get a lawyer specifically familiar with open source licensing and intellectual property rights.

There are however, some CRAN packages that do restrict commercial use (they are not GPL or compatible) and you should check to see if any of the packages that you are interested in using have such a restriction. In those cases, the actual use of the CRAN package is restricted.

Regards,

Marc Schwartz


From michel.arnaud at cirad.fr  Wed Jul 17 19:21:26 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 17 Jul 2013 19:21:26 +0200
Subject: [R] simplify a dataframe
Message-ID: <51E6D296.9010707@cirad.fr>

Un texte encapsul? et encod? dans un jeu de caract?res inconnu a ?t? nettoy?...
Nom : non disponible
URL : <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/5cf0483d/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 17 19:32:37 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 10:32:37 -0700 (PDT)
Subject: [R] writing multiple lines to a file
In-Reply-To: <1374029611.38676.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1374029611.38676.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1374082357.46463.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
No problem.

You could try:

printer = file("out.txt","w")
?writeLines("This is line.",con=printer,sep=" ")
?writeLines("The same line.",con=printer)
?close(printer)

#or
cat(sprintf("This is line %d. ",1),file="out.txt",append=TRUE)
cat("The same line.",file="out.txt",append=TRUE)

A.K.

Thank you very much, I just have one more simple question. It worked 
with writing "w" when opening the file. However another problem 
occoured, When I wrote \n, it went two lines down, so I had to do this, 
witout \n 

printer = file("out.txt","w") 
write(sprintf("This is line %d.",1),printer,append=T) 
write("This is line 2.",printer,append=T) 
close(printer) 


However, sometimes, I do not want to start on the new line, 
it depends on the situation. That is I may write something to a file. 
And then I want to add to the same line a new string: 
" The same line." Like this. 

printer = file("out.txt","w") 
write(sprintf("This is line %d.",1),printer,append=T) 
write(" The same line.",printer,append=T) 
close(printer) 

But the output is: 
This is line 1. 
?The same line. 


How can I make it stop going to the new line automatically. 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 16, 2013 10:53 PM
Subject: Re: writing multiple lines to a file

HI,
May be this helps:
printer1<- file("out1.txt","w")
write(sprintf("This is line %d.\n",1),printer1,append=TRUE) 
write("This is line 2",printer1,append=TRUE)
close(printer1)

#or


?printer1<- file("out1.txt","w")
writeLines("This is line",con=printer1,sep="\n")
writeLines("This is line 2",con=printer1)
?close(printer1)
A.K.


Hello, I am trying to wrote multiple lines to a file, but I only seem to be able to write the last line. 

printer = file("out.txt") 
write(sprintf("This is line %d.\n",1),printer,append=T) 
write("This is line 2.",printer,append=T) 
close(printer) 

How can I fix this? I would like to be able to do this in a for-loop with hundreds of elements.


From kicco1991 at hotmail.it  Wed Jul 17 19:41:55 2013
From: kicco1991 at hotmail.it (Francesco Miranda)
Date: Wed, 17 Jul 2013 19:41:55 +0200
Subject: [R] truncation and approximation
In-Reply-To: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>
References: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>
Message-ID: <DUB107-W27CC7C8A340D1E748B29A4DE610@phx.gbl>

? stato filtrato un testo allegato il cui set di caratteri non era
indicato...
Nome: non disponibile
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/290a8726/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 17 19:47:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 10:47:00 -0700 (PDT)
Subject: [R] Splitting dataframes and cleaning extraneous characters
In-Reply-To: <1374073569.36658.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1374073569.36658.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <1374083220.66202.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
One problem with using ?subst() would be it depends upon the number of digits, characters etc.? 

For eg.
substring("-005-190",6)
#[1] "190"
?substring("-0057-190",6)
#[1] "-190"

#whereas

gsub("^-[^-]*-","","-0057-190")
#[1] "190"

Probably, your dataset doesn't have that sort of problem.

dat1<- read.table(text="
project boro
123 m
134 k
123 m
123 m
543 q
543 q
134 k
",sep="",header=TRUE,stringsAsFactors=FALSE)
?res<-split(dat1,gsub("\\.","",as.character(interaction(dat1[,2],dat1[,1]))))
?res
$k134
#? project boro
#2???? 134??? k
#7???? 134??? k
#
#$m123
?# project boro
#1???? 123??? m
#3???? 123??? m
#4???? 123??? m
#
#$q543
?# project boro
#5???? 543??? q
#6???? 543??? q
?str(res$k134)
#'data.frame':??? 2 obs. of? 2 variables:
# $ project: int? 134 134
# $ boro?? : chr? "k" "k"
A.K.



I was able to split the extraneous stuff using 

a<-substring(Project_NBR, first=6) 

and then cbind to add the edited column to the df. I have a 
sample but I am not sure how to provide it to you. I will try to produce
 an example that's similar to what I have: 

project	boro 
123	m 
134	k 
123	m 
123 	m 
543	q 
543	q 
134	k 


Basically I am trying to subset the data frame according to 
project and boro with the name of the subset being boro-project (ex. 
m123, k134) 

I hope this provides more clarity to my problem. 


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, July 17, 2013 11:06 AM
Subject: Re: Splitting dataframes and cleaning extraneous characters

Hi,
YOu could try.
?split()
split(ats,ats$Project_NBR)
You also mentioned about two columns.

split(ats,list(ats$col1, ats$col2))

You should have provided an example dataset using ?dput() ( dput(head(data,10)) ) for testing.
Also,

gsub("^-[^-]*-","","-005-190")
#[1] "190"
A.K.




Problem: I have a large data set and need to separate based on factors 
in 2 columns. The final output would be a collection of dataframes 
renamed to 

the corresponding factor levels. ? 

So far I know that for each corresponding factor I can execute 

x190<-ats[which(Project_NBR=='-005-190'),] 

However there are about 400 factors needing to be separated. 
Also, I would like to remove the "-005-". ?Any guidance will be greatly 
appreciated. ?


From ruipbarradas at sapo.pt  Wed Jul 17 19:57:58 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Jul 2013 18:57:58 +0100
Subject: [R] simplify a dataframe
In-Reply-To: <51E6D296.9010707@cirad.fr>
References: <51E6D296.9010707@cirad.fr>
Message-ID: <51E6DB26.60501@sapo.pt>

Hello,

As for question (1), try the following.


y2 <- cumsum(c(TRUE, diff(x1) > 0))
identical(as.integer(y1), y2)  # y1 is of class "numeric"


As for question (2) I'm not understanding it.

Hope this helps,

Rui Barradas

Em 17-07-2013 18:21, Arnaud Michel escreveu:
> Hi Arun
>
> I have two questions always about the question of symplify a dataframe
>
> I would like
> 1)  to transform the vector x1 into the vector y1
> x1 <- c(1,1,1,-1000,         1,-1000,          1,1,1,1,1,1,-1000)
> y1 <- c(1,1,1,1,                    2,2, 3,3,3,3,3,3,3)
>
>
> 2) to transform the vectors Debut and Fin by taking into account INDX
> into the two vectors Deb and Fin
> Debut <- c (
> "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" ,"28/02/1995"
> ,"01/03/1995",
> "13/03/1995", "01/01/1996", "31/01/1996", "24/01/1995", "01/07/1995"
> ,"01/09/1995",
>    "01/07/1997", "01/01/1998", "01/08/1998", "01/01/2000",
> "17/01/2000","29/02/2000")
>
> Fin <- c (
> "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", "28/02/1995",
> "12/03/1995",
> "30/06/1995", "30/01/1996", "31/01/1996", "30/06/1995", "31/08/1995",
> "30/06/1997",
> "31/12/1997", "31/07/1998", "31/12/1999", "16/01/2000", "28/02/2000",
> "29/02/2000")
>
> INDX <- c(6,6,6,                    11,11,11, 4,        5,5)
>
>
> Deb  <- c("*24/01/1995*",     "*02/02/1995*",     "*13/03/1995*",
> "*01/01/1996*")
> Fi n  <-  c("*31/12/1997*", "*12/03/1995*",     "*30/06/1995*",
> "*31/01/1996*")
>
>
>        Debut        Fin INDX
> *24/01/1995* 30/04/1997    6
> 01/05/1997 30/12/1997    6
> 31/12/1997 *31/12/1997*    6
> *02/02/1995* 27/02/1995   11
> 28/02/1995 28/02/1995   11
> 01/03/1995 *12/03/1995*   11
> *13/03/1995* *30/06/1995*    4
> *01/01/1996* 30/01/1996    5
> 31/01/1996 *31/01/1996*    5
> ................
>
> Thanks for your help
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ivo.welch at anderson.ucla.edu  Wed Jul 17 20:14:09 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Wed, 17 Jul 2013 11:14:09 -0700
Subject: [R] C Interface in R
Message-ID: <CAPr7RtX5KGHqbJ8Gn=rJarSiHn-b=yTnEM0UBC77Ht_prOvFWg@mail.gmail.com>

Dear R Users---

I spent some time implementing the AS75 WLS regression algorithm in C
in order to learn the R interface to C.  I did not find an easy, brief
C+R example of an algorithm that used persistent storage across calls.
 they probably exist, but I could not find a nice brief template for
me to start from, for learning purposes.  thus, I thought I would
share my own learning template example, which you can see in
http://R.ivo-welch.info/ .  as I will probably find small bugs, I will
update the file.  for the google cache of the r-help mailing list, I
am also enclosing the example below.  best to be ignored.

/iaw

----
Ivo Welch (ivo.welch at gmail.com)




--- the as75.R file, at least as of july 2013

###  see end of file for documentation

debug <- 0

if (debug) cat(rep("\n",10))  ## visual separation

dyn.load("Ras75.so")   # created with R CMD SHLIB -o Ras75.so Ras75.c

list.of.names <-  c("np.no.nrbar", "d", "rbar", "thetab", "ss.et")

################################################################
as75.new <- function(k) {
    stopifnot(k>1)  ## we need more than 1 variable to be interesting
    nrbar <- (k-1)*k/2
    object <- list( "np.no.nrbar"= c(k,0,nrbar), "d"= rep(0, k),
                   "rbar"= rep(0, nrbar), "thetab"= rep(0, k),
"ss.et"= rep(0, 2) );
    stopifnot( names(object) == list.of.names )
    class(object) <- "as75"
    object
}

################################################################
as75.include <- function(as75obj, weight, y, x ) {
    stopifnot(class(as75obj)=="as75")
    stopifnot( is.numeric(weight) & (length(weight)==1))
    stopifnot( is.numeric(y) & (length(y)==1))
    stopifnot( is.numeric(x) & (length(x)==as75obj[["np"]]))

    retobj <- .C("Ras75include",
                 ## start is persistent structure objects
                 as.integer( as75obj[[ "np.no.nrbar" ]]),
                 as.double( as75obj[[ "d" ]]),
                 as.double( as75obj[[ "rbar" ]]),
                 as.double( as75obj[[ "thetab" ]]),
                 as.double( as75obj[[ "ss.et" ]]),
                 ## rest are inputs
                 as.double(weight),
                 as.double(y),
                 as.double(x)
                 )

    retobj <- retobj[1:length(list.of.names)]  ## we no longer need
the last inputs, and the old
inputs are now obsolete

    names(retobj) <- list.of.names
    class(retobj) <- "as75"
    retobj
}

################################################################
as75.calcresults <- function(as75obj) {
    stopifnot(class(as75obj)=="as75")
    results.coefs <- rep(0, (as75obj[["np.no.nrbar"]])[1] )  ## allocate storage
    results.rsq <- c(-1,-1)
    results.N <- c(0)
    retobj <- .C("Ras75regress",
                 as.integer( as75obj[[ "np.no.nrbar" ]]),
                 as.double( as75obj[[ "d" ]]),
                 as.double( as75obj[[ "rbar" ]]),
                 as.double( as75obj[[ "thetab" ]]),
                 as.double( as75obj[[ "ss.et" ]]),
                 ## this is an output
                 coefs=as.double(results.coefs),
                 rsq=as.double(results.rsq),
                 N=as.integer(results.N)
                 )

    names(retobj) <- c(list.of.names, "coefs", "rsq", "N")
    class(retobj) <- "as75"
    retobj
}


################################################################
### The main program
################################################################

x2 <- c(3,5,31,11)
x3 <- c(-1,2,0,2)
y <- c(2,1,20,15)

as75o <- as75.new(3)   ## create storage
if (debug) { cat("[0] post new\n"); str(as75o) }

for (i in 1:length(y)) {
    as75o <- as75.include(as75o, weight=1,  y=y[i], x=c( 1.0,  x2[i],
x3[i] ))  ## include an obs
    if (debug) { cat("\n[",i,"] include y=", y[i], "on (1", x2[i],
x3[i], ")\n"); str(as75o) }
}

as75o <- as75.calcresults(as75o)  ## this will add a few elements to the list
cat("\n\n[5] Results:  Coefs=", as75o[["coefs"]], "  R^2=",
as75o[["rsq"]],  "  N=", as75o[["N"]]
, "\n" )

cat("\n\n The contents of the structure, initialized in R but
calculated in C, are\n")
str(as75o)




#################################################################################################
###############################
c(title='R AS75 in C',
  author='ivo.welch at gmail.com',
  date='2013',
  description='implements the WLS AS75 algorithm in C for R',
  usage='outside R:
     $ R CMD SHLIB Ras75.c   ## this creates Ras75.so (the shared
library $ R ...
inside R:
     > source("as75.R")
',
  arguments='',
  details='Example of C interface of R with a structure

 AS75 is an implementation of a sequential regression algorithm by WM
   Gentlemen, published in Applied Statistics 1974.  It makes it possible
   to include or remove observations and feed an infinite number of
   observations with R.  For more information, look it up.

 However, the main purpose here is to provides an example
   with multiple structures and use of the C interface in R.
   It may be quite clumsy, because this is my first use of
   this interface.

',
  seealso='',
  examples='',
  test= '',
  changes= '',
  version='0.0 --- july 2013')




------------ and the .C file Ras75.c

#include <R.h>
#include <Rmath.h>
#include <Rinternals.h>

#define iszero(x) (fabs(x)<1e-8)

/****************************************************************
 * R as75 interface.  AS75 is an implementation of a sequential
 *   regression algorithm by WM Gentlemen, published in Applied
 *   Statistics 1974.  It makes it possible to include or remove
 *   observations and feed an infinite number of observations
 *   with R.  For more information, look it up.
 *
 * However, the main purpose here is to provides an example with
 * multiple structures and use of the C interface in R.  It may
 * be quite clumsy, because this is my first use of this
 * interface.
 *
 * Use as follows:
 *
 *    $ R CMD SHLIB Ras75.c
 *      ## this creates Ras75.so (the shared library
 *    $ R
 *    ...
 *    > source("as75.R")
 *
 ****************************************************************/



/****************************************************************
 * Ras75include includes one observation in the regression.  All
 * variables passed into C by R can be modified.  In the R
 * interface to C, there are no return values afaik.
 ****************************************************************/

void Ras75include( int *npnonrbar, double *d, double *rbar, double
*thetab, double *sset,
  const double *w_in, const double *y_in, const double *x_in ) {


  // the input variables will be changed, so we need to copy them first
  const int np= npnonrbar[0]; const int nrbar= npnonrbar[2];

  double w= (*w_in);
  double y= (*y_in);
  double x[ np ];
  for (int i=0; i< np; ++i) x[i]= x_in[i];

  // announce your presence
  const int debug=0;
  if (debug) printf("\n[Ras75.c w=%.4lf y=%.4lf x=%.4lf %.4lf
%.4lf]\n", w, y, 1.0, x[1], x[2]);

  // this is useless.  R does not allow passing in NaN
  // if (isnan(y)) return; for (int i=0; i<(np); ++i) if (isnan(x[i])) return;

  if (iszero(w)) return;

  sset[1] += w * y * y;
  ++(npnonrbar[1]); // this is numobs

  for (int i1 = 0; i1 < np; ++i1) {
    if (iszero(w)) return;  // this is a necessary test.  weight will
be changed in loop
    if (iszero(x[i1])) continue;

    const double xi = x[i1];
    const double di = d[i1];
    const double dpi = di + w * xi * xi;
    const double cbar = di / dpi;
    const double sbar = w * xi / dpi;
    w = cbar * w;
    d[i1] = dpi;

    if (i1 <= np ) {
      int nextr = i1 * ( np  +  np  - (i1+1)) / 2;
      for (int k = (i1+1); k < np; ++k) {
        const double xk = x[k]; // temporary storage
        x[k] = xk - xi * rbar[nextr];
        rbar[nextr] = cbar * rbar[nextr] + sbar * xk;
        ++nextr;
      }
    }
    const double xk = y;
    y = xk - xi * thetab[i1];
    thetab[i1] = cbar * thetab[i1] + sbar * xk;
  }
  sset[0] += w * y * y;
}


/****************************************************************
 * Ras75regress calculates the results, primarily the
 * coefficient vector and the R^2.  In the R interface to C,
 * there are no return values afaik.
 ****************************************************************/

void Ras75regress( const int *npnonrbar, const double *d,
  const double *rbar, const double *thetab, const double *sset,
  double *coef, double *rsq, int *N ) {

  const int np= npnonrbar[0]; const int no= npnonrbar[1];

  for (int j=0; j < (np); ++j) {
    const int npmj= (np) - j;
    coef[npmj-1] = thetab[npmj-1];
    int nextr = (npmj - 1) * ( (np)  +  (np)  - npmj) / 2;
    for (int k = npmj; k < (np) ; ++k) {
      coef[npmj-1] -= rbar[nextr] * coef[k];
      ++nextr;
    }
  }
  rsq[0] = 1.0- sset[0]/sset[1];
  rsq[1] = 1.0- (1-sset[0]/sset[1])*((no)-1)/((no)-(np));
  *N = no;
}


From kristi.glover at hotmail.com  Wed Jul 17 20:48:59 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 17 Jul 2013 15:48:59 -0300
Subject: [R] How to open .WTG file Extension in R?
Message-ID: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/3ef58693/attachment.pl>

From gunter.berton at gene.com  Wed Jul 17 21:00:58 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 17 Jul 2013 12:00:58 -0700
Subject: [R] How to open .WTG file Extension in R?
In-Reply-To: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>
References: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>
Message-ID: <CACk-te0pt5M+fBp5M6yK3XYuKZEmTHPD+EnYunaT5y29uKFsFg@mail.gmail.com>

I am wondering what .WTG files have to do with R.

Care to elaborate? (Suggestion: Read and follow the posting guide)

Cheers,
Bert

On Wed, Jul 17, 2013 at 11:48 AM, Kristi Glover
<kristi.glover at hotmail.com> wrote:
> Hi R user,
> I am wondering  how we can open the data file which have .WTG extension?
> Thanks for your help
> cheers,
> KG
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From marc_schwartz at me.com  Wed Jul 17 21:04:03 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 17 Jul 2013 14:04:03 -0500
Subject: [R] How to open .WTG file Extension in R?
In-Reply-To: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>
References: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>
Message-ID: <6921B3CA-E921-4B53-B240-8CA47092B9FE@me.com>

On Jul 17, 2013, at 1:48 PM, Kristi Glover <kristi.glover at hotmail.com> wrote:

> Hi R user,
> I am wondering  how we can open the data file which have .WTG extension?
> Thanks for your help
> cheers,
> KG


A quick search led me to http://wasptechnical.dk/Forum/viewtopic.php?id=433, which suggests that the .WTG extension may refer to either an XML file created by WAsP or a binary file created by WindPro. So it will depend upon the source of the file(s) you have.

One possibility vis-a-vis R, seems to be in the CRAN package bReeze:

  http://cran.r-project.org/web/packages/bReeze/

by using the readPC() function therein.

Regards,

Marc Schwartz


From kristi.glover at hotmail.com  Wed Jul 17 21:04:39 2013
From: kristi.glover at hotmail.com (Kristi Glover)
Date: Wed, 17 Jul 2013 16:04:39 -0300
Subject: [R] How to open .WTG file Extension in R?
In-Reply-To: <CACk-te0pt5M+fBp5M6yK3XYuKZEmTHPD+EnYunaT5y29uKFsFg@mail.gmail.com>
References: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>,
	<CACk-te0pt5M+fBp5M6yK3XYuKZEmTHPD+EnYunaT5y29uKFsFg@mail.gmail.com>
Message-ID: <BAY154-W2992F747914B5BE158AE73FA610@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/95b4382e/attachment.pl>

From dcarlson at tamu.edu  Wed Jul 17 21:29:19 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 17 Jul 2013 14:29:19 -0500
Subject: [R] How to open .WTG file Extension in R?
In-Reply-To: <BAY154-W2992F747914B5BE158AE73FA610@phx.gbl>
References: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>,
	<CACk-te0pt5M+fBp5M6yK3XYuKZEmTHPD+EnYunaT5y29uKFsFg@mail.gmail.com>
	<BAY154-W2992F747914B5BE158AE73FA610@phx.gbl>
Message-ID: <00d901ce8323$eeca4350$cc5ec9f0$@tamu.edu>

That reduces the number of possibilities for the file structure to
ones that R can probably read, but we need to know more. Try opening
a sample file in a text editor to see if it is plain text. If so,
you can probably use read.table() or read.csv() to get the file into
R. If not, you will need one of the packages that can read Excel
files.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Kristi Glover
Sent: Wednesday, July 17, 2013 2:05 PM
To: Bert Gunter
Cc: R-help
Subject: Re: [R] How to open .WTG file Extension in R?

Hi Bert, 
This is the data related to climate. I can open it in Excel but the
problem is I do have 190 files . 
thanks



> Date: Wed, 17 Jul 2013 12:00:58 -0700
> Subject: Re: [R] How to open .WTG file Extension in R?
> From: gunter.berton at gene.com
> To: kristi.glover at hotmail.com
> CC: r-help at r-project.org
> 
> I am wondering what .WTG files have to do with R.
> 
> Care to elaborate? (Suggestion: Read and follow the posting guide)
> 
> Cheers,
> Bert
> 
> On Wed, Jul 17, 2013 at 11:48 AM, Kristi Glover
> <kristi.glover at hotmail.com> wrote:
> > Hi R user,
> > I am wondering  how we can open the data file which have .WTG
extension?
> > Thanks for your help
> > cheers,
> > KG
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible
code.
> 
> 
> 
> -- 
> 
> Bert Gunter
> Genentech Nonclinical Biostatistics
> 
> Internal Contact Info:
> Phone: 467-7374
> Website:
>
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/p
db-biostatistics/pdb-ncb-home.htm
 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jul 17 21:31:38 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Jul 2013 20:31:38 +0100
Subject: [R] truncation and approximation
In-Reply-To: <DUB107-W27CC7C8A340D1E748B29A4DE610@phx.gbl>
References: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>
	<DUB107-W27CC7C8A340D1E748B29A4DE610@phx.gbl>
Message-ID: <51E6F11A.5000508@sapo.pt>

Hello,

As for truncation, you can write a one line function:

dec_trunc <- function(x, digits = 0) trunc(x * 10^digits)/10^digits


As for approximation, maybe you're looking for ?signif.

Hope this helps,

Rui Barradas

Em 17-07-2013 18:41, Francesco Miranda escreveu:
> What is the function to do the truncation to a certain decimal digit of a number. And the function approximation? 		 	   		
> Thanks.
> Francesco M 		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Wed Jul 17 21:34:46 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Jul 2013 20:34:46 +0100
Subject: [R] How to open .WTG file Extension in R?
In-Reply-To: <BAY154-W2992F747914B5BE158AE73FA610@phx.gbl>
References: <BAY154-W1B0CC382ACD669A7A4877FA610@phx.gbl>,
	<CACk-te0pt5M+fBp5M6yK3XYuKZEmTHPD+EnYunaT5y29uKFsFg@mail.gmail.com>
	<BAY154-W2992F747914B5BE158AE73FA610@phx.gbl>
Message-ID: <51E6F1D6.9020003@sapo.pt>

Hello,

So it's a XML file, like Marc said. See package XML.


install.packages('XML', dependencies = TRUE)

Hope this helps,

Rui Barradas

Em 17-07-2013 20:04, Kristi Glover escreveu:
> Hi Bert,
> This is the data related to climate. I can open it in Excel but the problem is I do have 190 files .
> thanks
>
>
>
>> Date: Wed, 17 Jul 2013 12:00:58 -0700
>> Subject: Re: [R] How to open .WTG file Extension in R?
>> From: gunter.berton at gene.com
>> To: kristi.glover at hotmail.com
>> CC: r-help at r-project.org
>>
>> I am wondering what .WTG files have to do with R.
>>
>> Care to elaborate? (Suggestion: Read and follow the posting guide)
>>
>> Cheers,
>> Bert
>>
>> On Wed, Jul 17, 2013 at 11:48 AM, Kristi Glover
>> <kristi.glover at hotmail.com> wrote:
>>> Hi R user,
>>> I am wondering  how we can open the data file which have .WTG extension?
>>> Thanks for your help
>>> cheers,
>>> KG
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> --
>>
>> Bert Gunter
>> Genentech Nonclinical Biostatistics
>>
>> Internal Contact Info:
>> Phone: 467-7374
>> Website:
>> http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm
>   		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From michel.arnaud at cirad.fr  Wed Jul 17 22:03:34 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 17 Jul 2013 22:03:34 +0200
Subject: [R] simplify a dataframe
In-Reply-To: <51E6DB26.60501@sapo.pt>
References: <51E6D296.9010707@cirad.fr> <51E6DB26.60501@sapo.pt>
Message-ID: <51E6F896.5000903@cirad.fr>

  Thank you for the question (1)
Sorry for the imprecision for the question (2) :
Suppose the date frame df
df1 <- data.frame(
Debut =c ( "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" 
,"28/02/1995"
,"01/03/1995", "13/03/1995", "01/01/1996", "31/01/1996") ,
Fin = c ( "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", 
"28/02/1995",
"12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996") ,
INDX = c(6,6,6,  11,11,11, 4,  5,5) )


I would like replace df1  by df2

df2 <- data.frame(
Deb  = c("24/01/1995",     "02/02/1995",     "13/03/1995",
"01/01/1996") ,
Fin  = c("31/12/1997", "12/03/1995",     "30/06/1995",
"31/01/1996") )

Explication :
The lines 1, 2 3 of df1 (who have same value of index =6) are replaced 
by only one line with
value of Debut of df2 = Debut of line 1 of df1
value of Fin of df2 = Fin of line 3 of df1

The lines 4,5,6 of df1 (who have same value of index =11) are replaced 
by only one line with
value of Debut of df2 = Debut of line 4 of df1
and value of fin of df2 = Fin of line 6 of df1

The line 7 of df1 (who have same value of index =4) are replaced by only 
one line with
value of Debut of df2 = Debut of line 7of df1
and value of fin of df2 = Fin of line 7of df1
==> No change

The lines 8,9 of df1 (who have same value of index =5) are replaced by 
only one line with
value of Debut of df2 = Debut of line 8of df1
and value of fin of df2 = Fin of line 9 of df1

df1
        Debut        Fin INDX
1 24/01/1995 30/04/1997    6
2 01/05/1997 30/12/1997    6
3 31/12/1997 31/12/1997    6
4 02/02/1995 27/02/1995   11
5 28/02/1995 28/02/1995   11
6 01/03/1995 12/03/1995   11
7 13/03/1995 30/06/1995    4
8 01/01/1996 30/01/1996    5
9 31/01/1996 31/01/1996    5

          Deb        Fin
1 24/01/1995 31/12/1997
2 02/02/1995 12/03/1995
3 13/03/1995 30/06/1995
4 01/01/1996 31/01/1996
Thank you for your helps
Michel

Le 17/07/2013 19:57, Rui Barradas a ?crit :
> Hello,
>
> As for question (1), try the following.
>
>
> y2 <- cumsum(c(TRUE, diff(x1) > 0))
> identical(as.integer(y1), y2)  # y1 is of class "numeric"
>
>
> As for question (2) I'm not understanding it.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 17-07-2013 18:21, Arnaud Michel escreveu:
>> Hi Arun
>>
>> I have two questions always about the question of symplify a dataframe
>>
>> I would like
>> 1)  to transform the vector x1 into the vector y1
>> x1 <- c(1,1,1,-1000,         1,-1000, 1,1,1,1,1,1,-1000)
>> y1 <- c(1,1,1,1,                    2,2, 3,3,3,3,3,3,3)
>>
>>
>> 2) to transform the vectors Debut and Fin by taking into account INDX
>> into the two vectors Deb and Fin
>> Debut <- c (
>> "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" ,"28/02/1995"
>> ,"01/03/1995",
>> "13/03/1995", "01/01/1996", "31/01/1996", "24/01/1995", "01/07/1995"
>> ,"01/09/1995",
>>    "01/07/1997", "01/01/1998", "01/08/1998", "01/01/2000",
>> "17/01/2000","29/02/2000")
>>
>> Fin <- c (
>> "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", "28/02/1995",
>> "12/03/1995",
>> "30/06/1995", "30/01/1996", "31/01/1996", "30/06/1995", "31/08/1995",
>> "30/06/1997",
>> "31/12/1997", "31/07/1998", "31/12/1999", "16/01/2000", "28/02/2000",
>> "29/02/2000")
>>
>> INDX <- c(6,6,6,                    11,11,11, 4,        5,5)
>>
>>
>> Deb  <- c("*24/01/1995*",     "*02/02/1995*", "*13/03/1995*",
>> "*01/01/1996*")
>> Fi n  <-  c("*31/12/1997*", "*12/03/1995*", "*30/06/1995*",
>> "*31/01/1996*")
>>
>>
>>        Debut        Fin INDX
>> *24/01/1995* 30/04/1997    6
>> 01/05/1997 30/12/1997    6
>> 31/12/1997 *31/12/1997*    6
>> *02/02/1995* 27/02/1995   11
>> 28/02/1995 28/02/1995   11
>> 01/03/1995 *12/03/1995*   11
>> *13/03/1995* *30/06/1995*    4
>> *01/01/1996* 30/01/1996    5
>> 31/01/1996 *31/01/1996*    5
>> ................
>>
>> Thanks for your help
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From wewolski at gmail.com  Wed Jul 17 22:04:52 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 17 Jul 2013 22:04:52 +0200
Subject: [R] anti off diagonal min max mean - how to rotate matrix by 90
	degree
Message-ID: <CAAjnpdhY5xLd0oae62_sTjg6Syu70uqDEwc6pEX7gGnQf2U9AQ@mail.gmail.com>

How can id do this efficiently in R ?

1 0 0
0 2 0
0 0 3


rotate right
0 0 1
0 2 0
3 0 0
rotate left
0 0 3
0 2 0
1 0 0

What I want to do is described here:
http://stackoverflow.com/questions/13049575/r-min-max-and-mean-of-off-diagonal-elements-in-a-matrix

but I want do to it for all off-anti-diagonals.

I am also concerned that the method described on stackoverflow isn't
necessarily efficient.
I work with matrices of size 3k * 3k.


--
Witold Eryk Wolski


From smartpink111 at yahoo.com  Wed Jul 17 22:14:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 13:14:48 -0700 (PDT)
Subject: [R] simplify a dataframe
In-Reply-To: <51E6F896.5000903@cirad.fr>
References: <51E6D296.9010707@cirad.fr> <51E6DB26.60501@sapo.pt>
	<51E6F896.5000903@cirad.fr>
Message-ID: <1374092088.72407.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
You could try:

df1[,1:2]<-lapply(df1[,1:2],as.character)
?df2New<- data.frame(Deb=unique(with(df1,ave(Debut,INDX,FUN=function(x) head(x,1)))),Fin=unique(with(df1,ave(Fin,INDX,FUN=function(x) tail(x,1)))))
identical(df2New,df2)
#[1] TRUE

A.K.


----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: Rui Barradas <ruipbarradas at sapo.pt>; R help <r-help at r-project.org>; arun <smartpink111 at yahoo.com>
Cc: 
Sent: Wednesday, July 17, 2013 4:03 PM
Subject: Re: [R] simplify a dataframe

? Thank you for the question (1)
Sorry for the imprecision for the question (2) :
Suppose the date frame df
df1 <- data.frame(
Debut =c ( "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" 
,"28/02/1995"
,"01/03/1995", "13/03/1995", "01/01/1996", "31/01/1996") ,
Fin = c ( "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", 
"28/02/1995",
"12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996") ,
INDX = c(6,6,6,? 11,11,11, 4,? 5,5) )


I would like replace df1? by df2

df2 <- data.frame(
Deb? = c("24/01/1995",? ?  "02/02/1995",? ?  "13/03/1995",
"01/01/1996") ,
Fin? = c("31/12/1997", "12/03/1995",? ?  "30/06/1995",
"31/01/1996") )

Explication :
The lines 1, 2 3 of df1 (who have same value of index =6) are replaced 
by only one line with
value of Debut of df2 = Debut of line 1 of df1
value of Fin of df2 = Fin of line 3 of df1

The lines 4,5,6 of df1 (who have same value of index =11) are replaced 
by only one line with
value of Debut of df2 = Debut of line 4 of df1
and value of fin of df2 = Fin of line 6 of df1

The line 7 of df1 (who have same value of index =4) are replaced by only 
one line with
value of Debut of df2 = Debut of line 7of df1
and value of fin of df2 = Fin of line 7of df1
==> No change

The lines 8,9 of df1 (who have same value of index =5) are replaced by 
only one line with
value of Debut of df2 = Debut of line 8of df1
and value of fin of df2 = Fin of line 9 of df1

df1
? ? ? ? Debut? ? ? ? Fin INDX
1 24/01/1995 30/04/1997? ? 6
2 01/05/1997 30/12/1997? ? 6
3 31/12/1997 31/12/1997? ? 6
4 02/02/1995 27/02/1995?  11
5 28/02/1995 28/02/1995?  11
6 01/03/1995 12/03/1995?  11
7 13/03/1995 30/06/1995? ? 4
8 01/01/1996 30/01/1996? ? 5
9 31/01/1996 31/01/1996? ? 5

? ? ? ? ? Deb? ? ? ? Fin
1 24/01/1995 31/12/1997
2 02/02/1995 12/03/1995
3 13/03/1995 30/06/1995
4 01/01/1996 31/01/1996
Thank you for your helps
Michel

Le 17/07/2013 19:57, Rui Barradas a ?crit :
> Hello,
>
> As for question (1), try the following.
>
>
> y2 <- cumsum(c(TRUE, diff(x1) > 0))
> identical(as.integer(y1), y2)? # y1 is of class "numeric"
>
>
> As for question (2) I'm not understanding it.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 17-07-2013 18:21, Arnaud Michel escreveu:
>> Hi Arun
>>
>> I have two questions always about the question of symplify a dataframe
>>
>> I would like
>> 1)? to transform the vector x1 into the vector y1
>> x1 <- c(1,1,1,-1000,? ? ? ?  1,-1000, 1,1,1,1,1,1,-1000)
>> y1 <- c(1,1,1,1,? ? ? ? ? ? ? ? ? ? 2,2, 3,3,3,3,3,3,3)
>>
>>
>> 2) to transform the vectors Debut and Fin by taking into account INDX
>> into the two vectors Deb and Fin
>> Debut <- c (
>> "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" ,"28/02/1995"
>> ,"01/03/1995",
>> "13/03/1995", "01/01/1996", "31/01/1996", "24/01/1995", "01/07/1995"
>> ,"01/09/1995",
>>? ? "01/07/1997", "01/01/1998", "01/08/1998", "01/01/2000",
>> "17/01/2000","29/02/2000")
>>
>> Fin <- c (
>> "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", "28/02/1995",
>> "12/03/1995",
>> "30/06/1995", "30/01/1996", "31/01/1996", "30/06/1995", "31/08/1995",
>> "30/06/1997",
>> "31/12/1997", "31/07/1998", "31/12/1999", "16/01/2000", "28/02/2000",
>> "29/02/2000")
>>
>> INDX <- c(6,6,6,? ? ? ? ? ? ? ? ? ? 11,11,11, 4,? ? ? ? 5,5)
>>
>>
>> Deb? <- c("*24/01/1995*",? ?  "*02/02/1995*", "*13/03/1995*",
>> "*01/01/1996*")
>> Fi n? <-? c("*31/12/1997*", "*12/03/1995*", "*30/06/1995*",
>> "*31/01/1996*")
>>
>>
>>? ? ? ? Debut? ? ? ? Fin INDX
>> *24/01/1995* 30/04/1997? ? 6
>> 01/05/1997 30/12/1997? ? 6
>> 31/12/1997 *31/12/1997*? ? 6
>> *02/02/1995* 27/02/1995?  11
>> 28/02/1995 28/02/1995?  11
>> 01/03/1995 *12/03/1995*?  11
>> *13/03/1995* *30/06/1995*? ? 4
>> *01/01/1996* 30/01/1996? ? 5
>> 31/01/1996 *31/01/1996*? ? 5
>> ................
>>
>> Thanks for your help
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From smartpink111 at yahoo.com  Wed Jul 17 22:20:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 13:20:35 -0700 (PDT)
Subject: [R] simplify a dataframe
In-Reply-To: <1374092088.72407.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <51E6D296.9010707@cirad.fr> <51E6DB26.60501@sapo.pt>
	<51E6F896.5000903@cirad.fr>
	<1374092088.72407.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1374092435.3165.YahooMailNeo@web142603.mail.bf1.yahoo.com>

#or
library(plyr)
res<-ddply(df1,.(INDX),summarize,Debut=head(Debut,1),Fin=tail(Fin,1))
res$INDX<-factor(res$INDX,levels=unique(df1$INDX))
res[order(res$INDX),-1]
#?????? Debut??????? Fin
#3 24/01/1995 31/12/1997
#4 02/02/1995 12/03/1995
#1 13/03/1995 30/06/1995
#2 01/01/1996 31/01/1996
A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Arnaud Michel <michel.arnaud at cirad.fr>
Cc: R help <r-help at r-project.org>; Rui Barradas <ruipbarradas at sapo.pt>
Sent: Wednesday, July 17, 2013 4:14 PM
Subject: Re: [R] simplify a dataframe

Hi,
You could try:

df1[,1:2]<-lapply(df1[,1:2],as.character)
?df2New<- data.frame(Deb=unique(with(df1,ave(Debut,INDX,FUN=function(x) head(x,1)))),Fin=unique(with(df1,ave(Fin,INDX,FUN=function(x) tail(x,1)))))
identical(df2New,df2)
#[1] TRUE

A.K.


----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: Rui Barradas <ruipbarradas at sapo.pt>; R help <r-help at r-project.org>; arun <smartpink111 at yahoo.com>
Cc: 
Sent: Wednesday, July 17, 2013 4:03 PM
Subject: Re: [R] simplify a dataframe

? Thank you for the question (1)
Sorry for the imprecision for the question (2) :
Suppose the date frame df
df1 <- data.frame(
Debut =c ( "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" 
,"28/02/1995"
,"01/03/1995", "13/03/1995", "01/01/1996", "31/01/1996") ,
Fin = c ( "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", 
"28/02/1995",
"12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996") ,
INDX = c(6,6,6,? 11,11,11, 4,? 5,5) )


I would like replace df1? by df2

df2 <- data.frame(
Deb? = c("24/01/1995",? ?? "02/02/1995",? ?? "13/03/1995",
"01/01/1996") ,
Fin? = c("31/12/1997", "12/03/1995",? ?? "30/06/1995",
"31/01/1996") )

Explication :
The lines 1, 2 3 of df1 (who have same value of index =6) are replaced 
by only one line with
value of Debut of df2 = Debut of line 1 of df1
value of Fin of df2 = Fin of line 3 of df1

The lines 4,5,6 of df1 (who have same value of index =11) are replaced 
by only one line with
value of Debut of df2 = Debut of line 4 of df1
and value of fin of df2 = Fin of line 6 of df1

The line 7 of df1 (who have same value of index =4) are replaced by only 
one line with
value of Debut of df2 = Debut of line 7of df1
and value of fin of df2 = Fin of line 7of df1
==> No change

The lines 8,9 of df1 (who have same value of index =5) are replaced by 
only one line with
value of Debut of df2 = Debut of line 8of df1
and value of fin of df2 = Fin of line 9 of df1

df1
? ? ? ? Debut? ? ? ? Fin INDX
1 24/01/1995 30/04/1997? ? 6
2 01/05/1997 30/12/1997? ? 6
3 31/12/1997 31/12/1997? ? 6
4 02/02/1995 27/02/1995?? 11
5 28/02/1995 28/02/1995?? 11
6 01/03/1995 12/03/1995?? 11
7 13/03/1995 30/06/1995? ? 4
8 01/01/1996 30/01/1996? ? 5
9 31/01/1996 31/01/1996? ? 5

? ? ? ? ? Deb? ? ? ? Fin
1 24/01/1995 31/12/1997
2 02/02/1995 12/03/1995
3 13/03/1995 30/06/1995
4 01/01/1996 31/01/1996
Thank you for your helps
Michel

Le 17/07/2013 19:57, Rui Barradas a ?crit :
> Hello,
>
> As for question (1), try the following.
>
>
> y2 <- cumsum(c(TRUE, diff(x1) > 0))
> identical(as.integer(y1), y2)? # y1 is of class "numeric"
>
>
> As for question (2) I'm not understanding it.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 17-07-2013 18:21, Arnaud Michel escreveu:
>> Hi Arun
>>
>> I have two questions always about the question of symplify a dataframe
>>
>> I would like
>> 1)? to transform the vector x1 into the vector y1
>> x1 <- c(1,1,1,-1000,? ? ? ?? 1,-1000, 1,1,1,1,1,1,-1000)
>> y1 <- c(1,1,1,1,? ? ? ? ? ? ? ? ? ? 2,2, 3,3,3,3,3,3,3)
>>
>>
>> 2) to transform the vectors Debut and Fin by taking into account INDX
>> into the two vectors Deb and Fin
>> Debut <- c (
>> "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" ,"28/02/1995"
>> ,"01/03/1995",
>> "13/03/1995", "01/01/1996", "31/01/1996", "24/01/1995", "01/07/1995"
>> ,"01/09/1995",
>>? ? "01/07/1997", "01/01/1998", "01/08/1998", "01/01/2000",
>> "17/01/2000","29/02/2000")
>>
>> Fin <- c (
>> "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", "28/02/1995",
>> "12/03/1995",
>> "30/06/1995", "30/01/1996", "31/01/1996", "30/06/1995", "31/08/1995",
>> "30/06/1997",
>> "31/12/1997", "31/07/1998", "31/12/1999", "16/01/2000", "28/02/2000",
>> "29/02/2000")
>>
>> INDX <- c(6,6,6,? ? ? ? ? ? ? ? ? ? 11,11,11, 4,? ? ? ? 5,5)
>>
>>
>> Deb? <- c("*24/01/1995*",? ?? "*02/02/1995*", "*13/03/1995*",
>> "*01/01/1996*")
>> Fi n? <-? c("*31/12/1997*", "*12/03/1995*", "*30/06/1995*",
>> "*31/01/1996*")
>>
>>
>>? ? ? ? Debut? ? ? ? Fin INDX
>> *24/01/1995* 30/04/1997? ? 6
>> 01/05/1997 30/12/1997? ? 6
>> 31/12/1997 *31/12/1997*? ? 6
>> *02/02/1995* 27/02/1995?? 11
>> 28/02/1995 28/02/1995?? 11
>> 01/03/1995 *12/03/1995*?? 11
>> *13/03/1995* *30/06/1995*? ? 4
>> *01/01/1996* 30/01/1996? ? 5
>> 31/01/1996 *31/01/1996*? ? 5
>> ................
>>
>> Thanks for your help
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From bcrombie at utk.edu  Wed Jul 17 22:12:52 2013
From: bcrombie at utk.edu (bcrombie)
Date: Wed, 17 Jul 2013 13:12:52 -0700 (PDT)
Subject: [R] combine select data from 2 dataframes sharing same variables
Message-ID: <1374091972085-4671790.post@n4.nabble.com>

#####  The following dataframes are the result of two analyses performed on
the same set of numeric data.
# The first analysis involved calculations that did not include zero values:
StatsUTAH = data.frame(MWtotaleesDue =
c(8.428571,2.496256,7,6.604472,1,17,3.593998,4.834573,12.02257),
                       OTtotaleesDue =
c(6.6,2.242023,3,7.089899,1,23,3.100782,3.499218,9.700782),
                       OTtotalBWsDue =
c(559.944,305.7341,257.55,966.816,15.19,3232.97,422.839,137.105,982.783),
                       TotalBWsFD =
c(693.2973,265.0846,267.58,1026.6682,15.19,3232.97,356.5468,336.7505,1049.8442))
rownames(StatsUTAH)<- c("Mean","StdError", "Median", "StdDev", "Min", "Max",
"NinetyPct", "NinetyPctLower", "NinetyPctUpper")
StatsUTAH

# The second analysis involved calculations that included zero values:
sStatsUTAH = data.frame(MWtotaleesDue =
c(0.9076923,0.411799,0,3.3200295,0,17,0.5332467,0.3744456,1.440939),
                        OTtotaleesDue =
c(1.0153846,0.4442433,0,3.5816036,0,23,0.5752594,0.4401252,1.590644),
                        OTtotalBWsDue =
c(86.14523,51.5752,0,415.81256,0,3232.97,66.78575,19.35948,152.93098),
                        TotalBWsFD =
c(159.99169,69.86036,0,563.23225,0,3232.97,90.46357,69.52812,250.45526))
rownames(sStatsUTAH)<- c("sMean","sStdError", "sMedian", "sStdDev", "sMin",
"sMax", "sNinetyPct", "sNinetyPctLower", "sNinetyPctUpper")
sStatsUTAH

#the rows 1-9 may have different names in each dataframe but are the same
corresponding calculation in both.

#####  I need to combine these data so that the OUTPUT is a SEPARATE table
(or matrix or whatever)
# FOR EACH VARIABLE SHARED BY THE DATAFRAMES that I can place in a word
document (which I can handle later with RTF).
#####  This is how I've mapped it out in my head, but need to convert to R
language:
# StatsUTAH ---data for "zeroNO"
# sStatsUTAH ---data for "zeroYES"
# 
# Table 1: MWtotaleesDue
# colnames("zeroNO", "zeroYES")
# rownames("Mean","StdError", "Median", "StdDev", "Min", "Max", "NinetyPct",
"NinetyPctLower", "NinetyPctUpper")
# 
# Table 2: OTtotaleesDue
# same colnames & rownames as Table 1
# 
# Table 3: OTtotalBWsDue
# same colnames & rownames as Table 1
# 
# Table 4: TotalBWsFD
# same colnames & rownames as Table 1

#WHAT IS THE BEST WAY TO DO THIS IN R?
#While a loop may be more efficient, is there also a good way to create each
table separately?
#Note: my real dataframes (StatsUTAH,etc) will have a lot more variables
than what are listed in this example
#so I will probably be picking and choosing which ones I'm interested in
creating tables for.



--
View this message in context: http://r.789695.n4.nabble.com/combine-select-data-from-2-dataframes-sharing-same-variables-tp4671790.html
Sent from the R help mailing list archive at Nabble.com.


From girijagun at gmail.com  Wed Jul 17 19:06:44 2013
From: girijagun at gmail.com (G Girija)
Date: Wed, 17 Jul 2013 22:36:44 +0530
Subject: [R] EWMA error
Message-ID: <CAOLvsEwTGtzhW6sFZct+xc80CV_MX=HvigLFWJLh69BVk6Pi3w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/5a1751b8/attachment.pl>

From girijagun at gmail.com  Wed Jul 17 19:49:35 2013
From: girijagun at gmail.com (G Girija)
Date: Wed, 17 Jul 2013 23:19:35 +0530
Subject: [R] EWMA --http://www.forecastingfinancialrisk.com/3.html
Message-ID: <CAOLvsEwTqjZL7iRvkK4qCRh9dOdpZZVi59AUWBJegt_rhTz9DQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/80195629/attachment.pl>

From marc_schwartz at me.com  Wed Jul 17 22:38:47 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 17 Jul 2013 15:38:47 -0500
Subject: [R] anti off diagonal min max mean - how to rotate matrix by
	90	degree
In-Reply-To: <CAAjnpdhY5xLd0oae62_sTjg6Syu70uqDEwc6pEX7gGnQf2U9AQ@mail.gmail.com>
References: <CAAjnpdhY5xLd0oae62_sTjg6Syu70uqDEwc6pEX7gGnQf2U9AQ@mail.gmail.com>
Message-ID: <CB47C6BE-FFDA-4987-A48F-4DD7AD194E24@me.com>

On Jul 17, 2013, at 3:04 PM, Witold E Wolski <wewolski at gmail.com> wrote:

> How can id do this efficiently in R ?
> 
> 1 0 0
> 0 2 0
> 0 0 3
> 
> 
> rotate right
> 0 0 1
> 0 2 0
> 3 0 0
> rotate left
> 0 0 3
> 0 2 0
> 1 0 0
> 
> What I want to do is described here:
> http://stackoverflow.com/questions/13049575/r-min-max-and-mean-of-off-diagonal-elements-in-a-matrix
> 
> but I want do to it for all off-anti-diagonals.
> 
> I am also concerned that the method described on stackoverflow isn't
> necessarily efficient.
> I work with matrices of size 3k * 3k.
> 


I did not take the time to review in detail the solutions on SO, but here is one approach for rotation, albeit, not fully tested:

> mat
     [,1] [,2] [,3]
[1,]    1    0    0
[2,]    0    2    0
[3,]    0    0    3


# Rotate right
> t(mat)[, ncol(mat):1]
     [,1] [,2] [,3]
[1,]    0    0    1
[2,]    0    2    0
[3,]    3    0    0


# Rotate left
> t(mat)[nrow(mat):1, ]
     [,1] [,2] [,3]
[1,]    0    0    3
[2,]    0    2    0
[3,]    1    0    0




big.mat <- matrix(rep(0, 3000 * 3000), ncol = 3000)

> str(big.mat)
 num [1:3000, 1:3000] 0 0 0 0 0 0 0 0 0 0 ...


> system.time(mat.right <- t(big.mat)[, ncol(big.mat):1])
   user  system elapsed 
  0.273   0.000   0.273 


> system.time(mat.left <- t(big.mat)[nrow(big.mat):1], )
   user  system elapsed 
  0.094   0.000   0.099 


Regards,

Marc Schwartz


From michel.arnaud at cirad.fr  Wed Jul 17 22:44:50 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 17 Jul 2013 22:44:50 +0200
Subject: [R] simplify a dataframe
In-Reply-To: <1374092435.3165.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <51E6D296.9010707@cirad.fr> <51E6DB26.60501@sapo.pt>
	<51E6F896.5000903@cirad.fr>
	<1374092088.72407.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<1374092435.3165.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <51E70242.6070308@cirad.fr>

Thanks Arun and Rui for your helps
Michel
Le 17/07/2013 22:20, arun a ?crit :
> #or
> library(plyr)
> res<-ddply(df1,.(INDX),summarize,Debut=head(Debut,1),Fin=tail(Fin,1))
> res$INDX<-factor(res$INDX,levels=unique(df1$INDX))
> res[order(res$INDX),-1]
> #       Debut        Fin
> #3 24/01/1995 31/12/1997
> #4 02/02/1995 12/03/1995
> #1 13/03/1995 30/06/1995
> #2 01/01/1996 31/01/1996
> A.K.
>
>
>
> ----- Original Message -----
> From: arun <smartpink111 at yahoo.com>
> To: Arnaud Michel <michel.arnaud at cirad.fr>
> Cc: R help <r-help at r-project.org>; Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Wednesday, July 17, 2013 4:14 PM
> Subject: Re: [R] simplify a dataframe
>
> Hi,
> You could try:
>
> df1[,1:2]<-lapply(df1[,1:2],as.character)
>   df2New<- data.frame(Deb=unique(with(df1,ave(Debut,INDX,FUN=function(x) head(x,1)))),Fin=unique(with(df1,ave(Fin,INDX,FUN=function(x) tail(x,1)))))
> identical(df2New,df2)
> #[1] TRUE
>
> A.K.
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: Rui Barradas <ruipbarradas at sapo.pt>; R help <r-help at r-project.org>; arun <smartpink111 at yahoo.com>
> Cc:
> Sent: Wednesday, July 17, 2013 4:03 PM
> Subject: Re: [R] simplify a dataframe
>
>    Thank you for the question (1)
> Sorry for the imprecision for the question (2) :
> Suppose the date frame df
> df1 <- data.frame(
> Debut =c ( "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995"
> ,"28/02/1995"
> ,"01/03/1995", "13/03/1995", "01/01/1996", "31/01/1996") ,
> Fin = c ( "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995",
> "28/02/1995",
> "12/03/1995", "30/06/1995", "30/01/1996", "31/01/1996") ,
> INDX = c(6,6,6,  11,11,11, 4,  5,5) )
>
>
> I would like replace df1  by df2
>
> df2 <- data.frame(
> Deb  = c("24/01/1995",     "02/02/1995",     "13/03/1995",
> "01/01/1996") ,
> Fin  = c("31/12/1997", "12/03/1995",     "30/06/1995",
> "31/01/1996") )
>
> Explication :
> The lines 1, 2 3 of df1 (who have same value of index =6) are replaced
> by only one line with
> value of Debut of df2 = Debut of line 1 of df1
> value of Fin of df2 = Fin of line 3 of df1
>
> The lines 4,5,6 of df1 (who have same value of index =11) are replaced
> by only one line with
> value of Debut of df2 = Debut of line 4 of df1
> and value of fin of df2 = Fin of line 6 of df1
>
> The line 7 of df1 (who have same value of index =4) are replaced by only
> one line with
> value of Debut of df2 = Debut of line 7of df1
> and value of fin of df2 = Fin of line 7of df1
> ==> No change
>
> The lines 8,9 of df1 (who have same value of index =5) are replaced by
> only one line with
> value of Debut of df2 = Debut of line 8of df1
> and value of fin of df2 = Fin of line 9 of df1
>
> df1
>          Debut        Fin INDX
> 1 24/01/1995 30/04/1997    6
> 2 01/05/1997 30/12/1997    6
> 3 31/12/1997 31/12/1997    6
> 4 02/02/1995 27/02/1995   11
> 5 28/02/1995 28/02/1995   11
> 6 01/03/1995 12/03/1995   11
> 7 13/03/1995 30/06/1995    4
> 8 01/01/1996 30/01/1996    5
> 9 31/01/1996 31/01/1996    5
>
>            Deb        Fin
> 1 24/01/1995 31/12/1997
> 2 02/02/1995 12/03/1995
> 3 13/03/1995 30/06/1995
> 4 01/01/1996 31/01/1996
> Thank you for your helps
> Michel
>
> Le 17/07/2013 19:57, Rui Barradas a ?crit :
>> Hello,
>>
>> As for question (1), try the following.
>>
>>
>> y2 <- cumsum(c(TRUE, diff(x1) > 0))
>> identical(as.integer(y1), y2)  # y1 is of class "numeric"
>>
>>
>> As for question (2) I'm not understanding it.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 17-07-2013 18:21, Arnaud Michel escreveu:
>>> Hi Arun
>>>
>>> I have two questions always about the question of symplify a dataframe
>>>
>>> I would like
>>> 1)  to transform the vector x1 into the vector y1
>>> x1 <- c(1,1,1,-1000,         1,-1000, 1,1,1,1,1,1,-1000)
>>> y1 <- c(1,1,1,1,                    2,2, 3,3,3,3,3,3,3)
>>>
>>>
>>> 2) to transform the vectors Debut and Fin by taking into account INDX
>>> into the two vectors Deb and Fin
>>> Debut <- c (
>>> "24/01/1995", "01/05/1997" ,"31/12/1997", "02/02/1995" ,"28/02/1995"
>>> ,"01/03/1995",
>>> "13/03/1995", "01/01/1996", "31/01/1996", "24/01/1995", "01/07/1995"
>>> ,"01/09/1995",
>>>      "01/07/1997", "01/01/1998", "01/08/1998", "01/01/2000",
>>> "17/01/2000","29/02/2000")
>>>
>>> Fin <- c (
>>> "30/04/1997", "30/12/1997" ,"31/12/1997", "27/02/1995", "28/02/1995",
>>> "12/03/1995",
>>> "30/06/1995", "30/01/1996", "31/01/1996", "30/06/1995", "31/08/1995",
>>> "30/06/1997",
>>> "31/12/1997", "31/07/1998", "31/12/1999", "16/01/2000", "28/02/2000",
>>> "29/02/2000")
>>>
>>> INDX <- c(6,6,6,                    11,11,11, 4,        5,5)
>>>
>>>
>>> Deb  <- c("*24/01/1995*",     "*02/02/1995*", "*13/03/1995*",
>>> "*01/01/1996*")
>>> Fi n  <-  c("*31/12/1997*", "*12/03/1995*", "*30/06/1995*",
>>> "*31/01/1996*")
>>>
>>>
>>>          Debut        Fin INDX
>>> *24/01/1995* 30/04/1997    6
>>> 01/05/1997 30/12/1997    6
>>> 31/12/1997 *31/12/1997*    6
>>> *02/02/1995* 27/02/1995   11
>>> 28/02/1995 28/02/1995   11
>>> 01/03/1995 *12/03/1995*   11
>>> *13/03/1995* *30/06/1995*    4
>>> *01/01/1996* 30/01/1996    5
>>> 31/01/1996 *31/01/1996*    5
>>> ................
>>>
>>> Thanks for your help
>>>
>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From gangchen6 at gmail.com  Wed Jul 17 23:38:39 2013
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 17 Jul 2013 17:38:39 -0400
Subject: [R] How to capture the printout on the screen?
Message-ID: <CAHmzXO5pZrBfS6N-gmPiDgVnEoyWJMua33QmG=jO3K7fasf06g@mail.gmail.com>

This is most likely a silly question.

First I run the following:

require(car)
mod.ok <- lm(cbind(pre.1, pre.2, pre.3, pre.4, pre.5, post.1, post.2,
post.3, post.4, post.5,
                          fup.1, fup.2, fup.3, fup.4, fup.5) ~
treatment*gender, data=OBrienKaiser)
phase <- factor(rep(c("pretest", "posttest", "followup"), c(5, 5, 5)),
levels=c("pretest", "posttest", "followup"))
hour <- ordered(rep(1:5, 3))
idata <- data.frame(phase, hour)
(fm <- linearHypothesis(mod.ok, c("treatment1", "treatment2"),
idata=idata, idesign=~phase*hour, iterms="phase:hour"))

I get the output like the following (only the last part at the end is
shown below):

...
Multivariate Tests:
                 Df test stat  approx F num Df den Df  Pr(>F)
Pillai            2 0.6623840 0.2475987     16      8 0.99155
Wilks             2 0.4460357 0.1864957     16      6 0.99668
Hotelling-Lawley  2 0.9988990 0.1248624     16      4 0.99904
Roy               2 0.5792977 0.2896488      8      4 0.93605

I want to capture the data frame shown above, but it's not part of 'fm':

str(fm)

I guess the print method for an object of class "Anova.mlm"
("print.Anova.mlm") generates the above data frame. My question is:
How to capture it? I mean, how can I store the output on the screen
and then extract the data frame?

Thanks,
Gang


From wewolski at gmail.com  Wed Jul 17 23:43:50 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 17 Jul 2013 23:43:50 +0200
Subject: [R] cut into groups of equal nr of elements...
Message-ID: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>

I would like to "cut" a vector into groups of equal nr of elements.
looking for a function on the lines of cut but where I can specify
the size of the groups instead of the nr of groups.




--
Witold Eryk Wolski


From macqueen1 at llnl.gov  Wed Jul 17 23:44:23 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 17 Jul 2013 21:44:23 +0000
Subject: [R] ERROR: missing value where TRUE/FALSE needed
In-Reply-To: <BAY159-W224AB875DC5FE90B228184F7600@phx.gbl>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521914A13A9@PRDEXMBX-08.the-lab.llnl.gov>

In addition to what Petr said,

That message most likely means that you have some missing data where
you're not allowed to have missing data in your Datos.

Look and see if the mctp() function has an argument that controls what it
does with missing data.

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/16/13 2:29 PM, "Lee Jejen" <yitus_14 at hotmail.com> wrote:

>Hello, I have a problem... I tried using a function and I get the error:
>"ERROR: missing value where TRUE/FALSE needed"
>Here is my code:
>a<-mctp(Ecoli~Fecha, data=Datos, type = "Tukey", alternative =
>"two.sided", asy.method = "mult.t", plot.simci = TRUE)summary(a)
>Ecoli, Fecha and Datos are well defined. I don't know what is the
>problem...
>THANKS
>  		 	   		  
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From wewolski at gmail.com  Wed Jul 17 23:47:07 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 17 Jul 2013 23:47:07 +0200
Subject: [R] robust smoothing - median smoothing.
Message-ID: <CAAjnpdh_US-SZQamPNFfCNGchyrOUo=mpopA4GnP32qEuB18+w@mail.gmail.com>

Looking for robust smoothing methods available in R... a robust
version of lowess or smooth.spline.
Was searching for "median and smoothing" but the search engine isn't
calibrated .

--
Witold Eryk Wolski


From 538280 at gmail.com  Thu Jul 18 00:00:00 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 17 Jul 2013 16:00:00 -0600
Subject: [R] How to capture the printout on the screen?
In-Reply-To: <CAHmzXO5pZrBfS6N-gmPiDgVnEoyWJMua33QmG=jO3K7fasf06g@mail.gmail.com>
References: <CAHmzXO5pZrBfS6N-gmPiDgVnEoyWJMua33QmG=jO3K7fasf06g@mail.gmail.com>
Message-ID: <CAFEqCdwXZJOdB4oAsUHgEe4gdd3L0iscPJVXP_jt43kC=CQpUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/7feb49d0/attachment.pl>

From 538280 at gmail.com  Thu Jul 18 00:02:49 2013
From: 538280 at gmail.com (Greg Snow)
Date: Wed, 17 Jul 2013 16:02:49 -0600
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
Message-ID: <CAFEqCdwR+3yifzD_ib4=vamENPZgpdvX9WM8BnUeNtmLkkyJMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/2879e32d/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 18 00:04:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 15:04:30 -0700 (PDT)
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
Message-ID: <1374098670.87775.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
Not sure whether this is what you wanted.


?vec1<- 1:7
?fun1<- function(x,nr) {((x-1)%/%nr)+1}
?fun1(vec1,2)
#[1] 1 1 2 2 3 3 4
?fun1(vec1,3)
#[1] 1 1 1 2 2 2 3
split(vec1,fun1(vec1,2))

A.K.



----- Original Message -----
From: Witold E Wolski <wewolski at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 17, 2013 5:43 PM
Subject: [R] cut into groups of equal nr of elements...

I would like to "cut" a vector into groups of equal nr of elements.
looking for a function on the lines of cut but where I can specify
the size of the groups instead of the nr of groups.




--
Witold Eryk Wolski

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Thu Jul 18 00:23:07 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 17 Jul 2013 23:23:07 +0100
Subject: [R] robust smoothing - median smoothing.
In-Reply-To: <CAAjnpdh_US-SZQamPNFfCNGchyrOUo=mpopA4GnP32qEuB18+w@mail.gmail.com>
References: <CAAjnpdh_US-SZQamPNFfCNGchyrOUo=mpopA4GnP32qEuB18+w@mail.gmail.com>
Message-ID: <51E7194B.8050206@sapo.pt>

Hello,

Maybe ?stats::smooth

Hope this helps,

Rui Barradas

Em 17-07-2013 22:47, Witold E Wolski escreveu:
> Looking for robust smoothing methods available in R... a robust
> version of lowess or smooth.spline.
> Was searching for "median and smoothing" but the search engine isn't
> calibrated .
>
> --
> Witold Eryk Wolski
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From axel.urbiz at gmail.com  Thu Jul 18 00:26:02 2013
From: axel.urbiz at gmail.com (Axel Urbiz)
Date: Wed, 17 Jul 2013 18:26:02 -0400
Subject: [R] glmnet on Autopilot
Message-ID: <CAAyVsXL7TbCHxayQRX9qo4T=6u=-7d38c54KCSYVJz1L=Wm4fw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/7bdb821c/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 18 00:37:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 15:37:38 -0700 (PDT)
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <1374098670.87775.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
	<1374098670.87775.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1374100658.5346.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Sorry, there was a mistake:
fun1 should be:
fun1<- function(x,nr) {((seq_along(x)-1)%/%nr)+1}

vec3<- c(4,5,7,9,8,5)
?fun1(vec3,2)
#[1] 1 1 2 2 3 3

split(vec3,fun1(vec3,2))


A.K.



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Witold E Wolski <wewolski at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Wednesday, July 17, 2013 6:04 PM
Subject: Re: [R] cut into groups of equal nr of elements...

HI,
Not sure whether this is what you wanted.


?vec1<- 1:7
?fun1<- function(x,nr) {((x-1)%/%nr)+1}
?fun1(vec1,2)
#[1] 1 1 2 2 3 3 4
?fun1(vec1,3)
#[1] 1 1 1 2 2 2 3
split(vec1,fun1(vec1,2))

A.K.



----- Original Message -----
From: Witold E Wolski <wewolski at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 17, 2013 5:43 PM
Subject: [R] cut into groups of equal nr of elements...

I would like to "cut" a vector into groups of equal nr of elements.
looking for a function on the lines of cut but where I can specify
the size of the groups instead of the nr of groups.




--
Witold Eryk Wolski

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From liuwensui at gmail.com  Thu Jul 18 00:43:30 2013
From: liuwensui at gmail.com (Wensui Liu)
Date: Wed, 17 Jul 2013 18:43:30 -0400
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
Message-ID: <CAKyN3iB0y_EvM-64UZVuUkMaPKaoYKw38yG7MYd2AsZSFEh60w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/50cbb882/attachment.pl>

From marc_schwartz at me.com  Thu Jul 18 01:04:30 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 17 Jul 2013 18:04:30 -0500
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
Message-ID: <7E74DEBD-3CD0-434A-BB9D-947A302B4701@me.com>

On Jul 17, 2013, at 4:43 PM, Witold E Wolski <wewolski at gmail.com> wrote:

> I would like to "cut" a vector into groups of equal nr of elements.
> looking for a function on the lines of cut but where I can specify
> the size of the groups instead of the nr of groups.



In addition to the other options, if the 'breaks' argument to cut() is a single number, rather than a vector of cut points, it defines the number of intervals to break the 'x' vector into, which of course you can derive from length(x) / size.

Thus:

set.seed(1)
Vec <- sample(30)

> Vec
 [1]  8 11 17 25  6 23 27 16 14  2  5  4 13  7 18 30 29 24 20  9 10 21
[23] 26  1 22 15 28 12  3 19


# Split into 5 groups of 6 each 

> split(Vec, cut(Vec, 5))
$`(0.971,6.78]`
[1] 6 2 5 4 1 3

$`(6.78,12.6]`
[1]  8 11  7  9 10 12

$`(12.6,18.4]`
[1] 17 16 14 13 18 15

$`(18.4,24.2]`
[1] 23 24 20 21 22 19

$`(24.2,30]`
[1] 25 27 30 29 26 28


Regards,

Marc Schwartz


From Peter.Alspach at plantandfood.co.nz  Thu Jul 18 01:59:30 2013
From: Peter.Alspach at plantandfood.co.nz (Peter Alspach)
Date: Thu, 18 Jul 2013 11:59:30 +1200
Subject: [R] combine select data from 2 dataframes sharing same variables
In-Reply-To: <1374091972085-4671790.post@n4.nabble.com>
References: <1374091972085-4671790.post@n4.nabble.com>
Message-ID: <3CD374BF2C285940A54C0A71225AF7DB0357678238@AKLEXM01.PFR.CO.NZ>

Tena koe

Without reading your request in detail, I will suggest you look at ?merge.  It is often the answer when 'combine' is in the question.

Peter Alspach

-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of bcrombie
Sent: Thursday, 18 July 2013 8:13 a.m.
To: r-help at r-project.org
Subject: [R] combine select data from 2 dataframes sharing same variables

#####  The following dataframes are the result of two analyses performed on the same set of numeric data.
# The first analysis involved calculations that did not include zero values:
StatsUTAH = data.frame(MWtotaleesDue =
c(8.428571,2.496256,7,6.604472,1,17,3.593998,4.834573,12.02257),
                       OTtotaleesDue =
c(6.6,2.242023,3,7.089899,1,23,3.100782,3.499218,9.700782),
                       OTtotalBWsDue =
c(559.944,305.7341,257.55,966.816,15.19,3232.97,422.839,137.105,982.783),
                       TotalBWsFD =
c(693.2973,265.0846,267.58,1026.6682,15.19,3232.97,356.5468,336.7505,1049.8442))
rownames(StatsUTAH)<- c("Mean","StdError", "Median", "StdDev", "Min", "Max", "NinetyPct", "NinetyPctLower", "NinetyPctUpper") StatsUTAH

# The second analysis involved calculations that included zero values:
sStatsUTAH = data.frame(MWtotaleesDue =
c(0.9076923,0.411799,0,3.3200295,0,17,0.5332467,0.3744456,1.440939),
                        OTtotaleesDue =
c(1.0153846,0.4442433,0,3.5816036,0,23,0.5752594,0.4401252,1.590644),
                        OTtotalBWsDue =
c(86.14523,51.5752,0,415.81256,0,3232.97,66.78575,19.35948,152.93098),
                        TotalBWsFD =
c(159.99169,69.86036,0,563.23225,0,3232.97,90.46357,69.52812,250.45526))
rownames(sStatsUTAH)<- c("sMean","sStdError", "sMedian", "sStdDev", "sMin", "sMax", "sNinetyPct", "sNinetyPctLower", "sNinetyPctUpper") sStatsUTAH

#the rows 1-9 may have different names in each dataframe but are the same corresponding calculation in both.

#####  I need to combine these data so that the OUTPUT is a SEPARATE table (or matrix or whatever) # FOR EACH VARIABLE SHARED BY THE DATAFRAMES that I can place in a word document (which I can handle later with RTF).
#####  This is how I've mapped it out in my head, but need to convert to R
language:
# StatsUTAH ---data for "zeroNO"
# sStatsUTAH ---data for "zeroYES"
#
# Table 1: MWtotaleesDue
# colnames("zeroNO", "zeroYES")
# rownames("Mean","StdError", "Median", "StdDev", "Min", "Max", "NinetyPct", "NinetyPctLower", "NinetyPctUpper") # # Table 2: OTtotaleesDue # same colnames & rownames as Table 1 # # Table 3: OTtotalBWsDue # same colnames & rownames as Table 1 # # Table 4: TotalBWsFD # same colnames & rownames as Table 1

#WHAT IS THE BEST WAY TO DO THIS IN R?
#While a loop may be more efficient, is there also a good way to create each table separately?
#Note: my real dataframes (StatsUTAH,etc) will have a lot more variables than what are listed in this example #so I will probably be picking and choosing which ones I'm interested in creating tables for.



--
View this message in context: http://r.789695.n4.nabble.com/combine-select-data-from-2-dataframes-sharing-same-variables-tp4671790.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The contents of this e-mail are confidential and may be ...{{dropped:14}}


From kridox at ymail.com  Thu Jul 18 02:24:56 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 18 Jul 2013 09:24:56 +0900
Subject: [R] EWMA error
In-Reply-To: <CAOLvsEwTGtzhW6sFZct+xc80CV_MX=HvigLFWJLh69BVk6Pi3w@mail.gmail.com>
References: <CAOLvsEwTGtzhW6sFZct+xc80CV_MX=HvigLFWJLh69BVk6Pi3w@mail.gmail.com>
Message-ID: <CAAcyNCzdkzwSOEdr2BNKmCWJkG6yQH6y=HwUcBrXY=bR9_2+kw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/a902d3be/attachment.pl>

From kridox at ymail.com  Thu Jul 18 02:26:41 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 18 Jul 2013 09:26:41 +0900
Subject: [R] robust smoothing - median smoothing.
In-Reply-To: <51E7194B.8050206@sapo.pt>
References: <CAAjnpdh_US-SZQamPNFfCNGchyrOUo=mpopA4GnP32qEuB18+w@mail.gmail.com>
	<51E7194B.8050206@sapo.pt>
Message-ID: <CAAcyNCznC=ZQS6LHgX+2=fqj-ZLpCNj1yWV6t+6Nb=yR3NX1rA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/d5f02d7a/attachment.pl>

From gangchen6 at gmail.com  Thu Jul 18 03:43:19 2013
From: gangchen6 at gmail.com (Gang Chen)
Date: Wed, 17 Jul 2013 21:43:19 -0400
Subject: [R] How to capture the printout on the screen?
In-Reply-To: <CAFEqCdwXZJOdB4oAsUHgEe4gdd3L0iscPJVXP_jt43kC=CQpUA@mail.gmail.com>
References: <CAHmzXO5pZrBfS6N-gmPiDgVnEoyWJMua33QmG=jO3K7fasf06g@mail.gmail.com>
	<CAFEqCdwXZJOdB4oAsUHgEe4gdd3L0iscPJVXP_jt43kC=CQpUA@mail.gmail.com>
Message-ID: <CAHmzXO7ms1yR7k90faKt74MXBxz9XPnY+gUXsk5tX+X-2erANA@mail.gmail.com>

Thanks a lot for the pointer!

After I downloaded the source code and saw the innards of the print
function, I know what to do now.

Thanks again,
Gang


On Wed, Jul 17, 2013 at 6:00 PM, Greg Snow <538280 at gmail.com> wrote:
> If you are happy with the character strings printed out then you can use the
> capture.output function.
>
> If you want the numbers (without needing to convert) then look at the print
> method for the class of object that you are working with and see what the
> code is.  It is probably calling another function to produce the output and
> you could just call that function directly.  If not, you can copy that
> section of the code into your own function to call and have it return the
> object rather than printing.
>
>
> On Wed, Jul 17, 2013 at 3:38 PM, Gang Chen <gangchen6 at gmail.com> wrote:
>>
>> This is most likely a silly question.
>>
>> First I run the following:
>>
>> require(car)
>> mod.ok <- lm(cbind(pre.1, pre.2, pre.3, pre.4, pre.5, post.1, post.2,
>> post.3, post.4, post.5,
>>                           fup.1, fup.2, fup.3, fup.4, fup.5) ~
>> treatment*gender, data=OBrienKaiser)
>> phase <- factor(rep(c("pretest", "posttest", "followup"), c(5, 5, 5)),
>> levels=c("pretest", "posttest", "followup"))
>> hour <- ordered(rep(1:5, 3))
>> idata <- data.frame(phase, hour)
>> (fm <- linearHypothesis(mod.ok, c("treatment1", "treatment2"),
>> idata=idata, idesign=~phase*hour, iterms="phase:hour"))
>>
>> I get the output like the following (only the last part at the end is
>> shown below):
>>
>> ...
>> Multivariate Tests:
>>                  Df test stat  approx F num Df den Df  Pr(>F)
>> Pillai            2 0.6623840 0.2475987     16      8 0.99155
>> Wilks             2 0.4460357 0.1864957     16      6 0.99668
>> Hotelling-Lawley  2 0.9988990 0.1248624     16      4 0.99904
>> Roy               2 0.5792977 0.2896488      8      4 0.93605
>>
>> I want to capture the data frame shown above, but it's not part of 'fm':
>>
>> str(fm)
>>
>> I guess the print method for an object of class "Anova.mlm"
>> ("print.Anova.mlm") generates the above data frame. My question is:
>> How to capture it? I mean, how can I store the output on the screen
>> and then extract the data frame?
>>
>> Thanks,
>> Gang
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
>
> --
> Gregory (Greg) L. Snow Ph.D.
> 538280 at gmail.com


From mackay at northnet.com.au  Thu Jul 18 04:14:00 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Thu, 18 Jul 2013 12:14:00 +1000
Subject: [R] robust smoothing - median smoothing.
In-Reply-To: <51E7194B.8050206@sapo.pt>
References: <CAAjnpdh_US-SZQamPNFfCNGchyrOUo=mpopA4GnP32qEuB18+w@mail.gmail.com>
	<51E7194B.8050206@sapo.pt>
Message-ID: <201307180214.r6I2E3ch023155@mail16.tpgi.com.au>

Another option is

library(locfit)
?locfit

There is also a web page from the help which gives a link to Clive 
Loaders book

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au

At 08:23 18/07/2013, you wrote:
>Hello,
>
>Maybe ?stats::smooth
>
>Hope this helps,
>
>Rui Barradas
>
>Em 17-07-2013 22:47, Witold E Wolski escreveu:
>>Looking for robust smoothing methods available in R... a robust
>>version of lowess or smooth.spline.
>>Was searching for "median and smoothing" but the search engine isn't
>>calibrated .
>>
>>--
>>Witold Eryk Wolski
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Thu Jul 18 04:44:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 17 Jul 2013 21:44:13 -0500
Subject: [R] glmnet on Autopilot
In-Reply-To: <CAAyVsXL7TbCHxayQRX9qo4T=6u=-7d38c54KCSYVJz1L=Wm4fw@mail.gmail.com>
References: <CAAyVsXL7TbCHxayQRX9qo4T=6u=-7d38c54KCSYVJz1L=Wm4fw@mail.gmail.com>
Message-ID: <B1ED2F02-7DDE-4B32-AB5D-998352EE93E8@comcast.net>


On Jul 17, 2013, at 5:26 PM, Axel Urbiz wrote:

> Dear List,
>
> I'm running simulations using the glmnet package. I need to use an
> 'automated' method for model selection at each iteration of the  
> simulation.
> The cv.glmnet function in the same package is handy for that purpose.
> However, in my simulation I have p >> N, and in some cases the  
> selected
> model from cv.glmet is essentially shrinking all coefficients to  
> zero. In
> this case, the prediction for each instance equals the average of the
> response variable. A reproducible example is shown below.
>
> Is there a reasonable way to prevent this from happening in a  
> simulation
> setting with glmnet? That is, I'd like the selected model to give me  
> some
> useful predictions.

I'd like to expose the premise of the request to criticism. Reporting  
the sample mean in cases where no preditctors meet the criteria for  
significance under penalsization IS an informative response under  
conditions of simulation. The simulated result is telling you that in  
some data situations of modest size assess under a penalized process  
will not deliver a "significant" result. Why does this bother yu\ou?  
The number of such messages would seem to be one measure of the power  
of the method, although other departures from the "true" result would  
also be substracted from teh count of runs.

  If you choose to ignore the "evidence", then I "predict" that you  
are also one who chooses to throw out outliers. Both would have a  
similar effect of inflating measures of significance at the expense of  
fideltity to the data. If you want to vary the parameter, then vary  
the penalization and determine the effect of that hyper-parameter.

David Winsemius

>
> I've tested using alternative loss measures (type.measure argument),  
> but
> none is satisfactory in all cases.
>
> This question is not necessarily R related (so sorry for that): when
> comparing glmnet with other models in terms of predictive accuracy,  
> is it
> fair to make the comparison including those cases in which the `best'
> cv.glmnet can do in an automated setting is pred = avg(response)?
>
> library(glmnet)
> set.seed(1010)
> n=100;p=3000
> nzc=trunc(p/10)
> x=matrix(rnorm(n*p),n,p)
> beta=rnorm(nzc)
> fx= x[,seq(nzc)] %*% beta
> eps=rnorm(n)*5
> y=drop(fx+eps)
> px=exp(fx)
> px=px/(1+px)
> ly=rbinom(n=length(px),prob=px,size=1)
>
> fit.net <- cv.glmnet(x,
>                     ly,
>                     family = "binomial",
>                     alpha = 1, # lasso penalty
>                     type.measure = "deviance",
>                     standardize = FALSE,
>                     intercept = FALSE,
>                     nfolds = 10,
>                     keep = FALSE)
>
> plot(fit.net)
> log(fit.net$lambda.1se)
> pred <- predict(fit.net, x,
>                type = "response", s = "lambda.1se")
> all(coef(fit.net) == 0)
> all(pred ==0.5)

>
> Thanks in advance for your thoughts.
>
> Regards,
> Lars.
>
> 	[[alternative HTML version deleted]]

No problems with this posting for my mail client but you should learn  
to use the facilities in gmail to send palin text. Yhey are easy to fnd.

-- 
David Winsemius, MD
Alameda, CA, USA


From rolf.turner at xtra.co.nz  Thu Jul 18 05:07:01 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Thu, 18 Jul 2013 15:07:01 +1200
Subject: [R] R-squared and GLM
In-Reply-To: <1374071802773-4671754.post@n4.nabble.com>
References: <1374071802773-4671754.post@n4.nabble.com>
Message-ID: <51E75BD5.1060602@xtra.co.nz>

On 18/07/13 02:36, Chris89 wrote:
> Dear users,
>
> I want to compute r-squared values from a glm regression using a gamma
> distribution and an "identity" link-function, but find no such thing when
> using the summary() or names() function. My next guess was to calculate it
> by "hand", i.e.
>
> r2 = (sum((estimate - xbar)^2) /sum((x-xbar)^2))
>
> but I am unsure if this is even allowed...

Who is going to disallow you?  It's a free country.  (I refer to Norway of
course; freer than most countries, in my understanding.)

But since you are maximizing a likelihood based on the Gamma distribution,
rather than doing least squares, what exactly is the relevance of R-squared
anyway?

     cheers,

         Rolf Turner


From zroslina at yahoo.com  Thu Jul 18 02:24:58 2013
From: zroslina at yahoo.com (Roslina Zakaria)
Date: Wed, 17 Jul 2013 17:24:58 -0700 (PDT)
Subject: [R] error message in gev
In-Reply-To: <51E6B820.9030003@sapo.pt>
References: <1374053626.76408.YahooMailNeo@web120603.mail.ne1.yahoo.com>
	<51E66917.6090905@sapo.pt>
	<1374064426.75463.YahooMailNeo@web120605.mail.ne1.yahoo.com>
	<51E692CB.7010303@sapo.pt>
	<1374069223.16671.YahooMailNeo@web120606.mail.ne1.yahoo.com>
	<51E6B820.9030003@sapo.pt>
Message-ID: <1374107098.87673.YahooMailNeo@web120605.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130717/ad26c7ad/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 17 22:41:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 17 Jul 2013 13:41:57 -0700 (PDT)
Subject: [R] combine select data from 2 dataframes sharing same variables
In-Reply-To: <1374091972085-4671790.post@n4.nabble.com>
References: <1374091972085-4671790.post@n4.nabble.com>
Message-ID: <1374093717.22037.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Not sure if this is what you wanted:
#If columns are arranged in the same order in both data.frames.

lst1<-lapply(seq_len(ncol(StatsUTAH)),function(i) {x1<-cbind(StatsUTAH[,i],sStatsUTAH[,i]);row.names(x1)<-row.names(StatsUTAH);colnames(x1)<-c("zeroNO","zeroYES");x1})
?names(lst1)<- colnames(StatsUTAH)

A.K.



----- Original Message -----
From: bcrombie <bcrombie at utk.edu>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 17, 2013 4:12 PM
Subject: [R] combine select data from 2 dataframes sharing same variables

#####? The following dataframes are the result of two analyses performed on
the same set of numeric data.
# The first analysis involved calculations that did not include zero values:
StatsUTAH = data.frame(MWtotaleesDue =
c(8.428571,2.496256,7,6.604472,1,17,3.593998,4.834573,12.02257),
? ? ? ? ? ? ? ? ? ? ?  OTtotaleesDue =
c(6.6,2.242023,3,7.089899,1,23,3.100782,3.499218,9.700782),
? ? ? ? ? ? ? ? ? ? ?  OTtotalBWsDue =
c(559.944,305.7341,257.55,966.816,15.19,3232.97,422.839,137.105,982.783),
? ? ? ? ? ? ? ? ? ? ?  TotalBWsFD =
c(693.2973,265.0846,267.58,1026.6682,15.19,3232.97,356.5468,336.7505,1049.8442))
rownames(StatsUTAH)<- c("Mean","StdError", "Median", "StdDev", "Min", "Max",
"NinetyPct", "NinetyPctLower", "NinetyPctUpper")
StatsUTAH

# The second analysis involved calculations that included zero values:
sStatsUTAH = data.frame(MWtotaleesDue =
c(0.9076923,0.411799,0,3.3200295,0,17,0.5332467,0.3744456,1.440939),
? ? ? ? ? ? ? ? ? ? ? ? OTtotaleesDue =
c(1.0153846,0.4442433,0,3.5816036,0,23,0.5752594,0.4401252,1.590644),
? ? ? ? ? ? ? ? ? ? ? ? OTtotalBWsDue =
c(86.14523,51.5752,0,415.81256,0,3232.97,66.78575,19.35948,152.93098),
? ? ? ? ? ? ? ? ? ? ? ? TotalBWsFD =
c(159.99169,69.86036,0,563.23225,0,3232.97,90.46357,69.52812,250.45526))
rownames(sStatsUTAH)<- c("sMean","sStdError", "sMedian", "sStdDev", "sMin",
"sMax", "sNinetyPct", "sNinetyPctLower", "sNinetyPctUpper")
sStatsUTAH

#the rows 1-9 may have different names in each dataframe but are the same
corresponding calculation in both.

#####? I need to combine these data so that the OUTPUT is a SEPARATE table
(or matrix or whatever)
# FOR EACH VARIABLE SHARED BY THE DATAFRAMES that I can place in a word
document (which I can handle later with RTF).
#####? This is how I've mapped it out in my head, but need to convert to R
language:
# StatsUTAH ---data for "zeroNO"
# sStatsUTAH ---data for "zeroYES"
# 
# Table 1: MWtotaleesDue
# colnames("zeroNO", "zeroYES")
# rownames("Mean","StdError", "Median", "StdDev", "Min", "Max", "NinetyPct",
"NinetyPctLower", "NinetyPctUpper")
# 
# Table 2: OTtotaleesDue
# same colnames & rownames as Table 1
# 
# Table 3: OTtotalBWsDue
# same colnames & rownames as Table 1
# 
# Table 4: TotalBWsFD
# same colnames & rownames as Table 1

#WHAT IS THE BEST WAY TO DO THIS IN R?
#While a loop may be more efficient, is there also a good way to create each
table separately?
#Note: my real dataframes (StatsUTAH,etc) will have a lot more variables
than what are listed in this example
#so I will probably be picking and choosing which ones I'm interested in
creating tables for.



--
View this message in context: http://r.789695.n4.nabble.com/combine-select-data-from-2-dataframes-sharing-same-variables-tp4671790.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From azam.peyvand at gmail.com  Thu Jul 18 09:47:26 2013
From: azam.peyvand at gmail.com (Azam Peyvand)
Date: Thu, 18 Jul 2013 00:47:26 -0700
Subject: [R] Finding All paths in a graph
Message-ID: <CAOkAhB8UvcmoxUBk4qjovaAezKFbJELu-vcUpQGqi=jGWXfGSg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/a1f5e866/attachment.pl>

From Thierry.ONKELINX at inbo.be  Thu Jul 18 11:37:06 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 18 Jul 2013 09:37:06 +0000
Subject: [R] stopping functions with long execution times
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD2FD6B0@inbomail.inbo.be>

Dear all,

I am running the same model on several datasets, each dataset is a different species. The problem is that for some datasets the model is not converging. Currently I have an INLA model running for 35 days and still no results. The process still uses near 100% of the CPU and less than 1 GB RAM on virtual Ubuntu box with 8 GB RAM on a blade server.

I can kill the process manual and make the script skip this model. However it would be more elegant if it was possible to automate this. E.g. let the model run but kill it automatically once it runs for more than 7 days. Once killed the model should throw an error so we can catch that in the error-handling.

Any suggestions on how to do this?

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From kridox at ymail.com  Thu Jul 18 11:45:17 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 18 Jul 2013 18:45:17 +0900
Subject: [R] EWMA error
In-Reply-To: <CAOLvsEyLbLUsZfD7EcvyAutAa=F4ZgX3D_BiLP3XOxUKjYNibw@mail.gmail.com>
References: <CAOLvsEwTGtzhW6sFZct+xc80CV_MX=HvigLFWJLh69BVk6Pi3w@mail.gmail.com>
	<CAAcyNCzdkzwSOEdr2BNKmCWJkG6yQH6y=HwUcBrXY=bR9_2+kw@mail.gmail.com>
	<CAOLvsEyLbLUsZfD7EcvyAutAa=F4ZgX3D_BiLP3XOxUKjYNibw@mail.gmail.com>
Message-ID: <CAAcyNCz=YEEE0kw+uatrsL00MiQg1KiR3BGfwnCmATZxkxQKsQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/368c87bc/attachment.pl>

From alfonso.carfora at uniparthenope.it  Thu Jul 18 11:48:19 2013
From: alfonso.carfora at uniparthenope.it (alfonso.carfora at uniparthenope.it)
Date: Thu, 18 Jul 2013 11:48:19 +0200
Subject: [R] truncation and approximation
In-Reply-To: <51E6F11A.5000508@sapo.pt>
References: <DUB107-W2479A3013696B6B031D881DE8A0@phx.gbl>
	<DUB107-W27CC7C8A340D1E748B29A4DE610@phx.gbl>
	<51E6F11A.5000508@sapo.pt>
Message-ID: <20130718114819.208024kxl8iba1nn@webmail.uniparthenope.it>

Maybe you can use "round" and "trunc" functions

For example if you have a vector like this:


x<- c(3.000 3.125 3.250 3.375 3.500 3.625 3.750 3.875 4.000)

and you want to round the numbers to 2 decimals you can use:

> round(x,2)
[1] 3.00 3.12 3.25 3.38 3.50 3.62 3.75 3.88 4.00


if you want a numeric vector containing the integers formed by  
truncating the values in x

> trunc(x)
[1] 3 3 3 3 3 3 3 3 4

I'hope it'is useful to you
A.C.




Def. Quota Rui Barradas <ruipbarradas at sapo.pt>:

> Hello,
>
> As for truncation, you can write a one line function:
>
> dec_trunc <- function(x, digits = 0) trunc(x * 10^digits)/10^digits
>
>
> As for approximation, maybe you're looking for ?signif.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 17-07-2013 18:41, Francesco Miranda escreveu:
>> What is the function to do the truncation to a certain decimal  
>> digit of a number. And the function approximation?
>> Thanks.
>> Francesco M
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



******************************************************************************	
IL MERITO DEGLI STUDENTI VIENE RICONOSCIUTO
 
Il 5 per mille all'Universita' degli Studi di Napoli "Parthenope" incrementa le borse di studio agli studenti - codice fiscale 80018240632
http://www.uniparthenope.it/index.php/5xmille 
 
http://www.uniparthenope.it/index.php/it/avvisi-sito-di-ateneo/2943-la-parthenope-premia-il-tuo-voto-di-diploma-ed-il-tuo-imegno-con-i-proventi-del-5-per-mille
 
Questa informativa e' inserita in automatico dal sistema al fine esclusivo della realizzazione dei fini istituzionali dell'ente.


From bogaso.christofer at gmail.com  Thu Jul 18 12:09:25 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Thu, 18 Jul 2013 15:39:25 +0530
Subject: [R] 'save' method for S4 class
Message-ID: <CA+dpOJ=K_yLH5QeK+PsL6QPXS-Pj1Hpefomh6Z3+MrNfcp=hgA@mail.gmail.com>

Hello again,

I am trying to define the 'save' method for my S4 class as below:

setClass("MyClass", representation(
		Slot1 = "data.frame"
	))	
	
setMethod("save", "MyClass", definition = function(x, file_Path) {
		
		write.table(x at Slot1, file = file_Path, append = FALSE, quote = TRUE,
sep = ",",
						eol = "\n", na = "NA", dec = ".", row.names = FALSE,
						col.names = TRUE, qmethod = c("escape", "double"),
						fileEncoding = "")
	})

However while doing this I am getting following error:

Error in conformMethod(signature, mnames, fnames, f, fdef, definition) :
  in method for ?save? with signature ?list="MyClass"?: formal
arguments (list = "MyClass", file = "MyClass", ascii = "MyClass",
version = "MyClass", envir = "MyClass", compress = "MyClass",
compression_level = "MyClass", eval.promises = "MyClass", precheck =
"MyClass") omitted in the method definition cannot be in the signature


Can somebody point me what will be the correct approach to define
'save' method for S4 class?

Thanks and regards,


From hb at biostat.ucsf.edu  Thu Jul 18 12:43:24 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 18 Jul 2013 12:43:24 +0200
Subject: [R] stopping functions with long execution times
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427CD2FD6B0@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA7427CD2FD6B0@inbomail.inbo.be>
Message-ID: <CAFDcVCSQsOouzDx1dz1pEVVLFEW2-3bhMvhiuprTfJHDDViXgw@mail.gmail.com>

See evalWithTimeout() of R.utils, e.g.

tryCatch({
  evalWithTimeout({
    slowFunction();
  }, timeout=7*24*3600);
}, TimeoutException=function(ex) {
  cat("Timeout. Skipping.\n");
})

help("evalWithTimeout") have more information and cross links.

/Henrik

On Thu, Jul 18, 2013 at 11:37 AM, ONKELINX, Thierry
<Thierry.ONKELINX at inbo.be> wrote:
> Dear all,
>
> I am running the same model on several datasets, each dataset is a different species. The problem is that for some datasets the model is not converging. Currently I have an INLA model running for 35 days and still no results. The process still uses near 100% of the CPU and less than 1 GB RAM on virtual Ubuntu box with 8 GB RAM on a blade server.
>
> I can kill the process manual and make the script skip this model. However it would be more elegant if it was possible to automate this. E.g. let the model run but kill it automatically once it runs for more than 7 days. Once killed the model should throw an error so we can catch that in the error-handling.
>
> Any suggestions on how to do this?
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Thu Jul 18 12:47:01 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 18 Jul 2013 12:47:01 +0200
Subject: [R] 'save' method for S4 class
In-Reply-To: <CA+dpOJ=K_yLH5QeK+PsL6QPXS-Pj1Hpefomh6Z3+MrNfcp=hgA@mail.gmail.com>
References: <CA+dpOJ=K_yLH5QeK+PsL6QPXS-Pj1Hpefomh6Z3+MrNfcp=hgA@mail.gmail.com>
Message-ID: <BFAE694C-6BE8-40AD-966D-C79584F18D75@uni-bonn.de>

Hi Christopher,

I think, that "save" is no generic function like "plot", "show", etc. So at first you have to determine a generic.

setGeneric("save", function(x, file_Path) standardGeneric("save"))

Now your definition via setMethod. 


Best

Simon



On Jul 18, 2013, at 12:09 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:

> Hello again,
> 
> I am trying to define the 'save' method for my S4 class as below:
> 
> setClass("MyClass", representation(
> 		Slot1 = "data.frame"
> 	))	
> 	
> setMethod("save", "MyClass", definition = function(x, file_Path) {
> 		
> 		write.table(x at Slot1, file = file_Path, append = FALSE, quote = TRUE,
> sep = ",",
> 						eol = "\n", na = "NA", dec = ".", row.names = FALSE,
> 						col.names = TRUE, qmethod = c("escape", "double"),
> 						fileEncoding = "")
> 	})
> 
> However while doing this I am getting following error:
> 
> Error in conformMethod(signature, mnames, fnames, f, fdef, definition) :
>  in method for ?save? with signature ?list="MyClass"?: formal
> arguments (list = "MyClass", file = "MyClass", ascii = "MyClass",
> version = "MyClass", envir = "MyClass", compress = "MyClass",
> compression_level = "MyClass", eval.promises = "MyClass", precheck =
> "MyClass") omitted in the method definition cannot be in the signature
> 
> 
> Can somebody point me what will be the correct approach to define
> 'save' method for S4 class?
> 
> Thanks and regards,
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Thierry.ONKELINX at inbo.be  Thu Jul 18 13:36:13 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Thu, 18 Jul 2013 11:36:13 +0000
Subject: [R] stopping functions with long execution times
In-Reply-To: <CAFDcVCSQsOouzDx1dz1pEVVLFEW2-3bhMvhiuprTfJHDDViXgw@mail.gmail.com>
References: <AA818EAD2576BC488B4F623941DA7427CD2FD6B0@inbomail.inbo.be>
	<CAFDcVCSQsOouzDx1dz1pEVVLFEW2-3bhMvhiuprTfJHDDViXgw@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD2FD76D@inbomail.inbo.be>

Hi Henrik,

That is exactly what I was looking for.

Thanks a lot.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey


-----Oorspronkelijk bericht-----
Van: henrik.bengtsson at gmail.com [mailto:henrik.bengtsson at gmail.com] Namens Henrik Bengtsson
Verzonden: donderdag 18 juli 2013 12:43
Aan: ONKELINX, Thierry
CC: r-help at r-project.org
Onderwerp: Re: [R] stopping functions with long execution times

See evalWithTimeout() of R.utils, e.g.

tryCatch({
  evalWithTimeout({
    slowFunction();
  }, timeout=7*24*3600);
}, TimeoutException=function(ex) {
  cat("Timeout. Skipping.\n");
})

help("evalWithTimeout") have more information and cross links.

/Henrik

On Thu, Jul 18, 2013 at 11:37 AM, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> Dear all,
>
> I am running the same model on several datasets, each dataset is a different species. The problem is that for some datasets the model is not converging. Currently I have an INLA model running for 35 days and still no results. The process still uses near 100% of the CPU and less than 1 GB RAM on virtual Ubuntu box with 8 GB RAM on a blade server.
>
> I can kill the process manual and make the script skip this model. However it would be more elegant if it was possible to automate this. E.g. let the model run but kill it automatically once it runs for more than 7 days. Once killed the model should throw an error so we can catch that in the error-handling.
>
> Any suggestions on how to do this?
>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and Forest team Biometrie & Kwaliteitszorg / team Biometrics & Quality
> Assurance Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
>
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * *
> * Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From mtmorgan at fhcrc.org  Thu Jul 18 13:45:13 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 18 Jul 2013 04:45:13 -0700
Subject: [R] 'save' method for S4 class
In-Reply-To: <BFAE694C-6BE8-40AD-966D-C79584F18D75@uni-bonn.de>
References: <CA+dpOJ=K_yLH5QeK+PsL6QPXS-Pj1Hpefomh6Z3+MrNfcp=hgA@mail.gmail.com>
	<BFAE694C-6BE8-40AD-966D-C79584F18D75@uni-bonn.de>
Message-ID: <51E7D549.7080507@fhcrc.org>

On 07/18/2013 03:47 AM, Simon Zehnder wrote:
> Hi Christopher,
>
> I think, that "save" is no generic function like "plot", "show", etc. So at first you have to determine a generic.
>
> setGeneric("save", function(x, file_Path) standardGeneric("save"))

The implementation offered by Christofer shows write.table, and the end result 
is a text file rather than a binary file expected from base::save. This makes it 
seem inappropriate to use 'save' in this context.

Instead, it seems that what Cristofer wants to implement is functionality to 
support write.table. ?write.table says

      'write.table' prints its required argument 'x' (after converting
      it to a data frame if it is not one nor a matrix)

So implementing an S3 method

   as.data.frame.MyClass <-
       function(x, row.names=NULL, optional=FALSE, ...)
   {
       x at x
   }

is all that is needed, gaining lots of flexibility by re-using the code of 
write.table.

   myClass = new("MyClass", x=data.frame(x=1:3, y=3:1))
   write.table(myClass, stdout())

In the case of a 'save' method producing binary output (but this is what save 
does already...), I think it's better practice to promote the non-generic 'save' 
to an S4 generic using it's existing arguments; in this case it makes sense to 
restrict dispatch to '...', so

   setGeneric("save", signature="...")

The resulting generic is

 > getGeneric("save")
standardGeneric for "save" defined from package ".GlobalEnv"

function (..., list = character(), file = stop("'file' must be specified"),
     ascii = FALSE, version = NULL, envir = parent.frame(), compress = !ascii,
     compression_level, eval.promises = TRUE, precheck = TRUE)
standardGeneric("save")
<environment: 0x4a7b860>
Methods may be defined for arguments: ...
Use  showMethods("save")  for currently available ones.

This means that a method might be defined as

   setMethod("save", "MyClass", function(..., list = character(),
       file = stop("'file' must be specified"), ascii = FALSE, version = NULL,
       envir = parent.frame(), compress = !ascii, compression_level,
       eval.promises = TRUE, precheck = TRUE)
   {
       ## check non-sensical or unsupported user input for 'MyClass'
       if (!is.null(version))
           stop("non-NULL 'version' not supported for 'MyClass'")
       ## ...
       ## implement save on MyClass
   })

It might be that Christofer wants to implement a 'write.table-like' (text 
output) or a 'save-like' (binary output) function that really does not conform 
to the behavior of write.table (e.g., producing output that could not be input 
by read.table) or save. Then I think the better approach is to implement 
writeMyClass (for text output) or saveMyClass (for binary output).

Martin

>
> Now your definition via setMethod.
>
>
> Best
>
> Simon
>
>
>
> On Jul 18, 2013, at 12:09 PM, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
>
>> Hello again,
>>
>> I am trying to define the 'save' method for my S4 class as below:
>>
>> setClass("MyClass", representation(
>> 		Slot1 = "data.frame"
>> 	))	
>> 	
>> setMethod("save", "MyClass", definition = function(x, file_Path) {
>> 		
>> 		write.table(x at Slot1, file = file_Path, append = FALSE, quote = TRUE,
>> sep = ",",
>> 						eol = "\n", na = "NA", dec = ".", row.names = FALSE,
>> 						col.names = TRUE, qmethod = c("escape", "double"),
>> 						fileEncoding = "")
>> 	})
>>
>> However while doing this I am getting following error:
>>
>> Error in conformMethod(signature, mnames, fnames, f, fdef, definition) :
>>   in method for ?save? with signature ?list="MyClass"?: formal
>> arguments (list = "MyClass", file = "MyClass", ascii = "MyClass",
>> version = "MyClass", envir = "MyClass", compress = "MyClass",
>> compression_level = "MyClass", eval.promises = "MyClass", precheck =
>> "MyClass") omitted in the method definition cannot be in the signature
>>
>>
>> Can somebody point me what will be the correct approach to define
>> 'save' method for S4 class?
>>
>> Thanks and regards,
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From ripley at stats.ox.ac.uk  Thu Jul 18 14:30:25 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Jul 2013 13:30:25 +0100
Subject: [R] stopping functions with long execution times
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427CD2FD6B0@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA7427CD2FD6B0@inbomail.inbo.be>
Message-ID: <51E7DFE1.8090207@stats.ox.ac.uk>

On 18/07/2013 10:37, ONKELINX, Thierry wrote:
> Dear all,
>
> I am running the same model on several datasets, each dataset is a different species. The problem is that for some datasets the model is not converging. Currently I have an INLA model running for 35 days and still no results. The process still uses near 100% of the CPU and less than 1 GB RAM on virtual Ubuntu box with 8 GB RAM on a blade server.
>
> I can kill the process manual and make the script skip this model. However it would be more elegant if it was possible to automate this. E.g. let the model run but kill it automatically once it runs for more than 7 days. Once killed the model should throw an error so we can catch that in the error-handling.
>
> Any suggestions on how to do this?

Learn how to use the R documentation.  ??limit gave me some useful hits, 
including to how I would do this.

However, as ?setTimeLimit points out, if this is running in C code, it 
cannot be interrupted from the R interpreter.  In that case, use 
separate processes and your OS facilities (man ulimit, for example).

>
> Best regards,
>
> Thierry
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
> + 32 2 525 02 51
> + 32 54 43 61 85
> Thierry.Onkelinx at inbo.be
> www.inbo.be
>
> To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
> ~ Sir Ronald Aylmer Fisher
>
> The plural of anecdote is not data.
> ~ Roger Brinner
>
> The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey

And

'Asking on R-help is no substitute for doing your own homework'
>
>
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From smartpink111 at yahoo.com  Thu Jul 18 16:32:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 18 Jul 2013 07:32:43 -0700 (PDT)
Subject: [R] Merge with transposed matrix.
Message-ID: <1374157963.86149.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

m1<- matrix(NA,5,5)
m1[upper.tri(m1)]<-c(2,3,8,4,9,14,5,10,15,20)
One way would be:
m1[lower.tri(m1)]<-t(m1)[lower.tri(t(m1))]
?m1
#???? [,1] [,2] [,3] [,4] [,5]
#[1,]?? NA??? 2??? 3??? 4??? 5
#[2,]??? 2?? NA??? 8??? 9?? 10
#[3,]??? 3??? 8?? NA?? 14?? 15
#[4,]??? 4??? 9?? 14?? NA?? 20
#[5,]??? 5?? 10?? 15?? 20?? NA
A.K. 



Hello ! 

I would like to have some simple sintax in order to fill my matrix with its transposed. 
That is, as an example I have a correlation matrix like this, and the transposed one: 

> matrix 
? ? ? ? ? [,1] ? ? ? ? ? ?[,2] ? ? ? ? [,3] ? ? ? ? [,4] ? ? ? ? [,5] ? ? ? ? 
[1,] ? NA ? ? ? ? ? ? 2 ? ? ? ? ? ? ? 3 ? ? ? ? ? ? ?4 ? ? ? ? ? 5 ? ? ? ? 
[2,] ? NA ? ? ? ? ?NA ? ? ? ? ? ? ?8 ? ? ? ? ? ? ?9 ? ? ? ? ?10 ? ? ? ? 
[3,] ? NA ? ? ? ? ?NA ? ? ? ? ? NA ? ? ? ? ? ?14 ? ? ? ? 15 
[4,] ? NA ? ? ? ? ?NA ? ? ? ? ? NA ? ? ? ? ? NA ? ? ? ? 20 
[5,] ? NA ? ? ? ? ?NA ? ? ? ? ? NA ? ? ? ? ? NA ? ? ? ? NA 

> transposed.matrix<-t(matrix) 

? ? ? ? ? [,1] ? ? ? ? ? ?[,2] ? ? ? ? [,3] ? ? ? ? [,4] ? ? ? ? [,5] 
[1,] ? ? ?NA ? ? ? ? NA ? ? ? ? ?NA ? ? ? ? ?NA ? ? ? ?NA 
[2,] ? ? ? 2 ? ? ? ? ? ?NA ? ? ? ? NA ? ? ? ? ?NA ? ? ? ? NA 
[3,] ? ? ? 3 ? ? ? ? ? ? 8 ? ? ? ? ? ?NA ? ? ? ? NA ? ? ? ? ?NA 
[4,] ? ? ? 4 ? ? ? ? ? ? 9 ? ? ? ? ? ?14 ? ? ? ? ?NA ? ? ? ? ?NA 
[5,] ? ? ? 5 ? ? ? ? ? 10 ? ? ? ? ? 15 ? ? ? ? ? 20 ? ? ? ? ? NA 


And I would like to have.... 

? ? ? ? ? [,1] ? ? ? ? ? ?[,2] ? ? ? ? [,3] ? ? ? ? [,4] ? ? ? ? ?[,5] 
[1,] ? ? ?NA ? ? ? ? ? 2 ? ? ? ? ? ? ? 3 ? ? ? ? ? ? ?4 ? ? ? ? ? ? 5 ? 
[2,] ? ? ? 2 ? ? ? ? ? ?NA ? ? ? ? ? ? 8 ? ? ? ? ? ? ?9 ? ? ? ? ? 10 ? ? 
[3,] ? ? ? 3 ? ? ? ? ? ? 8 ? ? ? ? ? ?NA ? ? ? ? ? ?14 ? ? ? ? ?15 
[4,] ? ? ? 4 ? ? ? ? ? ? 9 ? ? ? ? ? ?14 ? ? ? ? ? ?NA ? ? ? ? ? 20 
[5,] ? ? ? 5 ? ? ? ? ? 10 ? ? ? ? ? 15 ? ? ? ? ? ? 20 ? ? ? ? ? NA 


Thank you very much for your help !!


From smartpink111 at yahoo.com  Thu Jul 18 16:07:44 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 18 Jul 2013 07:07:44 -0700 (PDT)
Subject: [R] Bland Altman summary stats for all column combinations
Message-ID: <1374156464.63692.YahooMailNeo@web142601.mail.bf1.yahoo.com>

HI,
#dat1: data
Combn1<-combn(colnames(dat1)[2:5],2)
#For the first part, may be this helps:
library(plyr)
?res<-lapply(split(Combn1,col(Combn1)),function(x) {x1<-cbind(Var1=colnames(dat1[,x])[1],Var2=colnames(dat1[,x])[2],dat1[,x],Method=dat1[,6]);colnames(x1)[3:4]<- c("V1","V2"); ddply(x1,.(Method,Var1,Var2),summarize, mean1=mean(V1-V2,na.rm=TRUE),sd1=sd(V1-V2,na.rm=TRUE))})
?res[[1]]
#??????? Method Var1 Var2????? mean1????? sd1
#1 Simple_2_ROI?? G1?? G2 -0.6684211 5.223882
#2?? Single_ROI?? G1?? G2? 1.1263158 2.313929
#3 WIG_drawn_bg?? G1?? G2 -1.0894737 4.876576
#4?? WIG_Method?? G1?? G2 -1.1684211 4.894447


Also,
G1 G1 0 0 Simple_2_ROI 
#part is not clear bcz ur ddply() code didn't do that.

A.K.




Hello, 

I have the following data.frame 

structure(list(Study = structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L), .Label = c("WCBP12236", "WCBP12241", "WCBP12242", "WCBP12243", 
"WCBP12245", "WCBP13001", "WCBP13002", "WCBP13003", "WCBP13004", 
"WCBP13005", "WCBP13006", "WCBP13007", "WCBP13008", "WCBP13009", 
"WCBP13010", "WCBP13011", "WCBP13012", "WCBP13013", "WCBP13014" 
), class = "factor"), G1 = c(68, 68.6, 66.6, 73.1, 51.6, 50.1, 
64.1, 73, 63.7, 43.2, 62.3, 59.2, 67.5, 68.2, 54.6, 67.9, 56.5, 
54.2, 67.3, 68, 68.4, 67.9, 73.3, 51.7, 50.3, 63.9, 73.9, 64, 
42.9, 62.5, 59.3, 66.7, 68.4, 54, 68.2, 56.8, 54.5, 67, 53.2, 
41.4, 53, 52.3, 41, 37.4, 56.9, 65.3, 36.2, 35.3, 36.1, 32.5, 
56.5, 47.7, 39.4, 59.6, 38.1, 24.2, 30.2, 68.5, 68.9, 70.7, 74.9, 
53.4, 51.6, 65.9, 75.7, 64.7, 42.8, 61.4, 60.8, 69.5, 68.7, 55.9, 
70.7, 59.5, 51.1, 69.5), G2 = c(79.8, 72.2, 73.5, 74.4, 50.4, 
54.8, 63.1, 70.4, 63.6, 45.1, 65.3, 49.4, 65.3, 76.2, 51, 63.9, 
58.7, 57.8, 67, 79.6, 72.1, 73.9, 74.7, 50.5, 55.1, 62.8, 70.5, 
63.3, 44.6, 65.5, 48.9, 64.9, 76.3, 50.6, 64.8, 58.6, 58.3, 67.4, 
51.2, 37.7, 49.1, 53.7, 44.6, 37.3, 54.9, 64.1, 33.8, 31.9, 34.2, 
30.3, 56.2, 44.6, 38.2, 63.2, 35.8, 26.5, 27.6, 80.6, 71.6, 75.4, 
77.1, 52.4, 56.3, 66, 72.3, 64.5, 38.2, 64.3, 49.2, 66.9, 77.1, 
52.4, 67.5, 59.6, 55.6, 69.9), S1 = c(75.1, 65.9, 72.7, 68.8, 
49, 57.5, 66.5, 74.1, 60.9, 51.8, 58, 64.3, 71.1, 71.4, 58.9, 
62.2, 58, 57.7, 58.6, 75.2, 66, 73.2, 69.7, 48.9, 57.7, 66.5, 
74.7, 60.8, 51.4, 58.9, 65.5, 70.5, 71.4, 58.9, 65.1, 60.8, 57.7, 
58.4, 54.3, 40.2, 52.6, 60.5, 42.6, 34.1, 55, 64.7, 36.3, 32.5, 
39, 38.8, 58.1, 48, 40.5, 61, 40, 26.4, 28.8, 76.4, 66.5, 73.9, 
72, 50.7, 59.2, 69.9, 76.3, 62.4, 50, 58.5, 66.6, 73.7, 72.3, 
62.6, 69.6, 62.7, 57.9, 61.1), S2 = c(76.6, 71.6, 71.2, 72.7, 
51.6, 56.7, 65.9, 73.5, 63.6, 55.2, 62.6, 62.2, 69.1, 71.1, 56.8, 
61, 61.7, 60, 55.7, 76.9, 71.6, 72.3, 73.2, 51.7, 56.8, 64.5, 
74.9, 63.6, 51.3, 63, 62.8, 68.7, 71.3, 56.8, 64.2, 62.8, 60.4, 
55.8, 53.6, 42.5, 50, 54.4, 42.2, 36.4, 57.7, 64.1, 35.1, 30.8, 
39.1, 37.4, 58.7, 47.8, 42, 58.8, 39.4, 24.2, 28.2, 78.2, 73.3, 
72.3, 75.6, 53.4, 57.8, 68.3, 76.6, 63.7, 51.7, 63.4, 63.3, 71.5, 
72.3, 60.2, 67.1, 65.5, 58.2, 59.1), Method = structure(c(4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("Simple_2_ROI", 
"Single_ROI", "WIG_drawn_bg", "WIG_Method"), class = "factor")), .Names = c("Study", 
"G1", "G2", "S1", "S2", "Method"), row.names = c(NA, -76L), class = "data.frame") 

This shows the measurement results of 2 operators using 4 
slightly different analysis methods. The operators analyse each data 
file WCBPXXXXX twice - (G1,G2,S1,S2) and there are 4 methods 
(Single_ROI,Simple_2_ROI etc) 

What I would like to do is get the summary statistics from a Bland Altman (Mean vs Difference) plot for all 16 combinations. 

For example for G1 and G2, I can do the following 

ddply(df,.(Method),summarise,mean=mean(G1-G2, na.rm = TRUE), 
? ? ? ? ? ? ?sd=sd(G1-G2, na.rm = TRUE)) 

Eventually I want a data.frame with the format 
Var1 Var2 Mean ?Sd Method 
G1 ? G2 ? -.67 ?5.2 Simple_2_ROI 
G1 ? G2 ? 1.12 ?2.3 Single_ROI 
G1 ? G2 ? -1.08 4.8 WIG_drawn_bg 
G1 ? G2 ? -1.17 4.9 WIG_Method 
G1 G1 0 0 Simple_2_ROI 

Is there a simple way to achieve this structure? 



From potts.a at gmail.com  Thu Jul 18 11:18:26 2013
From: potts.a at gmail.com (Alastair Potts)
Date: Thu, 18 Jul 2013 11:18:26 +0200
Subject: [R] Orders of levels affecting wilcox.test() output
Message-ID: <CAG_8N1afkpSOjNG+ftHNdLhHOSY3eBAsfFLjm4BVG5ZLF0THvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/ab38b8c2/attachment.pl>

From laomeng_3 at 163.com  Thu Jul 18 09:04:08 2013
From: laomeng_3 at 163.com (meng)
Date: Thu, 18 Jul 2013 15:04:08 +0800 (CST)
Subject: [R] panel setting
Message-ID: <6b8136e8.4c7.13ff097d136.Coremail.laomeng_3@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/787874f1/attachment.pl>

From chrisege at stud.ntnu.no  Thu Jul 18 09:09:04 2013
From: chrisege at stud.ntnu.no (Chris89)
Date: Thu, 18 Jul 2013 00:09:04 -0700 (PDT)
Subject: [R] R-squared and GLM
In-Reply-To: <51E75BD5.1060602@xtra.co.nz>
References: <1374071802773-4671754.post@n4.nabble.com>
	<51E75BD5.1060602@xtra.co.nz>
Message-ID: <1374131344688-4671820.post@n4.nabble.com>

Haha, true true! ;)

It was to be used as a measure on how good the models I use are, but I found
out that the AIC would be much easier to implement, and as I understand, a
better measure of how good the model fit.

Thanks,
Chris



--
View this message in context: http://r.789695.n4.nabble.com/R-squared-and-GLM-tp4671754p4671820.html
Sent from the R help mailing list archive at Nabble.com.


From eric.jaeger at gmx.ch  Thu Jul 18 11:50:03 2013
From: eric.jaeger at gmx.ch (Eric Jaeger)
Date: Thu, 18 Jul 2013 11:50:03 +0200
Subject: [R] Test if 2 samples differ if they have autocorrelation
References: <F0FF65F6CE2DE347B8E3D3F42FEECC917D452BD1@Mailtrading02.trading.imc.intra>
Message-ID: <CC4E07E6-AAAA-409B-A4D6-F0E377D50A43@gmx.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/3cd6610a/attachment.pl>

From jamierobinson at nhs.net  Thu Jul 18 13:47:42 2013
From: jamierobinson at nhs.net (moadeep)
Date: Thu, 18 Jul 2013 04:47:42 -0700 (PDT)
Subject: [R] Bland Altman summary stats for all column combinations
Message-ID: <1374148062475-4671833.post@n4.nabble.com>

Hello,

I have the following data.frame

structure(list(Study = structure(c(1L, 2L, 3L, 4L, 5L, 6L, 7L, 
8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 1L, 
2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 
16L, 17L, 18L, 19L, 1L, 2L, 3L, 4L, 5L, 6L, 7L, 8L, 9L, 10L, 
11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 19L, 1L, 2L, 3L, 4L, 
5L, 6L, 7L, 8L, 9L, 10L, 11L, 12L, 13L, 14L, 15L, 16L, 17L, 18L, 
19L), .Label = c("WCBP12236", "WCBP12241", "WCBP12242", "WCBP12243", 
"WCBP12245", "WCBP13001", "WCBP13002", "WCBP13003", "WCBP13004", 
"WCBP13005", "WCBP13006", "WCBP13007", "WCBP13008", "WCBP13009", 
"WCBP13010", "WCBP13011", "WCBP13012", "WCBP13013", "WCBP13014"
), class = "factor"), G1 = c(68, 68.6, 66.6, 73.1, 51.6, 50.1, 
64.1, 73, 63.7, 43.2, 62.3, 59.2, 67.5, 68.2, 54.6, 67.9, 56.5, 
54.2, 67.3, 68, 68.4, 67.9, 73.3, 51.7, 50.3, 63.9, 73.9, 64, 
42.9, 62.5, 59.3, 66.7, 68.4, 54, 68.2, 56.8, 54.5, 67, 53.2, 
41.4, 53, 52.3, 41, 37.4, 56.9, 65.3, 36.2, 35.3, 36.1, 32.5, 
56.5, 47.7, 39.4, 59.6, 38.1, 24.2, 30.2, 68.5, 68.9, 70.7, 74.9, 
53.4, 51.6, 65.9, 75.7, 64.7, 42.8, 61.4, 60.8, 69.5, 68.7, 55.9, 
70.7, 59.5, 51.1, 69.5), G2 = c(79.8, 72.2, 73.5, 74.4, 50.4, 
54.8, 63.1, 70.4, 63.6, 45.1, 65.3, 49.4, 65.3, 76.2, 51, 63.9, 
58.7, 57.8, 67, 79.6, 72.1, 73.9, 74.7, 50.5, 55.1, 62.8, 70.5, 
63.3, 44.6, 65.5, 48.9, 64.9, 76.3, 50.6, 64.8, 58.6, 58.3, 67.4, 
51.2, 37.7, 49.1, 53.7, 44.6, 37.3, 54.9, 64.1, 33.8, 31.9, 34.2, 
30.3, 56.2, 44.6, 38.2, 63.2, 35.8, 26.5, 27.6, 80.6, 71.6, 75.4, 
77.1, 52.4, 56.3, 66, 72.3, 64.5, 38.2, 64.3, 49.2, 66.9, 77.1, 
52.4, 67.5, 59.6, 55.6, 69.9), S1 = c(75.1, 65.9, 72.7, 68.8, 
49, 57.5, 66.5, 74.1, 60.9, 51.8, 58, 64.3, 71.1, 71.4, 58.9, 
62.2, 58, 57.7, 58.6, 75.2, 66, 73.2, 69.7, 48.9, 57.7, 66.5, 
74.7, 60.8, 51.4, 58.9, 65.5, 70.5, 71.4, 58.9, 65.1, 60.8, 57.7, 
58.4, 54.3, 40.2, 52.6, 60.5, 42.6, 34.1, 55, 64.7, 36.3, 32.5, 
39, 38.8, 58.1, 48, 40.5, 61, 40, 26.4, 28.8, 76.4, 66.5, 73.9, 
72, 50.7, 59.2, 69.9, 76.3, 62.4, 50, 58.5, 66.6, 73.7, 72.3, 
62.6, 69.6, 62.7, 57.9, 61.1), S2 = c(76.6, 71.6, 71.2, 72.7, 
51.6, 56.7, 65.9, 73.5, 63.6, 55.2, 62.6, 62.2, 69.1, 71.1, 56.8, 
61, 61.7, 60, 55.7, 76.9, 71.6, 72.3, 73.2, 51.7, 56.8, 64.5, 
74.9, 63.6, 51.3, 63, 62.8, 68.7, 71.3, 56.8, 64.2, 62.8, 60.4, 
55.8, 53.6, 42.5, 50, 54.4, 42.2, 36.4, 57.7, 64.1, 35.1, 30.8, 
39.1, 37.4, 58.7, 47.8, 42, 58.8, 39.4, 24.2, 28.2, 78.2, 73.3, 
72.3, 75.6, 53.4, 57.8, 68.3, 76.6, 63.7, 51.7, 63.4, 63.3, 71.5, 
72.3, 60.2, 67.1, 65.5, 58.2, 59.1), Method = structure(c(4L, 
4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 4L, 
4L, 4L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 3L, 
3L, 3L, 3L, 3L, 3L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 
2L, 2L, 2L, 2L, 2L, 2L, 2L, 2L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L), .Label = c("Simple_2_ROI", 
"Single_ROI", "WIG_drawn_bg", "WIG_Method"), class = "factor")), .Names =
c("Study", 
"G1", "G2", "S1", "S2", "Method"), row.names = c(NA, -76L), class =
"data.frame")

This shows the measurement results of 2 operators using 4 slightly different
analysis methods. The operators analyse each data file WCBPXXXXX twice -
(G1,G2,S1,S2) and there are 4 methods (Single_ROI,Simple_2_ROI etc)

What I would like to do is get the summary statistics from a Bland Altman
(Mean vs Difference) plot for all 16 combinations.

For example for G1 and G2, I can do the following

ddply(df,.(Method),summarise,mean=mean(G1-G2, na.rm = TRUE),
             sd=sd(G1-G2, na.rm = TRUE))

Eventually I want a data.frame with the format
Var1 Var2 Mean  Sd Method
G1   G2   -.67  5.2 Simple_2_ROI
G1   G2   1.12  2.3 Single_ROI
G1   G2   -1.08 4.8 WIG_drawn_bg
G1   G2   -1.17 4.9 WIG_Method
G1 G1 0 0 Simple_2_ROI

Is there a simple way to achieve this structure?

>From that things get more tricky. What I would like to do is to create a
heatmap using ggplot2 (geom_tile) to provide a visual summary of the data
similar to the correlation heatmap I have produced from the same data set
<http://r.789695.n4.nabble.com/file/n4671833/EFCorrelations.png> 
Instead of filling each tile based on R^2 I would like to fill based on
standard deviation. Also I would like to add geom_text to each tile
highlighting the bias (mean difference) and the standard deviation.

Any pointers how I can achieve this. I am completely stuck.

Here is my code for the correlation heatmap
plots <- dlply(df, .(Method), function (x1) {
    ggplot(subset(melt(cor(x1[sapply(x1,is.numeric)]))[lower.tri(c),],Var1
!= Var2),
           aes(x=Var1,y=Var2,fill=value)) + geom_tile(aes(fill =
value),colour = "white") +
        geom_text(aes(label = sprintf("%1.2f",value)), vjust = 1) + 
        theme_bw() +
        scale_fill_gradient2(name="R^2",midpoint=0.7,low = "white", high =
"red") + xlab(NULL)+ylab(NULL) +
theme(axis.text.x=element_blank(),axis.text.y=element_blank(),
axis.ticks=element_blank(),panel.border=element_blank()) +
ggtitle(x1$Method) + theme(plot.title =
element_text(lineheight=1,face="bold")) + geom_text(data =
subset(melt(cor(x1[sapply(x1,is.numeric)])),Var1==Var2),aes(label=Var1),vjust=3
) })

#Function to grab legend
g_legend<-function(a.gplot){
    tmp <- ggplot_gtable(ggplot_build(a.gplot))
    leg <- which(sapply(tmp$grobs, function(x) x$name) == "guide-box")
    legend <- tmp$grobs[[leg]]
    legend
}

legend <- g_legend(plots$WIG_Method)

grid.arrange(legend,plots$Single_ROI+theme(legend.position='none'),
plots$Simple_2_ROI+theme(legend.position='none'),plots$WIG_Method+theme(legend.position='none'),
plots$WIG_drawn_bg+theme(legend.position='none'), ncol=5, nrow=1,
widths=c(1/17,4/17,4/17,4/17,4/17))





--
View this message in context: http://r.789695.n4.nabble.com/Bland-Altman-summary-stats-for-all-column-combinations-tp4671833.html
Sent from the R help mailing list archive at Nabble.com.


From bcrombie at utk.edu  Thu Jul 18 15:17:21 2013
From: bcrombie at utk.edu (bcrombie)
Date: Thu, 18 Jul 2013 06:17:21 -0700 (PDT)
Subject: [R] combine select data from 2 dataframes sharing same variables
In-Reply-To: <3CD374BF2C285940A54C0A71225AF7DB0357678238@AKLEXM01.PFR.CO.NZ>
References: <1374091972085-4671790.post@n4.nabble.com>
	<3CD374BF2C285940A54C0A71225AF7DB0357678238@AKLEXM01.PFR.CO.NZ>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE7F3BB6DC@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/d4cf2671/attachment.pl>

From zhulinkin at gmail.com  Thu Jul 18 16:56:20 2013
From: zhulinkin at gmail.com (=?GB2312?B?1uzB1g==?=)
Date: Thu, 18 Jul 2013 22:56:20 +0800
Subject: [R] binary distance measure of the "dist" function in the "stats"
	package
Message-ID: <CACG=VbfGFUmctS-WvDOeijZkhoiq1Gn=iTwkV7pnwDRDkabh1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/da04c864/attachment.pl>

From dcarlson at tamu.edu  Thu Jul 18 17:29:46 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 18 Jul 2013 10:29:46 -0500
Subject: [R] binary distance measure of the "dist" function in the
	"stats"	package
In-Reply-To: <CACG=VbfGFUmctS-WvDOeijZkhoiq1Gn=iTwkV7pnwDRDkabh1w@mail.gmail.com>
References: <CACG=VbfGFUmctS-WvDOeijZkhoiq1Gn=iTwkV7pnwDRDkabh1w@mail.gmail.com>
Message-ID: <01ad01ce83cb$a25d3420$e7179c60$@tamu.edu>

If you read ?dist, it says that:

binary:
    (aka asymmetric binary): The vectors are regarded as
binary bits, so non-zero elements are ?on? and zero elements
are ?off?. The distance is the proportion of bits in which
only one is on amongst those in which at least one is on.

The short answer is that this is the Jaccard Distance measure.
If we label the cells of a 2x2 presence absence matrix as a,
b, c, d:

          Present  Absent
Present      a        b
Absent       c        d

Then the Jaccard Similarity index is a/(a+b+c)
And the Jaccard Distance index is (1 - a/(a+b+c)) or
(b+c)/(a+b+c)

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of ??
Sent: Thursday, July 18, 2013 9:56 AM
To: r-help at r-project.org
Subject: [R] binary distance measure of the "dist" function in
the "stats" package

Dear all:
    I want to ask question about "binary" distance measure. As
far as I
know, there are many binary distance measures,eg, binary
Jarcad distance,
binary euclidean distance, and binary Bray-Curtis
distance,etc. It is even
more confusing because many have more than one name. So , I
wan to know
what the definite name of  the binary distance measure of the
"dist"
function in the "stats" package is and further want to know
the equation of
the binary distance. Thank you very much!
With  my  best  regards.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From george.milunovich at mq.edu.au  Thu Jul 18 17:14:19 2013
From: george.milunovich at mq.edu.au (george)
Date: Thu, 18 Jul 2013 08:14:19 -0700 (PDT)
Subject: [R] restrected arima models
Message-ID: <1374160459268-4671847.post@n4.nabble.com>

Dear all,
Does anyone know if it is possible to estimate restricted arima models using
the arima command in R? For instance lets say I want arima(6,0,0) but where
the first three ar parameters are restricted to zero, ie. ar(1)=ar(2)=ar(3)
= 0, and only the last three are actually estimated. 
Any help will be much appreciated.
george 



--
View this message in context: http://r.789695.n4.nabble.com/restrected-arima-models-tp4671847.html
Sent from the R help mailing list archive at Nabble.com.


From otyancey at email.wm.edu  Thu Jul 18 17:28:09 2013
From: otyancey at email.wm.edu (Owen Yancey)
Date: Thu, 18 Jul 2013 11:28:09 -0400
Subject: [R] Moran's I
Message-ID: <CAKrQRVQ6m-1yf2TvTOL4NhJ=JUwBEJEi42TrG6fwMogSwBoubQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/f0a3b1d9/attachment.pl>

From 538280 at gmail.com  Thu Jul 18 17:51:30 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 18 Jul 2013 09:51:30 -0600
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAKyN3iB0y_EvM-64UZVuUkMaPKaoYKw38yG7MYd2AsZSFEh60w@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
	<CAKyN3iB0y_EvM-64UZVuUkMaPKaoYKw38yG7MYd2AsZSFEh60w@mail.gmail.com>
Message-ID: <CAFEqCdxrex267-FurkVtM5uXSu+D+9=4q+RVqFBE3_Dur-dnXA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/87d472da/attachment.pl>

From 538280 at gmail.com  Thu Jul 18 17:55:38 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 18 Jul 2013 09:55:38 -0600
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <7E74DEBD-3CD0-434A-BB9D-947A302B4701@me.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
	<7E74DEBD-3CD0-434A-BB9D-947A302B4701@me.com>
Message-ID: <CAFEqCdyiOx6ARZS3qibJG6_HR+wOSbKTzo8pL1S6252n+BCW7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/995d1034/attachment.pl>

From dcarlson at tamu.edu  Thu Jul 18 17:56:10 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 18 Jul 2013 10:56:10 -0500
Subject: [R] Orders of levels affecting wilcox.test() output
In-Reply-To: <CAG_8N1afkpSOjNG+ftHNdLhHOSY3eBAsfFLjm4BVG5ZLF0THvw@mail.gmail.com>
References: <CAG_8N1afkpSOjNG+ftHNdLhHOSY3eBAsfFLjm4BVG5ZLF0THvw@mail.gmail.com>
Message-ID: <01b401ce83cf$527b14f0$f7713ed0$@tamu.edu>

The short answer is whichever version you want since they are
the same. Look at the t-test results, they are also different.
In one t is positive and in the other it is negative. That is
just a result of whether the smaller mean is subtracted from
the larger mean or vice versa. The same is happening with
Wilcoxon (see
http://en.wikipedia.org/wiki/Mann-Whitney-Wilcoxon_test ) for
the specific equations. 

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Alastair
Potts
Sent: Thursday, July 18, 2013 4:18 AM
To: r-help at r-project.org
Subject: [R] Orders of levels affecting wilcox.test() output

Good day all,

My first posting to this list. It looked like the best place
to post this
question.

When running the wilcox.test(), I noticed that the output
values change if
you change the ordering of the levels (example below which
includes a
t.test for comparison). I think this has something to do with
the change in
ranking order, but this doesn't make much sense as I would
expect the
ranking in this case to remain constant as there are no ties.
So my
questions are: a) is this correct (i.e. not a bug)?, and b) if
it is, then
which values should I report?


x <-
cbind(data.frame((c(rep("A",50),rep("B",50)))),runif(100))
colnames(x) <- c("a","b")
wilcox.test(b~a,data=x)
t.test(b~a,data=x)
x$a <- relevel(x$a,ref="B")
wilcox.test(b~a,data=x)
t.test(b~a,data=x)

Thank you in advance for your time,
Regards,
Alastair

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From demauro.jason at gmail.com  Thu Jul 18 18:02:32 2013
From: demauro.jason at gmail.com (Jason)
Date: Thu, 18 Jul 2013 12:02:32 -0400
Subject: [R] Changing settings
Message-ID: <51E81198.8000706@gmail.com>

How do I change my email settings? I would like to limit the emails that 
I receive to only those of interest.


From liuwensui at gmail.com  Thu Jul 18 18:07:46 2013
From: liuwensui at gmail.com (Wensui Liu)
Date: Thu, 18 Jul 2013 12:07:46 -0400
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAFEqCdxrex267-FurkVtM5uXSu+D+9=4q+RVqFBE3_Dur-dnXA@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
	<CAKyN3iB0y_EvM-64UZVuUkMaPKaoYKw38yG7MYd2AsZSFEh60w@mail.gmail.com>
	<CAFEqCdxrex267-FurkVtM5uXSu+D+9=4q+RVqFBE3_Dur-dnXA@mail.gmail.com>
Message-ID: <CAKyN3iDoeT2Q5U6NMqv=9hOFbCkKLLcxcRDwp-OB4Popdrs2wA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/74aa5ccf/attachment.pl>

From 538280 at gmail.com  Thu Jul 18 18:08:57 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 18 Jul 2013 10:08:57 -0600
Subject: [R] Orders of levels affecting wilcox.test() output
In-Reply-To: <CAG_8N1afkpSOjNG+ftHNdLhHOSY3eBAsfFLjm4BVG5ZLF0THvw@mail.gmail.com>
References: <CAG_8N1afkpSOjNG+ftHNdLhHOSY3eBAsfFLjm4BVG5ZLF0THvw@mail.gmail.com>
Message-ID: <CAFEqCdy+6ayFvJ2H8nWJw9vpbwicK_BEqFx5mczEQ2y60Nn2dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/ff8f786a/attachment.pl>

From marc_schwartz at me.com  Thu Jul 18 18:09:43 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 18 Jul 2013 11:09:43 -0500
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAFEqCdyiOx6ARZS3qibJG6_HR+wOSbKTzo8pL1S6252n+BCW7Q@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
	<7E74DEBD-3CD0-434A-BB9D-947A302B4701@me.com>
	<CAFEqCdyiOx6ARZS3qibJG6_HR+wOSbKTzo8pL1S6252n+BCW7Q@mail.gmail.com>
Message-ID: <95F5A2F2-E46D-42DE-AB84-01714842EC78@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/e7c010a4/attachment.pl>

From 538280 at gmail.com  Thu Jul 18 18:19:16 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 18 Jul 2013 10:19:16 -0600
Subject: [R] panel setting
In-Reply-To: <6b8136e8.4c7.13ff097d136.Coremail.laomeng_3@163.com>
References: <6b8136e8.4c7.13ff097d136.Coremail.laomeng_3@163.com>
Message-ID: <CAFEqCdzSy2eKKn=D39NJRunu6aFrvAY8xCBYVvFhLbuQp1RQwQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/fe80867b/attachment.pl>

From dcarlson at tamu.edu  Thu Jul 18 18:23:32 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 18 Jul 2013 11:23:32 -0500
Subject: [R] Changing settings
In-Reply-To: <51E81198.8000706@gmail.com>
References: <51E81198.8000706@gmail.com>
Message-ID: <01ca01ce83d3$2527da70$6f778f50$@tamu.edu>

Go to Settings  | Filters in Gmail and set filters to delete
the r-help messages you don't want or move them to a folder
for review. R-help messages are not tagged so you cannot
restrict them before they are sent. 

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Jason
Sent: Thursday, July 18, 2013 11:03 AM
To: R-help at r-project.org
Subject: [R] Changing settings

How do I change my email settings? I would like to limit the
emails that 
I receive to only those of interest.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From ruipbarradas at sapo.pt  Thu Jul 18 18:36:05 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 18 Jul 2013 17:36:05 +0100
Subject: [R] restrected arima models
In-Reply-To: <1374160459268-4671847.post@n4.nabble.com>
References: <1374160459268-4671847.post@n4.nabble.com>
Message-ID: <51E81975.4080808@sapo.pt>

Hello,

Take a look at parameter 'fixed' of function arima. From the help page 
for arima():

"fixed 	

optional numeric vector of the same length as the total number of 
parameters. If supplied, only NA entries in fixed will be varied."


Example use ('fixed' has length 7 because we must count the intercept term):

x <- ts(cumsum(rnorm(100)))

fit <- arima(x, order = c(6,0,0), fixed = c(0, 0, 0, NA, NA, NA, NA), 
transform.pars = FALSE)
fit

Hope this helps,

Rui Barradas

Em 18-07-2013 16:14, george escreveu:
> Dear all,
> Does anyone know if it is possible to estimate restricted arima models using
> the arima command in R? For instance lets say I want arima(6,0,0) but where
> the first three ar parameters are restricted to zero, ie. ar(1)=ar(2)=ar(3)
> = 0, and only the last three are actually estimated.
> Any help will be much appreciated.
> george
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/restrected-arima-models-tp4671847.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ripley at stats.ox.ac.uk  Thu Jul 18 18:40:18 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 18 Jul 2013 17:40:18 +0100
Subject: [R] restrected arima models
In-Reply-To: <1374160459268-4671847.post@n4.nabble.com>
References: <1374160459268-4671847.post@n4.nabble.com>
Message-ID: <51E81A72.50108@stats.ox.ac.uk>

On 18/07/2013 16:14, george wrote:
> Dear all,
> Does anyone know if it is possible to estimate restricted arima models using
> the arima command in R? For instance lets say I want arima(6,0,0) but where
> the first three ar parameters are restricted to zero, ie. ar(1)=ar(2)=ar(3)
> = 0, and only the last three are actually estimated.

Yes.

> Any help will be much appreciated.

Have you read the help page?  Someone helped you by writing it (and 
indeed, by providing the facility, which few ARIMA-fitting programs have).

    fixed: optional numeric vector of the same length as the total
           number of parameters.  If supplied, only ?NA? entries in
           ?fixed? will be varied.  ?transform.pars = TRUE? will be
           overridden (with a warning) if any AR parameters are fixed.

E.g.

x <- rnorm(100)
arima(x, order=c(6,0,0), fixed = c(0,0,0,NA,NA,NA,NA))

Coefficients:
       ar1  ar2  ar3     ar4     ar5     ar6  intercept
         0    0    0  0.0423  0.0977  0.1299    -0.1462
s.e.    0    0    0  0.1065  0.1075  0.1059     0.1323


> george



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dwinsemius at comcast.net  Thu Jul 18 19:29:31 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 18 Jul 2013 10:29:31 -0700
Subject: [R] Changing settings
In-Reply-To: <51E81198.8000706@gmail.com>
References: <51E81198.8000706@gmail.com>
Message-ID: <4BECC2BC-72F5-4812-A012-9A343A8D0B60@comcast.net>


On Jul 18, 2013, at 9:02 AM, Jason wrote:

> How do I change my email settings? I would like to limit the emails that I receive to only those of interest.
> 

You can use various search engines. I like the MarkMail option. It allows me to search in various r-related groups. If you wnat to run it daily with a particular set of filters, that should be possible to automate.

http://markmail.org/search/?q=list%3Aorg.r-project

-- 
David Winsemius
Alameda, CA, USA


From tmrsg11 at gmail.com  Thu Jul 18 20:13:37 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 18 Jul 2013 14:13:37 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
Message-ID: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>

Hi everyone,

I am using package knitr, FIRST TIME.  I don't have access to RStudio.

Read through Yihui's page, didn't find it helpful.  Stuck on terms
Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
reference is not helping.

Is there a simple step-by-step example WITHOUT RStudio?

My question:
What is the procedure?  The documentation explains the functions, but
does not say how to operate between R and LaTex.

Mike


From george.milunovich at mq.edu.au  Thu Jul 18 20:14:03 2013
From: george.milunovich at mq.edu.au (George Milunovich)
Date: Fri, 19 Jul 2013 03:14:03 +0900
Subject: [R] Difference between arima(1, 1, 1) of y and arima(1, 0,
	1) of diff(y)
Message-ID: <C9005956-FC61-4C69-B913-E0FC3653C605@mq.edu.au>

Dear all,
When I run an arima(1,1,1) on an I(1) variable, y, I get different estimates to when I first difference the variable myself, e.g y2<-diff(y), and then run arima(1,0,1) on y2. Shouldn't these two approaches give the same output?
Any help will be much appreciated.
george


From george.milunovich at mq.edu.au  Thu Jul 18 20:16:15 2013
From: george.milunovich at mq.edu.au (george)
Date: Thu, 18 Jul 2013 11:16:15 -0700 (PDT)
Subject: [R] restrected arima models
In-Reply-To: <51E81A72.50108@stats.ox.ac.uk>
References: <1374160459268-4671847.post@n4.nabble.com>
	<51E81A72.50108@stats.ox.ac.uk>
Message-ID: <21E713AD-CF62-4875-8753-D3226EBB12B0@mq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/f6c01d03/attachment.pl>

From bogaso.christofer at gmail.com  Thu Jul 18 20:23:14 2013
From: bogaso.christofer at gmail.com (Christofer Bogaso)
Date: Fri, 19 Jul 2013 00:08:14 +0545
Subject: [R] 'save' method for S4 class
In-Reply-To: <BFAE694C-6BE8-40AD-966D-C79584F18D75@uni-bonn.de>
References: <CA+dpOJ=K_yLH5QeK+PsL6QPXS-Pj1Hpefomh6Z3+MrNfcp=hgA@mail.gmail.com>
	<BFAE694C-6BE8-40AD-966D-C79584F18D75@uni-bonn.de>
Message-ID: <CA+dpOJksoLMhtKvkwg4AJmkRErjpxCfCANpTWB36uROvZaWLtw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/493cacee/attachment.pl>

From xie at yihui.name  Thu Jul 18 20:43:33 2013
From: xie at yihui.name (Yihui Xie)
Date: Thu, 18 Jul 2013 11:43:33 -0700
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
Message-ID: <CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>

I'm not sure what your question really is. You do not have to use
RStudio, but it will be much easier to get started with RStudio,
because it does a lot of automatic conversion behind the scenes (e.g.
tex to PDF, markdown to HTML, ...). If you want a "pure" solution
without any text editor support, the answer is

library(knitr)
knit('your_input_file')

For example, knit('foo.Rnw') gives you foo.tex; if you are familiar
with LaTeX, you can mess with this foo.tex now (outside of R).

Minimal examples for different document formats are at
http://yihui.name/knitr/demo/minimal/ (you must have read this page),
and more examples at https://github.com/yihui/knitr-examples

If you are asking about the internals of knitr, "Luke, use the
source": https://github.com/yihui/knitr Or for a more comprehensive
introduction, see http://www.crcpress.com/product/isbn/9781482203530

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Thu, Jul 18, 2013 at 11:13 AM, C W <tmrsg11 at gmail.com> wrote:
> Hi everyone,
>
> I am using package knitr, FIRST TIME.  I don't have access to RStudio.
>
> Read through Yihui's page, didn't find it helpful.  Stuck on terms
> Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
> reference is not helping.
>
> Is there a simple step-by-step example WITHOUT RStudio?
>
> My question:
> What is the procedure?  The documentation explains the functions, but
> does not say how to operate between R and LaTex.
>
> Mike
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From george.milunovich at mq.edu.au  Thu Jul 18 20:49:07 2013
From: george.milunovich at mq.edu.au (george)
Date: Thu, 18 Jul 2013 11:49:07 -0700 (PDT)
Subject: [R] Difference between arima(1, 1, 1) for y and arima(1, 0,
	1) for diff(y)
Message-ID: <1374173347596-4671873.post@n4.nabble.com>

Dear all,
When I run an arima(1,1,1) on an I(1) variable, e.g. y, I get different
estimates to when I first difference the variable myself, e.g y2<-diff(y),
and then run arima(1,0,1) on y2. Shouldn't these two approaches give the
same output?
Any help will be much appreciated.
george



--
View this message in context: http://r.789695.n4.nabble.com/Difference-between-arima-1-1-1-for-y-and-arima-1-0-1-for-diff-y-tp4671873.html
Sent from the R help mailing list archive at Nabble.com.


From markleeds2 at gmail.com  Thu Jul 18 20:51:45 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Thu, 18 Jul 2013 14:51:45 -0400
Subject: [R] Difference between arima(1, 1, 1) of y and arima(1, 0,
	1) of diff(y)
In-Reply-To: <C9005956-FC61-4C69-B913-E0FC3653C605@mq.edu.au>
References: <C9005956-FC61-4C69-B913-E0FC3653C605@mq.edu.au>
Message-ID: <CAHz+bWaP5+qwB0GN2LcNod08RQwKyZw_RZ0Go=A8i+Eob-yH7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/24752934/attachment.pl>

From tmrsg11 at gmail.com  Thu Jul 18 20:52:28 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 18 Jul 2013 14:52:28 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
Message-ID: <CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>

How do you create a .Rnw file, in R or LaTex?  I don't think any
tutorial mentions it.

btw, I am very new to the terms like markdown, so I don't understand
"markdown to HTML".

I am reading here http://biostat.mc.vanderbilt.edu/wiki/Main/KnitrHowto
that you need to compile at terminal.  I do not know terminal, is
there other ways?

Could you do a video on just "simple" R?  I have seen 3 videos on R
Studio including yours.

Mike

On Thu, Jul 18, 2013 at 2:43 PM, Yihui Xie <xie at yihui.name> wrote:
> I'm not sure what your question really is. You do not have to use
> RStudio, but it will be much easier to get started with RStudio,
> because it does a lot of automatic conversion behind the scenes (e.g.
> tex to PDF, markdown to HTML, ...). If you want a "pure" solution
> without any text editor support, the answer is
>
> library(knitr)
> knit('your_input_file')
>
> For example, knit('foo.Rnw') gives you foo.tex; if you are familiar
> with LaTeX, you can mess with this foo.tex now (outside of R).
>
> Minimal examples for different document formats are at
> http://yihui.name/knitr/demo/minimal/ (you must have read this page),
> and more examples at https://github.com/yihui/knitr-examples
>
> If you are asking about the internals of knitr, "Luke, use the
> source": https://github.com/yihui/knitr Or for a more comprehensive
> introduction, see http://www.crcpress.com/product/isbn/9781482203530
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Phone: 206-667-4385 Web: http://yihui.name
> Fred Hutchinson Cancer Research Center, Seattle
>
>
> On Thu, Jul 18, 2013 at 11:13 AM, C W <tmrsg11 at gmail.com> wrote:
>> Hi everyone,
>>
>> I am using package knitr, FIRST TIME.  I don't have access to RStudio.
>>
>> Read through Yihui's page, didn't find it helpful.  Stuck on terms
>> Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
>> reference is not helping.
>>
>> Is there a simple step-by-step example WITHOUT RStudio?
>>
>> My question:
>> What is the procedure?  The documentation explains the functions, but
>> does not say how to operate between R and LaTex.
>>
>> Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From wetbelldiver at gmail.com  Thu Jul 18 18:35:08 2013
From: wetbelldiver at gmail.com (Wet Bell Diver)
Date: Thu, 18 Jul 2013 18:35:08 +0200
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <95F5A2F2-E46D-42DE-AB84-01714842EC78@me.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
	<7E74DEBD-3CD0-434A-BB9D-947A302B4701@me.com>
	<CAFEqCdyiOx6ARZS3qibJG6_HR+wOSbKTzo8pL1S6252n+BCW7Q@mail.gmail.com>
	<95F5A2F2-E46D-42DE-AB84-01714842EC78@me.com>
Message-ID: <51E8193C.1090702@gmail.com>


Here's one way:

Vec <- rnorm(30)
Vec.cut <- cut(Vec, breaks=c(quantile(Vec, probs = seq(0, 1, by = 0.20))),
     labels=c("0-20","20-40","40-60","60-80","80-100"), include.lowest=TRUE)
table(Vec.cut)


or determine the breaks automatically:

cut.size <- function(x, size) {
   cut.prob <- size/length(x)
   if (length(x)%%size != 0) warning("Equal sized groups only possible 
by dropping some elements from x")
   Vec.cut <- cut(x, breaks=c(quantile(x, probs = seq(0, 1, by = 
size/length(x)))), include.lowest=TRUE)
}
CUT <- cut.size(Vec, 6)
table(CUT)

When asking for
cut.size(Vec, 7)
this will yield 4 equal-sized groups of 7, because there is no way to 
perfectly split 30 observations in groups of 7 each.

HTH,
Peter


Op 18-7-2013 18:09, Marc Schwartz schreef:
> Greg,
>
> Good catch. My recollection was that the vector would be broken up into 'breaks' groups of equal size, however it is range(x) that is split into 'breaks' intervals, each of which is equal width.
>
> Thanks,
>
> Marc
>
>
> On Jul 18, 2013, at 10:55 AM, Greg Snow <538280 at gmail.com> wrote:
>
>> Marc,
>>
>> Your method works fine when the data is perfectly uniform, but try it with "Vec <- rnorm(30)" and you will see that there are more observations in the middle groups and fewer in the tail groups.  Something like quantile needs to be used to find the unequally spaced breaks that will give equal counts within groups.
>>
>>
>> On Wed, Jul 17, 2013 at 5:04 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
>> On Jul 17, 2013, at 4:43 PM, Witold E Wolski <wewolski at gmail.com> wrote:
>>
>>> I would like to "cut" a vector into groups of equal nr of elements.
>>> looking for a function on the lines of cut but where I can specify
>>> the size of the groups instead of the nr of groups.
>>
>>
>> In addition to the other options, if the 'breaks' argument to cut() is a single number, rather than a vector of cut points, it defines the number of intervals to break the 'x' vector into, which of course you can derive from length(x) / size.
>>
>> Thus:
>>
>> set.seed(1)
>> Vec <- sample(30)
>>
>>> Vec
>>   [1]  8 11 17 25  6 23 27 16 14  2  5  4 13  7 18 30 29 24 20  9 10 21
>> [23] 26  1 22 15 28 12  3 19
>>
>>
>> # Split into 5 groups of 6 each
>>
>>> split(Vec, cut(Vec, 5))
>> $`(0.971,6.78]`
>> [1] 6 2 5 4 1 3
>>
>> $`(6.78,12.6]`
>> [1]  8 11  7  9 10 12
>>
>> $`(12.6,18.4]`
>> [1] 17 16 14 13 18 15
>>
>> $`(18.4,24.2]`
>> [1] 23 24 20 21 22 19
>>
>> $`(24.2,30]`
>> [1] 25 27 30 29 26 28
>>
>>
>> Regards,
>>
>> Marc Schwartz
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>>
>> -- 
>> Gregory (Greg) L. Snow Ph.D.
>> 538280 at gmail.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Eli.Ateljevich at water.ca.gov  Thu Jul 18 18:38:33 2013
From: Eli.Ateljevich at water.ca.gov (Ateljevich, Eli@DWR)
Date: Thu, 18 Jul 2013 16:38:33 +0000
Subject: [R] Principal component / EOF analysis of data dominated by a
 couple frequencies
Message-ID: <73F8F665C0FCF549AF963069AB8CB27F16121F@057-SN2MPN1-042.057d.mgd.msft.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/8a6381d6/attachment.pl>

From girijagun at gmail.com  Thu Jul 18 18:50:34 2013
From: girijagun at gmail.com (G Girija)
Date: Thu, 18 Jul 2013 22:20:34 +0530
Subject: [R] extracting variance and covariance
Message-ID: <CAOLvsEwthi6Z-8OMMhHpGAF635zLF9kmgWnKike7LCp0B42qig@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/ff554b5b/attachment.pl>

From george.milunovich at mq.edu.au  Thu Jul 18 21:03:24 2013
From: george.milunovich at mq.edu.au (George Milunovich)
Date: Fri, 19 Jul 2013 04:03:24 +0900
Subject: [R] Difference between arima(1, 1, 1) of y and arima(1, 0,
	1) of diff(y)
In-Reply-To: <CAHz+bWaP5+qwB0GN2LcNod08RQwKyZw_RZ0Go=A8i+Eob-yH7w@mail.gmail.com>
References: <C9005956-FC61-4C69-B913-E0FC3653C605@mq.edu.au>
	<CAHz+bWaP5+qwB0GN2LcNod08RQwKyZw_RZ0Go=A8i+Eob-yH7w@mail.gmail.com>
Message-ID: <50FA8D41-4BF4-48E9-BF0B-CF8F3B2EE51D@mq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/4815735d/attachment.pl>

From szehnder at uni-bonn.de  Thu Jul 18 21:25:13 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 18 Jul 2013 21:25:13 +0200
Subject: [R] 'save' method for S4 class
In-Reply-To: <CA+dpOJksoLMhtKvkwg4AJmkRErjpxCfCANpTWB36uROvZaWLtw@mail.gmail.com>
References: <CA+dpOJ=K_yLH5QeK+PsL6QPXS-Pj1Hpefomh6Z3+MrNfcp=hgA@mail.gmail.com>
	<BFAE694C-6BE8-40AD-966D-C79584F18D75@uni-bonn.de>
	<CA+dpOJksoLMhtKvkwg4AJmkRErjpxCfCANpTWB36uROvZaWLtw@mail.gmail.com>
Message-ID: <B65D2268-87EF-4400-A2E3-8437284B5F08@uni-bonn.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/65aa3b2a/attachment.pl>

From szehnder at uni-bonn.de  Thu Jul 18 21:31:34 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 18 Jul 2013 21:31:34 +0200
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
Message-ID: <EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>

Hi Mike,

I found my way with this little blog: http://yihui.name/knitr/demo/editors/

The .Rnw files are created very well in a Latex editor. Everything else can be easily googled. The command via knitr::knit2pdf works very fine if you use the chunks. If you are trying to compile an Rtex file, this I do not know either (I like the symbols though in for example https://github.com/yihui/knitr-examples/blob/master/005-latex.Rtex). But the .Rnw files are compiled pretty nice in e.g. texmaker, as described in the blog. Use for example this source file: https://github.com/yihui/knitr/blob/master/inst/examples/knitr-minimal.Rnw


Hope this helps


Best

Simon





On Jul 18, 2013, at 8:52 PM, C W <tmrsg11 at gmail.com> wrote:

> How do you create a .Rnw file, in R or LaTex?  I don't think any
> tutorial mentions it.
> 
> btw, I am very new to the terms like markdown, so I don't understand
> "markdown to HTML".
> 
> I am reading here http://biostat.mc.vanderbilt.edu/wiki/Main/KnitrHowto
> that you need to compile at terminal.  I do not know terminal, is
> there other ways?
> 
> Could you do a video on just "simple" R?  I have seen 3 videos on R
> Studio including yours.
> 
> Mike
> 
> On Thu, Jul 18, 2013 at 2:43 PM, Yihui Xie <xie at yihui.name> wrote:
>> I'm not sure what your question really is. You do not have to use
>> RStudio, but it will be much easier to get started with RStudio,
>> because it does a lot of automatic conversion behind the scenes (e.g.
>> tex to PDF, markdown to HTML, ...). If you want a "pure" solution
>> without any text editor support, the answer is
>> 
>> library(knitr)
>> knit('your_input_file')
>> 
>> For example, knit('foo.Rnw') gives you foo.tex; if you are familiar
>> with LaTeX, you can mess with this foo.tex now (outside of R).
>> 
>> Minimal examples for different document formats are at
>> http://yihui.name/knitr/demo/minimal/ (you must have read this page),
>> and more examples at https://github.com/yihui/knitr-examples
>> 
>> If you are asking about the internals of knitr, "Luke, use the
>> source": https://github.com/yihui/knitr Or for a more comprehensive
>> introduction, see http://www.crcpress.com/product/isbn/9781482203530
>> 
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Phone: 206-667-4385 Web: http://yihui.name
>> Fred Hutchinson Cancer Research Center, Seattle
>> 
>> 
>> On Thu, Jul 18, 2013 at 11:13 AM, C W <tmrsg11 at gmail.com> wrote:
>>> Hi everyone,
>>> 
>>> I am using package knitr, FIRST TIME.  I don't have access to RStudio.
>>> 
>>> Read through Yihui's page, didn't find it helpful.  Stuck on terms
>>> Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
>>> reference is not helping.
>>> 
>>> Is there a simple step-by-step example WITHOUT RStudio?
>>> 
>>> My question:
>>> What is the procedure?  The documentation explains the functions, but
>>> does not say how to operate between R and LaTex.
>>> 
>>> Mike
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Thu Jul 18 21:44:05 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 18 Jul 2013 15:44:05 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
Message-ID: <CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>

Hi Simon,
I am on OS X Lion, I have TeXworks, I don't have knitr as an option.

How do I install that into TeXworks?  Seems like I have to something
in terminal?

Mike

On Thu, Jul 18, 2013 at 3:31 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
> Hi Mike,
>
> I found my way with this little blog: http://yihui.name/knitr/demo/editors/
>
> The .Rnw files are created very well in a Latex editor. Everything else can be easily googled. The command via knitr::knit2pdf works very fine if you use the chunks. If you are trying to compile an Rtex file, this I do not know either (I like the symbols though in for example https://github.com/yihui/knitr-examples/blob/master/005-latex.Rtex). But the .Rnw files are compiled pretty nice in e.g. texmaker, as described in the blog. Use for example this source file: https://github.com/yihui/knitr/blob/master/inst/examples/knitr-minimal.Rnw
>
>
> Hope this helps
>
>
> Best
>
> Simon
>
>
>
>
>
> On Jul 18, 2013, at 8:52 PM, C W <tmrsg11 at gmail.com> wrote:
>
>> How do you create a .Rnw file, in R or LaTex?  I don't think any
>> tutorial mentions it.
>>
>> btw, I am very new to the terms like markdown, so I don't understand
>> "markdown to HTML".
>>
>> I am reading here http://biostat.mc.vanderbilt.edu/wiki/Main/KnitrHowto
>> that you need to compile at terminal.  I do not know terminal, is
>> there other ways?
>>
>> Could you do a video on just "simple" R?  I have seen 3 videos on R
>> Studio including yours.
>>
>> Mike
>>
>> On Thu, Jul 18, 2013 at 2:43 PM, Yihui Xie <xie at yihui.name> wrote:
>>> I'm not sure what your question really is. You do not have to use
>>> RStudio, but it will be much easier to get started with RStudio,
>>> because it does a lot of automatic conversion behind the scenes (e.g.
>>> tex to PDF, markdown to HTML, ...). If you want a "pure" solution
>>> without any text editor support, the answer is
>>>
>>> library(knitr)
>>> knit('your_input_file')
>>>
>>> For example, knit('foo.Rnw') gives you foo.tex; if you are familiar
>>> with LaTeX, you can mess with this foo.tex now (outside of R).
>>>
>>> Minimal examples for different document formats are at
>>> http://yihui.name/knitr/demo/minimal/ (you must have read this page),
>>> and more examples at https://github.com/yihui/knitr-examples
>>>
>>> If you are asking about the internals of knitr, "Luke, use the
>>> source": https://github.com/yihui/knitr Or for a more comprehensive
>>> introduction, see http://www.crcpress.com/product/isbn/9781482203530
>>>
>>> Regards,
>>> Yihui
>>> --
>>> Yihui Xie <xieyihui at gmail.com>
>>> Phone: 206-667-4385 Web: http://yihui.name
>>> Fred Hutchinson Cancer Research Center, Seattle
>>>
>>>
>>> On Thu, Jul 18, 2013 at 11:13 AM, C W <tmrsg11 at gmail.com> wrote:
>>>> Hi everyone,
>>>>
>>>> I am using package knitr, FIRST TIME.  I don't have access to RStudio.
>>>>
>>>> Read through Yihui's page, didn't find it helpful.  Stuck on terms
>>>> Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
>>>> reference is not helping.
>>>>
>>>> Is there a simple step-by-step example WITHOUT RStudio?
>>>>
>>>> My question:
>>>> What is the procedure?  The documentation explains the functions, but
>>>> does not say how to operate between R and LaTex.
>>>>
>>>> Mike
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From tmrsg11 at gmail.com  Thu Jul 18 21:56:26 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 18 Jul 2013 15:56:26 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
Message-ID: <CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>

Actually, I see it at the bottom.  Sorry!

On Thu, Jul 18, 2013 at 3:44 PM, C W <tmrsg11 at gmail.com> wrote:
> Hi Simon,
> I am on OS X Lion, I have TeXworks, I don't have knitr as an option.
>
> How do I install that into TeXworks?  Seems like I have to something
> in terminal?
>
> Mike
>
> On Thu, Jul 18, 2013 at 3:31 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
>> Hi Mike,
>>
>> I found my way with this little blog: http://yihui.name/knitr/demo/editors/
>>
>> The .Rnw files are created very well in a Latex editor. Everything else can be easily googled. The command via knitr::knit2pdf works very fine if you use the chunks. If you are trying to compile an Rtex file, this I do not know either (I like the symbols though in for example https://github.com/yihui/knitr-examples/blob/master/005-latex.Rtex). But the .Rnw files are compiled pretty nice in e.g. texmaker, as described in the blog. Use for example this source file: https://github.com/yihui/knitr/blob/master/inst/examples/knitr-minimal.Rnw
>>
>>
>> Hope this helps
>>
>>
>> Best
>>
>> Simon
>>
>>
>>
>>
>>
>> On Jul 18, 2013, at 8:52 PM, C W <tmrsg11 at gmail.com> wrote:
>>
>>> How do you create a .Rnw file, in R or LaTex?  I don't think any
>>> tutorial mentions it.
>>>
>>> btw, I am very new to the terms like markdown, so I don't understand
>>> "markdown to HTML".
>>>
>>> I am reading here http://biostat.mc.vanderbilt.edu/wiki/Main/KnitrHowto
>>> that you need to compile at terminal.  I do not know terminal, is
>>> there other ways?
>>>
>>> Could you do a video on just "simple" R?  I have seen 3 videos on R
>>> Studio including yours.
>>>
>>> Mike
>>>
>>> On Thu, Jul 18, 2013 at 2:43 PM, Yihui Xie <xie at yihui.name> wrote:
>>>> I'm not sure what your question really is. You do not have to use
>>>> RStudio, but it will be much easier to get started with RStudio,
>>>> because it does a lot of automatic conversion behind the scenes (e.g.
>>>> tex to PDF, markdown to HTML, ...). If you want a "pure" solution
>>>> without any text editor support, the answer is
>>>>
>>>> library(knitr)
>>>> knit('your_input_file')
>>>>
>>>> For example, knit('foo.Rnw') gives you foo.tex; if you are familiar
>>>> with LaTeX, you can mess with this foo.tex now (outside of R).
>>>>
>>>> Minimal examples for different document formats are at
>>>> http://yihui.name/knitr/demo/minimal/ (you must have read this page),
>>>> and more examples at https://github.com/yihui/knitr-examples
>>>>
>>>> If you are asking about the internals of knitr, "Luke, use the
>>>> source": https://github.com/yihui/knitr Or for a more comprehensive
>>>> introduction, see http://www.crcpress.com/product/isbn/9781482203530
>>>>
>>>> Regards,
>>>> Yihui
>>>> --
>>>> Yihui Xie <xieyihui at gmail.com>
>>>> Phone: 206-667-4385 Web: http://yihui.name
>>>> Fred Hutchinson Cancer Research Center, Seattle
>>>>
>>>>
>>>> On Thu, Jul 18, 2013 at 11:13 AM, C W <tmrsg11 at gmail.com> wrote:
>>>>> Hi everyone,
>>>>>
>>>>> I am using package knitr, FIRST TIME.  I don't have access to RStudio.
>>>>>
>>>>> Read through Yihui's page, didn't find it helpful.  Stuck on terms
>>>>> Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
>>>>> reference is not helping.
>>>>>
>>>>> Is there a simple step-by-step example WITHOUT RStudio?
>>>>>
>>>>> My question:
>>>>> What is the procedure?  The documentation explains the functions, but
>>>>> does not say how to operate between R and LaTex.
>>>>>
>>>>> Mike
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From tmrsg11 at gmail.com  Thu Jul 18 22:09:11 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 18 Jul 2013 16:09:11 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
Message-ID: <CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>

http://tex.stackexchange.com/questions/85154/knitr-with-texworks/85165#85165

In step 3: "add the executable file (step 3)".

What is the executable file?  Locate package knitr directory path in R?

Mike

On Thu, Jul 18, 2013 at 3:56 PM, C W <tmrsg11 at gmail.com> wrote:
> Actually, I see it at the bottom.  Sorry!
>
> On Thu, Jul 18, 2013 at 3:44 PM, C W <tmrsg11 at gmail.com> wrote:
>> Hi Simon,
>> I am on OS X Lion, I have TeXworks, I don't have knitr as an option.
>>
>> How do I install that into TeXworks?  Seems like I have to something
>> in terminal?
>>
>> Mike
>>
>> On Thu, Jul 18, 2013 at 3:31 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
>>> Hi Mike,
>>>
>>> I found my way with this little blog: http://yihui.name/knitr/demo/editors/
>>>
>>> The .Rnw files are created very well in a Latex editor. Everything else can be easily googled. The command via knitr::knit2pdf works very fine if you use the chunks. If you are trying to compile an Rtex file, this I do not know either (I like the symbols though in for example https://github.com/yihui/knitr-examples/blob/master/005-latex.Rtex). But the .Rnw files are compiled pretty nice in e.g. texmaker, as described in the blog. Use for example this source file: https://github.com/yihui/knitr/blob/master/inst/examples/knitr-minimal.Rnw
>>>
>>>
>>> Hope this helps
>>>
>>>
>>> Best
>>>
>>> Simon
>>>
>>>
>>>
>>>
>>>
>>> On Jul 18, 2013, at 8:52 PM, C W <tmrsg11 at gmail.com> wrote:
>>>
>>>> How do you create a .Rnw file, in R or LaTex?  I don't think any
>>>> tutorial mentions it.
>>>>
>>>> btw, I am very new to the terms like markdown, so I don't understand
>>>> "markdown to HTML".
>>>>
>>>> I am reading here http://biostat.mc.vanderbilt.edu/wiki/Main/KnitrHowto
>>>> that you need to compile at terminal.  I do not know terminal, is
>>>> there other ways?
>>>>
>>>> Could you do a video on just "simple" R?  I have seen 3 videos on R
>>>> Studio including yours.
>>>>
>>>> Mike
>>>>
>>>> On Thu, Jul 18, 2013 at 2:43 PM, Yihui Xie <xie at yihui.name> wrote:
>>>>> I'm not sure what your question really is. You do not have to use
>>>>> RStudio, but it will be much easier to get started with RStudio,
>>>>> because it does a lot of automatic conversion behind the scenes (e.g.
>>>>> tex to PDF, markdown to HTML, ...). If you want a "pure" solution
>>>>> without any text editor support, the answer is
>>>>>
>>>>> library(knitr)
>>>>> knit('your_input_file')
>>>>>
>>>>> For example, knit('foo.Rnw') gives you foo.tex; if you are familiar
>>>>> with LaTeX, you can mess with this foo.tex now (outside of R).
>>>>>
>>>>> Minimal examples for different document formats are at
>>>>> http://yihui.name/knitr/demo/minimal/ (you must have read this page),
>>>>> and more examples at https://github.com/yihui/knitr-examples
>>>>>
>>>>> If you are asking about the internals of knitr, "Luke, use the
>>>>> source": https://github.com/yihui/knitr Or for a more comprehensive
>>>>> introduction, see http://www.crcpress.com/product/isbn/9781482203530
>>>>>
>>>>> Regards,
>>>>> Yihui
>>>>> --
>>>>> Yihui Xie <xieyihui at gmail.com>
>>>>> Phone: 206-667-4385 Web: http://yihui.name
>>>>> Fred Hutchinson Cancer Research Center, Seattle
>>>>>
>>>>>
>>>>> On Thu, Jul 18, 2013 at 11:13 AM, C W <tmrsg11 at gmail.com> wrote:
>>>>>> Hi everyone,
>>>>>>
>>>>>> I am using package knitr, FIRST TIME.  I don't have access to RStudio.
>>>>>>
>>>>>> Read through Yihui's page, didn't find it helpful.  Stuck on terms
>>>>>> Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
>>>>>> reference is not helping.
>>>>>>
>>>>>> Is there a simple step-by-step example WITHOUT RStudio?
>>>>>>
>>>>>> My question:
>>>>>> What is the procedure?  The documentation explains the functions, but
>>>>>> does not say how to operate between R and LaTex.
>>>>>>
>>>>>> Mike
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>


From szehnder at uni-bonn.de  Thu Jul 18 22:14:34 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 18 Jul 2013 22:14:34 +0200
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
Message-ID: <36A0F2BB-4AF2-483D-9B18-C49D23E5F0FB@uni-bonn.de>

The executable is in case of knitr always Rscript. 
On a mac it is simply Rscript on windows it is Rscript.exe. This should be on your PATH. If you are not sure, open the Mac Terminal and type Rscript --version. If it does not say "Command not found" all is fine. 

Best

Simon
On Jul 18, 2013, at 10:09 PM, C W <tmrsg11 at gmail.com> wrote:

> http://tex.stackexchange.com/questions/85154/knitr-with-texworks/85165#85165
> 
> In step 3: "add the executable file (step 3)".
> 
> What is the executable file?  Locate package knitr directory path in R?
> 
> Mike
> 
> On Thu, Jul 18, 2013 at 3:56 PM, C W <tmrsg11 at gmail.com> wrote:
>> Actually, I see it at the bottom.  Sorry!
>> 
>> On Thu, Jul 18, 2013 at 3:44 PM, C W <tmrsg11 at gmail.com> wrote:
>>> Hi Simon,
>>> I am on OS X Lion, I have TeXworks, I don't have knitr as an option.
>>> 
>>> How do I install that into TeXworks?  Seems like I have to something
>>> in terminal?
>>> 
>>> Mike
>>> 
>>> On Thu, Jul 18, 2013 at 3:31 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
>>>> Hi Mike,
>>>> 
>>>> I found my way with this little blog: http://yihui.name/knitr/demo/editors/
>>>> 
>>>> The .Rnw files are created very well in a Latex editor. Everything else can be easily googled. The command via knitr::knit2pdf works very fine if you use the chunks. If you are trying to compile an Rtex file, this I do not know either (I like the symbols though in for example https://github.com/yihui/knitr-examples/blob/master/005-latex.Rtex). But the .Rnw files are compiled pretty nice in e.g. texmaker, as described in the blog. Use for example this source file: https://github.com/yihui/knitr/blob/master/inst/examples/knitr-minimal.Rnw
>>>> 
>>>> 
>>>> Hope this helps
>>>> 
>>>> 
>>>> Best
>>>> 
>>>> Simon
>>>> 
>>>> 
>>>> 
>>>> 
>>>> 
>>>> On Jul 18, 2013, at 8:52 PM, C W <tmrsg11 at gmail.com> wrote:
>>>> 
>>>>> How do you create a .Rnw file, in R or LaTex?  I don't think any
>>>>> tutorial mentions it.
>>>>> 
>>>>> btw, I am very new to the terms like markdown, so I don't understand
>>>>> "markdown to HTML".
>>>>> 
>>>>> I am reading here http://biostat.mc.vanderbilt.edu/wiki/Main/KnitrHowto
>>>>> that you need to compile at terminal.  I do not know terminal, is
>>>>> there other ways?
>>>>> 
>>>>> Could you do a video on just "simple" R?  I have seen 3 videos on R
>>>>> Studio including yours.
>>>>> 
>>>>> Mike
>>>>> 
>>>>> On Thu, Jul 18, 2013 at 2:43 PM, Yihui Xie <xie at yihui.name> wrote:
>>>>>> I'm not sure what your question really is. You do not have to use
>>>>>> RStudio, but it will be much easier to get started with RStudio,
>>>>>> because it does a lot of automatic conversion behind the scenes (e.g.
>>>>>> tex to PDF, markdown to HTML, ...). If you want a "pure" solution
>>>>>> without any text editor support, the answer is
>>>>>> 
>>>>>> library(knitr)
>>>>>> knit('your_input_file')
>>>>>> 
>>>>>> For example, knit('foo.Rnw') gives you foo.tex; if you are familiar
>>>>>> with LaTeX, you can mess with this foo.tex now (outside of R).
>>>>>> 
>>>>>> Minimal examples for different document formats are at
>>>>>> http://yihui.name/knitr/demo/minimal/ (you must have read this page),
>>>>>> and more examples at https://github.com/yihui/knitr-examples
>>>>>> 
>>>>>> If you are asking about the internals of knitr, "Luke, use the
>>>>>> source": https://github.com/yihui/knitr Or for a more comprehensive
>>>>>> introduction, see http://www.crcpress.com/product/isbn/9781482203530
>>>>>> 
>>>>>> Regards,
>>>>>> Yihui
>>>>>> --
>>>>>> Yihui Xie <xieyihui at gmail.com>
>>>>>> Phone: 206-667-4385 Web: http://yihui.name
>>>>>> Fred Hutchinson Cancer Research Center, Seattle
>>>>>> 
>>>>>> 
>>>>>> On Thu, Jul 18, 2013 at 11:13 AM, C W <tmrsg11 at gmail.com> wrote:
>>>>>>> Hi everyone,
>>>>>>> 
>>>>>>> I am using package knitr, FIRST TIME.  I don't have access to RStudio.
>>>>>>> 
>>>>>>> Read through Yihui's page, didn't find it helpful.  Stuck on terms
>>>>>>> Rnw, GFM (GitHub Flavored Markdown).  Never used Sweave, so the
>>>>>>> reference is not helping.
>>>>>>> 
>>>>>>> Is there a simple step-by-step example WITHOUT RStudio?
>>>>>>> 
>>>>>>> My question:
>>>>>>> What is the procedure?  The documentation explains the functions, but
>>>>>>> does not say how to operate between R and LaTex.
>>>>>>> 
>>>>>>> Mike
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 


From bhh at xs4all.nl  Thu Jul 18 22:19:27 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 18 Jul 2013 22:19:27 +0200
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
Message-ID: <74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>


On 18-07-2013, at 22:09, C W <tmrsg11 at gmail.com> wrote:

> http://tex.stackexchange.com/questions/85154/knitr-with-texworks/85165#85165
> 
> In step 3: "add the executable file (step 3)".
> 
> What is the executable file?  Locate package knitr directory path in R?
> 

From the window:  Executable ==> Program. So the executable is Rscript.exe.


Berend


From tmrsg11 at gmail.com  Thu Jul 18 22:22:56 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 18 Jul 2013 16:22:56 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
	<74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
Message-ID: <CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>

Thanks, Simon.  I would never figured it out!

I apologize if I sound frustrated, because I am.

@package author: you have a great package, but I think a lot of the
directions are hand waving.  For the newbies, this leads to more
confusion.

@Berend: I am using OS X.

Mike


On Thu, Jul 18, 2013 at 4:19 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
> On 18-07-2013, at 22:09, C W <tmrsg11 at gmail.com> wrote:
>
>> http://tex.stackexchange.com/questions/85154/knitr-with-texworks/85165#85165
>>
>> In step 3: "add the executable file (step 3)".
>>
>> What is the executable file?  Locate package knitr directory path in R?
>>
>
> From the window:  Executable ==> Program. So the executable is Rscript.exe.
>
>
> Berend
>


From bhh at xs4all.nl  Thu Jul 18 22:26:39 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 18 Jul 2013 22:26:39 +0200
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
	<74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
	<CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
Message-ID: <ADF7E531-8568-42C1-8FB0-16F9B37FD28D@xs4all.nl>


On 18-07-2013, at 22:22, C W <tmrsg11 at gmail.com> wrote:

> Thanks, Simon.  I would never figured it out!
> 
> I apologize if I sound frustrated, because I am.
> 
> @package author: you have a great package, but I think a lot of the
> directions are hand waving.  For the newbies, this leads to more
> confusion.
> 
> @Berend: I am using OS X.
> 

Then leave out the .exe.
And you could always try something!

Berend


From ligges at statistik.tu-dortmund.de  Thu Jul 18 22:43:56 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 18 Jul 2013 22:43:56 +0200
Subject: [R] 'save' method for S4 class
In-Reply-To: <CA+dpOJksoLMhtKvkwg4AJmkRErjpxCfCANpTWB36uROvZaWLtw@mail.gmail.com>
References: <CA+dpOJ=K_yLH5QeK+PsL6QPXS-Pj1Hpefomh6Z3+MrNfcp=hgA@mail.gmail.com>
	<BFAE694C-6BE8-40AD-966D-C79584F18D75@uni-bonn.de>
	<CA+dpOJksoLMhtKvkwg4AJmkRErjpxCfCANpTWB36uROvZaWLtw@mail.gmail.com>
Message-ID: <51E8538C.2080309@statistik.tu-dortmund.de>



On 18.07.2013 20:23, Christofer Bogaso wrote:
> Hi Simon,
>
> Thanks for your pointer.
>
> However could you please explain what 'function(x, file_Path)
> standardGeneric("save")' means here?

It is the definition of the generic function for save()?

The underlying help files look quite
> rocket science for me!

So start reading about S4 seems to be essential, if you ask for S4 
methods. Otherwise we cannot help, given you do not even understand the 
code to define the generic function.

Uwe Ligges


>
> Thanks for your time.
>
> Thanks and regards,
>
>
> On Thu, Jul 18, 2013 at 4:32 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
>
>> Hi Christopher,
>>
>> I think, that "save" is no generic function like "plot", "show", etc. So
>> at first you have to determine a generic.
>>
>> setGeneric("save", function(x, file_Path) standardGeneric("save"))
>>
>> Now your definition via setMethod.
>>
>>
>> Best
>>
>> Simon
>>
>>
>>
>> On Jul 18, 2013, at 12:09 PM, Christofer Bogaso <
>> bogaso.christofer at gmail.com> wrote:
>>
>>> Hello again,
>>>
>>> I am trying to define the 'save' method for my S4 class as below:
>>>
>>> setClass("MyClass", representation(
>>>                Slot1 = "data.frame"
>>>        ))
>>>
>>> setMethod("save", "MyClass", definition = function(x, file_Path) {
>>>
>>>                write.table(x at Slot1, file = file_Path, append = FALSE,
>> quote = TRUE,
>>> sep = ",",
>>>                                                eol = "\n", na = "NA", dec
>> = ".", row.names = FALSE,
>>>                                                col.names = TRUE, qmethod
>> = c("escape", "double"),
>>>                                                fileEncoding = "")
>>>        })
>>>
>>> However while doing this I am getting following error:
>>>
>>> Error in conformMethod(signature, mnames, fnames, f, fdef, definition) :
>>>   in method for ?save? with signature ?list="MyClass"?: formal
>>> arguments (list = "MyClass", file = "MyClass", ascii = "MyClass",
>>> version = "MyClass", envir = "MyClass", compress = "MyClass",
>>> compression_level = "MyClass", eval.promises = "MyClass", precheck =
>>> "MyClass") omitted in the method definition cannot be in the signature
>>>
>>>
>>> Can somebody point me what will be the correct approach to define
>>> 'save' method for S4 class?
>>>
>>> Thanks and regards,
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From xie at yihui.name  Thu Jul 18 22:46:45 2013
From: xie at yihui.name (Yihui Xie)
Date: Thu, 18 Jul 2013 13:46:45 -0700
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
	<74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
	<CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
Message-ID: <CANROs4dPaR7yh_iEUtG=HAV-=n3g7vv-+BVH3+qbHZDDwOQ01A@mail.gmail.com>

I recommend RStudio not because I want to promote it in any sense, but
because of the fact that it has the best support for Rnw/knitr at the
moment, and it will save you a lot of headache to get started. It
seems you just do not believe me, and insist on going through all the
low-level configurations as a newbie. That will lead to confusion by
definition. I do not know why you do not have _access_ to it; it is
free and open source, so everybody has access to it unless one does
not have the Internet connection.

I'm not the developer of TeXworks, so I have no control over what
TeXworks can support.

knitr and its website are open source; please feel free to improve
them if you find anything unclear:
http://yihui.name/en/2013/06/fix-typo-in-documentation/

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Thu, Jul 18, 2013 at 1:22 PM, C W <tmrsg11 at gmail.com> wrote:
> Thanks, Simon.  I would never figured it out!
>
> I apologize if I sound frustrated, because I am.
>
> @package author: you have a great package, but I think a lot of the
> directions are hand waving.  For the newbies, this leads to more
> confusion.
>
> @Berend: I am using OS X.
>
> Mike


From szehnder at uni-bonn.de  Thu Jul 18 22:50:35 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Thu, 18 Jul 2013 22:50:35 +0200
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
	<74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
	<CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
Message-ID: <8519B462-90A1-4EA1-8984-447D19935429@uni-bonn.de>

Hi Mike,

if you browse the folders, you find always the Rscript binary (the executable) under /Library/Frameworks/R.framework/Versions/.../Resources/Rscript. 

Do not forget to give your tex file the extension .Rnw! Then surround each Rcode with <<write here a name....add later further options (important one; results = 'asis')>>= Here your r code as you do it in the R shell .... at the end a @. Always inside the \begin{document} \end{document} tags.



Best

Simon

On Jul 18, 2013, at 10:22 PM, C W <tmrsg11 at gmail.com> wrote:

> Thanks, Simon.  I would never figured it out!
> 
> I apologize if I sound frustrated, because I am.
> 
> @package author: you have a great package, but I think a lot of the
> directions are hand waving.  For the newbies, this leads to more
> confusion.
> 
> @Berend: I am using OS X.
> 
> Mike
> 
> 
> On Thu, Jul 18, 2013 at 4:19 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>> 
>> On 18-07-2013, at 22:09, C W <tmrsg11 at gmail.com> wrote:
>> 
>>> http://tex.stackexchange.com/questions/85154/knitr-with-texworks/85165#85165
>>> 
>>> In step 3: "add the executable file (step 3)".
>>> 
>>> What is the executable file?  Locate package knitr directory path in R?
>>> 
>> 
>> From the window:  Executable ==> Program. So the executable is Rscript.exe.
>> 
>> 
>> Berend
>> 


From bcrombie at utk.edu  Thu Jul 18 22:12:17 2013
From: bcrombie at utk.edu (bcrombie)
Date: Thu, 18 Jul 2013 13:12:17 -0700 (PDT)
Subject: [R] combine select data from 2 dataframes sharing same variables
In-Reply-To: <1374093717.22037.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1374091972085-4671790.post@n4.nabble.com>
	<1374093717.22037.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <559C998F7039D84C9793AE43D9BBE9CE7F3BB7CA@kmbx3.utk.tennessee.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/594b97f7/attachment.pl>

From Ryan.Munroe at RNCan-NRCan.gc.ca  Thu Jul 18 21:18:01 2013
From: Ryan.Munroe at RNCan-NRCan.gc.ca (Munroe, Ryan)
Date: Thu, 18 Jul 2013 19:18:01 +0000
Subject: [R] How code for an exponential function
Message-ID: <C2624F060973C74B96D5A2BA27E12761EF21A3@S-BSC-MBX4.nrn.nrcan.gc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/24d3347e/attachment.pl>

From ruipbarradas at sapo.pt  Thu Jul 18 23:47:13 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 18 Jul 2013 22:47:13 +0100
Subject: [R] How code for an exponential function
In-Reply-To: <C2624F060973C74B96D5A2BA27E12761EF21A3@S-BSC-MBX4.nrn.nrcan.gc.ca>
References: <C2624F060973C74B96D5A2BA27E12761EF21A3@S-BSC-MBX4.nrn.nrcan.gc.ca>
Message-ID: <51E86261.9050104@sapo.pt>

Hello,

First of all, you need to read the posting guide.
Where is a data example? And code?

As for the question, at an R prompt, type ?log.

Hope this helps,

Rui Barradas

Em 18-07-2013 20:18, Munroe, Ryan escreveu:
> Hi,
>
> I ran a linear regression on a data set and got an Rsq of about .27. The plot looks as though an exponential curve would be a better fit. What codes do I use to do this?
> Thank you,
> Ryan Munroe
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From rolf.turner at xtra.co.nz  Thu Jul 18 23:51:22 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Fri, 19 Jul 2013 09:51:22 +1200
Subject: [R] Test if 2 samples differ if they have autocorrelation
In-Reply-To: <CC4E07E6-AAAA-409B-A4D6-F0E377D50A43@gmx.ch>
References: <F0FF65F6CE2DE347B8E3D3F42FEECC917D452BD1@Mailtrading02.trading.imc.intra>
	<CC4E07E6-AAAA-409B-A4D6-F0E377D50A43@gmx.ch>
Message-ID: <51E8635A.7020503@xtra.co.nz>



I imagine that most readers of this list will put your question in the 
too hard basket.
That being so, here is my inexpert take on the question.

The issue is to estimate the uncertainty in the estimated difference of 
the means.
This uncertainty depends on the nature of the serial dependence of the 
series.
Therefore in order to get anywhere you need to *model* this dependence.

Different models could yield very different values for the variance of 
the estimated
difference of the means.

If the series are observed at the same times I would suggest taking the 
pointwise
difference of the two series: D_t = X_t - Y_t, say.

Fit the best arima model that you can to D_t. Then the standard error of 
what
is incorrectly labelled "intercept" (it is actually the estimate of the 
series *mean*)
is the appropriate estimate of the uncertainty. The ratio of the 
"intercept" value
to its standard error is the test statistic you are looking for.

If the series are *not* observed at the same times but can be assumed to be
independent then model *each* series as well as you can (different 
models for
each series) and obtain the standard error of the "intercept" for each 
series.
Your test statistic is then the difference of the "intercept estimates 
divided by
sqrt(se_X^2 + se_Y^2) in what I hope is an "obvious" notation.

If the series are not observed at the same times and cannot be assumed to be
independent then you probably haven't got sufficient information to answer
the question that you wish to answer.

I hope that there is some value in the forgoing.

cheers,

Rolf Turner

On 18/07/13 21:50, Eric Jaeger wrote:
>> Dear all
>>
>> I have one question that I struggle to find an answer:
>>
>> Let`s assume I have 2 timeseries of daily PnL data over 2 years coming from 2 different trading strategies. I want to find out if strategy A is better than strategy B. The problem is that the two series have serial correlations, hence I cannot just do a simple t-test.
>>
>> I tried something like this:
>>
>> 1.create cumulative timeseries of PnL_A = C_A and of PnL_B = C_B
>>
>> 2.take the difference of both: C_A ??? C_B = DiffPnL (to see how the difference evolves over time)
>>
>> 3.do a regression: DiffPnL = beta * time + error (I thought if beta is significantly different from 0 than the two time series are different)
>>
>> 4.estimate beta not with OLS, but with the Newey-West method (HAC estimator) -> this corrects statistical tests, standard errors for beta heteroskedasticity and autocorrelation
>>
>> BUT: I read something that the tests are biased when the timeseries are unit root non-stationary (which is due to the fact that I take cumulative time series)
>>
>>   
>>
>> I am lost! This should be fairly simple: test if two samples differ if they have autocorrelation? Probably my approach above is completely wrong???


From tmrsg11 at gmail.com  Fri Jul 19 02:50:25 2013
From: tmrsg11 at gmail.com (C W)
Date: Thu, 18 Jul 2013 20:50:25 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <8519B462-90A1-4EA1-8984-447D19935429@uni-bonn.de>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
	<74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
	<CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
	<8519B462-90A1-4EA1-8984-447D19935429@uni-bonn.de>
Message-ID: <CAE2FW2n6LBpxe9_pi-ecjCBFcVVC=4WPzD4PyMtGtBACk+Fe=g@mail.gmail.com>

Hi,
@Yihui
When I am using a public computer, say university computer lab or
financial company.  I do not have control what to install.

I'm also very happy with R editor on OS X, it integrates with Mac
well.  As for my Mac Air, I am keeping installation to the minimal.

There are a lot links on your page, I don't understand what I am
reading.  What is Rnw, what is markdown?  As a newbie, it's above my
level.  I googled Rnw, it's refers to Sweave package, now I am
tracking back to Sweave.

As a user, I want to spend more time using the package, not installing.

@Simon: thanks, I will definitely rename the extension.  I really hope
there will be a more thorough description somewhere soon.

Mike

On Thu, Jul 18, 2013 at 4:50 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:
> Hi Mike,
>
> if you browse the folders, you find always the Rscript binary (the executable) under /Library/Frameworks/R.framework/Versions/.../Resources/Rscript.
>
> Do not forget to give your tex file the extension .Rnw! Then surround each Rcode with <<write here a name....add later further options (important one; results = 'asis')>>= Here your r code as you do it in the R shell .... at the end a @. Always inside the \begin{document} \end{document} tags.
>
>
>
> Best
>
> Simon
>
> On Jul 18, 2013, at 10:22 PM, C W <tmrsg11 at gmail.com> wrote:
>
>> Thanks, Simon.  I would never figured it out!
>>
>> I apologize if I sound frustrated, because I am.
>>
>> @package author: you have a great package, but I think a lot of the
>> directions are hand waving.  For the newbies, this leads to more
>> confusion.
>>
>> @Berend: I am using OS X.
>>
>> Mike
>>
>>
>> On Thu, Jul 18, 2013 at 4:19 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>
>>> On 18-07-2013, at 22:09, C W <tmrsg11 at gmail.com> wrote:
>>>
>>>> http://tex.stackexchange.com/questions/85154/knitr-with-texworks/85165#85165
>>>>
>>>> In step 3: "add the executable file (step 3)".
>>>>
>>>> What is the executable file?  Locate package knitr directory path in R?
>>>>
>>>
>>> From the window:  Executable ==> Program. So the executable is Rscript.exe.
>>>
>>>
>>> Berend
>>>
>


From yixuan.qiu at cos.name  Fri Jul 19 03:21:02 2013
From: yixuan.qiu at cos.name (Yixuan Qiu)
Date: Thu, 18 Jul 2013 21:21:02 -0400
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2n6LBpxe9_pi-ecjCBFcVVC=4WPzD4PyMtGtBACk+Fe=g@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
	<74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
	<CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
	<8519B462-90A1-4EA1-8984-447D19935429@uni-bonn.de>
	<CAE2FW2n6LBpxe9_pi-ecjCBFcVVC=4WPzD4PyMtGtBACk+Fe=g@mail.gmail.com>
Message-ID: <CAFr_7yGEeJJAi9g4SJU8DXoSrwvesH3+ni+GBxtCi_+PaCg22w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/4e7595e3/attachment.pl>

From mrahmankufmrt at gmail.com  Fri Jul 19 05:09:00 2013
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Fri, 19 Jul 2013 11:09:00 +0800
Subject: [R] Paternity data analysis
Message-ID: <CAGNSkSnB9nEYaAXTL+P4hQ0fNVz2W4SSrGB2CHMabU1upvHyZQ@mail.gmail.com>

Dear R-experts!

I did an experiment with Guppy where I had two dietary groups ("High" and
"Low"). I completed all my data analysis, but stacked in "paternity
analysis". I ran the attached model to analyse them, but as a novice in R,
it's very hard for me to confirm whether this gives me the correct output
or not. I would like to examine the effect of the predictor traits (VAP,
Viability, Body FAs) on paternity success (Proportion). Here, I fitted
generalized linear models (GLMs) using a logit-link function as my data has
some zeroes and ones. I also lie to use quasi-GLMs to correct for
overdispersion. Now, I need some help from you guys to estimate the
paternity success of my high group or both groups? **

 With kind regards,


Moshi

-- 
MD. MOSHIUR RAHMAN
PhD Candidate
School of Animal Biology/Zoology (M092)
University of Western Australia
35 Stirling Hwy, Crawley, WA, 6009
Australia.
Mob.: 061-425205507

From zroslina at yahoo.com  Fri Jul 19 08:15:22 2013
From: zroslina at yahoo.com (Roslina Zakaria)
Date: Thu, 18 Jul 2013 23:15:22 -0700 (PDT)
Subject: [R] construct stem and leaf plot
Message-ID: <1374214522.63506.YahooMailNeo@web120602.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130718/097bdcc0/attachment.pl>

From xie at yihui.name  Fri Jul 19 08:26:19 2013
From: xie at yihui.name (Yihui Xie)
Date: Thu, 18 Jul 2013 23:26:19 -0700
Subject: [R] Looking for knitr example for beginner (NO RStudio)
In-Reply-To: <CAE2FW2n6LBpxe9_pi-ecjCBFcVVC=4WPzD4PyMtGtBACk+Fe=g@mail.gmail.com>
References: <CAE2FW2kpdEKsG2MZYc-4cfDBHAeFUOCA0-Ly=XDy6-S19ZfCLw@mail.gmail.com>
	<CANROs4f0Qut6Jzjt_Sb_je7GAmpgnjtH2-t4q6WZXuB+m+g13Q@mail.gmail.com>
	<CAE2FW2=N4iic4Dow0+398ek0E0ZboPwJ2+QV4oE4zYbr5_RqZQ@mail.gmail.com>
	<EF2955BD-927D-4C17-9327-E6ADFFBB1974@uni-bonn.de>
	<CAE2FW2=-S5wS3pxgv6UC=R-v+TdQT-NdMtZQvKyS8brHy2b9jA@mail.gmail.com>
	<CAE2FW2md6WFK2QxT-iG8eY3rjEe=KQCdyg7deOp2x8f5SVDhNQ@mail.gmail.com>
	<CAE2FW2kjbxkN2tAOdWzsFbQXv6LBdGKhYNvXNVyym5SyaBucMA@mail.gmail.com>
	<74A778AC-3AD1-4C9A-AA62-AFA019827A3B@xs4all.nl>
	<CAE2FW2=VzjV2y5vo+kyxqpdhf_DQz5F=wzVZUS0yy4NCLEbSCg@mail.gmail.com>
	<8519B462-90A1-4EA1-8984-447D19935429@uni-bonn.de>
	<CAE2FW2n6LBpxe9_pi-ecjCBFcVVC=4WPzD4PyMtGtBACk+Fe=g@mail.gmail.com>
Message-ID: <CANROs4fRsBgoX-BkEvo5dvR+GUqkBqBe69d421Ak7AtDY8v_Zw@mail.gmail.com>

All your questions are answered by the knitr book in my first reply,
which introduces knitr in a systematic manner. For the web pages, I
have tried my best, and nobody can make everybody happy. I do not
understand why you do not understand Rnw and markdown, and I do not
quite believe a person who understands R cannot understand markdown. I
understand you do not have control over your lab machines, but you
still have other options like your own laptop (if you do not like
RStudio, feel free to remove it and use your favorite editors after
you have got the idea).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Thu, Jul 18, 2013 at 5:50 PM, C W <tmrsg11 at gmail.com> wrote:
> Hi,
> @Yihui
> When I am using a public computer, say university computer lab or
> financial company.  I do not have control what to install.
>
> I'm also very happy with R editor on OS X, it integrates with Mac
> well.  As for my Mac Air, I am keeping installation to the minimal.
>
> There are a lot links on your page, I don't understand what I am
> reading.  What is Rnw, what is markdown?  As a newbie, it's above my
> level.  I googled Rnw, it's refers to Sweave package, now I am
> tracking back to Sweave.
>
> As a user, I want to spend more time using the package, not installing.
>
> @Simon: thanks, I will definitely rename the extension.  I really hope
> there will be a more thorough description somewhere soon.
>
> Mike


From girijagun at gmail.com  Fri Jul 19 08:22:50 2013
From: girijagun at gmail.com (G Girija)
Date: Fri, 19 Jul 2013 11:52:50 +0530
Subject: [R] Fwd: extracting variance and covariance
In-Reply-To: <CAOLvsEwthi6Z-8OMMhHpGAF635zLF9kmgWnKike7LCp0B42qig@mail.gmail.com>
References: <CAOLvsEwthi6Z-8OMMhHpGAF635zLF9kmgWnKike7LCp0B42qig@mail.gmail.com>
Message-ID: <CAOLvsExM9L5Q+Am=70yZzmbu0hpziCLg3C5rCB_YZ7_0MVNfBQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/9b86d08a/attachment.pl>

From elaine.kuo.tw at gmail.com  Fri Jul 19 11:12:38 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Fri, 19 Jul 2013 17:12:38 +0800
Subject: [R] [R-sig-eco] extract beta.sim from dist type data (package
	betapart)
In-Reply-To: <CAM_vjukO74ohEKMO0hxE-c=6ryu9G18__n=6gfXGd9th=7oU1A@mail.gmail.com>
References: <CAGJhoDxNK7DS=HyogMOmDsVDrUzCTuMnhNJXAjkPqNqua8HxVQ@mail.gmail.com>
	<CAM_vjukO74ohEKMO0hxE-c=6ryu9G18__n=6gfXGd9th=7oU1A@mail.gmail.com>
Message-ID: <CAGJhoDz_+VzoJWsfNOoWjp89KGex5NDXHA-MpAtk-We8Op77AQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/df85a062/attachment.pl>

From katveie at hotmail.com  Fri Jul 19 12:33:01 2013
From: katveie at hotmail.com (Kathrine Veie)
Date: Fri, 19 Jul 2013 12:33:01 +0200
Subject: [R] mgcv: Impose monotonicity constraint on single or more smooth
	terms
Message-ID: <BLU0-SMTP4529D8B00C45D6D2D1DF702AE630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/39164b8c/attachment.pl>

From teresamarso at hotmail.com  Fri Jul 19 11:27:51 2013
From: teresamarso at hotmail.com (=?Windows-1252?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Fri, 19 Jul 2013 09:27:51 +0000
Subject: [R] R Help
Message-ID: <BAY172-W8B2754315527C874E8016B9630@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/5366c655/attachment.pl>

From luandex at cn.ibm.com  Fri Jul 19 12:16:33 2013
From: luandex at cn.ibm.com (De Xin Luan)
Date: Fri, 19 Jul 2013 18:16:33 +0800
Subject: [R] Help: Error when installing R 2.8.1 in IBM AIX system
 from	source code
In-Reply-To: <effbf650-568b-48c9-bf82-bf709d826e3d@email.android.com>
References: <OF2C981413.D6A8B470-ON48257BAB.00336AFA-48257BAB.00364FC8@cn.ibm.com>
	<effbf650-568b-48c9-bf82-bf709d826e3d@email.android.com>
Message-ID: <OFE7EEAB66.1AA93DEB-ON48257BAD.00360EDD-48257BAD.0038A2AC@cn.ibm.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/9e7e328e/attachment.pl>

From pedro.galindo at jot-im.com  Fri Jul 19 12:32:22 2013
From: pedro.galindo at jot-im.com (Pedro Galindo)
Date: Fri, 19 Jul 2013 03:32:22 -0700 (PDT)
Subject: [R] Heckit model with Robus std error fit
Message-ID: <1374229942068-4671915.post@n4.nabble.com>

Hi,

I am currently usind R to do a heckit maxlikehood model and I was wondering
if there is anyway to do it but specifying the robustness of the std error.
I would like it robust.

I am currently working with:

heckit(selection= ,outcome= , method "ml")

Is there anithing else to type into this function to manage that?

if not, Is there any other previous or later thing to do before/after
calling the heckit function to have a robust std error?

Thank you!



--
View this message in context: http://r.789695.n4.nabble.com/Heckit-model-with-Robus-std-error-fit-tp4671915.html
Sent from the R help mailing list archive at Nabble.com.


From petr.pikal at precheza.cz  Fri Jul 19 13:48:55 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 19 Jul 2013 11:48:55 +0000
Subject: [R] R Help
In-Reply-To: <BAY172-W8B2754315527C874E8016B9630@phx.gbl>
References: <BAY172-W8B2754315527C874E8016B9630@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7E959@SRVEXCHMBX.precheza.cz>

Hi

It would be better if you provided either str(yourdata) or dput(yourdata) 

(or a part illustrating those 2 kinds of missing values)

Anyway I would use NA for missing and some other identifier for empty.

temp
   a      b  c
1  1  empty   
2 NA filled xx
3  2 filled xx

is.na(temp)
         a     b     c
[1,] FALSE FALSE FALSE
[2,]  TRUE FALSE FALSE
[3,] FALSE FALSE FALSE

dput(temp)
structure(list(a = c(1L, NA, 2L), b = structure(c(1L, 2L, 2L), .Label = c("empty", 
"filled"), class = "factor"), c = structure(c(1L, 2L, 2L), .Label = c("", 
"xx"), class = "factor")), .Names = c("a", "b", "c"), class = "data.frame", row.names = c(NA, 
-3L))

str(temp)
'data.frame':   3 obs. of  3 variables:
 $ a: int  1 NA 2
 $ b: Factor w/ 2 levels "empty","filled": 1 2 2
 $ c: Factor w/ 2 levels "","xx": 1 2 2

The only real NA value which can be used for imputation is in first column.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ma Teresa Martinez Soriano
> Sent: Friday, July 19, 2013 11:28 AM
> To: r-help at R-project.org
> Subject: [R] R Help
> 
> Hi
> everyone,
> 
> I have
> a dataset which I am handling  with
> R . Unfortunately I have two kinds of empty cells, one corresponds to
> missing values and the other one is empty because it has to.
> 
> I 'm going
> to put an example (just a part of my dataset ) to try to clarify my
> question:
> 
> missing
> values are represented withNAs
> 
> 
> Enterprise
> Data of Stablishment   Earnings
> 2005          earning
> 2006         earnings 2007 earning 2008
> 
> Enterprise
> 1
> 05/06/2007
> It has to be empty      It has to be
> empty
> 2,3
> NA
> 
> Enterprise
> 2
> 09/08/2005
> 2.3
> 3,6
> NA
> 1.6
> 
> 
> 
> My intention is to find this missing values using imputation (library
> VIM) . How could I differenciate this NA with Cells that have to be
> empty?? I have tried putting Na for missing values and Nan for the
> others but it doesn't work because R imputes everythitng.
> Could you answer me
> to this e-mail
> 
> Thanks in
> advance
> 
> 
> 	[[alternative HTML version deleted]]


From eglenn at mit.edu  Sun Jul 14 22:53:12 2013
From: eglenn at mit.edu (Ezra Haber Glenn)
Date: Sun, 14 Jul 2013 16:53:12 -0400
Subject: [R] [R-pkgs] acs package version 1.1: download and analyze census
	data	from the ACS
Message-ID: <87ip0cq2x3.wl%eglenn@mit.edu>


We are pleased to announce that version 1.1 of the acs package is now
available on CRAN.  The package allows users to automatically
download, analyze, and present data from the U.S. Census American
Community Survey.

Major improvements in versions 1.0 and 1.1 include:

  * A single "acs.fetch()" function allows users to downloading data
    directly from the new Census American Community Survey API and
    import it into R (with proper statistical treatment of estimates
    and error, variable and geographic relabeling, and more);

  * A new "geo.make()" function allows users to create their own
    custom geographies from the existing census hierarchy to organize
    and download data.  The function accepts over 20 different
    geographic options (state, county, tract, congressional district,
    zip code, metropolitan statistical area, different types of state
    school and legislative districts, and more), which may be set to
    create and endlessly-combine 25 different summary levels for easy
    downloading from the Census; and

  * Two special lookup tools help users filter Census geographies
    (with the "geo.lookup()" function) and statistical tables (with
    the "acs.lookup()" function) to find exactly what they want.

The package is well documented via the manual on CRAN, as well as a
User Guide available at
<http://eglenn.scripts.mit.edu/citystate/wp-content/uploads/2013/06/wpid-working_with_acs_R3.pdf>.
Additional support, worked examples, and more can be found on the
CityState blog (<http://eglenn.scripts.mit.edu/citystate>), as well as
through the acs.R user group mailing list -- visit
<http://mailman.mit.edu/mailman/listinfo/acs-r> to subscribe and view
archives.

--
Ezra Haber Glenn, AICP
Department of Urban Studies and Planning
Massachusetts Institute of Technology
77 Massachusetts Ave., Room 7-337
Cambridge, MA 02139
eglenn at mit.edu 
http://dusp.mit.edu/faculty/ezra-glenn | http://eglenn.scripts.mit.edu/citystate/
617.253.2024 (w)
617.721.7131 (c)

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From brecht.devleesschauwer at ugent.be  Sat Jul  6 17:45:12 2013
From: brecht.devleesschauwer at ugent.be (Brecht Devleesschauwer)
Date: Sat, 6 Jul 2013 17:45:12 +0200
Subject: [R] [R-pkgs] new package 'prevalence'
In-Reply-To: <51D7EAB0.1080203@ugent.be>
References: <51D7EAB0.1080203@ugent.be>
Message-ID: <51D83B88.30903@ugent.be>

Dear list members,

A new package, called *prevalence *(version 0.1.0), is now available on 
CRAN: http://cran.r-project.org/package=prevalence

This package provides Frequentist and Bayesian methods useful in 
prevalence assessment studies. More specifically, the following 
functions are currently available:

  * truePrev -- Bayesian estimation of True Prevalence from Apparent
    Prevalence obtained by testing /individual /samples
  * truePrevPools -- Bayesian estimation of True Prevalence from
    Apparent Prevalence obtained by testing /pooled /samples
  * propCI -- Calculate confidence intervals for a prevalence estimate
  * betaPERT -- Calculate the parameters of a Beta-PERT distribution
  * betaExpert -- Calculate the parameters of a Beta distribution based
    on expert opinion

Function 'truePrev' is also implemented in an online Shiny app: 
http://users.ugent.be/~bdvleess/R/prevalence/shiny/

The development version is on GitHub: 
https://github.com/brechtdv/prevalence/

Comments and suggestions would be greatly appreciated.

Best wishes,
Brecht and coauthors.

-- 
Devleesschauwer Brecht
Doctoral Researcher, MVSc DVM
Department of Virology, Parasitology and Immunology
Faculty of Veterinary Medicine
Ghent University
Salisburylaan 133
9820 Merelbeke
Belgium

Telephone: +32 9 264 7328
Mobile (Belgium): +32 476 365743
Mobile (Nepal): +977 9842 223323
E-mail:brecht.devleesschauwer at ugent.be

http://users.ugent.be/~bdvleess/


	[[alternative HTML version deleted]]

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From smartpink111 at yahoo.com  Fri Jul 19 14:44:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 19 Jul 2013 05:44:30 -0700 (PDT)
Subject: [R] question...
Message-ID: <1374237870.68910.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
dat<-read.table(text="
? 1 0? 1? 1? 1? 1
?? 0? 0? 1? 0? 0? 1
?? 1? 0? 0? 0? 0? 0
?? 2? 1? 1? 2? 1? 1 
",sep="",header=FALSE)
?which(sapply(seq_len(nrow(dat)),function(i) wilcox.test(unlist(dat[i,]))$p.value)>0.05) #there will be warnings() though
#[1] 2 3
table(sapply(seq_len(nrow(dat)),function(i) wilcox.test(unlist(dat[i,]))$p.value)>0.05)

#FALSE? TRUE 
#??? 2???? 2?

Regarding the warnings(), please check:
http://r.789695.n4.nabble.com/What-are-ties-Wilcox-u-test-td857059.html

A.K.


I have some data like this... 

1 ? 1 ?0 ?1 ?1 ?1 ?1 
2 ? 0 ?0 ?1 ?0 ?0 ?1 
3 ? 1 ?0 ?0 ?0 ?0 ?0 
4 ? 2 ?1 ?1 ?2 ?1 ?1 
?and I have a expression 
lapply(Wilcox.test, function(testNew) 
apply(Specc[,-c(1:3)],1,function(x) get(testNew)(x)$p.value)) that gives
 me a p-values for each row. 

I need to count how many p-values are more than 0.05. 

How can I do this? I have always different errors... 

Thank you


From murdoch.duncan at gmail.com  Fri Jul 19 15:13:32 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Jul 2013 09:13:32 -0400
Subject: [R] Help: Error when installing R 2.8.1 in IBM AIX system from
 source code
In-Reply-To: <OFE7EEAB66.1AA93DEB-ON48257BAD.00360EDD-48257BAD.0038A2AC@cn.ibm.com>
References: <OF2C981413.D6A8B470-ON48257BAB.00336AFA-48257BAB.00364FC8@cn.ibm.com>
	<effbf650-568b-48c9-bf82-bf709d826e3d@email.android.com>
	<OFE7EEAB66.1AA93DEB-ON48257BAD.00360EDD-48257BAD.0038A2AC@cn.ibm.com>
Message-ID: <51E93B7C.1020507@gmail.com>

On 19/07/2013 6:16 AM, De Xin Luan wrote:
> Hi Jeff,
>
> Thanks for your quick response. Let me describe more about my situation.
>
> 1. Patch file - Yes, I found patch didn't change any file, so I manually
> changed 4 files(R-2.8.1/configure, R-2.8.1/configure.ac,
> R-2.8.1/Makeconf.in, R-2.8.1/src/main/Makefile.in) by reading the patch
> file.
>
> 2. why I use old version R 2.8.1 - We want to use SPSS Statistics to call R
> in our server and have to install "Statistics essentials for R" after R is
> installed successfully. In Statistics 20 document, it only supports R 2.8.1
> and provide that install guidance.

In that case, you should be contacting SPSS tech support for help.

Duncan Murdoch

>
> 3. I don't know how to disable HTML format in my mail client. Sorry for
> that. I rewrite colorful part again here as 3.1 and 3.2 :
>
> 3.1 Issue1: during "configure" step, I faced this error:"./configure
> [20510]: "${}": bad substitution".
> And I took action to solve it, the action is :add
> "shlibpath_var=LD_LIBRARY_PATH" before line 20510 of configure file.
>
> 3.2 Issue2: during "make" step, I faced the below error but I don't know
> how to fix it:
>
> ../../../bin/R[206]: "${}": bad substitution
> make: The error code from the last command is 1.
>
> Stop.
>
> 4. Since you said it's not a standard patch, do you have a standard patch
> for R 2.8.1 installation in AIX 7.1 64bit system?
>
> Best regards,
>
> Dexin Luan (??????)
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From sarah.goslee at gmail.com  Fri Jul 19 15:24:07 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Fri, 19 Jul 2013 09:24:07 -0400
Subject: [R] construct stem and leaf plot
In-Reply-To: <1374214522.63506.YahooMailNeo@web120602.mail.ne1.yahoo.com>
References: <1374214522.63506.YahooMailNeo@web120602.mail.ne1.yahoo.com>
Message-ID: <CAM_vjume0RugxToXaBjK1_y2GckSxuDZNStfBd0rs4DaOz9Txw@mail.gmail.com>

Hi,

On Fri, Jul 19, 2013 at 2:15 AM, Roslina Zakaria <zroslina at yahoo.com> wrote:
> Dear r-users,
>
> I would like to construct tem and leaf plot using iris data.  It should be easy, but I don't understand why the plot is not right.
>
> Thank you so much for your help.
>
> dat <- iris[,1] > stem(dat)  The decimal point is 1 digit(s) to the left of the | 42 | 0 44 | 0000 46 | 000000 48 | 00000000000 50 | 0000000000000000000 52 | 00000 54 | 0000000000000 56 | 00000000000000 58 | 0000000000 60 | 000000000000 62 | 0000000000000 64 | 000000000000 66 | 0000000000 68 | 0000000 70 | 00 72 | 0000 74 | 0 76 | 00000 78 | 0
>         [[alternative HTML version deleted]]

I can't really tell, because you posted in HTML, but that looks like
it was once a perfectly reasonable stem and leaf plot.

It's filled with zeros because the R function puts two digits as the
stem, and the third digit as the leaves, and for the iris data the
third digit is always zero. Compare:

data(faithful)
stem(faithful$eruptions)

Other than that, you'll have to tell us what you think the result should be.

Sarah


-- 
Sarah Goslee
http://www.functionaldiversity.org


From murdoch.duncan at gmail.com  Fri Jul 19 15:35:57 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Jul 2013 09:35:57 -0400
Subject: [R] Help: Error when installing R 2.8.1 in IBM AIX system from
 source code
In-Reply-To: <OFB53AA47B.3A92C0A5-ON48257BAD.0049C1E4-48257BAD.004A27A7@cn.ibm.com>
References: <OF2C981413.D6A8B470-ON48257BAB.00336AFA-48257BAB.00364FC8@cn.ibm.com>
	<effbf650-568b-48c9-bf82-bf709d826e3d@email.android.com>
	<OFE7EEAB66.1AA93DEB-ON48257BAD.00360EDD-48257BAD.0038A2AC@cn.ibm.com>
	<51E93B7C.1020507@gmail.com>
	<OFB53AA47B.3A92C0A5-ON48257BAD.0049C1E4-48257BAD.004A27A7@cn.ibm.com>
Message-ID: <51E940BD.3020902@gmail.com>

On 19/07/2013 9:27 AM, De Xin Luan wrote:
>
> Hello,
>
> They can't solve the problem of R installation and direct me to 
> contact R help. I want to follow your standard way to install R 2.8.1 
> in AIX 7.1 64bit system. Please guide me to install R 2.8.1. Thank you.
>

Presumably you're paying them, so if they can't figure out how to solve 
your problem, you should stop paying them.  You're not paying us, but we 
will continue to offer help as long as you follow our advice, which is 
to upgrade to R 3.0.1.

There might be someone on this list who would offer tech support for 
2.8.1 for a fee, but I doubt it.

Duncan Murdoch


>
>
> Inactive hide details for Duncan Murdoch ---07/19/2013 09:11:52 
> PM---On 19/07/2013 6:16 AM, De Xin Luan wrote: > Hi Jeff,Duncan 
> Murdoch ---07/19/2013 09:11:52 PM---On 19/07/2013 6:16 AM, De Xin Luan 
> wrote: > Hi Jeff,
>
> From: Duncan Murdoch <murdoch.duncan at gmail.com>
> To: De Xin Luan/China/IBM at IBMCN,
> Cc: Jeff Newmiller <jdnewmil at dcn.davis.ca.us>, r-help at r-project.org
> Date: 07/19/2013 09:11 PM
> Subject: Re: [R] Help: Error when installing R 2.8.1 in IBM AIX system 
> from source code
>
> ------------------------------------------------------------------------
>
>
>
> On 19/07/2013 6:16 AM, De Xin Luan wrote:
> > Hi Jeff,
> >
> > Thanks for your quick response. Let me describe more about my situation.
> >
> > 1. Patch file - Yes, I found patch didn't change any file, so I manually
> > changed 4 files(R-2.8.1/configure, R-2.8.1/configure.ac,
> > R-2.8.1/Makeconf.in, R-2.8.1/src/main/Makefile.in) by reading the patch
> > file.
> >
> > 2. why I use old version R 2.8.1 - We want to use SPSS Statistics to 
> call R
> > in our server and have to install "Statistics essentials for R" 
> after R is
> > installed successfully. In Statistics 20 document, it only supports 
> R 2.8.1
> > and provide that install guidance.
>
> In that case, you should be contacting SPSS tech support for help.
>
> Duncan Murdoch
>
> >
> > 3. I don't know how to disable HTML format in my mail client. Sorry for
> > that. I rewrite colorful part again here as 3.1 and 3.2 :
> >
> > 3.1 Issue1: during "configure" step, I faced this error:"./configure
> > [20510]: "${}": bad substitution".
> > And I took action to solve it, the action is :add
> > "shlibpath_var=LD_LIBRARY_PATH" before line 20510 of configure file.
> >
> > 3.2 Issue2: during "make" step, I faced the below error but I don't know
> > how to fix it:
> >
> > ../../../bin/R[206]: "${}": bad substitution
> > make: The error code from the last command is 1.
> >
> > Stop.
> >
> > 4. Since you said it's not a standard patch, do you have a standard 
> patch
> > for R 2.8.1 installation in AIX 7.1 64bit system?
> >
> > Best regards,
> >
> > Dexin Luan (??????)
> >
> > [[alternative HTML version deleted]]
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>


From marc_schwartz at me.com  Fri Jul 19 17:40:59 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 19 Jul 2013 10:40:59 -0500
Subject: [R] [R-pkgs] WriteXLS Version 3.0.0 Released
Message-ID: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>

Hi all,

Version 3.0.0 of the WriteXLS package has been released to CRAN. Source tarballs are being mirrored and binaries for Windows and OSX should appear in due course.

Main CRAN URL: http://cran.r-project.org/web/packages/WriteXLS/index.html

WriterXLS is a cross-platform Perl based R function to create Excel 2003 (XLS) and Excel 2007 (XLSX) files from one or more data frames. Each data frame will be written to a separate named worksheet in the Excel spreadsheet. The worksheet name will be the name of the data frame it contains or can be specified by the user.

The key changes in the new version are:

1. The ability to create Excel 2007 (XLSX) files in addition to Excel 2003 (XLS) files.

2. The Perl package Excel::Writer::XLSX is now included to facilitate the creation of the Excel 2007 files.

3. The Perl package Text::CSV_XS has been replaced with Text::CSV_PP, which is a Pure Perl implementation of the former package and is included in the WriteXLS package. This should make it easier for users to install WriteXLS since a pre-compiled or locally compiled binary for Text::CSV_XS is no longer required.

4. Data frame columns that have a 'comment' attribute, created using the comment() function, will have the text content of the 'comment' attribute written to a cell comment in the first row of the worksheet containing that data frame. This will work for both Excel 2003 (XLS) and Excel 2007 (XLSX) files. These comments can serve as column labels, providing descriptive information on the content of the column in the Excel worksheet.


The package is openly maintained under GPL-2 at:

  https://github.com/marcschwartz/WriteXLS


If anyone identifies any issues, please let me know.

Thanks and regards,

Marc Schwartz

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From szehnder at uni-bonn.de  Fri Jul 19 18:54:28 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 19 Jul 2013 18:54:28 +0200
Subject: [R] S4 method signature - integer matrix
Message-ID: <70F6188B-F7D0-4B20-80DF-24EB50B5D30B@uni-bonn.de>

Dear R-Users and R-Devels,

I am programming a package with S4 classes and I search for a solution of the following problem: 

If you want an S4 method to await an integer argument you set the signature like this

setMethod("myfunction", signature(object = "myClass", y = "integer"), function(object, y) {//Do sth})

Now, if you want the method to await an integer matrix or array there is only one way how to define it

setMethod("myfunction", signature(object = "myClass", y = "matrix"), function(object, y) {//Do sth}) or
setMethod("myfunction", signature(object = "myClass", y = "array"), function(object, y) {//Do sth}) 

am I right? WIth this you can also pass a numeric matrix.

How would you check for an integer matrix in an S4 method (in the index function of R I think it is just coerced to integer)? Furthermore: How would you check for an integer matrix with values 
bigger one (so the typical R indices)? Is there a way how it is usually done in R (I think probably with apply())? Or is it usually better to throw an exception?


Best

Simon


From smartpink111 at yahoo.com  Fri Jul 19 19:43:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 19 Jul 2013 10:43:16 -0700 (PDT)
Subject: [R] Kruskal.test
In-Reply-To: <CAHc7oGGVtVVY=4KN6F14f1MZZgiNR3LC_C2vJcBM060TdA1fAw@mail.gmail.com>
References: <11494491.311764.1373393429407.JavaMail.nabble@joe.nabble.com>
	<CAHc7oGGZ==Us=-tV6qQ4h2wn93r3CmgsFbndycLL4DPW2XaFnA@mail.gmail.com>
	<1373394564.51384.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAHc7oGFXjv-5ubDOocy-bWXQcWm4vr969RTmENv7xc2pxSjP+w@mail.gmail.com>
	<1373395191.25374.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAHc7oGG3KrPA3oc6z13+fjQg+vYFcurnQ0PgSeLG6PTUSAcCNw@mail.gmail.com>
	<1373395739.56187.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAHc7oGFV-+p00ET4aM02maCAxK0KkEbU+h4Wfh3t3Rt0MAp_Yw@mail.gmail.com>
	<1373397473.79930.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAHc7oGHA=f9mORssrU5YEh+aoRzX1+fWQPsgDRm4FxE9O9mQiA@mail.gmail.com>
	<1373459067.39099.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAHc7oGGR=PdUJtDn13TFO9PMiJncGM9Bv4AyM=7Er37GtrWShw@mail.gmail.com>
	<1374168233.1342.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAHc7oGEfurc+cgJ3Gt8aYG9yyDzS_=z6AisWM80OYo58p7Ke+Q@mail.gmail.com>
	<1374254426.81012.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CAHc7oGGVtVVY=4KN6F14f1MZZgiNR3LC_C2vJcBM060TdA1fAw@mail.gmail.com>
Message-ID: <1374255796.66789.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
You could try:
Chisq1<-do.call(cbind,lapply(c(0.05,0.001),function(i) {x1<-sapply(seq_len(nrow(Specc)),function(i) chisq.test(as.table(unlist(Specc[i,-c(1:3)])))$p.value); sum(x1<i)}))
?Wilcox1<-do.call(cbind,lapply(c(0.05,0.001),function(i){x1<-sapply(seq_len(nrow(Specc)),function(i) wilcox.test(unlist(Specc[i,-c(1:3)]))$p.value);sum(x1<i)}))

res<-rbind(Wilcox1,Chisq1)
?colnames(res)<- c("number of rows iwth p-value<0.05", "number of rows with p-value<0.001")
?rownames(res)<-c("wilcox.test","chisq.test")
? res
#??????????? number of rows iwth p-value<0.05 number of rows with p-value<0.001
#wilcox.test?????????????????????????????? 14???????????????????????????????? 0
#chisq.test???????????????????????????????? 0???????????????????????????????? 0


#The warnings() were there for all the rows.
#If you want, you could have a new column with "name of test", instead of rownames.

A.K.





________________________________
From: Vera Costa <veracosta.rt at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, July 19, 2013 1:25 PM
Subject: Re: Kruskal.test



Thank you. 
But I need to construct a dataframe like I sent you. You can help me in this? I will look for your code in a few moments
No dia 19 de Jul de 2013 18:20, "arun" <smartpink111 at yahoo.com> escreveu:


From S.Ellison at LGCGroup.com  Fri Jul 19 20:17:24 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 19 Jul 2013 19:17:24 +0100
Subject: [R] extracting variance and covariance
In-Reply-To: <CAOLvsEwthi6Z-8OMMhHpGAF635zLF9kmgWnKike7LCp0B42qig@mail.gmail.com>
References: <CAOLvsEwthi6Z-8OMMhHpGAF635zLF9kmgWnKike7LCp0B42qig@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACBBF8F87@GOLD.corp.lgc-group.com>

 

> -----Original Message-----
> I am not able to 'extract variance and covariance'

I'm having a little trouble extracing meaning.

What data or model do you intend extracing variances and covariances from?

S

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From kat.emidio at gmail.com  Fri Jul 19 16:17:03 2013
From: kat.emidio at gmail.com (=?ISO-8859-1?Q?K=E1tia_Emidio?=)
Date: Fri, 19 Jul 2013 10:17:03 -0400
Subject: [R] help with matrix
Message-ID: <CABFLJOnoEyDpLTNjNagz4Wvse1=s3d_g-TuskznTeq=zO0qwnw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/416aa228/attachment.pl>

From Peter.Brecknock at bp.com  Fri Jul 19 21:54:53 2013
From: Peter.Brecknock at bp.com (Pete Brecknock)
Date: Fri, 19 Jul 2013 12:54:53 -0700 (PDT)
Subject: [R] Adding List Elements To A Data Frame
Message-ID: <1374263692978-4671932.post@n4.nabble.com>

Hi 

I am trying to add the contents of the list "myList" to a new column "z" in
the data frame "myDataframe"

myList <- list(c("A1","B1"), c("A2","B2","C2"), c("A3","B3"))

myDataframe <- data.frame(x=c(1,2,3), y=c("R","S","T"))

Would like to produce

x  y  z
1  R  A1,B1
2  S  A2,B2,C2
3  T  A3,B3

where z is a character string holding the contents of the different elements
of the list.

Any thoughts greatly appreciated.

Pete 




--
View this message in context: http://r.789695.n4.nabble.com/Adding-List-Elements-To-A-Data-Frame-tp4671932.html
Sent from the R help mailing list archive at Nabble.com.


From diggsb at ohsu.edu  Fri Jul 19 22:01:10 2013
From: diggsb at ohsu.edu (Brian Diggs)
Date: Fri, 19 Jul 2013 13:01:10 -0700
Subject: [R] Adding List Elements To A Data Frame
References: <1374263692978-4671932.post@n4.nabble.com>
Message-ID: <E5BA65CAFB491A4DBB1370F6C97216550744586DD1@EX-MB05.ohsu.edu>

On 7/19/2013 12:54 PM, Pete Brecknock wrote:
> Hi
>
> I am trying to add the contents of the list "myList" to a new column "z" in
> the data frame "myDataframe"
>
> myList <- list(c("A1","B1"), c("A2","B2","C2"), c("A3","B3"))
>
> myDataframe <- data.frame(x=c(1,2,3), y=c("R","S","T"))
>
> Would like to produce
>
> x  y  z
> 1  R  A1,B1
> 2  S  A2,B2,C2
> 3  T  A3,B3

myDataframe$z <- sapply(myList, paste0, collapse=",")

> where z is a character string holding the contents of the different elements
> of the list.
>
> Any thoughts greatly appreciated.
>
> Pete

-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From murdoch.duncan at gmail.com  Fri Jul 19 22:02:40 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 19 Jul 2013 16:02:40 -0400
Subject: [R] help with matrix
In-Reply-To: <CABFLJOnoEyDpLTNjNagz4Wvse1=s3d_g-TuskznTeq=zO0qwnw@mail.gmail.com>
References: <CABFLJOnoEyDpLTNjNagz4Wvse1=s3d_g-TuskznTeq=zO0qwnw@mail.gmail.com>
Message-ID: <51E99B60.2080106@gmail.com>

On 19/07/2013 10:17 AM, K?tia Emidio wrote:
> Hi,
>   I am a beginner at R and I would like to get information from a matrix,
> where the numbers are larger than or equal to 50m . This means that plants
> need to be apart at least  50m.  I  need to get the selection as in a way
> that I can identify which pair of species are 50m or more apart.
>
> here a peace of my matrix:
>
>     Nauc_calo_1 Nauc_calo_2 Nauc_calo_3  Nauc_calo_1 0 22 36  Nauc_calo_2 22
> 0 165.8  Nauc_calo_3 36 165.8 0
>

The which() function with arr.ind=TRUE will identify which matrix 
entries meet a condition.  For example,

 > M <- matrix(rnorm(20), 4, 5)
 > M
            [,1]       [,2]        [,3]        [,4]       [,5]
[1,] -0.6947070  1.2079620  0.77996512 -0.04287046 -1.5487528
[2,] -0.2079173 -1.1231086 -0.08336907  1.36860228  0.5846137
[3,] -1.2653964 -0.4028848  0.25331851 -0.22577099  0.1238542
[4,]  2.1689560 -0.4666554 -0.02854676  1.51647060  0.2159416
 > which(M > 1.5, arr.ind=TRUE)
      row col
[1,]   4   1
[2,]   4   4

Duncan Murdoch


From Peter.Brecknock at bp.com  Fri Jul 19 22:13:34 2013
From: Peter.Brecknock at bp.com (Pete Brecknock)
Date: Fri, 19 Jul 2013 13:13:34 -0700 (PDT)
Subject: [R] Adding List Elements To A Data Frame
In-Reply-To: <E5BA65CAFB491A4DBB1370F6C97216550744586DD1@EX-MB05.ohsu.edu>
References: <1374263692978-4671932.post@n4.nabble.com>
	<E5BA65CAFB491A4DBB1370F6C97216550744586DD1@EX-MB05.ohsu.edu>
Message-ID: <1374264814978-4671936.post@n4.nabble.com>

Thanks Brian.  Perfect.


Brian Diggs wrote
> On 7/19/2013 12:54 PM, Pete Brecknock wrote:
>> Hi
>>
>> I am trying to add the contents of the list "myList" to a new column "z"
>> in
>> the data frame "myDataframe"
>>
>> myList <- list(c("A1","B1"), c("A2","B2","C2"), c("A3","B3"))
>>
>> myDataframe <- data.frame(x=c(1,2,3), y=c("R","S","T"))
>>
>> Would like to produce
>>
>> x  y  z
>> 1  R  A1,B1
>> 2  S  A2,B2,C2
>> 3  T  A3,B3
> 
> myDataframe$z <- sapply(myList, paste0, collapse=",")
> 
>> where z is a character string holding the contents of the different
>> elements
>> of the list.
>>
>> Any thoughts greatly appreciated.
>>
>> Pete
> 
> -- 
> Brian S. Diggs, PhD
> Senior Research Associate, Department of Surgery
> Oregon Health & Science University
> 
> ______________________________________________

> R-help@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.





--
View this message in context: http://r.789695.n4.nabble.com/Adding-List-Elements-To-A-Data-Frame-tp4671932p4671936.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Jul 19 23:28:29 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Jul 2013 14:28:29 -0700
Subject: [R] Adding List Elements To A Data Frame
In-Reply-To: <1374263692978-4671932.post@n4.nabble.com>
References: <1374263692978-4671932.post@n4.nabble.com>
Message-ID: <8C8F792E-0EB5-4A53-B421-02B19264311A@comcast.net>


On Jul 19, 2013, at 12:54 PM, Pete Brecknock wrote:

> Hi 
> 
> I am trying to add the contents of the list "myList" to a new column "z" in
> the data frame "myDataframe"
> 
> myList <- list(c("A1","B1"), c("A2","B2","C2"), c("A3","B3"))
> 
> myDataframe <- data.frame(x=c(1,2,3), y=c("R","S","T"))
> 
> Would like to produce
> 
> x  y  z
> 1  R  A1,B1
> 2  S  A2,B2,C2
> 3  T  A3,B3
> 
> where z is a character string holding the contents of the different elements
> of the list.

> myDataframe[[3]] <- I(myList)
> myDataframe
  x y          z
1 1 R     A1, B1
2 2 S A2, B2, C2
3 3 T     A3, B3

-- 

David Winsemius
Alameda, CA, USA


From mb3058 at columbia.edu  Fri Jul 19 23:17:24 2013
From: mb3058 at columbia.edu (Manisha Brahma chary)
Date: Fri, 19 Jul 2013 17:17:24 -0400
Subject: [R] Using text and variable in ggtitle (ggplot2)
Message-ID: <6CE4AF87-985F-439F-8330-59B47F12C7CA@columbia.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/ce2f1100/attachment.pl>

From ruipbarradas at sapo.pt  Fri Jul 19 23:49:04 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 19 Jul 2013 22:49:04 +0100
Subject: [R] Adding List Elements To A Data Frame
In-Reply-To: <8C8F792E-0EB5-4A53-B421-02B19264311A@comcast.net>
References: <1374263692978-4671932.post@n4.nabble.com>
	<8C8F792E-0EB5-4A53-B421-02B19264311A@comcast.net>
Message-ID: <51E9B450.9010403@sapo.pt>

Hello,

If you create the 3rd column like that, it will be named V3, not z. You 
must do one of

myDataframe$z <- I(myList)
myDataframe[["z"]] <- I(myList)

Rui Barradas

Em 19-07-2013 22:28, David Winsemius escreveu:
>
> On Jul 19, 2013, at 12:54 PM, Pete Brecknock wrote:
>
>> Hi
>>
>> I am trying to add the contents of the list "myList" to a new column "z" in
>> the data frame "myDataframe"
>>
>> myList <- list(c("A1","B1"), c("A2","B2","C2"), c("A3","B3"))
>>
>> myDataframe <- data.frame(x=c(1,2,3), y=c("R","S","T"))
>>
>> Would like to produce
>>
>> x  y  z
>> 1  R  A1,B1
>> 2  S  A2,B2,C2
>> 3  T  A3,B3
>>
>> where z is a character string holding the contents of the different elements
>> of the list.
>
>> myDataframe[[3]] <- I(myList)
>> myDataframe
>    x y          z
> 1 1 R     A1, B1
> 2 2 S A2, B2, C2
> 3 3 T     A3, B3
>


From dwinsemius at comcast.net  Sat Jul 20 00:03:51 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 19 Jul 2013 15:03:51 -0700
Subject: [R] S4 method signature - integer matrix
In-Reply-To: <70F6188B-F7D0-4B20-80DF-24EB50B5D30B@uni-bonn.de>
References: <70F6188B-F7D0-4B20-80DF-24EB50B5D30B@uni-bonn.de>
Message-ID: <C8BC3080-FF28-44BE-B900-1B7993C844AC@comcast.net>


On Jul 19, 2013, at 9:54 AM, Simon Zehnder wrote:

> Dear R-Users and R-Devels,
> 
> I am programming a package with S4 classes and I search for a solution of the following problem: 
> 
> If you want an S4 method to await an integer argument you set the signature like this
> 
> setMethod("myfunction", signature(object = "myClass", y = "integer"), function(object, y) {//Do sth})
> 
> Now, if you want the method to await an integer matrix or array there is only one way how to define it
> 
> setMethod("myfunction", signature(object = "myClass", y = "matrix"), function(object, y) {//Do sth}) or
> setMethod("myfunction", signature(object = "myClass", y = "array"), function(object, y) {//Do sth}) 
> 
> am I right?

I don't think that is the only way. You could also test for mode being 'numeric' at the signature level and then within the validation check to see whether it has dimensions. See ?is.numeric and ?validObject

There is also the option of using a prototype.

As I understand the S4 checks they will apply an is.<mode> or is.<class> test as long as there is an correspond function that returns a logical. see ... ?is


> WIth this you can also pass a numeric matrix.
> 
> How would you check for an integer matrix in an S4 method (in the index function of R I think it is just coerced to integer)?

It would need be both integer mode...   ?is.integer and have dimensions...  ?dim

> Furthermore: How would you check for an integer matrix with values 
> bigger one (so the typical R indices)?

Just add a test in the 'validity' code. See ... ?setClass

> Is there a way how it is usually done in R (I think probably with apply())? Or is it usually better to throw an exception?


I don't see a reason to use apply.

-- 
David Winsemius
Alameda, CA, USA


From noahsilverman at ucla.edu  Sat Jul 20 00:14:57 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Fri, 19 Jul 2013 15:14:57 -0700
Subject: [R] Identify Leverage Points
Message-ID: <413AC584-2ECE-4478-8DCB-3A8F6C528989@ucla.edu>

Hello,

I'm working on some fairly standard regression models (linear, logistic, and poisson.)  Unfortunately, the data is rather messy. 

A visual inspection, using either a histogram or a density plot indicates some significant outliers.  Furthermore, summary statistics of the data indicate the same thing.

If I fit a linear regression in R using the "lm" command, I can then plot the model to look at residuals, etc.

I'm interesting in re-fitting the model with a N% of the high leverage points removed.   (Large data set, want to fit "most" of the data.)

Is there a computational way to get the leverage for each data point?  That way I can subset the data skipping N% of the highest leverage ones.


Thanks!


--
Noah Silverman, M.S., C.Phil
UCLA Department of Statistics
8117 Math Sciences Building
Los Angeles, CA 90095


From gunter.berton at gene.com  Sat Jul 20 00:43:08 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 19 Jul 2013 15:43:08 -0700
Subject: [R] Adding List Elements To A Data Frame
In-Reply-To: <51E9B450.9010403@sapo.pt>
References: <1374263692978-4671932.post@n4.nabble.com>
	<8C8F792E-0EB5-4A53-B421-02B19264311A@comcast.net>
	<51E9B450.9010403@sapo.pt>
Message-ID: <CACk-te359v=3ruBzYntZTpTduVMXmjVY9OMQuhaWE9fQwzf1sg@mail.gmail.com>

Folks:

I think it worth noting that the solutions provided by Brian and
David, which look exactly the same when print()ed, are entirely
different beasts. Brian's gives a column of strings; David;s gives a
column of lists (a list of lists). str() will provide details.

Both solutions are "correct" -- and point out the dangers of posting a
poorly specified question without context. You get what you pay for. I
have no idea which, if either, is "correct". That depends entirely on
the unspecified use to which you wish to put the result.

Cheers,
Bert



On Fri, Jul 19, 2013 at 2:49 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> If you create the 3rd column like that, it will be named V3, not z. You must
> do one of
>
> myDataframe$z <- I(myList)
> myDataframe[["z"]] <- I(myList)
>
> Rui Barradas
>
> Em 19-07-2013 22:28, David Winsemius escreveu:
>>
>>
>> On Jul 19, 2013, at 12:54 PM, Pete Brecknock wrote:
>>
>>> Hi
>>>
>>> I am trying to add the contents of the list "myList" to a new column "z"
>>> in
>>> the data frame "myDataframe"
>>>
>>> myList <- list(c("A1","B1"), c("A2","B2","C2"), c("A3","B3"))
>>>
>>> myDataframe <- data.frame(x=c(1,2,3), y=c("R","S","T"))
>>>
>>> Would like to produce
>>>
>>> x  y  z
>>> 1  R  A1,B1
>>> 2  S  A2,B2,C2
>>> 3  T  A3,B3
>>>
>>> where z is a character string holding the contents of the different
>>> elements
>>> of the list.
>>
>>
>>> myDataframe[[3]] <- I(myList)
>>> myDataframe
>>
>>    x y          z
>> 1 1 R     A1, B1
>> 2 2 S A2, B2, C2
>> 3 3 T     A3, B3
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From rainer.schuermann at gmx.net  Sat Jul 20 00:58:33 2013
From: rainer.schuermann at gmx.net (Rainer Schuermann)
Date: Sat, 20 Jul 2013 00:58:33 +0200
Subject: [R] Using text and variable in ggtitle (ggplot2)
In-Reply-To: <6CE4AF87-985F-439F-8330-59B47F12C7CA@columbia.edu>
References: <6CE4AF87-985F-439F-8330-59B47F12C7CA@columbia.edu>
Message-ID: <3054802.uMcRx8Lxz0@augeatur>

Not sure whether I understand your question fully but I guess paste() is your friend:

ggtitle( paste( "RR(overall) =", RR, "N =", N, "alpha =", alpha1 ) )


On Friday 19 July 2013 17:17:24 Manisha Brahma chary wrote:
> Hello,
> I am using ggplot2 to plot a graph and I want to give a title to the plot that has both text and variables. I have tried a couple of ways, but none of the methods work. Below is my code. Under ggtitle RR, N, alpha1 are variables and "RR(overall), "N", "alpha" are strings.
> 
> Require(ggplot2)
> data <- do.call(rbind,result)
> data.new <- as.data.frame(cbind(data$p1,(data$prob),data$r))
> colnames(data.new) <- c("ES","Probability","Vector")
> bp<-(ggplot(data.new,aes(x=ES,y=Probability,group=Vector,colour=factor(Vector))) + geom_line())
> bp.title<- bp+ ggtitle("RR(overall) ="RR, "N" = N, "alpha = "alpha1)
> bp.title
> 
> Any suggestion on ggplot2 will be much appreciated.
> 
> Thanks
> Man
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
- - - - -

Der NSA keine Chance: e-mail verschluesseln!
http://www.gpg4win.org/


From markleeds2 at gmail.com  Sat Jul 20 01:13:15 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Fri, 19 Jul 2013 19:13:15 -0400
Subject: [R] Identify Leverage Points
In-Reply-To: <413AC584-2ECE-4478-8DCB-3A8F6C528989@ucla.edu>
References: <413AC584-2ECE-4478-8DCB-3A8F6C528989@ucla.edu>
Message-ID: <CAHz+bWZFsvs=L-BbOzK4NFEzyxFmQ3RXkX-5-_juFH+aT107eg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130719/76e82bbe/attachment.pl>

From elaine.kuo.tw at gmail.com  Sat Jul 20 03:19:55 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Sat, 20 Jul 2013 09:19:55 +0800
Subject: [R] how to calculate the average values of each row in a matrix
Message-ID: <CAGJhoDxQm=dF9f_ntO98UVVwWdBX4cNk7TQtpq9V4JT6QFwu0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/41e8a7f1/attachment.pl>

From michael.weylandt at gmail.com  Sat Jul 20 03:33:16 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Fri, 19 Jul 2013 20:33:16 -0500
Subject: [R] how to calculate the average values of each row in a matrix
In-Reply-To: <CAGJhoDxQm=dF9f_ntO98UVVwWdBX4cNk7TQtpq9V4JT6QFwu0w@mail.gmail.com>
References: <CAGJhoDxQm=dF9f_ntO98UVVwWdBX4cNk7TQtpq9V4JT6QFwu0w@mail.gmail.com>
Message-ID: <8550C453-74E2-4562-ABDD-204BEFC1E441@gmail.com>



On Jul 19, 2013, at 20:19, Elaine Kuo <elaine.kuo.tw at gmail.com> wrote:

> Hello,
> 
> I have a matrix (class matrix) composed of GridCell (row and column).
> The matrix value is the beta diversity index value between two grids.
> 
> Now I would like to get the average value of each GridCell.
> Please kindly advise how to make the calculation.
> Thank you.
> 

Perhaps the rowMeans() function?

MW

> Elaine
> 
> The matrix looks like (cited from Michael Friendly)
> I would like to get the average value of each color.
> 
> 
>      Obs  stim   RPur   Red   Yel   Gy1   Gy2  Green  Blue  BlP  Pur1
> Pur2
> 
>                      1  RPur     .     .     .     .     .      .     .
> .     .     .
>                      2  Red    11.5    .     .     .     .      .     .
> .     .     .
>                      3  Yel    13.1   6.0    .     .     .      .     .
> .     .     .
>                      4  Gy1    12.6   7.9   6.2    .     .      .     .
> .     .     .
>                      5  Gy2    10.6   8.4   8.4   5.2    .      .     .
> .     .     .
>                      6  Green  10.6   9.4   9.9   6.5   4.1     .     .
> .     .     .
>                      7  Blue   10.8  10.2  10.3   8.8   7.0    6.4    .
> .     .     .
>                       8  BlP     7.3  11.3  12.7  11.2  10.4    9.9   4.2
>  .     .     .
>                       9  Pur1    5.4  11.5  12.9  11.7  10.8    9.4   8.4
> 4.5    .     .
>                      10  Pur2    5.0  11.5  10.7  10.2  10.6   10.1   8.1
> 6.4    3     .
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stev0175 at gmail.com  Sat Jul 20 05:18:47 2013
From: stev0175 at gmail.com (Jeff Stevens)
Date: Fri, 19 Jul 2013 22:18:47 -0500
Subject: [R] Different x-axis scales using c() in latticeExtra
Message-ID: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>

Hi,

I would like to combine multiple xyplots into a single, multipanel
display.  Using R 3.0.1 in Ubuntu, I have used c() from latticeExtra
to combine three plots, but the x-axis for two plots are on a log
scale and the other is on a normal scale.  I also have included
equispace.log=FALSE to clean up the tick labels.  However, when I try
all of these, the x-axis scale of the first panel is used for all
three.  How do I keep different scales for the different panels?

Here is an example:
library(lattice)
library(latticeExtra)
response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)

pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
equispaced.log = FALSE),
  panel = function(x, y, ...) {
    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
    panel.text(x = log10(8), y = log10(120), labels = "(a)")
  }
)

pred2_plot <- xyplot(response ~ predictor2, scales = list(log = TRUE,
equispaced.log = FALSE),
  panel = function(x, y, ...) {
    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
    panel.text(x = log10(2), y = log10(120), labels = "(b)")
  }
)

pred3_plot <- xyplot(response ~ predictor3, scales = list(y = list(log
= TRUE, equispaced.log = FALSE)),
  panel = function(x, y, ...) {
    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
    panel.text(x = 22, y = log10(120), labels = "(c)")
  }
)

all_plots <- c(pred1_plot, pred2_plot, pred3_plot, layout = c(3, 1), x.same = F)
update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
scales = list(y=list(log=T, equispaced.log=FALSE), x = c(list(log=T,
equispaced.log=FALSE), list(log=T, equispaced.log=FALSE),
list(log=F))))

update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
scales = c(list(log = TRUE, equispaced.log = FALSE), list(log = TRUE,
equispaced.log = FALSE), list(y=list(log=T, equispaced.log = FALSE))))

Any help is appreciated!

Thanks,
Jeff


From oohpsjin at gmail.com  Sat Jul 20 06:37:22 2013
From: oohpsjin at gmail.com (Jin Choi)
Date: Sat, 20 Jul 2013 00:37:22 -0400
Subject: [R] Adding across columns ignoring NA
Message-ID: <CADO0ddMGZ4h1Wp4SNtdE2eX2jEzpmX3crposB5ve39aHz0XUsA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/85a2517f/attachment.pl>

From bhh at xs4all.nl  Sat Jul 20 07:06:49 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 20 Jul 2013 07:06:49 +0200
Subject: [R] Adding across columns ignoring NA
In-Reply-To: <CADO0ddMGZ4h1Wp4SNtdE2eX2jEzpmX3crposB5ve39aHz0XUsA@mail.gmail.com>
References: <CADO0ddMGZ4h1Wp4SNtdE2eX2jEzpmX3crposB5ve39aHz0XUsA@mail.gmail.com>
Message-ID: <FA380494-E809-481A-95F6-FC16FCF2B6FC@xs4all.nl>


On 20-07-2013, at 06:37, Jin Choi <oohpsjin at gmail.com> wrote:

> I am having difficulty finding a solution to devising an R code to do the
> following:
> 
> I have 5 numerical variables and I would like to create a new variable that
> is the sum of those 5 variables. However, there are many NA values
> throughout these 5 variables and everytime I run the following code
> 
> new_variable=var1+var2+var3+var4+var5
> 
> I get NA as the sum whenever one of those 5 variables are NA. I cannot
> figure out a way to have new_variable represent the sum for only those
> values that are not NA.
> 
> As an example,
> if var1=3
> var2=3
> var3=NA
> var4=NA
> var5=2
> 
> I would like new_variable to be 8 but I keep getting NA and I have
> unsuccessfully tried different methods to do so. I feel there is a simple
> method to solve my problem but I am unaware of such. I would appreciate any
> guidance!

?sum

Have a look at the na.rm argument of sum.

Berend


From gunter.berton at gene.com  Sat Jul 20 07:58:25 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 19 Jul 2013 22:58:25 -0700
Subject: [R] Adding across columns ignoring NA
In-Reply-To: <FA380494-E809-481A-95F6-FC16FCF2B6FC@xs4all.nl>
References: <CADO0ddMGZ4h1Wp4SNtdE2eX2jEzpmX3crposB5ve39aHz0XUsA@mail.gmail.com>
	<FA380494-E809-481A-95F6-FC16FCF2B6FC@xs4all.nl>
Message-ID: <CACk-te1t_JYoAd1jdSOsbPhgF5smo0b7ePdpHa_fa6cngXmOGg@mail.gmail.com>

Berend:

No. The OP's "variables" appear to be vectors. sum() sums columnwise
(vectorwise).

Something like

rowSums(cbind(var1,var2,var3,var4,var6), na.rm=TRUE)

appears to be what is wanted. But of course,Jin Choi appears to need
to do some homework -- e.g. by reading the Introduction to R online
manual to gain a better understanding of R's standard data structures.

Cheers,
Bert



On Fri, Jul 19, 2013 at 10:06 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
> On 20-07-2013, at 06:37, Jin Choi <oohpsjin at gmail.com> wrote:
>
>> I am having difficulty finding a solution to devising an R code to do the
>> following:
>>
>> I have 5 numerical variables and I would like to create a new variable that
>> is the sum of those 5 variables. However, there are many NA values
>> throughout these 5 variables and everytime I run the following code
>>
>> new_variable=var1+var2+var3+var4+var5
>>
>> I get NA as the sum whenever one of those 5 variables are NA. I cannot
>> figure out a way to have new_variable represent the sum for only those
>> values that are not NA.
>>
>> As an example,
>> if var1=3
>> var2=3
>> var3=NA
>> var4=NA
>> var5=2
>>
>> I would like new_variable to be 8 but I keep getting NA and I have
>> unsuccessfully tried different methods to do so. I feel there is a simple
>> method to solve my problem but I am unaware of such. I would appreciate any
>> guidance!
>
> ?sum
>
> Have a look at the na.rm argument of sum.
>
> Berend
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From smartpink111 at yahoo.com  Sat Jul 20 06:49:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 19 Jul 2013 21:49:10 -0700 (PDT)
Subject: [R] Adding across columns ignoring NA
In-Reply-To: <CADO0ddMGZ4h1Wp4SNtdE2eX2jEzpmX3crposB5ve39aHz0XUsA@mail.gmail.com>
References: <CADO0ddMGZ4h1Wp4SNtdE2eX2jEzpmX3crposB5ve39aHz0XUsA@mail.gmail.com>
Message-ID: <1374295750.51709.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
?sum(var1,var2,var3,var4,var5,na.rm=TRUE)
#[1] 8
A.K.




----- Original Message -----
From: Jin Choi <oohpsjin at gmail.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Saturday, July 20, 2013 12:37 AM
Subject: [R] Adding across columns ignoring NA

I am having difficulty finding a solution to devising an R code to do the
following:

I have 5 numerical variables and I would like to create a new variable that
is the sum of those 5 variables. However, there are many NA values
throughout these 5 variables and everytime I run the following code

new_variable=var1+var2+var3+var4+var5

I get NA as the sum whenever one of those 5 variables are NA. I cannot
figure out a way to have new_variable represent the sum for only those
values that are not NA.

As an example,
if var1=3
var2=3
var3=NA
var4=NA
var5=2

I would like new_variable to be 8 but I keep getting NA and I have
unsuccessfully tried different methods to do so. I feel there is a simple
method to solve my problem but I am unaware of such. I would appreciate any
guidance!

Thank you
JC

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gtchinde at aid.fr  Sat Jul 20 09:42:29 2013
From: gtchinde at aid.fr (Guibert TCHINDE)
Date: Sat, 20 Jul 2013 09:42:29 +0200
Subject: [R] RE : how to calculate the average values of each row in a matrix
In-Reply-To: <8550C453-74E2-4562-ABDD-204BEFC1E441@gmail.com>
References: <CAGJhoDxQm=dF9f_ntO98UVVwWdBX4cNk7TQtpq9V4JT6QFwu0w@mail.gmail.com>,
	<8550C453-74E2-4562-ABDD-204BEFC1E441@gmail.com>
Message-ID: <961B3E1A83021C4DB09B33D489893228435FB5456B@mail.aid.local>

> vec = matrix(data=round(rnorm(15,1,2)),ncol=3)
> vec
     [,1] [,2] [,3]
[1,]    1    1   -1
[2,]    6    2   -1
[3,]    0    0    2
[4,]    0   -3   -2
[5,]    1    1    2
> rowMeans(vec)
[1]  0.3333333  2.3333333  0.6666667 -1.6666667  1.3333333
> apply(vec,1,mean)
[1]  0.3333333  2.3333333  0.6666667 -1.6666667  1.3333333

may be this helps

GT
________________________________________
De : r-help-bounces at r-project.org [r-help-bounces at r-project.org] de la part de R. Michael Weylandt <michael.weylandt at gmail.com> [michael.weylandt at gmail.com]
Date d'envoi : samedi 20 juillet 2013 03:33
? : Elaine Kuo
Cc : r-help at stat.math.ethz.ch
Objet : Re: [R] how to calculate the average values of each row in a matrix

On Jul 19, 2013, at 20:19, Elaine Kuo <elaine.kuo.tw at gmail.com> wrote:

> Hello,
>
> I have a matrix (class matrix) composed of GridCell (row and column).
> The matrix value is the beta diversity index value between two grids.
>
> Now I would like to get the average value of each GridCell.
> Please kindly advise how to make the calculation.
> Thank you.
>

Perhaps the rowMeans() function?

MW

> Elaine
>
> The matrix looks like (cited from Michael Friendly)
> I would like to get the average value of each color.
>
>
>      Obs  stim   RPur   Red   Yel   Gy1   Gy2  Green  Blue  BlP  Pur1
> Pur2
>
>                      1  RPur     .     .     .     .     .      .     .
> .     .     .
>                      2  Red    11.5    .     .     .     .      .     .
> .     .     .
>                      3  Yel    13.1   6.0    .     .     .      .     .
> .     .     .
>                      4  Gy1    12.6   7.9   6.2    .     .      .     .
> .     .     .
>                      5  Gy2    10.6   8.4   8.4   5.2    .      .     .
> .     .     .
>                      6  Green  10.6   9.4   9.9   6.5   4.1     .     .
> .     .     .
>                      7  Blue   10.8  10.2  10.3   8.8   7.0    6.4    .
> .     .     .
>                       8  BlP     7.3  11.3  12.7  11.2  10.4    9.9   4.2
>  .     .     .
>                       9  Pur1    5.4  11.5  12.9  11.7  10.8    9.4   8.4
> 4.5    .     .
>                      10  Pur2    5.0  11.5  10.7  10.2  10.6   10.1   8.1
> 6.4    3     .
>
>    [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


Click https://www.mailcontrol.com/sr/0NMwdyLXvWXGX2PQPOmvUlvAwUAcTfZn4fkKLlvv9q+YH6kYUkFzXm6zZ2oqmDGRhRWtQ2HzzdeVGm43FW9a3A==  to report this email as spam.

From wetbelldiver at gmail.com  Sat Jul 20 12:25:17 2013
From: wetbelldiver at gmail.com (Wet Bell Diver)
Date: Sat, 20 Jul 2013 12:25:17 +0200
Subject: [R] cut into groups of equal nr of elements...
In-Reply-To: <CAFEqCdwR+3yifzD_ib4=vamENPZgpdvX9WM8BnUeNtmLkkyJMg@mail.gmail.com>
References: <CAAjnpdhQYnMmxGnXaGg6OqgmeVnZGU7kQ5irufPN8No1cN7NqA@mail.gmail.com>
	<CAFEqCdwR+3yifzD_ib4=vamENPZgpdvX9WM8BnUeNtmLkkyJMg@mail.gmail.com>
Message-ID: <51EA658D.80409@gmail.com>


Witold,

Here's one way:

Vec <- rnorm(30)
Vec.cut <- cut(Vec, breaks=c(quantile(Vec, probs = seq(0, 1, by = 0.20))),
     labels=c("0-20","20-40","40-60","60-80","80-100"), 
include.lowest=TRUE)
table(Vec.cut)


or determine the breaks automatically:

cut.size <- function(x, size) {
   cut.prob <- size/length(x)
   if (length(x)%%size != 0) warning("Equal sized groups only possible 
by dropping some elements from x")
   Vec.cut <- cut(x, breaks=c(quantile(x, probs = seq(0, 1, by = 
size/length(x)))), include.lowest=TRUE)
}
CUT <- cut.size(Vec, 6)
table(CUT)


Of course, when asking for
cut.size(Vec, 7)
this will yield 4 equal-sized groups of 7, because there is no way to 
perfectly split 30 observations in groups of 7 each (the highest two 
values from Vec will be dropped).

HTH,
Peter



Op 18-7-2013 0:02, Greg Snow schreef:
> You could use the quantile function to choose the cut points and pass that
> to cut.
>
> Or you could sort the vector and just take the first n elements as the 1st
> group, etc.
>
>
> On Wed, Jul 17, 2013 at 3:43 PM, Witold E Wolski <wewolski at gmail.com> wrote:
>
>> I would like to "cut" a vector into groups of equal nr of elements.
>> looking for a function on the lines of cut but where I can specify
>> the size of the groups instead of the nr of groups.
>>
>>
>>
>>
>> --
>> Witold Eryk Wolski
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>


From szehnder at uni-bonn.de  Sat Jul 20 14:06:51 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sat, 20 Jul 2013 14:06:51 +0200
Subject: [R] S4 method signature - integer matrix
In-Reply-To: <C8BC3080-FF28-44BE-B900-1B7993C844AC@comcast.net>
References: <70F6188B-F7D0-4B20-80DF-24EB50B5D30B@uni-bonn.de>
	<C8BC3080-FF28-44BE-B900-1B7993C844AC@comcast.net>
Message-ID: <170AF4E8-F17F-43E7-8AB9-B9589E3D452F@uni-bonn.de>

Hi David,

thanks for the reply! 

The prototype solution is I think not the appropriate solution, when the method adds the integer matrix next to the class object into the argument list. Also the .validObject method can only be applied to the object for which the method is called or I have to write an integer matrix class that has its own .validObject method.

From your suggestions I had a direction to search more precisely and I found this: 

Set the signature to "matrix": checks for matrix when method is called.
Then check for typeof(mymatrix) == "integer": Return an exception if FALSE.
In case of an index I can add then an all(apply(mymatrix, c(1, 2), ">", 0)): Return an exception if FALSE

Thank you very much for your advice. It helped me to find a good solution.


Best 

Simon


On Jul 20, 2013, at 12:03 AM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Jul 19, 2013, at 9:54 AM, Simon Zehnder wrote:
> 
>> Dear R-Users and R-Devels,
>> 
>> I am programming a package with S4 classes and I search for a solution of the following problem: 
>> 
>> If you want an S4 method to await an integer argument you set the signature like this
>> 
>> setMethod("myfunction", signature(object = "myClass", y = "integer"), function(object, y) {//Do sth})
>> 
>> Now, if you want the method to await an integer matrix or array there is only one way how to define it
>> 
>> setMethod("myfunction", signature(object = "myClass", y = "matrix"), function(object, y) {//Do sth}) or
>> setMethod("myfunction", signature(object = "myClass", y = "array"), function(object, y) {//Do sth}) 
>> 
>> am I right?
> 
> I don't think that is the only way. You could also test for mode being 'numeric' at the signature level and then within the validation check to see whether it has dimensions. See ?is.numeric and ?validObject
> 
> There is also the option of using a prototype.
> 
> As I understand the S4 checks they will apply an is.<mode> or is.<class> test as long as there is an correspond function that returns a logical. see ... ?is
> 
> 
>> WIth this you can also pass a numeric matrix.
>> 
>> How would you check for an integer matrix in an S4 method (in the index function of R I think it is just coerced to integer)?
> 
> It would need be both integer mode...   ?is.integer and have dimensions...  ?dim
> 
>> Furthermore: How would you check for an integer matrix with values 
>> bigger one (so the typical R indices)?
> 
> Just add a test in the 'validity' code. See ... ?setClass
> 
>> Is there a way how it is usually done in R (I think probably with apply())? Or is it usually better to throw an exception?
> 
> 
> I don't see a reason to use apply.
> 
> -- 
> David Winsemius
> Alameda, CA, USA
> 


From Hui.Du at dataventures.com  Sat Jul 20 17:43:58 2013
From: Hui.Du at dataventures.com (Hui Du)
Date: Sat, 20 Jul 2013 15:43:58 +0000
Subject: [R] read data from a URL with login required
Message-ID: <13A371591163EE48BD95F2D2B244AAF41C1A2606@TWIX.dataventures.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/f233aed9/attachment.pl>

From tmrsg11 at gmail.com  Sat Jul 20 18:05:42 2013
From: tmrsg11 at gmail.com (C W)
Date: Sat, 20 Jul 2013 12:05:42 -0400
Subject: [R] How to search for a sequence(and its combination) inside a
	vector?
Message-ID: <CAE2FW2m1BGETqeuA7Yjwec3Tw3EMJ5DmJ5mvZtOWwsQemDxzNw@mail.gmail.com>

Hi R list,

I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
to find how many times 1, 2, 3 appeared.
Basically, I want to "grab" the beginning of the sequence and tally it up.

R code:

> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)

> a <- vec %in% c(1, 2, 3)
> a
  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
TRUE  TRUE FALSE FALSE
 [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
FALSE FALSE FALSE FALSE
 [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
FALSE  TRUE  TRUE  TRUE
 [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
TRUE  TRUE  TRUE FALSE
 [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
FALSE FALSE FALSE FALSE
 [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
FALSE  TRUE  TRUE  TRUE
 [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
FALSE FALSE FALSE FALSE
 [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE

> rle(a)
Run Length Encoding
  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...

What should I do after this?

Thanks,
Mike


From dbp at apl.washington.edu  Sat Jul 20 18:05:32 2013
From: dbp at apl.washington.edu (dbp)
Date: Sat, 20 Jul 2013 09:05:32 -0700
Subject: [R] problem with minus signs when using postscript/pdf functions
	with ComputerModernItalic family
Message-ID: <B4D80349-3A7F-4265-968D-B107F7EC43A7@apl.washington.edu>

When I use the postscript with the ComputerModernItalic family, minus signs are not properly displayed, but are changed into capital gammas.   The attached test-postscript.pdf file illustrates the problem, which I created starting with the following R code:

> postscript("test-postscript.eps", family = "ComputerModernItalic")
> plot(seq(-5,5,1),seq(-5,5,1))
> dev.off()

I then created the attached .pdf file from the .eps file using the Preview application on a MacBook Pro (see below for details about my R session).  I have also attempted to create the same plot using the pdf function.  For some reason, pdf does not like `family = "ComputerModernItalic"', so I needed to do the following.

> CMitalic <- Type1Font("ComputerModern2",
+                       c("CM_regular_10.afm", "CM_boldx_10.afm",
+                         "cmti10.afm", "cmbxti10.afm",
+                         "CM_symbol_10.afm"),
+                       encoding = "TeXtext.enc")
> pdf("test-pdf.pdf", family = CMitalic)
> plot(seq(-5,5,1),seq(-5,5,1))
> dev.off()

The attached test-pdf.pdf file shows the minus signs are no longer replaced by capital gammas, but are now blanked out.
   For the record, I noticed this problem several years ago and have been hoping that it would disappear with each new release of R.  At the time that I first noted it, I asked a colleague to run an example on a Windows box, and the same problem occurred, leading me to conclude that the problem is not unique to Mac OS-X.  Any help or workarounds for the problem would be greatly appreciated!  Regards,
- Don Percival

> sessionInfo()
R version 2.15.3 (2013-03-01)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_2.15.3 tools_2.15.3  




-------------- next part --------------
A non-text attachment was scrubbed...
Name: test-postscript.pdf
Type: application/pdf
Size: 8186 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/fe6167fd/attachment.pdf>
-------------- next part --------------

-------------- next part --------------
A non-text attachment was scrubbed...
Name: test-pdf.pdf
Type: application/pdf
Size: 7803 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/fe6167fd/attachment-0001.pdf>
-------------- next part --------------




===========================================
dbp at apl.washington.edu
Applied Physics Laboratory
Box 355640
University of Washington
Seattle, WA 98195-5640
Phones: 206-543-1368      Fax: 206-543-6785
       206-543-1300
http://faculty.washington.edu/dbp
===========================================


From bhh at xs4all.nl  Sat Jul 20 18:24:29 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 20 Jul 2013 18:24:29 +0200
Subject: [R] How to search for a sequence(and its combination) inside a
	vector?
In-Reply-To: <CAE2FW2m1BGETqeuA7Yjwec3Tw3EMJ5DmJ5mvZtOWwsQemDxzNw@mail.gmail.com>
References: <CAE2FW2m1BGETqeuA7Yjwec3Tw3EMJ5DmJ5mvZtOWwsQemDxzNw@mail.gmail.com>
Message-ID: <1FEAB30C-207C-4965-8A3B-ED2120860D26@xs4all.nl>


On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:

> Hi R list,
> 
> I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
> to find how many times 1, 2, 3 appeared.
> Basically, I want to "grab" the beginning of the sequence and tally it up.
> 
> R code:
> 
>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
> 
>> a <- vec %in% c(1, 2, 3)
>> a
>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
> TRUE  TRUE FALSE FALSE
> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
> FALSE FALSE FALSE FALSE
> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
> FALSE  TRUE  TRUE  TRUE
> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
> TRUE  TRUE  TRUE FALSE
> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
> FALSE FALSE FALSE FALSE
> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
> FALSE  TRUE  TRUE  TRUE
> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
> FALSE FALSE FALSE FALSE
> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE
> 
>> rle(a)
> Run Length Encoding
>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
> 
> What should I do after this?
> 

Well how about

sum(a)

or 

b <- rle(a)
sum(b$lengths[b$values])

Berend

> Thanks,
> Mike
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Jul 20 18:31:17 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 20 Jul 2013 08:31:17 -0800
Subject: [R] Different x-axis scales using c() in latticeExtra
In-Reply-To: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>
Message-ID: <33AA3A06820.0000041Ejrkrideau@inbox.com>

No idea what I happening but does this give what you expect

library(gridExtra)
preds  <-  grid.arrange(pred1_plot,pred2_plot, pred3_plot, ncol=3)
preds

John Kane
Kingston ON Canada


> -----Original Message-----
> From: stev0175 at gmail.com
> Sent: Fri, 19 Jul 2013 22:18:47 -0500
> To: r-help at r-project.org
> Subject: [R] Different x-axis scales using c() in latticeExtra
> 
> Hi,
> 
> I would like to combine multiple xyplots into a single, multipanel
> display.  Using R 3.0.1 in Ubuntu, I have used c() from latticeExtra
> to combine three plots, but the x-axis for two plots are on a log
> scale and the other is on a normal scale.  I also have included
> equispace.log=FALSE to clean up the tick labels.  However, when I try
> all of these, the x-axis scale of the first panel is used for all
> three.  How do I keep different scales for the different panels?
> 
> Here is an example:
> library(lattice)
> library(latticeExtra)
> response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
> predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
> predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
> predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)
> 
> pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
> equispaced.log = FALSE),
>   panel = function(x, y, ...) {
>     panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>     panel.text(x = log10(8), y = log10(120), labels = "(a)")
>   }
> )
> 
> pred2_plot <- xyplot(response ~ predictor2, scales = list(log = TRUE,
> equispaced.log = FALSE),
>   panel = function(x, y, ...) {
>     panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>     panel.text(x = log10(2), y = log10(120), labels = "(b)")
>   }
> )
> 
> pred3_plot <- xyplot(response ~ predictor3, scales = list(y = list(log
> = TRUE, equispaced.log = FALSE)),
>   panel = function(x, y, ...) {
>     panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>     panel.text(x = 22, y = log10(120), labels = "(c)")
>   }
> )
> 
> all_plots <- c(pred1_plot, pred2_plot, pred3_plot, layout = c(3, 1),
> x.same = F)
> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
> scales = list(y=list(log=T, equispaced.log=FALSE), x = c(list(log=T,
> equispaced.log=FALSE), list(log=T, equispaced.log=FALSE),
> list(log=F))))
> 
> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
> scales = c(list(log = TRUE, equispaced.log = FALSE), list(log = TRUE,
> equispaced.log = FALSE), list(y=list(log=T, equispaced.log = FALSE))))
> 
> Any help is appreciated!
> 
> Thanks,
> Jeff
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From tmrsg11 at gmail.com  Sat Jul 20 18:36:55 2013
From: tmrsg11 at gmail.com (C W)
Date: Sat, 20 Jul 2013 12:36:55 -0400
Subject: [R] How to search for a sequence(and its combination) inside a
	vector?
In-Reply-To: <1FEAB30C-207C-4965-8A3B-ED2120860D26@xs4all.nl>
References: <CAE2FW2m1BGETqeuA7Yjwec3Tw3EMJ5DmJ5mvZtOWwsQemDxzNw@mail.gmail.com>
	<1FEAB30C-207C-4965-8A3B-ED2120860D26@xs4all.nl>
Message-ID: <CAE2FW2mgJ39D7+dTbeGcx0ymzfHi1oym3Bs_fCu0sKfoM-8GWA@mail.gmail.com>

Hi Berend
I am looking for a table,
# of times one element (out of 1, 2, 3) showed up, two elements, and all three.

I am trying, don't know if this works:

> aa <- rle(a)
> b <- aa$lengths[aa$values]
> table(b)
b
 1  3
 3 12

Mike



On Sat, Jul 20, 2013 at 12:24 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>
> On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:
>
>> Hi R list,
>>
>> I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
>> to find how many times 1, 2, 3 appeared.
>> Basically, I want to "grab" the beginning of the sequence and tally it up.
>>
>> R code:
>>
>>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
>> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
>> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
>> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
>> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
>> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
>>
>>> a <- vec %in% c(1, 2, 3)
>>> a
>>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
>> TRUE  TRUE FALSE FALSE
>> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>> FALSE FALSE FALSE FALSE
>> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>> FALSE  TRUE  TRUE  TRUE
>> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
>> TRUE  TRUE  TRUE FALSE
>> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
>> FALSE FALSE FALSE FALSE
>> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>> FALSE  TRUE  TRUE  TRUE
>> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>> FALSE FALSE FALSE FALSE
>> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE  TRUE
>>
>>> rle(a)
>> Run Length Encoding
>>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
>>
>> What should I do after this?
>>
>
> Well how about
>
> sum(a)
>
> or
>
> b <- rle(a)
> sum(b$lengths[b$values])
>
> Berend
>
>> Thanks,
>> Mike
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>


From dwinsemius at comcast.net  Sat Jul 20 18:50:59 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 20 Jul 2013 09:50:59 -0700
Subject: [R] Different x-axis scales using c() in latticeExtra
In-Reply-To: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>
References: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>
Message-ID: <0FFC0330-DBFC-4E77-B296-AC87B8B0B2D8@comcast.net>


On Jul 19, 2013, at 8:18 PM, Jeff Stevens wrote:

> Hi,
> 
> I would like to combine multiple xyplots into a single, multipanel
> display.  Using R 3.0.1 in Ubuntu, I have used c() from latticeExtra
> to combine three plots, but the x-axis for two plots are on a log
> scale and the other is on a normal scale.  I also have included
> equispace.log=FALSE to clean up the tick labels.  However, when I try
> all of these, the x-axis scale of the first panel is used for all
> three.  How do I keep different scales for the different panels?
> 
> Here is an example:
> library(lattice)
> library(latticeExtra)
> response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
> predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
> predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
> predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)
> 
> pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
> equispaced.log = FALSE),
>  panel = function(x, y, ...) {
>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>    panel.text(x = log10(8), y = log10(120), labels = "(a)")
>  }
> )
> 
> pred2_plot <- xyplot(response ~ predictor2, scales = list(log = TRUE,
> equispaced.log = FALSE),
>  panel = function(x, y, ...) {
>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>    panel.text(x = log10(2), y = log10(120), labels = "(b)")
>  }
> )
> 
> pred3_plot <- xyplot(response ~ predictor3, scales = list(y = list(log
> = TRUE, equispaced.log = FALSE)),
>  panel = function(x, y, ...) {
>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>    panel.text(x = 22, y = log10(120), labels = "(c)")
>  }
> )
> 
> all_plots <- c(pred1_plot, pred2_plot, pred3_plot, layout = c(3, 1), x.same = F)
> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
> scales = list(y=list(log=T, equispaced.log=FALSE), x = c(list(log=T,
> equispaced.log=FALSE), list(log=T, equispaced.log=FALSE),
> list(log=F))))
> 
> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
> scales = c(list(log = TRUE, equispaced.log = FALSE), list(log = TRUE,
> equispaced.log = FALSE), list(y=list(log=T, equispaced.log = FALSE))))
> 
> Any help is appreciated!

I assume there was a notice o your console that there were warnings, right? You should offer the full texts of warnings and error messages. Here the full text of the first and second warnings:

> warnings()[1:2]
$`log scales cannot be changed via 'update'`
update.trellis(all_plots, xlab = c("Predictor 1", "Predictor 2", 
    "Predictor 3"), scales = c(list(log = TRUE, equispaced.log = FALSE), 
    list(log = TRUE, equispaced.log = FALSE), list(y = list(log = T, 
        equispaced.log = FALSE))))
$`'x' is NULL so the result will be NULL`
rep(scales[[nm]], length.out = 2)

The first one is telling you why the results should be different than you expect. I'm not entirely sure what the second one is telling you, but it doesn't sound good.

-- 
David Winsemius
Alameda, CA, USA


From jrkrideau at inbox.com  Sat Jul 20 18:52:14 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 20 Jul 2013 08:52:14 -0800
Subject: [R] How to search for a sequence(and its combination) inside a
 vector?
In-Reply-To: <CAE2FW2mgJ39D7+dTbeGcx0ymzfHi1oym3Bs_fCu0sKfoM-8GWA@mail.gmail.com>
References: <cae2fw2m1bgetqeua7yjwec3tw3emj5dmj5mvztowwsqemdxznw@mail.gmail.com>
	<1feab30c-207c-4965-8a3b-ed2120860d26@xs4all.nl>
Message-ID: <33D90D5EEB1.0000044Djrkrideau@inbox.com>

Taking Berend's example a bit further, this seems to work

If you use str(b) you will see it is a list

b <- rle(a)
cc  <-  data.frame(b[[1]], b[[2]])
names(cc)  <-  c("leng", 'val')
dd  <-  subset(cc, val ==TRUE )
table(dd)

John Kane
Kingston ON Canada


> -----Original Message-----
> From: tmrsg11 at gmail.com
> Sent: Sat, 20 Jul 2013 12:36:55 -0400
> To: bhh at xs4all.nl
> Subject: Re: [R] How to search for a sequence(and its combination) inside
> a vector?
> 
> Hi Berend
> I am looking for a table,
> # of times one element (out of 1, 2, 3) showed up, two elements, and all
> three.
> 
> I am trying, don't know if this works:
> 
>> aa <- rle(a)
>> b <- aa$lengths[aa$values]
>> table(b)
> b
>  1  3
>  3 12
> 
> Mike
> 
> 
> 
> On Sat, Jul 20, 2013 at 12:24 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>> 
>> On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:
>> 
>>> Hi R list,
>>> 
>>> I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
>>> to find how many times 1, 2, 3 appeared.
>>> Basically, I want to "grab" the beginning of the sequence and tally it
>>> up.
>>> 
>>> R code:
>>> 
>>>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
>>> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
>>> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
>>> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
>>> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
>>> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
>>> 
>>>> a <- vec %in% c(1, 2, 3)
>>>> a
>>>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
>>> TRUE  TRUE FALSE FALSE
>>> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>>> FALSE FALSE FALSE FALSE
>>> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>> FALSE  TRUE  TRUE  TRUE
>>> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
>>> TRUE  TRUE  TRUE FALSE
>>> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
>>> FALSE FALSE FALSE FALSE
>>> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>> FALSE  TRUE  TRUE  TRUE
>>> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>> FALSE FALSE FALSE FALSE
>>> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
>>> TRUE
>>> 
>>>> rle(a)
>>> Run Length Encoding
>>>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>>>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
>>> 
>>> What should I do after this?
>>> 
>> 
>> Well how about
>> 
>> sum(a)
>> 
>> or
>> 
>> b <- rle(a)
>> sum(b$lengths[b$values])
>> 
>> Berend
>> 
>>> Thanks,
>>> Mike
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
Receive Notifications of Incoming Messages
Easily monitor multiple email accounts & access them with a click.
Visit http://www.inbox.com/notifier and check it out!


From ripley at stats.ox.ac.uk  Sat Jul 20 18:54:22 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 20 Jul 2013 17:54:22 +0100
Subject: [R] read data from a URL with login required
In-Reply-To: <13A371591163EE48BD95F2D2B244AAF41C1A2606@TWIX.dataventures.local>
References: <13A371591163EE48BD95F2D2B244AAF41C1A2606@TWIX.dataventures.local>
Message-ID: <51EAC0BE.2080209@stats.ox.ac.uk>

On 20/07/2013 16:43, Hui Du wrote:
> Hi All,
>
> How to read a URL requiring log in info in R? For example, I want to download some info from Linkedin pages, my username is abc, password is 123. How can I download my desired URL page in R?

It really depends what 'login' means.  For some sites this can be 
incorporated into a URL of the form "http://user:passwd at foo.dom.com": 
for others a multi-stage interaction is required.

I would try to do it using e.g. wget or curl and capture the output via 
system().  If curl works, you most likely can do the same with package 
RCurl.

Note that the help for tools usually calls such things 'authentication' 
and reserves 'login' for an ftp URL (you did not tell us the scheme).

Also note: any more detail would be appropriate only for the R-devel 
list (see the posting guide).

> Many thanks.
>
> HXD
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From tmrsg11 at gmail.com  Sat Jul 20 19:11:47 2013
From: tmrsg11 at gmail.com (C W)
Date: Sat, 20 Jul 2013 13:11:47 -0400
Subject: [R] How to search for a sequence(and its combination) inside a
	vector?
In-Reply-To: <33D90D5EEB1.0000044Djrkrideau@inbox.com>
References: <cae2fw2m1bgetqeua7yjwec3tw3emj5dmj5mvztowwsqemdxznw@mail.gmail.com>
	<1feab30c-207c-4965-8a3b-ed2120860d26@xs4all.nl>
	<CAE2FW2mgJ39D7+dTbeGcx0ymzfHi1oym3Bs_fCu0sKfoM-8GWA@mail.gmail.com>
	<33D90D5EEB1.0000044Djrkrideau@inbox.com>
Message-ID: <CAE2FW2kVGuZX-owWsY6fPcejB78OfwaaHLzaJnXWE6Qa+_gPCA@mail.gmail.com>

Thanks John.

Why do I get length of 5 and 6?  I thought I am only tallying up 1 to 3?
> table(dd)
    val
leng TRUE
   1    5
   2    4
   3   81
   5    1
   6    4

-M

On Sat, Jul 20, 2013 at 12:52 PM, John Kane <jrkrideau at inbox.com> wrote:
> Taking Berend's example a bit further, this seems to work
>
> If you use str(b) you will see it is a list
>
> b <- rle(a)
> cc  <-  data.frame(b[[1]], b[[2]])
> names(cc)  <-  c("leng", 'val')
> dd  <-  subset(cc, val ==TRUE )
> table(dd)
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: tmrsg11 at gmail.com
>> Sent: Sat, 20 Jul 2013 12:36:55 -0400
>> To: bhh at xs4all.nl
>> Subject: Re: [R] How to search for a sequence(and its combination) inside
>> a vector?
>>
>> Hi Berend
>> I am looking for a table,
>> # of times one element (out of 1, 2, 3) showed up, two elements, and all
>> three.
>>
>> I am trying, don't know if this works:
>>
>>> aa <- rle(a)
>>> b <- aa$lengths[aa$values]
>>> table(b)
>> b
>>  1  3
>>  3 12
>>
>> Mike
>>
>>
>>
>> On Sat, Jul 20, 2013 at 12:24 PM, Berend Hasselman <bhh at xs4all.nl> wrote:
>>>
>>> On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:
>>>
>>>> Hi R list,
>>>>
>>>> I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
>>>> to find how many times 1, 2, 3 appeared.
>>>> Basically, I want to "grab" the beginning of the sequence and tally it
>>>> up.
>>>>
>>>> R code:
>>>>
>>>>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
>>>> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
>>>> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
>>>> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
>>>> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
>>>> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
>>>>
>>>>> a <- vec %in% c(1, 2, 3)
>>>>> a
>>>>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
>>>> TRUE  TRUE FALSE FALSE
>>>> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>>>> FALSE FALSE FALSE FALSE
>>>> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>>> FALSE  TRUE  TRUE  TRUE
>>>> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
>>>> TRUE  TRUE  TRUE FALSE
>>>> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
>>>> FALSE FALSE FALSE FALSE
>>>> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>> FALSE  TRUE  TRUE  TRUE
>>>> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>> FALSE FALSE FALSE FALSE
>>>> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE
>>>> TRUE
>>>>
>>>>> rle(a)
>>>> Run Length Encoding
>>>>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>>>>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
>>>>
>>>> What should I do after this?
>>>>
>>>
>>> Well how about
>>>
>>> sum(a)
>>>
>>> or
>>>
>>> b <- rle(a)
>>> sum(b$lengths[b$values])
>>>
>>> Berend
>>>
>>>> Thanks,
>>>> Mike
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ____________________________________________________________
> Receive Notifications of Incoming Messages
> Easily monitor multiple email accounts & access them with a click.
> Visit http://www.inbox.com/notifier and check it out!
>
>


From bhh at xs4all.nl  Sat Jul 20 19:38:07 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sat, 20 Jul 2013 19:38:07 +0200
Subject: [R] How to search for a sequence(and its combination) inside a
	vector?
In-Reply-To: <CAE2FW2kVGuZX-owWsY6fPcejB78OfwaaHLzaJnXWE6Qa+_gPCA@mail.gmail.com>
References: <cae2fw2m1bgetqeua7yjwec3tw3emj5dmj5mvztowwsqemdxznw@mail.gmail.com>
	<1feab30c-207c-4965-8a3b-ed2120860d26@xs4all.nl>
	<CAE2FW2mgJ39D7+dTbeGcx0ymzfHi1oym3Bs_fCu0sKfoM-8GWA@mail.gmail.com>
	<33D90D5EEB1.0000044Djrkrideau@inbox.com>
	<CAE2FW2kVGuZX-owWsY6fPcejB78OfwaaHLzaJnXWE6Qa+_gPCA@mail.gmail.com>
Message-ID: <0C0CC48F-5A90-41CD-A12B-DDAB8FE17B6A@xs4all.nl>


On 20-07-2013, at 19:11, C W <tmrsg11 at gmail.com> wrote:

> Thanks John.
> 
> Why do I get length of 5 and 6?  I thought I am only tallying up 1 to 3?
>> table(dd)
>    val
> leng TRUE
>   1    5
>   2    4
>   3   81
>   5    1
>   6    4

I wouldn't know. Not same data?
It's completely unclear, to me at least, what you actually are trying to do.
With your initial data, my initial proposal and John's procedure I got

> cc  <-  data.frame(b[[1]], b[[2]])
> names(cc)  <-  c("leng", 'val')
> dd  <-  subset(cc, val ==TRUE )
> table(dd)
    val
leng TRUE
   1    3
   3   12

Berend


From jrkrideau at inbox.com  Sat Jul 20 19:41:34 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 20 Jul 2013 09:41:34 -0800
Subject: [R] How to search for a sequence(and its combination) inside a
 vector?
In-Reply-To: <CAE2FW2kVGuZX-owWsY6fPcejB78OfwaaHLzaJnXWE6Qa+_gPCA@mail.gmail.com>
References: <cae2fw2m1bgetqeua7yjwec3tw3emj5dmj5mvztowwsqemdxznw@mail.gmail.com>
	<33d90d5eeb1.0000044djrkrideau@inbox.com>
	<1feab30c-207c-4965-8a3b-ed2120860d26@xs4all.nl>
	<cae2fw2mgj39d7+dtbegcx0ymzfhi1oym3bs_fcu0skfom-8gwa@mail.gmail.com>
Message-ID: <34474C3D74B.0000049Ajrkrideau@inbox.com>

Beats me. I get: 
table(dd)
    val
leng TRUE
   1    3
   3   12

What does dd look like.  In my case I get this where the first column is the row number
dd
   leng  val
1     3 TRUE
3     3 TRUE
5     3 TRUE
7     3 TRUE
9     3 TRUE
11    1 TRUE
13    3 TRUE
15    3 TRUE
17    3 TRUE
19    3 TRUE
21    3 TRUE
23    3 TRUE
25    1 TRUE
27    3 TRUE
29    1 TRUE

John Kane
Kingston ON Canada


> -----Original Message-----
> From: tmrsg11 at gmail.com
> Sent: Sat, 20 Jul 2013 13:11:47 -0400
> To: jrkrideau at inbox.com
> Subject: Re: [R] How to search for a sequence(and its combination) inside
> a vector?
> 
> Thanks John.
> 
> Why do I get length of 5 and 6?  I thought I am only tallying up 1 to 3?
>> table(dd)
>     val
> leng TRUE
>    1    5
>    2    4
>    3   81
>    5    1
>    6    4
> 
> -M
> 
> On Sat, Jul 20, 2013 at 12:52 PM, John Kane <jrkrideau at inbox.com> wrote:
>> Taking Berend's example a bit further, this seems to work
>> 
>> If you use str(b) you will see it is a list
>> 
>> b <- rle(a)
>> cc  <-  data.frame(b[[1]], b[[2]])
>> names(cc)  <-  c("leng", 'val')
>> dd  <-  subset(cc, val ==TRUE )
>> table(dd)
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: tmrsg11 at gmail.com
>>> Sent: Sat, 20 Jul 2013 12:36:55 -0400
>>> To: bhh at xs4all.nl
>>> Subject: Re: [R] How to search for a sequence(and its combination)
>>> inside
>>> a vector?
>>> 
>>> Hi Berend
>>> I am looking for a table,
>>> # of times one element (out of 1, 2, 3) showed up, two elements, and
>>> all
>>> three.
>>> 
>>> I am trying, don't know if this works:
>>> 
>>>> aa <- rle(a)
>>>> b <- aa$lengths[aa$values]
>>>> table(b)
>>> b
>>>  1  3
>>>  3 12
>>> 
>>> Mike
>>> 
>>> 
>>> 
>>> On Sat, Jul 20, 2013 at 12:24 PM, Berend Hasselman <bhh at xs4all.nl>
>>> wrote:
>>>> 
>>>> On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:
>>>> 
>>>>> Hi R list,
>>>>> 
>>>>> I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
>>>>> to find how many times 1, 2, 3 appeared.
>>>>> Basically, I want to "grab" the beginning of the sequence and tally
>>>>> it
>>>>> up.
>>>>> 
>>>>> R code:
>>>>> 
>>>>>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13,
>>>>>> 14,
>>>>> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
>>>>> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
>>>>> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
>>>>> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
>>>>> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
>>>>> 
>>>>>> a <- vec %in% c(1, 2, 3)
>>>>>> a
>>>>>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
>>>>> TRUE  TRUE FALSE FALSE
>>>>> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>>>>> FALSE FALSE FALSE FALSE
>>>>> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>>>> FALSE  TRUE  TRUE  TRUE
>>>>> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
>>>>> TRUE  TRUE  TRUE FALSE
>>>>> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
>>>>> FALSE FALSE FALSE FALSE
>>>>> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>> FALSE  TRUE  TRUE  TRUE
>>>>> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>> FALSE FALSE FALSE FALSE
>>>>> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE
>>>>> FALSE
>>>>> TRUE
>>>>> 
>>>>>> rle(a)
>>>>> Run Length Encoding
>>>>>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>>>>>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
>>>>> 
>>>>> What should I do after this?
>>>>> 
>>>> 
>>>> Well how about
>>>> 
>>>> sum(a)
>>>> 
>>>> or
>>>> 
>>>> b <- rle(a)
>>>> sum(b$lengths[b$values])
>>>> 
>>>> Berend
>>>> 
>>>>> Thanks,
>>>>> Mike
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> ____________________________________________________________
>> Receive Notifications of Incoming Messages
>> Easily monitor multiple email accounts & access them with a click.
>> Visit http://www.inbox.com/notifier and check it out!
>> 
>>

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From noahsilverman at ucla.edu  Sat Jul 20 19:47:35 2013
From: noahsilverman at ucla.edu (Noah Silverman)
Date: Sat, 20 Jul 2013 10:47:35 -0700
Subject: [R] Identify Leverage Points
In-Reply-To: <CAHz+bWZFsvs=L-BbOzK4NFEzyxFmQ3RXkX-5-_juFH+aT107eg@mail.gmail.com>
References: <413AC584-2ECE-4478-8DCB-3A8F6C528989@ucla.edu>
	<CAHz+bWZFsvs=L-BbOzK4NFEzyxFmQ3RXkX-5-_juFH+aT107eg@mail.gmail.com>
Message-ID: <F5CD4198-22A0-47B6-99D6-1883A5DE9AEE@ucla.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/280f6a5e/attachment.pl>

From tmrsg11 at gmail.com  Sat Jul 20 19:50:10 2013
From: tmrsg11 at gmail.com (C W)
Date: Sat, 20 Jul 2013 13:50:10 -0400
Subject: [R] How to search for a sequence(and its combination) inside a
	vector?
In-Reply-To: <34474C3D74B.0000049Ajrkrideau@inbox.com>
References: <cae2fw2m1bgetqeua7yjwec3tw3emj5dmj5mvztowwsqemdxznw@mail.gmail.com>
	<33d90d5eeb1.0000044djrkrideau@inbox.com>
	<1feab30c-207c-4965-8a3b-ed2120860d26@xs4all.nl>
	<cae2fw2mgj39d7+dtbegcx0ymzfhi1oym3bs_fcu0skfom-8gwa@mail.gmail.com>
	<CAE2FW2kVGuZX-owWsY6fPcejB78OfwaaHLzaJnXWE6Qa+_gPCA@mail.gmail.com>
	<34474C3D74B.0000049Ajrkrideau@inbox.com>
Message-ID: <CAE2FW2=J0nw9qkxEQJCZrxqhjn7=toxftcCV5Tbz8u0-22LnsQ@mail.gmail.com>

Thanks, you guys are correct, I had different data.
But why I get length 5 and 6, should only be 1 to 3.

Full R code :

vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1, 2, 3,
4, 5, 6, 8, 9, 10, 11, 12, 14, 1, 2, 3, 4, 9, 13, 15, 1, 2, 3,
4, 6, 8, 9, 11, 12, 1, 2, 3, 7, 8, 9, 14, 1, 2, 3, 12, 1, 2,
3, 4, 5, 10, 14, 1, 2, 3, 4, 5, 7, 8, 12, 13, 14, 1, 2, 3, 10,
1, 3, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 1, 2, 3, 4, 5, 8, 9,
11, 12, 15, 1, 2, 3, 4, 7, 9, 10, 13, 1, 2, 3, 4, 5, 7, 10, 11,
15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 1, 2, 3, 6, 7,
8, 9, 10, 12, 13, 14, 15, 1, 2, 3, 4, 7, 1, 2, 3, 5, 8, 13, 1,
2, 3, 5, 8, 11, 15, 1, 2, 3, 1, 2, 3, 10, 1, 2, 3, 4, 7, 8, 9,
10, 11, 12, 14, 1, 3, 9, 11, 13, 14, 1, 2, 3, 4, 5, 7, 8, 9,
10, 11, 12, 13, 14, 15, 1, 2, 3, 4, 5, 13, 14, 15, 1, 2, 3, 11,
13, 14, 1, 2, 3, 8, 1, 2, 3, 4, 5, 6, 8, 11, 12, 14, 1, 2, 3,
5, 6, 9, 10, 11, 12, 15, 1, 2, 3, 4, 5, 9, 11, 12, 13, 1, 2,
3, 4, 5, 13, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15,
1, 2, 3, 7, 8, 9, 1, 2, 3, 5, 7, 8, 9, 10, 12, 14, 15, 1, 2,
3, 4, 5, 6, 8, 14, 1, 2, 3, 1, 2, 3, 10, 11, 13, 1, 2, 3, 4,
9, 10, 12, 13, 14, 1, 2, 3, 4, 5, 6, 12, 1, 2, 3, 4, 5, 6, 7,
10, 12, 13, 14, 15, 1, 2, 3, 6, 10, 14, 1, 2, 3, 4, 6, 7, 8,
9, 10, 11, 13, 14, 1, 2, 3, 1, 2, 3, 4, 7, 8, 10, 1, 2, 3, 7,
8, 11, 13, 15, 1, 2, 3, 4, 7, 8, 14, 15, 1, 2, 3, 4, 14, 1, 2,
3, 4, 6, 7, 10, 12, 1, 2, 3, 5, 7, 8, 11, 13, 14, 15, 1, 2, 3,
4, 1, 2, 3, 6, 7, 9, 11, 12, 13, 14, 1, 2, 3, 7, 11, 12, 1, 2,
3, 5, 6, 8, 9, 10, 12, 15, 1, 2, 3, 5, 6, 8, 9, 11, 1, 2, 3,
7, 8, 11, 13, 14, 15, 1, 2, 3, 4, 10, 12, 14, 1, 2, 3, 11, 12,
13, 15, 1, 2, 3, 5, 7, 10, 11, 12, 13, 14, 15, 1, 3, 10, 1, 2,
3, 1, 2, 3, 8, 10, 15, 1, 2, 3, 4, 7, 10, 12, 14, 1, 2, 3, 9,
10, 11, 1, 2, 3, 6, 9, 10, 15, 1, 9, 14, 1, 2, 3, 7, 10, 14,
1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 15, 1, 2, 3, 5, 6, 7, 8, 9,
11, 12, 13, 14, 15, 1, 2, 3, 6, 8, 11, 12, 1, 7, 1, 2, 3, 8,
13, 15, 1, 2, 3, 4, 8, 9, 11, 1, 2, 3, 4, 7, 13, 14, 1, 2, 3,
5, 6, 9, 1, 3, 7, 12, 13, 15, 1, 2, 3, 5, 6, 8, 10, 1, 3, 5,
7, 8, 10, 11, 1, 2, 3, 5, 6, 11, 14, 1, 2, 3, 4, 9, 10, 11, 13,
14, 1, 2, 3, 4, 6, 9, 14, 15, 1, 2, 3, 11, 1, 2, 3, 4, 5, 7,
11, 13, 14, 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 1, 2, 3, 4,
5, 6, 7, 9, 10, 11, 12, 14, 1, 4, 7, 1, 2, 3, 5, 6, 8, 9, 10,
12, 13, 15, 1, 2, 3, 4, 5, 8, 10, 12, 13)
a <- vec %in% c(1, 2, 3)
b <- rle(a)
cc  <-  data.frame(b[[1]], b[[2]])
names(cc)  <-  c("leng", 'val')
dd  <-  subset(cc, val ==TRUE )
table(dd)

> table(dd)
    val
leng TRUE
   1    5
   2    4
   3   81
   5    1
   6    4

btw,
> length(vec)
[1] 762

So, the tally should add up to that if correct.

-M


On Sat, Jul 20, 2013 at 1:41 PM, John Kane <jrkrideau at inbox.com> wrote:
> Beats me. I get:
> table(dd)
>     val
> leng TRUE
>    1    3
>    3   12
>
> What does dd look like.  In my case I get this where the first column is the row number
> dd
>    leng  val
> 1     3 TRUE
> 3     3 TRUE
> 5     3 TRUE
> 7     3 TRUE
> 9     3 TRUE
> 11    1 TRUE
> 13    3 TRUE
> 15    3 TRUE
> 17    3 TRUE
> 19    3 TRUE
> 21    3 TRUE
> 23    3 TRUE
> 25    1 TRUE
> 27    3 TRUE
> 29    1 TRUE
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: tmrsg11 at gmail.com
>> Sent: Sat, 20 Jul 2013 13:11:47 -0400
>> To: jrkrideau at inbox.com
>> Subject: Re: [R] How to search for a sequence(and its combination) inside
>> a vector?
>>
>> Thanks John.
>>
>> Why do I get length of 5 and 6?  I thought I am only tallying up 1 to 3?
>>> table(dd)
>>     val
>> leng TRUE
>>    1    5
>>    2    4
>>    3   81
>>    5    1
>>    6    4
>>
>> -M
>>
>> On Sat, Jul 20, 2013 at 12:52 PM, John Kane <jrkrideau at inbox.com> wrote:
>>> Taking Berend's example a bit further, this seems to work
>>>
>>> If you use str(b) you will see it is a list
>>>
>>> b <- rle(a)
>>> cc  <-  data.frame(b[[1]], b[[2]])
>>> names(cc)  <-  c("leng", 'val')
>>> dd  <-  subset(cc, val ==TRUE )
>>> table(dd)
>>>
>>> John Kane
>>> Kingston ON Canada
>>>
>>>
>>>> -----Original Message-----
>>>> From: tmrsg11 at gmail.com
>>>> Sent: Sat, 20 Jul 2013 12:36:55 -0400
>>>> To: bhh at xs4all.nl
>>>> Subject: Re: [R] How to search for a sequence(and its combination)
>>>> inside
>>>> a vector?
>>>>
>>>> Hi Berend
>>>> I am looking for a table,
>>>> # of times one element (out of 1, 2, 3) showed up, two elements, and
>>>> all
>>>> three.
>>>>
>>>> I am trying, don't know if this works:
>>>>
>>>>> aa <- rle(a)
>>>>> b <- aa$lengths[aa$values]
>>>>> table(b)
>>>> b
>>>>  1  3
>>>>  3 12
>>>>
>>>> Mike
>>>>
>>>>
>>>>
>>>> On Sat, Jul 20, 2013 at 12:24 PM, Berend Hasselman <bhh at xs4all.nl>
>>>> wrote:
>>>>>
>>>>> On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:
>>>>>
>>>>>> Hi R list,
>>>>>>
>>>>>> I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
>>>>>> to find how many times 1, 2, 3 appeared.
>>>>>> Basically, I want to "grab" the beginning of the sequence and tally
>>>>>> it
>>>>>> up.
>>>>>>
>>>>>> R code:
>>>>>>
>>>>>>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13,
>>>>>>> 14,
>>>>>> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
>>>>>> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
>>>>>> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
>>>>>> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
>>>>>> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
>>>>>>
>>>>>>> a <- vec %in% c(1, 2, 3)
>>>>>>> a
>>>>>>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
>>>>>> TRUE  TRUE FALSE FALSE
>>>>>> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>>>>>> FALSE FALSE FALSE FALSE
>>>>>> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>>>>> FALSE  TRUE  TRUE  TRUE
>>>>>> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
>>>>>> TRUE  TRUE  TRUE FALSE
>>>>>> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
>>>>>> FALSE FALSE FALSE FALSE
>>>>>> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>>> FALSE  TRUE  TRUE  TRUE
>>>>>> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>>> FALSE FALSE FALSE FALSE
>>>>>> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE
>>>>>> FALSE
>>>>>> TRUE
>>>>>>
>>>>>>> rle(a)
>>>>>> Run Length Encoding
>>>>>>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>>>>>>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
>>>>>>
>>>>>> What should I do after this?
>>>>>>
>>>>>
>>>>> Well how about
>>>>>
>>>>> sum(a)
>>>>>
>>>>> or
>>>>>
>>>>> b <- rle(a)
>>>>> sum(b$lengths[b$values])
>>>>>
>>>>> Berend
>>>>>
>>>>>> Thanks,
>>>>>> Mike
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>> ____________________________________________________________
>>> Receive Notifications of Incoming Messages
>>> Easily monitor multiple email accounts & access them with a click.
>>> Visit http://www.inbox.com/notifier and check it out!
>>>
>>>
>
> ____________________________________________________________
> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
> Visit http://www.inbox.com/photosharing to find out more!
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From tmrsg11 at gmail.com  Sat Jul 20 20:06:26 2013
From: tmrsg11 at gmail.com (C W)
Date: Sat, 20 Jul 2013 14:06:26 -0400
Subject: [R] How to search for a sequence(and its combination) inside a
	vector?
In-Reply-To: <CAE2FW2=J0nw9qkxEQJCZrxqhjn7=toxftcCV5Tbz8u0-22LnsQ@mail.gmail.com>
References: <cae2fw2m1bgetqeua7yjwec3tw3emj5dmj5mvztowwsqemdxznw@mail.gmail.com>
	<33d90d5eeb1.0000044djrkrideau@inbox.com>
	<1feab30c-207c-4965-8a3b-ed2120860d26@xs4all.nl>
	<cae2fw2mgj39d7+dtbegcx0ymzfhi1oym3bs_fcu0skfom-8gwa@mail.gmail.com>
	<CAE2FW2kVGuZX-owWsY6fPcejB78OfwaaHLzaJnXWE6Qa+_gPCA@mail.gmail.com>
	<34474C3D74B.0000049Ajrkrideau@inbox.com>
	<CAE2FW2=J0nw9qkxEQJCZrxqhjn7=toxftcCV5Tbz8u0-22LnsQ@mail.gmail.com>
Message-ID: <CAE2FW2m+mu+tze5_fyDPrJknPGAuR4ZMAE7u47okq7Dh6FC8KQ@mail.gmail.com>

Hi, John
I am doing sparsity recovery from glmnet.

Elements 1, 2, 3 of the repeating sequence are the nonzero elements.
But it's not always recovered.

How my original data frame looks like
> df[1:15, ]
    i             x
2   1  0.0869399788
3   2 -0.0994713934
4   3  0.0720312837
5   4  0.0075392684
6   5  0.0130364386
7   6  0.0238318855
8   7 -0.0152197121
9   8  0.0097389626
10 13  0.0005068968
12  1  0.0679442455
13  2 -0.0647438953
14  3  0.0656297104
15  5  0.0003406059
16  7  0.0241146788
17  8  0.0093850612


I trimmed out the data column, only grabbing the index.

-M


On Sat, Jul 20, 2013 at 1:50 PM, C W <tmrsg11 at gmail.com> wrote:
> Thanks, you guys are correct, I had different data.
> But why I get length 5 and 6, should only be 1 to 3.
>
> Full R code :
>
> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1, 2, 3,
> 4, 5, 6, 8, 9, 10, 11, 12, 14, 1, 2, 3, 4, 9, 13, 15, 1, 2, 3,
> 4, 6, 8, 9, 11, 12, 1, 2, 3, 7, 8, 9, 14, 1, 2, 3, 12, 1, 2,
> 3, 4, 5, 10, 14, 1, 2, 3, 4, 5, 7, 8, 12, 13, 14, 1, 2, 3, 10,
> 1, 3, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 1, 2, 3, 4, 5, 8, 9,
> 11, 12, 15, 1, 2, 3, 4, 7, 9, 10, 13, 1, 2, 3, 4, 5, 7, 10, 11,
> 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 1, 2, 3, 6, 7,
> 8, 9, 10, 12, 13, 14, 15, 1, 2, 3, 4, 7, 1, 2, 3, 5, 8, 13, 1,
> 2, 3, 5, 8, 11, 15, 1, 2, 3, 1, 2, 3, 10, 1, 2, 3, 4, 7, 8, 9,
> 10, 11, 12, 14, 1, 3, 9, 11, 13, 14, 1, 2, 3, 4, 5, 7, 8, 9,
> 10, 11, 12, 13, 14, 15, 1, 2, 3, 4, 5, 13, 14, 15, 1, 2, 3, 11,
> 13, 14, 1, 2, 3, 8, 1, 2, 3, 4, 5, 6, 8, 11, 12, 14, 1, 2, 3,
> 5, 6, 9, 10, 11, 12, 15, 1, 2, 3, 4, 5, 9, 11, 12, 13, 1, 2,
> 3, 4, 5, 13, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15,
> 1, 2, 3, 7, 8, 9, 1, 2, 3, 5, 7, 8, 9, 10, 12, 14, 15, 1, 2,
> 3, 4, 5, 6, 8, 14, 1, 2, 3, 1, 2, 3, 10, 11, 13, 1, 2, 3, 4,
> 9, 10, 12, 13, 14, 1, 2, 3, 4, 5, 6, 12, 1, 2, 3, 4, 5, 6, 7,
> 10, 12, 13, 14, 15, 1, 2, 3, 6, 10, 14, 1, 2, 3, 4, 6, 7, 8,
> 9, 10, 11, 13, 14, 1, 2, 3, 1, 2, 3, 4, 7, 8, 10, 1, 2, 3, 7,
> 8, 11, 13, 15, 1, 2, 3, 4, 7, 8, 14, 15, 1, 2, 3, 4, 14, 1, 2,
> 3, 4, 6, 7, 10, 12, 1, 2, 3, 5, 7, 8, 11, 13, 14, 15, 1, 2, 3,
> 4, 1, 2, 3, 6, 7, 9, 11, 12, 13, 14, 1, 2, 3, 7, 11, 12, 1, 2,
> 3, 5, 6, 8, 9, 10, 12, 15, 1, 2, 3, 5, 6, 8, 9, 11, 1, 2, 3,
> 7, 8, 11, 13, 14, 15, 1, 2, 3, 4, 10, 12, 14, 1, 2, 3, 11, 12,
> 13, 15, 1, 2, 3, 5, 7, 10, 11, 12, 13, 14, 15, 1, 3, 10, 1, 2,
> 3, 1, 2, 3, 8, 10, 15, 1, 2, 3, 4, 7, 10, 12, 14, 1, 2, 3, 9,
> 10, 11, 1, 2, 3, 6, 9, 10, 15, 1, 9, 14, 1, 2, 3, 7, 10, 14,
> 1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 15, 1, 2, 3, 5, 6, 7, 8, 9,
> 11, 12, 13, 14, 15, 1, 2, 3, 6, 8, 11, 12, 1, 7, 1, 2, 3, 8,
> 13, 15, 1, 2, 3, 4, 8, 9, 11, 1, 2, 3, 4, 7, 13, 14, 1, 2, 3,
> 5, 6, 9, 1, 3, 7, 12, 13, 15, 1, 2, 3, 5, 6, 8, 10, 1, 3, 5,
> 7, 8, 10, 11, 1, 2, 3, 5, 6, 11, 14, 1, 2, 3, 4, 9, 10, 11, 13,
> 14, 1, 2, 3, 4, 6, 9, 14, 15, 1, 2, 3, 11, 1, 2, 3, 4, 5, 7,
> 11, 13, 14, 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 1, 2, 3, 4,
> 5, 6, 7, 9, 10, 11, 12, 14, 1, 4, 7, 1, 2, 3, 5, 6, 8, 9, 10,
> 12, 13, 15, 1, 2, 3, 4, 5, 8, 10, 12, 13)
> a <- vec %in% c(1, 2, 3)
> b <- rle(a)
> cc  <-  data.frame(b[[1]], b[[2]])
> names(cc)  <-  c("leng", 'val')
> dd  <-  subset(cc, val ==TRUE )
> table(dd)
>
>> table(dd)
>     val
> leng TRUE
>    1    5
>    2    4
>    3   81
>    5    1
>    6    4
>
> btw,
>> length(vec)
> [1] 762
>
> So, the tally should add up to that if correct.
>
> -M
>
>
> On Sat, Jul 20, 2013 at 1:41 PM, John Kane <jrkrideau at inbox.com> wrote:
>> Beats me. I get:
>> table(dd)
>>     val
>> leng TRUE
>>    1    3
>>    3   12
>>
>> What does dd look like.  In my case I get this where the first column is the row number
>> dd
>>    leng  val
>> 1     3 TRUE
>> 3     3 TRUE
>> 5     3 TRUE
>> 7     3 TRUE
>> 9     3 TRUE
>> 11    1 TRUE
>> 13    3 TRUE
>> 15    3 TRUE
>> 17    3 TRUE
>> 19    3 TRUE
>> 21    3 TRUE
>> 23    3 TRUE
>> 25    1 TRUE
>> 27    3 TRUE
>> 29    1 TRUE
>>
>> John Kane
>> Kingston ON Canada
>>
>>
>>> -----Original Message-----
>>> From: tmrsg11 at gmail.com
>>> Sent: Sat, 20 Jul 2013 13:11:47 -0400
>>> To: jrkrideau at inbox.com
>>> Subject: Re: [R] How to search for a sequence(and its combination) inside
>>> a vector?
>>>
>>> Thanks John.
>>>
>>> Why do I get length of 5 and 6?  I thought I am only tallying up 1 to 3?
>>>> table(dd)
>>>     val
>>> leng TRUE
>>>    1    5
>>>    2    4
>>>    3   81
>>>    5    1
>>>    6    4
>>>
>>> -M
>>>
>>> On Sat, Jul 20, 2013 at 12:52 PM, John Kane <jrkrideau at inbox.com> wrote:
>>>> Taking Berend's example a bit further, this seems to work
>>>>
>>>> If you use str(b) you will see it is a list
>>>>
>>>> b <- rle(a)
>>>> cc  <-  data.frame(b[[1]], b[[2]])
>>>> names(cc)  <-  c("leng", 'val')
>>>> dd  <-  subset(cc, val ==TRUE )
>>>> table(dd)
>>>>
>>>> John Kane
>>>> Kingston ON Canada
>>>>
>>>>
>>>>> -----Original Message-----
>>>>> From: tmrsg11 at gmail.com
>>>>> Sent: Sat, 20 Jul 2013 12:36:55 -0400
>>>>> To: bhh at xs4all.nl
>>>>> Subject: Re: [R] How to search for a sequence(and its combination)
>>>>> inside
>>>>> a vector?
>>>>>
>>>>> Hi Berend
>>>>> I am looking for a table,
>>>>> # of times one element (out of 1, 2, 3) showed up, two elements, and
>>>>> all
>>>>> three.
>>>>>
>>>>> I am trying, don't know if this works:
>>>>>
>>>>>> aa <- rle(a)
>>>>>> b <- aa$lengths[aa$values]
>>>>>> table(b)
>>>>> b
>>>>>  1  3
>>>>>  3 12
>>>>>
>>>>> Mike
>>>>>
>>>>>
>>>>>
>>>>> On Sat, Jul 20, 2013 at 12:24 PM, Berend Hasselman <bhh at xs4all.nl>
>>>>> wrote:
>>>>>>
>>>>>> On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:
>>>>>>
>>>>>>> Hi R list,
>>>>>>>
>>>>>>> I have a sequence repeating 1:15 .  Some numbers are deleted.  I want
>>>>>>> to find how many times 1, 2, 3 appeared.
>>>>>>> Basically, I want to "grab" the beginning of the sequence and tally
>>>>>>> it
>>>>>>> up.
>>>>>>>
>>>>>>> R code:
>>>>>>>
>>>>>>>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13,
>>>>>>>> 14,
>>>>>>> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
>>>>>>> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
>>>>>>> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
>>>>>>> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
>>>>>>> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
>>>>>>>
>>>>>>>> a <- vec %in% c(1, 2, 3)
>>>>>>>> a
>>>>>>>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
>>>>>>> TRUE  TRUE FALSE FALSE
>>>>>>> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>>>>>>> FALSE FALSE FALSE FALSE
>>>>>>> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>>>>>> FALSE  TRUE  TRUE  TRUE
>>>>>>> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
>>>>>>> TRUE  TRUE  TRUE FALSE
>>>>>>> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
>>>>>>> FALSE FALSE FALSE FALSE
>>>>>>> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>>>> FALSE  TRUE  TRUE  TRUE
>>>>>>> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>>>> FALSE FALSE FALSE FALSE
>>>>>>> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE
>>>>>>> FALSE
>>>>>>> TRUE
>>>>>>>
>>>>>>>> rle(a)
>>>>>>> Run Length Encoding
>>>>>>>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>>>>>>>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
>>>>>>>
>>>>>>> What should I do after this?
>>>>>>>
>>>>>>
>>>>>> Well how about
>>>>>>
>>>>>> sum(a)
>>>>>>
>>>>>> or
>>>>>>
>>>>>> b <- rle(a)
>>>>>> sum(b$lengths[b$values])
>>>>>>
>>>>>> Berend
>>>>>>
>>>>>>> Thanks,
>>>>>>> Mike
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>> ____________________________________________________________
>>>> Receive Notifications of Incoming Messages
>>>> Easily monitor multiple email accounts & access them with a click.
>>>> Visit http://www.inbox.com/notifier and check it out!
>>>>
>>>>
>>
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jrkrideau at inbox.com  Sat Jul 20 20:40:54 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 20 Jul 2013 10:40:54 -0800
Subject: [R] How to search for a sequence(and its combination) inside a
 vector?
In-Reply-To: <CAE2FW2=J0nw9qkxEQJCZrxqhjn7=toxftcCV5Tbz8u0-22LnsQ@mail.gmail.com>
References: <cae2fw2kvguzx-owwsy6fpcejb78ofwaahlzajnxwe6qa+_gpca@mail.gmail.com>
	<34474c3d74b.0000049ajrkrideau@inbox.com>
	<33d90d5eeb1.0000044djrkrideau@inbox.com>
	<cae2fw2m1bgetqeua7yjwec3tw3emj5dmj5mvztowwsqemdxznw@mail.gmail.com>
	<1feab30c-207c-4965-8a3b-ed2120860d26@xs4all.nl>
	<cae2fw2mgj39d7+dtbegcx0ymzfhi1oym3bs_fcu0skfom-8gwa@mail.gmail.com>
Message-ID: <34CBEEF8B97.00000503jrkrideau@inbox.com>

My best guess it that you have something like 1 123123 in there somewhere 

try: 
which(cc[,1]  == 6)
and have a look at line 137 

Essentially your data does not look exactly like what you think it does.
John Kane
Kingston ON Canada


> -----Original Message-----
> From: tmrsg11 at gmail.com
> Sent: Sat, 20 Jul 2013 13:50:10 -0400
> To: jrkrideau at inbox.com, bhh at xs4all.nl
> Subject: Re: [R] How to search for a sequence(and its combination) inside
> a vector?
> 
> Thanks, you guys are correct, I had different data.
> But why I get length 5 and 6, should only be 1 to 3.
> 
> Full R code :
> 
> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13, 14,
> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1, 2, 3,
> 4, 5, 6, 8, 9, 10, 11, 12, 14, 1, 2, 3, 4, 9, 13, 15, 1, 2, 3,
> 4, 6, 8, 9, 11, 12, 1, 2, 3, 7, 8, 9, 14, 1, 2, 3, 12, 1, 2,
> 3, 4, 5, 10, 14, 1, 2, 3, 4, 5, 7, 8, 12, 13, 14, 1, 2, 3, 10,
> 1, 3, 1, 2, 3, 5, 7, 8, 10, 11, 13, 14, 1, 2, 3, 4, 5, 8, 9,
> 11, 12, 15, 1, 2, 3, 4, 7, 9, 10, 13, 1, 2, 3, 4, 5, 7, 10, 11,
> 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 13, 15, 1, 2, 3, 6, 7,
> 8, 9, 10, 12, 13, 14, 15, 1, 2, 3, 4, 7, 1, 2, 3, 5, 8, 13, 1,
> 2, 3, 5, 8, 11, 15, 1, 2, 3, 1, 2, 3, 10, 1, 2, 3, 4, 7, 8, 9,
> 10, 11, 12, 14, 1, 3, 9, 11, 13, 14, 1, 2, 3, 4, 5, 7, 8, 9,
> 10, 11, 12, 13, 14, 15, 1, 2, 3, 4, 5, 13, 14, 15, 1, 2, 3, 11,
> 13, 14, 1, 2, 3, 8, 1, 2, 3, 4, 5, 6, 8, 11, 12, 14, 1, 2, 3,
> 5, 6, 9, 10, 11, 12, 15, 1, 2, 3, 4, 5, 9, 11, 12, 13, 1, 2,
> 3, 4, 5, 13, 1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 14, 15,
> 1, 2, 3, 7, 8, 9, 1, 2, 3, 5, 7, 8, 9, 10, 12, 14, 15, 1, 2,
> 3, 4, 5, 6, 8, 14, 1, 2, 3, 1, 2, 3, 10, 11, 13, 1, 2, 3, 4,
> 9, 10, 12, 13, 14, 1, 2, 3, 4, 5, 6, 12, 1, 2, 3, 4, 5, 6, 7,
> 10, 12, 13, 14, 15, 1, 2, 3, 6, 10, 14, 1, 2, 3, 4, 6, 7, 8,
> 9, 10, 11, 13, 14, 1, 2, 3, 1, 2, 3, 4, 7, 8, 10, 1, 2, 3, 7,
> 8, 11, 13, 15, 1, 2, 3, 4, 7, 8, 14, 15, 1, 2, 3, 4, 14, 1, 2,
> 3, 4, 6, 7, 10, 12, 1, 2, 3, 5, 7, 8, 11, 13, 14, 15, 1, 2, 3,
> 4, 1, 2, 3, 6, 7, 9, 11, 12, 13, 14, 1, 2, 3, 7, 11, 12, 1, 2,
> 3, 5, 6, 8, 9, 10, 12, 15, 1, 2, 3, 5, 6, 8, 9, 11, 1, 2, 3,
> 7, 8, 11, 13, 14, 15, 1, 2, 3, 4, 10, 12, 14, 1, 2, 3, 11, 12,
> 13, 15, 1, 2, 3, 5, 7, 10, 11, 12, 13, 14, 15, 1, 3, 10, 1, 2,
> 3, 1, 2, 3, 8, 10, 15, 1, 2, 3, 4, 7, 10, 12, 14, 1, 2, 3, 9,
> 10, 11, 1, 2, 3, 6, 9, 10, 15, 1, 9, 14, 1, 2, 3, 7, 10, 14,
> 1, 2, 3, 4, 7, 8, 9, 10, 11, 13, 15, 1, 2, 3, 5, 6, 7, 8, 9,
> 11, 12, 13, 14, 15, 1, 2, 3, 6, 8, 11, 12, 1, 7, 1, 2, 3, 8,
> 13, 15, 1, 2, 3, 4, 8, 9, 11, 1, 2, 3, 4, 7, 13, 14, 1, 2, 3,
> 5, 6, 9, 1, 3, 7, 12, 13, 15, 1, 2, 3, 5, 6, 8, 10, 1, 3, 5,
> 7, 8, 10, 11, 1, 2, 3, 5, 6, 11, 14, 1, 2, 3, 4, 9, 10, 11, 13,
> 14, 1, 2, 3, 4, 6, 9, 14, 15, 1, 2, 3, 11, 1, 2, 3, 4, 5, 7,
> 11, 13, 14, 15, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 14, 1, 2, 3, 4,
> 5, 6, 7, 9, 10, 11, 12, 14, 1, 4, 7, 1, 2, 3, 5, 6, 8, 9, 10,
> 12, 13, 15, 1, 2, 3, 4, 5, 8, 10, 12, 13)
> a <- vec %in% c(1, 2, 3)
> b <- rle(a)
> cc  <-  data.frame(b[[1]], b[[2]])
> names(cc)  <-  c("leng", 'val')
> dd  <-  subset(cc, val ==TRUE )
> table(dd)
> 
>> table(dd)
>     val
> leng TRUE
>    1    5
>    2    4
>    3   81
>    5    1
>    6    4
> 
> btw,
>> length(vec)
> [1] 762
> 
> So, the tally should add up to that if correct.
> 
> -M
> 
> 
> On Sat, Jul 20, 2013 at 1:41 PM, John Kane <jrkrideau at inbox.com> wrote:
>> Beats me. I get:
>> table(dd)
>>     val
>> leng TRUE
>>    1    3
>>    3   12
>> 
>> What does dd look like.  In my case I get this where the first column is
>> the row number
>> dd
>>    leng  val
>> 1     3 TRUE
>> 3     3 TRUE
>> 5     3 TRUE
>> 7     3 TRUE
>> 9     3 TRUE
>> 11    1 TRUE
>> 13    3 TRUE
>> 15    3 TRUE
>> 17    3 TRUE
>> 19    3 TRUE
>> 21    3 TRUE
>> 23    3 TRUE
>> 25    1 TRUE
>> 27    3 TRUE
>> 29    1 TRUE
>> 
>> John Kane
>> Kingston ON Canada
>> 
>> 
>>> -----Original Message-----
>>> From: tmrsg11 at gmail.com
>>> Sent: Sat, 20 Jul 2013 13:11:47 -0400
>>> To: jrkrideau at inbox.com
>>> Subject: Re: [R] How to search for a sequence(and its combination)
>>> inside
>>> a vector?
>>> 
>>> Thanks John.
>>> 
>>> Why do I get length of 5 and 6?  I thought I am only tallying up 1 to
>>> 3?
>>>> table(dd)
>>>     val
>>> leng TRUE
>>>    1    5
>>>    2    4
>>>    3   81
>>>    5    1
>>>    6    4
>>> 
>>> -M
>>> 
>>> On Sat, Jul 20, 2013 at 12:52 PM, John Kane <jrkrideau at inbox.com>
>>> wrote:
>>>> Taking Berend's example a bit further, this seems to work
>>>> 
>>>> If you use str(b) you will see it is a list
>>>> 
>>>> b <- rle(a)
>>>> cc  <-  data.frame(b[[1]], b[[2]])
>>>> names(cc)  <-  c("leng", 'val')
>>>> dd  <-  subset(cc, val ==TRUE )
>>>> table(dd)
>>>> 
>>>> John Kane
>>>> Kingston ON Canada
>>>> 
>>>> 
>>>>> -----Original Message-----
>>>>> From: tmrsg11 at gmail.com
>>>>> Sent: Sat, 20 Jul 2013 12:36:55 -0400
>>>>> To: bhh at xs4all.nl
>>>>> Subject: Re: [R] How to search for a sequence(and its combination)
>>>>> inside
>>>>> a vector?
>>>>> 
>>>>> Hi Berend
>>>>> I am looking for a table,
>>>>> # of times one element (out of 1, 2, 3) showed up, two elements, and
>>>>> all
>>>>> three.
>>>>> 
>>>>> I am trying, don't know if this works:
>>>>> 
>>>>>> aa <- rle(a)
>>>>>> b <- aa$lengths[aa$values]
>>>>>> table(b)
>>>>> b
>>>>>  1  3
>>>>>  3 12
>>>>> 
>>>>> Mike
>>>>> 
>>>>> 
>>>>> 
>>>>> On Sat, Jul 20, 2013 at 12:24 PM, Berend Hasselman <bhh at xs4all.nl>
>>>>> wrote:
>>>>>> 
>>>>>> On 20-07-2013, at 18:05, C W <tmrsg11 at gmail.com> wrote:
>>>>>> 
>>>>>>> Hi R list,
>>>>>>> 
>>>>>>> I have a sequence repeating 1:15 .  Some numbers are deleted.  I
>>>>>>> want
>>>>>>> to find how many times 1, 2, 3 appeared.
>>>>>>> Basically, I want to "grab" the beginning of the sequence and tally
>>>>>>> it
>>>>>>> up.
>>>>>>> 
>>>>>>> R code:
>>>>>>> 
>>>>>>>> vec <- c(1, 2, 3, 4, 5, 6, 7, 8, 13, 1, 2, 3, 5, 7, 8, 10, 12, 13,
>>>>>>>> 14,
>>>>>>> 15, 1, 2, 3, 5, 6, 10, 12, 13, 1, 2, 3, 4, 5, 6, 7, 12, 13, 14,
>>>>>>> 15, 1, 2, 3, 6, 9, 10, 11, 13, 14, 1, 7, 10, 13, 1, 2, 3, 4,
>>>>>>> 6, 7, 9, 11, 14, 1, 2, 3, 5, 9, 10, 11, 12, 14, 1, 2, 3, 4, 1,
>>>>>>> 2, 3, 4, 11, 12, 14, 1, 2, 3, 4, 8, 11, 12, 1, 2, 3, 4, 5, 7,
>>>>>>> 8, 9, 11, 12, 15, 3, 14, 1, 2, 3, 6, 10, 11, 13, 14, 1)
>>>>>>> 
>>>>>>>> a <- vec %in% c(1, 2, 3)
>>>>>>>> a
>>>>>>>  [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE  TRUE
>>>>>>> TRUE  TRUE FALSE FALSE
>>>>>>> [15] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE
>>>>>>> FALSE FALSE FALSE FALSE
>>>>>>> [29]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE
>>>>>>> FALSE  TRUE  TRUE  TRUE
>>>>>>> [43] FALSE FALSE FALSE FALSE FALSE FALSE  TRUE FALSE FALSE FALSE
>>>>>>> TRUE  TRUE  TRUE FALSE
>>>>>>> [57] FALSE FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE
>>>>>>> FALSE FALSE FALSE FALSE
>>>>>>> [71]  TRUE  TRUE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>>>> FALSE  TRUE  TRUE  TRUE
>>>>>>> [85] FALSE FALSE FALSE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE
>>>>>>> FALSE FALSE FALSE FALSE
>>>>>>> [99] FALSE  TRUE FALSE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE
>>>>>>> FALSE
>>>>>>> TRUE
>>>>>>> 
>>>>>>>> rle(a)
>>>>>>> Run Length Encoding
>>>>>>>  lengths: int [1:29] 3 6 3 8 3 5 3 8 3 6 ...
>>>>>>>  values : logi [1:29] TRUE FALSE TRUE FALSE TRUE FALSE ...
>>>>>>> 
>>>>>>> What should I do after this?
>>>>>>> 
>>>>>> 
>>>>>> Well how about
>>>>>> 
>>>>>> sum(a)
>>>>>> 
>>>>>> or
>>>>>> 
>>>>>> b <- rle(a)
>>>>>> sum(b$lengths[b$values])
>>>>>> 
>>>>>> Berend
>>>>>> 
>>>>>>> Thanks,
>>>>>>> Mike
>>>>>>> 
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>> 
>>>> ____________________________________________________________
>>>> Receive Notifications of Incoming Messages
>>>> Easily monitor multiple email accounts & access them with a click.
>>>> Visit http://www.inbox.com/notifier and check it out!
>>>> 
>>>> 
>> 
>> ____________________________________________________________
>> FREE ONLINE PHOTOSHARING - Share your photos online with your friends
>> and family!
>> Visit http://www.inbox.com/photosharing to find out more!
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From wetbelldiver at gmail.com  Sat Jul 20 21:42:31 2013
From: wetbelldiver at gmail.com (Wet Bell Diver)
Date: Sat, 20 Jul 2013 21:42:31 +0200
Subject: [R] how to download Journal Citation Reports with R
Message-ID: <51EAE827.7030801@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/f027d266/attachment.pl>

From 538280 at gmail.com  Sat Jul 20 22:18:49 2013
From: 538280 at gmail.com (Greg Snow)
Date: Sat, 20 Jul 2013 14:18:49 -0600
Subject: [R] Identify Leverage Points
In-Reply-To: <413AC584-2ECE-4478-8DCB-3A8F6C528989@ucla.edu>
References: <413AC584-2ECE-4478-8DCB-3A8F6C528989@ucla.edu>
Message-ID: <CAFEqCdzkDhm1C4Uf=TE7gLNP3XRMqy7NhCEfFeLZtNZOCm8cMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/fd7dddcd/attachment.pl>

From gb at stat.umu.se  Sun Jul 21 00:26:37 2013
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sun, 21 Jul 2013 00:26:37 +0200
Subject: [R] Windows 7 (Swedish): 'Rcmd INSTALL' fails
Message-ID: <51EB0E9D.30609@stat.umu.se>

I am trying to build a Windows zip file of a private package by

C:/Program/R/R-3.0.1/bin/x64/Rcmd INSTALL --build --library=. 
epigen_0.1.tar.gz

but I get errors like

1: package 'datasets' in options("defaultPackages") was not found

and, finally,

Error in normalsizePath(path.expand(path), winslash, mustWork) :
path[1]="C:/Program/R/R-3.0.1/library/tools": Atkomst nekad
(Access denied)

This is on a Swedish version of Windows 7. I noticed that the R 
installer called the installation directory "Program Files" instead of 
"Program" (despite my effort to change it), so I tried the same thing 
with an English version of Windows 7 (on another machine), and there 
everything went as expected.

I installed R on both machines today so the setups should be identical, 
except for the languages. What can be wrong? Can it be a language/path 
thing?

Thanks for any insight!

G?ran Brostr?m


From ligges at statistik.tu-dortmund.de  Sun Jul 21 00:51:00 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 21 Jul 2013 00:51:00 +0200
Subject: [R] Windows 7 (Swedish): 'Rcmd INSTALL' fails
In-Reply-To: <51EB0E9D.30609@stat.umu.se>
References: <51EB0E9D.30609@stat.umu.se>
Message-ID: <51EB1454.5090205@statistik.tu-dortmund.de>



On 21.07.2013 00:26, G?ran Brostr?m wrote:
> I am trying to build a Windows zip file of a private package by
>
> C:/Program/R/R-3.0.1/bin/x64/Rcmd INSTALL --build --library=.
> epigen_0.1.tar.gz

Why --library=. ?
Do you have appropriate poermissions to do that? In this case, you need 
to start everything with admin priviliges explicitly unless your Windows 
is configured differently.


>
> but I get errors like
>
> 1: package 'datasets' in options("defaultPackages") was not found
>
> and, finally,
>
> Error in normalsizePath(path.expand(path), winslash, mustWork) :
> path[1]="C:/Program/R/R-3.0.1/library/tools": Atkomst nekad
> (Access denied)
>
> This is on a Swedish version of Windows 7. I noticed that the R
> installer called the installation directory "Program Files" instead of
> "Program" (despite my effort to change it), so I tried the same thing

But there is "Program Files", "Program" is just something like a link 
shown by the Windows Explorer that actually points to "Program Files".



> with an English version of Windows 7 (on another machine), and there
> everything went as expected.
>
> I installed R on both machines today so the setups should be identical,
> except for the languages. What can be wrong? Can it be a language/path
> thing?

Probably not the language but different admin settings.

Best,
Uwe Ligges

>
> Thanks for any insight!
>
> G?ran Brostr?m
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bbolker at gmail.com  Sun Jul 21 00:58:22 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 20 Jul 2013 22:58:22 +0000
Subject: [R] how to download Journal Citation Reports with R
References: <51EAE827.7030801@gmail.com>
Message-ID: <loom.20130721T005629-77@post.gmane.org>

Wet Bell Diver <wetbelldiver <at> gmail.com> writes:

> 
> R-3.0.1, Rstudio, Win7 x64
> 
> Dear list,
> 
> I would like to download all the webpages of the Journal Citations 
> Report (science edition), for a given year. I can do so manually, but 
> that it very time intensive, so I would like to use R for that.
> 
> I have tried many things, including:
> download.file(url = 
> "http://admin-apps.webofknowledge.com/JCR/JCR?RQ=SELECT_ALL&cursor=21", 
> destfile = "test.htm", method = "internal")
> which would get the page starting with journal number 21.
> However, test.htm only includes the message:
> 
>  >>>

  You need to review the RCurl package and look for "cookies", which
will allow you (once you have established a session in a browser) to
copy the cookies (tokens which allow you access) into your R session.
However, you will probably be violating the terms of service of JCR.
You should talk to your librarian about this.  When I wanted to do
a similar project I worked out a system where I generated the URLs 
automatically and got a student assistant to (efficiently) go to the
URLs and paste the results into output files.

  Ben Bolker


From ligges at statistik.tu-dortmund.de  Sun Jul 21 01:38:46 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 21 Jul 2013 01:38:46 +0200
Subject: [R] Error from running R2WinBUGS in R
In-Reply-To: <CALv--dY4fbRH-ngsCcbCSUEwzyj4ZKkKJVxY0oHJ=8dYQOZk4w@mail.gmail.com>
References: <CALv--dY4fbRH-ngsCcbCSUEwzyj4ZKkKJVxY0oHJ=8dYQOZk4w@mail.gmail.com>
Message-ID: <51EB1F86.5080608@statistik.tu-dortmund.de>

Several problems:

1. You havbe an object called "matrix", that actually is a list of two 
data.frames. WinBUGS does not know about data,frames. You have to 
provide a matrix here, hence

bugs(....., data=list(Y=as.matrix(Y), Nf=5, ....), ....)


2. In your model file, you have

gamma[1:2 ]
T[1:2 ,1:2 ])
n
an others, all of which need to be passed to WinBUGS as data. I do not 
see a dingle of these objects to be defined anywhere.

3. Then you have

   parameters.to.save = c("p","rho","sigma2")
but these are not mentioned in the model file,

So this is rather hopeless. My suggestion is to seek advice from a local 
BUGS expert or from the BUGS mailing list.

You should start to develop your model in BUSG directly, since the R 
interface is nice for automation, but not for model building, since you 
do not see the error messages as directly as in WinBUGS/OpenBUGS yourself.


Best,
uwe ligges





On 16.07.2013 17:52, Anamika Chaudhuri wrote:
> Hi All:
> I am getting an error (highlighted) from running R2WinBUGS in R.
> To be able to replicate the situation heres the code:
> .#Set working directory
> setwd("H://AChaudhuri/Testing/CSVS")
> matrix=NULL
> csvs <- paste("MVN", 1:2, ".csv", sep="")
> for(i in 1:length(csvs)){
>    matrix[[i]] <- read.csv(file=csvs[i], header=T)
>    print(matrix[[i]])
> }
>
> So now I have read in 2 simulated datasets which  look like
>   Y1 Y2
> 1 11  6
> 2  8  5
> 3 25 13
> 4  1 13
> 5  8 22
>    Y1 Y2
> 1  9  1
> 2  7  9
> 3 25 13
> 4  1 18
> 5  9 12
>
> My next step is to run a multivariate logit normal model on these datasets
> and automate this process for such simulated datasets. Heres the model
> statement:
> model
>   {
>    for (j in 1 : Nf)
>
>        {
>        p1[j, 1:2 ] ~ dmnorm(gamma[1:2 ], T[1:2 ,1:2 ])
>
>        for (i in 1:2)
>        {
>       logit(p[j,i])<-p1[j,i]
>
>       Y[j,i] ~ dbin(p[j,i],n)
> }}
>
> I am trying to use the following code to run it in R
> library("R2WinBUGS")
> bugs.output <- list()
> for(i in 1:2){
>
>         Y <-(matrix[i])
>
>         bugs.output[[i]] <- bugs(
>         data=list(Y=Y, Nf=5), # change for no of sites
>      inits=NULL,
>         model.file="M-LN_model_trial.txt",
>         parameters.to.save = c("p","rho","sigma2"),
> n.chains=1, n.iter=12000, n.burnin=5000,
> bugs.directory="H://AChaudhuri/winbugs14/WinBUGS14",
> working.directory=NULL)}
>
>
> Error in FUN(X[[1L]], ...) :
>
>    .C(..): 'type' must be "real" for this format
>
> Any suggestion would be helpful.
> Thanks!
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From felix at nfrac.org  Sun Jul 21 01:45:42 2013
From: felix at nfrac.org (Felix Andrews)
Date: Sun, 21 Jul 2013 09:45:42 +1000
Subject: [R] Different x-axis scales using c() in latticeExtra
In-Reply-To: <0FFC0330-DBFC-4E77-B296-AC87B8B0B2D8@comcast.net>
References: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>
	<0FFC0330-DBFC-4E77-B296-AC87B8B0B2D8@comcast.net>
Message-ID: <CAKZAQ7x-QxcogJPTAjRxz0PFY96Nvwkwqyy1Lvk-Bs1kfFeGYw@mail.gmail.com>

latticeExtra's c() can not combine logarithmic with linear x scales,
I'm afraid.  I would recommend displaying each separate plot on one
page using plot.trellis() or the gridExtra function that John Kane
mentioned.

Cheers
Felix


On 21 July 2013 02:50, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jul 19, 2013, at 8:18 PM, Jeff Stevens wrote:
>
>> Hi,
>>
>> I would like to combine multiple xyplots into a single, multipanel
>> display.  Using R 3.0.1 in Ubuntu, I have used c() from latticeExtra
>> to combine three plots, but the x-axis for two plots are on a log
>> scale and the other is on a normal scale.  I also have included
>> equispace.log=FALSE to clean up the tick labels.  However, when I try
>> all of these, the x-axis scale of the first panel is used for all
>> three.  How do I keep different scales for the different panels?
>>
>> Here is an example:
>> library(lattice)
>> library(latticeExtra)
>> response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
>> predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
>> predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
>> predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)
>>
>> pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
>> equispaced.log = FALSE),
>>  panel = function(x, y, ...) {
>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>    panel.text(x = log10(8), y = log10(120), labels = "(a)")
>>  }
>> )
>>
>> pred2_plot <- xyplot(response ~ predictor2, scales = list(log = TRUE,
>> equispaced.log = FALSE),
>>  panel = function(x, y, ...) {
>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>    panel.text(x = log10(2), y = log10(120), labels = "(b)")
>>  }
>> )
>>
>> pred3_plot <- xyplot(response ~ predictor3, scales = list(y = list(log
>> = TRUE, equispaced.log = FALSE)),
>>  panel = function(x, y, ...) {
>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>    panel.text(x = 22, y = log10(120), labels = "(c)")
>>  }
>> )
>>
>> all_plots <- c(pred1_plot, pred2_plot, pred3_plot, layout = c(3, 1), x.same = F)
>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>> scales = list(y=list(log=T, equispaced.log=FALSE), x = c(list(log=T,
>> equispaced.log=FALSE), list(log=T, equispaced.log=FALSE),
>> list(log=F))))
>>
>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>> scales = c(list(log = TRUE, equispaced.log = FALSE), list(log = TRUE,
>> equispaced.log = FALSE), list(y=list(log=T, equispaced.log = FALSE))))
>>
>> Any help is appreciated!
>
> I assume there was a notice o your console that there were warnings, right? You should offer the full texts of warnings and error messages. Here the full text of the first and second warnings:
>
>> warnings()[1:2]
> $`log scales cannot be changed via 'update'`
> update.trellis(all_plots, xlab = c("Predictor 1", "Predictor 2",
>     "Predictor 3"), scales = c(list(log = TRUE, equispaced.log = FALSE),
>     list(log = TRUE, equispaced.log = FALSE), list(y = list(log = T,
>         equispaced.log = FALSE))))
> $`'x' is NULL so the result will be NULL`
> rep(scales[[nm]], length.out = 2)
>
> The first one is telling you why the results should be different than you expect. I'm not entirely sure what the second one is telling you, but it doesn't sound good.
>
> --
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 
Felix Andrews / ???
http://www.neurofractal.org/felix/


From iza.ch1 at op.pl  Sun Jul 21 01:55:10 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Sun, 21 Jul 2013 01:55:10 +0200
Subject: [R] Linear regression repeat for each column
Message-ID: <117163464-7069bedf09e8acffd232b6e3f56b2867@pkn5.m5r2.onet>

Hi everyone

I need to calculate abnormal returns for different events applying event study methodology. I must create a market model in order to perform the analysis. I apply regression analysis to get OLS estimators.

I have a problem to create a linear regression which I could repeat for each column in two different data frames (one with explainatory and one with explaning variables). It means that I want to regress column 1 from first data frame with column 1 from second data frame,, clumn two with column two etc. I tried to use the following code:#x  is matrix containing stock returns
y is matrix containing market index                           
i<-1:length(x)
t[i] <- lapply(t[i], lm(x[,1]~y[,i]))

but it is not working.

Could anybody help me?

Thanks a lot

Iza


From Scott.Robinson at glasgow.ac.uk  Sat Jul 20 19:37:31 2013
From: Scott.Robinson at glasgow.ac.uk (Scott Robinson)
Date: Sat, 20 Jul 2013 18:37:31 +0100
Subject: [R] BH correction with p.adjust
Message-ID: <2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BED@CMS03.campus.gla.ac.uk>

Dear List,

I have been trying to use p.adjust() to do BH multiple test correction and have gotten some unexpected results. I thought that the equation for this was:

pBH = p*n/i

where p is the original p value, n is the number of tests and i is the rank of the p value. However when I try and recreate the corrected p from my most significant value it does not match up to the one computed by the method p.adjust:

> setwd("C:/work/Methylation/IMA/GM/siteLists")
> 
> hypTable <- read.delim("hypernormal vs others.txt")
> pList <- hypTable$p
> names(pList) <- hypTable$site
> 
> adjusted <- p.adjust(pList, method="BH")
> adjusted[1]
cg27433479 
0.05030589 
> 
> pList[1]*nrow(hypTable)/1
cg27433479 
0.09269194 

I tried to recreate this is a small example of a vector of 5 p values but everything worked as expected there. I was wondering if there is some subtle difference about how p.adjust operates? Is there something more complicated about how to calculate 'n' or 'i' - perhaps due to identical p values being assigned the same rank or something? Does anyone have an idea what might be going on here?

Many thanks,

Scott

From cxg040 at email.uark.edu  Sun Jul 21 00:56:42 2013
From: cxg040 at email.uark.edu (Chirag Gupta)
Date: Sat, 20 Jul 2013 17:56:42 -0500
Subject: [R] Extract specific rows from a data frame
Message-ID: <CADESCNyWaqQEQL3SMu0A5TTO421mdm1vWreyQJMv4JDNw_EL-Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130720/e4a96b1d/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Sun Jul 21 02:30:32 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sat, 20 Jul 2013 17:30:32 -0700
Subject: [R] Linear regression repeat for each column
In-Reply-To: <117163464-7069bedf09e8acffd232b6e3f56b2867@pkn5.m5r2.onet>
References: <117163464-7069bedf09e8acffd232b6e3f56b2867@pkn5.m5r2.onet>
Message-ID: <911df85a-9635-437a-8d7e-8dc68e5c4b59@email.android.com>

Sure. Read the Posting Guide, and provide a reproducible example with sample data.

I suspect the basic idea will be to merge the data frames and then setup the model to refer to the desired columns.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"iza.ch1" <iza.ch1 at op.pl> wrote:
>Hi everyone
>
>I need to calculate abnormal returns for different events applying
>event study methodology. I must create a market model in order to
>perform the analysis. I apply regression analysis to get OLS
>estimators.
>
>I have a problem to create a linear regression which I could repeat for
>each column in two different data frames (one with explainatory and one
>with explaning variables). It means that I want to regress column 1
>from first data frame with column 1 from second data frame,, clumn two
>with column two etc. I tried to use the following code:#x  is matrix
>containing stock returns
>y is matrix containing market index                           
>i<-1:length(x)
>t[i] <- lapply(t[i], lm(x[,1]~y[,i]))
>
>but it is not working.
>
>Could anybody help me?
>
>Thanks a lot
>
>Iza
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Sun Jul 21 03:18:57 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 20 Jul 2013 18:18:57 -0700 (PDT)
Subject: [R] Extract specific rows from a data frame
In-Reply-To: <CADESCNyWaqQEQL3SMu0A5TTO421mdm1vWreyQJMv4JDNw_EL-Q@mail.gmail.com>
References: <CADESCNyWaqQEQL3SMu0A5TTO421mdm1vWreyQJMv4JDNw_EL-Q@mail.gmail.com>
Message-ID: <1374369537.85178.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
May be this helps:
df1<- read.table(text="
? t1 t2 t3 t4
? len1 AA AA PP AP
? len2 FALSE AA PP MM
? len3 PP AA AA AP
? len4 PP AM MP PP
? len5 AA FALSE AP PP
? len6 PP AA AA AA
",sep="",header=TRUE,stringsAsFactors=FALSE)

df1[df1[,1]=="PP" & (rowSums(df1[,-1]!="PP")==(ncol(df1)-1)),]
#???? t1 t2 t3 t4
#len3 PP AA AA AP
#len6 PP AA AA AA
A.K.



----- Original Message -----
From: Chirag Gupta <cxg040 at email.uark.edu>
To: r-help at r-project.org
Cc: 
Sent: Saturday, July 20, 2013 6:56 PM
Subject: [R] Extract specific rows from a data frame

Hi

I have a data frame as below



? t1 t1 t3 t4? len1 AA AA PP AP? len2 FALSE AA PP MM? len3 PP AA AA AP? len4
PP AM MP PP? len5 AA FALSE AP PP? len6 PP AA AA AA
I am having trouble extracting only those rows which have "PP" in the first
column but AA or FALSE or all any other value but not PP in rest of the
columns.


-- 
*Chirag Gupta*

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sun Jul 21 03:30:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 20 Jul 2013 18:30:07 -0700 (PDT)
Subject: [R] Linear regression repeat for each column
In-Reply-To: <117163464-7069bedf09e8acffd232b6e3f56b2867@pkn5.m5r2.onet>
References: <117163464-7069bedf09e8acffd232b6e3f56b2867@pkn5.m5r2.onet>
Message-ID: <1374370207.88549.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
set.seed(28)
dat1<- as.data.frame(matrix(sample(1:20,100,replace=TRUE),ncol=10))
set.seed(49)
dat2<- as.data.frame(matrix(sample(40:80,100,replace=TRUE),ncol=10))
?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i])})
A.K.

----- Original Message -----
From: iza.ch1 <iza.ch1 at op.pl>
To: r-help at r-project.org
Cc: 
Sent: Saturday, July 20, 2013 7:55 PM
Subject: [R] Linear regression repeat for each column

Hi everyone

I need to calculate abnormal returns for different events applying event study methodology. I must create a market model in order to perform the analysis. I apply regression analysis to get OLS estimators.

I have a problem to create a linear regression which I could repeat for each column in two different data frames (one with explainatory and one with explaning variables). It means that I want to regress column 1 from first data frame with column 1 from second data frame,, clumn two with column two etc. I tried to use the following code:#x? is matrix containing stock returns
y is matrix containing market index? ? ? ? ? ? ? ? ? ? ? ? ? 
i<-1:length(x)
t[i] <- lapply(t[i], lm(x[,1]~y[,i]))

but it is not working.

Could anybody help me?

Thanks a lot

Iza

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwinsemius at comcast.net  Sun Jul 21 04:33:27 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sat, 20 Jul 2013 19:33:27 -0700
Subject: [R] BH correction with p.adjust
In-Reply-To: <2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BED@CMS03.campus.gla.ac.uk>
References: <2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BED@CMS03.campus.gla.ac.uk>
Message-ID: <E6217802-3118-4831-B877-2BF4AD211217@comcast.net>


On Jul 20, 2013, at 10:37 AM, Scott Robinson wrote:

> Dear List,
> 
> I have been trying to use p.adjust() to do BH multiple test correction and have gotten some unexpected results. I thought that the equation for this was:
> 
> pBH = p*n/i

Looking at the code for `p.adjust`, you see that the method is picked from a switch function

lp <- length(p)
BH = {
        i <- lp:1L
        o <- order(p, decreasing = TRUE)
        ro <- order(o)
        pmin(1, cummin(n/i * p[o]))[ro]
    }

You may not have sorted the p-values in pList.


> 
> where p is the original p value, n is the number of tests and i is the rank of the p value. However when I try and recreate the corrected p from my most significant value it does not match up to the one computed by the method p.adjust:
> 
>> setwd("C:/work/Methylation/IMA/GM/siteLists")
>> 
>> hypTable <- read.delim("hypernormal vs others.txt")
>> pList <- hypTable$p
>> names(pList) <- hypTable$site
>> 
>> adjusted <- p.adjust(pList, method="BH")
>> adjusted[1]
> cg27433479 
> 0.05030589 
>> 
>> pList[1]*nrow(hypTable)/1
> cg27433479 
> 0.09269194 
> 

No data provided, so unable to pursue this further.

> I tried to recreate this is a small example of a vector of 5 p values but everything worked as expected there. I was wondering if there is some subtle difference about how p.adjust operates? Is there something more complicated about how to calculate 'n' or 'i' - perhaps due to identical p values being assigned the same rank or something? Does anyone have an idea what might be going on here?


-- 

David Winsemius
Alameda, CA, USA


From shanxiao at umail.iu.edu  Sun Jul 21 06:51:10 2013
From: shanxiao at umail.iu.edu (shanxiao)
Date: Sun, 21 Jul 2013 00:51:10 -0400
Subject: [R] plot discrete time series against time
Message-ID: <000001ce85cd$ec79acb0$c56d0610$@iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130721/5a5b3d0f/attachment.pl>

From bhh at xs4all.nl  Sun Jul 21 09:07:31 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 21 Jul 2013 09:07:31 +0200
Subject: [R] plot discrete time series against time
In-Reply-To: <000001ce85cd$ec79acb0$c56d0610$@iu.edu>
References: <000001ce85cd$ec79acb0$c56d0610$@iu.edu>
Message-ID: <BC8D4009-3103-4DD4-B8C3-C82BFD54AFCA@xs4all.nl>


On 21-07-2013, at 06:51, shanxiao <shanxiao at umail.iu.edu> wrote:

> Dear all, 
> 
> 
> 
> I try to plot some discrete time series data through time, of course I can
> achieve it by using the combination of some basic R functions, but it is not
> that convenient, does anyone know any R-inbuilt function to do it? Best. 
> 


Look at the examples of ts()

?ts

Berend

From gb at stat.umu.se  Sun Jul 21 10:50:33 2013
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sun, 21 Jul 2013 10:50:33 +0200
Subject: [R] Windows 7 (Swedish): 'Rcmd INSTALL' fails (SOLVED)
In-Reply-To: <51EB1454.5090205@statistik.tu-dortmund.de>
References: <51EB0E9D.30609@stat.umu.se>
	<51EB1454.5090205@statistik.tu-dortmund.de>
Message-ID: <51EBA0D9.2080209@stat.umu.se>

Uwe, thanks!

The switch from "Program" to "Program Files" made it (stupid Windows!).

I tried the "--library=." flag because I got the error message

path[2]="C:/Program/R/R-3.0.1/library": Access denied

without it, and naively thought that I had a permission problem.
This was strange, because I am the administrator of my Windows machines.

BTW, why can't I, as an administrator, install packages in

"C:\Program Files\R\R-3.0.1\library" ?

This is of course a very minor problem, since I never do anything useful 
on Windows machines.

Best,

G?ran Brostr?m

Uwe Ligges skrev 2013-07-21 00:51:
>
>
> On 21.07.2013 00:26, G?ran Brostr?m wrote:
>> I am trying to build a Windows zip file of a private package by
>>
>> C:/Program/R/R-3.0.1/bin/x64/Rcmd INSTALL --build --library=.
>> epigen_0.1.tar.gz
>
> Why --library=. ?
> Do you have appropriate poermissions to do that? In this case, you need
> to start everything with admin priviliges explicitly unless your Windows
> is configured differently.
>
>
>>
>> but I get errors like
>>
>> 1: package 'datasets' in options("defaultPackages") was not found
>>
>> and, finally,
>>
>> Error in normalsizePath(path.expand(path), winslash, mustWork) :
>> path[1]="C:/Program/R/R-3.0.1/library/tools": Atkomst nekad
>> (Access denied)
>>
>> This is on a Swedish version of Windows 7. I noticed that the R
>> installer called the installation directory "Program Files" instead of
>> "Program" (despite my effort to change it), so I tried the same thing
>
> But there is "Program Files", "Program" is just something like a link
> shown by the Windows Explorer that actually points to "Program Files".
>
>
>
>> with an English version of Windows 7 (on another machine), and there
>> everything went as expected.
>>
>> I installed R on both machines today so the setups should be identical,
>> except for the languages. What can be wrong? Can it be a language/path
>> thing?
>
> Probably not the language but different admin settings.
>
> Best,
> Uwe Ligges
>
>>
>> Thanks for any insight!
>>
>> G?ran Brostr?m
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From rolf.turner at xtra.co.nz  Sun Jul 21 11:16:54 2013
From: rolf.turner at xtra.co.nz (Rolf Turner)
Date: Sun, 21 Jul 2013 21:16:54 +1200
Subject: [R] Windows 7 (Swedish): 'Rcmd INSTALL' fails (SOLVED)
In-Reply-To: <51EBA0D9.2080209@stat.umu.se>
References: <51EB0E9D.30609@stat.umu.se>
	<51EB1454.5090205@statistik.tu-dortmund.de>
	<51EBA0D9.2080209@stat.umu.se>
Message-ID: <51EBA706.8010708@xtra.co.nz>

On 21/07/13 20:50, G?ran Brostr?m wrote:

> Uwe, thanks!
>
> The switch from "Program" to "Program Files" made it (stupid Windows!).
>
     <SNIP>
> BTW, why can't I, as an administrator, install packages in
>
> "C:\Program Files\R\R-3.0.1\library" ?
>
> This is of course a very minor problem, since I never do anything 
> useful on Windows machines.

Fortune candidate?

     cheers,

         Rolf Turner


From ligges at statistik.tu-dortmund.de  Sun Jul 21 12:27:14 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 21 Jul 2013 12:27:14 +0200
Subject: [R] Windows 7 (Swedish): 'Rcmd INSTALL' fails (SOLVED)
In-Reply-To: <51EBA0D9.2080209@stat.umu.se>
References: <51EB0E9D.30609@stat.umu.se>
	<51EB1454.5090205@statistik.tu-dortmund.de>
	<51EBA0D9.2080209@stat.umu.se>
Message-ID: <51EBB782.7090004@statistik.tu-dortmund.de>



On 21.07.2013 10:50, G?ran Brostr?m wrote:
> Uwe, thanks!
>
> The switch from "Program" to "Program Files" made it (stupid Windows!).
>
> I tried the "--library=." flag because I got the error message
>
> path[2]="C:/Program/R/R-3.0.1/library": Access denied
>
> without it, and naively thought that I had a permission problem.
> This was strange, because I am the administrator of my Windows machines.
>
> BTW, why can't I, as an administrator, install packages in
>
> "C:\Program Files\R\R-3.0.1\library" ?


Because you started R with standard privileges? Right click on R and 
then tell Windows to start R as an administrator. That should fix your 
problems.

Best,
Uwe Ligges

> This is of course a very minor problem, since I never do anything useful
> on Windows machines.
>
> Best,
>
> G?ran Brostr?m
>
> Uwe Ligges skrev 2013-07-21 00:51:
>>
>>
>> On 21.07.2013 00:26, G?ran Brostr?m wrote:
>>> I am trying to build a Windows zip file of a private package by
>>>
>>> C:/Program/R/R-3.0.1/bin/x64/Rcmd INSTALL --build --library=.
>>> epigen_0.1.tar.gz
>>
>> Why --library=. ?
>> Do you have appropriate poermissions to do that? In this case, you need
>> to start everything with admin priviliges explicitly unless your Windows
>> is configured differently.
>>
>>
>>>
>>> but I get errors like
>>>
>>> 1: package 'datasets' in options("defaultPackages") was not found
>>>
>>> and, finally,
>>>
>>> Error in normalsizePath(path.expand(path), winslash, mustWork) :
>>> path[1]="C:/Program/R/R-3.0.1/library/tools": Atkomst nekad
>>> (Access denied)
>>>
>>> This is on a Swedish version of Windows 7. I noticed that the R
>>> installer called the installation directory "Program Files" instead of
>>> "Program" (despite my effort to change it), so I tried the same thing
>>
>> But there is "Program Files", "Program" is just something like a link
>> shown by the Windows Explorer that actually points to "Program Files".
>>
>>
>>
>>> with an English version of Windows 7 (on another machine), and there
>>> everything went as expected.
>>>
>>> I installed R on both machines today so the setups should be identical,
>>> except for the languages. What can be wrong? Can it be a language/path
>>> thing?
>>
>> Probably not the language but different admin settings.
>>
>> Best,
>> Uwe Ligges
>>
>>>
>>> Thanks for any insight!
>>>
>>> G?ran Brostr?m
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.


From Scott.Robinson at glasgow.ac.uk  Sun Jul 21 15:02:06 2013
From: Scott.Robinson at glasgow.ac.uk (Scott Robinson)
Date: Sun, 21 Jul 2013 14:02:06 +0100
Subject: [R] BH correction with p.adjust
In-Reply-To: <E6217802-3118-4831-B877-2BF4AD211217@comcast.net>
References: <2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BED@CMS03.campus.gla.ac.uk>,
	<E6217802-3118-4831-B877-2BF4AD211217@comcast.net>
Message-ID: <2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BEF@CMS03.campus.gla.ac.uk>

My understanding was that the vector was ranked, the adjusted p vector was calculated and then the vector is returned to the original order - I came across a stack overflow answer saying this:

http://stackoverflow.com/questions/10323817/r-unexpected-results-from-p-adjust-fdr

Although the code there does not appear to be the same as when I type "p.adjust" into the command line. The order shouldn't matter anyway since my data was ordered by p.

Yesterday I tried a short example of 5 numbers and it seemed to work out though today I tried to do another short example to demonstrate that the order in the p vector you input doesn't matter but didn't quite get a working example this time. Maybe due to a rounding to first significant figure or something?

> smallP <- c(0.01, 0.5, 0.0001)
> names(smallP) <- c("first", "second", "last")
> 
> p.adjust(smallP)
 first second   last 
 2e-02  5e-01  3e-04 
> 
> 0.01*3/2
[1] 0.015
> 0.5*3/3
[1] 0.5
> 0.0001*3/1
[1] 3e-04

In any case I reconstructed a large example which can be run without real data where the figure is way off and definitely not the result of a rounding error:

> exampleP <- seq(from=0.0000001, to=0.1, by=0.00000001)
> length(exampleP)
[1] 9999991
> 
> examplePBH <- p.adjust(exampleP, method="BH")
> 
> exampleP[1]
[1] 1e-07
> 
> examplePBH[1]
[1] 0.1
> 
> exampleP[1]*length(exampleP)/1
[1] 0.9999991

Any help with this would be very much appreciated. It seems like it ought to be such a simple and commonly used method and yet I am struggling and not sure what to do about it.

Thanks,

Scott

________________________________________
From: David Winsemius [dwinsemius at comcast.net]
Sent: 21 July 2013 03:33
To: Scott Robinson
Cc: r-help at r-project.org
Subject: Re: [R] BH correction with p.adjust

On Jul 20, 2013, at 10:37 AM, Scott Robinson wrote:

> Dear List,
>
> I have been trying to use p.adjust() to do BH multiple test correction and have gotten some unexpected results. I thought that the equation for this was:
>
> pBH = p*n/i

Looking at the code for `p.adjust`, you see that the method is picked from a switch function

lp <- length(p)
BH = {
        i <- lp:1L
        o <- order(p, decreasing = TRUE)
        ro <- order(o)
        pmin(1, cummin(n/i * p[o]))[ro]
    }

You may not have sorted the p-values in pList.


>
> where p is the original p value, n is the number of tests and i is the rank of the p value. However when I try and recreate the corrected p from my most significant value it does not match up to the one computed by the method p.adjust:
>
>> setwd("C:/work/Methylation/IMA/GM/siteLists")
>>
>> hypTable <- read.delim("hypernormal vs others.txt")
>> pList <- hypTable$p
>> names(pList) <- hypTable$site
>>
>> adjusted <- p.adjust(pList, method="BH")
>> adjusted[1]
> cg27433479
> 0.05030589
>>
>> pList[1]*nrow(hypTable)/1
> cg27433479
> 0.09269194
>

No data provided, so unable to pursue this further.

> I tried to recreate this is a small example of a vector of 5 p values but everything worked as expected there. I was wondering if there is some subtle difference about how p.adjust operates? Is there something more complicated about how to calculate 'n' or 'i' - perhaps due to identical p values being assigned the same rank or something? Does anyone have an idea what might be going on here?


--

David Winsemius
Alameda, CA, USA


From gb at stat.umu.se  Sun Jul 21 16:11:17 2013
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Sun, 21 Jul 2013 16:11:17 +0200
Subject: [R] Windows 7 (Swedish): 'Rcmd INSTALL' fails (SOLVED)
In-Reply-To: <51EBB782.7090004@statistik.tu-dortmund.de>
References: <51EB0E9D.30609@stat.umu.se>
	<51EB1454.5090205@statistik.tu-dortmund.de>
	<51EBA0D9.2080209@stat.umu.se>
	<51EBB782.7090004@statistik.tu-dortmund.de>
Message-ID: <51EBEC05.5080800@stat.umu.se>



On 07/21/2013 12:27 PM, Uwe Ligges wrote:
>
>
> On 21.07.2013 10:50, G?ran Brostr?m wrote:
>> Uwe, thanks!
>>
>> The switch from "Program" to "Program Files" made it (stupid Windows!).
>>
>> I tried the "--library=." flag because I got the error message
>>
>> path[2]="C:/Program/R/R-3.0.1/library": Access denied
>>
>> without it, and naively thought that I had a permission problem.
>> This was strange, because I am the administrator of my Windows machines.
>>
>> BTW, why can't I, as an administrator, install packages in
>>
>> "C:\Program Files\R\R-3.0.1\library" ?
>
>
> Because you started R with standard privileges? Right click on R and
> then tell Windows to start R as an administrator. That should fix your
> problems.

Thanks again; didn't know that either! Always fun to learn new things.

Best,

G?ran Brostr?m


> Best,
> Uwe Ligges
>
>> This is of course a very minor problem, since I never do anything useful
>> on Windows machines.
>>
>> Best,
>>
>> G?ran Brostr?m
>>
>> Uwe Ligges skrev 2013-07-21 00:51:
>>>
>>>
>>> On 21.07.2013 00:26, G?ran Brostr?m wrote:
>>>> I am trying to build a Windows zip file of a private package by
>>>>
>>>> C:/Program/R/R-3.0.1/bin/x64/Rcmd INSTALL --build --library=.
>>>> epigen_0.1.tar.gz
>>>
>>> Why --library=. ?
>>> Do you have appropriate poermissions to do that? In this case, you need
>>> to start everything with admin priviliges explicitly unless your Windows
>>> is configured differently.
>>>
>>>
>>>>
>>>> but I get errors like
>>>>
>>>> 1: package 'datasets' in options("defaultPackages") was not found
>>>>
>>>> and, finally,
>>>>
>>>> Error in normalsizePath(path.expand(path), winslash, mustWork) :
>>>> path[1]="C:/Program/R/R-3.0.1/library/tools": Atkomst nekad
>>>> (Access denied)
>>>>
>>>> This is on a Swedish version of Windows 7. I noticed that the R
>>>> installer called the installation directory "Program Files" instead of
>>>> "Program" (despite my effort to change it), so I tried the same thing
>>>
>>> But there is "Program Files", "Program" is just something like a link
>>> shown by the Windows Explorer that actually points to "Program Files".
>>>
>>>
>>>
>>>> with an English version of Windows 7 (on another machine), and there
>>>> everything went as expected.
>>>>
>>>> I installed R on both machines today so the setups should be identical,
>>>> except for the languages. What can be wrong? Can it be a language/path
>>>> thing?
>>>
>>> Probably not the language but different admin settings.
>>>
>>> Best,
>>> Uwe Ligges
>>>
>>>>
>>>> Thanks for any insight!
>>>>
>>>> G?ran Brostr?m
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Sun Jul 21 18:01:10 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 21 Jul 2013 18:01:10 +0200
Subject: [R] BH correction with p.adjust
In-Reply-To: <2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BEF@CMS03.campus.gla.ac.uk>
References: <2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BED@CMS03.campus.gla.ac.uk>,
	<E6217802-3118-4831-B877-2BF4AD211217@comcast.net>
	<2196FA45752E9F4CA84F1C8019CA8FC7564DBD6BEF@CMS03.campus.gla.ac.uk>
Message-ID: <3B034AB7-B5A6-4AB2-93BA-2F6FE7417B0B@gmail.com>


On Jul 21, 2013, at 15:02 , Scott Robinson wrote:

> My understanding was that the vector was ranked, the adjusted p vector was calculated and then the vector is returned to the original order - I came across a stack overflow answer saying this:
> 
> http://stackoverflow.com/questions/10323817/r-unexpected-results-from-p-adjust-fdr
> 
> Although the code there does not appear to be the same as when I type "p.adjust" into the command line. The order shouldn't matter anyway since my data was ordered by p.
> 
> Yesterday I tried a short example of 5 numbers and it seemed to work out though today I tried to do another short example to demonstrate that the order in the p vector you input doesn't matter but didn't quite get a working example this time. Maybe due to a rounding to first significant figure or something?
> 
>> smallP <- c(0.01, 0.5, 0.0001)
>> names(smallP) <- c("first", "second", "last")
>> 
>> p.adjust(smallP)
> first second   last 
> 2e-02  5e-01  3e-04 
>> 
>> 0.01*3/2
> [1] 0.015
>> 0.5*3/3
> [1] 0.5
>> 0.0001*3/1
> [1] 3e-04

Comparing the same method might help!

> p.adjust(smallP, method="BH")
[1] 0.0150 0.5000 0.0003


> 
> In any case I reconstructed a large example which can be run without real data where the figure is way off and definitely not the result of a rounding error:
> 
>> exampleP <- seq(from=0.0000001, to=0.1, by=0.00000001)
>> length(exampleP)
> [1] 9999991
>> 
>> examplePBH <- p.adjust(exampleP, method="BH")
>> 
>> exampleP[1]
> [1] 1e-07
>> 
>> examplePBH[1]
> [1] 0.1
>> 
>> exampleP[1]*length(exampleP)/1
> [1] 0.9999991
> 
> Any help with this would be very much appreciated. It seems like it ought to be such a simple and commonly used method and yet I am struggling and not sure what to do about it.

You have the source code, how about reading it?

    }, BH = {
        i <- lp:1L
        o <- order(p, decreasing = TRUE)
        ro <- order(o)
        pmin(1, cummin(n/i * p[o]))[ro]
    }

Notice the cumulative minimum. The first element in n/i*p[o] is going to be p[n] == 0.1 (since your p is in ascending order). So no element of the result is going to be bigger than 0.1. (I presume this is because p-adjustments must be order-preserving.) 

> Thanks,
> 
> Scott
> 
> ________________________________________
> From: David Winsemius [dwinsemius at comcast.net]
> Sent: 21 July 2013 03:33
> To: Scott Robinson
> Cc: r-help at r-project.org
> Subject: Re: [R] BH correction with p.adjust
> 
> On Jul 20, 2013, at 10:37 AM, Scott Robinson wrote:
> 
>> Dear List,
>> 
>> I have been trying to use p.adjust() to do BH multiple test correction and have gotten some unexpected results. I thought that the equation for this was:
>> 
>> pBH = p*n/i
> 
> Looking at the code for `p.adjust`, you see that the method is picked from a switch function
> 
> lp <- length(p)
> BH = {
>        i <- lp:1L
>        o <- order(p, decreasing = TRUE)
>        ro <- order(o)
>        pmin(1, cummin(n/i * p[o]))[ro]
>    }
> 
> You may not have sorted the p-values in pList.
> 
> 
>> 
>> where p is the original p value, n is the number of tests and i is the rank of the p value. However when I try and recreate the corrected p from my most significant value it does not match up to the one computed by the method p.adjust:
>> 
>>> setwd("C:/work/Methylation/IMA/GM/siteLists")
>>> 
>>> hypTable <- read.delim("hypernormal vs others.txt")
>>> pList <- hypTable$p
>>> names(pList) <- hypTable$site
>>> 
>>> adjusted <- p.adjust(pList, method="BH")
>>> adjusted[1]
>> cg27433479
>> 0.05030589
>>> 
>>> pList[1]*nrow(hypTable)/1
>> cg27433479
>> 0.09269194
>> 
> 
> No data provided, so unable to pursue this further.
> 
>> I tried to recreate this is a small example of a vector of 5 p values but everything worked as expected there. I was wondering if there is some subtle difference about how p.adjust operates? Is there something more complicated about how to calculate 'n' or 'i' - perhaps due to identical p values being assigned the same rank or something? Does anyone have an idea what might be going on here?
> 
> 
> --
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jun.shen.ut at gmail.com  Sun Jul 21 21:49:01 2013
From: jun.shen.ut at gmail.com (Jun Shen)
Date: Sun, 21 Jul 2013 15:49:01 -0400
Subject: [R] Is there a limit on the number of code line in .Rhistory
Message-ID: <CAMCXXmpHK6pu5YYqPYi5vr6M230CbJgbEaUkSmO0weum3nuDKQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130721/d45cd56f/attachment.pl>

From bhh at xs4all.nl  Sun Jul 21 21:57:23 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 21 Jul 2013 21:57:23 +0200
Subject: [R] Is there a limit on the number of code line in .Rhistory
In-Reply-To: <CAMCXXmpHK6pu5YYqPYi5vr6M230CbJgbEaUkSmO0weum3nuDKQ@mail.gmail.com>
References: <CAMCXXmpHK6pu5YYqPYi5vr6M230CbJgbEaUkSmO0weum3nuDKQ@mail.gmail.com>
Message-ID: <E7A4A106-63A6-40A7-BD87-458FE8273A6E@xs4all.nl>


On 21-07-2013, at 21:49, Jun Shen <jun.shen.ut at gmail.com> wrote:

> Dear list,
> 
> Just wonder if there is a limit on the number of code line in .Rhistory.
> When I check the .Rhistory, some code I enter at earlier time disappeared.
> If there is limit, how do I change it? Thanks.
> 

?history

Read section details.

Berend

> Jun
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stev0175 at gmail.com  Sun Jul 21 22:53:50 2013
From: stev0175 at gmail.com (Jeff Stevens)
Date: Sun, 21 Jul 2013 15:53:50 -0500
Subject: [R] Different x-axis scales using c() in latticeExtra
In-Reply-To: <CAKZAQ7x-QxcogJPTAjRxz0PFY96Nvwkwqyy1Lvk-Bs1kfFeGYw@mail.gmail.com>
References: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>
	<0FFC0330-DBFC-4E77-B296-AC87B8B0B2D8@comcast.net>
	<CAKZAQ7x-QxcogJPTAjRxz0PFY96Nvwkwqyy1Lvk-Bs1kfFeGYw@mail.gmail.com>
Message-ID: <CAJ6UiDRUPv6B7ZLam-zAZmOcwhQB==1mhxACVxeVTjg6eDKG0A@mail.gmail.com>

Many thanks, Felix.  Though, it seems like the x.same option should
allow this: "if TRUE, set the x scale relation to "same" and
recalculate panel limits using data from all panels. Otherwise, the x
scales in each panel will be as they were in the original objects (so
in general not the same), the default behaviour."  Or does this just
refer to different axis ranges on the same type of scale?

By the way, the grid.arrange feature from gridExtra seems to produce
the same output as plot.trellis using the split option.  Is there an
advantage to using grid.arrange over plot.trellis?  Also, do you have
pointers to documentation that would help me alter the plot.trellis
output to look more like the c() output (e.g., remove horizontal space
between plots and make sure plots have consistent widths?

Thanks,
Jeff

On Sat, Jul 20, 2013 at 6:45 PM, Felix Andrews <felix at nfrac.org> wrote:
> latticeExtra's c() can not combine logarithmic with linear x scales,
> I'm afraid.  I would recommend displaying each separate plot on one
> page using plot.trellis() or the gridExtra function that John Kane
> mentioned.
>
> Cheers
> Felix
>
>
> On 21 July 2013 02:50, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On Jul 19, 2013, at 8:18 PM, Jeff Stevens wrote:
>>
>>> Hi,
>>>
>>> I would like to combine multiple xyplots into a single, multipanel
>>> display.  Using R 3.0.1 in Ubuntu, I have used c() from latticeExtra
>>> to combine three plots, but the x-axis for two plots are on a log
>>> scale and the other is on a normal scale.  I also have included
>>> equispace.log=FALSE to clean up the tick labels.  However, when I try
>>> all of these, the x-axis scale of the first panel is used for all
>>> three.  How do I keep different scales for the different panels?
>>>
>>> Here is an example:
>>> library(lattice)
>>> library(latticeExtra)
>>> response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
>>> predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
>>> predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
>>> predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)
>>>
>>> pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
>>> equispaced.log = FALSE),
>>>  panel = function(x, y, ...) {
>>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>>    panel.text(x = log10(8), y = log10(120), labels = "(a)")
>>>  }
>>> )
>>>
>>> pred2_plot <- xyplot(response ~ predictor2, scales = list(log = TRUE,
>>> equispaced.log = FALSE),
>>>  panel = function(x, y, ...) {
>>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>>    panel.text(x = log10(2), y = log10(120), labels = "(b)")
>>>  }
>>> )
>>>
>>> pred3_plot <- xyplot(response ~ predictor3, scales = list(y = list(log
>>> = TRUE, equispaced.log = FALSE)),
>>>  panel = function(x, y, ...) {
>>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>>    panel.text(x = 22, y = log10(120), labels = "(c)")
>>>  }
>>> )
>>>
>>> all_plots <- c(pred1_plot, pred2_plot, pred3_plot, layout = c(3, 1), x.same = F)
>>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>>> scales = list(y=list(log=T, equispaced.log=FALSE), x = c(list(log=T,
>>> equispaced.log=FALSE), list(log=T, equispaced.log=FALSE),
>>> list(log=F))))
>>>
>>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>>> scales = c(list(log = TRUE, equispaced.log = FALSE), list(log = TRUE,
>>> equispaced.log = FALSE), list(y=list(log=T, equispaced.log = FALSE))))
>>>
>>> Any help is appreciated!
>>
>> I assume there was a notice o your console that there were warnings, right? You should offer the full texts of warnings and error messages. Here the full text of the first and second warnings:
>>
>>> warnings()[1:2]
>> $`log scales cannot be changed via 'update'`
>> update.trellis(all_plots, xlab = c("Predictor 1", "Predictor 2",
>>     "Predictor 3"), scales = c(list(log = TRUE, equispaced.log = FALSE),
>>     list(log = TRUE, equispaced.log = FALSE), list(y = list(log = T,
>>         equispaced.log = FALSE))))
>> $`'x' is NULL so the result will be NULL`
>> rep(scales[[nm]], length.out = 2)
>>
>> The first one is telling you why the results should be different than you expect. I'm not entirely sure what the second one is telling you, but it doesn't sound good.
>>
>> --
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Felix Andrews / ???
> http://www.neurofractal.org/felix/


From stev0175 at gmail.com  Sun Jul 21 22:59:01 2013
From: stev0175 at gmail.com (Jeff Stevens)
Date: Sun, 21 Jul 2013 15:59:01 -0500
Subject: [R] Different x-axis scales using c() in latticeExtra
In-Reply-To: <0FFC0330-DBFC-4E77-B296-AC87B8B0B2D8@comcast.net>
References: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>
	<0FFC0330-DBFC-4E77-B296-AC87B8B0B2D8@comcast.net>
Message-ID: <CAJ6UiDSJR4kRcAz--sbaPmo7BfqA+e3Ux2fRzTuQ5aTEmDA-4A@mail.gmail.com>

Thanks, David.  The warnings occur after the true problem of trying to
plot the three graphs with different scales.  I should have stopped
the example after assigning all_plots <- c(...), then plotted it (and
left out the update statements).  If you do this, the x-axes do not
maintain their scales.

But I take your point that I should have paid more attention to the warnings!

Thanks,
Jeff



On Sat, Jul 20, 2013 at 11:50 AM, David Winsemius
<dwinsemius at comcast.net> wrote:
>
> On Jul 19, 2013, at 8:18 PM, Jeff Stevens wrote:
>
>> Hi,
>>
>> I would like to combine multiple xyplots into a single, multipanel
>> display.  Using R 3.0.1 in Ubuntu, I have used c() from latticeExtra
>> to combine three plots, but the x-axis for two plots are on a log
>> scale and the other is on a normal scale.  I also have included
>> equispace.log=FALSE to clean up the tick labels.  However, when I try
>> all of these, the x-axis scale of the first panel is used for all
>> three.  How do I keep different scales for the different panels?
>>
>> Here is an example:
>> library(lattice)
>> library(latticeExtra)
>> response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
>> predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
>> predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
>> predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)
>>
>> pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
>> equispaced.log = FALSE),
>>  panel = function(x, y, ...) {
>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>    panel.text(x = log10(8), y = log10(120), labels = "(a)")
>>  }
>> )
>>
>> pred2_plot <- xyplot(response ~ predictor2, scales = list(log = TRUE,
>> equispaced.log = FALSE),
>>  panel = function(x, y, ...) {
>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>    panel.text(x = log10(2), y = log10(120), labels = "(b)")
>>  }
>> )
>>
>> pred3_plot <- xyplot(response ~ predictor3, scales = list(y = list(log
>> = TRUE, equispaced.log = FALSE)),
>>  panel = function(x, y, ...) {
>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>    panel.text(x = 22, y = log10(120), labels = "(c)")
>>  }
>> )
>>
>> all_plots <- c(pred1_plot, pred2_plot, pred3_plot, layout = c(3, 1), x.same = F)
>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>> scales = list(y=list(log=T, equispaced.log=FALSE), x = c(list(log=T,
>> equispaced.log=FALSE), list(log=T, equispaced.log=FALSE),
>> list(log=F))))
>>
>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>> scales = c(list(log = TRUE, equispaced.log = FALSE), list(log = TRUE,
>> equispaced.log = FALSE), list(y=list(log=T, equispaced.log = FALSE))))
>>
>> Any help is appreciated!
>
> I assume there was a notice o your console that there were warnings, right? You should offer the full texts of warnings and error messages. Here the full text of the first and second warnings:
>
>> warnings()[1:2]
> $`log scales cannot be changed via 'update'`
> update.trellis(all_plots, xlab = c("Predictor 1", "Predictor 2",
>     "Predictor 3"), scales = c(list(log = TRUE, equispaced.log = FALSE),
>     list(log = TRUE, equispaced.log = FALSE), list(y = list(log = T,
>         equispaced.log = FALSE))))
> $`'x' is NULL so the result will be NULL`
> rep(scales[[nm]], length.out = 2)
>
> The first one is telling you why the results should be different than you expect. I'm not entirely sure what the second one is telling you, but it doesn't sound good.
>
> --
> David Winsemius
> Alameda, CA, USA
>


From jwd at surewest.net  Mon Jul 22 03:07:38 2013
From: jwd at surewest.net (jwd)
Date: Sun, 21 Jul 2013 18:07:38 -0700
Subject: [R] Windows 7 (Swedish): 'Rcmd INSTALL' fails (SOLVED)
In-Reply-To: <51EBA706.8010708@xtra.co.nz>
References: <51EB0E9D.30609@stat.umu.se>
	<51EB1454.5090205@statistik.tu-dortmund.de>
	<51EBA0D9.2080209@stat.umu.se> <51EBA706.8010708@xtra.co.nz>
Message-ID: <20130721180740.10a4301e@draco.site>

On Sun, 21 Jul 2013 21:16:54 +1200
Rolf Turner <rolf.turner at xtra.co.nz> wrote:

...
> > "C:\Program Files\R\R-3.0.1\library" ?
> >
> > This is of course a very minor problem, since I never do anything 
> > useful on Windows machines.
> 
> Fortune candidate?
> 
Seconded.

JWDougherty


From krishna at primps.com.sg  Mon Jul 22 07:24:09 2013
From: krishna at primps.com.sg (S N V Krishna)
Date: Mon, 22 Jul 2013 05:24:09 +0000
Subject: [R] problem loading large xlsx file into r
Message-ID: <65ca1cdc29254c4690e19329be44e96f@HKXPR03MB007.apcprd03.prod.outlook.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/84185193/attachment.pl>

From yi.cheng at hp.com  Mon Jul 22 04:49:35 2013
From: yi.cheng at hp.com (Cheng, Yi)
Date: Mon, 22 Jul 2013 02:49:35 +0000
Subject: [R] clust algorithm for interval-typed data
Message-ID: <063B0F2850BFFB4CAB9E540AF2A9007E22D3616A@G2W2442.americas.hpqcorp.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/c9ef8525/attachment.pl>

From xueling.l456 at gmail.com  Mon Jul 22 06:36:21 2013
From: xueling.l456 at gmail.com (xl Liang)
Date: Mon, 22 Jul 2013 12:36:21 +0800
Subject: [R] Some doubts on the application of RHadoop
Message-ID: <CAK_-eKjJEu0y3vMeHDEq-_tOtCkhfq0cS2P9vinqr7=sdqP+PA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/030c1c75/attachment.pl>

From yi.cheng at hp.com  Mon Jul 22 08:23:19 2013
From: yi.cheng at hp.com (Cheng, Yi)
Date: Mon, 22 Jul 2013 06:23:19 +0000
Subject: [R] about mix type clust algorithm
Message-ID: <063B0F2850BFFB4CAB9E540AF2A9007E22D3625A@G2W2442.americas.hpqcorp.net>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/db235c43/attachment.pl>

From arne.henningsen at gmail.com  Mon Jul 22 10:31:54 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Mon, 22 Jul 2013 10:31:54 +0200
Subject: [R] [R-pkgs] Version 1.0 of the R package "frontier" released
Message-ID: <CAMTWbJh6ScLphf2nnd3guwOhk9Tp3N0utu_2S6Yuzp7sih0b6g@mail.gmail.com>

Dear all

I am happy to announce that version 1.0 of the "frontier" package is
available on CRAN. The R package "frontier" provides tools for
analysing efficiency and productivity using the "stochastic frontier"
approach. This R package is based on Tim Coelli's DOS software
"FRONTIER 4.1" and has been available on CRAN for almost 5 years now.
After many improvements of the source code, a few additional features,
and a few changes of the user interface in the beginning, the code and
the user interface have been rather stable in the previous 2.5 years.
The "frontier" package has been used by many R users and many
applications have proven its reliability. Therefore, I have called the
latest version of this package "1.0." This version is almost identical
to the previous versions but it includes citation information and the
argument "farrell" of efficiencies.frontier() has been renamed as
"minusU" and the argument "farrell" of summary.frontier() has been
renamed as "effMinusU", because the term "farrell" was misleading in
some cases. The argument "farrell" can still be used for maintaining
backward-compatibility.

http://cran.r-project.org/package=frontier

https://r-forge.r-project.org/projects/frontier/

Best regards,
Arne

--
Arne Henningsen
http://www.arne-henningsen.name

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From michel.arnaud at cirad.fr  Mon Jul 22 10:56:47 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 22 Jul 2013 10:56:47 +0200
Subject: [R] Calculate interaction for a big dataframe
Message-ID: <51ECF3CF.9030807@cirad.fr>

Hi

To calculate the value of the interaction between factors of a dataframe 
df, does exist any function which could replace the function when the 
dataframe df has the numbers of rows of df is large (~55000) and also 
the numbers of combinaison of the three factors is large. The calcul abort.
The function to calculate the interaction is :
as.numeric(interaction(df [,c(1:3)],drop=TRUE))

To complete the question and to calculate interaction beetween 3 factors 
f1, f2, f3, does it possible to calculate first f12 = interaction 
(f1,f2) and after calculate interaction (f12, f3).
It seems to me that yes.

Thanks for your help




-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From jholtman at gmail.com  Mon Jul 22 11:09:36 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Mon, 22 Jul 2013 05:09:36 -0400
Subject: [R] problem loading large xlsx file into r
In-Reply-To: <65ca1cdc29254c4690e19329be44e96f@HKXPR03MB007.apcprd03.prod.outlook.com>
References: <65ca1cdc29254c4690e19329be44e96f@HKXPR03MB007.apcprd03.prod.outlook.com>
Message-ID: <8ED09283-0C9A-4FE5-86EA-6C84D3AE549D@gmail.com>

try the "XLConnect" package and if possible change the "xlsx" to "xls" format for better performance.

Sent from my iPad

On Jul 22, 2013, at 1:24, S N V Krishna <krishna at primps.com.sg> wrote:

> Hi,
> 
> I am facing trouble when trying to read large xlsx file into R. please find the code and error below. The file I was trying to read has 36,500 rows X 188 col, ~ 37 MB size.
> 
>> options( java.parameters = "-Xmx4g" )
> 
>> library(xlsx)
> Loading required package: xlsxjars
> Loading required package: rJava
> 
>> cftc = read.xlsx("d:\\Krishna\\Research\\CFTC_COT\\cftcdata.xlsx", 1)
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>  java.lang.OutOfMemoryError: Java heap space
> 
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] xlsx_0.5.1     xlsxjars_0.5.0 rJava_0.9-5
> 
> Many thanks for the help and guidance.
> 
> Regards,
> 
> Krishna
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From landronimirc at gmail.com  Mon Jul 22 11:16:57 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Mon, 22 Jul 2013 11:16:57 +0200
Subject: [R] union of a list of logical values
Message-ID: <CABxs9Vkh1wRu-h2GcaNAViEZNMma_e7TGrTgvQR73ZKMaoz2EQ@mail.gmail.com>

Dear all,
How can I obtain the union of a list of logical values?

Consider the following:
x <- head(iris)
x[,c(2,4)] <- NA
x[c(2,4),] <- NA
# > x
# Sepal.Length Sepal.Width Petal.Length Petal.Width Species
# 1          5.1          NA          1.4          NA  setosa
# 2           NA          NA           NA          NA    <NA>
# 3          4.7          NA          1.3          NA  setosa
# 4           NA          NA           NA          NA    <NA>
# 5          5.0          NA          1.4          NA  setosa
# 6          5.4          NA          1.7          NA  setosa
z <- data.frame(!is.na(x))
# > z
# Sepal.Length Sepal.Width Petal.Length Petal.Width Species
# 1         TRUE       FALSE         TRUE       FALSE    TRUE
# 2        FALSE       FALSE        FALSE       FALSE   FALSE
# 3         TRUE       FALSE         TRUE       FALSE    TRUE
# 4        FALSE       FALSE        FALSE       FALSE   FALSE
# 5         TRUE       FALSE         TRUE       FALSE    TRUE
# 6         TRUE       FALSE         TRUE       FALSE    TRUE

I did find a solution, but it seems more like a hack:
> ##union of logical values by rows (union of list of logical values)
> as.logical(rowSums(z))
[1]  TRUE FALSE  TRUE FALSE  TRUE  TRUE
> ##union of logical values by columns
> as.logical(colSums(z))
[1]  TRUE FALSE  TRUE FALSE  TRUE

Another unusable monstrosity is as follows:
> ##union of list of logical values
> z[[1]] | z[[2]] | z[[3]] | z[[4]] | z[[5]]
[1]  TRUE FALSE  TRUE FALSE  TRUE  TRUE

Is there a more elegant way to approach this problem and obtain the
above logical vectors? Regards,
Liviu


-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From ripley at stats.ox.ac.uk  Mon Jul 22 11:37:30 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 22 Jul 2013 10:37:30 +0100
Subject: [R] union of a list of logical values
In-Reply-To: <CABxs9Vkh1wRu-h2GcaNAViEZNMma_e7TGrTgvQR73ZKMaoz2EQ@mail.gmail.com>
References: <CABxs9Vkh1wRu-h2GcaNAViEZNMma_e7TGrTgvQR73ZKMaoz2EQ@mail.gmail.com>
Message-ID: <51ECFD5A.5010001@stats.ox.ac.uk>

On 22/07/2013 10:16, Liviu Andronic wrote:
> Dear all,
> How can I obtain the union of a list of logical values?

This really only makes sense for a list of logical vectors of the same 
length.  And by 'union' you seem to mean 'or'.

Two approaches

1) Make a logical matrix and use apply(m, 1, any)

2) Use Reduce(`|`, z)

>
> Consider the following:
> x <- head(iris)
> x[,c(2,4)] <- NA
> x[c(2,4),] <- NA
> # > x
> # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> # 1          5.1          NA          1.4          NA  setosa
> # 2           NA          NA           NA          NA    <NA>
> # 3          4.7          NA          1.3          NA  setosa
> # 4           NA          NA           NA          NA    <NA>
> # 5          5.0          NA          1.4          NA  setosa
> # 6          5.4          NA          1.7          NA  setosa
> z <- data.frame(!is.na(x))
> # > z
> # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
> # 1         TRUE       FALSE         TRUE       FALSE    TRUE
> # 2        FALSE       FALSE        FALSE       FALSE   FALSE
> # 3         TRUE       FALSE         TRUE       FALSE    TRUE
> # 4        FALSE       FALSE        FALSE       FALSE   FALSE
> # 5         TRUE       FALSE         TRUE       FALSE    TRUE
> # 6         TRUE       FALSE         TRUE       FALSE    TRUE
>
> I did find a solution, but it seems more like a hack:
>> ##union of logical values by rows (union of list of logical values)
>> as.logical(rowSums(z))
> [1]  TRUE FALSE  TRUE FALSE  TRUE  TRUE
>> ##union of logical values by columns
>> as.logical(colSums(z))
> [1]  TRUE FALSE  TRUE FALSE  TRUE
>
> Another unusable monstrosity is as follows:
>> ##union of list of logical values
>> z[[1]] | z[[2]] | z[[3]] | z[[4]] | z[[5]]
> [1]  TRUE FALSE  TRUE FALSE  TRUE  TRUE
>
> Is there a more elegant way to approach this problem and obtain the
> above logical vectors? Regards,
> Liviu
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From antony.akkara at ge.com  Mon Jul 22 10:36:44 2013
From: antony.akkara at ge.com (R_Antony)
Date: Mon, 22 Jul 2013 01:36:44 -0700 (PDT)
Subject: [R] Select csv files by choosing datetime
Message-ID: <1374482203999-4672023.post@n4.nabble.com>

Hi,

how can we read particular files from a path ? - i mean, i need to read csv
files which is created between two date and time. Here i need to get
filename along with path.

Thanks,
Antony.



--
View this message in context: http://r.789695.n4.nabble.com/Select-csv-files-by-choosing-datetime-tp4672023.html
Sent from the R help mailing list archive at Nabble.com.


From landronimirc at gmail.com  Mon Jul 22 11:42:08 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Mon, 22 Jul 2013 11:42:08 +0200
Subject: [R] union of a list of logical values
In-Reply-To: <51ECFD5A.5010001@stats.ox.ac.uk>
References: <CABxs9Vkh1wRu-h2GcaNAViEZNMma_e7TGrTgvQR73ZKMaoz2EQ@mail.gmail.com>
	<51ECFD5A.5010001@stats.ox.ac.uk>
Message-ID: <CABxs9VmS6JGQVCStHkzSYuKym4Od+Re69OTGJ8D9v9SV_M737Q@mail.gmail.com>

On Mon, Jul 22, 2013 at 11:37 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> This really only makes sense for a list of logical vectors of the same
> length.  And by 'union' you seem to mean 'or'.
>
Indeed.


> Two approaches
>
> 1) Make a logical matrix and use apply(m, 1, any)
>
Of course! I tried apply(m, 1, "|") without luck, but I should have
used apply(m, 1, any) instead.

Thank you,
Liviu


> 2) Use Reduce(`|`, z)
>
>
>>
>> Consider the following:
>> x <- head(iris)
>> x[,c(2,4)] <- NA
>> x[c(2,4),] <- NA
>> # > x
>> # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
>> # 1          5.1          NA          1.4          NA  setosa
>> # 2           NA          NA           NA          NA    <NA>
>> # 3          4.7          NA          1.3          NA  setosa
>> # 4           NA          NA           NA          NA    <NA>
>> # 5          5.0          NA          1.4          NA  setosa
>> # 6          5.4          NA          1.7          NA  setosa
>> z <- data.frame(!is.na(x))
>> # > z
>> # Sepal.Length Sepal.Width Petal.Length Petal.Width Species
>> # 1         TRUE       FALSE         TRUE       FALSE    TRUE
>> # 2        FALSE       FALSE        FALSE       FALSE   FALSE
>> # 3         TRUE       FALSE         TRUE       FALSE    TRUE
>> # 4        FALSE       FALSE        FALSE       FALSE   FALSE
>> # 5         TRUE       FALSE         TRUE       FALSE    TRUE
>> # 6         TRUE       FALSE         TRUE       FALSE    TRUE
>>
>> I did find a solution, but it seems more like a hack:
>>>
>>> ##union of logical values by rows (union of list of logical values)
>>> as.logical(rowSums(z))
>>
>> [1]  TRUE FALSE  TRUE FALSE  TRUE  TRUE
>>>
>>> ##union of logical values by columns
>>> as.logical(colSums(z))
>>
>> [1]  TRUE FALSE  TRUE FALSE  TRUE
>>
>> Another unusable monstrosity is as follows:
>>>
>>> ##union of list of logical values
>>> z[[1]] | z[[2]] | z[[3]] | z[[4]] | z[[5]]
>>
>> [1]  TRUE FALSE  TRUE FALSE  TRUE  TRUE
>>
>> Is there a more elegant way to approach this problem and obtain the
>> above logical vectors? Regards,
>> Liviu
>>
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From teresamarso at hotmail.com  Mon Jul 22 09:09:15 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Mon, 22 Jul 2013 07:09:15 +0000
Subject: [R] HELP R
Message-ID: <BAY172-W33BB816185A3AC0E36A90EB96E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/7103cbe7/attachment.pl>

From teresamarso at hotmail.com  Mon Jul 22 10:58:00 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Mon, 22 Jul 2013 08:58:00 +0000
Subject: [R] HELP R
Message-ID: <BAY172-W29314114056B439ECC4673B96E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/d28a1323/attachment.pl>

From teresamarso at hotmail.com  Mon Jul 22 11:11:32 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Mon, 22 Jul 2013 09:11:32 +0000
Subject: [R] HELP R
In-Reply-To: <BAY172-W29314114056B439ECC4673B96E0@phx.gbl>
References: <BAY172-W29314114056B439ECC4673B96E0@phx.gbl>
Message-ID: <BAY172-W1773832052B73093600B4B96E0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/774b5b62/attachment.pl>

From krishna at primps.com.sg  Mon Jul 22 12:09:16 2013
From: krishna at primps.com.sg (S N V Krishna)
Date: Mon, 22 Jul 2013 10:09:16 +0000
Subject: [R] problem loading large xlsx file into r
In-Reply-To: <8ED09283-0C9A-4FE5-86EA-6C84D3AE549D@gmail.com>
References: <65ca1cdc29254c4690e19329be44e96f@HKXPR03MB007.apcprd03.prod.outlook.com>
	<8ED09283-0C9A-4FE5-86EA-6C84D3AE549D@gmail.com>
Message-ID: <8c04800ee65f4a05804ca18fa656e4a0@HKXPR03MB007.apcprd03.prod.outlook.com>

Thanks Jim, I tried XLConnect but faced with same error.

> options(java.parameters = '-Xmx5g')

> library(XLConnect)
Loading required package: rJava
XLConnect 0.2-5 by Mirai Solutions GmbH
http://www.mirai-solutions.com ,
http://miraisolutions.wordpress.com

> cftc = readWorksheetFromFile("d:\\Krishna\\Research\\CFTC_COT\\cftcdata.xlsx", sheet = 'Sheet1')
Error: OutOfMemoryError (Java): Java heap space

What is the maximum file size to load into R? is there a better way to load large excel files to R?

Many thanks for the help.

Regards, 

Krishna

-----Original Message-----
From: Jim Holtman [mailto:jholtman at gmail.com] 
Sent: Monday, July 22, 2013 5:10 PM
To: S N V Krishna
Cc: r-help at r-project.org
Subject: Re: [R] problem loading large xlsx file into r

try the "XLConnect" package and if possible change the "xlsx" to "xls" format for better performance.

Sent from my iPad

On Jul 22, 2013, at 1:24, S N V Krishna <krishna at primps.com.sg> wrote:

> Hi,
> 
> I am facing trouble when trying to read large xlsx file into R. please find the code and error below. The file I was trying to read has 36,500 rows X 188 col, ~ 37 MB size.
> 
>> options( java.parameters = "-Xmx4g" )
> 
>> library(xlsx)
> Loading required package: xlsxjars
> Loading required package: rJava
> 
>> cftc = read.xlsx("d:\\Krishna\\Research\\CFTC_COT\\cftcdata.xlsx", 1)
> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>  
> 
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United 
> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
> [5] LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] xlsx_0.5.1     xlsxjars_0.5.0 rJava_0.9-5
> 
> Many thanks for the help and guidance.
> 
> Regards,
> 
> Krishna
> 
>    [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From mohitdhingras at gmail.com  Mon Jul 22 12:17:47 2013
From: mohitdhingras at gmail.com (Mohit Dhingra)
Date: Mon, 22 Jul 2013 15:47:47 +0530
Subject: [R] Y label doesn't show up on printing files
Message-ID: <CAGkgU9WqQnRXaoqCMjcaHbAa0WGPn4cfKENQsKQ35jePZssPoQ@mail.gmail.com>

Hello,

I'm using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" .

System info: Linux ubuntu 3.5.0-36-generic #57~precise1-Ubuntu SMP Thu
Jun 20 18:21:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux.

When I plot something, y label does show up on the pop up image.
plot (x, rtimel[,2] , xlab="Memory Allocated (in MB)", ylab="Response
Time (in ms)", type="l", col="black", ylim=c(0,m) )

But when I try to save it using
dev.copy(pdf,'response_time_with_memory_direct.pdf')
dev.off()

Y-label doesn't get printed on the pdf file. Can someone please help?


----------------------------
Thanks & Regards
Mohit Dhingra
+919611190435


From petr.pikal at precheza.cz  Mon Jul 22 12:19:38 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 22 Jul 2013 10:19:38 +0000
Subject: [R] HELP R
In-Reply-To: <BAY172-W1773832052B73093600B4B96E0@phx.gbl>
References: <BAY172-W29314114056B439ECC4673B96E0@phx.gbl>
	<BAY172-W1773832052B73093600B4B96E0@phx.gbl>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7F051@SRVEXCHMBX.precheza.cz>

Hi

You rather shall stop using HTML mail, it gets scrambled when posting to R help.
Then I believe you will profit from reading an Introduction to R, you seem to not knowing what you really do.

result <- vector("list",ncol(datos))

initializes result before a loop. If you have some extra columns the size of resulting list is not correct. The same apply to following loop.

for( i in 2:ncol(datos) {
result [i-1] <- bartlett.test(datos[,i]~datos$Provincia))
}
Error en `[.data.frame`(DATOS, , i) : undefined columns selected

Well, there probably shall be

result [[i-1]] <- bartlett.test(datos[,i]~datos$Provincia))

to get rid of the error.

Without data I did not test my code and therefore did not use correct assignment. Sorry.

Regards 
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Ma Teresa Martinez Soriano
> Sent: Monday, July 22, 2013 11:12 AM
> To: r-help at r-project.org
> Subject: Re: [R] HELP R
> 
> 
> 
> 
> 
> 
> 
> 
> Hi, I did what you have told me but I can not do it well,
> NUMERO Provincia CENAES   IE.2005   IE.2006   IE.2007  IE.2008
> 29    183  Alicante          7711    42.000    46.000    55.000
> 47.00030    479  Alicante          8299  1158.000   476.000   503.000
> 300.00031    591  Alicante          8129   540.000   764.000  1037.000
> 938.00032   1429  Alicante          8219  5233.000  6234.000  4659.000
> 2212.00033   2681  Alicante          8299    17.000     8.000    10.000
> 9.00034   3374  Alicante          8299   346.000   416.000   343.000
> 330.00035   5341  Alicante          8299  1198.000  1531.000   235.000
> 0.00036   5772  Alicante          7732   709.000   689.000   584.000
> 419.00037   6127  Alicante          7711   225.000   125.000   175.000
> 71.00038   6132  Alicante          7711  1084.000   634.000   592.000
> 291.00039   6133  Alicante          7711  5143.000  5838.000  7136.000
> 7835.00040   6134  Alicante          7711   327.000   394.000   442.000
> 331.00041   6138  Alicante          7739   301.000   341.000   408.000
> 470.00042   6140  Alicante          7732   274.000   483.000   468.000
> 280.000...56    337  Valencia          7911   261.000   623.000
> 1302.000 1487.00057    772  Valencia          7911   163.000   178.000
> 192.000  127.00058   1082  Valencia          7739   399.000   528.000
> 778.000  758.00059   1628  Valencia          8130   269.000   353.000
> 396.000  486.00060   1645  Valencia          7739   848.000  1015.000
> 1217.000  876.00061   1960  Valencia          8110   168.000   180.000
> 205.000  235.00062   2415  Valencia          7911   221.000   139.000
> 110.000  184.00063   2416  Valencia          7911   262.000   265.000
> 296.000  207.00064   2446  Valencia          8299    44.000   193.000
> 337.000  415.00065   3485  Valencia          8122   880.000   726.000
> 774.000 1081.00066   4053  Valencia          8130   243.000   649.000
> 880.000  734.00067   5566  Valencia          8299   325.000   767.000
> 97.000  158.00068   5779  Valencia          7739   298.000   356.000
> 344.000  348.00069   6167  Valencia          7711  2483.000  2461.000
> 2363.000 1915.000....
> This is the code that you have told meresult <- vector("list",
> ncol(datos))for( i in 2:ncol(datos) {result [i-1] <-
> bartlett.test(datos[,i]~datos$Provincia))}
> This is what I get Error en `[.data.frame`(DATOS, , i) : undefined
> columns selectedAdem?s: Mensajes de aviso perdidos1: In result[i - 1]
> <- bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  n?mero de items para
> para sustituir no es un m?ltiplo de la longitud del reemplazo2: In
> result[i - 1] <- bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  n?mero
> de items para para sustituir no es un m?ltiplo de la longitud del
> reemplazo3: In result[i - 1] <- bartlett.test(DATOS[, i] ~
> DATOS$Provincia) :  n?mero de items para para sustituir no es un
> m?ltiplo de la longitud del reemplazo4: In result[i - 1] <-
> bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  n?mero de items para
> para sustituir no es un m?ltiplo de la longitud del reemplazo5: In
> result[i - 1] <- bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  n?mero
> de items para para sustituir no es un m?ltiplo de la longitud del
> reemplazo6: In result[i - 1] <- bartlett.test(DATOS[, i] ~
> DATOS$Provincia) :  n?mero de items para para sustituir no es un
> m?ltiplo de la longitud del reemplazo7: In result[i - 1] <-
> bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  n?mero de items para
> para sustituir no es un m?ltiplo de la longitud del reemplazo
> 
> (Sorry, I have R in Spanish, n?mero de items para para sustituir no es
> un m?ltiplo de la longitud del reemplazo= number of items to replace is
> not a multiple of replacement length)
> 
> SO, I have changed a bit your code : result <- vector("list",
> ncol(datos))for( i in 2:ncol(datos)+1) {result [i-1] <-
> bartlett.test(datos[,i]~datos$Provincia))}And now R answer is:
> Error en model.frame.default(formula = datos[, i] ~ datos ~ Provincia)
> :  object is not a matrix.
> What can I do? Is it necessary that datos works as a matrix?
> Thanks in advance
> 
> 	[[alternative HTML version deleted]]


From jholtman at gmail.com  Mon Jul 22 12:50:17 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Mon, 22 Jul 2013 06:50:17 -0400
Subject: [R] problem loading large xlsx file into r
In-Reply-To: <8c04800ee65f4a05804ca18fa656e4a0@HKXPR03MB007.apcprd03.prod.outlook.com>
References: <65ca1cdc29254c4690e19329be44e96f@HKXPR03MB007.apcprd03.prod.outlook.com>
	<8ED09283-0C9A-4FE5-86EA-6C84D3AE549D@gmail.com>
	<8c04800ee65f4a05804ca18fa656e4a0@HKXPR03MB007.apcprd03.prod.outlook.com>
Message-ID: <F3CCE77E-E5B4-4C09-A41C-2F42ACB1B710@gmail.com>

did you try converting xlsx to xls (if possible).  the xlsx format puts a large demand on both memory and cpu resources.

Sent from my iPad

On Jul 22, 2013, at 6:09, S N V Krishna <krishna at primps.com.sg> wrote:

> Thanks Jim, I tried XLConnect but faced with same error.
> 
>> options(java.parameters = '-Xmx5g')
> 
>> library(XLConnect)
> Loading required package: rJava
> XLConnect 0.2-5 by Mirai Solutions GmbH
> http://www.mirai-solutions.com ,
> http://miraisolutions.wordpress.com
> 
>> cftc = readWorksheetFromFile("d:\\Krishna\\Research\\CFTC_COT\\cftcdata.xlsx", sheet = 'Sheet1')
> Error: OutOfMemoryError (Java): Java heap space
> 
> What is the maximum file size to load into R? is there a better way to load large excel files to R?
> 
> Many thanks for the help.
> 
> Regards, 
> 
> Krishna
> 
> -----Original Message-----
> From: Jim Holtman [mailto:jholtman at gmail.com] 
> Sent: Monday, July 22, 2013 5:10 PM
> To: S N V Krishna
> Cc: r-help at r-project.org
> Subject: Re: [R] problem loading large xlsx file into r
> 
> try the "XLConnect" package and if possible change the "xlsx" to "xls" format for better performance.
> 
> Sent from my iPad
> 
> On Jul 22, 2013, at 1:24, S N V Krishna <krishna at primps.com.sg> wrote:
> 
>> Hi,
>> 
>> I am facing trouble when trying to read large xlsx file into R. please find the code and error below. The file I was trying to read has 36,500 rows X 188 col, ~ 37 MB size.
>> 
>>> options( java.parameters = "-Xmx4g" )
>> 
>>> library(xlsx)
>> Loading required package: xlsxjars
>> Loading required package: rJava
>> 
>>> cftc = read.xlsx("d:\\Krishna\\Research\\CFTC_COT\\cftcdata.xlsx", 1)
>> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>> 
>> 
>>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> 
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United 
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
>> [5] LC_TIME=English_United States.1252
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] xlsx_0.5.1     xlsxjars_0.5.0 rJava_0.9-5
>> 
>> Many thanks for the help and guidance.
>> 
>> Regards,
>> 
>> Krishna
>> 
>>   [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From jholtman at gmail.com  Mon Jul 22 12:52:45 2013
From: jholtman at gmail.com (Jim Holtman)
Date: Mon, 22 Jul 2013 06:52:45 -0400
Subject: [R] Select csv files by choosing datetime
In-Reply-To: <1374482203999-4672023.post@n4.nabble.com>
References: <1374482203999-4672023.post@n4.nabble.com>
Message-ID: <64CAF40B-921E-4643-9D3D-FB96FC7B6A55@gmail.com>

you can use 'file.info' to get the date the file was created and then choose the file you want.

Sent from my iPad

On Jul 22, 2013, at 4:36, R_Antony <antony.akkara at ge.com> wrote:

> Hi,
> 
> how can we read particular files from a path ? - i mean, i need to read csv
> files which is created between two date and time. Here i need to get
> filename along with path.
> 
> Thanks,
> Antony.
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Select-csv-files-by-choosing-datetime-tp4672023.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Jose.Iparraguirre at ageuk.org.uk  Mon Jul 22 13:12:25 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Mon, 22 Jul 2013 11:12:25 +0000
Subject: [R] about mix type clust algorithm
In-Reply-To: <063B0F2850BFFB4CAB9E540AF2A9007E22D3625A@G2W2442.americas.hpqcorp.net>
References: <063B0F2850BFFB4CAB9E540AF2A9007E22D3625A@G2W2442.americas.hpqcorp.net>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B20249E7@AGEPXMB005.uk.age.local>

Dear Cheng,

This question exceeds the topics of this group. However, you may benefit from this recent (and excellent) paper along with the discussions:

Henning, C. and T. Liao (2013). "How to find an appropriate clustering for mixed-type variables with application to socio-economy stratification", Journal of Applied Statistics, Vol. 62, Part 3, pp. 309-369.

Regards,

Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK

Profesor de Econom?a
Universidad de Mor?n
Mor?n, Buenos Aires, Argentina


-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Cheng, Yi
Sent: 22 July 2013 07:23
To: r-help at r-project.org
Subject: [R] about mix type clust algorithm

Hi:
I have tried to find the appropriate clust algorithm for mixed type of data.
The suggested way I see is:

1.       use daisy to get the dissimilarity matrix

2.       use PAM/hclust by providing the dissimilarity matrix, to get the clusters
but by following this, when the data set grows bigger say 10,000 rows of data, the dissimilarity matrix will be O(n^2), and out of memory will occur.
I am wondering is there any better ways to do the mixed type cluster?

Cheng Yi


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From cecilia.carmo at ua.pt  Mon Jul 22 14:08:02 2013
From: cecilia.carmo at ua.pt (Cecilia Carmo)
Date: Mon, 22 Jul 2013 12:08:02 +0000
Subject: [R] 2sls and systemfit
Message-ID: <104083AE5AAA634C993249DFCCE4C2030FE6B277@CIPRESTE.ua.pt>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/50fa4416/attachment.pl>

From jrkrideau at inbox.com  Mon Jul 22 14:34:03 2013
From: jrkrideau at inbox.com (John Kane)
Date: Mon, 22 Jul 2013 04:34:03 -0800
Subject: [R] HELP R
In-Reply-To: <BAY172-W1773832052B73093600B4B96E0@phx.gbl>
References: <bay172-w29314114056b439ecc4673b96e0@phx.gbl>
Message-ID: <4ABD46D6CFC.000001E8jrkrideau@inbox.com>

Everything is a mess. Please don't post in HTML. The list removes all formatting and sends it as text.
Have a look at these links for some suggestions on how to ask a question here.
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: teresamarso at hotmail.com
> Sent: Mon, 22 Jul 2013 09:11:32 +0000
> To: r-help at r-project.org
> Subject: Re: [R] HELP R
> 
> 
> 
> 
> 
> 
> 
> 
> Hi, I did what you have told me but I can not do it well,
> NUMERO Provincia CENAES   IE.2005   IE.2006   IE.2007  IE.2008
> 29    183  Alicante          7711    42.000    46.000    55.000
> 47.00030    479  Alicante          8299  1158.000   476.000   503.000
> 300.00031    591  Alicante          8129   540.000   764.000  1037.000
> 938.00032   1429  Alicante          8219  5233.000  6234.000  4659.000
> 2212.00033   2681  Alicante          8299    17.000     8.000    10.000
> 9.00034   3374  Alicante          8299   346.000   416.000   343.000
> 330.00035   5341  Alicante          8299  1198.000  1531.000   235.000
> 0.00036   5772  Alicante          7732   709.000   689.000   584.000
> 419.00037   6127  Alicante          7711   225.000   125.000   175.000
> 71.00038   6132  Alicante          7711  1084.000   634.000   592.000
> 291.00039   6133  Alicante          7711  5143.000  5838.000  7136.000
> 7835.00040   6134  Alicante          7711   327.000   394.000   442.000
> 331.00041   6138  Alicante          7739   301.000   341.000   408.000
> 470.00042   6140  Alicante          7732   274.000   483.000   468.000
> 280.000...56    337  Valencia          7911   261.000   623.000  1302.000
> 1487.00057    772  Valencia          7911   163.000   178.000   192.000
> 127.00058   1082  Valencia          7739   399.000   528.000   778.000
> 758.00059   1628  Valencia          8130   269.000   353.000   396.000
> 486.00060   1645  Valencia          7739   848.000  1015.000  1217.000
> 876.00061   1960  Valencia          8110   168.000   180.000   205.000
> 235.00062   2415  Valencia          7911   221.000   139.000   110.000
> 184.00063   2416  Valencia          7911   262.000   265.000   296.000
> 207.00064   2446  Valencia          8299    44.000   193.000   337.000
> 415.00065   3485  Valencia          8122   880.000   726.000   774.000
> 1081.00066   4053  Valencia          8130   243.000   649.000   880.000
> 734.00067   5566  Valencia          8299   325.000   767.000    97.000
> 158.00068   5779  Valencia          7739   298.000   356.000   344.000
> 348.00069   6167  Valencia          7711  2483.000  2461.000  2363.000
> 1915.000....
> This is the code that you have told meresult <- vector("list",
> ncol(datos))for( i in 2:ncol(datos) {result [i-1] <-
> bartlett.test(datos[,i]~datos$Provincia))}
> This is what I get Error en `[.data.frame`(DATOS, , i) : undefined
> columns selectedAdemas: Mensajes de aviso perdidos1: In result[i - 1] <-
> bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  nzmero de items para para
> sustituir no es un mzltiplo de la longitud del reemplazo2: In result[i -
> 1] <- bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  nzmero de items para
> para sustituir no es un mzltiplo de la longitud del reemplazo3: In
> result[i - 1] <- bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  nzmero de
> items para para sustituir no es un mzltiplo de la longitud del
> reemplazo4: In result[i - 1] <- bartlett.test(DATOS[, i] ~
> DATOS$Provincia) :  nzmero de items para para sustituir no es un mzltiplo
> de la longitud del reemplazo5: In result[i - 1] <- bartlett.test(DATOS[,
> i] ~ DATOS$Provincia) :  nzmero de items para para sustituir no es un
> mzltiplo de la longitud del reemplazo6: In result[i - 1] <-
> bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  nzmero de items para para
> sustituir no es un mzltiplo de la longitud del reemplazo7: In result[i -
> 1] <- bartlett.test(DATOS[, i] ~ DATOS$Provincia) :  nzmero de items para
> para sustituir no es un mzltiplo de la longitud del reemplazo
> 
> (Sorry, I have R in Spanish, nzmero de items para para sustituir no es un
> mzltiplo de la longitud del reemplazo= number of items to replace is not
> a multiple of replacement length)
> 
> SO, I have changed a bit your code : result <- vector("list",
> ncol(datos))for( i in 2:ncol(datos)+1) {result [i-1] <-
> bartlett.test(datos[,i]~datos$Provincia))}And now R answer is:
> Error en model.frame.default(formula = datos[, i] ~ datos ~ Provincia) :
> object is not a matrix.
> What can I do? Is it necessary that datos works as a matrix?
> Thanks in advance
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From petr.pikal at precheza.cz  Mon Jul 22 14:45:03 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Mon, 22 Jul 2013 12:45:03 +0000
Subject: [R] Calculate interaction for a big dataframe
In-Reply-To: <51ECF3CF.9030807@cirad.fr>
References: <51ECF3CF.9030807@cirad.fr>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7F0DD@SRVEXCHMBX.precheza.cz>

Hi

you maybe could use paste

> f1<-sample(letters[1:3], 10, replace=T)
> f2<-sample(letters[4:7], 10, replace=T)
> f3<-sample(letters[9:11], 10, replace=T)
> interaction(f1, f2, f3, drop=T)
 [1] c.e.j b.e.j a.e.j c.g.i a.f.j b.g.k a.e.i a.e.k a.d.j b.e.j
Levels: a.e.i c.g.i a.d.j a.e.j b.e.j c.e.j a.f.j a.e.k b.g.k
> paste(f1, f2, f3, sep=".")
 [1] "c.e.j" "b.e.j" "a.e.j" "c.g.i" "a.f.j" "b.g.k" "a.e.i" "a.e.k" "a.d.j"
[10] "b.e.j"

The difference is that interaction gives you directly factor, paste gives you character vector, but it may be convenient too for your purpose.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Arnaud Michel
> Sent: Monday, July 22, 2013 10:57 AM
> To: R help
> Subject: [R] Calculate interaction for a big dataframe
> 
> Hi
> 
> To calculate the value of the interaction between factors of a
> dataframe df, does exist any function which could replace the function
> when the dataframe df has the numbers of rows of df is large (~55000)
> and also the numbers of combinaison of the three factors is large. The
> calcul abort.
> The function to calculate the interaction is :
> as.numeric(interaction(df [,c(1:3)],drop=TRUE))
> 
> To complete the question and to calculate interaction beetween 3
> factors f1, f2, f3, does it possible to calculate first f12 =
> interaction
> (f1,f2) and after calculate interaction (f12, f3).
> It seems to me that yes.
> 
> Thanks for your help
> 
> 
> 
> 
> --
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bsmith030465 at gmail.com  Mon Jul 22 15:12:06 2013
From: bsmith030465 at gmail.com (Brian Smith)
Date: Mon, 22 Jul 2013 09:12:06 -0400
Subject: [R] about mix type clust algorithm
In-Reply-To: <5F8EC5C77B9AE547A8959F690F04C7B20249E7@AGEPXMB005.uk.age.local>
References: <063B0F2850BFFB4CAB9E540AF2A9007E22D3625A@G2W2442.americas.hpqcorp.net>
	<5F8EC5C77B9AE547A8959F690F04C7B20249E7@AGEPXMB005.uk.age.local>
Message-ID: <CAEQKoCEXm2dK0xsvtakkhck+D5BW349TcKFsePAiKqen6K7ocw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/fe944299/attachment.pl>

From jose at memo2.nl  Mon Jul 22 15:31:25 2013
From: jose at memo2.nl (=?ISO-8859-1?Q?Jos=E9_Verhoeven?=)
Date: Mon, 22 Jul 2013 15:31:25 +0200
Subject: [R] Why does impulse response function of VAR starts at zero and
	not at one?
Message-ID: <CAEaKQwW_u9ettAUw9r1QyH4np-FhxnJy6S5d=O8mLCuK_TkAMg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/b007be91/attachment.pl>

From info at software-solutions.nl  Mon Jul 22 13:18:05 2013
From: info at software-solutions.nl (Dark)
Date: Mon, 22 Jul 2013 04:18:05 -0700 (PDT)
Subject: [R] Saving multiple rda-files as one rda-file
Message-ID: <1374491885996-4672041.post@n4.nabble.com>

Hi all,

For a project we have to process some very large CSV files (up to 40 gig)
To reduce them in size and increase operating performance I wanted to store
them as RData files.
Since it was to big I decided to split the csv and saving those parts as
separate .RDA files.
So far so good. Now I want to bind them all together to save as one RDA file
again and this is supprisingly difficult.

First I load my rda files into my environment:
load(paste(rdaoutputdir, "file1.rda", sep=""))
load(paste(rdaoutputdir, "file2.rda", sep=""))
load(paste(rdaoutputdir, "file3.rda", sep=""))
etc

Then I try to combine them into one object.

Using rbind like this gives memory allocation problems ('Error: cannot
allocate vector of size')
objectToSave <- rbind(object1, object2, object3)

using pre-allocation gives me a factor level error. I used this code:
	nextrow <- nrow(object1)+1
	object1[nextrow:(nextrow+nrow(object2)-1),] <- object2
	# we need to assure unique row names
        row.names(object1) = 1:nrow(object1)
	rm(object2)
        gc()

15! warning messages:
1: In `[<-.factor`(`*tmp*`, iseq, value = structure(c(1L,  ... :
  invalid factor level, NA generated
2: In `[<-.factor`(`*tmp*`, iseq, value = structure(c(1L,  ... :
  invalid factor level, NA generated

What can I do?

Regards Derk



--
View this message in context: http://r.789695.n4.nabble.com/Saving-multiple-rda-files-as-one-rda-file-tp4672041.html
Sent from the R help mailing list archive at Nabble.com.


From dennis1991 at gmx.net  Mon Jul 22 16:09:15 2013
From: dennis1991 at gmx.net (dennis1991 at gmx.net)
Date: Mon, 22 Jul 2013 16:09:15 +0200 (CEST)
Subject: [R] How to split two levels several times?
Message-ID: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>

Hi,

I have a small problem with the function split() and would appreciate your help.

I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows belong to 8 different levels (electrode1, ...,electrode8). I want to split the table always at the row where ?electrode1? starts again so that I can export 7  individual dataframes (numbered ?dataframe1? to ?dataframe7?) which contain always electrode1 as first level (always three rows) with the varying number of rows for electrodes2-8 below.
I tried the split function with various setups:

t <- as.factor(XXX$electrode)

dataframeX <- split(XXX, f=(levels=t))

But this doesn?t work. Could you please help. Thank you! Dennis


This is the table "XXX"

electrode	length

electrode1	5.7
electrode1	6.3
electrode1	6.2
electrode2	11.4
electrode2	9.7
electrode1	5.7
electrode1	6.3
electrode1	6.2
electrode3	14.2
electrode3	14.8
electrode3	12.6
electrode1	5.7
electrode1	6.3
electrode1	6.2
electrode4	17.0
electrode4	16.3
electrode4	17.8
electrode4	18.3
electrode4	16.9
electrode4	18.5
electrode1	....
....		....
electrode5	....
....		....
electrode1	....
electrode6	....
electrode1	....
electrode7	....
electrode1	....
electrode8	....


From sa.filahi at gmail.com  Mon Jul 22 16:44:23 2013
From: sa.filahi at gmail.com (Said Filahi)
Date: Mon, 22 Jul 2013 15:44:23 +0100
Subject: [R] kandell
Message-ID: <CABNiEm=v6vrsE_4T76uuO5LLNM-+j=pkKKr6Rh+SzbdBGoa7cw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/1cf93da6/attachment.pl>

From michel.arnaud at cirad.fr  Mon Jul 22 17:41:05 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Mon, 22 Jul 2013 17:41:05 +0200
Subject: [R] Calculate interaction for a big dataframe
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7F0DD@SRVEXCHMBX.precheza.cz>
References: <51ECF3CF.9030807@cirad.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7F0DD@SRVEXCHMBX.precheza.cz>
Message-ID: <51ED5291.6010405@cirad.fr>

Thank you Petr
paste is better than interaction for long vectors
But now a new problem/question is appeared.
Now, I would like transform the vector
v1 <- c(
"4162.France", "4162.France", "4162.France",
"4162.Mali", "4162.Mali",
"4162.France", "4162.France", "4162.France", "4162.France",
"4162.Mali")
into a vector V2 with the same length but with number which are creasing
v2 <- c(1,     1,    1,
2, 2,
3, 3,3,3,
4))

Any idea (function) ?
Regards


Le 22/07/2013 14:45, PIKAL Petr a ?crit :
> Hi
>
> you maybe could use paste
>
>> f1<-sample(letters[1:3], 10, replace=T)
>> f2<-sample(letters[4:7], 10, replace=T)
>> f3<-sample(letters[9:11], 10, replace=T)
>> interaction(f1, f2, f3, drop=T)
>   [1] c.e.j b.e.j a.e.j c.g.i a.f.j b.g.k a.e.i a.e.k a.d.j b.e.j
> Levels: a.e.i c.g.i a.d.j a.e.j b.e.j c.e.j a.f.j a.e.k b.g.k
>> paste(f1, f2, f3, sep=".")
>   [1] "c.e.j" "b.e.j" "a.e.j" "c.g.i" "a.f.j" "b.g.k" "a.e.i" "a.e.k" "a.d.j"
> [10] "b.e.j"
>
> The difference is that interaction gives you directly factor, paste gives you character vector, but it may be convenient too for your purpose.
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Arnaud Michel
>> Sent: Monday, July 22, 2013 10:57 AM
>> To: R help
>> Subject: [R] Calculate interaction for a big dataframe
>>
>> Hi
>>
>> To calculate the value of the interaction between factors of a
>> dataframe df, does exist any function which could replace the function
>> when the dataframe df has the numbers of rows of df is large (~55000)
>> and also the numbers of combinaison of the three factors is large. The
>> calcul abort.
>> The function to calculate the interaction is :
>> as.numeric(interaction(df [,c(1:3)],drop=TRUE))
>>
>> To complete the question and to calculate interaction beetween 3
>> factors f1, f2, f3, does it possible to calculate first f12 =
>> interaction
>> (f1,f2) and after calculate interaction (f12, f3).
>> It seems to me that yes.
>>
>> Thanks for your help
>>
>>
>>
>>
>> --
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From sarah.goslee at gmail.com  Mon Jul 22 17:42:56 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Mon, 22 Jul 2013 11:42:56 -0400
Subject: [R] kandell
In-Reply-To: <CABNiEm=v6vrsE_4T76uuO5LLNM-+j=pkKKr6Rh+SzbdBGoa7cw@mail.gmail.com>
References: <CABNiEm=v6vrsE_4T76uuO5LLNM-+j=pkKKr6Rh+SzbdBGoa7cw@mail.gmail.com>
Message-ID: <CAM_vjunqGqtR_DFqp+5Ka5tMZpp_gPDuUZTOkRj3F5d2vRjGDA@mail.gmail.com>

Hi,

It's entirely possible you want the Kendall package, which you can
install from CRAN in the way you'd install any package (see
?install.packages for more), but searching for

kendall climate trend

at www.rseek.org suggests various other possibilities.

Sarah

On Mon, Jul 22, 2013 at 10:44 AM, Said Filahi <sa.filahi at gmail.com> wrote:
> hello,
> I want to use kendall to calculate climate trends. I want to know how to
> install this software on R
>
> Thanks
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ruipbarradas at sapo.pt  Mon Jul 22 17:47:24 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 22 Jul 2013 16:47:24 +0100
Subject: [R] How to split two levels several times?
In-Reply-To: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
Message-ID: <51ED540C.1000303@sapo.pt>

Hello,

Try the following.


idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
split(dat, idx)


Hope this helps,

Rui Barradas

Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
> Hi,
>
> I have a small problem with the function split() and would appreciate your help.
>
> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows belong to 8 different levels (electrode1, ...,electrode8). I want to split the table always at the row where ?electrode1? starts again so that I can export 7  individual dataframes (numbered ?dataframe1? to ?dataframe7?) which contain always electrode1 as first level (always three rows) with the varying number of rows for electrodes2-8 below.
> I tried the split function with various setups:
>
> t <- as.factor(XXX$electrode)
>
> dataframeX <- split(XXX, f=(levels=t))
>
> But this doesn?t work. Could you please help. Thank you! Dennis
>
>
> This is the table "XXX"
>
> electrode	length
>
> electrode1	5.7
> electrode1	6.3
> electrode1	6.2
> electrode2	11.4
> electrode2	9.7
> electrode1	5.7
> electrode1	6.3
> electrode1	6.2
> electrode3	14.2
> electrode3	14.8
> electrode3	12.6
> electrode1	5.7
> electrode1	6.3
> electrode1	6.2
> electrode4	17.0
> electrode4	16.3
> electrode4	17.8
> electrode4	18.3
> electrode4	16.9
> electrode4	18.5
> electrode1	....
> ....		....
> electrode5	....
> ....		....
> electrode1	....
> electrode6	....
> electrode1	....
> electrode7	....
> electrode1	....
> electrode8	....
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Mon Jul 22 17:52:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 22 Jul 2013 08:52:05 -0700 (PDT)
Subject: [R] Calculate interaction for a big dataframe
In-Reply-To: <51ED5291.6010405@cirad.fr>
References: <51ECF3CF.9030807@cirad.fr>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7F0DD@SRVEXCHMBX.precheza.cz>
	<51ED5291.6010405@cirad.fr>
Message-ID: <1374508325.22362.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
You could try:
?cumsum(c(1,abs(diff(as.numeric(factor(v1))))))
# [1] 1 1 1 2 2 3 3 3 3 4
A.K.




----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: PIKAL Petr <petr.pikal at precheza.cz>
Cc: R help <r-help at r-project.org>
Sent: Monday, July 22, 2013 11:41 AM
Subject: Re: [R] Calculate interaction for a big dataframe

Thank you Petr
paste is better than interaction for long vectors
But now a new problem/question is appeared.
Now, I would like transform the vector
v1 <- c(
"4162.France", "4162.France", "4162.France",
"4162.Mali", "4162.Mali",
"4162.France", "4162.France", "4162.France", "4162.France",
"4162.Mali")
into a vector V2 with the same length but with number which are creasing
v2 <- c(1,? ?  1,? ? 1,
2, 2,
3, 3,3,3,
4))

Any idea (function) ?
Regards


Le 22/07/2013 14:45, PIKAL Petr a ?crit :
> Hi
>
> you maybe could use paste
>
>> f1<-sample(letters[1:3], 10, replace=T)
>> f2<-sample(letters[4:7], 10, replace=T)
>> f3<-sample(letters[9:11], 10, replace=T)
>> interaction(f1, f2, f3, drop=T)
>?  [1] c.e.j b.e.j a.e.j c.g.i a.f.j b.g.k a.e.i a.e.k a.d.j b.e.j
> Levels: a.e.i c.g.i a.d.j a.e.j b.e.j c.e.j a.f.j a.e.k b.g.k
>> paste(f1, f2, f3, sep=".")
>?  [1] "c.e.j" "b.e.j" "a.e.j" "c.g.i" "a.f.j" "b.g.k" "a.e.i" "a.e.k" "a.d.j"
> [10] "b.e.j"
>
> The difference is that interaction gives you directly factor, paste gives you character vector, but it may be convenient too for your purpose.
>
> Regards
> Petr
>
>
>> -----Original Message-----
>> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
>> project.org] On Behalf Of Arnaud Michel
>> Sent: Monday, July 22, 2013 10:57 AM
>> To: R help
>> Subject: [R] Calculate interaction for a big dataframe
>>
>> Hi
>>
>> To calculate the value of the interaction between factors of a
>> dataframe df, does exist any function which could replace the function
>> when the dataframe df has the numbers of rows of df is large (~55000)
>> and also the numbers of combinaison of the three factors is large. The
>> calcul abort.
>> The function to calculate the interaction is :
>> as.numeric(interaction(df [,c(1:3)],drop=TRUE))
>>
>> To complete the question and to calculate interaction beetween 3
>> factors f1, f2, f3, does it possible to calculate first f12 =
>> interaction
>> (f1,f2) and after calculate interaction (f12, f3).
>> It seems to me that yes.
>>
>> Thanks for your help
>>
>>
>>
>>
>> --
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-
>> guide.html
>> and provide commented, minimal, self-contained, reproducible code.

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Mon Jul 22 17:53:23 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 22 Jul 2013 16:53:23 +0100
Subject: [R] How to split two levels several times?
In-Reply-To: <51ED540C.1000303@sapo.pt>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>
Message-ID: <51ED5573.9040303@sapo.pt>

Hello,

Sorry, I've just realized that your data frame is named 'XXX', not 
'dat'. Change that and the rest should work:


idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
split(XXX, idx)


Rui Barradas

Em 22-07-2013 16:47, Rui Barradas escreveu:
> Hello,
>
> Try the following.
>
>
> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
> split(dat, idx)
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
>> Hi,
>>
>> I have a small problem with the function split() and would appreciate
>> your help.
>>
>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
>> belong to 8 different levels (electrode1, ...,electrode8). I want to
>> split the table always at the row where ?electrode1? starts again so
>> that I can export 7  individual dataframes (numbered ?dataframe1? to
>> ?dataframe7?) which contain always electrode1 as first level (always
>> three rows) with the varying number of rows for electrodes2-8 below.
>> I tried the split function with various setups:
>>
>> t <- as.factor(XXX$electrode)
>>
>> dataframeX <- split(XXX, f=(levels=t))
>>
>> But this doesn?t work. Could you please help. Thank you! Dennis
>>
>>
>> This is the table "XXX"
>>
>> electrode    length
>>
>> electrode1    5.7
>> electrode1    6.3
>> electrode1    6.2
>> electrode2    11.4
>> electrode2    9.7
>> electrode1    5.7
>> electrode1    6.3
>> electrode1    6.2
>> electrode3    14.2
>> electrode3    14.8
>> electrode3    12.6
>> electrode1    5.7
>> electrode1    6.3
>> electrode1    6.2
>> electrode4    17.0
>> electrode4    16.3
>> electrode4    17.8
>> electrode4    18.3
>> electrode4    16.9
>> electrode4    18.5
>> electrode1    ....
>> ....        ....
>> electrode5    ....
>> ....        ....
>> electrode1    ....
>> electrode6    ....
>> electrode1    ....
>> electrode7    ....
>> electrode1    ....
>> electrode8    ....
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Jul 22 18:12:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 22 Jul 2013 09:12:47 -0700 (PDT)
Subject: [R] How to split two levels several times?
In-Reply-To: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
Message-ID: <1374509567.10631.YahooMailNeo@web142606.mail.bf1.yahoo.com>

May be this helps:


?split(XXX,cumsum(c(TRUE,diff(as.numeric(XXX$electrode))<0)))
A.K.



----- Original Message -----
From: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
To: r-help at r-project.org
Cc: 
Sent: Monday, July 22, 2013 10:09 AM
Subject: [R] How to split two levels several times?

Hi,

I have a small problem with the function split() and would appreciate your help.

I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows belong to 8 different levels (electrode1, ...,electrode8). I want to split the table always at the row where ?electrode1? starts again so that I can export 7? individual dataframes (numbered ?dataframe1? to ?dataframe7?) which contain always electrode1 as first level (always three rows) with the varying number of rows for electrodes2-8 below.
I tried the split function with various setups:

t <- as.factor(XXX$electrode)

dataframeX <- split(XXX, f=(levels=t))

But this doesn?t work. Could you please help. Thank you! Dennis


This is the table "XXX"

electrode??? length

electrode1??? 5.7
electrode1??? 6.3
electrode1??? 6.2
electrode2??? 11.4
electrode2??? 9.7
electrode1??? 5.7
electrode1??? 6.3
electrode1??? 6.2
electrode3??? 14.2
electrode3??? 14.8
electrode3??? 12.6
electrode1??? 5.7
electrode1??? 6.3
electrode1??? 6.2
electrode4??? 17.0
electrode4??? 16.3
electrode4??? 17.8
electrode4??? 18.3
electrode4??? 16.9
electrode4??? 18.5
electrode1??? ....
....??? ??? ....
electrode5??? ....
....??? ??? ....
electrode1??? ....
electrode6??? ....
electrode1??? ....
electrode7??? ....
electrode1??? ....
electrode8??? ....

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From geyu625 at gmail.com  Mon Jul 22 20:00:51 2013
From: geyu625 at gmail.com (yu ge)
Date: Mon, 22 Jul 2013 13:00:51 -0500
Subject: [R] fail to install shiny package in R 3.0.1 on Ubuntu
Message-ID: <CABzXcyhXguKeUxpft35u2gZeh8ML2-x0YPg=Lm88wM4qaSjoaw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/b6cef528/attachment.pl>

From dwinsemius at comcast.net  Mon Jul 22 20:25:15 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Jul 2013 11:25:15 -0700
Subject: [R] Y label doesn't show up on printing files
In-Reply-To: <CAGkgU9WqQnRXaoqCMjcaHbAa0WGPn4cfKENQsKQ35jePZssPoQ@mail.gmail.com>
References: <CAGkgU9WqQnRXaoqCMjcaHbAa0WGPn4cfKENQsKQ35jePZssPoQ@mail.gmail.com>
Message-ID: <DE1C512A-D9F0-4B53-9103-827C6378AD47@comcast.net>


On Jul 22, 2013, at 3:17 AM, Mohit Dhingra wrote:

> Hello,
> 
> I'm using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" .
> 
> System info: Linux ubuntu 3.5.0-36-generic #57~precise1-Ubuntu SMP Thu
> Jun 20 18:21:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux.
> 
> When I plot something, y label does show up on the pop up image.
> plot (x, rtimel[,2] , xlab="Memory Allocated (in MB)", ylab="Response
> Time (in ms)", type="l", col="black", ylim=c(0,m) )
> 
> But when I try to save it using
> dev.copy(pdf,'response_time_with_memory_direct.pdf')
> dev.off()
> 
> Y-label doesn't get printed on the pdf file. Can someone please help?

Perhaps a difficulty with the fonts in your R installation being different than the fonts in your pdf viewer?

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Jul 22 20:36:25 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Jul 2013 11:36:25 -0700
Subject: [R] problem loading large xlsx file into r
In-Reply-To: <8c04800ee65f4a05804ca18fa656e4a0@HKXPR03MB007.apcprd03.prod.outlook.com>
References: <65ca1cdc29254c4690e19329be44e96f@HKXPR03MB007.apcprd03.prod.outlook.com>
	<8ED09283-0C9A-4FE5-86EA-6C84D3AE549D@gmail.com>
	<8c04800ee65f4a05804ca18fa656e4a0@HKXPR03MB007.apcprd03.prod.outlook.com>
Message-ID: <4E934AE6-CFEE-41CD-9510-F0E16E1D9A76@comcast.net>


On Jul 22, 2013, at 3:09 AM, S N V Krishna wrote:

> Thanks Jim, I tried XLConnect but faced with same error.
> 
>> options(java.parameters = '-Xmx5g')
> 
>> library(XLConnect)
> Loading required package: rJava
> XLConnect 0.2-5 by Mirai Solutions GmbH
> http://www.mirai-solutions.com ,
> http://miraisolutions.wordpress.com
> 
>> cftc = readWorksheetFromFile("d:\\Krishna\\Research\\CFTC_COT\\cftcdata.xlsx", sheet = 'Sheet1')
> Error: OutOfMemoryError (Java): Java heap space

This is an error that is coming from you Java installation, not from R. You may need to investigate modifying your Java environment variables. This might not be the correct mailing list from which to expect advice on Java setup although I seem to rememer seeing advice of this sort offered in the past. Have you done a search of the Rhelp archives?

-- 
David.

> 
> What is the maximum file size to load into R? is there a better way to load large excel files to R?
> 
> Many thanks for the help.
> 
> Regards, 
> 
> Krishna
> 
> -----Original Message-----
> From: Jim Holtman [mailto:jholtman at gmail.com] 
> Sent: Monday, July 22, 2013 5:10 PM
> To: S N V Krishna
> Cc: r-help at r-project.org
> Subject: Re: [R] problem loading large xlsx file into r
> 
> try the "XLConnect" package and if possible change the "xlsx" to "xls" format for better performance.
> 
> Sent from my iPad
> 
> On Jul 22, 2013, at 1:24, S N V Krishna <krishna at primps.com.sg> wrote:
> 
>> Hi,
>> 
>> I am facing trouble when trying to read large xlsx file into R. please find the code and error below. The file I was trying to read has 36,500 rows X 188 col, ~ 37 MB size.
>> 
>>> options( java.parameters = "-Xmx4g" )
>> 
>>> library(xlsx)
>> Loading required package: xlsxjars
>> Loading required package: rJava
>> 
>>> cftc = read.xlsx("d:\\Krishna\\Research\\CFTC_COT\\cftcdata.xlsx", 1)
>> Error in .jcall("RJavaTools", "Ljava/lang/Object;", "invokeMethod", cl,  :
>> 
>> 
>>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> 
>> locale:
>> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United 
>> States.1252 [3] LC_MONETARY=English_United States.1252 LC_NUMERIC=C 
>> [5] LC_TIME=English_United States.1252
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] xlsx_0.5.1     xlsxjars_0.5.0 rJava_0.9-5
>> 
>> Many thanks for the help and guidance.
>> 
>> Regards,
>> 
>> Krishna
>> 
>>   [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Mon Jul 22 20:43:20 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Jul 2013 11:43:20 -0700
Subject: [R] about mix type clust algorithm
In-Reply-To: <5F8EC5C77B9AE547A8959F690F04C7B20249E7@AGEPXMB005.uk.age.local>
References: <063B0F2850BFFB4CAB9E540AF2A9007E22D3625A@G2W2442.americas.hpqcorp.net>
	<5F8EC5C77B9AE547A8959F690F04C7B20249E7@AGEPXMB005.uk.age.local>
Message-ID: <C0FC4C68-C3A0-4DAF-AC90-6EB921422494@comcast.net>


On Jul 22, 2013, at 4:12 AM, Jose Iparraguirre wrote:

> Dear Cheng,
> 
> This question exceeds the topics of this group. However, you may benefit from this recent (and excellent) paper along with the discussions:
> 
> Henning, C. and T. Liao (2013). "How to find an appropriate clustering for mixed-type variables with application to socio-economy stratification", Journal of Applied Statistics, Vol. 62, Part 3, pp. 309-369.
> 

Might be easier to find with the correct author citation:

C. Hennig and T. F. Liao

The first author makes a copy available at his website;
http://www.homepages.ucl.ac.uk/~ucakche/pp.html

-- 
David.
> Regards,
> 
> Jos?
> 
> Prof. Jos? Iparraguirre
> Chief Economist
> Age UK
> 
> Profesor de Econom?a
> Universidad de Mor?n
> Mor?n, Buenos Aires, Argentina
> 
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Cheng, Yi
> Sent: 22 July 2013 07:23
> To: r-help at r-project.org
> Subject: [R] about mix type clust algorithm
> 
> Hi:
> I have tried to find the appropriate clust algorithm for mixed type of data.
> The suggested way I see is:
> 
> 1.       use daisy to get the dissimilarity matrix
> 
> 2.       use PAM/hclust by providing the dissimilarity matrix, to get the clusters
> but by following this, when the data set grows bigger say 10,000 rows of data, the dissimilarity matrix will be O(n^2), and out of memory will occur.
> I am wondering is there any better ways to do the mixed type cluster?
> 
> Cheng Yi
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> The Wireless from Age UK | Radio for grown-ups.
> 
> www.ageuk.org.uk/thewireless
> 
> 
> If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
> Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.
> 
> 
> 
> 
> -------------------------------
> Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
> Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.
> 
> For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
> Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
> cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
> regulated by the Financial Services Authority. 
> ------------------------------
> 
> This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
> addressed. If you receive a message in error, please advise the sender and delete immediately.
> 
> Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
> necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
> through its network and may block or modify mails which are deemed to be unsuitable.
> 
> Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
> on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
> Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
> Age Scotland, Age NI, Age Cymru.
> 
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From orvaquim at gmail.com  Mon Jul 22 21:26:06 2013
From: orvaquim at gmail.com (Orvalho Augusto)
Date: Mon, 22 Jul 2013 21:26:06 +0200
Subject: [R] fail to install shiny package in R 3.0.1 on Ubuntu
In-Reply-To: <CABzXcyhXguKeUxpft35u2gZeh8ML2-x0YPg=Lm88wM4qaSjoaw@mail.gmail.com>
References: <CABzXcyhXguKeUxpft35u2gZeh8ML2-x0YPg=Lm88wM4qaSjoaw@mail.gmail.com>
Message-ID: <CAF4WX-fY08XR1Wt_36fWE+hzD++_G6-OPL-x7yN1xFnmfXHF4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/253b642e/attachment.pl>

From iza.ch1 at op.pl  Mon Jul 22 21:11:02 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Mon, 22 Jul 2013 21:11:02 +0200
Subject: [R] create data frame with coefficients from many regressions
Message-ID: <20934730-e25602e74e4b963d22e0772de144bd6d@pmq2v.m5r2.onet>


> Hi !
> 
> I want to ask if somebody knows the way to create data frame with coefficients from many regressions 
> I regress the first column from ret against the first columns from median, then the second with the second and so on.
> This is the code used for regression
> 
> i<-1:6
> lapply(seq_len(ncol(ret)),function(i) {lm(ret[,i]~median[,i])}
> 
> I get 6 results for each regression 
> 
> [[1]]
> 
> Call:
> lm(formula = ret[, i] ~ median[, i])
> 
> Coefficients:
> (Intercept)  median[, i]  
>           0            1  
> 
> 
> [[2]]
> 
> Call:
> lm(formula = ret[, i] ~ median[, i])
> 
> Coefficients:
> (Intercept)  median[, i]  
> -1.411e-17    1.000e+00 
> 
> now I would like to create a data frame with intercepts which looks like it
> 
>                         [[1]]          [[2]]
> Intercept
> median
> 
> I tried to use ddply command but it does not work. I will be very grateful for the hint :)
> 
> Thank you in advance
> 
> 

From smartpink111 at yahoo.com  Mon Jul 22 22:18:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 22 Jul 2013 13:18:36 -0700 (PDT)
Subject: [R] create data frame with coefficients from many regressions
In-Reply-To: <20934730-e25602e74e4b963d22e0772de144bd6d@pmq2v.m5r2.onet>
References: <20934730-e25602e74e4b963d22e0772de144bd6d@pmq2v.m5r2.onet>
Message-ID: <1374524316.16316.YahooMailNeo@web142601.mail.bf1.yahoo.com>

set.seed(28)
dat1<- as.data.frame(matrix(sample(1:20,100,replace=TRUE),ncol=10))

set.seed(49)
dat2<- as.data.frame(matrix(sample(40:80,100,replace=TRUE),ncol=10))

?sapply(seq_len(ncol(dat1)),function(i) {x1<- summary(lm(dat2[,i]~dat1[,i]));x1$coef[,1]})
#????????????????? [,1]?????? [,2]?????? [,3]?????? [,4]?????? [,5]????? [,6]
#(Intercept) 50.3768788 53.5300207 65.2972973 55.6530015 58.5158172 79.368165
#dat1[, i]??? 0.4770829? 0.2767426 -0.4554849? 0.3089312? 0.7785589 -1.193601
#????????????????? [,7]????? [,8]????? [,9]?????? [,10]
#(Intercept) 59.8130393 67.089662 74.593072 66.39938809
#dat1[, i]?? -0.4659636 -1.498945 -1.221709? 0.05624853
?
as.data.frame(sapply(seq_len(ncol(dat1)),function(i) {x1<- summary(lm(dat2[,i]~dat1[,i]));x1$coef[,1]}))


A.K.




----- Original Message -----
From: iza.ch1 <iza.ch1 at op.pl>
To: r-help at r-project.org
Cc: 
Sent: Monday, July 22, 2013 3:11 PM
Subject: [R] create data frame with coefficients from many regressions


> Hi !
> 
> I want to ask if somebody knows the way to create data frame with coefficients from many regressions 
> I regress the first column from ret against the first columns from median, then the second with the second and so on.
> This is the code used for regression
> 
> i<-1:6
> lapply(seq_len(ncol(ret)),function(i) {lm(ret[,i]~median[,i])}
> 
> I get 6 results for each regression 
> 
> [[1]]
> 
> Call:
> lm(formula = ret[, i] ~ median[, i])
> 
> Coefficients:
> (Intercept)? median[, i]? 
>? ? ? ? ?  0? ? ? ? ? ? 1? 
> 
> 
> [[2]]
> 
> Call:
> lm(formula = ret[, i] ~ median[, i])
> 
> Coefficients:
> (Intercept)? median[, i]? 
> -1.411e-17? ? 1.000e+00 
> 
> now I would like to create a data frame with intercepts which looks like it
> 
>? ? ? ? ? ? ? ? ? ? ? ?  [[1]]? ? ? ? ? [[2]]
> Intercept
> median
> 
> I tried to use ddply command but it does not work. I will be very grateful for the hint :)
> 
> Thank you in advance
> 
> 
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ruipbarradas at sapo.pt  Mon Jul 22 23:04:23 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 22 Jul 2013 22:04:23 +0100
Subject: [R] create data frame with coefficients from many regressions
In-Reply-To: <20934730-e25602e74e4b963d22e0772de144bd6d@pmq2v.m5r2.onet>
References: <20934730-e25602e74e4b963d22e0772de144bd6d@pmq2v.m5r2.onet>
Message-ID: <51ED9E57.1040409@sapo.pt>

Hello,

Using Arun's data example, you can also do the following.



set.seed(28)
dat1<- as.data.frame(matrix(sample(1:20,100,replace=TRUE),ncol=10))

set.seed(49)
dat2<- as.data.frame(matrix(sample(40:80,100,replace=TRUE),ncol=10))

lm.list <- lapply(seq_len(ncol(dat1)), function(i) lm(dat1[,i] ~ dat2[,i]))

do.call(cbind, lapply(lm.list, coef))   # object of class "matrix"


Hope this helps,

Rui Barradas


Em 22-07-2013 20:11, iza.ch1 escreveu:
>
>> Hi !
>>
>> I want to ask if somebody knows the way to create data frame with coefficients from many regressions
>> I regress the first column from ret against the first columns from median, then the second with the second and so on.
>> This is the code used for regression
>>
>> i<-1:6
>> lapply(seq_len(ncol(ret)),function(i) {lm(ret[,i]~median[,i])}
>>
>> I get 6 results for each regression
>>
>> [[1]]
>>
>> Call:
>> lm(formula = ret[, i] ~ median[, i])
>>
>> Coefficients:
>> (Intercept)  median[, i]
>>            0            1
>>
>>
>> [[2]]
>>
>> Call:
>> lm(formula = ret[, i] ~ median[, i])
>>
>> Coefficients:
>> (Intercept)  median[, i]
>> -1.411e-17    1.000e+00
>>
>> now I would like to create a data frame with intercepts which looks like it
>>
>>                          [[1]]          [[2]]
>> Intercept
>> median
>>
>> I tried to use ddply command but it does not work. I will be very grateful for the hint :)
>>
>> Thank you in advance
>>
>>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Tue Jul 23 00:07:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 22 Jul 2013 15:07:23 -0700 (PDT)
Subject: [R] Selecting names with regard to visit frequency
Message-ID: <1374530843.47153.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
myvector<- c(3,2,7,4,1)
names(myvector)<-paste0("name",1:5)
names(myvector)[myvector>=3 & myvector<=5] 
#[1] "name1" "name4"
#or
names(myvector)[myvector%in% 3:5]
#[1] "name1" "name4"

#or

?names(myvector)[!is.na(match(myvector,3:5))]
#[1] "name1" "name4"



A.K.


Hello all, 
I am new to R but trying to learn. 

I have a vector of names with visit frequencies (myvector) in the form 

name1 name2 name3 name4 name5 
3 ? ? ? ? ? ? ?2 ? ? ? ? ? ?7 ? ? ? ? ? ?4 ? ? ? ? ? ?1 

I can select names of patients that have visited more often: 

frequent.pats<-names(myvector) [myvector>5] 

or those that have visited less often, but how could I get the names of those who visited, say between 3&5 times? 
Thanks 
steele


From robert.b.lynch at gmail.com  Tue Jul 23 00:12:40 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Mon, 22 Jul 2013 15:12:40 -0700
Subject: [R] weighted average
Message-ID: <CACYeG1joTMSq8ntOaac-e6RtGf6Cv-4cf1dpkgr6DVDvAdkmHA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/a920a446/attachment.pl>

From dwinsemius at comcast.net  Tue Jul 23 00:23:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Jul 2013 15:23:41 -0700
Subject: [R] weighted average
In-Reply-To: <CACYeG1joTMSq8ntOaac-e6RtGf6Cv-4cf1dpkgr6DVDvAdkmHA@mail.gmail.com>
References: <CACYeG1joTMSq8ntOaac-e6RtGf6Cv-4cf1dpkgr6DVDvAdkmHA@mail.gmail.com>
Message-ID: <EA1AFAB0-E30C-48A5-BB08-6AF8E883B0C1@comcast.net>


On Jul 22, 2013, at 3:12 PM, Robert Lynch wrote:

> I am trying to compute GPA from class grades(which have been normallized)
> I have for example the following matrix
> 
> Master =
> SID    B2A    B2B    B2C   C2A     C2B    C2C    C118A    C118B     C118C
> 001    0.01    0.5      -0.4    1.2       -1.8     0.3      -0.3       0.4
>          0.5
> 002    0.01    0.5      -0.4    0.5       -0.4     1.2      -1.8       0.3
>          -0.3
> 003    0.04    0.05     0.5    -0.4     - 0.5     0.4      -1.2       1.8
>        0.3
> etc
> 
> Where each column has a zero mean and a standard deviation of 1.  I want to
> calculate a weighted average for each row(student ID) that takes into
> account that
> B2A, C118A, C118B, and C118C are all 4 unit classes, and the rest, B2B,
> B2C, C2A,C2B,C2C are 5 unit classes
> 
> I have tried
> Units<-c(4,5,5,5,5,5,4,4,4)
> Master$zGPA <-weighted.means(Master[,2:10],Units)
> 
> But that gets me one number and not a vector.

Perhaps something along lines of 

 Master$zGPA <-sapply( weighted.means(Master[,2:10], weighted.means, weghts=Units)

(Untested in absence of data or name of package from which function is loaded.)

> ?weighted.means
No documentation for ?weighted.means? in specified packages and libraries:
you could try ???weighted.means?

--- 
David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Tue Jul 23 00:26:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 22 Jul 2013 15:26:35 -0700 (PDT)
Subject: [R] weighted average
In-Reply-To: <CACYeG1joTMSq8ntOaac-e6RtGf6Cv-4cf1dpkgr6DVDvAdkmHA@mail.gmail.com>
References: <CACYeG1joTMSq8ntOaac-e6RtGf6Cv-4cf1dpkgr6DVDvAdkmHA@mail.gmail.com>
Message-ID: <1374531995.72771.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:
Master<-read.table(text="
SID??? B2A??? B2B??? B2C? C2A??? C2B??? C2C??? C118A??? C118B???? C118C
001??? 0.01??? 0.5????? -0.4??? 1.2????? -1.8??? 0.3????? -0.3????? 0.4?? 0.5
002??? 0.01??? 0.5????? -0.4??? 0.5????? -0.4??? 1.2????? -1.8????? 0.3? -0.3
003??? 0.04??? 0.05??? 0.5??? -0.4??? -0.5??? 0.4????? -1.2????? 1.8???? 0.3
",sep="",header=TRUE)
?library(matrixStats)


? Master$zGPA<-rowWeightedMeans(as.matrix(Master[,-1]),Units)
?Master
#? SID? B2A? B2B? B2C? C2A? C2B C2C C118A C118B C118C???????? zGPA
#1?? 1 0.01 0.50 -0.4? 1.2 -1.8 0.3? -0.3?? 0.4?? 0.5? 0.035121951
#2?? 2 0.01 0.50 -0.4? 0.5 -0.4 1.2? -1.8?? 0.3? -0.3 -0.003902439
#3?? 3 0.04 0.05? 0.5 -0.4 -0.5 0.4? -1.2?? 1.8?? 0.3? 0.097804878
A.K.

----- Original Message -----
From: Robert Lynch <robert.b.lynch at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Monday, July 22, 2013 6:12 PM
Subject: [R] weighted average

I am trying to compute GPA from class grades(which have been normallized)
I have for example the following matrix

Master =
SID? ? B2A? ? B2B? ? B2C?  C2A? ?  C2B? ? C2C? ? C118A? ? C118B? ?  C118C
001? ? 0.01? ? 0.5? ? ? -0.4? ? 1.2? ? ?  -1.8? ?  0.3? ? ? -0.3? ? ?  0.4
? ? ? ? ? 0.5
002? ? 0.01? ? 0.5? ? ? -0.4? ? 0.5? ? ?  -0.4? ?  1.2? ? ? -1.8? ? ?  0.3
? ? ? ? ? -0.3
003? ? 0.04? ? 0.05? ?  0.5? ? -0.4? ?  - 0.5? ?  0.4? ? ? -1.2? ? ?  1.8
? ? ? ? 0.3
etc

Where each column has a zero mean and a standard deviation of 1.? I want to
calculate a weighted average for each row(student ID) that takes into
account that
B2A, C118A, C118B, and C118C are all 4 unit classes, and the rest, B2B,
B2C, C2A,C2B,C2C are 5 unit classes

I have tried
Units<-c(4,5,5,5,5,5,4,4,4)
Master$zGPA <-weighted.means(Master[,2:10],Units)

But that gets me one number and not a vector.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jul 23 00:44:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 22 Jul 2013 15:44:18 -0700 (PDT)
Subject: [R] weighted average
In-Reply-To: <CACYeG1jmnqE=J7+7Dh0sQwTd4HKMtF-ctNwB-QUC2oQ6AUWK8A@mail.gmail.com>
References: <CACYeG1joTMSq8ntOaac-e6RtGf6Cv-4cf1dpkgr6DVDvAdkmHA@mail.gmail.com>
	<1374531995.72771.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1374532282.22013.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CACYeG1jmnqE=J7+7Dh0sQwTd4HKMtF-ctNwB-QUC2oQ6AUWK8A@mail.gmail.com>
Message-ID: <1374533058.85023.YahooMailNeo@web142604.mail.bf1.yahoo.com>



In that case:
Master1<- Master

Master1$zGPA<-sapply(seq_len(nrow(Master1[,-1])),function(i) weighted.mean(Master1[i,-1],Units))

Master1$zGPA
#[1]? 0.035121951 -0.003902439? 0.097804878
all.equal(Master,Master1)
#[1] TRUE

A.K.


________________________________
From: Robert Lynch <robert.b.lynch at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Monday, July 22, 2013 6:35 PM
Subject: Re: [R] weighted average



weighted.mean is the function. ?My apologies for appending an s





On Mon, Jul 22, 2013 at 3:31 PM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>
>I couldn't find the function `weighted.means` using ?weighted.means or ??weighted.means.? It would be useful to provide the library information.
>
>
>
>
>----- Original Message -----
>From: arun <smartpink111 at yahoo.com>
>To: Robert Lynch <robert.b.lynch at gmail.com>
>Cc: R help <r-help at r-project.org>
>Sent: Monday, July 22, 2013 6:26 PM
>Subject: Re: [R] weighted average
>
>Hi,
>May be this helps:
>Master<-read.table(text="
>SID??? B2A??? B2B??? B2C? C2A??? C2B??? C2C??? C118A??? C118B???? C118C
>001??? 0.01??? 0.5????? -0.4??? 1.2????? -1.8??? 0.3????? -0.3????? 0.4?? 0.5
>002??? 0.01??? 0.5????? -0.4??? 0.5????? -0.4??? 1.2????? -1.8????? 0.3? -0.3
>003??? 0.04??? 0.05??? 0.5??? -0.4??? -0.5??? 0.4????? -1.2????? 1.8???? 0.3
>",sep="",header=TRUE)
>?library(matrixStats)
>
>
>? Master$zGPA<-rowWeightedMeans(as.matrix(Master[,-1]),Units)
>?Master
>#? SID? B2A? B2B? B2C? C2A? C2B C2C C118A C118B C118C???????? zGPA
>#1?? 1 0.01 0.50 -0.4? 1.2 -1.8 0.3? -0.3?? 0.4?? 0.5? 0.035121951
>#2?? 2 0.01 0.50 -0.4? 0.5 -0.4 1.2? -1.8?? 0.3? -0.3 -0.003902439
>#3?? 3 0.04 0.05? 0.5 -0.4 -0.5 0.4? -1.2?? 1.8?? 0.3? 0.097804878
>A.K.
>
>----- Original Message -----
>From: Robert Lynch <robert.b.lynch at gmail.com>
>To: r-help at r-project.org
>Cc:
>Sent: Monday, July 22, 2013 6:12 PM
>Subject: [R] weighted average
>
>I am trying to compute GPA from class grades(which have been normallized)
>I have for example the following matrix
>
>Master =
>SID? ? B2A? ? B2B? ? B2C?? C2A? ?? C2B? ? C2C? ? C118A? ? C118B? ?? C118C
>001? ? 0.01? ? 0.5? ? ? -0.4? ? 1.2? ? ?? -1.8? ?? 0.3? ? ? -0.3? ? ?? 0.4
>? ? ? ? ? 0.5
>002? ? 0.01? ? 0.5? ? ? -0.4? ? 0.5? ? ?? -0.4? ?? 1.2? ? ? -1.8? ? ?? 0.3
>? ? ? ? ? -0.3
>003? ? 0.04? ? 0.05? ?? 0.5? ? -0.4? ?? - 0.5? ?? 0.4? ? ? -1.2? ? ?? 1.8
>? ? ? ? 0.3
>etc
>
>Where each column has a zero mean and a standard deviation of 1.? I want to
>calculate a weighted average for each row(student ID) that takes into
>account that
>B2A, C118A, C118B, and C118C are all 4 unit classes, and the rest, B2B,
>B2C, C2A,C2B,C2C are 5 unit classes
>
>I have tried
>Units<-c(4,5,5,5,5,5,4,4,4)
>Master$zGPA <-weighted.means(Master[,2:10],Units)
>
>But that gets me one number and not a vector.
>
>??? [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From dwinsemius at comcast.net  Tue Jul 23 01:17:41 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 22 Jul 2013 16:17:41 -0700
Subject: [R] weighted average
In-Reply-To: <EA1AFAB0-E30C-48A5-BB08-6AF8E883B0C1@comcast.net>
References: <CACYeG1joTMSq8ntOaac-e6RtGf6Cv-4cf1dpkgr6DVDvAdkmHA@mail.gmail.com>
	<EA1AFAB0-E30C-48A5-BB08-6AF8E883B0C1@comcast.net>
Message-ID: <DE4F6189-7436-4CF2-B69E-74BB619693F8@comcast.net>


On Jul 22, 2013, at 3:23 PM, David Winsemius wrote:

> 
> On Jul 22, 2013, at 3:12 PM, Robert Lynch wrote:
> 
>> I am trying to compute GPA from class grades(which have been normallized)
>> I have for example the following matrix
>> 
>> Master =
>> SID    B2A    B2B    B2C   C2A     C2B    C2C    C118A    C118B     C118C
>> 001    0.01    0.5      -0.4    1.2       -1.8     0.3      -0.3       0.4
>>         0.5
>> 002    0.01    0.5      -0.4    0.5       -0.4     1.2      -1.8       0.3
>>         -0.3
>> 003    0.04    0.05     0.5    -0.4     - 0.5     0.4      -1.2       1.8
>>       0.3
>> etc
>> 
>> Where each column has a zero mean and a standard deviation of 1.  I want to
>> calculate a weighted average for each row(student ID) that takes into
>> account that
>> B2A, C118A, C118B, and C118C are all 4 unit classes, and the rest, B2B,
>> B2C, C2A,C2B,C2C are 5 unit classes
>> 
>> I have tried
>> Units<-c(4,5,5,5,5,5,4,4,4)
>> Master$zGPA <-weighted.means(Master[,2:10],Units)
>> 
>> But that gets me one number and not a vector.
> 
> Perhaps something along lines of 
> 
> Master$zGPA <-sapply( weighted.means(Master[,2:10], weighted.means, weghts=Units)
> 
> (Untested in absence of data or name of package from which function is loaded.)
> 
>> ?weighted.means
> No documentation for ?weighted.means? in specified packages and libraries:
> you could try ???weighted.means?

If you are using weighted.mean and want this applied by row (one row per student I guess) , then probably this would be better:

Master$zGPA <-  apply( Master[,2:10],  1, weighted.means, w=Units)

-- 
David.

> 
> --- 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From stev0175 at gmail.com  Tue Jul 23 04:50:26 2013
From: stev0175 at gmail.com (Jeff Stevens)
Date: Mon, 22 Jul 2013 21:50:26 -0500
Subject: [R] Different x-axis scales using c() in latticeExtra
In-Reply-To: <CAKZAQ7x-QxcogJPTAjRxz0PFY96Nvwkwqyy1Lvk-Bs1kfFeGYw@mail.gmail.com>
References: <CAJ6UiDSB6XUPqK45VhtpdYSxKGysV2SikZQ+52KGii9i+q=wfg@mail.gmail.com>
	<0FFC0330-DBFC-4E77-B296-AC87B8B0B2D8@comcast.net>
	<CAKZAQ7x-QxcogJPTAjRxz0PFY96Nvwkwqyy1Lvk-Bs1kfFeGYw@mail.gmail.com>
Message-ID: <CAJ6UiDSc5rAKxrQuzCTWKzLspD7+d0B4hzLXOUf68AsUfrwFtA@mail.gmail.com>

Well, I finally found a work around.  It's not pretty, but it works.
I had to alter a number of padding values for par.settings in xyplot()
and minutely control the position and panel.width in plot.trellis().

Thanks for the help.

response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)

pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
equispaced.log = FALSE, y = list(tck = c(1,0))),
  par.settings = list(layout.widths = list(ylab.axis.padding = 1, ylab
= 1, axis.left = 0.8, panel = 1, between = 1, axis.right = 0,
ylab.right = 0, right.padding = 0), axis.components = list(left =
list(pad2 = 0))),
  panel = function(x, y, ...) {
    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
    panel.text(x = log10(8), y = log10(120), labels = "(a)")
  }
)

pred2_plot <- xyplot(response ~ predictor2, ylab = NULL, scales =
list(log = TRUE, equispaced.log = FALSE, y = list(labels = "", tck =
0)),
  par.settings = list(layout.widths = list(ylab.axis.padding = 0, ylab
= 0, axis.left = 0, panel = 1, between = 1, axis.right = 0, ylab.right
= 0, right.padding = 0), axis.components = list(left = list(pad2 =
0))),
  panel = function(x, y, ...) {
    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
    panel.text(x = log10(2), y = log10(120), labels = "(b)")
  }
)

pred3_plot <- xyplot(response ~ predictor3, ylab = NULL, scales =
list(y = list(log = TRUE, equispaced.log = FALSE, labels = "", tck =
c(0, 1))),
  par.settings = list(layout.widths = list(ylab.axis.padding = 0, ylab
= 0, axis.left = 0, panel = 1, between = 1, axis.right = 0, ylab.right
= 0, right.padding = 0), axis.components = list(left = list(pad2 =
0))),
  panel = function(x, y, ...) {
    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
    panel.text(x = 22, y = log10(120), labels = "(c)")
  }
)

pdf(file = "test_plot.pdf", width = 12, height = 5)
print(pred1_plot, split = c(1,1,3,1), position = c(0.02, 0, 1, 1),
panel.width = list(x = 3.6, unit = "in"), more=T)
print(pred2_plot, split = c(2,1,3,1), position = c(0.045, 0, 1, 1),
panel.width = list(x = 3.5, unit = "in"), more=T)
print(pred3_plot, split = c(3,1,3,1), panel.width = list(x = 3.5, unit
= "in"), more=F)
dev.off()




On Sat, Jul 20, 2013 at 6:45 PM, Felix Andrews <felix at nfrac.org> wrote:
> latticeExtra's c() can not combine logarithmic with linear x scales,
> I'm afraid.  I would recommend displaying each separate plot on one
> page using plot.trellis() or the gridExtra function that John Kane
> mentioned.
>
> Cheers
> Felix
>
>
> On 21 July 2013 02:50, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On Jul 19, 2013, at 8:18 PM, Jeff Stevens wrote:
>>
>>> Hi,
>>>
>>> I would like to combine multiple xyplots into a single, multipanel
>>> display.  Using R 3.0.1 in Ubuntu, I have used c() from latticeExtra
>>> to combine three plots, but the x-axis for two plots are on a log
>>> scale and the other is on a normal scale.  I also have included
>>> equispace.log=FALSE to clean up the tick labels.  However, when I try
>>> all of these, the x-axis scale of the first panel is used for all
>>> three.  How do I keep different scales for the different panels?
>>>
>>> Here is an example:
>>> library(lattice)
>>> library(latticeExtra)
>>> response <- c(76, 14, 15, 44, 26, 19, 74, 123, 49, 8, 56, 17, 18)
>>> predictor1 <- c(107, 7, 25, 501, 64, 88, 344, 367, 379, 10, 66, 31, 32)
>>> predictor2 <- c(10, 9, 8, 10, 29, 27, 55, 48, 2, 6, 14, 10, 5)
>>> predictor3 <- c(67, 22, 66, 41, 72, 64, 69, 63, 64, 70, 60, 75, 78)
>>>
>>> pred1_plot <- xyplot(response ~ predictor1, scales = list(log = TRUE,
>>> equispaced.log = FALSE),
>>>  panel = function(x, y, ...) {
>>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>>    panel.text(x = log10(8), y = log10(120), labels = "(a)")
>>>  }
>>> )
>>>
>>> pred2_plot <- xyplot(response ~ predictor2, scales = list(log = TRUE,
>>> equispaced.log = FALSE),
>>>  panel = function(x, y, ...) {
>>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>>    panel.text(x = log10(2), y = log10(120), labels = "(b)")
>>>  }
>>> )
>>>
>>> pred3_plot <- xyplot(response ~ predictor3, scales = list(y = list(log
>>> = TRUE, equispaced.log = FALSE)),
>>>  panel = function(x, y, ...) {
>>>    panel.xyplot(x, y, type = c("p", "r"), cex = 2)
>>>    panel.text(x = 22, y = log10(120), labels = "(c)")
>>>  }
>>> )
>>>
>>> all_plots <- c(pred1_plot, pred2_plot, pred3_plot, layout = c(3, 1), x.same = F)
>>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>>> scales = list(y=list(log=T, equispaced.log=FALSE), x = c(list(log=T,
>>> equispaced.log=FALSE), list(log=T, equispaced.log=FALSE),
>>> list(log=F))))
>>>
>>> update(all_plots, xlab=c("Predictor 1","Predictor 2", "Predictor 3"),
>>> scales = c(list(log = TRUE, equispaced.log = FALSE), list(log = TRUE,
>>> equispaced.log = FALSE), list(y=list(log=T, equispaced.log = FALSE))))
>>>
>>> Any help is appreciated!
>>
>> I assume there was a notice o your console that there were warnings, right? You should offer the full texts of warnings and error messages. Here the full text of the first and second warnings:
>>
>>> warnings()[1:2]
>> $`log scales cannot be changed via 'update'`
>> update.trellis(all_plots, xlab = c("Predictor 1", "Predictor 2",
>>     "Predictor 3"), scales = c(list(log = TRUE, equispaced.log = FALSE),
>>     list(log = TRUE, equispaced.log = FALSE), list(y = list(log = T,
>>         equispaced.log = FALSE))))
>> $`'x' is NULL so the result will be NULL`
>> rep(scales[[nm]], length.out = 2)
>>
>> The first one is telling you why the results should be different than you expect. I'm not entirely sure what the second one is telling you, but it doesn't sound good.
>>
>> --
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
>
> --
> Felix Andrews / ???
> http://www.neurofractal.org/felix/


From shanxiao at umail.iu.edu  Tue Jul 23 00:53:53 2013
From: shanxiao at umail.iu.edu (shanxiao)
Date: Mon, 22 Jul 2013 18:53:53 -0400
Subject: [R] constructing a daily time series
Message-ID: <000001ce872e$587ceab0$0976c010$@iu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/0418284e/attachment.pl>

From jamesijw23 at gmail.com  Tue Jul 23 00:55:31 2013
From: jamesijw23 at gmail.com (Immanuel Williams)
Date: Mon, 22 Jul 2013 18:55:31 -0400
Subject: [R] Error with sem function df = -6
Message-ID: <CAK6qXJ3V_H+dYiQekEqhrxavh8RZMdSO+O1rL11gUdVsf5nhyQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130722/70ad3a4a/attachment.pl>

From kridox at ymail.com  Tue Jul 23 06:17:18 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 23 Jul 2013 13:17:18 +0900
Subject: [R] constructing a daily time series
In-Reply-To: <000001ce872e$587ceab0$0976c010$@iu.edu>
References: <000001ce872e$587ceab0$0976c010$@iu.edu>
Message-ID: <CAAcyNCz7PjEsNC9oJ8eOOyF_+4aQGVTKNBis-_yt6m6xLNX68w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/55e9efe1/attachment.pl>

From ckluss at email.uni-kiel.de  Tue Jul 23 08:37:07 2013
From: ckluss at email.uni-kiel.de (=?ISO-8859-15?Q?Christof_Klu=DF?=)
Date: Tue, 23 Jul 2013 08:37:07 +0200
Subject: [R] optimize integer function parameters
Message-ID: <ksl8ad$buk$1@ger.gmane.org>

Hi

I have "observations" obs <- (11455, 11536, 11582, 11825, 11900,  ...)

and a simulation function f(A,B,C,D,E,F), so sim <- f(A,B,C,D,E,F)

e.g. sim = c(11464, 11554, 11603, 11831, 11907, ...)

now I would like to fit A,B,C,D,E,F such that "obs" and f(A,B,C,D,E,F) 
match as well as possible. A,..,F should be integers and have bounds.

How would you solve this problem without bruteforce in an acceptable time?

thx
Christof


From Christoph.Scherber at agr.uni-goettingen.de  Tue Jul 23 11:16:52 2013
From: Christoph.Scherber at agr.uni-goettingen.de (Christoph Scherber)
Date: Tue, 23 Jul 2013 11:16:52 +0200
Subject: [R] MGCV: Degrees of freedom of smooth terms
Message-ID: <51EE4A04.8090309@agr.uni-goettingen.de>

Dear all,

This is just a quick question regarding degrees of freedom in GAM models fit by MGCV (using select=T):

Can I roughly interpret them as:

1 df: linear effect of x on y
2 df: approximately quadratic of x on y
3 df: approximately cubic effect of x on y?
1 df for a spatial term s(x,y): bilinear effect (?) or how would I call this?

And what does "ref.df" in the summary output mean; is this the unpenalized degrees of freedom for
each term?

Thank you very much for answering!

Best wishes,
Christoph


-- 
PD Dr Christoph Scherber
Georg-August University Goettingen
Department of Crop Science
Agroecology
Grisebachstrasse 6
D-37077 Goettingen
Germany
phone 0049 (0)551 39 8807
fax 0049 (0)551 39 8806
http://www.gwdg.de/~cscherb1


From stefano.sofia at regione.marche.it  Tue Jul 23 11:33:46 2013
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Tue, 23 Jul 2013 09:33:46 +0000
Subject: [R] Some days missing using xtabs
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/f1c8181f/attachment.pl>

From daisy.duursma at gmail.com  Tue Jul 23 11:59:51 2013
From: daisy.duursma at gmail.com (Daisy Englert Duursma)
Date: Tue, 23 Jul 2013 19:59:51 +1000
Subject: [R] downloading web content
Message-ID: <CAFf2dDEiEJ_cD=JD4P=DX0=L=dxxC3N8GVz1GjA187H-Ad8yUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/01863863/attachment.pl>

From kridox at ymail.com  Tue Jul 23 12:02:36 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Tue, 23 Jul 2013 19:02:36 +0900
Subject: [R] Some days missing using xtabs
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
Message-ID: <CAAcyNCwv46BPpYMT4jva9QN7gmmv7+f0S1FW-TshWx3du4r9jw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/1466ef94/attachment.pl>

From ruipbarradas at sapo.pt  Tue Jul 23 12:37:22 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 23 Jul 2013 11:37:22 +0100
Subject: [R] Some days missing using xtabs
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
Message-ID: <51EE5CE2.5080301@sapo.pt>

Hello,

Why should those numbers show up in the final result? They are missing 
in the original data frame. A hack could be


fac <- factor(hospital_2004$d_release, levels = 
seq_len(max(hospital_2004$d_release)))

as.data.frame(xtabs( ~ fac + m_release + y_release, data=hospital_2004))


And there would still be a 31 in m_release 6, which you call June but in 
fact is just a number.


Hope this helps,

Rui Barradas

Em 23-07-2013 10:33, Stefano Sofia escreveu:
> Dear R-users,
> given the following data frame called hospital_2004
>
> gender d_birth m_birth y_birth address d_admittance m_admittance y_admittance yard_admittance d_release m_release y_release yard_release diaprinc diasec1 diasec2 diasec3 diasec4 diasec5
> 2 13 12 1929 42002 30 3 2004 3003 6 5 2004 4902 430 4299 51881 4275 78001 0
> 1 1 8 1935 42002 7 4 2004 2401 18 5 2004 1801 20500 V581 0388 5849 0 0
> 1 23 12 1956 42018 26 4 2004 2402 31 5 2004 2402 1552 5715 7895 25000 4148 5722
> 1 9 8 1919 42002 05 5 2004 2602 22 5 2004 4902 51881 4254 4275 0 0 0
> 2 11 1 1925 52014 30 4 2004 2603 13 6 2004 4902 51881 49121 2732 4275 4299 5849
> 2 1 3 1963 44060 1 5 2004 5101 16 5 2004 2401 3201 1519 1976 1983 4019 0
> 1 6 3 1937 45010 6 5 2004 3003 12 5 2004 4901 431 3314 41189 25001 4019 V594
> 1 3 9 1931 42034 3 5 2004 5101 5 5 2004 5101 78559 4829 5119 1619 4241 585
> 2 13 9 1912 41007 5 5 2004 4901 7 5 2004 4901 85225 4019 42731 49121 0 0
> 1 21 10 1936 15146 7 5 2004 4901 10 5 2004 4901 431 430 V594 V595 0 0
> 2 8 5 1933 43044 8 5 2004 5802 8 6 2004 5802 5712 45620 2851 5119 5184 0
> 1 25 1 1926 41057 8 5 2004 4901 15 5 2004 4901 431 78001 49121 0 0 0
> 1 6 1 1923 42002 10 5 2004 1401 11 5 2004 4901 4440 412 4413 0 0 0
> 1 19 3 1934 42022 9 5 2004 1401 21 6 2004 4901 4413 5609 99811 4019 412 0
> 1 6 6 1921 43052 15 5 2004 4302 4 6 2004 4302 1890 20280 436 49121 9986 V1005
>
> when I try to evaluate the frequency of daily releases through
>
> release_freq <- as.data.frame(xtabs( ~ d_release + m_release + y_release, data=hospital_2004))
>
> I get the following result:
>
> d_release m_release y_release Freq
> 4         5      2004    0
> 5         5      2004    1
> 6         5      2004    1
> 7         5      2004    1
> 8         5      2004    0
> 10         5      2004    1
> 11         5      2004    1
> 12         5      2004    1
> 13         5      2004    0
> 15         5      2004    1
> 16         5      2004    1
> 18         5      2004    1
> 21         5      2004    0
> 22         5      2004    1
> 31         5      2004    1
> 4         6      2004    1
> 5         6      2004    0
> 6         6      2004    0
> 7         6      2004    0
> 8         6      2004    1
> 10         6      2004    0
> 11         6      2004    0
> 12         6      2004    0
> 13         6      2004    1
> 15         6      2004    0
> 16         6      2004    0
> 18         6      2004    0
> 21         6      2004    1
> 22         6      2004    0
> 31         6      2004    0
>
> Why the 1st, 2nd, 3rd, 9th, 14th, 17th, 19th, 20th, from 23rd to 30th of both May and June are missing? (and there is the 31st of June?)
>
> And a final question: why given another data frame called temp_h12
>
> y_temp m_temp d_temp temp
> 2004 5 1 16.90
> 2004 5 2 18.00
> 2004 5 3 17.40
> 2004 5 4 19.70
> 2004 5 5 105.70
> 2004 5 6 17.30
> 2004 5 7 17.00
> 2004 5 8 16.20
> 2004 5 9 16.10
> 2004 5 10 16.10
> 2004 5 11 15.80
> 2004 5 12 15.10
> 2004 5 13 17.80
> 2004 5 14 17.40
> 2004 5 15 16.00
> 2004 5 16 17.70
> 2004 5 17 17.30
> 2004 5 18 22.30
> 2004 5 19 23.30
> 2004 5 20 24.30
> 2004 5 21 19.90
> 2004 5 22 15.70
> 2004 5 23 15.80
> 2004 5 24 17.10
> 2004 5 25 18.30
> 2004 5 26 21.00
> 2004 5 27 18.20
> 2004 5 28 17.90
> 2004 5 29 19.40
> 2004 5 30 22.10
> 2004 5 31 17.40
>
> merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>
> gives the following warning
>
> Warning message:
> In `[<-.factor`(`*tmp*`, ri, value = 1:31) :
>    invalid factor level, NAs generated
> ?
>
>
>
> Thank you for your help
> Stefano Sofia
>
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Tue Jul 23 12:50:25 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 23 Jul 2013 11:50:25 +0100
Subject: [R] Some days missing using xtabs
In-Reply-To: <8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
References: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
Message-ID: <51EE5FF1.7040603@sapo.pt>

Hello,

As for your second question, before merge(), try the following.

release_freq$d_release <- as.integer(as.character(release_freq$d_release))
release_freq$m_release <- as.integer(as.character(release_freq$m_release))
release_freq$y_release <- as.integer(as.character(release_freq$y_release))


And the warning is gone.

Hope this helps,

Rui Barradas

Em 23-07-2013 10:33, Stefano Sofia escreveu:
> Dear R-users,
> given the following data frame called hospital_2004
>
> gender d_birth m_birth y_birth address d_admittance m_admittance y_admittance yard_admittance d_release m_release y_release yard_release diaprinc diasec1 diasec2 diasec3 diasec4 diasec5
> 2 13 12 1929 42002 30 3 2004 3003 6 5 2004 4902 430 4299 51881 4275 78001 0
> 1 1 8 1935 42002 7 4 2004 2401 18 5 2004 1801 20500 V581 0388 5849 0 0
> 1 23 12 1956 42018 26 4 2004 2402 31 5 2004 2402 1552 5715 7895 25000 4148 5722
> 1 9 8 1919 42002 05 5 2004 2602 22 5 2004 4902 51881 4254 4275 0 0 0
> 2 11 1 1925 52014 30 4 2004 2603 13 6 2004 4902 51881 49121 2732 4275 4299 5849
> 2 1 3 1963 44060 1 5 2004 5101 16 5 2004 2401 3201 1519 1976 1983 4019 0
> 1 6 3 1937 45010 6 5 2004 3003 12 5 2004 4901 431 3314 41189 25001 4019 V594
> 1 3 9 1931 42034 3 5 2004 5101 5 5 2004 5101 78559 4829 5119 1619 4241 585
> 2 13 9 1912 41007 5 5 2004 4901 7 5 2004 4901 85225 4019 42731 49121 0 0
> 1 21 10 1936 15146 7 5 2004 4901 10 5 2004 4901 431 430 V594 V595 0 0
> 2 8 5 1933 43044 8 5 2004 5802 8 6 2004 5802 5712 45620 2851 5119 5184 0
> 1 25 1 1926 41057 8 5 2004 4901 15 5 2004 4901 431 78001 49121 0 0 0
> 1 6 1 1923 42002 10 5 2004 1401 11 5 2004 4901 4440 412 4413 0 0 0
> 1 19 3 1934 42022 9 5 2004 1401 21 6 2004 4901 4413 5609 99811 4019 412 0
> 1 6 6 1921 43052 15 5 2004 4302 4 6 2004 4302 1890 20280 436 49121 9986 V1005
>
> when I try to evaluate the frequency of daily releases through
>
> release_freq <- as.data.frame(xtabs( ~ d_release + m_release + y_release, data=hospital_2004))
>
> I get the following result:
>
> d_release m_release y_release Freq
> 4         5      2004    0
> 5         5      2004    1
> 6         5      2004    1
> 7         5      2004    1
> 8         5      2004    0
> 10         5      2004    1
> 11         5      2004    1
> 12         5      2004    1
> 13         5      2004    0
> 15         5      2004    1
> 16         5      2004    1
> 18         5      2004    1
> 21         5      2004    0
> 22         5      2004    1
> 31         5      2004    1
> 4         6      2004    1
> 5         6      2004    0
> 6         6      2004    0
> 7         6      2004    0
> 8         6      2004    1
> 10         6      2004    0
> 11         6      2004    0
> 12         6      2004    0
> 13         6      2004    1
> 15         6      2004    0
> 16         6      2004    0
> 18         6      2004    0
> 21         6      2004    1
> 22         6      2004    0
> 31         6      2004    0
>
> Why the 1st, 2nd, 3rd, 9th, 14th, 17th, 19th, 20th, from 23rd to 30th of both May and June are missing? (and there is the 31st of June?)
>
> And a final question: why given another data frame called temp_h12
>
> y_temp m_temp d_temp temp
> 2004 5 1 16.90
> 2004 5 2 18.00
> 2004 5 3 17.40
> 2004 5 4 19.70
> 2004 5 5 105.70
> 2004 5 6 17.30
> 2004 5 7 17.00
> 2004 5 8 16.20
> 2004 5 9 16.10
> 2004 5 10 16.10
> 2004 5 11 15.80
> 2004 5 12 15.10
> 2004 5 13 17.80
> 2004 5 14 17.40
> 2004 5 15 16.00
> 2004 5 16 17.70
> 2004 5 17 17.30
> 2004 5 18 22.30
> 2004 5 19 23.30
> 2004 5 20 24.30
> 2004 5 21 19.90
> 2004 5 22 15.70
> 2004 5 23 15.80
> 2004 5 24 17.10
> 2004 5 25 18.30
> 2004 5 26 21.00
> 2004 5 27 18.20
> 2004 5 28 17.90
> 2004 5 29 19.40
> 2004 5 30 22.10
> 2004 5 31 17.40
>
> merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>
> gives the following warning
>
> Warning message:
> In `[<-.factor`(`*tmp*`, ri, value = 1:31) :
>    invalid factor level, NAs generated
> ?
>
>
>
> Thank you for your help
> Stefano Sofia
>
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From es at enricoschumann.net  Tue Jul 23 13:20:04 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 23 Jul 2013 13:20:04 +0200
Subject: [R] optimize integer function parameters
In-Reply-To: <ksl8ad$buk$1@ger.gmane.org> ("Christof =?utf-8?Q?Klu=C3=9F?=
	=?utf-8?Q?=22's?= message of "Tue, 23 Jul 2013 08:37:07 +0200")
References: <ksl8ad$buk$1@ger.gmane.org>
Message-ID: <87bo5t34m3.fsf@enricoschumann.net>

On Tue, 23 Jul 2013, Christof Klu? <ckluss at email.uni-kiel.de> writes:

>
> I have "observations" obs <- (11455, 11536, 11582, 11825, 11900,  ...)
>
> and a simulation function f(A,B,C,D,E,F), so sim <- f(A,B,C,D,E,F)
>
> e.g. sim = c(11464, 11554, 11603, 11831, 11907, ...)
>
> now I would like to fit A,B,C,D,E,F such that "obs" and f(A,B,C,D,E,F)
> match as well as possible. A,..,F should be integers and have bounds.
>
> How would you solve this problem without bruteforce in an acceptable time?
>


That depends on what your "simulation function" looks like.  Could you
post a (small) self-contained example?


-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From ruipbarradas at sapo.pt  Tue Jul 23 13:36:39 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 23 Jul 2013 12:36:39 +0100
Subject: [R] How to split two levels several times?
In-Reply-To: <trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>
Message-ID: <51EE6AC7.1060003@sapo.pt>

Hello,

It's better if you keep this on the list, the odds of getting more and 
better answers are greater.

As for your new question, try the following.


lens <- rle(as.character(XXX$electrode))$lengths
m <- length(lens) %/% 2
idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
split(XXX, idx)


Hope this helps,

Rui Barradas

Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
> Hi
> this type of splitting works for my specific example. Thanks for your help.
>
> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,  electrode3-electrode2,  electrode4-electrode1. How should I split this?
>
>
> This is the table "XXX"
>
> electrode length
>
> electrode1 5.7
> electrode1 6.3
> electrode1 6.2
> electrode2 11.4
> electrode2 9.7
> electrode3 14.2
> electrode3 14.8
> electrode3 12.6
> electrode2 11.4
> electrode2 9.7
> electrode4 17.0
> electrode4 16.3
> electrode4 17.8
> electrode4 18.3
> electrode4 16.9
> electrode4 18.5
> electrode1 5.7
> electrode1 6.3
> electrode1 6.2
>
>
>
>
>
>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>> An: dennis1991 at gmx.net
>> Cc: r-help at r-project.org
>> Betreff: Re: [R] How to split two levels several times?
>>
>> Hello,
>>
>> Sorry, I've just realized that your data frame is named 'XXX', not
>> 'dat'. Change that and the rest should work:
>>
>>
>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
>> split(XXX, idx)
>>
>>
>> Rui Barradas
>>
>> Em 22-07-2013 16:47, Rui Barradas escreveu:
>>> Hello,
>>>
>>> Try the following.
>>>
>>>
>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
>>> split(dat, idx)
>>>
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
>>>> Hi,
>>>>
>>>> I have a small problem with the function split() and would appreciate
>>>> your help.
>>>>
>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
>>>> split the table always at the row where ?electrode1? starts again so
>>>> that I can export 7  individual dataframes (numbered ?dataframe1? to
>>>> ?dataframe7?) which contain always electrode1 as first level (always
>>>> three rows) with the varying number of rows for electrodes2-8 below.
>>>> I tried the split function with various setups:
>>>>
>>>> t <- as.factor(XXX$electrode)
>>>>
>>>> dataframeX <- split(XXX, f=(levels=t))
>>>>
>>>> But this doesn?t work. Could you please help. Thank you! Dennis
>>>>
>>>>
>>>> This is the table "XXX"
>>>>
>>>> electrode    length
>>>>
>>>> electrode1    5.7
>>>> electrode1    6.3
>>>> electrode1    6.2
>>>> electrode2    11.4
>>>> electrode2    9.7
>>>> electrode1    5.7
>>>> electrode1    6.3
>>>> electrode1    6.2
>>>> electrode3    14.2
>>>> electrode3    14.8
>>>> electrode3    12.6
>>>> electrode1    5.7
>>>> electrode1    6.3
>>>> electrode1    6.2
>>>> electrode4    17.0
>>>> electrode4    16.3
>>>> electrode4    17.8
>>>> electrode4    18.3
>>>> electrode4    16.9
>>>> electrode4    18.5
>>>> electrode1    ....
>>>> ....        ....
>>>> electrode5    ....
>>>> ....        ....
>>>> electrode1    ....
>>>> electrode6    ....
>>>> electrode1    ....
>>>> electrode7    ....
>>>> electrode1    ....
>>>> electrode8    ....
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>


From szehnder at uni-bonn.de  Tue Jul 23 14:36:15 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 23 Jul 2013 14:36:15 +0200
Subject: [R] Check the class of an object
Message-ID: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/bac7c55a/attachment.pl>

From ruipbarradas at sapo.pt  Tue Jul 23 14:40:52 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 23 Jul 2013 13:40:52 +0100
Subject: [R] Some days missing using xtabs
In-Reply-To: <1374583018.44098.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
	<51EE5FF1.7040603@sapo.pt>
	<1374583018.44098.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <51EE79D4.7050808@sapo.pt>

Hello,

Something I've just noticed, stringsAsFactors is not an argument to merge().

And, without changing the class I g a warning:

Warning message:
In `[<-.factor`(`*tmp*`, ri, value = 1:31) :
   invalid factor level, NA generated


Rui Barradas

Em 23-07-2013 13:36, arun escreveu:
> Hi,
>
> I tried this without the changing the class, but there was no warning.
>
>   str(release_freq)
> #'data.frame':    62 obs. of  4 variables:
> # $ d_release: Factor w/ 31 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
> # $ m_release: Factor w/ 2 levels "5","6": 1 1 1 1 1 1 1 1 1 1 ...
> # $ y_release: Factor w/ 1 level "2004": 1 1 1 1 1 1 1 1 1 1 ...
> # $ Freq     : num  0 0 0 0 1 1 1 0 0 1 ...
>   str(temp_h12)
> #'data.frame':    31 obs. of  4 variables:
> # $ y_temp: int  2004 2004 2004 2004 2004 2004 2004 2004 2004 2004 ...
> # $ m_temp: int  5 5 5 5 5 5 5 5 5 5 ...
> # $ d_temp: int  1 2 3 4 5 6 7 8 9 10 ...
> # $ temp  : num  16.9 18 17.4 19.7 105.7 ...
>
>
> res<-merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>
>    head(res)
>   # y_release m_release d_release Freq temp
> #1      2004         5         1    0 16.9
> #2      2004         5        10    1 16.1
> #3      2004         5        11    1 15.8
> #4      2004         5        12    1 15.1
> #5      2004         5        13    0 17.8
> #6      2004         5        14    0 17.4
>
> # changing the class
> release_freq$d_release <- as.integer(as.character(release_freq$d_release))
> release_freq$m_release <- as.integer(as.character(release_freq$m_release))
> release_freq$y_release <- as.integer(as.character(release_freq$y_release))
> res1<- merge(release_freq, temp_h12,
> by.x=c("y_release","m_release","d_release"),
> by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>
> head(res1)
> #  y_release m_release d_release Freq temp
> #1      2004         5         1    0 16.9
> #2      2004         5        10    1 16.1
> #3      2004         5        11    1 15.8
> #4      2004         5        12    1 15.1
> #5      2004         5        13    0 17.8
> #6      2004         5        14    0 17.4
>
> The results are not identical.
>    identical(res,res1)
> #[1] FALSE
> str(res)
> #'data.frame':    31 obs. of  5 variables:
> # $ y_release: Factor w/ 1 level "2004": 1 1 1 1 1 1 1 1 1 1 ...
> # $ m_release: Factor w/ 2 levels "5","6": 1 1 1 1 1 1 1 1 1 1 ...
> # $ d_release: Factor w/ 31 levels "1","2","3","4",..: 1 10 11 12 13 14 15 16 17 18 ...
> # $ Freq     : num  0 1 1 1 0 0 1 1 0 1 ...
> # $ temp     : num  16.9 16.1 15.8 15.1 17.8 17.4 16 17.7 17.3 22.3 ...
>   str(res1)
> #'data.frame':    31 obs. of  5 variables:
> # $ y_release: int  2004 2004 2004 2004 2004 2004 2004 2004 2004 2004 ...
> # $ m_release: int  5 5 5 5 5 5 5 5 5 5 ...
> # $ d_release: int  1 10 11 12 13 14 15 16 17 18 ...
> # $ Freq     : num  0 1 1 1 0 0 1 1 0 1 ...
> # $ temp     : num  16.9 16.1 15.8 15.1 17.8 17.4 16 17.7 17.3 22.3 ...
>
>
> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>   [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] stringr_0.6.2  reshape2_1.2.2
>
> loaded via a namespace (and not attached):
> [1] plyr_1.8
>
> A.K.
>
> ----- Original Message -----
> From: Rui Barradas <ruipbarradas at sapo.pt>
> To: Stefano Sofia <stefano.sofia at regione.marche.it>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Sent: Tuesday, July 23, 2013 6:50 AM
> Subject: Re: [R] Some days missing using xtabs
>
> Hello,
>
> As for your second question, before merge(), try the following.
>
> release_freq$d_release <- as.integer(as.character(release_freq$d_release))
> release_freq$m_release <- as.integer(as.character(release_freq$m_release))
> release_freq$y_release <- as.integer(as.character(release_freq$y_release))
>
>
> And the warning is gone.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 23-07-2013 10:33, Stefano Sofia escreveu:
>> Dear R-users,
>> given the following data frame called hospital_2004
>>
>> gender d_birth m_birth y_birth address d_admittance m_admittance y_admittance yard_admittance d_release m_release y_release yard_release diaprinc diasec1 diasec2 diasec3 diasec4 diasec5
>> 2 13 12 1929 42002 30 3 2004 3003 6 5 2004 4902 430 4299 51881 4275 78001 0
>> 1 1 8 1935 42002 7 4 2004 2401 18 5 2004 1801 20500 V581 0388 5849 0 0
>> 1 23 12 1956 42018 26 4 2004 2402 31 5 2004 2402 1552 5715 7895 25000 4148 5722
>> 1 9 8 1919 42002 05 5 2004 2602 22 5 2004 4902 51881 4254 4275 0 0 0
>> 2 11 1 1925 52014 30 4 2004 2603 13 6 2004 4902 51881 49121 2732 4275 4299 5849
>> 2 1 3 1963 44060 1 5 2004 5101 16 5 2004 2401 3201 1519 1976 1983 4019 0
>> 1 6 3 1937 45010 6 5 2004 3003 12 5 2004 4901 431 3314 41189 25001 4019 V594
>> 1 3 9 1931 42034 3 5 2004 5101 5 5 2004 5101 78559 4829 5119 1619 4241 585
>> 2 13 9 1912 41007 5 5 2004 4901 7 5 2004 4901 85225 4019 42731 49121 0 0
>> 1 21 10 1936 15146 7 5 2004 4901 10 5 2004 4901 431 430 V594 V595 0 0
>> 2 8 5 1933 43044 8 5 2004 5802 8 6 2004 5802 5712 45620 2851 5119 5184 0
>> 1 25 1 1926 41057 8 5 2004 4901 15 5 2004 4901 431 78001 49121 0 0 0
>> 1 6 1 1923 42002 10 5 2004 1401 11 5 2004 4901 4440 412 4413 0 0 0
>> 1 19 3 1934 42022 9 5 2004 1401 21 6 2004 4901 4413 5609 99811 4019 412 0
>> 1 6 6 1921 43052 15 5 2004 4302 4 6 2004 4302 1890 20280 436 49121 9986 V1005
>>
>> when I try to evaluate the frequency of daily releases through
>>
>> release_freq <- as.data.frame(xtabs( ~ d_release + m_release + y_release, data=hospital_2004))
>>
>> I get the following result:
>>
>> d_release m_release y_release Freq
>> 4         5      2004    0
>> 5         5      2004    1
>> 6         5      2004    1
>> 7         5      2004    1
>> 8         5      2004    0
>> 10         5      2004    1
>> 11         5      2004    1
>> 12         5      2004    1
>> 13         5      2004    0
>> 15         5      2004    1
>> 16         5      2004    1
>> 18         5      2004    1
>> 21         5      2004    0
>> 22         5      2004    1
>> 31         5      2004    1
>> 4         6      2004    1
>> 5         6      2004    0
>> 6         6      2004    0
>> 7         6      2004    0
>> 8         6      2004    1
>> 10         6      2004    0
>> 11         6      2004    0
>> 12         6      2004    0
>> 13         6      2004    1
>> 15         6      2004    0
>> 16         6      2004    0
>> 18         6      2004    0
>> 21         6      2004    1
>> 22         6      2004    0
>> 31         6      2004    0
>>
>> Why the 1st, 2nd, 3rd, 9th, 14th, 17th, 19th, 20th, from 23rd to 30th of both May and June are missing? (and there is the 31st of June?)
>>
>> And a final question: why given another data frame called temp_h12
>>
>> y_temp m_temp d_temp temp
>> 2004 5 1 16.90
>> 2004 5 2 18.00
>> 2004 5 3 17.40
>> 2004 5 4 19.70
>> 2004 5 5 105.70
>> 2004 5 6 17.30
>> 2004 5 7 17.00
>> 2004 5 8 16.20
>> 2004 5 9 16.10
>> 2004 5 10 16.10
>> 2004 5 11 15.80
>> 2004 5 12 15.10
>> 2004 5 13 17.80
>> 2004 5 14 17.40
>> 2004 5 15 16.00
>> 2004 5 16 17.70
>> 2004 5 17 17.30
>> 2004 5 18 22.30
>> 2004 5 19 23.30
>> 2004 5 20 24.30
>> 2004 5 21 19.90
>> 2004 5 22 15.70
>> 2004 5 23 15.80
>> 2004 5 24 17.10
>> 2004 5 25 18.30
>> 2004 5 26 21.00
>> 2004 5 27 18.20
>> 2004 5 28 17.90
>> 2004 5 29 19.40
>> 2004 5 30 22.10
>> 2004 5 31 17.40
>>
>> merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>>
>> gives the following warning
>>
>> Warning message:
>> In `[<-.factor`(`*tmp*`, ri, value = 1:31) :
>>      invalid factor level, NAs generated
>> ?
>>
>>
>>
>> Thank you for your help
>> Stefano Sofia
>>
>>
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>>
>>      [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From katveie at hotmail.com  Tue Jul 23 11:19:15 2013
From: katveie at hotmail.com (Kathrine Veie)
Date: Tue, 23 Jul 2013 11:19:15 +0200
Subject: [R] mgcv: pcls() makes everything linear
Message-ID: <BLU0-SMTP87864BFC10BE802AA70C0FAE6F0@phx.gbl>

Dear R helplisters,

I am trying to implement a mononicity constraint on a smooth term in my generalized additive model with the mgcv package (v. 1.7-18). I adapted the code from an example given in the help file for pcls(). The example runs just as one would expect, but when I adapt it and use the code on my data, the code results in a linear fit on ALL smooth terms in the model even though I only place restrictions on a single one of them. 

Can anyone give me any idea why this is the case?  The basis spline dimension is taken from the unconstrained object, but the coefficients determined by pcls() are such that the fit is linear (basically very, very small coefficients and large coefficients on a single spline component for each covariate as far as I can tell). (see figure which I hope comes through to the help list posting!)

The example is simpler than the model I actually want to estimate, but the problem is the same in the more expanded version. In the simple version, the curve I want to restrict to be monotonically increasing already satisfies the constraint, but in the full model it is more "wiggly" and has some downward sloping parts. 

In the code below I impose the constraint using a subset of the data, but I tried the same thing using the full data set for predictions and except for that being a bit slower the results are all the same. (The full data set has 14,000 observations)

## Preliminary unconstrained gam fit...
G <- gam(ksumphk~s(arlsaml)+s(road_quiet)+s(centrum), data=per1.200m,family=gaussian(link=log), fit=FALSE)
b <- gam(G=G)
c <- b ##Save unconstrained estimates in separate model 

## generate constraints, by finite differencing
## using predict.gam ....
eps <- 1e-7

#Sample from the data set to avoid too many obs in prediction

pd0 <- data.frame(per1.200m[sample(nrow(per1.200m),200),])
pd1 <- pd0
pd1$road_quiet<- pd0$road_quiet +eps

X0 <- predict(b,newdata=pd0,type="lpmatrix")
X1 <- predict(b,newdata=pd1,type="lpmatrix")
Xz <- (X1-X0)/eps


G$Ain <- rbind(Xz) ## inequality constraint matrix
G$bin <- rep(0,nrow(G$Ain))
G$sp <- b$sp
G$C<-matrix(0,0,0)
G$p <- coef(b)
G$off <- G$off-1 ## to match what pcls is expecting
## force inital parameters to meet constraint
G$p[11:18] <- 0.0
p <- pcls(G) ## constrained fit
par(mfrow=c(2,3))
plot(c) ## original fit
b$coefficients <- p
plot(b) ## constrained fit
## note that standard errors


Any help or suggestions on where to read more about pcls() would be very much appreciated!

Kind regards,
Kathrine

From girijagun at gmail.com  Tue Jul 23 11:29:40 2013
From: girijagun at gmail.com (G Girija)
Date: Tue, 23 Jul 2013 14:59:40 +0530
Subject: [R] non-conformable arrays
Message-ID: <CAOLvsEy6PzgHpjS=RwOFEfTSzSDEy=Z00=rmAk37Nrw0MCKKvw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/65617cb4/attachment.pl>

From Eric.TRAVAGLINI at crealp.vs.ch  Tue Jul 23 13:22:04 2013
From: Eric.TRAVAGLINI at crealp.vs.ch (Eric TRAVAGLINI)
Date: Tue, 23 Jul 2013 13:22:04 +0200
Subject: [R] List Structure and Acces to data
Message-ID: <51EE837C0200002D0001855B@mailhub1.vs.ch>

Hello,
 
I used some other langages as Matlab and i just began with R, and i need help with data structure.
 
Here is my code
 
"
fct_echant_hist <- function ( my_echant, my_vitesse, my_hist, my_summary) {
	  list (my_echant = my_echant,
		my_vitesse = my_vitesse,
		my_hist = my_hist,
		my_summary = my_summary)} 
 
 
my_echant_hist <- replicate(dim(pas)[1], fct_echant_hist(0L,
			   0L,
			   matrix(nrow=length(my_breaks),ncol=1),
			   matrix(nrow=6,ncol=1)),
	   simplify=FALSE)
" 
Is it possible to acces to all data of my_vitesse ?
 
 
to acces to the my_vitesse of the first record i write 
my_echant_hist[[1]][[2]]
 
I try something like that without succes :
my_echant_hist[[]][[2]] or 
my_echant_hist[[:]][[2]] or
my_echant_hist[[;]][[2]] 
 
 
Thanks a lot
 
Eric ./.
 
P:S Sorry for my English

From smartpink111 at yahoo.com  Tue Jul 23 14:36:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 23 Jul 2013 05:36:58 -0700 (PDT)
Subject: [R] Some days missing using xtabs
In-Reply-To: <51EE5FF1.7040603@sapo.pt>
References: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
	<51EE5FF1.7040603@sapo.pt>
Message-ID: <1374583018.44098.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,

I tried this without the changing the class, but there was no warning.

?str(release_freq)
#'data.frame':??? 62 obs. of? 4 variables:
# $ d_release: Factor w/ 31 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
# $ m_release: Factor w/ 2 levels "5","6": 1 1 1 1 1 1 1 1 1 1 ...
# $ y_release: Factor w/ 1 level "2004": 1 1 1 1 1 1 1 1 1 1 ...
# $ Freq???? : num? 0 0 0 0 1 1 1 0 0 1 ...
?str(temp_h12)
#'data.frame':??? 31 obs. of? 4 variables:
# $ y_temp: int? 2004 2004 2004 2004 2004 2004 2004 2004 2004 2004 ...
# $ m_temp: int? 5 5 5 5 5 5 5 5 5 5 ...
# $ d_temp: int? 1 2 3 4 5 6 7 8 9 10 ...
# $ temp? : num? 16.9 18 17.4 19.7 105.7 ...


res<-merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)

? head(res)
?# y_release m_release d_release Freq temp
#1????? 2004???????? 5???????? 1??? 0 16.9
#2????? 2004???????? 5??????? 10??? 1 16.1
#3????? 2004???????? 5??????? 11??? 1 15.8
#4????? 2004???????? 5??????? 12??? 1 15.1
#5????? 2004???????? 5??????? 13??? 0 17.8
#6????? 2004???????? 5??????? 14??? 0 17.4

# changing the class
release_freq$d_release <- as.integer(as.character(release_freq$d_release))
release_freq$m_release <- as.integer(as.character(release_freq$m_release))
release_freq$y_release <- as.integer(as.character(release_freq$y_release))
res1<- merge(release_freq, temp_h12, 
by.x=c("y_release","m_release","d_release"), 
by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)

head(res1)
#? y_release m_release d_release Freq temp
#1????? 2004???????? 5???????? 1??? 0 16.9
#2????? 2004???????? 5??????? 10??? 1 16.1
#3????? 2004???????? 5??????? 11??? 1 15.8
#4????? 2004???????? 5??????? 12??? 1 15.1
#5????? 2004???????? 5??????? 13??? 0 17.8
#6????? 2004???????? 5??????? 14??? 0 17.4

The results are not identical.
? identical(res,res1)
#[1] FALSE
str(res)
#'data.frame':??? 31 obs. of? 5 variables:
# $ y_release: Factor w/ 1 level "2004": 1 1 1 1 1 1 1 1 1 1 ...
# $ m_release: Factor w/ 2 levels "5","6": 1 1 1 1 1 1 1 1 1 1 ...
# $ d_release: Factor w/ 31 levels "1","2","3","4",..: 1 10 11 12 13 14 15 16 17 18 ...
# $ Freq???? : num? 0 1 1 1 0 0 1 1 0 1 ...
# $ temp???? : num? 16.9 16.1 15.8 15.1 17.8 17.4 16 17.7 17.3 22.3 ...
?str(res1)
#'data.frame':??? 31 obs. of? 5 variables:
# $ y_release: int? 2004 2004 2004 2004 2004 2004 2004 2004 2004 2004 ...
# $ m_release: int? 5 5 5 5 5 5 5 5 5 5 ...
# $ d_release: int? 1 10 11 12 13 14 15 16 17 18 ...
# $ Freq???? : num? 0 1 1 1 0 0 1 1 0 1 ...
# $ temp???? : num? 16.9 16.1 15.8 15.1 17.8 17.4 16 17.7 17.3 22.3 ...


sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_CA.UTF-8?????? LC_NUMERIC=C????????????? 
?[3] LC_TIME=en_CA.UTF-8??????? LC_COLLATE=en_CA.UTF-8??? 
?[5] LC_MONETARY=en_CA.UTF-8??? LC_MESSAGES=en_CA.UTF-8?? 
?[7] LC_PAPER=C???????????????? LC_NAME=C???????????????? 
?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C??????????? 
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C?????? 

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

other attached packages:
[1] stringr_0.6.2? reshape2_1.2.2

loaded via a namespace (and not attached):
[1] plyr_1.8

A.K.

----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Stefano Sofia <stefano.sofia at regione.marche.it>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Tuesday, July 23, 2013 6:50 AM
Subject: Re: [R] Some days missing using xtabs

Hello,

As for your second question, before merge(), try the following.

release_freq$d_release <- as.integer(as.character(release_freq$d_release))
release_freq$m_release <- as.integer(as.character(release_freq$m_release))
release_freq$y_release <- as.integer(as.character(release_freq$y_release))


And the warning is gone.

Hope this helps,

Rui Barradas

Em 23-07-2013 10:33, Stefano Sofia escreveu:
> Dear R-users,
> given the following data frame called hospital_2004
>
> gender d_birth m_birth y_birth address d_admittance m_admittance y_admittance yard_admittance d_release m_release y_release yard_release diaprinc diasec1 diasec2 diasec3 diasec4 diasec5
> 2 13 12 1929 42002 30 3 2004 3003 6 5 2004 4902 430 4299 51881 4275 78001 0
> 1 1 8 1935 42002 7 4 2004 2401 18 5 2004 1801 20500 V581 0388 5849 0 0
> 1 23 12 1956 42018 26 4 2004 2402 31 5 2004 2402 1552 5715 7895 25000 4148 5722
> 1 9 8 1919 42002 05 5 2004 2602 22 5 2004 4902 51881 4254 4275 0 0 0
> 2 11 1 1925 52014 30 4 2004 2603 13 6 2004 4902 51881 49121 2732 4275 4299 5849
> 2 1 3 1963 44060 1 5 2004 5101 16 5 2004 2401 3201 1519 1976 1983 4019 0
> 1 6 3 1937 45010 6 5 2004 3003 12 5 2004 4901 431 3314 41189 25001 4019 V594
> 1 3 9 1931 42034 3 5 2004 5101 5 5 2004 5101 78559 4829 5119 1619 4241 585
> 2 13 9 1912 41007 5 5 2004 4901 7 5 2004 4901 85225 4019 42731 49121 0 0
> 1 21 10 1936 15146 7 5 2004 4901 10 5 2004 4901 431 430 V594 V595 0 0
> 2 8 5 1933 43044 8 5 2004 5802 8 6 2004 5802 5712 45620 2851 5119 5184 0
> 1 25 1 1926 41057 8 5 2004 4901 15 5 2004 4901 431 78001 49121 0 0 0
> 1 6 1 1923 42002 10 5 2004 1401 11 5 2004 4901 4440 412 4413 0 0 0
> 1 19 3 1934 42022 9 5 2004 1401 21 6 2004 4901 4413 5609 99811 4019 412 0
> 1 6 6 1921 43052 15 5 2004 4302 4 6 2004 4302 1890 20280 436 49121 9986 V1005
>
> when I try to evaluate the frequency of daily releases through
>
> release_freq <- as.data.frame(xtabs( ~ d_release + m_release + y_release, data=hospital_2004))
>
> I get the following result:
>
> d_release m_release y_release Freq
> 4? ? ? ?  5? ? ? 2004? ? 0
> 5? ? ? ?  5? ? ? 2004? ? 1
> 6? ? ? ?  5? ? ? 2004? ? 1
> 7? ? ? ?  5? ? ? 2004? ? 1
> 8? ? ? ?  5? ? ? 2004? ? 0
> 10? ? ? ?  5? ? ? 2004? ? 1
> 11? ? ? ?  5? ? ? 2004? ? 1
> 12? ? ? ?  5? ? ? 2004? ? 1
> 13? ? ? ?  5? ? ? 2004? ? 0
> 15? ? ? ?  5? ? ? 2004? ? 1
> 16? ? ? ?  5? ? ? 2004? ? 1
> 18? ? ? ?  5? ? ? 2004? ? 1
> 21? ? ? ?  5? ? ? 2004? ? 0
> 22? ? ? ?  5? ? ? 2004? ? 1
> 31? ? ? ?  5? ? ? 2004? ? 1
> 4? ? ? ?  6? ? ? 2004? ? 1
> 5? ? ? ?  6? ? ? 2004? ? 0
> 6? ? ? ?  6? ? ? 2004? ? 0
> 7? ? ? ?  6? ? ? 2004? ? 0
> 8? ? ? ?  6? ? ? 2004? ? 1
> 10? ? ? ?  6? ? ? 2004? ? 0
> 11? ? ? ?  6? ? ? 2004? ? 0
> 12? ? ? ?  6? ? ? 2004? ? 0
> 13? ? ? ?  6? ? ? 2004? ? 1
> 15? ? ? ?  6? ? ? 2004? ? 0
> 16? ? ? ?  6? ? ? 2004? ? 0
> 18? ? ? ?  6? ? ? 2004? ? 0
> 21? ? ? ?  6? ? ? 2004? ? 1
> 22? ? ? ?  6? ? ? 2004? ? 0
> 31? ? ? ?  6? ? ? 2004? ? 0
>
> Why the 1st, 2nd, 3rd, 9th, 14th, 17th, 19th, 20th, from 23rd to 30th of both May and June are missing? (and there is the 31st of June?)
>
> And a final question: why given another data frame called temp_h12
>
> y_temp m_temp d_temp temp
> 2004 5 1 16.90
> 2004 5 2 18.00
> 2004 5 3 17.40
> 2004 5 4 19.70
> 2004 5 5 105.70
> 2004 5 6 17.30
> 2004 5 7 17.00
> 2004 5 8 16.20
> 2004 5 9 16.10
> 2004 5 10 16.10
> 2004 5 11 15.80
> 2004 5 12 15.10
> 2004 5 13 17.80
> 2004 5 14 17.40
> 2004 5 15 16.00
> 2004 5 16 17.70
> 2004 5 17 17.30
> 2004 5 18 22.30
> 2004 5 19 23.30
> 2004 5 20 24.30
> 2004 5 21 19.90
> 2004 5 22 15.70
> 2004 5 23 15.80
> 2004 5 24 17.10
> 2004 5 25 18.30
> 2004 5 26 21.00
> 2004 5 27 18.20
> 2004 5 28 17.90
> 2004 5 29 19.40
> 2004 5 30 22.10
> 2004 5 31 17.40
>
> merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>
> gives the following warning
>
> Warning message:
> In `[<-.factor`(`*tmp*`, ri, value = 1:31) :
>? ? invalid factor level, NAs generated
> ?
>
>
>
> Thank you for your help
> Stefano Sofia
>
>
>
> ________________________________
>
> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>
> ??? [[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Antony.Akkara at ge.com  Tue Jul 23 14:49:29 2013
From: Antony.Akkara at ge.com (Akkara, Antony (GE Power & Water, Non-GE))
Date: Tue, 23 Jul 2013 18:19:29 +0530
Subject: [R] Select csv files by choosing datetime
In-Reply-To: <64CAF40B-921E-4643-9D3D-FB96FC7B6A55@gmail.com>
References: <1374482203999-4672023.post@n4.nabble.com>
	<64CAF40B-921E-4643-9D3D-FB96FC7B6A55@gmail.com>
Message-ID: <5A52F9658B4B8C4B83D50A7BAD38F5D602F98953@BANMLVEM04.e2k.ad.ge.com>

Hi,

I tried with file.info() . But how can I get a set of filenames with
path which is created between two date/time.

Thanks,
Antony.



-----Original Message-----
From: Jim Holtman [mailto:jholtman at gmail.com] 
Sent: Monday, July 22, 2013 4:23 PM
To: Akkara, Antony (GE Power & Water, Non-GE)
Cc: r-help at r-project.org
Subject: Re: [R] Select csv files by choosing datetime

you can use 'file.info' to get the date the file was created and then
choose the file you want.

Sent from my iPad

On Jul 22, 2013, at 4:36, R_Antony <antony.akkara at ge.com> wrote:

> Hi,
> 
> how can we read particular files from a path ? - i mean, i need to 
> read csv files which is created between two date and time. Here i need

> to get filename along with path.
> 
> Thanks,
> Antony.
> 
> 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Select-csv-files-by-choosing-datetime-tp
> 4672023.html Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From stefano.sofia at regione.marche.it  Tue Jul 23 15:06:58 2013
From: stefano.sofia at regione.marche.it (Stefano Sofia)
Date: Tue, 23 Jul 2013 13:06:58 +0000
Subject: [R] R:  Some days missing using xtabs
In-Reply-To: <51EE79D4.7050808@sapo.pt>
References: <8B435C9568170B469AE31E8891E8CC4F026355@ESINO.regionemarche.intra>
	<8B435C9568170B469AE31E8891E8CC4F026374@ESINO.regionemarche.intra>
	<51EE5FF1.7040603@sapo.pt>
	<1374583018.44098.YahooMailNeo@web142605.mail.bf1.yahoo.com>,
	<51EE79D4.7050808@sapo.pt>
Message-ID: <8B435C9568170B469AE31E8891E8CC4F0294C4@CHIENTI.regionemarche.intra>

Thanks to Rui Barradas and to Arun.
Rui's considerations are very sensible, and they solved all my doubts.

Thank you
Stefano

________________________________________
Da: Rui Barradas [ruipbarradas at sapo.pt]
Inviato: marted? 23 luglio 2013 14.40
A: arun
Cc: Stefano Sofia; R help
Oggetto: Re: [R] Some days missing using xtabs

Hello,

Something I've just noticed, stringsAsFactors is not an argument to merge().

And, without changing the class I g a warning:

Warning message:
In `[<-.factor`(`*tmp*`, ri, value = 1:31) :
   invalid factor level, NA generated


Rui Barradas

Em 23-07-2013 13:36, arun escreveu:
> Hi,
>
> I tried this without the changing the class, but there was no warning.
>
>   str(release_freq)
> #'data.frame':    62 obs. of  4 variables:
> # $ d_release: Factor w/ 31 levels "1","2","3","4",..: 1 2 3 4 5 6 7 8 9 10 ...
> # $ m_release: Factor w/ 2 levels "5","6": 1 1 1 1 1 1 1 1 1 1 ...
> # $ y_release: Factor w/ 1 level "2004": 1 1 1 1 1 1 1 1 1 1 ...
> # $ Freq     : num  0 0 0 0 1 1 1 0 0 1 ...
>   str(temp_h12)
> #'data.frame':    31 obs. of  4 variables:
> # $ y_temp: int  2004 2004 2004 2004 2004 2004 2004 2004 2004 2004 ...
> # $ m_temp: int  5 5 5 5 5 5 5 5 5 5 ...
> # $ d_temp: int  1 2 3 4 5 6 7 8 9 10 ...
> # $ temp  : num  16.9 18 17.4 19.7 105.7 ...
>
>
> res<-merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>
>    head(res)
>   # y_release m_release d_release Freq temp
> #1      2004         5         1    0 16.9
> #2      2004         5        10    1 16.1
> #3      2004         5        11    1 15.8
> #4      2004         5        12    1 15.1
> #5      2004         5        13    0 17.8
> #6      2004         5        14    0 17.4
>
> # changing the class
> release_freq$d_release <- as.integer(as.character(release_freq$d_release))
> release_freq$m_release <- as.integer(as.character(release_freq$m_release))
> release_freq$y_release <- as.integer(as.character(release_freq$y_release))
> res1<- merge(release_freq, temp_h12,
> by.x=c("y_release","m_release","d_release"),
> by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>
> head(res1)
> #  y_release m_release d_release Freq temp
> #1      2004         5         1    0 16.9
> #2      2004         5        10    1 16.1
> #3      2004         5        11    1 15.8
> #4      2004         5        12    1 15.1
> #5      2004         5        13    0 17.8
> #6      2004         5        14    0 17.4
>
> The results are not identical.
>    identical(res,res1)
> #[1] FALSE
> str(res)
> #'data.frame':    31 obs. of  5 variables:
> # $ y_release: Factor w/ 1 level "2004": 1 1 1 1 1 1 1 1 1 1 ...
> # $ m_release: Factor w/ 2 levels "5","6": 1 1 1 1 1 1 1 1 1 1 ...
> # $ d_release: Factor w/ 31 levels "1","2","3","4",..: 1 10 11 12 13 14 15 16 17 18 ...
> # $ Freq     : num  0 1 1 1 0 0 1 1 0 1 ...
> # $ temp     : num  16.9 16.1 15.8 15.1 17.8 17.4 16 17.7 17.3 22.3 ...
>   str(res1)
> #'data.frame':    31 obs. of  5 variables:
> # $ y_release: int  2004 2004 2004 2004 2004 2004 2004 2004 2004 2004 ...
> # $ m_release: int  5 5 5 5 5 5 5 5 5 5 ...
> # $ d_release: int  1 10 11 12 13 14 15 16 17 18 ...
> # $ Freq     : num  0 1 1 1 0 0 1 1 0 1 ...
> # $ temp     : num  16.9 16.1 15.8 15.1 17.8 17.4 16 17.7 17.3 22.3 ...
>
>
> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-unknown-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_CA.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_CA.UTF-8        LC_COLLATE=en_CA.UTF-8
>   [5] LC_MONETARY=en_CA.UTF-8    LC_MESSAGES=en_CA.UTF-8
>   [7] LC_PAPER=C                 LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] stringr_0.6.2  reshape2_1.2.2
>
> loaded via a namespace (and not attached):
> [1] plyr_1.8
>
> A.K.
>
> ----- Original Message -----
> From: Rui Barradas <ruipbarradas at sapo.pt>
> To: Stefano Sofia <stefano.sofia at regione.marche.it>
> Cc: "r-help at r-project.org" <r-help at r-project.org>
> Sent: Tuesday, July 23, 2013 6:50 AM
> Subject: Re: [R] Some days missing using xtabs
>
> Hello,
>
> As for your second question, before merge(), try the following.
>
> release_freq$d_release <- as.integer(as.character(release_freq$d_release))
> release_freq$m_release <- as.integer(as.character(release_freq$m_release))
> release_freq$y_release <- as.integer(as.character(release_freq$y_release))
>
>
> And the warning is gone.
>
> Hope this helps,
>
> Rui Barradas
>
> Em 23-07-2013 10:33, Stefano Sofia escreveu:
>> Dear R-users,
>> given the following data frame called hospital_2004
>>
>> gender d_birth m_birth y_birth address d_admittance m_admittance y_admittance yard_admittance d_release m_release y_release yard_release diaprinc diasec1 diasec2 diasec3 diasec4 diasec5
>> 2 13 12 1929 42002 30 3 2004 3003 6 5 2004 4902 430 4299 51881 4275 78001 0
>> 1 1 8 1935 42002 7 4 2004 2401 18 5 2004 1801 20500 V581 0388 5849 0 0
>> 1 23 12 1956 42018 26 4 2004 2402 31 5 2004 2402 1552 5715 7895 25000 4148 5722
>> 1 9 8 1919 42002 05 5 2004 2602 22 5 2004 4902 51881 4254 4275 0 0 0
>> 2 11 1 1925 52014 30 4 2004 2603 13 6 2004 4902 51881 49121 2732 4275 4299 5849
>> 2 1 3 1963 44060 1 5 2004 5101 16 5 2004 2401 3201 1519 1976 1983 4019 0
>> 1 6 3 1937 45010 6 5 2004 3003 12 5 2004 4901 431 3314 41189 25001 4019 V594
>> 1 3 9 1931 42034 3 5 2004 5101 5 5 2004 5101 78559 4829 5119 1619 4241 585
>> 2 13 9 1912 41007 5 5 2004 4901 7 5 2004 4901 85225 4019 42731 49121 0 0
>> 1 21 10 1936 15146 7 5 2004 4901 10 5 2004 4901 431 430 V594 V595 0 0
>> 2 8 5 1933 43044 8 5 2004 5802 8 6 2004 5802 5712 45620 2851 5119 5184 0
>> 1 25 1 1926 41057 8 5 2004 4901 15 5 2004 4901 431 78001 49121 0 0 0
>> 1 6 1 1923 42002 10 5 2004 1401 11 5 2004 4901 4440 412 4413 0 0 0
>> 1 19 3 1934 42022 9 5 2004 1401 21 6 2004 4901 4413 5609 99811 4019 412 0
>> 1 6 6 1921 43052 15 5 2004 4302 4 6 2004 4302 1890 20280 436 49121 9986 V1005
>>
>> when I try to evaluate the frequency of daily releases through
>>
>> release_freq <- as.data.frame(xtabs( ~ d_release + m_release + y_release, data=hospital_2004))
>>
>> I get the following result:
>>
>> d_release m_release y_release Freq
>> 4         5      2004    0
>> 5         5      2004    1
>> 6         5      2004    1
>> 7         5      2004    1
>> 8         5      2004    0
>> 10         5      2004    1
>> 11         5      2004    1
>> 12         5      2004    1
>> 13         5      2004    0
>> 15         5      2004    1
>> 16         5      2004    1
>> 18         5      2004    1
>> 21         5      2004    0
>> 22         5      2004    1
>> 31         5      2004    1
>> 4         6      2004    1
>> 5         6      2004    0
>> 6         6      2004    0
>> 7         6      2004    0
>> 8         6      2004    1
>> 10         6      2004    0
>> 11         6      2004    0
>> 12         6      2004    0
>> 13         6      2004    1
>> 15         6      2004    0
>> 16         6      2004    0
>> 18         6      2004    0
>> 21         6      2004    1
>> 22         6      2004    0
>> 31         6      2004    0
>>
>> Why the 1st, 2nd, 3rd, 9th, 14th, 17th, 19th, 20th, from 23rd to 30th of both May and June are missing? (and there is the 31st of June?)
>>
>> And a final question: why given another data frame called temp_h12
>>
>> y_temp m_temp d_temp temp
>> 2004 5 1 16.90
>> 2004 5 2 18.00
>> 2004 5 3 17.40
>> 2004 5 4 19.70
>> 2004 5 5 105.70
>> 2004 5 6 17.30
>> 2004 5 7 17.00
>> 2004 5 8 16.20
>> 2004 5 9 16.10
>> 2004 5 10 16.10
>> 2004 5 11 15.80
>> 2004 5 12 15.10
>> 2004 5 13 17.80
>> 2004 5 14 17.40
>> 2004 5 15 16.00
>> 2004 5 16 17.70
>> 2004 5 17 17.30
>> 2004 5 18 22.30
>> 2004 5 19 23.30
>> 2004 5 20 24.30
>> 2004 5 21 19.90
>> 2004 5 22 15.70
>> 2004 5 23 15.80
>> 2004 5 24 17.10
>> 2004 5 25 18.30
>> 2004 5 26 21.00
>> 2004 5 27 18.20
>> 2004 5 28 17.90
>> 2004 5 29 19.40
>> 2004 5 30 22.10
>> 2004 5 31 17.40
>>
>> merge(release_freq, temp_h12, by.x=c("y_release","m_release","d_release"), by.y=c("y_temp","m_temp","d_temp"), stringsAsFactors=FALSE)
>>
>> gives the following warning
>>
>> Warning message:
>> In `[<-.factor`(`*tmp*`, ri, value = 1:31) :
>>      invalid factor level, NAs generated
>> ?
>>
>>
>>
>> Thank you for your help
>> Stefano Sofia
>>
>>
>>
>> ________________________________
>>
>> AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell'art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
>> IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.
>>
>>      [[alternative HTML version deleted]]
>>
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

________________________________

AVVISO IMPORTANTE: Questo messaggio di posta elettronica pu? contenere informazioni confidenziali, pertanto ? destinato solo a persone autorizzate alla ricezione. I messaggi di posta elettronica per i client di Regione Marche possono contenere informazioni confidenziali e con privilegi legali. Se non si ? il destinatario specificato, non leggere, copiare, inoltrare o archiviare questo messaggio. Se si ? ricevuto questo messaggio per errore, inoltrarlo al mittente ed eliminarlo completamente dal sistema del proprio computer. Ai sensi dell?art. 6 della DGR n. 1394/2008 si segnala che, in caso di necessit? ed urgenza, la risposta al presente messaggio di posta elettronica pu? essere visionata da persone estranee al destinatario.
IMPORTANT NOTICE: This e-mail message is intended to be received only by persons entitled to receive the confidential information it may contain. E-mail messages to clients of Regione Marche may contain information that is confidential and legally privileged. Please do not read, copy, forward, or store this message unless you are an intended recipient of it. If you have received this message in error, please forward it to the sender and delete it completely from your computer system.

From Antony.Akkara at ge.com  Tue Jul 23 15:34:28 2013
From: Antony.Akkara at ge.com (Akkara, Antony (GE Power & Water, Non-GE))
Date: Tue, 23 Jul 2013 19:04:28 +0530
Subject: [R] Select csv files by choosing datetime
References: <1374482203999-4672023.post@n4.nabble.com>
	<64CAF40B-921E-4643-9D3D-FB96FC7B6A55@gmail.com> 
Message-ID: <5A52F9658B4B8C4B83D50A7BAD38F5D602F989B9@BANMLVEM04.e2k.ad.ge.com>

I tried like this,

file.info(list.files(path = fpath, pattern = "*.csv", all.files = FALSE,
full.names = TRUE,ignore.case = TRUE))$mtime
- It returning files modified date.
["2013-07-23 15:43:51 IST" "2013-07-23 15:43:51 IST" "2013-07-23
15:43:51 IST" "2013-07-23 15:45:33 IST" "2013-07-23 15:45:32 IST"]


file.info(list.files(path = fpath, pattern = "*.csv", all.files = FALSE,
full.names = TRUE,ignore.case = TRUE))$mtime="2013-07-23 15:51:41 IST"
-here getting error
[Error in file.info(list.files(path = fpath, pattern = "*.csv",
all.files = FALSE,  :  could not find function "file.info<-"]



But how can I get filenames along with path which is created
between(modified date) two date/time.

Thanks
Antony.



-----Original Message-----
From: Akkara, Antony (GE Energy, Non-GE) 
Sent: Tuesday, July 23, 2013 6:19 PM
To: 'Jim Holtman'
Cc: r-help at r-project.org
Subject: RE: [R] Select csv files by choosing datetime

Hi,

I tried with file.info() . But how can I get a set of filenames with
path which is created between two date/time.

Thanks,
Antony.



-----Original Message-----
From: Jim Holtman [mailto:jholtman at gmail.com]
Sent: Monday, July 22, 2013 4:23 PM
To: Akkara, Antony (GE Power & Water, Non-GE)
Cc: r-help at r-project.org
Subject: Re: [R] Select csv files by choosing datetime

you can use 'file.info' to get the date the file was created and then
choose the file you want.

Sent from my iPad

On Jul 22, 2013, at 4:36, R_Antony <antony.akkara at ge.com> wrote:

> Hi,
> 
> how can we read particular files from a path ? - i mean, i need to 
> read csv files which is created between two date and time. Here i need

> to get filename along with path.
> 
> Thanks,
> Antony.
> 
> 
> 
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Select-csv-files-by-choosing-datetime-tp
> 4672023.html Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From fgnu32 at yahoo.com  Tue Jul 23 15:13:16 2013
From: fgnu32 at yahoo.com (Fg Nu)
Date: Tue, 23 Jul 2013 06:13:16 -0700 (PDT)
Subject: [R] cbind error with check.names
Message-ID: <1374585196.9069.YahooMailNeo@web160106.mail.bf1.yahoo.com>



Hello all,

I posted a question about cbind and an error when specifying the check.names argument here:
http://stackoverflow.com/questions/17810470/cbind-error-with-check-names


I was advised to take this to R-devel, but before that, I'd like to get the opinions of people on this list.

Thanks


From gunter.berton at gene.com  Tue Jul 23 15:44:41 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 23 Jul 2013 06:44:41 -0700
Subject: [R] List Structure and Acces to data
In-Reply-To: <51EE837C0200002D0001855B@mailhub1.vs.ch>
References: <51EE837C0200002D0001855B@mailhub1.vs.ch>
Message-ID: <CACk-te1K=LSCeim8-DWAMx4b8tVuJrwgtqyO-83T8EGOkswjPg@mail.gmail.com>

Read the "Introduction to R tutorial" that is part of your R
installation. For more complete information, consult the "R Language
Definition" and ?"["    .

-- Bert

On Tue, Jul 23, 2013 at 4:22 AM, Eric TRAVAGLINI
<Eric.TRAVAGLINI at crealp.vs.ch> wrote:
> Hello,
>
> I used some other langages as Matlab and i just began with R, and i need help with data structure.
>
> Here is my code
>
> "
> fct_echant_hist <- function ( my_echant, my_vitesse, my_hist, my_summary) {
>           list (my_echant = my_echant,
>                 my_vitesse = my_vitesse,
>                 my_hist = my_hist,
>                 my_summary = my_summary)}
>
>
> my_echant_hist <- replicate(dim(pas)[1], fct_echant_hist(0L,
>                            0L,
>                            matrix(nrow=length(my_breaks),ncol=1),
>                            matrix(nrow=6,ncol=1)),
>            simplify=FALSE)
> "
> Is it possible to acces to all data of my_vitesse ?
>
>
> to acces to the my_vitesse of the first record i write
> my_echant_hist[[1]][[2]]
>
> I try something like that without succes :
> my_echant_hist[[]][[2]] or
> my_echant_hist[[:]][[2]] or
> my_echant_hist[[;]][[2]]
>
>
> Thanks a lot
>
> Eric ./.
>
> P:S Sorry for my English
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From bhh at xs4all.nl  Tue Jul 23 15:47:26 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Tue, 23 Jul 2013 15:47:26 +0200
Subject: [R] List Structure and Acces to data
In-Reply-To: <51EE837C0200002D0001855B@mailhub1.vs.ch>
References: <51EE837C0200002D0001855B@mailhub1.vs.ch>
Message-ID: <B076867F-6098-42C2-BF29-7B69FC3C0432@xs4all.nl>


On 23-07-2013, at 13:22, "Eric TRAVAGLINI" <Eric.TRAVAGLINI at crealp.vs.ch> wrote:

> Hello,
> 
> I used some other langages as Matlab and i just began with R, and i need help with data structure.
> 
> Here is my code
> 
> "
> fct_echant_hist <- function ( my_echant, my_vitesse, my_hist, my_summary) {
> 	  list (my_echant = my_echant,
> 		my_vitesse = my_vitesse,
> 		my_hist = my_hist,
> 		my_summary = my_summary)} 
> 
> 
> my_echant_hist <- replicate(dim(pas)[1], fct_echant_hist(0L,
> 			   0L,
> 			   matrix(nrow=length(my_breaks),ncol=1),
> 			   matrix(nrow=6,ncol=1)),
> 	   simplify=FALSE)
> " 
> Is it possible to acces to all data of my_vitesse ?
> 
> 
> to acces to the my_vitesse of the first record i write 
> my_echant_hist[[1]][[2]]
> 
> I try something like that without succes :
> my_echant_hist[[]][[2]] or 
> my_echant_hist[[:]][[2]] or
> my_echant_hist[[;]][[2]] 
> 

Have a look in the "An Introduction to R" section 6.1 "Lists".

Berend


From jfox at mcmaster.ca  Tue Jul 23 15:56:56 2013
From: jfox at mcmaster.ca (John Fox)
Date: Tue, 23 Jul 2013 09:56:56 -0400
Subject: [R] Error with sem function df = -6
In-Reply-To: <CAK6qXJ3V_H+dYiQekEqhrxavh8RZMdSO+O1rL11gUdVsf5nhyQ@mail.gmail.com>
References: <CAK6qXJ3V_H+dYiQekEqhrxavh8RZMdSO+O1rL11gUdVsf5nhyQ@mail.gmail.com>
Message-ID: <web-466744046@cgpsrv2.cis.mcmaster.ca>

Dear Immanuel,

In the absence of more information, your question is unanswerable, since there's no way of knowing which variables in your model are observed and which are latent. It was my guess that Y1, Z1, and Z2 (along with UNIT) are observed and CF is latent, but this is clearly wrong given the df calculation.

Here, as the posting guide suggests, is a reproducible example, using your model and call to sem(), but clearly defined data:

---- snip ---

> set.seed(12345)
> data <- matrix(rnorm(500*3), 500, 3)
> S2 <- rawMoments(cbind(1, data))
> rownames(S2) <- colnames(S2) <- c("UNIT", "Z1", "Z2", "Y1")
> 
> sem.m1<-sem(model=model.ram1, S=S2, N=500, fixed.x="UNIT", raw=T)
Error in sem.default(ram, S = S, N = N, raw = raw, data = data, pattern.number = pattern.number,  : 
  The model has negative degrees of freedom = -2

---- snip ---

This model is underidentified, but at least it's possible to figure out why: There are 4*5/2 = 10 unique observed moments; your model has 11 parameters and also has to account for the second moment of the fixed exogenous UNIT. Thus 10 - (11 + 1) = -2, and the model is underidentified.

Some additional comments:

(1) Aside from UNIT there are no exogenous variables in this model.

(2) It's usually easier to use specifyEquations() than specifyModel() to define the model.

(3) If CF is really meant to be a latent variable, then there's a missing normalizing constraint, underidentifying the model apart from the gross comparison of moments and parameters.

(4) If, as here, you have the data, you don't have to compute the raw-moment matrix in a separate step, but could call sem() with the data argument.

Best,
 John

On Mon, 22 Jul 2013 18:55:31 -0400
 Immanuel Williams <jamesijw23 at gmail.com> wrote:
> Hello all,
> I have an issue where I am generating data and trying to confirm the
> estimates using a sem.  I keep getting an error about the degree of freedom
> being negative "Error in sem.default(ram, S = S, N = N, raw = raw, data =
> data, pattern.number = pattern.number,  : The model has negative degrees of
> freedom = -6"
> 
> Can someone explain this error or tell me what is wrong with my model?
> Thank you.
> Here is the code:
> 
> 
> 
> 
> model.ram1 <- specifyModel()
> UNIT -> Y1, ty,0.3
> UNIT -> Z1, tz1,-0.1
> UNIT -> Z2, tz2,0.1
> CF -> Y1, lamy,0.5
> CF -> Z1, lamz1,0.85
> CF -> Z2, lamz2,0.2
> UNIT -> CF, k
> Y1 <-> Y1, psi3, NA
> Z1 <-> Z1, psi1, NA
> Z2 <-> Z2, psi2, NA
> CF <-> CF,vCF1,NA
> 
> sem.m1<-sem(model=model.ram1,S=S2,N=500,fixed.x="UNIT",raw=T)
> 
> -- 
> 
> I.J. Williams
> 
> Ph.D. Student in Education Measurement and Statistics
> Statistics MS
> 
> Mathematics BS
> 
> Rutgers University
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

------------------------------------------------
John Fox
Sen. William McMaster Prof. of Social Statistics
Department of Sociology
McMaster University
Hamilton, Ontario, Canada
http://socserv.mcmaster.ca/jfox/


From ckluss at email.uni-kiel.de  Tue Jul 23 16:03:59 2013
From: ckluss at email.uni-kiel.de (=?UTF-8?B?Q2hyaXN0b2YgS2x1w58=?=)
Date: Tue, 23 Jul 2013 16:03:59 +0200
Subject: [R] optimize integer function parameters
In-Reply-To: <87bo5t34m3.fsf@enricoschumann.net>
References: <ksl8ad$buk$1@ger.gmane.org> <87bo5t34m3.fsf@enricoschumann.net>
Message-ID: <51EE8D4F.4040009@email.uni-kiel.de>

Hi

the integer values in the vectors sim and obs are dates

when I set sim <- f(TS0,TS1,TS2,TB0,TB1,TB2) my A,..,F below
then TS0 and TB0 are depend (and so on)


the main thing in f(...) is something like

  for (i in c(1:length(temperature))) {
       Temp <- temperature[i]
       if (DS < 0) {
         DS <- DS + max(Temp-TB0,0) / TS0
       } else if (DS < 1) {
         ... date0 <- i
         DS <- DS + max(Temp-TB1,0) / TS1
       } else if (DS < 2) {
         ... date1 <- i
         DS <- DS + max(Temp-TB2,0) / TS2
       } else {
         ... date2 <- i
         break
       }
     }


this produced a vector sim = c(date0,date1,date2,...)


now I would like to minimize RMSE(sim,obs) or something like that

thx
Christof



for brute force I would do something like

obs <- ...
act <- 1000

   for (TS0 in seq(50,100,10))
     for (TS1 in seq(750,850,10))
       for (TS2 in seq(400,600,10))
         for (TB0 in c(5:7))
           for (TB1 in c(5:7))
             for (TB2 in c(4:9)) {
               sim <- foosim(dat,TS0,TS1,TS2,TB0,TB1,TB2)
               rmse <- sqrt(mean((sim - obs)^2, na.rm = TRUE))

               if (rmse < act) {
                 print(paste(rmse,TS0,TS1,TS2,TB0,TB1,TB2))
                 act <- rmse
               }
             }


Am 23-07-2013 13:20, schrieb Enrico Schumann:
> On Tue, 23 Jul 2013, Christof Klu? <ckluss at email.uni-kiel.de> writes:
>
>>
>> I have "observations" obs <- (11455, 11536, 11582, 11825, 11900,  ...)
>>
>> and a simulation function f(A,B,C,D,E,F), so sim <- f(A,B,C,D,E,F)
>>
>> e.g. sim = c(11464, 11554, 11603, 11831, 11907, ...)
>>
>> now I would like to fit A,B,C,D,E,F such that "obs" and f(A,B,C,D,E,F)
>> match as well as possible. A,..,F should be integers and have bounds.
>>
>> How would you solve this problem without bruteforce in an acceptable time?
>>
>
>
> That depends on what your "simulation function" looks like.  Could you
> post a (small) self-contained example?
>
>


From ckluss at email.uni-kiel.de  Tue Jul 23 16:03:59 2013
From: ckluss at email.uni-kiel.de (=?UTF-8?B?Q2hyaXN0b2YgS2x1w58=?=)
Date: Tue, 23 Jul 2013 16:03:59 +0200
Subject: [R] optimize integer function parameters
In-Reply-To: <87bo5t34m3.fsf@enricoschumann.net>
References: <ksl8ad$buk$1@ger.gmane.org> <87bo5t34m3.fsf@enricoschumann.net>
Message-ID: <51EE8D4F.4040009@email.uni-kiel.de>

Hi

the integer values in the vectors sim and obs are dates

when I set sim <- f(TS0,TS1,TS2,TB0,TB1,TB2) my A,..,F below
then TS0 and TB0 are depend (and so on)


the main thing in f(...) is something like

  for (i in c(1:length(temperature))) {
       Temp <- temperature[i]
       if (DS < 0) {
         DS <- DS + max(Temp-TB0,0) / TS0
       } else if (DS < 1) {
         ... date0 <- i
         DS <- DS + max(Temp-TB1,0) / TS1
       } else if (DS < 2) {
         ... date1 <- i
         DS <- DS + max(Temp-TB2,0) / TS2
       } else {
         ... date2 <- i
         break
       }
     }


this produced a vector sim = c(date0,date1,date2,...)


now I would like to minimize RMSE(sim,obs) or something like that

thx
Christof



for brute force I would do something like

obs <- ...
act <- 1000

   for (TS0 in seq(50,100,10))
     for (TS1 in seq(750,850,10))
       for (TS2 in seq(400,600,10))
         for (TB0 in c(5:7))
           for (TB1 in c(5:7))
             for (TB2 in c(4:9)) {
               sim <- foosim(dat,TS0,TS1,TS2,TB0,TB1,TB2)
               rmse <- sqrt(mean((sim - obs)^2, na.rm = TRUE))

               if (rmse < act) {
                 print(paste(rmse,TS0,TS1,TS2,TB0,TB1,TB2))
                 act <- rmse
               }
             }


Am 23-07-2013 13:20, schrieb Enrico Schumann:
> On Tue, 23 Jul 2013, Christof Klu? <ckluss at email.uni-kiel.de> writes:
>
>>
>> I have "observations" obs <- (11455, 11536, 11582, 11825, 11900,  ...)
>>
>> and a simulation function f(A,B,C,D,E,F), so sim <- f(A,B,C,D,E,F)
>>
>> e.g. sim = c(11464, 11554, 11603, 11831, 11907, ...)
>>
>> now I would like to fit A,B,C,D,E,F such that "obs" and f(A,B,C,D,E,F)
>> match as well as possible. A,..,F should be integers and have bounds.
>>
>> How would you solve this problem without bruteforce in an acceptable time?
>>
>
>
> That depends on what your "simulation function" looks like.  Could you
> post a (small) self-contained example?
>
>


From dtemplelang at ucdavis.edu  Tue Jul 23 16:06:17 2013
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Tue, 23 Jul 2013 07:06:17 -0700
Subject: [R] downloading web content
In-Reply-To: <CAFf2dDEiEJ_cD=JD4P=DX0=L=dxxC3N8GVz1GjA187H-Ad8yUg@mail.gmail.com>
References: <CAFf2dDEiEJ_cD=JD4P=DX0=L=dxxC3N8GVz1GjA187H-Ad8yUg@mail.gmail.com>
Message-ID: <51EE8DD9.6050205@ucdavis.edu>

Hi Daisy

 Use getURLContent() rather than getURL().
The former handles binary content and this appears to be a zip file.

You can write it to a file or read its contents directly in memory, e.g

  library(RCurl)
  z = getURLContent("http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia")
  attributes(z)

  library(Rcompression)
  ar = zipArchive(z)
  names(ar)
  getZipInfo(ar)
  ar[["data.csv"]]
  dd = read.csv(textConnection(ar[["data.csv"]]))

  D.




On 7/23/13 2:59 AM, Daisy Englert Duursma wrote:
> Hello,
> I am trying to use R to download a bunch of .csv  files such as:
> 
> http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia
> 
> I have tried the following and neither work:
> 
> a<- getURL("
> http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia")
> 
> Error in curlPerform(curl = curl, .opts = opts, .encoding = .encoding) :
>   embedded nul in string:
> and
> 
> a<-httpPOST("
> http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia")
> 
> Error: Internal Server Error
> 
> 
> Any help would be appreciated.
> 
> Daisy
>


From wetbelldiver at gmail.com  Tue Jul 23 16:31:44 2013
From: wetbelldiver at gmail.com (Wet Bell Diver)
Date: Tue, 23 Jul 2013 16:31:44 +0200
Subject: [R] how to download Journal Citation Reports with R
In-Reply-To: <loom.20130721T005629-77@post.gmane.org>
References: <51EAE827.7030801@gmail.com>
	<loom.20130721T005629-77@post.gmane.org>
Message-ID: <51EE93D0.3040606@gmail.com>


Thank Ben,

This works wonderfully, thanks!
BTW: the policy my library publishes regarding JCR implies that this 
falls under acceptable use, as long as the data is for personal use, so 
that's fine.

I'll need to read up on RCurl a little further, as this seems a powerful 
package, thank you for bringing it to my attention.

--Peter


Op 21-7-2013 0:58, Ben Bolker schreef:
> Wet Bell Diver <wetbelldiver <at> gmail.com> writes:
>
>> R-3.0.1, Rstudio, Win7 x64
>>
>> Dear list,
>>
>> I would like to download all the webpages of the Journal Citations
>> Report (science edition), for a given year. I can do so manually, but
>> that it very time intensive, so I would like to use R for that.
>>
>> I have tried many things, including:
>> download.file(url =
>> "http://admin-apps.webofknowledge.com/JCR/JCR?RQ=SELECT_ALL&cursor=21",
>> destfile = "test.htm", method = "internal")
>> which would get the page starting with journal number 21.
>> However, test.htm only includes the message:
>>
>>   >>>
>    You need to review the RCurl package and look for "cookies", which
> will allow you (once you have established a session in a browser) to
> copy the cookies (tokens which allow you access) into your R session.
> However, you will probably be violating the terms of service of JCR.
> You should talk to your librarian about this.  When I wanted to do
> a similar project I worked out a system where I generated the URLs
> automatically and got a student assistant to (efficiently) go to the
> URLs and paste the results into output files.
>
>    Ben Bolker
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From kw1958 at gmail.com  Tue Jul 23 16:43:17 2013
From: kw1958 at gmail.com (Keith S Weintraub)
Date: Tue, 23 Jul 2013 10:43:17 -0400
Subject: [R] Simple example of web-scraping.
Message-ID: <2ABF6D2E-57BB-4CF6-8EED-DF036B2F58F5@gmail.com>

Folks,

I was wondering if anyone has an example or a pointer to an example of code to scrape a web page.

The tricky parts for me are the following:
* I might need to get multiple pages in sequence.
* I need to login with user-name and password.

Thanks for your time and help,
KW

--


From jimmycloud at gmail.com  Tue Jul 23 16:50:10 2013
From: jimmycloud at gmail.com (Jie)
Date: Tue, 23 Jul 2013 10:50:10 -0400
Subject: [R] p-values from multiple testing
Message-ID: <CACXG3Gh7peFDOztMjm+JduHx8VjqbWCscZzBjL8_Cwua+REGjg@mail.gmail.com>

Dear All,

I performed thousands of testings and obtained p-values.
And then I did two-sided uniform KS test of the p-values, the result
claimed it is uniform.
So does it mean that my model are wrong? Because I expect more small
p-values near 0.
This is a preliminary step before correcting the multiplicity.
Attached is hist of p-values (does this list allow attachment?). The ks test:

One-sample Kolmogorov-Smirnov test

D = 0.0493, p-value = 1.388e-06

alternative hypothesis: two-sided

Thank you for your attention.

Best wishes,
Jie
-------------- next part --------------
A non-text attachment was scrubbed...
Name: Untitled.png
Type: image/png
Size: 23284 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/ac5b93f8/attachment.png>

From gunter.berton at gene.com  Tue Jul 23 16:58:23 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 23 Jul 2013 07:58:23 -0700
Subject: [R] p-values from multiple testing
In-Reply-To: <CACXG3Gh7peFDOztMjm+JduHx8VjqbWCscZzBjL8_Cwua+REGjg@mail.gmail.com>
References: <CACXG3Gh7peFDOztMjm+JduHx8VjqbWCscZzBjL8_Cwua+REGjg@mail.gmail.com>
Message-ID: <CACk-te1BVJViOdt0PgeZ-sjujaC=LFvUdLdTAf81o4N0S0NQbw@mail.gmail.com>

Your question has effectively nothing to do with R, so is off topic
here. Post on a statistics or bioinformatics site like
stats.stackexchange.com .

I'll just mention that this is a ubiquitous issue  in, e.g. gene
testing (p>>n), is controversial, philosophical, and complex. You may
have a good bit of reading to do.

-- Bert

On Tue, Jul 23, 2013 at 7:50 AM, Jie <jimmycloud at gmail.com> wrote:
> Dear All,
>
> I performed thousands of testings and obtained p-values.
> And then I did two-sided uniform KS test of the p-values, the result
> claimed it is uniform.
> So does it mean that my model are wrong? Because I expect more small
> p-values near 0.
> This is a preliminary step before correcting the multiplicity.
> Attached is hist of p-values (does this list allow attachment?). The ks test:
>
> One-sample Kolmogorov-Smirnov test
>
> D = 0.0493, p-value = 1.388e-06
>
> alternative hypothesis: two-sided
>
> Thank you for your attention.
>
> Best wishes,
> Jie
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From alamont082 at gmail.com  Tue Jul 23 16:35:04 2013
From: alamont082 at gmail.com (Andrea Lamont)
Date: Tue, 23 Jul 2013 10:35:04 -0400
Subject: [R] flexible approach to subsetting data
Message-ID: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/9a34e8b8/attachment.pl>

From alice.jones at noc.soton.ac.uk  Tue Jul 23 17:02:41 2013
From: alice.jones at noc.soton.ac.uk (alice.jones)
Date: Tue, 23 Jul 2013 08:02:41 -0700 (PDT)
Subject: [R] Help with using unpenalised te smooth in negative binomial mgcv
	gam
Message-ID: <1374591761606-4672141.post@n4.nabble.com>

Hi, 

I have been trying to fit an un-penalised gam in mgcv (in order to get more
reliable p-values for hypothesis testing), but I am struggling to get the
model to fit sucessfully when I add in a te() interaction.  The model I am
trying to fit is:
        gam(count~ s(x1, bs = "ts", k = 4, fx = TRUE) + 
        s(x2, bs = "ts", k = 4, fx = TRUE) + 
        te(x2, x3, bs = c("ts", "cc"), fx = TRUE) + 
        log(offset(y)), 
        knots = list(x3=c(0,360)), family = negbin(c(1,10)))

The error message I get is:
"Error in sm[[i]]$S[[j]] : attempt to select less than one element"

I can fit this model sucessfully if I don't specify the 'fx=TRUE' argument
(i.e. I can sucesfully fit the penalised model).  It also works when I only
include the two main terms x1 and x2, but do specify fx = TRUE, and it works
fine when I only specify the main term x1 and the te smooth for x2 and x3
and specify fx = TRUE (i.e. without a spearate specification of the main
term, x2, that is also included in the interaction).  But.... when I have
both main terms x1 and x2, as well as an interaction between x2 and x3,
without penalisation, I get the error.

I have played around with other data and with different covariate
specification, but it seems that any time I specify a main term that is also
included in the te interaction, within an un-penalised model, I get this
same error message.

Any help would be much appreciated, as I am trying to compare nested models
(i.e. the full model with the interaction term against the model that just
contains the two main terms).  I understand that the most appropriate way to
do this is to use an un-penalised model for p-value estimation.

Thanks, 

Alice





--
View this message in context: http://r.789695.n4.nabble.com/Help-with-using-unpenalised-te-smooth-in-negative-binomial-mgcv-gam-tp4672141.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Tue Jul 23 16:48:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 23 Jul 2013 07:48:36 -0700 (PDT)
Subject: [R] Function apply
Message-ID: <1374590916.32972.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try:
set.seed(25)
X<- matrix(sample(1:50,3*140,replace=TRUE),nrow=140)
#either
res1<-do.call(rbind,lapply(split(as.data.frame(X),((seq_len(nrow(X))-1)%/%10)+1),function(x) apply(x,2,mean)))
#or
?res2<-t(sapply(split(as.data.frame(X),((seq_len(nrow(X))-1)%/%10)+1),colMeans))
?identical(res1,res2)
#[1] TRUE

#orlibrary(itertools)
it<-ihasNext(isplitRows(X,chunkSize=10))
?while(hasNext(it)){
?print( apply(nextElem(it),2,mean))
?}
#[1] 23.4 29.1 31.5
#[1] 28.2 21.8 17.2
#[1] 14.3 24.3 36.4
#[1] 22.2 25.2 24.2
#[1] 28.5 22.6 27.3
#[1] 19.6 25.6 20.0
#[1] 25.7 16.3 27.9
#[1] 20.0 24.8 26.7
#[1] 26.3 30.0 33.0
#[1] 21.9 24.0 32.3
#[1] 25.6 27.2 34.4
#[1] 13.7 30.2 16.7
#[1] 23.2 27.0 25.3
#[1] 26.4 28.6 25.2

?head(res1)
#??? V1?? V2?? V3
#1 23.4 29.1 31.5
#2 28.2 21.8 17.2
#3 14.3 24.3 36.4
#4 22.2 25.2 24.2
#5 28.5 22.6 27.3
#6 19.6 25.6 20.0

A.K.



Dear, 
I have a matrix with 140 rows. With the following code, I can calculate the mean of each column. 
> X <- matrix 
> apply(X,MARGIN=2,FUN=mean) 
But, how to calculate the mean of each 10 rows? 
Thank you at advance. ?


From soumitrodey1 at gmail.com  Tue Jul 23 16:14:38 2013
From: soumitrodey1 at gmail.com (Soumitro Dey)
Date: Tue, 23 Jul 2013 10:14:38 -0400
Subject: [R] percent correctly predicted (PCP) zeros for hurdle model
Message-ID: <CAJ+M79=aJn=f7Z2W=nAiJ7OXBS-zDObDTcQv3gX9c28WOmLGJA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/8822202b/attachment.pl>

From es at enricoschumann.net  Tue Jul 23 17:27:46 2013
From: es at enricoschumann.net (Enrico Schumann)
Date: Tue, 23 Jul 2013 17:27:46 +0200
Subject: [R] optimize integer function parameters
In-Reply-To: <51EE8D4F.4040009@email.uni-kiel.de> ("Christof =?utf-8?Q?Klu?=
	=?utf-8?Q?=C3=9F=22's?= message
	of "Tue, 23 Jul 2013 16:03:59 +0200")
References: <ksl8ad$buk$1@ger.gmane.org> <87bo5t34m3.fsf@enricoschumann.net>
	<51EE8D4F.4040009@email.uni-kiel.de>
Message-ID: <87wqohz47h.fsf@enricoschumann.net>

On Tue, 23 Jul 2013, Christof Klu? <ckluss at email.uni-kiel.de> writes:

> Am 23-07-2013 13:20, schrieb Enrico Schumann:
>
>> On Tue, 23 Jul 2013, Christof Klu? <ckluss at email.uni-kiel.de> writes:
>>
>>>
>>> I have "observations" obs <- (11455, 11536, 11582, 11825, 11900,  ...)
>>>
>>> and a simulation function f(A,B,C,D,E,F), so sim <- f(A,B,C,D,E,F)
>>>
>>> e.g. sim = c(11464, 11554, 11603, 11831, 11907, ...)
>>>
>>> now I would like to fit A,B,C,D,E,F such that "obs" and f(A,B,C,D,E,F)
>>> match as well as possible. A,..,F should be integers and have bounds.
>>>
>>> How would you solve this problem without bruteforce in an acceptable time?
>>>
>>
>>
>> That depends on what your "simulation function" looks like.  Could you
>> post a (small) self-contained example?
>>
>>
>
> the integer values in the vectors sim and obs are dates
>
> when I set sim <- f(TS0,TS1,TS2,TB0,TB1,TB2) my A,..,F below
> then TS0 and TB0 are depend (and so on)
>
>
> the main thing in f(...) is something like
>
>  for (i in c(1:length(temperature))) {
>       Temp <- temperature[i]
>       if (DS < 0) {
>         DS <- DS + max(Temp-TB0,0) / TS0
>       } else if (DS < 1) {
>         ... date0 <- i
>         DS <- DS + max(Temp-TB1,0) / TS1
>       } else if (DS < 2) {
>         ... date1 <- i
>         DS <- DS + max(Temp-TB2,0) / TS2
>       } else {
>         ... date2 <- i
>         break
>       }
>     }
>
>
> this produced a vector sim = c(date0,date1,date2,...)
>
>
> now I would like to minimize RMSE(sim,obs) or something like that
>
> thx
> Christof
>
>
>
> for brute force I would do something like
>
> obs <- ...
> act <- 1000
>
>   for (TS0 in seq(50,100,10))
>     for (TS1 in seq(750,850,10))
>       for (TS2 in seq(400,600,10))
>         for (TB0 in c(5:7))
>           for (TB1 in c(5:7))
>             for (TB2 in c(4:9)) {
>               sim <- foosim(dat,TS0,TS1,TS2,TB0,TB1,TB2)
>               rmse <- sqrt(mean((sim - obs)^2, na.rm = TRUE))
>
>               if (rmse < act) {
>                 print(paste(rmse,TS0,TS1,TS2,TB0,TB1,TB2))
>                 act <- rmse
>               }
>             }
>

Sorry, but that is not what I meant by "a (small) self-contained
example". 

In any case, if brute force is feasible -- ie, your function can be
evaluated quickly enough and there are no further parameters -- then why
not do brute force?  (In the NMOF package there is a function
'gridSearch' that allows you to distribute the function evaluations.
Disclosure: I am the package author.)

If that does not work, you might try a Local Search or one of its
variants (see for instance 'LSopt' in the NMOF package).  But it is
difficult to say anything specific without knowing your actual function.

Regards,
        Enrico

-- 
Enrico Schumann
Lucerne, Switzerland
http://enricoschumann.net


From dwinsemius at comcast.net  Tue Jul 23 18:07:47 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Jul 2013 09:07:47 -0700
Subject: [R] downloading web content
In-Reply-To: <CAFf2dDEiEJ_cD=JD4P=DX0=L=dxxC3N8GVz1GjA187H-Ad8yUg@mail.gmail.com>
References: <CAFf2dDEiEJ_cD=JD4P=DX0=L=dxxC3N8GVz1GjA187H-Ad8yUg@mail.gmail.com>
Message-ID: <BBAF7663-A961-4225-BC41-14C39C14797D@comcast.net>


On Jul 23, 2013, at 2:59 AM, Daisy Englert Duursma wrote:

> Hello,
> I am trying to use R to download a bunch of .csv  files such as:

It's are not a csv file; instead it's a zip file. Why not use the `download.file` function. This downloads it to my working directory:

> download.file("http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia", "data.zip")
trying URL 'http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia'
Content type 'application/zip' length unknown
opened URL
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
.......... .......... .......... .......... ..........
....
downloaded 204 Kb

-- 
David.


> 
> http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia
> 
> I have tried the following and neither work:
> 
> a<- getURL("
> http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia")
> 
> Error in curlPerform(curl = curl, .opts = opts, .encoding = .encoding) :
>  embedded nul in string:
> and
> 
> a<-httpPOST("
> http://biocache.ala.org.au/ws/occurrences/download?q=Banksia+ericifolia")
> 
> Error: Internal Server Error
> 
> 
> Any help would be appreciated.
> 
> Daisy
> -- 
> Daisy Englert Duursma
> Department of Biological Sciences
> Room E8C156
> Macquarie University, North Ryde, NSW 2109
> Australia
> 
> 	[[alternative HTML version deleted]]

And do learn to post in plain-text.

-- 

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Jul 23 18:15:32 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Jul 2013 09:15:32 -0700
Subject: [R] Check the class of an object
In-Reply-To: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>
References: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>
Message-ID: <21F05392-CB77-49C0-A35E-3989F8E99BFA@comcast.net>


On Jul 23, 2013, at 5:36 AM, Simon Zehnder wrote:

> Dear R-Users and R-Devels,
> 
> I have large project based on S4 classes. While writing my unit tests I found out, that 'is' cannot test for a specific class, as also inherited classes can be treated as their super classes. I need to do checks for specific classes. What I do right now is sth. like
> 
> if (class(myClass) == "firstClass") {

I would think that you would need to use `%in%` instead. 

 if( "firstClass" %in% class(myObject) ){

 Objects can have more than one class, so testing with "==" would fail in those instances.


> 
> } else if (class(myClass) == "secondClass") {
> 
> }
> 
> Is this the usual way how classes are checked in R?

Well, `inherits` IS the usual way.

> I was expecting some specific method (and 'inherits' or 'extends' is not what I look for)...
> 
> 
> Best
> 
> Simon
> 
> 	[[alternative HTML version deleted]]

Plain-text format is the recommended format for Rhelp

-- 
David Winsemius
Alameda, CA, USA


From szehnder at uni-bonn.de  Tue Jul 23 18:59:15 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 23 Jul 2013 18:59:15 +0200
Subject: [R] Check the class of an object
In-Reply-To: <21F05392-CB77-49C0-A35E-3989F8E99BFA@comcast.net>
References: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>
	<21F05392-CB77-49C0-A35E-3989F8E99BFA@comcast.net>
Message-ID: <3322A432-5855-4A70-ADC9-20AA39FB5B66@uni-bonn.de>

Hi David,

thanks for the reply. You are right. Using the %in% is more stable and I gonna change my code.

When testing for a specific class using 'is' one has to start at the lowest heir and walk up the inheritance structure. Starting at the checks at the root will always give TRUE. Having a structure which is quite complicated let me move to the check I suggested in my first mail. 

Best

Simon

On Jul 23, 2013, at 6:15 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Jul 23, 2013, at 5:36 AM, Simon Zehnder wrote:
> 
>> Dear R-Users and R-Devels,
>> 
>> I have large project based on S4 classes. While writing my unit tests I found out, that 'is' cannot test for a specific class, as also inherited classes can be treated as their super classes. I need to do checks for specific classes. What I do right now is sth. like
>> 
>> if (class(myClass) == "firstClass") {
> 
> I would think that you would need to use `%in%` instead. 
> 
> if( "firstClass" %in% class(myObject) ){
> 
> Objects can have more than one class, so testing with "==" would fail in those instances.
> 
> 
>> 
>> } else if (class(myClass) == "secondClass") {
>> 
>> }
>> 
>> Is this the usual way how classes are checked in R?
> 
> Well, `inherits` IS the usual way.
> 
>> I was expecting some specific method (and 'inherits' or 'extends' is not what I look for)...
>> 
>> 
>> Best
>> 
>> Simon
>> 
>> 	[[alternative HTML version deleted]]
> 
> Plain-text format is the recommended format for Rhelp
> 
> -- 
> David Winsemius
> Alameda, CA, USA
> 


From jvadams at usgs.gov  Tue Jul 23 19:01:39 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Tue, 23 Jul 2013 12:01:39 -0500
Subject: [R] flexible approach to subsetting data
In-Reply-To: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
Message-ID: <CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/3320f4be/attachment.pl>

From mtmorgan at fhcrc.org  Tue Jul 23 19:11:36 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Tue, 23 Jul 2013 10:11:36 -0700
Subject: [R] Check the class of an object
In-Reply-To: <3322A432-5855-4A70-ADC9-20AA39FB5B66@uni-bonn.de>
References: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>
	<21F05392-CB77-49C0-A35E-3989F8E99BFA@comcast.net>
	<3322A432-5855-4A70-ADC9-20AA39FB5B66@uni-bonn.de>
Message-ID: <51EEB948.70506@fhcrc.org>

On 07/23/2013 09:59 AM, Simon Zehnder wrote:
> Hi David,
>
> thanks for the reply. You are right. Using the %in% is more stable and I gonna change my code.

you said you were you were using S4 classes. S4 classes do not report vectors of 
length != 1, from ?class

      For objects which have a formal class, its name is returned by 'class'
      as a character vector of length one

so a first unit test could be

   stopifnot(length(class(myObject)) != 1L)


>
> When testing for a specific class using 'is' one has to start at the lowest heir and walk up the inheritance structure. Starting at the checks at the root will always give TRUE. Having a structure which is quite complicated let me move to the check I suggested in my first mail.
>
> Best
>
> Simon
>
> On Jul 23, 2013, at 6:15 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>>
>> On Jul 23, 2013, at 5:36 AM, Simon Zehnder wrote:
>>
>>> Dear R-Users and R-Devels,
>>>
>>> I have large project based on S4 classes. While writing my unit tests I found out, that 'is' cannot test for a specific class, as also inherited classes can be treated as their super classes. I need to do checks for specific classes. What I do right now is sth. like
>>>
>>> if (class(myClass) == "firstClass") {
>>
>> I would think that you would need to use `%in%` instead.
>>
>> if( "firstClass" %in% class(myObject) ){
>>
>> Objects can have more than one class, so testing with "==" would fail in those instances.
>>
>>
>>>
>>> } else if (class(myClass) == "secondClass") {
>>>
>>> }
>>>
>>> Is this the usual way how classes are checked in R?
>>
>> Well, `inherits` IS the usual way.
>>
>>> I was expecting some specific method (and 'inherits' or 'extends' is not what I look for)...
>>>
>>>
>>> Best
>>>
>>> Simon
>>>
>>> 	[[alternative HTML version deleted]]
>>
>> Plain-text format is the recommended format for Rhelp
>>
>> --
>> David Winsemius
>> Alameda, CA, USA
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From hpages at fhcrc.org  Tue Jul 23 19:20:12 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 23 Jul 2013 10:20:12 -0700
Subject: [R] Check the class of an object
In-Reply-To: <3322A432-5855-4A70-ADC9-20AA39FB5B66@uni-bonn.de>
References: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>
	<21F05392-CB77-49C0-A35E-3989F8E99BFA@comcast.net>
	<3322A432-5855-4A70-ADC9-20AA39FB5B66@uni-bonn.de>
Message-ID: <51EEBB4C.8080803@fhcrc.org>

Hi,

On 07/23/2013 09:59 AM, Simon Zehnder wrote:
> Hi David,
>
> thanks for the reply. You are right. Using the %in% is more stable and I gonna change my code.

Unlike with S3 objects, class() on an S4 object can only return 1 class.

Also note that, on an S3 object, doing

   "firstClass" %in% class(myObject)

is equivalent to doing inherits(myObject, "firstClass"), which is
what you said you wanted to avoid. The most specific class should be
the first so if that's what you wanted to check, you could do

   class(myObject)[1] == "firstClass"

But that precaution is not needed if 'myObject' is guaranteed to be
an S4 object (although when writing a unit test, one should probably
discard any guarantee of that sort).

Cheers,
H.


>
> When testing for a specific class using 'is' one has to start at the lowest heir and walk up the inheritance structure. Starting at the checks at the root will always give TRUE. Having a structure which is quite complicated let me move to the check I suggested in my first mail.
>
> Best
>
> Simon
>
> On Jul 23, 2013, at 6:15 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>
>>
>> On Jul 23, 2013, at 5:36 AM, Simon Zehnder wrote:
>>
>>> Dear R-Users and R-Devels,
>>>
>>> I have large project based on S4 classes. While writing my unit tests I found out, that 'is' cannot test for a specific class, as also inherited classes can be treated as their super classes. I need to do checks for specific classes. What I do right now is sth. like
>>>
>>> if (class(myClass) == "firstClass") {
>>
>> I would think that you would need to use `%in%` instead.
>>
>> if( "firstClass" %in% class(myObject) ){
>>
>> Objects can have more than one class, so testing with "==" would fail in those instances.
>>
>>
>>>
>>> } else if (class(myClass) == "secondClass") {
>>>
>>> }
>>>
>>> Is this the usual way how classes are checked in R?
>>
>> Well, `inherits` IS the usual way.
>>
>>> I was expecting some specific method (and 'inherits' or 'extends' is not what I look for)...
>>>
>>>
>>> Best
>>>
>>> Simon
>>>
>>> 	[[alternative HTML version deleted]]
>>
>> Plain-text format is the recommended format for Rhelp
>>
>> --
>> David Winsemius
>> Alameda, CA, USA
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From nprause at mednet.ucla.edu  Tue Jul 23 19:41:03 2013
From: nprause at mednet.ucla.edu (Nicole Prause)
Date: Tue, 23 Jul 2013 10:41:03 -0700
Subject: [R] (no subject)
Message-ID: <CAHskT4rGPTym92FBd+bcdHUVnMnpM-Yq-Z-WZzOEDZ+ExfQW_w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/04f6a691/attachment.pl>

From dwinsemius at comcast.net  Tue Jul 23 19:49:53 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Jul 2013 10:49:53 -0700
Subject: [R] flexible approach to subsetting data
In-Reply-To: <CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>
Message-ID: <F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>


On Jul 23, 2013, at 10:01 AM, Adams, Jean wrote:

> Check out the reshape() function of the reshape package.  Here's one of the
> examples from ?reshape.
> 
> Jean
> 
> 
> library(reshape)   # No,  at least not for the reshape-function

The reshape function is from the 'base' package. The 'reshape' and 'reshape2' packages were written (at least in part) because the 'reshape'-function was so difficult to understand.

If you do choose to use the reshape2 package, which is well-respected and often extremely helpful, the function you will want to start with is 'melt'.


> long <- reshape(wide, direction="long")

I don't think this example will be particularly helpful since the initial direction is "long" (from "wide") and more input would be needed.


> wide
> long
> 
> 
> 
> On Tue, Jul 23, 2013 at 9:35 AM, Andrea Lamont <alamont082 at gmail.com> wrote:
> 
>> Hello:
>> 
>> I am running a simulation study and am stuck with a subsetting problem.
>> 
>> Here is the basic issue:
>> I generated data and am running a simulation that uses multiple imputation.
>> For each generated dataset, I used multiple imputation.  The resultant
>> dataset is in wide for where each imputation is recorded as a separate
>> column (though the different simulations are stacked).  Here is an example
>> of what it looks like:
>> 
>> sim   X1   X2   X3   sim.1   X1.1    X1.1    X3.1

>> 1         #    #     #        #           #          #         #
>> 1         #    #     #        #           #          #         #
>> 1         #    #     #        #           #          #         #
>> 2         #    #     #        #           #          #         #
>> 2         #    #     #        #           #          #         #
>> 2         #    #     #        #           #          #         #
>> 
>> sim refers to the simulated/generated dataset. X1-X3 are the values for the
>> first imputed dataset, X1.1-X3.1 are the values for the second imputed
>> dataset.
>> 
>> The problem is that I want the data to be in long format, like this:
>> 
>> sim m X1 X2 X3
>> 1  1   #   #    #
>> 1  2   #   #    #
>> 2  1   #   #    #
>> 2  2   #   #    #
>> 
>> where m is the imputation number.
>> This will allow me to do cleaner calculations (e.g. X3-X1).
>> 
>> I know I can subset the data manually - e.g. [,1:10] and save this to
>> separate datasets then  rbind; however, I'm looking for a more flexible
>> approach to do this.  This manual approach would be quite tedious as number
>> of imputations (and therefore number of columns) increased (with only 10
>> imputations, there are roughly 810 columns). Also,I would like to
>> avoid having to recode each time I change the number of imputations.
>> 
>> THe same is true for the reshape function, which would require naming
>> a huge number of columns and edits each time 'm' changes.

If the columns are named regularly, then 'reshape' will attempt to split properly without an explicit naming. Details and a better description of the problem might allow more specific answers to emerge. The fact that the first instances have no numeric indicators may be a problem for the algorithm. 

Why not post dput(head( dfrm[ ,1:12]))

-- 
David.

>> 
>> 
>> Is there a flexible way to approach this? I'm inclined to use a for loop,
>> but know that 1) this is generally inefficient and 2) am having trouble
>> with
>> the coding regardless.
>> 
>> Any suggestions are appreciated.
>> 
>> Thanks,
>> Andrea
>> 
>> 
>> --
>> Andrea Lamont, MA

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Tue Jul 23 20:12:21 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Jul 2013 11:12:21 -0700
Subject: [R] flexible approach to subsetting data
In-Reply-To: <F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>
	<F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>
Message-ID: <F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>


On Jul 23, 2013, at 10:49 AM, David Winsemius wrote:

> 
> On Jul 23, 2013, at 10:01 AM, Adams, Jean wrote:
> 
>> Check out the reshape() function of the reshape package.  Here's one of the
>> examples from ?reshape.
>> 
>> Jean
>> 
>> 
>> library(reshape)   # No,  at least not for the reshape-function
> 
> The reshape function is from the 'base' package. The 'reshape' and 'reshape2' packages were written (at least in part) because the 'reshape'-function was so difficult to understand.
> 
> If you do choose to use the reshape2 package, which is well-respected and often extremely helpful, the function you will want to start with is 'melt'.
> 
> 
>> long <- reshape(wide, direction="long")
> 
> I don't think this example will be particularly helpful since the initial direction is "long" (from "wide") and more input would be needed.

Here's a dataset to experiment with

df5 <- data.frame(dose.0 = c(40,50,60,50),resp.0=c(40,50,60,50), 
 dose.1 = c(1,2,1,2), resp.1=c(1,2,1,2)+3, 
 dose.2 = c(2,1,2,1), resp.2=c(1,2,1,2)+3,
 dose.3 = c(3,3,3,3), resp.3=c(1,2,1,2)+3 )

Notice that you would need add the ".0" to the column names

reshape(df5,  direction="long", 
              v.names=c("dose", "resp"), 
               varying=list(dose=c(1,3,5,7), resp=c(2,4,6,8) )
        )  # succeeds



So perhaps could use similar call (after append the ".0"'s) with:

  varying=list(sim=seq(1,810,by=4),
               X1= seq(2,810,by=4),
               X2= seq(3,810,by=4),
               X3= seq(4,810,by=4)
               )
               
> 
> 
>> wide
>> long
>> 
>> 
>> 
>> On Tue, Jul 23, 2013 at 9:35 AM, Andrea Lamont <alamont082 at gmail.com> wrote:
>> 
>>> Hello:
>>> 
>>> I am running a simulation study and am stuck with a subsetting problem.
>>> 
>>> Here is the basic issue:
>>> I generated data and am running a simulation that uses multiple imputation.
>>> For each generated dataset, I used multiple imputation.  The resultant
>>> dataset is in wide for where each imputation is recorded as a separate
>>> column (though the different simulations are stacked).  Here is an example
>>> of what it looks like:
>>> 
>>> sim   X1   X2   X3   sim.1   X1.1    X1.1    X3.1
> 
>>> 1         #    #     #        #           #          #         #
>>> 1         #    #     #        #           #          #         #
>>> 1         #    #     #        #           #          #         #
>>> 2         #    #     #        #           #          #         #
>>> 2         #    #     #        #           #          #         #
>>> 2         #    #     #        #           #          #         #
>>> 
>>> sim refers to the simulated/generated dataset. X1-X3 are the values for the
>>> first imputed dataset, X1.1-X3.1 are the values for the second imputed
>>> dataset.
>>> 
>>> The problem is that I want the data to be in long format, like this:
>>> 
>>> sim m X1 X2 X3
>>> 1  1   #   #    #
>>> 1  2   #   #    #
>>> 2  1   #   #    #
>>> 2  2   #   #    #
>>> 
>>> where m is the imputation number.
>>> This will allow me to do cleaner calculations (e.g. X3-X1).
>>> 
>>> I know I can subset the data manually - e.g. [,1:10] and save this to
>>> separate datasets then  rbind; however, I'm looking for a more flexible
>>> approach to do this.  This manual approach would be quite tedious as number
>>> of imputations (and therefore number of columns) increased (with only 10
>>> imputations, there are roughly 810 columns). Also,I would like to
>>> avoid having to recode each time I change the number of imputations.
>>> 
>>> THe same is true for the reshape function, which would require naming
>>> a huge number of columns and edits each time 'm' changes.
> 
> If the columns are named regularly, then 'reshape' will attempt to split properly without an explicit naming. Details and a better description of the problem might allow more specific answers to emerge. The fact that the first instances have no numeric indicators may be a problem for the algorithm. 
> 
> Why not post dput(head( dfrm[ ,1:12]))
> 
> -- 
> David.
> 
>>> 
>>> 
>>> Is there a flexible way to approach this? I'm inclined to use a for loop,
>>> but know that 1) this is generally inefficient and 2) am having trouble
>>> with
>>> the coding regardless.
>>> 
>>> Any suggestions are appreciated.
>>> 
>>> Thanks,
>>> Andrea
>>> 


David Winsemius
Alameda, CA, USA


From szehnder at uni-bonn.de  Tue Jul 23 20:51:12 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 23 Jul 2013 20:51:12 +0200
Subject: [R] Check the class of an object
In-Reply-To: <51EEB948.70506@fhcrc.org>
References: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>
	<21F05392-CB77-49C0-A35E-3989F8E99BFA@comcast.net>
	<3322A432-5855-4A70-ADC9-20AA39FB5B66@uni-bonn.de>
	<51EEB948.70506@fhcrc.org>
Message-ID: <651AEAA8-66D1-482B-AB07-C60B1848BCC1@uni-bonn.de>

Hi Martin,

I didn't know that. But that is even more comfortable for checking. Thanks for the quick update!

Best


Simon

P.S. And thanks for the online documents about S4 - I could already learn a lot!


On Jul 23, 2013, at 7:11 PM, Martin Morgan <mtmorgan at fhcrc.org> wrote:

> On 07/23/2013 09:59 AM, Simon Zehnder wrote:
>> Hi David,
>> 
>> thanks for the reply. You are right. Using the %in% is more stable and I gonna change my code.
> 
> you said you were you were using S4 classes. S4 classes do not report vectors of length != 1, from ?class
> 
>     For objects which have a formal class, its name is returned by 'class'
>     as a character vector of length one
> 
> so a first unit test could be
> 
>  stopifnot(length(class(myObject)) != 1L)
> 
> 
>> 
>> When testing for a specific class using 'is' one has to start at the lowest heir and walk up the inheritance structure. Starting at the checks at the root will always give TRUE. Having a structure which is quite complicated let me move to the check I suggested in my first mail.
>> 
>> Best
>> 
>> Simon
>> 
>> On Jul 23, 2013, at 6:15 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> 
>>> On Jul 23, 2013, at 5:36 AM, Simon Zehnder wrote:
>>> 
>>>> Dear R-Users and R-Devels,
>>>> 
>>>> I have large project based on S4 classes. While writing my unit tests I found out, that 'is' cannot test for a specific class, as also inherited classes can be treated as their super classes. I need to do checks for specific classes. What I do right now is sth. like
>>>> 
>>>> if (class(myClass) == "firstClass") {
>>> 
>>> I would think that you would need to use `%in%` instead.
>>> 
>>> if( "firstClass" %in% class(myObject) ){
>>> 
>>> Objects can have more than one class, so testing with "==" would fail in those instances.
>>> 
>>> 
>>>> 
>>>> } else if (class(myClass) == "secondClass") {
>>>> 
>>>> }
>>>> 
>>>> Is this the usual way how classes are checked in R?
>>> 
>>> Well, `inherits` IS the usual way.
>>> 
>>>> I was expecting some specific method (and 'inherits' or 'extends' is not what I look for)...
>>>> 
>>>> 
>>>> Best
>>>> 
>>>> Simon
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>> 
>>> Plain-text format is the recommended format for Rhelp
>>> 
>>> --
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> 
> -- 
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
> 
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793


From szehnder at uni-bonn.de  Tue Jul 23 20:52:24 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Tue, 23 Jul 2013 20:52:24 +0200
Subject: [R] Check the class of an object
In-Reply-To: <51EEBB4C.8080803@fhcrc.org>
References: <F9802231-DAA3-4339-9E25-FCB0A3FEB348@uni-bonn.de>
	<21F05392-CB77-49C0-A35E-3989F8E99BFA@comcast.net>
	<3322A432-5855-4A70-ADC9-20AA39FB5B66@uni-bonn.de>
	<51EEBB4C.8080803@fhcrc.org>
Message-ID: <06ED4444-E9B0-4311-B117-F9604E038D7A@uni-bonn.de>

Hi Herv?,

thank you very much for your reply! This makes the different treatment of S3 and S4 objects by 'class' clear.

Best

Simon


On Jul 23, 2013, at 7:20 PM, Herv? Pag?s <hpages at fhcrc.org> wrote:

> Hi,
> 
> On 07/23/2013 09:59 AM, Simon Zehnder wrote:
>> Hi David,
>> 
>> thanks for the reply. You are right. Using the %in% is more stable and I gonna change my code.
> 
> Unlike with S3 objects, class() on an S4 object can only return 1 class.
> 
> Also note that, on an S3 object, doing
> 
>  "firstClass" %in% class(myObject)
> 
> is equivalent to doing inherits(myObject, "firstClass"), which is
> what you said you wanted to avoid. The most specific class should be
> the first so if that's what you wanted to check, you could do
> 
>  class(myObject)[1] == "firstClass"
> 
> But that precaution is not needed if 'myObject' is guaranteed to be
> an S4 object (although when writing a unit test, one should probably
> discard any guarantee of that sort).
> 
> Cheers,
> H.
> 
> 
>> 
>> When testing for a specific class using 'is' one has to start at the lowest heir and walk up the inheritance structure. Starting at the checks at the root will always give TRUE. Having a structure which is quite complicated let me move to the check I suggested in my first mail.
>> 
>> Best
>> 
>> Simon
>> 
>> On Jul 23, 2013, at 6:15 PM, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>>> 
>>> On Jul 23, 2013, at 5:36 AM, Simon Zehnder wrote:
>>> 
>>>> Dear R-Users and R-Devels,
>>>> 
>>>> I have large project based on S4 classes. While writing my unit tests I found out, that 'is' cannot test for a specific class, as also inherited classes can be treated as their super classes. I need to do checks for specific classes. What I do right now is sth. like
>>>> 
>>>> if (class(myClass) == "firstClass") {
>>> 
>>> I would think that you would need to use `%in%` instead.
>>> 
>>> if( "firstClass" %in% class(myObject) ){
>>> 
>>> Objects can have more than one class, so testing with "==" would fail in those instances.
>>> 
>>> 
>>>> 
>>>> } else if (class(myClass) == "secondClass") {
>>>> 
>>>> }
>>>> 
>>>> Is this the usual way how classes are checked in R?
>>> 
>>> Well, `inherits` IS the usual way.
>>> 
>>>> I was expecting some specific method (and 'inherits' or 'extends' is not what I look for)...
>>>> 
>>>> 
>>>> Best
>>>> 
>>>> Simon
>>>> 
>>>> 	[[alternative HTML version deleted]]
>>> 
>>> Plain-text format is the recommended format for Rhelp
>>> 
>>> --
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319


From michel.kohl at aggiemail.usu.edu  Tue Jul 23 19:15:06 2013
From: michel.kohl at aggiemail.usu.edu (Michel Kohl)
Date: Tue, 23 Jul 2013 11:15:06 -0600
Subject: [R] Coxme Package Error Message Help
Message-ID: <CANExmd_fdUCvRLXwzrCOv2TqAsbFmRvwGoYrBCRnVZ82QFPdOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/dcfee606/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 23 18:00:36 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 23 Jul 2013 09:00:36 -0700 (PDT)
Subject: [R] flexible approach to subsetting data
In-Reply-To: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
Message-ID: <1374595236.48572.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
It is better to provide a reproducible example using ?dput()
df1<- read.table(text="
sim?? X1?? X2?? X3?? sim.1?? X1.1??? X2.1??? X3.1
1???? 5??? 4???? 5??????? 1?????????? 4????????? 3??????? 7
1???? 4??? 3???? 2??????? 1?????????? 7????????? 4???????? 1
1???? 3??? 9???? 4??????? 1?????????? 5????????? 8???????? 4
2???? 6??? 4???? 8??????? 2?????????? 3????????? 9???????? 5
2???? 7??? 8???? 4??????? 2?????????? 5????????? 4???????? 8
2???? 9??? 6???? 7??????? 2?????????? 9????????? 5???????? 6
",sep="",header=TRUE)
res<-reshape(df1,sep=".",varying=list(c("sim","sim.1"),c("X1","X1.1"),c("X2","X2.1"),c("X3","X3.1")),direction="long",timevar="m")[,-5]
res
??? m sim X1 X2 id
1.1 1?? 1? 5? 4? 1
2.1 1?? 1? 4? 3? 2
3.1 1?? 1? 3? 9? 3
4.1 1?? 2? 6? 4? 4
5.1 1?? 2? 7? 8? 5
6.1 1?? 2? 9? 6? 6
1.2 2?? 1? 4? 3? 1
2.2 2?? 1? 7? 4? 2
3.2 2?? 1? 5? 8? 3
4.2 2?? 2? 3? 9? 4
5.2 2?? 2? 5? 4? 5
6.2 2?? 2? 9? 5? 6
?
A.K.




----- Original Message -----
From: Andrea Lamont <alamont082 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, July 23, 2013 10:35 AM
Subject: [R] flexible approach to subsetting data

Hello:

I am running a simulation study and am stuck with a subsetting problem.

Here is the basic issue:
I generated data and am running a simulation that uses multiple imputation.
For each generated dataset, I used multiple imputation.? The resultant
dataset is in wide for where each imputation is recorded as a separate
column (though the different simulations are stacked).? Here is an example
of what it looks like:

sim?  X1?  X2?  X3?  sim.1?  X1.1? ? X1.1? ? X3.1
1? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #? ? ? ?  #
1? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #? ? ? ?  #
1? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #? ? ? ?  #
2? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #? ? ? ?  #
2? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #? ? ? ?  #
2? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #? ? ? ?  #

sim refers to the simulated/generated dataset. X1-X3 are the values for the
first imputed dataset, X1.1-X3.1 are the values for the second imputed
dataset.

The problem is that I want the data to be in long format, like this:

sim m X1 X2 X3
1? 1?  #?  #? ? #
1? 2?  #?  #? ? #
2? 1?  #?  #? ? #
2? 2?  #?  #? ? #

where m is the imputation number.
This will allow me to do cleaner calculations (e.g. X3-X1).

I know I can subset the data manually - e.g. [,1:10] and save this to
separate datasets then? rbind; however, I'm looking for a more flexible
approach to do this.? This manual approach would be quite tedious as number
of imputations (and therefore number of columns) increased (with only 10
imputations, there are roughly 810 columns). Also,I would like to
avoid having to recode each time I change the number of imputations.

THe same is true for the reshape function, which would require naming
a huge number of columns and edits each time 'm' changes.


Is there a flexible way to approach this? I'm inclined to use a for loop,
but know that 1) this is generally inefficient and 2) am having trouble with
the coding regardless.

Any suggestions are appreciated.

Thanks,
Andrea


-- 
Andrea Lamont, MA
Clinical-Community Psychology
University of South Carolina
Barnwell College
Columbia, SC 29208

Please consider the environment before printing this email.

CONFIDENTIAL: This transmission is intended for the use of the
individual(s) or entity to which it is addressed, and may contain
information that is privileged, confidential, and exempt from disclosure
under applicable law. Should the reader of this message not be the intended
recipient(s), you are hereby notified that any dissemination, distribution,
or copying of this communication is strictly prohibited.? If you are not
the intended recipient, please contact the sender by reply email and
destroy/delete all copies of the original message.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jul 23 18:04:45 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 23 Jul 2013 09:04:45 -0700 (PDT)
Subject: [R] flexible approach to subsetting data
In-Reply-To: <1374595236.48572.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
	<1374595236.48572.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1374595485.31864.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Sorry, a mistake
It should be:
res<-reshape(df1,sep=".",varying=list(c("sim","sim.1"),c("X1","X1.1"),c("X2","X2.1"),c("X3","X3.1")),direction="long",timevar="m")[,-6]
row.names(res)<- 1:nrow(res)
head(res,2)
#? m sim X1 X2 X3
#1 1?? 1? 5? 4? 5
#2 1?? 1? 4? 3? 2
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Andrea Lamont <alamont082 at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, July 23, 2013 12:00 PM
Subject: Re: [R] flexible approach to subsetting data

Hi,
It is better to provide a reproducible example using ?dput()
df1<- read.table(text="
sim?? X1?? X2?? X3?? sim.1?? X1.1??? X2.1??? X3.1
1???? 5??? 4???? 5??????? 1?????????? 4????????? 3??????? 7
1???? 4??? 3???? 2??????? 1?????????? 7????????? 4???????? 1
1???? 3??? 9???? 4??????? 1?????????? 5????????? 8???????? 4
2???? 6??? 4???? 8??????? 2?????????? 3????????? 9???????? 5
2???? 7??? 8???? 4??????? 2?????????? 5????????? 4???????? 8
2???? 9??? 6???? 7??????? 2?????????? 9????????? 5???????? 6
",sep="",header=TRUE)
res<-reshape(df1,sep=".",varying=list(c("sim","sim.1"),c("X1","X1.1"),c("X2","X2.1"),c("X3","X3.1")),direction="long",timevar="m")[,-5]
res
??? m sim X1 X2 id
1.1 1?? 1? 5? 4? 1
2.1 1?? 1? 4? 3? 2
3.1 1?? 1? 3? 9? 3
4.1 1?? 2? 6? 4? 4
5.1 1?? 2? 7? 8? 5
6.1 1?? 2? 9? 6? 6
1.2 2?? 1? 4? 3? 1
2.2 2?? 1? 7? 4? 2
3.2 2?? 1? 5? 8? 3
4.2 2?? 2? 3? 9? 4
5.2 2?? 2? 5? 4? 5
6.2 2?? 2? 9? 5? 6
?
A.K.




----- Original Message -----
From: Andrea Lamont <alamont082 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, July 23, 2013 10:35 AM
Subject: [R] flexible approach to subsetting data

Hello:

I am running a simulation study and am stuck with a subsetting problem.

Here is the basic issue:
I generated data and am running a simulation that uses multiple imputation.
For each generated dataset, I used multiple imputation.? The resultant
dataset is in wide for where each imputation is recorded as a separate
column (though the different simulations are stacked).? Here is an example
of what it looks like:

sim?? X1?? X2?? X3?? sim.1?? X1.1? ? X1.1? ? X3.1
1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #

sim refers to the simulated/generated dataset. X1-X3 are the values for the
first imputed dataset, X1.1-X3.1 are the values for the second imputed
dataset.

The problem is that I want the data to be in long format, like this:

sim m X1 X2 X3
1? 1?? #?? #? ? #
1? 2?? #?? #? ? #
2? 1?? #?? #? ? #
2? 2?? #?? #? ? #

where m is the imputation number.
This will allow me to do cleaner calculations (e.g. X3-X1).

I know I can subset the data manually - e.g. [,1:10] and save this to
separate datasets then? rbind; however, I'm looking for a more flexible
approach to do this.? This manual approach would be quite tedious as number
of imputations (and therefore number of columns) increased (with only 10
imputations, there are roughly 810 columns). Also,I would like to
avoid having to recode each time I change the number of imputations.

THe same is true for the reshape function, which would require naming
a huge number of columns and edits each time 'm' changes.


Is there a flexible way to approach this? I'm inclined to use a for loop,
but know that 1) this is generally inefficient and 2) am having trouble with
the coding regardless.

Any suggestions are appreciated.

Thanks,
Andrea


-- 
Andrea Lamont, MA
Clinical-Community Psychology
University of South Carolina
Barnwell College
Columbia, SC 29208

Please consider the environment before printing this email.

CONFIDENTIAL: This transmission is intended for the use of the
individual(s) or entity to which it is addressed, and may contain
information that is privileged, confidential, and exempt from disclosure
under applicable law. Should the reader of this message not be the intended
recipient(s), you are hereby notified that any dissemination, distribution,
or copying of this communication is strictly prohibited.? If you are not
the intended recipient, please contact the sender by reply email and
destroy/delete all copies of the original message.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jul 23 18:47:51 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 23 Jul 2013 09:47:51 -0700 (PDT)
Subject: [R] flexible approach to subsetting data
In-Reply-To: <1374595485.31864.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
	<1374595236.48572.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1374595485.31864.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1374598071.52361.YahooMailNeo@web142604.mail.bf1.yahoo.com>

If you have more columns:
?names(df1)<-paste0(gsub("\\..*","",names(df1)),"_",rep(1:2,each=4)) #change `rep` accordingly
reshape(df1,direction="long",varying=1:ncol(df1),sep="_",timevar="m")[,-6]
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Andrea Lamont <alamont082 at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, July 23, 2013 12:04 PM
Subject: Re: [R] flexible approach to subsetting data

Sorry, a mistake
It should be:
res<-reshape(df1,sep=".",varying=list(c("sim","sim.1"),c("X1","X1.1"),c("X2","X2.1"),c("X3","X3.1")),direction="long",timevar="m")[,-6]
row.names(res)<- 1:nrow(res)
head(res,2)
#? m sim X1 X2 X3
#1 1?? 1? 5? 4? 5
#2 1?? 1? 4? 3? 2
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Andrea Lamont <alamont082 at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, July 23, 2013 12:00 PM
Subject: Re: [R] flexible approach to subsetting data

Hi,
It is better to provide a reproducible example using ?dput()
df1<- read.table(text="
sim?? X1?? X2?? X3?? sim.1?? X1.1??? X2.1??? X3.1
1???? 5??? 4???? 5??????? 1?????????? 4????????? 3??????? 7
1???? 4??? 3???? 2??????? 1?????????? 7????????? 4???????? 1
1???? 3??? 9???? 4??????? 1?????????? 5????????? 8???????? 4
2???? 6??? 4???? 8??????? 2?????????? 3????????? 9???????? 5
2???? 7??? 8???? 4??????? 2?????????? 5????????? 4???????? 8
2???? 9??? 6???? 7??????? 2?????????? 9????????? 5???????? 6
",sep="",header=TRUE)
res<-reshape(df1,sep=".",varying=list(c("sim","sim.1"),c("X1","X1.1"),c("X2","X2.1"),c("X3","X3.1")),direction="long",timevar="m")[,-5]
res
??? m sim X1 X2 id
1.1 1?? 1? 5? 4? 1
2.1 1?? 1? 4? 3? 2
3.1 1?? 1? 3? 9? 3
4.1 1?? 2? 6? 4? 4
5.1 1?? 2? 7? 8? 5
6.1 1?? 2? 9? 6? 6
1.2 2?? 1? 4? 3? 1
2.2 2?? 1? 7? 4? 2
3.2 2?? 1? 5? 8? 3
4.2 2?? 2? 3? 9? 4
5.2 2?? 2? 5? 4? 5
6.2 2?? 2? 9? 5? 6
?
A.K.




----- Original Message -----
From: Andrea Lamont <alamont082 at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, July 23, 2013 10:35 AM
Subject: [R] flexible approach to subsetting data

Hello:

I am running a simulation study and am stuck with a subsetting problem.

Here is the basic issue:
I generated data and am running a simulation that uses multiple imputation.
For each generated dataset, I used multiple imputation.? The resultant
dataset is in wide for where each imputation is recorded as a separate
column (though the different simulations are stacked).? Here is an example
of what it looks like:

sim?? X1?? X2?? X3?? sim.1?? X1.1? ? X1.1? ? X3.1
1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #
2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #? ? ? ?? #

sim refers to the simulated/generated dataset. X1-X3 are the values for the
first imputed dataset, X1.1-X3.1 are the values for the second imputed
dataset.

The problem is that I want the data to be in long format, like this:

sim m X1 X2 X3
1? 1?? #?? #? ? #
1? 2?? #?? #? ? #
2? 1?? #?? #? ? #
2? 2?? #?? #? ? #

where m is the imputation number.
This will allow me to do cleaner calculations (e.g. X3-X1).

I know I can subset the data manually - e.g. [,1:10] and save this to
separate datasets then? rbind; however, I'm looking for a more flexible
approach to do this.? This manual approach would be quite tedious as number
of imputations (and therefore number of columns) increased (with only 10
imputations, there are roughly 810 columns). Also,I would like to
avoid having to recode each time I change the number of imputations.

THe same is true for the reshape function, which would require naming
a huge number of columns and edits each time 'm' changes.


Is there a flexible way to approach this? I'm inclined to use a for loop,
but know that 1) this is generally inefficient and 2) am having trouble with
the coding regardless.

Any suggestions are appreciated.

Thanks,
Andrea


-- 
Andrea Lamont, MA
Clinical-Community Psychology
University of South Carolina
Barnwell College
Columbia, SC 29208

Please consider the environment before printing this email.

CONFIDENTIAL: This transmission is intended for the use of the
individual(s) or entity to which it is addressed, and may contain
information that is privileged, confidential, and exempt from disclosure
under applicable law. Should the reader of this message not be the intended
recipient(s), you are hereby notified that any dissemination, distribution,
or copying of this communication is strictly prohibited.? If you are not
the intended recipient, please contact the sender by reply email and
destroy/delete all copies of the original message.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jul 23 20:29:29 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 23 Jul 2013 11:29:29 -0700 (PDT)
Subject: [R] Selecting names with regard to visit frequency
In-Reply-To: <1374602601.77339.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <24519222.87230.1374552319727.JavaMail.nabble@joe.nabble.com>
	<CAObw_AV6Bs1FVCWivDi6MkYZcdzdnpn8ARccAFBrTkVC1GbJdw@mail.gmail.com>
	<CAP=QSFcd+iX3y11EwEdGRGNovUDExnAHP=hg7N+XV+ObDLG1xw@mail.gmail.com>
	<1374602601.77339.YahooMailNeo@web142603.mail.bf1.yahoo.com> 
Message-ID: <1374604169.38908.YahooMailNeo@web142604.mail.bf1.yahoo.com>



Hi Michael,


It is not clear how you read the dataset.? It looks like a dataframe.
df1<- read.table(text='
"","x" 
"A1",2 
"A2",5 
"A3",4 
"A4",6 
"A5",24 
"A6",7 
"A7",12 
"A8",3 
"A9",5
',sep=",",header=TRUE,row.names=1)
?vec1<-unlist(df1)
?names(vec1)<- row.names(df1)
?names(vec1)[vec1%in% 3:5]
#[1] "A2" "A3" "A8" "A9"
?names(vec1)[!is.na(match(vec1,3:5))]
#[1] "A2" "A3" "A8" "A9"
names(vec1)[vec1>=3 & vec1<=5]
#[1] "A2" "A3" "A8" "A9"
A.K.




________________________________
From: michael steele <real.steele500 at gmail.com>
To: smartpink111 at yahoo.com
Sent: Tuesday, July 23, 2013 11:30 AM
Subject: Re: Selecting names with regard to visit frequency



Hi A.K.,
Sorry for the confusion. The first option worked. I can't give out the actual data. But I can give something similar to its structure. Output from write.csv(myvector,file="copy") is attached.?

A1, A2... represent unique identification codes for individuals. Basically, we are interested in finding individuals who have visited within a certain range. It was easy enough to find those that visited the most and the least, but not somewhere in the middle. Your first option worked and I had tried something similar (I don't remember exactly what) but I must have missed something simple.

Thanks
steele



From:??<smartpink111 at yahoo.com>
>Date: Mon, Jul 22, 2013 at 11:05 PM
>Subject: Re: Selecting names with regard to visit frequency
>
>
>
>HI Steele,
>Could you provide a reproducible example for Options 2 and 3 that returns character(0)? Better would be use ?dput(). ?Not sure I understand you correctly. ?Did you meant that none of the options worked or except option 1? ?Also, comment regarding the practicality is also not clear.
>Tx.
><quote author='m.steele'>
>Thanks A.K., I actually tried something similar to option 1, but I missed
>something simple it seems. Options 2 and 3 do not work; they return:
>character(0)
>It may make a difference that myvector already exists, it displays in the
>form I provided. Recreating that vector in your solution may not be
>practical in this way as there are pushing towards 1000 names with
>corresponding visits.
>
>Thanks again this has been very helpful and I look forward to learning more.
>steele
></quote>
>Quoted from:
>http://r.789695.n4.nabble.com/Selecting-names-with-regard-to-visit-frequency-tp4672074p4672087.html
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>
>
>


From soccermucc at hotmail.com  Tue Jul 23 20:49:51 2013
From: soccermucc at hotmail.com (Valerie Mucciarelli)
Date: Tue, 23 Jul 2013 11:49:51 -0700
Subject: [R] Heat Map for species - code from Numerical Ecology with R
Message-ID: <BAY159-W9A73F734C9AF34A05BD8ADC6F0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/72d8734b/attachment.pl>

From rasmuson at uoregon.edu  Tue Jul 23 20:53:16 2013
From: rasmuson at uoregon.edu (Leif Rasmuson)
Date: Tue, 23 Jul 2013 11:53:16 -0700
Subject: [R] GLM with Binomial Distribution
Message-ID: <51EED11C.4040901@uoregon.edu>

Hi All,

I am working on re-analyzing per a reviewers request.

The goal of the project was to determine if the presence of predatory 
fishes caused female crabs to delay the release of larvae. Number of 
releases were recorded at three time periods: 1 hour before the 
simulated tide, 3 hours after the simulated tide and 6 hours after the 
tide. Predators were introduced at high tide and removed just following 
the 3 hour observation. Thus we have two categorical variables with 
three levels each. Time: pre-introduction, after introduction and after 
removal. Predator: no-predator, predator of adults and predator of larvae.

The number of females was not consistent between trials so my initial 
method was to use the SRH extension of the Kruskal wallace test to 
examine the percent of of larvae released.

A reviewer suggested that I use a GLM with a binomial distribution and 
logit link to analyze the larval release patterns. I used Crawley's book 
to analyze the data based on proportions. See code below. The problem I 
am running into is that the model is not including the predator control 
and interaction is excluding the predator control and the introduction 
time periods. Is this just the nature of using a binomial distribution 
(and/or our small sample size) or is there a way to force R to include 
all the factors and run all the interactions?

Thanks,
Leif

N=GLM$NumFemale-GLM$NumFemaleRelease
y=GLM$NumFemaleRelease
rv <-cbind(y,N)

 > model1=glm(y~GLM$Time*GLM$Treatment-1,family=binomial)
 > summary(model1)

Call:
glm(formula = y ~ GLM$Time * GLM$Treatment - 1, family = binomial)

Deviance Residuals:
Min 1Q Median 3Q Max
-1.6024 -0.7146 -0.4284 -0.2512 3.9885

Coefficients:
Estimate Std. Error z value Pr(>|z|)
GLM$TimeAfterIntroduction -1.8289 0.2297 -7.963 1.68e-15 ***
GLM$TimeAfterRemoval -3.6571 0.5064 -7.222 5.14e-13 ***
GLM$TimePreIntro -5.0626 1.0029 -5.048 4.46e-07 ***
GLM$TreatmentPlanktivore -0.0123 0.3211 -0.038 0.969
GLM$TreatmentPredator -0.1589 0.3311 -0.480 0.631
GLM$TimeAfterRemoval:GLM$TreatmentPlanktivore 0.5339 0.7132 0.749 0.454
GLM$TimePreIntro:GLM$TreatmentPlanktivore 0.6561 1.2708 0.516 0.606
GLM$TimeAfterRemoval:GLM$TreatmentPredator -0.1791 0.8399 -0.213 0.831
GLM$TimePreIntro:GLM$TreatmentPredator 1.7496 1.1496 1.522 0.128
---
Signif. codes: 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

(Dispersion parameter for binomial family taken to be 1)

Null deviance: 1720.2 on 270 degrees of freedom
Residual deviance: 258.3 on 261 degrees of freedom
AIC: 378.23

Number of Fisher Scoring iterations: 6

T

-- 
Leif K. Rasmuson

Doctoral Candidate
Oregon Institute of Marine Biology
Phone: (253)961-1763
E-Mail: Rasmuson at uoregon.edu
><((((?>`?.??.???`?...?><((((?>


From sarah.goslee at gmail.com  Tue Jul 23 21:47:16 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 23 Jul 2013 15:47:16 -0400
Subject: [R] Heat Map for species - code from Numerical Ecology with R
In-Reply-To: <BAY159-W9A73F734C9AF34A05BD8ADC6F0@phx.gbl>
References: <BAY159-W9A73F734C9AF34A05BD8ADC6F0@phx.gbl>
Message-ID: <CAM_vju=rZi_Ovy7ongdfLCQ2MoK8fFoXzA6oXx=QgkBYgpOzaA@mail.gmail.com>

Hi Valerie,

Are you using your own data or data provided by the authors?

If the latter, where can we get it?

If the former, please provide a reproducible example using dput() to
include some of your data.

Also, please resend your message with HTML mail turned off so we can
actually read it.

Providing a reproducible example makes it possible for us to figure
out what went wrong.

Sarah

On Tue, Jul 23, 2013 at 2:49 PM, Valerie Mucciarelli
<soccermucc at hotmail.com> wrote:
> Hello,   I am relatively new to R and I am working through the code that is provided in the book Numerical Ecology with R and I have run across an error message that I can't seem to figure out.   I am using the vegan, ade4, gclus and cluster packages.  The code is as follows: # Ordered community table # Species are ordered by their weighted averages on site scores or <- vegemite(spe, spe.chwo) spe is the dataframe spe.chwo came from:   spe.norm <- decostand(spe, "normalize")   spe.ch <- vegdist(spe.norm, "euc")   spe.ch.UPGMA <- hclust(spe.ch, method = "average")   spe.chwo <- reorder.hclust(spe.ch.UPGMA, spe.ch)   and the error is Error in vegemite(spe, spe.chwo) :   Cowardly refusing to use longer than 1 char symbols: Use scale  The data in the dataframe is biomass data recorded to 4 digits.  Here is an example of part of the dataframe:
>  AGA   ANT   BON  CAL11 0.42 0.092 0.051 0.0002 0.00 0.000 0.007 0.0024 0.00 0.008 0.000 0.0097 0.00 0.002 0.003 0.002
>
> I'm wondering if this code is not working because my data is more than one digit long. Any suggestions or insight on how to get this code to work with biomass data would be greatly appreciated. Thank you, Val
>         [[alternative HTML version deleted]]
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From sarah.goslee at gmail.com  Tue Jul 23 22:33:57 2013
From: sarah.goslee at gmail.com (Sarah Goslee)
Date: Tue, 23 Jul 2013 16:33:57 -0400
Subject: [R] Heat Map for species - code from Numerical Ecology with R
In-Reply-To: <BAY159-W42160503B0DD9CAB66B80EDC6F0@phx.gbl>
References: <BAY159-W9A73F734C9AF34A05BD8ADC6F0@phx.gbl>
	<CAM_vju=rZi_Ovy7ongdfLCQ2MoK8fFoXzA6oXx=QgkBYgpOzaA@mail.gmail.com>
	<BAY159-W42160503B0DD9CAB66B80EDC6F0@phx.gbl>
Message-ID: <CAM_vjunJQOCjs2fSuvouXtQHaR+TsEc124Yjy+WvOeZaHDHYUA@mail.gmail.com>

Hi Valerie,

On Tue, Jul 23, 2013 at 4:06 PM, Valerie Mucciarelli
<soccermucc at hotmail.com> wrote:
> Thank you Sarah for pointing out to me to turn HTML off.  Here is the message again.  To answer your questions the data I provide below is MY data.

That's still not a reproducible example, but much more readable.

Your guess appears to be correct: the help for vegemite specifically says:

 The table is printed in compact form: only one character
     can be used for abundance, and there are no spaces between
     columns.

and later suggests cut() or approx() for making cover scales.
Depending on your data, the scale argument to vegemite might be of
use.

There's a r-sig-ecology email list that you might be interested in joining.

Sarah


>   I am relatively new to R and I am working through the code that is provided in the book Numerical Ecology with R:  http://xa.yimg.com/kq/groups/19243105/1919134110/name/Numerical.pdf (pg 79)
>
>  and I have run across an error message that I can't seem to figure out.
>
>   I am using the vegan, ade4, gclus and cluster packages.  The code is as follows:
>
> # Ordered community table
> # Species are ordered by their weighted averages on site scores
>
> or <- vegemite(spe, spe.chwo)
>
> spe is the dataframe, here is part of it:
>
>     AGA   ANT   BON  CAL1   CAL   CER   CRY   DES  EUTH FRY
> 1  0.420 0.092 0.051 0.000 0.975 0.000 0.111 0.000 0.127   0
> 2  0.000 0.000 0.007 0.002 0.915 0.000 0.000 0.000 0.151   0
> 4  0.000 0.008 0.000 0.009 0.124 0.003 0.000 0.000 0.095   0
> 7  0.000 0.002 0.003 0.002 0.121 0.002 0.000 3.573 0.180   0
> 12 0.000 0.020 0.000 0.002 0.444 0.001 0.000 0.000 0.242   0
> 13 8.727 0.000 0.000 0.000 0.743 0.000 0.000 0.000 0.050   0
> 14 2.163 0.009 0.000 0.003 1.121 0.000 0.000 0.000 0.051   0
> 15 0.000 0.004 0.000 0.000 0.109 0.000 0.000 0.000 0.007   0
> 18 9.021 0.018 0.002 0.000 0.286 0.000 0.000 0.000 0.028   0
> 19 0.000 0.038 0.000 0.019 0.509 0.000 0.000 0.000 0.155   0
>
> spe.chwo came from:
>
>   spe.norm <- decostand(spe, "normalize")
>   spe.ch <- vegdist(spe.norm, "euc")
>   spe.ch.UPGMA <- hclust(spe.ch, method = "average")
>   spe.chwo <- reorder.hclust(spe.ch.UPGMA, spe.ch)
>
>
> and the error is
>
> Error in vegemite(spe, spe.chwo) :
>   Cowardly refusing to use longer than 1 char symbols:
> Use scale
>
>  The data in the dataframe is biomass data recorded to 4 digits.  I'm wondering if this code is not working because my data is more than one digit long.
>
> Any suggestions or insight on how to get this code to work would be greatly appreciated.
>
> Thank you,
>
> Val
>
>> Date: Tue, 23 Jul 2013 15:47:16 -0400
>> Subject: Re: [R] Heat Map for species - code from Numerical Ecology with R
>> From: sarah.goslee at gmail.com
>> To: soccermucc at hotmail.com
>> CC: r-help at r-project.org
>>
>> Hi Valerie,
>>
>> Are you using your own data or data provided by the authors?
>>
>> If the latter, where can we get it?
>>
>> If the former, please provide a reproducible example using dput() to
>> include some of your data.
>>
>> Also, please resend your message with HTML mail turned off so we can
>> actually read it.
>>
>> Providing a reproducible example makes it possible for us to figure
>> out what went wrong.
>>
>> Sarah
>>
>> On Tue, Jul 23, 2013 at 2:49 PM, Valerie Mucciarelli
>> <soccermucc at hotmail.com> wrote:
>>> Hello, I am relatively new to R and I am working through the code that is provided in the book Numerical Ecology with R and I have run across an error message that I can't seem to figure out. I am using the vegan, ade4, gclus and cluster packages. The code is as follows: # Ordered community table # Species are ordered by their weighted averages on site scores or <- vegemite(spe, spe.chwo) spe is the dataframe spe.chwo came from: spe.norm <- decostand(spe, "normalize") spe.ch <- vegdist(spe.norm, "euc") spe.ch.UPGMA <- hclust(spe.ch, method = "average") spe.chwo <- reorder.hclust(spe.ch.UPGMA, spe.ch) and the error is Error in vegemite(spe, spe.chwo) : Cowardly refusing to use longer than 1 char symbols: Use scale The data in the dataframe is biomass data recorded to 4 digits. Here is an example of part of the dataframe:
>>> AGA ANT BON CAL11 0.42 0.092 0.051 0.0002 0.00 0.000 0.007 0.0024 0.00 0.008 0.000 0.0097 0.00 0.002 0.003 0.002
>>>
>>> I'm wondering if this code is not working because my data is more than one digit long. Any suggestions or insight on how to get this code to work with biomass data would be greatly appreciated. Thank you, Val
>>> [[alternative HTML version deleted]]
>>>
>>
-- 
Sarah Goslee
http://www.functionaldiversity.org


From dcarlson at tamu.edu  Tue Jul 23 23:00:40 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Tue, 23 Jul 2013 16:00:40 -0500
Subject: [R] flexible approach to subsetting data
In-Reply-To: <F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>	<F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>
	<F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>
Message-ID: <01cc01ce87e7$b08340b0$1189c210$@tamu.edu>

Actually the ".0" on the first variable is not needed.

You could modify the reshape() call to search for the base
name of each variable so you would not need to change the code
if the number of replications changes:

reshape(df5,  direction="long", v.names=c("dose", "resp"), 
	varying=list(dose=grepl("dose", names(df5)),
	resp=grepl("resp", names(df5)) )
      )

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of David
Winsemius
Sent: Tuesday, July 23, 2013 1:12 PM
To: David Winsemius
Cc: R help; Andrea Lamont
Subject: Re: [R] flexible approach to subsetting data


On Jul 23, 2013, at 10:49 AM, David Winsemius wrote:

> 
> On Jul 23, 2013, at 10:01 AM, Adams, Jean wrote:
> 
>> Check out the reshape() function of the reshape package.
Here's one of the
>> examples from ?reshape.
>> 
>> Jean
>> 
>> 
>> library(reshape)   # No,  at least not for the
reshape-function
> 
> The reshape function is from the 'base' package. The
'reshape' and 'reshape2' packages were written (at least in
part) because the 'reshape'-function was so difficult to
understand.
> 
> If you do choose to use the reshape2 package, which is
well-respected and often extremely helpful, the function you
will want to start with is 'melt'.
> 
> 
>> long <- reshape(wide, direction="long")
> 
> I don't think this example will be particularly helpful
since the initial direction is "long" (from "wide") and more
input would be needed.

Here's a dataset to experiment with

df5 <- data.frame(dose.0 =
c(40,50,60,50),resp.0=c(40,50,60,50), 
 dose.1 = c(1,2,1,2), resp.1=c(1,2,1,2)+3, 
 dose.2 = c(2,1,2,1), resp.2=c(1,2,1,2)+3,
 dose.3 = c(3,3,3,3), resp.3=c(1,2,1,2)+3 )

Notice that you would need add the ".0" to the column names

reshape(df5,  direction="long", 
              v.names=c("dose", "resp"), 
               varying=list(dose=c(1,3,5,7), resp=c(2,4,6,8) )
        )  # succeeds



So perhaps could use similar call (after append the ".0"'s)
with:

  varying=list(sim=seq(1,810,by=4),
               X1= seq(2,810,by=4),
               X2= seq(3,810,by=4),
               X3= seq(4,810,by=4)
               )
               
> 
> 
>> wide
>> long
>> 
>> 
>> 
>> On Tue, Jul 23, 2013 at 9:35 AM, Andrea Lamont
<alamont082 at gmail.com> wrote:
>> 
>>> Hello:
>>> 
>>> I am running a simulation study and am stuck with a
subsetting problem.
>>> 
>>> Here is the basic issue:
>>> I generated data and am running a simulation that uses
multiple imputation.
>>> For each generated dataset, I used multiple imputation.
The resultant
>>> dataset is in wide for where each imputation is recorded
as a separate
>>> column (though the different simulations are stacked).
Here is an example
>>> of what it looks like:
>>> 
>>> sim   X1   X2   X3   sim.1   X1.1    X1.1    X3.1
> 
>>> 1         #    #     #        #           #          #
#
>>> 1         #    #     #        #           #          #
#
>>> 1         #    #     #        #           #          #
#
>>> 2         #    #     #        #           #          #
#
>>> 2         #    #     #        #           #          #
#
>>> 2         #    #     #        #           #          #
#
>>> 
>>> sim refers to the simulated/generated dataset. X1-X3 are
the values for the
>>> first imputed dataset, X1.1-X3.1 are the values for the
second imputed
>>> dataset.
>>> 
>>> The problem is that I want the data to be in long format,
like this:
>>> 
>>> sim m X1 X2 X3
>>> 1  1   #   #    #
>>> 1  2   #   #    #
>>> 2  1   #   #    #
>>> 2  2   #   #    #
>>> 
>>> where m is the imputation number.
>>> This will allow me to do cleaner calculations (e.g.
X3-X1).
>>> 
>>> I know I can subset the data manually - e.g. [,1:10] and
save this to
>>> separate datasets then  rbind; however, I'm looking for a
more flexible
>>> approach to do this.  This manual approach would be quite
tedious as number
>>> of imputations (and therefore number of columns) increased
(with only 10
>>> imputations, there are roughly 810 columns). Also,I would
like to
>>> avoid having to recode each time I change the number of
imputations.
>>> 
>>> THe same is true for the reshape function, which would
require naming
>>> a huge number of columns and edits each time 'm' changes.
> 
> If the columns are named regularly, then 'reshape' will
attempt to split properly without an explicit naming. Details
and a better description of the problem might allow more
specific answers to emerge. The fact that the first instances
have no numeric indicators may be a problem for the algorithm.

> 
> Why not post dput(head( dfrm[ ,1:12]))
> 
> -- 
> David.
> 
>>> 
>>> 
>>> Is there a flexible way to approach this? I'm inclined to
use a for loop,
>>> but know that 1) this is generally inefficient and 2) am
having trouble
>>> with
>>> the coding regardless.
>>> 
>>> Any suggestions are appreciated.
>>> 
>>> Thanks,
>>> Andrea
>>> 


David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From s.wood at bath.ac.uk  Tue Jul 23 23:08:26 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Tue, 23 Jul 2013 22:08:26 +0100
Subject: [R] mgcv: pcls() makes everything linear
In-Reply-To: <BLU0-SMTP87864BFC10BE802AA70C0FAE6F0@phx.gbl>
References: <BLU0-SMTP87864BFC10BE802AA70C0FAE6F0@phx.gbl>
Message-ID: <51EEF0CA.7040108@bath.ac.uk>

I can't see anything immediately wrong except:

1. presumably there are repeated values in 'road_quiet' aren't there? If 
so then your inequality constraint matrix
will contain constraints that are *exact* copies of each other. I'm not 
sure, and don't immediately have time to try it
out, but it could be that this will cause a problem (what might happen 
is that you hit a constraint, project into its null space, but 
numerically the search direction then appears to be about to violate a 
copy of the constraint, so the copy gets added to the set of active 
constraints, and then another copy, and so on until it appears that the 
problem is fully constrained). Could you try replacing your constraints 
with some based on a grid  of e.g. 50 points spread evenly over the 
range of 'road_quiet' values. (If that does solve the problem please let 
me know, and I can add a check for constraint uniqueness to pcls.)

2. A long shot, but what is the range of values of road_quiet? eps 
should probably be around 1e-7 times the typical size of road_quiet (by 
'around' I mean something in the range 1e-4 to 1e-9, say). If eps is 
much too small or much too large
then the constraints become poor approximations to the gradient of the 
spline. I doubt this is the problem, however.

If those two fail you could send me some data (offline) with which I can 
reproduce the problem (smaller the better!), and I can dig further (on 
usual - only for this purpose - basis).

best,

Simon

On 23/07/13 10:19, Kathrine Veie wrote:
> Dear R helplisters,
>
> I am trying to implement a mononicity constraint on a smooth term in my generalized additive model with the mgcv package (v. 1.7-18). I adapted the code from an example given in the help file for pcls(). The example runs just as one would expect, but when I adapt it and use the code on my data, the code results in a linear fit on ALL smooth terms in the model even though I only place restrictions on a single one of them.
>
> Can anyone give me any idea why this is the case?  The basis spline dimension is taken from the unconstrained object, but the coefficients determined by pcls() are such that the fit is linear (basically very, very small coefficients and large coefficients on a single spline component for each covariate as far as I can tell). (see figure which I hope comes through to the help list posting!)
>
> The example is simpler than the model I actually want to estimate, but the problem is the same in the more expanded version. In the simple version, the curve I want to restrict to be monotonically increasing already satisfies the constraint, but in the full model it is more "wiggly" and has some downward sloping parts.
>
> In the code below I impose the constraint using a subset of the data, but I tried the same thing using the full data set for predictions and except for that being a bit slower the results are all the same. (The full data set has 14,000 observations)
>
> ## Preliminary unconstrained gam fit...
> G <- gam(ksumphk~s(arlsaml)+s(road_quiet)+s(centrum), data=per1.200m,family=gaussian(link=log), fit=FALSE)
> b <- gam(G=G)
> c <- b ##Save unconstrained estimates in separate model
>
> ## generate constraints, by finite differencing
> ## using predict.gam ....
> eps <- 1e-7
>
> #Sample from the data set to avoid too many obs in prediction
>
> pd0 <- data.frame(per1.200m[sample(nrow(per1.200m),200),])
> pd1 <- pd0
> pd1$road_quiet<- pd0$road_quiet +eps
>
> X0 <- predict(b,newdata=pd0,type="lpmatrix")
> X1 <- predict(b,newdata=pd1,type="lpmatrix")
> Xz <- (X1-X0)/eps
>
>
> G$Ain <- rbind(Xz) ## inequality constraint matrix
> G$bin <- rep(0,nrow(G$Ain))
> G$sp <- b$sp
> G$C<-matrix(0,0,0)
> G$p <- coef(b)
> G$off <- G$off-1 ## to match what pcls is expecting
> ## force inital parameters to meet constraint
> G$p[11:18] <- 0.0
> p <- pcls(G) ## constrained fit
> par(mfrow=c(2,3))
> plot(c) ## original fit
> b$coefficients <- p
> plot(b) ## constrained fit
> ## note that standard errors
>
>
> Any help or suggestions on where to read more about pcls() would be very much appreciated!
>
> Kind regards,
> Kathrine
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Jul 23 23:59:51 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 23 Jul 2013 14:59:51 -0700
Subject: [R] flexible approach to subsetting data
In-Reply-To: <01cc01ce87e7$b08340b0$1189c210$@tamu.edu>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>	<F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>
	<F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>
	<01cc01ce87e7$b08340b0$1189c210$@tamu.edu>
Message-ID: <AA63C50C-12E8-421D-BA69-A46B50EAB258@comcast.net>


On Jul 23, 2013, at 2:00 PM, David Carlson wrote:

> Actually the ".0" on the first variable is not needed.
> 
> You could modify the reshape() call to search for the base
> name of each variable so you would not need to change the code
> if the number of replications changes:
> 
> reshape(df5,  direction="long", v.names=c("dose", "resp"), 
> 	varying=list(dose=grepl("dose", names(df5)),
> 	resp=grepl("resp", names(df5)) )
>      )
> 

That's really elegant and much more "elastic". (I hadn't realized that a logical vector would be accepted.) Also possible to just use 'grep' which would instead construct a vector of column numbers as the list elements of 'varying'. I've wondered for years whether the help page description of 'varying could be improved. It currently says:

"varying : 
names of sets of variables in the wide format that correspond to single variables in long format (?time-varying?). This is canonically a list of vectors of variable names, but it can optionally be a matrix of names, or a single vector of names. In each case, the names can be replaced by indices which are interpreted as referring to names(data). See ?Details? for more details and options."

I wondered if it might say instead:

"a list of sets of variables in the wide format that each correspond to single variables in long format (?time-varying?). This is canonically a list of vectors of column names or numbers , but it can optionally be a matrix of names, or a single vector of names. In each case, the names can be replaced by numeric or logical indices which are interpreted as extracting from names(data). See ?Details? for more details and options."

But it supposedly is the case that it can be a set of names, and in that case there is also a  further promise that an effort to do the automagic splitting. Unfortunately the magic is often unsuccessful

> reshape(df5,  direction="long", 
+ 	varying=c("dose", "resp")
+      )
Error in guess(varying) : 
  failed to guess time-varying variables from their names

# Seems like it should have been possible:
> df5
  dose.0 resp.0 dose.1 resp.1 dose.2 resp.2 dose.3 resp.3
1     40     40      1      4      2      4      3      4
2     50     50      2      5      1      5      3      5
3     60     60      1      4      2      4      3      4
4     50     50      2      5      1      5      3      5

-- 
David.

> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
> 
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Tuesday, July 23, 2013 1:12 PM
> To: David Winsemius
> Cc: R help; Andrea Lamont
> Subject: Re: [R] flexible approach to subsetting data
> 
> 
> On Jul 23, 2013, at 10:49 AM, David Winsemius wrote:
> 
>> 
>> On Jul 23, 2013, at 10:01 AM, Adams, Jean wrote:
>> 
>>> Check out the reshape() function of the reshape package.
> Here's one of the
>>> examples from ?reshape.
>>> 
>>> Jean
>>> 
>>> 
>>> library(reshape)   # No,  at least not for the
> reshape-function
>> 
>> The reshape function is from the 'base' package. The
> 'reshape' and 'reshape2' packages were written (at least in
> part) because the 'reshape'-function was so difficult to
> understand.
>> 
>> If you do choose to use the reshape2 package, which is
> well-respected and often extremely helpful, the function you
> will want to start with is 'melt'.
>> 
>> 
>>> long <- reshape(wide, direction="long")
>> 
>> I don't think this example will be particularly helpful
> since the initial direction is "long" (from "wide") and more
> input would be needed.
> 
> Here's a dataset to experiment with
> 
> df5 <- data.frame(dose.0 =
> c(40,50,60,50),resp.0=c(40,50,60,50), 
> dose.1 = c(1,2,1,2), resp.1=c(1,2,1,2)+3, 
> dose.2 = c(2,1,2,1), resp.2=c(1,2,1,2)+3,
> dose.3 = c(3,3,3,3), resp.3=c(1,2,1,2)+3 )
> 
> Notice that you would need add the ".0" to the column names
> 
> reshape(df5,  direction="long", 
>              v.names=c("dose", "resp"), 
>               varying=list(dose=c(1,3,5,7), resp=c(2,4,6,8) )
>        )  # succeeds
> 
> 
> 
> So perhaps could use similar call (after append the ".0"'s)
> with:
> 
>  varying=list(sim=seq(1,810,by=4),
>               X1= seq(2,810,by=4),
>               X2= seq(3,810,by=4),
>               X3= seq(4,810,by=4)
>               )
> 
>> 
>> 
>>> wide
>>> long
>>> 
>>> 
>>> 
>>> On Tue, Jul 23, 2013 at 9:35 AM, Andrea Lamont
> <alamont082 at gmail.com> wrote:
>>> 
>>>> Hello:
>>>> 
>>>> I am running a simulation study and am stuck with a
> subsetting problem.
>>>> 
>>>> Here is the basic issue:
>>>> I generated data and am running a simulation that uses
> multiple imputation.
>>>> For each generated dataset, I used multiple imputation.
> The resultant
>>>> dataset is in wide for where each imputation is recorded
> as a separate
>>>> column (though the different simulations are stacked).
> Here is an example
>>>> of what it looks like:
>>>> 
>>>> sim   X1   X2   X3   sim.1   X1.1    X1.1    X3.1
>> 
>>>> 1         #    #     #        #           #          #
> #
>>>> 1         #    #     #        #           #          #
> #
>>>> 1         #    #     #        #           #          #
> #
>>>> 2         #    #     #        #           #          #
> #
>>>> 2         #    #     #        #           #          #
> #
>>>> 2         #    #     #        #           #          #
> #
>>>> 
>>>> sim refers to the simulated/generated dataset. X1-X3 are
> the values for the
>>>> first imputed dataset, X1.1-X3.1 are the values for the
> second imputed
>>>> dataset.
>>>> 
>>>> The problem is that I want the data to be in long format,
> like this:
>>>> 
>>>> sim m X1 X2 X3
>>>> 1  1   #   #    #
>>>> 1  2   #   #    #
>>>> 2  1   #   #    #
>>>> 2  2   #   #    #
>>>> 
>>>> where m is the imputation number.
>>>> This will allow me to do cleaner calculations (e.g.
> X3-X1).
>>>> 
>>>> I know I can subset the data manually - e.g. [,1:10] and
> save this to
>>>> separate datasets then  rbind; however, I'm looking for a
> more flexible
>>>> approach to do this.  This manual approach would be quite
> tedious as number
>>>> of imputations (and therefore number of columns) increased
> (with only 10
>>>> imputations, there are roughly 810 columns). Also,I would
> like to
>>>> avoid having to recode each time I change the number of
> imputations.
>>>> 
>>>> THe same is true for the reshape function, which would
> require naming
>>>> a huge number of columns and edits each time 'm' changes.
>> 
>> If the columns are named regularly, then 'reshape' will
> attempt to split properly without an explicit naming. Details
> and a better description of the problem might allow more
> specific answers to emerge. The fact that the first instances
> have no numeric indicators may be a problem for the algorithm.
> 
>> 
>> Why not post dput(head( dfrm[ ,1:12]))
>> 
>> -- 
>> David.
>> 
>>>> 
>>>> 
>>>> Is there a flexible way to approach this? I'm inclined to
> use a for loop,
>>>> but know that 1) this is generally inefficient and 2) am
> having trouble
>>>> with
>>>> the coding regardless.
>>>> 
>>>> Any suggestions are appreciated.
>>>> 
>>>> Thanks,
>>>> Andrea
>>>> 
> 
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
> 

David Winsemius
Alameda, CA, USA


From iza.ch1 at op.pl  Tue Jul 23 23:58:27 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Tue, 23 Jul 2013 23:58:27 +0200
Subject: [R] do not perform function if the outcome is NA
Message-ID: <45020227-7b171e3c3674cf0e9375e1aa83d67df4@pmq5.m5r2.onet>

Hi you all

I have a question regarding the function. In my function I divide the values by the standard errors and sometimes the standard error is equal to zero and I get the result NA. Can I write the function in the way that if the outcome of the function is zero then the function is not conducted and it stays the value (not divided by standard errors)? the code for my function is the following:

standardised.abnormal.returns<-lapply(seq_len(ncol(abnormal.returns)),function(i) {abnormal.returns[,i]/standard.deviation[i,1]})

Thank you all for the help


From soccermucc at hotmail.com  Tue Jul 23 22:06:27 2013
From: soccermucc at hotmail.com (Valerie Mucciarelli)
Date: Tue, 23 Jul 2013 13:06:27 -0700
Subject: [R] Heat Map for species - code from Numerical Ecology with R
In-Reply-To: <CAM_vju=rZi_Ovy7ongdfLCQ2MoK8fFoXzA6oXx=QgkBYgpOzaA@mail.gmail.com>
References: <BAY159-W9A73F734C9AF34A05BD8ADC6F0@phx.gbl>,
	<CAM_vju=rZi_Ovy7ongdfLCQ2MoK8fFoXzA6oXx=QgkBYgpOzaA@mail.gmail.com>
Message-ID: <BAY159-W42160503B0DD9CAB66B80EDC6F0@phx.gbl>

Thank you Sarah for pointing out to me to turn HTML off. ?Here is the message again. ?To answer your questions the data I provide below is MY data.

? I am relatively new to R and I am working through the code that is provided in the book Numerical Ecology with R: ?http://xa.yimg.com/kq/groups/19243105/1919134110/name/Numerical.pdf?(pg 79)

?and I have run across an error message that I can't seem to figure out.?

? I am using the vegan, ade4, gclus and cluster packages. ?The code is as follows:?

# Ordered community table?
# Species are ordered by their weighted averages on site scores?

or <- vegemite(spe, spe.chwo)?

spe is the dataframe, here is part of it:

? ? AGA ? ANT ? BON ?CAL1 ? CAL ? CER ? CRY ? DES ?EUTH FRY
1 ?0.420 0.092 0.051 0.000 0.975 0.000 0.111 0.000 0.127 ? 0
2 ?0.000 0.000 0.007 0.002 0.915 0.000 0.000 0.000 0.151 ? 0
4 ?0.000 0.008 0.000 0.009 0.124 0.003 0.000 0.000 0.095 ? 0
7 ?0.000 0.002 0.003 0.002 0.121 0.002 0.000 3.573 0.180 ? 0
12 0.000 0.020 0.000 0.002 0.444 0.001 0.000 0.000 0.242 ? 0
13 8.727 0.000 0.000 0.000 0.743 0.000 0.000 0.000 0.050 ? 0
14 2.163 0.009 0.000 0.003 1.121 0.000 0.000 0.000 0.051 ? 0
15 0.000 0.004 0.000 0.000 0.109 0.000 0.000 0.000 0.007 ? 0
18 9.021 0.018 0.002 0.000 0.286 0.000 0.000 0.000 0.028 ? 0
19 0.000 0.038 0.000 0.019 0.509 0.000 0.000 0.000 0.155 ? 0

spe.chwo came from:?

? spe.norm <- decostand(spe, "normalize")?
? spe.ch <- vegdist(spe.norm, "euc")?
? spe.ch.UPGMA <- hclust(spe.ch, method = "average")?
? spe.chwo <- reorder.hclust(spe.ch.UPGMA, spe.ch)?
??

and the error is?

Error in vegemite(spe, spe.chwo) :?
? Cowardly refusing to use longer than 1 char symbols:?
Use scale?

?The data in the dataframe is biomass data recorded to 4 digits. ?I'm wondering if this code is not working because my data is more than one digit long.?

Any suggestions or insight on how to get this code to work would be greatly appreciated.?

Thank you,?

Val?

> Date: Tue, 23 Jul 2013 15:47:16 -0400
> Subject: Re: [R] Heat Map for species - code from Numerical Ecology with R
> From: sarah.goslee at gmail.com
> To: soccermucc at hotmail.com
> CC: r-help at r-project.org
> 
> Hi Valerie,
> 
> Are you using your own data or data provided by the authors?
> 
> If the latter, where can we get it?
> 
> If the former, please provide a reproducible example using dput() to
> include some of your data.
> 
> Also, please resend your message with HTML mail turned off so we can
> actually read it.
> 
> Providing a reproducible example makes it possible for us to figure
> out what went wrong.
> 
> Sarah
> 
> On Tue, Jul 23, 2013 at 2:49 PM, Valerie Mucciarelli
> <soccermucc at hotmail.com> wrote:
>> Hello, I am relatively new to R and I am working through the code that is provided in the book Numerical Ecology with R and I have run across an error message that I can't seem to figure out. I am using the vegan, ade4, gclus and cluster packages. The code is as follows: # Ordered community table # Species are ordered by their weighted averages on site scores or <- vegemite(spe, spe.chwo) spe is the dataframe spe.chwo came from: spe.norm <- decostand(spe, "normalize") spe.ch <- vegdist(spe.norm, "euc") spe.ch.UPGMA <- hclust(spe.ch, method = "average") spe.chwo <- reorder.hclust(spe.ch.UPGMA, spe.ch) and the error is Error in vegemite(spe, spe.chwo) : Cowardly refusing to use longer than 1 char symbols: Use scale The data in the dataframe is biomass data recorded to 4 digits. Here is an example of part of the dataframe:
>> AGA ANT BON CAL11 0.42 0.092 0.051 0.0002 0.00 0.000 0.007 0.0024 0.00 0.008 0.000 0.0097 0.00 0.002 0.003 0.002
>>
>> I'm wondering if this code is not working because my data is more than one digit long. Any suggestions or insight on how to get this code to work with biomass data would be greatly appreciated. Thank you, Val
>> [[alternative HTML version deleted]]
>>
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org 		 	   		  

From smartpink111 at yahoo.com  Wed Jul 24 00:39:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 23 Jul 2013 15:39:00 -0700 (PDT)
Subject: [R] Selecting names with regard to visit frequency
Message-ID: <1374619140.19712.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Michael,
It could be due to some extra space.? If you use read.table(..., fill=TRUE), it should read.? Then, there would be missing values.? Using ?dput() will be better.? 

?dput(df1)
structure(list(x = c(2L, 5L, 4L, 6L, 24L, 7L, 12L, 3L, 5L)), .Names = "x", class = "data.frame", row.names = c("A1", 
"A2", "A3", "A4", "A5", "A6", "A7", "A8", "A9"))
Now, try the code by assigning:
df1<- structure(list(x.....


It wouldn't work with decimals because here:
3:5
#[1] 3 4 5 #it will matching all values that are 3,4, and 5

Trying this on another dataset:

df2<- structure(list(x = c(2, 5, 4.4, 6, 24, 7, 12, 3.6, 5)), .Names = "x", class = "data.frame", row.names = c("A1", 
"A2", "A3", "A4", "A5", "A6", "A7", "A8", "A9"))
vec2<- unlist(df2)
?names(vec2)<- row.names(df2)
vec2
#? A1?? A2?? A3?? A4?? A5?? A6?? A7?? A8?? A9 
# 2.0? 5.0? 4.4? 6.0 24.0? 7.0 12.0? 3.6? 5.0 
?names(vec2)[vec2%in% 3:5] #incorrect
#[1] "A2" "A9"

names(vec2)[vec2%in% seq(3,5,by=0.1)]
#[1] "A2" "A3" "A8" "A9"


#If I change
vec2[3]<- 4.46
?names(vec2)[vec2%in% seq(3,5,by=0.1)]
#[1] "A2" "A8" "A9"
?names(vec2)[round(vec2,1)%in% seq(3,5,by=0.1)]
#[1] "A2" "A3" "A8" "A9"

names(vec2)[vec2>=3 & vec2<=5] #should be better in such cases
#[1] "A2" "A3" "A8" "A9"


It is also better to check R FAQ 7.31.

A.K.




Hi Arun, 
Perhaps these are dataframes I am working with, and have mistaken 
them for vectors (I am still very new at this and learning the data 
structures). 

I tried to read the text in as you have it here (copied and pasted), but it did not work. 
Error in read.table(text = " \n\"\",\"x\" \n\"A1\",2 \n\"A2\",5 
\n\"A3\",4 \n\"A4\",6 \n\"A5\",24 \n\"A6\",7 \n\"A7\",12 \n\"A8\",3 
\n\"A9\",5 \n", ?: 
? more columns than column names 

I retried both: 
names(vec1)[vec1%in% 3:5] 

& 

names(vec1)[!is.na(match(vec1,3:5))] 

before and after processing my current dataframe to a vector but
 I get a NULL return. I also get a NULL return if I unlist the dataframe
 and try to execute: 
names(vec1)[vec1>=3 & vec1<=5] 

All 3 do work if I keep the dataframe in its original form, instead of using: 
?vec1<-unlist(df1) 
?names(vec1)<- row.names(df1) 

?I discovered another issue, however. I am working with a couple
 datasets, one of them has whole numbers the other has percentages in 
place of visits such as: 
"A1",0.2 
"A2",0.5 
?... 
the two options: 

names(vec1)[vec1%in% 3:5] 
names(vec1)[!is.na(match(vec1,3:5))] 

do not seem to work with ranges given in decimals (and that is 
probably what I originally tested them on) but are fine with whole 
numbers. 

Thanks, 
steele


From geoff at uyleman.com  Wed Jul 24 00:40:09 2013
From: geoff at uyleman.com (cognizio)
Date: Tue, 23 Jul 2013 15:40:09 -0700 (PDT)
Subject: [R] [R-pkgs] WriteXLS Version 3.0.0 Released
In-Reply-To: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>
References: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>
Message-ID: <1374619209185-4672180.post@n4.nabble.com>

Great summary! It works great without the heavy PERL library. I am running
the YAML package I thought I needed to support WRITEXLS. Do I need it or is
YAML not a dependency? 

Other question is on your last point: 'WRITEXLS COMMENT:' now shows up
across the first row of the data output in the XLS. How do I modify these
values? 

Thx!

Cog  



--
View this message in context: http://r.789695.n4.nabble.com/R-pkgs-WriteXLS-Version-3-0-0-Released-tp4671927p4672180.html
Sent from the R help mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Wed Jul 24 00:45:13 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 23 Jul 2013 23:45:13 +0100
Subject: [R] do not perform function if the outcome is NA
In-Reply-To: <45020227-7b171e3c3674cf0e9375e1aa83d67df4@pmq5.m5r2.onet>
References: <45020227-7b171e3c3674cf0e9375e1aa83d67df4@pmq5.m5r2.onet>
Message-ID: <51EF0779.20000@sapo.pt>

Hello,

Try the following.


standardised.abnormal.returns <- 
lapply(seq_len(ncol(abnormal.returns)),function(i) {
	if(standard.deviation[i,1] == 0)
		abnormal.returns[,i]
	else
		abnormal.returns[,i]/standard.deviation[i,1]
})



Hope this helps,

Rui Barradas

Em 23-07-2013 22:58, iza.ch1 escreveu:
> Hi you all
>
> I have a question regarding the function. In my function I divide the values by the standard errors and sometimes the standard error is equal to zero and I get the result NA. Can I write the function in the way that if the outcome of the function is zero then the function is not conducted and it stays the value (not divided by standard errors)? the code for my function is the following:
>
> standardised.abnormal.returns<-lapply(seq_len(ncol(abnormal.returns)),function(i) {abnormal.returns[,i]/standard.deviation[i,1]})
>
> Thank you all for the help
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From iza.ch1 at op.pl  Wed Jul 24 00:48:10 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Wed, 24 Jul 2013 00:48:10 +0200
Subject: [R] do not perform function if the outcome is NA
Message-ID: <21031056-f87dca88965d5c61b49853bfb84b2155@pmq2v.m5r2.onet>

Hi Rui 

Thanks a lot. It works perfect. 

Izzie


> Hello,
> 
> Try the following.
> 
> 
> standardised.abnormal.returns <- 
> lapply(seq_len(ncol(abnormal.returns)),function(i) {
> 	if(standard.deviation[i,1] == 0)
> 		abnormal.returns[,i]
> 	else
> 		abnormal.returns[,i]/standard.deviation[i,1]
> })
> 
> 
> 
> Hope this helps,
> 
> Rui Barradas
> 
> Em 23-07-2013 22:58, iza.ch1 escreveu:
> > Hi you all
> >
> > I have a question regarding the function. In my function I divide the values by the standard errors and sometimes the standard error is equal to zero and I get the result NA. Can I write the function in the way that if the outcome of the function is zero then the function is not conducted and it stays the value (not divided by standard errors)? the code for my function is the following:
> >
> > standardised.abnormal.returns<-lapply(seq_len(ncol(abnormal.returns)),function(i) {abnormal.returns[,i]/standard.deviation[i,1]})
> >
> > Thank you all for the help
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> 

From rmh at temple.edu  Wed Jul 24 04:23:46 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 23 Jul 2013 22:23:46 -0400
Subject: [R] .eps files and powerpoint
Message-ID: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130723/72ed688d/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Wed Jul 24 04:25:00 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 23 Jul 2013 19:25:00 -0700
Subject: [R] do not perform function if the outcome is NA
In-Reply-To: <21031056-f87dca88965d5c61b49853bfb84b2155@pmq2v.m5r2.onet>
References: <21031056-f87dca88965d5c61b49853bfb84b2155@pmq2v.m5r2.onet>
Message-ID: <3b772543-cad6-4768-9f28-f1111e844885@email.android.com>

The problem specification here seems flawed. The normal return values are unitless, but the abnormal return values have units. I would expect that returning NA when the standard deviations are zero will give rather less surprising results.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"iza.ch1" <iza.ch1 at op.pl> wrote:
>Hi Rui 
>
>Thanks a lot. It works perfect. 
>
>Izzie
>
>
>> Hello,
>> 
>> Try the following.
>> 
>> 
>> standardised.abnormal.returns <- 
>> lapply(seq_len(ncol(abnormal.returns)),function(i) {
>> 	if(standard.deviation[i,1] == 0)
>> 		abnormal.returns[,i]
>> 	else
>> 		abnormal.returns[,i]/standard.deviation[i,1]
>> })
>> 
>> 
>> 
>> Hope this helps,
>> 
>> Rui Barradas
>> 
>> Em 23-07-2013 22:58, iza.ch1 escreveu:
>> > Hi you all
>> >
>> > I have a question regarding the function. In my function I divide
>the values by the standard errors and sometimes the standard error is
>equal to zero and I get the result NA. Can I write the function in the
>way that if the outcome of the function is zero then the function is
>not conducted and it stays the value (not divided by standard errors)?
>the code for my function is the following:
>> >
>> >
>standardised.abnormal.returns<-lapply(seq_len(ncol(abnormal.returns)),function(i)
>{abnormal.returns[,i]/standard.deviation[i,1]})
>> >
>> > Thank you all for the help
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>> 
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From kridox at ymail.com  Wed Jul 24 06:14:36 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Wed, 24 Jul 2013 13:14:36 +0900
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
Message-ID: <CAAcyNCz5Ru_PYC9R_4NYkuZ2D2pvw3hTOSqn13JUPpwKFDusVQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/a3e0e3d2/attachment.pl>

From p_connolly at slingshot.co.nz  Wed Jul 24 08:07:47 2013
From: p_connolly at slingshot.co.nz (Patrick Connolly)
Date: Wed, 24 Jul 2013 18:07:47 +1200
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
Message-ID: <20130724060747.GC24293@slingshot.co.nz>

On Tue, 23-Jul-2013 at 10:23PM -0400, Richard M. Heiberger wrote:

|> I have colleagues who use powerpoint.  When I send my colleagues pdf files
|> or ps files, powerpoint
|> rejects them.  Powerpoint does accept some eps files.
|> 

[...]

|> Does anyone know a workaround that will get vector graphics from R into
|> powerpoint?
|> win.metafile is not acceptable.  The resolution of emf files from R is
|> worse than png files.

Maybe worse than png files at the default resolution which is 72 dpi.
Change that to something like 300 and nobody will see a jagged edge in
a PowerPoint slide.

HTH


|> 
|> Thanks
|> Rich
|> 
|> 	[[alternative HTML version deleted]]
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From terry.seaward at investecmail.com  Wed Jul 24 08:23:32 2013
From: terry.seaward at investecmail.com (Terry Seaward)
Date: Wed, 24 Jul 2013 08:23:32 +0200
Subject: [R]  R base package grid does not output raster image
Message-ID: <922D1973-A313-49D8-A685-A2403BA9AFDF@AURORA.iam.corp.investec.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/cdf6023e/attachment.pl>

From michel.arnaud at cirad.fr  Wed Jul 24 08:39:38 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 24 Jul 2013 08:39:38 +0200
Subject: [R] Change values in a dateframe
Message-ID: <51EF76AA.7000803@cirad.fr>

Hello

I have the following problem :
The dataframe TEST has multiple lines for a same person because :
there are differents values of Nom or differents values of Prenom
but the values of Matricule or Sexe or Date.de.naissance are the same.

TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
"JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
"Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = 
"factor"),
     Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
     1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
     "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = 
"factor")), .Names = c("Matricule",
"Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", 
row.names = c(NA,
-11L))


I would want to make homogeneous the information and would like built 2 
dataframes :
df1 wich has the value of Nom and Prenom of the first lines of TEST when 
there are different values. The other values (Matricule or Sexe or 
Date.de.naissance) are unchanged

df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
"JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom = 
structure(c(6L,
3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
"Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = 
"factor"),
     Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
     1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
     "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = 
"factor")), .Names = c("Matricule",
"Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", 
row.names = c(NA,
-11L))

df2 wich has the value of Nom and Prenom of the last lines of TEST when 
there are different values. The other values (Matricule or Sexe or 
Date.de.naissance) are unchanged.

df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
"LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
     Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
     5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
     "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe = 
structure(c(1L,
     1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
     "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
     2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
     "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
     "30/03/1935"), class = "factor")), .Names = c("Matricule",
"Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", 
row.names = c(NA,
-11L))

Thank for your helps
Michel

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From ripley at stats.ox.ac.uk  Wed Jul 24 08:43:21 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 24 Jul 2013 07:43:21 +0100
Subject: [R] R base package grid does not output raster image
In-Reply-To: <922D1973-A313-49D8-A685-A2403BA9AFDF@AURORA.iam.corp.investec.com>
References: <922D1973-A313-49D8-A685-A2403BA9AFDF@AURORA.iam.corp.investec.com>
Message-ID: <51EF7789.9000801@stats.ox.ac.uk>

On 24/07/2013 07:23, Terry Seaward wrote:
> Hi,
>
>
>
> I don't think this is a remote desktop issue. I can run the following
> code by remoting into both a Windows 7 machine and a Windows Server R2

There are Windows Server 2003, 2008, 2012 but not R2.

> machine. I can see the results on the Windows 7 machine but not the
> server.

This is a known problem with Windows Remote Desktop: it is nothing to do 
with R.  See ?rasterImage in R.

Basically Remote Desktop restricts the number of colours when connecting 
to a Windows Server machine, and interpolating rasters needs a lot of 
colours.

>> library(grid)
>
>> grid.raster(1:10/11)
>
>
>
> Best regards,
>
> Terry
>
>
> Terry Seaward Risk Manager
> T +27 21 416 1923
> terry.seaward at investecmail.com
>
> 36 Hans Strijdom Avenue Foreshore, Cape Town, 8001, South Africa
> www.investecassetmanagement.com


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From rni.boh at gmail.com  Wed Jul 24 08:44:42 2013
From: rni.boh at gmail.com (Bob O'Hara)
Date: Wed, 24 Jul 2013 08:44:42 +0200
Subject: [R] GLM with Binomial Distribution
In-Reply-To: <51EED11C.4040901@uoregon.edu>
References: <51EED11C.4040901@uoregon.edu>
Message-ID: <CAN-Z0xWRkbjkv_cywfk-GXmUkxji+pM1WiGe4=jT3Et4Nx49zg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/dc7e3484/attachment.pl>

From bhh at xs4all.nl  Wed Jul 24 09:48:37 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Wed, 24 Jul 2013 09:48:37 +0200
Subject: [R] Change values in a dateframe
In-Reply-To: <51EF76AA.7000803@cirad.fr>
References: <51EF76AA.7000803@cirad.fr>
Message-ID: <4AB9302F-9708-49AB-85B7-F53DEC00D134@xs4all.nl>


On 24-07-2013, at 08:39, Arnaud Michel <michel.arnaud at cirad.fr> wrote:

> Hello
> 
> I have the following problem :
> The dataframe TEST has multiple lines for a same person because :
> there are differents values of Nom or differents values of Prenom
> but the values of Matricule or Sexe or Date.de.naissance are the same.
> 
> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = "factor"),
>    Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>    1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>    "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", row.names = c(NA,
> -11L))
> 
> 
> I would want to make homogeneous the information and would like built 2 dataframes :
> df1 wich has the value of Nom and Prenom of the first lines of TEST when there are different values. The other values (Matricule or Sexe or Date.de.naissance) are unchanged
> 
> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom = structure(c(6L,
> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = "factor"),
>    Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>    1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>    "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", row.names = c(NA,
> -11L))
> 
> df2 wich has the value of Nom and Prenom of the last lines of TEST when there are different values. The other values (Matricule or Sexe or Date.de.naissance) are unchanged.
> 
> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>    Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>    5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>    "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe = structure(c(1L,
>    1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>    "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
>    2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>    "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
>    "30/03/1935"), class = "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", row.names = c(NA,
> -11L))
> 

Something like this

r1 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
                    FUN=function(x) {x[,c("Nom","Prenom")] <- x[1,c("Nom","Prenom"),drop=TRUE];x})))
rownames(r1) <- NULL 
r1

r2 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
                    FUN=function(x) {x[,c("Nom","Prenom")] <- x[nrow(x),c("Nom","Prenom"),drop=TRUE];x})))
rownames(r2) <- NULL
r2

#> identical(r1,df1)
#[1] TRUE
#> identical(r2,df2)
#[1] TRUE

Note: I had to change the Prenom and Sexe columns because of encoding issues. but that shouldn't have any influence on the above.

Berend


From michel.arnaud at cirad.fr  Wed Jul 24 10:18:56 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 24 Jul 2013 10:18:56 +0200
Subject: [R] Change values in a dateframe
In-Reply-To: <4AB9302F-9708-49AB-85B7-F53DEC00D134@xs4all.nl>
References: <51EF76AA.7000803@cirad.fr>
	<4AB9302F-9708-49AB-85B7-F53DEC00D134@xs4all.nl>
Message-ID: <51EF8DF0.5000607@cirad.fr>

Thank you Berend
It is exactly what I wanted.
Michel
Le 24/07/2013 09:48, Berend Hasselman a ?crit :
> On 24-07-2013, at 08:39, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>
>> Hello
>>
>> I have the following problem :
>> The dataframe TEST has multiple lines for a same person because :
>> there are differents values of Nom or differents values of Prenom
>> but the values of Matricule or Sexe or Date.de.naissance are the same.
>>
>> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
>> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
>> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
>> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
>> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
>> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = "factor"),
>>     Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>     1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>     "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = "factor")), .Names = c("Matricule",
>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", row.names = c(NA,
>> -11L))
>>
>>
>> I would want to make homogeneous the information and would like built 2 dataframes :
>> df1 wich has the value of Nom and Prenom of the first lines of TEST when there are different values. The other values (Matricule or Sexe or Date.de.naissance) are unchanged
>>
>> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
>> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
>> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom = structure(c(6L,
>> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
>> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = "factor"),
>>     Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>     1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>     "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = "factor")), .Names = c("Matricule",
>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", row.names = c(NA,
>> -11L))
>>
>> df2 wich has the value of Nom and Prenom of the last lines of TEST when there are different values. The other values (Matricule or Sexe or Date.de.naissance) are unchanged.
>>
>> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
>> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
>> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>>     Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>>     5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>>     "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe = structure(c(1L,
>>     1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>>     "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
>>     2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>>     "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
>>     "30/03/1935"), class = "factor")), .Names = c("Matricule",
>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", row.names = c(NA,
>> -11L))
>>
> Something like this
>
> r1 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
>                      FUN=function(x) {x[,c("Nom","Prenom")] <- x[1,c("Nom","Prenom"),drop=TRUE];x})))
> rownames(r1) <- NULL
> r1
>
> r2 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
>                      FUN=function(x) {x[,c("Nom","Prenom")] <- x[nrow(x),c("Nom","Prenom"),drop=TRUE];x})))
> rownames(r2) <- NULL
> r2
>
> #> identical(r1,df1)
> #[1] TRUE
> #> identical(r2,df2)
> #[1] TRUE
>
> Note: I had to change the Prenom and Sexe columns because of encoding issues. but that shouldn't have any influence on the above.
>
> Berend
>
>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From s.wood at bath.ac.uk  Wed Jul 24 10:47:21 2013
From: s.wood at bath.ac.uk (Simon Wood)
Date: Wed, 24 Jul 2013 09:47:21 +0100
Subject: [R] Help with using unpenalised te smooth in negative binomial
 mgcv gam
In-Reply-To: <1374591761606-4672141.post@n4.nabble.com>
References: <1374591761606-4672141.post@n4.nabble.com>
Message-ID: <51EF9499.6020001@bath.ac.uk>

Hi Alice,

This is a bug in gam.side, which was assuming that any interaction 
smooth that needed identifiability constraints would be penalized. 
thanks for reporting it - fixed for next version.

In the meantime have you considered using `ti' terms instead of `te'? 
These provide a more satisfactory way of building
models with main effects and interactions. A ti smooth is basically 
built as an interaction with the main effects completely removed, and 
therefore does not require the imposition of further side conditions to 
enforce identifiability  (using `ti' would mean including the main 
effect of x3 in your model).

best,
Simon

On 23/07/13 16:02, alice.jones wrote:
> Hi,
>
> I have been trying to fit an un-penalised gam in mgcv (in order to get more
> reliable p-values for hypothesis testing), but I am struggling to get the
> model to fit sucessfully when I add in a te() interaction.  The model I am
> trying to fit is:
>          gam(count~ s(x1, bs = "ts", k = 4, fx = TRUE) +
>          s(x2, bs = "ts", k = 4, fx = TRUE) +
>          te(x2, x3, bs = c("ts", "cc"), fx = TRUE) +
>          log(offset(y)),
>          knots = list(x3=c(0,360)), family = negbin(c(1,10)))
>
> The error message I get is:
> "Error in sm[[i]]$S[[j]] : attempt to select less than one element"
>
> I can fit this model sucessfully if I don't specify the 'fx=TRUE' argument
> (i.e. I can sucesfully fit the penalised model).  It also works when I only
> include the two main terms x1 and x2, but do specify fx = TRUE, and it works
> fine when I only specify the main term x1 and the te smooth for x2 and x3
> and specify fx = TRUE (i.e. without a spearate specification of the main
> term, x2, that is also included in the interaction).  But.... when I have
> both main terms x1 and x2, as well as an interaction between x2 and x3,
> without penalisation, I get the error.
>
> I have played around with other data and with different covariate
> specification, but it seems that any time I specify a main term that is also
> included in the te interaction, within an un-penalised model, I get this
> same error message.
>
> Any help would be much appreciated, as I am trying to compare nested models
> (i.e. the full model with the interaction term against the model that just
> contains the two main terms).  I understand that the most appropriate way to
> do this is to use an un-penalised model for p-value estimation.
>
> Thanks,
>
> Alice
>
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Help-with-using-unpenalised-te-smooth-in-negative-binomial-mgcv-gam-tp4672141.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From harb at student.unimelb.edu.au  Wed Jul 24 11:05:26 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Wed, 24 Jul 2013 19:05:26 +1000
Subject: [R] Help to improve prediction from supervised mapping using
	kohonen package
Message-ID: <CAGYnQNT_RYHTFQXx_ByfcXLhJoXKNDDKajnq_=kH2kYmEW3e4g@mail.gmail.com>

I would really like some or any advice on how I can improve (or fix??)
the following analysis. I hope I have provided a completely runnable
code - it doesn't produce any errors for me.

The resulting plot at the end shows a pretty poor correlation (just
speaking visually here) to the test set. How can I improve the
performance of the mapping and prediction?

Here are some of the data (continuous, numerical):

> head(somdata)
   MEAS_TC        SP        LN        SN       GR     NEUT
1 2.780000 59.181090  33.74364  19.75361 66.57665 257.0368
2 1.490000 49.047750 184.14598 139.07980 54.75052 326.8001
3 1.490000 49.128902 183.58853 138.02768 55.54114 327.4739
4 2.201276 18.240331  19.20386  10.74748 62.04492 494.4161
5 2.201276 18.215522  19.18009  10.72446 61.87448 494.7409
6 1.276476  9.337769  14.16061  19.06902 14.99612 363.0020

Complete data set is at the following link if you fancy it:
https://gist.github.com/ottadini/6068259

The first variable is the dependent. I wish to train a som using this
data, and then be able to predict MEAS_TC using a new set of data with
missing values of MEAS_TC. Below I'm simply splitting the somdata into
a training and a testing set for evaluation purposes.

# ===== #
library(kohonen)

somdata <- read.csv("somdata.csv")

# Create test and training sets from data:
inTrain <- sample(nrow(somdata), nrow(somdata)*(2/3))
training <- somdata[inTrain, ]
testing <- somdata[-inTrain, ]

# Supervised kohonen map, where the dependent variable is MEAS_TC.
# Attempting to follow the examples in Wehrens and Buydens, 2007,
21(5), J Stat Soft.
# somdata[1] is the MEAS_TC variable
somX <- scale(training[-1])
somY <- training[[1]]  # Needs to return a vector
# Train the map (not sure this is how it should be done):
tc.xyf <- xyf(data=somX, Y=somY, xweight=0.5, grid=somgrid(6, 6,
"hexagonal"), contin=TRUE)

# Prediction with test set:
tc.xyf.prediction <- predict(tc.xyf, newdata = scale(testing[-1]))

# Basic plot:
x <- seq(nrow(testing))
plot(x, testing[, "MEAS_TC"], type="l", col="black", ylim=c(0, 3.5))
par(new=TRUE)
plot(x, tc.xyf.prediction$prediction, type="l", col="red", ylim=c(0, 3.5))

# Wow, that's terrible. Do I have something wrong?
# ===== #


From Thierry.ONKELINX at inbo.be  Wed Jul 24 11:25:51 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Wed, 24 Jul 2013 09:25:51 +0000
Subject: [R] Help to improve prediction from supervised mapping
	using	kohonen package
In-Reply-To: <CAGYnQNT_RYHTFQXx_ByfcXLhJoXKNDDKajnq_=kH2kYmEW3e4g@mail.gmail.com>
References: <CAGYnQNT_RYHTFQXx_ByfcXLhJoXKNDDKajnq_=kH2kYmEW3e4g@mail.gmail.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD314774@inbomail.inbo.be>

Try rescaling your data prior to splitting it up into a training and test set. Otherwise you end up with two different ways of scaling.

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens Ben Harrison
Verzonden: woensdag 24 juli 2013 11:05
Aan: r-help at r-project.org
Onderwerp: [R] Help to improve prediction from supervised mapping using kohonen package

I would really like some or any advice on how I can improve (or fix??) the following analysis. I hope I have provided a completely runnable code - it doesn't produce any errors for me.

The resulting plot at the end shows a pretty poor correlation (just speaking visually here) to the test set. How can I improve the performance of the mapping and prediction?

Here are some of the data (continuous, numerical):

> head(somdata)
   MEAS_TC        SP        LN        SN       GR     NEUT
1 2.780000 59.181090  33.74364  19.75361 66.57665 257.0368
2 1.490000 49.047750 184.14598 139.07980 54.75052 326.8001
3 1.490000 49.128902 183.58853 138.02768 55.54114 327.4739
4 2.201276 18.240331  19.20386  10.74748 62.04492 494.4161
5 2.201276 18.215522  19.18009  10.72446 61.87448 494.7409
6 1.276476  9.337769  14.16061  19.06902 14.99612 363.0020

Complete data set is at the following link if you fancy it:
https://gist.github.com/ottadini/6068259

The first variable is the dependent. I wish to train a som using this data, and then be able to predict MEAS_TC using a new set of data with missing values of MEAS_TC. Below I'm simply splitting the somdata into a training and a testing set for evaluation purposes.

# ===== #
library(kohonen)

somdata <- read.csv("somdata.csv")

# Create test and training sets from data:
inTrain <- sample(nrow(somdata), nrow(somdata)*(2/3)) training <- somdata[inTrain, ] testing <- somdata[-inTrain, ]

# Supervised kohonen map, where the dependent variable is MEAS_TC.
# Attempting to follow the examples in Wehrens and Buydens, 2007, 21(5), J Stat Soft.
# somdata[1] is the MEAS_TC variable
somX <- scale(training[-1])
somY <- training[[1]]  # Needs to return a vector # Train the map (not sure this is how it should be done):
tc.xyf <- xyf(data=somX, Y=somY, xweight=0.5, grid=somgrid(6, 6, "hexagonal"), contin=TRUE)

# Prediction with test set:
tc.xyf.prediction <- predict(tc.xyf, newdata = scale(testing[-1]))

# Basic plot:
x <- seq(nrow(testing))
plot(x, testing[, "MEAS_TC"], type="l", col="black", ylim=c(0, 3.5))
par(new=TRUE)
plot(x, tc.xyf.prediction$prediction, type="l", col="red", ylim=c(0, 3.5))

# Wow, that's terrible. Do I have something wrong?
# ===== #

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From wewolski at gmail.com  Wed Jul 24 12:00:25 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 24 Jul 2013 12:00:25 +0200
Subject: [R] function 2 convert matrix to long-format?
Message-ID: <CAAjnpdgyv4ESwOgR5ddGk8NzQhMCgO-Yz4MXpAcDt0M3uyjK2Q@mail.gmail.com>

I would like to convert this (output of tapply)
, , minus

       B6      S9
T0 0.1416 0.12235
T1 0.1049 0.11890
T2 0.1328 0.15510

, , plus

        B6      S9
T0 0.14225 0.16875
T1 0.09295 0.09900
T2 0.13350 0.14560

to long-format :

T0 B6 minus 0.1416
T0 S9 minus 0.12235
T0 B6 plus 0.14225
T0 S9 plus 0.16875
....
...


whats the default way in R?

best




--
Witold Eryk Wolski


From wewolski at gmail.com  Wed Jul 24 12:03:22 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 24 Jul 2013 12:03:22 +0200
Subject: [R] function 2 convert matrix to long-format?
In-Reply-To: <CAAjnpdgyv4ESwOgR5ddGk8NzQhMCgO-Yz4MXpAcDt0M3uyjK2Q@mail.gmail.com>
References: <CAAjnpdgyv4ESwOgR5ddGk8NzQhMCgO-Yz4MXpAcDt0M3uyjK2Q@mail.gmail.com>
Message-ID: <CAAjnpdiCcuuBObL_sF2n5tkofCDM_eL62iacTn67Y=+TZLUTug@mail.gmail.com>

RECALL : found the answer:
use aggregate instead of tapply

thx

On 24 July 2013 12:00, Witold E Wolski <wewolski at gmail.com> wrote:
> I would like to convert this (output of tapply)
> , , minus
>
>        B6      S9
> T0 0.1416 0.12235
> T1 0.1049 0.11890
> T2 0.1328 0.15510
>
> , , plus
>
>         B6      S9
> T0 0.14225 0.16875
> T1 0.09295 0.09900
> T2 0.13350 0.14560
>
> to long-format :
>
> T0 B6 minus 0.1416
> T0 S9 minus 0.12235
> T0 B6 plus 0.14225
> T0 S9 plus 0.16875
> ....
> ...
>
>
> whats the default way in R?
>
> best
>
>
>
>
> --
> Witold Eryk Wolski



-- 
Witold Eryk Wolski


From egimenez at antares-consulting.com  Wed Jul 24 11:32:49 2013
From: egimenez at antares-consulting.com (=?iso-8859-1?Q?Emmanuel_Gim=E9nez?=)
Date: Wed, 24 Jul 2013 11:32:49 +0200
Subject: [R] Adjusting published survival functions
Message-ID: <78BE7FAC528458499129DBA4BFD1059D0B5F9B7DF4@antares-ex.antares.internal>

Dear,

I would like to know how to adjust survival functions in R and after reading lots of posts I don't have it clear. I downloaded the fitdistrplus package but it seems me like it only fits univariately the functions.
Being specific , having a survival curve which corresponds to a set of data such as:
"months"	"survival"
1	0,9
2	0,85
3	0,83
3,5	0,8
4,2	0,75
5	0,43
7	0,4
9	0,3
11	0,3
13	0,3

i'm searching the parameters that fit with the curve with loglogistic, lognormal and weibull, and then, comparing the AICs of the adjustments, to select the best fit curve.
Could you please help me?

Thank you in advance,

Manu

From mohitdhingras at gmail.com  Wed Jul 24 13:14:38 2013
From: mohitdhingras at gmail.com (Mohit Dhingra)
Date: Wed, 24 Jul 2013 16:44:38 +0530
Subject: [R] Y label doesn't show up on printing files
In-Reply-To: <DE1C512A-D9F0-4B53-9103-827C6378AD47@comcast.net>
References: <CAGkgU9WqQnRXaoqCMjcaHbAa0WGPn4cfKENQsKQ35jePZssPoQ@mail.gmail.com>
	<DE1C512A-D9F0-4B53-9103-827C6378AD47@comcast.net>
Message-ID: <CAGkgU9WQN4JOpxU=qbJbL9T6i8qqa9QJCGu9xvH+bwdd-EVvFg@mail.gmail.com>

Hi David,

Thanks for your reply! How do I exactly find it out and solve? Also,
the problem is not reproducible every time :-/
----------------------------
Thanks & Regards
Mohit Dhingra
+919611190435


On 22 July 2013 23:55, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Jul 22, 2013, at 3:17 AM, Mohit Dhingra wrote:
>
>> Hello,
>>
>> I'm using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" .
>>
>> System info: Linux ubuntu 3.5.0-36-generic #57~precise1-Ubuntu SMP Thu
>> Jun 20 18:21:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux.
>>
>> When I plot something, y label does show up on the pop up image.
>> plot (x, rtimel[,2] , xlab="Memory Allocated (in MB)", ylab="Response
>> Time (in ms)", type="l", col="black", ylim=c(0,m) )
>>
>> But when I try to save it using
>> dev.copy(pdf,'response_time_with_memory_direct.pdf')
>> dev.off()
>>
>> Y-label doesn't get printed on the pdf file. Can someone please help?
>
> Perhaps a difficulty with the fonts in your R installation being different than the fonts in your pdf viewer?
>
> --
>
> David Winsemius
> Alameda, CA, USA
>


From harb at student.unimelb.edu.au  Wed Jul 24 13:20:28 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Wed, 24 Jul 2013 21:20:28 +1000
Subject: [R] Help to improve prediction from supervised mapping using
 kohonen package
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427CD314774@inbomail.inbo.be>
References: <CAGYnQNT_RYHTFQXx_ByfcXLhJoXKNDDKajnq_=kH2kYmEW3e4g@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427CD314774@inbomail.inbo.be>
Message-ID: <CAGYnQNTn2_PCc2k-ehf-knT+zZA6PxADoG4L39k9a5vgUVLfjA@mail.gmail.com>

On 24 July 2013 19:25, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> Try rescaling your data prior to splitting it up into a training and test set. Otherwise you end up with two different ways of scaling.


Thanks, good point.
I have adjusted the code, however with no visible improvement.

Also, I want to be able to revert the scaling operation to compare
data to predicted values. I tried this:
meas.tc <- testing[, "MEAS_TC"] * attr(testing, 'scaled:scale') +
attr(testing, 'scaled:center')
predicted.tc <- tc.xyf.prediction$prediction * attr(testing,
'scaled:scale') + attr(testing, 'scaled:center')

but I get warnings, and values that are very wrong:

Warning messages:
1: In testing[, "MEAS_TC"] * attr(testing, "scaled:scale") :
  longer object length is not a multiple of shorter object length
2: In testing[, "MEAS_TC"] * attr(testing, "scaled:scale") + attr(testing,  :
  longer object length is not a multiple of shorter object length


Adjusted code:
(now also in a gist: https://gist.github.com/ottadini/6069736)

# ===== #
library(kohonen)

somdata <- read.csv("somdata.csv")

# Create SCALED test and training sets from data:
inTrain <- sample(nrow(somdata), nrow(somdata)*(2/3))
training <- scale(somdata[inTrain, ])
testing <- scale(somdata[-inTrain, ],
                 center = attr(training, "scaled:center"),
                 scale = attr(training, "scaled:scale"))

# Supervised kohonen map, where the dependent variable is MEAS_TC.
# Attempting to follow the examples in Wehrens and Buydens, 2007,
21(5), J Stat Soft.
# somdata[1] is the MEAS_TC variable
somX <- training[, -1]
somY <- training[, 1]
tc.xyf <- xyf(data=somX, Y=somY, xweight=0.5, grid=somgrid(6, 6,
"hexagonal"), contin=TRUE)

# Prediction with test set:
tc.xyf.prediction <- predict(tc.xyf, newdata=testing[, -1])

# Basic plot:
x <- seq(nrow(testing))
plot(x, testing[, "MEAS_TC"], type="l", col="black", ylim=c(-2, 2))
par(new=TRUE)
plot(x, tc.xyf.prediction$prediction, type="l", col="red", ylim=c(-2, 2))


# Still terrible. Do I have something wrong in scaling?

# ===== #


From harb at student.unimelb.edu.au  Wed Jul 24 13:32:40 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Wed, 24 Jul 2013 21:32:40 +1000
Subject: [R] Help to improve prediction from supervised mapping using
 kohonen package
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427CD314774@inbomail.inbo.be>
References: <CAGYnQNT_RYHTFQXx_ByfcXLhJoXKNDDKajnq_=kH2kYmEW3e4g@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427CD314774@inbomail.inbo.be>
Message-ID: <CAGYnQNSq3iaNtBUyN8+yG+3zyMAyKykHp4+FkXgSgG4r+WLcCg@mail.gmail.com>

On 24 July 2013 19:25, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
> Try rescaling your data prior to splitting it up into a training and test set. Otherwise you end up with two different ways of scaling.
>

I was mistaken, there is a visible improvement!

I still cannot understand how I can sensibly revert the scaling of the values.

# ===== #
meas.tc <- testing[, "MEAS_TC"] * attr(testing, 'scaled:scale') +
attr(testing, 'scaled:center')
predicted.tc <- tc.xyf.prediction$prediction * attr(testing,
'scaled:scale') + attr(testing, 'scaled:center')
# ===== #

but I get warnings, and values that are very wrong:

Warning messages:
1: In testing[, "MEAS_TC"] * attr(testing, "scaled:scale") :
  longer object length is not a multiple of shorter object length
2: In testing[, "MEAS_TC"] * attr(testing, "scaled:scale") + attr(testing,  :
  longer object length is not a multiple of shorter object length

The original values for somdata["MEAS_TC"] are around 0.5 to 3, but
the unscaled values are about -170 to 700.


From marc_schwartz at me.com  Wed Jul 24 14:27:56 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 24 Jul 2013 07:27:56 -0500
Subject: [R] [R-pkgs] WriteXLS Version 3.0.0 Released
In-Reply-To: <1374619209185-4672180.post@n4.nabble.com>
References: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>
	<1374619209185-4672180.post@n4.nabble.com>
Message-ID: <533E5385-BCB9-4F8E-9443-BC9217622EA3@me.com>

On Jul 23, 2013, at 5:40 PM, cognizio <geoff at uyleman.com> wrote:

> Great summary! It works great without the heavy PERL library. I am running
> the YAML package I thought I needed to support WRITEXLS. Do I need it or is
> YAML not a dependency? 
> 
> Other question is on your last point: 'WRITEXLS COMMENT:' now shows up
> across the first row of the data output in the XLS. How do I modify these
> values? 
> 
> Thx!
> 
> Cog  


Hi,

There is no direct dependency on YAML.

The comments that appear in the first row in Excel are based upon the use of the ?comment function, which adds a 'comment' attribute to the columns of the data frame. If that attribute is present on one or more columns, an Excel comment will be created for the columns that have it.

There is an example of this in ?WriteXLS:

    # Example using comment()
    # Commented cells with have a small red triangle in the
    # upper right hand corner of the cell. Click on the cell
    # or place the cursor over the cell to see the pop-up
    # containing the comment text.
    # Create an XLSX (Excel 2007) file
    # Adjust the column widths
    # Bold the header row
    comment(iris$Sepal.Length) <- "Length of the sepals (cm)"
    comment(iris$Sepal.Width) <- "Width of the sepals (cm)"
    comment(iris$Petal.Length) <- "Length of the petals (cm)"
    comment(iris$Petal.Width) <- "Width of the petals (cm)"
    comment(iris$Species) <- "Species of the flowers"
    WriteXLS("iris", "iriscomments.xlsx", AdjWidth = TRUE, BoldHeaderRow = TRUE)


The 'comment' attribute is not seen when printing the data frame, but can be seen when using ?str to print the structure of the data frame:

> str(iris)
'data.frame':	150 obs. of  5 variables:
 $ Sepal.Length: atomic  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
  ..- attr(*, "comment")= chr "Length of the sepals (cm)"
 $ Sepal.Width : atomic  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
  ..- attr(*, "comment")= chr "Width of the sepals (cm)"
 $ Petal.Length: atomic  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
  ..- attr(*, "comment")= chr "Length of the petals (cm)"
 $ Petal.Width : atomic  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
  ..- attr(*, "comment")= chr "Width of the petals (cm)"
 $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1 1 1 1 1 ...
  ..- attr(*, "comment")= chr "Species of the flowers"



Regards,

Marc Schwartz


From sundas.javad12 at imperial.ac.uk  Wed Jul 24 12:18:03 2013
From: sundas.javad12 at imperial.ac.uk (Javad, Sundas)
Date: Wed, 24 Jul 2013 10:18:03 +0000
Subject: [R] Network analysis
Message-ID: <92666BC4218C574F97B56361E75EE89124A672C4@icexch-m6.ic.ac.uk>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/e39754c5/attachment.pl>

From gallrein at psychologie.tu-dresden.de  Wed Jul 24 12:25:35 2013
From: gallrein at psychologie.tu-dresden.de (Anne-Marie B. Gallrein)
Date: Wed, 24 Jul 2013 12:25:35 +0200
Subject: [R] Function, that assigns two vectors to each other
Message-ID: <51EFAB9F.4040604@psychologie.tu-dresden.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/0ca72292/attachment.pl>

From mrahmankufmrt at gmail.com  Wed Jul 24 13:00:42 2013
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Wed, 24 Jul 2013 19:00:42 +0800
Subject: [R] Paternity data analysis problem
Message-ID: <CAGNSkSm2C_cnv4HU3-u84OJaTD5JHwHZ1WMgZgCm2KK=2YWBGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/dc5edcfb/attachment.pl>

From jrkrideau at inbox.com  Wed Jul 24 14:47:26 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 24 Jul 2013 04:47:26 -0800
Subject: [R] Function, that assigns two vectors to each other
In-Reply-To: <51EFAB9F.4040604@psychologie.tu-dresden.de>
Message-ID: <64007B3443B.00000E62jrkrideau@inbox.com>

Welcome  to R-help
it is a bit hard to see exactly what you want without data. Rest of the explanation looks good though it appears you may have sent this in HTML and the list asks for text.  It strips out the html and we lose any html format.

Can I suggest reading these https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example 

and then getting back to use with some data.  The best way to provide data , as is described in the above links is to use dput()  (type ?dput for help ) and then just copy and paste the results into the mail.



John Kane
Kingston ON Canada


> -----Original Message-----
> From: gallrein at psychologie.tu-dresden.de
> Sent: Wed, 24 Jul 2013 12:25:35 +0200
> To: r-help at r-project.org
> Subject: [R] Function, that assigns two vectors to each other
> 
> Hey guys,
> 
> In my data setv ("KD") I have 4 columns
> ("Punkte.AG1","Punkte.AG2","Punkte.AG3","Punkte.WI") I'm interested in.
> 
> These columns contain the participants' scores of a specific task.
> 
> I computed the percentiles of the columns using this code:
> 
> pe<-apply(X=KD[,c("Punkte.AG1","Punkte.AG2","Punkte.AG3","Punkte.WI")],
> 
> MARGIN=2,
> 
> FUN=quantile,
> 
> probs=seq(0,1,by=.01),
> 
> na.rm=TRUE)
> 
> round(pe,0)
> 
> 
> This is the output (to the 20^th percentile):
> 
> pe
> 
> Punkte.AG1 Punkte.AG2 Punkte.AG3 Punkte.WI
> 
> 0%6319
> 
> 1%74311
> 
> 2%86312
> 
> 3%87412
> 
> 4%97512
> 
> 5%98512
> 
> 6%108512
> 
> 7%108512
> 
> 8%108614
> 
> 9%109614
> 
> 10%109615
> 
> 11%1010715
> 
> 12%1010715
> 
> 13%1110715
> 
> 14%1110816
> 
> 15%1110816
> 
> 16%1110816
> 
> 17%1110816
> 
> 18%1110816
> 
> 19%1210816
> 
> 20%1210816
> 
> So now I know, what percentile a person has, when she/ he scored a
> certain amount of points (e.g. 6 points in "Punkte.AG1" = 0%).
> 
> Here is my problem:
> 
> I now want to write a function that assigns the percentile to the score
> (for each task) and saves it in a new variable.
> 
> So every person that scored 10 in "Punkte.AG1" gets a "12" in the new
> variable "Percentile.AG1".
> 
> Every person that scored 6 in "Punkte.AG1" gets a "6" in the new
> variable "Percentile.AG1".
> 
> The same thing should be done for the other tasks.
> 
> 
> I new to R, so I don't have any clue, how to solve that. It would be
> awesome, if you would know how to handle that.
> 
> Thanks a lot!
> 
> Anne
> 
> --
> M. Sc. Anne-Marie B. Gallrein
> Technische Universitdt Dresden
> Institut f|r Klinische, Diagnostische und Differentielle Psychologie
> Diagnostik und Intervention
> 01062 Dresden
> Tel. +49 351 463-34004
> gallrein at psychologie.tu-dresden.de
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From jrkrideau at inbox.com  Wed Jul 24 14:48:51 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 24 Jul 2013 04:48:51 -0800
Subject: [R] Paternity data analysis problem
In-Reply-To: <CAGNSkSm2C_cnv4HU3-u84OJaTD5JHwHZ1WMgZgCm2KK=2YWBGQ@mail.gmail.com>
Message-ID: <6403A5C133B.00000E67jrkrideau@inbox.com>

Please use dput() to supply data and send in text format not html.

Thanks

John Kane
Kingston ON Canada


> -----Original Message-----
> From: mrahmankufmrt at gmail.com
> Sent: Wed, 24 Jul 2013 19:00:42 +0800
> To: r-help at r-project.org, r-help-request at r-project.org,
> r-help-owner at r-project.org
> Subject: [R] Paternity data analysis problem
> 
> Dear R-helps,
> 
> I did an experiment with FAs ['High' and 'Zero'(no w-3) quality; n=24 for
> each group]. Then I did AI to see their sperm competitiveness based on
> their paternity performance. My data is as below where Fish ID- Blind ID
> for each fish; Group ID- Dietary group ID; Diet quality - High=1, zero=0;
> Babies for paternity- total no. of babies got from females; Success -
> Babies shared/paterned by focal male; Failure - Babies shared/paterned by
> competitor, Proportion - Success/(Success+Failure).
> 
> Fish ID
> 
> Group ID
> 
> Diet quality
> 
> Babies for paternity
> 
> Success
> 
> Failure
> 
> Proportion
> 
> 1
> 
> High
> 
> 1
> 
> 9
> 
> 5
> 
> 4
> 
> 0.556
> 
> 12
> 
> High
> 
> 1
> 
> 7
> 
> 5
> 
> 2
> 
> 0.714
> 
> 15
> 
> High
> 
> 1
> 
> 7
> 
> 4
> 
> 3
> 
> 0.571
> 
> 20
> 
> High
> 
> 1
> 
> 6
> 
> 5
> 
> 1
> 
> 0.833
> 
> 32
> 
> High
> 
> 1
> 
> 7
> 
> 2
> 
> 5
> 
> 0.286
> 
> 37
> 
> High
> 
> 1
> 
> 3
> 
> 1
> 
> 2
> 
> 0.333
> 
> 48
> 
> High
> 
> 1
> 
> 4
> 
> 1
> 
> 3
> 
> 0.25
> 
> 53
> 
> High
> 
> 1
> 
> 10
> 
> 0
> 
> 10
> 
> 0
> 
> 65
> 
> High
> 
> 1
> 
> 3
> 
> 3
> 
> 0
> 
> 1
> 
> 70
> 
> High
> 
> 1
> 
> 4
> 
> 4
> 
> 0
> 
> 1
> 
> 77
> 
> High
> 
> 1
> 
> 7
> 
> 2
> 
> 5
> 
> 0.286
> 
> 82
> 
> High
> 
> 1
> 
> 6
> 
> 6
> 
> 0
> 
> 1
> 
> 96
> 
> High
> 
> 1
> 
> 8
> 
> 2
> 
> 6
> 
> 0.25
> 
> 104
> 
> High
> 
> 1
> 
> 12
> 
> 10
> 
> 2
> 
> 0.833
> 
> 111
> 
> High
> 
> 1
> 
> 4
> 
> 3
> 
> 1
> 
> 0.75
> 
> 123
> 
> High
> 
> 1
> 
> 6
> 
> 5
> 
> 1
> 
> 0.833
> 
> 128
> 
> High
> 
> 1
> 
> 8
> 
> 8
> 
> 0
> 
> 1
> 
> 133
> 
> High
> 
> 1
> 
> 6
> 
> 5
> 
> 1
> 
> 0.833
> 
> 144
> 
> High
> 
> 1
> 
> 12
> 
> 6
> 
> 6
> 
> 0.5
> 
> 152
> 
> High
> 
> 1
> 
> 13
> 
> 11
> 
> 2
> 
> 0.846
> 
> 159
> 
> High
> 
> 1
> 
> 8
> 
> 1
> 
> 7
> 
> 0.125
> 
> 164
> 
> High
> 
> 1
> 
> 4
> 
> 1
> 
> 3
> 
> 0.25
> 
> 169
> 
> High
> 
> 1
> 
> 6
> 
> 2
> 
> 4
> 
> 0.333
> 
> 5
> 
> Zero
> 
> 0
> 
> 9
> 
> 4
> 
> 5
> 
> 0.444
> 
> 10
> 
> Zero
> 
> 0
> 
> 7
> 
> 2
> 
> 5
> 
> 0.286
> 
> 17
> 
> Zero
> 
> 0
> 
> 7
> 
> 3
> 
> 4
> 
> 0.429
> 
> 22
> 
> Zero
> 
> 0
> 
> 6
> 
> 1
> 
> 5
> 
> 0.167
> 
> 36
> 
> Zero
> 
> 0
> 
> 7
> 
> 5
> 
> 2
> 
> 0.714
> 
> 39
> 
> Zero
> 
> 0
> 
> 3
> 
> 2
> 
> 1
> 
> 0.667
> 
> 44
> 
> Zero
> 
> 0
> 
> 4
> 
> 3
> 
> 1
> 
> 0.75
> 
> 51
> 
> Zero
> 
> 0
> 
> 10
> 
> 10
> 
> 0
> 
> 1
> 
> 63
> 
> Zero
> 
> 0
> 
> 3
> 
> 0
> 
> 3
> 
> 0
> 
> 68
> 
> Zero
> 
> 0
> 
> 4
> 
> 0
> 
> 4
> 
> 0
> 
> 73
> 
> Zero
> 
> 0
> 
> 7
> 
> 5
> 
> 2
> 
> 0.714
> 
> 84
> 
> Zero
> 
> 0
> 
> 6
> 
> 0
> 
> 6
> 
> 0
> 
> 94
> 
> Zero
> 
> 0
> 
> 8
> 
> 6
> 
> 2
> 
> 0.75
> 
> 106
> 
> Zero
> 
> 0
> 
> 12
> 
> 2
> 
> 10
> 
> 0.167
> 
> 109
> 
> Zero
> 
> 0
> 
> 4
> 
> 1
> 
> 3
> 
> 0.25
> 
> 121
> 
> Zero
> 
> 0
> 
> 6
> 
> 1
> 
> 5
> 
> 0.167
> 
> 132
> 
> Zero
> 
> 0
> 
> 8
> 
> 0
> 
> 8
> 
> 0
> 
> 137
> 
> Zero
> 
> 0
> 
> 6
> 
> 1
> 
> 5
> 
> 0.167
> 
> 142
> 
> Zero
> 
> 0
> 
> 12
> 
> 6
> 
> 6
> 
> 0.5
> 
> 154
> 
> Zero
> 
> 0
> 
> 13
> 
> 2
> 
> 11
> 
> 0.154
> 
> 157
> 
> Zero
> 
> 0
> 
> 8
> 
> 7
> 
> 1
> 
> 0.875
> 
> 168
> 
> Zero
> 
> 0
> 
> 4
> 
> 3
> 
> 1
> 
> 0.75
> 
> 173
> 
> Zero
> 
> 0
> 
> 6
> 
> 4
> 
> 2
> 
> 0.667
> 
> 
> 
> I ran the following codes to have my results:
> 
> ###Proportion estimate:
> p<-Data$Success/(Data$Success+Data$Failure)
> plot(Data$Group.ID,p,ylab="Proportion of success")
> 
> ###Response variable:
> y<-cbind(Data$Success,Data$Failure)
> model1 <- glm(y~Diet.quality, data=Data, family=binomial)
> summary(model1)
> plot(model1)# gives Q-Q plots
> ###The residual deviance is 152.66  on 44 d.f. so the model is quite
> badly
> overdispersed:
> #152.66/44 where The overdispersion factor is almost 3.46 (unbelievable).
> 
> ## model with logit link functions and weights:
> model2<-glm(cbind(Success,Failure)~Group.ID,data=Data,
> family="binomial"(link="logit"),weights=Success+Failure)
> summary(model2)
> ###The residual deviance is 1196.1  on 46 d.f. so the model is quite
> badly
> overdispersed:
> #1192.1/44 where The overdispersion factor is almost 27.09
> (unbelievable).
> 
> #The simplest way to take this into account is to use what is called an
> #?empirical scale parameter? to reflect the fact that the errors are not
> #binomial as we assumed, but were larger than this (overdispersed) by a
> factor of 3.38.
> 
> model3<-glm(y ~ Group.ID,data=Data,family="quasibinomial")
> summary(model3)
> 
> ###Note that the ratio of the residual deviance and the degrees of
> freedom
> is still
> #larger than 1, but that is no longer a problem as we now allow for
> overdispersion.
> 
>  Each models gives me different results with overdispersion. So, can
> anyone
> help me to give me some valuable suggesions to solve this problem. I'll
> really appreciate your kind assistance and will be grateful to you
> forever.
> 
> With kind regards,
> 
> Moshi
> mrahmankufmrt at gmail.com
> 
> --
> MD. MOSHIUR RAHMAN
> PhD Candidate
> School of Animal Biology/Zoology (M092)
> University of Western Australia
> 35 Stirling Hwy, Crawley, WA, 6009
> Australia.
> Mob.: 061-425205507
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Wed Jul 24 14:57:38 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 24 Jul 2013 04:57:38 -0800
Subject: [R] Network analysis
In-Reply-To: <92666BC4218C574F97B56361E75EE89124A672C4@icexch-m6.ic.ac.uk>
Message-ID: <641747A4E17.00000E84jrkrideau@inbox.com>

Hi Sarah,
It would help to know what the data looks like now and to have some idea of what you have already done.  Here are a couple of links what suggest how to frame a question for  the R-help list

And here is an article using network analysis. No idea if the techniques are at all relevant but there is a link to the author's code. And it's a fun read.
http://kieranhealy.org/blog/archives/2013/06/09/using-metadata-to-find-paul-revere/

John Kane
Kingston ON Canada


> -----Original Message-----
> From: sundas.javad12 at imperial.ac.uk
> Sent: Wed, 24 Jul 2013 10:18:03 +0000
> To: r-help at r-project.org
> Subject: [R] Network analysis
> 
> 
> 
> Hi,
> 
> I am trying to do network analysis for my data-set but facing few
> difficulties. Would be very grateful if could get some help from anyone.
> 
> My dataset has 5 columns and 110 rows and I am trying to build link which
> rows are more likely to be connected to the columns. I want to use
> Jaccard similarity coefficient as the weight for my network.   I am doing
> this in igraph library so far but would be happy to use any other library
> package.
> 
> I am not sure how to import my dataset into R for network analysis
> purposes and I also can't seem to add weights to my network and would be
> very grateful if someone could guide me as to how can I do it in R.
> 
> Thanks
> Sarah
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE ONLINE PHOTOSHARING - Share your photos online with your friends and family!
Visit http://www.inbox.com/photosharing to find out more!


From julian.bothe at elitepartner.de  Wed Jul 24 15:45:27 2013
From: julian.bothe at elitepartner.de (julian.bothe at elitepartner.de)
Date: Wed, 24 Jul 2013 15:45:27 +0200 (CEST)
Subject: [R] prediction survival curves for coxph-models;
	how to extract the right strata per individual
Message-ID: <6e26b18b.00000e10.00000002@FIW7PC12.ELITEMEDIANET>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/2b4c1457/attachment.pl>

From jose at memo2.nl  Wed Jul 24 16:07:33 2013
From: jose at memo2.nl (=?ISO-8859-1?Q?Jos=E9_Verhoeven?=)
Date: Wed, 24 Jul 2013 16:07:33 +0200
Subject: [R] Fwd: Why does impulse response function of VAR starts at zero
 and not at one?
In-Reply-To: <CAEaKQwW_u9ettAUw9r1QyH4np-FhxnJy6S5d=O8mLCuK_TkAMg@mail.gmail.com>
References: <CAEaKQwW_u9ettAUw9r1QyH4np-FhxnJy6S5d=O8mLCuK_TkAMg@mail.gmail.com>
Message-ID: <CAEaKQwX2psjJZBALRd_06SK-NjYB7XxW0N3S_cpgtg29a6pAQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/8fffd61a/attachment.pl>

From Jose.Iparraguirre at ageuk.org.uk  Wed Jul 24 16:13:51 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Wed, 24 Jul 2013 14:13:51 +0000
Subject: [R] Adjusting published survival functions
In-Reply-To: <78BE7FAC528458499129DBA4BFD1059D0B5F9B7DF4@antares-ex.antares.internal>
References: <78BE7FAC528458499129DBA4BFD1059D0B5F9B7DF4@antares-ex.antares.internal>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2034D32@AGEPXMB006.uk.age.local>

Have you tried the packages 'survival' and 'eha' yet? You can use the survreg() function in the former to compare between different models.

Have a look at this tutorial: http://www.openintro.org/stat/surv.php (a copy can also be found here: http://anson.ucdavis.edu/~hiwang/teaching/10fall/R_tutorial%201.pdf)

Here's the task view to learn what's available in R to run survival analysis: http://cran.r-project.org/web/views/Survival.html 

Hope this helps.

Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK




-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Emmanuel Gim?nez
Sent: 24 July 2013 10:33
To: r-help at r-project.org
Subject: [R] Adjusting published survival functions

Dear,

I would like to know how to adjust survival functions in R and after reading lots of posts I don't have it clear. I downloaded the fitdistrplus package but it seems me like it only fits univariately the functions.
Being specific , having a survival curve which corresponds to a set of data such as:
"months"	"survival"
1	0,9
2	0,85
3	0,83
3,5	0,8
4,2	0,75
5	0,43
7	0,4
9	0,3
11	0,3
13	0,3

i'm searching the parameters that fit with the curve with loglogistic, lognormal and weibull, and then, comparing the AICs of the adjustments, to select the best fit curve.
Could you please help me?

Thank you in advance,

Manu
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From michel.arnaud at cirad.fr  Wed Jul 24 16:31:49 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Wed, 24 Jul 2013 16:31:49 +0200
Subject: [R] Change values in a dateframe
In-Reply-To: <1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <51EF76AA.7000803@cirad.fr>
	<1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <51EFE555.7040104@cirad.fr>

Hi Arun,
Merci ? toi
Bien amicalement
Michel
Le 24/07/2013 15:29, arun a ?crit :
> Hi Michel,
> You could try:
>
>
> df1New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=min)),])
> row.names(df1New)<-1:nrow(df1New)
> df2New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=max)),])
> row.names(df2New)<-1:nrow(df2New)
>   identical(df1New,df1)
> #[1] TRUE
>   identical(df2New,df2)
> #[1] TRUE
> A.K.
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Wednesday, July 24, 2013 2:39 AM
> Subject: [R] Change values in a dateframe
>
> Hello
>
> I have the following problem :
> The dataframe TEST has multiple lines for a same person because :
> there are differents values of Nom or differents values of Prenom
> but the values of Matricule or Sexe or Date.de.naissance are the same.
>
> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
> "factor"),
>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
> "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
> row.names = c(NA,
> -11L))
>
>
> I would want to make homogeneous the information and would like built 2
> dataframes :
> df1 wich has the value of Nom and Prenom of the first lines of TEST when
> there are different values. The other values (Matricule or Sexe or
> Date.de.naissance) are unchanged
>
> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom =
> structure(c(6L,
> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
> "factor"),
>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
> "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
> row.names = c(NA,
> -11L))
>
> df2 wich has the value of Nom and Prenom of the last lines of TEST when
> there are different values. The other values (Matricule or Sexe or
> Date.de.naissance) are unchanged.
>
> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>       Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>       5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>       "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe =
> structure(c(1L,
>       1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>       "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
>       2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>       "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
>       "30/03/1935"), class = "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
> row.names = c(NA,
> -11L))
>
> Thank for your helps
> Michel
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From rmh at temple.edu  Wed Jul 24 17:20:14 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 24 Jul 2013 11:20:14 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <20130724060747.GC24293@slingshot.co.nz>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
Message-ID: <CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/95896f9c/attachment.pl>

From marc_schwartz at me.com  Wed Jul 24 17:36:45 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 24 Jul 2013 10:36:45 -0500
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
Message-ID: <C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>

Rich,

You are missing some options in the call to postscript() below. It needs to be:

  postscript(file = "file.eps", width = x, height = y,
             horizontal = FALSE, onefile = FALSE, paper = "special")

The first line needs to have values for 'x' and 'y' for the width and height of the image, as they default to 0.

The second line of 3 options are all critical to producing an EPS file, as opposed to a PS file. This is described in the 4th paragraph of the Details section of ?postscript.

If you import that file into any of the MS Office products (typically also for OpenOffce, LibreOffice, etc.), a PNG preview image will be created during import. It is the PNG bitmapped image that you can see when displaying the EPS file in the document, hence the degradation in quality. Some years ago, all you would see is a rectangular box with an "X" across it, as a placeholder for the imported image. 

Only if you then print the Office file using a Postscript printer driver, will you see the actual vector based EPS image. The target of that printing operation could be a printer for hard copy, a PS or a PDF file. MS Office does not support the rendering of the EPS image directly.

If you are operating on Windows, as opposed to Linux or OSX, typically EMF/WMF files are the easiest way to go in terms of sticking R plots into an Office file, as they are also vector based images, but are effectively Windows only.

Regards,

Marc Schwartz


On Jul 24, 2013, at 10:20 AM, Richard M. Heiberger <rmh at temple.edu> wrote:

> png("png300.png", res=300, width=2880, height=1440)
> 
> gives good behavior.  Thank you.  This will become my standard for export
> to powerpoint.
> 
> postscript(file='file.eps', onefile=FALSE)
> produces eps files that powerpoint rejects, even though ghostview is
> satisfied.
> 
> Rich
> 
> 
> On Wed, Jul 24, 2013 at 2:07 AM, Patrick Connolly <
> p_connolly at slingshot.co.nz> wrote:
> 
>> On Tue, 23-Jul-2013 at 10:23PM -0400, Richard M. Heiberger wrote:
>> 
>> |> I have colleagues who use powerpoint.  When I send my colleagues pdf
>> files
>> |> or ps files, powerpoint
>> |> rejects them.  Powerpoint does accept some eps files.
>> |>
>> 
>> [...]
>> 
>> |> Does anyone know a workaround that will get vector graphics from R into
>> |> powerpoint?
>> |> win.metafile is not acceptable.  The resolution of emf files from R is
>> |> worse than png files.
>> 
>> Maybe worse than png files at the default resolution which is 72 dpi.
>> Change that to something like 300 and nobody will see a jagged edge in
>> a PowerPoint slide.
>> 
>> HTH
>> 
>> 
>> |>
>> |> Thanks
>> |> Rich


From jdnewmil at dcn.davis.CA.us  Wed Jul 24 17:45:19 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 24 Jul 2013 08:45:19 -0700
Subject: [R] Fwd: Why does impulse response function of VAR starts at
	zero and not at one?
In-Reply-To: <CAEaKQwX2psjJZBALRd_06SK-NjYB7XxW0N3S_cpgtg29a6pAQg@mail.gmail.com>
References: <CAEaKQwW_u9ettAUw9r1QyH4np-FhxnJy6S5d=O8mLCuK_TkAMg@mail.gmail.com>
	<CAEaKQwX2psjJZBALRd_06SK-NjYB7XxW0N3S_cpgtg29a6pAQg@mail.gmail.com>
Message-ID: <312a95ed-3a80-4b7b-a75a-77a4dc8b039b@email.android.com>

It appeared on the mailing list (https://stat.ethz.ch/pipermail/r-help/2013-July/357190.html ... you have to click on the attachment URL). As did this one. (You are not addressing the moderators... you are addressing the whole list.)

Your question is not well-formed. Please read the Posting Guide. You might benefit from reading http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example as well. (We should be able to run your example and see a sample output that illustrates your problem. You should also post in text format so the HTML does not mangle your code.)

One thing to keep in mind is that this is a list for questions about R, and much less about theory. Questions about contributed packages must mention their name, and keep in mind that list participants may never have encountered that package (there are thousands of them). If a particular package has a bug then you should address the package maintainer (see ?maintainer). If your question turns out to focus on theory, you might be better off asking somewhere like stats.stackexchange.com. Even if your question is well-formed, no one here might know the answer and you could get no response at all, but at least you can make it easy to reproduce the problem in case someone is curious enough to investigate and offer some ideas or corroboration.

On the topic of R, I doubt that the package author intended that you supply vectors of all of the possible options for the type and ic parameters. Most likely, supplying just one of the options for each parameter will obtain best results.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Jos? Verhoeven" <jose at memo2.nl> wrote:
>Hi there,
>I sent this e-mail two days ago, but I did not see it pass by the
>R-help
>mailinglist and I was wondering if you could post it or is there a que?
>Thanks in advance.
>
>Kind regards,
>Jose
>
>
>
>
>---------- Forwarded message ----------
>From: Jos? Verhoeven <jose at memo2.nl>
>Date: 2013/7/22
>Subject: Why does impulse response function of VAR starts at zero and
>not
>at one?
>To: r-help at r-project.org
>
>
>Hi there,
>I have estimated a bivariate VAR model (with series x1 and x2 as
>endogenous
>variables):
>
>y=cbind(x1,x2)
>z=cbind(d1,d2,d3,d4,d5,d6,d7,d8,d9)       # some dummy variables
>
>model<-VAR(y, p = 3, type = c("const", "trend", "both", "none"),
>season = NULL, exogen = z, lag.max = NULL,
>ic = c("AIC", "HQ", "SC", "FPE"))
>
>and I have plotted the cumulative impulse response function with:
>
>impulseresponse<-irf(lagmodel, impulse = "x2", response = "x1", n.ahead
>=
>400,
>ortho = TRUE, cumulative = TRUE, boot = FALSE)
>plot(impulseresponse)
>
>Now as the impulse response function shows the effect on e.g. x1 of a
>unit
>shock in x2 I expect the value at t=0 to be at or around one (depending
>on
>whether there is an interscept in the model). Why then, does all
>impulse
>response plots I get start at zero?
>
>I really hope someone can help me out! Thanks in advance.
>
>Jose
>
>	[[alternative HTML version deleted]]
>
>
>
>------------------------------------------------------------------------
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From rmh at temple.edu  Wed Jul 24 17:49:35 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 24 Jul 2013 11:49:35 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
Message-ID: <CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/08290b26/attachment.pl>

From marc_schwartz at me.com  Wed Jul 24 18:16:00 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 24 Jul 2013 11:16:00 -0500
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
Message-ID: <151922E4-7260-475C-846E-0FD35809EC51@me.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/aaba5a6a/attachment.pl>

From rmh at temple.edu  Wed Jul 24 18:37:35 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 24 Jul 2013 12:37:35 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <151922E4-7260-475C-846E-0FD35809EC51@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
Message-ID: <CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/2a4f89fe/attachment.pl>

From marc_schwartz at me.com  Wed Jul 24 19:22:37 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 24 Jul 2013 12:22:37 -0500
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
Message-ID: <98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>

Hi Rich,

That's curious.

I noted that you are using barchart() below which is lattice versus base graphics. Is there any difference in the result on Windows if you use barplot() instead? If so, perhaps there is something about lattice graphics in this context.

Also, are you using Office 2008 or Office 2011 on your Mac? 2011 substantially improved Windows file format compatibility, not to mention a plethora of bug fixes.

Regards,

Marc


On Jul 24, 2013, at 11:37 AM, Richard M. Heiberger <rmh at temple.edu> wrote:

> Marc,
> 
> very interesting.
> 
> Your example works on Windows.  This example doesn't work on windows
> 
>> postscript(file = "file2.eps", height = 4, width = 4,
> +                 horizontal = FALSE, onefile = FALSE, paper = "special")
>> barchart(1:3)
>> dev.off()
> 
> Several examples, including the real one I was having trouble with
> previously, work on
> PowerPoint on Mac.  They don't work on PowerPoint in Windows.
> 
> More: I put some eps figures into PP on Mac (where they work) and then
> saved the file and
> opened it in PP on Windows.  They don't work on Windows.
> 
> Since Windows PP users are the target audience at the moment, I will stay
> with the res=300 png file.
> 
> This is consistent with my other experiences with PP and Word for Mac,
> compared to PP and
> Word for Windows.  The two MS sets of programs are highly correlated, but
> far from identical.
> 
> When people send my PP or Word files, I am more likely to open them first
> on the Mac side of my
> machine.  The graphs have spurious lines (connecting the end of the red
> line to the beginning of
> the green line, for example, when the two lines should be distinct).
> Alignment is different
> (two-line titles will get folded at the wrong place).  I need to move back
> to the Windows side in
> the VM to see the files as the author intended.
> 
> Rich
> 
> 
> On Wed, Jul 24, 2013 at 12:16 PM, Marc Schwartz <marc_schwartz at me.com>wrote:
> 
>> Hi Rich,
>> 
>> Seems to work for me using Powerpoint in MS Office 2011 for Mac.
>> 
>> I used the following code:
>> 
>> postscript(file = "file.eps", height = 4, width = 4,
>>                horizontal = FALSE, onefile = FALSE, paper = "special")
>> 
>> plot(rnorm(20))
>> 
>> dev.off()
>> 
>> 
>> 
>> Then I used the insert picture from file function in Powerpoint. It
>> created the PNG preview during import and I can see that on the slide in
>> the application without issue.
>> 
>> I put the EPS file and the PPTX file up on DropBox if you want to look at
>> them:
>> 
>> EPS File: https://www.dropbox.com/s/d8avze4yv51blso/file.eps
>> 
>> PPTX file: https://www.dropbox.com/s/pm7oejm0g6rc0a5/RPlot.pptx
>> 
>> 
>> Regards,
>> 
>> Marc
>> 
>> 
>> 
>> On Jul 24, 2013, at 10:49 AM, "Richard M. Heiberger" <rmh at temple.edu>
>> wrote:
>> 
>> Thanks Marc,
>> 
>> the extra arguments to postscript still don't produce something that
>> PowerPoint will accept.
>> With your call, PP still displayed only the icon.  PP did not generate its
>> own png file.
>> 
>> Since my immediate goal is the projection screen for a PowerPoint
>> presentation, I will go
>> directly to the png file.  For the proceedings and for paper I will
>> continue to use the pdf file.
>> 
>> Rich
>> 
>> On Wed, Jul 24, 2013 at 11:36 AM, Marc Schwartz <marc_schwartz at me.com>wrote:
>> 
>>> Rich,
>>> 
>>> You are missing some options in the call to postscript() below. It needs
>>> to be:
>>> 
>>>  postscript(file = "file.eps", width = x, height = y,
>>>             horizontal = FALSE, onefile = FALSE, paper = "special")
>>> 
>>> The first line needs to have values for 'x' and 'y' for the width and
>>> height of the image, as they default to 0.
>>> 
>>> The second line of 3 options are all critical to producing an EPS file,
>>> as opposed to a PS file. This is described in the 4th paragraph of the
>>> Details section of ?postscript.
>>> 
>>> If you import that file into any of the MS Office products (typically
>>> also for OpenOffce, LibreOffice, etc.), a PNG preview image will be created
>>> during import. It is the PNG bitmapped image that you can see when
>>> displaying the EPS file in the document, hence the degradation in quality.
>>> Some years ago, all you would see is a rectangular box with an "X" across
>>> it, as a placeholder for the imported image.
>>> 
>>> Only if you then print the Office file using a Postscript printer driver,
>>> will you see the actual vector based EPS image. The target of that printing
>>> operation could be a printer for hard copy, a PS or a PDF file. MS Office
>>> does not support the rendering of the EPS image directly.
>>> 
>>> If you are operating on Windows, as opposed to Linux or OSX, typically
>>> EMF/WMF files are the easiest way to go in terms of sticking R plots into
>>> an Office file, as they are also vector based images, but are effectively
>>> Windows only.
>>> 
>>> Regards,
>>> 
>>> Marc Schwartz
>>> 
>>> 
>>> On Jul 24, 2013, at 10:20 AM, Richard M. Heiberger <rmh at temple.edu>
>>> wrote:
>>> 
>>>> png("png300.png", res=300, width=2880, height=1440)
>>>> 
>>>> gives good behavior.  Thank you.  This will become my standard for
>>> export
>>>> to powerpoint.
>>>> 
>>>> postscript(file='file.eps', onefile=FALSE)
>>>> produces eps files that powerpoint rejects, even though ghostview is
>>>> satisfied.
>>>> 
>>>> Rich
>>>> 
>>>> 
>>>> On Wed, Jul 24, 2013 at 2:07 AM, Patrick Connolly <
>>>> p_connolly at slingshot.co.nz> wrote:
>>>> 
>>>>> On Tue, 23-Jul-2013 at 10:23PM -0400, Richard M. Heiberger wrote:
>>>>> 
>>>>> |> I have colleagues who use powerpoint.  When I send my colleagues pdf
>>>>> files
>>>>> |> or ps files, powerpoint
>>>>> |> rejects them.  Powerpoint does accept some eps files.
>>>>> |>
>>>>> 
>>>>> [...]
>>>>> 
>>>>> |> Does anyone know a workaround that will get vector graphics from R
>>> into
>>>>> |> powerpoint?
>>>>> |> win.metafile is not acceptable.  The resolution of emf files from R
>>> is
>>>>> |> worse than png files.
>>>>> 
>>>>> Maybe worse than png files at the default resolution which is 72 dpi.
>>>>> Change that to something like 300 and nobody will see a jagged edge in
>>>>> a PowerPoint slide.
>>>>> 
>>>>> HTH
>>>>> 
>>>>> 
>>>>> |>
>>>>> |> Thanks
>>>>> |> Rich
>>> 
>>> 
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jul 24 19:48:19 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 24 Jul 2013 10:48:19 -0700
Subject: [R] Y label doesn't show up on printing files
In-Reply-To: <CAGkgU9WQN4JOpxU=qbJbL9T6i8qqa9QJCGu9xvH+bwdd-EVvFg@mail.gmail.com>
References: <CAGkgU9WqQnRXaoqCMjcaHbAa0WGPn4cfKENQsKQ35jePZssPoQ@mail.gmail.com>
	<DE1C512A-D9F0-4B53-9103-827C6378AD47@comcast.net>
	<CAGkgU9WQN4JOpxU=qbJbL9T6i8qqa9QJCGu9xvH+bwdd-EVvFg@mail.gmail.com>
Message-ID: <D01326F3-B5E3-4184-8BCB-DB7D9D46F00C@comcast.net>


On Jul 24, 2013, at 4:14 AM, Mohit Dhingra wrote:

> Hi David,
> 
> Thanks for your reply! How do I exactly find it out and solve? Also,
> the problem is not reproducible every time :-/

One way would be to follow the directions in the link from ?pdf to ?embedFonts and force fonts to be included (via a call to Ghostscript.)  

Another strategy might be to look at the pdf code in the file ( or just call `names(pdfFonts()`)  )
and compare to the fonts used by your viewer.

I get quite a bit of information with this R command;

 pdfFonts()[c('serif','sans','mono')] 

My screen device is set to display the same fonts although they are listed in a slightly different format: 

quartzFonts()[c('serif','sans','mono')]. 

We Mac users have recurring problems with difficult-to-track-down issues of font corruption which creates similar problems, but it seems to afflict the screen device as well as pdf files. Generally one sees an extra copy using the font management application. Removing the corrupted copy is generally sufficient since it appears to the user that the OS has been smart enough to have already installed a fresh copy of the damaged font.

-- 
David
> ----------------------------
> Thanks & Regards
> Mohit Dhingra
> +919611190435
> 
> 
> On 22 July 2013 23:55, David Winsemius <dwinsemius at comcast.net> wrote:
>> 
>> On Jul 22, 2013, at 3:17 AM, Mohit Dhingra wrote:
>> 
>>> Hello,
>>> 
>>> I'm using R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows" .
>>> 
>>> System info: Linux ubuntu 3.5.0-36-generic #57~precise1-Ubuntu SMP Thu
>>> Jun 20 18:21:09 UTC 2013 x86_64 x86_64 x86_64 GNU/Linux.
>>> 
>>> When I plot something, y label does show up on the pop up image.
>>> plot (x, rtimel[,2] , xlab="Memory Allocated (in MB)", ylab="Response
>>> Time (in ms)", type="l", col="black", ylim=c(0,m) )
>>> 
>>> But when I try to save it using
>>> dev.copy(pdf,'response_time_with_memory_direct.pdf')
>>> dev.off()
>>> 
>>> Y-label doesn't get printed on the pdf file. Can someone please help?
>> 
>> Perhaps a difficulty with the fonts in your R installation being different than the fonts in your pdf viewer?
>> 
>> --
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 

David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Wed Jul 24 19:56:03 2013
From: rmh at temple.edu (Rmh)
Date: Wed, 24 Jul 2013 13:56:03 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
Message-ID: <18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>

office 2011 on mac, 2013 on windows.

i see the same misbehavior in base and lattice.
my standard simple test is
plot(1:10)
which is base.

did you try the windows side yet?

Rich

Sent from my iPhone

On Jul 24, 2013, at 13:22, Marc Schwartz <marc_schwartz at me.com> wrote:

> Hi Rich,
> 
> That's curious.
> 
> I noted that you are using barchart() below which is lattice versus base graphics. Is there any difference in the result on Windows if you use barplot() instead? If so, perhaps there is something about lattice graphics in this context.
> 
> Also, are you using Office 2008 or Office 2011 on your Mac? 2011 substantially improved Windows file format compatibility, not to mention a plethora of bug fixes.
> 
> Regards,
> 
> Marc
> 
> 
> On Jul 24, 2013, at 11:37 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> 
>> Marc,
>> 
>> very interesting.
>> 
>> Your example works on Windows.  This example doesn't work on windows
>> 
>>> postscript(file = "file2.eps", height = 4, width = 4,
>> +                 horizontal = FALSE, onefile = FALSE, paper = "special")
>>> barchart(1:3)
>>> dev.off()
>> 
>> Several examples, including the real one I was having trouble with
>> previously, work on
>> PowerPoint on Mac.  They don't work on PowerPoint in Windows.
>> 
>> More: I put some eps figures into PP on Mac (where they work) and then
>> saved the file and
>> opened it in PP on Windows.  They don't work on Windows.
>> 
>> Since Windows PP users are the target audience at the moment, I will stay
>> with the res=300 png file.
>> 
>> This is consistent with my other experiences with PP and Word for Mac,
>> compared to PP and
>> Word for Windows.  The two MS sets of programs are highly correlated, but
>> far from identical.
>> 
>> When people send my PP or Word files, I am more likely to open them first
>> on the Mac side of my
>> machine.  The graphs have spurious lines (connecting the end of the red
>> line to the beginning of
>> the green line, for example, when the two lines should be distinct).
>> Alignment is different
>> (two-line titles will get folded at the wrong place).  I need to move back
>> to the Windows side in
>> the VM to see the files as the author intended.
>> 
>> Rich
>> 
>> 
>> On Wed, Jul 24, 2013 at 12:16 PM, Marc Schwartz <marc_schwartz at me.com>wrote:
>> 
>>> Hi Rich,
>>> 
>>> Seems to work for me using Powerpoint in MS Office 2011 for Mac.
>>> 
>>> I used the following code:
>>> 
>>> postscript(file = "file.eps", height = 4, width = 4,
>>>               horizontal = FALSE, onefile = FALSE, paper = "special")
>>> 
>>> plot(rnorm(20))
>>> 
>>> dev.off()
>>> 
>>> 
>>> 
>>> Then I used the insert picture from file function in Powerpoint. It
>>> created the PNG preview during import and I can see that on the slide in
>>> the application without issue.
>>> 
>>> I put the EPS file and the PPTX file up on DropBox if you want to look at
>>> them:
>>> 
>>> EPS File: https://www.dropbox.com/s/d8avze4yv51blso/file.eps
>>> 
>>> PPTX file: https://www.dropbox.com/s/pm7oejm0g6rc0a5/RPlot.pptx
>>> 
>>> 
>>> Regards,
>>> 
>>> Marc
>>> 
>>> 
>>> 
>>> On Jul 24, 2013, at 10:49 AM, "Richard M. Heiberger" <rmh at temple.edu>
>>> wrote:
>>> 
>>> Thanks Marc,
>>> 
>>> the extra arguments to postscript still don't produce something that
>>> PowerPoint will accept.
>>> With your call, PP still displayed only the icon.  PP did not generate its
>>> own png file.
>>> 
>>> Since my immediate goal is the projection screen for a PowerPoint
>>> presentation, I will go
>>> directly to the png file.  For the proceedings and for paper I will
>>> continue to use the pdf file.
>>> 
>>> Rich
>>> 
>>> On Wed, Jul 24, 2013 at 11:36 AM, Marc Schwartz <marc_schwartz at me.com>wrote:
>>> 
>>>> Rich,
>>>> 
>>>> You are missing some options in the call to postscript() below. It needs
>>>> to be:
>>>> 
>>>> postscript(file = "file.eps", width = x, height = y,
>>>>            horizontal = FALSE, onefile = FALSE, paper = "special")
>>>> 
>>>> The first line needs to have values for 'x' and 'y' for the width and
>>>> height of the image, as they default to 0.
>>>> 
>>>> The second line of 3 options are all critical to producing an EPS file,
>>>> as opposed to a PS file. This is described in the 4th paragraph of the
>>>> Details section of ?postscript.
>>>> 
>>>> If you import that file into any of the MS Office products (typically
>>>> also for OpenOffce, LibreOffice, etc.), a PNG preview image will be created
>>>> during import. It is the PNG bitmapped image that you can see when
>>>> displaying the EPS file in the document, hence the degradation in quality.
>>>> Some years ago, all you would see is a rectangular box with an "X" across
>>>> it, as a placeholder for the imported image.
>>>> 
>>>> Only if you then print the Office file using a Postscript printer driver,
>>>> will you see the actual vector based EPS image. The target of that printing
>>>> operation could be a printer for hard copy, a PS or a PDF file. MS Office
>>>> does not support the rendering of the EPS image directly.
>>>> 
>>>> If you are operating on Windows, as opposed to Linux or OSX, typically
>>>> EMF/WMF files are the easiest way to go in terms of sticking R plots into
>>>> an Office file, as they are also vector based images, but are effectively
>>>> Windows only.
>>>> 
>>>> Regards,
>>>> 
>>>> Marc Schwartz
>>>> 
>>>> 
>>>> On Jul 24, 2013, at 10:20 AM, Richard M. Heiberger <rmh at temple.edu>
>>>> wrote:
>>>> 
>>>>> png("png300.png", res=300, width=2880, height=1440)
>>>>> 
>>>>> gives good behavior.  Thank you.  This will become my standard for
>>>> export
>>>>> to powerpoint.
>>>>> 
>>>>> postscript(file='file.eps', onefile=FALSE)
>>>>> produces eps files that powerpoint rejects, even though ghostview is
>>>>> satisfied.
>>>>> 
>>>>> Rich
>>>>> 
>>>>> 
>>>>> On Wed, Jul 24, 2013 at 2:07 AM, Patrick Connolly <
>>>>> p_connolly at slingshot.co.nz> wrote:
>>>>> 
>>>>>> On Tue, 23-Jul-2013 at 10:23PM -0400, Richard M. Heiberger wrote:
>>>>>> 
>>>>>> |> I have colleagues who use powerpoint.  When I send my colleagues pdf
>>>>>> files
>>>>>> |> or ps files, powerpoint
>>>>>> |> rejects them.  Powerpoint does accept some eps files.
>>>>>> |>
>>>>>> 
>>>>>> [...]
>>>>>> 
>>>>>> |> Does anyone know a workaround that will get vector graphics from R
>>>> into
>>>>>> |> powerpoint?
>>>>>> |> win.metafile is not acceptable.  The resolution of emf files from R
>>>> is
>>>>>> |> worse than png files.
>>>>>> 
>>>>>> Maybe worse than png files at the default resolution which is 72 dpi.
>>>>>> Change that to something like 300 and nobody will see a jagged edge in
>>>>>> a PowerPoint slide.
>>>>>> 
>>>>>> HTH
>>>>>> 
>>>>>> 
>>>>>> |>
>>>>>> |> Thanks
>>>>>> |> Rich
>> 
>>    [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From dennis1991 at gmx.net  Wed Jul 24 14:58:41 2013
From: dennis1991 at gmx.net (dennis1991 at gmx.net)
Date: Wed, 24 Jul 2013 14:58:41 +0200 (CEST)
Subject: [R] How to split two levels several times?
In-Reply-To: <51EE6AC7.1060003@sapo.pt>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
Message-ID: <trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>

Hi Rui
the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.

lens <- rle(as.character(XXX$electrode))$lengths
will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.

Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.


This is the table "XXX"

electrode length

electrode1 5.7
electrode1 6.3
electrode1 6.2
electrode2 11.4
electrode2 9.7
electrode3 14.2
electrode3 14.8
electrode3 12.6
electrode2 11.4
electrode2 9.7
electrode4 17.0
electrode4 16.3
electrode4 17.8
electrode4 18.3
electrode4 16.9
electrode4 18.5
electrode1 5.7
electrode1 6.3
electrode1 6.2
electrode1 5.7
electrode1 6.3
electrode1 6.2
electrode3 14.2
electrode3 14.8
electrode3 12.6


This is a simplified table XX

electrode1
electrode2
electrode1
electrode3
electrode1
electrode4
electrode2
electrode1
electrode2
electrode3
electrode2
electrode4
electrode3
electrode1
electrode3
electrode2
electrode3
electrode4
electrode4
electrode1
electrode4
electrode2
electrode4
electrode3






> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> An: dennis1991 at gmx.net
> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
> Betreff: Re: Aw: Re: [R] How to split two levels several times?
>
> Hello,
>
> It's better if you keep this on the list, the odds of getting more and
> better answers are greater.
> 
> As for your new question, try the following.
>
>
> lens <- rle(as.character(XXX$electrode))$lengths
> m <- length(lens) %/% 2
> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> split(XXX, idx)
> 
>
> Hope this helps,
>
> Rui Barradas
>
> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
> > Hi
> > this type of splitting works for my specific example. Thanks for your help.
> >
> > I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,  electrode3-electrode2,  electrode4-electrode1. How should I split this?
> >
> >
> > This is the table "XXX"
> >
> > electrode length
> >
> > electrode1 5.7
> > electrode1 6.3
> > electrode1 6.2
> > electrode2 11.4
> > electrode2 9.7
> > electrode3 14.2
> > electrode3 14.8
> > electrode3 12.6
> > electrode2 11.4
> > electrode2 9.7
> > electrode4 17.0
> > electrode4 16.3
> > electrode4 17.8
> > electrode4 18.3
> > electrode4 16.9
> > electrode4 18.5
> > electrode1 5.7
> > electrode1 6.3
> > electrode1 6.2
> >
> >
> >
> >
> >
> >> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
> >> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >> An: dennis1991 at gmx.net
> >> Cc: r-help at r-project.org
> >> Betreff: Re: [R] How to split two levels several times?
> >>
> >> Hello,
> >>
> >> Sorry, I've just realized that your data frame is named 'XXX', not
> >> 'dat'. Change that and the rest should work:
> >>
> >>
> >> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
> >> split(XXX, idx)
> >>
> >>
> >> Rui Barradas
> >>
> >> Em 22-07-2013 16:47, Rui Barradas escreveu:
> >>> Hello,
> >>>
> >>> Try the following.
> >>>
> >>>
> >>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
> >>> split(dat, idx)
> >>>
> >>>
> >>> Hope this helps,
> >>>
> >>> Rui Barradas
> >>>
> >>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
> >>>> Hi,
> >>>>
> >>>> I have a small problem with the function split() and would appreciate
> >>>> your help.
> >>>>
> >>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
> >>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
> >>>> split the table always at the row where ?electrode1? starts again so
> >>>> that I can export 7  individual dataframes (numbered ?dataframe1? to
> >>>> ?dataframe7?) which contain always electrode1 as first level (always
> >>>> three rows) with the varying number of rows for electrodes2-8 below.
> >>>> I tried the split function with various setups:
> >>>>
> >>>> t <- as.factor(XXX$electrode)
> >>>>
> >>>> dataframeX <- split(XXX, f=(levels=t))
> >>>>
> >>>> But this doesn?t work. Could you please help. Thank you! Dennis
> >>>>
> >>>>
> >>>> This is the table "XXX"
> >>>>
> >>>> electrode    length
> >>>>
> >>>> electrode1    5.7
> >>>> electrode1    6.3
> >>>> electrode1    6.2
> >>>> electrode2    11.4
> >>>> electrode2    9.7
> >>>> electrode1    5.7
> >>>> electrode1    6.3
> >>>> electrode1    6.2
> >>>> electrode3    14.2
> >>>> electrode3    14.8
> >>>> electrode3    12.6
> >>>> electrode1    5.7
> >>>> electrode1    6.3
> >>>> electrode1    6.2
> >>>> electrode4    17.0
> >>>> electrode4    16.3
> >>>> electrode4    17.8
> >>>> electrode4    18.3
> >>>> electrode4    16.9
> >>>> electrode4    18.5
> >>>> electrode1    ....
> >>>> ....        ....
> >>>> electrode5    ....
> >>>> ....        ....
> >>>> electrode1    ....
> >>>> electrode6    ....
> >>>> electrode1    ....
> >>>> electrode7    ....
> >>>> electrode1    ....
> >>>> electrode8    ....
> >>>>
> >>>> ______________________________________________
> >>>> R-help at r-project.org mailing list
> >>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>> PLEASE do read the posting guide
> >>>> http://www.R-project.org/posting-guide.html
> >>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>>
> >>> ______________________________________________
> >>> R-help at r-project.org mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>> PLEASE do read the posting guide
> >>> http://www.R-project.org/posting-guide.html
> >>> and provide commented, minimal, self-contained, reproducible code.
> >>
>


From smartpink111 at yahoo.com  Wed Jul 24 15:02:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 24 Jul 2013 06:02:58 -0700 (PDT)
Subject: [R] function 2 convert matrix to long-format?
In-Reply-To: <CAAjnpdgyv4ESwOgR5ddGk8NzQhMCgO-Yz4MXpAcDt0M3uyjK2Q@mail.gmail.com>
References: <CAAjnpdgyv4ESwOgR5ddGk8NzQhMCgO-Yz4MXpAcDt0M3uyjK2Q@mail.gmail.com>
Message-ID: <1374670978.50516.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
It is better to use ?dput().
a1<-array(c(0.1416,0.1049,0.1328,0.12235,0.11890,0.15510,0.14225,0.09295,0.13350,0.16875,0.09900,0.14560),c(3,2,2))
?dimnames(a1)<- list(c("T0","T1","T2"),c("B6","B9"),c("minus","plus"))
library(plyr)
library(reshape2)
res<-melt(adply(a1,c(1,2)),id.vars=c("X1","X2"))


res
#?? X1 X2 variable?? value
#1? T0 B6??? minus 0.14160
#2? T1 B6??? minus 0.10490
#3? T2 B6??? minus 0.13280
#4? T0 B9??? minus 0.12235
#5? T1 B9??? minus 0.11890
#6? T2 B9??? minus 0.15510
#7? T0 B6???? plus 0.14225
#8? T1 B6???? plus 0.09295
#9? T2 B6???? plus 0.13350
#10 T0 B9???? plus 0.16875
#11 T1 B9???? plus 0.09900
#12 T2 B9???? plus 0.14560
A.K.



----- Original Message -----
From: Witold E Wolski <wewolski at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 24, 2013 6:00 AM
Subject: [R] function 2 convert matrix to long-format?

I would like to convert this (output of tapply)
, , minus

? ? ?  B6? ? ? S9
T0 0.1416 0.12235
T1 0.1049 0.11890
T2 0.1328 0.15510

, , plus

? ? ? ? B6? ? ? S9
T0 0.14225 0.16875
T1 0.09295 0.09900
T2 0.13350 0.14560

to long-format :

T0 B6 minus 0.1416
T0 S9 minus 0.12235
T0 B6 plus 0.14225
T0 S9 plus 0.16875
....
...


whats the default way in R?

best




--
Witold Eryk Wolski

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From borja.rivier at gmail.com  Wed Jul 24 15:25:23 2013
From: borja.rivier at gmail.com (Borja Rivier)
Date: Wed, 24 Jul 2013 14:25:23 +0100
Subject: [R] Levels of a factor
Message-ID: <CAEJ+j1suE35XM5y49AeODi3hj=fbSY73Wx6NEw8oyr6n_amhVg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/de3bc414/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 24 15:29:03 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 24 Jul 2013 06:29:03 -0700 (PDT)
Subject: [R] Change values in a dateframe
In-Reply-To: <51EF76AA.7000803@cirad.fr>
References: <51EF76AA.7000803@cirad.fr>
Message-ID: <1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Michel,
You could try:


df1New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=min)),])
row.names(df1New)<-1:nrow(df1New)
df2New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=max)),])
row.names(df2New)<-1:nrow(df2New)
?identical(df1New,df1)
#[1] TRUE
?identical(df2New,df2)
#[1] TRUE
A.K.



----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: R help <r-help at r-project.org>
Cc: 
Sent: Wednesday, July 24, 2013 2:39 AM
Subject: [R] Change values in a dateframe

Hello

I have the following problem :
The dataframe TEST has multiple lines for a same person because :
there are differents values of Nom or differents values of Prenom
but the values of Matricule or Sexe or Date.de.naissance are the same.

TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
"JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
"Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = 
"factor"),
? ?  Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
? ?  1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
? ?  "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = 
"factor")), .Names = c("Matricule",
"Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", 
row.names = c(NA,
-11L))


I would want to make homogeneous the information and would like built 2 
dataframes :
df1 wich has the value of Nom and Prenom of the first lines of TEST when 
there are different values. The other values (Matricule or Sexe or 
Date.de.naissance) are unchanged

df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
"JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom = 
structure(c(6L,
3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
"Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class = 
"factor"),
? ?  Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
? ?  1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
? ?  "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class = 
"factor")), .Names = c("Matricule",
"Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", 
row.names = c(NA,
-11L))

df2 wich has the value of Nom and Prenom of the last lines of TEST when 
there are different values. The other values (Matricule or Sexe or 
Date.de.naissance) are unchanged.

df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
"LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
? ?  Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
? ?  5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
? ?  "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe = 
structure(c(1L,
? ?  1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
? ?  "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
? ?  2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
? ?  "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
? ?  "30/03/1935"), class = "factor")), .Names = c("Matricule",
"Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame", 
row.names = c(NA,
-11L))

Thank for your helps
Michel

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul 24 15:35:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 24 Jul 2013 06:35:08 -0700 (PDT)
Subject: [R] subtracting rows for unique
In-Reply-To: <1374611676.4941.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1374606669.8805.YahooMailNeo@web121306.mail.ne1.yahoo.com>
	<1374611676.4941.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1374672908.26901.YahooMailNeo@web142605.mail.bf1.yahoo.com>



Hi,
Try:
dat1<- read.table(text="
ID Date x2 x1????????? x3 
56 25-Jun-01 10 2? 126 
56 29-Oct-01 10 2? 140 
56 18-Mar-02 10 2? 445 
56 6-Jun-03 10 2??? 224 
56 16-Jan-04? 10 2??? NA 
58 10-Jan-02 10.8 1 715 
58 26-Dec-03 10.8 1??? NA 
",sep="",header=TRUE,stringsAsFactors=FALSE) 
?unlist(with(dat1,by(as.Date(Date,format="%d-%b-%y"),ID,FUN=function(x) c(diff(x),NA))),use.names=FALSE)
#[1] 126 140 445 224? NA 715? NA
#or
unlist(lapply(split(dat1,dat1$ID),function(x) c(diff(as.Date(x$Date,format="%d-%b-%y")),NA)),use.names=FALSE)
#[1] 126 140 445 224? NA 715? NA
A.K.



________________________________
From: farnoosh sheikhi <farnoosh_81 at yahoo.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Tuesday, July 23, 2013 3:11 PM
Subject: subtracting rows for unique 



Hi there,

Hope you are doing well.
I have a data set which looks like below, I want to create a new variable (x3-here) which subtracts the date for unique ID.
For example for ID 56, the first value is the difference between ?29-Oct, and 25-June.
Thanks for your help and time.




ID Date x2 x1???? ? ? ?x3 
56 25-Jun-01 10 2 126 
56 29-Oct-01 10 2 140 
56 18-Mar-02 10 2 445 
56 6-Jun-03 10 2 224 
56 16-Jan-04??NA ? ? ? ? ? ? NA 
58 10-Jan-02 10.8 1 715 
58 26-Dec-03 10.8 1 ? ? ? ? ? ? NA 

Best,Farnoosh Sheikhi?


From smartpink111 at yahoo.com  Wed Jul 24 15:39:47 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 24 Jul 2013 06:39:47 -0700 (PDT)
Subject: [R] Levels of a factor
Message-ID: <1374673187.10780.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
?vec1<- factor(1:5,levels=1:10)
?vec1
#[1] 1 2 3 4 5
#Levels: 1 2 3 4 5 6 7 8 9 10


vec2<-droplevels(vec1)
?levels(vec2)
#[1] "1" "2" "3" "4" "5"
?vec2
#[1] 1 2 3 4 5
#Levels: 1 2 3 4 5
A.K.

Hi all, 

I am having a bit of trouble using the levels() function. 
I have a factor with many elements, and when I use the function 
levels() to extract the list of unique elements, some of the elements 
returned are not actually in the factor. 

For example I would have this: 

> vector <- dataset$Benchmark 
> class(vector) 
[1] "factor" 
> length(vector) 
[1] 35615 
> vector2 <- levels(vector) 
> length(which(!(vector2 %in% vector))) 
[1] 235 

Does anyone know how this is possible? 

Many thanks! 

Borja


From ritwik_r at isical.ac.in  Wed Jul 24 16:06:12 2013
From: ritwik_r at isical.ac.in (ritwik_r at isical.ac.in)
Date: Wed, 24 Jul 2013 19:36:12 +0530
Subject: [R] Query on R plot : Unequispaced label on x-axis
Message-ID: <9eaa98f123a5c740183b77102af8e4b3.squirrel@www.isical.ac.in>

Dear R users,

I want to plot a one variable continuous function f(x) vs x, x=[0,1]. Say
for example: f(x)= x^2. Now, using the command plot(f~x) I will get a
curve where the range of x-axis is [0,1] with all equispaced label. But, I
need something else, and that is: my curve will be such that 80% on x-axis
the range would be [0,0.5] and the rest 20% would contain [0.5,1]. Let me
draw informally here. Say, the line below is my x-axis in graph and my
plotting points are like:



          ________________________________________
          0     0.01      0.1        0.5         1

Any help or suggestion will be highly appreciable.

Regards,
Ritwik
ISI Kolkata


From arnaud.blaser at unine.ch  Wed Jul 24 16:17:06 2013
From: arnaud.blaser at unine.ch (BLASER Arnaud)
Date: Wed, 24 Jul 2013 14:17:06 +0000
Subject: [R] x-axis (categorial variable) ordering with xyplot function
 (lattice package)
Message-ID: <4797A3DC820212418B235B3ED20FAF071CA1D4@MAIL-MBX-05.UNINE.CH>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/2a2d9418/attachment.pl>

From amybethhenry at gmail.com  Wed Jul 24 17:18:41 2013
From: amybethhenry at gmail.com (Amy Henry)
Date: Wed, 24 Jul 2013 08:18:41 -0700
Subject: [R] R help
Message-ID: <CADYQ-MLynhiMdJHQNKNQN-iRE+Eqi1g5WVXusF3A+oT94j2J+Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/5bb8b3d8/attachment.pl>

From alamont082 at gmail.com  Wed Jul 24 18:27:47 2013
From: alamont082 at gmail.com (Andrea Lamont)
Date: Wed, 24 Jul 2013 12:27:47 -0400
Subject: [R] flexible approach to subsetting data
In-Reply-To: <AA63C50C-12E8-421D-BA69-A46B50EAB258@comcast.net>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>
	<F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>
	<F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>
	<01cc01ce87e7$b08340b0$1189c210$@tamu.edu>
	<AA63C50C-12E8-421D-BA69-A46B50EAB258@comcast.net>
Message-ID: <CALxSy073wnWQFog2T9qsRhjoqzAS0Pp1c6xwTQ5-w-orQOqsTw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/561e94d4/attachment.pl>

From farnoosh_81 at yahoo.com  Wed Jul 24 18:39:05 2013
From: farnoosh_81 at yahoo.com (farnoosh sheikhi)
Date: Wed, 24 Jul 2013 09:39:05 -0700 (PDT)
Subject: [R] subtracting rows for unique
In-Reply-To: <1374611676.4941.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1374606669.8805.YahooMailNeo@web121306.mail.ne1.yahoo.com>
	<1374611676.4941.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1374683945.51194.YahooMailNeo@web121306.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/f117d435/attachment.pl>

From guetta at cantab.net  Wed Jul 24 20:10:08 2013
From: guetta at cantab.net (Daniel Guetta)
Date: Wed, 24 Jul 2013 11:10:08 -0700
Subject: [R] grid: Grid graphics flickering
Message-ID: <CAEycKKx2w64GUePsUkQnQS-zqqHRFrww32jxMCWbbHGTMHuV=g@mail.gmail.com>

I'm designing an interactive plot using the `grid` package in R. As
part of the interactivity, I repeatedly delete and re-create various
parts of the plot. However, the total number of grid elements (as
obtained using the `grid.ls()` command) stays constant; everything I
create was previously removed.

The problem is as follows - once I've gone through a few cycles of
creation and deletion, every deletion I make to the graphic, however
small, causes all the interactive parts of the plot (those I've been
repeatedly deleting and creating) to flicker.

Here's the simplest example I could come up with - first run this code
to set up the `grid` graphic, and repeatedly delete and re-create
certain elements

###############################

    library(grid)

    pushViewport(viewport())

    for (x in seq(0, 1, length=5))
    {
    for (y in seq(0, 1, length=5))
    {
    pushViewport(viewport(x = x, y = y, width=1/5, height=1/5,
name=paste("foo", x, y, sep="")))
    grid.rect()

    pushViewport(viewport(x = 0, 0, width=1/4, height=1/4, name="bar1"))
    grid.circle(name="testing")
    grid.text("123")
    upViewport()

    pushViewport(viewport(x = 1, 0, width=1/4, height=1/4, name="bar2"))
    grid.circle(name="testing")
    grid.text("123")
    upViewport()

    pushViewport(viewport(x = 0, 1, width=1/4, height=1/4, name="bar3"))
    grid.circle(name="testing")
    grid.text("123")
    upViewport()

    pushViewport(viewport(x = 1, 1, width=1/4, height=1/4, name="bar4"))
    grid.circle(name="testing")
    grid.text("123")
    upViewport()

    upViewport()
    }
    }

    for (i in 1:10)
    {

    grid.gremove("testing")

    for (x in seq(0, 1, length=5))
    {
    for (y in seq(0, 1, length=5))
    {
    downViewport(paste("foo", x, y, sep=""))

    downViewport("bar1"); grid.circle(name="testing"); upViewport()
    downViewport("bar2"); grid.circle(name="testing"); upViewport()
    downViewport("bar3"); grid.circle(name="testing"); upViewport()
    downViewport("bar4"); grid.circle(name="testing"); upViewport()

    upViewport()
    }
    }

    }

###############################

Once this is all set up, create a new arbitrary square on the device

###############################
    grid.rect(height=0.5, width=0.5, gp=gpar(lty = 2), name = "lastShape")
###############################

Now try to delete it

###############################
    grid.gremove("lastShape")
###############################

Notice that when you run this last deletion command, all the small
circles that I've been creating and deleting flicker slightly, even
though I haven't touched them. This makes the entire graphic very
distracting.

The thing is, if I don't delete and re-create the original graphics so
many times, this doesn't happen! So I figure I must be leaving a trail
somewhere because of inefficient deleting.

Any ideas how to prevent that?

Thanks a million!

------------------------------------------------------

Daniel Guetta
PhD Candidate, Columbia University


From groemer at nmsu.edu  Wed Jul 24 20:19:12 2013
From: groemer at nmsu.edu (Gary Roemer)
Date: Wed, 24 Jul 2013 11:19:12 -0700 (PDT)
Subject: [R] Problems loading siar package
In-Reply-To: <1374687006442-4672234.post@n4.nabble.com>
References: <1334532423814-4560105.post@n4.nabble.com>
	<1374687006442-4672234.post@n4.nabble.com>
Message-ID: <5CA86C6E-3155-4AC4-B3BD-5D413E5E76D9@nmsu.edu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/f1ad0305/attachment.pl>

From dwinsemius at comcast.net  Wed Jul 24 20:35:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 24 Jul 2013 11:35:55 -0700
Subject: [R] Levels of a factor
In-Reply-To: <CAEJ+j1suE35XM5y49AeODi3hj=fbSY73Wx6NEw8oyr6n_amhVg@mail.gmail.com>
References: <CAEJ+j1suE35XM5y49AeODi3hj=fbSY73Wx6NEw8oyr6n_amhVg@mail.gmail.com>
Message-ID: <88ED1074-4C48-4BC2-A493-B94B7DAD3889@comcast.net>


On Jul 24, 2013, at 6:25 AM, Borja Rivier wrote:

> Hi all,
> 
> I am having a bit of trouble using the levels() function.
> I have a factor with many elements, and when I use the function levels() to
> extract the list of unique elements, some of the elements returned are not
> actually in the factor.
> 
> For example I would have this:
> 
>> vector <- dataset$Benchmark
>> class(vector)
> [1] "factor"
>> length(vector)
> [1] 35615
>> vector2 <- levels(vector)
>> length(which(!(vector2 %in% vector)))
> [1] 235
> 
> Does anyone know how this is possible?
> 

When you take a subset of a factor vector, the levels are not reduced to the unique values in the new vector. There is droplevels function that would need to be applied if you already have such a vector, and there is a drop argument that you need to set to TRUE in the `[.factors` call if you want to "attack the problem at the source".

?`[.factor
?droplevels

-- 

David Winsemius
Alameda, CA, USA


From marc_schwartz at me.com  Wed Jul 24 20:39:40 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 24 Jul 2013 13:39:40 -0500
Subject: [R] .eps files and powerpoint
In-Reply-To: <18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
Message-ID: <472EC292-7324-4263-9F20-002CE607123B@me.com>

Rich,

I don't have direct access to Windows and I don't run a VM on my Mac. 

I e-mailed two PPTX files created on my Mac (Office 2011) to a colleague who has Office 2010 on his Windows laptop. The first was the file on DropBox that I linked earlier, with the regular plot. The second is this PPTX file:

  https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx

which contains this EPS file created with the barchart() code that you had below:

  https://www.dropbox.com/s/ujchnft7q3aa3pw/file2.eps

I went over to his office and he could open both PPTX files on his laptop and both of the embedded EPS plots were viewable without issue.

Can you open the PPTX file that I created above on your Windows instance?

Marc


On Jul 24, 2013, at 12:56 PM, Rmh <rmh at temple.edu> wrote:

> office 2011 on mac, 2013 on windows.
> 
> i see the same misbehavior in base and lattice.
> my standard simple test is
> plot(1:10)
> which is base.
> 
> did you try the windows side yet?
> 
> Rich
> 
> Sent from my iPhone
> 
> On Jul 24, 2013, at 13:22, Marc Schwartz <marc_schwartz at me.com> wrote:
> 
>> Hi Rich,
>> 
>> That's curious.
>> 
>> I noted that you are using barchart() below which is lattice versus base graphics. Is there any difference in the result on Windows if you use barplot() instead? If so, perhaps there is something about lattice graphics in this context.
>> 
>> Also, are you using Office 2008 or Office 2011 on your Mac? 2011 substantially improved Windows file format compatibility, not to mention a plethora of bug fixes.
>> 
>> Regards,
>> 
>> Marc
>> 
>> 
>> On Jul 24, 2013, at 11:37 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> 
>>> Marc,
>>> 
>>> very interesting.
>>> 
>>> Your example works on Windows.  This example doesn't work on windows
>>> 
>>>> postscript(file = "file2.eps", height = 4, width = 4,
>>> +                 horizontal = FALSE, onefile = FALSE, paper = "special")
>>>> barchart(1:3)
>>>> dev.off()
>>> 
>>> Several examples, including the real one I was having trouble with
>>> previously, work on
>>> PowerPoint on Mac.  They don't work on PowerPoint in Windows.
>>> 
>>> More: I put some eps figures into PP on Mac (where they work) and then
>>> saved the file and
>>> opened it in PP on Windows.  They don't work on Windows.
>>> 
>>> Since Windows PP users are the target audience at the moment, I will stay
>>> with the res=300 png file.
>>> 
>>> This is consistent with my other experiences with PP and Word for Mac,
>>> compared to PP and
>>> Word for Windows.  The two MS sets of programs are highly correlated, but
>>> far from identical.
>>> 
>>> When people send my PP or Word files, I am more likely to open them first
>>> on the Mac side of my
>>> machine.  The graphs have spurious lines (connecting the end of the red
>>> line to the beginning of
>>> the green line, for example, when the two lines should be distinct).
>>> Alignment is different
>>> (two-line titles will get folded at the wrong place).  I need to move back
>>> to the Windows side in
>>> the VM to see the files as the author intended.
>>> 
>>> Rich
>>> 
>>> 
>>> On Wed, Jul 24, 2013 at 12:16 PM, Marc Schwartz <marc_schwartz at me.com>wrote:
>>> 
>>>> Hi Rich,
>>>> 
>>>> Seems to work for me using Powerpoint in MS Office 2011 for Mac.
>>>> 
>>>> I used the following code:
>>>> 
>>>> postscript(file = "file.eps", height = 4, width = 4,
>>>>              horizontal = FALSE, onefile = FALSE, paper = "special")
>>>> 
>>>> plot(rnorm(20))
>>>> 
>>>> dev.off()
>>>> 
>>>> 
>>>> 
>>>> Then I used the insert picture from file function in Powerpoint. It
>>>> created the PNG preview during import and I can see that on the slide in
>>>> the application without issue.
>>>> 
>>>> I put the EPS file and the PPTX file up on DropBox if you want to look at
>>>> them:
>>>> 
>>>> EPS File: https://www.dropbox.com/s/d8avze4yv51blso/file.eps
>>>> 
>>>> PPTX file: https://www.dropbox.com/s/pm7oejm0g6rc0a5/RPlot.pptx
>>>> 
>>>> 
>>>> Regards,
>>>> 
>>>> Marc
>>>> 
>>>> 
>>>> 
>>>> On Jul 24, 2013, at 10:49 AM, "Richard M. Heiberger" <rmh at temple.edu>
>>>> wrote:
>>>> 
>>>> Thanks Marc,
>>>> 
>>>> the extra arguments to postscript still don't produce something that
>>>> PowerPoint will accept.
>>>> With your call, PP still displayed only the icon.  PP did not generate its
>>>> own png file.
>>>> 
>>>> Since my immediate goal is the projection screen for a PowerPoint
>>>> presentation, I will go
>>>> directly to the png file.  For the proceedings and for paper I will
>>>> continue to use the pdf file.
>>>> 
>>>> Rich
>>>> 
>>>> On Wed, Jul 24, 2013 at 11:36 AM, Marc Schwartz <marc_schwartz at me.com>wrote:
>>>> 
>>>>> Rich,
>>>>> 
>>>>> You are missing some options in the call to postscript() below. It needs
>>>>> to be:
>>>>> 
>>>>> postscript(file = "file.eps", width = x, height = y,
>>>>>           horizontal = FALSE, onefile = FALSE, paper = "special")
>>>>> 
>>>>> The first line needs to have values for 'x' and 'y' for the width and
>>>>> height of the image, as they default to 0.
>>>>> 
>>>>> The second line of 3 options are all critical to producing an EPS file,
>>>>> as opposed to a PS file. This is described in the 4th paragraph of the
>>>>> Details section of ?postscript.
>>>>> 
>>>>> If you import that file into any of the MS Office products (typically
>>>>> also for OpenOffce, LibreOffice, etc.), a PNG preview image will be created
>>>>> during import. It is the PNG bitmapped image that you can see when
>>>>> displaying the EPS file in the document, hence the degradation in quality.
>>>>> Some years ago, all you would see is a rectangular box with an "X" across
>>>>> it, as a placeholder for the imported image.
>>>>> 
>>>>> Only if you then print the Office file using a Postscript printer driver,
>>>>> will you see the actual vector based EPS image. The target of that printing
>>>>> operation could be a printer for hard copy, a PS or a PDF file. MS Office
>>>>> does not support the rendering of the EPS image directly.
>>>>> 
>>>>> If you are operating on Windows, as opposed to Linux or OSX, typically
>>>>> EMF/WMF files are the easiest way to go in terms of sticking R plots into
>>>>> an Office file, as they are also vector based images, but are effectively
>>>>> Windows only.
>>>>> 
>>>>> Regards,
>>>>> 
>>>>> Marc Schwartz
>>>>> 
>>>>> 
>>>>> On Jul 24, 2013, at 10:20 AM, Richard M. Heiberger <rmh at temple.edu>
>>>>> wrote:
>>>>> 
>>>>>> png("png300.png", res=300, width=2880, height=1440)
>>>>>> 
>>>>>> gives good behavior.  Thank you.  This will become my standard for
>>>>> export
>>>>>> to powerpoint.
>>>>>> 
>>>>>> postscript(file='file.eps', onefile=FALSE)
>>>>>> produces eps files that powerpoint rejects, even though ghostview is
>>>>>> satisfied.
>>>>>> 
>>>>>> Rich
>>>>>> 
>>>>>> 
>>>>>> On Wed, Jul 24, 2013 at 2:07 AM, Patrick Connolly <
>>>>>> p_connolly at slingshot.co.nz> wrote:
>>>>>> 
>>>>>>> On Tue, 23-Jul-2013 at 10:23PM -0400, Richard M. Heiberger wrote:
>>>>>>> 
>>>>>>> |> I have colleagues who use powerpoint.  When I send my colleagues pdf
>>>>>>> files
>>>>>>> |> or ps files, powerpoint
>>>>>>> |> rejects them.  Powerpoint does accept some eps files.
>>>>>>> |>
>>>>>>> 
>>>>>>> [...]
>>>>>>> 
>>>>>>> |> Does anyone know a workaround that will get vector graphics from R
>>>>> into
>>>>>>> |> powerpoint?
>>>>>>> |> win.metafile is not acceptable.  The resolution of emf files from R
>>>>> is
>>>>>>> |> worse than png files.
>>>>>>> 
>>>>>>> Maybe worse than png files at the default resolution which is 72 dpi.
>>>>>>> Change that to something like 300 and nobody will see a jagged edge in
>>>>>>> a PowerPoint slide.
>>>>>>> 
>>>>>>> HTH
>>>>>>> 
>>>>>>> 
>>>>>>> |>
>>>>>>> |> Thanks
>>>>>>> |> Rich
>>> 
>>>   [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jul 24 20:47:57 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 24 Jul 2013 11:47:57 -0700
Subject: [R] Levels of a factor
In-Reply-To: <88ED1074-4C48-4BC2-A493-B94B7DAD3889@comcast.net>
References: <CAEJ+j1suE35XM5y49AeODi3hj=fbSY73Wx6NEw8oyr6n_amhVg@mail.gmail.com>
	<88ED1074-4C48-4BC2-A493-B94B7DAD3889@comcast.net>
Message-ID: <1AFE4EA7-F1C0-4426-A0D3-9DB5BFC3CFB2@comcast.net>


On Jul 24, 2013, at 11:35 AM, David Winsemius wrote:

> 
> On Jul 24, 2013, at 6:25 AM, Borja Rivier wrote:
> 
>> Hi all,
>> 
>> I am having a bit of trouble using the levels() function.
>> I have a factor with many elements, and when I use the function levels() to
>> extract the list of unique elements, some of the elements returned are not
>> actually in the factor.
>> 
>> snipped
> 
> When you take a subset of a factor vector, the levels are not reduced to the unique values in the new vector. There is droplevels function that would need to be applied if you already have such a vector, and there is a drop argument that you need to set to TRUE in the `[.factors`

Make that `[.factor`

> call if you want to "attack the problem at the source".
> 
> ?`[.factor  # missing trailing back-tick

?`[.factor`


> ?droplevels
> 
> -- 

David Winsemius
Alameda, CA, USA


From dcarlson at tamu.edu  Wed Jul 24 20:51:50 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 24 Jul 2013 13:51:50 -0500
Subject: [R] Levels of a factor
In-Reply-To: <CAEJ+j1suE35XM5y49AeODi3hj=fbSY73Wx6NEw8oyr6n_amhVg@mail.gmail.com>
References: <CAEJ+j1suE35XM5y49AeODi3hj=fbSY73Wx6NEw8oyr6n_amhVg@mail.gmail.com>
Message-ID: <02dc01ce889e$db70b4d0$92521e70$@tamu.edu>

Benchmark is probably a subset from a larger dataframe. R does
not automatically remove empty levels but you can do it:

set.seed(42)
dataset <- data.frame(Benchmark=factor(sample(LETTERS[1:26],
50, 
    replace=TRUE), levels=LETTERS[1:26]))
levels(dataset$Benchmark)
# [1] "A" "B" "C" "D" "E" "F" "G" "H" "I" "J" "K" "L" "M" "N"
"O" "P" "Q" "R" "S"
# [20] "T" "U" "V" "W" "X" "Y" "Z"
dataset$Benchmark <- factor(dataset$Benchmark)
levels(dataset$Benchmark)
# [1] "A" "C" "D" "F" "G" "H" "J" "K" "L" "M" "N" "O" "P" "Q"
"R" "S" "T" "V" "X"
# [20] "Y" "Z"

There are times when you want to know if certain factor levels
do not appear in a subset of the original data.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Borja
Rivier
Sent: Wednesday, July 24, 2013 8:25 AM
To: r-help at r-project.org
Subject: [R] Levels of a factor

Hi all,

I am having a bit of trouble using the levels() function.
I have a factor with many elements, and when I use the
function levels() to
extract the list of unique elements, some of the elements
returned are not
actually in the factor.

For example I would have this:

> vector <- dataset$Benchmark
> class(vector)
[1] "factor"
> length(vector)
[1] 35615
> vector2 <- levels(vector)
> length(which(!(vector2 %in% vector)))
[1] 235

Does anyone know how this is possible?

Many thanks!

Borja

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From murdoch.duncan at gmail.com  Wed Jul 24 20:52:49 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 24 Jul 2013 14:52:49 -0400
Subject: [R] Query on R plot : Unequispaced label on x-axis
In-Reply-To: <9eaa98f123a5c740183b77102af8e4b3.squirrel@www.isical.ac.in>
References: <9eaa98f123a5c740183b77102af8e4b3.squirrel@www.isical.ac.in>
Message-ID: <51F02281.5040209@gmail.com>

On 24/07/2013 10:06 AM, ritwik_r at isical.ac.in wrote:
> Dear R users,
>
> I want to plot a one variable continuous function f(x) vs x, x=[0,1]. Say
> for example: f(x)= x^2. Now, using the command plot(f~x) I will get a
> curve where the range of x-axis is [0,1] with all equispaced label. But, I
> need something else, and that is: my curve will be such that 80% on x-axis
> the range would be [0,0.5] and the rest 20% would contain [0.5,1]. Let me
> draw informally here. Say, the line below is my x-axis in graph and my
> plotting points are like:
>
>
>
>            ________________________________________
>            0     0.01      0.1        0.5         1
>
> Any help or suggestion will be highly appreciable.

Construct a function pos(x) that takes the x values and converts them 
into the position on the axis that you want.  For example,

pos <- function(x) log(x + 0.001)

plot(pos(x), y, xaxt="n")

will plot the transformed values, with no x axis labels.  To get the 
labels, use

xvals <- c(0, 0.01, 0.1, 0.5, 1)  # or whatever makes sense
axis(1, at=pos(xvals), labels=xvals)

Duncan Murdoch


From macqueen1 at llnl.gov  Wed Jul 24 21:26:01 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Wed, 24 Jul 2013 19:26:01 +0000
Subject: [R] List Structure and Acces to data
In-Reply-To: <51EE837C0200002D0001855B@mailhub1.vs.ch>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521914AF532@PRDEXMBX-08.the-lab.llnl.gov>

What you are doing looks like it is probably more complicated than
necessary, but since I have no idea what structure you intend to create,
it is hard to say.

Here is a suggestion:

try this:

 str(my_echant_hist)

It will give you a summary of the structure of that object, which should
help you understand how to access its elements.

The expression
  my_echant_hist[[1]][[2]]
makes sense if my_enchant_hist is a list, and if its first element is also
a list. Then you're asking for the second element within the first element.

There is nothing in R syntax that I know of that gives meaning to any of
these
  my_echant_hist[[]]
  my_echant_hist[[:]]
  my_echant_hist[[;]]
so I don't know what you were trying to get.

I do suggest studying documentation for syntax related to using '['. Type
  ?'['
or
  help('[')

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/23/13 4:22 AM, "Eric TRAVAGLINI" <Eric.TRAVAGLINI at crealp.vs.ch> wrote:

>Hello,
> 
>I used some other langages as Matlab and i just began with R, and i need
>help with data structure.
> 
>Here is my code
> 
>"
>fct_echant_hist <- function ( my_echant, my_vitesse, my_hist, my_summary)
>{
>	  list (my_echant = my_echant,
>		my_vitesse = my_vitesse,
>		my_hist = my_hist,
>		my_summary = my_summary)}
> 
> 
>my_echant_hist <- replicate(dim(pas)[1], fct_echant_hist(0L,
>			   0L,
>			   matrix(nrow=length(my_breaks),ncol=1),
>			   matrix(nrow=6,ncol=1)),
>	   simplify=FALSE)
>" 
>Is it possible to acces to all data of my_vitesse ?
> 
> 
>to acces to the my_vitesse of the first record i write
>my_echant_hist[[1]][[2]]
> 
>I try something like that without succes :
>my_echant_hist[[]][[2]] or
>my_echant_hist[[:]][[2]] or
>my_echant_hist[[;]][[2]]
> 
> 
>Thanks a lot
> 
>Eric ./.
> 
>P:S Sorry for my English


From Jonathan at immersyve.com  Wed Jul 24 20:49:41 2013
From: Jonathan at immersyve.com (GameRed)
Date: Wed, 24 Jul 2013 11:49:41 -0700 (PDT)
Subject: [R] =?utf-8?q?Utility_scores_from_mlogit/clo=E2=80=8Bgit_for_CBC?=
Message-ID: <1374691781222-4672253.post@n4.nabble.com>

Hello Everyone,

 I am a graduate student working on a CBC study. I want to give participants
3 choices per task with a None option, so I have been looking at doing a
multinomial or conditional logit model. My issue is that in my experience,
logistic regressions involve dummy coding or having levels of a factor
compare with a base level. So if you have a factor with 3 attributes, the
analysis yields 2 coeefficents which give their relation to the third
attribute. 

 
I thought that the utility scores were equal to the coeeficients, but when I
look at other analysis software such as XLstat or Sawtooth, they have a
utility score for each attribute. 
 
Can anyone explain where I am going wrong? I would greatly appreciate it.

 I have also considered using the rhierMnlRwMixture command in the bayesm
package, but can not figure out if I am setting up the data correctly. 

 

Thanks for your time,



--
View this message in context: http://r.789695.n4.nabble.com/Utility-scores-from-mlogit-clo-git-for-CBC-tp4672253.html
Sent from the R help mailing list archive at Nabble.com.


From dcarlson at tamu.edu  Wed Jul 24 21:59:30 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 24 Jul 2013 14:59:30 -0500
Subject: [R] List Structure and Acces to data
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521914AF532@PRDEXMBX-08.the-lab.llnl.gov>
References: <51EE837C0200002D0001855B@mailhub1.vs.ch>
	<5E1B812FAC2C4A49B3D99593B5A521914AF532@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <030e01ce88a8$4f633cb0$ee29b610$@tamu.edu>

I may not understand, but if you are looking for a way to
extract the second item from each list element, you will need
to use lapply():

a <- list(LETTERS[1:3], 10:12, LETTERS[26:24], 15:13)
b <- list(LETTERS[4:6], 15:17, LETTERS[23:21], 10:8)
c <- list(LETTERS[7:9], 20:22, LETTERS[20:18], 5:3)
abc <- list(a=a, b=b, c=c)
abc
# . . . Output deleted
abc[[1]][[2]]
# [1] 10 11 12
abc[["a"]][[2]]
# [1] 10 11 12
abc[[1:3]][[2]] # Does not work
# Error in abc[[1:3]][[2]] : subscript out of bounds
lapply(abc, "[[", 2)
# $a
# [1] 10 11 12
#
# $b
# [1] 15 16 17
#
# $c
# [1] 20 21 22
# or less cryptically lapply(abc, function(x) x[[2]])


-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of MacQueen,
Don
Sent: Wednesday, July 24, 2013 2:26 PM
To: Eric TRAVAGLINI; r-help at r-project.org
Subject: Re: [R] List Structure and Acces to data

What you are doing looks like it is probably more complicated
than
necessary, but since I have no idea what structure you intend
to create,
it is hard to say.

Here is a suggestion:

try this:

 str(my_echant_hist)

It will give you a summary of the structure of that object,
which should
help you understand how to access its elements.

The expression
  my_echant_hist[[1]][[2]]
makes sense if my_enchant_hist is a list, and if its first
element is also
a list. Then you're asking for the second element within the
first element.

There is nothing in R syntax that I know of that gives meaning
to any of
these
  my_echant_hist[[]]
  my_echant_hist[[:]]
  my_echant_hist[[;]]
so I don't know what you were trying to get.

I do suggest studying documentation for syntax related to
using '['. Type
  ?'['
or
  help('[')

-Don

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/23/13 4:22 AM, "Eric TRAVAGLINI"
<Eric.TRAVAGLINI at crealp.vs.ch> wrote:

>Hello,
> 
>I used some other langages as Matlab and i just began with R,
and i need
>help with data structure.
> 
>Here is my code
> 
>"
>fct_echant_hist <- function ( my_echant, my_vitesse, my_hist,
my_summary)
>{
>	  list (my_echant = my_echant,
>		my_vitesse = my_vitesse,
>		my_hist = my_hist,
>		my_summary = my_summary)}
> 
> 
>my_echant_hist <- replicate(dim(pas)[1], fct_echant_hist(0L,
>			   0L,
>
matrix(nrow=length(my_breaks),ncol=1),
>			   matrix(nrow=6,ncol=1)),
>	   simplify=FALSE)
>" 
>Is it possible to acces to all data of my_vitesse ?
> 
> 
>to acces to the my_vitesse of the first record i write
>my_echant_hist[[1]][[2]]
> 
>I try something like that without succes :
>my_echant_hist[[]][[2]] or
>my_echant_hist[[:]][[2]] or
>my_echant_hist[[;]][[2]]
> 
> 
>Thanks a lot
> 
>Eric ./.
> 
>P:S Sorry for my English

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From brt381 at mail.usask.ca  Wed Jul 24 22:06:46 2013
From: brt381 at mail.usask.ca (brt)
Date: Wed, 24 Jul 2013 13:06:46 -0700 (PDT)
Subject: [R] Perform task on error
Message-ID: <1374696406949-4672258.post@n4.nabble.com>

I have a web service that uses an R script to perform the analysis.  At the
end of the R script, I use the system function to call an external (perl)
script that sends the user an e-mail telling them that their analysis has
finished running, and where they can download the results.  However, if the
R script crashes (say...

Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, 
: 
  line 5 did not have 42 elements
Calls: as.matrix -> read.table -> scan
Execution halted

), I want the R script to call an external script that will e-mail the user
telling them that an error has occurred. I do not want to use try-catch
blocks because I want this to happen no matter what/where the error, and
because the script is large and it would be unwieldy to try to catch
specific things. Is this possible, and if so, how?

Thank you very much in advance for any help!



--
View this message in context: http://r.789695.n4.nabble.com/Perform-task-on-error-tp4672258.html
Sent from the R help mailing list archive at Nabble.com.


From nicola.rossi20 at gmail.com  Wed Jul 24 22:30:36 2013
From: nicola.rossi20 at gmail.com (Nicola Rossi)
Date: Wed, 24 Jul 2013 22:30:36 +0200
Subject: [R] SpatialPolygonsDataFrame and unique()
Message-ID: <CAAkGiTXMUhyzzLQx7iDrtbLi_BqoQyoPXxm9OUpPU7gxgA9ZPw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/ff4e1f2c/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jul 24 23:47:07 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 24 Jul 2013 22:47:07 +0100
Subject: [R] How to split two levels several times?
In-Reply-To: <trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>
Message-ID: <51F04B5B.2010702@sapo.pt>

Hello,

As for the first question, note that in the case you describe, the 
resulting list of df's will not be a split of the original, there will 
be a duplication in the final 4-1 and 1-3. The following is a hack but 
will do it.


lens <- rle(as.character(XXX$electrode))$lengths
m <- length(lens) %/% 2
idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
if(length(lens) %% 2 != 0)
	idx <- c(idx, rep(m + 1, lens[length(lens)]))

sp <- split(XXX, idx)

if(length(lens) %% 2 != 0){
	idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
	sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
}
sp


As for the second question, I'm not understanding it, can you post 
sample output?

Rui Barradas

Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
> Hi Rui
> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
>
> lens <- rle(as.character(XXX$electrode))$lengths
> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
>
> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
>
>
> This is the table "XXX"
>
> electrode length
>
> electrode1 5.7
> electrode1 6.3
> electrode1 6.2
> electrode2 11.4
> electrode2 9.7
> electrode3 14.2
> electrode3 14.8
> electrode3 12.6
> electrode2 11.4
> electrode2 9.7
> electrode4 17.0
> electrode4 16.3
> electrode4 17.8
> electrode4 18.3
> electrode4 16.9
> electrode4 18.5
> electrode1 5.7
> electrode1 6.3
> electrode1 6.2
> electrode1 5.7
> electrode1 6.3
> electrode1 6.2
> electrode3 14.2
> electrode3 14.8
> electrode3 12.6
>
>
> This is a simplified table XX
>
> electrode1
> electrode2
> electrode1
> electrode3
> electrode1
> electrode4
> electrode2
> electrode1
> electrode2
> electrode3
> electrode2
> electrode4
> electrode3
> electrode1
> electrode3
> electrode2
> electrode3
> electrode4
> electrode4
> electrode1
> electrode4
> electrode2
> electrode4
> electrode3
>
>
>
>
>
>
>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>> An: dennis1991 at gmx.net
>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
>>
>> Hello,
>>
>> It's better if you keep this on the list, the odds of getting more and
>> better answers are greater.
>>
>> As for your new question, try the following.
>>
>>
>> lens <- rle(as.character(XXX$electrode))$lengths
>> m <- length(lens) %/% 2
>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
>> split(XXX, idx)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
>>> Hi
>>> this type of splitting works for my specific example. Thanks for your help.
>>>
>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,  electrode3-electrode2,  electrode4-electrode1. How should I split this?
>>>
>>>
>>> This is the table "XXX"
>>>
>>> electrode length
>>>
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode3 14.2
>>> electrode3 14.8
>>> electrode3 12.6
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode4 17.0
>>> electrode4 16.3
>>> electrode4 17.8
>>> electrode4 18.3
>>> electrode4 16.9
>>> electrode4 18.5
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>>
>>>
>>>
>>>
>>>
>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>>>> An: dennis1991 at gmx.net
>>>> Cc: r-help at r-project.org
>>>> Betreff: Re: [R] How to split two levels several times?
>>>>
>>>> Hello,
>>>>
>>>> Sorry, I've just realized that your data frame is named 'XXX', not
>>>> 'dat'. Change that and the rest should work:
>>>>
>>>>
>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
>>>> split(XXX, idx)
>>>>
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
>>>>> Hello,
>>>>>
>>>>> Try the following.
>>>>>
>>>>>
>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
>>>>> split(dat, idx)
>>>>>
>>>>>
>>>>> Hope this helps,
>>>>>
>>>>> Rui Barradas
>>>>>
>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
>>>>>> Hi,
>>>>>>
>>>>>> I have a small problem with the function split() and would appreciate
>>>>>> your help.
>>>>>>
>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
>>>>>> split the table always at the row where ?electrode1? starts again so
>>>>>> that I can export 7  individual dataframes (numbered ?dataframe1? to
>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
>>>>>> I tried the split function with various setups:
>>>>>>
>>>>>> t <- as.factor(XXX$electrode)
>>>>>>
>>>>>> dataframeX <- split(XXX, f=(levels=t))
>>>>>>
>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
>>>>>>
>>>>>>
>>>>>> This is the table "XXX"
>>>>>>
>>>>>> electrode    length
>>>>>>
>>>>>> electrode1    5.7
>>>>>> electrode1    6.3
>>>>>> electrode1    6.2
>>>>>> electrode2    11.4
>>>>>> electrode2    9.7
>>>>>> electrode1    5.7
>>>>>> electrode1    6.3
>>>>>> electrode1    6.2
>>>>>> electrode3    14.2
>>>>>> electrode3    14.8
>>>>>> electrode3    12.6
>>>>>> electrode1    5.7
>>>>>> electrode1    6.3
>>>>>> electrode1    6.2
>>>>>> electrode4    17.0
>>>>>> electrode4    16.3
>>>>>> electrode4    17.8
>>>>>> electrode4    18.3
>>>>>> electrode4    16.9
>>>>>> electrode4    18.5
>>>>>> electrode1    ....
>>>>>> ....        ....
>>>>>> electrode5    ....
>>>>>> ....        ....
>>>>>> electrode1    ....
>>>>>> electrode6    ....
>>>>>> electrode1    ....
>>>>>> electrode7    ....
>>>>>> electrode1    ....
>>>>>> electrode8    ....
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-help at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>> PLEASE do read the posting guide
>>>>>> http://www.R-project.org/posting-guide.html
>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-help at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>> PLEASE do read the posting guide
>>>>> http://www.R-project.org/posting-guide.html
>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>


From tgs.public.mail at gmail.com  Thu Jul 25 00:30:12 2013
From: tgs.public.mail at gmail.com (Thomas Stewart)
Date: Wed, 24 Jul 2013 18:30:12 -0400
Subject: [R] non-conformable arrays
In-Reply-To: <CAOLvsEy6PzgHpjS=RwOFEfTSzSDEy=Z00=rmAk37Nrw0MCKKvw@mail.gmail.com>
References: <CAOLvsEy6PzgHpjS=RwOFEfTSzSDEy=Z00=rmAk37Nrw0MCKKvw@mail.gmail.com>
Message-ID: <CAHJ=y96DSPivohMcrk7XLV4OuHzFfsKq+mC1WJJ9qotaYS96LA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/c454b0f7/attachment.pl>

From mackay at northnet.com.au  Thu Jul 25 00:40:01 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Thu, 25 Jul 2013 08:40:01 +1000
Subject: [R] .eps files and powerpoint
In-Reply-To: <98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
Message-ID: <201307242240.r6OMe6A0000414@mail15.tpg.com.au>

Hi Marc

I sometimes had trouble with postscript and pdf files with lattice 
and I printed with trellis.device(device = pdf, ...) or 
trellis.device(device = postscript, ...)

I wonder if this is the case here

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


At 03:22 25/07/2013, you wrote:
>Hi Rich,
>
>That's curious.
>
>I noted that you are using barchart() below which is lattice versus 
>base graphics. Is there any difference in the result on Windows if 
>you use barplot() instead? If so, perhaps there is something about 
>lattice graphics in this context.
>
>Also, are you using Office 2008 or Office 2011 on your Mac? 2011 
>substantially improved Windows file format compatibility, not to 
>mention a plethora of bug fixes.
>
>Regards,
>
>Marc
>
>
>On Jul 24, 2013, at 11:37 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>
> > Marc,
> >
> > very interesting.
> >
> > Your example works on Windows.  This example doesn't work on windows
> >
> >> postscript(file = "file2.eps", height = 4, width = 4,
> > +                 horizontal = FALSE, onefile = FALSE, paper = "special")
> >> barchart(1:3)
> >> dev.off()
> >
> > Several examples, including the real one I was having trouble with
> > previously, work on
> > PowerPoint on Mac.  They don't work on PowerPoint in Windows.
> >
> > More: I put some eps figures into PP on Mac (where they work) and then
> > saved the file and
> > opened it in PP on Windows.  They don't work on Windows.
> >
> > Since Windows PP users are the target audience at the moment, I will stay
> > with the res=300 png file.
> >
> > This is consistent with my other experiences with PP and Word for Mac,
> > compared to PP and
> > Word for Windows.  The two MS sets of programs are highly correlated, but
> > far from identical.
> >
> > When people send my PP or Word files, I am more likely to open them first
> > on the Mac side of my
> > machine.  The graphs have spurious lines (connecting the end of the red
> > line to the beginning of
> > the green line, for example, when the two lines should be distinct).
> > Alignment is different
> > (two-line titles will get folded at the wrong place).  I need to move back
> > to the Windows side in
> > the VM to see the files as the author intended.
> >
> > Rich
> >
> >
> > On Wed, Jul 24, 2013 at 12:16 PM, Marc Schwartz 
> <marc_schwartz at me.com>wrote:
> >
> >> Hi Rich,
> >>
> >> Seems to work for me using Powerpoint in MS Office 2011 for Mac.
> >>
> >> I used the following code:
> >>
> >> postscript(file = "file.eps", height = 4, width = 4,
> >>                horizontal = FALSE, onefile = FALSE, paper = "special")
> >>
> >> plot(rnorm(20))
> >>
> >> dev.off()
> >>
> >>
> >>
> >> Then I used the insert picture from file function in Powerpoint. It
> >> created the PNG preview during import and I can see that on the slide in
> >> the application without issue.
> >>
> >> I put the EPS file and the PPTX file up on DropBox if you want to look at
> >> them:
> >>
> >> EPS File: https://www.dropbox.com/s/d8avze4yv51blso/file.eps
> >>
> >> PPTX file: https://www.dropbox.com/s/pm7oejm0g6rc0a5/RPlot.pptx
> >>
> >>
> >> Regards,
> >>
> >> Marc
> >>
> >>
> >>
> >> On Jul 24, 2013, at 10:49 AM, "Richard M. Heiberger" <rmh at temple.edu>
> >> wrote:
> >>
> >> Thanks Marc,
> >>
> >> the extra arguments to postscript still don't produce something that
> >> PowerPoint will accept.
> >> With your call, PP still displayed only the icon.  PP did not generate its
> >> own png file.
> >>
> >> Since my immediate goal is the projection screen for a PowerPoint
> >> presentation, I will go
> >> directly to the png file.  For the proceedings and for paper I will
> >> continue to use the pdf file.
> >>
> >> Rich
> >>
> >> On Wed, Jul 24, 2013 at 11:36 AM, Marc Schwartz 
> <marc_schwartz at me.com>wrote:
> >>
> >>> Rich,
> >>>
> >>> You are missing some options in the call to postscript() below. It needs
> >>> to be:
> >>>
> >>>  postscript(file = "file.eps", width = x, height = y,
> >>>             horizontal = FALSE, onefile = FALSE, paper = "special")
> >>>
> >>> The first line needs to have values for 'x' and 'y' for the width and
> >>> height of the image, as they default to 0.
> >>>
> >>> The second line of 3 options are all critical to producing an EPS file,
> >>> as opposed to a PS file. This is described in the 4th paragraph of the
> >>> Details section of ?postscript.
> >>>
> >>> If you import that file into any of the MS Office products (typically
> >>> also for OpenOffce, LibreOffice, etc.), a PNG preview image 
> will be created
> >>> during import. It is the PNG bitmapped image that you can see when
> >>> displaying the EPS file in the document, hence the degradation 
> in quality.
> >>> Some years ago, all you would see is a rectangular box with an "X" across
> >>> it, as a placeholder for the imported image.
> >>>
> >>> Only if you then print the Office file using a Postscript printer driver,
> >>> will you see the actual vector based EPS image. The target of 
> that printing
> >>> operation could be a printer for hard copy, a PS or a PDF file. MS Office
> >>> does not support the rendering of the EPS image directly.
> >>>
> >>> If you are operating on Windows, as opposed to Linux or OSX, typically
> >>> EMF/WMF files are the easiest way to go in terms of sticking R plots into
> >>> an Office file, as they are also vector based images, but are effectively
> >>> Windows only.
> >>>
> >>> Regards,
> >>>
> >>> Marc Schwartz
> >>>
> >>>
> >>> On Jul 24, 2013, at 10:20 AM, Richard M. Heiberger <rmh at temple.edu>
> >>> wrote:
> >>>
> >>>> png("png300.png", res=300, width=2880, height=1440)
> >>>>
> >>>> gives good behavior.  Thank you.  This will become my standard for
> >>> export
> >>>> to powerpoint.
> >>>>
> >>>> postscript(file='file.eps', onefile=FALSE)
> >>>> produces eps files that powerpoint rejects, even though ghostview is
> >>>> satisfied.
> >>>>
> >>>> Rich
> >>>>
> >>>>
> >>>> On Wed, Jul 24, 2013 at 2:07 AM, Patrick Connolly <
> >>>> p_connolly at slingshot.co.nz> wrote:
> >>>>
> >>>>> On Tue, 23-Jul-2013 at 10:23PM -0400, Richard M. Heiberger wrote:
> >>>>>
> >>>>> |> I have colleagues who use powerpoint.  When I send my colleagues pdf
> >>>>> files
> >>>>> |> or ps files, powerpoint
> >>>>> |> rejects them.  Powerpoint does accept some eps files.
> >>>>> |>
> >>>>>
> >>>>> [...]
> >>>>>
> >>>>> |> Does anyone know a workaround that will get vector graphics from R
> >>> into
> >>>>> |> powerpoint?
> >>>>> |> win.metafile is not acceptable.  The resolution of emf files from R
> >>> is
> >>>>> |> worse than png files.
> >>>>>
> >>>>> Maybe worse than png files at the default resolution which is 72 dpi.
> >>>>> Change that to something like 300 and nobody will see a jagged edge in
> >>>>> a PowerPoint slide.
> >>>>>
> >>>>> HTH
> >>>>>
> >>>>>
> >>>>> |>
> >>>>> |> Thanks
> >>>>> |> Rich
> >>>
> >>>
> >>
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From mackay at northnet.com.au  Thu Jul 25 00:41:04 2013
From: mackay at northnet.com.au (Duncan Mackay)
Date: Thu, 25 Jul 2013 08:41:04 +1000
Subject: [R] x-axis (categorial variable) ordering with xyplot function
 (lattice package)
Message-ID: <201307242241.r6OMf9J2005126@mail15.tpg.com.au>

forgot to cc to list

Hi

For an xyplot you have not got the proper coding 
for the x value which should be numeric.

If you want to make a plot of the style of xyplot 
a numerical index of the country is needed and 
then use the scales argument to annote the labels with the country.
Do you want multiple panels ?

A self contained dataset via dput would help elicit further information.

Have a look at the outer and related arguments as 
well as the group arguments. A combined index for 
regions with countries may be necessary.

Regards

Duncan

Duncan Mackay
Department of Agronomy and Soil Science
University of New England
Armidale NSW 2351
Email: home: mackay at northnet.com.au


At 00:17 25/07/2013, you wrote:
>Content-Type: text/plain
>Content-Disposition: inline
>Content-length: 2322
>
>Dear R mailing list readers,
>
>I am facing the following problem; for 
>simplicity imagine I am working on a data frame 
>of, say, 5 columns. The first column is a list 
>of European countries, the other four are an 
>index (continuous variable) of climate change 
>impact under 4 different scenarios.
>
>Country
>
>2050B2
>
>2050A2
>
>2080B2
>
>2080A2
>
>Austria
>
>-0.2
>
>-0.6
>
>...
>
>
>
>Belgium
>
>-0.2
>
>-0.6
>
>
>
>
>
>Bulgaria
>
>-0.5
>
>-0.8
>
>
>
>
>
>Czech republic
>
>-0.5
>
>-0.8
>
>
>
>
>
>United kingdom
>
>-0.2
>
>-0.6
>
>
>
>
>
>
>I am using the package lattice to make a nice 
>plot of the dots from the different scenario using the following code;
>
>my.plot <- xyplot(2050B2+2050A2+2080B2+2080A2~country, data=my.dat,
>scales=list(x=list(rot=45)))
>
>note: the part "scales=list(x=list(rot=45))" is pure aesthetic here.
>
>So far, so good. However, I wish to order the 
>x-axis (countries) by grouping them by European 
>region; i.e Austria, Belgium and United kingdom 
>are western Europe, while Bulgaria and Czech 
>republic are eastern Europe. In excel I added a 
>new "region) variable (i.e 1 for Western Europe, 
>2 for eastern Europe) and I re-ordered my data 
>frame according to this "region" variable.
>
>I then imported this updated data frame in R, 
>and checked how it looked with the usual code;
>
>pot_dat <-read.csv(file.choose(),header=TRUE, sep=";",dec=".")
>pot_dat
>
>Again, so far so good; my second column 
>("country") is now ordered according to the 
>values of the first column ("region").
>
>Region
>
>Country
>
>2050B2
>
>2050A2
>
>2080B2
>
>2080A2
>
>1
>
>Austria
>
>-0.2
>
>-0.6
>
>...
>
>
>
>1
>
>Belgium
>
>-0.2
>
>-0.6
>
>
>
>
>
>1
>
>United Kingdom
>
>-0.2
>
>-0.6
>
>
>
>
>
>2
>
>Bulgaria
>
>-0.5
>
>-0.8
>
>
>
>
>
>2
>
>Czech republic
>
>-0.5
>
>-0.8
>
>
>
>
>
>
>
>However, when I try to use the code as above, R 
>automatically re-order the x-axis (country) in 
>alphabetical order. This was not unexpected, but 
>I have spent the day (unsuccessfully) looking 
>for a way to simply tell R not to do that and to 
>keep the variable "country" as it is now ordered 
>in the data frame to construct the x-axis of my 
>plot. Is there any way to force it to keep the 
>order as it is in the data frame ?
>
>Any help would be really welcomed !
>
>Best,
>
>Arnaud Blaser
>PhD candidate
>University of Neuch?tel
>Institute of Economic Research (IRENE)
>Pierre-?-Mazel 7
>CH-2000 Neuch?tel
>
>
>         [[alternative HTML version deleted]]
>
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tgs.public.mail at gmail.com  Thu Jul 25 00:50:19 2013
From: tgs.public.mail at gmail.com (Thomas Stewart)
Date: Wed, 24 Jul 2013 18:50:19 -0400
Subject: [R] Perform task on error
In-Reply-To: <1374696406949-4672258.post@n4.nabble.com>
References: <1374696406949-4672258.post@n4.nabble.com>
Message-ID: <CAHJ=y972aeqTOQq_pcV9wTvCH8fAUquMDxAFyKR4B7u8wtEn2A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/710fc911/attachment.pl>

From jim at bitwrit.com.au  Thu Jul 25 01:56:30 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 25 Jul 2013 09:56:30 +1000
Subject: [R] x-axis (categorial variable) ordering with xyplot function
 (lattice package)
In-Reply-To: <4797A3DC820212418B235B3ED20FAF071CA1D4@MAIL-MBX-05.UNINE.CH>
References: <4797A3DC820212418B235B3ED20FAF071CA1D4@MAIL-MBX-05.UNINE.CH>
Message-ID: <51F069AE.6040802@bitwrit.com.au>

On 07/25/2013 12:17 AM, BLASER Arnaud wrote:
> Dear R mailing list readers,
>
> I am facing the following problem; for simplicity imagine I am working on a data frame of, say, 5 columns. The first column is a list of European countries, the other four are an index (continuous variable) of climate change impact under 4 different scenarios.
>
> ...
> However, when I try to use the code as above, R automatically re-order the x-axis (country) in alphabetical order. This was not unexpected, but I have spent the day (unsuccessfully) looking for a way to simply tell R not to do that and to keep the variable "country" as it is now ordered in the data frame to construct the x-axis of my plot. Is there any way to force it to keep the order as it is in the data frame ?
>
Hi Arnaud,
If you want a non-alphabetic ordering of factors, you will have to 
explicitly specify the order:

country<-factor(
c("Austria","Belgium","Bulgaria","Czech Republic","United Kingdom"),
levels=c("Austria","Belgium","United Kingdom","Bulgaria",
"Czech Republic"))

Jim


From harb at student.unimelb.edu.au  Thu Jul 25 03:54:28 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Thu, 25 Jul 2013 11:54:28 +1000
Subject: [R] Help to improve prediction from supervised mapping using
 kohonen package
In-Reply-To: <CAGYnQNSq3iaNtBUyN8+yG+3zyMAyKykHp4+FkXgSgG4r+WLcCg@mail.gmail.com>
References: <CAGYnQNT_RYHTFQXx_ByfcXLhJoXKNDDKajnq_=kH2kYmEW3e4g@mail.gmail.com>
	<AA818EAD2576BC488B4F623941DA7427CD314774@inbomail.inbo.be>
	<CAGYnQNSq3iaNtBUyN8+yG+3zyMAyKykHp4+FkXgSgG4r+WLcCg@mail.gmail.com>
Message-ID: <CAGYnQNSYeaQtdqyMxwV45FcNtmFysSpkY8pc-2__VfafWR8ivw@mail.gmail.com>

On 24 July 2013 21:32, Ben Harrison <harb at student.unimelb.edu.au> wrote:
> On 24 July 2013 19:25, ONKELINX, Thierry <Thierry.ONKELINX at inbo.be> wrote:
>> Try rescaling your data prior to splitting it up into a training and test set. Otherwise you end up with two different ways of scaling.

> I still cannot understand how I can sensibly revert the scaling of the values.

I understand more now about the scaling attributes. I think the
following fixes my earlier errors:

# Unscale the predictions:
descale <- attr(testing, 'scaled:scale')[["MEAS_TC"]]
decentre <- attr(testing, 'scaled:center')[["MEAS_TC"]]
predicted.tc <- lapply(tc.xyf.prediction$prediction, function(x) x *
descale + decentre)


From alamont082 at gmail.com  Thu Jul 25 03:41:37 2013
From: alamont082 at gmail.com (Andrea Lamont)
Date: Wed, 24 Jul 2013 21:41:37 -0400
Subject: [R] flexible approach to subsetting data
In-Reply-To: <01cc01ce87e7$b08340b0$1189c210$@tamu.edu>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>
	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>
	<F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>
	<F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>
	<01cc01ce87e7$b08340b0$1189c210$@tamu.edu>
Message-ID: <CALxSy07CaJDRbM6ejOZq1iAM1xJ3Q+aOZruOP181iZBwK4ORXg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130724/4f7abafe/attachment.pl>

From xhl860728 at 163.com  Thu Jul 25 05:15:55 2013
From: xhl860728 at 163.com (=?GBK?B?us7BwQ==?=)
Date: Thu, 25 Jul 2013 11:15:55 +0800 (CST)
Subject: [R] [packages Sensitivity] Fast99 function,why model runs only 1
Message-ID: <261dcb05.4440.14013d3643a.Coremail.xhl860728@163.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/be9ec157/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 25 05:53:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 24 Jul 2013 20:53:48 -0700 (PDT)
Subject: [R] flexible approach to subsetting data
In-Reply-To: <CALxSy07CaJDRbM6ejOZq1iAM1xJ3Q+aOZruOP181iZBwK4ORXg@mail.gmail.com>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>	<F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>	<F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>	<01cc01ce87e7$b08340b0$1189c210$@tamu.edu>
	<CALxSy07CaJDRbM6ejOZq1iAM1xJ3Q+aOZruOP181iZBwK4ORXg@mail.gmail.com>
Message-ID: <1374724428.15562.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
It works in small dataset.
rt<- structure(list(sim = c(1L, 1L, 1L, 2L, 2L, 2L), txt.y.obs = c(5L, 
4L, 3L, 6L, 7L, 9L), cont.y.obs = c(4L, 3L, 9L, 4L, 8L, 6L), 
??? ID = 1:6, obs.txt = c(5L, 2L, 4L, 8L, 4L, 7L), TE = c(5L, 
??? 7L, 4L, 3L, 5L, 8L), X1 = c(1L, 1L, 1L, 2L, 2L, 2L), sim.1 = c(4L, 
??? 7L, 5L, 3L, 5L, 9L), txt.y.obs.1 = c(3L, 5L, 7L, 9L, 5L, 
??? 4L), cont.y.obs.1 = c(3L, 4L, 8L, 9L, 4L, 5L), ID.1 = 1:6, 
??? obs.txt.1 = c(7L, 1L, 4L, 5L, 8L, 6L), TE.1 = c(5L, 6L, 3L, 
??? 4L, 9L, 10L), X1.1 = c(6L, 4L, 3L, 8L, 5L, 6L)), .Names = c("sim", 
"txt.y.obs", "cont.y.obs", "ID", "obs.txt", "TE", "X1", "sim.1", 
"txt.y.obs.1", "cont.y.obs.1", "ID.1", "obs.txt.1", "TE.1", "X1.1"
), class = "data.frame", row.names = c(NA, -6L))



rtr<-reshape(rt,? direction="long",
varying=list(
sim=grepl("sim", names(rt)),
txt.y.obs=grepl("txt.y.obs", names(rt)),
cont.y.obs=grepl("cont.y.obs", names(rt)),
ID=grepl("ID", names(rt)),
obs.txt=grepl("obs.txt", names(rt)),
TE=grepl("TE", names(rt)),
X1=grepl("X1", names(rt))),
v.names=
c("sim","txt.y.obs","cont.y.obs","ID","obs.txt", "TE", "X1"),
timevar="imputation")



#Using a bigger dataset:
set.seed(48)
rtNew<- as.data.frame(matrix(sample(1:50,405*5,replace=TRUE),ncol=405))
colnames(rtNew)<-paste0(gsub("\\d+","",colnames(rtNew)),1:81)
colnames(rtNew)[-c(1:81)]<-paste(colnames(rtNew)[-c(1:81)],rep(1:4,each=81),sep=".")
res<- reshape(rtNew,direction="long",varying=list(V1=grepl("V1",names(rtNew)),
V2=grepl("V2",names(rtNew)),V3=grepl("V3",names(rtNew)),V4=grepl("V4",names(rtNew)),
V5=grepl("V5",names(rtNew)),V6=grepl("V6",names(rtNew)),V7=grepl("V7",names(rtNew))),
v.names=c("V1","V2","V3","V4","V5","V6","V7"),timevar="imputation")
#works

#When I forgot to close the list bracket:

reshape(rtNew,direction="long",varying=list(V1=grepl("V1",names(rtNew)),
V2=grepl("V2",names(rtNew)),V3=grepl("V3",names(rtNew)),V4=grepl("V4",names(rtNew)),
V5=grepl("V5",names(rtNew)),V6=grepl("V6",names(rtNew)),V7=grepl("V7",names(rtNew)),
v.names=c("V1","V2","V3","V4","V5","V6","V7"),timevar="imputation"))
#Error in reshapeLong(data, idvar = idvar, timevar = timevar, varying = varying,? : 
?# 'varying' arguments must be the same length
Though, your code looks fine with respect to closing brackets.
A.K.




----- Original Message -----
From: Andrea Lamont <alamont082 at gmail.com>
To: David Carlson <dcarlson at tamu.edu>
Cc: R help <r-help at r-project.org>
Sent: Wednesday, July 24, 2013 9:41 PM
Subject: Re: [R] flexible approach to subsetting data

Hi, all:

I have a follow-up question.

I have 81 variables in my dataset (all of which are repeated).? Reshape
seems to give me an error whenever more than six variables are used. The
error message is this: Error in reshapeLong(data, idvar = idvar,
timevar =timevar
, varying = varying, : 'varying arguments must be the same length.

I have tested the lengths of all the variables, and they are all equal.
Further, when I mix up the variables used in the reshape function, it
works -- so long as I keep the number of variables used under six. As soon
as I add the seventh variable (regardless of what it is), I receive this
error.


#This works:
rtr<-reshape(rt,? direction="long",
varying=list(
sim=grepl("sim", names(rt)),
txt.y.obs=grepl("txt.y.obs", names(rt)),
cont.y.obs=grepl("cont.y.obs", names(rt)),
ID=grepl("ID", names(rt)),
obs.txt=grepl("obs.txt", names(rt)),
TE=grepl("TE", names(rt))),
v.names=
c("sim","txt.y.obs","cont.y.obs","ID","obs.txt", "TE"),
timevar="imputation")



#The addition of one more variable creates an error. The problem is not
with X1.
rtr<-reshape(rt,? direction="long",
varying=list(
sim=grepl("sim", names(rt)),
txt.y.obs=grepl("txt.y.obs", names(rt)),
cont.y.obs=grepl("cont.y.obs", names(rt)),
ID=grepl("ID", names(rt)),
obs.txt=grepl("obs.txt", names(rt)),
TE=grepl("TE", names(rt)),
X1=grepl("X1", names(rt))),
v.names=
c("sim","txt.y.obs","cont.y.obs","ID","obs.txt", "TE", "X1"),
timevar="imputation")




On Tue, Jul 23, 2013 at 5:00 PM, David Carlson <dcarlson at tamu.edu> wrote:

> Actually the ".0" on the first variable is not needed.
>
> You could modify the reshape() call to search for the base
> name of each variable so you would not need to change the code
> if the number of replications changes:
>
> reshape(df5,? direction="long", v.names=c("dose", "resp"),
>? ? ? ?  varying=list(dose=grepl("dose", names(df5)),
>? ? ? ?  resp=grepl("resp", names(df5)) )
>? ? ?  )
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Tuesday, July 23, 2013 1:12 PM
> To: David Winsemius
> Cc: R help; Andrea Lamont
> Subject: Re: [R] flexible approach to subsetting data
>
>
> On Jul 23, 2013, at 10:49 AM, David Winsemius wrote:
>
> >
> > On Jul 23, 2013, at 10:01 AM, Adams, Jean wrote:
> >
> >> Check out the reshape() function of the reshape package.
> Here's one of the
> >> examples from ?reshape.
> >>
> >> Jean
> >>
> >>
> >> library(reshape)?  # No,? at least not for the
> reshape-function
> >
> > The reshape function is from the 'base' package. The
> 'reshape' and 'reshape2' packages were written (at least in
> part) because the 'reshape'-function was so difficult to
> understand.
> >
> > If you do choose to use the reshape2 package, which is
> well-respected and often extremely helpful, the function you
> will want to start with is 'melt'.
> >
> >
> >> long <- reshape(wide, direction="long")
> >
> > I don't think this example will be particularly helpful
> since the initial direction is "long" (from "wide") and more
> input would be needed.
>
> Here's a dataset to experiment with
>
> df5 <- data.frame(dose.0 =
> c(40,50,60,50),resp.0=c(40,50,60,50),
>? dose.1 = c(1,2,1,2), resp.1=c(1,2,1,2)+3,
>? dose.2 = c(2,1,2,1), resp.2=c(1,2,1,2)+3,
>? dose.3 = c(3,3,3,3), resp.3=c(1,2,1,2)+3 )
>
> Notice that you would need add the ".0" to the column names
>
> reshape(df5,? direction="long",
>? ? ? ? ? ? ?  v.names=c("dose", "resp"),
>? ? ? ? ? ? ? ? varying=list(dose=c(1,3,5,7), resp=c(2,4,6,8) )
>? ? ? ?  )? # succeeds
>
>
>
> So perhaps could use similar call (after append the ".0"'s)
> with:
>
>?  varying=list(sim=seq(1,810,by=4),
>? ? ? ? ? ? ? ? X1= seq(2,810,by=4),
>? ? ? ? ? ? ? ? X2= seq(3,810,by=4),
>? ? ? ? ? ? ? ? X3= seq(4,810,by=4)
>? ? ? ? ? ? ? ? )
>
> >
> >
> >> wide
> >> long
> >>
> >>
> >>
> >> On Tue, Jul 23, 2013 at 9:35 AM, Andrea Lamont
> <alamont082 at gmail.com> wrote:
> >>
> >>> Hello:
> >>>
> >>> I am running a simulation study and am stuck with a
> subsetting problem.
> >>>
> >>> Here is the basic issue:
> >>> I generated data and am running a simulation that uses
> multiple imputation.
> >>> For each generated dataset, I used multiple imputation.
> The resultant
> >>> dataset is in wide for where each imputation is recorded
> as a separate
> >>> column (though the different simulations are stacked).
> Here is an example
> >>> of what it looks like:
> >>>
> >>> sim?  X1?  X2?  X3?  sim.1?  X1.1? ? X1.1? ? X3.1
> >
> >>> 1? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #
> #
> >>> 1? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #
> #
> >>> 1? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #
> #
> >>> 2? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #
> #
> >>> 2? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #
> #
> >>> 2? ? ? ?  #? ? #? ?  #? ? ? ? #? ? ? ? ?  #? ? ? ? ? #
> #
> >>>
> >>> sim refers to the simulated/generated dataset. X1-X3 are
> the values for the
> >>> first imputed dataset, X1.1-X3.1 are the values for the
> second imputed
> >>> dataset.
> >>>
> >>> The problem is that I want the data to be in long format,
> like this:
> >>>
> >>> sim m X1 X2 X3
> >>> 1? 1?  #?  #? ? #
> >>> 1? 2?  #?  #? ? #
> >>> 2? 1?  #?  #? ? #
> >>> 2? 2?  #?  #? ? #
> >>>
> >>> where m is the imputation number.
> >>> This will allow me to do cleaner calculations (e.g.
> X3-X1).
> >>>
> >>> I know I can subset the data manually - e.g. [,1:10] and
> save this to
> >>> separate datasets then? rbind; however, I'm looking for a
> more flexible
> >>> approach to do this.? This manual approach would be quite
> tedious as number
> >>> of imputations (and therefore number of columns) increased
> (with only 10
> >>> imputations, there are roughly 810 columns). Also,I would
> like to
> >>> avoid having to recode each time I change the number of
> imputations.
> >>>
> >>> THe same is true for the reshape function, which would
> require naming
> >>> a huge number of columns and edits each time 'm' changes.
> >
> > If the columns are named regularly, then 'reshape' will
> attempt to split properly without an explicit naming. Details
> and a better description of the problem might allow more
> specific answers to emerge. The fact that the first instances
> have no numeric indicators may be a problem for the algorithm.
>
> >
> > Why not post dput(head( dfrm[ ,1:12]))
> >
> > --
> > David.
> >
> >>>
> >>>
> >>> Is there a flexible way to approach this? I'm inclined to
> use a for loop,
> >>> but know that 1) this is generally inefficient and 2) am
> having trouble
> >>> with
> >>> the coding regardless.
> >>>
> >>> Any suggestions are appreciated.
> >>>
> >>> Thanks,
> >>> Andrea
> >>>
>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>
>


-- 
Andrea Lamont, MA
Clinical-Community Psychology
University of South Carolina
Barnwell College
Columbia, SC 29208

Please consider the environment before printing this email.

CONFIDENTIAL: This transmission is intended for the use of the
individual(s) or entity to which it is addressed, and may contain
information that is privileged, confidential, and exempt from disclosure
under applicable law. Should the reader of this message not be the intended
recipient(s), you are hereby notified that any dissemination, distribution,
or copying of this communication is strictly prohibited.? If you are not
the intended recipient, please contact the sender by reply email and
destroy/delete all copies of the original message.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From mrahmankufmrt at gmail.com  Thu Jul 25 05:56:59 2013
From: mrahmankufmrt at gmail.com (Moshiur Rahman)
Date: Thu, 25 Jul 2013 11:56:59 +0800
Subject: [R] Paternity data analysis problem
Message-ID: <CAGNSkSndCnLYmDw=u+MXic3yM2RZQxkyb1N2mR_3VZLz8HkYwQ@mail.gmail.com>

Hi R-helps,

I did an experiment with FAs ['High' and 'Zero'(no w-3) quality; n=24 for
each group]. Then I did AI to see their sperm competitiveness based on
their paternity performance. My data is as below where Fish ID- Blind ID
for each fish; Group ID- Dietary group ID; Diet quality - High=1, zero=0;
Babies for paternity- total no. of babies got from females; Success -
Babies shared/paterned by focal male; Failure - Babies shared/paterned by
competitor, Proportion - Success/(Success+Failure), and the predictor
traits are Viability, CASA PC1 and Body FAs. I?d like to examin:

 1) effects of diet on paternity performance of fish (either high/low or
both);

2) effects of predictor traits on paternity success.

I ran the attached  codes to have my result sbut each model gives me
different results with overdispersion. So, can you help me to give me some
valuable suggesions to solve this problem. I'll really appreciate your kind
assistance and will be grateful to you.

With kind regards,
Moshi



-- 
MD. MOSHIUR RAHMAN
PhD Candidate
School of Animal Biology/Zoology (M092)
University of Western Australia
35 Stirling Hwy, Crawley, WA, 6009
Australia.
Mob.: 061-425205507

From orvaquim at gmail.com  Thu Jul 25 06:24:28 2013
From: orvaquim at gmail.com (Orvalho Augusto)
Date: Thu, 25 Jul 2013 06:24:28 +0200
Subject: [R] [R-pkgs] WriteXLS Version 3.0.0 Released
In-Reply-To: <533E5385-BCB9-4F8E-9443-BC9217622EA3@me.com>
References: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>
	<1374619209185-4672180.post@n4.nabble.com>
	<533E5385-BCB9-4F8E-9443-BC9217622EA3@me.com>
Message-ID: <CAF4WX-d83vJJJ2VhsQBzyToES-Z_Z8i+TRotEAqOFx_=NVDt5A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/86c06fe8/attachment.pl>

From michel.arnaud at cirad.fr  Thu Jul 25 08:06:11 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 25 Jul 2013 08:06:11 +0200
Subject: [R] Change values in a dateframe-Speed TEST
In-Reply-To: <1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <51EF76AA.7000803@cirad.fr>
	<1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <51F0C053.10603@cirad.fr>

Hi

For a dataframe with name PaysContrat1 and with
nrow(PaysContrat1)
[1] 52366

the test of system.time is :

system.time(droplevels(do.call(rbind,lapply(split(PaysContrat1,PaysContrat1$Matricule),
FUN=function(x) {x[,c("Nom","Pr?nom")] <- 
x[nrow(x),c("Nom","Pr?nom"),drop=TRUE];x}))))
    user  system elapsed
   14.03    0.00   14.04

system.time(droplevels(PaysContrat1[with(PaysContrat1,ave(seq_along(Matricule),Matricule,FUN=min)) 
,]  ))
    user  system elapsed
     0.2     0.0     0.2

Michel

Le 24/07/2013 15:29, arun a ?crit :
> Hi Michel,
> You could try:
>
>
> df1New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=min)),])
> row.names(df1New)<-1:nrow(df1New)
> df2New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=max)),])
> row.names(df2New)<-1:nrow(df2New)
>   identical(df1New,df1)
> #[1] TRUE
>   identical(df2New,df2)
> #[1] TRUE
> A.K.
>
>
>
> ----- Original Message -----
> From: Arnaud Michel <michel.arnaud at cirad.fr>
> To: R help <r-help at r-project.org>
> Cc:
> Sent: Wednesday, July 24, 2013 2:39 AM
> Subject: [R] Change values in a dateframe
>
> Hello
>
> I have the following problem :
> The dataframe TEST has multiple lines for a same person because :
> there are differents values of Nom or differents values of Prenom
> but the values of Matricule or Sexe or Date.de.naissance are the same.
>
> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
> "factor"),
>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
> "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
> row.names = c(NA,
> -11L))
>
>
> I would want to make homogeneous the information and would like built 2
> dataframes :
> df1 wich has the value of Nom and Prenom of the first lines of TEST when
> there are different values. The other values (Matricule or Sexe or
> Date.de.naissance) are unchanged
>
> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom =
> structure(c(6L,
> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
> "factor"),
>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
> "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
> row.names = c(NA,
> -11L))
>
> df2 wich has the value of Nom and Prenom of the last lines of TEST when
> there are different values. The other values (Matricule or Sexe or
> Date.de.naissance) are unchanged.
>
> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>       Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>       5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>       "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe =
> structure(c(1L,
>       1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>       "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
>       2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>       "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
>       "30/03/1935"), class = "factor")), .Names = c("Matricule",
> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
> row.names = c(NA,
> -11L))
>
> Thank for your helps
> Michel
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From michel.arnaud at cirad.fr  Thu Jul 25 08:35:56 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 25 Jul 2013 08:35:56 +0200
Subject: [R] Change values in a dateframe-Speed TEST
In-Reply-To: <51F0C053.10603@cirad.fr>
References: <51EF76AA.7000803@cirad.fr>
	<1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51F0C053.10603@cirad.fr>
Message-ID: <51F0C74C.7070404@cirad.fr>

But I just noticed that the two solutions are not comparable :
the change concern only Nom and Prenom (solution Berend) and not also 
Sexe or Date.de.naissance orother variables (solution Arun) that can 
changed. But my question was badly put.
Michel

Le 25/07/2013 08:06, Arnaud Michel a ?crit :
> Hi
>
> For a dataframe with name PaysContrat1 and with
> nrow(PaysContrat1)
> [1] 52366
>
> the test of system.time is :
>
> system.time(droplevels(do.call(rbind,lapply(split(PaysContrat1,PaysContrat1$Matricule), 
>
> FUN=function(x) {x[,c("Nom","Pr?nom")] <- 
> x[nrow(x),c("Nom","Pr?nom"),drop=TRUE];x}))))
>    user  system elapsed
>   14.03    0.00   14.04
>
> system.time(droplevels(PaysContrat1[with(PaysContrat1,ave(seq_along(Matricule),Matricule,FUN=min)) 
> ,]  ))
>    user  system elapsed
>     0.2     0.0     0.2
>
> Michel
>
> Le 24/07/2013 15:29, arun a ?crit :
>> Hi Michel,
>> You could try:
>>
>>
>> df1New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=min)),]) 
>>
>> row.names(df1New)<-1:nrow(df1New)
>> df2New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=max)),]) 
>>
>> row.names(df2New)<-1:nrow(df2New)
>>   identical(df1New,df1)
>> #[1] TRUE
>>   identical(df2New,df2)
>> #[1] TRUE
>> A.K.
>>
>>
>>
>> ----- Original Message -----
>> From: Arnaud Michel <michel.arnaud at cirad.fr>
>> To: R help <r-help at r-project.org>
>> Cc:
>> Sent: Wednesday, July 24, 2013 2:39 AM
>> Subject: [R] Change values in a dateframe
>>
>> Hello
>>
>> I have the following problem :
>> The dataframe TEST has multiple lines for a same person because :
>> there are differents values of Nom or differents values of Prenom
>> but the values of Matricule or Sexe or Date.de.naissance are the same.
>>
>> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
>> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
>> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
>> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
>> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
>> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>> "factor"),
>>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", 
>> "07/12/1947",
>>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>> "factor")), .Names = c("Matricule",
>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>> row.names = c(NA,
>> -11L))
>>
>>
>> I would want to make homogeneous the information and would like built 2
>> dataframes :
>> df1 wich has the value of Nom and Prenom of the first lines of TEST when
>> there are different values. The other values (Matricule or Sexe or
>> Date.de.naissance) are unchanged
>>
>> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
>> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
>> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom =
>> structure(c(6L,
>> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
>> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>> "factor"),
>>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", 
>> "07/12/1947",
>>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>> "factor")), .Names = c("Matricule",
>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>> row.names = c(NA,
>> -11L))
>>
>> df2 wich has the value of Nom and Prenom of the last lines of TEST when
>> there are different values. The other values (Matricule or Sexe or
>> Date.de.naissance) are unchanged.
>>
>> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
>> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
>> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>>       Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>>       5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>>       "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe =
>> structure(c(1L,
>>       1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>>       "Masculin"), class = "factor"), Date.de.naissance = 
>> structure(c(4L,
>>       2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>>       "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", 
>> "29/12/1936",
>>       "30/03/1935"), class = "factor")), .Names = c("Matricule",
>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>> row.names = c(NA,
>> -11L))
>>
>> Thank for your helps
>> Michel
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From bhh at xs4all.nl  Thu Jul 25 08:50:36 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Thu, 25 Jul 2013 08:50:36 +0200
Subject: [R] Change values in a dateframe-Speed TEST
In-Reply-To: <51F0C74C.7070404@cirad.fr>
References: <51EF76AA.7000803@cirad.fr>
	<1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51F0C053.10603@cirad.fr> <51F0C74C.7070404@cirad.fr>
Message-ID: <E8B9A235-FDE5-42E9-B551-B81D18DEC059@xs4all.nl>


On 25-07-2013, at 08:35, Arnaud Michel <michel.arnaud at cirad.fr> wrote:

> But I just noticed that the two solutions are not comparable :
> the change concern only Nom and Prenom (solution Berend) and not also Sexe or Date.de.naissance orother variables (solution Arun) that can changed. But my question was badly put.

Indeed:-)

But that can be remedied with (small correction w.r.t. initial solution: drop=TRUE removed; not relevant here)

r1 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
                    FUN=function(x) {x[,1:ncol(x)] <- x[1,1:ncol(x)];x})))

and

r2 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
                    FUN=function(x) {x[,1:ncol(x)] <- x[nrow(x),1:ncol(x)];x})))

Less elegant than alternative with ave

Berend

> Michel
> 
> Le 25/07/2013 08:06, Arnaud Michel a ?crit :
>> Hi
>> 
>> For a dataframe with name PaysContrat1 and with
>> nrow(PaysContrat1)
>> [1] 52366
>> 
>> the test of system.time is :
>> 
>> system.time(droplevels(do.call(rbind,lapply(split(PaysContrat1,PaysContrat1$Matricule), 
>> FUN=function(x) {x[,c("Nom","Pr?nom")] <- x[nrow(x),c("Nom","Pr?nom"),drop=TRUE];x}))))
>>   user  system elapsed
>>  14.03    0.00   14.04
>> 
>> system.time(droplevels(PaysContrat1[with(PaysContrat1,ave(seq_along(Matricule),Matricule,FUN=min)) ,]  ))
>>   user  system elapsed
>>    0.2     0.0     0.2
>> 
>> Michel
>> 
>> Le 24/07/2013 15:29, arun a ?crit :
>>> Hi Michel,
>>> You could try:
>>> 
>>> 
>>> df1New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=min)),]) 
>>> row.names(df1New)<-1:nrow(df1New)
>>> df2New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=max)),]) 
>>> row.names(df2New)<-1:nrow(df2New)
>>>  identical(df1New,df1)
>>> #[1] TRUE
>>>  identical(df2New,df2)
>>> #[1] TRUE
>>> A.K.
>>> 
>>> 
>>> 
>>> ----- Original Message -----
>>> From: Arnaud Michel <michel.arnaud at cirad.fr>
>>> To: R help <r-help at r-project.org>
>>> Cc:
>>> Sent: Wednesday, July 24, 2013 2:39 AM
>>> Subject: [R] Change values in a dateframe
>>> 
>>> Hello
>>> 
>>> I have the following problem :
>>> The dataframe TEST has multiple lines for a same person because :
>>> there are differents values of Nom or differents values of Prenom
>>> but the values of Matricule or Sexe or Date.de.naissance are the same.
>>> 
>>> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
>>> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
>>> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
>>> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
>>> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
>>> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
>>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>>> "factor"),
>>>      Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>>      1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>>      "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>>> "factor")), .Names = c("Matricule",
>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>> row.names = c(NA,
>>> -11L))
>>> 
>>> 
>>> I would want to make homogeneous the information and would like built 2
>>> dataframes :
>>> df1 wich has the value of Nom and Prenom of the first lines of TEST when
>>> there are different values. The other values (Matricule or Sexe or
>>> Date.de.naissance) are unchanged
>>> 
>>> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
>>> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
>>> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom =
>>> structure(c(6L,
>>> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
>>> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
>>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>>> "factor"),
>>>      Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>>      1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>>      "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>>> "factor")), .Names = c("Matricule",
>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>> row.names = c(NA,
>>> -11L))
>>> 
>>> df2 wich has the value of Nom and Prenom of the last lines of TEST when
>>> there are different values. The other values (Matricule or Sexe or
>>> Date.de.naissance) are unchanged.
>>> 
>>> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
>>> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
>>> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>>>      Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>>>      5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>>>      "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe =
>>> structure(c(1L,
>>>      1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>>>      "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
>>>      2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>>>      "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
>>>      "30/03/1935"), class = "factor")), .Names = c("Matricule",
>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>> row.names = c(NA,
>>> -11L))
>>> 
>>> Thank for your helps
>>> Michel
>>> 
>> 
> 
> -- 
> Michel ARNAUD
> Charg? de mission aupr?s du DRH
> DGDRD-Drh - TA 174/04
> Av Agropolis 34398 Montpellier cedex 5
> tel : 04.67.61.75.38
> fax : 04.67.61.57.87
> port: 06.47.43.55.31
> 


From harb at student.unimelb.edu.au  Thu Jul 25 09:42:24 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Thu, 25 Jul 2013 17:42:24 +1000
Subject: [R] Clarification of inputs for xyf function of kohonen package
Message-ID: <CAGYnQNTO56_x4EDzd5N-Rp3HRxV+k-e3ZcW526QGd52cJDm+ZQ@mail.gmail.com>

For supervised version of the kohonen SOM (xyf), I wish to train a
map, and then predict a property from the trained map. For the
function xyf, whose basic call is:

xyf(data, Y, grid)

should the data argument contain the Y property? Or does it need to be excluded?

e.g.:
> head(somdata)
   MEAS_TC        SP        LN        SN       GR     NEUT
1 2.780000 59.181090  33.74364  19.75361 66.57665 257.0368
2 1.490000 49.047750 184.14598 139.07980 54.75052 326.8001
3 1.490000 49.128902 183.58853 138.02768 55.54114 327.4739
4 2.201276 18.240331  19.20386  10.74748 62.04492 494.4161
5 2.201276 18.215522  19.18009  10.72446 61.87448 494.7409
6 1.276476  9.337769  14.16061  19.06902 14.99612 363.0020

Is the correct call like this:
data.xyf <- xyf(somdata, Y=somdata[1], ...)

Or this:
data.xyf <- xyf(somdata[-1], Y=somdata[1], ...)

Ben.


From michel.arnaud at cirad.fr  Thu Jul 25 09:59:07 2013
From: michel.arnaud at cirad.fr (Arnaud Michel)
Date: Thu, 25 Jul 2013 09:59:07 +0200
Subject: [R] Change values in a dateframe-Speed TEST
In-Reply-To: <E8B9A235-FDE5-42E9-B551-B81D18DEC059@xs4all.nl>
References: <51EF76AA.7000803@cirad.fr>
	<1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<51F0C053.10603@cirad.fr> <51F0C74C.7070404@cirad.fr>
	<E8B9A235-FDE5-42E9-B551-B81D18DEC059@xs4all.nl>
Message-ID: <51F0DACB.2010706@cirad.fr>

Le 25/07/2013 08:50, Berend Hasselman a ?crit :
> On 25-07-2013, at 08:35, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>
>> But I just noticed that the two solutions are not comparable :
>> the change concern only Nom and Prenom (solution Berend) and not also Sexe or Date.de.naissance orother variables (solution Arun) that can changed. But my question was badly put.
> Indeed:-)
>
> But that can be remedied with (small correction w.r.t. initial solution: drop=TRUE removed; not relevant here)
>
> r1 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
>                      FUN=function(x) {x[,1:ncol(x)] <- x[1,1:ncol(x)];x})))
>
> and
>
> r2 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
>                      FUN=function(x) {x[,1:ncol(x)] <- x[nrow(x),1:ncol(x)];x})))
Thank you but I keep
{x[,c("Nom","Pr?nom")] <- x[nrow(x),c("Nom","Pr?nom")];x} because in the 
dataframe there are other variables that I do not want to change. I want 
change only "Nom" and "Pr?nom"

PS : ?w.r.t.
Michel

> Less elegant than alternative with ave
>
> Berend
>
>> Michel
>>
>> Le 25/07/2013 08:06, Arnaud Michel a ?crit :
>>> Hi
>>>
>>> For a dataframe with name PaysContrat1 and with
>>> nrow(PaysContrat1)
>>> [1] 52366
>>>
>>> the test of system.time is :
>>>
>>> system.time(droplevels(do.call(rbind,lapply(split(PaysContrat1,PaysContrat1$Matricule),
>>> FUN=function(x) {x[,c("Nom","Pr?nom")] <- x[nrow(x),c("Nom","Pr?nom"),drop=TRUE];x}))))
>>>    user  system elapsed
>>>   14.03    0.00   14.04
>>>
>>> system.time(droplevels(PaysContrat1[with(PaysContrat1,ave(seq_along(Matricule),Matricule,FUN=min)) ,]  ))
>>>    user  system elapsed
>>>     0.2     0.0     0.2
>>>
>>> Michel
>>>
>>> Le 24/07/2013 15:29, arun a ?crit :
>>>> Hi Michel,
>>>> You could try:
>>>>
>>>>
>>>> df1New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=min)),])
>>>> row.names(df1New)<-1:nrow(df1New)
>>>> df2New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=max)),])
>>>> row.names(df2New)<-1:nrow(df2New)
>>>>   identical(df1New,df1)
>>>> #[1] TRUE
>>>>   identical(df2New,df2)
>>>> #[1] TRUE
>>>> A.K.
>>>>
>>>>
>>>>
>>>> ----- Original Message -----
>>>> From: Arnaud Michel <michel.arnaud at cirad.fr>
>>>> To: R help <r-help at r-project.org>
>>>> Cc:
>>>> Sent: Wednesday, July 24, 2013 2:39 AM
>>>> Subject: [R] Change values in a dateframe
>>>>
>>>> Hello
>>>>
>>>> I have the following problem :
>>>> The dataframe TEST has multiple lines for a same person because :
>>>> there are differents values of Nom or differents values of Prenom
>>>> but the values of Matricule or Sexe or Date.de.naissance are the same.
>>>>
>>>> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
>>>> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
>>>> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
>>>> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
>>>> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
>>>> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
>>>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>>>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>>>> "factor"),
>>>>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>>>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>>>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>>>> "factor")), .Names = c("Matricule",
>>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>>> row.names = c(NA,
>>>> -11L))
>>>>
>>>>
>>>> I would want to make homogeneous the information and would like built 2
>>>> dataframes :
>>>> df1 wich has the value of Nom and Prenom of the first lines of TEST when
>>>> there are different values. The other values (Matricule or Sexe or
>>>> Date.de.naissance) are unchanged
>>>>
>>>> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
>>>> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
>>>> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom =
>>>> structure(c(6L,
>>>> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
>>>> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
>>>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>>>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>>>> "factor"),
>>>>       Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>>>       1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>>>       "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>>>> "factor")), .Names = c("Matricule",
>>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>>> row.names = c(NA,
>>>> -11L))
>>>>
>>>> df2 wich has the value of Nom and Prenom of the last lines of TEST when
>>>> there are different values. The other values (Matricule or Sexe or
>>>> Date.de.naissance) are unchanged.
>>>>
>>>> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
>>>> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
>>>> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>>>>       Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>>>>       5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>>>>       "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe =
>>>> structure(c(1L,
>>>>       1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>>>>       "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
>>>>       2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>>>>       "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
>>>>       "30/03/1935"), class = "factor")), .Names = c("Matricule",
>>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>>> row.names = c(NA,
>>>> -11L))
>>>>
>>>> Thank for your helps
>>>> Michel
>>>>
>> -- 
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31


From chakrabarti.arnab at gmail.com  Thu Jul 25 09:36:05 2013
From: chakrabarti.arnab at gmail.com (Arnab Chakrabarti)
Date: Thu, 25 Jul 2013 13:06:05 +0530
Subject: [R] Unable to install packages
Message-ID: <CAG90avM3vG9QOMiBLo6tBxMaWDf+WrXj_D2AxkeAynERVO-dEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/c722cb3c/attachment.pl>

From info at software-solutions.nl  Thu Jul 25 10:59:58 2013
From: info at software-solutions.nl (Dark)
Date: Thu, 25 Jul 2013 01:59:58 -0700 (PDT)
Subject: [R] Saving multiple rda-files as one rda-file
In-Reply-To: <1374491885996-4672041.post@n4.nabble.com>
References: <1374491885996-4672041.post@n4.nabble.com>
Message-ID: <1374742798426-4672278.post@n4.nabble.com>

Really no one has any suggestions on this issue?



--
View this message in context: http://r.789695.n4.nabble.com/Saving-multiple-rda-files-as-one-rda-file-tp4672041p4672278.html
Sent from the R help mailing list archive at Nabble.com.


From mei_yuan at dragon.nchu.edu.tw  Thu Jul 25 11:44:27 2013
From: mei_yuan at dragon.nchu.edu.tw (mei_yuan)
Date: Thu, 25 Jul 2013 17:44:27 +0800 (CST)
Subject: [R] ask help!
Message-ID: <1374745467.10477.mei_yuan@dragon.nchu.edu.tw>

Hi,

In the R console, I have the following:

> runif(10)
Error in runif(10) : 
  '.Random.seed' is not an integer vector but of type 'list'
> 


Can someone advise me of the solution of the problem?



Mei-Yuan Chen
Department of Finance
NCHU, aiwan


From riantisu at gmail.com  Thu Jul 25 06:37:40 2013
From: riantisu at gmail.com (Rianti Siswi Utami)
Date: Thu, 25 Jul 2013 11:37:40 +0700
Subject: [R] Error in initial value for qmatrix in msm function
Message-ID: <CAKy+FjTpjCrEMA_N7unFViqzDfpSNSNZxmhdQkwkoo6TnESX7g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/5ce21ab2/attachment.pl>

From sheldon.qiu at okstate.edu  Thu Jul 25 09:12:07 2013
From: sheldon.qiu at okstate.edu (nntx)
Date: Thu, 25 Jul 2013 00:12:07 -0700 (PDT)
Subject: [R] Neural Network Problem
Message-ID: <1374736327874-4672275.post@n4.nabble.com>

Hello Professionals, 

I am new to R and am planning to use R for a Artificial Neural Network
regression. I have 10 different scenarios for each observation (Input). For
each scenario, there are 7 variables, which means 7 output.  I have 1000
observations in total and I do have 1000 expected output.I want to use 800
observations for training and the rest for testing. Could any one provide a
sample for my case? I don't quite understand the instructions from the
packages. Appreciated. 



--
View this message in context: http://r.789695.n4.nabble.com/Neural-Network-Problem-tp4672275.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Thu Jul 25 06:24:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 24 Jul 2013 21:24:08 -0700 (PDT)
Subject: [R] flexible approach to subsetting data
In-Reply-To: <1374724428.15562.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CALxSy073ajNiuYtufj9u1etjsgT==hbuCDdHMYuHiFYEj72m7g@mail.gmail.com>	<CAN5YmCHLQbUwrh2J2zAtPe-2io2+ccXL+m_sE+DDssisUBuFpA@mail.gmail.com>	<F6EBB4B0-6D4E-42DF-9FA5-1ABC94A8DA92@comcast.net>	<F83A2C57-1E6F-4779-AECA-C6449A4078E9@comcast.net>	<01cc01ce87e7$b08340b0$1189c210$@tamu.edu>
	<CALxSy07CaJDRbM6ejOZq1iAM1xJ3Q+aOZruOP181iZBwK4ORXg@mail.gmail.com>
	<1374724428.15562.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1374726248.16044.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Also, using the bigger example dataset:
If you want all the 81 variables in the long form,? it looks like you have to use 81 `grepl()` statements 

Wouldn't it be easier to just use:
names(rtNew)<-paste0(gsub("\\..*","",names(rtNew)),"_",rep(1:5,each=81))
reshape(rtNew,direction="long",varying=1:ncol(rtNew),sep="_",timevar="m")
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Andrea Lamont <alamont082 at gmail.com>
Cc: R help <r-help at r-project.org>; David Carlson <dcarlson at tamu.edu>
Sent: Wednesday, July 24, 2013 11:53 PM
Subject: Re: [R] flexible approach to subsetting data

Hi,
It works in small dataset.
rt<- structure(list(sim = c(1L, 1L, 1L, 2L, 2L, 2L), txt.y.obs = c(5L, 
4L, 3L, 6L, 7L, 9L), cont.y.obs = c(4L, 3L, 9L, 4L, 8L, 6L), 
??? ID = 1:6, obs.txt = c(5L, 2L, 4L, 8L, 4L, 7L), TE = c(5L, 
??? 7L, 4L, 3L, 5L, 8L), X1 = c(1L, 1L, 1L, 2L, 2L, 2L), sim.1 = c(4L, 
??? 7L, 5L, 3L, 5L, 9L), txt.y.obs.1 = c(3L, 5L, 7L, 9L, 5L, 
??? 4L), cont.y.obs.1 = c(3L, 4L, 8L, 9L, 4L, 5L), ID.1 = 1:6, 
??? obs.txt.1 = c(7L, 1L, 4L, 5L, 8L, 6L), TE.1 = c(5L, 6L, 3L, 
??? 4L, 9L, 10L), X1.1 = c(6L, 4L, 3L, 8L, 5L, 6L)), .Names = c("sim", 
"txt.y.obs", "cont.y.obs", "ID", "obs.txt", "TE", "X1", "sim.1", 
"txt.y.obs.1", "cont.y.obs.1", "ID.1", "obs.txt.1", "TE.1", "X1.1"
), class = "data.frame", row.names = c(NA, -6L))



rtr<-reshape(rt,? direction="long",
varying=list(
sim=grepl("sim", names(rt)),
txt.y.obs=grepl("txt.y.obs", names(rt)),
cont.y.obs=grepl("cont.y.obs", names(rt)),
ID=grepl("ID", names(rt)),
obs.txt=grepl("obs.txt", names(rt)),
TE=grepl("TE", names(rt)),
X1=grepl("X1", names(rt))),
v.names=
c("sim","txt.y.obs","cont.y.obs","ID","obs.txt", "TE", "X1"),
timevar="imputation")



#Using a bigger dataset:
set.seed(48)
rtNew<- as.data.frame(matrix(sample(1:50,405*5,replace=TRUE),ncol=405))
colnames(rtNew)<-paste0(gsub("\\d+","",colnames(rtNew)),1:81)
colnames(rtNew)[-c(1:81)]<-paste(colnames(rtNew)[-c(1:81)],rep(1:4,each=81),sep=".")
res<- reshape(rtNew,direction="long",varying=list(V1=grepl("V1",names(rtNew)),
V2=grepl("V2",names(rtNew)),V3=grepl("V3",names(rtNew)),V4=grepl("V4",names(rtNew)),
V5=grepl("V5",names(rtNew)),V6=grepl("V6",names(rtNew)),V7=grepl("V7",names(rtNew))),
v.names=c("V1","V2","V3","V4","V5","V6","V7"),timevar="imputation")
#works

#When I forgot to close the list bracket:

reshape(rtNew,direction="long",varying=list(V1=grepl("V1",names(rtNew)),
V2=grepl("V2",names(rtNew)),V3=grepl("V3",names(rtNew)),V4=grepl("V4",names(rtNew)),
V5=grepl("V5",names(rtNew)),V6=grepl("V6",names(rtNew)),V7=grepl("V7",names(rtNew)),
v.names=c("V1","V2","V3","V4","V5","V6","V7"),timevar="imputation"))
#Error in reshapeLong(data, idvar = idvar, timevar = timevar, varying = varying,? : 
?# 'varying' arguments must be the same length
Though, your code looks fine with respect to closing brackets.
A.K.




----- Original Message -----
From: Andrea Lamont <alamont082 at gmail.com>
To: David Carlson <dcarlson at tamu.edu>
Cc: R help <r-help at r-project.org>
Sent: Wednesday, July 24, 2013 9:41 PM
Subject: Re: [R] flexible approach to subsetting data

Hi, all:

I have a follow-up question.

I have 81 variables in my dataset (all of which are repeated).? Reshape
seems to give me an error whenever more than six variables are used. The
error message is this: Error in reshapeLong(data, idvar = idvar,
timevar =timevar
, varying = varying, : 'varying arguments must be the same length.

I have tested the lengths of all the variables, and they are all equal.
Further, when I mix up the variables used in the reshape function, it
works -- so long as I keep the number of variables used under six. As soon
as I add the seventh variable (regardless of what it is), I receive this
error.


#This works:
rtr<-reshape(rt,? direction="long",
varying=list(
sim=grepl("sim", names(rt)),
txt.y.obs=grepl("txt.y.obs", names(rt)),
cont.y.obs=grepl("cont.y.obs", names(rt)),
ID=grepl("ID", names(rt)),
obs.txt=grepl("obs.txt", names(rt)),
TE=grepl("TE", names(rt))),
v.names=
c("sim","txt.y.obs","cont.y.obs","ID","obs.txt", "TE"),
timevar="imputation")



#The addition of one more variable creates an error. The problem is not
with X1.
rtr<-reshape(rt,? direction="long",
varying=list(
sim=grepl("sim", names(rt)),
txt.y.obs=grepl("txt.y.obs", names(rt)),
cont.y.obs=grepl("cont.y.obs", names(rt)),
ID=grepl("ID", names(rt)),
obs.txt=grepl("obs.txt", names(rt)),
TE=grepl("TE", names(rt)),
X1=grepl("X1", names(rt))),
v.names=
c("sim","txt.y.obs","cont.y.obs","ID","obs.txt", "TE", "X1"),
timevar="imputation")




On Tue, Jul 23, 2013 at 5:00 PM, David Carlson <dcarlson at tamu.edu> wrote:

> Actually the ".0" on the first variable is not needed.
>
> You could modify the reshape() call to search for the base
> name of each variable so you would not need to change the code
> if the number of replications changes:
>
> reshape(df5,? direction="long", v.names=c("dose", "resp"),
>? ? ? ?? varying=list(dose=grepl("dose", names(df5)),
>? ? ? ?? resp=grepl("resp", names(df5)) )
>? ? ?? )
>
> -------------------------------------
> David L Carlson
> Associate Professor of Anthropology
> Texas A&M University
> College Station, TX 77840-4352
>
> -----Original Message-----
> From: r-help-bounces at r-project.org
> [mailto:r-help-bounces at r-project.org] On Behalf Of David
> Winsemius
> Sent: Tuesday, July 23, 2013 1:12 PM
> To: David Winsemius
> Cc: R help; Andrea Lamont
> Subject: Re: [R] flexible approach to subsetting data
>
>
> On Jul 23, 2013, at 10:49 AM, David Winsemius wrote:
>
> >
> > On Jul 23, 2013, at 10:01 AM, Adams, Jean wrote:
> >
> >> Check out the reshape() function of the reshape package.
> Here's one of the
> >> examples from ?reshape.
> >>
> >> Jean
> >>
> >>
> >> library(reshape)?? # No,? at least not for the
> reshape-function
> >
> > The reshape function is from the 'base' package. The
> 'reshape' and 'reshape2' packages were written (at least in
> part) because the 'reshape'-function was so difficult to
> understand.
> >
> > If you do choose to use the reshape2 package, which is
> well-respected and often extremely helpful, the function you
> will want to start with is 'melt'.
> >
> >
> >> long <- reshape(wide, direction="long")
> >
> > I don't think this example will be particularly helpful
> since the initial direction is "long" (from "wide") and more
> input would be needed.
>
> Here's a dataset to experiment with
>
> df5 <- data.frame(dose.0 =
> c(40,50,60,50),resp.0=c(40,50,60,50),
>? dose.1 = c(1,2,1,2), resp.1=c(1,2,1,2)+3,
>? dose.2 = c(2,1,2,1), resp.2=c(1,2,1,2)+3,
>? dose.3 = c(3,3,3,3), resp.3=c(1,2,1,2)+3 )
>
> Notice that you would need add the ".0" to the column names
>
> reshape(df5,? direction="long",
>? ? ? ? ? ? ?? v.names=c("dose", "resp"),
>? ? ? ? ? ? ? ? varying=list(dose=c(1,3,5,7), resp=c(2,4,6,8) )
>? ? ? ?? )? # succeeds
>
>
>
> So perhaps could use similar call (after append the ".0"'s)
> with:
>
>?? varying=list(sim=seq(1,810,by=4),
>? ? ? ? ? ? ? ? X1= seq(2,810,by=4),
>? ? ? ? ? ? ? ? X2= seq(3,810,by=4),
>? ? ? ? ? ? ? ? X3= seq(4,810,by=4)
>? ? ? ? ? ? ? ? )
>
> >
> >
> >> wide
> >> long
> >>
> >>
> >>
> >> On Tue, Jul 23, 2013 at 9:35 AM, Andrea Lamont
> <alamont082 at gmail.com> wrote:
> >>
> >>> Hello:
> >>>
> >>> I am running a simulation study and am stuck with a
> subsetting problem.
> >>>
> >>> Here is the basic issue:
> >>> I generated data and am running a simulation that uses
> multiple imputation.
> >>> For each generated dataset, I used multiple imputation.
> The resultant
> >>> dataset is in wide for where each imputation is recorded
> as a separate
> >>> column (though the different simulations are stacked).
> Here is an example
> >>> of what it looks like:
> >>>
> >>> sim?? X1?? X2?? X3?? sim.1?? X1.1? ? X1.1? ? X3.1
> >
> >>> 1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #
> #
> >>> 1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #
> #
> >>> 1? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #
> #
> >>> 2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #
> #
> >>> 2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #
> #
> >>> 2? ? ? ?? #? ? #? ?? #? ? ? ? #? ? ? ? ?? #? ? ? ? ? #
> #
> >>>
> >>> sim refers to the simulated/generated dataset. X1-X3 are
> the values for the
> >>> first imputed dataset, X1.1-X3.1 are the values for the
> second imputed
> >>> dataset.
> >>>
> >>> The problem is that I want the data to be in long format,
> like this:
> >>>
> >>> sim m X1 X2 X3
> >>> 1? 1?? #?? #? ? #
> >>> 1? 2?? #?? #? ? #
> >>> 2? 1?? #?? #? ? #
> >>> 2? 2?? #?? #? ? #
> >>>
> >>> where m is the imputation number.
> >>> This will allow me to do cleaner calculations (e.g.
> X3-X1).
> >>>
> >>> I know I can subset the data manually - e.g. [,1:10] and
> save this to
> >>> separate datasets then? rbind; however, I'm looking for a
> more flexible
> >>> approach to do this.? This manual approach would be quite
> tedious as number
> >>> of imputations (and therefore number of columns) increased
> (with only 10
> >>> imputations, there are roughly 810 columns). Also,I would
> like to
> >>> avoid having to recode each time I change the number of
> imputations.
> >>>
> >>> THe same is true for the reshape function, which would
> require naming
> >>> a huge number of columns and edits each time 'm' changes.
> >
> > If the columns are named regularly, then 'reshape' will
> attempt to split properly without an explicit naming. Details
> and a better description of the problem might allow more
> specific answers to emerge. The fact that the first instances
> have no numeric indicators may be a problem for the algorithm.
>
> >
> > Why not post dput(head( dfrm[ ,1:12]))
> >
> > --
> > David.
> >
> >>>
> >>>
> >>> Is there a flexible way to approach this? I'm inclined to
> use a for loop,
> >>> but know that 1) this is generally inefficient and 2) am
> having trouble
> >>> with
> >>> the coding regardless.
> >>>
> >>> Any suggestions are appreciated.
> >>>
> >>> Thanks,
> >>> Andrea
> >>>
>
>
> David Winsemius
> Alameda, CA, USA
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
> code.
>
>


-- 
Andrea Lamont, MA
Clinical-Community Psychology
University of South Carolina
Barnwell College
Columbia, SC 29208

Please consider the environment before printing this email.

CONFIDENTIAL: This transmission is intended for the use of the
individual(s) or entity to which it is addressed, and may contain
information that is privileged, confidential, and exempt from disclosure
under applicable law. Should the reader of this message not be the intended
recipient(s), you are hereby notified that any dissemination, distribution,
or copying of this communication is strictly prohibited.? If you are not
the intended recipient, please contact the sender by reply email and
destroy/delete all copies of the original message.

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jim at bitwrit.com.au  Thu Jul 25 12:01:50 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Thu, 25 Jul 2013 20:01:50 +1000
Subject: [R] ask help!
In-Reply-To: <1374745467.10477.mei_yuan@dragon.nchu.edu.tw>
References: <1374745467.10477.mei_yuan@dragon.nchu.edu.tw>
Message-ID: <51F0F78E.7070605@bitwrit.com.au>

On 07/25/2013 07:44 PM, mei_yuan wrote:
> Hi,
>
> In the R console, I have the following:
>
>> runif(10)
> Error in runif(10) :
>    '.Random.seed' is not an integer vector but of type 'list'
>>
>
>
> Can someone advise me of the solution of the problem?
>
>
>
> Mei-Yuan Chen

Hi Mei-Yuan,
.Random.seed should be a vector of numeric values. Somehow this has been 
set to an object of type "list":

.Random.seed<-list(.Random.seed)
runif(10)
Error in runif(10) :
   '.Random.seed' is not an integer vector but of type 'list'

I would suggest quitting R and _not_ saving the session, then restarting 
and trying:

runif(10)

again.

Jim


From kridox at ymail.com  Thu Jul 25 12:14:36 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Thu, 25 Jul 2013 19:14:36 +0900
Subject: [R] Unable to install packages
In-Reply-To: <CAG90avM3vG9QOMiBLo6tBxMaWDf+WrXj_D2AxkeAynERVO-dEg@mail.gmail.com>
References: <CAG90avM3vG9QOMiBLo6tBxMaWDf+WrXj_D2AxkeAynERVO-dEg@mail.gmail.com>
Message-ID: <CAAcyNCyHmjrnKpzvZ61GbNryBM_hGmUwBDtD_4A1B5MAUp+3CQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/59a9a8d5/attachment.pl>

From helios.derosario at ibv.upv.es  Thu Jul 25 12:30:12 2013
From: helios.derosario at ibv.upv.es (Helios de Rosario)
Date: Thu, 25 Jul 2013 12:30:12 +0200
Subject: [R] ask help!
Message-ID: <51F11A540200000C00017318@mailhost.biomec.upv.es>



-- 
Helios de Rosario Mart?nez
 
 Researcher
>>> El d?a 25/07/2013 a las 11:44, "mei_yuan"
<mei_yuan at dragon.nchu.edu.tw>
escribi?:
> Hi,
> 
> In the R console, I have the following:
> 
>> runif(10)
> Error in runif(10) : 
>   '.Random.seed' is not an integer vector but of type 'list'

It seems you have overwritten the default value of the variable
.Random.seed. Delete it and try again:

rm(.Random.seed)
runif(10)




INSTITUTO DE BIOMEC?NICA DE VALENCIA
Universidad Polit?cnica de Valencia ? Edificio 9C
Camino de Vera s/n ? 46022 VALENCIA (ESPA?A)
Tel. +34 96 387 91 60 ? Fax +34 96 387 91 69
www.ibv.org

  Antes de imprimir este e-mail piense bien si es necesario hacerlo.
En cumplimiento de la Ley Org?nica 15/1999 reguladora de la Protecci?n
de Datos de Car?cter Personal, le informamos de que el presente mensaje
contiene informaci?n confidencial, siendo para uso exclusivo del
destinatario arriba indicado. En caso de no ser usted el destinatario
del mismo le informamos que su recepci?n no le autoriza a su divulgaci?n
o reproducci?n por cualquier medio, debiendo destruirlo de inmediato,
rog?ndole lo notifique al remitente.


From ripley at stats.ox.ac.uk  Thu Jul 25 12:32:47 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 25 Jul 2013 11:32:47 +0100
Subject: [R] ask help!
In-Reply-To: <51F0F78E.7070605@bitwrit.com.au>
References: <1374745467.10477.mei_yuan@dragon.nchu.edu.tw>
	<51F0F78E.7070605@bitwrit.com.au>
Message-ID: <51F0FECF.7040108@stats.ox.ac.uk>

No R version was stated, but this is not the behaviour of R-patched so 
you could update.

On 25/07/2013 11:01, Jim Lemon wrote:
> On 07/25/2013 07:44 PM, mei_yuan wrote:
>> Hi,
>>
>> In the R console, I have the following:
>>
>>> runif(10)
>> Error in runif(10) :
>>    '.Random.seed' is not an integer vector but of type 'list'
>>>
>>
>>
>> Can someone advise me of the solution of the problem?
>>
>>
>>
>> Mei-Yuan Chen
>
> Hi Mei-Yuan,
> .Random.seed should be a vector of numeric values. Somehow this has been
> set to an object of type "list":
>
> .Random.seed<-list(.Random.seed)
> runif(10)
> Error in runif(10) :
>    '.Random.seed' is not an integer vector but of type 'list'
>
> I would suggest quitting R and _not_ saving the session, then restarting
> and trying:
>
> runif(10)
>
> again.
>
> Jim
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From dennis1991 at gmx.net  Thu Jul 25 12:40:45 2013
From: dennis1991 at gmx.net (dennis1991 at gmx.net)
Date: Thu, 25 Jul 2013 12:40:45 +0200 (CEST)
Subject: [R] How to split two levels several times?
In-Reply-To: <51F04B5B.2010702@sapo.pt>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>
Message-ID: <trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>

Hi Rui
once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.

So idx should not return
 [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4

but instead 6 times number 4 at the end
 [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4

Do you have any solution?


> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> An: dennis1991 at gmx.net
> Cc: r-help at r-project.org
> Betreff: Re: Aw: Re:  Re: [R] How to split two levels several times?
>
> Hello,
>
> As for the first question, note that in the case you describe, the
> resulting list of df's will not be a split of the original, there will
> be a duplication in the final 4-1 and 1-3. The following is a hack but
> will do it.
>
>
> lens <- rle(as.character(XXX$electrode))$lengths
> m <- length(lens) %/% 2
> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> if(length(lens) %% 2 != 0)
> 	idx <- c(idx, rep(m + 1, lens[length(lens)]))
>
> sp <- split(XXX, idx)
>
> if(length(lens) %% 2 != 0){
> 	idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
> 	sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
> }
> sp
>
>
> As for the second question, I'm not understanding it, can you post
> sample output?
>
> Rui Barradas
>
> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
> > Hi Rui
> > the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
> >
> > lens <- rle(as.character(XXX$electrode))$lengths
> > will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
> > split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
> > This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
> >
> > Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
> >
> >
> > This is the table "XXX"
> >
> > electrode length
> >
> > electrode1 5.7
> > electrode1 6.3
> > electrode1 6.2
> > electrode2 11.4
> > electrode2 9.7
> > electrode3 14.2
> > electrode3 14.8
> > electrode3 12.6
> > electrode2 11.4
> > electrode2 9.7
> > electrode4 17.0
> > electrode4 16.3
> > electrode4 17.8
> > electrode4 18.3
> > electrode4 16.9
> > electrode4 18.5
> > electrode1 5.7
> > electrode1 6.3
> > electrode1 6.2
> > electrode1 5.7
> > electrode1 6.3
> > electrode1 6.2
> > electrode3 14.2
> > electrode3 14.8
> > electrode3 12.6
> >
> >
> > This is a simplified table XX
> >
> > electrode1
> > electrode2
> > electrode1
> > electrode3
> > electrode1
> > electrode4
> > electrode2
> > electrode1
> > electrode2
> > electrode3
> > electrode2
> > electrode4
> > electrode3
> > electrode1
> > electrode3
> > electrode2
> > electrode3
> > electrode4
> > electrode4
> > electrode1
> > electrode4
> > electrode2
> > electrode4
> > electrode3
> >
> >
> >
> >
> >
> >
> >> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
> >> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >> An: dennis1991 at gmx.net
> >> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
> >> Betreff: Re: Aw: Re: [R] How to split two levels several times?
> >>
> >> Hello,
> >>
> >> It's better if you keep this on the list, the odds of getting more and
> >> better answers are greater.
> >>
> >> As for your new question, try the following.
> >>
> >>
> >> lens <- rle(as.character(XXX$electrode))$lengths
> >> m <- length(lens) %/% 2
> >> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> >> split(XXX, idx)
> >>
> >>
> >> Hope this helps,
> >>
> >> Rui Barradas
> >>
> >> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
> >>> Hi
> >>> this type of splitting works for my specific example. Thanks for your help.
> >>>
> >>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,  electrode3-electrode2,  electrode4-electrode1. How should I split this?
> >>>
> >>>
> >>> This is the table "XXX"
> >>>
> >>> electrode length
> >>>
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode3 14.2
> >>> electrode3 14.8
> >>> electrode3 12.6
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode4 17.0
> >>> electrode4 16.3
> >>> electrode4 17.8
> >>> electrode4 18.3
> >>> electrode4 16.9
> >>> electrode4 18.5
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
> >>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >>>> An: dennis1991 at gmx.net
> >>>> Cc: r-help at r-project.org
> >>>> Betreff: Re: [R] How to split two levels several times?
> >>>>
> >>>> Hello,
> >>>>
> >>>> Sorry, I've just realized that your data frame is named 'XXX', not
> >>>> 'dat'. Change that and the rest should work:
> >>>>
> >>>>
> >>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
> >>>> split(XXX, idx)
> >>>>
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
> >>>>> Hello,
> >>>>>
> >>>>> Try the following.
> >>>>>
> >>>>>
> >>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
> >>>>> split(dat, idx)
> >>>>>
> >>>>>
> >>>>> Hope this helps,
> >>>>>
> >>>>> Rui Barradas
> >>>>>
> >>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
> >>>>>> Hi,
> >>>>>>
> >>>>>> I have a small problem with the function split() and would appreciate
> >>>>>> your help.
> >>>>>>
> >>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
> >>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
> >>>>>> split the table always at the row where ?electrode1? starts again so
> >>>>>> that I can export 7  individual dataframes (numbered ?dataframe1? to
> >>>>>> ?dataframe7?) which contain always electrode1 as first level (always
> >>>>>> three rows) with the varying number of rows for electrodes2-8 below.
> >>>>>> I tried the split function with various setups:
> >>>>>>
> >>>>>> t <- as.factor(XXX$electrode)
> >>>>>>
> >>>>>> dataframeX <- split(XXX, f=(levels=t))
> >>>>>>
> >>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
> >>>>>>
> >>>>>>
> >>>>>> This is the table "XXX"
> >>>>>>
> >>>>>> electrode    length
> >>>>>>
> >>>>>> electrode1    5.7
> >>>>>> electrode1    6.3
> >>>>>> electrode1    6.2
> >>>>>> electrode2    11.4
> >>>>>> electrode2    9.7
> >>>>>> electrode1    5.7
> >>>>>> electrode1    6.3
> >>>>>> electrode1    6.2
> >>>>>> electrode3    14.2
> >>>>>> electrode3    14.8
> >>>>>> electrode3    12.6
> >>>>>> electrode1    5.7
> >>>>>> electrode1    6.3
> >>>>>> electrode1    6.2
> >>>>>> electrode4    17.0
> >>>>>> electrode4    16.3
> >>>>>> electrode4    17.8
> >>>>>> electrode4    18.3
> >>>>>> electrode4    16.9
> >>>>>> electrode4    18.5
> >>>>>> electrode1    ....
> >>>>>> ....        ....
> >>>>>> electrode5    ....
> >>>>>> ....        ....
> >>>>>> electrode1    ....
> >>>>>> electrode6    ....
> >>>>>> electrode1    ....
> >>>>>> electrode7    ....
> >>>>>> electrode1    ....
> >>>>>> electrode8    ....
> >>>>>>
> >>>>>> ______________________________________________
> >>>>>> R-help at r-project.org mailing list
> >>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>> PLEASE do read the posting guide
> >>>>>> http://www.R-project.org/posting-guide.html
> >>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>>
> >>>>> ______________________________________________
> >>>>> R-help at r-project.org mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>> PLEASE do read the posting guide
> >>>>> http://www.R-project.org/posting-guide.html
> >>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>
> >>
>


From jttkim at googlemail.com  Thu Jul 25 13:45:42 2013
From: jttkim at googlemail.com (Jan Kim)
Date: Thu, 25 Jul 2013 12:45:42 +0100
Subject: [R] Saved Session Pitfalls (was:  ask help!)
In-Reply-To: <51F0F78E.7070605@bitwrit.com.au>
References: <1374745467.10477.mei_yuan@dragon.nchu.edu.tw>
	<51F0F78E.7070605@bitwrit.com.au>
Message-ID: <20130725114502.GA2477@LIN-2F308X1.iah.ac.uk>

On Thu, Jul 25, 2013 at 08:01:50PM +1000, Jim Lemon wrote:
> On 07/25/2013 07:44 PM, mei_yuan wrote:
> >Hi,
> >
> >In the R console, I have the following:
> >
> >>runif(10)
> >Error in runif(10) :
> >   '.Random.seed' is not an integer vector but of type 'list'
> >>
> >
> >
> >Can someone advise me of the solution of the problem?
> >
> >
> >
> >Mei-Yuan Chen
> 
> Hi Mei-Yuan,
> .Random.seed should be a vector of numeric values. Somehow this has
> been set to an object of type "list":
> 
> .Random.seed<-list(.Random.seed)
> runif(10)
> Error in runif(10) :
>   '.Random.seed' is not an integer vector but of type 'list'
> 
> I would suggest quitting R and _not_ saving the session, then
> restarting and trying:
> 
> runif(10)
> 
> again.

Not saving the session won't help if the previously saved session
(still containing the broken .Random.seed) still lingers around.

So the fix is to start a fresh R session without restoring the
previous workspace (e.g. ``R --no-restore''), and then saving
that. This will lose all previously created stuff, though (which
is something to be aware of in case the workspace contains some
precious unsaved data).

Alternatively, if you run

    rm(.Random.seed)

the ``runif(10)'' call will work again (and create a new .Random.seed
of the right type as a side effect). Then when you quit, do save
the workspace to fix the problem "permanently".

Generally, I recommend disabling automatic saving and restoring of
workspaces, e.g. by aliasing R to ``R --no-save --no-restore'',
and using the save and load functions explicitly where needed;
I've seen (way too) many workspaces that have accumulated phenomenal
amounts of clutter and generating quite a share of "mysterious"
failures and irreproducibilities caused by this auto-save
mechanism.

Best regards, Jan
-- 
 +- Jan T. Kim -------------------------------------------------------+
 |             email: jttkim at gmail.com                                |
 |             WWW:   http://www.jtkim.dreamhosters.com/              |
 *-----=<  hierarchical systems are for files, not for humans  >=-----*


From gallrein at psychologie.tu-dresden.de  Thu Jul 25 13:28:44 2013
From: gallrein at psychologie.tu-dresden.de (Anne-Marie B. Gallrein)
Date: Thu, 25 Jul 2013 13:28:44 +0200
Subject: [R] Function, that assigns two vectors to each other
In-Reply-To: <64007B3443B.00000E62jrkrideau@inbox.com>
References: <64007B3443B.00000E62jrkrideau@inbox.com>
Message-ID: <51F10BEC.90406@psychologie.tu-dresden.de>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/8a96283e/attachment.pl>

From marc_schwartz at me.com  Thu Jul 25 13:31:49 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Jul 2013 06:31:49 -0500
Subject: [R] .eps files and powerpoint
In-Reply-To: <201307242240.r6OMe6A0000414@mail15.tpg.com.au>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<201307242240.r6OMe6A0000414@mail15.tpg.com.au>
Message-ID: <BF3C7432-4178-4F95-BF0F-D14DA8E24EC3@me.com>

Hi Duncan,

Based upon the subsequent exchange with Rich late yesterday, I could not replicate the problem that he was having with lattice (OSX versus Windows), so I don't believe that this is germane any longer. I also used trellis.device() just as an alternative to calling postscript() directly and did not have any issues either.

There is something else going on that has not become evident yet.

Thanks,

Marc


On Jul 24, 2013, at 5:40 PM, Duncan Mackay <mackay at northnet.com.au> wrote:

> Hi Marc
> 
> I sometimes had trouble with postscript and pdf files with lattice and I printed with trellis.device(device = pdf, ...) or trellis.device(device = postscript, ...)
> 
> I wonder if this is the case here
> 
> Duncan
> 
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
> 
> 
> At 03:22 25/07/2013, you wrote:
>> Hi Rich,
>> 
>> That's curious.
>> 
>> I noted that you are using barchart() below which is lattice versus base graphics. Is there any difference in the result on Windows if you use barplot() instead? If so, perhaps there is something about lattice graphics in this context.
>> 
>> Also, are you using Office 2008 or Office 2011 on your Mac? 2011 substantially improved Windows file format compatibility, not to mention a plethora of bug fixes.
>> 
>> Regards,
>> 
>> Marc
>> 
>> 
>> On Jul 24, 2013, at 11:37 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
>> 
>> > Marc,
>> >
>> > very interesting.
>> >
>> > Your example works on Windows.  This example doesn't work on windows
>> >
>> >> postscript(file = "file2.eps", height = 4, width = 4,
>> > +                 horizontal = FALSE, onefile = FALSE, paper = "special")
>> >> barchart(1:3)
>> >> dev.off()
>> >
>> > Several examples, including the real one I was having trouble with
>> > previously, work on
>> > PowerPoint on Mac.  They don't work on PowerPoint in Windows.
>> >
>> > More: I put some eps figures into PP on Mac (where they work) and then
>> > saved the file and
>> > opened it in PP on Windows.  They don't work on Windows.
>> >
>> > Since Windows PP users are the target audience at the moment, I will stay
>> > with the res=300 png file.
>> >
>> > This is consistent with my other experiences with PP and Word for Mac,
>> > compared to PP and
>> > Word for Windows.  The two MS sets of programs are highly correlated, but
>> > far from identical.
>> >
>> > When people send my PP or Word files, I am more likely to open them first
>> > on the Mac side of my
>> > machine.  The graphs have spurious lines (connecting the end of the red
>> > line to the beginning of
>> > the green line, for example, when the two lines should be distinct).
>> > Alignment is different
>> > (two-line titles will get folded at the wrong place).  I need to move back
>> > to the Windows side in
>> > the VM to see the files as the author intended.
>> >
>> > Rich
>> >
>> >
>> > On Wed, Jul 24, 2013 at 12:16 PM, Marc Schwartz <marc_schwartz at me.com>wrote:
>> >
>> >> Hi Rich,
>> >>
>> >> Seems to work for me using Powerpoint in MS Office 2011 for Mac.
>> >>
>> >> I used the following code:
>> >>
>> >> postscript(file = "file.eps", height = 4, width = 4,
>> >>                horizontal = FALSE, onefile = FALSE, paper = "special")
>> >>
>> >> plot(rnorm(20))
>> >>
>> >> dev.off()
>> >>
>> >>
>> >>
>> >> Then I used the insert picture from file function in Powerpoint. It
>> >> created the PNG preview during import and I can see that on the slide in
>> >> the application without issue.
>> >>
>> >> I put the EPS file and the PPTX file up on DropBox if you want to look at
>> >> them:
>> >>
>> >> EPS File: https://www.dropbox.com/s/d8avze4yv51blso/file.eps
>> >>
>> >> PPTX file: https://www.dropbox.com/s/pm7oejm0g6rc0a5/RPlot.pptx
>> >>
>> >>
>> >> Regards,
>> >>
>> >> Marc
>> >>
>> >>
>> >>
>> >> On Jul 24, 2013, at 10:49 AM, "Richard M. Heiberger" <rmh at temple.edu>
>> >> wrote:
>> >>
>> >> Thanks Marc,
>> >>
>> >> the extra arguments to postscript still don't produce something that
>> >> PowerPoint will accept.
>> >> With your call, PP still displayed only the icon.  PP did not generate its
>> >> own png file.
>> >>
>> >> Since my immediate goal is the projection screen for a PowerPoint
>> >> presentation, I will go
>> >> directly to the png file.  For the proceedings and for paper I will
>> >> continue to use the pdf file.
>> >>
>> >> Rich
>> >>
>> >> On Wed, Jul 24, 2013 at 11:36 AM, Marc Schwartz <marc_schwartz at me.com>wrote:
>> >>
>> >>> Rich,
>> >>>
>> >>> You are missing some options in the call to postscript() below. It needs
>> >>> to be:
>> >>>
>> >>>  postscript(file = "file.eps", width = x, height = y,
>> >>>             horizontal = FALSE, onefile = FALSE, paper = "special")
>> >>>
>> >>> The first line needs to have values for 'x' and 'y' for the width and
>> >>> height of the image, as they default to 0.
>> >>>
>> >>> The second line of 3 options are all critical to producing an EPS file,
>> >>> as opposed to a PS file. This is described in the 4th paragraph of the
>> >>> Details section of ?postscript.
>> >>>
>> >>> If you import that file into any of the MS Office products (typically
>> >>> also for OpenOffce, LibreOffice, etc.), a PNG preview image will be created
>> >>> during import. It is the PNG bitmapped image that you can see when
>> >>> displaying the EPS file in the document, hence the degradation in quality.
>> >>> Some years ago, all you would see is a rectangular box with an "X" across
>> >>> it, as a placeholder for the imported image.
>> >>>
>> >>> Only if you then print the Office file using a Postscript printer driver,
>> >>> will you see the actual vector based EPS image. The target of that printing
>> >>> operation could be a printer for hard copy, a PS or a PDF file. MS Office
>> >>> does not support the rendering of the EPS image directly.
>> >>>
>> >>> If you are operating on Windows, as opposed to Linux or OSX, typically
>> >>> EMF/WMF files are the easiest way to go in terms of sticking R plots into
>> >>> an Office file, as they are also vector based images, but are effectively
>> >>> Windows only.
>> >>>
>> >>> Regards,
>> >>>
>> >>> Marc Schwartz
>> >>>
>> >>>
>> >>> On Jul 24, 2013, at 10:20 AM, Richard M. Heiberger <rmh at temple.edu>
>> >>> wrote:
>> >>>
>> >>>> png("png300.png", res=300, width=2880, height=1440)
>> >>>>
>> >>>> gives good behavior.  Thank you.  This will become my standard for
>> >>> export
>> >>>> to powerpoint.
>> >>>>
>> >>>> postscript(file='file.eps', onefile=FALSE)
>> >>>> produces eps files that powerpoint rejects, even though ghostview is
>> >>>> satisfied.
>> >>>>
>> >>>> Rich
>> >>>>
>> >>>>
>> >>>> On Wed, Jul 24, 2013 at 2:07 AM, Patrick Connolly <
>> >>>> p_connolly at slingshot.co.nz> wrote:
>> >>>>
>> >>>>> On Tue, 23-Jul-2013 at 10:23PM -0400, Richard M. Heiberger wrote:
>> >>>>>
>> >>>>> |> I have colleagues who use powerpoint.  When I send my colleagues pdf
>> >>>>> files
>> >>>>> |> or ps files, powerpoint
>> >>>>> |> rejects them.  Powerpoint does accept some eps files.
>> >>>>> |>
>> >>>>>
>> >>>>> [...]
>> >>>>>
>> >>>>> |> Does anyone know a workaround that will get vector graphics from R
>> >>> into
>> >>>>> |> powerpoint?
>> >>>>> |> win.metafile is not acceptable.  The resolution of emf files from R
>> >>> is
>> >>>>> |> worse than png files.
>> >>>>>
>> >>>>> Maybe worse than png files at the default resolution which is 72 dpi.
>> >>>>> Change that to something like 300 and nobody will see a jagged edge in
>> >>>>> a PowerPoint slide.
>> >>>>>
>> >>>>> HTH
>> >>>>>
>> >>>>>
>> >>>>> |>
>> >>>>> |> Thanks
>> >>>>> |> Rich
>> >>>
>> >>>
>> >>
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From borja.rivier at gmail.com  Thu Jul 25 13:54:00 2013
From: borja.rivier at gmail.com (Borja Rivier)
Date: Thu, 25 Jul 2013 12:54:00 +0100
Subject: [R] Levels of a factor
In-Reply-To: <02dc01ce889e$db70b4d0$92521e70$@tamu.edu>
References: <CAEJ+j1suE35XM5y49AeODi3hj=fbSY73Wx6NEw8oyr6n_amhVg@mail.gmail.com>
	<02dc01ce889e$db70b4d0$92521e70$@tamu.edu>
Message-ID: <CAEJ+j1ueHzX3yt5ug5L3Cy5=BnnOvKNE4mpE=ZtgQwEJj4eFag@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/148294eb/attachment.pl>

From e.jahanshiri at gmail.com  Thu Jul 25 14:01:28 2013
From: e.jahanshiri at gmail.com (Ebrahim Jahanshiri)
Date: Thu, 25 Jul 2013 20:01:28 +0800
Subject: [R] Computing "standard error of the mean" using REML
Message-ID: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/488ea601/attachment.pl>

From petr.pikal at precheza.cz  Thu Jul 25 14:27:58 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Thu, 25 Jul 2013 12:27:58 +0000
Subject: [R] Saving multiple rda-files as one rda-file
In-Reply-To: <1374742798426-4672278.post@n4.nabble.com>
References: <1374491885996-4672041.post@n4.nabble.com>
	<1374742798426-4672278.post@n4.nabble.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FB64@SRVEXCHMBX.precheza.cz>

Hi

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Dark
> Sent: Thursday, July 25, 2013 11:00 AM
> To: r-help at r-project.org
> Subject: Re: [R] Saving multiple rda-files as one rda-file
> 
> Really no one has any suggestions on this issue?

What issue? AFAIK you can load any number of RDA files to your workspace and save your workspace as one file. I do not see any problem.

Regards
Petr

> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Saving-
> multiple-rda-files-as-one-rda-file-tp4672041p4672278.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Jose.Iparraguirre at ageuk.org.uk  Thu Jul 25 14:33:50 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Thu, 25 Jul 2013 12:33:50 +0000
Subject: [R] Computing "standard error of the mean" using REML
In-Reply-To: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B20355FC@AGEPXMB006.uk.age.local>

Dear Ebrahim,
We do not deal with study or work assignments in this group. 
I'd suggest, nonetheless, to look into the lme4 package and the mer-class objects created with this package.
Regards,

Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of Ebrahim Jahanshiri
Sent: 25 July 2013 13:01
To: r-help at r-project.org
Subject: [R] Computing "standard error of the mean" using REML

Let say we have different samples taken from the same population (I am talking about soil samples and different schemes of sampling) and now we want to compare the accuracy of samples using standard error of mean.
I have been asked to compute standard error of the mean of samples using "residual maximum likelihood (REML)" however, I couldn't find any function in R to do it. All I could find were the function "lmerTest" that do maximum likelihood for the fixed effects modelling but not for computing the "standard error of the mean".

I would appreciate any clue.

EJ

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From marc_schwartz at me.com  Thu Jul 25 15:00:04 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Jul 2013 08:00:04 -0500
Subject: [R] [R-pkgs] WriteXLS Version 3.0.0 Released
In-Reply-To: <CAF4WX-d83vJJJ2VhsQBzyToES-Z_Z8i+TRotEAqOFx_=NVDt5A@mail.gmail.com>
References: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>
	<1374619209185-4672180.post@n4.nabble.com>
	<533E5385-BCB9-4F8E-9443-BC9217622EA3@me.com>
	<CAF4WX-d83vJJJ2VhsQBzyToES-Z_Z8i+TRotEAqOFx_=NVDt5A@mail.gmail.com>
Message-ID: <79E1B669-D910-4781-99A8-71C7FCFCD16C@me.com>

Hi,

Perl is still required for WriteXLS. That dependency has not changed.

What did change is that I removed the requirement for Text::CSV_XS, which contains C code in the Perl package source that required compilation and therefore could not be included in the WriteXLS CRAN package. The compilation process to create the binary is OS and Perl version specific. Thus, if not already installed, WriteXLS users would either have to install a pre-compiled binary using their Perl or OS package manager or via the CLI using 'cpan' and compile during local installation, which requires that compiler related tools also be installed, making it a bit more cumbersome.

I can now include Text::CSV_PP, which is recently stable enough to use and is a Perl only implementation of the CSV file parsing functionality found in Text::CSV_XS.

The output below suggests that you have Perl version 5.14 installed but that you may be missing Archive::Zip, which based upon my prior research is typically installed with most recent Perl distributions. Thus, I did not include it in the WriteXLS CRAN package nor do I check for it in testPerl(). Archive::Zip is a dependency for Excel::Writer::XLSX, which creates the XLSX files in WriteXLS().

Can you run testPerl() from the WriteXLS package and post back the output and also let me know what OS you are running? I presume some Linux distribution, albeit feedback from others using the new version of WriteXLS on Linux, OSX and Windows have not indicated that Archive::Zip is missing. 

I may then need to update WriteXLS to include Archive::Zip if there are some Perl installations that do not include it.

Thanks,

Marc


On Jul 24, 2013, at 11:24 PM, Orvalho Augusto <orvaquim at gmail.com> wrote:

> Hello!
> 
> None can imagine how this package is helpful for me. I might have
> understood wrong... is it correct that WriteXLS doesn't no more require
> Perl?
> 
> It is because I got this on my machine:
>>    WriteXLS("iris", "iriscomments.xlsx", AdjWidth = TRUE, BoldHeaderRow
> = TRUE)
> Can't locate Archive/Zip.pm in @INC (@INC contains:
> /usr/local/lib/R/site-library/WriteXLS/Perl /etc/perl
> /usr/local/lib/perl/5.14.2 /usr/local/share/perl/5.14.2 /usr/lib/perl5
> /usr/share/perl5 /usr/lib/perl/5.14 /usr/share/perl/5.14
> /usr/local/lib/site_perl .) at
> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX/Workbook.pm
> line 25.
> BEGIN failed--compilation aborted at
> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX/Workbook.pm
> line 25.
> Compilation failed in require at
> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX.pm line 18.
> BEGIN failed--compilation aborted at
> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX.pm line 18.
> Compilation failed in require at
> /usr/local/lib/R/site-library/WriteXLS/Perl/WriteXLSX.pl line 35.
> BEGIN failed--compilation aborted at
> /usr/local/lib/R/site-library/WriteXLS/Perl/WriteXLSX.pl line 35.
> The Perl script 'WriteXLSX.pl' failed to run successfully.
> 
> Thank you
> Caveman
> 
> 
> 
> On Wed, Jul 24, 2013 at 2:27 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> 
>> On Jul 23, 2013, at 5:40 PM, cognizio <geoff at uyleman.com> wrote:
>> 
>>> Great summary! It works great without the heavy PERL library. I am
>> running
>>> the YAML package I thought I needed to support WRITEXLS. Do I need it or
>> is
>>> YAML not a dependency?
>>> 
>>> Other question is on your last point: 'WRITEXLS COMMENT:' now shows up
>>> across the first row of the data output in the XLS. How do I modify these
>>> values?
>>> 
>>> Thx!
>>> 
>>> Cog
>> 
>> 
>> Hi,
>> 
>> There is no direct dependency on YAML.
>> 
>> The comments that appear in the first row in Excel are based upon the use
>> of the ?comment function, which adds a 'comment' attribute to the columns
>> of the data frame. If that attribute is present on one or more columns, an
>> Excel comment will be created for the columns that have it.
>> 
>> There is an example of this in ?WriteXLS:
>> 
>>    # Example using comment()
>>    # Commented cells with have a small red triangle in the
>>    # upper right hand corner of the cell. Click on the cell
>>    # or place the cursor over the cell to see the pop-up
>>    # containing the comment text.
>>    # Create an XLSX (Excel 2007) file
>>    # Adjust the column widths
>>    # Bold the header row
>>    comment(iris$Sepal.Length) <- "Length of the sepals (cm)"
>>    comment(iris$Sepal.Width) <- "Width of the sepals (cm)"
>>    comment(iris$Petal.Length) <- "Length of the petals (cm)"
>>    comment(iris$Petal.Width) <- "Width of the petals (cm)"
>>    comment(iris$Species) <- "Species of the flowers"
>>    WriteXLS("iris", "iriscomments.xlsx", AdjWidth = TRUE, BoldHeaderRow =
>> TRUE)
>> 
>> 
>> The 'comment' attribute is not seen when printing the data frame, but can
>> be seen when using ?str to print the structure of the data frame:
>> 
>>> str(iris)
>> 'data.frame':   150 obs. of  5 variables:
>> $ Sepal.Length: atomic  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>>  ..- attr(*, "comment")= chr "Length of the sepals (cm)"
>> $ Sepal.Width : atomic  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>>  ..- attr(*, "comment")= chr "Width of the sepals (cm)"
>> $ Petal.Length: atomic  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>>  ..- attr(*, "comment")= chr "Length of the petals (cm)"
>> $ Petal.Width : atomic  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>>  ..- attr(*, "comment")= chr "Width of the petals (cm)"
>> $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1
>> 1 1 1 1 ...
>>  ..- attr(*, "comment")= chr "Species of the flowers"
>> 
>> 
>> 
>> Regards,
>> 
>> Marc Schwartz


From rmh at temple.edu  Thu Jul 25 15:50:51 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 25 Jul 2013 09:50:51 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <151922E4-7260-475C-846E-0FD35809EC51@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
Message-ID: <CAGx1TMDwupTFU_XUxp7FfdLw2s8m2jPknjVKEKzykOvJrPasZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/0e10260b/attachment.pl>

From rmh at temple.edu  Thu Jul 25 15:56:21 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 25 Jul 2013 09:56:21 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <472EC292-7324-4263-9F20-002CE607123B@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
Message-ID: <CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/c47fe045/attachment.pl>

From rmh at temple.edu  Thu Jul 25 16:03:37 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 25 Jul 2013 10:03:37 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
Message-ID: <CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/782e39df/attachment.pl>

From edoardo.baldoni at gmail.com  Thu Jul 25 16:34:44 2013
From: edoardo.baldoni at gmail.com (Edoardo Baldoni)
Date: Thu, 25 Jul 2013 16:34:44 +0200
Subject: [R] Network of cities with distances as edges length
Message-ID: <CAOcqoUMvorSNDUhN2-UjAUh5Uf_dmq_mgYW1Rh2n7V_tZLHnPg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/808bde86/attachment.pl>

From dcarlson at tamu.edu  Thu Jul 25 16:36:35 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 25 Jul 2013 09:36:35 -0500
Subject: [R] Unable to install packages
In-Reply-To: <CAG90avM3vG9QOMiBLo6tBxMaWDf+WrXj_D2AxkeAynERVO-dEg@mail.gmail.com>
References: <CAG90avM3vG9QOMiBLo6tBxMaWDf+WrXj_D2AxkeAynERVO-dEg@mail.gmail.com>
Message-ID: <005a01ce8944$5d7ba9d0$1872fd70$@tamu.edu>

I'd start with the home page for R: http://www.r-project.org/
because you seem to have no idea what version is current
(3.0.1). You will find Google to be very helpful. As for
manuals, the official documentation is at

http://cran.r-project.org/manuals.html

and the user contributed manuals are at

http://cran.r-project.org/other-docs.html which includes "R
and Data Mining: Examples and Case Studies" by Yanchang Zhao
(PDF, 2013-04-26, 160 pages).

the Task Views are at

http://cran.r-project.org/web/views/ 

There are a number of other useful web sites including

http://www.statmethods.net/index.html
http://www.ats.ucla.edu/stat/r/
http://www.cyclismo.org/tutorial/R/
http://ww2.coastal.edu/kingw/statistics/R-tutorials/

Just to get you started.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Arnab
Chakrabarti
Sent: Thursday, July 25, 2013 2:36 AM
To: r-help at r-project.org
Subject: [R] Unable to install packages

Hi all. I am new to R. I have just installed R2.10.1 for my
Windows 7
computer. When I go to Packages > Install Packages on the
drop-down list, I
get the message:

"Warning: unable to access index for repository
http://ftp.iitm.ac.in/cran/bin/windows/contrib/2.10
Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/2.10
Error in install.packages (Null, .libPaths () [1L],
dependencies = NA, type
= type) :
   no packages were specified"

Please advise suitably.

Also suggest any good free online book/free online recognized
course to *
quickly* master R for data mining.

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From marc_schwartz at me.com  Thu Jul 25 16:42:28 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Jul 2013 09:42:28 -0500
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
	<CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
Message-ID: <E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>

Rich,

Any chance that you have access to a native Windows machine or to a colleague that does to try the files.

I am wondering if there is any chance that there is something about running Office in Windows under a VM on OSX that might be involved in some manner.

BTW, which VM (VMWare, Parallels, VirtualBox or ?) are you using?

Marc

On Jul 25, 2013, at 9:03 AM, Richard M. Heiberger <rmh at temple.edu> wrote:

> The Header and Prolog of both file.eps and file2.eps are the same.
> 
> 
> On Thu, Jul 25, 2013 at 9:56 AM, Richard M. Heiberger <rmh at temple.edu>wrote:
> 
>> file2.eps opens as a graph in windows PP 2010 and as an icon in PP 2013.
>> 
>> RPlot2.pptx <https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx> opens
>> as a graph in both windows PP and in Mac PP.
>> 
>> 
>> On Wed, Jul 24, 2013 at 2:39 PM, Marc Schwartz <marc_schwartz at me.com>wrote:
>> 
>>> Rich,
>>> 
>>> I don't have direct access to Windows and I don't run a VM on my Mac.
>>> 
>>> I e-mailed two PPTX files created on my Mac (Office 2011) to a colleague
>>> who has Office 2010 on his Windows laptop. The first was the file on
>>> DropBox that I linked earlier, with the regular plot. The second is this
>>> PPTX file:
>>> 
>>>  https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx
>>> 
>>> which contains this EPS file created with the barchart() code that you
>>> had below:
>>> 
>>>  https://www.dropbox.com/s/ujchnft7q3aa3pw/file2.eps
>>> 
>>> I went over to his office and he could open both PPTX files on his laptop
>>> and both of the embedded EPS plots were viewable without issue.
>>> 
>>> Can you open the PPTX file that I created above on your Windows instance?
>>> 
>>> Marc
>>> 
>>> 
>>> On Jul 24, 2013, at 12:56 PM, Rmh <rmh at temple.edu> wrote:
>>> 
>>>> office 2011 on mac, 2013 on windows.
>>>> 
>>>> i see the same misbehavior in base and lattice.
>>>> my standard simple test is
>>>> plot(1:10)
>>>> which is base.
>>>> 
>>>> did you try the windows side yet?
>>>> 
>>>> Rich



<snip of prior content>

From rmh at temple.edu  Thu Jul 25 16:56:17 2013
From: rmh at temple.edu (Rmh)
Date: Thu, 25 Jul 2013 10:56:17 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
	<CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
	<E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>
Message-ID: <B1E8F78E-04D2-42D0-B7D5-96EA1B6EC670@temple.edu>

i have parallels 8 as the  vm.
i can try a native pc this afternoon.

Sent from my iPhone

On Jul 25, 2013, at 10:42, Marc Schwartz <marc_schwartz at me.com> wrote:

> Rich,
> 
> Any chance that you have access to a native Windows machine or to a colleague that does to try the files.
> 
> I am wondering if there is any chance that there is something about running Office in Windows under a VM on OSX that might be involved in some manner.
> 
> BTW, which VM (VMWare, Parallels, VirtualBox or ?) are you using?
> 
> Marc
> 
> On Jul 25, 2013, at 9:03 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> 
>> The Header and Prolog of both file.eps and file2.eps are the same.
>> 
>> 
>> On Thu, Jul 25, 2013 at 9:56 AM, Richard M. Heiberger <rmh at temple.edu>wrote:
>> 
>>> file2.eps opens as a graph in windows PP 2010 and as an icon in PP 2013.
>>> 
>>> RPlot2.pptx <https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx> opens
>>> as a graph in both windows PP and in Mac PP.
>>> 
>>> 
>>> On Wed, Jul 24, 2013 at 2:39 PM, Marc Schwartz <marc_schwartz at me.com>wrote:
>>> 
>>>> Rich,
>>>> 
>>>> I don't have direct access to Windows and I don't run a VM on my Mac.
>>>> 
>>>> I e-mailed two PPTX files created on my Mac (Office 2011) to a colleague
>>>> who has Office 2010 on his Windows laptop. The first was the file on
>>>> DropBox that I linked earlier, with the regular plot. The second is this
>>>> PPTX file:
>>>> 
>>>> https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx
>>>> 
>>>> which contains this EPS file created with the barchart() code that you
>>>> had below:
>>>> 
>>>> https://www.dropbox.com/s/ujchnft7q3aa3pw/file2.eps
>>>> 
>>>> I went over to his office and he could open both PPTX files on his laptop
>>>> and both of the embedded EPS plots were viewable without issue.
>>>> 
>>>> Can you open the PPTX file that I created above on your Windows instance?
>>>> 
>>>> Marc
>>>> 
>>>> 
>>>> On Jul 24, 2013, at 12:56 PM, Rmh <rmh at temple.edu> wrote:
>>>> 
>>>>> office 2011 on mac, 2013 on windows.
>>>>> 
>>>>> i see the same misbehavior in base and lattice.
>>>>> my standard simple test is
>>>>> plot(1:10)
>>>>> which is base.
>>>>> 
>>>>> did you try the windows side yet?
>>>>> 
>>>>> Rich
> 
> 
> 
> <snip of prior content>


From j.a.balbuena at uv.es  Thu Jul 25 17:13:04 2013
From: j.a.balbuena at uv.es (Juan Antonio Balbuena)
Date: Thu, 25 Jul 2013 17:13:04 +0200
Subject: [R] transform dataframe with look-up table
Message-ID: <51F14080.3070100@uv.es>


   Hello
   I hope that there is a simple solution to this apparently complex problem.
   Any help will be much appreciated:
   I have a dataframe with Left and Right readings (that is, elements in each
   row are paired). For instance,
       Left Right
    [1]  9    8
    [2]  4    3
    [3]  2    1
    [4]  6    5
    [5]  3    1
    [6]  4    1
    [7]  3    2
    [8]  4    2
    [9]  10   8
   [10]  9   10
   I  need  to  produce a new data frame where the values are transformed
   according to a look-up table such as
           input    output
    [1]     5      1
    [2]    10     1
    [3]     4      2
    [4]     8      3
    [5]     6      5
    [6]     5      6
    [7]     7      6
    [8]     2      7
    [9]     9      7
   [10]    10    7
   [11]     2     8
   So  [1, ] in the new dataframe would be 7 3. Quite simple so far, but what
   makes things complicated is the multiple outputs for a single input. In this
   example, 10 corresponds to 1 and 7 so [9, ] in the input dataframe must
   yield two rows in its output counterpart: 1 3 and 7 3. Likewise the output
   for  [10, ] should be 7 1 and 7 7. In addition, given that 3 and 1 are
   missing as inputs the output for [5, ] should be NA NA.
   Thank you very much for your time.
   Juan Antonio Balbuena

   --

   Dr. Juan A. Balbuena
   Marine Zoology Unit
   Cavanilles Institute of Biodiversity and Evolutionary Biology
   University of
   Valencia
   [1]http://www.uv.es/~balbuena
   P.O. Box 22085
   [2]http://www.uv.es/cavanilles/zoomarin/index.htm
   46071 Valencia, Spain
   [3]http://cetus.uv.es/mullpardb/index.html
   e-mail: [4]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543 733
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
   NOTE! For shipments by EXPRESS COURIER use the following street address:
   C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia), Spain.
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

References

   1. http://www.uv.es/%7Ebalbuena
   2. http://www.uv.es/cavanilles/zoomarin/index.htm
   3. http://cetus.uv.es/mullpardb/index.html
   4. mailto:j.a.balbuena at uv.es

From arnaud.blaser at unine.ch  Thu Jul 25 17:16:09 2013
From: arnaud.blaser at unine.ch (Arnaud Blaser)
Date: Thu, 25 Jul 2013 17:16:09 +0200
Subject: [R] x-axis (categorial variable) ordering with xyplot function
 (lattice package)
In-Reply-To: <201307242241.r6OMf9J2005126@mail15.tpg.com.au>
References: <201307242241.r6OMf9J2005126@mail15.tpg.com.au>
Message-ID: <51F14139.4080002@unine.ch>

Dear Duncan,

"If you want to make a plot of the style of xyplot a numerical index of 
the country is needed and then use the scales argument to annote the 
labels with the country."

I think you were right. It worked and I does seem to be the simplest 
option. Many thanks !

Regards,
Arnaud

Le 25.07.2013 00:41, Duncan Mackay a ?crit :
> forgot to cc to list
>
> Hi
>
> For an xyplot you have not got the proper coding for the x value which 
> should be numeric.
>
> If you want to make a plot of the style of xyplot a numerical index of 
> the country is needed and then use the scales argument to annote the 
> labels with the country.
> Do you want multiple panels ?
>
> A self contained dataset via dput would help elicit further information.
>
> Have a look at the outer and related arguments as well as the group 
> arguments. A combined index for regions with countries may be necessary.
>
> Regards
>
> Duncan
>
> Duncan Mackay
> Department of Agronomy and Soil Science
> University of New England
> Armidale NSW 2351
> Email: home: mackay at northnet.com.au
>
>
> At 00:17 25/07/2013, you wrote:
>> Content-Type: text/plain
>> Content-Disposition: inline
>> Content-length: 2322
>>
>> Dear R mailing list readers,
>>
>> I am facing the following problem; for simplicity imagine I am 
>> working on a data frame of, say, 5 columns. The first column is a 
>> list of European countries, the other four are an index (continuous 
>> variable) of climate change impact under 4 different scenarios.
>>
>> Country
>>
>> 2050B2
>>
>> 2050A2
>>
>> 2080B2
>>
>> 2080A2
>>
>> Austria
>>
>> -0.2
>>
>> -0.6
>>
>> ...
>>
>>
>>
>> Belgium
>>
>> -0.2
>>
>> -0.6
>>
>>
>>
>>
>>
>> Bulgaria
>>
>> -0.5
>>
>> -0.8
>>
>>
>>
>>
>>
>> Czech republic
>>
>> -0.5
>>
>> -0.8
>>
>>
>>
>>
>>
>> United kingdom
>>
>> -0.2
>>
>> -0.6
>>
>>
>>
>>
>>
>>
>> I am using the package lattice to make a nice plot of the dots from 
>> the different scenario using the following code;
>>
>> my.plot <- xyplot(2050B2+2050A2+2080B2+2080A2~country, data=my.dat,
>> scales=list(x=list(rot=45)))
>>
>> note: the part "scales=list(x=list(rot=45))" is pure aesthetic here.
>>
>> So far, so good. However, I wish to order the x-axis (countries) by 
>> grouping them by European region; i.e Austria, Belgium and United 
>> kingdom are western Europe, while Bulgaria and Czech republic are 
>> eastern Europe. In excel I added a new "region) variable (i.e 1 for 
>> Western Europe, 2 for eastern Europe) and I re-ordered my data frame 
>> according to this "region" variable.
>>
>> I then imported this updated data frame in R, and checked how it 
>> looked with the usual code;
>>
>> pot_dat <-read.csv(file.choose(),header=TRUE, sep=";",dec=".")
>> pot_dat
>>
>> Again, so far so good; my second column ("country") is now ordered 
>> according to the values of the first column ("region").
>>
>> Region
>>
>> Country
>>
>> 2050B2
>>
>> 2050A2
>>
>> 2080B2
>>
>> 2080A2
>>
>> 1
>>
>> Austria
>>
>> -0.2
>>
>> -0.6
>>
>> ...
>>
>>
>>
>> 1
>>
>> Belgium
>>
>> -0.2
>>
>> -0.6
>>
>>
>>
>>
>>
>> 1
>>
>> United Kingdom
>>
>> -0.2
>>
>> -0.6
>>
>>
>>
>>
>>
>> 2
>>
>> Bulgaria
>>
>> -0.5
>>
>> -0.8
>>
>>
>>
>>
>>
>> 2
>>
>> Czech republic
>>
>> -0.5
>>
>> -0.8
>>
>>
>>
>>
>>
>>
>>
>> However, when I try to use the code as above, R automatically 
>> re-order the x-axis (country) in alphabetical order. This was not 
>> unexpected, but I have spent the day (unsuccessfully) looking for a 
>> way to simply tell R not to do that and to keep the variable 
>> "country" as it is now ordered in the data frame to construct the 
>> x-axis of my plot. Is there any way to force it to keep the order as 
>> it is in the data frame ?
>>
>> Any help would be really welcomed !
>>
>> Best,
>>
>> Arnaud Blaser
>> PhD candidate
>> University of Neuch?tel
>> Institute of Economic Research (IRENE)
>> Pierre-?-Mazel 7
>> CH-2000 Neuch?tel
>>
>>
>>         [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
--------------
Arnaud Blaser
PhD candidate
University of Neuch?tel
Institute of Economic Research (IRENE)
Pierre-?-Mazel 7
CH-2000 Neuch?tel


From orvaquim at gmail.com  Thu Jul 25 17:30:21 2013
From: orvaquim at gmail.com (Orvalho Augusto)
Date: Thu, 25 Jul 2013 17:30:21 +0200
Subject: [R] [R-pkgs] WriteXLS Version 3.0.0 Released
In-Reply-To: <79E1B669-D910-4781-99A8-71C7FCFCD16C@me.com>
References: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>
	<1374619209185-4672180.post@n4.nabble.com>
	<533E5385-BCB9-4F8E-9443-BC9217622EA3@me.com>
	<CAF4WX-d83vJJJ2VhsQBzyToES-Z_Z8i+TRotEAqOFx_=NVDt5A@mail.gmail.com>
	<79E1B669-D910-4781-99A8-71C7FCFCD16C@me.com>
Message-ID: <CAF4WX-et-xHi2yx51dygK6dju97j3aUOUUxN2hCrCDKcwyt83Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/ddd08e03/attachment.pl>

From Roger.Bivand at nhh.no  Thu Jul 25 17:35:37 2013
From: Roger.Bivand at nhh.no (Roger Bivand)
Date: Thu, 25 Jul 2013 15:35:37 +0000
Subject: [R] SpatialPolygonsDataFrame and unique()
References: <CAAkGiTXMUhyzzLQx7iDrtbLi_BqoQyoPXxm9OUpPU7gxgA9ZPw@mail.gmail.com>
Message-ID: <loom.20130725T171910-852@post.gmane.org>

Nicola Rossi <nicola.rossi20 <at> gmail.com> writes:

> 
> Hello everyone!
> 
> I'm a newbie in using the RGDAL and sp packages in R and as written in the
> object I have a problem with a SPDF and unique():

Consider posting to the R-sig-geo list; this is not a general R question.

> 
> I would have liked to write a simple script to delete in a couple of clicks
> the duplicated nodes that sometimes pop-up during the digitizing process in
> QGIS (I know that this can be done by hand, but when you have lots of
> features using a script in R would save some time).

Have you actually thought through what you are doing in the light of the
fact that Polygon objects are defined as having coords slots "Object of
class "matrix"; coordinates of the polygon; first point should equal the
last point" in ?"Polygon-class"? You are choosing the 2:n-1 rows of this
matrix, so removing the end points which must by definition be identical.

So for an arbitrary SpatialPolygons object, you see:

> validObject(slot(slot(spatial, "polygons")[[1]], "Polygons")[[1]])
Error in validObject(slot(slot(spatial, "polygons")[[1]], "Polygons")[[1]]) : 
  invalid class ?Polygon? object: ring not closed

There are lots of other infelicities in your script, which uses the internal
@ operator - never do this, always use access functions, lapply(), and
class-based constructors to ensure that the related internal objects get
updated. With your coding choices, none of the automatic mechanisms checking
validity get invoked.

You would need to reconstruct the coords matrix by retaining the first and
last rows, and using unique only on rows 2:n-1, using rbind(), then pass
this through Polygon() and Polygons() to recreate the internal representations.

Hope this clarifies,

Roger

> 
> I tried to use unique() in the "coords" slot, but it simply doesn't work
> and I can't figure out why. here's a copy of the script that I wrote:
> 
> > library(rgdal)
> > p4s<-"+proj=tmerc +lat_0=0 +lon_0=21 +k=1 +x_0=1500000 +y_0=0 +ellps=intl
> +units=m +no_defs"
> > layer<-c("Kataja")
> > dsn<-c("C:/Users/vagabond/Desktop/copy_for_r")
> > spatial<-readOGR(dsn=dsn,layer=layer,p4s=p4s)
> > len<-length(spatial)
> > for (i in 1:len){
> + temp<-length(spatial <at> polygons[[i]] <at> Polygons[[1]] <at>
coords[,1])-1
> + spatial <at> polygons[[i]] <at> Polygons[[1]] <at>
coords<-unique(spatial <at> polygons
> [[i]] <at> Polygons[[1]] <at> coords[2:temp,])
> + }
> 
> Thank you very much for the help!
> 
> Nicola
> 

Please never post HTML!

> 	[[alternative HTML version deleted]]
> 
>


From marc_schwartz at me.com  Thu Jul 25 17:45:48 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Jul 2013 10:45:48 -0500
Subject: [R] [R-pkgs] WriteXLS Version 3.0.0 Released
In-Reply-To: <CAF4WX-et-xHi2yx51dygK6dju97j3aUOUUxN2hCrCDKcwyt83Q@mail.gmail.com>
References: <4B50EBB3-5545-4F75-BAA9-5967AB3024F1@me.com>
	<1374619209185-4672180.post@n4.nabble.com>
	<533E5385-BCB9-4F8E-9443-BC9217622EA3@me.com>
	<CAF4WX-d83vJJJ2VhsQBzyToES-Z_Z8i+TRotEAqOFx_=NVDt5A@mail.gmail.com>
	<79E1B669-D910-4781-99A8-71C7FCFCD16C@me.com>
	<CAF4WX-et-xHi2yx51dygK6dju97j3aUOUUxN2hCrCDKcwyt83Q@mail.gmail.com>
Message-ID: <4AD21852-1B6E-442F-B6FC-D9C36AFBF755@me.com>

Hi,

Thank you.

I will work on an update to the package that includes Archive::Zip so that it covers this situation.

Regards.

Marc

On Jul 25, 2013, at 10:30 AM, Orvalho Augusto <orvaquim at gmail.com> wrote:

> Thank you for the feedback.
> 
> I installed the missing Archive::Zip packge and everthing went fine.
> 
> Orvalho
> 
> 
> On Thu, Jul 25, 2013 at 3:00 PM, Marc Schwartz <marc_schwartz at me.com> wrote:
> 
>> Hi,
>> 
>> Perl is still required for WriteXLS. That dependency has not changed.
>> 
>> What did change is that I removed the requirement for Text::CSV_XS, which
>> contains C code in the Perl package source that required compilation and
>> therefore could not be included in the WriteXLS CRAN package. The
>> compilation process to create the binary is OS and Perl version specific.
>> Thus, if not already installed, WriteXLS users would either have to install
>> a pre-compiled binary using their Perl or OS package manager or via the CLI
>> using 'cpan' and compile during local installation, which requires that
>> compiler related tools also be installed, making it a bit more cumbersome.
>> 
>> I can now include Text::CSV_PP, which is recently stable enough to use and
>> is a Perl only implementation of the CSV file parsing functionality found
>> in Text::CSV_XS.
>> 
>> The output below suggests that you have Perl version 5.14 installed but
>> that you may be missing Archive::Zip, which based upon my prior research is
>> typically installed with most recent Perl distributions. Thus, I did not
>> include it in the WriteXLS CRAN package nor do I check for it in
>> testPerl(). Archive::Zip is a dependency for Excel::Writer::XLSX, which
>> creates the XLSX files in WriteXLS().
>> 
>> Can you run testPerl() from the WriteXLS package and post back the output
>> and also let me know what OS you are running? I presume some Linux
>> distribution, albeit feedback from others using the new version of WriteXLS
>> on Linux, OSX and Windows have not indicated that Archive::Zip is missing.
>> 
>> I may then need to update WriteXLS to include Archive::Zip if there are
>> some Perl installations that do not include it.
>> 
>> Thanks,
>> 
>> Marc
>> 
>> 
>> On Jul 24, 2013, at 11:24 PM, Orvalho Augusto <orvaquim at gmail.com> wrote:
>> 
>>> Hello!
>>> 
>>> None can imagine how this package is helpful for me. I might have
>>> understood wrong... is it correct that WriteXLS doesn't no more require
>>> Perl?
>>> 
>>> It is because I got this on my machine:
>>>>   WriteXLS("iris", "iriscomments.xlsx", AdjWidth = TRUE, BoldHeaderRow
>>> = TRUE)
>>> Can't locate Archive/Zip.pm in @INC (@INC contains:
>>> /usr/local/lib/R/site-library/WriteXLS/Perl /etc/perl
>>> /usr/local/lib/perl/5.14.2 /usr/local/share/perl/5.14.2 /usr/lib/perl5
>>> /usr/share/perl5 /usr/lib/perl/5.14 /usr/share/perl/5.14
>>> /usr/local/lib/site_perl .) at
>>> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX/Workbook.pm
>>> line 25.
>>> BEGIN failed--compilation aborted at
>>> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX/Workbook.pm
>>> line 25.
>>> Compilation failed in require at
>>> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX.pm line 18.
>>> BEGIN failed--compilation aborted at
>>> /usr/local/lib/R/site-library/WriteXLS/Perl/Excel/Writer/XLSX.pm line 18.
>>> Compilation failed in require at
>>> /usr/local/lib/R/site-library/WriteXLS/Perl/WriteXLSX.pl line 35.
>>> BEGIN failed--compilation aborted at
>>> /usr/local/lib/R/site-library/WriteXLS/Perl/WriteXLSX.pl line 35.
>>> The Perl script 'WriteXLSX.pl' failed to run successfully.
>>> 
>>> Thank you
>>> Caveman
>>> 
>>> 
>>> 
>>> On Wed, Jul 24, 2013 at 2:27 PM, Marc Schwartz <marc_schwartz at me.com>
>> wrote:
>>> 
>>>> On Jul 23, 2013, at 5:40 PM, cognizio <geoff at uyleman.com> wrote:
>>>> 
>>>>> Great summary! It works great without the heavy PERL library. I am
>>>> running
>>>>> the YAML package I thought I needed to support WRITEXLS. Do I need it
>> or
>>>> is
>>>>> YAML not a dependency?
>>>>> 
>>>>> Other question is on your last point: 'WRITEXLS COMMENT:' now shows up
>>>>> across the first row of the data output in the XLS. How do I modify
>> these
>>>>> values?
>>>>> 
>>>>> Thx!
>>>>> 
>>>>> Cog
>>>> 
>>>> 
>>>> Hi,
>>>> 
>>>> There is no direct dependency on YAML.
>>>> 
>>>> The comments that appear in the first row in Excel are based upon the
>> use
>>>> of the ?comment function, which adds a 'comment' attribute to the
>> columns
>>>> of the data frame. If that attribute is present on one or more columns,
>> an
>>>> Excel comment will be created for the columns that have it.
>>>> 
>>>> There is an example of this in ?WriteXLS:
>>>> 
>>>>   # Example using comment()
>>>>   # Commented cells with have a small red triangle in the
>>>>   # upper right hand corner of the cell. Click on the cell
>>>>   # or place the cursor over the cell to see the pop-up
>>>>   # containing the comment text.
>>>>   # Create an XLSX (Excel 2007) file
>>>>   # Adjust the column widths
>>>>   # Bold the header row
>>>>   comment(iris$Sepal.Length) <- "Length of the sepals (cm)"
>>>>   comment(iris$Sepal.Width) <- "Width of the sepals (cm)"
>>>>   comment(iris$Petal.Length) <- "Length of the petals (cm)"
>>>>   comment(iris$Petal.Width) <- "Width of the petals (cm)"
>>>>   comment(iris$Species) <- "Species of the flowers"
>>>>   WriteXLS("iris", "iriscomments.xlsx", AdjWidth = TRUE, BoldHeaderRow
>> =
>>>> TRUE)
>>>> 
>>>> 
>>>> The 'comment' attribute is not seen when printing the data frame, but
>> can
>>>> be seen when using ?str to print the structure of the data frame:
>>>> 
>>>>> str(iris)
>>>> 'data.frame':   150 obs. of  5 variables:
>>>> $ Sepal.Length: atomic  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
>>>> ..- attr(*, "comment")= chr "Length of the sepals (cm)"
>>>> $ Sepal.Width : atomic  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
>>>> ..- attr(*, "comment")= chr "Width of the sepals (cm)"
>>>> $ Petal.Length: atomic  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
>>>> ..- attr(*, "comment")= chr "Length of the petals (cm)"
>>>> $ Petal.Width : atomic  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
>>>> ..- attr(*, "comment")= chr "Width of the petals (cm)"
>>>> $ Species     : Factor w/ 3 levels "setosa","versicolor",..: 1 1 1 1 1 1
>>>> 1 1 1 1 ...
>>>> ..- attr(*, "comment")= chr "Species of the flowers"
>>>> 
>>>> 
>>>> 
>>>> Regards,
>>>> 
>>>> Marc Schwartz
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jvadams at usgs.gov  Thu Jul 25 17:57:19 2013
From: jvadams at usgs.gov (Adams, Jean)
Date: Thu, 25 Jul 2013 10:57:19 -0500
Subject: [R] transform dataframe with look-up table
In-Reply-To: <51F14080.3070100@uv.es>
References: <51F14080.3070100@uv.es>
Message-ID: <CAN5YmCG8HPmws58bqVfW2cg1Xm9Rs8jW6aYbV9OcPwqAgad0CQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/e209ac06/attachment.pl>

From wdunlap at tibco.com  Thu Jul 25 18:01:30 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 25 Jul 2013 16:01:30 +0000
Subject: [R] transform dataframe with look-up table
In-Reply-To: <51F14080.3070100@uv.es>
References: <51F14080.3070100@uv.es>
Message-ID: <E66794E69CFDE04D9A70842786030B931C329F4D@PA-MBX01.na.tibco.com>

It would be helpful if you included the expected output for your example, but I think the following does what you want by using merge() for each lookup:

f0 <- function(inputDF, lookupDF)
{
    tmp1 <- merge(inputDF, lookupDF, by.x="Left", by.y="input",all.x=TRUE)
    tmp2 <- merge(tmp1, lookupDF, by.x="Right", by.y="input", all.x=TRUE)
    with(tmp2, data.frame(ID=ID, Right=output.x, Left=output.y)[order(ID), ])
}
# Your example data with an ID column added to track where the output rows came from
myInputDF <- data.frame(
    ID = 1:10,
    Left = c(9, 4, 2, 6, 3, 4, 3, 4, 10, 9),
    Right = c(8, 3, 1, 5, 1, 1, 2, 2, 8, 10))
myLookupDF <- data.frame(
    input = c(5, 10, 4, 8, 6, 5, 7, 2, 9, 10, 2),
    output = c(1, 1, 2, 3, 5, 6, 6, 7, 7, 7, 8))

f0(myInputDF, myLookupDF)
#    ID Right Left
# 12  1     7    3
# 9   2     2   NA
# 1   3     7   NA
# 2   3     8   NA
# 10  4     5    6
# 11  4     5    1
# 3   5    NA   NA
# 4   6     2   NA
# 5   7    NA    7
# 6   7    NA    8
# 7   8     2    7
# 8   8     2    8
# 13  9     1    3
# 14  9     7    3
# 15 10     7    1
# 16 10     7    7

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of Juan Antonio Balbuena
> Sent: Thursday, July 25, 2013 8:13 AM
> To: r-help at r-project.org
> Subject: [R] transform dataframe with look-up table
> 
> 
>    Hello
>    I hope that there is a simple solution to this apparently complex problem.
>    Any help will be much appreciated:
>    I have a dataframe with Left and Right readings (that is, elements in each
>    row are paired). For instance,
>        Left Right
>     [1]  9    8
>     [2]  4    3
>     [3]  2    1
>     [4]  6    5
>     [5]  3    1
>     [6]  4    1
>     [7]  3    2
>     [8]  4    2
>     [9]  10   8
>    [10]  9   10
>    I  need  to  produce a new data frame where the values are transformed
>    according to a look-up table such as
>            input    output
>     [1]     5      1
>     [2]    10     1
>     [3]     4      2
>     [4]     8      3
>     [5]     6      5
>     [6]     5      6
>     [7]     7      6
>     [8]     2      7
>     [9]     9      7
>    [10]    10    7
>    [11]     2     8
>    So  [1, ] in the new dataframe would be 7 3. Quite simple so far, but what
>    makes things complicated is the multiple outputs for a single input. In this
>    example, 10 corresponds to 1 and 7 so [9, ] in the input dataframe must
>    yield two rows in its output counterpart: 1 3 and 7 3. Likewise the output
>    for  [10, ] should be 7 1 and 7 7. In addition, given that 3 and 1 are
>    missing as inputs the output for [5, ] should be NA NA.
>    Thank you very much for your time.
>    Juan Antonio Balbuena
> 
>    --
> 
>    Dr. Juan A. Balbuena
>    Marine Zoology Unit
>    Cavanilles Institute of Biodiversity and Evolutionary Biology
>    University of
>    Valencia
>    [1]http://www.uv.es/~balbuena
>    P.O. Box 22085
>    [2]http://www.uv.es/cavanilles/zoomarin/index.htm
>    46071 Valencia, Spain
>    [3]http://cetus.uv.es/mullpardb/index.html
>    e-mail: [4]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543 733
>    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
>    NOTE! For shipments by EXPRESS COURIER use the following street address:
>    C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia), Spain.
>    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
> 
> References
> 
>    1. http://www.uv.es/%7Ebalbuena
>    2. http://www.uv.es/cavanilles/zoomarin/index.htm
>    3. http://cetus.uv.es/mullpardb/index.html
>    4. mailto:j.a.balbuena at uv.es
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From diggsb at ohsu.edu  Thu Jul 25 18:02:59 2013
From: diggsb at ohsu.edu (Brian Diggs)
Date: Thu, 25 Jul 2013 09:02:59 -0700
Subject: [R] transform dataframe with look-up table
References: <51F14080.3070100@uv.es>
Message-ID: <E5BA65CAFB491A4DBB1370F6C97216550744586DD2@EX-MB05.ohsu.edu>

On 7/25/2013 8:13 AM, Juan Antonio Balbuena wrote:
>
>     Hello
>     I hope that there is a simple solution to this apparently complex problem.
>     Any help will be much appreciated:
>     I have a dataframe with Left and Right readings (that is, elements in each
>     row are paired). For instance,
>         Left Right
>      [1]  9    8
>      [2]  4    3
>      [3]  2    1
>      [4]  6    5
>      [5]  3    1
>      [6]  4    1
>      [7]  3    2
>      [8]  4    2
>      [9]  10   8
>     [10]  9   10
>     I  need  to  produce a new data frame where the values are transformed
>     according to a look-up table such as
>             input    output
>      [1]     5      1
>      [2]    10     1
>      [3]     4      2
>      [4]     8      3
>      [5]     6      5
>      [6]     5      6
>      [7]     7      6
>      [8]     2      7
>      [9]     9      7
>     [10]    10    7
>     [11]     2     8
>     So  [1, ] in the new dataframe would be 7 3. Quite simple so far, but what
>     makes things complicated is the multiple outputs for a single input. In this
>     example, 10 corresponds to 1 and 7 so [9, ] in the input dataframe must
>     yield two rows in its output counterpart: 1 3 and 7 3. Likewise the output
>     for  [10, ] should be 7 1 and 7 7. In addition, given that 3 and 1 are
>     missing as inputs the output for [5, ] should be NA NA.
>     Thank you very much for your time.
>     Juan Antonio Balbuena

merge can handle both of these requirements.

First, making the two datasets reproducible:

Start <- data.frame(Left=c(9,4,2,6,3,4,3,4,10,9),
                     Right=c(8,3,1,5,1,1,2,2,8,10))

transformer <- data.frame(input=c(5,10,4,8,6,5,7,2,9,10,2),
                           output=c(1,1,2,3,5,6,6,7,7,7,8))

Then add a marker of the original row numbers so that the work can be 
checked more easily later (not really needed for the calculations):

Start$rownum <- seq_len(nrow(Start))

Two merge statements with the columns specified and all.x set to TRUE 
(to keep cases even without a match):

End <- merge(merge(Start, transformer, by.x="Left", by.y="input", 
all.x=TRUE),
              transformer, by.x="Right", by.y="input", all.x=TRUE)

Then we can look at the output, resorted by the original row numbers:

End[order(End$rownum),]

which gives

    Right Left rownum output.x output.y
12     8    9      1        7        3
9      3    4      2        2       NA
1      1    2      3        7       NA
2      1    2      3        8       NA
10     5    6      4        5        6
11     5    6      4        5        1
3      1    3      5       NA       NA
4      1    4      6        2       NA
5      2    3      7       NA        7
6      2    3      7       NA        8
7      2    4      8        2        7
8      2    4      8        2        8
13     8   10      9        1        3
14     8   10      9        7        3
15    10    9     10        7        1
16    10    9     10        7        7


>     --
>
>     Dr. Juan A. Balbuena
>     Marine Zoology Unit
>     Cavanilles Institute of Biodiversity and Evolutionary Biology
>     University of
>     Valencia
>     [1]http://www.uv.es/~balbuena
>     P.O. Box 22085
>     [2]http://www.uv.es/cavanilles/zoomarin/index.htm
>     46071 Valencia, Spain
>     [3]http://cetus.uv.es/mullpardb/index.html
>     e-mail: [4]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543 733
>     ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
>     NOTE! For shipments by EXPRESS COURIER use the following street address:
>     C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia), Spain.
>     ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
>
> References
>
>     1. http://www.uv.es/%7Ebalbuena
>     2. http://www.uv.es/cavanilles/zoomarin/index.htm
>     3. http://cetus.uv.es/mullpardb/index.html
>     4. mailto:j.a.balbuena at uv.es
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From dcarlson at tamu.edu  Thu Jul 25 18:04:04 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Thu, 25 Jul 2013 11:04:04 -0500
Subject: [R] transform dataframe with look-up table
In-Reply-To: <51F14080.3070100@uv.es>
References: <51F14080.3070100@uv.es>
Message-ID: <006a01ce8950$95bacf40$c1306dc0$@tamu.edu>

Here's an approach that seems to work. I added an 11th case to
your data since you did not have a case where both Left and
Right had multiple values in the lookup table. This creates an
id value so that we can merge left and right separately and
then merge them back together:

# Create test data frames
Left <- c(9, 4, 2, 6, 3, 4, 3, 4, 10, 9, 2)
Right <- c(8, 3, 1, 5, 1, 1, 2, 2, 8, 10, 5)
ID <- 1:11
Pair <- data.frame(ID, Left, Right)
input <- c(5, 10, 4, 8, 6, 5, 7, 2, 9, 10, 2)
output <- c(1, 1, 2, 3, 5, 6, 6, 7, 7, 7, 8)
Lookup <- data.frame(input, output)
# Merges
Lout <- merge(Pair, Lookup, by.x="Left", by.y="input", 
	all.x=TRUE)[,c("ID", "Left", "output")]
Rout <- merge(Pair, Lookup, by.x="Right", by.y="input", 
	all.x=TRUE)[, c("ID", "Right", "output")]
names(Rout)[3] <- "outputR"
names(Lout)[3] <- "outputL"
merge(Lout, Rout, all=TRUE)[,c(1, 2, 4, 3, 5)]

   ID Left Right outputL outputR
1   1    9     8       7       3
2   2    4     3       2      NA
3   3    2     1       7      NA
4   3    2     1       8      NA
5   4    6     5       5       6
6   4    6     5       5       1
7   5    3     1      NA      NA
8   6    4     1       2      NA
9   7    3     2      NA       7
10  7    3     2      NA       8
11  8    4     2       2       8
12  8    4     2       2       7
13  9   10     8       1       3
14  9   10     8       7       3
15 10    9    10       7       1
16 10    9    10       7       7
17 11    2     5       7       6
18 11    2     5       7       1
19 11    2     5       8       6
20 11    2     5       8       1

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Juan
Antonio Balbuena
Sent: Thursday, July 25, 2013 10:13 AM
To: r-help at r-project.org
Subject: [R] transform dataframe with look-up table


   Hello
   I hope that there is a simple solution to this apparently
complex problem.
   Any help will be much appreciated:
   I have a dataframe with Left and Right readings (that is,
elements in each
   row are paired). For instance,
       Left Right
    [1]  9    8
    [2]  4    3
    [3]  2    1
    [4]  6    5
    [5]  3    1
    [6]  4    1
    [7]  3    2
    [8]  4    2
    [9]  10   8
   [10]  9   10
   I  need  to  produce a new data frame where the values are
transformed
   according to a look-up table such as
           input    output
    [1]     5      1
    [2]    10     1
    [3]     4      2
    [4]     8      3
    [5]     6      5
    [6]     5      6
    [7]     7      6
    [8]     2      7
    [9]     9      7
   [10]    10    7
   [11]     2     8
   So  [1, ] in the new dataframe would be 7 3. Quite simple
so far, but what
   makes things complicated is the multiple outputs for a
single input. In this
   example, 10 corresponds to 1 and 7 so [9, ] in the input
dataframe must
   yield two rows in its output counterpart: 1 3 and 7 3.
Likewise the output
   for  [10, ] should be 7 1 and 7 7. In addition, given that
3 and 1 are
   missing as inputs the output for [5, ] should be NA NA.
   Thank you very much for your time.
   Juan Antonio Balbuena

   --

   Dr. Juan A. Balbuena
   Marine Zoology Unit
   Cavanilles Institute of Biodiversity and Evolutionary
Biology
   University of
   Valencia
   [1]http://www.uv.es/~balbuena
   P.O. Box 22085
   [2]http://www.uv.es/cavanilles/zoomarin/index.htm
   46071 Valencia, Spain
   [3]http://cetus.uv.es/mullpardb/index.html
   e-mail: [4]j.a.balbuena at uv.es    tel. +34 963 543 658
fax +34 963 543 733

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
   NOTE! For shipments by EXPRESS COURIER use the following
street address:
   C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia),
Spain.

++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

References

   1. http://www.uv.es/%7Ebalbuena
   2. http://www.uv.es/cavanilles/zoomarin/index.htm
   3. http://cetus.uv.es/mullpardb/index.html
   4. mailto:j.a.balbuena at uv.es
______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From Gavin.Simpson at uregina.ca  Thu Jul 25 18:26:25 2013
From: Gavin.Simpson at uregina.ca (Gavin Simpson)
Date: Thu, 25 Jul 2013 10:26:25 -0600
Subject: [R] MGCV: Degrees of freedom of smooth terms
In-Reply-To: <51EE4A04.8090309@agr.uni-goettingen.de>
References: <51EE4A04.8090309@agr.uni-goettingen.de>
Message-ID: <1374769585.2386.19.camel@haul.biol.uregina.ca>

On Tue, 2013-07-23 at 11:16 +0200, Christoph Scherber wrote:
> Dear all,
> 
> This is just a quick question regarding degrees of freedom in GAM
> models fit by MGCV (using select=T):
> 
> Can I roughly interpret them as:
> 
> 1 df: linear effect of x on y
> 2 df: approximately quadratic of x on y
> 3 df: approximately cubic effect of x on y?

Yes, approximately

> 1 df for a spatial term s(x,y): bilinear effect (?) or how would I call this?

A bilinear effect would have two df, no? In a linear regression z ~ x +
y would define a plane just like s(x, y) can and would use 2 df. 1 df
for the entire s(x,y) implies an additional penalty such that less than
1df is spent in the `x` or `y` dimensions of the spline.

> And what does "ref.df" in the summary output mean; is this the unpenalized degrees of freedom for
> each term?

IIRC, these are the dfs that are used in the tests reported. I am not
familiar enough with the details to comment more. If you turn on Select
= TRUE for example which adds an additional penalty then the ref.df can
be much larger than the edf values.

You might send an email to Simon Wood (or see if he picks up on this)
for a (far) more authoritative answer on this part of your question.

HTH

G

> 
> Thank you very much for answering!
> 
> Best wishes,
> Christoph
> 
> 

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From rmh at temple.edu  Thu Jul 25 18:30:43 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 25 Jul 2013 12:30:43 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <B1E8F78E-04D2-42D0-B7D5-96EA1B6EC670@temple.edu>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
	<CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
	<E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>
	<B1E8F78E-04D2-42D0-B7D5-96EA1B6EC670@temple.edu>
Message-ID: <CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/6cd74053/attachment.pl>

From peter.langfelder at gmail.com  Thu Jul 25 18:43:35 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Thu, 25 Jul 2013 09:43:35 -0700
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
	<CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
	<E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>
	<B1E8F78E-04D2-42D0-B7D5-96EA1B6EC670@temple.edu>
	<CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>
Message-ID: <CA+hbrhWZZeBL3N4Nsmqs1Kh3K1pcnZOwTFRyuhAnKMgZ4RNowg@mail.gmail.com>

On Thu, Jul 25, 2013 at 9:30 AM, Richard M. Heiberger <rmh at temple.edu> wrote:
> On Vista with Powerpoint 2007, file2.eps crashes powerpoint,
> Once file.eps displayed, several times it crashed powerpoint.
>
> My task is now to see if ghostscript can read a pdf or ps or eps and
> convert it to png at res=300.
> Do you know the incantation for that?

pdftoppm can do it and is available for linux and windows, hopefully
also on a Mac.

It is a command line utility and on linux, you would run something like

pdftoppm -png -r 300 file.pdf

to convert file.pdf to file00001.png, file00002.png etc (one png file
per page) at the resolution of 300 dpi.

HTH,

Peter

pdftoppm has many options, see its man page (or google).


From marc_schwartz at me.com  Thu Jul 25 18:44:02 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Jul 2013 11:44:02 -0500
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
	<CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
	<E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>
	<B1E8F78E-04D2-42D0-B7D5-96EA1B6EC670@temple.edu>
	<CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>
Message-ID: <63FFC930-8E7B-4D02-8C50-38481AB30C72@me.com>

Rich,

That's scary. Well, I could make a comment about Vista, but that would take us in a whole new direction... ;-)

As far as GS, for an EPS file to a PNG, try something along the lines of:

  gs -dSAFER -dBATCH -dNOPAUSE -r300 -dEPSCrop -sDEVICE=png16m -sOutputFile=file.png file.eps

That seems to work for me on OSX.

Regards,

Marc

On Jul 25, 2013, at 11:30 AM, Richard M. Heiberger <rmh at temple.edu> wrote:

> On Vista with Powerpoint 2007, file2.eps crashes powerpoint,
> Once file.eps displayed, several times it crashed powerpoint.
> 
> My task is now to see if ghostscript can read a pdf or ps or eps and
> convert it to png at res=300.
> Do you know the incantation for that?
> 
> 
> Rich
> 
> 
> On Thu, Jul 25, 2013 at 10:56 AM, Rmh <rmh at temple.edu> wrote:
> 
>> i have parallels 8 as the  vm.
>> i can try a native pc this afternoon.
>> 
>> Sent from my iPhone
>> 
>> On Jul 25, 2013, at 10:42, Marc Schwartz <marc_schwartz at me.com> wrote:
>> 
>>> Rich,
>>> 
>>> Any chance that you have access to a native Windows machine or to a
>> colleague that does to try the files.
>>> 
>>> I am wondering if there is any chance that there is something about
>> running Office in Windows under a VM on OSX that might be involved in some
>> manner.
>>> 
>>> BTW, which VM (VMWare, Parallels, VirtualBox or ?) are you using?
>>> 
>>> Marc
>>> 
>>> On Jul 25, 2013, at 9:03 AM, Richard M. Heiberger <rmh at temple.edu>
>> wrote:
>>> 
>>>> The Header and Prolog of both file.eps and file2.eps are the same.
>>>> 
>>>> 
>>>> On Thu, Jul 25, 2013 at 9:56 AM, Richard M. Heiberger <rmh at temple.edu
>>> wrote:
>>>> 
>>>>> file2.eps opens as a graph in windows PP 2010 and as an icon in PP
>> 2013.
>>>>> 
>>>>> RPlot2.pptx <https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx>
>> opens
>>>>> as a graph in both windows PP and in Mac PP.
>>>>> 
>>>>> 
>>>>> On Wed, Jul 24, 2013 at 2:39 PM, Marc Schwartz <marc_schwartz at me.com
>>> wrote:
>>>>> 
>>>>>> Rich,
>>>>>> 
>>>>>> I don't have direct access to Windows and I don't run a VM on my Mac.
>>>>>> 
>>>>>> I e-mailed two PPTX files created on my Mac (Office 2011) to a
>> colleague
>>>>>> who has Office 2010 on his Windows laptop. The first was the file on
>>>>>> DropBox that I linked earlier, with the regular plot. The second is
>> this
>>>>>> PPTX file:
>>>>>> 
>>>>>> https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx
>>>>>> 
>>>>>> which contains this EPS file created with the barchart() code that you
>>>>>> had below:
>>>>>> 
>>>>>> https://www.dropbox.com/s/ujchnft7q3aa3pw/file2.eps
>>>>>> 
>>>>>> I went over to his office and he could open both PPTX files on his
>> laptop
>>>>>> and both of the embedded EPS plots were viewable without issue.
>>>>>> 
>>>>>> Can you open the PPTX file that I created above on your Windows
>> instance?
>>>>>> 
>>>>>> Marc
>>>>>> 
>>>>>> 
>>>>>> On Jul 24, 2013, at 12:56 PM, Rmh <rmh at temple.edu> wrote:
>>>>>> 
>>>>>>> office 2011 on mac, 2013 on windows.
>>>>>>> 
>>>>>>> i see the same misbehavior in base and lattice.
>>>>>>> my standard simple test is
>>>>>>> plot(1:10)
>>>>>>> which is base.
>>>>>>> 
>>>>>>> did you try the windows side yet?
>>>>>>> 
>>>>>>> Rich
>>> 
>>> 
>>> 
>>> <snip of prior content>
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Thu Jul 25 18:47:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jul 2013 09:47:35 -0700
Subject: [R] Saving multiple rda-files as one rda-file
In-Reply-To: <1374491885996-4672041.post@n4.nabble.com>
References: <1374491885996-4672041.post@n4.nabble.com>
Message-ID: <FF05669B-9729-4253-BAF6-F8D181DF2218@comcast.net>


On Jul 22, 2013, at 4:18 AM, Dark wrote:

> Hi all,
> 
> For a project we have to process some very large CSV files (up to 40 gig)
> To reduce them in size and increase operating performance I wanted to store
> them as RData files.
> Since it was to big I decided to split the csv and saving those parts as
> separate .RDA files.
> So far so good. Now I want to bind them all together to save as one RDA file
> again and this is supprisingly difficult.
> 
> First I load my rda files into my environment:
> load(paste(rdaoutputdir, "file1.rda", sep=""))
> load(paste(rdaoutputdir, "file2.rda", sep=""))
> load(paste(rdaoutputdir, "file3.rda", sep=""))
> etc
> 
> Then I try to combine them into one object.
> 
> Using rbind like this gives memory allocation problems ('Error: cannot
> allocate vector of size')
> objectToSave <- rbind(object1, object2, object3)
> 
> using pre-allocation gives me a factor level error. I used this code:
> 	nextrow <- nrow(object1)+1
> 	object1[nextrow:(nextrow+nrow(object2)-1),] <- object2
> 	# we need to assure unique row names
>        row.names(object1) = 1:nrow(object1)
> 	rm(object2)
>        gc()
> 
> 15! warning messages:
> 1: In `[<-.factor`(`*tmp*`, iseq, value = structure(c(1L,  ... :
>  invalid factor level, NA generated
> 2: In `[<-.factor`(`*tmp*`, iseq, value = structure(c(1L,  ... :
>  invalid factor level, NA generated
> 

The warning messages suggests that the factor levels in object1, object2, object3 in corresponding columns are not the same.

> What can I do?

You can identify which columns are factors and make the corresponding columns have levels that span the values.

OR:

Depending on the contents of that factor you could convert to character before the rbind operation. If the levels are not particularly long (in character length), that procedure might not expand the memory footprint very much.

-- 
David
> 
> Regards Derk
> 
> 


David Winsemius
Alameda, CA, USA


From rmh at temple.edu  Thu Jul 25 19:18:37 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 25 Jul 2013 13:18:37 -0400
Subject: [R] .eps files and powerpoint
In-Reply-To: <63FFC930-8E7B-4D02-8C50-38481AB30C72@me.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
	<CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
	<E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>
	<B1E8F78E-04D2-42D0-B7D5-96EA1B6EC670@temple.edu>
	<CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>
	<63FFC930-8E7B-4D02-8C50-38481AB30C72@me.com>
Message-ID: <CAGx1TMAwAQ_Kq1S0Wx0Txu9G_hjAOgYPntNC7GYq2qVZRffpKQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/c0b11137/attachment.pl>

From g.rudge at bham.ac.uk  Thu Jul 25 19:30:32 2013
From: g.rudge at bham.ac.uk (Gavin Rudge)
Date: Thu, 25 Jul 2013 18:30:32 +0100
Subject: [R] ggplot2: further query about back to back bar plots
Message-ID: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06F3DC8A@mds-exch-02.adf.bham.ac.uk>

Further to my recent post on this topic and thanks to help received already (thanks BTW), I've got back-to-back plots working nicely to give me population pyramids, with some overlaid point data from a different time period, using the code below.

#packages
library(ggplot2)
library(reshape2)
library(plyr)
#sample data
set.seed(33)
df<-data.frame(ag=c(1:18),males_year1=sample(100:200,18),females_year1=sample(100:200,18),males_year2=sample(100:200,18),females_year2=sample(100:200,18))
#melt the data set
df<-data.frame(melt(df,id="ag"))
df
#here is the plot
p<-ggplot(df)+
  geom_bar(subset=.(df$variable=="males_year1"),stat="identity",aes(x=ag,y=value),fill="#6666FF")+
  geom_bar(subset=.(df$variable=="females_year1"),stat="identity",aes(x=ag,y=-value),fill="#FF9333")+
  geom_point(subset=.(df$variable=="males_year2"),stat="identity",aes(x=ag,y=value),size=3,colour="#330099")+
  geom_point(subset=.(df$variable=="females_year2"),stat="identity",aes(x=ag,y=-value),size=3,colour="#CC3300")+
  coord_flip()+
  theme_bw()+
  scale_y_continuous(limits=c(-200,200),breaks=seq(-200,200,50),labels=abs(seq(-200,200,50)))+
  scale_x_continuous(limits=c(0,19),breaks=seq(1,18,1),labels=abs(seq(1,18,1)))+
  xlab("age group")+ylab("population")+
  theme_bw()+
  xlab("age group")+
  ylab("population")+
  geom_text(y=-100,x=19.2,label="Females")+
  geom_text(y=100,x=19.2,label="Males")

p

Two questions remaining.  Firstly have I used a large amount of code to acheive this or is this about right for the effect that I'm after?

Secondly I'm quite confused about how to put a legend onto a plot like this. I'm getting slowly into the ggplot way of doing things, but I'm totally baffled by legends; say I wanted a legend with an appropriate label for both genders and both time periods showing the colours of the bars and dots I've used here as examples, how do I do this?  I've tried scale_fill with a bunch of arguments to no avial.  I'm confused about where in the hierarchy of ggplot commands you actually build the legend and how you map it to your data.  The usual trawl of the package pdf / cook book for R etc hasn't really helped. Can someone show me how to do this please?

Many thanks.

Gavin.  


From wewolski at gmail.com  Thu Jul 25 20:12:34 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Thu, 25 Jul 2013 20:12:34 +0200
Subject: [R] heatmap scale parameter
Message-ID: <CAAjnpdh_k7HL1JMtH8OmHwk5=uK9XafpC4ksZ8oaJHn7udD1BQ@mail.gmail.com>

does change only the colors but dendrograms are unaffected.

d <- matrix(rnorm(100),nrow=20)
heatmap(d)
heatmap(d,scale="column")
heatmap(d,scale="row")
heatmap(d,scale="none")


However scaling clearly affects clustering. see:

d <- scale(d)
heatmap(d,scale="none")


R version 3.0.1 (2013-05-16) -- "Good Sport"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-pc-linux-gnu (64-bit)

ciao

--
Witold Eryk Wolski


From ruipbarradas at sapo.pt  Thu Jul 25 20:34:46 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 25 Jul 2013 19:34:46 +0100
Subject: [R] ggplot2: further query about back to back bar plots
In-Reply-To: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06F3DC8A@mds-exch-02.adf.bham.ac.uk>
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06F3DC8A@mds-exch-02.adf.bham.ac.uk>
Message-ID: <51F16FC6.8090805@sapo.pt>

Hello,

I'm not an expert in ggplot2 graphics but I can (partly) answer to your 
first question. Inline.

Em 25-07-2013 18:30, Gavin Rudge escreveu:
> Further to my recent post on this topic and thanks to help received already (thanks BTW), I've got back-to-back plots working nicely to give me population pyramids, with some overlaid point data from a different time period, using the code below.
>
> #packages
> library(ggplot2)
> library(reshape2)
> library(plyr)
> #sample data
> set.seed(33)
> df<-data.frame(ag=c(1:18),males_year1=sample(100:200,18),females_year1=sample(100:200,18),males_year2=sample(100:200,18),females_year2=sample(100:200,18))
> #melt the data set
> df<-data.frame(melt(df,id="ag"))
> df
> #here is the plot
> p<-ggplot(df)+
>    geom_bar(subset=.(df$variable=="males_year1"),stat="identity",aes(x=ag,y=value),fill="#6666FF")+
>    geom_bar(subset=.(df$variable=="females_year1"),stat="identity",aes(x=ag,y=-value),fill="#FF9333")+
>    geom_point(subset=.(df$variable=="males_year2"),stat="identity",aes(x=ag,y=value),size=3,colour="#330099")+
>    geom_point(subset=.(df$variable=="females_year2"),stat="identity",aes(x=ag,y=-value),size=3,colour="#CC3300")+
>    coord_flip()+
>    theme_bw()+
>    scale_y_continuous(limits=c(-200,200),breaks=seq(-200,200,50),labels=abs(seq(-200,200,50)))+
>    scale_x_continuous(limits=c(0,19),breaks=seq(1,18,1),labels=abs(seq(1,18,1)))+
>    xlab("age group")+ylab("population")+
>    theme_bw()+
>    xlab("age group")+
>    ylab("population")+
>    geom_text(y=-100,x=19.2,label="Females")+
>    geom_text(y=100,x=19.2,label="Males")
>
> p
>
> Two questions remaining.  Firstly have I used a large amount of code to acheive this or is this about right for the effect that I'm after?

You have repeated some code, the following lines show up twice.

   theme_bw()+
   xlab("age group")+
   ylab("population")+


Hope this helps,

Rui Barradas
>
> Secondly I'm quite confused about how to put a legend onto a plot like this. I'm getting slowly into the ggplot way of doing things, but I'm totally baffled by legends; say I wanted a legend with an appropriate label for both genders and both time periods showing the colours of the bars and dots I've used here as examples, how do I do this?  I've tried scale_fill with a bunch of arguments to no avial.  I'm confused about where in the hierarchy of ggplot commands you actually build the legend and how you map it to your data.  The usual trawl of the package pdf / cook book for R etc hasn't really helped. Can someone show me how to do this please?
>
> Many thanks.
>
> Gavin.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Thu Jul 25 20:53:32 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Thu, 25 Jul 2013 19:53:32 +0100
Subject: [R] How to split two levels several times?
In-Reply-To: <trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>
	<trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>
Message-ID: <51F1742C.7070405@sapo.pt>

Hello,

I think the following does what you want. (I don't know if it makes much 
sense but it works.)



lens <- rle(as.character(XXX$electrode))$lengths
m <- length(lens) %/% 2
idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
if(length(lens) %% 2 != 0){
	idx <- c(idx, rep(m + 1, lens[length(lens)]))
	sp_idx <- split(idx, idx)
	n <- length(sp_idx[[m]])
	if(n %/% 2 < length(sp_idx[[m + 1]]))
		sp_idx[[m]][(n %/% 2 + 1):n] <- sp_idx[[m + 1]][1]
	else
		sp_idx[[m]][(n - length(sp_idx[[m + 1]]) + 1):n] <-  sp_idx[[m + 1]][1]
	idx <- unlist(sp_idx)
}

sp <- split(XXX, idx)
sp



Rui Barradas

Em 25-07-2013 11:40, dennis1991 at gmx.net escreveu:
> Hi Rui
> once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.
>
> So idx should not return
>   [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4
>
> but instead 6 times number 4 at the end
>   [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4
>
> Do you have any solution?
>
>
>> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>> An: dennis1991 at gmx.net
>> Cc: r-help at r-project.org
>> Betreff: Re: Aw: Re:  Re: [R] How to split two levels several times?
>>
>> Hello,
>>
>> As for the first question, note that in the case you describe, the
>> resulting list of df's will not be a split of the original, there will
>> be a duplication in the final 4-1 and 1-3. The following is a hack but
>> will do it.
>>
>>
>> lens <- rle(as.character(XXX$electrode))$lengths
>> m <- length(lens) %/% 2
>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
>> if(length(lens) %% 2 != 0)
>> 	idx <- c(idx, rep(m + 1, lens[length(lens)]))
>>
>> sp <- split(XXX, idx)
>>
>> if(length(lens) %% 2 != 0){
>> 	idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
>> 	sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
>> }
>> sp
>>
>>
>> As for the second question, I'm not understanding it, can you post
>> sample output?
>>
>> Rui Barradas
>>
>> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
>>> Hi Rui
>>> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
>>>
>>> lens <- rle(as.character(XXX$electrode))$lengths
>>> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
>>> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
>>> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
>>>
>>> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
>>>
>>>
>>> This is the table "XXX"
>>>
>>> electrode length
>>>
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode3 14.2
>>> electrode3 14.8
>>> electrode3 12.6
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode4 17.0
>>> electrode4 16.3
>>> electrode4 17.8
>>> electrode4 18.3
>>> electrode4 16.9
>>> electrode4 18.5
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode3 14.2
>>> electrode3 14.8
>>> electrode3 12.6
>>>
>>>
>>> This is a simplified table XX
>>>
>>> electrode1
>>> electrode2
>>> electrode1
>>> electrode3
>>> electrode1
>>> electrode4
>>> electrode2
>>> electrode1
>>> electrode2
>>> electrode3
>>> electrode2
>>> electrode4
>>> electrode3
>>> electrode1
>>> electrode3
>>> electrode2
>>> electrode3
>>> electrode4
>>> electrode4
>>> electrode1
>>> electrode4
>>> electrode2
>>> electrode4
>>> electrode3
>>>
>>>
>>>
>>>
>>>
>>>
>>>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>>>> An: dennis1991 at gmx.net
>>>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
>>>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
>>>>
>>>> Hello,
>>>>
>>>> It's better if you keep this on the list, the odds of getting more and
>>>> better answers are greater.
>>>>
>>>> As for your new question, try the following.
>>>>
>>>>
>>>> lens <- rle(as.character(XXX$electrode))$lengths
>>>> m <- length(lens) %/% 2
>>>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
>>>> split(XXX, idx)
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
>>>>> Hi
>>>>> this type of splitting works for my specific example. Thanks for your help.
>>>>>
>>>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,  electrode3-electrode2,  electrode4-electrode1. How should I split this?
>>>>>
>>>>>
>>>>> This is the table "XXX"
>>>>>
>>>>> electrode length
>>>>>
>>>>> electrode1 5.7
>>>>> electrode1 6.3
>>>>> electrode1 6.2
>>>>> electrode2 11.4
>>>>> electrode2 9.7
>>>>> electrode3 14.2
>>>>> electrode3 14.8
>>>>> electrode3 12.6
>>>>> electrode2 11.4
>>>>> electrode2 9.7
>>>>> electrode4 17.0
>>>>> electrode4 16.3
>>>>> electrode4 17.8
>>>>> electrode4 18.3
>>>>> electrode4 16.9
>>>>> electrode4 18.5
>>>>> electrode1 5.7
>>>>> electrode1 6.3
>>>>> electrode1 6.2
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
>>>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>>>>>> An: dennis1991 at gmx.net
>>>>>> Cc: r-help at r-project.org
>>>>>> Betreff: Re: [R] How to split two levels several times?
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Sorry, I've just realized that your data frame is named 'XXX', not
>>>>>> 'dat'. Change that and the rest should work:
>>>>>>
>>>>>>
>>>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
>>>>>> split(XXX, idx)
>>>>>>
>>>>>>
>>>>>> Rui Barradas
>>>>>>
>>>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
>>>>>>> Hello,
>>>>>>>
>>>>>>> Try the following.
>>>>>>>
>>>>>>>
>>>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
>>>>>>> split(dat, idx)
>>>>>>>
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I have a small problem with the function split() and would appreciate
>>>>>>>> your help.
>>>>>>>>
>>>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
>>>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
>>>>>>>> split the table always at the row where ?electrode1? starts again so
>>>>>>>> that I can export 7  individual dataframes (numbered ?dataframe1? to
>>>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
>>>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
>>>>>>>> I tried the split function with various setups:
>>>>>>>>
>>>>>>>> t <- as.factor(XXX$electrode)
>>>>>>>>
>>>>>>>> dataframeX <- split(XXX, f=(levels=t))
>>>>>>>>
>>>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
>>>>>>>>
>>>>>>>>
>>>>>>>> This is the table "XXX"
>>>>>>>>
>>>>>>>> electrode    length
>>>>>>>>
>>>>>>>> electrode1    5.7
>>>>>>>> electrode1    6.3
>>>>>>>> electrode1    6.2
>>>>>>>> electrode2    11.4
>>>>>>>> electrode2    9.7
>>>>>>>> electrode1    5.7
>>>>>>>> electrode1    6.3
>>>>>>>> electrode1    6.2
>>>>>>>> electrode3    14.2
>>>>>>>> electrode3    14.8
>>>>>>>> electrode3    12.6
>>>>>>>> electrode1    5.7
>>>>>>>> electrode1    6.3
>>>>>>>> electrode1    6.2
>>>>>>>> electrode4    17.0
>>>>>>>> electrode4    16.3
>>>>>>>> electrode4    17.8
>>>>>>>> electrode4    18.3
>>>>>>>> electrode4    16.9
>>>>>>>> electrode4    18.5
>>>>>>>> electrode1    ....
>>>>>>>> ....        ....
>>>>>>>> electrode5    ....
>>>>>>>> ....        ....
>>>>>>>> electrode1    ....
>>>>>>>> electrode6    ....
>>>>>>>> electrode1    ....
>>>>>>>> electrode7    ....
>>>>>>>> electrode1    ....
>>>>>>>> electrode8    ....
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>
>>


From jsorkin at grecc.umaryland.edu  Thu Jul 25 21:11:37 2013
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 25 Jul 2013 15:11:37 -0400
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
Message-ID: <51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>

Colleagues,
Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
Thank you,
John

John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From dwinsemius at comcast.net  Thu Jul 25 21:14:46 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jul 2013 12:14:46 -0700
Subject: [R] .eps files and powerpoint
In-Reply-To: <CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>
References: <CAGx1TMDmtF1d1LF7Fg1XzOs9u4yBswQg_e1C15kMYTL-Http-g@mail.gmail.com>
	<20130724060747.GC24293@slingshot.co.nz>
	<CAGx1TMD9na0AOB2=RCvtTxQp4Bx-3Q-hTM1H+3nzCtrbbwX_6A@mail.gmail.com>
	<C1E51AED-9FA2-4073-9CE9-CDD78A154A39@me.com>
	<CAGx1TMBvA=2kA5dZ2piQUFNWe-PQ==FZpx_gy-Vy7LDkk9rT=A@mail.gmail.com>
	<151922E4-7260-475C-846E-0FD35809EC51@me.com>
	<CAGx1TMAB1ssb-iudDhw=RrgT8JZ531Qf0D6d+8g3UrXqBsHwXg@mail.gmail.com>
	<98D531FA-5F9A-4DA6-B781-2547A6382726@me.com>
	<18D5B6DD-3FFB-41A9-ADC9-0FD6FF7FE3BF@temple.edu>
	<472EC292-7324-4263-9F20-002CE607123B@me.com>
	<CAGx1TMApPzSryVgv7ozprt7qSLUc0nKmcXEcvX=yUJo6FuwJ7Q@mail.gmail.com>
	<CAGx1TMD78cKmGqnJQAiBUSN2rJStEdE6zKPfYtqwOcNk0ShYKA@mail.gmail.com>
	<E13A30FB-72BD-492C-ABF0-B779467EBD68@me.com>
	<B1E8F78E-04D2-42D0-B7D5-96EA1B6EC670@temple.edu>
	<CAGx1TMAcDCAdjduOGxLNWA98JViZMn89KjPqYxd_MOvMBsqyMA@mail.gmail.com>
Message-ID: <7D535E0F-7D91-4FA0-BAC4-C9D0BBF86700@comcast.net>


On Jul 25, 2013, at 9:30 AM, Richard M. Heiberger wrote:

> On Vista with Powerpoint 2007, file2.eps crashes powerpoint,
> Once file.eps displayed, several times it crashed powerpoint.
> 
> My task is now to see if ghostscript can read a pdf or ps or eps and
> convert it to png at res=300.
> Do you know the incantation for that?

On a Mac that can be done with Preview.app. It used to be that you would use the Save as ... menu, but with the newer versions, it is File/Export... choose Format=PNG and resolution.

-- 
David

> 
> 
> Rich
> 
> 
> On Thu, Jul 25, 2013 at 10:56 AM, Rmh <rmh at temple.edu> wrote:
> 
>> i have parallels 8 as the  vm.
>> i can try a native pc this afternoon.
>> 
>> Sent from my iPhone
>> 
>> On Jul 25, 2013, at 10:42, Marc Schwartz <marc_schwartz at me.com> wrote:
>> 
>>> Rich,
>>> 
>>> Any chance that you have access to a native Windows machine or to a
>> colleague that does to try the files.
>>> 
>>> I am wondering if there is any chance that there is something about
>> running Office in Windows under a VM on OSX that might be involved in some
>> manner.
>>> 
>>> BTW, which VM (VMWare, Parallels, VirtualBox or ?) are you using?
>>> 
>>> Marc
>>> 
>>> On Jul 25, 2013, at 9:03 AM, Richard M. Heiberger <rmh at temple.edu>
>> wrote:
>>> 
>>>> The Header and Prolog of both file.eps and file2.eps are the same.
>>>> 
>>>> 
>>>> On Thu, Jul 25, 2013 at 9:56 AM, Richard M. Heiberger <rmh at temple.edu
>>> wrote:
>>>> 
>>>>> file2.eps opens as a graph in windows PP 2010 and as an icon in PP
>> 2013.
>>>>> 
>>>>> RPlot2.pptx <https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx>
>> opens
>>>>> as a graph in both windows PP and in Mac PP.
>>>>> 
>>>>> 
>>>>> On Wed, Jul 24, 2013 at 2:39 PM, Marc Schwartz <marc_schwartz at me.com
>>> wrote:
>>>>> 
>>>>>> Rich,
>>>>>> 
>>>>>> I don't have direct access to Windows and I don't run a VM on my Mac.
>>>>>> 
>>>>>> I e-mailed two PPTX files created on my Mac (Office 2011) to a
>> colleague
>>>>>> who has Office 2010 on his Windows laptop. The first was the file on
>>>>>> DropBox that I linked earlier, with the regular plot. The second is
>> this
>>>>>> PPTX file:
>>>>>> 
>>>>>> https://www.dropbox.com/s/snm7cb9chrkcrff/RPlot2.pptx
>>>>>> 
>>>>>> which contains this EPS file created with the barchart() code that you
>>>>>> had below:
>>>>>> 
>>>>>> https://www.dropbox.com/s/ujchnft7q3aa3pw/file2.eps
>>>>>> 
>>>>>> I went over to his office and he could open both PPTX files on his
>> laptop
>>>>>> and both of the embedded EPS plots were viewable without issue.
>>>>>> 
>>>>>> Can you open the PPTX file that I created above on your Windows
>> instance?
>>>>>> 
>>>>>> Marc
>>>>>> 
>>>>>> 
>>>>>> On Jul 24, 2013, at 12:56 PM, Rmh <rmh at temple.edu> wrote:
>>>>>> 
>>>>>>> office 2011 on mac, 2013 on windows.
>>>>>>> 
>>>>>>> i see the same misbehavior in base and lattice.
>>>>>>> my standard simple test is
>>>>>>> plot(1:10)
>>>>>>> which is base.
>>>>>>> 
>>>>>>> did you try the windows side yet?
>>>>>>> 
>>>>>>> Rich
>>> 
>>> 
>>> 
>>> <snip of prior content>
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From diggsb at ohsu.edu  Thu Jul 25 21:24:41 2013
From: diggsb at ohsu.edu (Brian Diggs)
Date: Thu, 25 Jul 2013 12:24:41 -0700
Subject: [R] ggplot2: further query about back to back bar plots
References: <3AA2D3466F17A14B81EB6DBE74A8D0CC0B06F3DC8A@mds-exch-02.adf.bham.ac.uk>
	<51F16FC6.8090805@sapo.pt>
Message-ID: <E5BA65CAFB491A4DBB1370F6C97216550744586DD3@EX-MB05.ohsu.edu>

On 7/25/2013 11:34 AM, Rui Barradas wrote:
> Hello,
>
> I'm not an expert in ggplot2 graphics but I can (partly) answer to your
> first question. Inline.
>
> Em 25-07-2013 18:30, Gavin Rudge escreveu:
>> Further to my recent post on this topic and thanks to help received
>> already (thanks BTW), I've got back-to-back plots working nicely to
>> give me population pyramids, with some overlaid point data from a
>> different time period, using the code below.
>>
>> #packages
>> library(ggplot2)
>> library(reshape2)
>> library(plyr)
>> #sample data
>> set.seed(33)
>> df<-data.frame(ag=c(1:18),males_year1=sample(100:200,18),females_year1=sample(100:200,18),males_year2=sample(100:200,18),females_year2=sample(100:200,18))
>>
>> #melt the data set
>> df<-data.frame(melt(df,id="ag"))
>> df
>> #here is the plot
>> p<-ggplot(df)+
>>
>> geom_bar(subset=.(df$variable=="males_year1"),stat="identity",aes(x=ag,y=value),fill="#6666FF")+
>>
>>
>> geom_bar(subset=.(df$variable=="females_year1"),stat="identity",aes(x=ag,y=-value),fill="#FF9333")+
>>
>>
>> geom_point(subset=.(df$variable=="males_year2"),stat="identity",aes(x=ag,y=value),size=3,colour="#330099")+
>>
>>
>> geom_point(subset=.(df$variable=="females_year2"),stat="identity",aes(x=ag,y=-value),size=3,colour="#CC3300")+
>>
>>    coord_flip()+
>>    theme_bw()+
>>
>> scale_y_continuous(limits=c(-200,200),breaks=seq(-200,200,50),labels=abs(seq(-200,200,50)))+
>>
>>
>> scale_x_continuous(limits=c(0,19),breaks=seq(1,18,1),labels=abs(seq(1,18,1)))+
>>
>>    xlab("age group")+ylab("population")+
>>    theme_bw()+
>>    xlab("age group")+
>>    ylab("population")+
>>    geom_text(y=-100,x=19.2,label="Females")+
>>    geom_text(y=100,x=19.2,label="Males")
>>
>> p
>>
>> Two questions remaining.  Firstly have I used a large amount of code
>> to acheive this or is this about right for the effect that I'm after?
>
> You have repeated some code, the following lines show up twice.
>
>    theme_bw()+
>    xlab("age group")+
>    ylab("population")+

In addition to the repetition Rui notes, here is how I'd shorten it, 
albeit not by much (and with wrapping, actually more lines):

p <- ggplot(df)+
   geom_bar(subset=.(variable=="males_year1"), stat="identity",
            position="identity", aes(x=ag,y=value), fill="#6666FF")+
   geom_bar(subset=.(variable=="females_year1"), stat="identity",
            position="identity", aes(x=ag,y=-value), fill="#FF9333")+
   geom_point(subset=.(variable=="males_year2"),
              aes(x=ag,y=value), size=3, colour="#330099")+
   geom_point(subset=.(variable=="females_year2"),
              aes(x=ag,y=-value), size=3, colour="#CC3300")+
   coord_flip()+
   theme_bw()+
   scale_y_continuous("population", limits=c(-200,200),
                      breaks=seq(-200,200,50), labels=abs)+
   scale_x_continuous("age group", limits=c(0,19.2), breaks=seq(1,18,1))+
   annotate(geom="text", y=-100, x=19.2, label="Females")+
   annotate(geom="text", y= 100, x=19.2, label="Males")

Changes:
* adding position="identity" to the two geom_bar calls to suppress the
Warning message:
Stacking not well defined when ymin != 0
* dropping stat="identity" in geom_point since that is the default
* pulling the xlab and ylab into the scale_x_continuous and 
scale_y_continuous since you already have those calls
* simplify the labels for the scales. For x, don't need to do anything 
to specify the labels; the work as expected based on the breaks. For y, 
rather than give a vector of labels, give a function which transforms 
the breaks into the labels you want (abs).
* convert last two geom_text calls to annotations.
* increased the limits in scale_x_continuous so that the annotations 
were not lost
* the subset should not refer to df directly

>
> Hope this helps,
>
> Rui Barradas
>>
>> Secondly I'm quite confused about how to put a legend onto a plot like
>> this. I'm getting slowly into the ggplot way of doing things, but I'm
>> totally baffled by legends; say I wanted a legend with an appropriate
>> label for both genders and both time periods showing the colours of
>> the bars and dots I've used here as examples, how do I do this?  I've
>> tried scale_fill with a bunch of arguments to no avial.  I'm confused
>> about where in the hierarchy of ggplot commands you actually build the
>> legend and how you map it to your data.  The usual trawl of the
>> package pdf / cook book for R etc hasn't really helped. Can someone
>> show me how to do this please?

Your confusion with legends likely comes from how ggplot approaches 
legends. A legend, for ggplot, shows the mapping between an aesthetic 
(color, shape, etc.) and the data values that it represents. Therefore, 
it is only necessary when there is a mapping between data and 
aesthetics. In your example, you manually set your colour/fill 
aesthetics, so there is no mapping, so there is no legend.

The variables that are implied by your data are Sex and Year, so make 
those explicit:

df2 <- cbind(df, colsplit(df$variable, "_", c("Sex", "Year")))

Now we can simplify the two geom_bar and two geom_point calls into one 
each, setting the sign of value based on the Sex column. I set the 
colour and fill to the interaction of Sex and Year (could have just used 
variable, I suppose, but this is how I did it). Now colour and fill are 
really two separate aesthetics, but I need to treat them the same and 
include both in each geom so that it comes out right in the end. The 
colors that you specify manually in the original version become 
specified in the scale_colour_manual and scale_fill_manual calls:

p <- ggplot(df2) +
   geom_bar(subset=.(Year=="year1"), stat="identity",
            position="identity",
            aes(x=ag, y=ifelse(Sex=="females",-1,1)*value,
                colour=interaction(Sex,Year),
                fill=interaction(Sex,Year))) +
   geom_point(subset=.(Year=="year2"),
              aes(x=ag, y=ifelse(Sex=="females",-1,1)*value,
                  colour=interaction(Sex,Year),
                  fill=interaction(Sex,Year)),
              size=3) +
   annotate(geom="text", y=-100, x=19.2, label="Females") +
   annotate(geom="text", y= 100, x=19.2, label="Males") +
   scale_x_continuous("age group", limits=c(0,19.2), breaks=seq(1,18,1))+
   scale_y_continuous("population", limits=c(-200,200),
                      breaks=seq(-200,200,50), labels=abs) +
   scale_colour_manual("Sex and Year",
                       breaks = c("females.year1", "females.year2",
                                  "males.year1", "males.year2"),
                       values = c("#FF9333", "#CC3300",
                                  "#6666FF", "#330099")) +
   scale_fill_manual("Sex and Year",
                     breaks = c("females.year1", "females.year2",
                                "males.year1", "males.year2"),
                     values = c("#FF9333", "#CC3300",
                                "#6666FF", "#330099")) +
   coord_flip() +
   theme_bw()

Conceptually, you are mapping Sex to a color and Year to a shade of that 
color, but ggplot does not have a way of splitting up aspects of colors 
to different data variables (hue to one variable, saturation to another, 
say), so this hack of mapping the combination of them is used.

You can get the legend to be a bit more like a grid by adding

guide = guide_legend(nrow=2)

to both scale_colour_manual and scale_fill_manual. The labels in those 
can also be changed to something better (be sure to do it in both).

>> Many thanks.
>>
>> Gavin.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From marc_schwartz at me.com  Thu Jul 25 21:27:06 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Jul 2013 14:27:06 -0500
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
Message-ID: <4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>


On Jul 25, 2013, at 2:11 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:

> Colleagues,
> Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
> I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
> Thank you,
> John



John,

See Terry's 'coxme' package:

  http://cran.r-project.org/web/packages/coxme/index.html


You also might find the following of interest:

  http://bjo.bmj.com/content/71/9/645.full.pdf

  http://www.ncbi.nlm.nih.gov/pubmed/22226885

  http://www.ncbi.nlm.nih.gov/pubmed/22078901



Regards,

Marc Schwartz


From dwinsemius at comcast.net  Thu Jul 25 23:45:52 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 25 Jul 2013 14:45:52 -0700
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
	<4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
Message-ID: <4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>


On Jul 25, 2013, at 12:27 PM, Marc Schwartz wrote:

> 
> On Jul 25, 2013, at 2:11 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
> 
>> Colleagues,
>> Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
>> I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
>> Thank you,
>> John
> 
> 
> 
> John,
> 
> See Terry's 'coxme' package:
> 
>  http://cran.r-project.org/web/packages/coxme/index.html
> 

When I looked over the description of coxme, I was concerned it was not really designed with this in mind. Looking at Therneau and Grambsch, I thought section 8.4.2 in the 'Multiple Events per Subject' Chapter fit the analysis question well. There they compared the use of coxph( ...+cluster(ID),,...)  withcoxph( ...+strata(ID),,...). Unfortunately I could not tell for sure which one was being described as superio but I think it was the cluster() alternative. I seem to remember there are discussions in the archives.

-- 
David.
> 
> You also might find the following of interest:
> 
>  http://bjo.bmj.com/content/71/9/645.full.pdf
> 
>  http://www.ncbi.nlm.nih.gov/pubmed/22226885
> 
>  http://www.ncbi.nlm.nih.gov/pubmed/22078901
> 
> 
> 
> Regards,
> 
> Marc Schwartz
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From michael.weylandt at gmail.com  Thu Jul 25 23:58:54 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Thu, 25 Jul 2013 16:58:54 -0500
Subject: [R] constructing a daily time series
In-Reply-To: <CAAcyNCz7PjEsNC9oJ8eOOyF_+4aQGVTKNBis-_yt6m6xLNX68w@mail.gmail.com>
References: <000001ce872e$587ceab0$0976c010$@iu.edu>
	<CAAcyNCz7PjEsNC9oJ8eOOyF_+4aQGVTKNBis-_yt6m6xLNX68w@mail.gmail.com>
Message-ID: <CAAmySGNH+S-HEg4F3G5fqXGk8iiK7dYCuHBbMpHVS6TRiJ4WWg@mail.gmail.com>

On Mon, Jul 22, 2013 at 11:17 PM, Pascal Oettli <kridox at ymail.com> wrote:
> Hello,
>
> ?zoo
>
> Regards,
> Pascal
>
>
> 2013/7/23 shanxiao <shanxiao at umail.iu.edu>
>
>> Dear all,
>>
>>
>>
>> I have a vector of observations through day, and based on it, I try to
>> construct a daily time series with the R function ts(), but it seems that
>> it
>> only enables to construct a weekly, monthly, quarterly and yearly time
>> series, does anyone know whether there is an option to build a daily time
>> series? Thanks.
>>

Like Pascal said, you probably want to use the zoo/xts time series
classes, but if you have reason to stick to ts() you can set the
frequency to 365. I've written on this list before that "frequency" is
a slightly subtle idea with time series (and you can find that post if
you're interested), but it's not hard-coded to anything in particular.

MW


From f.harrell at Vanderbilt.Edu  Fri Jul 26 00:54:24 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Thu, 25 Jul 2013 17:54:24 -0500
Subject: [R] Can't figure out why short figure won't work
Message-ID: <51F1ACA0.20005@vanderbilt.edu>

I can't get the points and "a" and "b" to render correctly (they are 
squeezed into the axis) unless I make the height of the figure waste a 
lot of space.  I'd appreciate any ideas.  The code is below. Thanks!

png('/tmp/z.png', width=480, height=100)
par(mar=c(3,.5,1,.5))
plot.new()
par(usr=c(-10, 410, -.04, 1.04))
par(mgp=c(1.5,.5,0))
axis(1, at=seq(0, 400, by=50))
axis(1, at=seq(0, 400, by=25), tcl=-.25, labels=FALSE)
title(xlab='Mean Count')
points(x, rep(-.02, length(x)))
lines(rep(.25*1500, 2), c(-.04, .04), col='blue')
lines(rep(.196*1500, 2), c(-.04, .04), col='blue')
text(.25*1500, .07, 'a', col='blue')
text(.196*1500,.07, 'b', col='blue')
dev.off()

It works if I use height=350.

Frank


 > version
                _
platform       x86_64-pc-linux-gnu
arch           x86_64
os             linux-gnu
system         x86_64, linux-gnu
status
major          3
minor          0.1
year           2013
month          05
day            16
svn rev        62743
language       R
version.string R version 3.0.1 (2013-05-16)
nickname       Good Sport
 >
-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From rmh at temple.edu  Fri Jul 26 01:06:26 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 25 Jul 2013 19:06:26 -0400
Subject: [R] Can't figure out why short figure won't work
In-Reply-To: <51F1ACA0.20005@vanderbilt.edu>
References: <51F1ACA0.20005@vanderbilt.edu>
Message-ID: <CAGx1TMC+WRV9jqCCCCFDZbb=Xyedi+UY5mjNGgqrh+J7tG9+sA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/17913084/attachment.pl>

From robert.b.lynch at gmail.com  Fri Jul 26 02:45:49 2013
From: robert.b.lynch at gmail.com (Robert Lynch)
Date: Thu, 25 Jul 2013 17:45:49 -0700
Subject: [R] help with apply (lapply or sapply not sure)
Message-ID: <CACYeG1go=eMWigs5_8VRYcVT_OwQ=SfqHHbMret9DmTNtO1UUQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/92d9a22f/attachment.pl>

From marc_schwartz at me.com  Fri Jul 26 03:14:57 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 25 Jul 2013 20:14:57 -0500
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
	<4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
	<4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>
Message-ID: <6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>


On Jul 25, 2013, at 4:45 PM, David Winsemius <dwinsemius at comcast.net> wrote:

> 
> On Jul 25, 2013, at 12:27 PM, Marc Schwartz wrote:
> 
>> 
>> On Jul 25, 2013, at 2:11 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>> 
>>> Colleagues,
>>> Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
>>> I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
>>> Thank you,
>>> John
>> 
>> 
>> 
>> John,
>> 
>> See Terry's 'coxme' package:
>> 
>> http://cran.r-project.org/web/packages/coxme/index.html
>> 
> 
> When I looked over the description of coxme, I was concerned it was not really designed with this in mind. Looking at Therneau and Grambsch, I thought section 8.4.2 in the 'Multiple Events per Subject' Chapter fit the analysis question well. There they compared the use of coxph( ...+cluster(ID),,...)  withcoxph( ...+strata(ID),,...). Unfortunately I could not tell for sure which one was being described as superio but I think it was the cluster() alternative. I seem to remember there are discussions in the archives.


David,

I think that you raise a good point. The example in the book (I had to wait to get home to read it) is potentially different however, in that the subject's eye's were randomized to treatment or control, which would seem to suggest comparable baseline characteristics for each pair of eyes, as well as an active intervention on one side where a difference in treatment effect between each eye is being analyzed.

It is not clear from John's description above if there is one hip that will be treated versus one as a control and whether the extent of disease at baseline is similar in each pair of hips. Presumably the timing of hip replacements will be staggered at some level, even if there is comparable disease, simply due to post-op recovery time and surgical risk. In cases where the disease between each hip is materially different, that would be another factor to consider, however I would defer to orthopaedic physicians/surgeons from a subject matter expertise consideration. It is possible that the bilateral hip replacement data might be more of a parallel to bilateral breast cancer data, if each breast were to be tracked separately.

I have cc'd Terry here, hoping that he might jump in and offer some insights into the pros/cons of using coxme versus coxph with either a cluster or strata based approach, or perhaps even a frailty based approach as in 9.4.1 in the book.

Regards,

Marc


> 
> -- 
> David.
>> 
>> You also might find the following of interest:
>> 
>> http://bjo.bmj.com/content/71/9/645.full.pdf
>> 
>> http://www.ncbi.nlm.nih.gov/pubmed/22226885
>> 
>> http://www.ncbi.nlm.nih.gov/pubmed/22078901
>> 
>> 
>> 
>> Regards,
>> 
>> Marc Schwartz
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jsorkin at grecc.umaryland.edu  Fri Jul 26 04:06:34 2013
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Thu, 25 Jul 2013 22:06:34 -0400
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
	<4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
	<4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>
	<6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>
Message-ID: <51F1A176020000CB000EB1F4@smtp.medicine.umaryland.edu>

David 
Thank you for your thoughts.
The data I am analyzing do not come from a clinical trial but rather from a cohort study whose aim is to determine risk factors for surgical therapy to treat their joints.
John

Sent from my iPhone

On Jul 25, 2013, at 9:15 PM, "Marc Schwartz <marc_schwartz at me.com>" <marc_schwartz at me.com> wrote:

> 
> On Jul 25, 2013, at 4:45 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
>> 
>> On Jul 25, 2013, at 12:27 PM, Marc Schwartz wrote:
>> 
>>> 
>>> On Jul 25, 2013, at 2:11 PM, John Sorkin <jsorkin at grecc.umaryland.edu> wrote:
>>> 
>>>> Colleagues,
>>>> Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
>>>> I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
>>>> Thank you,
>>>> John
>>> 
>>> 
>>> 
>>> John,
>>> 
>>> See Terry's 'coxme' package:
>>> 
>>> http://cran.r-project.org/web/packages/coxme/index.html
>> 
>> When I looked over the description of coxme, I was concerned it was not really designed with this in mind. Looking at Therneau and Grambsch, I thought section 8.4.2 in the 'Multiple Events per Subject' Chapter fit the analysis question well. There they compared the use of coxph( ...+cluster(ID),,...)  withcoxph( ...+strata(ID),,...). Unfortunately I could not tell for sure which one was being described as superio but I think it was the cluster() alternative. I seem to remember there are discussions in the archives.
> 
> 
> David,
> 
> I think that you raise a good point. The example in the book (I had to wait to get home to read it) is potentially different however, in that the subject's eye's were randomized to treatment or control, which would seem to suggest comparable baseline characteristics for each pair of eyes, as well as an active intervention on one side where a difference in treatment effect between each eye is being analyzed.
> 
> It is not clear from John's description above if there is one hip that will be treated versus one as a control and whether the extent of disease at baseline is similar in each pair of hips. Presumably the timing of hip replacements will be staggered at some level, even if there is comparable disease, simply due to post-op recovery time and surgical risk. In cases where the disease between each hip is materially different, that would be another factor to consider, however I would defer to orthopaedic physicians/surgeons from a subject matter expertise consideration. It is possible that the bilateral hip replacement data might be more of a parallel to bilateral breast cancer data, if each breast were to be tracked separately.
> 
> I have cc'd Terry here, hoping that he might jump in and offer some insights into the pros/cons of using coxme versus coxph with either a cluster or strata based approach, or perhaps even a frailty based approach as in 9.4.1 in the book.
> 
> Regards,
> 
> Marc
> 
> 
>> 
>> -- 
>> David.
>>> 
>>> You also might find the following of interest:
>>> 
>>> http://bjo.bmj.com/content/71/9/645.full.pdf
>>> 
>>> http://www.ncbi.nlm.nih.gov/pubmed/22226885
>>> 
>>> http://www.ncbi.nlm.nih.gov/pubmed/22078901
>>> 
>>> 
>>> 
>>> Regards,
>>> 
>>> Marc Schwartz
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> 

Confidentiality Statement:
This email message, including any attachments, is for th...{{dropped:6}}


From jim at bitwrit.com.au  Fri Jul 26 07:34:36 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 26 Jul 2013 15:34:36 +1000
Subject: [R] Can't figure out why short figure won't work
In-Reply-To: <51F1ACA0.20005@vanderbilt.edu>
References: <51F1ACA0.20005@vanderbilt.edu>
Message-ID: <51F20A6C.20706@bitwrit.com.au>

On 07/26/2013 08:54 AM, Frank Harrell wrote:
> I can't get the points and "a" and "b" to render correctly (they are
> squeezed into the axis) unless I make the height of the figure waste a
> lot of space. I'd appreciate any ideas. The code is below. Thanks!
>
> png('/tmp/z.png', width=480, height=100)
> par(mar=c(3,.5,1,.5))
> plot.new()
> par(usr=c(-10, 410, -.04, 1.04))
> par(mgp=c(1.5,.5,0))
> axis(1, at=seq(0, 400, by=50))
> axis(1, at=seq(0, 400, by=25), tcl=-.25, labels=FALSE)
> title(xlab='Mean Count')
> points(x, rep(-.02, length(x)))
> lines(rep(.25*1500, 2), c(-.04, .04), col='blue')
> lines(rep(.196*1500, 2), c(-.04, .04), col='blue')
> text(.25*1500, .07, 'a', col='blue')
> text(.196*1500,.07, 'b', col='blue')
> dev.off()
>
> It works if I use height=350.
>
> Frank
>
I get an error (x is missing), but I would try:

...
par(usr=c(-10,410,-0.1,1.04)
...

Jim


From ahmedco31 at hotmail.com  Thu Jul 25 15:05:02 2013
From: ahmedco31 at hotmail.com (Ahmed Abo-Zaid)
Date: Thu, 25 Jul 2013 15:05:02 +0200
Subject: [R] simulating help
Message-ID: <DUB122-W1722837210D3A7D8296847A4690@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/d9c625ad/attachment.pl>

From didier.laurent3 at hotmail.com  Fri Jul 26 06:00:11 2013
From: didier.laurent3 at hotmail.com (Laurent DIDIER)
Date: Fri, 26 Jul 2013 13:00:11 +0900
Subject: [R] PPML in R
Message-ID: <DUB112-W974B5937A9D3213E21891FB06A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/57ad55de/attachment.pl>

From dobzhanski at gmail.com  Fri Jul 26 04:13:30 2013
From: dobzhanski at gmail.com (john d)
Date: Thu, 25 Jul 2013 23:13:30 -0300
Subject: [R] histogram with bars colored according to a vector of values
Message-ID: <CAMLNaBYjLfNV2KE12g1AbetuA=YMy+UCQxuth4144EH3Vdwh=A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/ad48f57e/attachment.pl>

From girijagun at gmail.com  Fri Jul 26 07:37:55 2013
From: girijagun at gmail.com (G Girija)
Date: Fri, 26 Jul 2013 11:07:55 +0530
Subject: [R] number of items to replace is not a multiple of replacement
	length
Message-ID: <CAOLvsEzRORQ+SQvrfcb4VqsXV5vqLtum9W01fgW516nvoiOORQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/c33acf3e/attachment.pl>

From info at software-solutions.nl  Thu Jul 25 16:17:44 2013
From: info at software-solutions.nl (Dark)
Date: Thu, 25 Jul 2013 07:17:44 -0700 (PDT)
Subject: [R] Saving multiple rda-files as one rda-file
In-Reply-To: <1374491885996-4672041.post@n4.nabble.com>
References: <1374491885996-4672041.post@n4.nabble.com>
Message-ID: <1374761864513-4672313.post@n4.nabble.com>

Hi, 

Yes maybe I should have been more clear on my problem.
I want to append the different data-frames back into one variable ( rbind )
and save it as one R Data file.

Regards Derk



--
View this message in context: http://r.789695.n4.nabble.com/Saving-multiple-rda-files-as-one-rda-file-tp4672041p4672313.html
Sent from the R help mailing list archive at Nabble.com.


From jclow at umail.ucsb.edu  Thu Jul 25 20:02:35 2013
From: jclow at umail.ucsb.edu (John W. Clow)
Date: Thu, 25 Jul 2013 18:02:35 +0000
Subject: [R] =?windows-1252?q?GGplot_2_=96_cannot_get_histogram_and_box_pl?=
 =?windows-1252?q?ot_axis_to_match=2E?=
Message-ID: <53F5FA310C439841A76E397AAFF387151E5B3EFC@BY2PRD0811MB439.namprd08.prod.outlook.com>

Problem:
I am trying to get the histogram and box plot x axis to match. I?ve tried using the expand_limits function to make the axis match but that didn?t make the axis match. The histogram?s axis are still consistently larger than the ones for the box plot (though the function did help). Does anyone have a suggestion as to what I should do instead?


Background:
I am building a Shiny app that displays a histogram below a bar chart for a set of data that a user uploads to the app. If you want to see the app, go here http://spark.rstudio.com/jclow/Archive20130725HistogramApp/
To run the app, select ?Use Sample Data? , then select  ?MPG.city? under choose a column, then finally select box plot.


Sample code:
Below is a snippet of my code to demonstrate the problems I have.

library(ggplot2)

#sample data from ggplot2
data(Cars93, package = "MASS")
dataSet <- Cars93

#variables to calculate the range to extend the axis
dataVector <- unlist(dataSet[,"MPG.city"]) 

dataRange <- max(dataVector) - min(dataVector)

graphRange <- c(min(dataVector) - dataRange/5,
                max(dataVector) + dataRange/5)

#making the box plot
theBoxPlot <- ggplot(dataSet,aes_string(x = "MPG.city",y = "MPG.city"))

theBoxPlot = theBoxPlot  + geom_boxplot() + expand_limits(y= graphRange) + coord_flip()
print(theBoxPlot)


#making the histogram
thePlot <- ggplot(dataSet,aes_string(x = "MPG.city"))
thePlot <-thePlot + geom_histogram()  + expand_limits(x= graphRange)

print(thePlot)


Thank you for taking the time to read this.

John Clow
UCSB Student


From jeroen.van.leuken at rivm.nl  Thu Jul 25 13:56:11 2013
From: jeroen.van.leuken at rivm.nl (Jeroen)
Date: Thu, 25 Jul 2013 04:56:11 -0700 (PDT)
Subject: [R] Multiple interaction terms in GAMM-model
Message-ID: <1374753371065-4672297.post@n4.nabble.com>

Dear all,

I am trying to correlate a variable tau1 to a set of other variables (x1,
x2, x3, x4), taking into account an interaction with time ('doy') and place
('region'), and taking into account dependency of data in time per object
ID. My dataset looks like:

  doy  objectID    region     tau1                x1              x2                   
x3         x4
      1         1             A              0.000000        0.08          
0.3657            64.1      0.001100
      1         2             C              0.000000        0.10          
0.3150            74.3      0.000847
      1         3             B              0.000000        0.07          
0.3264            60.9      0.000854
      1         4             B              0.000000        0.08          
0.3058            63.2      0.000713
      1         5             D              2.716998        0.11          
0.2835            93.7      0.000660
....
 365         1             A              0.010000        0.06          
0.5489            27.3      0.003878
 365         2             C              0.234000        0.12          
0.1798            23.1      0.000278
 365         3             B              1.353500        0.09          
0.3417            37.8      0.000271
 365         4             B              0.000000        0.40          
0.1347            13.4      0.000173
 365         5             D              3.478008        0.21          
0.2384            37.7      0.000703

The total dataset consists of 151,840 rows (365 days x 416 object ID's)

Since the data is dependent in time per objectID, I use a GAMM model with an
autocorrelation function. Since each variable x1, x2, etc. is dependent on
time and place, I should incorporate this as well. 

Therefore I am wondering if the following gamm-model is correct for my
situation:

model <- gamm( tau1 ~ te( x1, by= doy ) + te( x1, by= factor( region ) ) +
... + te( x4, by= doy ) + te( x4, by= factor( region ) ) + factor( region ),
correlation= corAR1(form= ~ doy|objectID ), na.action= na.omit ).

Does anyone know if this is ok? 

Or should I use a model which also includes terms like " te( x1 ) + ... +
te( x4 )".
And is the correlation function correct?

Thanks so much!!

Jeroen



--
View this message in context: http://r.789695.n4.nabble.com/Multiple-interaction-terms-in-GAMM-model-tp4672297.html
Sent from the R help mailing list archive at Nabble.com.


From sibylle.stoeckli at gmx.ch  Thu Jul 25 12:16:14 2013
From: sibylle.stoeckli at gmx.ch (=?ISO-8859-1?Q?Sibylle_St=F6ckli?=)
Date: Thu, 25 Jul 2013 12:16:14 +0200
Subject: [R] lme (weights) and glht
Message-ID: <19056582-2908-40AE-91BD-B60D9E10CF24@gmx.ch>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/e7d2fa05/attachment.pl>

From jim at bitwrit.com.au  Fri Jul 26 07:55:56 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Fri, 26 Jul 2013 15:55:56 +1000
Subject: [R] histogram with bars colored according to a vector of values
In-Reply-To: <CAMLNaBYjLfNV2KE12g1AbetuA=YMy+UCQxuth4144EH3Vdwh=A@mail.gmail.com>
References: <CAMLNaBYjLfNV2KE12g1AbetuA=YMy+UCQxuth4144EH3Vdwh=A@mail.gmail.com>
Message-ID: <51F20F6C.5070105@bitwrit.com.au>

On 07/26/2013 12:13 PM, john d wrote:
> Dear all,
>
> Let's say I have the following data.frame:
>
> dat<-data.frame(x=rnorm(100), y=rnorm(100,2))
>
> and I plot a histogram of variable x, somethink like:
> hist(dat$x, breaks=-5:5)
>
> Now, I'd like to color each bar according to the mean of the cases
> according to y. For instance, the color of the bar between -2 and -1 should
> reflect the mean of variable y for the corresponding cases. Any suggestions?
>
> John
>
Hi John,
Try this:

dat$xcut<-cut(dat$x,breaks=-5:5)
library(plotrix)
barcol<-color.scale(by(dat$y,dat$xcut,mean),extremes=c("red","blue"))
hist(dat$x,breaks=-5:5,col=barcol)

Jim


From petr.pikal at precheza.cz  Fri Jul 26 08:53:15 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Jul 2013 06:53:15 +0000
Subject: [R] help with apply (lapply or sapply not sure)
In-Reply-To: <CACYeG1go=eMWigs5_8VRYcVT_OwQ=SfqHHbMret9DmTNtO1UUQ@mail.gmail.com>
References: <CACYeG1go=eMWigs5_8VRYcVT_OwQ=SfqHHbMret9DmTNtO1UUQ@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FD27@SRVEXCHMBX.precheza.cz>

Hi

I would just use for cycle. Something like

lll <- vector("list", length(InputFiles))
for (i in InputFiles) {

everything what you want to do for each file
you can store it in a list
lll[[i]] <- whatever you want to store there

}

After populating list you can do anything with it.

Regards
Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of Robert Lynch
> Sent: Friday, July 26, 2013 2:46 AM
> To: r-help at r-project.org
> Subject: [R] help with apply (lapply or sapply not sure)
> 
> I am reading in a bunch of files and then processing them all in the
> same
> way.
> 
> I am sure there as a better way then to copy and past the code for each
> file. Here is what I've done so far
> 
> InputFiles<-
> as.character(list.files("~/ISLE/RWork/DataWarehouseMining/byCourse/"))
> #Path to the Course data files
> 
> for (i in InputFiles) {
>   #
> print(head(read.csv(paste("~/ISLE/RWork/DataWarehouseMining/byCourse/",
> i, sep=""))))
>   print(paste("Reading file
> ~/ISLE/RWork/DataWarehouseMining/byCourse/", i,
> sep=","))
>   assign(i,
> read.csv(paste("~/ISLE/RWork/DataWarehouseMining/byCourse/", i,
> sep="")))
> }#note last file is NOT a course file by the student information.
> Master<-StudentInfoForRobertWUnitAt7A_2.csv #this is the last file
> 
> 
> CourseFiles <-InputFiles[- c(15,16)] # ignore the student info
> ...7A.csv &
> ...7A_2.csv
> 
> #for each file I do the following
> #Bis 101
> summary(BigInstBIS101.csv)
> B101 <- BigInstBIS101.csv[-c(3,4,8)]
> summary(B101)
> B101$WH_ID <- as.factor(B101$WH_ID)
> B101$SID <- as.factor(B101$SID)
> B101$TERM <- as.factor(B101$TERM)
> B101$CRN <- as.factor(B101$CRN)
> B101$CRN_TRM <- as.factor(B101$CRN_TRM)
> B101$INST_NUM <- as.factor(B101$INST_NUM)
> B101$zGrade <- with(B101, ave(GRADE., list(TERM, INST_NUM), FUN =
> scale))
> write.csv(B101,"B101.csv", row.names = FALSE)
> 
> #Bis 2A
> B2A <- BigInstBIS2A.csv[-c(3,4,8)]
> summary(B2A)
> B2A$WH_ID <- as.factor(B2A$WH_ID)
> B2A$SID <- as.factor(B2A$SID)
> B2A$TERM <- as.factor(B2A$TERM)
> B2A$CRN <- as.factor(B2A$CRN)
> B2A$CRN_TRM <- as.factor(B2A$CRN_TRM)
> B2A$INST_NUM <- as.factor(B2A$INST_NUM)
> B2A$zGrade <- with(B2A, ave(GRADE., list(TERM, INST_NUM), FUN = scale))
> write.csv(B2A,"B2A.csv", row.names = FALSE)
> 
> 
> And so on for another 12 courses, however I am changing what I am doing
> as
> part of the reading in the file and don't want to replace the code in
> 14
> different places.
> suggestions?  Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From gb at stat.umu.se  Fri Jul 26 08:54:26 2013
From: gb at stat.umu.se (=?ISO-8859-1?Q?G=F6ran_Brostr=F6m?=)
Date: Fri, 26 Jul 2013 08:54:26 +0200
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <51F1A176020000CB000EB1F4@smtp.medicine.umaryland.edu>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
	<4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
	<4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>
	<6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>
	<51F1A176020000CB000EB1F4@smtp.medicine.umaryland.edu>
Message-ID: <51F21D22.2070603@stat.umu.se>

On 07/26/2013 04:06 AM, John Sorkin wrote:
> David Thank you for your thoughts. The data I am analyzing do not
> come from a clinical trial but rather from a cohort study whose aim
> is to determine risk factors for surgical therapy to treat their
> joints. John

As David explained, there are several ways of approaching this 
situation. If it is a treatment/control case (which yours isn't), 
stratification is appropriate. It boils down to a simple sign test 
where we compare the number of pairs with longest survival of the 
treated with the number of pairs with the longest survival of the 
control. Undetermined (due to censoring) pairs are thrown away.

Generally, stratification is an alternative to the frailty model, but it 
has some drawbacks: loss of power (especially with small stratum sizes), 
and you cannot use covariates that are constant within pairs (personal 
characteristics in your case). The frailty model comes with stronger 
assumptions than stratification, but you avoid the drawbacks just 
mentioned. The clustering method, finally, is for variance correction in 
the ordinary Cox regression.

In your case, would recommend the frailty approach with coxme (while we 
wait for Terry's verdict!).

G?ran

> Sent from my iPhone
>
> On Jul 25, 2013, at 9:15 PM, "Marc Schwartz <marc_schwartz at me.com>"
> <marc_schwartz at me.com> wrote:
>
>>
>> On Jul 25, 2013, at 4:45 PM, David Winsemius
>> <dwinsemius at comcast.net> wrote:
>>
>>>
>>> On Jul 25, 2013, at 12:27 PM, Marc Schwartz wrote:
>>>
>>>>
>>>> On Jul 25, 2013, at 2:11 PM, John Sorkin
>>>> <jsorkin at grecc.umaryland.edu> wrote:
>>>>
>>>>> Colleagues, Is there any R package that will allow one to
>>>>> perform a repeated measures Cox Proportional Hazards
>>>>> regression? I don't think coxph is set up to handle this type
>>>>> of problem, but I would be happy to know that I am not
>>>>> correct. I am doing a study of time to hip joint replacement.
>>>>> As each person has two hips, a given person can appear in the
>>>>> dataset twice, once for the left hip and once for the right
>>>>> hip, and I need to account for the correlation of data from a
>>>>> single individual. Thank you, John
>>>>
>>>>
>>>>
>>>> John,
>>>>
>>>> See Terry's 'coxme' package:
>>>>
>>>> http://cran.r-project.org/web/packages/coxme/index.html
>>>
>>> When I looked over the description of coxme, I was concerned it
>>> was not really designed with this in mind. Looking at Therneau
>>> and Grambsch, I thought section 8.4.2 in the 'Multiple Events per
>>> Subject' Chapter fit the analysis question well. There they
>>> compared the use of coxph( ...+cluster(ID),,...)  withcoxph(
>>> ...+strata(ID),,...). Unfortunately I could not tell for sure
>>> which one was being described as superio but I think it was the
>>> cluster() alternative. I seem to remember there are discussions
>>> in the archives.
>>
>>
>> David,
>>
>> I think that you raise a good point. The example in the book (I had
>> to wait to get home to read it) is potentially different however,
>> in that the subject's eye's were randomized to treatment or
>> control, which would seem to suggest comparable baseline
>> characteristics for each pair of eyes, as well as an active
>> intervention on one side where a difference in treatment effect
>> between each eye is being analyzed.
>>
>> It is not clear from John's description above if there is one hip
>> that will be treated versus one as a control and whether the extent
>> of disease at baseline is similar in each pair of hips. Presumably
>> the timing of hip replacements will be staggered at some level,
>> even if there is comparable disease, simply due to post-op recovery
>> time and surgical risk. In cases where the disease between each hip
>> is materially different, that would be another factor to consider,
>> however I would defer to orthopaedic physicians/surgeons from a
>> subject matter expertise consideration. It is possible that the
>> bilateral hip replacement data might be more of a parallel to
>> bilateral breast cancer data, if each breast were to be tracked
>> separately.
>>
>> I have cc'd Terry here, hoping that he might jump in and offer some
>> insights into the pros/cons of using coxme versus coxph with either
>> a cluster or strata based approach, or perhaps even a frailty based
>> approach as in 9.4.1 in the book.
>>
>> Regards,
>>
>> Marc
>>
>>
>>>
>>> -- David.
>>>>
>>>> You also might find the following of interest:
>>>>
>>>> http://bjo.bmj.com/content/71/9/645.full.pdf
>>>>
>>>> http://www.ncbi.nlm.nih.gov/pubmed/22226885
>>>>
>>>> http://www.ncbi.nlm.nih.gov/pubmed/22078901
>>>>
>>>>
>>>>
>>>> Regards,
>>>>
>>>> Marc Schwartz
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>>> posting guide http://www.R-project.org/posting-guide.html and
>>>> provide commented, minimal, self-contained, reproducible code.
>>>
>>> David Winsemius Alameda, CA, USA
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do read the
>>> posting guide http://www.R-project.org/posting-guide.html and
>>> provide commented, minimal, self-contained, reproducible code.
>>
>>
>
> Confidentiality Statement: This email message, including any
> attachments, is for th...{{dropped:6}}
>
> ______________________________________________ R-help at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-help PLEASE do
> read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Thu Jul 25 15:25:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 25 Jul 2013 06:25:24 -0700 (PDT)
Subject: [R] Change values in a dateframe-Speed TEST
In-Reply-To: <51F0DACB.2010706@cirad.fr>
References: <51EF76AA.7000803@cirad.fr>	<1374672543.67050.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<51F0C053.10603@cirad.fr>
	<51F0C74C.7070404@cirad.fr>	<E8B9A235-FDE5-42E9-B551-B81D18DEC059@xs4all.nl>
	<51F0DACB.2010706@cirad.fr>
Message-ID: <1374758724.12515.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi Michel,
Sorry, I misunderstood your question.
You could also try:
library(plyr)
df1New<-droplevels(ddply(TEST,.(Matricule),function(x) {x[,c("Nom","Prenom")]<- x[1,c("Nom","Prenom")];x}))
df2New<-droplevels(ddply(TEST,.(Matricule),function(x) {x[,c("Nom","Prenom")]<- x[nrow(x),c("Nom","Prenom")];x}))
?identical(df1,df1New)
#[1] TRUE
?identical(df2,df2New)
#[1] TRUE

#or

library(data.table)
dt1<- data.table(TEST)
dt2<-dt1
dt1[,Nom:=head(Nom,1),by=Matricule]
dt1[,Prenom:=head(Prenom,1),by=Matricule]
?identical(df1,droplevels(as.data.frame(dt1)))
#[1] TRUE

dt2[,Nom:=tail(Nom,1),by=Matricule]
dt2[,Prenom:=tail(Prenom,1),by=Matricule]
?identical(df2,droplevels(as.data.frame(dt2)))
#[1] TRUE


#If you are considering speed, then ?data.table() would be useful
set.seed(28)
dfTest<- as.data.frame(matrix(sample(1:50,1e6*5,replace=TRUE),ncol=5))

system.time({res1<-do.call(rbind,lapply(split(dfTest,dfTest$V1),
??????????????????? FUN=function(x) {x[,c("V2","V3")] <- x[1,c("V2","V3")];x}))})
#? user? system elapsed 
#? 4.452?? 0.036?? 4.499 
row.names(res1)<-1:nrow(res1)

dtNew<- data.table(dfTest)
system.time({dtNew[,V2:=head(V2,1),by=V1]
??? dtNew[,V3:=head(V3,1),by=V1]
??? ?dtNew<-dtNew[order(V1)]? #here, the dataset was not pre-sorted, so just to keep the same order as the above solution

??? })
# user? system elapsed 
#?? 0.132?? 0.000?? 0.133 
identical(res1,as.data.frame(dtNew))
#[1] TRUE


A.K.




----- Original Message -----
From: Arnaud Michel <michel.arnaud at cirad.fr>
To: Berend Hasselman <bhh at xs4all.nl>
Cc: R help <r-help at r-project.org>
Sent: Thursday, July 25, 2013 3:59 AM
Subject: Re: [R] Change values in a dateframe-Speed TEST

Le 25/07/2013 08:50, Berend Hasselman a ?crit :
> On 25-07-2013, at 08:35, Arnaud Michel <michel.arnaud at cirad.fr> wrote:
>
>> But I just noticed that the two solutions are not comparable :
>> the change concern only Nom and Prenom (solution Berend) and not also Sexe or Date.de.naissance orother variables (solution Arun) that can changed. But my question was badly put.
> Indeed:-)
>
> But that can be remedied with (small correction w.r.t. initial solution: drop=TRUE removed; not relevant here)
>
> r1 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
>? ? ? ? ? ? ? ? ? ? ? FUN=function(x) {x[,1:ncol(x)] <- x[1,1:ncol(x)];x})))
>
> and
>
> r2 <- droplevels(do.call(rbind,lapply(split(TEST,TEST$Matricule),
>? ? ? ? ? ? ? ? ? ? ? FUN=function(x) {x[,1:ncol(x)] <- x[nrow(x),1:ncol(x)];x})))
Thank you but I keep
{x[,c("Nom","Pr?nom")] <- x[nrow(x),c("Nom","Pr?nom")];x} because in the 
dataframe there are other variables that I do not want to change. I want 
change only "Nom" and "Pr?nom"

PS : ?w.r.t.
Michel

> Less elegant than alternative with ave
>
> Berend
>
>> Michel
>>
>> Le 25/07/2013 08:06, Arnaud Michel a ?crit :
>>> Hi
>>>
>>> For a dataframe with name PaysContrat1 and with
>>> nrow(PaysContrat1)
>>> [1] 52366
>>>
>>> the test of system.time is :
>>>
>>> system.time(droplevels(do.call(rbind,lapply(split(PaysContrat1,PaysContrat1$Matricule),
>>> FUN=function(x) {x[,c("Nom","Pr?nom")] <- x[nrow(x),c("Nom","Pr?nom"),drop=TRUE];x}))))
>>>? ? user? system elapsed
>>>?  14.03? ? 0.00?  14.04
>>>
>>> system.time(droplevels(PaysContrat1[with(PaysContrat1,ave(seq_along(Matricule),Matricule,FUN=min)) ,]? ))
>>>? ? user? system elapsed
>>>? ?  0.2? ?  0.0? ?  0.2
>>>
>>> Michel
>>>
>>> Le 24/07/2013 15:29, arun a ?crit :
>>>> Hi Michel,
>>>> You could try:
>>>>
>>>>
>>>> df1New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=min)),])
>>>> row.names(df1New)<-1:nrow(df1New)
>>>> df2New<-droplevels(TEST[with(TEST,ave(seq_along(Matricule),Matricule,FUN=max)),])
>>>> row.names(df2New)<-1:nrow(df2New)
>>>>?  identical(df1New,df1)
>>>> #[1] TRUE
>>>>?  identical(df2New,df2)
>>>> #[1] TRUE
>>>> A.K.
>>>>
>>>>
>>>>
>>>> ----- Original Message -----
>>>> From: Arnaud Michel <michel.arnaud at cirad.fr>
>>>> To: R help <r-help at r-project.org>
>>>> Cc:
>>>> Sent: Wednesday, July 24, 2013 2:39 AM
>>>> Subject: [R] Change values in a dateframe
>>>>
>>>> Hello
>>>>
>>>> I have the following problem :
>>>> The dataframe TEST has multiple lines for a same person because :
>>>> there are differents values of Nom or differents values of Prenom
>>>> but the values of Matricule or Sexe or Date.de.naissance are the same.
>>>>
>>>> TEST <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 8L,
>>>> 5L, 6L, 9L, 3L, 3L, 7L), .Label = c("CHICHE", "GEOF", "GUTIER",
>>>> "JACQUE", "LANGUE", "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"
>>>> ), class = "factor"), Prenom = structure(c(8L, 3L, 4L, 5L, 1L,
>>>> 2L, 2L, 9L, 6L, 7L, 7L), .Label = c("Edgar", "Elodie", "Jeanine",
>>>> "Jeannine", "Michel", "Michele", "Mich?le", "Michelle", "Victor"
>>>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>>>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>>>> "factor"),
>>>>? ? ?  Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>>>? ? ?  1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>>>? ? ?  "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>>>> "factor")), .Names = c("Matricule",
>>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>>> row.names = c(NA,
>>>> -11L))
>>>>
>>>>
>>>> I would want to make homogeneous the information and would like built 2
>>>> dataframes :
>>>> df1 wich has the value of Nom and Prenom of the first lines of TEST when
>>>> there are different values. The other values (Matricule or Sexe or
>>>> Date.de.naissance) are unchanged
>>>>
>>>> df1 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 4L, 6L,
>>>> 5L, 5L, 7L, 3L, 3L, 3L), .Label = c("CHICHE", "GEOF", "GUTIER",
>>>> "JACQUE", "LANGUE", "TRU", "VINCENT"), class = "factor"), Prenom =
>>>> structure(c(6L,
>>>> 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L, 5L, 5L), .Label = c("Edgar",
>>>> "Elodie", "Jeanine", "Michel", "Michele", "Michelle", "Victor"
>>>> ), class = "factor"), Sexe = structure(c(1L, 1L, 1L, 2L, 2L,
>>>> 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin", "Masculin"), class =
>>>> "factor"),
>>>>? ? ?  Date.de.naissance = structure(c(4L, 2L, 2L, 7L, 6L, 5L, 5L,
>>>>? ? ?  1L, 3L, 3L, 3L), .Label = c("03/09/1940", "04/03/1946", "07/12/1947",
>>>>? ? ?  "18/11/1945", "27/09/1947", "29/12/1936", "30/03/1935"), class =
>>>> "factor")), .Names = c("Matricule",
>>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>>> row.names = c(NA,
>>>> -11L))
>>>>
>>>> df2 wich has the value of Nom and Prenom of the last lines of TEST when
>>>> there are different values. The other values (Matricule or Sexe or
>>>> Date.de.naissance) are unchanged.
>>>>
>>>> df2 <- structure(list(Matricule = c(66L, 67L, 67L, 68L, 89L, 90L, 90L,
>>>> 91L, 108L, 108L, 108L), Nom = structure(c(1L, 2L, 2L, 3L, 6L,
>>>> 4L, 4L, 7L, 5L, 5L, 5L), .Label = c("CHICHE", "GEOF", "JACQUE",
>>>> "LANGUE-LOPEZ", "RIVIER", "TRU", "VINCENT"), class = "factor"),
>>>>? ? ?  Prenom = structure(c(6L, 3L, 3L, 4L, 1L, 2L, 2L, 7L, 5L,
>>>>? ? ?  5L, 5L), .Label = c("Edgar", "Elodie", "Jeannine", "Michel",
>>>>? ? ?  "Mich?le", "Michelle", "Victor"), class = "factor"), Sexe =
>>>> structure(c(1L,
>>>>? ? ?  1L, 1L, 2L, 2L, 1L, 1L, 2L, 1L, 1L, 1L), .Label = c("F?minin",
>>>>? ? ?  "Masculin"), class = "factor"), Date.de.naissance = structure(c(4L,
>>>>? ? ?  2L, 2L, 7L, 6L, 5L, 5L, 1L, 3L, 3L, 3L), .Label = c("03/09/1940",
>>>>? ? ?  "04/03/1946", "07/12/1947", "18/11/1945", "27/09/1947", "29/12/1936",
>>>>? ? ?  "30/03/1935"), class = "factor")), .Names = c("Matricule",
>>>> "Nom", "Prenom", "Sexe", "Date.de.naissance"), class = "data.frame",
>>>> row.names = c(NA,
>>>> -11L))
>>>>
>>>> Thank for your helps
>>>> Michel
>>>>
>> -- 
>> Michel ARNAUD
>> Charg? de mission aupr?s du DRH
>> DGDRD-Drh - TA 174/04
>> Av Agropolis 34398 Montpellier cedex 5
>> tel : 04.67.61.75.38
>> fax : 04.67.61.57.87
>> port: 06.47.43.55.31
>>
>

-- 
Michel ARNAUD
Charg? de mission aupr?s du DRH
DGDRD-Drh - TA 174/04
Av Agropolis 34398 Montpellier cedex 5
tel : 04.67.61.75.38
fax : 04.67.61.57.87
port: 06.47.43.55.31

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Thu Jul 25 16:20:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 25 Jul 2013 07:20:41 -0700 (PDT)
Subject: [R] Function, that assigns two vectors to each other
In-Reply-To: <51F10BEC.90406@psychologie.tu-dresden.de>
References: <64007B3443B.00000E62jrkrideau@inbox.com>
	<51F10BEC.90406@psychologie.tu-dresden.de>
Message-ID: <1374762041.93346.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
You could try:
my.data<- structure...
pe<-round(pe,0)
peMax<-as.data.frame(sapply(paste0("a",1:4),function(x) {x1<-my.data[,x]; unsplit(lapply(split(x1,x1),function(y) {x2<-row.names(pe)[pe[,x]%in% y]; x3<-x2[which.max(as.numeric(gsub("\\D+","",x2)))];rep(x3,length(y))}),x1)}),stringsAsFactors=FALSE)
?names(peMax)<- paste0("pe",1:4)
?my.dataNew<- cbind(my.data,peMax)
?
? my.dataNew
#?? pa? a1? a2? a3? a4? pe1? pe2? pe3? pe4
#1?? 1? 84 113? 96? 76? 12%? 89%? 24%?? 0%
#2?? 2 108 101 108 106? 90%? 45%? 80%? 72%
#3?? 3 113? 99 110? 94 100%? 36%? 89%? 25%
#4?? 4? 99 108? 99 124? 78%? 61%? 49% 100%
#5?? 5? 98 122 118? 91? 72% 100% 100%? 12%
#6?? 6? 88? 92 100 103? 27%? 12%? 58%? 46%
#7?? 7? 90? 90? 90 107? 45%?? 2%? 12%? 78%
#8?? 8? 89 110? 89 106? 38%? 79%?? 5%? 72%
#9?? 9? 95 109 102 113? 57%? 72%? 67%? 89%
#10 10? 77? 95? 99? 96?? 0%? 23%? 49%? 34%

If you don't want the "%" attached to the number
?my.dataNew[,6:9]<-lapply(my.dataNew[6:9],function(x) as.numeric(gsub("\\D+","",x)))
?my.dataNew
#?? pa? a1? a2? a3? a4 pe1 pe2 pe3 pe4
#1?? 1? 84 113? 96? 76? 12? 89? 24?? 0
#2?? 2 108 101 108 106? 90? 45? 80? 72
#3?? 3 113? 99 110? 94 100? 36? 89? 25
#4?? 4? 99 108? 99 124? 78? 61? 49 100
#5?? 5? 98 122 118? 91? 72 100 100? 12
#6?? 6? 88? 92 100 103? 27? 12? 58? 46
#7?? 7? 90? 90? 90 107? 45?? 2? 12? 78
#8?? 8? 89 110? 89 106? 38? 79?? 5? 72
#9?? 9? 95 109 102 113? 57? 72? 67? 89
#10 10? 77? 95? 99? 96?? 0? 23? 49? 34
A.K. 



----- Original Message -----
From: Anne-Marie B. Gallrein <gallrein at psychologie.tu-dresden.de>
To: John Kane <jrkrideau at inbox.com>
Cc: r-help at r-project.org
Sent: Thursday, July 25, 2013 7:28 AM
Subject: Re: [R] Function, that assigns two vectors to each other

Hello guys, I created an example data set:

structure(list(pa = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10), a1 = c(84,
108, 113, 99, 98, 88, 90, 89, 95, 77), a2 = c(113, 101, 99, 108,
122, 92, 90, 110, 109, 95), a3 = c(96, 108, 110, 99, 118, 100,
90, 89, 102, 99), a4 = c(76, 106, 94, 124, 91, 103, 107, 106,
113, 96)), .Names = c("pa", "a1", "a2", "a3", "a4"), row.names = c(NA,
-10L), class = "data.frame")

So the data frame contains the numbers of my participants (1 to 10) and the score, they hit on 4 tasks (a1 to a4).

I wrote this function, to use on the data:


pe<-apply(X=my.data[,c("a1","a2","a3","a4")],
? ? ? ? ? 
? ? ? ? ?  MARGIN=2,
? ? ? ? ? 
? ? ? ? ?  FUN=quantile,
? ? ? ? ? 
? ? ? ? ?  probs=seq(0,1,by=.01),
? ? ? ? ? 
? ? ? ? ?  na.rm=TRUE)

round(pe,0)


It computes the percentiles of each task. So when using this function I know, that e.g.
a person who got 77 points on task 1 (a1) has a percentile of 0%.
If a person scores 88 points then he/she got the percentiles 21% to 27%, so 27% got the same amount of points or less.
In comparison in task 4 (a4) a person reaching 77 points has a percentile of 1%.

Now I want to add 4 columns to my.data (pe1 to pe4).

The final data frame my.data shall have 10 rows and 9 columns

These columns (pe1 to pe4) shall show the maximum percentile someone reached according to his points for each task.
So for the person who reached 77 points in a1 the respective pe1 would be 0.
For all the people who reached 88 points in a1 the respective pe1 would be 27.
For all the people who reached 77 points in a4 the respective pe1 would be 1.
The final data frame my.data shall have 10 rows and 9 columns.

So for the first participant (pa=1), the pe's would be a1=84? --> pe=12; a2=113? --> pe=89, a3=96 --> pe=24, a4=76 --> pe=0

I hope, that is clearer than before :)

Thanks a lot,

Anne




Am 24.07.2013 14:47, schrieb John Kane:
> Welcome? to R-help
> it is a bit hard to see exactly what you want without data. Rest of the explanation looks good though it appears you may have sent this in HTML and the list asks for text.? It strips out the html and we lose any html format.
>
> Can I suggest reading these https://github.com/hadley/devtools/wiki/Reproducibility
>? http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> and then getting back to use with some data.? The best way to provide data , as is described in the above links is to use dput()? (type ?dput for help ) and then just copy and paste the results into the mail.
>
>
>
> John Kane
> Kingston ON Canada
>
>
>> -----Original Message-----
>> From: gallrein at psychologie.tu-dresden.de
>> Sent: Wed, 24 Jul 2013 12:25:35 +0200
>> To: r-help at r-project.org
>> Subject: [R] Function, that assigns two vectors to each other
>>
>> Hey guys,
>>
>> In my data setv ("KD") I have 4 columns
>> ("Punkte.AG1","Punkte.AG2","Punkte.AG3","Punkte.WI") I'm interested in.
>>
>> These columns contain the participants' scores of a specific task.
>>
>> I computed the percentiles of the columns using this code:
>>
>> pe<-apply(X=KD[,c("Punkte.AG1","Punkte.AG2","Punkte.AG3","Punkte.WI")],
>>
>> MARGIN=2,
>>
>> FUN=quantile,
>>
>> probs=seq(0,1,by=.01),
>>
>> na.rm=TRUE)
>>
>> round(pe,0)
>>
>>
>> This is the output (to the 20^th percentile):
>>
>> pe
>>
>> Punkte.AG1 Punkte.AG2 Punkte.AG3 Punkte.WI
>>
>> 0%6319
>>
>> 1%74311
>>
>> 2%86312
>>
>> 3%87412
>>
>> 4%97512
>>
>> 5%98512
>>
>> 6%108512
>>
>> 7%108512
>>
>> 8%108614
>>
>> 9%109614
>>
>> 10%109615
>>
>> 11%1010715
>>
>> 12%1010715
>>
>> 13%1110715
>>
>> 14%1110816
>>
>> 15%1110816
>>
>> 16%1110816
>>
>> 17%1110816
>>
>> 18%1110816
>>
>> 19%1210816
>>
>> 20%1210816
>>
>> So now I know, what percentile a person has, when she/ he scored a
>> certain amount of points (e.g. 6 points in "Punkte.AG1" = 0%).
>>
>> Here is my problem:
>>
>> I now want to write a function that assigns the percentile to the score
>> (for each task) and saves it in a new variable.
>>
>> So every person that scored 10 in "Punkte.AG1" gets a "12" in the new
>> variable "Percentile.AG1".
>>
>> Every person that scored 6 in "Punkte.AG1" gets a "6" in the new
>> variable "Percentile.AG1".
>>
>> The same thing should be done for the other tasks.
>>
>>
>> I new to R, so I don't have any clue, how to solve that. It would be
>> awesome, if you would know how to handle that.
>>
>> Thanks a lot!
>>
>> Anne
>>
>> --
>> M. Sc. Anne-Marie B. Gallrein
>> Technische Universitdt Dresden
>> Institut f|r Klinische, Diagnostische und Differentielle Psychologie
>> Diagnostik und Intervention
>> 01062 Dresden
>> Tel. +49 351 463-34004
>> gallrein at psychologie.tu-dresden.de
>>
>>
>> ??? [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> ____________________________________________________________
> GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
> Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails
>
>


-- 
M. Sc. Anne-Marie B. Gallrein
Technische Universit?t Dresden
Institut f?r Klinische, Diagnostische und Differentielle Psychologie
Diagnostik und Intervention
01062 Dresden
Tel. +49 351 463-34004
gallrein at psychologie.tu-dresden.de


??? [[alternative HTML version deleted]]


______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From sollago at umd.edu  Thu Jul 25 18:00:55 2013
From: sollago at umd.edu (Maria Sol Lago)
Date: Thu, 25 Jul 2013 16:00:55 +0000
Subject: [R] How do I get a a p-value for the output of an lme model with
	lme4?
Message-ID: <97662D4A-23FF-4FFE-AFFF-7BA18C1DD0AB@umd.edu>

Hi there,

I just started using lme4 and I have a question about obtaining p-values. I'm trying to get p-values for the output of a linear mixed-effects model. In my experiment  I have a 2 by 2 within subjects design, fully crossing two factors, "Gram" and "Number". This is the command I used to run the model:

    >m <- lmer(RT ~ Gram*Number + (1|Subject) + (0+Gram+Number|Subject) + (1|Item_number),data= data)
    
If I understand this code, I am getting coefficients for the two fixed effects (Gram and Number) and their interaction, and I am fitting a model that has by-subject intercepts and slopes for the two fixed effects, and a by-item intercept for them. Following Barr et al. (2013), I thought that this code gets rid of the correlation parameters. I don't want estimate the correlations because I want to get the p-values using pvals.fnc (), and I read that this function doesn't work if there are correlations in the model.

The command seems to work:

    >m
    Linear mixed model fit by REML 
    Formula: RT ~ Gram * Number + (1 | Subject) + (0 + Gram + Number | Subject) + (1 |Item_number) 
       Data: mverb[mverb$Region == "06v1", ] 
       AIC   BIC logLik deviance REMLdev
     20134 20204 -10054    20138   20108
    Random effects:
     Groups      Name        Variance  Std.Dev. Corr          
    Item_number (Intercept)   273.508  16.5381               
     Subject     Gramgram        0.000   0.0000               
                 Gramungram   3717.213  60.9689    NaN        
                 Number1        59.361   7.7046    NaN -1.000 
     Subject     (Intercept) 14075.240 118.6391               
     Residual                35758.311 189.0987               
    Number of obs: 1502, groups: Item_number, 48; Subject, 32

    Fixed effects:
                 Estimate Std. Error t value
    (Intercept)    402.520     22.321  18.033
    Gram1          -57.788     14.545  -3.973
    Number1         -4.191      9.858  -0.425
    Gram1:Number1   15.693     19.527   0.804

    Correlation of Fixed Effects:
                (Intr) Gram1  Numbr1
    Gram1       -0.181              
    Number1     -0.034  0.104       
    Gram1:Nmbr1  0.000 -0.002 -0.011

However, when I try to calculate the p-values I still get an error message:
    
    >pvals.fnc(m, withMCMC=T)$fixed
    Error in pvals.fnc(m, withMCMC = T) : 
    MCMC sampling is not implemented in recent versions of lme4
      for models with random correlation parameters

Am I making a mistake when I specify my model? Shouldn't pvals.fnc() work if I removed the correlations?

Thanks for your help!

--Sol

From vanessa.vaart at gmail.com  Thu Jul 25 21:05:37 2013
From: vanessa.vaart at gmail.com (vanessa van der vaart)
Date: Thu, 25 Jul 2013 20:05:37 +0100
Subject: [R] Duplicated function with conditional statement
Message-ID: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/3787f130/attachment.pl>

From smartpink111 at yahoo.com  Thu Jul 25 23:52:18 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 25 Jul 2013 14:52:18 -0700 (PDT)
Subject: [R] duplicated() with conditional statement
In-Reply-To: <CAEQiC4iOB9CP5MsbOS185KpyOzjL3etysX2=30=qmQxNEJONFg@mail.gmail.com>
References: <1476518.72035.1374780293585.JavaMail.nabble@joe.nabble.com>
	<CAEQiC4iOB9CP5MsbOS185KpyOzjL3etysX2=30=qmQxNEJONFg@mail.gmail.com>
Message-ID: <1374789138.80385.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
You may try this (didn't get time to test this extensively)
indx<-which(tt$response!="buy")
tt$newcolumn<-0
?tt[unlist(lapply(seq_along(indx),function(i) {x1<-if(indx[i]==nrow(tt)) indx[i] else seq(indx[i]+1,indx[i+1]-1);x2<-rbind(tt[indx[1:i],],tt[x1,]); if(any(x2$response=="sample")) row.names(x2[duplicated(x2$product),])})),"newcolumn"]<-1
?tt
#?? subj response product newcolumn
#1???? 1?? sample?????? 1???????? 0
#2???? 1?? sample?????? 2???????? 0
#3???? 1????? buy?????? 3???????? 0
#4???? 2?? sample?????? 2???????? 0
#5???? 2????? buy?????? 2???????? 0
#6???? 3?? sample?????? 3???????? 1
#7???? 3?? sample?????? 2???????? 1
#8???? 3????? buy?????? 1???????? 0
#9???? 4?? sample?????? 1???????? 1
#10??? 4????? buy?????? 4???????? 0
A.K.







________________________________
From: vanessa van der vaart <vanessa.vaart at gmail.com>
To: smartpink111 at yahoo.com 
Sent: Thursday, July 25, 2013 3:49 PM
Subject: Re: duplicated() with conditional statement



thank you for the reply.
It based on entire data set.?

subj response product newcolumn
1 ? ? 1 ? sample ? ? ? 1 ? ? ? ? ?0 ? ? ? ??
2 ? ? 1 ? sample ? ? ? 2 ? ? ? ? ?0 ? ? ? ??
3 ? ? 1 ? ? ?buy ? ? ? ? ?3 ? ? ? ? ? 0 ? ? ??
4 ? ? 2 ? sample ? ? ? 2 ? ? ? ? ?0 ? ? ? ?.?
5 ? ? 2 ? ? ? ? buy ? ? ? 2 ? ? ? ? ? 0
6 ? ? 3 ? sample ? ? ? 3 ? ? ? ? ?1
7 ? ? 3 ? sample ? ? ? 2 ? ? ? ? ? 1
8 ? ? 3 ? ? ? ? buy ? ? ? 1 ? ? ? ? ? 0
9 ? ? 4 ?sample ? ? ? 1 ? ? ? ? ? ?1
10 ? 4 ? ? ? buy ? ? ? 4 ? ? ? ? ? ? 0

I am sorry i didnt question it very clearly, let me change the conditional statement, I hope you can understand. i will explain by example

as you can see, almost every number is duplicated, but only in row 6th,7th,and 9th the value on column is 1.

on row4th, the value is duplicated( 2 already?occurred?on 2nd row),but since the value is considered as duplicated only if the value is duplicated where the response is 'buy' than the value on column, on row4th still zero.?

On row 6th, where the value product column is 3. 3 is already occurred in 3rd row where the value on response is 'buy', so the value on column should be 1

I hope it can understand the conditional statement.?





On Thu, Jul 25, 2013 at 8:25 PM, <smartpink111 at yahoo.com> wrote:

Hi,
>May be I understand it incorrectly.
>Your new column value doesn't correspond to your conditional statement. ?Also, is this duplication based on entire dataset or within "subj".
><quote author='misseb'>
>Hi everybody,,
>I have a question about R function duplicated(). I have spent days try to
>figure this out,but I cant find any solution yet. I hope somebody can help
>me..
>this is my data:
>
>subj=c(1,1,1,2,2,3,3,3,4,4)
>response=c('sample','sample','buy','sample','buy','sample','sample','buy','sample','buy')
>product=c(1,2,3,2,2,3,2,1,1,4)
>tt=data.frame(subj, response, product)
>
>the data look like this:
>
>?subj response product
>1 ? ? 1 ? sample ? ? ? 1
>2 ? ? 1 ? sample ? ? ? 2
>3 ? ? 1 ? ? ?buy ? ? ? ? ?3
>4 ? ? 2 ? sample ? ? ? 2
>5 ? ? 2 ? ? ? ? buy ? ? ? 2
>6 ? ? 3 ? sample ? ? ? 3
>7 ? ? 3 ? sample ? ? ? 2
>8 ? ? 3 ? ? ? ? buy ? ? ? 1
>9 ? ? 4 ?sample ? ? ? 1
>10 ? 4 ? ? ? buy ? ? ? ?4
>
>
>
>I want to create new ?column based on the value on response and product
>column. if the value on product is duplicated, then ?the value on new column
>is 1, otherwise is 0.
>but I want to add conditional statement that the value on product column
>will only be considered as duplicated if the value on response column is
>'buy'.
>for illustration, the table should look like this:
>
>subj response product newcolumn
>1 ? ? 1 ? sample ? ? ? 1 ? ? ? ? ?0
>2 ? ? 1 ? sample ? ? ? 2 ? ? ? ? ?0
>3 ? ? 1 ? ? ?buy ? ? ? ? ?3 ? ? ? ? ? 0
>4 ? ? 2 ? sample ? ? ? 2 ? ? ? ? ?0
>5 ? ? 2 ? ? ? ? buy ? ? ? 2 ? ? ? ? ? 0
>6 ? ? 3 ? sample ? ? ? 3 ? ? ? ? ?1
>7 ? ? 3 ? sample ? ? ? 2 ? ? ? ? ? 1
>8 ? ? 3 ? ? ? ? buy ? ? ? 1 ? ? ? ? ? 0
>9 ? ? 4 ?sample ? ? ? 1 ? ? ? ? ? ?1
>10 ? 4 ? ? ? buy ? ? ? 4 ? ? ? ? ? ? 0
>
>
>can somebody help me?
>any help will be appreciated.
>I am new in this mailing list, so forgive me in advance, If I did not ?ask
>the question appropriately.
>
>
>
>
>
></quote>
>Quoted from:
>http://r.789695.n4.nabble.com/duplicated-with-conditional-statement-tp4672342.html
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>
>


From smartpink111 at yahoo.com  Fri Jul 26 01:16:58 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 25 Jul 2013 16:16:58 -0700 (PDT)
Subject: [R] Pairwise comparison between columns, logic
Message-ID: <1374794218.76874.YahooMailNeo@web142602.mail.bf1.yahoo.com>

HI,
Not sure about what your expected output would be.? Also 'CEBPA' was not present in the Data.txt. 

gset<- read.table("Names.txt",header=TRUE,stringsAsFactors=FALSE)
?temp1<- read.table("Data.txt",header=TRUE,stringsAsFactors=FALSE)
lst1<-split(temp1,temp1$Names)
mat1<-combn(gset[-1,1],2) #removed CEBPA
library(plyr)

lst2<-lapply(split(mat1,col(mat1)),function(x) {x1<-join_all(lst1[x],by="patient_id",type="inner");x1["patient_id"] })
names(lst2)<-apply(mat1,2,paste,collapse="_")
do.call(rbind,lst2)
#?????????????????? patient_id
#DNMT3A_FLT3.1 LAML-AB-2811-TB #common ids between DNMT3A and FLT3
#DNMT3A_FLT3.2 LAML-AB-2816-TB
#DNMT3A_FLT3.3 LAML-AB-2818-TB
#DNMT3A_IDH1.1 LAML-AB-2802-TB#common ids between DNMT3A and IDH1.? If you wanted it as separate dataframes, use `lst2`.
#DNMT3A_IDH1.2 LAML-AB-2822-TB
#DNMT3A_NPM1.1 LAML-AB-2802-TB
#DNMT3A_NPM1.2 LAML-AB-2809-TB
#DNMT3A_NPM1.3 LAML-AB-2811-TB
#DNMT3A_NPM1.4 LAML-AB-2816-TB
#DNMT3A_NRAS?? LAML-AB-2816-TB
#FLT3_NPM1.1?? LAML-AB-2811-TB
#FLT3_NPM1.2?? LAML-AB-2812-TB
#FLT3_NPM1.3?? LAML-AB-2816-TB
#FLT3_NRAS???? LAML-AB-2816-TB
#IDH1_NPM1???? LAML-AB-2802-TB
#NPM1_NRAS???? LAML-AB-2816-TB
A.K.



Hello R experts, 

I am trying to solve the following logic. 
I have two input files. The first file (Names.txt) that has two columns: 
Column1	Column2 
CEBPA	CEBPA 
DNMT3A	DNMT3A 
FLT3	FLT3 
IDH1	IDH1 
NPM1	NPM1 
NRAS	NRAS 
and the second input file Data.txt has two columns Names, patient_id. 
Name	patient_id 
DNMT3A	LAML-AB-2802-TB 
DNMT3A	LAML-AB-2809-TB 
DNMT3A	LAML-AB-2811-TB 
DNMT3A	LAML-AB-2816-TB 
DNMT3A	LAML-AB-2818-TB 
DNMT3A	LAML-AB-2822-TB 
DNMT3A	LAML-AB-2824-TB 
FLT3	LAML-AB-2811-TB 
FLT3	LAML-AB-2812-TB 
FLT3	LAML-AB-2814-TB 
FLT3	LAML-AB-2816-TB 
FLT3	LAML-AB-2818-TB 
FLT3	LAML-AB-2825-TB 
FLT3	LAML-AB-2830-TB 
FLT3	LAML-AB-2834-TB 
IDH1	LAML-AB-2802-TB 
IDH1	LAML-AB-2821-TB 

?What I am attempting to do is for each name in first column of 
names.txt, I do a pairwise comparison with the other names in the second
 column based on which patient ids are common. 
To explain in detail: 
As an example: I extract patient_ids for CEBPA and DNMT3A and see 
which are common, then I do the same for CEBPA and FLT3 and so on for 
CEBPA and the next name in column 2. 
So far the script I have written only does the comparison with the 
first name in the list. So essentially with itself. I am not sure why 
this logic is not working for all the names in column 2 for a single 
name in column 1. 

Below is my script: 

gset<-read.table("Names.txt",header=F,na.strings = ".", as.is=T) # reading in the genes 
temp<-read.table("Data.txt",header=T,sep="\t") 


################################################# 
? 
? all<-length(unique(temp$fpatient_id)) 
? final<-c() 
? 
? both.ab <- list() 
? both <- list() 
? temp.b <- matrix() 
? 
? for(i in 1:nrow(gset)) ?# Loop for genes in the first column 
? 
? { 
? ? 
? ? temp2<-temp[which(temp$Column1 %in% gset[i,]),] 
? ? num.mut<-length(unique(temp2$patient_id)) 
? ? 
? ? temp.a <-temp[which(temp$Column1 == gset[i,1]),] 
? 
? ? for(j in 1:(nrow(gset)) ?# Loop for genes in the second column 
? ? ? ? ? ? 
? ? { 
? ? ? temp.b <-temp[which(temp$Column2 == gset[j,2]),] 
? ? ? # See which patient_ids of temp.a are in temp.b 
? ? ? both.ab[[i]]<-temp.a[which(temp.a$patient_id %in% temp.b$patient_id),] 
? ? } 

? ? both[[i]]<-both.ab[[i]] 
? ? 
? ? num.both<-length(unique(both[[i]]$patient_id)) 
? ? 
? ? line<-c(paste(gset[i, which(!(is.na(gset[i,]))) ],collapse="/"), num.mut, all, num.mut/all, num.both) 
? ? final<-rbind(final,line) 
? } 
Names.txtData.txtScript.txt


From smartpink111 at yahoo.com  Fri Jul 26 03:26:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 25 Jul 2013 18:26:32 -0700 (PDT)
Subject: [R] duplicated() with conditional statement
In-Reply-To: <CAEQiC4gRbwh+Vtcs7X0LZQeAA16kqsBG+xobuuEyepzeByADig@mail.gmail.com>
References: <1476518.72035.1374780293585.JavaMail.nabble@joe.nabble.com>
	<CAEQiC4iOB9CP5MsbOS185KpyOzjL3etysX2=30=qmQxNEJONFg@mail.gmail.com>
	<1374789138.80385.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAEQiC4gRbwh+Vtcs7X0LZQeAA16kqsBG+xobuuEyepzeByADig@mail.gmail.com>
Message-ID: <1374801992.84427.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
Sorry,`indx` should be:
indx<-which(tt$response=="buy") #I changed indx but forgot about it
?tt$newcolumn<-0
? tt[unlist(lapply(seq_along(indx),function(i) {x1<-if(indx[i]==nrow(tt)) indx[i] else seq(indx[i]+1,indx[i+1]-1);x2<-rbind(tt[indx[1:i],],tt[x1,]); if(any(x2$response=="sample")) row.names(x2[duplicated(x2$product),])})),"newcolumn"]<-1
?tt
?? subj response product newcolumn
1???? 1?? sample?????? 1???????? 0
2???? 1?? sample?????? 2???????? 0
3???? 1????? buy?????? 3???????? 0
4???? 2?? sample?????? 2???????? 0
5???? 2????? buy?????? 2???????? 0
6???? 3?? sample?????? 3???????? 1
7???? 3?? sample?????? 2???????? 1
8???? 3????? buy?????? 1???????? 0
9???? 4?? sample?????? 1???????? 1
10??? 4????? buy?????? 4???????? 0
A.K.







________________________________
From: vanessa van der vaart <vanessa.vaart at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Thursday, July 25, 2013 8:55 PM
Subject: Re: duplicated() with conditional statement



hii thanks for the code, I tried the code but i got the error message,
Error in from:to : NA/NaN argument


I dont know what doest it mean, and I dont know how to fix it..
could you help please..

thank you very much in advance





On Thu, Jul 25, 2013 at 10:52 PM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>You may try this (didn't get time to test this extensively)
>indx<-which(tt$response!="buy")
>tt$newcolumn<-0
>?tt[unlist(lapply(seq_along(indx),function(i) {x1<-if(indx[i]==nrow(tt)) indx[i] else seq(indx[i]+1,indx[i+1]-1);x2<-rbind(tt[indx[1:i],],tt[x1,]); if(any(x2$response=="sample")) row.names(x2[duplicated(x2$product),])})),"newcolumn"]<-1
>?tt
>#?? subj response product newcolumn
>#1???? 1?? sample?????? 1???????? 0
>#2???? 1?? sample?????? 2???????? 0
>#3???? 1????? buy?????? 3???????? 0
>#4???? 2?? sample?????? 2???????? 0
>#5???? 2????? buy?????? 2???????? 0
>#6???? 3?? sample?????? 3???????? 1
>#7???? 3?? sample?????? 2???????? 1
>#8???? 3????? buy?????? 1???????? 0
>#9???? 4?? sample?????? 1???????? 1
>#10??? 4????? buy?????? 4???????? 0
>A.K.
>
>
>
>
>
>
>
>
>________________________________
>From: vanessa van der vaart <vanessa.vaart at gmail.com>
>To: smartpink111 at yahoo.com
>Sent: Thursday, July 25, 2013 3:49 PM
>Subject: Re: duplicated() with conditional statement
>
>
>
>
>thank you for the reply.
>It based on entire data set.?
>
>subj response product newcolumn
>1 ? ? 1 ? sample ? ? ? 1 ? ? ? ? ?0 ? ? ? ??
>2 ? ? 1 ? sample ? ? ? 2 ? ? ? ? ?0 ? ? ? ??
>3 ? ? 1 ? ? ?buy ? ? ? ? ?3 ? ? ? ? ? 0 ? ? ??
>4 ? ? 2 ? sample ? ? ? 2 ? ? ? ? ?0 ? ? ? ?.?
>5 ? ? 2 ? ? ? ? buy ? ? ? 2 ? ? ? ? ? 0
>6 ? ? 3 ? sample ? ? ? 3 ? ? ? ? ?1
>7 ? ? 3 ? sample ? ? ? 2 ? ? ? ? ? 1
>8 ? ? 3 ? ? ? ? buy ? ? ? 1 ? ? ? ? ? 0
>9 ? ? 4 ?sample ? ? ? 1 ? ? ? ? ? ?1
>10 ? 4 ? ? ? buy ? ? ? 4 ? ? ? ? ? ? 0
>
>I am sorry i didnt question it very clearly, let me change the conditional statement, I hope you can understand. i will explain by example
>
>as you can see, almost every number is duplicated, but only in row 6th,7th,and 9th the value on column is 1.
>
>on row4th, the value is duplicated( 2 already?occurred?on 2nd row),but since the value is considered as duplicated only if the value is duplicated where the response is 'buy' than the value on column, on row4th still zero.?
>
>On row 6th, where the value product column is 3. 3 is already occurred in 3rd row where the value on response is 'buy', so the value on column should be 1
>
>I hope it can understand the conditional statement.?
>
>
>
>
>
>On Thu, Jul 25, 2013 at 8:25 PM, <smartpink111 at yahoo.com> wrote:
>
>Hi,
>>May be I understand it incorrectly.
>>Your new column value doesn't correspond to your conditional statement. ?Also, is this duplication based on entire dataset or within "subj".
>><quote author='misseb'>
>>Hi everybody,,
>>I have a question about R function duplicated(). I have spent days try to
>>figure this out,but I cant find any solution yet. I hope somebody can help
>>me..
>>this is my data:
>>
>>subj=c(1,1,1,2,2,3,3,3,4,4)
>>response=c('sample','sample','buy','sample','buy','sample','sample','buy','sample','buy')
>>product=c(1,2,3,2,2,3,2,1,1,4)
>>tt=data.frame(subj, response, product)
>>
>>the data look like this:
>>
>>?subj response product
>>1 ? ? 1 ? sample ? ? ? 1
>>2 ? ? 1 ? sample ? ? ? 2
>>3 ? ? 1 ? ? ?buy ? ? ? ? ?3
>>4 ? ? 2 ? sample ? ? ? 2
>>5 ? ? 2 ? ? ? ? buy ? ? ? 2
>>6 ? ? 3 ? sample ? ? ? 3
>>7 ? ? 3 ? sample ? ? ? 2
>>8 ? ? 3 ? ? ? ? buy ? ? ? 1
>>9 ? ? 4 ?sample ? ? ? 1
>>10 ? 4 ? ? ? buy ? ? ? ?4
>>
>>
>>
>>I want to create new ?column based on the value on response and product
>>column. if the value on product is duplicated, then ?the value on new column
>>is 1, otherwise is 0.
>>but I want to add conditional statement that the value on product column
>>will only be considered as duplicated if the value on response column is
>>'buy'.
>>for illustration, the table should look like this:
>>
>>subj response product newcolumn
>>1 ? ? 1 ? sample ? ? ? 1 ? ? ? ? ?0
>>2 ? ? 1 ? sample ? ? ? 2 ? ? ? ? ?0
>>3 ? ? 1 ? ? ?buy ? ? ? ? ?3 ? ? ? ? ? 0
>>4 ? ? 2 ? sample ? ? ? 2 ? ? ? ? ?0
>>5 ? ? 2 ? ? ? ? buy ? ? ? 2 ? ? ? ? ? 0
>>6 ? ? 3 ? sample ? ? ? 3 ? ? ? ? ?1
>>7 ? ? 3 ? sample ? ? ? 2 ? ? ? ? ? 1
>>8 ? ? 3 ? ? ? ? buy ? ? ? 1 ? ? ? ? ? 0
>>9 ? ? 4 ?sample ? ? ? 1 ? ? ? ? ? ?1
>>10 ? 4 ? ? ? buy ? ? ? 4 ? ? ? ? ? ? 0
>>
>>
>>can somebody help me?
>>any help will be appreciated.
>>I am new in this mailing list, so forgive me in advance, If I did not ?ask
>>the question appropriately.
>>
>>
>>
>>
>>
>></quote>
>>Quoted from:
>>http://r.789695.n4.nabble.com/duplicated-with-conditional-statement-tp4672342.html
>>
>>
>>_____________________________________
>>Sent from http://r.789695.n4.nabble.com
>>
>>
>


From smartpink111 at yahoo.com  Fri Jul 26 06:53:09 2013
From: smartpink111 at yahoo.com (arun)
Date: Thu, 25 Jul 2013 21:53:09 -0700 (PDT)
Subject: [R] How to split two levels several times?
In-Reply-To: <51F1742C.7070405@sapo.pt>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>	<51ED540C.1000303@sapo.pt>,
	<51ED5573.9040303@sapo.pt>	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>	<trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>
	<51F1742C.7070405@sapo.pt>
Message-ID: <1374814389.40381.YahooMailNeo@web142602.mail.bf1.yahoo.com>



May be this also helps:
XXX: dataset
rl<-rle(as.character(XXX$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode1" & (rl$lengths[i]%/%3>1)) rep(3,rl$lengths[i]%/%3) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX[seq(vec2[i],max(x1)),]})
?res
#[[1]]
?#? electrode length
#1 electrode1??? 5.7
#2 electrode1??? 6.3
#3 electrode1??? 6.2
#4 electrode2?? 11.4
#5 electrode2??? 9.7
#
#[[2]]
?# ? electrode length
#6? electrode3?? 14.2
#7? electrode3?? 14.8
#8? electrode3?? 12.6
#9? electrode2?? 11.4
#10 electrode2??? 9.7
#
#[[3]]
?# ? electrode length
#11 electrode4?? 17.0
#12 electrode4?? 16.3
#13 electrode4?? 17.8
#14 electrode4?? 18.3
#15 electrode4?? 16.9
#16 electrode4?? 18.5
#17 electrode1??? 5.7
#18 electrode1??? 6.3
#19 electrode1??? 6.2

#[[4]]
?# ? electrode length
#20 electrode1??? 5.7
#21 electrode1??? 6.3
#22 electrode1??? 6.2
#23 electrode3?? 14.2
#24 electrode3?? 14.8
#25 electrode3?? 12.6

Also, tested in cases like below:
XXX1<- structure(list(electrode = structure(c(1L, 1L, 1L, 2L, 2L, 3L, 
3L, 3L, 2L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L), .Label = c("electrode1", 
"electrode2", "electrode3", "electrode4"), class = "factor"), 
??? length = c(5.7, 6.3, 6.2, 11.4, 9.7, 14.2, 14.8, 12.6, 11.4, 
??? 9.7, 17, 16.3, 17.8, 18.3, 16.9, 18.5, 5.7, 6.3, 6.2, 7.7, 
??? 7.3, 6.2, 6.7, 6.8, 6.9, 5.7, 6.3, 6.2, 14.2, 14.8, 12.6)), .Names = c("electrode", 
"length"), class = "data.frame", row.names = c(NA, -31L))

XXX2<-structure(list(electrode = structure(c(1L, 1L, 1L, 2L, 2L, 3L, 
3L, 3L, 2L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 3L, 3L, 3L), .Label = c("electrode1", "electrode2", 
"electrode3", "electrode4"), class = "factor"), length = c(5.7, 
6.3, 6.2, 11.4, 9.7, 14.2, 14.8, 12.6, 11.4, 9.7, 17, 16.3, 17.8, 
18.3, 16.9, 18.5, 5.7, 6.3, 6.2, 7.7, 7.3, 6.2, 6.7, 6.8, 6.9, 
14.2, 14.8, 12.6)), .Names = c("electrode", "length"), class = "data.frame", row.names = c(NA, 
-28L))

rl<-rle(as.character(XXX1$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode1" & (rl$lengths[i]%/%3>1)) rep(3,rl$lengths[i]%/%3) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res1<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX1[seq(vec2[i],max(x1)),]})


rl<-rle(as.character(XXX2$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode1" & (rl$lengths[i]%/%3>1)) rep(3,rl$lengths[i]%/%3) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res2<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX2[seq(vec2[i],max(x1)),]})

Didn't test it extensively.? So, it may fail in other situations.
A.K.






----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: dennis1991 at gmx.net
Cc: r-help at r-project.org
Sent: Thursday, July 25, 2013 2:53 PM
Subject: Re: [R] How to split two levels several times?

Hello,

I think the following does what you want. (I don't know if it makes much 
sense but it works.)



lens <- rle(as.character(XXX$electrode))$lengths
m <- length(lens) %/% 2
idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
if(length(lens) %% 2 != 0){
??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
??? sp_idx <- split(idx, idx)
??? n <- length(sp_idx[[m]])
??? if(n %/% 2 < length(sp_idx[[m + 1]]))
??? ??? sp_idx[[m]][(n %/% 2 + 1):n] <- sp_idx[[m + 1]][1]
??? else
??? ??? sp_idx[[m]][(n - length(sp_idx[[m + 1]]) + 1):n] <-? sp_idx[[m + 1]][1]
??? idx <- unlist(sp_idx)
}

sp <- split(XXX, idx)
sp



Rui Barradas

Em 25-07-2013 11:40, dennis1991 at gmx.net escreveu:
> Hi Rui
> once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.
>
> So idx should not return
>?  [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4
>
> but instead 6 times number 4 at the end
>?  [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4
>
> Do you have any solution?
>
>
>> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>> An: dennis1991 at gmx.net
>> Cc: r-help at r-project.org
>> Betreff: Re: Aw: Re:? Re: [R] How to split two levels several times?
>>
>> Hello,
>>
>> As for the first question, note that in the case you describe, the
>> resulting list of df's will not be a split of the original, there will
>> be a duplication in the final 4-1 and 1-3. The following is a hack but
>> will do it.
>>
>>
>> lens <- rle(as.character(XXX$electrode))$lengths
>> m <- length(lens) %/% 2
>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
>> if(length(lens) %% 2 != 0)
>> ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
>>
>> sp <- split(XXX, idx)
>>
>> if(length(lens) %% 2 != 0){
>> ??? idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
>> ??? sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
>> }
>> sp
>>
>>
>> As for the second question, I'm not understanding it, can you post
>> sample output?
>>
>> Rui Barradas
>>
>> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
>>> Hi Rui
>>> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
>>>
>>> lens <- rle(as.character(XXX$electrode))$lengths
>>> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
>>> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
>>> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
>>>
>>> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
>>>
>>>
>>> This is the table "XXX"
>>>
>>> electrode length
>>>
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode3 14.2
>>> electrode3 14.8
>>> electrode3 12.6
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode4 17.0
>>> electrode4 16.3
>>> electrode4 17.8
>>> electrode4 18.3
>>> electrode4 16.9
>>> electrode4 18.5
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode3 14.2
>>> electrode3 14.8
>>> electrode3 12.6
>>>
>>>
>>> This is a simplified table XX
>>>
>>> electrode1
>>> electrode2
>>> electrode1
>>> electrode3
>>> electrode1
>>> electrode4
>>> electrode2
>>> electrode1
>>> electrode2
>>> electrode3
>>> electrode2
>>> electrode4
>>> electrode3
>>> electrode1
>>> electrode3
>>> electrode2
>>> electrode3
>>> electrode4
>>> electrode4
>>> electrode1
>>> electrode4
>>> electrode2
>>> electrode4
>>> electrode3
>>>
>>>
>>>
>>>
>>>
>>>
>>>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>>>> An: dennis1991 at gmx.net
>>>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
>>>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
>>>>
>>>> Hello,
>>>>
>>>> It's better if you keep this on the list, the odds of getting more and
>>>> better answers are greater.
>>>>
>>>> As for your new question, try the following.
>>>>
>>>>
>>>> lens <- rle(as.character(XXX$electrode))$lengths
>>>> m <- length(lens) %/% 2
>>>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
>>>> split(XXX, idx)
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
>>>>> Hi
>>>>> this type of splitting works for my specific example. Thanks for your help.
>>>>>
>>>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,? electrode3-electrode2,? electrode4-electrode1. How should I split this?
>>>>>
>>>>>
>>>>> This is the table "XXX"
>>>>>
>>>>> electrode length
>>>>>
>>>>> electrode1 5.7
>>>>> electrode1 6.3
>>>>> electrode1 6.2
>>>>> electrode2 11.4
>>>>> electrode2 9.7
>>>>> electrode3 14.2
>>>>> electrode3 14.8
>>>>> electrode3 12.6
>>>>> electrode2 11.4
>>>>> electrode2 9.7
>>>>> electrode4 17.0
>>>>> electrode4 16.3
>>>>> electrode4 17.8
>>>>> electrode4 18.3
>>>>> electrode4 16.9
>>>>> electrode4 18.5
>>>>> electrode1 5.7
>>>>> electrode1 6.3
>>>>> electrode1 6.2
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
>>>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>>>>>> An: dennis1991 at gmx.net
>>>>>> Cc: r-help at r-project.org
>>>>>> Betreff: Re: [R] How to split two levels several times?
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Sorry, I've just realized that your data frame is named 'XXX', not
>>>>>> 'dat'. Change that and the rest should work:
>>>>>>
>>>>>>
>>>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
>>>>>> split(XXX, idx)
>>>>>>
>>>>>>
>>>>>> Rui Barradas
>>>>>>
>>>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
>>>>>>> Hello,
>>>>>>>
>>>>>>> Try the following.
>>>>>>>
>>>>>>>
>>>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
>>>>>>> split(dat, idx)
>>>>>>>
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I have a small problem with the function split() and would appreciate
>>>>>>>> your help.
>>>>>>>>
>>>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
>>>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
>>>>>>>> split the table always at the row where ?electrode1? starts again so
>>>>>>>> that I can export 7? individual dataframes (numbered ?dataframe1? to
>>>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
>>>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
>>>>>>>> I tried the split function with various setups:
>>>>>>>>
>>>>>>>> t <- as.factor(XXX$electrode)
>>>>>>>>
>>>>>>>> dataframeX <- split(XXX, f=(levels=t))
>>>>>>>>
>>>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
>>>>>>>>
>>>>>>>>
>>>>>>>> This is the table "XXX"
>>>>>>>>
>>>>>>>> electrode? ? length
>>>>>>>>
>>>>>>>> electrode1? ? 5.7
>>>>>>>> electrode1? ? 6.3
>>>>>>>> electrode1? ? 6.2
>>>>>>>> electrode2? ? 11.4
>>>>>>>> electrode2? ? 9.7
>>>>>>>> electrode1? ? 5.7
>>>>>>>> electrode1? ? 6.3
>>>>>>>> electrode1? ? 6.2
>>>>>>>> electrode3? ? 14.2
>>>>>>>> electrode3? ? 14.8
>>>>>>>> electrode3? ? 12.6
>>>>>>>> electrode1? ? 5.7
>>>>>>>> electrode1? ? 6.3
>>>>>>>> electrode1? ? 6.2
>>>>>>>> electrode4? ? 17.0
>>>>>>>> electrode4? ? 16.3
>>>>>>>> electrode4? ? 17.8
>>>>>>>> electrode4? ? 18.3
>>>>>>>> electrode4? ? 16.9
>>>>>>>> electrode4? ? 18.5
>>>>>>>> electrode1? ? ....
>>>>>>>> ....? ? ? ? ....
>>>>>>>> electrode5? ? ....
>>>>>>>> ....? ? ? ? ....
>>>>>>>> electrode1? ? ....
>>>>>>>> electrode6? ? ....
>>>>>>>> electrode1? ? ....
>>>>>>>> electrode7? ? ....
>>>>>>>> electrode1? ? ....
>>>>>>>> electrode8? ? ....
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>
>>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From theobroma22 at gmail.com  Fri Jul 26 07:00:32 2013
From: theobroma22 at gmail.com (franklin johnson)
Date: Thu, 25 Jul 2013 22:00:32 -0700
Subject: [R] help on carrying forward several vectors of rownames
Message-ID: <CAGRQPxHjbnmXrOwRWZeOmBUW7EvgaN1sk8n1fsVS0g2-whFPtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130725/08f36272/attachment.pl>

From s00123776 at myacu.edu.au  Fri Jul 26 09:34:57 2013
From: s00123776 at myacu.edu.au (s00123776 at myacu.edu.au)
Date: Fri, 26 Jul 2013 17:34:57 +1000
Subject: [R] Maintaining data order in factanal with missing data
Message-ID: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/2e140b37/attachment.pl>

From Thierry.ONKELINX at inbo.be  Fri Jul 26 10:03:32 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 26 Jul 2013 08:03:32 +0000
Subject: [R]
 =?windows-1252?q?GGplot_2_=96_cannot_get_histogram_and_box_pl?=
 =?windows-1252?q?ot_axis_to_match=2E?=
In-Reply-To: <53F5FA310C439841A76E397AAFF387151E5B3EFC@BY2PRD0811MB439.namprd08.prod.outlook.com>
References: <53F5FA310C439841A76E397AAFF387151E5B3EFC@BY2PRD0811MB439.namprd08.prod.outlook.com>
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD31947A@inbomail.inbo.be>

Dear John,

Use xlim() and ylim() instead of expand_limits()

library(ggplot2)

#sample data from ggplot2
data(Cars93, package = "MASS")
dataSet <- Cars93

#variables to calculate the range to extend the axis dataVector <- unlist(dataSet[,"MPG.city"])

dataRange <- diff(range(dataSet$MPG.city))

graphRange <- c(min(dataSet$MPG.city) - dataRange/5,
                max(dataSet$MPG.city) + dataRange/5)

#making the box plot
theBoxPlot <- ggplot(dataSet,aes_string(x = "MPG.city", y = "MPG.city"))

theBoxPlot <-
  theBoxPlot  + geom_boxplot() + coord_flip() + ylim(limits = graphRange)
print(theBoxPlot)


#making the histogram
thePlot <- ggplot(dataSet,aes_string(x = "MPG.city"))
thePlot <- thePlot + geom_histogram()  + xlim(graphRange)
print(thePlot)



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens John W. Clow
Verzonden: donderdag 25 juli 2013 20:03
Aan: r-help at r-project.org
Onderwerp: [R] GGplot 2 ? cannot get histogram and box plot axis to match.

Problem:
I am trying to get the histogram and box plot x axis to match. I?ve tried using the expand_limits function to make the axis match but that didn?t make the axis match. The histogram?s axis are still consistently larger than the ones for the box plot (though the function did help). Does anyone have a suggestion as to what I should do instead?


Background:
I am building a Shiny app that displays a histogram below a bar chart for a set of data that a user uploads to the app. If you want to see the app, go here http://spark.rstudio.com/jclow/Archive20130725HistogramApp/
To run the app, select ?Use Sample Data? , then select  ?MPG.city? under choose a column, then finally select box plot.


Sample code:
Below is a snippet of my code to demonstrate the problems I have.

library(ggplot2)

#sample data from ggplot2
data(Cars93, package = "MASS")
dataSet <- Cars93

#variables to calculate the range to extend the axis dataVector <- unlist(dataSet[,"MPG.city"])

dataRange <- max(dataVector) - min(dataVector)

graphRange <- c(min(dataVector) - dataRange/5,
                max(dataVector) + dataRange/5)

#making the box plot
theBoxPlot <- ggplot(dataSet,aes_string(x = "MPG.city",y = "MPG.city"))

theBoxPlot = theBoxPlot  + geom_boxplot() + expand_limits(y= graphRange) + coord_flip()
print(theBoxPlot)


#making the histogram
thePlot <- ggplot(dataSet,aes_string(x = "MPG.city")) thePlot <-thePlot + geom_histogram()  + expand_limits(x= graphRange)

print(thePlot)


Thank you for taking the time to read this.

John Clow
UCSB Student

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.


From Thierry.ONKELINX at inbo.be  Fri Jul 26 10:07:47 2013
From: Thierry.ONKELINX at inbo.be (ONKELINX, Thierry)
Date: Fri, 26 Jul 2013 08:07:47 +0000
Subject: [R] lme (weights) and glht
In-Reply-To: <19056582-2908-40AE-91BD-B60D9E10CF24@gmx.ch>
References: <19056582-2908-40AE-91BD-B60D9E10CF24@gmx.ch>
Message-ID: <AA818EAD2576BC488B4F623941DA7427CD31948F@inbomail.inbo.be>

Een ingesloten tekst met niet-gespecificeerde tekenset is gescrubt ...
Naam: niet beschikbaar
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/8de4c67b/attachment.pl>

From kridox at ymail.com  Fri Jul 26 10:59:35 2013
From: kridox at ymail.com (Pascal Oettli)
Date: Fri, 26 Jul 2013 17:59:35 +0900
Subject: [R] number of items to replace is not a multiple of replacement
 length
In-Reply-To: <CAOLvsEzRORQ+SQvrfcb4VqsXV5vqLtum9W01fgW516nvoiOORQ@mail.gmail.com>
References: <CAOLvsEzRORQ+SQvrfcb4VqsXV5vqLtum9W01fgW516nvoiOORQ@mail.gmail.com>
Message-ID: <51F23A77.30507@ymail.com>

Hello,

Once again, the matrix EWMA has not the correct size.

Did you carefully read the answer by Thomas Stewart?
https://stat.ethz.ch/pipermail/r-help/attachments/20130724/c454b0f7/attachment.pl

Extract of his reply: "When you expand the example to 5 stocks,
there will be 15 elements (5 variances and 10 covariances)"

 > EWMA<-matrix(nrow=T,ncol=15))

Regards,
Pascal

On 26/07/2013 14:37, G Girija wrote:
> Hi All,
>
> I have 5 stock values and i am calculating EWMA
> followed the logic as given ind following link.[
> http://www.orecastingfinancialrisk.com/3.html<http://www.forecastingfinancialrisk.com/3.html>
> ]
>
> library('tseries')
> returns[,1]<-returns[,1]-mean(returns[,1])
> returns[,2]<-returns[,2]-mean(returns[,2])
> returns[,3]<-returns[,3]-mean(returns[,3])
> returns[,4]<-returns[,4]-mean(returns[,4])
> returns[,5]<-returns[,5]-mean(returns[,5])
> T<-length(returns[,1])
> T
> EWMA<-matrix(nrow=T,ncol=5)
> lambda=0.94
> S<-cov(returns)
> S
> EWMA[1,] <- S[lower.tri(S,diag=TRUE)]
>
>
> *Error in EWMA[1, ] <- S[lower.tri(S, diag = TRUE)] : *
> *  number of items to replace is not a multiple of replacement length*
> *
> *
> for(i in 2:T)
> {
>    S<- lambda*S +(1-lambda)*t(returns[i])%*% returns[i]
> EWMA[i,] <- S[lower.tri(S,diag=TRUE)]
> }
> *
> *
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From petr.pikal at precheza.cz  Fri Jul 26 11:34:56 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Jul 2013 09:34:56 +0000
Subject: [R] Maintaining data order in factanal with missing data
In-Reply-To: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>
References: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FE58@SRVEXCHMBX.precheza.cz>

Hi

You provided functions, so far so good. But without data it would be quite difficult to understand what the functions do and where could be the issue.

I suspect combination of complete cases selection together with subset and factor behaviour. But I can be completely out of target too.

Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of s00123776 at myacu.edu.au
> Sent: Friday, July 26, 2013 9:35 AM
> To: r-help at r-project.org
> Subject: [R] Maintaining data order in factanal with missing data
> 
> Hi,
> 
> 
> 
> I'm new to R, so sorry if this is a simple answer. I'm currently trying
> to collapse some ordinal variables into a composite; the program
> ideally should take a data frame as input, perform a factor analysis,
> compute factor scores, sds, etc., and return the rescaled scores and
> loadings. The difficulty I'm having is that my data set contains a
> number of NA, which I am excluding from the analysis using
> complete.cases(), and thus the incomplete cases are "skipped". These
> functions are for a longitudinal data set with repeated waves of data,
> so the final rescaled scores from each wave need to be saved as
> variables grouped by a unique ID (DMID). The functions I'm trying to
> implement are as follows:
> 
> 
> 
> weighted.sd<-function(x,w){
> 
>                                 sum.w<-sum(w)
> 
>                                 sum.w2<-sum(w^2)
> 
>                                 mean.w<-sum(x*w)/sum(w)
> 
> 
> x.sd.w<-sqrt((sum.w/(sum.w^2-sum.w2))*sum(w*(x-mean.w)^2))
> 
>                                 return(x.sd.w)
> 
>                                 }
> 
> 
> 
> re.scale<-function(f.scores, raw.data, loadings){
> 
> 
> fz.scores<-(f.scores+mean(f.scores))/(sd(f.scores))
> 
> 
> means<-apply(raw.data,1,weighted.mean,w=loadings)
> 
> 
> sds<-apply(raw.data,1,weighted.sd,w=loadings)
> 
>                                 grand.mean<-mean(means)
> 
>                                 grand.sd<-mean(sds)
> 
> 
> final.scores<-((fz.scores*grand.sd)+grand.mean)
> 
>                                 return(final.scores)
> 
>                                 }
> 
> 
> 
> get.scores<-function(data){
> 
> 
> fact<-
> factanal(data[complete.cases(data),],factors=1,scores="regression")
> 
>                                 f.scores<-fact$scores[,1]
> 
>                                 f.loads<-fact$loadings[,1]
> 
>                                 rescaled.scores<-re.scale(f.scores,
> data[complete.cases(data),], f.loads)
> 
>                                 output.list<-list(rescaled.scores,
> f.loads)
> 
>                                 names(output.list)<-
> c("rescaled.scores",
> "factor.loadings")
> 
>                                 return(output.list)
> 
>                                 }
> 
> 
> 
> init.dfs<-function(){
> 
> 
> ab.1.df<-subset(ab.df,,select=c(dmid,g5oab2:g5ovb1))
> 
> 
> ab.2.df<-subset(ab.df,,select=c(dmid,w2oab3:w2ovb1))
> 
>                                 ab.3.df<-subset(ab.df,,select=c(dmid,
> w3oab3, w3oab4, w3oab7, w3oab8, w3ovb1))
> 
> 
> 
>                                 ab.1.fa<-get.scores(ab.1.df[-1])
> 
>                                 ab.2.fa<-get.scores(ab.2.df[-1])
> 
>                                 ab.3.fa<-get.scores(ab.3.df[-1])
> 
> 
>                                 }
> 
> 
> 
> Thanks for your help,
> 
> 
> 
> Justin
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dennis1991 at gmx.net  Fri Jul 26 12:07:39 2013
From: dennis1991 at gmx.net (dennis1991 at gmx.net)
Date: Fri, 26 Jul 2013 12:07:39 +0200 (CEST)
Subject: [R] How to split two levels several times?
In-Reply-To: <51F1742C.7070405@sapo.pt>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>
	<trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>,
	<51F1742C.7070405@sapo.pt>
Message-ID: <trinity-0aef6fe9-ceb7-4b5c-bbc6-2949bc354692-1374833259262@3capp-gmx-bs52>

Hi Rui & Arun,
really thanks for investing so much time to deal with this problem! The code works now for this specific example. However it is not generally robust for slightly different situations. For instance it cannot correctly handle a slight variation of the table where I have again 4 types of electrodes of certain lengths. Electrode4 exists only 6 times. At the transition of the combinations 3-4 and 4-1 there are 12 times electrode4 which stick together in the output $`9`. This leads to wrong splittings thereafter. Sorry for asking such tricky questions.

New table XXX

electrode	length
electrode1	206
electrode1	194
electrode1	182
electrode1	172
electrode1	169
electrode2	82
electrode2	78
electrode2	70
electrode2	58
electrode1	206
electrode1	194
electrode1	182
electrode1	172
electrode1	169
electrode3	260
electrode3	176
electrode3	137
electrode1	206
electrode1	194
electrode1	182
electrode1	172
electrode1	169
electrode4	86
electrode4	66
electrode4	64
electrode4	52
electrode4	27
electrode4	26
electrode2	82
electrode2	78
electrode2	70
electrode2	58
electrode1	206
electrode1	194
electrode1	182
electrode1	172
electrode1	169
electrode2	82
electrode2	78
electrode2	70
electrode2	58
electrode3	260
electrode3	176
electrode3	137
electrode2	82
electrode2	78
electrode2	70
electrode2	58
electrode4	86
electrode4	66
electrode4	64
electrode4	52
electrode4	27
electrode4	26
electrode3	260
electrode3	176
electrode3	137
electrode1	206
electrode1	194
electrode1	182
electrode1	172
electrode1	169
electrode3	260
electrode3	176
electrode3	137
electrode2	82
electrode2	78
electrode2	70
electrode2	58
electrode3	260
electrode3	176
electrode3	137
electrode4	86
electrode4	66
electrode4	64
electrode4	52
electrode4	27
electrode4	26
electrode4	86
electrode4	66
electrode4	64
electrode4	52
electrode4	27
electrode4	26
electrode1	206
electrode1	194
electrode1	182
electrode1	172
electrode1	169
electrode4	86
electrode4	66
electrode4	64
electrode4	52
electrode4	27
electrode4	26
electrode2	82
electrode2	78
electrode2	70
electrode2	58
electrode4	86
electrode4	66
electrode4	64
electrode4	52
electrode4	27
electrode4	26
electrode3	260
electrode3	176
electrode3	137





> Gesendet: Donnerstag, 25. Juli 2013 um 20:53 Uhr
> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> An: dennis1991 at gmx.net
> Cc: r-help at r-project.org
> Betreff: Re: Aw: Re:  Re:  Re: [R] How to split two levels several times?
>
> Hello,
>
> I think the following does what you want. (I don't know if it makes much
> sense but it works.)
>
>
>
> lens <- rle(as.character(XXX$electrode))$lengths
> m <- length(lens) %/% 2
> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> if(length(lens) %% 2 != 0){
> 	idx <- c(idx, rep(m + 1, lens[length(lens)]))
> 	sp_idx <- split(idx, idx)
> 	n <- length(sp_idx[[m]])
> 	if(n %/% 2 < length(sp_idx[[m + 1]]))
> 		sp_idx[[m]][(n %/% 2 + 1):n] <- sp_idx[[m + 1]][1]
> 	else
> 		sp_idx[[m]][(n - length(sp_idx[[m + 1]]) + 1):n] <-  sp_idx[[m + 1]][1]
> 	idx <- unlist(sp_idx)
> }
>
> sp <- split(XXX, idx)
> sp
>
>
>
> Rui Barradas
>
> Em 25-07-2013 11:40, dennis1991 at gmx.net escreveu:
> > Hi Rui
> > once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.
> >
> > So idx should not return
> >   [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4
> >
> > but instead 6 times number 4 at the end
> >   [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4
> >
> > Do you have any solution?
> >
> >
> >> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
> >> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >> An: dennis1991 at gmx.net
> >> Cc: r-help at r-project.org
> >> Betreff: Re: Aw: Re:  Re: [R] How to split two levels several times?
> >>
> >> Hello,
> >>
> >> As for the first question, note that in the case you describe, the
> >> resulting list of df's will not be a split of the original, there will
> >> be a duplication in the final 4-1 and 1-3. The following is a hack but
> >> will do it.
> >>
> >>
> >> lens <- rle(as.character(XXX$electrode))$lengths
> >> m <- length(lens) %/% 2
> >> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> >> if(length(lens) %% 2 != 0)
> >> 	idx <- c(idx, rep(m + 1, lens[length(lens)]))
> >>
> >> sp <- split(XXX, idx)
> >>
> >> if(length(lens) %% 2 != 0){
> >> 	idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
> >> 	sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
> >> }
> >> sp
> >>
> >>
> >> As for the second question, I'm not understanding it, can you post
> >> sample output?
> >>
> >> Rui Barradas
> >>
> >> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
> >>> Hi Rui
> >>> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
> >>>
> >>> lens <- rle(as.character(XXX$electrode))$lengths
> >>> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
> >>> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
> >>> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
> >>>
> >>> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
> >>>
> >>>
> >>> This is the table "XXX"
> >>>
> >>> electrode length
> >>>
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode3 14.2
> >>> electrode3 14.8
> >>> electrode3 12.6
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode4 17.0
> >>> electrode4 16.3
> >>> electrode4 17.8
> >>> electrode4 18.3
> >>> electrode4 16.9
> >>> electrode4 18.5
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode3 14.2
> >>> electrode3 14.8
> >>> electrode3 12.6
> >>>
> >>>
> >>> This is a simplified table XX
> >>>
> >>> electrode1
> >>> electrode2
> >>> electrode1
> >>> electrode3
> >>> electrode1
> >>> electrode4
> >>> electrode2
> >>> electrode1
> >>> electrode2
> >>> electrode3
> >>> electrode2
> >>> electrode4
> >>> electrode3
> >>> electrode1
> >>> electrode3
> >>> electrode2
> >>> electrode3
> >>> electrode4
> >>> electrode4
> >>> electrode1
> >>> electrode4
> >>> electrode2
> >>> electrode4
> >>> electrode3
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
> >>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >>>> An: dennis1991 at gmx.net
> >>>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
> >>>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
> >>>>
> >>>> Hello,
> >>>>
> >>>> It's better if you keep this on the list, the odds of getting more and
> >>>> better answers are greater.
> >>>>
> >>>> As for your new question, try the following.
> >>>>
> >>>>
> >>>> lens <- rle(as.character(XXX$electrode))$lengths
> >>>> m <- length(lens) %/% 2
> >>>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> >>>> split(XXX, idx)
> >>>>
> >>>>
> >>>> Hope this helps,
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
> >>>>> Hi
> >>>>> this type of splitting works for my specific example. Thanks for your help.
> >>>>>
> >>>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,  electrode3-electrode2,  electrode4-electrode1. How should I split this?
> >>>>>
> >>>>>
> >>>>> This is the table "XXX"
> >>>>>
> >>>>> electrode length
> >>>>>
> >>>>> electrode1 5.7
> >>>>> electrode1 6.3
> >>>>> electrode1 6.2
> >>>>> electrode2 11.4
> >>>>> electrode2 9.7
> >>>>> electrode3 14.2
> >>>>> electrode3 14.8
> >>>>> electrode3 12.6
> >>>>> electrode2 11.4
> >>>>> electrode2 9.7
> >>>>> electrode4 17.0
> >>>>> electrode4 16.3
> >>>>> electrode4 17.8
> >>>>> electrode4 18.3
> >>>>> electrode4 16.9
> >>>>> electrode4 18.5
> >>>>> electrode1 5.7
> >>>>> electrode1 6.3
> >>>>> electrode1 6.2
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
> >>>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >>>>>> An: dennis1991 at gmx.net
> >>>>>> Cc: r-help at r-project.org
> >>>>>> Betreff: Re: [R] How to split two levels several times?
> >>>>>>
> >>>>>> Hello,
> >>>>>>
> >>>>>> Sorry, I've just realized that your data frame is named 'XXX', not
> >>>>>> 'dat'. Change that and the rest should work:
> >>>>>>
> >>>>>>
> >>>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
> >>>>>> split(XXX, idx)
> >>>>>>
> >>>>>>
> >>>>>> Rui Barradas
> >>>>>>
> >>>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
> >>>>>>> Hello,
> >>>>>>>
> >>>>>>> Try the following.
> >>>>>>>
> >>>>>>>
> >>>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
> >>>>>>> split(dat, idx)
> >>>>>>>
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
> >>>>>>>> Hi,
> >>>>>>>>
> >>>>>>>> I have a small problem with the function split() and would appreciate
> >>>>>>>> your help.
> >>>>>>>>
> >>>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
> >>>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
> >>>>>>>> split the table always at the row where ?electrode1? starts again so
> >>>>>>>> that I can export 7  individual dataframes (numbered ?dataframe1? to
> >>>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
> >>>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
> >>>>>>>> I tried the split function with various setups:
> >>>>>>>>
> >>>>>>>> t <- as.factor(XXX$electrode)
> >>>>>>>>
> >>>>>>>> dataframeX <- split(XXX, f=(levels=t))
> >>>>>>>>
> >>>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> This is the table "XXX"
> >>>>>>>>
> >>>>>>>> electrode    length
> >>>>>>>>
> >>>>>>>> electrode1    5.7
> >>>>>>>> electrode1    6.3
> >>>>>>>> electrode1    6.2
> >>>>>>>> electrode2    11.4
> >>>>>>>> electrode2    9.7
> >>>>>>>> electrode1    5.7
> >>>>>>>> electrode1    6.3
> >>>>>>>> electrode1    6.2
> >>>>>>>> electrode3    14.2
> >>>>>>>> electrode3    14.8
> >>>>>>>> electrode3    12.6
> >>>>>>>> electrode1    5.7
> >>>>>>>> electrode1    6.3
> >>>>>>>> electrode1    6.2
> >>>>>>>> electrode4    17.0
> >>>>>>>> electrode4    16.3
> >>>>>>>> electrode4    17.8
> >>>>>>>> electrode4    18.3
> >>>>>>>> electrode4    16.9
> >>>>>>>> electrode4    18.5
> >>>>>>>> electrode1    ....
> >>>>>>>> ....        ....
> >>>>>>>> electrode5    ....
> >>>>>>>> ....        ....
> >>>>>>>> electrode1    ....
> >>>>>>>> electrode6    ....
> >>>>>>>> electrode1    ....
> >>>>>>>> electrode7    ....
> >>>>>>>> electrode1    ....
> >>>>>>>> electrode8    ....
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>>
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>
> >>
>


From engiltigadress at gmail.com  Fri Jul 26 10:36:59 2013
From: engiltigadress at gmail.com (Anders Sand)
Date: Fri, 26 Jul 2013 10:36:59 +0200
Subject: [R] n-dash instead of hyphens in plots
Message-ID: <CAO50X8CGXy_Rq8SENUFy2ZAPtxYdPZmVCaTUdnnWyeJHN1eXUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/875459ce/attachment.pl>

From teresamarso at hotmail.com  Fri Jul 26 10:36:04 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Fri, 26 Jul 2013 08:36:04 +0000
Subject: [R] Help R
Message-ID: <BAY172-W3995C76A1F4BFD264B5559B96A0@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/7ea06dc8/attachment.pl>

From minaorang at gmail.com  Fri Jul 26 10:26:18 2013
From: minaorang at gmail.com (mina orang)
Date: Fri, 26 Jul 2013 12:56:18 +0430
Subject: [R] a very urgunt and important question about R
Message-ID: <CANjNdtyaqnx5a0td1+RCivjMjc+LXPthAUcnT2cKD=Wufkxf8w@mail.gmail.com>

Dear all

I am doing a research in clinical psychology and I need to Generate a
block randomization for a clinical trial, with two treatments and
three therapists. I mean I must randomize the clients (all women) to
two kinds of treatment (called "treatment as usual" and "narrative
exposure therapy") and three different therapists.
I tried to do this randomization by using R software and by using
stratification package but I didn't (and still can not) understand how
I should use R for this job.

Could you please help me and show me how I should use R for this kind
of randomization in a really easy way?

I really appreciate your help in advance.

Best
Mina

P.S. I just know little about statistics and software. Please teach me
in a really easy way.


From ripley at stats.ox.ac.uk  Fri Jul 26 12:23:37 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 26 Jul 2013 11:23:37 +0100
Subject: [R] n-dash instead of hyphens in plots
In-Reply-To: <CAO50X8CGXy_Rq8SENUFy2ZAPtxYdPZmVCaTUdnnWyeJHN1eXUA@mail.gmail.com>
References: <CAO50X8CGXy_Rq8SENUFy2ZAPtxYdPZmVCaTUdnnWyeJHN1eXUA@mail.gmail.com>
Message-ID: <51F24E29.5010402@stats.ox.ac.uk>

On 26/07/2013 09:36, Anders Sand wrote:
> Dear community,
>
> How do I change the hyphens that appear when using '-' to n-dash in, for
> example, x-axes?
>
> Example code:
> axis(1, c(1:2), c("1-4", "23-26"), tck=.05)

On what device on what platform?   The commonest answer would be

'if you want en-dash not hyphen, ask for en-dash and not hyphen'

en-dash is "\u2013" where that is supported.


>
> Thanks
> Anders
>
> 	[[alternative HTML version deleted]]
>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

This did ask for 'at a minimum' information and no HTML.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From petr.pikal at precheza.cz  Fri Jul 26 12:23:59 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Jul 2013 10:23:59 +0000
Subject: [R] a very urgunt and important question about R
In-Reply-To: <CANjNdtyaqnx5a0td1+RCivjMjc+LXPthAUcnT2cKD=Wufkxf8w@mail.gmail.com>
References: <CANjNdtyaqnx5a0td1+RCivjMjc+LXPthAUcnT2cKD=Wufkxf8w@mail.gmail.com>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FEB3@SRVEXCHMBX.precheza.cz>

Hi

I recommend to start with

library(fortunes)
fortune("surgery")

Anyway, beside Introduction to R you could go through 

CRAN Task View: Design of Experiments (DoE) & Analysis of Experimental Data

and specifically through

Experimental designs for clinical trials 
This task view only covers specific design of experiments packages; there may be some grey areas. Please, also consult the ClinicalTrials task view. 

*experiment contains tools for clinical experiments, e.g., a randomization tool, and it provides a few special analysis options for clinical trials. 
*Package gsDesign implements group sequential designs, 
*Package gsbDesign evaluates operating characteristics for group sequential Bayesian designs, 
*package asd implements adaptive sequential designs. 
*Package TEQR provides toxicity equivalence range designs (Blanchard and Longmate 2010) for phase I clinical trials. 
*The DoseFinding package provides functions for the design and analysis of dose-finding experiments (for example pharmaceutical Phase II clinical trials); it combines the facilities of the "MCPMod" package (maintenance discontinued; described in Bornkamp, Pinheiro and Bretz 2009) with a special type of optimal designs for dose finding situations (MED-optimal designs, or D-optimal designs, or a mixture of both; cf., Dette et al. 2008)

Which shall provide you with some insight.

Regards
Petr


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> project.org] On Behalf Of mina orang
> Sent: Friday, July 26, 2013 10:26 AM
> To: r-help at r-project.org
> Subject: [R] a very urgunt and important question about R
> 
> Dear all
> 
> I am doing a research in clinical psychology and I need to Generate a
> block randomization for a clinical trial, with two treatments and three
> therapists. I mean I must randomize the clients (all women) to two
> kinds of treatment (called "treatment as usual" and "narrative exposure
> therapy") and three different therapists.
> I tried to do this randomization by using R software and by using
> stratification package but I didn't (and still can not) understand how
> I should use R for this job.
> 
> Could you please help me and show me how I should use R for this kind
> of randomization in a really easy way?
> 
> I really appreciate your help in advance.
> 
> Best
> Mina
> 
> P.S. I just know little about statistics and software. Please teach me
> in a really easy way.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-
> guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Jul 26 13:51:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 04:51:15 -0700 (PDT)
Subject: [R] a very urgunt and important question about R
In-Reply-To: <CANjNdtyaqnx5a0td1+RCivjMjc+LXPthAUcnT2cKD=Wufkxf8w@mail.gmail.com>
References: <CANjNdtyaqnx5a0td1+RCivjMjc+LXPthAUcnT2cKD=Wufkxf8w@mail.gmail.com>
Message-ID: <1374839475.73389.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
You may try:
library(psych)
?block.random()

Also, look this link
http://personality-project.org/revelle/syllabi/205/block.randomization.pdf
A.K.




----- Original Message -----
From: mina orang <minaorang at gmail.com>
To: r-help at r-project.org
Cc: 
Sent: Friday, July 26, 2013 4:26 AM
Subject: [R] a very urgunt and important question about R

Dear all

I am doing a research in clinical psychology and I need to Generate a
block randomization for a clinical trial, with two treatments and
three therapists. I mean I must randomize the clients (all women) to
two kinds of treatment (called "treatment as usual" and "narrative
exposure therapy") and three different therapists.
I tried to do this randomization by using R software and by using
stratification package but I didn't (and still can not) understand how
I should use R for this job.

Could you please help me and show me how I should use R for this kind
of randomization in a really easy way?

I really appreciate your help in advance.

Best
Mina

P.S. I just know little about statistics and software. Please teach me
in a really easy way.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From f.harrell at Vanderbilt.Edu  Fri Jul 26 13:57:21 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Fri, 26 Jul 2013 06:57:21 -0500
Subject: [R] Jul 26, 2013; 12:34am
Message-ID: <51F26421.3010408@vanderbilt.edu>

Thanks Rich and Jim and apologies for omitting the line

x <- c(285, 43.75, 94, 150, 214, 375, 270, 350, 41.5, 210, 30, 37.6,
281, 101, 210)

But the fundamental problem remains that vertical spacing is not correct 
unless I waste a lot of image space at the top.

Frank


-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From therneau at mayo.edu  Fri Jul 26 14:02:12 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 26 Jul 2013 07:02:12 -0500
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
	<4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
	<4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>
	<6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>
Message-ID: <51F26544.5000701@mayo.edu>

Two choices.
If this were a linear model, do you like the GEE approach or a mixed effects approach?  
Assume that "subject" is a variable containing a per-subject identifier.

GEE approach: add "+ cluster(subject)" to the model statement in coxph
Mixed models approach: Add " + (1|subject)" to the model statment in coxme.

When only a very few subjects have multiple events, the mixed model (random effect) 
approach may not be reliable, however.  Multiple events per group are the fuel for 
estimation of the variance of the random effect, and with few of these the profile 
likelihood of the random effect will be very flat.  You can get esssentially a random 
estimate of the variance of the "subject effect".  I'm still getting my arms around this 
issue, and it has taken me a long time.

"Frailty" is an alternate label for "random effects when all we have is a random 
intercept".  Multiple labels for the same idea adds confusion, but nothing else.

Terry Therneau

On 07/25/2013 08:14 PM, Marc Schwartz wrote:
> On Jul 25, 2013, at 4:45 PM, David Winsemius<dwinsemius at comcast.net>  wrote:
>
>> On Jul 25, 2013, at 12:27 PM, Marc Schwartz wrote:
>>
>>> On Jul 25, 2013, at 2:11 PM, John Sorkin<jsorkin at grecc.umaryland.edu>  wrote:
>>>
>>>> Colleagues,
>>>> Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
>>>> I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
>>>> Thank you,
>>>> John
>>>
>>>
>>> John,
>>>
>>> See Terry's 'coxme' package:
>>>
>>> http://cran.r-project.org/web/packages/coxme/index.html
>>>
>> When I looked over the description of coxme, I was concerned it was not really designed with this in mind. Looking at Therneau and Grambsch, I thought section 8.4.2 in the 'Multiple Events per Subject' Chapter fit the analysis question well. There they compared the use of coxph( ...+cluster(ID),,...)  withcoxph( ...+strata(ID),,...). Unfortunately I could not tell for sure which one was being described as superio but I think it was the cluster() alternative. I seem to remember there are discussions in the archives.
>
> David,
>
> I think that you raise a good point. The example in the book (I had to wait to get home to read it) is potentially different however, in that the subject's eye's were randomized to treatment or control, which would seem to suggest comparable baseline characteristics for each pair of eyes, as well as an active intervention on one side where a difference in treatment effect between each eye is being analyzed.
>
> It is not clear from John's description above if there is one hip that will be treated versus one as a control and whether the extent of disease at baseline is similar in each pair of hips. Presumably the timing of hip replacements will be staggered at some level, even if there is comparable disease, simply due to post-op recovery time and surgical risk. In cases where the disease between each hip is materially different, that would be another factor to consider, however I would defer to orthopaedic physicians/surgeons from a subject matter expertise consideration. It is possible that the bilateral hip replacement data might be more of a parallel to bilateral breast cancer data, if each breast were to be tracked separately.
>
> I have cc'd Terry here, hoping that he might jump in and offer some insights into the pros/cons of using coxme versus coxph with either a cluster or strata based approach, or perhaps even a frailty based approach as in 9.4.1 in the book.
>
> Regards,
>
> Marc
>
>
>> -- 
>> David.
>>> You also might find the following of interest:
>>>
>>> http://bjo.bmj.com/content/71/9/645.full.pdf
>>>
>>> http://www.ncbi.nlm.nih.gov/pubmed/22226885
>>>
>>> http://www.ncbi.nlm.nih.gov/pubmed/22078901
>>>
>>>
>>>
>>> Regards,
>>>
>>> Marc Schwartz
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Jul 26 14:32:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 05:32:25 -0700 (PDT)
Subject: [R] How to split two levels several times?
In-Reply-To: <1374815138.93641.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>	<51ED540C.1000303@sapo.pt>,
	<51ED5573.9040303@sapo.pt>	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>	<trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>
	<51F1742C.7070405@sapo.pt>
	<1374814389.40381.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1374815138.93641.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1374841945.97125.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Dennis,
No problem.

As I mentioned, I was under the understanding that "electrode1" occurs only in multiples of 3.? I think your earlier post sounded like that.? May be I was misunderstood.? So, my solution was based on that.? In the below table, I am not sure, how you wanted to split.? For ex. it is not clear, whether rows 1-5 (electrode1) are only in the first list element or should it include? the next electrode "electrode2" also?? Could you also show the expected output?

dat$Len
# [1]? 5? 4? 5? 3? 5? 6? 4? 5? 4? 3? 4? 6? 3? 5? 3? 4? 3 12? 5? 6? 4? 6? 3
?as.character(dat$Val)
# [1] "electrode1" "electrode2" "electrode1" "electrode3" "electrode1"
?#[6] "electrode4" "electrode2" "electrode1" "electrode2" "electrode3"
#[11] "electrode2" "electrode4" "electrode3" "electrode1" "electrode3"
#[16] "electrode2" "electrode3" "electrode4" "electrode1" "electrode4"
#[21] "electrode2" "electrode4" "electrode3"
A.K.



Hi Rui & Arun, 
really thanks for investing so much time to deal with this problem! 
The code works now for this specific example. However it is not 
generally robust for slightly different situations. For instance it 
cannot correctly handle a slight variation of the table where I have 
again 4 types of electrodes of certain lengths. Electrode4 exists only 6
 times. At the transition of the combinations 3-4 and 4-1 there are 12 
times electrode4 which stick together in the output $`9`. This leads to 
wrong splittings thereafter. Sorry for asking such tricky questions. 

New table XXX 

electrode	length 
electrode1	206 
electrode1	194 
electrode1	182 
electrode1	172 
electrode1	169 
electrode2	82 
electrode2	78 
electrode2	70 
electrode2	58 
electrode1	206 
electrode1	194 
electrode1	182 
electrode1	172 
electrode1	169 
electrode3	260 
electrode3	176 
electrode3	137 
electrode1	206 
electrode1	194 
electrode1	182 
electrode1	172 
electrode1	169 
electrode4	86 
electrode4	66 
electrode4	64 
electrode4	52 
electrode4	27 
electrode4	26 
electrode2	82 
electrode2	78 
electrode2	70 
electrode2	58 
electrode1	206 
electrode1	194 
electrode1	182 
electrode1	172 
electrode1	169 
electrode2	82 
electrode2	78 
electrode2	70 
electrode2	58 
electrode3	260 
electrode3	176 
electrode3	137 
electrode2	82 
electrode2	78 
electrode2	70 
electrode2	58 
electrode4	86 
electrode4	66 
electrode4	64 
electrode4	52 
electrode4	27 
electrode4	26 
electrode3	260 
electrode3	176 
electrode3	137 
electrode1	206 
electrode1	194 
electrode1	182 
electrode1	172 
electrode1	169 
electrode3	260 
electrode3	176 
electrode3	137 
electrode2	82 
electrode2	78 
electrode2	70 
electrode2	58 
electrode3	260 
electrode3	176 
electrode3	137 
electrode4	86 
electrode4	66 
electrode4	64 
electrode4	52 
electrode4	27 
electrode4	26 
electrode4	86 
electrode4	66 
electrode4	64 
electrode4	52 
electrode4	27 
electrode4	26 
electrode1	206 
electrode1	194 
electrode1	182 
electrode1	172 
electrode1	169 
electrode4	86 
electrode4	66 
electrode4	64 
electrode4	52 
electrode4	27 
electrode4	26 
electrode2	82 
electrode2	78 
electrode2	70 
electrode2	58 
electrode4	86 
electrode4	66 
electrode4	64 
electrode4	52 
electrode4	27 
electrode4	26 
electrode3	260 
electrode3	176 
electrode3	137 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
Cc: 
Sent: Friday, July 26, 2013 1:05 AM
Subject: Re: [R] How to split two levels several times?

Just to add:
I assumed that "electrode1" would be found in multiples of 3.? I could be wrong.? 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Rui Barradas <ruipbarradas at sapo.pt>
Cc: "dennis1991 at gmx.net" <dennis1991 at gmx.net>; "r-help at r-project.org" <r-help at r-project.org>
Sent: Friday, July 26, 2013 12:53 AM
Subject: Re: [R] How to split two levels several times?



May be this also helps:
XXX: dataset
rl<-rle(as.character(XXX$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode1" & (rl$lengths[i]%/%3>1)) rep(3,rl$lengths[i]%/%3) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX[seq(vec2[i],max(x1)),]})
?res
#[[1]]
?#? electrode length
#1 electrode1??? 5.7
#2 electrode1??? 6.3
#3 electrode1??? 6.2
#4 electrode2?? 11.4
#5 electrode2??? 9.7
#
#[[2]]
?# ? electrode length
#6? electrode3?? 14.2
#7? electrode3?? 14.8
#8? electrode3?? 12.6
#9? electrode2?? 11.4
#10 electrode2??? 9.7
#
#[[3]]
?# ? electrode length
#11 electrode4?? 17.0
#12 electrode4?? 16.3
#13 electrode4?? 17.8
#14 electrode4?? 18.3
#15 electrode4?? 16.9
#16 electrode4?? 18.5
#17 electrode1??? 5.7
#18 electrode1??? 6.3
#19 electrode1??? 6.2

#[[4]]
?# ? electrode length
#20 electrode1??? 5.7
#21 electrode1??? 6.3
#22 electrode1??? 6.2
#23 electrode3?? 14.2
#24 electrode3?? 14.8
#25 electrode3?? 12.6

Also, tested in cases like below:
XXX1<- structure(list(electrode = structure(c(1L, 1L, 1L, 2L, 2L, 3L, 
3L, 3L, 2L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 1L, 1L, 1L, 3L, 3L, 3L), .Label = c("electrode1", 
"electrode2", "electrode3", "electrode4"), class = "factor"), 
??? length = c(5.7, 6.3, 6.2, 11.4, 9.7, 14.2, 14.8, 12.6, 11.4, 
??? 9.7, 17, 16.3, 17.8, 18.3, 16.9, 18.5, 5.7, 6.3, 6.2, 7.7, 
??? 7.3, 6.2, 6.7, 6.8, 6.9, 5.7, 6.3, 6.2, 14.2, 14.8, 12.6)), .Names = c("electrode", 
"length"), class = "data.frame", row.names = c(NA, -31L))

XXX2<-structure(list(electrode = structure(c(1L, 1L, 1L, 2L, 2L, 3L, 
3L, 3L, 2L, 2L, 4L, 4L, 4L, 4L, 4L, 4L, 1L, 1L, 1L, 1L, 1L, 1L, 
1L, 1L, 1L, 3L, 3L, 3L), .Label = c("electrode1", "electrode2", 
"electrode3", "electrode4"), class = "factor"), length = c(5.7, 
6.3, 6.2, 11.4, 9.7, 14.2, 14.8, 12.6, 11.4, 9.7, 17, 16.3, 17.8, 
18.3, 16.9, 18.5, 5.7, 6.3, 6.2, 7.7, 7.3, 6.2, 6.7, 6.8, 6.9, 
14.2, 14.8, 12.6)), .Names = c("electrode", "length"), class = "data.frame", row.names = c(NA, 
-28L))

rl<-rle(as.character(XXX1$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode1" & (rl$lengths[i]%/%3>1)) rep(3,rl$lengths[i]%/%3) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res1<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX1[seq(vec2[i],max(x1)),]})


rl<-rle(as.character(XXX2$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode1" & (rl$lengths[i]%/%3>1)) rep(3,rl$lengths[i]%/%3) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res2<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX2[seq(vec2[i],max(x1)),]})

Didn't test it extensively.? So, it may fail in other situations.
A.K.






----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: dennis1991 at gmx.net
Cc: r-help at r-project.org
Sent: Thursday, July 25, 2013 2:53 PM
Subject: Re: [R] How to split two levels several times?

Hello,

I think the following does what you want. (I don't know if it makes much 
sense but it works.)



lens <- rle(as.character(XXX$electrode))$lengths
m <- length(lens) %/% 2
idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
if(length(lens) %% 2 != 0){
??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
??? sp_idx <- split(idx, idx)
??? n <- length(sp_idx[[m]])
??? if(n %/% 2 < length(sp_idx[[m + 1]]))
??? ??? sp_idx[[m]][(n %/% 2 + 1):n] <- sp_idx[[m + 1]][1]
??? else
??? ??? sp_idx[[m]][(n - length(sp_idx[[m + 1]]) + 1):n] <-? sp_idx[[m + 1]][1]
??? idx <- unlist(sp_idx)
}

sp <- split(XXX, idx)
sp



Rui Barradas

Em 25-07-2013 11:40, dennis1991 at gmx.net escreveu:
> Hi Rui
> once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.
>
> So idx should not return
>?? [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4
>
> but instead 6 times number 4 at the end
>?? [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4
>
> Do you have any solution?
>
>
>> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>> An: dennis1991 at gmx.net
>> Cc: r-help at r-project.org
>> Betreff: Re: Aw: Re:? Re: [R] How to split two levels several times?
>>
>> Hello,
>>
>> As for the first question, note that in the case you describe, the
>> resulting list of df's will not be a split of the original, there will
>> be a duplication in the final 4-1 and 1-3. The following is a hack but
>> will do it.
>>
>>
>> lens <- rle(as.character(XXX$electrode))$lengths
>> m <- length(lens) %/% 2
>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
>> if(length(lens) %% 2 != 0)
>> ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
>>
>> sp <- split(XXX, idx)
>>
>> if(length(lens) %% 2 != 0){
>> ??? idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
>> ??? sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
>> }
>> sp
>>
>>
>> As for the second question, I'm not understanding it, can you post
>> sample output?
>>
>> Rui Barradas
>>
>> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
>>> Hi Rui
>>> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
>>>
>>> lens <- rle(as.character(XXX$electrode))$lengths
>>> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
>>> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
>>> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
>>>
>>> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
>>>
>>>
>>> This is the table "XXX"
>>>
>>> electrode length
>>>
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode3 14.2
>>> electrode3 14.8
>>> electrode3 12.6
>>> electrode2 11.4
>>> electrode2 9.7
>>> electrode4 17.0
>>> electrode4 16.3
>>> electrode4 17.8
>>> electrode4 18.3
>>> electrode4 16.9
>>> electrode4 18.5
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode1 5.7
>>> electrode1 6.3
>>> electrode1 6.2
>>> electrode3 14.2
>>> electrode3 14.8
>>> electrode3 12.6
>>>
>>>
>>> This is a simplified table XX
>>>
>>> electrode1
>>> electrode2
>>> electrode1
>>> electrode3
>>> electrode1
>>> electrode4
>>> electrode2
>>> electrode1
>>> electrode2
>>> electrode3
>>> electrode2
>>> electrode4
>>> electrode3
>>> electrode1
>>> electrode3
>>> electrode2
>>> electrode3
>>> electrode4
>>> electrode4
>>> electrode1
>>> electrode4
>>> electrode2
>>> electrode4
>>> electrode3
>>>
>>>
>>>
>>>
>>>
>>>
>>>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>>>> An: dennis1991 at gmx.net
>>>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
>>>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
>>>>
>>>> Hello,
>>>>
>>>> It's better if you keep this on the list, the odds of getting more and
>>>> better answers are greater.
>>>>
>>>> As for your new question, try the following.
>>>>
>>>>
>>>> lens <- rle(as.character(XXX$electrode))$lengths
>>>> m <- length(lens) %/% 2
>>>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
>>>> split(XXX, idx)
>>>>
>>>>
>>>> Hope this helps,
>>>>
>>>> Rui Barradas
>>>>
>>>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
>>>>> Hi
>>>>> this type of splitting works for my specific example. Thanks for your help.
>>>>>
>>>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,? electrode3-electrode2,? electrode4-electrode1. How should I split this?
>>>>>
>>>>>
>>>>> This is the table "XXX"
>>>>>
>>>>> electrode length
>>>>>
>>>>> electrode1 5.7
>>>>> electrode1 6.3
>>>>> electrode1 6.2
>>>>> electrode2 11.4
>>>>> electrode2 9.7
>>>>> electrode3 14.2
>>>>> electrode3 14.8
>>>>> electrode3 12.6
>>>>> electrode2 11.4
>>>>> electrode2 9.7
>>>>> electrode4 17.0
>>>>> electrode4 16.3
>>>>> electrode4 17.8
>>>>> electrode4 18.3
>>>>> electrode4 16.9
>>>>> electrode4 18.5
>>>>> electrode1 5.7
>>>>> electrode1 6.3
>>>>> electrode1 6.2
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>
>>>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
>>>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
>>>>>> An: dennis1991 at gmx.net
>>>>>> Cc: r-help at r-project.org
>>>>>> Betreff: Re: [R] How to split two levels several times?
>>>>>>
>>>>>> Hello,
>>>>>>
>>>>>> Sorry, I've just realized that your data frame is named 'XXX', not
>>>>>> 'dat'. Change that and the rest should work:
>>>>>>
>>>>>>
>>>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
>>>>>> split(XXX, idx)
>>>>>>
>>>>>>
>>>>>> Rui Barradas
>>>>>>
>>>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
>>>>>>> Hello,
>>>>>>>
>>>>>>> Try the following.
>>>>>>>
>>>>>>>
>>>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
>>>>>>> split(dat, idx)
>>>>>>>
>>>>>>>
>>>>>>> Hope this helps,
>>>>>>>
>>>>>>> Rui Barradas
>>>>>>>
>>>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
>>>>>>>> Hi,
>>>>>>>>
>>>>>>>> I have a small problem with the function split() and would appreciate
>>>>>>>> your help.
>>>>>>>>
>>>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
>>>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
>>>>>>>> split the table always at the row where ?electrode1? starts again so
>>>>>>>> that I can export 7? individual dataframes (numbered ?dataframe1? to
>>>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
>>>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
>>>>>>>> I tried the split function with various setups:
>>>>>>>>
>>>>>>>> t <- as.factor(XXX$electrode)
>>>>>>>>
>>>>>>>> dataframeX <- split(XXX, f=(levels=t))
>>>>>>>>
>>>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
>>>>>>>>
>>>>>>>>
>>>>>>>> This is the table "XXX"
>>>>>>>>
>>>>>>>> electrode? ? length
>>>>>>>>
>>>>>>>> electrode1? ? 5.7
>>>>>>>> electrode1? ? 6.3
>>>>>>>> electrode1? ? 6.2
>>>>>>>> electrode2? ? 11.4
>>>>>>>> electrode2? ? 9.7
>>>>>>>> electrode1? ? 5.7
>>>>>>>> electrode1? ? 6.3
>>>>>>>> electrode1? ? 6.2
>>>>>>>> electrode3? ? 14.2
>>>>>>>> electrode3? ? 14.8
>>>>>>>> electrode3? ? 12.6
>>>>>>>> electrode1? ? 5.7
>>>>>>>> electrode1? ? 6.3
>>>>>>>> electrode1? ? 6.2
>>>>>>>> electrode4? ? 17.0
>>>>>>>> electrode4? ? 16.3
>>>>>>>> electrode4? ? 17.8
>>>>>>>> electrode4? ? 18.3
>>>>>>>> electrode4? ? 16.9
>>>>>>>> electrode4? ? 18.5
>>>>>>>> electrode1? ? ....
>>>>>>>> ....? ? ? ? ....
>>>>>>>> electrode5? ? ....
>>>>>>>> ....? ? ? ? ....
>>>>>>>> electrode1? ? ....
>>>>>>>> electrode6? ? ....
>>>>>>>> electrode1? ? ....
>>>>>>>> electrode7? ? ....
>>>>>>>> electrode1? ? ....
>>>>>>>> electrode8? ? ....
>>>>>>>>
>>>>>>>> ______________________________________________
>>>>>>>> R-help at r-project.org mailing list
>>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>>> PLEASE do read the posting guide
>>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>>>
>>>>>>>
>>>>>>> ______________________________________________
>>>>>>> R-help at r-project.org mailing list
>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>>>>> PLEASE do read the posting guide
>>>>>>> http://www.R-project.org/posting-guide.html
>>>>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>>>
>>>>
>>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From petr.pikal at precheza.cz  Fri Jul 26 14:58:58 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Jul 2013 12:58:58 +0000
Subject: [R] Maintaining data order in factanal with missing data
In-Reply-To: <000701ce89fa$c511f200$4f35d600$@genius.net.au>
References: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>
	<03afd01260fc4ba4ab892501a5be1d08@BLUPRD0113HT003.prod.exchangelabs.com>
	<000701ce89fa$c511f200$4f35d600$@genius.net.au>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FF48@SRVEXCHMBX.precheza.cz>

Hi

Well, the function init.dfs does nothing as all data frames created inside it does not propagate to global environment and there is nothing what the function returns.

Tha last line (when used outside a function) gives warnings but there is no sign of error.

When 

> head(ab.1.df)
  dmid   g5oab2      g53      g54      g55   g5ovb1
1    1 1.418932 1.805227 2.791152 3.624116 3.425586
2    2 2.293907 1.187830 1.611237 1.748526 3.816533
3    3 2.836536 2.679523 1.279639 2.674986 2.452395
4    4 1.872259 3.278359 1.785872 2.458315 1.146480
5    5 1.467195 1.180747 3.564127 3.007682 2.109506
6    6 3.098512 3.151974 3.969379 3.750571 1.497358
> head(ab.2.df)
  dmid   w2oab3      w22      w23      w24   w2ovb1
1    1 4.831362 5.522764 7.809366 6.969172 7.398385
2    2 6.706346 4.101742 1.434697 5.266775 5.357641
3    3 3.653806 2.666885 1.209326 5.125556 4.963374
4    4 7.221255 7.649152 6.540398 6.648506 2.576081
5    5 1.848023 5.044314 2.761881 3.307220 1.454234
6    6 7.606429 4.911766 2.034813 2.638573 2.818834
> head(ab.3.df)
  dmid   w3oab3   w3oab4   w3oab7   w3oab8   w3ovb1
1    1 5.835609 6.108220 6.587721 2.451461 2.785467
2    2 4.973198 1.196815 6.388056 1.110877 4.226463
3    3 3.800367 6.697287 5.235345 6.666829 6.319073
4    4 1.093141 1.477773 2.269252 3.194978 4.916342
5    5 1.975060 7.204516 4.825435 1.775874 3.484027
6    6 3.273361 2.243805 5.326547 5.720892 6.118723
>

> str(ab.1.fa)
List of 2
 $ rescaled.scores: Named num [1:154] 3.43 3.83 2.43 1.1 2.08 ...
  ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
 $ factor.loadings: Named num [1:5] -0.0106 -0.0227 -0.1093 -0.0912 0.9975
  ..- attr(*, "names")= chr [1:5] "g5oab2" "g53" "g54" "g55" ...
> str(ab.2.fa)
List of 2
 $ rescaled.scores: Named num [1:154] 6.34 5.24 5.3 1.91 2.16 ...
  ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
 $ factor.loadings: Named num [1:5] -0.2042 0.0063 -0.2287 -0.0119 0.7138
  ..- attr(*, "names")= chr [1:5] "w2oab3" "w22" "w23" "w24" ...
> str(ab.3.fa)
List of 2
 $ rescaled.scores: Named num [1:154] NaN NaN NaN NaN NaN NaN NaN NaN NaN NaN ...
  ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
 $ factor.loadings: Named num [1:5] -0.1172 0.0128 -0.0968 0.106 0.9975
  ..- attr(*, "names")= chr [1:5] "w3oab3" "w3oab4" "w3oab7" "w3oab8" ...

Anyway I have no idea what you consider wrong?

Regards
Petr



> -----Original Message-----
> From: Justin Delahunty [mailto:ACU at genius.net.au]
> Sent: Friday, July 26, 2013 2:22 PM
> To: PIKAL Petr; 'Justin Delahunty'; r-help at r-project.org
> Subject: RE: [R] Maintaining data order in factanal with missing data
> 
> Hi Petr,
> 
> Thanks for the quick response. Unfortunately I cannot share the data I
> am working with, however please find attached a suitable R workspace
> with generated data. It has the appropriate variable names, only the
> data has been changed.
> 
> The last function in the list (init.dfs()) I call to subset the overall
> data set into the three waves, then conduct the factor analysis on each
> (1 factor CFA); it's just in a function to ease re-typing in a new
> workspace.
> 
> 
> Thanks,
> 
> Justin
> 
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Friday, 26 July 2013 7:35 PM
> To: Justin Delahunty; r-help at r-project.org
> Subject: RE: [R] Maintaining data order in factanal with missing data
> 
> Hi
> 
> You provided functions, so far so good. But without data it would be
> quite difficult to understand what the functions do and where could be
> the issue.
> 
> I suspect combination of complete cases selection together with subset
> and factor behaviour. But I can be completely out of target too.
> 
> Petr
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > project.org] On Behalf Of s00123776 at myacu.edu.au
> > Sent: Friday, July 26, 2013 9:35 AM
> > To: r-help at r-project.org
> > Subject: [R] Maintaining data order in factanal with missing data
> >
> > Hi,
> >
> >
> >
> > I'm new to R, so sorry if this is a simple answer. I'm currently
> > trying to collapse some ordinal variables into a composite; the
> > program ideally should take a data frame as input, perform a factor
> > analysis, compute factor scores, sds, etc., and return the rescaled
> > scores and loadings. The difficulty I'm having is that my data set
> > contains a number of NA, which I am excluding from the analysis using
> > complete.cases(), and thus the incomplete cases are "skipped". These
> > functions are for a longitudinal data set with repeated waves of
> data,
> > so the final rescaled scores from each wave need to be saved as
> > variables grouped by a unique ID (DMID). The functions I'm trying to
> > implement are as follows:
> >
> >
> >
> > weighted.sd<-function(x,w){
> >
> >                                 sum.w<-sum(w)
> >
> >                                 sum.w2<-sum(w^2)
> >
> >                                 mean.w<-sum(x*w)/sum(w)
> >
> >
> > x.sd.w<-sqrt((sum.w/(sum.w^2-sum.w2))*sum(w*(x-mean.w)^2))
> >
> >                                 return(x.sd.w)
> >
> >                                 }
> >
> >
> >
> > re.scale<-function(f.scores, raw.data, loadings){
> >
> >
> > fz.scores<-(f.scores+mean(f.scores))/(sd(f.scores))
> >
> >
> > means<-apply(raw.data,1,weighted.mean,w=loadings)
> >
> >
> > sds<-apply(raw.data,1,weighted.sd,w=loadings)
> >
> >                                 grand.mean<-mean(means)
> >
> >                                 grand.sd<-mean(sds)
> >
> >
> > final.scores<-((fz.scores*grand.sd)+grand.mean)
> >
> >                                 return(final.scores)
> >
> >                                 }
> >
> >
> >
> > get.scores<-function(data){
> >
> >
> > fact<-
> > factanal(data[complete.cases(data),],factors=1,scores="regression")
> >
> >                                 f.scores<-fact$scores[,1]
> >
> >                                 f.loads<-fact$loadings[,1]
> >
> >                                 rescaled.scores<-re.scale(f.scores,
> > data[complete.cases(data),], f.loads)
> >
> >                                 output.list<-list(rescaled.scores,
> > f.loads)
> >
> >                                 names(output.list)<-
> > c("rescaled.scores",
> > "factor.loadings")
> >
> >                                 return(output.list)
> >
> >                                 }
> >
> >
> >
> > init.dfs<-function(){
> >
> >
> > ab.1.df<-subset(ab.df,,select=c(dmid,g5oab2:g5ovb1))
> >
> >
> > ab.2.df<-subset(ab.df,,select=c(dmid,w2oab3:w2ovb1))
> >
> >                                 ab.3.df<-subset(ab.df,,select=c(dmid,
> > w3oab3, w3oab4, w3oab7, w3oab8, w3ovb1))
> >
> >
> >
> >                                 ab.1.fa<-get.scores(ab.1.df[-1])
> >
> >                                 ab.2.fa<-get.scores(ab.2.df[-1])
> >
> >                                 ab.3.fa<-get.scores(ab.3.df[-1])
> >
> >
> >                                 }
> >
> >
> >
> > Thanks for your help,
> >
> >
> >
> > Justin
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-
> > guide.html and provide commented, minimal, self-contained,
> > reproducible code.
> 


From tomhopper at gmail.com  Fri Jul 26 15:18:45 2013
From: tomhopper at gmail.com (Tom Hopper)
Date: Fri, 26 Jul 2013 09:18:45 -0400
Subject: [R] modeest with non-numeric data?
Message-ID: <CAJ_8u+LVtZx42BZ9TusFYP+sYG0oL_-M7Q7w3Pq1srpPPzfXVw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/6a6d89b0/attachment.pl>

From smartpink111 at yahoo.com  Fri Jul 26 15:26:32 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 06:26:32 -0700 (PDT)
Subject: [R] How to split two levels several times?
In-Reply-To: <trinity-0aef6fe9-ceb7-4b5c-bbc6-2949bc354692-1374833259262@3capp-gmx-bs52>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>
	<trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>,
	<51F1742C.7070405@sapo.pt>
	<trinity-0aef6fe9-ceb7-4b5c-bbc6-2949bc354692-1374833259262@3capp-gmx-bs52>
Message-ID: <1374845192.55351.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi Dennis,
I guess in this case, instead of "Eletrode1" occuring 3 times, it is "Electrode4" exists only 6 times.? If that is the situation:
just change:
XXX: data
rl<-rle(as.character(XXX$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode4" & (rl$lengths[i]%/%6>1)) rep(6,rl$lengths[i]%/%6) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX[seq(vec2[i],max(x1)),]})
res
[[1]]
?? electrode length
1 electrode1??? 206
2 electrode1??? 194
3 electrode1??? 182
4 electrode1??? 172
5 electrode1??? 169
6 electrode2???? 82
7 electrode2???? 78
8 electrode2???? 70
9 electrode2???? 58

[[2]]
??? electrode length
10 electrode1??? 206
11 electrode1??? 194
12 electrode1??? 182
13 electrode1??? 172
14 electrode1??? 169
15 electrode3??? 260
16 electrode3??? 176
17 electrode3??? 137

[[3]]
??? electrode length
18 electrode1??? 206
19 electrode1??? 194
20 electrode1??? 182
21 electrode1??? 172
22 electrode1??? 169
23 electrode4???? 86
24 electrode4???? 66
25 electrode4???? 64
26 electrode4???? 52
27 electrode4???? 27
28 electrode4???? 26

[[4]]
??? electrode length
29 electrode2???? 82
30 electrode2???? 78
31 electrode2???? 70
32 electrode2???? 58
33 electrode1??? 206
34 electrode1??? 194
35 electrode1??? 182
36 electrode1??? 172
37 electrode1??? 169

[[5]]
??? electrode length
38 electrode2???? 82
39 electrode2???? 78
40 electrode2???? 70
41 electrode2???? 58
42 electrode3??? 260
43 electrode3??? 176
44 electrode3??? 137

[[6]]
??? electrode length
45 electrode2???? 82
46 electrode2???? 78
47 electrode2???? 70
48 electrode2???? 58
49 electrode4???? 86
50 electrode4???? 66
51 electrode4???? 64
52 electrode4???? 52
53 electrode4???? 27
54 electrode4???? 26

[[7]]
??? electrode length
55 electrode3??? 260
56 electrode3??? 176
57 electrode3??? 137
58 electrode1??? 206
59 electrode1??? 194
60 electrode1??? 182
61 electrode1??? 172
62 electrode1??? 169

[[8]]
??? electrode length
63 electrode3??? 260
64 electrode3??? 176
65 electrode3??? 137
66 electrode2???? 82
67 electrode2???? 78
68 electrode2???? 70
69 electrode2???? 58

[[9]]
??? electrode length
70 electrode3??? 260
71 electrode3??? 176
72 electrode3??? 137
73 electrode4???? 86
74 electrode4???? 66
75 electrode4???? 64
76 electrode4???? 52
77 electrode4???? 27
78 electrode4???? 26

[[10]]
??? electrode length
79 electrode4???? 86
80 electrode4???? 66
81 electrode4???? 64
82 electrode4???? 52
83 electrode4???? 27
84 electrode4???? 26
85 electrode1??? 206
86 electrode1??? 194
87 electrode1??? 182
88 electrode1??? 172
89 electrode1??? 169

[[11]]
??? electrode length
90 electrode4???? 86
91 electrode4???? 66
92 electrode4???? 64
93 electrode4???? 52
94 electrode4???? 27
95 electrode4???? 26
96 electrode2???? 82
97 electrode2???? 78
98 electrode2???? 70
99 electrode2???? 58

[[12]]
???? electrode length
100 electrode4???? 86
101 electrode4???? 66
102 electrode4???? 64
103 electrode4???? 52
104 electrode4???? 27
105 electrode4???? 26
106 electrode3??? 260
107 electrode3??? 176
108 electrode3??? 137


A.K.




----- Original Message -----
From: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
Cc: 
Sent: Friday, July 26, 2013 6:07 AM
Subject: Re: [R] How to split two levels several times?

Hi Rui & Arun,
really thanks for investing so much time to deal with this problem! The code works now for this specific example. However it is not generally robust for slightly different situations. For instance it cannot correctly handle a slight variation of the table where I have again 4 types of electrodes of certain lengths. Electrode4 exists only 6 times. At the transition of the combinations 3-4 and 4-1 there are 12 times electrode4 which stick together in the output $`9`. This leads to wrong splittings thereafter. Sorry for asking such tricky questions.

New table XXX

electrode??? length
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode3??? 260
electrode3??? 176
electrode3??? 137





> Gesendet: Donnerstag, 25. Juli 2013 um 20:53 Uhr
> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> An: dennis1991 at gmx.net
> Cc: r-help at r-project.org
> Betreff: Re: Aw: Re:? Re:? Re: [R] How to split two levels several times?
>
> Hello,
>
> I think the following does what you want. (I don't know if it makes much
> sense but it works.)
>
>
>
> lens <- rle(as.character(XXX$electrode))$lengths
> m <- length(lens) %/% 2
> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> if(length(lens) %% 2 != 0){
> ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
> ??? sp_idx <- split(idx, idx)
> ??? n <- length(sp_idx[[m]])
> ??? if(n %/% 2 < length(sp_idx[[m + 1]]))
> ??? ??? sp_idx[[m]][(n %/% 2 + 1):n] <- sp_idx[[m + 1]][1]
> ??? else
> ??? ??? sp_idx[[m]][(n - length(sp_idx[[m + 1]]) + 1):n] <-? sp_idx[[m + 1]][1]
> ??? idx <- unlist(sp_idx)
> }
>
> sp <- split(XXX, idx)
> sp
>
>
>
> Rui Barradas
>
> Em 25-07-2013 11:40, dennis1991 at gmx.net escreveu:
> > Hi Rui
> > once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.
> >
> > So idx should not return
> >?  [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4
> >
> > but instead 6 times number 4 at the end
> >?  [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4
> >
> > Do you have any solution?
> >
> >
> >> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
> >> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >> An: dennis1991 at gmx.net
> >> Cc: r-help at r-project.org
> >> Betreff: Re: Aw: Re:? Re: [R] How to split two levels several times?
> >>
> >> Hello,
> >>
> >> As for the first question, note that in the case you describe, the
> >> resulting list of df's will not be a split of the original, there will
> >> be a duplication in the final 4-1 and 1-3. The following is a hack but
> >> will do it.
> >>
> >>
> >> lens <- rle(as.character(XXX$electrode))$lengths
> >> m <- length(lens) %/% 2
> >> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> >> if(length(lens) %% 2 != 0)
> >> ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
> >>
> >> sp <- split(XXX, idx)
> >>
> >> if(length(lens) %% 2 != 0){
> >> ??? idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
> >> ??? sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
> >> }
> >> sp
> >>
> >>
> >> As for the second question, I'm not understanding it, can you post
> >> sample output?
> >>
> >> Rui Barradas
> >>
> >> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
> >>> Hi Rui
> >>> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
> >>>
> >>> lens <- rle(as.character(XXX$electrode))$lengths
> >>> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
> >>> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
> >>> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
> >>>
> >>> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
> >>>
> >>>
> >>> This is the table "XXX"
> >>>
> >>> electrode length
> >>>
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode3 14.2
> >>> electrode3 14.8
> >>> electrode3 12.6
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode4 17.0
> >>> electrode4 16.3
> >>> electrode4 17.8
> >>> electrode4 18.3
> >>> electrode4 16.9
> >>> electrode4 18.5
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode3 14.2
> >>> electrode3 14.8
> >>> electrode3 12.6
> >>>
> >>>
> >>> This is a simplified table XX
> >>>
> >>> electrode1
> >>> electrode2
> >>> electrode1
> >>> electrode3
> >>> electrode1
> >>> electrode4
> >>> electrode2
> >>> electrode1
> >>> electrode2
> >>> electrode3
> >>> electrode2
> >>> electrode4
> >>> electrode3
> >>> electrode1
> >>> electrode3
> >>> electrode2
> >>> electrode3
> >>> electrode4
> >>> electrode4
> >>> electrode1
> >>> electrode4
> >>> electrode2
> >>> electrode4
> >>> electrode3
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
> >>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >>>> An: dennis1991 at gmx.net
> >>>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
> >>>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
> >>>>
> >>>> Hello,
> >>>>
> >>>> It's better if you keep this on the list, the odds of getting more and
> >>>> better answers are greater.
> >>>>
> >>>> As for your new question, try the following.
> >>>>
> >>>>
> >>>> lens <- rle(as.character(XXX$electrode))$lengths
> >>>> m <- length(lens) %/% 2
> >>>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> >>>> split(XXX, idx)
> >>>>
> >>>>
> >>>> Hope this helps,
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
> >>>>> Hi
> >>>>> this type of splitting works for my specific example. Thanks for your help.
> >>>>>
> >>>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,? electrode3-electrode2,? electrode4-electrode1. How should I split this?
> >>>>>
> >>>>>
> >>>>> This is the table "XXX"
> >>>>>
> >>>>> electrode length
> >>>>>
> >>>>> electrode1 5.7
> >>>>> electrode1 6.3
> >>>>> electrode1 6.2
> >>>>> electrode2 11.4
> >>>>> electrode2 9.7
> >>>>> electrode3 14.2
> >>>>> electrode3 14.8
> >>>>> electrode3 12.6
> >>>>> electrode2 11.4
> >>>>> electrode2 9.7
> >>>>> electrode4 17.0
> >>>>> electrode4 16.3
> >>>>> electrode4 17.8
> >>>>> electrode4 18.3
> >>>>> electrode4 16.9
> >>>>> electrode4 18.5
> >>>>> electrode1 5.7
> >>>>> electrode1 6.3
> >>>>> electrode1 6.2
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
> >>>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >>>>>> An: dennis1991 at gmx.net
> >>>>>> Cc: r-help at r-project.org
> >>>>>> Betreff: Re: [R] How to split two levels several times?
> >>>>>>
> >>>>>> Hello,
> >>>>>>
> >>>>>> Sorry, I've just realized that your data frame is named 'XXX', not
> >>>>>> 'dat'. Change that and the rest should work:
> >>>>>>
> >>>>>>
> >>>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
> >>>>>> split(XXX, idx)
> >>>>>>
> >>>>>>
> >>>>>> Rui Barradas
> >>>>>>
> >>>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
> >>>>>>> Hello,
> >>>>>>>
> >>>>>>> Try the following.
> >>>>>>>
> >>>>>>>
> >>>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
> >>>>>>> split(dat, idx)
> >>>>>>>
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
> >>>>>>>> Hi,
> >>>>>>>>
> >>>>>>>> I have a small problem with the function split() and would appreciate
> >>>>>>>> your help.
> >>>>>>>>
> >>>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
> >>>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
> >>>>>>>> split the table always at the row where ?electrode1? starts again so
> >>>>>>>> that I can export 7? individual dataframes (numbered ?dataframe1? to
> >>>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
> >>>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
> >>>>>>>> I tried the split function with various setups:
> >>>>>>>>
> >>>>>>>> t <- as.factor(XXX$electrode)
> >>>>>>>>
> >>>>>>>> dataframeX <- split(XXX, f=(levels=t))
> >>>>>>>>
> >>>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> This is the table "XXX"
> >>>>>>>>
> >>>>>>>> electrode? ? length
> >>>>>>>>
> >>>>>>>> electrode1? ? 5.7
> >>>>>>>> electrode1? ? 6.3
> >>>>>>>> electrode1? ? 6.2
> >>>>>>>> electrode2? ? 11.4
> >>>>>>>> electrode2? ? 9.7
> >>>>>>>> electrode1? ? 5.7
> >>>>>>>> electrode1? ? 6.3
> >>>>>>>> electrode1? ? 6.2
> >>>>>>>> electrode3? ? 14.2
> >>>>>>>> electrode3? ? 14.8
> >>>>>>>> electrode3? ? 12.6
> >>>>>>>> electrode1? ? 5.7
> >>>>>>>> electrode1? ? 6.3
> >>>>>>>> electrode1? ? 6.2
> >>>>>>>> electrode4? ? 17.0
> >>>>>>>> electrode4? ? 16.3
> >>>>>>>> electrode4? ? 17.8
> >>>>>>>> electrode4? ? 18.3
> >>>>>>>> electrode4? ? 16.9
> >>>>>>>> electrode4? ? 18.5
> >>>>>>>> electrode1? ? ....
> >>>>>>>> ....? ? ? ? ....
> >>>>>>>> electrode5? ? ....
> >>>>>>>> ....? ? ? ? ....
> >>>>>>>> electrode1? ? ....
> >>>>>>>> electrode6? ? ....
> >>>>>>>> electrode1? ? ....
> >>>>>>>> electrode7? ? ....
> >>>>>>>> electrode1? ? ....
> >>>>>>>> electrode8? ? ....
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>>
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>
> >>
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Fri Jul 26 15:43:10 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 06:43:10 -0700 (PDT)
Subject: [R] How to split two levels several times?
In-Reply-To: <1374845192.55351.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>
	<trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>,
	<51F1742C.7070405@sapo.pt>
	<trinity-0aef6fe9-ceb7-4b5c-bbc6-2949bc354692-1374833259262@3capp-gmx-bs52>
	<1374845192.55351.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <1374846190.47754.YahooMailNeo@web142603.mail.bf1.yahoo.com>

It would be better to wrap it in a function.

fun1<- function(x,colName,N,value){
rl<- rle(as.character(x[,colName]))
dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]==value & (rl$lengths[i]%/%N>1)) rep(N,rl$lengths[i]%/%N) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; x[seq(vec2[i],max(x1)),]})
res
}

fun1(XXX,"electrode",6,"electrode4")
#Using previous dataset XXX, XXX1, XXX2
fun1(XXX,"electrode",3,"electrode1")

fun1(XXX1,"electrode",3,"electrode1")

fun1(XXX2,"electrode",3,"electrode1")
A.K.

----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
Cc: R help <r-help at r-project.org>; Rui Barradas <ruipbarradas at sapo.pt>
Sent: Friday, July 26, 2013 9:26 AM
Subject: Re: [R] How to split two levels several times?



Hi Dennis,
I guess in this case, instead of "Eletrode1" occuring 3 times, it is "Electrode4" exists only 6 times.? If that is the situation:
just change:
XXX: data
rl<-rle(as.character(XXX$electrode))
?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode4" & (rl$lengths[i]%/%6>1)) rep(6,rl$lengths[i]%/%6) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
vec1<-sapply(lst1,max)
vec2<-c(1,vec1[-length(vec1)]+1)
res<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX[seq(vec2[i],max(x1)),]})
res
[[1]]
?? electrode length
1 electrode1??? 206
2 electrode1??? 194
3 electrode1??? 182
4 electrode1??? 172
5 electrode1??? 169
6 electrode2???? 82
7 electrode2???? 78
8 electrode2???? 70
9 electrode2???? 58

[[2]]
??? electrode length
10 electrode1??? 206
11 electrode1??? 194
12 electrode1??? 182
13 electrode1??? 172
14 electrode1??? 169
15 electrode3??? 260
16 electrode3??? 176
17 electrode3??? 137

[[3]]
??? electrode length
18 electrode1??? 206
19 electrode1??? 194
20 electrode1??? 182
21 electrode1??? 172
22 electrode1??? 169
23 electrode4???? 86
24 electrode4???? 66
25 electrode4???? 64
26 electrode4???? 52
27 electrode4???? 27
28 electrode4???? 26

[[4]]
??? electrode length
29 electrode2???? 82
30 electrode2???? 78
31 electrode2???? 70
32 electrode2???? 58
33 electrode1??? 206
34 electrode1??? 194
35 electrode1??? 182
36 electrode1??? 172
37 electrode1??? 169

[[5]]
??? electrode length
38 electrode2???? 82
39 electrode2???? 78
40 electrode2???? 70
41 electrode2???? 58
42 electrode3??? 260
43 electrode3??? 176
44 electrode3??? 137

[[6]]
??? electrode length
45 electrode2???? 82
46 electrode2???? 78
47 electrode2???? 70
48 electrode2???? 58
49 electrode4???? 86
50 electrode4???? 66
51 electrode4???? 64
52 electrode4???? 52
53 electrode4???? 27
54 electrode4???? 26

[[7]]
??? electrode length
55 electrode3??? 260
56 electrode3??? 176
57 electrode3??? 137
58 electrode1??? 206
59 electrode1??? 194
60 electrode1??? 182
61 electrode1??? 172
62 electrode1??? 169

[[8]]
??? electrode length
63 electrode3??? 260
64 electrode3??? 176
65 electrode3??? 137
66 electrode2???? 82
67 electrode2???? 78
68 electrode2???? 70
69 electrode2???? 58

[[9]]
??? electrode length
70 electrode3??? 260
71 electrode3??? 176
72 electrode3??? 137
73 electrode4???? 86
74 electrode4???? 66
75 electrode4???? 64
76 electrode4???? 52
77 electrode4???? 27
78 electrode4???? 26

[[10]]
??? electrode length
79 electrode4???? 86
80 electrode4???? 66
81 electrode4???? 64
82 electrode4???? 52
83 electrode4???? 27
84 electrode4???? 26
85 electrode1??? 206
86 electrode1??? 194
87 electrode1??? 182
88 electrode1??? 172
89 electrode1??? 169

[[11]]
??? electrode length
90 electrode4???? 86
91 electrode4???? 66
92 electrode4???? 64
93 electrode4???? 52
94 electrode4???? 27
95 electrode4???? 26
96 electrode2???? 82
97 electrode2???? 78
98 electrode2???? 70
99 electrode2???? 58

[[12]]
???? electrode length
100 electrode4???? 86
101 electrode4???? 66
102 electrode4???? 64
103 electrode4???? 52
104 electrode4???? 27
105 electrode4???? 26
106 electrode3??? 260
107 electrode3??? 176
108 electrode3??? 137


A.K.




----- Original Message -----
From: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
Cc: 
Sent: Friday, July 26, 2013 6:07 AM
Subject: Re: [R] How to split two levels several times?

Hi Rui & Arun,
really thanks for investing so much time to deal with this problem! The code works now for this specific example. However it is not generally robust for slightly different situations. For instance it cannot correctly handle a slight variation of the table where I have again 4 types of electrodes of certain lengths. Electrode4 exists only 6 times. At the transition of the combinations 3-4 and 4-1 there are 12 times electrode4 which stick together in the output $`9`. This leads to wrong splittings thereafter. Sorry for asking such tricky questions.

New table XXX

electrode??? length
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode3??? 260
electrode3??? 176
electrode3??? 137
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode1??? 206
electrode1??? 194
electrode1??? 182
electrode1??? 172
electrode1??? 169
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode2??? 82
electrode2??? 78
electrode2??? 70
electrode2??? 58
electrode4??? 86
electrode4??? 66
electrode4??? 64
electrode4??? 52
electrode4??? 27
electrode4??? 26
electrode3??? 260
electrode3??? 176
electrode3??? 137





> Gesendet: Donnerstag, 25. Juli 2013 um 20:53 Uhr
> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> An: dennis1991 at gmx.net
> Cc: r-help at r-project.org
> Betreff: Re: Aw: Re:? Re:? Re: [R] How to split two levels several times?
>
> Hello,
>
> I think the following does what you want. (I don't know if it makes much
> sense but it works.)
>
>
>
> lens <- rle(as.character(XXX$electrode))$lengths
> m <- length(lens) %/% 2
> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> if(length(lens) %% 2 != 0){
> ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
> ??? sp_idx <- split(idx, idx)
> ??? n <- length(sp_idx[[m]])
> ??? if(n %/% 2 < length(sp_idx[[m + 1]]))
> ??? ??? sp_idx[[m]][(n %/% 2 + 1):n] <- sp_idx[[m + 1]][1]
> ??? else
> ??? ??? sp_idx[[m]][(n - length(sp_idx[[m + 1]]) + 1):n] <-? sp_idx[[m + 1]][1]
> ??? idx <- unlist(sp_idx)
> }
>
> sp <- split(XXX, idx)
> sp
>
>
>
> Rui Barradas
>
> Em 25-07-2013 11:40, dennis1991 at gmx.net escreveu:
> > Hi Rui
> > once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.
> >
> > So idx should not return
> >?? [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4
> >
> > but instead 6 times number 4 at the end
> >?? [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4
> >
> > Do you have any solution?
> >
> >
> >> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
> >> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >> An: dennis1991 at gmx.net
> >> Cc: r-help at r-project.org
> >> Betreff: Re: Aw: Re:? Re: [R] How to split two levels several times?
> >>
> >> Hello,
> >>
> >> As for the first question, note that in the case you describe, the
> >> resulting list of df's will not be a split of the original, there will
> >> be a duplication in the final 4-1 and 1-3. The following is a hack but
> >> will do it.
> >>
> >>
> >> lens <- rle(as.character(XXX$electrode))$lengths
> >> m <- length(lens) %/% 2
> >> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> >> if(length(lens) %% 2 != 0)
> >> ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
> >>
> >> sp <- split(XXX, idx)
> >>
> >> if(length(lens) %% 2 != 0){
> >> ??? idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
> >> ??? sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
> >> }
> >> sp
> >>
> >>
> >> As for the second question, I'm not understanding it, can you post
> >> sample output?
> >>
> >> Rui Barradas
> >>
> >> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
> >>> Hi Rui
> >>> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
> >>>
> >>> lens <- rle(as.character(XXX$electrode))$lengths
> >>> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
> >>> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
> >>> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
> >>>
> >>> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
> >>>
> >>>
> >>> This is the table "XXX"
> >>>
> >>> electrode length
> >>>
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode3 14.2
> >>> electrode3 14.8
> >>> electrode3 12.6
> >>> electrode2 11.4
> >>> electrode2 9.7
> >>> electrode4 17.0
> >>> electrode4 16.3
> >>> electrode4 17.8
> >>> electrode4 18.3
> >>> electrode4 16.9
> >>> electrode4 18.5
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode1 5.7
> >>> electrode1 6.3
> >>> electrode1 6.2
> >>> electrode3 14.2
> >>> electrode3 14.8
> >>> electrode3 12.6
> >>>
> >>>
> >>> This is a simplified table XX
> >>>
> >>> electrode1
> >>> electrode2
> >>> electrode1
> >>> electrode3
> >>> electrode1
> >>> electrode4
> >>> electrode2
> >>> electrode1
> >>> electrode2
> >>> electrode3
> >>> electrode2
> >>> electrode4
> >>> electrode3
> >>> electrode1
> >>> electrode3
> >>> electrode2
> >>> electrode3
> >>> electrode4
> >>> electrode4
> >>> electrode1
> >>> electrode4
> >>> electrode2
> >>> electrode4
> >>> electrode3
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>
> >>>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
> >>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >>>> An: dennis1991 at gmx.net
> >>>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
> >>>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
> >>>>
> >>>> Hello,
> >>>>
> >>>> It's better if you keep this on the list, the odds of getting more and
> >>>> better answers are greater.
> >>>>
> >>>> As for your new question, try the following.
> >>>>
> >>>>
> >>>> lens <- rle(as.character(XXX$electrode))$lengths
> >>>> m <- length(lens) %/% 2
> >>>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> >>>> split(XXX, idx)
> >>>>
> >>>>
> >>>> Hope this helps,
> >>>>
> >>>> Rui Barradas
> >>>>
> >>>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
> >>>>> Hi
> >>>>> this type of splitting works for my specific example. Thanks for your help.
> >>>>>
> >>>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,? electrode3-electrode2,? electrode4-electrode1. How should I split this?
> >>>>>
> >>>>>
> >>>>> This is the table "XXX"
> >>>>>
> >>>>> electrode length
> >>>>>
> >>>>> electrode1 5.7
> >>>>> electrode1 6.3
> >>>>> electrode1 6.2
> >>>>> electrode2 11.4
> >>>>> electrode2 9.7
> >>>>> electrode3 14.2
> >>>>> electrode3 14.8
> >>>>> electrode3 12.6
> >>>>> electrode2 11.4
> >>>>> electrode2 9.7
> >>>>> electrode4 17.0
> >>>>> electrode4 16.3
> >>>>> electrode4 17.8
> >>>>> electrode4 18.3
> >>>>> electrode4 16.9
> >>>>> electrode4 18.5
> >>>>> electrode1 5.7
> >>>>> electrode1 6.3
> >>>>> electrode1 6.2
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>
> >>>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
> >>>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> >>>>>> An: dennis1991 at gmx.net
> >>>>>> Cc: r-help at r-project.org
> >>>>>> Betreff: Re: [R] How to split two levels several times?
> >>>>>>
> >>>>>> Hello,
> >>>>>>
> >>>>>> Sorry, I've just realized that your data frame is named 'XXX', not
> >>>>>> 'dat'. Change that and the rest should work:
> >>>>>>
> >>>>>>
> >>>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
> >>>>>> split(XXX, idx)
> >>>>>>
> >>>>>>
> >>>>>> Rui Barradas
> >>>>>>
> >>>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
> >>>>>>> Hello,
> >>>>>>>
> >>>>>>> Try the following.
> >>>>>>>
> >>>>>>>
> >>>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
> >>>>>>> split(dat, idx)
> >>>>>>>
> >>>>>>>
> >>>>>>> Hope this helps,
> >>>>>>>
> >>>>>>> Rui Barradas
> >>>>>>>
> >>>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
> >>>>>>>> Hi,
> >>>>>>>>
> >>>>>>>> I have a small problem with the function split() and would appreciate
> >>>>>>>> your help.
> >>>>>>>>
> >>>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
> >>>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
> >>>>>>>> split the table always at the row where ?electrode1? starts again so
> >>>>>>>> that I can export 7? individual dataframes (numbered ?dataframe1? to
> >>>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
> >>>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
> >>>>>>>> I tried the split function with various setups:
> >>>>>>>>
> >>>>>>>> t <- as.factor(XXX$electrode)
> >>>>>>>>
> >>>>>>>> dataframeX <- split(XXX, f=(levels=t))
> >>>>>>>>
> >>>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
> >>>>>>>>
> >>>>>>>>
> >>>>>>>> This is the table "XXX"
> >>>>>>>>
> >>>>>>>> electrode? ? length
> >>>>>>>>
> >>>>>>>> electrode1? ? 5.7
> >>>>>>>> electrode1? ? 6.3
> >>>>>>>> electrode1? ? 6.2
> >>>>>>>> electrode2? ? 11.4
> >>>>>>>> electrode2? ? 9.7
> >>>>>>>> electrode1? ? 5.7
> >>>>>>>> electrode1? ? 6.3
> >>>>>>>> electrode1? ? 6.2
> >>>>>>>> electrode3? ? 14.2
> >>>>>>>> electrode3? ? 14.8
> >>>>>>>> electrode3? ? 12.6
> >>>>>>>> electrode1? ? 5.7
> >>>>>>>> electrode1? ? 6.3
> >>>>>>>> electrode1? ? 6.2
> >>>>>>>> electrode4? ? 17.0
> >>>>>>>> electrode4? ? 16.3
> >>>>>>>> electrode4? ? 17.8
> >>>>>>>> electrode4? ? 18.3
> >>>>>>>> electrode4? ? 16.9
> >>>>>>>> electrode4? ? 18.5
> >>>>>>>> electrode1? ? ....
> >>>>>>>> ....? ? ? ? ....
> >>>>>>>> electrode5? ? ....
> >>>>>>>> ....? ? ? ? ....
> >>>>>>>> electrode1? ? ....
> >>>>>>>> electrode6? ? ....
> >>>>>>>> electrode1? ? ....
> >>>>>>>> electrode7? ? ....
> >>>>>>>> electrode1? ? ....
> >>>>>>>> electrode8? ? ....
> >>>>>>>>
> >>>>>>>> ______________________________________________
> >>>>>>>> R-help at r-project.org mailing list
> >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>>> PLEASE do read the posting guide
> >>>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>>>
> >>>>>>>
> >>>>>>> ______________________________________________
> >>>>>>> R-help at r-project.org mailing list
> >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> >>>>>>> PLEASE do read the posting guide
> >>>>>>> http://www.R-project.org/posting-guide.html
> >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> >>>>>>
> >>>>
> >>
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Fri Jul 26 15:46:36 2013
From: jrkrideau at inbox.com (John Kane)
Date: Fri, 26 Jul 2013 05:46:36 -0800
Subject: [R] help on carrying forward several vectors of rownames
In-Reply-To: <CAGRQPxHjbnmXrOwRWZeOmBUW7EvgaN1sk8n1fsVS0g2-whFPtA@mail.gmail.com>
Message-ID: <7DAA04CD00A.000002E3jrkrideau@inbox.com>

Can you supply some code and data? At the moment the question in not clear, or not expressed in R terminology.  Maybe I'm just not awake yet but 
"I tried to insert these vectors as a list, e.g. row.names=c(1,4), from the excel file"
does not seem to make any sense at all probably because 'list' has a special meaning in R and I don't think that is what you mean. if it is, my appologies.


Perhaps have a look at
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: theobroma22 at gmail.com
> Sent: Thu, 25 Jul 2013 22:00:32 -0700
> To: r-help at r-project.org
> Subject: [R] help on carrying forward several vectors of rownames
> 
> Dear reader,
> I'm trying to use multiple vectors as rownames for the read.table
> function.
> I tried to insert these vectors as a list, e.g. row.names=c(1,4), from
> the
> excel file. I tried other ways, as if the argument only took continuous
> tab
> separated
> columns, e.g. row.names=c(1:4). But, this also did not work.
> Is there a solution to this problem?
> Regards,
> --
> Franklin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From ACU at genius.net.au  Fri Jul 26 14:22:16 2013
From: ACU at genius.net.au (Justin Delahunty)
Date: Fri, 26 Jul 2013 22:22:16 +1000
Subject: [R] Maintaining data order in factanal with missing data
In-Reply-To: <03afd01260fc4ba4ab892501a5be1d08@BLUPRD0113HT003.prod.exchangelabs.com>
References: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>
	<03afd01260fc4ba4ab892501a5be1d08@BLUPRD0113HT003.prod.exchangelabs.com>
Message-ID: <000701ce89fa$c511f200$4f35d600$@genius.net.au>

Hi Petr,

Thanks for the quick response. Unfortunately I cannot share the data I am
working with, however please find attached a suitable R workspace with
generated data. It has the appropriate variable names, only the data has
been changed.

The last function in the list (init.dfs()) I call to subset the overall data
set into the three waves, then conduct the factor analysis on each (1 factor
CFA); it's just in a function to ease re-typing in a new workspace.


Thanks,

Justin

-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: Friday, 26 July 2013 7:35 PM
To: Justin Delahunty; r-help at r-project.org
Subject: RE: [R] Maintaining data order in factanal with missing data

Hi

You provided functions, so far so good. But without data it would be quite
difficult to understand what the functions do and where could be the issue.

I suspect combination of complete cases selection together with subset and
factor behaviour. But I can be completely out of target too.

Petr

> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r- 
> project.org] On Behalf Of s00123776 at myacu.edu.au
> Sent: Friday, July 26, 2013 9:35 AM
> To: r-help at r-project.org
> Subject: [R] Maintaining data order in factanal with missing data
> 
> Hi,
> 
> 
> 
> I'm new to R, so sorry if this is a simple answer. I'm currently 
> trying to collapse some ordinal variables into a composite; the 
> program ideally should take a data frame as input, perform a factor 
> analysis, compute factor scores, sds, etc., and return the rescaled 
> scores and loadings. The difficulty I'm having is that my data set 
> contains a number of NA, which I am excluding from the analysis using 
> complete.cases(), and thus the incomplete cases are "skipped". These 
> functions are for a longitudinal data set with repeated waves of data, 
> so the final rescaled scores from each wave need to be saved as 
> variables grouped by a unique ID (DMID). The functions I'm trying to 
> implement are as follows:
> 
> 
> 
> weighted.sd<-function(x,w){
> 
>                                 sum.w<-sum(w)
> 
>                                 sum.w2<-sum(w^2)
> 
>                                 mean.w<-sum(x*w)/sum(w)
> 
> 
> x.sd.w<-sqrt((sum.w/(sum.w^2-sum.w2))*sum(w*(x-mean.w)^2))
> 
>                                 return(x.sd.w)
> 
>                                 }
> 
> 
> 
> re.scale<-function(f.scores, raw.data, loadings){
> 
> 
> fz.scores<-(f.scores+mean(f.scores))/(sd(f.scores))
> 
> 
> means<-apply(raw.data,1,weighted.mean,w=loadings)
> 
> 
> sds<-apply(raw.data,1,weighted.sd,w=loadings)
> 
>                                 grand.mean<-mean(means)
> 
>                                 grand.sd<-mean(sds)
> 
> 
> final.scores<-((fz.scores*grand.sd)+grand.mean)
> 
>                                 return(final.scores)
> 
>                                 }
> 
> 
> 
> get.scores<-function(data){
> 
> 
> fact<-
> factanal(data[complete.cases(data),],factors=1,scores="regression")
> 
>                                 f.scores<-fact$scores[,1]
> 
>                                 f.loads<-fact$loadings[,1]
> 
>                                 rescaled.scores<-re.scale(f.scores,
> data[complete.cases(data),], f.loads)
> 
>                                 output.list<-list(rescaled.scores,
> f.loads)
> 
>                                 names(output.list)<- 
> c("rescaled.scores",
> "factor.loadings")
> 
>                                 return(output.list)
> 
>                                 }
> 
> 
> 
> init.dfs<-function(){
> 
> 
> ab.1.df<-subset(ab.df,,select=c(dmid,g5oab2:g5ovb1))
> 
> 
> ab.2.df<-subset(ab.df,,select=c(dmid,w2oab3:w2ovb1))
> 
>                                 ab.3.df<-subset(ab.df,,select=c(dmid,
> w3oab3, w3oab4, w3oab7, w3oab8, w3ovb1))
> 
> 
> 
>                                 ab.1.fa<-get.scores(ab.1.df[-1])
> 
>                                 ab.2.fa<-get.scores(ab.2.df[-1])
> 
>                                 ab.3.fa<-get.scores(ab.3.df[-1])
> 
> 
>                                 }
> 
> 
> 
> Thanks for your help,
> 
> 
> 
> Justin
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting- 
> guide.html and provide commented, minimal, self-contained, 
> reproducible code.



From ACU at genius.net.au  Fri Jul 26 15:33:35 2013
From: ACU at genius.net.au (Justin Delahunty)
Date: Fri, 26 Jul 2013 23:33:35 +1000
Subject: [R] Maintaining data order in factanal with missing data
In-Reply-To: <9bdd72cc4fd046faa91b3274d2eb8a64@BLUPRD0113HT004.prod.exchangelabs.com>
References: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>
	<03afd01260fc4ba4ab892501a5be1d08@BLUPRD0113HT003.prod.exchangelabs.com>
	<000701ce89fa$c511f200$4f35d600$@genius.net.au>
	<9bdd72cc4fd046faa91b3274d2eb8a64@BLUPRD0113HT004.prod.exchangelabs.com>
Message-ID: <001901ce8a04$bbbfe220$333fa660$@genius.net.au>

Hi Petr,

So sorry, I accidentally attached the complete data set rather than the one
with missing values. I've attached the correct file to this email. RE:
init.dfs() being local, I hadn't even thought of that. I've been away from
OOP for close to 15 years now, so it might be time to revise!

The problem I have is that with missing values the list of factor scores
returned (ab.w1.fa$factor.scores) does not map onto the originating data
frame (ab.w1.df) as it no longer includes the cases which had missing
values. So while the original data set for ab.w1.df contains 154 ordered
cases, the factor analysis contains only 150.

I am seeking a way to map the values derived from the factor analysis
(ab.w1.fa$factor.scores) back to their original ordered position, so that
these factor score variables may be merged back into the master data frame
(ab.df). A unique ID for each case is available ($dmid) which I had thought
to use when merging the new variables, however I don't know how to implement
this.


Thanks for your help,

Justin


-----Original Message-----
From: PIKAL Petr [mailto:petr.pikal at precheza.cz] 
Sent: Friday, 26 July 2013 10:59 PM
To: Justin Delahunty; Justin Delahunty; r-help at r-project.org
Subject: RE: [R] Maintaining data order in factanal with missing data

Hi

Well, the function init.dfs does nothing as all data frames created inside
it does not propagate to global environment and there is nothing what the
function returns.

Tha last line (when used outside a function) gives warnings but there is no
sign of error.

When 

> head(ab.1.df)
  dmid   g5oab2      g53      g54      g55   g5ovb1
1    1 1.418932 1.805227 2.791152 3.624116 3.425586
2    2 2.293907 1.187830 1.611237 1.748526 3.816533
3    3 2.836536 2.679523 1.279639 2.674986 2.452395
4    4 1.872259 3.278359 1.785872 2.458315 1.146480
5    5 1.467195 1.180747 3.564127 3.007682 2.109506
6    6 3.098512 3.151974 3.969379 3.750571 1.497358
> head(ab.2.df)
  dmid   w2oab3      w22      w23      w24   w2ovb1
1    1 4.831362 5.522764 7.809366 6.969172 7.398385
2    2 6.706346 4.101742 1.434697 5.266775 5.357641
3    3 3.653806 2.666885 1.209326 5.125556 4.963374
4    4 7.221255 7.649152 6.540398 6.648506 2.576081
5    5 1.848023 5.044314 2.761881 3.307220 1.454234
6    6 7.606429 4.911766 2.034813 2.638573 2.818834
> head(ab.3.df)
  dmid   w3oab3   w3oab4   w3oab7   w3oab8   w3ovb1
1    1 5.835609 6.108220 6.587721 2.451461 2.785467
2    2 4.973198 1.196815 6.388056 1.110877 4.226463
3    3 3.800367 6.697287 5.235345 6.666829 6.319073
4    4 1.093141 1.477773 2.269252 3.194978 4.916342
5    5 1.975060 7.204516 4.825435 1.775874 3.484027
6    6 3.273361 2.243805 5.326547 5.720892 6.118723
>

> str(ab.1.fa)
List of 2
 $ rescaled.scores: Named num [1:154] 3.43 3.83 2.43 1.1 2.08 ...
  ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
 $ factor.loadings: Named num [1:5] -0.0106 -0.0227 -0.1093 -0.0912 0.9975
  ..- attr(*, "names")= chr [1:5] "g5oab2" "g53" "g54" "g55" ...
> str(ab.2.fa)
List of 2
 $ rescaled.scores: Named num [1:154] 6.34 5.24 5.3 1.91 2.16 ...
  ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
 $ factor.loadings: Named num [1:5] -0.2042 0.0063 -0.2287 -0.0119 0.7138
  ..- attr(*, "names")= chr [1:5] "w2oab3" "w22" "w23" "w24" ...
> str(ab.3.fa)
List of 2
 $ rescaled.scores: Named num [1:154] NaN NaN NaN NaN NaN NaN NaN NaN NaN
NaN ...
  ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
 $ factor.loadings: Named num [1:5] -0.1172 0.0128 -0.0968 0.106 0.9975
  ..- attr(*, "names")= chr [1:5] "w3oab3" "w3oab4" "w3oab7" "w3oab8" ...

Anyway I have no idea what you consider wrong?

Regards
Petr



> -----Original Message-----
> From: Justin Delahunty [mailto:ACU at genius.net.au]
> Sent: Friday, July 26, 2013 2:22 PM
> To: PIKAL Petr; 'Justin Delahunty'; r-help at r-project.org
> Subject: RE: [R] Maintaining data order in factanal with missing data
> 
> Hi Petr,
> 
> Thanks for the quick response. Unfortunately I cannot share the data I 
> am working with, however please find attached a suitable R workspace 
> with generated data. It has the appropriate variable names, only the 
> data has been changed.
> 
> The last function in the list (init.dfs()) I call to subset the 
> overall data set into the three waves, then conduct the factor 
> analysis on each
> (1 factor CFA); it's just in a function to ease re-typing in a new 
> workspace.
> 
> 
> Thanks,
> 
> Justin
> 
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Friday, 26 July 2013 7:35 PM
> To: Justin Delahunty; r-help at r-project.org
> Subject: RE: [R] Maintaining data order in factanal with missing data
> 
> Hi
> 
> You provided functions, so far so good. But without data it would be 
> quite difficult to understand what the functions do and where could be 
> the issue.
> 
> I suspect combination of complete cases selection together with subset 
> and factor behaviour. But I can be completely out of target too.
> 
> Petr
> 
> > -----Original Message-----
> > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r- 
> > project.org] On Behalf Of s00123776 at myacu.edu.au
> > Sent: Friday, July 26, 2013 9:35 AM
> > To: r-help at r-project.org
> > Subject: [R] Maintaining data order in factanal with missing data
> >
> > Hi,
> >
> >
> >
> > I'm new to R, so sorry if this is a simple answer. I'm currently 
> > trying to collapse some ordinal variables into a composite; the 
> > program ideally should take a data frame as input, perform a factor 
> > analysis, compute factor scores, sds, etc., and return the rescaled 
> > scores and loadings. The difficulty I'm having is that my data set 
> > contains a number of NA, which I am excluding from the analysis 
> > using complete.cases(), and thus the incomplete cases are "skipped". 
> > These functions are for a longitudinal data set with repeated waves 
> > of
> data,
> > so the final rescaled scores from each wave need to be saved as 
> > variables grouped by a unique ID (DMID). The functions I'm trying to 
> > implement are as follows:
> >
> >
> >
> > weighted.sd<-function(x,w){
> >
> >                                 sum.w<-sum(w)
> >
> >                                 sum.w2<-sum(w^2)
> >
> >                                 mean.w<-sum(x*w)/sum(w)
> >
> >
> > x.sd.w<-sqrt((sum.w/(sum.w^2-sum.w2))*sum(w*(x-mean.w)^2))
> >
> >                                 return(x.sd.w)
> >
> >                                 }
> >
> >
> >
> > re.scale<-function(f.scores, raw.data, loadings){
> >
> >
> > fz.scores<-(f.scores+mean(f.scores))/(sd(f.scores))
> >
> >
> > means<-apply(raw.data,1,weighted.mean,w=loadings)
> >
> >
> > sds<-apply(raw.data,1,weighted.sd,w=loadings)
> >
> >                                 grand.mean<-mean(means)
> >
> >                                 grand.sd<-mean(sds)
> >
> >
> > final.scores<-((fz.scores*grand.sd)+grand.mean)
> >
> >                                 return(final.scores)
> >
> >                                 }
> >
> >
> >
> > get.scores<-function(data){
> >
> >
> > fact<-
> > factanal(data[complete.cases(data),],factors=1,scores="regression")
> >
> >                                 f.scores<-fact$scores[,1]
> >
> >                                 f.loads<-fact$loadings[,1]
> >
> >                                 rescaled.scores<-re.scale(f.scores,
> > data[complete.cases(data),], f.loads)
> >
> >                                 output.list<-list(rescaled.scores,
> > f.loads)
> >
> >                                 names(output.list)<- 
> > c("rescaled.scores",
> > "factor.loadings")
> >
> >                                 return(output.list)
> >
> >                                 }
> >
> >
> >
> > init.dfs<-function(){
> >
> >
> > ab.1.df<-subset(ab.df,,select=c(dmid,g5oab2:g5ovb1))
> >
> >
> > ab.2.df<-subset(ab.df,,select=c(dmid,w2oab3:w2ovb1))
> >
> >                                 
> > ab.3.df<-subset(ab.df,,select=c(dmid,
> > w3oab3, w3oab4, w3oab7, w3oab8, w3ovb1))
> >
> >
> >
> >                                 ab.1.fa<-get.scores(ab.1.df[-1])
> >
> >                                 ab.2.fa<-get.scores(ab.2.df[-1])
> >
> >                                 ab.3.fa<-get.scores(ab.3.df[-1])
> >
> >
> >                                 }
> >
> >
> >
> > Thanks for your help,
> >
> >
> >
> > Justin
> >
> >
> > 	[[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting- 
> > guide.html and provide commented, minimal, self-contained, 
> > reproducible code.
> 




From petr.pikal at precheza.cz  Fri Jul 26 16:06:18 2013
From: petr.pikal at precheza.cz (PIKAL Petr)
Date: Fri, 26 Jul 2013 14:06:18 +0000
Subject: [R] Maintaining data order in factanal with missing data
In-Reply-To: <001901ce8a04$bbbfe220$333fa660$@genius.net.au>
References: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>
	<03afd01260fc4ba4ab892501a5be1d08@BLUPRD0113HT003.prod.exchangelabs.com>
	<000701ce89fa$c511f200$4f35d600$@genius.net.au>
	<9bdd72cc4fd046faa91b3274d2eb8a64@BLUPRD0113HT004.prod.exchangelabs.com>
	<001901ce8a04$bbbfe220$333fa660$@genius.net.au>
Message-ID: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FFE9@SRVEXCHMBX.precheza.cz>

Hi

There are probably better options but

merge(data.frame(x=1:154),data.frame(x=names(ab.1.fa[[1]]), y=ab.1.fa[[1]]), all.x=T)

gives you data frame with NA when there was missing value in the first data.frame.

You probably can automate the process a bit with nrow function.

Regards
Petr



> -----Original Message-----
> From: Justin Delahunty [mailto:ACU at genius.net.au]
> Sent: Friday, July 26, 2013 3:34 PM
> To: PIKAL Petr; 'Justin Delahunty'; 'Justin Delahunty'; r-help at r-
> project.org
> Subject: RE: [R] Maintaining data order in factanal with missing data
> 
> Hi Petr,
> 
> So sorry, I accidentally attached the complete data set rather than the
> one with missing values. I've attached the correct file to this email.
> RE:
> init.dfs() being local, I hadn't even thought of that. I've been away
> from OOP for close to 15 years now, so it might be time to revise!
> 
> The problem I have is that with missing values the list of factor
> scores returned (ab.w1.fa$factor.scores) does not map onto the
> originating data frame (ab.w1.df) as it no longer includes the cases
> which had missing values. So while the original data set for ab.w1.df
> contains 154 ordered cases, the factor analysis contains only 150.
> 
> I am seeking a way to map the values derived from the factor analysis
> (ab.w1.fa$factor.scores) back to their original ordered position, so
> that these factor score variables may be merged back into the master
> data frame (ab.df). A unique ID for each case is available ($dmid)
> which I had thought to use when merging the new variables, however I
> don't know how to implement this.
> 
> 
> Thanks for your help,
> 
> Justin
> 
> 
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Friday, 26 July 2013 10:59 PM
> To: Justin Delahunty; Justin Delahunty; r-help at r-project.org
> Subject: RE: [R] Maintaining data order in factanal with missing data
> 
> Hi
> 
> Well, the function init.dfs does nothing as all data frames created
> inside it does not propagate to global environment and there is nothing
> what the function returns.
> 
> Tha last line (when used outside a function) gives warnings but there
> is no sign of error.
> 
> When
> 
> > head(ab.1.df)
>   dmid   g5oab2      g53      g54      g55   g5ovb1
> 1    1 1.418932 1.805227 2.791152 3.624116 3.425586
> 2    2 2.293907 1.187830 1.611237 1.748526 3.816533
> 3    3 2.836536 2.679523 1.279639 2.674986 2.452395
> 4    4 1.872259 3.278359 1.785872 2.458315 1.146480
> 5    5 1.467195 1.180747 3.564127 3.007682 2.109506
> 6    6 3.098512 3.151974 3.969379 3.750571 1.497358
> > head(ab.2.df)
>   dmid   w2oab3      w22      w23      w24   w2ovb1
> 1    1 4.831362 5.522764 7.809366 6.969172 7.398385
> 2    2 6.706346 4.101742 1.434697 5.266775 5.357641
> 3    3 3.653806 2.666885 1.209326 5.125556 4.963374
> 4    4 7.221255 7.649152 6.540398 6.648506 2.576081
> 5    5 1.848023 5.044314 2.761881 3.307220 1.454234
> 6    6 7.606429 4.911766 2.034813 2.638573 2.818834
> > head(ab.3.df)
>   dmid   w3oab3   w3oab4   w3oab7   w3oab8   w3ovb1
> 1    1 5.835609 6.108220 6.587721 2.451461 2.785467
> 2    2 4.973198 1.196815 6.388056 1.110877 4.226463
> 3    3 3.800367 6.697287 5.235345 6.666829 6.319073
> 4    4 1.093141 1.477773 2.269252 3.194978 4.916342
> 5    5 1.975060 7.204516 4.825435 1.775874 3.484027
> 6    6 3.273361 2.243805 5.326547 5.720892 6.118723
> >
> 
> > str(ab.1.fa)
> List of 2
>  $ rescaled.scores: Named num [1:154] 3.43 3.83 2.43 1.1 2.08 ...
>   ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
>  $ factor.loadings: Named num [1:5] -0.0106 -0.0227 -0.1093 -0.0912
> 0.9975
>   ..- attr(*, "names")= chr [1:5] "g5oab2" "g53" "g54" "g55" ...
> > str(ab.2.fa)
> List of 2
>  $ rescaled.scores: Named num [1:154] 6.34 5.24 5.3 1.91 2.16 ...
>   ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
>  $ factor.loadings: Named num [1:5] -0.2042 0.0063 -0.2287 -0.0119
> 0.7138
>   ..- attr(*, "names")= chr [1:5] "w2oab3" "w22" "w23" "w24" ...
> > str(ab.3.fa)
> List of 2
>  $ rescaled.scores: Named num [1:154] NaN NaN NaN NaN NaN NaN NaN NaN
> NaN NaN ...
>   ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
>  $ factor.loadings: Named num [1:5] -0.1172 0.0128 -0.0968 0.106 0.9975
>   ..- attr(*, "names")= chr [1:5] "w3oab3" "w3oab4" "w3oab7" "w3oab8"
> ...
> 
> Anyway I have no idea what you consider wrong?
> 
> Regards
> Petr
> 
> 
> 
> > -----Original Message-----
> > From: Justin Delahunty [mailto:ACU at genius.net.au]
> > Sent: Friday, July 26, 2013 2:22 PM
> > To: PIKAL Petr; 'Justin Delahunty'; r-help at r-project.org
> > Subject: RE: [R] Maintaining data order in factanal with missing data
> >
> > Hi Petr,
> >
> > Thanks for the quick response. Unfortunately I cannot share the data
> I
> > am working with, however please find attached a suitable R workspace
> > with generated data. It has the appropriate variable names, only the
> > data has been changed.
> >
> > The last function in the list (init.dfs()) I call to subset the
> > overall data set into the three waves, then conduct the factor
> > analysis on each
> > (1 factor CFA); it's just in a function to ease re-typing in a new
> > workspace.
> >
> >
> > Thanks,
> >
> > Justin
> >
> > -----Original Message-----
> > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > Sent: Friday, 26 July 2013 7:35 PM
> > To: Justin Delahunty; r-help at r-project.org
> > Subject: RE: [R] Maintaining data order in factanal with missing data
> >
> > Hi
> >
> > You provided functions, so far so good. But without data it would be
> > quite difficult to understand what the functions do and where could
> be
> > the issue.
> >
> > I suspect combination of complete cases selection together with
> subset
> > and factor behaviour. But I can be completely out of target too.
> >
> > Petr
> >
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-
> > > project.org] On Behalf Of s00123776 at myacu.edu.au
> > > Sent: Friday, July 26, 2013 9:35 AM
> > > To: r-help at r-project.org
> > > Subject: [R] Maintaining data order in factanal with missing data
> > >
> > > Hi,
> > >
> > >
> > >
> > > I'm new to R, so sorry if this is a simple answer. I'm currently
> > > trying to collapse some ordinal variables into a composite; the
> > > program ideally should take a data frame as input, perform a factor
> > > analysis, compute factor scores, sds, etc., and return the rescaled
> > > scores and loadings. The difficulty I'm having is that my data set
> > > contains a number of NA, which I am excluding from the analysis
> > > using complete.cases(), and thus the incomplete cases are
> "skipped".
> > > These functions are for a longitudinal data set with repeated waves
> > > of
> > data,
> > > so the final rescaled scores from each wave need to be saved as
> > > variables grouped by a unique ID (DMID). The functions I'm trying
> to
> > > implement are as follows:
> > >
> > >
> > >
> > > weighted.sd<-function(x,w){
> > >
> > >                                 sum.w<-sum(w)
> > >
> > >                                 sum.w2<-sum(w^2)
> > >
> > >                                 mean.w<-sum(x*w)/sum(w)
> > >
> > >
> > > x.sd.w<-sqrt((sum.w/(sum.w^2-sum.w2))*sum(w*(x-mean.w)^2))
> > >
> > >                                 return(x.sd.w)
> > >
> > >                                 }
> > >
> > >
> > >
> > > re.scale<-function(f.scores, raw.data, loadings){
> > >
> > >
> > > fz.scores<-(f.scores+mean(f.scores))/(sd(f.scores))
> > >
> > >
> > > means<-apply(raw.data,1,weighted.mean,w=loadings)
> > >
> > >
> > > sds<-apply(raw.data,1,weighted.sd,w=loadings)
> > >
> > >                                 grand.mean<-mean(means)
> > >
> > >                                 grand.sd<-mean(sds)
> > >
> > >
> > > final.scores<-((fz.scores*grand.sd)+grand.mean)
> > >
> > >                                 return(final.scores)
> > >
> > >                                 }
> > >
> > >
> > >
> > > get.scores<-function(data){
> > >
> > >
> > > fact<-
> > > factanal(data[complete.cases(data),],factors=1,scores="regression")
> > >
> > >                                 f.scores<-fact$scores[,1]
> > >
> > >                                 f.loads<-fact$loadings[,1]
> > >
> > >                                 rescaled.scores<-re.scale(f.scores,
> > > data[complete.cases(data),], f.loads)
> > >
> > >                                 output.list<-list(rescaled.scores,
> > > f.loads)
> > >
> > >                                 names(output.list)<-
> > > c("rescaled.scores",
> > > "factor.loadings")
> > >
> > >                                 return(output.list)
> > >
> > >                                 }
> > >
> > >
> > >
> > > init.dfs<-function(){
> > >
> > >
> > > ab.1.df<-subset(ab.df,,select=c(dmid,g5oab2:g5ovb1))
> > >
> > >
> > > ab.2.df<-subset(ab.df,,select=c(dmid,w2oab3:w2ovb1))
> > >
> > >
> > > ab.3.df<-subset(ab.df,,select=c(dmid,
> > > w3oab3, w3oab4, w3oab7, w3oab8, w3ovb1))
> > >
> > >
> > >
> > >                                 ab.1.fa<-get.scores(ab.1.df[-1])
> > >
> > >                                 ab.2.fa<-get.scores(ab.2.df[-1])
> > >
> > >                                 ab.3.fa<-get.scores(ab.3.df[-1])
> > >
> > >
> > >                                 }
> > >
> > >
> > >
> > > Thanks for your help,
> > >
> > >
> > >
> > > Justin
> > >
> > >
> > > 	[[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide http://www.R-project.org/posting-
> > > guide.html and provide commented, minimal, self-contained,
> > > reproducible code.
> >
> 
> 


From therneau at mayo.edu  Fri Jul 26 16:11:41 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 26 Jul 2013 09:11:41 -0500
Subject: [R] prediction survival curves for coxph-models;
 how to	extract the right strata per individual
In-Reply-To: <mailman.25.1374746408.28595.r-help@r-project.org>
References: <mailman.25.1374746408.28595.r-help@r-project.org>
Message-ID: <51F2839D.4030602@mayo.edu>

It would help me to give advice if I knew what you wanted to do with the new curves.  
Plot, print, extract?

A more direct solution to your question will appear in the next release of the code, btw.

Terry T.


On 07/25/2013 05:00 AM, r-help-request at r-project.org wrote:
> My problem is:
>
>
>
> I have a coxph.model with several strata and other covariables.
>
> Now I want to fit the estimated survival-curves for new data, using
> survfit.coxph.
>
> But this returns a prediction for each stratum per individual. So if I
> have 15 new individuals and 10 strata, I have 150 fitted surivival curves
> (or if I don't use the subscripts I have 15 predictions with the curves
> for all strata pasted together)
>
>
>
> Is there any possibility to get only the survival curves for the stratum
> the new individual belongs to?
>
>


From soumitrodey1 at gmail.com  Fri Jul 26 16:55:06 2013
From: soumitrodey1 at gmail.com (Soumitro Dey)
Date: Fri, 26 Jul 2013 10:55:06 -0400
Subject: [R] X matrix deemed to be singular and cbind
Message-ID: <CAJ+M79nuHvHoiknmOvRoxKf7KBiouQEzvymy4KftUtUE_UEVHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/d8b56a9a/attachment.pl>

From dwinsemius at comcast.net  Fri Jul 26 17:04:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jul 2013 08:04:55 -0700
Subject: [R] Saving multiple rda-files as one rda-file
In-Reply-To: <1374761864513-4672313.post@n4.nabble.com>
References: <1374491885996-4672041.post@n4.nabble.com>
	<1374761864513-4672313.post@n4.nabble.com>
Message-ID: <411A664B-596D-46DD-B8A2-74EA128DA8E0@comcast.net>


On Jul 25, 2013, at 7:17 AM, Dark wrote:

> Hi, 
> 
> Yes maybe I should have been more clear on my problem.
> I want to append the different data-frames back into one variable ( rbind )
> and save it as one R Data file.
> 

Indeed. That was the operation I had in mind when I made my suggestions. Perhaps you need to create a set of toy dataframes with similar structure and then the audience can propose solutions. That's the usual process around these parts.

-- 
David.


> Regards Derk
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Saving-multiple-rda-files-as-one-rda-file-tp4672041p4672313.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From arl3nu at gmail.com  Fri Jul 26 16:18:09 2013
From: arl3nu at gmail.com (Przemek Gawin)
Date: Fri, 26 Jul 2013 17:18:09 +0300
Subject: [R] Holt-Winters problem
Message-ID: <CABiFE36CXNkTEPY9eCJGEuQKU-yAwgKry_60erKtXjp3FwDrmA@mail.gmail.com>

This post has NOT been accepted by the mailing list yet.
This post was updated on Jul 26, 2013; 4:40pm.
Hello,

Two days ago I started my journey with R, and right now I'm struck on
Holtwinters, and have no idea, what I'm doing wrong. So now, I'll show
step by step what I've been doing. Actually it is a part of "Introducy
Time Series with R".

1) I download data from
http://www.massey.ac.nz/~pscowper/ts/motororg.dat due to port
blockage. Save it as motororg.txt

2) Inserting this code:
Motor.dat <- read.table("motororg.txt", header = T)
attach(Motor.dat)
Comp.hw1 <- HoltWinters(complaints, beta = 0, gamma = 0)

3) Baang! Error here.
"Error in decompose(ts(x[1L:wind], start = start(x), frequency = f),
seasonal) :
 time series has no or less than 2 periods"

4) Actually it has, and I turned it on with attach command?

Motor.dat
   complaints
1          27
2          34
3          31
4          24
5          18
6          19
7          17
8          12
9          26
10         14
11         18
12         33
13         31
14         31
15         19
16         17
17         10
18         25
19         26
20         18
21         18
22         10
23          4
24         20
25         28
26         21
27         18
28         23
29         19
30         16
31         10
32         24
33         11
34         11
35         13
36         27
37         18
38         20
39         21
40          6
41          9
42         29
43         12
44         19
45         14
46         19
47         16
48         23

Can you tell me what I am doing wrong?

PS

I tried to make complaints.ts as well but I didn't work either.


From raphaelle.carraud at oc-metalchem.com  Fri Jul 26 16:14:18 2013
From: raphaelle.carraud at oc-metalchem.com (=?iso-8859-1?Q?Rapha=EBlle_Carraud?=)
Date: Fri, 26 Jul 2013 16:14:18 +0200
Subject: [R] Differential problem
Message-ID: <4565B2277456ED4EB03CD34B21283B472067E6A01B@EXH01001.hmc.local>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/074a1162/attachment.pl>

From alexander.grach at credit-suisse.com  Fri Jul 26 16:44:38 2013
From: alexander.grach at credit-suisse.com (Grach, Alexander)
Date: Fri, 26 Jul 2013 10:44:38 -0400
Subject: [R] cannot install XML package - getting "cannot open URL
	'http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
	error
Message-ID: <7E3B93542C4F3D42B40446964CB4D79B1E83A2F3@EPRI17P32009A.csfb.cs-group.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/82aed91e/attachment.pl>

From marc_schwartz at me.com  Fri Jul 26 17:12:54 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Fri, 26 Jul 2013 10:12:54 -0500
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <51F26544.5000701@mayo.edu>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
	<4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
	<4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>
	<6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>
	<51F26544.5000701@mayo.edu>
Message-ID: <60519D1C-6097-4F47-A837-5A69561E274E@me.com>

Thanks Terry. 

Good points. I recalled last night some exchanges on r-sig-mixed-models regarding a reasonable number of 'replications' for the estimation of random effects and it occurred to me that with this study, you will have 0, 1 or 2 events per subject, depending upon the subject risk profiles for hip replacement and length of follow up. 

It was not clear to me if John's cohort study is retrospective or prospective. If the former, then he will have some insights into the event distribution. If the latter and he needs to pre-specify the analytic method, a GEE style approach using coxph() may make more sense here given the unknowns.

Regards,

Marc
 
On Jul 26, 2013, at 7:02 AM, Terry Therneau <therneau at mayo.edu> wrote:

> Two choices.
> If this were a linear model, do you like the GEE approach or a mixed effects approach?  Assume that "subject" is a variable containing a per-subject identifier.
> 
> GEE approach: add "+ cluster(subject)" to the model statement in coxph
> Mixed models approach: Add " + (1|subject)" to the model statment in coxme.
> 
> When only a very few subjects have multiple events, the mixed model (random effect) approach may not be reliable, however.  Multiple events per group are the fuel for estimation of the variance of the random effect, and with few of these the profile likelihood of the random effect will be very flat.  You can get esssentially a random estimate of the variance of the "subject effect".  I'm still getting my arms around this issue, and it has taken me a long time.
> 
> "Frailty" is an alternate label for "random effects when all we have is a random intercept".  Multiple labels for the same idea adds confusion, but nothing else.
> 
> Terry Therneau
> 
> On 07/25/2013 08:14 PM, Marc Schwartz wrote:
>> On Jul 25, 2013, at 4:45 PM, David Winsemius<dwinsemius at comcast.net>  wrote:
>> 
>>> On Jul 25, 2013, at 12:27 PM, Marc Schwartz wrote:
>>> 
>>>> On Jul 25, 2013, at 2:11 PM, John Sorkin<jsorkin at grecc.umaryland.edu>  wrote:
>>>> 
>>>>> Colleagues,
>>>>> Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
>>>>> I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
>>>>> Thank you,
>>>>> John
>>>> 
>>>> 
>>>> John,
>>>> 
>>>> See Terry's 'coxme' package:
>>>> 
>>>> http://cran.r-project.org/web/packages/coxme/index.html
>>>> 
>>> When I looked over the description of coxme, I was concerned it was not really designed with this in mind. Looking at Therneau and Grambsch, I thought section 8.4.2 in the 'Multiple Events per Subject' Chapter fit the analysis question well. There they compared the use of coxph( ...+cluster(ID),,...)  withcoxph( ...+strata(ID),,...). Unfortunately I could not tell for sure which one was being described as superio but I think it was the cluster() alternative. I seem to remember there are discussions in the archives.
>> 
>> David,
>> 
>> I think that you raise a good point. The example in the book (I had to wait to get home to read it) is potentially different however, in that the subject's eye's were randomized to treatment or control, which would seem to suggest comparable baseline characteristics for each pair of eyes, as well as an active intervention on one side where a difference in treatment effect between each eye is being analyzed.
>> 
>> It is not clear from John's description above if there is one hip that will be treated versus one as a control and whether the extent of disease at baseline is similar in each pair of hips. Presumably the timing of hip replacements will be staggered at some level, even if there is comparable disease, simply due to post-op recovery time and surgical risk. In cases where the disease between each hip is materially different, that would be another factor to consider, however I would defer to orthopaedic physicians/surgeons from a subject matter expertise consideration. It is possible that the bilateral hip replacement data might be more of a parallel to bilateral breast cancer data, if each breast were to be tracked separately.
>> 
>> I have cc'd Terry here, hoping that he might jump in and offer some insights into the pros/cons of using coxme versus coxph with either a cluster or strata based approach, or perhaps even a frailty based approach as in 9.4.1 in the book.
>> 
>> Regards,
>> 
>> Marc
>> 
>> 
>>> -- 
>>> David.
>>>> You also might find the following of interest:
>>>> 
>>>> http://bjo.bmj.com/content/71/9/645.full.pdf
>>>> 
>>>> http://www.ncbi.nlm.nih.gov/pubmed/22226885
>>>> 
>>>> http://www.ncbi.nlm.nih.gov/pubmed/22078901
>>>> 
>>>> 
>>>> 
>>>> Regards,
>>>> 
>>>> Marc Schwartz
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Fri Jul 26 17:18:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 08:18:48 -0700 (PDT)
Subject: [R] Pairwise comparison between columns, logic
In-Reply-To: <CANsTkzw=VMXo9TnoYdh=mQSf8cGKdX11mo9sMN2T7jY188S7jA@mail.gmail.com>
References: <16537728.95738.1374845250639.JavaMail.nabble@joe.nabble.com>	<1374845344.46982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CANsTkzw=VMXo9TnoYdh=mQSf8cGKdX11mo9sMN2T7jY188S7jA@mail.gmail.com>
Message-ID: <1374851928.44787.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi Manisha,
I didn't run your dataset as I am on the way to college.? But, from the error reported, I think it will be due to some missing combinations in one of the dataset.? For ex. if you run my previous code without removing CEBPA:
ie.
mat1<- combn(gset[,1],2)


lst2<-lapply(split(mat1,col(mat1)),function(x) {x1<-join_all(lst1[x],by="patient_id",type="inner");x1["patient_id"] } )
#Error: All inputs to rbind.fill must be data.frames


So, check whether all the combinations are available in the `lst1`.

2. I will get back to you once I run it.
A.K.





________________________________
From: Manisha <manishabh77 at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, July 26, 2013 11:09 AM
Subject: Re: Pairwise comparison between columns, logic



Hi Arun,
I ran the script on a larger dataset and I seem to be running into this following error:
Error: All inputs to rbind.fill must be data.frames
after the step;
lst2<-lapply(split(mat1,col(mat1)),function(x) {x1<-join_all(lst1[x],by="firehose_patient_id",type="inner");x1["firehose_patient_id"]}) 
I tried a few things to solve the issue but I am not able to. The format of input files and data are same as in the code you posted.
Could you suggest me something?
I have attached my input files on which I am trying to run the code. See attached code as well. Minor changes have been made by me.

2. I have another question. From your code how do also capture those pairs of names that donot have any common patient id?

Thanks again,
-M


On Fri, Jul 26, 2013 at 9:29 AM, arun <smartpink111 at yahoo.com> wrote:

Hi M,
>No problem.
>Regards,
>Arun
>
>
>
>
>----- Original Message -----
>From: "manishabh77 at gmail.com" <manishabh77 at gmail.com>
>To: smartpink111 at yahoo.com
>Cc:
>Sent: Friday, July 26, 2013 9:27 AM
>Subject: Re: Pairwise comparison between columns, logic
>
>Thanks for the code. It is elegant and does what I need. Learnt some new things.
>-M
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>??


From gunter.berton at gene.com  Fri Jul 26 17:22:00 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 26 Jul 2013 08:22:00 -0700
Subject: [R] X matrix deemed to be singular and cbind
In-Reply-To: <CAJ+M79nuHvHoiknmOvRoxKf7KBiouQEzvymy4KftUtUE_UEVHQ@mail.gmail.com>
References: <CAJ+M79nuHvHoiknmOvRoxKf7KBiouQEzvymy4KftUtUE_UEVHQ@mail.gmail.com>
Message-ID: <CACk-te1NPEH3C5-xaXu-uhaqYvLYnk_U5hDxoSbrjte89akZSQ@mail.gmail.com>

Soumitro:

Have you read "An Introduction to R." If not, do so, as some of your
confusion appears related to basic concepts (e.g. of factors)
explained there.

1. Presumably your categorical variables are factors, not character.
If so, when you cbind() them, you cbind their integer codes, yielding
numerical variables. This produces an in incorrect design matrix in
fitting -- 1 df per categorical variable instead of 1 less than the
number of levels. Also see ?cbind.

2. Produces the correct design matrix, but you are overfitting,
presumably because of many different levels for your categorical
variables. I suggest you consult with a local statistician to decide
how best to handle this, as you seem to be out of your depth with
regard to model fitting.

... unless I have misunderstood, of course.

Cheers,
Bert

On Fri, Jul 26, 2013 at 7:55 AM, Soumitro Dey <soumitrodey1 at gmail.com> wrote:
> Hi list,
>
> While the "X matrix deemed to be singular" question has been answered in
> the list for quite a few times, I have a twist to it.
>
> I am using the coxph model for survival analysis on a dataset containing
> over 160,000 instances and 46 independent variables and I have 2 scenarios:
>
> 1. If I use cbind on the 46 independent variables (many of which are
> categorical), coxph runs without any frills. The problem however is that it
> won't report which of the categorical variables (e.g. VERY HIGH, HIGH,
> NEUTRAL, LOW or VERY LOW) are actually meaningful/significant(e.g. XHIGH
> ***, XLOW ., etc). Is there any way to check this?
>
> 2. If I don't use cbind, assuming it'll give me the details I am looking
> for in the previous step, it throws me the "X matrix deemed to be
> singular", more precisely: "X matrix deemed to be singular; variable 130
> 131 132 133 134 135 136 137 138 139 140 141 142 143 144 145 146 147 148 149
> 150 151 152 153 154 155 156 157 158 159 160 161 162 163 164 165 166 167 168
> 169 170 171 172 173 174 175 176 177 178 179 180 181"
>
> Could anyone please elaborate on how to get around problem #1 or #2?
>
> Thanks!
> SD
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From jsorkin at grecc.umaryland.edu  Fri Jul 26 17:32:37 2013
From: jsorkin at grecc.umaryland.edu (John Sorkin)
Date: Fri, 26 Jul 2013 11:32:37 -0400
Subject: [R] Repeated measures Cox regression ??coxph??
In-Reply-To: <60519D1C-6097-4F47-A837-5A69561E274E@me.com>
References: <CANCB45t0fkmA8qkxp5hSrzo224-ifEdULnAtGbtBc2bdg_GRnQ@mail.gmail.com>
	<51F14029020000CB000EB14D@smtp.medicine.umaryland.edu>
	<4B7D175D-0225-49DE-BC6B-CC0F9130D14A@me.com>
	<4655CDC8-C3A7-41F3-BBFA-E8D121053395@comcast.net>
	<6CE72D24-E84E-4B64-BF8E-3497E460B60F@me.com>
	<51F26544.5000701@mayo.edu>
	<60519D1C-6097-4F47-A837-5A69561E274E@me.com>
Message-ID: <51F25E55020000CB000EB319@smtp.medicine.umaryland.edu>

Marc,
Thank you for your comments. The data has been previously collected, so the study is a non-concurrent prospective analysis, i.e. retrospective analysis.
John


John David Sorkin M.D., Ph.D.
Professor of Medicine
Chief, Biostatistics and Informatics
University of Maryland School of Medicine Division of Gerontology
Baltimore VA Medical Center
10 North Greene Street
GRECC (BT/18/GR)
Baltimore, MD 21201-1524
(Phone) 410-605-7119
(Fax) 410-605-7913 (Please call phone number above prior to faxing) 
>>> Marc Schwartz <marc_schwartz at me.com> 07/26/13 11:13 AM >>>
Thanks Terry. 

Good points. I recalled last night some exchanges on r-sig-mixed-models regarding a reasonable number of 'replications' for the estimation of random effects and it occurred to me that with this study, you will have 0, 1 or 2 events per subject, depending upon the subject risk profiles for hip replacement and length of follow up. 

It was not clear to me if John's cohort study is retrospective or prospective. If the former, then he will have some insights into the event distribution. If the latter and he needs to pre-specify the analytic method, a GEE style approach using coxph() may make more sense here given the unknowns.

Regards,

Marc
 
On Jul 26, 2013, at 7:02 AM, Terry Therneau <therneau at mayo.edu> wrote:

> Two choices.
> If this were a linear model, do you like the GEE approach or a mixed effects approach?  Assume that "subject" is a variable containing a per-subject identifier.
> 
> GEE approach: add "+ cluster(subject)" to the model statement in coxph
> Mixed models approach: Add " + (1|subject)" to the model statment in coxme.
> 
> When only a very few subjects have multiple events, the mixed model (random effect) approach may not be reliable, however.  Multiple events per group are the fuel for estimation of the variance of the random effect, and with few of these the profile likelihood of the random effect will be very flat.  You can get esssentially a random estimate of the variance of the "subject effect".  I'm still getting my arms around this issue, and it has taken me a long time.
> 
> "Frailty" is an alternate label for "random effects when all we have is a random intercept".  Multiple labels for the same idea adds confusion, but nothing else.
> 
> Terry Therneau
> 
> On 07/25/2013 08:14 PM, Marc Schwartz wrote:
>> On Jul 25, 2013, at 4:45 PM, David Winsemius<dwinsemius at comcast.net>  wrote:
>> 
>>> On Jul 25, 2013, at 12:27 PM, Marc Schwartz wrote:
>>> 
>>>> On Jul 25, 2013, at 2:11 PM, John Sorkin<jsorkin at grecc.umaryland.edu>  wrote:
>>>> 
>>>>> Colleagues,
>>>>> Is there any R package that will allow one to perform a repeated measures Cox Proportional Hazards regression? I don't think coxph is set up to handle this type of problem, but I would be happy to know that I am not correct.
>>>>> I am doing a study of time to hip joint replacement. As each person has two hips, a given person can appear in the dataset twice, once for the left hip and once for the right hip, and I need to account for the correlation of data from a single individual.
>>>>> Thank you,
>>>>> John
>>>> 
>>>> 
>>>> John,
>>>> 
>>>> See Terry's 'coxme' package:
>>>> 
>>>> http://cran.r-project.org/web/packages/coxme/index.html
>>>> 
>>> When I looked over the description of coxme, I was concerned it was not really designed with this in mind. Looking at Therneau and Grambsch, I thought section 8.4.2 in the 'Multiple Events per Subject' Chapter fit the analysis question well. There they compared the use of coxph( ...+cluster(ID),,...)  withcoxph( ...+strata(ID),,...). Unfortunately I could not tell for sure which one was being described as superio but I think it was the cluster() alternative. I seem to remember there are discussions in the archives.
>> 
>> David,
>> 
>> I think that you raise a good point. The example in the book (I had to wait to get home to read it) is potentially different however, in that the subject's eye's were randomized to treatment or control, which would seem to suggest comparable baseline characteristics for each pair of eyes, as well as an active intervention on one side where a difference in treatment effect between each eye is being analyzed.
>> 
>> It is not clear from John's description above if there is one hip that will be treated versus one as a control and whether the extent of disease at baseline is similar in each pair of hips. Presumably the timing of hip replacements will be staggered at some level, even if there is comparable disease, simply due to post-op recovery time and surgical risk. In cases where the disease between each hip is materially different, that would be another factor to consider, however I would defer to orthopaedic physicians/surgeons from a subject matter expertise consideration. It is possible that the bilateral hip replacement data might be more of a parallel to bilateral breast cancer data, if each breast were to be tracked separately.
>> 
>> I have cc'd Terry here, hoping that he might jump in and offer some insights into the pros/cons of using coxme versus coxph with either a cluster or strata based approach, or perhaps even a frailty based approach as in 9.4.1 in the book.
>> 
>> Regards,
>> 
>> Marc
>> 
>> 
>>> -- 
>>> David.
>>>> You also might find the following of interest:
>>>> 
>>>> http://bjo.bmj.com/content/71/9/645.full.pdf
>>>> 
>>>> http://www.ncbi.nlm.nih.gov/pubmed/22226885
>>>> 
>>>> http://www.ncbi.nlm.nih.gov/pubmed/22078901
>>>> 
>>>> 
>>>> 
>>>> Regards,
>>>> 
>>>> Marc Schwartz
>>>> 
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>> David Winsemius
>>> Alameda, CA, USA
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.




Confidentiality Statement:
This email message, including any attachments, is for the sole use of the intended recipient(s) and may contain confidential and privileged information.  Any unauthorized use, disclosure or distribution is prohibited.  If you are not the intended recipient, please contact the sender by reply email and destroy all copies of the original message. 

From bhh at xs4all.nl  Fri Jul 26 17:33:14 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Fri, 26 Jul 2013 17:33:14 +0200
Subject: [R] Holt-Winters problem
In-Reply-To: <CABiFE36CXNkTEPY9eCJGEuQKU-yAwgKry_60erKtXjp3FwDrmA@mail.gmail.com>
References: <CABiFE36CXNkTEPY9eCJGEuQKU-yAwgKry_60erKtXjp3FwDrmA@mail.gmail.com>
Message-ID: <6A75B9AC-04F7-427D-8246-A9BC79A06E6D@xs4all.nl>


On 26-07-2013, at 16:18, Przemek Gawin <arl3nu at gmail.com> wrote:

> This post has NOT been accepted by the mailing list yet.
> This post was updated on Jul 26, 2013; 4:40pm.
> Hello,
> 
> Two days ago I started my journey with R, and right now I'm struck on
> Holtwinters, and have no idea, what I'm doing wrong. So now, I'll show
> step by step what I've been doing. Actually it is a part of "Introducy
> Time Series with R".
> 
> 1) I download data from
> http://www.massey.ac.nz/~pscowper/ts/motororg.dat due to port
> blockage. Save it as motororg.txt
> 
> 2) Inserting this code:
> Motor.dat <- read.table("motororg.txt", header = T)
> attach(Motor.dat)
> Comp.hw1 <- HoltWinters(complaints, beta = 0, gamma = 0)
> 
> 3) Baang! Error here.
> "Error in decompose(ts(x[1L:wind], start = start(x), frequency = f),
> seasonal) :
> time series has no or less than 2 periods"
> 

Your complaints vector is not a timeseries. 

From the section Arguments of HoltWinters:

gamma	parameter used for the seasonal component. If set to FALSE, an non-seasonal model is fitted.

So use gamma=FALSE.

Don't use attach().
Use Motor.dat$complaints in the HoltWinter call 

or

Comp.hw1 <- with(Motor.dat, HoltWinters(complaints,  beta = 0, gamma = FALSE))


Berend

> 4) Actually it has, and I turned it on with attach command?
> 
> Motor.dat
>   complaints
> 1          27
> 2          34
> 3          31
> 4          24
> 5          18
> 6          19
> 7          17
> 8          12
> 9          26
> 10         14
> 11         18
> 12         33
> 13         31
> 14         31
> 15         19
> 16         17
> 17         10
> 18         25
> 19         26
> 20         18
> 21         18
> 22         10
> 23          4
> 24         20
> 25         28
> 26         21
> 27         18
> 28         23
> 29         19
> 30         16
> 31         10
> 32         24
> 33         11
> 34         11
> 35         13
> 36         27
> 37         18
> 38         20
> 39         21
> 40          6
> 41          9
> 42         29
> 43         12
> 44         19
> 45         14
> 46         19
> 47         16
> 48         23
> 
> Can you tell me what I am doing wrong?
> 
> PS
> 
> I tried to make complaints.ts as well but I didn't work either.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From szehnder at uni-bonn.de  Fri Jul 26 17:34:46 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Fri, 26 Jul 2013 17:34:46 +0200
Subject: [R] Hmisc ctable rotate option obsolete?
Message-ID: <A678F5E7-0C89-48A9-8F2C-21DFDA915F21@uni-bonn.de>

Dear R-Users and R-Devels,

I may have found a deprecated option for the 'latex' function in the Hmisc package. I am working with Hmisc and knitr and tried the following code:

 \documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{ctable}
%\usepackage{booktabs}
\begin{document}
<<results = 'asis'>>=
library(Hmisc)
iris.t <- head(iris)
iris.t[seq(2, NROW(iris.t), by = 2),] <- format(iris.t[seq(2, NROW(iris.t), by = 2),], scientific = TRUE)
texMat <- matrix("", ncol = 5, nrow = 6)
texMat[seq(2,nrow(texMat), by = 2), ] <- "scriptsize"
latex(iris.t, 
file = '', 
landscape = TRUE,
dcolumn = TRUE,
col.just = c('r','c', 'r','c', 'l'),
cdec = c(0, 0, 1, 1, 0),
na.blank = TRUE,
rowname = '',
rowlabel = '', 
cellTexCmd = texMat,
ctable = TRUE, 
cgroup = c('Observations', ''),
n.cgroup = c(4, 1),
rgroup = c('',''),
n.rgroup = c(3, 3),
caption = 'iris'
)
@
\end{document}

Everything runs fine but the 'landscape' option. It says in the help for 'latex' that if option 'ctable' is set to TRUE the 'rotate' option for ctable is used if 'nadscape' is set TRUE. Looking at the ctable documentary (http://texdoc.net/texmf-dist/doc/latex/ctable/ctable.pdf) in section Change History, I get for version v1.07: General: Added option sideways, option rotate now obsolete. Hasn't this been updated in the Hmisc package?

Best

Simon


From tiago.pereira at mbe.bio.br  Fri Jul 26 17:44:19 2013
From: tiago.pereira at mbe.bio.br (Tiago V. Pereira)
Date: Fri, 26 Jul 2013 12:44:19 -0300 (BRT)
Subject: [R] How to double integrate a function in R
Message-ID: <39811.186.215.164.146.1374853459.squirrel@webmail.mbe.bio.br>

Hello, R users!

I am trying to double integrate the following expression:

#  expression
(1/(2*pi))*exp(-y2/2)*sqrt((y1/(y2-y1)))

for y2>y1>0.

I am trying the following approach

# first attempt

 library(cubature)
    fun <- function(x)   { (1/(2*pi))*exp(-x[2]/2)*sqrt((x[1]/(x[2]-x[1])))}
    adaptIntegrate(fun, lower = c(0,0), upper =c(5, 6), tol=1e-8)

However, I don't know how to constrain the integration so that y2>y1>0.

Any ideas?

Tiago


From j.a.balbuena at uv.es  Fri Jul 26 17:52:58 2013
From: j.a.balbuena at uv.es (Juan Antonio Balbuena)
Date: Fri, 26 Jul 2013 17:52:58 +0200
Subject: [R] transform dataframe with look-up table
In-Reply-To: <E5BA65CAFB491A4DBB1370F6C97216550744586DD2@EX-MB05.ohsu.edu>
References: <51F14080.3070100@uv.es>
	<E5BA65CAFB491A4DBB1370F6C97216550744586DD2@EX-MB05.ohsu.edu>
Message-ID: <51F29B5A.5010604@uv.es>


   Hello
   First thank you very much to Jean, Bill, Brian and David for the answers and
   code. I very extremely grateful.
   I am eventually going to adapt Brian's code with a very minor alteration. If
   one follows the original syntax
End <- merge(merge(Start, transformer, by.x="Left", by.y="input", 
all.x=TRUE),
              transformer, by.x="Right", by.y="input", all.x=TRUE)

   the "Left" variables are listed right and vice versa, which seems odd. Just
   swapping "Left" and "Right" will put it right (pun intentional):
End <- merge(merge(Start, transformer, by.x="Right", by.y="input", 
all.x=TRUE),
              transformer, by.x="Left", by.y="input", all.x=TRUE)

   Best wishes
   Juan Antonio

   El 25/07/2013 18:02, Brian Diggs escribi??:

On 7/25/2013 8:13 AM, Juan Antonio Balbuena wrote:

    Hello
    I hope that there is a simple solution to this apparently complex problem.
    Any help will be much appreciated:
    I have a dataframe with Left and Right readings (that is, elements in each
    row are paired). For instance,
        Left Right
     [1]  9    8
     [2]  4    3
     [3]  2    1
     [4]  6    5
     [5]  3    1
     [6]  4    1
     [7]  3    2
     [8]  4    2
     [9]  10   8
    [10]  9   10
    I  need  to  produce a new data frame where the values are transformed
    according to a look-up table such as
            input    output
     [1]     5      1
     [2]    10     1
     [3]     4      2
     [4]     8      3
     [5]     6      5
     [6]     5      6
     [7]     7      6
     [8]     2      7
     [9]     9      7
    [10]    10    7
    [11]     2     8
    So  [1, ] in the new dataframe would be 7 3. Quite simple so far, but what
    makes things complicated is the multiple outputs for a single input. In thi
s
    example, 10 corresponds to 1 and 7 so [9, ] in the input dataframe must
    yield two rows in its output counterpart: 1 3 and 7 3. Likewise the output
    for  [10, ] should be 7 1 and 7 7. In addition, given that 3 and 1 are
    missing as inputs the output for [5, ] should be NA NA.
    Thank you very much for your time.
    Juan Antonio Balbuena

merge can handle both of these requirements.

First, making the two datasets reproducible:

Start <- data.frame(Left=c(9,4,2,6,3,4,3,4,10,9),
                     Right=c(8,3,1,5,1,1,2,2,8,10))

transformer <- data.frame(input=c(5,10,4,8,6,5,7,2,9,10,2),
                           output=c(1,1,2,3,5,6,6,7,7,7,8))

Then add a marker of the original row numbers so that the work can be 
checked more easily later (not really needed for the calculations):

Start$rownum <- seq_len(nrow(Start))

Two merge statements with the columns specified and all.x set to TRUE 
(to keep cases even without a match):

End <- merge(merge(Start, transformer, by.x="Left", by.y="input", 
all.x=TRUE),
              transformer, by.x="Right", by.y="input", all.x=TRUE)

Then we can look at the output, resorted by the original row numbers:

End[order(End$rownum),]

which gives

    Right Left rownum output.x output.y
12     8    9      1        7        3
9      3    4      2        2       NA
1      1    2      3        7       NA
2      1    2      3        8       NA
10     5    6      4        5        6
11     5    6      4        5        1
3      1    3      5       NA       NA
4      1    4      6        2       NA
5      2    3      7       NA        7
6      2    3      7       NA        8
7      2    4      8        2        7
8      2    4      8        2        8
13     8   10      9        1        3
14     8   10      9        7        3
15    10    9     10        7        1
16    10    9     10        7        7


    --

    Dr. Juan A. Balbuena
    Marine Zoology Unit
    Cavanilles Institute of Biodiversity and Evolutionary Biology
    University of
    Valencia
    [1][1]http://www.uv.es/~balbuena
    P.O. Box 22085
    [2][2]http://www.uv.es/cavanilles/zoomarin/index.htm
    46071 Valencia, Spain
    [3][3]http://cetus.uv.es/mullpardb/index.html
    e-mail: [[4]4]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543
 733
    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
    NOTE! For shipments by EXPRESS COURIER use the following street address:
    C/ Catedr????tico Jos???? Beltr????n 2, 46980 Paterna (Valencia), Spain.
    ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

References

    1. [5]http://www.uv.es/%7Ebalbuena
    2. [6]http://www.uv.es/cavanilles/zoomarin/index.htm
    3. [7]http://cetus.uv.es/mullpardb/index.html
    4. [8]mailto:j.a.balbuena at uv.es


   --

   Dr. Juan A. Balbuena
   Marine Zoology Unit
   Cavanilles Institute of Biodiversity and Evolutionary Biology
   University of
   Valencia
   [9]http://www.uv.es/~balbuena
   P.O. Box 22085
   [10]http://www.uv.es/cavanilles/zoomarin/index.htm
   46071 Valencia, Spain
   [11]http://cetus.uv.es/mullpardb/index.html
   e-mail: [12]j.a.balbuena at uv.es    tel. +34 963 543 658    fax +34 963 543
   733
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
   NOTE! For shipments by EXPRESS COURIER use the following street address:
   C/ Catedr??tico Jos?? Beltr??n 2, 46980 Paterna (Valencia), Spain.
   ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++

References

   1. http://www.uv.es/~balbuena
   2. http://www.uv.es/cavanilles/zoomarin/index.htm
   3. http://cetus.uv.es/mullpardb/index.html
   4. mailto:4]j.a.balbuena at uv.es
   5. http://www.uv.es/%7Ebalbuena
   6. http://www.uv.es/cavanilles/zoomarin/index.htm
   7. http://cetus.uv.es/mullpardb/index.html
   8. mailto:j.a.balbuena at uv.es
   9. http://www.uv.es/%7Ebalbuena
  10. http://www.uv.es/cavanilles/zoomarin/index.htm
  11. http://cetus.uv.es/mullpardb/index.html
  12. mailto:j.a.balbuena at uv.es

From jdnewmil at dcn.davis.CA.us  Fri Jul 26 17:58:37 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 26 Jul 2013 08:58:37 -0700
Subject: [R] cannot install XML package - getting "cannot open
	URL	'http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip'	error
In-Reply-To: <7E3B93542C4F3D42B40446964CB4D79B1E83A2F3@EPRI17P32009A.csfb.cs-group.com>
References: <7E3B93542C4F3D42B40446964CB4D79B1E83A2F3@EPRI17P32009A.csfb.cs-group.com>
Message-ID: <9029ac7a-67af-46e9-bcb0-96e94f2892bc@email.android.com>

I have no trouble accessing either of those files. Keep in mind that servers do not have 100% uptime (and the people responsible for uptime do not monitor this forum), and any local network problems you may be having cannot be addressed here. So, in general you need to try more servers, confirm the file you want does exist, verify that your local network is functioning, and practice a little patience.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

"Grach, Alexander" <alexander.grach at credit-suisse.com> wrote:
>Hello All, 
>
> 
>
>I am not able to install/update XML package, getting the following:
>
> 
>
>> install.packages("XML", lib = .libPaths()[3])
>
>trying URL
>'http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>
>Error in download.file(url, destfile, method, mode = "wb", ...) : 
>
>  cannot open URL
>'http://cran.cnr.Berkeley.edu/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>
>In addition: Warning message:
>
>In download.file(url, destfile, method, mode = "wb", ...) :
>
>  cannot open: HTTP status was '503 Service Unavailable'
>
>Warning in download.packages(pkgs, destdir = tmpd, available =
>available,  :
>
>  download of package 'XML' failed
>
> 
>
>Also have tried to download  the XML_3.98-1.1.zip from
>http://cran.r-project.org/web/packages/XML/index.html - getting an
>error:
>
>"Unable to download XML_3.98-1.1.zip from cran.r-project.org
>
>Unable to open this internet site. The requested site is either
>unavailable or cannot be found. Please try again later."
>
> 
>
>Using R 3.0.1 on windows and able to install/update other packages
>fine.
>
> 
>
>Please help,
>
> 
>
>Many thanks,
>
>Alex
>
> 
>
> 
>
>
>=============================================================================================================
>
>This material has been prepared by individual sales and/or trading
>personnel and does not 
>constitute investment research.  Please follow the attached hyperlink
>to an important disclaimer: 
>http://www.credit-suisse.com/americas/legal/salestrading 
>=============================================================================================================
>
>
>
>===============================================================================
>
>Please access the attached hyperlink for an important
>el...{{dropped:8}}
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Fri Jul 26 18:12:58 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Fri, 26 Jul 2013 11:12:58 -0500
Subject: [R] Maintaining data order in factanal with missing data
In-Reply-To: <6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FFE9@SRVEXCHMBX.precheza.cz>
References: <002501ce89d2$a26134a0$e7239de0$@myacu.edu.au>	<03afd01260fc4ba4ab892501a5be1d08@BLUPRD0113HT003.prod.exchangelabs.com>	<000701ce89fa$c511f200$4f35d600$@genius.net.au>	<9bdd72cc4fd046faa91b3274d2eb8a64@BLUPRD0113HT004.prod.exchangelabs.com>	<001901ce8a04$bbbfe220$333fa660$@genius.net.au>
	<6E8D8DFDE5FA5D4ABCB8508389D1BF8802B7FFE9@SRVEXCHMBX.precheza.cz>
Message-ID: <01a901ce8a1a$fed3a8b0$fc7afa10$@tamu.edu>

When you use complete.cases(), it creates a logical vector
that selects cases with no missing values, but it does not
change the rownames in the data.frame and those are carried
through to the factor scores so you could link them up that
way. Alternatively, you could use na.exclude as the na.action
in the call to factanal() instead of complete.cases()? That
should pad the output with NAs for the cases that have missing
data.

You have to use the formula version of factanal():

> set.seed(42)
> example <- data.frame(x=rnorm(15), y=rnorm(15), z=rnorm(15))
> to.na <- cbind(sample.int(15, 3), sample.int(3, 3))
> example[to.na] <- NA
> out <- factanal(~x+y+z, 1, data=example, na.action=na.omit,
scores="regression")
> out$scores   # With na.omit the cases with missing values
are gone as indicated
       Factor1 # by the missing row numbers
2  -0.92604879
4   0.10731539
5  -0.24370504
6   0.07357697
7   0.69905895
8  -0.17646575
9   1.58430095
10 -0.35934769
12  1.07671299
13 -1.47487960
14 -0.30235156
15 -0.05816682
> out <- factanal(~x+y+z, 1, data=example,
na.action=na.exclude, scores="regression")
> out$scores   # With na.exclude, the cases are kept out of
the analysis but the rows are
       Factor1 # preserved in the factor scores output
1           NA
2  -0.92604879
3           NA
4   0.10731539
5  -0.24370504
6   0.07357697
7   0.69905895
8  -0.17646575
9   1.58430095
10 -0.35934769
11          NA
12  1.07671299
13 -1.47487960
14 -0.30235156
15 -0.05816682

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of PIKAL Petr
Sent: Friday, July 26, 2013 9:06 AM
To: s00123776 at myacu.edu.au; 'Justin Delahunty';
r-help at r-project.org
Subject: Re: [R] Maintaining data order in factanal with
missing data

Hi

There are probably better options but

merge(data.frame(x=1:154),data.frame(x=names(ab.1.fa[[1]]),
y=ab.1.fa[[1]]), all.x=T)

gives you data frame with NA when there was missing value in
the first data.frame.

You probably can automate the process a bit with nrow
function.

Regards
Petr



> -----Original Message-----
> From: Justin Delahunty [mailto:ACU at genius.net.au]
> Sent: Friday, July 26, 2013 3:34 PM
> To: PIKAL Petr; 'Justin Delahunty'; 'Justin Delahunty';
r-help at r-
> project.org
> Subject: RE: [R] Maintaining data order in factanal with
missing data
> 
> Hi Petr,
> 
> So sorry, I accidentally attached the complete data set
rather than the
> one with missing values. I've attached the correct file to
this email.
> RE:
> init.dfs() being local, I hadn't even thought of that. I've
been away
> from OOP for close to 15 years now, so it might be time to
revise!
> 
> The problem I have is that with missing values the list of
factor
> scores returned (ab.w1.fa$factor.scores) does not map onto
the
> originating data frame (ab.w1.df) as it no longer includes
the cases
> which had missing values. So while the original data set for
ab.w1.df
> contains 154 ordered cases, the factor analysis contains
only 150.
> 
> I am seeking a way to map the values derived from the factor
analysis
> (ab.w1.fa$factor.scores) back to their original ordered
position, so
> that these factor score variables may be merged back into
the master
> data frame (ab.df). A unique ID for each case is available
($dmid)
> which I had thought to use when merging the new variables,
however I
> don't know how to implement this.
> 
> 
> Thanks for your help,
> 
> Justin
> 
> 
> -----Original Message-----
> From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> Sent: Friday, 26 July 2013 10:59 PM
> To: Justin Delahunty; Justin Delahunty; r-help at r-project.org
> Subject: RE: [R] Maintaining data order in factanal with
missing data
> 
> Hi
> 
> Well, the function init.dfs does nothing as all data frames
created
> inside it does not propagate to global environment and there
is nothing
> what the function returns.
> 
> Tha last line (when used outside a function) gives warnings
but there
> is no sign of error.
> 
> When
> 
> > head(ab.1.df)
>   dmid   g5oab2      g53      g54      g55   g5ovb1
> 1    1 1.418932 1.805227 2.791152 3.624116 3.425586
> 2    2 2.293907 1.187830 1.611237 1.748526 3.816533
> 3    3 2.836536 2.679523 1.279639 2.674986 2.452395
> 4    4 1.872259 3.278359 1.785872 2.458315 1.146480
> 5    5 1.467195 1.180747 3.564127 3.007682 2.109506
> 6    6 3.098512 3.151974 3.969379 3.750571 1.497358
> > head(ab.2.df)
>   dmid   w2oab3      w22      w23      w24   w2ovb1
> 1    1 4.831362 5.522764 7.809366 6.969172 7.398385
> 2    2 6.706346 4.101742 1.434697 5.266775 5.357641
> 3    3 3.653806 2.666885 1.209326 5.125556 4.963374
> 4    4 7.221255 7.649152 6.540398 6.648506 2.576081
> 5    5 1.848023 5.044314 2.761881 3.307220 1.454234
> 6    6 7.606429 4.911766 2.034813 2.638573 2.818834
> > head(ab.3.df)
>   dmid   w3oab3   w3oab4   w3oab7   w3oab8   w3ovb1
> 1    1 5.835609 6.108220 6.587721 2.451461 2.785467
> 2    2 4.973198 1.196815 6.388056 1.110877 4.226463
> 3    3 3.800367 6.697287 5.235345 6.666829 6.319073
> 4    4 1.093141 1.477773 2.269252 3.194978 4.916342
> 5    5 1.975060 7.204516 4.825435 1.775874 3.484027
> 6    6 3.273361 2.243805 5.326547 5.720892 6.118723
> >
> 
> > str(ab.1.fa)
> List of 2
>  $ rescaled.scores: Named num [1:154] 3.43 3.83 2.43 1.1
2.08 ...
>   ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
>  $ factor.loadings: Named num [1:5] -0.0106 -0.0227 -0.1093
-0.0912
> 0.9975
>   ..- attr(*, "names")= chr [1:5] "g5oab2" "g53" "g54" "g55"
...
> > str(ab.2.fa)
> List of 2
>  $ rescaled.scores: Named num [1:154] 6.34 5.24 5.3 1.91
2.16 ...
>   ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
>  $ factor.loadings: Named num [1:5] -0.2042 0.0063 -0.2287
-0.0119
> 0.7138
>   ..- attr(*, "names")= chr [1:5] "w2oab3" "w22" "w23" "w24"
...
> > str(ab.3.fa)
> List of 2
>  $ rescaled.scores: Named num [1:154] NaN NaN NaN NaN NaN
NaN NaN NaN
> NaN NaN ...
>   ..- attr(*, "names")= chr [1:154] "1" "2" "3" "4" ...
>  $ factor.loadings: Named num [1:5] -0.1172 0.0128 -0.0968
0.106 0.9975
>   ..- attr(*, "names")= chr [1:5] "w3oab3" "w3oab4" "w3oab7"
"w3oab8"
> ...
> 
> Anyway I have no idea what you consider wrong?
> 
> Regards
> Petr
> 
> 
> 
> > -----Original Message-----
> > From: Justin Delahunty [mailto:ACU at genius.net.au]
> > Sent: Friday, July 26, 2013 2:22 PM
> > To: PIKAL Petr; 'Justin Delahunty'; r-help at r-project.org
> > Subject: RE: [R] Maintaining data order in factanal with
missing data
> >
> > Hi Petr,
> >
> > Thanks for the quick response. Unfortunately I cannot
share the data
> I
> > am working with, however please find attached a suitable R
workspace
> > with generated data. It has the appropriate variable
names, only the
> > data has been changed.
> >
> > The last function in the list (init.dfs()) I call to
subset the
> > overall data set into the three waves, then conduct the
factor
> > analysis on each
> > (1 factor CFA); it's just in a function to ease re-typing
in a new
> > workspace.
> >
> >
> > Thanks,
> >
> > Justin
> >
> > -----Original Message-----
> > From: PIKAL Petr [mailto:petr.pikal at precheza.cz]
> > Sent: Friday, 26 July 2013 7:35 PM
> > To: Justin Delahunty; r-help at r-project.org
> > Subject: RE: [R] Maintaining data order in factanal with
missing data
> >
> > Hi
> >
> > You provided functions, so far so good. But without data
it would be
> > quite difficult to understand what the functions do and
where could
> be
> > the issue.
> >
> > I suspect combination of complete cases selection together
with
> subset
> > and factor behaviour. But I can be completely out of
target too.
> >
> > Petr
> >
> > > -----Original Message-----
> > > From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-
> > > project.org] On Behalf Of s00123776 at myacu.edu.au
> > > Sent: Friday, July 26, 2013 9:35 AM
> > > To: r-help at r-project.org
> > > Subject: [R] Maintaining data order in factanal with
missing data
> > >
> > > Hi,
> > >
> > >
> > >
> > > I'm new to R, so sorry if this is a simple answer. I'm
currently
> > > trying to collapse some ordinal variables into a
composite; the
> > > program ideally should take a data frame as input,
perform a factor
> > > analysis, compute factor scores, sds, etc., and return
the rescaled
> > > scores and loadings. The difficulty I'm having is that
my data set
> > > contains a number of NA, which I am excluding from the
analysis
> > > using complete.cases(), and thus the incomplete cases
are
> "skipped".
> > > These functions are for a longitudinal data set with
repeated waves
> > > of
> > data,
> > > so the final rescaled scores from each wave need to be
saved as
> > > variables grouped by a unique ID (DMID). The functions
I'm trying
> to
> > > implement are as follows:
> > >
> > >
> > >
> > > weighted.sd<-function(x,w){
> > >
> > >                                 sum.w<-sum(w)
> > >
> > >                                 sum.w2<-sum(w^2)
> > >
> > >                                 mean.w<-sum(x*w)/sum(w)
> > >
> > >
> > >
x.sd.w<-sqrt((sum.w/(sum.w^2-sum.w2))*sum(w*(x-mean.w)^2))
> > >
> > >                                 return(x.sd.w)
> > >
> > >                                 }
> > >
> > >
> > >
> > > re.scale<-function(f.scores, raw.data, loadings){
> > >
> > >
> > > fz.scores<-(f.scores+mean(f.scores))/(sd(f.scores))
> > >
> > >
> > > means<-apply(raw.data,1,weighted.mean,w=loadings)
> > >
> > >
> > > sds<-apply(raw.data,1,weighted.sd,w=loadings)
> > >
> > >                                 grand.mean<-mean(means)
> > >
> > >                                 grand.sd<-mean(sds)
> > >
> > >
> > > final.scores<-((fz.scores*grand.sd)+grand.mean)
> > >
> > >                                 return(final.scores)
> > >
> > >                                 }
> > >
> > >
> > >
> > > get.scores<-function(data){
> > >
> > >
> > > fact<-
> > >
factanal(data[complete.cases(data),],factors=1,scores="regress
ion")
> > >
> > >
f.scores<-fact$scores[,1]
> > >
> > >
f.loads<-fact$loadings[,1]
> > >
> > >
rescaled.scores<-re.scale(f.scores,
> > > data[complete.cases(data),], f.loads)
> > >
> > >
output.list<-list(rescaled.scores,
> > > f.loads)
> > >
> > >                                 names(output.list)<-
> > > c("rescaled.scores",
> > > "factor.loadings")
> > >
> > >                                 return(output.list)
> > >
> > >                                 }
> > >
> > >
> > >
> > > init.dfs<-function(){
> > >
> > >
> > > ab.1.df<-subset(ab.df,,select=c(dmid,g5oab2:g5ovb1))
> > >
> > >
> > > ab.2.df<-subset(ab.df,,select=c(dmid,w2oab3:w2ovb1))
> > >
> > >
> > > ab.3.df<-subset(ab.df,,select=c(dmid,
> > > w3oab3, w3oab4, w3oab7, w3oab8, w3ovb1))
> > >
> > >
> > >
> > >
ab.1.fa<-get.scores(ab.1.df[-1])
> > >
> > >
ab.2.fa<-get.scores(ab.2.df[-1])
> > >
> > >
ab.3.fa<-get.scores(ab.3.df[-1])
> > >
> > >
> > >                                 }
> > >
> > >
> > >
> > > Thanks for your help,
> > >
> > >
> > >
> > > Justin
> > >
> > >
> > > 	[[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-help at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-help
> > > PLEASE do read the posting guide
http://www.R-project.org/posting-
> > > guide.html and provide commented, minimal,
self-contained,
> > > reproducible code.
> >
> 
> 

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From soumitrodey1 at gmail.com  Fri Jul 26 18:14:22 2013
From: soumitrodey1 at gmail.com (Soumitro Dey)
Date: Fri, 26 Jul 2013 12:14:22 -0400
Subject: [R] X matrix deemed to be singular and cbind
In-Reply-To: <CACk-te1NPEH3C5-xaXu-uhaqYvLYnk_U5hDxoSbrjte89akZSQ@mail.gmail.com>
References: <CAJ+M79nuHvHoiknmOvRoxKf7KBiouQEzvymy4KftUtUE_UEVHQ@mail.gmail.com>
	<CACk-te1NPEH3C5-xaXu-uhaqYvLYnk_U5hDxoSbrjte89akZSQ@mail.gmail.com>
Message-ID: <CAJ+M79=XOUT_nMwsJzCxONihx6ep8CG_8n--DOq5tmPM9tGCMA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/fab377da/attachment.pl>

From jholtman at gmail.com  Fri Jul 26 18:21:38 2013
From: jholtman at gmail.com (jim holtman)
Date: Fri, 26 Jul 2013 12:21:38 -0400
Subject: [R] Saving multiple rda-files as one rda-file
In-Reply-To: <411A664B-596D-46DD-B8A2-74EA128DA8E0@comcast.net>
References: <1374491885996-4672041.post@n4.nabble.com>
	<1374761864513-4672313.post@n4.nabble.com>
	<411A664B-596D-46DD-B8A2-74EA128DA8E0@comcast.net>
Message-ID: <CAAxdm-4XoH_MNsbkVnXh+N+6mb2cybD9M0vqt=eSg9_XXg9M0w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/c53b2491/attachment.pl>

From dwinsemius at comcast.net  Fri Jul 26 18:33:59 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jul 2013 09:33:59 -0700
Subject: [R] How to double integrate a function in R
In-Reply-To: <39811.186.215.164.146.1374853459.squirrel@webmail.mbe.bio.br>
References: <39811.186.215.164.146.1374853459.squirrel@webmail.mbe.bio.br>
Message-ID: <38D0D3F0-3188-47EF-8619-B3E7A036F24A@comcast.net>


On Jul 26, 2013, at 8:44 AM, Tiago V. Pereira wrote:

> I am trying to double integrate the following expression:
> 
> #  expression
> (1/(2*pi))*exp(-y2/2)*sqrt((y1/(y2-y1)))
> 
> for y2>y1>0.
> 
> I am trying the following approach
> 
> # first attempt
> 
> library(cubature)
>    fun <- function(x)   { (1/(2*pi))*exp(-x[2]/2)*sqrt((x[1]/(x[2]-x[1])))}
>    adaptIntegrate(fun, lower = c(0,0), upper =c(5, 6), tol=1e-8)
> 
> However, I don't know how to constrain the integration so that y2>y1>0.

Generally incorporating boundaries is accomplished by multiplying the integrand with logical vectors that encapsulate what are effectively two conditions: Perhaps:

 fun <- function(x)   { (x[1]<x[2])*(x[1]>0)* (1/(2*pi))*exp(-x[2]/2)* sqrt((x[1]/(x[2]-x[1])))}

That was taking quite a long time and I interrupted it. There were quite a few warnings of the sort
1: In sqrt((x[1]/(x[2] - x[1]))) : NaNs produced
2: In sqrt((x[1]/(x[2] - x[1]))) : NaNs produced

Thinking the NaNs might sabotage the integration process, I added a conditional to the section of that expression that was generating the NaNs. I don't really know whether NaN's are excluded from the summation process in adaptIntegrate:

 fun <- function(x)   { (x[1]<x[2])*(x[1]>0)* (1/(2*pi))*exp(-x[2]/2)*
                              if(x[1]>x[2]){ 0 }else{ sqrt((x[1]/(x[2]-x[1])) )} }
 adaptIntegrate(fun, lower = c(0,0), upper =c(5, 6) )

I still didn't have the patience to wait for an answer, but I did plot the function:

fun2 <- function(x,y)   { (x<y)*(x>0)* (1/(2*pi))*exp(-y/2)* sqrt((x/(y-x)))}
persp(outer(0:5, 0:6, fun2) )

So at least the function is finite over most of its domain.

-- 

David Winsemius
Alameda, CA, USA


From nfmcclure at gmail.com  Fri Jul 26 18:43:32 2013
From: nfmcclure at gmail.com (Nick McClure)
Date: Fri, 26 Jul 2013 09:43:32 -0700
Subject: [R] Externalptr class to character class from (web) scrape
Message-ID: <CAJb9FVx7GOKaKemOfENVfCF5Z7TErbp3kJTpmLgp02c5C9mhOA@mail.gmail.com>

I'm hitting a wall. When I use the 'scrape' function from the package
'scrapeR' to get the pagesource from a web page, I do the following:
(as an example)

website.doc = parse("http://www.google.com")

When I look at it, it seems fine:

website.doc[[1]]

This seems to have the information I need.  Then when I try to get it
into a character vector,

character.website = as.character(website.doc[[1]])

I get the error:

Error in as.vector(x, "character") :
cannot coerce type 'externalptr' to vector of type 'character'

I'm trying very very hard to wrap my head around how to get this
external pointer to a character, but after reading many help files, I
cannot understand how to do this. Any ideas?


From f.harrell at Vanderbilt.Edu  Fri Jul 26 18:58:12 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Fri, 26 Jul 2013 11:58:12 -0500
Subject: [R] Can't figure out why short figure won't work
Message-ID: <51F2AAA4.4040607@vanderbilt.edu>

[Sorry I can't quote past messages as I get mail on Nabble and have been 
told I can't reply through Nabble].

Thanks Kennel for recommended a narrowing range for usr y-limits.  That 
does help quite a bit.

But I found a disappointing aspect of the graphics system: When you 
change height= on the device call you have to change the y-coordinates 
to keep the same absolute vertical positioning.

Frank

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From Gavin.Simpson at uregina.ca  Fri Jul 26 19:01:49 2013
From: Gavin.Simpson at uregina.ca (Gavin Simpson)
Date: Fri, 26 Jul 2013 11:01:49 -0600
Subject: [R] Multiple interaction terms in GAMM-model
In-Reply-To: <1374753371065-4672297.post@n4.nabble.com>
References: <1374753371065-4672297.post@n4.nabble.com>
Message-ID: <1374858109.2386.38.camel@haul.biol.uregina.ca>

On Thu, 2013-07-25 at 04:56 -0700, Jeroen wrote:
> Dear all,
> 
> I am trying to correlate a variable tau1 to a set of other variables (x1,
> x2, x3, x4), taking into account an interaction with time ('doy') and place
> ('region'), and taking into account dependency of data in time per object
> ID. My dataset looks like:

<snip />

> Since the data is dependent in time per objectID, I use a GAMM model with an
> autocorrelation function. Since each variable x1, x2, etc. is dependent on
> time and place, I should incorporate this as well. 
> 
> Therefore I am wondering if the following gamm-model is correct for my
> situation:
> 
> model <- gamm( tau1 ~ te( x1, by= doy ) + te( x1, by= factor( region ) ) +
> ... + te( x4, by= doy ) + te( x4, by= factor( region ) ) + factor( region ),
> correlation= corAR1(form= ~ doy|objectID ), na.action= na.omit ).
> 
> Does anyone know if this is ok? 

The model looks a little odd - the way you've written it you don't need
`te()` smooths. For the interaction with doy, I would try

te(x1, doy, bs = c("cr", "cc"))

assuming x1 and doy are continuous. This specifies cubic splines and
cyclic cubic splines respectively for x1 and doy. I use a cyclic spline
for doy as we might not expect Jan 1st and Dec 31st to be much
different. By separating the interaction between x1 and doy and the one
for x1 and region you are saying that the way the effect of x1 varies
through the year does not change between regions. Is that reasonable?

I think you need something for the objectID - a random effect or a fixed
effect will account for differences in mean values of taul between
objects. A random effect seems most useful otherwise you'll eat into
your degrees of freedom, but you have plenty of those.

The correlation part assumes that the residuals follow an AR(1) applied
within the objects, with each AR(1) having the same coefficient.
Autocorrelation decreases exponentially with lag/separation. It is a
reasonable start. Fitting will be much quicker without this. Could you
try fitting without and then extract the normalised residuals to check
for residual correlation?

I hope you have a lot of memory and a lot of spare time available; my
experience of fitting similarly sized (though not as complex - I had one
*very* long series) was that gamm() used large amounts of RAM (I had
16GB and most was used for a single model) and took many days to fit.
You may find the random effect for object fights with the AR(1) so you
could end up with an odd fit if it fits at all.

You are going to want to turn on verbosity when fitting so you can see
how the optimisation is proceeding. Something like

require(nlme)
## need a control object
ctrl <- lmeControl(msVerbose = TRUE,
                   maxIter = 400,
                   msMaxIter = 400,
                   niterEM = 0, ## this is VERY important for gamm()!
                   tolerance = 1e-8,
                   msTol = 1e-8,
                   msMaxEval = 400)

then add `control = ctrl` to the `gamm()` call.

I would approach the expecting the model to fail to fit so be prepared
to simplify it etc.

Good luck,

G

> Or should I use a model which also includes terms like " te( x1 ) + ... +
> te( x4 )".
> And is the correlation function correct?
> 
> Thanks so much!!
> 
> Jeroen
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Multiple-interaction-terms-in-GAMM-model-tp4672297.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Gavin Simpson, PhD                          [t] +1 306 337 8863
Adjunct Professor, Department of Biology    [f] +1 306 337 2410
Institute of Environmental Change & Society [e] gavin.simpson at uregina.ca
523 Research and Innovation Centre          [tw] @ucfagls
University of Regina
Regina, SK S4S 0A2, Canada


From rmh at temple.edu  Fri Jul 26 19:12:38 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Fri, 26 Jul 2013 13:12:38 -0400
Subject: [R] Can't figure out why short figure won't work
In-Reply-To: <51F2AAA4.4040607@vanderbilt.edu>
References: <51F2AAA4.4040607@vanderbilt.edu>
Message-ID: <CAGx1TMDqiZ2UrFhZ=9k+MBZL7F2S3d2q3LRhgOZuXsNgLdawhg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/a851c9a7/attachment.pl>

From dwinsemius at comcast.net  Fri Jul 26 19:21:24 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jul 2013 10:21:24 -0700
Subject: [R] How to double integrate a function in R
In-Reply-To: <38D0D3F0-3188-47EF-8619-B3E7A036F24A@comcast.net>
References: <39811.186.215.164.146.1374853459.squirrel@webmail.mbe.bio.br>
	<38D0D3F0-3188-47EF-8619-B3E7A036F24A@comcast.net>
Message-ID: <B43A7491-07A6-404D-8AE5-FB9CCB75B163@comcast.net>


On Jul 26, 2013, at 9:33 AM, David Winsemius wrote:

> fun2 <- function(x,y)   { (x<y)*(x>0)* (1/(2*pi))*exp(-y/2)* sqrt((x/(y-x)))}
> persp(outer(0:5, 0:6, fun2) )

There does seem to be some potential pathology at the edges of the range, Restricting it to x >= 0.03 removes most of that concern. 

fun2 <- function(x,y)   { (x<y)*(x>0)* (1/(2*pi))*exp(-y/2)* sqrt((x/(y-x)))}
persp(outer(seq(0.01,5,by=.01), seq(.02,6,by=.01), fun2) ,ticktype="detailed")


> fun <- function(x)   { (x[1]<x[2])*(x[1]>0)* (1/(2*pi))*exp(-x[2]/2)*if(x[1]>x[2]){0}else{ sqrt((x[1]/(x[2]-x[1])) )}}
>   adaptIntegrate(fun, lower = c(0.03,0.03), upper =c(5, 6), tol=1e-2 )
$integral
[1] 0.7605703

$error
[1] 0.00760384

$functionEvaluations
[1] 190859

$returnCode
[1] 0

I tried decreasing the tolerance to 1e-3 but the wait exceeds the patience I have allocated to the problem.

-- 
David Winsemius
Alameda, CA, USA


From murdoch.duncan at gmail.com  Fri Jul 26 19:26:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Jul 2013 13:26:11 -0400
Subject: [R] Externalptr class to character class from (web) scrape
In-Reply-To: <CAJb9FVx7GOKaKemOfENVfCF5Z7TErbp3kJTpmLgp02c5C9mhOA@mail.gmail.com>
References: <CAJb9FVx7GOKaKemOfENVfCF5Z7TErbp3kJTpmLgp02c5C9mhOA@mail.gmail.com>
Message-ID: <51F2B133.1080802@gmail.com>

On 26/07/2013 12:43 PM, Nick McClure wrote:
> I'm hitting a wall. When I use the 'scrape' function from the package
> 'scrapeR' to get the pagesource from a web page, I do the following:
> (as an example)
>
> website.doc = parse("http://www.google.com")
>
> When I look at it, it seems fine:
>
> website.doc[[1]]
>
> This seems to have the information I need.  Then when I try to get it
> into a character vector,
>
> character.website = as.character(website.doc[[1]])
>
> I get the error:
>
> Error in as.vector(x, "character") :
> cannot coerce type 'externalptr' to vector of type 'character'
>
> I'm trying very very hard to wrap my head around how to get this
> external pointer to a character, but after reading many help files, I
> cannot understand how to do this. Any ideas?

You should use str() in cases like this. When I look at 
str(website.doc[[1]]) (after producing website.doc with scrape(), not 
parse()), I see

 > str(website.doc[[1]])
Classes 'HTMLInternalDocument', 'HTMLInternalDocument', 
'XMLInternalDocument', 'XMLAbstractDocument' <externalptr>
- attr(*, "headers")= Named chr [1:2] "<HTML><HEAD><meta 
http-equiv=\"content-type\" 
content=\"text/html;charset=utf-8\">\n<TITLE>302 
Moved</TITLE></HEAD><BODY>\n<H1>"| __truncated__ "</BODY></HTML>"
..- attr(*, "names")= chr [1:2] "<HTML><HEAD><meta 
http-equiv=\"content-type\" 
content=\"text/html;charset=utf-8\">\n<TITLE>302 
Moved</TITLE></HEAD><BODY>\n<H1>"| __truncated__ "</BODY></HTML>"

So it is an external pointer with a number of classes. One or more of 
those will have a print method. methods(print) will list all the print 
methods, and I see there's a (hidden) print.XMLInternalDocument method 
somewhere. Then

 > getAnywhere("print.XMLInternalDocument")
A single object matching ?print.XMLInternalDocument? was found
It was found in the following places
registered S3 method for print from namespace XML
namespace:XML
with value

function (x, ...)
{
cat(as(x, "character"), "\n")
}
<environment: namespace:XML>

shows that the as() generic should work, even though as.character() 
doesn't, and indeed as(website.doc[[1]], "character") does display 
something.

Duncan Murdoch


From murdoch.duncan at gmail.com  Fri Jul 26 19:32:41 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 26 Jul 2013 13:32:41 -0400
Subject: [R] Externalptr class to character class from (web) scrape
In-Reply-To: <51F2B133.1080802@gmail.com>
References: <CAJb9FVx7GOKaKemOfENVfCF5Z7TErbp3kJTpmLgp02c5C9mhOA@mail.gmail.com>
	<51F2B133.1080802@gmail.com>
Message-ID: <51F2B2B9.704@gmail.com>

By the way, here's a quicker (but slightly more dangerous) way to find the

print.XMLInternalDocument


function:  just call debug(print) before printing the object.  Two steps 
take you to the method, and let you see what it's doing. The "danger" 
comes because now print() will always trigger the debugger, which can be 
a little confusing!  Remember undebug(print) at the end.

Duncan Murdoch


On 26/07/2013 1:26 PM, Duncan Murdoch wrote:
> On 26/07/2013 12:43 PM, Nick McClure wrote:
> > I'm hitting a wall. When I use the 'scrape' function from the package
> > 'scrapeR' to get the pagesource from a web page, I do the following:
> > (as an example)
> >
> > website.doc = parse("http://www.google.com")
> >
> > When I look at it, it seems fine:
> >
> > website.doc[[1]]
> >
> > This seems to have the information I need.  Then when I try to get it
> > into a character vector,
> >
> > character.website = as.character(website.doc[[1]])
> >
> > I get the error:
> >
> > Error in as.vector(x, "character") :
> > cannot coerce type 'externalptr' to vector of type 'character'
> >
> > I'm trying very very hard to wrap my head around how to get this
> > external pointer to a character, but after reading many help files, I
> > cannot understand how to do this. Any ideas?
>
> You should use str() in cases like this. When I look at
> str(website.doc[[1]]) (after producing website.doc with scrape(), not
> parse()), I see
>
>   > str(website.doc[[1]])
> Classes 'HTMLInternalDocument', 'HTMLInternalDocument',
> 'XMLInternalDocument', 'XMLAbstractDocument' <externalptr>
> - attr(*, "headers")= Named chr [1:2] "<HTML><HEAD><meta
> http-equiv=\"content-type\"
> content=\"text/html;charset=utf-8\">\n<TITLE>302
> Moved</TITLE></HEAD><BODY>\n<H1>"| __truncated__ "</BODY></HTML>"
> ..- attr(*, "names")= chr [1:2] "<HTML><HEAD><meta
> http-equiv=\"content-type\"
> content=\"text/html;charset=utf-8\">\n<TITLE>302
> Moved</TITLE></HEAD><BODY>\n<H1>"| __truncated__ "</BODY></HTML>"
>
> So it is an external pointer with a number of classes. One or more of
> those will have a print method. methods(print) will list all the print
> methods, and I see there's a (hidden) print.XMLInternalDocument method
> somewhere. Then
>
>   > getAnywhere("print.XMLInternalDocument")
> A single object matching ?print.XMLInternalDocument? was found
> It was found in the following places
> registered S3 method for print from namespace XML
> namespace:XML
> with value
>
> function (x, ...)
> {
> cat(as(x, "character"), "\n")
> }
> <environment: namespace:XML>
>
> shows that the as() generic should work, even though as.character()
> doesn't, and indeed as(website.doc[[1]], "character") does display
> something.
>
> Duncan Murdoch
>
>
>


From ross at biostat.ucsf.edu  Fri Jul 26 20:08:18 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 26 Jul 2013 11:08:18 -0700
Subject: [R] Error: Line starting ' ...' is malformed!
Message-ID: <201307261108.18883.ross@biostat.ucsf.edu>

A DESCRIPTION file begins with 0xFFFE and
$ file DESCRIPTION 
DESCRIPTION: Little-endian UTF-16 Unicode text, with CRLF, CR line terminators

I think it was created on Windows.

In R (2,15,1 on Debian GNU/Linux), using roxygen2, I get
> roxygenize("../GitHub/mice")
Error: Line starting '??P ...' is malformed!

Enter a frame number, or 0 to exit   

1: roxygenize("../GitHub/mice")
2: read.description(DESCRIPTION)
3: read.dcf(file)

Selection: 3
Called from: read.description(DESCRIPTION)
Browse[1]> Q

I'm not sure if the first 2 characters after line starting ', which are octal 
377, 376, will survive email; I stripped them out of the subject line.

The files (DESCRIPTION isn't the only one) have also caused trouble for git 
(even on  Windows 7), since it thinks they are binary.

Any advice about what to do?

I'm reluctant to change the format of the files because it's not my package.

Ross Boylan


From smartpink111 at yahoo.com  Fri Jul 26 20:19:16 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 11:19:16 -0700 (PDT)
Subject: [R] Pairwise comparison between columns, logic
In-Reply-To: <1374851928.44787.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <16537728.95738.1374845250639.JavaMail.nabble@joe.nabble.com>	<1374845344.46982.YahooMailNeo@web142606.mail.bf1.yahoo.com>
	<CANsTkzw=VMXo9TnoYdh=mQSf8cGKdX11mo9sMN2T7jY188S7jA@mail.gmail.com>
	<1374851928.44787.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1374862756.14544.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
Using the example code without removing CEBPA:
gset<- read.table("Names.txt",header=TRUE,stringsAsFactors=FALSE)
?temp1<- read.table("Data.txt",header=TRUE,stringsAsFactors=FALSE)
lst1<-split(temp1,temp1$Names)
mat1<-combn(gset[,1],2) 
library(plyr)
lst2<-lapply(split(mat1,col(mat1)),function(x){lst1[x][all(lapply(lst1[x],length)==2)]})
lst3<-lapply(lst2[lapply(lst2,length)==2],function(x) {x1<- join_all(x,by="patient_id",type="inner");x2<-x1["patient_id"];row.names(x2)<-if(nrow(x1)!=0) paste(x1[,1],x1[,3],1:nrow(x1),sep="_") else NULL;x2 })
?Reduce(rbind,lst3)
#?????????????????? patient_id
#DNMT3A_FLT3_1 LAML-AB-2811-TB
#DNMT3A_FLT3_2 LAML-AB-2816-TB
#DNMT3A_FLT3_3 LAML-AB-2818-TB
#DNMT3A_IDH1_1 LAML-AB-2802-TB
#DNMT3A_IDH1_2 LAML-AB-2822-TB
#DNMT3A_NPM1_1 LAML-AB-2802-TB
#DNMT3A_NPM1_2 LAML-AB-2809-TB
#DNMT3A_NPM1_3 LAML-AB-2811-TB
#DNMT3A_NPM1_4 LAML-AB-2816-TB
#DNMT3A_NRAS_1 LAML-AB-2816-TB
#FLT3_NPM1_1?? LAML-AB-2811-TB
#FLT3_NPM1_2?? LAML-AB-2812-TB
#FLT3_NPM1_3?? LAML-AB-2816-TB
#FLT3_NRAS_1?? LAML-AB-2816-TB
#IDH1_NPM1_1?? LAML-AB-2802-TB
#NPM1_NRAS_1?? LAML-AB-2816-TB




########From your original dataset:
gset<- read.table("SampleGenes.txt",header=TRUE,stringsAsFactors=FALSE) 
temp0<- read.table("LAML-TB.final_analysis_set.txt",header=TRUE,stringsAsFactors=FALSE,sep="\t") 
?temp1<- temp0[,c("Hugo_Symbol","firehose_patient_id")]
?str(temp1)
#'data.frame':??? 2221 obs. of? 2 variables:
# $ Hugo_Symbol??????? : chr? "TBX15" "TCHHL1" "DNMT3A" "IDH1" ...
# $ firehose_patient_id: chr? "LAML-AB-2802-TB" "LAML-AB-2802-TB" "LAML-AB-2802-TB" "LAML-AB-2802-TB" ...
lst1<-split(temp1,temp1$Hugo_Symbol) 
?length(lst1)
#[1] 1607
mat1<-combn(gset[,1],2) # Generate all
lst2<-lapply(split(mat1,col(mat1)),function(x){lst1[x][all(lapply(lst1[x],length)==2)]}) 
?length(lst2)
#[1] 105


?lst3<-lapply(lst2[lapply(lst2,length)==2],function(x) {x1<- join_all(x,by="firehose_patient_id",type="inner");x2<-x1["firehose_patient_id"];row.names(x2)<-if(nrow(x1)!=0) paste(x1[,1],x1[,3],1:nrow(x1),sep="_") else NULL;x2 })
res<-Reduce(rbind,lst3)
?nrow(res)
#[1] 234
head(res)
#??????????? firehose_patient_id
#NPM1_FLT3_1???? LAML-AB-2811-TB
#NPM1_FLT3_2???? LAML-AB-2812-TB
#NPM1_FLT3_3???? LAML-AB-2816-TB
#NPM1_FLT3_4???? LAML-AB-2818-TB
#NPM1_FLT3_5???? LAML-AB-2825-TB
#NPM1_FLT3_6???? LAML-AB-2836-TB




Regarding your second question:
setdiff(gset[,1],unique(temp1[,1])) # CEBPA was not found in the temp1[,1]
#[1] "CEBPA"
mat2<- combn(gset[-5,1],2)
vec1<- apply(mat2,2,paste,collapse="_")
vec2<-unique(gsub("(.*\\_.*)\\_.*","\\1",row.names(res)))
setdiff(vec1,vec2)
?#[1] "NPM1_TP53"?? "NPM1_EZH2"?? "NPM1_RUNX1"? "NPM1_ASXL1"? "NPM1_KDM6A" 
?#[6] "FLT3_TP53"?? "FLT3_EZH2"?? "FLT3_KRAS"?? "FLT3_ASXL1"? "FLT3_KDM6A" 
#[11] "IDH1_TP53"?? "IDH1_KRAS"?? "NRAS_IDH2"?? "NRAS_KRAS"?? "NRAS_ASXL1" 
#[16] "NRAS_KDM6A"? "TP53_EZH2"?? "TP53_IDH2"?? "TP53_RUNX1"? "TP53_KRAS"? 
#[21] "TP53_WT1"??? "TP53_ASXL1"? "TP53_KDM6A"? "EZH2_IDH2"?? "EZH2_WT1"?? 
#[26] "EZH2_ASXL1"? "EZH2_KDM6A"? "IDH2_TET2"?? "IDH2_KDM6A"? "RUNX1_KDM6A"
#[31] "KRAS_WT1"??? "KRAS_KDM6A"? "WT1_ASXL1"?? "WT1_TET2"??? "WT1_KDM6A"? 
#[36] "ASXL1_TET2"? "ASXL1_KDM6A" "TET2_KDM6A" 
A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Manisha <manishabh77 at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Friday, July 26, 2013 11:18 AM
Subject: Re: Pairwise comparison between columns, logic

Hi Manisha,
I didn't run your dataset as I am on the way to college.? But, from the error reported, I think it will be due to some missing combinations in one of the dataset.? For ex. if you run my previous code without removing CEBPA:
ie.
mat1<- combn(gset[,1],2)


lst2<-lapply(split(mat1,col(mat1)),function(x) {x1<-join_all(lst1[x],by="patient_id",type="inner");x1["patient_id"] } )
#Error: All inputs to rbind.fill must be data.frames


So, check whether all the combinations are available in the `lst1`.

2. I will get back to you once I run it.
A.K.





________________________________
From: Manisha <manishabh77 at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Friday, July 26, 2013 11:09 AM
Subject: Re: Pairwise comparison between columns, logic



Hi Arun,
I ran the script on a larger dataset and I seem to be running into this following error:
Error: All inputs to rbind.fill must be data.frames
after the step;
lst2<-lapply(split(mat1,col(mat1)),function(x) {x1<-join_all(lst1[x],by="firehose_patient_id",type="inner");x1["firehose_patient_id"]}) 
I tried a few things to solve the issue but I am not able to. The format of input files and data are same as in the code you posted.
Could you suggest me something?
I have attached my input files on which I am trying to run the code. See attached code as well. Minor changes have been made by me.

2. I have another question. From your code how do also capture those pairs of names that donot have any common patient id?

Thanks again,
-M


On Fri, Jul 26, 2013 at 9:29 AM, arun <smartpink111 at yahoo.com> wrote:

Hi M,
>No problem.
>Regards,
>Arun
>
>
>
>
>----- Original Message -----
>From: "manishabh77 at gmail.com" <manishabh77 at gmail.com>
>To: smartpink111 at yahoo.com
>Cc:
>Sent: Friday, July 26, 2013 9:27 AM
>Subject: Re: Pairwise comparison between columns, logic
>
>Thanks for the code. It is elegant and does what I need. Learnt some new things.
>-M
>
>
>_____________________________________
>Sent from http://r.789695.n4.nabble.com
>??


From manishabh77 at gmail.com  Fri Jul 26 20:32:29 2013
From: manishabh77 at gmail.com (biobee)
Date: Fri, 26 Jul 2013 11:32:29 -0700 (PDT)
Subject: [R] Pairwise comparison between columns, logic
In-Reply-To: <1374862756.14544.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <1374783070174-4672356.post@n4.nabble.com>
	<1374851928.44787.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1374862756.14544.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CANsTkzwP+xC85Y6B0_+=EKMaUy7DpDzvvZgRWKPSewY2GtsQuA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/079e1d42/attachment.pl>

From ligges at statistik.tu-dortmund.de  Fri Jul 26 20:51:48 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 26 Jul 2013 20:51:48 +0200
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>
Message-ID: <51F2C544.8030809@statistik.tu-dortmund.de>



On 25.07.2013 21:05, vanessa van der vaart wrote:
> Hi everybody,,
> I have a question about R function duplicated(). I have spent days try to
> figure this out,but I cant find any solution yet. I hope somebody can help
> me..
> this is my data:
>
> subj=c(1,1,1,2,2,3,3,3,4,4)
> response=c('sample','sample','buy','sample','buy','sample','
> sample','buy','sample','buy')
> product=c(1,2,3,2,2,3,2,1,1,4)
> tt=data.frame(subj, response, product)
>
> the data look like this:
>
>   subj response product
> 1     1   sample       1
> 2     1   sample       2
> 3     1      buy          3
> 4     2   sample       2
> 5     2         buy       2
> 6     3   sample       3
> 7     3   sample       2
> 8     3         buy       1
> 9     4  sample       1
> 10   4       buy        4
>
> I want to create new  column based on the value on response and product
> column. if the value on product is duplicated, then  the value on new column
> is 1, otherwise is 0.


According to your description:

tt$newcolumn <- as.integer(duplicated(tt$product) & tt$response=="buy")

which is different from what you show us below, where I cannot derive 
any systematic rule from.

Uwe Ligges

> but I want to add conditional statement that the value on product column
> will only be considered as duplicated if the value on response column is
> 'buy'.
> for illustration, the table should look like this:
>
> subj response product newcolumn
> 1     1   sample       1          0
> 2     1   sample       2          0
> 3     1      buy          3          0
> 4     2   sample       2          0
> 5     2         buy       2          0
> 6     3   sample       3          1
> 7     3   sample       2           1
> 8     3         buy       1           0
> 9     4  sample       1            1
> 10   4       buy       4             0
>
>
> can somebody help me?
> any help will be appreciated.
> I am new in this mailing list, so forgive me in advance, If I did not  ask
> the question appropriately.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From nicola.rossi20 at gmail.com  Fri Jul 26 21:06:29 2013
From: nicola.rossi20 at gmail.com (Nicola Rossi)
Date: Fri, 26 Jul 2013 21:06:29 +0200
Subject: [R] SpatialPolygonsDataFrame and unique()
Message-ID: <CAAkGiTUfAB=hy63ET3jJnPC44AMOE04=rmiXi67rreCuGUXcCA@mail.gmail.com>

Thank you very much for the help, that's what I was looking for!

Also my apologies for sending an html, I thought I turned it off
(hopefully this time works).

Best regards,

Nicola


From yelin at lbl.gov  Fri Jul 26 21:21:23 2013
From: yelin at lbl.gov (Ye Lin)
Date: Fri, 26 Jul 2013 12:21:23 -0700
Subject: [R] add different regression lines for groups on ggplot
Message-ID: <CAAvu=bkQ-itDQUgT_FJMupcGRxvTf+ufgsDRs9XM9H2KhxmLjA@mail.gmail.com>

Hey All,

I need to apply different regression lines to different group on my ggplot,
and here is the code I use:

qplot(x=Var1,y=Var2,data=df,color=SiteID,group=SiteID)+geom_point()+geom_smooth(method='lm',formula=log(y)~I(1/x),se=FALSE,size=2)

However the regression for different groups is as below:

AL1/AL2: log(y)~I(1/x)
AL3: log(y)~log(x)

How can I apply each regression equation on the same ggplot?

Also I have an issue that if I use the code above, the regression lines are
not overlapped on top of my data points.

Thanks for your help!

From reith_william at bah.com  Fri Jul 26 22:51:44 2013
From: reith_william at bah.com (wwreith)
Date: Fri, 26 Jul 2013 13:51:44 -0700 (PDT)
Subject: [R] readTiff - Sorry can't handle images with 32-bit samples
Message-ID: <1374871904863-4672465.post@n4.nabble.com>

I tried using readTiff() and got the error message "Sorry can't handle images
with 32-bit samples"

line of code

x <- readTiff("C:/Users/550062/Desktop/Data/example1.tif")

So far I have not had any luck finding this error message on google. Any
guess at what it means and how to get the code to work?

Thanks!



--
View this message in context: http://r.789695.n4.nabble.com/readTiff-Sorry-can-t-handle-images-with-32-bit-samples-tp4672465.html
Sent from the R help mailing list archive at Nabble.com.


From dwinsemius at comcast.net  Fri Jul 26 23:06:03 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jul 2013 14:06:03 -0700
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <51F2C544.8030809@statistik.tu-dortmund.de>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>
	<51F2C544.8030809@statistik.tu-dortmund.de>
Message-ID: <AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>


On Jul 26, 2013, at 11:51 AM, Uwe Ligges wrote:

> 
> 
> On 25.07.2013 21:05, vanessa van der vaart wrote:
>> Hi everybody,,
>> I have a question about R function duplicated(). I have spent days try to
>> figure this out,but I cant find any solution yet. I hope somebody can help
>> me..
>> this is my data:
>> 
>> subj=c(1,1,1,2,2,3,3,3,4,4)
>> response=c('sample','sample','buy','sample','buy','sample','
>> sample','buy','sample','buy')
>> product=c(1,2,3,2,2,3,2,1,1,4)
>> tt=data.frame(subj, response, product)
>> 
>> the data look like this:
>> 
>>  subj response product
>> 1     1   sample       1
>> 2     1   sample       2
>> 3     1      buy          3
>> 4     2   sample       2
>> 5     2         buy       2
>> 6     3   sample       3
>> 7     3   sample       2
>> 8     3         buy       1
>> 9     4  sample       1
>> 10   4       buy        4
>> 
>> I want to create new  column based on the value on response and product
>> column. if the value on product is duplicated, then  the value on new column
>> is 1, otherwise is 0.
> 
> 
> According to your description:
> 

Agree that the description did not match the output. I tried to match the output using a rule that could be expressed as: 

 if( a "buy"- associated "product" value precedes the current "product" value){1}else{0}

-- 
David.

> tt$newcolumn <- as.integer(duplicated(tt$product) & tt$response=="buy")
> 
> which is different from what you show us below, where I cannot derive any systematic rule from.
> 
> Uwe Ligges
> 
>> but I want to add conditional statement that the value on product column
>> will only be considered as duplicated if the value on response column is
>> 'buy'.
>> for illustration, the table should look like this:
>> 
>> subj response product newcolumn
>> 1     1   sample       1          0
>> 2     1   sample       2          0
>> 3     1      buy          3          0
>> 4     2   sample       2          0
>> 5     2         buy       2          0
>> 6     3   sample       3          1
>> 7     3   sample       2           1
>> 8     3         buy       1           0
>> 9     4  sample       1            1
>> 10   4       buy       4             0
>> 
>> 
>> can somebody help me?
>> any help will be appreciated.
>> I am new in this mailing list, so forgive me in advance, If I did not  ask
>> the question appropriately.
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Fri Jul 26 23:16:34 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jul 2013 14:16:34 -0700
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>
	<51F2C544.8030809@statistik.tu-dortmund.de>
	<AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>
Message-ID: <7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>


On Jul 26, 2013, at 2:06 PM, David Winsemius wrote:

> 
> On Jul 26, 2013, at 11:51 AM, Uwe Ligges wrote:
> 
>> 
>> 
>> On 25.07.2013 21:05, vanessa van der vaart wrote:
>>> Hi everybody,,
>>> I have a question about R function duplicated(). I have spent days try to
>>> figure this out,but I cant find any solution yet. I hope somebody can help
>>> me..
>>> this is my data:
>>> 
>>> subj=c(1,1,1,2,2,3,3,3,4,4)
>>> response=c('sample','sample','buy','sample','buy','sample','
>>> sample','buy','sample','buy')
>>> product=c(1,2,3,2,2,3,2,1,1,4)
>>> tt=data.frame(subj, response, product)
>>> 
>>> the data look like this:
>>> 
>>> subj response product
>>> 1     1   sample       1
>>> 2     1   sample       2
>>> 3     1      buy          3
>>> 4     2   sample       2
>>> 5     2         buy       2
>>> 6     3   sample       3
>>> 7     3   sample       2
>>> 8     3         buy       1
>>> 9     4  sample       1
>>> 10   4       buy        4
>>> 
>>> I want to create new  column based on the value on response and product
>>> column. if the value on product is duplicated, then  the value on new column
>>> is 1, otherwise is 0.
>> 
>> 
>> According to your description:
>> 
> 
> Agree that the description did not match the output. I tried to match the output using a rule that could be expressed as: 
> 
> if( a "buy"- associated "product" value precedes the current "product" value){1}else{0}
> 

So this delivers the specified output:

tt$rown <- rownames(tt)
as.numeric ( apply(tt, 1, function(x) { 
     x['product'] %in% tt[ rownames(tt) < x['rown'] & tt$response == "buy", "product"]  } ) )

# [1] 0 0 0 0 0 1 1 0 1 0

> -- 
> David.
> 
>> tt$newcolumn <- as.integer(duplicated(tt$product) & tt$response=="buy")
>> 
>> which is different from what you show us below, where I cannot derive any systematic rule from.
>> 
>> Uwe Ligges
>> 
>>> but I want to add conditional statement that the value on product column
>>> will only be considered as duplicated if the value on response column is
>>> 'buy'.
>>> for illustration, the table should look like this:
>>> 
>>> subj response product newcolumn
>>> 1     1   sample       1          0
>>> 2     1   sample       2          0
>>> 3     1      buy          3          0
>>> 4     2   sample       2          0
>>> 5     2         buy       2          0
>>> 6     3   sample       3          1
>>> 7     3   sample       2           1
>>> 8     3         buy       1           0
>>> 9     4  sample       1            1
>>> 10   4       buy       4             0
>>> 
>>> 
>>> can somebody help me?
>>> any help will be appreciated.
>>> I am new in this mailing list, so forgive me in advance, If I did not  ask
>>> the question appropriately.
>>> 
>>> 	[[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From tal.galili at gmail.com  Fri Jul 26 23:41:48 2013
From: tal.galili at gmail.com (Tal Galili)
Date: Sat, 27 Jul 2013 00:41:48 +0300
Subject: [R] Is it possible (/reasonable) to write an as.RefClass function
 for R "list" class?
Message-ID: <CANdJ3dUz48hWG3wD2kz-iqACrjAkeaq84WV-Xd7ZfndVeuqurw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130727/54effc6b/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Fri Jul 26 23:57:46 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 26 Jul 2013 14:57:46 -0700
Subject: [R] readTiff - Sorry can't handle images with 32-bit samples
In-Reply-To: <1374871904863-4672465.post@n4.nabble.com>
References: <1374871904863-4672465.post@n4.nabble.com>
Message-ID: <49d59665-a65d-472b-bf04-c44538c48846@email.android.com>

Try reading a different file. The error message says the existing code cannot read that file.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

wwreith <reith_william at bah.com> wrote:
>I tried using readTiff() and got the error message "Sorry can't handle
>images
>with 32-bit samples"
>
>line of code
>
>x <- readTiff("C:/Users/550062/Desktop/Data/example1.tif")
>
>So far I have not had any luck finding this error message on google.
>Any
>guess at what it means and how to get the code to work?
>
>Thanks!
>
>
>
>--
>View this message in context:
>http://r.789695.n4.nabble.com/readTiff-Sorry-can-t-handle-images-with-32-bit-samples-tp4672465.html
>Sent from the R help mailing list archive at Nabble.com.
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From peter.langfelder at gmail.com  Sat Jul 27 00:08:16 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Fri, 26 Jul 2013 15:08:16 -0700
Subject: [R] readTiff - Sorry can't handle images with 32-bit samples
In-Reply-To: <1374871904863-4672465.post@n4.nabble.com>
References: <1374871904863-4672465.post@n4.nabble.com>
Message-ID: <CA+hbrhVOWvZzQk8-t8CqHtaAHG2E0u=eV4UdvHrC__y3PfPwHg@mail.gmail.com>

Disclaimer: I haven't seen your tif file and I know nothing about
readTiff... but here go some general comments.

TIF files can use different bit depths (number of bits to store each
pixel (or each color for each pixel). Most common software outputs 8-
or 16-bits, but your file probably has a higher bit depth of 32 bits
per sample. Apparently readTiff cannot handle such bit depth.

You may need to convert the 32-bit delth file(s) into 16-bit depth (or
whatever readTiff can handle). My suggestion would be to look at
ImageMagick, but you may also be able to use some image editing
applications to do that,

Peter

On Fri, Jul 26, 2013 at 1:51 PM, wwreith <reith_william at bah.com> wrote:
> I tried using readTiff() and got the error message "Sorry can't handle images
> with 32-bit samples"
>
> line of code
>
> x <- readTiff("C:/Users/550062/Desktop/Data/example1.tif")
>
> So far I have not had any luck finding this error message on google. Any
> guess at what it means and how to get the code to work?
>
> Thanks!
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/readTiff-Sorry-can-t-handle-images-with-32-bit-samples-tp4672465.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil at dcn.davis.CA.us  Sat Jul 27 00:17:06 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Fri, 26 Jul 2013 15:17:06 -0700
Subject: [R] Is it possible (/reasonable) to write an as.RefClass
	function for R "list" class?
In-Reply-To: <CANdJ3dUz48hWG3wD2kz-iqACrjAkeaq84WV-Xd7ZfndVeuqurw@mail.gmail.com>
References: <CANdJ3dUz48hWG3wD2kz-iqACrjAkeaq84WV-Xd7ZfndVeuqurw@mail.gmail.com>
Message-ID: <b112bfd0-e737-468a-855c-966fa1dbb819@email.android.com>

Reference classes are implemented with environment objects, which are mutable. Once you convert to list, the converted object is not mutable, since there is no such thing as a mutable list. So I would say your request is not possible.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Tal Galili <tal.galili at gmail.com> wrote:
>Hello all.
>
>
>I am interested in creating a mutable "list" object in R.
>
>Ideally I would do it through something like this:
>
>x <- list(a = list(1:4), b = "miao", c = 4:1)
>x_RC <- as.RefClass(x)
>attr(x_RC[[2]], "I am") <- "string"
>x_RC[[3]] <- x_RC[[3]]+1
>x_new <- as.list(x_RC)
>
>Is that reasonably possible to create? Or does that make
>little/no-sense?
>
>Thanks.
>
>
>
>
>----------------Contact
>Details:-------------------------------------------------------
>Contact me: Tal.Galili at gmail.com |
>Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew)
>|
>www.r-statistics.com (English)
>----------------------------------------------------------------------------------------------
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From jclow at umail.ucsb.edu  Fri Jul 26 23:08:26 2013
From: jclow at umail.ucsb.edu (John W. Clow)
Date: Fri, 26 Jul 2013 21:08:26 +0000
Subject: [R]
 =?windows-1252?q?GGplot_2_=96_cannot_get_histogram_and_box_pl?=
 =?windows-1252?q?ot_axis_to_match=2E?=
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427CD31947A@inbomail.inbo.be>
References: <53F5FA310C439841A76E397AAFF387151E5B3EFC@BY2PRD0811MB439.namprd08.prod.outlook.com>,
	<AA818EAD2576BC488B4F623941DA7427CD31947A@inbomail.inbo.be>
Message-ID: <53F5FA310C439841A76E397AAFF387151E5B4331@BY2PRD0811MB439.namprd08.prod.outlook.com>

Dear Thierry,

Thank you for your help. My code now works the way I wanted it to.

To other readers out there, I think the reason why the two functions work differently is because extend_limits only ensures that the axis includes the coordinates supplied, and does not guarantee that limits will be the coordinates you supplied to the function (they might extend further in some graphs like the heatmap)

Thierry, if any of the above is wrong or incomplete, feel free to correct me or add more details.

John Clow
UCSB Student
________________________________________
From: ONKELINX, Thierry [Thierry.ONKELINX at inbo.be]
Sent: Friday, July 26, 2013 1:03 AM
To: John W. Clow; r-help at r-project.org
Subject: RE: GGplot 2 ? cannot get histogram and box plot axis to match.

Dear John,

Use xlim() and ylim() instead of expand_limits()

library(ggplot2)

#sample data from ggplot2
data(Cars93, package = "MASS")
dataSet <- Cars93

#variables to calculate the range to extend the axis dataVector <- unlist(dataSet[,"MPG.city"])

dataRange <- diff(range(dataSet$MPG.city))

graphRange <- c(min(dataSet$MPG.city) - dataRange/5,
                max(dataSet$MPG.city) + dataRange/5)

#making the box plot
theBoxPlot <- ggplot(dataSet,aes_string(x = "MPG.city", y = "MPG.city"))

theBoxPlot <-
  theBoxPlot  + geom_boxplot() + coord_flip() + ylim(limits = graphRange)
print(theBoxPlot)


#making the histogram
thePlot <- ggplot(dataSet,aes_string(x = "MPG.city"))
thePlot <- thePlot + geom_histogram()  + xlim(graphRange)
print(thePlot)



ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium
+ 32 2 525 02 51
+ 32 54 43 61 85
Thierry.Onkelinx at inbo.be
www.inbo.be

To call in the statistician after the experiment is done may be no more than asking him to perform a post-mortem examination: he may be able to say what the experiment died of.
~ Sir Ronald Aylmer Fisher

The plural of anecdote is not data.
~ Roger Brinner

The combination of some data and an aching desire for an answer does not ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

-----Oorspronkelijk bericht-----
Van: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] Namens John W. Clow
Verzonden: donderdag 25 juli 2013 20:03
Aan: r-help at r-project.org
Onderwerp: [R] GGplot 2 ? cannot get histogram and box plot axis to match.

Problem:
I am trying to get the histogram and box plot x axis to match. I?ve tried using the expand_limits function to make the axis match but that didn?t make the axis match. The histogram?s axis are still consistently larger than the ones for the box plot (though the function did help). Does anyone have a suggestion as to what I should do instead?


Background:
I am building a Shiny app that displays a histogram below a bar chart for a set of data that a user uploads to the app. If you want to see the app, go here http://spark.rstudio.com/jclow/Archive20130725HistogramApp/
To run the app, select ?Use Sample Data? , then select  ?MPG.city? under choose a column, then finally select box plot.


Sample code:
Below is a snippet of my code to demonstrate the problems I have.

library(ggplot2)

#sample data from ggplot2
data(Cars93, package = "MASS")
dataSet <- Cars93

#variables to calculate the range to extend the axis dataVector <- unlist(dataSet[,"MPG.city"])

dataRange <- max(dataVector) - min(dataVector)

graphRange <- c(min(dataVector) - dataRange/5,
                max(dataVector) + dataRange/5)

#making the box plot
theBoxPlot <- ggplot(dataSet,aes_string(x = "MPG.city",y = "MPG.city"))

theBoxPlot = theBoxPlot  + geom_boxplot() + expand_limits(y= graphRange) + coord_flip()
print(theBoxPlot)


#making the histogram
thePlot <- ggplot(dataSet,aes_string(x = "MPG.city")) thePlot <-thePlot + geom_histogram()  + expand_limits(x= graphRange)

print(thePlot)


Thank you for taking the time to read this.

John Clow
UCSB Student

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
* * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.



From corganbm at gmail.com  Sat Jul 27 00:00:46 2013
From: corganbm at gmail.com (Miller Ruiz)
Date: Fri, 26 Jul 2013 17:00:46 -0500
Subject: [R] Boxcox transformation error
Message-ID: <CAG0be2nmeU9h1mmX7psL48wqHserGHwmQvvTunccWQAOAXdt+w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/b06ba6f6/attachment.pl>

From ross at biostat.ucsf.edu  Sat Jul 27 04:23:10 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Fri, 26 Jul 2013 19:23:10 -0700
Subject: [R] matching columns of model matrix to those in original data.frame
Message-ID: <201307261923.10203.ross@biostat.ucsf.edu>

What is a reliable way to go from a column of a model matrix back to the column (or columns) of the original data source used to make the model 
matrix?  I can come up with a method that seems to work, but I don't see guarantees in the documentation that it will.

In particular, does the order of the term.labels match the order of columns for factors in a terms object?  The documentation says the model.matrix 
assign attribute uses the ordering of terms.labels.

If anyone can tell me if this approach is reliable, or of one that is, I would appreciate it.

Ross Boylan

Proposed function and a little example follow.

# return a vector v such that data[,v[i]] contributed to mm[,i]
# mm = model matrix produced by
# form = formula
# data = data
reverse.map <- function(mm, form, data){
    tt <- terms(form, data=data)
    ttf <- attr(tt, "factors")
    mmi <- attr(mm, "assign")
    # this depends on assign using same order as columns of factors
    # entries in mmi that are 0 (the intercept) are silently dropped
    ttf2 <- ttf[,mmi]
    # take the first row that contributes
    r <- apply(ttf2, 2, function(is) rownames(ttf)[is > 0][1])
    match(r, colnames(data))
}

> ### experiment with mapping model matrix to original columns
> df <- sp2b[sample(nrow(sp2b), 8), c("pEthnic", "ethnic_sg", "rac_gay")]
> form <- ~pEthnic+ethnic_sg*rac_gay
> mm <- model.matrix(form, df)
> tt <- terms(form, data=df)
> ttf <- attr(tt, "factors")
> mmi <- attr(mm, "assign")
> df
      pEthnic ethnic_sg rac_gay
1366 Afr Amer  Afr Amer    3.25
3052 Afr Amer  Afr Amer    1.75
3012   Latino  Afr Amer    2.00
369  Afr Amer  Asian/PI    2.00
529     White  Asian/PI    2.00
194  Asian/PI  Asian/PI    3.25
126     White  Asian/PI    2.25
2147   Latino    Latino    2.75
> colnames(mm)
 [1] "(Intercept)"               "pEthnicAsian/PI"          
 [3] "pEthnicLatino"             "pEthnicOther"             
 [5] "pEthnicWhite"              "ethnic_sgAsian/PI"        
 [7] "ethnic_sgLatino"           "rac_gay"                  
 [9] "ethnic_sgAsian/PI:rac_gay" "ethnic_sgLatino:rac_gay"  
> ttf  # term "factors"
          pEthnic ethnic_sg rac_gay ethnic_sg:rac_gay
pEthnic         1         0       0                 0
ethnic_sg       0         1       0                 1
rac_gay         0         0       1                 1
> mmi  #model matrix "assign"
 [1] 0 1 1 1 1 2 2 3 4 4
> reverse.map(mm, form, df)
[1] 1 1 1 1 2 2 3 2 2


From smartpink111 at yahoo.com  Sat Jul 27 04:45:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 19:45:14 -0700 (PDT)
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>
	<51F2C544.8030809@statistik.tu-dortmund.de>
	<AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>
	<7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>
Message-ID: <1374893114.11693.YahooMailNeo@web142604.mail.bf1.yahoo.com>



On some slightly different datasets:
tt1<-structure(list(subj = c(1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 
6, 6, 6, 7, 7, 7, 8, 8, 8), response = structure(c(2L, 2L, 1L, 
2L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L, 
1L, 2L, 1L), .Label = c("buy", "sample"), class = "factor"), 
??? product = c(1, 2, 3, 2, 2, 3, 2, 1, 1, 4, 4, 2, 2, 4, 5, 
??? 5, 4, 3, 4, 5, 4, 2)), .Names = c("subj", "response", "product"
), class = "data.frame", row.names = c(NA, 22L))

tt2<- structure(list(subj = c(1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 
6, 6, 6, 7, 7, 7, 8, 8, 8), response = structure(c(2L, 2L, 1L, 
2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 
1L, 2L, 2L), .Label = c("buy", "sample"), class = "factor"), 
??? product = c(1, 2, 3, 2, 2, 3, 2, 1, 1, 4, 1, 4, 5, 1, 4, 
??? 2, 3, 3, 2, 5, 3, 4)), .Names = c("subj", "response", "product"
), class = "data.frame", row.names = c(NA, 22L))

tt3<- structure(list(subj = c(1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5, 
6, 6, 6, 7, 7, 7, 8, 8, 8), response = structure(c(2L, 2L, 1L, 
2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L, 
1L, 1L, 2L), .Label = c("buy", "sample"), class = "factor"), 
??? product = c(1, 2, 3, 2, 2, 3, 2, 1, 1, 4, 1, 1, 3, 5, 2, 
??? 2, 2, 2, 4, 3, 2, 5)), .Names = c("subj", "response", "product"
), class = "data.frame", row.names = c(NA, 22L))


#Tried David's solution:
tt1$rown <- rownames(tt1)
as.numeric ( apply(tt1, 1, function(x) {
??? x['product'] %in% tt1[ rownames(tt1) < x['rown'] & tt1$response == "buy", "product"]? } ) )
? #gave inconsistent results especially since the first 10 rows were from `tt`
# [1] 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1

#similarly for `tt2` and `tt3`.


##Created this function.? It seems to work in the tested cases, though it is not tested extensively.
fun1<- function(dat,colName,newColumn){
????? indx<- which(dat[,colName]=="buy")
????? dat[,newColumn]<-0
????? dat[unlist(lapply(seq_along(indx),function(i){
??? ??? ??? x1<- if(i==length(indx)){
??? ??? ??? ??? seq(indx[i],nrow(dat))
??? ??? ??? ?}
??? ??? ??? else if((indx[i+1]-indx[i])==1){
??? ??? ??? indx[i]
??? ??? ??? }
??? ??? ??? else {
??? ??? ??? seq(indx[i]+1,indx[i+1]-1)
??? ??? ??? ?}
??? ??? ??? x2<- dat[unique(c(indx[i:1],x1)),]
??? ??? ??? x3<- subset(x2,response=="sample")
??? ??? ??? x4<- subset(x2,response=="buy")
??? ??? ??? if(nrow(x3)!=0) {
??? ??? ??? ??????????????? row.names(x3)[x3$product%in% x4$product]
??? ??? ??? ??? ??? ?? }
??? ??? ??? ??? ??? ??? ??? ??? ??? 
??? ??? ??? })),newColumn]<-1
??? dat

??? }
fun1(tt,"response","newCol")
#?? subj response product rown newCol
#1???? 1?? sample?????? 1??? 1????? 0
#2???? 1?? sample?????? 2??? 2????? 0
#3???? 1????? buy?????? 3??? 3????? 0
#4???? 2?? sample?????? 2??? 4????? 0
#5???? 2????? buy?????? 2??? 5????? 0
#6???? 3?? sample?????? 3??? 6????? 1
#7???? 3?? sample?????? 2??? 7????? 1
#8???? 3????? buy?????? 1??? 8????? 0
#9???? 4?? sample?????? 1??? 9????? 1
#10??? 4????? buy?????? 4?? 10????? 0

fun1(tt1,"response","newCol")
#?? subj response product newCol
#1???? 1?? sample?????? 1????? 0
#2???? 1?? sample?????? 2????? 0
#3???? 1????? buy?????? 3????? 0
#4???? 2?? sample?????? 2????? 0
#5???? 2????? buy?????? 2????? 0
#6???? 3?? sample?????? 3????? 1
#7???? 3?? sample?????? 2????? 1
#8???? 3????? buy?????? 1????? 0
#9???? 4?? sample?????? 1????? 1
#10??? 4????? buy?????? 4????? 0
#11??? 5????? buy?????? 4????? 0
#12??? 5?? sample?????? 2????? 1
#13??? 5????? buy?????? 2????? 0
#14??? 6????? buy?????? 4????? 0
#15??? 6?? sample?????? 5????? 0
#16??? 6?? sample?????? 5????? 0
#17??? 7?? sample?????? 4????? 1
#18??? 7????? buy?????? 3????? 0
#19??? 7????? buy?????? 4????? 0
#20??? 8????? buy?????? 5????? 0
#21??? 8?? sample?????? 4????? 1
#22??? 8????? buy?????? 2????? 0
#Also
?fun1(tt2,"response","newCol")
?fun1(tt3,"response","newCol")
A.K.

P.S.? Below is OP's clarification regarding the conditional statement in a private message:

I am sorry i didnt question it very clearly, let me change the 
conditional statement, I hope you can understand. i will explain by 
example

as you can see, almost every number is duplicated, but only in row 6th,7th,and 9th the value on column is 1.

on row4th, the value is duplicated( 2 already?occurred?on 2nd row),but 
since the value is considered as duplicated only if the value is 
duplicated where the response is 'buy' than the value on column, on 
row4th still zero.?

On row 6th, where the value product column is 3. 3 is already occurred 
in 3rd row where the value on response is 'buy', so the value on column 
should be 1

I hope it can understand the conditional statement. 








----- Original Message -----
From: David Winsemius <dwinsemius at comcast.net>
To: David Winsemius <dwinsemius at comcast.net>
Cc: R-help at r-project.org; Uwe Ligges <ligges at statistik.tu-dortmund.de>
Sent: Friday, July 26, 2013 5:16 PM
Subject: Re: [R] Duplicated function with conditional statement


On Jul 26, 2013, at 2:06 PM, David Winsemius wrote:

> 
> On Jul 26, 2013, at 11:51 AM, Uwe Ligges wrote:
> 
>> 
>> 
>> On 25.07.2013 21:05, vanessa van der vaart wrote:
>>> Hi everybody,,
>>> I have a question about R function duplicated(). I have spent days try to
>>> figure this out,but I cant find any solution yet. I hope somebody can help
>>> me..
>>> this is my data:
>>> 
>>> subj=c(1,1,1,2,2,3,3,3,4,4)
>>> response=c('sample','sample','buy','sample','buy','sample','
>>> sample','buy','sample','buy')
>>> product=c(1,2,3,2,2,3,2,1,1,4)
>>> tt=data.frame(subj, response, product)
>>> 
>>> the data look like this:
>>> 
>>> subj response product
>>> 1? ?  1?  sample? ? ?  1
>>> 2? ?  1?  sample? ? ?  2
>>> 3? ?  1? ? ? buy? ? ? ? ? 3
>>> 4? ?  2?  sample? ? ?  2
>>> 5? ?  2? ? ? ?  buy? ? ?  2
>>> 6? ?  3?  sample? ? ?  3
>>> 7? ?  3?  sample? ? ?  2
>>> 8? ?  3? ? ? ?  buy? ? ?  1
>>> 9? ?  4? sample? ? ?  1
>>> 10?  4? ? ?  buy? ? ? ? 4
>>> 
>>> I want to create new? column based on the value on response and product
>>> column. if the value on product is duplicated, then? the value on new column
>>> is 1, otherwise is 0.
>> 
>> 
>> According to your description:
>> 
> 
> Agree that the description did not match the output. I tried to match the output using a rule that could be expressed as: 
> 
> if( a "buy"- associated "product" value precedes the current "product" value){1}else{0}
> 

So this delivers the specified output:

tt$rown <- rownames(tt)
as.numeric ( apply(tt, 1, function(x) { 
? ?  x['product'] %in% tt[ rownames(tt) < x['rown'] & tt$response == "buy", "product"]? } ) )

# [1] 0 0 0 0 0 1 1 0 1 0

> -- 
> David.
> 
>> tt$newcolumn <- as.integer(duplicated(tt$product) & tt$response=="buy")
>> 
>> which is different from what you show us below, where I cannot derive any systematic rule from.
>> 
>> Uwe Ligges
>> 
>>> but I want to add conditional statement that the value on product column
>>> will only be considered as duplicated if the value on response column is
>>> 'buy'.
>>> for illustration, the table should look like this:
>>> 
>>> subj response product newcolumn
>>> 1? ?  1?  sample? ? ?  1? ? ? ? ? 0
>>> 2? ?  1?  sample? ? ?  2? ? ? ? ? 0
>>> 3? ?  1? ? ? buy? ? ? ? ? 3? ? ? ? ? 0
>>> 4? ?  2?  sample? ? ?  2? ? ? ? ? 0
>>> 5? ?  2? ? ? ?  buy? ? ?  2? ? ? ? ? 0
>>> 6? ?  3?  sample? ? ?  3? ? ? ? ? 1
>>> 7? ?  3?  sample? ? ?  2? ? ? ? ?  1
>>> 8? ?  3? ? ? ?  buy? ? ?  1? ? ? ? ?  0
>>> 9? ?  4? sample? ? ?  1? ? ? ? ? ? 1
>>> 10?  4? ? ?  buy? ? ?  4? ? ? ? ? ?  0
>>> 
>>> 
>>> can somebody help me?
>>> any help will be appreciated.
>>> I am new in this mailing list, so forgive me in advance, If I did not? ask
>>> the question appropriately.
>>> 
>>> ??? [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Sat Jul 27 06:26:22 2013
From: smartpink111 at yahoo.com (arun)
Date: Fri, 26 Jul 2013 21:26:22 -0700 (PDT)
Subject: [R] Combine multiple random forests contained in a list
Message-ID: <1374899182.65786.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
Using the example in ?combine
library(randomForest)
rf1 <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
????? rf2 <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
????? rf3 <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
????? rf.all <- combine(rf1, rf2, rf3)
lst1<- list(rf1,rf2,rf3)

rf.allL<- do.call(`combine`,lst1)
#or
rf.allL<- Reduce(`combine,lst1)
?identical(rf.all,rf.allL)
#[1] TRUE
A.K.


Is there a quick and easy way to pass randomForest objects contained in a list into the combine() function? 

As a result of calling randomForest through lapply(), I now have 10 randomForests in a list (rfors) 

I want to combine all 10 of them. Understandably combine(rfors) 
doesn't work as it doesn't recognise the individual forests within the 
list. I have spend quite sometime messing around with unlist(), lapply()
 and apply() to try and extract the information in a suitable format but
 to no avail. The only thing that works is combine(rfors[[1]], 
rfors[[2]] ...etc). 

This is a bit cumbersome though, not least because the number of
 random forests I'll need to combine is likely to change. Any sleek and 
elegant solution to this someone can suggest? 

Thanks in advance for any help. 

Anna


From erinm.hodgess at gmail.com  Sat Jul 27 06:45:06 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Fri, 26 Jul 2013 23:45:06 -0500
Subject: [R] problem with ldpaths and new R
Message-ID: <CACxE24mC9TaTKK_6KwXhN0ZAhTmn=TXMT8SuSCo+KAqqq4Jn5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130726/1e43b4c9/attachment.pl>

From dwinsemius at comcast.net  Sat Jul 27 07:27:35 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 26 Jul 2013 22:27:35 -0700
Subject: [R] problem with ldpaths and new R
In-Reply-To: <CACxE24mC9TaTKK_6KwXhN0ZAhTmn=TXMT8SuSCo+KAqqq4Jn5g@mail.gmail.com>
References: <CACxE24mC9TaTKK_6KwXhN0ZAhTmn=TXMT8SuSCo+KAqqq4Jn5g@mail.gmail.com>
Message-ID: <5F879716-DE76-44BC-9528-DD5117803817@comcast.net>


On Jul 26, 2013, at 9:45 PM, Erin Hodgess wrote:

> Hello!
> 
> I have just installed R on an Ubutnu machine (13.04)

Did you follow directions given here:

http://cran.us.r-project.org/bin/linux/ubuntu/

"Users who need to compile R packages from source [e.g. package maintainers, or anyone installing packages with install.packages()] should also install the r-base-dev package:

   sudo apt-get install r-base-dev
"

I ask because one ot the other directions that you did not follow was:

"The best place to report problems with these packages or ask R questions specific to Ubuntu is the R-SIG-Debian mailing list. See

   https://stat.ethz.ch/mailman/listinfo/r-sig-debian
"

-- 
David.

> and keep getting the
> following:
> 
> erin at erin-Lenovo-IdeaPad-Y480:~$ R
> /usr/bin/R: line 236: /usr/lib/R/etc/ldpaths: No such file or directory
> 
> R version 3.0.1 (2013-05-16) -- "Good Sport"
> Copyright (C) 2013 The R Foundation for Statistical Computing
> Platform: x86_64-pc-linux-gnu (64-bit)
> 
> R is free software and comes with ABSOLUTELY NO WARRANTY.
> You are welcome to redistribute it under certain conditions.
> Type 'license()' or 'licence()' for distribution details.
> 
>  Natural language support but running in an English locale
> 
> R is a collaborative project with many contributors.
> Type 'contributors()' for more information and
> 'citation()' on how to cite R or R packages in publications.
> 
> Type 'demo()' for some demos, 'help()' for on-line help, or
> 'help.start()' for an HTML browser interface to help.
> Type 'q()' to quit R.
> 
>> install.packages("pbdMPI",depen=TRUE)
> Installing package into ?/home/erin/lib/R/library?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> also installing the dependency ?rlecuyer?
> 
> trying URL '
> http://cran.revolutionanalytics.com/src/contrib/rlecuyer_0.3-3.tar.gz'
> Content type 'application/x-gzip' length 11756 bytes (11 Kb)
> opened URL
> ==================================================
> downloaded 11 Kb
> 
> trying URL '
> http://cran.revolutionanalytics.com/src/contrib/pbdMPI_0.1-8.tar.gz'
> Content type 'application/x-gzip' length 417547 bytes (407 Kb)
> opened URL
> ==================================================
> downloaded 407 Kb
> 
> /usr/lib/R/bin/R: line 140: /usr/lib/R/etc/ldpaths: No such file or
> directory
> /usr/lib/R/bin/R: line 236: /usr/lib/R/etc/ldpaths: No such file or
> directory
> Error in file(con, "r") : cannot open the connection
> Calls: <Anonymous> -> sub -> grep -> readLines -> file
> In addition: Warning message:
> In file(con, "r") :
>  cannot open file '/usr/lib/R/etc/Makeconf': No such file or directory
> /usr/lib/R/bin/R: line 140: /usr/lib/R/etc/ldpaths: No such file or
> directory
> /usr/lib/R/bin/R: line 236: /usr/lib/R/etc/ldpaths: No such file or
> directory
> Error in file(con, "r") : cannot open the connection
> Calls: <Anonymous> -> sub -> grep -> readLines -> file
> In addition: Warning message:
> In file(con, "r") :
>  cannot open file '/usr/lib/R/etc/Makeconf': No such file or directory
> 
> The downloaded source packages are in
>    ?/tmp/RtmpAtAxNL/downloaded_packages?
> Warning messages:
> 1: In install.packages("pbdMPI", depen = TRUE) :
>  installation of package ?rlecuyer? had non-zero exit status
> 2: In install.packages("pbdMPI", depen = TRUE) :
>  installation of package ?pbdMPI? had non-zero exit status
>> 
> 
> 
> I uninstalled it, deleted the /etc/R and /usr/lib/R directories, and
> re-installed.  (Actually, I followed that process twice).
> 
> I'm still stuck.  Does anyone have any suggestions, please?
> 
> Thanks,
> Erin
> 
> 
> -- 
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From gunter.berton at gene.com  Sat Jul 27 07:42:22 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 26 Jul 2013 22:42:22 -0700
Subject: [R] Combine multiple random forests contained in a list
In-Reply-To: <1374899182.65786.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <1374899182.65786.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <CACk-te1z=6s_awL3ZnPQBmLiU9UOs2kjaODBKvCKW+z0ro7MFA@mail.gmail.com>

I would say that the use of Reduce in this context is bad practice.

from ?Reduce :

"Reduce uses a binary function to successively combine the elements of
a given vector and a possibly given initial value."

combine() is obviously not a binary function. do.call() seems to be
THE appropriate idiom.

-- Bert

On Fri, Jul 26, 2013 at 9:26 PM, arun <smartpink111 at yahoo.com> wrote:
> HI,
> Using the example in ?combine
> library(randomForest)
> rf1 <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
>       rf2 <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
>       rf3 <- randomForest(Species ~ ., iris, ntree=50, norm.votes=FALSE)
>       rf.all <- combine(rf1, rf2, rf3)
> lst1<- list(rf1,rf2,rf3)
>
> rf.allL<- do.call(`combine`,lst1)
> #or
> rf.allL<- Reduce(`combine,lst1)
>  identical(rf.all,rf.allL)
> #[1] TRUE
> A.K.
>
>
> Is there a quick and easy way to pass randomForest objects contained in a list into the combine() function?
>
> As a result of calling randomForest through lapply(), I now have 10 randomForests in a list (rfors)
>
> I want to combine all 10 of them. Understandably combine(rfors)
> doesn't work as it doesn't recognise the individual forests within the
> list. I have spend quite sometime messing around with unlist(), lapply()
>  and apply() to try and extract the information in a suitable format but
>  to no avail. The only thing that works is combine(rfors[[1]],
> rfors[[2]] ...etc).
>
> This is a bit cumbersome though, not least because the number of
>  random forests I'll need to combine is likely to change. Any sleek and
> elegant solution to this someone can suggest?
>
> Thanks in advance for any help.
>
> Anna
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ripley at stats.ox.ac.uk  Sat Jul 27 08:12:23 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 27 Jul 2013 07:12:23 +0100
Subject: [R] readTiff - Sorry can't handle images with 32-bit samples
In-Reply-To: <CA+hbrhVOWvZzQk8-t8CqHtaAHG2E0u=eV4UdvHrC__y3PfPwHg@mail.gmail.com>
References: <1374871904863-4672465.post@n4.nabble.com>
	<CA+hbrhVOWvZzQk8-t8CqHtaAHG2E0u=eV4UdvHrC__y3PfPwHg@mail.gmail.com>
Message-ID: <51F364C7.9090407@stats.ox.ac.uk>

It is a little more complex than that.

readTiff is not part of R.  It is in an unstated package, and there are 
instances in packages biOps and rtiff.

There are also readTIFF in packages tiff and beadArray.  It is 
tiff::readTIFF that I would recommend.  Its help says it can read 32-bit 
tiffs.

rtiff::readTiff is old, limited and orphaned.

Secondly, all of these are interfaces to libtiff, and that is an OS 
library.  So what images they can read mainly depends on what version of 
libtiff and what capabilities it was configured to provide.  Athough we 
were not told (see the posting guide) it looks like the OP was using 
Windows.  There I compiled libtiff from source and it is a fairly 
minimal build (not least as most people with complex image requirements 
do not use Windows).

There are other ways to read TIFF files, e.g. rgdal and EBImage.  See 
the R manuals, specifically 
http://cran.r-project.org/doc/manuals/r-release/R-data.html#Image-files 
.  E.g. some versions of rgdal have support for 12-bit TIFFs that 
libtiff cannot handle.

In short: use a better tool.


On 26/07/2013 23:08, Peter Langfelder wrote:
> Disclaimer: I haven't seen your tif file and I know nothing about
> readTiff... but here go some general comments.
>
> TIF files can use different bit depths (number of bits to store each
> pixel (or each color for each pixel). Most common software outputs 8-
> or 16-bits, but your file probably has a higher bit depth of 32 bits
> per sample. Apparently readTiff cannot handle such bit depth.
>
> You may need to convert the 32-bit delth file(s) into 16-bit depth (or
> whatever readTiff can handle). My suggestion would be to look at
> ImageMagick, but you may also be able to use some image editing
> applications to do that,
>
> Peter
>
> On Fri, Jul 26, 2013 at 1:51 PM, wwreith <reith_william at bah.com> wrote:
>> I tried using readTiff() and got the error message "Sorry can't handle images
>> with 32-bit samples"
>>
>> line of code
>>
>> x <- readTiff("C:/Users/550062/Desktop/Data/example1.tif")
>>
>> So far I have not had any luck finding this error message on google. Any
>> guess at what it means and how to get the code to work?
>>
>> Thanks!


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From hwborchers at googlemail.com  Sat Jul 27 08:32:19 2013
From: hwborchers at googlemail.com (Hans W Borchers)
Date: Sat, 27 Jul 2013 06:32:19 +0000
Subject: [R] How to double integrate a function in R
References: <39811.186.215.164.146.1374853459.squirrel@webmail.mbe.bio.br>
Message-ID: <loom.20130727T082802-752@post.gmane.org>

Tiago V. Pereira <tiago.pereira <at> mbe.bio.br> writes:

> I am trying to double integrate the following expression:
> 
> #  expression
> (1/(2*pi))*exp(-y2/2)*sqrt((y1/(y2-y1)))
> 
> for y2>y1>0.
> 
> I am trying the following approach
> 
> # first attempt
> 
>  library(cubature)
>     fun <- function(x)   { (1/(2*pi))*exp(-x[2]/2)*sqrt((x[1]/(x[2]-x[1])))}
>     adaptIntegrate(fun, lower = c(0,0), upper =c(5, 6), tol=1e-8)
> 
> However, I don't know how to constrain the integration so that y2>y1>0.
> 
> Any ideas?
> Tiago

You could use integral2() in package 'pracma'. It implements the
"TwoD" algorithm and has the following properties:

(1) The boundaries of the second variable y can be functions of the first
      variable x;
(2) it can handle singularities on the boundaries (to a certain extent).

    > library(pracma)
    > fun <- function(y1, y2) (1/(2*pi))*exp(-y2/2)*sqrt((y1/(y2-y1)))

    > integral2(fun, 0, 5, function(x) x, 6, singular=TRUE)
    $Q
    [1] 0.7706771
    
    $error
    [1] 7.890093e-11

The relative error is a bit optimistic, the absolute error here is < 0.5e-6.
The computation time is 0.025 seconds.

Hans Werner


From terry.seaward at gmail.com  Sat Jul 27 08:31:41 2013
From: terry.seaward at gmail.com (Terry)
Date: Sat, 27 Jul 2013 06:31:41 +0000
Subject: [R] R base package grid does not output raster image
References: <922D1973-A313-49D8-A685-A2403BA9AFDF@AURORA.iam.corp.investec.com>
	<51EF7789.9000801@stats.ox.ac.uk>
Message-ID: <loom.20130727T081648-6@post.gmane.org>

Prof Brian Ripley <ripley <at> stats.ox.ac.uk> writes:

> Basically Remote Desktop restricts the number of colours when connecting 
> to a Windows Server machine, and interpolating rasters needs a lot of 
> colours.

Hi Brain,

I looked into this further and have a solution.

1. On the server launch Remote Desktop Session Host Configuration. 
2. Under Connections, right click on RDP-Tcp and select Properties. 
3. On the Client Settings tab either uncheck LimitMaximum Color Depth 
    or set it to 32 bits per pixel. 
4. Click OK and log out of the remote session.

When remoting back in ensure that the colour depth on the Display tab is 
set to 32 bit. rasterImage, grid.raster, etc. now work as expected.

Regards,
Terry


From landronimirc at gmail.com  Sat Jul 27 13:36:56 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Sat, 27 Jul 2013 13:36:56 +0200
Subject: [R] list of valid characters in object names
Message-ID: <CABxs9Vkf6Fw8XZNHVDru3jsgRkHve4tZ7+jbSWr98gSyfbxkoQ@mail.gmail.com>

Dear all,
Could someone please point me to the definitive list of valid
characters that are allowed in object names in R? I believe that the
following list covers them:
_.abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789

but I would like to make sure.

Thank you,
Liviu


-- 
Do you know how to read?
http://www.alienetworks.com/srtest.cfm
http://goodies.xfce.org/projects/applications/xfce4-dict#speed-reader
Do you know how to write?
http://garbl.home.comcast.net/~garbl/stylemanual/e.htm#e-mail


From tomhopper at gmail.com  Sat Jul 27 14:25:56 2013
From: tomhopper at gmail.com (Tom Hopper)
Date: Sat, 27 Jul 2013 08:25:56 -0400
Subject: [R] Fwd: modeest with non-numeric data?
In-Reply-To: <CAJ_8u+LVtZx42BZ9TusFYP+sYG0oL_-M7Q7w3Pq1srpPPzfXVw@mail.gmail.com>
References: <CAJ_8u+LVtZx42BZ9TusFYP+sYG0oL_-M7Q7w3Pq1srpPPzfXVw@mail.gmail.com>
Message-ID: <CAJ_8u+LTCoaOA4R9UFNUhN99WedFkDDxiVxEc+_wHcxzZK6P8g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130727/bea24932/attachment.pl>

From iza.ch1 at op.pl  Sat Jul 27 14:47:42 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Sat, 27 Jul 2013 14:47:42 +0200
Subject: [R] linear fit function with NA values
Message-ID: <115547517-04d03e2f4e085537beef56fdc730aea0@pkn7.m5r2.onet>

Hi

Quick question. I am running a multiple regression function for each column of two data sets. That means as a result I get several coefficients. I have a problem because data that I use for regression contains NA. How can I ignore NA in lm function. I use the following code for regression: 
OLS<-lapply(seq_len(ncol(es.w)),function(i) {lm(es.w[,i]~es.median[,i])})
as response I get
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
  all values NA

thanks for help :)


From murdoch.duncan at gmail.com  Sat Jul 27 15:08:27 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 27 Jul 2013 09:08:27 -0400
Subject: [R] list of valid characters in object names
In-Reply-To: <CABxs9Vkf6Fw8XZNHVDru3jsgRkHve4tZ7+jbSWr98gSyfbxkoQ@mail.gmail.com>
References: <CABxs9Vkf6Fw8XZNHVDru3jsgRkHve4tZ7+jbSWr98gSyfbxkoQ@mail.gmail.com>
Message-ID: <51F3C64B.9080501@gmail.com>

On 13-07-27 7:36 AM, Liviu Andronic wrote:
> Dear all,
> Could someone please point me to the definitive list of valid
> characters that are allowed in object names in R? I believe that the
> following list covers them:
> _.abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789
>
> but I would like to make sure.

Your question is a little ambiguous.  All characters are allowed in 
object names, but the parser will only recognize some of them if they 
are quoted in backticks.

The ones it recognizes without the backticks are ones that the C 
isalnum() (or iswalnum()) function declares to be alphanumeric, plus . 
and _.  Your list above are all allowed, but locales are allowed to 
declare other characters to be alpha.  I wouldn't recommend using 
anything else, because your code won't be recognized in other locales.

The definitive reference for this is the source code, specifically 
src/main/gram.y.  There's some discussion in the Intro to R manual, 
section 1.8.

Duncan Murdoch


From landronimirc at gmail.com  Sat Jul 27 15:10:20 2013
From: landronimirc at gmail.com (Liviu Andronic)
Date: Sat, 27 Jul 2013 15:10:20 +0200
Subject: [R] list of valid characters in object names
In-Reply-To: <51F3C64B.9080501@gmail.com>
References: <CABxs9Vkf6Fw8XZNHVDru3jsgRkHve4tZ7+jbSWr98gSyfbxkoQ@mail.gmail.com>
	<51F3C64B.9080501@gmail.com>
Message-ID: <CABxs9VnTdeQU0bUZM6DeZKRx0H+B=gAwquGwpunbz6rg=csUsA@mail.gmail.com>

On Sat, Jul 27, 2013 at 3:08 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> Your question is a little ambiguous.  All characters are allowed in object
> names, but the parser will only recognize some of them if they are quoted in
> backticks.
>
> The ones it recognizes without the backticks are ones that the C isalnum()
> (or iswalnum()) function declares to be alphanumeric, plus . and _.  Your
> list above are all allowed, but locales are allowed to declare other
> characters to be alpha.  I wouldn't recommend using anything else, because
> your code won't be recognized in other locales.
>
> The definitive reference for this is the source code, specifically
> src/main/gram.y.  There's some discussion in the Intro to R manual, section
> 1.8.
>
Exactly what I was looking for. Thank you,
Liviu


From szehnder at uni-bonn.de  Sat Jul 27 15:30:29 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Sat, 27 Jul 2013 15:30:29 +0200
Subject: [R] Hmisc ctable rotate option obsolete?
In-Reply-To: <A678F5E7-0C89-48A9-8F2C-21DFDA915F21@uni-bonn.de>
References: <A678F5E7-0C89-48A9-8F2C-21DFDA915F21@uni-bonn.de>
Message-ID: <F9E391EC-5005-4E0B-8A57-9478C0CCD38E@uni-bonn.de>

So, I downloaded the source files of Hmisc and changed in the file latex.s line 688 'rotate' to 'sideways'. This does the work for landscape ctables in Latex. 

I also wrote an email to the package maintainer. I consider this thread as solved. 


Best

Simon

On Jul 26, 2013, at 5:34 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:

> Dear R-Users and R-Devels,
> 
> I may have found a deprecated option for the 'latex' function in the Hmisc package. I am working with Hmisc and knitr and tried the following code:
> 
> \documentclass{article}
> \usepackage[utf8]{inputenc}
> \usepackage{amsmath, amssymb}
> \usepackage{ctable}
> %\usepackage{booktabs}
> \begin{document}
> <<results = 'asis'>>=
> library(Hmisc)
> iris.t <- head(iris)
> iris.t[seq(2, NROW(iris.t), by = 2),] <- format(iris.t[seq(2, NROW(iris.t), by = 2),], scientific = TRUE)
> texMat <- matrix("", ncol = 5, nrow = 6)
> texMat[seq(2,nrow(texMat), by = 2), ] <- "scriptsize"
> latex(iris.t, 
> file = '', 
> landscape = TRUE,
> dcolumn = TRUE,
> col.just = c('r','c', 'r','c', 'l'),
> cdec = c(0, 0, 1, 1, 0),
> na.blank = TRUE,
> rowname = '',
> rowlabel = '', 
> cellTexCmd = texMat,
> ctable = TRUE, 
> cgroup = c('Observations', ''),
> n.cgroup = c(4, 1),
> rgroup = c('',''),
> n.rgroup = c(3, 3),
> caption = 'iris'
> )
> @
> \end{document}
> 
> Everything runs fine but the 'landscape' option. It says in the help for 'latex' that if option 'ctable' is set to TRUE the 'rotate' option for ctable is used if 'nadscape' is set TRUE. Looking at the ctable documentary (http://texdoc.net/texmf-dist/doc/latex/ctable/ctable.pdf) in section Change History, I get for version v1.07: General: Added option sideways, option rotate now obsolete. Hasn't this been updated in the Hmisc package?
> 
> Best
> 
> Simon
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From erinm.hodgess at gmail.com  Sat Jul 27 16:02:31 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Sat, 27 Jul 2013 09:02:31 -0500
Subject: [R] problem with ldpaths and new R
In-Reply-To: <5F879716-DE76-44BC-9528-DD5117803817@comcast.net>
References: <CACxE24mC9TaTKK_6KwXhN0ZAhTmn=TXMT8SuSCo+KAqqq4Jn5g@mail.gmail.com>
	<5F879716-DE76-44BC-9528-DD5117803817@comcast.net>
Message-ID: <CACxE24kjz596c90q7CMPwjOWhb9=C7ZbjoPZTumf68jxGW0Jww@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130727/808b212d/attachment.pl>

From smartpink111 at yahoo.com  Sat Jul 27 17:33:30 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 27 Jul 2013 08:33:30 -0700 (PDT)
Subject: [R] linear fit function with NA values
In-Reply-To: <115547517-04d03e2f4e085537beef56fdc730aea0@pkn7.m5r2.onet>
References: <115547517-04d03e2f4e085537beef56fdc730aea0@pkn7.m5r2.onet>
Message-ID: <1374939210.40811.YahooMailNeo@web142604.mail.bf1.yahoo.com>



HI,
set.seed(28)
dat1<- as.data.frame(matrix(sample(c(NA,1:20),100,replace=TRUE),ncol=10))

set.seed(49)
dat2<- as.data.frame(matrix(sample(c(NA,40:80),100,replace=TRUE),ncol=10))
?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i])}) #works bcz the default setting removes NA
Regarding the options:
?lm()
na.action: a function which indicates what should happen when the data
????????? contain ?NA?s.? The default is set by the ?na.action? setting
????????? of ?options?, and is ?na.fail? if that is unset.? The
????????? ?factory-fresh? default is ?na.omit?.? Another possible value
????????? is ?NULL?, no action.? Value ?na.exclude? can be useful.

?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.exclude)})
#or
?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.omit)})

lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.fail)})
#Error in na.fail.default(list(`dat2[, i]` = c(54L, 59L, 50L, 64L, 40L,? : 
?# missing values in object

In your case, the error is different.? It could be something similar to the below case:
dat1[,1]<- NA

lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.omit)})
#Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
?# 0 (non-NA) cases # here it is different

?lapply(seq_len(ncol(dat1)),function(i) {try(lm(dat2[,i]~dat1[,i]))}) #works in the above case.? It may not work in your case.

You need to provide a reproducible example to understand the situation better.
A.K.













----- Original Message -----
From: iza.ch1 <iza.ch1 at op.pl>
To: r-help at r-project.org
Cc: 
Sent: Saturday, July 27, 2013 8:47 AM
Subject: [R] linear fit function with NA values

Hi

Quick question. I am running a multiple regression function for each column of two data sets. That means as a result I get several coefficients. I have a problem because data that I use for regression contains NA. How can I ignore NA in lm function. I use the following code for regression: 
OLS<-lapply(seq_len(ncol(es.w)),function(i) {lm(es.w[,i]~es.median[,i])})
as response I get
Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
? all values NA

thanks for help :)

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jrkrideau at inbox.com  Sat Jul 27 18:14:18 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sat, 27 Jul 2013 08:14:18 -0800
Subject: [R] add different regression lines for groups on ggplot
In-Reply-To: <CAAvu=bkQ-itDQUgT_FJMupcGRxvTf+ufgsDRs9XM9H2KhxmLjA@mail.gmail.com>
Message-ID: <8B86CE18F7C.00000368jrkrideau@inbox.com>

I have not tried anything like that but have a look at www.google.ca/url?sa=t&rct=j&q=&esrc=s&source=web&cd=3&ved=0CDkQFjAC&url=http%3A%2F%2Fstackoverflow.com%2Fquestions%2F7476022%2Fgeom-point-and-geom-line-for-multiple-datasets-on-same-graph-in-ggplot2&ei=MfHzUej7FoSergG1_ICYAw&usg=AFQjCNH2b72a6un_xAM-PYxC-sUGU8-xOw&sig2=iBIrl1uhIsJXmPbAh4kUbw&bvm=bv.49784469,d.aWM

You may be able to use two smooth statements to do what you want.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: yelin at lbl.gov
> Sent: Fri, 26 Jul 2013 12:21:23 -0700
> To: r-help at r-project.org
> Subject: [R] add different regression lines for groups on ggplot
> 
> Hey All,
> 
> I need to apply different regression lines to different group on my
> ggplot,
> and here is the code I use:
> 
> qplot(x=Var1,y=Var2,data=df,color=SiteID,group=SiteID)+geom_point()+geom_smooth(method='lm',formula=log(y)~I(1/x),se=FALSE,size=2)
> 
> However the regression for different groups is as below:
> 
> AL1/AL2: log(y)~I(1/x)
> AL3: log(y)~log(x)
> 
> How can I apply each regression equation on the same ggplot?
> 
> Also I have an issue that if I use the code above, the regression lines
> are
> not overlapped on top of my data points.
> 
> Thanks for your help!
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
TRY FREE IM TOOLPACK at http://www.imtoolpack.com/default.aspx?rc=if5
Capture screenshots, upload images, edit and send them to your friends
through IMs, post on Twitter?, Facebook?, MySpace?, LinkedIn? ? FAST!


From stan.aggerwal at gmail.com  Sat Jul 27 13:24:32 2013
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Sat, 27 Jul 2013 04:24:32 -0700
Subject: [R] repeated measures logistic regression
Message-ID: <CAOZp1o=XYWN8Gj7bVCWvqvM=2kQiJMJwuWdKcwoOjjZffygjfA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130727/744d0174/attachment.pl>

From bbolker at gmail.com  Sat Jul 27 21:05:25 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Sat, 27 Jul 2013 19:05:25 +0000
Subject: [R] repeated measures logistic regression
References: <CAOZp1o=XYWN8Gj7bVCWvqvM=2kQiJMJwuWdKcwoOjjZffygjfA@mail.gmail.com>
Message-ID: <loom.20130727T205849-73@post.gmane.org>

Stanislav Aggerwal <stan.aggerwal <at> gmail.com> writes:

> 
> I have searched the r-help archive and saw only one 
> unanswered post related
> to mine.

  Take a look at the r-sig-mixed-models (@r-project.org)
mailing list and archive ...
> 
> My design is as follows.
> 
>    - y is Bernoulli response
>    - x1 is continuous variable
>    - x2 is categorical (factor) variable with two levels
> 
> The experiment is completely within subjects. That is, each subject
> receives each combination of x1 and x2.
> 
> This is a repeated measures logistic regression set-up.
> The experiment will
> give two ogives for p(y==1) vs x1, one for level1 and one 
> for level2 of x2.
> The effect of x2 should be that for level2 compared to level1, the ogive
> should have a shallower slope and increased intercept.

> I am struggling with finding the model using lme4. Here is a guess at it:
> 
> glmer(y~x1*x2 +(1|subject),family=binomial)
 
> So far as I understand it, the 1|subject part says 
> that subject is a random
> effect. But I do not really understand the notation or
>  how to specify that x1 and x2 are repeated measures variables. 
> In the end I want a model that
> includes a random effect for subjects, and gives estimated slopes and
> intercepts for level1 and level2.

  I believe you want

glmer(y~x1*x2 +(x1*x2|subject),family=binomial,data=...)

 (I strongly recommend including the data= argument in your call)

This will give a population-level estimate of

intercept (log-odds in group 1 at x1=0)
treatment effect on intercept (log-odds(level2,x1=0)-log-odds(level1,x=0))
log-odds slope in level 1
difference in slopes

as well as among-individual variances in all four of these parameters,
and covariances among all the parameters (i.e. a 4x4 variance-covariance
matrix for these parameters).

  For binary data and estimating 4 fixed + 10 RE parameters
(i.e., variances and covariances), you're going to need a lot of data --
very conservatively, 140 total observations.

  It may help to center your x1 variable.

  see http://glmm.wikidot.com/faq 
(especially http://glmm.wikidot.com/faq#modelspec), 
and the r-sig-mixed-models mailing list.


From iza.ch1 at op.pl  Sat Jul 27 22:46:59 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Sat, 27 Jul 2013 22:46:59 +0200
Subject: [R] linear fit function with NA values
Message-ID: <45272633-bd71b012a593bdb925f36b87b43e3eaa@pmq5.m5r2.onet>

Hi

Thanks for your hints. I would like to describe my problem better and give an examle of the data that I use.

I conduct the event study and I need to create abnormal returns for the daily stock prices. I have for each stock returns from time period of 8 years. For some days I don't have the data for many reasons. in excel file they are just empty cells but I convert my data into 'zoo' and then it is transformed into NA. I get something like this

return


       ATI        AMU
-1   0.734     9.003
0    0.999     2.001
1    3.097     -1.003
2        NA        NA
3        NA     3.541

median
      ATI        AMU
-1   3.224     -2.003
0    2.999     -1.301
1    1.3        -1.003
2    4.000     2.442
3       -10     4.511

I want to regress first column return with first column median and second column return with second column median. when I do 
OLS<-lapply(seq_len(ncol(return)),function(i) {lm(return[,i]~median[,i])})
I get an error message. I would like my function to omit the NAs and for example for ATI returns to take into account only the values for -1,0,1 and regress it against the same values from ATI in median which means it would also take only (3.224, 2.999, 1.3)

Is it possible to do it?

Thanks a lot 

W dniu 2013-07-27 17:33:30 u?ytkownik arun <smartpink111 at yahoo.com> napisa?:
> 
> 
> HI,
> set.seed(28)
> dat1<- as.data.frame(matrix(sample(c(NA,1:20),100,replace=TRUE),ncol=10))
> 
> set.seed(49)
> dat2<- as.data.frame(matrix(sample(c(NA,40:80),100,replace=TRUE),ncol=10))
> ?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i])}) #works bcz the default setting removes NA
> Regarding the options:
> ?lm()
> na.action: a function which indicates what should happen when the data
> ????????? contain ?NA?s.? The default is set by the ?na.action? setting
> ????????? of ?options?, and is ?na.fail? if that is unset.? The
> ????????? ?factory-fresh? default is ?na.omit?.? Another possible value
> ????????? is ?NULL?, no action.? Value ?na.exclude? can be useful.
> 
> ?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.exclude)})
> #or
> ?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.omit)})
> 
> lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.fail)})
> #Error in na.fail.default(list(`dat2[, i]` = c(54L, 59L, 50L, 64L, 40L,? : 
> ?# missing values in object
> 
> In your case, the error is different.? It could be something similar to the below case:
> dat1[,1]<- NA
> 
> lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.omit)})
> #Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
> ?# 0 (non-NA) cases # here it is different
> 
> ?lapply(seq_len(ncol(dat1)),function(i) {try(lm(dat2[,i]~dat1[,i]))}) #works in the above case.? It may not work in your case.
> 
> You need to provide a reproducible example to understand the situation better.
> A.K.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ----- Original Message -----
> From: iza.ch1 <iza.ch1 at op.pl>
> To: r-help at r-project.org
> Cc: 
> Sent: Saturday, July 27, 2013 8:47 AM
> Subject: [R] linear fit function with NA values
> 
> Hi
> 
> Quick question. I am running a multiple regression function for each column of two data sets. That means as a result I get several coefficients. I have a problem because data that I use for regression contains NA. How can I ignore NA in lm function. I use the following code for regression: 
> OLS<-lapply(seq_len(ncol(es.w)),function(i) {lm(es.w[,i]~es.median[,i])})
> as response I get
> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
> ? all values NA
> 
> thanks for help :)
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
> 

From smartpink111 at yahoo.com  Sat Jul 27 22:57:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 27 Jul 2013 13:57:38 -0700 (PDT)
Subject: [R] linear fit function with NA values
In-Reply-To: <45272633-bd71b012a593bdb925f36b87b43e3eaa@pmq5.m5r2.onet>
References: <45272633-bd71b012a593bdb925f36b87b43e3eaa@pmq5.m5r2.onet>
Message-ID: <1374958658.73932.YahooMailNeo@web142606.mail.bf1.yahoo.com>

HI,
I couldn't get any error message with the data you provided.
return<- read.table(text="
????? ATI??????? AMU
-1? 0.734??? 9.003
0??? 0.999??? 2.001
1??? 3.097??? -1.003
2??????? NA??????? NA
3??????? NA??? 3.541
",sep="",header=TRUE)

median<- read.table(text="
????? ATI??????? AMU
-1? 3.224??? -2.003
0??? 2.999??? -1.301
1??? 1.3??????? -1.003
2??? 4.000??? 2.442
3????? -10??? 4.511
",sep="",header=TRUE)

?lapply(seq_len(ncol(return)),function(i) {lm(return[,i]~median[,i])}) 
[[1]]

Call:
lm(formula = return[, i] ~ median[, i])

Coefficients:
(Intercept)? median[, i]? 
????? 4.696?????? -1.231? 


[[2]]

Call:
lm(formula = return[, i] ~ median[, i])

Coefficients:
(Intercept)? median[, i]? 
???? 3.3937????? -0.1607? 

lapply(seq_len(ncol(return)),function(i) {lm(return[,i]~median[,i],na.action=na.omit)}) #same as above.

?sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_CA.UTF-8?????? LC_NUMERIC=C????????????? 
?[3] LC_TIME=en_CA.UTF-8??????? LC_COLLATE=en_CA.UTF-8??? 
?[5] LC_MONETARY=en_CA.UTF-8??? LC_MESSAGES=en_CA.UTF-8?? 
?[7] LC_PAPER=C???????????????? LC_NAME=C???????????????? 
?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C??????????? 
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C?????? 

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

other attached packages:
[1] stringr_0.6.2? reshape2_1.2.2

loaded via a namespace (and not attached):
[1] plyr_1.8??? tools_3.0.1

BTW, It is better to ?dput() the example dataset.

A.K.



----- Original Message -----
From: iza.ch1 <iza.ch1 at op.pl>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Saturday, July 27, 2013 4:46 PM
Subject: Re: Re: [R] linear fit function with NA values

Hi

Thanks for your hints. I would like to describe my problem better and give an examle of the data that I use.

I conduct the event study and I need to create abnormal returns for the daily stock prices. I have for each stock returns from time period of 8 years. For some days I don't have the data for many reasons. in excel file they are just empty cells but I convert my data into 'zoo' and then it is transformed into NA. I get something like this

return


? ? ?  ATI? ? ? ? AMU
-1?  0.734? ?  9.003
0? ? 0.999? ?  2.001
1? ? 3.097? ?  -1.003
2? ? ? ? NA? ? ? ? NA
3? ? ? ? NA? ?  3.541

median
? ? ? ATI? ? ? ? AMU
-1?  3.224? ?  -2.003
0? ? 2.999? ?  -1.301
1? ? 1.3? ? ? ? -1.003
2? ? 4.000? ?  2.442
3? ? ?  -10? ?  4.511

I want to regress first column return with first column median and second column return with second column median. when I do 
OLS<-lapply(seq_len(ncol(return)),function(i) {lm(return[,i]~median[,i])})
I get an error message. I would like my function to omit the NAs and for example for ATI returns to take into account only the values for -1,0,1 and regress it against the same values from ATI in median which means it would also take only (3.224, 2.999, 1.3)

Is it possible to do it?

Thanks a lot 

W dniu 2013-07-27 17:33:30 u?ytkownik arun <smartpink111 at yahoo.com> napisa?:
> 
> 
> HI,
> set.seed(28)
> dat1<- as.data.frame(matrix(sample(c(NA,1:20),100,replace=TRUE),ncol=10))
> 
> set.seed(49)
> dat2<- as.data.frame(matrix(sample(c(NA,40:80),100,replace=TRUE),ncol=10))
> ?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i])}) #works bcz the default setting removes NA
> Regarding the options:
> ?lm()
> na.action: a function which indicates what should happen when the data
> ????????? contain ?NA?s.? The default is set by the ?na.action? setting
> ????????? of ?options?, and is ?na.fail? if that is unset.? The
> ????????? ?factory-fresh? default is ?na.omit?.? Another possible value
> ????????? is ?NULL?, no action.? Value ?na.exclude? can be useful.
> 
> ?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.exclude)})
> #or
> ?lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.omit)})
> 
> lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.fail)})
> #Error in na.fail.default(list(`dat2[, i]` = c(54L, 59L, 50L, 64L, 40L,? : 
> ?# missing values in object
> 
> In your case, the error is different.? It could be something similar to the below case:
> dat1[,1]<- NA
> 
> lapply(seq_len(ncol(dat1)),function(i) {lm(dat2[,i]~dat1[,i],na.action=na.omit)})
> #Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
> ?# 0 (non-NA) cases # here it is different
> 
> ?lapply(seq_len(ncol(dat1)),function(i) {try(lm(dat2[,i]~dat1[,i]))}) #works in the above case.? It may not work in your case.
> 
> You need to provide a reproducible example to understand the situation better.
> A.K.
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> ----- Original Message -----
> From: iza.ch1 <iza.ch1 at op.pl>
> To: r-help at r-project.org
> Cc: 
> Sent: Saturday, July 27, 2013 8:47 AM
> Subject: [R] linear fit function with NA values
> 
> Hi
> 
> Quick question. I am running a multiple regression function for each column of two data sets. That means as a result I get several coefficients. I have a problem because data that I use for regression contains NA. How can I ignore NA in lm function. I use the following code for regression: 
> OLS<-lapply(seq_len(ncol(es.w)),function(i) {lm(es.w[,i]~es.median[,i])})
> as response I get
> Error in lm.fit(x, y, offset = offset, singular.ok = singular.ok, ...) : 
> ? all values NA
> 
> thanks for help :)
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 
>


From hellyj at ucsd.edu  Sun Jul 28 00:28:42 2013
From: hellyj at ucsd.edu (John Helly)
Date: Sat, 27 Jul 2013 15:28:42 -0700
Subject: [R] Alternative method for range-matching within 2 nested loops in
	R?
Message-ID: <51F4499A.6020304@ucsd.edu>

Hi.

I've been puzzling about how to replace the nested loops below. The idea 
is that the B dataframe has rows with a posix datetime and the C 
dataframes has posix Start and End times.  I want to assign a value to 
the observations in B based in intersecting the appropriate 
time-interval in C.  I haven't been able to discern a more efficient way 
to do this.  Any suggestions would be most appreciated.

brows = dim(B)[1]
mrows = dim(C)[1]

for (i in 1:brows ) {
     for (j in 1:mrows ) {
         if (B$Datetime[i] >= C$DT_Start[j] & B$Datetime<=C$DT_End[j]){
             B$Site[i] = C$Proximity[j]
         }
     }
}

-- 
John Helly, University of California, San Diego / San Diego Supercomputer Center / Scripps Institution of Oceanography / 760 840 8660 mobile / stonesteps (Skype) / stonesteps7 (iChat) / http://www.sdsc.edu/~hellyj


From dupouey at nancy.inra.fr  Sat Jul 27 20:50:21 2013
From: dupouey at nancy.inra.fr (Jean-Luc Dupouey)
Date: Sat, 27 Jul 2013 20:50:21 +0200
Subject: [R] smooth.spline gives different results from sreg ?
Message-ID: <51F4166D.8010008@nancy.inra.fr>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130727/50bf67bc/attachment.pl>

From murdoch.duncan at gmail.com  Sun Jul 28 01:10:51 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 27 Jul 2013 19:10:51 -0400
Subject: [R] smooth.spline gives different results from sreg ?
In-Reply-To: <51F4166D.8010008@nancy.inra.fr>
References: <51F4166D.8010008@nancy.inra.fr>
Message-ID: <51F4537B.8010805@gmail.com>

On 13-07-27 2:50 PM, Jean-Luc Dupouey wrote:
> Dear R-helpers,
>
> I compared various programs for cubic spline smoothing, and it appeared
> that smooth.spline ( stats version 3.0.1) seems to behave surprisingly.
> For enough long series and low values of lambda (or spar), the results
> of smooth.spline seem to be different from those of sreg ( package
> fields version 6.8), Octave (=MATLAB) or SAS. These three last softwares
> always gave the same results.

Did you read the ?smooth.spline help page, in particular the Details and 
Note sections?  They indicate that the default computation makes some 
efficiency simplifications.

Duncan Murdoch

>
> Here is a script which shows the problem:
>
> #generate a random series of 2000 values
>
> set.seed(1)
> MyData=data.frame(Time=1:2000,Val=runif(1000))
>
> #calculate the sreg cubic smoothing spline with a given lambda parameter
> (0.006 here)
>
> library(fields)
>
> SplineFields=sreg(MyData$Time,MyData$Val,lambda=0.006)
>
> #keep the minimim fitted value (or any other from a long list of
> possible values)
>
> ValMin=min(SplineFields$fitted.values)
> TimeValMin=which.min(SplineFields$fitted.values)
>
> #calculations of all possible fitted values at the TimeValMin point with
> smooth.spline,
> #varying the spar parameter in the range of all its possible values
>
> SplineRValMin=sapply(seq(-0.5,2.5,0.1),
>     function(Ispar) {
>       SplineR=smooth.spline(MyData$Time,MyData$Val,spar=Ispar)
>       SplineR$y[TimeValMin]})
>
> #None of the smooth.spline fitted values reach the one calculated with
> sreg !
>
> Lim=range(ValMin,SplineRValMin)
>
> #smooth.spline values
> plot(seq(-0.5,2.5,0.1),SplineRValMin,type="l",ylim=Lim)
>
> #sreg value
> abline(h=ValMin)
>
> I hope there is no real problem here, but only some misunderstanding
> from my side, because cubic splines are very often used. Best regards,
>
> Jean-Luc Dupouey
>


From gunter.berton at gene.com  Sun Jul 28 01:53:53 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 27 Jul 2013 16:53:53 -0700
Subject: [R] Alternative method for range-matching within 2 nested loops
 in R?
In-Reply-To: <51F4499A.6020304@ucsd.edu>
References: <51F4499A.6020304@ucsd.edu>
Message-ID: <CACk-te3FBBRiYA8Uk7P1zOtN_MM1uLCzAhfd=v42FdW_BnpAkw@mail.gmail.com>

Perhaps: ?findInterval

(you may need to do some type conversion first)

-- Bert

On Sat, Jul 27, 2013 at 3:28 PM, John Helly <hellyj at ucsd.edu> wrote:
> Hi.
>
> I've been puzzling about how to replace the nested loops below. The idea is
> that the B dataframe has rows with a posix datetime and the C dataframes has
> posix Start and End times.  I want to assign a value to the observations in
> B based in intersecting the appropriate time-interval in C.  I haven't been
> able to discern a more efficient way to do this.  Any suggestions would be
> most appreciated.
>
> brows = dim(B)[1]
> mrows = dim(C)[1]
>
> for (i in 1:brows ) {
>     for (j in 1:mrows ) {
>         if (B$Datetime[i] >= C$DT_Start[j] & B$Datetime<=C$DT_End[j]){
>             B$Site[i] = C$Proximity[j]
>         }
>     }
> }
>
> --
> John Helly, University of California, San Diego / San Diego Supercomputer
> Center / Scripps Institution of Oceanography / 760 840 8660 mobile /
> stonesteps (Skype) / stonesteps7 (iChat) / http://www.sdsc.edu/~hellyj
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From vanessa.vaart at gmail.com  Sun Jul 28 00:55:26 2013
From: vanessa.vaart at gmail.com (vanessa van der vaart)
Date: Sat, 27 Jul 2013 23:55:26 +0100
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <1374893114.11693.YahooMailNeo@web142604.mail.bf1.yahoo.com>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>
	<51F2C544.8030809@statistik.tu-dortmund.de>
	<AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>
	<7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>
	<1374893114.11693.YahooMailNeo@web142604.mail.bf1.yahoo.com>
Message-ID: <CAEQiC4hs1ENPQJwGS3he-2sPud8K_rh=jro_p2bz4PG2_35PUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130727/0637afc6/attachment.pl>

From smartpink111 at yahoo.com  Sun Jul 28 03:11:24 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 27 Jul 2013 18:11:24 -0700 (PDT)
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <CAEQiC4hs1ENPQJwGS3he-2sPud8K_rh=jro_p2bz4PG2_35PUg@mail.gmail.com>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>	<51F2C544.8030809@statistik.tu-dortmund.de>	<AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>	<7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>	<1374893114.11693.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAEQiC4hs1ENPQJwGS3he-2sPud8K_rh=jro_p2bz4PG2_35PUg@mail.gmail.com>
Message-ID: <1374973884.42471.YahooMailNeo@web142605.mail.bf1.yahoo.com>

HI,
May be this is what you wanted.
#using tt1
indx<-which(tt1$response=="buy")
tt1$newcolumn<-0
tt1[unique(unlist(lapply(seq_along(indx),function(i){x1<-if(i==length(indx)) seq(indx[i],nrow(tt1)) else if((indx[i+1]-indx[i])==1) indx[i] else seq(indx[i]+1,indx[i+1]-1);x2<- tt1[unique(c(indx[1:i],x1)),];x3<-subset(x2,response=="sample");x4<- subset(x2,response=="buy"); x5<-row.names(x4)[duplicated(x4$product)];x6<-if(nrow(x3)!=0) row.names(x3)[x3$product%in% x4$product];sort(c(x5,x6))}))),"newcolumn"]<-1


?tt1
?? subj response product newcolumn
1???? 1?? sample?????? 1???????? 0
2???? 1?? sample?????? 2???????? 0
3???? 1????? buy?????? 3???????? 0
4???? 2?? sample?????? 2???????? 0
5???? 2????? buy?????? 2???????? 0
6???? 3?? sample?????? 3???????? 1
7???? 3?? sample?????? 2???????? 1
8???? 3????? buy?????? 1???????? 0
9???? 4?? sample?????? 1???????? 1
10??? 4????? buy?????? 4???????? 0
11??? 5????? buy?????? 4???????? 1
12??? 5?? sample?????? 2???????? 1
13??? 5????? buy?????? 2???????? 1
14??? 6????? buy?????? 4???????? 1
15??? 6?? sample?????? 5???????? 0
16??? 6?? sample?????? 5???????? 0
17??? 7?? sample?????? 4???????? 1
18??? 7????? buy?????? 3???????? 1
19??? 7????? buy?????? 4???????? 1
20??? 8????? buy?????? 5???????? 0
21??? 8?? sample?????? 4???????? 1
22??? 8????? buy?????? 2???????? 1
A.K.





________________________________
From: vanessa van der vaart <vanessa.vaart at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: David Winsemius <dwinsemius at comcast.net>; R help <r-help at r-project.org> 
Sent: Saturday, July 27, 2013 6:55 PM
Subject: Re: [R] Duplicated function with conditional statement



Dear all,,
thank you all for your help..Its been such a help but its not really exactly what I am looking for. Apparently I havent explained the condition very clearly. I hope this can works.

If the data on column product is duplicated from the previous row, (its applied for response==buy and ==sample) , and it is duplicated from the row which has the value on column 'response'== buy, than ?the value = 1, otherwise is =0.
so in that case,
if the value is duplicated but it is duplicated from the previous row where the value of resonse==sample, than it is not considered duplicated, and in the new column is 0

thank you very much in advance,
I really appreciated



On Sat, Jul 27, 2013 at 3:45 AM, arun <smartpink111 at yahoo.com> wrote:


>
>On some slightly different datasets:
>tt1<-structure(list(subj = c(1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5,
>6, 6, 6, 7, 7, 7, 8, 8, 8), response = structure(c(2L, 2L, 1L,
>2L, 1L, 2L, 2L, 1L, 2L, 1L, 1L, 2L, 1L, 1L, 2L, 2L, 2L, 1L, 1L,
>1L, 2L, 1L), .Label = c("buy", "sample"), class = "factor"),
>??? product = c(1, 2, 3, 2, 2, 3, 2, 1, 1, 4, 4, 2, 2, 4, 5,
>??? 5, 4, 3, 4, 5, 4, 2)), .Names = c("subj", "response", "product"
>), class = "data.frame", row.names = c(NA, 22L))
>
>tt2<- structure(list(subj = c(1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5,
>6, 6, 6, 7, 7, 7, 8, 8, 8), response = structure(c(2L, 2L, 1L,
>2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 1L, 2L, 2L, 2L, 2L, 1L,
>1L, 2L, 2L), .Label = c("buy", "sample"), class = "factor"),
>??? product = c(1, 2, 3, 2, 2, 3, 2, 1, 1, 4, 1, 4, 5, 1, 4,
>??? 2, 3, 3, 2, 5, 3, 4)), .Names = c("subj", "response", "product"
>), class = "data.frame", row.names = c(NA, 22L))
>
>tt3<- structure(list(subj = c(1, 1, 1, 2, 2, 3, 3, 3, 4, 4, 5, 5, 5,
>6, 6, 6, 7, 7, 7, 8, 8, 8), response = structure(c(2L, 2L, 1L,
>2L, 1L, 2L, 2L, 1L, 2L, 1L, 2L, 2L, 2L, 2L, 1L, 2L, 2L, 1L, 1L,
>1L, 1L, 2L), .Label = c("buy", "sample"), class = "factor"),
>??? product = c(1, 2, 3, 2, 2, 3, 2, 1, 1, 4, 1, 1, 3, 5, 2,
>??? 2, 2, 2, 4, 3, 2, 5)), .Names = c("subj", "response", "product"
>), class = "data.frame", row.names = c(NA, 22L))
>
>
>#Tried David's solution:
>tt1$rown <- rownames(tt1)
>as.numeric ( apply(tt1, 1, function(x) {
>??? x['product'] %in% tt1[ rownames(tt1) < x['rown'] & tt1$response == "buy", "product"]? } ) )
>? #gave inconsistent results especially since the first 10 rows were from `tt`
># [1] 0 1 1 1 1 1 1 0 1 0 1 0 0 1 0 0 1 0 1 0 1 1
>
>#similarly for `tt2` and `tt3`.
>
>
>##Created this function.? It seems to work in the tested cases, though it is not tested extensively.
>fun1<- function(dat,colName,newColumn){
>????? indx<- which(dat[,colName]=="buy")
>????? dat[,newColumn]<-0
>????? dat[unlist(lapply(seq_along(indx),function(i){
>??? ??? ??? x1<- if(i==length(indx)){
>??? ??? ??? ??? seq(indx[i],nrow(dat))
>??? ??? ??? ?}
>??? ??? ??? else if((indx[i+1]-indx[i])==1){
>??? ??? ??? indx[i]
>??? ??? ??? }
>??? ??? ??? else {
>??? ??? ??? seq(indx[i]+1,indx[i+1]-1)
>??? ??? ??? ?}
>??? ??? ??? x2<- dat[unique(c(indx[i:1],x1)),]
>??? ??? ??? x3<- subset(x2,response=="sample")
>??? ??? ??? x4<- subset(x2,response=="buy")
>??? ??? ??? if(nrow(x3)!=0) {
>??? ??? ??? ??????????????? row.names(x3)[x3$product%in% x4$product]
>??? ??? ??? ??? ??? ?? }
>??? ??? ??? ??? ??? ??? ??? ??? ???
>??? ??? ??? })),newColumn]<-1
>??? dat
>
>??? }
>fun1(tt,"response","newCol")
>#?? subj response product rown newCol
>#1???? 1?? sample?????? 1??? 1????? 0
>#2???? 1?? sample?????? 2??? 2????? 0
>#3???? 1????? buy?????? 3??? 3????? 0
>#4???? 2?? sample?????? 2??? 4????? 0
>#5???? 2????? buy?????? 2??? 5????? 0
>#6???? 3?? sample?????? 3??? 6????? 1
>#7???? 3?? sample?????? 2??? 7????? 1
>#8???? 3????? buy?????? 1??? 8????? 0
>#9???? 4?? sample?????? 1??? 9????? 1
>#10??? 4????? buy?????? 4?? 10????? 0
>
>fun1(tt1,"response","newCol")
>#?? subj response product newCol
>#1???? 1?? sample?????? 1????? 0
>#2???? 1?? sample?????? 2????? 0
>#3???? 1????? buy?????? 3????? 0
>#4???? 2?? sample?????? 2????? 0
>#5???? 2????? buy?????? 2????? 0
>#6???? 3?? sample?????? 3????? 1
>#7???? 3?? sample?????? 2????? 1
>#8???? 3????? buy?????? 1????? 0
>#9???? 4?? sample?????? 1????? 1
>#10??? 4????? buy?????? 4????? 0
>#11??? 5????? buy?????? 4????? 0
>#12??? 5?? sample?????? 2????? 1
>#13??? 5????? buy?????? 2????? 0
>#14??? 6????? buy?????? 4????? 0
>#15??? 6?? sample?????? 5????? 0
>#16??? 6?? sample?????? 5????? 0
>#17??? 7?? sample?????? 4????? 1
>#18??? 7????? buy?????? 3????? 0
>#19??? 7????? buy?????? 4????? 0
>#20??? 8????? buy?????? 5????? 0
>#21??? 8?? sample?????? 4????? 1
>#22??? 8????? buy?????? 2????? 0
>#Also
>?fun1(tt2,"response","newCol")
>?fun1(tt3,"response","newCol")
>A.K.
>
>P.S.? Below is OP's clarification regarding the conditional statement in a private message:
>
>I am sorry i didnt question it very clearly, let me change the
>conditional statement, I hope you can understand. i will explain by
>example
>
>as you can see, almost every number is duplicated, but only in row 6th,7th,and 9th the value on column is 1.
>
>on row4th, the value is duplicated( 2 already?occurred?on 2nd row),but
>since the value is considered as duplicated only if the value is
>duplicated where the response is 'buy' than the value on column, on
>row4th still zero.?
>
>On row 6th, where the value product column is 3. 3 is already occurred
>in 3rd row where the value on response is 'buy', so the value on column
>should be 1
>
>I hope it can understand the conditional statement.
>
>
>
>
>
>
>
>
>
>----- Original Message -----
>From: David Winsemius <dwinsemius at comcast.net>
>To: David Winsemius <dwinsemius at comcast.net>
>Cc: R-help at r-project.org; Uwe Ligges <ligges at statistik.tu-dortmund.de>
>Sent: Friday, July 26, 2013 5:16 PM
>Subject: Re: [R] Duplicated function with conditional statement
>
>
>On Jul 26, 2013, at 2:06 PM, David Winsemius wrote:
>
>>
>> On Jul 26, 2013, at 11:51 AM, Uwe Ligges wrote:
>>
>>>
>>>
>>> On 25.07.2013 21:05, vanessa van der vaart wrote:
>>>> Hi everybody,,
>>>> I have a question about R function duplicated(). I have spent days try to
>>>> figure this out,but I cant find any solution yet. I hope somebody can help
>>>> me..
>>>> this is my data:
>>>>
>>>> subj=c(1,1,1,2,2,3,3,3,4,4)
>>>> response=c('sample','sample','buy','sample','buy','sample','
>>>> sample','buy','sample','buy')
>>>> product=c(1,2,3,2,2,3,2,1,1,4)
>>>> tt=data.frame(subj, response, product)
>>>>
>>>> the data look like this:
>>>>
>>>> subj response product
>>>> 1? ? ?1? ?sample? ? ? ?1
>>>> 2? ? ?1? ?sample? ? ? ?2
>>>> 3? ? ?1? ? ? buy? ? ? ? ? 3
>>>> 4? ? ?2? ?sample? ? ? ?2
>>>> 5? ? ?2? ? ? ? ?buy? ? ? ?2
>>>> 6? ? ?3? ?sample? ? ? ?3
>>>> 7? ? ?3? ?sample? ? ? ?2
>>>> 8? ? ?3? ? ? ? ?buy? ? ? ?1
>>>> 9? ? ?4? sample? ? ? ?1
>>>> 10? ?4? ? ? ?buy? ? ? ? 4
>>>>
>>>> I want to create new? column based on the value on response and product
>>>> column. if the value on product is duplicated, then? the value on new column
>>>> is 1, otherwise is 0.
>>>
>>>
>>> According to your description:
>>>
>>
>> Agree that the description did not match the output. I tried to match the output using a rule that could be expressed as:
>>
>> if( a "buy"- associated "product" value precedes the current "product" value){1}else{0}
>>
>
>So this delivers the specified output:
>
>tt$rown <- rownames(tt)
>as.numeric ( apply(tt, 1, function(x) {
>? ? ?x['product'] %in% tt[ rownames(tt) < x['rown'] & tt$response == "buy", "product"]? } ) )
>
># [1] 0 0 0 0 0 1 1 0 1 0
>
>> --
>> David.
>>
>>> tt$newcolumn <- as.integer(duplicated(tt$product) & tt$response=="buy")
>>>
>>> which is different from what you show us below, where I cannot derive any systematic rule from.
>>>
>>> Uwe Ligges
>>>
>>>> but I want to add conditional statement that the value on product column
>>>> will only be considered as duplicated if the value on response column is
>>>> 'buy'.
>>>> for illustration, the table should look like this:
>>>>
>>>> subj response product newcolumn
>>>> 1? ? ?1? ?sample? ? ? ?1? ? ? ? ? 0
>>>> 2? ? ?1? ?sample? ? ? ?2? ? ? ? ? 0
>>>> 3? ? ?1? ? ? buy? ? ? ? ? 3? ? ? ? ? 0
>>>> 4? ? ?2? ?sample? ? ? ?2? ? ? ? ? 0
>>>> 5? ? ?2? ? ? ? ?buy? ? ? ?2? ? ? ? ? 0
>>>> 6? ? ?3? ?sample? ? ? ?3? ? ? ? ? 1
>>>> 7? ? ?3? ?sample? ? ? ?2? ? ? ? ? ?1
>>>> 8? ? ?3? ? ? ? ?buy? ? ? ?1? ? ? ? ? ?0
>>>> 9? ? ?4? sample? ? ? ?1? ? ? ? ? ? 1
>>>> 10? ?4? ? ? ?buy? ? ? ?4? ? ? ? ? ? ?0
>>>>
>>>>
>>>> can somebody help me?
>>>> any help will be appreciated.
>>>> I am new in this mailing list, so forgive me in advance, If I did not? ask
>>>> the question appropriately.
>>>>
>>>> ??? [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>David Winsemius
>Alameda, CA, USA
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.
>
>


From smartpink111 at yahoo.com  Sun Jul 28 03:40:14 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 27 Jul 2013 18:40:14 -0700 (PDT)
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <1374973884.42471.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>	<51F2C544.8030809@statistik.tu-dortmund.de>	<AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>	<7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>	<1374893114.11693.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAEQiC4hs1ENPQJwGS3he-2sPud8K_rh=jro_p2bz4PG2_35PUg@mail.gmail.com>
	<1374973884.42471.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <1374975614.56248.YahooMailNeo@web142606.mail.bf1.yahoo.com>

If you wanted to wrap it in a function:


fun1<- function(dat,colName,newColumn){
????? indx<- which(dat[,colName]=="buy")
????? dat[,newColumn]<-0
????? dat[unique(unlist(lapply(seq_along(indx),function(i){
??? ??? ??? x1<- if(i==length(indx)){
??? ??? ??? ??? seq(indx[i],nrow(dat))
??? ??? ??? ?}
??? ??? ??? else if((indx[i+1]-indx[i])==1){
??? ??? ??? indx[i]
??? ??? ??? }
??? ??? ??? else {
??? ??? ??? seq(indx[i]+1,indx[i+1]-1)
??? ??? ??? ?}
??? ??? ??? x2<- dat[unique(c(indx[i:1],x1)),]
??? ??? ??? x3<- subset(x2,response=="sample")
??? ??? ??? x4<- subset(x2,response=="buy")
??? ??? ??? x4New<-x4[order(as.numeric(row.names(x4))),]
??? ??? ??? x5<- row.names(x4New)[duplicated(x4New$product)]
??? ??? ??? x6<- if(nrow(x3)!=0) {
??? ??? ??? ??????????????? row.names(x3)[x3$product%in% x4$product]
??? ??? ??? ??? ??? ?? }
??? ??? ??? 
??? ??? ??? sort(as.numeric(c(x5,x6)))
??? ??? ??? }))),newColumn] <- 1
??? dat??? 

??? }


?fun1(tt1,"response","newCol")
#?? subj response product newCol
#1???? 1?? sample?????? 1????? 0
#2???? 1?? sample?????? 2????? 0
#3???? 1????? buy?????? 3????? 0
#4???? 2?? sample?????? 2????? 0
#5???? 2????? buy?????? 2????? 0
#6???? 3?? sample?????? 3????? 1
#7???? 3?? sample?????? 2????? 1
#8???? 3????? buy?????? 1????? 0
#9???? 4?? sample?????? 1????? 1
#10??? 4????? buy?????? 4????? 0
#11??? 5????? buy?????? 4????? 1
#12??? 5?? sample?????? 2????? 1
#13??? 5????? buy?????? 2????? 1
#14??? 6????? buy?????? 4????? 1
#15??? 6?? sample?????? 5????? 0
#16??? 6?? sample?????? 5????? 0
#17??? 7?? sample?????? 4????? 1
#18??? 7????? buy?????? 3????? 1
#19??? 7????? buy?????? 4????? 1
#20??? 8????? buy?????? 5????? 0
#21??? 8?? sample?????? 4????? 1
#22??? 8????? buy?????? 2????? 1

A.K.


----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: vanessa van der vaart <vanessa.vaart at gmail.com>
Cc: David Winsemius <dwinsemius at comcast.net>; R help <r-help at r-project.org>
Sent: Saturday, July 27, 2013 9:11 PM
Subject: Re: [R] Duplicated function with conditional statement

HI,
May be this is what you wanted.
#using tt1
indx<-which(tt1$response=="buy")
tt1$newcolumn<-0
tt1[unique(unlist(lapply(seq_along(indx),function(i){x1<-if(i==length(indx)) seq(indx[i],nrow(tt1)) else if((indx[i+1]-indx[i])==1) indx[i] else seq(indx[i]+1,indx[i+1]-1);x2<- tt1[unique(c(indx[1:i],x1)),];x3<-subset(x2,response=="sample");x4<- subset(x2,response=="buy"); x5<-row.names(x4)[duplicated(x4$product)];x6<-if(nrow(x3)!=0) row.names(x3)[x3$product%in% x4$product];sort(c(x5,x6))}))),"newcolumn"]<-1


?tt1
?? subj response product newcolumn
1???? 1?? sample?????? 1???????? 0
2???? 1?? sample?????? 2???????? 0
3???? 1????? buy?????? 3???????? 0
4???? 2?? sample?????? 2???????? 0
5???? 2????? buy?????? 2???????? 0
6???? 3?? sample?????? 3???????? 1
7???? 3?? sample?????? 2???????? 1
8???? 3????? buy?????? 1???????? 0
9???? 4?? sample?????? 1???????? 1
10??? 4????? buy?????? 4???????? 0
11??? 5????? buy?????? 4???????? 1
12??? 5?? sample?????? 2???????? 1
13??? 5????? buy?????? 2???????? 1
14??? 6????? buy?????? 4???????? 1
15??? 6?? sample?????? 5???????? 0
16??? 6?? sample?????? 5???????? 0
17??? 7?? sample?????? 4???????? 1
18??? 7????? buy?????? 3???????? 1
19??? 7????? buy?????? 4???????? 1
20??? 8????? buy?????? 5???????? 0
21??? 8?? sample?????? 4???????? 1
22??? 8????? buy?????? 2???????? 1
A.K.





________________________________
From: vanessa van der vaart <vanessa.vaart at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Cc: David Winsemius <dwinsemius at comcast.net>; R help <r-help at r-project.org> 
Sent: Saturday, July 27, 2013 6:55 PM
Subject: Re: [R] Duplicated function with conditional statement



Dear all,,
thank you all for your help..Its been such a help but its not really exactly what I am looking for. Apparently I havent explained the condition very clearly. I hope this can works.

If the data on column product is duplicated from the previous row, (its applied for response==buy and ==sample) , and it is duplicated from the row which has the value on column 'response'== buy, than ?the value = 1, otherwise is =0.
so in that case,
if the value is duplicated but it is duplicated from the previous row where the value of resonse==sample, than it is not considered duplicated, and in the new column is 0

thank you very much in advance,
I really appreciated


From dwarnold45 at suddenlink.net  Sun Jul 28 03:49:51 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sat, 27 Jul 2013 18:49:51 -0700 (PDT)
Subject: [R] tikzDevice
Message-ID: <1374976191353-4672523.post@n4.nabble.com>

All,

What is the current method for installing tikzDevice in R version 3.0.1? I'd
like to use it with knitr and RStudio.

Thanks.

D.



--
View this message in context: http://r.789695.n4.nabble.com/tikzDevice-tp4672523.html
Sent from the R help mailing list archive at Nabble.com.


From xie at yihui.name  Sun Jul 28 04:08:41 2013
From: xie at yihui.name (Yihui Xie)
Date: Sat, 27 Jul 2013 19:08:41 -0700
Subject: [R] tikzDevice
In-Reply-To: <1374976191353-4672523.post@n4.nabble.com>
References: <1374976191353-4672523.post@n4.nabble.com>
Message-ID: <CANROs4c1VXdctnVgktfu93u6DDKdUr=Koe11s5o2f2Z0auqfYQ@mail.gmail.com>

It seems I can still install from source under Ubuntu:

install.packages('tikzDevice', repos='http://r-forge.r-project.org',
type='source')

If you are under Windows, I think you have to install RTools.

I'm cc'ing its author to see if there is still hope to get it back to
CRAN, or if someone else can resurrect this great package and the
original author is willing to hand over the maintainership.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Sat, Jul 27, 2013 at 6:49 PM, David Arnold <dwarnold45 at suddenlink.net> wrote:
> All,
>
> What is the current method for installing tikzDevice in R version 3.0.1? I'd
> like to use it with knitr and RStudio.
>
> Thanks.
>
> D.
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/tikzDevice-tp4672523.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwarnold45 at suddenlink.net  Sun Jul 28 04:18:51 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sat, 27 Jul 2013 19:18:51 -0700 (PDT)
Subject: [R] tikzDevice
In-Reply-To: <CANROs4c1VXdctnVgktfu93u6DDKdUr=Koe11s5o2f2Z0auqfYQ@mail.gmail.com>
References: <1374976191353-4672523.post@n4.nabble.com>
	<CANROs4c1VXdctnVgktfu93u6DDKdUr=Koe11s5o2f2Z0auqfYQ@mail.gmail.com>
Message-ID: <1374977931205-4672525.post@n4.nabble.com>

I am using a MacBook Pro, 10.6.8, R version 3.0.1. and RStudio 0.97.551. I
entered your command in the Console Window in RStudio and got the following
reply:

> install.packages('tikzDevice', repos='http://r-forge.r-project.org',
> type='source')
Warning in install.packages :
  package ?tikzDevice? is not available (for R version 3.0.1)
trying URL
'http://r-forge.r-project.org/src/contrib/tikzDevice_0.6.3.tar.gz'
Content type 'application/x-gzip' length 1733547 bytes (1.7 Mb)
opened URL
==================================================
downloaded 1.7 Mb

* installing *source* package ?tikzDevice? ...
** libs
llvm-gcc-4.2 -arch x86_64 -std=gnu99
-I/Library/Frameworks/R.framework/Resources/include -DNDEBUG 
-I/usr/local/include    -fPIC  -mtune=core2 -g -O2  -c tikzDevice.c -o
tikzDevice.o
tikzDevice.c: In function ?TikZ_Setup?:
tikzDevice.c:286: warning: passing argument 1 of ?__builtin___strcpy_chk?
discards qualifiers from pointer target type
tikzDevice.c:286: warning: passing argument 1 of ?__inline_strcpy_chk?
discards qualifiers from pointer target type
tikzDevice.c:288: warning: passing argument 1 of ?__builtin___strcpy_chk?
discards qualifiers from pointer target type
tikzDevice.c:288: warning: passing argument 1 of ?__inline_strcpy_chk?
discards qualifiers from pointer target type
tikzDevice.c:290: warning: passing argument 1 of ?__builtin___strcpy_chk?
discards qualifiers from pointer target type
tikzDevice.c:290: warning: passing argument 1 of ?__inline_strcpy_chk?
discards qualifiers from pointer target type
tikzDevice.c: In function ?TikZ_Close?:
tikzDevice.c:579: warning: passing argument 1 of ?free? discards qualifiers
from pointer target type
tikzDevice.c:580: warning: passing argument 1 of ?free? discards qualifiers
from pointer target type
tikzDevice.c:581: warning: passing argument 1 of ?free? discards qualifiers
from pointer target type
llvm-gcc-4.2 -arch x86_64 -std=gnu99 -dynamiclib
-Wl,-headerpad_max_install_names -undefined dynamic_lookup -single_module
-multiply_defined suppress -L/usr/local/lib -L/usr/local/lib -o
tikzDevice.so tikzDevice.o -F/Library/Frameworks/R.framework/.. -framework R
-Wl,-framework -Wl,CoreFoundation
installing to
/Library/Frameworks/R.framework/Versions/3.0/Resources/library/tikzDevice/libs
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
   ?tikzDevice.Rnw? 
** testing if installed package can be loaded
* DONE (tikzDevice)

The downloaded source packages are in

?/private/var/folders/qE/qEavkZWTFMmxjncuY+HnqE+++TI/-Tmp-/RtmpGK7w0V/downloaded_packages?



--
View this message in context: http://r.789695.n4.nabble.com/tikzDevice-tp4672523p4672525.html
Sent from the R help mailing list archive at Nabble.com.


From dwarnold45 at suddenlink.net  Sun Jul 28 04:25:37 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sat, 27 Jul 2013 19:25:37 -0700 (PDT)
Subject: [R] tikzDevice
In-Reply-To: <1374977931205-4672525.post@n4.nabble.com>
References: <1374976191353-4672523.post@n4.nabble.com>
	<CANROs4c1VXdctnVgktfu93u6DDKdUr=Koe11s5o2f2Z0auqfYQ@mail.gmail.com>
	<1374977931205-4672525.post@n4.nabble.com>
Message-ID: <1374978337117-4672526.post@n4.nabble.com>

The following minimal example Sweave file compiled properly in RStudio.

\documentclass{article}

\begin{document}

Example text outside R code here; we know the value of pi is \Sexpr{pi}.
<<my-label, eval=TRUE, dev='tikz'>>=
set.seed(1213)  # for reproducibility
x = cumsum(rnorm(100))
mean(x)  # mean of x
plot(x, type = 'l')  # Brownian motion
@
Other text outside R code here.

\end{document}

Result:  junk.pdf <http://r.789695.n4.nabble.com/file/n4672526/junk.pdf>  



--
View this message in context: http://r.789695.n4.nabble.com/tikzDevice-tp4672523p4672526.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Sun Jul 28 05:55:48 2013
From: smartpink111 at yahoo.com (arun)
Date: Sat, 27 Jul 2013 20:55:48 -0700 (PDT)
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <CAEQiC4jtUPfUKxu+OY+i5rQEw36Q=ST3bRwvS3XuMA3a1HCQWA@mail.gmail.com>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>	<51F2C544.8030809@statistik.tu-dortmund.de>	<AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>	<7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>	<1374893114.11693.YahooMailNeo@web142604.mail.bf1.yahoo.com>	<CAEQiC4hs1ENPQJwGS3he-2sPud8K_rh=jro_p2bz4PG2_35PUg@mail.gmail.com>	<1374973884.42471.YahooMailNeo@web142605.mail.bf1.yahoo.com>	<1374975614.56248.YahooMailNeo@web142606.mail.bf1.yahoo.com>	<CAEQiC4gQbyMbNrYnTwVmdnqbnp2vJCPOfR=ta8CHV04VAyK+Zg@mail.gmail.com>
	<CAEQiC4jtUPfUKxu+OY+i5rQEw36Q=ST3bRwvS3XuMA3a1HCQWA@mail.gmail.com>
Message-ID: <1374983748.55460.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Dear Vanessa,
Glad to know that it works.
Sorry, I misunderstood ur question initially because there were no duplicates for "product" from response=="buy" in your initial dataset (tt).
Regarding the code: what i did in brief is:
1. Find the rows with response=="buy
?indx<- which(dat[,colName]=="buy")? #in fun1()
dat[,newColumn]<-0 #created a newcolumn with 0's
2.? Loop over these `indx` using lapply()
3. Checked some conditions:
? a. if(i==length(indx)) #means if it is the last element in indx or the last row with response=="buy"
??? seq(indx[i], nrow(dat)) # here I wanted to get the sequence from the last indx to the last? row of dataframe
?? #for example.

? indx<-which(tt1$response=="buy")
?indx
# [1]? 3? 5? 8 10 11 13 14 18 19 20 22
?nrow(tt1)
#[1] 22
seq(indx[length(indx)],nrow(tt1))
#[1] 22
#this could change depending upon the two values.
seq(20,22) #if the last indx with response=="buy" was in 20th row
#[1] 20 21 22

b. the second condition occurs when you have consecutive "buy" rows
?else if((indx[i+1]-indx[i])==1){
indx
# [1]? 3? 5? 8 10 11 13 14 18 19 20 22
indx[5]-indx[4] # or
indx[7]-indx[6] #or
indx[9]-indx[8] etc..
then I would want that indx[i] value in the loop

c. if it is other cases:
indx[1], indx[2]
seq(indx[1]+1, indx[1+1]-1)
#[1] 4
4. x2<- dat[unique(c(indx[i:1],x1)),] ### this was a bug in the function which troubled me.
it should be
x2<- dat[unique(c(indx[1:i],x1)),] #this is what I was looking for.? It created a problem which I fixed using
x4New<- #? 
x2 ## gives me all the rows starting from the 1st row of response=="buy" to that row of response=="buy" according to the indx + the rows that are between two indx values
For indx[1], it should be row 4 because indx[2] is 5.
likewise for indx[2], it is
seq(indx[2]+1, indx[2+1]-1)
#[1] 6 7

5. Subset the data `x2` into x3 and x4 which have response=="sample" and response=="buy" respectively
6. x4New <- # because of a previous mistake by me.? It is still needed as an additional check
7. x5<- # it checks the duplicated rows for product in x4New
8. x6<- #here, a condition was used because some list elements have 0 rows for x3.? I guess it occurs when you have consecutive "buy" rows.
9. sort(as.numeric(c(x5,x6))) #concatentate and sorted these
10. unique(unlist(.... #unlist the list and choose only the unique elements
11. dat[unique(unlist(....,newColumn]<-1 # assign those rows that fits the condition in newColumn as 1.

Hope it helps.
Regards,
A.K.

?














________________________________
From: vanessa van der vaart <vanessa.vaart at gmail.com>
To: arun <smartpink111 at yahoo.com> 
Sent: Saturday, July 27, 2013 11:07 PM
Subject: Re: [R] Duplicated function with conditional statement



Dear Arun,,

Thank you very much. the code really works.

I was wondering if you could explain how the code works.
I am really interested in R, and I really want to master it?

I will really appreciate it, but please, if you think this is too much to ask, please just ignore it.

Thank you very much in advance,
Best Regards,Vanessa



On Sun, Jul 28, 2013 at 4:02 AM, vanessa van der vaart <vanessa.vaart at gmail.com> wrote:

Dear Arun,,
>
>
>Thank you. its perfect! wow! thank you very much..and David, thank you for you too.. its such a help. I am so sorry it must've been confusing at the beginning..
>really, I dont know how to thank you.. ?
>
>
>well do you mind if I ask you how can you be so expert? what kind a book or training did you have? and how long have you been working on R?
>I am really interested in R
>
>
>
>On Sun, Jul 28, 2013 at 2:40 AM, arun <smartpink111 at yahoo.com> wrote:
>
>If you wanted to wrap it in a function:
>>
>>
>>
>>fun1<- function(dat,colName,newColumn){
>>????? indx<- which(dat[,colName]=="buy")
>>????? dat[,newColumn]<-0
>>????? dat[unique(unlist(lapply(seq_along(indx),function(i){
>>
>>??? ??? ??? x1<- if(i==length(indx)){
>>??? ??? ??? ??? seq(indx[i],nrow(dat))
>>??? ??? ??? ?}
>>??? ??? ??? else if((indx[i+1]-indx[i])==1){
>>??? ??? ??? indx[i]
>>??? ??? ??? }
>>??? ??? ??? else {
>>??? ??? ??? seq(indx[i]+1,indx[i+1]-1)
>>??? ??? ??? ?}
>>??? ??? ??? x2<- dat[unique(c(indx[i:1],x1)),]
>>??? ??? ??? x3<- subset(x2,response=="sample")
>>??? ??? ??? x4<- subset(x2,response=="buy")
>>??? ??? ??? x4New<-x4[order(as.numeric(row.names(x4))),]
>>??? ??? ??? x5<- row.names(x4New)[duplicated(x4New$product)]
>>??? ??? ??? x6<- if(nrow(x3)!=0) {
>>??? ??? ??? ??????????????? row.names(x3)[x3$product%in% x4$product]
>>??? ??? ??? ??? ??? ?? }
>>??? ??? ???
>>??? ??? ??? sort(as.numeric(c(x5,x6)))
>>??? ??? ??? }))),newColumn] <- 1
>>??? dat???
>>
>>
>>??? }
>>
>>
>>?fun1(tt1,"response","newCol")
>>#?? subj response product newCol
>>#1???? 1?? sample?????? 1????? 0
>>#2???? 1?? sample?????? 2????? 0
>>#3???? 1????? buy?????? 3????? 0
>>#4???? 2?? sample?????? 2????? 0
>>#5???? 2????? buy?????? 2????? 0
>>#6???? 3?? sample?????? 3????? 1
>>#7???? 3?? sample?????? 2????? 1
>>#8???? 3????? buy?????? 1????? 0
>>#9???? 4?? sample?????? 1????? 1
>>#10??? 4????? buy?????? 4????? 0
>>#11??? 5????? buy?????? 4????? 1
>>#12??? 5?? sample?????? 2????? 1
>>#13??? 5????? buy?????? 2????? 1
>>#14??? 6????? buy?????? 4????? 1
>>#15??? 6?? sample?????? 5????? 0
>>#16??? 6?? sample?????? 5????? 0
>>#17??? 7?? sample?????? 4????? 1
>>#18??? 7????? buy?????? 3????? 1
>>#19??? 7????? buy?????? 4????? 1
>>#20??? 8????? buy?????? 5????? 0
>>#21??? 8?? sample?????? 4????? 1
>>#22??? 8????? buy?????? 2????? 1
>>
>>A.K.
>>
>>
>>
>>----- Original Message -----
>>From: arun <smartpink111 at yahoo.com>
>>To: vanessa van der vaart <vanessa.vaart at gmail.com>
>>Cc: David Winsemius <dwinsemius at comcast.net>; R help <r-help at r-project.org>
>>
>>Sent: Saturday, July 27, 2013 9:11 PM
>>Subject: Re: [R] Duplicated function with conditional statement
>>
>>HI,
>>May be this is what you wanted.
>>#using tt1
>>indx<-which(tt1$response=="buy")
>>tt1$newcolumn<-0
>>tt1[unique(unlist(lapply(seq_along(indx),function(i){x1<-if(i==length(indx)) seq(indx[i],nrow(tt1)) else if((indx[i+1]-indx[i])==1) indx[i] else seq(indx[i]+1,indx[i+1]-1);x2<- tt1[unique(c(indx[1:i],x1)),];x3<-subset(x2,response=="sample");x4<- subset(x2,response=="buy"); x5<-row.names(x4)[duplicated(x4$product)];x6<-if(nrow(x3)!=0) row.names(x3)[x3$product%in% x4$product];sort(c(x5,x6))}))),"newcolumn"]<-1
>>
>>
>>?tt1
>>?? subj response product newcolumn
>>1???? 1?? sample?????? 1???????? 0
>>2???? 1?? sample?????? 2???????? 0
>>3???? 1????? buy?????? 3???????? 0
>>4???? 2?? sample?????? 2???????? 0
>>5???? 2????? buy?????? 2???????? 0
>>6???? 3?? sample?????? 3???????? 1
>>7???? 3?? sample?????? 2???????? 1
>>8???? 3????? buy?????? 1???????? 0
>>9???? 4?? sample?????? 1???????? 1
>>10??? 4????? buy?????? 4???????? 0
>>11??? 5????? buy?????? 4???????? 1
>>12??? 5?? sample?????? 2???????? 1
>>13??? 5????? buy?????? 2???????? 1
>>14??? 6????? buy?????? 4???????? 1
>>15??? 6?? sample?????? 5???????? 0
>>16??? 6?? sample?????? 5???????? 0
>>17??? 7?? sample?????? 4???????? 1
>>18??? 7????? buy?????? 3???????? 1
>>19??? 7????? buy?????? 4???????? 1
>>20??? 8????? buy?????? 5???????? 0
>>21??? 8?? sample?????? 4???????? 1
>>22??? 8????? buy?????? 2???????? 1
>>A.K.
>>
>>
>>
>>
>>
>>________________________________
>>From: vanessa van der vaart <vanessa.vaart at gmail.com>
>>To: arun <smartpink111 at yahoo.com>
>>Cc: David Winsemius <dwinsemius at comcast.net>; R help <r-help at r-project.org>
>>Sent: Saturday, July 27, 2013 6:55 PM
>>Subject: Re: [R] Duplicated function with conditional statement
>>
>>
>>
>>Dear all,,
>>thank you all for your help..Its been such a help but its not really exactly what I am looking for. Apparently I havent explained the condition very clearly. I hope this can works.
>>
>>If the data on column product is duplicated from the previous row, (its applied for response==buy and ==sample) , and it is duplicated from the row which has the value on column 'response'== buy, than ?the value = 1, otherwise is =0.
>>so in that case,
>>if the value is duplicated but it is duplicated from the previous row where the value of resonse==sample, than it is not considered duplicated, and in the new column is 0
>>
>>thank you very much in advance,
>>I really appreciated
>>
>


From vanessa.vaart at gmail.com  Sun Jul 28 05:02:38 2013
From: vanessa.vaart at gmail.com (vanessa van der vaart)
Date: Sun, 28 Jul 2013 04:02:38 +0100
Subject: [R] Duplicated function with conditional statement
In-Reply-To: <1374975614.56248.YahooMailNeo@web142606.mail.bf1.yahoo.com>
References: <CAEQiC4i3YMb7KEUcCg8UcaEpS5RqRUfiT=dv+h3d5wS1TujFbQ@mail.gmail.com>
	<51F2C544.8030809@statistik.tu-dortmund.de>
	<AD3805BE-7BE6-43A5-B37F-775222E84468@comcast.net>
	<7A2E6FDA-4369-4FB2-B5D5-8B229D49C982@comcast.net>
	<1374893114.11693.YahooMailNeo@web142604.mail.bf1.yahoo.com>
	<CAEQiC4hs1ENPQJwGS3he-2sPud8K_rh=jro_p2bz4PG2_35PUg@mail.gmail.com>
	<1374973884.42471.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<1374975614.56248.YahooMailNeo@web142606.mail.bf1.yahoo.com>
Message-ID: <CAEQiC4gQbyMbNrYnTwVmdnqbnp2vJCPOfR=ta8CHV04VAyK+Zg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/2300ff10/attachment.pl>

From aljehani-k at hotmail.com  Sun Jul 28 05:18:35 2013
From: aljehani-k at hotmail.com (Ms khulood aljehani)
Date: Sun, 28 Jul 2013 06:18:35 +0300
Subject: [R] variable bandwidths  in R
Message-ID: <DUB122-W35236BEA14C429D2D4CA785540@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/9bf66d56/attachment.pl>

From pdalgd at gmail.com  Sun Jul 28 10:43:43 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Sun, 28 Jul 2013 10:43:43 +0200
Subject: [R] Boxcox transformation error
In-Reply-To: <CAG0be2nmeU9h1mmX7psL48wqHserGHwmQvvTunccWQAOAXdt+w@mail.gmail.com>
References: <CAG0be2nmeU9h1mmX7psL48wqHserGHwmQvvTunccWQAOAXdt+w@mail.gmail.com>
Message-ID: <0424CEFC-4232-4C98-A733-7C3F77124389@gmail.com>


On Jul 27, 2013, at 00:00 , Miller Ruiz wrote:

> Hello
> 
> I'm trying to run the script below for making a boxcox transformation of
> some variables contained on  an excel file, but i can't get it. I ever have
> the same message :
> error : $ operator is invalid for atomic vectors
> 
> One of the names of the variables is "Ec30" and it's the variable I put as
> example.
> 
> require(RODBC)
> require(fBasics)
> require(e1071)
> require(MASS)
> setwd("C:\\estadisticafijo")
> dir()
> temp=odbcConnectExcel("prueba35r")
> rs<-sqlFetch(temp,"Hoja1")
> close(temp)
> fix(rs)
> boxcox(rs$"Ec30")
> 
> Thaks a lot for your help.

The most obvious guess is that "rs" isn't what you think it should be, so how about showing us the result of str(rs)?

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ruipbarradas at sapo.pt  Sun Jul 28 11:33:35 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 28 Jul 2013 10:33:35 +0100
Subject: [R] variable bandwidths  in R
In-Reply-To: <DUB122-W35236BEA14C429D2D4CA785540@phx.gbl>
References: <DUB122-W35236BEA14C429D2D4CA785540@phx.gbl>
Message-ID: <51F4E56F.6070505@sapo.pt>

Hello,

Try function ?density, argument bw, in package stats.

Hope this helps,

Rui Barradas

Em 28-07-2013 04:18, Ms khulood aljehani escreveu:
>
>
>
>
>
> HelloI want to know how can
> implement variable bandwidths  for kernel
> density estimation in R.
>
> What the packages that
> I need to use? And what the command?
>
>
>
> Thank You Khulood H.
>
>
>
>             		 	   		
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From stan.aggerwal at gmail.com  Sun Jul 28 12:37:54 2013
From: stan.aggerwal at gmail.com (Stanislav Aggerwal)
Date: Sun, 28 Jul 2013 03:37:54 -0700
Subject: [R] repeated measures logistic regression
In-Reply-To: <loom.20130727T205849-73@post.gmane.org>
References: <CAOZp1o=XYWN8Gj7bVCWvqvM=2kQiJMJwuWdKcwoOjjZffygjfA@mail.gmail.com>
	<loom.20130727T205849-73@post.gmane.org>
Message-ID: <CAOZp1on8d_5uCLJY4eF0+a43yA6Qd-Bs-CLKsKF46rtUwHYHSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/f1fb8d23/attachment.pl>

From neotropical.bats at gmail.com  Sun Jul 28 15:19:19 2013
From: neotropical.bats at gmail.com (Neotropical bat risk assessments)
Date: Sun, 28 Jul 2013 09:19:19 -0400
Subject: [R] How to replace  NA values
Message-ID: <51F51A57.4090500@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/eb17af68/attachment.pl>

From gunter.berton at gene.com  Sun Jul 28 15:37:09 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 28 Jul 2013 06:37:09 -0700
Subject: [R] How to replace NA values
In-Reply-To: <51F51A57.4090500@gmail.com>
References: <51F51A57.4090500@gmail.com>
Message-ID: <CACk-te2__aSfaL8+jjtC_6jQ=huTs2xnJ4ppGZE7HxYe-X1Nyg@mail.gmail.com>

Inline.

--Bert

On Sun, Jul 28, 2013 at 6:19 AM, Neotropical bat risk assessments
<neotropical.bats at gmail.com> wrote:
> Hi all,
>
> I am using reshape2 to reformat a data frame and all is great using:
>
> Bats.melt <- melt(data = Bats)
>
> Bats.cast <- dcast(data = Bats.melt, formula = Species ~ Location)
>
> dput(Bats.cast,'C:/=Bat data working/Nica_new/Bats_niche.robj')
>
> write.csv(Bat.cast,'C:/=Bat data working/Nica_new/test_Niche.csv')
>
>
> The resulting file from both dput and write are great, however in order
> to run another R analysis I need to replace all the NA values in the
> output with a zero - 0 value.

I strongly suspect this is false. Most R functions have options to
deal with NA, alas, not consistently though.
See, e.g.  ?na.omit  . For manual processing, see ?NA (of course!).

However, replacing NA's with 0's is dangerous. It may also be
scientifically/statistically flawed; although properly dealing with
missing data can be a very difficult issue.

Cheers,
Bert

>
> I have just been opening this in Excel and using a simple find NA
> replace with 0 and saving then reopening in R.
>
> There must be a simple way to do this in R.
>
> Any suggestions welcomed.
>
>
>
> --
> Bruce W. Miller, PhD.
> Neotropical bat risk assessments
>
> If we lose the bats, we may lose much of the tropical vegetation and the lungs of the planet
>
> Using acoustic sampling to map species distributions for >15 years.
>
> Providing Interactive identification keys to the vocal signatures of New World Bats
>
> For various project details see:
>
> https://sites.google.com/site/batsoundservices/
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From rmh at temple.edu  Sun Jul 28 17:05:21 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Sun, 28 Jul 2013 11:05:21 -0400
Subject: [R] How to replace NA values
In-Reply-To: <51F51A57.4090500@gmail.com>
References: <51F51A57.4090500@gmail.com>
Message-ID: <CAGx1TMCdWm5YByXdT0ywwTMC7UnNLPxpALDxDMY6p_vU6v1NQw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/896eab62/attachment.pl>

From batsncats at gmail.com  Sun Jul 28 15:12:22 2013
From: batsncats at gmail.com (Bruce Miller)
Date: Sun, 28 Jul 2013 09:12:22 -0400
Subject: [R] How to replace  NA values
Message-ID: <51F518B6.4030403@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/9de7a94e/attachment.pl>

From neotropical.bats at gmail.com  Sun Jul 28 17:52:51 2013
From: neotropical.bats at gmail.com (Neotropical bat risk assessments)
Date: Sun, 28 Jul 2013 11:52:51 -0400
Subject: [R] Replacing  NA values solved
Message-ID: <51F53E53.6010507@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/7055cb1d/attachment.pl>

From ruipbarradas at sapo.pt  Sun Jul 28 19:38:34 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Sun, 28 Jul 2013 18:38:34 +0100
Subject: [R] variable bandwidths  in R
In-Reply-To: <DUB122-W28654F115A11F2D0E1A55C85540@phx.gbl>
References: <DUB122-W35236BEA14C429D2D4CA785540@phx.gbl>,
	<51F4E56F.6070505@sapo.pt>
	<DUB122-W28654F115A11F2D0E1A55C85540@phx.gbl>
Message-ID: <51F5571A.1050705@sapo.pt>

Hello,

You should Cc the list, the odds of getting more and better answers is 
greater.
I don't believe what you want is statistically sound, why more than one 
bandwidth? Anyway, if density() doesn't do what you need, you can try to 
look for similar functions in other packages. Try the following.

library(sos)

findFn('kernel density estimation')


There are several hits with 'kde' in the name of the function. But I 
doubt they implement multiple bandwidths per call.

Rui Barradas

Em 28-07-2013 16:11, Ms khulood aljehani escreveu:
>
> Hi
> Thank You for your help
>
> I tried this way, bw argument allowed to one value
> I want more than one value, and this values change as the observation in the original vector change
>
> Thank You
>
>> Date: Sun, 28 Jul 2013 10:33:35 +0100
>> From: ruipbarradas at sapo.pt
>> To: aljehani-k at hotmail.com
>> CC: r-help at stat.math.ethz.ch
>> Subject: Re: [R] variable bandwidths  in R
>>
>> Hello,
>>
>> Try function ?density, argument bw, in package stats.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>> Em 28-07-2013 04:18, Ms khulood aljehani escreveu:
>>>
>>>
>>>
>>>
>>>
>>> HelloI want to know how can
>>> implement variable bandwidths  for kernel
>>> density estimation in R.
>>>
>>> What the packages that
>>> I need to use? And what the command?
>>>
>>>
>>>
>>> Thank You Khulood H.
>>>
>>>
>>>
>>>              		 	   		
>>> 	[[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>   		 	   		
>


From gunter.berton at gene.com  Sun Jul 28 19:47:07 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Sun, 28 Jul 2013 10:47:07 -0700
Subject: [R] variable bandwidths in R
In-Reply-To: <51F5571A.1050705@sapo.pt>
References: <DUB122-W35236BEA14C429D2D4CA785540@phx.gbl>
	<51F4E56F.6070505@sapo.pt>
	<DUB122-W28654F115A11F2D0E1A55C85540@phx.gbl>
	<51F5571A.1050705@sapo.pt>
Message-ID: <CACk-te3oUEfuekdk8OSdVr+Gz7ajb9hsyauXDHepSQQfanshxA@mail.gmail.com>

Inline.

On Sun, Jul 28, 2013 at 10:38 AM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> You should Cc the list, the odds of getting more and better answers is
> greater.
> I don't believe what you want is statistically sound, why more than one
> bandwidth? Anyway, if density() doesn't do what you need, you can try to
> look for similar functions in other packages. Try the following.
>
> library(sos)
>
> findFn('kernel density estimation')
>
>
> There are several hits with 'kde' in the name of the function. But I doubt
> they implement multiple bandwidths per call.

I agree. Trying adding "adaptive" to your search (e.g. "adaptive
smoothing", "adaptive density estimation" or whatever.

-- Bert


>
> Rui Barradas
>
> Em 28-07-2013 16:11, Ms khulood aljehani escreveu:
>>
>>
>> Hi
>> Thank You for your help
>>
>> I tried this way, bw argument allowed to one value
>> I want more than one value, and this values change as the observation in
>> the original vector change
>>
>> Thank You
>>
>>> Date: Sun, 28 Jul 2013 10:33:35 +0100
>>> From: ruipbarradas at sapo.pt
>>> To: aljehani-k at hotmail.com
>>> CC: r-help at stat.math.ethz.ch
>>> Subject: Re: [R] variable bandwidths  in R
>>>
>>> Hello,
>>>
>>> Try function ?density, argument bw, in package stats.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>> Em 28-07-2013 04:18, Ms khulood aljehani escreveu:
>>>>
>>>>
>>>>
>>>>
>>>>
>>>>
>>>> HelloI want to know how can
>>>> implement variable bandwidths  for kernel
>>>> density estimation in R.
>>>>
>>>> What the packages that
>>>> I need to use? And what the command?
>>>>
>>>>
>>>>
>>>> Thank You Khulood H.
>>>>
>>>>
>>>>
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-help at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>>> PLEASE do read the posting guide
>>>> http://www.R-project.org/posting-guide.html
>>>> and provide commented, minimal, self-contained, reproducible code.
>>>>
>>
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From pmaclean2011 at yahoo.com  Sun Jul 28 21:20:30 2013
From: pmaclean2011 at yahoo.com (Peter Maclean)
Date: Sun, 28 Jul 2013 12:20:30 -0700 (PDT)
Subject: [R] Extracting Current and Old Date
Message-ID: <1375039230.80064.YahooMailNeo@web121705.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130728/b6589b70/attachment.pl>

From jrkrideau at inbox.com  Sun Jul 28 21:29:49 2013
From: jrkrideau at inbox.com (John Kane)
Date: Sun, 28 Jul 2013 11:29:49 -0800
Subject: [R] Extracting Current and Old Date
In-Reply-To: <1375039230.80064.YahooMailNeo@web121705.mail.ne1.yahoo.com>
Message-ID: <99CE7C80BE5.0000043Ajrkrideau@inbox.com>

If I read this correctly:

mydates <- as.Date(c("2007-06-22", "2007-05-21", "2004-04-13",
"2004-03-11","2004-02-13"))
xx  <-  min(mydates)
yy  <-  max(mydates)
yy-xx

John Kane
Kingston ON Canada


> -----Original Message-----
> From: pmaclean2011 at yahoo.com
> Sent: Sun, 28 Jul 2013 12:20:30 -0700 (PDT)
> To: r-help at r-project.org
> Subject: Re: [R] Extracting Current and Old Date
> 
> #This my look trivial but has been killing my time
> #I want to extract most current and old date from mydates #variable that
> has more than 10,000 observation.
> #Get days
> # use as.Date( ) to convert strings to dates
> mydates <- as.Date(c("2007-06-22", "2007-05-21", "2004-04-13",
> "2004-03-11","2004-02-13",))
> #Is there a way/fuction to extract mostcurrent date
> #from mydates variable
> mostcurrent <- as.Date(c("2007-06-22"))
> 
> #Is there a way/function to extract olddate
> #from mydates variable
> olddate    <- as.Date(c("2004-02-13"))
> 
> #Days between most current and old dayte
> days <- as.numeric(mostcurrent - olddate)
> 
> 
> Peter Maclean
> Department of Economics
> UDSM
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE 5GB EMAIL - Check out spam free email with many cool features!
Visit http://www.inbox.com/email to find out more!


From dwinsemius at comcast.net  Sun Jul 28 21:30:17 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Sun, 28 Jul 2013 12:30:17 -0700
Subject: [R] Extracting Current and Old Date
In-Reply-To: <1375039230.80064.YahooMailNeo@web121705.mail.ne1.yahoo.com>
References: <1375039230.80064.YahooMailNeo@web121705.mail.ne1.yahoo.com>
Message-ID: <0FA26DB7-24A7-4E99-AC24-5CCC283AD2D5@comcast.net>


On Jul 28, 2013, at 12:20 PM, Peter Maclean wrote:

> #This my look trivial but has been killing my time
> #I want to extract most current and old date from mydates #variable that has more than 10,000 observation. 
> #Get days
> # use as.Date( ) to convert strings to dates 
> mydates <- as.Date(c("2007-06-22", "2007-05-21", "2004-04-13", "2004-03-11","2004-02-13",))
> #Is there a way/fuction to extract mostcurrent date
> #from mydates variable
> mostcurrent <- as.Date(c("2007-06-22"))
> 
> #Is there a way/function to extract olddate 
> #from mydates variable
> olddate    <- as.Date(c("2004-02-13"))
> 
> #Days between most current and old dayte
> days <- as.numeric(mostcurrent - olddate)  

The usual ways to work with numeric data have been given .Date methods:

> mydates <- as.Date(c("2007-06-22", "2007-05-21", "2004-04-13", "2004-03-11","2004-02-13"))
> min(mydates)
[1] "2004-02-13"
> max(mydates)
[1] "2007-06-22"
> range(mydates)
[1] "2004-02-13" "2007-06-22"
> diff(range(mydates))
Time difference of 1225 days

-- 

David Winsemius
Alameda, CA, USA


From smartpink111 at yahoo.com  Sun Jul 28 21:32:38 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 28 Jul 2013 12:32:38 -0700 (PDT)
Subject: [R] Extracting Current and Old Date
In-Reply-To: <1375039230.80064.YahooMailNeo@web121705.mail.ne1.yahoo.com>
References: <1375039230.80064.YahooMailNeo@web121705.mail.ne1.yahoo.com>
Message-ID: <1375039958.93119.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,

?max
?min

max(mydates)
#[1] "2007-06-22"
min(mydates)
#[1] "2004-02-13"
?max(mydates)-min(mydates)
Time difference of 1225 days
?max(as.numeric(mydates))-min(as.numeric(mydates))
#[1] 1225
A.K.


----- Original Message -----
From: Peter Maclean <pmaclean2011 at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, July 28, 2013 3:20 PM
Subject: Re: [R] Extracting Current and Old Date

#This my look trivial but has been killing my time
#I want to extract most current and old date from mydates #variable that has more than 10,000 observation.?
#Get days
# use as.Date( ) to convert strings to dates 
mydates <- as.Date(c("2007-06-22", "2007-05-21", "2004-04-13", "2004-03-11","2004-02-13",))
#Is there a way/fuction to extract mostcurrent date
#from mydates variable
mostcurrent <- as.Date(c("2007-06-22"))

#Is there a way/function to extract olddate 
#from mydates variable
olddate??? <- as.Date(c("2004-02-13"))

#Days between most current and old dayte
days <- as.numeric(mostcurrent - olddate) ?


Peter Maclean
Department of Economics
UDSM
??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dwarnold45 at suddenlink.net  Sun Jul 28 23:41:30 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Sun, 28 Jul 2013 14:41:30 -0700 (PDT)
Subject: [R] ggplot position_dodge requires constant width
Message-ID: <1375047689854-4672559.post@n4.nabble.com>

Hi,

library(ggplot2,plyr)
qplot(carat,depth,data=diamonds,
      geom="boxplot",
      group=round_any(carat,0.1,floor),
      xlim=c(0,3))

Typing:

warnings()

Gives me:

Warning messages:
1: position_dodge requires constant width: output may be incorrect

How should the above code be adjusted to avoid this warning? Curious, as
this code is copied directly from ggplot2 Elegant Graphics for Data
Analysis.

D.



--
View this message in context: http://r.789695.n4.nabble.com/ggplot-position-dodge-requires-constant-width-tp4672559.html
Sent from the R help mailing list archive at Nabble.com.


From smartpink111 at yahoo.com  Mon Jul 29 00:04:08 2013
From: smartpink111 at yahoo.com (arun)
Date: Sun, 28 Jul 2013 15:04:08 -0700 (PDT)
Subject: [R] ggplot position_dodge requires constant width
In-Reply-To: <1375047689854-4672559.post@n4.nabble.com>
References: <1375047689854-4672559.post@n4.nabble.com>
Message-ID: <1375049048.45051.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
This link may help:
http://stackoverflow.com/questions/14476961/why-do-i-get-position-dodge-requires-constant-width-even-though-widths-are-con
A.K.




----- Original Message -----
From: David Arnold <dwarnold45 at suddenlink.net>
To: r-help at r-project.org
Cc: 
Sent: Sunday, July 28, 2013 5:41 PM
Subject: [R] ggplot position_dodge requires constant width

Hi,

library(ggplot2,plyr)
qplot(carat,depth,data=diamonds,
? ? ? geom="boxplot",
? ? ? group=round_any(carat,0.1,floor),
? ? ? xlim=c(0,3))

Typing:

warnings()

Gives me:

Warning messages:
1: position_dodge requires constant width: output may be incorrect

How should the above code be adjusted to avoid this warning? Curious, as
this code is copied directly from ggplot2 Elegant Graphics for Data
Analysis.

D.



--
View this message in context: http://r.789695.n4.nabble.com/ggplot-position-dodge-requires-constant-width-tp4672559.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From wangyong1 at gmail.com  Mon Jul 29 05:32:45 2013
From: wangyong1 at gmail.com (Yong Wang)
Date: Mon, 29 Jul 2013 11:32:45 +0800
Subject: [R] Chinese characters in html source captured by download.file()
 are garbled code , how to convert it readable
Message-ID: <CAHB3Jmk=+_0R+eTaV+axdQaJApBcSbia1GtMxZJVM3kiXrPDYA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/a2692245/attachment.pl>

From haleybeck at att.net  Mon Jul 29 03:00:24 2013
From: haleybeck at att.net (ba0728)
Date: Sun, 28 Jul 2013 18:00:24 -0700 (PDT)
Subject: [R] MCMClogit: Cannot calculate marginal likelihood with improper
	prior
Message-ID: <1375059624872-4672561.post@n4.nabble.com>

I'm an undergrad who is new to MCMCpack and I haven't been able to find an
answer to my problem online yet: I'm attempting to run MCMClogit with a
Cauchy proper prior but I'm getting the warning "Cannot calculate marginal
likelihood with improper prior" (my purposes require the marginal likelihood
calculation so I understand that I need to use a proper prior).

I'm trying to simulate the "user-defined independent Cauchy prior with
additional args" as specified in the MCMCpack User Manual (p. 76, April 2013
version). My input data has been standardized  (mean = 0, sd = 0.5 for
non-binary variables, and binary variables with mean of 0 and difference of
1 between upper and lower ends) according to the Gelman 2008 paper on
logistic regression
(www.stat.columbia.edu/~gelman/research/published/priors11.pdf?). 

When I run the example data set (birthwt) from the User Manual, the
logpriorfun works correctly allowing the marginal likelihood to be
generated. However, when I try running my data with the logprior fun, I get
a warning that the prior is improper. Here is the code I am running:

*logpriorfun = function(beta, location,scale){
  sum(dcauchy(beta, location, scale, log = TRUE))
}*

*> MCMC.2= MCMClogit(DEAD ~ YEARS + MALE + x1 + x2 + x3+ x4 +x5 + x6 + x7 +
x8 + x9, tune= 0.65,burnin =500, mcmc=5000, data = dat, marginal.likelihood
= "Laplace", user.prior.density=logpriorfun, logfun=TRUE, location = 0,
scale=2.5)
*

*@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
The Metropolis acceptance rate was 0.27418
@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
Warning message:
In MCMClogit(DEAD ~ YEARS + MALE + x1 + x2 + x3 +  :
  Cannot calculate marginal likelihood with improper prior*

Any advice on how to fix my arguments so it is a proper prior and will allow
me to generate a marginal likelihood using the Laplace approximation? Or how
should I be coding a Cauchy proper prior? I'm having problems defining the
priors.

Thanks, B.





--
View this message in context: http://r.789695.n4.nabble.com/MCMClogit-Cannot-calculate-marginal-likelihood-with-improper-prior-tp4672561.html
Sent from the R help mailing list archive at Nabble.com.


From dstr7320 at uni.sydney.edu.au  Mon Jul 29 04:00:15 2013
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Mon, 29 Jul 2013 02:00:15 +0000
Subject: [R] Declare BASH Array Using R System Function
Message-ID: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>

Hello,

It is difficult searching for previous posts about this since the keywords are short and ambiguous, so I hope this is not a duplicate question.

I can easily declare an array on the command line.

$ names=(X Y)
$ echo ${names[0]}
X

I am unable to do the same from within R.

> system("names=(X Y)")
sh: Syntax error: "(" unexpected

Reading the documentation for the system function, it appears to only be relevant for executing commands. What can I do instead to declare a BASH array ? Thanks.

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia


From q.schuyler at uq.edu.au  Mon Jul 29 06:09:44 2013
From: q.schuyler at uq.edu.au (Qamar Schuyler)
Date: Mon, 29 Jul 2013 04:09:44 +0000
Subject: [R] Help with prefmod
Message-ID: <E2C6DB41-9DE0-4B53-BDD3-EFC5F49D9995@uq.edu.au>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/bf21f570/attachment.pl>

From j.bayat194 at gmail.com  Mon Jul 29 07:31:04 2013
From: j.bayat194 at gmail.com (javad bayat)
Date: Mon, 29 Jul 2013 10:01:04 +0430
Subject: [R] surface plot
Message-ID: <CANTxAmLvLuNP9YT88EKVaDvFCq3+O=1THrZc2RMCzJ1dNLYsmw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/7517db3d/attachment.pl>

From j.bayat194 at gmail.com  Mon Jul 29 07:35:50 2013
From: j.bayat194 at gmail.com (javad bayat)
Date: Mon, 29 Jul 2013 10:05:50 +0430
Subject: [R] R function
Message-ID: <CANTxAmKYf4_0eDY1h8=wv6393+Qe3zS_4dFmDqS40Vngh2wVDA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/3fd4fab9/attachment.pl>

From jdnewmil at dcn.davis.CA.us  Mon Jul 29 08:27:09 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Sun, 28 Jul 2013 23:27:09 -0700
Subject: [R] Declare BASH Array Using R System Function
In-Reply-To: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>
References: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>
Message-ID: <88cf2a86-0762-43f8-be7d-868656bd2c39@email.android.com>

You seem confused. You are programming in R, and asking questions about bash on an R mailing list. You seem to need to learn the difference between environment variables and bash variables and how processes acquire and transfer environment variables, which is really an operating system concept and off topic here. Once you do understand this difference, you might be interested in reading the R help file on Sys.setenv().
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

Dario Strbenac <dstr7320 at uni.sydney.edu.au> wrote:
>Hello,
>
>It is difficult searching for previous posts about this since the
>keywords are short and ambiguous, so I hope this is not a duplicate
>question.
>
>I can easily declare an array on the command line.
>
>$ names=(X Y)
>$ echo ${names[0]}
>X
>
>I am unable to do the same from within R.
>
>> system("names=(X Y)")
>sh: Syntax error: "(" unexpected
>
>Reading the documentation for the system function, it appears to only
>be relevant for executing commands. What can I do instead to declare a
>BASH array ? Thanks.
>
>--------------------------------------
>Dario Strbenac
>PhD Student
>University of Sydney
>Camperdown NSW 2050
>Australia
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From pdalgd at gmail.com  Mon Jul 29 09:49:28 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 29 Jul 2013 09:49:28 +0200
Subject: [R] Declare BASH Array Using R System Function
In-Reply-To: <88cf2a86-0762-43f8-be7d-868656bd2c39@email.android.com>
References: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>
	<88cf2a86-0762-43f8-be7d-868656bd2c39@email.android.com>
Message-ID: <90B83137-F009-4A19-8ABC-9C0AD838AFA4@gmail.com>


On Jul 29, 2013, at 08:27 , Jeff Newmiller wrote:

> You seem confused.

Not particularly, but he needs to be aware of _which_ shell R is executing in system() calls. These things work for me:

> system("foo=(bar baz); echo ${foo[1]}")
baz

Dario's issue is suggested by his error message

>>> system("names=(X Y)")
>> sh: Syntax error: "(" unexpected

The shell is (Bourne) "sh", not "bash", so bash extension won't work. 

This is highly system dependent: On OSX Snow Leopard, e.g., /bin/sh really is GNU bash, which is why it works for me. Others have the more sane setup where /bin/sh really is Bourne sh.

Next question is of course how to ensure that bash gets used. I must admit that I have long forgotten...

-Peter D.


> You are programming in R, and asking questions about bash on an R mailing list. You seem to need to learn the difference between environment variables and bash variables and how processes acquire and transfer environment variables, which is really an operating system concept and off topic here. Once you do understand this difference, you might be interested in reading the R help file on Sys.setenv().
> ---------------------------------------------------------------------------
> Jeff Newmiller                        The     .....       .....  Go Live...
> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>                                      Live:   OO#.. Dead: OO#..  Playing
> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
> --------------------------------------------------------------------------- 
> Sent from my phone. Please excuse my brevity.
> 
> Dario Strbenac <dstr7320 at uni.sydney.edu.au> wrote:
>> Hello,
>> 
>> It is difficult searching for previous posts about this since the
>> keywords are short and ambiguous, so I hope this is not a duplicate
>> question.
>> 
>> I can easily declare an array on the command line.
>> 
>> $ names=(X Y)
>> $ echo ${names[0]}
>> X
>> 
>> I am unable to do the same from within R.
>> 
>>> system("names=(X Y)")
>> sh: Syntax error: "(" unexpected
>> 
>> Reading the documentation for the system function, it appears to only
>> be relevant for executing commands. What can I do instead to declare a
>> BASH array ? Thanks.
>> 
>> --------------------------------------
>> Dario Strbenac
>> PhD Student
>> University of Sydney
>> Camperdown NSW 2050
>> Australia
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ruipbarradas at sapo.pt  Mon Jul 29 10:32:48 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 29 Jul 2013 09:32:48 +0100
Subject: [R] R function
In-Reply-To: <CANTxAmKYf4_0eDY1h8=wv6393+Qe3zS_4dFmDqS40Vngh2wVDA@mail.gmail.com>
References: <CANTxAmKYf4_0eDY1h8=wv6393+Qe3zS_4dFmDqS40Vngh2wVDA@mail.gmail.com>
Message-ID: <51F628B0.4050702@sapo.pt>

Hello,

Try the following.

T <- function(x){
	ifelse(pah1$P > = 1, "Combustion", "Petroleum")
}

T(pah1$P[1:83])


Hope this helps,

Rui Barradas

Em 29-07-2013 06:35, javad bayat escreveu:
> Dear R users;
> I am MSc student and I want to write my own function, but it cant be
> completed. please help me for solve it. here is my code:
>
> pah1$P = (pah1$Fluoranthene/pah1$Pyrene)
> T = function(x){
> for (i in 1:length(pah1$P))
> if (i >= 1)
> print("Combustion")
> if (i < 1)
> print("Petroleum")
> }
> T(pah1$P[c(1:83),])
>
> I wish that R gives me a column that if value greater or equal to one give
> "Combustion"  and if value is less than one give "Petroleum".
> but my function dose not work.
> thank you so much for your help.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Mon Jul 29 10:45:53 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 29 Jul 2013 09:45:53 +0100
Subject: [R] R function
In-Reply-To: <51F628B0.4050702@sapo.pt>
References: <CANTxAmKYf4_0eDY1h8=wv6393+Qe3zS_4dFmDqS40Vngh2wVDA@mail.gmail.com>
	<51F628B0.4050702@sapo.pt>
Message-ID: <51F62BC1.2060203@sapo.pt>

Hello,

Sorry, that should be


T <- function(x){
	ifelse(x > = 1, "Combustion", "Petroleum")
}



Rui Barradas

Em 29-07-2013 09:32, Rui Barradas escreveu:
> Hello,
>
> Try the following.
>
> T <- function(x){
>      ifelse(pah1$P > = 1, "Combustion", "Petroleum")
> }
>
> T(pah1$P[1:83])
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 29-07-2013 06:35, javad bayat escreveu:
>> Dear R users;
>> I am MSc student and I want to write my own function, but it cant be
>> completed. please help me for solve it. here is my code:
>>
>> pah1$P = (pah1$Fluoranthene/pah1$Pyrene)
>> T = function(x){
>> for (i in 1:length(pah1$P))
>> if (i >= 1)
>> print("Combustion")
>> if (i < 1)
>> print("Petroleum")
>> }
>> T(pah1$P[c(1:83),])
>>
>> I wish that R gives me a column that if value greater or equal to one
>> give
>> "Combustion"  and if value is less than one give "Petroleum".
>> but my function dose not work.
>> thank you so much for your help.
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jim at bitwrit.com.au  Mon Jul 29 11:14:04 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Mon, 29 Jul 2013 19:14:04 +1000
Subject: [R] surface plot
In-Reply-To: <CANTxAmLvLuNP9YT88EKVaDvFCq3+O=1THrZc2RMCzJ1dNLYsmw@mail.gmail.com>
References: <CANTxAmLvLuNP9YT88EKVaDvFCq3+O=1THrZc2RMCzJ1dNLYsmw@mail.gmail.com>
Message-ID: <51F6325C.6000603@bitwrit.com.au>

On 07/29/2013 03:31 PM, javad bayat wrote:
> Dear R users;
> I have a question about surface plot that show me spatial variability of
> parameter. I have a data frame with 6 variables and X and Y for coordinate
> system.
>
> X       Y      pH
> ..        ...      ...
>
> so I want to create a surface plot for my data.
> please help me.

Hi javad,
There are a number of packages that will produce plots that might be 
useful to you. I suggest that you search for:

surface plot r

with Google and see which plot suits you.

Jim


From Jose.Iparraguirre at ageuk.org.uk  Mon Jul 29 11:20:23 2013
From: Jose.Iparraguirre at ageuk.org.uk (Jose Iparraguirre)
Date: Mon, 29 Jul 2013 09:20:23 +0000
Subject: [R] Help R
In-Reply-To: <BAY172-W3995C76A1F4BFD264B5559B96A0@phx.gbl>
References: <BAY172-W3995C76A1F4BFD264B5559B96A0@phx.gbl>
Message-ID: <5F8EC5C77B9AE547A8959F690F04C7B2036617@AGEPXMB006.uk.age.local>

Hola Maria Teresa,

For multiple imputation, I would suggest the Amelia package by Gary King, James Honaker, and Matthew Blackwell, which uses the expectation-maximisation (EM) algorithm with bootstrap. Its excellent vignette has examples which should be more than enough for your needs. Do read very carefully the imputation-improving transformation section to deal with ordinal, nominal, etc., variables.

With regards to which variables to select, this goes beyond this R-help group, but the package vignette provides you with this short answer:

"It is crucial to include at least as much information as will be used in the analysis model. That is, any variable that will be in the analysis model should also be in the imputation model. This includes any transformations or interactions of variables that will appear in the analysis model.
In fact, it is often useful to add more information to the imputation model than will be present when the analysis is run. Since imputation is predictive, any variables that would increase predictive power should be included in the model, even if including them in the analysis model would produce bias in estimating a causal effect (such as for post-treatment variables) or collinearity would preclude determining which variable had a relationship with the dependent variable (such as including multiple alternate measures of GDP)." 

Hope this helps!

Jos?

Prof. Jos? Iparraguirre
Chief Economist
Age UK



-----Original Message-----
From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf Of M? Teresa Martinez Soriano
Sent: 26 July 2013 09:36
To: r-help at r-project.org
Subject: [R] Help R

Hi to everyone, first of all thanks for this service, it is being very useful for me, thanks in 

advance.

I am new in R, so I suppose I could make really naive questions, I'm sorry.

I have to impute some missing values and I am trying to do it with VIM library trough Hot Deck 

imputation.

I writte:vmGUImenu(), and it opens a small window of: Visualization and Imputation of Missing Values 

and I select Imptation and Hot Deck and then one of the variables which I have to select is Select 

Variables to Build Domains.

I don't know which variables I have to select, I don't understand this. I have tried don't put 

anything and I get :

hotdeck(dataframe,variable=c("CRV.IE.2005","CRV.IE.2006","CRV.IE.2007","CRV.IE.2008","CRV.IE.2009","CR

V.IE.2010"),ord_var=c("CRV.IE.2001","CRV.IE.2002","CRV.IE.2003","CRV.IE.2004","CRV.IE.2005","CRV.IE.20

06","CRV.IE.2007","CRV.IE.2008","CRV.IE.2009","CRV.IE.2010"),domain_var=NULL,imp_suffix="_imp")

Mensajes de aviso perdido:

 In hotdeck(data, variable = vars, ord_var = sort, domain_var = domain,  

 Some NAs remained, maybe due to a too restrictive domain building!?

 In hotdeck(b, variable = c("CRV.IE.2005", "CRV.IE.2006", "CRV.IE.2007", Some NAs remained, maybe due 

to a too restrictive domain building!?


What should I  put in this variable??

Thanks in advance

Best regards

Teresa 		 	   		  
	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

The Wireless from Age UK | Radio for grown-ups.

www.ageuk.org.uk/thewireless


If you?re looking for a radio station that offers real variety, tune in to The Wireless from Age UK. 
Whether you choose to listen through the website at www.ageuk.org.uk/thewireless, on digital radio (currently available in London and Yorkshire) or through our TuneIn Radio app, you can look forward to an inspiring mix of music, conversation and useful information 24 hours a day.



 
-------------------------------
Age UK is a registered charity and company limited by guarantee, (registered charity number 1128267, registered company number 6825798). 
Registered office: Tavis House, 1-6 Tavistock Square, London WC1H 9NA.

For the purposes of promoting Age UK Insurance, Age UK is an Appointed Representative of Age UK Enterprises Limited, Age UK is an Introducer 
Appointed Representative of JLT Benefit Solutions Limited and Simplyhealth Access for the purposes of introducing potential annuity and health 
cash plans customers respectively.  Age UK Enterprises Limited, JLT Benefit Solutions Limited and Simplyhealth Access are all authorised and 
regulated by the Financial Services Authority. 
------------------------------

This email and any files transmitted with it are confidential and intended solely for the use of the individual or entity to whom they are 
addressed. If you receive a message in error, please advise the sender and delete immediately.

Except where this email is sent in the usual course of our business, any opinions expressed in this email are those of the author and do not 
necessarily reflect the opinions of Age UK or its subsidiaries and associated companies. Age UK monitors all e-mail transmissions passing 
through its network and may block or modify mails which are deemed to be unsuitable.

Age Concern England (charity number 261794) and Help the Aged (charity number 272786) and their trading and other associated companies merged 
on 1st April 2009.  Together they have formed the Age UK Group, dedicated to improving the lives of people in later life.  The three national 
Age Concerns in Scotland, Northern Ireland and Wales have also merged with Help the Aged in these nations to form three registered charities: 
Age Scotland, Age NI, Age Cymru.





From ripley at stats.ox.ac.uk  Mon Jul 29 12:45:56 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 29 Jul 2013 11:45:56 +0100
Subject: [R] Declare BASH Array Using R System Function
In-Reply-To: <90B83137-F009-4A19-8ABC-9C0AD838AFA4@gmail.com>
References: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>
	<88cf2a86-0762-43f8-be7d-868656bd2c39@email.android.com>
	<90B83137-F009-4A19-8ABC-9C0AD838AFA4@gmail.com>
Message-ID: <51F647E4.9090201@stats.ox.ac.uk>

On 29/07/2013 08:49, peter dalgaard wrote:
>
> On Jul 29, 2013, at 08:27 , Jeff Newmiller wrote:
>
>> You seem confused.
>
> Not particularly, but he needs to be aware of _which_ shell R is executing in system() calls. These things work for me:
>
>> system("foo=(bar baz); echo ${foo[1]}")
> baz
>
> Dario's issue is suggested by his error message
>
>>>> system("names=(X Y)")
>>> sh: Syntax error: "(" unexpected
>
> The shell is (Bourne) "sh", not "bash", so bash extension won't work.

See below: the shell should always be 'sh'.

> This is highly system dependent: On OSX Snow Leopard, e.g., /bin/sh really is GNU bash, which is why it works for me. Others have the more sane setup where /bin/sh really is Bourne sh.

On recent OS X /bin/sh is *a variant of* bash.  E.g. shopt xpg_echo is 
different if it gets invoked as sh or bash.  Where sh is a link to bash 
the behaviour is usually different depending on how it is invoked.

There are quite a lot of systems for which /bin/sh is not based on 
either bash or Bourne sh.  As I understand it, Debian/Ubuntu nowadays 
use dash by default, and some other Linuxen use ash.  zsh is also seen 
as a system shell.  And in many cases this is configurable

Note too that there is quite a lot of flexibility in how bash is configured.

> Next question is of course how to ensure that bash gets used. I must admit that I have long forgotten...

 From ?system

      ?command? is parsed as a command plus arguments separated by
      spaces.  So if the path to the command (or an argument) contains
      spaces, it must be quoted e.g. by ?shQuote?.  Unix-alikes pass the
      command line to a shell (normally ?/bin/sh?, and POSIX requires
      that shell), so ?command? can be anything the shell regards as
      executable, including shell scripts, and it can contain multiple
      commands separated by ?;?.

So you do not have a choice of shell, and the command-line you pass 
needs to invoke a different shell if that is what you want.


But apart from knowing that R's system calls the system(1) OS call (on a 
Unix-alike) there is nothing relevant to R-help here.

> -Peter D.
>
>
>> You are programming in R, and asking questions about bash on an R mailing list. You seem to need to learn the difference between environment variables and bash variables and how processes acquire and transfer environment variables, which is really an operating system concept and off topic here. Once you do understand this difference, you might be interested in reading the R help file on Sys.setenv().
>> ---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
>>                                       Live:   OO#.. Dead: OO#..  Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
>> ---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> Dario Strbenac <dstr7320 at uni.sydney.edu.au> wrote:
>>> Hello,
>>>
>>> It is difficult searching for previous posts about this since the
>>> keywords are short and ambiguous, so I hope this is not a duplicate
>>> question.
>>>
>>> I can easily declare an array on the command line.
>>>
>>> $ names=(X Y)
>>> $ echo ${names[0]}
>>> X
>>>
>>> I am unable to do the same from within R.
>>>
>>>> system("names=(X Y)")
>>> sh: Syntax error: "(" unexpected
>>>
>>> Reading the documentation for the system function, it appears to only
>>> be relevant for executing commands. What can I do instead to declare a
>>> BASH array ? Thanks.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From szehnder at uni-bonn.de  Mon Jul 29 13:58:03 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Mon, 29 Jul 2013 13:58:03 +0200
Subject: [R] MCMClogit: Cannot calculate marginal likelihood with
	improper prior
In-Reply-To: <1375059624872-4672561.post@n4.nabble.com>
References: <1375059624872-4672561.post@n4.nabble.com>
Message-ID: <D8741AE7-D53E-4CD4-B196-636721558B7B@uni-bonn.de>

Hi, 

what I see so far is that you have specified your user.prior.density correctly. The error comes from the prior precision matrix "B0" in combination with the marginal.likelihood set to "Laplace". B0, if not explicitly specified, defaults to zero, which results in eigenvalues of zero. If "Laplace" is indicated for the marginal.likelihood, the algorithm usually calls an optimization over "logpost.logit" in "BayesianFactors.R" where the matrix B0 is tried to be solved by solve(B0) ... as it is a zero matrix its linear equation system is exactly singular and cannot be solved. The Function MCMClogit knows about this fact and gives out a warning "Cannot calculate marginal likelihood with improper prior" while changing marginal.likelihood to "none".

So concluding: Choose your user.prior.density with marginal.likelihood = "none" and all is fine (implicitly it is done so nevertheless).

Best

Simon

P.S. Using a name on a community help list will certainly improve the number of answers to your questions. 

 
On Jul 29, 2013, at 3:00 AM, ba0728 <haleybeck at att.net> wrote:

> I'm an undergrad who is new to MCMCpack and I haven't been able to find an
> answer to my problem online yet: I'm attempting to run MCMClogit with a
> Cauchy proper prior but I'm getting the warning "Cannot calculate marginal
> likelihood with improper prior" (my purposes require the marginal likelihood
> calculation so I understand that I need to use a proper prior).
> 
> I'm trying to simulate the "user-defined independent Cauchy prior with
> additional args" as specified in the MCMCpack User Manual (p. 76, April 2013
> version). My input data has been standardized  (mean = 0, sd = 0.5 for
> non-binary variables, and binary variables with mean of 0 and difference of
> 1 between upper and lower ends) according to the Gelman 2008 paper on
> logistic regression
> (www.stat.columbia.edu/~gelman/research/published/priors11.pdf?). 
> 
> When I run the example data set (birthwt) from the User Manual, the
> logpriorfun works correctly allowing the marginal likelihood to be
> generated. However, when I try running my data with the logprior fun, I get
> a warning that the prior is improper. Here is the code I am running:
> 
> *logpriorfun = function(beta, location,scale){
>  sum(dcauchy(beta, location, scale, log = TRUE))
> }*
> 
> *> MCMC.2= MCMClogit(DEAD ~ YEARS + MALE + x1 + x2 + x3+ x4 +x5 + x6 + x7 +
> x8 + x9, tune= 0.65,burnin =500, mcmc=5000, data = dat, marginal.likelihood
> = "Laplace", user.prior.density=logpriorfun, logfun=TRUE, location = 0,
> scale=2.5)
> *
> 
> *@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
> The Metropolis acceptance rate was 0.27418
> @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@
> Warning message:
> In MCMClogit(DEAD ~ YEARS + MALE + x1 + x2 + x3 +  :
>  Cannot calculate marginal likelihood with improper prior*
> 
> Any advice on how to fix my arguments so it is a proper prior and will allow
> me to generate a marginal likelihood using the Laplace approximation? Or how
> should I be coding a Cauchy proper prior? I'm having problems defining the
> priors.
> 
> Thanks, B.
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/MCMClogit-Cannot-calculate-marginal-likelihood-with-improper-prior-tp4672561.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Mon Jul 29 15:11:23 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 29 Jul 2013 06:11:23 -0700 (PDT)
Subject: [R] Declare BASH Array Using R System Function
In-Reply-To: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>
References: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>
Message-ID: <1375103483.77711.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
?system("names=(X Y); echo ${names[0]}")
#sh: 1: Syntax error: "(" unexpected


#this worked for me:
?system("bash -c 'names=(X Y); echo ${names[0]}'")
#X

A.K.



----- Original Message -----
From: Dario Strbenac <dstr7320 at uni.sydney.edu.au>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Sunday, July 28, 2013 10:00 PM
Subject: [R] Declare BASH Array Using R System Function

Hello,

It is difficult searching for previous posts about this since the keywords are short and ambiguous, so I hope this is not a duplicate question.

I can easily declare an array on the command line.

$ names=(X Y)
$ echo ${names[0]}
X

I am unable to do the same from within R.

> system("names=(X Y)")
sh: Syntax error: "(" unexpected

Reading the documentation for the system function, it appears to only be relevant for executing commands. What can I do instead to declare a BASH array ? Thanks.

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dennis1991 at gmx.net  Mon Jul 29 15:20:25 2013
From: dennis1991 at gmx.net (dennis1991 at gmx.net)
Date: Mon, 29 Jul 2013 15:20:25 +0200 (CEST)
Subject: [R] How to split two levels several times?
In-Reply-To: <1374846190.47754.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <trinity-8f6ec312-bb99-47e0-a9ba-c69aec73cdcc-1374502154539@3capp-gmx-bs45>
	<51ED540C.1000303@sapo.pt>, <51ED5573.9040303@sapo.pt>
	<trinity-7d3f5814-7670-4dc8-9ff6-5f64c8305e6c-1374576070210@3capp-gmx-bs42>,
	<51EE6AC7.1060003@sapo.pt>
	<trinity-f42b80d2-1d5b-422b-9871-60c086b25b98-1374670720295@3capp-gmx-bs29>,
	<51F04B5B.2010702@sapo.pt>
	<trinity-f11b1831-3c9c-40eb-91a2-5a15a7a43b53-1374748844228@3capp-gmx-bs34>,
	<51F1742C.7070405@sapo.pt>
	<trinity-0aef6fe9-ceb7-4b5c-bbc6-2949bc354692-1374833259262@3capp-gmx-bs52>
	<1374845192.55351.YahooMailNeo@web142606.mail.bf1.yahoo.com>,
	<1374846190.47754.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <trinity-01bcabcb-b686-41e0-8a62-2bad22f136de-1375104025714@3capp-gmx-bs62>

Hi Arun, thanks. Great help. I tested the code for several tables and your function works well.
Dennis


> Gesendet: Freitag, 26. Juli 2013 um 15:43 Uhr
> Von: arun <smartpink111 at yahoo.com>
> An: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
> Cc: "R help" <r-help at r-project.org>, "Rui Barradas" <ruipbarradas at sapo.pt>
> Betreff: Re: [R] How to split two levels several times?
>
> It would be better to wrap it in a function.
>
> fun1<- function(x,colName,N,value){
> rl<- rle(as.character(x[,colName]))
> dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]==value & (rl$lengths[i]%/%N>1)) rep(N,rl$lengths[i]%/%N) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
> lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
> vec1<-sapply(lst1,max)
> vec2<-c(1,vec1[-length(vec1)]+1)
> res<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; x[seq(vec2[i],max(x1)),]})
> res
> }
>
> fun1(XXX,"electrode",6,"electrode4")
> #Using previous dataset XXX, XXX1, XXX2
> fun1(XXX,"electrode",3,"electrode1")
>
> fun1(XXX1,"electrode",3,"electrode1")
>
> fun1(XXX2,"electrode",3,"electrode1")
> A.K.
>
> ----- Original Message -----
> From: arun <smartpink111 at yahoo.com>
> To: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
> Cc: R help <r-help at r-project.org>; Rui Barradas <ruipbarradas at sapo.pt>
> Sent: Friday, July 26, 2013 9:26 AM
> Subject: Re: [R] How to split two levels several times?
>
>
>
> Hi Dennis,
> I guess in this case, instead of "Eletrode1" occuring 3 times, it is "Electrode4" exists only 6 times.? If that is the situation:
> just change:
> XXX: data
> rl<-rle(as.character(XXX$electrode))
> ?dat<-do.call(rbind,lapply(seq_along(rl$lengths),function(i){x1<-if(rl$values[i]=="electrode4" & (rl$lengths[i]%/%6>1)) rep(6,rl$lengths[i]%/%6) else rl$lengths[i];data.frame(Len=x1,Val=rl$values[i])}))
> ?lst1<-split(cumsum(dat[,1]),((seq_along(dat[,1])-1)%/%2)+1)
> vec1<-sapply(lst1,max)
> vec2<-c(1,vec1[-length(vec1)]+1)
> res<-? lapply(seq_along(lst1),function(i) {x1<-lst1[[i]]; XXX[seq(vec2[i],max(x1)),]})
> res
> [[1]]
> ?? electrode length
> 1 electrode1??? 206
> 2 electrode1??? 194
> 3 electrode1??? 182
> 4 electrode1??? 172
> 5 electrode1??? 169
> 6 electrode2???? 82
> 7 electrode2???? 78
> 8 electrode2???? 70
> 9 electrode2???? 58
>
> [[2]]
> ??? electrode length
> 10 electrode1??? 206
> 11 electrode1??? 194
> 12 electrode1??? 182
> 13 electrode1??? 172
> 14 electrode1??? 169
> 15 electrode3??? 260
> 16 electrode3??? 176
> 17 electrode3??? 137
>
> [[3]]
> ??? electrode length
> 18 electrode1??? 206
> 19 electrode1??? 194
> 20 electrode1??? 182
> 21 electrode1??? 172
> 22 electrode1??? 169
> 23 electrode4???? 86
> 24 electrode4???? 66
> 25 electrode4???? 64
> 26 electrode4???? 52
> 27 electrode4???? 27
> 28 electrode4???? 26
>
> [[4]]
> ??? electrode length
> 29 electrode2???? 82
> 30 electrode2???? 78
> 31 electrode2???? 70
> 32 electrode2???? 58
> 33 electrode1??? 206
> 34 electrode1??? 194
> 35 electrode1??? 182
> 36 electrode1??? 172
> 37 electrode1??? 169
>
> [[5]]
> ??? electrode length
> 38 electrode2???? 82
> 39 electrode2???? 78
> 40 electrode2???? 70
> 41 electrode2???? 58
> 42 electrode3??? 260
> 43 electrode3??? 176
> 44 electrode3??? 137
>
> [[6]]
> ??? electrode length
> 45 electrode2???? 82
> 46 electrode2???? 78
> 47 electrode2???? 70
> 48 electrode2???? 58
> 49 electrode4???? 86
> 50 electrode4???? 66
> 51 electrode4???? 64
> 52 electrode4???? 52
> 53 electrode4???? 27
> 54 electrode4???? 26
>
> [[7]]
> ??? electrode length
> 55 electrode3??? 260
> 56 electrode3??? 176
> 57 electrode3??? 137
> 58 electrode1??? 206
> 59 electrode1??? 194
> 60 electrode1??? 182
> 61 electrode1??? 172
> 62 electrode1??? 169
>
> [[8]]
> ??? electrode length
> 63 electrode3??? 260
> 64 electrode3??? 176
> 65 electrode3??? 137
> 66 electrode2???? 82
> 67 electrode2???? 78
> 68 electrode2???? 70
> 69 electrode2???? 58
>
> [[9]]
> ??? electrode length
> 70 electrode3??? 260
> 71 electrode3??? 176
> 72 electrode3??? 137
> 73 electrode4???? 86
> 74 electrode4???? 66
> 75 electrode4???? 64
> 76 electrode4???? 52
> 77 electrode4???? 27
> 78 electrode4???? 26
>
> [[10]]
> ??? electrode length
> 79 electrode4???? 86
> 80 electrode4???? 66
> 81 electrode4???? 64
> 82 electrode4???? 52
> 83 electrode4???? 27
> 84 electrode4???? 26
> 85 electrode1??? 206
> 86 electrode1??? 194
> 87 electrode1??? 182
> 88 electrode1??? 172
> 89 electrode1??? 169
>
> [[11]]
> ??? electrode length
> 90 electrode4???? 86
> 91 electrode4???? 66
> 92 electrode4???? 64
> 93 electrode4???? 52
> 94 electrode4???? 27
> 95 electrode4???? 26
> 96 electrode2???? 82
> 97 electrode2???? 78
> 98 electrode2???? 70
> 99 electrode2???? 58
>
> [[12]]
> ???? electrode length
> 100 electrode4???? 86
> 101 electrode4???? 66
> 102 electrode4???? 64
> 103 electrode4???? 52
> 104 electrode4???? 27
> 105 electrode4???? 26
> 106 electrode3??? 260
> 107 electrode3??? 176
> 108 electrode3??? 137
>
>
> A.K.
>
>
>
>
> ----- Original Message -----
> From: "dennis1991 at gmx.net" <dennis1991 at gmx.net>
> To: Rui Barradas <ruipbarradas at sapo.pt>; r-help at r-project.org
> Cc:
> Sent: Friday, July 26, 2013 6:07 AM
> Subject: Re: [R] How to split two levels several times?
>
> Hi Rui & Arun,
> really thanks for investing so much time to deal with this problem! The code works now for this specific example. However it is not generally robust for slightly different situations. For instance it cannot correctly handle a slight variation of the table where I have again 4 types of electrodes of certain lengths. Electrode4 exists only 6 times. At the transition of the combinations 3-4 and 4-1 there are 12 times electrode4 which stick together in the output $`9`. This leads to wrong splittings thereafter. Sorry for asking such tricky questions.
>
> New table XXX
>
> electrode??? length
> electrode1??? 206
> electrode1??? 194
> electrode1??? 182
> electrode1??? 172
> electrode1??? 169
> electrode2??? 82
> electrode2??? 78
> electrode2??? 70
> electrode2??? 58
> electrode1??? 206
> electrode1??? 194
> electrode1??? 182
> electrode1??? 172
> electrode1??? 169
> electrode3??? 260
> electrode3??? 176
> electrode3??? 137
> electrode1??? 206
> electrode1??? 194
> electrode1??? 182
> electrode1??? 172
> electrode1??? 169
> electrode4??? 86
> electrode4??? 66
> electrode4??? 64
> electrode4??? 52
> electrode4??? 27
> electrode4??? 26
> electrode2??? 82
> electrode2??? 78
> electrode2??? 70
> electrode2??? 58
> electrode1??? 206
> electrode1??? 194
> electrode1??? 182
> electrode1??? 172
> electrode1??? 169
> electrode2??? 82
> electrode2??? 78
> electrode2??? 70
> electrode2??? 58
> electrode3??? 260
> electrode3??? 176
> electrode3??? 137
> electrode2??? 82
> electrode2??? 78
> electrode2??? 70
> electrode2??? 58
> electrode4??? 86
> electrode4??? 66
> electrode4??? 64
> electrode4??? 52
> electrode4??? 27
> electrode4??? 26
> electrode3??? 260
> electrode3??? 176
> electrode3??? 137
> electrode1??? 206
> electrode1??? 194
> electrode1??? 182
> electrode1??? 172
> electrode1??? 169
> electrode3??? 260
> electrode3??? 176
> electrode3??? 137
> electrode2??? 82
> electrode2??? 78
> electrode2??? 70
> electrode2??? 58
> electrode3??? 260
> electrode3??? 176
> electrode3??? 137
> electrode4??? 86
> electrode4??? 66
> electrode4??? 64
> electrode4??? 52
> electrode4??? 27
> electrode4??? 26
> electrode4??? 86
> electrode4??? 66
> electrode4??? 64
> electrode4??? 52
> electrode4??? 27
> electrode4??? 26
> electrode1??? 206
> electrode1??? 194
> electrode1??? 182
> electrode1??? 172
> electrode1??? 169
> electrode4??? 86
> electrode4??? 66
> electrode4??? 64
> electrode4??? 52
> electrode4??? 27
> electrode4??? 26
> electrode2??? 82
> electrode2??? 78
> electrode2??? 70
> electrode2??? 58
> electrode4??? 86
> electrode4??? 66
> electrode4??? 64
> electrode4??? 52
> electrode4??? 27
> electrode4??? 26
> electrode3??? 260
> electrode3??? 176
> electrode3??? 137
>
>
>
>
>
> > Gesendet: Donnerstag, 25. Juli 2013 um 20:53 Uhr
> > Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> > An: dennis1991 at gmx.net
> > Cc: r-help at r-project.org
> > Betreff: Re: Aw: Re:? Re:? Re: [R] How to split two levels several times?
> >
> > Hello,
> >
> > I think the following does what you want. (I don't know if it makes much
> > sense but it works.)
> >
> >
> >
> > lens <- rle(as.character(XXX$electrode))$lengths
> > m <- length(lens) %/% 2
> > idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> > if(length(lens) %% 2 != 0){
> > ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
> > ??? sp_idx <- split(idx, idx)
> > ??? n <- length(sp_idx[[m]])
> > ??? if(n %/% 2 < length(sp_idx[[m + 1]]))
> > ??? ??? sp_idx[[m]][(n %/% 2 + 1):n] <- sp_idx[[m + 1]][1]
> > ??? else
> > ??? ??? sp_idx[[m]][(n - length(sp_idx[[m + 1]]) + 1):n] <-? sp_idx[[m + 1]][1]
> > ??? idx <- unlist(sp_idx)
> > }
> >
> > sp <- split(XXX, idx)
> > sp
> >
> >
> >
> > Rui Barradas
> >
> > Em 25-07-2013 11:40, dennis1991 at gmx.net escreveu:
> > > Hi Rui
> > > once more thank you for your help. But the code does so far not solve the problem because it still treats rows 17-22 (repeated appearance of electrode1) as one single level. However as can be seen by rows 1-3 (or rows 17-19 and rows 20-22) and the order of the length variable (row 1 = 5.7, row 2 = 6.3, row 3 = 6.2) electrode1 consists only of 3 rows. Maybe that was not made absolutely clear by me. As described in my mail before if by chance (or systematically) it happens to be that electrode1 appears right after each other in the table then the code should split it ?half way?.
> > >
> > > So idx should not return
> > >?? [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3 3 4 4 4
> > >
> > > but instead 6 times number 4 at the end
> > >?? [1] 1 1 1 1 1 2 2 2 2 2 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4
> > >
> > > Do you have any solution?
> > >
> > >
> > >> Gesendet: Mittwoch, 24. Juli 2013 um 23:47 Uhr
> > >> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> > >> An: dennis1991 at gmx.net
> > >> Cc: r-help at r-project.org
> > >> Betreff: Re: Aw: Re:? Re: [R] How to split two levels several times?
> > >>
> > >> Hello,
> > >>
> > >> As for the first question, note that in the case you describe, the
> > >> resulting list of df's will not be a split of the original, there will
> > >> be a duplication in the final 4-1 and 1-3. The following is a hack but
> > >> will do it.
> > >>
> > >>
> > >> lens <- rle(as.character(XXX$electrode))$lengths
> > >> m <- length(lens) %/% 2
> > >> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> > >> if(length(lens) %% 2 != 0)
> > >> ??? idx <- c(idx, rep(m + 1, lens[length(lens)]))
> > >>
> > >> sp <- split(XXX, idx)
> > >>
> > >> if(length(lens) %% 2 != 0){
> > >> ??? idx2 <- sp[[m]]$electrode == sp[[m]]$electrode[nrow(sp[[m]])]
> > >> ??? sp[[m + 1]] <- rbind(sp[[m]][idx2, ], sp[[m + 1]])
> > >> }
> > >> sp
> > >>
> > >>
> > >> As for the second question, I'm not understanding it, can you post
> > >> sample output?
> > >>
> > >> Rui Barradas
> > >>
> > >> Em 24-07-2013 13:58, dennis1991 at gmx.net escreveu:
> > >>> Hi Rui
> > >>> the splitting code worked fine. Thanks for your help. Now I realized that the code cannot handle a table with levels that by chance (or systematically) repeatedly appear after each other. For instance this may happen if I need to extract the final two pairs of the table XXX below: electrode4+electrode1 and electrode1+electrode3.
> > >>>
> > >>> lens <- rle(as.character(XXX$electrode))$lengths
> > >>> will return 3 2 3 2 6 6 3 and not 3 2 3 2 6 3 3 3 because it counts electrode1 double.
> > >>> split(XXX, idx) will produce 3 incorrect outputs instead of the required 4.
> > >>> This will also occur if I have systematic combinations 1-4 after each other for instance in a new table ?XX? below where electrode4 appears twice.
> > >>>
> > >>> Is there a way to make splitting "half-way" between two of the same levels possible by predefining the length of each individual level? This would make the splitting code more robust. Thanks for advice.
> > >>>
> > >>>
> > >>> This is the table "XXX"
> > >>>
> > >>> electrode length
> > >>>
> > >>> electrode1 5.7
> > >>> electrode1 6.3
> > >>> electrode1 6.2
> > >>> electrode2 11.4
> > >>> electrode2 9.7
> > >>> electrode3 14.2
> > >>> electrode3 14.8
> > >>> electrode3 12.6
> > >>> electrode2 11.4
> > >>> electrode2 9.7
> > >>> electrode4 17.0
> > >>> electrode4 16.3
> > >>> electrode4 17.8
> > >>> electrode4 18.3
> > >>> electrode4 16.9
> > >>> electrode4 18.5
> > >>> electrode1 5.7
> > >>> electrode1 6.3
> > >>> electrode1 6.2
> > >>> electrode1 5.7
> > >>> electrode1 6.3
> > >>> electrode1 6.2
> > >>> electrode3 14.2
> > >>> electrode3 14.8
> > >>> electrode3 12.6
> > >>>
> > >>>
> > >>> This is a simplified table XX
> > >>>
> > >>> electrode1
> > >>> electrode2
> > >>> electrode1
> > >>> electrode3
> > >>> electrode1
> > >>> electrode4
> > >>> electrode2
> > >>> electrode1
> > >>> electrode2
> > >>> electrode3
> > >>> electrode2
> > >>> electrode4
> > >>> electrode3
> > >>> electrode1
> > >>> electrode3
> > >>> electrode2
> > >>> electrode3
> > >>> electrode4
> > >>> electrode4
> > >>> electrode1
> > >>> electrode4
> > >>> electrode2
> > >>> electrode4
> > >>> electrode3
> > >>>
> > >>>
> > >>>
> > >>>
> > >>>
> > >>>
> > >>>> Gesendet: Dienstag, 23. Juli 2013 um 13:36 Uhr
> > >>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> > >>>> An: dennis1991 at gmx.net
> > >>>> Cc: smartpink111 at yahoo.com, 'r-help' <r-help at r-project.org>
> > >>>> Betreff: Re: Aw: Re: [R] How to split two levels several times?
> > >>>>
> > >>>> Hello,
> > >>>>
> > >>>> It's better if you keep this on the list, the odds of getting more and
> > >>>> better answers are greater.
> > >>>>
> > >>>> As for your new question, try the following.
> > >>>>
> > >>>>
> > >>>> lens <- rle(as.character(XXX$electrode))$lengths
> > >>>> m <- length(lens) %/% 2
> > >>>> idx <- rep(1:m, sapply(1:m, function(.m) sum(lens[(2*.m - 1):(2*.m)])))
> > >>>> split(XXX, idx)
> > >>>>
> > >>>>
> > >>>> Hope this helps,
> > >>>>
> > >>>> Rui Barradas
> > >>>>
> > >>>> Em 23-07-2013 11:41, dennis1991 at gmx.net escreveu:
> > >>>>> Hi
> > >>>>> this type of splitting works for my specific example. Thanks for your help.
> > >>>>>
> > >>>>> I was not absolutely clear what I generally want. I'm looking for an option that generally permits splitting two joint levels of a table after each other. For instance for the table below I want it to be divided into combinations electrode1-electrode2,? electrode3-electrode2,? electrode4-electrode1. How should I split this?
> > >>>>>
> > >>>>>
> > >>>>> This is the table "XXX"
> > >>>>>
> > >>>>> electrode length
> > >>>>>
> > >>>>> electrode1 5.7
> > >>>>> electrode1 6.3
> > >>>>> electrode1 6.2
> > >>>>> electrode2 11.4
> > >>>>> electrode2 9.7
> > >>>>> electrode3 14.2
> > >>>>> electrode3 14.8
> > >>>>> electrode3 12.6
> > >>>>> electrode2 11.4
> > >>>>> electrode2 9.7
> > >>>>> electrode4 17.0
> > >>>>> electrode4 16.3
> > >>>>> electrode4 17.8
> > >>>>> electrode4 18.3
> > >>>>> electrode4 16.9
> > >>>>> electrode4 18.5
> > >>>>> electrode1 5.7
> > >>>>> electrode1 6.3
> > >>>>> electrode1 6.2
> > >>>>>
> > >>>>>
> > >>>>>
> > >>>>>
> > >>>>>
> > >>>>>> Gesendet: Montag, 22. Juli 2013 um 17:53 Uhr
> > >>>>>> Von: "Rui Barradas" <ruipbarradas at sapo.pt>
> > >>>>>> An: dennis1991 at gmx.net
> > >>>>>> Cc: r-help at r-project.org
> > >>>>>> Betreff: Re: [R] How to split two levels several times?
> > >>>>>>
> > >>>>>> Hello,
> > >>>>>>
> > >>>>>> Sorry, I've just realized that your data frame is named 'XXX', not
> > >>>>>> 'dat'. Change that and the rest should work:
> > >>>>>>
> > >>>>>>
> > >>>>>> idx <- cumsum(c(TRUE, diff(XXX$electrode == "electrode1") > 0))
> > >>>>>> split(XXX, idx)
> > >>>>>>
> > >>>>>>
> > >>>>>> Rui Barradas
> > >>>>>>
> > >>>>>> Em 22-07-2013 16:47, Rui Barradas escreveu:
> > >>>>>>> Hello,
> > >>>>>>>
> > >>>>>>> Try the following.
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> idx <- cumsum(c(TRUE, diff(dat$electrode == "electrode1") > 0))
> > >>>>>>> split(dat, idx)
> > >>>>>>>
> > >>>>>>>
> > >>>>>>> Hope this helps,
> > >>>>>>>
> > >>>>>>> Rui Barradas
> > >>>>>>>
> > >>>>>>> Em 22-07-2013 15:09, dennis1991 at gmx.net escreveu:
> > >>>>>>>> Hi,
> > >>>>>>>>
> > >>>>>>>> I have a small problem with the function split() and would appreciate
> > >>>>>>>> your help.
> > >>>>>>>>
> > >>>>>>>> I have a table called ?XXX? with 2 columns and 49 rows. The 49 rows
> > >>>>>>>> belong to 8 different levels (electrode1, ...,electrode8). I want to
> > >>>>>>>> split the table always at the row where ?electrode1? starts again so
> > >>>>>>>> that I can export 7? individual dataframes (numbered ?dataframe1? to
> > >>>>>>>> ?dataframe7?) which contain always electrode1 as first level (always
> > >>>>>>>> three rows) with the varying number of rows for electrodes2-8 below.
> > >>>>>>>> I tried the split function with various setups:
> > >>>>>>>>
> > >>>>>>>> t <- as.factor(XXX$electrode)
> > >>>>>>>>
> > >>>>>>>> dataframeX <- split(XXX, f=(levels=t))
> > >>>>>>>>
> > >>>>>>>> But this doesn?t work. Could you please help. Thank you! Dennis
> > >>>>>>>>
> > >>>>>>>>
> > >>>>>>>> This is the table "XXX"
> > >>>>>>>>
> > >>>>>>>> electrode? ? length
> > >>>>>>>>
> > >>>>>>>> electrode1? ? 5.7
> > >>>>>>>> electrode1? ? 6.3
> > >>>>>>>> electrode1? ? 6.2
> > >>>>>>>> electrode2? ? 11.4
> > >>>>>>>> electrode2? ? 9.7
> > >>>>>>>> electrode1? ? 5.7
> > >>>>>>>> electrode1? ? 6.3
> > >>>>>>>> electrode1? ? 6.2
> > >>>>>>>> electrode3? ? 14.2
> > >>>>>>>> electrode3? ? 14.8
> > >>>>>>>> electrode3? ? 12.6
> > >>>>>>>> electrode1? ? 5.7
> > >>>>>>>> electrode1? ? 6.3
> > >>>>>>>> electrode1? ? 6.2
> > >>>>>>>> electrode4? ? 17.0
> > >>>>>>>> electrode4? ? 16.3
> > >>>>>>>> electrode4? ? 17.8
> > >>>>>>>> electrode4? ? 18.3
> > >>>>>>>> electrode4? ? 16.9
> > >>>>>>>> electrode4? ? 18.5
> > >>>>>>>> electrode1? ? ....
> > >>>>>>>> ....? ? ? ? ....
> > >>>>>>>> electrode5? ? ....
> > >>>>>>>> ....? ? ? ? ....
> > >>>>>>>> electrode1? ? ....
> > >>>>>>>> electrode6? ? ....
> > >>>>>>>> electrode1? ? ....
> > >>>>>>>> electrode7? ? ....
> > >>>>>>>> electrode1? ? ....
> > >>>>>>>> electrode8? ? ....
> > >>>>>>>>
> > >>>>>>>> ______________________________________________
> > >>>>>>>> R-help at r-project.org mailing list
> > >>>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>>> PLEASE do read the posting guide
> > >>>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>>>>>>
> > >>>>>>>
> > >>>>>>> ______________________________________________
> > >>>>>>> R-help at r-project.org mailing list
> > >>>>>>> https://stat.ethz.ch/mailman/listinfo/r-help
> > >>>>>>> PLEASE do read the posting guide
> > >>>>>>> http://www.R-project.org/posting-guide.html
> > >>>>>>> and provide commented, minimal, self-contained, reproducible code.
> > >>>>>>
> > >>>>
> > >>
> >
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>


From tiago.pereira at mbe.bio.br  Mon Jul 29 15:42:37 2013
From: tiago.pereira at mbe.bio.br (Tiago V. Pereira)
Date: Mon, 29 Jul 2013 10:42:37 -0300 (BRT)
Subject: [R] How to double integrate a function in R
Message-ID: <48422.186.215.164.146.1375105357.squirrel@webmail.mbe.bio.br>

I would like to express my gratitude for the great help given by David and
Hans regarding my last query.

Thank you very much for your time, people.

All the best,

Tiago
---
Hello, R users!

I am trying to double integrate the following expression:

#  expression
(1/(2*pi))*exp(-y2/2)*sqrt((y1/(y2-y1)))

for y2>y1>0.

I am trying the following approach

# first attempt

 library(cubature)
    fun <- function(x)   {
(1/(2*pi))*exp(-x[2]/2)*sqrt((x[1]/(x[2]-x[1])))} adaptIntegrate(fun,
lower = c(0,0), upper =c(5, 6), tol=1e-8)

However, I don't know how to constrain the integration so that y2>y1>0.

Any ideas?

Tiago




-- 
Tiago V. Pereira, MSc, PhD
Center for Studies of the Human Genome
Department of Genetics and Evolutionary Biology
University of S?o Paulo
Rua do Mat?o, 277
CEP 05508-900
S?o Paulo - SP,  Brazil


From wdunlap at tibco.com  Mon Jul 29 16:22:16 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 29 Jul 2013 14:22:16 +0000
Subject: [R] Alternative method for range-matching within 2 nested loops
 in	R?
In-Reply-To: <51F4499A.6020304@ucsd.edu>
References: <51F4499A.6020304@ucsd.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B931C32A77F@PA-MBX01.na.tibco.com>

Look into the findInterval function.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of John Helly
> Sent: Saturday, July 27, 2013 3:29 PM
> To: r-help at r-project.org
> Subject: [R] Alternative method for range-matching within 2 nested loops in R?
> 
> Hi.
> 
> I've been puzzling about how to replace the nested loops below. The idea
> is that the B dataframe has rows with a posix datetime and the C
> dataframes has posix Start and End times.  I want to assign a value to
> the observations in B based in intersecting the appropriate
> time-interval in C.  I haven't been able to discern a more efficient way
> to do this.  Any suggestions would be most appreciated.
> 
> brows = dim(B)[1]
> mrows = dim(C)[1]
> 
> for (i in 1:brows ) {
>      for (j in 1:mrows ) {
>          if (B$Datetime[i] >= C$DT_Start[j] & B$Datetime<=C$DT_End[j]){
>              B$Site[i] = C$Proximity[j]
>          }
>      }
> }
> 
> --
> John Helly, University of California, San Diego / San Diego Supercomputer Center /
> Scripps Institution of Oceanography / 760 840 8660 mobile / stonesteps (Skype) /
> stonesteps7 (iChat) / http://www.sdsc.edu/~hellyj


From edoardo.baldoni at gmail.com  Mon Jul 29 16:27:30 2013
From: edoardo.baldoni at gmail.com (Edoardo Baldoni)
Date: Mon, 29 Jul 2013 16:27:30 +0200
Subject: [R] legend in ggmap
Message-ID: <CAOcqoUNCCC=kpQkOgL-KD81iqQxAb_QhDsDxOxobFFLAOWcquw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/daad6c3c/attachment.pl>

From dcarlson at tamu.edu  Mon Jul 29 16:35:52 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 29 Jul 2013 09:35:52 -0500
Subject: [R] R function
In-Reply-To: <51F62BC1.2060203@sapo.pt>
References: <CANTxAmKYf4_0eDY1h8=wv6393+Qe3zS_4dFmDqS40Vngh2wVDA@mail.gmail.com>	<51F628B0.4050702@sapo.pt>
	<51F62BC1.2060203@sapo.pt>
Message-ID: <02d201ce8c68$ed6f60f0$c84e22d0$@tamu.edu>

Rui has shown you a much more efficient way to code your
function in R. To fix the code you posted, you need to add
brackets around the loop, test x[i] instead of i (which is
always >= 1), and get the length of the loop from x not
pah1$P. Without the brackets only the first if() is included
in the for loop:

T <- function(x) {
for (i in 1:length(x)) {
	if (x[i] >= 1) 
		print("Combustion")
	if (x[i] < 1) 
		print("Petroleum")
	}
}

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Rui
Barradas
Sent: Monday, July 29, 2013 3:46 AM
To: javad bayat
Cc: r-help at r-project.org
Subject: Re: [R] R function

Hello,

Sorry, that should be


T <- function(x){
	ifelse(x > = 1, "Combustion", "Petroleum")
}



Rui Barradas

Em 29-07-2013 09:32, Rui Barradas escreveu:
> Hello,
>
> Try the following.
>
> T <- function(x){
>      ifelse(pah1$P > = 1, "Combustion", "Petroleum")
> }
>
> T(pah1$P[1:83])
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 29-07-2013 06:35, javad bayat escreveu:
>> Dear R users;
>> I am MSc student and I want to write my own function, but
it cant be
>> completed. please help me for solve it. here is my code:
>>
>> pah1$P = (pah1$Fluoranthene/pah1$Pyrene)
>> T = function(x){
>> for (i in 1:length(pah1$P))
>> if (i >= 1)
>> print("Combustion")
>> if (i < 1)
>> print("Petroleum")
>> }
>> T(pah1$P[c(1:83),])
>>
>> I wish that R gives me a column that if value greater or
equal to one
>> give
>> "Combustion"  and if value is less than one give
"Petroleum".
>> but my function dose not work.
>> thank you so much for your help.
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained,
reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible
code.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From macqueen1 at llnl.gov  Mon Jul 29 16:47:34 2013
From: macqueen1 at llnl.gov (MacQueen, Don)
Date: Mon, 29 Jul 2013 14:47:34 +0000
Subject: [R] Error: Line starting ' ...' is malformed!
In-Reply-To: <201307261108.18883.ross@biostat.ucsf.edu>
Message-ID: <5E1B812FAC2C4A49B3D99593B5A521914B65B8@PRDEXMBX-08.the-lab.llnl.gov>

A recent version of the R extension manual says,

"For maximal portability, the ?DESCRIPTION? file should be written
entirely in ASCII ? if this is not possible it must contain an ?Encoding?
field (see below)."

It also says, regarding the DESCRIPTION file,

"Fields start with an ASCII name immediately followed by a colon: the
value starts after the colon and a space."

-- 
Don MacQueen

Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062





On 7/26/13 11:08 AM, "Ross Boylan" <ross at biostat.ucsf.edu> wrote:

>A DESCRIPTION file begins with 0xFFFE and
>$ file DESCRIPTION
>DESCRIPTION: Little-endian UTF-16 Unicode text, with CRLF, CR line
>terminators
>
>I think it was created on Windows.
>
>In R (2,15,1 on Debian GNU/Linux), using roxygen2, I get
>> roxygenize("../GitHub/mice")
>Error: Line starting '??P ...' is malformed!
>
>Enter a frame number, or 0 to exit
>
>1: roxygenize("../GitHub/mice")
>2: read.description(DESCRIPTION)
>3: read.dcf(file)
>
>Selection: 3
>Called from: read.description(DESCRIPTION)
>Browse[1]> Q
>
>I'm not sure if the first 2 characters after line starting ', which are
>octal 
>377, 376, will survive email; I stripped them out of the subject line.
>
>The files (DESCRIPTION isn't the only one) have also caused trouble for
>git 
>(even on  Windows 7), since it thinks they are binary.
>
>Any advice about what to do?
>
>I'm reluctant to change the format of the files because it's not my
>package.
>
>Ross Boylan
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From hb at biostat.ucsf.edu  Mon Jul 29 18:03:52 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Mon, 29 Jul 2013 09:03:52 -0700
Subject: [R] Chinese characters in html source captured by
 download.file() are garbled code , how to convert it readable
In-Reply-To: <CAHB3Jmk=+_0R+eTaV+axdQaJApBcSbia1GtMxZJVM3kiXrPDYA@mail.gmail.com>
References: <CAHB3Jmk=+_0R+eTaV+axdQaJApBcSbia1GtMxZJVM3kiXrPDYA@mail.gmail.com>
Message-ID: <CAFDcVCTHOYeP4Sm6uu4xs96dDC+SFLBo3s3c_ZZdWwocZDbnxg@mail.gmail.com>

Try with adding mode="wb" to download.file(), or just use
downloadFile() of R.utils.

/Henrik

On Sun, Jul 28, 2013 at 8:32 PM, Yong Wang <wangyong1 at gmail.com> wrote:
> Dear list,
> I am working with R to download numerous html source code from which the
> data extracted will be further processed.
> The problem is the Chinese character in the html source code are all
> garbled and I can't really find a way to convert them to something readable.
> This problem persists on ubuntu-10 and win-7, English environment. Not try
> Operating system in Chinese yet.
> I know literally nothing about encoding and a comprehensive search online
> does not save me from this woe.
>
> # the code
> download.file("
> https://www.google.com.hk/finance/company_news?q=SHA:601857&gl=cn&num=200
> ",destfile="tmp.txt")
> test<-readLines("tmp.txt",encoding="UTF-8")
>
>     #the garbled code in "tmp.txt" and "test" is like below
>     #??&#22269;??o??M?a??????????q?]?
>
>
> Any help is highly appreciated.
>
> yong
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jeroen.van.leuken at rivm.nl  Mon Jul 29 11:48:58 2013
From: jeroen.van.leuken at rivm.nl (Jeroen)
Date: Mon, 29 Jul 2013 02:48:58 -0700 (PDT)
Subject: [R] Multiple interaction terms in GAMM-model
In-Reply-To: <1374753371065-4672297.post@n4.nabble.com>
References: <1374753371065-4672297.post@n4.nabble.com>
Message-ID: <1375091338324-4672577.post@n4.nabble.com>

Thanks for your extended reply. Application of the splines seems to be very
plausible.
 
I have now added random effects to the GAMM-model:

random= list( objectID= ~1|doy )

(is that defined correct?)

But I am wondering how to include both time and space in one te()-function?
Or would it be better to not use the by= factor(region), but a special
spatial autocorrelation with the x and y-coordinates per objectID? Thus
something like:

 correlation= corAR1( form= ~ objectX + objectY )

Thus resulting in the GAMM-model:

model.formula           <- formula( tau ~ te( x1, doy, bs= c('cr','cc' ) ) +
... + te( x4, doy, bs= c('cr', 'cc' ) ) )
model                           <- gamm( formula= model.formula, 
                                             random= list( farmID=
~1|dayOfTheYear ),
                                             correlation= corAR1( form= ~
farmX+farmY ), 
                                             control= ctrl,
                                             na.action= na.omit )

Concerning the memory, yes this will be an issue. I have a 16 GB server
available with 6 processors. Maybe it would be wise to run 4 seperate
GAMM-models, i.e. with x1, x2, x3, and x4 seperated. 

Thanks in advance.

Jeroen







--
View this message in context: http://r.789695.n4.nabble.com/Multiple-interaction-terms-in-GAMM-model-tp4672297p4672577.html
Sent from the R help mailing list archive at Nabble.com.


From hermia84 at hotmail.com  Mon Jul 29 17:04:29 2013
From: hermia84 at hotmail.com (ZhouYuepeng)
Date: Mon, 29 Jul 2013 23:04:29 +0800
Subject: [R] package "ridge"-how to obtain R squared
Message-ID: <BAY173-W378470B5E82D7BE1CC58CCD9550@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/99b0885e/attachment.pl>

From iza.ch1 at op.pl  Mon Jul 29 18:39:48 2013
From: iza.ch1 at op.pl (iza.ch1)
Date: Mon, 29 Jul 2013 18:39:48 +0200
Subject: [R] replace Na values with the mean of the column which contains
	them
Message-ID: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>

Hi everyone

I have a problem with replacing the NA values with the mean of the column which contains them. If I replace Na with the means of the rest values in the column, the mean of the whole column will be still the same as if I would have omitted NA values. I have the following data

de
     [,1]        [,2]       [,3]
 [1,]          NA -0.26928087 -0.1192078
 [2,]          NA  1.20925752  0.9325334
 [3,]          NA  0.38012008 -1.8927164
 [4,]          NA -0.41778861  1.4330507
 [5,]          NA -0.49677462  0.2892706
 [6,]          NA -0.13248754  1.3976522
 [7,]          NA -0.54179054  0.2295291
 [8,]          NA  0.35788624 -0.5009389
 [9,]  0.27500571 -0.41467591 -0.3426560
[10,] -3.07568579 -0.59234248 -0.8439027
[11,] -0.42240954  0.73642396 -0.4971999
[12,] -0.26901731 -0.06768044 -1.6127122
[13,]  0.01766284 -0.40321968 -0.6508823
[14,] -0.80999580 -1.52283305  1.4729576
[15,]  0.20805934  0.25974308 -1.6093478
[16,]  0.03036708 -0.04013730  0.1686006

and I wrote the code 
de[which(is.na(de))]<-sapply(seq_len(ncol(de)),function(i) {mean(de[,i],na.rm=TRUE)})

I get as the result 
   [,1]        [,2]       [,3]
 [1,] -0.50575168 -0.26928087 -0.1192078
 [2,] -0.12222376  1.20925752  0.9325334
 [3,] -0.13412312  0.38012008 -1.8927164
 [4,] -0.50575168 -0.41778861  1.4330507
 [5,] -0.12222376 -0.49677462  0.2892706
 [6,] -0.13412312 -0.13248754  1.3976522
 [7,] -0.50575168 -0.54179054  0.2295291
 [8,] -0.12222376  0.35788624 -0.5009389
 [9,]  0.27500571 -0.41467591 -0.3426560
[10,] -3.07568579 -0.59234248 -0.8439027
[11,] -0.42240954  0.73642396 -0.4971999
[12,] -0.26901731 -0.06768044 -1.6127122
[13,]  0.01766284 -0.40321968 -0.6508823
[14,] -0.80999580 -1.52283305  1.4729576
[15,]  0.20805934  0.25974308 -1.6093478
[16,]  0.03036708 -0.04013730  0.1686006

It has replaced the NA values in first column with mean of first column -0.505... and second cell with mean of second column etc.
I want to have the result like this:
[,1]        [,2]       [,3]
 [1,] -0.50575168 -0.26928087 -0.1192078
 [2,] -0.50575168  1.20925752  0.9325334
 [3,] -0.50575168  0.38012008 -1.8927164
 [4,] -0.50575168 -0.41778861  1.4330507
 [5,] -0.50575168 -0.49677462  0.2892706
 [6,] -0.50575168 -0.13248754  1.3976522
 [7,] -0.50575168 -0.54179054  0.2295291
 [8,] -0.50575168  0.35788624 -0.5009389
 [9,]  0.27500571 -0.41467591 -0.3426560
[10,] -3.07568579 -0.59234248 -0.8439027
[11,] -0.42240954  0.73642396 -0.4971999
[12,] -0.26901731 -0.06768044 -1.6127122
[13,]  0.01766284 -0.40321968 -0.6508823
[14,] -0.80999580 -1.52283305  1.4729576
[15,]  0.20805934  0.25974308 -1.6093478
[16,]  0.03036708 -0.04013730  0.1686006

Thanks in advance


From ingo at gfz-potsdam.de  Mon Jul 29 12:48:03 2013
From: ingo at gfz-potsdam.de (Ingo Wardinski)
Date: Mon, 29 Jul 2013 12:48:03 +0200
Subject: [R] discontinous ssa forecast
Message-ID: <51F64863.1020405@gfz-potsdam.de>

Hello,
I compute a singular spectrum ananlysis of a time series using ssa of 
the Rssa package. Then I compute the forecast based on the results of 
the singular spectrum ananlysis (ssa). Here I observe that the original 
time series and the forecast are discontinous.
How can I force the forecast to start at the last value (x,y) of the 
original time series?

This minimal setup should show the (my) problem

library(Rssa)
md=data.frame(time=1:2000,val=runif(1000))
sdd = ts(md[,2], start=0, freq=1)
s<-ssa(sdd)
f1 <- forecast(s,groups=list(1:4),len=60)
plot(f1,xlim=c(1950,2100))

I use the latest version of Rssa, R on linux
Many greets and TIA
ingo


From soledad.esteban at transmittingscience.org  Mon Jul 29 18:57:49 2013
From: soledad.esteban at transmittingscience.org (Soledad De Esteban Trivigno)
Date: Mon, 29 Jul 2013 18:57:49 +0200 (CEST)
Subject: [R] Course R for Beginners, September 3-6, Barcelona, Spain
Message-ID: <1937045245.342402.1375117069079.open-xchange@email.1and1.es>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/e55cb524/attachment.pl>

From bhh at xs4all.nl  Mon Jul 29 19:27:01 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 29 Jul 2013 19:27:01 +0200
Subject: [R] replace Na values with the mean of the column which
	contains them
In-Reply-To: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
References: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
Message-ID: <270D710E-2E84-4F81-88CB-330D08DCC2C2@xs4all.nl>


On 29-07-2013, at 18:39, "iza.ch1" <iza.ch1 at op.pl> wrote:

> Hi everyone
> 
> I have a problem with replacing the NA values with the mean of the column which contains them. If I replace Na with the means of the rest values in the column, the mean of the whole column will be still the same as if I would have omitted NA values. I have the following data
> 
> de
>     [,1]        [,2]       [,3]
> [1,]          NA -0.26928087 -0.1192078
> [2,]          NA  1.20925752  0.9325334
> [3,]          NA  0.38012008 -1.8927164
> [4,]          NA -0.41778861  1.4330507
> [5,]          NA -0.49677462  0.2892706
> [6,]          NA -0.13248754  1.3976522
> [7,]          NA -0.54179054  0.2295291
> [8,]          NA  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> and I wrote the code 
> de[which(is.na(de))]<-sapply(seq_len(ncol(de)),function(i) {mean(de[,i],na.rm=TRUE)})
> 
> I get as the result 
>   [,1]        [,2]       [,3]
> [1,] -0.50575168 -0.26928087 -0.1192078
> [2,] -0.12222376  1.20925752  0.9325334
> [3,] -0.13412312  0.38012008 -1.8927164
> [4,] -0.50575168 -0.41778861  1.4330507
> [5,] -0.12222376 -0.49677462  0.2892706
> [6,] -0.13412312 -0.13248754  1.3976522
> [7,] -0.50575168 -0.54179054  0.2295291
> [8,] -0.12222376  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> It has replaced the NA values in first column with mean of first column -0.505... and second cell with mean of second column etc.
> I want to have the result like this:
> [,1]        [,2]       [,3]
> [1,] -0.50575168 -0.26928087 -0.1192078
> [2,] -0.50575168  1.20925752  0.9325334
> [3,] -0.50575168  0.38012008 -1.8927164
> [4,] -0.50575168 -0.41778861  1.4330507
> [5,] -0.50575168 -0.49677462  0.2892706
> [6,] -0.50575168 -0.13248754  1.3976522
> [7,] -0.50575168 -0.54179054  0.2295291
> [8,] -0.50575168  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006


This seems to do what you want:

library(plyr)
de.res <- t(aaply(de,2,.fun=function(x) {x[which(is.na(x))] <- mean(x,na.rm=TRUE);x})) 
dimnames(de.res) <- NULL


Berend


From jfox at mcmaster.ca  Mon Jul 29 19:29:09 2013
From: jfox at mcmaster.ca (John Fox)
Date: Mon, 29 Jul 2013 13:29:09 -0400
Subject: [R] replace Na values with the mean of the column which
	contains	them
In-Reply-To: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
References: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
Message-ID: <web-467550392@cgpsrv2.cis.mcmaster.ca>

Dear iza.ch1,

I hesitate to say this, because mean imputation is such a bad idea, but it's easy to do what you want with a loop, rather than puzzling over a "cleverer" way to accomplish the task. Here's an example using the Freedman data set in the car package:

> colSums(is.na(Freedman))
population   nonwhite    density      crime 
        10          0         10          0 

> means <- colMeans(Freedman, na.rm=TRUE)

> for (j in 1:ncol(Freedman)){
+     Freedman[is.na(Freedman[, j]), j] <- means[j]
+ }

> colSums(is.na(Freedman))
population   nonwhite    density      crime 
         0          0          0          0 

> colMeans(Freedman)
population   nonwhite    density      crime 
1135.99000   10.80273  765.67000 2714.08182 

> means
population   nonwhite    density      crime 
1135.99000   10.80273  765.67000 2714.08182 

Now you should probably think about whether you really want to do this...

Best,
 John

On Mon, 29 Jul 2013 18:39:48 +0200
 "iza.ch1" <iza.ch1 at op.pl> wrote:
> Hi everyone
> 
> I have a problem with replacing the NA values with the mean of the column which contains them. If I replace Na with the means of the rest values in the column, the mean of the whole column will be still the same as if I would have omitted NA values. I have the following data
> 
> de
>      [,1]        [,2]       [,3]
>  [1,]          NA -0.26928087 -0.1192078
>  [2,]          NA  1.20925752  0.9325334
>  [3,]          NA  0.38012008 -1.8927164
>  [4,]          NA -0.41778861  1.4330507
>  [5,]          NA -0.49677462  0.2892706
>  [6,]          NA -0.13248754  1.3976522
>  [7,]          NA -0.54179054  0.2295291
>  [8,]          NA  0.35788624 -0.5009389
>  [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> and I wrote the code 
> de[which(is.na(de))]<-sapply(seq_len(ncol(de)),function(i) {mean(de[,i],na.rm=TRUE)})
> 
> I get as the result 
>    [,1]        [,2]       [,3]
>  [1,] -0.50575168 -0.26928087 -0.1192078
>  [2,] -0.12222376  1.20925752  0.9325334
>  [3,] -0.13412312  0.38012008 -1.8927164
>  [4,] -0.50575168 -0.41778861  1.4330507
>  [5,] -0.12222376 -0.49677462  0.2892706
>  [6,] -0.13412312 -0.13248754  1.3976522
>  [7,] -0.50575168 -0.54179054  0.2295291
>  [8,] -0.12222376  0.35788624 -0.5009389
>  [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> It has replaced the NA values in first column with mean of first column -0.505... and second cell with mean of second column etc.
> I want to have the result like this:
> [,1]        [,2]       [,3]
>  [1,] -0.50575168 -0.26928087 -0.1192078
>  [2,] -0.50575168  1.20925752  0.9325334
>  [3,] -0.50575168  0.38012008 -1.8927164
>  [4,] -0.50575168 -0.41778861  1.4330507
>  [5,] -0.50575168 -0.49677462  0.2892706
>  [6,] -0.50575168 -0.13248754  1.3976522
>  [7,] -0.50575168 -0.54179054  0.2295291
>  [8,] -0.50575168  0.35788624 -0.5009389
>  [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> Thanks in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jorgeivanvelez at gmail.com  Mon Jul 29 19:32:01 2013
From: jorgeivanvelez at gmail.com (Jorge I Velez)
Date: Tue, 30 Jul 2013 03:32:01 +1000
Subject: [R] replace Na values with the mean of the column which
	contains them
In-Reply-To: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
References: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
Message-ID: <CAKL8G3HXZ32NAfPJB44S3nfVE+77FnmWeTh_dwAVO+3CNruz6g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/9f6e41b0/attachment.pl>

From bhh at xs4all.nl  Mon Jul 29 19:33:11 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 29 Jul 2013 19:33:11 +0200
Subject: [R] replace Na values with the mean of the column which
	contains them
In-Reply-To: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
References: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
Message-ID: <19A2F74F-FB36-4E79-A0A0-CABB07158C5B@xs4all.nl>


On 29-07-2013, at 18:39, "iza.ch1" <iza.ch1 at op.pl> wrote:

> Hi everyone
> 
> I have a problem with replacing the NA values with the mean of the column which contains them. If I replace Na with the means of the rest values in the column, the mean of the whole column will be still the same as if I would have omitted NA values. I have the following data
> 
> de
>     [,1]        [,2]       [,3]
> [1,]          NA -0.26928087 -0.1192078
> [2,]          NA  1.20925752  0.9325334
> [3,]          NA  0.38012008 -1.8927164
> [4,]          NA -0.41778861  1.4330507
> [5,]          NA -0.49677462  0.2892706
> [6,]          NA -0.13248754  1.3976522
> [7,]          NA -0.54179054  0.2295291
> [8,]          NA  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> and I wrote the code 
> de[which(is.na(de))]<-sapply(seq_len(ncol(de)),function(i) {mean(de[,i],na.rm=TRUE)})
> 
> I get as the result 
>   [,1]        [,2]       [,3]
> [1,] -0.50575168 -0.26928087 -0.1192078
> [2,] -0.12222376  1.20925752  0.9325334
> [3,] -0.13412312  0.38012008 -1.8927164
> [4,] -0.50575168 -0.41778861  1.4330507
> [5,] -0.12222376 -0.49677462  0.2892706
> [6,] -0.13412312 -0.13248754  1.3976522
> [7,] -0.50575168 -0.54179054  0.2295291
> [8,] -0.12222376  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> It has replaced the NA values in first column with mean of first column -0.505... and second cell with mean of second column etc.
> I want to have the result like this:
> [,1]        [,2]       [,3]
> [1,] -0.50575168 -0.26928087 -0.1192078
> [2,] -0.50575168  1.20925752  0.9325334
> [3,] -0.50575168  0.38012008 -1.8927164
> [4,] -0.50575168 -0.41778861  1.4330507
> [5,] -0.50575168 -0.49677462  0.2892706
> [6,] -0.50575168 -0.13248754  1.3976522
> [7,] -0.50575168 -0.54179054  0.2295291
> [8,] -0.50575168  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 

or this:

apply(de,2, function(x) {x[which(is.na(x))] <- mean(x,na.rm=TRUE);x})


Berend


From smartpink111 at yahoo.com  Mon Jul 29 19:57:49 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 29 Jul 2013 10:57:49 -0700 (PDT)
Subject: [R] replace Na values with the mean of the column which
	contains them
Message-ID: <1375120669.86318.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Hi,

de<- structure(c(NA, NA, NA, NA, NA, NA, NA, NA, 0.27500571, -3.07568579, 
-0.42240954, -0.26901731, 0.01766284, -0.8099958, 0.20805934, 
0.03036708, -0.26928087, 1.20925752, 0.38012008, -0.41778861, 
-0.49677462, -0.13248754, -0.54179054, 0.35788624, -0.41467591, 
-0.59234248, 0.73642396, -0.06768044, -0.40321968, -1.52283305, 
0.25974308, -0.0401373, -0.1192078, 0.9325334, -1.8927164, 1.4330507, 
0.2892706, 1.3976522, 0.2295291, -0.5009389, -0.342656, -0.8439027, 
-0.4971999, -1.6127122, -0.6508823, 1.4729576, -1.6093478, 0.1686006
), .Dim = c(16L, 3L))


Your code should be:
sapply(seq_len(ncol(de)),function(i) {de[,i][is.na(de[,i])]<-mean(de[,i],na.rm=TRUE);de[,i]})
A.K.




Hi everyone 

I have a problem with replacing the NA values with the mean of 
the column which contains them. If I replace Na with the means of the 
rest values in the column, the mean of the whole column will be still 
the same as if I would have omitted NA values. I have the following data 

de 
? ? ?[,1] ? ? ? ?[,2] ? ? ? [,3] 
?[1,] ? ? ? ? ?NA -0.26928087 -0.1192078 
?[2,] ? ? ? ? ?NA ?1.20925752 ?0.9325334 
?[3,] ? ? ? ? ?NA ?0.38012008 -1.8927164 
?[4,] ? ? ? ? ?NA -0.41778861 ?1.4330507 
?[5,] ? ? ? ? ?NA -0.49677462 ?0.2892706 
?[6,] ? ? ? ? ?NA -0.13248754 ?1.3976522 
?[7,] ? ? ? ? ?NA -0.54179054 ?0.2295291 
?[8,] ? ? ? ? ?NA ?0.35788624 -0.5009389 
?[9,] ?0.27500571 -0.41467591 -0.3426560 
[10,] -3.07568579 -0.59234248 -0.8439027 
[11,] -0.42240954 ?0.73642396 -0.4971999 
[12,] -0.26901731 -0.06768044 -1.6127122 
[13,] ?0.01766284 -0.40321968 -0.6508823 
[14,] -0.80999580 -1.52283305 ?1.4729576 
[15,] ?0.20805934 ?0.25974308 -1.6093478 
[16,] ?0.03036708 -0.04013730 ?0.1686006 

and I wrote the code 
de[which(is.na(de))]<-sapply(seq_len(ncol(de)),function(i) {mean(de[,i],na.rm=TRUE)}) 

I get as the result 
? ?[,1] ? ? ? ?[,2] ? ? ? [,3] 
?[1,] -0.50575168 -0.26928087 -0.1192078 
?[2,] -0.12222376 ?1.20925752 ?0.9325334 
?[3,] -0.13412312 ?0.38012008 -1.8927164 
?[4,] -0.50575168 -0.41778861 ?1.4330507 
?[5,] -0.12222376 -0.49677462 ?0.2892706 
?[6,] -0.13412312 -0.13248754 ?1.3976522 
?[7,] -0.50575168 -0.54179054 ?0.2295291 
?[8,] -0.12222376 ?0.35788624 -0.5009389 
?[9,] ?0.27500571 -0.41467591 -0.3426560 
[10,] -3.07568579 -0.59234248 -0.8439027 
[11,] -0.42240954 ?0.73642396 -0.4971999 
[12,] -0.26901731 -0.06768044 -1.6127122 
[13,] ?0.01766284 -0.40321968 -0.6508823 
[14,] -0.80999580 -1.52283305 ?1.4729576 
[15,] ?0.20805934 ?0.25974308 -1.6093478 
[16,] ?0.03036708 -0.04013730 ?0.1686006 

It has replaced the NA values in first column with mean of first
 column -0.505... and second cell with mean of second column etc. 
I want to have the result like this: 
[,1] ? ? ? ?[,2] ? ? ? [,3] 
?[1,] -0.50575168 -0.26928087 -0.1192078 
?[2,] -0.50575168 ?1.20925752 ?0.9325334 
?[3,] -0.50575168 ?0.38012008 -1.8927164 
?[4,] -0.50575168 -0.41778861 ?1.4330507 
?[5,] -0.50575168 -0.49677462 ?0.2892706 
?[6,] -0.50575168 -0.13248754 ?1.3976522 
?[7,] -0.50575168 -0.54179054 ?0.2295291 
?[8,] -0.50575168 ?0.35788624 -0.5009389 
?[9,] ?0.27500571 -0.41467591 -0.3426560 
[10,] -3.07568579 -0.59234248 -0.8439027 
[11,] -0.42240954 ?0.73642396 -0.4971999 
[12,] -0.26901731 -0.06768044 -1.6127122 
[13,] ?0.01766284 -0.40321968 -0.6508823 
[14,] -0.80999580 -1.52283305 ?1.4729576 
[15,] ?0.20805934 ?0.25974308 -1.6093478 
[16,] ?0.03036708 -0.04013730 ?0.1686006 

Thanks in advance


From yelin at lbl.gov  Mon Jul 29 20:14:15 2013
From: yelin at lbl.gov (Ye Lin)
Date: Mon, 29 Jul 2013 11:14:15 -0700
Subject: [R] add different regression lines for groups on ggplot
In-Reply-To: <8B86CE18F7C.00000368jrkrideau@inbox.com>
References: <CAAvu=bkQ-itDQUgT_FJMupcGRxvTf+ufgsDRs9XM9H2KhxmLjA@mail.gmail.com>
	<8B86CE18F7C.00000368jrkrideau@inbox.com>
Message-ID: <CAAvu=b=gJ9t=ybWT+F5o_Oaio508PL-a3Bp+yQYRH9aivU_-eQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/52dd99f3/attachment.pl>

From john_szumiloski at merck.com  Mon Jul 29 20:28:12 2013
From: john_szumiloski at merck.com (Szumiloski, John)
Date: Mon, 29 Jul 2013 14:28:12 -0400
Subject: [R] Customized interpolating spline?
Message-ID: <78AB1F8EE6D76741958317F29EA5F1CB013606D6D3C0@USCTMXP51004.merck.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/1ad26701/attachment.pl>

From wdunlap at tibco.com  Mon Jul 29 20:40:35 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 29 Jul 2013 18:40:35 +0000
Subject: [R] replace Na values with the mean of the column
	which	contains them
In-Reply-To: <1375120669.86318.YahooMailNeo@web142601.mail.bf1.yahoo.com>
References: <1375120669.86318.YahooMailNeo@web142601.mail.bf1.yahoo.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C32A92B@PA-MBX01.na.tibco.com>

Replacements are a case where I think an explicit for-loop is better than sapply or any
other *apply function.  The for-loop will make the output resemble the output: while
sapply and friends will mangle the class, dimnames, and other attributes of the input.
Also, if you want to replace the NA's by the mean of the containing row then you have
to use t() on sapply's output.

E.g.
  > d <- cbind(AllNAs=NA, NoNAs=c(i=1,ii=2,iii=3,iv=4,v=5), SomeNAs=rep(c(100,NA),len=5))
  > f1 <- function(de)sapply(seq_len(ncol(de)),function(i) {de[,i][is.na(de[,i])]<-mean(de[,i],na.rm=TRUE);de[,i]})
  > f2 <- function(de) { for(i in seq_len(ncol(de))) de[is.na(de[,i]),i] <- mean(de[,i], na.rm=TRUE) ; de }
  > str(f1(d)) # no column names
   num [1:5, 1:3] NaN NaN NaN NaN NaN 1 2 3 4 5 ...
   - attr(*, "dimnames")=List of 2
    ..$ : chr [1:5] "i" "ii" "iii" "iv" ...
    ..$ : NULL
  > str(f2(d))
   num [1:5, 1:3] NaN NaN NaN NaN NaN 1 2 3 4 5 ...
   - attr(*, "dimnames")=List of 2
    ..$ : chr [1:5] "i" "ii" "iii" "iv" ...
    ..$ : chr [1:3] "AllNAs" "NoNAs" "SomeNAs"

  > df <- data.frame(AllNAs=NA, NoNAs=c(i=1,ii=2,iii=3,iv=4,v=5), SomeNAs=rep(c(100+1i,NA),len=5))
  > str(f1(df)) # matrix of complex, not data.frame
   cplx [1:5, 1:3] NaN+0i NaN+0i NaN+0i ...
  > str(f2(df))
  'data.frame':   5 obs. of  3 variables:
   $ AllNAs : num  NaN NaN NaN NaN NaN
   $ NoNAs  : num  1 2 3 4 5
   $ SomeNAs: cplx  100+1i 100+1i 100+1i ...

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of arun
> Sent: Monday, July 29, 2013 10:58 AM
> To: iza.ch1
> Cc: R help
> Subject: Re: [R] replace Na values with the mean of the column which contains them
> 
> Hi,
> 
> de<- structure(c(NA, NA, NA, NA, NA, NA, NA, NA, 0.27500571, -3.07568579,
> -0.42240954, -0.26901731, 0.01766284, -0.8099958, 0.20805934,
> 0.03036708, -0.26928087, 1.20925752, 0.38012008, -0.41778861,
> -0.49677462, -0.13248754, -0.54179054, 0.35788624, -0.41467591,
> -0.59234248, 0.73642396, -0.06768044, -0.40321968, -1.52283305,
> 0.25974308, -0.0401373, -0.1192078, 0.9325334, -1.8927164, 1.4330507,
> 0.2892706, 1.3976522, 0.2295291, -0.5009389, -0.342656, -0.8439027,
> -0.4971999, -1.6127122, -0.6508823, 1.4729576, -1.6093478, 0.1686006
> ), .Dim = c(16L, 3L))
> 
> 
> Your code should be:
> sapply(seq_len(ncol(de)),function(i) {de[,i][is.na(de[,i])]<-
> mean(de[,i],na.rm=TRUE);de[,i]})
> A.K.
> 
> 
> 
> 
> Hi everyone
> 
> I have a problem with replacing the NA values with the mean of
> the column which contains them. If I replace Na with the means of the
> rest values in the column, the mean of the whole column will be still
> the same as if I would have omitted NA values. I have the following data
> 
> de
> ? ? ?[,1] ? ? ? ?[,2] ? ? ? [,3]
> ?[1,] ? ? ? ? ?NA -0.26928087 -0.1192078
> ?[2,] ? ? ? ? ?NA ?1.20925752 ?0.9325334
> ?[3,] ? ? ? ? ?NA ?0.38012008 -1.8927164
> ?[4,] ? ? ? ? ?NA -0.41778861 ?1.4330507
> ?[5,] ? ? ? ? ?NA -0.49677462 ?0.2892706
> ?[6,] ? ? ? ? ?NA -0.13248754 ?1.3976522
> ?[7,] ? ? ? ? ?NA -0.54179054 ?0.2295291
> ?[8,] ? ? ? ? ?NA ?0.35788624 -0.5009389
> ?[9,] ?0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954 ?0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,] ?0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305 ?1.4729576
> [15,] ?0.20805934 ?0.25974308 -1.6093478
> [16,] ?0.03036708 -0.04013730 ?0.1686006
> 
> and I wrote the code
> de[which(is.na(de))]<-sapply(seq_len(ncol(de)),function(i) {mean(de[,i],na.rm=TRUE)})
> 
> I get as the result
> ? ?[,1] ? ? ? ?[,2] ? ? ? [,3]
> ?[1,] -0.50575168 -0.26928087 -0.1192078
> ?[2,] -0.12222376 ?1.20925752 ?0.9325334
> ?[3,] -0.13412312 ?0.38012008 -1.8927164
> ?[4,] -0.50575168 -0.41778861 ?1.4330507
> ?[5,] -0.12222376 -0.49677462 ?0.2892706
> ?[6,] -0.13412312 -0.13248754 ?1.3976522
> ?[7,] -0.50575168 -0.54179054 ?0.2295291
> ?[8,] -0.12222376 ?0.35788624 -0.5009389
> ?[9,] ?0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954 ?0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,] ?0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305 ?1.4729576
> [15,] ?0.20805934 ?0.25974308 -1.6093478
> [16,] ?0.03036708 -0.04013730 ?0.1686006
> 
> It has replaced the NA values in first column with mean of first
>  column -0.505... and second cell with mean of second column etc.
> I want to have the result like this:
> [,1] ? ? ? ?[,2] ? ? ? [,3]
> ?[1,] -0.50575168 -0.26928087 -0.1192078
> ?[2,] -0.50575168 ?1.20925752 ?0.9325334
> ?[3,] -0.50575168 ?0.38012008 -1.8927164
> ?[4,] -0.50575168 -0.41778861 ?1.4330507
> ?[5,] -0.50575168 -0.49677462 ?0.2892706
> ?[6,] -0.50575168 -0.13248754 ?1.3976522
> ?[7,] -0.50575168 -0.54179054 ?0.2295291
> ?[8,] -0.50575168 ?0.35788624 -0.5009389
> ?[9,] ?0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954 ?0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,] ?0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305 ?1.4729576
> [15,] ?0.20805934 ?0.25974308 -1.6093478
> [16,] ?0.03036708 -0.04013730 ?0.1686006
> 
> Thanks in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From e.rapsomaniki at ucl.ac.uk  Mon Jul 29 20:52:37 2013
From: e.rapsomaniki at ucl.ac.uk (Rapsomaniki, Eleni)
Date: Mon, 29 Jul 2013 18:52:37 +0000
Subject: [R] Greek symbols in study labels and custom summary lines in
 forest plot (meta)
Message-ID: <B9A4D9CE43DAC5489E46CB4996D5B9EE467C40BB@AMSPRD0111MB497.eurprd01.prod.exchangelabs.com>

Dear R helpers,

Is there a way to display mathematical notations (e.g. greek characters, subscripts) properly in study (studlab) and group (byvar) labels in a forest plot created using the meta package?

#Example:
library(meta)
logHR <- log(runif(10,0.5,2))
selogHR <- log(runif(10,0.05,0.2))
study=c(0.1,.2,.3,.4,.5,0.1,.2,.3,.4,.5)
group=c(rep('alpha',5),rep('beta',5))
meta1=metagen(logHR, selogHR, sm="HR",studlab=paste("Fixed",expression(beta[w]),study),byvar=group)
forest(meta1, print.byvar=F)

Question 2
Is there a way to add a line to this plot at my preferred location? For example, I want to add a within-group combined estimate line (the default here is just an overall group line by random or fixed effects). 
I know I need to use grid.lines, e.g.

grid.lines(x = 3, y = c(0.5,1),gp = gpar(col = 5))

But for the life of me I can't work out the co-ordinate system in grid graphics!

Thank you for ANY help or tips! I've run out of things to try :(

Eleni

Eleni Rapsomaniki
Research Associate/Statistics, PhD
Clinical Epidemiology Group
Department of Epidemiology and Public Health 
University College London Medical School






From white.232 at wright.edu  Mon Jul 29 20:54:04 2013
From: white.232 at wright.edu (White, William Patrick)
Date: Mon, 29 Jul 2013 18:54:04 +0000
Subject: [R] triangular color plot of array
Message-ID: <182B9AEE07E5114BAB45E0689016C11313488C02@CO1PRD0112MB602.prod.exchangelabs.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/d98f87d9/attachment.pl>

From dwinsemius at comcast.net  Mon Jul 29 20:59:13 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 Jul 2013 11:59:13 -0700
Subject: [R] replace Na values with the mean of the column which
	contains them
In-Reply-To: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
References: <45494284-c26fb82a19892060017f6d6da388dd96@pmq3v.m5r2.onet>
Message-ID: <FF42C572-6F42-456E-B821-CF8B717E0A44@comcast.net>


On Jul 29, 2013, at 9:39 AM, iza.ch1 wrote:

> Hi everyone
> 
> I have a problem with replacing the NA values with the mean of the column which contains them. If I replace Na with the means of the rest values in the column, the mean of the whole column will be still the same as if I would have omitted NA values. I have the following data
> 
> de
>     [,1]        [,2]       [,3]
> [1,]          NA -0.26928087 -0.1192078
> [2,]          NA  1.20925752  0.9325334
> [3,]          NA  0.38012008 -1.8927164
> [4,]          NA -0.41778861  1.4330507
> [5,]          NA -0.49677462  0.2892706
> [6,]          NA -0.13248754  1.3976522
> [7,]          NA -0.54179054  0.2295291
> [8,]          NA  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006

Why not replace with a result that would have both the same mean and standard deviation as the existing data?

set.seed(123)
de[,1][is.na(de[,1])] <- rnorm(sum(is.na(de[,1]),  #specify the number of random values
                               mean(de[,1],na.rm=TRUE), sd(de[,1],na.rm=TRUE ) ) )

-- 
David.

> 
> and I wrote the code 
> de[which(is.na(de))]<-sapply(seq_len(ncol(de)),function(i) {mean(de[,i],na.rm=TRUE)})
> 
> I get as the result 
>   [,1]        [,2]       [,3]
> [1,] -0.50575168 -0.26928087 -0.1192078
> [2,] -0.12222376  1.20925752  0.9325334
> [3,] -0.13412312  0.38012008 -1.8927164
> [4,] -0.50575168 -0.41778861  1.4330507
> [5,] -0.12222376 -0.49677462  0.2892706
> [6,] -0.13412312 -0.13248754  1.3976522
> [7,] -0.50575168 -0.54179054  0.2295291
> [8,] -0.12222376  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> It has replaced the NA values in first column with mean of first column -0.505... and second cell with mean of second column etc.
> I want to have the result like this:
> [,1]        [,2]       [,3]
> [1,] -0.50575168 -0.26928087 -0.1192078
> [2,] -0.50575168  1.20925752  0.9325334
> [3,] -0.50575168  0.38012008 -1.8927164
> [4,] -0.50575168 -0.41778861  1.4330507
> [5,] -0.50575168 -0.49677462  0.2892706
> [6,] -0.50575168 -0.13248754  1.3976522
> [7,] -0.50575168 -0.54179054  0.2295291
> [8,] -0.50575168  0.35788624 -0.5009389
> [9,]  0.27500571 -0.41467591 -0.3426560
> [10,] -3.07568579 -0.59234248 -0.8439027
> [11,] -0.42240954  0.73642396 -0.4971999
> [12,] -0.26901731 -0.06768044 -1.6127122
> [13,]  0.01766284 -0.40321968 -0.6508823
> [14,] -0.80999580 -1.52283305  1.4729576
> [15,]  0.20805934  0.25974308 -1.6093478
> [16,]  0.03036708 -0.04013730  0.1686006
> 
> Thanks in advance
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From LanYing.Gu at cancercare.on.ca  Mon Jul 29 21:23:32 2013
From: LanYing.Gu at cancercare.on.ca (Gu, LanYing)
Date: Mon, 29 Jul 2013 19:23:32 +0000
Subject: [R] about R stat.table function
Message-ID: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/3f0636a7/attachment.pl>

From andrew_cooper at sfu.ca  Mon Jul 29 21:54:37 2013
From: andrew_cooper at sfu.ca (Andrew Cooper)
Date: Mon, 29 Jul 2013 12:54:37 -0700
Subject: [R] split beanplot in ggplot2 - adjusting bandwidth
Message-ID: <20041E52-7A5C-47B4-A2C3-C3F5F89CB2AD@sfu.ca>

Dear R Users,

I'm attempting to create a split beanplot in ggplot2 and have figured most of it out except how to adjust the bandwidth for the density statistic.  I read online that geom_violin will not plot 2 separate sets of data and that geom_ribbon should be used to create a split beanplot.  So, I was able to create this as a quick example that does a split beanplot of mpg for 6-cylinder vehicle vs 8 cylinder vehicles:

p <- ggplot(mtcars)
p + geom_ribbon(data=subset(mtcars,mtcars$cyl==6),
                aes(x=mpg,ymax=..density..,ymin=0),stat="density") +
            geom_ribbon(data=subset(mtcars,mtcars$cyl==8),
              aes(x=mpg,ymax=0,ymin=-..density..),stat="density")

What I can't figure out is how to adjust the bandwidth (e.g. as with 'adjust' in geom_density) for the density statistic in the ribbon plot to make the density plots either more or less smooth.  Or, is there a better way to go about this than what I've currently tried?

Any advice you might have on this would be greatly appreciated!  Thank you for your help!

cheers,
Andy  


From dcarlson at tamu.edu  Mon Jul 29 22:22:25 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 29 Jul 2013 15:22:25 -0500
Subject: [R] triangular color plot of array
In-Reply-To: <182B9AEE07E5114BAB45E0689016C11313488C02@CO1PRD0112MB602.prod.exchangelabs.com>
References: <182B9AEE07E5114BAB45E0689016C11313488C02@CO1PRD0112MB602.prod.exchangelabs.com>
Message-ID: <034001ce8c99$571bd5d0$05538170$@tamu.edu>

A triangular plot can represent three dimensions in a two
dimensional plane because the three dimensions are constrained
by the fact that they sum to 100% (e.g. sand/silt/clay
composition of a soil). That does not seem to apply to your
example. It sounds like you might need a 3d contour plot. You
might look at package misc3d, function countour3d. See the R
Graphical Manual for some examples:

http://rgm3.lab.nig.ac.jp/RGM/R_image_list?package=misc3d

Alternatively you can use lattice to draw 2d contours for a
series of slices. That may not be as snazzy, but it will
probably be easier to interpret.

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of White,
William Patrick
Sent: Monday, July 29, 2013 1:54 PM
To: r-help at R-project.org
Subject: [R] triangular color plot of array

Hello,
I've encountered an interesting situation and can't seem to
find an applicable solution. I've got a multivariate synthetic
dataset I generated in order to explore various statistical
techniques. In my dataset I vary three things, sample size,
effect size, and the number of variables that are affected. As
these are varied I've output my results into a three
dimensional array. So for each possible combination, think xyz
location, I have an output value. What I would like to do is
to create a somewhat unique style of plot very similar to a
triangular soil texture plot, excepting that at rather than
dropping a point at a given coordinate, I have all possible
coordinates on the grid, and I would like to overlay a color
map in which combinations that yield high values shade towards
one color, and low values another or some other such color
scheme. Thus displaying under what conditions certain
accuracies are achieved for the test.
I've explored both the soil texture plotting solutions in R,
and as best I can with little background in image work the 3d
plotting solutions offered by various packages. I haven't
found anything that seems to be able to handle an array this
way. I was wondering if anyone could point me in the right
direction.
P~

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From weigelti at mailserver.tu-freiberg.de  Mon Jul 29 22:20:36 2013
From: weigelti at mailserver.tu-freiberg.de (weigelti at mailserver.tu-freiberg.de)
Date: Mon, 29 Jul 2013 22:20:36 +0200
Subject: [R] cross-correlation with R
Message-ID: <20130729222036.14878sc1d2mr2vf8@webmail.tu-freiberg.de>

Dear R-User,

I'm Student at the TU Bergakademie Freiberg and have R used for the  
first time. I have created cross-correlations of air pressure, outside  
temperature, temperature laboratory and X-ray radiation intensity.  
However, I do not know how I interpret the graphs. Can someone help me?

best regards
Tina Weigel


From E.Vettorazzi at uke.de  Mon Jul 29 22:45:53 2013
From: E.Vettorazzi at uke.de (Eik Vettorazzi)
Date: Mon, 29 Jul 2013 22:45:53 +0200
Subject: [R] Jul 26, 2013; 12:34am
In-Reply-To: <51F26421.3010408@vanderbilt.edu>
References: <51F26421.3010408@vanderbilt.edu>
Message-ID: <51F6D481.4020909@uke.de>

Dear Frank,
you can use grconvertY and grconvertX to convert from user coordinates
to inches etc and vice versa.
E.g.

lines(rep(.25*1500,2),grconvertY(grconvertY(par("usr")[3],"user","inches")+c(0,.1),from="inches",to="user"))

should produce a tick of 0.1 inches height, regardless of the actual
plot height.

Hope this helps.

Am 26.07.2013 13:57, schrieb Frank Harrell:
> Thanks Rich and Jim and apologies for omitting the line
> 
> x <- c(285, 43.75, 94, 150, 214, 375, 270, 350, 41.5, 210, 30, 37.6,
> 281, 101, 210)
> 
> But the fundamental problem remains that vertical spacing is not correct
> unless I waste a lot of image space at the top.
> 
> Frank
> 
> 


-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistr. 52
20246 Hamburg

T ++49/40/7410-58243
F ++49/40/7410-57790


From smartpink111 at yahoo.com  Mon Jul 29 22:58:19 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 29 Jul 2013 13:58:19 -0700 (PDT)
Subject: [R] Aggregate
In-Reply-To: <1375130227.23756.YahooMailNeo@web121306.mail.ne1.yahoo.com>
References: <1375130227.23756.YahooMailNeo@web121306.mail.ne1.yahoo.com>
Message-ID: <1375131499.43776.YahooMailNeo@web142602.mail.bf1.yahoo.com>



Hi,
You could try:
dat1<- read.table(text="
ID ??? Group1
1 ??? 1
1 ??? 0
1 ??? 1
1 ??? 0
2 ??? 1
2 ??? 1
2 ??? 0
2 ??? 1
5 ??? 1
5 ??? 1
5 ??? 1
5 ??? 0
",sep="",header=TRUE)

library(plyr)
res<- ddply(dat1,.(ID),summarize,yes=sum(Group1),no=length(Group1)-sum(Group1))
res
#? ID yes no
#1? 1?? 2? 2
#2? 2?? 3? 1 #need to check
#3? 5?? 3? 1 ###


#or
do.call(rbind,by(dat1$Group1,dat1$ID,table))
#? 0 1
#1 2 2
#2 1 3
#5 1 3

#or
?do.call(rbind,with(dat1,tapply(Group1,ID,FUN=table)))
#? 0 1
#1 2 2
#2 1 3
#5 1 3



A.K.


________________________________
From: farnoosh sheikhi <farnoosh_81 at yahoo.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Monday, July 29, 2013 4:37 PM
Subject: Aggregate



Hi Arun,

I have a question about aggregation in R.
I have the following data set:

ID Group1 
1 1 
1 0 
1 1 
1 0 
2 1 
2 1 
2 0 
2 1 
5 1 
5 1 
5 1 
5 0 

I want to aggregate the data for each ID to get number of zeros and number of ones. something like the following data sets:
? ? ?ID ? ? yes no 
1 2 2 
2 3 0 
5 3 0 



I though I can put the number of ones as YES and the number of Zeroes as NO.
Thanks a lot.
Best,Farnoosh Sheikhi?


From ruipbarradas at sapo.pt  Mon Jul 29 23:13:48 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Mon, 29 Jul 2013 22:13:48 +0100
Subject: [R] about R stat.table function
In-Reply-To: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>
References: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>
Message-ID: <51F6DB0C.7040103@sapo.pt>

Hello,

Where did you get that script from? You should ask the person that gave 
it to you for that missing function, of which we know nothing about.

Hope this helps,

Rui Barradas

Em 29-07-2013 20:23, Gu, LanYing escreveu:
> Hi R Help group,
>
> I try to use stat.table function in my R script, when I run stat.table in R. it shows that "No stat.function found", and I try to get help using "?stat.table" it shows that "No documentation for 'stat.table' in specified packages and libraries:
> you could try '??stat.table'".
>
> it seems no "stat.table" function in my R. I want to know Do I need to install this function? From which website I could install this function? Could you please guide me how to do.
>
> Many thanks,
>
> Lan
>
> ________________________________
>
>
> This e-mail message (and any attachments) may contain co...{{dropped:11}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From dcarlson at tamu.edu  Mon Jul 29 23:16:10 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 29 Jul 2013 16:16:10 -0500
Subject: [R] about R stat.table function
In-Reply-To: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>
References: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>
Message-ID: <035f01ce8ca0$d95b5320$8c11f960$@tamu.edu>

Where did you find out about stat.table()? There is one in
package Epi, but who knows if it is the one you are looking
for? If you don't know about packages and the library()
function, you need to work through a basic tutorial on R. You
can't really expect to download a script file and run it
without knowing anything about R.

The main webpage for R is at http://www.r-project.org/ 
The official documentation is at
http://cran.r-project.org/manuals.html 
User contributed manuals and tutorials in multiple languages
at
http://cran.r-project.org/other-docs.html 
90 two minute R tutorials at http://www.twotorials.com/ 

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Gu, LanYing
Sent: Monday, July 29, 2013 2:24 PM
To: r-help at r-project.org
Subject: [R] about R stat.table function

Hi R Help group,

I try to use stat.table function in my R script, when I run
stat.table in R. it shows that "No stat.function found", and I
try to get help using "?stat.table" it shows that "No
documentation for 'stat.table' in specified packages and
libraries:
you could try '??stat.table'".

it seems no "stat.table" function in my R. I want to know Do I
need to install this function? From which website I could
install this function? Could you please guide me how to do.

Many thanks,

Lan

________________________________


This e-mail message (and any attachments) may contain\ c...{{dropped:11}}


From jdnewmil at dcn.davis.CA.us  Mon Jul 29 23:25:26 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Mon, 29 Jul 2013 14:25:26 -0700
Subject: [R] cross-correlation with R
In-Reply-To: <20130729222036.14878sc1d2mr2vf8@webmail.tu-freiberg.de>
References: <20130729222036.14878sc1d2mr2vf8@webmail.tu-freiberg.de>
Message-ID: <14a0b462-1704-4e3a-924d-c4fa43010d25@email.android.com>

Homework help is off-topic on this list (see the Posting Guide). You should use the assistance provided by your educational institution.

In addition, even if this is not homework, in most cases discussions of theoretical background (interpretation) are off-topic here as well. See stats.stack exchange.com for an example of a forum where such discussions may not be off-topic.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

weigelti at mailserver.tu-freiberg.de wrote:
>Dear R-User,
>
>I'm Student at the TU Bergakademie Freiberg and have R used for the  
>first time. I have created cross-correlations of air pressure, outside 
>
>temperature, temperature laboratory and X-ray radiation intensity.  
>However, I do not know how I interpret the graphs. Can someone help me?
>
>best regards
>Tina Weigel
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From dcarlson at tamu.edu  Mon Jul 29 23:28:57 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Mon, 29 Jul 2013 16:28:57 -0500
Subject: [R] Aggregate
In-Reply-To: <1375131499.43776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1375130227.23756.YahooMailNeo@web121306.mail.ne1.yahoo.com>
	<1375131499.43776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <036101ce8ca2$a23ab4b0$e6b01e10$@tamu.edu>

Or just

table(dat1$ID, dat1$Group1)
#     0 1
#   1 2 2
#   2 1 3
#   5 1 3

Or
xtabs(~ID+Group1, dat1)
#    Group1
# ID  0 1
#   1 2 2
#   2 1 3
#   5 1 3

Or with labeling

dat1$Group1 <- factor(dat1$Group1, labels=c("No", "Yes"))
xtabs(~ID+Group1, dat1)
#    Group1
#  ID  No Yes
#   1  2   2
#   2  1   3
#   5  1   3

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of arun
Sent: Monday, July 29, 2013 3:58 PM
To: farnoosh sheikhi
Cc: R help
Subject: Re: [R] Aggregate



Hi,
You could try:
dat1<- read.table(text="
ID ??? Group1
1 ??? 1
1 ??? 0
1 ??? 1
1 ??? 0
2 ??? 1
2 ??? 1
2 ??? 0
2 ??? 1
5 ??? 1
5 ??? 1
5 ??? 1
5 ??? 0
",sep="",header=TRUE)

library(plyr)
res<-
ddply(dat1,.(ID),summarize,yes=sum(Group1),no=length(Group1)-s
um(Group1))
res
#? ID yes no
#1? 1?? 2? 2
#2? 2?? 3? 1 #need to check
#3? 5?? 3? 1 ###


#or
do.call(rbind,by(dat1$Group1,dat1$ID,table))
#? 0 1
#1 2 2
#2 1 3
#5 1 3

#or
?do.call(rbind,with(dat1,tapply(Group1,ID,FUN=table)))
#? 0 1
#1 2 2
#2 1 3
#5 1 3



A.K.


________________________________
From: farnoosh sheikhi <farnoosh_81 at yahoo.com>

Sent: Monday, July 29, 2013 4:37 PM
Subject: Aggregate



Hi Arun,

I have a question about aggregation in R.
I have the following data set:

ID Group1 
1 1 
1 0 
1 1 
1 0 
2 1 
2 1 
2 0 
2 1 
5 1 
5 1 
5 1 
5 0 

I want to aggregate the data for each ID to get number of
zeros and number of ones. something like the following data
sets:
? ? ?ID ? ? yes no 
1 2 2 
2 3 0 
5 3 0 



I though I can put the number of ones as YES and the number of
Zeroes as NO.
Thanks a lot.
Best,Farnoosh Sheikhi?

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From smartpink111 at yahoo.com  Mon Jul 29 23:40:05 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 29 Jul 2013 14:40:05 -0700 (PDT)
Subject: [R] Aggregate
In-Reply-To: <036101ce8ca2$a23ab4b0$e6b01e10$@tamu.edu>
References: <1375130227.23756.YahooMailNeo@web121306.mail.ne1.yahoo.com>
	<1375131499.43776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<036101ce8ca2$a23ab4b0$e6b01e10$@tamu.edu>
Message-ID: <1375134005.79769.YahooMailNeo@web142601.mail.bf1.yahoo.com>



To add:
library(reshape2)
?dcast(dat1,ID~Group1,length,value.var="Group1") # ID would be a column 
# ID No Yes
#1? 1? 2?? 2
#2? 2? 1?? 3
#3? 5? 1?? 3

A.K.

----- Original Message -----
From: David Carlson <dcarlson at tamu.edu>
To: 'arun' <smartpink111 at yahoo.com>; 'farnoosh sheikhi' <farnoosh_81 at yahoo.com>
Cc: 'R help' <r-help at r-project.org>
Sent: Monday, July 29, 2013 5:28 PM
Subject: RE: [R] Aggregate

Or just

table(dat1$ID, dat1$Group1)
#? ?  0 1
#?  1 2 2
#?  2 1 3
#?  5 1 3

Or
xtabs(~ID+Group1, dat1)
#? ? Group1
# ID? 0 1
#?  1 2 2
#?  2 1 3
#?  5 1 3

Or with labeling

dat1$Group1 <- factor(dat1$Group1, labels=c("No", "Yes"))
xtabs(~ID+Group1, dat1)
#? ? Group1
#? ID? No Yes
#?  1? 2?  2
#?  2? 1?  3
#?  5? 1?  3

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of arun
Sent: Monday, July 29, 2013 3:58 PM
To: farnoosh sheikhi
Cc: R help
Subject: Re: [R] Aggregate



Hi,
You could try:
dat1<- read.table(text="
ID ??? Group1
1 ??? 1
1 ??? 0
1 ??? 1
1 ??? 0
2 ??? 1
2 ??? 1
2 ??? 0
2 ??? 1
5 ??? 1
5 ??? 1
5 ??? 1
5 ??? 0
",sep="",header=TRUE)

library(plyr)
res<-
ddply(dat1,.(ID),summarize,yes=sum(Group1),no=length(Group1)-s
um(Group1))
res
#? ID yes no
#1? 1?? 2? 2
#2? 2?? 3? 1 #need to check
#3? 5?? 3? 1 ###


#or
do.call(rbind,by(dat1$Group1,dat1$ID,table))
#? 0 1
#1 2 2
#2 1 3
#5 1 3

#or
?do.call(rbind,with(dat1,tapply(Group1,ID,FUN=table)))
#? 0 1
#1 2 2
#2 1 3
#5 1 3



A.K.


________________________________
From: farnoosh sheikhi <farnoosh_81 at yahoo.com>
To: "smartpink111 at yahoo.com" <smartpink111 at yahoo.com> 
Sent: Monday, July 29, 2013 4:37 PM
Subject: Aggregate



Hi Arun,

I have a question about aggregation in R.
I have the following data set:

ID Group1 
1 1 
1 0 
1 1 
1 0 
2 1 
2 1 
2 0 
2 1 
5 1 
5 1 
5 1 
5 0 

I want to aggregate the data for each ID to get number of
zeros and number of ones. something like the following data
sets:
? ? ?ID ? ? yes no 
1 2 2 
2 3 0 
5 3 0 



I though I can put the number of ones as YES and the number of
Zeroes as NO.
Thanks a lot.
Best,Farnoosh Sheikhi?

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.



From smartpink111 at yahoo.com  Mon Jul 29 23:54:01 2013
From: smartpink111 at yahoo.com (arun)
Date: Mon, 29 Jul 2013 14:54:01 -0700 (PDT)
Subject: [R] about R stat.table function
In-Reply-To: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>
References: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>
Message-ID: <1375134841.71138.YahooMailNeo@web142604.mail.bf1.yahoo.com>

Hi,
Try:
library(Epi)
?stat.table(tension,list(count(),mean(breaks)),data=warpbreaks)
# ------------------------------- 
# tension?? count() mean(breaks)? 
?#------------------------------- 
?#L????????????? 18??????? 36.39? 
?#M????????????? 18??????? 26.39? 
?#H????????????? 18??????? 21.67? 
?#------------------------------- 
A.K.




----- Original Message -----
From: "Gu, LanYing" <LanYing.Gu at cancercare.on.ca>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Monday, July 29, 2013 3:23 PM
Subject: [R] about R stat.table function

Hi R Help group,

I try to use stat.table function in my R script, when I run stat.table in R. it shows that "No stat.function found", and I try to get help using "?stat.table" it shows that "No documentation for 'stat.table' in specified packages and libraries:
you could try '??stat.table'".

it seems no "stat.table" function in my R. I want to know Do I need to install this function? From which website I could install this function? Could you please guide me how to do.

Many thanks,

Lan

________________________________


This e-mail message (and any attachments) may contain co...{{dropped:11}}

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From farnoosh_81 at yahoo.com  Mon Jul 29 23:18:31 2013
From: farnoosh_81 at yahoo.com (farnoosh sheikhi)
Date: Mon, 29 Jul 2013 14:18:31 -0700 (PDT)
Subject: [R] Aggregate
In-Reply-To: <1375131499.43776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1375130227.23756.YahooMailNeo@web121306.mail.ne1.yahoo.com>
	<1375131499.43776.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1375132711.96625.YahooMailNeo@web121303.mail.ne1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/e9434773/attachment.pl>

From charlie.hsia.us at gmail.com  Tue Jul 30 01:04:11 2013
From: charlie.hsia.us at gmail.com (c char)
Date: Mon, 29 Jul 2013 16:04:11 -0700
Subject: [R] Intersecting two matrices
Message-ID: <CAEOnvcHOjZzQADMJf=AAmf0LUswq_w7iB3Ohh2D0U_j15ds52A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/70c820e4/attachment.pl>

From ashwamegh1935 at gmail.com  Tue Jul 30 01:47:04 2013
From: ashwamegh1935 at gmail.com (Ashwani Rao)
Date: Mon, 29 Jul 2013 16:47:04 -0700
Subject: [R] tm (text mining) package persistent storage
Message-ID: <CAB-sbgqyMzK0kMQXDBQ1gd+LFhRjxkBtzGi8xnPE1YpOLnhHrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130729/f88aaabc/attachment.pl>

From wdunlap at tibco.com  Tue Jul 30 03:24:26 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 30 Jul 2013 01:24:26 +0000
Subject: [R] Intersecting two matrices
In-Reply-To: <CAEOnvcHOjZzQADMJf=AAmf0LUswq_w7iB3Ohh2D0U_j15ds52A@mail.gmail.com>
References: <CAEOnvcHOjZzQADMJf=AAmf0LUswq_w7iB3Ohh2D0U_j15ds52A@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931C32AAFE@PA-MBX01.na.tibco.com>

I haven't looked at the size-time relationship, but im2 (below) is faster than your
function on at least one example:

intersectMat <- function(mat1, mat2)
{
    #mat1 and mat2 are both deduplicated
    nr1 <- nrow(mat1)
    nr2 <- nrow(mat2)
    mat2[duplicated(rbind(mat1, mat2))[(nr1 + 1):(nr1 + nr2)], , drop=FALSE]
}

im2 <- function(mat1, mat2)
{
    stopifnot(ncol(mat1)==2, ncol(mat1)==ncol(mat2))
    toChar <- function(twoColMat) paste(sep="\1", twoColMat[,1], twoColMat[,2])
    mat1[match(toChar(mat2), toChar(mat1), nomatch=0), , drop=FALSE]
}

> m1 <- cbind(1:1e7, rep(1:10, len=1e7))
> m2 <- cbind(1:1e7, rep(1:20, len=1e7))
> system.time(r1 <- intersectMat(m1,m2))
   user  system elapsed 
 430.37    1.96  433.98 
> system.time(r2 <- im2(m1,m2))
   user  system elapsed 
  27.89    0.20   28.13 
> identical(r1, r2)
[1] TRUE
> dim(r1)
[1] 5000000       2

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-help-bounces at r-project.org [mailto:r-help-bounces at r-project.org] On Behalf
> Of c char
> Sent: Monday, July 29, 2013 4:04 PM
> To: r-help at r-project.org
> Subject: [R] Intersecting two matrices
> 
> Dear all,
> 
> I am interested to know a faster matrix intersection package for R handles
> intersection of two integer matrices with ncol=2. Currently I am using my
> homemade code adapted from a previous thread:
> 
> 
> intersectMat <- function(mat1, mat2){#mat1 and mat2 are both
> deduplicated  nr1 <- nrow(mat1)  nr2 <- nrow(mat2)
> mat2[duplicated(rbind(mat1, mat2))[(nr1 + 1):(nr1 + nr2)], ]}
> 
> 
> which handles:
> size A= 10578373
> size B= 9519807
> expected intersecting time= 251.2272
> intersecting for corssing MPRs took 409.602 seconds.
> 
> scale a little bit worse than linearly but atomic operation is not good.
> Wonder if a super fast C/C++ extension exists for this task. Your ideas are
> appreciated.
> 
> Thanks!
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dstr7320 at uni.sydney.edu.au  Tue Jul 30 03:00:14 2013
From: dstr7320 at uni.sydney.edu.au (Dario Strbenac)
Date: Tue, 30 Jul 2013 01:00:14 +0000
Subject: [R] Declare BASH Array Using R System Function
In-Reply-To: <1375103483.77711.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <A4D0AD48C137224D9E532742F418928A1CFB8D27@BL2PRD0111MB520.prod.exchangelabs.com>,
	<1375103483.77711.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <A4D0AD48C137224D9E532742F418928A1CFB8EBD@BL2PRD0111MB520.prod.exchangelabs.com>

Thank you. This answers my question. I am using Linux, too.

________________________________________
From: arun [smartpink111 at yahoo.com]
Sent: Monday, 29 July 2013 11:11 PM
To: Dario Strbenac
Cc: R help
Subject: Re: [R] Declare BASH Array Using R System Function

Hi,
 system("names=(X Y); echo ${names[0]}")
#sh: 1: Syntax error: "(" unexpected


#this worked for me:
 system("bash -c 'names=(X Y); echo ${names[0]}'")
#X

A.K.



----- Original Message -----
From: Dario Strbenac <dstr7320 at uni.sydney.edu.au>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc:
Sent: Sunday, July 28, 2013 10:00 PM
Subject: [R] Declare BASH Array Using R System Function

Hello,

It is difficult searching for previous posts about this since the keywords are short and ambiguous, so I hope this is not a duplicate question.

I can easily declare an array on the command line.

$ names=(X Y)
$ echo ${names[0]}
X

I am unable to do the same from within R.

> system("names=(X Y)")
sh: Syntax error: "(" unexpected

Reading the documentation for the system function, it appears to only be relevant for executing commands. What can I do instead to declare a BASH array ? Thanks.

--------------------------------------
Dario Strbenac
PhD Student
University of Sydney
Camperdown NSW 2050
Australia

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.




From dwinsemius at comcast.net  Tue Jul 30 06:04:45 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Mon, 29 Jul 2013 21:04:45 -0700
Subject: [R] tm (text mining) package persistent storage
In-Reply-To: <CAB-sbgqyMzK0kMQXDBQ1gd+LFhRjxkBtzGi8xnPE1YpOLnhHrg@mail.gmail.com>
References: <CAB-sbgqyMzK0kMQXDBQ1gd+LFhRjxkBtzGi8xnPE1YpOLnhHrg@mail.gmail.com>
Message-ID: <E3ACB819-E945-4D4D-89A2-9BB5BBB56B74@comcast.net>


On Jul 29, 2013, at 4:47 PM, Ashwani Rao wrote:

> Hi,
> 
> My Corpus is bunch of xml files in a single directory.
> Each xml files have bunch of documents.
> I can create a persitent storage using PCorpus constructor  by specifying a
> DIrectorySource.
> PCorpus writes this as key-value data base.
> My problem is that next time when I want to start R then I want to read
> from this persistent storage created in my last session.
> I don't see a constructor/class in the tm package which will just take this
> persistent storage as input and initialize itself.

Identifying exactly what error you are making will require a copy of your history file leading up to saving and loading the data-objects in question.

-- 
David.
> 
> Currently, I always have to process my xml corpus directory with each new R
> session.
> 
> -- 
> Ashwin
> 
> 	[[alternative HTML version deleted]]

And do read the posting Guide. HTML is deprecated.

-- 

David Winsemius
Alameda, CA, USA


From jim at bitwrit.com.au  Tue Jul 30 06:10:47 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 30 Jul 2013 14:10:47 +1000
Subject: [R] triangular color plot of array
In-Reply-To: <182B9AEE07E5114BAB45E0689016C11313488C02@CO1PRD0112MB602.prod.exchangelabs.com>
References: <182B9AEE07E5114BAB45E0689016C11313488C02@CO1PRD0112MB602.prod.exchangelabs.com>
Message-ID: <51F73CC7.9040100@bitwrit.com.au>

On 07/30/2013 04:54 AM, White, William Patrick wrote:
> Hello,
> I've encountered an interesting situation and can't seem to find an applicable solution. I've got a multivariate synthetic dataset I generated in order to explore various statistical techniques. In my dataset I vary three things, sample size, effect size, and the number of variables that are affected. As these are varied I've output my results into a three dimensional array. So for each possible combination, think xyz location, I have an output value. What I would like to do is to create a somewhat unique style of plot very similar to a triangular soil texture plot, excepting that at rather than dropping a point at a given coordinate, I have all possible coordinates on the grid, and I would like to overlay a color map in which combinations that yield high values shade towards one color, and low values another or some other such color scheme. Thus displaying under what conditions certain accuracies are achieved for the test.
> I've explored both the soil texture plotting solutions in R, and as best I can with little background in image work the 3d plotting solutions offered by various packages. I haven't found anything that seems to be able to handle an array this way. I was wondering if anyone could point me in the right direction.
> P~
>
Hi William,
If you haven't looked at the triax.fill function in the plotrix package, 
that might be helpful. I'm not sure what resolution you want on the 
plot, but triax.fill will display colors down to a few pixels.

Jim


From dwarnold45 at suddenlink.net  Tue Jul 30 08:21:26 2013
From: dwarnold45 at suddenlink.net (David Arnold)
Date: Mon, 29 Jul 2013 23:21:26 -0700 (PDT)
Subject: [R] Dot plot similar to StatKey
Message-ID: <1375165286917-4672628.post@n4.nabble.com>

Hi,

I'd like to use R to produce the following plot:

dotplot.jpeg <http://r.789695.n4.nabble.com/file/n4672628/dotplot.jpeg>  

This was constructed using StatKey at:

http://www.lock5stat.com/statkey/bootstrap_1_quant/bootstrap_1_quant.html
<http://www.lock5stat.com/statkey/bootstrap_1_quant/bootstrap_1_quant.html>  

The data used was AtlantaCommute (Time) and I generated 1000 bootstrap
samples of size 500 with replacement. I'd really like to learn how to make
such a dotplot in R.

Any thoughts?

Thanks.



--
View this message in context: http://r.789695.n4.nabble.com/Dot-plot-similar-to-StatKey-tp4672628.html
Sent from the R help mailing list archive at Nabble.com.


From jim at bitwrit.com.au  Tue Jul 30 08:26:33 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Tue, 30 Jul 2013 16:26:33 +1000
Subject: [R] Dot plot similar to StatKey
In-Reply-To: <1375165286917-4672628.post@n4.nabble.com>
References: <1375165286917-4672628.post@n4.nabble.com>
Message-ID: <51F75C99.4020603@bitwrit.com.au>

On 07/30/2013 04:21 PM, David Arnold wrote:
> Hi,
>
> I'd like to use R to produce the following plot:
>
> dotplot.jpeg<http://r.789695.n4.nabble.com/file/n4672628/dotplot.jpeg>
>
> This was constructed using StatKey at:
>
> http://www.lock5stat.com/statkey/bootstrap_1_quant/bootstrap_1_quant.html
> <http://www.lock5stat.com/statkey/bootstrap_1_quant/bootstrap_1_quant.html>
>
> The data used was AtlantaCommute (Time) and I generated 1000 bootstrap
> samples of size 500 with replacement. I'd really like to learn how to make
> such a dotplot in R.
>
> Any thoughts?
>
Hi David,
Have a look at the dotplot.mtb function in plotrix.

Jim


From arne.henningsen at gmail.com  Tue Jul 30 11:08:10 2013
From: arne.henningsen at gmail.com (Arne Henningsen)
Date: Tue, 30 Jul 2013 11:08:10 +0200
Subject: [R] 2sls and systemfit
In-Reply-To: <104083AE5AAA634C993249DFCCE4C2030FE6B277@CIPRESTE.ua.pt>
References: <104083AE5AAA634C993249DFCCE4C2030FE6B277@CIPRESTE.ua.pt>
Message-ID: <CAMTWbJgAyMMugwe4V+Y5zL2bEjBMXA_UzeEc5Tvory84QpmA+Q@mail.gmail.com>

Dear Cecilla!

On 22 July 2013 14:08, Cecilia Carmo <cecilia.carmo at ua.pt> wrote:
> I have the following model:
> Cost of debt = intercept + information quality + control variable1
> + control variable2 + ? + error term
>
> I want to perform 2sls because I think I could have two situations:
> First: maybe information quality is correlated with the error term
> (because of omitted variables)
>
> Second: maybe information quality depends on the cost of debt like this:
> information quality = intercept + Cost of debt + control variable1 +
> control variable2 + ? + error term
>
> I have some variables (instruments) for information quality.
> Now I need to know how to use systemfit with this information
> in each of those situations.

The use of systemfit depends on the econometric model that you want to
estimate. In the first case, the following specification might be
suitable:

result1 <- systemfit( Cost_of_debt ~ intercept + information_quality +
control_variable1 + control_variable2, inst = ~ control_variable1 +
control_variable2 + instrument_variable1 + instrument_variable2,
method = "2SLS" )

Please note that you have to assume that the instrumental variables
(instrument_variable1 and instrument_variable2) do not influence the
cost of debt.

In the second case, you can only estimate the model if you have some
exclusion restrictions, i.e. at least one exogenous variable that does
not influence the cost of debt (e.g. instrument_variable1 and
instrument_variable2) and at least one exogenous variable that does
not influence the information quality (e.g. control_variable2). In
this case, the following specification might be suitable:

sys <- list( Cost_of_debt ~ intercept + information_quality +
control_variable1 + control_variable2, information_quality ~ intercept
+ Cost_of_debt + control_variable1 + instrument_variable1 +
instrument_variable2 )

result2 <- systemfit( sys, inst = ~ control_variable1 +
control_variable2 + instrument_variable1 + instrument_variable2,
method = "2SLS" )

You could also use the 3SLS method in this case.

Please do not forget to cite the systemfit package in your publications. Thanks!

Best regards,
Arne

-- 
Arne Henningsen
http://www.arne-henningsen.name


From harb at student.unimelb.edu.au  Tue Jul 30 11:33:15 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Tue, 30 Jul 2013 19:33:15 +1000
Subject: [R] Plot a series of plots without using a loop
Message-ID: <CAGYnQNS4UUu+Qa2-7cbBhVO_eLkziKGiq5s20nJNevSUhMgDqA@mail.gmail.com>

I have an xyf object from the kohonen package, and wish to plot a
lattice or grid or multiplot of a set of attributes of this object.

I've included the structure of the object below for reference, and
here is the set of plots I wish to produce, given in long-hand. I
don't know enough R to generalise this set of commands, can you help?
I am looking for a single command if possible.

op <- par(mfrow=c(2, 3))  # 6 plots in this case
plot(somdata.xyf,
     type="property",
     property=somdata.xyf$codes$X[, 1],
     main=colnames(somdata.xyf$codes$X)[1])

plot(somdata.xyf,
     type="property",
     property=somdata.xyf$codes$X[, 2],
     main=colnames(somdata.xyf$codes$X)[2])

... etc...

plot(somdata.xyf,
     type="property",
     property=somdata.xyf$codes$X[, 6],
     main=colnames(somdata.xyf$codes$X)[6])

par(op)

The "codes" list of the somdata.xyf object contains a further list "X"
containing the items I wish to plot. So the properties are
somdata.xyf$codes$X[, 1:6].

Here are some of the details (snipped for clarity):

> str(somdata.xyf)
List of 12
 $ data        : num [1:68, 1:6] -0.7509 -0.057 -1.5547 -0.4019 -0.0192 ...
... <snip>
 $ codes       :List of 2
  ..$ X: num [1:25, 1:6] -2.006 -0.817 -0.249 0.131 0.476 ...
  .. ..- attr(*, "dimnames")=List of 2
  .. .. ..$ : NULL
  .. .. ..$ : chr [1:6] "MEAS_TC" "SP" "LN" "SN" ...
  ..$ Y: num [1:25, 1] -2.006 -0.817 -0.249 0.131 0.476 ...
 $ changes     : num [1:500, 1:2] 0.1058 0.0954 0.1197 0.1085 0.1279 ...
... snip


> head(somdata.xyf$codes$X)
        MEAS_TC         SP         LN         SN         GR        NEUT
[1,] -2.0058516 -0.3207971 -0.2886428 -0.2645986 -0.3874740 -0.41095949
[2,] -0.8167927  0.1898585 -0.4094999 -0.3778524  0.3163603  0.05596098
[3,] -0.2492923 -0.8087226  0.4889264  0.2041352 -0.2634253 -0.27536594
[4,]  0.1309919  0.1330020  2.0283477  2.4009782 -0.5614304  0.82821634
[5,]  0.4764463 -0.1288688 -0.3767898 -0.3946008 -0.8674591 -0.19527494
[6,] -1.5912249  0.5690732 -0.2411219 -0.1630187 -0.4678983 -0.80916499

Ben
University of Melbourne


From ruipbarradas at sapo.pt  Tue Jul 30 13:35:33 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 30 Jul 2013 12:35:33 +0100
Subject: [R] Plot a series of plots without using a loop
In-Reply-To: <CAGYnQNS4UUu+Qa2-7cbBhVO_eLkziKGiq5s20nJNevSUhMgDqA@mail.gmail.com>
References: <CAGYnQNS4UUu+Qa2-7cbBhVO_eLkziKGiq5s20nJNevSUhMgDqA@mail.gmail.com>
Message-ID: <51F7A505.4050308@sapo.pt>

Hello,

Maybe the following does it.

op <- par(mfrow=c(2, 3))

for(i in 1:6){
	plot(somdata.xyf,
	     type="property",
	     property=somdata.xyf$codes$X[, i],
	     main=colnames(somdata.xyf$codes$X)[i])
}

par(op)


Hope this helps,

Rui Barradas

Em 30-07-2013 10:33, Ben Harrison escreveu:
> I have an xyf object from the kohonen package, and wish to plot a
> lattice or grid or multiplot of a set of attributes of this object.
>
> I've included the structure of the object below for reference, and
> here is the set of plots I wish to produce, given in long-hand. I
> don't know enough R to generalise this set of commands, can you help?
> I am looking for a single command if possible.
>
> op <- par(mfrow=c(2, 3))  # 6 plots in this case
> plot(somdata.xyf,
>       type="property",
>       property=somdata.xyf$codes$X[, 1],
>       main=colnames(somdata.xyf$codes$X)[1])
>
> plot(somdata.xyf,
>       type="property",
>       property=somdata.xyf$codes$X[, 2],
>       main=colnames(somdata.xyf$codes$X)[2])
>
> ... etc...
>
> plot(somdata.xyf,
>       type="property",
>       property=somdata.xyf$codes$X[, 6],
>       main=colnames(somdata.xyf$codes$X)[6])
>
> par(op)
>
> The "codes" list of the somdata.xyf object contains a further list "X"
> containing the items I wish to plot. So the properties are
> somdata.xyf$codes$X[, 1:6].
>
> Here are some of the details (snipped for clarity):
>
>> str(somdata.xyf)
> List of 12
>   $ data        : num [1:68, 1:6] -0.7509 -0.057 -1.5547 -0.4019 -0.0192 ...
> ... <snip>
>   $ codes       :List of 2
>    ..$ X: num [1:25, 1:6] -2.006 -0.817 -0.249 0.131 0.476 ...
>    .. ..- attr(*, "dimnames")=List of 2
>    .. .. ..$ : NULL
>    .. .. ..$ : chr [1:6] "MEAS_TC" "SP" "LN" "SN" ...
>    ..$ Y: num [1:25, 1] -2.006 -0.817 -0.249 0.131 0.476 ...
>   $ changes     : num [1:500, 1:2] 0.1058 0.0954 0.1197 0.1085 0.1279 ...
> ... snip
>
>
>> head(somdata.xyf$codes$X)
>          MEAS_TC         SP         LN         SN         GR        NEUT
> [1,] -2.0058516 -0.3207971 -0.2886428 -0.2645986 -0.3874740 -0.41095949
> [2,] -0.8167927  0.1898585 -0.4094999 -0.3778524  0.3163603  0.05596098
> [3,] -0.2492923 -0.8087226  0.4889264  0.2041352 -0.2634253 -0.27536594
> [4,]  0.1309919  0.1330020  2.0283477  2.4009782 -0.5614304  0.82821634
> [5,]  0.4764463 -0.1288688 -0.3767898 -0.3946008 -0.8674591 -0.19527494
> [6,] -1.5912249  0.5690732 -0.2411219 -0.1630187 -0.4678983 -0.80916499
>
> Ben
> University of Melbourne
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From motyocska at yahoo.com  Tue Jul 30 14:13:21 2013
From: motyocska at yahoo.com (Andras Farkas)
Date: Tue, 30 Jul 2013 05:13:21 -0700 (PDT)
Subject: [R] selection based on dates
Message-ID: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>

Dear All
?
please provide your insigths on the following: 
?
I have:
?
a <-c("1/1/13",15,20)
b <-c("1/5/13",15,25)
c <-c("1/9/13",15,28)
d <-c("2/1/13",18,30)
e <-c("2/5/13",18,35)
f <-c("2/9/13",18,38)
x <-matrix(c(a,b,c,d,e,f),ncol=3,byrow=TRUE)
?
What I would like to do is to eliminate certain rows of this matrix based on the date column values. As you can see, in the second column my values (15 and 18) repeat 3 times each, so this column serves as an ID number if you will. Thus each ID numbers show up with 3 different date values in the first column. Now I would like to eliminate the rows with the earliest date per ID number. My result should look like this:
?
z <-x[-c(1,4),]
?
as allways, your help is greatly appreciated,
?
thanks,
?
Andras


From smartpink111 at yahoo.com  Tue Jul 30 15:00:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 06:00:55 -0700 (PDT)
Subject: [R] selection based on dates
In-Reply-To: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
References: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
Message-ID: <1375189255.77549.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
If the rows are already ordered:
x1<- as.data.frame(x)
x[with(x1,ave(seq_along(V2),V2,FUN=function(x) !x%in%min(x)))==1,]
#???? [,1]???? [,2] [,3]
#[1,] "1/5/13" "15" "25"
#[2,] "1/9/13" "15" "28"
#[3,] "2/5/13" "18" "35"
#[4,] "2/9/13" "18" "38"

#otherwise
?x[with(x1,unlist(tapply(as.Date(V1,"%m/%d/%y"),list(V2),function(x) x!=min(x)),use.names=FALSE)),]
#???? [,1]???? [,2] [,3]
#[1,] "1/5/13" "15" "25"
#[2,] "1/9/13" "15" "28"
#[3,] "2/5/13" "18" "35"
#[4,] "2/9/13" "18" "38"


A.K.



----- Original Message -----
From: Andras Farkas <motyocska at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 30, 2013 8:13 AM
Subject: [R] selection based on dates

Dear All
?
please provide your insigths on the following: 
?
I have:
?
a <-c("1/1/13",15,20)
b <-c("1/5/13",15,25)
c <-c("1/9/13",15,28)
d <-c("2/1/13",18,30)
e <-c("2/5/13",18,35)
f <-c("2/9/13",18,38)
x <-matrix(c(a,b,c,d,e,f),ncol=3,byrow=TRUE)
?
What I would like to do is to eliminate certain rows of this matrix based on the date column values. As you can see, in the second column my values (15 and 18) repeat 3 times each, so this column serves as an ID number if you will. Thus each ID numbers show up with 3 different date values in the first column. Now I would like to eliminate the rows with the earliest date per ID number. My result should look like this:
?
z <-x[-c(1,4),]
?
as allways, your help is greatly appreciated,
?
thanks,
?
Andras

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From btupper at bigelow.org  Tue Jul 30 15:01:41 2013
From: btupper at bigelow.org (Ben Tupper)
Date: Tue, 30 Jul 2013 08:01:41 -0500
Subject: [R] selection based on dates
In-Reply-To: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
References: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
Message-ID: <FB328795-812E-4AE6-9329-064EB8570B7C@bigelow.org>


On Jul 30, 2013, at 7:13 AM, Andras Farkas wrote:

> Dear All
>  
> please provide your insigths on the following: 
>  
> I have:
>  
> a <-c("1/1/13",15,20)
> b <-c("1/5/13",15,25)
> c <-c("1/9/13",15,28)
> d <-c("2/1/13",18,30)
> e <-c("2/5/13",18,35)
> f <-c("2/9/13",18,38)
> x <-matrix(c(a,b,c,d,e,f),ncol=3,byrow=TRUE)
>  
> What I would like to do is to eliminate certain rows of this matrix based on the date column values. As you can see, in the second column my values (15 and 18) repeat 3 times each, so this column serves as an ID number if you will. Thus each ID numbers show up with 3 different date values in the first column. Now I would like to eliminate the rows with the earliest date per ID number. My result should look like this:
>  
> z <-x[-c(1,4),]
>  

Hi,

It is not clear to me that the result you show in z is what you describe in words.  On the other hand, I think the following will "eliminate the rows with the earliest date per ID number".

x <- structure(c("1/1/13", "1/5/13", "1/9/13", "2/1/13", "2/5/13", 
"2/9/13", "15", "15", "15", "18", "18", "18", "20", "25", "28", 
"30", "35", "38"), .Dim = c(6L, 3L))

ix <- duplicated(x[,2])

z <- x[ix,]

Is that what you are looking to achieve?  By the way, the solution is not based upon selecting by date as your subject message suggests.  Do you need to filter on dates instead?  If that is so, then you will need a different solution.

Regards,
Ben


> as allways, your help is greatly appreciated,
>  
> thanks,
>  
> Andras
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org


From S.Ellison at lgcgroup.com  Tue Jul 30 14:58:30 2013
From: S.Ellison at lgcgroup.com (S Ellison)
Date: Tue, 30 Jul 2013 13:58:30 +0100
Subject: [R] Dot plot similar to StatKey
In-Reply-To: <1375165286917-4672628.post@n4.nabble.com>
References: <1375165286917-4672628.post@n4.nabble.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACBD02124@GOLD.corp.lgc-group.com>

> I'd like to use R to produce the following plot:
> 
> dotplot.jpeg 
> <http://r.789695.n4.nabble.com/file/n4672628/dotplot.jpeg>  
> 

x<-rnorm(500)
xr <- round(x, 1)
stripchart(xr, method="stack", pch=19) 

will do this if the data are rounded appropriately. You may have some fun with 'appropriately'.

Tinker with ylim to get the axis limits right; stripchart's baseline is at 1 for a single group.

S Ellison
 



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From ruipbarradas at sapo.pt  Tue Jul 30 15:08:38 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 30 Jul 2013 14:08:38 +0100
Subject: [R] selection based on dates
In-Reply-To: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
References: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
Message-ID: <51F7BAD6.9020604@sapo.pt>

Hello,

Try the following.


idx <- which(c(TRUE, diff(as.integer(x[,2])) != 0))
x[-idx,]


Also, note that in constructs such as
a <-c("1/1/13",15,20)
both 15 and 20 are coerced to character. So your matrix is a matrix of 
chars. For different types of data, use data.frames

Hope this helps,

Rui Barradas

Em 30-07-2013 13:13, Andras Farkas escreveu:
> Dear All
>
> please provide your insigths on the following:
>
> I have:
>
> a <-c("1/1/13",15,20)
> b <-c("1/5/13",15,25)
> c <-c("1/9/13",15,28)
> d <-c("2/1/13",18,30)
> e <-c("2/5/13",18,35)
> f <-c("2/9/13",18,38)
> x <-matrix(c(a,b,c,d,e,f),ncol=3,byrow=TRUE)
>
> What I would like to do is to eliminate certain rows of this matrix based on the date column values. As you can see, in the second column my values (15 and 18) repeat 3 times each, so this column serves as an ID number if you will. Thus each ID numbers show up with 3 different date values in the first column. Now I would like to eliminate the rows with the earliest date per ID number. My result should look like this:
>
> z <-x[-c(1,4),]
>
> as allways, your help is greatly appreciated,
>
> thanks,
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Tue Jul 30 15:49:46 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 06:49:46 -0700 (PDT)
Subject: [R] selection based on dates
In-Reply-To: <51F7BAD6.9020604@sapo.pt>
References: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
	<51F7BAD6.9020604@sapo.pt>
Message-ID: <1375192186.14692.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Just a note:

If the dataset is not ordered, this could result in:

?set.seed(24)
?xNew<-x[sample(1:nrow(x),6,replace=FALSE),]
idxN<-which(c(TRUE,diff(as.integer(xNew[,2]))!=0))
?xNew[-idxN,]
#[1] "2/1/13" "18"???? "30"? 


xNew1<-xNew[order(xNew[,2],xNew[,1]),]
idx<-which(c(TRUE,diff(as.integer(xNew1[,2]))!=0))
?xNew1[-idx,]
#???? [,1]???? [,2] [,3]
#[1,] "1/5/13" "15" "25"
#[2,] "1/9/13" "15" "28"
#[3,] "2/5/13" "18" "35"
#[4,] "2/9/13" "18" "38"


#Same problem applies to my solution

? xNew2<- as.data.frame(xNew, stringsAsFactors=FALSE)
?xNew[with(xNew2,ave(as.numeric(as.Date(V1,"%m/%d/%y")),V2,FUN=function(x) !x%in% min(x)))!=0,] #keeps the original order of xNew
#???? [,1]???? [,2] [,3]
#[1,] "1/5/13" "15" "25"
#[2,] "2/9/13" "18" "38"
#[3,] "1/9/13" "15" "28"
#[4,] "2/5/13" "18" "35"


A.K.





----- Original Message -----
From: Rui Barradas <ruipbarradas at sapo.pt>
To: Andras Farkas <motyocska at yahoo.com>
Cc: "r-help at r-project.org" <r-help at r-project.org>
Sent: Tuesday, July 30, 2013 9:08 AM
Subject: Re: [R] selection based on dates

Hello,

Try the following.


idx <- which(c(TRUE, diff(as.integer(x[,2])) != 0))
x[-idx,]


Also, note that in constructs such as
a <-c("1/1/13",15,20)
both 15 and 20 are coerced to character. So your matrix is a matrix of 
chars. For different types of data, use data.frames

Hope this helps,

Rui Barradas

Em 30-07-2013 13:13, Andras Farkas escreveu:
> Dear All
>
> please provide your insigths on the following:
>
> I have:
>
> a <-c("1/1/13",15,20)
> b <-c("1/5/13",15,25)
> c <-c("1/9/13",15,28)
> d <-c("2/1/13",18,30)
> e <-c("2/5/13",18,35)
> f <-c("2/9/13",18,38)
> x <-matrix(c(a,b,c,d,e,f),ncol=3,byrow=TRUE)
>
> What I would like to do is to eliminate certain rows of this matrix based on the date column values. As you can see, in the second column my values (15 and 18) repeat 3 times each, so this column serves as an ID number if you will. Thus each ID numbers show up with 3 different date values in the first column. Now I would like to eliminate the rows with the earliest date per ID number. My result should look like this:
>
> z <-x[-c(1,4),]
>
> as allways, your help is greatly appreciated,
>
> thanks,
>
> Andras
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From dimitri.liakhovitski at gmail.com  Tue Jul 30 16:06:02 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 30 Jul 2013 10:06:02 -0400
Subject: [R] Select only rows that don't contain one number
Message-ID: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/4cf57b78/attachment.pl>

From dimitri.liakhovitski at gmail.com  Tue Jul 30 16:27:32 2013
From: dimitri.liakhovitski at gmail.com (Dimitri Liakhovitski)
Date: Tue, 30 Jul 2013 10:27:32 -0400
Subject: [R] Select only rows that don't contain one number
In-Reply-To: <CAJuU=iMemvXG95M_xdRd0wt8EMs+qdymDK8w2xWb-ZMdvvB-zg@mail.gmail.com>
References: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
	<CAJuU=iMemvXG95M_xdRd0wt8EMs+qdymDK8w2xWb-ZMdvvB-zg@mail.gmail.com>
Message-ID: <CAN2xGJYB2UUUwjvx1cr_KCfDhA-iGCjZqqt7WJy162dyUrDo4Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/03fb49cf/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 30 16:30:07 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 07:30:07 -0700 (PDT)
Subject: [R] Select only rows that don't contain one number
In-Reply-To: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
References: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
Message-ID: <1375194607.14454.YahooMailNeo@web142603.mail.bf1.yahoo.com>

x[rowSums(!x<0)==ncol(x),] #if you don't want x<0
#? a b c d e
#3 2 3 3 4 3
#5 4 5 5 6 4

#or
?x[rowSums(!x==-1)==ncol(x),]
#? a b c d e
#3 2 3 3 4 3
#5 4 5 5 6 4


A.K.




----- Original Message -----
From: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 30, 2013 10:06 AM
Subject: [R] Select only rows that don't contain one number

Hello!

I have a data frame:

x<-data.frame(a=c(-1,1,2,3,4),b=c(1,-1,3,4,5),c=1:5,d=2:6,e=c(1,2,3,-1,4))
x

How can I grab only those rows that don't contain any -1s (no matter in
what columns? Without writing a loop.
In other words, I want my output to contain only rows 3 and 5 of x.

Thank you very much!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From smartpink111 at yahoo.com  Tue Jul 30 16:40:56 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 07:40:56 -0700 (PDT)
Subject: [R] Select only rows that don't contain one number
In-Reply-To: <1375194607.14454.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
	<1375194607.14454.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <1375195256.28130.YahooMailNeo@web142603.mail.bf1.yahoo.com>

You could also use:
indx<-with(x,(1+2*(a!=-1)+4*(b!=-1)+8*(c!=-1)+16*(d!=-1)+32*(e!=-1)))
?x[indx==max(indx),]
#? a b c d e
#3 2 3 3 4 3
#5 4 5 5 6 4


#Speed comparisons:
set.seed(548)
x1<- as.data.frame(matrix(sample(c(-1,1:10),5*1e6,replace=TRUE),ncol=5))

system.time({
?index <- apply(x1, 1, function (x) { !(c(-1) %in% x)})
?res1<-x1[index, ]
})
# user? system elapsed 
# 11.252?? 0.028? 11.304 

system.time({res2<- x1[rowSums(!x1==-1)==ncol(x1),]})
# user? system elapsed 
#? 0.340?? 0.004?? 0.342 
identical(res1,res2)
#[1] TRUE

system.time({
indx<-with(x1,(1+2*(V1!=-1)+4*(V2!=-1)+8*(V3!=-1)+16*(V4!=-1)+32*(V5!=-1)))
res3<-x1[indx==max(indx),]
})
#? user? system elapsed 
#? 0.268?? 0.008?? 0.274 
?identical(res1,res3)
#[1] TRUE
A.K.




----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, July 30, 2013 10:30 AM
Subject: Re: [R] Select only rows that don't contain one number

x[rowSums(!x<0)==ncol(x),] #if you don't want x<0
#? a b c d e
#3 2 3 3 4 3
#5 4 5 5 6 4

#or
?x[rowSums(!x==-1)==ncol(x),]
#? a b c d e
#3 2 3 3 4 3
#5 4 5 5 6 4


A.K.




----- Original Message -----
From: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
To: r-help <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 30, 2013 10:06 AM
Subject: [R] Select only rows that don't contain one number

Hello!

I have a data frame:

x<-data.frame(a=c(-1,1,2,3,4),b=c(1,-1,3,4,5),c=1:5,d=2:6,e=c(1,2,3,-1,4))
x

How can I grab only those rows that don't contain any -1s (no matter in
what columns? Without writing a loop.
In other words, I want my output to contain only rows 3 and 5 of x.

Thank you very much!

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From gunter.berton at gene.com  Tue Jul 30 16:49:57 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Tue, 30 Jul 2013 07:49:57 -0700
Subject: [R] Select only rows that don't contain one number
In-Reply-To: <1375194607.14454.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
	<1375194607.14454.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CACk-te1nnaKYZXz+ZyEyGc0Y--Z-iwAa6aundffL-i6b_f+BZQ@mail.gmail.com>

or

x[ !rowSums(x == -1), ]

 if you are willing to tolerate the coercions and equality testing.

-- Bert

On Tue, Jul 30, 2013 at 7:30 AM, arun <smartpink111 at yahoo.com> wrote:
> x[rowSums(!x<0)==ncol(x),] #if you don't want x<0
> #  a b c d e
> #3 2 3 3 4 3
> #5 4 5 5 6 4
>
> #or
>  x[rowSums(!x==-1)==ncol(x),]
> #  a b c d e
> #3 2 3 3 4 3
> #5 4 5 5 6 4
>
>
> A.K.
>
>
>
>
> ----- Original Message -----
> From: Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>
> To: r-help <r-help at r-project.org>
> Cc:
> Sent: Tuesday, July 30, 2013 10:06 AM
> Subject: [R] Select only rows that don't contain one number
>
> Hello!
>
> I have a data frame:
>
> x<-data.frame(a=c(-1,1,2,3,4),b=c(1,-1,3,4,5),c=1:5,d=2:6,e=c(1,2,3,-1,4))
> x
>
> How can I grab only those rows that don't contain any -1s (no matter in
> what columns? Without writing a loop.
> In other words, I want my output to contain only rows 3 and 5 of x.
>
> Thank you very much!
>
>     [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From farhan at farhan.org  Tue Jul 30 15:11:30 2013
From: farhan at farhan.org (Farhan Ahmed)
Date: Tue, 30 Jul 2013 13:11:30 +0000
Subject: [R] selection based on dates
In-Reply-To: <1375186401.25521.YahooMailNeo@web140401.mail.bf1.yahoo.com>
Message-ID: <emd952b6bd-81bf-4f29-a5b9-fc2625aa3e6e@quasar>

  I'm still a novice at R, so this may be a bit convoluted but it works:

colnames(x) = c("date", "id", "value")
do.call(rbind, (dlply(as.data.frame(x), .(id), function (y) 
y[-c(which(as.Date(y$date, "%m/%d/%y") == min(as.Date(y$date, 
"%m/%d/%y")), arr.ind=T)),])))
- FA

------ Original Message ------
From: "Andras Farkas" <motyocska at yahoo.com>
To: "r-help at r-project.org" <r-help at r-project.org>
Sent: 7/30/2013 8:13:21 AM
Subject: [R] selection based on dates
>Dear All
>
>please provide your insigths on the following:
>
>I have:
>
>a <-c("1/1/13",15,20)
>b <-c("1/5/13",15,25)
>c <-c("1/9/13",15,28)
>d <-c("2/1/13",18,30)
>e <-c("2/5/13",18,35)
>f <-c("2/9/13",18,38)
>x <-matrix(c(a,b,c,d,e,f),ncol=3,byrow=TRUE)
>
>What I would like to do is to eliminate certain rows of this matrix 
>based on the date column values. As you can see, in the second column 
>my values (15 and 18) repeat 3 times each, so this column serves as an 
>ID number if you will. Thus each ID numbers show up with 3 different 
>date values in the first column. Now I would like to eliminate the rows 
>with the earliest date per ID number. My result should look like this:
>
>z <-x[-c(1,4),]
>
>as allways, your help is greatly appreciated,
>
>thanks,
>
>Andras
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From tbrowning700 at hotmail.com  Tue Jul 30 13:17:04 2013
From: tbrowning700 at hotmail.com (tbrowning700 at hotmail.com)
Date: Tue, 30 Jul 2013 12:17:04 +0100
Subject: [R] Interpolate irregularly spaced data without typical convex hull
Message-ID: <BLU0-SMTP137E8DE0B6F25F53ACF455D8A560@phx.gbl>

I have some irregularly spaced data points I want to interpolate (and ideally
extrapolate marginally beyond). I have been using Akima and predict surface
but this interpolates through the whole convex hull region. As this space
includes a large region where there are actually no data points I want to
curb the extent to which it does this.

Hopefully the following will make this somewhat more clear!

#load Akima library
library(akima)
#define data
x<-c(seq(1,10,by=1),c(4,2,2,9,8,6))
y<-c(seq(1,10,by=1),c(1,2,4,6,8,9))
z<-c(seq(1,16,by=1))
df<-as.data.frame(cbind(x,y))
colnames(df)<-c("x","y")
#perform tps interpolation
Tps(df,z)->out
#output surface data
out2<-predict.surface(out,extrap=F)
#plot
image(out2,xlim=c(0,10),ylim=c(0,10))
points(df)

I want to curb the interpolation are to something more like this (although a
bit smoother!)

df_poly<-cbind(c(4,5.5,5,1),c(5,6,9,6))
polygon(df_poly,col="white",border="white")
extrap and cull.mask in predict.surface seemed promising but could just not
get this to work?

Any help appreciated!
Cheers


From mohan.radhakrishnan at polarisft.com  Tue Jul 30 14:05:30 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Tue, 30 Jul 2013 17:35:30 +0530
Subject: [R] List of lists
Message-ID: <OF16CA59CA.50E23016-ON65257BB8.0041FCCB-65257BB8.00426597@polarisft.com>


Hi,
               I am creating a list of 2 lists, one containing filenames
and the other file descriptors.  When I retrieve them I am  unable to close
the file descriptor.

I am getting this error when I try to call close(filedescriptors
[[2]][[1]]).

Error in UseMethod("close") :
  no applicable method for 'close' applied to an object of class "c
('integer', 'numeric')"

print(filedescriptors[[2]][[1]]) seems to be printing individual elements.

Thanks,
Mohan

filelist.array <- function(n){
  cpufile <- list()
  cpufiledescriptors <- list()
  length(cpufile) <- n
  for (i in 1:n) {
    cpufile[[i]] <- paste("output", i, ".txt", sep = "")
	cpufiledescriptors[[i]]<-file( cpufile[[i]], "a" )
  }
    listoffiles <- list(cpufile=cpufile,
cpufiledescriptors=cpufiledescriptors)
	return (listoffiles)
}



#Test function

test.filelist.array <- function() {
	filedescriptors <- filelist.array(3)
    print(filedescriptors[[2]][[1]])
    print(filedescriptors[[2]][[2]])
    print(filedescriptors[[2]][[3]])

}



This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com


From lcmail4lists at gmail.com  Tue Jul 30 14:31:06 2013
From: lcmail4lists at gmail.com (=?ISO-8859-1?Q?L=EDvio?= Cipriano)
Date: Tue, 30 Jul 2013 13:31:06 +0100
Subject: [R] Time Series X labels
Message-ID: <1969822.QeFe3DcKt1@venus.lcipriano.pt>

Hi,

When we plot a Time Series object with a annual frequency, in the X axes 
usually appears mark ticks with an interval of 5 years. How can customize the 
X axes putting a tick for every year?

Regards

L?vio Cipriano


From lcmail4lists at gmail.com  Tue Jul 30 14:33:29 2013
From: lcmail4lists at gmail.com (=?ISO-8859-1?Q?L=EDvio?= Cipriano)
Date: Tue, 30 Jul 2013 13:33:29 +0100
Subject: [R] Time Series with daily frequency
Message-ID: <1495604.LKoUsnG6RQ@venus.lcipriano.pt>

Hi,

I tried to use the ts function to create a Time Series object with daily 
frequency but I couldn't. It's not possible or I'm not using the right 
parameters?

Regards

L?vio Cipriano


From dominic.roye at gmail.com  Tue Jul 30 15:41:46 2013
From: dominic.roye at gmail.com (Dominic Roye)
Date: Tue, 30 Jul 2013 15:41:46 +0200
Subject: [R] Reshape
Message-ID: <CALvVS-FV=dHdC-dAP9-7i3nr7CMbhUhtR9DjgwEpi=e97cUi4w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/5b3c0d5e/attachment.pl>

From farhan at farhan.org  Tue Jul 30 16:17:21 2013
From: farhan at farhan.org (Farhan Ahmed)
Date: Tue, 30 Jul 2013 14:17:21 +0000
Subject: [R] Select only rows that don't contain one number
In-Reply-To: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
Message-ID: <em4c239bff-0ef9-4a78-82be-082cdd3ee8aa@quasar>

  x[!apply(x, 1, function (y) any(y==-1)),]

------ Original Message ------
From: "Dimitri Liakhovitski" <dimitri.liakhovitski at gmail.com>
To: "r-help" <r-help at r-project.org>
Sent: 7/30/2013 10:06:02 AM
Subject: [R] Select only rows that don't contain one number
>Hello!
>
>I have a data frame:
>
>x<-data.frame(a=c(-1,1,2,3,4),b=c(1,-1,3,4,5),c=1:5,d=2:6,e=c(1,2,3,-1,4))
>x
>
>How can I grab only those rows that don't contain any -1s (no matter in
>what columns? Without writing a loop.
>In other words, I want my output to contain only rows 3 and 5 of x.
>
>Thank you very much!
>
>  [[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide 
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From midinac at eunet.rs  Tue Jul 30 16:18:01 2013
From: midinac at eunet.rs (Miroslav Stojadinovic)
Date: Tue, 30 Jul 2013 16:18:01 +0200
Subject: [R] reclassification table
Message-ID: <000801ce8d2f$bb471420$0a01a8c0@system>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/a460b0ce/attachment.pl>

From jmmateos at mce.hggm.es  Tue Jul 30 16:19:18 2013
From: jmmateos at mce.hggm.es (=?ISO-8859-1?Q?Jos=E9_Mar=EDa_Mateos?=)
Date: Tue, 30 Jul 2013 16:19:18 +0200
Subject: [R] Select only rows that don't contain one number
In-Reply-To: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
References: <CAN2xGJbY3wyWAYjVB4W7cYa5Kiz6tEMLOJpRCJ7Ms9A-2mW79A@mail.gmail.com>
Message-ID: <CAJuU=iMemvXG95M_xdRd0wt8EMs+qdymDK8w2xWb-ZMdvvB-zg@mail.gmail.com>

2013/7/30 Dimitri Liakhovitski <dimitri.liakhovitski at gmail.com>:
> How can I grab only those rows that don't contain any -1s (no matter in
> what columns? Without writing a loop.
> In other words, I want my output to contain only rows 3 and 5 of x.

index <- apply(x, 1, function (x) { !(c(-1) %in% x)})
x[index, ]
  a b c d e
3 2 3 3 4 3
5 4 5 5 6 4

Best,

Jos?.


From LanYing.Gu at cancercare.on.ca  Tue Jul 30 16:33:44 2013
From: LanYing.Gu at cancercare.on.ca (Gu, LanYing)
Date: Tue, 30 Jul 2013 14:33:44 +0000
Subject: [R] about R stat.table function
In-Reply-To: <035f01ce8ca0$d95b5320$8c11f960$@tamu.edu>
References: <798B772271F02B4097DA4A67176B0BBCC2B9A17C@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>
	<035f01ce8ca0$d95b5320$8c11f960$@tamu.edu>
Message-ID: <798B772271F02B4097DA4A67176B0BBCC2B9C29A@CCOPRD1EXMBX1.cco.ccods.cancercare.on.ca>

Hi David, Rui and Arun,

Thank you very much for your response, your email much help me to solve my problem. I installed library(Epi) into my R, I can use stat.table function in R now.

As a Biostatistician and researcher, I did some projects using R, but I used basic R. Even though I like R very much, my R is well, not very well. My SAS is excellent, I use SAS the most time, I'll take any opportunities to study and use R to improve my R skill from now on.

I'd like to say Thank you all of you for supporting R and making R such powerful, excellent and popular.

Thanks and Regards,

Lan





-----Original Message-----
From: David Carlson [mailto:dcarlson at tamu.edu]
Sent: Monday, July 29, 2013 5:16 PM
To: Gu, LanYing; r-help at r-project.org
Subject: RE: [R] about R stat.table function

Where did you find out about stat.table()? There is one in package Epi, but who knows if it is the one you are looking for? If you don't know about packages and the library() function, you need to work through a basic tutorial on R. You can't really expect to download a script file and run it without knowing anything about R.

The main webpage for R is at http://www.r-project.org/ The official documentation is at http://cran.r-project.org/manuals.html
User contributed manuals and tutorials in multiple languages at http://cran.r-project.org/other-docs.html
90 two minute R tutorials at http://www.twotorials.com/

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Gu, LanYing
Sent: Monday, July 29, 2013 2:24 PM
To: r-help at r-project.org
Subject: [R] about R stat.table function

Hi R Help group,

I try to use stat.table function in my R script, when I run stat.table in R. it shows that "No stat.function found", and I try to get help using "?stat.table" it shows that "No documentation for 'stat.table' in specified packages and
libraries:
you could try '??stat.table'".

it seems no "stat.table" function in my R. I want to know Do I need to install this function? From which website I could install this function? Could you please guide me how to do.

Many thanks,

Lan

________________________________


This e-mail message (and any attachments) may contain co...{{dropped:22}}


From jrkrideau at inbox.com  Tue Jul 30 17:28:56 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 30 Jul 2013 07:28:56 -0800
Subject: [R] Time Series with daily frequency
In-Reply-To: <1495604.LKoUsnG6RQ@venus.lcipriano.pt>
Message-ID: <B0D95BFBD5A.000001FBjrkrideau@inbox.com>

Who knows? You have not told us what you are actually doing.
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: lcmail4lists at gmail.com
> Sent: Tue, 30 Jul 2013 13:33:29 +0100
> To: r-help at r-project.org
> Subject: [R] Time Series with daily frequency
> 
> Hi,
> 
> I tried to use the ts function to create a Time Series object with daily
> frequency but I couldn't. It's not possible or I'm not using the right
> parameters?
> 
> Regards
> 
> L?vio Cipriano
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From jrkrideau at inbox.com  Tue Jul 30 17:30:00 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 30 Jul 2013 07:30:00 -0800
Subject: [R] Reshape
In-Reply-To: <CALvVS-FV=dHdC-dAP9-7i3nr7CMbhUhtR9DjgwEpi=e97cUi4w@mail.gmail.com>
Message-ID: <B0DBC38AF62.00000200jrkrideau@inbox.com>

https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dominic.roye at gmail.com
> Sent: Tue, 30 Jul 2013 15:41:46 +0200
> To: r-help at r-project.org
> Subject: [R] Reshape
> 
> Hello,
> 
> I try out to create a new form from the below data.frame.
> 
> I would like to have this form:
> 
> V3                 Santiago                  Ourense     Vigo    Ferrol
> 2013-07-04     2013-07-04 07:01:04 ......................................
> 
> How can i get this?
> 
>> str(sunrise)
> 'data.frame': 24 obs. of  3 variables:
>  $ day_frac: Factor w/ 4 levels "Ferrol","Ourense",..: 3 2 4 1 3 2 4 1 3
> 2
> ...
>  $ time    : POSIXct, format: "2013-07-04 07:01:04" ...
>  $ V3      : Factor w/ 6 levels "2013-07-04","2013-07-05",..: 1 1 1 1 2 2
> 2
> 2 3 3 ...
> 
>> sunrise
>    day_frac                time         V3
> 1  Santiago 2013-07-04 07:01:04 2013-07-04
> 2   Ourense 2013-07-04 07:00:05 2013-07-04
> 3      Vigo 2013-07-04 07:04:06 2013-07-04
> 4    Ferrol 2013-07-04 06:57:38 2013-07-04
> 5  Santiago 2013-07-05 07:01:41 2013-07-05
> 6   Ourense 2013-07-05 07:00:41 2013-07-05
> 7      Vigo 2013-07-05 07:04:42 2013-07-05
> 8    Ferrol 2013-07-05 06:58:16 2013-07-05
> 9  Santiago 2013-07-06 07:02:20 2013-07-06
> 10  Ourense 2013-07-06 07:01:19 2013-07-06
> 11     Vigo 2013-07-06 07:05:20 2013-07-06
> 12   Ferrol 2013-07-06 06:58:56 2013-07-06
> 
> 
> 
> 
> Thanks,
> 
> Regards
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From jrkrideau at inbox.com  Tue Jul 30 17:53:36 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 30 Jul 2013 07:53:36 -0800
Subject: [R] Dot plot similar to StatKey
In-Reply-To: <1375165286917-4672628.post@n4.nabble.com>
Message-ID: <B1107C6513A.00000276jrkrideau@inbox.com>

geom_dotplot() in the ggplot2 package perhaps?
ggplot(mtcars, aes(x = mpg)) + geom_dotplot()

John Kane
Kingston ON Canada


> -----Original Message-----
> From: dwarnold45 at suddenlink.net
> Sent: Mon, 29 Jul 2013 23:21:26 -0700 (PDT)
> To: r-help at r-project.org
> Subject: [R] Dot plot similar to StatKey
> 
> Hi,
> 
> I'd like to use R to produce the following plot:
> 
> dotplot.jpeg <http://r.789695.n4.nabble.com/file/n4672628/dotplot.jpeg>
> 
> This was constructed using StatKey at:
> 
> http://www.lock5stat.com/statkey/bootstrap_1_quant/bootstrap_1_quant.html
> <http://www.lock5stat.com/statkey/bootstrap_1_quant/bootstrap_1_quant.html>
> 
> The data used was AtlantaCommute (Time) and I generated 1000 bootstrap
> samples of size 500 with replacement. I'd really like to learn how to
> make
> such a dotplot in R.
> 
> Any thoughts?
> 
> Thanks.
> 
> 
> 
> --
> View this message in context:
> http://r.789695.n4.nabble.com/Dot-plot-similar-to-StatKey-tp4672628.html
> Sent from the R help mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
GET FREE SMILEYS FOR YOUR IM & EMAIL - Learn more at http://www.inbox.com/smileys
Works with AIM?, MSN? Messenger, Yahoo!? Messenger, ICQ?, Google Talk? and most webmails


From jrkrideau at inbox.com  Tue Jul 30 18:01:44 2013
From: jrkrideau at inbox.com (John Kane)
Date: Tue, 30 Jul 2013 08:01:44 -0800
Subject: [R] cross-correlation with R
In-Reply-To: <20130729222036.14878sc1d2mr2vf8@webmail.tu-freiberg.de>
Message-ID: <B122AB79F67.000002A3jrkrideau@inbox.com>

We need to know what you actually are doing before we can suggest anything.  Have a look at these links :
https://github.com/hadley/devtools/wiki/Reproducibility
 http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

John Kane
Kingston ON Canada


> -----Original Message-----
> From: weigelti at mailserver.tu-freiberg.de
> Sent: Mon, 29 Jul 2013 22:20:36 +0200
> To: r-help at r-project.org
> Subject: [R] cross-correlation with R
> 
> Dear R-User,
> 
> I'm Student at the TU Bergakademie Freiberg and have R used for the
> first time. I have created cross-correlations of air pressure, outside
> temperature, temperature laboratory and X-ray radiation intensity.
> However, I do not know how I interpret the graphs. Can someone help me?
> 
> best regards
> Tina Weigel
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D EARTH SCREENSAVER - Watch the Earth right on your desktop!


From smartpink111 at yahoo.com  Tue Jul 30 18:09:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 09:09:02 -0700 (PDT)
Subject: [R] Reshape
In-Reply-To: <CALvVS-FV=dHdC-dAP9-7i3nr7CMbhUhtR9DjgwEpi=e97cUi4w@mail.gmail.com>
References: <CALvVS-FV=dHdC-dAP9-7i3nr7CMbhUhtR9DjgwEpi=e97cUi4w@mail.gmail.com>
Message-ID: <1375200542.1969.YahooMailNeo@web142603.mail.bf1.yahoo.com>



Hi,

Please use ?dput() for the example data
sunrise<- structure(list(day_frac = c("Santiago", "Ourense", "Vigo", "Ferrol", 
"Santiago", "Ourense", "Vigo", "Ferrol", "Santiago", "Ourense", 
"Vigo", "Ferrol"), time = structure(c(1372935664, 1372935605, 
1372935846, 1372935458, 1373022101, 1373022041, 1373022282, 1373021896, 
1373108540, 1373108479, 1373108720, 1373108336), class = c("POSIXct", 
"POSIXt"), tzone = ""), V3 = c("2013-07-04", "2013-07-04", "2013-07-04", 
"2013-07-04", "2013-07-05", "2013-07-05", "2013-07-05", "2013-07-05", 
"2013-07-06", "2013-07-06", "2013-07-06", "2013-07-06")), .Names = c("day_frac", 
"time", "V3"), row.names = c("1", "2", "3", "4", "5", "6", "7", 
"8", "9", "10", "11", "12"), class = "data.frame")
library(reshape2)
res<-dcast(sunrise,V3~day_frac,value.var="time")
res
?# ??????? V3????????????? Ferrol???????????? Ourense??????????? Santiago
#1 2013-07-04 2013-07-04 06:57:38 2013-07-04 07:00:05 2013-07-04 07:01:04
#2 2013-07-05 2013-07-05 06:58:16 2013-07-05 07:00:41 2013-07-05 07:01:41
#3 2013-07-06 2013-07-06 06:58:56 2013-07-06 07:01:19 2013-07-06 07:02:20
?# ?????????????? Vigo
#1 2013-07-04 07:04:06
#2 2013-07-05 07:04:42
#3 2013-07-06 07:05:20
A.K.



----- Original Message -----
From: Dominic Roye <dominic.roye at gmail.com>
To: R help <r-help at r-project.org>
Cc: 
Sent: Tuesday, July 30, 2013 9:41 AM
Subject: [R] Reshape

Hello,

I try out to create a new form from the below data.frame.

I would like to have this form:

V3? ? ? ? ? ? ? ?  Santiago? ? ? ? ? ? ? ? ? Ourense? ?  Vigo? ? Ferrol
2013-07-04? ?  2013-07-04 07:01:04 ......................................

How can i get this?

> str(sunrise)
'data.frame': 24 obs. of? 3 variables:
$ day_frac: Factor w/ 4 levels "Ferrol","Ourense",..: 3 2 4 1 3 2 4 1 3 2
...
$ time? ? : POSIXct, format: "2013-07-04 07:01:04" ...
$ V3? ? ? : Factor w/ 6 levels "2013-07-04","2013-07-05",..: 1 1 1 1 2 2 2
2 3 3 ...

> sunrise
?  day_frac? ? ? ? ? ? ? ? time? ? ? ?  V3
1? Santiago 2013-07-04 07:01:04 2013-07-04
2?  Ourense 2013-07-04 07:00:05 2013-07-04
3? ? ? Vigo 2013-07-04 07:04:06 2013-07-04
4? ? Ferrol 2013-07-04 06:57:38 2013-07-04
5? Santiago 2013-07-05 07:01:41 2013-07-05
6?  Ourense 2013-07-05 07:00:41 2013-07-05
7? ? ? Vigo 2013-07-05 07:04:42 2013-07-05
8? ? Ferrol 2013-07-05 06:58:16 2013-07-05
9? Santiago 2013-07-06 07:02:20 2013-07-06
10? Ourense 2013-07-06 07:01:19 2013-07-06
11? ?  Vigo 2013-07-06 07:05:20 2013-07-06
12?  Ferrol 2013-07-06 06:58:56 2013-07-06




Thanks,

Regards

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From doggene at earthlink.net  Tue Jul 30 18:00:00 2013
From: doggene at earthlink.net (Liz Hare)
Date: Tue, 30 Jul 2013 12:00:00 -0400
Subject: [R] as.Date with characters error
Message-ID: <51F7E300.8040305@earthlink.net>

Hello,

I'm trying to convert dates in the format dd-mmm-yy using as.Date.
I have two columns like this, and it works on one but not on the other.

 > options(stringsAsFactors=FALSE)
 > ortho <- read.csv("test1.csv", header=TRUE, nrows=10)
 > ortho
    DogID BirthDate xray.date
1  11877 23-Aug-87 15-Feb-88
2  11877 23-Aug-87 15-Feb-88
3   3599 21-Feb-87 21-Feb-88
4   3599 21-Feb-87 21-Feb-88
5   3599 21-Feb-87 21-Feb-88
6   3599 21-Feb-87 21-Feb-88
7   3599 21-Feb-87 21-Feb-88
8   9563 29-Jun-87 29-Jun-88
9   9563 29-Jun-87 29-Jun-88
10  9563 29-Jun-87 29-Jun-88
 > ortho$bdat <- as.Date(ortho$BirthDate, format="%d-%b-%y")
 > ortho$bdat
  [1] "1987-08-23" "1987-08-23" "1987-02-21" "1987-02-21" "1987-02-21"
  [6] "1987-02-21" "1987-02-21" "1987-06-29" "1987-06-29" "1987-06-29"
 > ortho$test.dat <- as.Date(ortho$xray.date, formate="%d-%b-%y")
Error in charToDate(x) :
   character string is not in a standard unambiguous format
 > sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
 >

Does anyone have a guess about what's going on? I've googled for this 
error but haven't found any where the problem is with this type of 
conversion.

Thanks,
Liz

-- 
Liz Hare PhD
Dog Genetics LLC
doggene at earthlink.net
http://www.doggenetics.com


From basille.web at ase-research.org  Tue Jul 30 18:01:21 2013
From: basille.web at ase-research.org (Mathieu Basille)
Date: Tue, 30 Jul 2013 12:01:21 -0400
Subject: [R] 'format' behaviour in a 'apply' call depending on
 'options(digits = K)'
Message-ID: <51F7E351.9000209@ase-research.org>

Dear list,

Here is a simple example in which the behaviour of 'format' does not make 
sense to me. I have read the documentation and searched the archives, but 
nothing pointed me in the right direction to understand this behaviour. 
Let's start with a simple data frame:

df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)

Let's now create a new variable 'id2' which is the character representation 
of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers 
such as 100,000 are not formatted using their scientific representation (in 
this case 1e+05):

df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))

Let's have a look at part of the result:

df1$id2[99990:100010]
  [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"
  [8] "99997"  "99998"  "99999"  "100000" "100001" "100002" "100003"
[15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"

So far, so good. Let's now play with the 'digits' option:

options(digits = 4)
df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], scientific = FALSE))
df2$id2[99990:100010]
  [1] "99990"  "99991"  "99992"  "99993"  "99994"  " 99995" " 99996"
  [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
[15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"

Notice the extra leading space from 99995 to 99999? To make sure it only 
happened there:

df2$id2[which(df1$id2 != df2$id2)]
[1] " 99995" " 99996" " 99997" " 99998" " 99999"

And just to make sure it only occurs in a 'apply' call, here is the same 
directly on a numeric vector:

id2 <- format(1:110000, scientific = FALSE)
id2[99990:100010]
  [1] " 99990" " 99991" " 99992" " 99993" " 99994" " 99995" " 99996"
  [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
[15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"

Here the leading spaces are for every number, which makes sense to me. Is 
there anything I'm misinterpreting in the behaviour of 'format'?
Thanks in advance for any hint,
Mathieu.


PS: Some background for this question. It all comes from a Rmd document, 
that knitr consistently failed to process, while the R code was fine using 
batch or interactive R. knitr uses 'options(digits = 4)' as opposed to 
'options(digits = 7)' by default in R, which made one of my function throw 
an error with knitr, but not with batch or interactive R. I managed to 
solve the problem using 'trim = TRUE' in 'format', but I still do not 
understand what's going on...
If you're interested, see here for more details on the original problem: 
http://stackoverflow.com/questions/17866230/knitr-vs-interactive-r-behaviour/17872176


-- 

~$ whoami
Mathieu Basille, PhD

~$ locate --details
University of Florida \\
Fort Lauderdale Research and Education Center
(+1) 954-577-6314
http://ase-research.org/basille

~$ fortune
? Le tout est de tout dire, et je manque de mots
Et je manque de temps, et je manque d'audace. ?
  -- Paul ?luard


From pauljohn at ku.edu  Tue Jul 30 16:41:18 2013
From: pauljohn at ku.edu (Paul Johnson)
Date: Tue, 30 Jul 2013 09:41:18 -0500
Subject: [R] [R-pkgs] update: rockchalk 1.8.0
Message-ID: <51F7D08E.5090205@ku.edu>

This will appear on CRAN mirrors soon. It's my update for Spring, 2013. I keep
track of R problems that arise in the regression course and try to facilitate
them. There are functions for describing data, presenting regression plots and
tables, some regression diagnostics.

Most of the usages are illustrated in the vignette "rockchalk".  That has plenty
of illustrations if you care to take a quick look.

If you did not try this before, here is why you might want to. The function that
the package was organized around originally was plotSlopes: draw predicted value
lines on the same scatterplot. Now this is generalized a bit, the moderator
variable can be numeric or factor and I have bent over backwards to make this
flexible for the end users. If you run the examples for "predictOMatic" and
"plotSlopes" and "plotCurves," you will get the idea.

The rest is details.

I started a NEWS file using Emacs org mode, here it is:

* version 1.8

This is the end of the Spring semester, so its time for the new rockchalk
release.

** New, general, flexible framework for calculating marginal effects
   in regression models, linear or otherwise.

*** newdata function works. It can scan a regression, isolate the
   predictors, and then make a "mix and match" new data object for use
   with a predict function.  This is convenient for users but also very
   flexible.

*** The newdata framework is built on top of "divider" methods that can
    check whether a variable is numeric or categorical, and select
    example values according to user-specified criteria.

*** predictOMatic works dependably! Please try
    example(predictOMatic). The problem with single predictor models
    that bugged users of rockchalk 1.6.2 has been solved.

*** predictOMatic argument interval = c("none", "confidence",
    "prediction").  Guess what that is supposed to do? For glm,
    which does not provide a confidence interval, I've written code
    for an approximate Wald type CI, and hope to do better in future.

** Regression diagnostics.

*** getPartialCor: get partial correlations from a fitted model
(student convenience).

*** getDeltaRsquare: Returns the change in estimated R-square observed
    when each predictor is removed.  This is the squared semi-partial
    correlation coefficients (student convenience).

*** mcDiangose for multicollinearity diagnostics (student convenience)

** MeanCenter: add arguments to make selection of variables for
centering more convenient when users don't like the automatic
options centerOnlyInteractors.

** plotSlopes, plotCurves:
 *** Added intervals argument, for confidence and prediction intervals.

*** Added opacity argument to determine darkness of interval regions
    (which use the transparency "alpha layer.").

*** A lot of fiddling under the hood to make colors consistent when
    levels of modx are altered to compare plots of a given model.

*** Can produce a simple regression prediction plot if modx argument
    is omitted. This is a widely requested feature.

Please run example(plotSlopes) and example(plotCurves)

*** Changes under the hood. The common plotting functions of
    plotSlopes and plotCurves are abstracted into a function
    plotFancy, so now this will be eaiser for me to maintain. The
    plotting ritual is the same, why keep 2 functions, you ask?
    plotCurves tolerates more complicated regression
    formula. plotSlopes leads to testSlopes, and hence to
    plot.testSlopes.

** addLines: communication between 2 dimensional regression plots and 3
dimensional plots from plotPlane. Run example(addLines).

** plot.testSlopes. Run testSlopes on an interactive model. For a
model with 2 ocontinuous predictors that interact, this will generate
an ABSOLUTELY EXCELLENT and highly informative plot displaying the
effect of the interaction.

** outreg: LaTeX tables from regression models.

*** Reworked with new arguments to make tables for more types
of regressions. There's quite a bit more room for users to customize
the type of diagnostics they want to report.

The wide variety of output types from regression models is very
bothersome. I refuse to write a separate outreg method for each
different regression packages. If you want to use a package
from an author who is willing to do that, consider the "texreg"
package.

*** outreg2HTML. converts outreg to HTML markup and into a file.
Intended for importation into word processor programs.

** New vignette Rstyle. Most of the source-code files have been reformatted
to comply with my advice.

** genCorrelatedData2

*** genCorrelatedData2. For regression examples, suppose you want to
    have 6 columns of an MVN with a certain mean and covariance
    structure. And you want the regression formula to have
    interactions and squared-terms. No more hassle. This is a
    framework that works. Users set the mean, standard deviations, and
    correlation values in various ways. Run
    example(genCorrelatedData2).

*** To support that, there are more generally useful
    functions. lazyCor and lazyCov are flexible ways to create
    correlation and covariance matrices. As the names suggest, they
    are for lazy users who just want to specify some information and
    get the right thing.  This requires a set of transformation
    functions, to receive vech and create matrices, and so forth.
    Check genCorrelatedData.R, for vech2Corr, makeVec, makeSymmetric,
    checkPosDef. The latter, which I am surprised not to find in the
    base of R itself, imitates code in the MASS package for
    ascertaining if a matrix is positive definite.

*** Small, almost microscopic, revision of MASS package mvrnorm
    function to assure replication of MVN draws when the sample size
    is adjusted. The first rows of the resulting MVN draw will be the
    same, no matter how the "n" argument is changed. The same change
    has been made in the mvtnorm package's MVN random generator. While
    this is a very small code change, it does solve some very
    mysterious simulation results that have been obtained with MASS
    mvrnorm in our lab.


-- 
Paul E. Johnson			email: pauljohn at ku.edu
http://pj.freefaculty.org	Assoc. Director
Professor, Political Science 	Ctr for Research Methods & Data Analysis
1541 Lilac Lane, Rm 504		1425 Jayhawk Blvd.	
University of Kansas		Watson Library, Rm. 470  	
Lawrence, Kansas 66045-3129	Lawrence, Kansas 66045-7555
Ph: (785) 864-3523		Ph: (785) 864-3353

_______________________________________________
R-packages mailing list
R-packages at r-project.org
https://stat.ethz.ch/mailman/listinfo/r-packages


From smartpink111 at yahoo.com  Tue Jul 30 18:16:02 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 09:16:02 -0700 (PDT)
Subject: [R] as.Date with characters error
In-Reply-To: <51F7E300.8040305@earthlink.net>
References: <51F7E300.8040305@earthlink.net>
Message-ID: <1375200962.53878.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
Did you checked after removing "e" from "formate"?

ortho$test.dat <- as.Date(ortho$xray.date, formate="%d-%b-%y")
?
A.K.


----- Original Message -----
From: Liz Hare <doggene at earthlink.net>
To: r-help at r-project.org
Cc: 
Sent: Tuesday, July 30, 2013 12:00 PM
Subject: [R] as.Date with characters error

Hello,

I'm trying to convert dates in the format dd-mmm-yy using as.Date.
I have two columns like this, and it works on one but not on the other.

> options(stringsAsFactors=FALSE)
> ortho <- read.csv("test1.csv", header=TRUE, nrows=10)
> ortho
? ? DogID BirthDate xray.date
1? 11877 23-Aug-87 15-Feb-88
2? 11877 23-Aug-87 15-Feb-88
3?  3599 21-Feb-87 21-Feb-88
4?  3599 21-Feb-87 21-Feb-88
5?  3599 21-Feb-87 21-Feb-88
6?  3599 21-Feb-87 21-Feb-88
7?  3599 21-Feb-87 21-Feb-88
8?  9563 29-Jun-87 29-Jun-88
9?  9563 29-Jun-87 29-Jun-88
10? 9563 29-Jun-87 29-Jun-88
> ortho$bdat <- as.Date(ortho$BirthDate, format="%d-%b-%y")
> ortho$bdat
? [1] "1987-08-23" "1987-08-23" "1987-02-21" "1987-02-21" "1987-02-21"
? [6] "1987-02-21" "1987-02-21" "1987-06-29" "1987-06-29" "1987-06-29"
> ortho$test.dat <- as.Date(ortho$xray.date, formate="%d-%b-%y")
Error in charToDate(x) :
?  character string is not in a standard unambiguous format
> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats? ?  graphics? grDevices utils? ?  datasets? methods?  base
>

Does anyone have a guess about what's going on? I've googled for this 
error but haven't found any where the problem is with this type of 
conversion.

Thanks,
Liz

-- 
Liz Hare PhD
Dog Genetics LLC
doggene at earthlink.net
http://www.doggenetics.com

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From doggene at earthlink.net  Tue Jul 30 18:24:46 2013
From: doggene at earthlink.net (Liz Hare)
Date: Tue, 30 Jul 2013 12:24:46 -0400
Subject: [R] as.Date with characters error
In-Reply-To: <1375200962.53878.YahooMailNeo@web142605.mail.bf1.yahoo.com>
References: <51F7E300.8040305@earthlink.net>
	<1375200962.53878.YahooMailNeo@web142605.mail.bf1.yahoo.com>
Message-ID: <51F7E8CE.5050702@earthlink.net>

Oh! Thank you so much! Sorry to have bothered everyone with this!

Liz


On 7/30/2013 12:16 PM, arun wrote:
> Hi,
> Did you checked after removing "e" from "formate"?
>
> ortho$test.dat <- as.Date(ortho$xray.date, formate="%d-%b-%y")
>
> A.K.
>
>
> ----- Original Message -----
> From: Liz Hare <doggene at earthlink.net>
> To: r-help at r-project.org
> Cc:
> Sent: Tuesday, July 30, 2013 12:00 PM
> Subject: [R] as.Date with characters error
>
> Hello,
>
> I'm trying to convert dates in the format dd-mmm-yy using as.Date.
> I have two columns like this, and it works on one but not on the other.
>
>> options(stringsAsFactors=FALSE)
>> ortho <- read.csv("test1.csv", header=TRUE, nrows=10)
>> ortho
>      DogID BirthDate xray.date
> 1  11877 23-Aug-87 15-Feb-88
> 2  11877 23-Aug-87 15-Feb-88
> 3   3599 21-Feb-87 21-Feb-88
> 4   3599 21-Feb-87 21-Feb-88
> 5   3599 21-Feb-87 21-Feb-88
> 6   3599 21-Feb-87 21-Feb-88
> 7   3599 21-Feb-87 21-Feb-88
> 8   9563 29-Jun-87 29-Jun-88
> 9   9563 29-Jun-87 29-Jun-88
> 10  9563 29-Jun-87 29-Jun-88
>> ortho$bdat <- as.Date(ortho$BirthDate, format="%d-%b-%y")
>> ortho$bdat
>    [1] "1987-08-23" "1987-08-23" "1987-02-21" "1987-02-21" "1987-02-21"
>    [6] "1987-02-21" "1987-02-21" "1987-06-29" "1987-06-29" "1987-06-29"
>> ortho$test.dat <- as.Date(ortho$xray.date, formate="%d-%b-%y")
> Error in charToDate(x) :
>     character string is not in a standard unambiguous format
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>
> Does anyone have a guess about what's going on? I've googled for this
> error but haven't found any where the problem is with this type of
> conversion.
>
> Thanks,
> Liz
>


From charlie.hsia.us at gmail.com  Tue Jul 30 18:37:59 2013
From: charlie.hsia.us at gmail.com (c char)
Date: Tue, 30 Jul 2013 09:37:59 -0700
Subject: [R] Intersecting two matrices
In-Reply-To: <E66794E69CFDE04D9A70842786030B931C32AAFE@PA-MBX01.na.tibco.com>
References: <CAEOnvcHOjZzQADMJf=AAmf0LUswq_w7iB3Ohh2D0U_j15ds52A@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C32AAFE@PA-MBX01.na.tibco.com>
Message-ID: <CAEOnvcHw154E3--LJCQuPpRhVNDP3zNaZg0_n37JdBGvsm47Og@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/e7e76c7b/attachment.pl>

From ruipbarradas at sapo.pt  Tue Jul 30 18:50:08 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 30 Jul 2013 17:50:08 +0100
Subject: [R] Time Series with daily frequency
In-Reply-To: <1495604.LKoUsnG6RQ@venus.lcipriano.pt>
References: <1495604.LKoUsnG6RQ@venus.lcipriano.pt>
Message-ID: <51F7EEC0.2080209@sapo.pt>

Hello,

You should show us an example of what you're doing.
Anyway, there's an agument frequency to ?ts. Maybe you could set it 
frequency = 365.

Also, see packages zoo and xts for the creation of time series objects 
with real time stamps.

Hope this helps,

Rui Barradas

Em 30-07-2013 13:33, L?vio Cipriano escreveu:
> Hi,
>
> I tried to use the ts function to create a Time Series object with daily
> frequency but I couldn't. It's not possible or I'm not using the right
> parameters?
>
> Regards
>
> L?vio Cipriano
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Tue Jul 30 18:51:55 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Tue, 30 Jul 2013 17:51:55 +0100
Subject: [R] Time Series X labels
In-Reply-To: <1969822.QeFe3DcKt1@venus.lcipriano.pt>
References: <1969822.QeFe3DcKt1@venus.lcipriano.pt>
Message-ID: <51F7EF2B.2010203@sapo.pt>

Hello,

The standard way of customizing the x axis is

plot(..., xaxt = "n")
axis(1, at = where you want the ticks)

Hope this helps,

Rui Barradas

Em 30-07-2013 13:31, L?vio Cipriano escreveu:
> Hi,
>
> When we plot a Time Series object with a annual frequency, in the X axes
> usually appears mark ticks with an interval of 5 years. How can customize the
> X axes putting a tick for every year?
>
> Regards
>
> L?vio Cipriano
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil at dcn.davis.CA.us  Tue Jul 30 19:36:09 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Tue, 30 Jul 2013 10:36:09 -0700
Subject: [R] Intersecting two matrices
In-Reply-To: <CAEOnvcHw154E3--LJCQuPpRhVNDP3zNaZg0_n37JdBGvsm47Og@mail.gmail.com>
References: <CAEOnvcHOjZzQADMJf=AAmf0LUswq_w7iB3Ohh2D0U_j15ds52A@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C32AAFE@PA-MBX01.na.tibco.com>
	<CAEOnvcHw154E3--LJCQuPpRhVNDP3zNaZg0_n37JdBGvsm47Og@mail.gmail.com>
Message-ID: <c9ed6187-37a1-4f64-9e3c-81680e8f26b9@email.android.com>

In that case, you should be looking at a relational inner join, perhaps with SQLite (see package sqldf).
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

c char <charlie.hsia.us at gmail.com> wrote:
>Thanks a lot.
>Still looking for some super fast and memory efficient solution, as the
>matrix I have in real world has billions of rows.
>
>
>On Mon, Jul 29, 2013 at 6:24 PM, William Dunlap <wdunlap at tibco.com>
>wrote:
>
>> I haven't looked at the size-time relationship, but im2 (below) is
>faster
>> than your
>> function on at least one example:
>>
>> intersectMat <- function(mat1, mat2)
>> {
>>     #mat1 and mat2 are both deduplicated
>>     nr1 <- nrow(mat1)
>>     nr2 <- nrow(mat2)
>>     mat2[duplicated(rbind(mat1, mat2))[(nr1 + 1):(nr1 + nr2)], ,
>> drop=FALSE]
>> }
>>
>> im2 <- function(mat1, mat2)
>> {
>>     stopifnot(ncol(mat1)==2, ncol(mat1)==ncol(mat2))
>>     toChar <- function(twoColMat) paste(sep="\1", twoColMat[,1],
>> twoColMat[,2])
>>     mat1[match(toChar(mat2), toChar(mat1), nomatch=0), , drop=FALSE]
>> }
>>
>> > m1 <- cbind(1:1e7, rep(1:10, len=1e7))
>> > m2 <- cbind(1:1e7, rep(1:20, len=1e7))
>> > system.time(r1 <- intersectMat(m1,m2))
>>    user  system elapsed
>>  430.37    1.96  433.98
>> > system.time(r2 <- im2(m1,m2))
>>    user  system elapsed
>>   27.89    0.20   28.13
>> > identical(r1, r2)
>> [1] TRUE
>> > dim(r1)
>> [1] 5000000       2
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>>
>> > -----Original Message-----
>> > From: r-help-bounces at r-project.org
>[mailto:r-help-bounces at r-project.org]
>> On Behalf
>> > Of c char
>> > Sent: Monday, July 29, 2013 4:04 PM
>> > To: r-help at r-project.org
>> > Subject: [R] Intersecting two matrices
>> >
>> > Dear all,
>> >
>> > I am interested to know a faster matrix intersection package for R
>> handles
>> > intersection of two integer matrices with ncol=2. Currently I am
>using my
>> > homemade code adapted from a previous thread:
>> >
>> >
>> > intersectMat <- function(mat1, mat2){#mat1 and mat2 are both
>> > deduplicated  nr1 <- nrow(mat1)  nr2 <- nrow(mat2)
>> > mat2[duplicated(rbind(mat1, mat2))[(nr1 + 1):(nr1 + nr2)], ]}
>> >
>> >
>> > which handles:
>> > size A= 10578373
>> > size B= 9519807
>> > expected intersecting time= 251.2272
>> > intersecting for corssing MPRs took 409.602 seconds.
>> >
>> > scale a little bit worse than linearly but atomic operation is not
>good.
>> > Wonder if a super fast C/C++ extension exists for this task. Your
>ideas
>> are
>> > appreciated.
>> >
>> > Thanks!
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ross at biostat.ucsf.edu  Tue Jul 30 19:45:58 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Tue, 30 Jul 2013 10:45:58 -0700
Subject: [R] Error: Line starting ' ...' is malformed!
In-Reply-To: <5E1B812FAC2C4A49B3D99593B5A521914B65B8@PRDEXMBX-08.the-lab.llnl.gov>
References: <5E1B812FAC2C4A49B3D99593B5A521914B65B8@PRDEXMBX-08.the-lab.llnl.gov>
Message-ID: <201307301045.59146.ross@biostat.ucsf.edu>

On Monday, July 29, 2013 07:47:34 AM MacQueen, Don wrote:
> A recent version of the R extension manual says,
> 
> "For maximal portability, the ?DESCRIPTION? file should be written
> entirely in ASCII ? if this is not possible it must contain an ?Encoding?
> field (see below)."
> 
> It also says, regarding the DESCRIPTION file,
> 
> "Fields start with an ASCII name immediately followed by a colon: the
> value starts after the colon and a space."
That, plus the fact that all the other files were in plain ASCII, convinced me 
to recode DESCRIPTION to ASCII. Which solved the problem.

I guess, at least in this context, ASCII is considered an encoding as well as 
a character set.

Thanks.

Ross

P.S. For the record, I used recode on linux to do the conversion; iconv is 
another utility that would probably work.

> 
> >A DESCRIPTION file begins with 0xFFFE and
> >$ file DESCRIPTION
> >DESCRIPTION: Little-endian UTF-16 Unicode text, with CRLF, CR line
> >terminators
> >
> >I think it was created on Windows.
> >
> >In R (2,15,1 on Debian GNU/Linux), using roxygen2, I get
> >
> >> roxygenize("../GitHub/mice")
> >
> >Error: Line starting '??P ...' is malformed!
> >
> >Enter a frame number, or 0 to exit
> >
> >1: roxygenize("../GitHub/mice")
> >2: read.description(DESCRIPTION)
> >3: read.dcf(file)
> >
> >Selection: 3
> >Called from: read.description(DESCRIPTION)
> >Browse[1]> Q
> >
> >I'm not sure if the first 2 characters after line starting ', which are
> >octal
> >377, 376, will survive email; I stripped them out of the subject line.
> >
> >The files (DESCRIPTION isn't the only one) have also caused trouble for
> >git
> >(even on  Windows 7), since it thinks they are binary.
> >
> >Any advice about what to do?
> >
> >I'm reluctant to change the format of the files because it's not my
> >package.
> >
> >Ross Boylan
> >
> >______________________________________________
> >R-help at r-project.org mailing list
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Tue Jul 30 19:58:37 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 30 Jul 2013 10:58:37 -0700
Subject: [R] 'format' behaviour in a 'apply' call depending on
	'options(digits = K)'
In-Reply-To: <51F7E351.9000209@ase-research.org>
References: <51F7E351.9000209@ase-research.org>
Message-ID: <33B10231-D584-4B9E-A154-AFA793ECA3B6@comcast.net>


On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:

> Dear list,
> 
> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
> 
> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
> 
> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
> 
> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
> 
> Let's have a look at part of the result:
> 
> df1$id2[99990:100010]
> [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"
> [8] "99997"  "99998"  "99999"  "100000" "100001" "100002" "100003"
> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"

Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched

> df1$id2[99990:100010]
 [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"  "99997" 
 [9] "99998"  "99999"  "100000" "100001" "100002" "100003" "100004" "100005"
[17] "100006" "100007" "100008" "100009" "100010"

(I did notice that generation of the id2 variable seemed to take an inordinately long time.)

-- 
David.
> 
> So far, so good. Let's now play with the 'digits' option:
> 
> options(digits = 4)
> df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
> df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], scientific = FALSE))
> df2$id2[99990:100010]
> [1] "99990"  "99991"  "99992"  "99993"  "99994"  " 99995" " 99996"
> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
> 
> Notice the extra leading space from 99995 to 99999? To make sure it only happened there:
> 
> df2$id2[which(df1$id2 != df2$id2)]
> [1] " 99995" " 99996" " 99997" " 99998" " 99999"
> 
> And just to make sure it only occurs in a 'apply' call, here is the same directly on a numeric vector:
> 
> id2 <- format(1:110000, scientific = FALSE)
> id2[99990:100010]
> [1] " 99990" " 99991" " 99992" " 99993" " 99994" " 99995" " 99996"
> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
> 
> Here the leading spaces are for every number, which makes sense to me. Is there anything I'm misinterpreting in the behaviour of 'format'?
> Thanks in advance for any hint,
> Mathieu.
> 
> 
> PS: Some background for this question. It all comes from a Rmd document, that knitr consistently failed to process, while the R code was fine using batch or interactive R. knitr uses 'options(digits = 4)' as opposed to 'options(digits = 7)' by default in R, which made one of my function throw an error with knitr, but not with batch or interactive R. I managed to solve the problem using 'trim = TRUE' in 'format', but I still do not understand what's going on...
> If you're interested, see here for more details on the original problem: http://stackoverflow.com/questions/17866230/knitr-vs-interactive-r-behaviour/17872176
> 
> 
> -- 
> 
> ~$ whoami
> Mathieu Basille, PhD
> 
> ~$ locate --details
> University of Florida \\
> Fort Lauderdale Research and Education Center
> (+1) 954-577-6314
> http://ase-research.org/basille
> 
> ~$ fortune
> ? Le tout est de tout dire, et je manque de mots
> Et je manque de temps, et je manque d'audace. ?
> -- Paul ?luard
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA


From charlie.hsia.us at gmail.com  Tue Jul 30 20:02:48 2013
From: charlie.hsia.us at gmail.com (c char)
Date: Tue, 30 Jul 2013 11:02:48 -0700
Subject: [R] Intersecting two matrices
In-Reply-To: <c9ed6187-37a1-4f64-9e3c-81680e8f26b9@email.android.com>
References: <CAEOnvcHOjZzQADMJf=AAmf0LUswq_w7iB3Ohh2D0U_j15ds52A@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C32AAFE@PA-MBX01.na.tibco.com>
	<CAEOnvcHw154E3--LJCQuPpRhVNDP3zNaZg0_n37JdBGvsm47Og@mail.gmail.com>
	<c9ed6187-37a1-4f64-9e3c-81680e8f26b9@email.android.com>
Message-ID: <CAEOnvcEWOzSNcgL+Xde9Bw9j1F7i0E4ygq_Kv8cWy5OnGwSXtg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/412d4a20/attachment.pl>

From basille.web at ase-research.org  Tue Jul 30 20:07:30 2013
From: basille.web at ase-research.org (Mathieu Basille)
Date: Tue, 30 Jul 2013 14:07:30 -0400
Subject: [R] 'format' behaviour in a 'apply' call depending on
 'options(digits = K)'
In-Reply-To: <33B10231-D584-4B9E-A154-AFA793ECA3B6@comcast.net>
References: <51F7E351.9000209@ase-research.org>
	<33B10231-D584-4B9E-A154-AFA793ECA3B6@comcast.net>
Message-ID: <51F800E2.5040805@ase-research.org>

Thanks David for your interest. I have to admit that your answer puzzles me 
even more than before. It seems that the underlying problem is way beyond 
my R skills...

The generation of id2 is indeed quite demanding, especially compared to a 
simple 'as.character' call. Anyway, since it seems to be system specific, 
here is the sessionInfo() that I forgot to attach to my first message:

R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
  [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8
  [5] LC_MONETARY=fr_FR.UTF-8    LC_MESSAGES=fr_FR.UTF-8
  [7] LC_PAPER=C                 LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

In brief: last stable R available under Debian Testing... Hopefully this 
can help tracking down the problem.
Mathieu.


Le 07/30/2013 01:58 PM, David Winsemius a ?crit :
>
> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>
>> Dear list,
>>
>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>
>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>
>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>
>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>
>> Let's have a look at part of the result:
>>
>> df1$id2[99990:100010]
>> [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"
>> [8] "99997"  "99998"  "99999"  "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>
> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>
>> df1$id2[99990:100010]
>  [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"  "99997"
>  [9] "99998"  "99999"  "100000" "100001" "100002" "100003" "100004" "100005"
> [17] "100006" "100007" "100008" "100009" "100010"
>
> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>
> -- David.
>>
>> So far, so good. Let's now play with the 'digits' option:
>>
>> options(digits = 4)
>> df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>> df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>> df2$id2[99990:100010]
>> [1] "99990"  "99991"  "99992"  "99993"  "99994"  " 99995" " 99996"
>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Notice the extra leading space from 99995 to 99999? To make sure it only happened there:
>>
>> df2$id2[which(df1$id2 != df2$id2)]
>> [1] " 99995" " 99996" " 99997" " 99998" " 99999"
>>
>> And just to make sure it only occurs in a 'apply' call, here is the same directly on a numeric vector:
>>
>> id2 <- format(1:110000, scientific = FALSE)
>> id2[99990:100010]
>> [1] " 99990" " 99991" " 99992" " 99993" " 99994" " 99995" " 99996"
>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Here the leading spaces are for every number, which makes sense to me. Is there anything I'm misinterpreting in the behaviour of 'format'?
>> Thanks in advance for any hint,
>> Mathieu.
>>
>>
>> PS: Some background for this question. It all comes from a Rmd document, that knitr consistently failed to process, while the R code was fine using batch or interactive R. knitr uses 'options(digits = 4)' as opposed to 'options(digits = 7)' by default in R, which made one of my function throw an error with knitr, but not with batch or interactive R. I managed to solve the problem using 'trim = TRUE' in 'format', but I still do not understand what's going on...
>> If you're interested, see here for more details on the original problem: http://stackoverflow.com/questions/17866230/knitr-vs-interactive-r-behaviour/17872176
>>
>>
>> --
>>
>> ~$ whoami
>> Mathieu Basille, PhD
>>
>> ~$ locate --details
>> University of Florida \\
>> Fort Lauderdale Research and Education Center
>> (+1) 954-577-6314
>> http://ase-research.org/basille
>>
>> ~$ fortune
>> ? Le tout est de tout dire, et je manque de mots
>> Et je manque de temps, et je manque d'audace. ?
>> -- Paul ?luard
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>



>
> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>
>> Dear list,
>>
>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>
>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>
>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>
>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>
>> Let's have a look at part of the result:
>>
>> df1$id2[99990:100010]
>> [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"
>> [8] "99997"  "99998"  "99999"  "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>
> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>
>> df1$id2[99990:100010]
>   [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"  "99997"
>   [9] "99998"  "99999"  "100000" "100001" "100002" "100003" "100004" "100005"
> [17] "100006" "100007" "100008" "100009" "100010"
>
> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>


From S.Ellison at LGCGroup.com  Tue Jul 30 20:08:46 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Tue, 30 Jul 2013 19:08:46 +0100
Subject: [R] Dot plot similar to StatKey
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4ACBD02124@GOLD.corp.lgc-group.com>
References: <1375165286917-4672628.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED4ACBD02124@GOLD.corp.lgc-group.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACBD022A7@GOLD.corp.lgc-group.com>

 

I said:
> stripchart(xr, method="stack", pch=19) 

> will do this if the data are rounded appropriately. You may 
> have some fun with 'appropriately'.
> 

A bit of tinkering gives something that gets close to 'appropriate' (below); you may want to tinker with the tuning factor (or, of course, write something entirely different).

#
# Based on ?points: For 'pch' in '0:25' the default size is about
#          75% of the character height (see 'par("cin")')

round.pch<-function(x, tune=1.0) {
	#produces data rounded to approximate graphics symbol width
                is.window <- !is.null(dev.list()[1])
	if(is.window) {
		psize.ins <- 0.75 * par("cin")[2]/(2 * tune)
		psize.usr <- psize.ins*diff(par("usr")[1:2] / par("pin")[1])
	} else {
		psize.usr <- diff(range(pretty(x))) * 0.15 / (14 * tune)
		               #0.15 is the default par("cin")[2] * 0.75
	}
	return( psize.usr * (floor(x/psize.usr) + 0.5) ) 
}

set.seed(73)
x<-rnorm(500)
stripchart(round.pch(x), method="stack", pch=19, ylim=c(0.9,2))


round.pch above uses a vaguely reasonable default rounding with no graphics device present and will use the present device size and units if you have already called plot.new and set user coordinates. Odd things wll happen with a device open and no user coordinates set. Calling this repeatedly with no xlim set in stripchart will cause results to vary visibly as the user coordinates change slightly for each call.

*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From macrakis at alum.mit.edu  Tue Jul 30 20:10:31 2013
From: macrakis at alum.mit.edu (Stavros Macrakis)
Date: Tue, 30 Jul 2013 14:10:31 -0400
Subject: [R] xmlToDataFrame very slow
Message-ID: <CACLVabVXb2WeTwZ1x-dGE+15NpguFS-QthdjuRqkZQx+EPiPUg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/e68f87b9/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 30 20:15:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 11:15:43 -0700 (PDT)
Subject: [R] 'format' behaviour in a 'apply' call depending on
	'options(digits = K)'
In-Reply-To: <51F800E2.5040805@ase-research.org>
References: <51F7E351.9000209@ase-research.org>	<33B10231-D584-4B9E-A154-AFA793ECA3B6@comcast.net>
	<51F800E2.5040805@ase-research.org>
Message-ID: <1375208143.22952.YahooMailNeo@web142603.mail.bf1.yahoo.com>

Hi,
Try using trim=TRUE, in ?format()
options(digits=4)

df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
?df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], trim=TRUE,scientific = FALSE)) 
? df2$id2[99990:100010] 
# [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997" 
# [9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
#[17] "100006" "100007" "100008" "100009" "100010"


id2 <- format(1:110000, scientific = FALSE,trim=TRUE) 
id2[99990:100010]
# [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997" 
?#[9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
#[17] "100006" "100007" "100008" "100009" "100010"
A.K.


----- Original Message -----
From: Mathieu Basille <basille.web at ase-research.org>
To: David Winsemius <dwinsemius at comcast.net>
Cc: r-help at r-project.org
Sent: Tuesday, July 30, 2013 2:07 PM
Subject: Re: [R] 'format' behaviour in a 'apply' call depending on 'options(digits = K)'

Thanks David for your interest. I have to admit that your answer puzzles me 
even more than before. It seems that the underlying problem is way beyond 
my R skills...

The generation of id2 is indeed quite demanding, especially compared to a 
simple 'as.character' call. Anyway, since it seems to be system specific, 
here is the sessionInfo() that I forgot to attach to my first message:

R version 3.0.1 (2013-05-16)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
? [1] LC_CTYPE=fr_FR.UTF-8? ? ?  LC_NUMERIC=C
? [3] LC_TIME=fr_FR.UTF-8? ? ? ? LC_COLLATE=fr_FR.UTF-8
? [5] LC_MONETARY=fr_FR.UTF-8? ? LC_MESSAGES=fr_FR.UTF-8
? [7] LC_PAPER=C? ? ? ? ? ? ? ?  LC_NAME=C
? [9] LC_ADDRESS=C? ? ? ? ? ? ?  LC_TELEPHONE=C
[11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats? ?  graphics? grDevices utils? ?  datasets? methods?  base

In brief: last stable R available under Debian Testing... Hopefully this 
can help tracking down the problem.
Mathieu.


Le 07/30/2013 01:58 PM, David Winsemius a ?crit :
>
> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>
>> Dear list,
>>
>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>
>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>
>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>
>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>
>> Let's have a look at part of the result:
>>
>> df1$id2[99990:100010]
>> [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"
>> [8] "99997"? "99998"? "99999"? "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>
> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>
>> df1$id2[99990:100010]
>? [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997"
>? [9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
> [17] "100006" "100007" "100008" "100009" "100010"
>
> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>
> -- David.
>>
>> So far, so good. Let's now play with the 'digits' option:
>>
>> options(digits = 4)
>> df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>> df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>> df2$id2[99990:100010]
>> [1] "99990"? "99991"? "99992"? "99993"? "99994"? " 99995" " 99996"
>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Notice the extra leading space from 99995 to 99999? To make sure it only happened there:
>>
>> df2$id2[which(df1$id2 != df2$id2)]
>> [1] " 99995" " 99996" " 99997" " 99998" " 99999"
>>
>> And just to make sure it only occurs in a 'apply' call, here is the same directly on a numeric vector:
>>
>> id2 <- format(1:110000, scientific = FALSE)
>> id2[99990:100010]
>> [1] " 99990" " 99991" " 99992" " 99993" " 99994" " 99995" " 99996"
>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Here the leading spaces are for every number, which makes sense to me. Is there anything I'm misinterpreting in the behaviour of 'format'?
>> Thanks in advance for any hint,
>> Mathieu.
>>
>>
>> PS: Some background for this question. It all comes from a Rmd document, that knitr consistently failed to process, while the R code was fine using batch or interactive R. knitr uses 'options(digits = 4)' as opposed to 'options(digits = 7)' by default in R, which made one of my function throw an error with knitr, but not with batch or interactive R. I managed to solve the problem using 'trim = TRUE' in 'format', but I still do not understand what's going on...
>> If you're interested, see here for more details on the original problem: http://stackoverflow.com/questions/17866230/knitr-vs-interactive-r-behaviour/17872176
>>
>>
>> --
>>
>> ~$ whoami
>> Mathieu Basille, PhD
>>
>> ~$ locate --details
>> University of Florida \\
>> Fort Lauderdale Research and Education Center
>> (+1) 954-577-6314
>> http://ase-research.org/basille
>>
>> ~$ fortune
>> ? Le tout est de tout dire, et je manque de mots
>> Et je manque de temps, et je manque d'audace. ?
>> -- Paul ?luard
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>



>
> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>
>> Dear list,
>>
>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>
>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>
>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>
>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>
>> Let's have a look at part of the result:
>>
>> df1$id2[99990:100010]
>> [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"
>> [8] "99997"? "99998"? "99999"? "100000" "100001" "100002" "100003"
>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>
> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>
>> df1$id2[99990:100010]
>?  [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997"
>?  [9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
> [17] "100006" "100007" "100008" "100009" "100010"
>
> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From nouri4 at yahoo.com  Tue Jul 30 20:17:27 2013
From: nouri4 at yahoo.com (knouri)
Date: Tue, 30 Jul 2013 11:17:27 -0700 (PDT)
Subject: [R] MCMC with cumulative link models
Message-ID: <1375208247.21966.YahooMailNeo@web160102.mail.bf1.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/dbea6a71/attachment.pl>

From basille.web at ase-research.org  Tue Jul 30 20:29:01 2013
From: basille.web at ase-research.org (Mathieu Basille)
Date: Tue, 30 Jul 2013 14:29:01 -0400
Subject: [R] 'format' behaviour in a 'apply' call depending on
 'options(digits = K)'
In-Reply-To: <1375208143.22952.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <51F7E351.9000209@ase-research.org>	<33B10231-D584-4B9E-A154-AFA793ECA3B6@comcast.net>
	<51F800E2.5040805@ase-research.org>
	<1375208143.22952.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <51F805ED.5040407@ase-research.org>

Thanks Arun for your answer. 'trim = TRUE' does indeed solve the symptoms 
of the problem, and this is the solution I'm currently using. However, it 
does not help to understand what the problem is, and what is the cause of it.

Can you confirm that the original problem also occurs on your computer (and 
what is your OS)? It would be interesting since David is not able to 
reproduce the problem with Mac OS X.
Mathieu.


Le 07/30/2013 02:15 PM, arun a ?crit :
> Hi,
> Try using trim=TRUE, in ?format()
> options(digits=4)
>
> df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>   df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], trim=TRUE,scientific = FALSE))
>    df2$id2[99990:100010]
> # [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"  "99997"
> # [9] "99998"  "99999"  "100000" "100001" "100002" "100003" "100004" "100005"
> #[17] "100006" "100007" "100008" "100009" "100010"
>
>
> id2 <- format(1:110000, scientific = FALSE,trim=TRUE)
> id2[99990:100010]
> # [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"  "99997"
>   #[9] "99998"  "99999"  "100000" "100001" "100002" "100003" "100004" "100005"
> #[17] "100006" "100007" "100008" "100009" "100010"
> A.K.
>
>
> ----- Original Message -----
> From: Mathieu Basille <basille.web at ase-research.org>
> To: David Winsemius <dwinsemius at comcast.net>
> Cc: r-help at r-project.org
> Sent: Tuesday, July 30, 2013 2:07 PM
> Subject: Re: [R] 'format' behaviour in a 'apply' call depending on 'options(digits = K)'
>
> Thanks David for your interest. I have to admit that your answer puzzles me
> even more than before. It seems that the underlying problem is way beyond
> my R skills...
>
> The generation of id2 is indeed quite demanding, especially compared to a
> simple 'as.character' call. Anyway, since it seems to be system specific,
> here is the sessionInfo() that I forgot to attach to my first message:
>
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>    [1] LC_CTYPE=fr_FR.UTF-8       LC_NUMERIC=C
>    [3] LC_TIME=fr_FR.UTF-8        LC_COLLATE=fr_FR.UTF-8
>    [5] LC_MONETARY=fr_FR.UTF-8    LC_MESSAGES=fr_FR.UTF-8
>    [7] LC_PAPER=C                 LC_NAME=C
>    [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> In brief: last stable R available under Debian Testing... Hopefully this
> can help tracking down the problem.
> Mathieu.
>
>
> Le 07/30/2013 01:58 PM, David Winsemius a ?crit :
>>
>> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>>
>>> Dear list,
>>>
>>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>>
>>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>>
>>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>>
>>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>>
>>> Let's have a look at part of the result:
>>>
>>> df1$id2[99990:100010]
>>> [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"
>>> [8] "99997"  "99998"  "99999"  "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>>
>>> df1$id2[99990:100010]
>>    [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"  "99997"
>>    [9] "99998"  "99999"  "100000" "100001" "100002" "100003" "100004" "100005"
>> [17] "100006" "100007" "100008" "100009" "100010"
>>
>> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>>
>> -- David.
>>>
>>> So far, so good. Let's now play with the 'digits' option:
>>>
>>> options(digits = 4)
>>> df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>> df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>> df2$id2[99990:100010]
>>> [1] "99990"  "99991"  "99992"  "99993"  "99994"  " 99995" " 99996"
>>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>>
>>> Notice the extra leading space from 99995 to 99999? To make sure it only happened there:
>>>
>>> df2$id2[which(df1$id2 != df2$id2)]
>>> [1] " 99995" " 99996" " 99997" " 99998" " 99999"
>>>
>>> And just to make sure it only occurs in a 'apply' call, here is the same directly on a numeric vector:
>>>
>>> id2 <- format(1:110000, scientific = FALSE)
>>> id2[99990:100010]
>>> [1] " 99990" " 99991" " 99992" " 99993" " 99994" " 99995" " 99996"
>>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>>
>>> Here the leading spaces are for every number, which makes sense to me. Is there anything I'm misinterpreting in the behaviour of 'format'?
>>> Thanks in advance for any hint,
>>> Mathieu.
>>>
>>>
>>> PS: Some background for this question. It all comes from a Rmd document, that knitr consistently failed to process, while the R code was fine using batch or interactive R. knitr uses 'options(digits = 4)' as opposed to 'options(digits = 7)' by default in R, which made one of my function throw an error with knitr, but not with batch or interactive R. I managed to solve the problem using 'trim = TRUE' in 'format', but I still do not understand what's going on...
>>> If you're interested, see here for more details on the original problem: http://stackoverflow.com/questions/17866230/knitr-vs-interactive-r-behaviour/17872176
>>>
>>>
>>> --
>>>
>>> ~$ whoami
>>> Mathieu Basille, PhD
>>>
>>> ~$ locate --details
>>> University of Florida \\
>>> Fort Lauderdale Research and Education Center
>>> (+1) 954-577-6314
>>> http://ase-research.org/basille
>>>
>>> ~$ fortune
>>> ? Le tout est de tout dire, et je manque de mots
>>> Et je manque de temps, et je manque d'audace. ?
>>> -- Paul ?luard
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
>
>
>>
>> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>>
>>> Dear list,
>>>
>>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>>
>>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>>
>>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>>
>>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>>
>>> Let's have a look at part of the result:
>>>
>>> df1$id2[99990:100010]
>>> [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"
>>> [8] "99997"  "99998"  "99999"  "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>>
>>> df1$id2[99990:100010]
>>     [1] "99990"  "99991"  "99992"  "99993"  "99994"  "99995"  "99996"  "99997"
>>     [9] "99998"  "99999"  "100000" "100001" "100002" "100003" "100004" "100005"
>> [17] "100006" "100007" "100008" "100009" "100010"
>>
>> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 

~$ whoami
Mathieu Basille, PhD

~$ locate --details
University of Florida \\
Fort Lauderdale Research and Education Center
(+1) 954-577-6314
http://ase-research.org/basille

~$ fortune
? Le tout est de tout dire, et je manque de mots
Et je manque de temps, et je manque d'audace. ?
  -- Paul ?luard


From smartpink111 at yahoo.com  Tue Jul 30 20:34:25 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 11:34:25 -0700 (PDT)
Subject: [R] 'format' behaviour in a 'apply' call depending on
	'options(digits = K)'
In-Reply-To: <51F805ED.5040407@ase-research.org>
References: <51F7E351.9000209@ase-research.org>	<33B10231-D584-4B9E-A154-AFA793ECA3B6@comcast.net>
	<51F800E2.5040805@ase-research.org>
	<1375208143.22952.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<51F805ED.5040407@ase-research.org>
Message-ID: <1375209265.83596.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi Mathieu
yes, the original problem occurs in my system too. I am using R 3.0.1 on linux mint 15.? I guess the default case would be trim=FALSE, but still it looks very strange especially in ?apply(), as it starts from " 99995" onwards.

sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
?[1] LC_CTYPE=en_CA.UTF-8?????? LC_NUMERIC=C????????????? 
?[3] LC_TIME=en_CA.UTF-8??????? LC_COLLATE=en_CA.UTF-8??? 
?[5] LC_MONETARY=en_CA.UTF-8??? LC_MESSAGES=en_CA.UTF-8?? 
?[7] LC_PAPER=C???????????????? LC_NAME=C???????????????? 
?[9] LC_ADDRESS=C?????????????? LC_TELEPHONE=C??????????? 
[11] LC_MEASUREMENT=en_CA.UTF-8 LC_IDENTIFICATION=C?????? 

attached base packages:
[1] stats???? graphics? grDevices utils???? datasets? methods?? base???? 

other attached packages:
[1] stringr_0.6.2? reshape2_1.2.2

loaded via a namespace (and not attached):
[1] plyr_1.8??? tools_3.0.1








----- Original Message -----
From: Mathieu Basille <basille.web at ase-research.org>
To: arun <smartpink111 at yahoo.com>
Cc: R help <r-help at r-project.org>
Sent: Tuesday, July 30, 2013 2:29 PM
Subject: Re: [R] 'format' behaviour in a 'apply' call depending on 'options(digits = K)'

Thanks Arun for your answer. 'trim = TRUE' does indeed solve the symptoms 
of the problem, and this is the solution I'm currently using. However, it 
does not help to understand what the problem is, and what is the cause of it.

Can you confirm that the original problem also occurs on your computer (and 
what is your OS)? It would be interesting since David is not able to 
reproduce the problem with Mac OS X.
Mathieu.


Le 07/30/2013 02:15 PM, arun a ?crit :
> Hi,
> Try using trim=TRUE, in ?format()
> options(digits=4)
>
> df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>?  df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], trim=TRUE,scientific = FALSE))
>? ? df2$id2[99990:100010]
> # [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997"
> # [9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
> #[17] "100006" "100007" "100008" "100009" "100010"
>
>
> id2 <- format(1:110000, scientific = FALSE,trim=TRUE)
> id2[99990:100010]
> # [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997"
>?  #[9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
> #[17] "100006" "100007" "100008" "100009" "100010"
> A.K.
>
>
> ----- Original Message -----
> From: Mathieu Basille <basille.web at ase-research.org>
> To: David Winsemius <dwinsemius at comcast.net>
> Cc: r-help at r-project.org
> Sent: Tuesday, July 30, 2013 2:07 PM
> Subject: Re: [R] 'format' behaviour in a 'apply' call depending on 'options(digits = K)'
>
> Thanks David for your interest. I have to admit that your answer puzzles me
> even more than before. It seems that the underlying problem is way beyond
> my R skills...
>
> The generation of id2 is indeed quite demanding, especially compared to a
> simple 'as.character' call. Anyway, since it seems to be system specific,
> here is the sessionInfo() that I forgot to attach to my first message:
>
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>? ? [1] LC_CTYPE=fr_FR.UTF-8? ? ?  LC_NUMERIC=C
>? ? [3] LC_TIME=fr_FR.UTF-8? ? ? ? LC_COLLATE=fr_FR.UTF-8
>? ? [5] LC_MONETARY=fr_FR.UTF-8? ? LC_MESSAGES=fr_FR.UTF-8
>? ? [7] LC_PAPER=C? ? ? ? ? ? ? ?  LC_NAME=C
>? ? [9] LC_ADDRESS=C? ? ? ? ? ? ?  LC_TELEPHONE=C
> [11] LC_MEASUREMENT=fr_FR.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats? ?  graphics? grDevices utils? ?  datasets? methods?  base
>
> In brief: last stable R available under Debian Testing... Hopefully this
> can help tracking down the problem.
> Mathieu.
>
>
> Le 07/30/2013 01:58 PM, David Winsemius a ?crit :
>>
>> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>>
>>> Dear list,
>>>
>>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>>
>>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>>
>>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>>
>>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>>
>>> Let's have a look at part of the result:
>>>
>>> df1$id2[99990:100010]
>>> [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"
>>> [8] "99997"? "99998"? "99999"? "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>>
>>> df1$id2[99990:100010]
>>? ? [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997"
>>? ? [9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
>> [17] "100006" "100007" "100008" "100009" "100010"
>>
>> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>>
>> -- David.
>>>
>>> So far, so good. Let's now play with the 'digits' option:
>>>
>>> options(digits = 4)
>>> df2 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>> df2$id2 <- apply(df2, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>> df2$id2[99990:100010]
>>> [1] "99990"? "99991"? "99992"? "99993"? "99994"? " 99995" " 99996"
>>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>>
>>> Notice the extra leading space from 99995 to 99999? To make sure it only happened there:
>>>
>>> df2$id2[which(df1$id2 != df2$id2)]
>>> [1] " 99995" " 99996" " 99997" " 99998" " 99999"
>>>
>>> And just to make sure it only occurs in a 'apply' call, here is the same directly on a numeric vector:
>>>
>>> id2 <- format(1:110000, scientific = FALSE)
>>> id2[99990:100010]
>>> [1] " 99990" " 99991" " 99992" " 99993" " 99994" " 99995" " 99996"
>>> [8] " 99997" " 99998" " 99999" "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>>
>>> Here the leading spaces are for every number, which makes sense to me. Is there anything I'm misinterpreting in the behaviour of 'format'?
>>> Thanks in advance for any hint,
>>> Mathieu.
>>>
>>>
>>> PS: Some background for this question. It all comes from a Rmd document, that knitr consistently failed to process, while the R code was fine using batch or interactive R. knitr uses 'options(digits = 4)' as opposed to 'options(digits = 7)' by default in R, which made one of my function throw an error with knitr, but not with batch or interactive R. I managed to solve the problem using 'trim = TRUE' in 'format', but I still do not understand what's going on...
>>> If you're interested, see here for more details on the original problem: http://stackoverflow.com/questions/17866230/knitr-vs-interactive-r-behaviour/17872176
>>>
>>>
>>> --
>>>
>>> ~$ whoami
>>> Mathieu Basille, PhD
>>>
>>> ~$ locate --details
>>> University of Florida \\
>>> Fort Lauderdale Research and Education Center
>>> (+1) 954-577-6314
>>> http://ase-research.org/basille
>>>
>>> ~$ fortune
>>> ? Le tout est de tout dire, et je manque de mots
>>> Et je manque de temps, et je manque d'audace. ?
>>> -- Paul ?luard
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>
>> David Winsemius
>> Alameda, CA, USA
>>
>
>
>
>>
>> On Jul 30, 2013, at 9:01 AM, Mathieu Basille wrote:
>>
>>> Dear list,
>>>
>>> Here is a simple example in which the behaviour of 'format' does not make sense to me. I have read the documentation and searched the archives, but nothing pointed me in the right direction to understand this behaviour. Let's start with a simple data frame:
>>>
>>> df1 <- data.frame(x = rnorm(110000), y = rnorm(110000), id = 1:110000)
>>>
>>> Let's now create a new variable 'id2' which is the character representation of 'id'. Note that I use 'scientific = FALSE' to ensure that long numbers such as 100,000 are not formatted using their scientific representation (in this case 1e+05):
>>>
>>> df1$id2 <- apply(df1, 1, function(dfi) format(dfi["id"], scientific = FALSE))
>>>
>>> Let's have a look at part of the result:
>>>
>>> df1$id2[99990:100010]
>>> [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"
>>> [8] "99997"? "99998"? "99999"? "100000" "100001" "100002" "100003"
>>> [15] "100004" "100005" "100006" "100007" "100008" "100009" "100010"
>>
>> Some formating processes are carried out by system functions. In this case I am unable to reproduce with the same code on a Mac OS 10.7.5/R 3.0.1 Patched
>>
>>> df1$id2[99990:100010]
>>? ?  [1] "99990"? "99991"? "99992"? "99993"? "99994"? "99995"? "99996"? "99997"
>>? ?  [9] "99998"? "99999"? "100000" "100001" "100002" "100003" "100004" "100005"
>> [17] "100006" "100007" "100008" "100009" "100010"
>>
>> (I did notice that generation of the id2 variable seemed to take an inordinately long time.)
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

-- 

~$ whoami
Mathieu Basille, PhD

~$ locate --details
University of Florida \\
Fort Lauderdale Research and Education Center
(+1) 954-577-6314
http://ase-research.org/basille

~$ fortune
? Le tout est de tout dire, et je manque de mots
Et je manque de temps, et je manque d'audace. ?
? -- Paul ?luard



From rmh at temple.edu  Tue Jul 30 21:04:50 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Tue, 30 Jul 2013 15:04:50 -0400
Subject: [R] Dot plot similar to StatKey
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED4ACBD022A7@GOLD.corp.lgc-group.com>
References: <1375165286917-4672628.post@n4.nabble.com>
	<A4E5A0B016B8CB41A485FC629B633CED4ACBD02124@GOLD.corp.lgc-group.com>
	<A4E5A0B016B8CB41A485FC629B633CED4ACBD022A7@GOLD.corp.lgc-group.com>
Message-ID: <CAGx1TMAFgK_LGoCyXXT+LbR4qvCxOmS+f1vRAeopAxc9WT-kCQ@mail.gmail.com>

I would use panel.dotplot.tb from the HH package.
It is based on lattice, hence will plot multiple groups on the same scale.

continuing with S Ellison's example

## install.packages("HH") ## if necessary
library(HH)
rpx <- round.pch(x)
dotplot( ~ rpx, panel=panel.dotplot.tb, ylim=c(.98, 1.15))
dotplot( ~ rpx | factor(rep(1:2, each=250)), panel=panel.dotplot.tb,
layout=c(1,2), ylim=c(.98, 1.15))

Rich


 On 7/30/13, S Ellison <S.Ellison at lgcgroup.com> wrote:
>
>
> I said:
>> stripchart(xr, method="stack", pch=19)
>
>> will do this if the data are rounded appropriately. You may
>> have some fun with 'appropriately'.
>>
>
> A bit of tinkering gives something that gets close to 'appropriate' (below);
> you may want to tinker with the tuning factor (or, of course, write
> something entirely different).
>
> #
> # Based on ?points: For 'pch' in '0:25' the default size is about
> #          75% of the character height (see 'par("cin")')
>
> round.pch<-function(x, tune=1.0) {
> 	#produces data rounded to approximate graphics symbol width
>                 is.window <- !is.null(dev.list()[1])
> 	if(is.window) {
> 		psize.ins <- 0.75 * par("cin")[2]/(2 * tune)
> 		psize.usr <- psize.ins*diff(par("usr")[1:2] / par("pin")[1])
> 	} else {
> 		psize.usr <- diff(range(pretty(x))) * 0.15 / (14 * tune)
> 		               #0.15 is the default par("cin")[2] * 0.75
> 	}
> 	return( psize.usr * (floor(x/psize.usr) + 0.5) )
> }
>
> set.seed(73)
> x<-rnorm(500)
> stripchart(round.pch(x), method="stack", pch=19, ylim=c(0.9,2))
>
>
> round.pch above uses a vaguely reasonable default rounding with no graphics
> device present and will use the present device size and units if you have
> already called plot.new and set user coordinates. Odd things wll happen with
> a device open and no user coordinates set. Calling this repeatedly with no
> xlim set in stripchart will cause results to vary visibly as the user
> coordinates change slightly for each call.
>
> *******************************************************************
> This email and any attachments are confidential. Any use...{{dropped:8}}
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From lcmail4lists at gmail.com  Tue Jul 30 21:06:46 2013
From: lcmail4lists at gmail.com (=?ISO-8859-1?Q?L=EDvio?= Cipriano)
Date: Tue, 30 Jul 2013 20:06:46 +0100
Subject: [R] Time Series with daily frequency
In-Reply-To: <51F7EEC0.2080209@sapo.pt>
References: <1495604.LKoUsnG6RQ@venus.lcipriano.pt> <51F7EEC0.2080209@sapo.pt>
Message-ID: <3266664.M9mVvv6B42@venus.lcipriano.pt>

On 30 July 2013 17:50:08 Rui Barradas wrote:
> Maybe you could set it 
> frequency = 365.

No. It didn't worked. Was my first trial.

> 
> Also, see packages zoo and xts for the creation of time series objects 
> with real time stamps.

I'll look in to them.

Regards

L?vio Cipriano


From leegi001 at umn.edu  Tue Jul 30 22:02:08 2013
From: leegi001 at umn.edu (Cathy Lee Gierke)
Date: Tue, 30 Jul 2013 15:02:08 -0500
Subject: [R] acf and ccf
Message-ID: <CAOeg=__7PhriLu57qWeCjcDnMdVG8K44FnbRVcZ5wHKHDeQOSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/5e0f0c33/attachment.pl>

From smartpink111 at yahoo.com  Tue Jul 30 22:28:00 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 13:28:00 -0700 (PDT)
Subject: [R] acf and ccf
In-Reply-To: <CAOeg=__7PhriLu57qWeCjcDnMdVG8K44FnbRVcZ5wHKHDeQOSA@mail.gmail.com>
References: <CAOeg=__7PhriLu57qWeCjcDnMdVG8K44FnbRVcZ5wHKHDeQOSA@mail.gmail.com>
Message-ID: <1375216080.94867.YahooMailNeo@web142601.mail.bf1.yahoo.com>

Just type 
acf 
ccf
on R prompt
A.K.





----- Original Message -----
From: Cathy Lee Gierke <leegi001 at umn.edu>
To: r-help at r-project.org; r-core-owner at r-project.org
Cc: 
Sent: Tuesday, July 30, 2013 4:02 PM
Subject: [R] acf and ccf

Greetings,

Is it possible to see the source code for the acf and ccf functions?? I
want to understand the exact formula used.

It may be in this book, but I am hoping I can find it elsewhere, as the
book is quite expensive.
Venables, W. N. and Ripley, B. D. (2002) *Modern Applied Statistics with S*.
Fourth Edition. Springer-Verlag.


Sincere thanks,
Cathy Lee Gierke

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From jim at bitwrit.com.au  Tue Jul 30 23:02:06 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 31 Jul 2013 07:02:06 +1000
Subject: [R] Reshape
In-Reply-To: <CALvVS-FV=dHdC-dAP9-7i3nr7CMbhUhtR9DjgwEpi=e97cUi4w@mail.gmail.com>
References: <CALvVS-FV=dHdC-dAP9-7i3nr7CMbhUhtR9DjgwEpi=e97cUi4w@mail.gmail.com>
Message-ID: <51F829CE.8090908@bitwrit.com.au>

On 07/30/2013 11:41 PM, Dominic Roye wrote:
> Hello,
>
> I try out to create a new form from the below data.frame.
>
> I would like to have this form:
>
> V3                 Santiago                  Ourense     Vigo    Ferrol
> 2013-07-04     2013-07-04 07:01:04 ......................................
>
> How can i get this?
>
>> str(sunrise)
> 'data.frame': 24 obs. of  3 variables:
>   $ day_frac: Factor w/ 4 levels "Ferrol","Ourense",..: 3 2 4 1 3 2 4 1 3 2
> ...
>   $ time    : POSIXct, format: "2013-07-04 07:01:04" ...
>   $ V3      : Factor w/ 6 levels "2013-07-04","2013-07-05",..: 1 1 1 1 2 2 2
> 2 3 3 ...
>
>> sunrise
>     day_frac                time         V3
> 1  Santiago 2013-07-04 07:01:04 2013-07-04
> 2   Ourense 2013-07-04 07:00:05 2013-07-04
> 3      Vigo 2013-07-04 07:04:06 2013-07-04
> 4    Ferrol 2013-07-04 06:57:38 2013-07-04
> 5  Santiago 2013-07-05 07:01:41 2013-07-05
> 6   Ourense 2013-07-05 07:00:41 2013-07-05
> 7      Vigo 2013-07-05 07:04:42 2013-07-05
> 8    Ferrol 2013-07-05 06:58:16 2013-07-05
> 9  Santiago 2013-07-06 07:02:20 2013-07-06
> 10  Ourense 2013-07-06 07:01:19 2013-07-06
> 11     Vigo 2013-07-06 07:05:20 2013-07-06
> 12   Ferrol 2013-07-06 06:58:56 2013-07-06

Hi Dominic,
Try this:

library(prettyR)
sunrise_wide<-stretch_df(sunrise,idvar="V3",to.stretch="time",
  ordervar="day_frac",include.ordervar=FALSE)
names(sunrise_wide)<-c("V3","Ferrol","Ourense","Santiago","Vigo")
sunrise_wide

Jim


From smartpink111 at yahoo.com  Tue Jul 30 23:15:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 14:15:15 -0700 (PDT)
Subject: [R] acf and ccf
In-Reply-To: <CAOeg=_8ZEmpZdXu0-Rx_CaoxdzfmonkeOYHPMeHfY+0asX4Lpg@mail.gmail.com>
References: <CAOeg=__7PhriLu57qWeCjcDnMdVG8K44FnbRVcZ5wHKHDeQOSA@mail.gmail.com>
	<1375216080.94867.YahooMailNeo@web142601.mail.bf1.yahoo.com>
	<CAOeg=_9JK=AZ1VGFUnn5xoCxfjGSW88b525L_COcWSmG7HND4g@mail.gmail.com>
	<1375217832.88539.YahooMailNeo@web142605.mail.bf1.yahoo.com>
	<CAOeg=_8ZEmpZdXu0-Rx_CaoxdzfmonkeOYHPMeHfY+0asX4Lpg@mail.gmail.com>
Message-ID: <1375218915.84202.YahooMailNeo@web142603.mail.bf1.yahoo.com>

I use R 3.0.1.

#I do have that line after? ` lag[lower.tri(lag)] <- -1`

?acf <- .Call(C_acf, x, lag.max, type == "correlation")
??? lag <- outer(0:lag.max, lag/x.freq)
??? acf.out <- structure(list(acf = acf, type = type, n.used = sampleT, 
??????? lag = lag, series = series, snames = colnames(x)), class = "acf")


Check this link:
http://stackoverflow.com/questions/14035506/how-to-see-the-source-code-of-r-internal-or-primitive-function

A.K.

________________________________
From: Cathy Lee Gierke <leegi001 at umn.edu>
To: arun <smartpink111 at yahoo.com> 
Sent: Tuesday, July 30, 2013 5:04 PM
Subject: Re: [R] acf and ccf



You must have a different version of R? ?But you do have a line: ???? acf <- .Call(C_acf, x, lag.max, type == "correlation")
That is quite similar. ?It is a call to a function that does the actual math.


Here is what I get:

function (x, lag.max = NULL, type = c("correlation", "covariance",?
? ? "partial"), plot = TRUE, na.action = na.fail, demean = TRUE,?
? ? ...)?
{
? ? type <- match.arg(type)
? ? if (type == "partial") {
? ? ? ? m <- match.call()
? ? ? ? m[[1L]] <- as.name("pacf")
? ? ? ? m$type <- NULL
? ? ? ? return(eval(m, parent.frame()))
? ? }
? ? series <- deparse(substitute(x))
? ? x <- na.action(as.ts(x))
? ? x.freq <- frequency(x)
? ? x <- as.matrix(x)
? ? if (!is.numeric(x))?
? ? ? ? stop("'x' must be numeric")
? ? sampleT <- as.integer(nrow(x))
? ? nser <- as.integer(ncol(x))
? ? if (is.na(sampleT) || is.na(nser))?
? ? ? ? stop("sampleT and nser must be ints", domain = NA)
? ? if (is.null(lag.max))?
? ? ? ? lag.max <- floor(10 * (log10(sampleT) - log10(nser)))
? ? lag.max <- as.integer(min(lag.max, sampleT - 1L))
? ? if (is.na(lag.max) || lag.max < 0)?
? ? ? ? stop("'lag.max' must be at least 0")
? ? if (demean)?
? ? ? ? x <- sweep(x, 2, colMeans(x, na.rm = TRUE), check.margin = FALSE)
? ? lag <- matrix(1, nser, nser)
? ? lag[lower.tri(lag)] <- -1
? ? acf <- array(.C(C_acf, as.double(x), sampleT, nser, lag.max,?
? ? ? ? as.integer(type == "correlation"), acf = double((lag.max +?
? ? ? ? ? ? 1L) * nser * nser), NAOK = TRUE)$acf, c(lag.max +?
? ? ? ? 1L, nser, nser))
? ? lag <- outer(0:lag.max, lag/x.freq)
? ? acf.out <- structure(.Data = list(acf = acf, type = type,?
? ? ? ? n.used = sampleT, lag = lag, series = series, snames = colnames(x)),?
? ? ? ? class = "acf")
? ? if (plot) {
? ? ? ? plot.acf(acf.out, ...)
? ? ? ? return(invisible(acf.out))
? ? }
? ? else return(acf.out)
}
<bytecode: 0x7f8e04f34ea8>
<environment: namespace:stats>


Cathy Lee Gierke


On Tue, Jul 30, 2013 at 3:57 PM, arun <smartpink111 at yahoo.com> wrote:

Hi,
>When I type 'acf', I get this:
>
>
>function (x, lag.max = NULL, type = c("correlation", "covariance",
>??? "partial"), plot = TRUE, na.action = na.fail, demean = TRUE,
>??? ...)
>{
>??? type <- match.arg(type)
>??? if (type == "partial") {
>??????? m <- match.call()
>??????? m[[1L]] <- as.name("pacf")
>??????? m$type <- NULL
>??????? return(eval(m, parent.frame()))
>??? }
>??? series <- deparse(substitute(x))
>??? x <- na.action(as.ts(x))
>??? x.freq <- frequency(x)
>??? x <- as.matrix(x)
>??? if (!is.numeric(x))
>??????? stop("'x' must be numeric")
>??? sampleT <- as.integer(nrow(x))
>??? nser <- as.integer(ncol(x))
>??? if (is.na(sampleT) || is.na(nser))
>??????? stop("'sampleT' and 'nser' must be integer")
>??? if (is.null(lag.max))
>??????? lag.max <- floor(10 * (log10(sampleT) - log10(nser)))
>??? lag.max <- as.integer(min(lag.max, sampleT - 1L))
>??? if (is.na(lag.max) || lag.max < 0)
>??????? stop("'lag.max' must be at least 0")
>??? if (demean)
>??????? x <- sweep(x, 2, colMeans(x, na.rm = TRUE), check.margin = FALSE)
>??? lag <- matrix(1, nser, nser)
>??? lag[lower.tri(lag)] <- -1
>??? acf <- .Call(C_acf, x, lag.max, type == "correlation")
>??? lag <- outer(0:lag.max, lag/x.freq)
>??? acf.out <- structure(list(acf = acf, type = type, n.used = sampleT,
>??????? lag = lag, series = series, snames = colnames(x)), class = "acf")
>??? if (plot) {
>??????? plot.acf(acf.out, ...)
>??????? invisible(acf.out)
>??? }
>??? else acf.out
>}
>
>
>
>I couldn't get:
>
>array(.C(C_acf, as.double(x), sampleT, nser, lag.max,?
>? ? ? ? as.integer(type == "correlation"), acf = double((lag.max +?
>? ? ? ? ? ? 1L) * nser * nser), NAOK = TRUE)$acf, c(lag.max +?
>? ? ? ? 1L, nser, nser))
>
>
>________________________________
>
>From: Cathy Lee Gierke <leegi001 at umn.edu>
>To: arun <smartpink111 at yahoo.com>
>Sent: Tuesday, July 30, 2013 4:49 PM
>
>Subject: Re: [R] acf and ccf
>
>
>
>
>Thank you. ?Yes, I supposed that does give you the function. ?However, most of the meaningful code is inside another compiled function:
>
>?acf <- array(.C(C_acf, as.double(x), sampleT, nser, lag.max,?
>? ? ? ? as.integer(type == "correlation"), acf = double((lag.max +?
>? ? ? ? ? ? 1L) * nser * nser), NAOK = TRUE)$acf, c(lag.max +?
>? ? ? ? 1L, nser, nser))
>
>Any idea how to see that?
>
>
>Cathy Lee Gierke
>
>
>On Tue, Jul 30, 2013 at 3:28 PM, arun <smartpink111 at yahoo.com> wrote:
>
>Just type
>>acf
>>ccf
>>on R prompt
>>A.K.
>>
>>
>>
>>
>>
>>
>>----- Original Message -----
>>From: Cathy Lee Gierke <leegi001 at umn.edu>
>>To: r-help at r-project.org; r-core-owner at r-project.org
>>Cc:
>>Sent: Tuesday, July 30, 2013 4:02 PM
>>Subject: [R] acf and ccf
>>
>>Greetings,
>>
>>Is it possible to see the source code for the acf and ccf functions?? I
>>want to understand the exact formula used.
>>
>>It may be in this book, but I am hoping I can find it elsewhere, as the
>>book is quite expensive.
>>Venables, W. N. and Ripley, B. D. (2002) *Modern Applied Statistics with S*.
>>
>>Fourth Edition. Springer-Verlag.
>>
>>
>>Sincere thanks,
>>Cathy Lee Gierke
>>
>>??? [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>>
>>
>


From jim at bitwrit.com.au  Tue Jul 30 23:33:24 2013
From: jim at bitwrit.com.au (Jim Lemon)
Date: Wed, 31 Jul 2013 07:33:24 +1000
Subject: [R] List of lists
In-Reply-To: <OF16CA59CA.50E23016-ON65257BB8.0041FCCB-65257BB8.00426597@polarisft.com>
References: <OF16CA59CA.50E23016-ON65257BB8.0041FCCB-65257BB8.00426597@polarisft.com>
Message-ID: <51F83124.20009@bitwrit.com.au>

On 07/30/2013 10:05 PM, mohan.radhakrishnan at polarisft.com wrote:
>
> Hi,
>                 I am creating a list of 2 lists, one containing filenames
> and the other file descriptors.  When I retrieve them I am  unable to close
> the file descriptor.
>
> I am getting this error when I try to call close(filedescriptors
> [[2]][[1]]).
>
> Error in UseMethod("close") :
>    no applicable method for 'close' applied to an object of class "c
> ('integer', 'numeric')"
>
> print(filedescriptors[[2]][[1]]) seems to be printing individual elements.
>
> Thanks,
> Mohan
>
> filelist.array<- function(n){
>    cpufile<- list()
>    cpufiledescriptors<- list()
>    length(cpufile)<- n
>    for (i in 1:n) {
>      cpufile[[i]]<- paste("output", i, ".txt", sep = "")
> 	cpufiledescriptors[[i]]<-file( cpufile[[i]], "a" )
>    }
>      listoffiles<- list(cpufile=cpufile,
> cpufiledescriptors=cpufiledescriptors)
> 	return (listoffiles)
> }
>
>
>
> #Test function
>
> test.filelist.array<- function() {
> 	filedescriptors<- filelist.array(3)
>      print(filedescriptors[[2]][[1]])
>      print(filedescriptors[[2]][[2]])
>      print(filedescriptors[[2]][[3]])
>
> }
>
>
Hi Mohan,
When you have opened connections as above, you need to pass the 
connection, not just one element, to "close":

close(listoffiles$cpufiledescriptors[[1]])

Jim


From smartpink111 at yahoo.com  Wed Jul 31 00:41:55 2013
From: smartpink111 at yahoo.com (arun)
Date: Tue, 30 Jul 2013 15:41:55 -0700 (PDT)
Subject: [R] set the wd based on cdv file
Message-ID: <1375224115.5451.YahooMailNeo@web142606.mail.bf1.yahoo.com>

Hi,
It is not clear which OS you are using.? Most probably, the "Directory" column would be "factor".
table1<- read.table(text="
ID Directory
1? /home/arunksa111/Documents
2? /home/arunksa111/Trial
3? ~/Trial1
4 ~Trial2
",sep="",header=TRUE,stringsAsFactors=FALSE)

setwd(table1$Directory[2])
?getwd()
#[1] "/home/arunksa111/Trial"

setwd(table1$Directory[1])
getwd()
#[1] "/home/arunksa111/Documents"
T2<- subset(table1,ID==3)
setwd(T2$Directory)
?getwd()
#[1] "/home/arunksa111/Trial1"
?T3<-subset(table1,ID==4)
setwd(T3$Directory)
#Error in setwd(T3$Directory) : cannot change working directory
#The error is different here.

#Now using stringsAsFactors=TRUE

table1<- read.table(text="
ID Directory
1? /home/arunksa111/Documents
2? /home/arunksa111/Trial
3? ~/Trial1
4 ~Trial2
",sep="",header=TRUE,stringsAsFactors=TRUE)

?setwd(table1$Directory[2])
#Error in setwd(table1$Directory[2]) : character argument expected
T2<- subset(table1,ID==3)
?setwd(T2$Directory)
#Error in setwd(T2$Directory) : character argument expected
?T3<-subset(table1,ID==4)
?setwd(T3$Directory)
#Error in setwd(T3$Directory) : character argument expected
setwd(as.character(T3$Directory)) #path is? not correct
#Error in setwd(as.character(T3$Directory)) : 
?# cannot change working directory
?setwd(as.character(T2$Directory))
?getwd()
#[1] "/home/arunksa111/Trial1"

sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-unknown-linux-gnu (64-bit)

A.K.



Hello, 

I have a CSV file that summarises different working directories.
 I would like to write a script to be able to access the different 
directories. 

CSV "table" file: 
ID ? ? ? ? ? ? ?directory 
1 ? ? ? ? ? ? ? ?"~Documents/16_06_13" 
2 ? ? ? ? ? ? ? ?"~Documents/18_06_13" 
3 ? ? ? ? ? ? ? ?"~Documents/19_06_13" 
... 

I tried by sub setting the "table.csv" file: 
T1 <- subset(table, table$ID== "1") 
setwd(T1$directory) 

but it gives me the following error: 
Error in setwd(T1$directory) : character argument expected 

can someone help me to solve this problem? 

Thank you very much 

Stefano


From harb at student.unimelb.edu.au  Wed Jul 31 01:25:25 2013
From: harb at student.unimelb.edu.au (Ben Harrison)
Date: Wed, 31 Jul 2013 09:25:25 +1000
Subject: [R] Plot a series of plots without using a loop
In-Reply-To: <51F7A505.4050308@sapo.pt>
References: <CAGYnQNS4UUu+Qa2-7cbBhVO_eLkziKGiq5s20nJNevSUhMgDqA@mail.gmail.com>
	<51F7A505.4050308@sapo.pt>
Message-ID: <CAGYnQNTi+36SzXCOOuD5zZA8aH2-Lmj7x-=9KuxtWfDk8FDTrg@mail.gmail.com>

On 30 July 2013 21:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Maybe the following does it.
>
> op <- par(mfrow=c(2, 3))
>
> for(i in 1:6){
>         plot(somdata.xyf,
>              type="property",
>              property=somdata.xyf$codes$X[, i],
>              main=colnames(somdata.xyf$codes$X)[i])
> }
>
> par(op)
>
>
> Hope this helps,
>
> Rui Barradas

Thanks Rui,
that does it for sure. I had come to that solution, but just realised
by looking at it again, I could change
for (i in 1:6)
with
for (i in 1:length(dim(somdata.xyf$codes$X)[2]))

I was also wondering if there was a way to do it without a for loop,
but in this case it's a very small number of iterations, so probably
not worth it.

Ben


From erinm.hodgess at gmail.com  Wed Jul 31 06:28:38 2013
From: erinm.hodgess at gmail.com (Erin Hodgess)
Date: Tue, 30 Jul 2013 23:28:38 -0500
Subject: [R] installing rJava
Message-ID: <CACxE24naQvqbdV1LgVdBV1-p_qTU7gUjgihHM6NiPVfOtK3xbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130730/eca2b0a2/attachment.pl>

From orvaquim at gmail.com  Wed Jul 31 07:09:20 2013
From: orvaquim at gmail.com (Orvalho Augusto)
Date: Wed, 31 Jul 2013 07:09:20 +0200
Subject: [R] installing rJava
In-Reply-To: <CACxE24naQvqbdV1LgVdBV1-p_qTU7gUjgihHM6NiPVfOtK3xbA@mail.gmail.com>
References: <CACxE24naQvqbdV1LgVdBV1-p_qTU7gUjgihHM6NiPVfOtK3xbA@mail.gmail.com>
Message-ID: <CAF4WX-cVEei07Yr3Y6ORT7hK0tbxJFKs8gf9qu9aJmzvLzRRXw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/d71a4d06/attachment.pl>

From xie at yihui.name  Wed Jul 31 07:13:48 2013
From: xie at yihui.name (Yihui Xie)
Date: Tue, 30 Jul 2013 22:13:48 -0700
Subject: [R] installing rJava
In-Reply-To: <CACxE24naQvqbdV1LgVdBV1-p_qTU7gUjgihHM6NiPVfOtK3xbA@mail.gmail.com>
References: <CACxE24naQvqbdV1LgVdBV1-p_qTU7gUjgihHM6NiPVfOtK3xbA@mail.gmail.com>
Message-ID: <CANROs4fZaaxSA8iK4kkHjXg_Xtu_1us4AfYuMWAo29WLcw6XJg@mail.gmail.com>

You can install it from Michael Rutter's PPA:

sudo apt-add-repository -y ppa:marutter/c2d4u
sudo apt-get update
sudo apt-get install r-cran-rjava

The last time I tried the official Ubuntu repository, rJava still did
not work under R 3.0.x (because R 3.0.x requires recompiling all R
packages). I'm not sure if that has changed or not. Michael's
repository has been working well for me (including many other R
packages that have system dependencies).

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Phone: 206-667-4385 Web: http://yihui.name
Fred Hutchinson Cancer Research Center, Seattle


On Tue, Jul 30, 2013 at 9:28 PM, Erin Hodgess <erinm.hodgess at gmail.com> wrote:
> Dear R People:
>
> I am trying to install rJava on an Ubuntu 13.04 64 bit system.  But the
> Java part is causing me fits.  Here is the code:
>
>> install.packages("rJava",depen=TRUE)
> Installing package into ?/home/erin/R/x86_64-pc-linux-gnu-library/3.0?
> (as ?lib? is unspecified)
> --- Please select a CRAN mirror for use in this session ---
> trying URL 'http://cran.at.r-project.org/src/contrib/rJava_0.9-4.tar.gz'
> Content type 'application/x-gzip' length 498108 bytes (486 Kb)
> opened URL
> ==================================================
> downloaded 486 Kb
>
> * installing *source* package ?rJava? ...
> ** package ?rJava? successfully unpacked and MD5 sums checked
> checking for gcc... gcc -std=gnu99
> checking for C compiler default output file name... a.out
> checking whether the C compiler works... yes
> checking whether we are cross compiling... no
> checking for suffix of executables...
> checking for suffix of object files... o
> checking whether we are using the GNU C compiler... yes
> checking whether gcc -std=gnu99 accepts -g... yes
> checking for gcc -std=gnu99 option to accept ISO C89... none needed
> checking how to run the C preprocessor... gcc -std=gnu99 -E
> checking for grep that handles long lines and -e... /bin/grep
> checking for egrep... /bin/grep -E
> checking for ANSI C header files... yes
> checking for sys/wait.h that is POSIX.1 compatible... yes
> checking for sys/types.h... yes
> checking for sys/stat.h... yes
> checking for stdlib.h... yes
> checking for string.h... yes
> checking for memory.h... yes
> checking for strings.h... yes
> checking for inttypes.h... yes
> checking for stdint.h... yes
> checking for unistd.h... yes
> checking for string.h... (cached) yes
> checking sys/time.h usability... yes
> checking sys/time.h presence... yes
> checking for sys/time.h... yes
> checking for unistd.h... (cached) yes
> checking for an ANSI C-conforming const... yes
> checking whether time.h and sys/time.h may both be included... yes
> configure: checking whether gcc -std=gnu99 supports static inline...
> yes
> checking whether setjmp.h is POSIX.1 compatible... yes
> checking whether sigsetjmp is declared... yes
> checking whether siglongjmp is declared... yes
> checking Java support in R... present:
> interpreter : '/usr/lib/jvm/jdk1.7.0_25/jre/bin/java'
> archiver    : '/usr/lib/jvm/jdk1.7.0_25/bin/jar'
> compiler    : '/usr/lib/jvm/jdk1.7.0_25/bin/javac'
> header prep.: '/usr/lib/jvm/jdk1.7.0_25/bin/javah'
> cpp flags   : ''
> java libs   : ''
> configure: error: One or more Java configuration variables are not set.
> Make sure R is configured with full Java support (including JDK). Run
> R CMD javareconf
> as root to add Java support to R.
>
> If you don't have root privileges, run
> R CMD javareconf -e
> to set all Java-related variables and then install rJava.
>
> ERROR: configuration failed for package ?rJava?
> * removing ?/home/erin/R/x86_64-pc-linux-gnu-library/3.0/rJava?
>
> The downloaded source packages are in
>     ?/tmp/RtmpSzdy7i/downloaded_packages?
> Warning message:
> In install.packages("rJava", depen = TRUE) :
>   installation of package ?rJava? had non-zero exit status
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=C                 LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tcltk_3.0.1 tools_3.0.1
>> q()
> Save workspace image? [y/n/c]: y
>
> Now here is the command line:
>
> erin at erin-Lenovo-IdeaPad-Y480:~$ sudo R CMD javareconf
> Java interpreter : /usr/bin/java
> Java version     : 1.7.0_25
> Java home path   : /usr/lib/jvm/jdk1.7.0_25/jre
> Java compiler    : /usr/bin/javac
> Java headers gen.: /usr/bin/javah
> Java archive tool: /usr/bin/jar
>
> trying to compile and link a JNI progam
> detected JNI cpp flags    : -I$(JAVA_HOME)/../include
> -I$(JAVA_HOME)/../include/linux
> detected JNI linker flags : -L$(JAVA_HOME)/lib/i386/client -ljvm
> gcc -std=gnu99 -I/usr/share/R/include -DNDEBUG
> -I/usr/lib/jvm/jdk1.7.0_25/jre/../include
> -I/usr/lib/jvm/jdk1.7.0_25/jre/../include/linux     -fpic  -O2 -pipe -g  -c
> conftest.c -o conftest.o
> gcc -std=gnu99 -shared -o conftest.so conftest.o
> -L/usr/lib/jvm/jdk1.7.0_25/jre/lib/i386/client -ljvm -L/usr/lib/R/lib -lR
> /usr/bin/ld: skipping incompatible
> /usr/lib/jvm/jdk1.7.0_25/jre/lib/i386/client/libjvm.so when searching for
> -ljvm
> /usr/bin/ld: cannot find -ljvm
> collect2: error: ld returned 1 exit status
> make: *** [conftest.so] Error 1
> Unable to compile a JNI program
>
>
> Java library path:
> JNI cpp flags    :
> JNI linker flags :
> Updating Java configuration in /usr/lib/R
> Done.
>
> erin at erin-Lenovo-IdeaPad-Y480:~$
>
> I'm thinking that there is a problem with shared/static libraries,
> perhaps?
>
>
> Has anyone else run into this, please?  Any help much appreciated.
>
> Sincerely,
> Erin
>
>
> --
> Erin Hodgess
> Associate Professor
> Department of Computer and Mathematical Sciences
> University of Houston - Downtown
> mailto: erinm.hodgess at gmail.com


From jdnewmil at dcn.davis.CA.us  Wed Jul 31 09:57:51 2013
From: jdnewmil at dcn.davis.CA.us (Jeff Newmiller)
Date: Wed, 31 Jul 2013 00:57:51 -0700
Subject: [R] Intersecting two matrices
In-Reply-To: <CAEOnvcEWOzSNcgL+Xde9Bw9j1F7i0E4ygq_Kv8cWy5OnGwSXtg@mail.gmail.com>
References: <CAEOnvcHOjZzQADMJf=AAmf0LUswq_w7iB3Ohh2D0U_j15ds52A@mail.gmail.com>
	<E66794E69CFDE04D9A70842786030B931C32AAFE@PA-MBX01.na.tibco.com>
	<CAEOnvcHw154E3--LJCQuPpRhVNDP3zNaZg0_n37JdBGvsm47Og@mail.gmail.com>
	<c9ed6187-37a1-4f64-9e3c-81680e8f26b9@email.android.com>
	<CAEOnvcEWOzSNcgL+Xde9Bw9j1F7i0E4ygq_Kv8cWy5OnGwSXtg@mail.gmail.com>
Message-ID: <9e062e9f-88f2-4ec1-a81c-f6563c3a0ce2@email.android.com>

I would appreciate it if you would follow the Posting Guide and give a reproducible example and post all messages using plain text.

Try

m1 <- matrix(sample(0:999,2*1057837,TRUE),ncol=2)
m2 <- matrix(sample(0:999,2*951980,TRUE),ncol=2)
df1 <- as.data.frame(m1)
df2 <- as.data.frame(m2)
library(sqldf)
system.time(df3 <- sqldf("SELECT DISTINCT df1.V1, df1.V2 FROM df1 INNER JOIN df2 ON df1.V1=df2.V1 AND df1.V2=df2.V2") )

The speed seems heavily dependent on how many rows are duplicated within the input data frames... so if the range of values is small then the query runs slower. Note also that moving the data from R to the database and back takes time... you may be able to import the data directly from your source data to the database and save some time. Read ?sqldf and ?read.csv.sql examples for more info.
---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                      Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
--------------------------------------------------------------------------- 
Sent from my phone. Please excuse my brevity.

c char <charlie.hsia.us at gmail.com> wrote:
>I am not familiar with R's sort and sql libs. appreciate if you can
>post a
>code snippet when you got time. Thanks a lot!
>
>
>On Tue, Jul 30, 2013 at 10:36 AM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us>wrote:
>
>> In that case, you should be looking at a relational inner join,
>perhaps
>> with SQLite (see package sqldf).
>>
>---------------------------------------------------------------------------
>> Jeff Newmiller                        The     .....       .....  Go
>Live...
>> DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live
>> Go...
>>                                       Live:   OO#.. Dead: OO#.. 
>Playing
>> Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
>> /Software/Embedded Controllers)               .OO#.       .OO#. 
>rocks...1k
>>
>---------------------------------------------------------------------------
>> Sent from my phone. Please excuse my brevity.
>>
>> c char <charlie.hsia.us at gmail.com> wrote:
>> >Thanks a lot.
>> >Still looking for some super fast and memory efficient solution, as
>the
>> >matrix I have in real world has billions of rows.
>> >
>> >
>> >On Mon, Jul 29, 2013 at 6:24 PM, William Dunlap <wdunlap at tibco.com>
>> >wrote:
>> >
>> >> I haven't looked at the size-time relationship, but im2 (below) is
>> >faster
>> >> than your
>> >> function on at least one example:
>> >>
>> >> intersectMat <- function(mat1, mat2)
>> >> {
>> >>     #mat1 and mat2 are both deduplicated
>> >>     nr1 <- nrow(mat1)
>> >>     nr2 <- nrow(mat2)
>> >>     mat2[duplicated(rbind(mat1, mat2))[(nr1 + 1):(nr1 + nr2)], ,
>> >> drop=FALSE]
>> >> }
>> >>
>> >> im2 <- function(mat1, mat2)
>> >> {
>> >>     stopifnot(ncol(mat1)==2, ncol(mat1)==ncol(mat2))
>> >>     toChar <- function(twoColMat) paste(sep="\1", twoColMat[,1],
>> >> twoColMat[,2])
>> >>     mat1[match(toChar(mat2), toChar(mat1), nomatch=0), ,
>drop=FALSE]
>> >> }
>> >>
>> >> > m1 <- cbind(1:1e7, rep(1:10, len=1e7))
>> >> > m2 <- cbind(1:1e7, rep(1:20, len=1e7))
>> >> > system.time(r1 <- intersectMat(m1,m2))
>> >>    user  system elapsed
>> >>  430.37    1.96  433.98
>> >> > system.time(r2 <- im2(m1,m2))
>> >>    user  system elapsed
>> >>   27.89    0.20   28.13
>> >> > identical(r1, r2)
>> >> [1] TRUE
>> >> > dim(r1)
>> >> [1] 5000000       2
>> >>
>> >> Bill Dunlap
>> >> Spotfire, TIBCO Software
>> >> wdunlap tibco.com
>> >>
>> >>
>> >> > -----Original Message-----
>> >> > From: r-help-bounces at r-project.org
>> >[mailto:r-help-bounces at r-project.org]
>> >> On Behalf
>> >> > Of c char
>> >> > Sent: Monday, July 29, 2013 4:04 PM
>> >> > To: r-help at r-project.org
>> >> > Subject: [R] Intersecting two matrices
>> >> >
>> >> > Dear all,
>> >> >
>> >> > I am interested to know a faster matrix intersection package for
>R
>> >> handles
>> >> > intersection of two integer matrices with ncol=2. Currently I am
>> >using my
>> >> > homemade code adapted from a previous thread:
>> >> >
>> >> >
>> >> > intersectMat <- function(mat1, mat2){#mat1 and mat2 are both
>> >> > deduplicated  nr1 <- nrow(mat1)  nr2 <- nrow(mat2)
>> >> > mat2[duplicated(rbind(mat1, mat2))[(nr1 + 1):(nr1 + nr2)], ]}
>> >> >
>> >> >
>> >> > which handles:
>> >> > size A= 10578373
>> >> > size B= 9519807
>> >> > expected intersecting time= 251.2272
>> >> > intersecting for corssing MPRs took 409.602 seconds.
>> >> >
>> >> > scale a little bit worse than linearly but atomic operation is
>not
>> >good.
>> >> > Wonder if a super fast C/C++ extension exists for this task.
>Your
>> >ideas
>> >> are
>> >> > appreciated.
>> >> >
>> >> > Thanks!
>> >> >
>> >> >       [[alternative HTML version deleted]]
>> >> >
>> >> > ______________________________________________
>> >> > R-help at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-help
>> >> > PLEASE do read the posting guide
>> >> http://www.R-project.org/posting-guide.html
>> >> > and provide commented, minimal, self-contained, reproducible
>code.
>> >>
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> >______________________________________________
>> >R-help at r-project.org mailing list
>> >https://stat.ethz.ch/mailman/listinfo/r-help
>> >PLEASE do read the posting guide
>> >http://www.R-project.org/posting-guide.html
>> >and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.


From ruipbarradas at sapo.pt  Wed Jul 31 10:35:42 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 31 Jul 2013 09:35:42 +0100
Subject: [R] Plot a series of plots without using a loop
In-Reply-To: <CAGYnQNTi+36SzXCOOuD5zZA8aH2-Lmj7x-=9KuxtWfDk8FDTrg@mail.gmail.com>
References: <CAGYnQNS4UUu+Qa2-7cbBhVO_eLkziKGiq5s20nJNevSUhMgDqA@mail.gmail.com>
	<51F7A505.4050308@sapo.pt>
	<CAGYnQNTi+36SzXCOOuD5zZA8aH2-Lmj7x-=9KuxtWfDk8FDTrg@mail.gmail.com>
Message-ID: <51F8CC5E.5060508@sapo.pt>

Hello,

There's a bug in the line

for (i in 1:length(dim(somdata.xyf$codes$X)[2]))

length() is always 1, you can use simply 1:dim(...)[2] or even simpler

for(i in 1:ncol(somdata.xyf$codes$X))

As for a way without a loop, you could use ?sapply:

sapply(1:ncol(somdata.xyf$codes$X), function(i) plot(...))

But I believe the loop is far more readable, and preferable.

Rui Barradas

Em 31-07-2013 00:25, Ben Harrison escreveu:
> On 30 July 2013 21:35, Rui Barradas <ruipbarradas at sapo.pt> wrote:
>> Hello,
>>
>> Maybe the following does it.
>>
>> op <- par(mfrow=c(2, 3))
>>
>> for(i in 1:6){
>>          plot(somdata.xyf,
>>               type="property",
>>               property=somdata.xyf$codes$X[, i],
>>               main=colnames(somdata.xyf$codes$X)[i])
>> }
>>
>> par(op)
>>
>>
>> Hope this helps,
>>
>> Rui Barradas
>
> Thanks Rui,
> that does it for sure. I had come to that solution, but just realised
> by looking at it again, I could change
> for (i in 1:6)
> with
> for (i in 1:length(dim(somdata.xyf$codes$X)[2]))
>
> I was also wondering if there was a way to do it without a for loop,
> but in this case it's a very small number of iterations, so probably
> not worth it.
>
> Ben
>


From mohan.radhakrishnan at polarisft.com  Wed Jul 31 08:18:30 2013
From: mohan.radhakrishnan at polarisft.com (mohan.radhakrishnan at polarisft.com)
Date: Wed, 31 Jul 2013 11:48:30 +0530
Subject: [R] List of lists
In-Reply-To: <51F83124.20009@bitwrit.com.au>
References: <OF16CA59CA.50E23016-ON65257BB8.0041FCCB-65257BB8.00426597@polarisft.com>
	<51F83124.20009@bitwrit.com.au>
Message-ID: <OF55042A8A.E64E51D9-ON65257BB9.002277C3-65257BB9.0022A72D@polarisft.com>

Hi Jim,

    close(filedescriptors$cpufiledescriptors[[1]])
    close(filedescriptors$cpufiledescriptors[[2]])
    close(filedescriptors$cpufiledescriptors[[3]])

  I might be doing something wrong. Error is

   Error in UseMethod("close") :
  no applicable method for 'close' applied to an object of class "c
('integer', 'numeric')"


Thanks,
Mohan


                                                                            
                                                                            
                                                                            
   Re: [R] List of lists                                                    
                                                                            
                                                                            
   Jim Lemon                                                                
              to:                                                           
                 mohan.radhakrishnan, R-help at r-project.org                  
                                                           31-07-2013 03:05 
                                                                         AM 
                                                                            
                                                                            





On 07/30/2013 10:05 PM, mohan.radhakrishnan at polarisft.com wrote:
>
> Hi,
>                 I am creating a list of 2 lists, one containing filenames
> and the other file descriptors.  When I retrieve them I am  unable to
close
> the file descriptor.
>
> I am getting this error when I try to call close(filedescriptors
> [[2]][[1]]).
>
> Error in UseMethod("close") :
>    no applicable method for 'close' applied to an object of class "c
> ('integer', 'numeric')"
>
> print(filedescriptors[[2]][[1]]) seems to be printing individual
elements.
>
> Thanks,
> Mohan
>
> filelist.array<- function(n){
>    cpufile<- list()
>    cpufiledescriptors<- list()
>    length(cpufile)<- n
>    for (i in 1:n) {
>      cpufile[[i]]<- paste("output", i, ".txt", sep = "")
> 		 cpufiledescriptors[[i]]<-file( cpufile[[i]], "a" )
>    }
>      listoffiles<- list(cpufile=cpufile,
> cpufiledescriptors=cpufiledescriptors)
> 		 return (listoffiles)
> }
>
>
>
> #Test function
>
> test.filelist.array<- function() {
> 		 filedescriptors<- filelist.array(3)
>      print(filedescriptors[[2]][[1]])
>      print(filedescriptors[[2]][[2]])
>      print(filedescriptors[[2]][[3]])
>
> }
>
>
Hi Mohan,
When you have opened connections as above, you need to pass the
connection, not just one element, to "close":

close(listoffiles$cpufiledescriptors[[1]])

Jim





This e-Mail may contain proprietary and confidential information and is sent for the intended recipient(s) only.  If by an addressing or transmission error this mail has been misdirected to you, you are requested to delete this mail immediately. You are also hereby notified that any use, any form of reproduction, dissemination, copying, disclosure, modification, distribution and/or publication of this e-mail message, contents or its attachment other than by its intended recipient/s is strictly prohibited.

Visit us at http://www.polarisFT.com


From ravi.raghava at classle.co.in  Wed Jul 31 09:46:00 2013
From: ravi.raghava at classle.co.in (ravi.raghava1)
Date: Wed, 31 Jul 2013 00:46:00 -0700 (PDT)
Subject: [R] Using If loop in R how to extract even and odd ids
Message-ID: <1375256760601-4672707.post@n4.nabble.com>

I have 500 ids ; i want to take out even and odd ids separately and store it
another data files.
How can it be done in R by using *If and for loop* ??




--
View this message in context: http://r.789695.n4.nabble.com/Using-If-loop-in-R-how-to-extract-even-and-odd-ids-tp4672707.html
Sent from the R help mailing list archive at Nabble.com.


From pierre.khoueiry at embl.de  Wed Jul 31 10:15:38 2013
From: pierre.khoueiry at embl.de (PQuery)
Date: Wed, 31 Jul 2013 01:15:38 -0700 (PDT)
Subject: [R] comparing real set vs sampled sets
Message-ID: <1375258538453-4672709.post@n4.nabble.com>

Dear R helper,

I have a statistic question. 
I have a vector of 500 values for which I need to assess the statistical
significance of occurrence

real.dist <- realValues

For that, I sampled from my data large data pool 1000 other vectors of 500
values each.

I then run ks.test with my real vec vs each of the sampled vectors.

ks.res<-unlist(lapply(l.sampled,function(x){
  ks <- ks.test(real.dist, x$dist)
  as.numeric(ks[["statistic"]])
}))

I now have 1000 "D" values with their corresponding p.values. How can I have
a general p.value saying that
my real data differs from the sampled one, and thus significant ?

Any suggestion ?
Many thanks,




--
View this message in context: http://r.789695.n4.nabble.com/comparing-real-set-vs-sampled-sets-tp4672709.html
Sent from the R help mailing list archive at Nabble.com.


From info at software-solutions.nl  Wed Jul 31 11:37:38 2013
From: info at software-solutions.nl (Dark)
Date: Wed, 31 Jul 2013 02:37:38 -0700 (PDT)
Subject: [R] Add a column to a data frame with value based on the percentile
 of the row
Message-ID: <1375263458733-4672711.post@n4.nabble.com>

Hi all,

I think this should be an easy question for the guru's out here.

I have this large data frame (2.500.000 rows, 15 columns) and I want to add
a column named "SEGMENT" to it.
The first 5% rows (first 125.000 rows) should have the value "Top 5%" in the
SEGMENT column
Then the rows from 5% to 20% should have the value "5 to 20"
Then 20-50% should have the value "20 to 50"
And the last 50% of the rows should have the value "Bottom 50"

What is the easiest way of doing this? I was thinking of using quantile but
then I should have some rownumber column.

Regards Derk



--
View this message in context: http://r.789695.n4.nabble.com/Add-a-column-to-a-data-frame-with-value-based-on-the-percentile-of-the-row-tp4672711.html
Sent from the R help mailing list archive at Nabble.com.


From raoosten at gmail.com  Wed Jul 31 11:43:02 2013
From: raoosten at gmail.com (Raoul Van Oosten)
Date: Wed, 31 Jul 2013 11:43:02 +0200
Subject: [R] parfm frailty model and post hoc testing
Message-ID: <CALMYze9mBwp50uzx3DGC3uXzHJBKDT3G=5j_mJbCsgSVA6096A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/8ca48c9c/attachment.pl>

From mfu001 at uit.no  Wed Jul 31 12:45:50 2013
From: mfu001 at uit.no (monaR)
Date: Wed, 31 Jul 2013 03:45:50 -0700 (PDT)
Subject: [R] detect multivariate outliers with aq.plot {mvoutliers} high
 dimensions
Message-ID: <1375267550103-4672714.post@n4.nabble.com>

Hei,
i have a species abundance data set CommData, with n (samples)=40 and p
(species)=107. 
Sample	Species A	Species B	Species C	Species D	?.
411_2010	40	20	0	0	
412_2010	30	20	0	0	
413_2010	0	0	0	0	
414_2010	0	10	0	0	
415_2010	20	0	0	0	
418_2010	0	0	0	0	
419_2010	0	0	0	0	
421_2010	160	40	0	10	
?.					
	
I try to find outliers based on the Mahalonis distance with the package
{mvoutliers}. I get an error using >aq.plot(CommData): "Error in covMcd(x,
alpha = quan) : n <= p -- you can't be serious!" 
SoI try >pcout(CommData), which is supposed to work for high dimensions, but
get the error "More than 50% equal values in one or more variables!"

Can this be fixed? Any idea how i can find outliers in my multidimensional
data?
Thanks a lot for any help!!



--
View this message in context: http://r.789695.n4.nabble.com/detect-multivariate-outliers-with-aq-plot-mvoutliers-high-dimensions-tp4672714.html
Sent from the R help mailing list archive at Nabble.com.


From ruipbarradas at sapo.pt  Wed Jul 31 13:11:05 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 31 Jul 2013 12:11:05 +0100
Subject: [R] Using If loop in R how to extract even and odd ids
In-Reply-To: <1375256760601-4672707.post@n4.nabble.com>
References: <1375256760601-4672707.post@n4.nabble.com>
Message-ID: <51F8F0C9.2070707@sapo.pt>

Hello,

Who told you you need a loop or an if?


even <- function(x) x %% 2 == 0

x <- 1:50
idx <- even(x)
x[idx]


Hope this helps,

Rui Barradas

Em 31-07-2013 08:46, ravi.raghava1 escreveu:
> I have 500 ids ; i want to take out even and odd ids separately and store it
> another data files.
> How can it be done in R by using *If and for loop* ??
>
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Using-If-loop-in-R-how-to-extract-even-and-odd-ids-tp4672707.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ruipbarradas at sapo.pt  Wed Jul 31 13:22:36 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 31 Jul 2013 12:22:36 +0100
Subject: [R] Add a column to a data frame with value based on the
 percentile of the row
In-Reply-To: <1375263458733-4672711.post@n4.nabble.com>
References: <1375263458733-4672711.post@n4.nabble.com>
Message-ID: <51F8F37C.7070907@sapo.pt>

Hello,

Combine quantile() with findInterval(). Something like the following.


# sample data
x <- rnorm(100)

val <- c("Bottom 50", "20 to 50", "5 to 20", "Top 5%")
qq <- quantile(x, probs = c(0, 0.50, 0.70, 0.95, 1))

idx <- findInterval(x, qq)
val[idx]


Hope this helps,

Rui Barradas

Em 31-07-2013 10:37, Dark escreveu:
> Hi all,
>
> I think this should be an easy question for the guru's out here.
>
> I have this large data frame (2.500.000 rows, 15 columns) and I want to add
> a column named "SEGMENT" to it.
> The first 5% rows (first 125.000 rows) should have the value "Top 5%" in the
> SEGMENT column
> Then the rows from 5% to 20% should have the value "5 to 20"
> Then 20-50% should have the value "20 to 50"
> And the last 50% of the rows should have the value "Bottom 50"
>
> What is the easiest way of doing this? I was thinking of using quantile but
> then I should have some rownumber column.
>
> Regards Derk
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Add-a-column-to-a-data-frame-with-value-based-on-the-percentile-of-the-row-tp4672711.html
> Sent from the R help mailing list archive at Nabble.com.
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From smartpink111 at yahoo.com  Wed Jul 31 13:23:40 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 31 Jul 2013 04:23:40 -0700 (PDT)
Subject: [R] Using If loop in R how to extract even and odd ids
In-Reply-To: <1375256760601-4672707.post@n4.nabble.com>
References: <1375256760601-4672707.post@n4.nabble.com>
Message-ID: <1375269820.76300.YahooMailNeo@web142605.mail.bf1.yahoo.com>

Hi,
May be this helps:

set.seed(24)
dat1<- data.frame(ID=1:500,value=rnorm(500))
res<- split(dat1,dat1$ID%%2)


A.K.

----- Original Message -----
From: ravi.raghava1 <ravi.raghava at classle.co.in>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 31, 2013 3:46 AM
Subject: [R] Using If loop in R how to extract even and odd ids

I have 500 ids ; i want to take out even and odd ids separately and store it
another data files.
How can it be done in R by using *If and for loop* ??




--
View this message in context: http://r.789695.n4.nabble.com/Using-If-loop-in-R-how-to-extract-even-and-odd-ids-tp4672707.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul 31 13:48:41 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 31 Jul 2013 04:48:41 -0700 (PDT)
Subject: [R] Add a column to a data frame with value based on the
	percentile of the row
In-Reply-To: <1375263458733-4672711.post@n4.nabble.com>
References: <1375263458733-4672711.post@n4.nabble.com>
Message-ID: <1375271321.13862.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,
May be this helps:
set.seed(24)
dat1<- data.frame(ID=1:500,value=rnorm(500))
indx<-round(quantile(as.numeric(row.names(dat1)),probs=c(0.05,0.20,0.50,1)))
indx1<-findInterval(row.names(dat1),indx,rightmost.closed=TRUE)
dat1$SEGMENT<- as.character(factor(indx1,labels=c("Top 5%","5 to 20","20 to 50", "Bottom 50")))
head(dat1)
#? ID????? value SEGMENT
#1? 3 -0.7859574? Top 5%
#2? 3? 1.0117428? Top 5%
#3? 8 -2.1558035? Top 5%
#4? 6? 1.7803880? Top 5%
#5? 7? 0.4192816? Top 5%
#6 10 -1.0142512? Top 5%
?tail(dat1)
#??? ID????? value?? SEGMENT
#495? 1? 0.3571848 Bottom 50
#496? 9 -1.1971854 Bottom 50
#497? 5? 0.3544896 Bottom 50
#498? 8 -0.1562356 Bottom 50
#499? 8 -0.2994321 Bottom 50
#500? 8 -0.4170319 Bottom 50


A.K.



----- Original Message -----
From: Dark <info at software-solutions.nl>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 31, 2013 5:37 AM
Subject: [R] Add a column to a data frame with value based on the percentile of the row

Hi all,

I think this should be an easy question for the guru's out here.

I have this large data frame (2.500.000 rows, 15 columns) and I want to add
a column named "SEGMENT" to it.
The first 5% rows (first 125.000 rows) should have the value "Top 5%" in the
SEGMENT column
Then the rows from 5% to 20% should have the value "5 to 20"
Then 20-50% should have the value "20 to 50"
And the last 50% of the rows should have the value "Bottom 50"

What is the easiest way of doing this? I was thinking of using quantile but
then I should have some rownumber column.

Regards Derk



--
View this message in context: http://r.789695.n4.nabble.com/Add-a-column-to-a-data-frame-with-value-based-on-the-percentile-of-the-row-tp4672711.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From wewolski at gmail.com  Wed Jul 31 14:03:43 2013
From: wewolski at gmail.com (Witold E Wolski)
Date: Wed, 31 Jul 2013 14:03:43 +0200
Subject: [R] heatmap scale parameter question
Message-ID: <CAAjnpdg-RnrhWpaAWFus=kEjVBtLZ9UK-KCTeDDk2xadABAsAg@mail.gmail.com>

Would anyone of the more experienced r-users explain to me the
behaviour of the scale parameter in the heatmap function.

different options for scale (R 3.0.1) do change only the colors but do
not affect the dendrograms. Please see for yourself executing the
following code:

d <- matrix(rnorm(100),nrow=20)
stats::heatmap(d)
X11()
heatmap(d,scale="column")
X11()
heatmap(d,scale="row")
X11()
heatmap(d,scale="none")

In all four above cases the dendrograms look exactly the same
However, scaling clearly affects clustering. see:

d <- scale(d)
heatmap(d,scale="none")


best regards

R version 3.0.1 (2013-05-16) -- "Good Sport"
ciao

--
Witold Eryk Wolski


-- 
Witold Eryk Wolski


From appel at neuro.mpg.de  Wed Jul 31 14:11:29 2013
From: appel at neuro.mpg.de (Mirjam Appel)
Date: Wed, 31 Jul 2013 12:11:29 +0000
Subject: [R] Please take me out of the mailing list
Message-ID: <E5835C04D9D9FA4F94C4B1E538C727510B745B61@S60>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/d1e47e2c/attachment.pl>

From S.Ellison at LGCGroup.com  Wed Jul 31 14:22:18 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Wed, 31 Jul 2013 13:22:18 +0100
Subject: [R] Please take me out of the mailing list
In-Reply-To: <E5835C04D9D9FA4F94C4B1E538C727510B745B61@S60>
References: <E5835C04D9D9FA4F94C4B1E538C727510B745B61@S60>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED4ACBD02566@GOLD.corp.lgc-group.com>

> Subject: [R] Please take me out of the mailing list
Please follow the instructions on the mailing list page. The link is given at the bottom of every mail from the list.



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From smartpink111 at yahoo.com  Wed Jul 31 14:56:35 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 31 Jul 2013 05:56:35 -0700 (PDT)
Subject: [R] Add a column to a data frame with value based on the
	percentile of the row
In-Reply-To: <1375271321.13862.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1375263458733-4672711.post@n4.nabble.com>
	<1375271321.13862.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1375275395.68914.YahooMailNeo@web142602.mail.bf1.yahoo.com>

Hi,

?set.seed(24)
dat1<- data.frame(ID=1:500,value=rnorm(500))
?dat1 <- dat1[order(-dat1$value),]
row.names(dat1)<-1:nrow(dat1) ########


indx<-round(quantile(as.numeric(row.names(dat1)),probs=c(0.05,0.20,0.50,1)))
indx1<-findInterval(row.names(dat1),indx,rightmost.closed=TRUE)
dat1$SEGMENT<- as.character(factor(indx1,labels=c("Top 5%","5 to 20","20 to 50", "Bottom 50")))

A.K.

Hi Arun Kirshna, 

I have tested your method and it will work for me. 
I only run into one problem. Before I want to do this operation I have sorted my data frame so my rownumbers ar not subsequent. 

You can see if you first order your example data frame like: 
dat1 <- dat1[order(-dat1$value),] 

head(dat1) 
? ? ?ID ? ?value ? SEGMENT 
237 237 3.538552 ?20 to 50 
21 ? 21 3.376149 ? ?Top 5% 
421 421 3.015634 Bottom 50 
339 339 2.855991 Bottom 50 
119 119 2.589574 ?20 to 50 
12 ? 12 2.512276 ? ?Top 5% 

Do you have a solution for this? 



----- Original Message -----
From: arun <smartpink111 at yahoo.com>
To: Dark <info at software-solutions.nl>
Cc: R help <r-help at r-project.org>
Sent: Wednesday, July 31, 2013 7:48 AM
Subject: Re: [R] Add a column to a data frame with value based on the percentile of the row

Hi,
May be this helps:
set.seed(24)
dat1<- data.frame(ID=1:500,value=rnorm(500))
indx<-round(quantile(as.numeric(row.names(dat1)),probs=c(0.05,0.20,0.50,1)))
indx1<-findInterval(row.names(dat1),indx,rightmost.closed=TRUE)
dat1$SEGMENT<- as.character(factor(indx1,labels=c("Top 5%","5 to 20","20 to 50", "Bottom 50")))
head(dat1)
#? ID????? value SEGMENT
#1? 3 -0.7859574? Top 5%
#2? 3? 1.0117428? Top 5%
#3? 8 -2.1558035? Top 5%
#4? 6? 1.7803880? Top 5%
#5? 7? 0.4192816? Top 5%
#6 10 -1.0142512? Top 5%
?tail(dat1)
#??? ID????? value?? SEGMENT
#495? 1? 0.3571848 Bottom 50
#496? 9 -1.1971854 Bottom 50
#497? 5? 0.3544896 Bottom 50
#498? 8 -0.1562356 Bottom 50
#499? 8 -0.2994321 Bottom 50
#500? 8 -0.4170319 Bottom 50


A.K.



----- Original Message -----
From: Dark <info at software-solutions.nl>
To: r-help at r-project.org
Cc: 
Sent: Wednesday, July 31, 2013 5:37 AM
Subject: [R] Add a column to a data frame with value based on the percentile of the row

Hi all,

I think this should be an easy question for the guru's out here.

I have this large data frame (2.500.000 rows, 15 columns) and I want to add
a column named "SEGMENT" to it.
The first 5% rows (first 125.000 rows) should have the value "Top 5%" in the
SEGMENT column
Then the rows from 5% to 20% should have the value "5 to 20"
Then 20-50% should have the value "20 to 50"
And the last 50% of the rows should have the value "Bottom 50"

What is the easiest way of doing this? I was thinking of using quantile but
then I should have some rownumber column.

Regards Derk



--
View this message in context: http://r.789695.n4.nabble.com/Add-a-column-to-a-data-frame-with-value-based-on-the-percentile-of-the-row-tp4672711.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From elaine.kuo.tw at gmail.com  Wed Jul 31 15:03:59 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Wed, 31 Jul 2013 21:03:59 +0800
Subject: [R] merge matrix row data
Message-ID: <CAGJhoDwgdFoVnmZaTY-h66yfm+TRiTe1WYoWZRnntukpV99XGg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/74d20508/attachment.pl>

From smartpink111 at yahoo.com  Wed Jul 31 15:35:15 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 31 Jul 2013 06:35:15 -0700 (PDT)
Subject: [R] merge matrix row data
In-Reply-To: <CAGJhoDwgdFoVnmZaTY-h66yfm+TRiTe1WYoWZRnntukpV99XGg@mail.gmail.com>
References: <CAGJhoDwgdFoVnmZaTY-h66yfm+TRiTe1WYoWZRnntukpV99XGg@mail.gmail.com>
Message-ID: <1375277715.42333.YahooMailNeo@web142603.mail.bf1.yahoo.com>

HI,

Please use ?dput()
mat1<- as.matrix(read.table(text="
D0989? D9820? D5629? D4327? D2134
GID_1??? 1??????? 0??????? 0????? 1????? 0
GID_2??? 0??????? 1??????? 1????? 0????? 0
GID_4??? 0??????? 0??????? 1????? 0????? 0
GID_5??? 1??????? 1??????? 0????? 0????? 0
GID_7??? 0??????? 1??????? 0????? 0????? 1
",sep="",header=TRUE))
row.names(mat1)<- gsub("[_]"," ",row.names(mat1))
IslandA<-c("GID 1", "GID 5")
IslandB<- c("GID 2", "GID 4", "GID 7")
?res<-? t(sapply(c("IslandA","IslandB"),function(x) {x1<-mat1[match(get(x),row.names(mat1)),];(!!colSums(x1))*1} ))

?res
#??????? D0989 D9820 D5629 D4327 D2134
#IslandA???? 1???? 1???? 0???? 1???? 0
#IslandB???? 0???? 1???? 1???? 0???? 1
A.K.




----- Original Message -----
From: Elaine Kuo <elaine.kuo.tw at gmail.com>
To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
Cc: 
Sent: Wednesday, July 31, 2013 9:03 AM
Subject: [R] merge matrix row data

Dear list,



I have a matrix showing the species presence-absence on a map.

Its rows are map locations, represented by GridCellID, such as GID1 and GID
5.

Its columns are species ID, such as D0989, D9820, and D5629.

The matrix is as followed.



Now I want to merge the GridCellID according to the map location of each
island.

For instance, Island A consist of GID 1 and 5. Island B consist of GID 2,
4, and 7.

In GID 1 and 5, species D0989 are both 1.

Then I want to merge GID 1 and 5 into Island A, with species D0989 as 1.

The original matrix and the resulting matrix are listed below.

Please kindly advise how to code the calculation in R.

Please do not hesitate to ask if anything is unclear.

Thank you in advance.



Elaine



Original matrix

? ? ? ? D0989?  D9820? D5629? D4327? D2134

GID 1? ? 1? ? ? ? 0? ? ? ? 0? ? ?  1? ? ? 0

GID 2? ? 0? ? ? ? 1? ? ? ? 1? ? ?  0? ? ? 0

GID 4? ? 0? ? ? ? 0? ? ? ? 1? ? ?  0? ? ? 0

GID 5? ? 1? ? ? ? 1? ? ? ? 0? ? ?  0? ? ? 0

GID 7? ? 0? ? ? ? 1? ? ? ? 0? ? ?  0? ? ? 1



Resulting matrix

? ? ? ? ? ? ? ? D0989?  D9820? D5629? D4327? D2134

Island A?  1? ? ? ? 1? ? ?  0? ? ?  1? ? ?  0

Island B?  0? ? ? ? 1? ? ?  1? ? ?  0? ? ?  1

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From debruinjj at gmail.com  Wed Jul 31 16:57:55 2013
From: debruinjj at gmail.com (Jurgens de Bruin)
Date: Wed, 31 Jul 2013 16:57:55 +0200
Subject: [R] Highlight selected bar in barplot
Message-ID: <CAMrqo6yiM2umx7qw_w3e=fVVy_KMWbVqkjo4+tJ7OOx7tEEssw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/95d2f8ac/attachment.pl>

From szehnder at uni-bonn.de  Wed Jul 31 17:05:02 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Wed, 31 Jul 2013 17:05:02 +0200
Subject: [R] R number format with Hmisc and knitr
Message-ID: <8FF7FD94-DB2B-4878-A80A-EE0F6361E5DB@uni-bonn.de>

Dear R-Users and R-Devels,

I have a problem when using knitr in combination with Hmisc. I generate a data.frame which has mixed scientific and non-scientific numbers inside. In my Latex Table I just want to have non-scientific format, so I call

latex(myDataFrame,
file = '',
cdec = c(0, rep(4, NROW(myDataFrame) - 1)),
)

Usually this works, but in this case it doesn't. I do not know why but suspect the mixed data format to be the culprit. What could I do?

Using format(, scientific = FALSE) before or options(scipen = 4) before has no influence. 


Best

Simon


From szehnder at uni-bonn.de  Wed Jul 31 17:15:01 2013
From: szehnder at uni-bonn.de (Simon Zehnder)
Date: Wed, 31 Jul 2013 17:15:01 +0200
Subject: [R] R number format with Hmisc and knitr
In-Reply-To: <8FF7FD94-DB2B-4878-A80A-EE0F6361E5DB@uni-bonn.de>
References: <8FF7FD94-DB2B-4878-A80A-EE0F6361E5DB@uni-bonn.de>
Message-ID: <65CA5422-781B-4328-9AB0-C9FDB8F92CBD@uni-bonn.de>

Errata:

it must say:

latex(myDataFrame,
file = '',
cdec = c(0, rep(4, NCOL(myDataFrame) - 1))
)

But this does not work. Scientific notation is very robust :)

Apologize

Simon

On Jul 31, 2013, at 5:05 PM, Simon Zehnder <szehnder at uni-bonn.de> wrote:

> Dear R-Users and R-Devels,
> 
> I have a problem when using knitr in combination with Hmisc. I generate a data.frame which has mixed scientific and non-scientific numbers inside. In my Latex Table I just want to have non-scientific format, so I call
> 
> latex(myDataFrame,
> file = '',
> cdec = c(0, rep(4, NROW(myDataFrame) - 1)),
> )
> 
> Usually this works, but in this case it doesn't. I do not know why but suspect the mixed data format to be the culprit. What could I do?
> 
> Using format(, scientific = FALSE) before or options(scipen = 4) before has no influence. 
> 
> 
> Best
> 
> Simon
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From smartpink111 at yahoo.com  Wed Jul 31 17:15:43 2013
From: smartpink111 at yahoo.com (arun)
Date: Wed, 31 Jul 2013 08:15:43 -0700 (PDT)
Subject: [R] Correlation Loops in time series
Message-ID: <1375283743.84153.YahooMailNeo@web142606.mail.bf1.yahoo.com>



Hi,
May be this helps:

set.seed(25)
mt1<- matrix(sample(c(NA,1:40),20*200,replace=TRUE),ncol=200)

set.seed(487)
mt2<- matrix(sample(c(NA,1:80),20*200,replace=TRUE),ncol=200)
res<- sapply(seq_len(ncol(mt1)),function(i) cor(mt1[,i],mt2[,i],use="complete.obs",method="pearson"))


A.K.




Hello, I've got the following problem. 
I have to matrices each containing 200 time series. 
Now I want to calculate the correlation of the first time series of each of the matrices. 
I use the following command: 
cor(mts1[,1],mts2[,1], use="complete.obs", method=c("pearson")) 
cor(mts1[,2],mts2[,2], use="complete.obs", method=c("pearson")) 
cor(mts1[,3],mts2[,3], use="complete.obs", method=c("pearson")) 
and so on.. 
I would like to repeat this for each of the 200 time series. As it 
is quite painful to change the command 200 times I wanted to ask if 
there's a loop function that can cover these series in a fast way? 
Thanks in advance for your help 
Best 
Tom


From dcarlson at tamu.edu  Wed Jul 31 17:53:26 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 31 Jul 2013 10:53:26 -0500
Subject: [R] heatmap scale parameter question
In-Reply-To: <CAAjnpdg-RnrhWpaAWFus=kEjVBtLZ9UK-KCTeDDk2xadABAsAg@mail.gmail.com>
References: <CAAjnpdg-RnrhWpaAWFus=kEjVBtLZ9UK-KCTeDDk2xadABAsAg@mail.gmail.com>
Message-ID: <00e701ce8e06$17c9c450$475d4cf0$@tamu.edu>

In your example all of the values are drawn from the same
distribution so there will not be substantial differences (row
means/variances and column means/variances will be
approximately the same). 

set.seed(42)
d <- matrix(rnorm(100),nrow=20)
# Start with your example and modify the row/col means
rows <- sample.int(15:25, 20, replace=TRUE)
cols <- sample.int(5:15, 5, replace=TRUE)
d2 <- sweep(d, 2, cols, "+")
d2 <- sweep(d2, 1, rows, "+")
heatmap(d2, scale="none")
heatmap(d2, scale="row")
heatmap(d2, scale="col")

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352




-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of Witold E
Wolski
Sent: Wednesday, July 31, 2013 7:04 AM
To: r-help at r-project.org
Subject: [R] heatmap scale parameter question

Would anyone of the more experienced r-users explain to me the
behaviour of the scale parameter in the heatmap function.

different options for scale (R 3.0.1) do change only the
colors but do
not affect the dendrograms. Please see for yourself executing
the
following code:

d <- matrix(rnorm(100),nrow=20)
stats::heatmap(d)
X11()
heatmap(d,scale="column")
X11()
heatmap(d,scale="row")
X11()
heatmap(d,scale="none")

In all four above cases the dendrograms look exactly the same
However, scaling clearly affects clustering. see:

d <- scale(d)
heatmap(d,scale="none")


best regards

R version 3.0.1 (2013-05-16) -- "Good Sport"
ciao

--
Witold Eryk Wolski


-- 
Witold Eryk Wolski

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From ruipbarradas at sapo.pt  Wed Jul 31 18:39:55 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 31 Jul 2013 17:39:55 +0100
Subject: [R] Add a column to a data frame with value based on the
 percentile of the row
In-Reply-To: <51F8F37C.7070907@sapo.pt>
References: <1375263458733-4672711.post@n4.nabble.com>
	<51F8F37C.7070907@sapo.pt>
Message-ID: <51F93DDB.9030403@sapo.pt>

Hello,

Sorry, that should be 0.80, not 0.70.

qq <- quantile(x, probs = c(0, 0.50, 0.80, 0.95, 1))

Rui Barradas


Em 31-07-2013 12:22, Rui Barradas escreveu:
> Hello,
>
> Combine quantile() with findInterval(). Something like the following.
>
>
> # sample data
> x <- rnorm(100)
>
> val <- c("Bottom 50", "20 to 50", "5 to 20", "Top 5%")
> qq <- quantile(x, probs = c(0, 0.50, 0.70, 0.95, 1))
>
> idx <- findInterval(x, qq)
> val[idx]
>
>
> Hope this helps,
>
> Rui Barradas
>
> Em 31-07-2013 10:37, Dark escreveu:
>> Hi all,
>>
>> I think this should be an easy question for the guru's out here.
>>
>> I have this large data frame (2.500.000 rows, 15 columns) and I want
>> to add
>> a column named "SEGMENT" to it.
>> The first 5% rows (first 125.000 rows) should have the value "Top 5%"
>> in the
>> SEGMENT column
>> Then the rows from 5% to 20% should have the value "5 to 20"
>> Then 20-50% should have the value "20 to 50"
>> And the last 50% of the rows should have the value "Bottom 50"
>>
>> What is the easiest way of doing this? I was thinking of using
>> quantile but
>> then I should have some rownumber column.
>>
>> Regards Derk
>>
>>
>>
>> --
>> View this message in context:
>> http://r.789695.n4.nabble.com/Add-a-column-to-a-data-frame-with-value-based-on-the-percentile-of-the-row-tp4672711.html
>>
>> Sent from the R help mailing list archive at Nabble.com.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwinsemius at comcast.net  Wed Jul 31 19:02:22 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Wed, 31 Jul 2013 10:02:22 -0700
Subject: [R] Greek symbols in study labels and custom summary lines in
	forest plot (meta)
In-Reply-To: <B9A4D9CE43DAC5489E46CB4996D5B9EE467C40BB@AMSPRD0111MB497.eurprd01.prod.exchangelabs.com>
References: <B9A4D9CE43DAC5489E46CB4996D5B9EE467C40BB@AMSPRD0111MB497.eurprd01.prod.exchangelabs.com>
Message-ID: <211492D2-98F7-433A-BC8C-5C77BF23E0FF@comcast.net>


On Jul 29, 2013, at 11:52 AM, Rapsomaniki, Eleni wrote:

> Dear R helpers,
> 
> Is there a way to display mathematical notations (e.g. greek characters, subscripts) properly in study (studlab) and group (byvar) labels in a forest plot created using the meta package?
> 
> #Example:
> library(meta)
> logHR <- log(runif(10,0.5,2))
> selogHR <- log(runif(10,0.05,0.2))
> study=c(0.1,.2,.3,.4,.5,0.1,.2,.3,.4,.5)
> group=c(rep('alpha',5),rep('beta',5))
> meta1=metagen(logHR, selogHR, sm="HR",studlab=paste("Fixed",expression(beta[w]),study),byvar=group)
> forest(meta1, print.byvar=F)

I tried a variety of plotmath and substitute strategies but the arguments to studlab get first processed with 'as.character' and then put into a data.frame before printing. Dataframes do not accept language objects, so R expressions could not be processed.

> dftest <- data.frame(a =expression(a,b,c))
Error in as.data.frame.default(x[[i]], optional = TRUE) : 
  cannot coerce class ""expression"" to a data.frame


Best I could to was '

   ... ,studlab=paste('Fixed ?[w]=',study), ....

> 
> Question 2
> Is there a way to add a line to this plot at my preferred location? For example, I want to add a within-group combined estimate line (the default here is just an overall group line by random or fixed effects). 
> I know I need to use grid.lines, e.g.
> 
> grid.lines(x = 3, y = c(0.5,1),gp = gpar(col = 5))
> 
> But for the life of me I can't work out the co-ordinate system in grid graphics!

Unfortunately all of the printing to the device is handled inside the 'forest' function and no list representation is returned as a value to be augmented and later printed. So the input data would need to be entered in a manner that gets processed as text or you would need to modify the code. I don't have the knowledge of the meta package that can get there.

-- 
David Winsemius
Alameda, CA, USA


From jrkrideau at inbox.com  Wed Jul 31 19:15:18 2013
From: jrkrideau at inbox.com (John Kane)
Date: Wed, 31 Jul 2013 09:15:18 -0800
Subject: [R] Highlight selected bar in barplot
In-Reply-To: <CAMrqo6yiM2umx7qw_w3e=fVVy_KMWbVqkjo4+tJ7OOx7tEEssw@mail.gmail.com>
Message-ID: <BE59C09E63C.00001283jrkrideau@inbox.com>

It's a bit difficult to know what you are doing without any data.  Would you supply some data please.

See ?dput for the easiest way to supply it.  Also have a look at https://github.com/hadley/devtools/wiki/Reproducibility and/or http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example for some suggetions on asking questions and code formatting.

John Kane
Kingston ON Canada


> -----Original Message-----
> From: debruinjj at gmail.com
> Sent: Wed, 31 Jul 2013 16:57:55 +0200
> To: r-help at r-project.org
> Subject: [R] Highlight selected bar in barplot
> 
> Hi All,
> 
> I am new at R so any help would be appreciate.
> 
> Below my current R-code/script:
> 
> initial.dir<-getwd()
> setwd('/Users/jurgens/VirtualEnv/venv/Projects/QTLS/Resaved_Results')
> dataset <- read.table("LWxANNA_FinalReport_resaved_spwc.csv",
> header=TRUE,
> sep="\t" )
> n <- length(dataset$X..No.Call)
> x <- sort(dataset$X..No.Call,partial = n )[n]
> 
> outlier <- dataset[ dataset$X..No.Call >
> quantile(dataset$X..No.Call,0.25)
> + (IQR(dataset$X..No.Call) *1.5),]
> 
> par( las=2,  cex.axis=0.5, cex.lab=1, cex.main=2, cex.sub=1)
> barplot(dataset$X..No.Call, names.arg = dataset$Individual.Sample,
> cex.names=0.5 ,space=0.5, ylim=c(0,x*1.5) )
> setwd(initial.dir)
> 
> I would like to highlight the sample in outlier on the barplot that is
> create, would this be possible?
> 
> 
> Thanks
> --
> Regards/Groete/Mit freundlichen GrC<C?en/recuerdos/meilleures
> salutations/
> distinti saluti/siong/duC, yC:/P?Q?P8P2P5Q?
> 
> Jurgens de Bruin
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

____________________________________________________________
FREE 3D MARINE AQUARIUM SCREENSAVER - Watch dolphins, sharks & orcas on your desktop!


From dtemplelang at ucdavis.edu  Wed Jul 31 19:53:39 2013
From: dtemplelang at ucdavis.edu (Duncan Temple Lang)
Date: Wed, 31 Jul 2013 10:53:39 -0700
Subject: [R] xmlToDataFrame very slow
In-Reply-To: <CACLVabVXb2WeTwZ1x-dGE+15NpguFS-QthdjuRqkZQx+EPiPUg@mail.gmail.com>
References: <CACLVabVXb2WeTwZ1x-dGE+15NpguFS-QthdjuRqkZQx+EPiPUg@mail.gmail.com>
Message-ID: <51F94F23.5010904@ucdavis.edu>

Hi Stavros

 xmlToDataFrame() is very generic and so doesn't know anything
about the particulars of the XML it is processing. If you know
something about the structure of the XML, you should be able to leverage that
for performance.

xmlToDataFrame is also not optimized as it is just a convenience routine for people who want to work with
XML without much effort.

If you send me the file and the code you are using to read the file, I'll take a
look at it.

 D.

On 7/30/13 11:10 AM, Stavros Macrakis wrote:
> I have a modest-size XML file (52MB) in a format suited to xmlToDataFrame (package XML).
> 
> I have successfully read it into R by splitting the file 10 ways then running xmlToDataFrame on each part, then
> rbind.fill (package plyr) on the result. This takes about 530 s total, and results in a data.frame with 71k rows and
> object.size of 21MB.
> 
> But trying to run xmlToDataFrame on the whole file takes forever (> 10000 s so far). xmlParse of this file takes only 0.8 s.
> 
> I tried running xmlToDataFrame on the first 10% of the file, then the first 10% repeated twice, then three times (with
> the outer tags adjusted of course). Timings:
> 
> 1 copy: 111 s = 111 per copy
> 2 copy: 311 s = 155   " "
> 3 copy: 626 s = 209   " "
> 
> The runtime is superlinear.  What is going on here? Is there a better approach?
> 
> Thanks,
> 
>           -s
>


From f.harrell at Vanderbilt.Edu  Wed Jul 31 22:03:35 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Wed, 31 Jul 2013 15:03:35 -0500
Subject: [R] Does a general latex table-making function exist?
Message-ID: <51F96D97.6070807@vanderbilt.edu>

Our Hmisc package summary.formula function and its latex methods can 
make some fairly advanced tables.  But the tables have to be regular. 
For example, all rows of the tables are based on the same data frame. 
I'm thinking that what is needed is a ggplot2-like set of functions for 
building a table row-by-row or row-by-block of rows.  Different row 
blocks could have different denominators, e.g., the first part of the 
table might be on everyone and a latter block of rows be for females, 
with different summary statistics computed.

Has anyone already written functions creating LaTeX markup with such 
functionality?

Thanks
Frank

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From murdoch.duncan at gmail.com  Wed Jul 31 22:29:22 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 31 Jul 2013 16:29:22 -0400
Subject: [R] Does a general latex table-making function exist?
In-Reply-To: <51F96D97.6070807@vanderbilt.edu>
References: <51F96D97.6070807@vanderbilt.edu>
Message-ID: <51F973A2.8080107@gmail.com>

On 13-07-31 4:03 PM, Frank Harrell wrote:
> Our Hmisc package summary.formula function and its latex methods can
> make some fairly advanced tables.  But the tables have to be regular.
> For example, all rows of the tables are based on the same data frame.
> I'm thinking that what is needed is a ggplot2-like set of functions for
> building a table row-by-row or row-by-block of rows.  Different row
> blocks could have different denominators, e.g., the first part of the
> table might be on everyone and a latter block of rows be for females,
> with different summary statistics computed.
>
> Has anyone already written functions creating LaTeX markup with such
> functionality?

My tables package does some of what you are asking for; I'm not sure if 
it does everything.

Duncan Murdoch


From antosanf at gmail.com  Wed Jul 31 20:13:55 2013
From: antosanf at gmail.com (=?ISO-8859-1?Q?Mar=EDa_Antonieta_S=E1nchez_Farr=E1n?=)
Date: Wed, 31 Jul 2013 14:13:55 -0400
Subject: [R] qgraph: how to create legend (scale) for edge thickness?
Message-ID: <CABUNgr38F3U_c7srJRP13Vxoym8U4d6Qr6VoEPWzrdttN1XtLA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/f0a2d1cc/attachment.pl>

From bayes77 at yahoo.com.tw  Wed Jul 31 18:10:31 2013
From: bayes77 at yahoo.com.tw (Chaos Chen)
Date: Thu, 1 Aug 2013 00:10:31 +0800 (CST)
Subject: [R] problem about mean function in ffbase package
Message-ID: <1375287031.30618.YahooMailNeo@web74001.mail.tp2.yahoo.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130801/c46f868a/attachment.pl>

From dominic.roye at gmail.com  Wed Jul 31 16:39:54 2013
From: dominic.roye at gmail.com (Dominic Roye)
Date: Wed, 31 Jul 2013 16:39:54 +0200
Subject: [R] Split in blocks
Message-ID: <CALvVS-FG8NGSXBqk9=DJ1RruAawOYqE8Y8ajab74HTT4njMFiA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/4e26b334/attachment.pl>

From fabiano_vergari at mastercard.com  Wed Jul 31 13:56:23 2013
From: fabiano_vergari at mastercard.com (Vergari, Fabiano)
Date: Wed, 31 Jul 2013 11:56:23 +0000
Subject: [R] geocoding using the Google API with a key
In-Reply-To: <F493DCDB79D6614598ADDCAC0CD3B6C5162AC16E@BRUMSXP01.corp.mastercard.org>
References: <F493DCDB79D6614598ADDCAC0CD3B6C5162AC16E@BRUMSXP01.corp.mastercard.org>
Message-ID: <F493DCDB79D6614598ADDCAC0CD3B6C5162AC194@BRUMSXP01.corp.mastercard.org>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/91597903/attachment.pl>

From rslopes at fc.ul.pt  Wed Jul 31 13:23:38 2013
From: rslopes at fc.ul.pt (Rita Gamito)
Date: Wed, 31 Jul 2013 12:23:38 +0100
Subject: [R] resampling
Message-ID: <61E14673ED9D784980778EBC0E000C4C413CBC80D3@FC-MBXCLUSTER.fc.ul.pt>

Could anyone tell me how,from a pool of 1002 observations (one variable),  can I resample 1000 samples of 20 observations?
And then calculate the mean and standard deviation between 2, 3, 4, ..., 1000 samples and plot them?
Thank you!

_____________________________________

Rita Gamito
Centro de Oceanografia
Faculdade de Ci?ncias, Universidade de Lisboa
Campo Grande, 1749-016 Lisboa, Portugal
e-mail: rgamito at fc.ul.pt
Tel: + 351 21 750 00 00 - ext. 22575
Fax: + 351 21 750 02 07
www.co.fc.ul.pt

From thomas.mueller at student.unisg.ch  Wed Jul 31 15:16:25 2013
From: thomas.mueller at student.unisg.ch (TMiller)
Date: Wed, 31 Jul 2013 06:16:25 -0700 (PDT)
Subject: [R] Correlation Loops in time series
Message-ID: <1375276585399-4672732.post@n4.nabble.com>

Hello, I've got the following problem.
I have to matrices each containing 200 time series.
Now I want to calculate the correlation of the first time series of each of
the matrices.
I use the following command:
cor(mts1[,1],mts2[,1], use="complete.obs", method=c("pearson"))
cor(mts1[,2],mts2[,2], use="complete.obs", method=c("pearson"))
cor(mts1[,3],mts2[,3], use="complete.obs", method=c("pearson"))
and so on..
I would like to repeat this for each of the 200 time series. As it is quite
painful to change the command 200 times I wanted to ask if there's a loop
function that can cover these series in a fast way?
Thanks in advance for your help
Best
Tom



--
View this message in context: http://r.789695.n4.nabble.com/Correlation-Loops-in-time-series-tp4672732.html
Sent from the R help mailing list archive at Nabble.com.


From info at software-solutions.nl  Wed Jul 31 15:04:41 2013
From: info at software-solutions.nl (Dark)
Date: Wed, 31 Jul 2013 06:04:41 -0700 (PDT)
Subject: [R] Add a column to a data frame with value based on the
 percentile of the row
In-Reply-To: <1375275395.68914.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1375263458733-4672711.post@n4.nabble.com>
	<1375271321.13862.YahooMailNeo@web142602.mail.bf1.yahoo.com>
	<1375275395.68914.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1375275881930-4672728.post@n4.nabble.com>

Works like a charm, thanks a lot!



--
View this message in context: http://r.789695.n4.nabble.com/Add-a-column-to-a-data-frame-with-value-based-on-the-percentile-of-the-row-tp4672711p4672728.html
Sent from the R help mailing list archive at Nabble.com.


From info at software-solutions.nl  Wed Jul 31 14:49:15 2013
From: info at software-solutions.nl (Dark)
Date: Wed, 31 Jul 2013 05:49:15 -0700 (PDT)
Subject: [R] Add a column to a data frame with value based on the
 percentile of the row
In-Reply-To: <1375271321.13862.YahooMailNeo@web142602.mail.bf1.yahoo.com>
References: <1375263458733-4672711.post@n4.nabble.com>
	<1375271321.13862.YahooMailNeo@web142602.mail.bf1.yahoo.com>
Message-ID: <1375274955857-4672726.post@n4.nabble.com>

Hi Arun Kirshna,

I have tested your method and it will work for me.
I only run into one problem. Before I want to do this operation I have
sorted my data frame so my rownumbers ar not subsequent.

You can see if you first order your example data frame like:
dat1 <- dat1[order(-dat1$value),]

head(dat1)
     ID    value   SEGMENT
237 237 3.538552  20 to 50
21   21 3.376149    Top 5%
421 421 3.015634 Bottom 50
339 339 2.855991 Bottom 50
119 119 2.589574  20 to 50
12   12 2.512276    Top 5%

Do you have a solution for this?





--
View this message in context: http://r.789695.n4.nabble.com/Add-a-column-to-a-data-frame-with-value-based-on-the-percentile-of-the-row-tp4672711p4672726.html
Sent from the R help mailing list archive at Nabble.com.


From teresamarso at hotmail.com  Wed Jul 31 14:03:20 2013
From: teresamarso at hotmail.com (=?iso-8859-1?B?TaogVGVyZXNhIE1hcnRpbmV6IFNvcmlhbm8=?=)
Date: Wed, 31 Jul 2013 12:03:20 +0000
Subject: [R] R help
Message-ID: <BAY172-W52A3B2D284FFD99C67C05FB9570@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/cc5c4f76/attachment.pl>

From djandrija at gmail.com  Wed Jul 31 22:47:39 2013
From: djandrija at gmail.com (andrija djurovic)
Date: Wed, 31 Jul 2013 22:47:39 +0200
Subject: [R] resampling
In-Reply-To: <61E14673ED9D784980778EBC0E000C4C413CBC80D3@FC-MBXCLUSTER.fc.ul.pt>
References: <61E14673ED9D784980778EBC0E000C4C413CBC80D3@FC-MBXCLUSTER.fc.ul.pt>
Message-ID: <CABcwgRSvcOz8PiXAC32CvuPhmixBqO8Epv+cZ+DBcyPWS_b7Gw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/d1be7261/attachment.pl>

From friendly at yorku.ca  Wed Jul 31 22:52:27 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Wed, 31 Jul 2013 16:52:27 -0400
Subject: [R] Canadian common CV: how to cite R packages?
Message-ID: <51F9790B.8090208@yorku.ca>

A Q for Canadians who have filled out the new Canadian common CV for 
grant applications:  is there
any way to cite research contributions of software such as R packages, 
aside from published journal
articles? If so, where/how in the online application can they be entered?

For example, under Publications, they list Reports and Manuals,but the 
required fields there
seem to apply only to things like printed technical reports and printed 
manuals.

If the answer is: these cannot be listed, OK, but the online app is 
extremely Byzantine and maybe
there was something I missed.

TIA
-Michael

-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From dcarlson at tamu.edu  Wed Jul 31 23:05:56 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 31 Jul 2013 16:05:56 -0500
Subject: [R] Correlation Loops in time series
In-Reply-To: <1375276585399-4672732.post@n4.nabble.com>
References: <1375276585399-4672732.post@n4.nabble.com>
Message-ID: <01a901ce8e31$bff63b10$3fe2b130$@tamu.edu>

sapply(1:200, function(x) cor(mts1[,x], mts2[,x],
use="complete.obs", method=c("pearson")))

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352


-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of TMiller
Sent: Wednesday, July 31, 2013 8:16 AM
To: r-help at r-project.org
Subject: [R] Correlation Loops in time series

Hello, I've got the following problem.
I have to matrices each containing 200 time series.
Now I want to calculate the correlation of the first time
series of each of
the matrices.
I use the following command:
cor(mts1[,1],mts2[,1], use="complete.obs",
method=c("pearson"))
cor(mts1[,2],mts2[,2], use="complete.obs",
method=c("pearson"))
cor(mts1[,3],mts2[,3], use="complete.obs",
method=c("pearson"))
and so on..
I would like to repeat this for each of the 200 time series.
As it is quite
painful to change the command 200 times I wanted to ask if
there's a loop
function that can cover these series in a fast way?
Thanks in advance for your help
Best
Tom



--
View this message in context:
http://r.789695.n4.nabble.com/Correlation-Loops-in-time-series
-tp4672732.html
Sent from the R help mailing list archive at Nabble.com.

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From elaine.kuo.tw at gmail.com  Wed Jul 31 23:07:17 2013
From: elaine.kuo.tw at gmail.com (Elaine Kuo)
Date: Thu, 1 Aug 2013 05:07:17 +0800
Subject: [R] merge matrix row data
In-Reply-To: <1375277715.42333.YahooMailNeo@web142603.mail.bf1.yahoo.com>
References: <CAGJhoDwgdFoVnmZaTY-h66yfm+TRiTe1WYoWZRnntukpV99XGg@mail.gmail.com>
	<1375277715.42333.YahooMailNeo@web142603.mail.bf1.yahoo.com>
Message-ID: <CAGJhoDx1wydT=Ch0123fr2JBMD-iLfjuLyJhucs03qBbtxNvvg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130801/fd9c6766/attachment.pl>

From gunter.berton at gene.com  Wed Jul 31 23:11:39 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 31 Jul 2013 14:11:39 -0700
Subject: [R] Split in blocks
In-Reply-To: <CALvVS-FG8NGSXBqk9=DJ1RruAawOYqE8Y8ajab74HTT4njMFiA@mail.gmail.com>
References: <CALvVS-FG8NGSXBqk9=DJ1RruAawOYqE8Y8ajab74HTT4njMFiA@mail.gmail.com>
Message-ID: <CACk-te1XV78FfC+6t8qmsotPGYCJZSNWW-9YcUWaERs8qd0zCA@mail.gmail.com>

Enter
?help
at the prompt to learn how to use R's (extensive) Help system to
answer questions like this.
For this question:
?split  ## what else?

Also ?tapply, ?ave, ?aggregate, ?by

may be relevant.

Also, read "AN Introduction to R" if you haven't already done so to
start learning about R's many data manipulation and analysis features.

Cheers,
Bert

On Wed, Jul 31, 2013 at 7:39 AM, Dominic Roye <dominic.roye at gmail.com> wrote:
> Hello,
>
> I am a little bit lost on my search for a solution and idea. I would like
> to split my time serie in blocks of "night". V1 indicates if its night or
> not.
>
> How can i split this kind of cases?
>
>
> Best regards,
>
>
> str(ou[,c(1,3,8)])
> 'data.frame': 863 obs. of  3 variables:
>  $ Fecha: POSIXct, format: "2013-07-04 00:10:00" ...
>  $ Ta   : num  22.6 22.2 22.2 22.2 22.2 ...
>  $ V1   : num  1 1 1 1 1 1 1 1 1 1 ...
>
> ########
>
>  dput(ou[,c(1,3,8)])
> structure(list(Fecha = structure(c(1372889400, 1372890000, 1372890600,
> 1372891200, 1372891800, 1372892400, 1372893000, 1372893600, 1372894200,
> 1372894800, 1372895400, 1372896000, 1372896600, 1372897200, 1372897800,
> 1372898400, 1372899000, 1372899600, 1372900200, 1372900800, 1372901400,
> 1372902000, 1372902600, 1372903200, 1372903800, 1372904400, 1372905000,
> 1372905600, 1372906200, 1372906800, 1372907400, 1372908000, 1372908600,
> 1372909200, 1372909800, 1372910400, 1372911000, 1372911600, 1372912200,
> 1372912800, 1372913400, 1372914000, 1372914600, 1372915200, 1372915800,
> 1372916400, 1372917000, 1372917600, 1372918200, 1372918800, 1372919400,
> 1372920000, 1372920600, 1372921200, 1372921800, 1372922400, 1372923000,
> 1372923600, 1372924200, 1372924800, 1372925400, 1372926000, 1372926600,
> 1372927200, 1372927800, 1372928400, 1372929000, 1372929600, 1372930200,
> 1372930800, 1372931400, 1372932000, 1372932600, 1372933200, 1372933800,
> 1372934400, 1372935000, 1372935600, 1372936200, 1372936800, 1372937400,
> 1372938000, 1372938600, 1372939200, 1372939800, 1372940400, 1372941000,
> 1372941600, 1372942200, 1372942800, 1372943400, 1372944000, 1372944600,
> 1372945200, 1372945800, 1372946400, 1372947000, 1372947600, 1372948200,
> 1372948800, 1372949400, 1372950000, 1372950600, 1372951200, 1372951800,
> 1372952400, 1372953000, 1372953600, 1372954200, 1372954800, 1372955400,
> 1372956000, 1372956600, 1372957200, 1372957800, 1372958400, 1372959000,
> 1372959600, 1372960200, 1372960800, 1372961400, 1372962000, 1372962600,
> 1372963200, 1372963800, 1372964400, 1372965000, 1372965600, 1372966200,
> 1372966800, 1372967400, 1372968000, 1372968600, 1372969200, 1372969800,
> 1372970400, 1372971000, 1372971600, 1372972200, 1372972800, 1372973400,
> 1372974000, 1372974600, 1372975200, 1372975800, 1372976400, 1372977000,
> 1372977600, 1372978200, 1372978800, 1372979400, 1372980000, 1372980600,
> 1372981200, 1372981800, 1372982400, 1372983000, 1372983600, 1372984200,
> 1372984800, 1372985400, 1372986000, 1372986600, 1372987200, 1372987800,
> 1372988400, 1372989000, 1372989600, 1372990200, 1372990800, 1372991400,
> 1372992000, 1372992600, 1372993200, 1372993800, 1372994400, 1372995000,
> 1372995600, 1372996200, 1372996800, 1372997400, 1372998000, 1372998600,
> 1372999200, 1372999800, 1373000400, 1373001000, 1373001600, 1373002200,
> 1373002800, 1373003400, 1373004000, 1373004600, 1373005200, 1373005800,
> 1373006400, 1373007000, 1373007600, 1373008200, 1373008800, 1373009400,
> 1373010000, 1373010600, 1373011200, 1373011800, 1373012400, 1373013000,
> 1373013600, 1373014200, 1373014800, 1373015400, 1373016000, 1373016600,
> 1373017200, 1373017800, 1373018400, 1373019000, 1373019600, 1373020200,
> 1373020800, 1373021400, 1373022000, 1373022600, 1373023200, 1373023800,
> 1373024400, 1373025000, 1373025600, 1373026200, 1373026800, 1373027400,
> 1373028000, 1373028600, 1373029200, 1373029800, 1373030400, 1373031000,
> 1373031600, 1373032200, 1373032800, 1373033400, 1373034000, 1373034600,
> 1373035200, 1373035800, 1373036400, 1373037000, 1373037600, 1373038200,
> 1373038800, 1373039400, 1373040000, 1373040600, 1373041200, 1373041800,
> 1373042400, 1373043000, 1373043600, 1373044200, 1373044800, 1373045400,
> 1373046000, 1373046600, 1373047200, 1373047800, 1373048400, 1373049000,
> 1373049600, 1373050200, 1373050800, 1373051400, 1373052000, 1373052600,
> 1373053200, 1373053800, 1373054400, 1373055000, 1373055600, 1373056200,
> 1373056800, 1373057400, 1373058000, 1373058600, 1373059200, 1373059800,
> 1373060400, 1373061000, 1373061600, 1373062200, 1373062800, 1373063400,
> 1373064000, 1373064600, 1373065200, 1373065800, 1373066400, 1373067000,
> 1373067600, 1373068200, 1373068800, 1373069400, 1373070000, 1373070600,
> 1373071200, 1373071800, 1373072400, 1373073000, 1373073600, 1373074200,
> 1373074800, 1373075400, 1373076000, 1373076600, 1373077200, 1373077800,
> 1373078400, 1373079000, 1373079600, 1373080200, 1373080800, 1373081400,
> 1373082000, 1373082600, 1373083200, 1373083800, 1373084400, 1373085000,
> 1373085600, 1373086200, 1373086800, 1373087400, 1373088000, 1373088600,
> 1373089200, 1373089800, 1373090400, 1373091000, 1373091600, 1373092200,
> 1373092800, 1373093400, 1373094000, 1373094600, 1373095200, 1373095800,
> 1373096400, 1373097000, 1373097600, 1373098200, 1373098800, 1373099400,
> 1373100000, 1373100600, 1373101200, 1373101800, 1373102400, 1373103000,
> 1373103600, 1373104200, 1373104800, 1373105400, 1373106000, 1373106600,
> 1373107200, 1373107800, 1373108400, 1373109000, 1373109600, 1373110200,
> 1373110800, 1373111400, 1373112000, 1373112600, 1373113200, 1373113800,
> 1373114400, 1373115000, 1373115600, 1373116200, 1373116800, 1373117400,
> 1373118000, 1373118600, 1373119200, 1373119800, 1373120400, 1373121000,
> 1373121600, 1373122200, 1373122800, 1373123400, 1373124000, 1373124600,
> 1373125200, 1373125800, 1373126400, 1373127000, 1373127600, 1373128200,
> 1373128800, 1373129400, 1373130000, 1373130600, 1373131200, 1373131800,
> 1373132400, 1373133000, 1373133600, 1373134200, 1373134800, 1373135400,
> 1373136000, 1373136600, 1373137200, 1373137800, 1373138400, 1373139000,
> 1373139600, 1373140200, 1373140800, 1373141400, 1373142000, 1373142600,
> 1373143200, 1373143800, 1373144400, 1373145000, 1373145600, 1373146200,
> 1373146800, 1373147400, 1373148000, 1373148600, 1373149200, 1373149800,
> 1373150400, 1373151000, 1373151600, 1373152200, 1373152800, 1373153400,
> 1373154000, 1373154600, 1373155200, 1373155800, 1373156400, 1373157000,
> 1373157600, 1373158200, 1373158800, 1373159400, 1373160000, 1373160600,
> 1373161200, 1373161800, 1373162400, 1373163000, 1373163600, 1373164200,
> 1373164800, 1373165400, 1373166000, 1373166600, 1373167200, 1373167800,
> 1373168400, 1373169000, 1373169600, 1373170200, 1373170800, 1373171400,
> 1373172000, 1373172600, 1373173200, 1373173800, 1373174400, 1373175000,
> 1373175600, 1373176200, 1373176800, 1373177400, 1373178000, 1373178600,
> 1373179200, 1373179800, 1373180400, 1373181000, 1373181600, 1373182200,
> 1373182800, 1373183400, 1373184000, 1373184600, 1373185200, 1373185800,
> 1373186400, 1373187000, 1373187600, 1373188200, 1373188800, 1373189400,
> 1373190000, 1373190600, 1373191200, 1373191800, 1373192400, 1373193000,
> 1373193600, 1373194200, 1373194800, 1373195400, 1373196000, 1373196600,
> 1373197200, 1373197800, 1373198400, 1373199000, 1373199600, 1373200200,
> 1373200800, 1373201400, 1373202000, 1373202600, 1373203200, 1373203800,
> 1373204400, 1373205000, 1373205600, 1373206200, 1373206800, 1373207400,
> 1373208000, 1373208600, 1373209200, 1373209800, 1373210400, 1373211000,
> 1373211600, 1373212200, 1373212800, 1373213400, 1373214000, 1373214600,
> 1373215200, 1373215800, 1373216400, 1373217000, 1373217600, 1373218200,
> 1373218800, 1373219400, 1373220000, 1373220600, 1373221200, 1373221800,
> 1373222400, 1373223000, 1373223600, 1373224200, 1373224800, 1373225400,
> 1373226000, 1373226600, 1373227200, 1373227800, 1373228400, 1373229000,
> 1373229600, 1373230200, 1373230800, 1373231400, 1373232000, 1373232600,
> 1373233200, 1373233800, 1373234400, 1373235000, 1373235600, 1373236200,
> 1373236800, 1373237400, 1373238000, 1373238600, 1373239200, 1373239800,
> 1373240400, 1373241000, 1373241600, 1373242200, 1373242800, 1373243400,
> 1373244000, 1373244600, 1373245200, 1373245800, 1373246400, 1373247000,
> 1373247600, 1373248200, 1373248800, 1373249400, 1373250000, 1373250600,
> 1373251200, 1373251800, 1373252400, 1373253000, 1373253600, 1373254200,
> 1373254800, 1373255400, 1373256000, 1373256600, 1373257200, 1373257800,
> 1373258400, 1373259000, 1373259600, 1373260200, 1373260800, 1373261400,
> 1373262000, 1373262600, 1373263200, 1373263800, 1373264400, 1373265000,
> 1373265600, 1373266200, 1373266800, 1373267400, 1373268000, 1373268600,
> 1373269200, 1373269800, 1373270400, 1373271000, 1373271600, 1373272200,
> 1373272800, 1373273400, 1373274000, 1373274600, 1373275200, 1373275800,
> 1373276400, 1373277000, 1373277600, 1373278200, 1373278800, 1373279400,
> 1373280000, 1373280600, 1373281200, 1373281800, 1373282400, 1373283000,
> 1373283600, 1373284200, 1373284800, 1373285400, 1373286000, 1373286600,
> 1373287200, 1373287800, 1373288400, 1373289000, 1373289600, 1373290200,
> 1373290800, 1373291400, 1373292000, 1373292600, 1373293200, 1373293800,
> 1373294400, 1373295000, 1373295600, 1373296200, 1373296800, 1373297400,
> 1373298000, 1373298600, 1373299200, 1373299800, 1373300400, 1373301000,
> 1373301600, 1373302200, 1373302800, 1373303400, 1373304000, 1373304600,
> 1373305200, 1373305800, 1373306400, 1373307000, 1373307600, 1373308200,
> 1373308800, 1373309400, 1373310000, 1373310600, 1373311200, 1373311800,
> 1373312400, 1373313000, 1373313600, 1373314200, 1373314800, 1373315400,
> 1373316000, 1373316600, 1373317200, 1373317800, 1373318400, 1373319000,
> 1373319600, 1373320200, 1373320800, 1373321400, 1373322000, 1373322600,
> 1373323200, 1373323800, 1373324400, 1373325000, 1373325600, 1373326200,
> 1373326800, 1373327400, 1373328000, 1373328600, 1373329200, 1373329800,
> 1373330400, 1373331000, 1373331600, 1373332200, 1373332800, 1373333400,
> 1373334000, 1373334600, 1373335200, 1373335800, 1373336400, 1373337000,
> 1373337600, 1373338200, 1373338800, 1373339400, 1373340000, 1373340600,
> 1373341200, 1373341800, 1373342400, 1373343000, 1373343600, 1373344200,
> 1373344800, 1373345400, 1373346000, 1373346600, 1373347200, 1373347800,
> 1373348400, 1373349000, 1373349600, 1373350200, 1373350800, 1373351400,
> 1373352000, 1373352600, 1373353200, 1373353800, 1373354400, 1373355000,
> 1373355600, 1373356200, 1373356800, 1373357400, 1373358000, 1373358600,
> 1373359200, 1373359800, 1373360400, 1373361000, 1373361600, 1373362200,
> 1373362800, 1373363400, 1373364000, 1373364600, 1373365200, 1373365800,
> 1373366400, 1373367000, 1373367600, 1373368200, 1373368800, 1373369400,
> 1373370000, 1373370600, 1373371200, 1373371800, 1373372400, 1373373000,
> 1373373600, 1373374200, 1373374800, 1373375400, 1373376000, 1373376600,
> 1373377200, 1373377800, 1373378400, 1373379000, 1373379600, 1373380200,
> 1373380800, 1373381400, 1373382000, 1373382600, 1373383200, 1373383800,
> 1373384400, 1373385000, 1373385600, 1373386200, 1373386800, 1373387400,
> 1373388000, 1373388600, 1373389200, 1373389800, 1373390400, 1373391000,
> 1373391600, 1373392200, 1373392800, 1373393400, 1373394000, 1373394600,
> 1373395200, 1373395800, 1373396400, 1373397000, 1373397600, 1373398200,
> 1373398800, 1373399400, 1373400000, 1373400600, 1373401200, 1373401800,
> 1373402400, 1373403000, 1373403600, 1373404200, 1373404800, 1373405400,
> 1373406000, 1373406600), tzone = "", class = c("POSIXct", "POSIXt"
> )), Ta = c(22.61, 22.24, 22.17, 22.19, 22.16, 21.97, 21.7, 21.4,
> 21.11, 20.77, 20.63, 20.47, 20.31, 20.16, 19.99, 19.82, 19.8,
> 19.73, 19.6, 19.45, 19.36, 19.3, 19.2, 19.1, 19.04, 18.93, 18.94,
> 18.93, 18.83, 18.77, 18.74, 18.86, 18.79, 18.81, 18.78, 18.76,
> 18.72, 19.09, 19.17, 19.21, 19.21, 19.21, 19.32, 19.36, 19.45,
> 19.7, 19.79, 20.3, 20.01, 20.36, 20.74, 21.09, 21.55, 21.78,
> 22.24, 22.51, 22.99, 23.41, 23.55, 24.05, 24.39, 24.64, 25.03,
> 25.49, 26.13, 26.49, 27.1, 27.74, 28.26, 28.76, 29.34, 29.55,
> 30.22, 30.52, 30.77, 31.3, 31.52, 31.69, 32.32, 32.34, 32.7,
> 33.04, 33.07, 33.38, 33.61, 34.17, 34.41, 34.87, 34.83, 34.82,
> 34.86, 35.13, 35.05, 35.16, 35.52, 35.66, 35.33, 35.38, 35.03,
> 35.06, 35.06, 35.36, 35.08, 34.92, 34.76, 34.65, 34.57, 34.38,
> 34.13, 33.83, 33.73, 33.37, 33.01, 32.69, 32.42, 32.11, 31.63,
> 30.97, 30.63, 30.18, 29.66, 29.38, 29.06, 28.78, 28.54, 28.41,
> 28.33, 28.07, 27.59, 27.1, 26.75, 26.39, 26.06, 25.87, 25.72,
> 25.42, 25.21, 25.19, 25.01, 24.76, 24.5, 24.24, 23.85, 23.28,
> 23.1, 22.77, 22.63, 22.55, 22.38, 22.24, 21.79, 21.81, 21.74,
> 21.67, 21.39, 20.68, 20.17, 20.3, 20.45, 19.92, 19.55, 19.24,
> 19.19, 19.36, 19.25, 19.03, 18.94, 18.59, 18.18, 18.26, 18.47,
> 18.25, 18.32, 17.99, 18.15, 18.27, 18.32, 18.25, 18.42, 18.65,
> 19.31, 19.42, 19.87, 20.07, 20.46, 21.1, 21.38, 21.77, 22.37,
> 22.33, 22.59, 23.44, 22.78, 22.92, 22.7, 23.13, 23.55, 23.92,
> 24.24, 24.91, 25.05, 25.69, 26.19, 26.72, 27.12, 27.63, 28.19,
> 29.01, 29.42, 29.83, 30.27, 30.87, 31.39, 31.71, 32.02, 32.05,
> 32.37, 32.8, 33.22, 33.52, 34.04, 34.51, 34.78, 35.11, 35.17,
> 35.29, 35.07, 35.5, 35.98, 36.23, 36.67, 36.59, 36.56, 36.69,
> 37.1, 37.12, 37.01, 37.28, 37.31, 37.2, 37.25, 37.17, 37.38,
> 37.34, 37.48, 37.52, 37.39, 37.42, 37.32, 37.11, 37.01, 36.81,
> 36.51, 36.19, 35.73, 35.26, 34.94, 34.57, 34.2, 33.8, 33.4, 32.84,
> 32.37, 32, 31.66, 31.43, 31.08, 30.84, 30.74, 30.4, 30.16, 29.81,
> 29.43, 29.04, 28.51, 28.15, 27.82, 27.61, 27.39, 27.07, 26.8,
> 26.42, 26.03, 25.61, 25.15, 24.83, 24.55, 24.34, 24.12, 23.87,
> 23.57, 23.3, 23.08, 22.78, 22.66, 22.36, 22.18, 22.11, 22.01,
> 21.61, 21.79, 21.5, 21.15, 20.83, 20.6, 20.58, 20.51, 20.19,
> 20.16, 20.07, 20.09, 19.97, 19.67, 19.37, 19.36, 19.39, 19.09,
> 18.82, 19, 19.06, 19.06, 18.83, 18.74, 19.42, 19.78, 20.22, 20.86,
> 20.86, 20.63, 20.97, 21.48, 21.41, 22.07, 22.31, 22.45, 22.56,
> 22.91, 23.14, 23.7, 24.04, 25.13, 25.38, 25.88, 26.29, 27.75,
> 27.59, 27.76, 28.44, 28.79, 29.25, 30.15, 30.5, 30.76, 31.17,
> 31.63, 32.24, 32.65, 32.98, 33.5, 33.66, 34.26, 34.91, 35.37,
> 35.67, 35.92, 36.18, 36.56, 36.71, 37.2, 37.43, 37.61, 38.18,
> 37.97, 38.15, 38.42, 38.35, 38.16, 38.42, 38.69, 38.85, 38.94,
> 38.97, 39.11, 39.49, 39.03, 39.17, 39.08, 39.09, 39.09, 39.16,
> 39.04, 38.79, 38.81, 38.43, 37.88, 37.46, 36.88, 36.37, 35.93,
> 35.63, 35.38, 35.15, 34.88, 34.51, 34.08, 33.59, 33.04, 32.45,
> 31.95, 31.54, 31.11, 30.72, 30.38, 30.08, 29.78, 29.44, 29.05,
> 28.86, 28.53, 28.24, 28.16, 27.88, 27.55, 27.21, 26.88, 26.56,
> 26.31, 26.08, 25.79, 25.47, 25.18, 24.92, 24.69, 24.5, 24.32,
> 24.1, 23.86, 23.63, 23.49, 23.4, 23.19, 23.01, 22.87, 22.65,
> 22.54, 22.42, 22.25, 22.1, 21.63, 21.54, 21.74, 21.42, 21.23,
> 21.42, 21.24, 20.92, 20.63, 20.38, 20.53, 20.32, 20.19, 20.01,
> 20.03, 19.88, 19.77, 19.76, 20.09, 20.25, 20.6, 20.98, 21.56,
> 21.99, 21.51, 21.96, 21.73, 21.99, 22.08, 22.35, 22.91, 23.17,
> 23.39, 23.58, 23.82, 24.19, 24.57, 25.11, 25.58, 26.04, 26.15,
> 26.77, 27.19, 27.87, 28.44, 29.1, 29.58, 29.78, 30.17, 30.78,
> 31.37, 31.78, 32.45, 32.98, 33.31, 33.78, 34.49, 34.32, 34.69,
> 35.2, 35.79, 36.18, 36.6, 36.86, 37.17, 37.21, 37.96, 37.6, 38.06,
> 38.15, 39.13, 38.59, 38.39, 38.68, 38.65, 38.53, 38.81, 38.68,
> 39.43, 39.02, 38.92, 39.07, 38.82, 38.05, 37.91, 37.72, 37.59,
> 37.38, 37.19, 37.11, 36.92, 36.74, 36.54, 36.06, 35.6, 35.32,
> 34.97, 34.5, 34.14, 33.87, 33.52, 33.03, 32.54, 32.14, 31.83,
> 31.48, 31.11, 30.62, 30.27, 30.12, 29.79, 29.48, 29.02, 28.68,
> 28.45, 28.17, 27.88, 27.55, 27.12, 26.68, 26.55, 26.41, 26.02,
> 25.63, 25.34, 25.1, 24.91, 24.67, 24.43, 24.23, 23.75, 23.28,
> 23.07, 22.72, 22.4, 22.27, 22.08, 21.95, 21.7, 21.25, 21.09,
> 20.77, 20.48, 20.56, 20.16, 20.27, 20.5, 20.23, 20.29, 20.66,
> 20.62, 20.35, 19.82, 19.35, 19.2, 18.92, 18.99, 18.99, 18.63,
> 18.34, 18.6, 18.36, 18.88, 18.89, 19.03, 19.99, 20.2, 20.27,
> 20.92, 21.96, 21.37, 21.32, 21.36, 21.61, 22.2, 22.28, 22.54,
> 23.02, 23.28, 24.42, 24.58, 24.91, 25.53, 26.02, 26.29, 26.68,
> 27.5, 28.24, 28.59, 29.23, 29.2, 29.76, 30.54, 30.87, 31.04,
> 31.71, 32.04, 32.44, 33.52, 33.17, 33.98, 34.54, 34.68, 35.13,
> 34.75, 35.4, 35.62, 35.44, 35.66, 36.03, 36.26, 36.83, 36.88,
> 37.78, 37.49, 37.4, 38.12, 38.74, 38.48, 38.72, 38.41, 38.29,
> 38.49, 38.07, 37.99, 38.25, 38.02, 38.53, 39.06, 38.26, 38.77,
> 38.29, 38.16, 38.5, 38.04, 38.06, 37.91, 37.58, 37.42, 37.11,
> 36.44, 35.58, 34.36, 33.8, 33.4, 33.11, 32.74, 32.49, 32.02,
> 31.74, 31.52, 31.18, 30.77, 30.28, 29.79, 29.75, 29.49, 29.03,
> 28.76, 28.49, 28.09, 27.74, 27.65, 27.43, 27.12, 26.82, 26.41,
> 26.14, 25.96, 25.8, 25.75, 25.7, 25.49, 24.99, 24.74, 24.88,
> 24.65, 24.26, 24.03, 23.93, 23.73, 23.48, 23.37, 23.23, 23.09,
> 22.88, 22.7, 22.43, 22.27, 22.02, 21.86, 21.8, 21.52, 21.24,
> 21.21, 21.16, 20.79, 20.54, 20.39, 20.62, 20.65, 20.3, 20.45,
> 20.67, 19.95, 19.79, 19.95, 19.98, 20.61, 20.79, 20.95, 20.95,
> 20.84, 21.02, 21.43, 21.82, 21.95, 22.28, 22.49, 22.34, 22.59,
> 22.87, 23.27, 23.7, 24.03, 24.45, 24.97, 25.13, 25.7, 26.58,
> 26.82, 27.42, 28.83, 28.5, 28.61, 29.18, 28.95, 29.39, 30.38,
> 30.8, 31.57, 31.91, 32.44, 32.71, 33.13, 33.44, 33.68, 34.27,
> 33.92, 34.19, 34.85, 35.18, 35.48, 35.89, 36.02, 36.24, 36.47,
> 35.99, 35.98, 36.66, 36.32, 36.85, 36.95, 36.57, 36.36, 36.22,
> 36.06, 35.94, 36.18, 36.13, 35.54, 34.86, 34.21, 33.94, 33.85,
> 33.95, 34.23, 34.37, 34.45, 34.25, 34.28, 34.36, 34.32, 33.87,
> 33.78, 33, 32.38, 31.94, 31.52, 31.03, 30.84, 30.57, 30.22, 29.85,
> 29.62, 29.32, 29.15, 28.98, 28.8, 28.5, 28.12, 27.63, 27.2, 26.91,
> 26.77, 26.42, 26.19, 25.98, 25.68, 25.38, 25.16, 25.02, 24.76,
> 24.6, 24.4), V1 = c(1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,
> 1, 1, 1, 1, 1, 1, 1, 1, 1)), .Names = c("Fecha", "Ta", "V1"), class =
> "data.frame", row.names = c(NA,
> 863L))
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From gunter.berton at gene.com  Wed Jul 31 23:13:34 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Wed, 31 Jul 2013 14:13:34 -0700
Subject: [R] merge matrix row data
In-Reply-To: <CAGJhoDx1wydT=Ch0123fr2JBMD-iLfjuLyJhucs03qBbtxNvvg@mail.gmail.com>
References: <CAGJhoDwgdFoVnmZaTY-h66yfm+TRiTe1WYoWZRnntukpV99XGg@mail.gmail.com>
	<1375277715.42333.YahooMailNeo@web142603.mail.bf1.yahoo.com>
	<CAGJhoDx1wydT=Ch0123fr2JBMD-iLfjuLyJhucs03qBbtxNvvg@mail.gmail.com>
Message-ID: <CACk-te2V3e0Usk+P0P9hmjqfmhj83Vwr7PWuuFP6vBUusc+=jg@mail.gmail.com>

Time to do some homework, Elaine:

?regexp

There are also numerous online tutorials on regular expressions that
you can use to educate yourself.

Cheers,
Bert

On Wed, Jul 31, 2013 at 2:07 PM, Elaine Kuo <elaine.kuo.tw at gmail.com> wrote:
> Dear Arun
>
> Thank you for the very useful help.
> However, please kindly explain the code below.
> row.names(mat1)<- gsub("[_]"," ",row.names(mat1))
>
> 1. what does "[_]" mean?
> 2. what does " "  mean?
> 3. what does row.names(mat1) mean?
>
> I checked ?gsub but still did not get the idea.
>
> Thank you again
>
> Elaine
>
>
> On Wed, Jul 31, 2013 at 9:35 PM, arun <smartpink111 at yahoo.com> wrote:
>
>> HI,
>>
>> Please use ?dput()
>> mat1<- as.matrix(read.table(text="
>> D0989  D9820  D5629  D4327  D2134
>> GID_1    1        0        0      1      0
>> GID_2    0        1        1      0      0
>> GID_4    0        0        1      0      0
>> GID_5    1        1        0      0      0
>> GID_7    0        1        0      0      1
>> ",sep="",header=TRUE))
>> row.names(mat1)<- gsub("[_]"," ",row.names(mat1))
>> IslandA<-c("GID 1", "GID 5")
>> IslandB<- c("GID 2", "GID 4", "GID 7")
>>  res<-  t(sapply(c("IslandA","IslandB"),function(x)
>> {x1<-mat1[match(get(x),row.names(mat1)),];(!!colSums(x1))*1} ))
>>
>>  res
>> #        D0989 D9820 D5629 D4327 D2134
>> #IslandA     1     1     0     1     0
>> #IslandB     0     1     1     0     1
>> A.K.
>>
>>
>>
>>
>> ----- Original Message -----
>> From: Elaine Kuo <elaine.kuo.tw at gmail.com>
>> To: "r-help at stat.math.ethz.ch" <r-help at stat.math.ethz.ch>
>> Cc:
>> Sent: Wednesday, July 31, 2013 9:03 AM
>> Subject: [R] merge matrix row data
>>
>> Dear list,
>>
>>
>>
>> I have a matrix showing the species presence-absence on a map.
>>
>> Its rows are map locations, represented by GridCellID, such as GID1 and GID
>> 5.
>>
>> Its columns are species ID, such as D0989, D9820, and D5629.
>>
>> The matrix is as followed.
>>
>>
>>
>> Now I want to merge the GridCellID according to the map location of each
>> island.
>>
>> For instance, Island A consist of GID 1 and 5. Island B consist of GID 2,
>> 4, and 7.
>>
>> In GID 1 and 5, species D0989 are both 1.
>>
>> Then I want to merge GID 1 and 5 into Island A, with species D0989 as 1.
>>
>> The original matrix and the resulting matrix are listed below.
>>
>> Please kindly advise how to code the calculation in R.
>>
>> Please do not hesitate to ask if anything is unclear.
>>
>> Thank you in advance.
>>
>>
>>
>> Elaine
>>
>>
>>
>> Original matrix
>>
>>         D0989   D9820  D5629  D4327  D2134
>>
>> GID 1    1        0        0       1      0
>>
>> GID 2    0        1        1       0      0
>>
>> GID 4    0        0        1       0      0
>>
>> GID 5    1        1        0       0      0
>>
>> GID 7    0        1        0       0      1
>>
>>
>>
>> Resulting matrix
>>
>>                 D0989   D9820  D5629  D4327  D2134
>>
>> Island A   1        1       0       1       0
>>
>> Island B   0        1       1       0       1
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From bruce087 at umn.edu  Wed Jul 31 22:47:31 2013
From: bruce087 at umn.edu (bruce087 at umn.edu)
Date: 31 Jul 2013 15:47:31 -0500
Subject: [R] double matrix?
Message-ID: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>

Hi-

I have a 37 X 473971 character matrix that I am trying to convert into a 
numeric matrix. When I use the code:

 class(matrix) = "numeric"  

I end up with something called a "double matrix" whose dimensions are still 
37 X 473971

I have also tried 

new = apply(matrix,2, as.numeric) and got the same thing.

The analysis code I am ultimately attempting to run on this data requires 
that it be in a numerical matrix, and it is really not okay with a double 
matrix.

Does anyone know how to fix this?

Thanks.

-- 
Jessica R.B. Musselman, MS
T32 Trainee/Doctoral Candidate
University of Minnesota
Department of Pediatrics
Division of Epidemiology/Clinical Research
Mayo Mail Code 715
Room 1-195 Moos Tower
420 Delaware St. SE
Minneapolis MN 55455
Phone: (612)626-3281
email: bruce087 at umn.edu


From f.harrell at Vanderbilt.Edu  Wed Jul 31 23:41:22 2013
From: f.harrell at Vanderbilt.Edu (Frank Harrell)
Date: Wed, 31 Jul 2013 16:41:22 -0500
Subject: [R] Does a general latex table-making function exist?
Message-ID: <51F98482.4000405@vanderbilt.edu>

Duncan,

I had read your excellent tables package vignette at 
http://cran.r-project.org/web/packages/tables/vignettes/tables.pdf when 
it first came out.  It is extremely impressive.  I'm glad to be reminded 
to give it another look.

Is there a way to make the special symbols n and 1 refer to the number 
of non-missing observations rather than the length of a vector?

Do you feel like taking on this challenge?  An example of an irregular 
table I'm thinking of is the following

                Females              Males
              Q1 Med Q3   (n)       Q1 Med Q3   (n)
Age          25  49 63 (1016)     26  50 64  (1767)

Canadians
  Weight (kg) 57  63 74 ( 243)     67  73 90  ( 401)

Canadians could mean country=='Canada'.

Thanks!
Frank

-- 
Frank E Harrell Jr Professor and Chairman      School of Medicine
                    Department of Biostatistics Vanderbilt University


From dmck at u.washington.edu  Wed Jul 31 23:46:13 2013
From: dmck at u.washington.edu (Don McKenzie)
Date: Wed, 31 Jul 2013 14:46:13 -0700
Subject: [R] double matrix?
In-Reply-To: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
References: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
Message-ID: <CA874EEC-B898-4394-B033-A32E7CBAD9D2@u.washington.edu>

What are the entries in your matrix?  If they are something that won't coerce to numeric, you need to backtrack. Note how R distinguishes types of characters.

> as.numeric("a")
[1] NA
Warning message:
NAs introduced by coercion 
> as.character(2)
[1] "2"
> as.numeric("2")
[1] 2


On Jul 31, 2013, at 1:47 PM, bruce087 at umn.edu wrote:

> Hi-
> 
> I have a 37 X 473971 character matrix that I am trying to convert into a numeric matrix. When I use the code:
> 
> class(matrix) = "numeric"  
> I end up with something called a "double matrix" whose dimensions are still 37 X 473971
> 
> I have also tried 
> new = apply(matrix,2, as.numeric) and got the same thing.
> 
> The analysis code I am ultimately attempting to run on this data requires that it be in a numerical matrix, and it is really not okay with a double matrix.
> 
> Does anyone know how to fix this?
> 
> Thanks.
> 
> -- 
> Jessica R.B. Musselman, MS
> T32 Trainee/Doctoral Candidate
> University of Minnesota
> Department of Pediatrics
> Division of Epidemiology/Clinical Research
> Mayo Mail Code 715
> Room 1-195 Moos Tower
> 420 Delaware St. SE
> Minneapolis MN 55455
> Phone: (612)626-3281
> email: bruce087 at umn.edu
> 
> ______________________________________________
> R-help at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

Don McKenzie, Research Ecologist
Pacific WIldland Fire Sciences Lab
US Forest Service

Affiliate Professor
School of Forest Resources, College of the Environment
CSES Climate Impacts Group
University of Washington

phone: 206-732-7824
dmck at uw.edu


From rmh at temple.edu  Wed Jul 31 23:53:14 2013
From: rmh at temple.edu (Richard M. Heiberger)
Date: Wed, 31 Jul 2013 17:53:14 -0400
Subject: [R] double matrix?
In-Reply-To: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
References: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
Message-ID: <CAGx1TMADndkjwjjq4uN-5HGTUf71NPgLzL8274e9aa_vLqODSA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20130731/e627d4d8/attachment.pl>

From ruipbarradas at sapo.pt  Wed Jul 31 23:53:19 2013
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Wed, 31 Jul 2013 22:53:19 +0100
Subject: [R] double matrix?
In-Reply-To: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
References: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
Message-ID: <51F9874F.2090206@sapo.pt>

Hello,

"double" and "numeric" are the same. From the help page for ?double, 
section "Note on names"

"It is a historical anomaly that R has two names for its floating-point 
vectors, double and numeric (and formerly had real)."

Apparently you are successfully converting characters to double 
precision floating-point numbers.

Hope this helps,

Rui Barradas


Em 31-07-2013 21:47, bruce087 at umn.edu escreveu:
> Hi-
>
> I have a 37 X 473971 character matrix that I am trying to convert into a
> numeric matrix. When I use the code:
>
> class(matrix) = "numeric"
> I end up with something called a "double matrix" whose dimensions are
> still 37 X 473971
>
> I have also tried
> new = apply(matrix,2, as.numeric) and got the same thing.
>
> The analysis code I am ultimately attempting to run on this data
> requires that it be in a numerical matrix, and it is really not okay
> with a double matrix.
>
> Does anyone know how to fix this?
>
> Thanks.
>


From dcarlson at tamu.edu  Wed Jul 31 23:54:35 2013
From: dcarlson at tamu.edu (David Carlson)
Date: Wed, 31 Jul 2013 16:54:35 -0500
Subject: [R] double matrix?
In-Reply-To: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
References: <Gophermail.2.0.1307311547310.17321@vs-a.tc.umn.edu>
Message-ID: <01c901ce8e38$8bd3cf30$a37b6d90$@tamu.edu>

It is hard to understand that your R code will not work with a
double matrix since double is just short for double precision
floating point matrix. Your only alternative would be integer.

>From ?numeric

"It is a historical anomaly that R has two names for its
floating-point vectors, double and numeric (and formerly had
real).

"double is the name of the type. numeric is the name of the
mode and also of the implicit class."

-------------------------------------
David L Carlson
Associate Professor of Anthropology
Texas A&M University
College Station, TX 77840-4352

-----Original Message-----
From: r-help-bounces at r-project.org
[mailto:r-help-bounces at r-project.org] On Behalf Of
bruce087 at umn.edu
Sent: Wednesday, July 31, 2013 3:48 PM
To: r-help at r-project.org
Subject: [R] double matrix?

Hi-

I have a 37 X 473971 character matrix that I am trying to
convert into a 
numeric matrix. When I use the code:

 class(matrix) = "numeric"  

I end up with something called a "double matrix" whose
dimensions are still 
37 X 473971

I have also tried 

new = apply(matrix,2, as.numeric) and got the same thing.

The analysis code I am ultimately attempting to run on this
data requires 
that it be in a numerical matrix, and it is really not okay
with a double 
matrix.

Does anyone know how to fix this?

Thanks.

-- 
Jessica R.B. Musselman, MS
T32 Trainee/Doctoral Candidate
University of Minnesota
Department of Pediatrics
Division of Epidemiology/Clinical Research
Mayo Mail Code 715
Room 1-195 Moos Tower
420 Delaware St. SE
Minneapolis MN 55455
Phone: (612)626-3281
email: bruce087 at umn.edu

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide
http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible
code.


From sjackman at gmail.com  Wed Jul 31 23:58:19 2013
From: sjackman at gmail.com (Shaun Jackman)
Date: Wed, 31 Jul 2013 14:58:19 -0700
Subject: [R] Convert rbind of lists to data.frame
Message-ID: <CADX6M3r=2jUGY0n41swRyP=M-POosTgfkHygWDgH1E66XH453Q@mail.gmail.com>

I'm trying to build a data.frame row-by-row like so:

df <- data.frame(rbind(list('a',1), list('b', 2), list('c', 3)))

I was surprised to see that the columns of the resulting data.frame
are stored in lists rather than vectors.

str(df)
'data.frame': 3 obs. of  2 variables:
 $ X1:List of 3
  ..$ : chr "a"
  ..$ : chr "b"
  ..$ : chr "c"
 $ X2:List of 3
  ..$ : num 1
  ..$ : num 2
  ..$ : num 3

The desired result is:

str(df)
'data.frame': 3 obs. of  2 variables:
 $ X1: chr  "a" "b" "c"
 $ X2: num  1 2 3

The following works, but is rather ugly:

df <- data.frame(lapply(data.frame(rbind(list('a',1), list('b', 2),
list('c', 3))), unlist))

Thanks,
Shaun


