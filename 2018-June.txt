From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Jun  1 03:46:16 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 31 May 2018 18:46:16 -0700
Subject: [R] Help About R-Package Portability
In-Reply-To: <CAFkrz9bzvirESLgtJd-9eSxW4LzKyhvt7rVr3k26ToMb4xLJpw@mail.gmail.com>
References: <CAFkrz9bzvirESLgtJd-9eSxW4LzKyhvt7rVr3k26ToMb4xLJpw@mail.gmail.com>
Message-ID: <ACB491C6-462C-4F29-924C-5590446258FC@dcn.davis.ca.us>

Your lack of permissions is highly operating-system-specific and local-policy-specific and therefore outside the scope of this mailing list... I suggest you have a conversation with your system administrator(s). Insuring the ability to run R code when the admin is not cooperating is not really something we can help with. (Some systems are configured to prevent any executables from running off removable media at all.)

You should also read

?.libPaths

as well as the R Installation and Administration manual.

On May 31, 2018 6:02:35 AM PDT, BEDIRHAN CALDIR <bcaldir at ku.edu.tr> wrote:
>Hi,
>
>I'm having an issue with R package configurations which I thought the
>community would help me. I have two softwares written in R, DECoN and
>panelcn.mops, and need to run both of them isolated. The problem is
>that I
>couldn't install them onto neither the OS with the sudo permissions nor
>the
>home folder of a specific user with the right permissions. What I need
>is
>making them as portable as possible by installing R-related packages
>separately once and for all, so that I can run any of them even from a
>USB
>drive where no further R installation would be required. I'll run both
>of
>them from Python as a subprocess.
>
>I'd appreciate any suggession to overcome this issue. Thank you in
>advance.

-- 
Sent from my phone. Please excuse my brevity.


From bori@@@teipe @ending from utoronto@c@  Fri Jun  1 05:53:09 2018
From: bori@@@teipe @ending from utoronto@c@ (Boris Steipe)
Date: Thu, 31 May 2018 23:53:09 -0400
Subject: [R] How to alpha entire plot?
In-Reply-To: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
References: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
Message-ID: <FDB33FD3-BD35-4B9A-883A-B1469BAB7C0F@utoronto.ca>

Interesting problem.

I would discretize the x-values and interleave them. Lines from one dataset still overlap, so you see high- density and low-density regions, but lines from the other dataset are drawn into the interval. Like so:

interleave <- function(x, MIN, MAX, N, nChannel = 2, channel) {
  
  isp <- seq(MIN, MAX, length.out = N + 1) # interleave support points
  offset <- ((isp[2] - isp[1]) / nChannel) * (channel - 1) # offset for channel
  
  # round x to the nearest support point and add the channel specific offset
  x <- isp[round(as.numeric(cut(x, breaks = N)))] + offset
  
  return(x)
}

xi <- min(EU$DAX)
xa <- max(EU$DAX)

plot(interleave(EU$DAX, MIN=xi, MAX=xa, N=130, channel=1 ),
     EU$CAC,
     col = "#6600EE07",
     type = "h",
     ylim = c(0,6000),
     xlab = "DAX")

points(interleave(EU$DAX, MIN = xi, MAX = xa, N = 130, channel = 2 ),
     EU$FTSE,
     col = "#EE000007",
     type = "h")


Cheers,
B.



> On 2018-05-31, at 16:56, Ed Siefker <ebs15242 at gmail.com> wrote:
> 
> I have two chromatograms I want plotted on the same axes.
> I would like the plots to be transparent, so the first chart is
> not obscured.
> 
> I have tried adjustcolor(..., alpha.f=0.3), the problem is that
> my chromatogram is so dense with datapoints that they
> overlap and the entire graph just ends up a solid color.  The
> second histogram still obscures the first.
> 
> Consider this example:
> 
> 
> col1 <- adjustcolor("red", alpha.f=0.3)
> col2 <- adjustcolor("blue", alpha.f=0.3)
> EU <- data.frame(EuStockMarkets)
> with(EU, plot(DAX, CAC, col=col2, type="h", ylim=c(0,6000)))
> par(new=TRUE)
> with(EU, plot(DAX, FTSE, col=col1, type="h", ylim=c(0,6000)))
> 
> The density of the red plot around 2000 completely obscures the blue
> plot behind it.
> 
> What I would like to do is plot both plots in solid colors, then alpha
> the entire thing, and then overlay them.  Or some other method that
> achieves a comparable result.
> Thanks
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nunub@h @ending from y@hoo@com  Fri Jun  1 00:37:38 2018
From: nunub@h @ending from y@hoo@com (Wedaj Bahiru)
Date: Thu, 31 May 2018 22:37:38 +0000 (UTC)
Subject: [R] Help in dynamic simulation using deSolve
References: <530845079.7447270.1527806258446.ref@mail.yahoo.com>
Message-ID: <530845079.7447270.1527806258446@mail.yahoo.com>

Hi R help,
I wanted to simulate two pool model (A&B) using deSolve package for time 0 to 12 by 1.? Initial values of the state variables are A=5, B=3. The fluxes are as follows1) Flux into A= 5 units per unit time?2) Flux from A to B= 0.33) Flux out of A=0.1?4) Flux from B to A=0.35) Flux out of B=0.3
Here is the R code I compiled to estimate the size of A and B and graph the output
library(deSolve)
# Define time sequence from 0 to 12 by 1
time <- seq(0,12, by=1)
# Define the function?
Mod <- function (t, parms){? derivs <- function(t, state, parms){? ? with(as.list (c(state, parms)), {? ? ??? ? ? #Fluxes? ? ??? ? ? inA <- kinA? ? ? AtoB <- kAtoB*A? ? ? Aout <- kAout*A? ? ? inB <- kinB? ? ? BtoA <- kBtoA*B? ? ? Bout <- kBout*B? ? ??? ? ? # Rate of change? ? ? dA <- inA+BtoA-AtoB-Aout? ? ? dB <- inB+AtoB-BtoA-Bout? ? ??? ? ??? ? ? return (list (c(dA, dB)))? ? })? }??? #Step 4: Define some starting values for the pools??? state <- c(A=5, B=3)??? ?return (ode(y=state, times=t,func=derivs, parms=parms, method="rk4"))}
# Starting values of fluxes/parameterspars <- c(kinA=5, kAtoB=0.3, kAout=0.1, kinB=2, kBtoA=0.3, kBout=0.3)
#Model results
Mod(time, pars)data <- data.frame(Mod(time, pars))plot(Mod(time, pars))
The result does not look right. I could not figure out where I made a mistake in compiling code.??
Any help is highly appreciated.?
Wodaj
	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Jun  1 13:20:05 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 1 Jun 2018 11:20:05 +0000
Subject: [R] Time-series moving average question
Message-ID: <SN1PR0201MB18404E4546FE7FF73A50633BEA620@SN1PR0201MB1840.namprd02.prod.outlook.com>

Good morning, I hope someone can help with these questions, or perhaps suggest one of the other R-lists?

I have two questions:


  1.  Why am I getting this warning?
  2.  Why is the second example "Point Forecast" the same value, I do not see that in previous attempts with similar but different data sets as in example 1?

Example1:
dat3 <- structure(c(3539122.86, 3081383.87, 4158672.31, 4137518.78, 4123682.08, 4819375.2, 4342687.77, 5028674.58, 4472145.07, 4967277.73, 4516240.31, 4876194.63, 4816446.59,
                    4887399.37, 5478504.85, 4871385.27, 5487543.68, 5464193.69, 5252591.03, 7071416.89, 5524350.89, 6107166.69, 6530003.55, 6445929.08, 7356743.81, 6750025.03,
                    6934714.08, 6656194.35

                    ,-13913, -29385.31, -39633.37, -23487.13, -18202.86, -57335.49, -26061.45, -60880.07, -17589.45, -35970.08, -89133.94,
                    -84694.58, -31724.89, -29847.95, -65421.74, -34334.22, -48511.98, -30298.97, -38729.46, -29292.89, -46098.4, -65909.49,
                    -85879.23, -71845.28, -69017.07, -93161.03, -70847.29, -85106.04

                    ,-357694.19, -444792.75, -361349.57, -386717.55, -547422.05, -518259.22, -417613.76, -578631.46, -804516.81, -572875.52, -510487.53,
                    -666294.87, -673233.37, -556564.45, -963346.75, -639288.2, -910104.23, -773428.8, -1008078.84, -546685.3, -729932.94, -987098.23,
                    -964001.63, -986995.93, -680066.58, -728854.58, -730766.92, -753861.59)
                    ,.Dim = c(28L, 3L)
                    ,.Dimnames = list(NULL, c("OONNetRev","OONAdjusted" ,"OONCancelled"))
                    ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
head(dat3); nrow(dat3)

TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
TNR_moving_average

# Warning message:
#   In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
#            Missing values encountered. Using longest contiguous portion of time series
#          > Point Forecast         Lo 80         Hi 80         Lo 95         Hi 95
#         28  7007065.99688 6675015.72012 7339116.27365 6499238.92148 7514893.07229
#         29  7135745.42473 6721543.41996 7549947.42950 6502278.12345 7769212.72601
#         30  7264424.85258 6779532.18065 7749317.52450 6522845.50541 8006004.19974
#         31  7393104.28042 6844496.10189 7941712.45896 6554080.47486 8232128.08599
#         32  7521783.70827 6914203.11991 8129364.29663 6592569.38486 8450998.03168
#         33  7650463.13612 6987355.72657 8313570.54567 6636327.86794 8664598.40429
#         34  7779142.56396 7063123.29787 8495161.83005 6684085.59434 8874199.53358
#         35  7907821.99181 7140937.69145 8674706.29217 6734973.66528 9080670.31834




Example2:
dat3 <- structure(c(994320.58, 811664.54, 1045259.43, 951659.48, 669458.94, 986741.09, 1023344.82, 938971.65, 897670.06, 1040074.6, 1090310.01,
                    1289821.17, 1187806.23, 971485.76, 1161147.42, 870585.04, 1021301.52, 1215798.03, 1015004.43, 1365863.09, 995769.41,
                    1331725.36, 1271032.91, 1092103.82, 1297131.4, 1129195.28, 1372594.58, 1553717.57,

                    -39811.51, -47356.74, -49046.86, -41311.13, -79063.98, -43916.59, -16746.33, -38347.9, -84797.44, -38961.44,
                    -72036.83, -62854.78, -35259.84, -44198.39, -34262.65, -49245.82, -34977.28, -36797.35, -47534.43, -33515.13,
                    -25764.41, -29130.53, -57693.63, -51026.83, -49624.49, -36508.13, -32667.21, -37900.5,

                    -247443.87, -372942.34, -344080.78, -355586.21, -458998.84, -378086.44, -333994.18, -567024.45, -521499.8, -428915.13,
                    -512034.28, -440865.42, -347494.22, -422436.19, -444588.65, -462891.57, -518395.47, -373818.5, -398899.53, -381573.69,
                    -531449.2, -476238.48, -434296.86, -655679.94, -528999.52, -423725.95, -556977.31, -518633.95)
                  ,.Dim = c(28L, 3L)
                  ,.Dimnames = list(NULL, c("EditNetRev","EditNetAdjusted" ,"EditNetCancelled"))
                  ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
head(dat3); nrow(dat3)



TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
TNR_moving_average

# Warning message:
# In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
#          Missing values encountered. Using longest contiguous portion of time series
#        > TNR_moving_average
#        Point Forecast         Lo 80         Hi 80          Lo 95         Hi 95
#        28  1351827.24389 1246570.02118 1457084.46661 1190850.213255 1512804.27453
#        29  1351827.24389 1202841.21791 1500813.26987 1123972.779844 1579681.70794
#        30  1351827.24389 1169192.03201 1534462.45578 1072510.790913 1631143.69687
#        31  1351827.24389 1140745.29674 1562909.19105 1029005.263624 1674649.22416
#        32  1351827.24389 1115613.58783 1588040.89996  990569.631639 1713084.85615
#        33  1351827.24389 1092829.78856 1610824.69923  955724.817592 1747929.67020
#        34  1351827.24389 1071819.89899 1631834.58880  923592.964312 1780061.52348
#        35  1351827.24389 1052210.25675 1651444.23104  893602.604521 1810051.88327

Thank you for any advice or direction.


WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From @@himk@poor @ending from gm@il@com  Fri Jun  1 14:00:21 2018
From: @@himk@poor @ending from gm@il@com (Ashim Kapoor)
Date: Fri, 1 Jun 2018 17:30:21 +0530
Subject: [R] Last page on a multi page, faceted graph created using ggforce,
 loses its layout under a certain condition
Message-ID: <CAC8=1epkp9Wf446udo11Vk=He1_CciJ38w_9U-kkbHTzXn--Cw@mail.gmail.com>

Dear All,

I posted this query on stack overflow but I received no replies so I am
posting it here so that someone here can take a look at this.

My query is that suppose the variable I am faceting by has 40 categories
and I want 3 categories per page( 1 row x 3 columns),then the last category
fills the entire second page. I want the last category to fill only the
left - most position in the grid and the remaining 2 places to be empty on
the last page.

Here is the link to the stackoverflow query which has a reprex in it as
well:

https://stackoverflow.com/questions/50604211/facetting-a-graph-across-multiple-pages-and-keeping-the-same-layout-on-all-pag

Many thanks and Best Regards,
Ashim

	[[alternative HTML version deleted]]


From md@umner @ending from gm@il@com  Fri Jun  1 14:14:23 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Fri, 1 Jun 2018 22:14:23 +1000
Subject: [R] Problem with adding a raster and a brick
In-Reply-To: <CAAcGz9-fKOWXMawV5ygUdrk7qnfcFqxhnvyhG9rvVH+W5r3dzQ@mail.gmail.com>
References: <CAGBzUO-LrEB7kfKBvGD=uD+5Dh6-UXdqQhXTBbZBVCDpALMYSg@mail.gmail.com>
 <CAAcGz9-fKOWXMawV5ygUdrk7qnfcFqxhnvyhG9rvVH+W5r3dzQ@mail.gmail.com>
Message-ID: <CAAcGz98ib=gfC6B5bTE0ZPCZoTbFM3nPinpAhiQWqTqp7B6cAg@mail.gmail.com>

This is now fixed in development on RForge, you can try it out by
installing from there, or from the Github mirror with
devtools::install_github("rforge/raster/pkg/raster").

(To get fixes into raster email the maintainer directly - you might not get
a response but it'll be addressed).

Cheers, Mike.


On Thu, 24 May 2018 at 20:08 Michael Sumner <mdsumner at gmail.com> wrote:

>
>
>
> On Thu, 24 May 2018 at 18:41 Mark R Payne <markpayneatwork at gmail.com>
> wrote:
>
> Hi,
>
> I seem to be having a problem adding the following two raster objects
> together - one is a rasterLayer, the other is a rasterBrick. The extent,
> resolution, and origin are the same, so according to my understand it
> should work. The objects look like so:
>
> > obs.clim
> class : RasterLayer
> dimensions : 60, 200, 12000 (nrow, ncol, ncell)
> resolution : 0.5, 0.5 (x, y)
> extent : -70, 30, 50, 80 (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
> /home/mpayne/Documents/Predictability_engine/scratch/Bluefin/HadISST/
> obs_climatology.nc
> names : sst
> z-value : 1988-02-15
> zvar : sst
>
> > mdl.anom
> class : RasterBrick
> dimensions : 60, 200, 12000, 1 (nrow, ncol, ncell, nlayers)
> resolution : 0.5, 0.5 (x, y)
> extent : -70, 30, 50, 80 (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
>
> /home/mpayne/Documents/Predictability_engine/scratch/Bluefin/DCPP-hindcasts/IPSL-CM5A-LR/B.realmean/IPSL-CM5A-LR_S19610101_L000000_realmean_
> anom.nc
>
> names : X1961.08.16
> Date : 1961-08-16
> varname : tos
>
> When I try to add them together, I get the follow error:
>
> > mdl.val <- obs.clim + mdl.anom
> Error in .readRowsNetCDF(x = x, row = row, nrows = nrows, col = col, ncols
> = ncols) :
> no slot of name "band" for this object of class ".MultipleRasterData"
> >
>
> I can reproduce, with netcf-file-backed bricks. I would try
>
> obs.clim[[1]] + mdl.anom[[1]]
>
> or
>
> readAll(obs.clim) + readAll(mdl.anom)
>
> those differ mainly in what will happen to multi-layer versions of the
> files, the first will give just the first layer. The key is breaking the
> file-read-delay, both objects have no data in memory but the add operation
> invalidates and causes read to occur - but with a bug - (I will check in
> dev raster and report if necessary).
>
> FYI, R-Sig-Geo is generally a better forum for spatial stuff:
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> Cheers, Mike.
>
>
> I get the same error if I treat mdl.anom as a raster, or if they are both
> bricks. Any suggestions what could be going wrong? Installation details
> below
>
> Best wishes,
>
> Mark
>
> > R.version
> _
> platform x86_64-pc-linux-gnu
> arch x86_64
> os linux-gnu
> system x86_64, linux-gnu
> status
> major 3
> minor 4.2
> year 2017
> month 09
> day 28
> svn rev 73368
> language R
> version.string R version 3.4.2 (2017-09-28)
> nickname Short Summer
> >
> > packageDescription("raster")
> Package: raster
> Type: Package
> Title: Geographic Data Analysis and Modeling
> Version: 2.6-7
> Date: 2017-11-12
>
> > packageDescription("ncdf4")
> Package: ncdf4
> Version: 1.16
> Date: 2017-04-01
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Fri Jun  1 15:08:53 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Fri, 1 Jun 2018 18:38:53 +0530
Subject: [R] Unable to take correct Web-snapshot
Message-ID: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>

Hi again,

I use the *webshot* package to take snapshot from Webpage. However, when I
try to take snapshot from* https://www.coinbase.com/
<https://www.coinbase.com/>*, this fails to take the full snapshot of that
page.

I tried following :

> library(webshot)
> webshot("https://www.coinbase.com/", 'aa.pdf')

However in the pdf page, I done see the quotes which are available on the
main page in the 4 boxes.

Any help how to resolve this would be highly appreciated.

Thanks,

	[[alternative HTML version deleted]]


From tr@xpl@yer @ending from gm@il@com  Fri Jun  1 17:05:40 2018
From: tr@xpl@yer @ending from gm@il@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 1 Jun 2018 17:05:40 +0200
Subject: [R] Unable to take correct Web-snapshot
In-Reply-To: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
References: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
Message-ID: <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>

On 1 June 2018 at 15:08, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I use the *webshot* package to take snapshot from Webpage. However, when I
> try to take snapshot from* https://www.coinbase.com/
> <https://www.coinbase.com/>*, this fails to take the full snapshot of that
> page.

Yes, that is a general problem with many webshot programs and libraries.

The coinbase page ( and many others ) uses a lot of javascript to generate their
pages and the webshot programs must understand javascript in all
details which is hard.

If you are looking for the coinbase prices you can use their api to
get json instead:

https://api.coinbase.com/v2/prices/spot?currency=USD

Regards
Martin


From bog@@o@chri@tofer @ending from gm@il@com  Fri Jun  1 17:12:57 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Fri, 1 Jun 2018 20:42:57 +0530
Subject: [R] Unable to take correct Web-snapshot
In-Reply-To: <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>
References: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
 <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>
Message-ID: <CA+dpOJ=u+j1Xd1D+k8Er403A5-LMp=ozH=eBL2=Ytjs6CWkqKw@mail.gmail.com>

Thanks for that information.

However how can I use R to directly get data from that API?

On Fri, Jun 1, 2018 at 8:36 PM Martin M?ller Skarbiniks Pedersen <
traxplayer at gmail.com> wrote:

> On 1 June 2018 at 15:08, Christofer Bogaso <bogaso.christofer at gmail.com>
> wrote:
> > Hi again,
> >
> > I use the *webshot* package to take snapshot from Webpage. However, when
> I
> > try to take snapshot from* https://www.coinbase.com/
> > <https://www.coinbase.com/>*, this fails to take the full snapshot of
> that
> > page.
>
> Yes, that is a general problem with many webshot programs and libraries.
>
> The coinbase page ( and many others ) uses a lot of javascript to generate
> their
> pages and the webshot programs must understand javascript in all
> details which is hard.
>
> If you are looking for the coinbase prices you can use their api to
> get json instead:
>
> https://api.coinbase.com/v2/prices/spot?currency=USD
>
> Regards
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Fri Jun  1 17:23:40 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 1 Jun 2018 15:23:40 +0000
Subject: [R] Time-series moving average question
Message-ID: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>

My guess would be that if you inspect the output from
    ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/1/18, 4:20 AM, "R-help on behalf of Bill Poling" <r-help-bounces at r-project.org on behalf of Bill.Poling at zelis.com> wrote:

    Good morning, I hope someone can help with these questions, or perhaps suggest one of the other R-lists?
    
    I have two questions:
    
    
      1.  Why am I getting this warning?
      2.  Why is the second example "Point Forecast" the same value, I do not see that in previous attempts with similar but different data sets as in example 1?
    
    Example1:
    dat3 <- structure(c(3539122.86, 3081383.87, 4158672.31, 4137518.78, 4123682.08, 4819375.2, 4342687.77, 5028674.58, 4472145.07, 4967277.73, 4516240.31, 4876194.63, 4816446.59,
                        4887399.37, 5478504.85, 4871385.27, 5487543.68, 5464193.69, 5252591.03, 7071416.89, 5524350.89, 6107166.69, 6530003.55, 6445929.08, 7356743.81, 6750025.03,
                        6934714.08, 6656194.35
    
                        ,-13913, -29385.31, -39633.37, -23487.13, -18202.86, -57335.49, -26061.45, -60880.07, -17589.45, -35970.08, -89133.94,
                        -84694.58, -31724.89, -29847.95, -65421.74, -34334.22, -48511.98, -30298.97, -38729.46, -29292.89, -46098.4, -65909.49,
                        -85879.23, -71845.28, -69017.07, -93161.03, -70847.29, -85106.04
    
                        ,-357694.19, -444792.75, -361349.57, -386717.55, -547422.05, -518259.22, -417613.76, -578631.46, -804516.81, -572875.52, -510487.53,
                        -666294.87, -673233.37, -556564.45, -963346.75, -639288.2, -910104.23, -773428.8, -1008078.84, -546685.3, -729932.94, -987098.23,
                        -964001.63, -986995.93, -680066.58, -728854.58, -730766.92, -753861.59)
                        ,.Dim = c(28L, 3L)
                        ,.Dimnames = list(NULL, c("OONNetRev","OONAdjusted" ,"OONCancelled"))
                        ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
    head(dat3); nrow(dat3)
    
    TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
    TNR_moving_average
    
    # Warning message:
    #   In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
    #            Missing values encountered. Using longest contiguous portion of time series
    #          > Point Forecast         Lo 80         Hi 80         Lo 95         Hi 95
    #         28  7007065.99688 6675015.72012 7339116.27365 6499238.92148 7514893.07229
    #         29  7135745.42473 6721543.41996 7549947.42950 6502278.12345 7769212.72601
    #         30  7264424.85258 6779532.18065 7749317.52450 6522845.50541 8006004.19974
    #         31  7393104.28042 6844496.10189 7941712.45896 6554080.47486 8232128.08599
    #         32  7521783.70827 6914203.11991 8129364.29663 6592569.38486 8450998.03168
    #         33  7650463.13612 6987355.72657 8313570.54567 6636327.86794 8664598.40429
    #         34  7779142.56396 7063123.29787 8495161.83005 6684085.59434 8874199.53358
    #         35  7907821.99181 7140937.69145 8674706.29217 6734973.66528 9080670.31834
    
    
    
    
    Example2:
    dat3 <- structure(c(994320.58, 811664.54, 1045259.43, 951659.48, 669458.94, 986741.09, 1023344.82, 938971.65, 897670.06, 1040074.6, 1090310.01,
                        1289821.17, 1187806.23, 971485.76, 1161147.42, 870585.04, 1021301.52, 1215798.03, 1015004.43, 1365863.09, 995769.41,
                        1331725.36, 1271032.91, 1092103.82, 1297131.4, 1129195.28, 1372594.58, 1553717.57,
    
                        -39811.51, -47356.74, -49046.86, -41311.13, -79063.98, -43916.59, -16746.33, -38347.9, -84797.44, -38961.44,
                        -72036.83, -62854.78, -35259.84, -44198.39, -34262.65, -49245.82, -34977.28, -36797.35, -47534.43, -33515.13,
                        -25764.41, -29130.53, -57693.63, -51026.83, -49624.49, -36508.13, -32667.21, -37900.5,
    
                        -247443.87, -372942.34, -344080.78, -355586.21, -458998.84, -378086.44, -333994.18, -567024.45, -521499.8, -428915.13,
                        -512034.28, -440865.42, -347494.22, -422436.19, -444588.65, -462891.57, -518395.47, -373818.5, -398899.53, -381573.69,
                        -531449.2, -476238.48, -434296.86, -655679.94, -528999.52, -423725.95, -556977.31, -518633.95)
                      ,.Dim = c(28L, 3L)
                      ,.Dimnames = list(NULL, c("EditNetRev","EditNetAdjusted" ,"EditNetCancelled"))
                      ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
    head(dat3); nrow(dat3)
    
    
    
    TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
    TNR_moving_average
    
    # Warning message:
    # In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
    #          Missing values encountered. Using longest contiguous portion of time series
    #        > TNR_moving_average
    #        Point Forecast         Lo 80         Hi 80          Lo 95         Hi 95
    #        28  1351827.24389 1246570.02118 1457084.46661 1190850.213255 1512804.27453
    #        29  1351827.24389 1202841.21791 1500813.26987 1123972.779844 1579681.70794
    #        30  1351827.24389 1169192.03201 1534462.45578 1072510.790913 1631143.69687
    #        31  1351827.24389 1140745.29674 1562909.19105 1029005.263624 1674649.22416
    #        32  1351827.24389 1115613.58783 1588040.89996  990569.631639 1713084.85615
    #        33  1351827.24389 1092829.78856 1610824.69923  955724.817592 1747929.67020
    #        34  1351827.24389 1071819.89899 1631834.58880  923592.964312 1780061.52348
    #        35  1351827.24389 1052210.25675 1651444.23104  893602.604521 1810051.88327
    
    Thank you for any advice or direction.
    
    
    WHP
    
    
    
    Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From Bill@Poling @ending from zeli@@com  Fri Jun  1 17:57:22 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 1 Jun 2018 15:57:22 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
Message-ID: <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Fri Jun  1 18:54:16 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 1 Jun 2018 16:54:16 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

  tnr.ma <- ma(dat3[1:28], order=3)
  TNR_moving_average <- forecast(tnr.ma, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
?


From: Bill Poling <Bill.Poling at zelis.com>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov>, array R-help <r-help at r-project.org>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help. 
?
I am using the forecast package, originally I found it following a forecasting example on bloggers.com 
?
https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/
?
And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf
?
Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?
?
No worries though, I am going to reach out to the package author.
?
Cheers. 
?
WHP
?
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question
?
My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018. 


From m@ni@hmukherjee @ending from hotm@il@com  Fri Jun  1 19:20:50 2018
From: m@ni@hmukherjee @ending from hotm@il@com (Manish Mukherjee)
Date: Fri, 1 Jun 2018 17:20:50 +0000
Subject: [R] Issue with batch forecasting of Time series data
Message-ID: <MAXPR0101MB148442C572FAC9C08E9460B2B9620@MAXPR0101MB1484.INDPRD01.PROD.OUTLOOK.COM>

Hi,


i have a weekly data for servers for 62 weeks. want to predict the cpu% for next 5 weeks.I am trying to forecast for many servers at once but with the code i am getting only one week of future forecast for all the servers. Also the week date for the predicted week is showing as the last week of the original data . Need help in two things How can i change the date for the predicted  week, and  how can i predict for more than one week.


R code.

input_data <- read.csv("input.csv", header= TRUE)
head(input_data)
str(input_data)
library("forecast")
library("DBI")
library("RPostgreSQL")
library("lubridate")
Products = unique(input_data["Server.Name"][,])
output = matrix(0,nrow=(length(Products)*(1)),ncol=7)
colnames(output) =

  c(
    "Product",
    "DATE",
    "Forecast",
    "Lo_80",
    "Hi_80 ",
    "Lo_95",
    "Hi_95"
  )

for (i in Products) {

 train = head(input_data["PERCENT_USED"][input_data["Server.Name"]==i] , 90)

  train     = ts(train[1:(length(train))])

  fc1 = auto.arima(train)
  pred1 = forecast( fc1)
  fit1_acry   = accuracy(pred1)
  fc2 = ets(train)
  pred2 = forecast( fc2 )
  fit2_acry = accuracy(pred2 )

  MAPE = data.frame ( fit1_MAPE = fit1_acry[,'MAPE'],
                       fit2_MAPE = fit2_acry[,'MAPE']
  )

  best =  which.min(MAPE)

  BestModel = get(paste('fc',best,sep=""))

  forecastoutput = rbind(data.frame(forecast(BestModel, h=1)) )
  forecast_date = rbind(tail(input_data["DATE"][input_data["Server.Name"]==i],(1)))
  row_index = which(Products==i)

  output[row_index,1]   = i
  output[row_index,2]   = forecast_date
  output[row_index,3]   = (round(forecastoutput$Point.Forecast,2))
  output[row_index,4]   = as.numeric(round(forecastoutput$Lo.80,2))
  output[row_index,5]   = as.numeric(round(forecastoutput$Hi.80,2))
  output[row_index,6]   = as.numeric(round(forecastoutput$Lo.95,2))
  output[row_index,7] = as.numeric(round(forecastoutput$Hi.95,2))
  output_onestep = data.frame(output)

}
output_onestep



	[[alternative HTML version deleted]]


From chri@ti@n @ending from echoffm@nn@ch  Fri Jun  1 16:25:01 2018
From: chri@ti@n @ending from echoffm@nn@ch (Christian)
Date: Fri, 1 Jun 2018 16:25:01 +0200
Subject: [R] values of list of variable names
Message-ID: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>

Hi,

I have searched the documentations of eval, substitute, expression, and 
I cannot make work something like the values of a list of variable names:

lis <- ls(pattern="pr") # all variables with names containing 'pr'

What is the mantra giving me the _values_ of the variables whose names 
are  contained in 'lis'. eval(parse(ls(pattern="pr"))) will not do but 
returning TRUE.

TIA
C.
-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853


From nguy2952 @ending from umn@edu  Fri Jun  1 17:54:03 2018
From: nguy2952 @ending from umn@edu (nguy2952 University of Minnesota)
Date: Fri, 1 Jun 2018 10:54:03 -0500
Subject: [R] Regroup and create new dataframe
Message-ID: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>

Hello folks,

I have a big project to work on and the dataset is classified so I am just
going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target
brand, 3M and Avery. The original data frame has 4 columns: Year of Record,
Product_Name(which contains three brands of tape), Sales, and Region. I
want to create a new data frame that looks like this:

                      Year of Record       Sales     Region
  Target Brand
  3M
  Avery

Here is what I did.

   1.

   I split the original data frame which I called data1:

   X = split(data1, Product_name)

   2.

   Unlist X

   X1 = unlist(X)

   3.

   Create a new data frame

   new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left
one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different
regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to
those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Jun  1 19:42:31 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 1 Jun 2018 17:42:31 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
Message-ID: <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi Don, wow, you are so right. I picked that piece up from the bloggers tutorial and since I am R naive yet, I thought it was all one step

moving_average = forecast(ma(tdat[1:31], order=2), h=5)

Truly, I usually print and check at every step I can, as painful as it is sometimes.
Great lesson for this novice usR.

So the first and last values are NA in each case? Do you know why? Should I replace the NA with a value, say the average of the others?

Also, I have 5 series of data I am working with using this script and of course each gave me that warning, but only the one series had the same 8 Point Forecast values, is that coincidental you think?

Terrific of you to help, I really appreciate it.

WHP


From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 12:54 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

tnr.ma<http://tnr.ma> <- ma(dat3[1:28], order=3)
TNR_moving_average <- forecast(tnr.ma<http://tnr.ma>, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma<http://tnr.ma> and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com<http://bloggers.com>

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/<https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/>

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf<https://cran.r-project.org/web/packages/forecast/forecast.pdf>

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Jun  1 19:52:13 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 1 Jun 2018 10:52:13 -0700
Subject: [R] values of list of variable names
In-Reply-To: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
References: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
Message-ID: <CAF8bMcbcQaQFh+TaL5q3H8TXUto2EGT_sUY79k+OJxKbXuWQEA@mail.gmail.com>

One way is
   values <- lapply(lis, get)
You can do
   names(values) <- lis
to attach the object names to the values in the list returned by lapply.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 1, 2018 at 7:25 AM, Christian <christian at echoffmann.ch> wrote:

> Hi,
>
> I have searched the documentations of eval, substitute, expression, and I
> cannot make work something like the values of a list of variable names:
>
> lis <- ls(pattern="pr") # all variables with names containing 'pr'
>
> What is the mantra giving me the _values_ of the variables whose names
> are  contained in 'lis'. eval(parse(ls(pattern="pr"))) will not do but
> returning TRUE.
>
> TIA
> C.
> --
> Christian Hoffmann
> Rigiblickstrasse 15b
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From dimitrijoe @ending from gm@il@com  Fri Jun  1 20:26:51 2018
From: dimitrijoe @ending from gm@il@com (Dimitri Szerman)
Date: Fri, 1 Jun 2018 15:26:51 -0300
Subject: [R] rasterize SpatialPolygon object using a RasterBrick object
Message-ID: <CAJcfORJdivKJRntDrq-igrv-FXDPL23yiKCT4n63jirGepjqEQ@mail.gmail.com>

I am trying to rasterize a SpatialPolygon object by a RasterBrick object.
The documentation of the raster::rasterize function explicitly says this is
allowed. Here's what I am doing

# load the raster package
library("raster")
# create a raster brick object using the example from the brick
function documentation
b <- brick(system.file("external/rlogo.grd", package="raster"))
b
nlayers(b)
names(b)
extract(b, 870)
# create a SpatialPolygon object using the example from the function
documentation
Sr1 = Polygon(10*cbind(c(2,4,4,1,2),10*c(2,3,5,4,2)))
Sr2 = Polygon(10*cbind(c(5,4,2,5),10*c(2,3,2,2)))
Sr3 = Polygon(10*cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
Sr4 = Polygon(10*cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)

Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr3, Sr4), "s3/4")
SpP = SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3)

plot(b[[1]])
plot(SpP, add = T)
# crop
clip1 = crop(b, extent(SpP))
# rasterize returns an error, but documentation says it should return
a RasterBrick object
clip2 = rasterize(SpP, b, mask = T)
Error in v[, r] <- rrv :
     number of items to replace is not a multiple of replacement length
# however, if I used only one layer, all would be fine
clip2 = rasterize(SpP, b[[1]], mask = T)

Of course, I could loop over the brick's layers, but as I understand it,
that would defeat the purpose of a brick object.

I want to use clip2 to then get the histogram of pixel values in the
layers, like this:

vals = getValues(clip2)

Can anyone tell me why I am getting this error, and how to go around it
efficiently?

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Fri Jun  1 20:55:47 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 1 Jun 2018 18:55:47 +0000
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
Message-ID: <da3839d03c474079afdcd05514df4a08@tamu.edu>

Your question raises several issues. First, we do not do homework here, so if this is an assignment, you will not get much help. Second, you need to send your emails as plain text, not html. Third, you need to provide a reproducible example and send your data using dput() so that we can follow what you have tried so far. For example, here's a data set that resembles what you have described:

set.seed(42)
Tape <- data.frame(Year=2011:2015, Product=rep(c("Target", "3M", "Avery"),
     each=5), Sales=sample(1000:2000, 15), Region=rep(c("North", "South",
     "West"), each=5), stringsAsFactors=FALSE)
dput(Tape)
structure(list(Year = c(2011L, 2012L, 2013L, 2014L, 2015L, 2011L, 
2012L, 2013L, 2014L, 2015L, 2011L, 2012L, 2013L, 2014L, 2015L
), Product = c("Target", "Target", "Target", "Target", "Target", 
"3M", "3M", "3M", "3M", "3M", "Avery", "Avery", "Avery", "Avery", 
"Avery"), Sales = c(1915L, 1937L, 1285L, 1828L, 1639L, 1517L, 
1732L, 1133L, 1652L, 1699L, 1453L, 1711L, 1924L, 1252L, 1456L
), Region = c("North", "North", "North", "North", "North", "South", 
"South", "South", "South", "South", "West", "West", "West", "West", 
"West")), .Names = c("Year", "Product", "Sales", "Region"), row.names = c(NA, 
-15L), class = "data.frame")

It is not clear what you want in your new data frame. This one has 5 years of data for each tape brand and you seem to want one row for each tape brand? Tables created in html and then sent to a plain text mailing list can be dramatically different from the original format. It is not clear that you cannot answer your questions from the data as presented here. Look at the results of unlist(split(Tape, Tape$Product)). You should see that this is nowhere near what you described.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of nguy2952 University of Minnesota
Sent: Friday, June 1, 2018 10:54 AM
To: r-help at r-project.org
Subject: [R] Regroup and create new dataframe

Hello folks,

I have a big project to work on and the dataset is classified so I am just going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target brand, 3M and Avery. The original data frame has 4 columns: Year of Record, Product_Name(which contains three brands of tape), Sales, and Region. I want to create a new data frame that looks like this:

                      Year of Record       Sales     Region
  Target Brand
  3M
  Avery

Here is what I did.

   1.

   I split the original data frame which I called data1:

   X = split(data1, Product_name)

   2.

   Unlist X

   X1 = unlist(X)

   3.

   Create a new data frame

   new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ruipb@rr@d@@ @ending from @@po@pt  Fri Jun  1 20:58:13 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 1 Jun 2018 19:58:13 +0100
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
Message-ID: <dab8572f-405e-6e2c-d6e0-2c8215138a95@sapo.pt>

Hello,

I don't understand why you are splitting data1 and then unlisting the 
result.

if you want to apply a modeling function to each of the subdf's, split 
by Product name, you can follow more or less these steps:

0. Create a dataset

set.seed(9376)??? # Make the results reproducible

n <- 100
PN <- c("Target Brand", "3M", "Avery")
data1 <- data.frame(Product_name = sample(PN, n, TRUE),
 ??????????????????? Year_of_Record = sample(2011:2018, n, TRUE),
 ??????????????????? Sales = runif(n, 10, 1000),
 ??????????????????? Region = sample(letters[1:5], n, TRUE)
 ??????????????????? )

head(data1)


1. Split the dataset by product name. Thsi gives a list of subdf's.


X <- split(data1, data1$Product_name)


2. Now lappy a modeling function to each subdf.


modelFun <- function(DF){

 ??? lm(Sales ~ Region, data = DF)

}

model_list <- lapply(X, modelFun )
model_smry <- lapply(model_list, summary)
model_smry[[1]]
#
#Call:
#? lm(formula = Sales ~ Region, data = DF)
#
#Residuals:
#? Min????? 1Q? Median????? 3Q???? Max
#-487.41 -196.17??? 1.76? 195.96? 498.48
#
#Coefficients:
#? Estimate Std. Error t value Pr(>|t|)
#(Intercept)? 437.300??? 108.147?? 4.044 0.000355 ***
#? Regionb????? 437.019??? 167.540?? 2.608 0.014229 *
#? Regionc????? 102.989??? 179.341?? 0.574 0.570217
#Regiond????? 105.520??? 152.942?? 0.690 0.495721
#Regione?????? -5.638??? 138.342? -0.041 0.967773
#---
#? Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
#
#Residual standard error: 286.1 on 29 degrees of freedom
#Multiple R-squared:? 0.2426,??? Adjusted R-squared:? 0.1381
#F-statistic: 2.322 on 4 and 29 DF,? p-value: 0.08039

Hope this helps,


Rui Barradas


?s 16:54 de 01-06-2018, nguy2952 University of Minnesota escreveu:
> Hello folks,
>
> I have a big project to work on and the dataset is classified so I am just
> going to use my own example so everyone can understand what I am targeting.
>
> Let's take Target as an example: We consider three brands of tape: Target
> brand, 3M and Avery. The original data frame has 4 columns: Year of Record,
> Product_Name(which contains three brands of tape), Sales, and Region. I
> want to create a new data frame that looks like this:
>
>                        Year of Record       Sales     Region
>    Target Brand
>    3M
>    Avery
>
> Here is what I did.
>
>     1.
>
>     I split the original data frame which I called data1:
>
>     X = split(data1, Product_name)
>
>     2.
>
>     Unlist X
>
>     X1 = unlist(X)
>
>     3.
>
>     Create a new data frame
>
>     new_df = as.data.frame(X1)
>
>
> But, when I used the command View(new_df), I had only two columns: The left
> one is similar to TargetBrand.Sales, etc. and the right one is just "X1"
>
> I did not achieve what I wanted.
>
> **A potentially big question from readers:*
>
> Why am I doing this?
>
> *Answer:*
>
> I want to run a multiple regression model later to see among different
> regions, what the sales look like for these three brands of tape:
>
> *Does Mid-west buy more house brand than East Coast?*
>
> or
>
> *Does region really affect the sales? Are Mid-West's purchases similar to
> those of East Coast and West Coast?*
>
> I need help. Please give me guidance.
>
> Sincerely,
> Hugh N
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dc@rl@on @ending from t@mu@edu  Fri Jun  1 21:09:43 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 1 Jun 2018 19:09:43 +0000
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwX_=5Ov3i1EPJrVzqWQ5r1LDCRw-v9YQ7Sn=wF6f_JabQ@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
 <da3839d03c474079afdcd05514df4a08@tamu.edu>
 <CAPjFEwX_=5Ov3i1EPJrVzqWQ5r1LDCRw-v9YQ7Sn=wF6f_JabQ@mail.gmail.com>
Message-ID: <9acc43d429f1417cbe4efcd7b388946b@tamu.edu>

Responses should be copied to r-help using ReplyAll. You are still sending html formatted emails. If you are using Microsoft Outlook, click the Format Text tab and select ?Aa Plain Text?. No one has asked you to reveal the data set, only to create one with a similar structure. Is the data I sent reasonably close? What should it look like after it is transformed? 

David C

From: nguy2952 University of Minnesota <nguy2952 at umn.edu> 
Sent: Friday, June 1, 2018 1:57 PM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Regroup and create new dataframe

Hi,
This is not an assignment for school.
This is a project at WORK.?
I am not allowed to reveal the dataset.

Thanks!

On Fri, Jun 1, 2018 at 1:55 PM, David L Carlson <mailto:dcarlson at tamu.edu> wrote:
Your question raises several issues. First, we do not do homework here, so if this is an assignment, you will not get much help. Second, you need to send your emails as plain text, not html. Third, you need to provide a reproducible example and send your data using dput() so that we can follow what you have tried so far. For example, here's a data set that resembles what you have described:

set.seed(42)
Tape <- data.frame(Year=2011:2015, Product=rep(c("Target", "3M", "Avery"),
? ? ?each=5), Sales=sample(1000:2000, 15), Region=rep(c("North", "South",
? ? ?"West"), each=5), stringsAsFactors=FALSE)
dput(Tape)
structure(list(Year = c(2011L, 2012L, 2013L, 2014L, 2015L, 2011L, 
2012L, 2013L, 2014L, 2015L, 2011L, 2012L, 2013L, 2014L, 2015L
), Product = c("Target", "Target", "Target", "Target", "Target", 
"3M", "3M", "3M", "3M", "3M", "Avery", "Avery", "Avery", "Avery", 
"Avery"), Sales = c(1915L, 1937L, 1285L, 1828L, 1639L, 1517L, 
1732L, 1133L, 1652L, 1699L, 1453L, 1711L, 1924L, 1252L, 1456L
), Region = c("North", "North", "North", "North", "North", "South", 
"South", "South", "South", "South", "West", "West", "West", "West", 
"West")), .Names = c("Year", "Product", "Sales", "Region"), row.names = c(NA, 
-15L), class = "data.frame")

It is not clear what you want in your new data frame. This one has 5 years of data for each tape brand and you seem to want one row for each tape brand? Tables created in html and then sent to a plain text mailing list can be dramatically different from the original format. It is not clear that you cannot answer your questions from the data as presented here. Look at the results of unlist(split(Tape, Tape$Product)). You should see that this is nowhere near what you described.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of nguy2952 University of Minnesota
Sent: Friday, June 1, 2018 10:54 AM
To: mailto:r-help at r-project.org
Subject: [R] Regroup and create new dataframe

Hello folks,

I have a big project to work on and the dataset is classified so I am just going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target brand, 3M and Avery. The original data frame has 4 columns: Year of Record, Product_Name(which contains three brands of tape), Sales, and Region. I want to create a new data frame that looks like this:

? ? ? ? ? ? ? ? ? ? ? Year of Record? ? ? ?Sales? ? ?Region
? Target Brand
? 3M
? Avery

Here is what I did.

? ?1.

? ?I split the original data frame which I called data1:

? ?X = split(data1, Product_name)

? ?2.

? ?Unlist X

? ?X1 = unlist(X)

? ?3.

? ?Create a new data frame

? ?new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=nPZ3F6nROsY3KM0z7y6ixAAYLjMGVhEZyuXMi3bg0rY&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=XNpVm_6i2GLFLk3FzpM9T15aezUet1BA0FlapuVXdmc&e=
and provide commented, minimal, self-contained, reproducible code.


From dc@rl@on @ending from t@mu@edu  Fri Jun  1 21:35:24 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 1 Jun 2018 19:35:24 +0000
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwUoz9wkgh+i3StzVPcvjXWm0mYwZGZfMYUqM8+SbMY-9Q@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
 <da3839d03c474079afdcd05514df4a08@tamu.edu>
 <CAPjFEwX_=5Ov3i1EPJrVzqWQ5r1LDCRw-v9YQ7Sn=wF6f_JabQ@mail.gmail.com>
 <9acc43d429f1417cbe4efcd7b388946b@tamu.edu>
 <CAPjFEwUoz9wkgh+i3StzVPcvjXWm0mYwZGZfMYUqM8+SbMY-9Q@mail.gmail.com>
Message-ID: <436f756b18bd4c13b2404929c9701573@tamu.edu>

No html!, Copy the list using Reply-All. 

The data frame group_PrivateLabel does not contain variables called Product_Name or Region.

David C

From: nguy2952 University of Minnesota <nguy2952 at umn.edu> 
Sent: Friday, June 1, 2018 2:13 PM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Regroup and create new dataframe

Hi David,
your example is perfect!
I am still learning so please stay with me.
So, I am running a regression model:
model1 = lm(MarginDollars ~ Region + Product_Name, group_PrivateLabel)
I have an error message:?
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :?
? contrasts can be applied only to factors with 2 or more levels

> str(group_PrivateLabel)
'data.frame':	14802 obs. of? 12 variables:
?$ ACCTG_YEAR_KEY? ? ? ? : int? 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 ...
?$ ITEM_CATEGORY_DESCR? ?: Factor w/ 462 levels "ABRASIVE AND POLISHING MATERIAL",..: 145 145 145 145 145 145 145 145 145 145 ...
?$ ITEM_DESCR? ? ? ? ? ? : Factor w/ 12319 levels "@EASE X-RAY BADGE QTRLY SRVC",..: 8263 8263 8263 8263 8263 8263 8263 8263 8263 8264 ...
?$ PRODUCT_SUB_LINE_DESCR: Factor w/ 3 levels "Handpieces","PRIVATE LABEL",..: 2 2 2 2 2 2 2 2 2 2 ...
?$ MAJOR_CATEGORY_DESCR? : Factor w/ 25 levels "AIR ABRASION",..: 4 4 4 4 4 4 4 4 4 4 ...
?$ CUST_BRANCH_DESCR? ? ?: Factor w/ 60 levels "ALBUQUERQUE",..: 58 35 24 55 8 22 22 46 46 35 ...
?$ CUST_STATE_KEY? ? ? ? : Factor w/ 52 levels "AK","AL","AR",..: 15 49 44 16 6 6 28 6 6 49 ...
?$ CUST_REGION_DESCR? ? ?: Factor w/ 7 levels "MOUNTAIN WEST REGION",..: 2 2 5 4 6 6 6 6 6 2 ...
?$ Sales? ? ? ? ? ? ? ? ?: num? 25.9 13.5 28.5 28.5 57 ...
?$ QtySold? ? ? ? ? ? ? ?: int? 2 1 2 2 5 2 1 3 3 1 ...
?$ MFGCOST? ? ? ? ? ? ? ?: num? 13.2 6.6 13.2 13.2 33 13.2 6.6 19.8 19.8 6.6 ...
?$ MarginDollars? ? ? ? ?: num? 11.72 6.43 14.28 14.28 21.45 ...

What can I do?
Everything seems to fit perfectly to what I learned at school.
I am just working on a real-life huge data set. The regression model should work.

Please help.


On Fri, Jun 1, 2018 at 2:09 PM, David L Carlson <mailto:dcarlson at tamu.edu> wrote:
Responses should be copied to r-help using ReplyAll. You are still sending html formatted emails. If you are using Microsoft Outlook, click the Format Text tab and select ?Aa Plain Text?. No one has asked you to reveal the data set, only to create one with a similar structure. Is the data I sent reasonably close? What should it look like after it is transformed? 

David C

From: nguy2952 University of Minnesota <mailto:nguy2952 at umn.edu> 
Sent: Friday, June 1, 2018 1:57 PM
To: David L Carlson <mailto:dcarlson at tamu.edu>
Subject: Re: [R] Regroup and create new dataframe

Hi,
This is not an assignment for school.
This is a project at WORK.?
I am not allowed to reveal the dataset.

Thanks!

On Fri, Jun 1, 2018 at 1:55 PM, David L Carlson <mailto:mailto:dcarlson at tamu.edu> wrote:
Your question raises several issues. First, we do not do homework here, so if this is an assignment, you will not get much help. Second, you need to send your emails as plain text, not html. Third, you need to provide a reproducible example and send your data using dput() so that we can follow what you have tried so far. For example, here's a data set that resembles what you have described:

set.seed(42)
Tape <- data.frame(Year=2011:2015, Product=rep(c("Target", "3M", "Avery"),
? ? ?each=5), Sales=sample(1000:2000, 15), Region=rep(c("North", "South",
? ? ?"West"), each=5), stringsAsFactors=FALSE)
dput(Tape)
structure(list(Year = c(2011L, 2012L, 2013L, 2014L, 2015L, 2011L, 
2012L, 2013L, 2014L, 2015L, 2011L, 2012L, 2013L, 2014L, 2015L
), Product = c("Target", "Target", "Target", "Target", "Target", 
"3M", "3M", "3M", "3M", "3M", "Avery", "Avery", "Avery", "Avery", 
"Avery"), Sales = c(1915L, 1937L, 1285L, 1828L, 1639L, 1517L, 
1732L, 1133L, 1652L, 1699L, 1453L, 1711L, 1924L, 1252L, 1456L
), Region = c("North", "North", "North", "North", "North", "South", 
"South", "South", "South", "South", "West", "West", "West", "West", 
"West")), .Names = c("Year", "Product", "Sales", "Region"), row.names = c(NA, 
-15L), class = "data.frame")

It is not clear what you want in your new data frame. This one has 5 years of data for each tape brand and you seem to want one row for each tape brand? Tables created in html and then sent to a plain text mailing list can be dramatically different from the original format. It is not clear that you cannot answer your questions from the data as presented here. Look at the results of unlist(split(Tape, Tape$Product)). You should see that this is nowhere near what you described.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <mailto:mailto:r-help-bounces at r-project.org> On Behalf Of nguy2952 University of Minnesota
Sent: Friday, June 1, 2018 10:54 AM
To: mailto:mailto:r-help at r-project.org
Subject: [R] Regroup and create new dataframe

Hello folks,

I have a big project to work on and the dataset is classified so I am just going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target brand, 3M and Avery. The original data frame has 4 columns: Year of Record, Product_Name(which contains three brands of tape), Sales, and Region. I want to create a new data frame that looks like this:

? ? ? ? ? ? ? ? ? ? ? Year of Record? ? ? ?Sales? ? ?Region
? Target Brand
? 3M
? Avery

Here is what I did.

? ?1.

? ?I split the original data frame which I called data1:

? ?X = split(data1, Product_name)

? ?2.

? ?Unlist X

? ?X1 = unlist(X)

? ?3.

? ?Create a new data frame

? ?new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
mailto:mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=nPZ3F6nROsY3KM0z7y6ixAAYLjMGVhEZyuXMi3bg0rY&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=XNpVm_6i2GLFLk3FzpM9T15aezUet1BA0FlapuVXdmc&e=
and provide commented, minimal, self-contained, reproducible code.


From jholtm@n @ending from gm@il@com  Fri Jun  1 21:40:24 2018
From: jholtm@n @ending from gm@il@com (jim holtman)
Date: Fri, 1 Jun 2018 12:40:24 -0700
Subject: [R] values of list of variable names
In-Reply-To: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
References: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
Message-ID: <CAAxdm-5qBMt_2XdG_yNJi5sY6ZxwNxJQRsif+z6Xb3MBvmbgEQ@mail.gmail.com>

You probably want to use 'get':

> r1 <- 5
> r2 <- 3
> r3 <- 45
> x <- ls(pattern = '^r.$')
> x
[1] "r1" "r2" "r3"
> lapply(x, get)
[[1]]
[1] 5

[[2]]
[1] 3

[[3]]
[1] 45

>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Jun 1, 2018 at 7:25 AM, Christian <christian at echoffmann.ch> wrote:

> Hi,
>
> I have searched the documentations of eval, substitute, expression, and I
> cannot make work something like the values of a list of variable names:
>
> lis <- ls(pattern="pr") # all variables with names containing 'pr'
>
> What is the mantra giving me the _values_ of the variables whose names
> are  contained in 'lis'. eval(parse(ls(pattern="pr"))) will not do but
> returning TRUE.
>
> TIA
> C.
> --
> Christian Hoffmann
> Rigiblickstrasse 15b
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From md@umner @ending from gm@il@com  Fri Jun  1 22:57:00 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Sat, 2 Jun 2018 06:57:00 +1000
Subject: [R] rasterize SpatialPolygon object using a RasterBrick object
In-Reply-To: <CAJcfORJdivKJRntDrq-igrv-FXDPL23yiKCT4n63jirGepjqEQ@mail.gmail.com>
References: <CAJcfORJdivKJRntDrq-igrv-FXDPL23yiKCT4n63jirGepjqEQ@mail.gmail.com>
Message-ID: <CAAcGz9-08PaEvLd4aFfg=eMW4HC3O9D9Bi+yv_OQxWLm7ERHbg@mail.gmail.com>

I see this problem in 2.6-7 (version on CRAN) but it's now fixed in dev on
RForge, you can try it out by installing from there, or from the Github
mirror with devtools::install_github("rforge/raster/pkg/raster").

There's an imminent release to CRAN some time soon.

Cheers, Mike.


On Sat, 2 Jun 2018 at 04:48 Dimitri Szerman <dimitrijoe at gmail.com> wrote:

I am trying to rasterize a SpatialPolygon object by a RasterBrick object.
The documentation of the raster::rasterize function explicitly says this is
allowed. Here's what I am doing

# load the raster package
library("raster")
# create a raster brick object using the example from the brick
function documentation
b <- brick(system.file("external/rlogo.grd", package="raster"))
b
nlayers(b)
names(b)
extract(b, 870)
# create a SpatialPolygon object using the example from the function
documentation
Sr1 = Polygon(10*cbind(c(2,4,4,1,2),10*c(2,3,5,4,2)))
Sr2 = Polygon(10*cbind(c(5,4,2,5),10*c(2,3,2,2)))
Sr3 = Polygon(10*cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
Sr4 = Polygon(10*cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)

Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr3, Sr4), "s3/4")
SpP = SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3)

plot(b[[1]])
plot(SpP, add = T)
# crop
clip1 = crop(b, extent(SpP))
# rasterize returns an error, but documentation says it should return
a RasterBrick object
clip2 = rasterize(SpP, b, mask = T)
Error in v[, r] <- rrv :
number of items to replace is not a multiple of replacement length
# however, if I used only one layer, all would be fine
clip2 = rasterize(SpP, b[[1]], mask = T)

Of course, I could loop over the brick's layers, but as I understand it,
that would defeat the purpose of a brick object.

I want to use clip2 to then get the histogram of pixel values in the
layers, like this:

vals = getValues(clip2)

Can anyone tell me why I am getting this error, and how to go around it
efficiently?

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Fri Jun  1 23:03:18 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 1 Jun 2018 21:03:18 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
 <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <04C0271F-0455-4F38-BD4C-773B24B2DA21@llnl.gov>

For your first question, you?re doing moving averages of 3 points (I assume that?s what order=3 does). For any given time point of your input data, that would be one before, one at, and one after the given time point. Do all of  your input times have both one before and one after?

Don?t know about your same 8 point forecast values question, not without running it myself, but I would say that if the data really is different, yet the forecasts are the same, it would have to be coincidental. But a priori this seems unlikely, so I?d inspect your script very carefully for mistakes.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com>
Date: Friday, June 1, 2018 at 10:43 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov>, array R-help <r-help at r-project.org>
Subject: RE: [R] Time-series moving average question

Hi Don, wow, you are so right. I picked that piece up from the bloggers tutorial and since I am R naive yet, I thought it was all one step

moving_average = forecast(ma(tdat[1:31], order=2), h=5)

Truly, I usually print and check at every step I can, as painful as it is sometimes.
Great lesson for this novice usR.

So the first and last values are NA in each case? Do you know why? Should I replace the NA with a value, say the average of the others?

Also, I have 5 series of data I am working with using this script and of course each gave me that warning, but only the one series had the same 8 Point Forecast values, is that coincidental you think?

Terrific of you to help, I really appreciate it.

WHP


From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 12:54 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

tnr.ma<http://tnr.ma> <- ma(dat3[1:28], order=3)
TNR_moving_average <- forecast(tnr.ma<http://tnr.ma>, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma<http://tnr.ma> and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com<http://bloggers.com>

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From min@h@ll @ending from @cm@org  Fri Jun  1 22:07:38 2018
From: min@h@ll @ending from @cm@org (Greg Minshall)
Date: Fri, 01 Jun 2018 16:07:38 -0400
Subject: [R] values of list of variable names
In-Reply-To: Your message of "Fri, 01 Jun 2018 16:25:01 +0200."
 <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
Message-ID: <29330.1527883658@minshall-apollo.minshall.org>

Christian,

does this do it?

> eval(lapply(ls(pattern="pr"), function(x) eval(parse(text=x))))

cheers, Greg


From @hivipmp82 @ending from gm@il@com  Fri Jun  1 23:24:37 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Sat, 2 Jun 2018 02:54:37 +0530
Subject: [R] Cannot Load A Package
Message-ID: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>

Hi All,

I am trying to download semnet package but getting the error:
package not available for R version 3.4.4.

I tried downloading it from
install.packages('semnet',repos='http://cran.us.r-project.org')
and install.packages('semnet',repos='http://cran.revolutionanalytics.com/')
and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
doesnt seem to get success.

Please suggest some alternate.

Regards, Shivi

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Sat Jun  2 01:17:58 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Fri, 1 Jun 2018 19:17:58 -0400
Subject: [R] Cannot Load A Package
In-Reply-To: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
References: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
Message-ID: <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>

On 01/06/2018 5:24 PM, Shivi Bhatia wrote:
> Hi All,
> 
> I am trying to download semnet package but getting the error:
> package not available for R version 3.4.4.

As far as I can see, there is no semnet package on CRAN, and never has 
been (or if there was, it was there by mistake).

Packages whose names start with "sem" are:

sem	Structural Equation Models
semantic.dashboard	Dashboard with Semantic UI Support for 'shiny'
Semblance	Pair-Wise Semblance Using a Rank-Based Kernel
semdiag	Structural equation modeling diagnostics
semds	Structural Equation Multidimensional Scaling
semGOF	Goodness-of-fit indexes for structural equation models
semiArtificial	Generator of Semi-Artificial Data
SemiCompRisks	Hierarchical Models for Parametric and Semi-Parametric 
Analyses of Semi-Competing Risks Data
SEMID	Identifiability of Linear Structural Equation Models
SemiMarkov	Multi-States Semi-Markov Models
seminr	Domain-Specific Language for Building PLS Structural Equation Models
SemiPar	Semiparametic Regression
SemiParSampleSel	Semi-Parametric Sample Selection Modelling with 
Continuous or Discrete Response
SemiSupervised	Safe Semi-Supervised Learning Tools
semisupKernelPCA	Kernel PCA projection, and semi-supervised variant
SEMModComp	Model Comparisons for SEM
SemNetCleaner	An Automated Cleaning Tool for Semantic and Linguistic Data
semPlot	Path Diagrams and Visual Analysis of Various SEM Packages' Output
semPLS	Structural Equation Modeling Using Partial Least Squares
semPower	Power Analyses for SEM
semsfa	Semiparametric Estimation of Stochastic Frontier Models
semTools	Useful Tools for Structural Equation Modeling
semtree	Recursive Partitioning for Structural Equation Models
semver	'Semantic Versioning V2.0.0' Parser

Perhaps you really want one of those.

Duncan Murdoch

> 
> I tried downloading it from
> install.packages('semnet',repos='http://cran.us.r-project.org')
> and install.packages('semnet',repos='http://cran.revolutionanalytics.com/')
> and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
> doesnt seem to get success.
> 
> Please suggest some alternate.
> 
> Regards, Shivi
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From i@t@z@hn @ending from gm@il@com  Sat Jun  2 02:28:16 2018
From: i@t@z@hn @ending from gm@il@com (Ista Zahn)
Date: Fri, 1 Jun 2018 20:28:16 -0400
Subject: [R] Unable to take correct Web-snapshot
In-Reply-To: <CA+dpOJ=u+j1Xd1D+k8Er403A5-LMp=ozH=eBL2=Ytjs6CWkqKw@mail.gmail.com>
References: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
 <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>
 <CA+dpOJ=u+j1Xd1D+k8Er403A5-LMp=ozH=eBL2=Ytjs6CWkqKw@mail.gmail.com>
Message-ID: <CA+vqiLFVf7rFZhdUf6-+Mxs00ZkSuy24mt4gt4a7p6kQ3CVbZA@mail.gmail.com>

The documentation is at https://developers.coinbase.com/api/v2. You
can make GET requests in R using the httr packge.

--Ista

On Fri, Jun 1, 2018 at 11:12 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Thanks for that information.
>
> However how can I use R to directly get data from that API?
>
> On Fri, Jun 1, 2018 at 8:36 PM Martin M?ller Skarbiniks Pedersen <
> traxplayer at gmail.com> wrote:
>
>> On 1 June 2018 at 15:08, Christofer Bogaso <bogaso.christofer at gmail.com>
>> wrote:
>> > Hi again,
>> >
>> > I use the *webshot* package to take snapshot from Webpage. However, when
>> I
>> > try to take snapshot from* https://www.coinbase.com/
>> > <https://www.coinbase.com/>*, this fails to take the full snapshot of
>> that
>> > page.
>>
>> Yes, that is a general problem with many webshot programs and libraries.
>>
>> The coinbase page ( and many others ) uses a lot of javascript to generate
>> their
>> pages and the webshot programs must understand javascript in all
>> details which is hard.
>>
>> If you are looking for the coinbase prices you can use their api to
>> get json instead:
>>
>> https://api.coinbase.com/v2/prices/spot?currency=USD
>>
>> Regards
>> Martin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From djnordlund @ending from gm@il@com  Sat Jun  2 09:03:42 2018
From: djnordlund @ending from gm@il@com (Daniel Nordlund)
Date: Sat, 2 Jun 2018 00:03:42 -0700
Subject: [R] Cannot Load A Package
In-Reply-To: <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>
References: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
 <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>
Message-ID: <158aeed2-2b3a-ee06-f60a-d32c5196149a@gmail.com>

On 6/1/2018 4:17 PM, Duncan Murdoch wrote:
> On 01/06/2018 5:24 PM, Shivi Bhatia wrote:
>> Hi All,
>>
>> I am trying to download semnet package but getting the error:
>> package not available for R version 3.4.4.
> 
> As far as I can see, there is no semnet package on CRAN, and never has 
> been (or if there was, it was there by mistake).
> 
> Packages whose names start with "sem" are:
> 
> sem??? Structural Equation Models
> semantic.dashboard??? Dashboard with Semantic UI Support for 'shiny'
> Semblance??? Pair-Wise Semblance Using a Rank-Based Kernel
> semdiag??? Structural equation modeling diagnostics
> semds??? Structural Equation Multidimensional Scaling
> semGOF??? Goodness-of-fit indexes for structural equation models
> semiArtificial??? Generator of Semi-Artificial Data
> SemiCompRisks??? Hierarchical Models for Parametric and Semi-Parametric 
> Analyses of Semi-Competing Risks Data
> SEMID??? Identifiability of Linear Structural Equation Models
> SemiMarkov??? Multi-States Semi-Markov Models
> seminr??? Domain-Specific Language for Building PLS Structural Equation 
> Models
> SemiPar??? Semiparametic Regression
> SemiParSampleSel??? Semi-Parametric Sample Selection Modelling with 
> Continuous or Discrete Response
> SemiSupervised??? Safe Semi-Supervised Learning Tools
> semisupKernelPCA??? Kernel PCA projection, and semi-supervised variant
> SEMModComp??? Model Comparisons for SEM
> SemNetCleaner??? An Automated Cleaning Tool for Semantic and Linguistic 
> Data
> semPlot??? Path Diagrams and Visual Analysis of Various SEM Packages' 
> Output
> semPLS??? Structural Equation Modeling Using Partial Least Squares
> semPower??? Power Analyses for SEM
> semsfa??? Semiparametric Estimation of Stochastic Frontier Models
> semTools??? Useful Tools for Structural Equation Modeling
> semtree??? Recursive Partitioning for Structural Equation Models
> semver??? 'Semantic Versioning V2.0.0' Parser
> 
> Perhaps you really want one of those.
> 
> Duncan Murdoch
> 
>>
>> I tried downloading it from
>> install.packages('semnet',repos='http://cran.us.r-project.org')
>> and 
>> install.packages('semnet',repos='http://cran.revolutionanalytics.com/')
>> and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
>> doesnt seem to get success.
>>
>> Please suggest some alternate.
>>
>> Regards, Shivi
>>
>> ????[[alternative HTML version deleted]]
>>

Maybe this is what the OP is looking for

library(devtools)
install_github("kasperwelbers/semnet")


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From @hivipmp82 @ending from gm@il@com  Sat Jun  2 13:22:27 2018
From: @hivipmp82 @ending from gm@il@com (Shivi Bhatia)
Date: Sat, 2 Jun 2018 16:52:27 +0530
Subject: [R] Cannot Load A Package
In-Reply-To: <158aeed2-2b3a-ee06-f60a-d32c5196149a@gmail.com>
References: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
 <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>
 <158aeed2-2b3a-ee06-f60a-d32c5196149a@gmail.com>
Message-ID: <CAB=p7SqEroHFQb6zPvgLAqc881tRCRc+O2Qh-9_RRbSNexEo6w@mail.gmail.com>

Thank you Dan, this is what i had been searching. Thanks again,

Regards, Shivi

On Sat, Jun 2, 2018 at 12:33 PM, Daniel Nordlund <djnordlund at gmail.com>
wrote:

> On 6/1/2018 4:17 PM, Duncan Murdoch wrote:
>
>> On 01/06/2018 5:24 PM, Shivi Bhatia wrote:
>>
>>> Hi All,
>>>
>>> I am trying to download semnet package but getting the error:
>>> package not available for R version 3.4.4.
>>>
>>
>> As far as I can see, there is no semnet package on CRAN, and never has
>> been (or if there was, it was there by mistake).
>>
>> Packages whose names start with "sem" are:
>>
>> sem    Structural Equation Models
>> semantic.dashboard    Dashboard with Semantic UI Support for 'shiny'
>> Semblance    Pair-Wise Semblance Using a Rank-Based Kernel
>> semdiag    Structural equation modeling diagnostics
>> semds    Structural Equation Multidimensional Scaling
>> semGOF    Goodness-of-fit indexes for structural equation models
>> semiArtificial    Generator of Semi-Artificial Data
>> SemiCompRisks    Hierarchical Models for Parametric and Semi-Parametric
>> Analyses of Semi-Competing Risks Data
>> SEMID    Identifiability of Linear Structural Equation Models
>> SemiMarkov    Multi-States Semi-Markov Models
>> seminr    Domain-Specific Language for Building PLS Structural Equation
>> Models
>> SemiPar    Semiparametic Regression
>> SemiParSampleSel    Semi-Parametric Sample Selection Modelling with
>> Continuous or Discrete Response
>> SemiSupervised    Safe Semi-Supervised Learning Tools
>> semisupKernelPCA    Kernel PCA projection, and semi-supervised variant
>> SEMModComp    Model Comparisons for SEM
>> SemNetCleaner    An Automated Cleaning Tool for Semantic and Linguistic
>> Data
>> semPlot    Path Diagrams and Visual Analysis of Various SEM Packages'
>> Output
>> semPLS    Structural Equation Modeling Using Partial Least Squares
>> semPower    Power Analyses for SEM
>> semsfa    Semiparametric Estimation of Stochastic Frontier Models
>> semTools    Useful Tools for Structural Equation Modeling
>> semtree    Recursive Partitioning for Structural Equation Models
>> semver    'Semantic Versioning V2.0.0' Parser
>>
>> Perhaps you really want one of those.
>>
>> Duncan Murdoch
>>
>>
>>> I tried downloading it from
>>> install.packages('semnet',repos='http://cran.us.r-project.org')
>>> and install.packages('semnet',repos='http://cran.revolutionanaly
>>> tics.com/')
>>> and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
>>> doesnt seem to get success.
>>>
>>> Please suggest some alternate.
>>>
>>> Regards, Shivi
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>>
> Maybe this is what the OP is looking for
>
> library(devtools)
> install_github("kasperwelbers/semnet")
>
>
> Hope this is helpful,
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From yellowb@n@n@27 @ending from hotm@il@com  Sun Jun  3 15:52:58 2018
From: yellowb@n@n@27 @ending from hotm@il@com (Qian Yiting)
Date: Sun, 3 Jun 2018 13:52:58 +0000
Subject: [R] read .asc from web into R
Message-ID: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>

Hi All?

I am new to R. To import data with .asc ending from the web into R, I have tried many functions for importing data but it came out not well.  The problem may seem to be very basic but unfortunately I haven?t  found any useful information somehow.  Which command should I use for that purpose?

Here ist the url of the data:
https://moodle.lmu.de/pluginfile.php/218819/mod_resource/content/1/nba.asc

Thanks in advance!

Best regards,
Yiting

	[[alternative HTML version deleted]]


From @-dh@r @ending from northwe@tern@edu  Sun Jun  3 18:03:21 2018
From: @-dh@r @ending from northwe@tern@edu (Sumitrajit Dhar)
Date: Sun, 3 Jun 2018 11:03:21 -0500
Subject: [R] Running segmented on grouped data and collating model
 parameters in a data frame
Message-ID: <CAPfim6MmgTiQmQhSSZQwUAtYE6QGrd-d2u8EMU9=K1fQspgaGQ@mail.gmail.com>

Hi Folks,

I am trying to teach myself how to solve the problem described below but am
running out of time. Hence the plea for help. Thanks in advance.

Here is my data frame.

> t
# A tibble: 12 x 12
   subject  ageGrp ear   hearingGrp sex    freq    L2   Ldp Phidp    NF
SNR   Ldp_p
   <fct>    <fct>  <fct> <fct>      <fct> <int> <int> <dbl> <dbl> <dbl>
<dbl>   <dbl>
 1 HALAF573 A      L     A          F         2     0 -19.6 197.  -28.5
8.88  2.10e-6
 2 HALAF573 A      L     A          F         2     2 -18.7 203.  -22.0
3.25  2.31e-6
 3 HALAF573 A      L     A          F         2     4 -29.1 255.  -27.4
 -1.64  7.04e-7
 4 HALAF573 A      L     A          F         2     6 -12.4 174.  -12.2
 -0.206 4.78e-6
 5 HALAF573 A      L     A          F         4     0 -28.6 232.  -26.7
 -1.87  7.45e-7
 6 HALAF573 A      L     A          F         4     2 -27.2 351.  -28.8
1.59  8.68e-7
 7 HALAF573 A      L     A          F         4     4 -20.4  26.2 -35.0
 14.6   1.92e-6
 8 HALAF573 A      L     A          F         4     6 -20.0  85.1 -29.8
9.75  2.00e-6
 9 HALAF573 A      L     A          F         8     0 -22.8  39.2 -22.1
 -0.689 1.45e-6
10 HALAF573 A      L     A          F         8     2 -14.5  13.4 -20.7
6.23  3.76e-6
11 HALAF573 A      L     A          F         8     4 -17.3 345.  -21.6
4.30  2.73e-6
12 HALAF573 A      L     A          F         8     6 -14.1 320.  -21.7
7.59  3.94e-6

# Note that there are more levels of L2 (31 in total)  and 344 other
subjects but I truncated the frame for posting.

# I want to do this:  t %>%  group_by(freq) %>% [run segmented] %>% [create
a data frame with [subject, freq, breakpoint1, breakpoint2, slope1, slope2,
slope3, L2 when Ldp_p == 0].

# Also note that ultimately I will be grouping by "subject, freq".

# I can run the models and get believable results. The following run on a
data frame with L2 between 0 and 60.

out.lm <- lm(Ldp_p ~ L2, data = t)
o <- segmented(out.lm, seg.Z = ~L2, psi = list(L2 = c(20,45)),
               control = seg.control(display = FALSE)

o$psi
#        Initial     Est.    St.Err
#psi1.L2      20 30.78256 0.5085192
#psi2.L2      45 53.16390 0.4671701

slope(o)
slope(o)
$L2
#              Est.    St.Err. t value   CI(95%).l   CI(95%).u
#slope1  1.2060e-06 1.6606e-07  7.2622  8.6397e-07  1.5480e-06
#slope2  1.0708e-05 2.9196e-07 36.6770  1.0107e-05  1.1309e-05
#slope3 -4.5791e-06 1.3694e-06 -3.3439 -7.3995e-06 -1.7588e-06

Thanks again for bailing me out.

Regards,
Sumit

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jun  3 18:53:15 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 03 Jun 2018 10:53:15 -0600
Subject: [R] read .asc from web into R
In-Reply-To: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
Message-ID: <C0EA82DA-FD90-4C4F-BC14-CD8CE6349741@dcn.davis.ca.us>

Have you tried that url in a web browser? I encountered an access permission error. If you also encountered an error, then so would R. You need to download the file using appropriate access credentials (typ. through a web browser) and read it from disk.

FWIW the ".asc" extension is very nearly meaningless as to identifying the format of the data inside the file. The only useful information imparted by that extension is that you can use a text editor to view it and judge by inspection what the layout is. Originally that extension was used for storing the readable output of a program, which could be laid out in any form deemed readable by a human, with little regard for whether it would be machine-readable.

On June 3, 2018 7:52:58 AM MDT, Qian Yiting <yellowbanana27 at hotmail.com> wrote:
>Hi All?
>
>I am new to R. To import data with .asc ending from the web into R, I
>have tried many functions for importing data but it came out not well. 
>The problem may seem to be very basic but unfortunately I haven?t 
>found any useful information somehow.  Which command should I use for
>that purpose?
>
>Here ist the url of the data:
>https://moodle.lmu.de/pluginfile.php/218819/mod_resource/content/1/nba.asc
>
>Thanks in advance!
>
>Best regards,
>Yiting
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dwin@emiu@ @ending from comc@@t@net  Sun Jun  3 20:30:21 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sun, 3 Jun 2018 11:30:21 -0700
Subject: [R] read .asc from web into R
In-Reply-To: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
Message-ID: <F2712B71-F4A5-4B30-9891-2E15081F55A4@comcast.net>



> On Jun 3, 2018, at 6:52 AM, Qian Yiting <yellowbanana27 at hotmail.com> wrote:
> 
> Hi All?
> 
> I am new to R. To import data with .asc ending from the web into R, I have tried many functions for importing data but it came out not well.  The problem may seem to be very basic but unfortunately I haven?t  found any useful information somehow.  Which command should I use for that purpose?
> 
> Here ist the url of the data:
> https://moodle.lmu.de/pluginfile.php/218819/mod_resource/content/1/nba.asc

This URL requires authorization. You probably need to sign in with your username and password and download with a browser or FTP client. The instructions should be somewhere in their website (which is in German).


> 
> Thanks in advance!
> 
> Best regards,
> Yiting
> 
> 	[[alternative HTML version deleted]]

R-help is a plain text mailing list. Please read these instructions as well as the instructions at https://moodle.lmu.de/
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
David.

From d@vi@glenn@1952 @ending from gm@il@com  Mon Jun  4 03:54:33 2018
From: d@vi@glenn@1952 @ending from gm@il@com (Glenn Davis)
Date: Sun, 3 Jun 2018 21:54:33 -0400
Subject: [R] package colorspace and .WhitePoint question
Message-ID: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>

 In colorspace.R  I see:

    setAs("color", "LAB", function(from)
      LAB(.Call("as_LAB", from at coords, class(from), .WhitePoint, PACKAGE = "
colorspace"),
          names = dimnames(from at coords)[[1]]))
    ...
    .WhitePoint = NULL

and then in colorspace.c and the function CheckWhite(),
I see that .WhitePoint = NULL is converted to D65.

I would like to pass a different .WhitePoint to
    as( XYZ( 100,100,100)  , "LAB" )


I have tried 3 methods:
    as( XYZ( 100,100,100)  , "LAB", .WhitePoint=XYZ(95,100,105) )
    .WhitePoint = XYZ(95,100,105)
    assign( ".WhitePoint", XYZ(95,100,105), env=as.environment('package:
colorspace') )
but all fail, for different reasons.

How can I transform XYZ to LAB using a whitepoint different than D65 ?

Thanks,
Glenn Davis
gdavis at gluonics.com

	[[alternative HTML version deleted]]


From Achim@Zeilei@ @ending from uibk@@c@@t  Mon Jun  4 09:42:42 2018
From: Achim@Zeilei@ @ending from uibk@@c@@t (Achim Zeileis)
Date: Mon, 4 Jun 2018 09:42:42 +0200 (CEST)
Subject: [R] package colorspace and .WhitePoint question
In-Reply-To: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>
References: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1806040940020.26338@paninaro>

Glenn,

currently, this is currently not exposed in "colorspace" AFAICS. You can 
modify it by changing .WhitePoint inside colorspace's NAMESPACE, though:

R> assignInNamespace(".WhitePoint", rbind(c(95, 100, 105)),
+    ns = "colorspace")
R> as(XYZ(100, 100, 100), "LAB")
        L        A        B
[1,] 100 8.622384 3.226371

I'll have another look whether this could be exposed easily (cc also 
Paul).

Best,
Z

On Mon, 4 Jun 2018, Glenn Davis wrote:

> In colorspace.R  I see:
>
>    setAs("color", "LAB", function(from)
>      LAB(.Call("as_LAB", from at coords, class(from), .WhitePoint, PACKAGE = "
> colorspace"),
>          names = dimnames(from at coords)[[1]]))
>    ...
>    .WhitePoint = NULL
>
> and then in colorspace.c and the function CheckWhite(),
> I see that .WhitePoint = NULL is converted to D65.
>
> I would like to pass a different .WhitePoint to
>    as( XYZ( 100,100,100)  , "LAB" )
>
>
> I have tried 3 methods:
>    as( XYZ( 100,100,100)  , "LAB", .WhitePoint=XYZ(95,100,105) )
>    .WhitePoint = XYZ(95,100,105)
>    assign( ".WhitePoint", XYZ(95,100,105), env=as.environment('package:
> colorspace') )
> but all fail, for different reasons.
>
> How can I transform XYZ to LAB using a whitepoint different than D65 ?
>
> Thanks,
> Glenn Davis
> gdavis at gluonics.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jun  4 10:45:43 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 4 Jun 2018 14:15:43 +0530
Subject: [R] Time and date conversion
Message-ID: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>

Hi,

I have an automatic data feed and I obtained a Date vector in the following
format:

> Date
[1] "03 Jun 2018 10:01 am CT"    "01 Jun 2018 22:04:25 pm CT"

I now like to convert it to UTC time-zone

Is there any easy way to convert them so, particularly since 1st element
doesnt have any Second element whereas the 2nd element has.

Thanks for any pointer.

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Mon Jun  4 12:08:37 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Mon, 4 Jun 2018 10:08:37 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <04C0271F-0455-4F38-BD4C-773B24B2DA21@llnl.gov>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
 <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <04C0271F-0455-4F38-BD4C-773B24B2DA21@llnl.gov>
Message-ID: <CY1PR0201MB1834161A62B2963369868ACDEA670@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning Don, thank you for your support. I will give this all more investigation and submit my findings when finalized.

Cheers and thanks again for your help Sir.

WHP



From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 5:03 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

For your first question, you?re doing moving averages of 3 points (I assume that?s what order=3 does). For any given time point of your input data, that would be one before, one at, and one after the given time point. Do all of  your input times have both one before and one after?

Don?t know about your same 8 point forecast values question, not without running it myself, but I would say that if the data really is different, yet the forecasts are the same, it would have to be coincidental. But a priori this seems unlikely, so I?d inspect your script very carefully for mistakes.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 10:43 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hi Don, wow, you are so right. I picked that piece up from the bloggers tutorial and since I am R naive yet, I thought it was all one step

moving_average = forecast(ma(tdat[1:31], order=2), h=5)

Truly, I usually print and check at every step I can, as painful as it is sometimes.
Great lesson for this novice usR.

So the first and last values are NA in each case? Do you know why? Should I replace the NA with a value, say the average of the others?

Also, I have 5 series of data I am working with using this script and of course each gave me that warning, but only the one series had the same 8 Point Forecast values, is that coincidental you think?

Terrific of you to help, I really appreciate it.

WHP


From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 12:54 PM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

tnr.ma<http://tnr.ma> <- ma(dat3[1:28], order=3)
TNR_moving_average <- forecast(tnr.ma<http://tnr.ma>, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma<http://tnr.ma> and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com<http://bloggers.com>

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/<https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/>

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf<https://cran.r-project.org/web/packages/forecast/forecast.pdf>

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Mon Jun  4 12:54:26 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Mon, 4 Jun 2018 12:54:26 +0200
Subject: [R] Time and date conversion
In-Reply-To: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>
References: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>
Message-ID: <DA6671CE-8F73-48A0-807B-63A223B9BA4A@gmail.com>



> On 4 Jun 2018, at 10:45 , Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> Hi,
> 
> I have an automatic data feed and I obtained a Date vector in the following
> format:
> 
>> Date
> [1] "03 Jun 2018 10:01 am CT"    "01 Jun 2018 22:04:25 pm CT"
> 
> I now like to convert it to UTC time-zone
> 
> Is there any easy way to convert them so, particularly since 1st element
> doesnt have any Second element whereas the 2nd element has.

..and it also mixes up am/pm notation and 24hr clock.

There are two basic approaches to the format inconsistency thing:

(A) preprocess using gsub() constructions 

> gsub(" (..:..) ", " \\1:00 ", d.txt)
[1] "03 Jun 2018 10:01:00 am CT" "01 Jun 2018 22:04:25 pm CT"

(B) Try multiple formats

> d <- strptime(d.txt, format="%d %B %Y %H:%M:%S %p")
> d[is.na(d)] <- strptime(d.txt[is.na(d)], format="%d %B %Y %H:%M %p")
> d
[1] "2018-06-03 10:01:00 CEST" "2018-06-01 22:04:25 CEST"

I would likely go for (A) since you probably need to do something gsub-ish to get the TZ thing in place.

-pd

> 
> Thanks for any pointer.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From vito@muggeo @ending from unip@@it  Mon Jun  4 17:08:13 2018
From: vito@muggeo @ending from unip@@it (Vito M. R. Muggeo)
Date: Mon, 4 Jun 2018 17:08:13 +0200
Subject: [R] Running segmented on grouped data and collating model
 parameters in a data frame
In-Reply-To: <CAPfim6MmgTiQmQhSSZQwUAtYE6QGrd-d2u8EMU9=K1fQspgaGQ@mail.gmail.com>
References: <CAPfim6MmgTiQmQhSSZQwUAtYE6QGrd-d2u8EMU9=K1fQspgaGQ@mail.gmail.com>
Message-ID: <9801628c-ba51-de9c-6bdb-4455b3417290@unipa.it>

dear Sumi,
I am not familiar with the dplyr package (%>%..), however if you want to 
fit the model for each subject times freq interaction, a simple for loop 
will suffice.
Here possible code:

Assuming d is the dataframe, something like

subj<-levels(d$subject)
fr<-unique(d$freq)

#new dataframe where the estimates will be stored
newd<-expand.grid(subj=subj, freq=fr)
newd<-cbind(newd, matrix(-99,nrow(newd),9))
names(newd)[-(1:2)]<-c(paste0("slope",1:3), 
paste0(c("CI.inf.","CI.sup."), rep(paste0("slope",1:3),each=2)))

library(segmented)

#fit the model for each subject x freq combination
for(i in subj){
       for(j in fr){
             current.d<-subset(d, subject==i & freq==j)
             if(nrow(current.d)>0){
               o<-lm(Ldp_p~L2, data=current.d)
               os<-try(segmented(o, ~L2, psi=c(20,50)), silent=TRUE)
               if(class(os)[1]!="try-error"){
                      est.slope<-as.vector(slope(os)[[1]][,1]) #point est
                      ci.slope<-as.vector(t(slope(os)[[1]][,4:5])) #CI
                      newd[newd$subj==i & newd$freq==j, 
-c(1:2)]<-c(est.slope, ci.slope)
                                        }
                      }

       }
}


However it seems that you can be interested in segmented *mixed* 
models.. I mean, rather than estimating a segmented model for each 
subject, you could estimate a single model assuming random effects (for 
each model parameter, including the breakpoint) for each subject:

Have a look to

http://journals.sagepub.com/doi/abs/10.1177/1471082X13504721

Let me know (not on the R list) if you are interested in relevant code

best,
vito


Il 03/06/2018 18:03, Sumitrajit Dhar ha scritto:
> Hi Folks,
> 
> I am trying to teach myself how to solve the problem described below but am
> running out of time. Hence the plea for help. Thanks in advance.
> 
> Here is my data frame.
> 
>> t
> # A tibble: 12 x 12
>     subject  ageGrp ear   hearingGrp sex    freq    L2   Ldp Phidp    NF
> SNR   Ldp_p
>     <fct>    <fct>  <fct> <fct>      <fct> <int> <int> <dbl> <dbl> <dbl>
> <dbl>   <dbl>
>   1 HALAF573 A      L     A          F         2     0 -19.6 197.  -28.5
> 8.88  2.10e-6
>   2 HALAF573 A      L     A          F         2     2 -18.7 203.  -22.0
> 3.25  2.31e-6
>   3 HALAF573 A      L     A          F         2     4 -29.1 255.  -27.4
>   -1.64  7.04e-7
>   4 HALAF573 A      L     A          F         2     6 -12.4 174.  -12.2
>   -0.206 4.78e-6
>   5 HALAF573 A      L     A          F         4     0 -28.6 232.  -26.7
>   -1.87  7.45e-7
>   6 HALAF573 A      L     A          F         4     2 -27.2 351.  -28.8
> 1.59  8.68e-7
>   7 HALAF573 A      L     A          F         4     4 -20.4  26.2 -35.0
>   14.6   1.92e-6
>   8 HALAF573 A      L     A          F         4     6 -20.0  85.1 -29.8
> 9.75  2.00e-6
>   9 HALAF573 A      L     A          F         8     0 -22.8  39.2 -22.1
>   -0.689 1.45e-6
> 10 HALAF573 A      L     A          F         8     2 -14.5  13.4 -20.7
> 6.23  3.76e-6
> 11 HALAF573 A      L     A          F         8     4 -17.3 345.  -21.6
> 4.30  2.73e-6
> 12 HALAF573 A      L     A          F         8     6 -14.1 320.  -21.7
> 7.59  3.94e-6
> 
> # Note that there are more levels of L2 (31 in total)  and 344 other
> subjects but I truncated the frame for posting.
> 
> # I want to do this:  t %>%  group_by(freq) %>% [run segmented] %>% [create
> a data frame with [subject, freq, breakpoint1, breakpoint2, slope1, slope2,
> slope3, L2 when Ldp_p == 0].
> 
> # Also note that ultimately I will be grouping by "subject, freq".
> 
> # I can run the models and get believable results. The following run on a
> data frame with L2 between 0 and 60.
> 
> out.lm <- lm(Ldp_p ~ L2, data = t)
> o <- segmented(out.lm, seg.Z = ~L2, psi = list(L2 = c(20,45)),
>                 control = seg.control(display = FALSE)
> 
> o$psi
> #        Initial     Est.    St.Err
> #psi1.L2      20 30.78256 0.5085192
> #psi2.L2      45 53.16390 0.4671701
> 
> slope(o)
> slope(o)
> $L2
> #              Est.    St.Err. t value   CI(95%).l   CI(95%).u
> #slope1  1.2060e-06 1.6606e-07  7.2622  8.6397e-07  1.5480e-06
> #slope2  1.0708e-05 2.9196e-07 36.6770  1.0107e-05  1.1309e-05
> #slope3 -4.5791e-06 1.3694e-06 -3.3439 -7.3995e-06 -1.7588e-06
> 
> Thanks again for bailing me out.
> 
> Regards,
> Sumit
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Econom, Az e Statistiche
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo
Associate Editor, Statistical Modelling
Chair, Statistical Modelling Society


From p@ul @ending from @t@t@@uckl@nd@@c@nz  Tue Jun  5 01:13:12 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Tue, 5 Jun 2018 11:13:12 +1200
Subject: [R] [FORGED]  How to alpha entire plot?
In-Reply-To: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
References: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
Message-ID: <48f3aa41-22ce-0c71-e55a-fb8287eb5e8c@stat.auckland.ac.nz>

Hi

Here is one way to do it ...

col1 <- "red"
col2 <- "blue"
EU <- data.frame(EuStockMarkets)
with(EU, plot(DAX, CAC, col=col2, type="h", ylim=c(0,6000)))
par(new=TRUE)
with(EU, plot(DAX, FTSE, col=col1, type="h", ylim=c(0,6000)))

## Convert 'graphics' to 'grid'
library(gridGraphics)
grid.echo()
## grid.ls(print=grobPathListing, viewports=TRUE)

## Rasterize spikes
library(rasterize)
downViewport("graphics-window-1-1")
grid.rasterize("graphics-plot-1-spike-1")
upViewport(0)
downViewport("graphics-window-2-1")
grid.rasterize("graphics-plot-2-spike-1")
upViewport(0)

## Apply alpha adjustment to rasterized spikes
spike1 <- as.matrix(grid.get("graphics-plot-1-spike-1")$raster)
alphaSpike1 <- adjustcolor(spike1, alpha=.3)
dim(alphaSpike1) <- dim(spike1)
grid.edit("graphics-plot-1-spike-1", raster=as.raster(alphaSpike1))
spike2 <- as.matrix(grid.get("graphics-plot-2-spike-1")$raster)
alphaSpike2 <- adjustcolor(spike2, alpha=.3)
dim(alphaSpike2) <- dim(spike2)
grid.edit("graphics-plot-2-spike-1", raster=as.raster(alphaSpike2))

... though that may not be the best way and may just reflect what I have 
been thinking about recently ...

https://www.stat.auckland.ac.nz/~paul/Reports/rasterize/rasterize.html

Paul


On 01/06/18 08:56, Ed Siefker wrote:
> I have two chromatograms I want plotted on the same axes.
> I would like the plots to be transparent, so the first chart is
> not obscured.
> 
> I have tried adjustcolor(..., alpha.f=0.3), the problem is that
> my chromatogram is so dense with datapoints that they
> overlap and the entire graph just ends up a solid color.  The
> second histogram still obscures the first.
> 
> Consider this example:
> 
> 
> col1 <- adjustcolor("red", alpha.f=0.3)
> col2 <- adjustcolor("blue", alpha.f=0.3)
> EU <- data.frame(EuStockMarkets)
> with(EU, plot(DAX, CAC, col=col2, type="h", ylim=c(0,6000)))
> par(new=TRUE)
> with(EU, plot(DAX, FTSE, col=col1, type="h", ylim=c(0,6000)))
> 
> The density of the red plot around 2000 completely obscures the blue
> plot behind it.
> 
> What I would like to do is plot both plots in solid colors, then alpha
> the entire thing, and then overlay them.  Or some other method that
> achieves a comparable result.
> Thanks
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From pb @ending from infolink@com@br  Tue Jun  5 00:03:51 2018
From: pb @ending from infolink@com@br (Paulo Barata)
Date: Mon, 4 Jun 2018 19:03:51 -0300
Subject: [R] malware reported by antivirus on R Windows .exe file
Message-ID: <181e2208-1f3c-50de-1cb9-0d26a39d4159@infolink.com.br>

Dear R-list members,

This is just to make a report: Today, 04 June 2018, I attempted to 
download R-3.5.0 Patched build for Windows (a .exe file) from the 
Austria CRAN https site. My antivirus software, AVG Internet Security 
with all the latest updates, aborted the connection, saying that some 
malware was found - please see the attached Figure 1.

I went then to the CRAN mirror at Oswaldo Cruz Foundation, Rio de 
Janeiro, Brazil, and was able to download the .exe file. I immediately 
asked the AVG software to scan the file; it found something suspicious 
and sent the file for analysis in their labs. Some hours later, AVG said 
that the file was malicious, and sent it to quarantine; I am not able to 
figure out which kind of malware was supposed to exist in the file - 
please see the attached Figure 2.

Yesterday I was also not able to download the .exe file from the Austria 
CRAN site, for the same reason.

I am not able to evaluate the technical corretness of AVG's decisions. I 
am only reporting what happened.

Paulo Barata

(Rio de Janeiro - Brazil)


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fig-1-Link-from-CRAN-Austria-for-R-3.5.0-patched-0n-04-June-2018.png
Type: image/png
Size: 87899 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180604/29a72f2a/attachment.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fig-2-R-3.5.0-patched-from-Fiocruz-Brazil-site-on-04-June-2018.png
Type: image/png
Size: 25795 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180604/29a72f2a/attachment-0001.png>

From pd@lgd @ending from gm@il@com  Tue Jun  5 12:19:38 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Tue, 5 Jun 2018 12:19:38 +0200
Subject: [R] malware reported by antivirus on R Windows .exe file
In-Reply-To: <181e2208-1f3c-50de-1cb9-0d26a39d4159@infolink.com.br>
References: <181e2208-1f3c-50de-1cb9-0d26a39d4159@infolink.com.br>
Message-ID: <69F308AA-E502-41CB-9995-7F48978AA590@gmail.com>

These are almost always false positives. The checks are based on checksumming and sometimes a perfectly innocent .exe will match the checksum of some virus/malware. The .exe is rebuilt nightly and changes slightly between builds, so you may want just retry after a day or so.

(The AV vendors are behaving pretty irresponsibly in these matters, but as long as it only hits a patch build, I don't think anyone cares enough to take action.)

-pd

> On 5 Jun 2018, at 00:03 , Paulo Barata <pb at infolink.com.br> wrote:
> 
> Dear R-list members,
> 
> This is just to make a report: Today, 04 June 2018, I attempted to download R-3.5.0 Patched build for Windows (a .exe file) from the Austria CRAN https site. My antivirus software, AVG Internet Security with all the latest updates, aborted the connection, saying that some malware was found - please see the attached Figure 1.
> 
> I went then to the CRAN mirror at Oswaldo Cruz Foundation, Rio de Janeiro, Brazil, and was able to download the .exe file. I immediately asked the AVG software to scan the file; it found something suspicious and sent the file for analysis in their labs. Some hours later, AVG said that the file was malicious, and sent it to quarantine; I am not able to figure out which kind of malware was supposed to exist in the file - please see the attached Figure 2.
> 
> Yesterday I was also not able to download the .exe file from the Austria CRAN site, for the same reason.
> 
> I am not able to evaluate the technical corretness of AVG's decisions. I am only reporting what happened.
> 
> Paulo Barata
> 
> (Rio de Janeiro - Brazil)
> 
> <Fig-1-Link-from-CRAN-Austria-for-R-3.5.0-patched-0n-04-June-2018.png><Fig-2-R-3.5.0-patched-from-Fiocruz-Brazil-site-on-04-June-2018.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From zli@t@erv @ending from gm@il@com  Tue Jun  5 16:24:04 2018
From: zli@t@erv @ending from gm@il@com (zListserv)
Date: Tue, 5 Jun 2018 10:24:04 -0400
Subject: [R] Printing left-justified character strings
Message-ID: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>

Many (most?) R functions print character strings and factor labels right-justified.

print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.

Is there a way to set left-justification globally so every routine will print character strings left-justified?

From devendr@@ingh260 @ending from gm@il@com  Tue Jun  5 15:37:13 2018
From: devendr@@ingh260 @ending from gm@il@com (Devendra Singh)
Date: Tue, 5 Jun 2018 15:37:13 +0200
Subject: [R] Convert data frame to XML-Tree
Message-ID: <CAMSHyTNffGLjJQw8PY-pGq119TTcjLAm7u9COMKz1fA87ptZhw@mail.gmail.com>

Dear



I trying to convert data frame in xml using R in Spotfire. But getting
error:



"In xmlRoot.XMLInternalDocument(currentNodes[[1]]) : empty XML document"



Please Help.



Regards

Devendra

Regards
Devendra
Mobile-+91 8884266448

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Tue Jun  5 16:07:11 2018
From: ruipb@rr@d@@ @ending from @@po@pt (ruipbarradas)
Date: Tue, 05 Jun 2018 15:07:11 +0100
Subject: [R] malware reported by antivirus on R Windows .exe file
Message-ID: <h5nc2l40efyr7obq0fwlw45r.1528207631724@email.android.com>

Hello,
I had a similar problem a while ago.And it was also a problem with AVG.Apparently these false positives are a known issue with that AV. At the time I got an answer directing me to an online source on this but it was some 3-4 years ago and I don't believe I still have it.
Anyway, the problem was not worrying.
Hope this helps,
Rui Barradas?



Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: peter dalgaard <pdalgd at gmail.com> Data: 05/06/2018  11:19  (GMT+00:00) Para: Paulo Barata <pb at infolink.com.br> Cc: r-help at r-project.org Assunto: Re: [R] malware reported by antivirus on R Windows .exe file 
These are almost always false positives. The checks are based on checksumming and sometimes a perfectly innocent .exe will match the checksum of some virus/malware. The .exe is rebuilt nightly and changes slightly between builds, so you may want just retry after a day or so.

(The AV vendors are behaving pretty irresponsibly in these matters, but as long as it only hits a patch build, I don't think anyone cares enough to take action.)

-pd

> On 5 Jun 2018, at 00:03 , Paulo Barata <pb at infolink.com.br> wrote:
> 
> Dear R-list members,
> 
> This is just to make a report: Today, 04 June 2018, I attempted to download R-3.5.0 Patched build for Windows (a .exe file) from the Austria CRAN https site. My antivirus software, AVG Internet Security with all the latest updates, aborted the connection, saying that some malware was found - please see the attached Figure 1.
> 
> I went then to the CRAN mirror at Oswaldo Cruz Foundation, Rio de Janeiro, Brazil, and was able to download the .exe file. I immediately asked the AVG software to scan the file; it found something suspicious and sent the file for analysis in their labs. Some hours later, AVG said that the file was malicious, and sent it to quarantine; I am not able to figure out which kind of malware was supposed to exist in the file - please see the attached Figure 2.
> 
> Yesterday I was also not able to download the .exe file from the Austria CRAN site, for the same reason.
> 
> I am not able to evaluate the technical corretness of AVG's decisions. I am only reporting what happened.
> 
> Paulo Barata
> 
> (Rio de Janeiro - Brazil)
> 
> <Fig-1-Link-from-CRAN-Austria-for-R-3.5.0-patched-0n-04-June-2018.png><Fig-2-R-3.5.0-patched-from-Fiocruz-Brazil-site-on-04-June-2018.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Tue Jun  5 18:39:45 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 5 Jun 2018 12:39:45 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
Message-ID: <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>

On 05/06/2018 10:24 AM, zListserv wrote:
> Many (most?) R functions print character strings and factor labels right-justified.

Could you be more specific?  I see character strings left justified, 
e.g. x <- rep(c("a", "ab", "abc"), 7) prints as

   [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
   [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
  [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"

In a data frame, I do see it right justified:

      x
1    a
2   ab
3  abc
etc.

It is easy to change the printing of data frames:

print.data.frame <- function(x, ..., right = FALSE) {
   base::print.data.frame(x, ..., right = right)
}

 > data.frame(x)
    x
1  a
2  ab
3  abc

Are there other examples you're seeing?

Duncan Murdoch

> 
> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
> 
> Is there a way to set left-justification globally so every routine will print character strings left-justified?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From cry@n @ending from bingh@mton@edu  Tue Jun  5 18:45:20 2018
From: cry@n @ending from bingh@mton@edu (Christopher W Ryan)
Date: Tue, 5 Jun 2018 12:45:20 -0400
Subject: [R] printing an arbitrary-length character vector in columns on a
 page of a pdf report
Message-ID: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>

I'm writing code for a recurring report, using an R --> Sweave --> pdflatex
workflow. It includes a character vector of short words that I would like
to display compactly, in columns on a page, rather than one word per line,
which would waste a lot of space. The vector of words will increase
unpredictably over time, with future versions of the report.

I thought I would go about it by turning the character vector into a
matrix, as follows:

dd <- LETTERS
## set number of columns. Three for now
nc <- 3
## have to pad the character vector to a length that is multiple of nc
add <- nc - (length(dd) %% nc)
dd2 <- c(dd, rep("", add))
ddm <- matrix(dd2, ncol = nc)
library(Hmisc)
latex(ddm, file = "")

Any ideas for a more elegant way to do this?

Thanks.

--Chris Ryan
Binghamton University
and
Broome County Health Department
Binghamton, NY, US

	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Tue Jun  5 19:21:56 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Tue, 5 Jun 2018 17:21:56 +0000
Subject: [R] Printing left-justified character strings
In-Reply-To: <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
Message-ID: <d347321be5724187bdc962ffc1633c1c@tamu.edu>

I think the OP does not realize that head() and tail() do not print anything. They extract the first or last values/rows and if they are not assigned to an object, they automatically go to print(). 

Redefining print.data.frame would also fix that problem.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Tuesday, June 5, 2018 11:40 AM
To: zListserv <zlistserv at gmail.com>; r-help at r-project.org
Subject: Re: [R] Printing left-justified character strings

On 05/06/2018 10:24 AM, zListserv wrote:
> Many (most?) R functions print character strings and factor labels right-justified.

Could you be more specific?  I see character strings left justified, 
e.g. x <- rep(c("a", "ab", "abc"), 7) prints as

   [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
   [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
  [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"

In a data frame, I do see it right justified:

      x
1    a
2   ab
3  abc
etc.

It is easy to change the printing of data frames:

print.data.frame <- function(x, ..., right = FALSE) {
   base::print.data.frame(x, ..., right = right)
}

 > data.frame(x)
    x
1  a
2  ab
3  abc

Are there other examples you're seeing?

Duncan Murdoch

> 
> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
> 
> Is there a way to set left-justification globally so every routine will print character strings left-justified?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From zli@t@erv @ending from gm@il@com  Tue Jun  5 20:49:24 2018
From: zli@t@erv @ending from gm@il@com (zListserv)
Date: Tue, 5 Jun 2018 14:49:24 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
Message-ID: <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>

Duncan et al

I tried to redefine print.data.frame the way you suggested, but I misplaced the ellipsis by putting it at the end of the function definition instead of immediately following the name of the data frame.

Works now.

Thanks!


> On 2018-06-05, at 12:39, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/06/2018 10:24 AM, zListserv wrote:
>> Many (most?) R functions print character strings and factor labels right-justified.
> 
> Could you be more specific?  I see character strings left justified, e.g. x <- rep(c("a", "ab", "abc"), 7) prints as
> 
>  [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
>  [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
> [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"
> 
> In a data frame, I do see it right justified:
> 
>     x
> 1    a
> 2   ab
> 3  abc
> etc.
> 
> It is easy to change the printing of data frames:
> 
> print.data.frame <- function(x, ..., right = FALSE) {
>  base::print.data.frame(x, ..., right = right)
> }
> 
> > data.frame(x)
>   x
> 1  a
> 2  ab
> 3  abc
> 
> Are there other examples you're seeing?
> 
> Duncan Murdoch
> 
>> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
>> Is there a way to set left-justification globally so every routine will print character strings left-justified?
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 


From zli@t@erv @ending from gm@il@com  Wed Jun  6 01:49:10 2018
From: zli@t@erv @ending from gm@il@com (zListserv)
Date: Tue, 5 Jun 2018 19:49:10 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
Message-ID: <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>

p.s.  It seems to work for print command, but not for head, tail, or printing a data frame, per below.  Any way fix the others so they all left-justify?

R> x <- as.data.frame(rep(c("a", "ab", "abc"), 7))
R> print(x)
 rep(c("a", "ab", "abc"), 7)
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
R> head(x)
  rep(c("a", "ab", "abc"), 7)
1                           a
2                          ab
3                         abc
4                           a
5                          ab
6                         abc
R> x
   rep(c("a", "ab", "abc"), 7)
1                            a
2                           ab
3                          abc
4                            a
5                           ab
6                          abc
7                            a
8                           ab
9                          abc
10                           a
11                          ab
12                         abc
13                           a
14                          ab
15                         abc
16                           a
17                          ab
18                         abc
19                           a
20                          ab
21                         abc

> On 2018-06-05, at 14:49, zListserv <zlistserv at gmail.com> wrote:
> 
> Duncan et al
> 
> I tried to redefine print.data.frame the way you suggested, but I misplaced the ellipsis by putting it at the end of the function definition instead of immediately following the name of the data frame.
> 
> Works now.
> 
> Thanks!
> 
> 
>> On 2018-06-05, at 12:39, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 05/06/2018 10:24 AM, zListserv wrote:
>>> Many (most?) R functions print character strings and factor labels right-justified.
>> 
>> Could you be more specific?  I see character strings left justified, e.g. x <- rep(c("a", "ab", "abc"), 7) prints as
>> 
>> [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
>> [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
>> [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"
>> 
>> In a data frame, I do see it right justified:
>> 
>>    x
>> 1    a
>> 2   ab
>> 3  abc
>> etc.
>> 
>> It is easy to change the printing of data frames:
>> 
>> print.data.frame <- function(x, ..., right = FALSE) {
>> base::print.data.frame(x, ..., right = right)
>> }
>> 
>>> data.frame(x)
>>  x
>> 1  a
>> 2  ab
>> 3  abc
>> 
>> Are there other examples you're seeing?
>> 
>> Duncan Murdoch
>> 
>>> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
>>> Is there a way to set left-justification globally so every routine will print character strings left-justified?
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 


From murdoch@dunc@n @ending from gm@il@com  Wed Jun  6 02:16:10 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Tue, 5 Jun 2018 20:16:10 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
Message-ID: <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>

On 05/06/2018 7:49 PM, zListserv wrote:
> p.s.  It seems to work for print command, but not for head, tail, or printing a data frame, per below.  Any way fix the others so they all left-justify?

You haven't shown us what you did.

Duncan Murdoch


From ccberry @ending from uc@d@edu  Wed Jun  6 04:33:07 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Wed, 6 Jun 2018 02:33:07 +0000
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
Message-ID: <BA0E392E-508F-4C93-A577-A156C93ACCF6@ucsd.edu>



> On Jun 5, 2018, at 9:45 AM, Christopher W Ryan <cryan at binghamton.edu> wrote:
> 
> I'm writing code for a recurring report, using an R --> Sweave --> pdflatex
> workflow. It includes a character vector of short words that I would like
> to display compactly, in columns on a page, rather than one word per line,
> which would waste a lot of space. The vector of words will increase
> unpredictably over time, with future versions of the report.
> 
> I thought I would go about it by turning the character vector into a
> matrix, as follows:
> 
> dd <- LETTERS
> ## set number of columns. Three for now
> nc <- 3
> ## have to pad the character vector to a length that is multiple of nc
> add <- nc - (length(dd) %% nc)
> dd2 <- c(dd, rep("", add))
> ddm <- matrix(dd2, ncol = nc)
> library(Hmisc)
> latex(ddm, file = "")
> 
> Any ideas for a more elegant way to do this?
> 

Use a LaTeX longtable environment (and add \usepackage{longtable} to the header of your document). Put something like this in your *.Rnw file:

% longtable header goes here

<<results=tex>>=
cat( paste(dd, ifelse( seq(along = dd) %% 3 == 0, "\\\\\n", "&")) )
@

% longtable footer goes here

should do it. But if there are exactly 3*k elements, you might skip the trailing `\\'.

If you are unclear what the header/footer ought to look like try this:

HMisc::latex(ddm, file="", longtable=TRUE)

and you should figure it out.

HTH,

Chuck

From rmh @ending from temple@edu  Wed Jun  6 05:10:53 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Tue, 5 Jun 2018 23:10:53 -0400
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
Message-ID: <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>

I think this is cuter, and it is a hair faster.

n <- length(dd)
ddm <- matrix("", (n+2) %/% nc, nc)
ddm[1:n] <- dd

Rich


> system.time(for (i in 1:10000) {
+ add <- nc - (length(dd) %% nc)
+ dd2 <- c(dd, rep("", add))
+ ddm <- matrix(dd2, ncol = nc)
+ })
   user  system elapsed
  0.064   0.100   0.483
>
> system.time(for (i in 1:10000) {
+ n <- length(dd)
+ ddm <- matrix("", (n+2) %/% nc, nc)
+ ddm[1:n] <- dd
+ })
   user  system elapsed
  0.045   0.000   0.045

On Tue, Jun 5, 2018 at 12:45 PM, Christopher W Ryan
<cryan at binghamton.edu> wrote:
> I'm writing code for a recurring report, using an R --> Sweave --> pdflatex
> workflow. It includes a character vector of short words that I would like
> to display compactly, in columns on a page, rather than one word per line,
> which would waste a lot of space. The vector of words will increase
> unpredictably over time, with future versions of the report.
>
> I thought I would go about it by turning the character vector into a
> matrix, as follows:
>
> dd <- LETTERS
> ## set number of columns. Three for now
> nc <- 3
> ## have to pad the character vector to a length that is multiple of nc
> add <- nc - (length(dd) %% nc)
> dd2 <- c(dd, rep("", add))
> ddm <- matrix(dd2, ncol = nc)
> library(Hmisc)
> latex(ddm, file = "")
>
> Any ideas for a more elegant way to do this?
>
> Thanks.
>
> --Chris Ryan
> Binghamton University
> and
> Broome County Health Department
> Binghamton, NY, US
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From cry@n @ending from bingh@mton@edu  Wed Jun  6 05:29:44 2018
From: cry@n @ending from bingh@mton@edu (Christopher W. Ryan)
Date: Tue, 5 Jun 2018 23:29:44 -0400
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
 <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>
Message-ID: <cf5ee983-45a5-50e1-3ff1-0e6eefe21a4f@binghamton.edu>

Richard--

Nice. If I understand your code correctly, in the line

ddm <- matrix("", (n+2) %/% nc, nc)

I could instead use

ddm <- matrix("", (n + nc - 1) %/% nc, nc)

for generalizability, as I may have to increase nc as the list of words
grows ever longer.

Thanks everyone. Several good suggestions.

--Chris Ryan

Richard M. Heiberger wrote:
> n <- length(dd)
> ddm <- matrix("", (n+2) %/% nc, nc)
> ddm[1:n] <- dd


From rmh @ending from temple@edu  Wed Jun  6 06:52:45 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Wed, 6 Jun 2018 00:52:45 -0400
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <cf5ee983-45a5-50e1-3ff1-0e6eefe21a4f@binghamton.edu>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
 <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>
 <cf5ee983-45a5-50e1-3ff1-0e6eefe21a4f@binghamton.edu>
Message-ID: <CAGx1TMB9vihNrHDbDGqHi3nw2Hdnr2zWpPtAin4=hsRf6vNM=g@mail.gmail.com>

yes, thank you for catching that slip.

On Tue, Jun 5, 2018 at 11:29 PM, Christopher W. Ryan
<cryan at binghamton.edu> wrote:
> Richard--
>
> Nice. If I understand your code correctly, in the line
>
> ddm <- matrix("", (n+2) %/% nc, nc)
>
> I could instead use
>
> ddm <- matrix("", (n + nc - 1) %/% nc, nc)
>
> for generalizability, as I may have to increase nc as the list of words
> grows ever longer.
>
> Thanks everyone. Several good suggestions.
>
> --Chris Ryan
>
> Richard M. Heiberger wrote:
>> n <- length(dd)
>> ddm <- matrix("", (n+2) %/% nc, nc)
>> ddm[1:n] <- dd
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From nguy2952 @ending from umn@edu  Wed Jun  6 04:35:27 2018
From: nguy2952 @ending from umn@edu (nguy2952 University of Minnesota)
Date: Tue, 5 Jun 2018 21:35:27 -0500
Subject: [R] Decision Tree Issue: Why does tree() not pick all variables for
 the nodes
Message-ID: <CAPjFEwUxA7yG=mqHYiL5m439yuTOOiysOX4n9FFmqs8nkUZdMg@mail.gmail.com>

I am working on a project at my work place and I am running into some
issues with my decision tree analysis. THIS IS NOT A HOMEWORK ASSIGNMENT.
Sample dataset

    PRODUCT_SUB_LINE_DESCR   MAJOR_CATEGORY_DESCR      CUST_REGION_DESCR
    SUNDRY                        SMALL EQUIP          NORTH EAST REGION
    SUNDRY                        SMALL EQUIP          SOUTH EAST REGION
    SUNDRY                        SMALL EQUIP          SOUTH EAST REGION
    SUNDRY                        SMALL EQUIP          NORTH EAST REGION
    SUNDRY                        PREVENTIVE          SOUTH CENTRAL REGION
    SUNDRY                        PREVENTIVE          SOUTH EAST REGION
    SUNDRY                        PREVENTIVE          SOUTH EAST REGION
    SUNDRY                        SMALL EQUIP          NORTH CENTRAL REGION
    SUNDRY                        SMALL EQUIP          MOUNTAIN WEST REGION
    SUNDRY                        SMALL EQUIP          MOUNTAIN WEST REGION
    SUNDRY                        COMPOSITE          NORTH CENTRAL REGION
    SUNDRY                        COMPOSITE          NORTH CENTRAL REGION
    SUNDRY                        COMPOSITE          OHIO VALLEY REGION
    SUNDRY                        COMPOSITE          NORTH EAST REGION

    Sales QtySold      MFGCOST MarginDollars new_ProductName
    209.97 3           134.55 72.72          no
    -76.15 -1           -44.85 -30.4          no
    275.6 2           162.5     109.84          no
    138.7 1           81.25     55.82          no
    226     2           136     87.28          no
    115     1           68     45.64          no
    210.7 2           136     71.98          no
    29     1           18.85     9.77          no
    29     1           18.85     9.77          no
    46.32 2           37.7     7.86          no
    159.86 1           132.4     24.81          no
    441.3 2           264.8     171.2          no
    209.62 1           132.4     74.57          no
    209.62 1           132.4     74.57          no

1) My tree has only two nodes and here is why

    >summary(tree_model)
    Classification tree:
    tree(formula = new_ProductName ~ ., data = training_data)
    Variables actually used in tree construction:
    [1] "PRODUCT_SUB_LINE_DESCR"
    Number of terminal nodes:  2
    Residual mean deviance:  0 = 0 / 41140
    Misclassification error rate: 0 = 0 / 41146

2) I did create a new data frame which has only factors with level less
than 22 level. There is one factor with 25 levels, but the tree() does not
give an error so I think the algorithm accepts 25 levels

    >str(new_Dataset)
    'data.frame': 51433 obs. of  7 variables:
     $ PRODUCT_SUB_LINE_DESCR: Factor w/ 3 levels "Handpieces","PRIVATE
                                 LABEL",..: 3 3 3 3 3 3 3 3 3 3 ...
     $ MAJOR_CATEGORY_DESCR  : Factor w/ 25 levels "AIR ABRASION",..: 23 23
23
                                 23 21 21 21 23 23 23 ...
     $ CUST_REGION_DESCR     : Factor w/ 7 levels "MOUNTAIN WEST
REGION",..: 3
                                 6 6 3 5 6 6 2 1 1 ...
     $ Sales                 : num  210 -76.2 275.6 138.7 226 ...
     $ QtySold               : int  3 -1 2 1 2 1 2 1 1 2 ...
     $ MFGCOST               : num  134.6 -44.9 162.5 81.2 136 ...
     $ MarginDollars         : num  72.7 -30.4 109.8 55.8 87.3 ...

3) Here is how I set up my analysis

     # I choose product name as my main attribute(maybe that is why it
appears at
     the root node?)
     new_ProductName = ifelse( PRODUCT_SUB_LINE_DESCR == "PRIVATE
                                  LABEL","yes","no")
     data = data.frame(new_Dataset, new_ProductName)
     set.seed(100)
     train = sample(1:nrow(data), 0.8*nrow(data)) # training row indices
     training_data = data[train,] # training data
     testing_data = data[-train,] # testing data

     #fit the tree model using training data
     tree_model = tree(new_ProductName ~.,data = training_data)
     summary(tree_model)
     plot(tree_model)
     text(tree_model, pretty = 0)
     out = predict(tree_model) # predict the training data
     # actuals
     input.newproduct = as.character(training_data$new_ProductName)
     # predicted
     pred.newproduct = colnames(out)[max.col(out,ties.method = c("first"))]
     mean (input.newproduct != pred.newproduct) # misclassification %

    # Cross Validation to see how much we need to prune the tree
    set.seed(400)
    cv_Tree = cv.tree(tree_model, FUN = prune.misclass) # run cross
validation
    attach(cv_Tree)
    plot(cv_Tree) # plot the CV
    plot(size, dev, type = "b")
    # set size corresponding to lowest value in the plot above.
    treePruneMod = prune.misclass(tree_model, best = 9) plot(treePruneMod)
    text(treePruneMod, pretty = 0)
    out = predict(treePruneMod) # fit the pruned tree
    # Predicted
    pred.newproduct = colnames(out)[max.col(out,ties.method = c("random"))]
    # calculate Mis-classification error
    mean(training_data$new_ProductName != pred.newproduct)
    # Predict testData with Pruned tree
    out = predict(treePruneMod, testing_data, type = "class")

4) I have never done this before. I watched a couple of youtube videos and
started to do this. I welcome great advice, explanation, criticism and
please help me through this process. This has been challenging to me.


    > table(data$PRODUCT_SUB_LINE_DESCR, data$new_ProductName)

                      no      yes
      Handpieces      164     0
      PRIVATE LABEL   0       14802
      SUNDRY          36467    0

Best,
Hugh N

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot01.png
Type: image/png
Size: 13333 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180605/07f77314/attachment.png>

From m@@@imo@bre@@@n @ending from @rp@@veneto@it  Wed Jun  6 10:13:10 2018
From: m@@@imo@bre@@@n @ending from @rp@@veneto@it (Massimo Bressan)
Date: Wed, 6 Jun 2018 10:13:10 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
Message-ID: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>

#given the following reproducible and simplified example 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

#I need to get the following result 

r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
r 

# i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
#any help for that? 

#so far I've just managed to "aggregate" and "count", like: 

library(sqldf) 
sqldf('select count(*) as count_id, A as unique_A from t group by A') 

library(dplyr) 
t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 

# thank you 


	[[alternative HTML version deleted]]


From c@l@ndr@ @ending from rgzm@de  Wed Jun  6 10:21:48 2018
From: c@l@ndr@ @ending from rgzm@de (Ivan Calandra)
Date: Wed, 6 Jun 2018 10:21:48 +0200
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <5628b730-026c-93c2-9c61-60d2407bcc1f@rgzm.de>

Hi Massimo,

Something along those lines could help you I guess:
t$A <- factor(t$A)
sapply(levels(t$A), function(x) which(t$A==x))

You can then play with the output using paste()

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 06/06/2018 10:13, Massimo Bressan wrote:
> #given the following reproducible and simplified example
>
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))
> t
>
> #I need to get the following result
>
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10'))
> r
>
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A"
> #any help for that?
>
> #so far I've just managed to "aggregate" and "count", like:
>
> library(sqldf)
> sqldf('select count(*) as count_id, A as unique_A from t group by A')
>
> library(dplyr)
> t%>%group_by(unique_A=A) %>% summarise(count_id = n())
>
> # thank you
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From @igbert @ending from wiwi@hu-berlin@de  Wed Jun  6 10:33:56 2018
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Wed, 6 Jun 2018 10:33:56 +0200
Subject: [R] Ubuntu 18.04 / R 3.4.4 / shinyjs / V8
Message-ID: <ee46a9d6-d44f-404c-0c02-d44795a93c10@wiwi.hu-berlin.de>

Hi,

if I want to use shinyjs package then I need the V8 package.
Therefore I installed

apt-get install libv8-3.14-dev

and tried

install.packages("V8")

and get

** preparing package for lazy loading
Error in dyn.load(file, DLLpath = DLLpath, ...) :
   kann shared object 
'/home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so' 
nicht laden:
   /usr/lib/x86_64-linux-gnu/libcurl.so.4: version `CURL_OPENSSL_3' not 
found (required by 
/home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so)
ERROR: lazy loading failed for package ?V8?

I also tried to install curl3, but when I install R 3.4.4 then curl3 is 
replaced by curl4 :(

Any ideas what I could do?

Thanks

Sigbert

-- 
Sprechstunde: Fr 12-13, SPA1, R308
https://hu.berlin/sk
https://hu.berlin/mmstat3


From zli@t@erv @ending from gm@il@com  Wed Jun  6 12:28:54 2018
From: zli@t@erv @ending from gm@il@com (zListserv)
Date: Wed, 6 Jun 2018 06:28:54 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
 <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
Message-ID: <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>

Sorry.  Here's how I re-defined print, print.default, and print.data.frame:

print = function(df, ..., right=FALSE, row.names=FALSE) base::print(df, ..., right=right, row.names=row.names)

print.default = function(df, ..., right=FALSE, row.names=FALSE) base::print.default(df, ..., right=right, row.names=row.names)

print.data.frame = function(df, ..., right=FALSE, row.names=FALSE) base::print.data.frame(df, ..., right=right, row.names=row.names)

and this is what it yields (I would like it to print without row names and with text left-adjusted):

R> x <- as.data.frame(rep(c("a", "ab", "abc"), 7))
R> print(x)
rep(c("a", "ab", "abc"), 7)
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
R> head(x)
 rep(c("a", "ab", "abc"), 7)
1                           a
2                          ab
3                         abc
4                           a
5                          ab
6                         abc
R> x
  rep(c("a", "ab", "abc"), 7)
1                            a
2                           ab
3                          abc
4                            a
5                           ab
6                          abc
7                            a
8                           ab
9                          abc
10                           a
11                          ab
12                         abc
13                           a
14                          ab
15                         abc
16                           a
17                          ab
18                         abc
19                           a
20                          ab
21                         abc


> On 2018-06-05, at 20:16, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/06/2018 7:49 PM, zListserv wrote:
>> p.s.  It seems to work for print command, but not for head, tail, or printing a data frame, per below.  Any way fix the others so they all left-justify?
> 
> You haven't shown us what you did.
> 
> Duncan Murdoch


From murdoch@dunc@n @ending from gm@il@com  Wed Jun  6 13:06:30 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 6 Jun 2018 07:06:30 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
 <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
 <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>
Message-ID: <9cdac39e-2d8a-5618-b897-d821655ebc81@gmail.com>

On 06/06/2018 6:28 AM, zListserv wrote:
> Sorry.  Here's how I re-defined print, print.default, and print.data.frame:
> 
> print = function(df, ..., right=FALSE, row.names=FALSE) base::print(df, ..., right=right, row.names=row.names)

base::print doesn't have those arguments.  It only has arguments 
print(x, ...).  You shouldn't redefine it, since it just dispatches to 
one of the methods.

In fact, I think this redefinition is causing the problem way down 
below:  instead of your two methods applying to the base package 
generic, they are applying only to your own generic defined here. 
Auto-printing uses the base generic.

> 
> print.default = function(df, ..., right=FALSE, row.names=FALSE) base::print.default(df, ..., right=right, row.names=row.names)

base::print.default doesn't have a row.names argument.  It won't cause 
an error, but will be ignored.  It already has `right=FALSE` as a 
default, so it seems pretty pointless to redefine it.

> 
> print.data.frame = function(df, ..., right=FALSE, row.names=FALSE) base::print.data.frame(df, ..., right=right, row.names=row.names)

That definition makes sense if you want left justification and no row 
names, but remember that some print methods may rely on the display of 
row names for sensible output.  (I can't think of any examples right 
now, but I'd look at print methods for summary objects if I was 
searching for them.  There are several that rely on row names when they 
print matrices, e.g. print.summary.lm.)

And as a general rule, you should use the same argument names as in the 
generic, i.e. x instead of df.  It's pretty rare, but someone might say
print(x = data.frame(1:10)), and your print.data.frame method would 
absorb the argument into the ... , yielding an error

'argument "df" is missing, with no default'



> 
> and this is what it yields (I would like it to print without row names and with text left-adjusted):
> 
> R> x <- as.data.frame(rep(c("a", "ab", "abc"), 7))
> R> print(x)
> rep(c("a", "ab", "abc"), 7)
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> R> head(x)
>   rep(c("a", "ab", "abc"), 7)
> 1                           a
> 2                          ab
> 3                         abc
> 4                           a
> 5                          ab
> 6                         abc

I don't get that, because I didn't redefine the generic, only the methods.

> R> x
>    rep(c("a", "ab", "abc"), 7)
> 1                            a
> 2                           ab
> 3                          abc

Or that.

Duncan Murdoch


From zli@t@erv @ending from gm@il@com  Wed Jun  6 13:24:03 2018
From: zli@t@erv @ending from gm@il@com (zListserv)
Date: Wed, 6 Jun 2018 07:24:03 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <9cdac39e-2d8a-5618-b897-d821655ebc81@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
 <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
 <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>
 <9cdac39e-2d8a-5618-b897-d821655ebc81@gmail.com>
Message-ID: <D52FDF25-F7C8-4BD0-95B7-372B45E5AA5D@gmail.com>

Duncan

Many thanks.  I removed the (re-)definitions for print and print.default, and I redefined print.data.frame using 'x' instead of 'df'.

Your point about possible issues downstream with row names is well taken.  I'll keep a lookout for any untoward side effects.

In the meantime, all is well and I'm grateful for your help.

> On 2018-06-06, at 07:06, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 06/06/2018 6:28 AM, zListserv wrote:
>> Sorry.  Here's how I re-defined print, print.default, and print.data.frame:
>> print = function(df, ..., right=FALSE, row.names=FALSE) base::print(df, ..., right=right, row.names=row.names)
> 
> base::print doesn't have those arguments.  It only has arguments print(x, ...).  You shouldn't redefine it, since it just dispatches to one of the methods.
> 
> In fact, I think this redefinition is causing the problem way down below:  instead of your two methods applying to the base package generic, they are applying only to your own generic defined here. Auto-printing uses the base generic.
> 
>> print.default = function(df, ..., right=FALSE, row.names=FALSE) base::print.default(df, ..., right=right, row.names=row.names)
> 
> base::print.default doesn't have a row.names argument.  It won't cause an error, but will be ignored.  It already has `right=FALSE` as a default, so it seems pretty pointless to redefine it.
> 
>> print.data.frame = function(df, ..., right=FALSE, row.names=FALSE) base::print.data.frame(df, ..., right=right, row.names=row.names)
> 
> That definition makes sense if you want left justification and no row names, but remember that some print methods may rely on the display of row names for sensible output.  (I can't think of any examples right now, but I'd look at print methods for summary objects if I was searching for them.  There are several that rely on row names when they print matrices, e.g. print.summary.lm.)
> 
> And as a general rule, you should use the same argument names as in the generic, i.e. x instead of df.  It's pretty rare, but someone might say
> print(x = data.frame(1:10)), and your print.data.frame method would absorb the argument into the ... , yielding an error
> 
> 'argument "df" is missing, with no default'
> 
> <snip>


From Bill@Poling @ending from zeli@@com  Wed Jun  6 13:24:47 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 6 Jun 2018 11:24:47 +0000
Subject: [R] Help with "ERROR: lazy loading failed for package 'psycho'"
Message-ID: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning. In my continuing pursuit of self-taught R programming I am interested in following the tutorial provided by Bloggers.com "Beautiful and Powerful Correlation Tables in R"


https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r-2/ 3/

Although, I have hit a snag in the first step?

devtools::install_github("neuropsychology/psycho.R") # Install the newest version
library(psycho)
library(tidyverse)

I have installed both psycho & tidyverse pkgs, however, when I go to run the devtools::install_github("neuropsychology/psycho.R") piece I get this warning.

Downloading GitHub repo neuropsychology/psycho.R at master
from URL https://api.github.com/repos/neuropsychology/psycho.R/zipball/master
Installing psycho
"C:/Users/bp/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
  "C:/Users/bp/AppData/Local/Temp/RtmpCkkmhB/devtools25601693478c/neuropsychology-psycho.R-b62e316" --library="C:/Users/bp/Documents/R/R-3.4.4/library" --install-tests

* installing *source* package 'psycho' ...
** R
** data
*** moving datasets to lazyload DB
** inst
** tests
** preparing package for lazy loading
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
  there is no package called 'Matrix'
ERROR: lazy loading failed for package 'psycho'
* removing 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
* restoring previous 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
In R CMD INSTALL
Installation failed: Command failed (1)
> install.packages("psycho")
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.2.3.zip'
Content type 'application/zip' length 1650628 bytes (1.6 MB)
downloaded 1.6 MB

Just a guess, but does this have to do with presetting my work directory?

setwd("C:/WHP/R/PracticeScripts and Testing Ideas")

Here is my session info:


> sessionInfo() #R version 3.4.4 (2018-03-15)

R version 3.4.4 (2018-03-15)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1


.libPaths() #"C:/Users/bp/Documents/R/R-3.4.4/library"

[1] "C:/Users/bp/Documents/R/R-3.4.4/library"


Thank you for any advice.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From ericjberger @ending from gm@il@com  Wed Jun  6 13:49:42 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 6 Jun 2018 14:49:42 +0300
Subject: [R] Help with "ERROR: lazy loading failed for package 'psycho'"
In-Reply-To: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAGgJW74p8m+KZg-AapE1uR_tCirV-GGnM-Ddv6j3Cy7xhLC6cQ@mail.gmail.com>

> install.packages("Matrix")


On Wed, Jun 6, 2018 at 2:24 PM, Bill Poling <Bill.Poling at zelis.com> wrote:

> Good morning. In my continuing pursuit of self-taught R programming I am
> interested in following the tutorial provided by Bloggers.com "Beautiful
> and Powerful Correlation Tables in R"
>
>
> https://www.r-bloggers.com/beautiful-and-powerful-
> correlation-tables-in-r-2/ 3/
>
> Although, I have hit a snag in the first step?
>
> devtools::install_github("neuropsychology/psycho.R") # Install the newest
> version
> library(psycho)
> library(tidyverse)
>
> I have installed both psycho & tidyverse pkgs, however, when I go to run
> the devtools::install_github("neuropsychology/psycho.R") piece I get this
> warning.
>
> Downloading GitHub repo neuropsychology/psycho.R at master
> from URL https://api.github.com/repos/neuropsychology/psycho.R/
> zipball/master
> Installing psycho
> "C:/Users/bp/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ
> --no-save --no-restore --quiet CMD INSTALL  \
>   "C:/Users/bp/AppData/Local/Temp/RtmpCkkmhB/devtools25601693478c/
> neuropsychology-psycho.R-b62e316" --library="C:/Users/bp/Documents/R/R-3.4.4/library"
> --install-tests
>
> * installing *source* package 'psycho' ...
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** tests
> ** preparing package for lazy loading
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called 'Matrix'
> ERROR: lazy loading failed for package 'psycho'
> * removing 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
> * restoring previous 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
> In R CMD INSTALL
> Installation failed: Command failed (1)
> > install.packages("psycho")
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.
> 2.3.zip'
> Content type 'application/zip' length 1650628 bytes (1.6 MB)
> downloaded 1.6 MB
>
> Just a guess, but does this have to do with presetting my work directory?
>
> setwd("C:/WHP/R/PracticeScripts and Testing Ideas")
>
> Here is my session info:
>
>
> > sessionInfo() #R version 3.4.4 (2018-03-15)
>
> R version 3.4.4 (2018-03-15)
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>
> .libPaths() #"C:/Users/bp/Documents/R/R-3.4.4/library"
>
> [1] "C:/Users/bp/Documents/R/R-3.4.4/library"
>
>
> Thank you for any advice.
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Wed Jun  6 13:53:59 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 6 Jun 2018 11:53:59 +0000
Subject: [R] Help with "ERROR: lazy loading failed for package 'psycho'"
In-Reply-To: <CAGgJW74p8m+KZg-AapE1uR_tCirV-GGnM-Ddv6j3Cy7xhLC6cQ@mail.gmail.com>
References: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CAGgJW74p8m+KZg-AapE1uR_tCirV-GGnM-Ddv6j3Cy7xhLC6cQ@mail.gmail.com>
Message-ID: <CY1PR0201MB18347547A9AE012D0CDFE5F8EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>

Yep, terrific, that?s got it, thank you Eric!

WHP


From: Eric Berger [mailto:ericjberger at gmail.com]
Sent: Wednesday, June 06, 2018 7:50 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with "ERROR: lazy loading failed for package 'psycho'"

> install.packages("Matrix")


On Wed, Jun 6, 2018 at 2:24 PM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
Good morning. In my continuing pursuit of self-taught R programming I am interested in following the tutorial provided by Bloggers.com<http://Bloggers.com> "Beautiful and Powerful Correlation Tables in R"


https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r-2/<https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r-2/> 3/

Although, I have hit a snag in the first step?

devtools::install_github("neuropsychology/psycho.R") # Install the newest version
library(psycho)
library(tidyverse)

I have installed both psycho & tidyverse pkgs, however, when I go to run the devtools::install_github("neuropsychology/psycho.R") piece I get this warning.

Downloading GitHub repo neuropsychology/psycho.R at master<mailto:neuropsychology/psycho.R at master>
from URL https://api.github.com/repos/neuropsychology/psycho.R/zipball/master<https://api.github.com/repos/neuropsychology/psycho.R/zipball/master>
Installing psycho
"C:/Users/bp/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
  "C:/Users/bp/AppData/Local/Temp/RtmpCkkmhB/devtools25601693478c/neuropsychology-psycho.R-b62e316" --library="C:/Users/bp/Documents/R/R-3.4.4/library" --install-tests

* installing *source* package 'psycho' ...
** R
** data
*** moving datasets to lazyload DB
** inst
** tests
** preparing package for lazy loading
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
  there is no package called 'Matrix'
ERROR: lazy loading failed for package 'psycho'
* removing 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
* restoring previous 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
In R CMD INSTALL
Installation failed: Command failed (1)
> install.packages("psycho")
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.2.3.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.2.3.zip>'
Content type 'application/zip' length 1650628 bytes (1.6 MB)
downloaded 1.6 MB

Just a guess, but does this have to do with presetting my work directory?

setwd("C:/WHP/R/PracticeScripts and Testing Ideas")

Here is my session info:


> sessionInfo() #R version 3.4.4 (2018-03-15)

R version 3.4.4 (2018-03-15)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1


.libPaths() #"C:/Users/bp/Documents/R/R-3.4.4/library"

[1] "C:/Users/bp/Documents/R/R-3.4.4/library"


Thank you for any advice.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From @igbert @ending from wiwi@hu-berlin@de  Wed Jun  6 14:16:30 2018
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Wed, 6 Jun 2018 14:16:30 +0200
Subject: [R] Ubuntu 18.04 / R 3.4.4 / shinyjs / V8
In-Reply-To: <ee46a9d6-d44f-404c-0c02-d44795a93c10@wiwi.hu-berlin.de>
References: <ee46a9d6-d44f-404c-0c02-d44795a93c10@wiwi.hu-berlin.de>
Message-ID: <2455e4e5-570a-78da-c4ff-a8113589651d@wiwi.hu-berlin.de>

Hi,

found myself a workaround:

Replaced the javascript functionality by calls of 
session$sendCustomMesssage(...) & Sys.sleep(...) and deleted 
library(shinyjs) from my code.

Best Sigbert

Am 06.06.2018 um 10:33 schrieb Sigbert Klinke:
> Hi,
> 
> if I want to use shinyjs package then I need the V8 package.
> Therefore I installed
> 
> apt-get install libv8-3.14-dev
> 
> and tried
> 
> install.packages("V8")
> 
> and get
> 
> ** preparing package for lazy loading
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  ? kann shared object 
> '/home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so' 
> nicht laden:
>  ? /usr/lib/x86_64-linux-gnu/libcurl.so.4: version `CURL_OPENSSL_3' not 
> found (required by 
> /home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so)
> ERROR: lazy loading failed for package ?V8?
> 
> I also tried to install curl3, but when I install R 3.4.4 then curl3 is 
> replaced by curl4 :(
> 
> Any ideas what I could do?
> 
> Thanks
> 
> Sigbert
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Sprechstunde: Fr 12-13, SPA1, R308
https://hu.berlin/sk
https://hu.berlin/mmstat3


From br@n@chri @ending from gm@il@com  Wed Jun  6 16:00:49 2018
From: br@n@chri @ending from gm@il@com (Christian =?ISO-8859-1?Q?Brandst=E4tter?=)
Date: Wed, 06 Jun 2018 16:00:49 +0200
Subject: [R] Plot in real unit (1:1)
Message-ID: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>

Dear List, 

Is it possible to plot in R in "real" units? I would like to draw a
plot on A4 paper, where 1 plot unit would be a mm in reality. Is
something like that possible? I would also like to be able to scale the
plot in x and y direction. 
Background: For a project I would have to draw around 65 fast sketches
of elevation courves. 

Copied from here, due to no answer: https://stackoverflow.com/questions
/50606797/plot-in-real-units-mm

Thank you!


From lmh_u@er@-group@ @ending from molconn@com  Wed Jun  6 18:27:16 2018
From: lmh_u@er@-group@ @ending from molconn@com (LMH)
Date: Wed, 6 Jun 2018 12:27:16 -0400
Subject: [R] internet routines cannot be loaded, R 3.5.0
Message-ID: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>

Hello,

I recently upgraded my version of R and find I need to reinstall packages
(unless there is some method to import my old profile and files). I have set
my repository to CRAN and set my CRAN mirror to US, NY. If I select
"packages > install packages" in the R console, I get a message, "no
packages were specified". I thought this command gave me a list of packages
available to install.

If I select, "packages > update packages", I get the message,

Warning: unable to access index for repository
https://mirrors.sorengard.com/cran/src/contrib:
  internet routines cannot be loaded
Error in gzfile(file, mode) : cannot open the connection
In addition: Warning message:
In gzfile(file, mode) :
  cannot open compressed file
'C:\DOCUME~1\BASIC_~1\LOCALS~1\Temp\RtmpqiUPQX/libloc_185_34943e0b.rds',
probable reason 'No such file or directory'

I have done a search on, "internet routines cannot be loaded" and don't find
anything that looks relevant.

i have installed some packages manually from local zip files, but many
packages have a large number of dependencies and it would take forever to
download them all.

Can someone help me to get this working?

Thanks,

LMH


From p@lmerr @ending from uth@c@@@edu  Wed Jun  6 19:37:50 2018
From: p@lmerr @ending from uth@c@@@edu (Palmer, Raymond F)
Date: Wed, 6 Jun 2018 17:37:50 +0000
Subject: [R] ROC within SEM
Message-ID: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>

Dear R group.
Does anyone have an idea how to utilize a latent variable in an ROC (AUC) analysis? I want to create a latent variable, then use that latent construct as a continuous variable in an ROC.
I understand both SEM and ROC analysis can be done in R, but how to use the latent variable in the ROC is the issue.
Thanks for any insights.
Best, Ray

Ray Palmer, Ph.D.
Professor
Department of Family and Community Medicine
University of Texas Health Science Center San Antonio
palmerr at uthscsa.edu<mailto:palmerr at uthscsa.edu>
210-827-7681


	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Wed Jun  6 22:48:03 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 6 Jun 2018 13:48:03 -0700
Subject: [R] ROC within SEM
In-Reply-To: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>
References: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>
Message-ID: <B29381BB-526A-46CF-9589-DC2DC4B204B0@comcast.net>


> On Jun 6, 2018, at 10:37 AM, Palmer, Raymond F <palmerr at uthscsa.edu> wrote:
> 
> Dear R group.
> Does anyone have an idea how to utilize a latent variable in an ROC (AUC) analysis? I want to create a latent variable, then use that latent construct as a continuous variable in an ROC.
> I understand both SEM and ROC analysis can be done in R, but how to use the latent variable in the ROC is the issue.
> Thanks for any insights.
> Best, Ray
> 
> Ray Palmer, Ph.D.
> Professor
> Department of Family and Community Medicine
> University of Texas Health Science Center San Antonio
> palmerr at uthscsa.edu<mailto:palmerr at uthscsa.edu>
> 210-827-7681
> 
> 
> 	[[alternative HTML version deleted]]

There are two sections from the Posting Guide that may be relevant:

---begin--
Questions about statistics: The R mailing lists are primarily intended for questions and discussion about the R software. However, questions about statistical methodology are sometimes posted. If the question is well-asked and of interest to someone on the list, it may elicit an informative up-to-date answer. See also the Usenet groups sci.stat.consult (applied statistics and consulting) and sci.stat.math (mathematical stat and probability).
---end-----

Frankly I would not considered this question to be "well-asked" but anyone is free to dispute this or to take on the task of asking clarifying questions. 

A modern update might add to the Posting Guide in these more web-centric times, the CrossValidated.com site. https://stats.stackexchange.com/search?q=latent+variable+roc

(Those newsgroups are basically defunct.)

> 
---begin--
	? No HTML posting (harder to detect spam) (note that this is the default in some mail clients - you may have to turn it off). Note that chances have become relatively high for ?HTMLified? e-mails to be completely intercepted (without notice to the sender).
---end-

One of the effects of redistribution by a mail-server is the removal of the identity of your mail-client, so advice about that concern can only be "RTFM".


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From @@r@h@go@lee @ending from gm@il@com  Wed Jun  6 22:56:37 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Wed, 6 Jun 2018 16:56:37 -0400
Subject: [R] internet routines cannot be loaded, R 3.5.0
In-Reply-To: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
References: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
Message-ID: <CAM_vjumrLCrrcGR8j9yPvXMDqskH9cTwGuR2HgROb42L1b6wUA@mail.gmail.com>

Hi,

install.packages() will install packages you specify,

update.packages(ask = FALSE, checkBuilt = TRUE)

is a useful way to update all installed packages after a major R update.

Your specific error message is probably because the sorengard mirror is down:

https://cran.r-project.org/mirmon_report.html#us

Pick a different mirror, and it should work.

Sarah

On Wed, Jun 6, 2018 at 12:27 PM, LMH <lmh_users-groups at molconn.com> wrote:
> Hello,
>
> I recently upgraded my version of R and find I need to reinstall packages
> (unless there is some method to import my old profile and files). I have set
> my repository to CRAN and set my CRAN mirror to US, NY. If I select
> "packages > install packages" in the R console, I get a message, "no
> packages were specified". I thought this command gave me a list of packages
> available to install.
>
> If I select, "packages > update packages", I get the message,
>
> Warning: unable to access index for repository
> https://mirrors.sorengard.com/cran/src/contrib:
>   internet routines cannot be loaded
> Error in gzfile(file, mode) : cannot open the connection
> In addition: Warning message:
> In gzfile(file, mode) :
>   cannot open compressed file
> 'C:\DOCUME~1\BASIC_~1\LOCALS~1\Temp\RtmpqiUPQX/libloc_185_34943e0b.rds',
> probable reason 'No such file or directory'
>
> I have done a search on, "internet routines cannot be loaded" and don't find
> anything that looks relevant.
>
> i have installed some packages manually from local zip files, but many
> packages have a large number of dependencies and it would take forever to
> download them all.
>
> Can someone help me to get this working?
>
> Thanks,
>
> LMH
>


From chri@@@ @ending from med@umich@edu  Wed Jun  6 23:55:29 2018
From: chri@@@ @ending from med@umich@edu (Andrews, Chris)
Date: Wed, 6 Jun 2018 21:55:29 +0000
Subject: [R] verInd= and HorInd= arguments to pairs() function
Message-ID: <eea156749e3044249cf0b56a264249ef@med.umich.edu>


After making scatterplot matrix, I determined I only needed the first 2 columns of the matrix so I added verInd=1:2 to my pairs() call.  However, it did not turn out as I expected. 

Perhaps the attached pdf of the example code will make it through.  If not, my description is "the wrong scatterplot pairs are in the wrong places" for the last two pairs() calls.

Thanks,
Chris

################################################################

# fake data
xmat <- matrix(1:28, ncol=4)
lim <- range(xmat)

# what I expected
pairs(xmat, xlim=lim, ylim=lim) # 4x4 matrix of scatterplots
pairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:2) # 2x2 matrix of scatterplots: upper left

# here comes trouble
pairs(xmat, xlim=lim, ylim=lim, horInd=1:2) # 2x4 matrix of scatterplots: but not the top 2 rows (or bottom 2 rows)
pairs(xmat, xlim=lim, ylim=lim, verInd=1:2) # 4x2 matrix of scatterplots: but not the left 2 columns (or right 2 columns)


###############################################################

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.5.0 tools_3.5.0   
**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pairs.pdf
Type: application/pdf
Size: 9892 bytes
Desc: pairs.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180606/f4d28bf4/attachment.pdf>

From drjimlemon @ending from gm@il@com  Thu Jun  7 00:16:36 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 7 Jun 2018 08:16:36 +1000
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
Message-ID: <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>

Hi Christian,
When I have to do something like this, I usually write it in
Postscript using this:

/def mm 2.8346 mul

that converts a dimension in mm to points (1/72 inch). However, this
won't work in R. It may be possible to set up the device like this:

postscript("myfile.ps",paper="a4")
par(mar=c(0,0,0,0))
# generate a blank plot
plot(0,type="n",xlim=c(0,210),ylim=c(0,297),axes=FALSE)
# display lines, etc. in mm with 0,0 at the bottom left
dev.off()

The resulting file should be printable. Warning, I don't have time to
test this right now.

Jim



On Thu, Jun 7, 2018 at 12:00 AM, Christian Brandst?tter
<bran.chri at gmail.com> wrote:
> Dear List,
>
> Is it possible to plot in R in "real" units? I would like to draw a
> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
> something like that possible? I would also like to be able to scale the
> plot in x and y direction.
> Background: For a project I would have to draw around 65 fast sketches
> of elevation courves.
>
> Copied from here, due to no answer: https://stackoverflow.com/questions
> /50606797/plot-in-real-units-mm
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@cqueen1 @ending from llnl@gov  Thu Jun  7 01:26:58 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 6 Jun 2018 23:26:58 +0000
Subject: [R] Time and date conversion
In-Reply-To: <DA6671CE-8F73-48A0-807B-63A223B9BA4A@gmail.com>
References: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>
 <DA6671CE-8F73-48A0-807B-63A223B9BA4A@gmail.com>
Message-ID: <AA962A6D-3235-4EA9-A262-C52646476C9B@llnl.gov>

After you've solved the format inconsistency issues, per Peter's advice, you will need to understand that R internally converts and stores the timedate values in UTC. Therefore, it is absolutely essential to give it the correct timezone specification on input.

The user does not "convert to UTC time-zone". Instead, you tell it to format in UTC when you print. If you don't specify a timezone on input, the default timezone will be your local timezone.

Here's an example of how to do it right, assuming "CT" is meant to be the US central timezone.

> t1 <- '2018-02-03 11:15:17 CT'
> t1t <- as.POSIXct(t1, tz='US/Central')
> print(t1t)
[1] "2018-02-03 11:15:17 CST"
> format(t1t, tz='UTC')
[1] "2018-02-03 17:15:17"

UTC is 6 hours ahead of US central time zone in February, so the displayed UTC hour is "17" instead of the US central "11".
The "CT" is ignored on input.

Note that there is no R command to convert from US/Central to UTC. There is only formatting. The actual data itself does not change.

t1u <- '2018-02-03 17:15:17'
t1ut <- as.POSIXct(t1u, tz='UTC')

> as.numeric(t1t)
[1] 1517678117
> as.numeric(t1ut)
[1] 1517678117

If the input time were during so-called daylight savings time (say, in June), the difference would be 5 hours; the UTC formatted hour would be "16".

------- further comments -------
There is some danger in using as.POSIXct, because it does not force you to supply a timezone (whereas strptime does).If no tz is supplied, as.POSIXct will default to the sessions timezone (PST in my case):

> t1p <- as.POSIXct(t1)
> print(t1p)
[1] "2018-02-03 11:15:17 PST"

My system does not recognized "CT" or "CST" as valid timezone codes:

> t1t <- as.POSIXct(t1, tz='CT')
Warning messages:
1: In strptime(xx, f <- "%Y-%m-%d %H:%M:%OS", tz = tz) :
  unknown timezone 'CT'
2: In as.POSIXct.POSIXlt(x) : unknown timezone 'CT'
3: In strptime(x, f, tz = tz) : unknown timezone 'CT'
4: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone 'CT'

> t1t <- as.POSIXct(t1, tz='CST')
Warning messages:
1: In strptime(xx, f <- "%Y-%m-%d %H:%M:%OS", tz = tz) :
  unknown timezone 'CST'
2: In as.POSIXct.POSIXlt(x) : unknown timezone 'CST'
3: In strptime(x, f, tz = tz) : unknown timezone 'CST'
4: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone 'CST'

R uses the underlying operating system date/time libraries to recognize when an input datetime is during daylight savings time, and converts to UTC accordingly. Therefore, if your incoming character strings are standard time all year around (a standard practice for some kinds of realtime data collection processes, such as for meteorological data), the above timezone codes won't work. You would have to use
    t1ut <- as.POSIXct(t1u, tz='Etc/GMT+6')
for the US central timezone (on a Mac or Linux box; I don't know about Windows).

As far as I understand it, the only way to specify the timezone when coverting from character to datetime is using the 'tz' argument. A timezone as part of the character string will be ignored (see the formatting codes in ?strptime).

I almost always use as.POSIXct() instead of strptime() for conversion from character to datetime, because strptime() returns class POSIXlt, and I generally find POSIXct more appropriate for how I work with datetime data.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/4/18, 3:54 AM, "R-help on behalf of peter dalgaard" <r-help-bounces at r-project.org on behalf of pdalgd at gmail.com> wrote:

    
    
    > On 4 Jun 2018, at 10:45 , Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
    > 
    > Hi,
    > 
    > I have an automatic data feed and I obtained a Date vector in the following
    > format:
    > 
    >> Date
    > [1] "03 Jun 2018 10:01 am CT"    "01 Jun 2018 22:04:25 pm CT"
    > 
    > I now like to convert it to UTC time-zone
    > 
    > Is there any easy way to convert them so, particularly since 1st element
    > doesnt have any Second element whereas the 2nd element has.
    
    ..and it also mixes up am/pm notation and 24hr clock.
    
    There are two basic approaches to the format inconsistency thing:
    
    (A) preprocess using gsub() constructions 
    
    > gsub(" (..:..) ", " \\1:00 ", d.txt)
    [1] "03 Jun 2018 10:01:00 am CT" "01 Jun 2018 22:04:25 pm CT"
    
    (B) Try multiple formats
    
    > d <- strptime(d.txt, format="%d %B %Y %H:%M:%S %p")
    > d[is.na(d)] <- strptime(d.txt[is.na(d)], format="%d %B %Y %H:%M %p")
    > d
    [1] "2018-06-03 10:01:00 CEST" "2018-06-01 22:04:25 CEST"
    
    I would likely go for (A) since you probably need to do something gsub-ish to get the TZ thing in place.
    
    -pd
    
    > 
    > Thanks for any pointer.
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Peter Dalgaard, Professor,
    Center for Statistics, Copenhagen Business School
    Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    Phone: (+45)38153501
    Office: A 4.23
    Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From chettyvk @ending from gm@il@com  Thu Jun  7 05:04:44 2018
From: chettyvk @ending from gm@il@com (Veerappa Chetty)
Date: Wed, 6 Jun 2018 23:04:44 -0400
Subject: [R] using myfunction in stat_function
Message-ID: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>

HI,

I use solve(A,b) inside my function, myfun2; it works fine when I return
one value or a list.

 I want use the return values in ggplot as below: ggplot(data.frame(
x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
I get a blank graph. Would greatly appreciate help! Thanks.

-- 
Professor of Family Medicine
Boston University
Tel: 617-414-6221, Fax:617-414-3345
emails: chettyvk at gmail.com

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Thu Jun  7 05:12:53 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 6 Jun 2018 20:12:53 -0700
Subject: [R] using myfunction in stat_function
In-Reply-To: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
References: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
Message-ID: <5A35A0FB-A019-4449-9DB6-1D8A22E05533@comcast.net>


> On Jun 6, 2018, at 8:04 PM, Veerappa Chetty <chettyvk at gmail.com> wrote:
> 
> HI,
> 
> I use solve(A,b) inside my function, myfun2; it works fine when I return
> one value or a list.
> 
> I want use the return values in ggplot as below:


> ggplot(data.frame(
> x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")

Error in layer(data = data, mapping = mapping, stat = StatFunction, geom = geom,  : 
  object 'myfun.2' not found

> I get a blank graph. Would greatly appreciate help! Thanks.
> 
> -- 
> Professor of Family Medicine
> Boston University
> Tel: 617-414-6221, Fax:617-414-3345
> emails: chettyvk at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From drjimlemon @ending from gm@il@com  Thu Jun  7 06:13:20 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 7 Jun 2018 14:13:20 +1000
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
 <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>
Message-ID: <CA+8X3fUGK9FiKdGVudST=Ly-hLiudVWg1MYO_tRjewBLAA6JzA@mail.gmail.com>

Hi Christian,
Well, it almost worked. I suspect that the postscript device adds some
padding to account for the printable area, so with a bit of
experimentation, The following example seems to do what you want. When
I printed the resulting file from the GIMP, the box and diamond were
the correct dimensions.

postscript("test.ps",paper="a4",horizontal=FALSE)
par(mai=c(1.713,0,1.713,0),xaxs="i",yaxs="i")
plot(0,type="n",xlim=c(0,190),ylim=c(0,190),xlab="",axes=FALSE)
segments(c(0,95),c(95,0),c(190,95),c(95,190))
segments(c(45,95,145,95),c(95,145,95,45),
 c(95,145,95,45),c(145,95,45,95))
box()
dev.off()

Jim

On Thu, Jun 7, 2018 at 8:16 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Christian,
> When I have to do something like this, I usually write it in
> Postscript using this:
>
> /def mm 2.8346 mul
>
> that converts a dimension in mm to points (1/72 inch). However, this
> won't work in R. It may be possible to set up the device like this:
>
> postscript("myfile.ps",paper="a4")
> par(mar=c(0,0,0,0))
> # generate a blank plot
> plot(0,type="n",xlim=c(0,210),ylim=c(0,297),axes=FALSE)
> # display lines, etc. in mm with 0,0 at the bottom left
> dev.off()
>
> The resulting file should be printable. Warning, I don't have time to
> test this right now.
>
> Jim
>
>
>
> On Thu, Jun 7, 2018 at 12:00 AM, Christian Brandst?tter
> <bran.chri at gmail.com> wrote:
>> Dear List,
>>
>> Is it possible to plot in R in "real" units? I would like to draw a
>> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
>> something like that possible? I would also like to be able to scale the
>> plot in x and y direction.
>> Background: For a project I would have to draw around 65 fast sketches
>> of elevation courves.
>>
>> Copied from here, due to no answer: https://stackoverflow.com/questions
>> /50606797/plot-in-real-units-mm
>>
>> Thank you!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


From br@n@chri @ending from gm@il@com  Thu Jun  7 06:20:37 2018
From: br@n@chri @ending from gm@il@com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Thu, 7 Jun 2018 06:20:37 +0200
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <CA+8X3fUGK9FiKdGVudST=Ly-hLiudVWg1MYO_tRjewBLAA6JzA@mail.gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
 <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>
 <CA+8X3fUGK9FiKdGVudST=Ly-hLiudVWg1MYO_tRjewBLAA6JzA@mail.gmail.com>
Message-ID: <CAALi0vJPXGhi0M9+3tCDpBRbt093VMgkjpHRz7ocCFhXMsXxaw@mail.gmail.com>

Thanks a lot!

Jim Lemon <drjimlemon at gmail.com> schrieb am Do., 7. Juni 2018, 06:13:

> Hi Christian,
> Well, it almost worked. I suspect that the postscript device adds some
> padding to account for the printable area, so with a bit of
> experimentation, The following example seems to do what you want. When
> I printed the resulting file from the GIMP, the box and diamond were
> the correct dimensions.
>
> postscript("test.ps",paper="a4",horizontal=FALSE)
> par(mai=c(1.713,0,1.713,0),xaxs="i",yaxs="i")
> plot(0,type="n",xlim=c(0,190),ylim=c(0,190),xlab="",axes=FALSE)
> segments(c(0,95),c(95,0),c(190,95),c(95,190))
> segments(c(45,95,145,95),c(95,145,95,45),
>  c(95,145,95,45),c(145,95,45,95))
> box()
> dev.off()
>
> Jim
>
> On Thu, Jun 7, 2018 at 8:16 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > Hi Christian,
> > When I have to do something like this, I usually write it in
> > Postscript using this:
> >
> > /def mm 2.8346 mul
> >
> > that converts a dimension in mm to points (1/72 inch). However, this
> > won't work in R. It may be possible to set up the device like this:
> >
> > postscript("myfile.ps",paper="a4")
> > par(mar=c(0,0,0,0))
> > # generate a blank plot
> > plot(0,type="n",xlim=c(0,210),ylim=c(0,297),axes=FALSE)
> > # display lines, etc. in mm with 0,0 at the bottom left
> > dev.off()
> >
> > The resulting file should be printable. Warning, I don't have time to
> > test this right now.
> >
> > Jim
> >
> >
> >
> > On Thu, Jun 7, 2018 at 12:00 AM, Christian Brandst?tter
> > <bran.chri at gmail.com> wrote:
> >> Dear List,
> >>
> >> Is it possible to plot in R in "real" units? I would like to draw a
> >> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
> >> something like that possible? I would also like to be able to scale the
> >> plot in x and y direction.
> >> Background: For a project I would have to draw around 65 fast sketches
> >> of elevation courves.
> >>
> >> Copied from here, due to no answer: https://stackoverflow.com/questions
> >> /50606797/plot-in-real-units-mm
> >>
> >> Thank you!
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From gerrit@eichner @ending from m@th@uni-gie@@en@de  Thu Jun  7 09:03:46 2018
From: gerrit@eichner @ending from m@th@uni-gie@@en@de (Gerrit Eichner)
Date: Thu, 7 Jun 2018 09:03:46 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
Message-ID: <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>

Hi, Chris,

had the same problem (and first thought it was my fault), but there
seems to be a typo in the code of pairs.default. Below is a workaround.
Look for two comments (starting with #####) in the code to see what I
have changed to make it work at least the way I'd expect it in one of
your examples.

  Hth --  Gerrit


mypairs <- function (x, labels, panel = points, ...,
     horInd = 1:nc, verInd = 1:nc,
     lower.panel = panel, upper.panel = panel, diag.panel = NULL,
     text.panel = textPanel, label.pos = 0.5 + has.diag/3, line.main = 3,
     cex.labels = NULL, font.labels = 1, row1attop = TRUE, gap = 1,
     log = "") {
     if (doText <- missing(text.panel) || is.function(text.panel))
         textPanel <- function(x = 0.5, y = 0.5, txt, cex, font) text(x,
             y, txt, cex = cex, font = font)
     localAxis <- function(side, x, y, xpd, bg, col = NULL, main,
         oma, ...) {
         xpd <- NA
         if (side%%2L == 1L && xl[j])
             xpd <- FALSE
         if (side%%2L == 0L && yl[i])
             xpd <- FALSE
         if (side%%2L == 1L)
             Axis(x, side = side, xpd = xpd, ...)
         else Axis(y, side = side, xpd = xpd, ...)
     }
     localPlot <- function(..., main, oma, font.main, cex.main) plot(...)
     localLowerPanel <- function(..., main, oma, font.main, cex.main) 
lower.panel(...)
     localUpperPanel <- function(..., main, oma, font.main, cex.main) 
upper.panel(...)
     localDiagPanel <- function(..., main, oma, font.main, cex.main) 
diag.panel(...)
     dots <- list(...)
     nmdots <- names(dots)
     if (!is.matrix(x)) {
         x <- as.data.frame(x)
         for (i in seq_along(names(x))) {
             if (is.factor(x[[i]]) || is.logical(x[[i]]))
                 x[[i]] <- as.numeric(x[[i]])
             if (!is.numeric(unclass(x[[i]])))
                 stop("non-numeric argument to 'pairs'")
         }
     }
     else if (!is.numeric(x))
         stop("non-numeric argument to 'pairs'")
     panel <- match.fun(panel)
     if ((has.lower <- !is.null(lower.panel)) && !missing(lower.panel))
         lower.panel <- match.fun(lower.panel)
     if ((has.upper <- !is.null(upper.panel)) && !missing(upper.panel))
         upper.panel <- match.fun(upper.panel)
     if ((has.diag <- !is.null(diag.panel)) && !missing(diag.panel))
         diag.panel <- match.fun(diag.panel)
     if (row1attop) {
         tmp <- lower.panel
         lower.panel <- upper.panel
         upper.panel <- tmp
         tmp <- has.lower
         has.lower <- has.upper
         has.upper <- tmp
     }
     nc <- ncol(x)
     if (nc < 2L)
         stop("only one column in the argument to 'pairs'")
     if (!all(horInd >= 1L && horInd <= nc))
         stop("invalid argument 'horInd'")
     if (!all(verInd >= 1L && verInd <= nc))
         stop("invalid argument 'verInd'")
     if (doText) {
         if (missing(labels)) {
             labels <- colnames(x)
             if (is.null(labels))
                 labels <- paste("var", 1L:nc)
         }
         else if (is.null(labels))
             doText <- FALSE
     }
     oma <- if ("oma" %in% nmdots)
         dots$oma
     main <- if ("main" %in% nmdots)
         dots$main
     if (is.null(oma))
         oma <- c(4, 4, if (!is.null(main)) 6 else 4, 4)
     opar <- par(mfcol = c(length(horInd), length(verInd)),
##### Changed from mfrow to mfcol
                 mar = rep.int(gap/2, 4), oma = oma)
     on.exit(par(opar))
     dev.hold()
     on.exit(dev.flush(), add = TRUE)
     xl <- yl <- logical(nc)
     if (is.numeric(log))
         xl[log] <- yl[log] <- TRUE
     else {
         xl[] <- grepl("x", log)
         yl[] <- grepl("y", log)
     }
     for (j in if (row1attop) verInd else rev(verInd))
      for (i in horInd) {
##### Exchanged i and j. (i used to be in
##### the outer and j in the inner loop!)
         l <- paste0(ifelse(xl[j], "x", ""), ifelse(yl[i], "y", ""))
         localPlot(x[, j], x[, i], xlab = "", ylab = "", axes = FALSE,
             type = "n", ..., log = l)
         if (i == j || (i < j && has.lower) || (i > j && has.upper)) {
             box()
             if (i == 1 && (!(j%%2L) || !has.upper || !has.lower))
                 localAxis(1L + 2L * row1attop, x[, j], x[, i],
                   ...)
             if (i == nc && (j%%2L || !has.upper || !has.lower))
                 localAxis(3L - 2L * row1attop, x[, j], x[, i],
                   ...)
             if (j == 1 && (!(i%%2L) || !has.upper || !has.lower))
                 localAxis(2L, x[, j], x[, i], ...)
             if (j == nc && (i%%2L || !has.upper || !has.lower))
                 localAxis(4L, x[, j], x[, i], ...)
             mfg <- par("mfg")
             if (i == j) {
                 if (has.diag)
                   localDiagPanel(as.vector(x[, i]), ...)
                 if (doText) {
                   par(usr = c(0, 1, 0, 1))
                   if (is.null(cex.labels)) {
                     l.wid <- strwidth(labels, "user")
                     cex.labels <- max(0.8, min(2, 0.9/max(l.wid)))
                   }
                   xlp <- if (xl[i])
                     10^0.5
                   else 0.5
                   ylp <- if (yl[j])
                     10^label.pos
                   else label.pos
                   text.panel(xlp, ylp, labels[i], cex = cex.labels,
                     font = font.labels)
                 }
             }
             else if (i < j)
                 localLowerPanel(as.vector(x[, j]), as.vector(x[,
                   i]), ...)
             else localUpperPanel(as.vector(x[, j]), as.vector(x[,
                 i]), ...)
             if (any(par("mfg") != mfg))
                 stop("the 'panel' function made a new plot")
         }
         else par(new = FALSE)
     }
     if (!is.null(main)) {
         font.main <- if ("font.main" %in% nmdots)
             dots$font.main
         else par("font.main")
         cex.main <- if ("cex.main" %in% nmdots)
             dots$cex.main
         else par("cex.main")
         mtext(main, 3, line.main, outer = TRUE, at = 0.5, cex = cex.main,
             font = font.main)
     }
     invisible(NULL)
}



## Example:

mypairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:4)



Am 06.06.2018 um 23:55 schrieb Andrews, Chris:
> 
> After making scatterplot matrix, I determined I only needed the first 2 columns of the matrix so I added verInd=1:2 to my pairs() call.  However, it did not turn out as I expected.
> 
> Perhaps the attached pdf of the example code will make it through.  If not, my description is "the wrong scatterplot pairs are in the wrong places" for the last two pairs() calls.
> 
> Thanks,
> Chris
> 
> ################################################################
> 
> # fake data
> xmat <- matrix(1:28, ncol=4)
> lim <- range(xmat)
> 
> # what I expected
> pairs(xmat, xlim=lim, ylim=lim) # 4x4 matrix of scatterplots
> pairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:2) # 2x2 matrix of scatterplots: upper left
> 
> # here comes trouble
> pairs(xmat, xlim=lim, ylim=lim, horInd=1:2) # 2x4 matrix of scatterplots: but not the top 2 rows (or bottom 2 rows)
> pairs(xmat, xlim=lim, ylim=lim, verInd=1:2) # 4x2 matrix of scatterplots: but not the left 2 columns (or right 2 columns)
> 
> 
> ###############################################################
> 
>> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.5.0 tools_3.5.0
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jun  7 09:29:27 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 07 Jun 2018 00:29:27 -0700
Subject: [R] using myfunction in stat_function
In-Reply-To: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
References: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
Message-ID: <96A42C1D-F2C3-44BC-9BD6-261685181CA5@dcn.davis.ca.us>

Your example is not reproducible.

Perhaps read [1]

[1] http://rstudio-pubs-static.s3.amazonaws.com/3365_9573f6d661b444499365fe1841ee65d3.html

On June 6, 2018 8:04:44 PM PDT, Veerappa Chetty <chettyvk at gmail.com> wrote:
>HI,
>
>I use solve(A,b) inside my function, myfun2; it works fine when I
>return
>one value or a list.
>
> I want use the return values in ggplot as below: ggplot(data.frame(
>x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
>I get a blank graph. Would greatly appreciate help! Thanks.

-- 
Sent from my phone. Please excuse my brevity.


From m@@@imo@bre@@@n @ending from @rp@@veneto@it  Thu Jun  7 10:09:55 2018
From: m@@@imo@bre@@@n @ending from @rp@@veneto@it (Massimo Bressan)
Date: Thu, 7 Jun 2018 10:09:55 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>

thanks for the help 

I'm posting here the complete solution 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t$A <- factor(t$A) 
l<-sapply(levels(t$A), function(x) which(t$A==x)) 
r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", "))) 
r<-cbind(unique_A=row.names(r),r) 
row.names(r)<-NULL 
r 

best 



Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
A: "r-help" <R-help at r-project.org> 
Inviato: Mercoled?, 6 giugno 2018 10:13:10 
Oggetto: aggregate and list elements of variables in data.frame 

#given the following reproducible and simplified example 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

#I need to get the following result 

r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
r 

# i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
#any help for that? 

#so far I've just managed to "aggregate" and "count", like: 

library(sqldf) 
sqldf('select count(*) as count_id, A as unique_A from t group by A') 

library(dplyr) 
t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 

# thank you 


-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Thu Jun  7 10:41:23 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Thu, 7 Jun 2018 11:41:23 +0300
Subject: [R] ROC within SEM
In-Reply-To: <B29381BB-526A-46CF-9589-DC2DC4B204B0@comcast.net>
References: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>
 <B29381BB-526A-46CF-9589-DC2DC4B204B0@comcast.net>
Message-ID: <CAGgJW75AyExdR0v2+kJJXBrORvyyFE7NBPo6uS7QGdvoTwTudw@mail.gmail.com>

Hi Ray,
Have you done any search at all? I did a search on "R package ROC latent
variable" and got several hits.
In particular the package randomLCA seems relevant

https://cran.r-project.org/web/packages/randomLCA/vignettes/randomLCA-package.pdf

I glanced at the documentation which mentions 2 other R packages that also
seem to address your needs - poLCA and BayesLCA.

HTH,
Eric


On Wed, Jun 6, 2018 at 11:48 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jun 6, 2018, at 10:37 AM, Palmer, Raymond F <palmerr at uthscsa.edu>
> wrote:
> >
> > Dear R group.
> > Does anyone have an idea how to utilize a latent variable in an ROC
> (AUC) analysis? I want to create a latent variable, then use that latent
> construct as a continuous variable in an ROC.
> > I understand both SEM and ROC analysis can be done in R, but how to use
> the latent variable in the ROC is the issue.
> > Thanks for any insights.
> > Best, Ray
> >
> > Ray Palmer, Ph.D.
> > Professor
> > Department of Family and Community Medicine
> > University of Texas Health Science Center San Antonio
> > palmerr at uthscsa.edu<mailto:palmerr at uthscsa.edu>
> > 210-827-7681
> >
> >
> >       [[alternative HTML version deleted]]
>
> There are two sections from the Posting Guide that may be relevant:
>
> ---begin--
> Questions about statistics: The R mailing lists are primarily intended for
> questions and discussion about the R software. However, questions about
> statistical methodology are sometimes posted. If the question is well-asked
> and of interest to someone on the list, it may elicit an informative
> up-to-date answer. See also the Usenet groups sci.stat.consult (applied
> statistics and consulting) and sci.stat.math (mathematical stat and
> probability).
> ---end-----
>
> Frankly I would not considered this question to be "well-asked" but anyone
> is free to dispute this or to take on the task of asking clarifying
> questions.
>
> A modern update might add to the Posting Guide in these more web-centric
> times, the CrossValidated.com site. https://stats.stackexchange.
> com/search?q=latent+variable+roc
>
> (Those newsgroups are basically defunct.)
>
> >
> ---begin--
>         ? No HTML posting (harder to detect spam) (note that this is the
> default in some mail clients - you may have to turn it off). Note that
> chances have become relatively high for ?HTMLified? e-mails to be
> completely intercepted (without notice to the sender).
> ---end-
>
> One of the effects of redistribution by a mail-server is the removal of
> the identity of your mail-client, so advice about that concern can only be
> "RTFM".
>
>
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From E@Vettor@zzi @ending from uke@de  Thu Jun  7 11:46:43 2018
From: E@Vettor@zzi @ending from uke@de (Eik Vettorazzi)
Date: Thu, 7 Jun 2018 11:46:43 +0200
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
Message-ID: <c30500f2-2f5e-902c-05e7-57e9b4261247@uke.de>

How about this:

in2mm<-25.4 # scale factor to convert inches to mm

pdf("test.pdf",width=8.3,height=11.7)
pin<-par("pin")
plot(c(0,pin[1]*in2mm),c(0,pin[2]*in2mm), type="n", xaxs="i", yaxs="i")
lines(c(10,10),c(0,10))
text(11,5,"1 cm", adj=0)

lines(c(0,40),c(20,20))
text(20,24,"4 cm")

polygon(c(50,50,70,70),c(50,70,70,50))
text(60,60,"2x2 cm")
dev.off()

cheers

Am 06.06.2018 um 16:00 schrieb Christian Brandst?tter:
> Dear List, 
> 
> Is it possible to plot in R in "real" units? I would like to draw a
> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
> something like that possible? I would also like to be able to scale the
> plot in x and y direction. 
> Background: For a project I would have to draw around 65 fast sketches
> of elevation courves. 
> 
> Copied from here, due to no answer: https://stackoverflow.com/questions
> /50606797/plot-in-real-units-mm
> 
> Thank you!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistrasse 52
building W 34
20246 Hamburg

Phone: +49 (0) 40 7410 - 58243
Fax:   +49 (0) 40 7410 - 57790
Web: www.uke.de/imbe
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From m@rongiu@luigi @ending from gm@il@com  Thu Jun  7 12:00:57 2018
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 12:00:57 +0200
Subject: [R] Histogram of character elements
Message-ID: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>

Dear all,
I have a dataframe with a column representing the names of the
elements (a, b, etc) and one with their frequencies.
How can I plot the frequencies so that each element has an associated
frequency value?
I have been thinking of a histogram, but I have found it difficult to
implement. I have tried the following:

group <- c("a", "b", "c", "d", "e")
freq <-c(1, 2, 2, 5, 3)
df <- data.frame(group, freq, stringsAsFactors = FALSE)
hist(df$freq)
library(lattice)
histogram( ~ df$group)
histogram( ~ as.factor(df$group))
histogram(df$freq ~ as.factor(df$group))

hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
times, the values 3 and 5 appear once and 4 never. This is not what I
wanted; I want instead a graph telling me that a appears once, b twice
etc.

histogram( ~ df$group) gives the error:
Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
include.lowest = include.lowest,  :
  negative length vectors are not allowed

histogram( ~ as.factor(df$group)) and histogram(df$freq ~
as.factor(df$group)) report all groups on the x axis (that is good)
but all at 20% level.

What am I missing?
Thank you.

-- 
Best regards,
Luigi


From btupper @ending from bigelow@org  Thu Jun  7 12:47:59 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Thu, 7 Jun 2018 06:47:59 -0400
Subject: [R] Histogram of character elements
In-Reply-To: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
Message-ID: <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>

Hi,

Is this what you are after? 

group <- c("a", "b", "c", "d", "e")
freq <-c(1, 2, 2, 5, 3)
x = rep(group, freq)
barplot(table(x))

Cheers,
Ben



> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
> 
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
> 
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
> 
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
>  negative length vectors are not allowed
> 
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
> 
> What am I missing?
> Thank you.
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From m@rongiu@luigi @ending from gm@il@com  Thu Jun  7 13:00:12 2018
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 13:00:12 +0200
Subject: [R] Histogram of character elements
In-Reply-To: <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
Message-ID: <CAMk+s2RLAS_56YOSmJ5sgFL9GFSSZoDo0wXpvyDLJ9ad+g11SQ@mail.gmail.com>

exactly! Thank you!
but it is possible to do it with lattice? I might have an extra level
of information, for instance super-group, and in that case, I could
plot all the supergroup easily together.
On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> Hi,
>
> Is this what you are after?
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> x = rep(group, freq)
> barplot(table(x))
>
> Cheers,
> Ben
>
>
>
> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
>
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
>
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
>  negative length vectors are not allowed
>
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
>
> What am I missing?
> Thank you.
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>


-- 
Best regards,
Luigi


From m@rongiu@luigi @ending from gm@il@com  Thu Jun  7 13:02:46 2018
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 13:02:46 +0200
Subject: [R] Histogram of character elements
In-Reply-To: <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
Message-ID: <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>

also, with this approach, I need to re-arrange the data. Is it
possible to work directly on a dataframe?
On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> Hi,
>
> Is this what you are after?
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> x = rep(group, freq)
> barplot(table(x))
>
> Cheers,
> Ben
>
>
>
> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
>
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
>
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
>  negative length vectors are not allowed
>
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
>
> What am I missing?
> Thank you.
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>


-- 
Best regards,
Luigi


From btupper @ending from bigelow@org  Thu Jun  7 13:43:09 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Thu, 7 Jun 2018 07:43:09 -0400
Subject: [R] Histogram of character elements
In-Reply-To: <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
 <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>
Message-ID: <59084912-ADF6-447A-AD55-8026A5F1086C@bigelow.org>

Hi again,

I'm sort of pre-coffee still, but does this do it?  The data frame only has one variable, a factor where the order of the levels is specified.

library(lattice)
group   <- c("a", "b", "c", "d", "e")
freq    <- c(1, 2, 2, 5, 3)
x       <- rep(group, freq)
df      <- data.frame(group = factor(x, levels = c("d", "a", "b", "c", "e")) )
histogram(~ group, data = df)

As far as super-grouping the answer is likely yes, but without details and an example (and coffee) I'm at a loss.   I suggest getting a your hands on a copy of https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008 <https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008> It's really worth it if you plan to spend time with lattice.

Cheers,
Ben 


> On Jun 7, 2018, at 7:02 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> also, with this approach, I need to re-arrange the data. Is it
> possible to work directly on a dataframe?
> On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>> 
>> Hi,
>> 
>> Is this what you are after?
>> 
>> group <- c("a", "b", "c", "d", "e")
>> freq <-c(1, 2, 2, 5, 3)
>> x = rep(group, freq)
>> barplot(table(x))
>> 
>> Cheers,
>> Ben
>> 
>> 
>> 
>> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> 
>> Dear all,
>> I have a dataframe with a column representing the names of the
>> elements (a, b, etc) and one with their frequencies.
>> How can I plot the frequencies so that each element has an associated
>> frequency value?
>> I have been thinking of a histogram, but I have found it difficult to
>> implement. I have tried the following:
>> 
>> group <- c("a", "b", "c", "d", "e")
>> freq <-c(1, 2, 2, 5, 3)
>> df <- data.frame(group, freq, stringsAsFactors = FALSE)
>> hist(df$freq)
>> library(lattice)
>> histogram( ~ df$group)
>> histogram( ~ as.factor(df$group))
>> histogram(df$freq ~ as.factor(df$group))
>> 
>> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
>> times, the values 3 and 5 appear once and 4 never. This is not what I
>> wanted; I want instead a graph telling me that a appears once, b twice
>> etc.
>> 
>> histogram( ~ df$group) gives the error:
>> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
>> include.lowest = include.lowest,  :
>> negative length vectors are not allowed
>> 
>> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
>> as.factor(df$group)) report all groups on the x axis (that is good)
>> but all at 20% level.
>> 
>> What am I missing?
>> Thank you.
>> 
>> --
>> Best regards,
>> Luigi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> Ecological Forecasting: https://eco.bigelow.org/
>> 
>> 
>> 
>> 
>> 
> 
> 
> -- 
> Best regards,
> Luigi
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From m@rongiu@luigi @ending from gm@il@com  Thu Jun  7 13:49:11 2018
From: m@rongiu@luigi @ending from gm@il@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 13:49:11 +0200
Subject: [R] Histogram of character elements
In-Reply-To: <59084912-ADF6-447A-AD55-8026A5F1086C@bigelow.org>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
 <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>
 <59084912-ADF6-447A-AD55-8026A5F1086C@bigelow.org>
Message-ID: <CAMk+s2RvnWd6vZ0m=ckpKGi7zUSsCxUDf1jrDGXGs_2hdPsRVw@mail.gmail.com>

Thank you Ben, this also works! I have a copy of the Sarkar but,
usually, I don't work with histograms. I'll brush it up, then. Best
regards, Luigi

On Thu, Jun 7, 2018 at 1:43 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> Hi again,
>
> I'm sort of pre-coffee still, but does this do it?  The data frame only has one variable, a factor where the order of the levels is specified.
>
> library(lattice)
> group   <- c("a", "b", "c", "d", "e")
> freq    <- c(1, 2, 2, 5, 3)
> x       <- rep(group, freq)
> df      <- data.frame(group = factor(x, levels = c("d", "a", "b", "c", "e")) )
> histogram(~ group, data = df)
>
> As far as super-grouping the answer is likely yes, but without details and an example (and coffee) I'm at a loss.   I suggest getting a your hands on a copy of https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008 It's really worth it if you plan to spend time with lattice.
>
> Cheers,
> Ben
>
>
> On Jun 7, 2018, at 7:02 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> also, with this approach, I need to re-arrange the data. Is it
> possible to work directly on a dataframe?
> On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>
>
> Hi,
>
> Is this what you are after?
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> x = rep(group, freq)
> barplot(table(x))
>
> Cheers,
> Ben
>
>
>
> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
>
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
>
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
> negative length vectors are not allowed
>
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
>
> What am I missing?
> Thank you.
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>
>
>
> --
> Best regards,
> Luigi
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>


-- 
Best regards,
Luigi


From m@@@imo@bre@@@n @ending from @rp@@veneto@it  Thu Jun  7 14:21:52 2018
From: m@@@imo@bre@@@n @ending from @rp@@veneto@it (Massimo Bressan)
Date: Thu, 7 Jun 2018 14:21:52 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>

sorry, but by further looking at the example I just realised that the posted solution it's not completely what I need because in fact I do not need to get back the 'indices' but instead the corrisponding values of column A 

#please consider this new example 

t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

# I need to get this result 
r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('18,20,27,4','91,54,15','68','26,97')) 
r 

# any help for this, please? 





Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
A: "r-help" <R-help at r-project.org> 
Inviato: Gioved?, 7 giugno 2018 10:09:55 
Oggetto: Re: aggregate and list elements of variables in data.frame 

thanks for the help 

I'm posting here the complete solution 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t$A <- factor(t$A) 
l<-sapply(levels(t$A), function(x) which(t$A==x)) 
r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", "))) 
r<-cbind(unique_A=row.names(r),r) 
row.names(r)<-NULL 
r 

best 



Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
A: "r-help" <R-help at r-project.org> 
Inviato: Mercoled?, 6 giugno 2018 10:13:10 
Oggetto: aggregate and list elements of variables in data.frame 

#given the following reproducible and simplified example 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

#I need to get the following result 

r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
r 

# i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
#any help for that? 

#so far I've just managed to "aggregate" and "count", like: 

library(sqldf) 
sqldf('select count(*) as count_id, A as unique_A from t group by A') 

library(dplyr) 
t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 

# thank you 


-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 


-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 

	[[alternative HTML version deleted]]


From c@l@ndr@ @ending from rgzm@de  Thu Jun  7 14:28:07 2018
From: c@l@ndr@ @ending from rgzm@de (Ivan Calandra)
Date: Thu, 7 Jun 2018 14:28:07 +0200
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <c8d0c50b-bc3c-662f-58c3-2f0cdc2db50d@rgzm.de>

Using which() to subset t$id should do the trick:

sapply(levels(t$A), function(x) t$id[which(t$A==x)])

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 07/06/2018 14:21, Massimo Bressan wrote:
> sorry, but by further looking at the example I just realised that the posted solution it's not completely what I need because in fact I do not need to get back the 'indices' but instead the corrisponding values of column A
>
> #please consider this new example
>
> t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789))
> t
>
> # I need to get this result
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('18,20,27,4','91,54,15','68','26,97'))
> r
>
> # any help for this, please?
>
>
>
>
>
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> A: "r-help" <R-help at r-project.org>
> Inviato: Gioved?, 7 giugno 2018 10:09:55
> Oggetto: Re: aggregate and list elements of variables in data.frame
>
> thanks for the help
>
> I'm posting here the complete solution
>
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))
> t$A <- factor(t$A)
> l<-sapply(levels(t$A), function(x) which(t$A==x))
> r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", ")))
> r<-cbind(unique_A=row.names(r),r)
> row.names(r)<-NULL
> r
>
> best
>
>
>
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> A: "r-help" <R-help at r-project.org>
> Inviato: Mercoled?, 6 giugno 2018 10:13:10
> Oggetto: aggregate and list elements of variables in data.frame
>
> #given the following reproducible and simplified example
>
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))
> t
>
> #I need to get the following result
>
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10'))
> r
>
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A"
> #any help for that?
>
> #so far I've just managed to "aggregate" and "count", like:
>
> library(sqldf)
> sqldf('select count(*) as count_id, A as unique_A from t group by A')
>
> library(dplyr)
> t%>%group_by(unique_A=A) %>% summarise(count_id = n())
>
> # thank you
>
>


From btupper @ending from bigelow@org  Thu Jun  7 14:47:55 2018
From: btupper @ending from bigelow@org (Ben Tupper)
Date: Thu, 7 Jun 2018 08:47:55 -0400
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>

Hi,

Does this do what you want?  I had to change the id values to something more obvious.  It uses tibbles which allow each variable to be a list.

library(tibble)
library(dplyr)
x       <- tibble(id=LETTERS[1:10],
                A=c(123,345,123,678,345,123,789,345,123,789))
uA      <- unique(x$A)
idx     <- lapply(uA, function(v) which(x$A %in% v))
vals    <- lapply(idx, function(index) x$id[index])

r <- tibble(unique_A = uA, list_idx = idx, list_vals = vals)


> r
# A tibble: 4 x 3
  unique_A list_idx  list_vals
     <dbl> <list>    <list>   
1     123. <int [4]> <chr [4]>
2     345. <int [3]> <chr [3]>
3     678. <int [1]> <chr [1]>
4     789. <int [2]> <chr [2]>
> r$list_idx[1]
[[1]]
[1] 1 3 6 9

> r$list_vals[1]
[[1]]
[1] "A" "C" "F" "I"


Cheers,
ben



> On Jun 7, 2018, at 8:21 AM, Massimo Bressan <massimo.bressan at arpa.veneto.it> wrote:
> 
> sorry, but by further looking at the example I just realised that the posted solution it's not completely what I need because in fact I do not need to get back the 'indices' but instead the corrisponding values of column A 
> 
> #please consider this new example 
> 
> t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789)) 
> t 
> 
> # I need to get this result 
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('18,20,27,4','91,54,15','68','26,97')) 
> r 
> 
> # any help for this, please? 
> 
> 
> 
> 
> 
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
> A: "r-help" <R-help at r-project.org> 
> Inviato: Gioved?, 7 giugno 2018 10:09:55 
> Oggetto: Re: aggregate and list elements of variables in data.frame 
> 
> thanks for the help 
> 
> I'm posting here the complete solution 
> 
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
> t$A <- factor(t$A) 
> l<-sapply(levels(t$A), function(x) which(t$A==x)) 
> r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", "))) 
> r<-cbind(unique_A=row.names(r),r) 
> row.names(r)<-NULL 
> r 
> 
> best 
> 
> 
> 
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
> A: "r-help" <R-help at r-project.org> 
> Inviato: Mercoled?, 6 giugno 2018 10:13:10 
> Oggetto: aggregate and list elements of variables in data.frame 
> 
> #given the following reproducible and simplified example 
> 
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
> t 
> 
> #I need to get the following result 
> 
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
> r 
> 
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
> #any help for that? 
> 
> #so far I've just managed to "aggregate" and "count", like: 
> 
> library(sqldf) 
> sqldf('select count(*) as count_id, A as unique_A from t group by A') 
> 
> library(dplyr) 
> t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 
> 
> # thank you 
> 
> 
> -- 
> 
> ------------------------------------------------------------ 
> Massimo Bressan 
> 
> ARPAV 
> Agenzia Regionale per la Prevenzione e 
> Protezione Ambientale del Veneto 
> 
> Dipartimento Provinciale di Treviso 
> Via Santa Barbara, 5/a 
> 31100 Treviso, Italy 
> 
> tel: +39 0422 558545 
> fax: +39 0422 558516 
> e-mail: massimo.bressan at arpa.veneto.it 
> ------------------------------------------------------------ 
> 
> 
> -- 
> 
> ------------------------------------------------------------ 
> Massimo Bressan 
> 
> ARPAV 
> Agenzia Regionale per la Prevenzione e 
> Protezione Ambientale del Veneto 
> 
> Dipartimento Provinciale di Treviso 
> Via Santa Barbara, 5/a 
> 31100 Treviso, Italy 
> 
> tel: +39 0422 558545 
> fax: +39 0422 558516 
> e-mail: massimo.bressan at arpa.veneto.it 
> ------------------------------------------------------------ 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]


From m@@@imo@bre@@@n @ending from @rp@@veneto@it  Thu Jun  7 15:27:56 2018
From: m@@@imo@bre@@@n @ending from @rp@@veneto@it (Massimo Bressan)
Date: Thu, 7 Jun 2018 15:27:56 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
 <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
Message-ID: <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>

thank you for the help 

this is my solution based on your valuable hint but without the need to pass through the use of a 'tibble' 

x<-data.frame(id=LETTERS[1:10], A=c(123,345,123,678,345,123,789,345,123,789)) 
uA<-unique(x$A) 
idx<-lapply(uA, function(v) which(x$A %in% v)) 
vals<- lapply(idx, function(index) x$id[index]) 
data.frame(unique_A = uA, list_vals=unlist(lapply(vals, paste, collapse = ", "))) 

best 



Da: "Ben Tupper" <btupper at bigelow.org> 
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
Cc: "r-help" <R-help at r-project.org> 
Inviato: Gioved?, 7 giugno 2018 14:47:55 
Oggetto: Re: [R] aggregate and list elements of variables in data.frame 

Hi, 

Does this do what you want? I had to change the id values to something more obvious. It uses tibbles which allow each variable to be a list. 

library(tibble) 
library(dplyr) 
x <- tibble(id=LETTERS[1:10], 
A=c(123,345,123,678,345,123,789,345,123,789)) 
uA <- unique(x$A) 
idx <- lapply(uA, function(v) which(x$A %in% v)) 
vals <- lapply(idx, function(index) x$id[index]) 

r <- tibble(unique_A = uA, list_idx = idx, list_vals = vals) 


> r 
# A tibble: 4 x 3 
unique_A list_idx list_vals 
<dbl> <list> <list> 
1 123. <int [4]> <chr [4]> 
2 345. <int [3]> <chr [3]> 
3 678. <int [1]> <chr [1]> 
4 789. <int [2]> <chr [2]> 
> r$list_idx[1] 
[[1]] 
[1] 1 3 6 9 

> r$list_vals[1] 
[[1]] 
[1] "A" "C" "F" "I" 


Cheers, 
ben 


	[[alternative HTML version deleted]]


From m@@@imo@bre@@@n @ending from @rp@@veneto@it  Thu Jun  7 15:48:38 2018
From: m@@@imo@bre@@@n @ending from @rp@@veneto@it (Massimo Bressan)
Date: Thu, 7 Jun 2018 15:48:38 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
 <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
 <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <582342719.9778477.1528379318105.JavaMail.zimbra@arpa.veneto.it>

#ok, finally this is my final "best and more compact" solution of the problem by merging different contributions (thanks to all indeed) 

t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789)) 
l<-sapply(unique(t$A), function(x) t$id[which(t$A==x)]) 
r<-data.frame(unique_A= unique(t$A), list_id=unlist(lapply(l, paste, collapse = ", "))) 
r 


	[[alternative HTML version deleted]]


From chettyvk @ending from gm@il@com  Thu Jun  7 16:18:18 2018
From: chettyvk @ending from gm@il@com (Veerappa Chetty)
Date: Thu, 7 Jun 2018 10:18:18 -0400
Subject: [R] stat_function with data frames in ggplot2
Message-ID: <CAFpsATaZmLYFBEWPX3k+WTBgLTOeanijOOR0BpmtL-sQ+88ckA@mail.gmail.com>

I use solve(A,b) inside my function, myfun2; it works fine when I return
one value or a list.
I want use the return values in ggplot as below: ggplot(data.frame(
x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
I get a blank graph. Would greatly appreciate help! Thanks.

Here are my codes:
p.lm<-0.05 ##to initialze only
p.lh<-0.1
p.ll<-1-p.lm-p.lh
p.ml<-0.3
p.mh<-0.1
p.mm<-1-p.ml-p.mh
p.hl<-0.05
p.hm<-0.5
p.hh<-1-p.hl-p.hm
myfun.5<-function(xvar){
y<-numeric(2)
p.lm<-xvar
A<-matrix(c(p.lm+p.lh+p.hl,p.hl-p.ml,p.hm-p.lm,p.ml+p.mh+p.hm),nrow=2,byrow
= TRUE)
b<-c(p.hl,p.hm)
y<-solve(A,b)
z<-list(y[1],y[2],1-y[1]-y[2])
z[1]
}

g.2<-ggplot(data.frame(
x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.5,geom="line")
g.2

-- 
Professor of Family Medicine
Boston University
Tel: 617-414-6221, Fax:617-414-3345
emails: chettyvk at gmail.com,vchetty at bu.edu

	[[alternative HTML version deleted]]


From dmitri@pop@venko @ending from gm@il@com  Thu Jun  7 17:21:58 2018
From: dmitri@pop@venko @ending from gm@il@com (Dmitri Popavenko)
Date: Thu, 7 Jun 2018 18:21:58 +0300
Subject: [R] open help files from Terminal
Message-ID: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>

Dear R users,

I am sometimes using R from a Terminal (either from Linux but most often on
MacOS).
When looking at a help file using the question mark (e.g. ?sd) the help
file opens in the Terminal itself.

If possible, I would like to open the HTML version of the help file in a
webpage, but I am completely unaware of how this might be done.

If anyone has a suggestion, I would be very grateful.

Best,
Dmitri

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Thu Jun  7 17:23:50 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 7 Jun 2018 08:23:50 -0700
Subject: [R] stat_function with data frames in ggplot2
In-Reply-To: <CAFpsATaZmLYFBEWPX3k+WTBgLTOeanijOOR0BpmtL-sQ+88ckA@mail.gmail.com>
References: <CAFpsATaZmLYFBEWPX3k+WTBgLTOeanijOOR0BpmtL-sQ+88ckA@mail.gmail.com>
Message-ID: <077AAEEF-A087-4992-8F64-20EB4B1F5B93@comcast.net>


> On Jun 7, 2018, at 7:18 AM, Veerappa Chetty <chettyvk at gmail.com> wrote:
> 
> I use solve(A,b) inside my function, myfun2; it works fine when I return
> one value or a list.
> I want use the return values in ggplot as below: ggplot(data.frame(
> x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
> I get a blank graph. Would greatly appreciate help! Thanks.
> 
> Here are my codes:
> p.lm<-0.05 ##to initialze only
> p.lh<-0.1
> p.ll<-1-p.lm-p.lh
> p.ml<-0.3
> p.mh<-0.1
> p.mm<-1-p.ml-p.mh
> p.hl<-0.05
> p.hm<-0.5
> p.hh<-1-p.hl-p.hm
> myfun.5<-function(xvar){
> y<-numeric(2)
> p.lm<-xvar
> A<-matrix(c(p.lm+p.lh+p.hl,p.hl-p.ml,p.hm-p.lm,p.ml+p.mh+p.hm),nrow=2,byrow
> = TRUE)
> b<-c(p.hl,p.hm)
> y<-solve(A,b)
> z<-list(y[1],y[2],1-y[1]-y[2])
> z[1]
> }
> 
> g.2<-ggplot(data.frame(
> x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.5,geom="line")
> g.2

You are a) failing to pay attention to the warning message:

> g.2
Warning message:
Computation failed in `stat_function()`:
'a' (2 x 102) must be square 

> 

.... and b) as a consequence failing to debug your function. Add a print(A) line immediately after your construction of A:

 myfun.5(1:10)
      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
[1,]  1.15  2.15  3.15  4.15  5.15  6.15  7.15  8.15  9.15 10.15 -0.25
[2,] -0.50 -1.50 -2.50 -3.50 -4.50 -5.50 -6.50 -7.50 -8.50 -9.50  0.90
Error in solve.default(A, b) : 'a' (2 x 11) must be square

The fun argument in stat_fun is supposed to accept a vector with x values and return y values for "predictions". You have not indicated what plot was expected, You've given no indication what the various constants are supposed to represent, and you are only giving x-values to aes.ggplot, so I'm unable to infer what is intended.



> -- 
> Professor of Family Medicine
> Boston University
> Tel: 617-414-6221, Fax:617-414-3345
> emails: chettyvk at gmail.com,vchetty at bu.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwin@emiu@ @ending from comc@@t@net  Thu Jun  7 17:29:39 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Thu, 7 Jun 2018 08:29:39 -0700
Subject: [R] open help files from Terminal
In-Reply-To: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
Message-ID: <B9245AF6-414D-4EBF-9FD3-8FCA718B429A@comcast.net>


> On Jun 7, 2018, at 8:21 AM, Dmitri Popavenko <dmitri.popavenko at gmail.com> wrote:
> 
> Dear R users,
> 
> I am sometimes using R from a Terminal (either from Linux but most often on
> MacOS).
> When looking at a help file using the question mark (e.g. ?sd) the help
> file opens in the Terminal itself.
> 
> If possible, I would like to open the HTML version of the help file in a
> webpage, but I am completely unaware of how this might be done.

First I looked at:

?help

Seeing the help-type parameter included "html" as a potential value, I therefore tried this from a Terminal-launched session on a Mac (although normally I work in the R.app GUI):

help(sd, help_type="html")

I get the expected sd-help page displayed in my open Chrome browser.


> 
> If anyone has a suggestion, I would be very grateful.
> 
> Best,
> Dmitri
> 
> 	[[alternative HTML version deleted]]

R is a plain text mailing list.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From @@r@h@go@lee @ending from gm@il@com  Thu Jun  7 17:39:48 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Thu, 7 Jun 2018 11:39:48 -0400
Subject: [R] open help files from Terminal
In-Reply-To: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
Message-ID: <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>

Here are two options:

> # for one occurrence
> help("help", help_type="html")
starting httpd help server ... done
>
> # to set the default for your R session
> options(help_type = "html")
> ?help

If you read the help file for help(), you will see all the possibilities.

Sarah

On Thu, Jun 7, 2018 at 11:21 AM, Dmitri Popavenko
<dmitri.popavenko at gmail.com> wrote:
> Dear R users,
>
> I am sometimes using R from a Terminal (either from Linux but most often on
> MacOS).
> When looking at a help file using the question mark (e.g. ?sd) the help
> file opens in the Terminal itself.
>
> If possible, I would like to open the HTML version of the help file in a
> webpage, but I am completely unaware of how this might be done.
>
> If anyone has a suggestion, I would be very grateful.
>
> Best,
> Dmitri

-- 
Sarah Goslee
http://www.functionaldiversity.org


From dmitri@pop@venko @ending from gm@il@com  Thu Jun  7 17:47:36 2018
From: dmitri@pop@venko @ending from gm@il@com (Dmitri Popavenko)
Date: Thu, 7 Jun 2018 18:47:36 +0300
Subject: [R] open help files from Terminal
In-Reply-To: <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
 <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>
Message-ID: <CAJL_pohsSWXQLite=xa4huknBy8bD-XzmR2rRzc486ntdN5wbQ@mail.gmail.com>

Dear Sarah, dear David,

Thank you very much indeed, this is exactly what I needed.

Best,
Dmitri

On Thu, Jun 7, 2018 at 6:39 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Here are two options:
>
> > # for one occurrence
> > help("help", help_type="html")
> starting httpd help server ... done
> >
> > # to set the default for your R session
> > options(help_type = "html")
> > ?help
>
> If you read the help file for help(), you will see all the possibilities.
>
> Sarah
>
> On Thu, Jun 7, 2018 at 11:21 AM, Dmitri Popavenko
> <dmitri.popavenko at gmail.com> wrote:
> > Dear R users,
> >
> > I am sometimes using R from a Terminal (either from Linux but most often
> on
> > MacOS).
> > When looking at a help file using the question mark (e.g. ?sd) the help
> > file opens in the Terminal itself.
> >
> > If possible, I would like to open the HTML version of the help file in a
> > webpage, but I am completely unaware of how this might be done.
> >
> > If anyone has a suggestion, I would be very grateful.
> >
> > Best,
> > Dmitri
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]


From m@echler @ending from @t@t@m@th@ethz@ch  Thu Jun  7 18:35:48 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 7 Jun 2018 18:35:48 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
Message-ID: <23321.24292.243245.897326@stat.math.ethz.ch>

>>>>> Gerrit Eichner 
>>>>>     on Thu, 7 Jun 2018 09:03:46 +0200 writes:

    > Hi, Chris, had the same problem (and first thought it was
    > my fault), but there seems to be a typo in the code of
    > pairs.default. Below is a workaround.  Look for two
    > comments (starting with #####) in the code to see what I
    > have changed to make it work at least the way I'd expect
    > it in one of your examples.

    >   Hth -- Gerrit

> mypairs <- function (x, labels, panel = points, ...,
>      horInd = 1:nc, verInd = 1:nc,
>      lower.panel = panel, upper.panel = panel, diag.panel = NULL,
>      text.panel = textPanel, label.pos = 0.5 + has.diag/3, line.main = 3,
>      cex.labels = NULL, font.labels = 1, row1attop = TRUE, gap = 1,
>      log = "") {
>      if (doText <- missing(text.panel) || is.function(text.panel))
>          textPanel <- function(x = 0.5, y = 0.5, txt, cex, font) text(x,
>              y, txt, cex = cex, font = font)
>      localAxis <- function(side, x, y, xpd, bg, col = NULL, main,
>          oma, ...) {
>          xpd <- NA
>          if (side%%2L == 1L && xl[j])
>              xpd <- FALSE
>          if (side%%2L == 0L && yl[i])
>              xpd <- FALSE
>          if (side%%2L == 1L)
>              Axis(x, side = side, xpd = xpd, ...)
>          else Axis(y, side = side, xpd = xpd, ...)
>      }
>      localPlot <- function(..., main, oma, font.main, cex.main) plot(...)
>      localLowerPanel <- function(..., main, oma, font.main, cex.main) lower.panel(...)
>      localUpperPanel <- function(..., main, oma, font.main, cex.main) upper.panel(...)
>      localDiagPanel <- function(..., main, oma, font.main, cex.main) diag.panel(...)
>      dots <- list(...)
>      nmdots <- names(dots)
>      if (!is.matrix(x)) {
>          x <- as.data.frame(x)
>          for (i in seq_along(names(x))) {
>              if (is.factor(x[[i]]) || is.logical(x[[i]]))
>                  x[[i]] <- as.numeric(x[[i]])
>              if (!is.numeric(unclass(x[[i]])))
>                  stop("non-numeric argument to 'pairs'")
>          }
>      }
>      else if (!is.numeric(x))
>          stop("non-numeric argument to 'pairs'")
>      panel <- match.fun(panel)
>      if ((has.lower <- !is.null(lower.panel)) && !missing(lower.panel))
>          lower.panel <- match.fun(lower.panel)
>      if ((has.upper <- !is.null(upper.panel)) && !missing(upper.panel))
>          upper.panel <- match.fun(upper.panel)
>      if ((has.diag <- !is.null(diag.panel)) && !missing(diag.panel))
>          diag.panel <- match.fun(diag.panel)
>      if (row1attop) {
>          tmp <- lower.panel
>          lower.panel <- upper.panel
>          upper.panel <- tmp
>          tmp <- has.lower
>          has.lower <- has.upper
>          has.upper <- tmp
>      }
>      nc <- ncol(x)
>      if (nc < 2L)
>          stop("only one column in the argument to 'pairs'")
>      if (!all(horInd >= 1L && horInd <= nc))
>          stop("invalid argument 'horInd'")
>      if (!all(verInd >= 1L && verInd <= nc))
>          stop("invalid argument 'verInd'")
>      if (doText) {
>          if (missing(labels)) {
>              labels <- colnames(x)
>              if (is.null(labels))
>                  labels <- paste("var", 1L:nc)
>          }
>          else if (is.null(labels))
>              doText <- FALSE
>      }
>      oma <- if ("oma" %in% nmdots)
>          dots$oma
>      main <- if ("main" %in% nmdots)
>          dots$main
>      if (is.null(oma))
>          oma <- c(4, 4, if (!is.null(main)) 6 else 4, 4)
>      opar <- par(mfcol = c(length(horInd), length(verInd)),
> ##### Changed from mfrow to mfcol
>                  mar = rep.int(gap/2, 4), oma = oma)
>      on.exit(par(opar))
>      dev.hold()
>      on.exit(dev.flush(), add = TRUE)
>      xl <- yl <- logical(nc)
>      if (is.numeric(log))
>          xl[log] <- yl[log] <- TRUE
>      else {
>          xl[] <- grepl("x", log)
>          yl[] <- grepl("y", log)
>      }
>      for (j in if (row1attop) verInd else rev(verInd))
>       for (i in horInd) {
> ##### Exchanged i and j. (i used to be in
> ##### the outer and j in the inner loop!)
>          l <- paste0(ifelse(xl[j], "x", ""), ifelse(yl[i], "y", ""))
>          localPlot(x[, j], x[, i], xlab = "", ylab = "", axes = FALSE,
>              type = "n", ..., log = l)
>          if (i == j || (i < j && has.lower) || (i > j && has.upper)) {
>              box()
>              if (i == 1 && (!(j%%2L) || !has.upper || !has.lower))
>                  localAxis(1L + 2L * row1attop, x[, j], x[, i],
>                    ...)
>              if (i == nc && (j%%2L || !has.upper || !has.lower))
>                  localAxis(3L - 2L * row1attop, x[, j], x[, i],
>                    ...)
>              if (j == 1 && (!(i%%2L) || !has.upper || !has.lower))
>                  localAxis(2L, x[, j], x[, i], ...)
>              if (j == nc && (i%%2L || !has.upper || !has.lower))
>                  localAxis(4L, x[, j], x[, i], ...)
>              mfg <- par("mfg")
>              if (i == j) {
>                  if (has.diag)
>                    localDiagPanel(as.vector(x[, i]), ...)
>                  if (doText) {
>                    par(usr = c(0, 1, 0, 1))
>                    if (is.null(cex.labels)) {
>                      l.wid <- strwidth(labels, "user")
>                      cex.labels <- max(0.8, min(2, 0.9/max(l.wid)))
>                    }
>                    xlp <- if (xl[i])
>                      10^0.5
>                    else 0.5
>                    ylp <- if (yl[j])
>                      10^label.pos
>                    else label.pos
>                    text.panel(xlp, ylp, labels[i], cex = cex.labels,
>                      font = font.labels)
>                  }
>              }
>              else if (i < j)
>                  localLowerPanel(as.vector(x[, j]), as.vector(x[,
>                    i]), ...)
>              else localUpperPanel(as.vector(x[, j]), as.vector(x[,
>                  i]), ...)
>              if (any(par("mfg") != mfg))
>                  stop("the 'panel' function made a new plot")
>          }
>          else par(new = FALSE)
>      }
>      if (!is.null(main)) {
>          font.main <- if ("font.main" %in% nmdots)
>              dots$font.main
>          else par("font.main")
>          cex.main <- if ("cex.main" %in% nmdots)
>              dots$cex.main
>          else par("cex.main")
>          mtext(main, 3, line.main, outer = TRUE, at = 0.5, cex = cex.main,
>              font = font.main)
>      }
>      invisible(NULL)
> }
> 
> 
> 
> ## Example:
> 
> mypairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:4)

Thank you, Chris, for the report and
Gerrit for your proposed fix !!

It looks good to me,  but I will test some more (also with
'row1attop=FALSE')  before committing the bug fix.

Best regards,

Martin Maechler
ETH Zurich and R Core Team

> Am 06.06.2018 um 23:55 schrieb Andrews, Chris:
> > 
> > After making scatterplot matrix, I determined I only needed the first 2 columns of the matrix so I added verInd=1:2 to my pairs() call.  However, it did not turn out as I expected.
> > 
> > Perhaps the attached pdf of the example code will make it through.  If not, my description is "the wrong scatterplot pairs are in the wrong places" for the last two pairs() calls.
> > 
> > Thanks,
> > Chris
> > 
> > ################################################################
> > 
> > # fake data
> > xmat <- matrix(1:28, ncol=4)
> > lim <- range(xmat)
> > 
> > # what I expected
> > pairs(xmat, xlim=lim, ylim=lim) # 4x4 matrix of scatterplots
> > pairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:2) # 2x2 matrix of scatterplots: upper left
> > 
> > # here comes trouble
> > pairs(xmat, xlim=lim, ylim=lim, horInd=1:2) # 2x4 matrix of scatterplots: but not the top 2 rows (or bottom 2 rows)
> > pairs(xmat, xlim=lim, ylim=lim, verInd=1:2) # 4x2 matrix of scatterplots: but not the left 2 columns (or right 2 columns)
> > 
> > 
> > ###############################################################
> > 
> >> sessionInfo()
> > R version 3.5.0 (2018-04-23)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> > 
> > Matrix products: default
> > 
> > locale:
> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
> > 
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> > 
> > loaded via a namespace (and not attached):
> > [1] compiler_3.5.0 tools_3.5.0
> > **********************************************************


From ruiy@ngliu94 @ending from gm@il@com  Thu Jun  7 17:12:27 2018
From: ruiy@ngliu94 @ending from gm@il@com (=?utf-8?B?5YiY55Ge6Ziz?=)
Date: Thu, 7 Jun 2018 10:12:27 -0500
Subject: [R] problems in converting numeric to character
Message-ID: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>

Hi,
I am having trouble converting numeric to characters in the format I desire. To be more specific, I have a number of numeric as follows:

x<-c(1.0,2.0,2.00,2.1)
I want to convert them to characters so that the out put would be c(?1.0?,?2.0?,?2.00?,?2.1?). 

However, I used as.character(x) and the output is:
"1"   "2"   "2"   ?2.1"

The decimals are removed if the numeric ends with ?.0?. Is there a way to circumvent this problem?

Thanks very much!

Sincerely,

Ruiyang Liu

From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jun  7 21:40:40 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 07 Jun 2018 12:40:40 -0700
Subject: [R] problems in converting numeric to character
In-Reply-To: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
References: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
Message-ID: <033F6E18-1EF7-4C92-9B98-79B931AC1E9C@dcn.davis.ca.us>

?formatC (digits, drop0trailing)
?sprintf (format %f)
?cat 
?options (digits)

You appear to be confusing source code formatting with output formatting. The internal representation of a numeric value has no notion of the number of decimals that were used to enter it into memory from source code. By the time you (or R) decide to re-convert it to a visual representation (characters), all trace of the original representation has been forgotten, so you have to be explicit about your output format, or R will make assumptions.

On June 7, 2018 8:12:27 AM PDT, "???" <ruiyangliu94 at gmail.com> wrote:
>Hi,
>I am having trouble converting numeric to characters in the format I
>desire. To be more specific, I have a number of numeric as follows:
>
>x<-c(1.0,2.0,2.00,2.1)
>I want to convert them to characters so that the out put would be
>c(?1.0?,?2.0?,?2.00?,?2.1?). 
>
>However, I used as.character(x) and the output is:
>"1"   "2"   "2"   ?2.1"
>
>The decimals are removed if the numeric ends with ?.0?. Is there a way
>to circumvent this problem?
>
>Thanks very much!
>
>Sincerely,
>
>Ruiyang Liu
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Fri Jun  8 02:26:43 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Thu, 7 Jun 2018 17:26:43 -0700
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <582342719.9778477.1528379318105.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
 <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
 <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>
 <582342719.9778477.1528379318105.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAGxFJbTu8f_kMDd7EiEwVdNxYUUnAZn=OQ_b5qdOWRSAw8eRbw@mail.gmail.com>

which() is unnecessary. Use logical subscripting:

... t$id[t$A ==x]

Further simplification can be gotten by using the with() function:

l <- with(t, sapply(unique(A), function(x) id[A ==x]))

Check this though -- there might be scoping issues.

Cheers,
Bert



On Thu, Jun 7, 2018, 6:49 AM Massimo Bressan <massimo.bressan at arpa.veneto.it>
wrote:

> #ok, finally this is my final "best and more compact" solution of the
> problem by merging different contributions (thanks to all indeed)
>
> t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789))
>
> l<-sapply(unique(t$A), function(x) t$id[which(t$A==x)])
> r<-data.frame(unique_A= unique(t$A), list_id=unlist(lapply(l, paste,
> collapse = ", ")))
> r
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From d@vid@mi @ending from micro@oft@com  Thu Jun  7 23:29:29 2018
From: d@vid@mi @ending from micro@oft@com (David Smith (CDA))
Date: Thu, 7 Jun 2018 21:29:29 +0000
Subject: [R] Revolutions blog: May 2018 roundup
Message-ID: <DM5PR2101MB10481D3343F5519CA52EED23C8640@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of May:

The R Consortium has announced a new round of grants for projects proposed by
the R community:
http://blog.revolutionanalytics.com/2018/05/r-consortium-spring-2018.html

A look back at the ROpenSci unconference held in Seattle:
http://blog.revolutionanalytics.com/2018/05/reflections-on-the-ropensci-unconference.html

Video of my European R Users Meeting talk, "Speeding up R with Parallel
Programming in the Cloud":
http://blog.revolutionanalytics.com/2018/05/video-speeding-up-r-foreach.html

Slides from my talk at the Microsoft Build conference, "Open-Source Machine
Learning in Azure":
http://blog.revolutionanalytics.com/2018/05/open-source-machine-learning-in-azure.html

Discussions on Twitter: R packages by stage of data analysis; thinking
differently about AI development; and, why is package management harder in Python
than R? http://blog.revolutionanalytics.com/2018/05/three-twitter-threads.html

Microsoft R Open 3.4.4 is now available:
http://blog.revolutionanalytics.com/2018/04/microsoft-r-open-344-now-available.html

And some general interest stories (not necessarily related to R):

* A really bad road in Nepal:
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-bad-road.html

* Our May 2018 roundup of AI and data science news:
  http://blog.revolutionanalytics.com/2018/05/ai-roundup-may-2018.html 

* The definitive answer to "Laurel" or "Yanny" (it's Laurel):
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-laurel-or-yanny.html

* Panelist Francesca Lazzeri reviews the Mind Bytes AI conference in Chicago:
  http://blog.revolutionanalytics.com/2018/05/mind-bytes.html

* A parody of air travel:
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-planes-pains-and-automobiles.html

* When magpies attack:
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-the-eyes-dont-work.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com


From du@@@@dri@n @ending from unibuc@ro  Thu Jun  7 21:12:10 2018
From: du@@@@dri@n @ending from unibuc@ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Thu, 7 Jun 2018 22:12:10 +0300
Subject: [R] problems in converting numeric to character
In-Reply-To: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
References: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
Message-ID: <CAJ=0CtAhuwYoLgz-Q_M=E1Vq3sTUZA+=b6WyVSQBQ2wOs1F6_Q@mail.gmail.com>

Does this helps?

> formatC(x, digits = 1, format = "f")
[1] "1.0" "2.0" "2.0" "2.1"


On Thu, Jun 7, 2018 at 10:08 PM ??? <ruiyangliu94 at gmail.com> wrote:

> Hi,
> I am having trouble converting numeric to characters in the format I
> desire. To be more specific, I have a number of numeric as follows:
>
> x<-c(1.0,2.0,2.00,2.1)
> I want to convert them to characters so that the out put would be
> c(?1.0?,?2.0?,?2.00?,?2.1?).
>
> However, I used as.character(x) and the output is:
> "1"   "2"   "2"   ?2.1"
>
> The decimals are removed if the numeric ends with ?.0?. Is there a way to
> circumvent this problem?
>
> Thanks very much!
>
> Sincerely,
>
> Ruiyang Liu
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @igbert @ending from wiwi@hu-berlin@de  Fri Jun  8 09:08:46 2018
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Fri, 8 Jun 2018 09:08:46 +0200
Subject: [R] problems in converting numeric to character
In-Reply-To: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
References: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
Message-ID: <0dd0ca0b-5938-e8a8-2a26-93bf1f50f9c8@wiwi.hu-berlin.de>

sprintf("%.1f", x)
sprintf("%.2f", x)

Am 07.06.2018 um 17:12 schrieb ???:
> Hi,
> I am having trouble converting numeric to characters in the format I desire. To be more specific, I have a number of numeric as follows:
> 
> x<-c(1.0,2.0,2.00,2.1)
> I want to convert them to characters so that the out put would be c(?1.0?,?2.0?,?2.00?,?2.1?).
> 
> However, I used as.character(x) and the output is:
> "1"   "2"   "2"   ?2.1"
> 
> The decimals are removed if the numeric ends with ?.0?. Is there a way to circumvent this problem?
> 
> Thanks very much!
> 
> Sincerely,
> 
> Ruiyang Liu
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Sprechstunde: Fr 12-13, SPA1, R308
https://hu.berlin/sk
https://hu.berlin/mmstat3


From E@Vettor@zzi @ending from uke@de  Fri Jun  8 09:45:30 2018
From: E@Vettor@zzi @ending from uke@de (Eik Vettorazzi)
Date: Fri, 8 Jun 2018 09:45:30 +0200
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <13f05a25-03cb-5d0a-0b87-f719c3d0d875@uke.de>

Hi,
if you are willing to use dplyr, you can do all in one line of code:

library(dplyr)
df<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))

df%>%group_by(unique_A=A)%>%summarise(list_id=paste(id,collapse=", "))->r

cheers


Am 06.06.2018 um 10:13 schrieb Massimo Bressan:
> #given the following reproducible and simplified example 
> 
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
> t 
> 
> #I need to get the following result 
> 
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
> r 
> 
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
> #any help for that? 
> 
> #so far I've just managed to "aggregate" and "count", like: 
> 
> library(sqldf) 
> sqldf('select count(*) as count_id, A as unique_A from t group by A') 
> 
> library(dplyr) 
> t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 
> 
> # thank you 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistrasse 52
building W 34
20246 Hamburg

Phone: +49 (0) 40 7410 - 58243
Fax:   +49 (0) 40 7410 - 57790
Web: www.uke.de/imbe
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From m@echler @ending from @t@t@m@th@ethz@ch  Fri Jun  8 11:13:24 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 8 Jun 2018 11:13:24 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <23321.24292.243245.897326@stat.math.ethz.ch>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
Message-ID: <23322.18612.376176.297782@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Thu, 7 Jun 2018 18:35:48 +0200 writes:

>>>>> Gerrit Eichner 
>>>>>     on Thu, 7 Jun 2018 09:03:46 +0200 writes:

    >> Hi, Chris, had the same problem (and first thought it was
    >> my fault), but there seems to be a typo in the code of
    >> pairs.default. Below is a workaround.  Look for two
    >> comments (starting with #####) in the code to see what I
    >> have changed to make it work at least the way I'd expect
    >> it in one of your examples.

    >> Hth -- Gerrit


> > mypairs <- function (x, labels, panel = points, ...,
> >      horInd = 1:nc, verInd = 1:nc,
> >      lower.panel = panel, upper.panel = panel, diag.panel = NULL,
> >      text.panel = textPanel, label.pos = 0.5 + has.diag/3, line.main = 3,
> >      cex.labels = NULL, font.labels = 1, row1attop = TRUE, gap = 1,
> >      log = "") {
> >      if (doText <- missing(text.panel) || is.function(text.panel))
> >          textPanel <- function(x = 0.5, y = 0.5, txt, cex, font) text(x,
> >              y, txt, cex = cex, font = font)
> >      localAxis <- function(side, x, y, xpd, bg, col = NULL, main,
> >          oma, ...) {
> >          xpd <- NA
> >          if (side%%2L == 1L && xl[j])
> >              xpd <- FALSE
> >          if (side%%2L == 0L && yl[i])
> >              xpd <- FALSE
> >          if (side%%2L == 1L)
> >              Axis(x, side = side, xpd = xpd, ...)
> >          else Axis(y, side = side, xpd = xpd, ...)
> >      }
> >      localPlot <- function(..., main, oma, font.main, cex.main) plot(...)
> >      localLowerPanel <- function(..., main, oma, font.main, cex.main) lower.panel(...)
> >      localUpperPanel <- function(..., main, oma, font.main, cex.main) upper.panel(...)
> >      localDiagPanel <- function(..., main, oma, font.main, cex.main) diag.panel(...)
> >      dots <- list(...)
> >      nmdots <- names(dots)
> >      if (!is.matrix(x)) {
> >          x <- as.data.frame(x)
> >          for (i in seq_along(names(x))) {
> >              if (is.factor(x[[i]]) || is.logical(x[[i]]))
> >                  x[[i]] <- as.numeric(x[[i]])
> >              if (!is.numeric(unclass(x[[i]])))
> >                  stop("non-numeric argument to 'pairs'")
> >          }
> >      }
> >      else if (!is.numeric(x))
> >          stop("non-numeric argument to 'pairs'")
> >      panel <- match.fun(panel)
> >      if ((has.lower <- !is.null(lower.panel)) && !missing(lower.panel))
> >          lower.panel <- match.fun(lower.panel)
> >      if ((has.upper <- !is.null(upper.panel)) && !missing(upper.panel))
> >          upper.panel <- match.fun(upper.panel)
> >      if ((has.diag <- !is.null(diag.panel)) && !missing(diag.panel))
> >          diag.panel <- match.fun(diag.panel)
> >      if (row1attop) {
> >          tmp <- lower.panel
> >          lower.panel <- upper.panel
> >          upper.panel <- tmp
> >          tmp <- has.lower
> >          has.lower <- has.upper
> >          has.upper <- tmp
> >      }
> >      nc <- ncol(x)
> >      if (nc < 2L)
> >          stop("only one column in the argument to 'pairs'")
> >      if (!all(horInd >= 1L && horInd <= nc))
> >          stop("invalid argument 'horInd'")
> >      if (!all(verInd >= 1L && verInd <= nc))
> >          stop("invalid argument 'verInd'")
> >      if (doText) {
> >          if (missing(labels)) {
> >              labels <- colnames(x)
> >              if (is.null(labels))
> >                  labels <- paste("var", 1L:nc)
> >          }
> >          else if (is.null(labels))
> >              doText <- FALSE
> >      }
> >      oma <- if ("oma" %in% nmdots)
> >          dots$oma
> >      main <- if ("main" %in% nmdots)
> >          dots$main
> >      if (is.null(oma))
> >          oma <- c(4, 4, if (!is.null(main)) 6 else 4, 4)
> >      opar <- par(mfcol = c(length(horInd), length(verInd)),
> > ##### Changed from mfrow to mfcol
> >                  mar = rep.int(gap/2, 4), oma = oma)
> >      on.exit(par(opar))
> >      dev.hold()
> >      on.exit(dev.flush(), add = TRUE)
> >      xl <- yl <- logical(nc)
> >      if (is.numeric(log))
> >          xl[log] <- yl[log] <- TRUE
> >      else {
> >          xl[] <- grepl("x", log)
> >          yl[] <- grepl("y", log)
> >      }
> >      for (j in if (row1attop) verInd else rev(verInd))
> >       for (i in horInd) {
> > ##### Exchanged i and j. (i used to be in
> > ##### the outer and j in the inner loop!)
> >          l <- paste0(ifelse(xl[j], "x", ""), ifelse(yl[i], "y", ""))
> >          localPlot(x[, j], x[, i], xlab = "", ylab = "", axes = FALSE,
> >              type = "n", ..., log = l)
> >          if (i == j || (i < j && has.lower) || (i > j && has.upper)) {
> >              box()
> >              if (i == 1 && (!(j%%2L) || !has.upper || !has.lower))
> >                  localAxis(1L + 2L * row1attop, x[, j], x[, i],
> >                    ...)
> >              if (i == nc && (j%%2L || !has.upper || !has.lower))
> >                  localAxis(3L - 2L * row1attop, x[, j], x[, i],
> >                    ...)
> >              if (j == 1 && (!(i%%2L) || !has.upper || !has.lower))
> >                  localAxis(2L, x[, j], x[, i], ...)
> >              if (j == nc && (i%%2L || !has.upper || !has.lower))
> >                  localAxis(4L, x[, j], x[, i], ...)
> >              mfg <- par("mfg")
> >              if (i == j) {
> >                  if (has.diag)
> >                    localDiagPanel(as.vector(x[, i]), ...)
> >                  if (doText) {
> >                    par(usr = c(0, 1, 0, 1))
> >                    if (is.null(cex.labels)) {
> >                      l.wid <- strwidth(labels, "user")
> >                      cex.labels <- max(0.8, min(2, 0.9/max(l.wid)))
> >                    }
> >                    xlp <- if (xl[i])
> >                      10^0.5
> >                    else 0.5
> >                    ylp <- if (yl[j])
> >                      10^label.pos
> >                    else label.pos
> >                    text.panel(xlp, ylp, labels[i], cex = cex.labels,
> >                      font = font.labels)
> >                  }
> >              }
> >              else if (i < j)
> >                  localLowerPanel(as.vector(x[, j]), as.vector(x[,
> >                    i]), ...)
> >              else localUpperPanel(as.vector(x[, j]), as.vector(x[,
> >                  i]), ...)
> >              if (any(par("mfg") != mfg))
> >                  stop("the 'panel' function made a new plot")
> >          }
> >          else par(new = FALSE)
> >      }
> >      if (!is.null(main)) {
> >          font.main <- if ("font.main" %in% nmdots)
> >              dots$font.main
> >          else par("font.main")
> >          cex.main <- if ("cex.main" %in% nmdots)
> >              dots$cex.main
> >          else par("cex.main")
> >          mtext(main, 3, line.main, outer = TRUE, at = 0.5, cex = cex.main,
> >              font = font.main)
> >      }
> >      invisible(NULL)
> > }
> > 
> > 
> > 
> > ## Example:
> > 
> > mypairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:4)
> 
> Thank you, Chris, for the report and
> Gerrit for your proposed fix !!
> 
> It looks good to me,  but I will test some more (also with
> 'row1attop=FALSE')  before committing the bug fix.

and there, another change was needed:  Instead of your

    for (j in if (row1attop) verInd else rev(verInd))
        for (i in horInd) {

we do now need

    for(j in verInd)
        for(i in if(row1attop) horInd else rev(horInd)) {

and the difference is of course only relevant for the
non-default  'row1attop = FALSE'

  (which some graphic experts argue to be clearly *better* than the default,
   as only in that case,  the upper and lower triangles of the
   matrix are nicely "mirrors of each other", and that is also
   the reason why  lattice::splom()  uses the equivalent of
   'row1attop=FALSE')

I will commit the change to R-devel today - and intend to port
to R-patched in time to make it into the upcoming R 3.5.1.

Thank you once more !
Martin


From m@echler @ending from @t@t@m@th@ethz@ch  Fri Jun  8 12:02:43 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 8 Jun 2018 12:02:43 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <23322.18612.376176.297782@stat.math.ethz.ch>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
 <23322.18612.376176.297782@stat.math.ethz.ch>
Message-ID: <23322.21571.493562.112124@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Fri, 8 Jun 2018 11:13:24 +0200 writes:

[..........]

    >> Thank you, Chris, for the report and
    >> Gerrit for your proposed fix !!
    >> 
    >> It looks good to me,  but I will test some more (also with
    >> 'row1attop=FALSE')  before committing the bug fix.

    > and there, another change was needed:  Instead of your

    > for (j in if (row1attop) verInd else rev(verInd))
    >    for (i in horInd) {

    > we do now need

    > for(j in verInd)
    >    for(i in if(row1attop) horInd else rev(horInd)) {

    > and the difference is of course only relevant for the
    > non-default  'row1attop = FALSE'

    > (which some graphic experts argue to be clearly *better* than the default,
    > as only in that case,  the upper and lower triangles of the
    > matrix are nicely "mirrors of each other", and that is also
    > the reason why  lattice::splom()  uses the equivalent of
    > 'row1attop=FALSE')

    > I will commit the change to R-devel today - and intend to port
    > to R-patched in time to make it into the upcoming R 3.5.1.

Well, as I find, there are more bugs there, if you are using
'horInd' and 'verInd' creatively:

In a nice pairs(), the axis ticks (and their labels (numbers))
are always "on the outside" of the scatterplot matrix, and
nicely alternating.  This is not the case unfortunately, when using
 horInd or verInd which are *not* of the form p1:p2 (p1 <= p2)

==> even more changes are needed to make these cases "nice",
or  should we *require* horInd and verInd to be of that form??

This would not be back-compatible, but than such cases have been
"wrong" really in all versions of R anyway, *and*  at least be
reordering the matrix/data.frame columns, the restriction of

    (hor|ver)Ind =  p1:p2 (p1 <= p2)

would seem acceptable, would it ?


From S@Elli@on @ending from LGCGroup@com  Fri Jun  8 12:40:02 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Fri, 8 Jun 2018 10:40:02 +0000
Subject: [R] internet routines cannot be loaded, R 3.5.0
In-Reply-To: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
References: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
Message-ID: <a172a6f2722e47719b9686ed381c37aa@GBDCVPEXC08.corp.lgc-group.com>

> If I select
> "packages > install packages" in the R console, I get a message, "no
> packages were specified". I thought this command gave me a list of packages
> available to install.

You are thinking of the command line function "installed.packages", not the menu function or the package installation function "install.packages"

The latter needs a list of packages to install. The former tells you what is already installed.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From gerrit@eichner @ending from m@th@uni-gie@@en@de  Fri Jun  8 12:55:31 2018
From: gerrit@eichner @ending from m@th@uni-gie@@en@de (Gerrit Eichner)
Date: Fri, 8 Jun 2018 12:55:31 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <23322.21571.493562.112124@stat.math.ethz.ch>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
 <23322.18612.376176.297782@stat.math.ethz.ch>
 <23322.21571.493562.112124@stat.math.ethz.ch>
Message-ID: <c330a86d-bc1c-8bff-ac82-8209e38e9e6b@math.uni-giessen.de>

Am 08.06.2018 um 12:02 schrieb Martin Maechler:
>>>>>> Martin Maechler
>>>>>>      on Fri, 8 Jun 2018 11:13:24 +0200 writes:
> 
> [..........]
> 
>      >> Thank you, Chris, for the report and
>      >> Gerrit for your proposed fix !!
>      >>
>      >> It looks good to me,  but I will test some more (also with
>      >> 'row1attop=FALSE')  before committing the bug fix.
> 
>      > and there, another change was needed:  Instead of your
> 
>      > for (j in if (row1attop) verInd else rev(verInd))
>      >    for (i in horInd) {
> 
>      > we do now need
> 
>      > for(j in verInd)
>      >    for(i in if(row1attop) horInd else rev(horInd)) {
> 
>      > and the difference is of course only relevant for the
>      > non-default  'row1attop = FALSE'
> 
>      > (which some graphic experts argue to be clearly *better* than the default,
>      > as only in that case,  the upper and lower triangles of the
>      > matrix are nicely "mirrors of each other", and that is also
>      > the reason why  lattice::splom()  uses the equivalent of
>      > 'row1attop=FALSE')
> 
>      > I will commit the change to R-devel today - and intend to port
>      > to R-patched in time to make it into the upcoming R 3.5.1.
> 
> Well, as I find, there are more bugs there, if you are using
> 'horInd' and 'verInd' creatively:
> 
> In a nice pairs(), the axis ticks (and their labels (numbers))
> are always "on the outside" of the scatterplot matrix, and
> nicely alternating.  This is not the case unfortunately, when using
>   horInd or verInd which are *not* of the form p1:p2 (p1 <= p2)
> 
> ==> even more changes are needed to make these cases "nice",

Well, the *shown* axis ticks and labels do nicely alternate if
(hor|ver)Ind = p1:p2 (p1 <= p2) is fulfilled, but not all of
the axis ticks and labels, which one *might* wish to see, are
currently drawn anyway ... I would consider changes which "heal"
this as more interesting than solving this problem in full
generality, i.e., in cases of creative use of (hor|ver)Ind.
However, I don't think it's urgent, at all.


> or  should we *require* horInd and verInd to be of that form??
> 
> This would not be back-compatible, but than such cases have been
> "wrong" really in all versions of R anyway, *and*  at least be
> reordering the matrix/data.frame columns, the restriction of
> 
>      (hor|ver)Ind =  p1:p2 (p1 <= p2)
> 
> would seem acceptable, would it ?
> 

I could live very well with that requirement (while breaking
back-compatibility), because from my point of view a "creative"
use of 'horInd' and 'verInd' violating (hor|ver)Ind = p1:p2
(p1 <= p2) won't occur often.

On the other hand, why forcing (hor|ver)Ind = p1:p2 (p1 <= p2)?
If people violated it "they get what they deserve". ;-)

Btw, 'horInd' and 'verInd' sort of exchange their meaning if
row1attop = FALSE, but I this can be explained by the "work flow":
First, (hor|ver)Ind are used to select the respective rows and
columns from the full paris-plot, and then, row1attop is used
when the results are drawn. I think this is sensible.

  Regards  --  Gerrit


From @ez@reb@ki @ending from gm@il@com  Fri Jun  8 02:49:11 2018
From: @ez@reb@ki @ending from gm@il@com (Alex Zarebski)
Date: Fri, 8 Jun 2018 10:49:11 +1000
Subject: [R] open help files from Terminal
In-Reply-To: <CAJL_pohsSWXQLite=xa4huknBy8bD-XzmR2rRzc486ntdN5wbQ@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
 <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>
 <CAJL_pohsSWXQLite=xa4huknBy8bD-XzmR2rRzc486ntdN5wbQ@mail.gmail.com>
Message-ID: <CAKsw2nHSSPCM-qz3f2eSKk=DpBnvE=vACWog1mwR=Thzpd_ExA@mail.gmail.com>

While we are on the topic, if you wanted to go the other way (open help in
terminal without a whole R session) you can do

R --no-init-file --slave -e "?sd"

I suspect this does start an R session in the background, but makes for a
clean way to view docs through terminal if you use an alias.

Cheers,
Alex

On Fri, Jun 8, 2018 at 1:47 AM, Dmitri Popavenko <dmitri.popavenko at gmail.com
> wrote:

> Dear Sarah, dear David,
>
> Thank you very much indeed, this is exactly what I needed.
>
> Best,
> Dmitri
>
> On Thu, Jun 7, 2018 at 6:39 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
> > Here are two options:
> >
> > > # for one occurrence
> > > help("help", help_type="html")
> > starting httpd help server ... done
> > >
> > > # to set the default for your R session
> > > options(help_type = "html")
> > > ?help
> >
> > If you read the help file for help(), you will see all the possibilities.
> >
> > Sarah
> >
> > On Thu, Jun 7, 2018 at 11:21 AM, Dmitri Popavenko
> > <dmitri.popavenko at gmail.com> wrote:
> > > Dear R users,
> > >
> > > I am sometimes using R from a Terminal (either from Linux but most
> often
> > on
> > > MacOS).
> > > When looking at a help file using the question mark (e.g. ?sd) the help
> > > file opens in the Terminal itself.
> > >
> > > If possible, I would like to open the HTML version of the help file in
> a
> > > webpage, but I am completely unaware of how this might be done.
> > >
> > > If anyone has a suggestion, I would be very grateful.
> > >
> > > Best,
> > > Dmitri
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@echler @ending from @t@t@m@th@ethz@ch  Fri Jun  8 17:31:12 2018
From: m@echler @ending from @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 8 Jun 2018 17:31:12 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <c330a86d-bc1c-8bff-ac82-8209e38e9e6b@math.uni-giessen.de>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
 <23322.18612.376176.297782@stat.math.ethz.ch>
 <23322.21571.493562.112124@stat.math.ethz.ch>
 <c330a86d-bc1c-8bff-ac82-8209e38e9e6b@math.uni-giessen.de>
Message-ID: <23322.41280.560267.586732@stat.math.ethz.ch>

>>>>> Gerrit Eichner 
>>>>>     on Fri, 8 Jun 2018 12:55:31 +0200 writes:

    > Am 08.06.2018 um 12:02 schrieb Martin Maechler:
    >>>>>>> Martin Maechler
    >>>>>>> on Fri, 8 Jun 2018 11:13:24 +0200 writes:
    >> 
    >> [..........]
    >> 
    >> >> Thank you, Chris, for the report and
    >> >> Gerrit for your proposed fix !!
    >> >>
    >> >> It looks good to me,  but I will test some more (also with
    >> >> 'row1attop=FALSE')  before committing the bug fix.
    >> 
    >> > and there, another change was needed:  Instead of your
    >> 
    >> > for (j in if (row1attop) verInd else rev(verInd))
    >> >    for (i in horInd) {
    >> 
    >> > we do now need
    >> 
    >> > for(j in verInd)
    >> >    for(i in if(row1attop) horInd else rev(horInd)) {
    >> 
    >> > and the difference is of course only relevant for the
    >> > non-default  'row1attop = FALSE'
    >> 
    >> > (which some graphic experts argue to be clearly *better* than the default,
    >> > as only in that case,  the upper and lower triangles of the
    >> > matrix are nicely "mirrors of each other", and that is also
    >> > the reason why  lattice::splom()  uses the equivalent of
    >> > 'row1attop=FALSE')
    >> 
    >> > I will commit the change to R-devel today - and intend to port
    >> > to R-patched in time to make it into the upcoming R 3.5.1.
    >> 
    >> Well, as I find, there are more bugs there, if you are using
    >> 'horInd' and 'verInd' creatively:
    >> 
    >> In a nice pairs(), the axis ticks (and their labels (numbers))
    >> are always "on the outside" of the scatterplot matrix, and
    >> nicely alternating.  This is not the case unfortunately, when using
    >> horInd or verInd which are *not* of the form p1:p2 (p1 <= p2)
    >> 
    >> ==> even more changes are needed to make these cases "nice",

    > Well, the *shown* axis ticks and labels do nicely alternate if
    > (hor|ver)Ind = p1:p2 (p1 <= p2) is fulfilled, but not all of
    > the axis ticks and labels, which one *might* wish to see, are
    > currently drawn anyway ... I would consider changes which "heal"
    > this as more interesting than solving this problem in full
    > generality, i.e., in cases of creative use of (hor|ver)Ind.
    > However, I don't think it's urgent, at all.


    >> or  should we *require* horInd and verInd to be of that form??
    >> 
    >> This would not be back-compatible, but than such cases have been
    >> "wrong" really in all versions of R anyway, *and*  at least be
    >> reordering the matrix/data.frame columns, the restriction of
    >> 
    >> (hor|ver)Ind =  p1:p2 (p1 <= p2)
    >> 
    >> would seem acceptable, would it ?
    >> 

    > I could live very well with that requirement (while breaking
    > back-compatibility), because from my point of view a "creative"
    > use of 'horInd' and 'verInd' violating (hor|ver)Ind = p1:p2
    > (p1 <= p2) won't occur often.

    > On the other hand, why forcing (hor|ver)Ind = p1:p2 (p1 <= p2)?
    > If people violated it "they get what they deserve". ;-)

    > Btw, 'horInd' and 'verInd' sort of exchange their meaning if
    > row1attop = FALSE, but I this can be explained by the "work flow":
    > First, (hor|ver)Ind are used to select the respective rows and
    > columns from the full paris-plot, and then, row1attop is used
    > when the results are drawn. I think this is sensible.

Thank you; and yes indeed, and I was not going to change that.

In fact, I've found a relatively nice solution now, which does
*not* restrict the settings of '{hor,ver}Ind' and fixes all
problems mentioned,  quite back compatibly, and in some sense
perfectly labeling the axes.

==> Committed to R-devel svn c74871  a few minutes ago.

Martin


From m@rine@regi@ @ending from hotm@il@fr  Fri Jun  8 18:00:23 2018
From: m@rine@regi@ @ending from hotm@il@fr (Marine Regis)
Date: Fri, 8 Jun 2018 16:00:23 +0000
Subject: [R] Calculate focal values for neighboring cells that are located
 at the raster edge from the function "focal" in the R package "raster"
Message-ID: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>

Hello All,

I am using the function "focal" in the R package "raster" but I don?t understand how the function calculates values for neighboring cells that are located at the raster edge. Here is an example reproducible:

f <- matrix(1, nrow=3, ncol=3)
f[c(1,3,7,9)]=1/sqrt(2)
f[5]=0

func <- function(x) {
  sum(abs(x-x[5])*f)/8
}

r <- raster(ncol=3, nrow=3)
vals <- 1:ncell(r)
r <- setValues(r, vals)
plot(r)

func_f  <- focal(r, w=matrix(1,nrow=3,ncol=3),
                   fun= func, pad = TRUE, padValue = NA)
text(func_f )
getValues(func_f)


From the example, I manage to find the value ?2.06066?:

c <- 5

(abs(1-c)*(1/sqrt(2)) + abs(2-c)*1 + abs(3-c)*(1/sqrt(2)) +

  abs(4-c)*1 + abs(5-c)*0 + abs(6-c)*1 +

  abs(7-c)*(1/sqrt(2)) + abs(8-c)*1 + abs(9-c)*(1/sqrt(2))) / 8


 but I don?t manage to find the value ?2.18566?. How can I find this value ? In addition, why does the function with ?pad = TRUE? and without ?pad=TRUE? give the same result ?

 Thank you very much for your time.

Have a nice day

Marine


	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Fri Jun  8 23:52:22 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 8 Jun 2018 14:52:22 -0700
Subject: [R] 
 Calculate focal values for neighboring cells that are located
 at the raster edge from the function "focal" in the R package "raster"
In-Reply-To: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>
References: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>
Message-ID: <CAGxFJbRbwu0Oup4Tw1w4mu=CPDNNtFWK1=n5eGyL6PmaRvYEWA@mail.gmail.com>

The r-sig-geo list is often a better place to post for such
"geographically" related questions, especially if you don't  get a helpful
response  here.

But R is open source, so typing

raster:::focal

at the command line prompt will show you the function code if it is written
in R. Whether that is "helpful" is another matter.

Cheers,
Bert

On Fri, Jun 8, 2018, 9:00 AM Marine Regis <marine.regis at hotmail.fr> wrote:

> Hello All,
>
> I am using the function "focal" in the R package "raster" but I don?t
> understand how the function calculates values for neighboring cells that
> are located at the raster edge. Here is an example reproducible:
>
> f <- matrix(1, nrow=3, ncol=3)
> f[c(1,3,7,9)]=1/sqrt(2)
> f[5]=0
>
> func <- function(x) {
>   sum(abs(x-x[5])*f)/8
> }
>
> r <- raster(ncol=3, nrow=3)
> vals <- 1:ncell(r)
> r <- setValues(r, vals)
> plot(r)
>
> func_f  <- focal(r, w=matrix(1,nrow=3,ncol=3),
>                    fun= func, pad = TRUE, padValue = NA)
> text(func_f )
> getValues(func_f)
>
>
> From the example, I manage to find the value ?2.06066?:
>
> c <- 5
>
> (abs(1-c)*(1/sqrt(2)) + abs(2-c)*1 + abs(3-c)*(1/sqrt(2)) +
>
>   abs(4-c)*1 + abs(5-c)*0 + abs(6-c)*1 +
>
>   abs(7-c)*(1/sqrt(2)) + abs(8-c)*1 + abs(9-c)*(1/sqrt(2))) / 8
>
>
>  but I don?t manage to find the value ?2.18566?. How can I find this value
> ? In addition, why does the function with ?pad = TRUE? and without
> ?pad=TRUE? give the same result ?
>
>  Thank you very much for your time.
>
> Have a nice day
>
> Marine
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. Is
> helpful is
>

	[[alternative HTML version deleted]]


From p@ulbern@l07 @ending from gm@il@com  Fri Jun  8 21:26:13 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Fri, 8 Jun 2018 14:26:13 -0500
Subject: [R] Calculating AIC and BIC for Time Series Models
Message-ID: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>

Dear friends,

I have been fitting some TS models from the forecast package like ets(),
ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
trying to use the AIC and BIC functions, I receive the following error
message:

Error in UseMethod("logLik") :
  no applicable method for 'logLik' applied to an object of class "forecast"

Yes, the message is clear, those functions cannot be applied to objects
from the forecast class. However, I would like to know if there is a way to
assess the goodness of fit for this models that is somewhat equivalent to
AIC and BIC, or of there is any other function that could help me in the
model selection stage, other than computing MASE, MAPE, etc.

Any help and or guidance will be greatly appreciated.

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Fri Jun  8 21:43:53 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 8 Jun 2018 12:43:53 -0700
Subject: [R] Calculating AIC and BIC for Time Series Models
In-Reply-To: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
References: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
Message-ID: <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>


> On Jun 8, 2018, at 12:26 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> I have been fitting some TS models from the forecast package like ets(),
> ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
> trying to use the AIC and BIC functions, I receive the following error
> message:
> 
> Error in UseMethod("logLik") :
>  no applicable method for 'logLik' applied to an object of class "forecast"
> 
> Yes, the message is clear, those functions cannot be applied to objects
> from the forecast class. However, I would like to know if there is a way to
> assess the goodness of fit for this models that is somewhat equivalent to
> AIC and BIC, or of there is any other function that could help me in the
> model selection stage, other than computing MASE, MAPE, etc.
> 
> Any help and or guidance will be greatly appreciated.
> 
> 	[[alternative HTML version deleted]]

Fourth google hit on a search "goodness of fit measures for forecasts" by the author of hte forecast package:

goodness of fit measures for forecasts


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From rc@e2006 @ending from gm@il@com  Fri Jun  8 16:36:31 2018
From: rc@e2006 @ending from gm@il@com (Rama shankar)
Date: Fri, 8 Jun 2018 20:06:31 +0530
Subject: [R] How to threshold point in time series
Message-ID: <CAGYGU1cHcTUE=mg2rnyJwUo1Bf4fsACjUCdoQXk56s3wsFmpQg@mail.gmail.com>

Hi All,
I am having very high-frequency data, captured  between 3 to 7 seconds by
sensor for liquid tank and capacity of tank is 50k dm3. When tank capacity
reduce to 1k dm3, than tank refilling need to call.
How in time series we can perform, refilling can call when tank capacity
reduce to 1k dm3, and how to find 1k dm3 as threshold point and repeat the
process.

Please help me, how to approach and which kinds of algorithm required to
solve this problem using R/ python.

Thanks..

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Fri Jun  8 22:22:51 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 8 Jun 2018 13:22:51 -0700
Subject: [R] Calculating AIC and BIC for Time Series Models
In-Reply-To: <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>
References: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
 <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>
Message-ID: <18DFEF58-20A9-43FE-8663-3BA24D745F2C@comcast.net>


> On Jun 8, 2018, at 12:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 8, 2018, at 12:26 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
>> 
>> Dear friends,
>> 
>> I have been fitting some TS models from the forecast package like ets(),
>> ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
>> trying to use the AIC and BIC functions, I receive the following error
>> message:
>> 
>> Error in UseMethod("logLik") :
>> no applicable method for 'logLik' applied to an object of class "forecast"
>> 
>> Yes, the message is clear, those functions cannot be applied to objects
>> from the forecast class. However, I would like to know if there is a way to
>> assess the goodness of fit for this models that is somewhat equivalent to
>> AIC and BIC, or of there is any other function that could help me in the
>> model selection stage, other than computing MASE, MAPE, etc.
>> 
>> Any help and or guidance will be greatly appreciated.
>> 
>> 	[[alternative HTML version deleted]]
> 
> Fourth google hit on a search "goodness of fit measures for forecasts" by the author of hte forecast package:

https://pdfs.semanticscholar.org/af71/3d815a7caba8dff7248ecea05a5956b2a487.pdf

> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From bgunter@4567 @ending from gm@il@com  Sat Jun  9 01:29:35 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 8 Jun 2018 16:29:35 -0700
Subject: [R] Calculating AIC and BIC for Time Series Models
In-Reply-To: <18DFEF58-20A9-43FE-8663-3BA24D745F2C@comcast.net>
References: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
 <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>
 <18DFEF58-20A9-43FE-8663-3BA24D745F2C@comcast.net>
Message-ID: <CAGxFJbR5F0wHVOGVYYeMeWc-9MDGpcVUftEZQR8di03KxJ+0sQ@mail.gmail.com>

... Or have you looked here?

https://cran.r-project.org/web/views/TimeSeries.html

Bert

On Fri, Jun 8, 2018, 1:29 PM David Winsemius <dwinsemius at comcast.net> wrote:

>
> > On Jun 8, 2018, at 12:43 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> >> On Jun 8, 2018, at 12:26 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >>
> >> Dear friends,
> >>
> >> I have been fitting some TS models from the forecast package like ets(),
> >> ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
> >> trying to use the AIC and BIC functions, I receive the following error
> >> message:
> >>
> >> Error in UseMethod("logLik") :
> >> no applicable method for 'logLik' applied to an object of class
> "forecast"
> >>
> >> Yes, the message is clear, those functions cannot be applied to objects
> >> from the forecast class. However, I would like to know if there is a
> way to
> >> assess the goodness of fit for this models that is somewhat equivalent
> to
> >> AIC and BIC, or of there is any other function that could help me in the
> >> model selection stage, other than computing MASE, MAPE, etc.
> >>
> >> Any help and or guidance will be greatly appreciated.
> >>
> >>      [[alternative HTML version deleted]]
> >
> > Fourth google hit on a search "goodness of fit measures for forecasts"
> by the author of hte forecast package:
>
>
> https://pdfs.semanticscholar.org/af71/3d815a7caba8dff7248ecea05a5956b2a487.pdf
>
> >
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jrkride@u @ending from y@hoo@c@  Fri Jun  8 23:26:03 2018
From: jrkride@u @ending from y@hoo@c@ (John Kane)
Date: Fri, 8 Jun 2018 21:26:03 +0000 (UTC)
Subject: [R] How to threshold point in time series
In-Reply-To: <CAGYGU1cHcTUE=mg2rnyJwUo1Bf4fsACjUCdoQXk56s3wsFmpQg@mail.gmail.com>
References: <CAGYGU1cHcTUE=mg2rnyJwUo1Bf4fsACjUCdoQXk56s3wsFmpQg@mail.gmail.com>
Message-ID: <724210387.2564904.1528493163842@mail.yahoo.com>

 
Homework?
    On Friday, June 8, 2018, 4:20:40 p.m. EDT, Rama shankar <rcse2006 at gmail.com> wrote:  
 
 Hi All,
I am having very high-frequency data, captured? between 3 to 7 seconds by
sensor for liquid tank and capacity of tank is 50k dm3. When tank capacity
reduce to 1k dm3, than tank refilling need to call.
How in time series we can perform, refilling can call when tank capacity
reduce to 1k dm3, and how to find 1k dm3 as threshold point and repeat the
process.

Please help me, how to approach and which kinds of algorithm required to
solve this problem using R/ python.

Thanks..

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]


From jeremieju@te @ending from gm@il@com  Sat Jun  9 14:25:18 2018
From: jeremieju@te @ending from gm@il@com (Jeremie Juste)
Date: Sat, 09 Jun 2018 14:25:18 +0200
Subject: [R] 
 Calculate focal values for neighboring cells that are located
 at the raster edge from the function "focal" in the R package "raster"
In-Reply-To: <CAGxFJbRbwu0Oup4Tw1w4mu=CPDNNtFWK1=n5eGyL6PmaRvYEWA@mail.gmail.com>
 (Bert Gunter's message of "Fri, 8 Jun 2018 14:52:22 -0700")
References: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>
 <CAGxFJbRbwu0Oup4Tw1w4mu=CPDNNtFWK1=n5eGyL6PmaRvYEWA@mail.gmail.com>
Message-ID: <871sdgno41.fsf@gmail.com>


Hello,

>> I am using the function "focal" in the R package "raster" but I don?t
>> understand how the function calculates values for neighboring cells that
>> are located at the raster edge. Here is an example reproducible:

focal is a method for the S4 object RasterLayer. You can have access to
this method by using 

> findMethods("focal")

and you can trace the method by using
> trace(what='focal', tracer=browser, at=1, signature='RasterLayer')

HTH,

Jeremie






>> }
>>
>> r <- raster(ncol=3, nrow=3)
>> vals <- 1:ncell(r)
>> r <- setValues(r, vals)
>> plot(r)
>>
>> func_f  <- focal(r, w=matrix(1,nrow=3,ncol=3),
>>                    fun= func, pad = TRUE, padValue = NA)
>> text(func_f )
>> getValues(func_f)
>>
>>
>> From the example, I manage to find the value ?2.06066?:
>>
>> c <- 5
>>
>> (abs(1-c)*(1/sqrt(2)) + abs(2-c)*1 + abs(3-c)*(1/sqrt(2)) +
>>
>>   abs(4-c)*1 + abs(5-c)*0 + abs(6-c)*1 +
>>
>>   abs(7-c)*(1/sqrt(2)) + abs(8-c)*1 + abs(9-c)*(1/sqrt(2))) / 8
>>
>>
>>  but I don?t manage to find the value ?2.18566?. How can I find this value
>> ? In addition, why does the function with ?pad = TRUE? and without
>> ?pad=TRUE? give the same result ?
>>
>>  Thank you very much for your time.
>>
>> Have a nice day
>>
>> Marine
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code. Is
>> helpful is
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chri@tofer @ending from gm@il@com  Sun Jun 10 17:33:49 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sun, 10 Jun 2018 21:03:49 +0530
Subject: [R] Efficient manipulation with list object
Message-ID: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>

Hi,

I have a list of length 10,000, and each element of that list is a matrix
with 3 columns and 2,000 rows.

Now when I tried to make a Matrix object with that list using
Reduce('rbind', list), my code is taking a considerable amount of time.

Is there any way to implement same above task in more efficient way?

Thanks,

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Sun Jun 10 18:10:27 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Sun, 10 Jun 2018 19:10:27 +0300
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>
References: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>
Message-ID: <CAGgJW77Jr172=W7uX-xi1kv3eDSbQpqitoYBes0qXycjiST_iw@mail.gmail.com>

Try this. Suppose your list of matrices is in the list locL.

nc <- 3

locL2 <- list()
for ( i in 1:length(locL )
  locL2[[i]] <- as.numeric(t(locL[[i]]))

bigMat <- matrix(unlist(locL3), ncol=nc, byrow=TRUE)

HTH,
Eric


On Sun, Jun 10, 2018 at 6:33 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I have a list of length 10,000, and each element of that list is a matrix
> with 3 columns and 2,000 rows.
>
> Now when I tried to make a Matrix object with that list using
> Reduce('rbind', list), my code is taking a considerable amount of time.
>
> Is there any way to implement same above task in more efficient way?
>
> Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Sun Jun 10 18:11:49 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Sun, 10 Jun 2018 19:11:49 +0300
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CAGgJW77Jr172=W7uX-xi1kv3eDSbQpqitoYBes0qXycjiST_iw@mail.gmail.com>
References: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>
 <CAGgJW77Jr172=W7uX-xi1kv3eDSbQpqitoYBes0qXycjiST_iw@mail.gmail.com>
Message-ID: <CAGgJW74E_CacB7S0HYFZL4awWpWNRqhRvZ4PFZ4Qf_9MrWaE=A@mail.gmail.com>

Sorry typos

Try this. Suppose your list of matrices is in the list locL.

nc <- 3

locL2 <- list()
for ( i in 1:length(locL) )
  locL2[[i]] <- as.numeric( t( locL[[i]] ) )

bigMat <- matrix(unlist(locL2), ncol=nc, byrow=TRUE)

HTH,
Eric


On Sun, Jun 10, 2018 at 7:10 PM, Eric Berger <ericjberger at gmail.com> wrote:

> Try this. Suppose your list of matrices is in the list locL.
>
> nc <- 3
>
> locL2 <- list()
> for ( i in 1:length(locL )
>   locL2[[i]] <- as.numeric(t(locL[[i]]))
>
> bigMat <- matrix(unlist(locL3), ncol=nc, byrow=TRUE)
>
> HTH,
> Eric
>
>
> On Sun, Jun 10, 2018 at 6:33 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Hi,
>>
>> I have a list of length 10,000, and each element of that list is a matrix
>> with 3 columns and 2,000 rows.
>>
>> Now when I tried to make a Matrix object with that list using
>> Reduce('rbind', list), my code is taking a considerable amount of time.
>>
>> Is there any way to implement same above task in more efficient way?
>>
>> Thanks,
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From ruipb@rr@d@@ @ending from @@po@pt  Sun Jun 10 19:15:23 2018
From: ruipb@rr@d@@ @ending from @@po@pt (ruipbarradas)
Date: Sun, 10 Jun 2018 18:15:23 +0100
Subject: [R] Efficient manipulation with list object
Message-ID: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>

Hello,
Instead of Reduce try do.call.
do.call ('rbind', list)
But with such a long list it will still take time.
Hope this helps,
Rui Barradas?


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Christofer Bogaso <bogaso.christofer at gmail.com> Data: 10/06/2018  16:33  (GMT+00:00) Para: r-help <r-help at r-project.org> Assunto: [R] Efficient manipulation with list object 
Hi,

I have a list of length 10,000, and each element of that list is a matrix
with 3 columns and 2,000 rows.

Now when I tried to make a Matrix object with that list using
Reduce('rbind', list), my code is taking a considerable amount of time.

Is there any way to implement same above task in more efficient way?

Thanks,

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Sun Jun 10 21:20:45 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Mon, 11 Jun 2018 00:50:45 +0530
Subject: [R] Efficient manipulation with list object
In-Reply-To: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
References: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
Message-ID: <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>

Using do.call() reduces my calculation time significantly.

On Sun, Jun 10, 2018 at 10:45 PM ruipbarradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Instead of Reduce try do.call.
>
> do.call ('rbind', list)
>
> But with such a long list it will still take time.
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Enviado a partir do meu smartphone Samsung Galaxy.
> -------- Mensagem original --------
> De: Christofer Bogaso <bogaso.christofer at gmail.com>
> Data: 10/06/2018 16:33 (GMT+00:00)
> Para: r-help <r-help at r-project.org>
> Assunto: [R] Efficient manipulation with list object
>
> Hi,
>
> I have a list of length 10,000, and each element of that list is a matrix
> with 3 columns and 2,000 rows.
>
> Now when I tried to make a Matrix object with that list using
> Reduce('rbind', list), my code is taking a considerable amount of time.
>
> Is there any way to implement same above task in more efficient way?
>
> Thanks,
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From boennecd @ending from gm@il@com  Mon Jun 11 00:18:39 2018
From: boennecd @ending from gm@il@com (Benjamin Christoffersen)
Date: Mon, 11 Jun 2018 00:18:39 +0200
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>
References: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
 <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>
Message-ID: <CAHHSL8tjoKGnCyResRAr8SfwCzOg_xG_aM0tfhvpmrXn1RfyqA@mail.gmail.com>

You may be able to speed it up further by using `data.table`'s
`rbindlist` or a similar function as shown here
https://stackoverflow.com/a/49772719/5861244.

2018-06-10 21:20 GMT+02:00 Christofer Bogaso <bogaso.christofer at gmail.com>:
> Using do.call() reduces my calculation time significantly.
>
> On Sun, Jun 10, 2018 at 10:45 PM ruipbarradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Instead of Reduce try do.call.
>>
>> do.call ('rbind', list)
>>
>> But with such a long list it will still take time.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Enviado a partir do meu smartphone Samsung Galaxy.
>> -------- Mensagem original --------
>> De: Christofer Bogaso <bogaso.christofer at gmail.com>
>> Data: 10/06/2018 16:33 (GMT+00:00)
>> Para: r-help <r-help at r-project.org>
>> Assunto: [R] Efficient manipulation with list object
>>
>> Hi,
>>
>> I have a list of length 10,000, and each element of that list is a matrix
>> with 3 columns and 2,000 rows.
>>
>> Now when I tried to make a Matrix object with that list using
>> Reduce('rbind', list), my code is taking a considerable amount of time.
>>
>> Is there any way to implement same above task in more efficient way?
>>
>> Thanks,
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jun 11 08:53:53 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 10 Jun 2018 20:53:53 -1000
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CAHHSL8tjoKGnCyResRAr8SfwCzOg_xG_aM0tfhvpmrXn1RfyqA@mail.gmail.com>
References: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
 <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>
 <CAHHSL8tjoKGnCyResRAr8SfwCzOg_xG_aM0tfhvpmrXn1RfyqA@mail.gmail.com>
Message-ID: <6F8452A8-E3BB-49FD-8714-C0AB966F03DB@dcn.davis.ca.us>

The question was about matrices, not data frames or data tables. While faster than Reduce, the conversions still make it over twice as slow as Rui's answer.

On June 10, 2018 12:18:39 PM HST, Benjamin Christoffersen <boennecd at gmail.com> wrote:
>You may be able to speed it up further by using `data.table`'s
>`rbindlist` or a similar function as shown here
>https://stackoverflow.com/a/49772719/5861244.
>
>2018-06-10 21:20 GMT+02:00 Christofer Bogaso
><bogaso.christofer at gmail.com>:
>> Using do.call() reduces my calculation time significantly.
>>
>> On Sun, Jun 10, 2018 at 10:45 PM ruipbarradas <ruipbarradas at sapo.pt>
>wrote:
>>
>>> Hello,
>>>
>>> Instead of Reduce try do.call.
>>>
>>> do.call ('rbind', list)
>>>
>>> But with such a long list it will still take time.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>>> Enviado a partir do meu smartphone Samsung Galaxy.
>>> -------- Mensagem original --------
>>> De: Christofer Bogaso <bogaso.christofer at gmail.com>
>>> Data: 10/06/2018 16:33 (GMT+00:00)
>>> Para: r-help <r-help at r-project.org>
>>> Assunto: [R] Efficient manipulation with list object
>>>
>>> Hi,
>>>
>>> I have a list of length 10,000, and each element of that list is a
>matrix
>>> with 3 columns and 2,000 rows.
>>>
>>> Now when I tried to make a Matrix object with that list using
>>> Reduce('rbind', list), my code is taking a considerable amount of
>time.
>>>
>>> Is there any way to implement same above task in more efficient way?
>>>
>>> Thanks,
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From chettyvk @ending from gm@il@com  Mon Jun 11 20:26:32 2018
From: chettyvk @ending from gm@il@com (Veerappa Chetty)
Date: Mon, 11 Jun 2018 14:26:32 -0400
Subject: [R] Using MAP with a function returning a vector
Message-ID: <CAFpsATZTS-USTf2pGkWOJ8AcAtkx-JjgZOYneFe9jNvOB+rTww@mail.gmail.com>

Hi Experts,

The following codes work when the return value is a scalar.
 But I like to get the whole vector instead of one element of the vector x
using map  as a data frame instead getting one element of the vector using
of map_dbl.
In other words, I would like a data frame with one row for each iteration.
I would appreciate your help.
Thanks.
Chetty
__________________________________________
library(matlib)
v<-c(0.6,0.3,0.1,0.5,0.3,.2,0.1,0.2,0.8)
markov<-function(v){
nrow<-sqrt(length(v))
B<-matrix(v,nrow=nrow,byrow=TRUE)
A.sub<-t(B)[1:nrow-1,]-diag(nrow)[1:nrow-1,]
A<-rbind(A.sub,c(rep(1,nrow)))
b<-c(rep(0,nrow-1),1)
x<-solve(A,b)
x[2]
}
df<-data.frame(v.1=c(0.05,0.95,0.2,0.8),v.1=c(0.01,0.90,0.4,0.6))
df%>% map(~markov(v,v =.))
map_dbl(df,markov)
________________________________________

Professor of Family Medicine
Boston University
Tel: 617-414-6221, Fax:617-414-3345
emails: chettyvk at gmail.com,vchetty at bu.edu

	[[alternative HTML version deleted]]


From m@r@l@m@ck @ending from hotm@il@com  Mon Jun 11 21:35:15 2018
From: m@r@l@m@ck @ending from hotm@il@com (L... L...)
Date: Mon, 11 Jun 2018 19:35:15 +0000
Subject: [R] shaded area with polygon
Message-ID: <BY2PR20MB0453D2D4E8AED84B9EFC584B96780@BY2PR20MB0453.namprd20.prod.outlook.com>

Dear All, I know this is a trivial question .. but .. I want to shade the area between 2 curves. For example:

x <- 1:10

y <- 3*x^2 + 2*x + 7

z <- y + 100

plot(x, y,  type = 'l')

lines(x, z)

I can not understand polygon.

I tried

polygon(cbind(c(min(x), x, max(x)), c(min(y), z, max(y))), col="#00CC66")

But I do not return what I want.

Thank you very much

ML



	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Mon Jun 11 21:45:30 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 11 Jun 2018 12:45:30 -0700
Subject: [R] shaded area with polygon
In-Reply-To: <BY2PR20MB0453D2D4E8AED84B9EFC584B96780@BY2PR20MB0453.namprd20.prod.outlook.com>
References: <BY2PR20MB0453D2D4E8AED84B9EFC584B96780@BY2PR20MB0453.namprd20.prod.outlook.com>
Message-ID: <CAF8bMcYj8fMFNyaP-COLrAs7JRAWVPRsM_A5mh+9gjQH3kzqDA@mail.gmail.com>

Does
  polygon(c(x,rev(x)), c(y, rev(z)), col="orange")
do what you want?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 11, 2018 at 12:35 PM, L... L... <mar.lamack at hotmail.com> wrote:

> Dear All, I know this is a trivial question .. but .. I want to shade the
> area between 2 curves. For example:
>
> x <- 1:10
>
> y <- 3*x^2 + 2*x + 7
>
> z <- y + 100
>
> plot(x, y,  type = 'l')
>
> lines(x, z)
>
> I can not understand polygon.
>
> I tried
>
> polygon(cbind(c(min(x), x, max(x)), c(min(y), z, max(y))), col="#00CC66")
>
> But I do not return what I want.
>
> Thank you very much
>
> ML
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From p@ulbern@l07 @ending from gm@il@com  Mon Jun 11 23:15:44 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Mon, 11 Jun 2018 16:15:44 -0500
Subject: [R] Issues when Trying to Install Packages in R
Message-ID: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>

Dear friends,

I recently installed the following R version:

R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

However, when  trying to install package lubridate (it also happened when I
tried to install the forecast package), the following error message popped
up:

Error: package or namespace load failed for ?lubridate? in loadNamespace(i,
c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 there is no package called ?stringi?

Does anyone know how to solve this problem?

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Tue Jun 12 01:15:58 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Mon, 11 Jun 2018 19:15:58 -0400
Subject: [R] Issues when Trying to Install Packages in R
In-Reply-To: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>
References: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>
Message-ID: <fc3bf754-3d14-8a85-c80f-22a47c0cb085@gmail.com>

On 11/06/2018 5:15 PM, Paul Bernal wrote:
> Dear friends,
> 
> I recently installed the following R version:
> 
> R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> However, when  trying to install package lubridate (it also happened when I
> tried to install the forecast package), the following error message popped
> up:
> 
> Error: package or namespace load failed for ?lubridate? in loadNamespace(i,
> c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>   there is no package called ?stringi?
> 
> Does anyone know how to solve this problem?
> 

You need to install the stringi package first.  Normally that is done 
automatically, but sometimes suitable versions are not available, and it 
needs to be done manually.

Duncan Murdoch


From h@@@n@diw@n @ending from gm@il@com  Tue Jun 12 01:26:18 2018
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Mon, 11 Jun 2018 16:26:18 -0700
Subject: [R] Issues when Trying to Install Packages in R
In-Reply-To: <fc3bf754-3d14-8a85-c80f-22a47c0cb085@gmail.com>
References: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>
 <fc3bf754-3d14-8a85-c80f-22a47c0cb085@gmail.com>
Message-ID: <CAP+bYWCoNZ9ijFCjOWH_OaBWPpDGEEtpCngverwpFB3vUkAPLA@mail.gmail.com>

Paul,
install.packages('lubridate', type='source',
repos='https://cran.rstudio.com') # worked for me

You should be able to copy/paste the line into an R session. -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable


From reichm@nj @ending from @bcglob@l@net  Tue Jun 12 01:57:46 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Mon, 11 Jun 2018 18:57:46 -0500
Subject: [R] Changing selected columns to factor
Message-ID: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>

R-Help Forum

 

If I have a data frame consisting of say ten (10) variables
(A,B,C,D,E,F,G,H,I,J) and I want to change Variables 2,7,8,and 9 to factors
is there a command such that I can do it in one line or do I simply have to
convert each separately?

 

Jeff


	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Tue Jun 12 06:49:30 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 12 Jun 2018 14:49:30 +1000
Subject: [R] Changing selected columns to factor
In-Reply-To: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>
References: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>
Message-ID: <CA+8X3fVgD_SGHmRBnAB3Jjg1aJBntF6FEa7YajZd3McuyeSQSw@mail.gmail.com>

Hi Jeff,

jrdf<-data.frame(A=rnorm(10),B=rnorm(10),C=rnorm(10),
 D=rnorm(10),E=rnorm(10),F=rnorm(10),G=rnorm(10),
 H=rnorm(10),I=rnorm(10),J=rnorm(10))
for(i in c(2,7,8,9)) jrdf[,i]<-factor(jrdf[,i])
sapply(jrdf,"class")

Jim

On Tue, Jun 12, 2018 at 9:57 AM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> R-Help Forum
>
>
>
> If I have a data frame consisting of say ten (10) variables
> (A,B,C,D,E,F,G,H,I,J) and I want to change Variables 2,7,8,and 9 to factors
> is there a command such that I can do it in one line or do I simply have to
> convert each separately?
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From vc@vett @ending from @cripp@@edu  Tue Jun 12 01:39:58 2018
From: vc@vett @ending from @cripp@@edu (Valerie Cavett)
Date: Mon, 11 Jun 2018 23:39:58 +0000
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
Message-ID: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>

I?ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted?.  I?m happy to provide a sample binary file; even ones that are quite small (12 MB) generate this error. (I wasn?t sure whether a binary file attached to this email would trigger a spam filter.)

bin.read = file(files[i], "rb?)
datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little?)

Error: vector memory exhausted (limit reached?)


sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6


This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On?) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.

Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.

Any help, suggestions or workarounds are greatly appreciated!
Val

	[[alternative HTML version deleted]]


From luke-tier@ey m@ili@g off uiow@@edu  Tue Jun 12 11:26:37 2018
From: luke-tier@ey m@ili@g off uiow@@edu (luke-tier@ey m@ili@g off uiow@@edu)
Date: Tue, 12 Jun 2018 04:26:37 -0500 (CDT)
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>
Message-ID: <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>

This item in NEWS explains the change:

     ? The environment variable R_MAX_VSIZE can now be used to specify
       the maximal vector heap size. On macOS, unless specified by this
       environment variable, the maximal vector heap size is set to the
       maximum of 16GB and the available physical memory. This is to
       avoid having the R process killed when macOS over-commits memory.

You can set R_MAX_VSIZE to a larger value but you should do some
experimenting to decide on a safe value for your system. Mac OS is
quite good at using virtual memory up to a point but then gets very
bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
be killed, so a setting of around 60GB _might_ be safe.

File size probably doesn't matter in your example since you are
setting a large value for n - I can't tell how large since you didn't
provide your value of 'hertz'.

Best,

luke

On Mon, 11 Jun 2018, Valerie Cavett wrote:

> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.  I???m happy to provide a sample binary file; even ones that are quite small (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>
> bin.read = file(files[i], "rb???)
> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>
> Error: vector memory exhausted (limit reached?)
>
>
> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS Sierra 10.12.6
>
>
> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>
> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>
> Any help, suggestions or workarounds are greatly appreciated!
> Val
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From Bill@Poling @ending from zeli@@com  Tue Jun 12 14:00:34 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Tue, 12 Jun 2018 12:00:34 +0000
Subject: [R] Help installing the finalfit package
Message-ID: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning. Over the weekend I worked through this tutorial on bloggers.com at home where I am on 3.5.5:

#Elegant regression results tables and plots in R: the finalfit package

https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/

Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.

The tutorial ran splendidly at home but here at office, not so much, big smile.

> devtools::install_github("ewenharrison/finalfit")
Downloading GitHub repo ewenharrison/finalfit at master
from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master
Installing finalfit
Installing 1 package: mice
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
Content type 'application/zip' length 1490726 bytes (1.4 MB)
downloaded 1.4 MB

package 'mice' successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package 'mice'

The downloaded binary packages are in
        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
"C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
  "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests

ERROR: dependency 'mice' is not available for package 'finalfit'
* removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
In R CMD INSTALL
Installation failed: Command failed (1)

I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho'  etc... which I now load at the beginning of every session.

So my hunch is that maybe I need 3.5.5 for all this to work?

Also I have this error with the mice package:


> install.packages("mice")

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'

Content type 'application/zip' length 1490726 bytes (1.4 MB)

downloaded 1.4 MB



package 'mice' successfully unpacked and MD5 sums checked

Warning in install.packages :

  cannot remove prior installation of package 'mice'



The downloaded binary packages are in

        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages

> library(mice)

Error in library(mice) : there is no package called 'mice'


I would appreciate any suggestion please.

Thank you

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From vc@vett @ending from @cripp@@edu  Tue Jun 12 14:25:58 2018
From: vc@vett @ending from @cripp@@edu (Valerie Cavett)
Date: Tue, 12 Jun 2018 12:25:58 +0000
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
Message-ID: <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>

Thanks so much for taking a look at this.


Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.


Next, I tried to set a value with
Sys.setenv("R_MAX_VSIZE" = 8e9)


When the system environment is checked again, there is now a value of?
	R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09


Unfortunately, when I try to read in a small binary file, I still encounter the same error.?


I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:


	hertz <- 6000
	bin.read = file("20180611_A4", "rb")
	datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")


datavals is a large integer with 6046880 elements, 23.1 Mb.


If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.


However, if I switch back to the newest R version (3.5.0), I encounter the same error:


	> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
	Error: vector memory exhausted (limit reached?)


I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.


From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
Sent: Tuesday, June 12, 2018 5:26:37 AM
To: Valerie Cavett
Cc: r-help at R-project.org
Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
? 

This item in NEWS explains the change:

???? ? The environment variable R_MAX_VSIZE can now be used to specify
?????? the maximal vector heap size. On macOS, unless specified by this
?????? environment variable, the maximal vector heap size is set to the
?????? maximum of 16GB and the available physical memory. This is to
?????? avoid having the R process killed when macOS over-commits memory.

You can set R_MAX_VSIZE to a larger value but you should do some
experimenting to decide on a safe value for your system. Mac OS is
quite good at using virtual memory up to a point but then gets very
bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
be killed, so a setting of around 60GB _might_ be safe.

File size probably doesn't matter in your example since you are
setting a large value for n - I can't tell how large since you didn't
provide your value of 'hertz'.

Best,

luke

On Mon, 11 Jun 2018, Valerie Cavett wrote:

> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>
> bin.read = file(files[i], "rb???)
> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>
> Error: vector memory exhausted (limit reached?)
>
>
> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS Sierra 10.12.6
>
>
> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>
> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>
> Any help, suggestions or workarounds are greatly appreciated!
> Val
>
>??????? [[alternative HTML version deleted]]
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa????????????????? Phone:???????????? 319-335-3386
Department of Statistics and??????? Fax:?????????????? 319-335-3017
??? Actuarial Science
241 Schaeffer Hall????????????????? email:?? luke-tierney at uiowa.edu
Iowa City, IA 52242???????????????? WWW:? http://www.stat.uiowa.edu    

From m@@@imo@bre@@@n @ending from @rp@@veneto@it  Tue Jun 12 15:32:57 2018
From: m@@@imo@bre@@@n @ending from @rp@@veneto@it (Massimo Bressan)
Date: Tue, 12 Jun 2018 15:32:57 +0200 (CEST)
Subject: [R] extract and re-arrange components of data frame
Message-ID: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>

# considering this data.frame as a reproducible example 
d<-data.frame(i=c(1,2,3), s=c('97,98,99','103,105', '118'), stringsAsFactors = FALSE) 
d 

#I need to get this final result 
r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118)) 
r 

#this is my attempt 

#number of components for each element (3) of the list 
#returned by strsplit 
n<-unlist(lapply(strsplit(d$s,','), length)) 

#extract components of all elements of the list 
s<-cbind(unlist(strsplit(d$s,','))) 

#replicate each element of i 
#by the number of components of each element of the list 
i<-rep(d$i, n) 
i 

#compose final result 
r_final<-data.frame(i,s, stringsAsFactors = FALSE) 
r_final 

#I'm not much satisfied by the approach, it seems to me a bit clumsy... 

#any help for improving it? 
#thanks 
#a novice 



	[[alternative HTML version deleted]]


From luke-tier@ey m@ili@g off uiow@@edu  Tue Jun 12 16:14:07 2018
From: luke-tier@ey m@ili@g off uiow@@edu (luke-tier@ey m@ili@g off uiow@@edu)
Date: Tue, 12 Jun 2018 09:14:07 -0500 (CDT)
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
 <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
Message-ID: <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>

The environment variable R_MAX_VSIZE is read at start-up so need to be
set outside R. If you are starting R from a shell you can use

     env R_MAX_VSIZE=700Gb R

If you use a GUI you might need to set the variable in another
way.

Here is a reproducible version of your example:

     hertz <- 6000
     binfile <- tempfile()
     writeBin(1L, binfile, size = 2)
     v <- readBin(binfile, integer(), size = 2, n = 8*hertz*60*60000)
     unlink(binfile)

With the limit raised to 700Gb or more this will work in R 3.5.0
but you lose the protection of the lower default setting. You need a
value that high because your 'n' value is asking readBin to allocate a
buffer 643.7 Gb. Mac OS lets you allocate this much address space, as
long as you don't try to use all of it (this is memory
overcommitment). Running this example on a Linux system with 128Gb of
memory produces

     Error: cannot allocate vector of size 643.7 Gb

I suspect this will fail on pretty much any Windows system as well.

My recommendation would be to figure out a lower upper bound on the
number of elements to read, maybe using file.size, and use that for 'n'
in your readBin call. That will allow your code to be more portable
and avoid the risks of removing the allocation protection.

Best,

luke

On Tue, 12 Jun 2018, Valerie Cavett wrote:

> Thanks so much for taking a look at this.
> 

> Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.
> 

> Next, I tried to set a value with
> Sys.setenv("R_MAX_VSIZE" = 8e9)
>
>
> When the system environment is checked again, there is now a value of
?? 	R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09
>
>
> Unfortunately, when I try to read in a small binary file, I still encounter the same error.
??
>
> I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:
>
>
> 	hertz <- 6000
> 	bin.read = file("20180611_A4", "rb")
> 	datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>
>
> datavals is a large integer with 6046880 elements, 23.1 Mb.
>
>
> If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.
>
>
> However, if I switch back to the newest R version (3.5.0), I encounter the same error:
>
>
> 	> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
> 	Error: vector memory exhausted (limit reached?)
>
>
> I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.
>
>
> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Sent: Tuesday, June 12, 2018 5:26:37 AM
> To: Valerie Cavett
> Cc: r-help at R-project.org
> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
> 
??
> This item in NEWS explains the change:
>
> ???? ? The environment variable R_MAX_VSIZE can now be used to specify
> ?????? the maximal vector heap size. On macOS, unless specified by this
> ?????? environment variable, the maximal vector heap size is set to the
> ?????? maximum of 16GB and the available physical memory. This is to
> ?????? avoid having the R process killed when macOS over-commits memory.
>
> You can set R_MAX_VSIZE to a larger value but you should do some
> experimenting to decide on a safe value for your system. Mac OS is
> quite good at using virtual memory up to a point but then gets very
> bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
> be killed, so a setting of around 60GB _might_ be safe.
>
> File size probably doesn't matter in your example since you are
> setting a large value for n - I can't tell how large since you didn't
> provide your value of 'hertz'.
>
> Best,
>
> luke
>
> On Mon, 11 Jun 2018, Valerie Cavett wrote:
>
>> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>>
>> bin.read = file(files[i], "rb???)
>> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>>
>> Error: vector memory exhausted (limit reached?)
>>
>>
>> sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>> Running under: macOS Sierra 10.12.6
>>
>>
>> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>>
>> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>>
>> Any help, suggestions or workarounds are greatly appreciated!
>> Val
>>
>> ??????? [[alternative HTML version deleted]]
>>
>>
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From bgunter@4567 @ending from gm@il@com  Tue Jun 12 16:42:18 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 12 Jun 2018 07:42:18 -0700
Subject: [R] extract and re-arrange components of data frame
In-Reply-To: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
References: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAGxFJbThzkjKHsjnMWhArOu6YPom=XBQU2EM_P9EcAybUKFaXw@mail.gmail.com>

You mean like this?

> s.new <-with(d, as.numeric(unlist(strsplit(s,","))))

> s.new <- cut(s.new,breaks = c(0,100,110,200),lab = d$i)

> s.new
[1] 1 1 1 2 2 3
Levels: 1 2 3

(Obviously, this could be a one-liner)

See ?cut

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jun 12, 2018 at 6:32 AM, Massimo Bressan <
massimo.bressan at arpa.veneto.it> wrote:

> # considering this data.frame as a reproducible example
> d<-data.frame(i=c(1,2,3), s=c('97,98,99','103,105', '118'),
> stringsAsFactors = FALSE)
> d
>
> #I need to get this final result
> r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118))
> r
>
> #this is my attempt
>
> #number of components for each element (3) of the list
> #returned by strsplit
> n<-unlist(lapply(strsplit(d$s,','), length))
>
> #extract components of all elements of the list
> s<-cbind(unlist(strsplit(d$s,',')))
>
> #replicate each element of i
> #by the number of components of each element of the list
> i<-rep(d$i, n)
> i
>
> #compose final result
> r_final<-data.frame(i,s, stringsAsFactors = FALSE)
> r_final
>
> #I'm not much satisfied by the approach, it seems to me a bit clumsy...
>
> #any help for improving it?
> #thanks
> #a novice
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From S@Elli@on @ending from LGCGroup@com  Tue Jun 12 17:13:01 2018
From: S@Elli@on @ending from LGCGroup@com (S Ellison)
Date: Tue, 12 Jun 2018 15:13:01 +0000
Subject: [R] extract and re-arrange components of data frame
In-Reply-To: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
References: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <6f7a59eadc674b2582fc3f6e983f8d56@GBDCVPEXC08.corp.lgc-group.com>

> #I need to get this final result
> r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118))

Nothing magic to suggest.

But maybe:

list.s <- strsplit(d$s,",")
r <- data.frame(i=rep(d$i, times=sapply(list.s, length)), s=unlist(list.s), stringsAsFactors=FALSE )

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From m@@@imo@bre@@@n @ending from @rp@@veneto@it  Tue Jun 12 17:07:27 2018
From: m@@@imo@bre@@@n @ending from @rp@@veneto@it (Massimo Bressan)
Date: Tue, 12 Jun 2018 17:07:27 +0200 (CEST)
Subject: [R] extract and re-arrange components of data frame
In-Reply-To: <CAGxFJbThzkjKHsjnMWhArOu6YPom=XBQU2EM_P9EcAybUKFaXw@mail.gmail.com>
References: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
 <CAGxFJbThzkjKHsjnMWhArOu6YPom=XBQU2EM_P9EcAybUKFaXw@mail.gmail.com>
Message-ID: <102419610.10371312.1528816047729.JavaMail.zimbra@arpa.veneto.it>

thank you for your reply 

well, you are resorting to a supposed order of i which is not necessary the case, and in fact is not in mine... 

consider this example, please 

d<-data.frame(i=c(8,12,3), s=c('97,918,19','103,1205', '418'), stringsAsFactors = FALSE) 
d 


Da: "Bert Gunter" <bgunter.4567 at gmail.com> 
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
Cc: "r-help" <R-help at r-project.org> 
Inviato: Marted?, 12 giugno 2018 16:42:18 
Oggetto: Re: [R] extract and re-arrange components of data frame 

You mean like this? 

> s.new <-with(d, as.numeric(unlist(strsplit(s,",")))) 

> s.new <- cut(s.new,breaks = c(0,100,110,200),lab = d$i) 

> s.new 
[1] 1 1 1 2 2 3 
Levels: 1 2 3 

(Obviously, this could be a one-liner) 

See ?cut 

Cheers, 
Bert 





Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Tue, Jun 12, 2018 at 6:32 AM, Massimo Bressan < massimo.bressan at arpa.veneto.it > wrote: 


# considering this data.frame as a reproducible example 
d<-data.frame(i=c(1,2,3), s=c('97,98,99','103,105', '118'), stringsAsFactors = FALSE) 
d 

#I need to get this final result 
r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118)) 
r 

#this is my attempt 

#number of components for each element (3) of the list 
#returned by strsplit 
n<-unlist(lapply(strsplit(d$s,','), length)) 

#extract components of all elements of the list 
s<-cbind(unlist(strsplit(d$s,','))) 

#replicate each element of i 
#by the number of components of each element of the list 
i<-rep(d$i, n) 
i 

#compose final result 
r_final<-data.frame(i,s, stringsAsFactors = FALSE) 
r_final 

#I'm not much satisfied by the approach, it seems to me a bit clumsy... 

#any help for improving it? 
#thanks 
#a novice 



[[alternative HTML version deleted]] 

______________________________________________ 
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 





	[[alternative HTML version deleted]]


From wetering @ending from pum@edu@pl  Tue Jun 12 14:05:31 2018
From: wetering @ending from pum@edu@pl (Thierry van de Wetering)
Date: Tue, 12 Jun 2018 14:05:31 +0200
Subject: [R] SNPassoc association and weights
Message-ID: <51bab0d8-f831-41c1-5054-f64b87f4ab66@pum.edu.pl>

Dear Reader,

Please can you tell me how to use weights with the SNPassoc package 
function association.

association(NEB~recessive(rs178012)*as.factor(GENDER), weights = 
as.factor(WAGA), data=dat2SNP)

SNP: recessive(rs178012 adjusted by: Interaction --------------------- 1 
dif lower upper 2 dif lower upper G/G-A/G 1485 1.451 0.03814 0.0000 NA 
NA 1702 1.854 0.03879 0.4025 0.2946 0.5105 A/A 11 1.091 0.45636 -0.3603 
-1.28 0.5599 20 1.900 0.62786 0.4488 -0.2356 1.1333 p interaction: 0.48707


In this example I want to know if there is an interaction between GENDER 
and the SNP in assocation with NEB, weighted for WAGA. Removal of the 
weights argument gives exactly the same p.value.

association(NEB~recessive(rs178012)*as.factor(GENDER), data=dat2SNP)

SNP: recessive(rs178012 adjusted by: Interaction --------------------- 1 
dif lower upper 2 dif lower upper G/G-A/G 1485 1.451 0.03814 0.0000 NA 
NA 1702 1.854 0.03879 0.4025 0.2946 0.5105 A/A 11 1.091 0.45636 -0.3603 
-1.28 0.5599 20 1.900 0.62786 0.4488 -0.2356 1.1333 p interaction: 0.48707



Changing the model from recessive into for example dominant gives me 
other p interactions and p.values, but still the weighting is not giving 
any differences.

Many thanks in advance.
Your sincerely

-- 
Thierry


	[[alternative HTML version deleted]]


From vc@vett @ending from @cripp@@edu  Tue Jun 12 21:02:49 2018
From: vc@vett @ending from @cripp@@edu (Valerie Cavett)
Date: Tue, 12 Jun 2018 19:02:49 +0000
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
 <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>
Message-ID: <BN6PR11MB19867C53B6D61E8F61791448BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>

Ah - I see the problem - thanks so much for the clarification!

Just in case anyone else is using Rstudio on a mac and runs into this issue, I ended up following the instructions from
http://btibert3.github.io/2015/12/08/Environment-Variables-in-Rstudio-on-Mac.html

to add the following line to the .Renviron file:
R_MAX_VSIZE=700Gb

On restart (R 3.5.0), this did the trick and the files read normally.

Thanks again for all the assistance!
Val




From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
Sent: Tuesday, June 12, 2018 10:14 AM
To: Valerie Cavett
Cc: r-help at R-project.org
Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
? 

The environment variable R_MAX_VSIZE is read at start-up so need to be
set outside R. If you are starting R from a shell you can use

???? env R_MAX_VSIZE=700Gb R

If you use a GUI you might need to set the variable in another
way.

Here is a reproducible version of your example:

???? hertz <- 6000
???? binfile <- tempfile()
???? writeBin(1L, binfile, size = 2)
???? v <- readBin(binfile, integer(), size = 2, n = 8*hertz*60*60000)
???? unlink(binfile)

With the limit raised to 700Gb or more this will work in R 3.5.0
but you lose the protection of the lower default setting. You need a
value that high because your 'n' value is asking readBin to allocate a
buffer 643.7 Gb. Mac OS lets you allocate this much address space, as
long as you don't try to use all of it (this is memory
overcommitment). Running this example on a Linux system with 128Gb of
memory produces

???? Error: cannot allocate vector of size 643.7 Gb

I suspect this will fail on pretty much any Windows system as well.

My recommendation would be to figure out a lower upper bound on the
number of elements to read, maybe using file.size, and use that for 'n'
in your readBin call. That will allow your code to be more portable
and avoid the risks of removing the allocation protection.

Best,

luke

On Tue, 12 Jun 2018, Valerie Cavett wrote:

> Thanks so much for taking a look at this.
> 

> Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.
> 

> Next, I tried to set a value with
> Sys.setenv("R_MAX_VSIZE" = 8e9)
>
>
> When the system environment is checked again, there is now a value of
???????? R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09
>
>
> Unfortunately, when I try to read in a small binary file, I still encounter the same error.
??
>
> I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:
>
>
>??????? hertz <- 6000
>??????? bin.read = file("20180611_A4", "rb")
>??????? datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>
>
> datavals is a large integer with 6046880 elements, 23.1 Mb.
>
>
> If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.
>
>
> However, if I switch back to the newest R version (3.5.0), I encounter the same error:
>
>
>??????? > datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>??????? Error: vector memory exhausted (limit reached?)
>
>
> I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.
>
>
> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Sent: Tuesday, June 12, 2018 5:26:37 AM
> To: Valerie Cavett
> Cc: r-help at R-project.org
> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
> 
??
> This item in NEWS explains the change:
>
> ???? ? The environment variable R_MAX_VSIZE can now be used to specify
> ?????? the maximal vector heap size. On macOS, unless specified by this
> ?????? environment variable, the maximal vector heap size is set to the
> ?????? maximum of 16GB and the available physical memory. This is to
> ?????? avoid having the R process killed when macOS over-commits memory.
>
> You can set R_MAX_VSIZE to a larger value but you should do some
> experimenting to decide on a safe value for your system. Mac OS is
> quite good at using virtual memory up to a point but then gets very
> bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
> be killed, so a setting of around 60GB _might_ be safe.
>
> File size probably doesn't matter in your example since you are
> setting a large value for n - I can't tell how large since you didn't
> provide your value of 'hertz'.
>
> Best,
>
> luke
>
> On Mon, 11 Jun 2018, Valerie Cavett wrote:
>
>> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small?  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>>
>> bin.read = file(files[i], "rb???)
>> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>>
>> Error: vector memory exhausted (limit reached?)
>>
>>
>> sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>> Running under: macOS Sierra 10.12.6
>>
>>
>> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>>
>> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>>
>> Any help, suggestions or workarounds are greatly appreciated!
>> Val
>>
>> ??????? [[alternative HTML version deleted]]
>>
>>
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa????????????????? Phone:???????????? 319-335-3386
Department of Statistics and??????? Fax:?????????????? 319-335-3017
??? Actuarial Science
241 Schaeffer Hall????????????????? email:?? luke-tierney at uiowa.edu
Iowa City, IA 52242???????????????? WWW:? http://www.stat.uiowa.edu    

From luke-tier@ey m@ili@g off uiow@@edu  Tue Jun 12 23:06:09 2018
From: luke-tier@ey m@ili@g off uiow@@edu (luke-tier@ey m@ili@g off uiow@@edu)
Date: Tue, 12 Jun 2018 16:06:09 -0500 (CDT)
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <BN6PR11MB19867C53B6D61E8F61791448BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
 <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>
 <BN6PR11MB19867C53B6D61E8F61791448BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
Message-ID: <alpine.OSX.2.21.1806121558570.1839@lukes-macbook-air.local>

On Tue, 12 Jun 2018, Valerie Cavett wrote:

> Ah - I see the problem - thanks so much for the clarification!
>
> Just in case anyone else is using Rstudio on a mac and runs into this issue, I ended up following the instructions from
> http://btibert3.github.io/2015/12/08/Environment-Variables-in-Rstudio-on-Mac.html
>
> to add the following line to the .Renviron file:
> R_MAX_VSIZE=700Gb
>

And, also for the record, I advise not to do this. It may be an
adequate quick fix for your setting for now, but it loses the
protection the default provides, and it means your code will only work
on a Linux or Windows system with well above half a terabyte of
memory.

Best,

luke

> On restart (R 3.5.0), this did the trick and the files read normally.
>
> Thanks again for all the assistance!
> Val
>
>
>
>
> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Sent: Tuesday, June 12, 2018 10:14 AM
> To: Valerie Cavett
> Cc: r-help at R-project.org
> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
> 
??
> The environment variable R_MAX_VSIZE is read at start-up so need to be
> set outside R. If you are starting R from a shell you can use
>
> ???? env R_MAX_VSIZE=700Gb R
>
> If you use a GUI you might need to set the variable in another
> way.
>
> Here is a reproducible version of your example:
>
> ???? hertz <- 6000
> ???? binfile <- tempfile()
> ???? writeBin(1L, binfile, size = 2)
> ???? v <- readBin(binfile, integer(), size = 2, n = 8*hertz*60*60000)
> ???? unlink(binfile)
>
> With the limit raised to 700Gb or more this will work in R 3.5.0
> but you lose the protection of the lower default setting. You need a
> value that high because your 'n' value is asking readBin to allocate a
> buffer 643.7 Gb. Mac OS lets you allocate this much address space, as
> long as you don't try to use all of it (this is memory
> overcommitment). Running this example on a Linux system with 128Gb of
> memory produces
>
> ???? Error: cannot allocate vector of size 643.7 Gb
>
> I suspect this will fail on pretty much any Windows system as well.
>
> My recommendation would be to figure out a lower upper bound on the
> number of elements to read, maybe using file.size, and use that for 'n'
> in your readBin call. That will allow your code to be more portable
> and avoid the risks of removing the allocation protection.
>
> Best,
>
> luke
>
> On Tue, 12 Jun 2018, Valerie Cavett wrote:
>
>> Thanks so much for taking a look at this.
>> 

>> Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.
>> 

>> Next, I tried to set a value with
>> Sys.setenv("R_MAX_VSIZE" = 8e9)
>>
>>
>> When the system environment is checked again, there is now a value of
> ???????? R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09
>>
>>
>> Unfortunately, when I try to read in a small binary file, I still encounter the same error.
> ??
>>
>> I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:
>>
>>
>> ??????? hertz <- 6000
>> ??????? bin.read = file("20180611_A4", "rb")
>> ??????? datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>>
>>
>> datavals is a large integer with 6046880 elements, 23.1 Mb.
>>
>>
>> If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.
>>
>>
>> However, if I switch back to the newest R version (3.5.0), I encounter the same error:
>>
>>
>> ??????? > datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>> ??????? Error: vector memory exhausted (limit reached?)
>>
>>
>> I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.
>>
>>
>> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
>> Sent: Tuesday, June 12, 2018 5:26:37 AM
>> To: Valerie Cavett
>> Cc: r-help at R-project.org
>> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
>>
> ??
>> This item in NEWS explains the change:
>>
>> ???? ? The environment variable R_MAX_VSIZE can now be used to specify
>> ?????? the maximal vector heap size. On macOS, unless specified by this
>> ?????? environment variable, the maximal vector heap size is set to the
>> ?????? maximum of 16GB and the available physical memory. This is to
>> ?????? avoid having the R process killed when macOS over-commits memory.
>>
>> You can set R_MAX_VSIZE to a larger value but you should do some
>> experimenting to decide on a safe value for your system. Mac OS is
>> quite good at using virtual memory up to a point but then gets very
>> bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
>> be killed, so a setting of around 60GB _might_ be safe.
>>
>> File size probably doesn't matter in your example since you are
>> setting a large value for n - I can't tell how large since you didn't
>> provide your value of 'hertz'.
>>
>> Best,
>>
>> luke
>>
>> On Mon, 11 Jun 2018, Valerie Cavett wrote:
>>
>>> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small?  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>>>
>>> bin.read = file(files[i], "rb???)
>>> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>>>
>>> Error: vector memory exhausted (limit reached?)
>>>
>>>
>>> sessionInfo()
>>> R version 3.5.0 (2018-04-23)
>>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>>> Running under: macOS Sierra 10.12.6
>>>
>>>
>>> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>>>
>>> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>>>
>>> Any help, suggestions or workarounds are greatly appreciated!
>>> Val
>>>
>>> ??????? [[alternative HTML version deleted]]
>>>
>>>
>>
>>
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From reichm@nj @ending from @bcglob@l@net  Wed Jun 13 04:19:06 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Tue, 12 Jun 2018 21:19:06 -0500
Subject: [R] Changing selected columns to factor
In-Reply-To: <CA+8X3fVgD_SGHmRBnAB3Jjg1aJBntF6FEa7YajZd3McuyeSQSw@mail.gmail.com>
References: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>
 <CA+8X3fVgD_SGHmRBnAB3Jjg1aJBntF6FEa7YajZd3McuyeSQSw@mail.gmail.com>
Message-ID: <000001d402bc$e7f33550$b7d99ff0$@sbcglobal.net>

Well that?s easy enough - thank you

-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com> 
Sent: Monday, June 11, 2018 11:50 PM
To: Jeff Reichman <reichmanj at sbcglobal.net>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Changing selected columns to factor

Hi Jeff,

jrdf<-data.frame(A=rnorm(10),B=rnorm(10),C=rnorm(10),
 D=rnorm(10),E=rnorm(10),F=rnorm(10),G=rnorm(10),
 H=rnorm(10),I=rnorm(10),J=rnorm(10))
for(i in c(2,7,8,9)) jrdf[,i]<-factor(jrdf[,i])
sapply(jrdf,"class")

Jim

On Tue, Jun 12, 2018 at 9:57 AM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> R-Help Forum
>
>
>
> If I have a data frame consisting of say ten (10) variables
> (A,B,C,D,E,F,G,H,I,J) and I want to change Variables 2,7,8,and 9 to 
> factors is there a command such that I can do it in one line or do I 
> simply have to convert each separately?
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From dwin@emiu@ @ending from comc@@t@net  Wed Jun 13 06:47:35 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Tue, 12 Jun 2018 21:47:35 -0700
Subject: [R] Help installing the finalfit package
In-Reply-To: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>


> On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> Good morning. Over the weekend I worked through this tutorial on bloggers.com at home where I am on 3.5.5:
> 
> #Elegant regression results tables and plots in R: the finalfit package
> 
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
> 
> Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
> 
> The tutorial ran splendidly at home but here at office, not so much, big smile.
> 
>> devtools::install_github("ewenharrison/finalfit")
> Downloading GitHub repo ewenharrison/finalfit at master
> from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master
> Installing finalfit
> Installing 1 package: mice
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
> downloaded 1.4 MB
> 
> package 'mice' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'mice'

Generally the first task is to address the first error, which in this case appears to be a windows permission issue.

-- 
David


> 
> The downloaded binary packages are in
>        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
>  "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
> 
> ERROR: dependency 'mice' is not available for package 'finalfit'
> * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> In R CMD INSTALL
> Installation failed: Command failed (1)
> 
> I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho'  etc... which I now load at the beginning of every session.
> 
> So my hunch is that maybe I need 3.5.5 for all this to work?
> 
> Also I have this error with the mice package:
> 
> 
>> install.packages("mice")
> 
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> 
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
> 
> downloaded 1.4 MB
> 
> 
> 
> package 'mice' successfully unpacked and MD5 sums checked
> 
> Warning in install.packages :
> 
>  cannot remove prior installation of package 'mice'
> 
> 
> 
> The downloaded binary packages are in
> 
>        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> 
>> library(mice)
> 
> Error in library(mice) : there is no package called 'mice'
> 
> 
> I would appreciate any suggestion please.
> 
> Thank you
> 
> WHP
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From STuck @ending from nz@uperfund@co@nz  Wed Jun 13 04:33:41 2018
From: STuck @ending from nz@uperfund@co@nz (Sam Tuck)
Date: Wed, 13 Jun 2018 02:33:41 +0000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
Message-ID: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>

Hi All,
          I am new to R and am wondering if there is a way to pass arguments between rscripts.  I have this working but have had to create a C# shell calling the scripts in sequence via windows scripting which enables command line arguments to get the necessary interaction.  

I'm wondering if I'm using an outdated program construction technique - I create r files like I would programme functions or reoccurring code snippets in C.  It may be that r was not designed to create lots of little r script modules that interact via a master script? 

Ideally I'd like to call r scripts from other r scripts and have all the variables still in memory: For example

I've been using RStudio Version 1.1.447 to programme and regression test my individual scripts,. 

Script Arg Script.R
{
# We are going to pass arguments into this script
arguments <- commandArgs(trailingOnly = TRUE)
#arguments[1] is double
#arguments[2] is double
#arguments[3] is double.
if(length(arguments) <3) 
{
  stop("Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter")
}
TotalDeviation <- as.numeric(arguments[1])/100
IndividualDeviation <- as.numeric(arguments[2])/100
RecenterPeriods <- as.numeric(arguments[3])
# We then manipulate some objects based on these inputs, but for this test we will output them to a file. 
fileConn<-file("output.txt")
writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods), fileConn)
close(fileConn)
}
Script RunningScript.R
{
Arg Script.R 0.6 0.4 132
}

To which I get
Error: unexpected symbol in " Arg Script.R"

When I use the script RunningScript.R
{
system(paste("Arg Script.R", 0.8, 0.4, 132))
}
Nothing occurs (there is no output file created, but also no error)

When I use RunningScript.R
{
commandArgs <- c(0.6,0.4,132)
source("Arg Script.R')
}
I don't get any args passed into the file.  Instead getting the error 
Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter

Thanks

Sam Tuck 


From @k@h@y_e4 @ending from hotm@il@com  Wed Jun 13 07:36:40 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Wed, 13 Jun 2018 05:36:40 +0000
Subject: [R] on execution time of a function...
Message-ID: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

I ran  a function in R three days ago and the execution time was about 4 minutes. I ran the same function yesterday and the execution time was more than 6:50 minutes(I aborted the function after that time).

I read in the Internet that this is possible. I also came to know that software or hardware interrupts are the main reasons.

How do you know whether the delay was caused by interrupts? Which hardware or software triggered the interrupts? In general, how to know the exact cause of the delay in execution in R? Are there any packages for these analyses?

Very many thanks for your time and effort....

yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From Sh@keel@Sulem@n @ending from phe@gov@uk  Wed Jun 13 09:05:55 2018
From: Sh@keel@Sulem@n @ending from phe@gov@uk (Shakeel Suleman)
Date: Wed, 13 Jun 2018 07:05:55 +0000
Subject: [R] Tables in Rmarkdown Word
Message-ID: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>

I am relatively new to R and was wondering if someone could advise me on presenting tables in R Markdown for Word. I would like to present a simple table of counts, with column 1 representing name of an organisation (and last row called "All organisations") and another four columns representing the most recent four week period (e.g. week 21, 22, 23, 24) and a final total column, as illustrated below. The actual data is just counts (e.g. 4, 5, 8, widgets produced, number of people off sick etc).

My question is: can this be done to a publication quality standard. I have tried Pander, but that adds "Sum" instead of All Organisations and 4 Week Total and doesn't look particularly good.



Week



20

21

22

23

4 week total

Organisation

6

6

1

1

14

ABC

2

4

1

5

12

DCE

0

5

1

5

11

EFG

3

6

3

5

17

HIJ

1

8

3

2

14

All Organizations

12

29

9

18

68



Kind regards,

Shakeel


**************************************************************************
The information contained in the EMail and any attachments is confidential and intended solely and for the attention and use of the named addressee(s). It may not be disclosed to any other person without the express authority of Public Health England, or the intended recipient, or both. If you are not the intended recipient, you must not disclose, copy, distribute or retain this message or any part of it. This footnote also confirms that this EMail has been swept for computer viruses by Symantec.Cloud, but please re-sweep any attachments before opening or saving. http://www.gov.uk/PHE
**************************************************************************
	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Wed Jun 13 09:09:21 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Wed, 13 Jun 2018 10:09:21 +0300
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
Message-ID: <CAGgJW756Hm1EPa_Bvp8YoqjkjZbvU_NRNPmxOOZDZpUcu-1nTg@mail.gmail.com>

Hi Sam,
I use the littler package for scripting. You may find it meets your needs.

https://github.com/eddelbuettel/littler

HTH,
Eric


On Wed, Jun 13, 2018 at 5:33 AM, Sam Tuck <STuck at nzsuperfund.co.nz> wrote:

> Hi All,
>           I am new to R and am wondering if there is a way to pass
> arguments between rscripts.  I have this working but have had to create a
> C# shell calling the scripts in sequence via windows scripting which
> enables command line arguments to get the necessary interaction.
>
> I'm wondering if I'm using an outdated program construction technique - I
> create r files like I would programme functions or reoccurring code
> snippets in C.  It may be that r was not designed to create lots of little
> r script modules that interact via a master script?
>
> Ideally I'd like to call r scripts from other r scripts and have all the
> variables still in memory: For example
>
> I've been using RStudio Version 1.1.447 to programme and regression test
> my individual scripts,.
>
> Script Arg Script.R
> {
> # We are going to pass arguments into this script
> arguments <- commandArgs(trailingOnly = TRUE)
> #arguments[1] is double
> #arguments[2] is double
> #arguments[3] is double.
> if(length(arguments) <3)
> {
>   stop("Not enough arguments, please supply 3, [% dbl}total deviation, [%
> dbl] individual deviation, [int] periods before recenter")
> }
> TotalDeviation <- as.numeric(arguments[1])/100
> IndividualDeviation <- as.numeric(arguments[2])/100
> RecenterPeriods <- as.numeric(arguments[3])
> # We then manipulate some objects based on these inputs, but for this test
> we will output them to a file.
> fileConn<-file("output.txt")
> writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
> fileConn)
> close(fileConn)
> }
> Script RunningScript.R
> {
> Arg Script.R 0.6 0.4 132
> }
>
> To which I get
> Error: unexpected symbol in " Arg Script.R"
>
> When I use the script RunningScript.R
> {
> system(paste("Arg Script.R", 0.8, 0.4, 132))
> }
> Nothing occurs (there is no output file created, but also no error)
>
> When I use RunningScript.R
> {
> commandArgs <- c(0.6,0.4,132)
> source("Arg Script.R')
> }
> I don't get any args passed into the file.  Instead getting the error
> Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl]
> individual deviation, [int] periods before recenter
>
> Thanks
>
> Sam Tuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jun 13 09:53:57 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 12 Jun 2018 21:53:57 -1000
Subject: [R] on execution time of a function...
In-Reply-To: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>

Wow, you can find almost any explanation on the Internets. That doesn't mean you should believe all of them. R does not do anything likely to tweak interrupts... if that is your problem then you need to be on an operating-system/computer-model-specific forum rather than this OS-agnostic mailing list.

It is far more likely that your overall memory usage conditions have changed since the last time you ran it... or that you didn't actually record all of the things you did last time in your script. (Newbie R users often do things at the console without putting them in their scripts.)

I suggest that you run your script one statement at a time and see where your problem is. You might also want to make sure that other programs are not using up a lot of your memory (which could involve some OS-specific tools or just shutting down some other programs.)

On June 12, 2018 7:36:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>I ran  a function in R three days ago and the execution time was about
>4 minutes. I ran the same function yesterday and the execution time was
>more than 6:50 minutes(I aborted the function after that time).
>
>I read in the Internet that this is possible. I also came to know that
>software or hardware interrupts are the main reasons.
>
>How do you know whether the delay was caused by interrupts? Which
>hardware or software triggered the interrupts? In general, how to know
>the exact cause of the delay in execution in R? Are there any packages
>for these analyses?
>
>Very many thanks for your time and effort....
>
>yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From lori@@bennett @ending from fu-berlin@de  Wed Jun 13 10:07:38 2018
From: lori@@bennett @ending from fu-berlin@de (Loris Bennett)
Date: Wed, 13 Jun 2018 10:07:38 +0200
Subject: [R] on execution time of a function...
In-Reply-To: <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us> (Jeff
 Newmiller's message of "Tue, 12 Jun 2018 21:53:57 -1000")
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>
Message-ID: <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>

Hi Akshay,

In addition to all the things Jeff rightly points out, contention for IO
resources can be an issue.  So if another process was hogging the
bandwidth while your program was attempting to read or write to disk,
that could also have slowed things down.

HTH

Loris

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

> Wow, you can find almost any explanation on the Internets. That doesn't mean you
> should believe all of them. R does not do anything likely to tweak
> interrupts... if that is your problem then you need to be on an
> operating-system/computer-model-specific forum rather than this OS-agnostic
> mailing list.
>
> It is far more likely that your overall memory usage conditions have changed
> since the last time you ran it... or that you didn't actually record all of the
> things you did last time in your script. (Newbie R users often do things at the
> console without putting them in their scripts.)
>
> I suggest that you run your script one statement at a time and see where your
> problem is. You might also want to make sure that other programs are not using
> up a lot of your memory (which could involve some OS-specific tools or just
> shutting down some other programs.)
>
> On June 12, 2018 7:36:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>>I ran  a function in R three days ago and the execution time was about
>>4 minutes. I ran the same function yesterday and the execution time was
>>more than 6:50 minutes(I aborted the function after that time).
>>
>>I read in the Internet that this is possible. I also came to know that
>>software or hardware interrupts are the main reasons.
>>
>>How do you know whether the delay was caused by interrupts? Which
>>hardware or software triggered the interrupts? In general, how to know
>>the exact cause of the delay in execution in R? Are there any packages
>>for these analyses?
>>
>>Very many thanks for your time and effort....
>>
>>yours sincerely,
>>AKSHAY M KULKARNI
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de


From @k@h@y_e4 @ending from hotm@il@com  Wed Jun 13 11:39:40 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Wed, 13 Jun 2018 09:39:40 +0000
Subject: [R] on execution time of a function...
In-Reply-To: <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>,
 <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <SL2P216MB0091615418967B977F2B4876C87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

I do felt a little unsettled by your exhortions on the incongruity of posting this question on an OS-agnostic mailing list...I thought that there might be some issues on how R communicates with the OS...and also that some R packages might rectify the issue(in my experience, I have had a R package for every R issue that I had!)

Anyway, I ran the  same function again and it is executing within limits. Also, I would be using AWS EC2 servers to run my R functions(I am a day trader in india and input some 250 stocks to R functions daily), and I don't think that the issue would persist on Intel Xeon processors and dedicated VMs....

Anyway,thanks for all your concerns tolerating my query on an OS-agnostic mailing list!

AKSHAY M KULKARNI
________________________________
From: Loris Bennett <loris.bennett at fu-berlin.de>
Sent: Wednesday, June 13, 2018 1:37 PM
To: Jeff Newmiller
Cc: r-help at r-project.org; akshay kulkarni
Subject: Re: [R] on execution time of a function...

Hi Akshay,

In addition to all the things Jeff rightly points out, contention for IO
resources can be an issue.  So if another process was hogging the
bandwidth while your program was attempting to read or write to disk,
that could also have slowed things down.

HTH

Loris

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

> Wow, you can find almost any explanation on the Internets. That doesn't mean you
> should believe all of them. R does not do anything likely to tweak
> interrupts... if that is your problem then you need to be on an
> operating-system/computer-model-specific forum rather than this OS-agnostic
> mailing list.
>
> It is far more likely that your overall memory usage conditions have changed
> since the last time you ran it... or that you didn't actually record all of the
> things you did last time in your script. (Newbie R users often do things at the
> console without putting them in their scripts.)
>
> I suggest that you run your script one statement at a time and see where your
> problem is. You might also want to make sure that other programs are not using
> up a lot of your memory (which could involve some OS-specific tools or just
> shutting down some other programs.)
>
> On June 12, 2018 7:36:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>>I ran  a function in R three days ago and the execution time was about
>>4 minutes. I ran the same function yesterday and the execution time was
>>more than 6:50 minutes(I aborted the function after that time).
>>
>>I read in the Internet that this is possible. I also came to know that
>>software or hardware interrupts are the main reasons.
>>
>>How do you know whether the delay was caused by interrupts? Which
>>hardware or software triggered the interrupts? In general, how to know
>>the exact cause of the delay in execution in R? Are there any packages
>>for these analyses?
>>
>>Very many thanks for your time and effort....
>>
>>yours sincerely,
>>AKSHAY M KULKARNI
>>
>>      [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
--
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jun 13 11:58:02 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 12 Jun 2018 23:58:02 -1000
Subject: [R] on execution time of a function...
In-Reply-To: <SL2P216MB0091615418967B977F2B4876C87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>,
 <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>
 <SL2P216MB0091615418967B977F2B4876C87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAEAF349-F570-413D-99EF-6618C382C617@dcn.davis.ca.us>

it is not just the list that is OS-agnostic... R itself is quite OS-agnostic. However, depending on where you get your packages from they may have something unusual going on in their compiled C or Fortran code. It is just that for a computationally-oriented application like R code that messed with hardware interrupts seem out of place.

I suppose that a bug in a CUDA-related package could screw up interrupts... but the whole point of having an OS as hardware drivers/APIs is to insulate user-level programs like R from those issues, and at best you would post the details of your code and packages and someone might pick up on an odd package and point you toward a more appropriate forum for debugging it.

On June 12, 2018 11:39:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>I do felt a little unsettled by your exhortions on the incongruity of
>posting this question on an OS-agnostic mailing list...I thought that
>there might be some issues on how R communicates with the OS...and also
>that some R packages might rectify the issue(in my experience, I have
>had a R package for every R issue that I had!)
>
>Anyway, I ran the  same function again and it is executing within
>limits. Also, I would be using AWS EC2 servers to run my R functions(I
>am a day trader in india and input some 250 stocks to R functions
>daily), and I don't think that the issue would persist on Intel Xeon
>processors and dedicated VMs....
>
>Anyway,thanks for all your concerns tolerating my query on an
>OS-agnostic mailing list!
>
>AKSHAY M KULKARNI
>________________________________
>From: Loris Bennett <loris.bennett at fu-berlin.de>
>Sent: Wednesday, June 13, 2018 1:37 PM
>To: Jeff Newmiller
>Cc: r-help at r-project.org; akshay kulkarni
>Subject: Re: [R] on execution time of a function...
>
>Hi Akshay,
>
>In addition to all the things Jeff rightly points out, contention for
>IO
>resources can be an issue.  So if another process was hogging the
>bandwidth while your program was attempting to read or write to disk,
>that could also have slowed things down.
>
>HTH
>
>Loris
>
>Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:
>
>> Wow, you can find almost any explanation on the Internets. That
>doesn't mean you
>> should believe all of them. R does not do anything likely to tweak
>> interrupts... if that is your problem then you need to be on an
>> operating-system/computer-model-specific forum rather than this
>OS-agnostic
>> mailing list.
>>
>> It is far more likely that your overall memory usage conditions have
>changed
>> since the last time you ran it... or that you didn't actually record
>all of the
>> things you did last time in your script. (Newbie R users often do
>things at the
>> console without putting them in their scripts.)
>>
>> I suggest that you run your script one statement at a time and see
>where your
>> problem is. You might also want to make sure that other programs are
>not using
>> up a lot of your memory (which could involve some OS-specific tools
>or just
>> shutting down some other programs.)
>>
>> On June 12, 2018 7:36:40 PM HST, akshay kulkarni
><akshay_e4 at hotmail.com> wrote:
>>>I ran  a function in R three days ago and the execution time was
>about
>>>4 minutes. I ran the same function yesterday and the execution time
>was
>>>more than 6:50 minutes(I aborted the function after that time).
>>>
>>>I read in the Internet that this is possible. I also came to know
>that
>>>software or hardware interrupts are the main reasons.
>>>
>>>How do you know whether the delay was caused by interrupts? Which
>>>hardware or software triggered the interrupts? In general, how to
>know
>>>the exact cause of the delay in execution in R? Are there any
>packages
>>>for these analyses?
>>>
>>>Very many thanks for your time and effort....
>>>
>>>yours sincerely,
>>>AKSHAY M KULKARNI
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>--
>Dr. Loris Bennett (Mr.)
>ZEDAT, Freie Universit?t Berlin         Email
>loris.bennett at fu-berlin.de

-- 
Sent from my phone. Please excuse my brevity.


From Bill@Poling @ending from zeli@@com  Wed Jun 13 12:20:32 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 13 Jun 2018 10:20:32 +0000
Subject: [R] Help installing the finalfit package
In-Reply-To: <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
Message-ID: <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning David, thank you for your reply.

However, I am not sure what you mean regarding the windows error? Where or what is the windows error? And how would I remedy this issue please?

Thanks

WHP

From: David Winsemius [mailto:dwinsemius at comcast.net]
Sent: Wednesday, June 13, 2018 12:48 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help installing the finalfit package


> On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
> Good morning. Over the weekend I worked through this tutorial on bloggers.com<http://bloggers.com> at home where I am on 3.5.5:
>
> #Elegant regression results tables and plots in R: the finalfit package
>
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/<https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/>
>
> Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
>
> The tutorial ran splendidly at home but here at office, not so much, big smile.
>
>> devtools::install_github("ewenharrison/finalfit")
> Downloading GitHub repo ewenharrison/finalfit at master
> from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master<https://api.github.com/repos/ewenharrison/finalfit/zipball/master>
> Installing finalfit
> Installing 1 package: mice
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
> downloaded 1.4 MB
>
> package 'mice' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'mice'

Generally the first task is to address the first error, which in this case appears to be a windows permission issue.

--
David


>
> The downloaded binary packages are in
> C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \
> "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
>
> ERROR: dependency 'mice' is not available for package 'finalfit'
> * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> In R CMD INSTALL
> Installation failed: Command failed (1)
>
> I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho' etc... which I now load at the beginning of every session.
>
> So my hunch is that maybe I need 3.5.5 for all this to work?
>
> Also I have this error with the mice package:
>
>
>> install.packages("mice")
>
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
>
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
>
> downloaded 1.4 MB
>
>
>
> package 'mice' successfully unpacked and MD5 sums checked
>
> Warning in install.packages :
>
> cannot remove prior installation of package 'mice'
>
>
>
> The downloaded binary packages are in
>
> C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
>
>> library(mice)
>
> Error in library(mice) : there is no package called 'mice'
>
>
> I would appreciate any suggestion please.
>
> Thank you
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law




Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From m@ij@@@irkj@rvi @ending from gm@il@com  Wed Jun 13 13:21:55 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 13 Jun 2018 14:21:55 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
Message-ID: <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>

Hi!

I have a quadratic optimization problem and I have some difficulties coding
it with R. The math version of the problem looks like this:

min sum(mj -mj^)^2 which goes from 1 to J

st.

mj-1 <= mj - delta1

1/(Qj-1 -Qj-2)(mj-2 -mj-1) <= 1/(Qj -Qj-1 ) (mj-1 - mj) -delta2

And I'm coding it like this:

Dmat <- matrix(0, J,J)
diag(Dmat) <- 1
dvec <- -hsmooth
Aeq <- 0
beq <- 0
Amat <- matrix(0,2*J-3,J)
bvec <- rep(0,2*J-3)

for(j in 1:J)
{
  Amat[j-1,j-1] = -1
  Amat[j-1,j]   = 1
  bvec[j-1]     = Delta1
}

for(j in 2:J)
  {
  Amat[J-1+j-2,j] = -1/ (Q[j] - Q[j-1])
  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
  Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
  bvec[J-1+j-1]= Delta2
}

solution <- solve.QP(Dmat, dvec, Amat, bvec)


I get errors:
Error in Amat[J - 1 + j - 2, j - 1] <- 1/(Q[j] - Q[j - 1]) + 1/(Q[j -  :
  replacement has length zero

And

Error in solve.QP(Dmat, dvec, Amat, bvec) :
  Amat and dvec are incompatible!

I'm not sure what I'm doing wrong here, and I really could use some help
with this. Thanks in advance!

	[[alternative HTML version deleted]]


From bori@@@teipe @ending from utoronto@c@  Wed Jun 13 14:52:10 2018
From: bori@@@teipe @ending from utoronto@c@ (Boris Steipe)
Date: Wed, 13 Jun 2018 08:52:10 -0400
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
Message-ID: <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>

Q[j-2] gives you Q[0] in your first inner loop iteration.
R arrays start at one. 

B.


> On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
> 
>  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])


From bgunter@4567 @ending from gm@il@com  Wed Jun 13 16:10:03 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 13 Jun 2018 07:10:03 -0700
Subject: [R] Tables in Rmarkdown Word
In-Reply-To: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
Message-ID: <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>

You should post this on the r-package-devel  list, not here. That list is
exactly concerned with such issues. This list is about R programming itself.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 13, 2018 at 12:05 AM, Shakeel Suleman <
Shakeel.Suleman at phe.gov.uk> wrote:

> I am relatively new to R and was wondering if someone could advise me on
> presenting tables in R Markdown for Word. I would like to present a simple
> table of counts, with column 1 representing name of an organisation (and
> last row called "All organisations") and another four columns representing
> the most recent four week period (e.g. week 21, 22, 23, 24) and a final
> total column, as illustrated below. The actual data is just counts (e.g. 4,
> 5, 8, widgets produced, number of people off sick etc).
>
> My question is: can this be done to a publication quality standard. I have
> tried Pander, but that adds "Sum" instead of All Organisations and 4 Week
> Total and doesn't look particularly good.
>
>
>
> Week
>
>
>
> 20
>
> 21
>
> 22
>
> 23
>
> 4 week total
>
> Organisation
>
> 6
>
> 6
>
> 1
>
> 1
>
> 14
>
> ABC
>
> 2
>
> 4
>
> 1
>
> 5
>
> 12
>
> DCE
>
> 0
>
> 5
>
> 1
>
> 5
>
> 11
>
> EFG
>
> 3
>
> 6
>
> 3
>
> 5
>
> 17
>
> HIJ
>
> 1
>
> 8
>
> 3
>
> 2
>
> 14
>
> All Organizations
>
> 12
>
> 29
>
> 9
>
> 18
>
> 68
>
>
>
> Kind regards,
>
> Shakeel
>
>
> **************************************************************************
> The information contained in the EMail and any attachments is confidential
> and intended solely and for the attention and use of the named
> addressee(s). It may not be disclosed to any other person without the
> express authority of Public Health England, or the intended recipient, or
> both. If you are not the intended recipient, you must not disclose, copy,
> distribute or retain this message or any part of it. This footnote also
> confirms that this EMail has been swept for computer viruses by
> Symantec.Cloud, but please re-sweep any attachments before opening or
> saving. http://www.gov.uk/PHE
> **************************************************************************
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Wed Jun 13 16:31:38 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 13 Jun 2018 10:31:38 -0400
Subject: [R] Tables in Rmarkdown Word
In-Reply-To: <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
 <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>
Message-ID: <b64e7905-71f7-431f-f32d-ec4c4b31b1ae@gmail.com>

On 13/06/2018 10:10 AM, Bert Gunter wrote:
> You should post this on the r-package-devel  list, not here. That list is
> exactly concerned with such issues. This list is about R programming itself.

No, r-package-devel is about developing and publishing R packages, not 
using them.

I don't know the answer to this question.  Others like it tend to appear 
on Stack Overflow with the "knitr" tag, so that might be a better place 
to ask if no answer appears here.  But like here, that forum asks for 
reproducible examples (i.e. the R code that doesn't quite work).

Duncan Murdoch


> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Wed, Jun 13, 2018 at 12:05 AM, Shakeel Suleman <
> Shakeel.Suleman at phe.gov.uk> wrote:
> 
>> I am relatively new to R and was wondering if someone could advise me on
>> presenting tables in R Markdown for Word. I would like to present a simple
>> table of counts, with column 1 representing name of an organisation (and
>> last row called "All organisations") and another four columns representing
>> the most recent four week period (e.g. week 21, 22, 23, 24) and a final
>> total column, as illustrated below. The actual data is just counts (e.g. 4,
>> 5, 8, widgets produced, number of people off sick etc).
>>
>> My question is: can this be done to a publication quality standard. I have
>> tried Pander, but that adds "Sum" instead of All Organisations and 4 Week
>> Total and doesn't look particularly good.
>>
>>
>>
>> Week
>>
>>
>>
>> 20
>>
>> 21
>>
>> 22
>>
>> 23
>>
>> 4 week total
>>
>> Organisation
>>
>> 6
>>
>> 6
>>
>> 1
>>
>> 1
>>
>> 14
>>
>> ABC
>>
>> 2
>>
>> 4
>>
>> 1
>>
>> 5
>>
>> 12
>>
>> DCE
>>
>> 0
>>
>> 5
>>
>> 1
>>
>> 5
>>
>> 11
>>
>> EFG
>>
>> 3
>>
>> 6
>>
>> 3
>>
>> 5
>>
>> 17
>>
>> HIJ
>>
>> 1
>>
>> 8
>>
>> 3
>>
>> 2
>>
>> 14
>>
>> All Organizations
>>
>> 12
>>
>> 29
>>
>> 9
>>
>> 18
>>
>> 68
>>
>>
>>
>> Kind regards,
>>
>> Shakeel
>>
>>
>> **************************************************************************
>> The information contained in the EMail and any attachments is confidential
>> and intended solely and for the attention and use of the named
>> addressee(s). It may not be disclosed to any other person without the
>> express authority of Public Health England, or the intended recipient, or
>> both. If you are not the intended recipient, you must not disclose, copy,
>> distribute or retain this message or any part of it. This footnote also
>> confirms that this EMail has been swept for computer viruses by
>> Symantec.Cloud, but please re-sweep any attachments before opening or
>> saving. http://www.gov.uk/PHE
>> **************************************************************************
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From ibr@himi@i@@cm @ending from gm@il@com  Wed Jun 13 14:56:07 2018
From: ibr@himi@i@@cm @ending from gm@il@com (Khaled Ibrahimi)
Date: Wed, 13 Jun 2018 14:56:07 +0200
Subject: [R] R examples in Agronomy
Message-ID: <CALUo2PTC0ox-0TMD4QdOtDffs0A+zkpG5bUWe6-1fErF4CZd5g@mail.gmail.com>

Dear all,
Are there good R stat examples in the field of agronomy (especially field
experiments)?
Thanks
----------------------------------------/-----------------------------------------
Khaled IBRAHIMI, PhD
Assistant Professor, Soil Science & Environment
Higher Institute of Agricultural Sciences of Chott-Mariem
The University of Sousse, Tunisia
Tel.: 216 97 276 835
Email: ibrahimi.isacm at gmail.com

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Wed Jun 13 16:47:54 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 13 Jun 2018 14:47:54 +0000
Subject: [R] Data frame with Factor column missing data change to NA
Message-ID: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning.

#I have df with a Factor column called "NonAcceptanceOther" that contains missing data.

#Not every record in the df is expected to have a value in this column.

# Typical values look like:
# ERS
# Claim paid without PHX recommended savings
# Claim paid without PHX recommended savings
# MRC Amount
# MRC Amount
# PPO per provider
#Or they are missing (blank)

#Example

df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
head(df2, n=20)

   PlaceOfService ClaimStatusID                         NonAcceptanceOther RejectionCodeID          CPTCats     RevCodeCats GCode2 ClaimTypeID

1              11             2                                                         NA          ResPSys NotValidRevCode      2           2

2              81             3                                                         53       PathandLab NotValidRevCode      2           2

3              11             3                                                         47         Medicine NotValidRevCode      1           2

4              09             2                                                         NA           NotCPT NotValidRevCode      1           2

5              11             2                                                         NA        Radiology NotValidRevCode      2           2

6              23             2                                                         NA       MusculoSys NotValidRevCode      2           2

7              12             3                                                         47           NotCPT NotValidRevCode      2           2

8              12             2                                                         NA         Medicine NotValidRevCode      2           2

9              11             3                                                         47         Medicine NotValidRevCode      1           2

10             21             2                                                         NA       Anesthesia NotValidRevCode      2           2

11             11             3                                        ERS              30      EvalandMgmt NotValidRevCode      2           2

12             81             2                                                         NA       PathandLab NotValidRevCode      2           2

13             21             2                                                         NA        Radiology NotValidRevCode      1           2

14             11             2                                                         NA         Medicine NotValidRevCode      1           2

15             99             3 Claim paid without PHX recommended savings              30 CardioHemLympSys             Lab      0           1

16             99             3 Claim paid without PHX recommended savings              30       PathandLab             Lab      0           1

17             99             3                                 MRC Amount              30           NotCPT          Pharma      2           1

18             99             3                                 MRC Amount              30       PathandLab             Lab      2           1

19             81             2                                                         NA       PathandLab NotValidRevCode      2           2

20             23             2                                                         NA         IntegSys NotValidRevCode      1           2

#I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.

#I have tried several approaches from Googled references:

NonAcceptanceOther <- df$NonAcceptanceOther
table(addNA(NonAcceptanceOther))

is.na <- df$NonAcceptanceOther

df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA

#However, when I go to use:

missingDF <- PlotMissing(df)

#Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID)  and this "NonAcceptanceOther" column does not reflect or hold the NA values?

Thank you for any advice.

WHP












Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}


From bgunter@4567 @ending from gm@il@com  Wed Jun 13 17:12:00 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 13 Jun 2018 08:12:00 -0700
Subject: [R] Fwd:  Tables in Rmarkdown Word
In-Reply-To: <CAGxFJbQWWcv99s_UcpmoSxNjksuDCgkuAVniFBXtpFKQw0xozQ@mail.gmail.com>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
 <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>
 <b64e7905-71f7-431f-f32d-ec4c4b31b1ae@gmail.com>
 <CAGxFJbQWWcv99s_UcpmoSxNjksuDCgkuAVniFBXtpFKQw0xozQ@mail.gmail.com>
Message-ID: <CAGxFJbQ7xvD0nyJB_f7Ken7Gw9z=Qvf0A7uN+6U=T0ZkZ_Kwjw@mail.gmail.com>

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

---------- Forwarded message ----------
From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Wed, Jun 13, 2018 at 8:11 AM
Subject: Re: [R] Tables in Rmarkdown Word
To: Duncan Murdoch <murdoch.duncan at gmail.com>


Duncan:

OK. I'll stand corrected.

A web search on "Rmarkdown tables" produced what looked like several useful
links, e.g.

https://rmarkdown.rstudio.com/lesson-7.html


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 13, 2018 at 7:31 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 13/06/2018 10:10 AM, Bert Gunter wrote:
>
>> You should post this on the r-package-devel  list, not here. That list is
>> exactly concerned with such issues. This list is about R programming
>> itself.
>>
>
> No, r-package-devel is about developing and publishing R packages, not
> using them.
>
> I don't know the answer to this question.  Others like it tend to appear
> on Stack Overflow with the "knitr" tag, so that might be a better place to
> ask if no answer appears here.  But like here, that forum asks for
> reproducible examples (i.e. the R code that doesn't quite work).
>
> Duncan Murdoch
>
>
>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Wed, Jun 13, 2018 at 12:05 AM, Shakeel Suleman <
>> Shakeel.Suleman at phe.gov.uk> wrote:
>>
>> I am relatively new to R and was wondering if someone could advise me on
>>> presenting tables in R Markdown for Word. I would like to present a
>>> simple
>>> table of counts, with column 1 representing name of an organisation (and
>>> last row called "All organisations") and another four columns
>>> representing
>>> the most recent four week period (e.g. week 21, 22, 23, 24) and a final
>>> total column, as illustrated below. The actual data is just counts (e.g.
>>> 4,
>>> 5, 8, widgets produced, number of people off sick etc).
>>>
>>> My question is: can this be done to a publication quality standard. I
>>> have
>>> tried Pander, but that adds "Sum" instead of All Organisations and 4 Week
>>> Total and doesn't look particularly good.
>>>
>>>
>>>
>>> Week
>>>
>>>
>>>
>>> 20
>>>
>>> 21
>>>
>>> 22
>>>
>>> 23
>>>
>>> 4 week total
>>>
>>> Organisation
>>>
>>> 6
>>>
>>> 6
>>>
>>> 1
>>>
>>> 1
>>>
>>> 14
>>>
>>> ABC
>>>
>>> 2
>>>
>>> 4
>>>
>>> 1
>>>
>>> 5
>>>
>>> 12
>>>
>>> DCE
>>>
>>> 0
>>>
>>> 5
>>>
>>> 1
>>>
>>> 5
>>>
>>> 11
>>>
>>> EFG
>>>
>>> 3
>>>
>>> 6
>>>
>>> 3
>>>
>>> 5
>>>
>>> 17
>>>
>>> HIJ
>>>
>>> 1
>>>
>>> 8
>>>
>>> 3
>>>
>>> 2
>>>
>>> 14
>>>
>>> All Organizations
>>>
>>> 12
>>>
>>> 29
>>>
>>> 9
>>>
>>> 18
>>>
>>> 68
>>>
>>>
>>>
>>> Kind regards,
>>>
>>> Shakeel
>>>
>>>
>>> ************************************************************
>>> **************
>>> The information contained in the EMail and any attachments is
>>> confidential
>>> and intended solely and for the attention and use of the named
>>> addressee(s). It may not be disclosed to any other person without the
>>> express authority of Public Health England, or the intended recipient, or
>>> both. If you are not the intended recipient, you must not disclose, copy,
>>> distribute or retain this message or any part of it. This footnote also
>>> confirms that this EMail has been swept for computer viruses by
>>> Symantec.Cloud, but please re-sweep any attachments before opening or
>>> saving. http://www.gov.uk/PHE
>>> ************************************************************
>>> **************
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Wed Jun 13 17:33:22 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 13 Jun 2018 08:33:22 -0700
Subject: [R] Help installing the finalfit package
In-Reply-To: <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
 <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <1FE90007-CFBF-4855-9E31-351C19DD2BA7@comcast.net>


> On Jun 13, 2018, at 3:20 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> Good morning David, thank you for your reply.
>  
> However, I am not sure what you mean regarding the windows error?

I'm not a Windows user, but the first indication of a problem was when the installation procedure tried to replace an older version of mice with a newer version and failed. I only chimed in from my place on the sidelines of an R-Windows game because no one else had responded.

I tried finding the finalfit package on CRAN but it doesn't seem to have yet been submitted in a version that can be installed on a Mac. So I followed the advice on the blog you linked to and I can now see the package DESCRIPTION file. It has these dependencies:

Imports: Hmisc, ggplot2, grid, gridExtra, lme4, magrittr, mice, pROC,
        plyr, scales, stats, stringr, survival, survminer
RoxygenNote: 6.0.1
Suggests: knitr, rmarkdown, rstan, boot


> Where or what is the windows error?

It appears you have an older version of mice but I cannot tell why it is unacceptable to this version of 'finalfit' since there is no version requirement in the deescription 'Imports:' line.

You might try to update your 'mice'-package. The current version on CRAN is 3.0.0, and attempting to make that available might illuminate the problem.


> And how would I remedy this issue please?

Fixing permissions on windows is not actually on-topic for Rhelp. Perhaps you could ask on the SuperUser forum where advice about Windows system maintenance is on-topic: https://superuser.com/


Best of luck.

David.
> Thanks
>  
> WHP
>  
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Wednesday, June 13, 2018 12:48 AM
> To: Bill Poling <Bill.Poling at zelis.com>
> Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
> Subject: Re: [R] Help installing the finalfit package
>  
> 
> > On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> > 
> > Good morning. Over the weekend I worked through this tutorial on bloggers.com at home where I am on 3.5.5:
> > 
> > #Elegant regression results tables and plots in R: the finalfit package
> > 
> > https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
> > 
> > Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
> > 
> > The tutorial ran splendidly at home but here at office, not so much, big smile.
> > 
> >> devtools::install_github("ewenharrison/finalfit")
> > Downloading GitHub repo ewenharrison/finalfit at master
> > from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master
> > Installing finalfit
> > Installing 1 package: mice
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> > downloaded 1.4 MB
> > 
> > package 'mice' successfully unpacked and MD5 sums checked
> > Warning: cannot remove prior installation of package 'mice'
> 
> Generally the first task is to address the first error, which in this case appears to be a windows permission issue.
> 
> -- 
> David
> 
> 
> > 
> > The downloaded binary packages are in
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> > "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \
> > "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
> > 
> > ERROR: dependency 'mice' is not available for package 'finalfit'
> > * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> > In R CMD INSTALL
> > Installation failed: Command failed (1)
> > 
> > I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho' etc... which I now load at the beginning of every session.
> > 
> > So my hunch is that maybe I need 3.5.5 for all this to work?
> > 
> > Also I have this error with the mice package:
> > 
> > 
> >> install.packages("mice")
> > 
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> > 
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> > 
> > downloaded 1.4 MB
> > 
> > 
> > 
> > package 'mice' successfully unpacked and MD5 sums checked
> > 
> > Warning in install.packages :
> > 
> > cannot remove prior installation of package 'mice'
> > 
> > 
> > 
> > The downloaded binary packages are in
> > 
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> > 
> >> library(mice)
> > 
> > Error in library(mice) : there is no package called 'mice'
> > 
> > 
> > I would appreciate any suggestion please.
> > 
> > Thank you
> > 
> > WHP
> > 
> > Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jun 13 18:13:17 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 13 Jun 2018 06:13:17 -1000
Subject: [R] Tables in Rmarkdown Word
In-Reply-To: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
Message-ID: <F4717260-062E-4BD0-9DE1-DCC1C90717FC@dcn.davis.ca.us>

I have heard of people using CSS formatting with Rmarkdown output and copy-pasting into Word/LibreOffice, but LaTeX is so much nicer if you don't require Word that I suppose there haven't been many with that itch. To some extent you can use a manually-styled Word starting document (referred to as a template but not what Word refers to as a template) with Word output, but that is pretty limited for table formatting.

You could look at the ReporteRs package instead... but that is not Rmarkdown.

If you really need publication quality with Word

On June 12, 2018 9:05:55 PM HST, Shakeel Suleman <Shakeel.Suleman at phe.gov.uk> wrote:
>I am relatively new to R and was wondering if someone could advise me
>on presenting tables in R Markdown for Word. I would like to present a
>simple table of counts, with column 1 representing name of an
>organisation (and last row called "All organisations") and another four
>columns representing the most recent four week period (e.g. week 21,
>22, 23, 24) and a final total column, as illustrated below. The actual
>data is just counts (e.g. 4, 5, 8, widgets produced, number of people
>off sick etc).
>
>My question is: can this be done to a publication quality standard. I
>have tried Pander, but that adds "Sum" instead of All Organisations and
>4 Week Total and doesn't look particularly good.
>
>
>
>Week
>
>
>
>20
>
>21
>
>22
>
>23
>
>4 week total
>
>Organisation
>
>6
>
>6
>
>1
>
>1
>
>14
>
>ABC
>
>2
>
>4
>
>1
>
>5
>
>12
>
>DCE
>
>0
>
>5
>
>1
>
>5
>
>11
>
>EFG
>
>3
>
>6
>
>3
>
>5
>
>17
>
>HIJ
>
>1
>
>8
>
>3
>
>2
>
>14
>
>All Organizations
>
>12
>
>29
>
>9
>
>18
>
>68
>
>
>
>Kind regards,
>
>Shakeel
>
>
>**************************************************************************
>The information contained in the EMail and any attachments is
>confidential and intended solely and for the attention and use of the
>named addressee(s). It may not be disclosed to any other person without
>the express authority of Public Health England, or the intended
>recipient, or both. If you are not the intended recipient, you must not
>disclose, copy, distribute or retain this message or any part of it.
>This footnote also confirms that this EMail has been swept for computer
>viruses by Symantec.Cloud, but please re-sweep any attachments before
>opening or saving. http://www.gov.uk/PHE
>**************************************************************************
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From wdunl@p @ending from tibco@com  Wed Jun 13 18:27:10 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Wed, 13 Jun 2018 09:27:10 -0700
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
Message-ID: <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>

Use functions calling functions instead of scripts invoking scripts.  Put
all your
functions in a 'package'.  Then your scripts would be very small, just
passing
command line arguments to R functions.

(It is possible to call scripts from scripts, but I think it quickly leads
to headaches.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jun 12, 2018 at 7:33 PM, Sam Tuck <STuck at nzsuperfund.co.nz> wrote:

> Hi All,
>           I am new to R and am wondering if there is a way to pass
> arguments between rscripts.  I have this working but have had to create a
> C# shell calling the scripts in sequence via windows scripting which
> enables command line arguments to get the necessary interaction.
>
> I'm wondering if I'm using an outdated program construction technique - I
> create r files like I would programme functions or reoccurring code
> snippets in C.  It may be that r was not designed to create lots of little
> r script modules that interact via a master script?
>
> Ideally I'd like to call r scripts from other r scripts and have all the
> variables still in memory: For example
>
> I've been using RStudio Version 1.1.447 to programme and regression test
> my individual scripts,.
>
> Script Arg Script.R
> {
> # We are going to pass arguments into this script
> arguments <- commandArgs(trailingOnly = TRUE)
> #arguments[1] is double
> #arguments[2] is double
> #arguments[3] is double.
> if(length(arguments) <3)
> {
>   stop("Not enough arguments, please supply 3, [% dbl}total deviation, [%
> dbl] individual deviation, [int] periods before recenter")
> }
> TotalDeviation <- as.numeric(arguments[1])/100
> IndividualDeviation <- as.numeric(arguments[2])/100
> RecenterPeriods <- as.numeric(arguments[3])
> # We then manipulate some objects based on these inputs, but for this test
> we will output them to a file.
> fileConn<-file("output.txt")
> writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
> fileConn)
> close(fileConn)
> }
> Script RunningScript.R
> {
> Arg Script.R 0.6 0.4 132
> }
>
> To which I get
> Error: unexpected symbol in " Arg Script.R"
>
> When I use the script RunningScript.R
> {
> system(paste("Arg Script.R", 0.8, 0.4, 132))
> }
> Nothing occurs (there is no output file created, but also no error)
>
> When I use RunningScript.R
> {
> commandArgs <- c(0.6,0.4,132)
> source("Arg Script.R')
> }
> I don't get any args passed into the file.  Instead getting the error
> Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl]
> individual deviation, [int] periods before recenter
>
> Thanks
>
> Sam Tuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From wjm1 @ending from c@@@columbi@@edu  Wed Jun 13 18:34:07 2018
From: wjm1 @ending from c@@@columbi@@edu (William Michels)
Date: Wed, 13 Jun 2018 09:34:07 -0700
Subject: [R] R examples in Agronomy
Message-ID: <CAA99HCzNVFg-RG5snx94yym-OYNDK0DfafFbxn3DG62NsyADdA@mail.gmail.com>

Hello,

For introductory material there is--of course--Immer's Barley Data
(popularized by Bill Cleveland), and used extensively in R to
demonstrate lattice graphics:

>library(lattice)
>?barley

Note the example dotplot() at the bottom of the "barley" help page,
and also on the "barchart" help page. The citation is included, and
there is also other commentary online:

Immer, R. F., H. K. Hayes, and LeRoy Powers. (1934). Statistical
Determination of Barley Varietal Adaptation.  Journal of the American
Society of Agronomy, 26, 403?419.
Wright, Kevin (2013). Revisiting Immer's Barley Data. The American
Statistician, 67(3), 129?133.
http://blog.revolutionanalytics.com/2014/07/theres-no-mistake-in-the-barley-data.html

For a more extensive collection of agronomic data, take a look at the
"agridat" package. There's a nice vignette as well.

https://CRAN.R-project.org/package=agridat
https://cran.r-project.org/web/packages/agridat/vignettes/agridat_examples.pdf

HTH,

Bill.

William Michels, Ph.D.



On Wed, Jun 13, 2018 at 5:56 AM, Khaled Ibrahimi
<ibrahimi.isacm at gmail.com> wrote:
> Dear all,
> Are there good R stat examples in the field of agronomy (especially field
> experiments)?
> Thanks
> ----------------------------------------/-----------------------------------------
> Khaled IBRAHIMI, PhD
> Assistant Professor, Soil Science & Environment
> Higher Institute of Agricultural Sciences of Chott-Mariem
> The University of Sousse, Tunisia
> Tel.: 216 97 276 835
> Email: ibrahimi.isacm at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From Bill@Poling @ending from zeli@@com  Wed Jun 13 18:38:31 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Wed, 13 Jun 2018 16:38:31 +0000
Subject: [R] Help installing the finalfit package
In-Reply-To: <1FE90007-CFBF-4855-9E31-351C19DD2BA7@comcast.net>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
 <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <1FE90007-CFBF-4855-9E31-351C19DD2BA7@comcast.net>
Message-ID: <CY1PR0201MB1834D65BA14E18C6A013B9FFEA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Ok, thank you David, I understand better now. I will start with the mice package issue and move any further questions to the forum you suggested.

Really appreciate your help.

Cheers.

WHP

From: David Winsemius [mailto:dwinsemius at comcast.net]
Sent: Wednesday, June 13, 2018 11:33 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help installing the finalfit package


> On Jun 13, 2018, at 3:20 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
> Good morning David, thank you for your reply.
>
> However, I am not sure what you mean regarding the windows error?

I'm not a Windows user, but the first indication of a problem was when the installation procedure tried to replace an older version of mice with a newer version and failed. I only chimed in from my place on the sidelines of an R-Windows game because no one else had responded.

I tried finding the finalfit package on CRAN but it doesn't seem to have yet been submitted in a version that can be installed on a Mac. So I followed the advice on the blog you linked to and I can now see the package DESCRIPTION file. It has these dependencies:

Imports: Hmisc, ggplot2, grid, gridExtra, lme4, magrittr, mice, pROC,
plyr, scales, stats, stringr, survival, survminer
RoxygenNote: 6.0.1
Suggests: knitr, rmarkdown, rstan, boot


> Where or what is the windows error?

It appears you have an older version of mice but I cannot tell why it is unacceptable to this version of 'finalfit' since there is no version requirement in the deescription 'Imports:' line.

You might try to update your 'mice'-package. The current version on CRAN is 3.0.0, and attempting to make that available might illuminate the problem.


> And how would I remedy this issue please?

Fixing permissions on windows is not actually on-topic for Rhelp. Perhaps you could ask on the SuperUser forum where advice about Windows system maintenance is on-topic: https://superuser.com/<https://superuser.com/>


Best of luck.

David.
> Thanks
>
> WHP
>
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Wednesday, June 13, 2018 12:48 AM
> To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
> Cc: r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] Help installing the finalfit package
>
>
> > On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
> >
> > Good morning. Over the weekend I worked through this tutorial on bloggers.com<http://bloggers.com> at home where I am on 3.5.5:
> >
> > #Elegant regression results tables and plots in R: the finalfit package
> >
> > https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/<https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/>
> >
> > Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
> >
> > The tutorial ran splendidly at home but here at office, not so much, big smile.
> >
> >> devtools::install_github("ewenharrison/finalfit")
> > Downloading GitHub repo ewenharrison/finalfit at master
> > from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master<https://api.github.com/repos/ewenharrison/finalfit/zipball/master>
> > Installing finalfit
> > Installing 1 package: mice
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> > downloaded 1.4 MB
> >
> > package 'mice' successfully unpacked and MD5 sums checked
> > Warning: cannot remove prior installation of package 'mice'
>
> Generally the first task is to address the first error, which in this case appears to be a windows permission issue.
>
> --
> David
>
>
> >
> > The downloaded binary packages are in
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> > "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \
> > "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
> >
> > ERROR: dependency 'mice' is not available for package 'finalfit'
> > * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> > In R CMD INSTALL
> > Installation failed: Command failed (1)
> >
> > I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho' etc... which I now load at the beginning of every session.
> >
> > So my hunch is that maybe I need 3.5.5 for all this to work?
> >
> > Also I have this error with the mice package:
> >
> >
> >> install.packages("mice")
> >
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
> >
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> >
> > downloaded 1.4 MB
> >
> >
> >
> > package 'mice' successfully unpacked and MD5 sums checked
> >
> > Warning in install.packages :
> >
> > cannot remove prior installation of package 'mice'
> >
> >
> >
> > The downloaded binary packages are in
> >
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> >
> >> library(mice)
> >
> > Error in library(mice) : there is no package called 'mice'
> >
> >
> > I would appreciate any suggestion please.
> >
> > Thank you
> >
> > WHP
> >
> > Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law




Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From profjcn@@h @ending from gm@il@com  Wed Jun 13 18:46:11 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Wed, 13 Jun 2018 12:46:11 -0400
Subject: [R] rJava woes on Linux Mint 18.3 Sylvia
Message-ID: <c30108c8-44e2-79f2-b10d-9658ba8df2c3@gmail.com>

Is anyone else having trouble with installing rJava on Linux Mint under R 3.5?

I managed to work around troubles in Bunsenlabs Deuterium (Debian Jessie), but
it uses older libraries (openjdk-7).

Please contact off-list and I will post information when solution understood,
as, looking on the net, there seem to be a lot of people with suggestions
that don't work, or work only in some environments.

JN


From ibr@himi@i@@cm @ending from gm@il@com  Wed Jun 13 19:53:31 2018
From: ibr@himi@i@@cm @ending from gm@il@com (Khaled Ibrahimi)
Date: Wed, 13 Jun 2018 18:53:31 +0100
Subject: [R] R examples in Agronomy
In-Reply-To: <CAA99HCzNVFg-RG5snx94yym-OYNDK0DfafFbxn3DG62NsyADdA@mail.gmail.com>
References: <CAA99HCzNVFg-RG5snx94yym-OYNDK0DfafFbxn3DG62NsyADdA@mail.gmail.com>
Message-ID: <CALUo2PSnUv8T5FkZTmYD+zFYavenEammBoWM24u=LscMhCa25w@mail.gmail.com>

Thanks, I'll check them out.

Le mer. 13 juin 2018 17:34, William Michels <wjm1 at caa.columbia.edu> a
?crit :

> Hello,
>
> For introductory material there is--of course--Immer's Barley Data
> (popularized by Bill Cleveland), and used extensively in R to
> demonstrate lattice graphics:
>
> >library(lattice)
> >?barley
>
> Note the example dotplot() at the bottom of the "barley" help page,
> and also on the "barchart" help page. The citation is included, and
> there is also other commentary online:
>
> Immer, R. F., H. K. Hayes, and LeRoy Powers. (1934). Statistical
> Determination of Barley Varietal Adaptation.  Journal of the American
> Society of Agronomy, 26, 403?419.
> Wright, Kevin (2013). Revisiting Immer's Barley Data. The American
> Statistician, 67(3), 129?133.
>
> http://blog.revolutionanalytics.com/2014/07/theres-no-mistake-in-the-barley-data.html
>
> For a more extensive collection of agronomic data, take a look at the
> "agridat" package. There's a nice vignette as well.
>
> https://CRAN.R-project.org/package=agridat
>
> https://cran.r-project.org/web/packages/agridat/vignettes/agridat_examples.pdf
>
> HTH,
>
> Bill.
>
> William Michels, Ph.D.
>
>
>
> On Wed, Jun 13, 2018 at 5:56 AM, Khaled Ibrahimi
> <ibrahimi.isacm at gmail.com> wrote:
> > Dear all,
> > Are there good R stat examples in the field of agronomy (especially field
> > experiments)?
> > Thanks
> >
> ----------------------------------------/-----------------------------------------
> > Khaled IBRAHIMI, PhD
> > Assistant Professor, Soil Science & Environment
> > Higher Institute of Agricultural Sciences of Chott-Mariem
> > The University of Sousse, Tunisia
> > Tel.: 216 97 276 835
> > Email: ibrahimi.isacm at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Wed Jun 13 22:21:07 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Wed, 13 Jun 2018 20:21:07 +0000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
Message-ID: <3BD3520F-4CB7-4500-A89B-43186C048B99@llnl.gov>

When I want to run multiple scripts one after the other, and have variables created in a script be still in memory for use by a subsequent script, I normally create a master script (say, "runall.r") and it sources each of the others in turn. For example, my master script (runall.r) would look like this:

## master script (runall.r)
source('script1.r')
source('script2.r')
source('script3.r')
cat('[runall.r] Done\n')
## end of master script

Then, optionally, I can pass command line arguments to runall.r and parse them before sourcing the other scripts.

Since all three scripts are run in the same R session, all variables in memory when script1 finishes will be available to script2, and so on.

If you want to have each of the scripts be executable (by which I mean you run them by typing their name at the command line in a Linux environment; I don't know how it's done in Windows) and have the results of script1 be used as command line arguments to script2 -- well, I'm sure it can be done, but I don't think R's way of doing things is conducive to this approach. If you want to go that route, look up the --save, --no-save, --restore, and --no-restore arguments to R scripts.

See also the help page for Rscript [type help('Rscript') or ?Rscript at the R prompt] if you haven't already.

In my opinion, there are pros and cons to William Dunlap's suggestion to embed everything in functions in a package. I do it either way, depending on various factors. I would suggest, however, that you wait until you have more R experience before trying that route.

Incidentally, this construct:

  fileConn<-file("output.txt") 
  writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods), fileConn)
  close(fileConn)

looks to me like it's more complex than needed.
I would suggest

  cat( TotalDeviation, IndividualDeviation, RecenterPeriods, '\n', file='output.txt')


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/12/18, 7:33 PM, "R-help on behalf of Sam Tuck" <r-help-bounces at r-project.org on behalf of STuck at nzsuperfund.co.nz> wrote:

    Hi All,
              I am new to R and am wondering if there is a way to pass arguments between rscripts.  I have this working but have had to create a C# shell calling the scripts in sequence via windows scripting which enables command line arguments to get the necessary interaction.  
    
    I'm wondering if I'm using an outdated program construction technique - I create r files like I would programme functions or reoccurring code snippets in C.  It may be that r was not designed to create lots of little r script modules that interact via a master script? 
    
    Ideally I'd like to call r scripts from other r scripts and have all the variables still in memory: For example
    
    I've been using RStudio Version 1.1.447 to programme and regression test my individual scripts,. 
    
    Script Arg Script.R
    {
    # We are going to pass arguments into this script
    arguments <- commandArgs(trailingOnly = TRUE)
    #arguments[1] is double
    #arguments[2] is double
    #arguments[3] is double.
    if(length(arguments) <3) 
    {
      stop("Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter")
    }
    TotalDeviation <- as.numeric(arguments[1])/100
    IndividualDeviation <- as.numeric(arguments[2])/100
    RecenterPeriods <- as.numeric(arguments[3])
    # We then manipulate some objects based on these inputs, but for this test we will output them to a file. 
    fileConn<-file("output.txt")
    writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods), fileConn)
    close(fileConn)
    }
    Script RunningScript.R
    {
    Arg Script.R 0.6 0.4 132
    }
    
    To which I get
    Error: unexpected symbol in " Arg Script.R"
    
    When I use the script RunningScript.R
    {
    system(paste("Arg Script.R", 0.8, 0.4, 132))
    }
    Nothing occurs (there is no output file created, but also no error)
    
    When I use RunningScript.R
    {
    commandArgs <- c(0.6,0.4,132)
    source("Arg Script.R')
    }
    I don't get any args passed into the file.  Instead getting the error 
    Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter
    
    Thanks
    
    Sam Tuck 
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @ez@reb@ki @ending from gm@il@com  Thu Jun 14 00:55:32 2018
From: @ez@reb@ki @ending from gm@il@com (Alex Zarebski)
Date: Thu, 14 Jun 2018 08:55:32 +1000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
 <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
Message-ID: <CAKsw2nFfgkXkUGCOMKp-MQi7ALJ+YPMVX5A8ZBKgiAKD-wf6Bg@mail.gmail.com>

Sourcing scripts is a bit hacky but it is a quick way to get a job done.
If you want to take your source-ing to the next level you might want to
look up how to use the "local" argument with environments.

Packages are probably the way to go if you are doing anything substantial
though.

Also, "argparse" (available through CRAN) provides some tools for parsing
command line arguments.
It is very similar to the python package of the same name which might be
more familiar.

Cheers,
Alex

On Thu, Jun 14, 2018 at 2:27 AM, William Dunlap via R-help <
r-help at r-project.org> wrote:

> Use functions calling functions instead of scripts invoking scripts.  Put
> all your
> functions in a 'package'.  Then your scripts would be very small, just
> passing
> command line arguments to R functions.
>
> (It is possible to call scripts from scripts, but I think it quickly leads
> to headaches.)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Jun 12, 2018 at 7:33 PM, Sam Tuck <STuck at nzsuperfund.co.nz> wrote:
>
> > Hi All,
> >           I am new to R and am wondering if there is a way to pass
> > arguments between rscripts.  I have this working but have had to create a
> > C# shell calling the scripts in sequence via windows scripting which
> > enables command line arguments to get the necessary interaction.
> >
> > I'm wondering if I'm using an outdated program construction technique - I
> > create r files like I would programme functions or reoccurring code
> > snippets in C.  It may be that r was not designed to create lots of
> little
> > r script modules that interact via a master script?
> >
> > Ideally I'd like to call r scripts from other r scripts and have all the
> > variables still in memory: For example
> >
> > I've been using RStudio Version 1.1.447 to programme and regression test
> > my individual scripts,.
> >
> > Script Arg Script.R
> > {
> > # We are going to pass arguments into this script
> > arguments <- commandArgs(trailingOnly = TRUE)
> > #arguments[1] is double
> > #arguments[2] is double
> > #arguments[3] is double.
> > if(length(arguments) <3)
> > {
> >   stop("Not enough arguments, please supply 3, [% dbl}total deviation, [%
> > dbl] individual deviation, [int] periods before recenter")
> > }
> > TotalDeviation <- as.numeric(arguments[1])/100
> > IndividualDeviation <- as.numeric(arguments[2])/100
> > RecenterPeriods <- as.numeric(arguments[3])
> > # We then manipulate some objects based on these inputs, but for this
> test
> > we will output them to a file.
> > fileConn<-file("output.txt")
> > writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
> > fileConn)
> > close(fileConn)
> > }
> > Script RunningScript.R
> > {
> > Arg Script.R 0.6 0.4 132
> > }
> >
> > To which I get
> > Error: unexpected symbol in " Arg Script.R"
> >
> > When I use the script RunningScript.R
> > {
> > system(paste("Arg Script.R", 0.8, 0.4, 132))
> > }
> > Nothing occurs (there is no output file created, but also no error)
> >
> > When I use RunningScript.R
> > {
> > commandArgs <- c(0.6,0.4,132)
> > source("Arg Script.R')
> > }
> > I don't get any args passed into the file.  Instead getting the error
> > Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl]
> > individual deviation, [int] periods before recenter
> >
> > Thanks
> >
> > Sam Tuck
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Thu Jun 14 02:30:13 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 14 Jun 2018 10:30:13 +1000
Subject: [R] Data frame with Factor column missing data change to NA
In-Reply-To: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>

Hi Bill,
It may be that the NonAcceptanceOther, being a character value, has ""
(0 length string) rather than NA. You can convert that to NA like
this:

df2$NonAcceptanceOther[nchar(df2$NonAcceptanceOther) == 0]<-NA

Jim


On Thu, Jun 14, 2018 at 12:47 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> Good morning.
>
> #I have df with a Factor column called "NonAcceptanceOther" that contains missing data.
>
> #Not every record in the df is expected to have a value in this column.
>
> # Typical values look like:
> # ERS
> # Claim paid without PHX recommended savings
> # Claim paid without PHX recommended savings
> # MRC Amount
> # MRC Amount
> # PPO per provider
> #Or they are missing (blank)
>
> #Example
>
> df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
> head(df2, n=20)
>
>    PlaceOfService ClaimStatusID                         NonAcceptanceOther RejectionCodeID          CPTCats     RevCodeCats GCode2 ClaimTypeID
>
> 1              11             2                                                         NA          ResPSys NotValidRevCode      2           2
>
> 2              81             3                                                         53       PathandLab NotValidRevCode      2           2
>
> 3              11             3                                                         47         Medicine NotValidRevCode      1           2
>
> 4              09             2                                                         NA           NotCPT NotValidRevCode      1           2
>
> 5              11             2                                                         NA        Radiology NotValidRevCode      2           2
>
> 6              23             2                                                         NA       MusculoSys NotValidRevCode      2           2
>
> 7              12             3                                                         47           NotCPT NotValidRevCode      2           2
>
> 8              12             2                                                         NA         Medicine NotValidRevCode      2           2
>
> 9              11             3                                                         47         Medicine NotValidRevCode      1           2
>
> 10             21             2                                                         NA       Anesthesia NotValidRevCode      2           2
>
> 11             11             3                                        ERS              30      EvalandMgmt NotValidRevCode      2           2
>
> 12             81             2                                                         NA       PathandLab NotValidRevCode      2           2
>
> 13             21             2                                                         NA        Radiology NotValidRevCode      1           2
>
> 14             11             2                                                         NA         Medicine NotValidRevCode      1           2
>
> 15             99             3 Claim paid without PHX recommended savings              30 CardioHemLympSys             Lab      0           1
>
> 16             99             3 Claim paid without PHX recommended savings              30       PathandLab             Lab      0           1
>
> 17             99             3                                 MRC Amount              30           NotCPT          Pharma      2           1
>
> 18             99             3                                 MRC Amount              30       PathandLab             Lab      2           1
>
> 19             81             2                                                         NA       PathandLab NotValidRevCode      2           2
>
> 20             23             2                                                         NA         IntegSys NotValidRevCode      1           2
>
> #I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.
>
> #I have tried several approaches from Googled references:
>
> NonAcceptanceOther <- df$NonAcceptanceOther
> table(addNA(NonAcceptanceOther))
>
> is.na <- df$NonAcceptanceOther
>
> df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA
>
> #However, when I go to use:
>
> missingDF <- PlotMissing(df)
>
> #Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID)  and this "NonAcceptanceOther" column does not reflect or hold the NA values?
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jun 14 04:03:39 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 13 Jun 2018 16:03:39 -1000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
 <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
Message-ID: <E797D790-F907-47C7-8DD4-C77674EE7D69@dcn.davis.ca.us>

I echo Bill's sentiments regarding use of functions, but think that you can afford to delay building packages while you are in the exploratory phase.

You can start out by building your sequence of statements using explicitly defined variables at the beginning like

fname <- "test.csv"
#your code

and then wrap the statements into functions using those fname as a parameter:

myfunc <- function( fname ) {
   # your code
}

Functions are written in files, but loaded into (typically) the global variables environment to be used.

RStudio helps incentivise working with functions by supporting debugging in the original source code if you source the entire file. Just mark the function

debug(myfunc)

before running code the directly or indirectly runs that function.

(Debugging works at the terminal console as well, but it only shows you the next line so you have to keep track of where you are in the function yourself.)

Once you have a lot of useful functions available, you will find making packages to be a way better approach to handling code re-use than keeping track of script files.

On June 13, 2018 6:27:10 AM HST, William Dunlap via R-help <r-help at r-project.org> wrote:
>Use functions calling functions instead of scripts invoking scripts. 
>Put
>all your
>functions in a 'package'.  Then your scripts would be very small, just
>passing
>command line arguments to R functions.
>
>(It is possible to call scripts from scripts, but I think it quickly
>leads
>to headaches.)
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Tue, Jun 12, 2018 at 7:33 PM, Sam Tuck <STuck at nzsuperfund.co.nz>
>wrote:
>
>> Hi All,
>>           I am new to R and am wondering if there is a way to pass
>> arguments between rscripts.  I have this working but have had to
>create a
>> C# shell calling the scripts in sequence via windows scripting which
>> enables command line arguments to get the necessary interaction.
>>
>> I'm wondering if I'm using an outdated program construction technique
>- I
>> create r files like I would programme functions or reoccurring code
>> snippets in C.  It may be that r was not designed to create lots of
>little
>> r script modules that interact via a master script?
>>
>> Ideally I'd like to call r scripts from other r scripts and have all
>the
>> variables still in memory: For example
>>
>> I've been using RStudio Version 1.1.447 to programme and regression
>test
>> my individual scripts,.
>>
>> Script Arg Script.R
>> {
>> # We are going to pass arguments into this script
>> arguments <- commandArgs(trailingOnly = TRUE)
>> #arguments[1] is double
>> #arguments[2] is double
>> #arguments[3] is double.
>> if(length(arguments) <3)
>> {
>>   stop("Not enough arguments, please supply 3, [% dbl}total
>deviation, [%
>> dbl] individual deviation, [int] periods before recenter")
>> }
>> TotalDeviation <- as.numeric(arguments[1])/100
>> IndividualDeviation <- as.numeric(arguments[2])/100
>> RecenterPeriods <- as.numeric(arguments[3])
>> # We then manipulate some objects based on these inputs, but for this
>test
>> we will output them to a file.
>> fileConn<-file("output.txt")
>> writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
>> fileConn)
>> close(fileConn)
>> }
>> Script RunningScript.R
>> {
>> Arg Script.R 0.6 0.4 132
>> }
>>
>> To which I get
>> Error: unexpected symbol in " Arg Script.R"
>>
>> When I use the script RunningScript.R
>> {
>> system(paste("Arg Script.R", 0.8, 0.4, 132))
>> }
>> Nothing occurs (there is no output file created, but also no error)
>>
>> When I use RunningScript.R
>> {
>> commandArgs <- c(0.6,0.4,132)
>> source("Arg Script.R')
>> }
>> I don't get any args passed into the file.  Instead getting the error
>> Not enough arguments, please supply 3, [% dbl}total deviation, [%
>dbl]
>> individual deviation, [int] periods before recenter
>>
>> Thanks
>>
>> Sam Tuck
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @t@t@@@tudent4647 @ending from gm@il@com  Thu Jun 14 04:43:21 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Wed, 13 Jun 2018 19:43:21 -0700
Subject: [R] Storing tableGrobs in a list
Message-ID: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>

Hi, I'm trying to generate tableGrobs in a loop, store them in a list so I
can use it in a call to gtable_combine().

L1<-list()
for (i in seq( ... )) {
   L1[i] <-tableGrob( ... )
}

gtable_combine(L1, along=1)

On the assignment inside the loop, I get "number of items to replace is not
a multiple of replacement length" which I'm guessing has to do with the
tableGrob object not "fitting" in the list but am not sure how to fix it.

Thanks in advance for any pointers.

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jun 14 08:01:28 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 13 Jun 2018 20:01:28 -1000
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
Message-ID: <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>

?`[[`

and read the discussions of indexing in the Introduction to R document that comes with R. Also, find a way to predict the number of elements you will need as making this a habit will pay off big time when you work with large amounts of data:

L1<-vector( "list", N )
for (i in seq.int( N )) {
   L1[[i]] <-tableGrob( ... )
}

PS Post using your email program "plain text" mode... HTML gets stripped anyway and that often leads to partial corruption of your message. Read the Posting Guide.

On June 13, 2018 4:43:21 PM HST, Stats Student <stats.student4647 at gmail.com> wrote:
>Hi, I'm trying to generate tableGrobs in a loop, store them in a list
>so I
>can use it in a call to gtable_combine().
>
>L1<-list()
>for (i in seq( ... )) {
>   L1[i] <-tableGrob( ... )
>}
>
>gtable_combine(L1, along=1)
>
>On the assignment inside the loop, I get "number of items to replace is
>not
>a multiple of replacement length" which I'm guessing has to do with the
>tableGrob object not "fitting" in the list but am not sure how to fix
>it.
>
>Thanks in advance for any pointers.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From Bill@Poling @ending from zeli@@com  Thu Jun 14 12:48:48 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 14 Jun 2018 10:48:48 +0000
Subject: [R] Data frame with Factor column missing data change to NA
In-Reply-To: <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>
References: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>
Message-ID: <CY1PR0201MB183445F2EA5570D097DAC6E9EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>

#Good morning Jim, thank you for your response and guidance.


So I ran the suggested and got: Error in nchar(df2$NonAcceptanceOther) :   'nchar()' requires a character vector

So I ran this:

df2$NonAcceptanceOther[] <- lapply(df2$NonAcceptanceOther,as.character)

#Then tried again.

#But still getting the error?

#Because the column remains a factor?
names(df2)

#[1] "PlaceOfService"     "ClaimStatusID"      "NonAcceptanceOther" "RejectionCodeID"    "CPTCats"            "RevCodeCats"        "GCode2"             "ClaimTypeID"

classes <- as.character(sapply(df2, class))
classes


#[1] "factor"  "integer" "factor"  "integer" "factor"  "factor"  "integer" "integer"



#Not sure if this structure helps, I guess that the 1L?s are the missing

dput(head(df2$NonAcceptanceOther, 25))

#structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 118L, 1L,

#1L, 1L, 64L, 64L, 134L, 134L, 1L, 1L, 1L, 1L, 1L, 1L, 1L)



#View from the CSV file original data


NonAcceptanceOther











ERS




Claim paid without PHX recommended savings

Claim paid without PHX recommended savings

MRC Amount

MRC Amount









Appreciate your help Sir.

WHP

From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: Wednesday, June 13, 2018 8:30 PM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Data frame with Factor column missing data change to NA

Hi Bill,
It may be that the NonAcceptanceOther, being a character value, has ""
(0 length string) rather than NA. You can convert that to NA like
this:

df2$NonAcceptanceOther[nchar(df2$NonAcceptanceOther) == 0]<-NA

Jim


On Thu, Jun 14, 2018 at 12:47 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
> Good morning.
>
> #I have df with a Factor column called "NonAcceptanceOther" that contains missing data.
>
> #Not every record in the df is expected to have a value in this column.
>
> # Typical values look like:
> # ERS
> # Claim paid without PHX recommended savings
> # Claim paid without PHX recommended savings
> # MRC Amount
> # MRC Amount
> # PPO per provider
> #Or they are missing (blank)
>
> #Example
>
> df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
> head(df2, n=20)
>
> PlaceOfService ClaimStatusID NonAcceptanceOther RejectionCodeID CPTCats RevCodeCats GCode2 ClaimTypeID
>
> 1 11 2 NA ResPSys NotValidRevCode 2 2
>
> 2 81 3 53 PathandLab NotValidRevCode 2 2
>
> 3 11 3 47 Medicine NotValidRevCode 1 2
>
> 4 09 2 NA NotCPT NotValidRevCode 1 2
>
> 5 11 2 NA Radiology NotValidRevCode 2 2
>
> 6 23 2 NA MusculoSys NotValidRevCode 2 2
>
> 7 12 3 47 NotCPT NotValidRevCode 2 2
>
> 8 12 2 NA Medicine NotValidRevCode 2 2
>
> 9 11 3 47 Medicine NotValidRevCode 1 2
>
> 10 21 2 NA Anesthesia NotValidRevCode 2 2
>
> 11 11 3 ERS 30 EvalandMgmt NotValidRevCode 2 2
>
> 12 81 2 NA PathandLab NotValidRevCode 2 2
>
> 13 21 2 NA Radiology NotValidRevCode 1 2
>
> 14 11 2 NA Medicine NotValidRevCode 1 2
>
> 15 99 3 Claim paid without PHX recommended savings 30 CardioHemLympSys Lab 0 1
>
> 16 99 3 Claim paid without PHX recommended savings 30 PathandLab Lab 0 1
>
> 17 99 3 MRC Amount 30 NotCPT Pharma 2 1
>
> 18 99 3 MRC Amount 30 PathandLab Lab 2 1
>
> 19 81 2 NA PathandLab NotValidRevCode 2 2
>
> 20 23 2 NA IntegSys NotValidRevCode 1 2
>
> #I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.
>
> #I have tried several approaches from Googled references:
>
> NonAcceptanceOther <- df$NonAcceptanceOther
> table(addNA(NonAcceptanceOther))
>
> is.na<http://is.na> <- df$NonAcceptanceOther
>
> df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA
>
> #However, when I go to use:
>
> missingDF <- PlotMissing(df)
>
> #Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID) and this "NonAcceptanceOther" column does not reflect or hold the NA values?
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From bori@@@teipe @ending from utoronto@c@  Thu Jun 14 14:52:53 2018
From: bori@@@teipe @ending from utoronto@c@ (Boris Steipe)
Date: Thu, 14 Jun 2018 08:52:53 -0400
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
Message-ID: <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>

Keep replies on list please.

You are not accessing a value from vector Q if you access the zero'th element!
R > Q <- c(3, 5, 8)
R > Q[0]
numeric(0)
R > Q[1]
[1] 3
R > Q[2]
[1] 5

In the first iteration of the loop j is 2 thus j-2 is 0 and that's the reason for the error message: you are trying to replace a matrix element with a zero-length (i.e. unassigned) numeric value. Perhaps, in your mind, you are mixing up the index of a vector element and its value? If you need two zeros to start your vector, do something like

R > Q <- c(0, 0, Q)
R > Q
[1] 0 0 3 5 8


Clear now?
B.



> On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
> 
> Many thanks for your message! 
> 
> The thing is that I need  Q[j-2] to be zero for the first two iterations because I don't have those values (J starts from 1). Do you have any idea how to do it?
> 
> Thanks again!
> 
> Maija
> 
> 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> Q[j-2] gives you Q[0] in your first inner loop iteration.
> R arrays start at one. 
> 
> B.
> 
> 
> > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
> > 
> >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> 
> 


From kevin@thorpe @ending from utoronto@c@  Thu Jun 14 15:55:21 2018
From: kevin@thorpe @ending from utoronto@c@ (Kevin E. Thorpe)
Date: Thu, 14 Jun 2018 09:55:21 -0400
Subject: [R] Trouble with tibbles
Message-ID: <1387723f-be10-5b3d-4047-5cc03041786e@utoronto.ca>

I am trying to learn and use the tidyverse tools and one peculiarity 
that I seem to encounter is that converting some data frames to tibbles 
gives surprising results. I tried to make a toy example illustrates the 
problem but couldn't. Let me show some output that illustrates the problem.

 > str(bincrct)
'data.frame':	267 obs. of  4 variables:
  $ StudyID     : num  20101 20102 20103 20104 20105 ...
  $ Intervention: Factor w/ 2 levels "Intervention",..: 2 2 2 2 2 1 1 1 
1 1 ...
  $ Cluster     : num  1 1 1 1 1 2 2 2 2 3 ...
  $ apptx       : num  0 0 1 0 0 1 1 1 0 1 ...
 > as_tibble(bincrct)
Error: `x` must be a numeric or a character vector
 > str(as_tibble(bincrct))
Classes ?tbl_df?, ?tbl? and 'data.frame':	267 obs. of  4 variables:
  $ StudyID     : num  20101 20102 20103 20104 20105 ...
  $ Intervention: Factor w/ 2 levels "Intervention",..: 2 2 2 2 2 1 1 1 
1 1 ...
  $ Cluster     : num  1 1 1 1 1 2 2 2 2 3 ...
  $ apptx       : num  0 0 1 0 0 1 1 1 0 1 ...

When I tried to create a data frame and run as_tibble() on it, things 
behaved correctly. My best guess is that the old data frame I am using 
has some additional baggage with it that I am unaware of.

I also tried manually creating a tibble as follows which also did not work.

 > with(bincrct, tibble(StudyID,Intervention,Cluster,apptx))
Error: `x` must be a numeric or a character vector

Any ideas? Here is my sessionInfo(). I just updated my packages this 
morning to see if that was the issue.

 > sessionInfo()
R version 3.5.0 Patched (2018-04-23 r74633)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Slackware 14.2 x86_64 (post 14.2 -current)

Matrix products: default
BLAS: /usr/local/lib64/R/lib/libRblas.so
LAPACK: /usr/local/lib64/R/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] forcats_0.3.0   stringr_1.3.1   dplyr_0.7.5     purrr_0.2.5
  [5] readr_1.1.1     tidyr_0.8.1     tibble_1.4.2    ggplot2_2.2.1
  [9] tidyverse_1.2.1 knitr_1.20

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.17     cellranger_1.1.0 pillar_1.2.3     compiler_3.5.0
  [5] plyr_1.8.4       bindr_0.1.1      tools_3.5.0      lubridate_1.7.4
  [9] jsonlite_1.5     nlme_3.1-137     gtable_0.2.0     lattice_0.20-35
[13] pkgconfig_2.0.1  rlang_0.2.1      psych_1.8.4      cli_1.0.0
[17] rstudioapi_0.7   parallel_3.5.0   haven_1.1.1      bindrcpp_0.2.2
[21] xml2_1.2.0       httr_1.3.1       hms_0.4.2        grid_3.5.0
[25] tidyselect_0.2.4 glue_1.2.0       R6_2.2.2         readxl_1.1.0
[29] foreign_0.8-70   modelr_0.1.2     reshape2_1.4.3   magrittr_1.5
[33] scales_0.5.0     rvest_0.3.2      assertthat_0.2.0 mnormt_1.5-5
[37] colorspace_1.3-2 stringi_1.2.3    lazyeval_0.2.1   munsell_0.5.0
[41] broom_0.4.4      crayon_1.3.4


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016


From Bill@Poling @ending from zeli@@com  Thu Jun 14 16:01:42 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Thu, 14 Jun 2018 14:01:42 +0000
Subject: [R] Data frame with Factor column missing data change to NA
In-Reply-To: <CY1PR0201MB183445F2EA5570D097DAC6E9EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>
 <CY1PR0201MB183445F2EA5570D097DAC6E9EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CY1PR0201MB1834796983107420F88F6CF2EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Jim,
Actually, I got this to work.

df$NonAcceptanceOther[df$NonAcceptanceOther==""]<- NA
df$NonAcceptanceOther

missingDF <- plot_missing(df)

# missingDF
#                  feature                num_missing   pct_missing    group
# 13 NonAcceptanceOther       26157       0.86859932257 Remove


Good to go now, for the moment, big smile!

Thank you for your help Sir.


WHP




From: Bill Poling
Sent: Thursday, June 14, 2018 6:49 AM
To: 'Jim Lemon' <drjimlemon at gmail.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: RE: [R] Data frame with Factor column missing data change to NA

#Good morning Jim, thank you for your response and guidance.


So I ran the suggested and got: Error in nchar(df2$NonAcceptanceOther) :   'nchar()' requires a character vector

So I ran this:

df2$NonAcceptanceOther[] <- lapply(df2$NonAcceptanceOther,as.character)

#Then tried again.

#But still getting the error?

#Because the column remains a factor?
names(df2)

#[1] "PlaceOfService"     "ClaimStatusID"      "NonAcceptanceOther" "RejectionCodeID"    "CPTCats"            "RevCodeCats"        "GCode2"             "ClaimTypeID"

classes <- as.character(sapply(df2, class))
classes


#[1] "factor"  "integer" "factor"  "integer" "factor"  "factor"  "integer" "integer"



#Not sure if this structure helps, I guess that the 1L?s are the missing

dput(head(df2$NonAcceptanceOther, 25))

#structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 118L, 1L,

#1L, 1L, 64L, 64L, 134L, 134L, 1L, 1L, 1L, 1L, 1L, 1L, 1L)



#View from the CSV file original data


NonAcceptanceOther











ERS




Claim paid without PHX recommended savings

Claim paid without PHX recommended savings

MRC Amount

MRC Amount









Appreciate your help Sir.

WHP

From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: Wednesday, June 13, 2018 8:30 PM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Cc: r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Data frame with Factor column missing data change to NA

Hi Bill,
It may be that the NonAcceptanceOther, being a character value, has ""
(0 length string) rather than NA. You can convert that to NA like
this:

df2$NonAcceptanceOther[nchar(df2$NonAcceptanceOther) == 0]<-NA

Jim


On Thu, Jun 14, 2018 at 12:47 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
> Good morning.
>
> #I have df with a Factor column called "NonAcceptanceOther" that contains missing data.
>
> #Not every record in the df is expected to have a value in this column.
>
> # Typical values look like:
> # ERS
> # Claim paid without PHX recommended savings
> # Claim paid without PHX recommended savings
> # MRC Amount
> # MRC Amount
> # PPO per provider
> #Or they are missing (blank)
>
> #Example
>
> df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
> head(df2, n=20)
>
> PlaceOfService ClaimStatusID NonAcceptanceOther RejectionCodeID CPTCats RevCodeCats GCode2 ClaimTypeID
>
> 1 11 2 NA ResPSys NotValidRevCode 2 2
>
> 2 81 3 53 PathandLab NotValidRevCode 2 2
>
> 3 11 3 47 Medicine NotValidRevCode 1 2
>
> 4 09 2 NA NotCPT NotValidRevCode 1 2
>
> 5 11 2 NA Radiology NotValidRevCode 2 2
>
> 6 23 2 NA MusculoSys NotValidRevCode 2 2
>
> 7 12 3 47 NotCPT NotValidRevCode 2 2
>
> 8 12 2 NA Medicine NotValidRevCode 2 2
>
> 9 11 3 47 Medicine NotValidRevCode 1 2
>
> 10 21 2 NA Anesthesia NotValidRevCode 2 2
>
> 11 11 3 ERS 30 EvalandMgmt NotValidRevCode 2 2
>
> 12 81 2 NA PathandLab NotValidRevCode 2 2
>
> 13 21 2 NA Radiology NotValidRevCode 1 2
>
> 14 11 2 NA Medicine NotValidRevCode 1 2
>
> 15 99 3 Claim paid without PHX recommended savings 30 CardioHemLympSys Lab 0 1
>
> 16 99 3 Claim paid without PHX recommended savings 30 PathandLab Lab 0 1
>
> 17 99 3 MRC Amount 30 NotCPT Pharma 2 1
>
> 18 99 3 MRC Amount 30 PathandLab Lab 2 1
>
> 19 81 2 NA PathandLab NotValidRevCode 2 2
>
> 20 23 2 NA IntegSys NotValidRevCode 1 2
>
> #I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.
>
> #I have tried several approaches from Googled references:
>
> NonAcceptanceOther <- df$NonAcceptanceOther
> table(addNA(NonAcceptanceOther))
>
> is.na<http://is.na> <- df$NonAcceptanceOther
>
> df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA
>
> #However, when I go to use:
>
> missingDF <- PlotMissing(df)
>
> #Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID) and this "NonAcceptanceOther" column does not reflect or hold the NA values?
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @ending from gm@il@com  Thu Jun 14 20:07:19 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Thu, 14 Jun 2018 11:07:19 -0700
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
 <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
Message-ID: <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>

Thanks for the replies. Wasn't aware that Gmail on Android sent HTML by
default, apologies. 

Storing the tableGrob-s in a list worked but for some reason grid.arrange complains on output from gtable_combine() using lists vs individual tableGrob-s. 

# works when supplying individual tableGrobs

p1<-gtable_combine(p11,p22, along=2)
p2<-gtable_combine(p11,p22, along=2)
grid.arrange(p1,p2,ncol=2)

# breaks when supplying a list of tableGrobs, error from grid.arrange()

p1<-gtable_combine(L1,along=2)
p2<-gtable_combine(L2,along=2)

grid.arrange(p1,p2,ncol=2)

Error in gList(list(list(grobs = list(list(label = "status", x = 0.5,? : 
? only 'grobs' allowed in "gList"

Also tried, still no go 

p1<-do.call(gtable_combine, list(L1,along=2))
p2<-do.call(gtable_combine, list(L2,along=2))




On Jun 13, 2018, 11:01 PM, at 11:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>?`[[`
>
>and read the discussions of indexing in the Introduction to R document
>that comes with R. Also, find a way to predict the number of elements
>you will need as making this a habit will pay off big time when you
>work with large amounts of data:
>
>L1<-vector( "list", N )
>for (i in seq.int( N )) {
>   L1[[i]] <-tableGrob( ... )
>}
>
>PS Post using your email program "plain text" mode... HTML gets
>stripped anyway and that often leads to partial corruption of your
>message. Read the Posting Guide.
>
>On June 13, 2018 4:43:21 PM HST, Stats Student
><stats.student4647 at gmail.com> wrote:
>>Hi, I'm trying to generate tableGrobs in a loop, store them in a list
>>so I
>>can use it in a call to gtable_combine().
>>
>>L1<-list()
>>for (i in seq( ... )) {
>>   L1[i] <-tableGrob( ... )
>>}
>>
>>gtable_combine(L1, along=1)
>>
>>On the assignment inside the loop, I get "number of items to replace
>is
>>not
>>a multiple of replacement length" which I'm guessing has to do with
>the
>>tableGrob object not "fitting" in the list but am not sure how to fix
>>it.
>>
>>Thanks in advance for any pointers.
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Sent from my phone. Please excuse my brevity.


From profjcn@@h @ending from gm@il@com  Thu Jun 14 20:24:16 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Thu, 14 Jun 2018 14:24:16 -0400
Subject: [R] rJava woes on Linux Mint 18.3 Sylvia
Message-ID: <f380bbb0-d655-a0f7-046b-baa5cb37e801@gmail.com>

Answering my own post. On the particular machine in question, I managed to install rJava after installing
(in the OS) libbz2-dev and liblzma-dev. There was a hint of this in the install output,
but not as clear as would help a novice.

JN


From reichm@nj @ending from @bcglob@l@net  Thu Jun 14 22:04:26 2018
From: reichm@nj @ending from @bcglob@l@net (JEFFERY REICHMAN)
Date: Thu, 14 Jun 2018 20:04:26 +0000 (UTC)
Subject: [R] Kendall tau a, b, or c
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
Message-ID: <1241157164.481576.1529006666994@mail.yahoo.com>

r-help Forum

Is there a function to calculate either Kendall tau a, b, or c.  It appears the Kendall library only calculates tau b.  Just wanted to check before writing a function to calculate the concordant and discordant pairs. Then its pretty easy.

jeff


From m@rc_@chw@rtz @ending from me@com  Thu Jun 14 23:06:38 2018
From: m@rc_@chw@rtz @ending from me@com (Marc Schwartz)
Date: Thu, 14 Jun 2018 17:06:38 -0400
Subject: [R] Kendall tau a, b, or c
In-Reply-To: <1241157164.481576.1529006666994@mail.yahoo.com>
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
 <1241157164.481576.1529006666994@mail.yahoo.com>
Message-ID: <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>


> On Jun 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net> wrote:
> 
> r-help Forum
> 
> Is there a function to calculate either Kendall tau a, b, or c.  It appears the Kendall library only calculates tau b.  Just wanted to check before writing a function to calculate the concordant and discordant pairs. Then its pretty easy.
> 
> jeff
> 


Hi Jeff,

Take a look at my Github Gist here:

 https://gist.github.com/marcschwartz/3665743

I have b and c (among other measures), and supporting functions to calculate concordant and discordant pairs.

Regards,

Marc Schwartz


From reichm@nj @ending from @bcglob@l@net  Thu Jun 14 23:19:27 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Thu, 14 Jun 2018 16:19:27 -0500
Subject: [R] Kendall tau a, b, or c
In-Reply-To: <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
 <1241157164.481576.1529006666994@mail.yahoo.com>
 <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>
Message-ID: <000001d40425$60fde4e0$22f9aea0$@sbcglobal.net>

Marc

Thank you - that will save me some time.

Jeff

-----Original Message-----
From: Marc Schwartz <marc_schwartz at me.com> 
Sent: Thursday, June 14, 2018 4:07 PM
To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>
Cc: R-help <r-help at R-project.org>
Subject: Re: [R] Kendall tau a, b, or c


> On Jun 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net>
wrote:
> 
> r-help Forum
> 
> Is there a function to calculate either Kendall tau a, b, or c.  It
appears the Kendall library only calculates tau b.  Just wanted to check
before writing a function to calculate the concordant and discordant pairs.
Then its pretty easy.
> 
> jeff
> 


Hi Jeff,

Take a look at my Github Gist here:

 https://gist.github.com/marcschwartz/3665743

I have b and c (among other measures), and supporting functions to calculate
concordant and discordant pairs.

Regards,

Marc Schwartz


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Jun 15 03:30:33 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 14 Jun 2018 15:30:33 -1000
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
 <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
 <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>
Message-ID: <0398F3BA-3D1E-4123-87CD-759FECE97849@dcn.davis.ca.us>

I don't know gtable_combine well enough to answer based on hand waving. A reproducible example is more likely to tempt someone to dig a little.

On June 14, 2018 8:07:19 AM HST, Stats Student <stats.student4647 at gmail.com> wrote:
>Thanks for the replies. Wasn't aware that Gmail on Android sent HTML by
>default, apologies.
>
>Storing the tableGrob-s in a list worked but for some reason
>grid.arrange complains on output from gtable_combine() using lists vs
>individual tableGrob-s.
>
># works when supplying individual tableGrobs
>
>p1<-gtable_combine(p11,p22, along=2)
>p2<-gtable_combine(p11,p22, along=2)
>grid.arrange(p1,p2,ncol=2)
>
># breaks when supplying a list of tableGrobs, error from grid.arrange()
>
>p1<-gtable_combine(L1,along=2)
>p2<-gtable_combine(L2,along=2)
>
>grid.arrange(p1,p2,ncol=2)
>
>Error in gList(list(list(grobs = list(list(label = "status", x = 0.5,?
>: 
>? only 'grobs' allowed in "gList"
>
>Also tried, still no go
>
>p1<-do.call(gtable_combine, list(L1,along=2))
>p2<-do.call(gtable_combine, list(L2,along=2))
>
>
>
>
>On Jun 13, 2018, 11:01 PM, at 11:01 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>?`[[`
>>
>>and read the discussions of indexing in the Introduction to R document
>>that comes with R. Also, find a way to predict the number of elements
>>you will need as making this a habit will pay off big time when you
>>work with large amounts of data:
>>
>>L1<-vector( "list", N )
>>for (i in seq.int( N )) {
>>   L1[[i]] <-tableGrob( ... )
>>}
>>
>>PS Post using your email program "plain text" mode... HTML gets
>>stripped anyway and that often leads to partial corruption of your
>>message. Read the Posting Guide.
>>
>>On June 13, 2018 4:43:21 PM HST, Stats Student
>><stats.student4647 at gmail.com> wrote:
>>>Hi, I'm trying to generate tableGrobs in a loop, store them in a list
>>>so I
>>>can use it in a call to gtable_combine().
>>>
>>>L1<-list()
>>>for (i in seq( ... )) {
>>>   L1[i] <-tableGrob( ... )
>>>}
>>>
>>>gtable_combine(L1, along=1)
>>>
>>>On the assignment inside the loop, I get "number of items to replace
>>is
>>>not
>>>a multiple of replacement length" which I'm guessing has to do with
>>the
>>>tableGrob object not "fitting" in the list but am not sure how to fix
>>>it.
>>>
>>>Thanks in advance for any pointers.
>>>
>>>	[[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>--
>>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.


From @t@t@@@tudent4647 @ending from gm@il@com  Fri Jun 15 03:42:02 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Thu, 14 Jun 2018 18:42:02 -0700
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <0398F3BA-3D1E-4123-87CD-759FECE97849@dcn.davis.ca.us>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
 <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
 <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>
 <0398F3BA-3D1E-4123-87CD-759FECE97849@dcn.davis.ca.us>
Message-ID: <490dd737-6f65-4d4d-baf1-8830a95373ec@gmail.com>

Thanks. The trick was in the do.call() syntax -

p1<-do.call(gtable_combine, c(L1, list(along=2)))



On Jun 14, 2018, 6:30 PM, at 6:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>I don't know gtable_combine well enough to answer based on hand waving.
>A reproducible example is more likely to tempt someone to dig a little.
>
>On June 14, 2018 8:07:19 AM HST, Stats Student
><stats.student4647 at gmail.com> wrote:
>>Thanks for the replies. Wasn't aware that Gmail on Android sent HTML
>by
>>default, apologies.
>>
>>Storing the tableGrob-s in a list worked but for some reason
>>grid.arrange complains on output from gtable_combine() using lists vs
>>individual tableGrob-s.
>>
>># works when supplying individual tableGrobs
>>
>>p1<-gtable_combine(p11,p22, along=2)
>>p2<-gtable_combine(p11,p22, along=2)
>>grid.arrange(p1,p2,ncol=2)
>>
>># breaks when supplying a list of tableGrobs, error from
>grid.arrange()
>>
>>p1<-gtable_combine(L1,along=2)
>>p2<-gtable_combine(L2,along=2)
>>
>>grid.arrange(p1,p2,ncol=2)
>>
>>Error in gList(list(list(grobs = list(list(label = "status", x = 0.5,?
>>: 
>>? only 'grobs' allowed in "gList"
>>
>>Also tried, still no go
>>
>>p1<-do.call(gtable_combine, list(L1,along=2))
>>p2<-do.call(gtable_combine, list(L2,along=2))
>>
>>
>>
>>
>>On Jun 13, 2018, 11:01 PM, at 11:01 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>>?`[[`
>>>
>>>and read the discussions of indexing in the Introduction to R
>document
>>>that comes with R. Also, find a way to predict the number of elements
>>>you will need as making this a habit will pay off big time when you
>>>work with large amounts of data:
>>>
>>>L1<-vector( "list", N )
>>>for (i in seq.int( N )) {
>>>   L1[[i]] <-tableGrob( ... )
>>>}
>>>
>>>PS Post using your email program "plain text" mode... HTML gets
>>>stripped anyway and that often leads to partial corruption of your
>>>message. Read the Posting Guide.
>>>
>>>On June 13, 2018 4:43:21 PM HST, Stats Student
>>><stats.student4647 at gmail.com> wrote:
>>>>Hi, I'm trying to generate tableGrobs in a loop, store them in a
>list
>>>>so I
>>>>can use it in a call to gtable_combine().
>>>>
>>>>L1<-list()
>>>>for (i in seq( ... )) {
>>>>   L1[i] <-tableGrob( ... )
>>>>}
>>>>
>>>>gtable_combine(L1, along=1)
>>>>
>>>>On the assignment inside the loop, I get "number of items to replace
>>>is
>>>>not
>>>>a multiple of replacement length" which I'm guessing has to do with
>>>the
>>>>tableGrob object not "fitting" in the list but am not sure how to
>fix
>>>>it.
>>>>
>>>>Thanks in advance for any pointers.
>>>>
>>>>	[[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>>--
>>>Sent from my phone. Please excuse my brevity.
>
>-- 
>Sent from my phone. Please excuse my brevity.


From @k@h@y_e4 @ending from hotm@il@com  Fri Jun 15 13:18:38 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Fri, 15 Jun 2018 11:18:38 +0000
Subject: [R] inconsistency in parallel processing in R.....
Message-ID: <SLXP216MB00933EF9550FC45439D4C75EC87C0@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am using the "parallel" package in R. I am using the following function to automate the process of starting the cluster(the function is named preparePP):

function (vte) {
                nc <- detectCores()
                cl <- makeCluster(nc)
                clusterExport(cl,vte)
                clusterEvalQ(cl,{ld.packages()})


}
<bytecode: 0x0b787508>

vte is the character vector of variables to be exported and ld.packages is the function that loads all the required packages.

However, when I run the  preparePP function at the beginning of the session, it frequently throws up the following error:

Error in summary.connection(connection) : invalid connection

Sometimes the function stands but othertimes it throws up the above error. But when I run the individual functions of preparePP independently at the R console, the cluster object "cl" stays put for the whole session( parLapply works all the time it is called):

> nc <- detectCores()
> cl <- makeCluster(nc)
> clusterExport(cl,vte)
> clusterEvalQ(cl,{ld.packages()})

What is wrong with preparePP?

very many thanks for your time and effort.....

yours sincerely,
AKSHAY M KULKARNI







	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Fri Jun 15 15:31:55 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Fri, 15 Jun 2018 13:31:55 +0000
Subject: [R] Kendall tau a, b, or c
In-Reply-To: <000001d40425$60fde4e0$22f9aea0$@sbcglobal.net>
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
 <1241157164.481576.1529006666994@mail.yahoo.com>
 <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>
 <000001d40425$60fde4e0$22f9aea0$@sbcglobal.net>
Message-ID: <38af0f89b53e4d629ef70c53a5fd54af@tamu.edu>

Also look at the DescTools package for functions KendallTauA, KendallTauB, StuartTauC().  

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Thursday, June 14, 2018 4:19 PM
To: 'Marc Schwartz' <marc_schwartz at me.com>
Cc: 'R-help' <r-help at R-project.org>
Subject: Re: [R] Kendall tau a, b, or c

Marc

Thank you - that will save me some time.

Jeff

-----Original Message-----
From: Marc Schwartz <marc_schwartz at me.com> 
Sent: Thursday, June 14, 2018 4:07 PM
To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>
Cc: R-help <r-help at R-project.org>
Subject: Re: [R] Kendall tau a, b, or c


> On Jun 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net>
wrote:
> 
> r-help Forum
> 
> Is there a function to calculate either Kendall tau a, b, or c.  It
appears the Kendall library only calculates tau b.  Just wanted to check
before writing a function to calculate the concordant and discordant pairs.
Then its pretty easy.
> 
> jeff
> 


Hi Jeff,

Take a look at my Github Gist here:

 https://gist.github.com/marcschwartz/3665743

I have b and c (among other measures), and supporting functions to calculate
concordant and discordant pairs.

Regards,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From pelj@@z @ending from y@hoo@co@uk  Fri Jun 15 16:49:17 2018
From: pelj@@z @ending from y@hoo@co@uk (lejeczek)
Date: Fri, 15 Jun 2018 15:49:17 +0100
Subject: [R] mzR fails to install/compile (linuxes)
Message-ID: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>

hi guys, just an admin here.

I wonder if anybody see what I see, or similar? I'm on Centos 7.x and 
this occurs with R 3.4.x 3.5.x and probably earlier versions too.

Every time I use something like -j>1 to pass to a compiler, eg.echo -ne

$ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n 
source(\"https://bioconductor.org/biocLite.R\")\\n biocLite(c(\"mzR\"), 
suppressUpdates=FALSE, suppressAutoUpdate=FALSE, ask=FALSE)" | 
/usr/bin/R --vanilla

mzR fails to compile:
...
g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so 
cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o 
RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o 
./boost/libs/system/src/error_code.o ./boost/libs/regex/src/posix_api.o 
./boost/libs/regex/src/fileiter.o 
./boost/libs/regex/src/regex_raw_buffer.o 
./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o 
./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o 
./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o 
./boost/libs/regex/src/wide_posix_api.o 
./boost/libs/regex/src/regex_traits_defaults.o 
./boost/libs/regex/src/winstances.o 
./boost/libs/regex/src/wc_regex_traits.o 
./boost/libs/regex/src/c_regex_traits.o 
./boost/libs/regex/src/cpp_regex_traits.o 
./boost/libs/regex/src/static_mutex.o 
./boost/libs/regex/src/w32_regex_traits.o 
./boost/libs/iostreams/src/zlib.o 
./boost/libs/iostreams/src/file_descriptor.o 
./boost/libs/filesystem/src/operations.o 
./boost/libs/filesystem/src/path.o 
./boost/libs/filesystem/src/utf8_codecvt_facet.o 
./boost/libs/chrono/src/chrono.o 
./boost/libs/chrono/src/process_cpu_clocks.o 
./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o 
./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o 
./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o 
./pwiz/data/common/ParamTypes.o ./pwiz/data/common/BinaryIndexStream.o 
./pwiz/data/common/diff_std.o ./pwiz/data/common/Unimod.o 
./pwiz/data/msdata/mz5/Configuration_mz5.o 
./pwiz/data/msdata/mz5/Connection_mz5.o 
./pwiz/data/msdata/mz5/Datastructures_mz5.o 
./pwiz/data/msdata/mz5/ReferenceRead_mz5.o 
./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o 
./pwiz/data/msdata/mz5/Translator_mz5.o 
./pwiz/data/msdata/SpectrumList_MGF.o 
./pwiz/data/msdata/DefaultReaderList.o 
./pwiz/data/msdata/ChromatogramList_mzML.o 
./pwiz/data/msdata/ChromatogramList_mz5.o ./pwiz/data/msdata/examples.o 
./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o 
./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_mz5.o 
./pwiz/data/msdata/Serializer_MGF.o 
./pwiz/data/msdata/Serializer_mzXML.o 
./pwiz/data/msdata/SpectrumList_mzML.o 
./pwiz/data/msdata/SpectrumList_MSn.o 
./pwiz/data/msdata/SpectrumList_mz5.o 
./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o 
./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o 
./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o 
./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o 
./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o 
./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o 
./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o 
./pwiz/data/msdata/Index_mzML.o 
./pwiz/data/msdata/SpectrumWorkerThreads.o 
./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o 
./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o 
./pwiz/data/identdata/Serializer_protXML.o 
./pwiz/data/identdata/Serializer_pepXML.o 
./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o 
./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o 
./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o 
./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o 
./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o 
./pwiz/utility/chemistry/Chemistry.o 
./pwiz/utility/chemistry/ChemistryData.o 
./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o 
./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o 
./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o 
./pwiz/utility/misc/TabReader.o 
./pwiz/utility/misc/random_access_compressed_ifstream.o 
./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o 
./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o 
./boost/libs/thread/src/pthread/once.o 
./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o -lpthread 
/usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a 
/usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a 
/usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ 
-lnetcdf -L/usr/lib64/R/lib -lR
g++: error: cramp.o: No such file or directory
make: *** [mzR.so] Error 1
ERROR: compilation failed for package ?mzR?
* removing ?/usr/lib64/R/library/mzR?

If j is 1, then compilation succeeds.
I have hundreds of packages and so far only "mzR" and "MSnbase" fail if 
I compile with -j>1.

Would anybody be able to confirm this problem exists?
Many thanks, L.


From pelj@@z @ending from y@hoo@co@uk  Fri Jun 15 17:58:58 2018
From: pelj@@z @ending from y@hoo@co@uk (lejeczek)
Date: Fri, 15 Jun 2018 16:58:58 +0100
Subject: [R] rgdal in 3.5 fails(?)
Message-ID: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>

hi there

installation of the package fails:

...

g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g 
-pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector-strong --param=ssp-buffer-size=4 
-grecord-gcc-switches?? -m64 -mtune=generic -c OGR_write.cpp -o OGR_write.o
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g 
-pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector-strong --param=ssp-buffer-size=4 
-grecord-gcc-switches?? -m64 -mtune=generic -c gdal-bindings.cpp -o 
gdal-bindings.o
gdal-bindings.cpp: In function ?SEXPREC* RGDAL_GDALwithGEOS()?:
gdal-bindings.cpp:334:81: error: no matching function for call to 
?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
 ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
&poGeometry1 );
^
gdal-bindings.cpp:334:81: note: candidate is:
In file included from /usr/include/gdal/ogr_feature.h:34:0,
 ???????????????? from /usr/include/gdal/ogrsf_frmts.h:35,
 ???????????????? from gdal-bindings.cpp:7:
/usr/include/gdal/ogr_geometry.h:663:19: note: static OGRErr 
OGRGeometryFactory::createFromWkt(char**, OGRSpatialReference*, 
OGRGeometry**)
 ???? static OGRErr createFromWkt( char **, OGRSpatialReference *,
 ?????????????????? ^
/usr/include/gdal/ogr_geometry.h:663:19: note:?? no known conversion for 
argument 1 from ?const char*? to ?char**?
gdal-bindings.cpp:340:81: error: no matching function for call to 
?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
 ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
&poGeometry2 );


Would you know is this the package's problem in new 3.5 version?

Many thanks, L.


From reichm@nj @ending from @bcglob@l@net  Fri Jun 15 18:07:13 2018
From: reichm@nj @ending from @bcglob@l@net (JEFFERY REICHMAN)
Date: Fri, 15 Jun 2018 16:07:13 +0000 (UTC)
Subject: [R] Kendall tau a, b, or c
References: <1031061800.969830.1529078833258.ref@mail.yahoo.com>
Message-ID: <1031061800.969830.1529078833258@mail.yahoo.com>

Dr. Carlson

Yes, just became aware of the DescTools library after working off Marcs R Code last night. Oh well now I have two options. 

Thanks

Jeff
--------------------------------------------
On Fri, 6/15/18, David L Carlson <dcarlson at tamu.edu> wrote:

 Subject: RE: [R] Kendall tau a, b, or c
 To: "reichmanj at sbcglobal.net" <reichmanj at sbcglobal.net>, "'Marc Schwartz'" <marc_schwartz at me.com>
 Cc: "'R-help'" <r-help at R-project.org>
 Date: Friday, June 15, 2018, 8:31 AM

 Also look at the DescTools
 package for functions KendallTauA, KendallTauB,
 StuartTauC().? 

 ----------------------------------------
 David L Carlson
 Department of
 Anthropology
 Texas A&M University
 College Station, TX 77843-4352

 -----Original Message-----
 From: R-help <r-help-bounces at r-project.org>
 On Behalf Of Jeff Reichman
 Sent: Thursday,
 June 14, 2018 4:19 PM
 To: 'Marc
 Schwartz' <marc_schwartz at me.com>
 Cc: 'R-help' <r-help at R-project.org>
 Subject: Re: [R] Kendall tau a, b, or c

 Marc

 Thank you - that will save me some time.

 Jeff

 -----Original Message-----
 From: Marc Schwartz <marc_schwartz at me.com>

 Sent: Thursday, June 14, 2018 4:07 PM
 To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>
 Cc: R-help <r-help at R-project.org>
 Subject: Re: [R] Kendall tau a, b, or c


 > On Jun
 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net>
 wrote:
 > 
 > r-help Forum
 > 
 > Is there a function to calculate either
 Kendall tau a, b, or c.? It
 appears the
 Kendall library only calculates tau b.? Just wanted to
 check
 before writing a function to calculate
 the concordant and discordant pairs.
 Then
 its pretty easy.
 > 
 >
 jeff
 > 


 Hi Jeff,

 Take a look at my Github Gist here:

  https://gist.github.com/marcschwartz/3665743

 I have b and c (among other
 measures), and supporting functions to calculate
 concordant and discordant pairs.

 Regards,

 Marc Schwartz

 ______________________________________________
 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained,
 reproducible code.


From profjcn@@h @ending from gm@il@com  Fri Jun 15 18:31:04 2018
From: profjcn@@h @ending from gm@il@com (J C Nash)
Date: Fri, 15 Jun 2018 12:31:04 -0400
Subject: [R] rgdal in 3.5 fails(?)
In-Reply-To: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
References: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
Message-ID: <2e15eb9b-28a5-7ac4-9427-bd88c51aca25@gmail.com>

I just tested that it installs in Linux Mint 18.3, but I've had similar install problems recently where
I had to explicitly install some libraries in the OS. In some cases there were hints. I don't see anything
here that I recognize, but I do know in the past I've needed to install libgdal-dev.

JN

On 2018-06-15 11:58 AM, lejeczek via R-help wrote:
> hi there
> 
> installation of the package fails:
> 
> ...
> 
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal
> -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include
> -I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
> -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches?? -m64 -mtune=generic -c OGR_write.cpp -o
> OGR_write.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal
> -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include
> -I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
> -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches?? -m64 -mtune=generic -c gdal-bindings.cpp -o
> gdal-bindings.o
> gdal-bindings.cpp: In function ?SEXPREC* RGDAL_GDALwithGEOS()?:
> gdal-bindings.cpp:334:81: error: no matching function for call to ?OGRGeometryFactory::createFromWkt(const char*, NULL,
> OGRGeometry**)?
> ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, &poGeometry1 );
> ^
> gdal-bindings.cpp:334:81: note: candidate is:
> In file included from /usr/include/gdal/ogr_feature.h:34:0,
> ???????????????? from /usr/include/gdal/ogrsf_frmts.h:35,
> ???????????????? from gdal-bindings.cpp:7:
> /usr/include/gdal/ogr_geometry.h:663:19: note: static OGRErr OGRGeometryFactory::createFromWkt(char**,
> OGRSpatialReference*, OGRGeometry**)
> ???? static OGRErr createFromWkt( char **, OGRSpatialReference *,
> ?????????????????? ^
> /usr/include/gdal/ogr_geometry.h:663:19: note:?? no known conversion for argument 1 from ?const char*? to ?char**?
> gdal-bindings.cpp:340:81: error: no matching function for call to ?OGRGeometryFactory::createFromWkt(const char*, NULL,
> OGRGeometry**)?
> ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, &poGeometry2 );
> 
> 
> Would you know is this the package's problem in new 3.5 version?
> 
> Many thanks, L.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From m@cqueen1 @ending from llnl@gov  Fri Jun 15 20:10:20 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 15 Jun 2018 18:10:20 +0000
Subject: [R] rgdal in 3.5 fails(?)
In-Reply-To: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
References: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
Message-ID: <A707ACC8-33A5-46FD-9477-62374ECB2224@llnl.gov>

In case no one else has made the suggestion yet, take this question to R-sig-geo, where there has already been discussion and sharing of information and experiences about this.

You'll need to include the output of sessionInfo().

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/15/18, 8:58 AM, "R-help on behalf of lejeczek via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    hi there
    
    installation of the package fails:
    
    ...
    
    g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I"/usr/lib64/R/library/sp/include" -I/usr/local/include   -fpic -O2 -g 
    -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
    -fstack-protector-strong --param=ssp-buffer-size=4 
    -grecord-gcc-switches   -m64 -mtune=generic -c OGR_write.cpp -o OGR_write.o
    g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I"/usr/lib64/R/library/sp/include" -I/usr/local/include   -fpic -O2 -g 
    -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
    -fstack-protector-strong --param=ssp-buffer-size=4 
    -grecord-gcc-switches   -m64 -mtune=generic -c gdal-bindings.cpp -o 
    gdal-bindings.o
    gdal-bindings.cpp: In function ?SEXPREC* RGDAL_GDALwithGEOS()?:
    gdal-bindings.cpp:334:81: error: no matching function for call to 
    ?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
          OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
    &poGeometry1 );
    ^
    gdal-bindings.cpp:334:81: note: candidate is:
    In file included from /usr/include/gdal/ogr_feature.h:34:0,
                      from /usr/include/gdal/ogrsf_frmts.h:35,
                      from gdal-bindings.cpp:7:
    /usr/include/gdal/ogr_geometry.h:663:19: note: static OGRErr 
    OGRGeometryFactory::createFromWkt(char**, OGRSpatialReference*, 
    OGRGeometry**)
          static OGRErr createFromWkt( char **, OGRSpatialReference *,
                        ^
    /usr/include/gdal/ogr_geometry.h:663:19: note:   no known conversion for 
    argument 1 from ?const char*? to ?char**?
    gdal-bindings.cpp:340:81: error: no matching function for call to 
    ?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
          OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
    &poGeometry2 );
    
    
    Would you know is this the package's problem in new 3.5 version?
    
    Many thanks, L.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From pd@lgd @ending from gm@il@com  Sat Jun 16 12:27:59 2018
From: pd@lgd @ending from gm@il@com (Peter Dalgaard)
Date: Sat, 16 Jun 2018 12:27:59 +0200
Subject: [R] mzR fails to install/compile (linuxes)
In-Reply-To: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
References: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
Message-ID: <FC7A3172-EDF4-4586-BCE3-2301B38C69FE@gmail.com>

This is almost certainly a Makefile error. Something (A) is relying on something (B) without stating the dependency explicitly in the Makefile. You can get away with that (sometimes) in a non-parallel make, because the sequence of compilations is such that B gets built before A. However, with a parallel make, one thread may try to build A before B gets built by another thread. 

The fix is to add the dependency in the Makefile (plus any other issues of the same kind). In this case, AFAICT, you need

mzR.so: cramp.o

in addition to what might be there already and any other stuff that is also missing. If there is already something like

mzR.so: $(OBJECTS)

chances are that there is a deficient macro definition earlier on, so that cramp.o is not contained in OBJECTS.

-pd

> On 15 Jun 2018, at 16:49 , lejeczek via R-help <r-help at r-project.org> wrote:
> 
> hi guys, just an admin here.
> 
> I wonder if anybody see what I see, or similar? I'm on Centos 7.x and this occurs with R 3.4.x 3.5.x and probably earlier versions too.
> 
> Every time I use something like -j>1 to pass to a compiler, eg.echo -ne
> 
> $ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n source(\"https://bioconductor.org/biocLite.R\")\\n biocLite(c(\"mzR\"), suppressUpdates=FALSE, suppressAutoUpdate=FALSE, ask=FALSE)" | /usr/bin/R --vanilla
> 
> mzR fails to compile:
> ...
> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o ./boost/libs/system/src/error_code.o ./boost/libs/regex/src/posix_api.o ./boost/libs/regex/src/fileiter.o ./boost/libs/regex/src/regex_raw_buffer.o ./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o ./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o ./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o ./boost/libs/regex/src/wide_posix_api.o ./boost/libs/regex/src/regex_traits_defaults.o ./boost/libs/regex/src/winstances.o ./boost/libs/regex/src/wc_regex_traits.o ./boost/libs/regex/src/c_regex_traits.o ./boost/libs/regex/src/cpp_regex_traits.o ./boost/libs/regex/src/static_mutex.o ./boost/libs/regex/src/w32_regex_traits.o ./boost/libs/iostreams/src/zlib.o ./boost/libs/iostreams/src/file_descriptor.o ./boost/libs/filesystem/src/operations.o ./boost/libs/filesystem/src/path.o ./boost/libs/filesystem/src/utf8_codecvt_facet.o ./boost/libs/chrono/src/chrono.o ./boost/libs/chrono/src/process_cpu_clocks.o ./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o ./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o ./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o ./pwiz/data/common/ParamTypes.o ./pwiz/data/common/BinaryIndexStream.o ./pwiz/data/common/diff_std.o ./pwiz/data/common/Unimod.o ./pwiz/data/msdata/mz5/Configuration_mz5.o ./pwiz/data/msdata/mz5/Connection_mz5.o ./pwiz/data/msdata/mz5/Datastructures_mz5.o ./pwiz/data/msdata/mz5/ReferenceRead_mz5.o ./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o ./pwiz/data/msdata/mz5/Translator_mz5.o ./pwiz/data/msdata/SpectrumList_MGF.o ./pwiz/data/msdata/DefaultReaderList.o ./pwiz/data/msdata/ChromatogramList_mzML.o ./pwiz/data/msdata/ChromatogramList_mz5.o ./pwiz/data/msdata/examples.o ./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o ./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_mz5.o ./pwiz/data/msdata/Serializer_MGF.o ./pwiz/data/msdata/Serializer_mzXML.o ./pwiz/data/msdata/SpectrumList_mzML.o ./pwiz/data/msdata/SpectrumList_MSn.o ./pwiz/data/msdata/SpectrumList_mz5.o ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o ./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o ./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o ./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o ./pwiz/data/msdata/Index_mzML.o ./pwiz/data/msdata/SpectrumWorkerThreads.o ./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o ./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o ./pwiz/data/identdata/Serializer_protXML.o ./pwiz/data/identdata/Serializer_pepXML.o ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o ./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o ./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o ./pwiz/utility/chemistry/Chemistry.o ./pwiz/utility/chemistry/ChemistryData.o ./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o ./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o ./pwiz/utility/misc/TabReader.o ./pwiz/utility/misc/random_access_compressed_ifstream.o ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o ./boost/libs/thread/src/pthread/once.o ./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o -lpthread /usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a /usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a /usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ -lnetcdf -L/usr/lib64/R/lib -lR
> g++: error: cramp.o: No such file or directory
> make: *** [mzR.so] Error 1
> ERROR: compilation failed for package ?mzR?
> * removing ?/usr/lib64/R/library/mzR?
> 
> If j is 1, then compilation succeeds.
> I have hundreds of packages and so far only "mzR" and "MSnbase" fail if I compile with -j>1.
> 
> Would anybody be able to confirm this problem exists?
> Many thanks, L.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From c@b@@tride @ending from @heffield@@c@uk  Sat Jun 16 13:00:23 2018
From: c@b@@tride @ending from @heffield@@c@uk (Chris Stride)
Date: Sat, 16 Jun 2018 12:00:23 +0100
Subject: [R] specifying random effects covariance structure in nlme
Message-ID: <8c10f484-8a04-5448-edc5-30846301aaf7@sheffield.ac.uk>

Hi

I'm trying to fit a mixed effects exponential decay model, in which I 
have random effects for the initial value (init), the asymptote (asymp), 
and the rate (rate).

The catch is that I'd also like to estimate the correlation between init 
and asymp, but not between init and rate, or asymp and rate.

Now using? random = pdDiag(init + asymp + rate ~ 1) has none of the 
random effects correlated

And using? random = pdSymm(init + asymp + rate ~ 1) has all three of the 
random effects correlated

How do I specify just the correlation I want?

cheers

Chris


From m@rtin@morg@n @ending from ro@wellp@rk@org  Sat Jun 16 14:09:26 2018
From: m@rtin@morg@n @ending from ro@wellp@rk@org (Martin Morgan)
Date: Sat, 16 Jun 2018 08:09:26 -0400
Subject: [R] mzR fails to install/compile (linuxes)
In-Reply-To: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
References: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
Message-ID: <f3f77e1c-cd98-310d-3a04-a789730d96d7@roswellpark.org>

mzR is a Bioconductor package so you might have more luck contacting the 
maintainer on the Bioconductor support site

   https://support.bioconductor.org

or on the 'bioc-devel' mailing list

   https://stat.ethz.ch/mailman/listinfo/bioc-devel

or most directly by opening an issue on the maintainer's github

   https://github.com/sneumann/mzR/issues/

this is linked to from the package 'landing page'

   https://bioconductor.org/packages/mzR

Martin Morgan

On 06/15/2018 10:49 AM, lejeczek via R-help wrote:
> hi guys, just an admin here.
> 
> I wonder if anybody see what I see, or similar? I'm on Centos 7.x and 
> this occurs with R 3.4.x 3.5.x and probably earlier versions too.
> 
> Every time I use something like -j>1 to pass to a compiler, eg.echo -ne
> 
> $ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n 
> source(\"https://bioconductor.org/biocLite.R\")\\n biocLite(c(\"mzR\"), 
> suppressUpdates=FALSE, suppressAutoUpdate=FALSE, ask=FALSE)" | 
> /usr/bin/R --vanilla
> 
> mzR fails to compile:
> ...
> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so 
> cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o 
> RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o 
> ./boost/libs/system/src/error_code.o ./boost/libs/regex/src/posix_api.o 
> ./boost/libs/regex/src/fileiter.o 
> ./boost/libs/regex/src/regex_raw_buffer.o 
> ./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o 
> ./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o 
> ./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o 
> ./boost/libs/regex/src/wide_posix_api.o 
> ./boost/libs/regex/src/regex_traits_defaults.o 
> ./boost/libs/regex/src/winstances.o 
> ./boost/libs/regex/src/wc_regex_traits.o 
> ./boost/libs/regex/src/c_regex_traits.o 
> ./boost/libs/regex/src/cpp_regex_traits.o 
> ./boost/libs/regex/src/static_mutex.o 
> ./boost/libs/regex/src/w32_regex_traits.o 
> ./boost/libs/iostreams/src/zlib.o 
> ./boost/libs/iostreams/src/file_descriptor.o 
> ./boost/libs/filesystem/src/operations.o 
> ./boost/libs/filesystem/src/path.o 
> ./boost/libs/filesystem/src/utf8_codecvt_facet.o 
> ./boost/libs/chrono/src/chrono.o 
> ./boost/libs/chrono/src/process_cpu_clocks.o 
> ./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o 
> ./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o 
> ./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o 
> ./pwiz/data/common/ParamTypes.o ./pwiz/data/common/BinaryIndexStream.o 
> ./pwiz/data/common/diff_std.o ./pwiz/data/common/Unimod.o 
> ./pwiz/data/msdata/mz5/Configuration_mz5.o 
> ./pwiz/data/msdata/mz5/Connection_mz5.o 
> ./pwiz/data/msdata/mz5/Datastructures_mz5.o 
> ./pwiz/data/msdata/mz5/ReferenceRead_mz5.o 
> ./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o 
> ./pwiz/data/msdata/mz5/Translator_mz5.o 
> ./pwiz/data/msdata/SpectrumList_MGF.o 
> ./pwiz/data/msdata/DefaultReaderList.o 
> ./pwiz/data/msdata/ChromatogramList_mzML.o 
> ./pwiz/data/msdata/ChromatogramList_mz5.o ./pwiz/data/msdata/examples.o 
> ./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o 
> ./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_mz5.o 
> ./pwiz/data/msdata/Serializer_MGF.o 
> ./pwiz/data/msdata/Serializer_mzXML.o 
> ./pwiz/data/msdata/SpectrumList_mzML.o 
> ./pwiz/data/msdata/SpectrumList_MSn.o 
> ./pwiz/data/msdata/SpectrumList_mz5.o 
> ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o 
> ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o 
> ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o 
> ./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o 
> ./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o 
> ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o 
> ./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o 
> ./pwiz/data/msdata/Index_mzML.o 
> ./pwiz/data/msdata/SpectrumWorkerThreads.o 
> ./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o 
> ./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o 
> ./pwiz/data/identdata/Serializer_protXML.o 
> ./pwiz/data/identdata/Serializer_pepXML.o 
> ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o 
> ./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o 
> ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o 
> ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o 
> ./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o 
> ./pwiz/utility/chemistry/Chemistry.o 
> ./pwiz/utility/chemistry/ChemistryData.o 
> ./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o 
> ./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o 
> ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o 
> ./pwiz/utility/misc/TabReader.o 
> ./pwiz/utility/misc/random_access_compressed_ifstream.o 
> ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o 
> ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o 
> ./boost/libs/thread/src/pthread/once.o 
> ./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o -lpthread 
> /usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a 
> /usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a 
> /usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ 
> -lnetcdf -L/usr/lib64/R/lib -lR
> g++: error: cramp.o: No such file or directory
> make: *** [mzR.so] Error 1
> ERROR: compilation failed for package ?mzR?
> * removing ?/usr/lib64/R/library/mzR?
> 
> If j is 1, then compilation succeeds.
> I have hundreds of packages and so far only "mzR" and "MSnbase" fail if 
> I compile with -j>1.
> 
> Would anybody be able to confirm this problem exists?
> Many thanks, L.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or...{{dropped:2}}


From pd@lgd @ending from gm@il@com  Sat Jun 16 15:18:36 2018
From: pd@lgd @ending from gm@il@com (Peter Dalgaard)
Date: Sat, 16 Jun 2018 15:18:36 +0200
Subject: [R] specifying random effects covariance structure in nlme
In-Reply-To: <8c10f484-8a04-5448-edc5-30846301aaf7@sheffield.ac.uk>
References: <8c10f484-8a04-5448-edc5-30846301aaf7@sheffield.ac.uk>
Message-ID: <B815AB0D-25F3-4E28-9BC3-F3BDB84ED73F@gmail.com>

I haven't played with this for a decade or so, but I believe you can do something with pdBlocked(). Possibly ask over on R-sig-ME as this quickly gets beyond the R-help level.

(Also, you are aware that it is not about what you want to estimate, but whether you believe the correlations are nonzero?)

-pd

> On 16 Jun 2018, at 13:00 , Chris Stride <c.b.stride at sheffield.ac.uk> wrote:
> 
> Hi
> 
> I'm trying to fit a mixed effects exponential decay model, in which I have random effects for the initial value (init), the asymptote (asymp), and the rate (rate).
> 
> The catch is that I'd also like to estimate the correlation between init and asymp, but not between init and rate, or asymp and rate.
> 
> Now using  random = pdDiag(init + asymp + rate ~ 1) has none of the random effects correlated
> 
> And using  random = pdSymm(init + asymp + rate ~ 1) has all three of the random effects correlated
> 
> How do I specify just the correlation I want?
> 
> cheers
> 
> Chris
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From h@nn@hvnoort @ending from gm@il@com  Sat Jun 16 22:37:08 2018
From: h@nn@hvnoort @ending from gm@il@com (Hannah van Noort)
Date: Sat, 16 Jun 2018 22:37:08 +0200
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
Message-ID: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>

Hi everyone,

I'm having trouble running a PGLS model with the package "AICmodavg". I
continuously get the error of false convergence with certain Lambda
values (even
when trying to run the model with different Lambda values) and for other La
mbda values I run into "error in eigen(val) : infinite or missing values in
'X' ". I've tried several optimizers and removing some outlier values but
the same errors keep on popping up.. Does anyone know how to solve this
problem?
Below a part of my script with the specific dependent and independent varia
bles and I've also attached files with the relevant data and phylogenetic
tree information.

Cand.models = list()
niter = 100
for (i in 1:niter) {
  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av), data =
d, method= "ML", na.action=na.omit
                         correlation = corPagel(value=0.4, trees[[i]]))
}

Thank you in advance for any help, it's much appreciated!

Kind regards,

Hannah van Noort

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Seabirddat_growth.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180616/c5e8bbad/attachment.txt>

From dwin@emiu@ @ending from comc@@t@net  Sun Jun 17 07:27:01 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sat, 16 Jun 2018 22:27:01 -0700
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
Message-ID: <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>


> On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
> 
> Hi everyone,
> 
> I'm having trouble running a PGLS model with the package "AICmodavg".

Did you mean "AICmodavg"?


> I
> continuously get the error of false convergence with certain Lambda
> values (even
> when trying to run the model with different Lambda values) and for other La
> mbda values I run into "error in eigen(val) : infinite or missing values in
> 'X' ". I've tried several optimizers and removing some outlier values but
> the same errors keep on popping up.. Does anyone know how to solve this
> problem?
> Below a part of my script with the specific dependent and independent varia
> bles and I've also attached files with the relevant data and phylogenetic
> tree information.

d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
library(AICmodavg)
Error in library(AICmodavg) : there is no package called ?AICmodavg?
library(AICcmodavg)
> 
> Cand.models = list()
> niter = 100
> for (i in 1:niter) {
>  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),

A syntax error is thrown here -------------------------------------^  #removed paren
> data =
> d, method= "ML", na.action=na.omit

And here ---------------------------^
>                         correlation = corPagel(value=0.4, trees[[i]]))

And after fixing these errors I get the error that `gls` is not found (even after adding `library(AICcmodavg)`

 could not find function "gls"
> ?corPagel
No documentation for ?corPagel? in specified packages and libraries:
you could try ???corPagel?
> ??gls
> library(nlme)

Attaching package: ?nlme?

The following object is masked from ?package:dplyr?:

    collapse

> Cand.models = list()
> niter = 100
> for (i in 1:niter) {
+  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
+ d, method= "ML", na.action=na.omit,
+                         correlation = corPagel(value=0.4, trees[[i]]) )
+ }
Error in corPagel(value = 0.4, trees[[i]]) : 
  could not find function "corPagel"
> ??corPagel
> library(ape)

Attaching package: ?ape?

The following object is masked from ?package:Hmisc?:

    zoom

> Cand.models = list()
> niter = 100
> for (i in 1:niter) {
+  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
+ d, method= "ML", na.action=na.omit,
+                         correlation = corPagel(value=0.4, trees[[i]]) )
+ }
Error in corPagel(value = 0.4, trees[[i]]) : 
  object "phy" is not of class "phylo"



Perhaps you have yet another unnamed package with a corPagel that doesn't require a second argument of class "phylo"? I've reached "the end of my rope".




> }
> 
> Thank you in advance for any help, it's much appreciated!

Please submit code that will run in a clean session. Close R. Do not save anything except your history. Delete or rename your `.Rdata` file and staart a fresh session. then include everything needed to get the behavior you are reporting.

> 
> Kind regards,
> 
> Hannah van Noort
> <Seabirddat_growth.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From h@nn@hvnoort @ending from gm@il@com  Sun Jun 17 19:19:30 2018
From: h@nn@hvnoort @ending from gm@il@com (Hannah van Noort)
Date: Sun, 17 Jun 2018 19:19:30 +0200
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
 <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
Message-ID: <CAO1bxtj69_dpP-uWrLzkcL=aNMBP6_OC4vSoZO20Mm0iApG3SA@mail.gmail.com>

Hi again,

My apologies for the incomplete script last time. Hereby the updated
dataset, phylogenetic tree information and R-script. This time the errors I
mentioned should pop up.
Once again thank you in advance for any help/tips.

Kind regards,

Hannah van Noort

2018-06-17 7:27 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com>
> wrote:
> >
> > Hi everyone,
> >
> > I'm having trouble running a PGLS model with the package "AICmodavg".
>
> Did you mean "AICmodavg"?
>
>
> > I
> > continuously get the error of false convergence with certain Lambda
> > values (even
> > when trying to run the model with different Lambda values) and for other
> La
> > mbda values I run into "error in eigen(val) : infinite or missing values
> in
> > 'X' ". I've tried several optimizers and removing some outlier values but
> > the same errors keep on popping up.. Does anyone know how to solve this
> > problem?
> > Below a part of my script with the specific dependent and independent
> varia
> > bles and I've also attached files with the relevant data and phylogenetic
> > tree information.
>
> d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
> library(AICmodavg)
> Error in library(AICmodavg) : there is no package called ?AICmodavg?
> library(AICcmodavg)
> >
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> >  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),
>
> A syntax error is thrown here -------------------------------------^
> #removed paren
> > data =
> > d, method= "ML", na.action=na.omit
>
> And here ---------------------------^
> >                         correlation = corPagel(value=0.4, trees[[i]]))
>
> And after fixing these errors I get the error that `gls` is not found
> (even after adding `library(AICcmodavg)`
>
>  could not find function "gls"
> > ?corPagel
> No documentation for ?corPagel? in specified packages and libraries:
> you could try ???corPagel?
> > ??gls
> > library(nlme)
>
> Attaching package: ?nlme?
>
> The following object is masked from ?package:dplyr?:
>
>     collapse
>
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) :
>   could not find function "corPagel"
> > ??corPagel
> > library(ape)
>
> Attaching package: ?ape?
>
> The following object is masked from ?package:Hmisc?:
>
>     zoom
>
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) :
>   object "phy" is not of class "phylo"
>
>
>
> Perhaps you have yet another unnamed package with a corPagel that doesn't
> require a second argument of class "phylo"? I've reached "the end of my
> rope".
>
>
>
>
> > }
> >
> > Thank you in advance for any help, it's much appreciated!
>
> Please submit code that will run in a clean session. Close R. Do not save
> anything except your history. Delete or rename your `.Rdata` file and
> staart a fresh session. then include everything needed to get the behavior
> you are reporting.
>
> >
> > Kind regards,
> >
> > Hannah van Noort
> > <Seabirddat_growth.txt>______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Seabirddat_growth.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180617/55711f90/attachment.txt>

From dwin@emiu@ @ending from comc@@t@net  Sun Jun 17 23:33:13 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sun, 17 Jun 2018 14:33:13 -0700
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <CAO1bxtj69_dpP-uWrLzkcL=aNMBP6_OC4vSoZO20Mm0iApG3SA@mail.gmail.com>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
 <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
 <CAO1bxtj69_dpP-uWrLzkcL=aNMBP6_OC4vSoZO20Mm0iApG3SA@mail.gmail.com>
Message-ID: <B80000E1-9836-471B-AA94-7C69524B7B1D@comcast.net>


> On Jun 17, 2018, at 10:19 AM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
> 
> Hi again,
> 
> My apologies for the incomplete script last time. Hereby the updated dataset, phylogenetic tree information and R-script. This time the errors I mentioned should pop up.
> Once again thank you in advance for any help/tips.

> row.names(d) <- c("Diomedea_exulans", "Diomedea_epomophora", "Thalassarche_chrysostoma", "Thalassarche_melanophrys", "Phoebetria_palpebrata", "Macronectes_giganteus", "Fulmarus_glacialis",
+                   "Procellaria_aequinoctialis", "Puffinus_tenuirostris", "Puffinus_puffinus", "Oceanites_oceanicus", "Oceanodroma_leucorhoa", "Phaethon_rubricauda", 
+                   "Pelecanus_occidentalis", "Fregata_magnificens", "Morus_bassanus", 
+                   "Sula_dactylatra", "Sula_leucogaster", "Sula_sula", "Phalacrocorax_carbo", "Phalacrocorax_aristotelis", "Larus_dominicanus", "Larus_occidentalis", "Larus_argentatus", "Rissa_tridactyla", "Sterna_bergii",
+                   "Sterna_sandvicensis", "Sterna_dougallii", "Sterna_hirundo", "Sterna_paradisaea", "Sterna_fuscata", "Anous_stolidus", "Anous_minutus", "Cepphus_columba", "Cepphus_grylle", "Uria_lomvia", "Alca_torda")
Error in `.rowNamesDF<-`(x, value = value) : invalid 'row.names' length

Needed to remove the extraneous "+" signs that persisted after copying from the console, but still no progress:


length( c("Diomedea_exulans", "Diomedea_epomophora", "Thalassarche_chrysostoma", "Thalassarche_melanophrys", "Phoebetria_palpebrata", "Macronectes_giganteus", "Fulmarus_glacialis",
+                    "Procellaria_aequinoctialis", "Puffinus_tenuirostris", "Puffinus_puffinus", "Oceanites_oceanicus", "Oceanodroma_leucorhoa", "Phaethon_rubricauda", 
+                   "Pelecanus_occidentalis", "Fregata_magnificens", "Morus_bassanus", 
+                    "Sula_dactylatra", "Sula_leucogaster", "Sula_sula", "Phalacrocorax_carbo", "Phalacrocorax_aristotelis", "Larus_dominicanus", "Larus_occidentalis", "Larus_argentatus", "Rissa_tridactyla", "Sterna_bergii",
+                   "Sterna_sandvicensis", "Sterna_dougallii", "Sterna_hirundo", "Sterna_paradisaea", "Sterna_fuscata", "Anous_stolidus", "Anous_minutus", "Cepphus_columba", "Cepphus_grylle", "Uria_lomvia", "Alca_torda")
+ )
[1] 37

> 
 nrow(d)
[1] 40

So yet another error that prevents further progress.


PLEASE 
PLEASE
PLEASE
Run your code in a clean session and try to recognize and correct the syntactic and other errors that I have already identified. I think it's time for you to adopt a strategy of creating asource file that is then submitted by your editor. (Such a facility is supplied by Rstudio.)


> Kind regards,
> 
> Hannah van Noort
> 
> 2018-06-17 7:27 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
> 
> > On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
> > 
> > Hi everyone,
> > 
> > I'm having trouble running a PGLS model with the package "AICmodavg".
> 
> Did you mean "AICmodavg"?
> 
> 
> > I
> > continuously get the error of false convergence with certain Lambda
> > values (even
> > when trying to run the model with different Lambda values) and for other La
> > mbda values I run into "error in eigen(val) : infinite or missing values in
> > 'X' ". I've tried several optimizers and removing some outlier values but
> > the same errors keep on popping up.. Does anyone know how to solve this
> > problem?
> > Below a part of my script with the specific dependent and independent varia
> > bles and I've also attached files with the relevant data and phylogenetic
> > tree information.
> 
> d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
> library(AICmodavg)
> Error in library(AICmodavg) : there is no package called ?AICmodavg?
> library(AICcmodavg)
> > 
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> >  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),
> 
> A syntax error is thrown here -------------------------------------^  #removed paren
> > data =
> > d, method= "ML", na.action=na.omit
> 
> And here ---------------------------^
> >                         correlation = corPagel(value=0.4, trees[[i]]))
> 
> And after fixing these errors I get the error that `gls` is not found (even after adding `library(AICcmodavg)`
> 
>  could not find function "gls"
> > ?corPagel
> No documentation for ?corPagel? in specified packages and libraries:
> you could try ???corPagel?
> > ??gls
> > library(nlme)
> 
> Attaching package: ?nlme?
> 
> The following object is masked from ?package:dplyr?:
> 
>     collapse
> 
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>   could not find function "corPagel"
> > ??corPagel
> > library(ape)
> 
> Attaching package: ?ape?
> 
> The following object is masked from ?package:Hmisc?:
> 
>     zoom
> 
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>   object "phy" is not of class "phylo"
> 
> 
> 
> Perhaps you have yet another unnamed package with a corPagel that doesn't require a second argument of class "phylo"? I've reached "the end of my rope".
> 
> 
> 
> 
> > }
> > 
> > Thank you in advance for any help, it's much appreciated!
> 
> Please submit code that will run in a clean session. Close R. Do not save anything except your history. Delete or rename your `.Rdata` file and staart a fresh session. then include everything needed to get the behavior you are reporting.
> 
> > 
> > Kind regards,
> > 
> > Hannah van Noort
> > <Seabirddat_growth.txt>______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 
> <Seabirddat_growth.txt><output.nex><Scripts_Growthrate.R>

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From dwin@emiu@ @ending from comc@@t@net  Sun Jun 17 22:51:00 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Sun, 17 Jun 2018 13:51:00 -0700
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
 <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
Message-ID: <E5903E7C-50BB-4891-A1EE-5BFD3CC5D583@comcast.net>


> On Jun 16, 2018, at 10:27 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
>> 
>> Hi everyone,
>> 
>> I'm having trouble running a PGLS model with the package "AICmodavg".
> 
> Did you mean "AICmodavg"?
> 
> 
>> I
>> continuously get the error of false convergence with certain Lambda
>> values (even
>> when trying to run the model with different Lambda values) and for other La
>> mbda values I run into "error in eigen(val) : infinite or missing values in
>> 'X' ". I've tried several optimizers and removing some outlier values but
>> the same errors keep on popping up.. Does anyone know how to solve this
>> problem?
>> Below a part of my script with the specific dependent and independent varia
>> bles and I've also attached files with the relevant data and phylogenetic
>> tree information.

I didn't notice on first reading that your said you had attached a file about "phylogenetic
tree information." There was only one file in the material passed to Rhelp readers and htat was the .txt data file. Files ending in anything other than ".txt", ".ps", ".pdf", or ".png" will get scrubbed by hte mail-server that mediated rhelp communication. So you can fool your mail-client into thinking that a file is plain text by adding a '.txt' extension and communication will be improved.

Since drafting this I see that you sent another message to both me and Rhelp. I'm the only one who will get the `.nex` and `.R` files. They were scrubbed by the mailserver. I've looked at the .R file and wil now follow my own advice and append a .txt extension  and attach to this email. The 190KB output.nex file is also basically a text file and I'm applying the same treatment:


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: output.nex.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180617/b18132be/attachment.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Scripts_Growthrate.R.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180617/b18132be/attachment-0001.txt>

-------------- next part --------------

 
> 
> d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
> library(AICmodavg)
> Error in library(AICmodavg) : there is no package called ?AICmodavg?
> library(AICcmodavg)
>> 
>> Cand.models = list()
>> niter = 100
>> for (i in 1:niter) {
>> Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),
> 
> A syntax error is thrown here -------------------------------------^  #removed paren
>> data =
>> d, method= "ML", na.action=na.omit
> 
> And here ---------------------------^
>>                        correlation = corPagel(value=0.4, trees[[i]]))
> 
> And after fixing these errors I get the error that `gls` is not found (even after adding `library(AICcmodavg)`
> 
> could not find function "gls"
>> ?corPagel
> No documentation for ?corPagel? in specified packages and libraries:
> you could try ???corPagel?
>> ??gls
>> library(nlme)
> 
> Attaching package: ?nlme?
> 
> The following object is masked from ?package:dplyr?:
> 
>    collapse
> 
>> Cand.models = list()
>> niter = 100
>> for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>  could not find function "corPagel"
>> ??corPagel
>> library(ape)
> 
> Attaching package: ?ape?
> 
> The following object is masked from ?package:Hmisc?:
> 
>    zoom
> 
>> Cand.models = list()
>> niter = 100
>> for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>  object "phy" is not of class "phylo"
> 
> 
> 
> Perhaps you have yet another unnamed package with a corPagel that doesn't require a second argument of class "phylo"? I've reached "the end of my rope".
> 
> 
> 
> 
>> }
>> 
>> Thank you in advance for any help, it's much appreciated!
> 
> Please submit code that will run in a clean session. Close R. Do not save anything except your history. Delete or rename your `.Rdata` file and staart a fresh session. then include everything needed to get the behavior you are reporting.
> 
>> 
>> Kind regards,
>> 
>> Hannah van Noort
>> <Seabirddat_growth.txt>______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






From pelj@@z @ending from y@hoo@co@uk  Mon Jun 18 12:28:37 2018
From: pelj@@z @ending from y@hoo@co@uk (lejeczek)
Date: Mon, 18 Jun 2018 11:28:37 +0100
Subject: [R] mzR fails to install/compile (linuxes)
In-Reply-To: <f3f77e1c-cd98-310d-3a04-a789730d96d7@roswellpark.org>
References: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
 <f3f77e1c-cd98-310d-3a04-a789730d96d7@roswellpark.org>
Message-ID: <1e1509bb-5bd4-f7b0-d2d5-88ac67c99faf@yahoo.co.uk>

On 16/06/18 13:09, Martin Morgan wrote:
> mzR is a Bioconductor package so you might have more luck contacting 
> the maintainer on the Bioconductor support site
>
> ? https://support.bioconductor.org
>
> or on the 'bioc-devel' mailing list
>
> ? https://stat.ethz.ch/mailman/listinfo/bioc-devel
>
> or most directly by opening an issue on the maintainer's github
>
> ? https://github.com/sneumann/mzR/issues/
>
> this is linked to from the package 'landing page'
>
> ? https://bioconductor.org/packages/mzR
>
> Martin Morgan
>
> On 06/15/2018 10:49 AM, lejeczek via R-help wrote:
>> hi guys, just an admin here.
>>
>> I wonder if anybody see what I see, or similar? I'm on Centos 7.x and 
>> this occurs with R 3.4.x 3.5.x and probably earlier versions too.
>>
>> Every time I use something like -j>1 to pass to a compiler, eg.echo -ne
>>
>> $ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n 
>> source(\"https://bioconductor.org/biocLite.R\")\\n 
>> biocLite(c(\"mzR\"), suppressUpdates=FALSE, suppressAutoUpdate=FALSE, 
>> ask=FALSE)" | /usr/bin/R --vanilla
>>
>> mzR fails to compile:
>> ...
>> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o 
>> mzR.so cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o 
>> rnetCDF.o RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o 
>> ./boost/libs/system/src/error_code.o 
>> ./boost/libs/regex/src/posix_api.o ./boost/libs/regex/src/fileiter.o 
>> ./boost/libs/regex/src/regex_raw_buffer.o 
>> ./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o 
>> ./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o 
>> ./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o 
>> ./boost/libs/regex/src/wide_posix_api.o 
>> ./boost/libs/regex/src/regex_traits_defaults.o 
>> ./boost/libs/regex/src/winstances.o 
>> ./boost/libs/regex/src/wc_regex_traits.o 
>> ./boost/libs/regex/src/c_regex_traits.o 
>> ./boost/libs/regex/src/cpp_regex_traits.o 
>> ./boost/libs/regex/src/static_mutex.o 
>> ./boost/libs/regex/src/w32_regex_traits.o 
>> ./boost/libs/iostreams/src/zlib.o 
>> ./boost/libs/iostreams/src/file_descriptor.o 
>> ./boost/libs/filesystem/src/operations.o 
>> ./boost/libs/filesystem/src/path.o 
>> ./boost/libs/filesystem/src/utf8_codecvt_facet.o 
>> ./boost/libs/chrono/src/chrono.o 
>> ./boost/libs/chrono/src/process_cpu_clocks.o 
>> ./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o 
>> ./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o 
>> ./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o 
>> ./pwiz/data/common/ParamTypes.o 
>> ./pwiz/data/common/BinaryIndexStream.o ./pwiz/data/common/diff_std.o 
>> ./pwiz/data/common/Unimod.o 
>> ./pwiz/data/msdata/mz5/Configuration_mz5.o 
>> ./pwiz/data/msdata/mz5/Connection_mz5.o 
>> ./pwiz/data/msdata/mz5/Datastructures_mz5.o 
>> ./pwiz/data/msdata/mz5/ReferenceRead_mz5.o 
>> ./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o 
>> ./pwiz/data/msdata/mz5/Translator_mz5.o 
>> ./pwiz/data/msdata/SpectrumList_MGF.o 
>> ./pwiz/data/msdata/DefaultReaderList.o 
>> ./pwiz/data/msdata/ChromatogramList_mzML.o 
>> ./pwiz/data/msdata/ChromatogramList_mz5.o 
>> ./pwiz/data/msdata/examples.o ./pwiz/data/msdata/Serializer_mzML.o 
>> ./pwiz/data/msdata/Serializer_MSn.o ./pwiz/data/msdata/Reader.o 
>> ./pwiz/data/msdata/Serializer_mz5.o 
>> ./pwiz/data/msdata/Serializer_MGF.o 
>> ./pwiz/data/msdata/Serializer_mzXML.o 
>> ./pwiz/data/msdata/SpectrumList_mzML.o 
>> ./pwiz/data/msdata/SpectrumList_MSn.o 
>> ./pwiz/data/msdata/SpectrumList_mz5.o 
>> ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o 
>> ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o 
>> ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o 
>> ./pwiz/data/msdata/SpectrumList_BTDX.o 
>> ./pwiz/data/msdata/SpectrumInfo.o ./pwiz/data/msdata/RAMPAdapter.o 
>> ./pwiz/data/msdata/LegacyAdapter.o 
>> ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o 
>> ./pwiz/data/msdata/MSNumpress.o 
>> ./pwiz/data/msdata/SpectrumListCache.o 
>> ./pwiz/data/msdata/Index_mzML.o 
>> ./pwiz/data/msdata/SpectrumWorkerThreads.o 
>> ./pwiz/data/identdata/IdentDataFile.o 
>> ./pwiz/data/identdata/IdentData.o 
>> ./pwiz/data/identdata/DefaultReaderList.o 
>> ./pwiz/data/identdata/Reader.o 
>> ./pwiz/data/identdata/Serializer_protXML.o 
>> ./pwiz/data/identdata/Serializer_pepXML.o 
>> ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o 
>> ./pwiz/data/identdata/References.o 
>> ./pwiz/data/identdata/MascotReader.o 
>> ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o 
>> ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o 
>> ./pwiz/utility/minimxml/XMLWriter.o 
>> ./pwiz/utility/minimxml/SAXParser.o 
>> ./pwiz/utility/chemistry/Chemistry.o 
>> ./pwiz/utility/chemistry/ChemistryData.o 
>> ./pwiz/utility/chemistry/MZTolerance.o 
>> ./pwiz/utility/misc/IntegerSet.o ./pwiz/utility/misc/Base64.o 
>> ./pwiz/utility/misc/IterationListener.o 
>> ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o 
>> ./pwiz/utility/misc/TabReader.o 
>> ./pwiz/utility/misc/random_access_compressed_ifstream.o 
>> ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o 
>> ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o 
>> ./RcppExports.o ./boost/libs/thread/src/pthread/once.o 
>> ./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o 
>> -lpthread /usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a 
>> /usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a 
>> /usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ 
>> -lnetcdf -L/usr/lib64/R/lib -lR
>> g++: error: cramp.o: No such file or directory
>> make: *** [mzR.so] Error 1
>> ERROR: compilation failed for package ?mzR?
>> * removing ?/usr/lib64/R/library/mzR?
>>
>> If j is 1, then compilation succeeds.
>> I have hundreds of packages and so far only "mzR" and "MSnbase" fail 
>> if I compile with -j>1.
>>
>> Would anybody be able to confirm this problem exists?
>> Many thanks, L.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> This email message may contain legally privileged and/or confidential 
> information.? If you are not the intended recipient(s), or the 
> employee or agent responsible for the delivery of this message to the 
> intended recipient(s), you are hereby notified that any disclosure, 
> copying, distribution, or use of this email message is prohibited.? If 
> you have received this message in error, please notify the sender 
> immediately by e-mail and delete this email message from your 
> computer. Thank you.

sure sure,

Could somebody just run compilation the way I described it and confirm 
it fails? Anybody on Centos/rhel?

many thanks, L.


From @k@h@y_e4 @ending from hotm@il@com  Mon Jun 18 12:55:53 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Mon, 18 Jun 2018 10:55:53 +0000
Subject: [R] subsetting lists....
Message-ID: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...

How to do this?
I searched SO and the internet but was bootless....

Very many thanks for your time and effort.....
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Mon Jun 18 13:15:30 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Mon, 18 Jun 2018 11:15:30 +0000
Subject: [R] Fw: subsetting lists....
In-Reply-To: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

correction....I want the method without a for loop
________________________________
From: akshay kulkarni <akshay_e4 at hotmail.com>
Sent: Monday, June 18, 2018 4:25 PM
To: R help Mailing list
Subject: subsetting lists....

dear members,
                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...

How to do this?
I searched SO and the internet but was bootless....

Very many thanks for your time and effort.....
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Mon Jun 18 13:18:30 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 18 Jun 2018 14:18:30 +0300
Subject: [R] subsetting lists....
In-Reply-To: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW76oTkU8R0M+U1ZUvuS5fmbpmaK_KZGbi2=BksLKq8AeGw@mail.gmail.com>

 sapply( 1:length(YH), function(i) { YH[[i]][iuhV[i]]})

On Mon, Jun 18, 2018 at 1:55 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                             I have list YH and index vector iuhV. I want
> to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from
> YH[[3]]......iuhv[n] from YH[[n]]...
>
> How to do this?
> I searched SO and the internet but was bootless....
>
> Very many thanks for your time and effort.....
> Yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Mon Jun 18 13:46:16 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Mon, 18 Jun 2018 14:46:16 +0300
Subject: [R] Fw: subsetting lists....
In-Reply-To: <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW77rMpD-M1K50XiG2S8F-ssx1zMd3VKL+xan0hgqYq_=dg@mail.gmail.com>

My response does not have an explicit for loop.

On Mon, Jun 18, 2018 at 2:15 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> correction....I want the method without a for loop
> ________________________________
> From: akshay kulkarni <akshay_e4 at hotmail.com>
> Sent: Monday, June 18, 2018 4:25 PM
> To: R help Mailing list
> Subject: subsetting lists....
>
> dear members,
>                             I have list YH and index vector iuhV. I want
> to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from
> YH[[3]]......iuhv[n] from YH[[n]]...
>
> How to do this?
> I searched SO and the internet but was bootless....
>
> Very many thanks for your time and effort.....
> Yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From miluji@b @ending from gm@il@com  Mon Jun 18 16:21:50 2018
From: miluji@b @ending from gm@il@com (Miluji Sb)
Date: Mon, 18 Jun 2018 16:21:50 +0200
Subject: [R] Subset Rasterbrick by time
Message-ID: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>

 Dear all,

I have a rasterbrick with the date/time information provided which I would
like to subset by year.

However, when I use the following code for sub-setting;

new_brick <- subset(original, which(getZ( original ) >= as.Date("2000-01-01
10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))

The date/time information seems to be lost.

Furthermore, the class of the date/time seems to be character;

##
class(getZ( original ))
[1] "character"

Is it possible to convert this string to date before sub-setting or retain
the date/time information after sub-setting?

### original RasterBrick ###
class       : RasterBrick
dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
resolution  : 0.25, 0.25  (x, y)
extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source :
/work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_precip_windspd_sphum_daily_1986_2016.nc4
names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
X1986.01.15.10.30.00, ...
Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
varname     : v1

### new RasterBrick ###
class       : RasterStack
dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
resolution  : 0.25, 0.25  (x, y)
extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
X2000.01.15.10.30.00, ...

Any help will be greatly appreciated.

Sincerely,

Milu

	[[alternative HTML version deleted]]


From dwin@emiu@ @ending from comc@@t@net  Mon Jun 18 17:08:37 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Mon, 18 Jun 2018 08:08:37 -0700
Subject: [R] Subset Rasterbrick by time
In-Reply-To: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
Message-ID: <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>



> On Jun 18, 2018, at 7:21 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear all,
> 
> I have a rasterbrick with the date/time information provided which I would
> like to subset by year.
> 
> However, when I use the following code for sub-setting;
> 
> new_brick <- subset(original, which(getZ( original ) >= as.Date("2000-01-01
> 10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))
> 
> The date/time information seems to be lost.
> 
> Furthermore, the class of the date/time seems to be character;
> 
> ##
> class(getZ( original ))
> [1] "character"
> 
> Is it possible to convert this string to date before sub-setting or retain
> the date/time information after sub-setting?

Yes, it is certainly possible, but why bother? R's Comparison operators work on character values so you should be able to do this (if the subsetting is syntactically correct:

 new_brick <- subset(original, which(getZ( original ) >= "2000-01-01
10:30:00" & getZ(original ) <= "2014-12-31 10:30:00") )


As always if you had presented the output of dput(head(original)) assuming that head is a meaningful operation on such an object, the demonstration would have been possible. An alternate would be to offer a library call to a package and then load a relevant example.


Best;
David
> 
> ### original RasterBrick ###
> class       : RasterBrick
> dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
> resolution  : 0.25, 0.25  (x, y)
> extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
> /work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_precip_windspd_sphum_daily_1986_2016.nc4
> names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
> X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
> X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
> X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
> X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
> X1986.01.15.10.30.00, ...
> Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
> varname     : v1
> 
> ### new RasterBrick ###
> class       : RasterStack
> dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
> resolution  : 0.25, 0.25  (x, y)
> extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
> X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
> X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
> X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
> X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
> X2000.01.15.10.30.00, ...
> 
> Any help will be greatly appreciated.
> 
> Sincerely,
> 
> Milu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From g@g@ndeep_d@tt@ @ending from hotm@il@com  Mon Jun 18 17:31:36 2018
From: g@g@ndeep_d@tt@ @ending from hotm@il@com (Gagandeep S. Datta)
Date: Mon, 18 Jun 2018 15:31:36 +0000
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>,
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
Message-ID: <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>

Hi,

Is there a code available for zero-truncated Binomial distribution on the lines of zero-truncated Poisson distribution available at:
https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html

Regards,
Gagandeep

	[[alternative HTML version deleted]]


From pd@lgd @ending from gm@il@com  Mon Jun 18 17:52:27 2018
From: pd@lgd @ending from gm@il@com (peter dalgaard)
Date: Mon, 18 Jun 2018 17:52:27 +0200
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
Message-ID: <5411EC03-BB16-4EEE-BA3C-7C27CE46883F@gmail.com>

I think you can pretty much copy what is in that reference while substituting "binom" for "pois" (not quite, but you get the point?)

-pd

> On 18 Jun 2018, at 17:31 , Gagandeep S. Datta <gagandeep_datta at hotmail.com> wrote:
> 
> Hi,
> 
> Is there a code available for zero-truncated Binomial distribution on the lines of zero-truncated Poisson distribution available at:
> https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html
> 
> Regards,
> Gagandeep
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jun 18 17:59:02 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 18 Jun 2018 08:59:02 -0700
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>,
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
Message-ID: <6FBAFB1D-80FD-4706-97E1-A5EF3E802189@dcn.davis.ca.us>

Mailing list etiquette requires that you don't start a new thread by replying to an existing thread. Start a new thread with a fresh email.

Also, this is a plain text mailing list... HTML formatting gets removed and what is left often does not look to the list readers like what you sent. Read the Posting Guide mentioned below for more about interacting with the list.

On June 18, 2018 8:31:36 AM PDT, "Gagandeep S. Datta" <gagandeep_datta at hotmail.com> wrote:
>Hi,
>
>Is there a code available for zero-truncated Binomial distribution on
>the lines of zero-truncated Poisson distribution available at:
>https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html
>
>Regards,
>Gagandeep
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From ccberry @ending from uc@d@edu  Mon Jun 18 19:00:40 2018
From: ccberry @ending from uc@d@edu (Berry, Charles)
Date: Mon, 18 Jun 2018 17:00:40 +0000
Subject: [R] subsetting lists....
In-Reply-To: <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <4625A3BE-D93E-4674-B8AE-D44C9AA0BBA2@ucsd.edu>



> On Jun 18, 2018, at 4:15 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> correction....I want the method without a for loop

Here are two. The first is more readable, but the second is 5 times faster.

mapply("[", YH, iuhV)

unlist(YH, recursive = FALSE, use.names = FALSE)[cumsum( lengths(YH)) - lengths(YH) + iuhV]

HTH,

Chuck

> ________________________________
> From: akshay kulkarni <akshay_e4 at hotmail.com>
> Sent: Monday, June 18, 2018 4:25 PM
> To: R help Mailing list
> Subject: subsetting lists....
> 
> dear members,
>                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...
> 
> How to do this?
> I searched SO and the internet but was bootless....
> 
> Very many thanks for your time and effort.....
> Yours sincerely,
> AKSHAY M KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 


From @eb@@tien@bihorel @ending from cognigencorp@com  Mon Jun 18 20:01:11 2018
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Mon, 18 Jun 2018 14:01:11 -0400 (EDT)
Subject: [R] Porbably bug in panel.abline
Message-ID: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>

Hi, 

I recently encountered situations in which reference lines are not drawn with the lattice panel.abline function. Please, consider the following example code: 


require(lattice)

a <- runif(1,0,100)
data <- data.frame(x=c(0,a^2), y=c(0,a^2))

xyplot(
  y~x,
  data = data,
  type = 'l',
  panel = function(x,y,...){
    panel.xyplot(x,y,...)
    panel.abline(c(a^2,-1.0), col=2)
  }
) 

Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some axis limits seems to bypass the problem. 

The problem also happens for different data source and abline coefficients: 
data <- data.frame(x=c(18,81), y=c(18,81)) 
... 
panel.abline(c(99,-1.0), col=2)


Thank you in advance for your feedback.

Sebastien

PS: the problem was also posted at https://github.com/deepayan/lattice/issues/8


From bgunter@4567 @ending from gm@il@com  Mon Jun 18 20:07:17 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 18 Jun 2018 11:07:17 -0700
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <6FBAFB1D-80FD-4706-97E1-A5EF3E802189@dcn.davis.ca.us>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
 <6FBAFB1D-80FD-4706-97E1-A5EF3E802189@dcn.davis.ca.us>
Message-ID: <CAGxFJbT5br-bAwauPoNvHd0QZw7qk_i8K9u20CL06iiXHoGi-Q@mail.gmail.com>

Search!

My first hit on a google search of "zero truncated binomial" was this:

https://rdrr.io/cran/actuar/man/ZeroTruncatedBinomial.html

which appears to be what you want.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 8:59 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Mailing list etiquette requires that you don't start a new thread by
> replying to an existing thread. Start a new thread with a fresh email.
>
> Also, this is a plain text mailing list... HTML formatting gets removed
> and what is left often does not look to the list readers like what you
> sent. Read the Posting Guide mentioned below for more about interacting
> with the list.
>
> On June 18, 2018 8:31:36 AM PDT, "Gagandeep S. Datta" <
> gagandeep_datta at hotmail.com> wrote:
> >Hi,
> >
> >Is there a code available for zero-truncated Binomial distribution on
> >the lines of zero-truncated Poisson distribution available at:
> >https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html
> >
> >Regards,
> >Gagandeep
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Jun 18 20:28:21 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 18 Jun 2018 11:28:21 -0700
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>

Note that:

xyplot(
   y~x,
   data = data,
   type = 'l', col="blue",
   panel = function(x,y,...){
      panel.xyplot(x,y,...)
      panel.abline(c(a^2-1,-1), col="red")
   }
)

works. The problem is a^2  is just above the "drawable" y axis limit (it is
the intercept of the line at x=0 with slope -1, of course). This also
explains all your other comments.

Cheers,
Bert



-- 

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

> Hi,
>
> I recently encountered situations in which reference lines are not drawn
> with the lattice panel.abline function. Please, consider the following
> example code:
>
>
> require(lattice)
>
> a <- runif(1,0,100)
> data <- data.frame(x=c(0,a^2), y=c(0,a^2))
>
> xyplot(
>   y~x,
>   data = data,
>   type = 'l',
>   panel = function(x,y,...){
>     panel.xyplot(x,y,...)
>     panel.abline(c(a^2,-1.0), col=2)
>   }
> )
>
> Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some
> axis limits seems to bypass the problem.
>
> The problem also happens for different data source and abline
> coefficients:
> data <- data.frame(x=c(18,81), y=c(18,81))
> ...
> panel.abline(c(99,-1.0), col=2)
>
>
> Thank you in advance for your feedback.
>
> Sebastien
>
> PS: the problem was also posted at https://github.com/deepayan/
> lattice/issues/8
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @eb@@tien@bihorel @ending from cognigencorp@com  Mon Jun 18 21:05:30 2018
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Mon, 18 Jun 2018 15:05:30 -0400 (EDT)
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
Message-ID: <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>


No, the intercept a^2 f the abline is exactly the upper limit of the data, so it is in the range. 


From: "Bert Gunter" <bgunter.4567 at gmail.com> 
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
Cc: "R-help" <r-help at r-project.org> 
Sent: Monday, June 18, 2018 2:28:21 PM 
Subject: Re: [R] Porbably bug in panel.abline 

Note that: 

xyplot( 
y~x, 
data = data, 
type = 'l', col="blue", 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2-1,-1), col="red") 
} 
) 

works. The problem is a^2 is just above the "drawable" y axis limit (it is the intercept of the line at x=0 with slope -1, of course). This also explains all your other comments. 

Cheers, 
Bert 



-- 

Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 


Hi, 

I recently encountered situations in which reference lines are not drawn with the lattice panel.abline function. Please, consider the following example code: 


require(lattice) 

a <- runif(1,0,100) 
data <- data.frame(x=c(0,a^2), y=c(0,a^2)) 

xyplot( 
y~x, 
data = data, 
type = 'l', 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2,-1.0), col=2) 
} 
) 

Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some axis limits seems to bypass the problem. 

The problem also happens for different data source and abline coefficients: 
data <- data.frame(x=c(18,81), y=c(18,81)) 
... 
panel.abline(c(99,-1.0), col=2) 


Thank you in advance for your feedback. 

Sebastien 

PS: the problem was also posted at [ https://github.com/deepayan/lattice/issues/8 | https://github.com/deepayan/lattice/issues/8 ] 

______________________________________________ 
[ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To UNSUBSCRIBE and more, see 
[ https://stat.ethz.ch/mailman/listinfo/r-help | https://stat.ethz.ch/mailman/listinfo/r-help ] 
PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html | http://www.R-project.org/posting-guide.html ] 
and provide commented, minimal, self-contained, reproducible code. 





	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Jun 18 22:15:29 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 18 Jun 2018 13:15:29 -0700
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
 <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbTwxi_jBbwyTx3BwGdGJVKcusVxdLgu8s7XEXgG+Tq9VA@mail.gmail.com>

hmmm...
Youre right: something subtle is occurring.

Here is a simpler reproducible example that illustrates the issue:

a <- 10
y <- x <- c(0,a)
for(k in c(-1,0,1)){
   print(xyplot(
      y~x,
      type = 'l', col="blue",
      panel = function(x,y,...){
         panel.xyplot(x,y,...)
         panel.abline(c(a+k,-1), col="red")
      }
   ))}

Somehow, the "drawable limits" seem to exclude the corners of the plotting
rectangle.

I would guess that this has something to do with how the plotting viewport
is clipped, but that's just a guess.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 12:05 PM, Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

>
> No, the intercept a^2 f the abline is exactly the upper limit of the data,
> so it is in the range.
>
> ------------------------------
> *From: *"Bert Gunter" <bgunter.4567 at gmail.com>
> *To: *"Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
> *Cc: *"R-help" <r-help at r-project.org>
> *Sent: *Monday, June 18, 2018 2:28:21 PM
> *Subject: *Re: [R] Porbably bug in panel.abline
>
> Note that:
>
> xyplot(
>    y~x,
>    data = data,
>    type = 'l', col="blue",
>    panel = function(x,y,...){
>       panel.xyplot(x,y,...)
>       panel.abline(c(a^2-1,-1), col="red")
>    }
> )
>
> works. The problem is a^2  is just above the "drawable" y axis limit (it
> is the intercept of the line at x=0 with slope -1, of course). This also
> explains all your other comments.
>
> Cheers,
> Bert
>
>
>
> --
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel <sebastien.bihorel@
> cognigencorp.com> wrote:
>
>> Hi,
>>
>> I recently encountered situations in which reference lines are not drawn
>> with the lattice panel.abline function. Please, consider the following
>> example code:
>>
>>
>> require(lattice)
>>
>> a <- runif(1,0,100)
>> data <- data.frame(x=c(0,a^2), y=c(0,a^2))
>>
>> xyplot(
>>   y~x,
>>   data = data,
>>   type = 'l',
>>   panel = function(x,y,...){
>>     panel.xyplot(x,y,...)
>>     panel.abline(c(a^2,-1.0), col=2)
>>   }
>> )
>>
>> Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some
>> axis limits seems to bypass the problem.
>>
>> The problem also happens for different data source and abline
>> coefficients:
>> data <- data.frame(x=c(18,81), y=c(18,81))
>> ...
>> panel.abline(c(99,-1.0), col=2)
>>
>>
>> Thank you in advance for your feedback.
>>
>> Sebastien
>>
>> PS: the problem was also posted at https://github.com/deepayan/
>> lattice/issues/8
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From @tephen66 @ending from gm@il@com  Mon Jun 18 22:46:57 2018
From: @tephen66 @ending from gm@il@com (Honkit Wong)
Date: Mon, 18 Jun 2018 13:46:57 -0700
Subject: [R] How to modify data frame stored in a list
Message-ID: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>

Dear R community,
I have a question seems very simple but have trouble to do it. 
I have a list which stores many data frames. Now, I want to perform log10 on one column in each data frame in the list and save the value as a new column back to the original data frame in the list. How do I quickly do that with lapply function ?

Many thanks. 

From b@mith030465 @ending from gm@il@com  Mon Jun 18 23:45:29 2018
From: b@mith030465 @ending from gm@il@com (Brian Smith)
Date: Mon, 18 Jun 2018 17:45:29 -0400
Subject: [R] numeric comparison error
Message-ID: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>

Hi,

I am a little bit perplexed at why I am getting some values as FALSE:

> cpgbins <- seq(0,1,0.05)

> cpgbins
 [1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65
0.70 0.75 0.80 0.85 0.90 0.95 1.00

> cpgbins[1] == 0.00
[1] TRUE
> cpgbins[2] == 0.05
[1] TRUE
> cpgbins[3] == 0.10
[1] TRUE
> cpgbins[4] == 0.15
[1] FALSE
> cpgbins[5] == 0.20
[1] TRUE
> cpgbins[6] == 0.25
[1] TRUE
> cpgbins[7] == 0.30
[1] FALSE

> class(cpgbins)
[1] "numeric"

> class(cpgbins[7])
[1] "numeric"

What is the cause for this?

thanks!!

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jun 18 23:50:17 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 18 Jun 2018 14:50:17 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
Message-ID: <DAE92D92-148A-4A34-827B-E6CF7DE2F32B@dcn.davis.ca.us>

Do you want it to run quickly or be quick to write?

Why have you specified that you want a solution that uses lapply? (Such constraints often arise in the context of homework, whereas someone interested in getting the job done does not usually care about which function is used.)

On June 18, 2018 1:46:57 PM PDT, Honkit Wong <stephen66 at gmail.com> wrote:
>Dear R community,
>I have a question seems very simple but have trouble to do it. 
>I have a list which stores many data frames. Now, I want to perform
>log10 on one column in each data frame in the list and save the value
>as a new column back to the original data frame in the list. How do I
>quickly do that with lapply function ?
>
>Many thanks. 
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From m@cqueen1 @ending from llnl@gov  Mon Jun 18 23:52:32 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 18 Jun 2018 21:52:32 +0000
Subject: [R] subsetting lists....
Message-ID: <7E0D239E-4A56-49A4-A2F5-F15924D1D6F9@llnl.gov>

The unlist solution is quite clever.

But I will note that none of the solutions offered so far succeed if the input is, for example,

   YH <- list(1:5, letters[1:3], 1:7)
    iuhV <- c(2,2,4)

and the desire is to return a list whose elements are of the same types as the input list. Which would be the sensible thing to do if the input list mixes types.

(Note that the output structure was not specified in the original question, nor was it stated whether the input list could mix types)

unlist(YH, recursive = FALSE, use.names = FALSE)[cumsum( lengths(YH)) - lengths(YH) + iuhV]
[1] "2" "b" "4"

However,

> lapply( 1:length(YH), function(i) { YH[[i]][iuhV[i]]})
[[1]]
[1] 2

[[2]]
[1] "b"

[[3]]
[1] 4

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/18/18, 10:00 AM, "R-help on behalf of Berry, Charles" <r-help-bounces at r-project.org on behalf of ccberry at ucsd.edu> wrote:

    
    
    > On Jun 18, 2018, at 4:15 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
    > 
    > correction....I want the method without a for loop
    
    Here are two. The first is more readable, but the second is 5 times faster.
    
    mapply("[", YH, iuhV)
    
    unlist(YH, recursive = FALSE, use.names = FALSE)[cumsum( lengths(YH)) - lengths(YH) + iuhV]
    
    HTH,
    
    Chuck
    
    > ________________________________
    > From: akshay kulkarni <akshay_e4 at hotmail.com>
    > Sent: Monday, June 18, 2018 4:25 PM
    > To: R help Mailing list
    > Subject: subsetting lists....
    > 
    > dear members,
    >                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...
    > 
    > How to do this?
    > I searched SO and the internet but was bootless....
    > 
    > Very many thanks for your time and effort.....
    > Yours sincerely,
    > AKSHAY M KULKARNI
    > 
    > 	[[alternative HTML version deleted]]
    > 
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Mon Jun 18 23:53:00 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 18 Jun 2018 14:53:00 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
Message-ID: <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>

It depends on whether you wish to refer to the column to be logged by name
or index.

Reprex:

set.seed(1234)
dat <- lapply(1:3, function(i)data.frame(a = runif(5), b =
sample(letters,5)))

## by numerical index of column
d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})

## by name of column
dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})

There are also slight variations on how you can do the "[" indexing that
others may post.
Note that you have to return the modified data frame in the function.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com> wrote:

> Dear R community,
> I have a question seems very simple but have trouble to do it.
> I have a list which stores many data frames. Now, I want to perform log10
> on one column in each data frame in the list and save the value as a new
> column back to the original data frame in the list. How do I quickly do
> that with lapply function ?
>
> Many thanks.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jun 18 23:53:11 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Mon, 18 Jun 2018 14:53:11 -0700
Subject: [R] numeric comparison error
In-Reply-To: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
References: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
Message-ID: <F7A22688-2365-42A9-BC6D-4D5BDA854E84@dcn.davis.ca.us>

FAQ 7.31, or take a university course in numerical analysis.

https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

On June 18, 2018 2:45:29 PM PDT, Brian Smith <bsmith030465 at gmail.com> wrote:
>Hi,
>
>I am a little bit perplexed at why I am getting some values as FALSE:
>
>> cpgbins <- seq(0,1,0.05)
>
>> cpgbins
>[1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60
>0.65
>0.70 0.75 0.80 0.85 0.90 0.95 1.00
>
>> cpgbins[1] == 0.00
>[1] TRUE
>> cpgbins[2] == 0.05
>[1] TRUE
>> cpgbins[3] == 0.10
>[1] TRUE
>> cpgbins[4] == 0.15
>[1] FALSE
>> cpgbins[5] == 0.20
>[1] TRUE
>> cpgbins[6] == 0.25
>[1] TRUE
>> cpgbins[7] == 0.30
>[1] FALSE
>
>> class(cpgbins)
>[1] "numeric"
>
>> class(cpgbins[7])
>[1] "numeric"
>
>What is the cause for this?
>
>thanks!!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Mon Jun 18 23:58:53 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 18 Jun 2018 14:58:53 -0700
Subject: [R] numeric comparison error
In-Reply-To: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
References: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
Message-ID: <CAGxFJbSCoH17i+XaOH-mEXf-a1HSFduhDYA1UMvrBAe_C4GrQw@mail.gmail.com>

FAQ 7.31.

Binary arithmetic.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 2:45 PM, Brian Smith <bsmith030465 at gmail.com> wrote:

> Hi,
>
> I am a little bit perplexed at why I am getting some values as FALSE:
>
> > cpgbins <- seq(0,1,0.05)
>
> > cpgbins
>  [1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65
> 0.70 0.75 0.80 0.85 0.90 0.95 1.00
>
> > cpgbins[1] == 0.00
> [1] TRUE
> > cpgbins[2] == 0.05
> [1] TRUE
> > cpgbins[3] == 0.10
> [1] TRUE
> > cpgbins[4] == 0.15
> [1] FALSE
> > cpgbins[5] == 0.20
> [1] TRUE
> > cpgbins[6] == 0.25
> [1] TRUE
> > cpgbins[7] == 0.30
> [1] FALSE
>
> > class(cpgbins)
> [1] "numeric"
>
> > class(cpgbins[7])
> [1] "numeric"
>
> What is the cause for this?
>
> thanks!!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Mon Jun 18 23:58:55 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Mon, 18 Jun 2018 21:58:55 +0000
Subject: [R] numeric comparison error
In-Reply-To: <F7A22688-2365-42A9-BC6D-4D5BDA854E84@dcn.davis.ca.us>
References: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
 <F7A22688-2365-42A9-BC6D-4D5BDA854E84@dcn.davis.ca.us>
Message-ID: <04854EA9-B098-4746-B823-985A3CDA19A8@llnl.gov>

What Jeff, said, plus to see it explicitly:

> print(cpgbins[5:7], digits=18)
[1] 0.200000000000000011 0.250000000000000000 0.300000000000000044

> print(c(0.2, 0.25, 0.3), digits=18)
[1] 0.200000000000000011 0.250000000000000000 0.299999999999999989

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/18/18, 2:53 PM, "R-help on behalf of Jeff Newmiller" <r-help-bounces at r-project.org on behalf of jdnewmil at dcn.davis.ca.us> wrote:

    FAQ 7.31, or take a university course in numerical analysis.
    
    https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
    
    On June 18, 2018 2:45:29 PM PDT, Brian Smith <bsmith030465 at gmail.com> wrote:
    >Hi,
    >
    >I am a little bit perplexed at why I am getting some values as FALSE:
    >
    >> cpgbins <- seq(0,1,0.05)
    >
    >> cpgbins
    >[1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60
    >0.65
    >0.70 0.75 0.80 0.85 0.90 0.95 1.00
    >
    >> cpgbins[1] == 0.00
    >[1] TRUE
    >> cpgbins[2] == 0.05
    >[1] TRUE
    >> cpgbins[3] == 0.10
    >[1] TRUE
    >> cpgbins[4] == 0.15
    >[1] FALSE
    >> cpgbins[5] == 0.20
    >[1] TRUE
    >> cpgbins[6] == 0.25
    >[1] TRUE
    >> cpgbins[7] == 0.30
    >[1] FALSE
    >
    >> class(cpgbins)
    >[1] "numeric"
    >
    >> class(cpgbins[7])
    >[1] "numeric"
    >
    >What is the cause for this?
    >
    >thanks!!
    >
    >	[[alternative HTML version deleted]]
    >
    >______________________________________________
    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >https://stat.ethz.ch/mailman/listinfo/r-help
    >PLEASE do read the posting guide
    >http://www.R-project.org/posting-guide.html
    >and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Sent from my phone. Please excuse my brevity.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @ending from gm@il@com  Tue Jun 19 00:04:57 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 18 Jun 2018 15:04:57 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
 <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
 <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
Message-ID: <CAGxFJbQDBtZ1KuLjxFE4oj19fpmE2ts4-wNB5Xy=ti4ehdPdng@mail.gmail.com>

search:

"Default function return R"

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 2:58 PM, Honkit Wong <stephen66 at gmail.com> wrote:

> Thanks!
> Why have to add ?x? at the end of function, which was what I missed.
>
> On Jun 18, 2018, at 2:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> It depends on whether you wish to refer to the column to be logged by name
> or index.
>
> Reprex:
>
> set.seed(1234)
> dat <- lapply(1:3, function(i)data.frame(a = runif(5), b =
> sample(letters,5)))
>
> ## by numerical index of column
> d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})
>
> ## by name of column
> dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})
>
> There are also slight variations on how you can do the "[" indexing that
> others may post.
> Note that you have to return the modified data frame in the function.
>
> Cheers,
> Bert
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com> wrote:
>
>> Dear R community,
>> I have a question seems very simple but have trouble to do it.
>> I have a list which stores many data frames. Now, I want to perform log10
>> on one column in each data frame in the list and save the value as a new
>> column back to the original data frame in the list. How do I quickly do
>> that with lapply function ?
>>
>> Many thanks.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From @tephen66 @ending from gm@il@com  Mon Jun 18 23:58:47 2018
From: @tephen66 @ending from gm@il@com (Honkit Wong)
Date: Mon, 18 Jun 2018 14:58:47 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
 <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
Message-ID: <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>

Thanks!
Why have to add ?x? at the end of function, which was what I missed. 

> On Jun 18, 2018, at 2:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> It depends on whether you wish to refer to the column to be logged by name or index.
> 
> Reprex:
> 
> set.seed(1234)
> dat <- lapply(1:3, function(i)data.frame(a = runif(5), b = sample(letters,5)))
> 
> ## by numerical index of column
> d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})
> 
> ## by name of column
> dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})
> 
> There are also slight variations on how you can do the "[" indexing that others may post.
> Note that you have to return the modified data frame in the function.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
>> On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com> wrote:
>> Dear R community,
>> I have a question seems very simple but have trouble to do it. 
>> I have a list which stores many data frames. Now, I want to perform log10 on one column in each data frame in the list and save the value as a new column back to the original data frame in the list. How do I quickly do that with lapply function ?
>> 
>> Many thanks. 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Tue Jun 19 01:12:07 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 18 Jun 2018 16:12:07 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
 <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
 <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
Message-ID: <CAF8bMcayfxSG9NJvdYSRkeeXBeyfB6khmqE_cNQotW1ffWKmCQ@mail.gmail.com>

 >Thanks!
>Why have to add ?x? at the end of function, which was what I missed.

You can see for yourself with some tests:

f1 <- function(x) { x[1] <- 10 }
f2 <- function(x) { x[1] <- 10 ; x }

print(f1(1:3)) # 10
print(f2(1:3)) # 10 2 3

An assignment returns the value of its right hand side but you want to
return the altered input.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 18, 2018 at 2:58 PM, Honkit Wong <stephen66 at gmail.com> wrote:

> Thanks!
> Why have to add ?x? at the end of function, which was what I missed.
>
> > On Jun 18, 2018, at 2:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > It depends on whether you wish to refer to the column to be logged by
> name or index.
> >
> > Reprex:
> >
> > set.seed(1234)
> > dat <- lapply(1:3, function(i)data.frame(a = runif(5), b =
> sample(letters,5)))
> >
> > ## by numerical index of column
> > d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})
> >
> > ## by name of column
> > dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})
> >
> > There are also slight variations on how you can do the "[" indexing that
> others may post.
> > Note that you have to return the modified data frame in the function.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >> On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com>
> wrote:
> >> Dear R community,
> >> I have a question seems very simple but have trouble to do it.
> >> I have a list which stores many data frames. Now, I want to perform
> log10 on one column in each data frame in the list and save the value as a
> new column back to the original data frame in the list. How do I quickly do
> that with lapply function ?
> >>
> >> Many thanks.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @eb@@tien@bihorel @ending from cognigencorp@com  Tue Jun 19 04:16:04 2018
From: @eb@@tien@bihorel @ending from cognigencorp@com (Sebastien Bihorel)
Date: Mon, 18 Jun 2018 22:16:04 -0400 (EDT)
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <CAGxFJbTwxi_jBbwyTx3BwGdGJVKcusVxdLgu8s7XEXgG+Tq9VA@mail.gmail.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
 <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbTwxi_jBbwyTx3BwGdGJVKcusVxdLgu8s7XEXgG+Tq9VA@mail.gmail.com>
Message-ID: <296327582.1754843.1529374564328.JavaMail.zimbra@cognigencorp.com>

Paul Murrell posted some comments on [ https://github.com/deepayan/lattice/issues/8 | https://github.com/deepayan/lattice/issues/8 ]

----- Original Message -----
From: "Bert Gunter" <bgunter.4567 at gmail.com>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
Cc: "R-help" <r-help at r-project.org>
Sent: Monday, June 18, 2018 4:15:29 PM
Subject: Re: [R] Porbably bug in panel.abline

hmmm... 
Youre right: something subtle is occurring. 

Here is a simpler reproducible example that illustrates the issue: 

a <- 10 
y <- x <- c(0,a) 
for(k in c(-1,0,1)){ 
print(xyplot( 
y~x, 
type = 'l', col="blue", 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a+k,-1), col="red") 
} 
))} 

Somehow, the "drawable limits" seem to exclude the corners of the plotting rectangle. 

I would guess that this has something to do with how the plotting viewport is clipped, but that's just a guess. 

Cheers, 
Bert 

Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Mon, Jun 18, 2018 at 12:05 PM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 




No, the intercept a^2 f the abline is exactly the upper limit of the data, so it is in the range. 


From: "Bert Gunter" < [ mailto:bgunter.4567 at gmail.com | bgunter.4567 at gmail.com ] > 
To: "Sebastien Bihorel" < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > 
Cc: "R-help" < [ mailto:r-help at r-project.org | r-help at r-project.org ] > 
Sent: Monday, June 18, 2018 2:28:21 PM 
Subject: Re: [R] Porbably bug in panel.abline 

Note that: 

xyplot( 
y~x, 
data = data, 
type = 'l', col="blue", 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2-1,-1), col="red") 
} 
) 

works. The problem is a^2 is just above the "drawable" y axis limit (it is the intercept of the line at x=0 with slope -1, of course). This also explains all your other comments. 

Cheers, 
Bert 



-- 

Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 

BQ_BEGIN
Hi, 

I recently encountered situations in which reference lines are not drawn with the lattice panel.abline function. Please, consider the following example code: 


require(lattice) 

a <- runif(1,0,100) 
data <- data.frame(x=c(0,a^2), y=c(0,a^2)) 

xyplot( 
y~x, 
data = data, 
type = 'l', 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2,-1.0), col=2) 
} 
) 

Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some axis limits seems to bypass the problem. 

The problem also happens for different data source and abline coefficients: 
data <- data.frame(x=c(18,81), y=c(18,81)) 
... 
panel.abline(c(99,-1.0), col=2) 


Thank you in advance for your feedback. 

Sebastien 

PS: the problem was also posted at [ https://github.com/deepayan/lattice/issues/8 | https://github.com/deepayan/lattice/issues/8 ] 

______________________________________________ 
[ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To UNSUBSCRIBE and more, see 
[ https://stat.ethz.ch/mailman/listinfo/r-help | https://stat.ethz.ch/mailman/listinfo/r-help ] 
PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html | http://www.R-project.org/posting-guide.html ] 
and provide commented, minimal, self-contained, reproducible code. 





BQ_END


From md@umner @ending from gm@il@com  Tue Jun 19 07:32:25 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Tue, 19 Jun 2018 12:32:25 +0700
Subject: [R] Subset Rasterbrick by time
In-Reply-To: <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
Message-ID: <CAAcGz99Md6L6efMRc7tBi+YFT7egGAnef4RYtnky-1eHCcnVYQ@mail.gmail.com>

On Mon, 18 Jun 2018, 22:09 David Winsemius, <dwinsemius at comcast.net> wrote:

>
>
> > On Jun 18, 2018, at 7:21 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all,
> >
> > I have a rasterbrick with the date/time information provided which I
> would
> > like to subset by year.
> >
> > However, when I use the following code for sub-setting;
> >
> > new_brick <- subset(original, which(getZ( original ) >=
> as.Date("2000-01-01
> > 10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))
> >
> > The date/time information seems to be lost.
> >
>

This is a bug, I tend to extract (getZ) the dates, do the subset logic on
both and restore (setZ).

It takes a bit of learning and practice, good luck. I can't expand more at
the moment. See R-Sig-Geo for more specific discussion forum, and #rstats
on twitter is really good.

Cheers, Mike

> > Furthermore, the class of the date/time seems to be character;
> >
> > ##
> > class(getZ( original ))
> > [1] "character"
> >
> > Is it possible to convert this string to date before sub-setting or
> retain
> > the date/time information after sub-setting?
>
> Yes, it is certainly possible, but why bother? R's Comparison operators
> work on character values so you should be able to do this (if the
> subsetting is syntactically correct:
>
>  new_brick <- subset(original, which(getZ( original ) >= "2000-01-01
> 10:30:00" & getZ(original ) <= "2014-12-31 10:30:00") )
>
>
> As always if you had presented the output of dput(head(original)) assuming
> that head is a meaningful operation on such an object, the demonstration
> would have been possible. An alternate would be to offer a library call to
> a package and then load a relevant example.
>
>
> Best;
> David
> >
> > ### original RasterBrick ###
> > class       : RasterBrick
> > dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
> > resolution  : 0.25, 0.25  (x, y)
> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > data source :
> >
> /work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_precip_windspd_sphum_daily_1986_2016.nc4
> > names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
> > X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
> > X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
> > X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
> > X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
> > X1986.01.15.10.30.00, ...
> > Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
> > varname     : v1
> >
> > ### new RasterBrick ###
> > class       : RasterStack
> > dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
> > resolution  : 0.25, 0.25  (x, y)
> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
> > X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
> > X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
> > X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
> > X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
> > X2000.01.15.10.30.00, ...
> >
> > Any help will be greatly appreciated.
> >
> > Sincerely,
> >
> > Milu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From miluji@b @ending from gm@il@com  Tue Jun 19 12:12:13 2018
From: miluji@b @ending from gm@il@com (Miluji Sb)
Date: Tue, 19 Jun 2018 12:12:13 +0200
Subject: [R] Subset Rasterbrick by time
In-Reply-To: <CAAcGz99Md6L6efMRc7tBi+YFT7egGAnef4RYtnky-1eHCcnVYQ@mail.gmail.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <CAAcGz99Md6L6efMRc7tBi+YFT7egGAnef4RYtnky-1eHCcnVYQ@mail.gmail.com>
Message-ID: <CAMLwc7MkDJh2vFQGCL5W9QM34cgPDfe2WXTZQGdb24uMd3KMEg@mail.gmail.com>

Dear David,

Subsetting works but the 'date' information is lost in the new file.

Thanks, Mike. I was not aware of the bug but will work on learning
about (getZ) and (setZ). Thanks again!

Sincerely,

Milu

On Tue, Jun 19, 2018 at 7:32 AM, Michael Sumner <mdsumner at gmail.com> wrote:

>
>
> On Mon, 18 Jun 2018, 22:09 David Winsemius, <dwinsemius at comcast.net>
> wrote:
>
>>
>>
>> > On Jun 18, 2018, at 7:21 AM, Miluji Sb <milujisb at gmail.com> wrote:
>> >
>> > Dear all,
>> >
>> > I have a rasterbrick with the date/time information provided which I
>> would
>> > like to subset by year.
>> >
>> > However, when I use the following code for sub-setting;
>> >
>> > new_brick <- subset(original, which(getZ( original ) >=
>> as.Date("2000-01-01
>> > 10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))
>> >
>> > The date/time information seems to be lost.
>> >
>>
>
> This is a bug, I tend to extract (getZ) the dates, do the subset logic on
> both and restore (setZ).
>
> It takes a bit of learning and practice, good luck. I can't expand more at
> the moment. See R-Sig-Geo for more specific discussion forum, and #rstats
> on twitter is really good.
>
> Cheers, Mike
>
>> > Furthermore, the class of the date/time seems to be character;
>> >
>> > ##
>> > class(getZ( original ))
>> > [1] "character"
>> >
>> > Is it possible to convert this string to date before sub-setting or
>> retain
>> > the date/time information after sub-setting?
>>
>> Yes, it is certainly possible, but why bother? R's Comparison operators
>> work on character values so you should be able to do this (if the
>> subsetting is syntactically correct:
>>
>>  new_brick <- subset(original, which(getZ( original ) >= "2000-01-01
>> 10:30:00" & getZ(original ) <= "2014-12-31 10:30:00") )
>>
>>
>> As always if you had presented the output of dput(head(original))
>> assuming that head is a meaningful operation on such an object, the
>> demonstration would have been possible. An alternate would be to offer a
>> library call to a package and then load a relevant example.
>>
>>
>> Best;
>> David
>> >
>> > ### original RasterBrick ###
>> > class       : RasterBrick
>> > dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
>> > resolution  : 0.25, 0.25  (x, y)
>> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > data source :
>> > /work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_
>> precip_windspd_sphum_daily_1986_2016.nc4
>> > names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
>> > X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
>> > X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
>> > X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
>> > X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
>> > X1986.01.15.10.30.00, ...
>> > Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
>> > varname     : v1
>> >
>> > ### new RasterBrick ###
>> > class       : RasterStack
>> > dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
>> > resolution  : 0.25, 0.25  (x, y)
>> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
>> > X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
>> > X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
>> > X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
>> > X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
>> > X2000.01.15.10.30.00, ...
>> >
>> > Any help will be greatly appreciated.
>> >
>> > Sincerely,
>> >
>> > Milu
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> <https://maps.google.com/?q=203+Channel+Highway+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
> Kingston Tasmania 7050 Australia
> <https://maps.google.com/?q=203+Channel+Highway+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
>
>

	[[alternative HTML version deleted]]


From m@ckenzietjone@ @ending from gm@il@com  Tue Jun 19 23:54:42 2018
From: m@ckenzietjone@ @ending from gm@il@com (Mackenzie Jones)
Date: Tue, 19 Jun 2018 16:54:42 -0500
Subject: [R] Multinomial Logistic Regression with Complex Survey using
 'Survey' Package in R
Message-ID: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>

Dear R Users,

I want to use a multinomial logistic regression model with survey data in the ?survey? package. The original package did not have a function for multinomial logistic regression, so Thomas Lumley suggested creating replicate weights for the survey and doing a multinomial regression with frequency weights in the mlogit package. See the below message for reference:

There isn't an implementation of multinomial regression in the survey package.  The easiest way to do this would be to create replicate weights for your survey if it doesn't already have them (with
as.svrepdesign()) and then use withReplicates() to do the regression using a function that does multinomial regression with frequency weights, such as mlogit() in the mlogit package.  The example on the withReplicates() help page shows how to do this for quantile regression, and it should be similar.

However, there has been a more recent release of the ?survey? package in May 2018, so I am wondering if there is now a function that does multinomial logistic regression with the survey. Please let me know if anyone knows of this update, or has any additional advice on how to perform this function.

Thank you,
Mackenzie


	[[alternative HTML version deleted]]


From @jd@mico @ending from gm@il@com  Wed Jun 20 00:11:34 2018
From: @jd@mico @ending from gm@il@com (Anthony Damico)
Date: Tue, 19 Jun 2018 18:11:34 -0400
Subject: [R] Multinomial Logistic Regression with Complex Survey using
 'Survey' Package in R
In-Reply-To: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
References: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
Message-ID: <CAOwvMDy0PiVaAF1fufRNJ9C8RPA5fT92nzjep1NHG+56oB8G_Q@mail.gmail.com>

hi, check out the news page..
https://cran.r-project.org/web/packages/survey/NEWS

On Tue, Jun 19, 2018 at 5:54 PM, Mackenzie Jones <mackenzietjones at gmail.com>
wrote:

> Dear R Users,
>
> I want to use a multinomial logistic regression model with survey data in
> the ?survey? package. The original package did not have a function for
> multinomial logistic regression, so Thomas Lumley suggested creating
> replicate weights for the survey and doing a multinomial regression with
> frequency weights in the mlogit package. See the below message for
> reference:
>
> There isn't an implementation of multinomial regression in the survey
> package.  The easiest way to do this would be to create replicate weights
> for your survey if it doesn't already have them (with
> as.svrepdesign()) and then use withReplicates() to do the regression using
> a function that does multinomial regression with frequency weights, such as
> mlogit() in the mlogit package.  The example on the withReplicates() help
> page shows how to do this for quantile regression, and it should be similar.
>
> However, there has been a more recent release of the ?survey? package in
> May 2018, so I am wondering if there is now a function that does
> multinomial logistic regression with the survey. Please let me know if
> anyone knows of this update, or has any additional advice on how to perform
> this function.
>
> Thank you,
> Mackenzie
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Jun 20 00:33:40 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Tue, 19 Jun 2018 15:33:40 -0700
Subject: [R] Multinomial Logistic Regression with Complex Survey using
 'Survey' Package in R
In-Reply-To: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
References: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
Message-ID: <CAGxFJbQgpVV45P8=Owc2pjdvg1VD8ZitsMb2QXR7KrK2rrYF6A@mail.gmail.com>

Did you download the new package and check? Is there some reason you
shouldn't do this in any case?

There is also usually a News file in the package download that tells you
about new features.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jun 19, 2018 at 2:54 PM, Mackenzie Jones <mackenzietjones at gmail.com>
wrote:

> Dear R Users,
>
> I want to use a multinomial logistic regression model with survey data in
> the ?survey? package. The original package did not have a function for
> multinomial logistic regression, so Thomas Lumley suggested creating
> replicate weights for the survey and doing a multinomial regression with
> frequency weights in the mlogit package. See the below message for
> reference:
>
> There isn't an implementation of multinomial regression in the survey
> package.  The easiest way to do this would be to create replicate weights
> for your survey if it doesn't already have them (with
> as.svrepdesign()) and then use withReplicates() to do the regression using
> a function that does multinomial regression with frequency weights, such as
> mlogit() in the mlogit package.  The example on the withReplicates() help
> page shows how to do this for quantile regression, and it should be similar.
>
> However, there has been a more recent release of the ?survey? package in
> May 2018, so I am wondering if there is now a function that does
> multinomial logistic regression with the survey. Please let me know if
> anyone knows of this update, or has any additional advice on how to perform
> this function.
>
> Thank you,
> Mackenzie
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From @igbert @ending from wiwi@hu-berlin@de  Wed Jun 20 10:08:11 2018
From: @igbert @ending from wiwi@hu-berlin@de (Sigbert Klinke)
Date: Wed, 20 Jun 2018 10:08:11 +0200
Subject: [R] Extract function parameters from a R expression
Message-ID: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>

Hi,

I have read an R program with

expr <- parse("myRprg.R")

How can I extract the parameters of a specifc R command, e.g. "library"?

So, if myprg.R containes the lines

library("xyz")
library("abc")

then I would like to get "xyz" and "abc" back from expr.

Thanks in advance

Sigbert

-- 
https://hu.berlin/sk



From h@wickh@m @ending from gm@il@com  Wed Jun 20 10:26:10 2018
From: h@wickh@m @ending from gm@il@com (Hadley Wickham)
Date: Wed, 20 Jun 2018 10:26:10 +0200
Subject: [R] Extract function parameters from a R expression
In-Reply-To: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
References: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
Message-ID: <CABdHhvERFOwgg0tSNbYUFp9wt23TRw_TdAp8YJ97KfXED90g8w@mail.gmail.com>

You need to recursively walk the parse tree/AST. See, e.g.,
https://adv-r.hadley.nz/expressions.html#ast-funs

Hadley

On Wed, Jun 20, 2018 at 10:08 AM, Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
> Hi,
>
> I have read an R program with
>
> expr <- parse("myRprg.R")
>
> How can I extract the parameters of a specifc R command, e.g. "library"?
>
> So, if myprg.R containes the lines
>
> library("xyz")
> library("abc")
>
> then I would like to get "xyz" and "abc" back from expr.
>
> Thanks in advance
>
> Sigbert
>
> --
> https://hu.berlin/sk
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
http://hadley.nz


From je@nphilippe@font@ine @ending from g@@i@infn@it  Wed Jun 20 12:53:00 2018
From: je@nphilippe@font@ine @ending from g@@i@infn@it (jean-philippe)
Date: Wed, 20 Jun 2018 12:53:00 +0200
Subject: [R] interpret a p-value result as a significance of a linear
 regression in terms of sigmas
Message-ID: <5B2A320C.9070301@gssi.infn.it>

dear R community,

I am running a linear regression for my dataset between 2 variables 
(disk mass and velocities).
This is the result returned by the summary function onto the lm object 
for one of my dataset.

Call:
lm(formula = df$md1 ~ df$logV, data = df)

Residuals:
      Min       1Q   Median       3Q      Max
-0.64856 -0.16492  0.04127  0.18027  0.45727

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)   6.2582     0.2682  23.333  < 2e-16 ***
df$logV       1.2926     0.2253   5.738  6.5e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.3067 on 24 degrees of freedom
Multiple R-squared:  0.5784,    Adjusted R-squared:  0.5609
F-statistic: 32.93 on 1 and 24 DF,  p-value: 6.504e-06


I am interested to give the significance in terms of sigmas (as 
generally done in particle physics, see for instance the 7 \sigma 
discovery of the Higgs particle)
of my regression.
For this, if I understood well, I should look at the p-value for the 
F-statistic which is in this univariate linear regression the same as 
the one for logV.

My question is, am I right if I state that the significance in terms of 
sigmas (sign) is given by: p = 2*(1-pnorm(sign)) since I guess the 
p-value returned by R is for a two sided test (and assuming Gaussianity 
for my dataset)?

Otherwise is there any way to get the significance of this linear 
regression in terms of sigmas?

I would have a similar question also, as extension, for a multivariate 
linear regression for which the p-value associated to F statistics is 
not the same as the p-value for each variable of the regression.



Thanks in advance,


Best Regards


Jean-Philippe Fontaine

-- 
Jean-Philippe Fontaine
PhD Student in Astroparticle Physics,
Gran Sasso Science Institute (GSSI),
Viale Francesco Crispi 7,
67100 L'Aquila, Italy
Mobile: +393487128593, +33615653774


From bgunter@4567 @ending from gm@il@com  Wed Jun 20 13:24:27 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 20 Jun 2018 04:24:27 -0700
Subject: [R] Extract function parameters from a R expression
In-Reply-To: <CABdHhvERFOwgg0tSNbYUFp9wt23TRw_TdAp8YJ97KfXED90g8w@mail.gmail.com>
References: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
 <CABdHhvERFOwgg0tSNbYUFp9wt23TRw_TdAp8YJ97KfXED90g8w@mail.gmail.com>
Message-ID: <CAGxFJbRJTVAoEcCOD4iZ9-NzTP++sV-mBrX+VEqVV-jPtr2K5g@mail.gmail.com>

... or if the argument is just quoted text or a numeric value as in your
library() example, don't parse the text and use regex's to search for the
function call and pick out the text of the arguments.

Again, this only works (I think) for the simple sort of case of your
example. Beyond that, you'll have to follow Hadley's prescription.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 20, 2018 at 1:26 AM, Hadley Wickham <h.wickham at gmail.com> wrote:

> You need to recursively walk the parse tree/AST. See, e.g.,
> https://adv-r.hadley.nz/expressions.html#ast-funs
>
> Hadley
>
> On Wed, Jun 20, 2018 at 10:08 AM, Sigbert Klinke
> <sigbert at wiwi.hu-berlin.de> wrote:
> > Hi,
> >
> > I have read an R program with
> >
> > expr <- parse("myRprg.R")
> >
> > How can I extract the parameters of a specifc R command, e.g. "library"?
> >
> > So, if myprg.R containes the lines
> >
> > library("xyz")
> > library("abc")
> >
> > then I would like to get "xyz" and "abc" back from expr.
> >
> > Thanks in advance
> >
> > Sigbert
> >
> > --
> > https://hu.berlin/sk
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> http://hadley.nz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From murdoch@dunc@n @ending from gm@il@com  Wed Jun 20 13:42:48 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Wed, 20 Jun 2018 07:42:48 -0400
Subject: [R] interpret a p-value result as a significance of a linear
 regression in terms of sigmas
In-Reply-To: <5B2A320C.9070301@gssi.infn.it>
References: <5B2A320C.9070301@gssi.infn.it>
Message-ID: <fda79607-1ebe-251f-55f4-4bcaf7f3b777@gmail.com>

On 20/06/2018 6:53 AM, jean-philippe wrote:
> dear R community,
> 
> I am running a linear regression for my dataset between 2 variables
> (disk mass and velocities).
> This is the result returned by the summary function onto the lm object
> for one of my dataset.
> 
> Call:
> lm(formula = df$md1 ~ df$logV, data = df)
> 
> Residuals:
>        Min       1Q   Median       3Q      Max
> -0.64856 -0.16492  0.04127  0.18027  0.45727
> 
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)   6.2582     0.2682  23.333  < 2e-16 ***
> df$logV       1.2926     0.2253   5.738  6.5e-06 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 0.3067 on 24 degrees of freedom
> Multiple R-squared:  0.5784,    Adjusted R-squared:  0.5609
> F-statistic: 32.93 on 1 and 24 DF,  p-value: 6.504e-06
> 
> 
> I am interested to give the significance in terms of sigmas (as
> generally done in particle physics, see for instance the 7 \sigma
> discovery of the Higgs particle)
> of my regression.
> For this, if I understood well, I should look at the p-value for the
> F-statistic which is in this univariate linear regression the same as
> the one for logV.

The t value is probably what you want, but I think you'll have to ask 
your supervisor for the definition used in your area.

Duncan Murdoch

> 
> My question is, am I right if I state that the significance in terms of
> sigmas (sign) is given by: p = 2*(1-pnorm(sign)) since I guess the
> p-value returned by R is for a two sided test (and assuming Gaussianity
> for my dataset)?
> 
> Otherwise is there any way to get the significance of this linear
> regression in terms of sigmas?
> 
> I would have a similar question also, as extension, for a multivariate
> linear regression for which the p-value associated to F statistics is
> not the same as the p-value for each variable of the regression.
> 
> 
> 
> Thanks in advance,
> 
> 
> Best Regards
> 
> 
> Jean-Philippe Fontaine
>


From pd@lgd @ending from gm@il@com  Wed Jun 20 13:45:57 2018
From: pd@lgd @ending from gm@il@com (Peter Dalgaard)
Date: Wed, 20 Jun 2018 13:45:57 +0200
Subject: [R] interpret a p-value result as a significance of a linear
 regression in terms of sigmas
In-Reply-To: <5B2A320C.9070301@gssi.infn.it>
References: <5B2A320C.9070301@gssi.infn.it>
Message-ID: <61406CD4-5CF3-4852-B06A-6114D9B8179F@gmail.com>

Sorry to say so, but you seem confused. 

The "sigma" in physics parlance is presumably the s.e. of the estimate so the "number of sigmas" equal the t statistic, in this case 5.738. However, use of that measure ignores the t distribution, effectively assuming that there are infinite df (and 24 in not quite infinite). 

- pd

> On 20 Jun 2018, at 12:53 , jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
> 
> dear R community,
> 
> I am running a linear regression for my dataset between 2 variables (disk mass and velocities).
> This is the result returned by the summary function onto the lm object for one of my dataset.
> 
> Call:
> lm(formula = df$md1 ~ df$logV, data = df)
> 
> Residuals:
>     Min       1Q   Median       3Q      Max
> -0.64856 -0.16492  0.04127  0.18027  0.45727
> 
> Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)   6.2582     0.2682  23.333  < 2e-16 ***
> df$logV       1.2926     0.2253   5.738  6.5e-06 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 0.3067 on 24 degrees of freedom
> Multiple R-squared:  0.5784,    Adjusted R-squared:  0.5609
> F-statistic: 32.93 on 1 and 24 DF,  p-value: 6.504e-06
> 
> 
> I am interested to give the significance in terms of sigmas (as generally done in particle physics, see for instance the 7 \sigma discovery of the Higgs particle)
> of my regression.
> For this, if I understood well, I should look at the p-value for the F-statistic which is in this univariate linear regression the same as the one for logV.
> 
> My question is, am I right if I state that the significance in terms of sigmas (sign) is given by: p = 2*(1-pnorm(sign)) since I guess the p-value returned by R is for a two sided test (and assuming Gaussianity for my dataset)?
> 
> Otherwise is there any way to get the significance of this linear regression in terms of sigmas?
> 
> I would have a similar question also, as extension, for a multivariate linear regression for which the p-value associated to F statistics is not the same as the p-value for each variable of the regression.
> 
> 
> 
> Thanks in advance,
> 
> 
> Best Regards
> 
> 
> Jean-Philippe Fontaine
> 
> -- 
> Jean-Philippe Fontaine
> PhD Student in Astroparticle Physics,
> Gran Sasso Science Institute (GSSI),
> Viale Francesco Crispi 7,
> 67100 L'Aquila, Italy
> Mobile: +393487128593, +33615653774
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ggrothendieck @ending from gm@il@com  Wed Jun 20 13:52:49 2018
From: ggrothendieck @ending from gm@il@com (Gabor Grothendieck)
Date: Wed, 20 Jun 2018 07:52:49 -0400
Subject: [R] Extract function parameters from a R expression
In-Reply-To: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
References: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
Message-ID: <CAP01uRmn68-=mRwK3FKMaR25Y5d8++H0CQMEydMFv0VxD=ZWAw@mail.gmail.com>

If you specifically want to know which packages were loaded by the script
then using a vanilla version of R (i.e. one where only base packages are
loaded):

  vanilla_search <- search()
  source("myRprg.R")
  setdiff(search(), vanilla_search)



On Wed, Jun 20, 2018 at 4:08 AM, Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
> Hi,
>
> I have read an R program with
>
> expr <- parse("myRprg.R")
>
> How can I extract the parameters of a specifc R command, e.g. "library"?
>
> So, if myprg.R containes the lines
>
> library("xyz")
> library("abc")
>
> then I would like to get "xyz" and "abc" back from expr.
>
> Thanks in advance
>
> Sigbert
>
> --
> https://hu.berlin/sk
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From lorenzo@i@ell@ @ending from gm@il@com  Wed Jun 20 17:50:48 2018
From: lorenzo@i@ell@ @ending from gm@il@com (Lorenzo Isella)
Date: Wed, 20 Jun 2018 17:50:48 +0200
Subject: [R] Optimisation with Normalisation Constraint
Message-ID: <20180620155048.luwh3w7o7cp5lujr@masha>

Dear All,
I have a problem I haver been struggling with for a while: I need to
carry out a non-linear fit (and this is the
easy part).
I have a set of discrete values {x1,x2...xN} and the corresponding
{y1, y2...yN}. The difficulty is that I would like the linear fit to
preserve the sum of the values y1+y2+...yN.
I give an example below (for which there may even be an analytical
solution, but that is not the point here)

############################################################################
library(minpack.lm)



set.seed(124)

z <- rexp(3000,3)


zf <- z[z<= 0.5 | z>=0.9]

myhist <- hist(zf, plot=FALSE) 



df <- data.frame(x=myhist$mids, y=myhist$density)



myfit <- nlsLM(y~(A*exp(-lambda*x))
                ,data=df, start=list(A=1,lambda=1))



> sum(myhist$density)
[1] 5
> sum(predict(myfit))
[1] 4.931496

############################################################################
I would like sum(predict(myfit)) to be exactly 5 from the start,
without renormalising a posteriori the fit.

Any suggestion is appreciated.
Cheers

Lorenzo


From p@ulbern@l07 @ending from gm@il@com  Wed Jun 20 18:00:53 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Wed, 20 Jun 2018 11:00:53 -0500
Subject: [R] Any Unsupervised Learning Algorithm for Time Series Forecasting
 in R
Message-ID: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>

Dear friends,

Hope you are all doing great. I would like to know if R has any
unsupervised algorithm to generate forecasts for historical data.

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Jun 20 18:30:51 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 20 Jun 2018 09:30:51 -0700
Subject: [R] 
 Any Unsupervised Learning Algorithm for Time Series Forecasting in R
In-Reply-To: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
References: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
Message-ID: <CAGxFJbTreby+0qo1J=GUhNTasYORyPrqfHjV4ffVHs491ZS5CA@mail.gmail.com>

Depending on exactly what you mean by"unsupervised", many.

See here under "Decomposition and filtering":

https://cran.r-project.org/web/views/TimeSeries.html

You could also search on something like "smooth time series R" etc.

However, assuming I have correcty interpreted "unsupervised algorithm," be
aware that extrapolating from such smoothed historical data can be
problematic precisely because no structure/model has been specified. See
here for some further background and R functions:

http://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html#holt-winters-exponential-smoothing


Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 20, 2018 at 9:00 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friends,
>
> Hope you are all doing great. I would like to know if R has any
> unsupervised algorithm to generate forecasts for historical data.
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Wed Jun 20 18:34:34 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 20 Jun 2018 09:34:34 -0700
Subject: [R] 
 Any Unsupervised Learning Algorithm for Time Series Forecasting in R
In-Reply-To: <CAGxFJbTreby+0qo1J=GUhNTasYORyPrqfHjV4ffVHs491ZS5CA@mail.gmail.com>
References: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
 <CAGxFJbTreby+0qo1J=GUhNTasYORyPrqfHjV4ffVHs491ZS5CA@mail.gmail.com>
Message-ID: <CAGxFJbSV6N54KUQdsDeRvjF8rFttMbXMRjtPmTe5eEEFu6jkFw@mail.gmail.com>

... and II should have added that the "forecast" package may be what you're
looking for.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 20, 2018 at 9:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Depending on exactly what you mean by"unsupervised", many.
>
> See here under "Decomposition and filtering":
>
> https://cran.r-project.org/web/views/TimeSeries.html
>
> You could also search on something like "smooth time series R" etc.
>
> However, assuming I have correcty interpreted "unsupervised algorithm," be
> aware that extrapolating from such smoothed historical data can be
> problematic precisely because no structure/model has been specified. See
> here for some further background and R functions:
>
> http://a-little-book-of-r-for-time-series.readthedocs.io/en/
> latest/src/timeseries.html#holt-winters-exponential-smoothing
>
>
> Cheers,
> Bert
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Jun 20, 2018 at 9:00 AM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear friends,
>>
>> Hope you are all doing great. I would like to know if R has any
>> unsupervised algorithm to generate forecasts for historical data.
>>
>> Any help will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From h@@@n@diw@n @ending from gm@il@com  Wed Jun 20 22:46:31 2018
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Wed, 20 Jun 2018 13:46:31 -0700
Subject: [R] 
 Any Unsupervised Learning Algorithm for Time Series Forecasting in R
In-Reply-To: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
References: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
Message-ID: <CAP+bYWDpfwQjrFROpCdNM8w-5KzFgU6Oawsm+brcGZ3Y=kh_YA@mail.gmail.com>

Paul,

On Wed, 20 Jun 2018 at 09:04, Paul Bernal <paulbernal07 at gmail.com> wrote:
> I would like to know if R has any unsupervised algorithm to generate forecasts for historical data.

Yes , it does. Perhaps you'd be kind enough to provide a sample of
your data --dput(sample(pauls.data)) on gist.github.com -- and what
you wish to achieve with it? Many thanks! -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jun 21 00:21:29 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 20 Jun 2018 15:21:29 -0700
Subject: [R] Optimisation with Normalisation Constraint
In-Reply-To: <20180620155048.luwh3w7o7cp5lujr@masha>
References: <20180620155048.luwh3w7o7cp5lujr@masha>
Message-ID: <697B5B62-649C-463C-86EA-D00BE707A0F8@dcn.davis.ca.us>

I recommend posting this on a mathematics discussion forum like Stack Exchange and (re-)reading the Posting Guide for this mailing list.

I think you are going to need to re-write your model function to algebraically combine your original model along with the constraint, and then use the original model alone for prediction... but I haven't tried it so might be quite far off the mark.

On June 20, 2018 8:50:48 AM PDT, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
>Dear All,
>I have a problem I haver been struggling with for a while: I need to
>carry out a non-linear fit (and this is the
>easy part).
>I have a set of discrete values {x1,x2...xN} and the corresponding
>{y1, y2...yN}. The difficulty is that I would like the linear fit to
>preserve the sum of the values y1+y2+...yN.
>I give an example below (for which there may even be an analytical
>solution, but that is not the point here)
>
>############################################################################
>library(minpack.lm)
>
>
>
>set.seed(124)
>
>z <- rexp(3000,3)
>
>
>zf <- z[z<= 0.5 | z>=0.9]
>
>myhist <- hist(zf, plot=FALSE) 
>
>
>
>df <- data.frame(x=myhist$mids, y=myhist$density)
>
>
>
>myfit <- nlsLM(y~(A*exp(-lambda*x))
>                ,data=df, start=list(A=1,lambda=1))
>
>
>
>> sum(myhist$density)
>[1] 5
>> sum(predict(myfit))
>[1] 4.931496
>
>############################################################################
>I would like sum(predict(myfit)) to be exactly 5 from the start,
>without renormalising a posteriori the fit.
>
>Any suggestion is appreciated.
>Cheers
>
>Lorenzo
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From dwin@emiu@ @ending from comc@@t@net  Thu Jun 21 02:04:28 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Wed, 20 Jun 2018 17:04:28 -0700
Subject: [R] Optimisation with Normalisation Constraint
In-Reply-To: <20180620155048.luwh3w7o7cp5lujr@masha>
References: <20180620155048.luwh3w7o7cp5lujr@masha>
Message-ID: <D19FBACC-3A56-41BB-9D4F-038803F08A86@comcast.net>


> On Jun 20, 2018, at 8:50 AM, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> 
> Dear All,
> I have a problem I haver been struggling with for a while: I need to
> carry out a non-linear fit (and this is the
> easy part).
> I have a set of discrete values {x1,x2...xN} and the corresponding
> {y1, y2...yN}. The difficulty is that I would like the linear fit to
> preserve the sum of the values y1+y2+...yN.
> I give an example below (for which there may even be an analytical
> solution, but that is not the point here)
> 
> ############################################################################
> library(minpack.lm)
> 
> 
> 
> set.seed(124)
> 
> z <- rexp(3000,3)
> 
> 
> zf <- z[z<= 0.5 | z>=0.9]
> 
> myhist <- hist(zf, plot=FALSE) 
> 
> 
> df <- data.frame(x=myhist$mids, y=myhist$density)
> 
> 
> 
> myfit <- nlsLM(y~(A*exp(-lambda*x))
>               ,data=df, start=list(A=1,lambda=1))
> 
> 
> 
>> sum(myhist$density)
> [1] 5
>> sum(predict(myfit))
> [1] 4.931496
> 
> ############################################################################
> I would like sum(predict(myfit)) to be exactly 5 from the start,
> without renormalising a posteriori the fit.

Wouldn't that happen if you minimized that absolute deviations from the fit rather than minimizing the sums of squares??
> 
> Any suggestion is appreciated.
> Cheers
> 
> Lorenzo
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From @k@h@y_e4 @ending from hotm@il@com  Thu Jun 21 12:28:03 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Thu, 21 Jun 2018 10:28:03 +0000
Subject: [R] compiling functions....
Message-ID: <SL2P216MB00911F10E3834E8F0232FF2BC8760@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I a Day Trader based in INDIA. I use R for my research. I have a function ygusa(snlq,snlcqn) which takes 208 stocks and returns 4 best stocks for the next day(snlq is the list of 208 stocks and snlcqn is their names). However, the execution time is around 2 hrs, making it hard for me.

I recently read in the internet that you can precompile the code in R to make it run faster. Also that you can enable JIT(just in time compilation) from your R session automatically. I came to know that R 3.4.x has JIT enabled in it by default. Is it true? Is it also true that even after enabling JIT in R 3.4.x, the first run of a function is not Byte compiled?

So when I start my R session, download the data, and run ygusa(snlq,snlcqn), it is not byte compiled and therefore it is very slow? Will including the following lines in ygusa solve my problem:
> require(compiler)
> enableJIT(3)

?

Also, instead of compiling the function ygusa every time I run it, can I compile it once and store it, and run that compiled file instead of ygusa(snlq,snlcqn)?

Can you point me to some online resources that can help on this issue?

very many thanks for your time and effort...
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From @@r@h@go@lee @ending from gm@il@com  Thu Jun 21 15:29:45 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Thu, 21 Jun 2018 09:29:45 -0400
Subject: [R] compiling functions....
In-Reply-To: <SL2P216MB00911F10E3834E8F0232FF2BC8760@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00911F10E3834E8F0232FF2BC8760@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAM_vjun6kQZFHNYT1GbGOSC=L7rq+J9icsQw3nnj=S2+51eYbg@mail.gmail.com>

There are many things you can do to improve speed in R. Byte compiling
is just one of them.

This chapter in Hadley Wickham's excellent Advanced R book covers both
profiling and byte compiling.

http://adv-r.had.co.nz/Profiling.html

I've gotten some stunning improvements in speed through profiling and
careful thought: 3 days to 3 seconds, even.

Sarah

On Thu, Jun 21, 2018 at 6:28 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> dear members,
>                             I a Day Trader based in INDIA. I use R for my research. I have a function ygusa(snlq,snlcqn) which takes 208 stocks and returns 4 best stocks for the next day(snlq is the list of 208 stocks and snlcqn is their names). However, the execution time is around 2 hrs, making it hard for me.
>
> I recently read in the internet that you can precompile the code in R to make it run faster. Also that you can enable JIT(just in time compilation) from your R session automatically. I came to know that R 3.4.x has JIT enabled in it by default. Is it true? Is it also true that even after enabling JIT in R 3.4.x, the first run of a function is not Byte compiled?
>
> So when I start my R session, download the data, and run ygusa(snlq,snlcqn), it is not byte compiled and therefore it is very slow? Will including the following lines in ygusa solve my problem:
>> require(compiler)
>> enableJIT(3)
>
> ?
>
> Also, instead of compiling the function ygusa every time I run it, can I compile it once and store it, and run that compiled file instead of ygusa(snlq,snlcqn)?
>
> Can you point me to some online resources that can help on this issue?
>
> very many thanks for your time and effort...
> Yours sincerely,
> AKSHAY M KULKARNI
>


-- 
Sarah Goslee
http://www.functionaldiversity.org


From reichm@nj @ending from @bcglob@l@net  Thu Jun 21 18:35:36 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Thu, 21 Jun 2018 11:35:36 -0500
Subject: [R] KNN
Message-ID: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>

R-Help

 

Does one need to normalize ones data is using the knn function within the
caret Library.

 

Jeff


	[[alternative HTML version deleted]]


From dc@rl@on @ending from t@mu@edu  Thu Jun 21 18:43:00 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Thu, 21 Jun 2018 16:43:00 +0000
Subject: [R] KNN
In-Reply-To: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
References: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
Message-ID: <a483a42a966f46c9aaa715c3b33162c2@tamu.edu>

It depends on what you are trying to do and what kind of data you are using. If you are using Euclidian distance and your variables have different means and standard deviations, the answer is probably yes. That will weight each variable equally. Without standardization the variables with the larger magnitudes will determine the groups more than the variables with the smaller magnitudes.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Reichman
Sent: Thursday, June 21, 2018 11:36 AM
To: R-help at r-project.org
Subject: [R] KNN

R-Help

 

Does one need to normalize ones data is using the knn function within the
caret Library.

 

Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From hello @ending from eivinddovik@com  Thu Jun 21 18:46:05 2018
From: hello @ending from eivinddovik@com (Eivind K. Dovik)
Date: Thu, 21 Jun 2018 18:46:05 +0200 (CEST)
Subject: [R] KNN
In-Reply-To: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
References: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
Message-ID: <alpine.LFD.2.21.1806211843390.911@localhost>

Yes, however using caret you  can do it directly 
using the preProcess parameter, e.g. train(y ~., data 
= train, method = "knn", preProcess = c("center", "scale")).

Hope this helps.


Eivind


On Thu, 21 Jun 2018, Jeff Reichman wrote:

> R-Help
>
>
>
> Does one need to normalize ones data is using the knn function within the
> caret Library.
>
>
>
> Jeff
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From reichm@nj @ending from @bcglob@l@net  Thu Jun 21 18:46:54 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Thu, 21 Jun 2018 11:46:54 -0500
Subject: [R] KNN
In-Reply-To: <a483a42a966f46c9aaa715c3b33162c2@tamu.edu>
References: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
 <a483a42a966f46c9aaa715c3b33162c2@tamu.edu>
Message-ID: <000d01d4097f$764caca0$62e605e0$@sbcglobal.net>

David

I figured out where I went wrong.  But thank you for the response

Jeff

-----Original Message-----
From: David L Carlson <dcarlson at tamu.edu> 
Sent: Thursday, June 21, 2018 11:43 AM
To: reichmanj at sbcglobal.net; R-help at r-project.org
Subject: RE: [R] KNN

It depends on what you are trying to do and what kind of data you are using
If you are using Euclidian distance and your variables have different means
and standard deviations, the answer is probably yes. That will weight each
variable equally. Without standardization the variables with the larger
magnitudes will determine the groups more than the variables with the
smaller magnitudes.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
Reichman
Sent: Thursday, June 21, 2018 11:36 AM
To: R-help at r-project.org
Subject: [R] KNN

R-Help

 

Does one need to normalize ones data is using the knn function within the
caret Library.

 

Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From Achim@Zeilei@ @ending from uibk@@c@@t  Fri Jun 22 02:07:46 2018
From: Achim@Zeilei@ @ending from uibk@@c@@t (Achim Zeileis)
Date: Fri, 22 Jun 2018 02:07:46 +0200 (CEST)
Subject: [R] package colorspace and .WhitePoint question
In-Reply-To: <alpine.DEB.2.21.1806040940020.26338@paninaro>
References: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>
 <alpine.DEB.2.21.1806040940020.26338@paninaro>
Message-ID: <alpine.DEB.2.21.1806220203240.10704@paninaro>

As a follow-up to this issue:

A revised version of the "colorspace" package is now available on R-Forge 
at https://R-Forge.R-project.org/R/?group_id=20

This provides a function whitepoint() that can query and/or modify the 
whitepoint used in all color conversions within the package. To try it you 
can do:

install.packages("colorspace", repos="http://R-Forge.R-project.org")
example("whitepoint", package = "colorspace")

Glenn, it would be great if you could try this and let us know if any 
problems remain.


On Mon, 4 Jun 2018, Achim Zeileis wrote:

> Glenn,
>
> currently, this is currently not exposed in "colorspace" AFAICS. You can 
> modify it by changing .WhitePoint inside colorspace's NAMESPACE, though:
>
> R> assignInNamespace(".WhitePoint", rbind(c(95, 100, 105)),
> +    ns = "colorspace")
> R> as(XYZ(100, 100, 100), "LAB")
>       L        A        B
> [1,] 100 8.622384 3.226371
>
> I'll have another look whether this could be exposed easily (cc also Paul).
>
> Best,
> Z
>
> On Mon, 4 Jun 2018, Glenn Davis wrote:
>
>> In colorspace.R  I see:
>>
>>    setAs("color", "LAB", function(from)
>>      LAB(.Call("as_LAB", from at coords, class(from), .WhitePoint, PACKAGE = "
>> colorspace"),
>>          names = dimnames(from at coords)[[1]]))
>>    ...
>>    .WhitePoint = NULL
>> 
>> and then in colorspace.c and the function CheckWhite(),
>> I see that .WhitePoint = NULL is converted to D65.
>> 
>> I would like to pass a different .WhitePoint to
>>    as( XYZ( 100,100,100)  , "LAB" )
>> 
>> 
>> I have tried 3 methods:
>>    as( XYZ( 100,100,100)  , "LAB", .WhitePoint=XYZ(95,100,105) )
>>    .WhitePoint = XYZ(95,100,105)
>>    assign( ".WhitePoint", XYZ(95,100,105), env=as.environment('package:
>> colorspace') )
>> but all fail, for different reasons.
>> 
>> How can I transform XYZ to LAB using a whitepoint different than D65 ?
>> 
>> Thanks,
>> Glenn Davis
>> gdavis at gluonics.com
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>


From hwborcher@ @ending from gm@il@com  Fri Jun 22 09:27:14 2018
From: hwborcher@ @ending from gm@il@com (Hans W Borchers)
Date: Fri, 22 Jun 2018 09:27:14 +0200
Subject: [R] Optimisation with Normalisation Constraint
Message-ID: <CAML4n3OuMBF3oVOm9WKRaii9UfyGbRWuyPBPrJANX2tGWbP4iA@mail.gmail.com>

One way will be to solve this as an ordinary optimization problem with
an equality constraint. Function `alabama::auglag` can do this:

    library(alabama)
    fn <- function(p) sum((df$y - p[1]*exp(-p[2]*df$x))^2)
    heq <- function(p) sum(p[1]*exp(-p[2]*df$x)) - 5

    # Start with initial values near first solution
    sol <- auglag(c(4, 4), fn=fn, heq=heq)

Solution with myfit:    4.134    4.078
Solution with auglag:   4.126763 4.017768

The equality constraint is still fulfilled:

    a <- sol$par[1]; lambda <- sol$par[2]
    sum(a*exp(-lambda*df$x))
    ## [1] 5

Plot the differences of these two solutions:

    plot(df$x, a*exp(-lambda*df$x) - predict(myfit), type='l')

Interestingly, the difference between 5 and `predict(myfit)` is *not*
just evenly spread across all 15 points.


From @k@h@y_e4 @ending from hotm@il@com  Fri Jun 22 12:12:28 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Fri, 22 Jun 2018 10:12:28 +0000
Subject: [R] parallel computing in r....
Message-ID: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am taking recourse to parallel computing to speed up my R code.

The mcparallel function(in parallel package),presumably, sends a single task (an R function, to be precise) to a single core. Is this right? Is that one and only one core? What if there are other cores lying idle?

As far as I am concerned, I am going to rent an AWS EC2 server with 48 cores. I have four functions to be parallelized. Can I send the thread of one function to 12 cores, so that all 48 cores are utilized? If so, how do I do that with mcparallel function in the parallel package?

Very many thanks for your time and effort...
yours sincerely....
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Jun 22 13:43:25 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 22 Jun 2018 11:43:25 +0000
Subject: [R] Help with transpose please.
Message-ID: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning.


I have data in the form:

head(Edit041IA, n=25)
   ClaimServiceID  ClaimID DiagnosisCode
1       183056004 78044473          C562
2       183056004 78044473          C778
3       183056004 78044473          C784
4       183056004 78044473          C786
5       183056004 78044473         C7961
6       183056004 78044473         C7982
7       183056004 78044473         C7989
8       183056008 78044473          C562
9       183056008 78044473          C778
10      183056008 78044473          C784
11      183056008 78044473          C786
12      183056008 78044473         C7961
13      183056008 78044473         C7982
14      183056008 78044473         C7989
15      183139945 78078925        M79606
16      183139945 78078925         M7989
17      183139945 78078925          R600
18      183236728 78119632        H02831
19      183236728 78119632        H02832
20      183236728 78119632        H02834
21      183236728 78119632        H02835
22      183236728 78119632        H04123
23      183236728 78119632          Z411
24      183236728 78119632         H2513
25      183236728 78119632        H43813

And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:

There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.

    claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc


(If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",

"ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,

-1272L))



At the moment the classes are:

classes <- as.character(sapply(Edit041IA, class))

classes

# [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in

The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.

I have looked at a variety of webpages and cannot get this right,

dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
View(dta2)
 # https://www.r-bloggers.com/pivot-tables-in-r/

# https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function


dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
View(dta3)
dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
View(dta3)

dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
View(dta3)

dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
View(dta3)


dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
View(dta3)
 # https://www.r-statistics.com/tag/transpose/

 dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
View(dta3)


I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.

WHP





Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From r@me@h@y@p@lp@rvi @ending from icloud@com  Fri Jun 22 13:46:45 2018
From: r@me@h@y@p@lp@rvi @ending from icloud@com (Ramesh YAPALPARVI)
Date: Fri, 22 Jun 2018 07:46:45 -0400
Subject: [R] Help with transpose please.
In-Reply-To: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <93AA619D-1A7A-4875-94C2-4F3716656303@icloud.com>

Please check out tidyr package and use commands like spread/ gather which would make data wide or long



> On Jun 22, 2018, at 07:43, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> Good morning.
> 
> 
> I have data in the form:
> 
> head(Edit041IA, n=25)
>   ClaimServiceID  ClaimID DiagnosisCode
> 1       183056004 78044473          C562
> 2       183056004 78044473          C778
> 3       183056004 78044473          C784
> 4       183056004 78044473          C786
> 5       183056004 78044473         C7961
> 6       183056004 78044473         C7982
> 7       183056004 78044473         C7989
> 8       183056008 78044473          C562
> 9       183056008 78044473          C778
> 10      183056008 78044473          C784
> 11      183056008 78044473          C786
> 12      183056008 78044473         C7961
> 13      183056008 78044473         C7982
> 14      183056008 78044473         C7989
> 15      183139945 78078925        M79606
> 16      183139945 78078925         M7989
> 17      183139945 78078925          R600
> 18      183236728 78119632        H02831
> 19      183236728 78119632        H02832
> 20      183236728 78119632        H02834
> 21      183236728 78119632        H02835
> 22      183236728 78119632        H04123
> 23      183236728 78119632          Z411
> 24      183236728 78119632         H2513
> 25      183236728 78119632        H43813
> 
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
> 
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
> 
>    claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
> 1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc
> 
> 
> (If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
> 
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
> 
> -1272L))
> 
> 
> 
> At the moment the classes are:
> 
> classes <- as.character(sapply(Edit041IA, class))
> 
> classes
> 
> # [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
> 
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
> 
> I have looked at a variety of webpages and cannot get this right,
> 
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/
> 
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function
> 
> 
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
> 
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
> 
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/
> 
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
> 
> 
> I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
> 
> WHP
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @rued@ @ending from ced@u@b@e@  Fri Jun 22 14:13:36 2018
From: @rued@ @ending from ced@u@b@e@ (=?UTF-8?Q?Sarah=C3=AD_Rueda_Salazar?=)
Date: Fri, 22 Jun 2018 14:13:36 +0200
Subject: [R] Coxme, package updated on May 2018,
 Similar case to Re:  CoxME: Family relatedness
Message-ID: <CAHRw6-9Ma+BYY28qB4EY3x_AGK72WOHuDsonEVRAqBuT2P_WbA@mail.gmail.com>

Dear Terry,

I can imagine that you are overwhelming with a quite large demand of
request emails, so I hope (always optimistic) that you have time to see
this email.

It is related to the recently updated version of coxme package.  Currently,
I work with multistate models with changes in health status on elder
population.  I use coxPH by stratifying the hazard by different transition
type ( deterioration, health improvements, death from healthy status and
death from not healthy status). I use mstate and Biograph packages to
reshape my data disentangling different events by transition type (1:4)

So, I wondered if I can apply mixed effect on my multistate model to see
the differences by countries (shared frailty).  I?ve read the material you
post on May 11, 2018 and other several materials in this subject :Steele et
al:2004, Austin : 2017,Putter: 2014, Willekens: 2014, Brost?n:2011, Mills,
2011 and finally Allison which provide me a quite understandable approach
in the line of my humble knowledge in mathematical demography.

I thought it is not possible to use to multilevel in
multistate with coxme package. By stratifying the hazard  (reference risk
by interested covariates )  by my transitions type, I make hazard be
free(no proportional by transition type) and it means that the model
estimates separate baseline hazard for the different values of transition
type ( following this material by Putter( 2018:7
<https://cran.r-project.org/web/packages/mstate/vignettes/Tutorial.pdf>)

It is a simple model using sex , reference category "male" with my data:

> modelSex.0 <- coxph(Surv(Tstarta,Tstopa,status) ~
+                        SexF.1+ SexF.2+SexF.3+SexF.4+
+                       strata(trans),
+                     data=d0)

SexF.1= related to covariate sex  in transition 1(healthy to not healthy)
SexF.2 = transition healthy to death
SexF.3= transition  Not healthy to Healthy
SexF.4= transition  Not healthy to Death

But, I came across  this post
<https://stat.ethz.ch/pipermail/r-help/2014-September/421690.html>  where
you replied a request ( I copy a chunk that I?m interested in):

2. The model above is the correct covariance structure for a set of
> families. There is a
> single intercept per subject, with a complex correlation matrix. The
> simpler "per family"
> frailty model would be



> model4 <- coxme(Surv(Survival, Event) ~ Sex + strata(cohort) + SNP1 + SNP2
> + SNP3 +
> (1|famid), death.dat)



> This model lets each family have a separate risk, with everyone in the
> same family sharing
> the exact same risk. It is less general than model3 above which lets a
> family have higher
> risk plus has variation between family members. A model with both
> per-subject and per family terms is identical to one with a covariance
> matrix of s1 K + s2 B, where K is the kinship matrix, B is a block
> diagonal matrix which
> has a solid block of "1" for each family, and s1 s2 are the fitted
> variance coefficients.


 So, my strata would be my transition type (trans) instead "cohort"  and my
groups (instead famid) would be country, as follows


> modelSex.1 <- coxme(Surv(Tstarta,Tstopa,status) ~
+                        SexF.1+ SexF.2+SexF.3+SexF.4+
+                       (1|Country),
+                     data=d0)

> anova(modelSex.0,modelSex.1)

Analysis of Deviance Table
 Cox model: response is  Surv(Tstarta, Tstopa, status)
 Model 1: ~ SexF.1+ SexF.2+SexF.3+SexF.4+ strata(trans)
 Model 2: ~ SexF.1+ SexF.2+SexF.3+SexF.4+ strata(trans) + (1 | Country)
    loglik  Chisq Df P(>|Chi|)
1 -1342082
2 -1339605 4953.8  1 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> stem(exp(ranef(modelSex.1)[[1]]))

  The decimal point is 1 digit(s) to the left of the |

   6 | 589
   8 | 1448477
  10 | 115669
  12 | 0846

> exp(ranef(modelSex.1)[[1]])
       AT        BE        BG        CY        CZ        EE
1.1981346 0.9712875 0.8092424 1.3614033 0.8382588 1.0117071
       EL        ES        HU        IE        IT        LT
0.7514988 1.2761863 1.0085404 0.8760514 1.1615717 0.9708070
       LU        LV        MT        PL        PT        RO
1.1893096 1.3381012 1.0522161 0.7843473 1.1642434 0.7911292
       SK        UK
0.9440166 0.8428222

> fixed.effects(modelSex.1)
     SexF.1      SexF.2      SexF.3      SexF.4
 0.16349517 -0.63184370 -0.08578787 -0.61023260


The thing is that I?m not sure on how to interpret the frailty values by
countries (random effect described by the variance within groups)  because
I have four different effects (each related with my transition types). I
know that by using strata for my transition type is the same as I applied 4
different cox model (related for each type of transition). If I
apply separated model  I would obtain frailty random effect by groups
(countries) regarding specific transition but, doing this model with the
strata  ( modelSex.1 ) with my 4 transition type at once, I do not know
what those frailty values are telling me about the different type of hazard.

For other side, I have other question related to the recent article of
Mixed Effect (May, 2018) . Might be it is a very very silly question but I
need to understand .
In pag 9, second parraph , you describe the simple cox model : when you
describe the standard deviation (excess of risk for each group)  , you
state that "... 15% of the families to be 1 std dev or more above the
mean..."  Im working with that data and code but I couldnt find where you
got the value of 15%.


I hope this makes any sense to you,

Best wishes

 Sarah?


-- 
*Sarah? Rueda Salazar*
*Investigadora en Formaci?n (FPI/CED)*












*Centre d'Estudis Demogr?ficsCarrer de Ca n'Altay?, Edifici E2Universitat
Aut?noma de Barcelona,08193
Bellaterra, Barcelona/SPAINPhone: 34/93.581.30.60
<34%2F93.581.30.60>Fax: 34/93.581.30.61
<34%2F93.581.30.61>e-mail: srueda at ced.uab.es
<ssancho at ced.uab.es>http://www.ced.uab.es <http://www.ced.uab.es/>*

From bgunter@4567 @ending from gm@il@com  Fri Jun 22 17:53:37 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 22 Jun 2018 08:53:37 -0700
Subject: [R] Help with transpose please.
In-Reply-To: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbQq8SZvgDbnmMSThpKaqfD5FYBipZK8YMbAbt7e5iQe2g@mail.gmail.com>

1. "The max number of columns based on this transpose of the DiagnosisCode
column (in this dataset) is 12 if that is important to know."

I count about 20 different DX codes in the data you show, so I don't know
what this means.

2. I was not able to unambiguously parse your request (I admit that I just
may be dense) , but maybe split() is what you want, at least to start with:

##untested in the absence of a reprex
## dat is your data frame

split(dat, dat$ClaimServiceID)


This will give you a list of data frames, one for eachClaimServiceID. You
can order each list however you like using, e.g. lapply() with order().

If I have missed your intent completely, just say so and hopefully someone
else can help. Or follow Ramesh's suggestion

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jun 22, 2018 at 4:43 AM, Bill Poling <Bill.Poling at zelis.com> wrote:

> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
>    ClaimServiceID  ClaimID DiagnosisCode
> 1       183056004 78044473          C562
> 2       183056004 78044473          C778
> 3       183056004 78044473          C784
> 4       183056004 78044473          C786
> 5       183056004 78044473         C7961
> 6       183056004 78044473         C7982
> 7       183056004 78044473         C7989
> 8       183056008 78044473          C562
> 9       183056008 78044473          C778
> 10      183056008 78044473          C784
> 11      183056008 78044473          C786
> 12      183056008 78044473         C7961
> 13      183056008 78044473         C7982
> 14      183056008 78044473         C7989
> 15      183139945 78078925        M79606
> 16      183139945 78078925         M7989
> 17      183139945 78078925          R600
> 18      183236728 78119632        H02831
> 19      183236728 78119632        H02832
> 20      183236728 78119632        H02834
> 21      183236728 78119632        H02835
> 22      183236728 78119632        H04123
> 23      183236728 78119632          Z411
> 24      183236728 78119632         H2513
> 25      183236728 78119632        H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID,
> and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique
> ClaimServiceID as the identifier when I join this data back into a longer
> single record length file by that column.
>
>     claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
> 1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete  dput of the 1272 records I will gladly
> provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer"   "integer"   "character" <---but do not have to be if
> that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode
> column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
>  # https://www.r-bloggers.com/pivot-tables-in-r/
>
> # https://stackoverflow.com/questions/18449938/pivot-on-
> data-table-similar-to-rehape-melt-function
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID,
> DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
>  # https://www.r-statistics.com/tag/transpose/
>
>  dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID,
> ClaimID))
> View(dta3)
>
>
> I am sure it's a basic,  simple procedure, but I am pressed for time on
> this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Jun 22 18:36:36 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 22 Jun 2018 16:36:36 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <CAGxFJbQq8SZvgDbnmMSThpKaqfD5FYBipZK8YMbAbt7e5iQe2g@mail.gmail.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CAGxFJbQq8SZvgDbnmMSThpKaqfD5FYBipZK8YMbAbt7e5iQe2g@mail.gmail.com>
Message-ID: <CY1PR0201MB18348CE8430D063E2AD01A36EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi Bert and thank you for your assistance, I will try this.

I was not clear enough about the number of expected output columns based on the  DiagnosisCode column, my appologies.

Specifically, by virtue of the ClaimServiceID being the unique identifier, among them there is one with 12 DiagnosisCodes so the record length would be at the most 12 + the ClaimServiceID and the ClaimID

Example:
ClaimServiceID ClaimID DX1 DX2 DX3 DX4 DX5 DX6 DX7 DX8 DX9 DX10 DX11 DX12

And of course those ClaimServiceID?s with less than 12 DX?s would be NULL in place of a DiagnosisCode

I will work with what you suggest and report back thank you again Sir!

WHP


From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Friday, June 22, 2018 11:54 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

1. "The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know."

I count about 20 different DX codes in the data you show, so I don't know what this means.

2. I was not able to unambiguously parse your request (I admit that I just may be dense) , but maybe split() is what you want, at least to start with:

##untested in the absence of a reprex
## dat is your data frame

split(dat, dat$ClaimServiceID)


This will give you a list of data frames, one for eachClaimServiceID. You can order each list however you like using, e.g. lapply() with order().

If I have missed your intent completely, just say so and hopefully someone else can help. Or follow Ramesh's suggestion

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jun 22, 2018 at 4:43 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
Good morning.


I have data in the form:

head(Edit041IA, n=25)
   ClaimServiceID  ClaimID DiagnosisCode
1       183056004 78044473          C562
2       183056004 78044473          C778
3       183056004 78044473          C784
4       183056004 78044473          C786
5       183056004 78044473         C7961
6       183056004 78044473         C7982
7       183056004 78044473         C7989
8       183056008 78044473          C562
9       183056008 78044473          C778
10      183056008 78044473          C784
11      183056008 78044473          C786
12      183056008 78044473         C7961
13      183056008 78044473         C7982
14      183056008 78044473         C7989
15      183139945 78078925        M79606
16      183139945 78078925         M7989
17      183139945 78078925          R600
18      183236728 78119632        H02831
19      183236728 78119632        H02832
20      183236728 78119632        H02834
21      183236728 78119632        H02835
22      183236728 78119632        H04123
23      183236728 78119632          Z411
24      183236728 78119632         H2513
25      183236728 78119632        H43813

And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:

There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.

    claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc


(If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",

"ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,

-1272L))



At the moment the classes are:

classes <- as.character(sapply(Edit041IA, class))

classes

# [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in

The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.

I have looked at a variety of webpages and cannot get this right,

dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
View(dta2)
 # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>

# https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>


dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
View(dta3)
dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
View(dta3)

dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
View(dta3)

dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
View(dta3)


dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
View(dta3)
 # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>

 dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
View(dta3)


I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.

WHP





Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From Bill@Poling @ending from zeli@@com  Fri Jun 22 18:39:00 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Fri, 22 Jun 2018 16:39:00 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <93AA619D-1A7A-4875-94C2-4F3716656303@icloud.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <93AA619D-1A7A-4875-94C2-4F3716656303@icloud.com>
Message-ID: <CY1PR0201MB18345A1D2336DF4A9546FD0EEA750@CY1PR0201MB1834.namprd02.prod.outlook.com>

Thank you Ramesh, I will investigate, appreciate your response Sir!

WHP


From: Ramesh YAPALPARVI [mailto:ramesh.yapalparvi at icloud.com]
Sent: Friday, June 22, 2018 7:47 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

Please check out tidyr package and use commands like spread/ gather which would make data wide or long



> On Jun 22, 2018, at 07:43, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
> ClaimServiceID ClaimID DiagnosisCode
> 1 183056004 78044473 C562
> 2 183056004 78044473 C778
> 3 183056004 78044473 C784
> 4 183056004 78044473 C786
> 5 183056004 78044473 C7961
> 6 183056004 78044473 C7982
> 7 183056004 78044473 C7989
> 8 183056008 78044473 C562
> 9 183056008 78044473 C778
> 10 183056008 78044473 C784
> 11 183056008 78044473 C786
> 12 183056008 78044473 C7961
> 13 183056008 78044473 C7982
> 14 183056008 78044473 C7989
> 15 183139945 78078925 M79606
> 16 183139945 78078925 M7989
> 17 183139945 78078925 R600
> 18 183236728 78119632 H02831
> 19 183236728 78119632 H02832
> 20 183236728 78119632 H02834
> 21 183236728 78119632 H02835
> 22 183236728 78119632 H04123
> 23 183236728 78119632 Z411
> 24 183236728 78119632 H2513
> 25 183236728 78119632 H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
>
> claimServiceID ClaimID Dx1 Dx2 Dx3 ...etc
> 1 183056004 78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008 78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer" "integer" "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>
>
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>
>
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
>
>
> I am sure it's a basic, simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}


From giftedlife2014 @ending from gm@il@com  Fri Jun 22 21:12:45 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Fri, 22 Jun 2018 20:12:45 +0100
Subject: [R] as.Date and Legend in a plot
Message-ID: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>

Dear Contributors,

I am surprised that I cannot add legend to a certain plot. Although the
x-axis indicates years, the actual data was in year, month and day format.
I then used as.Date to play around and get what I am looking for. I am,
however, worried that I cannot add legend to the plot no matter how I
tried. Looking at the axis, I tried:
legend(1998,3, c("Climax", "Thule", "Sopo"), lty = 1, col =
c("black","red","blue")). I also tried:

legend(as.Date(1998-02-10),3, c("Climax", "Thule", "Sopo"), lty = 1, col =
c("black","red","blue"))
but no result and no error.

I have attached the plot in case it will assist in your suggestions.

Many thanks for your time.

Ogbos

From dwin@emiu@ @ending from comc@@t@net  Fri Jun 22 22:33:38 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 22 Jun 2018 13:33:38 -0700
Subject: [R] as.Date and Legend in a plot
In-Reply-To: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
References: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
Message-ID: <B58340BA-654E-4095-9713-A5F08B6563A1@comcast.net>


> On Jun 22, 2018, at 12:12 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear Contributors,
> 
> I am surprised that I cannot add legend to a certain plot. Although the
> x-axis indicates years, the actual data was in year, month and day format.
> I then used as.Date to play around and get what I am looking for. I am,
> however, worried that I cannot add legend to the plot no matter how I
> tried. Looking at the axis, I tried:
> legend(1998,3, c("Climax", "Thule", "Sopo"), lty = 1, col =
> c("black","red","blue")). I also tried:
> 
> legend(as.Date(1998-02-10),

I don't think you understand the difference between character values and numeric values. Thr using 

as.Date("1998-02-10")


> 3, c("Climax", "Thule", "Sopo"), lty = 1, col =
> c("black","red","blue"))
> but no result and no error.
> 
> I have attached the plot in case it will assist in your suggestions.
> 
> Many thanks for your time.
> 
> Ogbos
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From m@cqueen1 @ending from llnl@gov  Fri Jun 22 23:34:05 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Fri, 22 Jun 2018 21:34:05 +0000
Subject: [R] as.Date and Legend in a plot
In-Reply-To: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
References: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
Message-ID: <9CC667B3-F92E-426A-9259-4BF329872ECB@llnl.gov>

What David Winsemius said, plus:

Does
  legend('topleft', c("Climax", "Thule", "Sopo"), lty = 1, col = ("black","red","blue"))
not work?

It should, which will illustrate that you CAN add a legend to the plot.

The x,y that you supply to legend must be values that are within the x,y range of the plot. Type
   par()$usr
to see what that range is, and I think you will see that 1998 is not within the plot range.

David showed you how to supply legend with an x value that is, we assume, within the plot range.

You *should* have had an error on your second try:

> as.Date(1998-02-10)
Error in as.Date.numeric(1998 - 2 - 10) : 'origin' must be supplied

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/22/18, 12:12 PM, "R-help on behalf of Ogbos Okike" <r-help-bounces at r-project.org on behalf of giftedlife2014 at gmail.com> wrote:

    Dear Contributors,
    
    I am surprised that I cannot add legend to a certain plot. Although the
    x-axis indicates years, the actual data was in year, month and day format.
    I then used as.Date to play around and get what I am looking for. I am,
    however, worried that I cannot add legend to the plot no matter how I
    tried. Looking at the axis, I tried:
    legend(1998,3, c("Climax", "Thule", "Sopo"), lty = 1, col =
    c("black","red","blue")). I also tried:
    
    legend(as.Date(1998-02-10),3, c("Climax", "Thule", "Sopo"), lty = 1, col =
    c("black","red","blue"))
    but no result and no error.
    
    I have attached the plot in case it will assist in your suggestions.
    
    Many thanks for your time.
    
    Ogbos
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From giftedlife2014 @ending from gm@il@com  Sat Jun 23 08:35:37 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Sat, 23 Jun 2018 07:35:37 +0100
Subject: [R] tapply and error bars
Message-ID: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>

Dear workers,
I have a data of length 1136. Below is the code I use to get the means B.
It worked fine and I had the mean calculated and plotted.

I wish to plot the error bars as well. I already plotted such means with
error bars before. Please see attached for example.

I tried to redo the same plot but unlikely could not get around it as I
lost my system containing the script.
Among many attempts, I tried:
library(gplots)

 plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68, main="Main
  effect Plot",barcol="black")
Nothing worked.

I would really be thankful should somebody return me to the track.
Many, many thanks for your time.
Ogbos

A sample of the data is:
S/N      A        B
1    -5  64833
2    -4  95864
3    -3  82322
4    -2  95591
5    -1  69378
6     0  74281
7     1 103261
8     2  92473
9     3  84344
10    4 127415
11    5 123826
12    6 100029
13    7  76205
14    8 105162
15    9 119533
16   10 106490
17   -5  82322
18   -4  95591
19   -3  69378
20   -2  74281
21   -1 103261
22    0  92473
23    1  84344
24    2 127415
25    3 123826
26    4 100029
27    5  76205
28    6 105162
29    7 119533
30    8 106490
31    9 114771
32   10  55593
33   -5  85694
34   -4  65205
35   -3  80995
36   -2  51723
37   -1  62310
38    0  53401
39    1  65677
40    2  76094
41    3  64035
42    4  68290
43    5  73306
44    6  82176
45    7  75566
46    8  89762
47    9  88063
48   10  94395
49   -5  80651
50   -4  81291
51   -3  63702
52   -2  70297
53   -1  64117
54    0  71219
55    1  57354
56    2  62111
57    3  42252
58    4  35454
59    5  33469
60    6  38899
61    7  64981
62    8  85694
63    9  79452
64   10  85216
65   -5  71219
66   -4  57354
67   -3  62111
68   -2  42252
69   -1  35454
70    0  33469
71    1  38899
72    2  64981
73    3  85694
74    4  79452
75    5  85216
76    6  81721
77    7  91231
78    8 107074
79    9 108103
80   10  7576

A<-matrix(rep(-5:10,71))
B<-matrix(data)
 AB<-data.frame(A,B)

x= B

 f<-factor(A)
AB<- tapply(x,f,mean)
x<--5:10
plot(x,AB,type="l")

-------------- next part --------------
A non-text attachment was scrubbed...
Name: true.png
Type: image/png
Size: 34158 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180623/67dd79a5/attachment.png>

From drjimlemon @ending from gm@il@com  Sat Jun 23 11:09:17 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sat, 23 Jun 2018 19:09:17 +1000
Subject: [R] tapply and error bars
In-Reply-To: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
Message-ID: <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>

Hi Ogbos,
This may help:

# assume your data frame is named "oodf"
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

Jim

On Sat, Jun 23, 2018 at 4:35 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Dear workers,
> I have a data of length 1136. Below is the code I use to get the means B.
> It worked fine and I had the mean calculated and plotted.
>
> I wish to plot the error bars as well. I already plotted such means with
> error bars before. Please see attached for example.
>
> I tried to redo the same plot but unlikely could not get around it as I
> lost my system containing the script.
> Among many attempts, I tried:
> library(gplots)
>
>  plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68, main="Main
>   effect Plot",barcol="black")
> Nothing worked.
>
> I would really be thankful should somebody return me to the track.
> Many, many thanks for your time.
> Ogbos
>
> A sample of the data is:
> S/N      A        B
> 1    -5  64833
> 2    -4  95864
> 3    -3  82322
> 4    -2  95591
> 5    -1  69378
> 6     0  74281
> 7     1 103261
> 8     2  92473
> 9     3  84344
> 10    4 127415
> 11    5 123826
> 12    6 100029
> 13    7  76205
> 14    8 105162
> 15    9 119533
> 16   10 106490
> 17   -5  82322
> 18   -4  95591
> 19   -3  69378
> 20   -2  74281
> 21   -1 103261
> 22    0  92473
> 23    1  84344
> 24    2 127415
> 25    3 123826
> 26    4 100029
> 27    5  76205
> 28    6 105162
> 29    7 119533
> 30    8 106490
> 31    9 114771
> 32   10  55593
> 33   -5  85694
> 34   -4  65205
> 35   -3  80995
> 36   -2  51723
> 37   -1  62310
> 38    0  53401
> 39    1  65677
> 40    2  76094
> 41    3  64035
> 42    4  68290
> 43    5  73306
> 44    6  82176
> 45    7  75566
> 46    8  89762
> 47    9  88063
> 48   10  94395
> 49   -5  80651
> 50   -4  81291
> 51   -3  63702
> 52   -2  70297
> 53   -1  64117
> 54    0  71219
> 55    1  57354
> 56    2  62111
> 57    3  42252
> 58    4  35454
> 59    5  33469
> 60    6  38899
> 61    7  64981
> 62    8  85694
> 63    9  79452
> 64   10  85216
> 65   -5  71219
> 66   -4  57354
> 67   -3  62111
> 68   -2  42252
> 69   -1  35454
> 70    0  33469
> 71    1  38899
> 72    2  64981
> 73    3  85694
> 74    4  79452
> 75    5  85216
> 76    6  81721
> 77    7  91231
> 78    8 107074
> 79    9 108103
> 80   10  7576
>
> A<-matrix(rep(-5:10,71))
> B<-matrix(data)
>  AB<-data.frame(A,B)
>
> x= B
>
>  f<-factor(A)
> AB<- tapply(x,f,mean)
> x<--5:10
> plot(x,AB,type="l")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From djnordlund @ending from gm@il@com  Sat Jun 23 12:04:26 2018
From: djnordlund @ending from gm@il@com (Daniel Nordlund)
Date: Sat, 23 Jun 2018 03:04:26 -0700
Subject: [R] Help with transpose please.
In-Reply-To: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>

On 6/22/2018 4:43 AM, Bill Poling wrote:
> Good morning.
> 
> 
> I have data in the form:
> 
> head(Edit041IA, n=25)
>     ClaimServiceID  ClaimID DiagnosisCode
> 1       183056004 78044473          C562
> 2       183056004 78044473          C778
> 3       183056004 78044473          C784
> 4       183056004 78044473          C786
> 5       183056004 78044473         C7961
> 6       183056004 78044473         C7982
> 7       183056004 78044473         C7989
> 8       183056008 78044473          C562
> 9       183056008 78044473          C778
> 10      183056008 78044473          C784
> 11      183056008 78044473          C786
> 12      183056008 78044473         C7961
> 13      183056008 78044473         C7982
> 14      183056008 78044473         C7989
> 15      183139945 78078925        M79606
> 16      183139945 78078925         M7989
> 17      183139945 78078925          R600
> 18      183236728 78119632        H02831
> 19      183236728 78119632        H02832
> 20      183236728 78119632        H02834
> 21      183236728 78119632        H02835
> 22      183236728 78119632        H04123
> 23      183236728 78119632          Z411
> 24      183236728 78119632         H2513
> 25      183236728 78119632        H43813
> 
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
> 
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
> 
>      claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
> 1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc
> 
> 
> (If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
> 
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
> 
> -1272L))
> 
> 
> 
> At the moment the classes are:
> 
> classes <- as.character(sapply(Edit041IA, class))
> 
> classes
> 
> # [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
> 
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
> 
> I have looked at a variety of webpages and cannot get this right,
> 
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
>   # https://www.r-bloggers.com/pivot-tables-in-r/
> 
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function
> 
> 
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
> 
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
> 
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
>   # https://www.r-statistics.com/tag/transpose/
> 
>   dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
> 
> 
> I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
> 
> WHP
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Bill,

you have received some good suggestions and since you are pressed for 
time this may be too late.  However, here is a solution using ave() 
function and  cast() from the reshape package.

# create diagnosis variable names
dxnames <- paste('Dx',ave(rep(1, nrow(have)), have[,1:2], FUN = 
seq_along), sep='')
# cast the data into wide format
cast(cbind(have,dxnames), ClaimServiceID + ClaimID ~ dxnames, 
value='DiagnosisCode')


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA


From j@b@y@t194 @ending from gm@il@com  Sat Jun 23 13:09:41 2018
From: j@b@y@t194 @ending from gm@il@com (javad bayat)
Date: Sat, 23 Jun 2018 15:39:41 +0430
Subject: [R] Deleting a specific value in a column of a data frame
Message-ID: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>

Dear R users;
I have two columns data frame (column names is A and B). I want to write a
function in order to compare column of B with A and if the values of B are
equal or greater than that of A, replace them with "NA" or delete them and
if the values of B are less than values in A, do nothing.

Sincerely.

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sat Jun 23 16:26:44 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 23 Jun 2018 07:26:44 -0700
Subject: [R] Deleting a specific value in a column of a data frame
In-Reply-To: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>
References: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>
Message-ID: <CAGxFJbSMDYt2em5HFgXi8KL1D4Fp7R6RF05Re+d=hPcZE041CA@mail.gmail.com>

You understand, of course, that all columns in a data frame must be of the
same length; and that "NA" is not the same as NA?

This is pretty basic stuff and suggests you need to spend some time with an
R tutorial or two.

In any case, a construct of the form:

B[B >= A] <- NA

should do.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 23, 2018 at 4:09 AM, javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I have two columns data frame (column names is A and B). I want to write a
> function in order to compare column of B with A and if the values of B are
> equal or greater than that of A, replace them with "NA" or delete them and
> if the values of B are less than values in A, do nothing.
>
> Sincerely.
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From giftedlife2014 @ending from gm@il@com  Sat Jun 23 04:09:14 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Sat, 23 Jun 2018 03:09:14 +0100
Subject: [R] as.Date and Legend in a plot: Fixed
Message-ID: <CAC8ss33w1i_QJehakhHGCV_DBDSSiAmzY_WjF6RXiLUApsPA7w@mail.gmail.com>

Dear List,
I am happy to report that the problem is fixed. as.Date("1998-02-10") as
suggested by David handled the problem with easy. Many thanks to everybody.
as.Date(1998-02-10) really resulted in error. It is my oversight. I really
tried many things the day I was working on that and have forgotten some of
the errors.

Thanks again.



Ogbos

From dc@rl@on @ending from t@mu@edu  Sat Jun 23 19:25:00 2018
From: dc@rl@on @ending from t@mu@edu (David L Carlson)
Date: Sat, 23 Jun 2018 17:25:00 +0000
Subject: [R] Deleting a specific value in a column of a data frame
In-Reply-To: <CAGxFJbSMDYt2em5HFgXi8KL1D4Fp7R6RF05Re+d=hPcZE041CA@mail.gmail.com>
References: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>
 <CAGxFJbSMDYt2em5HFgXi8KL1D4Fp7R6RF05Re+d=hPcZE041CA@mail.gmail.com>
Message-ID: <d4fab29a0744446e991187f63f6b24dc@tamu.edu>

Bert's solution works if A and B are vectors, but not if they are columns in a data frame. First, let's make up some data:

set.seed(42)
Dat <- data.frame(A=runif(10), B=runif(1))
Dat
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 3  0.2861395 0.9346722
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 6  0.5190959 0.9400145
# 7  0.7365883 0.9782264
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

It is safer to preserve the original data frame and store the modified data into a new one. To insert missing values:

Dat1 <- Dat
Dat1[Dat$B >= Dat$A, ] <- NA
Dat1
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 3         NA        NA
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 6         NA        NA
# 7         NA        NA
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Dat1 has the same number of rows as Dat with missing values for the rows that meet your logical expression. Here are three ways to remove those rows. We can delete the missing values:

Dat2 <- na.omit(Dat1)
Dat2
#           A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Or we can extract the rows we want by flipping the logical expression:

# Dat2 <- Dat
# Dat2 <- Dat[Dat$B < Dat$A, ]
# Dat2
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Or we can subset the original data frame with the subset() function:

Dat2 <- Dat
Dat2 <- subset(Dat, B < A)
Dat2
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Notice that whichever one we use, the row numbers match the original data frame.


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Saturday, June 23, 2018 9:27 AM
To: javad bayat <j.bayat194 at gmail.com>
Cc: R-help <R-help at r-project.org>
Subject: Re: [R] Deleting a specific value in a column of a data frame

You understand, of course, that all columns in a data frame must be of the
same length; and that "NA" is not the same as NA?

This is pretty basic stuff and suggests you need to spend some time with an
R tutorial or two.

In any case, a construct of the form:

B[B >= A] <- NA

should do.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 23, 2018 at 4:09 AM, javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I have two columns data frame (column names is A and B). I want to write a
> function in order to compare column of B with A and if the values of B are
> equal or greater than that of A, replace them with "NA" or delete them and
> if the values of B are less than values in A, do nothing.
>
> Sincerely.
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From ruipb@rr@d@@ @ending from @@po@pt  Sat Jun 23 19:11:58 2018
From: ruipb@rr@d@@ @ending from @@po@pt (ruipbarradas)
Date: Sat, 23 Jun 2018 18:11:58 +0100
Subject: [R] Deleting a specific value in a column of a data frame
Message-ID: <1qletd906mwfuur4rmdyj5ht.1529773918921@email.android.com>

Hello,
Also possible is

is.na (B) <- B >= A

Hope this helps,
Rui Barradas?


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Bert Gunter <bgunter.4567 at gmail.com> Data: 23/06/2018  15:26  (GMT+00:00) Para: javad bayat <j.bayat194 at gmail.com> Cc: R-help <R-help at r-project.org> Assunto: Re: [R] Deleting a specific value in a column of a data frame 
You understand, of course, that all columns in a data frame must be of the
same length; and that "NA" is not the same as NA?

This is pretty basic stuff and suggests you need to spend some time with an
R tutorial or two.

In any case, a construct of the form:

B[B >= A] <- NA

should do.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 23, 2018 at 4:09 AM, javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I have two columns data frame (column names is A and B). I want to write a
> function in order to compare column of B with A and if the values of B are
> equal or greater than that of A, replace them with "NA" or delete them and
> if the values of B are less than values in A, do nothing.
>
> Sincerely.
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>???????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From h@medh@@eli @ending from gm@il@com  Sat Jun 23 22:23:10 2018
From: h@medh@@eli @ending from gm@il@com (Hamed Ha)
Date: Sat, 23 Jun 2018 21:23:10 +0100
Subject: [R] Issue with R write() function
Message-ID: <CAAC89xeJeiJP12G6yK9DHhM7mZet9VxmFLuRRvrXvh2ROK5Bwg@mail.gmail.com>

I
am recently updated to R 3.5.0 and noticed some weird errors in write()
function. Further, I noticed that write.csv, write.table and generally the
functions that derive from write() are all weird.

   1. write() function does not accept a path longer than 256 characters
   neither on Windows or Unix. Noticed that a full path can be longer than 256
   characters, however, the directory name cannot, at least on windows.

   2. The append parameter does not work at all, just try
   ??
   ??
   write.table(x = 1,file =  '
   tmp
   ',append = TRUE)
   ? or write.csv(x = 1,file =  'tmp',append = TRUE)?

P
lease can someone report to the developement team?


Regards,
Hamed.

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jun 23 23:58:33 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 23 Jun 2018 14:58:33 -0700
Subject: [R] Issue with R write() function
In-Reply-To: <CAAC89xeJeiJP12G6yK9DHhM7mZet9VxmFLuRRvrXvh2ROK5Bwg@mail.gmail.com>
References: <CAAC89xeJeiJP12G6yK9DHhM7mZet9VxmFLuRRvrXvh2ROK5Bwg@mail.gmail.com>
Message-ID: <6ACEFFE6-4741-4930-9D3E-60B2C011AB02@dcn.davis.ca.us>

1. This behavior is dictated by the file system (an operating system feature) that is in use. Chances of it changing in R are extremely small.

2. While not clearly documented, this behavior is consistent with the definition of what a "csv" file is. Headers located at other than line 1 are not valid, and the write.csv function cannot insure that multiple invocations will lead to a valid csv file. Since write.csv is just a convenience wrapper around write.table, you can probably accomplish what you are after by giving appropriate parameters to write.table. e.g.

write.table( x=1, file="tmp.csv", sep=",", row.names=FALSE )
write.table( x=2, file="tmp.csv", append=TRUE, sep=",", row.names=FALSE, col.names=FALSE )

It will be up to you to keep the format consistent.


On June 23, 2018 1:23:10 PM PDT, Hamed Ha <hamedhaseli at gmail.com> wrote:
>I
>am recently updated to R 3.5.0 and noticed some weird errors in write()
>function. Further, I noticed that write.csv, write.table and generally
>the
>functions that derive from write() are all weird.
>
>  1. write() function does not accept a path longer than 256 characters
>neither on Windows or Unix. Noticed that a full path can be longer than
>256
>   characters, however, the directory name cannot, at least on windows.
>
>   2. The append parameter does not work at all, just try
>   ??
>   ??
>   write.table(x = 1,file =  '
>   tmp
>   ',append = TRUE)
>   ? or write.csv(x = 1,file =  'tmp',append = TRUE)?
>
>P
>lease can someone report to the developement team?
>
>
>Regards,
>Hamed.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drjimlemon @ending from gm@il@com  Sun Jun 24 12:24:43 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Sun, 24 Jun 2018 20:24:43 +1000
Subject: [R] tapply and error bars
In-Reply-To: <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
 <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>
 <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
Message-ID: <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>

Hi Ogbos,
If I use the example data that you sent, I get the error after this line:

oose<-as.vector(by(oodf$B,oodf$A,std.error))
Error in FUN(X[[i]], ...) : object 'std.error' not found

The reason is that you have not defined std.error as a function, but
as the result of a calculation. When I rewrite it like this:

std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

I get the expected plot.

Jim


On Sat, Jun 23, 2018 at 9:36 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Hi Jim,
>
> Thanks for assisting. Here is what I did:
>
> A<-matrix(rep(-5:10,71))
> B<-matrix(data)
> std.error = sd(B)/sqrt(sum(!is.na(B)))
>  oodf<-data.frame(A,B)
>
>  oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> And the error says:
> Error in FUN(X[[1L]], ...) : could not find function "FUN"
>
> Please note that I use:
> std.error = sd(B)/sqrt(sum(!is.na(B)))
>  to calculate the standard error as it requested for it.
>
> Thanks
> Ogbos
>
> On Sat, Jun 23, 2018 at 10:09 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Ogbos,
>> This may help:
>>
>> # assume your data frame is named "oodf"
>> oomean<-as.vector(by(oodf$B,oodf$A,mean))
>> oose<-as.vector(by(oodf$B,oodf$A,std.error))
>> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
>> dispersion(-5:10,oomean,oose)
>>
>> Jim
>>
>> On Sat, Jun 23, 2018 at 4:35 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>> > Dear workers,
>> > I have a data of length 1136. Below is the code I use to get the means
>> > B.
>> > It worked fine and I had the mean calculated and plotted.
>> >
>> > I wish to plot the error bars as well. I already plotted such means with
>> > error bars before. Please see attached for example.
>> >
>> > I tried to redo the same plot but unlikely could not get around it as I
>> > lost my system containing the script.
>> > Among many attempts, I tried:
>> > library(gplots)
>> >
>> >  plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68,
>> > main="Main
>> >   effect Plot",barcol="black")
>> > Nothing worked.
>> >
>> > I would really be thankful should somebody return me to the track.
>> > Many, many thanks for your time.
>> > Ogbos
>> >
>> > A sample of the data is:
>> > S/N      A        B
>> > 1    -5  64833
>> > 2    -4  95864
>> > 3    -3  82322
>> > 4    -2  95591
>> > 5    -1  69378
>> > 6     0  74281
>> > 7     1 103261
>> > 8     2  92473
>> > 9     3  84344
>> > 10    4 127415
>> > 11    5 123826
>> > 12    6 100029
>> > 13    7  76205
>> > 14    8 105162
>> > 15    9 119533
>> > 16   10 106490
>> > 17   -5  82322
>> > 18   -4  95591
>> > 19   -3  69378
>> > 20   -2  74281
>> > 21   -1 103261
>> > 22    0  92473
>> > 23    1  84344
>> > 24    2 127415
>> > 25    3 123826
>> > 26    4 100029
>> > 27    5  76205
>> > 28    6 105162
>> > 29    7 119533
>> > 30    8 106490
>> > 31    9 114771
>> > 32   10  55593
>> > 33   -5  85694
>> > 34   -4  65205
>> > 35   -3  80995
>> > 36   -2  51723
>> > 37   -1  62310
>> > 38    0  53401
>> > 39    1  65677
>> > 40    2  76094
>> > 41    3  64035
>> > 42    4  68290
>> > 43    5  73306
>> > 44    6  82176
>> > 45    7  75566
>> > 46    8  89762
>> > 47    9  88063
>> > 48   10  94395
>> > 49   -5  80651
>> > 50   -4  81291
>> > 51   -3  63702
>> > 52   -2  70297
>> > 53   -1  64117
>> > 54    0  71219
>> > 55    1  57354
>> > 56    2  62111
>> > 57    3  42252
>> > 58    4  35454
>> > 59    5  33469
>> > 60    6  38899
>> > 61    7  64981
>> > 62    8  85694
>> > 63    9  79452
>> > 64   10  85216
>> > 65   -5  71219
>> > 66   -4  57354
>> > 67   -3  62111
>> > 68   -2  42252
>> > 69   -1  35454
>> > 70    0  33469
>> > 71    1  38899
>> > 72    2  64981
>> > 73    3  85694
>> > 74    4  79452
>> > 75    5  85216
>> > 76    6  81721
>> > 77    7  91231
>> > 78    8 107074
>> > 79    9 108103
>> > 80   10  7576
>> >
>> > A<-matrix(rep(-5:10,71))
>> > B<-matrix(data)
>> >  AB<-data.frame(A,B)
>> >
>> > x= B
>> >
>> >  f<-factor(A)
>> > AB<- tapply(x,f,mean)
>> > x<--5:10
>> > plot(x,AB,type="l")
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>
>


From giftedlife2014 @ending from gm@il@com  Sun Jun 24 17:58:06 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Sun, 24 Jun 2018 16:58:06 +0100
Subject: [R] tapply and error bars
In-Reply-To: <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
 <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>
 <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
 <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>
Message-ID: <CAC8ss30FJ4GyDMsa5hVcq0uV8M4tYaRBabAij=Q6-o-mAJ2tYg@mail.gmail.com>

Hi Jim

Thanks again for returning to this.
please not that the line "oomean<-as.vector(by(oodf$B,oodf$A,mean))" was
omitted (not sure whether deliberate)  after you introduced the standard
error function.
When I used it, empty plot window with the correct axes were generated but
no data was displayed. No error too.

library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

When I included the line, the same empty graph window was generated but
with the former error "Error in FUN(X[[1L]], ...) : could not find function
"FUN""
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

I am sure am missing something but can't place it. Please have a look again
to track my mistake.

Warmest regards
Ogbos

On Sun, Jun 24, 2018 at 11:24 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ogbos,
> If I use the example data that you sent, I get the error after this line:
>
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> Error in FUN(X[[i]], ...) : object 'std.error' not found
>
> The reason is that you have not defined std.error as a function, but
> as the result of a calculation. When I rewrite it like this:
>
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> I get the expected plot.
>
> Jim
>
>
> On Sat, Jun 23, 2018 at 9:36 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> > Hi Jim,
> >
> > Thanks for assisting. Here is what I did:
> >
> > A<-matrix(rep(-5:10,71))
> > B<-matrix(data)
> > std.error = sd(B)/sqrt(sum(!is.na(B)))
> >  oodf<-data.frame(A,B)
> >
> >  oomean<-as.vector(by(oodf$B,oodf$A,mean))
> > oose<-as.vector(by(oodf$B,oodf$A,std.error))
> > plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> > dispersion(-5:10,oomean,oose)
> >
> > And the error says:
> > Error in FUN(X[[1L]], ...) : could not find function "FUN"
> >
> > Please note that I use:
> > std.error = sd(B)/sqrt(sum(!is.na(B)))
> >  to calculate the standard error as it requested for it.
> >
> > Thanks
> > Ogbos
> >
> > On Sat, Jun 23, 2018 at 10:09 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>
> >> Hi Ogbos,
> >> This may help:
> >>
> >> # assume your data frame is named "oodf"
> >> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> >> dispersion(-5:10,oomean,oose)
> >>
> >> Jim
> >>
> >> On Sat, Jun 23, 2018 at 4:35 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> >> wrote:
> >> > Dear workers,
> >> > I have a data of length 1136. Below is the code I use to get the means
> >> > B.
> >> > It worked fine and I had the mean calculated and plotted.
> >> >
> >> > I wish to plot the error bars as well. I already plotted such means
> with
> >> > error bars before. Please see attached for example.
> >> >
> >> > I tried to redo the same plot but unlikely could not get around it as
> I
> >> > lost my system containing the script.
> >> > Among many attempts, I tried:
> >> > library(gplots)
> >> >
> >> >  plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68,
> >> > main="Main
> >> >   effect Plot",barcol="black")
> >> > Nothing worked.
> >> >
> >> > I would really be thankful should somebody return me to the track.
> >> > Many, many thanks for your time.
> >> > Ogbos
> >> >
> >> > A sample of the data is:
> >> > S/N      A        B
> >> > 1    -5  64833
> >> > 2    -4  95864
> >> > 3    -3  82322
> >> > 4    -2  95591
> >> > 5    -1  69378
> >> > 6     0  74281
> >> > 7     1 103261
> >> > 8     2  92473
> >> > 9     3  84344
> >> > 10    4 127415
> >> > 11    5 123826
> >> > 12    6 100029
> >> > 13    7  76205
> >> > 14    8 105162
> >> > 15    9 119533
> >> > 16   10 106490
> >> > 17   -5  82322
> >> > 18   -4  95591
> >> > 19   -3  69378
> >> > 20   -2  74281
> >> > 21   -1 103261
> >> > 22    0  92473
> >> > 23    1  84344
> >> > 24    2 127415
> >> > 25    3 123826
> >> > 26    4 100029
> >> > 27    5  76205
> >> > 28    6 105162
> >> > 29    7 119533
> >> > 30    8 106490
> >> > 31    9 114771
> >> > 32   10  55593
> >> > 33   -5  85694
> >> > 34   -4  65205
> >> > 35   -3  80995
> >> > 36   -2  51723
> >> > 37   -1  62310
> >> > 38    0  53401
> >> > 39    1  65677
> >> > 40    2  76094
> >> > 41    3  64035
> >> > 42    4  68290
> >> > 43    5  73306
> >> > 44    6  82176
> >> > 45    7  75566
> >> > 46    8  89762
> >> > 47    9  88063
> >> > 48   10  94395
> >> > 49   -5  80651
> >> > 50   -4  81291
> >> > 51   -3  63702
> >> > 52   -2  70297
> >> > 53   -1  64117
> >> > 54    0  71219
> >> > 55    1  57354
> >> > 56    2  62111
> >> > 57    3  42252
> >> > 58    4  35454
> >> > 59    5  33469
> >> > 60    6  38899
> >> > 61    7  64981
> >> > 62    8  85694
> >> > 63    9  79452
> >> > 64   10  85216
> >> > 65   -5  71219
> >> > 66   -4  57354
> >> > 67   -3  62111
> >> > 68   -2  42252
> >> > 69   -1  35454
> >> > 70    0  33469
> >> > 71    1  38899
> >> > 72    2  64981
> >> > 73    3  85694
> >> > 74    4  79452
> >> > 75    5  85216
> >> > 76    6  81721
> >> > 77    7  91231
> >> > 78    8 107074
> >> > 79    9 108103
> >> > 80   10  7576
> >> >
> >> > A<-matrix(rep(-5:10,71))
> >> > B<-matrix(data)
> >> >  AB<-data.frame(A,B)
> >> >
> >> > x= B
> >> >
> >> >  f<-factor(A)
> >> > AB<- tapply(x,f,mean)
> >> > x<--5:10
> >> > plot(x,AB,type="l")
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >
> >
>

	[[alternative HTML version deleted]]


From @elli@ @ending from v@@@@r@edu  Sun Jun 24 20:00:51 2018
From: @elli@ @ending from v@@@@r@edu (Simon Ellis)
Date: Sun, 24 Jun 2018 14:00:51 -0400
Subject: [R] Outputting variable names and their value bindings
Message-ID: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>

Hullo,

I'm writing a piece of scripting glue for a colleague who is doing
computations in several different languages. (It's the most convenient way,
right now.) My system calls the relevant program (e.g. Rstudio, MATLAB)
with a path to a script, captures stdout and parses it for output
variables, which it stores in its own environment for use later on.

This is easy with MATLAB, since it writes back the variable name with its
value, e.g.:

> freq = {somefunction}()
freq =

    <value>

All I have to do is look for lines with '=' on the end, then grab the next
section of non-empty lines as the binding for the variable. Boom.

With Rscript, if I write something like this:

Rscript -e "a = (2 + 2)" -e "a"

it prints

[1] 4

Is there any way to get R to print output similarly to MATLAB, in an x = y
format?

I have other solutions in mind, but they're all kludgy and I'd rather not
have to. Please can someone save me from the kludge? :-D

Thank you,

~Simon Ellis


-- 
Visiting Assistant Professor,
Department of Computer Science,
Vassar College,
Poughkeepsie, NY 12604

?The whole modern world has divided itself into Conservatives and
Progressives. The business of Progressives is to go on making mistakes. The
business of Conservatives is to prevent mistakes from being corrected.? *--
G. K. Chesterton*

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jun 24 22:03:53 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 24 Jun 2018 13:03:53 -0700
Subject: [R] parallel computing in r....
In-Reply-To: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <9479A978-896B-45F4-8DBF-C769B8BEFAF4@dcn.davis.ca.us>

You cannot send one task to 12 processors... the price of parallelism is that you must break down your task into smaller tasks. Once you have number of tasks equal to our more than the number of available cores then the higher level functions such as parLapply or mclapply can shuffle tasks onto cores. If you have 48 cores and 4 tasks, only 4 of the cores will be used. You probably should stay away from directly calling mcparallel as it is a low level function. Read the vignette about the base "parallel" package [1]. You might also like to use the forEach contributed package to simplify your work, and should look at the CRAN High Performance Computing Task View [2].

[1] vignette("parallel") or http://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf
[2] https://cran.r-project.org/web/views/HighPerformanceComputing.html

On June 22, 2018 3:12:28 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>      I am taking recourse to parallel computing to speed up my R code.
>
>The mcparallel function(in parallel package),presumably, sends a single
>task (an R function, to be precise) to a single core. Is this right? Is
>that one and only one core? What if there are other cores lying idle?
>
>As far as I am concerned, I am going to rent an AWS EC2 server with 48
>cores. I have four functions to be parallelized. Can I send the thread
>of one function to 12 cores, so that all 48 cores are utilized? If so,
>how do I do that with mcparallel function in the parallel package?
>
>Very many thanks for your time and effort...
>yours sincerely....
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sun Jun 24 22:14:07 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 24 Jun 2018 13:14:07 -0700
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
References: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
Message-ID: <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>

Yes and no. R does not have a "Matlab-output-compatibility" mode, but you can write your script to output anything you want it to using the "cat" function with various functions like "sprintf" and "as.character". You may want to write some functions that format some common objects that you typically output. Then just make sure to use those functions instead of the standard "put an object alone on a line" method of printing.

On June 24, 2018 11:00:51 AM PDT, Simon Ellis <sellis at vassar.edu> wrote:
>Hullo,
>
>I'm writing a piece of scripting glue for a colleague who is doing
>computations in several different languages. (It's the most convenient
>way,
>right now.) My system calls the relevant program (e.g. Rstudio, MATLAB)
>with a path to a script, captures stdout and parses it for output
>variables, which it stores in its own environment for use later on.
>
>This is easy with MATLAB, since it writes back the variable name with
>its
>value, e.g.:
>
>> freq = {somefunction}()
>freq =
>
>    <value>
>
>All I have to do is look for lines with '=' on the end, then grab the
>next
>section of non-empty lines as the binding for the variable. Boom.
>
>With Rscript, if I write something like this:
>
>Rscript -e "a = (2 + 2)" -e "a"
>
>it prints
>
>[1] 4
>
>Is there any way to get R to print output similarly to MATLAB, in an x
>= y
>format?
>
>I have other solutions in mind, but they're all kludgy and I'd rather
>not
>have to. Please can someone save me from the kludge? :-D
>
>Thank you,
>
>~Simon Ellis

-- 
Sent from my phone. Please excuse my brevity.


From drjimlemon @ending from gm@il@com  Sun Jun 24 22:51:14 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Mon, 25 Jun 2018 06:51:14 +1000
Subject: [R] tapply and error bars
In-Reply-To: <CAC8ss30FJ4GyDMsa5hVcq0uV8M4tYaRBabAij=Q6-o-mAJ2tYg@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
 <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>
 <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
 <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>
 <CAC8ss30FJ4GyDMsa5hVcq0uV8M4tYaRBabAij=Q6-o-mAJ2tYg@mail.gmail.com>
Message-ID: <CA+8X3fUSRmq0yPErQDYqQL6bR3MgWBVM=m6N=ymtNriY+2RMyA@mail.gmail.com>

Hi Ogbos,
The problem is almost certainly with the data. I get the plot I expect
with the sample data that you first posted, so I know that the code
works. If you try thIs what do you get?

oodf<-read.table(text="S/N      A        B
1    -5  64833
2    -4  95864
3    -3  82322
4    -2  95591
5    -1  69378
6     0  74281
7     1 103261
8     2  92473
9     3  84344
10    4 127415
11    5 123826
12    6 100029
13    7  76205
14    8 105162
15    9 119533
16   10 106490
17   -5  82322
18   -4  95591
19   -3  69378
20   -2  74281
21   -1 103261
22    0  92473
23    1  84344
24    2 127415
25    3 123826
26    4 100029
27    5  76205
28    6 105162
29    7 119533
30    8 106490
31    9 114771
32   10  55593
33   -5  85694
34   -4  65205
35   -3  80995
36   -2  51723
37   -1  62310
38    0  53401
39    1  65677
40    2  76094
41    3  64035
42    4  68290
43    5  73306
44    6  82176
45    7  75566
46    8  89762
47    9  88063
48   10  94395
49   -5  80651
50   -4  81291
51   -3  63702
52   -2  70297
53   -1  64117
54    0  71219
55    1  57354
56    2  62111
57    3  42252
58    4  35454
59    5  33469
60    6  38899
61    7  64981
62    8  85694
63    9  79452
64   10  85216
65   -5  71219
66   -4  57354
67   -3  62111
68   -2  42252
69   -1  35454
70    0  33469
71    1  38899
72    2  64981
73    3  85694
74    4  79452
75    5  85216
76    6  81721
77    7  91231
78    8 107074
79    9 108103
80   10  7576",
header=TRUE)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

I get the attached plot;

Jim

On Mon, Jun 25, 2018 at 1:58 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Hi Jim
>
> Thanks again for returning to this.
> please not that the line "oomean<-as.vector(by(oodf$B,oodf$A,mean))" was
> omitted (not sure whether deliberate)  after you introduced the standard
> error function.
> When I used it, empty plot window with the correct axes were generated but
> no data was displayed. No error too.
>
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> When I included the line, the same empty graph window was generated but with
> the former error "Error in FUN(X[[1L]], ...) : could not find function
> "FUN""
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> I am sure am missing something but can't place it. Please have a look again
> to track my mistake.
>
> Warmest regards
> Ogbos
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ooplot.pdf
Type: application/pdf
Size: 5776 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180625/fe014680/attachment.pdf>

From r@turner @ending from @uckl@nd@@c@nz  Sun Jun 24 23:46:07 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 25 Jun 2018 09:46:07 +1200
Subject: [R] OT --- grammar.
Message-ID: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>


Does/should one say "the degrees of freedom is defined to be" or "the 
degrees of freedom are defined to be"?

Although value of "degrees of freedom" is a single number, the first 
formulation sounds very odd to my ear.

I would like to call upon the collective wisdom of the R community to 
help me decide.

Thanks, and my apologies for the off-topic post.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From murdoch@dunc@n @ending from gm@il@com  Mon Jun 25 00:06:16 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Sun, 24 Jun 2018 18:06:16 -0400
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <d75aa587-dd1d-f512-9e5d-e5f0cfbe3c3e@gmail.com>

On 24/06/2018 5:46 PM, Rolf Turner wrote:
> 
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?
> 
> Although value of "degrees of freedom" is a single number, the first
> formulation sounds very odd to my ear.
> 
> I would like to call upon the collective wisdom of the R community to
> help me decide.
> 
> Thanks, and my apologies for the off-topic post.

I'd agree with you:  "are".

Duncan Murdoch


From h@@@n@diw@n @ending from gm@il@com  Mon Jun 25 00:08:47 2018
From: h@@@n@diw@n @ending from gm@il@com (Hasan Diwan)
Date: Sun, 24 Jun 2018 15:08:47 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <CAP+bYWB5q_7+8ejpOOBrvSR-sRE0WmksuKvsvQkhps3Q1VbgVg@mail.gmail.com>

On Sun, 24 Jun 2018 at 14:46, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?

"are", the noun in your statement is "degrees", while the fragment "of
freedom" acts as an adjective, narrowing the scope of the term
"degrees". Hope that helps... -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable


From peter@l@ngfelder @ending from gm@il@com  Mon Jun 25 00:17:01 2018
From: peter@l@ngfelder @ending from gm@il@com (Peter Langfelder)
Date: Sun, 24 Jun 2018 15:17:01 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <CA+hbrhUQxVeiS48BmBUBMXYq9faTbhkDTF++waZexhxa9HWiXA@mail.gmail.com>

I would use "the number of degrees of freedom is defined... ".

Peter
On Sun, Jun 24, 2018 at 2:46 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?
>
> Although value of "degrees of freedom" is a single number, the first
> formulation sounds very odd to my ear.
>
> I would like to call upon the collective wisdom of the R community to
> help me decide.
>
> Thanks, and my apologies for the off-topic post.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From loe@ljrg @ending from @ccucom@net  Mon Jun 25 00:40:45 2018
From: loe@ljrg @ending from @ccucom@net (JRG)
Date: Sun, 24 Jun 2018 18:40:45 -0400
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <38251b00-9a89-ba39-72b3-59b6fffc657a@accucom.net>

(I suspect there will be much disagreement about "is" vs. "are".)

I'd say something like "the parameter degrees of freedom is defined to
be ..."

---JRG



On 06/24/2018 05:46 PM, Rolf Turner wrote:
> 
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?
> 
> Although value of "degrees of freedom" is a single number, the first
> formulation sounds very odd to my ear.
> 
> I would like to call upon the collective wisdom of the R community to
> help me decide.
> 
> Thanks, and my apologies for the off-topic post.
> 
> cheers,
> 
> Rolf Turner
>


From ted@h@rding @ending from wl@ndre@@net  Mon Jun 25 00:44:30 2018
From: ted@h@rding @ending from wl@ndre@@net (Ted Harding)
Date: Sun, 24 Jun 2018 23:44:30 +0100
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <1529880270.3898.26.camel@deb2.fort.knox.uk>

On Mon, 2018-06-25 at 09:46 +1200, Rolf Turner wrote:
> Does/should one say "the degrees of freedom is defined to be" or "the 
> degrees of freedom are defined to be"?
> 
> Although value of "degrees of freedom" is a single number, the first 
> formulation sounds very odd to my ear.
> 
> I would like to call upon the collective wisdom of the R community to 
> help me decide.
> 
> Thanks, and my apologies for the off-topic post.
> 
> cheers,
> Rolf Turner

Interesting question, Rolf!
>From my point of view. I see "degrees of freedon" as a plural noun,
because of "degrees". But in some cases, we have only 1 degree of
freedon. Then the degrees of freedon is 1.

But we do not say, in that case, "the degree of freedom is defined
to be", or the degree of freedom are 1"

Nor would we say "The degrees of freedom are 19".!

So I thonk that the solution is to encapsulate the term within
aingle quotes, so that it becomes a singular entity. Thus:

The 'degrees of freedom' is defined to be ... "; and
The 'degrees of freedom' is 1.
Or
The degrees of freedom' is 19.

This is not the same issue as (one of my prime hates) saying
"the data is srored in the dataframe ... ". "Data" is a
plural noun (ainguler "datum"), and I would insist on
"the data are stored ... ". The French use "une donnee" and
"les donnees"; the Germans use "ein Datum", "der Daten";
so they know what they're doing! English-speakers mostly do not"

Best wishes to all,
Ted.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Mon Jun 25 01:38:30 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sun, 24 Jun 2018 16:38:30 -0700
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <CAPfrqaHKQKbGOZSfN83YoZw+WNLnM=XdmGk16fz-THeKcaKmYA@mail.gmail.com>
References: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
 <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>
 <CAPfrqaHKQKbGOZSfN83YoZw+WNLnM=XdmGk16fz-THeKcaKmYA@mail.gmail.com>
Message-ID: <444D6F5F-2C74-40CC-A6AD-22947B78210B@dcn.davis.ca.us>

Yes [1], though most people use it interactively, e.g.

?cat
?sprintf

[1] https://cran.r-project.org/manuals.html

On June 24, 2018 4:31:40 PM PDT, Simon Ellis <sellis at vassar.edu> wrote:
>Thank you for your reply.
>
>At the moment, my colleague and her students are just using
>zero-dimensional variables for output, no vectors or matrices, which
>does
>make my life easier.
>
>Since my code-glue parses through the scripts' code to substitute
>variables
>as required, I could code a command to cause my system to emit a line
>to
>get R to print something I could use.
>
>I am sure this is a dumb question, but is there a reference manual for
>R
>available online?
>
>On 24 June 2018 at 16:14, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Yes and no. R does not have a "Matlab-output-compatibility" mode, but
>you
>> can write your script to output anything you want it to using the
>"cat"
>> function with various functions like "sprintf" and "as.character".
>You may
>> want to write some functions that format some common objects that you
>> typically output. Then just make sure to use those functions instead
>of the
>> standard "put an object alone on a line" method of printing.
>>
>> On June 24, 2018 11:00:51 AM PDT, Simon Ellis <sellis at vassar.edu>
>wrote:
>> >Hullo,
>> >
>> >I'm writing a piece of scripting glue for a colleague who is doing
>> >computations in several different languages. (It's the most
>convenient
>> >way,
>> >right now.) My system calls the relevant program (e.g. Rstudio,
>MATLAB)
>> >with a path to a script, captures stdout and parses it for output
>> >variables, which it stores in its own environment for use later on.
>> >
>> >This is easy with MATLAB, since it writes back the variable name
>with
>> >its
>> >value, e.g.:
>> >
>> >> freq = {somefunction}()
>> >freq =
>> >
>> >    <value>
>> >
>> >All I have to do is look for lines with '=' on the end, then grab
>the
>> >next
>> >section of non-empty lines as the binding for the variable. Boom.
>> >
>> >With Rscript, if I write something like this:
>> >
>> >Rscript -e "a = (2 + 2)" -e "a"
>> >
>> >it prints
>> >
>> >[1] 4
>> >
>> >Is there any way to get R to print output similarly to MATLAB, in an
>x
>> >= y
>> >format?
>> >
>> >I have other solutions in mind, but they're all kludgy and I'd
>rather
>> >not
>> >have to. Please can someone save me from the kludge? :-D
>> >
>> >Thank you,
>> >
>> >~Simon Ellis
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Mon Jun 25 02:03:57 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sun, 24 Jun 2018 17:03:57 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <1529880270.3898.26.camel@deb2.fort.knox.uk>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
Message-ID: <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>

Ted, et. al.:

Re: "Data is" vs "data are" ... Heh heh!

"This is the kind of arrant pedantry up with which I will not put."
(Attributed to Churchill in one form or another, likely wrongly.)

See here for some semi-authoritative dicussion:

http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jun 24, 2018 at 3:44 PM, Ted Harding <ted.harding at wlandres.net>
wrote:

> On Mon, 2018-06-25 at 09:46 +1200, Rolf Turner wrote:
> > Does/should one say "the degrees of freedom is defined to be" or "the
> > degrees of freedom are defined to be"?
> >
> > Although value of "degrees of freedom" is a single number, the first
> > formulation sounds very odd to my ear.
> >
> > I would like to call upon the collective wisdom of the R community to
> > help me decide.
> >
> > Thanks, and my apologies for the off-topic post.
> >
> > cheers,
> > Rolf Turner
>
> Interesting question, Rolf!
> >From my point of view. I see "degrees of freedon" as a plural noun,
> because of "degrees". But in some cases, we have only 1 degree of
> freedon. Then the degrees of freedon is 1.
>
> But we do not say, in that case, "the degree of freedom is defined
> to be", or the degree of freedom are 1"
>
> Nor would we say "The degrees of freedom are 19".!
>
> So I thonk that the solution is to encapsulate the term within
> aingle quotes, so that it becomes a singular entity. Thus:
>
> The 'degrees of freedom' is defined to be ... "; and
> The 'degrees of freedom' is 1.
> Or
> The degrees of freedom' is 19.
>
> This is not the same issue as (one of my prime hates) saying
> "the data is srored in the dataframe ... ". "Data" is a
> plural noun (ainguler "datum"), and I would insist on
> "the data are stored ... ". The French use "une donnee" and
> "les donnees"; the Germans use "ein Datum", "der Daten";
> so they know what they're doing! English-speakers mostly do not"
>
> Best wishes to all,
> Ted.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From loe@ljrg @ending from @ccucom@net  Mon Jun 25 02:16:24 2018
From: loe@ljrg @ending from @ccucom@net (JRG)
Date: Sun, 24 Jun 2018 20:16:24 -0400
Subject: [R] OT --- grammar.
In-Reply-To: <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
Message-ID: <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>


On 06/24/2018 08:03 PM, Bert Gunter wrote:
> Ted, et. al.:
> 
> Re: "Data is" vs "data are" ... Heh heh!
> 
> "This is the kind of arrant pedantry up with which I will not put."
> (Attributed to Churchill in one form or another, likely wrongly.)
> 
> See here for some semi-authoritative dicussion:
> 
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/


Hmmm.  "semi-authoritative or not", the 1980 Edition of the Oxford
American dictionary says:

"data (day-ta) n. pl. facts or information ...  'Data' should not be
used with a singular verb, as in 'the data is inconclusive'; it is by
origin a Latin plural (the singular is 'datum') and should be used with
a plural verb. ..."


Interesting how Latin seemed to have changed in the past 40 or so years.


---JRG

John R. Gleason



> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Sun, Jun 24, 2018 at 3:44 PM, Ted Harding <ted.harding at wlandres.net>
> wrote:
> 
>> On Mon, 2018-06-25 at 09:46 +1200, Rolf Turner wrote:
>>> Does/should one say "the degrees of freedom is defined to be" or "the
>>> degrees of freedom are defined to be"?
>>>
>>> Although value of "degrees of freedom" is a single number, the first
>>> formulation sounds very odd to my ear.
>>>
>>> I would like to call upon the collective wisdom of the R community to
>>> help me decide.
>>>
>>> Thanks, and my apologies for the off-topic post.
>>>
>>> cheers,
>>> Rolf Turner
>>
>> Interesting question, Rolf!
>> >From my point of view. I see "degrees of freedon" as a plural noun,
>> because of "degrees". But in some cases, we have only 1 degree of
>> freedon. Then the degrees of freedon is 1.
>>
>> But we do not say, in that case, "the degree of freedom is defined
>> to be", or the degree of freedom are 1"
>>
>> Nor would we say "The degrees of freedom are 19".!
>>
>> So I thonk that the solution is to encapsulate the term within
>> aingle quotes, so that it becomes a singular entity. Thus:
>>
>> The 'degrees of freedom' is defined to be ... "; and
>> The 'degrees of freedom' is 1.
>> Or
>> The degrees of freedom' is 19.
>>
>> This is not the same issue as (one of my prime hates) saying
>> "the data is srored in the dataframe ... ". "Data" is a
>> plural noun (ainguler "datum"), and I would insist on
>> "the data are stored ... ". The French use "une donnee" and
>> "les donnees"; the Germans use "ein Datum", "der Daten";
>> so they know what they're doing! English-speakers mostly do not"
>>
>> Best wishes to all,
>> Ted.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


From r@turner @ending from @uckl@nd@@c@nz  Mon Jun 25 02:16:26 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Mon, 25 Jun 2018 12:16:26 +1200
Subject: [R] OT --- grammar.
In-Reply-To: <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
Message-ID: <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>

On 25/06/18 12:03, Bert Gunter wrote:
> Ted, et. al.:
> 
> Re: "Data is" vs "data are" ... Heh heh!
> 
> "This is the kind of arrant pedantry up with which I will not put."
> (Attributed to Churchill in one form or another, likely wrongly.)
> 
> See here for some semi-authoritative dicussion:
> 
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/

I beg to differ.  "The data was out of date" sounds just plain stupid to 
my sensitive ears.

It's rather like using the phrase "begs the question" to mean "raises 
the question" or "invites the question" rather than to carry its 
*correct* meaning of "assumes what is to be proved".  The fact that the 
phrase is almost always used in its *incorrect* sense these days, and 
almost never in its *correct* sense, does not diminish the fact that 
those who use it incorrectly are ignorant scumbags!  The language is 
weakened and diminished by the encroachment of incorrect usage.

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From drjimlemon @ending from gm@il@com  Mon Jun 25 02:37:05 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Mon, 25 Jun 2018 10:37:05 +1000
Subject: [R] Outputting variable names and their value bindings
Message-ID: <CA+8X3fWmQkiRNd46RfA4-WSBT8F=86s+DoO-7fioM7zRHRBd9A@mail.gmail.com>

Hi Simon,
Easy to do if you call "print" directly:

print<-function(x) cat(deparse(substitute(x)),"=\n",x,"\n")
y<-3
print(y)
y =
 3

Obviously you will want to get rid of your print function when it is
not being used with "rm" or by starting a new session. Getting it to
bypass the default print method is more difficult and I don't have the
time to untangle that one at the moment.

Jim


From md@umner @ending from gm@il@com  Mon Jun 25 03:07:38 2018
From: md@umner @ending from gm@il@com (Michael Sumner)
Date: Mon, 25 Jun 2018 08:07:38 +0700
Subject: [R] OT --- grammar.
In-Reply-To: <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
Message-ID: <CAAcGz98=sxKDBPd35i1sALxU7954b+7TfOHt8JdSA+YAeNQT5w@mail.gmail.com>

No it isn't. Your stature is diminished by hateful behaviour.

Cheers, Mike

On Mon, 25 Jun 2018, 07:26 Rolf Turner, <r.turner at auckland.ac.nz> wrote:

> On 25/06/18 12:03, Bert Gunter wrote:
> > Ted, et. al.:
> >
> > Re: "Data is" vs "data are" ... Heh heh!
> >
> > "This is the kind of arrant pedantry up with which I will not put."
> > (Attributed to Churchill in one form or another, likely wrongly.)
> >
> > See here for some semi-authoritative dicussion:
> >
> >
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/
>
> I beg to differ.  "The data was out of date" sounds just plain stupid to
> my sensitive ears.
>
> It's rather like using the phrase "begs the question" to mean "raises
> the question" or "invites the question" rather than to carry its
> *correct* meaning of "assumes what is to be proved".  The fact that the
> phrase is almost always used in its *incorrect* sense these days, and
> almost never in its *correct* sense, does not diminish the fact that
> those who use it incorrectly are ignorant scumbags!  The language is
> weakened and diminished by the encroachment of incorrect usage.
>
>
>
> cheers,
>
> Rolf
>
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]


From @elli@ @ending from v@@@@r@edu  Mon Jun 25 01:31:40 2018
From: @elli@ @ending from v@@@@r@edu (Simon Ellis)
Date: Sun, 24 Jun 2018 19:31:40 -0400
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>
References: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
 <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>
Message-ID: <CAPfrqaHKQKbGOZSfN83YoZw+WNLnM=XdmGk16fz-THeKcaKmYA@mail.gmail.com>

Thank you for your reply.

At the moment, my colleague and her students are just using
zero-dimensional variables for output, no vectors or matrices, which does
make my life easier.

Since my code-glue parses through the scripts' code to substitute variables
as required, I could code a command to cause my system to emit a line to
get R to print something I could use.

I am sure this is a dumb question, but is there a reference manual for R
available online?

On 24 June 2018 at 16:14, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Yes and no. R does not have a "Matlab-output-compatibility" mode, but you
> can write your script to output anything you want it to using the "cat"
> function with various functions like "sprintf" and "as.character". You may
> want to write some functions that format some common objects that you
> typically output. Then just make sure to use those functions instead of the
> standard "put an object alone on a line" method of printing.
>
> On June 24, 2018 11:00:51 AM PDT, Simon Ellis <sellis at vassar.edu> wrote:
> >Hullo,
> >
> >I'm writing a piece of scripting glue for a colleague who is doing
> >computations in several different languages. (It's the most convenient
> >way,
> >right now.) My system calls the relevant program (e.g. Rstudio, MATLAB)
> >with a path to a script, captures stdout and parses it for output
> >variables, which it stores in its own environment for use later on.
> >
> >This is easy with MATLAB, since it writes back the variable name with
> >its
> >value, e.g.:
> >
> >> freq = {somefunction}()
> >freq =
> >
> >    <value>
> >
> >All I have to do is look for lines with '=' on the end, then grab the
> >next
> >section of non-empty lines as the binding for the variable. Boom.
> >
> >With Rscript, if I write something like this:
> >
> >Rscript -e "a = (2 + 2)" -e "a"
> >
> >it prints
> >
> >[1] 4
> >
> >Is there any way to get R to print output similarly to MATLAB, in an x
> >= y
> >format?
> >
> >I have other solutions in mind, but they're all kludgy and I'd rather
> >not
> >have to. Please can someone save me from the kludge? :-D
> >
> >Thank you,
> >
> >~Simon Ellis
>
> --
> Sent from my phone. Please excuse my brevity.
>



-- 
Visiting Assistant Professor,
Department of Computer Science,
Vassar College,
Poughkeepsie, NY 12604

?The whole modern world has divided itself into Conservatives and
Progressives. The business of Progressives is to go on making mistakes. The
business of Conservatives is to prevent mistakes from being corrected.? *--
G. K. Chesterton*

	[[alternative HTML version deleted]]


From @elli@ @ending from v@@@@r@edu  Mon Jun 25 02:59:54 2018
From: @elli@ @ending from v@@@@r@edu (Simon Ellis)
Date: Sun, 24 Jun 2018 20:59:54 -0400
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <CA+8X3fWmQkiRNd46RfA4-WSBT8F=86s+DoO-7fioM7zRHRBd9A@mail.gmail.com>
References: <CA+8X3fWmQkiRNd46RfA4-WSBT8F=86s+DoO-7fioM7zRHRBd9A@mail.gmail.com>
Message-ID: <CAPfrqaE0enu_81HOFUhr0BQYmveEuZpmMxyEKObUkbWgiXW9Uw@mail.gmail.com>

Hullo Jim,

That's wonderful: thank you so much! That makes things even easier. There
are also no problems regarding getting rid of the function as each set of
computations occurs in a new Rstudio process: it's not optimal, but given
the problem it was the best solution. My code will just stick this print
function at the very top of each R script, and then I can get my
collaborator to call it where there are variables to be read out.

This is great. Thank you again! :-)

On 24 June 2018 at 20:37, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Simon,
> Easy to do if you call "print" directly:
>
> print<-function(x) cat(deparse(substitute(x)),"=\n",x,"\n")
> y<-3
> print(y)
> y =
>  3
>
> Obviously you will want to get rid of your print function when it is
> not being used with "rm" or by starting a new session. Getting it to
> bypass the default print method is more difficult and I don't have the
> time to untangle that one at the moment.
>
> Jim
>



-- 
Visiting Assistant Professor,
Department of Computer Science,
Vassar College,
Poughkeepsie, NY 12604

?The whole modern world has divided itself into Conservatives and
Progressives. The business of Progressives is to go on making mistakes. The
business of Conservatives is to prevent mistakes from being corrected.? *--
G. K. Chesterton*

	[[alternative HTML version deleted]]


From p@ul @ending from @t@t@@uckl@nd@@c@nz  Mon Jun 25 05:43:22 2018
From: p@ul @ending from @t@t@@uckl@nd@@c@nz (Paul Murrell)
Date: Mon, 25 Jun 2018 15:43:22 +1200
Subject: [R] HLS and HSV in package colorspace [not whitepoint related]
In-Reply-To: <CAEvk5z+_GBBpKqnptA7EJ+QdqiHFSit8+YbpkvaOV6Xm+G+e=A@mail.gmail.com>
References: <CAEvk5z+_GBBpKqnptA7EJ+QdqiHFSit8+YbpkvaOV6Xm+G+e=A@mail.gmail.com>
Message-ID: <443c7fa6-609d-b79f-404b-1dd829dcf760@stat.auckland.ac.nz>


Thanks Glenn.
I also favour restricting to sRGB<->HSV/HLS top remove ambiguity (so 
there is no direct conversion RGB<->HSV/HLS).
This would also be consistent with grDevices::rgb2hsv().

Paul

On 23/06/18 13:43, Glenn Davis wrote:
> Achim and Paul,
> 
> This is an entirely different subject - unrelated to whitepoint.
> 
> In the diagram I sketched, I made direct links between HSV and sRGB, and 
> HLS and sRGB.
> This is because the man page for HLS says:
> 
> This function creates colors in the HLS color space which corresponds to 
> the standard sRGB color space (IEC standard 61966).
> 
> and similarly for HSV.? But the C code in as_HSV()? actually does this:
> 
> case RGB:
> case sRGB:
>  ??? for(i = 0; i < n; i++) {
>  ??????? RGB_to_HSV(REAL(color)[i], REAL(color)[i+n], REAL(color)[i+2*n],
>  ??? ??? ???? &REAL(ans)[i], &REAL(ans)[i+n], &REAL(ans)[i+2*n]);
>  ??? }
>  ??? break;
> 
> And so both linear RGB and non-linear sRGB are converted to HSV in 
> exactly the same way.
> And it's the same for HLS (though not as obvious).
> My diagram does not match the C code since the code also has /direct 
> /links between RGB and HLS/HSV.
> This means that if one transforms from RGB to sRGB and then to HLS,
> it is not the same as? transforming from RGB to HLS in one step.
> A beginner probably would be surprised by this behavior.
> See an actual example below.
> 
> I can see the dilemma here.? The Wikipedia page
> https://en.wikipedia.org/wiki/HSL_and_HSV
> says
> Also, in general, HSL and HSV are today computed directly from 
> gamma-corrected <https://en.wikipedia.org/wiki/Gamma_correction> /R/?, 
> /G/?, and /B/??for instance in sRGB <https://en.wikipedia.org/wiki/SRGB> 
> space?but, when the models were developed, might have been 
> transformations of a linear RGB space.
> So some authors use linear RGB and some use non-linear RGB.
> In the *colorspace *package there are really 2 HLS spaces - a 
> linear-based HLS
> and a non-linear based HLS.? It is up to the user to keep things straight.
> As protection against confusion, I see that many *colorspace * 
> conversions to and from
> HLS/HSV generate the error message
> error("Ambiguous conversion");
> There is no mention of possible ambiguity in the man pages.
> 
> So what I am really bringing to your attention is a mismatch between the 
> man pages
> and the code.?? I see 2 ways to fix this mismatch:
> 
>  1. pick one HLS/HSV space (linear or non-linear) and stick to it and
>     document it.? I would recommend non-linear sRGB based on the
>     Wikipedia article.? Change the C code so it matches my sketch. 
>     There will no longer be any ambiguous transformations.
>  2. change the man pages and explain that HLS and HSV are currently
>     ambiguous, and so some conversions are also ambiguous.
> 
> I do not care, since I do not use these 2 spaces and probably never will.
> Option 1 might break someone else's package,
> so I would run this mismatch by your community of HLS/HSV users and see 
> what they think.
> 
> Glenn Davis
> 
> 
> An example of a non-commutative triangle:
> 
>> as( as( RGB(0.1,0.5,0.9), 'sRGB' ), 'HLS' )
>  ??????????? H???????? L???????? S
> [1,] 201.7339 0.6519387 0.8698137
> 
>> as( RGB(0.1,0.5,0.9), 'HLS' )
>  ?????? H?? L?? S
> [1,] 210 0.5 0.8
>> 
> 
> Note that 201.7339 0.6519387 0.8698137 != 210 0.5 0.8
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From giftedlife2014 @ending from gm@il@com  Mon Jun 25 06:46:44 2018
From: giftedlife2014 @ending from gm@il@com (Ogbos Okike)
Date: Mon, 25 Jun 2018 05:46:44 +0100
Subject: [R] tapply and error bars: Problem Fixed
Message-ID: <CAC8ss31w5VrQ9riU9mbrEaJnDaJPhW7nSrKiZ75yAJXpBx2-Ag@mail.gmail.com>

HI Jim,

This is great!! It is also tricky!!! The problem lies in the choice of
ylim. And looking at the data and choosing ylim based on the maximum and
minimum values of y is a waste of time. And choosing it by other means was
yet much more difficult.

I had to start plotting part of the data with incremental step of 80 data
points and manually varying ylim till I got to the last data point 1136,
where I finally used ylim=c(150000,162000) which has nothing to do with the
raw data.

Many, many thanks.
Best wishes
Ogbos

On Sun, Jun 24, 2018 at 9:51 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ogbos,
> The problem is almost certainly with the data. I get the plot I expect
> with the sample data that you first posted, so I know that the code
> works. If you try thIs what do you get?
>
> oodf<-read.table(text="S/N      A        B
> 1    -5  64833
> 2    -4  95864
> 3    -3  82322
> 4    -2  95591
> 5    -1  69378
> 6     0  74281
> 7     1 103261
> 8     2  92473
> 9     3  84344
> 10    4 127415
> 11    5 123826
> 12    6 100029
> 13    7  76205
> 14    8 105162
> 15    9 119533
> 16   10 106490
> 17   -5  82322
> 18   -4  95591
> 19   -3  69378
> 20   -2  74281
> 21   -1 103261
> 22    0  92473
> 23    1  84344
> 24    2 127415
> 25    3 123826
> 26    4 100029
> 27    5  76205
> 28    6 105162
> 29    7 119533
> 30    8 106490
> 31    9 114771
> 32   10  55593
> 33   -5  85694
> 34   -4  65205
> 35   -3  80995
> 36   -2  51723
> 37   -1  62310
> 38    0  53401
> 39    1  65677
> 40    2  76094
> 41    3  64035
> 42    4  68290
> 43    5  73306
> 44    6  82176
> 45    7  75566
> 46    8  89762
> 47    9  88063
> 48   10  94395
> 49   -5  80651
> 50   -4  81291
> 51   -3  63702
> 52   -2  70297
> 53   -1  64117
> 54    0  71219
> 55    1  57354
> 56    2  62111
> 57    3  42252
> 58    4  35454
> 59    5  33469
> 60    6  38899
> 61    7  64981
> 62    8  85694
> 63    9  79452
> 64   10  85216
> 65   -5  71219
> 66   -4  57354
> 67   -3  62111
> 68   -2  42252
> 69   -1  35454
> 70    0  33469
> 71    1  38899
> 72    2  64981
> 73    3  85694
> 74    4  79452
> 75    5  85216
> 76    6  81721
> 77    7  91231
> 78    8 107074
> 79    9 108103
> 80   10  7576",
> header=TRUE)
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> I get the attached plot;
>
> Jim
>
> On Mon, Jun 25, 2018 at 1:58 AM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> > Hi Jim
> >
> > Thanks again for returning to this.
> > please not that the line "oomean<-as.vector(by(oodf$B,oodf$A,mean))" was
> > omitted (not sure whether deliberate)  after you introduced the standard
> > error function.
> > When I used it, empty plot window with the correct axes were generated
> but
> > no data was displayed. No error too.
> >
> > library(plotrix)
> > std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> > oose<-as.vector(by(oodf$B,oodf$A,std.error))
> > plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> > dispersion(-5:10,oomean,oose)
> >
> > When I included the line, the same empty graph window was generated but
> with
> > the former error "Error in FUN(X[[1L]], ...) : could not find function
> > "FUN""
> > library(plotrix)
> > std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> > oomean<-as.vector(by(oodf$B,oodf$A,mean))
> > oose<-as.vector(by(oodf$B,oodf$A,std.error))
> > plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> > dispersion(-5:10,oomean,oose)
> >
> > I am sure am missing something but can't place it. Please have a look
> again
> > to track my mistake.
> >
> > Warmest regards
> > Ogbos
> >
>

	[[alternative HTML version deleted]]


From ml@thouri @ending from y@hoo@gr  Mon Jun 25 09:50:53 2018
From: ml@thouri @ending from y@hoo@gr (Maria Lathouri)
Date: Mon, 25 Jun 2018 07:50:53 +0000 (UTC)
Subject: [R] geom_text only in the first panel with facet_wrap in ggplot2
References: <1858534513.2037097.1529913053406.ref@mail.yahoo.com>
Message-ID: <1858534513.2037097.1529913053406@mail.yahoo.com>

Dear all, 


I am trying to add text only in the first panel of a faceted ggplot; I have been struggling to find a solution on this online but unfortunately none of what I found is working. 

Here it is a reproducible example. I hope it helps: 
library(gamm4) 
library(ggplot2) 

example<-read.csv("example.csv") 

head(example) 
#  Q  index ASB Year       WB_ID  S_ID score_1 score_2 works 
#1 100  1.02  1 2011 CL102021072830 157166     0   2.83    0 
#2 100  1.03  1 2014 CL102021072830 157166     0   2.83    0 
#3  80  1.02  1 2013 CL102021072860  1636     0  10.39    0 
#4  80  1.06  2 2006 CL102021072860  1636     0  10.39    0 
#5  80  1.06  2 2003 CL102021072860  1636     0  10.39    0 
#6  98  1.07  3 2002 CL102021072900  1635     0   7.57    0 

str(example) 
#'data.frame':    249 obs. of  9 variables: 
#  $ Q    : int  100 100 80 80 80 98 105 105 105 105 ... 
#$ index  : num  1.02 1.03 1.02 1.06 1.06 1.07 1.14 1.05 1.1 1.08 ... 
#$ ASB   : int  1 1 1 2 2 3 1 1 3 3 ... 
#$ Year  : int  2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ... 
#$ WB_ID  : Factor w/ 44 levels "CL102021072830",..: 1 1 2 2 2 3 3 3 4 4 ... 
#$ S_ID  : int  157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 ... 
#$ score_1: int  0 0 0 0 0 0 0 0 0 0 ... 
#$ score_2: num  2.83 2.83 10.39 10.39 10.39 ... 
#$ works  : num  0 0 0 0 0 0 0 0 0 0 ... 

# I need first to run a mixed-effect model
model<-gamm4(index~s(Q, by=factor(ASB))+Year+score_1+score_2+works, data=example, random=~(1|WB_ID/S_ID)) 


#I had to create a new dataset so I can use this with the ggplot2
newDat <- expand.grid(ASB = factor(example$ASB), 
Q = seq(from = min(example$Q, na.rm = TRUE), 
to = max(example$Q, na.rm = TRUE), 
length = 100), 
Year = 2002, 
score_1 = mean(example$score_1), 
score_2 = mean(example$score_2), 
works = mean(example$works), 
WB_ID = "CL102021072830", 
S_ID = "157166") 

datM <- predict(model$gam, type = "response", 
se.fit = TRUE, newdata = newDat) 

newDat$fit <- datM$fit 
newDat$upr <- datM$fit + (1.96 * datM$se.fit) 
newDat$lwr <- datM$fit - (1.96 * datM$se.fit) 



#I create a new variable for ASB so I can change the panel text
newDat$asb_1<-factor(newDat$ASB, levels=c(1, 2, 3), labels=c("ASB1", "ASB2", "ASB3")) 


#I plot this with ggplot2
p<-ggplot(newDat, aes(x = Q, y = fit, group = ASB)) + 
theme_bw() + 
geom_rug(data = example, aes(x = Q, y = 0.96), sides = "b") + 
ylim(0.96, 1.04) + 
geom_ribbon(aes(ymin = lwr, ymax = upr), col = NA, fill = "grey", 
alpha = 0.3) + 
geom_line(size = 1) + 
facet_wrap(~ asb_1, labeller = label_parsed) 


#When I try to add the text through geom_text, I get the text to all the three panels 
dat_text <- data.frame(label = c("Text", " ", " "), ASB  = c(1, 2, 3)) 

p + geom_text(x=20, y=1.03, data = dat_text, label = label) 

# or
p+geom_text(x=20, y=1.03 , aes(label=label), data=dat_text)


# I tried another way
ann_text <- data.frame(Q = 20, fit = 1.03, lab = "Text", ASB = factor(1,levels = c("1","2","3"))) 

p + geom_text(data = ann_text, label = "Text") 


# When I tried to use asb_1 instead of ASB, I got an errorann_text <- data.frame(Q = 20, fit = 1.03, lab = "Text", asb = factor("ASB1",levels = c("1","2","3"))) 


#Error in FUN(X[[i]], ...) : object 'ASB' not found

I would very much appreciate for your help. 

Thank you very much in advance. 

Kind regards,
Maria


From r@e@crump @ending from w@rwick@@c@uk  Mon Jun 25 13:49:18 2018
From: r@e@crump @ending from w@rwick@@c@uk (Ron Crump)
Date: Mon, 25 Jun 2018 12:49:18 +0100
Subject: [R] 
 geom_text only in the first panel with facet_wrap in ggplot2
Message-ID: <d4b94098-ec45-7e31-47ea-8027522e4916@warwick.ac.uk>

Dear Maria,

> I am trying to add text only in the first panel of a faceted ggplot
The following might help you to achieve what you
want. I created a small dummy dataset, but I tried to use
your column names in the hope this would help:

library(ggplot2)
# data.frame
DF <- data.frame(Q = rep(1:5, times=2),
                  fit = rep(1:5, times=2),
                  asb_1 = rep(letters[1:2], each=5))
# a DF holding the text and where to put it
tDF<-data.frame(Q = 2, fit = 3, str = 'example', asb_1 = "a")
# basic plot
p <- ggplot(DF, aes(x = Q, y = fit)) +
        geom_point() +
        facet_wrap(~ asb_1)
# and adding the text
p <- p + geom_text(data = tDF, mapping = aes(label = str) )

Hope this is useful,
Ron.


From john@@rchie@mckown @ending from gm@il@com  Mon Jun 25 14:34:49 2018
From: john@@rchie@mckown @ending from gm@il@com (John McKown)
Date: Mon, 25 Jun 2018 07:34:49 -0500
Subject: [R] OT --- grammar.
In-Reply-To: <CAAcGz98=sxKDBPd35i1sALxU7954b+7TfOHt8JdSA+YAeNQT5w@mail.gmail.com>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
 <CAAcGz98=sxKDBPd35i1sALxU7954b+7TfOHt8JdSA+YAeNQT5w@mail.gmail.com>
Message-ID: <CAAJSdjj65qA2XG+voF_f42JbBo0851mQ=ZTG8Uqu27vpvTfwEw@mail.gmail.com>

On Sun, Jun 24, 2018 at 8:08 PM Michael Sumner <mdsumner at gmail.com> wrote:

> No it isn't. Your stature is diminished by hateful behaviour.
>

?I will most likely also be labelled "hateful" for saying this, but I found
Rolf's post to be accurate, although phrased in a bit of an elitist way.?
Being a bit of a grammar Nazi (I may as well label myself as others likely
will), I sometimes come across as elitist as well. I am come across this
way because in any scientific endeavour, under which I include programming,
precision and accuracy is the top priority. Because if people think that
_I_ am a grammar Nazi, they haven't run into very many compilers
(especially for the archaic language COBOL) who will simply refuse to
compile something which doesn't make sense according to _its_ rules.

However, unlike Rolf, I do not take offense when people use idiomatic
expressions or even make up phrases on an English speaking mailing list
(English not being any kind of pristine, planned, language). So long as I
can puzzle it out, it is good to me. If I can't puzzle it out, I ignore it.
?
?My apologies to Dr. Sumner for originally sending this to him directly.
That was my error in not double checking that "reply" went to the proper
recipient. ?



>
> Cheers, Mike
>
> On Mon, 25 Jun 2018, 07:26 Rolf Turner, <r.turner at auckland.ac.nz> wrote:
>
> > On 25/06/18 12:03, Bert Gunter wrote:
> > > Ted, et. al.:
> > >
> > > Re: "Data is" vs "data are" ... Heh heh!
> > >
> > > "This is the kind of arrant pedantry up with which I will not put."
> > > (Attributed to Churchill in one form or another, likely wrongly.)
> > >
> > > See here for some semi-authoritative dicussion:
> > >
> > >
> >
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/
> >
> > I beg to differ.  "The data was out of date" sounds just plain stupid to
> > my sensitive ears.
> >
> > It's rather like using the phrase "begs the question" to mean "raises
> > the question" or "invites the question" rather than to carry its
> > *correct* meaning of "assumes what is to be proved".  The fact that the
> > phrase is almost always used in its *incorrect* sense these days, and
> > almost never in its *correct* sense, does not diminish the fact that
> > those who use it incorrectly are ignorant scumbags!  The language is
> > weakened and diminished by the encroachment of incorrect usage.
> >
> >
> >
> > cheers,
> >
> > Rolf
> >
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
There is no such thing as the Cloud. It is just somebody else?s computer.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]


From @bouelm@k@rim1962 @ending from gm@il@com  Mon Jun 25 16:36:48 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Mon, 25 Jun 2018 10:36:48 -0400
Subject: [R] Adding Axis value to R Plot
Message-ID: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>

Dear All: good morning



within this code, please see below,


plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt =
"n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)



Is there a way to force R to add the following Axis ticks to this plot


xticks <- c(15,25,35,45,55,65,75,85)
yticks <- c(300,400,500,600)



with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]


From ml@thouri @ending from y@hoo@gr  Mon Jun 25 16:46:02 2018
From: ml@thouri @ending from y@hoo@gr (Maria Lathouri)
Date: Mon, 25 Jun 2018 14:46:02 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBnZW9tX3RleHQgb25seSBpbiB0aGUgZmly?=
 =?utf-8?q?st_panel_with_facet=5Fwrap_in_ggplot2?=
In-Reply-To: <45144d17bdb88d003e998e623a6494ac@ruhr-uni-bochum.de>
References: <1858534513.2037097.1529913053406.ref@mail.yahoo.com>
 <1858534513.2037097.1529913053406@mail.yahoo.com>
 <45144d17bdb88d003e998e623a6494ac@ruhr-uni-bochum.de>
Message-ID: <392111583.2576251.1529937962889@mail.yahoo.com>

Dear Ulrik and all,
Thank you all so much; well, Ulrik's suggestion worked better. Very much appreciated.
Best,Maria 

    ???? 11:17 ?.?. ???????, 25 ??????? 2018, ?/? Ulrik Stervbo <Ulrik.Stervbo at ruhr-uni-bochum.de> ??????:
 

 Hi Maria,

you are on the right way. The data.frame with the text must have the 
same columns as you use in the clobal aesthetics, that is 'Q', 'fit', 
'ASB', and the facet variable ('asb_1') and the label you want shown.

ann_text <- data.frame(Q = 20, fit = 1.03, ASB = 1, plot_lab =? 
c("1","2","3"), asb_1 = c("ASB1", ASB2", "ASB3"))

p + geom_text(data = ann_text, aes(label = plot_lab)

should do the trick

HTH
Ulrik

On 2018-06-25 09:50, Maria Lathouri via R-help wrote:
> Dear all,
> 
> 
> I am trying to add text only in the first panel of a faceted ggplot; I
> have been struggling to find a solution on this online but
> unfortunately none of what I found is working.
> 
> Here it is a reproducible example. I hope it helps:
> library(gamm4)
> library(ggplot2)
> 
> example<-read.csv("example.csv")
> 
> head(example)
> #? Q? index ASB Year? ? ? WB_ID? S_ID score_1 score_2 works
> #1 100? 1.02? 1 2011 CL102021072830 157166? ? 0? 2.83? ? 0
> #2 100? 1.03? 1 2014 CL102021072830 157166? ? 0? 2.83? ? 0
> #3? 80? 1.02? 1 2013 CL102021072860? 1636? ? 0? 10.39? ? 0
> #4? 80? 1.06? 2 2006 CL102021072860? 1636? ? 0? 10.39? ? 0
> #5? 80? 1.06? 2 2003 CL102021072860? 1636? ? 0? 10.39? ? 0
> #6? 98? 1.07? 3 2002 CL102021072900? 1635? ? 0? 7.57? ? 0
> 
> str(example)
> #'data.frame':? ? 249 obs. of? 9 variables:
> #? $ Q? ? : int? 100 100 80 80 80 98 105 105 105 105 ...
> #$ index? : num? 1.02 1.03 1.02 1.06 1.06 1.07 1.14 1.05 1.1 1.08 ...
> #$ ASB? : int? 1 1 1 2 2 3 1 1 3 3 ...
> #$ Year? : int? 2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ...
> #$ WB_ID? : Factor w/ 44 levels "CL102021072830",..: 1 1 2 2 2 3 3 3 4 
> 4 ...
> #$ S_ID? : int? 157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 
> ...
> #$ score_1: int? 0 0 0 0 0 0 0 0 0 0 ...
> #$ score_2: num? 2.83 2.83 10.39 10.39 10.39 ...
> #$ works? : num? 0 0 0 0 0 0 0 0 0 0 ...
> 
> # I need first to run a mixed-effect model
> model<-gamm4(index~s(Q, by=factor(ASB))+Year+score_1+score_2+works,
> data=example, random=~(1|WB_ID/S_ID))
> 
> 
> #I had to create a new dataset so I can use this with the ggplot2
> newDat <- expand.grid(ASB = factor(example$ASB),
> Q = seq(from = min(example$Q, na.rm = TRUE),
> to = max(example$Q, na.rm = TRUE),
> length = 100),
> Year = 2002,
> score_1 = mean(example$score_1),
> score_2 = mean(example$score_2),
> works = mean(example$works),
> WB_ID = "CL102021072830",
> S_ID = "157166")
> 
> datM <- predict(model$gam, type = "response",
> se.fit = TRUE, newdata = newDat)
> 
> newDat$fit <- datM$fit
> newDat$upr <- datM$fit + (1.96 * datM$se.fit)
> newDat$lwr <- datM$fit - (1.96 * datM$se.fit)
> 
> 
> 
> #I create a new variable for ASB so I can change the panel text
> newDat$asb_1<-factor(newDat$ASB, levels=c(1, 2, 3), labels=c("ASB1",
> "ASB2", "ASB3"))
> 
> 
> #I plot this with ggplot2
> p<-ggplot(newDat, aes(x = Q, y = fit, group = ASB)) +
> theme_bw() +
> geom_rug(data = example, aes(x = Q, y = 0.96), sides = "b") +
> ylim(0.96, 1.04) +
> geom_ribbon(aes(ymin = lwr, ymax = upr), col = NA, fill = "grey",
> alpha = 0.3) +
> geom_line(size = 1) +
> facet_wrap(~ asb_1, labeller = label_parsed)
> 
> 
> #When I try to add the text through geom_text, I get the text to all
> the three panels
> dat_text <- data.frame(label = c("Text", " ", " "), ASB? = c(1, 2, 3))
> 
> p + geom_text(x=20, y=1.03, data = dat_text, label = label)
> 
> # or
> p+geom_text(x=20, y=1.03 , aes(label=label), data=dat_text)
> 
> 
> # I tried another way
> ann_text <- data.frame(Q = 20, fit = 1.03, lab = "Text", ASB =
> factor(1,levels = c("1","2","3")))
> 
> p + geom_text(data = ann_text, label = "Text")
> 
> 
> # When I tried to use asb_1 instead of ASB, I got an errorann_text <-
> data.frame(Q = 20, fit = 1.03, lab = "Text", asb =
> factor("ASB1",levels = c("1","2","3")))
> 
> 
> #Error in FUN(X[[i]], ...) : object 'ASB' not found
> 
> I would very much appreciate for your help.
> 
> Thank you very much in advance.
> 
> Kind regards,
> Maria
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Mon Jun 25 17:00:49 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Mon, 25 Jun 2018 08:00:49 -0700
Subject: [R] Adding Axis value to R Plot
In-Reply-To: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
References: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
Message-ID: <CAGxFJbTKoswrAoMM-M2=2JfNMJUnAa1OKVy_LBbW9G3cXyef8A@mail.gmail.com>

See ?plot.default, where it says:

axes

a logical value indicating whether both axes should be drawn on the plot.
Use graphical parameter
<http://127.0.0.1:29349/help/library/graphics/help/graphical%20parameter>
"xaxt" or "yaxt" to suppress just one of the axes.
 and use the "at" argument of ?axis to draw the axis and add ticks where
you like.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 25, 2018 at 7:36 AM, AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All: good morning
>
>
>
> within this code, please see below,
>
>
> plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt =
> "n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
> grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
>
>
>
> Is there a way to force R to add the following Axis ticks to this plot
>
>
> xticks <- c(15,25,35,45,55,65,75,85)
> yticks <- c(300,400,500,600)
>
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jw1085 @ending from wildc@t@@unh@edu  Mon Jun 25 20:24:28 2018
From: jw1085 @ending from wildc@t@@unh@edu (Jochen Wirsing)
Date: Mon, 25 Jun 2018 14:24:28 -0400
Subject: [R] Problems with 3.5.0 package installation & knitr
Message-ID: <5569677.kxo05TxI5a@lenny3>

Dear r-help,

I updated to R 3.5.0 a few days ago and was really excited about the new 
features it promised. Unfortunately, I ran into some serious trouble 
relatively quickly.
The main problem is, that I cannot install packages that depend on other 
packages. 
The problem has been (wrongfully) posted here: https://community.rstudio.com/
t/r-3-5-0-problem-installing-libraries/10155/3
A possibly connected problem is described here: https://community.rstudio.com/
t/file-does-not-exist-error-possibly-connected-with-r-3-5-0-update/10153

Both problems occur under R 3.5.0 (vanilla) as well as RStudio (1.1.453) and 
Antergos 18.04, as well as Win7.
The Antergos installation is brand new, the R installation in Win7 used to 
work absolutely perfectly before the update to 3.5.0

I hope those issues can be resolved quickly.


Thank you very much!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180625/4d93e154/attachment.sig>

From murdoch@dunc@n @ending from gm@il@com  Mon Jun 25 22:04:39 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Mon, 25 Jun 2018 16:04:39 -0400
Subject: [R] Problems with 3.5.0 package installation & knitr
In-Reply-To: <5569677.kxo05TxI5a@lenny3>
References: <5569677.kxo05TxI5a@lenny3>
Message-ID: <8f53c9e1-38d4-4f15-8c26-dcb82f70fe93@gmail.com>

On 25/06/2018 2:24 PM, Jochen Wirsing wrote:
> Dear r-help,
> 
> I updated to R 3.5.0 a few days ago and was really excited about the new
> features it promised. Unfortunately, I ran into some serious trouble
> relatively quickly.
> The main problem is, that I cannot install packages that depend on other
> packages.
> The problem has been (wrongfully) posted here: https://community.rstudio.com/
> t/r-3-5-0-problem-installing-libraries/10155/3
> A possibly connected problem is described here: https://community.rstudio.com/
> t/file-does-not-exist-error-possibly-connected-with-r-3-5-0-update/10153
> 
> Both problems occur under R 3.5.0 (vanilla) as well as RStudio (1.1.453) and
> Antergos 18.04, as well as Win7.
> The Antergos installation is brand new, the R installation in Win7 used to
> work absolutely perfectly before the update to 3.5.0
> 
> I hope those issues can be resolved quickly.

You posted this same issue to R-devel yesterday, and got a response 
asking you some questions about your setup.

Duncan Murdoch


From p@ulbern@l07 @ending from gm@il@com  Mon Jun 25 22:07:47 2018
From: p@ulbern@l07 @ending from gm@il@com (Paul Bernal)
Date: Mon, 25 Jun 2018 15:07:47 -0500
Subject: [R] Automating Azure ML Experiments from R
Message-ID: <CAMOcQfOUYOsZw3f_XnXt6rWLcE8wvzFVQWqGNxJzdp5sHudLsw@mail.gmail.com>

Dear friends,

Hope you are all doing great. I created a forecasting model experiment in
azure ml studio and I am trying to automate the execution of the experiment.

Does anybody knows or has an idea of how to automate azure ml experiments
from R?

Best regards,

Paul

	[[alternative HTML version deleted]]


From bog@@o@chri@tofer @ending from gm@il@com  Mon Jun 25 23:04:21 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Tue, 26 Jun 2018 02:34:21 +0530
Subject: [R] Correctly executing system code using R in Ubuntu server
Message-ID: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>

Hi,

I am curious on how to correctly run System code with R under Ubuntu. I
tried to execute below 2 lines of code using system() functions in Ubuntu
server, however could not achieve the desired result.

system('Xvfb :10 -ac &')
system('export DISPLAY=:10')

System parameters:
> Sys.info()
                                       sysname
                                       "Linux"
                                       release
                           "4.4.0-128-generic"
                                       version
"#154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018"
                                      nodename
                  "ubuntu-s-2vcpu-4gb-blr1-01"
                                       machine
                                      "x86_64"
                                         login
                                        "root"
                                          user
                                        "root"
                                effective_user
                                        "root"

Background:
I use RSelenium package to perform various testing using web-browser. I
have installed firefox to do the same, however to make RSelenium work, it
requires display parameter as guided in below link:
https://medium.com/@griggheo/running-selenium-webdriver-tests-using-firefox-headless-mode-on-ubuntu-d32500bb6af2
I want to set those parameters through R, each time I start R in Ubuntu
server.

Appreciate for any pointer.

Thanks,

	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Mon Jun 25 23:15:51 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Mon, 25 Jun 2018 14:15:51 -0700
Subject: [R] Correctly executing system code using R in Ubuntu server
In-Reply-To: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>
References: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>
Message-ID: <CAF8bMcaa+0KfZ36dkqyCofdHbbrd0fpPfSqM7s6U6T6Mn7Z6gg@mail.gmail.com>

Each call to system() starts and finishes a new shell so your approach will
not work.
Does the following do what you need?

> system('Xvfb :10 -ac &')
> Sys.setenv(DISPLAY=":10")
> x11()
Warning message:
In x11() : cairo-based types may only work correctly on TrueColor visuals



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 25, 2018 at 2:04 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I am curious on how to correctly run System code with R under Ubuntu. I
> tried to execute below 2 lines of code using system() functions in Ubuntu
> server, however could not achieve the desired result.
>
> system('Xvfb :10 -ac &')
> system('export DISPLAY=:10')
>
> System parameters:
> > Sys.info()
>                                        sysname
>                                        "Linux"
>                                        release
>                            "4.4.0-128-generic"
>                                        version
> "#154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018"
>                                       nodename
>                   "ubuntu-s-2vcpu-4gb-blr1-01"
>                                        machine
>                                       "x86_64"
>                                          login
>                                         "root"
>                                           user
>                                         "root"
>                                 effective_user
>                                         "root"
>
> Background:
> I use RSelenium package to perform various testing using web-browser. I
> have installed firefox to do the same, however to make RSelenium work, it
> requires display parameter as guided in below link:
> https://medium.com/@griggheo/running-selenium-webdriver-
> tests-using-firefox-headless-mode-on-ubuntu-d32500bb6af2
> I want to set those parameters through R, each time I start R in Ubuntu
> server.
>
> Appreciate for any pointer.
>
> Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From drjimlemon @ending from gm@il@com  Tue Jun 26 01:25:55 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Tue, 26 Jun 2018 09:25:55 +1000
Subject: [R] Adding Axis value to R Plot
In-Reply-To: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
References: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
Message-ID: <CA+8X3fUZLJnssb6AFhQh6YJNX-YWkTx7r_uNURDWYLmgQp87fw@mail.gmail.com>

Hi Abou,
You can't display an axis if it is not in the range of the plot. I
think you want:

plot(0,type="n",yaxs="i",xaxs="i",xaxt="n",yaxt="n",xlim=c(15,85),
 ylim=c(300,600),xlab="Age",ylab="Distance (ft)",cex.lab=1.5)
grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
xticks <- c(15,25,35,45,55,65,75,85)
yticks <- c(300,400,500,600)
axis(1,at=xticks)
axis(2,at=yticks)

Note the addition of xlim and ylim arguments.

Jim

On Tue, Jun 26, 2018 at 12:36 AM, AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
> Dear All: good morning
>
>
>
> within this code, please see below,
>
>
> plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt =
> "n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
> grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
>
>
>
> Is there a way to force R to add the following Axis ticks to this plot
>
>
> xticks <- c(15,25,35,45,55,65,75,85)
> yticks <- c(300,400,500,600)
>
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From jwd @ending from @urewe@t@net  Tue Jun 26 02:58:05 2018
From: jwd @ending from @urewe@t@net (John)
Date: Mon, 25 Jun 2018 17:58:05 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <20180625175805.11fd5a3a@Draco.localdomain>

On Mon, 25 Jun 2018 09:46:07 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> Does/should one say "the degrees of freedom is defined to be" or "the 
> degrees of freedom are defined to be"?
> 
I've leaned to differentiating between one degree of freedom and
multiple degrees of freedom and, when needed, phrase what I write
accordingly.  Canned phrases in the output of a routine may use
"degrees" simply because most of the time there are multiple degrees of
freedom.  After all, the only time "degree of freedom" would be
appropriate would be when there is just one.

JWDougherty


From jwd @ending from @urewe@t@net  Tue Jun 26 03:05:08 2018
From: jwd @ending from @urewe@t@net (John)
Date: Mon, 25 Jun 2018 18:05:08 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>
Message-ID: <20180625180508.70c545df@Draco.localdomain>

On Sun, 24 Jun 2018 20:16:24 -0400
JRG <loesljrg at accucom.net> wrote:

> On 06/24/2018 08:03 PM, Bert Gunter wrote:
> > Ted, et. al.:
> > 
> > Re: "Data is" vs "data are" ... Heh heh!
> > 
> > "This is the kind of arrant pedantry up with which I will not put."
> > (Attributed to Churchill in one form or another, likely wrongly.)
> > 
> > See here for some semi-authoritative dicussion:
> > 
> > http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/  
> 
> 
> Hmmm.  "semi-authoritative or not", the 1980 Edition of the Oxford
> American dictionary says:
> 
> "data (day-ta) n. pl. facts or information ...  'Data' should not be
> used with a singular verb, as in 'the data is inconclusive'; it is by
> origin a Latin plural (the singular is 'datum') and should be used
> with a plural verb. ..."
> 
> 
> Interesting how Latin seemed to have changed in the past 40 or so
> years.
> 
In fact, "the data are/is inconclusive" is shorthand for a longer
sentence.  Data are merely observations.  It is only after they are
made and summarized that a conclusion might be reached.  In which
case it was the analysis of the data that was inconclusive.  Since many
analyses of a single data set can be conducted and they are not
necessarily all going to be inconclusive, it really never was the data
that were inconclusive.

JWDoughetry


From dwin@emiu@ @ending from comc@@t@net  Tue Jun 26 04:27:13 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Mon, 25 Jun 2018 19:27:13 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <20180625180508.70c545df@Draco.localdomain>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>
 <20180625180508.70c545df@Draco.localdomain>
Message-ID: <586326E3-709E-42CB-B3E0-A714793ADDAB@comcast.net>

I?m surprised no on has reference the F distribution where the degrees of freedom are manifestly plural.

Sent from my iPhone

> On Jun 25, 2018, at 6:05 PM, John <jwd at surewest.net> wrote:
> 
> On Sun, 24 Jun 2018 20:16:24 -0400
> JRG <loesljrg at accucom.net> wrote:
> 
>>> On 06/24/2018 08:03 PM, Bert Gunter wrote:
>>> Ted, et. al.:
>>> 
>>> Re: "Data is" vs "data are" ... Heh heh!
>>> 
>>> "This is the kind of arrant pedantry up with which I will not put."
>>> (Attributed to Churchill in one form or another, likely wrongly.)
>>> 
>>> See here for some semi-authoritative dicussion:
>>> 
>>> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/  
>> 
>> 
>> Hmmm.  "semi-authoritative or not", the 1980 Edition of the Oxford
>> American dictionary says:
>> 
>> "data (day-ta) n. pl. facts or information ...  'Data' should not be
>> used with a singular verb, as in 'the data is inconclusive'; it is by
>> origin a Latin plural (the singular is 'datum') and should be used
>> with a plural verb. ..."
>> 
>> 
>> Interesting how Latin seemed to have changed in the past 40 or so
>> years.
>> 
> In fact, "the data are/is inconclusive" is shorthand for a longer
> sentence.  Data are merely observations.  It is only after they are
> made and summarized that a conclusion might be reached.  In which
> case it was the analysis of the data that was inconclusive.  Since many
> analyses of a single data set can be conducted and they are not
> necessarily all going to be inconclusive, it really never was the data
> that were inconclusive.
> 
> JWDoughetry
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From bog@@o@chri@tofer @ending from gm@il@com  Tue Jun 26 05:30:41 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Tue, 26 Jun 2018 09:00:41 +0530
Subject: [R] Correctly executing system code using R in Ubuntu server
In-Reply-To: <CAF8bMcaa+0KfZ36dkqyCofdHbbrd0fpPfSqM7s6U6T6Mn7Z6gg@mail.gmail.com>
References: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>
 <CAF8bMcaa+0KfZ36dkqyCofdHbbrd0fpPfSqM7s6U6T6Mn7Z6gg@mail.gmail.com>
Message-ID: <CA+dpOJ=AJA80eq775Z8ZtA=CP54bXGq3+3Rvng78c6vQ0jeBiA@mail.gmail.com>

It worked. Thanks,

On Tue, Jun 26, 2018 at 2:46 AM William Dunlap <wdunlap at tibco.com> wrote:

> Each call to system() starts and finishes a new shell so your approach
> will not work.
> Does the following do what you need?
>
> > system('Xvfb :10 -ac &')
> > Sys.setenv(DISPLAY=":10")
> > x11()
> Warning message:
> In x11() : cairo-based types may only work correctly on TrueColor visuals
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Jun 25, 2018 at 2:04 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Hi,
>>
>> I am curious on how to correctly run System code with R under Ubuntu. I
>> tried to execute below 2 lines of code using system() functions in Ubuntu
>> server, however could not achieve the desired result.
>>
>> system('Xvfb :10 -ac &')
>> system('export DISPLAY=:10')
>>
>> System parameters:
>> > Sys.info()
>>                                        sysname
>>                                        "Linux"
>>                                        release
>>                            "4.4.0-128-generic"
>>                                        version
>> "#154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018"
>>                                       nodename
>>                   "ubuntu-s-2vcpu-4gb-blr1-01"
>>                                        machine
>>                                       "x86_64"
>>                                          login
>>                                         "root"
>>                                           user
>>                                         "root"
>>                                 effective_user
>>                                         "root"
>>
>> Background:
>> I use RSelenium package to perform various testing using web-browser. I
>> have installed firefox to do the same, however to make RSelenium work, it
>> requires display parameter as guided in below link:
>>
>> https://medium.com/@griggheo/running-selenium-webdriver-tests-using-firefox-headless-mode-on-ubuntu-d32500bb6af2
>> I want to set those parameters through R, each time I start R in Ubuntu
>> server.
>>
>> Appreciate for any pointer.
>>
>> Thanks,
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From m@ij@@@irkj@rvi @ending from gm@il@com  Tue Jun 26 10:16:55 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 26 Jun 2018 11:16:55 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
Message-ID: <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>

Thanks for the reply! I got that figured out, but still have some problems
with the quadratic programming.

It seems that my Amat and dvec are incompatible. Amat is a matrix of zeros
size: *2*J-3,J* and dvec is a vector of length *J*. There should be no
problem, but apparently there is. The piece of code looks like this:

Dmat <- matrix(0,nrow= J, ncol=J)
diag(Dmat) <- 1
dvec <- rep(0,J)
dvec
dvec <- -hsmooth
Aeq <- 0
beq <- 0
Amat <- matrix(0,2*J-3,J)
bvec <- rep(0,2*J-3)

for(j in 2:J)
{
Amat[j-1,j-1] = -1
Amat[j-1,j] = 1
bvec[j-1] = Delta1
}

for(j in 3:J)
{
Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
bvec[J-1+j-2]= Delta2
}

solution <- solve.QP(Dmat, dvec, Amat, bvec)


2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:

> Keep replies on list please.
>
> You are not accessing a value from vector Q if you access the zero'th
> element!
> R > Q <- c(3, 5, 8)
> R > Q[0]
> numeric(0)
> R > Q[1]
> [1] 3
> R > Q[2]
> [1] 5
>
> In the first iteration of the loop j is 2 thus j-2 is 0 and that's the
> reason for the error message: you are trying to replace a matrix element
> with a zero-length (i.e. unassigned) numeric value. Perhaps, in your mind,
> you are mixing up the index of a vector element and its value? If you need
> two zeros to start your vector, do something like
>
> R > Q <- c(0, 0, Q)
> R > Q
> [1] 0 0 3 5 8
>
>
> Clear now?
> B.
>
>
>
> > On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> >
> > Many thanks for your message!
> >
> > The thing is that I need  Q[j-2] to be zero for the first two iterations
> because I don't have those values (J starts from 1). Do you have any idea
> how to do it?
> >
> > Thanks again!
> >
> > Maija
> >
> > 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> > Q[j-2] gives you Q[0] in your first inner loop iteration.
> > R arrays start at one.
> >
> > B.
> >
> >
> > > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> > >
> > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> >
> >
>
>

	[[alternative HTML version deleted]]


From ericjberger @ending from gm@il@com  Tue Jun 26 10:24:16 2018
From: ericjberger @ending from gm@il@com (Eric Berger)
Date: Tue, 26 Jun 2018 11:24:16 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
Message-ID: <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>

 The statement

dvec <- -hsmooth

looks like it might be the source of the problem, depending on what hsmooth
is.


On Tue, Jun 26, 2018 at 11:16 AM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com
> wrote:

> Thanks for the reply! I got that figured out, but still have some problems
> with the quadratic programming.
>
> It seems that my Amat and dvec are incompatible. Amat is a matrix of zeros
> size: *2*J-3,J* and dvec is a vector of length *J*. There should be no
> problem, but apparently there is. The piece of code looks like this:
>
> Dmat <- matrix(0,nrow= J, ncol=J)
> diag(Dmat) <- 1
> dvec <- rep(0,J)
> dvec
> dvec <- -hsmooth
> Aeq <- 0
> beq <- 0
> Amat <- matrix(0,2*J-3,J)
> bvec <- rep(0,2*J-3)
>
> for(j in 2:J)
> {
> Amat[j-1,j-1] = -1
> Amat[j-1,j] = 1
> bvec[j-1] = Delta1
> }
>
> for(j in 3:J)
> {
> Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
> Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
> bvec[J-1+j-2]= Delta2
> }
>
> solution <- solve.QP(Dmat, dvec, Amat, bvec)
>
>
> 2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>
> > Keep replies on list please.
> >
> > You are not accessing a value from vector Q if you access the zero'th
> > element!
> > R > Q <- c(3, 5, 8)
> > R > Q[0]
> > numeric(0)
> > R > Q[1]
> > [1] 3
> > R > Q[2]
> > [1] 5
> >
> > In the first iteration of the loop j is 2 thus j-2 is 0 and that's the
> > reason for the error message: you are trying to replace a matrix element
> > with a zero-length (i.e. unassigned) numeric value. Perhaps, in your
> mind,
> > you are mixing up the index of a vector element and its value? If you
> need
> > two zeros to start your vector, do something like
> >
> > R > Q <- c(0, 0, Q)
> > R > Q
> > [1] 0 0 3 5 8
> >
> >
> > Clear now?
> > B.
> >
> >
> >
> > > On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> > wrote:
> > >
> > > Many thanks for your message!
> > >
> > > The thing is that I need  Q[j-2] to be zero for the first two
> iterations
> > because I don't have those values (J starts from 1). Do you have any idea
> > how to do it?
> > >
> > > Thanks again!
> > >
> > > Maija
> > >
> > > 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> > > Q[j-2] gives you Q[0] in your first inner loop iteration.
> > > R arrays start at one.
> > >
> > > B.
> > >
> > >
> > > > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> > wrote:
> > > >
> > > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> > >
> > >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From m@ij@@@irkj@rvi @ending from gm@il@com  Tue Jun 26 10:34:31 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 26 Jun 2018 11:34:31 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>
Message-ID: <CAJxz9NajxNm-MigCXPFA9mOn0nXZeh4m4WHecz7fj0ExBhAW-A@mail.gmail.com>

Thanks for the reply!

dvec, thus hsmooth, has the same length J. It shouldn't be the problem.

2018-06-26 11:24 GMT+03:00 Eric Berger <ericjberger at gmail.com>:

> The statement
>
> dvec <- -hsmooth
>
> looks like it might be the source of the problem, depending on what
> hsmooth is.
>
>
> On Tue, Jun 26, 2018 at 11:16 AM, Maija Sirkj?rvi <
> maija.sirkjarvi at gmail.com> wrote:
>
>> Thanks for the reply! I got that figured out, but still have some problems
>> with the quadratic programming.
>>
>> It seems that my Amat and dvec are incompatible. Amat is a matrix of zeros
>> size: *2*J-3,J* and dvec is a vector of length *J*. There should be no
>>
>> problem, but apparently there is. The piece of code looks like this:
>>
>> Dmat <- matrix(0,nrow= J, ncol=J)
>> diag(Dmat) <- 1
>> dvec <- rep(0,J)
>> dvec
>> dvec <- -hsmooth
>> Aeq <- 0
>> beq <- 0
>> Amat <- matrix(0,2*J-3,J)
>> bvec <- rep(0,2*J-3)
>>
>> for(j in 2:J)
>> {
>> Amat[j-1,j-1] = -1
>> Amat[j-1,j] = 1
>> bvec[j-1] = Delta1
>> }
>>
>> for(j in 3:J)
>> {
>> Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
>> Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>> Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
>> bvec[J-1+j-2]= Delta2
>> }
>>
>> solution <- solve.QP(Dmat, dvec, Amat, bvec)
>>
>>
>> 2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>>
>> > Keep replies on list please.
>> >
>> > You are not accessing a value from vector Q if you access the zero'th
>> > element!
>> > R > Q <- c(3, 5, 8)
>> > R > Q[0]
>> > numeric(0)
>> > R > Q[1]
>> > [1] 3
>> > R > Q[2]
>> > [1] 5
>> >
>> > In the first iteration of the loop j is 2 thus j-2 is 0 and that's the
>> > reason for the error message: you are trying to replace a matrix element
>> > with a zero-length (i.e. unassigned) numeric value. Perhaps, in your
>> mind,
>> > you are mixing up the index of a vector element and its value? If you
>> need
>> > two zeros to start your vector, do something like
>> >
>> > R > Q <- c(0, 0, Q)
>> > R > Q
>> > [1] 0 0 3 5 8
>> >
>> >
>> > Clear now?
>> > B.
>> >
>> >
>> >
>> > > On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
>> > wrote:
>> > >
>> > > Many thanks for your message!
>> > >
>> > > The thing is that I need  Q[j-2] to be zero for the first two
>> iterations
>> > because I don't have those values (J starts from 1). Do you have any
>> idea
>> > how to do it?
>> > >
>> > > Thanks again!
>> > >
>> > > Maija
>> > >
>> > > 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>> > > Q[j-2] gives you Q[0] in your first inner loop iteration.
>> > > R arrays start at one.
>> > >
>> > > B.
>> > >
>> > >
>> > > > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com
>> >
>> > wrote:
>> > > >
>> > > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>> > >
>> > >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From berwin@turl@ch @ending from gm@il@com  Tue Jun 26 14:01:36 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Tue, 26 Jun 2018 20:01:36 +0800
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
Message-ID: <20180626200136.115557ce@goodenia>

G'day all,

On Tue, 26 Jun 2018 11:16:55 +0300
Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:

> It seems that my Amat and dvec are incompatible. Amat is a matrix of
> zeros size: *2*J-3,J* and dvec is a vector of length *J*. There
> should be no problem, but apparently there is. [...]

solve.QP solves the quadratic program:
	 min(-d^T b + 1/2 b^T D b) 
   where A^T b >= b_0.

Note the transpose. :)
If dvec is of length *J*, then b will be of length J too, and Amat
should be Jx(2J-3) so that its transpose is (2j-3)xJ, making it
compatible for matrix multiplication with b.

Cheers,

	Berwin

---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus


From Bill@Poling @ending from zeli@@com  Tue Jun 26 14:07:22 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Tue, 26 Jun 2018 12:07:22 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
Message-ID: <CY1PR0201MB1834A9FA7E201A7069D50D9DEA490@CY1PR0201MB1834.namprd02.prod.outlook.com>

Thank you Dan, that was very helpful. Sorry for the delayed response.

Cheers

WHP



From: Daniel Nordlund [mailto:djnordlund at gmail.com]
Sent: Saturday, June 23, 2018 6:04 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

On 6/22/2018 4:43 AM, Bill Poling wrote:
> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
> ClaimServiceID ClaimID DiagnosisCode
> 1 183056004 78044473 C562
> 2 183056004 78044473 C778
> 3 183056004 78044473 C784
> 4 183056004 78044473 C786
> 5 183056004 78044473 C7961
> 6 183056004 78044473 C7982
> 7 183056004 78044473 C7989
> 8 183056008 78044473 C562
> 9 183056008 78044473 C778
> 10 183056008 78044473 C784
> 11 183056008 78044473 C786
> 12 183056008 78044473 C7961
> 13 183056008 78044473 C7982
> 14 183056008 78044473 C7989
> 15 183139945 78078925 M79606
> 16 183139945 78078925 M7989
> 17 183139945 78078925 R600
> 18 183236728 78119632 H02831
> 19 183236728 78119632 H02832
> 20 183236728 78119632 H02834
> 21 183236728 78119632 H02835
> 22 183236728 78119632 H04123
> 23 183236728 78119632 Z411
> 24 183236728 78119632 H2513
> 25 183236728 78119632 H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
>
> claimServiceID ClaimID Dx1 Dx2 Dx3 ...etc
> 1 183056004 78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008 78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer" "integer" "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>
>
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>
>
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
>
>
> I am sure it's a basic, simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>

Bill,

you have received some good suggestions and since you are pressed for
time this may be too late. However, here is a solution using ave()
function and cast() from the reshape package.

# create diagnosis variable names
dxnames <- paste('Dx',ave(rep(1, nrow(have)), have[,1:2], FUN =
seq_along), sep='')
# cast the data into wide format
cast(cbind(have,dxnames), ClaimServiceID + ClaimID ~ dxnames,
value='DiagnosisCode')


Hope this is helpful,

Dan

--
Daniel Nordlund
Port Townsend, WA USA

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Tue Jun 26 14:14:10 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Tue, 26 Jun 2018 05:14:10 -0700
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NajxNm-MigCXPFA9mOn0nXZeh4m4WHecz7fj0ExBhAW-A@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>
 <CAJxz9NajxNm-MigCXPFA9mOn0nXZeh4m4WHecz7fj0ExBhAW-A@mail.gmail.com>
Message-ID: <B2938D61-C3EF-421C-B8D0-E509B77D315C@dcn.davis.ca.us>

The recommended (see the Posting Guide) way to resolve questions like this is to post a reproducible example so we can see the problem occur in our R session. There are a number of Internet resources that can help you get this right such as [1][2][3].

Note that one key to success is to learn how to configure your email program send plain text formatted email, since the mailing list will strip the HTML formatting anyway but this often leaves extraneous characters that make no sense to R. Most email attachments are removed, so keep including the code in the email body as you have been.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On June 26, 2018 1:34:31 AM PDT, "Maija Sirkj?rvi" <maija.sirkjarvi at gmail.com> wrote:
>Thanks for the reply!
>
>dvec, thus hsmooth, has the same length J. It shouldn't be the problem.
>
>2018-06-26 11:24 GMT+03:00 Eric Berger <ericjberger at gmail.com>:
>
>> The statement
>>
>> dvec <- -hsmooth
>>
>> looks like it might be the source of the problem, depending on what
>> hsmooth is.
>>
>>
>> On Tue, Jun 26, 2018 at 11:16 AM, Maija Sirkj?rvi <
>> maija.sirkjarvi at gmail.com> wrote:
>>
>>> Thanks for the reply! I got that figured out, but still have some
>problems
>>> with the quadratic programming.
>>>
>>> It seems that my Amat and dvec are incompatible. Amat is a matrix of
>zeros
>>> size: *2*J-3,J* and dvec is a vector of length *J*. There should be
>no
>>>
>>> problem, but apparently there is. The piece of code looks like this:
>>>
>>> Dmat <- matrix(0,nrow= J, ncol=J)
>>> diag(Dmat) <- 1
>>> dvec <- rep(0,J)
>>> dvec
>>> dvec <- -hsmooth
>>> Aeq <- 0
>>> beq <- 0
>>> Amat <- matrix(0,2*J-3,J)
>>> bvec <- rep(0,2*J-3)
>>>
>>> for(j in 2:J)
>>> {
>>> Amat[j-1,j-1] = -1
>>> Amat[j-1,j] = 1
>>> bvec[j-1] = Delta1
>>> }
>>>
>>> for(j in 3:J)
>>> {
>>> Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
>>> Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>>> Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
>>> bvec[J-1+j-2]= Delta2
>>> }
>>>
>>> solution <- solve.QP(Dmat, dvec, Amat, bvec)
>>>
>>>
>>> 2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>>>
>>> > Keep replies on list please.
>>> >
>>> > You are not accessing a value from vector Q if you access the
>zero'th
>>> > element!
>>> > R > Q <- c(3, 5, 8)
>>> > R > Q[0]
>>> > numeric(0)
>>> > R > Q[1]
>>> > [1] 3
>>> > R > Q[2]
>>> > [1] 5
>>> >
>>> > In the first iteration of the loop j is 2 thus j-2 is 0 and that's
>the
>>> > reason for the error message: you are trying to replace a matrix
>element
>>> > with a zero-length (i.e. unassigned) numeric value. Perhaps, in
>your
>>> mind,
>>> > you are mixing up the index of a vector element and its value? If
>you
>>> need
>>> > two zeros to start your vector, do something like
>>> >
>>> > R > Q <- c(0, 0, Q)
>>> > R > Q
>>> > [1] 0 0 3 5 8
>>> >
>>> >
>>> > Clear now?
>>> > B.
>>> >
>>> >
>>> >
>>> > > On 2018-06-14, at 01:22, Maija Sirkj?rvi
><maija.sirkjarvi at gmail.com>
>>> > wrote:
>>> > >
>>> > > Many thanks for your message!
>>> > >
>>> > > The thing is that I need  Q[j-2] to be zero for the first two
>>> iterations
>>> > because I don't have those values (J starts from 1). Do you have
>any
>>> idea
>>> > how to do it?
>>> > >
>>> > > Thanks again!
>>> > >
>>> > > Maija
>>> > >
>>> > > 2018-06-13 15:52 GMT+03:00 Boris Steipe
><boris.steipe at utoronto.ca>:
>>> > > Q[j-2] gives you Q[0] in your first inner loop iteration.
>>> > > R arrays start at one.
>>> > >
>>> > > B.
>>> > >
>>> > >
>>> > > > On 2018-06-13, at 07:21, Maija Sirkj?rvi
><maija.sirkjarvi at gmail.com
>>> >
>>> > wrote:
>>> > > >
>>> > > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>>> > >
>>> > >
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From Bill@Poling @ending from zeli@@com  Tue Jun 26 14:15:30 2018
From: Bill@Poling @ending from zeli@@com (Bill Poling)
Date: Tue, 26 Jun 2018 12:15:30 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
Message-ID: <CY1PR0201MB18348C8A71CEF766FC0F803DEA490@CY1PR0201MB1834.namprd02.prod.outlook.com>

Yep, thanks Dan, that?s got it. Thank you to everyone who responded as well.

WHP

ClaimServiceID  ClaimID     Dx1  Dx10  Dx11 Dx12     Dx2     Dx3     Dx4     Dx5     Dx6    Dx7    Dx8    Dx9
1        183056004 78044473    C562  <NA>  <NA> <NA>    C778    C784    C786   C7961   C7982  C7989   <NA>   <NA>
2        183056008 78044473    C562  <NA>  <NA> <NA>    C778    C784    C786   C7961   C7982  C7989   <NA>   <NA>
3        183139945 78078925  M79606  <NA>  <NA> <NA>   M7989    R600    <NA>    <NA>    <NA>   <NA>   <NA>   <NA>

From: Daniel Nordlund [mailto:djnordlund at gmail.com]
Sent: Saturday, June 23, 2018 6:04 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

On 6/22/2018 4:43 AM, Bill Poling wrote:
> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
> ClaimServiceID ClaimID DiagnosisCode
> 1 183056004 78044473 C562
> 2 183056004 78044473 C778
> 3 183056004 78044473 C784
> 4 183056004 78044473 C786
> 5 183056004 78044473 C7961
> 6 183056004 78044473 C7982
> 7 183056004 78044473 C7989
> 8 183056008 78044473 C562
> 9 183056008 78044473 C778
> 10 183056008 78044473 C784
> 11 183056008 78044473 C786
> 12 183056008 78044473 C7961
> 13 183056008 78044473 C7982
> 14 183056008 78044473 C7989
> 15 183139945 78078925 M79606
> 16 183139945 78078925 M7989
> 17 183139945 78078925 R600
> 18 183236728 78119632 H02831
> 19 183236728 78119632 H02832
> 20 183236728 78119632 H02834
> 21 183236728 78119632 H02835
> 22 183236728 78119632 H04123
> 23 183236728 78119632 Z411
> 24 183236728 78119632 H2513
> 25 183236728 78119632 H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
>
> claimServiceID ClaimID Dx1 Dx2 Dx3 ...etc
> 1 183056004 78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008 78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer" "integer" "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>
>
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>
>
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
>
>
> I am sure it's a basic, simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>

Bill,

you have received some good suggestions and since you are pressed for
time this may be too late. However, here is a solution using ave()
function and cast() from the reshape package.

# create diagnosis variable names
dxnames <- paste('Dx',ave(rep(1, nrow(have)), have[,1:2], FUN =
seq_along), sep='')
# cast the data into wide format
cast(cbind(have,dxnames), ClaimServiceID + ClaimID ~ dxnames,
value='DiagnosisCode')


Hope this is helpful,

Dan

--
Daniel Nordlund
Port Townsend, WA USA

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From reg@rdt@@ch@lkwyk @ending from gm@il@com  Mon Jun 25 22:39:11 2018
From: reg@rdt@@ch@lkwyk @ending from gm@il@com (Regardt Schalkwyk)
Date: Mon, 25 Jun 2018 20:39:11 +0000
Subject: [R] Automating Azure ML Experiments from R
In-Reply-To: <CAMOcQfOUYOsZw3f_XnXt6rWLcE8wvzFVQWqGNxJzdp5sHudLsw@mail.gmail.com>
References: <CAMOcQfOUYOsZw3f_XnXt6rWLcE8wvzFVQWqGNxJzdp5sHudLsw@mail.gmail.com>
Message-ID: <VI1PR0402MB38858CFCEDC181084FA4AFFBA84A0@VI1PR0402MB3885.eurprd04.prod.outlook.com>

Hi Paul

Microsoft has made this really easy for you.
Just deploy the web service, go to services.azureml.net, select your web service, click on consume, go to sample code and select R.

It will give you a sample script using RCurl and rjson to consume your service.

Regards
Regardt

Regardt Schalkwyk
________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Paul Bernal <paulbernal07 at gmail.com>
Sent: Monday, June 25, 2018 10:07:47 PM
To: r-help at r-project.org
Subject: [R] Automating Azure ML Experiments from R

Dear friends,

Hope you are all doing great. I created a forecasting model experiment in
azure ml studio and I am trying to automate the execution of the experiment.

Does anybody knows or has an idea of how to automate azure ml experiments
from R?

Best regards,

Paul

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From @pencer@gr@ve@ @ending from effectivedefen@e@org  Tue Jun 26 17:00:53 2018
From: @pencer@gr@ve@ @ending from effectivedefen@e@org (Spencer Graves)
Date: Tue, 26 Jun 2018 10:00:53 -0500
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <20180626200136.115557ce@goodenia>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
Message-ID: <17542e52-7c8c-5ccb-e89a-61f369db16b9@effectivedefense.org>

 ????? sos::findFn('{quadratic programming}') just identified 156 help 
pages in 68 packages containing the term "quadratic programming".? The 
function mentioned by Berwin Turlach, "solve.QP", is in package 
"quadprog", which has not been updated since 2016-12-20.? I've used 
qudprod successfully, but you might wish to consider some of the other 
options in package(s) more actively maintained.


 ????? The "print" method for sos::findFn('{quadratic programming}') 
produced two sheets in my default browser.? The first of these contained 
156 rows for the 156 help pages in 68 packages, sorted by default by 
c('Count', 'MaxScore', 'TotalScore', 'Package', 'Score', 'Function').? 
The second sheet listed only the 68 packages sorted by c('Count', 
'MaxScore', 'TotalScore', 'Package').? You can click on the column 
headers to get them sorted in different orders, if you want.


 ????? "sos::findFn" is for me the fastest literature search for 
anything statistical.? I often write the list of help pages and the 
package summary to an Excel file using the "writeFindFn2xls" function, 
then annotate the package summary with other information to help me 
decide which package(s) and function(s) to try.


 ????? Hope this helps.
 ????? Spencer Graves, lead author of "sos"


On 2018-06-26 07:01, Berwin A Turlach wrote:
> G'day all,
>
> On Tue, 26 Jun 2018 11:16:55 +0300
> Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
>
>> It seems that my Amat and dvec are incompatible. Amat is a matrix of
>> zeros size: *2*J-3,J* and dvec is a vector of length *J*. There
>> should be no problem, but apparently there is. [...]
> solve.QP solves the quadratic program:
> 	 min(-d^T b + 1/2 b^T D b)
>     where A^T b >= b_0.
>
> Note the transpose. :)
> If dvec is of length *J*, then b will be of length J too, and Amat
> should be Jx(2J-3) so that its transpose is (2j-3)xJ, making it
> compatible for matrix multiplication with b.
>
> Cheers,
>
> 	Berwin
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @bouelm@k@rim1962 @ending from gm@il@com  Tue Jun 26 17:35:34 2018
From: @bouelm@k@rim1962 @ending from gm@il@com (AbouEl-Makarim Aboueissa)
Date: Tue, 26 Jun 2018 11:35:34 -0400
Subject: [R] Adding Axis value to R Plot
In-Reply-To: <CA+8X3fUZLJnssb6AFhQh6YJNX-YWkTx7r_uNURDWYLmgQp87fw@mail.gmail.com>
References: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
 <CA+8X3fUZLJnssb6AFhQh6YJNX-YWkTx7r_uNURDWYLmgQp87fw@mail.gmail.com>
Message-ID: <CAE9stmc1Oz5sk+TxNowxYA3QbwyXC6Lr6n2w7dK3pVKyR7VM0Q@mail.gmail.com>

Dear Jim:

many thanks

abou

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*


On Mon, Jun 25, 2018 at 7:25 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Abou,
> You can't display an axis if it is not in the range of the plot. I
> think you want:
>
> plot(0,type="n",yaxs="i",xaxs="i",xaxt="n",yaxt="n",xlim=c(15,85),
>  ylim=c(300,600),xlab="Age",ylab="Distance (ft)",cex.lab=1.5)
> grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
> xticks <- c(15,25,35,45,55,65,75,85)
> yticks <- c(300,400,500,600)
> axis(1,at=xticks)
> axis(2,at=yticks)
>
> Note the addition of xlim and ylim arguments.
>
> Jim
>
> On Tue, Jun 26, 2018 at 12:36 AM, AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> > Dear All: good morning
> >
> >
> >
> > within this code, please see below,
> >
> >
> > plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt
> =
> > "n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
> > grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
> >
> >
> >
> > Is there a way to force R to add the following Axis ticks to this plot
> >
> >
> > xticks <- c(15,25,35,45,55,65,75,85)
> > yticks <- c(300,400,500,600)
> >
> >
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor of Statistics*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From reichm@nj @ending from @bcglob@l@net  Wed Jun 27 02:37:57 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Tue, 26 Jun 2018 19:37:57 -0500
Subject: [R] Convert Hijri to Gregorian
Message-ID: <000001d40daf$190590a0$4b10b1e0$@sbcglobal.net>

R-help

 

Does R have a package or function that will convert Gregorian to Hijri
(Islamic) dates (time series)?

 

Jeff 


	[[alternative HTML version deleted]]


From m@ij@@@irkj@rvi @ending from gm@il@com  Wed Jun 27 07:48:08 2018
From: m@ij@@@irkj@rvi @ending from gm@il@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 27 Jun 2018 08:48:08 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <20180626200136.115557ce@goodenia>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
Message-ID: <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>

Thanks for your reply! Unfortunately something is still wrong.

After the transpose, dvec and Amat are still incompatible.

> d <- -hsmooth
> dvec <- t(d)
> c <- dvec*Amat
Error in dvec * Amat : non-conformable arrays

Moreover, I don't understand the following:

> If dvec is of length *J*, then b will be of length J too.

I believe the length of dvec comes from the number of variables and the
length of b from the number of constraints. In this case they are not
equal.

2018-06-26 15:01 GMT+03:00 Berwin A Turlach <berwin.turlach at gmail.com>:

> G'day all,
>
> On Tue, 26 Jun 2018 11:16:55 +0300
> Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
>
> > It seems that my Amat and dvec are incompatible. Amat is a matrix of
> > zeros size: *2*J-3,J* and dvec is a vector of length *J*. There
> > should be no problem, but apparently there is. [...]
>
> solve.QP solves the quadratic program:
>          min(-d^T b + 1/2 b^T D b)
>    where A^T b >= b_0.
>
> Note the transpose. :)
> If dvec is of length *J*, then b will be of length J too, and Amat
> should be Jx(2J-3) so that its transpose is (2j-3)xJ, making it
> compatible for matrix multiplication with b.
>
> Cheers,
>
>         Berwin
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
>

	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @ending from gm@il@com  Wed Jun 27 22:53:58 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Wed, 27 Jun 2018 13:53:58 -0700
Subject: [R] Adding lines to the page
Message-ID: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>

Hi, I'm looking for a way to add lines to a report. To be clear, I don't want to add lines to any specific plot, but instead to add line(s) to the page itself - e.g. add a line to the footer area, above the actual footer text. 

Any thoughts on how to do this? Many thanks.


From jdnewmil @ending from dcn@d@vi@@c@@u@  Wed Jun 27 23:07:48 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Jun 2018 14:07:48 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
Message-ID: <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>

That would depend how you are generating the page... plots alone don't really have such options. If you don't know what this means then I suggest you read the Reproducible Research Task View [1]. knitr in conjunction with LaTeX (Rnw files) is very powerful, but there are many other tools as well (e.g. bookdown) depending on your preferences.

[1] https://cran.r-project.org/web/views/ReproducibleResearch.html

On June 27, 2018 1:53:58 PM PDT, Stats Student <stats.student4647 at gmail.com> wrote:
>Hi, I'm looking for a way to add lines to a report. To be clear, I
>don't want to add lines to any specific plot, but instead to add
>line(s) to the page itself - e.g. add a line to the footer area, above
>the actual footer text. 
>
>Any thoughts on how to do this? Many thanks.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From nichol@@@wr@y @ending from ntlworld@com  Thu Jun 28 00:33:39 2018
From: nichol@@@wr@y @ending from ntlworld@com (Nick Wray)
Date: Wed, 27 Jun 2018 23:33:39 +0100 (BST)
Subject: [R] How long can a csv file label be?
Message-ID: <1066236676.882891.1530138819259@mail2.virginmedia.com>

Hi For various reasons too dull to go into I have been trying to write csv files from R with very long filenames.  However R doesn't seem to like my doing this, but it is not clear to me what the maximum filename size is, and I can't find the info on the net.  I believe that the maximum pathname is 255 characters but is that the same thing?

Thanks if anyone can enlighten me

Nick Wray
	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Thu Jun 28 00:39:30 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Jun 2018 15:39:30 -0700
Subject: [R] How long can a csv file label be?
In-Reply-To: <1066236676.882891.1530138819259@mail2.virginmedia.com>
References: <1066236676.882891.1530138819259@mail2.virginmedia.com>
Message-ID: <067CF37F-5190-4347-A95E-6D8F83063C75@dcn.davis.ca.us>

This is operating-system-dependent. Check the documentation for your operating system (or the file subsystem you are using, since some OSes support multiple filesystems). Knowing this fact can make Googling more effective as well.

On June 27, 2018 3:33:39 PM PDT, Nick Wray via R-help <r-help at r-project.org> wrote:
>Hi For various reasons too dull to go into I have been trying to write
>csv files from R with very long filenames.  However R doesn't seem to
>like my doing this, but it is not clear to me what the maximum filename
>size is, and I can't find the info on the net.  I believe that the
>maximum pathname is 255 characters but is that the same thing?
>
>Thanks if anyone can enlighten me
>
>Nick Wray
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drjimlemon @ending from gm@il@com  Thu Jun 28 00:48:21 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Thu, 28 Jun 2018 08:48:21 +1000
Subject: [R] How long can a csv file label be?
In-Reply-To: <1066236676.882891.1530138819259@mail2.virginmedia.com>
References: <1066236676.882891.1530138819259@mail2.virginmedia.com>
Message-ID: <CA+8X3fWPZ9QCV918XL0v2UURFQfnG3bF1G_0xcv1T-0nimvEdw@mail.gmail.com>

Hi Nick,
You are probably using Windows, for which the maximum path length is
claimed to be 260 characters. The most common alternative, Linux, has
a maximum filename length of 255 and a maximum path length of 4096. If
you are simply writing a file to the current path, it won't make much
difference.

Jim

On Thu, Jun 28, 2018 at 8:33 AM, Nick Wray via R-help
<r-help at r-project.org> wrote:
> Hi For various reasons too dull to go into I have been trying to write csv files from R with very long filenames.  However R doesn't seem to like my doing this, but it is not clear to me what the maximum filename size is, and I can't find the info on the net.  I believe that the maximum pathname is 255 characters but is that the same thing?
>
> Thanks if anyone can enlighten me
>
> Nick Wray
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From @t@t@@@tudent4647 @ending from gm@il@com  Thu Jun 28 00:56:09 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Wed, 27 Jun 2018 15:56:09 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
Message-ID: <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>

Thanks, Jeff. The Task View page was very informative.

To answer your question, I'm using ggplot to generate my plots and grid/gridExtra/gtable to place those plots on a page. 

Considering that there are ways to add text on a page through textGrobs, independent of the plots, I was wondering if there was a similar functionality for adding lines. Also noticed a package called pagenum for adding page numbers. 

knitr is certainly interesting, but might be an overkill for what I am trying to do (creating basic multipage reports with basic headers, footers). 




On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>That would depend how you are generating the page... plots alone don't
>really have such options. If you don't know what this means then I
>suggest you read the Reproducible Research Task View [1]. knitr in
>conjunction with LaTeX (Rnw files) is very powerful, but there are many
>other tools as well (e.g. bookdown) depending on your preferences.
>
>[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
>
>On June 27, 2018 1:53:58 PM PDT, Stats Student
><stats.student4647 at gmail.com> wrote:
>>Hi, I'm looking for a way to add lines to a report. To be clear, I
>>don't want to add lines to any specific plot, but instead to add
>>line(s) to the page itself - e.g. add a line to the footer area, above
>>the actual footer text. 
>>
>>Any thoughts on how to do this? Many thanks.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Sent from my phone. Please excuse my brevity.


From nichol@@@wr@y @ending from ntlworld@com  Thu Jun 28 00:58:01 2018
From: nichol@@@wr@y @ending from ntlworld@com (Nick Wray)
Date: Wed, 27 Jun 2018 23:58:01 +0100 (BST)
Subject: [R] How long can a csv file label be?
In-Reply-To: <CA+8X3fWPZ9QCV918XL0v2UURFQfnG3bF1G_0xcv1T-0nimvEdw@mail.gmail.com>
References: <1066236676.882891.1530138819259@mail2.virginmedia.com>
 <CA+8X3fWPZ9QCV918XL0v2UURFQfnG3bF1G_0xcv1T-0nimvEdw@mail.gmail.com>
Message-ID: <829245353.883175.1530140281580@mail2.virginmedia.com>

Thanks Jim

> On 27 June 2018 at 23:48 Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
> Hi Nick,
> You are probably using Windows, for which the maximum path length is
> claimed to be 260 characters. The most common alternative, Linux, has
> a maximum filename length of 255 and a maximum path length of 4096. If
> you are simply writing a file to the current path, it won't make much
> difference.
>
> Jim
>
> On Thu, Jun 28, 2018 at 8:33 AM, Nick Wray via R-help
> <r-help at r-project.org> wrote:
> > Hi For various reasons too dull to go into I have been trying to write csv files from R with very long filenames. However R doesn't seem to like my doing this, but it is not clear to me what the maximum filename size is, and I can't find the info on the net. I believe that the maximum pathname is 255 characters but is that the same thing?
> >
> > Thanks if anyone can enlighten me
> >
> > Nick Wray
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Thu Jun 28 01:38:07 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 27 Jun 2018 16:38:07 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
 <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
Message-ID: <CAGxFJbQez+SMgH_PP-qfjK2Y54TojdGRdF_Qye_Gg1WvMzraJw@mail.gmail.com>

"Considering that there are ways to add text on a page through textGrobs.."

... and the linesGrob() function would do the same for lines, no?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 27, 2018 at 3:56 PM, Stats Student <stats.student4647 at gmail.com>
wrote:

> Thanks, Jeff. The Task View page was very informative.
>
> To answer your question, I'm using ggplot to generate my plots and
> grid/gridExtra/gtable to place those plots on a page.
>
> Considering that there are ways to add text on a page through textGrobs,
> independent of the plots, I was wondering if there was a similar
> functionality for adding lines. Also noticed a package called pagenum for
> adding page numbers.
>
> knitr is certainly interesting, but might be an overkill for what I am
> trying to do (creating basic multipage reports with basic headers,
> footers).
>
>
>
>
> On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> wrote:
> >That would depend how you are generating the page... plots alone don't
> >really have such options. If you don't know what this means then I
> >suggest you read the Reproducible Research Task View [1]. knitr in
> >conjunction with LaTeX (Rnw files) is very powerful, but there are many
> >other tools as well (e.g. bookdown) depending on your preferences.
> >
> >[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
> >
> >On June 27, 2018 1:53:58 PM PDT, Stats Student
> ><stats.student4647 at gmail.com> wrote:
> >>Hi, I'm looking for a way to add lines to a report. To be clear, I
> >>don't want to add lines to any specific plot, but instead to add
> >>line(s) to the page itself - e.g. add a line to the footer area, above
> >>the actual footer text.
> >>
> >>Any thoughts on how to do this? Many thanks.
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> >--
> >Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From rmh @ending from temple@edu  Thu Jun 28 01:45:10 2018
From: rmh @ending from temple@edu (Richard M. Heiberger)
Date: Wed, 27 Jun 2018 19:45:10 -0400
Subject: [R] Adding lines to the page
In-Reply-To: <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
 <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
Message-ID: <CAGx1TMAUO6vxP1D8OqdErV3c3fc+bxkqqKZZWn5vjCcD2hdXyw@mail.gmail.com>

See if the microplot package provides what you need.
The package help file and the vignette will get you started.
Microplot works with Hmisc::latex or with MS Word into either Word or HTML.

On Wed, Jun 27, 2018 at 19:04 Stats Student <stats.student4647 at gmail.com>
wrote:

> Thanks, Jeff. The Task View page was very informative.
>
> To answer your question, I'm using ggplot to generate my plots and
> grid/gridExtra/gtable to place those plots on a page.
>
> Considering that there are ways to add text on a page through textGrobs,
> independent of the plots, I was wondering if there was a similar
> functionality for adding lines. Also noticed a package called pagenum for
> adding page numbers.
>
> knitr is certainly interesting, but might be an overkill for what I am
> trying to do (creating basic multipage reports with basic headers,
> footers).
>
>
>
>
> On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> wrote:
> >That would depend how you are generating the page... plots alone don't
> >really have such options. If you don't know what this means then I
> >suggest you read the Reproducible Research Task View [1]. knitr in
> >conjunction with LaTeX (Rnw files) is very powerful, but there are many
> >other tools as well (e.g. bookdown) depending on your preferences.
> >
> >[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
> >
> >On June 27, 2018 1:53:58 PM PDT, Stats Student
> ><stats.student4647 at gmail.com> wrote:
> >>Hi, I'm looking for a way to add lines to a report. To be clear, I
> >>don't want to add lines to any specific plot, but instead to add
> >>line(s) to the page itself - e.g. add a line to the footer area, above
> >>the actual footer text.
> >>
> >>Any thoughts on how to do this? Many thanks.
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> >--
> >Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From je@n@@udu@@e@u @ending from y@hoo@fr  Wed Jun 27 22:42:47 2018
From: je@n@@udu@@e@u @ending from y@hoo@fr (audusseau jean)
Date: Wed, 27 Jun 2018 20:42:47 +0000 (UTC)
Subject: [R] r crossed nested random effects lme4
References: <768880710.5092604.1530132167533.ref@mail.yahoo.com>
Message-ID: <768880710.5092604.1530132167533@mail.yahoo.com>


I am new to this forum. I try to find the appropriate model for the following data set with lme4:

Each individual subject goes through 3 conditions ("Group", within-subject factor). These 3 conditions include 9 items (3 items in each condition, but the items differ in each condition). Score (4th column not represented above) is a continuous dependant variable (reaction time).I am interested in the fixed effect of the "Cond" variable and also would like to take into account the dependencies between my factors, but I have difficulties to know if my factors should be considered as nested or crossed.Does the following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any help would be much appreciated.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1530132091008blob.jpg
Type: image/png
Size: 13883 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180627/7bcffd6c/attachment.png>

From bgunter@4567 @ending from gm@il@com  Thu Jun 28 03:48:08 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Wed, 27 Jun 2018 18:48:08 -0700
Subject: [R] r crossed nested random effects lme4
In-Reply-To: <768880710.5092604.1530132167533@mail.yahoo.com>
References: <768880710.5092604.1530132167533.ref@mail.yahoo.com>
 <768880710.5092604.1530132167533@mail.yahoo.com>
Message-ID: <CAGxFJbTPGts25RW4n+p01N1Qsmn-ki0BWZ7fhkR0+DgGJ60pPg@mail.gmail.com>

Generally speaking, purely statistical issues are off topic on this forum,
which is about programming in the R language. More to the point, the
r-sig-mixed-models forum is concerned with questions about mixed effects
models, so you should post there.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 27, 2018 at 1:42 PM, audusseau jean via R-help <
r-help at r-project.org> wrote:

>
> I am new to this forum. I try to find the appropriate model for the
> following data set with lme4:
>
> Each individual subject goes through 3 conditions ("Group", within-subject
> factor). These 3 conditions include 9 items (3 items in each condition, but
> the items differ in each condition). Score (4th column not represented
> above) is a continuous dependant variable (reaction time).I am interested
> in the fixed effect of the "Cond" variable and also would like to take into
> account the dependencies between my factors, but I have difficulties to
> know if my factors should be considered as nested or crossed.Does the
> following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any
> help would be much appreciated.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]


From mikorym @ending from protonm@il@com  Thu Jun 28 10:56:26 2018
From: mikorym @ending from protonm@il@com (mikorym)
Date: Thu, 28 Jun 2018 04:56:26 -0400
Subject: [R] R examples in Agronomy
Message-ID: <v6iRc6_t8x0yGPVeokJiP57xyBJIjbdrk-GAYPZzb7Rcq5XTvh7Xq3AH3y9Epp14-Y0UanqHVBRzgVlxG5TCybev6Fh8pa5LXBL_pLl1xLY=@protonmail.com>

> Dear all,
> Are there good R stat examples in the field of agronomy (especially field experiments)?
> Thanks
> ----------------------------------------/-----------------------------------------
> Khaled IBRAHIMI, PhD
> Assistant Professor, Soil Science & Environment
> Higher Institute of Agricultural Sciences of Chott-Mariem
> The University of Sousse, Tunisia
> Tel.: 216 97 276 835
> Email: ibrahimi.is... at gmail.com

I apologise preemptively if this reply messes up the formatting.

Hi Khaled

If your data has a lot of (possibly correlated) parameters, then I would
suggest to look at ade4. 

The main tool behind this package is Principal Component Analysis (PCA) and
although aimed at ecological data, there are specific applications to
agronomical contexts, such as: soil and leaf analyses; market price analyses
or yield analyses; dimensionality reduction of the weather component; and
several other types of possible agronomy related data contexts.

There are other packages for PCA as well, but I don't think they were
specifically aimed at a biological context.

If you are looking for specific papers on this, I would recommend as a
starting point any paper by Patrice Cadet. Or, if you have specific
questions, you are welcome to ask me.

Best regards
Phillip

Phillip-Jan van Zyl
MSc (Category Theory)


From tri@podd@r19 @ending from gm@il@com  Thu Jun 28 11:45:12 2018
From: tri@podd@r19 @ending from gm@il@com (Triparna Poddar)
Date: Thu, 28 Jun 2018 15:15:12 +0530
Subject: [R] CARET PACKAGE - PENALISED MULTINOMIAL REGRESSION MODEL
Message-ID: <CAOQsHG+bZrxoQSFO=F8DpwKr_nrtEGP3sqzskuSN==H6BDf5Gw@mail.gmail.com>

Hi,
     In the Caret package, in one of the training model method for
classification , penalised multinomial regression has been used? I could
not find anywhere how the penalised parameters have been chosen here . I
need the statistical methods that have been used. Can someone please help
me?

Thanks in advance.

	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @ending from gm@il@com  Thu Jun 28 15:24:42 2018
From: @t@t@@@tudent4647 @ending from gm@il@com (Stats Student)
Date: Thu, 28 Jun 2018 06:24:42 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <CAGxFJbQez+SMgH_PP-qfjK2Y54TojdGRdF_Qye_Gg1WvMzraJw@mail.gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
 <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
 <CAGxFJbQez+SMgH_PP-qfjK2Y54TojdGRdF_Qye_Gg1WvMzraJw@mail.gmail.com>
Message-ID: <CAMZO7w+Khpqa=ohXffTad6VmJ8c_os2xUnAvBwPO7wy5XTCpig@mail.gmail.com>

Didn't know about linesGrob(). Thanks



On Wed, Jun 27, 2018, 4:38 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> "Considering that there are ways to add text on a page through textGrobs.."
>
> ... and the linesGrob() function would do the same for lines, no?
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Jun 27, 2018 at 3:56 PM, Stats Student <
> stats.student4647 at gmail.com> wrote:
>
>> Thanks, Jeff. The Task View page was very informative.
>>
>> To answer your question, I'm using ggplot to generate my plots and
>> grid/gridExtra/gtable to place those plots on a page.
>>
>> Considering that there are ways to add text on a page through textGrobs,
>> independent of the plots, I was wondering if there was a similar
>> functionality for adding lines. Also noticed a package called pagenum for
>> adding page numbers.
>>
>> knitr is certainly interesting, but might be an overkill for what I am
>> trying to do (creating basic multipage reports with basic headers,
>> footers).
>>
>>
>>
>>
>> On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <
>> jdnewmil at dcn.davis.ca.us> wrote:
>> >That would depend how you are generating the page... plots alone don't
>> >really have such options. If you don't know what this means then I
>> >suggest you read the Reproducible Research Task View [1]. knitr in
>> >conjunction with LaTeX (Rnw files) is very powerful, but there are many
>> >other tools as well (e.g. bookdown) depending on your preferences.
>> >
>> >[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
>> >
>> >On June 27, 2018 1:53:58 PM PDT, Stats Student
>> ><stats.student4647 at gmail.com> wrote:
>> >>Hi, I'm looking for a way to add lines to a report. To be clear, I
>> >>don't want to add lines to any specific plot, but instead to add
>> >>line(s) to the page itself - e.g. add a line to the footer area, above
>> >>the actual footer text.
>> >>
>> >>Any thoughts on how to do this? Many thanks.
>> >>
>> >>______________________________________________
>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>PLEASE do read the posting guide
>> >>http://www.R-project.org/posting-guide.html
>> >>and provide commented, minimal, self-contained, reproducible code.
>> >
>> >--
>> >Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]


From jtelleri@@rproject @ending from gm@il@com  Thu Jun 28 18:52:17 2018
From: jtelleri@@rproject @ending from gm@il@com (Juan Telleria Ruiz de Aguirre)
Date: Thu, 28 Jun 2018 18:52:17 +0200
Subject: [R] parallel computing in r....
In-Reply-To: <9479A978-896B-45F4-8DBF-C769B8BEFAF4@dcn.davis.ca.us>
References: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <9479A978-896B-45F4-8DBF-C769B8BEFAF4@dcn.davis.ca.us>
Message-ID: <CAJXDcw1G6WKuZvzZiOky+9r4v4UtYpT-zS=Os_rMu0dY6_OyAw@mail.gmail.com>

Maybe this R-bloggers post could also help you:

https://www.google.es/amp/s/www.r-bloggers.com/implementing-parallel-processing-in-r/amp/

https://www.google.es/amp/s/www.r-bloggers.com/a-guide-to-parallelism-in-r/amp/

	[[alternative HTML version deleted]]


From jtelleri@@rproject @ending from gm@il@com  Thu Jun 28 19:01:55 2018
From: jtelleri@@rproject @ending from gm@il@com (Juan Telleria Ruiz de Aguirre)
Date: Thu, 28 Jun 2018 19:01:55 +0200
Subject: [R] Trouble with tibbles
In-Reply-To: <1387723f-be10-5b3d-4047-5cc03041786e@utoronto.ca>
References: <1387723f-be10-5b3d-4047-5cc03041786e@utoronto.ca>
Message-ID: <CAJXDcw04hjiH8NEzdH+oMDBgNoz2Li3YhcQniH4Hwo+T0C8W8g@mail.gmail.com>

Factor Data Type, indeed, is of typeof() Numeric.

Try converting that column to character with as.character()

Class transformation then must work :)

Juan

	[[alternative HTML version deleted]]


From tonight@thenight @ending from gm@il@com  Thu Jun 28 19:58:13 2018
From: tonight@thenight @ending from gm@il@com (Sam Albers)
Date: Thu, 28 Jun 2018 10:58:13 -0700
Subject: [R] Unable to return gmtoff from as.POSIXlt without converting date
 string to as.POSIXct first
Message-ID: <CADkXsV1=k28MhK9tGW7on3FnTfGSUjiwc3GJTD9HAxznCE3N1A@mail.gmail.com>

Is it possible for someone to explain what is going on here? I would expect
that `as.POSIXlt` would be able to accept `datestring` and return all the
elements without having to convert it using `as.POSIXct` first. Do
`as.POSIXlt` and `as.POSIXct` do different things with the `tz` arg?

datestring <- "2017-01-01 12:00:00"
foo <- as.POSIXlt(datestring, tz = "America/Moncton")
foo
[1] "2017-01-01 12:00:00 AST"
foo$gmtoff
[1] NA

bar <- as.POSIXlt(as.POSIXct(datestring, tz = "America/Moncton"))
bar
[1] "2017-01-01 12:00:00 AST"
bar$gmtoff
[1] -14400

Thanks in advance,

Sam

	[[alternative HTML version deleted]]


From kekwu @ending from ucd@vi@@edu  Thu Jun 28 21:53:44 2018
From: kekwu @ending from ucd@vi@@edu (Kelly Wu)
Date: Thu, 28 Jun 2018 12:53:44 -0700
Subject: [R] trouble with exiting loop if condition is met
Message-ID: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>

I am working on a clinical trial simulation with two groups, treatment and
placebo, and the outcome is dichotomous (recovery or no recovery) . I would
like to stop my loop if either of my conditions are met:

1) futility - there are no responses to treatment in the treatment group.
2) the p-value is significant (<=0.01).

The problem I am having is my loop continues to run 10,000 times even though
I am sure that at least one of the conditions are met in some instances. It
appears the main problem is that my if loop is not adequately filtering the
conditions I specified in it.

library(magrittr)
library(dplyr)

nSims <- 10000 #number of simulated experiments
futility1 <-numeric(nSims) #set up empty container for all simulated
futility
futility2 <-numeric(nSims) #set up empty container for all simulated
futility

significant1 <-numeric(nSims) #set up empty container for all simulated
significance
significant2 <-numeric(nSims) #set up empty container for all simulated
significance

for(i in 1:nSims){ #for each simulated experiment
 # Year 1

 # p1<-response in controls
 # p2<-response in treated
 # Generating random deviates from a Uniform(0,1) distribution
 control.year1<-(runif(16, min = 0, max = 1))
 treat.year1<-(runif(16, min = 0, max = 1))

 #Generating dichotomous response variables for each group
 control.respond1<-ifelse(control.year1<=0.05,1,0)
 treat.respond1<-ifelse(treat.year1<=0.30,1,0)

 #Summing number of responses from each group
 control.no1<-sum(control.respond1==0)
 control.yes1<-sum(control.respond1==1)
 treat.no1<-sum(treat.respond1==0)
 treat.yes1<-sum(treat.respond1==1)

 #Perform the Fisher's exact test (one sided) with p<0.01

fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
 f<-fisher.test(fisher,alternative = "greater") 

 #year 2
 if (f$p.value>0.01 && treat.yes1!=0){
   # Generating random deviates from a Uniform(0,1) distribution
   control.year2<-(runif(16, min = 0, max = 1))
   treat.year2<-(runif(16, min = 0, max = 1))

   #Generating dichotomous response variables for each group
   control.respond2<-ifelse(control.year2<=0.05,1,0)
   treat.respond2<-ifelse(treat.year2<=0.30,1,0)

   #Summing number of responses from each group
   control.no2<-sum(control.respond2==0)
   control.yes2<-sum(control.respond2==1)
   treat.no2<-sum(treat.respond2==0)
   treat.yes2<-sum(treat.respond2==1)

   #Perform the Fisher's exact test (one sided) with p<0.01

fisher2<-matrix(c(control.no2,control.yes2,treat.no2,treat.yes2),nrow=2,ncol=2)
   f2<-fisher.test(fisher2,alternative = "greater") 
 }


 significant2[i]<-ifelse(f2$p.value<0.01,1,0)
 futility2[i]<-ifelse(treat.yes2==0,1,0)
}

table(significant1)
table(futility1)

table(significant2)
table(futility2)


From reichm@nj @ending from @bcglob@l@net  Thu Jun 28 23:29:19 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Thu, 28 Jun 2018 16:29:19 -0500
Subject: [R] Plot Rect Transparency
Message-ID: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>

R-Help

 

Is there a way to make a rectangle transparent (alpha=0.1??)

 

  plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")

   rect(110, 300, 175, 350, density = 5, border = "red")

 

Can't figure out how to take the changepoint function results and plot in
ggplot2 so I can just simply add rectangles to the plot function, but I need
to make transparent and there doesn't seem to be an alpha option.

 

Jeff


	[[alternative HTML version deleted]]


From m@cqueen1 @ending from llnl@gov  Thu Jun 28 23:45:52 2018
From: m@cqueen1 @ending from llnl@gov (MacQueen, Don)
Date: Thu, 28 Jun 2018 21:45:52 +0000
Subject: [R] trouble with exiting loop if condition is met
In-Reply-To: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
References: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
Message-ID: <A3B1205D-BA6B-4DB8-A15F-B5FAF923F68A@llnl.gov>

Does this example help?

> for (ii in 1:10) { cat( ii,'\n') ; if (ii >3) break }
1 
2 
3 
4

The loop won't stop unless you tell it to stop, and I don't see any place where you told it to stop.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/28/18, 12:53 PM, "R-help on behalf of Kelly Wu" <r-help-bounces at r-project.org on behalf of kekwu at ucdavis.edu> wrote:

    I am working on a clinical trial simulation with two groups, treatment and
    placebo, and the outcome is dichotomous (recovery or no recovery) . I would
    like to stop my loop if either of my conditions are met:
    
    1) futility - there are no responses to treatment in the treatment group.
    2) the p-value is significant (<=0.01).
    
    The problem I am having is my loop continues to run 10,000 times even though
    I am sure that at least one of the conditions are met in some instances. It
    appears the main problem is that my if loop is not adequately filtering the
    conditions I specified in it.
    
    library(magrittr)
    library(dplyr)
    
    nSims <- 10000 #number of simulated experiments
    futility1 <-numeric(nSims) #set up empty container for all simulated
    futility
    futility2 <-numeric(nSims) #set up empty container for all simulated
    futility
    
    significant1 <-numeric(nSims) #set up empty container for all simulated
    significance
    significant2 <-numeric(nSims) #set up empty container for all simulated
    significance
    
    for(i in 1:nSims){ #for each simulated experiment
     # Year 1
    
     # p1<-response in controls
     # p2<-response in treated
     # Generating random deviates from a Uniform(0,1) distribution
     control.year1<-(runif(16, min = 0, max = 1))
     treat.year1<-(runif(16, min = 0, max = 1))
    
     #Generating dichotomous response variables for each group
     control.respond1<-ifelse(control.year1<=0.05,1,0)
     treat.respond1<-ifelse(treat.year1<=0.30,1,0)
    
     #Summing number of responses from each group
     control.no1<-sum(control.respond1==0)
     control.yes1<-sum(control.respond1==1)
     treat.no1<-sum(treat.respond1==0)
     treat.yes1<-sum(treat.respond1==1)
    
     #Perform the Fisher's exact test (one sided) with p<0.01
    
    fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
     f<-fisher.test(fisher,alternative = "greater") 
    
     #year 2
     if (f$p.value>0.01 && treat.yes1!=0){
       # Generating random deviates from a Uniform(0,1) distribution
       control.year2<-(runif(16, min = 0, max = 1))
       treat.year2<-(runif(16, min = 0, max = 1))
    
       #Generating dichotomous response variables for each group
       control.respond2<-ifelse(control.year2<=0.05,1,0)
       treat.respond2<-ifelse(treat.year2<=0.30,1,0)
    
       #Summing number of responses from each group
       control.no2<-sum(control.respond2==0)
       control.yes2<-sum(control.respond2==1)
       treat.no2<-sum(treat.respond2==0)
       treat.yes2<-sum(treat.respond2==1)
    
       #Perform the Fisher's exact test (one sided) with p<0.01
    
    fisher2<-matrix(c(control.no2,control.yes2,treat.no2,treat.yes2),nrow=2,ncol=2)
       f2<-fisher.test(fisher2,alternative = "greater") 
     }
    
    
     significant2[i]<-ifelse(f2$p.value<0.01,1,0)
     futility2[i]<-ifelse(treat.yes2==0,1,0)
    }
    
    table(significant1)
    table(futility1)
    
    table(significant2)
    table(futility2)
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Jun 29 00:16:30 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Thu, 28 Jun 2018 15:16:30 -0700
Subject: [R] 
 Unable to return gmtoff from as.POSIXlt without converting date
 string to as.POSIXct first
In-Reply-To: <CADkXsV1=k28MhK9tGW7on3FnTfGSUjiwc3GJTD9HAxznCE3N1A@mail.gmail.com>
References: <CADkXsV1=k28MhK9tGW7on3FnTfGSUjiwc3GJTD9HAxznCE3N1A@mail.gmail.com>
Message-ID: <A78DF603-7F6C-4445-AC81-71DC7A0E2777@dcn.davis.ca.us>

Read

?DateTimeClasses

regarding gmtoff. In short, it is implementation-dependent.

On June 28, 2018 10:58:13 AM PDT, Sam Albers <tonightsthenight at gmail.com> wrote:
>Is it possible for someone to explain what is going on here? I would
>expect
>that `as.POSIXlt` would be able to accept `datestring` and return all
>the
>elements without having to convert it using `as.POSIXct` first. Do
>`as.POSIXlt` and `as.POSIXct` do different things with the `tz` arg?
>
>datestring <- "2017-01-01 12:00:00"
>foo <- as.POSIXlt(datestring, tz = "America/Moncton")
>foo
>[1] "2017-01-01 12:00:00 AST"
>foo$gmtoff
>[1] NA
>
>bar <- as.POSIXlt(as.POSIXct(datestring, tz = "America/Moncton"))
>bar
>[1] "2017-01-01 12:00:00 AST"
>bar$gmtoff
>[1] -14400
>
>Thanks in advance,
>
>Sam
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From drjimlemon @ending from gm@il@com  Fri Jun 29 00:18:41 2018
From: drjimlemon @ending from gm@il@com (Jim Lemon)
Date: Fri, 29 Jun 2018 08:18:41 +1000
Subject: [R] trouble with exiting loop if condition is met
In-Reply-To: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
References: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
Message-ID: <CA+8X3fXg4B3cuyHv4wAJGPjgoFCNymptBH5Sn+z2Dy7_VXCRDg@mail.gmail.com>

Hi Kelly,
You seem to be testing the two "years" independently, so here is a
possible solution:

npg<-16
futility1<-futility2<-psignif1<-psignif2<-nrep<-0
while(!futility1 && !futility2 && !psignif1 && !psignif2 && nrep < 10000) {
 control_respond1<-sum(runif(npg,0,1) < 0.05)
 control_respond2<-sum(runif(npg,0,1) < 0.05)
 treat_respond1<-sum(runif(npg,0,1) < 0.3)
 treat_respond2<-sum(runif(npg,0,1) < 0.3)
 futility1<-treat_respond1 == 0
 futility2<-treat_respond2 == 0
 psignif1<-fisher.test(matrix(c(control_respond1,npg-control_respond1,
  treat_respond1,npg-treat_respond1),nrow=2),
  alternative="greater")$p.value < 0.01
 psignif2<-fisher.test(matrix(c(control_respond2,npg-control_respond2,
  treat_respond2,npg-treat_respond2),nrow=2),
  alternative="greater")$p.value < 0.01
 nrep<-nrep+1
}
cat("futility1",futility1,"futility2",futility2,"psignif1",psignif1,
 "psignif2",psignif2,"nrep",nrep,"\n")

The output tells you which condition was met and on which repetition
it occurred. The outcomes for all previous repetitions will be FALSE
and for the remaining repetitions, undefined (unless you have a cat
named Schrodinger)..

If you want to test the two "years" as sequential observations, it
will only require a minor modification.

Jim

On Fri, Jun 29, 2018 at 5:53 AM, Kelly Wu <kekwu at ucdavis.edu> wrote:
> I am working on a clinical trial simulation with two groups, treatment and
> placebo, and the outcome is dichotomous (recovery or no recovery) . I would
> like to stop my loop if either of my conditions are met:
>
> 1) futility - there are no responses to treatment in the treatment group.
> 2) the p-value is significant (<=0.01).
>
> The problem I am having is my loop continues to run 10,000 times even though
> I am sure that at least one of the conditions are met in some instances. It
> appears the main problem is that my if loop is not adequately filtering the
> conditions I specified in it.
>
> library(magrittr)
> library(dplyr)
>
> nSims <- 10000 #number of simulated experiments
> futility1 <-numeric(nSims) #set up empty container for all simulated
> futility
> futility2 <-numeric(nSims) #set up empty container for all simulated
> futility
>
> significant1 <-numeric(nSims) #set up empty container for all simulated
> significance
> significant2 <-numeric(nSims) #set up empty container for all simulated
> significance
>
> for(i in 1:nSims){ #for each simulated experiment
>  # Year 1
>
>  # p1<-response in controls
>  # p2<-response in treated
>  # Generating random deviates from a Uniform(0,1) distribution
>  control.year1<-(runif(16, min = 0, max = 1))
>  treat.year1<-(runif(16, min = 0, max = 1))
>
>  #Generating dichotomous response variables for each group
>  control.respond1<-ifelse(control.year1<=0.05,1,0)
>  treat.respond1<-ifelse(treat.year1<=0.30,1,0)
>
>  #Summing number of responses from each group
>  control.no1<-sum(control.respond1==0)
>  control.yes1<-sum(control.respond1==1)
>  treat.no1<-sum(treat.respond1==0)
>  treat.yes1<-sum(treat.respond1==1)
>
>  #Perform the Fisher's exact test (one sided) with p<0.01
>
> fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
>  f<-fisher.test(fisher,alternative = "greater")
>
>  #year 2
>  if (f$p.value>0.01 && treat.yes1!=0){
>    # Generating random deviates from a Uniform(0,1) distribution
>    control.year2<-(runif(16, min = 0, max = 1))
>    treat.year2<-(runif(16, min = 0, max = 1))
>
>    #Generating dichotomous response variables for each group
>    control.respond2<-ifelse(control.year2<=0.05,1,0)
>    treat.respond2<-ifelse(treat.year2<=0.30,1,0)
>
>    #Summing number of responses from each group
>    control.no2<-sum(control.respond2==0)
>    control.yes2<-sum(control.respond2==1)
>    treat.no2<-sum(treat.respond2==0)
>    treat.yes2<-sum(treat.respond2==1)
>
>    #Perform the Fisher's exact test (one sided) with p<0.01
>
> fisher2<-matrix(c(control.no2,control.yes2,treat.no2,treat.yes2),nrow=2,ncol=2)
>    f2<-fisher.test(fisher2,alternative = "greater")
>  }
>
>
>  significant2[i]<-ifelse(f2$p.value<0.01,1,0)
>  futility2[i]<-ifelse(treat.yes2==0,1,0)
> }
>
> table(significant1)
> table(futility1)
>
> table(significant2)
> table(futility2)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


From murdoch@dunc@n @ending from gm@il@com  Fri Jun 29 02:57:19 2018
From: murdoch@dunc@n @ending from gm@il@com (Duncan Murdoch)
Date: Thu, 28 Jun 2018 20:57:19 -0400
Subject: [R] Plot Rect Transparency
In-Reply-To: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
References: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
Message-ID: <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>

On 28/06/2018 5:29 PM, Jeff Reichman wrote:
> R-Help
> 
>   
> 
> Is there a way to make a rectangle transparent (alpha=0.1??)
> 
>   
> 
>    plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")
> 
>     rect(110, 300, 175, 350, density = 5, border = "red")
> 
>   
> 
> Can't figure out how to take the changepoint function results and plot in
> ggplot2 so I can just simply add rectangles to the plot function, but I need
> to make transparent and there doesn't seem to be an alpha option.

Alpha is part of the colour spec.  For example,

rect(110, 300, 175, 350, density = 5, border = rgb("red")


rect(110, 300, 175, 350, density = 5, border = rgb(red=1, green=0, 
blue=0, alpha=0.1))

I'm not sure what is the quickest way to work out the rgb values for a 
named colour (col2rgb can do it, but not in a convenient format) if you 
want to add alpha to it.

Duncan Murdoch


From reichm@nj @ending from @bcglob@l@net  Fri Jun 29 04:03:31 2018
From: reichm@nj @ending from @bcglob@l@net (Jeff Reichman)
Date: Thu, 28 Jun 2018 21:03:31 -0500
Subject: [R] Plot Rect Transparency
In-Reply-To: <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
References: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
 <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
Message-ID: <000a01d40f4d$617d3140$247793c0$@sbcglobal.net>

Duncan 

Thanks I was able to find it in the help doc.

x <- c(1,2,4,6,8,9,10,12,13,14,18,20)
y <- c(4,5,3,6,7,4,8,9,12,4,7,5)

mydata <- data.frame(x,y)

plot(mydata)
rect(5,0,8,8, col=rgb(0,1,0,alpha=0.2), border=F)

-----Original Message-----
From: Duncan Murdoch <murdoch.duncan at gmail.com> 
Sent: Thursday, June 28, 2018 7:57 PM
To: reichmanj at sbcglobal.net; R-help at r-project.org
Subject: Re: [R] Plot Rect Transparency

On 28/06/2018 5:29 PM, Jeff Reichman wrote:
> R-Help
> 
>   
> 
> Is there a way to make a rectangle transparent (alpha=0.1??)
> 
>   
> 
>    plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")
> 
>     rect(110, 300, 175, 350, density = 5, border = "red")
> 
>   
> 
> Can't figure out how to take the changepoint function results and plot 
> in
> ggplot2 so I can just simply add rectangles to the plot function, but 
> I need to make transparent and there doesn't seem to be an alpha option.

Alpha is part of the colour spec.  For example,

rect(110, 300, 175, 350, density = 5, border = rgb("red")


rect(110, 300, 175, 350, density = 5, border = rgb(red=1, green=0, blue=0, alpha=0.1))

I'm not sure what is the quickest way to work out the rgb values for a named colour (col2rgb can do it, but not in a convenient format) if you want to add alpha to it.

Duncan Murdoch


From ir@@h@renow100 @ending from y@hoo@com  Fri Jun 29 08:36:23 2018
From: ir@@h@renow100 @ending from y@hoo@com (Ira Sharenow)
Date: Thu, 28 Jun 2018 23:36:23 -0700
Subject: [R] Convert list of data frames to one data frame
Message-ID: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>

I have a list of data frames which I would like to combine into one data 
frame doing something like rbind. I wish to combine in column order and 
not by names. However, there are issues.

The number of columns is not the same for each data frame. This is an 
intermediate step to a problem and the number of columns could be 
2,4,6,8,or10. There might be a few thousand data frames. Another problem 
is that the names of the columns produced by the first step are garbage.

Below is a method that I obtained by asking a question on stack 
overflow. Unfortunately, my example was not general enough. The code 
below works for the simple case where the names of the people are 
consistent. It does not work when the names are realistically not the same.

https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432 


Please note that the lapply step sets things up except for the column 
name issue. If I could figure out a way to change the column names, then 
the bind_rows step will, I believe, work.

So I really have two questions. How to change all column names of all 
the data frames and then how to solve the original problem.

# The non general case works fine. It produces one data frame and I can 
then change the column names to

# c("first1", "last1","first2", "last2","first3", "last3",)

#Non general easy case

employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),

data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),

data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones", 
"Smith", "Adams")),

data.frame(first1 = ("Al"), second1 = "Jones"))

employees4BList

bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))

# This produces a nice list of data frames, except for the names

lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))

# This list is a disaster. I am looking for a solution that works in 
this case.

employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),

data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),

data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", 
"Smith", "Adams")),

data.frame(first4 = ("Al"), second4 = "Jones2"))

 ?bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))

Thanks.

Ira


	[[alternative HTML version deleted]]


From ml@thouri @ending from y@hoo@gr  Fri Jun 29 12:01:37 2018
From: ml@thouri @ending from y@hoo@gr (Maria Lathouri)
Date: Fri, 29 Jun 2018 10:01:37 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6IHgtYXhpcyB0aWNrIG1hcmtzIGxlbmd0aCBp?=
 =?utf-8?q?n_ggplot2?=
In-Reply-To: <CALe7saLmjnDtGoJ6go6NB+NGx82RLNsTWwCdF9uZmh6sHyLLQw@mail.gmail.com>
References: <1894507928.4864388.1530116258439.ref@mail.yahoo.com>
 <1894507928.4864388.1530116258439@mail.yahoo.com>
 <CA+-dKdONv8Y+pWH42RU47YVccmtU_HOBAEnTkowdzUggjmi87g@mail.gmail.com>
 <624069206.5599815.1530185883999@mail.yahoo.com>
 <8316569.5602775.1530186534961@mail.yahoo.com>
 <CALe7saLmjnDtGoJ6go6NB+NGx82RLNsTWwCdF9uZmh6sHyLLQw@mail.gmail.com>
Message-ID: <1078453055.282011.1530266497799@mail.yahoo.com>

Dear Walter,?
I tried to use scale_x_continuous but the arguments that I found was to change the labels, the limits and the breaks. I was only able to increase the number of the tick marks.?
Best,Maria 

    ???? 3:14 ?.?. ??????, 28 ??????? 2018, ?/? Walter Pina <walter.pina1954 at gmail.com> ??????:
 

 Dear Maria, you are totally right!
Did you tried the scale_x_continuous function and its arguments?
RegardsWalter
2018-06-28 8:48 GMT-03:00 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com>:

Dear Abhimanyu, 

If I am not mistaken, this online help is to post questions, and if possible, these questions to be answered. NOT for sarcastic and insulting posts. You could have just easily ignored my question. So simple. ? ? 

Kind regards,Maria 

    ???? 12:38 ?.?. ??????, 28 ??????? 2018, ?/? Maria Lathouri <mlathouri at yahoo.gr> ??????:
 

 I am sorry but I didn't get your point. And I am not new in data science!!

Maria 

    ???? 11:38 ?.?. ??????, 28 ??????? 2018, ?/? Abhimanyu Khatry <khatryabhimanyu at gmail.com> ??????:
 

 How a beginner can get started on ggplot ? Is it right to start this if someone is new to data science ?
On Wed, Jun 27, 2018 at 9:47 PM, 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com> wrote:

Dear all, 


I would like to ask if there is a way to increase the length of the tick marks on the x-axis only. 


I got the code:

p+ theme(axis.ticks.length=unit(. 30, "cm"))

but this increases the length for both x and y axis; whereas, I would like only on x-axis. 


Thank you very much in advance. 


Kind regards,
Maria

-- 
-- 
You received this message because you are subscribed to the ggplot2 mailing list.
Please provide a reproducible example: https://github.com/hadley/ devtools/wiki/Reproducibility

To post: email ggplot2 at googlegroups.com
To unsubscribe: email ggplot2+unsubscribe@ googlegroups.com
More options: http://groups.google.com/ group/ggplot2

--- 
You received this message because you are subscribed to the Google Groups "ggplot2" group.
To unsubscribe from this group and stop receiving emails from it, send an email to ggplot2+unsubscribe@ googlegroups.com.
For more options, visit https://groups.google.com/d/ optout.


-- 
-- 
You received this message because you are subscribed to the ggplot2 mailing list.
Please provide a reproducible example: https://github.com/hadley/ devtools/wiki/Reproducibility
?
To post: email ggplot2 at googlegroups.com
To unsubscribe: email ggplot2+unsubscribe@ googlegroups.com
More options: http://groups.google.com/ group/ggplot2

--- 
You received this message because you are subscribed to the Google Groups "ggplot2" group.
To unsubscribe from this group and stop receiving emails from it, send an email to ggplot2+unsubscribe@ googlegroups.com.
For more options, visit https://groups.google.com/d/ optout.


   

   -- 
-- 
You received this message because you are subscribed to the ggplot2 mailing list.
Please provide a reproducible example: https://github.com/hadley/ devtools/wiki/Reproducibility
?
To post: email ggplot2 at googlegroups.com
To unsubscribe: email ggplot2+unsubscribe@ googlegroups.com
More options: http://groups.google.com/ group/ggplot2

--- 
You received this message because you are subscribed to the Google Groups "ggplot2" group.
To unsubscribe from this group and stop receiving emails from it, send an email to ggplot2+unsubscribe@ googlegroups.com.
For more options, visit https://groups.google.com/d/ optout.




   
	[[alternative HTML version deleted]]


From berwin@turl@ch @ending from gm@il@com  Fri Jun 29 12:29:25 2018
From: berwin@turl@ch @ending from gm@il@com (Berwin A Turlach)
Date: Fri, 29 Jun 2018 18:29:25 +0800
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
 <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>
Message-ID: <20180629182925.4606e7be@goodenia>

G'day Maija,

On Wed, 27 Jun 2018 08:48:08 +0300
Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:

> Thanks for your reply! Unfortunately something is still wrong.
> 
> After the transpose, dvec and Amat are still incompatible.
> 
> > d <- -hsmooth
> > dvec <- t(d)
> > c <- dvec*Amat  
> Error in dvec * Amat : non-conformable arrays

'*' in R is element-wise multiplication and '%*%' implements
matrix/matrix (matrix/vector) multiplication as defined in matrix
algebra.  I presume you want to use the latter operator here.

> Moreover, I don't understand the following:
> 
> > If dvec is of length *J*, then b will be of length J too.  
> 
> I believe the length of dvec comes from the number of variables and
> the length of b from the number of constraints. In this case they are
> not equal.

As I said:

> > solve.QP solves the quadratic program:
> >          min(-d^T b + 1/2 b^T D b)
> >    where A^T b >= b_0.

The minimisation is with respect to b.

Note that the objective function contains the inner product of d
(passed to dvec) and b, so d and b must have the same
dimension/length.  b contains the parameters/variables over which you
want to minimise.  b_0 (passed to bvec) depends on the number of
constraints.

Cheers,

	Berwin


From @k@h@y_e4 @ending from hotm@il@com  Fri Jun 29 13:19:40 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Fri, 29 Jun 2018 11:19:40 +0000
Subject: [R] inconsistency in list subsetting in R in linux
Message-ID: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                           I am using GNU R(R in linux CLI). I am trying to debug a function called "grand.finalelPf". In the function the following line appears

> yhpf2 <- mclapply(LYG2[-w], fun = forecast, h = 1)

I execute the above line in browse[2] prompt. I then type the following:
Browse[2] > length(yhpf2)

It also is getting executed with the following output:
[1] 464

But when I type this:
Browse[2] > yhpf2[[3]]

the ouput is this:

[1] "Error in lapply(X = S, FUN = FUN, ...) : \n  argument \"FUN\" is missing, with no default\n"
attr(,"class")
[1] "try-error"
attr(,"condition")
<simpleError in lapply(X = S, FUN = FUN, ...): argument "FUN" is missing, with no default>
Browse[2] >

why is this getting outputted instead of a value? Even if all the yhpf's are NULL, the above is output is weird.

What is wrong? Why would the output relate to lapply? If the culprit was mclapply, then why does the line get executed without an error message? The same function is working perfectly well in windows(I used parLapply instead of mclapply).
Is this peculiar to R on Linux? Please help....

very many thanks for your time and effort,
Yours sincerely,
AKSHAY M KULKARNI


	[[alternative HTML version deleted]]


From wdunl@p @ending from tibco@com  Fri Jun 29 15:51:36 2018
From: wdunl@p @ending from tibco@com (William Dunlap)
Date: Fri, 29 Jun 2018 06:51:36 -0700
Subject: [R] inconsistency in list subsetting in R in linux
In-Reply-To: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcbNuG4ah_2+-jy45R4U6fmnNN+24+Xcjs87OYB+ePd8Dg@mail.gmail.com>

> args(parallel::mclapply)
function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,
    mc.silent = FALSE, mc.cores = 1L, mc.cleanup = TRUE, mc.allow.recursive
= TRUE)

You gave it 'fun=forecast' instead of 'FUN=forecast'.  Case matters in R.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 29, 2018 at 4:19 AM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                            I am using GNU R(R in linux CLI). I am trying
> to debug a function called "grand.finalelPf". In the function the following
> line appears
>
> > yhpf2 <- mclapply(LYG2[-w], fun = forecast, h = 1)
>
> I execute the above line in browse[2] prompt. I then type the following:
> Browse[2] > length(yhpf2)
>
> It also is getting executed with the following output:
> [1] 464
>
> But when I type this:
> Browse[2] > yhpf2[[3]]
>
> the ouput is this:
>
> [1] "Error in lapply(X = S, FUN = FUN, ...) : \n  argument \"FUN\" is
> missing, with no default\n"
> attr(,"class")
> [1] "try-error"
> attr(,"condition")
> <simpleError in lapply(X = S, FUN = FUN, ...): argument "FUN" is missing,
> with no default>
> Browse[2] >
>
> why is this getting outputted instead of a value? Even if all the yhpf's
> are NULL, the above is output is weird.
>
> What is wrong? Why would the output relate to lapply? If the culprit was
> mclapply, then why does the line get executed without an error message? The
> same function is working perfectly well in windows(I used parLapply instead
> of mclapply).
> Is this peculiar to R on Linux? Please help....
>
> very many thanks for your time and effort,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Fri Jun 29 16:02:40 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 29 Jun 2018 07:02:40 -0700
Subject: [R] inconsistency in list subsetting in R in linux
In-Reply-To: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <BA6D202C-C55F-4AF0-B848-BD2725157167@dcn.davis.ca.us>

Read the Value section of ?mclapply. That error is an encapsulated error from the forecast function.

I suggest not debugging your code running in parallel... temporarily replace mclapply with lapply to debug so you can step into your worker fictions. You may also want to temporarily reduce the volume of data you are working with.

On June 29, 2018 4:19:40 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>I am using GNU R(R in linux CLI). I am trying to debug a function
>called "grand.finalelPf". In the function the following line appears
>
>> yhpf2 <- mclapply(LYG2[-w], fun = forecast, h = 1)
>
>I execute the above line in browse[2] prompt. I then type the
>following:
>Browse[2] > length(yhpf2)
>
>It also is getting executed with the following output:
>[1] 464
>
>But when I type this:
>Browse[2] > yhpf2[[3]]
>
>the ouput is this:
>
>[1] "Error in lapply(X = S, FUN = FUN, ...) : \n  argument \"FUN\" is
>missing, with no default\n"
>attr(,"class")
>[1] "try-error"
>attr(,"condition")
><simpleError in lapply(X = S, FUN = FUN, ...): argument "FUN" is
>missing, with no default>
>Browse[2] >
>
>why is this getting outputted instead of a value? Even if all the
>yhpf's are NULL, the above is output is weird.
>
>What is wrong? Why would the output relate to lapply? If the culprit
>was mclapply, then why does the line get executed without an error
>message? The same function is working perfectly well in windows(I used
>parLapply instead of mclapply).
>Is this peculiar to R on Linux? Please help....
>
>very many thanks for your time and effort,
>Yours sincerely,
>AKSHAY M KULKARNI
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From @@r@h@go@lee @ending from gm@il@com  Fri Jun 29 16:28:50 2018
From: @@r@h@go@lee @ending from gm@il@com (Sarah Goslee)
Date: Fri, 29 Jun 2018 10:28:50 -0400
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
Message-ID: <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>

Hi,

It isn't super clear to me what you're after. Is this what you intend?

> dfbycol(employees4BList)
  first1 last1 first2 last2 first3 last3
1     Al Jones   <NA>  <NA>   <NA>  <NA>
2     Al Jones   Barb Smith   <NA>  <NA>
3     Al Jones   Barb Smith  Carol Adams
4     Al Jones   <NA>  <NA>   <NA>  <NA>
>
> dfbycol(employees4List)
  first1  last1  first2 last2 first3 last3
1     Al  Jones    <NA>  <NA>   <NA>  <NA>
2    Al2  Jones    Barb Smith   <NA>  <NA>
3    Al3  Jones Barbara Smith  Carol Adams
4     Al Jones2    <NA>  <NA>   <NA>  <NA>


If so:

employees4BList = list(
data.frame(first1 = "Al", second1 = "Jones"),
data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
"Smith", "Adams")),
data.frame(first1 = ("Al"), second1 = "Jones"))

employees4List = list(
data.frame(first1 = ("Al"), second1 = "Jones"),
data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
"Smith", "Adams")),
data.frame(first4 = ("Al"), second4 = "Jones2"))

###

dfbycol <- function(x) {
  x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
  x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
  x <- do.call(rbind, x)
  x <- data.frame(x, stringsAsFactors=FALSE)
  colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
  x
}

###

dfbycol(employees4BList)

dfbycol(employees4List)

On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
<r-help at r-project.org> wrote:
> I have a list of data frames which I would like to combine into one data
> frame doing something like rbind. I wish to combine in column order and
> not by names. However, there are issues.
>
> The number of columns is not the same for each data frame. This is an
> intermediate step to a problem and the number of columns could be
> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
> is that the names of the columns produced by the first step are garbage.
>
> Below is a method that I obtained by asking a question on stack
> overflow. Unfortunately, my example was not general enough. The code
> below works for the simple case where the names of the people are
> consistent. It does not work when the names are realistically not the same.
>
> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>
>
> Please note that the lapply step sets things up except for the column
> name issue. If I could figure out a way to change the column names, then
> the bind_rows step will, I believe, work.
>
> So I really have two questions. How to change all column names of all
> the data frames and then how to solve the original problem.
>
> # The non general case works fine. It produces one data frame and I can
> then change the column names to
>
> # c("first1", "last1","first2", "last2","first3", "last3",)
>
> #Non general easy case
>
> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>
> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>
> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> "Smith", "Adams")),
>
> data.frame(first1 = ("Al"), second1 = "Jones"))
>
> employees4BList
>
> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>
> # This produces a nice list of data frames, except for the names
>
> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>
> # This list is a disaster. I am looking for a solution that works in
> this case.
>
> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>
> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>
> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> "Smith", "Adams")),
>
> data.frame(first4 = ("Al"), second4 = "Jones2"))
>
>   bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>
> Thanks.
>
> Ira
>

-- 
Sarah Goslee
http://www.functionaldiversity.org


From ld1083-r @ending from y@hoo@com  Fri Jun 29 15:41:19 2018
From: ld1083-r @ending from y@hoo@com (=?UTF-8?Q?J=C3=A9r=C3=B4me_Fran=C3=A7ois?=)
Date: Fri, 29 Jun 2018 13:41:19 +0000 (UTC)
Subject: [R] Plot multiple time series on a seasonal plot
References: <615332437.512512.1530279679993.ref@mail.yahoo.com>
Message-ID: <615332437.512512.1530279679993@mail.yahoo.com>

Dear members,

I would like to plot a second time series (a forecast) to a seasonal plot made with function seasonplot() from the package forecast.


Here is a reproducible example:
ts1 <- structure(c(112035, 111182, 111015, 109331, 107525, 107749, 111435, 
111629, 112462, 112256, 109496, 107917, 108221, 107463, 105960, 
103883, 101038, 100056, 101628, 102973, 103371, 102463, 100774, 
100718, 100471, 99828, 99365, 98521, 95695, 96443, 96287, 97525, 
98293, 98014, 96658, 96736, 96089, 95337, 95382, 92748, 91448, 
91560, 92996, 94046, 94128, 93888, 93888, 91091, 91877, 91681, 
91045, 89367, 87912), .Tsp = c(2014, 2018.33333333333, 12), class = "ts")

ts2 <- structure(c(87867.2152330971, 89713.0862474283, 89600.565347383, 
91066.3196835822, 90523.1926861474, 89322.8025396445, 88771.5545520503, 
89247.0913151542, 88803.5578121458, 88060.0948570082, 87015.6578227365, 
85785.4121532206), .Tsp = c(2018.41666666667, 2019.33333333333, 
12), class = "ts")


library(forecast)seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE)


How can I add ts2 to the seasonal plot? I would like it to be distinguishable from ts1 (e.g. different color).

lines(ts2) doesn't work.
Thank you.
Sincerely,

J?r?me


From ruipb@rr@d@@ @ending from @@po@pt  Fri Jun 29 19:33:11 2018
From: ruipb@rr@d@@ @ending from @@po@pt (Rui Barradas)
Date: Fri, 29 Jun 2018 18:33:11 +0100
Subject: [R] 
 =?utf-8?b?zqPPh861z4Q6IHgtYXhpcyB0aWNrIG1hcmtzIGxlbmd0aCBp?=
 =?utf-8?q?n_ggplot2?=
In-Reply-To: <1078453055.282011.1530266497799@mail.yahoo.com>
References: <1894507928.4864388.1530116258439.ref@mail.yahoo.com>
 <1894507928.4864388.1530116258439@mail.yahoo.com>
 <CA+-dKdONv8Y+pWH42RU47YVccmtU_HOBAEnTkowdzUggjmi87g@mail.gmail.com>
 <624069206.5599815.1530185883999@mail.yahoo.com>
 <8316569.5602775.1530186534961@mail.yahoo.com>
 <CALe7saLmjnDtGoJ6go6NB+NGx82RLNsTWwCdF9uZmh6sHyLLQw@mail.gmail.com>
 <1078453055.282011.1530266497799@mail.yahoo.com>
Message-ID: <99a81d2d-1e2d-f0df-8a28-7e70e1ed5322@sapo.pt>

Hello,

I don't believe what you want is possible because:

axis.ticks.x and axis.ticks.y change the width of the tick marks

axis.ticks.length changes the length but there is no x and y axis 
versions, just a general purpose one.

Sorry I couldn't be of much help,

Rui Barradas

?s 11:01 de 29-06-2018, Maria Lathouri via R-help escreveu:
> Dear Walter,
> I tried to use scale_x_continuous but the arguments that I found was to change the labels, the limits and the breaks. I was only able to increase the number of the tick marks.
> Best,Maria
> 
>      ???? 3:14 ?.?. ??????, 28 ??????? 2018, ?/? Walter Pina <walter.pina1954 at gmail.com> ??????:
>   
> 
>   Dear Maria, you are totally right!
> Did you tried the scale_x_continuous function and its arguments?
> RegardsWalter
> 2018-06-28 8:48 GMT-03:00 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com>:
> 
> Dear Abhimanyu,
> 
> If I am not mistaken, this online help is to post questions, and if possible, these questions to be answered. NOT for sarcastic and insulting posts. You could have just easily ignored my question. So simple.
> 
> Kind regards,Maria
> 
>      ???? 12:38 ?.?. ??????, 28 ??????? 2018, ?/? Maria Lathouri <mlathouri at yahoo.gr> ??????:
>   
> 
>   I am sorry but I didn't get your point. And I am not new in data science!!
> 
> Maria
> 
>      ???? 11:38 ?.?. ??????, 28 ??????? 2018, ?/? Abhimanyu Khatry <khatryabhimanyu at gmail.com> ??????:
>   
> 
>   How a beginner can get started on ggplot ? Is it right to start this if someone is new to data science ?
> On Wed, Jun 27, 2018 at 9:47 PM, 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com> wrote:
> 
> Dear all,
> 
> 
> I would like to ask if there is a way to increase the length of the tick marks on the x-axis only.
> 
> 
> I got the code:
> 
> p+ theme(axis.ticks.length=unit(. 30, "cm"))
> 
> but this increases the length for both x and y axis; whereas, I would like only on x-axis.
> 
> 
> Thank you very much in advance.
> 
> 
> Kind regards,
> Maria
>


From dwin@emiu@ @ending from comc@@t@net  Fri Jun 29 21:49:15 2018
From: dwin@emiu@ @ending from comc@@t@net (David Winsemius)
Date: Fri, 29 Jun 2018 12:49:15 -0700
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
Message-ID: <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>


> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi,
> 
> It isn't super clear to me what you're after.

Agree.

Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:

library(dplyr)
 newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) ) 
 bind_rows(newList)

#---------

   first1 second1
1      Al   Jones
2     Al2   Jones
3    Barb   Smith
4     Al3   Jones
5 Barbara   Smith
6   Carol   Adams
7      Al  Jones2

Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.

-- 
David.
> Is this what you intend?
> 
>> dfbycol(employees4BList)
>  first1 last1 first2 last2 first3 last3
> 1     Al Jones   <NA>  <NA>   <NA>  <NA>
> 2     Al Jones   Barb Smith   <NA>  <NA>
> 3     Al Jones   Barb Smith  Carol Adams
> 4     Al Jones   <NA>  <NA>   <NA>  <NA>
>> 
>> dfbycol(employees4List)
>  first1  last1  first2 last2 first3 last3
> 1     Al  Jones    <NA>  <NA>   <NA>  <NA>
> 2    Al2  Jones    Barb Smith   <NA>  <NA>
> 3    Al3  Jones Barbara Smith  Carol Adams
> 4     Al Jones2    <NA>  <NA>   <NA>  <NA>
> 
> 
> If so:
> 
> employees4BList = list(
> data.frame(first1 = "Al", second1 = "Jones"),
> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> "Smith", "Adams")),
> data.frame(first1 = ("Al"), second1 = "Jones"))
> 
> employees4List = list(
> data.frame(first1 = ("Al"), second1 = "Jones"),
> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> "Smith", "Adams")),
> data.frame(first4 = ("Al"), second4 = "Jones2"))
> 
> ###
> 
> dfbycol <- function(x) {
>  x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>  x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>  x <- do.call(rbind, x)
>  x <- data.frame(x, stringsAsFactors=FALSE)
>  colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>  x
> }
> 
> ###
> 
> dfbycol(employees4BList)
> 
> dfbycol(employees4List)
> 
> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
> <r-help at r-project.org> wrote:
>> I have a list of data frames which I would like to combine into one data
>> frame doing something like rbind. I wish to combine in column order and
>> not by names. However, there are issues.
>> 
>> The number of columns is not the same for each data frame. This is an
>> intermediate step to a problem and the number of columns could be
>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>> is that the names of the columns produced by the first step are garbage.
>> 
>> Below is a method that I obtained by asking a question on stack
>> overflow. Unfortunately, my example was not general enough. The code
>> below works for the simple case where the names of the people are
>> consistent. It does not work when the names are realistically not the same.
>> 
>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>> 
>> 
>> Please note that the lapply step sets things up except for the column
>> name issue. If I could figure out a way to change the column names, then
>> the bind_rows step will, I believe, work.
>> 
>> So I really have two questions. How to change all column names of all
>> the data frames and then how to solve the original problem.
>> 
>> # The non general case works fine. It produces one data frame and I can
>> then change the column names to
>> 
>> # c("first1", "last1","first2", "last2","first3", "last3",)
>> 
>> #Non general easy case
>> 
>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>> 
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> 
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>> 
>> employees4BList
>> 
>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>> 
>> # This produces a nice list of data frames, except for the names
>> 
>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>> 
>> # This list is a disaster. I am looking for a solution that works in
>> this case.
>> 
>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>> 
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> 
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>> 
>>  bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>> 
>> Thanks.
>> 
>> Ira
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law


From kekwu @ending from ucd@vi@@edu  Fri Jun 29 23:56:09 2018
From: kekwu @ending from ucd@vi@@edu (Kelly Wu)
Date: Fri, 29 Jun 2018 14:56:09 -0700
Subject: [R] trouble with exiting loop if condition is met
In-Reply-To: <CA+8X3fXg4B3cuyHv4wAJGPjgoFCNymptBH5Sn+z2Dy7_VXCRDg@mail.gmail.com>
References: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
 <CA+8X3fXg4B3cuyHv4wAJGPjgoFCNymptBH5Sn+z2Dy7_VXCRDg@mail.gmail.com>
Message-ID: <36234D0D-FF2D-4961-A753-01D4E9058530@ucdavis.edu>

Hi Jim & Don,


I was trying to use the break command originally before posting but for some reason it was making almost all of the p-values in the replications non significant. I think I am going to change the flow of the loop so I don?t have to use a break, such as the code Jim wrote. Thanks for your detailed response! 


Kelly


> On Jun 28, 2018, at 3:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> " as sequential observations, it
> will only require a minor modification.
> 
> Jim
> 
> On Fri, Jun 29, 2018 at 5:53 AM, Kelly Wu <kekwu at ucdavis.edu> wrote:
> 


	[[alternative HTML version deleted]]


From r@turner @ending from @uckl@nd@@c@nz  Sat Jun 30 00:56:36 2018
From: r@turner @ending from @uckl@nd@@c@nz (Rolf Turner)
Date: Sat, 30 Jun 2018 10:56:36 +1200
Subject: [R] [FORGED]  Plot multiple time series on a seasonal plot
In-Reply-To: <615332437.512512.1530279679993@mail.yahoo.com>
References: <615332437.512512.1530279679993.ref@mail.yahoo.com>
 <615332437.512512.1530279679993@mail.yahoo.com>
Message-ID: <79cffece-fbfa-bedf-b3e0-73f230dccd3f@auckland.ac.nz>

On 30/06/18 01:41, J?r?me Fran?ois via R-help wrote:
> Dear members,
> 
> I would like to plot a second time series (a forecast) to a seasonal plot made with function seasonplot() from the package forecast.
> 
> 
> Here is a reproducible example:
> ts1 <- structure(c(112035, 111182, 111015, 109331, 107525, 107749, 111435,
> 111629, 112462, 112256, 109496, 107917, 108221, 107463, 105960,
> 103883, 101038, 100056, 101628, 102973, 103371, 102463, 100774,
> 100718, 100471, 99828, 99365, 98521, 95695, 96443, 96287, 97525,
> 98293, 98014, 96658, 96736, 96089, 95337, 95382, 92748, 91448,
> 91560, 92996, 94046, 94128, 93888, 93888, 91091, 91877, 91681,
> 91045, 89367, 87912), .Tsp = c(2014, 2018.33333333333, 12), class = "ts")
> 
> ts2 <- structure(c(87867.2152330971, 89713.0862474283, 89600.565347383,
> 91066.3196835822, 90523.1926861474, 89322.8025396445, 88771.5545520503,
> 89247.0913151542, 88803.5578121458, 88060.0948570082, 87015.6578227365,
> 85785.4121532206), .Tsp = c(2018.41666666667, 2019.33333333333,
> 12), class = "ts")
> 
> 
> library(forecast)seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE)
> 
> 
> How can I add ts2 to the seasonal plot? I would like it to be distinguishable from ts1 (e.g. different color).
> 
> lines(ts2) doesn't work.
> Thank you.


I don't know anything about forecast/seasonplot.  However my experience 
is that par(new=TRUE) usually rescues one in situations like this.

It's a bit shaganappi, but ...

seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE,
            main="Whatever")
OP <- par(new=TRUE,xaxt="n",yaxt="n")
seasonplot(ts2, col="red",main="")
par(OP)

seems to work.

It would be nice to have an "add=" argument (defaulting to FALSE, of 
course) to seasonplot().

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From ir@@h@renow100 @ending from y@hoo@com  Sat Jun 30 02:29:07 2018
From: ir@@h@renow100 @ending from y@hoo@com (Ira Sharenow)
Date: Sat, 30 Jun 2018 00:29:07 +0000 (UTC)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
Message-ID: <951618652.604333.1530318547705@mail.yahoo.com>

 
Sarah and David,

Thank you for your responses.I will try and be clearer.

Base R solution: Sarah?smethod worked perfectly

Is there a dplyrsolution?

START: list of dataframes

FINISH: one data frame

DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows. 

SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.

EXAMPLE: List with twodata frames

# DF1

First?? ???????Last

George Washington

?

# DF2

Start????????????? End

John?????????????? Adams

Thomas??????? Jefferson

?

# End Result. One dataframe

First1????? Second1??????? First2?????????? Second2

George Washington?????? NA??????????????????? NA

John?????????????? Adams??? Thomas??????? Jefferson

?

DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.

The suggested solution was:

library(dplyr)

bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))

?

On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))

For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.

I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.

In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.

Ira


    On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:  
 
 
> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi,
> 
> It isn't super clear to me what you're after.

Agree.

Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:

library(dplyr)
 newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) ) 
 bind_rows(newList)

#---------

? first1 second1
1? ? ? Al? Jones
2? ? Al2? Jones
3? ? Barb? Smith
4? ? Al3? Jones
5 Barbara? Smith
6? Carol? Adams
7? ? ? Al? Jones2

Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.

-- 
David.
> Is this what you intend?
> 
>> dfbycol(employees4BList)
>? first1 last1 first2 last2 first3 last3
> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
> 2? ? Al Jones? Barb Smith? <NA>? <NA>
> 3? ? Al Jones? Barb Smith? Carol Adams
> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>> 
>> dfbycol(employees4List)
>? first1? last1? first2 last2 first3 last3
> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
> 3? ? Al3? Jones Barbara Smith? Carol Adams
> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
> 
> 
> If so:
> 
> employees4BList = list(
> data.frame(first1 = "Al", second1 = "Jones"),
> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> "Smith", "Adams")),
> data.frame(first1 = ("Al"), second1 = "Jones"))
> 
> employees4List = list(
> data.frame(first1 = ("Al"), second1 = "Jones"),
> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> "Smith", "Adams")),
> data.frame(first4 = ("Al"), second4 = "Jones2"))
> 
> ###
> 
> dfbycol <- function(x) {
>? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>? x <- do.call(rbind, x)
>? x <- data.frame(x, stringsAsFactors=FALSE)
>? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>? x
> }
> 
> ###
> 
> dfbycol(employees4BList)
> 
> dfbycol(employees4List)
> 
> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
> <r-help at r-project.org> wrote:
>> I have a list of data frames which I would like to combine into one data
>> frame doing something like rbind. I wish to combine in column order and
>> not by names. However, there are issues.
>> 
>> The number of columns is not the same for each data frame. This is an
>> intermediate step to a problem and the number of columns could be
>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>> is that the names of the columns produced by the first step are garbage.
>> 
>> Below is a method that I obtained by asking a question on stack
>> overflow. Unfortunately, my example was not general enough. The code
>> below works for the simple case where the names of the people are
>> consistent. It does not work when the names are realistically not the same.
>> 
>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>> 
>> 
>> Please note that the lapply step sets things up except for the column
>> name issue. If I could figure out a way to change the column names, then
>> the bind_rows step will, I believe, work.
>> 
>> So I really have two questions. How to change all column names of all
>> the data frames and then how to solve the original problem.
>> 
>> # The non general case works fine. It produces one data frame and I can
>> then change the column names to
>> 
>> # c("first1", "last1","first2", "last2","first3", "last3",)
>> 
>> #Non general easy case
>> 
>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>> 
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> 
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>> 
>> employees4BList
>> 
>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>> 
>> # This produces a nice list of data frames, except for the names
>> 
>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>> 
>> # This list is a disaster. I am looking for a solution that works in
>> this case.
>> 
>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>> 
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> 
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>> 
>>? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>> 
>> Thanks.
>> 
>> Ira
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law




  
	[[alternative HTML version deleted]]


From bgunter@4567 @ending from gm@il@com  Sat Jun 30 03:33:46 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Fri, 29 Jun 2018 18:33:46 -0700
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <951618652.604333.1530318547705@mail.yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
Message-ID: <CAGxFJbSUVF5E8GDzzZ9X-SSBTQH8sV+Bywk4QZU-pOCe7p+RMA@mail.gmail.com>

Well, I don't know your constraints, of course; but if I understand
correctly, in situations like this, it is usually worthwhile to reconsider
your data structure.

This is a one-liner if you simply rbind all your data frames into one with
2 columns. Here's an example to indicate how:

## list of two data frames with different column names and numbers of rows:
zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a =
5:9,b = letters[11:15]))

## create common column names and bind them up:
do.call(rbind,lapply(zz,function(x){   names(x) <- c("first","last"); x}))

Note that the row names of the result tell you which original frame the
rows came from. This can also be obtained just from a count of rows (?nrow)
of the original list.

Apologies if I misunderstand or your query or your constraints make this
simple approach impossible.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jun 29, 2018 at 5:29 PM, Ira Sharenow via R-help <
r-help at r-project.org> wrote:

>
> Sarah and David,
>
> Thank you for your responses.I will try and be clearer.
>
> Base R solution: Sarah?smethod worked perfectly
>
> Is there a dplyrsolution?
>
> START: list of dataframes
>
> FINISH: one data frame
>
> DETAILS: The initiallist of data frames might have hundreds or a few
> thousand data frames. Everydata frame will have two columns. The first
> column will represent first names.The second column will represent last
> names. The column names are notconsistent. Data frames will most likely
> have from one to five rows.
>
> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames.
> Then somehow do an rbindeven though the number of columns differ from data
> frame to data frame.
>
> EXAMPLE: List with twodata frames
>
> # DF1
>
> First          Last
>
> George Washington
>
>
>
> # DF2
>
> Start              End
>
> John               Adams
>
> Thomas        Jefferson
>
>
>
> # End Result. One dataframe
>
> First1      Second1        First2           Second2
>
> George Washington       NA                    NA
>
> John               Adams    Thomas        Jefferson
>
>
>
> DISCUSSION: As mentionedI posted something on Stack Overflow.
> Unfortunately, my example was not generalenough and so the suggested
> solutions worked on the easy case which I provided butnot when the names
> were different.
>
> The suggested solution was:
>
> library(dplyr)
>
> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>
>
>
> On this site I pointedout that the inner function: lapply(employees4List,
> function(x) rbind.data.frame(c(t(x))))
>
> For each data frame correctlyspread the multiple rows into  1 by 2ndata
> frames. However, the column names were derived from the values and were
> amess. This caused a problem with bind_rows.
>
> I felt that if I knewhow to change all the names of all of the data frames
> that were created afterlapply, then I could then use bind_rows. So if
> someone knows how to change allof the names at this intermediate stage, I
> hope that person will provide thesolution.
>
> In  the end a 1 by 2 data frame would have namesFirst1      Second1. A 1
> by 4 data framewould have names First1      Second1        First2
> Second2.
>
> Ira
>
>
>     On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <
> dwinsemius at comcast.net> wrote:
>
>
> > On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> >
> > Hi,
> >
> > It isn't super clear to me what you're after.
>
> Agree.
>
> Had a different read of ht erequest. Thought the request was for a first
> step that "harmonized" the names of the columns and then used
> `dplyr::bind_rows`:
>
> library(dplyr)
>  newList <- lapply( employees4List, 'names<-', names(employees4List[[1]])
> )
>  bind_rows(newList)
>
> #---------
>
>   first1 second1
> 1      Al  Jones
> 2    Al2  Jones
> 3    Barb  Smith
> 4    Al3  Jones
> 5 Barbara  Smith
> 6  Carol  Adams
> 7      Al  Jones2
>
> Might want to wrap suppressWarnings around the right side of that
> assignment since there were many warnings regarding incongruent factor
> levels.
>
> --
> David.
> > Is this what you intend?
> >
> >> dfbycol(employees4BList)
> >  first1 last1 first2 last2 first3 last3
> > 1    Al Jones  <NA>  <NA>  <NA>  <NA>
> > 2    Al Jones  Barb Smith  <NA>  <NA>
> > 3    Al Jones  Barb Smith  Carol Adams
> > 4    Al Jones  <NA>  <NA>  <NA>  <NA>
> >>
> >> dfbycol(employees4List)
> >  first1  last1  first2 last2 first3 last3
> > 1    Al  Jones    <NA>  <NA>  <NA>  <NA>
> > 2    Al2  Jones    Barb Smith  <NA>  <NA>
> > 3    Al3  Jones Barbara Smith  Carol Adams
> > 4    Al Jones2    <NA>  <NA>  <NA>  <NA>
> >
> >
> > If so:
> >
> > employees4BList = list(
> > data.frame(first1 = "Al", second1 = "Jones"),
> > data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> > data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> > "Smith", "Adams")),
> > data.frame(first1 = ("Al"), second1 = "Jones"))
> >
> > employees4List = list(
> > data.frame(first1 = ("Al"), second1 = "Jones"),
> > data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> > data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> > "Smith", "Adams")),
> > data.frame(first4 = ("Al"), second4 = "Jones2"))
> >
> > ###
> >
> > dfbycol <- function(x) {
> >  x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
> >  x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
> >  x <- do.call(rbind, x)
> >  x <- data.frame(x, stringsAsFactors=FALSE)
> >  colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2),
> each=2))
> >  x
> > }
> >
> > ###
> >
> > dfbycol(employees4BList)
> >
> > dfbycol(employees4List)
> >
> > On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
> > <r-help at r-project.org> wrote:
> >> I have a list of data frames which I would like to combine into one data
> >> frame doing something like rbind. I wish to combine in column order and
> >> not by names. However, there are issues.
> >>
> >> The number of columns is not the same for each data frame. This is an
> >> intermediate step to a problem and the number of columns could be
> >> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
> >> is that the names of the columns produced by the first step are garbage.
> >>
> >> Below is a method that I obtained by asking a question on stack
> >> overflow. Unfortunately, my example was not general enough. The code
> >> below works for the simple case where the names of the people are
> >> consistent. It does not work when the names are realistically not the
> same.
> >>
> >> https://stackoverflow.com/questions/50807970/converting-
> a-list-of-data-frames-not-a-simple-rbind-second-row-to-
> new-columns/50809432#50809432
> >>
> >>
> >> Please note that the lapply step sets things up except for the column
> >> name issue. If I could figure out a way to change the column names, then
> >> the bind_rows step will, I believe, work.
> >>
> >> So I really have two questions. How to change all column names of all
> >> the data frames and then how to solve the original problem.
> >>
> >> # The non general case works fine. It produces one data frame and I can
> >> then change the column names to
> >>
> >> # c("first1", "last1","first2", "last2","first3", "last3",)
> >>
> >> #Non general easy case
> >>
> >> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
> >>
> >> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> >>
> >> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> >> "Smith", "Adams")),
> >>
> >> data.frame(first1 = ("Al"), second1 = "Jones"))
> >>
> >> employees4BList
> >>
> >> bind_rows(lapply(employees4BList, function(x)
> rbind.data.frame(c(t(x)))))
> >>
> >> # This produces a nice list of data frames, except for the names
> >>
> >> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
> >>
> >> # This list is a disaster. I am looking for a solution that works in
> >> this case.
> >>
> >> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
> >>
> >> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> >>
> >> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> >> "Smith", "Adams")),
> >>
> >> data.frame(first4 = ("Al"), second4 = "Jones2"))
> >>
> >>  bind_rows(lapply(employees4List, function(x)
> rbind.data.frame(c(t(x)))))
> >>
> >> Thanks.
> >>
> >> Ira
> >>
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
> -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jun 30 04:50:58 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Fri, 29 Jun 2018 19:50:58 -0700 (PDT)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <951618652.604333.1530318547705@mail.yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>

Code below...

a) Just because something can be done with dplyr does not mean that is the 
best way to do it. A solution in the hand is worth two on the Internet, 
and dplyr is not always the fastest method anyway.

b) I highly recommend that you read Hadley Wickham's paper on tidy data 
[1]. Also, having a group of one or more columns at all times that 
uniquely identify where the data came from is a "key" to success [2].

c) Please read and follow one of the various online documents about making 
reproducible examples in R (e.g. [3]). HTML formatting is really a pain 
(at best... at worst, it corrupts your code) on a plain-text-only list 
(you have read the Posting Guide, right?). Consider my example below as a 
model for you to follow in the future, and make sure to set your email 
program to send plain text. (Obviously your examples don't have to achieve 
success... but they should bring us up to speed with where you are having 
troubles IN R.)

[1] https://www.jstatsoft.org/article/view/v059i10
[2] http://r4ds.had.co.nz/relational-data.html#keys
[3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

----
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)

# note that these data frames all have character columns
# rather than factors, due to the as.is option when the
# data are read in.
DF1 <- read.table( text =
"First          Last
George          Washington
", header=TRUE, as.is = TRUE )

# dput looks ugly but is actually much more practical for
# providing R data on the mailing list... here is an example
dput( DF1 )
#> structure(list(First = "George", Last = "Washington")
#>, .Names = c("First",
#> "Last"), class = "data.frame", row.names = c(NA, -1L))

DF2 <- read.table( text =
"Start              End
John               Adams
Thomas        Jefferson
", header = TRUE, as.is = TRUE )

DFL <- list( DF1, DF2 )

# DFNames is a set of unique identifiers
DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
                   , data = DFL
                   )

DFL2 <- (   DFL1
         %>% mutate( data = lapply( data
                                  , function( DF ) {
                                      DF[[ ".PK" ]] <- seq.int( nrow( DF ))
                                      gather( DF, ".Col", "value", -.PK )
                                    }
                                  )
                   )
         %>% unnest
         %>% spread( .Col, value )
         )
DFL2
#> # A tibble: 3 x 6
#>   .DFNames   .PK End       First  Last       Start
#>   <chr>    <int> <chr>     <chr>  <chr>      <chr>
#> 1 DF1          1 <NA>      George Washington <NA>
#> 2 DF2          1 Adams     <NA>   <NA>       John
#> 3 DF2          2 Jefferson <NA>   <NA>       Thomas

#' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
----

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

>
> Sarah and David,
>
> Thank you for your responses.I will try and be clearer.
>
> Base R solution: Sarah?smethod worked perfectly
>
> Is there a dplyrsolution?
>
> START: list of dataframes
>
> FINISH: one data frame
>
> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>
> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>
> EXAMPLE: List with twodata frames
>
> # DF1
>
> First?? ???????Last
>
> George Washington
>
> ?
>
> # DF2
>
> Start????????????? End
>
> John?????????????? Adams
>
> Thomas??????? Jefferson
>
> ?
>
> # End Result. One dataframe
>
> First1????? Second1??????? First2?????????? Second2
>
> George Washington?????? NA??????????????????? NA
>
> John?????????????? Adams??? Thomas??????? Jefferson
>
> ?
>
> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>
> The suggested solution was:
>
> library(dplyr)
>
> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>
> ?
>
> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>
> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>
> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>
> Ira
>
>
>    On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>
>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> It isn't super clear to me what you're after.
>
> Agree.
>
> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>
> library(dplyr)
> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
> bind_rows(newList)
>
> #---------
>
> ? first1 second1
> 1? ? ? Al? Jones
> 2? ? Al2? Jones
> 3? ? Barb? Smith
> 4? ? Al3? Jones
> 5 Barbara? Smith
> 6? Carol? Adams
> 7? ? ? Al? Jones2
>
> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>
> -- 
> David.
>> Is this what you intend?
>>
>>> dfbycol(employees4BList)
>> ? first1 last1 first2 last2 first3 last3
>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>> 3? ? Al Jones? Barb Smith? Carol Adams
>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>
>>> dfbycol(employees4List)
>> ? first1? last1? first2 last2 first3 last3
>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>
>>
>> If so:
>>
>> employees4BList = list(
>> data.frame(first1 = "Al", second1 = "Jones"),
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>
>> employees4List = list(
>> data.frame(first1 = ("Al"), second1 = "Jones"),
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>
>> ###
>>
>> dfbycol <- function(x) {
>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>> ? x <- do.call(rbind, x)
>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>> ? x
>> }
>>
>> ###
>>
>> dfbycol(employees4BList)
>>
>> dfbycol(employees4List)
>>
>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>> <r-help at r-project.org> wrote:
>>> I have a list of data frames which I would like to combine into one data
>>> frame doing something like rbind. I wish to combine in column order and
>>> not by names. However, there are issues.
>>>
>>> The number of columns is not the same for each data frame. This is an
>>> intermediate step to a problem and the number of columns could be
>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>> is that the names of the columns produced by the first step are garbage.
>>>
>>> Below is a method that I obtained by asking a question on stack
>>> overflow. Unfortunately, my example was not general enough. The code
>>> below works for the simple case where the names of the people are
>>> consistent. It does not work when the names are realistically not the same.
>>>
>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>
>>>
>>> Please note that the lapply step sets things up except for the column
>>> name issue. If I could figure out a way to change the column names, then
>>> the bind_rows step will, I believe, work.
>>>
>>> So I really have two questions. How to change all column names of all
>>> the data frames and then how to solve the original problem.
>>>
>>> # The non general case works fine. It produces one data frame and I can
>>> then change the column names to
>>>
>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>
>>> #Non general easy case
>>>
>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4BList
>>>
>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> # This produces a nice list of data frames, except for the names
>>>
>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>
>>> # This list is a disaster. I am looking for a solution that works in
>>> this case.
>>>
>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> Thanks.
>>>
>>> Ira
>>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From ir@@h@renow100 @ending from y@hoo@com  Sat Jun 30 04:08:56 2018
From: ir@@h@renow100 @ending from y@hoo@com (Ira Sharenow)
Date: Fri, 29 Jun 2018 19:08:56 -0700
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <CAGxFJbSUVF5E8GDzzZ9X-SSBTQH8sV+Bywk4QZU-pOCe7p+RMA@mail.gmail.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <CAGxFJbSUVF5E8GDzzZ9X-SSBTQH8sV+Bywk4QZU-pOCe7p+RMA@mail.gmail.com>
Message-ID: <388607cc-83f3-78fb-466e-f6fff4787077@yahoo.com>

Bert,

Thanks for your idea. However, the end results is not what I am looking 
for. Each initial data frame in the list will result in just one row in 
the final data frame. In your case

Row 1 of the initial structure will become 1 b 2 c3d NA NA NA NA in the 
end structure

Row 2 of the initial structure will become 5 k 6 l 7 m 8 n 9 o

Sarah?s code works

> dfbycol(zz)

first1 last1 first2 last2 first3 last3 first4 last4 first5 last5

one1b2c3d<NA><NA><NA><NA>

two5k6l7m8n9o


> 

dfbycol <- function(x) {

x <- lapply(x, function(y)as.vector(t(as.matrix(y))))

x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})

x <- do.call(rbind, x)

x <- data.frame(x, stringsAsFactors=FALSE)

colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))

x

}

Thanks.

By the way I am working with a colleague on this. Apparently the data 
came from reading in XML data.

Ira


On 6/29/2018 6:33 PM, Bert Gunter wrote:
> Well, I don't know your constraints, of course; but if I understand 
> correctly, in situations like this, it is usually worthwhile to 
> reconsider your data structure.
>
> This is a one-liner if you simply rbind all your data frames into one 
> with 2 columns. Here's an example to indicate how:
>
> ## list of two data frames with different column names and numbers of 
> rows:
> zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 
> 5:9,b = letters[11:15]))
>
> ## create common column names and bind them up:
> do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
>
> Note that the row names of the result tell you which original frame 
> the rows came from. This can also be obtained just from a count of 
> rows (?nrow) of the original list.
>
> Apologies if I misunderstand or your query or your constraints make 
> this simple approach impossible.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Jun 29, 2018 at 5:29 PM, Ira Sharenow via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>
>     Sarah and David,
>
>     Thank you for your responses.I will try and be clearer.
>
>     Base R solution: Sarah?smethod worked perfectly
>
>     Is there a dplyrsolution?
>
>     START: list of dataframes
>
>     FINISH: one data frame
>
>     DETAILS: The initiallist of data frames might have hundreds or a
>     few thousand data frames. Everydata frame will have two columns.
>     The first column will represent first names.The second column will
>     represent last names. The column names are notconsistent. Data
>     frames will most likely have from one to five rows.
>
>     SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data
>     frames. Then somehow do an rbindeven though the number of columns
>     differ from data frame to data frame.
>
>     EXAMPLE: List with twodata frames
>
>     # DF1
>
>     First?? ???????Last
>
>     George Washington
>
>
>
>     # DF2
>
>     Start????????????? End
>
>     John?????????????? Adams
>
>     Thomas??????? Jefferson
>
>
>
>     # End Result. One dataframe
>
>     First1????? Second1??????? First2?????????? Second2
>
>     George Washington?????? NA??????????????????? NA
>
>     John?????????????? Adams??? Thomas??????? Jefferson
>
>
>
>     DISCUSSION: As mentionedI posted something on Stack Overflow.
>     Unfortunately, my example was not generalenough and so the
>     suggested solutions worked on the easy case which I provided
>     butnot when the names were different.
>
>     The suggested solution was:
>
>     library(dplyr)
>
>     bind_rows(lapply(employees4List,function(x)
>     rbind.data.frame(c(t(x)))))
>
>
>
>     On this site I pointedout that the inner function:
>     lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
>     For each data frame correctlyspread the multiple rows into ?1 by
>     2ndata frames. However, the column names were derived from the
>     values and were amess. This caused a problem with bind_rows.
>
>     I felt that if I knewhow to change all the names of all of the
>     data frames that were created afterlapply, then I could then use
>     bind_rows. So if someone knows how to change allof the names at
>     this intermediate stage, I hope that person will provide thesolution.
>
>     In? the end a 1 by 2 data frame would have namesFirst1 Second1. A
>     1 by 4 data framewould have names First1 Second1???????
>     First2?????????? Second2.
>
>     Ira
>
>
>     ? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius
>     <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     > On Jun 29, 2018, at 7:28 AM, Sarah Goslee
>     <sarah.goslee at gmail.com <mailto:sarah.goslee at gmail.com>> wrote:
>     >
>     > Hi,
>     >
>     > It isn't super clear to me what you're after.
>
>     Agree.
>
>     Had a different read of ht erequest. Thought the request was for a
>     first step that "harmonized" the names of the columns and then
>     used `dplyr::bind_rows`:
>
>     library(dplyr)
>     ?newList <- lapply( employees4List, 'names<-',
>     names(employees4List[[1]]) )
>     ?bind_rows(newList)
>
>     #---------
>
>     ? first1 second1
>     1? ? ? Al? Jones
>     2? ? Al2? Jones
>     3? ? Barb? Smith
>     4? ? Al3? Jones
>     5 Barbara? Smith
>     6? Carol? Adams
>     7? ? ? Al? Jones2
>
>     Might want to wrap suppressWarnings around the right side of that
>     assignment since there were many warnings regarding incongruent
>     factor levels.
>
>     -- 
>     David.
>     > Is this what you intend?
>     >
>     >> dfbycol(employees4BList)
>     >? first1 last1 first2 last2 first3 last3
>     > 1? ? Al Jones? <NA>? <NA>? <NA> <NA>
>     > 2? ? Al Jones? Barb Smith? <NA>? <NA>
>     > 3? ? Al Jones? Barb Smith? Carol Adams
>     > 4? ? Al Jones? <NA>? <NA>? <NA> <NA>
>     >>
>     >> dfbycol(employees4List)
>     >? first1? last1? first2 last2 first3 last3
>     > 1? ? Al? Jones? ? <NA>? <NA>? <NA> <NA>
>     > 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>     > 3? ? Al3? Jones Barbara Smith? Carol Adams
>     > 4? ? Al Jones2? ? <NA>? <NA>? <NA> <NA>
>     >
>     >
>     > If so:
>     >
>     > employees4BList = list(
>     > data.frame(first1 = "Al", second1 = "Jones"),
>     > data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>     > data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>     > "Smith", "Adams")),
>     > data.frame(first1 = ("Al"), second1 = "Jones"))
>     >
>     > employees4List = list(
>     > data.frame(first1 = ("Al"), second1 = "Jones"),
>     > data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones",
>     "Smith")),
>     > data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 =
>     c("Jones",
>     > "Smith", "Adams")),
>     > data.frame(first4 = ("Al"), second4 = "Jones2"))
>     >
>     > ###
>     >
>     > dfbycol <- function(x) {
>     >? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>     >? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>     >? x <- do.call(rbind, x)
>     >? x <- data.frame(x, stringsAsFactors=FALSE)
>     >? colnames(x) <- paste0(c("first", "last"), rep(seq(1,
>     ncol(x)/2), each=2))
>     >? x
>     > }
>     >
>     > ###
>     >
>     > dfbycol(employees4BList)
>     >
>     > dfbycol(employees4List)
>     >
>     > On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>     > <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>     >> I have a list of data frames which I would like to combine into
>     one data
>     >> frame doing something like rbind. I wish to combine in column
>     order and
>     >> not by names. However, there are issues.
>     >>
>     >> The number of columns is not the same for each data frame. This
>     is an
>     >> intermediate step to a problem and the number of columns could be
>     >> 2,4,6,8,or10. There might be a few thousand data frames.
>     Another problem
>     >> is that the names of the columns produced by the first step are
>     garbage.
>     >>
>     >> Below is a method that I obtained by asking a question on stack
>     >> overflow. Unfortunately, my example was not general enough. The
>     code
>     >> below works for the simple case where the names of the people are
>     >> consistent. It does not work when the names are realistically
>     not the same.
>     >>
>     >>
>     https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>     <https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432>
>     >>
>     >>
>     >> Please note that the lapply step sets things up except for the
>     column
>     >> name issue. If I could figure out a way to change the column
>     names, then
>     >> the bind_rows step will, I believe, work.
>     >>
>     >> So I really have two questions. How to change all column names
>     of all
>     >> the data frames and then how to solve the original problem.
>     >>
>     >> # The non general case works fine. It produces one data frame
>     and I can
>     >> then change the column names to
>     >>
>     >> # c("first1", "last1","first2", "last2","first3", "last3",)
>     >>
>     >> #Non general easy case
>     >>
>     >> employees4BList = list(data.frame(first1 = "Al", second1 =
>     "Jones"),
>     >>
>     >> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones",
>     "Smith")),
>     >>
>     >> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>     >> "Smith", "Adams")),
>     >>
>     >> data.frame(first1 = ("Al"), second1 = "Jones"))
>     >>
>     >> employees4BList
>     >>
>     >> bind_rows(lapply(employees4BList, function(x)
>     rbind.data.frame(c(t(x)))))
>     >>
>     >> # This produces a nice list of data frames, except for the names
>     >>
>     >> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>     >>
>     >> # This list is a disaster. I am looking for a solution that
>     works in
>     >> this case.
>     >>
>     >> employees4List = list(data.frame(first1 = ("Al"), second1 =
>     "Jones"),
>     >>
>     >> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones",
>     "Smith")),
>     >>
>     >> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 =
>     c("Jones",
>     >> "Smith", "Adams")),
>     >>
>     >> data.frame(first4 = ("Al"), second4 = "Jones2"))
>     >>
>     >>? bind_rows(lapply(employees4List, function(x)
>     rbind.data.frame(c(t(x)))))
>     >>
>     >> Thanks.
>     >>
>     >> Ira
>     >>
>     >
>     > --
>     > Sarah Goslee
>     > http://www.functionaldiversity.org
>     <http://www.functionaldiversity.org>
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     David Winsemius
>     Alameda, CA, USA
>
>     'Any technology distinguishable from magic is insufficiently
>     advanced.'? -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]


From p_connolly @ending from @ling@hot@co@nz  Sat Jun 30 11:09:45 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Sat, 30 Jun 2018 21:09:45 +1200
Subject: [R] OT --- grammar.
In-Reply-To: <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
Message-ID: <20180630090945.GA14260@slingshot.co.nz>

How about "Physics / politics / economics are my favoruite subject"?

Might be fun to see how long we could make that list.  It seems to be
a fact of life that it's impossible to make a (useful) language that
has totally consistent grammar.  

Something else to consider:I knew an English teacher who frowned on
what Rolf wrote (to quote) "...almost never .. "  which *should be*
"... hardly ever ... "

How boring it would be if we all agreed. :-)

On Mon, 25-Jun-2018 at 12:16PM +1200, Rolf Turner wrote:

|> On 25/06/18 12:03, Bert Gunter wrote:
|> >Ted, et. al.:
|> >
|> >Re: "Data is" vs "data are" ... Heh heh!
|> >
|> >"This is the kind of arrant pedantry up with which I will not put."
|> >(Attributed to Churchill in one form or another, likely wrongly.)
|> >
|> >See here for some semi-authoritative dicussion:
|> >
|> >http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/
|> 
|> I beg to differ.  "The data was out of date" sounds just plain
|> stupid to my sensitive ears.
|> 
|> It's rather like using the phrase "begs the question" to mean
|> "raises the question" or "invites the question" rather than to
|> carry its *correct* meaning of "assumes what is to be proved".  The
|> fact that the phrase is almost always used in its *incorrect* sense
|> these days, and almost never in its *correct* sense, does not
|> diminish the fact that those who use it incorrectly are ignorant
|> scumbags!  The language is weakened and diminished by the
|> encroachment of incorrect usage.
|> 
|> cheers,
|> 
|> Rolf
|> 
|> 
|> -- 
|> Technical Editor ANZJS
|> Department of Statistics
|> University of Auckland
|> Phone: +64-9-373-7599 ext. 88276
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.


From L@Piet@k @ending from poczt@@fm  Sat Jun 30 11:03:06 2018
From: L@Piet@k @ending from poczt@@fm (=?UTF-8?b?xYF1a2FzeiBQacSZdGFr?=)
Date: Sat, 30 Jun 2018 11:03:06 +0200
Subject: [R] Question
Message-ID: <hbqeaucobgtjfdbbzufb@kmye>


Hi, My name is Luke and I come from Poland. I have one question, maybe very simple, but I can not resolve it. In dynamic panel data (GMM estimator) after running the model, I recieve a AR test and Sargan test, but the "number of instruments" are not displayed. In Stata and Gretl this informatios is given, in R no. My question is, how to obtain the number of instruments?.
Thank you for helping.
Luke


From bgunter@4567 @ending from gm@il@com  Sat Jun 30 17:00:46 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 30 Jun 2018 08:00:46 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <20180630090945.GA14260@slingshot.co.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
 <20180630090945.GA14260@slingshot.co.nz>
Message-ID: <CAGxFJbSQYp3QUOwwEQRGRyS-nRDf_ZqxJNYAcpC+GFnOhKtPEw@mail.gmail.com>

No substantive comment.

But your addendum does bring to mind Gilbert and Sullivan (HMS Pinafore):

"
I am never known to quail At the fury of a gale, And I'm never, never sick
at sea! Chorus. What, never? Captain. No, never! Chorus. What, never?
Captain. Hardly ever! "

https://www.letssingit.com/gilbert-and-sullivan-lyrics-my-gallant-crew-good-morning-fv97wfr
LetsSingIt - The Internet Lyrics Database

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 30, 2018 at 2:09 AM, Patrick Connolly <
p_connolly at slingshot.co.nz> wrote:

> How about "Physics / politics / economics are my favoruite subject"?
>
> Might be fun to see how long we could make that list.  It seems to be
> a fact of life that it's impossible to make a (useful) language that
> has totally consistent grammar.
>
> Something else to consider:I knew an English teacher who frowned on
> what Rolf wrote (to quote) "...almost never .. "  which *should be*
> "... hardly ever ... "
>
> How boring it would be if we all agreed. :-)
>
> On Mon, 25-Jun-2018 at 12:16PM +1200, Rolf Turner wrote:
>
> |> On 25/06/18 12:03, Bert Gunter wrote:
> |> >Ted, et. al.:
> |> >
> |> >Re: "Data is" vs "data are" ... Heh heh!
> |> >
> |> >"This is the kind of arrant pedantry up with which I will not put."
> |> >(Attributed to Churchill in one form or another, likely wrongly.)
> |> >
> |> >See here for some semi-authoritative dicussion:
> |> >
> |> >http://www.onlinegrammar.com.au/top-10-grammar-myths-data-
> is-plural-so-must-take-a-plural-verb/
> |>
> |> I beg to differ.  "The data was out of date" sounds just plain
> |> stupid to my sensitive ears.
> |>
> |> It's rather like using the phrase "begs the question" to mean
> |> "raises the question" or "invites the question" rather than to
> |> carry its *correct* meaning of "assumes what is to be proved".  The
> |> fact that the phrase is almost always used in its *incorrect* sense
> |> these days, and almost never in its *correct* sense, does not
> |> diminish the fact that those who use it incorrectly are ignorant
> |> scumbags!  The language is weakened and diminished by the
> |> encroachment of incorrect usage.
> |>
> |> cheers,
> |>
> |> Rolf
> |>
> |>
> |> --
> |> Technical Editor ANZJS
> |> Department of Statistics
> |> University of Auckland
> |> Phone: +64-9-373-7599 ext. 88276
> |>
> |> ______________________________________________
> |> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> https://stat.ethz.ch/mailman/listinfo/r-help
> |> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> |> and provide commented, minimal, self-contained, reproducible code.
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>

	[[alternative HTML version deleted]]


From @k@h@y_e4 @ending from hotm@il@com  Sat Jun 30 19:07:49 2018
From: @k@h@y_e4 @ending from hotm@il@com (akshay kulkarni)
Date: Sat, 30 Jun 2018 17:07:49 +0000
Subject: [R] parallel processing in r...
Message-ID: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am using mclapply to parallelize my code. I am using Red Hat Linux in AWS.

When I use mclapply, I see no speed increase. I doubt that the Linux OS is allowing fewer than the maximum number of cores to mclapply ( by default, mclapply takes all the available cores to it).

How do you check if the number of workers is less than the output given by detectCores(), in Linux? Is there any R function for it?

I do acknowledge that help on an OS is not suitable for this mailing list, but even Internet could'nt help me. Therefore this mail......

very many thanks for your time  and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jun 30 19:41:35 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 10:41:35 -0700
Subject: [R] Question
In-Reply-To: <hbqeaucobgtjfdbbzufb@kmye>
References: <hbqeaucobgtjfdbbzufb@kmye>
Message-ID: <8FEC5AE2-3344-4050-B4F9-1AA3E5052061@dcn.davis.ca.us>

Your question is notable for what it is missing... any trace of R code. [1][2][3] Do read the Posting Guide.

I don't see "Sargan" in base R, so your analysis likely used a contributed package... there seem to be a couple, so your example code would clarify. I don't see the number of IVs listed in the print result of the ivmodels package, so you might have to use length( Z ) (your input) to record that. Note that it is typical of stats models in R to report degrees of freedom rather than number of inputs, so this may be intentional.

You should also keep in mind that contributed packages are maintained by their contributors. If they turn out to be missing features then adding those features will involve communicating with those contributors as indicated in the package DESCRIPTION file (summarized on the CRAN web site)... they may or may not subscribe to this mailing list.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 



On June 30, 2018 2:03:06 AM PDT, "?ukasz Pi?tak" <L.Pietak at poczta.fm> wrote:
>
>Hi, My name is Luke and I come from Poland. I have one question, maybe
>very simple, but I can not resolve it. In dynamic panel data (GMM
>estimator) after running the model, I recieve a AR test and Sargan
>test, but the "number of instruments" are not displayed. In Stata and
>Gretl this informatios is given, in R no. My question is, how to obtain
>the number of instruments?.
>Thank you for helping.
>Luke
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bgunter@4567 @ending from gm@il@com  Sat Jun 30 20:14:57 2018
From: bgunter@4567 @ending from gm@il@com (Bert Gunter)
Date: Sat, 30 Jun 2018 11:14:57 -0700
Subject: [R] parallel processing in r...
In-Reply-To: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbTh7ie-AgkUz1ikTre0PTOMOaEbMXzmsijBx+=2ithKLw@mail.gmail.com>

The effectiveness of parallelizing code, be it with mclapply or otherwise,
depends in large part on the code, which you failed to show.

I cannot answer your other question.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 30, 2018 at 10:07 AM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                              I am using mclapply to parallelize my code. I
> am using Red Hat Linux in AWS.
>
> When I use mclapply, I see no speed increase. I doubt that the Linux OS is
> allowing fewer than the maximum number of cores to mclapply ( by default,
> mclapply takes all the available cores to it).
>
> How do you check if the number of workers is less than the output given by
> detectCores(), in Linux? Is there any R function for it?
>
> I do acknowledge that help on an OS is not suitable for this mailing list,
> but even Internet could'nt help me. Therefore this mail......
>
> very many thanks for your time  and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jun 30 20:16:19 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 11:16:19 -0700
Subject: [R] parallel processing in r...
In-Reply-To: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>

Use "top" at the bash prompt.

Read about the "mc.cores" parameter to mclapply.

Make a simplified example version of your analysis and post your question in the context of that example [1][2][3]. You will learn about the issues you are dealing with in the process of trimming your problem, and will have code you can share that demonstrates the issue without exposing private information.

Running parallel does not necessarily improve performance because other factors like task switching overhead and Inter-process-communication (data sharing) can drag it down. Read about the real benefits and drawbacks of parallelism... there are many discussions out there out there... you might start with [4].


[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 

[4] https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html

On June 30, 2018 10:07:49 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>I am using mclapply to parallelize my code. I am using Red Hat Linux in
>AWS.
>
>When I use mclapply, I see no speed increase. I doubt that the Linux OS
>is allowing fewer than the maximum number of cores to mclapply ( by
>default, mclapply takes all the available cores to it).
>
>How do you check if the number of workers is less than the output given
>by detectCores(), in Linux? Is there any R function for it?
>
>I do acknowledge that help on an OS is not suitable for this mailing
>list, but even Internet could'nt help me. Therefore this mail......
>
>very many thanks for your time  and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.


From bog@@o@chri@tofer @ending from gm@il@com  Sat Jun 30 21:39:14 2018
From: bog@@o@chri@tofer @ending from gm@il@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 01:09:14 +0530
Subject: [R] A question on Statistics
Message-ID: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>

Hi,

I have a quick question on Statistical distribution as follows, hoping
Statisticians here would give me very insightful feedback.

Say, I have a large sample from a highly asymmetric distribution ranging
from -Inf to +Inf. Now I wish to calculate sample X1 and X2 within which
middle 70% probability would reside.

One approach
x = my sample
calculatte quantile(x, prob = 15%) & quantile(x, prob = 85%)

another approach
calculate quantile(abs[x], prob = 85%)
In this case X1 and X2 would be +/- of above result.

My question is in all scenarios, are above two approach equivalent? If not
which is the better approach to find such range.

Thanks,

	[[alternative HTML version deleted]]


From jdnewmil @ending from dcn@d@vi@@c@@u@  Sat Jun 30 21:51:50 2018
From: jdnewmil @ending from dcn@d@vi@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 12:51:50 -0700 (PDT)
Subject: [R] A question on Statistics
In-Reply-To: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>

You should use Stack Exchange for questions about statistics.

You should also think a bit before you post, regardless of where. You are 
the one who described this as a highly asymmetric distribution, and didn't 
say anything about it being centered at zero. You already answered your 
own question, to the extent that it can be answered.

On Sun, 1 Jul 2018, Christofer Bogaso wrote:

> Hi,
>
> I have a quick question on Statistical distribution as follows, hoping
> Statisticians here would give me very insightful feedback.
>
> Say, I have a large sample from a highly asymmetric distribution ranging
> from -Inf to +Inf. Now I wish to calculate sample X1 and X2 within which
> middle 70% probability would reside.
>
> One approach
> x = my sample
> calculatte quantile(x, prob = 15%) & quantile(x, prob = 85%)
>
> another approach
> calculate quantile(abs[x], prob = 85%)
> In this case X1 and X2 would be +/- of above result.
>
> My question is in all scenarios, are above two approach equivalent? If not
> which is the better approach to find such range.
>
> Thanks,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k


From p_connolly @ending from @ling@hot@co@nz  Sat Jun 30 23:05:33 2018
From: p_connolly @ending from @ling@hot@co@nz (Patrick Connolly)
Date: Sun, 1 Jul 2018 09:05:33 +1200
Subject: [R] parallel processing in r...
In-Reply-To: <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
Message-ID: <50d1370d-9783-1917-e37b-c96b2142fc79@slingshot.co.nz>

If you use gkrellm, you'll get a plot of each core's activity so it's 
easy to see how many are being used.

yum install gkrellm.


HTH

On 07/01/2018 06:16 AM, Jeff Newmiller wrote:
> Use "top" at the bash prompt.
>
> Read about the "mc.cores" parameter to mclapply.
>
> Make a simplified example version of your analysis and post your question in the context of that example [1][2][3]. You will learn about the issues you are dealing with in the process of trimming your problem, and will have code you can share that demonstrates the issue without exposing private information.
>
> Running parallel does not necessarily improve performance because other factors like task switching overhead and Inter-process-communication (data sharing) can drag it down. Read about the real benefits and drawbacks of parallelism... there are many discussions out there out there... you might start with [4].
>
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
>
> [4] https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
>
> On June 30, 2018 10:07:49 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>> dear members,
>> I am using mclapply to parallelize my code. I am using Red Hat Linux in
>> AWS.
>>
>> When I use mclapply, I see no speed increase. I doubt that the Linux OS
>> is allowing fewer than the maximum number of cores to mclapply ( by
>> default, mclapply takes all the available cores to it).
>>
>> How do you check if the number of workers is less than the output given
>> by detectCores(), in Linux? Is there any R function for it?
>>
>> I do acknowledge that help on an OS is not suitable for this mailing
>> list, but even Internet could'nt help me. Therefore this mail......
>>
>> very many thanks for your time  and effort...
>> yours sincerely,
>> AKSHAY M KULKARNI
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun  1 03:46:16 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 31 May 2018 18:46:16 -0700
Subject: [R] Help About R-Package Portability
In-Reply-To: <CAFkrz9bzvirESLgtJd-9eSxW4LzKyhvt7rVr3k26ToMb4xLJpw@mail.gmail.com>
References: <CAFkrz9bzvirESLgtJd-9eSxW4LzKyhvt7rVr3k26ToMb4xLJpw@mail.gmail.com>
Message-ID: <ACB491C6-462C-4F29-924C-5590446258FC@dcn.davis.ca.us>

Your lack of permissions is highly operating-system-specific and local-policy-specific and therefore outside the scope of this mailing list... I suggest you have a conversation with your system administrator(s). Insuring the ability to run R code when the admin is not cooperating is not really something we can help with. (Some systems are configured to prevent any executables from running off removable media at all.)

You should also read

?.libPaths

as well as the R Installation and Administration manual.

On May 31, 2018 6:02:35 AM PDT, BEDIRHAN CALDIR <bcaldir at ku.edu.tr> wrote:
>Hi,
>
>I'm having an issue with R package configurations which I thought the
>community would help me. I have two softwares written in R, DECoN and
>panelcn.mops, and need to run both of them isolated. The problem is
>that I
>couldn't install them onto neither the OS with the sudo permissions nor
>the
>home folder of a specific user with the right permissions. What I need
>is
>making them as portable as possible by installing R-related packages
>separately once and for all, so that I can run any of them even from a
>USB
>drive where no further R installation would be required. I'll run both
>of
>them from Python as a subprocess.
>
>I'd appreciate any suggession to overcome this issue. Thank you in
>advance.

-- 
Sent from my phone. Please excuse my brevity.



From bor|@@@te|pe @end|ng |rom utoronto@c@  Fri Jun  1 05:53:09 2018
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Thu, 31 May 2018 23:53:09 -0400
Subject: [R] How to alpha entire plot?
In-Reply-To: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
References: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
Message-ID: <FDB33FD3-BD35-4B9A-883A-B1469BAB7C0F@utoronto.ca>

Interesting problem.

I would discretize the x-values and interleave them. Lines from one dataset still overlap, so you see high- density and low-density regions, but lines from the other dataset are drawn into the interval. Like so:

interleave <- function(x, MIN, MAX, N, nChannel = 2, channel) {
  
  isp <- seq(MIN, MAX, length.out = N + 1) # interleave support points
  offset <- ((isp[2] - isp[1]) / nChannel) * (channel - 1) # offset for channel
  
  # round x to the nearest support point and add the channel specific offset
  x <- isp[round(as.numeric(cut(x, breaks = N)))] + offset
  
  return(x)
}

xi <- min(EU$DAX)
xa <- max(EU$DAX)

plot(interleave(EU$DAX, MIN=xi, MAX=xa, N=130, channel=1 ),
     EU$CAC,
     col = "#6600EE07",
     type = "h",
     ylim = c(0,6000),
     xlab = "DAX")

points(interleave(EU$DAX, MIN = xi, MAX = xa, N = 130, channel = 2 ),
     EU$FTSE,
     col = "#EE000007",
     type = "h")


Cheers,
B.



> On 2018-05-31, at 16:56, Ed Siefker <ebs15242 at gmail.com> wrote:
> 
> I have two chromatograms I want plotted on the same axes.
> I would like the plots to be transparent, so the first chart is
> not obscured.
> 
> I have tried adjustcolor(..., alpha.f=0.3), the problem is that
> my chromatogram is so dense with datapoints that they
> overlap and the entire graph just ends up a solid color.  The
> second histogram still obscures the first.
> 
> Consider this example:
> 
> 
> col1 <- adjustcolor("red", alpha.f=0.3)
> col2 <- adjustcolor("blue", alpha.f=0.3)
> EU <- data.frame(EuStockMarkets)
> with(EU, plot(DAX, CAC, col=col2, type="h", ylim=c(0,6000)))
> par(new=TRUE)
> with(EU, plot(DAX, FTSE, col=col1, type="h", ylim=c(0,6000)))
> 
> The density of the red plot around 2000 completely obscures the blue
> plot behind it.
> 
> What I would like to do is plot both plots in solid colors, then alpha
> the entire thing, and then overlay them.  Or some other method that
> achieves a comparable result.
> Thanks
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nunub@h @end|ng |rom y@hoo@com  Fri Jun  1 00:37:38 2018
From: nunub@h @end|ng |rom y@hoo@com (Wedaj Bahiru)
Date: Thu, 31 May 2018 22:37:38 +0000 (UTC)
Subject: [R] Help in dynamic simulation using deSolve
References: <530845079.7447270.1527806258446.ref@mail.yahoo.com>
Message-ID: <530845079.7447270.1527806258446@mail.yahoo.com>

Hi R help,
I wanted to simulate two pool model (A&B) using deSolve package for time 0 to 12 by 1.? Initial values of the state variables are A=5, B=3. The fluxes are as follows1) Flux into A= 5 units per unit time?2) Flux from A to B= 0.33) Flux out of A=0.1?4) Flux from B to A=0.35) Flux out of B=0.3
Here is the R code I compiled to estimate the size of A and B and graph the output
library(deSolve)
# Define time sequence from 0 to 12 by 1
time <- seq(0,12, by=1)
# Define the function?
Mod <- function (t, parms){? derivs <- function(t, state, parms){? ? with(as.list (c(state, parms)), {? ? ??? ? ? #Fluxes? ? ??? ? ? inA <- kinA? ? ? AtoB <- kAtoB*A? ? ? Aout <- kAout*A? ? ? inB <- kinB? ? ? BtoA <- kBtoA*B? ? ? Bout <- kBout*B? ? ??? ? ? # Rate of change? ? ? dA <- inA+BtoA-AtoB-Aout? ? ? dB <- inB+AtoB-BtoA-Bout? ? ??? ? ??? ? ? return (list (c(dA, dB)))? ? })? }??? #Step 4: Define some starting values for the pools??? state <- c(A=5, B=3)??? ?return (ode(y=state, times=t,func=derivs, parms=parms, method="rk4"))}
# Starting values of fluxes/parameterspars <- c(kinA=5, kAtoB=0.3, kAout=0.1, kinB=2, kBtoA=0.3, kBout=0.3)
#Model results
Mod(time, pars)data <- data.frame(Mod(time, pars))plot(Mod(time, pars))
The result does not look right. I could not figure out where I made a mistake in compiling code.??
Any help is highly appreciated.?
Wodaj
	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Fri Jun  1 13:20:05 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 1 Jun 2018 11:20:05 +0000
Subject: [R] Time-series moving average question
Message-ID: <SN1PR0201MB18404E4546FE7FF73A50633BEA620@SN1PR0201MB1840.namprd02.prod.outlook.com>

Good morning, I hope someone can help with these questions, or perhaps suggest one of the other R-lists?

I have two questions:


  1.  Why am I getting this warning?
  2.  Why is the second example "Point Forecast" the same value, I do not see that in previous attempts with similar but different data sets as in example 1?

Example1:
dat3 <- structure(c(3539122.86, 3081383.87, 4158672.31, 4137518.78, 4123682.08, 4819375.2, 4342687.77, 5028674.58, 4472145.07, 4967277.73, 4516240.31, 4876194.63, 4816446.59,
                    4887399.37, 5478504.85, 4871385.27, 5487543.68, 5464193.69, 5252591.03, 7071416.89, 5524350.89, 6107166.69, 6530003.55, 6445929.08, 7356743.81, 6750025.03,
                    6934714.08, 6656194.35

                    ,-13913, -29385.31, -39633.37, -23487.13, -18202.86, -57335.49, -26061.45, -60880.07, -17589.45, -35970.08, -89133.94,
                    -84694.58, -31724.89, -29847.95, -65421.74, -34334.22, -48511.98, -30298.97, -38729.46, -29292.89, -46098.4, -65909.49,
                    -85879.23, -71845.28, -69017.07, -93161.03, -70847.29, -85106.04

                    ,-357694.19, -444792.75, -361349.57, -386717.55, -547422.05, -518259.22, -417613.76, -578631.46, -804516.81, -572875.52, -510487.53,
                    -666294.87, -673233.37, -556564.45, -963346.75, -639288.2, -910104.23, -773428.8, -1008078.84, -546685.3, -729932.94, -987098.23,
                    -964001.63, -986995.93, -680066.58, -728854.58, -730766.92, -753861.59)
                    ,.Dim = c(28L, 3L)
                    ,.Dimnames = list(NULL, c("OONNetRev","OONAdjusted" ,"OONCancelled"))
                    ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
head(dat3); nrow(dat3)

TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
TNR_moving_average

# Warning message:
#   In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
#            Missing values encountered. Using longest contiguous portion of time series
#          > Point Forecast         Lo 80         Hi 80         Lo 95         Hi 95
#         28  7007065.99688 6675015.72012 7339116.27365 6499238.92148 7514893.07229
#         29  7135745.42473 6721543.41996 7549947.42950 6502278.12345 7769212.72601
#         30  7264424.85258 6779532.18065 7749317.52450 6522845.50541 8006004.19974
#         31  7393104.28042 6844496.10189 7941712.45896 6554080.47486 8232128.08599
#         32  7521783.70827 6914203.11991 8129364.29663 6592569.38486 8450998.03168
#         33  7650463.13612 6987355.72657 8313570.54567 6636327.86794 8664598.40429
#         34  7779142.56396 7063123.29787 8495161.83005 6684085.59434 8874199.53358
#         35  7907821.99181 7140937.69145 8674706.29217 6734973.66528 9080670.31834




Example2:
dat3 <- structure(c(994320.58, 811664.54, 1045259.43, 951659.48, 669458.94, 986741.09, 1023344.82, 938971.65, 897670.06, 1040074.6, 1090310.01,
                    1289821.17, 1187806.23, 971485.76, 1161147.42, 870585.04, 1021301.52, 1215798.03, 1015004.43, 1365863.09, 995769.41,
                    1331725.36, 1271032.91, 1092103.82, 1297131.4, 1129195.28, 1372594.58, 1553717.57,

                    -39811.51, -47356.74, -49046.86, -41311.13, -79063.98, -43916.59, -16746.33, -38347.9, -84797.44, -38961.44,
                    -72036.83, -62854.78, -35259.84, -44198.39, -34262.65, -49245.82, -34977.28, -36797.35, -47534.43, -33515.13,
                    -25764.41, -29130.53, -57693.63, -51026.83, -49624.49, -36508.13, -32667.21, -37900.5,

                    -247443.87, -372942.34, -344080.78, -355586.21, -458998.84, -378086.44, -333994.18, -567024.45, -521499.8, -428915.13,
                    -512034.28, -440865.42, -347494.22, -422436.19, -444588.65, -462891.57, -518395.47, -373818.5, -398899.53, -381573.69,
                    -531449.2, -476238.48, -434296.86, -655679.94, -528999.52, -423725.95, -556977.31, -518633.95)
                  ,.Dim = c(28L, 3L)
                  ,.Dimnames = list(NULL, c("EditNetRev","EditNetAdjusted" ,"EditNetCancelled"))
                  ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
head(dat3); nrow(dat3)



TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
TNR_moving_average

# Warning message:
# In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
#          Missing values encountered. Using longest contiguous portion of time series
#        > TNR_moving_average
#        Point Forecast         Lo 80         Hi 80          Lo 95         Hi 95
#        28  1351827.24389 1246570.02118 1457084.46661 1190850.213255 1512804.27453
#        29  1351827.24389 1202841.21791 1500813.26987 1123972.779844 1579681.70794
#        30  1351827.24389 1169192.03201 1534462.45578 1072510.790913 1631143.69687
#        31  1351827.24389 1140745.29674 1562909.19105 1029005.263624 1674649.22416
#        32  1351827.24389 1115613.58783 1588040.89996  990569.631639 1713084.85615
#        33  1351827.24389 1092829.78856 1610824.69923  955724.817592 1747929.67020
#        34  1351827.24389 1071819.89899 1631834.58880  923592.964312 1780061.52348
#        35  1351827.24389 1052210.25675 1651444.23104  893602.604521 1810051.88327

Thank you for any advice or direction.


WHP



Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From @@h|mk@poor @end|ng |rom gm@||@com  Fri Jun  1 14:00:21 2018
From: @@h|mk@poor @end|ng |rom gm@||@com (Ashim Kapoor)
Date: Fri, 1 Jun 2018 17:30:21 +0530
Subject: [R] Last page on a multi page, faceted graph created using ggforce,
 loses its layout under a certain condition
Message-ID: <CAC8=1epkp9Wf446udo11Vk=He1_CciJ38w_9U-kkbHTzXn--Cw@mail.gmail.com>

Dear All,

I posted this query on stack overflow but I received no replies so I am
posting it here so that someone here can take a look at this.

My query is that suppose the variable I am faceting by has 40 categories
and I want 3 categories per page( 1 row x 3 columns),then the last category
fills the entire second page. I want the last category to fill only the
left - most position in the grid and the remaining 2 places to be empty on
the last page.

Here is the link to the stackoverflow query which has a reprex in it as
well:

https://stackoverflow.com/questions/50604211/facetting-a-graph-across-multiple-pages-and-keeping-the-same-layout-on-all-pag

Many thanks and Best Regards,
Ashim

	[[alternative HTML version deleted]]



From md@umner @end|ng |rom gm@||@com  Fri Jun  1 14:14:23 2018
From: md@umner @end|ng |rom gm@||@com (Michael Sumner)
Date: Fri, 1 Jun 2018 22:14:23 +1000
Subject: [R] Problem with adding a raster and a brick
In-Reply-To: <CAAcGz9-fKOWXMawV5ygUdrk7qnfcFqxhnvyhG9rvVH+W5r3dzQ@mail.gmail.com>
References: <CAGBzUO-LrEB7kfKBvGD=uD+5Dh6-UXdqQhXTBbZBVCDpALMYSg@mail.gmail.com>
 <CAAcGz9-fKOWXMawV5ygUdrk7qnfcFqxhnvyhG9rvVH+W5r3dzQ@mail.gmail.com>
Message-ID: <CAAcGz98ib=gfC6B5bTE0ZPCZoTbFM3nPinpAhiQWqTqp7B6cAg@mail.gmail.com>

This is now fixed in development on RForge, you can try it out by
installing from there, or from the Github mirror with
devtools::install_github("rforge/raster/pkg/raster").

(To get fixes into raster email the maintainer directly - you might not get
a response but it'll be addressed).

Cheers, Mike.


On Thu, 24 May 2018 at 20:08 Michael Sumner <mdsumner at gmail.com> wrote:

>
>
>
> On Thu, 24 May 2018 at 18:41 Mark R Payne <markpayneatwork at gmail.com>
> wrote:
>
> Hi,
>
> I seem to be having a problem adding the following two raster objects
> together - one is a rasterLayer, the other is a rasterBrick. The extent,
> resolution, and origin are the same, so according to my understand it
> should work. The objects look like so:
>
> > obs.clim
> class : RasterLayer
> dimensions : 60, 200, 12000 (nrow, ncol, ncell)
> resolution : 0.5, 0.5 (x, y)
> extent : -70, 30, 50, 80 (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
> /home/mpayne/Documents/Predictability_engine/scratch/Bluefin/HadISST/
> obs_climatology.nc
> names : sst
> z-value : 1988-02-15
> zvar : sst
>
> > mdl.anom
> class : RasterBrick
> dimensions : 60, 200, 12000, 1 (nrow, ncol, ncell, nlayers)
> resolution : 0.5, 0.5 (x, y)
> extent : -70, 30, 50, 80 (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
>
> /home/mpayne/Documents/Predictability_engine/scratch/Bluefin/DCPP-hindcasts/IPSL-CM5A-LR/B.realmean/IPSL-CM5A-LR_S19610101_L000000_realmean_
> anom.nc
>
> names : X1961.08.16
> Date : 1961-08-16
> varname : tos
>
> When I try to add them together, I get the follow error:
>
> > mdl.val <- obs.clim + mdl.anom
> Error in .readRowsNetCDF(x = x, row = row, nrows = nrows, col = col, ncols
> = ncols) :
> no slot of name "band" for this object of class ".MultipleRasterData"
> >
>
> I can reproduce, with netcf-file-backed bricks. I would try
>
> obs.clim[[1]] + mdl.anom[[1]]
>
> or
>
> readAll(obs.clim) + readAll(mdl.anom)
>
> those differ mainly in what will happen to multi-layer versions of the
> files, the first will give just the first layer. The key is breaking the
> file-read-delay, both objects have no data in memory but the add operation
> invalidates and causes read to occur - but with a bug - (I will check in
> dev raster and report if necessary).
>
> FYI, R-Sig-Geo is generally a better forum for spatial stuff:
> https://stat.ethz.ch/mailman/listinfo/r-sig-geo
>
> Cheers, Mike.
>
>
> I get the same error if I treat mdl.anom as a raster, or if they are both
> bricks. Any suggestions what could be going wrong? Installation details
> below
>
> Best wishes,
>
> Mark
>
> > R.version
> _
> platform x86_64-pc-linux-gnu
> arch x86_64
> os linux-gnu
> system x86_64, linux-gnu
> status
> major 3
> minor 4.2
> year 2017
> month 09
> day 28
> svn rev 73368
> language R
> version.string R version 3.4.2 (2017-09-28)
> nickname Short Summer
> >
> > packageDescription("raster")
> Package: raster
> Type: Package
> Title: Geographic Data Analysis and Modeling
> Version: 2.6-7
> Date: 2017-11-12
>
> > packageDescription("ncdf4")
> Package: ncdf4
> Version: 1.16
> Date: 2017-04-01
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> <http://www.r-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
> --
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Fri Jun  1 15:08:53 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Fri, 1 Jun 2018 18:38:53 +0530
Subject: [R] Unable to take correct Web-snapshot
Message-ID: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>

Hi again,

I use the *webshot* package to take snapshot from Webpage. However, when I
try to take snapshot from* https://www.coinbase.com/
<https://www.coinbase.com/>*, this fails to take the full snapshot of that
page.

I tried following :

> library(webshot)
> webshot("https://www.coinbase.com/", 'aa.pdf')

However in the pdf page, I done see the quotes which are available on the
main page in the 4 boxes.

Any help how to resolve this would be highly appreciated.

Thanks,

	[[alternative HTML version deleted]]



From tr@xp|@yer @end|ng |rom gm@||@com  Fri Jun  1 17:05:40 2018
From: tr@xp|@yer @end|ng |rom gm@||@com (=?UTF-8?Q?Martin_M=C3=B8ller_Skarbiniks_Pedersen?=)
Date: Fri, 1 Jun 2018 17:05:40 +0200
Subject: [R] Unable to take correct Web-snapshot
In-Reply-To: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
References: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
Message-ID: <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>

On 1 June 2018 at 15:08, Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> Hi again,
>
> I use the *webshot* package to take snapshot from Webpage. However, when I
> try to take snapshot from* https://www.coinbase.com/
> <https://www.coinbase.com/>*, this fails to take the full snapshot of that
> page.

Yes, that is a general problem with many webshot programs and libraries.

The coinbase page ( and many others ) uses a lot of javascript to generate their
pages and the webshot programs must understand javascript in all
details which is hard.

If you are looking for the coinbase prices you can use their api to
get json instead:

https://api.coinbase.com/v2/prices/spot?currency=USD

Regards
Martin



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Fri Jun  1 17:12:57 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Fri, 1 Jun 2018 20:42:57 +0530
Subject: [R] Unable to take correct Web-snapshot
In-Reply-To: <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>
References: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
 <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>
Message-ID: <CA+dpOJ=u+j1Xd1D+k8Er403A5-LMp=ozH=eBL2=Ytjs6CWkqKw@mail.gmail.com>

Thanks for that information.

However how can I use R to directly get data from that API?

On Fri, Jun 1, 2018 at 8:36 PM Martin M?ller Skarbiniks Pedersen <
traxplayer at gmail.com> wrote:

> On 1 June 2018 at 15:08, Christofer Bogaso <bogaso.christofer at gmail.com>
> wrote:
> > Hi again,
> >
> > I use the *webshot* package to take snapshot from Webpage. However, when
> I
> > try to take snapshot from* https://www.coinbase.com/
> > <https://www.coinbase.com/>*, this fails to take the full snapshot of
> that
> > page.
>
> Yes, that is a general problem with many webshot programs and libraries.
>
> The coinbase page ( and many others ) uses a lot of javascript to generate
> their
> pages and the webshot programs must understand javascript in all
> details which is hard.
>
> If you are looking for the coinbase prices you can use their api to
> get json instead:
>
> https://api.coinbase.com/v2/prices/spot?currency=USD
>
> Regards
> Martin
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Jun  1 17:23:40 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 1 Jun 2018 15:23:40 +0000
Subject: [R] Time-series moving average question
Message-ID: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>

My guess would be that if you inspect the output from
    ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/1/18, 4:20 AM, "R-help on behalf of Bill Poling" <r-help-bounces at r-project.org on behalf of Bill.Poling at zelis.com> wrote:

    Good morning, I hope someone can help with these questions, or perhaps suggest one of the other R-lists?
    
    I have two questions:
    
    
      1.  Why am I getting this warning?
      2.  Why is the second example "Point Forecast" the same value, I do not see that in previous attempts with similar but different data sets as in example 1?
    
    Example1:
    dat3 <- structure(c(3539122.86, 3081383.87, 4158672.31, 4137518.78, 4123682.08, 4819375.2, 4342687.77, 5028674.58, 4472145.07, 4967277.73, 4516240.31, 4876194.63, 4816446.59,
                        4887399.37, 5478504.85, 4871385.27, 5487543.68, 5464193.69, 5252591.03, 7071416.89, 5524350.89, 6107166.69, 6530003.55, 6445929.08, 7356743.81, 6750025.03,
                        6934714.08, 6656194.35
    
                        ,-13913, -29385.31, -39633.37, -23487.13, -18202.86, -57335.49, -26061.45, -60880.07, -17589.45, -35970.08, -89133.94,
                        -84694.58, -31724.89, -29847.95, -65421.74, -34334.22, -48511.98, -30298.97, -38729.46, -29292.89, -46098.4, -65909.49,
                        -85879.23, -71845.28, -69017.07, -93161.03, -70847.29, -85106.04
    
                        ,-357694.19, -444792.75, -361349.57, -386717.55, -547422.05, -518259.22, -417613.76, -578631.46, -804516.81, -572875.52, -510487.53,
                        -666294.87, -673233.37, -556564.45, -963346.75, -639288.2, -910104.23, -773428.8, -1008078.84, -546685.3, -729932.94, -987098.23,
                        -964001.63, -986995.93, -680066.58, -728854.58, -730766.92, -753861.59)
                        ,.Dim = c(28L, 3L)
                        ,.Dimnames = list(NULL, c("OONNetRev","OONAdjusted" ,"OONCancelled"))
                        ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
    head(dat3); nrow(dat3)
    
    TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
    TNR_moving_average
    
    # Warning message:
    #   In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
    #            Missing values encountered. Using longest contiguous portion of time series
    #          > Point Forecast         Lo 80         Hi 80         Lo 95         Hi 95
    #         28  7007065.99688 6675015.72012 7339116.27365 6499238.92148 7514893.07229
    #         29  7135745.42473 6721543.41996 7549947.42950 6502278.12345 7769212.72601
    #         30  7264424.85258 6779532.18065 7749317.52450 6522845.50541 8006004.19974
    #         31  7393104.28042 6844496.10189 7941712.45896 6554080.47486 8232128.08599
    #         32  7521783.70827 6914203.11991 8129364.29663 6592569.38486 8450998.03168
    #         33  7650463.13612 6987355.72657 8313570.54567 6636327.86794 8664598.40429
    #         34  7779142.56396 7063123.29787 8495161.83005 6684085.59434 8874199.53358
    #         35  7907821.99181 7140937.69145 8674706.29217 6734973.66528 9080670.31834
    
    
    
    
    Example2:
    dat3 <- structure(c(994320.58, 811664.54, 1045259.43, 951659.48, 669458.94, 986741.09, 1023344.82, 938971.65, 897670.06, 1040074.6, 1090310.01,
                        1289821.17, 1187806.23, 971485.76, 1161147.42, 870585.04, 1021301.52, 1215798.03, 1015004.43, 1365863.09, 995769.41,
                        1331725.36, 1271032.91, 1092103.82, 1297131.4, 1129195.28, 1372594.58, 1553717.57,
    
                        -39811.51, -47356.74, -49046.86, -41311.13, -79063.98, -43916.59, -16746.33, -38347.9, -84797.44, -38961.44,
                        -72036.83, -62854.78, -35259.84, -44198.39, -34262.65, -49245.82, -34977.28, -36797.35, -47534.43, -33515.13,
                        -25764.41, -29130.53, -57693.63, -51026.83, -49624.49, -36508.13, -32667.21, -37900.5,
    
                        -247443.87, -372942.34, -344080.78, -355586.21, -458998.84, -378086.44, -333994.18, -567024.45, -521499.8, -428915.13,
                        -512034.28, -440865.42, -347494.22, -422436.19, -444588.65, -462891.57, -518395.47, -373818.5, -398899.53, -381573.69,
                        -531449.2, -476238.48, -434296.86, -655679.94, -528999.52, -423725.95, -556977.31, -518633.95)
                      ,.Dim = c(28L, 3L)
                      ,.Dimnames = list(NULL, c("EditNetRev","EditNetAdjusted" ,"EditNetCancelled"))
                      ,.Tsp = c(2016, 2018.25, 12), class = c("mts", "ts", "matrix"))
    head(dat3); nrow(dat3)
    
    
    
    TNR_moving_average <- forecast(ma(dat3[1:28], order=3), h=8)
    TNR_moving_average
    
    # Warning message:
    # In ets(object, lambda = lambda, biasadj = biasadj, allow.multiplicative.trend = allow.multiplicative.trend,  :
    #          Missing values encountered. Using longest contiguous portion of time series
    #        > TNR_moving_average
    #        Point Forecast         Lo 80         Hi 80          Lo 95         Hi 95
    #        28  1351827.24389 1246570.02118 1457084.46661 1190850.213255 1512804.27453
    #        29  1351827.24389 1202841.21791 1500813.26987 1123972.779844 1579681.70794
    #        30  1351827.24389 1169192.03201 1534462.45578 1072510.790913 1631143.69687
    #        31  1351827.24389 1140745.29674 1562909.19105 1029005.263624 1674649.22416
    #        32  1351827.24389 1115613.58783 1588040.89996  990569.631639 1713084.85615
    #        33  1351827.24389 1092829.78856 1610824.69923  955724.817592 1747929.67020
    #        34  1351827.24389 1071819.89899 1631834.58880  923592.964312 1780061.52348
    #        35  1351827.24389 1052210.25675 1651444.23104  893602.604521 1810051.88327
    
    Thank you for any advice or direction.
    
    
    WHP
    
    
    
    Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From B|||@Po||ng @end|ng |rom ze||@@com  Fri Jun  1 17:57:22 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 1 Jun 2018 15:57:22 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
Message-ID: <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From m@cqueen1 @end|ng |rom ||n|@gov  Fri Jun  1 18:54:16 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 1 Jun 2018 16:54:16 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

  tnr.ma <- ma(dat3[1:28], order=3)
  TNR_moving_average <- forecast(tnr.ma, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
?


From: Bill Poling <Bill.Poling at zelis.com>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov>, array R-help <r-help at r-project.org>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help. 
?
I am using the forecast package, originally I found it following a forecasting example on bloggers.com 
?
https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/
?
And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf
?
Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?
?
No worries though, I am going to reach out to the package author.
?
Cheers. 
?
WHP
?
From: MacQueen, Don [mailto:macqueen1 at llnl.gov] 
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question
?
My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018. 


From m@n|@hmukherjee @end|ng |rom hotm@||@com  Fri Jun  1 19:20:50 2018
From: m@n|@hmukherjee @end|ng |rom hotm@||@com (Manish Mukherjee)
Date: Fri, 1 Jun 2018 17:20:50 +0000
Subject: [R] Issue with batch forecasting of Time series data
Message-ID: <MAXPR0101MB148442C572FAC9C08E9460B2B9620@MAXPR0101MB1484.INDPRD01.PROD.OUTLOOK.COM>

Hi,


i have a weekly data for servers for 62 weeks. want to predict the cpu% for next 5 weeks.I am trying to forecast for many servers at once but with the code i am getting only one week of future forecast for all the servers. Also the week date for the predicted week is showing as the last week of the original data . Need help in two things How can i change the date for the predicted  week, and  how can i predict for more than one week.


R code.

input_data <- read.csv("input.csv", header= TRUE)
head(input_data)
str(input_data)
library("forecast")
library("DBI")
library("RPostgreSQL")
library("lubridate")
Products = unique(input_data["Server.Name"][,])
output = matrix(0,nrow=(length(Products)*(1)),ncol=7)
colnames(output) =

  c(
    "Product",
    "DATE",
    "Forecast",
    "Lo_80",
    "Hi_80 ",
    "Lo_95",
    "Hi_95"
  )

for (i in Products) {

 train = head(input_data["PERCENT_USED"][input_data["Server.Name"]==i] , 90)

  train     = ts(train[1:(length(train))])

  fc1 = auto.arima(train)
  pred1 = forecast( fc1)
  fit1_acry   = accuracy(pred1)
  fc2 = ets(train)
  pred2 = forecast( fc2 )
  fit2_acry = accuracy(pred2 )

  MAPE = data.frame ( fit1_MAPE = fit1_acry[,'MAPE'],
                       fit2_MAPE = fit2_acry[,'MAPE']
  )

  best =  which.min(MAPE)

  BestModel = get(paste('fc',best,sep=""))

  forecastoutput = rbind(data.frame(forecast(BestModel, h=1)) )
  forecast_date = rbind(tail(input_data["DATE"][input_data["Server.Name"]==i],(1)))
  row_index = which(Products==i)

  output[row_index,1]   = i
  output[row_index,2]   = forecast_date
  output[row_index,3]   = (round(forecastoutput$Point.Forecast,2))
  output[row_index,4]   = as.numeric(round(forecastoutput$Lo.80,2))
  output[row_index,5]   = as.numeric(round(forecastoutput$Hi.80,2))
  output[row_index,6]   = as.numeric(round(forecastoutput$Lo.95,2))
  output[row_index,7] = as.numeric(round(forecastoutput$Hi.95,2))
  output_onestep = data.frame(output)

}
output_onestep



	[[alternative HTML version deleted]]



From chr|@t|@n @end|ng |rom echo||m@nn@ch  Fri Jun  1 16:25:01 2018
From: chr|@t|@n @end|ng |rom echo||m@nn@ch (Christian)
Date: Fri, 1 Jun 2018 16:25:01 +0200
Subject: [R] values of list of variable names
Message-ID: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>

Hi,

I have searched the documentations of eval, substitute, expression, and 
I cannot make work something like the values of a list of variable names:

lis <- ls(pattern="pr") # all variables with names containing 'pr'

What is the mantra giving me the _values_ of the variables whose names 
are  contained in 'lis'. eval(parse(ls(pattern="pr"))) will not do but 
returning TRUE.

TIA
C.
-- 
Christian Hoffmann
Rigiblickstrasse 15b
CH-8915 Hausen am Albis
Switzerland
Telefon +41-(0)44-7640853



From nguy2952 @end|ng |rom umn@edu  Fri Jun  1 17:54:03 2018
From: nguy2952 @end|ng |rom umn@edu (nguy2952 University of Minnesota)
Date: Fri, 1 Jun 2018 10:54:03 -0500
Subject: [R] Regroup and create new dataframe
Message-ID: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>

Hello folks,

I have a big project to work on and the dataset is classified so I am just
going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target
brand, 3M and Avery. The original data frame has 4 columns: Year of Record,
Product_Name(which contains three brands of tape), Sales, and Region. I
want to create a new data frame that looks like this:

                      Year of Record       Sales     Region
  Target Brand
  3M
  Avery

Here is what I did.

   1.

   I split the original data frame which I called data1:

   X = split(data1, Product_name)

   2.

   Unlist X

   X1 = unlist(X)

   3.

   Create a new data frame

   new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left
one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different
regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to
those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Fri Jun  1 19:42:31 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 1 Jun 2018 17:42:31 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
Message-ID: <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi Don, wow, you are so right. I picked that piece up from the bloggers tutorial and since I am R naive yet, I thought it was all one step

moving_average = forecast(ma(tdat[1:31], order=2), h=5)

Truly, I usually print and check at every step I can, as painful as it is sometimes.
Great lesson for this novice usR.

So the first and last values are NA in each case? Do you know why? Should I replace the NA with a value, say the average of the others?

Also, I have 5 series of data I am working with using this script and of course each gave me that warning, but only the one series had the same 8 Point Forecast values, is that coincidental you think?

Terrific of you to help, I really appreciate it.

WHP


From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 12:54 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

tnr.ma<http://tnr.ma> <- ma(dat3[1:28], order=3)
TNR_moving_average <- forecast(tnr.ma<http://tnr.ma>, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma<http://tnr.ma> and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com<http://bloggers.com>

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/<https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/>

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf<https://cran.r-project.org/web/packages/forecast/forecast.pdf>

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From wdun|@p @end|ng |rom t|bco@com  Fri Jun  1 19:52:13 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 1 Jun 2018 10:52:13 -0700
Subject: [R] values of list of variable names
In-Reply-To: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
References: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
Message-ID: <CAF8bMcbcQaQFh+TaL5q3H8TXUto2EGT_sUY79k+OJxKbXuWQEA@mail.gmail.com>

One way is
   values <- lapply(lis, get)
You can do
   names(values) <- lis
to attach the object names to the values in the list returned by lapply.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 1, 2018 at 7:25 AM, Christian <christian at echoffmann.ch> wrote:

> Hi,
>
> I have searched the documentations of eval, substitute, expression, and I
> cannot make work something like the values of a list of variable names:
>
> lis <- ls(pattern="pr") # all variables with names containing 'pr'
>
> What is the mantra giving me the _values_ of the variables whose names
> are  contained in 'lis'. eval(parse(ls(pattern="pr"))) will not do but
> returning TRUE.
>
> TIA
> C.
> --
> Christian Hoffmann
> Rigiblickstrasse 15b
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From d|m|tr|joe @end|ng |rom gm@||@com  Fri Jun  1 20:26:51 2018
From: d|m|tr|joe @end|ng |rom gm@||@com (Dimitri Szerman)
Date: Fri, 1 Jun 2018 15:26:51 -0300
Subject: [R] rasterize SpatialPolygon object using a RasterBrick object
Message-ID: <CAJcfORJdivKJRntDrq-igrv-FXDPL23yiKCT4n63jirGepjqEQ@mail.gmail.com>

I am trying to rasterize a SpatialPolygon object by a RasterBrick object.
The documentation of the raster::rasterize function explicitly says this is
allowed. Here's what I am doing

# load the raster package
library("raster")
# create a raster brick object using the example from the brick
function documentation
b <- brick(system.file("external/rlogo.grd", package="raster"))
b
nlayers(b)
names(b)
extract(b, 870)
# create a SpatialPolygon object using the example from the function
documentation
Sr1 = Polygon(10*cbind(c(2,4,4,1,2),10*c(2,3,5,4,2)))
Sr2 = Polygon(10*cbind(c(5,4,2,5),10*c(2,3,2,2)))
Sr3 = Polygon(10*cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
Sr4 = Polygon(10*cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)

Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr3, Sr4), "s3/4")
SpP = SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3)

plot(b[[1]])
plot(SpP, add = T)
# crop
clip1 = crop(b, extent(SpP))
# rasterize returns an error, but documentation says it should return
a RasterBrick object
clip2 = rasterize(SpP, b, mask = T)
Error in v[, r] <- rrv :
     number of items to replace is not a multiple of replacement length
# however, if I used only one layer, all would be fine
clip2 = rasterize(SpP, b[[1]], mask = T)

Of course, I could loop over the brick's layers, but as I understand it,
that would defeat the purpose of a brick object.

I want to use clip2 to then get the histogram of pixel values in the
layers, like this:

vals = getValues(clip2)

Can anyone tell me why I am getting this error, and how to go around it
efficiently?

	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Fri Jun  1 20:55:47 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Fri, 1 Jun 2018 18:55:47 +0000
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
Message-ID: <da3839d03c474079afdcd05514df4a08@tamu.edu>

Your question raises several issues. First, we do not do homework here, so if this is an assignment, you will not get much help. Second, you need to send your emails as plain text, not html. Third, you need to provide a reproducible example and send your data using dput() so that we can follow what you have tried so far. For example, here's a data set that resembles what you have described:

set.seed(42)
Tape <- data.frame(Year=2011:2015, Product=rep(c("Target", "3M", "Avery"),
     each=5), Sales=sample(1000:2000, 15), Region=rep(c("North", "South",
     "West"), each=5), stringsAsFactors=FALSE)
dput(Tape)
structure(list(Year = c(2011L, 2012L, 2013L, 2014L, 2015L, 2011L, 
2012L, 2013L, 2014L, 2015L, 2011L, 2012L, 2013L, 2014L, 2015L
), Product = c("Target", "Target", "Target", "Target", "Target", 
"3M", "3M", "3M", "3M", "3M", "Avery", "Avery", "Avery", "Avery", 
"Avery"), Sales = c(1915L, 1937L, 1285L, 1828L, 1639L, 1517L, 
1732L, 1133L, 1652L, 1699L, 1453L, 1711L, 1924L, 1252L, 1456L
), Region = c("North", "North", "North", "North", "North", "South", 
"South", "South", "South", "South", "West", "West", "West", "West", 
"West")), .Names = c("Year", "Product", "Sales", "Region"), row.names = c(NA, 
-15L), class = "data.frame")

It is not clear what you want in your new data frame. This one has 5 years of data for each tape brand and you seem to want one row for each tape brand? Tables created in html and then sent to a plain text mailing list can be dramatically different from the original format. It is not clear that you cannot answer your questions from the data as presented here. Look at the results of unlist(split(Tape, Tape$Product)). You should see that this is nowhere near what you described.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of nguy2952 University of Minnesota
Sent: Friday, June 1, 2018 10:54 AM
To: r-help at r-project.org
Subject: [R] Regroup and create new dataframe

Hello folks,

I have a big project to work on and the dataset is classified so I am just going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target brand, 3M and Avery. The original data frame has 4 columns: Year of Record, Product_Name(which contains three brands of tape), Sales, and Region. I want to create a new data frame that looks like this:

                      Year of Record       Sales     Region
  Target Brand
  3M
  Avery

Here is what I did.

   1.

   I split the original data frame which I called data1:

   X = split(data1, Product_name)

   2.

   Unlist X

   X1 = unlist(X)

   3.

   Create a new data frame

   new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun  1 20:58:13 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 1 Jun 2018 19:58:13 +0100
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
Message-ID: <dab8572f-405e-6e2c-d6e0-2c8215138a95@sapo.pt>

Hello,

I don't understand why you are splitting data1 and then unlisting the 
result.

if you want to apply a modeling function to each of the subdf's, split 
by Product name, you can follow more or less these steps:

0. Create a dataset

set.seed(9376)??? # Make the results reproducible

n <- 100
PN <- c("Target Brand", "3M", "Avery")
data1 <- data.frame(Product_name = sample(PN, n, TRUE),
 ??????????????????? Year_of_Record = sample(2011:2018, n, TRUE),
 ??????????????????? Sales = runif(n, 10, 1000),
 ??????????????????? Region = sample(letters[1:5], n, TRUE)
 ??????????????????? )

head(data1)


1. Split the dataset by product name. Thsi gives a list of subdf's.


X <- split(data1, data1$Product_name)


2. Now lappy a modeling function to each subdf.


modelFun <- function(DF){

 ??? lm(Sales ~ Region, data = DF)

}

model_list <- lapply(X, modelFun )
model_smry <- lapply(model_list, summary)
model_smry[[1]]
#
#Call:
#? lm(formula = Sales ~ Region, data = DF)
#
#Residuals:
#? Min????? 1Q? Median????? 3Q???? Max
#-487.41 -196.17??? 1.76? 195.96? 498.48
#
#Coefficients:
#? Estimate Std. Error t value Pr(>|t|)
#(Intercept)? 437.300??? 108.147?? 4.044 0.000355 ***
#? Regionb????? 437.019??? 167.540?? 2.608 0.014229 *
#? Regionc????? 102.989??? 179.341?? 0.574 0.570217
#Regiond????? 105.520??? 152.942?? 0.690 0.495721
#Regione?????? -5.638??? 138.342? -0.041 0.967773
#---
#? Signif. codes:? 0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
#
#Residual standard error: 286.1 on 29 degrees of freedom
#Multiple R-squared:? 0.2426,??? Adjusted R-squared:? 0.1381
#F-statistic: 2.322 on 4 and 29 DF,? p-value: 0.08039

Hope this helps,


Rui Barradas


?s 16:54 de 01-06-2018, nguy2952 University of Minnesota escreveu:
> Hello folks,
>
> I have a big project to work on and the dataset is classified so I am just
> going to use my own example so everyone can understand what I am targeting.
>
> Let's take Target as an example: We consider three brands of tape: Target
> brand, 3M and Avery. The original data frame has 4 columns: Year of Record,
> Product_Name(which contains three brands of tape), Sales, and Region. I
> want to create a new data frame that looks like this:
>
>                        Year of Record       Sales     Region
>    Target Brand
>    3M
>    Avery
>
> Here is what I did.
>
>     1.
>
>     I split the original data frame which I called data1:
>
>     X = split(data1, Product_name)
>
>     2.
>
>     Unlist X
>
>     X1 = unlist(X)
>
>     3.
>
>     Create a new data frame
>
>     new_df = as.data.frame(X1)
>
>
> But, when I used the command View(new_df), I had only two columns: The left
> one is similar to TargetBrand.Sales, etc. and the right one is just "X1"
>
> I did not achieve what I wanted.
>
> **A potentially big question from readers:*
>
> Why am I doing this?
>
> *Answer:*
>
> I want to run a multiple regression model later to see among different
> regions, what the sales look like for these three brands of tape:
>
> *Does Mid-west buy more house brand than East Coast?*
>
> or
>
> *Does region really affect the sales? Are Mid-West's purchases similar to
> those of East Coast and West Coast?*
>
> I need help. Please give me guidance.
>
> Sincerely,
> Hugh N
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dc@r|@on @end|ng |rom t@mu@edu  Fri Jun  1 21:09:43 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Fri, 1 Jun 2018 19:09:43 +0000
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwX_=5Ov3i1EPJrVzqWQ5r1LDCRw-v9YQ7Sn=wF6f_JabQ@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
 <da3839d03c474079afdcd05514df4a08@tamu.edu>
 <CAPjFEwX_=5Ov3i1EPJrVzqWQ5r1LDCRw-v9YQ7Sn=wF6f_JabQ@mail.gmail.com>
Message-ID: <9acc43d429f1417cbe4efcd7b388946b@tamu.edu>

Responses should be copied to r-help using ReplyAll. You are still sending html formatted emails. If you are using Microsoft Outlook, click the Format Text tab and select ?Aa Plain Text?. No one has asked you to reveal the data set, only to create one with a similar structure. Is the data I sent reasonably close? What should it look like after it is transformed? 

David C

From: nguy2952 University of Minnesota <nguy2952 at umn.edu> 
Sent: Friday, June 1, 2018 1:57 PM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Regroup and create new dataframe

Hi,
This is not an assignment for school.
This is a project at WORK.?
I am not allowed to reveal the dataset.

Thanks!

On Fri, Jun 1, 2018 at 1:55 PM, David L Carlson <mailto:dcarlson at tamu.edu> wrote:
Your question raises several issues. First, we do not do homework here, so if this is an assignment, you will not get much help. Second, you need to send your emails as plain text, not html. Third, you need to provide a reproducible example and send your data using dput() so that we can follow what you have tried so far. For example, here's a data set that resembles what you have described:

set.seed(42)
Tape <- data.frame(Year=2011:2015, Product=rep(c("Target", "3M", "Avery"),
? ? ?each=5), Sales=sample(1000:2000, 15), Region=rep(c("North", "South",
? ? ?"West"), each=5), stringsAsFactors=FALSE)
dput(Tape)
structure(list(Year = c(2011L, 2012L, 2013L, 2014L, 2015L, 2011L, 
2012L, 2013L, 2014L, 2015L, 2011L, 2012L, 2013L, 2014L, 2015L
), Product = c("Target", "Target", "Target", "Target", "Target", 
"3M", "3M", "3M", "3M", "3M", "Avery", "Avery", "Avery", "Avery", 
"Avery"), Sales = c(1915L, 1937L, 1285L, 1828L, 1639L, 1517L, 
1732L, 1133L, 1652L, 1699L, 1453L, 1711L, 1924L, 1252L, 1456L
), Region = c("North", "North", "North", "North", "North", "South", 
"South", "South", "South", "South", "West", "West", "West", "West", 
"West")), .Names = c("Year", "Product", "Sales", "Region"), row.names = c(NA, 
-15L), class = "data.frame")

It is not clear what you want in your new data frame. This one has 5 years of data for each tape brand and you seem to want one row for each tape brand? Tables created in html and then sent to a plain text mailing list can be dramatically different from the original format. It is not clear that you cannot answer your questions from the data as presented here. Look at the results of unlist(split(Tape, Tape$Product)). You should see that this is nowhere near what you described.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <mailto:r-help-bounces at r-project.org> On Behalf Of nguy2952 University of Minnesota
Sent: Friday, June 1, 2018 10:54 AM
To: mailto:r-help at r-project.org
Subject: [R] Regroup and create new dataframe

Hello folks,

I have a big project to work on and the dataset is classified so I am just going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target brand, 3M and Avery. The original data frame has 4 columns: Year of Record, Product_Name(which contains three brands of tape), Sales, and Region. I want to create a new data frame that looks like this:

? ? ? ? ? ? ? ? ? ? ? Year of Record? ? ? ?Sales? ? ?Region
? Target Brand
? 3M
? Avery

Here is what I did.

? ?1.

? ?I split the original data frame which I called data1:

? ?X = split(data1, Product_name)

? ?2.

? ?Unlist X

? ?X1 = unlist(X)

? ?3.

? ?Create a new data frame

? ?new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=nPZ3F6nROsY3KM0z7y6ixAAYLjMGVhEZyuXMi3bg0rY&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=XNpVm_6i2GLFLk3FzpM9T15aezUet1BA0FlapuVXdmc&e=
and provide commented, minimal, self-contained, reproducible code.


From dc@r|@on @end|ng |rom t@mu@edu  Fri Jun  1 21:35:24 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Fri, 1 Jun 2018 19:35:24 +0000
Subject: [R] Regroup and create new dataframe
In-Reply-To: <CAPjFEwUoz9wkgh+i3StzVPcvjXWm0mYwZGZfMYUqM8+SbMY-9Q@mail.gmail.com>
References: <CAPjFEwXi9GRFKeE48s5z=nS=5mDBcmvNRgvXCE_xxSLUpF0KrA@mail.gmail.com>
 <da3839d03c474079afdcd05514df4a08@tamu.edu>
 <CAPjFEwX_=5Ov3i1EPJrVzqWQ5r1LDCRw-v9YQ7Sn=wF6f_JabQ@mail.gmail.com>
 <9acc43d429f1417cbe4efcd7b388946b@tamu.edu>
 <CAPjFEwUoz9wkgh+i3StzVPcvjXWm0mYwZGZfMYUqM8+SbMY-9Q@mail.gmail.com>
Message-ID: <436f756b18bd4c13b2404929c9701573@tamu.edu>

No html!, Copy the list using Reply-All. 

The data frame group_PrivateLabel does not contain variables called Product_Name or Region.

David C

From: nguy2952 University of Minnesota <nguy2952 at umn.edu> 
Sent: Friday, June 1, 2018 2:13 PM
To: David L Carlson <dcarlson at tamu.edu>
Subject: Re: [R] Regroup and create new dataframe

Hi David,
your example is perfect!
I am still learning so please stay with me.
So, I am running a regression model:
model1 = lm(MarginDollars ~ Region + Product_Name, group_PrivateLabel)
I have an error message:?
Error in `contrasts<-`(`*tmp*`, value = contr.funs[1 + isOF[nn]]) :?
? contrasts can be applied only to factors with 2 or more levels

> str(group_PrivateLabel)
'data.frame':	14802 obs. of? 12 variables:
?$ ACCTG_YEAR_KEY? ? ? ? : int? 2019 2019 2019 2019 2019 2019 2019 2019 2019 2019 ...
?$ ITEM_CATEGORY_DESCR? ?: Factor w/ 462 levels "ABRASIVE AND POLISHING MATERIAL",..: 145 145 145 145 145 145 145 145 145 145 ...
?$ ITEM_DESCR? ? ? ? ? ? : Factor w/ 12319 levels "@EASE X-RAY BADGE QTRLY SRVC",..: 8263 8263 8263 8263 8263 8263 8263 8263 8263 8264 ...
?$ PRODUCT_SUB_LINE_DESCR: Factor w/ 3 levels "Handpieces","PRIVATE LABEL",..: 2 2 2 2 2 2 2 2 2 2 ...
?$ MAJOR_CATEGORY_DESCR? : Factor w/ 25 levels "AIR ABRASION",..: 4 4 4 4 4 4 4 4 4 4 ...
?$ CUST_BRANCH_DESCR? ? ?: Factor w/ 60 levels "ALBUQUERQUE",..: 58 35 24 55 8 22 22 46 46 35 ...
?$ CUST_STATE_KEY? ? ? ? : Factor w/ 52 levels "AK","AL","AR",..: 15 49 44 16 6 6 28 6 6 49 ...
?$ CUST_REGION_DESCR? ? ?: Factor w/ 7 levels "MOUNTAIN WEST REGION",..: 2 2 5 4 6 6 6 6 6 2 ...
?$ Sales? ? ? ? ? ? ? ? ?: num? 25.9 13.5 28.5 28.5 57 ...
?$ QtySold? ? ? ? ? ? ? ?: int? 2 1 2 2 5 2 1 3 3 1 ...
?$ MFGCOST? ? ? ? ? ? ? ?: num? 13.2 6.6 13.2 13.2 33 13.2 6.6 19.8 19.8 6.6 ...
?$ MarginDollars? ? ? ? ?: num? 11.72 6.43 14.28 14.28 21.45 ...

What can I do?
Everything seems to fit perfectly to what I learned at school.
I am just working on a real-life huge data set. The regression model should work.

Please help.


On Fri, Jun 1, 2018 at 2:09 PM, David L Carlson <mailto:dcarlson at tamu.edu> wrote:
Responses should be copied to r-help using ReplyAll. You are still sending html formatted emails. If you are using Microsoft Outlook, click the Format Text tab and select ?Aa Plain Text?. No one has asked you to reveal the data set, only to create one with a similar structure. Is the data I sent reasonably close? What should it look like after it is transformed? 

David C

From: nguy2952 University of Minnesota <mailto:nguy2952 at umn.edu> 
Sent: Friday, June 1, 2018 1:57 PM
To: David L Carlson <mailto:dcarlson at tamu.edu>
Subject: Re: [R] Regroup and create new dataframe

Hi,
This is not an assignment for school.
This is a project at WORK.?
I am not allowed to reveal the dataset.

Thanks!

On Fri, Jun 1, 2018 at 1:55 PM, David L Carlson <mailto:mailto:dcarlson at tamu.edu> wrote:
Your question raises several issues. First, we do not do homework here, so if this is an assignment, you will not get much help. Second, you need to send your emails as plain text, not html. Third, you need to provide a reproducible example and send your data using dput() so that we can follow what you have tried so far. For example, here's a data set that resembles what you have described:

set.seed(42)
Tape <- data.frame(Year=2011:2015, Product=rep(c("Target", "3M", "Avery"),
? ? ?each=5), Sales=sample(1000:2000, 15), Region=rep(c("North", "South",
? ? ?"West"), each=5), stringsAsFactors=FALSE)
dput(Tape)
structure(list(Year = c(2011L, 2012L, 2013L, 2014L, 2015L, 2011L, 
2012L, 2013L, 2014L, 2015L, 2011L, 2012L, 2013L, 2014L, 2015L
), Product = c("Target", "Target", "Target", "Target", "Target", 
"3M", "3M", "3M", "3M", "3M", "Avery", "Avery", "Avery", "Avery", 
"Avery"), Sales = c(1915L, 1937L, 1285L, 1828L, 1639L, 1517L, 
1732L, 1133L, 1652L, 1699L, 1453L, 1711L, 1924L, 1252L, 1456L
), Region = c("North", "North", "North", "North", "North", "South", 
"South", "South", "South", "South", "West", "West", "West", "West", 
"West")), .Names = c("Year", "Product", "Sales", "Region"), row.names = c(NA, 
-15L), class = "data.frame")

It is not clear what you want in your new data frame. This one has 5 years of data for each tape brand and you seem to want one row for each tape brand? Tables created in html and then sent to a plain text mailing list can be dramatically different from the original format. It is not clear that you cannot answer your questions from the data as presented here. Look at the results of unlist(split(Tape, Tape$Product)). You should see that this is nowhere near what you described.

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <mailto:mailto:r-help-bounces at r-project.org> On Behalf Of nguy2952 University of Minnesota
Sent: Friday, June 1, 2018 10:54 AM
To: mailto:mailto:r-help at r-project.org
Subject: [R] Regroup and create new dataframe

Hello folks,

I have a big project to work on and the dataset is classified so I am just going to use my own example so everyone can understand what I am targeting.

Let's take Target as an example: We consider three brands of tape: Target brand, 3M and Avery. The original data frame has 4 columns: Year of Record, Product_Name(which contains three brands of tape), Sales, and Region. I want to create a new data frame that looks like this:

? ? ? ? ? ? ? ? ? ? ? Year of Record? ? ? ?Sales? ? ?Region
? Target Brand
? 3M
? Avery

Here is what I did.

? ?1.

? ?I split the original data frame which I called data1:

? ?X = split(data1, Product_name)

? ?2.

? ?Unlist X

? ?X1 = unlist(X)

? ?3.

? ?Create a new data frame

? ?new_df = as.data.frame(X1)


But, when I used the command View(new_df), I had only two columns: The left one is similar to TargetBrand.Sales, etc. and the right one is just "X1"

I did not achieve what I wanted.

**A potentially big question from readers:*

Why am I doing this?

*Answer:*

I want to run a multiple regression model later to see among different regions, what the sales look like for these three brands of tape:

*Does Mid-west buy more house brand than East Coast?*

or

*Does region really affect the sales? Are Mid-West's purchases similar to those of East Coast and West Coast?*

I need help. Please give me guidance.

Sincerely,
Hugh N

? ? ? ? [[alternative HTML version deleted]]

______________________________________________
mailto:mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Dhelp&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=nPZ3F6nROsY3KM0z7y6ixAAYLjMGVhEZyuXMi3bg0rY&e=
PLEASE do read the posting guide https://urldefense.proofpoint.com/v2/url?u=http-3A__www.R-2Dproject.org_posting-2Dguide.html&d=DwMFaQ&c=ODFT-G5SujMiGrKuoJJjVg&r=veMGHMCNZShld-KX-bIj4jRE_tP9ojUvB_Lqp0ieSdk&m=LnVfoBf5smekeCFlal5rmpELFRoDrB3H3ij_lZJRy0w&s=XNpVm_6i2GLFLk3FzpM9T15aezUet1BA0FlapuVXdmc&e=
and provide commented, minimal, self-contained, reproducible code.


From jho|tm@n @end|ng |rom gm@||@com  Fri Jun  1 21:40:24 2018
From: jho|tm@n @end|ng |rom gm@||@com (jim holtman)
Date: Fri, 1 Jun 2018 12:40:24 -0700
Subject: [R] values of list of variable names
In-Reply-To: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
References: <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
Message-ID: <CAAxdm-5qBMt_2XdG_yNJi5sY6ZxwNxJQRsif+z6Xb3MBvmbgEQ@mail.gmail.com>

You probably want to use 'get':

> r1 <- 5
> r2 <- 3
> r3 <- 45
> x <- ls(pattern = '^r.$')
> x
[1] "r1" "r2" "r3"
> lapply(x, get)
[[1]]
[1] 5

[[2]]
[1] 3

[[3]]
[1] 45

>


Jim Holtman
Data Munger Guru

What is the problem that you are trying to solve?
Tell me what you want to do, not how you want to do it.

On Fri, Jun 1, 2018 at 7:25 AM, Christian <christian at echoffmann.ch> wrote:

> Hi,
>
> I have searched the documentations of eval, substitute, expression, and I
> cannot make work something like the values of a list of variable names:
>
> lis <- ls(pattern="pr") # all variables with names containing 'pr'
>
> What is the mantra giving me the _values_ of the variables whose names
> are  contained in 'lis'. eval(parse(ls(pattern="pr"))) will not do but
> returning TRUE.
>
> TIA
> C.
> --
> Christian Hoffmann
> Rigiblickstrasse 15b
> CH-8915 Hausen am Albis
> Switzerland
> Telefon +41-(0)44-7640853
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From md@umner @end|ng |rom gm@||@com  Fri Jun  1 22:57:00 2018
From: md@umner @end|ng |rom gm@||@com (Michael Sumner)
Date: Sat, 2 Jun 2018 06:57:00 +1000
Subject: [R] rasterize SpatialPolygon object using a RasterBrick object
In-Reply-To: <CAJcfORJdivKJRntDrq-igrv-FXDPL23yiKCT4n63jirGepjqEQ@mail.gmail.com>
References: <CAJcfORJdivKJRntDrq-igrv-FXDPL23yiKCT4n63jirGepjqEQ@mail.gmail.com>
Message-ID: <CAAcGz9-08PaEvLd4aFfg=eMW4HC3O9D9Bi+yv_OQxWLm7ERHbg@mail.gmail.com>

I see this problem in 2.6-7 (version on CRAN) but it's now fixed in dev on
RForge, you can try it out by installing from there, or from the Github
mirror with devtools::install_github("rforge/raster/pkg/raster").

There's an imminent release to CRAN some time soon.

Cheers, Mike.


On Sat, 2 Jun 2018 at 04:48 Dimitri Szerman <dimitrijoe at gmail.com> wrote:

I am trying to rasterize a SpatialPolygon object by a RasterBrick object.
The documentation of the raster::rasterize function explicitly says this is
allowed. Here's what I am doing

# load the raster package
library("raster")
# create a raster brick object using the example from the brick
function documentation
b <- brick(system.file("external/rlogo.grd", package="raster"))
b
nlayers(b)
names(b)
extract(b, 870)
# create a SpatialPolygon object using the example from the function
documentation
Sr1 = Polygon(10*cbind(c(2,4,4,1,2),10*c(2,3,5,4,2)))
Sr2 = Polygon(10*cbind(c(5,4,2,5),10*c(2,3,2,2)))
Sr3 = Polygon(10*cbind(c(4,4,5,10,4),c(5,3,2,5,5)))
Sr4 = Polygon(10*cbind(c(5,6,6,5,5),c(4,4,3,3,4)), hole = TRUE)

Srs1 = Polygons(list(Sr1), "s1")
Srs2 = Polygons(list(Sr2), "s2")
Srs3 = Polygons(list(Sr3, Sr4), "s3/4")
SpP = SpatialPolygons(list(Srs1,Srs2,Srs3), 1:3)

plot(b[[1]])
plot(SpP, add = T)
# crop
clip1 = crop(b, extent(SpP))
# rasterize returns an error, but documentation says it should return
a RasterBrick object
clip2 = rasterize(SpP, b, mask = T)
Error in v[, r] <- rrv :
number of items to replace is not a multiple of replacement length
# however, if I used only one layer, all would be fine
clip2 = rasterize(SpP, b[[1]], mask = T)

Of course, I could loop over the brick's layers, but as I understand it,
that would defeat the purpose of a brick object.

I want to use clip2 to then get the histogram of pixel values in the
layers, like this:

vals = getValues(clip2)

Can anyone tell me why I am getting this error, and how to go around it
efficiently?

[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
<http://www.r-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Jun  1 23:03:18 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 1 Jun 2018 21:03:18 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
 <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <04C0271F-0455-4F38-BD4C-773B24B2DA21@llnl.gov>

For your first question, you?re doing moving averages of 3 points (I assume that?s what order=3 does). For any given time point of your input data, that would be one before, one at, and one after the given time point. Do all of  your input times have both one before and one after?

Don?t know about your same 8 point forecast values question, not without running it myself, but I would say that if the data really is different, yet the forecasts are the same, it would have to be coincidental. But a priori this seems unlikely, so I?d inspect your script very carefully for mistakes.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com>
Date: Friday, June 1, 2018 at 10:43 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov>, array R-help <r-help at r-project.org>
Subject: RE: [R] Time-series moving average question

Hi Don, wow, you are so right. I picked that piece up from the bloggers tutorial and since I am R naive yet, I thought it was all one step

moving_average = forecast(ma(tdat[1:31], order=2), h=5)

Truly, I usually print and check at every step I can, as painful as it is sometimes.
Great lesson for this novice usR.

So the first and last values are NA in each case? Do you know why? Should I replace the NA with a value, say the average of the others?

Also, I have 5 series of data I am working with using this script and of course each gave me that warning, but only the one series had the same 8 Point Forecast values, is that coincidental you think?

Terrific of you to help, I really appreciate it.

WHP


From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 12:54 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

tnr.ma<http://tnr.ma> <- ma(dat3[1:28], order=3)
TNR_moving_average <- forecast(tnr.ma<http://tnr.ma>, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma<http://tnr.ma> and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com<http://bloggers.com>

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From m|n@h@|| @end|ng |rom @cm@org  Fri Jun  1 22:07:38 2018
From: m|n@h@|| @end|ng |rom @cm@org (Greg Minshall)
Date: Fri, 01 Jun 2018 16:07:38 -0400
Subject: [R] values of list of variable names
In-Reply-To: Your message of "Fri, 01 Jun 2018 16:25:01 +0200."
 <93b0eec4-149e-02d7-6cf3-13765728f3da@echoffmann.ch>
Message-ID: <29330.1527883658@minshall-apollo.minshall.org>

Christian,

does this do it?

> eval(lapply(ls(pattern="pr"), function(x) eval(parse(text=x))))

cheers, Greg



From @h|v|pmp82 @end|ng |rom gm@||@com  Fri Jun  1 23:24:37 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Sat, 2 Jun 2018 02:54:37 +0530
Subject: [R] Cannot Load A Package
Message-ID: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>

Hi All,

I am trying to download semnet package but getting the error:
package not available for R version 3.4.4.

I tried downloading it from
install.packages('semnet',repos='http://cran.us.r-project.org')
and install.packages('semnet',repos='http://cran.revolutionanalytics.com/')
and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
doesnt seem to get success.

Please suggest some alternate.

Regards, Shivi

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Sat Jun  2 01:17:58 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Fri, 1 Jun 2018 19:17:58 -0400
Subject: [R] Cannot Load A Package
In-Reply-To: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
References: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
Message-ID: <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>

On 01/06/2018 5:24 PM, Shivi Bhatia wrote:
> Hi All,
> 
> I am trying to download semnet package but getting the error:
> package not available for R version 3.4.4.

As far as I can see, there is no semnet package on CRAN, and never has 
been (or if there was, it was there by mistake).

Packages whose names start with "sem" are:

sem	Structural Equation Models
semantic.dashboard	Dashboard with Semantic UI Support for 'shiny'
Semblance	Pair-Wise Semblance Using a Rank-Based Kernel
semdiag	Structural equation modeling diagnostics
semds	Structural Equation Multidimensional Scaling
semGOF	Goodness-of-fit indexes for structural equation models
semiArtificial	Generator of Semi-Artificial Data
SemiCompRisks	Hierarchical Models for Parametric and Semi-Parametric 
Analyses of Semi-Competing Risks Data
SEMID	Identifiability of Linear Structural Equation Models
SemiMarkov	Multi-States Semi-Markov Models
seminr	Domain-Specific Language for Building PLS Structural Equation Models
SemiPar	Semiparametic Regression
SemiParSampleSel	Semi-Parametric Sample Selection Modelling with 
Continuous or Discrete Response
SemiSupervised	Safe Semi-Supervised Learning Tools
semisupKernelPCA	Kernel PCA projection, and semi-supervised variant
SEMModComp	Model Comparisons for SEM
SemNetCleaner	An Automated Cleaning Tool for Semantic and Linguistic Data
semPlot	Path Diagrams and Visual Analysis of Various SEM Packages' Output
semPLS	Structural Equation Modeling Using Partial Least Squares
semPower	Power Analyses for SEM
semsfa	Semiparametric Estimation of Stochastic Frontier Models
semTools	Useful Tools for Structural Equation Modeling
semtree	Recursive Partitioning for Structural Equation Models
semver	'Semantic Versioning V2.0.0' Parser

Perhaps you really want one of those.

Duncan Murdoch

> 
> I tried downloading it from
> install.packages('semnet',repos='http://cran.us.r-project.org')
> and install.packages('semnet',repos='http://cran.revolutionanalytics.com/')
> and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
> doesnt seem to get success.
> 
> Please suggest some alternate.
> 
> Regards, Shivi
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From |@t@z@hn @end|ng |rom gm@||@com  Sat Jun  2 02:28:16 2018
From: |@t@z@hn @end|ng |rom gm@||@com (Ista Zahn)
Date: Fri, 1 Jun 2018 20:28:16 -0400
Subject: [R] Unable to take correct Web-snapshot
In-Reply-To: <CA+dpOJ=u+j1Xd1D+k8Er403A5-LMp=ozH=eBL2=Ytjs6CWkqKw@mail.gmail.com>
References: <CA+dpOJkmnpxDGAcZ+4=9irx+O=AocF7wRJ9ojVw3cR3iU=Ed8Q@mail.gmail.com>
 <CAGAA5bcyi3ifNAG=jwOwPhaTfY152KJ9xPp5wWBQYNEvvnNPvw@mail.gmail.com>
 <CA+dpOJ=u+j1Xd1D+k8Er403A5-LMp=ozH=eBL2=Ytjs6CWkqKw@mail.gmail.com>
Message-ID: <CA+vqiLFVf7rFZhdUf6-+Mxs00ZkSuy24mt4gt4a7p6kQ3CVbZA@mail.gmail.com>

The documentation is at https://developers.coinbase.com/api/v2. You
can make GET requests in R using the httr packge.

--Ista

On Fri, Jun 1, 2018 at 11:12 AM, Christofer Bogaso
<bogaso.christofer at gmail.com> wrote:
> Thanks for that information.
>
> However how can I use R to directly get data from that API?
>
> On Fri, Jun 1, 2018 at 8:36 PM Martin M?ller Skarbiniks Pedersen <
> traxplayer at gmail.com> wrote:
>
>> On 1 June 2018 at 15:08, Christofer Bogaso <bogaso.christofer at gmail.com>
>> wrote:
>> > Hi again,
>> >
>> > I use the *webshot* package to take snapshot from Webpage. However, when
>> I
>> > try to take snapshot from* https://www.coinbase.com/
>> > <https://www.coinbase.com/>*, this fails to take the full snapshot of
>> that
>> > page.
>>
>> Yes, that is a general problem with many webshot programs and libraries.
>>
>> The coinbase page ( and many others ) uses a lot of javascript to generate
>> their
>> pages and the webshot programs must understand javascript in all
>> details which is hard.
>>
>> If you are looking for the coinbase prices you can use their api to
>> get json instead:
>>
>> https://api.coinbase.com/v2/prices/spot?currency=USD
>>
>> Regards
>> Martin
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From djnord|und @end|ng |rom gm@||@com  Sat Jun  2 09:03:42 2018
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Sat, 2 Jun 2018 00:03:42 -0700
Subject: [R] Cannot Load A Package
In-Reply-To: <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>
References: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
 <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>
Message-ID: <158aeed2-2b3a-ee06-f60a-d32c5196149a@gmail.com>

On 6/1/2018 4:17 PM, Duncan Murdoch wrote:
> On 01/06/2018 5:24 PM, Shivi Bhatia wrote:
>> Hi All,
>>
>> I am trying to download semnet package but getting the error:
>> package not available for R version 3.4.4.
> 
> As far as I can see, there is no semnet package on CRAN, and never has 
> been (or if there was, it was there by mistake).
> 
> Packages whose names start with "sem" are:
> 
> sem??? Structural Equation Models
> semantic.dashboard??? Dashboard with Semantic UI Support for 'shiny'
> Semblance??? Pair-Wise Semblance Using a Rank-Based Kernel
> semdiag??? Structural equation modeling diagnostics
> semds??? Structural Equation Multidimensional Scaling
> semGOF??? Goodness-of-fit indexes for structural equation models
> semiArtificial??? Generator of Semi-Artificial Data
> SemiCompRisks??? Hierarchical Models for Parametric and Semi-Parametric 
> Analyses of Semi-Competing Risks Data
> SEMID??? Identifiability of Linear Structural Equation Models
> SemiMarkov??? Multi-States Semi-Markov Models
> seminr??? Domain-Specific Language for Building PLS Structural Equation 
> Models
> SemiPar??? Semiparametic Regression
> SemiParSampleSel??? Semi-Parametric Sample Selection Modelling with 
> Continuous or Discrete Response
> SemiSupervised??? Safe Semi-Supervised Learning Tools
> semisupKernelPCA??? Kernel PCA projection, and semi-supervised variant
> SEMModComp??? Model Comparisons for SEM
> SemNetCleaner??? An Automated Cleaning Tool for Semantic and Linguistic 
> Data
> semPlot??? Path Diagrams and Visual Analysis of Various SEM Packages' 
> Output
> semPLS??? Structural Equation Modeling Using Partial Least Squares
> semPower??? Power Analyses for SEM
> semsfa??? Semiparametric Estimation of Stochastic Frontier Models
> semTools??? Useful Tools for Structural Equation Modeling
> semtree??? Recursive Partitioning for Structural Equation Models
> semver??? 'Semantic Versioning V2.0.0' Parser
> 
> Perhaps you really want one of those.
> 
> Duncan Murdoch
> 
>>
>> I tried downloading it from
>> install.packages('semnet',repos='http://cran.us.r-project.org')
>> and 
>> install.packages('semnet',repos='http://cran.revolutionanalytics.com/')
>> and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
>> doesnt seem to get success.
>>
>> Please suggest some alternate.
>>
>> Regards, Shivi
>>
>> ????[[alternative HTML version deleted]]
>>

Maybe this is what the OP is looking for

library(devtools)
install_github("kasperwelbers/semnet")


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA



From @h|v|pmp82 @end|ng |rom gm@||@com  Sat Jun  2 13:22:27 2018
From: @h|v|pmp82 @end|ng |rom gm@||@com (Shivi Bhatia)
Date: Sat, 2 Jun 2018 16:52:27 +0530
Subject: [R] Cannot Load A Package
In-Reply-To: <158aeed2-2b3a-ee06-f60a-d32c5196149a@gmail.com>
References: <CAB=p7Sq7EQFEAZrH7qp+EZyVO5HiUf4jBQQuL7-M5Twm7nHtwQ@mail.gmail.com>
 <c19c3a14-df16-0269-46b1-8e8fbaab8616@gmail.com>
 <158aeed2-2b3a-ee06-f60a-d32c5196149a@gmail.com>
Message-ID: <CAB=p7SqEroHFQb6zPvgLAqc881tRCRc+O2Qh-9_RRbSNexEo6w@mail.gmail.com>

Thank you Dan, this is what i had been searching. Thanks again,

Regards, Shivi

On Sat, Jun 2, 2018 at 12:33 PM, Daniel Nordlund <djnordlund at gmail.com>
wrote:

> On 6/1/2018 4:17 PM, Duncan Murdoch wrote:
>
>> On 01/06/2018 5:24 PM, Shivi Bhatia wrote:
>>
>>> Hi All,
>>>
>>> I am trying to download semnet package but getting the error:
>>> package not available for R version 3.4.4.
>>>
>>
>> As far as I can see, there is no semnet package on CRAN, and never has
>> been (or if there was, it was there by mistake).
>>
>> Packages whose names start with "sem" are:
>>
>> sem    Structural Equation Models
>> semantic.dashboard    Dashboard with Semantic UI Support for 'shiny'
>> Semblance    Pair-Wise Semblance Using a Rank-Based Kernel
>> semdiag    Structural equation modeling diagnostics
>> semds    Structural Equation Multidimensional Scaling
>> semGOF    Goodness-of-fit indexes for structural equation models
>> semiArtificial    Generator of Semi-Artificial Data
>> SemiCompRisks    Hierarchical Models for Parametric and Semi-Parametric
>> Analyses of Semi-Competing Risks Data
>> SEMID    Identifiability of Linear Structural Equation Models
>> SemiMarkov    Multi-States Semi-Markov Models
>> seminr    Domain-Specific Language for Building PLS Structural Equation
>> Models
>> SemiPar    Semiparametic Regression
>> SemiParSampleSel    Semi-Parametric Sample Selection Modelling with
>> Continuous or Discrete Response
>> SemiSupervised    Safe Semi-Supervised Learning Tools
>> semisupKernelPCA    Kernel PCA projection, and semi-supervised variant
>> SEMModComp    Model Comparisons for SEM
>> SemNetCleaner    An Automated Cleaning Tool for Semantic and Linguistic
>> Data
>> semPlot    Path Diagrams and Visual Analysis of Various SEM Packages'
>> Output
>> semPLS    Structural Equation Modeling Using Partial Least Squares
>> semPower    Power Analyses for SEM
>> semsfa    Semiparametric Estimation of Stochastic Frontier Models
>> semTools    Useful Tools for Structural Equation Modeling
>> semtree    Recursive Partitioning for Structural Equation Models
>> semver    'Semantic Versioning V2.0.0' Parser
>>
>> Perhaps you really want one of those.
>>
>> Duncan Murdoch
>>
>>
>>> I tried downloading it from
>>> install.packages('semnet',repos='http://cran.us.r-project.org')
>>> and install.packages('semnet',repos='http://cran.revolutionanaly
>>> tics.com/')
>>> and even the https://cran.r-project.org/src/contrib/semnet.tar.gz but
>>> doesnt seem to get success.
>>>
>>> Please suggest some alternate.
>>>
>>> Regards, Shivi
>>>
>>>     [[alternative HTML version deleted]]
>>>
>>>
> Maybe this is what the OP is looking for
>
> library(devtools)
> install_github("kasperwelbers/semnet")
>
>
> Hope this is helpful,
>
> Dan
>
> --
> Daniel Nordlund
> Port Townsend, WA  USA
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posti
> ng-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From ye||owb@n@n@27 @end|ng |rom hotm@||@com  Sun Jun  3 15:52:58 2018
From: ye||owb@n@n@27 @end|ng |rom hotm@||@com (Qian Yiting)
Date: Sun, 3 Jun 2018 13:52:58 +0000
Subject: [R] read .asc from web into R
Message-ID: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>

Hi All?

I am new to R. To import data with .asc ending from the web into R, I have tried many functions for importing data but it came out not well.  The problem may seem to be very basic but unfortunately I haven?t  found any useful information somehow.  Which command should I use for that purpose?

Here ist the url of the data:
https://moodle.lmu.de/pluginfile.php/218819/mod_resource/content/1/nba.asc

Thanks in advance!

Best regards,
Yiting

	[[alternative HTML version deleted]]


From @-dh@r @end|ng |rom northwe@tern@edu  Sun Jun  3 18:03:21 2018
From: @-dh@r @end|ng |rom northwe@tern@edu (Sumitrajit Dhar)
Date: Sun, 3 Jun 2018 11:03:21 -0500
Subject: [R] Running segmented on grouped data and collating model
 parameters in a data frame
Message-ID: <CAPfim6MmgTiQmQhSSZQwUAtYE6QGrd-d2u8EMU9=K1fQspgaGQ@mail.gmail.com>

Hi Folks,

I am trying to teach myself how to solve the problem described below but am
running out of time. Hence the plea for help. Thanks in advance.

Here is my data frame.

> t
# A tibble: 12 x 12
   subject  ageGrp ear   hearingGrp sex    freq    L2   Ldp Phidp    NF
SNR   Ldp_p
   <fct>    <fct>  <fct> <fct>      <fct> <int> <int> <dbl> <dbl> <dbl>
<dbl>   <dbl>
 1 HALAF573 A      L     A          F         2     0 -19.6 197.  -28.5
8.88  2.10e-6
 2 HALAF573 A      L     A          F         2     2 -18.7 203.  -22.0
3.25  2.31e-6
 3 HALAF573 A      L     A          F         2     4 -29.1 255.  -27.4
 -1.64  7.04e-7
 4 HALAF573 A      L     A          F         2     6 -12.4 174.  -12.2
 -0.206 4.78e-6
 5 HALAF573 A      L     A          F         4     0 -28.6 232.  -26.7
 -1.87  7.45e-7
 6 HALAF573 A      L     A          F         4     2 -27.2 351.  -28.8
1.59  8.68e-7
 7 HALAF573 A      L     A          F         4     4 -20.4  26.2 -35.0
 14.6   1.92e-6
 8 HALAF573 A      L     A          F         4     6 -20.0  85.1 -29.8
9.75  2.00e-6
 9 HALAF573 A      L     A          F         8     0 -22.8  39.2 -22.1
 -0.689 1.45e-6
10 HALAF573 A      L     A          F         8     2 -14.5  13.4 -20.7
6.23  3.76e-6
11 HALAF573 A      L     A          F         8     4 -17.3 345.  -21.6
4.30  2.73e-6
12 HALAF573 A      L     A          F         8     6 -14.1 320.  -21.7
7.59  3.94e-6

# Note that there are more levels of L2 (31 in total)  and 344 other
subjects but I truncated the frame for posting.

# I want to do this:  t %>%  group_by(freq) %>% [run segmented] %>% [create
a data frame with [subject, freq, breakpoint1, breakpoint2, slope1, slope2,
slope3, L2 when Ldp_p == 0].

# Also note that ultimately I will be grouping by "subject, freq".

# I can run the models and get believable results. The following run on a
data frame with L2 between 0 and 60.

out.lm <- lm(Ldp_p ~ L2, data = t)
o <- segmented(out.lm, seg.Z = ~L2, psi = list(L2 = c(20,45)),
               control = seg.control(display = FALSE)

o$psi
#        Initial     Est.    St.Err
#psi1.L2      20 30.78256 0.5085192
#psi2.L2      45 53.16390 0.4671701

slope(o)
slope(o)
$L2
#              Est.    St.Err. t value   CI(95%).l   CI(95%).u
#slope1  1.2060e-06 1.6606e-07  7.2622  8.6397e-07  1.5480e-06
#slope2  1.0708e-05 2.9196e-07 36.6770  1.0107e-05  1.1309e-05
#slope3 -4.5791e-06 1.3694e-06 -3.3439 -7.3995e-06 -1.7588e-06

Thanks again for bailing me out.

Regards,
Sumit

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jun  3 18:53:15 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 03 Jun 2018 10:53:15 -0600
Subject: [R] read .asc from web into R
In-Reply-To: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
Message-ID: <C0EA82DA-FD90-4C4F-BC14-CD8CE6349741@dcn.davis.ca.us>

Have you tried that url in a web browser? I encountered an access permission error. If you also encountered an error, then so would R. You need to download the file using appropriate access credentials (typ. through a web browser) and read it from disk.

FWIW the ".asc" extension is very nearly meaningless as to identifying the format of the data inside the file. The only useful information imparted by that extension is that you can use a text editor to view it and judge by inspection what the layout is. Originally that extension was used for storing the readable output of a program, which could be laid out in any form deemed readable by a human, with little regard for whether it would be machine-readable.

On June 3, 2018 7:52:58 AM MDT, Qian Yiting <yellowbanana27 at hotmail.com> wrote:
>Hi All?
>
>I am new to R. To import data with .asc ending from the web into R, I
>have tried many functions for importing data but it came out not well. 
>The problem may seem to be very basic but unfortunately I haven?t 
>found any useful information somehow.  Which command should I use for
>that purpose?
>
>Here ist the url of the data:
>https://moodle.lmu.de/pluginfile.php/218819/mod_resource/content/1/nba.asc
>
>Thanks in advance!
>
>Best regards,
>Yiting
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jun  3 20:30:21 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 3 Jun 2018 11:30:21 -0700
Subject: [R] read .asc from web into R
In-Reply-To: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
References: <DB6PR0101MB25365897EFB5598E54D330DECD600@DB6PR0101MB2536.eurprd01.prod.exchangelabs.com>
Message-ID: <F2712B71-F4A5-4B30-9891-2E15081F55A4@comcast.net>



> On Jun 3, 2018, at 6:52 AM, Qian Yiting <yellowbanana27 at hotmail.com> wrote:
> 
> Hi All?
> 
> I am new to R. To import data with .asc ending from the web into R, I have tried many functions for importing data but it came out not well.  The problem may seem to be very basic but unfortunately I haven?t  found any useful information somehow.  Which command should I use for that purpose?
> 
> Here ist the url of the data:
> https://moodle.lmu.de/pluginfile.php/218819/mod_resource/content/1/nba.asc

This URL requires authorization. You probably need to sign in with your username and password and download with a browser or FTP client. The instructions should be somewhere in their website (which is in German).


> 
> Thanks in advance!
> 
> Best regards,
> Yiting
> 
> 	[[alternative HTML version deleted]]

R-help is a plain text mailing list. Please read these instructions as well as the instructions at https://moodle.lmu.de/
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


-- 
David.


From d@v|@g|enn@1952 @end|ng |rom gm@||@com  Mon Jun  4 03:54:33 2018
From: d@v|@g|enn@1952 @end|ng |rom gm@||@com (Glenn Davis)
Date: Sun, 3 Jun 2018 21:54:33 -0400
Subject: [R] package colorspace and .WhitePoint question
Message-ID: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>

 In colorspace.R  I see:

    setAs("color", "LAB", function(from)
      LAB(.Call("as_LAB", from at coords, class(from), .WhitePoint, PACKAGE = "
colorspace"),
          names = dimnames(from at coords)[[1]]))
    ...
    .WhitePoint = NULL

and then in colorspace.c and the function CheckWhite(),
I see that .WhitePoint = NULL is converted to D65.

I would like to pass a different .WhitePoint to
    as( XYZ( 100,100,100)  , "LAB" )


I have tried 3 methods:
    as( XYZ( 100,100,100)  , "LAB", .WhitePoint=XYZ(95,100,105) )
    .WhitePoint = XYZ(95,100,105)
    assign( ".WhitePoint", XYZ(95,100,105), env=as.environment('package:
colorspace') )
but all fail, for different reasons.

How can I transform XYZ to LAB using a whitepoint different than D65 ?

Thanks,
Glenn Davis
gdavis at gluonics.com

	[[alternative HTML version deleted]]



From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Mon Jun  4 09:42:42 2018
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Mon, 4 Jun 2018 09:42:42 +0200 (CEST)
Subject: [R] package colorspace and .WhitePoint question
In-Reply-To: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>
References: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>
Message-ID: <alpine.DEB.2.21.1806040940020.26338@paninaro>

Glenn,

currently, this is currently not exposed in "colorspace" AFAICS. You can 
modify it by changing .WhitePoint inside colorspace's NAMESPACE, though:

R> assignInNamespace(".WhitePoint", rbind(c(95, 100, 105)),
+    ns = "colorspace")
R> as(XYZ(100, 100, 100), "LAB")
        L        A        B
[1,] 100 8.622384 3.226371

I'll have another look whether this could be exposed easily (cc also 
Paul).

Best,
Z

On Mon, 4 Jun 2018, Glenn Davis wrote:

> In colorspace.R  I see:
>
>    setAs("color", "LAB", function(from)
>      LAB(.Call("as_LAB", from at coords, class(from), .WhitePoint, PACKAGE = "
> colorspace"),
>          names = dimnames(from at coords)[[1]]))
>    ...
>    .WhitePoint = NULL
>
> and then in colorspace.c and the function CheckWhite(),
> I see that .WhitePoint = NULL is converted to D65.
>
> I would like to pass a different .WhitePoint to
>    as( XYZ( 100,100,100)  , "LAB" )
>
>
> I have tried 3 methods:
>    as( XYZ( 100,100,100)  , "LAB", .WhitePoint=XYZ(95,100,105) )
>    .WhitePoint = XYZ(95,100,105)
>    assign( ".WhitePoint", XYZ(95,100,105), env=as.environment('package:
> colorspace') )
> but all fail, for different reasons.
>
> How can I transform XYZ to LAB using a whitepoint different than D65 ?
>
> Thanks,
> Glenn Davis
> gdavis at gluonics.com
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jun  4 10:45:43 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 4 Jun 2018 14:15:43 +0530
Subject: [R] Time and date conversion
Message-ID: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>

Hi,

I have an automatic data feed and I obtained a Date vector in the following
format:

> Date
[1] "03 Jun 2018 10:01 am CT"    "01 Jun 2018 22:04:25 pm CT"

I now like to convert it to UTC time-zone

Is there any easy way to convert them so, particularly since 1st element
doesnt have any Second element whereas the 2nd element has.

Thanks for any pointer.

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Mon Jun  4 12:08:37 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Mon, 4 Jun 2018 10:08:37 +0000
Subject: [R] Time-series moving average question
In-Reply-To: <04C0271F-0455-4F38-BD4C-773B24B2DA21@llnl.gov>
References: <C096197C-5671-4251-B8EA-EFD332B2E367@llnl.gov>
 <CY1PR0201MB1834A7F3671A930D27AD694BEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <90B2796F-369D-4399-A9BE-A59EE2578B3D@llnl.gov>
 <CY1PR0201MB1834792D955CBC4C280C603EEA620@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <04C0271F-0455-4F38-BD4C-773B24B2DA21@llnl.gov>
Message-ID: <CY1PR0201MB1834161A62B2963369868ACDEA670@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning Don, thank you for your support. I will give this all more investigation and submit my findings when finalized.

Cheers and thanks again for your help Sir.

WHP



From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 5:03 PM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Time-series moving average question

For your first question, you?re doing moving averages of 3 points (I assume that?s what order=3 does). For any given time point of your input data, that would be one before, one at, and one after the given time point. Do all of  your input times have both one before and one after?

Don?t know about your same 8 point forecast values question, not without running it myself, but I would say that if the data really is different, yet the forecasts are the same, it would have to be coincidental. But a priori this seems unlikely, so I?d inspect your script very carefully for mistakes.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 10:43 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hi Don, wow, you are so right. I picked that piece up from the bloggers tutorial and since I am R naive yet, I thought it was all one step

moving_average = forecast(ma(tdat[1:31], order=2), h=5)

Truly, I usually print and check at every step I can, as painful as it is sometimes.
Great lesson for this novice usR.

So the first and last values are NA in each case? Do you know why? Should I replace the NA with a value, say the average of the others?

Also, I have 5 series of data I am working with using this script and of course each gave me that warning, but only the one series had the same 8 Point Forecast values, is that coincidental you think?

Terrific of you to help, I really appreciate it.

WHP


From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 12:54 PM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

You are right that there are no NAs in the practice data. But there are NAs in the moving average data.

To see this, break your work into two separate steps, like this:

tnr.ma<http://tnr.ma> <- ma(dat3[1:28], order=3)
TNR_moving_average <- forecast(tnr.ma<http://tnr.ma>, h=8)

I think you will find that the warning comes from the second step.

Print tnr.ma<http://tnr.ma> and you will see some NAs.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509



From: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Date: Friday, June 1, 2018 at 8:58 AM
To: "MacQueen, Don" <macqueen1 at llnl.gov<mailto:macqueen1 at llnl.gov>>, array R-help <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: RE: [R] Time-series moving average question

Hello Don, thank you for your response. I appreciate your help.

I am using the forecast package, originally I found it following a forecasting example on bloggers.com<http://bloggers.com>

https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/<https://www.r-bloggers.com/time-series-analysis-using-r-forecast-package/>

And subsequently located the complete pdf https://cran.r-project.org/web/packages/forecast/forecast.pdf<https://cran.r-project.org/web/packages/forecast/forecast.pdf>

Since I created this practice data using the structure() function I am unsure why there would be NA?s as there are none apparently in the structure?

No worries though, I am going to reach out to the package author.

Cheers.

WHP

From: MacQueen, Don [mailto:macqueen1 at llnl.gov]
Sent: Friday, June 01, 2018 11:24 AM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>; r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Time-series moving average question

My guess would be that if you inspect the output from
ma(dat3[1:28], order=3)
you will find some NAs in it. And then forecast() doesn't like NAs.

But I can't check, because I can't find the ma() and forecast() functions. I assume they come from some package you installed; it would be helpful to say which package.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509


______________________________________________
mailto:R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.



Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From pd@|gd @end|ng |rom gm@||@com  Mon Jun  4 12:54:26 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 4 Jun 2018 12:54:26 +0200
Subject: [R] Time and date conversion
In-Reply-To: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>
References: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>
Message-ID: <DA6671CE-8F73-48A0-807B-63A223B9BA4A@gmail.com>



> On 4 Jun 2018, at 10:45 , Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
> 
> Hi,
> 
> I have an automatic data feed and I obtained a Date vector in the following
> format:
> 
>> Date
> [1] "03 Jun 2018 10:01 am CT"    "01 Jun 2018 22:04:25 pm CT"
> 
> I now like to convert it to UTC time-zone
> 
> Is there any easy way to convert them so, particularly since 1st element
> doesnt have any Second element whereas the 2nd element has.

..and it also mixes up am/pm notation and 24hr clock.

There are two basic approaches to the format inconsistency thing:

(A) preprocess using gsub() constructions 

> gsub(" (..:..) ", " \\1:00 ", d.txt)
[1] "03 Jun 2018 10:01:00 am CT" "01 Jun 2018 22:04:25 pm CT"

(B) Try multiple formats

> d <- strptime(d.txt, format="%d %B %Y %H:%M:%S %p")
> d[is.na(d)] <- strptime(d.txt[is.na(d)], format="%d %B %Y %H:%M %p")
> d
[1] "2018-06-03 10:01:00 CEST" "2018-06-01 22:04:25 CEST"

I would likely go for (A) since you probably need to do something gsub-ish to get the TZ thing in place.

-pd

> 
> Thanks for any pointer.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From v|to@muggeo @end|ng |rom un|p@@|t  Mon Jun  4 17:08:13 2018
From: v|to@muggeo @end|ng |rom un|p@@|t (Vito M. R. Muggeo)
Date: Mon, 4 Jun 2018 17:08:13 +0200
Subject: [R] Running segmented on grouped data and collating model
 parameters in a data frame
In-Reply-To: <CAPfim6MmgTiQmQhSSZQwUAtYE6QGrd-d2u8EMU9=K1fQspgaGQ@mail.gmail.com>
References: <CAPfim6MmgTiQmQhSSZQwUAtYE6QGrd-d2u8EMU9=K1fQspgaGQ@mail.gmail.com>
Message-ID: <9801628c-ba51-de9c-6bdb-4455b3417290@unipa.it>

dear Sumi,
I am not familiar with the dplyr package (%>%..), however if you want to 
fit the model for each subject times freq interaction, a simple for loop 
will suffice.
Here possible code:

Assuming d is the dataframe, something like

subj<-levels(d$subject)
fr<-unique(d$freq)

#new dataframe where the estimates will be stored
newd<-expand.grid(subj=subj, freq=fr)
newd<-cbind(newd, matrix(-99,nrow(newd),9))
names(newd)[-(1:2)]<-c(paste0("slope",1:3), 
paste0(c("CI.inf.","CI.sup."), rep(paste0("slope",1:3),each=2)))

library(segmented)

#fit the model for each subject x freq combination
for(i in subj){
       for(j in fr){
             current.d<-subset(d, subject==i & freq==j)
             if(nrow(current.d)>0){
               o<-lm(Ldp_p~L2, data=current.d)
               os<-try(segmented(o, ~L2, psi=c(20,50)), silent=TRUE)
               if(class(os)[1]!="try-error"){
                      est.slope<-as.vector(slope(os)[[1]][,1]) #point est
                      ci.slope<-as.vector(t(slope(os)[[1]][,4:5])) #CI
                      newd[newd$subj==i & newd$freq==j, 
-c(1:2)]<-c(est.slope, ci.slope)
                                        }
                      }

       }
}


However it seems that you can be interested in segmented *mixed* 
models.. I mean, rather than estimating a segmented model for each 
subject, you could estimate a single model assuming random effects (for 
each model parameter, including the breakpoint) for each subject:

Have a look to

http://journals.sagepub.com/doi/abs/10.1177/1471082X13504721

Let me know (not on the R list) if you are interested in relevant code

best,
vito


Il 03/06/2018 18:03, Sumitrajit Dhar ha scritto:
> Hi Folks,
> 
> I am trying to teach myself how to solve the problem described below but am
> running out of time. Hence the plea for help. Thanks in advance.
> 
> Here is my data frame.
> 
>> t
> # A tibble: 12 x 12
>     subject  ageGrp ear   hearingGrp sex    freq    L2   Ldp Phidp    NF
> SNR   Ldp_p
>     <fct>    <fct>  <fct> <fct>      <fct> <int> <int> <dbl> <dbl> <dbl>
> <dbl>   <dbl>
>   1 HALAF573 A      L     A          F         2     0 -19.6 197.  -28.5
> 8.88  2.10e-6
>   2 HALAF573 A      L     A          F         2     2 -18.7 203.  -22.0
> 3.25  2.31e-6
>   3 HALAF573 A      L     A          F         2     4 -29.1 255.  -27.4
>   -1.64  7.04e-7
>   4 HALAF573 A      L     A          F         2     6 -12.4 174.  -12.2
>   -0.206 4.78e-6
>   5 HALAF573 A      L     A          F         4     0 -28.6 232.  -26.7
>   -1.87  7.45e-7
>   6 HALAF573 A      L     A          F         4     2 -27.2 351.  -28.8
> 1.59  8.68e-7
>   7 HALAF573 A      L     A          F         4     4 -20.4  26.2 -35.0
>   14.6   1.92e-6
>   8 HALAF573 A      L     A          F         4     6 -20.0  85.1 -29.8
> 9.75  2.00e-6
>   9 HALAF573 A      L     A          F         8     0 -22.8  39.2 -22.1
>   -0.689 1.45e-6
> 10 HALAF573 A      L     A          F         8     2 -14.5  13.4 -20.7
> 6.23  3.76e-6
> 11 HALAF573 A      L     A          F         8     4 -17.3 345.  -21.6
> 4.30  2.73e-6
> 12 HALAF573 A      L     A          F         8     6 -14.1 320.  -21.7
> 7.59  3.94e-6
> 
> # Note that there are more levels of L2 (31 in total)  and 344 other
> subjects but I truncated the frame for posting.
> 
> # I want to do this:  t %>%  group_by(freq) %>% [run segmented] %>% [create
> a data frame with [subject, freq, breakpoint1, breakpoint2, slope1, slope2,
> slope3, L2 when Ldp_p == 0].
> 
> # Also note that ultimately I will be grouping by "subject, freq".
> 
> # I can run the models and get believable results. The following run on a
> data frame with L2 between 0 and 60.
> 
> out.lm <- lm(Ldp_p ~ L2, data = t)
> o <- segmented(out.lm, seg.Z = ~L2, psi = list(L2 = c(20,45)),
>                 control = seg.control(display = FALSE)
> 
> o$psi
> #        Initial     Est.    St.Err
> #psi1.L2      20 30.78256 0.5085192
> #psi2.L2      45 53.16390 0.4671701
> 
> slope(o)
> slope(o)
> $L2
> #              Est.    St.Err. t value   CI(95%).l   CI(95%).u
> #slope1  1.2060e-06 1.6606e-07  7.2622  8.6397e-07  1.5480e-06
> #slope2  1.0708e-05 2.9196e-07 36.6770  1.0107e-05  1.1309e-05
> #slope3 -4.5791e-06 1.3694e-06 -3.3439 -7.3995e-06 -1.7588e-06
> 
> Thanks again for bailing me out.
> 
> Regards,
> Sumit
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
==============================================
Vito M.R. Muggeo
Dip.to Sc Econom, Az e Statistiche
Universit? di Palermo
viale delle Scienze, edificio 13
90128 Palermo - ITALY
tel: 091 23895240
fax: 091 485726
http://dssm.unipa.it/vmuggeo
Associate Editor, Statistical Modelling
Chair, Statistical Modelling Society



From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Tue Jun  5 01:13:12 2018
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Tue, 5 Jun 2018 11:13:12 +1200
Subject: [R] [FORGED]  How to alpha entire plot?
In-Reply-To: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
References: <CALRb-oeC=PtnpJwF+4M0RvwOrdqW7jSO-zQLwnjLBVoYu4uCOA@mail.gmail.com>
Message-ID: <48f3aa41-22ce-0c71-e55a-fb8287eb5e8c@stat.auckland.ac.nz>

Hi

Here is one way to do it ...

col1 <- "red"
col2 <- "blue"
EU <- data.frame(EuStockMarkets)
with(EU, plot(DAX, CAC, col=col2, type="h", ylim=c(0,6000)))
par(new=TRUE)
with(EU, plot(DAX, FTSE, col=col1, type="h", ylim=c(0,6000)))

## Convert 'graphics' to 'grid'
library(gridGraphics)
grid.echo()
## grid.ls(print=grobPathListing, viewports=TRUE)

## Rasterize spikes
library(rasterize)
downViewport("graphics-window-1-1")
grid.rasterize("graphics-plot-1-spike-1")
upViewport(0)
downViewport("graphics-window-2-1")
grid.rasterize("graphics-plot-2-spike-1")
upViewport(0)

## Apply alpha adjustment to rasterized spikes
spike1 <- as.matrix(grid.get("graphics-plot-1-spike-1")$raster)
alphaSpike1 <- adjustcolor(spike1, alpha=.3)
dim(alphaSpike1) <- dim(spike1)
grid.edit("graphics-plot-1-spike-1", raster=as.raster(alphaSpike1))
spike2 <- as.matrix(grid.get("graphics-plot-2-spike-1")$raster)
alphaSpike2 <- adjustcolor(spike2, alpha=.3)
dim(alphaSpike2) <- dim(spike2)
grid.edit("graphics-plot-2-spike-1", raster=as.raster(alphaSpike2))

... though that may not be the best way and may just reflect what I have 
been thinking about recently ...

https://www.stat.auckland.ac.nz/~paul/Reports/rasterize/rasterize.html

Paul


On 01/06/18 08:56, Ed Siefker wrote:
> I have two chromatograms I want plotted on the same axes.
> I would like the plots to be transparent, so the first chart is
> not obscured.
> 
> I have tried adjustcolor(..., alpha.f=0.3), the problem is that
> my chromatogram is so dense with datapoints that they
> overlap and the entire graph just ends up a solid color.  The
> second histogram still obscures the first.
> 
> Consider this example:
> 
> 
> col1 <- adjustcolor("red", alpha.f=0.3)
> col2 <- adjustcolor("blue", alpha.f=0.3)
> EU <- data.frame(EuStockMarkets)
> with(EU, plot(DAX, CAC, col=col2, type="h", ylim=c(0,6000)))
> par(new=TRUE)
> with(EU, plot(DAX, FTSE, col=col1, type="h", ylim=c(0,6000)))
> 
> The density of the red plot around 2000 completely obscures the blue
> plot behind it.
> 
> What I would like to do is plot both plots in solid colors, then alpha
> the entire thing, and then overlay them.  Or some other method that
> achieves a comparable result.
> Thanks
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From pb @end|ng |rom |n|o||nk@com@br  Tue Jun  5 00:03:51 2018
From: pb @end|ng |rom |n|o||nk@com@br (Paulo Barata)
Date: Mon, 4 Jun 2018 19:03:51 -0300
Subject: [R] malware reported by antivirus on R Windows .exe file
Message-ID: <181e2208-1f3c-50de-1cb9-0d26a39d4159@infolink.com.br>

Dear R-list members,

This is just to make a report: Today, 04 June 2018, I attempted to 
download R-3.5.0 Patched build for Windows (a .exe file) from the 
Austria CRAN https site. My antivirus software, AVG Internet Security 
with all the latest updates, aborted the connection, saying that some 
malware was found - please see the attached Figure 1.

I went then to the CRAN mirror at Oswaldo Cruz Foundation, Rio de 
Janeiro, Brazil, and was able to download the .exe file. I immediately 
asked the AVG software to scan the file; it found something suspicious 
and sent the file for analysis in their labs. Some hours later, AVG said 
that the file was malicious, and sent it to quarantine; I am not able to 
figure out which kind of malware was supposed to exist in the file - 
please see the attached Figure 2.

Yesterday I was also not able to download the .exe file from the Austria 
CRAN site, for the same reason.

I am not able to evaluate the technical corretness of AVG's decisions. I 
am only reporting what happened.

Paulo Barata

(Rio de Janeiro - Brazil)


-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fig-1-Link-from-CRAN-Austria-for-R-3.5.0-patched-0n-04-June-2018.png
Type: image/png
Size: 87899 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180604/29a72f2a/attachment-0004.png>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Fig-2-R-3.5.0-patched-from-Fiocruz-Brazil-site-on-04-June-2018.png
Type: image/png
Size: 25795 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180604/29a72f2a/attachment-0005.png>

From pd@|gd @end|ng |rom gm@||@com  Tue Jun  5 12:19:38 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Tue, 5 Jun 2018 12:19:38 +0200
Subject: [R] malware reported by antivirus on R Windows .exe file
In-Reply-To: <181e2208-1f3c-50de-1cb9-0d26a39d4159@infolink.com.br>
References: <181e2208-1f3c-50de-1cb9-0d26a39d4159@infolink.com.br>
Message-ID: <69F308AA-E502-41CB-9995-7F48978AA590@gmail.com>

These are almost always false positives. The checks are based on checksumming and sometimes a perfectly innocent .exe will match the checksum of some virus/malware. The .exe is rebuilt nightly and changes slightly between builds, so you may want just retry after a day or so.

(The AV vendors are behaving pretty irresponsibly in these matters, but as long as it only hits a patch build, I don't think anyone cares enough to take action.)

-pd

> On 5 Jun 2018, at 00:03 , Paulo Barata <pb at infolink.com.br> wrote:
> 
> Dear R-list members,
> 
> This is just to make a report: Today, 04 June 2018, I attempted to download R-3.5.0 Patched build for Windows (a .exe file) from the Austria CRAN https site. My antivirus software, AVG Internet Security with all the latest updates, aborted the connection, saying that some malware was found - please see the attached Figure 1.
> 
> I went then to the CRAN mirror at Oswaldo Cruz Foundation, Rio de Janeiro, Brazil, and was able to download the .exe file. I immediately asked the AVG software to scan the file; it found something suspicious and sent the file for analysis in their labs. Some hours later, AVG said that the file was malicious, and sent it to quarantine; I am not able to figure out which kind of malware was supposed to exist in the file - please see the attached Figure 2.
> 
> Yesterday I was also not able to download the .exe file from the Austria CRAN site, for the same reason.
> 
> I am not able to evaluate the technical corretness of AVG's decisions. I am only reporting what happened.
> 
> Paulo Barata
> 
> (Rio de Janeiro - Brazil)
> 
> <Fig-1-Link-from-CRAN-Austria-for-R-3.5.0-patched-0n-04-June-2018.png><Fig-2-R-3.5.0-patched-from-Fiocruz-Brazil-site-on-04-June-2018.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From z||@t@erv @end|ng |rom gm@||@com  Tue Jun  5 16:24:04 2018
From: z||@t@erv @end|ng |rom gm@||@com (zListserv)
Date: Tue, 5 Jun 2018 10:24:04 -0400
Subject: [R] Printing left-justified character strings
Message-ID: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>

Many (most?) R functions print character strings and factor labels right-justified.

print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.

Is there a way to set left-justification globally so every routine will print character strings left-justified?


From devendr@@|ngh260 @end|ng |rom gm@||@com  Tue Jun  5 15:37:13 2018
From: devendr@@|ngh260 @end|ng |rom gm@||@com (Devendra Singh)
Date: Tue, 5 Jun 2018 15:37:13 +0200
Subject: [R] Convert data frame to XML-Tree
Message-ID: <CAMSHyTNffGLjJQw8PY-pGq119TTcjLAm7u9COMKz1fA87ptZhw@mail.gmail.com>

Dear



I trying to convert data frame in xml using R in Spotfire. But getting
error:



"In xmlRoot.XMLInternalDocument(currentNodes[[1]]) : empty XML document"



Please Help.



Regards

Devendra

Regards
Devendra
Mobile-+91 8884266448

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Tue Jun  5 16:07:11 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (ruipbarradas)
Date: Tue, 05 Jun 2018 15:07:11 +0100
Subject: [R] malware reported by antivirus on R Windows .exe file
Message-ID: <h5nc2l40efyr7obq0fwlw45r.1528207631724@email.android.com>

Hello,
I had a similar problem a while ago.And it was also a problem with AVG.Apparently these false positives are a known issue with that AV. At the time I got an answer directing me to an online source on this but it was some 3-4 years ago and I don't believe I still have it.
Anyway, the problem was not worrying.
Hope this helps,
Rui Barradas?



Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: peter dalgaard <pdalgd at gmail.com> Data: 05/06/2018  11:19  (GMT+00:00) Para: Paulo Barata <pb at infolink.com.br> Cc: r-help at r-project.org Assunto: Re: [R] malware reported by antivirus on R Windows .exe file 
These are almost always false positives. The checks are based on checksumming and sometimes a perfectly innocent .exe will match the checksum of some virus/malware. The .exe is rebuilt nightly and changes slightly between builds, so you may want just retry after a day or so.

(The AV vendors are behaving pretty irresponsibly in these matters, but as long as it only hits a patch build, I don't think anyone cares enough to take action.)

-pd

> On 5 Jun 2018, at 00:03 , Paulo Barata <pb at infolink.com.br> wrote:
> 
> Dear R-list members,
> 
> This is just to make a report: Today, 04 June 2018, I attempted to download R-3.5.0 Patched build for Windows (a .exe file) from the Austria CRAN https site. My antivirus software, AVG Internet Security with all the latest updates, aborted the connection, saying that some malware was found - please see the attached Figure 1.
> 
> I went then to the CRAN mirror at Oswaldo Cruz Foundation, Rio de Janeiro, Brazil, and was able to download the .exe file. I immediately asked the AVG software to scan the file; it found something suspicious and sent the file for analysis in their labs. Some hours later, AVG said that the file was malicious, and sent it to quarantine; I am not able to figure out which kind of malware was supposed to exist in the file - please see the attached Figure 2.
> 
> Yesterday I was also not able to download the .exe file from the Austria CRAN site, for the same reason.
> 
> I am not able to evaluate the technical corretness of AVG's decisions. I am only reporting what happened.
> 
> Paulo Barata
> 
> (Rio de Janeiro - Brazil)
> 
> <Fig-1-Link-from-CRAN-Austria-for-R-3.5.0-patched-0n-04-June-2018.png><Fig-2-R-3.5.0-patched-from-Fiocruz-Brazil-site-on-04-June-2018.png>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk? Priv: PDalgd at gmail.com

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jun  5 18:39:45 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 5 Jun 2018 12:39:45 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
Message-ID: <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>

On 05/06/2018 10:24 AM, zListserv wrote:
> Many (most?) R functions print character strings and factor labels right-justified.

Could you be more specific?  I see character strings left justified, 
e.g. x <- rep(c("a", "ab", "abc"), 7) prints as

   [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
   [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
  [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"

In a data frame, I do see it right justified:

      x
1    a
2   ab
3  abc
etc.

It is easy to change the printing of data frames:

print.data.frame <- function(x, ..., right = FALSE) {
   base::print.data.frame(x, ..., right = right)
}

 > data.frame(x)
    x
1  a
2  ab
3  abc

Are there other examples you're seeing?

Duncan Murdoch

> 
> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
> 
> Is there a way to set left-justification globally so every routine will print character strings left-justified?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From cry@n @end|ng |rom b|ngh@mton@edu  Tue Jun  5 18:45:20 2018
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W Ryan)
Date: Tue, 5 Jun 2018 12:45:20 -0400
Subject: [R] printing an arbitrary-length character vector in columns on a
 page of a pdf report
Message-ID: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>

I'm writing code for a recurring report, using an R --> Sweave --> pdflatex
workflow. It includes a character vector of short words that I would like
to display compactly, in columns on a page, rather than one word per line,
which would waste a lot of space. The vector of words will increase
unpredictably over time, with future versions of the report.

I thought I would go about it by turning the character vector into a
matrix, as follows:

dd <- LETTERS
## set number of columns. Three for now
nc <- 3
## have to pad the character vector to a length that is multiple of nc
add <- nc - (length(dd) %% nc)
dd2 <- c(dd, rep("", add))
ddm <- matrix(dd2, ncol = nc)
library(Hmisc)
latex(ddm, file = "")

Any ideas for a more elegant way to do this?

Thanks.

--Chris Ryan
Binghamton University
and
Broome County Health Department
Binghamton, NY, US

	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Tue Jun  5 19:21:56 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Tue, 5 Jun 2018 17:21:56 +0000
Subject: [R] Printing left-justified character strings
In-Reply-To: <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
Message-ID: <d347321be5724187bdc962ffc1633c1c@tamu.edu>

I think the OP does not realize that head() and tail() do not print anything. They extract the first or last values/rows and if they are not assigned to an object, they automatically go to print(). 

Redefining print.data.frame would also fix that problem.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Duncan Murdoch
Sent: Tuesday, June 5, 2018 11:40 AM
To: zListserv <zlistserv at gmail.com>; r-help at r-project.org
Subject: Re: [R] Printing left-justified character strings

On 05/06/2018 10:24 AM, zListserv wrote:
> Many (most?) R functions print character strings and factor labels right-justified.

Could you be more specific?  I see character strings left justified, 
e.g. x <- rep(c("a", "ab", "abc"), 7) prints as

   [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
   [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
  [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"

In a data frame, I do see it right justified:

      x
1    a
2   ab
3  abc
etc.

It is easy to change the printing of data frames:

print.data.frame <- function(x, ..., right = FALSE) {
   base::print.data.frame(x, ..., right = right)
}

 > data.frame(x)
    x
1  a
2  ab
3  abc

Are there other examples you're seeing?

Duncan Murdoch

> 
> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
> 
> Is there a way to set left-justification globally so every routine will print character strings left-justified?
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From z||@t@erv @end|ng |rom gm@||@com  Tue Jun  5 20:49:24 2018
From: z||@t@erv @end|ng |rom gm@||@com (zListserv)
Date: Tue, 5 Jun 2018 14:49:24 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
Message-ID: <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>

Duncan et al

I tried to redefine print.data.frame the way you suggested, but I misplaced the ellipsis by putting it at the end of the function definition instead of immediately following the name of the data frame.

Works now.

Thanks!


> On 2018-06-05, at 12:39, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/06/2018 10:24 AM, zListserv wrote:
>> Many (most?) R functions print character strings and factor labels right-justified.
> 
> Could you be more specific?  I see character strings left justified, e.g. x <- rep(c("a", "ab", "abc"), 7) prints as
> 
>  [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
>  [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
> [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"
> 
> In a data frame, I do see it right justified:
> 
>     x
> 1    a
> 2   ab
> 3  abc
> etc.
> 
> It is easy to change the printing of data frames:
> 
> print.data.frame <- function(x, ..., right = FALSE) {
>  base::print.data.frame(x, ..., right = right)
> }
> 
> > data.frame(x)
>   x
> 1  a
> 2  ab
> 3  abc
> 
> Are there other examples you're seeing?
> 
> Duncan Murdoch
> 
>> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
>> Is there a way to set left-justification globally so every routine will print character strings left-justified?
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 



From z||@t@erv @end|ng |rom gm@||@com  Wed Jun  6 01:49:10 2018
From: z||@t@erv @end|ng |rom gm@||@com (zListserv)
Date: Tue, 5 Jun 2018 19:49:10 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
Message-ID: <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>

p.s.  It seems to work for print command, but not for head, tail, or printing a data frame, per below.  Any way fix the others so they all left-justify?

R> x <- as.data.frame(rep(c("a", "ab", "abc"), 7))
R> print(x)
 rep(c("a", "ab", "abc"), 7)
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
 a                          
 ab                         
 abc                        
R> head(x)
  rep(c("a", "ab", "abc"), 7)
1                           a
2                          ab
3                         abc
4                           a
5                          ab
6                         abc
R> x
   rep(c("a", "ab", "abc"), 7)
1                            a
2                           ab
3                          abc
4                            a
5                           ab
6                          abc
7                            a
8                           ab
9                          abc
10                           a
11                          ab
12                         abc
13                           a
14                          ab
15                         abc
16                           a
17                          ab
18                         abc
19                           a
20                          ab
21                         abc

> On 2018-06-05, at 14:49, zListserv <zlistserv at gmail.com> wrote:
> 
> Duncan et al
> 
> I tried to redefine print.data.frame the way you suggested, but I misplaced the ellipsis by putting it at the end of the function definition instead of immediately following the name of the data frame.
> 
> Works now.
> 
> Thanks!
> 
> 
>> On 2018-06-05, at 12:39, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 05/06/2018 10:24 AM, zListserv wrote:
>>> Many (most?) R functions print character strings and factor labels right-justified.
>> 
>> Could you be more specific?  I see character strings left justified, e.g. x <- rep(c("a", "ab", "abc"), 7) prints as
>> 
>> [1] "a"   "ab"  "abc" "a"   "ab"  "abc" "a"
>> [8] "ab"  "abc" "a"   "ab"  "abc" "a"   "ab"
>> [15] "abc" "a"   "ab"  "abc" "a"   "ab"  "abc"
>> 
>> In a data frame, I do see it right justified:
>> 
>>    x
>> 1    a
>> 2   ab
>> 3  abc
>> etc.
>> 
>> It is easy to change the printing of data frames:
>> 
>> print.data.frame <- function(x, ..., right = FALSE) {
>> base::print.data.frame(x, ..., right = right)
>> }
>> 
>>> data.frame(x)
>>  x
>> 1  a
>> 2  ab
>> 3  abc
>> 
>> Are there other examples you're seeing?
>> 
>> Duncan Murdoch
>> 
>>> print accepts right=FALSE to print character strings left-justified, but neither head nor tail seem to do so, and even print is a little inconsistent depending on whether it's done while knitting.
>>> Is there a way to set left-justification globally so every routine will print character strings left-justified?
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>> 
> 



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jun  6 02:16:10 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Tue, 5 Jun 2018 20:16:10 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
Message-ID: <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>

On 05/06/2018 7:49 PM, zListserv wrote:
> p.s.  It seems to work for print command, but not for head, tail, or printing a data frame, per below.  Any way fix the others so they all left-justify?

You haven't shown us what you did.

Duncan Murdoch



From ccberry @end|ng |rom uc@d@edu  Wed Jun  6 04:33:07 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Wed, 6 Jun 2018 02:33:07 +0000
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
Message-ID: <BA0E392E-508F-4C93-A577-A156C93ACCF6@ucsd.edu>



> On Jun 5, 2018, at 9:45 AM, Christopher W Ryan <cryan at binghamton.edu> wrote:
> 
> I'm writing code for a recurring report, using an R --> Sweave --> pdflatex
> workflow. It includes a character vector of short words that I would like
> to display compactly, in columns on a page, rather than one word per line,
> which would waste a lot of space. The vector of words will increase
> unpredictably over time, with future versions of the report.
> 
> I thought I would go about it by turning the character vector into a
> matrix, as follows:
> 
> dd <- LETTERS
> ## set number of columns. Three for now
> nc <- 3
> ## have to pad the character vector to a length that is multiple of nc
> add <- nc - (length(dd) %% nc)
> dd2 <- c(dd, rep("", add))
> ddm <- matrix(dd2, ncol = nc)
> library(Hmisc)
> latex(ddm, file = "")
> 
> Any ideas for a more elegant way to do this?
> 

Use a LaTeX longtable environment (and add \usepackage{longtable} to the header of your document). Put something like this in your *.Rnw file:

% longtable header goes here

<<results=tex>>=
cat( paste(dd, ifelse( seq(along = dd) %% 3 == 0, "\\\\\n", "&")) )
@

% longtable footer goes here

should do it. But if there are exactly 3*k elements, you might skip the trailing `\\'.

If you are unclear what the header/footer ought to look like try this:

HMisc::latex(ddm, file="", longtable=TRUE)

and you should figure it out.

HTH,

Chuck


From rmh @end|ng |rom temp|e@edu  Wed Jun  6 05:10:53 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Tue, 5 Jun 2018 23:10:53 -0400
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
Message-ID: <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>

I think this is cuter, and it is a hair faster.

n <- length(dd)
ddm <- matrix("", (n+2) %/% nc, nc)
ddm[1:n] <- dd

Rich


> system.time(for (i in 1:10000) {
+ add <- nc - (length(dd) %% nc)
+ dd2 <- c(dd, rep("", add))
+ ddm <- matrix(dd2, ncol = nc)
+ })
   user  system elapsed
  0.064   0.100   0.483
>
> system.time(for (i in 1:10000) {
+ n <- length(dd)
+ ddm <- matrix("", (n+2) %/% nc, nc)
+ ddm[1:n] <- dd
+ })
   user  system elapsed
  0.045   0.000   0.045

On Tue, Jun 5, 2018 at 12:45 PM, Christopher W Ryan
<cryan at binghamton.edu> wrote:
> I'm writing code for a recurring report, using an R --> Sweave --> pdflatex
> workflow. It includes a character vector of short words that I would like
> to display compactly, in columns on a page, rather than one word per line,
> which would waste a lot of space. The vector of words will increase
> unpredictably over time, with future versions of the report.
>
> I thought I would go about it by turning the character vector into a
> matrix, as follows:
>
> dd <- LETTERS
> ## set number of columns. Three for now
> nc <- 3
> ## have to pad the character vector to a length that is multiple of nc
> add <- nc - (length(dd) %% nc)
> dd2 <- c(dd, rep("", add))
> ddm <- matrix(dd2, ncol = nc)
> library(Hmisc)
> latex(ddm, file = "")
>
> Any ideas for a more elegant way to do this?
>
> Thanks.
>
> --Chris Ryan
> Binghamton University
> and
> Broome County Health Department
> Binghamton, NY, US
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From cry@n @end|ng |rom b|ngh@mton@edu  Wed Jun  6 05:29:44 2018
From: cry@n @end|ng |rom b|ngh@mton@edu (Christopher W. Ryan)
Date: Tue, 5 Jun 2018 23:29:44 -0400
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
 <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>
Message-ID: <cf5ee983-45a5-50e1-3ff1-0e6eefe21a4f@binghamton.edu>

Richard--

Nice. If I understand your code correctly, in the line

ddm <- matrix("", (n+2) %/% nc, nc)

I could instead use

ddm <- matrix("", (n + nc - 1) %/% nc, nc)

for generalizability, as I may have to increase nc as the list of words
grows ever longer.

Thanks everyone. Several good suggestions.

--Chris Ryan

Richard M. Heiberger wrote:
> n <- length(dd)
> ddm <- matrix("", (n+2) %/% nc, nc)
> ddm[1:n] <- dd



From rmh @end|ng |rom temp|e@edu  Wed Jun  6 06:52:45 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 6 Jun 2018 00:52:45 -0400
Subject: [R] 
 printing an arbitrary-length character vector in columns on a
 page of a pdf report
In-Reply-To: <cf5ee983-45a5-50e1-3ff1-0e6eefe21a4f@binghamton.edu>
References: <CAM+rpY=_Y2sRZ8P13aXFw_85RZAcZYDehpyjGEtY-Zth-j4v0w@mail.gmail.com>
 <CAGx1TMC-DtojLgsg99T=XCMPuX3Fn_JYTkpPoG6D4UmiVTAr4A@mail.gmail.com>
 <cf5ee983-45a5-50e1-3ff1-0e6eefe21a4f@binghamton.edu>
Message-ID: <CAGx1TMB9vihNrHDbDGqHi3nw2Hdnr2zWpPtAin4=hsRf6vNM=g@mail.gmail.com>

yes, thank you for catching that slip.

On Tue, Jun 5, 2018 at 11:29 PM, Christopher W. Ryan
<cryan at binghamton.edu> wrote:
> Richard--
>
> Nice. If I understand your code correctly, in the line
>
> ddm <- matrix("", (n+2) %/% nc, nc)
>
> I could instead use
>
> ddm <- matrix("", (n + nc - 1) %/% nc, nc)
>
> for generalizability, as I may have to increase nc as the list of words
> grows ever longer.
>
> Thanks everyone. Several good suggestions.
>
> --Chris Ryan
>
> Richard M. Heiberger wrote:
>> n <- length(dd)
>> ddm <- matrix("", (n+2) %/% nc, nc)
>> ddm[1:n] <- dd
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From nguy2952 @end|ng |rom umn@edu  Wed Jun  6 04:35:27 2018
From: nguy2952 @end|ng |rom umn@edu (nguy2952 University of Minnesota)
Date: Tue, 5 Jun 2018 21:35:27 -0500
Subject: [R] Decision Tree Issue: Why does tree() not pick all variables for
 the nodes
Message-ID: <CAPjFEwUxA7yG=mqHYiL5m439yuTOOiysOX4n9FFmqs8nkUZdMg@mail.gmail.com>

I am working on a project at my work place and I am running into some
issues with my decision tree analysis. THIS IS NOT A HOMEWORK ASSIGNMENT.
Sample dataset

    PRODUCT_SUB_LINE_DESCR   MAJOR_CATEGORY_DESCR      CUST_REGION_DESCR
    SUNDRY                        SMALL EQUIP          NORTH EAST REGION
    SUNDRY                        SMALL EQUIP          SOUTH EAST REGION
    SUNDRY                        SMALL EQUIP          SOUTH EAST REGION
    SUNDRY                        SMALL EQUIP          NORTH EAST REGION
    SUNDRY                        PREVENTIVE          SOUTH CENTRAL REGION
    SUNDRY                        PREVENTIVE          SOUTH EAST REGION
    SUNDRY                        PREVENTIVE          SOUTH EAST REGION
    SUNDRY                        SMALL EQUIP          NORTH CENTRAL REGION
    SUNDRY                        SMALL EQUIP          MOUNTAIN WEST REGION
    SUNDRY                        SMALL EQUIP          MOUNTAIN WEST REGION
    SUNDRY                        COMPOSITE          NORTH CENTRAL REGION
    SUNDRY                        COMPOSITE          NORTH CENTRAL REGION
    SUNDRY                        COMPOSITE          OHIO VALLEY REGION
    SUNDRY                        COMPOSITE          NORTH EAST REGION

    Sales QtySold      MFGCOST MarginDollars new_ProductName
    209.97 3           134.55 72.72          no
    -76.15 -1           -44.85 -30.4          no
    275.6 2           162.5     109.84          no
    138.7 1           81.25     55.82          no
    226     2           136     87.28          no
    115     1           68     45.64          no
    210.7 2           136     71.98          no
    29     1           18.85     9.77          no
    29     1           18.85     9.77          no
    46.32 2           37.7     7.86          no
    159.86 1           132.4     24.81          no
    441.3 2           264.8     171.2          no
    209.62 1           132.4     74.57          no
    209.62 1           132.4     74.57          no

1) My tree has only two nodes and here is why

    >summary(tree_model)
    Classification tree:
    tree(formula = new_ProductName ~ ., data = training_data)
    Variables actually used in tree construction:
    [1] "PRODUCT_SUB_LINE_DESCR"
    Number of terminal nodes:  2
    Residual mean deviance:  0 = 0 / 41140
    Misclassification error rate: 0 = 0 / 41146

2) I did create a new data frame which has only factors with level less
than 22 level. There is one factor with 25 levels, but the tree() does not
give an error so I think the algorithm accepts 25 levels

    >str(new_Dataset)
    'data.frame': 51433 obs. of  7 variables:
     $ PRODUCT_SUB_LINE_DESCR: Factor w/ 3 levels "Handpieces","PRIVATE
                                 LABEL",..: 3 3 3 3 3 3 3 3 3 3 ...
     $ MAJOR_CATEGORY_DESCR  : Factor w/ 25 levels "AIR ABRASION",..: 23 23
23
                                 23 21 21 21 23 23 23 ...
     $ CUST_REGION_DESCR     : Factor w/ 7 levels "MOUNTAIN WEST
REGION",..: 3
                                 6 6 3 5 6 6 2 1 1 ...
     $ Sales                 : num  210 -76.2 275.6 138.7 226 ...
     $ QtySold               : int  3 -1 2 1 2 1 2 1 1 2 ...
     $ MFGCOST               : num  134.6 -44.9 162.5 81.2 136 ...
     $ MarginDollars         : num  72.7 -30.4 109.8 55.8 87.3 ...

3) Here is how I set up my analysis

     # I choose product name as my main attribute(maybe that is why it
appears at
     the root node?)
     new_ProductName = ifelse( PRODUCT_SUB_LINE_DESCR == "PRIVATE
                                  LABEL","yes","no")
     data = data.frame(new_Dataset, new_ProductName)
     set.seed(100)
     train = sample(1:nrow(data), 0.8*nrow(data)) # training row indices
     training_data = data[train,] # training data
     testing_data = data[-train,] # testing data

     #fit the tree model using training data
     tree_model = tree(new_ProductName ~.,data = training_data)
     summary(tree_model)
     plot(tree_model)
     text(tree_model, pretty = 0)
     out = predict(tree_model) # predict the training data
     # actuals
     input.newproduct = as.character(training_data$new_ProductName)
     # predicted
     pred.newproduct = colnames(out)[max.col(out,ties.method = c("first"))]
     mean (input.newproduct != pred.newproduct) # misclassification %

    # Cross Validation to see how much we need to prune the tree
    set.seed(400)
    cv_Tree = cv.tree(tree_model, FUN = prune.misclass) # run cross
validation
    attach(cv_Tree)
    plot(cv_Tree) # plot the CV
    plot(size, dev, type = "b")
    # set size corresponding to lowest value in the plot above.
    treePruneMod = prune.misclass(tree_model, best = 9) plot(treePruneMod)
    text(treePruneMod, pretty = 0)
    out = predict(treePruneMod) # fit the pruned tree
    # Predicted
    pred.newproduct = colnames(out)[max.col(out,ties.method = c("random"))]
    # calculate Mis-classification error
    mean(training_data$new_ProductName != pred.newproduct)
    # Predict testData with Pruned tree
    out = predict(treePruneMod, testing_data, type = "class")

4) I have never done this before. I watched a couple of youtube videos and
started to do this. I welcome great advice, explanation, criticism and
please help me through this process. This has been challenging to me.


    > table(data$PRODUCT_SUB_LINE_DESCR, data$new_ProductName)

                      no      yes
      Handpieces      164     0
      PRIVATE LABEL   0       14802
      SUNDRY          36467    0

Best,
Hugh N

-------------- next part --------------
A non-text attachment was scrubbed...
Name: Rplot01.png
Type: image/png
Size: 13333 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180605/07f77314/attachment-0002.png>

From m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t  Wed Jun  6 10:13:10 2018
From: m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t (Massimo Bressan)
Date: Wed, 6 Jun 2018 10:13:10 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
Message-ID: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>

#given the following reproducible and simplified example 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

#I need to get the following result 

r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
r 

# i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
#any help for that? 

#so far I've just managed to "aggregate" and "count", like: 

library(sqldf) 
sqldf('select count(*) as count_id, A as unique_A from t group by A') 

library(dplyr) 
t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 

# thank you 


	[[alternative HTML version deleted]]



From c@|@ndr@ @end|ng |rom rgzm@de  Wed Jun  6 10:21:48 2018
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Wed, 6 Jun 2018 10:21:48 +0200
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <5628b730-026c-93c2-9c61-60d2407bcc1f@rgzm.de>

Hi Massimo,

Something along those lines could help you I guess:
t$A <- factor(t$A)
sapply(levels(t$A), function(x) which(t$A==x))

You can then play with the output using paste()

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 06/06/2018 10:13, Massimo Bressan wrote:
> #given the following reproducible and simplified example
>
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))
> t
>
> #I need to get the following result
>
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10'))
> r
>
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A"
> #any help for that?
>
> #so far I've just managed to "aggregate" and "count", like:
>
> library(sqldf)
> sqldf('select count(*) as count_id, A as unique_A from t group by A')
>
> library(dplyr)
> t%>%group_by(unique_A=A) %>% summarise(count_id = n())
>
> # thank you
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Wed Jun  6 10:33:56 2018
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Wed, 6 Jun 2018 10:33:56 +0200
Subject: [R] Ubuntu 18.04 / R 3.4.4 / shinyjs / V8
Message-ID: <ee46a9d6-d44f-404c-0c02-d44795a93c10@wiwi.hu-berlin.de>

Hi,

if I want to use shinyjs package then I need the V8 package.
Therefore I installed

apt-get install libv8-3.14-dev

and tried

install.packages("V8")

and get

** preparing package for lazy loading
Error in dyn.load(file, DLLpath = DLLpath, ...) :
   kann shared object 
'/home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so' 
nicht laden:
   /usr/lib/x86_64-linux-gnu/libcurl.so.4: version `CURL_OPENSSL_3' not 
found (required by 
/home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so)
ERROR: lazy loading failed for package ?V8?

I also tried to install curl3, but when I install R 3.4.4 then curl3 is 
replaced by curl4 :(

Any ideas what I could do?

Thanks

Sigbert

-- 
Sprechstunde: Fr 12-13, SPA1, R308
https://hu.berlin/sk
https://hu.berlin/mmstat3


From z||@t@erv @end|ng |rom gm@||@com  Wed Jun  6 12:28:54 2018
From: z||@t@erv @end|ng |rom gm@||@com (zListserv)
Date: Wed, 6 Jun 2018 06:28:54 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
 <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
Message-ID: <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>

Sorry.  Here's how I re-defined print, print.default, and print.data.frame:

print = function(df, ..., right=FALSE, row.names=FALSE) base::print(df, ..., right=right, row.names=row.names)

print.default = function(df, ..., right=FALSE, row.names=FALSE) base::print.default(df, ..., right=right, row.names=row.names)

print.data.frame = function(df, ..., right=FALSE, row.names=FALSE) base::print.data.frame(df, ..., right=right, row.names=row.names)

and this is what it yields (I would like it to print without row names and with text left-adjusted):

R> x <- as.data.frame(rep(c("a", "ab", "abc"), 7))
R> print(x)
rep(c("a", "ab", "abc"), 7)
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
a                          
ab                         
abc                        
R> head(x)
 rep(c("a", "ab", "abc"), 7)
1                           a
2                          ab
3                         abc
4                           a
5                          ab
6                         abc
R> x
  rep(c("a", "ab", "abc"), 7)
1                            a
2                           ab
3                          abc
4                            a
5                           ab
6                          abc
7                            a
8                           ab
9                          abc
10                           a
11                          ab
12                         abc
13                           a
14                          ab
15                         abc
16                           a
17                          ab
18                         abc
19                           a
20                          ab
21                         abc


> On 2018-06-05, at 20:16, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 05/06/2018 7:49 PM, zListserv wrote:
>> p.s.  It seems to work for print command, but not for head, tail, or printing a data frame, per below.  Any way fix the others so they all left-justify?
> 
> You haven't shown us what you did.
> 
> Duncan Murdoch



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jun  6 13:06:30 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 6 Jun 2018 07:06:30 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
 <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
 <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>
Message-ID: <9cdac39e-2d8a-5618-b897-d821655ebc81@gmail.com>

On 06/06/2018 6:28 AM, zListserv wrote:
> Sorry.  Here's how I re-defined print, print.default, and print.data.frame:
> 
> print = function(df, ..., right=FALSE, row.names=FALSE) base::print(df, ..., right=right, row.names=row.names)

base::print doesn't have those arguments.  It only has arguments 
print(x, ...).  You shouldn't redefine it, since it just dispatches to 
one of the methods.

In fact, I think this redefinition is causing the problem way down 
below:  instead of your two methods applying to the base package 
generic, they are applying only to your own generic defined here. 
Auto-printing uses the base generic.

> 
> print.default = function(df, ..., right=FALSE, row.names=FALSE) base::print.default(df, ..., right=right, row.names=row.names)

base::print.default doesn't have a row.names argument.  It won't cause 
an error, but will be ignored.  It already has `right=FALSE` as a 
default, so it seems pretty pointless to redefine it.

> 
> print.data.frame = function(df, ..., right=FALSE, row.names=FALSE) base::print.data.frame(df, ..., right=right, row.names=row.names)

That definition makes sense if you want left justification and no row 
names, but remember that some print methods may rely on the display of 
row names for sensible output.  (I can't think of any examples right 
now, but I'd look at print methods for summary objects if I was 
searching for them.  There are several that rely on row names when they 
print matrices, e.g. print.summary.lm.)

And as a general rule, you should use the same argument names as in the 
generic, i.e. x instead of df.  It's pretty rare, but someone might say
print(x = data.frame(1:10)), and your print.data.frame method would 
absorb the argument into the ... , yielding an error

'argument "df" is missing, with no default'



> 
> and this is what it yields (I would like it to print without row names and with text left-adjusted):
> 
> R> x <- as.data.frame(rep(c("a", "ab", "abc"), 7))
> R> print(x)
> rep(c("a", "ab", "abc"), 7)
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> a
> ab
> abc
> R> head(x)
>   rep(c("a", "ab", "abc"), 7)
> 1                           a
> 2                          ab
> 3                         abc
> 4                           a
> 5                          ab
> 6                         abc

I don't get that, because I didn't redefine the generic, only the methods.

> R> x
>    rep(c("a", "ab", "abc"), 7)
> 1                            a
> 2                           ab
> 3                          abc

Or that.

Duncan Murdoch



From z||@t@erv @end|ng |rom gm@||@com  Wed Jun  6 13:24:03 2018
From: z||@t@erv @end|ng |rom gm@||@com (zListserv)
Date: Wed, 6 Jun 2018 07:24:03 -0400
Subject: [R] Printing left-justified character strings
In-Reply-To: <9cdac39e-2d8a-5618-b897-d821655ebc81@gmail.com>
References: <61709702-9C5D-4F5A-B77F-DF178F19CE4B@gmail.com>
 <b8805f71-3ed6-a50b-c597-ce0812c89482@gmail.com>
 <C64A82C8-D701-435D-A4DF-A55A0C7EC46D@gmail.com>
 <4E15F4A0-7837-47B7-8628-62AF067FC2AA@gmail.com>
 <26bcd19e-c617-2e09-4ce3-f3d50d9991cf@gmail.com>
 <B9E40881-8E6E-4E74-BBAD-42656088C0C1@gmail.com>
 <9cdac39e-2d8a-5618-b897-d821655ebc81@gmail.com>
Message-ID: <D52FDF25-F7C8-4BD0-95B7-372B45E5AA5D@gmail.com>

Duncan

Many thanks.  I removed the (re-)definitions for print and print.default, and I redefined print.data.frame using 'x' instead of 'df'.

Your point about possible issues downstream with row names is well taken.  I'll keep a lookout for any untoward side effects.

In the meantime, all is well and I'm grateful for your help.

> On 2018-06-06, at 07:06, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 06/06/2018 6:28 AM, zListserv wrote:
>> Sorry.  Here's how I re-defined print, print.default, and print.data.frame:
>> print = function(df, ..., right=FALSE, row.names=FALSE) base::print(df, ..., right=right, row.names=row.names)
> 
> base::print doesn't have those arguments.  It only has arguments print(x, ...).  You shouldn't redefine it, since it just dispatches to one of the methods.
> 
> In fact, I think this redefinition is causing the problem way down below:  instead of your two methods applying to the base package generic, they are applying only to your own generic defined here. Auto-printing uses the base generic.
> 
>> print.default = function(df, ..., right=FALSE, row.names=FALSE) base::print.default(df, ..., right=right, row.names=row.names)
> 
> base::print.default doesn't have a row.names argument.  It won't cause an error, but will be ignored.  It already has `right=FALSE` as a default, so it seems pretty pointless to redefine it.
> 
>> print.data.frame = function(df, ..., right=FALSE, row.names=FALSE) base::print.data.frame(df, ..., right=right, row.names=row.names)
> 
> That definition makes sense if you want left justification and no row names, but remember that some print methods may rely on the display of row names for sensible output.  (I can't think of any examples right now, but I'd look at print methods for summary objects if I was searching for them.  There are several that rely on row names when they print matrices, e.g. print.summary.lm.)
> 
> And as a general rule, you should use the same argument names as in the generic, i.e. x instead of df.  It's pretty rare, but someone might say
> print(x = data.frame(1:10)), and your print.data.frame method would absorb the argument into the ... , yielding an error
> 
> 'argument "df" is missing, with no default'
> 
> <snip>



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jun  6 13:24:47 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 6 Jun 2018 11:24:47 +0000
Subject: [R] Help with "ERROR: lazy loading failed for package 'psycho'"
Message-ID: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning. In my continuing pursuit of self-taught R programming I am interested in following the tutorial provided by Bloggers.com "Beautiful and Powerful Correlation Tables in R"


https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r-2/ 3/

Although, I have hit a snag in the first step?

devtools::install_github("neuropsychology/psycho.R") # Install the newest version
library(psycho)
library(tidyverse)

I have installed both psycho & tidyverse pkgs, however, when I go to run the devtools::install_github("neuropsychology/psycho.R") piece I get this warning.

Downloading GitHub repo neuropsychology/psycho.R at master
from URL https://api.github.com/repos/neuropsychology/psycho.R/zipball/master
Installing psycho
"C:/Users/bp/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
  "C:/Users/bp/AppData/Local/Temp/RtmpCkkmhB/devtools25601693478c/neuropsychology-psycho.R-b62e316" --library="C:/Users/bp/Documents/R/R-3.4.4/library" --install-tests

* installing *source* package 'psycho' ...
** R
** data
*** moving datasets to lazyload DB
** inst
** tests
** preparing package for lazy loading
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
  there is no package called 'Matrix'
ERROR: lazy loading failed for package 'psycho'
* removing 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
* restoring previous 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
In R CMD INSTALL
Installation failed: Command failed (1)
> install.packages("psycho")
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.2.3.zip'
Content type 'application/zip' length 1650628 bytes (1.6 MB)
downloaded 1.6 MB

Just a guess, but does this have to do with presetting my work directory?

setwd("C:/WHP/R/PracticeScripts and Testing Ideas")

Here is my session info:


> sessionInfo() #R version 3.4.4 (2018-03-15)

R version 3.4.4 (2018-03-15)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1


.libPaths() #"C:/Users/bp/Documents/R/R-3.4.4/library"

[1] "C:/Users/bp/Documents/R/R-3.4.4/library"


Thank you for any advice.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From er|cjberger @end|ng |rom gm@||@com  Wed Jun  6 13:49:42 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 6 Jun 2018 14:49:42 +0300
Subject: [R] Help with "ERROR: lazy loading failed for package 'psycho'"
In-Reply-To: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAGgJW74p8m+KZg-AapE1uR_tCirV-GGnM-Ddv6j3Cy7xhLC6cQ@mail.gmail.com>

> install.packages("Matrix")


On Wed, Jun 6, 2018 at 2:24 PM, Bill Poling <Bill.Poling at zelis.com> wrote:

> Good morning. In my continuing pursuit of self-taught R programming I am
> interested in following the tutorial provided by Bloggers.com "Beautiful
> and Powerful Correlation Tables in R"
>
>
> https://www.r-bloggers.com/beautiful-and-powerful-
> correlation-tables-in-r-2/ 3/
>
> Although, I have hit a snag in the first step?
>
> devtools::install_github("neuropsychology/psycho.R") # Install the newest
> version
> library(psycho)
> library(tidyverse)
>
> I have installed both psycho & tidyverse pkgs, however, when I go to run
> the devtools::install_github("neuropsychology/psycho.R") piece I get this
> warning.
>
> Downloading GitHub repo neuropsychology/psycho.R at master
> from URL https://api.github.com/repos/neuropsychology/psycho.R/
> zipball/master
> Installing psycho
> "C:/Users/bp/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ
> --no-save --no-restore --quiet CMD INSTALL  \
>   "C:/Users/bp/AppData/Local/Temp/RtmpCkkmhB/devtools25601693478c/
> neuropsychology-psycho.R-b62e316" --library="C:/Users/bp/Documents/R/R-3.4.4/library"
> --install-tests
>
> * installing *source* package 'psycho' ...
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** tests
> ** preparing package for lazy loading
> Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck
> = vI[[j]]) :
>   there is no package called 'Matrix'
> ERROR: lazy loading failed for package 'psycho'
> * removing 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
> * restoring previous 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
> In R CMD INSTALL
> Installation failed: Command failed (1)
> > install.packages("psycho")
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.
> 2.3.zip'
> Content type 'application/zip' length 1650628 bytes (1.6 MB)
> downloaded 1.6 MB
>
> Just a guess, but does this have to do with presetting my work directory?
>
> setwd("C:/WHP/R/PracticeScripts and Testing Ideas")
>
> Here is my session info:
>
>
> > sessionInfo() #R version 3.4.4 (2018-03-15)
>
> R version 3.4.4 (2018-03-15)
>
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> Running under: Windows 7 x64 (build 7601) Service Pack 1
>
>
> .libPaths() #"C:/Users/bp/Documents/R/R-3.4.4/library"
>
> [1] "C:/Users/bp/Documents/R/R-3.4.4/library"
>
>
> Thank you for any advice.
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jun  6 13:53:59 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 6 Jun 2018 11:53:59 +0000
Subject: [R] Help with "ERROR: lazy loading failed for package 'psycho'"
In-Reply-To: <CAGgJW74p8m+KZg-AapE1uR_tCirV-GGnM-Ddv6j3Cy7xhLC6cQ@mail.gmail.com>
References: <CY1PR0201MB1834EB274F977684D69710D6EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CAGgJW74p8m+KZg-AapE1uR_tCirV-GGnM-Ddv6j3Cy7xhLC6cQ@mail.gmail.com>
Message-ID: <CY1PR0201MB18347547A9AE012D0CDFE5F8EA650@CY1PR0201MB1834.namprd02.prod.outlook.com>

Yep, terrific, that?s got it, thank you Eric!

WHP


From: Eric Berger [mailto:ericjberger at gmail.com]
Sent: Wednesday, June 06, 2018 7:50 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with "ERROR: lazy loading failed for package 'psycho'"

> install.packages("Matrix")


On Wed, Jun 6, 2018 at 2:24 PM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
Good morning. In my continuing pursuit of self-taught R programming I am interested in following the tutorial provided by Bloggers.com<http://Bloggers.com> "Beautiful and Powerful Correlation Tables in R"


https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r-2/<https://www.r-bloggers.com/beautiful-and-powerful-correlation-tables-in-r-2/> 3/

Although, I have hit a snag in the first step?

devtools::install_github("neuropsychology/psycho.R") # Install the newest version
library(psycho)
library(tidyverse)

I have installed both psycho & tidyverse pkgs, however, when I go to run the devtools::install_github("neuropsychology/psycho.R") piece I get this warning.

Downloading GitHub repo neuropsychology/psycho.R at master<mailto:neuropsychology/psycho.R at master>
from URL https://api.github.com/repos/neuropsychology/psycho.R/zipball/master<https://api.github.com/repos/neuropsychology/psycho.R/zipball/master>
Installing psycho
"C:/Users/bp/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
  "C:/Users/bp/AppData/Local/Temp/RtmpCkkmhB/devtools25601693478c/neuropsychology-psycho.R-b62e316" --library="C:/Users/bp/Documents/R/R-3.4.4/library" --install-tests

* installing *source* package 'psycho' ...
** R
** data
*** moving datasets to lazyload DB
** inst
** tests
** preparing package for lazy loading
Error in loadNamespace(j <- i[[1L]], c(lib.loc, .libPaths()), versionCheck = vI[[j]]) :
  there is no package called 'Matrix'
ERROR: lazy loading failed for package 'psycho'
* removing 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
* restoring previous 'C:/Users/bp/Documents/R/R-3.4.4/library/psycho'
In R CMD INSTALL
Installation failed: Command failed (1)
> install.packages("psycho")
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.2.3.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/psycho_0.2.3.zip>'
Content type 'application/zip' length 1650628 bytes (1.6 MB)
downloaded 1.6 MB

Just a guess, but does this have to do with presetting my work directory?

setwd("C:/WHP/R/PracticeScripts and Testing Ideas")

Here is my session info:


> sessionInfo() #R version 3.4.4 (2018-03-15)

R version 3.4.4 (2018-03-15)

Platform: x86_64-w64-mingw32/x64 (64-bit)

Running under: Windows 7 x64 (build 7601) Service Pack 1


.libPaths() #"C:/Users/bp/Documents/R/R-3.4.4/library"

[1] "C:/Users/bp/Documents/R/R-3.4.4/library"


Thank you for any advice.

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Wed Jun  6 14:16:30 2018
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Wed, 6 Jun 2018 14:16:30 +0200
Subject: [R] Ubuntu 18.04 / R 3.4.4 / shinyjs / V8
In-Reply-To: <ee46a9d6-d44f-404c-0c02-d44795a93c10@wiwi.hu-berlin.de>
References: <ee46a9d6-d44f-404c-0c02-d44795a93c10@wiwi.hu-berlin.de>
Message-ID: <2455e4e5-570a-78da-c4ff-a8113589651d@wiwi.hu-berlin.de>

Hi,

found myself a workaround:

Replaced the javascript functionality by calls of 
session$sendCustomMesssage(...) & Sys.sleep(...) and deleted 
library(shinyjs) from my code.

Best Sigbert

Am 06.06.2018 um 10:33 schrieb Sigbert Klinke:
> Hi,
> 
> if I want to use shinyjs package then I need the V8 package.
> Therefore I installed
> 
> apt-get install libv8-3.14-dev
> 
> and tried
> 
> install.packages("V8")
> 
> and get
> 
> ** preparing package for lazy loading
> Error in dyn.load(file, DLLpath = DLLpath, ...) :
>  ? kann shared object 
> '/home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so' 
> nicht laden:
>  ? /usr/lib/x86_64-linux-gnu/libcurl.so.4: version `CURL_OPENSSL_3' not 
> found (required by 
> /home/sigbert/R/x86_64-pc-linux-gnu-library/3.4/curl/libs/curl.so)
> ERROR: lazy loading failed for package ?V8?
> 
> I also tried to install curl3, but when I install R 3.4.4 then curl3 is 
> replaced by curl4 :(
> 
> Any ideas what I could do?
> 
> Thanks
> 
> Sigbert
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Sprechstunde: Fr 12-13, SPA1, R308
https://hu.berlin/sk
https://hu.berlin/mmstat3


From br@n@chr| @end|ng |rom gm@||@com  Wed Jun  6 16:00:49 2018
From: br@n@chr| @end|ng |rom gm@||@com (Christian =?ISO-8859-1?Q?Brandst=E4tter?=)
Date: Wed, 06 Jun 2018 16:00:49 +0200
Subject: [R] Plot in real unit (1:1)
Message-ID: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>

Dear List, 

Is it possible to plot in R in "real" units? I would like to draw a
plot on A4 paper, where 1 plot unit would be a mm in reality. Is
something like that possible? I would also like to be able to scale the
plot in x and y direction. 
Background: For a project I would have to draw around 65 fast sketches
of elevation courves. 

Copied from here, due to no answer: https://stackoverflow.com/questions
/50606797/plot-in-real-units-mm

Thank you!



From |mh_u@er@-group@ @end|ng |rom mo|conn@com  Wed Jun  6 18:27:16 2018
From: |mh_u@er@-group@ @end|ng |rom mo|conn@com (LMH)
Date: Wed, 6 Jun 2018 12:27:16 -0400
Subject: [R] internet routines cannot be loaded, R 3.5.0
Message-ID: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>

Hello,

I recently upgraded my version of R and find I need to reinstall packages
(unless there is some method to import my old profile and files). I have set
my repository to CRAN and set my CRAN mirror to US, NY. If I select
"packages > install packages" in the R console, I get a message, "no
packages were specified". I thought this command gave me a list of packages
available to install.

If I select, "packages > update packages", I get the message,

Warning: unable to access index for repository
https://mirrors.sorengard.com/cran/src/contrib:
  internet routines cannot be loaded
Error in gzfile(file, mode) : cannot open the connection
In addition: Warning message:
In gzfile(file, mode) :
  cannot open compressed file
'C:\DOCUME~1\BASIC_~1\LOCALS~1\Temp\RtmpqiUPQX/libloc_185_34943e0b.rds',
probable reason 'No such file or directory'

I have done a search on, "internet routines cannot be loaded" and don't find
anything that looks relevant.

i have installed some packages manually from local zip files, but many
packages have a large number of dependencies and it would take forever to
download them all.

Can someone help me to get this working?

Thanks,

LMH



From p@|merr @end|ng |rom uth@c@@@edu  Wed Jun  6 19:37:50 2018
From: p@|merr @end|ng |rom uth@c@@@edu (Palmer, Raymond F)
Date: Wed, 6 Jun 2018 17:37:50 +0000
Subject: [R] ROC within SEM
Message-ID: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>

Dear R group.
Does anyone have an idea how to utilize a latent variable in an ROC (AUC) analysis? I want to create a latent variable, then use that latent construct as a continuous variable in an ROC.
I understand both SEM and ROC analysis can be done in R, but how to use the latent variable in the ROC is the issue.
Thanks for any insights.
Best, Ray

Ray Palmer, Ph.D.
Professor
Department of Family and Community Medicine
University of Texas Health Science Center San Antonio
palmerr at uthscsa.edu<mailto:palmerr at uthscsa.edu>
210-827-7681


	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun  6 22:48:03 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 6 Jun 2018 13:48:03 -0700
Subject: [R] ROC within SEM
In-Reply-To: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>
References: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>
Message-ID: <B29381BB-526A-46CF-9589-DC2DC4B204B0@comcast.net>


> On Jun 6, 2018, at 10:37 AM, Palmer, Raymond F <palmerr at uthscsa.edu> wrote:
> 
> Dear R group.
> Does anyone have an idea how to utilize a latent variable in an ROC (AUC) analysis? I want to create a latent variable, then use that latent construct as a continuous variable in an ROC.
> I understand both SEM and ROC analysis can be done in R, but how to use the latent variable in the ROC is the issue.
> Thanks for any insights.
> Best, Ray
> 
> Ray Palmer, Ph.D.
> Professor
> Department of Family and Community Medicine
> University of Texas Health Science Center San Antonio
> palmerr at uthscsa.edu<mailto:palmerr at uthscsa.edu>
> 210-827-7681
> 
> 
> 	[[alternative HTML version deleted]]

There are two sections from the Posting Guide that may be relevant:

---begin--
Questions about statistics: The R mailing lists are primarily intended for questions and discussion about the R software. However, questions about statistical methodology are sometimes posted. If the question is well-asked and of interest to someone on the list, it may elicit an informative up-to-date answer. See also the Usenet groups sci.stat.consult (applied statistics and consulting) and sci.stat.math (mathematical stat and probability).
---end-----

Frankly I would not considered this question to be "well-asked" but anyone is free to dispute this or to take on the task of asking clarifying questions. 

A modern update might add to the Posting Guide in these more web-centric times, the CrossValidated.com site. https://stats.stackexchange.com/search?q=latent+variable+roc

(Those newsgroups are basically defunct.)

> 
---begin--
	? No HTML posting (harder to detect spam) (note that this is the default in some mail clients - you may have to turn it off). Note that chances have become relatively high for ?HTMLified? e-mails to be completely intercepted (without notice to the sender).
---end-

One of the effects of redistribution by a mail-server is the removal of the identity of your mail-client, so advice about that concern can only be "RTFM".


> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From @@r@h@go@|ee @end|ng |rom gm@||@com  Wed Jun  6 22:56:37 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Wed, 6 Jun 2018 16:56:37 -0400
Subject: [R] internet routines cannot be loaded, R 3.5.0
In-Reply-To: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
References: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
Message-ID: <CAM_vjumrLCrrcGR8j9yPvXMDqskH9cTwGuR2HgROb42L1b6wUA@mail.gmail.com>

Hi,

install.packages() will install packages you specify,

update.packages(ask = FALSE, checkBuilt = TRUE)

is a useful way to update all installed packages after a major R update.

Your specific error message is probably because the sorengard mirror is down:

https://cran.r-project.org/mirmon_report.html#us

Pick a different mirror, and it should work.

Sarah

On Wed, Jun 6, 2018 at 12:27 PM, LMH <lmh_users-groups at molconn.com> wrote:
> Hello,
>
> I recently upgraded my version of R and find I need to reinstall packages
> (unless there is some method to import my old profile and files). I have set
> my repository to CRAN and set my CRAN mirror to US, NY. If I select
> "packages > install packages" in the R console, I get a message, "no
> packages were specified". I thought this command gave me a list of packages
> available to install.
>
> If I select, "packages > update packages", I get the message,
>
> Warning: unable to access index for repository
> https://mirrors.sorengard.com/cran/src/contrib:
>   internet routines cannot be loaded
> Error in gzfile(file, mode) : cannot open the connection
> In addition: Warning message:
> In gzfile(file, mode) :
>   cannot open compressed file
> 'C:\DOCUME~1\BASIC_~1\LOCALS~1\Temp\RtmpqiUPQX/libloc_185_34943e0b.rds',
> probable reason 'No such file or directory'
>
> I have done a search on, "internet routines cannot be loaded" and don't find
> anything that looks relevant.
>
> i have installed some packages manually from local zip files, but many
> packages have a large number of dependencies and it would take forever to
> download them all.
>
> Can someone help me to get this working?
>
> Thanks,
>
> LMH
>



From chr|@@@ @end|ng |rom med@um|ch@edu  Wed Jun  6 23:55:29 2018
From: chr|@@@ @end|ng |rom med@um|ch@edu (Andrews, Chris)
Date: Wed, 6 Jun 2018 21:55:29 +0000
Subject: [R] verInd= and HorInd= arguments to pairs() function
Message-ID: <eea156749e3044249cf0b56a264249ef@med.umich.edu>


After making scatterplot matrix, I determined I only needed the first 2 columns of the matrix so I added verInd=1:2 to my pairs() call.  However, it did not turn out as I expected. 

Perhaps the attached pdf of the example code will make it through.  If not, my description is "the wrong scatterplot pairs are in the wrong places" for the last two pairs() calls.

Thanks,
Chris

################################################################

# fake data
xmat <- matrix(1:28, ncol=4)
lim <- range(xmat)

# what I expected
pairs(xmat, xlim=lim, ylim=lim) # 4x4 matrix of scatterplots
pairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:2) # 2x2 matrix of scatterplots: upper left

# here comes trouble
pairs(xmat, xlim=lim, ylim=lim, horInd=1:2) # 2x4 matrix of scatterplots: but not the top 2 rows (or bottom 2 rows)
pairs(xmat, xlim=lim, ylim=lim, verInd=1:2) # 4x2 matrix of scatterplots: but not the left 2 columns (or right 2 columns)


###############################################################

> sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 7 x64 (build 7601) Service Pack 1

Matrix products: default

locale:
[1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C                           LC_TIME=English_United States.1252    

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] compiler_3.5.0 tools_3.5.0   
**********************************************************
Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues 

-------------- next part --------------
A non-text attachment was scrubbed...
Name: pairs.pdf
Type: application/pdf
Size: 9892 bytes
Desc: pairs.pdf
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180606/f4d28bf4/attachment-0002.pdf>

From drj|m|emon @end|ng |rom gm@||@com  Thu Jun  7 00:16:36 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 7 Jun 2018 08:16:36 +1000
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
Message-ID: <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>

Hi Christian,
When I have to do something like this, I usually write it in
Postscript using this:

/def mm 2.8346 mul

that converts a dimension in mm to points (1/72 inch). However, this
won't work in R. It may be possible to set up the device like this:

postscript("myfile.ps",paper="a4")
par(mar=c(0,0,0,0))
# generate a blank plot
plot(0,type="n",xlim=c(0,210),ylim=c(0,297),axes=FALSE)
# display lines, etc. in mm with 0,0 at the bottom left
dev.off()

The resulting file should be printable. Warning, I don't have time to
test this right now.

Jim



On Thu, Jun 7, 2018 at 12:00 AM, Christian Brandst?tter
<bran.chri at gmail.com> wrote:
> Dear List,
>
> Is it possible to plot in R in "real" units? I would like to draw a
> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
> something like that possible? I would also like to be able to scale the
> plot in x and y direction.
> Background: For a project I would have to draw around 65 fast sketches
> of elevation courves.
>
> Copied from here, due to no answer: https://stackoverflow.com/questions
> /50606797/plot-in-real-units-mm
>
> Thank you!
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Jun  7 01:26:58 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 6 Jun 2018 23:26:58 +0000
Subject: [R] Time and date conversion
In-Reply-To: <DA6671CE-8F73-48A0-807B-63A223B9BA4A@gmail.com>
References: <CA+dpOJmzXotkrORaWvKPvq8yp2oDsxUSGDoUuKjP+F2hk3aGSA@mail.gmail.com>
 <DA6671CE-8F73-48A0-807B-63A223B9BA4A@gmail.com>
Message-ID: <AA962A6D-3235-4EA9-A262-C52646476C9B@llnl.gov>

After you've solved the format inconsistency issues, per Peter's advice, you will need to understand that R internally converts and stores the timedate values in UTC. Therefore, it is absolutely essential to give it the correct timezone specification on input.

The user does not "convert to UTC time-zone". Instead, you tell it to format in UTC when you print. If you don't specify a timezone on input, the default timezone will be your local timezone.

Here's an example of how to do it right, assuming "CT" is meant to be the US central timezone.

> t1 <- '2018-02-03 11:15:17 CT'
> t1t <- as.POSIXct(t1, tz='US/Central')
> print(t1t)
[1] "2018-02-03 11:15:17 CST"
> format(t1t, tz='UTC')
[1] "2018-02-03 17:15:17"

UTC is 6 hours ahead of US central time zone in February, so the displayed UTC hour is "17" instead of the US central "11".
The "CT" is ignored on input.

Note that there is no R command to convert from US/Central to UTC. There is only formatting. The actual data itself does not change.

t1u <- '2018-02-03 17:15:17'
t1ut <- as.POSIXct(t1u, tz='UTC')

> as.numeric(t1t)
[1] 1517678117
> as.numeric(t1ut)
[1] 1517678117

If the input time were during so-called daylight savings time (say, in June), the difference would be 5 hours; the UTC formatted hour would be "16".

------- further comments -------
There is some danger in using as.POSIXct, because it does not force you to supply a timezone (whereas strptime does).If no tz is supplied, as.POSIXct will default to the sessions timezone (PST in my case):

> t1p <- as.POSIXct(t1)
> print(t1p)
[1] "2018-02-03 11:15:17 PST"

My system does not recognized "CT" or "CST" as valid timezone codes:

> t1t <- as.POSIXct(t1, tz='CT')
Warning messages:
1: In strptime(xx, f <- "%Y-%m-%d %H:%M:%OS", tz = tz) :
  unknown timezone 'CT'
2: In as.POSIXct.POSIXlt(x) : unknown timezone 'CT'
3: In strptime(x, f, tz = tz) : unknown timezone 'CT'
4: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone 'CT'

> t1t <- as.POSIXct(t1, tz='CST')
Warning messages:
1: In strptime(xx, f <- "%Y-%m-%d %H:%M:%OS", tz = tz) :
  unknown timezone 'CST'
2: In as.POSIXct.POSIXlt(x) : unknown timezone 'CST'
3: In strptime(x, f, tz = tz) : unknown timezone 'CST'
4: In as.POSIXct.POSIXlt(as.POSIXlt(x, tz, ...), tz, ...) :
  unknown timezone 'CST'

R uses the underlying operating system date/time libraries to recognize when an input datetime is during daylight savings time, and converts to UTC accordingly. Therefore, if your incoming character strings are standard time all year around (a standard practice for some kinds of realtime data collection processes, such as for meteorological data), the above timezone codes won't work. You would have to use
    t1ut <- as.POSIXct(t1u, tz='Etc/GMT+6')
for the US central timezone (on a Mac or Linux box; I don't know about Windows).

As far as I understand it, the only way to specify the timezone when coverting from character to datetime is using the 'tz' argument. A timezone as part of the character string will be ignored (see the formatting codes in ?strptime).

I almost always use as.POSIXct() instead of strptime() for conversion from character to datetime, because strptime() returns class POSIXlt, and I generally find POSIXct more appropriate for how I work with datetime data.

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/4/18, 3:54 AM, "R-help on behalf of peter dalgaard" <r-help-bounces at r-project.org on behalf of pdalgd at gmail.com> wrote:

    
    
    > On 4 Jun 2018, at 10:45 , Christofer Bogaso <bogaso.christofer at gmail.com> wrote:
    > 
    > Hi,
    > 
    > I have an automatic data feed and I obtained a Date vector in the following
    > format:
    > 
    >> Date
    > [1] "03 Jun 2018 10:01 am CT"    "01 Jun 2018 22:04:25 pm CT"
    > 
    > I now like to convert it to UTC time-zone
    > 
    > Is there any easy way to convert them so, particularly since 1st element
    > doesnt have any Second element whereas the 2nd element has.
    
    ..and it also mixes up am/pm notation and 24hr clock.
    
    There are two basic approaches to the format inconsistency thing:
    
    (A) preprocess using gsub() constructions 
    
    > gsub(" (..:..) ", " \\1:00 ", d.txt)
    [1] "03 Jun 2018 10:01:00 am CT" "01 Jun 2018 22:04:25 pm CT"
    
    (B) Try multiple formats
    
    > d <- strptime(d.txt, format="%d %B %Y %H:%M:%S %p")
    > d[is.na(d)] <- strptime(d.txt[is.na(d)], format="%d %B %Y %H:%M %p")
    > d
    [1] "2018-06-03 10:01:00 CEST" "2018-06-01 22:04:25 CEST"
    
    I would likely go for (A) since you probably need to do something gsub-ish to get the TZ thing in place.
    
    -pd
    
    > 
    > Thanks for any pointer.
    > 
    > 	[[alternative HTML version deleted]]
    > 
    > ______________________________________________
    > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    > https://stat.ethz.ch/mailman/listinfo/r-help
    > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    > and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Peter Dalgaard, Professor,
    Center for Statistics, Copenhagen Business School
    Solbjerg Plads 3, 2000 Frederiksberg, Denmark
    Phone: (+45)38153501
    Office: A 4.23
    Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From chettyvk @end|ng |rom gm@||@com  Thu Jun  7 05:04:44 2018
From: chettyvk @end|ng |rom gm@||@com (Veerappa Chetty)
Date: Wed, 6 Jun 2018 23:04:44 -0400
Subject: [R] using myfunction in stat_function
Message-ID: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>

HI,

I use solve(A,b) inside my function, myfun2; it works fine when I return
one value or a list.

 I want use the return values in ggplot as below: ggplot(data.frame(
x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
I get a blank graph. Would greatly appreciate help! Thanks.

-- 
Professor of Family Medicine
Boston University
Tel: 617-414-6221, Fax:617-414-3345
emails: chettyvk at gmail.com

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jun  7 05:12:53 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 6 Jun 2018 20:12:53 -0700
Subject: [R] using myfunction in stat_function
In-Reply-To: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
References: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
Message-ID: <5A35A0FB-A019-4449-9DB6-1D8A22E05533@comcast.net>


> On Jun 6, 2018, at 8:04 PM, Veerappa Chetty <chettyvk at gmail.com> wrote:
> 
> HI,
> 
> I use solve(A,b) inside my function, myfun2; it works fine when I return
> one value or a list.
> 
> I want use the return values in ggplot as below:


> ggplot(data.frame(
> x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")

Error in layer(data = data, mapping = mapping, stat = StatFunction, geom = geom,  : 
  object 'myfun.2' not found

> I get a blank graph. Would greatly appreciate help! Thanks.
> 
> -- 
> Professor of Family Medicine
> Boston University
> Tel: 617-414-6221, Fax:617-414-3345
> emails: chettyvk at gmail.com
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From drj|m|emon @end|ng |rom gm@||@com  Thu Jun  7 06:13:20 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 7 Jun 2018 14:13:20 +1000
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
 <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>
Message-ID: <CA+8X3fUGK9FiKdGVudST=Ly-hLiudVWg1MYO_tRjewBLAA6JzA@mail.gmail.com>

Hi Christian,
Well, it almost worked. I suspect that the postscript device adds some
padding to account for the printable area, so with a bit of
experimentation, The following example seems to do what you want. When
I printed the resulting file from the GIMP, the box and diamond were
the correct dimensions.

postscript("test.ps",paper="a4",horizontal=FALSE)
par(mai=c(1.713,0,1.713,0),xaxs="i",yaxs="i")
plot(0,type="n",xlim=c(0,190),ylim=c(0,190),xlab="",axes=FALSE)
segments(c(0,95),c(95,0),c(190,95),c(95,190))
segments(c(45,95,145,95),c(95,145,95,45),
 c(95,145,95,45),c(145,95,45,95))
box()
dev.off()

Jim

On Thu, Jun 7, 2018 at 8:16 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> Hi Christian,
> When I have to do something like this, I usually write it in
> Postscript using this:
>
> /def mm 2.8346 mul
>
> that converts a dimension in mm to points (1/72 inch). However, this
> won't work in R. It may be possible to set up the device like this:
>
> postscript("myfile.ps",paper="a4")
> par(mar=c(0,0,0,0))
> # generate a blank plot
> plot(0,type="n",xlim=c(0,210),ylim=c(0,297),axes=FALSE)
> # display lines, etc. in mm with 0,0 at the bottom left
> dev.off()
>
> The resulting file should be printable. Warning, I don't have time to
> test this right now.
>
> Jim
>
>
>
> On Thu, Jun 7, 2018 at 12:00 AM, Christian Brandst?tter
> <bran.chri at gmail.com> wrote:
>> Dear List,
>>
>> Is it possible to plot in R in "real" units? I would like to draw a
>> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
>> something like that possible? I would also like to be able to scale the
>> plot in x and y direction.
>> Background: For a project I would have to draw around 65 fast sketches
>> of elevation courves.
>>
>> Copied from here, due to no answer: https://stackoverflow.com/questions
>> /50606797/plot-in-real-units-mm
>>
>> Thank you!
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.



From br@n@chr| @end|ng |rom gm@||@com  Thu Jun  7 06:20:37 2018
From: br@n@chr| @end|ng |rom gm@||@com (=?UTF-8?Q?Brandst=C3=A4tter_Christian?=)
Date: Thu, 7 Jun 2018 06:20:37 +0200
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <CA+8X3fUGK9FiKdGVudST=Ly-hLiudVWg1MYO_tRjewBLAA6JzA@mail.gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
 <CA+8X3fXfxy6OrQawPBkJNZfjsHZ2+7w3JnAS9-7ocNsRGbH1qA@mail.gmail.com>
 <CA+8X3fUGK9FiKdGVudST=Ly-hLiudVWg1MYO_tRjewBLAA6JzA@mail.gmail.com>
Message-ID: <CAALi0vJPXGhi0M9+3tCDpBRbt093VMgkjpHRz7ocCFhXMsXxaw@mail.gmail.com>

Thanks a lot!

Jim Lemon <drjimlemon at gmail.com> schrieb am Do., 7. Juni 2018, 06:13:

> Hi Christian,
> Well, it almost worked. I suspect that the postscript device adds some
> padding to account for the printable area, so with a bit of
> experimentation, The following example seems to do what you want. When
> I printed the resulting file from the GIMP, the box and diamond were
> the correct dimensions.
>
> postscript("test.ps",paper="a4",horizontal=FALSE)
> par(mai=c(1.713,0,1.713,0),xaxs="i",yaxs="i")
> plot(0,type="n",xlim=c(0,190),ylim=c(0,190),xlab="",axes=FALSE)
> segments(c(0,95),c(95,0),c(190,95),c(95,190))
> segments(c(45,95,145,95),c(95,145,95,45),
>  c(95,145,95,45),c(145,95,45,95))
> box()
> dev.off()
>
> Jim
>
> On Thu, Jun 7, 2018 at 8:16 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
> > Hi Christian,
> > When I have to do something like this, I usually write it in
> > Postscript using this:
> >
> > /def mm 2.8346 mul
> >
> > that converts a dimension in mm to points (1/72 inch). However, this
> > won't work in R. It may be possible to set up the device like this:
> >
> > postscript("myfile.ps",paper="a4")
> > par(mar=c(0,0,0,0))
> > # generate a blank plot
> > plot(0,type="n",xlim=c(0,210),ylim=c(0,297),axes=FALSE)
> > # display lines, etc. in mm with 0,0 at the bottom left
> > dev.off()
> >
> > The resulting file should be printable. Warning, I don't have time to
> > test this right now.
> >
> > Jim
> >
> >
> >
> > On Thu, Jun 7, 2018 at 12:00 AM, Christian Brandst?tter
> > <bran.chri at gmail.com> wrote:
> >> Dear List,
> >>
> >> Is it possible to plot in R in "real" units? I would like to draw a
> >> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
> >> something like that possible? I would also like to be able to scale the
> >> plot in x and y direction.
> >> Background: For a project I would have to draw around 65 fast sketches
> >> of elevation courves.
> >>
> >> Copied from here, due to no answer: https://stackoverflow.com/questions
> >> /50606797/plot-in-real-units-mm
> >>
> >> Thank you!
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Thu Jun  7 09:03:46 2018
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Thu, 7 Jun 2018 09:03:46 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
Message-ID: <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>

Hi, Chris,

had the same problem (and first thought it was my fault), but there
seems to be a typo in the code of pairs.default. Below is a workaround.
Look for two comments (starting with #####) in the code to see what I
have changed to make it work at least the way I'd expect it in one of
your examples.

  Hth --  Gerrit


mypairs <- function (x, labels, panel = points, ...,
     horInd = 1:nc, verInd = 1:nc,
     lower.panel = panel, upper.panel = panel, diag.panel = NULL,
     text.panel = textPanel, label.pos = 0.5 + has.diag/3, line.main = 3,
     cex.labels = NULL, font.labels = 1, row1attop = TRUE, gap = 1,
     log = "") {
     if (doText <- missing(text.panel) || is.function(text.panel))
         textPanel <- function(x = 0.5, y = 0.5, txt, cex, font) text(x,
             y, txt, cex = cex, font = font)
     localAxis <- function(side, x, y, xpd, bg, col = NULL, main,
         oma, ...) {
         xpd <- NA
         if (side%%2L == 1L && xl[j])
             xpd <- FALSE
         if (side%%2L == 0L && yl[i])
             xpd <- FALSE
         if (side%%2L == 1L)
             Axis(x, side = side, xpd = xpd, ...)
         else Axis(y, side = side, xpd = xpd, ...)
     }
     localPlot <- function(..., main, oma, font.main, cex.main) plot(...)
     localLowerPanel <- function(..., main, oma, font.main, cex.main) 
lower.panel(...)
     localUpperPanel <- function(..., main, oma, font.main, cex.main) 
upper.panel(...)
     localDiagPanel <- function(..., main, oma, font.main, cex.main) 
diag.panel(...)
     dots <- list(...)
     nmdots <- names(dots)
     if (!is.matrix(x)) {
         x <- as.data.frame(x)
         for (i in seq_along(names(x))) {
             if (is.factor(x[[i]]) || is.logical(x[[i]]))
                 x[[i]] <- as.numeric(x[[i]])
             if (!is.numeric(unclass(x[[i]])))
                 stop("non-numeric argument to 'pairs'")
         }
     }
     else if (!is.numeric(x))
         stop("non-numeric argument to 'pairs'")
     panel <- match.fun(panel)
     if ((has.lower <- !is.null(lower.panel)) && !missing(lower.panel))
         lower.panel <- match.fun(lower.panel)
     if ((has.upper <- !is.null(upper.panel)) && !missing(upper.panel))
         upper.panel <- match.fun(upper.panel)
     if ((has.diag <- !is.null(diag.panel)) && !missing(diag.panel))
         diag.panel <- match.fun(diag.panel)
     if (row1attop) {
         tmp <- lower.panel
         lower.panel <- upper.panel
         upper.panel <- tmp
         tmp <- has.lower
         has.lower <- has.upper
         has.upper <- tmp
     }
     nc <- ncol(x)
     if (nc < 2L)
         stop("only one column in the argument to 'pairs'")
     if (!all(horInd >= 1L && horInd <= nc))
         stop("invalid argument 'horInd'")
     if (!all(verInd >= 1L && verInd <= nc))
         stop("invalid argument 'verInd'")
     if (doText) {
         if (missing(labels)) {
             labels <- colnames(x)
             if (is.null(labels))
                 labels <- paste("var", 1L:nc)
         }
         else if (is.null(labels))
             doText <- FALSE
     }
     oma <- if ("oma" %in% nmdots)
         dots$oma
     main <- if ("main" %in% nmdots)
         dots$main
     if (is.null(oma))
         oma <- c(4, 4, if (!is.null(main)) 6 else 4, 4)
     opar <- par(mfcol = c(length(horInd), length(verInd)),
##### Changed from mfrow to mfcol
                 mar = rep.int(gap/2, 4), oma = oma)
     on.exit(par(opar))
     dev.hold()
     on.exit(dev.flush(), add = TRUE)
     xl <- yl <- logical(nc)
     if (is.numeric(log))
         xl[log] <- yl[log] <- TRUE
     else {
         xl[] <- grepl("x", log)
         yl[] <- grepl("y", log)
     }
     for (j in if (row1attop) verInd else rev(verInd))
      for (i in horInd) {
##### Exchanged i and j. (i used to be in
##### the outer and j in the inner loop!)
         l <- paste0(ifelse(xl[j], "x", ""), ifelse(yl[i], "y", ""))
         localPlot(x[, j], x[, i], xlab = "", ylab = "", axes = FALSE,
             type = "n", ..., log = l)
         if (i == j || (i < j && has.lower) || (i > j && has.upper)) {
             box()
             if (i == 1 && (!(j%%2L) || !has.upper || !has.lower))
                 localAxis(1L + 2L * row1attop, x[, j], x[, i],
                   ...)
             if (i == nc && (j%%2L || !has.upper || !has.lower))
                 localAxis(3L - 2L * row1attop, x[, j], x[, i],
                   ...)
             if (j == 1 && (!(i%%2L) || !has.upper || !has.lower))
                 localAxis(2L, x[, j], x[, i], ...)
             if (j == nc && (i%%2L || !has.upper || !has.lower))
                 localAxis(4L, x[, j], x[, i], ...)
             mfg <- par("mfg")
             if (i == j) {
                 if (has.diag)
                   localDiagPanel(as.vector(x[, i]), ...)
                 if (doText) {
                   par(usr = c(0, 1, 0, 1))
                   if (is.null(cex.labels)) {
                     l.wid <- strwidth(labels, "user")
                     cex.labels <- max(0.8, min(2, 0.9/max(l.wid)))
                   }
                   xlp <- if (xl[i])
                     10^0.5
                   else 0.5
                   ylp <- if (yl[j])
                     10^label.pos
                   else label.pos
                   text.panel(xlp, ylp, labels[i], cex = cex.labels,
                     font = font.labels)
                 }
             }
             else if (i < j)
                 localLowerPanel(as.vector(x[, j]), as.vector(x[,
                   i]), ...)
             else localUpperPanel(as.vector(x[, j]), as.vector(x[,
                 i]), ...)
             if (any(par("mfg") != mfg))
                 stop("the 'panel' function made a new plot")
         }
         else par(new = FALSE)
     }
     if (!is.null(main)) {
         font.main <- if ("font.main" %in% nmdots)
             dots$font.main
         else par("font.main")
         cex.main <- if ("cex.main" %in% nmdots)
             dots$cex.main
         else par("cex.main")
         mtext(main, 3, line.main, outer = TRUE, at = 0.5, cex = cex.main,
             font = font.main)
     }
     invisible(NULL)
}



## Example:

mypairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:4)



Am 06.06.2018 um 23:55 schrieb Andrews, Chris:
> 
> After making scatterplot matrix, I determined I only needed the first 2 columns of the matrix so I added verInd=1:2 to my pairs() call.  However, it did not turn out as I expected.
> 
> Perhaps the attached pdf of the example code will make it through.  If not, my description is "the wrong scatterplot pairs are in the wrong places" for the last two pairs() calls.
> 
> Thanks,
> Chris
> 
> ################################################################
> 
> # fake data
> xmat <- matrix(1:28, ncol=4)
> lim <- range(xmat)
> 
> # what I expected
> pairs(xmat, xlim=lim, ylim=lim) # 4x4 matrix of scatterplots
> pairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:2) # 2x2 matrix of scatterplots: upper left
> 
> # here comes trouble
> pairs(xmat, xlim=lim, ylim=lim, horInd=1:2) # 2x4 matrix of scatterplots: but not the top 2 rows (or bottom 2 rows)
> pairs(xmat, xlim=lim, ylim=lim, verInd=1:2) # 4x2 matrix of scatterplots: but not the left 2 columns (or right 2 columns)
> 
> 
> ###############################################################
> 
>> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 7 x64 (build 7601) Service Pack 1
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.5.0 tools_3.5.0
> **********************************************************
> Electronic Mail is not secure, may not be read every day, and should not be used for urgent or sensitive issues
> 
> 
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  7 09:29:27 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 07 Jun 2018 00:29:27 -0700
Subject: [R] using myfunction in stat_function
In-Reply-To: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
References: <CAFpsATbww+QYA=hWaGTYykS5=p12nF3sk=D6CcogDtNtJ8zFGw@mail.gmail.com>
Message-ID: <96A42C1D-F2C3-44BC-9BD6-261685181CA5@dcn.davis.ca.us>

Your example is not reproducible.

Perhaps read [1]

[1] http://rstudio-pubs-static.s3.amazonaws.com/3365_9573f6d661b444499365fe1841ee65d3.html

On June 6, 2018 8:04:44 PM PDT, Veerappa Chetty <chettyvk at gmail.com> wrote:
>HI,
>
>I use solve(A,b) inside my function, myfun2; it works fine when I
>return
>one value or a list.
>
> I want use the return values in ggplot as below: ggplot(data.frame(
>x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
>I get a blank graph. Would greatly appreciate help! Thanks.

-- 
Sent from my phone. Please excuse my brevity.



From m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t  Thu Jun  7 10:09:55 2018
From: m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t (Massimo Bressan)
Date: Thu, 7 Jun 2018 10:09:55 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>

thanks for the help 

I'm posting here the complete solution 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t$A <- factor(t$A) 
l<-sapply(levels(t$A), function(x) which(t$A==x)) 
r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", "))) 
r<-cbind(unique_A=row.names(r),r) 
row.names(r)<-NULL 
r 

best 



Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
A: "r-help" <R-help at r-project.org> 
Inviato: Mercoled?, 6 giugno 2018 10:13:10 
Oggetto: aggregate and list elements of variables in data.frame 

#given the following reproducible and simplified example 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

#I need to get the following result 

r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
r 

# i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
#any help for that? 

#so far I've just managed to "aggregate" and "count", like: 

library(sqldf) 
sqldf('select count(*) as count_id, A as unique_A from t group by A') 

library(dplyr) 
t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 

# thank you 


-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Thu Jun  7 10:41:23 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Thu, 7 Jun 2018 11:41:23 +0300
Subject: [R] ROC within SEM
In-Reply-To: <B29381BB-526A-46CF-9589-DC2DC4B204B0@comcast.net>
References: <95F30A9C080A02408E96F59F4260C3F7022CA61EBA@EX-CTRC-MBX3.win.uthscsa.edu>
 <B29381BB-526A-46CF-9589-DC2DC4B204B0@comcast.net>
Message-ID: <CAGgJW75AyExdR0v2+kJJXBrORvyyFE7NBPo6uS7QGdvoTwTudw@mail.gmail.com>

Hi Ray,
Have you done any search at all? I did a search on "R package ROC latent
variable" and got several hits.
In particular the package randomLCA seems relevant

https://cran.r-project.org/web/packages/randomLCA/vignettes/randomLCA-package.pdf

I glanced at the documentation which mentions 2 other R packages that also
seem to address your needs - poLCA and BayesLCA.

HTH,
Eric


On Wed, Jun 6, 2018 at 11:48 PM, David Winsemius <dwinsemius at comcast.net>
wrote:

>
> > On Jun 6, 2018, at 10:37 AM, Palmer, Raymond F <palmerr at uthscsa.edu>
> wrote:
> >
> > Dear R group.
> > Does anyone have an idea how to utilize a latent variable in an ROC
> (AUC) analysis? I want to create a latent variable, then use that latent
> construct as a continuous variable in an ROC.
> > I understand both SEM and ROC analysis can be done in R, but how to use
> the latent variable in the ROC is the issue.
> > Thanks for any insights.
> > Best, Ray
> >
> > Ray Palmer, Ph.D.
> > Professor
> > Department of Family and Community Medicine
> > University of Texas Health Science Center San Antonio
> > palmerr at uthscsa.edu<mailto:palmerr at uthscsa.edu>
> > 210-827-7681
> >
> >
> >       [[alternative HTML version deleted]]
>
> There are two sections from the Posting Guide that may be relevant:
>
> ---begin--
> Questions about statistics: The R mailing lists are primarily intended for
> questions and discussion about the R software. However, questions about
> statistical methodology are sometimes posted. If the question is well-asked
> and of interest to someone on the list, it may elicit an informative
> up-to-date answer. See also the Usenet groups sci.stat.consult (applied
> statistics and consulting) and sci.stat.math (mathematical stat and
> probability).
> ---end-----
>
> Frankly I would not considered this question to be "well-asked" but anyone
> is free to dispute this or to take on the task of asking clarifying
> questions.
>
> A modern update might add to the Posting Guide in these more web-centric
> times, the CrossValidated.com site. https://stats.stackexchange.
> com/search?q=latent+variable+roc
>
> (Those newsgroups are basically defunct.)
>
> >
> ---begin--
>         ? No HTML posting (harder to detect spam) (note that this is the
> default in some mail clients - you may have to turn it off). Note that
> chances have become relatively high for ?HTMLified? e-mails to be
> completely intercepted (without notice to the sender).
> ---end-
>
> One of the effects of redistribution by a mail-server is the removal of
> the identity of your mail-client, so advice about that concern can only be
> "RTFM".
>
>
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From E@Vettor@zz| @end|ng |rom uke@de  Thu Jun  7 11:46:43 2018
From: E@Vettor@zz| @end|ng |rom uke@de (Eik Vettorazzi)
Date: Thu, 7 Jun 2018 11:46:43 +0200
Subject: [R] Plot in real unit (1:1)
In-Reply-To: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
References: <145846eef400f1de031e4c020702276d253bf22b.camel@gmail.com>
Message-ID: <c30500f2-2f5e-902c-05e7-57e9b4261247@uke.de>

How about this:

in2mm<-25.4 # scale factor to convert inches to mm

pdf("test.pdf",width=8.3,height=11.7)
pin<-par("pin")
plot(c(0,pin[1]*in2mm),c(0,pin[2]*in2mm), type="n", xaxs="i", yaxs="i")
lines(c(10,10),c(0,10))
text(11,5,"1 cm", adj=0)

lines(c(0,40),c(20,20))
text(20,24,"4 cm")

polygon(c(50,50,70,70),c(50,70,70,50))
text(60,60,"2x2 cm")
dev.off()

cheers

Am 06.06.2018 um 16:00 schrieb Christian Brandst?tter:
> Dear List, 
> 
> Is it possible to plot in R in "real" units? I would like to draw a
> plot on A4 paper, where 1 plot unit would be a mm in reality. Is
> something like that possible? I would also like to be able to scale the
> plot in x and y direction. 
> Background: For a project I would have to draw around 65 fast sketches
> of elevation courves. 
> 
> Copied from here, due to no answer: https://stackoverflow.com/questions
> /50606797/plot-in-real-units-mm
> 
> Thank you!
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistrasse 52
building W 34
20246 Hamburg

Phone: +49 (0) 40 7410 - 58243
Fax:   +49 (0) 40 7410 - 57790
Web: www.uke.de/imbe
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jun  7 12:00:57 2018
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 12:00:57 +0200
Subject: [R] Histogram of character elements
Message-ID: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>

Dear all,
I have a dataframe with a column representing the names of the
elements (a, b, etc) and one with their frequencies.
How can I plot the frequencies so that each element has an associated
frequency value?
I have been thinking of a histogram, but I have found it difficult to
implement. I have tried the following:

group <- c("a", "b", "c", "d", "e")
freq <-c(1, 2, 2, 5, 3)
df <- data.frame(group, freq, stringsAsFactors = FALSE)
hist(df$freq)
library(lattice)
histogram( ~ df$group)
histogram( ~ as.factor(df$group))
histogram(df$freq ~ as.factor(df$group))

hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
times, the values 3 and 5 appear once and 4 never. This is not what I
wanted; I want instead a graph telling me that a appears once, b twice
etc.

histogram( ~ df$group) gives the error:
Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
include.lowest = include.lowest,  :
  negative length vectors are not allowed

histogram( ~ as.factor(df$group)) and histogram(df$freq ~
as.factor(df$group)) report all groups on the x axis (that is good)
but all at 20% level.

What am I missing?
Thank you.

-- 
Best regards,
Luigi



From btupper @end|ng |rom b|ge|ow@org  Thu Jun  7 12:47:59 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 7 Jun 2018 06:47:59 -0400
Subject: [R] Histogram of character elements
In-Reply-To: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
Message-ID: <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>

Hi,

Is this what you are after? 

group <- c("a", "b", "c", "d", "e")
freq <-c(1, 2, 2, 5, 3)
x = rep(group, freq)
barplot(table(x))

Cheers,
Ben



> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
> 
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
> 
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
> 
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
>  negative length vectors are not allowed
> 
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
> 
> What am I missing?
> Thank you.
> 
> -- 
> Best regards,
> Luigi
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jun  7 13:00:12 2018
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 13:00:12 +0200
Subject: [R] Histogram of character elements
In-Reply-To: <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
Message-ID: <CAMk+s2RLAS_56YOSmJ5sgFL9GFSSZoDo0wXpvyDLJ9ad+g11SQ@mail.gmail.com>

exactly! Thank you!
but it is possible to do it with lattice? I might have an extra level
of information, for instance super-group, and in that case, I could
plot all the supergroup easily together.
On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> Hi,
>
> Is this what you are after?
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> x = rep(group, freq)
> barplot(table(x))
>
> Cheers,
> Ben
>
>
>
> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
>
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
>
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
>  negative length vectors are not allowed
>
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
>
> What am I missing?
> Thank you.
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>


-- 
Best regards,
Luigi



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jun  7 13:02:46 2018
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 13:02:46 +0200
Subject: [R] Histogram of character elements
In-Reply-To: <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
Message-ID: <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>

also, with this approach, I need to re-arrange the data. Is it
possible to work directly on a dataframe?
On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> Hi,
>
> Is this what you are after?
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> x = rep(group, freq)
> barplot(table(x))
>
> Cheers,
> Ben
>
>
>
> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
>
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
>
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
>  negative length vectors are not allowed
>
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
>
> What am I missing?
> Thank you.
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>


-- 
Best regards,
Luigi



From btupper @end|ng |rom b|ge|ow@org  Thu Jun  7 13:43:09 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 7 Jun 2018 07:43:09 -0400
Subject: [R] Histogram of character elements
In-Reply-To: <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
 <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>
Message-ID: <59084912-ADF6-447A-AD55-8026A5F1086C@bigelow.org>

Hi again,

I'm sort of pre-coffee still, but does this do it?  The data frame only has one variable, a factor where the order of the levels is specified.

library(lattice)
group   <- c("a", "b", "c", "d", "e")
freq    <- c(1, 2, 2, 5, 3)
x       <- rep(group, freq)
df      <- data.frame(group = factor(x, levels = c("d", "a", "b", "c", "e")) )
histogram(~ group, data = df)

As far as super-grouping the answer is likely yes, but without details and an example (and coffee) I'm at a loss.   I suggest getting a your hands on a copy of https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008 <https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008> It's really worth it if you plan to spend time with lattice.

Cheers,
Ben 


> On Jun 7, 2018, at 7:02 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
> 
> also, with this approach, I need to re-arrange the data. Is it
> possible to work directly on a dataframe?
> On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>> 
>> Hi,
>> 
>> Is this what you are after?
>> 
>> group <- c("a", "b", "c", "d", "e")
>> freq <-c(1, 2, 2, 5, 3)
>> x = rep(group, freq)
>> barplot(table(x))
>> 
>> Cheers,
>> Ben
>> 
>> 
>> 
>> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>> 
>> Dear all,
>> I have a dataframe with a column representing the names of the
>> elements (a, b, etc) and one with their frequencies.
>> How can I plot the frequencies so that each element has an associated
>> frequency value?
>> I have been thinking of a histogram, but I have found it difficult to
>> implement. I have tried the following:
>> 
>> group <- c("a", "b", "c", "d", "e")
>> freq <-c(1, 2, 2, 5, 3)
>> df <- data.frame(group, freq, stringsAsFactors = FALSE)
>> hist(df$freq)
>> library(lattice)
>> histogram( ~ df$group)
>> histogram( ~ as.factor(df$group))
>> histogram(df$freq ~ as.factor(df$group))
>> 
>> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
>> times, the values 3 and 5 appear once and 4 never. This is not what I
>> wanted; I want instead a graph telling me that a appears once, b twice
>> etc.
>> 
>> histogram( ~ df$group) gives the error:
>> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
>> include.lowest = include.lowest,  :
>> negative length vectors are not allowed
>> 
>> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
>> as.factor(df$group)) report all groups on the x axis (that is good)
>> but all at 20% level.
>> 
>> What am I missing?
>> Thank you.
>> 
>> --
>> Best regards,
>> Luigi
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>> 
>> Ben Tupper
>> Bigelow Laboratory for Ocean Sciences
>> 60 Bigelow Drive, P.O. Box 380
>> East Boothbay, Maine 04544
>> http://www.bigelow.org
>> 
>> Ecological Forecasting: https://eco.bigelow.org/
>> 
>> 
>> 
>> 
>> 
> 
> 
> -- 
> Best regards,
> Luigi
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From m@rong|u@|u|g| @end|ng |rom gm@||@com  Thu Jun  7 13:49:11 2018
From: m@rong|u@|u|g| @end|ng |rom gm@||@com (Luigi Marongiu)
Date: Thu, 7 Jun 2018 13:49:11 +0200
Subject: [R] Histogram of character elements
In-Reply-To: <59084912-ADF6-447A-AD55-8026A5F1086C@bigelow.org>
References: <CAMk+s2T+DQpzzuUDfRW4Rbnn_usTYJ-qhexzNQ041gg2nxPMhQ@mail.gmail.com>
 <BFF0D8B3-0205-4819-B835-878D7D63A6CB@bigelow.org>
 <CAMk+s2QG3CNcENB1kRiLxFN7TTFxEHG1jqrL6Vk2=LXeaMy0RA@mail.gmail.com>
 <59084912-ADF6-447A-AD55-8026A5F1086C@bigelow.org>
Message-ID: <CAMk+s2RvnWd6vZ0m=ckpKGi7zUSsCxUDf1jrDGXGs_2hdPsRVw@mail.gmail.com>

Thank you Ben, this also works! I have a copy of the Sarkar but,
usually, I don't work with histograms. I'll brush it up, then. Best
regards, Luigi

On Thu, Jun 7, 2018 at 1:43 PM Ben Tupper <btupper at bigelow.org> wrote:
>
> Hi again,
>
> I'm sort of pre-coffee still, but does this do it?  The data frame only has one variable, a factor where the order of the levels is specified.
>
> library(lattice)
> group   <- c("a", "b", "c", "d", "e")
> freq    <- c(1, 2, 2, 5, 3)
> x       <- rep(group, freq)
> df      <- data.frame(group = factor(x, levels = c("d", "a", "b", "c", "e")) )
> histogram(~ group, data = df)
>
> As far as super-grouping the answer is likely yes, but without details and an example (and coffee) I'm at a loss.   I suggest getting a your hands on a copy of https://www.r-project.org/doc/bib/R-books_bib.html#R:Sarkar:2008 It's really worth it if you plan to spend time with lattice.
>
> Cheers,
> Ben
>
>
> On Jun 7, 2018, at 7:02 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> also, with this approach, I need to re-arrange the data. Is it
> possible to work directly on a dataframe?
> On Thu, Jun 7, 2018 at 12:48 PM Ben Tupper <btupper at bigelow.org> wrote:
>
>
> Hi,
>
> Is this what you are after?
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> x = rep(group, freq)
> barplot(table(x))
>
> Cheers,
> Ben
>
>
>
> On Jun 7, 2018, at 6:00 AM, Luigi Marongiu <marongiu.luigi at gmail.com> wrote:
>
> Dear all,
> I have a dataframe with a column representing the names of the
> elements (a, b, etc) and one with their frequencies.
> How can I plot the frequencies so that each element has an associated
> frequency value?
> I have been thinking of a histogram, but I have found it difficult to
> implement. I have tried the following:
>
> group <- c("a", "b", "c", "d", "e")
> freq <-c(1, 2, 2, 5, 3)
> df <- data.frame(group, freq, stringsAsFactors = FALSE)
> hist(df$freq)
> library(lattice)
> histogram( ~ df$group)
> histogram( ~ as.factor(df$group))
> histogram(df$freq ~ as.factor(df$group))
>
> hist(df$freq) returns a histogram in which the values 1 and 2 appear 3
> times, the values 3 and 5 appear once and 4 never. This is not what I
> wanted; I want instead a graph telling me that a appears once, b twice
> etc.
>
> histogram( ~ df$group) gives the error:
> Error in hist.default(as.numeric(x), breaks = breaks, plot = FALSE,
> include.lowest = include.lowest,  :
> negative length vectors are not allowed
>
> histogram( ~ as.factor(df$group)) and histogram(df$freq ~
> as.factor(df$group)) report all groups on the x axis (that is good)
> but all at 20% level.
>
> What am I missing?
> Thank you.
>
> --
> Best regards,
> Luigi
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>
>
>
> --
> Best regards,
> Luigi
>
>
> Ben Tupper
> Bigelow Laboratory for Ocean Sciences
> 60 Bigelow Drive, P.O. Box 380
> East Boothbay, Maine 04544
> http://www.bigelow.org
>
> Ecological Forecasting: https://eco.bigelow.org/
>
>
>
>
>


-- 
Best regards,
Luigi



From m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t  Thu Jun  7 14:21:52 2018
From: m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t (Massimo Bressan)
Date: Thu, 7 Jun 2018 14:21:52 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>

sorry, but by further looking at the example I just realised that the posted solution it's not completely what I need because in fact I do not need to get back the 'indices' but instead the corrisponding values of column A 

#please consider this new example 

t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

# I need to get this result 
r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('18,20,27,4','91,54,15','68','26,97')) 
r 

# any help for this, please? 





Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
A: "r-help" <R-help at r-project.org> 
Inviato: Gioved?, 7 giugno 2018 10:09:55 
Oggetto: Re: aggregate and list elements of variables in data.frame 

thanks for the help 

I'm posting here the complete solution 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t$A <- factor(t$A) 
l<-sapply(levels(t$A), function(x) which(t$A==x)) 
r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", "))) 
r<-cbind(unique_A=row.names(r),r) 
row.names(r)<-NULL 
r 

best 



Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
A: "r-help" <R-help at r-project.org> 
Inviato: Mercoled?, 6 giugno 2018 10:13:10 
Oggetto: aggregate and list elements of variables in data.frame 

#given the following reproducible and simplified example 

t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
t 

#I need to get the following result 

r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
r 

# i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
#any help for that? 

#so far I've just managed to "aggregate" and "count", like: 

library(sqldf) 
sqldf('select count(*) as count_id, A as unique_A from t group by A') 

library(dplyr) 
t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 

# thank you 


-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 


-- 

------------------------------------------------------------ 
Massimo Bressan 

ARPAV 
Agenzia Regionale per la Prevenzione e 
Protezione Ambientale del Veneto 

Dipartimento Provinciale di Treviso 
Via Santa Barbara, 5/a 
31100 Treviso, Italy 

tel: +39 0422 558545 
fax: +39 0422 558516 
e-mail: massimo.bressan at arpa.veneto.it 
------------------------------------------------------------ 

	[[alternative HTML version deleted]]



From c@|@ndr@ @end|ng |rom rgzm@de  Thu Jun  7 14:28:07 2018
From: c@|@ndr@ @end|ng |rom rgzm@de (Ivan Calandra)
Date: Thu, 7 Jun 2018 14:28:07 +0200
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <c8d0c50b-bc3c-662f-58c3-2f0cdc2db50d@rgzm.de>

Using which() to subset t$id should do the trick:

sapply(levels(t$A), function(x) t$id[which(t$A==x)])

Ivan

--
Dr. Ivan Calandra
TraCEr, laboratory for Traceology and Controlled Experiments
MONREPOS Archaeological Research Centre and
Museum for Human Behavioural Evolution
Schloss Monrepos
56567 Neuwied, Germany
+49 (0) 2631 9772-243
https://www.researchgate.net/profile/Ivan_Calandra

On 07/06/2018 14:21, Massimo Bressan wrote:
> sorry, but by further looking at the example I just realised that the posted solution it's not completely what I need because in fact I do not need to get back the 'indices' but instead the corrisponding values of column A
>
> #please consider this new example
>
> t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789))
> t
>
> # I need to get this result
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('18,20,27,4','91,54,15','68','26,97'))
> r
>
> # any help for this, please?
>
>
>
>
>
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> A: "r-help" <R-help at r-project.org>
> Inviato: Gioved?, 7 giugno 2018 10:09:55
> Oggetto: Re: aggregate and list elements of variables in data.frame
>
> thanks for the help
>
> I'm posting here the complete solution
>
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))
> t$A <- factor(t$A)
> l<-sapply(levels(t$A), function(x) which(t$A==x))
> r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", ")))
> r<-cbind(unique_A=row.names(r),r)
> row.names(r)<-NULL
> r
>
> best
>
>
>
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it>
> A: "r-help" <R-help at r-project.org>
> Inviato: Mercoled?, 6 giugno 2018 10:13:10
> Oggetto: aggregate and list elements of variables in data.frame
>
> #given the following reproducible and simplified example
>
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))
> t
>
> #I need to get the following result
>
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10'))
> r
>
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A"
> #any help for that?
>
> #so far I've just managed to "aggregate" and "count", like:
>
> library(sqldf)
> sqldf('select count(*) as count_id, A as unique_A from t group by A')
>
> library(dplyr)
> t%>%group_by(unique_A=A) %>% summarise(count_id = n())
>
> # thank you
>
>



From btupper @end|ng |rom b|ge|ow@org  Thu Jun  7 14:47:55 2018
From: btupper @end|ng |rom b|ge|ow@org (Ben Tupper)
Date: Thu, 7 Jun 2018 08:47:55 -0400
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>

Hi,

Does this do what you want?  I had to change the id values to something more obvious.  It uses tibbles which allow each variable to be a list.

library(tibble)
library(dplyr)
x       <- tibble(id=LETTERS[1:10],
                A=c(123,345,123,678,345,123,789,345,123,789))
uA      <- unique(x$A)
idx     <- lapply(uA, function(v) which(x$A %in% v))
vals    <- lapply(idx, function(index) x$id[index])

r <- tibble(unique_A = uA, list_idx = idx, list_vals = vals)


> r
# A tibble: 4 x 3
  unique_A list_idx  list_vals
     <dbl> <list>    <list>   
1     123. <int [4]> <chr [4]>
2     345. <int [3]> <chr [3]>
3     678. <int [1]> <chr [1]>
4     789. <int [2]> <chr [2]>
> r$list_idx[1]
[[1]]
[1] 1 3 6 9

> r$list_vals[1]
[[1]]
[1] "A" "C" "F" "I"


Cheers,
ben



> On Jun 7, 2018, at 8:21 AM, Massimo Bressan <massimo.bressan at arpa.veneto.it> wrote:
> 
> sorry, but by further looking at the example I just realised that the posted solution it's not completely what I need because in fact I do not need to get back the 'indices' but instead the corrisponding values of column A 
> 
> #please consider this new example 
> 
> t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789)) 
> t 
> 
> # I need to get this result 
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('18,20,27,4','91,54,15','68','26,97')) 
> r 
> 
> # any help for this, please? 
> 
> 
> 
> 
> 
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
> A: "r-help" <R-help at r-project.org> 
> Inviato: Gioved?, 7 giugno 2018 10:09:55 
> Oggetto: Re: aggregate and list elements of variables in data.frame 
> 
> thanks for the help 
> 
> I'm posting here the complete solution 
> 
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
> t$A <- factor(t$A) 
> l<-sapply(levels(t$A), function(x) which(t$A==x)) 
> r<-data.frame(list_id=unlist(lapply(l, paste, collapse = ", "))) 
> r<-cbind(unique_A=row.names(r),r) 
> row.names(r)<-NULL 
> r 
> 
> best 
> 
> 
> 
> Da: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
> A: "r-help" <R-help at r-project.org> 
> Inviato: Mercoled?, 6 giugno 2018 10:13:10 
> Oggetto: aggregate and list elements of variables in data.frame 
> 
> #given the following reproducible and simplified example 
> 
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
> t 
> 
> #I need to get the following result 
> 
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
> r 
> 
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
> #any help for that? 
> 
> #so far I've just managed to "aggregate" and "count", like: 
> 
> library(sqldf) 
> sqldf('select count(*) as count_id, A as unique_A from t group by A') 
> 
> library(dplyr) 
> t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 
> 
> # thank you 
> 
> 
> -- 
> 
> ------------------------------------------------------------ 
> Massimo Bressan 
> 
> ARPAV 
> Agenzia Regionale per la Prevenzione e 
> Protezione Ambientale del Veneto 
> 
> Dipartimento Provinciale di Treviso 
> Via Santa Barbara, 5/a 
> 31100 Treviso, Italy 
> 
> tel: +39 0422 558545 
> fax: +39 0422 558516 
> e-mail: massimo.bressan at arpa.veneto.it 
> ------------------------------------------------------------ 
> 
> 
> -- 
> 
> ------------------------------------------------------------ 
> Massimo Bressan 
> 
> ARPAV 
> Agenzia Regionale per la Prevenzione e 
> Protezione Ambientale del Veneto 
> 
> Dipartimento Provinciale di Treviso 
> Via Santa Barbara, 5/a 
> 31100 Treviso, Italy 
> 
> tel: +39 0422 558545 
> fax: +39 0422 558516 
> e-mail: massimo.bressan at arpa.veneto.it 
> ------------------------------------------------------------ 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Ben Tupper
Bigelow Laboratory for Ocean Sciences
60 Bigelow Drive, P.O. Box 380
East Boothbay, Maine 04544
http://www.bigelow.org

Ecological Forecasting: https://eco.bigelow.org/






	[[alternative HTML version deleted]]



From m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t  Thu Jun  7 15:27:56 2018
From: m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t (Massimo Bressan)
Date: Thu, 7 Jun 2018 15:27:56 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
 <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
Message-ID: <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>

thank you for the help 

this is my solution based on your valuable hint but without the need to pass through the use of a 'tibble' 

x<-data.frame(id=LETTERS[1:10], A=c(123,345,123,678,345,123,789,345,123,789)) 
uA<-unique(x$A) 
idx<-lapply(uA, function(v) which(x$A %in% v)) 
vals<- lapply(idx, function(index) x$id[index]) 
data.frame(unique_A = uA, list_vals=unlist(lapply(vals, paste, collapse = ", "))) 

best 



Da: "Ben Tupper" <btupper at bigelow.org> 
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
Cc: "r-help" <R-help at r-project.org> 
Inviato: Gioved?, 7 giugno 2018 14:47:55 
Oggetto: Re: [R] aggregate and list elements of variables in data.frame 

Hi, 

Does this do what you want? I had to change the id values to something more obvious. It uses tibbles which allow each variable to be a list. 

library(tibble) 
library(dplyr) 
x <- tibble(id=LETTERS[1:10], 
A=c(123,345,123,678,345,123,789,345,123,789)) 
uA <- unique(x$A) 
idx <- lapply(uA, function(v) which(x$A %in% v)) 
vals <- lapply(idx, function(index) x$id[index]) 

r <- tibble(unique_A = uA, list_idx = idx, list_vals = vals) 


> r 
# A tibble: 4 x 3 
unique_A list_idx list_vals 
<dbl> <list> <list> 
1 123. <int [4]> <chr [4]> 
2 345. <int [3]> <chr [3]> 
3 678. <int [1]> <chr [1]> 
4 789. <int [2]> <chr [2]> 
> r$list_idx[1] 
[[1]] 
[1] 1 3 6 9 

> r$list_vals[1] 
[[1]] 
[1] "A" "C" "F" "I" 


Cheers, 
ben 


	[[alternative HTML version deleted]]



From m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t  Thu Jun  7 15:48:38 2018
From: m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t (Massimo Bressan)
Date: Thu, 7 Jun 2018 15:48:38 +0200 (CEST)
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
 <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
 <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <582342719.9778477.1528379318105.JavaMail.zimbra@arpa.veneto.it>

#ok, finally this is my final "best and more compact" solution of the problem by merging different contributions (thanks to all indeed) 

t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789)) 
l<-sapply(unique(t$A), function(x) t$id[which(t$A==x)]) 
r<-data.frame(unique_A= unique(t$A), list_id=unlist(lapply(l, paste, collapse = ", "))) 
r 


	[[alternative HTML version deleted]]



From chettyvk @end|ng |rom gm@||@com  Thu Jun  7 16:18:18 2018
From: chettyvk @end|ng |rom gm@||@com (Veerappa Chetty)
Date: Thu, 7 Jun 2018 10:18:18 -0400
Subject: [R] stat_function with data frames in ggplot2
Message-ID: <CAFpsATaZmLYFBEWPX3k+WTBgLTOeanijOOR0BpmtL-sQ+88ckA@mail.gmail.com>

I use solve(A,b) inside my function, myfun2; it works fine when I return
one value or a list.
I want use the return values in ggplot as below: ggplot(data.frame(
x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
I get a blank graph. Would greatly appreciate help! Thanks.

Here are my codes:
p.lm<-0.05 ##to initialze only
p.lh<-0.1
p.ll<-1-p.lm-p.lh
p.ml<-0.3
p.mh<-0.1
p.mm<-1-p.ml-p.mh
p.hl<-0.05
p.hm<-0.5
p.hh<-1-p.hl-p.hm
myfun.5<-function(xvar){
y<-numeric(2)
p.lm<-xvar
A<-matrix(c(p.lm+p.lh+p.hl,p.hl-p.ml,p.hm-p.lm,p.ml+p.mh+p.hm),nrow=2,byrow
= TRUE)
b<-c(p.hl,p.hm)
y<-solve(A,b)
z<-list(y[1],y[2],1-y[1]-y[2])
z[1]
}

g.2<-ggplot(data.frame(
x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.5,geom="line")
g.2

-- 
Professor of Family Medicine
Boston University
Tel: 617-414-6221, Fax:617-414-3345
emails: chettyvk at gmail.com,vchetty at bu.edu

	[[alternative HTML version deleted]]



From dm|tr|@pop@venko @end|ng |rom gm@||@com  Thu Jun  7 17:21:58 2018
From: dm|tr|@pop@venko @end|ng |rom gm@||@com (Dmitri Popavenko)
Date: Thu, 7 Jun 2018 18:21:58 +0300
Subject: [R] open help files from Terminal
Message-ID: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>

Dear R users,

I am sometimes using R from a Terminal (either from Linux but most often on
MacOS).
When looking at a help file using the question mark (e.g. ?sd) the help
file opens in the Terminal itself.

If possible, I would like to open the HTML version of the help file in a
webpage, but I am completely unaware of how this might be done.

If anyone has a suggestion, I would be very grateful.

Best,
Dmitri

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jun  7 17:23:50 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 7 Jun 2018 08:23:50 -0700
Subject: [R] stat_function with data frames in ggplot2
In-Reply-To: <CAFpsATaZmLYFBEWPX3k+WTBgLTOeanijOOR0BpmtL-sQ+88ckA@mail.gmail.com>
References: <CAFpsATaZmLYFBEWPX3k+WTBgLTOeanijOOR0BpmtL-sQ+88ckA@mail.gmail.com>
Message-ID: <077AAEEF-A087-4992-8F64-20EB4B1F5B93@comcast.net>


> On Jun 7, 2018, at 7:18 AM, Veerappa Chetty <chettyvk at gmail.com> wrote:
> 
> I use solve(A,b) inside my function, myfun2; it works fine when I return
> one value or a list.
> I want use the return values in ggplot as below: ggplot(data.frame(
> x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.2,geom="line")
> I get a blank graph. Would greatly appreciate help! Thanks.
> 
> Here are my codes:
> p.lm<-0.05 ##to initialze only
> p.lh<-0.1
> p.ll<-1-p.lm-p.lh
> p.ml<-0.3
> p.mh<-0.1
> p.mm<-1-p.ml-p.mh
> p.hl<-0.05
> p.hm<-0.5
> p.hh<-1-p.hl-p.hm
> myfun.5<-function(xvar){
> y<-numeric(2)
> p.lm<-xvar
> A<-matrix(c(p.lm+p.lh+p.hl,p.hl-p.ml,p.hm-p.lm,p.ml+p.mh+p.hm),nrow=2,byrow
> = TRUE)
> b<-c(p.hl,p.hm)
> y<-solve(A,b)
> z<-list(y[1],y[2],1-y[1]-y[2])
> z[1]
> }
> 
> g.2<-ggplot(data.frame(
> x=c(0.1,0.8)),aes(x=x))+stat_function(fun=myfun.5,geom="line")
> g.2

You are a) failing to pay attention to the warning message:

> g.2
Warning message:
Computation failed in `stat_function()`:
'a' (2 x 102) must be square 

> 

.... and b) as a consequence failing to debug your function. Add a print(A) line immediately after your construction of A:

 myfun.5(1:10)
      [,1]  [,2]  [,3]  [,4]  [,5]  [,6]  [,7]  [,8]  [,9] [,10] [,11]
[1,]  1.15  2.15  3.15  4.15  5.15  6.15  7.15  8.15  9.15 10.15 -0.25
[2,] -0.50 -1.50 -2.50 -3.50 -4.50 -5.50 -6.50 -7.50 -8.50 -9.50  0.90
Error in solve.default(A, b) : 'a' (2 x 11) must be square

The fun argument in stat_fun is supposed to accept a vector with x values and return y values for "predictions". You have not indicated what plot was expected, You've given no indication what the various constants are supposed to represent, and you are only giving x-values to aes.ggplot, so I'm unable to infer what is intended.



> -- 
> Professor of Family Medicine
> Boston University
> Tel: 617-414-6221, Fax:617-414-3345
> emails: chettyvk at gmail.com,vchetty at bu.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jun  7 17:29:39 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Thu, 7 Jun 2018 08:29:39 -0700
Subject: [R] open help files from Terminal
In-Reply-To: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
Message-ID: <B9245AF6-414D-4EBF-9FD3-8FCA718B429A@comcast.net>


> On Jun 7, 2018, at 8:21 AM, Dmitri Popavenko <dmitri.popavenko at gmail.com> wrote:
> 
> Dear R users,
> 
> I am sometimes using R from a Terminal (either from Linux but most often on
> MacOS).
> When looking at a help file using the question mark (e.g. ?sd) the help
> file opens in the Terminal itself.
> 
> If possible, I would like to open the HTML version of the help file in a
> webpage, but I am completely unaware of how this might be done.

First I looked at:

?help

Seeing the help-type parameter included "html" as a potential value, I therefore tried this from a Terminal-launched session on a Mac (although normally I work in the R.app GUI):

help(sd, help_type="html")

I get the expected sd-help page displayed in my open Chrome browser.


> 
> If anyone has a suggestion, I would be very grateful.
> 
> Best,
> Dmitri
> 
> 	[[alternative HTML version deleted]]

R is a plain text mailing list.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Jun  7 17:39:48 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 7 Jun 2018 11:39:48 -0400
Subject: [R] open help files from Terminal
In-Reply-To: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
Message-ID: <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>

Here are two options:

> # for one occurrence
> help("help", help_type="html")
starting httpd help server ... done
>
> # to set the default for your R session
> options(help_type = "html")
> ?help

If you read the help file for help(), you will see all the possibilities.

Sarah

On Thu, Jun 7, 2018 at 11:21 AM, Dmitri Popavenko
<dmitri.popavenko at gmail.com> wrote:
> Dear R users,
>
> I am sometimes using R from a Terminal (either from Linux but most often on
> MacOS).
> When looking at a help file using the question mark (e.g. ?sd) the help
> file opens in the Terminal itself.
>
> If possible, I would like to open the HTML version of the help file in a
> webpage, but I am completely unaware of how this might be done.
>
> If anyone has a suggestion, I would be very grateful.
>
> Best,
> Dmitri

-- 
Sarah Goslee
http://www.functionaldiversity.org



From dm|tr|@pop@venko @end|ng |rom gm@||@com  Thu Jun  7 17:47:36 2018
From: dm|tr|@pop@venko @end|ng |rom gm@||@com (Dmitri Popavenko)
Date: Thu, 7 Jun 2018 18:47:36 +0300
Subject: [R] open help files from Terminal
In-Reply-To: <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
 <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>
Message-ID: <CAJL_pohsSWXQLite=xa4huknBy8bD-XzmR2rRzc486ntdN5wbQ@mail.gmail.com>

Dear Sarah, dear David,

Thank you very much indeed, this is exactly what I needed.

Best,
Dmitri

On Thu, Jun 7, 2018 at 6:39 PM, Sarah Goslee <sarah.goslee at gmail.com> wrote:

> Here are two options:
>
> > # for one occurrence
> > help("help", help_type="html")
> starting httpd help server ... done
> >
> > # to set the default for your R session
> > options(help_type = "html")
> > ?help
>
> If you read the help file for help(), you will see all the possibilities.
>
> Sarah
>
> On Thu, Jun 7, 2018 at 11:21 AM, Dmitri Popavenko
> <dmitri.popavenko at gmail.com> wrote:
> > Dear R users,
> >
> > I am sometimes using R from a Terminal (either from Linux but most often
> on
> > MacOS).
> > When looking at a help file using the question mark (e.g. ?sd) the help
> > file opens in the Terminal itself.
> >
> > If possible, I would like to open the HTML version of the help file in a
> > webpage, but I am completely unaware of how this might be done.
> >
> > If anyone has a suggestion, I would be very grateful.
> >
> > Best,
> > Dmitri
>
> --
> Sarah Goslee
> http://www.functionaldiversity.org
>

	[[alternative HTML version deleted]]



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Thu Jun  7 18:35:48 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Thu, 7 Jun 2018 18:35:48 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
Message-ID: <23321.24292.243245.897326@stat.math.ethz.ch>

>>>>> Gerrit Eichner 
>>>>>     on Thu, 7 Jun 2018 09:03:46 +0200 writes:

    > Hi, Chris, had the same problem (and first thought it was
    > my fault), but there seems to be a typo in the code of
    > pairs.default. Below is a workaround.  Look for two
    > comments (starting with #####) in the code to see what I
    > have changed to make it work at least the way I'd expect
    > it in one of your examples.

    >   Hth -- Gerrit

> mypairs <- function (x, labels, panel = points, ...,
>      horInd = 1:nc, verInd = 1:nc,
>      lower.panel = panel, upper.panel = panel, diag.panel = NULL,
>      text.panel = textPanel, label.pos = 0.5 + has.diag/3, line.main = 3,
>      cex.labels = NULL, font.labels = 1, row1attop = TRUE, gap = 1,
>      log = "") {
>      if (doText <- missing(text.panel) || is.function(text.panel))
>          textPanel <- function(x = 0.5, y = 0.5, txt, cex, font) text(x,
>              y, txt, cex = cex, font = font)
>      localAxis <- function(side, x, y, xpd, bg, col = NULL, main,
>          oma, ...) {
>          xpd <- NA
>          if (side%%2L == 1L && xl[j])
>              xpd <- FALSE
>          if (side%%2L == 0L && yl[i])
>              xpd <- FALSE
>          if (side%%2L == 1L)
>              Axis(x, side = side, xpd = xpd, ...)
>          else Axis(y, side = side, xpd = xpd, ...)
>      }
>      localPlot <- function(..., main, oma, font.main, cex.main) plot(...)
>      localLowerPanel <- function(..., main, oma, font.main, cex.main) lower.panel(...)
>      localUpperPanel <- function(..., main, oma, font.main, cex.main) upper.panel(...)
>      localDiagPanel <- function(..., main, oma, font.main, cex.main) diag.panel(...)
>      dots <- list(...)
>      nmdots <- names(dots)
>      if (!is.matrix(x)) {
>          x <- as.data.frame(x)
>          for (i in seq_along(names(x))) {
>              if (is.factor(x[[i]]) || is.logical(x[[i]]))
>                  x[[i]] <- as.numeric(x[[i]])
>              if (!is.numeric(unclass(x[[i]])))
>                  stop("non-numeric argument to 'pairs'")
>          }
>      }
>      else if (!is.numeric(x))
>          stop("non-numeric argument to 'pairs'")
>      panel <- match.fun(panel)
>      if ((has.lower <- !is.null(lower.panel)) && !missing(lower.panel))
>          lower.panel <- match.fun(lower.panel)
>      if ((has.upper <- !is.null(upper.panel)) && !missing(upper.panel))
>          upper.panel <- match.fun(upper.panel)
>      if ((has.diag <- !is.null(diag.panel)) && !missing(diag.panel))
>          diag.panel <- match.fun(diag.panel)
>      if (row1attop) {
>          tmp <- lower.panel
>          lower.panel <- upper.panel
>          upper.panel <- tmp
>          tmp <- has.lower
>          has.lower <- has.upper
>          has.upper <- tmp
>      }
>      nc <- ncol(x)
>      if (nc < 2L)
>          stop("only one column in the argument to 'pairs'")
>      if (!all(horInd >= 1L && horInd <= nc))
>          stop("invalid argument 'horInd'")
>      if (!all(verInd >= 1L && verInd <= nc))
>          stop("invalid argument 'verInd'")
>      if (doText) {
>          if (missing(labels)) {
>              labels <- colnames(x)
>              if (is.null(labels))
>                  labels <- paste("var", 1L:nc)
>          }
>          else if (is.null(labels))
>              doText <- FALSE
>      }
>      oma <- if ("oma" %in% nmdots)
>          dots$oma
>      main <- if ("main" %in% nmdots)
>          dots$main
>      if (is.null(oma))
>          oma <- c(4, 4, if (!is.null(main)) 6 else 4, 4)
>      opar <- par(mfcol = c(length(horInd), length(verInd)),
> ##### Changed from mfrow to mfcol
>                  mar = rep.int(gap/2, 4), oma = oma)
>      on.exit(par(opar))
>      dev.hold()
>      on.exit(dev.flush(), add = TRUE)
>      xl <- yl <- logical(nc)
>      if (is.numeric(log))
>          xl[log] <- yl[log] <- TRUE
>      else {
>          xl[] <- grepl("x", log)
>          yl[] <- grepl("y", log)
>      }
>      for (j in if (row1attop) verInd else rev(verInd))
>       for (i in horInd) {
> ##### Exchanged i and j. (i used to be in
> ##### the outer and j in the inner loop!)
>          l <- paste0(ifelse(xl[j], "x", ""), ifelse(yl[i], "y", ""))
>          localPlot(x[, j], x[, i], xlab = "", ylab = "", axes = FALSE,
>              type = "n", ..., log = l)
>          if (i == j || (i < j && has.lower) || (i > j && has.upper)) {
>              box()
>              if (i == 1 && (!(j%%2L) || !has.upper || !has.lower))
>                  localAxis(1L + 2L * row1attop, x[, j], x[, i],
>                    ...)
>              if (i == nc && (j%%2L || !has.upper || !has.lower))
>                  localAxis(3L - 2L * row1attop, x[, j], x[, i],
>                    ...)
>              if (j == 1 && (!(i%%2L) || !has.upper || !has.lower))
>                  localAxis(2L, x[, j], x[, i], ...)
>              if (j == nc && (i%%2L || !has.upper || !has.lower))
>                  localAxis(4L, x[, j], x[, i], ...)
>              mfg <- par("mfg")
>              if (i == j) {
>                  if (has.diag)
>                    localDiagPanel(as.vector(x[, i]), ...)
>                  if (doText) {
>                    par(usr = c(0, 1, 0, 1))
>                    if (is.null(cex.labels)) {
>                      l.wid <- strwidth(labels, "user")
>                      cex.labels <- max(0.8, min(2, 0.9/max(l.wid)))
>                    }
>                    xlp <- if (xl[i])
>                      10^0.5
>                    else 0.5
>                    ylp <- if (yl[j])
>                      10^label.pos
>                    else label.pos
>                    text.panel(xlp, ylp, labels[i], cex = cex.labels,
>                      font = font.labels)
>                  }
>              }
>              else if (i < j)
>                  localLowerPanel(as.vector(x[, j]), as.vector(x[,
>                    i]), ...)
>              else localUpperPanel(as.vector(x[, j]), as.vector(x[,
>                  i]), ...)
>              if (any(par("mfg") != mfg))
>                  stop("the 'panel' function made a new plot")
>          }
>          else par(new = FALSE)
>      }
>      if (!is.null(main)) {
>          font.main <- if ("font.main" %in% nmdots)
>              dots$font.main
>          else par("font.main")
>          cex.main <- if ("cex.main" %in% nmdots)
>              dots$cex.main
>          else par("cex.main")
>          mtext(main, 3, line.main, outer = TRUE, at = 0.5, cex = cex.main,
>              font = font.main)
>      }
>      invisible(NULL)
> }
> 
> 
> 
> ## Example:
> 
> mypairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:4)

Thank you, Chris, for the report and
Gerrit for your proposed fix !!

It looks good to me,  but I will test some more (also with
'row1attop=FALSE')  before committing the bug fix.

Best regards,

Martin Maechler
ETH Zurich and R Core Team

> Am 06.06.2018 um 23:55 schrieb Andrews, Chris:
> > 
> > After making scatterplot matrix, I determined I only needed the first 2 columns of the matrix so I added verInd=1:2 to my pairs() call.  However, it did not turn out as I expected.
> > 
> > Perhaps the attached pdf of the example code will make it through.  If not, my description is "the wrong scatterplot pairs are in the wrong places" for the last two pairs() calls.
> > 
> > Thanks,
> > Chris
> > 
> > ################################################################
> > 
> > # fake data
> > xmat <- matrix(1:28, ncol=4)
> > lim <- range(xmat)
> > 
> > # what I expected
> > pairs(xmat, xlim=lim, ylim=lim) # 4x4 matrix of scatterplots
> > pairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:2) # 2x2 matrix of scatterplots: upper left
> > 
> > # here comes trouble
> > pairs(xmat, xlim=lim, ylim=lim, horInd=1:2) # 2x4 matrix of scatterplots: but not the top 2 rows (or bottom 2 rows)
> > pairs(xmat, xlim=lim, ylim=lim, verInd=1:2) # 4x2 matrix of scatterplots: but not the left 2 columns (or right 2 columns)
> > 
> > 
> > ###############################################################
> > 
> >> sessionInfo()
> > R version 3.5.0 (2018-04-23)
> > Platform: x86_64-w64-mingw32/x64 (64-bit)
> > Running under: Windows 7 x64 (build 7601) Service Pack 1
> > 
> > Matrix products: default
> > 
> > locale:
> > [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United States.1252    LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C                           LC_TIME=English_United States.1252
> > 
> > attached base packages:
> > [1] stats     graphics  grDevices utils     datasets  methods   base
> > 
> > loaded via a namespace (and not attached):
> > [1] compiler_3.5.0 tools_3.5.0
> > **********************************************************



From ru|y@ng||u94 @end|ng |rom gm@||@com  Thu Jun  7 17:12:27 2018
From: ru|y@ng||u94 @end|ng |rom gm@||@com (=?utf-8?B?5YiY55Ge6Ziz?=)
Date: Thu, 7 Jun 2018 10:12:27 -0500
Subject: [R] problems in converting numeric to character
Message-ID: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>

Hi,
I am having trouble converting numeric to characters in the format I desire. To be more specific, I have a number of numeric as follows:

x<-c(1.0,2.0,2.00,2.1)
I want to convert them to characters so that the out put would be c(?1.0?,?2.0?,?2.00?,?2.1?). 

However, I used as.character(x) and the output is:
"1"   "2"   "2"   ?2.1"

The decimals are removed if the numeric ends with ?.0?. Is there a way to circumvent this problem?

Thanks very much!

Sincerely,

Ruiyang Liu


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun  7 21:40:40 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 07 Jun 2018 12:40:40 -0700
Subject: [R] problems in converting numeric to character
In-Reply-To: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
References: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
Message-ID: <033F6E18-1EF7-4C92-9B98-79B931AC1E9C@dcn.davis.ca.us>

?formatC (digits, drop0trailing)
?sprintf (format %f)
?cat 
?options (digits)

You appear to be confusing source code formatting with output formatting. The internal representation of a numeric value has no notion of the number of decimals that were used to enter it into memory from source code. By the time you (or R) decide to re-convert it to a visual representation (characters), all trace of the original representation has been forgotten, so you have to be explicit about your output format, or R will make assumptions.

On June 7, 2018 8:12:27 AM PDT, "???" <ruiyangliu94 at gmail.com> wrote:
>Hi,
>I am having trouble converting numeric to characters in the format I
>desire. To be more specific, I have a number of numeric as follows:
>
>x<-c(1.0,2.0,2.00,2.1)
>I want to convert them to characters so that the out put would be
>c(?1.0?,?2.0?,?2.00?,?2.1?). 
>
>However, I used as.character(x) and the output is:
>"1"   "2"   "2"   ?2.1"
>
>The decimals are removed if the numeric ends with ?.0?. Is there a way
>to circumvent this problem?
>
>Thanks very much!
>
>Sincerely,
>
>Ruiyang Liu
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  8 02:26:43 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Thu, 7 Jun 2018 17:26:43 -0700
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <582342719.9778477.1528379318105.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
 <94563671.9657390.1528358995450.JavaMail.zimbra@arpa.veneto.it>
 <1550482729.9752009.1528374112046.JavaMail.zimbra@arpa.veneto.it>
 <18080F1A-2527-4E9C-A3D7-B2721F324D56@bigelow.org>
 <1198630950.9771632.1528378076847.JavaMail.zimbra@arpa.veneto.it>
 <582342719.9778477.1528379318105.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAGxFJbTu8f_kMDd7EiEwVdNxYUUnAZn=OQ_b5qdOWRSAw8eRbw@mail.gmail.com>

which() is unnecessary. Use logical subscripting:

... t$id[t$A ==x]

Further simplification can be gotten by using the with() function:

l <- with(t, sapply(unique(A), function(x) id[A ==x]))

Check this though -- there might be scoping issues.

Cheers,
Bert



On Thu, Jun 7, 2018, 6:49 AM Massimo Bressan <massimo.bressan at arpa.veneto.it>
wrote:

> #ok, finally this is my final "best and more compact" solution of the
> problem by merging different contributions (thanks to all indeed)
>
> t<-data.frame(id=c(18,91,20,68,54,27,26,15,4,97),A=c(123,345,123,678,345,123,789,345,123,789))
>
> l<-sapply(unique(t$A), function(x) t$id[which(t$A==x)])
> r<-data.frame(unique_A= unique(t$A), list_id=unlist(lapply(l, paste,
> collapse = ", ")))
> r
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From d@v|d@m| @end|ng |rom m|cro@o|t@com  Thu Jun  7 23:29:29 2018
From: d@v|d@m| @end|ng |rom m|cro@o|t@com (David Smith (CDA))
Date: Thu, 7 Jun 2018 21:29:29 +0000
Subject: [R] Revolutions blog: May 2018 roundup
Message-ID: <DM5PR2101MB10481D3343F5519CA52EED23C8640@DM5PR2101MB1048.namprd21.prod.outlook.com>

Since 2008, Microsoft staff and guests have written about R at the Revolutions
blog (http://blog.revolutionanalytics.com) and every month I post a summary of
articles from the previous month of particular interest to readers of r-help.

In case you missed them, here are some articles related to R from the
month of May:

The R Consortium has announced a new round of grants for projects proposed by
the R community:
http://blog.revolutionanalytics.com/2018/05/r-consortium-spring-2018.html

A look back at the ROpenSci unconference held in Seattle:
http://blog.revolutionanalytics.com/2018/05/reflections-on-the-ropensci-unconference.html

Video of my European R Users Meeting talk, "Speeding up R with Parallel
Programming in the Cloud":
http://blog.revolutionanalytics.com/2018/05/video-speeding-up-r-foreach.html

Slides from my talk at the Microsoft Build conference, "Open-Source Machine
Learning in Azure":
http://blog.revolutionanalytics.com/2018/05/open-source-machine-learning-in-azure.html

Discussions on Twitter: R packages by stage of data analysis; thinking
differently about AI development; and, why is package management harder in Python
than R? http://blog.revolutionanalytics.com/2018/05/three-twitter-threads.html

Microsoft R Open 3.4.4 is now available:
http://blog.revolutionanalytics.com/2018/04/microsoft-r-open-344-now-available.html

And some general interest stories (not necessarily related to R):

* A really bad road in Nepal:
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-bad-road.html

* Our May 2018 roundup of AI and data science news:
  http://blog.revolutionanalytics.com/2018/05/ai-roundup-may-2018.html 

* The definitive answer to "Laurel" or "Yanny" (it's Laurel):
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-laurel-or-yanny.html

* Panelist Francesca Lazzeri reviews the Mind Bytes AI conference in Chicago:
  http://blog.revolutionanalytics.com/2018/05/mind-bytes.html

* A parody of air travel:
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-planes-pains-and-automobiles.html

* When magpies attack:
  http://blog.revolutionanalytics.com/2018/05/because-its-friday-the-eyes-dont-work.html

As always, thanks for the comments and please keep sending suggestions to
me at davidsmi at microsoft.com or via Twitter (I'm @revodavid).

Cheers,
# David

-- 
David M Smith <davidsmi at microsoft.com>
Developer Advocate, Microsoft Cloud & Enterprise 
Tel: +1 (312) 9205766 (Chicago IL, USA)
Twitter: @revodavid | Blog: ?http://blog.revolutionanalytics.com



From du@@@@dr|@n @end|ng |rom un|buc@ro  Thu Jun  7 21:12:10 2018
From: du@@@@dr|@n @end|ng |rom un|buc@ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Thu, 7 Jun 2018 22:12:10 +0300
Subject: [R] problems in converting numeric to character
In-Reply-To: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
References: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
Message-ID: <CAJ=0CtAhuwYoLgz-Q_M=E1Vq3sTUZA+=b6WyVSQBQ2wOs1F6_Q@mail.gmail.com>

Does this helps?

> formatC(x, digits = 1, format = "f")
[1] "1.0" "2.0" "2.0" "2.1"


On Thu, Jun 7, 2018 at 10:08 PM ??? <ruiyangliu94 at gmail.com> wrote:

> Hi,
> I am having trouble converting numeric to characters in the format I
> desire. To be more specific, I have a number of numeric as follows:
>
> x<-c(1.0,2.0,2.00,2.1)
> I want to convert them to characters so that the out put would be
> c(?1.0?,?2.0?,?2.00?,?2.1?).
>
> However, I used as.character(x) and the output is:
> "1"   "2"   "2"   ?2.1"
>
> The decimals are removed if the numeric ends with ?.0?. Is there a way to
> circumvent this problem?
>
> Thanks very much!
>
> Sincerely,
>
> Ruiyang Liu
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Fri Jun  8 09:08:46 2018
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Fri, 8 Jun 2018 09:08:46 +0200
Subject: [R] problems in converting numeric to character
In-Reply-To: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
References: <B333E2C0-A34C-4DDB-88B3-BC371FA2CC46@gmail.com>
Message-ID: <0dd0ca0b-5938-e8a8-2a26-93bf1f50f9c8@wiwi.hu-berlin.de>

sprintf("%.1f", x)
sprintf("%.2f", x)

Am 07.06.2018 um 17:12 schrieb ???:
> Hi,
> I am having trouble converting numeric to characters in the format I desire. To be more specific, I have a number of numeric as follows:
> 
> x<-c(1.0,2.0,2.00,2.1)
> I want to convert them to characters so that the out put would be c(?1.0?,?2.0?,?2.00?,?2.1?).
> 
> However, I used as.character(x) and the output is:
> "1"   "2"   "2"   ?2.1"
> 
> The decimals are removed if the numeric ends with ?.0?. Is there a way to circumvent this problem?
> 
> Thanks very much!
> 
> Sincerely,
> 
> Ruiyang Liu
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 


-- 
Sprechstunde: Fr 12-13, SPA1, R308
https://hu.berlin/sk
https://hu.berlin/mmstat3


From E@Vettor@zz| @end|ng |rom uke@de  Fri Jun  8 09:45:30 2018
From: E@Vettor@zz| @end|ng |rom uke@de (Eik Vettorazzi)
Date: Fri, 8 Jun 2018 09:45:30 +0200
Subject: [R] aggregate and list elements of variables in data.frame
In-Reply-To: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
References: <976964276.9474260.1528272790562.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <13f05a25-03cb-5d0a-0b87-f719c3d0d875@uke.de>

Hi,
if you are willing to use dplyr, you can do all in one line of code:

library(dplyr)
df<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789))

df%>%group_by(unique_A=A)%>%summarise(list_id=paste(id,collapse=", "))->r

cheers


Am 06.06.2018 um 10:13 schrieb Massimo Bressan:
> #given the following reproducible and simplified example 
> 
> t<-data.frame(id=1:10,A=c(123,345,123,678,345,123,789,345,123,789)) 
> t 
> 
> #I need to get the following result 
> 
> r<-data.frame(unique_A=c(123, 345, 678, 789),list_id=c('1,3,6,9','2,5,8','4','7,10')) 
> r 
> 
> # i.e. aggregate over the variable "A" and list all elements of the variable "id" satisfying the criteria of having the same corrisponding value of "A" 
> #any help for that? 
> 
> #so far I've just managed to "aggregate" and "count", like: 
> 
> library(sqldf) 
> sqldf('select count(*) as count_id, A as unique_A from t group by A') 
> 
> library(dplyr) 
> t%>%group_by(unique_A=A) %>% summarise(count_id = n()) 
> 
> # thank you 
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

-- 
Eik Vettorazzi

Department of Medical Biometry and Epidemiology
University Medical Center Hamburg-Eppendorf

Martinistrasse 52
building W 34
20246 Hamburg

Phone: +49 (0) 40 7410 - 58243
Fax:   +49 (0) 40 7410 - 57790
Web: www.uke.de/imbe
--

_____________________________________________________________________

Universit?tsklinikum Hamburg-Eppendorf; K?rperschaft des ?ffentlichen Rechts; Gerichtsstand: Hamburg | www.uke.de
Vorstandsmitglieder: Prof. Dr. Burkhard G?ke (Vorsitzender), Prof. Dr. Dr. Uwe Koch-Gromus, Joachim Pr?l?, Martina Saurin (komm.)
_____________________________________________________________________

SAVE PAPER - THINK BEFORE PRINTING

From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jun  8 11:13:24 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 8 Jun 2018 11:13:24 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <23321.24292.243245.897326@stat.math.ethz.ch>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
Message-ID: <23322.18612.376176.297782@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Thu, 7 Jun 2018 18:35:48 +0200 writes:

>>>>> Gerrit Eichner 
>>>>>     on Thu, 7 Jun 2018 09:03:46 +0200 writes:

    >> Hi, Chris, had the same problem (and first thought it was
    >> my fault), but there seems to be a typo in the code of
    >> pairs.default. Below is a workaround.  Look for two
    >> comments (starting with #####) in the code to see what I
    >> have changed to make it work at least the way I'd expect
    >> it in one of your examples.

    >> Hth -- Gerrit


> > mypairs <- function (x, labels, panel = points, ...,
> >      horInd = 1:nc, verInd = 1:nc,
> >      lower.panel = panel, upper.panel = panel, diag.panel = NULL,
> >      text.panel = textPanel, label.pos = 0.5 + has.diag/3, line.main = 3,
> >      cex.labels = NULL, font.labels = 1, row1attop = TRUE, gap = 1,
> >      log = "") {
> >      if (doText <- missing(text.panel) || is.function(text.panel))
> >          textPanel <- function(x = 0.5, y = 0.5, txt, cex, font) text(x,
> >              y, txt, cex = cex, font = font)
> >      localAxis <- function(side, x, y, xpd, bg, col = NULL, main,
> >          oma, ...) {
> >          xpd <- NA
> >          if (side%%2L == 1L && xl[j])
> >              xpd <- FALSE
> >          if (side%%2L == 0L && yl[i])
> >              xpd <- FALSE
> >          if (side%%2L == 1L)
> >              Axis(x, side = side, xpd = xpd, ...)
> >          else Axis(y, side = side, xpd = xpd, ...)
> >      }
> >      localPlot <- function(..., main, oma, font.main, cex.main) plot(...)
> >      localLowerPanel <- function(..., main, oma, font.main, cex.main) lower.panel(...)
> >      localUpperPanel <- function(..., main, oma, font.main, cex.main) upper.panel(...)
> >      localDiagPanel <- function(..., main, oma, font.main, cex.main) diag.panel(...)
> >      dots <- list(...)
> >      nmdots <- names(dots)
> >      if (!is.matrix(x)) {
> >          x <- as.data.frame(x)
> >          for (i in seq_along(names(x))) {
> >              if (is.factor(x[[i]]) || is.logical(x[[i]]))
> >                  x[[i]] <- as.numeric(x[[i]])
> >              if (!is.numeric(unclass(x[[i]])))
> >                  stop("non-numeric argument to 'pairs'")
> >          }
> >      }
> >      else if (!is.numeric(x))
> >          stop("non-numeric argument to 'pairs'")
> >      panel <- match.fun(panel)
> >      if ((has.lower <- !is.null(lower.panel)) && !missing(lower.panel))
> >          lower.panel <- match.fun(lower.panel)
> >      if ((has.upper <- !is.null(upper.panel)) && !missing(upper.panel))
> >          upper.panel <- match.fun(upper.panel)
> >      if ((has.diag <- !is.null(diag.panel)) && !missing(diag.panel))
> >          diag.panel <- match.fun(diag.panel)
> >      if (row1attop) {
> >          tmp <- lower.panel
> >          lower.panel <- upper.panel
> >          upper.panel <- tmp
> >          tmp <- has.lower
> >          has.lower <- has.upper
> >          has.upper <- tmp
> >      }
> >      nc <- ncol(x)
> >      if (nc < 2L)
> >          stop("only one column in the argument to 'pairs'")
> >      if (!all(horInd >= 1L && horInd <= nc))
> >          stop("invalid argument 'horInd'")
> >      if (!all(verInd >= 1L && verInd <= nc))
> >          stop("invalid argument 'verInd'")
> >      if (doText) {
> >          if (missing(labels)) {
> >              labels <- colnames(x)
> >              if (is.null(labels))
> >                  labels <- paste("var", 1L:nc)
> >          }
> >          else if (is.null(labels))
> >              doText <- FALSE
> >      }
> >      oma <- if ("oma" %in% nmdots)
> >          dots$oma
> >      main <- if ("main" %in% nmdots)
> >          dots$main
> >      if (is.null(oma))
> >          oma <- c(4, 4, if (!is.null(main)) 6 else 4, 4)
> >      opar <- par(mfcol = c(length(horInd), length(verInd)),
> > ##### Changed from mfrow to mfcol
> >                  mar = rep.int(gap/2, 4), oma = oma)
> >      on.exit(par(opar))
> >      dev.hold()
> >      on.exit(dev.flush(), add = TRUE)
> >      xl <- yl <- logical(nc)
> >      if (is.numeric(log))
> >          xl[log] <- yl[log] <- TRUE
> >      else {
> >          xl[] <- grepl("x", log)
> >          yl[] <- grepl("y", log)
> >      }
> >      for (j in if (row1attop) verInd else rev(verInd))
> >       for (i in horInd) {
> > ##### Exchanged i and j. (i used to be in
> > ##### the outer and j in the inner loop!)
> >          l <- paste0(ifelse(xl[j], "x", ""), ifelse(yl[i], "y", ""))
> >          localPlot(x[, j], x[, i], xlab = "", ylab = "", axes = FALSE,
> >              type = "n", ..., log = l)
> >          if (i == j || (i < j && has.lower) || (i > j && has.upper)) {
> >              box()
> >              if (i == 1 && (!(j%%2L) || !has.upper || !has.lower))
> >                  localAxis(1L + 2L * row1attop, x[, j], x[, i],
> >                    ...)
> >              if (i == nc && (j%%2L || !has.upper || !has.lower))
> >                  localAxis(3L - 2L * row1attop, x[, j], x[, i],
> >                    ...)
> >              if (j == 1 && (!(i%%2L) || !has.upper || !has.lower))
> >                  localAxis(2L, x[, j], x[, i], ...)
> >              if (j == nc && (i%%2L || !has.upper || !has.lower))
> >                  localAxis(4L, x[, j], x[, i], ...)
> >              mfg <- par("mfg")
> >              if (i == j) {
> >                  if (has.diag)
> >                    localDiagPanel(as.vector(x[, i]), ...)
> >                  if (doText) {
> >                    par(usr = c(0, 1, 0, 1))
> >                    if (is.null(cex.labels)) {
> >                      l.wid <- strwidth(labels, "user")
> >                      cex.labels <- max(0.8, min(2, 0.9/max(l.wid)))
> >                    }
> >                    xlp <- if (xl[i])
> >                      10^0.5
> >                    else 0.5
> >                    ylp <- if (yl[j])
> >                      10^label.pos
> >                    else label.pos
> >                    text.panel(xlp, ylp, labels[i], cex = cex.labels,
> >                      font = font.labels)
> >                  }
> >              }
> >              else if (i < j)
> >                  localLowerPanel(as.vector(x[, j]), as.vector(x[,
> >                    i]), ...)
> >              else localUpperPanel(as.vector(x[, j]), as.vector(x[,
> >                  i]), ...)
> >              if (any(par("mfg") != mfg))
> >                  stop("the 'panel' function made a new plot")
> >          }
> >          else par(new = FALSE)
> >      }
> >      if (!is.null(main)) {
> >          font.main <- if ("font.main" %in% nmdots)
> >              dots$font.main
> >          else par("font.main")
> >          cex.main <- if ("cex.main" %in% nmdots)
> >              dots$cex.main
> >          else par("cex.main")
> >          mtext(main, 3, line.main, outer = TRUE, at = 0.5, cex = cex.main,
> >              font = font.main)
> >      }
> >      invisible(NULL)
> > }
> > 
> > 
> > 
> > ## Example:
> > 
> > mypairs(xmat, xlim=lim, ylim=lim, verInd=1:2, horInd=1:4)
> 
> Thank you, Chris, for the report and
> Gerrit for your proposed fix !!
> 
> It looks good to me,  but I will test some more (also with
> 'row1attop=FALSE')  before committing the bug fix.

and there, another change was needed:  Instead of your

    for (j in if (row1attop) verInd else rev(verInd))
        for (i in horInd) {

we do now need

    for(j in verInd)
        for(i in if(row1attop) horInd else rev(horInd)) {

and the difference is of course only relevant for the
non-default  'row1attop = FALSE'

  (which some graphic experts argue to be clearly *better* than the default,
   as only in that case,  the upper and lower triangles of the
   matrix are nicely "mirrors of each other", and that is also
   the reason why  lattice::splom()  uses the equivalent of
   'row1attop=FALSE')

I will commit the change to R-devel today - and intend to port
to R-patched in time to make it into the upcoming R 3.5.1.

Thank you once more !
Martin



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jun  8 12:02:43 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 8 Jun 2018 12:02:43 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <23322.18612.376176.297782@stat.math.ethz.ch>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
 <23322.18612.376176.297782@stat.math.ethz.ch>
Message-ID: <23322.21571.493562.112124@stat.math.ethz.ch>

>>>>> Martin Maechler 
>>>>>     on Fri, 8 Jun 2018 11:13:24 +0200 writes:

[..........]

    >> Thank you, Chris, for the report and
    >> Gerrit for your proposed fix !!
    >> 
    >> It looks good to me,  but I will test some more (also with
    >> 'row1attop=FALSE')  before committing the bug fix.

    > and there, another change was needed:  Instead of your

    > for (j in if (row1attop) verInd else rev(verInd))
    >    for (i in horInd) {

    > we do now need

    > for(j in verInd)
    >    for(i in if(row1attop) horInd else rev(horInd)) {

    > and the difference is of course only relevant for the
    > non-default  'row1attop = FALSE'

    > (which some graphic experts argue to be clearly *better* than the default,
    > as only in that case,  the upper and lower triangles of the
    > matrix are nicely "mirrors of each other", and that is also
    > the reason why  lattice::splom()  uses the equivalent of
    > 'row1attop=FALSE')

    > I will commit the change to R-devel today - and intend to port
    > to R-patched in time to make it into the upcoming R 3.5.1.

Well, as I find, there are more bugs there, if you are using
'horInd' and 'verInd' creatively:

In a nice pairs(), the axis ticks (and their labels (numbers))
are always "on the outside" of the scatterplot matrix, and
nicely alternating.  This is not the case unfortunately, when using
 horInd or verInd which are *not* of the form p1:p2 (p1 <= p2)

==> even more changes are needed to make these cases "nice",
or  should we *require* horInd and verInd to be of that form??

This would not be back-compatible, but than such cases have been
"wrong" really in all versions of R anyway, *and*  at least be
reordering the matrix/data.frame columns, the restriction of

    (hor|ver)Ind =  p1:p2 (p1 <= p2)

would seem acceptable, would it ?



From S@E|||@on @end|ng |rom LGCGroup@com  Fri Jun  8 12:40:02 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Fri, 8 Jun 2018 10:40:02 +0000
Subject: [R] internet routines cannot be loaded, R 3.5.0
In-Reply-To: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
References: <66399177-3c3e-74f7-6008-19cc00bf574a@molconn.com>
Message-ID: <a172a6f2722e47719b9686ed381c37aa@GBDCVPEXC08.corp.lgc-group.com>

> If I select
> "packages > install packages" in the R console, I get a message, "no
> packages were specified". I thought this command gave me a list of packages
> available to install.

You are thinking of the command line function "installed.packages", not the menu function or the package installation function "install.packages"

The latter needs a list of packages to install. The former tells you what is already installed.

S Ellison


*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de  Fri Jun  8 12:55:31 2018
From: gerr|t@e|chner @end|ng |rom m@th@un|-g|e@@en@de (Gerrit Eichner)
Date: Fri, 8 Jun 2018 12:55:31 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <23322.21571.493562.112124@stat.math.ethz.ch>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
 <23322.18612.376176.297782@stat.math.ethz.ch>
 <23322.21571.493562.112124@stat.math.ethz.ch>
Message-ID: <c330a86d-bc1c-8bff-ac82-8209e38e9e6b@math.uni-giessen.de>

Am 08.06.2018 um 12:02 schrieb Martin Maechler:
>>>>>> Martin Maechler
>>>>>>      on Fri, 8 Jun 2018 11:13:24 +0200 writes:
> 
> [..........]
> 
>      >> Thank you, Chris, for the report and
>      >> Gerrit for your proposed fix !!
>      >>
>      >> It looks good to me,  but I will test some more (also with
>      >> 'row1attop=FALSE')  before committing the bug fix.
> 
>      > and there, another change was needed:  Instead of your
> 
>      > for (j in if (row1attop) verInd else rev(verInd))
>      >    for (i in horInd) {
> 
>      > we do now need
> 
>      > for(j in verInd)
>      >    for(i in if(row1attop) horInd else rev(horInd)) {
> 
>      > and the difference is of course only relevant for the
>      > non-default  'row1attop = FALSE'
> 
>      > (which some graphic experts argue to be clearly *better* than the default,
>      > as only in that case,  the upper and lower triangles of the
>      > matrix are nicely "mirrors of each other", and that is also
>      > the reason why  lattice::splom()  uses the equivalent of
>      > 'row1attop=FALSE')
> 
>      > I will commit the change to R-devel today - and intend to port
>      > to R-patched in time to make it into the upcoming R 3.5.1.
> 
> Well, as I find, there are more bugs there, if you are using
> 'horInd' and 'verInd' creatively:
> 
> In a nice pairs(), the axis ticks (and their labels (numbers))
> are always "on the outside" of the scatterplot matrix, and
> nicely alternating.  This is not the case unfortunately, when using
>   horInd or verInd which are *not* of the form p1:p2 (p1 <= p2)
> 
> ==> even more changes are needed to make these cases "nice",

Well, the *shown* axis ticks and labels do nicely alternate if
(hor|ver)Ind = p1:p2 (p1 <= p2) is fulfilled, but not all of
the axis ticks and labels, which one *might* wish to see, are
currently drawn anyway ... I would consider changes which "heal"
this as more interesting than solving this problem in full
generality, i.e., in cases of creative use of (hor|ver)Ind.
However, I don't think it's urgent, at all.


> or  should we *require* horInd and verInd to be of that form??
> 
> This would not be back-compatible, but than such cases have been
> "wrong" really in all versions of R anyway, *and*  at least be
> reordering the matrix/data.frame columns, the restriction of
> 
>      (hor|ver)Ind =  p1:p2 (p1 <= p2)
> 
> would seem acceptable, would it ?
> 

I could live very well with that requirement (while breaking
back-compatibility), because from my point of view a "creative"
use of 'horInd' and 'verInd' violating (hor|ver)Ind = p1:p2
(p1 <= p2) won't occur often.

On the other hand, why forcing (hor|ver)Ind = p1:p2 (p1 <= p2)?
If people violated it "they get what they deserve". ;-)

Btw, 'horInd' and 'verInd' sort of exchange their meaning if
row1attop = FALSE, but I this can be explained by the "work flow":
First, (hor|ver)Ind are used to select the respective rows and
columns from the full paris-plot, and then, row1attop is used
when the results are drawn. I think this is sensible.

  Regards  --  Gerrit



From @ez@reb@k| @end|ng |rom gm@||@com  Fri Jun  8 02:49:11 2018
From: @ez@reb@k| @end|ng |rom gm@||@com (Alex Zarebski)
Date: Fri, 8 Jun 2018 10:49:11 +1000
Subject: [R] open help files from Terminal
In-Reply-To: <CAJL_pohsSWXQLite=xa4huknBy8bD-XzmR2rRzc486ntdN5wbQ@mail.gmail.com>
References: <CAJL_pojgKwYOm4OXFXROPHsa242pYSVyzAkJtp3FZ9PPFJPyEg@mail.gmail.com>
 <CAM_vjumVK3EzWtP5FN+rPOH3ThgqL8id2WrsKb=vnS+cy9HYXg@mail.gmail.com>
 <CAJL_pohsSWXQLite=xa4huknBy8bD-XzmR2rRzc486ntdN5wbQ@mail.gmail.com>
Message-ID: <CAKsw2nHSSPCM-qz3f2eSKk=DpBnvE=vACWog1mwR=Thzpd_ExA@mail.gmail.com>

While we are on the topic, if you wanted to go the other way (open help in
terminal without a whole R session) you can do

R --no-init-file --slave -e "?sd"

I suspect this does start an R session in the background, but makes for a
clean way to view docs through terminal if you use an alias.

Cheers,
Alex

On Fri, Jun 8, 2018 at 1:47 AM, Dmitri Popavenko <dmitri.popavenko at gmail.com
> wrote:

> Dear Sarah, dear David,
>
> Thank you very much indeed, this is exactly what I needed.
>
> Best,
> Dmitri
>
> On Thu, Jun 7, 2018 at 6:39 PM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
>
> > Here are two options:
> >
> > > # for one occurrence
> > > help("help", help_type="html")
> > starting httpd help server ... done
> > >
> > > # to set the default for your R session
> > > options(help_type = "html")
> > > ?help
> >
> > If you read the help file for help(), you will see all the possibilities.
> >
> > Sarah
> >
> > On Thu, Jun 7, 2018 at 11:21 AM, Dmitri Popavenko
> > <dmitri.popavenko at gmail.com> wrote:
> > > Dear R users,
> > >
> > > I am sometimes using R from a Terminal (either from Linux but most
> often
> > on
> > > MacOS).
> > > When looking at a help file using the question mark (e.g. ?sd) the help
> > > file opens in the Terminal itself.
> > >
> > > If possible, I would like to open the HTML version of the help file in
> a
> > > webpage, but I am completely unaware of how this might be done.
> > >
> > > If anyone has a suggestion, I would be very grateful.
> > >
> > > Best,
> > > Dmitri
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@ech|er @end|ng |rom @t@t@m@th@ethz@ch  Fri Jun  8 17:31:12 2018
From: m@ech|er @end|ng |rom @t@t@m@th@ethz@ch (Martin Maechler)
Date: Fri, 8 Jun 2018 17:31:12 +0200
Subject: [R] verInd= and HorInd= arguments to pairs() function
In-Reply-To: <c330a86d-bc1c-8bff-ac82-8209e38e9e6b@math.uni-giessen.de>
References: <eea156749e3044249cf0b56a264249ef@med.umich.edu>
 <ff1e9b9d-8b53-f7f0-8702-d7ffd0927614@math.uni-giessen.de>
 <23321.24292.243245.897326@stat.math.ethz.ch>
 <23322.18612.376176.297782@stat.math.ethz.ch>
 <23322.21571.493562.112124@stat.math.ethz.ch>
 <c330a86d-bc1c-8bff-ac82-8209e38e9e6b@math.uni-giessen.de>
Message-ID: <23322.41280.560267.586732@stat.math.ethz.ch>

>>>>> Gerrit Eichner 
>>>>>     on Fri, 8 Jun 2018 12:55:31 +0200 writes:

    > Am 08.06.2018 um 12:02 schrieb Martin Maechler:
    >>>>>>> Martin Maechler
    >>>>>>> on Fri, 8 Jun 2018 11:13:24 +0200 writes:
    >> 
    >> [..........]
    >> 
    >> >> Thank you, Chris, for the report and
    >> >> Gerrit for your proposed fix !!
    >> >>
    >> >> It looks good to me,  but I will test some more (also with
    >> >> 'row1attop=FALSE')  before committing the bug fix.
    >> 
    >> > and there, another change was needed:  Instead of your
    >> 
    >> > for (j in if (row1attop) verInd else rev(verInd))
    >> >    for (i in horInd) {
    >> 
    >> > we do now need
    >> 
    >> > for(j in verInd)
    >> >    for(i in if(row1attop) horInd else rev(horInd)) {
    >> 
    >> > and the difference is of course only relevant for the
    >> > non-default  'row1attop = FALSE'
    >> 
    >> > (which some graphic experts argue to be clearly *better* than the default,
    >> > as only in that case,  the upper and lower triangles of the
    >> > matrix are nicely "mirrors of each other", and that is also
    >> > the reason why  lattice::splom()  uses the equivalent of
    >> > 'row1attop=FALSE')
    >> 
    >> > I will commit the change to R-devel today - and intend to port
    >> > to R-patched in time to make it into the upcoming R 3.5.1.
    >> 
    >> Well, as I find, there are more bugs there, if you are using
    >> 'horInd' and 'verInd' creatively:
    >> 
    >> In a nice pairs(), the axis ticks (and their labels (numbers))
    >> are always "on the outside" of the scatterplot matrix, and
    >> nicely alternating.  This is not the case unfortunately, when using
    >> horInd or verInd which are *not* of the form p1:p2 (p1 <= p2)
    >> 
    >> ==> even more changes are needed to make these cases "nice",

    > Well, the *shown* axis ticks and labels do nicely alternate if
    > (hor|ver)Ind = p1:p2 (p1 <= p2) is fulfilled, but not all of
    > the axis ticks and labels, which one *might* wish to see, are
    > currently drawn anyway ... I would consider changes which "heal"
    > this as more interesting than solving this problem in full
    > generality, i.e., in cases of creative use of (hor|ver)Ind.
    > However, I don't think it's urgent, at all.


    >> or  should we *require* horInd and verInd to be of that form??
    >> 
    >> This would not be back-compatible, but than such cases have been
    >> "wrong" really in all versions of R anyway, *and*  at least be
    >> reordering the matrix/data.frame columns, the restriction of
    >> 
    >> (hor|ver)Ind =  p1:p2 (p1 <= p2)
    >> 
    >> would seem acceptable, would it ?
    >> 

    > I could live very well with that requirement (while breaking
    > back-compatibility), because from my point of view a "creative"
    > use of 'horInd' and 'verInd' violating (hor|ver)Ind = p1:p2
    > (p1 <= p2) won't occur often.

    > On the other hand, why forcing (hor|ver)Ind = p1:p2 (p1 <= p2)?
    > If people violated it "they get what they deserve". ;-)

    > Btw, 'horInd' and 'verInd' sort of exchange their meaning if
    > row1attop = FALSE, but I this can be explained by the "work flow":
    > First, (hor|ver)Ind are used to select the respective rows and
    > columns from the full paris-plot, and then, row1attop is used
    > when the results are drawn. I think this is sensible.

Thank you; and yes indeed, and I was not going to change that.

In fact, I've found a relatively nice solution now, which does
*not* restrict the settings of '{hor,ver}Ind' and fixes all
problems mentioned,  quite back compatibly, and in some sense
perfectly labeling the axes.

==> Committed to R-devel svn c74871  a few minutes ago.

Martin



From m@r|ne@reg|@ @end|ng |rom hotm@||@|r  Fri Jun  8 18:00:23 2018
From: m@r|ne@reg|@ @end|ng |rom hotm@||@|r (Marine Regis)
Date: Fri, 8 Jun 2018 16:00:23 +0000
Subject: [R] Calculate focal values for neighboring cells that are located
 at the raster edge from the function "focal" in the R package "raster"
Message-ID: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>

Hello All,

I am using the function "focal" in the R package "raster" but I don?t understand how the function calculates values for neighboring cells that are located at the raster edge. Here is an example reproducible:

f <- matrix(1, nrow=3, ncol=3)
f[c(1,3,7,9)]=1/sqrt(2)
f[5]=0

func <- function(x) {
  sum(abs(x-x[5])*f)/8
}

r <- raster(ncol=3, nrow=3)
vals <- 1:ncell(r)
r <- setValues(r, vals)
plot(r)

func_f  <- focal(r, w=matrix(1,nrow=3,ncol=3),
                   fun= func, pad = TRUE, padValue = NA)
text(func_f )
getValues(func_f)


From the example, I manage to find the value ?2.06066?:

c <- 5

(abs(1-c)*(1/sqrt(2)) + abs(2-c)*1 + abs(3-c)*(1/sqrt(2)) +

  abs(4-c)*1 + abs(5-c)*0 + abs(6-c)*1 +

  abs(7-c)*(1/sqrt(2)) + abs(8-c)*1 + abs(9-c)*(1/sqrt(2))) / 8


 but I don?t manage to find the value ?2.18566?. How can I find this value ? In addition, why does the function with ?pad = TRUE? and without ?pad=TRUE? give the same result ?

 Thank you very much for your time.

Have a nice day

Marine


	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun  8 23:52:22 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 8 Jun 2018 14:52:22 -0700
Subject: [R] 
 Calculate focal values for neighboring cells that are located
 at the raster edge from the function "focal" in the R package "raster"
In-Reply-To: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>
References: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>
Message-ID: <CAGxFJbRbwu0Oup4Tw1w4mu=CPDNNtFWK1=n5eGyL6PmaRvYEWA@mail.gmail.com>

The r-sig-geo list is often a better place to post for such
"geographically" related questions, especially if you don't  get a helpful
response  here.

But R is open source, so typing

raster:::focal

at the command line prompt will show you the function code if it is written
in R. Whether that is "helpful" is another matter.

Cheers,
Bert

On Fri, Jun 8, 2018, 9:00 AM Marine Regis <marine.regis at hotmail.fr> wrote:

> Hello All,
>
> I am using the function "focal" in the R package "raster" but I don?t
> understand how the function calculates values for neighboring cells that
> are located at the raster edge. Here is an example reproducible:
>
> f <- matrix(1, nrow=3, ncol=3)
> f[c(1,3,7,9)]=1/sqrt(2)
> f[5]=0
>
> func <- function(x) {
>   sum(abs(x-x[5])*f)/8
> }
>
> r <- raster(ncol=3, nrow=3)
> vals <- 1:ncell(r)
> r <- setValues(r, vals)
> plot(r)
>
> func_f  <- focal(r, w=matrix(1,nrow=3,ncol=3),
>                    fun= func, pad = TRUE, padValue = NA)
> text(func_f )
> getValues(func_f)
>
>
> From the example, I manage to find the value ?2.06066?:
>
> c <- 5
>
> (abs(1-c)*(1/sqrt(2)) + abs(2-c)*1 + abs(3-c)*(1/sqrt(2)) +
>
>   abs(4-c)*1 + abs(5-c)*0 + abs(6-c)*1 +
>
>   abs(7-c)*(1/sqrt(2)) + abs(8-c)*1 + abs(9-c)*(1/sqrt(2))) / 8
>
>
>  but I don?t manage to find the value ?2.18566?. How can I find this value
> ? In addition, why does the function with ?pad = TRUE? and without
> ?pad=TRUE? give the same result ?
>
>  Thank you very much for your time.
>
> Have a nice day
>
> Marine
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code. Is
> helpful is
>

	[[alternative HTML version deleted]]



From p@u|bern@|07 @end|ng |rom gm@||@com  Fri Jun  8 21:26:13 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Fri, 8 Jun 2018 14:26:13 -0500
Subject: [R] Calculating AIC and BIC for Time Series Models
Message-ID: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>

Dear friends,

I have been fitting some TS models from the forecast package like ets(),
ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
trying to use the AIC and BIC functions, I receive the following error
message:

Error in UseMethod("logLik") :
  no applicable method for 'logLik' applied to an object of class "forecast"

Yes, the message is clear, those functions cannot be applied to objects
from the forecast class. However, I would like to know if there is a way to
assess the goodness of fit for this models that is somewhat equivalent to
AIC and BIC, or of there is any other function that could help me in the
model selection stage, other than computing MASE, MAPE, etc.

Any help and or guidance will be greatly appreciated.

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jun  8 21:43:53 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 8 Jun 2018 12:43:53 -0700
Subject: [R] Calculating AIC and BIC for Time Series Models
In-Reply-To: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
References: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
Message-ID: <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>


> On Jun 8, 2018, at 12:26 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
> 
> Dear friends,
> 
> I have been fitting some TS models from the forecast package like ets(),
> ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
> trying to use the AIC and BIC functions, I receive the following error
> message:
> 
> Error in UseMethod("logLik") :
>  no applicable method for 'logLik' applied to an object of class "forecast"
> 
> Yes, the message is clear, those functions cannot be applied to objects
> from the forecast class. However, I would like to know if there is a way to
> assess the goodness of fit for this models that is somewhat equivalent to
> AIC and BIC, or of there is any other function that could help me in the
> model selection stage, other than computing MASE, MAPE, etc.
> 
> Any help and or guidance will be greatly appreciated.
> 
> 	[[alternative HTML version deleted]]

Fourth google hit on a search "goodness of fit measures for forecasts" by the author of hte forecast package:

goodness of fit measures for forecasts


> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From rc@e2006 @end|ng |rom gm@||@com  Fri Jun  8 16:36:31 2018
From: rc@e2006 @end|ng |rom gm@||@com (Rama shankar)
Date: Fri, 8 Jun 2018 20:06:31 +0530
Subject: [R] How to threshold point in time series
Message-ID: <CAGYGU1cHcTUE=mg2rnyJwUo1Bf4fsACjUCdoQXk56s3wsFmpQg@mail.gmail.com>

Hi All,
I am having very high-frequency data, captured  between 3 to 7 seconds by
sensor for liquid tank and capacity of tank is 50k dm3. When tank capacity
reduce to 1k dm3, than tank refilling need to call.
How in time series we can perform, refilling can call when tank capacity
reduce to 1k dm3, and how to find 1k dm3 as threshold point and repeat the
process.

Please help me, how to approach and which kinds of algorithm required to
solve this problem using R/ python.

Thanks..

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jun  8 22:22:51 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 8 Jun 2018 13:22:51 -0700
Subject: [R] Calculating AIC and BIC for Time Series Models
In-Reply-To: <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>
References: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
 <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>
Message-ID: <18DFEF58-20A9-43FE-8663-3BA24D745F2C@comcast.net>


> On Jun 8, 2018, at 12:43 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 8, 2018, at 12:26 PM, Paul Bernal <paulbernal07 at gmail.com> wrote:
>> 
>> Dear friends,
>> 
>> I have been fitting some TS models from the forecast package like ets(),
>> ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
>> trying to use the AIC and BIC functions, I receive the following error
>> message:
>> 
>> Error in UseMethod("logLik") :
>> no applicable method for 'logLik' applied to an object of class "forecast"
>> 
>> Yes, the message is clear, those functions cannot be applied to objects
>> from the forecast class. However, I would like to know if there is a way to
>> assess the goodness of fit for this models that is somewhat equivalent to
>> AIC and BIC, or of there is any other function that could help me in the
>> model selection stage, other than computing MASE, MAPE, etc.
>> 
>> Any help and or guidance will be greatly appreciated.
>> 
>> 	[[alternative HTML version deleted]]
> 
> Fourth google hit on a search "goodness of fit measures for forecasts" by the author of hte forecast package:

https://pdfs.semanticscholar.org/af71/3d815a7caba8dff7248ecea05a5956b2a487.pdf

> 
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun  9 01:29:35 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 8 Jun 2018 16:29:35 -0700
Subject: [R] Calculating AIC and BIC for Time Series Models
In-Reply-To: <18DFEF58-20A9-43FE-8663-3BA24D745F2C@comcast.net>
References: <CAMOcQfPfjqDdbQHEBcsqvpOGNKUGVUvE-dbc+hEb5ttEvKpNyA@mail.gmail.com>
 <2EE32313-BE9A-42C2-89AE-6F9AB6495EAD@comcast.net>
 <18DFEF58-20A9-43FE-8663-3BA24D745F2C@comcast.net>
Message-ID: <CAGxFJbR5F0wHVOGVYYeMeWc-9MDGpcVUftEZQR8di03KxJ+0sQ@mail.gmail.com>

... Or have you looked here?

https://cran.r-project.org/web/views/TimeSeries.html

Bert

On Fri, Jun 8, 2018, 1:29 PM David Winsemius <dwinsemius at comcast.net> wrote:

>
> > On Jun 8, 2018, at 12:43 PM, David Winsemius <dwinsemius at comcast.net>
> wrote:
> >
> >
> >> On Jun 8, 2018, at 12:26 PM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
> >>
> >> Dear friends,
> >>
> >> I have been fitting some TS models from the forecast package like ets(),
> >> ses(), hw(), HoltWinters(), stlf(), bats() and tbats(), however, when
> >> trying to use the AIC and BIC functions, I receive the following error
> >> message:
> >>
> >> Error in UseMethod("logLik") :
> >> no applicable method for 'logLik' applied to an object of class
> "forecast"
> >>
> >> Yes, the message is clear, those functions cannot be applied to objects
> >> from the forecast class. However, I would like to know if there is a
> way to
> >> assess the goodness of fit for this models that is somewhat equivalent
> to
> >> AIC and BIC, or of there is any other function that could help me in the
> >> model selection stage, other than computing MASE, MAPE, etc.
> >>
> >> Any help and or guidance will be greatly appreciated.
> >>
> >>      [[alternative HTML version deleted]]
> >
> > Fourth google hit on a search "goodness of fit measures for forecasts"
> by the author of hte forecast package:
>
>
> https://pdfs.semanticscholar.org/af71/3d815a7caba8dff7248ecea05a5956b2a487.pdf
>
> >
> >>
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
> > David Winsemius
> > Alameda, CA, USA
> >
> > 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jrkr|de@u @end|ng |rom y@hoo@c@  Fri Jun  8 23:26:03 2018
From: jrkr|de@u @end|ng |rom y@hoo@c@ (John Kane)
Date: Fri, 8 Jun 2018 21:26:03 +0000 (UTC)
Subject: [R] How to threshold point in time series
In-Reply-To: <CAGYGU1cHcTUE=mg2rnyJwUo1Bf4fsACjUCdoQXk56s3wsFmpQg@mail.gmail.com>
References: <CAGYGU1cHcTUE=mg2rnyJwUo1Bf4fsACjUCdoQXk56s3wsFmpQg@mail.gmail.com>
Message-ID: <724210387.2564904.1528493163842@mail.yahoo.com>

 
Homework?
    On Friday, June 8, 2018, 4:20:40 p.m. EDT, Rama shankar <rcse2006 at gmail.com> wrote:  
 
 Hi All,
I am having very high-frequency data, captured? between 3 to 7 seconds by
sensor for liquid tank and capacity of tank is 50k dm3. When tank capacity
reduce to 1k dm3, than tank refilling need to call.
How in time series we can perform, refilling can call when tank capacity
reduce to 1k dm3, and how to find 1k dm3 as threshold point and repeat the
process.

Please help me, how to approach and which kinds of algorithm required to
solve this problem using R/ python.

Thanks..

??? [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.
  
	[[alternative HTML version deleted]]



From jerem|eju@te @end|ng |rom gm@||@com  Sat Jun  9 14:25:18 2018
From: jerem|eju@te @end|ng |rom gm@||@com (Jeremie Juste)
Date: Sat, 09 Jun 2018 14:25:18 +0200
Subject: [R] 
 Calculate focal values for neighboring cells that are located
 at the raster edge from the function "focal" in the R package "raster"
In-Reply-To: <CAGxFJbRbwu0Oup4Tw1w4mu=CPDNNtFWK1=n5eGyL6PmaRvYEWA@mail.gmail.com>
 (Bert Gunter's message of "Fri, 8 Jun 2018 14:52:22 -0700")
References: <VI1PR07MB3503483BBBE2B93D9BE6A17CE27B0@VI1PR07MB3503.eurprd07.prod.outlook.com>
 <CAGxFJbRbwu0Oup4Tw1w4mu=CPDNNtFWK1=n5eGyL6PmaRvYEWA@mail.gmail.com>
Message-ID: <871sdgno41.fsf@gmail.com>


Hello,

>> I am using the function "focal" in the R package "raster" but I don?t
>> understand how the function calculates values for neighboring cells that
>> are located at the raster edge. Here is an example reproducible:

focal is a method for the S4 object RasterLayer. You can have access to
this method by using 

> findMethods("focal")

and you can trace the method by using
> trace(what='focal', tracer=browser, at=1, signature='RasterLayer')

HTH,

Jeremie






>> }
>>
>> r <- raster(ncol=3, nrow=3)
>> vals <- 1:ncell(r)
>> r <- setValues(r, vals)
>> plot(r)
>>
>> func_f  <- focal(r, w=matrix(1,nrow=3,ncol=3),
>>                    fun= func, pad = TRUE, padValue = NA)
>> text(func_f )
>> getValues(func_f)
>>
>>
>> From the example, I manage to find the value ?2.06066?:
>>
>> c <- 5
>>
>> (abs(1-c)*(1/sqrt(2)) + abs(2-c)*1 + abs(3-c)*(1/sqrt(2)) +
>>
>>   abs(4-c)*1 + abs(5-c)*0 + abs(6-c)*1 +
>>
>>   abs(7-c)*(1/sqrt(2)) + abs(8-c)*1 + abs(9-c)*(1/sqrt(2))) / 8
>>
>>
>>  but I don?t manage to find the value ?2.18566?. How can I find this value
>> ? In addition, why does the function with ?pad = TRUE? and without
>> ?pad=TRUE? give the same result ?
>>
>>  Thank you very much for your time.
>>
>> Have a nice day
>>
>> Marine
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code. Is
>> helpful is
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Jun 10 17:33:49 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 10 Jun 2018 21:03:49 +0530
Subject: [R] Efficient manipulation with list object
Message-ID: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>

Hi,

I have a list of length 10,000, and each element of that list is a matrix
with 3 columns and 2,000 rows.

Now when I tried to make a Matrix object with that list using
Reduce('rbind', list), my code is taking a considerable amount of time.

Is there any way to implement same above task in more efficient way?

Thanks,

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Sun Jun 10 18:10:27 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 10 Jun 2018 19:10:27 +0300
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>
References: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>
Message-ID: <CAGgJW77Jr172=W7uX-xi1kv3eDSbQpqitoYBes0qXycjiST_iw@mail.gmail.com>

Try this. Suppose your list of matrices is in the list locL.

nc <- 3

locL2 <- list()
for ( i in 1:length(locL )
  locL2[[i]] <- as.numeric(t(locL[[i]]))

bigMat <- matrix(unlist(locL3), ncol=nc, byrow=TRUE)

HTH,
Eric


On Sun, Jun 10, 2018 at 6:33 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I have a list of length 10,000, and each element of that list is a matrix
> with 3 columns and 2,000 rows.
>
> Now when I tried to make a Matrix object with that list using
> Reduce('rbind', list), my code is taking a considerable amount of time.
>
> Is there any way to implement same above task in more efficient way?
>
> Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Sun Jun 10 18:11:49 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Sun, 10 Jun 2018 19:11:49 +0300
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CAGgJW77Jr172=W7uX-xi1kv3eDSbQpqitoYBes0qXycjiST_iw@mail.gmail.com>
References: <CA+dpOJmd0UXpgcBFtFx=YdvcRRbjb+DeoejHEOChRrvsYEg+Kw@mail.gmail.com>
 <CAGgJW77Jr172=W7uX-xi1kv3eDSbQpqitoYBes0qXycjiST_iw@mail.gmail.com>
Message-ID: <CAGgJW74E_CacB7S0HYFZL4awWpWNRqhRvZ4PFZ4Qf_9MrWaE=A@mail.gmail.com>

Sorry typos

Try this. Suppose your list of matrices is in the list locL.

nc <- 3

locL2 <- list()
for ( i in 1:length(locL) )
  locL2[[i]] <- as.numeric( t( locL[[i]] ) )

bigMat <- matrix(unlist(locL2), ncol=nc, byrow=TRUE)

HTH,
Eric


On Sun, Jun 10, 2018 at 7:10 PM, Eric Berger <ericjberger at gmail.com> wrote:

> Try this. Suppose your list of matrices is in the list locL.
>
> nc <- 3
>
> locL2 <- list()
> for ( i in 1:length(locL )
>   locL2[[i]] <- as.numeric(t(locL[[i]]))
>
> bigMat <- matrix(unlist(locL3), ncol=nc, byrow=TRUE)
>
> HTH,
> Eric
>
>
> On Sun, Jun 10, 2018 at 6:33 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Hi,
>>
>> I have a list of length 10,000, and each element of that list is a matrix
>> with 3 columns and 2,000 rows.
>>
>> Now when I tried to make a Matrix object with that list using
>> Reduce('rbind', list), my code is taking a considerable amount of time.
>>
>> Is there any way to implement same above task in more efficient way?
>>
>> Thanks,
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sun Jun 10 19:15:23 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (ruipbarradas)
Date: Sun, 10 Jun 2018 18:15:23 +0100
Subject: [R] Efficient manipulation with list object
Message-ID: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>

Hello,
Instead of Reduce try do.call.
do.call ('rbind', list)
But with such a long list it will still take time.
Hope this helps,
Rui Barradas?


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Christofer Bogaso <bogaso.christofer at gmail.com> Data: 10/06/2018  16:33  (GMT+00:00) Para: r-help <r-help at r-project.org> Assunto: [R] Efficient manipulation with list object 
Hi,

I have a list of length 10,000, and each element of that list is a matrix
with 3 columns and 2,000 rows.

Now when I tried to make a Matrix object with that list using
Reduce('rbind', list), my code is taking a considerable amount of time.

Is there any way to implement same above task in more efficient way?

Thanks,

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sun Jun 10 21:20:45 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Mon, 11 Jun 2018 00:50:45 +0530
Subject: [R] Efficient manipulation with list object
In-Reply-To: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
References: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
Message-ID: <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>

Using do.call() reduces my calculation time significantly.

On Sun, Jun 10, 2018 at 10:45 PM ruipbarradas <ruipbarradas at sapo.pt> wrote:

> Hello,
>
> Instead of Reduce try do.call.
>
> do.call ('rbind', list)
>
> But with such a long list it will still take time.
>
> Hope this helps,
>
> Rui Barradas
>
>
>
> Enviado a partir do meu smartphone Samsung Galaxy.
> -------- Mensagem original --------
> De: Christofer Bogaso <bogaso.christofer at gmail.com>
> Data: 10/06/2018 16:33 (GMT+00:00)
> Para: r-help <r-help at r-project.org>
> Assunto: [R] Efficient manipulation with list object
>
> Hi,
>
> I have a list of length 10,000, and each element of that list is a matrix
> with 3 columns and 2,000 rows.
>
> Now when I tried to make a Matrix object with that list using
> Reduce('rbind', list), my code is taking a considerable amount of time.
>
> Is there any way to implement same above task in more efficient way?
>
> Thanks,
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From boennecd @end|ng |rom gm@||@com  Mon Jun 11 00:18:39 2018
From: boennecd @end|ng |rom gm@||@com (Benjamin Christoffersen)
Date: Mon, 11 Jun 2018 00:18:39 +0200
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>
References: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
 <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>
Message-ID: <CAHHSL8tjoKGnCyResRAr8SfwCzOg_xG_aM0tfhvpmrXn1RfyqA@mail.gmail.com>

You may be able to speed it up further by using `data.table`'s
`rbindlist` or a similar function as shown here
https://stackoverflow.com/a/49772719/5861244.

2018-06-10 21:20 GMT+02:00 Christofer Bogaso <bogaso.christofer at gmail.com>:
> Using do.call() reduces my calculation time significantly.
>
> On Sun, Jun 10, 2018 at 10:45 PM ruipbarradas <ruipbarradas at sapo.pt> wrote:
>
>> Hello,
>>
>> Instead of Reduce try do.call.
>>
>> do.call ('rbind', list)
>>
>> But with such a long list it will still take time.
>>
>> Hope this helps,
>>
>> Rui Barradas
>>
>>
>>
>> Enviado a partir do meu smartphone Samsung Galaxy.
>> -------- Mensagem original --------
>> De: Christofer Bogaso <bogaso.christofer at gmail.com>
>> Data: 10/06/2018 16:33 (GMT+00:00)
>> Para: r-help <r-help at r-project.org>
>> Assunto: [R] Efficient manipulation with list object
>>
>> Hi,
>>
>> I have a list of length 10,000, and each element of that list is a matrix
>> with 3 columns and 2,000 rows.
>>
>> Now when I tried to make a Matrix object with that list using
>> Reduce('rbind', list), my code is taking a considerable amount of time.
>>
>> Is there any way to implement same above task in more efficient way?
>>
>> Thanks,
>>
>> [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun 11 08:53:53 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 10 Jun 2018 20:53:53 -1000
Subject: [R] Efficient manipulation with list object
In-Reply-To: <CAHHSL8tjoKGnCyResRAr8SfwCzOg_xG_aM0tfhvpmrXn1RfyqA@mail.gmail.com>
References: <06s2mdp2n5a86ba9vhq11aln.1528650923340@email.android.com>
 <CA+dpOJ=qODcHNoSXUk1dMA=L9E_aK5cPPWS=AAG+WrwUxtE7dg@mail.gmail.com>
 <CAHHSL8tjoKGnCyResRAr8SfwCzOg_xG_aM0tfhvpmrXn1RfyqA@mail.gmail.com>
Message-ID: <6F8452A8-E3BB-49FD-8714-C0AB966F03DB@dcn.davis.ca.us>

The question was about matrices, not data frames or data tables. While faster than Reduce, the conversions still make it over twice as slow as Rui's answer.

On June 10, 2018 12:18:39 PM HST, Benjamin Christoffersen <boennecd at gmail.com> wrote:
>You may be able to speed it up further by using `data.table`'s
>`rbindlist` or a similar function as shown here
>https://stackoverflow.com/a/49772719/5861244.
>
>2018-06-10 21:20 GMT+02:00 Christofer Bogaso
><bogaso.christofer at gmail.com>:
>> Using do.call() reduces my calculation time significantly.
>>
>> On Sun, Jun 10, 2018 at 10:45 PM ruipbarradas <ruipbarradas at sapo.pt>
>wrote:
>>
>>> Hello,
>>>
>>> Instead of Reduce try do.call.
>>>
>>> do.call ('rbind', list)
>>>
>>> But with such a long list it will still take time.
>>>
>>> Hope this helps,
>>>
>>> Rui Barradas
>>>
>>>
>>>
>>> Enviado a partir do meu smartphone Samsung Galaxy.
>>> -------- Mensagem original --------
>>> De: Christofer Bogaso <bogaso.christofer at gmail.com>
>>> Data: 10/06/2018 16:33 (GMT+00:00)
>>> Para: r-help <r-help at r-project.org>
>>> Assunto: [R] Efficient manipulation with list object
>>>
>>> Hi,
>>>
>>> I have a list of length 10,000, and each element of that list is a
>matrix
>>> with 3 columns and 2,000 rows.
>>>
>>> Now when I tried to make a Matrix object with that list using
>>> Reduce('rbind', list), my code is taking a considerable amount of
>time.
>>>
>>> Is there any way to implement same above task in more efficient way?
>>>
>>> Thanks,
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From chettyvk @end|ng |rom gm@||@com  Mon Jun 11 20:26:32 2018
From: chettyvk @end|ng |rom gm@||@com (Veerappa Chetty)
Date: Mon, 11 Jun 2018 14:26:32 -0400
Subject: [R] Using MAP with a function returning a vector
Message-ID: <CAFpsATZTS-USTf2pGkWOJ8AcAtkx-JjgZOYneFe9jNvOB+rTww@mail.gmail.com>

Hi Experts,

The following codes work when the return value is a scalar.
 But I like to get the whole vector instead of one element of the vector x
using map  as a data frame instead getting one element of the vector using
of map_dbl.
In other words, I would like a data frame with one row for each iteration.
I would appreciate your help.
Thanks.
Chetty
__________________________________________
library(matlib)
v<-c(0.6,0.3,0.1,0.5,0.3,.2,0.1,0.2,0.8)
markov<-function(v){
nrow<-sqrt(length(v))
B<-matrix(v,nrow=nrow,byrow=TRUE)
A.sub<-t(B)[1:nrow-1,]-diag(nrow)[1:nrow-1,]
A<-rbind(A.sub,c(rep(1,nrow)))
b<-c(rep(0,nrow-1),1)
x<-solve(A,b)
x[2]
}
df<-data.frame(v.1=c(0.05,0.95,0.2,0.8),v.1=c(0.01,0.90,0.4,0.6))
df%>% map(~markov(v,v =.))
map_dbl(df,markov)
________________________________________

Professor of Family Medicine
Boston University
Tel: 617-414-6221, Fax:617-414-3345
emails: chettyvk at gmail.com,vchetty at bu.edu

	[[alternative HTML version deleted]]



From m@r@|@m@ck @end|ng |rom hotm@||@com  Mon Jun 11 21:35:15 2018
From: m@r@|@m@ck @end|ng |rom hotm@||@com (L... L...)
Date: Mon, 11 Jun 2018 19:35:15 +0000
Subject: [R] shaded area with polygon
Message-ID: <BY2PR20MB0453D2D4E8AED84B9EFC584B96780@BY2PR20MB0453.namprd20.prod.outlook.com>

Dear All, I know this is a trivial question .. but .. I want to shade the area between 2 curves. For example:

x <- 1:10

y <- 3*x^2 + 2*x + 7

z <- y + 100

plot(x, y,  type = 'l')

lines(x, z)

I can not understand polygon.

I tried

polygon(cbind(c(min(x), x, max(x)), c(min(y), z, max(y))), col="#00CC66")

But I do not return what I want.

Thank you very much

ML



	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Mon Jun 11 21:45:30 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 11 Jun 2018 12:45:30 -0700
Subject: [R] shaded area with polygon
In-Reply-To: <BY2PR20MB0453D2D4E8AED84B9EFC584B96780@BY2PR20MB0453.namprd20.prod.outlook.com>
References: <BY2PR20MB0453D2D4E8AED84B9EFC584B96780@BY2PR20MB0453.namprd20.prod.outlook.com>
Message-ID: <CAF8bMcYj8fMFNyaP-COLrAs7JRAWVPRsM_A5mh+9gjQH3kzqDA@mail.gmail.com>

Does
  polygon(c(x,rev(x)), c(y, rev(z)), col="orange")
do what you want?

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 11, 2018 at 12:35 PM, L... L... <mar.lamack at hotmail.com> wrote:

> Dear All, I know this is a trivial question .. but .. I want to shade the
> area between 2 curves. For example:
>
> x <- 1:10
>
> y <- 3*x^2 + 2*x + 7
>
> z <- y + 100
>
> plot(x, y,  type = 'l')
>
> lines(x, z)
>
> I can not understand polygon.
>
> I tried
>
> polygon(cbind(c(min(x), x, max(x)), c(min(y), z, max(y))), col="#00CC66")
>
> But I do not return what I want.
>
> Thank you very much
>
> ML
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Jun 11 23:15:44 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 11 Jun 2018 16:15:44 -0500
Subject: [R] Issues when Trying to Install Packages in R
Message-ID: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>

Dear friends,

I recently installed the following R version:

R version 3.5.0 (2018-04-23) -- "Joy in Playing"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

However, when  trying to install package lubridate (it also happened when I
tried to install the forecast package), the following error message popped
up:

Error: package or namespace load failed for ?lubridate? in loadNamespace(i,
c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
 there is no package called ?stringi?

Does anyone know how to solve this problem?

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Tue Jun 12 01:15:58 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 11 Jun 2018 19:15:58 -0400
Subject: [R] Issues when Trying to Install Packages in R
In-Reply-To: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>
References: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>
Message-ID: <fc3bf754-3d14-8a85-c80f-22a47c0cb085@gmail.com>

On 11/06/2018 5:15 PM, Paul Bernal wrote:
> Dear friends,
> 
> I recently installed the following R version:
> 
> R version 3.5.0 (2018-04-23) -- "Joy in Playing"
> Copyright (C) 2018 The R Foundation for Statistical Computing
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> 
> However, when  trying to install package lubridate (it also happened when I
> tried to install the forecast package), the following error message popped
> up:
> 
> Error: package or namespace load failed for ?lubridate? in loadNamespace(i,
> c(lib.loc, .libPaths()), versionCheck = vI[[i]]):
>   there is no package called ?stringi?
> 
> Does anyone know how to solve this problem?
> 

You need to install the stringi package first.  Normally that is done 
automatically, but sometimes suitable versions are not available, and it 
needs to be done manually.

Duncan Murdoch



From h@@@n@d|w@n @end|ng |rom gm@||@com  Tue Jun 12 01:26:18 2018
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Mon, 11 Jun 2018 16:26:18 -0700
Subject: [R] Issues when Trying to Install Packages in R
In-Reply-To: <fc3bf754-3d14-8a85-c80f-22a47c0cb085@gmail.com>
References: <CAMOcQfPeXd64nF_DUCAtH9BHbiFyyVdqUnX3obQcTJ6TZryyoA@mail.gmail.com>
 <fc3bf754-3d14-8a85-c80f-22a47c0cb085@gmail.com>
Message-ID: <CAP+bYWCoNZ9ijFCjOWH_OaBWPpDGEEtpCngverwpFB3vUkAPLA@mail.gmail.com>

Paul,
install.packages('lubridate', type='source',
repos='https://cran.rstudio.com') # worked for me

You should be able to copy/paste the line into an R session. -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Tue Jun 12 01:57:46 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Mon, 11 Jun 2018 18:57:46 -0500
Subject: [R] Changing selected columns to factor
Message-ID: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>

R-Help Forum

 

If I have a data frame consisting of say ten (10) variables
(A,B,C,D,E,F,G,H,I,J) and I want to change Variables 2,7,8,and 9 to factors
is there a command such that I can do it in one line or do I simply have to
convert each separately?

 

Jeff


	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Tue Jun 12 06:49:30 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 12 Jun 2018 14:49:30 +1000
Subject: [R] Changing selected columns to factor
In-Reply-To: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>
References: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>
Message-ID: <CA+8X3fVgD_SGHmRBnAB3Jjg1aJBntF6FEa7YajZd3McuyeSQSw@mail.gmail.com>

Hi Jeff,

jrdf<-data.frame(A=rnorm(10),B=rnorm(10),C=rnorm(10),
 D=rnorm(10),E=rnorm(10),F=rnorm(10),G=rnorm(10),
 H=rnorm(10),I=rnorm(10),J=rnorm(10))
for(i in c(2,7,8,9)) jrdf[,i]<-factor(jrdf[,i])
sapply(jrdf,"class")

Jim

On Tue, Jun 12, 2018 at 9:57 AM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> R-Help Forum
>
>
>
> If I have a data frame consisting of say ten (10) variables
> (A,B,C,D,E,F,G,H,I,J) and I want to change Variables 2,7,8,and 9 to factors
> is there a command such that I can do it in one line or do I simply have to
> convert each separately?
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From vc@vett @end|ng |rom @cr|pp@@edu  Tue Jun 12 01:39:58 2018
From: vc@vett @end|ng |rom @cr|pp@@edu (Valerie Cavett)
Date: Mon, 11 Jun 2018 23:39:58 +0000
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
Message-ID: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>

I?ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted?.  I?m happy to provide a sample binary file; even ones that are quite small (12 MB) generate this error. (I wasn?t sure whether a binary file attached to this email would trigger a spam filter.)

bin.read = file(files[i], "rb?)
datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little?)

Error: vector memory exhausted (limit reached?)


sessionInfo()
R version 3.5.0 (2018-04-23)
Platform: x86_64-apple-darwin15.6.0 (64-bit)
Running under: macOS Sierra 10.12.6


This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On?) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.

Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.

Any help, suggestions or workarounds are greatly appreciated!
Val

	[[alternative HTML version deleted]]



From iuke-tier@ey m@iii@g oii uiow@@edu  Tue Jun 12 11:26:37 2018
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Tue, 12 Jun 2018 04:26:37 -0500 (CDT)
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>
Message-ID: <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>

This item in NEWS explains the change:

     ? The environment variable R_MAX_VSIZE can now be used to specify
       the maximal vector heap size. On macOS, unless specified by this
       environment variable, the maximal vector heap size is set to the
       maximum of 16GB and the available physical memory. This is to
       avoid having the R process killed when macOS over-commits memory.

You can set R_MAX_VSIZE to a larger value but you should do some
experimenting to decide on a safe value for your system. Mac OS is
quite good at using virtual memory up to a point but then gets very
bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
be killed, so a setting of around 60GB _might_ be safe.

File size probably doesn't matter in your example since you are
setting a large value for n - I can't tell how large since you didn't
provide your value of 'hertz'.

Best,

luke

On Mon, 11 Jun 2018, Valerie Cavett wrote:

> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.  I???m happy to provide a sample binary file; even ones that are quite small (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>
> bin.read = file(files[i], "rb???)
> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>
> Error: vector memory exhausted (limit reached?)
>
>
> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS Sierra 10.12.6
>
>
> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>
> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>
> Any help, suggestions or workarounds are greatly appreciated!
> Val
>
> 	[[alternative HTML version deleted]]
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From B|||@Po||ng @end|ng |rom ze||@@com  Tue Jun 12 14:00:34 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 12 Jun 2018 12:00:34 +0000
Subject: [R] Help installing the finalfit package
Message-ID: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning. Over the weekend I worked through this tutorial on bloggers.com at home where I am on 3.5.5:

#Elegant regression results tables and plots in R: the finalfit package

https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/

Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.

The tutorial ran splendidly at home but here at office, not so much, big smile.

> devtools::install_github("ewenharrison/finalfit")
Downloading GitHub repo ewenharrison/finalfit at master
from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master
Installing finalfit
Installing 1 package: mice
trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
Content type 'application/zip' length 1490726 bytes (1.4 MB)
downloaded 1.4 MB

package 'mice' successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package 'mice'

The downloaded binary packages are in
        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
"C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
  "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests

ERROR: dependency 'mice' is not available for package 'finalfit'
* removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
In R CMD INSTALL
Installation failed: Command failed (1)

I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho'  etc... which I now load at the beginning of every session.

So my hunch is that maybe I need 3.5.5 for all this to work?

Also I have this error with the mice package:


> install.packages("mice")

trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'

Content type 'application/zip' length 1490726 bytes (1.4 MB)

downloaded 1.4 MB



package 'mice' successfully unpacked and MD5 sums checked

Warning in install.packages :

  cannot remove prior installation of package 'mice'



The downloaded binary packages are in

        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages

> library(mice)

Error in library(mice) : there is no package called 'mice'


I would appreciate any suggestion please.

Thank you

WHP

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From vc@vett @end|ng |rom @cr|pp@@edu  Tue Jun 12 14:25:58 2018
From: vc@vett @end|ng |rom @cr|pp@@edu (Valerie Cavett)
Date: Tue, 12 Jun 2018 12:25:58 +0000
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
Message-ID: <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>

Thanks so much for taking a look at this.


Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.


Next, I tried to set a value with
Sys.setenv("R_MAX_VSIZE" = 8e9)


When the system environment is checked again, there is now a value of?
	R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09


Unfortunately, when I try to read in a small binary file, I still encounter the same error.?


I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:


	hertz <- 6000
	bin.read = file("20180611_A4", "rb")
	datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")


datavals is a large integer with 6046880 elements, 23.1 Mb.


If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.


However, if I switch back to the newest R version (3.5.0), I encounter the same error:


	> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
	Error: vector memory exhausted (limit reached?)


I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.


From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
Sent: Tuesday, June 12, 2018 5:26:37 AM
To: Valerie Cavett
Cc: r-help at R-project.org
Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
? 

This item in NEWS explains the change:

???? ? The environment variable R_MAX_VSIZE can now be used to specify
?????? the maximal vector heap size. On macOS, unless specified by this
?????? environment variable, the maximal vector heap size is set to the
?????? maximum of 16GB and the available physical memory. This is to
?????? avoid having the R process killed when macOS over-commits memory.

You can set R_MAX_VSIZE to a larger value but you should do some
experimenting to decide on a safe value for your system. Mac OS is
quite good at using virtual memory up to a point but then gets very
bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
be killed, so a setting of around 60GB _might_ be safe.

File size probably doesn't matter in your example since you are
setting a large value for n - I can't tell how large since you didn't
provide your value of 'hertz'.

Best,

luke

On Mon, 11 Jun 2018, Valerie Cavett wrote:

> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>
> bin.read = file(files[i], "rb???)
> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>
> Error: vector memory exhausted (limit reached?)
>
>
> sessionInfo()
> R version 3.5.0 (2018-04-23)
> Platform: x86_64-apple-darwin15.6.0 (64-bit)
> Running under: macOS Sierra 10.12.6
>
>
> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>
> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>
> Any help, suggestions or workarounds are greatly appreciated!
> Val
>
>??????? [[alternative HTML version deleted]]
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa????????????????? Phone:???????????? 319-335-3386
Department of Statistics and??????? Fax:?????????????? 319-335-3017
??? Actuarial Science
241 Schaeffer Hall????????????????? email:?? luke-tierney at uiowa.edu
Iowa City, IA 52242???????????????? WWW:? http://www.stat.uiowa.edu    

From m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t  Tue Jun 12 15:32:57 2018
From: m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t (Massimo Bressan)
Date: Tue, 12 Jun 2018 15:32:57 +0200 (CEST)
Subject: [R] extract and re-arrange components of data frame
Message-ID: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>

# considering this data.frame as a reproducible example 
d<-data.frame(i=c(1,2,3), s=c('97,98,99','103,105', '118'), stringsAsFactors = FALSE) 
d 

#I need to get this final result 
r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118)) 
r 

#this is my attempt 

#number of components for each element (3) of the list 
#returned by strsplit 
n<-unlist(lapply(strsplit(d$s,','), length)) 

#extract components of all elements of the list 
s<-cbind(unlist(strsplit(d$s,','))) 

#replicate each element of i 
#by the number of components of each element of the list 
i<-rep(d$i, n) 
i 

#compose final result 
r_final<-data.frame(i,s, stringsAsFactors = FALSE) 
r_final 

#I'm not much satisfied by the approach, it seems to me a bit clumsy... 

#any help for improving it? 
#thanks 
#a novice 



	[[alternative HTML version deleted]]



From iuke-tier@ey m@iii@g oii uiow@@edu  Tue Jun 12 16:14:07 2018
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Tue, 12 Jun 2018 09:14:07 -0500 (CDT)
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
 <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
Message-ID: <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>

The environment variable R_MAX_VSIZE is read at start-up so need to be
set outside R. If you are starting R from a shell you can use

     env R_MAX_VSIZE=700Gb R

If you use a GUI you might need to set the variable in another
way.

Here is a reproducible version of your example:

     hertz <- 6000
     binfile <- tempfile()
     writeBin(1L, binfile, size = 2)
     v <- readBin(binfile, integer(), size = 2, n = 8*hertz*60*60000)
     unlink(binfile)

With the limit raised to 700Gb or more this will work in R 3.5.0
but you lose the protection of the lower default setting. You need a
value that high because your 'n' value is asking readBin to allocate a
buffer 643.7 Gb. Mac OS lets you allocate this much address space, as
long as you don't try to use all of it (this is memory
overcommitment). Running this example on a Linux system with 128Gb of
memory produces

     Error: cannot allocate vector of size 643.7 Gb

I suspect this will fail on pretty much any Windows system as well.

My recommendation would be to figure out a lower upper bound on the
number of elements to read, maybe using file.size, and use that for 'n'
in your readBin call. That will allow your code to be more portable
and avoid the risks of removing the allocation protection.

Best,

luke

On Tue, 12 Jun 2018, Valerie Cavett wrote:

> Thanks so much for taking a look at this.
> 

> Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.
> 

> Next, I tried to set a value with
> Sys.setenv("R_MAX_VSIZE" = 8e9)
>
>
> When the system environment is checked again, there is now a value of
?? 	R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09
>
>
> Unfortunately, when I try to read in a small binary file, I still encounter the same error.
??
>
> I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:
>
>
> 	hertz <- 6000
> 	bin.read = file("20180611_A4", "rb")
> 	datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>
>
> datavals is a large integer with 6046880 elements, 23.1 Mb.
>
>
> If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.
>
>
> However, if I switch back to the newest R version (3.5.0), I encounter the same error:
>
>
> 	> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
> 	Error: vector memory exhausted (limit reached?)
>
>
> I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.
>
>
> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Sent: Tuesday, June 12, 2018 5:26:37 AM
> To: Valerie Cavett
> Cc: r-help at R-project.org
> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
> 
??
> This item in NEWS explains the change:
>
> ???? ? The environment variable R_MAX_VSIZE can now be used to specify
> ?????? the maximal vector heap size. On macOS, unless specified by this
> ?????? environment variable, the maximal vector heap size is set to the
> ?????? maximum of 16GB and the available physical memory. This is to
> ?????? avoid having the R process killed when macOS over-commits memory.
>
> You can set R_MAX_VSIZE to a larger value but you should do some
> experimenting to decide on a safe value for your system. Mac OS is
> quite good at using virtual memory up to a point but then gets very
> bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
> be killed, so a setting of around 60GB _might_ be safe.
>
> File size probably doesn't matter in your example since you are
> setting a large value for n - I can't tell how large since you didn't
> provide your value of 'hertz'.
>
> Best,
>
> luke
>
> On Mon, 11 Jun 2018, Valerie Cavett wrote:
>
>> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>>
>> bin.read = file(files[i], "rb???)
>> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>>
>> Error: vector memory exhausted (limit reached?)
>>
>>
>> sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>> Running under: macOS Sierra 10.12.6
>>
>>
>> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>>
>> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>>
>> Any help, suggestions or workarounds are greatly appreciated!
>> Val
>>
>> ??????? [[alternative HTML version deleted]]
>>
>>
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun 12 16:42:18 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 12 Jun 2018 07:42:18 -0700
Subject: [R] extract and re-arrange components of data frame
In-Reply-To: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
References: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <CAGxFJbThzkjKHsjnMWhArOu6YPom=XBQU2EM_P9EcAybUKFaXw@mail.gmail.com>

You mean like this?

> s.new <-with(d, as.numeric(unlist(strsplit(s,","))))

> s.new <- cut(s.new,breaks = c(0,100,110,200),lab = d$i)

> s.new
[1] 1 1 1 2 2 3
Levels: 1 2 3

(Obviously, this could be a one-liner)

See ?cut

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jun 12, 2018 at 6:32 AM, Massimo Bressan <
massimo.bressan at arpa.veneto.it> wrote:

> # considering this data.frame as a reproducible example
> d<-data.frame(i=c(1,2,3), s=c('97,98,99','103,105', '118'),
> stringsAsFactors = FALSE)
> d
>
> #I need to get this final result
> r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118))
> r
>
> #this is my attempt
>
> #number of components for each element (3) of the list
> #returned by strsplit
> n<-unlist(lapply(strsplit(d$s,','), length))
>
> #extract components of all elements of the list
> s<-cbind(unlist(strsplit(d$s,',')))
>
> #replicate each element of i
> #by the number of components of each element of the list
> i<-rep(d$i, n)
> i
>
> #compose final result
> r_final<-data.frame(i,s, stringsAsFactors = FALSE)
> r_final
>
> #I'm not much satisfied by the approach, it seems to me a bit clumsy...
>
> #any help for improving it?
> #thanks
> #a novice
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From S@E|||@on @end|ng |rom LGCGroup@com  Tue Jun 12 17:13:01 2018
From: S@E|||@on @end|ng |rom LGCGroup@com (S Ellison)
Date: Tue, 12 Jun 2018 15:13:01 +0000
Subject: [R] extract and re-arrange components of data frame
In-Reply-To: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
References: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
Message-ID: <6f7a59eadc674b2582fc3f6e983f8d56@GBDCVPEXC08.corp.lgc-group.com>

> #I need to get this final result
> r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118))

Nothing magic to suggest.

But maybe:

list.s <- strsplit(d$s,",")
r <- data.frame(i=rep(d$i, times=sapply(list.s, length)), s=unlist(list.s), stringsAsFactors=FALSE )

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}



From m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t  Tue Jun 12 17:07:27 2018
From: m@@@|mo@bre@@@n @end|ng |rom @rp@@veneto@|t (Massimo Bressan)
Date: Tue, 12 Jun 2018 17:07:27 +0200 (CEST)
Subject: [R] extract and re-arrange components of data frame
In-Reply-To: <CAGxFJbThzkjKHsjnMWhArOu6YPom=XBQU2EM_P9EcAybUKFaXw@mail.gmail.com>
References: <1289005120.10352174.1528810377307.JavaMail.zimbra@arpa.veneto.it>
 <CAGxFJbThzkjKHsjnMWhArOu6YPom=XBQU2EM_P9EcAybUKFaXw@mail.gmail.com>
Message-ID: <102419610.10371312.1528816047729.JavaMail.zimbra@arpa.veneto.it>

thank you for your reply 

well, you are resorting to a supposed order of i which is not necessary the case, and in fact is not in mine... 

consider this example, please 

d<-data.frame(i=c(8,12,3), s=c('97,918,19','103,1205', '418'), stringsAsFactors = FALSE) 
d 


Da: "Bert Gunter" <bgunter.4567 at gmail.com> 
A: "Massimo Bressan" <massimo.bressan at arpa.veneto.it> 
Cc: "r-help" <R-help at r-project.org> 
Inviato: Marted?, 12 giugno 2018 16:42:18 
Oggetto: Re: [R] extract and re-arrange components of data frame 

You mean like this? 

> s.new <-with(d, as.numeric(unlist(strsplit(s,",")))) 

> s.new <- cut(s.new,breaks = c(0,100,110,200),lab = d$i) 

> s.new 
[1] 1 1 1 2 2 3 
Levels: 1 2 3 

(Obviously, this could be a one-liner) 

See ?cut 

Cheers, 
Bert 





Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Tue, Jun 12, 2018 at 6:32 AM, Massimo Bressan < massimo.bressan at arpa.veneto.it > wrote: 


# considering this data.frame as a reproducible example 
d<-data.frame(i=c(1,2,3), s=c('97,98,99','103,105', '118'), stringsAsFactors = FALSE) 
d 

#I need to get this final result 
r<-data.frame(i=c(1,1,1,2,2,3), s=c(97, 98, 99, 103, 105, 118)) 
r 

#this is my attempt 

#number of components for each element (3) of the list 
#returned by strsplit 
n<-unlist(lapply(strsplit(d$s,','), length)) 

#extract components of all elements of the list 
s<-cbind(unlist(strsplit(d$s,','))) 

#replicate each element of i 
#by the number of components of each element of the list 
i<-rep(d$i, n) 
i 

#compose final result 
r_final<-data.frame(i,s, stringsAsFactors = FALSE) 
r_final 

#I'm not much satisfied by the approach, it seems to me a bit clumsy... 

#any help for improving it? 
#thanks 
#a novice 



[[alternative HTML version deleted]] 

______________________________________________ 
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
https://stat.ethz.ch/mailman/listinfo/r-help 
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html 
and provide commented, minimal, self-contained, reproducible code. 





	[[alternative HTML version deleted]]



From weter|ng @end|ng |rom pum@edu@p|  Tue Jun 12 14:05:31 2018
From: weter|ng @end|ng |rom pum@edu@p| (Thierry van de Wetering)
Date: Tue, 12 Jun 2018 14:05:31 +0200
Subject: [R] SNPassoc association and weights
Message-ID: <51bab0d8-f831-41c1-5054-f64b87f4ab66@pum.edu.pl>

Dear Reader,

Please can you tell me how to use weights with the SNPassoc package 
function association.

association(NEB~recessive(rs178012)*as.factor(GENDER), weights = 
as.factor(WAGA), data=dat2SNP)

SNP: recessive(rs178012 adjusted by: Interaction --------------------- 1 
dif lower upper 2 dif lower upper G/G-A/G 1485 1.451 0.03814 0.0000 NA 
NA 1702 1.854 0.03879 0.4025 0.2946 0.5105 A/A 11 1.091 0.45636 -0.3603 
-1.28 0.5599 20 1.900 0.62786 0.4488 -0.2356 1.1333 p interaction: 0.48707


In this example I want to know if there is an interaction between GENDER 
and the SNP in assocation with NEB, weighted for WAGA. Removal of the 
weights argument gives exactly the same p.value.

association(NEB~recessive(rs178012)*as.factor(GENDER), data=dat2SNP)

SNP: recessive(rs178012 adjusted by: Interaction --------------------- 1 
dif lower upper 2 dif lower upper G/G-A/G 1485 1.451 0.03814 0.0000 NA 
NA 1702 1.854 0.03879 0.4025 0.2946 0.5105 A/A 11 1.091 0.45636 -0.3603 
-1.28 0.5599 20 1.900 0.62786 0.4488 -0.2356 1.1333 p interaction: 0.48707



Changing the model from recessive into for example dominant gives me 
other p interactions and p.values, but still the weighting is not giving 
any differences.

Many thanks in advance.
Your sincerely

-- 
Thierry


	[[alternative HTML version deleted]]



From vc@vett @end|ng |rom @cr|pp@@edu  Tue Jun 12 21:02:49 2018
From: vc@vett @end|ng |rom @cr|pp@@edu (Valerie Cavett)
Date: Tue, 12 Jun 2018 19:02:49 +0000
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
 <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>
Message-ID: <BN6PR11MB19867C53B6D61E8F61791448BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>

Ah - I see the problem - thanks so much for the clarification!

Just in case anyone else is using Rstudio on a mac and runs into this issue, I ended up following the instructions from
http://btibert3.github.io/2015/12/08/Environment-Variables-in-Rstudio-on-Mac.html

to add the following line to the .Renviron file:
R_MAX_VSIZE=700Gb

On restart (R 3.5.0), this did the trick and the files read normally.

Thanks again for all the assistance!
Val




From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
Sent: Tuesday, June 12, 2018 10:14 AM
To: Valerie Cavett
Cc: r-help at R-project.org
Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
? 

The environment variable R_MAX_VSIZE is read at start-up so need to be
set outside R. If you are starting R from a shell you can use

???? env R_MAX_VSIZE=700Gb R

If you use a GUI you might need to set the variable in another
way.

Here is a reproducible version of your example:

???? hertz <- 6000
???? binfile <- tempfile()
???? writeBin(1L, binfile, size = 2)
???? v <- readBin(binfile, integer(), size = 2, n = 8*hertz*60*60000)
???? unlink(binfile)

With the limit raised to 700Gb or more this will work in R 3.5.0
but you lose the protection of the lower default setting. You need a
value that high because your 'n' value is asking readBin to allocate a
buffer 643.7 Gb. Mac OS lets you allocate this much address space, as
long as you don't try to use all of it (this is memory
overcommitment). Running this example on a Linux system with 128Gb of
memory produces

???? Error: cannot allocate vector of size 643.7 Gb

I suspect this will fail on pretty much any Windows system as well.

My recommendation would be to figure out a lower upper bound on the
number of elements to read, maybe using file.size, and use that for 'n'
in your readBin call. That will allow your code to be more portable
and avoid the risks of removing the allocation protection.

Best,

luke

On Tue, 12 Jun 2018, Valerie Cavett wrote:

> Thanks so much for taking a look at this.
> 

> Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.
> 

> Next, I tried to set a value with
> Sys.setenv("R_MAX_VSIZE" = 8e9)
>
>
> When the system environment is checked again, there is now a value of
???????? R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09
>
>
> Unfortunately, when I try to read in a small binary file, I still encounter the same error.
??
>
> I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:
>
>
>??????? hertz <- 6000
>??????? bin.read = file("20180611_A4", "rb")
>??????? datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>
>
> datavals is a large integer with 6046880 elements, 23.1 Mb.
>
>
> If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.
>
>
> However, if I switch back to the newest R version (3.5.0), I encounter the same error:
>
>
>??????? > datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>??????? Error: vector memory exhausted (limit reached?)
>
>
> I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.
>
>
> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Sent: Tuesday, June 12, 2018 5:26:37 AM
> To: Valerie Cavett
> Cc: r-help at R-project.org
> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
> 
??
> This item in NEWS explains the change:
>
> ???? ? The environment variable R_MAX_VSIZE can now be used to specify
> ?????? the maximal vector heap size. On macOS, unless specified by this
> ?????? environment variable, the maximal vector heap size is set to the
> ?????? maximum of 16GB and the available physical memory. This is to
> ?????? avoid having the R process killed when macOS over-commits memory.
>
> You can set R_MAX_VSIZE to a larger value but you should do some
> experimenting to decide on a safe value for your system. Mac OS is
> quite good at using virtual memory up to a point but then gets very
> bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
> be killed, so a setting of around 60GB _might_ be safe.
>
> File size probably doesn't matter in your example since you are
> setting a large value for n - I can't tell how large since you didn't
> provide your value of 'hertz'.
>
> Best,
>
> luke
>
> On Mon, 11 Jun 2018, Valerie Cavett wrote:
>
>> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small?  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>>
>> bin.read = file(files[i], "rb???)
>> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>>
>> Error: vector memory exhausted (limit reached?)
>>
>>
>> sessionInfo()
>> R version 3.5.0 (2018-04-23)
>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>> Running under: macOS Sierra 10.12.6
>>
>>
>> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>>
>> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>>
>> Any help, suggestions or workarounds are greatly appreciated!
>> Val
>>
>> ??????? [[alternative HTML version deleted]]
>>
>>
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa????????????????? Phone:???????????? 319-335-3386
Department of Statistics and??????? Fax:?????????????? 319-335-3017
??? Actuarial Science
241 Schaeffer Hall????????????????? email:?? luke-tierney at uiowa.edu
Iowa City, IA 52242???????????????? WWW:? http://www.stat.uiowa.edu    

From iuke-tier@ey m@iii@g oii uiow@@edu  Tue Jun 12 23:06:09 2018
From: iuke-tier@ey m@iii@g oii uiow@@edu (iuke-tier@ey m@iii@g oii uiow@@edu)
Date: Tue, 12 Jun 2018 16:06:09 -0500 (CDT)
Subject: [R] R 3.5.0, vector memory exhausted error on readBin
In-Reply-To: <BN6PR11MB19867C53B6D61E8F61791448BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
References: <BN6PR11MB198687BB1D69FFCD0347D3AABF780@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120413280.1839@lukes-macbook-air.local>
 <BN6PR11MB1986C85538AA97574B1C7C30BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>,
 <alpine.OSX.2.21.1806120850240.1839@lukes-macbook-air.local>
 <BN6PR11MB19867C53B6D61E8F61791448BF7F0@BN6PR11MB1986.namprd11.prod.outlook.com>
Message-ID: <alpine.OSX.2.21.1806121558570.1839@lukes-macbook-air.local>

On Tue, 12 Jun 2018, Valerie Cavett wrote:

> Ah - I see the problem - thanks so much for the clarification!
>
> Just in case anyone else is using Rstudio on a mac and runs into this issue, I ended up following the instructions from
> http://btibert3.github.io/2015/12/08/Environment-Variables-in-Rstudio-on-Mac.html
>
> to add the following line to the .Renviron file:
> R_MAX_VSIZE=700Gb
>

And, also for the record, I advise not to do this. It may be an
adequate quick fix for your setting for now, but it loses the
protection the default provides, and it means your code will only work
on a Linux or Windows system with well above half a terabyte of
memory.

Best,

luke

> On restart (R 3.5.0), this did the trick and the files read normally.
>
> Thanks again for all the assistance!
> Val
>
>
>
>
> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
> Sent: Tuesday, June 12, 2018 10:14 AM
> To: Valerie Cavett
> Cc: r-help at R-project.org
> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
> 
??
> The environment variable R_MAX_VSIZE is read at start-up so need to be
> set outside R. If you are starting R from a shell you can use
>
> ???? env R_MAX_VSIZE=700Gb R
>
> If you use a GUI you might need to set the variable in another
> way.
>
> Here is a reproducible version of your example:
>
> ???? hertz <- 6000
> ???? binfile <- tempfile()
> ???? writeBin(1L, binfile, size = 2)
> ???? v <- readBin(binfile, integer(), size = 2, n = 8*hertz*60*60000)
> ???? unlink(binfile)
>
> With the limit raised to 700Gb or more this will work in R 3.5.0
> but you lose the protection of the lower default setting. You need a
> value that high because your 'n' value is asking readBin to allocate a
> buffer 643.7 Gb. Mac OS lets you allocate this much address space, as
> long as you don't try to use all of it (this is memory
> overcommitment). Running this example on a Linux system with 128Gb of
> memory produces
>
> ???? Error: cannot allocate vector of size 643.7 Gb
>
> I suspect this will fail on pretty much any Windows system as well.
>
> My recommendation would be to figure out a lower upper bound on the
> number of elements to read, maybe using file.size, and use that for 'n'
> in your readBin call. That will allow your code to be more portable
> and avoid the risks of removing the allocation protection.
>
> Best,
>
> luke
>
> On Tue, 12 Jun 2018, Valerie Cavett wrote:
>
>> Thanks so much for taking a look at this.
>> 

>> Before setting a new value, I opened a fresh session of R and checked to see whether there was any value set for R_MAX_VSIZE. There was not, so we'll assume the default as you described.
>> 

>> Next, I tried to set a value with
>> Sys.setenv("R_MAX_VSIZE" = 8e9)
>>
>>
>> When the system environment is checked again, there is now a value of
> ???????? R_MAX_SIZE? ? ? ? ? ? ? ? ? ? ? ? ? 8e+09
>>
>>
>> Unfortunately, when I try to read in a small binary file, I still encounter the same error.
> ??
>>
>> I restored R 3.3 and checked the system environment to confirm that there was no R_MAX_SIZE configured in the startup file, then tested readBin as follows:
>>
>>
>> ??????? hertz <- 6000
>> ??????? bin.read = file("20180611_A4", "rb")
>> ??????? datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>>
>>
>> datavals is a large integer with 6046880 elements, 23.1 Mb.
>>
>>
>> If I then set the R_MAX_SIZE to 8e9, this also works just fine since the file is not really that large.
>>
>>
>> However, if I switch back to the newest R version (3.5.0), I encounter the same error:
>>
>>
>> ??????? > datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little")
>> ??????? Error: vector memory exhausted (limit reached?)
>>
>>
>> I?m at a loss for why this is an issue (same machine) in R 3.5.0, but not in 3.3.2 or 3.4.4. If you have any further suggestions, I?d greatly appreciate them.
>>
>>
>> From: luke-tierney at uiowa.edu <luke-tierney at uiowa.edu>
>> Sent: Tuesday, June 12, 2018 5:26:37 AM
>> To: Valerie Cavett
>> Cc: r-help at R-project.org
>> Subject: Re: [R] R 3.5.0, vector memory exhausted error on readBin
>>
> ??
>> This item in NEWS explains the change:
>>
>> ???? ? The environment variable R_MAX_VSIZE can now be used to specify
>> ?????? the maximal vector heap size. On macOS, unless specified by this
>> ?????? environment variable, the maximal vector heap size is set to the
>> ?????? maximum of 16GB and the available physical memory. This is to
>> ?????? avoid having the R process killed when macOS over-commits memory.
>>
>> You can set R_MAX_VSIZE to a larger value but you should do some
>> experimenting to decide on a safe value for your system. Mac OS is
>> quite good at using virtual memory up to a point but then gets very
>> bad. For my 4 GB mac numeric(8e9) works but numeric(9e9) causes R to
>> be killed, so a setting of around 60GB _might_ be safe.
>>
>> File size probably doesn't matter in your example since you are
>> setting a large value for n - I can't tell how large since you didn't
>> provide your value of 'hertz'.
>>
>> Best,
>>
>> luke
>>
>> On Mon, 11 Jun 2018, Valerie Cavett wrote:
>>
>>> I???ve been reading in binary data collected via LabView for a project, and after upgrading to R 3.5.0, the code returns an error indicating that the 'vector memory is exhausted???.? I???m happy to provide a sample binary file; even ones that are quite small?  (12 MB) generate this error. (I wasn???t sure whether a binary file attached to this email would trigger a spam filter.)
>>>
>>> bin.read = file(files[i], "rb???)
>>> datavals = readBin(bin.read, integer(), size = 2, n = 8*hertz*60*60000, endian = "little???)
>>>
>>> Error: vector memory exhausted (limit reached?)
>>>
>>>
>>> sessionInfo()
>>> R version 3.5.0 (2018-04-23)
>>> Platform: x86_64-apple-darwin15.6.0 (64-bit)
>>> Running under: macOS Sierra 10.12.6
>>>
>>>
>>> This does not happen in R 3.4 (R version 3.4.4 (2018-03-15) -- "Someone to Lean On???) - the vector is created and populated by the binary file values without issue, even at a 1GB binary file size.
>>>
>>> Other files that are read in as csv files, even at 1GB, load correctly to 3.5, so I assume that this is a function of a vector being explicitly defined/changed in some way from 3.4 to 3.5.
>>>
>>> Any help, suggestions or workarounds are greatly appreciated!
>>> Val
>>>
>>> ??????? [[alternative HTML version deleted]]
>>>
>>>
>>
>>
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Jun 13 04:19:06 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 12 Jun 2018 21:19:06 -0500
Subject: [R] Changing selected columns to factor
In-Reply-To: <CA+8X3fVgD_SGHmRBnAB3Jjg1aJBntF6FEa7YajZd3McuyeSQSw@mail.gmail.com>
References: <000001d401df$ff8889a0$fe999ce0$@sbcglobal.net>
 <CA+8X3fVgD_SGHmRBnAB3Jjg1aJBntF6FEa7YajZd3McuyeSQSw@mail.gmail.com>
Message-ID: <000001d402bc$e7f33550$b7d99ff0$@sbcglobal.net>

Well that?s easy enough - thank you

-----Original Message-----
From: Jim Lemon <drjimlemon at gmail.com> 
Sent: Monday, June 11, 2018 11:50 PM
To: Jeff Reichman <reichmanj at sbcglobal.net>
Cc: r-help mailing list <r-help at r-project.org>
Subject: Re: [R] Changing selected columns to factor

Hi Jeff,

jrdf<-data.frame(A=rnorm(10),B=rnorm(10),C=rnorm(10),
 D=rnorm(10),E=rnorm(10),F=rnorm(10),G=rnorm(10),
 H=rnorm(10),I=rnorm(10),J=rnorm(10))
for(i in c(2,7,8,9)) jrdf[,i]<-factor(jrdf[,i])
sapply(jrdf,"class")

Jim

On Tue, Jun 12, 2018 at 9:57 AM, Jeff Reichman <reichmanj at sbcglobal.net> wrote:
> R-Help Forum
>
>
>
> If I have a data frame consisting of say ten (10) variables
> (A,B,C,D,E,F,G,H,I,J) and I want to change Variables 2,7,8,and 9 to 
> factors is there a command such that I can do it in one line or do I 
> simply have to convert each separately?
>
>
>
> Jeff
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see 
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun 13 06:47:35 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Tue, 12 Jun 2018 21:47:35 -0700
Subject: [R] Help installing the finalfit package
In-Reply-To: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>


> On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> Good morning. Over the weekend I worked through this tutorial on bloggers.com at home where I am on 3.5.5:
> 
> #Elegant regression results tables and plots in R: the finalfit package
> 
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
> 
> Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
> 
> The tutorial ran splendidly at home but here at office, not so much, big smile.
> 
>> devtools::install_github("ewenharrison/finalfit")
> Downloading GitHub repo ewenharrison/finalfit at master
> from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master
> Installing finalfit
> Installing 1 package: mice
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
> downloaded 1.4 MB
> 
> package 'mice' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'mice'

Generally the first task is to address the first error, which in this case appears to be a windows permission issue.

-- 
David


> 
> The downloaded binary packages are in
>        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL  \
>  "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
> 
> ERROR: dependency 'mice' is not available for package 'finalfit'
> * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> In R CMD INSTALL
> Installation failed: Command failed (1)
> 
> I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho'  etc... which I now load at the beginning of every session.
> 
> So my hunch is that maybe I need 3.5.5 for all this to work?
> 
> Also I have this error with the mice package:
> 
> 
>> install.packages("mice")
> 
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> 
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
> 
> downloaded 1.4 MB
> 
> 
> 
> package 'mice' successfully unpacked and MD5 sums checked
> 
> Warning in install.packages :
> 
>  cannot remove prior installation of package 'mice'
> 
> 
> 
> The downloaded binary packages are in
> 
>        C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> 
>> library(mice)
> 
> Error in library(mice) : there is no package called 'mice'
> 
> 
> I would appreciate any suggestion please.
> 
> Thank you
> 
> WHP
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From STuck @end|ng |rom nz@uper|und@co@nz  Wed Jun 13 04:33:41 2018
From: STuck @end|ng |rom nz@uper|und@co@nz (Sam Tuck)
Date: Wed, 13 Jun 2018 02:33:41 +0000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
Message-ID: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>

Hi All,
          I am new to R and am wondering if there is a way to pass arguments between rscripts.  I have this working but have had to create a C# shell calling the scripts in sequence via windows scripting which enables command line arguments to get the necessary interaction.  

I'm wondering if I'm using an outdated program construction technique - I create r files like I would programme functions or reoccurring code snippets in C.  It may be that r was not designed to create lots of little r script modules that interact via a master script? 

Ideally I'd like to call r scripts from other r scripts and have all the variables still in memory: For example

I've been using RStudio Version 1.1.447 to programme and regression test my individual scripts,. 

Script Arg Script.R
{
# We are going to pass arguments into this script
arguments <- commandArgs(trailingOnly = TRUE)
#arguments[1] is double
#arguments[2] is double
#arguments[3] is double.
if(length(arguments) <3) 
{
  stop("Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter")
}
TotalDeviation <- as.numeric(arguments[1])/100
IndividualDeviation <- as.numeric(arguments[2])/100
RecenterPeriods <- as.numeric(arguments[3])
# We then manipulate some objects based on these inputs, but for this test we will output them to a file. 
fileConn<-file("output.txt")
writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods), fileConn)
close(fileConn)
}
Script RunningScript.R
{
Arg Script.R 0.6 0.4 132
}

To which I get
Error: unexpected symbol in " Arg Script.R"

When I use the script RunningScript.R
{
system(paste("Arg Script.R", 0.8, 0.4, 132))
}
Nothing occurs (there is no output file created, but also no error)

When I use RunningScript.R
{
commandArgs <- c(0.6,0.4,132)
source("Arg Script.R')
}
I don't get any args passed into the file.  Instead getting the error 
Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter

Thanks

Sam Tuck 



From @k@h@y_e4 @end|ng |rom hotm@||@com  Wed Jun 13 07:36:40 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Wed, 13 Jun 2018 05:36:40 +0000
Subject: [R] on execution time of a function...
Message-ID: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

I ran  a function in R three days ago and the execution time was about 4 minutes. I ran the same function yesterday and the execution time was more than 6:50 minutes(I aborted the function after that time).

I read in the Internet that this is possible. I also came to know that software or hardware interrupts are the main reasons.

How do you know whether the delay was caused by interrupts? Which hardware or software triggered the interrupts? In general, how to know the exact cause of the delay in execution in R? Are there any packages for these analyses?

Very many thanks for your time and effort....

yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From Sh@kee|@Su|em@n @end|ng |rom phe@gov@uk  Wed Jun 13 09:05:55 2018
From: Sh@kee|@Su|em@n @end|ng |rom phe@gov@uk (Shakeel Suleman)
Date: Wed, 13 Jun 2018 07:05:55 +0000
Subject: [R] Tables in Rmarkdown Word
Message-ID: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>

I am relatively new to R and was wondering if someone could advise me on presenting tables in R Markdown for Word. I would like to present a simple table of counts, with column 1 representing name of an organisation (and last row called "All organisations") and another four columns representing the most recent four week period (e.g. week 21, 22, 23, 24) and a final total column, as illustrated below. The actual data is just counts (e.g. 4, 5, 8, widgets produced, number of people off sick etc).

My question is: can this be done to a publication quality standard. I have tried Pander, but that adds "Sum" instead of All Organisations and 4 Week Total and doesn't look particularly good.



Week



20

21

22

23

4 week total

Organisation

6

6

1

1

14

ABC

2

4

1

5

12

DCE

0

5

1

5

11

EFG

3

6

3

5

17

HIJ

1

8

3

2

14

All Organizations

12

29

9

18

68



Kind regards,

Shakeel


**************************************************************************
The information contained in the EMail and any attachments is confidential and intended solely and for the attention and use of the named addressee(s). It may not be disclosed to any other person without the express authority of Public Health England, or the intended recipient, or both. If you are not the intended recipient, you must not disclose, copy, distribute or retain this message or any part of it. This footnote also confirms that this EMail has been swept for computer viruses by Symantec.Cloud, but please re-sweep any attachments before opening or saving. http://www.gov.uk/PHE
**************************************************************************
	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Wed Jun 13 09:09:21 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Wed, 13 Jun 2018 10:09:21 +0300
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
Message-ID: <CAGgJW756Hm1EPa_Bvp8YoqjkjZbvU_NRNPmxOOZDZpUcu-1nTg@mail.gmail.com>

Hi Sam,
I use the littler package for scripting. You may find it meets your needs.

https://github.com/eddelbuettel/littler

HTH,
Eric


On Wed, Jun 13, 2018 at 5:33 AM, Sam Tuck <STuck at nzsuperfund.co.nz> wrote:

> Hi All,
>           I am new to R and am wondering if there is a way to pass
> arguments between rscripts.  I have this working but have had to create a
> C# shell calling the scripts in sequence via windows scripting which
> enables command line arguments to get the necessary interaction.
>
> I'm wondering if I'm using an outdated program construction technique - I
> create r files like I would programme functions or reoccurring code
> snippets in C.  It may be that r was not designed to create lots of little
> r script modules that interact via a master script?
>
> Ideally I'd like to call r scripts from other r scripts and have all the
> variables still in memory: For example
>
> I've been using RStudio Version 1.1.447 to programme and regression test
> my individual scripts,.
>
> Script Arg Script.R
> {
> # We are going to pass arguments into this script
> arguments <- commandArgs(trailingOnly = TRUE)
> #arguments[1] is double
> #arguments[2] is double
> #arguments[3] is double.
> if(length(arguments) <3)
> {
>   stop("Not enough arguments, please supply 3, [% dbl}total deviation, [%
> dbl] individual deviation, [int] periods before recenter")
> }
> TotalDeviation <- as.numeric(arguments[1])/100
> IndividualDeviation <- as.numeric(arguments[2])/100
> RecenterPeriods <- as.numeric(arguments[3])
> # We then manipulate some objects based on these inputs, but for this test
> we will output them to a file.
> fileConn<-file("output.txt")
> writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
> fileConn)
> close(fileConn)
> }
> Script RunningScript.R
> {
> Arg Script.R 0.6 0.4 132
> }
>
> To which I get
> Error: unexpected symbol in " Arg Script.R"
>
> When I use the script RunningScript.R
> {
> system(paste("Arg Script.R", 0.8, 0.4, 132))
> }
> Nothing occurs (there is no output file created, but also no error)
>
> When I use RunningScript.R
> {
> commandArgs <- c(0.6,0.4,132)
> source("Arg Script.R')
> }
> I don't get any args passed into the file.  Instead getting the error
> Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl]
> individual deviation, [int] periods before recenter
>
> Thanks
>
> Sam Tuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 13 09:53:57 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 12 Jun 2018 21:53:57 -1000
Subject: [R] on execution time of a function...
In-Reply-To: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>

Wow, you can find almost any explanation on the Internets. That doesn't mean you should believe all of them. R does not do anything likely to tweak interrupts... if that is your problem then you need to be on an operating-system/computer-model-specific forum rather than this OS-agnostic mailing list.

It is far more likely that your overall memory usage conditions have changed since the last time you ran it... or that you didn't actually record all of the things you did last time in your script. (Newbie R users often do things at the console without putting them in their scripts.)

I suggest that you run your script one statement at a time and see where your problem is. You might also want to make sure that other programs are not using up a lot of your memory (which could involve some OS-specific tools or just shutting down some other programs.)

On June 12, 2018 7:36:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>I ran  a function in R three days ago and the execution time was about
>4 minutes. I ran the same function yesterday and the execution time was
>more than 6:50 minutes(I aborted the function after that time).
>
>I read in the Internet that this is possible. I also came to know that
>software or hardware interrupts are the main reasons.
>
>How do you know whether the delay was caused by interrupts? Which
>hardware or software triggered the interrupts? In general, how to know
>the exact cause of the delay in execution in R? Are there any packages
>for these analyses?
>
>Very many thanks for your time and effort....
>
>yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From |or|@@bennett @end|ng |rom |u-ber||n@de  Wed Jun 13 10:07:38 2018
From: |or|@@bennett @end|ng |rom |u-ber||n@de (Loris Bennett)
Date: Wed, 13 Jun 2018 10:07:38 +0200
Subject: [R] on execution time of a function...
In-Reply-To: <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us> (Jeff
 Newmiller's message of "Tue, 12 Jun 2018 21:53:57 -1000")
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>
Message-ID: <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>

Hi Akshay,

In addition to all the things Jeff rightly points out, contention for IO
resources can be an issue.  So if another process was hogging the
bandwidth while your program was attempting to read or write to disk,
that could also have slowed things down.

HTH

Loris

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

> Wow, you can find almost any explanation on the Internets. That doesn't mean you
> should believe all of them. R does not do anything likely to tweak
> interrupts... if that is your problem then you need to be on an
> operating-system/computer-model-specific forum rather than this OS-agnostic
> mailing list.
>
> It is far more likely that your overall memory usage conditions have changed
> since the last time you ran it... or that you didn't actually record all of the
> things you did last time in your script. (Newbie R users often do things at the
> console without putting them in their scripts.)
>
> I suggest that you run your script one statement at a time and see where your
> problem is. You might also want to make sure that other programs are not using
> up a lot of your memory (which could involve some OS-specific tools or just
> shutting down some other programs.)
>
> On June 12, 2018 7:36:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>>I ran  a function in R three days ago and the execution time was about
>>4 minutes. I ran the same function yesterday and the execution time was
>>more than 6:50 minutes(I aborted the function after that time).
>>
>>I read in the Internet that this is possible. I also came to know that
>>software or hardware interrupts are the main reasons.
>>
>>How do you know whether the delay was caused by interrupts? Which
>>hardware or software triggered the interrupts? In general, how to know
>>the exact cause of the delay in execution in R? Are there any packages
>>for these analyses?
>>
>>Very many thanks for your time and effort....
>>
>>yours sincerely,
>>AKSHAY M KULKARNI
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
-- 
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de



From @k@h@y_e4 @end|ng |rom hotm@||@com  Wed Jun 13 11:39:40 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Wed, 13 Jun 2018 09:39:40 +0000
Subject: [R] on execution time of a function...
In-Reply-To: <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>,
 <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>
Message-ID: <SL2P216MB0091615418967B977F2B4876C87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

I do felt a little unsettled by your exhortions on the incongruity of posting this question on an OS-agnostic mailing list...I thought that there might be some issues on how R communicates with the OS...and also that some R packages might rectify the issue(in my experience, I have had a R package for every R issue that I had!)

Anyway, I ran the  same function again and it is executing within limits. Also, I would be using AWS EC2 servers to run my R functions(I am a day trader in india and input some 250 stocks to R functions daily), and I don't think that the issue would persist on Intel Xeon processors and dedicated VMs....

Anyway,thanks for all your concerns tolerating my query on an OS-agnostic mailing list!

AKSHAY M KULKARNI
________________________________
From: Loris Bennett <loris.bennett at fu-berlin.de>
Sent: Wednesday, June 13, 2018 1:37 PM
To: Jeff Newmiller
Cc: r-help at r-project.org; akshay kulkarni
Subject: Re: [R] on execution time of a function...

Hi Akshay,

In addition to all the things Jeff rightly points out, contention for IO
resources can be an issue.  So if another process was hogging the
bandwidth while your program was attempting to read or write to disk,
that could also have slowed things down.

HTH

Loris

Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:

> Wow, you can find almost any explanation on the Internets. That doesn't mean you
> should believe all of them. R does not do anything likely to tweak
> interrupts... if that is your problem then you need to be on an
> operating-system/computer-model-specific forum rather than this OS-agnostic
> mailing list.
>
> It is far more likely that your overall memory usage conditions have changed
> since the last time you ran it... or that you didn't actually record all of the
> things you did last time in your script. (Newbie R users often do things at the
> console without putting them in their scripts.)
>
> I suggest that you run your script one statement at a time and see where your
> problem is. You might also want to make sure that other programs are not using
> up a lot of your memory (which could involve some OS-specific tools or just
> shutting down some other programs.)
>
> On June 12, 2018 7:36:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>>I ran  a function in R three days ago and the execution time was about
>>4 minutes. I ran the same function yesterday and the execution time was
>>more than 6:50 minutes(I aborted the function after that time).
>>
>>I read in the Internet that this is possible. I also came to know that
>>software or hardware interrupts are the main reasons.
>>
>>How do you know whether the delay was caused by interrupts? Which
>>hardware or software triggered the interrupts? In general, how to know
>>the exact cause of the delay in execution in R? Are there any packages
>>for these analyses?
>>
>>Very many thanks for your time and effort....
>>
>>yours sincerely,
>>AKSHAY M KULKARNI
>>
>>      [[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
--
Dr. Loris Bennett (Mr.)
ZEDAT, Freie Universit?t Berlin         Email loris.bennett at fu-berlin.de

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 13 11:58:02 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 12 Jun 2018 23:58:02 -1000
Subject: [R] on execution time of a function...
In-Reply-To: <SL2P216MB0091615418967B977F2B4876C87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00913AE8DD74748326BCCDDDC87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <B13099F3-227B-4392-8490-BC31E8D66E0E@dcn.davis.ca.us>,
 <87efhbcdo5.fsf@hornfels.zedat.fu-berlin.de>
 <SL2P216MB0091615418967B977F2B4876C87E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAEAF349-F570-413D-99EF-6618C382C617@dcn.davis.ca.us>

it is not just the list that is OS-agnostic... R itself is quite OS-agnostic. However, depending on where you get your packages from they may have something unusual going on in their compiled C or Fortran code. It is just that for a computationally-oriented application like R code that messed with hardware interrupts seem out of place.

I suppose that a bug in a CUDA-related package could screw up interrupts... but the whole point of having an OS as hardware drivers/APIs is to insulate user-level programs like R from those issues, and at best you would post the details of your code and packages and someone might pick up on an odd package and point you toward a more appropriate forum for debugging it.

On June 12, 2018 11:39:40 PM HST, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>I do felt a little unsettled by your exhortions on the incongruity of
>posting this question on an OS-agnostic mailing list...I thought that
>there might be some issues on how R communicates with the OS...and also
>that some R packages might rectify the issue(in my experience, I have
>had a R package for every R issue that I had!)
>
>Anyway, I ran the  same function again and it is executing within
>limits. Also, I would be using AWS EC2 servers to run my R functions(I
>am a day trader in india and input some 250 stocks to R functions
>daily), and I don't think that the issue would persist on Intel Xeon
>processors and dedicated VMs....
>
>Anyway,thanks for all your concerns tolerating my query on an
>OS-agnostic mailing list!
>
>AKSHAY M KULKARNI
>________________________________
>From: Loris Bennett <loris.bennett at fu-berlin.de>
>Sent: Wednesday, June 13, 2018 1:37 PM
>To: Jeff Newmiller
>Cc: r-help at r-project.org; akshay kulkarni
>Subject: Re: [R] on execution time of a function...
>
>Hi Akshay,
>
>In addition to all the things Jeff rightly points out, contention for
>IO
>resources can be an issue.  So if another process was hogging the
>bandwidth while your program was attempting to read or write to disk,
>that could also have slowed things down.
>
>HTH
>
>Loris
>
>Jeff Newmiller <jdnewmil at dcn.davis.ca.us> writes:
>
>> Wow, you can find almost any explanation on the Internets. That
>doesn't mean you
>> should believe all of them. R does not do anything likely to tweak
>> interrupts... if that is your problem then you need to be on an
>> operating-system/computer-model-specific forum rather than this
>OS-agnostic
>> mailing list.
>>
>> It is far more likely that your overall memory usage conditions have
>changed
>> since the last time you ran it... or that you didn't actually record
>all of the
>> things you did last time in your script. (Newbie R users often do
>things at the
>> console without putting them in their scripts.)
>>
>> I suggest that you run your script one statement at a time and see
>where your
>> problem is. You might also want to make sure that other programs are
>not using
>> up a lot of your memory (which could involve some OS-specific tools
>or just
>> shutting down some other programs.)
>>
>> On June 12, 2018 7:36:40 PM HST, akshay kulkarni
><akshay_e4 at hotmail.com> wrote:
>>>I ran  a function in R three days ago and the execution time was
>about
>>>4 minutes. I ran the same function yesterday and the execution time
>was
>>>more than 6:50 minutes(I aborted the function after that time).
>>>
>>>I read in the Internet that this is possible. I also came to know
>that
>>>software or hardware interrupts are the main reasons.
>>>
>>>How do you know whether the delay was caused by interrupts? Which
>>>hardware or software triggered the interrupts? In general, how to
>know
>>>the exact cause of the delay in execution in R? Are there any
>packages
>>>for these analyses?
>>>
>>>Very many thanks for your time and effort....
>>>
>>>yours sincerely,
>>>AKSHAY M KULKARNI
>>>
>>>      [[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>--
>Dr. Loris Bennett (Mr.)
>ZEDAT, Freie Universit?t Berlin         Email
>loris.bennett at fu-berlin.de

-- 
Sent from my phone. Please excuse my brevity.



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jun 13 12:20:32 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 13 Jun 2018 10:20:32 +0000
Subject: [R] Help installing the finalfit package
In-Reply-To: <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
Message-ID: <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning David, thank you for your reply.

However, I am not sure what you mean regarding the windows error? Where or what is the windows error? And how would I remedy this issue please?

Thanks

WHP

From: David Winsemius [mailto:dwinsemius at comcast.net]
Sent: Wednesday, June 13, 2018 12:48 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help installing the finalfit package


> On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
> Good morning. Over the weekend I worked through this tutorial on bloggers.com<http://bloggers.com> at home where I am on 3.5.5:
>
> #Elegant regression results tables and plots in R: the finalfit package
>
> https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/<https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/>
>
> Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
>
> The tutorial ran splendidly at home but here at office, not so much, big smile.
>
>> devtools::install_github("ewenharrison/finalfit")
> Downloading GitHub repo ewenharrison/finalfit at master
> from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master<https://api.github.com/repos/ewenharrison/finalfit/zipball/master>
> Installing finalfit
> Installing 1 package: mice
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
> downloaded 1.4 MB
>
> package 'mice' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'mice'

Generally the first task is to address the first error, which in this case appears to be a windows permission issue.

--
David


>
> The downloaded binary packages are in
> C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \
> "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
>
> ERROR: dependency 'mice' is not available for package 'finalfit'
> * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> In R CMD INSTALL
> Installation failed: Command failed (1)
>
> I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho' etc... which I now load at the beginning of every session.
>
> So my hunch is that maybe I need 3.5.5 for all this to work?
>
> Also I have this error with the mice package:
>
>
>> install.packages("mice")
>
> trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
>
> Content type 'application/zip' length 1490726 bytes (1.4 MB)
>
> downloaded 1.4 MB
>
>
>
> package 'mice' successfully unpacked and MD5 sums checked
>
> Warning in install.packages :
>
> cannot remove prior installation of package 'mice'
>
>
>
> The downloaded binary packages are in
>
> C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
>
>> library(mice)
>
> Error in library(mice) : there is no package called 'mice'
>
>
> I would appreciate any suggestion please.
>
> Thank you
>
> WHP
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law




Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Wed Jun 13 13:21:55 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 13 Jun 2018 14:21:55 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
Message-ID: <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>

Hi!

I have a quadratic optimization problem and I have some difficulties coding
it with R. The math version of the problem looks like this:

min sum(mj -mj^)^2 which goes from 1 to J

st.

mj-1 <= mj - delta1

1/(Qj-1 -Qj-2)(mj-2 -mj-1) <= 1/(Qj -Qj-1 ) (mj-1 - mj) -delta2

And I'm coding it like this:

Dmat <- matrix(0, J,J)
diag(Dmat) <- 1
dvec <- -hsmooth
Aeq <- 0
beq <- 0
Amat <- matrix(0,2*J-3,J)
bvec <- rep(0,2*J-3)

for(j in 1:J)
{
  Amat[j-1,j-1] = -1
  Amat[j-1,j]   = 1
  bvec[j-1]     = Delta1
}

for(j in 2:J)
  {
  Amat[J-1+j-2,j] = -1/ (Q[j] - Q[j-1])
  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
  Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
  bvec[J-1+j-1]= Delta2
}

solution <- solve.QP(Dmat, dvec, Amat, bvec)


I get errors:
Error in Amat[J - 1 + j - 2, j - 1] <- 1/(Q[j] - Q[j - 1]) + 1/(Q[j -  :
  replacement has length zero

And

Error in solve.QP(Dmat, dvec, Amat, bvec) :
  Amat and dvec are incompatible!

I'm not sure what I'm doing wrong here, and I really could use some help
with this. Thanks in advance!

	[[alternative HTML version deleted]]



From bor|@@@te|pe @end|ng |rom utoronto@c@  Wed Jun 13 14:52:10 2018
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Wed, 13 Jun 2018 08:52:10 -0400
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
Message-ID: <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>

Q[j-2] gives you Q[0] in your first inner loop iteration.
R arrays start at one. 

B.


> On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
> 
>  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 13 16:10:03 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 13 Jun 2018 07:10:03 -0700
Subject: [R] Tables in Rmarkdown Word
In-Reply-To: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
Message-ID: <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>

You should post this on the r-package-devel  list, not here. That list is
exactly concerned with such issues. This list is about R programming itself.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 13, 2018 at 12:05 AM, Shakeel Suleman <
Shakeel.Suleman at phe.gov.uk> wrote:

> I am relatively new to R and was wondering if someone could advise me on
> presenting tables in R Markdown for Word. I would like to present a simple
> table of counts, with column 1 representing name of an organisation (and
> last row called "All organisations") and another four columns representing
> the most recent four week period (e.g. week 21, 22, 23, 24) and a final
> total column, as illustrated below. The actual data is just counts (e.g. 4,
> 5, 8, widgets produced, number of people off sick etc).
>
> My question is: can this be done to a publication quality standard. I have
> tried Pander, but that adds "Sum" instead of All Organisations and 4 Week
> Total and doesn't look particularly good.
>
>
>
> Week
>
>
>
> 20
>
> 21
>
> 22
>
> 23
>
> 4 week total
>
> Organisation
>
> 6
>
> 6
>
> 1
>
> 1
>
> 14
>
> ABC
>
> 2
>
> 4
>
> 1
>
> 5
>
> 12
>
> DCE
>
> 0
>
> 5
>
> 1
>
> 5
>
> 11
>
> EFG
>
> 3
>
> 6
>
> 3
>
> 5
>
> 17
>
> HIJ
>
> 1
>
> 8
>
> 3
>
> 2
>
> 14
>
> All Organizations
>
> 12
>
> 29
>
> 9
>
> 18
>
> 68
>
>
>
> Kind regards,
>
> Shakeel
>
>
> **************************************************************************
> The information contained in the EMail and any attachments is confidential
> and intended solely and for the attention and use of the named
> addressee(s). It may not be disclosed to any other person without the
> express authority of Public Health England, or the intended recipient, or
> both. If you are not the intended recipient, you must not disclose, copy,
> distribute or retain this message or any part of it. This footnote also
> confirms that this EMail has been swept for computer viruses by
> Symantec.Cloud, but please re-sweep any attachments before opening or
> saving. http://www.gov.uk/PHE
> **************************************************************************
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jun 13 16:31:38 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 13 Jun 2018 10:31:38 -0400
Subject: [R] Tables in Rmarkdown Word
In-Reply-To: <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
 <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>
Message-ID: <b64e7905-71f7-431f-f32d-ec4c4b31b1ae@gmail.com>

On 13/06/2018 10:10 AM, Bert Gunter wrote:
> You should post this on the r-package-devel  list, not here. That list is
> exactly concerned with such issues. This list is about R programming itself.

No, r-package-devel is about developing and publishing R packages, not 
using them.

I don't know the answer to this question.  Others like it tend to appear 
on Stack Overflow with the "knitr" tag, so that might be a better place 
to ask if no answer appears here.  But like here, that forum asks for 
reproducible examples (i.e. the R code that doesn't quite work).

Duncan Murdoch


> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Wed, Jun 13, 2018 at 12:05 AM, Shakeel Suleman <
> Shakeel.Suleman at phe.gov.uk> wrote:
> 
>> I am relatively new to R and was wondering if someone could advise me on
>> presenting tables in R Markdown for Word. I would like to present a simple
>> table of counts, with column 1 representing name of an organisation (and
>> last row called "All organisations") and another four columns representing
>> the most recent four week period (e.g. week 21, 22, 23, 24) and a final
>> total column, as illustrated below. The actual data is just counts (e.g. 4,
>> 5, 8, widgets produced, number of people off sick etc).
>>
>> My question is: can this be done to a publication quality standard. I have
>> tried Pander, but that adds "Sum" instead of All Organisations and 4 Week
>> Total and doesn't look particularly good.
>>
>>
>>
>> Week
>>
>>
>>
>> 20
>>
>> 21
>>
>> 22
>>
>> 23
>>
>> 4 week total
>>
>> Organisation
>>
>> 6
>>
>> 6
>>
>> 1
>>
>> 1
>>
>> 14
>>
>> ABC
>>
>> 2
>>
>> 4
>>
>> 1
>>
>> 5
>>
>> 12
>>
>> DCE
>>
>> 0
>>
>> 5
>>
>> 1
>>
>> 5
>>
>> 11
>>
>> EFG
>>
>> 3
>>
>> 6
>>
>> 3
>>
>> 5
>>
>> 17
>>
>> HIJ
>>
>> 1
>>
>> 8
>>
>> 3
>>
>> 2
>>
>> 14
>>
>> All Organizations
>>
>> 12
>>
>> 29
>>
>> 9
>>
>> 18
>>
>> 68
>>
>>
>>
>> Kind regards,
>>
>> Shakeel
>>
>>
>> **************************************************************************
>> The information contained in the EMail and any attachments is confidential
>> and intended solely and for the attention and use of the named
>> addressee(s). It may not be disclosed to any other person without the
>> express authority of Public Health England, or the intended recipient, or
>> both. If you are not the intended recipient, you must not disclose, copy,
>> distribute or retain this message or any part of it. This footnote also
>> confirms that this EMail has been swept for computer viruses by
>> Symantec.Cloud, but please re-sweep any attachments before opening or
>> saving. http://www.gov.uk/PHE
>> **************************************************************************
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From |br@h|m|@|@@cm @end|ng |rom gm@||@com  Wed Jun 13 14:56:07 2018
From: |br@h|m|@|@@cm @end|ng |rom gm@||@com (Khaled Ibrahimi)
Date: Wed, 13 Jun 2018 14:56:07 +0200
Subject: [R] R examples in Agronomy
Message-ID: <CALUo2PTC0ox-0TMD4QdOtDffs0A+zkpG5bUWe6-1fErF4CZd5g@mail.gmail.com>

Dear all,
Are there good R stat examples in the field of agronomy (especially field
experiments)?
Thanks
----------------------------------------/-----------------------------------------
Khaled IBRAHIMI, PhD
Assistant Professor, Soil Science & Environment
Higher Institute of Agricultural Sciences of Chott-Mariem
The University of Sousse, Tunisia
Tel.: 216 97 276 835
Email: ibrahimi.isacm at gmail.com

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jun 13 16:47:54 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 13 Jun 2018 14:47:54 +0000
Subject: [R] Data frame with Factor column missing data change to NA
Message-ID: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning.

#I have df with a Factor column called "NonAcceptanceOther" that contains missing data.

#Not every record in the df is expected to have a value in this column.

# Typical values look like:
# ERS
# Claim paid without PHX recommended savings
# Claim paid without PHX recommended savings
# MRC Amount
# MRC Amount
# PPO per provider
#Or they are missing (blank)

#Example

df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
head(df2, n=20)

   PlaceOfService ClaimStatusID                         NonAcceptanceOther RejectionCodeID          CPTCats     RevCodeCats GCode2 ClaimTypeID

1              11             2                                                         NA          ResPSys NotValidRevCode      2           2

2              81             3                                                         53       PathandLab NotValidRevCode      2           2

3              11             3                                                         47         Medicine NotValidRevCode      1           2

4              09             2                                                         NA           NotCPT NotValidRevCode      1           2

5              11             2                                                         NA        Radiology NotValidRevCode      2           2

6              23             2                                                         NA       MusculoSys NotValidRevCode      2           2

7              12             3                                                         47           NotCPT NotValidRevCode      2           2

8              12             2                                                         NA         Medicine NotValidRevCode      2           2

9              11             3                                                         47         Medicine NotValidRevCode      1           2

10             21             2                                                         NA       Anesthesia NotValidRevCode      2           2

11             11             3                                        ERS              30      EvalandMgmt NotValidRevCode      2           2

12             81             2                                                         NA       PathandLab NotValidRevCode      2           2

13             21             2                                                         NA        Radiology NotValidRevCode      1           2

14             11             2                                                         NA         Medicine NotValidRevCode      1           2

15             99             3 Claim paid without PHX recommended savings              30 CardioHemLympSys             Lab      0           1

16             99             3 Claim paid without PHX recommended savings              30       PathandLab             Lab      0           1

17             99             3                                 MRC Amount              30           NotCPT          Pharma      2           1

18             99             3                                 MRC Amount              30       PathandLab             Lab      2           1

19             81             2                                                         NA       PathandLab NotValidRevCode      2           2

20             23             2                                                         NA         IntegSys NotValidRevCode      1           2

#I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.

#I have tried several approaches from Googled references:

NonAcceptanceOther <- df$NonAcceptanceOther
table(addNA(NonAcceptanceOther))

is.na <- df$NonAcceptanceOther

df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA

#However, when I go to use:

missingDF <- PlotMissing(df)

#Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID)  and this "NonAcceptanceOther" column does not reflect or hold the NA values?

Thank you for any advice.

WHP












Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 13 17:12:00 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 13 Jun 2018 08:12:00 -0700
Subject: [R] Fwd:  Tables in Rmarkdown Word
In-Reply-To: <CAGxFJbQWWcv99s_UcpmoSxNjksuDCgkuAVniFBXtpFKQw0xozQ@mail.gmail.com>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
 <CAGxFJbRrytJJv-DtJvHyckyXwxH3+RVnjCeF3ebf8GUoFYCPXg@mail.gmail.com>
 <b64e7905-71f7-431f-f32d-ec4c4b31b1ae@gmail.com>
 <CAGxFJbQWWcv99s_UcpmoSxNjksuDCgkuAVniFBXtpFKQw0xozQ@mail.gmail.com>
Message-ID: <CAGxFJbQ7xvD0nyJB_f7Ken7Gw9z=Qvf0A7uN+6U=T0ZkZ_Kwjw@mail.gmail.com>

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

---------- Forwarded message ----------
From: Bert Gunter <bgunter.4567 at gmail.com>
Date: Wed, Jun 13, 2018 at 8:11 AM
Subject: Re: [R] Tables in Rmarkdown Word
To: Duncan Murdoch <murdoch.duncan at gmail.com>


Duncan:

OK. I'll stand corrected.

A web search on "Rmarkdown tables" produced what looked like several useful
links, e.g.

https://rmarkdown.rstudio.com/lesson-7.html


Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 13, 2018 at 7:31 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 13/06/2018 10:10 AM, Bert Gunter wrote:
>
>> You should post this on the r-package-devel  list, not here. That list is
>> exactly concerned with such issues. This list is about R programming
>> itself.
>>
>
> No, r-package-devel is about developing and publishing R packages, not
> using them.
>
> I don't know the answer to this question.  Others like it tend to appear
> on Stack Overflow with the "knitr" tag, so that might be a better place to
> ask if no answer appears here.  But like here, that forum asks for
> reproducible examples (i.e. the R code that doesn't quite work).
>
> Duncan Murdoch
>
>
>
>> Cheers,
>> Bert
>>
>>
>>
>> Bert Gunter
>>
>> "The trouble with having an open mind is that people keep coming along and
>> sticking things into it."
>> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>>
>> On Wed, Jun 13, 2018 at 12:05 AM, Shakeel Suleman <
>> Shakeel.Suleman at phe.gov.uk> wrote:
>>
>> I am relatively new to R and was wondering if someone could advise me on
>>> presenting tables in R Markdown for Word. I would like to present a
>>> simple
>>> table of counts, with column 1 representing name of an organisation (and
>>> last row called "All organisations") and another four columns
>>> representing
>>> the most recent four week period (e.g. week 21, 22, 23, 24) and a final
>>> total column, as illustrated below. The actual data is just counts (e.g.
>>> 4,
>>> 5, 8, widgets produced, number of people off sick etc).
>>>
>>> My question is: can this be done to a publication quality standard. I
>>> have
>>> tried Pander, but that adds "Sum" instead of All Organisations and 4 Week
>>> Total and doesn't look particularly good.
>>>
>>>
>>>
>>> Week
>>>
>>>
>>>
>>> 20
>>>
>>> 21
>>>
>>> 22
>>>
>>> 23
>>>
>>> 4 week total
>>>
>>> Organisation
>>>
>>> 6
>>>
>>> 6
>>>
>>> 1
>>>
>>> 1
>>>
>>> 14
>>>
>>> ABC
>>>
>>> 2
>>>
>>> 4
>>>
>>> 1
>>>
>>> 5
>>>
>>> 12
>>>
>>> DCE
>>>
>>> 0
>>>
>>> 5
>>>
>>> 1
>>>
>>> 5
>>>
>>> 11
>>>
>>> EFG
>>>
>>> 3
>>>
>>> 6
>>>
>>> 3
>>>
>>> 5
>>>
>>> 17
>>>
>>> HIJ
>>>
>>> 1
>>>
>>> 8
>>>
>>> 3
>>>
>>> 2
>>>
>>> 14
>>>
>>> All Organizations
>>>
>>> 12
>>>
>>> 29
>>>
>>> 9
>>>
>>> 18
>>>
>>> 68
>>>
>>>
>>>
>>> Kind regards,
>>>
>>> Shakeel
>>>
>>>
>>> ************************************************************
>>> **************
>>> The information contained in the EMail and any attachments is
>>> confidential
>>> and intended solely and for the attention and use of the named
>>> addressee(s). It may not be disclosed to any other person without the
>>> express authority of Public Health England, or the intended recipient, or
>>> both. If you are not the intended recipient, you must not disclose, copy,
>>> distribute or retain this message or any part of it. This footnote also
>>> confirms that this EMail has been swept for computer viruses by
>>> Symantec.Cloud, but please re-sweep any attachments before opening or
>>> saving. http://www.gov.uk/PHE
>>> ************************************************************
>>> **************
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/
>>> posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>>
>

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Wed Jun 13 17:33:22 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 13 Jun 2018 08:33:22 -0700
Subject: [R] Help installing the finalfit package
In-Reply-To: <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
 <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <1FE90007-CFBF-4855-9E31-351C19DD2BA7@comcast.net>


> On Jun 13, 2018, at 3:20 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> Good morning David, thank you for your reply.
>  
> However, I am not sure what you mean regarding the windows error?

I'm not a Windows user, but the first indication of a problem was when the installation procedure tried to replace an older version of mice with a newer version and failed. I only chimed in from my place on the sidelines of an R-Windows game because no one else had responded.

I tried finding the finalfit package on CRAN but it doesn't seem to have yet been submitted in a version that can be installed on a Mac. So I followed the advice on the blog you linked to and I can now see the package DESCRIPTION file. It has these dependencies:

Imports: Hmisc, ggplot2, grid, gridExtra, lme4, magrittr, mice, pROC,
        plyr, scales, stats, stringr, survival, survminer
RoxygenNote: 6.0.1
Suggests: knitr, rmarkdown, rstan, boot


> Where or what is the windows error?

It appears you have an older version of mice but I cannot tell why it is unacceptable to this version of 'finalfit' since there is no version requirement in the deescription 'Imports:' line.

You might try to update your 'mice'-package. The current version on CRAN is 3.0.0, and attempting to make that available might illuminate the problem.


> And how would I remedy this issue please?

Fixing permissions on windows is not actually on-topic for Rhelp. Perhaps you could ask on the SuperUser forum where advice about Windows system maintenance is on-topic: https://superuser.com/


Best of luck.

David.
> Thanks
>  
> WHP
>  
> From: David Winsemius [mailto:dwinsemius at comcast.net] 
> Sent: Wednesday, June 13, 2018 12:48 AM
> To: Bill Poling <Bill.Poling at zelis.com>
> Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
> Subject: Re: [R] Help installing the finalfit package
>  
> 
> > On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> > 
> > Good morning. Over the weekend I worked through this tutorial on bloggers.com at home where I am on 3.5.5:
> > 
> > #Elegant regression results tables and plots in R: the finalfit package
> > 
> > https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/
> > 
> > Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
> > 
> > The tutorial ran splendidly at home but here at office, not so much, big smile.
> > 
> >> devtools::install_github("ewenharrison/finalfit")
> > Downloading GitHub repo ewenharrison/finalfit at master
> > from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master
> > Installing finalfit
> > Installing 1 package: mice
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> > downloaded 1.4 MB
> > 
> > package 'mice' successfully unpacked and MD5 sums checked
> > Warning: cannot remove prior installation of package 'mice'
> 
> Generally the first task is to address the first error, which in this case appears to be a windows permission issue.
> 
> -- 
> David
> 
> 
> > 
> > The downloaded binary packages are in
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> > "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \
> > "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
> > 
> > ERROR: dependency 'mice' is not available for package 'finalfit'
> > * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> > In R CMD INSTALL
> > Installation failed: Command failed (1)
> > 
> > I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho' etc... which I now load at the beginning of every session.
> > 
> > So my hunch is that maybe I need 3.5.5 for all this to work?
> > 
> > Also I have this error with the mice package:
> > 
> > 
> >> install.packages("mice")
> > 
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip'
> > 
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> > 
> > downloaded 1.4 MB
> > 
> > 
> > 
> > package 'mice' successfully unpacked and MD5 sums checked
> > 
> > Warning in install.packages :
> > 
> > cannot remove prior installation of package 'mice'
> > 
> > 
> > 
> > The downloaded binary packages are in
> > 
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> > 
> >> library(mice)
> > 
> > Error in library(mice) : there is no package called 'mice'
> > 
> > 
> > I would appreciate any suggestion please.
> > 
> > Thank you
> > 
> > WHP
> > 
> > Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> > 
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 13 18:13:17 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 13 Jun 2018 06:13:17 -1000
Subject: [R] Tables in Rmarkdown Word
In-Reply-To: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
References: <87596AC185AC7044835858C43B6A83DC01C99515DD@MAILMBXCOL03.phe.gov.uk>
Message-ID: <F4717260-062E-4BD0-9DE1-DCC1C90717FC@dcn.davis.ca.us>

I have heard of people using CSS formatting with Rmarkdown output and copy-pasting into Word/LibreOffice, but LaTeX is so much nicer if you don't require Word that I suppose there haven't been many with that itch. To some extent you can use a manually-styled Word starting document (referred to as a template but not what Word refers to as a template) with Word output, but that is pretty limited for table formatting.

You could look at the ReporteRs package instead... but that is not Rmarkdown.

If you really need publication quality with Word

On June 12, 2018 9:05:55 PM HST, Shakeel Suleman <Shakeel.Suleman at phe.gov.uk> wrote:
>I am relatively new to R and was wondering if someone could advise me
>on presenting tables in R Markdown for Word. I would like to present a
>simple table of counts, with column 1 representing name of an
>organisation (and last row called "All organisations") and another four
>columns representing the most recent four week period (e.g. week 21,
>22, 23, 24) and a final total column, as illustrated below. The actual
>data is just counts (e.g. 4, 5, 8, widgets produced, number of people
>off sick etc).
>
>My question is: can this be done to a publication quality standard. I
>have tried Pander, but that adds "Sum" instead of All Organisations and
>4 Week Total and doesn't look particularly good.
>
>
>
>Week
>
>
>
>20
>
>21
>
>22
>
>23
>
>4 week total
>
>Organisation
>
>6
>
>6
>
>1
>
>1
>
>14
>
>ABC
>
>2
>
>4
>
>1
>
>5
>
>12
>
>DCE
>
>0
>
>5
>
>1
>
>5
>
>11
>
>EFG
>
>3
>
>6
>
>3
>
>5
>
>17
>
>HIJ
>
>1
>
>8
>
>3
>
>2
>
>14
>
>All Organizations
>
>12
>
>29
>
>9
>
>18
>
>68
>
>
>
>Kind regards,
>
>Shakeel
>
>
>**************************************************************************
>The information contained in the EMail and any attachments is
>confidential and intended solely and for the attention and use of the
>named addressee(s). It may not be disclosed to any other person without
>the express authority of Public Health England, or the intended
>recipient, or both. If you are not the intended recipient, you must not
>disclose, copy, distribute or retain this message or any part of it.
>This footnote also confirms that this EMail has been swept for computer
>viruses by Symantec.Cloud, but please re-sweep any attachments before
>opening or saving. http://www.gov.uk/PHE
>**************************************************************************
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From wdun|@p @end|ng |rom t|bco@com  Wed Jun 13 18:27:10 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Wed, 13 Jun 2018 09:27:10 -0700
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
Message-ID: <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>

Use functions calling functions instead of scripts invoking scripts.  Put
all your
functions in a 'package'.  Then your scripts would be very small, just
passing
command line arguments to R functions.

(It is possible to call scripts from scripts, but I think it quickly leads
to headaches.)

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Tue, Jun 12, 2018 at 7:33 PM, Sam Tuck <STuck at nzsuperfund.co.nz> wrote:

> Hi All,
>           I am new to R and am wondering if there is a way to pass
> arguments between rscripts.  I have this working but have had to create a
> C# shell calling the scripts in sequence via windows scripting which
> enables command line arguments to get the necessary interaction.
>
> I'm wondering if I'm using an outdated program construction technique - I
> create r files like I would programme functions or reoccurring code
> snippets in C.  It may be that r was not designed to create lots of little
> r script modules that interact via a master script?
>
> Ideally I'd like to call r scripts from other r scripts and have all the
> variables still in memory: For example
>
> I've been using RStudio Version 1.1.447 to programme and regression test
> my individual scripts,.
>
> Script Arg Script.R
> {
> # We are going to pass arguments into this script
> arguments <- commandArgs(trailingOnly = TRUE)
> #arguments[1] is double
> #arguments[2] is double
> #arguments[3] is double.
> if(length(arguments) <3)
> {
>   stop("Not enough arguments, please supply 3, [% dbl}total deviation, [%
> dbl] individual deviation, [int] periods before recenter")
> }
> TotalDeviation <- as.numeric(arguments[1])/100
> IndividualDeviation <- as.numeric(arguments[2])/100
> RecenterPeriods <- as.numeric(arguments[3])
> # We then manipulate some objects based on these inputs, but for this test
> we will output them to a file.
> fileConn<-file("output.txt")
> writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
> fileConn)
> close(fileConn)
> }
> Script RunningScript.R
> {
> Arg Script.R 0.6 0.4 132
> }
>
> To which I get
> Error: unexpected symbol in " Arg Script.R"
>
> When I use the script RunningScript.R
> {
> system(paste("Arg Script.R", 0.8, 0.4, 132))
> }
> Nothing occurs (there is no output file created, but also no error)
>
> When I use RunningScript.R
> {
> commandArgs <- c(0.6,0.4,132)
> source("Arg Script.R')
> }
> I don't get any args passed into the file.  Instead getting the error
> Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl]
> individual deviation, [int] periods before recenter
>
> Thanks
>
> Sam Tuck
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From wjm1 @end|ng |rom c@@@co|umb|@@edu  Wed Jun 13 18:34:07 2018
From: wjm1 @end|ng |rom c@@@co|umb|@@edu (William Michels)
Date: Wed, 13 Jun 2018 09:34:07 -0700
Subject: [R] R examples in Agronomy
Message-ID: <CAA99HCzNVFg-RG5snx94yym-OYNDK0DfafFbxn3DG62NsyADdA@mail.gmail.com>

Hello,

For introductory material there is--of course--Immer's Barley Data
(popularized by Bill Cleveland), and used extensively in R to
demonstrate lattice graphics:

>library(lattice)
>?barley

Note the example dotplot() at the bottom of the "barley" help page,
and also on the "barchart" help page. The citation is included, and
there is also other commentary online:

Immer, R. F., H. K. Hayes, and LeRoy Powers. (1934). Statistical
Determination of Barley Varietal Adaptation.  Journal of the American
Society of Agronomy, 26, 403?419.
Wright, Kevin (2013). Revisiting Immer's Barley Data. The American
Statistician, 67(3), 129?133.
http://blog.revolutionanalytics.com/2014/07/theres-no-mistake-in-the-barley-data.html

For a more extensive collection of agronomic data, take a look at the
"agridat" package. There's a nice vignette as well.

https://CRAN.R-project.org/package=agridat
https://cran.r-project.org/web/packages/agridat/vignettes/agridat_examples.pdf

HTH,

Bill.

William Michels, Ph.D.



On Wed, Jun 13, 2018 at 5:56 AM, Khaled Ibrahimi
<ibrahimi.isacm at gmail.com> wrote:
> Dear all,
> Are there good R stat examples in the field of agronomy (especially field
> experiments)?
> Thanks
> ----------------------------------------/-----------------------------------------
> Khaled IBRAHIMI, PhD
> Assistant Professor, Soil Science & Environment
> Higher Institute of Agricultural Sciences of Chott-Mariem
> The University of Sousse, Tunisia
> Tel.: 216 97 276 835
> Email: ibrahimi.isacm at gmail.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From B|||@Po||ng @end|ng |rom ze||@@com  Wed Jun 13 18:38:31 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Wed, 13 Jun 2018 16:38:31 +0000
Subject: [R] Help installing the finalfit package
In-Reply-To: <1FE90007-CFBF-4855-9E31-351C19DD2BA7@comcast.net>
References: <CY1PR0201MB1834DB13545863570A26AC11EA7F0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <59C80A35-90D4-4152-85C3-BA4977E7A5FD@comcast.net>
 <CY1PR0201MB1834E3F69ACD5FE27BD09282EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <1FE90007-CFBF-4855-9E31-351C19DD2BA7@comcast.net>
Message-ID: <CY1PR0201MB1834D65BA14E18C6A013B9FFEA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Ok, thank you David, I understand better now. I will start with the mice package issue and move any further questions to the forum you suggested.

Really appreciate your help.

Cheers.

WHP

From: David Winsemius [mailto:dwinsemius at comcast.net]
Sent: Wednesday, June 13, 2018 11:33 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help installing the finalfit package


> On Jun 13, 2018, at 3:20 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
> Good morning David, thank you for your reply.
>
> However, I am not sure what you mean regarding the windows error?

I'm not a Windows user, but the first indication of a problem was when the installation procedure tried to replace an older version of mice with a newer version and failed. I only chimed in from my place on the sidelines of an R-Windows game because no one else had responded.

I tried finding the finalfit package on CRAN but it doesn't seem to have yet been submitted in a version that can be installed on a Mac. So I followed the advice on the blog you linked to and I can now see the package DESCRIPTION file. It has these dependencies:

Imports: Hmisc, ggplot2, grid, gridExtra, lme4, magrittr, mice, pROC,
plyr, scales, stats, stringr, survival, survminer
RoxygenNote: 6.0.1
Suggests: knitr, rmarkdown, rstan, boot


> Where or what is the windows error?

It appears you have an older version of mice but I cannot tell why it is unacceptable to this version of 'finalfit' since there is no version requirement in the deescription 'Imports:' line.

You might try to update your 'mice'-package. The current version on CRAN is 3.0.0, and attempting to make that available might illuminate the problem.


> And how would I remedy this issue please?

Fixing permissions on windows is not actually on-topic for Rhelp. Perhaps you could ask on the SuperUser forum where advice about Windows system maintenance is on-topic: https://superuser.com/<https://superuser.com/>


Best of luck.

David.
> Thanks
>
> WHP
>
> From: David Winsemius [mailto:dwinsemius at comcast.net]
> Sent: Wednesday, June 13, 2018 12:48 AM
> To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
> Cc: r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
> Subject: Re: [R] Help installing the finalfit package
>
>
> > On Jun 12, 2018, at 5:00 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
> >
> > Good morning. Over the weekend I worked through this tutorial on bloggers.com<http://bloggers.com> at home where I am on 3.5.5:
> >
> > #Elegant regression results tables and plots in R: the finalfit package
> >
> > https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/<https://www.r-bloggers.com/elegant-regression-results-tables-and-plots-in-r-the-finalfit-package/>
> >
> > Here at my office I am on "R version 3.4.4 (2018-03-15)" and wish to use some of what I learned.
> >
> > The tutorial ran splendidly at home but here at office, not so much, big smile.
> >
> >> devtools::install_github("ewenharrison/finalfit")
> > Downloading GitHub repo ewenharrison/finalfit at master
> > from URL https://api.github.com/repos/ewenharrison/finalfit/zipball/master<https://api.github.com/repos/ewenharrison/finalfit/zipball/master>
> > Installing finalfit
> > Installing 1 package: mice
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> > downloaded 1.4 MB
> >
> > package 'mice' successfully unpacked and MD5 sums checked
> > Warning: cannot remove prior installation of package 'mice'
>
> Generally the first task is to address the first error, which in this case appears to be a windows permission issue.
>
> --
> David
>
>
> >
> > The downloaded binary packages are in
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> > "C:/Users/bpoling/DOCUME~1/R/R-34~1.4/bin/x64/R" --no-site-file --no-environ --no-save --no-restore --quiet CMD INSTALL \
> > "C:/Users/bpoling/AppData/Local/Temp/RtmpWYkyVd/devtools1b0436122944/ewenharrison-finalfit-9438bc2" --library="C:/Users/bpoling/Documents/R/R-3.4.4/library" --install-tests
> >
> > ERROR: dependency 'mice' is not available for package 'finalfit'
> > * removing 'C:/Users/bpoling/Documents/R/R-3.4.4/library/finalfit'
> > In R CMD INSTALL
> > Installation failed: Command failed (1)
> >
> > I believe I had a similar problem last week and was advised to install the package library(Matrix) which was evidently necessary for sessionInfo() and for lazy load DB -- *source* package 'psycho' etc... which I now load at the beginning of every session.
> >
> > So my hunch is that maybe I need 3.5.5 for all this to work?
> >
> > Also I have this error with the mice package:
> >
> >
> >> install.packages("mice")
> >
> > trying URL 'https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip<https://cran.rstudio.com/bin/windows/contrib/3.4/mice_3.0.0.zip>'
> >
> > Content type 'application/zip' length 1490726 bytes (1.4 MB)
> >
> > downloaded 1.4 MB
> >
> >
> >
> > package 'mice' successfully unpacked and MD5 sums checked
> >
> > Warning in install.packages :
> >
> > cannot remove prior installation of package 'mice'
> >
> >
> >
> > The downloaded binary packages are in
> >
> > C:\Users\bpoling\AppData\Local\Temp\RtmpWYkyVd\downloaded_packages
> >
> >> library(mice)
> >
> > Error in library(mice) : there is no package called 'mice'
> >
> >
> > I would appreciate any suggestion please.
> >
> > Thank you
> >
> > WHP
> >
> > Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> >
> > ______________________________________________
> > R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.' -Gehm's Corollary to Clarke's Third Law




Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From pro|jcn@@h @end|ng |rom gm@||@com  Wed Jun 13 18:46:11 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Wed, 13 Jun 2018 12:46:11 -0400
Subject: [R] rJava woes on Linux Mint 18.3 Sylvia
Message-ID: <c30108c8-44e2-79f2-b10d-9658ba8df2c3@gmail.com>

Is anyone else having trouble with installing rJava on Linux Mint under R 3.5?

I managed to work around troubles in Bunsenlabs Deuterium (Debian Jessie), but
it uses older libraries (openjdk-7).

Please contact off-list and I will post information when solution understood,
as, looking on the net, there seem to be a lot of people with suggestions
that don't work, or work only in some environments.

JN



From |br@h|m|@|@@cm @end|ng |rom gm@||@com  Wed Jun 13 19:53:31 2018
From: |br@h|m|@|@@cm @end|ng |rom gm@||@com (Khaled Ibrahimi)
Date: Wed, 13 Jun 2018 18:53:31 +0100
Subject: [R] R examples in Agronomy
In-Reply-To: <CAA99HCzNVFg-RG5snx94yym-OYNDK0DfafFbxn3DG62NsyADdA@mail.gmail.com>
References: <CAA99HCzNVFg-RG5snx94yym-OYNDK0DfafFbxn3DG62NsyADdA@mail.gmail.com>
Message-ID: <CALUo2PSnUv8T5FkZTmYD+zFYavenEammBoWM24u=LscMhCa25w@mail.gmail.com>

Thanks, I'll check them out.

Le mer. 13 juin 2018 17:34, William Michels <wjm1 at caa.columbia.edu> a
?crit :

> Hello,
>
> For introductory material there is--of course--Immer's Barley Data
> (popularized by Bill Cleveland), and used extensively in R to
> demonstrate lattice graphics:
>
> >library(lattice)
> >?barley
>
> Note the example dotplot() at the bottom of the "barley" help page,
> and also on the "barchart" help page. The citation is included, and
> there is also other commentary online:
>
> Immer, R. F., H. K. Hayes, and LeRoy Powers. (1934). Statistical
> Determination of Barley Varietal Adaptation.  Journal of the American
> Society of Agronomy, 26, 403?419.
> Wright, Kevin (2013). Revisiting Immer's Barley Data. The American
> Statistician, 67(3), 129?133.
>
> http://blog.revolutionanalytics.com/2014/07/theres-no-mistake-in-the-barley-data.html
>
> For a more extensive collection of agronomic data, take a look at the
> "agridat" package. There's a nice vignette as well.
>
> https://CRAN.R-project.org/package=agridat
>
> https://cran.r-project.org/web/packages/agridat/vignettes/agridat_examples.pdf
>
> HTH,
>
> Bill.
>
> William Michels, Ph.D.
>
>
>
> On Wed, Jun 13, 2018 at 5:56 AM, Khaled Ibrahimi
> <ibrahimi.isacm at gmail.com> wrote:
> > Dear all,
> > Are there good R stat examples in the field of agronomy (especially field
> > experiments)?
> > Thanks
> >
> ----------------------------------------/-----------------------------------------
> > Khaled IBRAHIMI, PhD
> > Assistant Professor, Soil Science & Environment
> > Higher Institute of Agricultural Sciences of Chott-Mariem
> > The University of Sousse, Tunisia
> > Tel.: 216 97 276 835
> > Email: ibrahimi.isacm at gmail.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Wed Jun 13 22:21:07 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Wed, 13 Jun 2018 20:21:07 +0000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
Message-ID: <3BD3520F-4CB7-4500-A89B-43186C048B99@llnl.gov>

When I want to run multiple scripts one after the other, and have variables created in a script be still in memory for use by a subsequent script, I normally create a master script (say, "runall.r") and it sources each of the others in turn. For example, my master script (runall.r) would look like this:

## master script (runall.r)
source('script1.r')
source('script2.r')
source('script3.r')
cat('[runall.r] Done\n')
## end of master script

Then, optionally, I can pass command line arguments to runall.r and parse them before sourcing the other scripts.

Since all three scripts are run in the same R session, all variables in memory when script1 finishes will be available to script2, and so on.

If you want to have each of the scripts be executable (by which I mean you run them by typing their name at the command line in a Linux environment; I don't know how it's done in Windows) and have the results of script1 be used as command line arguments to script2 -- well, I'm sure it can be done, but I don't think R's way of doing things is conducive to this approach. If you want to go that route, look up the --save, --no-save, --restore, and --no-restore arguments to R scripts.

See also the help page for Rscript [type help('Rscript') or ?Rscript at the R prompt] if you haven't already.

In my opinion, there are pros and cons to William Dunlap's suggestion to embed everything in functions in a package. I do it either way, depending on various factors. I would suggest, however, that you wait until you have more R experience before trying that route.

Incidentally, this construct:

  fileConn<-file("output.txt") 
  writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods), fileConn)
  close(fileConn)

looks to me like it's more complex than needed.
I would suggest

  cat( TotalDeviation, IndividualDeviation, RecenterPeriods, '\n', file='output.txt')


--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/12/18, 7:33 PM, "R-help on behalf of Sam Tuck" <r-help-bounces at r-project.org on behalf of STuck at nzsuperfund.co.nz> wrote:

    Hi All,
              I am new to R and am wondering if there is a way to pass arguments between rscripts.  I have this working but have had to create a C# shell calling the scripts in sequence via windows scripting which enables command line arguments to get the necessary interaction.  
    
    I'm wondering if I'm using an outdated program construction technique - I create r files like I would programme functions or reoccurring code snippets in C.  It may be that r was not designed to create lots of little r script modules that interact via a master script? 
    
    Ideally I'd like to call r scripts from other r scripts and have all the variables still in memory: For example
    
    I've been using RStudio Version 1.1.447 to programme and regression test my individual scripts,. 
    
    Script Arg Script.R
    {
    # We are going to pass arguments into this script
    arguments <- commandArgs(trailingOnly = TRUE)
    #arguments[1] is double
    #arguments[2] is double
    #arguments[3] is double.
    if(length(arguments) <3) 
    {
      stop("Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter")
    }
    TotalDeviation <- as.numeric(arguments[1])/100
    IndividualDeviation <- as.numeric(arguments[2])/100
    RecenterPeriods <- as.numeric(arguments[3])
    # We then manipulate some objects based on these inputs, but for this test we will output them to a file. 
    fileConn<-file("output.txt")
    writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods), fileConn)
    close(fileConn)
    }
    Script RunningScript.R
    {
    Arg Script.R 0.6 0.4 132
    }
    
    To which I get
    Error: unexpected symbol in " Arg Script.R"
    
    When I use the script RunningScript.R
    {
    system(paste("Arg Script.R", 0.8, 0.4, 132))
    }
    Nothing occurs (there is no output file created, but also no error)
    
    When I use RunningScript.R
    {
    commandArgs <- c(0.6,0.4,132)
    source("Arg Script.R')
    }
    I don't get any args passed into the file.  Instead getting the error 
    Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl] individual deviation, [int] periods before recenter
    
    Thanks
    
    Sam Tuck 
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From @ez@reb@k| @end|ng |rom gm@||@com  Thu Jun 14 00:55:32 2018
From: @ez@reb@k| @end|ng |rom gm@||@com (Alex Zarebski)
Date: Thu, 14 Jun 2018 08:55:32 +1000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
 <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
Message-ID: <CAKsw2nFfgkXkUGCOMKp-MQi7ALJ+YPMVX5A8ZBKgiAKD-wf6Bg@mail.gmail.com>

Sourcing scripts is a bit hacky but it is a quick way to get a job done.
If you want to take your source-ing to the next level you might want to
look up how to use the "local" argument with environments.

Packages are probably the way to go if you are doing anything substantial
though.

Also, "argparse" (available through CRAN) provides some tools for parsing
command line arguments.
It is very similar to the python package of the same name which might be
more familiar.

Cheers,
Alex

On Thu, Jun 14, 2018 at 2:27 AM, William Dunlap via R-help <
r-help at r-project.org> wrote:

> Use functions calling functions instead of scripts invoking scripts.  Put
> all your
> functions in a 'package'.  Then your scripts would be very small, just
> passing
> command line arguments to R functions.
>
> (It is possible to call scripts from scripts, but I think it quickly leads
> to headaches.)
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Tue, Jun 12, 2018 at 7:33 PM, Sam Tuck <STuck at nzsuperfund.co.nz> wrote:
>
> > Hi All,
> >           I am new to R and am wondering if there is a way to pass
> > arguments between rscripts.  I have this working but have had to create a
> > C# shell calling the scripts in sequence via windows scripting which
> > enables command line arguments to get the necessary interaction.
> >
> > I'm wondering if I'm using an outdated program construction technique - I
> > create r files like I would programme functions or reoccurring code
> > snippets in C.  It may be that r was not designed to create lots of
> little
> > r script modules that interact via a master script?
> >
> > Ideally I'd like to call r scripts from other r scripts and have all the
> > variables still in memory: For example
> >
> > I've been using RStudio Version 1.1.447 to programme and regression test
> > my individual scripts,.
> >
> > Script Arg Script.R
> > {
> > # We are going to pass arguments into this script
> > arguments <- commandArgs(trailingOnly = TRUE)
> > #arguments[1] is double
> > #arguments[2] is double
> > #arguments[3] is double.
> > if(length(arguments) <3)
> > {
> >   stop("Not enough arguments, please supply 3, [% dbl}total deviation, [%
> > dbl] individual deviation, [int] periods before recenter")
> > }
> > TotalDeviation <- as.numeric(arguments[1])/100
> > IndividualDeviation <- as.numeric(arguments[2])/100
> > RecenterPeriods <- as.numeric(arguments[3])
> > # We then manipulate some objects based on these inputs, but for this
> test
> > we will output them to a file.
> > fileConn<-file("output.txt")
> > writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
> > fileConn)
> > close(fileConn)
> > }
> > Script RunningScript.R
> > {
> > Arg Script.R 0.6 0.4 132
> > }
> >
> > To which I get
> > Error: unexpected symbol in " Arg Script.R"
> >
> > When I use the script RunningScript.R
> > {
> > system(paste("Arg Script.R", 0.8, 0.4, 132))
> > }
> > Nothing occurs (there is no output file created, but also no error)
> >
> > When I use RunningScript.R
> > {
> > commandArgs <- c(0.6,0.4,132)
> > source("Arg Script.R')
> > }
> > I don't get any args passed into the file.  Instead getting the error
> > Not enough arguments, please supply 3, [% dbl}total deviation, [% dbl]
> > individual deviation, [int] periods before recenter
> >
> > Thanks
> >
> > Sam Tuck
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> > posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 14 02:30:13 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 14 Jun 2018 10:30:13 +1000
Subject: [R] Data frame with Factor column missing data change to NA
In-Reply-To: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>

Hi Bill,
It may be that the NonAcceptanceOther, being a character value, has ""
(0 length string) rather than NA. You can convert that to NA like
this:

df2$NonAcceptanceOther[nchar(df2$NonAcceptanceOther) == 0]<-NA

Jim


On Thu, Jun 14, 2018 at 12:47 AM, Bill Poling <Bill.Poling at zelis.com> wrote:
> Good morning.
>
> #I have df with a Factor column called "NonAcceptanceOther" that contains missing data.
>
> #Not every record in the df is expected to have a value in this column.
>
> # Typical values look like:
> # ERS
> # Claim paid without PHX recommended savings
> # Claim paid without PHX recommended savings
> # MRC Amount
> # MRC Amount
> # PPO per provider
> #Or they are missing (blank)
>
> #Example
>
> df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
> head(df2, n=20)
>
>    PlaceOfService ClaimStatusID                         NonAcceptanceOther RejectionCodeID          CPTCats     RevCodeCats GCode2 ClaimTypeID
>
> 1              11             2                                                         NA          ResPSys NotValidRevCode      2           2
>
> 2              81             3                                                         53       PathandLab NotValidRevCode      2           2
>
> 3              11             3                                                         47         Medicine NotValidRevCode      1           2
>
> 4              09             2                                                         NA           NotCPT NotValidRevCode      1           2
>
> 5              11             2                                                         NA        Radiology NotValidRevCode      2           2
>
> 6              23             2                                                         NA       MusculoSys NotValidRevCode      2           2
>
> 7              12             3                                                         47           NotCPT NotValidRevCode      2           2
>
> 8              12             2                                                         NA         Medicine NotValidRevCode      2           2
>
> 9              11             3                                                         47         Medicine NotValidRevCode      1           2
>
> 10             21             2                                                         NA       Anesthesia NotValidRevCode      2           2
>
> 11             11             3                                        ERS              30      EvalandMgmt NotValidRevCode      2           2
>
> 12             81             2                                                         NA       PathandLab NotValidRevCode      2           2
>
> 13             21             2                                                         NA        Radiology NotValidRevCode      1           2
>
> 14             11             2                                                         NA         Medicine NotValidRevCode      1           2
>
> 15             99             3 Claim paid without PHX recommended savings              30 CardioHemLympSys             Lab      0           1
>
> 16             99             3 Claim paid without PHX recommended savings              30       PathandLab             Lab      0           1
>
> 17             99             3                                 MRC Amount              30           NotCPT          Pharma      2           1
>
> 18             99             3                                 MRC Amount              30       PathandLab             Lab      2           1
>
> 19             81             2                                                         NA       PathandLab NotValidRevCode      2           2
>
> 20             23             2                                                         NA         IntegSys NotValidRevCode      1           2
>
> #I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.
>
> #I have tried several approaches from Googled references:
>
> NonAcceptanceOther <- df$NonAcceptanceOther
> table(addNA(NonAcceptanceOther))
>
> is.na <- df$NonAcceptanceOther
>
> df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA
>
> #However, when I go to use:
>
> missingDF <- PlotMissing(df)
>
> #Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID)  and this "NonAcceptanceOther" column does not reflect or hold the NA values?
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 14 04:03:39 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 13 Jun 2018 16:03:39 -1000
Subject: [R] Calling r-scripts with arguments from other scripts,
 or possibly R programming conventions/style guide
In-Reply-To: <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
References: <SYXPR01MB086193292668ED7839641567F47E0@SYXPR01MB0861.ausprd01.prod.outlook.com>
 <CAF8bMcaFJiaoPrcxd53RwrQr79-OsXiK-dLpFpv3jPo2nFtz0A@mail.gmail.com>
Message-ID: <E797D790-F907-47C7-8DD4-C77674EE7D69@dcn.davis.ca.us>

I echo Bill's sentiments regarding use of functions, but think that you can afford to delay building packages while you are in the exploratory phase.

You can start out by building your sequence of statements using explicitly defined variables at the beginning like

fname <- "test.csv"
#your code

and then wrap the statements into functions using those fname as a parameter:

myfunc <- function( fname ) {
   # your code
}

Functions are written in files, but loaded into (typically) the global variables environment to be used.

RStudio helps incentivise working with functions by supporting debugging in the original source code if you source the entire file. Just mark the function

debug(myfunc)

before running code the directly or indirectly runs that function.

(Debugging works at the terminal console as well, but it only shows you the next line so you have to keep track of where you are in the function yourself.)

Once you have a lot of useful functions available, you will find making packages to be a way better approach to handling code re-use than keeping track of script files.

On June 13, 2018 6:27:10 AM HST, William Dunlap via R-help <r-help at r-project.org> wrote:
>Use functions calling functions instead of scripts invoking scripts. 
>Put
>all your
>functions in a 'package'.  Then your scripts would be very small, just
>passing
>command line arguments to R functions.
>
>(It is possible to call scripts from scripts, but I think it quickly
>leads
>to headaches.)
>
>Bill Dunlap
>TIBCO Software
>wdunlap tibco.com
>
>On Tue, Jun 12, 2018 at 7:33 PM, Sam Tuck <STuck at nzsuperfund.co.nz>
>wrote:
>
>> Hi All,
>>           I am new to R and am wondering if there is a way to pass
>> arguments between rscripts.  I have this working but have had to
>create a
>> C# shell calling the scripts in sequence via windows scripting which
>> enables command line arguments to get the necessary interaction.
>>
>> I'm wondering if I'm using an outdated program construction technique
>- I
>> create r files like I would programme functions or reoccurring code
>> snippets in C.  It may be that r was not designed to create lots of
>little
>> r script modules that interact via a master script?
>>
>> Ideally I'd like to call r scripts from other r scripts and have all
>the
>> variables still in memory: For example
>>
>> I've been using RStudio Version 1.1.447 to programme and regression
>test
>> my individual scripts,.
>>
>> Script Arg Script.R
>> {
>> # We are going to pass arguments into this script
>> arguments <- commandArgs(trailingOnly = TRUE)
>> #arguments[1] is double
>> #arguments[2] is double
>> #arguments[3] is double.
>> if(length(arguments) <3)
>> {
>>   stop("Not enough arguments, please supply 3, [% dbl}total
>deviation, [%
>> dbl] individual deviation, [int] periods before recenter")
>> }
>> TotalDeviation <- as.numeric(arguments[1])/100
>> IndividualDeviation <- as.numeric(arguments[2])/100
>> RecenterPeriods <- as.numeric(arguments[3])
>> # We then manipulate some objects based on these inputs, but for this
>test
>> we will output them to a file.
>> fileConn<-file("output.txt")
>> writeLines(c(TotalDeviation, IndividualDeviation, RecenterPeriods),
>> fileConn)
>> close(fileConn)
>> }
>> Script RunningScript.R
>> {
>> Arg Script.R 0.6 0.4 132
>> }
>>
>> To which I get
>> Error: unexpected symbol in " Arg Script.R"
>>
>> When I use the script RunningScript.R
>> {
>> system(paste("Arg Script.R", 0.8, 0.4, 132))
>> }
>> Nothing occurs (there is no output file created, but also no error)
>>
>> When I use RunningScript.R
>> {
>> commandArgs <- c(0.6,0.4,132)
>> source("Arg Script.R')
>> }
>> I don't get any args passed into the file.  Instead getting the error
>> Not enough arguments, please supply 3, [% dbl}total deviation, [%
>dbl]
>> individual deviation, [int] periods before recenter
>>
>> Thanks
>>
>> Sam Tuck
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Thu Jun 14 04:43:21 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Wed, 13 Jun 2018 19:43:21 -0700
Subject: [R] Storing tableGrobs in a list
Message-ID: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>

Hi, I'm trying to generate tableGrobs in a loop, store them in a list so I
can use it in a call to gtable_combine().

L1<-list()
for (i in seq( ... )) {
   L1[i] <-tableGrob( ... )
}

gtable_combine(L1, along=1)

On the assignment inside the loop, I get "number of items to replace is not
a multiple of replacement length" which I'm guessing has to do with the
tableGrob object not "fitting" in the list but am not sure how to fix it.

Thanks in advance for any pointers.

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 14 08:01:28 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 13 Jun 2018 20:01:28 -1000
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
Message-ID: <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>

?`[[`

and read the discussions of indexing in the Introduction to R document that comes with R. Also, find a way to predict the number of elements you will need as making this a habit will pay off big time when you work with large amounts of data:

L1<-vector( "list", N )
for (i in seq.int( N )) {
   L1[[i]] <-tableGrob( ... )
}

PS Post using your email program "plain text" mode... HTML gets stripped anyway and that often leads to partial corruption of your message. Read the Posting Guide.

On June 13, 2018 4:43:21 PM HST, Stats Student <stats.student4647 at gmail.com> wrote:
>Hi, I'm trying to generate tableGrobs in a loop, store them in a list
>so I
>can use it in a call to gtable_combine().
>
>L1<-list()
>for (i in seq( ... )) {
>   L1[i] <-tableGrob( ... )
>}
>
>gtable_combine(L1, along=1)
>
>On the assignment inside the loop, I get "number of items to replace is
>not
>a multiple of replacement length" which I'm guessing has to do with the
>tableGrob object not "fitting" in the list but am not sure how to fix
>it.
>
>Thanks in advance for any pointers.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Jun 14 12:48:48 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 14 Jun 2018 10:48:48 +0000
Subject: [R] Data frame with Factor column missing data change to NA
In-Reply-To: <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>
References: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>
Message-ID: <CY1PR0201MB183445F2EA5570D097DAC6E9EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>

#Good morning Jim, thank you for your response and guidance.


So I ran the suggested and got: Error in nchar(df2$NonAcceptanceOther) :   'nchar()' requires a character vector

So I ran this:

df2$NonAcceptanceOther[] <- lapply(df2$NonAcceptanceOther,as.character)

#Then tried again.

#But still getting the error?

#Because the column remains a factor?
names(df2)

#[1] "PlaceOfService"     "ClaimStatusID"      "NonAcceptanceOther" "RejectionCodeID"    "CPTCats"            "RevCodeCats"        "GCode2"             "ClaimTypeID"

classes <- as.character(sapply(df2, class))
classes


#[1] "factor"  "integer" "factor"  "integer" "factor"  "factor"  "integer" "integer"



#Not sure if this structure helps, I guess that the 1L?s are the missing

dput(head(df2$NonAcceptanceOther, 25))

#structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 118L, 1L,

#1L, 1L, 64L, 64L, 134L, 134L, 1L, 1L, 1L, 1L, 1L, 1L, 1L)



#View from the CSV file original data


NonAcceptanceOther











ERS




Claim paid without PHX recommended savings

Claim paid without PHX recommended savings

MRC Amount

MRC Amount









Appreciate your help Sir.

WHP

From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: Wednesday, June 13, 2018 8:30 PM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Data frame with Factor column missing data change to NA

Hi Bill,
It may be that the NonAcceptanceOther, being a character value, has ""
(0 length string) rather than NA. You can convert that to NA like
this:

df2$NonAcceptanceOther[nchar(df2$NonAcceptanceOther) == 0]<-NA

Jim


On Thu, Jun 14, 2018 at 12:47 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
> Good morning.
>
> #I have df with a Factor column called "NonAcceptanceOther" that contains missing data.
>
> #Not every record in the df is expected to have a value in this column.
>
> # Typical values look like:
> # ERS
> # Claim paid without PHX recommended savings
> # Claim paid without PHX recommended savings
> # MRC Amount
> # MRC Amount
> # PPO per provider
> #Or they are missing (blank)
>
> #Example
>
> df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
> head(df2, n=20)
>
> PlaceOfService ClaimStatusID NonAcceptanceOther RejectionCodeID CPTCats RevCodeCats GCode2 ClaimTypeID
>
> 1 11 2 NA ResPSys NotValidRevCode 2 2
>
> 2 81 3 53 PathandLab NotValidRevCode 2 2
>
> 3 11 3 47 Medicine NotValidRevCode 1 2
>
> 4 09 2 NA NotCPT NotValidRevCode 1 2
>
> 5 11 2 NA Radiology NotValidRevCode 2 2
>
> 6 23 2 NA MusculoSys NotValidRevCode 2 2
>
> 7 12 3 47 NotCPT NotValidRevCode 2 2
>
> 8 12 2 NA Medicine NotValidRevCode 2 2
>
> 9 11 3 47 Medicine NotValidRevCode 1 2
>
> 10 21 2 NA Anesthesia NotValidRevCode 2 2
>
> 11 11 3 ERS 30 EvalandMgmt NotValidRevCode 2 2
>
> 12 81 2 NA PathandLab NotValidRevCode 2 2
>
> 13 21 2 NA Radiology NotValidRevCode 1 2
>
> 14 11 2 NA Medicine NotValidRevCode 1 2
>
> 15 99 3 Claim paid without PHX recommended savings 30 CardioHemLympSys Lab 0 1
>
> 16 99 3 Claim paid without PHX recommended savings 30 PathandLab Lab 0 1
>
> 17 99 3 MRC Amount 30 NotCPT Pharma 2 1
>
> 18 99 3 MRC Amount 30 PathandLab Lab 2 1
>
> 19 81 2 NA PathandLab NotValidRevCode 2 2
>
> 20 23 2 NA IntegSys NotValidRevCode 1 2
>
> #I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.
>
> #I have tried several approaches from Googled references:
>
> NonAcceptanceOther <- df$NonAcceptanceOther
> table(addNA(NonAcceptanceOther))
>
> is.na<http://is.na> <- df$NonAcceptanceOther
>
> df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA
>
> #However, when I go to use:
>
> missingDF <- PlotMissing(df)
>
> #Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID) and this "NonAcceptanceOther" column does not reflect or hold the NA values?
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From bor|@@@te|pe @end|ng |rom utoronto@c@  Thu Jun 14 14:52:53 2018
From: bor|@@@te|pe @end|ng |rom utoronto@c@ (Boris Steipe)
Date: Thu, 14 Jun 2018 08:52:53 -0400
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
Message-ID: <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>

Keep replies on list please.

You are not accessing a value from vector Q if you access the zero'th element!
R > Q <- c(3, 5, 8)
R > Q[0]
numeric(0)
R > Q[1]
[1] 3
R > Q[2]
[1] 5

In the first iteration of the loop j is 2 thus j-2 is 0 and that's the reason for the error message: you are trying to replace a matrix element with a zero-length (i.e. unassigned) numeric value. Perhaps, in your mind, you are mixing up the index of a vector element and its value? If you need two zeros to start your vector, do something like

R > Q <- c(0, 0, Q)
R > Q
[1] 0 0 3 5 8


Clear now?
B.



> On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
> 
> Many thanks for your message! 
> 
> The thing is that I need  Q[j-2] to be zero for the first two iterations because I don't have those values (J starts from 1). Do you have any idea how to do it?
> 
> Thanks again!
> 
> Maija
> 
> 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> Q[j-2] gives you Q[0] in your first inner loop iteration.
> R arrays start at one. 
> 
> B.
> 
> 
> > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
> > 
> >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> 
> 



From kev|n@thorpe @end|ng |rom utoronto@c@  Thu Jun 14 15:55:21 2018
From: kev|n@thorpe @end|ng |rom utoronto@c@ (Kevin E. Thorpe)
Date: Thu, 14 Jun 2018 09:55:21 -0400
Subject: [R] Trouble with tibbles
Message-ID: <1387723f-be10-5b3d-4047-5cc03041786e@utoronto.ca>

I am trying to learn and use the tidyverse tools and one peculiarity 
that I seem to encounter is that converting some data frames to tibbles 
gives surprising results. I tried to make a toy example illustrates the 
problem but couldn't. Let me show some output that illustrates the problem.

 > str(bincrct)
'data.frame':	267 obs. of  4 variables:
  $ StudyID     : num  20101 20102 20103 20104 20105 ...
  $ Intervention: Factor w/ 2 levels "Intervention",..: 2 2 2 2 2 1 1 1 
1 1 ...
  $ Cluster     : num  1 1 1 1 1 2 2 2 2 3 ...
  $ apptx       : num  0 0 1 0 0 1 1 1 0 1 ...
 > as_tibble(bincrct)
Error: `x` must be a numeric or a character vector
 > str(as_tibble(bincrct))
Classes ?tbl_df?, ?tbl? and 'data.frame':	267 obs. of  4 variables:
  $ StudyID     : num  20101 20102 20103 20104 20105 ...
  $ Intervention: Factor w/ 2 levels "Intervention",..: 2 2 2 2 2 1 1 1 
1 1 ...
  $ Cluster     : num  1 1 1 1 1 2 2 2 2 3 ...
  $ apptx       : num  0 0 1 0 0 1 1 1 0 1 ...

When I tried to create a data frame and run as_tibble() on it, things 
behaved correctly. My best guess is that the old data frame I am using 
has some additional baggage with it that I am unaware of.

I also tried manually creating a tibble as follows which also did not work.

 > with(bincrct, tibble(StudyID,Intervention,Cluster,apptx))
Error: `x` must be a numeric or a character vector

Any ideas? Here is my sessionInfo(). I just updated my packages this 
morning to see if that was the issue.

 > sessionInfo()
R version 3.5.0 Patched (2018-04-23 r74633)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Slackware 14.2 x86_64 (post 14.2 -current)

Matrix products: default
BLAS: /usr/local/lib64/R/lib/libRblas.so
LAPACK: /usr/local/lib64/R/lib/libRlapack.so

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

other attached packages:
  [1] forcats_0.3.0   stringr_1.3.1   dplyr_0.7.5     purrr_0.2.5
  [5] readr_1.1.1     tidyr_0.8.1     tibble_1.4.2    ggplot2_2.2.1
  [9] tidyverse_1.2.1 knitr_1.20

loaded via a namespace (and not attached):
  [1] Rcpp_0.12.17     cellranger_1.1.0 pillar_1.2.3     compiler_3.5.0
  [5] plyr_1.8.4       bindr_0.1.1      tools_3.5.0      lubridate_1.7.4
  [9] jsonlite_1.5     nlme_3.1-137     gtable_0.2.0     lattice_0.20-35
[13] pkgconfig_2.0.1  rlang_0.2.1      psych_1.8.4      cli_1.0.0
[17] rstudioapi_0.7   parallel_3.5.0   haven_1.1.1      bindrcpp_0.2.2
[21] xml2_1.2.0       httr_1.3.1       hms_0.4.2        grid_3.5.0
[25] tidyselect_0.2.4 glue_1.2.0       R6_2.2.2         readxl_1.1.0
[29] foreign_0.8-70   modelr_0.1.2     reshape2_1.4.3   magrittr_1.5
[33] scales_0.5.0     rvest_0.3.2      assertthat_0.2.0 mnormt_1.5-5
[37] colorspace_1.3-2 stringi_1.2.3    lazyeval_0.2.1   munsell_0.5.0
[41] broom_0.4.4      crayon_1.3.4


-- 
Kevin E. Thorpe
Head of Biostatistics,  Applied Health Research Centre (AHRC)
Li Ka Shing Knowledge Institute of St. Michael's Hospital
Assistant Professor, Dalla Lana School of Public Health
University of Toronto
email: kevin.thorpe at utoronto.ca  Tel: 416.864.5776  Fax: 416.864.3016



From B|||@Po||ng @end|ng |rom ze||@@com  Thu Jun 14 16:01:42 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Thu, 14 Jun 2018 14:01:42 +0000
Subject: [R] Data frame with Factor column missing data change to NA
In-Reply-To: <CY1PR0201MB183445F2EA5570D097DAC6E9EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB1834AB3B2E94AEDF103A86C6EA7E0@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CA+8X3fV-PH5aqr9d3nOizwERx5mPSiJeQ2XOw3L1gKK+SYEZgA@mail.gmail.com>
 <CY1PR0201MB183445F2EA5570D097DAC6E9EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CY1PR0201MB1834796983107420F88F6CF2EA7D0@CY1PR0201MB1834.namprd02.prod.outlook.com>

Jim,
Actually, I got this to work.

df$NonAcceptanceOther[df$NonAcceptanceOther==""]<- NA
df$NonAcceptanceOther

missingDF <- plot_missing(df)

# missingDF
#                  feature                num_missing   pct_missing    group
# 13 NonAcceptanceOther       26157       0.86859932257 Remove


Good to go now, for the moment, big smile!

Thank you for your help Sir.


WHP




From: Bill Poling
Sent: Thursday, June 14, 2018 6:49 AM
To: 'Jim Lemon' <drjimlemon at gmail.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: RE: [R] Data frame with Factor column missing data change to NA

#Good morning Jim, thank you for your response and guidance.


So I ran the suggested and got: Error in nchar(df2$NonAcceptanceOther) :   'nchar()' requires a character vector

So I ran this:

df2$NonAcceptanceOther[] <- lapply(df2$NonAcceptanceOther,as.character)

#Then tried again.

#But still getting the error?

#Because the column remains a factor?
names(df2)

#[1] "PlaceOfService"     "ClaimStatusID"      "NonAcceptanceOther" "RejectionCodeID"    "CPTCats"            "RevCodeCats"        "GCode2"             "ClaimTypeID"

classes <- as.character(sapply(df2, class))
classes


#[1] "factor"  "integer" "factor"  "integer" "factor"  "factor"  "integer" "integer"



#Not sure if this structure helps, I guess that the 1L?s are the missing

dput(head(df2$NonAcceptanceOther, 25))

#structure(c(1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 1L, 118L, 1L,

#1L, 1L, 64L, 64L, 134L, 134L, 1L, 1L, 1L, 1L, 1L, 1L, 1L)



#View from the CSV file original data


NonAcceptanceOther











ERS




Claim paid without PHX recommended savings

Claim paid without PHX recommended savings

MRC Amount

MRC Amount









Appreciate your help Sir.

WHP

From: Jim Lemon [mailto:drjimlemon at gmail.com]
Sent: Wednesday, June 13, 2018 8:30 PM
To: Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>>
Cc: r-help (r-help at r-project.org<mailto:r-help at r-project.org>) <r-help at r-project.org<mailto:r-help at r-project.org>>
Subject: Re: [R] Data frame with Factor column missing data change to NA

Hi Bill,
It may be that the NonAcceptanceOther, being a character value, has ""
(0 length string) rather than NA. You can convert that to NA like
this:

df2$NonAcceptanceOther[nchar(df2$NonAcceptanceOther) == 0]<-NA

Jim


On Thu, Jun 14, 2018 at 12:47 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
> Good morning.
>
> #I have df with a Factor column called "NonAcceptanceOther" that contains missing data.
>
> #Not every record in the df is expected to have a value in this column.
>
> # Typical values look like:
> # ERS
> # Claim paid without PHX recommended savings
> # Claim paid without PHX recommended savings
> # MRC Amount
> # MRC Amount
> # PPO per provider
> #Or they are missing (blank)
>
> #Example
>
> df2 <- df[,c("PlaceOfService","ClaimStatusID","NonAcceptanceOther","RejectionCodeID","CPTCats","RevCodeCats","GCode2","ClaimTypeID")]
> head(df2, n=20)
>
> PlaceOfService ClaimStatusID NonAcceptanceOther RejectionCodeID CPTCats RevCodeCats GCode2 ClaimTypeID
>
> 1 11 2 NA ResPSys NotValidRevCode 2 2
>
> 2 81 3 53 PathandLab NotValidRevCode 2 2
>
> 3 11 3 47 Medicine NotValidRevCode 1 2
>
> 4 09 2 NA NotCPT NotValidRevCode 1 2
>
> 5 11 2 NA Radiology NotValidRevCode 2 2
>
> 6 23 2 NA MusculoSys NotValidRevCode 2 2
>
> 7 12 3 47 NotCPT NotValidRevCode 2 2
>
> 8 12 2 NA Medicine NotValidRevCode 2 2
>
> 9 11 3 47 Medicine NotValidRevCode 1 2
>
> 10 21 2 NA Anesthesia NotValidRevCode 2 2
>
> 11 11 3 ERS 30 EvalandMgmt NotValidRevCode 2 2
>
> 12 81 2 NA PathandLab NotValidRevCode 2 2
>
> 13 21 2 NA Radiology NotValidRevCode 1 2
>
> 14 11 2 NA Medicine NotValidRevCode 1 2
>
> 15 99 3 Claim paid without PHX recommended savings 30 CardioHemLympSys Lab 0 1
>
> 16 99 3 Claim paid without PHX recommended savings 30 PathandLab Lab 0 1
>
> 17 99 3 MRC Amount 30 NotCPT Pharma 2 1
>
> 18 99 3 MRC Amount 30 PathandLab Lab 2 1
>
> 19 81 2 NA PathandLab NotValidRevCode 2 2
>
> 20 23 2 NA IntegSys NotValidRevCode 1 2
>
> #I would like to set these missing to NA and have them reflected similarly to an NA in a numeric or integer column if possible.
>
> #I have tried several approaches from Googled references:
>
> NonAcceptanceOther <- df$NonAcceptanceOther
> table(addNA(NonAcceptanceOther))
>
> is.na<http://is.na> <- df$NonAcceptanceOther
>
> df[NonAcceptanceOther == '' | NonAcceptanceOther == 'NA'] <- NA
>
> #However, when I go to use:
>
> missingDF <- PlotMissing(df)
>
> #Only the columns that are numeric or integer reflect their missing values (i.e. RejectionCodeID) and this "NonAcceptanceOther" column does not reflect or hold the NA values?
>
> Thank you for any advice.
>
> WHP
>
>
>
>
>
>
>
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:16}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Thu Jun 14 20:07:19 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Thu, 14 Jun 2018 11:07:19 -0700
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
 <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
Message-ID: <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>

Thanks for the replies. Wasn't aware that Gmail on Android sent HTML by
default, apologies. 

Storing the tableGrob-s in a list worked but for some reason grid.arrange complains on output from gtable_combine() using lists vs individual tableGrob-s. 

# works when supplying individual tableGrobs

p1<-gtable_combine(p11,p22, along=2)
p2<-gtable_combine(p11,p22, along=2)
grid.arrange(p1,p2,ncol=2)

# breaks when supplying a list of tableGrobs, error from grid.arrange()

p1<-gtable_combine(L1,along=2)
p2<-gtable_combine(L2,along=2)

grid.arrange(p1,p2,ncol=2)

Error in gList(list(list(grobs = list(list(label = "status", x = 0.5,? : 
? only 'grobs' allowed in "gList"

Also tried, still no go 

p1<-do.call(gtable_combine, list(L1,along=2))
p2<-do.call(gtable_combine, list(L2,along=2))




On Jun 13, 2018, 11:01 PM, at 11:01 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>?`[[`
>
>and read the discussions of indexing in the Introduction to R document
>that comes with R. Also, find a way to predict the number of elements
>you will need as making this a habit will pay off big time when you
>work with large amounts of data:
>
>L1<-vector( "list", N )
>for (i in seq.int( N )) {
>   L1[[i]] <-tableGrob( ... )
>}
>
>PS Post using your email program "plain text" mode... HTML gets
>stripped anyway and that often leads to partial corruption of your
>message. Read the Posting Guide.
>
>On June 13, 2018 4:43:21 PM HST, Stats Student
><stats.student4647 at gmail.com> wrote:
>>Hi, I'm trying to generate tableGrobs in a loop, store them in a list
>>so I
>>can use it in a call to gtable_combine().
>>
>>L1<-list()
>>for (i in seq( ... )) {
>>   L1[i] <-tableGrob( ... )
>>}
>>
>>gtable_combine(L1, along=1)
>>
>>On the assignment inside the loop, I get "number of items to replace
>is
>>not
>>a multiple of replacement length" which I'm guessing has to do with
>the
>>tableGrob object not "fitting" in the list but am not sure how to fix
>>it.
>>
>>Thanks in advance for any pointers.
>>
>>	[[alternative HTML version deleted]]
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Sent from my phone. Please excuse my brevity.



From pro|jcn@@h @end|ng |rom gm@||@com  Thu Jun 14 20:24:16 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Thu, 14 Jun 2018 14:24:16 -0400
Subject: [R] rJava woes on Linux Mint 18.3 Sylvia
Message-ID: <f380bbb0-d655-a0f7-046b-baa5cb37e801@gmail.com>

Answering my own post. On the particular machine in question, I managed to install rJava after installing
(in the OS) libbz2-dev and liblzma-dev. There was a hint of this in the install output,
but not as clear as would help a novice.

JN



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Jun 14 22:04:26 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (JEFFERY REICHMAN)
Date: Thu, 14 Jun 2018 20:04:26 +0000 (UTC)
Subject: [R] Kendall tau a, b, or c
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
Message-ID: <1241157164.481576.1529006666994@mail.yahoo.com>

r-help Forum

Is there a function to calculate either Kendall tau a, b, or c.  It appears the Kendall library only calculates tau b.  Just wanted to check before writing a function to calculate the concordant and discordant pairs. Then its pretty easy.

jeff



From m@rc_@chw@rtz @end|ng |rom me@com  Thu Jun 14 23:06:38 2018
From: m@rc_@chw@rtz @end|ng |rom me@com (Marc Schwartz)
Date: Thu, 14 Jun 2018 17:06:38 -0400
Subject: [R] Kendall tau a, b, or c
In-Reply-To: <1241157164.481576.1529006666994@mail.yahoo.com>
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
 <1241157164.481576.1529006666994@mail.yahoo.com>
Message-ID: <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>


> On Jun 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net> wrote:
> 
> r-help Forum
> 
> Is there a function to calculate either Kendall tau a, b, or c.  It appears the Kendall library only calculates tau b.  Just wanted to check before writing a function to calculate the concordant and discordant pairs. Then its pretty easy.
> 
> jeff
> 


Hi Jeff,

Take a look at my Github Gist here:

 https://gist.github.com/marcschwartz/3665743

I have b and c (among other measures), and supporting functions to calculate concordant and discordant pairs.

Regards,

Marc Schwartz



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Jun 14 23:19:27 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 14 Jun 2018 16:19:27 -0500
Subject: [R] Kendall tau a, b, or c
In-Reply-To: <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
 <1241157164.481576.1529006666994@mail.yahoo.com>
 <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>
Message-ID: <000001d40425$60fde4e0$22f9aea0$@sbcglobal.net>

Marc

Thank you - that will save me some time.

Jeff

-----Original Message-----
From: Marc Schwartz <marc_schwartz at me.com> 
Sent: Thursday, June 14, 2018 4:07 PM
To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>
Cc: R-help <r-help at R-project.org>
Subject: Re: [R] Kendall tau a, b, or c


> On Jun 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net>
wrote:
> 
> r-help Forum
> 
> Is there a function to calculate either Kendall tau a, b, or c.  It
appears the Kendall library only calculates tau b.  Just wanted to check
before writing a function to calculate the concordant and discordant pairs.
Then its pretty easy.
> 
> jeff
> 


Hi Jeff,

Take a look at my Github Gist here:

 https://gist.github.com/marcschwartz/3665743

I have b and c (among other measures), and supporting functions to calculate
concordant and discordant pairs.

Regards,

Marc Schwartz



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun 15 03:30:33 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 14 Jun 2018 15:30:33 -1000
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
 <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
 <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>
Message-ID: <0398F3BA-3D1E-4123-87CD-759FECE97849@dcn.davis.ca.us>

I don't know gtable_combine well enough to answer based on hand waving. A reproducible example is more likely to tempt someone to dig a little.

On June 14, 2018 8:07:19 AM HST, Stats Student <stats.student4647 at gmail.com> wrote:
>Thanks for the replies. Wasn't aware that Gmail on Android sent HTML by
>default, apologies.
>
>Storing the tableGrob-s in a list worked but for some reason
>grid.arrange complains on output from gtable_combine() using lists vs
>individual tableGrob-s.
>
># works when supplying individual tableGrobs
>
>p1<-gtable_combine(p11,p22, along=2)
>p2<-gtable_combine(p11,p22, along=2)
>grid.arrange(p1,p2,ncol=2)
>
># breaks when supplying a list of tableGrobs, error from grid.arrange()
>
>p1<-gtable_combine(L1,along=2)
>p2<-gtable_combine(L2,along=2)
>
>grid.arrange(p1,p2,ncol=2)
>
>Error in gList(list(list(grobs = list(list(label = "status", x = 0.5,?
>: 
>? only 'grobs' allowed in "gList"
>
>Also tried, still no go
>
>p1<-do.call(gtable_combine, list(L1,along=2))
>p2<-do.call(gtable_combine, list(L2,along=2))
>
>
>
>
>On Jun 13, 2018, 11:01 PM, at 11:01 PM, Jeff Newmiller
><jdnewmil at dcn.davis.ca.us> wrote:
>>?`[[`
>>
>>and read the discussions of indexing in the Introduction to R document
>>that comes with R. Also, find a way to predict the number of elements
>>you will need as making this a habit will pay off big time when you
>>work with large amounts of data:
>>
>>L1<-vector( "list", N )
>>for (i in seq.int( N )) {
>>   L1[[i]] <-tableGrob( ... )
>>}
>>
>>PS Post using your email program "plain text" mode... HTML gets
>>stripped anyway and that often leads to partial corruption of your
>>message. Read the Posting Guide.
>>
>>On June 13, 2018 4:43:21 PM HST, Stats Student
>><stats.student4647 at gmail.com> wrote:
>>>Hi, I'm trying to generate tableGrobs in a loop, store them in a list
>>>so I
>>>can use it in a call to gtable_combine().
>>>
>>>L1<-list()
>>>for (i in seq( ... )) {
>>>   L1[i] <-tableGrob( ... )
>>>}
>>>
>>>gtable_combine(L1, along=1)
>>>
>>>On the assignment inside the loop, I get "number of items to replace
>>is
>>>not
>>>a multiple of replacement length" which I'm guessing has to do with
>>the
>>>tableGrob object not "fitting" in the list but am not sure how to fix
>>>it.
>>>
>>>Thanks in advance for any pointers.
>>>
>>>	[[alternative HTML version deleted]]
>>>
>>>______________________________________________
>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>PLEASE do read the posting guide
>>>http://www.R-project.org/posting-guide.html
>>>and provide commented, minimal, self-contained, reproducible code.
>>
>>--
>>Sent from my phone. Please excuse my brevity.

-- 
Sent from my phone. Please excuse my brevity.



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Fri Jun 15 03:42:02 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Thu, 14 Jun 2018 18:42:02 -0700
Subject: [R] Storing tableGrobs in a list
In-Reply-To: <0398F3BA-3D1E-4123-87CD-759FECE97849@dcn.davis.ca.us>
References: <CAMZO7wJ2h1XGBMsMTT03SH7r9zFropyvF6N=b_tiOv06ObGzFg@mail.gmail.com>
 <E22A139F-4248-40A0-9E8B-97580A217DB7@dcn.davis.ca.us>
 <331f694a-3312-4cbd-8788-ca65da668eed@gmail.com>
 <0398F3BA-3D1E-4123-87CD-759FECE97849@dcn.davis.ca.us>
Message-ID: <490dd737-6f65-4d4d-baf1-8830a95373ec@gmail.com>

Thanks. The trick was in the do.call() syntax -

p1<-do.call(gtable_combine, c(L1, list(along=2)))



On Jun 14, 2018, 6:30 PM, at 6:30 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>I don't know gtable_combine well enough to answer based on hand waving.
>A reproducible example is more likely to tempt someone to dig a little.
>
>On June 14, 2018 8:07:19 AM HST, Stats Student
><stats.student4647 at gmail.com> wrote:
>>Thanks for the replies. Wasn't aware that Gmail on Android sent HTML
>by
>>default, apologies.
>>
>>Storing the tableGrob-s in a list worked but for some reason
>>grid.arrange complains on output from gtable_combine() using lists vs
>>individual tableGrob-s.
>>
>># works when supplying individual tableGrobs
>>
>>p1<-gtable_combine(p11,p22, along=2)
>>p2<-gtable_combine(p11,p22, along=2)
>>grid.arrange(p1,p2,ncol=2)
>>
>># breaks when supplying a list of tableGrobs, error from
>grid.arrange()
>>
>>p1<-gtable_combine(L1,along=2)
>>p2<-gtable_combine(L2,along=2)
>>
>>grid.arrange(p1,p2,ncol=2)
>>
>>Error in gList(list(list(grobs = list(list(label = "status", x = 0.5,?
>>: 
>>? only 'grobs' allowed in "gList"
>>
>>Also tried, still no go
>>
>>p1<-do.call(gtable_combine, list(L1,along=2))
>>p2<-do.call(gtable_combine, list(L2,along=2))
>>
>>
>>
>>
>>On Jun 13, 2018, 11:01 PM, at 11:01 PM, Jeff Newmiller
>><jdnewmil at dcn.davis.ca.us> wrote:
>>>?`[[`
>>>
>>>and read the discussions of indexing in the Introduction to R
>document
>>>that comes with R. Also, find a way to predict the number of elements
>>>you will need as making this a habit will pay off big time when you
>>>work with large amounts of data:
>>>
>>>L1<-vector( "list", N )
>>>for (i in seq.int( N )) {
>>>   L1[[i]] <-tableGrob( ... )
>>>}
>>>
>>>PS Post using your email program "plain text" mode... HTML gets
>>>stripped anyway and that often leads to partial corruption of your
>>>message. Read the Posting Guide.
>>>
>>>On June 13, 2018 4:43:21 PM HST, Stats Student
>>><stats.student4647 at gmail.com> wrote:
>>>>Hi, I'm trying to generate tableGrobs in a loop, store them in a
>list
>>>>so I
>>>>can use it in a call to gtable_combine().
>>>>
>>>>L1<-list()
>>>>for (i in seq( ... )) {
>>>>   L1[i] <-tableGrob( ... )
>>>>}
>>>>
>>>>gtable_combine(L1, along=1)
>>>>
>>>>On the assignment inside the loop, I get "number of items to replace
>>>is
>>>>not
>>>>a multiple of replacement length" which I'm guessing has to do with
>>>the
>>>>tableGrob object not "fitting" in the list but am not sure how to
>fix
>>>>it.
>>>>
>>>>Thanks in advance for any pointers.
>>>>
>>>>	[[alternative HTML version deleted]]
>>>>
>>>>______________________________________________
>>>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>>>https://stat.ethz.ch/mailman/listinfo/r-help
>>>>PLEASE do read the posting guide
>>>>http://www.R-project.org/posting-guide.html
>>>>and provide commented, minimal, self-contained, reproducible code.
>>>
>>>--
>>>Sent from my phone. Please excuse my brevity.
>
>-- 
>Sent from my phone. Please excuse my brevity.



From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Jun 15 13:18:38 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 15 Jun 2018 11:18:38 +0000
Subject: [R] inconsistency in parallel processing in R.....
Message-ID: <SLXP216MB00933EF9550FC45439D4C75EC87C0@SLXP216MB0093.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am using the "parallel" package in R. I am using the following function to automate the process of starting the cluster(the function is named preparePP):

function (vte) {
                nc <- detectCores()
                cl <- makeCluster(nc)
                clusterExport(cl,vte)
                clusterEvalQ(cl,{ld.packages()})


}
<bytecode: 0x0b787508>

vte is the character vector of variables to be exported and ld.packages is the function that loads all the required packages.

However, when I run the  preparePP function at the beginning of the session, it frequently throws up the following error:

Error in summary.connection(connection) : invalid connection

Sometimes the function stands but othertimes it throws up the above error. But when I run the individual functions of preparePP independently at the R console, the cluster object "cl" stays put for the whole session( parLapply works all the time it is called):

> nc <- detectCores()
> cl <- makeCluster(nc)
> clusterExport(cl,vte)
> clusterEvalQ(cl,{ld.packages()})

What is wrong with preparePP?

very many thanks for your time and effort.....

yours sincerely,
AKSHAY M KULKARNI







	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Fri Jun 15 15:31:55 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Fri, 15 Jun 2018 13:31:55 +0000
Subject: [R] Kendall tau a, b, or c
In-Reply-To: <000001d40425$60fde4e0$22f9aea0$@sbcglobal.net>
References: <1241157164.481576.1529006666994.ref@mail.yahoo.com>
 <1241157164.481576.1529006666994@mail.yahoo.com>
 <F21D99B3-7FAD-41A5-AAD7-CD0161E88311@me.com>
 <000001d40425$60fde4e0$22f9aea0$@sbcglobal.net>
Message-ID: <38af0f89b53e4d629ef70c53a5fd54af@tamu.edu>

Also look at the DescTools package for functions KendallTauA, KendallTauB, StuartTauC().  

----------------------------------------
David L Carlson
Department of Anthropology
Texas A&M University
College Station, TX 77843-4352

-----Original Message-----
From: R-help <r-help-bounces at r-project.org> On Behalf Of Jeff Reichman
Sent: Thursday, June 14, 2018 4:19 PM
To: 'Marc Schwartz' <marc_schwartz at me.com>
Cc: 'R-help' <r-help at R-project.org>
Subject: Re: [R] Kendall tau a, b, or c

Marc

Thank you - that will save me some time.

Jeff

-----Original Message-----
From: Marc Schwartz <marc_schwartz at me.com> 
Sent: Thursday, June 14, 2018 4:07 PM
To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>
Cc: R-help <r-help at R-project.org>
Subject: Re: [R] Kendall tau a, b, or c


> On Jun 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net>
wrote:
> 
> r-help Forum
> 
> Is there a function to calculate either Kendall tau a, b, or c.  It
appears the Kendall library only calculates tau b.  Just wanted to check
before writing a function to calculate the concordant and discordant pairs.
Then its pretty easy.
> 
> jeff
> 


Hi Jeff,

Take a look at my Github Gist here:

 https://gist.github.com/marcschwartz/3665743

I have b and c (among other measures), and supporting functions to calculate
concordant and discordant pairs.

Regards,

Marc Schwartz

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From pe|j@@z @end|ng |rom y@hoo@co@uk  Fri Jun 15 16:49:17 2018
From: pe|j@@z @end|ng |rom y@hoo@co@uk (lejeczek)
Date: Fri, 15 Jun 2018 15:49:17 +0100
Subject: [R] mzR fails to install/compile (linuxes)
Message-ID: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>

hi guys, just an admin here.

I wonder if anybody see what I see, or similar? I'm on Centos 7.x and 
this occurs with R 3.4.x 3.5.x and probably earlier versions too.

Every time I use something like -j>1 to pass to a compiler, eg.echo -ne

$ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n 
source(\"https://bioconductor.org/biocLite.R\")\\n biocLite(c(\"mzR\"), 
suppressUpdates=FALSE, suppressAutoUpdate=FALSE, ask=FALSE)" | 
/usr/bin/R --vanilla

mzR fails to compile:
...
g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so 
cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o 
RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o 
./boost/libs/system/src/error_code.o ./boost/libs/regex/src/posix_api.o 
./boost/libs/regex/src/fileiter.o 
./boost/libs/regex/src/regex_raw_buffer.o 
./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o 
./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o 
./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o 
./boost/libs/regex/src/wide_posix_api.o 
./boost/libs/regex/src/regex_traits_defaults.o 
./boost/libs/regex/src/winstances.o 
./boost/libs/regex/src/wc_regex_traits.o 
./boost/libs/regex/src/c_regex_traits.o 
./boost/libs/regex/src/cpp_regex_traits.o 
./boost/libs/regex/src/static_mutex.o 
./boost/libs/regex/src/w32_regex_traits.o 
./boost/libs/iostreams/src/zlib.o 
./boost/libs/iostreams/src/file_descriptor.o 
./boost/libs/filesystem/src/operations.o 
./boost/libs/filesystem/src/path.o 
./boost/libs/filesystem/src/utf8_codecvt_facet.o 
./boost/libs/chrono/src/chrono.o 
./boost/libs/chrono/src/process_cpu_clocks.o 
./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o 
./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o 
./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o 
./pwiz/data/common/ParamTypes.o ./pwiz/data/common/BinaryIndexStream.o 
./pwiz/data/common/diff_std.o ./pwiz/data/common/Unimod.o 
./pwiz/data/msdata/mz5/Configuration_mz5.o 
./pwiz/data/msdata/mz5/Connection_mz5.o 
./pwiz/data/msdata/mz5/Datastructures_mz5.o 
./pwiz/data/msdata/mz5/ReferenceRead_mz5.o 
./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o 
./pwiz/data/msdata/mz5/Translator_mz5.o 
./pwiz/data/msdata/SpectrumList_MGF.o 
./pwiz/data/msdata/DefaultReaderList.o 
./pwiz/data/msdata/ChromatogramList_mzML.o 
./pwiz/data/msdata/ChromatogramList_mz5.o ./pwiz/data/msdata/examples.o 
./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o 
./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_mz5.o 
./pwiz/data/msdata/Serializer_MGF.o 
./pwiz/data/msdata/Serializer_mzXML.o 
./pwiz/data/msdata/SpectrumList_mzML.o 
./pwiz/data/msdata/SpectrumList_MSn.o 
./pwiz/data/msdata/SpectrumList_mz5.o 
./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o 
./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o 
./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o 
./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o 
./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o 
./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o 
./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o 
./pwiz/data/msdata/Index_mzML.o 
./pwiz/data/msdata/SpectrumWorkerThreads.o 
./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o 
./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o 
./pwiz/data/identdata/Serializer_protXML.o 
./pwiz/data/identdata/Serializer_pepXML.o 
./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o 
./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o 
./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o 
./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o 
./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o 
./pwiz/utility/chemistry/Chemistry.o 
./pwiz/utility/chemistry/ChemistryData.o 
./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o 
./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o 
./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o 
./pwiz/utility/misc/TabReader.o 
./pwiz/utility/misc/random_access_compressed_ifstream.o 
./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o 
./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o 
./boost/libs/thread/src/pthread/once.o 
./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o -lpthread 
/usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a 
/usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a 
/usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ 
-lnetcdf -L/usr/lib64/R/lib -lR
g++: error: cramp.o: No such file or directory
make: *** [mzR.so] Error 1
ERROR: compilation failed for package ?mzR?
* removing ?/usr/lib64/R/library/mzR?

If j is 1, then compilation succeeds.
I have hundreds of packages and so far only "mzR" and "MSnbase" fail if 
I compile with -j>1.

Would anybody be able to confirm this problem exists?
Many thanks, L.



From pe|j@@z @end|ng |rom y@hoo@co@uk  Fri Jun 15 17:58:58 2018
From: pe|j@@z @end|ng |rom y@hoo@co@uk (lejeczek)
Date: Fri, 15 Jun 2018 16:58:58 +0100
Subject: [R] rgdal in 3.5 fails(?)
Message-ID: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>

hi there

installation of the package fails:

...

g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g 
-pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector-strong --param=ssp-buffer-size=4 
-grecord-gcc-switches?? -m64 -mtune=generic -c OGR_write.cpp -o OGR_write.o
g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
-I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g 
-pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
-fstack-protector-strong --param=ssp-buffer-size=4 
-grecord-gcc-switches?? -m64 -mtune=generic -c gdal-bindings.cpp -o 
gdal-bindings.o
gdal-bindings.cpp: In function ?SEXPREC* RGDAL_GDALwithGEOS()?:
gdal-bindings.cpp:334:81: error: no matching function for call to 
?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
 ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
&poGeometry1 );
^
gdal-bindings.cpp:334:81: note: candidate is:
In file included from /usr/include/gdal/ogr_feature.h:34:0,
 ???????????????? from /usr/include/gdal/ogrsf_frmts.h:35,
 ???????????????? from gdal-bindings.cpp:7:
/usr/include/gdal/ogr_geometry.h:663:19: note: static OGRErr 
OGRGeometryFactory::createFromWkt(char**, OGRSpatialReference*, 
OGRGeometry**)
 ???? static OGRErr createFromWkt( char **, OGRSpatialReference *,
 ?????????????????? ^
/usr/include/gdal/ogr_geometry.h:663:19: note:?? no known conversion for 
argument 1 from ?const char*? to ?char**?
gdal-bindings.cpp:340:81: error: no matching function for call to 
?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
 ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
&poGeometry2 );


Would you know is this the package's problem in new 3.5 version?

Many thanks, L.



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Jun 15 18:07:13 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (JEFFERY REICHMAN)
Date: Fri, 15 Jun 2018 16:07:13 +0000 (UTC)
Subject: [R] Kendall tau a, b, or c
References: <1031061800.969830.1529078833258.ref@mail.yahoo.com>
Message-ID: <1031061800.969830.1529078833258@mail.yahoo.com>

Dr. Carlson

Yes, just became aware of the DescTools library after working off Marcs R Code last night. Oh well now I have two options. 

Thanks

Jeff
--------------------------------------------
On Fri, 6/15/18, David L Carlson <dcarlson at tamu.edu> wrote:

 Subject: RE: [R] Kendall tau a, b, or c
 To: "reichmanj at sbcglobal.net" <reichmanj at sbcglobal.net>, "'Marc Schwartz'" <marc_schwartz at me.com>
 Cc: "'R-help'" <r-help at R-project.org>
 Date: Friday, June 15, 2018, 8:31 AM

 Also look at the DescTools
 package for functions KendallTauA, KendallTauB,
 StuartTauC().? 

 ----------------------------------------
 David L Carlson
 Department of
 Anthropology
 Texas A&M University
 College Station, TX 77843-4352

 -----Original Message-----
 From: R-help <r-help-bounces at r-project.org>
 On Behalf Of Jeff Reichman
 Sent: Thursday,
 June 14, 2018 4:19 PM
 To: 'Marc
 Schwartz' <marc_schwartz at me.com>
 Cc: 'R-help' <r-help at R-project.org>
 Subject: Re: [R] Kendall tau a, b, or c

 Marc

 Thank you - that will save me some time.

 Jeff

 -----Original Message-----
 From: Marc Schwartz <marc_schwartz at me.com>

 Sent: Thursday, June 14, 2018 4:07 PM
 To: JEFFERY REICHMAN <reichmanj at sbcglobal.net>
 Cc: R-help <r-help at R-project.org>
 Subject: Re: [R] Kendall tau a, b, or c


 > On Jun
 14, 2018, at 4:04 PM, JEFFERY REICHMAN <reichmanj at sbcglobal.net>
 wrote:
 > 
 > r-help Forum
 > 
 > Is there a function to calculate either
 Kendall tau a, b, or c.? It
 appears the
 Kendall library only calculates tau b.? Just wanted to
 check
 before writing a function to calculate
 the concordant and discordant pairs.
 Then
 its pretty easy.
 > 
 >
 jeff
 > 


 Hi Jeff,

 Take a look at my Github Gist here:

  https://gist.github.com/marcschwartz/3665743

 I have b and c (among other
 measures), and supporting functions to calculate
 concordant and discordant pairs.

 Regards,

 Marc Schwartz

 ______________________________________________
 R-help at r-project.org
 mailing list -- To UNSUBSCRIBE and more, see
 https://stat.ethz.ch/mailman/listinfo/r-help
 PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
 and provide commented, minimal, self-contained,
 reproducible code.



From pro|jcn@@h @end|ng |rom gm@||@com  Fri Jun 15 18:31:04 2018
From: pro|jcn@@h @end|ng |rom gm@||@com (J C Nash)
Date: Fri, 15 Jun 2018 12:31:04 -0400
Subject: [R] rgdal in 3.5 fails(?)
In-Reply-To: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
References: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
Message-ID: <2e15eb9b-28a5-7ac4-9427-bd88c51aca25@gmail.com>

I just tested that it installs in Linux Mint 18.3, but I've had similar install problems recently where
I had to explicitly install some libraries in the OS. In some cases there were hints. I don't see anything
here that I recognize, but I do know in the past I've needed to install libgdal-dev.

JN

On 2018-06-15 11:58 AM, lejeczek via R-help wrote:
> hi there
> 
> installation of the package fails:
> 
> ...
> 
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal
> -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include
> -I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
> -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches?? -m64 -mtune=generic -c OGR_write.cpp -o
> OGR_write.o
> g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal
> -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include
> -I"/usr/lib64/R/library/sp/include" -I/usr/local/include?? -fpic -O2 -g -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions
> -fstack-protector-strong --param=ssp-buffer-size=4 -grecord-gcc-switches?? -m64 -mtune=generic -c gdal-bindings.cpp -o
> gdal-bindings.o
> gdal-bindings.cpp: In function ?SEXPREC* RGDAL_GDALwithGEOS()?:
> gdal-bindings.cpp:334:81: error: no matching function for call to ?OGRGeometryFactory::createFromWkt(const char*, NULL,
> OGRGeometry**)?
> ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, &poGeometry1 );
> ^
> gdal-bindings.cpp:334:81: note: candidate is:
> In file included from /usr/include/gdal/ogr_feature.h:34:0,
> ???????????????? from /usr/include/gdal/ogrsf_frmts.h:35,
> ???????????????? from gdal-bindings.cpp:7:
> /usr/include/gdal/ogr_geometry.h:663:19: note: static OGRErr OGRGeometryFactory::createFromWkt(char**,
> OGRSpatialReference*, OGRGeometry**)
> ???? static OGRErr createFromWkt( char **, OGRSpatialReference *,
> ?????????????????? ^
> /usr/include/gdal/ogr_geometry.h:663:19: note:?? no known conversion for argument 1 from ?const char*? to ?char**?
> gdal-bindings.cpp:340:81: error: no matching function for call to ?OGRGeometryFactory::createFromWkt(const char*, NULL,
> OGRGeometry**)?
> ???? OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, &poGeometry2 );
> 
> 
> Would you know is this the package's problem in new 3.5 version?
> 
> Many thanks, L.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Jun 15 20:10:20 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 15 Jun 2018 18:10:20 +0000
Subject: [R] rgdal in 3.5 fails(?)
In-Reply-To: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
References: <e2a1c0ce-f307-cbb8-d19d-6d816baccae4@yahoo.co.uk>
Message-ID: <A707ACC8-33A5-46FD-9477-62374ECB2224@llnl.gov>

In case no one else has made the suggestion yet, take this question to R-sig-geo, where there has already been discussion and sharing of information and experiences about this.

You'll need to include the output of sessionInfo().

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/15/18, 8:58 AM, "R-help on behalf of lejeczek via R-help" <r-help-bounces at r-project.org on behalf of r-help at r-project.org> wrote:

    hi there
    
    installation of the package fails:
    
    ...
    
    g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I"/usr/lib64/R/library/sp/include" -I/usr/local/include   -fpic -O2 -g 
    -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
    -fstack-protector-strong --param=ssp-buffer-size=4 
    -grecord-gcc-switches   -m64 -mtune=generic -c OGR_write.cpp -o OGR_write.o
    g++ -m64 -std=gnu++11 -I"/usr/include/R" -DNDEBUG -I/usr/include/gdal 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I/tmp/RtmpPEjOIB/R.INSTALL952df53b77184/rgdal/inst/include 
    -I"/usr/lib64/R/library/sp/include" -I/usr/local/include   -fpic -O2 -g 
    -pipe -Wall -Wp,-D_FORTIFY_SOURCE=2 -fexceptions 
    -fstack-protector-strong --param=ssp-buffer-size=4 
    -grecord-gcc-switches   -m64 -mtune=generic -c gdal-bindings.cpp -o 
    gdal-bindings.o
    gdal-bindings.cpp: In function ?SEXPREC* RGDAL_GDALwithGEOS()?:
    gdal-bindings.cpp:334:81: error: no matching function for call to 
    ?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
          OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
    &poGeometry1 );
    ^
    gdal-bindings.cpp:334:81: note: candidate is:
    In file included from /usr/include/gdal/ogr_feature.h:34:0,
                      from /usr/include/gdal/ogrsf_frmts.h:35,
                      from gdal-bindings.cpp:7:
    /usr/include/gdal/ogr_geometry.h:663:19: note: static OGRErr 
    OGRGeometryFactory::createFromWkt(char**, OGRSpatialReference*, 
    OGRGeometry**)
          static OGRErr createFromWkt( char **, OGRSpatialReference *,
                        ^
    /usr/include/gdal/ogr_geometry.h:663:19: note:   no known conversion for 
    argument 1 from ?const char*? to ?char**?
    gdal-bindings.cpp:340:81: error: no matching function for call to 
    ?OGRGeometryFactory::createFromWkt(const char*, NULL, OGRGeometry**)?
          OGRGeometryFactory::createFromWkt( (const char*) pszWKT, NULL, 
    &poGeometry2 );
    
    
    Would you know is this the package's problem in new 3.5 version?
    
    Many thanks, L.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From pd@|gd @end|ng |rom gm@||@com  Sat Jun 16 12:27:59 2018
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Sat, 16 Jun 2018 12:27:59 +0200
Subject: [R] mzR fails to install/compile (linuxes)
In-Reply-To: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
References: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
Message-ID: <FC7A3172-EDF4-4586-BCE3-2301B38C69FE@gmail.com>

This is almost certainly a Makefile error. Something (A) is relying on something (B) without stating the dependency explicitly in the Makefile. You can get away with that (sometimes) in a non-parallel make, because the sequence of compilations is such that B gets built before A. However, with a parallel make, one thread may try to build A before B gets built by another thread. 

The fix is to add the dependency in the Makefile (plus any other issues of the same kind). In this case, AFAICT, you need

mzR.so: cramp.o

in addition to what might be there already and any other stuff that is also missing. If there is already something like

mzR.so: $(OBJECTS)

chances are that there is a deficient macro definition earlier on, so that cramp.o is not contained in OBJECTS.

-pd

> On 15 Jun 2018, at 16:49 , lejeczek via R-help <r-help at r-project.org> wrote:
> 
> hi guys, just an admin here.
> 
> I wonder if anybody see what I see, or similar? I'm on Centos 7.x and this occurs with R 3.4.x 3.5.x and probably earlier versions too.
> 
> Every time I use something like -j>1 to pass to a compiler, eg.echo -ne
> 
> $ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n source(\"https://bioconductor.org/biocLite.R\")\\n biocLite(c(\"mzR\"), suppressUpdates=FALSE, suppressAutoUpdate=FALSE, ask=FALSE)" | /usr/bin/R --vanilla
> 
> mzR fails to compile:
> ...
> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o ./boost/libs/system/src/error_code.o ./boost/libs/regex/src/posix_api.o ./boost/libs/regex/src/fileiter.o ./boost/libs/regex/src/regex_raw_buffer.o ./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o ./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o ./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o ./boost/libs/regex/src/wide_posix_api.o ./boost/libs/regex/src/regex_traits_defaults.o ./boost/libs/regex/src/winstances.o ./boost/libs/regex/src/wc_regex_traits.o ./boost/libs/regex/src/c_regex_traits.o ./boost/libs/regex/src/cpp_regex_traits.o ./boost/libs/regex/src/static_mutex.o ./boost/libs/regex/src/w32_regex_traits.o ./boost/libs/iostreams/src/zlib.o ./boost/libs/iostreams/src/file_descriptor.o ./boost/libs/filesystem/src/operations.o ./boost/libs/filesystem/src/path.o ./boost/libs/filesystem/src/utf8_codecvt_facet.o ./boost/libs/chrono/src/chrono.o ./boost/libs/chrono/src/process_cpu_clocks.o ./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o ./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o ./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o ./pwiz/data/common/ParamTypes.o ./pwiz/data/common/BinaryIndexStream.o ./pwiz/data/common/diff_std.o ./pwiz/data/common/Unimod.o ./pwiz/data/msdata/mz5/Configuration_mz5.o ./pwiz/data/msdata/mz5/Connection_mz5.o ./pwiz/data/msdata/mz5/Datastructures_mz5.o ./pwiz/data/msdata/mz5/ReferenceRead_mz5.o ./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o ./pwiz/data/msdata/mz5/Translator_mz5.o ./pwiz/data/msdata/SpectrumList_MGF.o ./pwiz/data/msdata/DefaultReaderList.o ./pwiz/data/msdata/ChromatogramList_mzML.o ./pwiz/data/msdata/ChromatogramList_mz5.o ./pwiz/data/msdata/examples.o ./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o ./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_mz5.o ./pwiz/data/msdata/Serializer_MGF.o ./pwiz/data/msdata/Serializer_mzXML.o ./pwiz/data/msdata/SpectrumList_mzML.o ./pwiz/data/msdata/SpectrumList_MSn.o ./pwiz/data/msdata/SpectrumList_mz5.o ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o ./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o ./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o ./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o ./pwiz/data/msdata/Index_mzML.o ./pwiz/data/msdata/SpectrumWorkerThreads.o ./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o ./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o ./pwiz/data/identdata/Serializer_protXML.o ./pwiz/data/identdata/Serializer_pepXML.o ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o ./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o ./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o ./pwiz/utility/chemistry/Chemistry.o ./pwiz/utility/chemistry/ChemistryData.o ./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o ./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o ./pwiz/utility/misc/TabReader.o ./pwiz/utility/misc/random_access_compressed_ifstream.o ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o ./boost/libs/thread/src/pthread/once.o ./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o -lpthread /usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a /usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a /usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ -lnetcdf -L/usr/lib64/R/lib -lR
> g++: error: cramp.o: No such file or directory
> make: *** [mzR.so] Error 1
> ERROR: compilation failed for package ?mzR?
> * removing ?/usr/lib64/R/library/mzR?
> 
> If j is 1, then compilation succeeds.
> I have hundreds of packages and so far only "mzR" and "MSnbase" fail if I compile with -j>1.
> 
> Would anybody be able to confirm this problem exists?
> Many thanks, L.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From c@b@@tr|de @end|ng |rom @he|||e|d@@c@uk  Sat Jun 16 13:00:23 2018
From: c@b@@tr|de @end|ng |rom @he|||e|d@@c@uk (Chris Stride)
Date: Sat, 16 Jun 2018 12:00:23 +0100
Subject: [R] specifying random effects covariance structure in nlme
Message-ID: <8c10f484-8a04-5448-edc5-30846301aaf7@sheffield.ac.uk>

Hi

I'm trying to fit a mixed effects exponential decay model, in which I 
have random effects for the initial value (init), the asymptote (asymp), 
and the rate (rate).

The catch is that I'd also like to estimate the correlation between init 
and asymp, but not between init and rate, or asymp and rate.

Now using? random = pdDiag(init + asymp + rate ~ 1) has none of the 
random effects correlated

And using? random = pdSymm(init + asymp + rate ~ 1) has all three of the 
random effects correlated

How do I specify just the correlation I want?

cheers

Chris



From m@rt|n@morg@n @end|ng |rom ro@we||p@rk@org  Sat Jun 16 14:09:26 2018
From: m@rt|n@morg@n @end|ng |rom ro@we||p@rk@org (Martin Morgan)
Date: Sat, 16 Jun 2018 08:09:26 -0400
Subject: [R] mzR fails to install/compile (linuxes)
In-Reply-To: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
References: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
Message-ID: <f3f77e1c-cd98-310d-3a04-a789730d96d7@roswellpark.org>

mzR is a Bioconductor package so you might have more luck contacting the 
maintainer on the Bioconductor support site

   https://support.bioconductor.org

or on the 'bioc-devel' mailing list

   https://stat.ethz.ch/mailman/listinfo/bioc-devel

or most directly by opening an issue on the maintainer's github

   https://github.com/sneumann/mzR/issues/

this is linked to from the package 'landing page'

   https://bioconductor.org/packages/mzR

Martin Morgan

On 06/15/2018 10:49 AM, lejeczek via R-help wrote:
> hi guys, just an admin here.
> 
> I wonder if anybody see what I see, or similar? I'm on Centos 7.x and 
> this occurs with R 3.4.x 3.5.x and probably earlier versions too.
> 
> Every time I use something like -j>1 to pass to a compiler, eg.echo -ne
> 
> $ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n 
> source(\"https://bioconductor.org/biocLite.R\")\\n biocLite(c(\"mzR\"), 
> suppressUpdates=FALSE, suppressAutoUpdate=FALSE, ask=FALSE)" | 
> /usr/bin/R --vanilla
> 
> mzR fails to compile:
> ...
> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o mzR.so 
> cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o rnetCDF.o 
> RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o 
> ./boost/libs/system/src/error_code.o ./boost/libs/regex/src/posix_api.o 
> ./boost/libs/regex/src/fileiter.o 
> ./boost/libs/regex/src/regex_raw_buffer.o 
> ./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o 
> ./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o 
> ./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o 
> ./boost/libs/regex/src/wide_posix_api.o 
> ./boost/libs/regex/src/regex_traits_defaults.o 
> ./boost/libs/regex/src/winstances.o 
> ./boost/libs/regex/src/wc_regex_traits.o 
> ./boost/libs/regex/src/c_regex_traits.o 
> ./boost/libs/regex/src/cpp_regex_traits.o 
> ./boost/libs/regex/src/static_mutex.o 
> ./boost/libs/regex/src/w32_regex_traits.o 
> ./boost/libs/iostreams/src/zlib.o 
> ./boost/libs/iostreams/src/file_descriptor.o 
> ./boost/libs/filesystem/src/operations.o 
> ./boost/libs/filesystem/src/path.o 
> ./boost/libs/filesystem/src/utf8_codecvt_facet.o 
> ./boost/libs/chrono/src/chrono.o 
> ./boost/libs/chrono/src/process_cpu_clocks.o 
> ./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o 
> ./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o 
> ./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o 
> ./pwiz/data/common/ParamTypes.o ./pwiz/data/common/BinaryIndexStream.o 
> ./pwiz/data/common/diff_std.o ./pwiz/data/common/Unimod.o 
> ./pwiz/data/msdata/mz5/Configuration_mz5.o 
> ./pwiz/data/msdata/mz5/Connection_mz5.o 
> ./pwiz/data/msdata/mz5/Datastructures_mz5.o 
> ./pwiz/data/msdata/mz5/ReferenceRead_mz5.o 
> ./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o 
> ./pwiz/data/msdata/mz5/Translator_mz5.o 
> ./pwiz/data/msdata/SpectrumList_MGF.o 
> ./pwiz/data/msdata/DefaultReaderList.o 
> ./pwiz/data/msdata/ChromatogramList_mzML.o 
> ./pwiz/data/msdata/ChromatogramList_mz5.o ./pwiz/data/msdata/examples.o 
> ./pwiz/data/msdata/Serializer_mzML.o ./pwiz/data/msdata/Serializer_MSn.o 
> ./pwiz/data/msdata/Reader.o ./pwiz/data/msdata/Serializer_mz5.o 
> ./pwiz/data/msdata/Serializer_MGF.o 
> ./pwiz/data/msdata/Serializer_mzXML.o 
> ./pwiz/data/msdata/SpectrumList_mzML.o 
> ./pwiz/data/msdata/SpectrumList_MSn.o 
> ./pwiz/data/msdata/SpectrumList_mz5.o 
> ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o 
> ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o 
> ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o 
> ./pwiz/data/msdata/SpectrumList_BTDX.o ./pwiz/data/msdata/SpectrumInfo.o 
> ./pwiz/data/msdata/RAMPAdapter.o ./pwiz/data/msdata/LegacyAdapter.o 
> ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o 
> ./pwiz/data/msdata/MSNumpress.o ./pwiz/data/msdata/SpectrumListCache.o 
> ./pwiz/data/msdata/Index_mzML.o 
> ./pwiz/data/msdata/SpectrumWorkerThreads.o 
> ./pwiz/data/identdata/IdentDataFile.o ./pwiz/data/identdata/IdentData.o 
> ./pwiz/data/identdata/DefaultReaderList.o ./pwiz/data/identdata/Reader.o 
> ./pwiz/data/identdata/Serializer_protXML.o 
> ./pwiz/data/identdata/Serializer_pepXML.o 
> ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o 
> ./pwiz/data/identdata/References.o ./pwiz/data/identdata/MascotReader.o 
> ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o 
> ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o 
> ./pwiz/utility/minimxml/XMLWriter.o ./pwiz/utility/minimxml/SAXParser.o 
> ./pwiz/utility/chemistry/Chemistry.o 
> ./pwiz/utility/chemistry/ChemistryData.o 
> ./pwiz/utility/chemistry/MZTolerance.o ./pwiz/utility/misc/IntegerSet.o 
> ./pwiz/utility/misc/Base64.o ./pwiz/utility/misc/IterationListener.o 
> ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o 
> ./pwiz/utility/misc/TabReader.o 
> ./pwiz/utility/misc/random_access_compressed_ifstream.o 
> ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o 
> ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o ./RcppExports.o 
> ./boost/libs/thread/src/pthread/once.o 
> ./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o -lpthread 
> /usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a 
> /usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a 
> /usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ 
> -lnetcdf -L/usr/lib64/R/lib -lR
> g++: error: cramp.o: No such file or directory
> make: *** [mzR.so] Error 1
> ERROR: compilation failed for package ?mzR?
> * removing ?/usr/lib64/R/library/mzR?
> 
> If j is 1, then compilation succeeds.
> I have hundreds of packages and so far only "mzR" and "MSnbase" fail if 
> I compile with -j>1.
> 
> Would anybody be able to confirm this problem exists?
> Many thanks, L.
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


This email message may contain legally privileged and/or...{{dropped:2}}



From pd@|gd @end|ng |rom gm@||@com  Sat Jun 16 15:18:36 2018
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Sat, 16 Jun 2018 15:18:36 +0200
Subject: [R] specifying random effects covariance structure in nlme
In-Reply-To: <8c10f484-8a04-5448-edc5-30846301aaf7@sheffield.ac.uk>
References: <8c10f484-8a04-5448-edc5-30846301aaf7@sheffield.ac.uk>
Message-ID: <B815AB0D-25F3-4E28-9BC3-F3BDB84ED73F@gmail.com>

I haven't played with this for a decade or so, but I believe you can do something with pdBlocked(). Possibly ask over on R-sig-ME as this quickly gets beyond the R-help level.

(Also, you are aware that it is not about what you want to estimate, but whether you believe the correlations are nonzero?)

-pd

> On 16 Jun 2018, at 13:00 , Chris Stride <c.b.stride at sheffield.ac.uk> wrote:
> 
> Hi
> 
> I'm trying to fit a mixed effects exponential decay model, in which I have random effects for the initial value (init), the asymptote (asymp), and the rate (rate).
> 
> The catch is that I'd also like to estimate the correlation between init and asymp, but not between init and rate, or asymp and rate.
> 
> Now using  random = pdDiag(init + asymp + rate ~ 1) has none of the random effects correlated
> 
> And using  random = pdSymm(init + asymp + rate ~ 1) has all three of the random effects correlated
> 
> How do I specify just the correlation I want?
> 
> cheers
> 
> Chris
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From h@nn@hvnoort @end|ng |rom gm@||@com  Sat Jun 16 22:37:08 2018
From: h@nn@hvnoort @end|ng |rom gm@||@com (Hannah van Noort)
Date: Sat, 16 Jun 2018 22:37:08 +0200
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
Message-ID: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>

Hi everyone,

I'm having trouble running a PGLS model with the package "AICmodavg". I
continuously get the error of false convergence with certain Lambda
values (even
when trying to run the model with different Lambda values) and for other La
mbda values I run into "error in eigen(val) : infinite or missing values in
'X' ". I've tried several optimizers and removing some outlier values but
the same errors keep on popping up.. Does anyone know how to solve this
problem?
Below a part of my script with the specific dependent and independent varia
bles and I've also attached files with the relevant data and phylogenetic
tree information.

Cand.models = list()
niter = 100
for (i in 1:niter) {
  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av), data =
d, method= "ML", na.action=na.omit
                         correlation = corPagel(value=0.4, trees[[i]]))
}

Thank you in advance for any help, it's much appreciated!

Kind regards,

Hannah van Noort

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Seabirddat_growth.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180616/c5e8bbad/attachment-0002.txt>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jun 17 07:27:01 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sat, 16 Jun 2018 22:27:01 -0700
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
Message-ID: <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>


> On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
> 
> Hi everyone,
> 
> I'm having trouble running a PGLS model with the package "AICmodavg".

Did you mean "AICmodavg"?


> I
> continuously get the error of false convergence with certain Lambda
> values (even
> when trying to run the model with different Lambda values) and for other La
> mbda values I run into "error in eigen(val) : infinite or missing values in
> 'X' ". I've tried several optimizers and removing some outlier values but
> the same errors keep on popping up.. Does anyone know how to solve this
> problem?
> Below a part of my script with the specific dependent and independent varia
> bles and I've also attached files with the relevant data and phylogenetic
> tree information.

d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
library(AICmodavg)
Error in library(AICmodavg) : there is no package called ?AICmodavg?
library(AICcmodavg)
> 
> Cand.models = list()
> niter = 100
> for (i in 1:niter) {
>  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),

A syntax error is thrown here -------------------------------------^  #removed paren
> data =
> d, method= "ML", na.action=na.omit

And here ---------------------------^
>                         correlation = corPagel(value=0.4, trees[[i]]))

And after fixing these errors I get the error that `gls` is not found (even after adding `library(AICcmodavg)`

 could not find function "gls"
> ?corPagel
No documentation for ?corPagel? in specified packages and libraries:
you could try ???corPagel?
> ??gls
> library(nlme)

Attaching package: ?nlme?

The following object is masked from ?package:dplyr?:

    collapse

> Cand.models = list()
> niter = 100
> for (i in 1:niter) {
+  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
+ d, method= "ML", na.action=na.omit,
+                         correlation = corPagel(value=0.4, trees[[i]]) )
+ }
Error in corPagel(value = 0.4, trees[[i]]) : 
  could not find function "corPagel"
> ??corPagel
> library(ape)

Attaching package: ?ape?

The following object is masked from ?package:Hmisc?:

    zoom

> Cand.models = list()
> niter = 100
> for (i in 1:niter) {
+  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
+ d, method= "ML", na.action=na.omit,
+                         correlation = corPagel(value=0.4, trees[[i]]) )
+ }
Error in corPagel(value = 0.4, trees[[i]]) : 
  object "phy" is not of class "phylo"



Perhaps you have yet another unnamed package with a corPagel that doesn't require a second argument of class "phylo"? I've reached "the end of my rope".




> }
> 
> Thank you in advance for any help, it's much appreciated!

Please submit code that will run in a clean session. Close R. Do not save anything except your history. Delete or rename your `.Rdata` file and staart a fresh session. then include everything needed to get the behavior you are reporting.

> 
> Kind regards,
> 
> Hannah van Noort
> <Seabirddat_growth.txt>______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From h@nn@hvnoort @end|ng |rom gm@||@com  Sun Jun 17 19:19:30 2018
From: h@nn@hvnoort @end|ng |rom gm@||@com (Hannah van Noort)
Date: Sun, 17 Jun 2018 19:19:30 +0200
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
 <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
Message-ID: <CAO1bxtj69_dpP-uWrLzkcL=aNMBP6_OC4vSoZO20Mm0iApG3SA@mail.gmail.com>

Hi again,

My apologies for the incomplete script last time. Hereby the updated
dataset, phylogenetic tree information and R-script. This time the errors I
mentioned should pop up.
Once again thank you in advance for any help/tips.

Kind regards,

Hannah van Noort

2018-06-17 7:27 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:

>
> > On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com>
> wrote:
> >
> > Hi everyone,
> >
> > I'm having trouble running a PGLS model with the package "AICmodavg".
>
> Did you mean "AICmodavg"?
>
>
> > I
> > continuously get the error of false convergence with certain Lambda
> > values (even
> > when trying to run the model with different Lambda values) and for other
> La
> > mbda values I run into "error in eigen(val) : infinite or missing values
> in
> > 'X' ". I've tried several optimizers and removing some outlier values but
> > the same errors keep on popping up.. Does anyone know how to solve this
> > problem?
> > Below a part of my script with the specific dependent and independent
> varia
> > bles and I've also attached files with the relevant data and phylogenetic
> > tree information.
>
> d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
> library(AICmodavg)
> Error in library(AICmodavg) : there is no package called ?AICmodavg?
> library(AICcmodavg)
> >
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> >  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),
>
> A syntax error is thrown here -------------------------------------^
> #removed paren
> > data =
> > d, method= "ML", na.action=na.omit
>
> And here ---------------------------^
> >                         correlation = corPagel(value=0.4, trees[[i]]))
>
> And after fixing these errors I get the error that `gls` is not found
> (even after adding `library(AICcmodavg)`
>
>  could not find function "gls"
> > ?corPagel
> No documentation for ?corPagel? in specified packages and libraries:
> you could try ???corPagel?
> > ??gls
> > library(nlme)
>
> Attaching package: ?nlme?
>
> The following object is masked from ?package:dplyr?:
>
>     collapse
>
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) :
>   could not find function "corPagel"
> > ??corPagel
> > library(ape)
>
> Attaching package: ?ape?
>
> The following object is masked from ?package:Hmisc?:
>
>     zoom
>
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) :
>   object "phy" is not of class "phylo"
>
>
>
> Perhaps you have yet another unnamed package with a corPagel that doesn't
> require a second argument of class "phylo"? I've reached "the end of my
> rope".
>
>
>
>
> > }
> >
> > Thank you in advance for any help, it's much appreciated!
>
> Please submit code that will run in a clean session. Close R. Do not save
> anything except your history. Delete or rename your `.Rdata` file and
> staart a fresh session. then include everything needed to get the behavior
> you are reporting.
>
> >
> > Kind regards,
> >
> > Hannah van Noort
> > <Seabirddat_growth.txt>______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
>  -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Seabirddat_growth.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180617/55711f90/attachment-0002.txt>

From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jun 17 23:33:13 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 17 Jun 2018 14:33:13 -0700
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <CAO1bxtj69_dpP-uWrLzkcL=aNMBP6_OC4vSoZO20Mm0iApG3SA@mail.gmail.com>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
 <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
 <CAO1bxtj69_dpP-uWrLzkcL=aNMBP6_OC4vSoZO20Mm0iApG3SA@mail.gmail.com>
Message-ID: <B80000E1-9836-471B-AA94-7C69524B7B1D@comcast.net>


> On Jun 17, 2018, at 10:19 AM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
> 
> Hi again,
> 
> My apologies for the incomplete script last time. Hereby the updated dataset, phylogenetic tree information and R-script. This time the errors I mentioned should pop up.
> Once again thank you in advance for any help/tips.

> row.names(d) <- c("Diomedea_exulans", "Diomedea_epomophora", "Thalassarche_chrysostoma", "Thalassarche_melanophrys", "Phoebetria_palpebrata", "Macronectes_giganteus", "Fulmarus_glacialis",
+                   "Procellaria_aequinoctialis", "Puffinus_tenuirostris", "Puffinus_puffinus", "Oceanites_oceanicus", "Oceanodroma_leucorhoa", "Phaethon_rubricauda", 
+                   "Pelecanus_occidentalis", "Fregata_magnificens", "Morus_bassanus", 
+                   "Sula_dactylatra", "Sula_leucogaster", "Sula_sula", "Phalacrocorax_carbo", "Phalacrocorax_aristotelis", "Larus_dominicanus", "Larus_occidentalis", "Larus_argentatus", "Rissa_tridactyla", "Sterna_bergii",
+                   "Sterna_sandvicensis", "Sterna_dougallii", "Sterna_hirundo", "Sterna_paradisaea", "Sterna_fuscata", "Anous_stolidus", "Anous_minutus", "Cepphus_columba", "Cepphus_grylle", "Uria_lomvia", "Alca_torda")
Error in `.rowNamesDF<-`(x, value = value) : invalid 'row.names' length

Needed to remove the extraneous "+" signs that persisted after copying from the console, but still no progress:


length( c("Diomedea_exulans", "Diomedea_epomophora", "Thalassarche_chrysostoma", "Thalassarche_melanophrys", "Phoebetria_palpebrata", "Macronectes_giganteus", "Fulmarus_glacialis",
+                    "Procellaria_aequinoctialis", "Puffinus_tenuirostris", "Puffinus_puffinus", "Oceanites_oceanicus", "Oceanodroma_leucorhoa", "Phaethon_rubricauda", 
+                   "Pelecanus_occidentalis", "Fregata_magnificens", "Morus_bassanus", 
+                    "Sula_dactylatra", "Sula_leucogaster", "Sula_sula", "Phalacrocorax_carbo", "Phalacrocorax_aristotelis", "Larus_dominicanus", "Larus_occidentalis", "Larus_argentatus", "Rissa_tridactyla", "Sterna_bergii",
+                   "Sterna_sandvicensis", "Sterna_dougallii", "Sterna_hirundo", "Sterna_paradisaea", "Sterna_fuscata", "Anous_stolidus", "Anous_minutus", "Cepphus_columba", "Cepphus_grylle", "Uria_lomvia", "Alca_torda")
+ )
[1] 37

> 
 nrow(d)
[1] 40

So yet another error that prevents further progress.


PLEASE 
PLEASE
PLEASE
Run your code in a clean session and try to recognize and correct the syntactic and other errors that I have already identified. I think it's time for you to adopt a strategy of creating asource file that is then submitted by your editor. (Such a facility is supplied by Rstudio.)


> Kind regards,
> 
> Hannah van Noort
> 
> 2018-06-17 7:27 GMT+02:00 David Winsemius <dwinsemius at comcast.net>:
> 
> > On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
> > 
> > Hi everyone,
> > 
> > I'm having trouble running a PGLS model with the package "AICmodavg".
> 
> Did you mean "AICmodavg"?
> 
> 
> > I
> > continuously get the error of false convergence with certain Lambda
> > values (even
> > when trying to run the model with different Lambda values) and for other La
> > mbda values I run into "error in eigen(val) : infinite or missing values in
> > 'X' ". I've tried several optimizers and removing some outlier values but
> > the same errors keep on popping up.. Does anyone know how to solve this
> > problem?
> > Below a part of my script with the specific dependent and independent varia
> > bles and I've also attached files with the relevant data and phylogenetic
> > tree information.
> 
> d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
> library(AICmodavg)
> Error in library(AICmodavg) : there is no package called ?AICmodavg?
> library(AICcmodavg)
> > 
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> >  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),
> 
> A syntax error is thrown here -------------------------------------^  #removed paren
> > data =
> > d, method= "ML", na.action=na.omit
> 
> And here ---------------------------^
> >                         correlation = corPagel(value=0.4, trees[[i]]))
> 
> And after fixing these errors I get the error that `gls` is not found (even after adding `library(AICcmodavg)`
> 
>  could not find function "gls"
> > ?corPagel
> No documentation for ?corPagel? in specified packages and libraries:
> you could try ???corPagel?
> > ??gls
> > library(nlme)
> 
> Attaching package: ?nlme?
> 
> The following object is masked from ?package:dplyr?:
> 
>     collapse
> 
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>   could not find function "corPagel"
> > ??corPagel
> > library(ape)
> 
> Attaching package: ?ape?
> 
> The following object is masked from ?package:Hmisc?:
> 
>     zoom
> 
> > Cand.models = list()
> > niter = 100
> > for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>   object "phy" is not of class "phylo"
> 
> 
> 
> Perhaps you have yet another unnamed package with a corPagel that doesn't require a second argument of class "phylo"? I've reached "the end of my rope".
> 
> 
> 
> 
> > }
> > 
> > Thank you in advance for any help, it's much appreciated!
> 
> Please submit code that will run in a clean session. Close R. Do not save anything except your history. Delete or rename your `.Rdata` file and staart a fresh session. then include everything needed to get the behavior you are reporting.
> 
> > 
> > Kind regards,
> > 
> > Hannah van Noort
> > <Seabirddat_growth.txt>______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> 
> 
> 
> 
> 
> <Seabirddat_growth.txt><output.nex><Scripts_Growthrate.R>

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From dw|n@em|u@ @end|ng |rom comc@@t@net  Sun Jun 17 22:51:00 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Sun, 17 Jun 2018 13:51:00 -0700
Subject: [R] Problems running a PGLS model with phylogenetic uncertainty
In-Reply-To: <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
References: <CAO1bxtgS4oO6bhiPpZdK6iZzyHbCC1fEQQex5UhyD+jwGx+zWg@mail.gmail.com>
 <9FF5A4AC-549A-4208-AC9B-02B00432CCBF@comcast.net>
Message-ID: <E5903E7C-50BB-4891-A1EE-5BFD3CC5D583@comcast.net>


> On Jun 16, 2018, at 10:27 PM, David Winsemius <dwinsemius at comcast.net> wrote:
> 
> 
>> On Jun 16, 2018, at 1:37 PM, Hannah van Noort <hannahvnoort at gmail.com> wrote:
>> 
>> Hi everyone,
>> 
>> I'm having trouble running a PGLS model with the package "AICmodavg".
> 
> Did you mean "AICmodavg"?
> 
> 
>> I
>> continuously get the error of false convergence with certain Lambda
>> values (even
>> when trying to run the model with different Lambda values) and for other La
>> mbda values I run into "error in eigen(val) : infinite or missing values in
>> 'X' ". I've tried several optimizers and removing some outlier values but
>> the same errors keep on popping up.. Does anyone know how to solve this
>> problem?
>> Below a part of my script with the specific dependent and independent varia
>> bles and I've also attached files with the relevant data and phylogenetic
>> tree information.

I didn't notice on first reading that your said you had attached a file about "phylogenetic
tree information." There was only one file in the material passed to Rhelp readers and htat was the .txt data file. Files ending in anything other than ".txt", ".ps", ".pdf", or ".png" will get scrubbed by hte mail-server that mediated rhelp communication. So you can fool your mail-client into thinking that a file is plain text by adding a '.txt' extension and communication will be improved.

Since drafting this I see that you sent another message to both me and Rhelp. I'm the only one who will get the `.nex` and `.R` files. They were scrubbed by the mailserver. I've looked at the .R file and wil now follow my own advice and append a .txt extension  and attach to this email. The 190KB output.nex file is also basically a text file and I'm applying the same treatment:


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: output.nex.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180617/b18132be/attachment-0004.txt>

-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: Scripts_Growthrate.R.txt
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180617/b18132be/attachment-0005.txt>

-------------- next part --------------

 
> 
> d <- read.table("~/Seabirddat_growth.txt", head=TRUE)
> library(AICmodavg)
> Error in library(AICmodavg) : there is no package called ?AICmodavg?
> library(AICcmodavg)
>> 
>> Cand.models = list()
>> niter = 100
>> for (i in 1:niter) {
>> Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av),
> 
> A syntax error is thrown here -------------------------------------^  #removed paren
>> data =
>> d, method= "ML", na.action=na.omit
> 
> And here ---------------------------^
>>                        correlation = corPagel(value=0.4, trees[[i]]))
> 
> And after fixing these errors I get the error that `gls` is not found (even after adding `library(AICcmodavg)`
> 
> could not find function "gls"
>> ?corPagel
> No documentation for ?corPagel? in specified packages and libraries:
> you could try ???corPagel?
>> ??gls
>> library(nlme)
> 
> Attaching package: ?nlme?
> 
> The following object is masked from ?package:dplyr?:
> 
>    collapse
> 
>> Cand.models = list()
>> niter = 100
>> for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>  could not find function "corPagel"
>> ??corPagel
>> library(ape)
> 
> Attaching package: ?ape?
> 
> The following object is masked from ?package:Hmisc?:
> 
>    zoom
> 
>> Cand.models = list()
>> niter = 100
>> for (i in 1:niter) {
> +  Cand.models[[i]] = gls(Maxgrowthrate ~ log.Forrang+log.Weight_av, data =
> + d, method= "ML", na.action=na.omit,
> +                         correlation = corPagel(value=0.4, trees[[i]]) )
> + }
> Error in corPagel(value = 0.4, trees[[i]]) : 
>  object "phy" is not of class "phylo"
> 
> 
> 
> Perhaps you have yet another unnamed package with a corPagel that doesn't require a second argument of class "phylo"? I've reached "the end of my rope".
> 
> 
> 
> 
>> }
>> 
>> Thank you in advance for any help, it's much appreciated!
> 
> Please submit code that will run in a clean session. Close R. Do not save anything except your history. Delete or rename your `.Rdata` file and staart a fresh session. then include everything needed to get the behavior you are reporting.
> 
>> 
>> Kind regards,
>> 
>> Hannah van Noort
>> <Seabirddat_growth.txt>______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 
> David Winsemius
> Alameda, CA, USA
> 
> 'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law






From pe|j@@z @end|ng |rom y@hoo@co@uk  Mon Jun 18 12:28:37 2018
From: pe|j@@z @end|ng |rom y@hoo@co@uk (lejeczek)
Date: Mon, 18 Jun 2018 11:28:37 +0100
Subject: [R] mzR fails to install/compile (linuxes)
In-Reply-To: <f3f77e1c-cd98-310d-3a04-a789730d96d7@roswellpark.org>
References: <643e94aa-e757-a632-cc61-39b3785de045@yahoo.co.uk>
 <f3f77e1c-cd98-310d-3a04-a789730d96d7@roswellpark.org>
Message-ID: <1e1509bb-5bd4-f7b0-d2d5-88ac67c99faf@yahoo.co.uk>

On 16/06/18 13:09, Martin Morgan wrote:
> mzR is a Bioconductor package so you might have more luck contacting 
> the maintainer on the Bioconductor support site
>
> ? https://support.bioconductor.org
>
> or on the 'bioc-devel' mailing list
>
> ? https://stat.ethz.ch/mailman/listinfo/bioc-devel
>
> or most directly by opening an issue on the maintainer's github
>
> ? https://github.com/sneumann/mzR/issues/
>
> this is linked to from the package 'landing page'
>
> ? https://bioconductor.org/packages/mzR
>
> Martin Morgan
>
> On 06/15/2018 10:49 AM, lejeczek via R-help wrote:
>> hi guys, just an admin here.
>>
>> I wonder if anybody see what I see, or similar? I'm on Centos 7.x and 
>> this occurs with R 3.4.x 3.5.x and probably earlier versions too.
>>
>> Every time I use something like -j>1 to pass to a compiler, eg.echo -ne
>>
>> $ "Sys.setenv(MAKEFLAGS = \"-j2\")\\n 
>> source(\"https://bioconductor.org/biocLite.R\")\\n 
>> biocLite(c(\"mzR\"), suppressUpdates=FALSE, suppressAutoUpdate=FALSE, 
>> ask=FALSE)" | /usr/bin/R --vanilla
>>
>> mzR fails to compile:
>> ...
>> g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o 
>> mzR.so cramp.o ramp_base64.o ramp.o RcppRamp.o RcppRampModule.o 
>> rnetCDF.o RcppPwiz.o RcppPwizModule.o RcppIdent.o RcppIdentModule.o 
>> ./boost/libs/system/src/error_code.o 
>> ./boost/libs/regex/src/posix_api.o ./boost/libs/regex/src/fileiter.o 
>> ./boost/libs/regex/src/regex_raw_buffer.o 
>> ./boost/libs/regex/src/cregex.o ./boost/libs/regex/src/regex_debug.o 
>> ./boost/libs/regex/src/instances.o ./boost/libs/regex/src/icu.o 
>> ./boost/libs/regex/src/usinstances.o ./boost/libs/regex/src/regex.o 
>> ./boost/libs/regex/src/wide_posix_api.o 
>> ./boost/libs/regex/src/regex_traits_defaults.o 
>> ./boost/libs/regex/src/winstances.o 
>> ./boost/libs/regex/src/wc_regex_traits.o 
>> ./boost/libs/regex/src/c_regex_traits.o 
>> ./boost/libs/regex/src/cpp_regex_traits.o 
>> ./boost/libs/regex/src/static_mutex.o 
>> ./boost/libs/regex/src/w32_regex_traits.o 
>> ./boost/libs/iostreams/src/zlib.o 
>> ./boost/libs/iostreams/src/file_descriptor.o 
>> ./boost/libs/filesystem/src/operations.o 
>> ./boost/libs/filesystem/src/path.o 
>> ./boost/libs/filesystem/src/utf8_codecvt_facet.o 
>> ./boost/libs/chrono/src/chrono.o 
>> ./boost/libs/chrono/src/process_cpu_clocks.o 
>> ./boost/libs/chrono/src/thread_clock.o ./pwiz/data/msdata/Version.o 
>> ./pwiz/data/identdata/Version.o ./pwiz/data/common/MemoryIndex.o 
>> ./pwiz/data/common/CVTranslator.o ./pwiz/data/common/cv.o 
>> ./pwiz/data/common/ParamTypes.o 
>> ./pwiz/data/common/BinaryIndexStream.o ./pwiz/data/common/diff_std.o 
>> ./pwiz/data/common/Unimod.o 
>> ./pwiz/data/msdata/mz5/Configuration_mz5.o 
>> ./pwiz/data/msdata/mz5/Connection_mz5.o 
>> ./pwiz/data/msdata/mz5/Datastructures_mz5.o 
>> ./pwiz/data/msdata/mz5/ReferenceRead_mz5.o 
>> ./pwiz/data/msdata/mz5/ReferenceWrite_mz5.o 
>> ./pwiz/data/msdata/mz5/Translator_mz5.o 
>> ./pwiz/data/msdata/SpectrumList_MGF.o 
>> ./pwiz/data/msdata/DefaultReaderList.o 
>> ./pwiz/data/msdata/ChromatogramList_mzML.o 
>> ./pwiz/data/msdata/ChromatogramList_mz5.o 
>> ./pwiz/data/msdata/examples.o ./pwiz/data/msdata/Serializer_mzML.o 
>> ./pwiz/data/msdata/Serializer_MSn.o ./pwiz/data/msdata/Reader.o 
>> ./pwiz/data/msdata/Serializer_mz5.o 
>> ./pwiz/data/msdata/Serializer_MGF.o 
>> ./pwiz/data/msdata/Serializer_mzXML.o 
>> ./pwiz/data/msdata/SpectrumList_mzML.o 
>> ./pwiz/data/msdata/SpectrumList_MSn.o 
>> ./pwiz/data/msdata/SpectrumList_mz5.o 
>> ./pwiz/data/msdata/BinaryDataEncoder.o ./pwiz/data/msdata/Diff.o 
>> ./pwiz/data/msdata/MSData.o ./pwiz/data/msdata/References.o 
>> ./pwiz/data/msdata/SpectrumList_mzXML.o ./pwiz/data/msdata/IO.o 
>> ./pwiz/data/msdata/SpectrumList_BTDX.o 
>> ./pwiz/data/msdata/SpectrumInfo.o ./pwiz/data/msdata/RAMPAdapter.o 
>> ./pwiz/data/msdata/LegacyAdapter.o 
>> ./pwiz/data/msdata/SpectrumIterator.o ./pwiz/data/msdata/MSDataFile.o 
>> ./pwiz/data/msdata/MSNumpress.o 
>> ./pwiz/data/msdata/SpectrumListCache.o 
>> ./pwiz/data/msdata/Index_mzML.o 
>> ./pwiz/data/msdata/SpectrumWorkerThreads.o 
>> ./pwiz/data/identdata/IdentDataFile.o 
>> ./pwiz/data/identdata/IdentData.o 
>> ./pwiz/data/identdata/DefaultReaderList.o 
>> ./pwiz/data/identdata/Reader.o 
>> ./pwiz/data/identdata/Serializer_protXML.o 
>> ./pwiz/data/identdata/Serializer_pepXML.o 
>> ./pwiz/data/identdata/Serializer_mzid.o ./pwiz/data/identdata/IO.o 
>> ./pwiz/data/identdata/References.o 
>> ./pwiz/data/identdata/MascotReader.o 
>> ./pwiz/data/proteome/Modification.o ./pwiz/data/proteome/Digestion.o 
>> ./pwiz/data/proteome/Peptide.o ./pwiz/data/proteome/AminoAcid.o 
>> ./pwiz/utility/minimxml/XMLWriter.o 
>> ./pwiz/utility/minimxml/SAXParser.o 
>> ./pwiz/utility/chemistry/Chemistry.o 
>> ./pwiz/utility/chemistry/ChemistryData.o 
>> ./pwiz/utility/chemistry/MZTolerance.o 
>> ./pwiz/utility/misc/IntegerSet.o ./pwiz/utility/misc/Base64.o 
>> ./pwiz/utility/misc/IterationListener.o 
>> ./pwiz/utility/misc/MSIHandler.o ./pwiz/utility/misc/Filesystem.o 
>> ./pwiz/utility/misc/TabReader.o 
>> ./pwiz/utility/misc/random_access_compressed_ifstream.o 
>> ./pwiz/utility/misc/SHA1.o ./pwiz/utility/misc/SHA1Calculator.o 
>> ./pwiz/utility/misc/sha1calc.o ./random_access_gzFile.o 
>> ./RcppExports.o ./boost/libs/thread/src/pthread/once.o 
>> ./boost/libs/thread/src/pthread/thread.o rampR.o R_init_mzR.o 
>> -lpthread /usr/lib64/R/library/Rhdf5lib/lib/libhdf5_cpp.a 
>> /usr/lib64/R/library/Rhdf5lib/lib/libhdf5.a 
>> /usr/lib64/R/library/Rhdf5lib/lib/libsz.a -lz -L/opt/lib/hdf5-18/lib/ 
>> -lnetcdf -L/usr/lib64/R/lib -lR
>> g++: error: cramp.o: No such file or directory
>> make: *** [mzR.so] Error 1
>> ERROR: compilation failed for package ?mzR?
>> * removing ?/usr/lib64/R/library/mzR?
>>
>> If j is 1, then compilation succeeds.
>> I have hundreds of packages and so far only "mzR" and "MSnbase" fail 
>> if I compile with -j>1.
>>
>> Would anybody be able to confirm this problem exists?
>> Many thanks, L.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
>
> This email message may contain legally privileged and/or confidential 
> information.? If you are not the intended recipient(s), or the 
> employee or agent responsible for the delivery of this message to the 
> intended recipient(s), you are hereby notified that any disclosure, 
> copying, distribution, or use of this email message is prohibited.? If 
> you have received this message in error, please notify the sender 
> immediately by e-mail and delete this email message from your 
> computer. Thank you.

sure sure,

Could somebody just run compilation the way I described it and confirm 
it fails? Anybody on Centos/rhel?

many thanks, L.



From @k@h@y_e4 @end|ng |rom hotm@||@com  Mon Jun 18 12:55:53 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Mon, 18 Jun 2018 10:55:53 +0000
Subject: [R] subsetting lists....
Message-ID: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...

How to do this?
I searched SO and the internet but was bootless....

Very many thanks for your time and effort.....
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Mon Jun 18 13:15:30 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Mon, 18 Jun 2018 11:15:30 +0000
Subject: [R] Fw: subsetting lists....
In-Reply-To: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

correction....I want the method without a for loop
________________________________
From: akshay kulkarni <akshay_e4 at hotmail.com>
Sent: Monday, June 18, 2018 4:25 PM
To: R help Mailing list
Subject: subsetting lists....

dear members,
                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...

How to do this?
I searched SO and the internet but was bootless....

Very many thanks for your time and effort.....
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Mon Jun 18 13:18:30 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 18 Jun 2018 14:18:30 +0300
Subject: [R] subsetting lists....
In-Reply-To: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW76oTkU8R0M+U1ZUvuS5fmbpmaK_KZGbi2=BksLKq8AeGw@mail.gmail.com>

 sapply( 1:length(YH), function(i) { YH[[i]][iuhV[i]]})

On Mon, Jun 18, 2018 at 1:55 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                             I have list YH and index vector iuhV. I want
> to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from
> YH[[3]]......iuhv[n] from YH[[n]]...
>
> How to do this?
> I searched SO and the internet but was bootless....
>
> Very many thanks for your time and effort.....
> Yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Mon Jun 18 13:46:16 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Mon, 18 Jun 2018 14:46:16 +0300
Subject: [R] Fw: subsetting lists....
In-Reply-To: <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGgJW77rMpD-M1K50XiG2S8F-ssx1zMd3VKL+xan0hgqYq_=dg@mail.gmail.com>

My response does not have an explicit for loop.

On Mon, Jun 18, 2018 at 2:15 PM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> correction....I want the method without a for loop
> ________________________________
> From: akshay kulkarni <akshay_e4 at hotmail.com>
> Sent: Monday, June 18, 2018 4:25 PM
> To: R help Mailing list
> Subject: subsetting lists....
>
> dear members,
>                             I have list YH and index vector iuhV. I want
> to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from
> YH[[3]]......iuhv[n] from YH[[n]]...
>
> How to do this?
> I searched SO and the internet but was bootless....
>
> Very many thanks for your time and effort.....
> Yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m||uj|@b @end|ng |rom gm@||@com  Mon Jun 18 16:21:50 2018
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Mon, 18 Jun 2018 16:21:50 +0200
Subject: [R] Subset Rasterbrick by time
Message-ID: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>

 Dear all,

I have a rasterbrick with the date/time information provided which I would
like to subset by year.

However, when I use the following code for sub-setting;

new_brick <- subset(original, which(getZ( original ) >= as.Date("2000-01-01
10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))

The date/time information seems to be lost.

Furthermore, the class of the date/time seems to be character;

##
class(getZ( original ))
[1] "character"

Is it possible to convert this string to date before sub-setting or retain
the date/time information after sub-setting?

### original RasterBrick ###
class       : RasterBrick
dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
resolution  : 0.25, 0.25  (x, y)
extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
data source :
/work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_precip_windspd_sphum_daily_1986_2016.nc4
names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
X1986.01.15.10.30.00, ...
Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
varname     : v1

### new RasterBrick ###
class       : RasterStack
dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
resolution  : 0.25, 0.25  (x, y)
extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
X2000.01.15.10.30.00, ...

Any help will be greatly appreciated.

Sincerely,

Milu

	[[alternative HTML version deleted]]



From dw|n@em|u@ @end|ng |rom comc@@t@net  Mon Jun 18 17:08:37 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 18 Jun 2018 08:08:37 -0700
Subject: [R] Subset Rasterbrick by time
In-Reply-To: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
Message-ID: <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>



> On Jun 18, 2018, at 7:21 AM, Miluji Sb <milujisb at gmail.com> wrote:
> 
> Dear all,
> 
> I have a rasterbrick with the date/time information provided which I would
> like to subset by year.
> 
> However, when I use the following code for sub-setting;
> 
> new_brick <- subset(original, which(getZ( original ) >= as.Date("2000-01-01
> 10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))
> 
> The date/time information seems to be lost.
> 
> Furthermore, the class of the date/time seems to be character;
> 
> ##
> class(getZ( original ))
> [1] "character"
> 
> Is it possible to convert this string to date before sub-setting or retain
> the date/time information after sub-setting?

Yes, it is certainly possible, but why bother? R's Comparison operators work on character values so you should be able to do this (if the subsetting is syntactically correct:

 new_brick <- subset(original, which(getZ( original ) >= "2000-01-01
10:30:00" & getZ(original ) <= "2014-12-31 10:30:00") )


As always if you had presented the output of dput(head(original)) assuming that head is a meaningful operation on such an object, the demonstration would have been possible. An alternate would be to offer a library call to a package and then load a relevant example.


Best;
David
> 
> ### original RasterBrick ###
> class       : RasterBrick
> dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
> resolution  : 0.25, 0.25  (x, y)
> extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> data source :
> /work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_precip_windspd_sphum_daily_1986_2016.nc4
> names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
> X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
> X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
> X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
> X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
> X1986.01.15.10.30.00, ...
> Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
> varname     : v1
> 
> ### new RasterBrick ###
> class       : RasterStack
> dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
> resolution  : 0.25, 0.25  (x, y)
> extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
> X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
> X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
> X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
> X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
> X2000.01.15.10.30.00, ...
> 
> Any help will be greatly appreciated.
> 
> Sincerely,
> 
> Milu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From g@g@ndeep_d@tt@ @end|ng |rom hotm@||@com  Mon Jun 18 17:31:36 2018
From: g@g@ndeep_d@tt@ @end|ng |rom hotm@||@com (Gagandeep S. Datta)
Date: Mon, 18 Jun 2018 15:31:36 +0000
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>,
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
Message-ID: <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>

Hi,

Is there a code available for zero-truncated Binomial distribution on the lines of zero-truncated Poisson distribution available at:
https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html

Regards,
Gagandeep

	[[alternative HTML version deleted]]



From pd@|gd @end|ng |rom gm@||@com  Mon Jun 18 17:52:27 2018
From: pd@|gd @end|ng |rom gm@||@com (peter dalgaard)
Date: Mon, 18 Jun 2018 17:52:27 +0200
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
Message-ID: <5411EC03-BB16-4EEE-BA3C-7C27CE46883F@gmail.com>

I think you can pretty much copy what is in that reference while substituting "binom" for "pois" (not quite, but you get the point?)

-pd

> On 18 Jun 2018, at 17:31 , Gagandeep S. Datta <gagandeep_datta at hotmail.com> wrote:
> 
> Hi,
> 
> Is there a code available for zero-truncated Binomial distribution on the lines of zero-truncated Poisson distribution available at:
> https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html
> 
> Regards,
> Gagandeep
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun 18 17:59:02 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 18 Jun 2018 08:59:02 -0700
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>,
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
Message-ID: <6FBAFB1D-80FD-4706-97E1-A5EF3E802189@dcn.davis.ca.us>

Mailing list etiquette requires that you don't start a new thread by replying to an existing thread. Start a new thread with a fresh email.

Also, this is a plain text mailing list... HTML formatting gets removed and what is left often does not look to the list readers like what you sent. Read the Posting Guide mentioned below for more about interacting with the list.

On June 18, 2018 8:31:36 AM PDT, "Gagandeep S. Datta" <gagandeep_datta at hotmail.com> wrote:
>Hi,
>
>Is there a code available for zero-truncated Binomial distribution on
>the lines of zero-truncated Poisson distribution available at:
>https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html
>
>Regards,
>Gagandeep
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From ccberry @end|ng |rom uc@d@edu  Mon Jun 18 19:00:40 2018
From: ccberry @end|ng |rom uc@d@edu (Berry, Charles)
Date: Mon, 18 Jun 2018 17:00:40 +0000
Subject: [R] subsetting lists....
In-Reply-To: <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091C88C44270C9A38166D29C8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <SL2P216MB009121FF5F01EA5EB2B75E7DC8710@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <4625A3BE-D93E-4674-B8AE-D44C9AA0BBA2@ucsd.edu>



> On Jun 18, 2018, at 4:15 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> 
> correction....I want the method without a for loop

Here are two. The first is more readable, but the second is 5 times faster.

mapply("[", YH, iuhV)

unlist(YH, recursive = FALSE, use.names = FALSE)[cumsum( lengths(YH)) - lengths(YH) + iuhV]

HTH,

Chuck

> ________________________________
> From: akshay kulkarni <akshay_e4 at hotmail.com>
> Sent: Monday, June 18, 2018 4:25 PM
> To: R help Mailing list
> Subject: subsetting lists....
> 
> dear members,
>                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...
> 
> How to do this?
> I searched SO and the internet but was bootless....
> 
> Very many thanks for your time and effort.....
> Yours sincerely,
> AKSHAY M KULKARNI
> 
> 	[[alternative HTML version deleted]]
> 



From @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com  Mon Jun 18 20:01:11 2018
From: @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com (Sebastien Bihorel)
Date: Mon, 18 Jun 2018 14:01:11 -0400 (EDT)
Subject: [R] Porbably bug in panel.abline
Message-ID: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>

Hi, 

I recently encountered situations in which reference lines are not drawn with the lattice panel.abline function. Please, consider the following example code: 


require(lattice)

a <- runif(1,0,100)
data <- data.frame(x=c(0,a^2), y=c(0,a^2))

xyplot(
  y~x,
  data = data,
  type = 'l',
  panel = function(x,y,...){
    panel.xyplot(x,y,...)
    panel.abline(c(a^2,-1.0), col=2)
  }
) 

Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some axis limits seems to bypass the problem. 

The problem also happens for different data source and abline coefficients: 
data <- data.frame(x=c(18,81), y=c(18,81)) 
... 
panel.abline(c(99,-1.0), col=2)


Thank you in advance for your feedback.

Sebastien

PS: the problem was also posted at https://github.com/deepayan/lattice/issues/8



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun 18 20:07:17 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 18 Jun 2018 11:07:17 -0700
Subject: [R] Help, zero-truncated Binomial distribution
In-Reply-To: <6FBAFB1D-80FD-4706-97E1-A5EF3E802189@dcn.davis.ca.us>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <DM5PR16MB2152FBD7315CEA28D7F60A1C8E710@DM5PR16MB2152.namprd16.prod.outlook.com>
 <6FBAFB1D-80FD-4706-97E1-A5EF3E802189@dcn.davis.ca.us>
Message-ID: <CAGxFJbT5br-bAwauPoNvHd0QZw7qk_i8K9u20CL06iiXHoGi-Q@mail.gmail.com>

Search!

My first hit on a google search of "zero truncated binomial" was this:

https://rdrr.io/cran/actuar/man/ZeroTruncatedBinomial.html

which appears to be what you want.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 8:59 AM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
wrote:

> Mailing list etiquette requires that you don't start a new thread by
> replying to an existing thread. Start a new thread with a fresh email.
>
> Also, this is a plain text mailing list... HTML formatting gets removed
> and what is left often does not look to the list readers like what you
> sent. Read the Posting Guide mentioned below for more about interacting
> with the list.
>
> On June 18, 2018 8:31:36 AM PDT, "Gagandeep S. Datta" <
> gagandeep_datta at hotmail.com> wrote:
> >Hi,
> >
> >Is there a code available for zero-truncated Binomial distribution on
> >the lines of zero-truncated Poisson distribution available at:
> >https://stat.ethz.ch/pipermail/r-help/2005-May/070680.html
> >
> >Regards,
> >Gagandeep
> >
> >       [[alternative HTML version deleted]]
> >
> >______________________________________________
> >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >https://stat.ethz.ch/mailman/listinfo/r-help
> >PLEASE do read the posting guide
> >http://www.R-project.org/posting-guide.html
> >and provide commented, minimal, self-contained, reproducible code.
>
> --
> Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun 18 20:28:21 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 18 Jun 2018 11:28:21 -0700
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>

Note that:

xyplot(
   y~x,
   data = data,
   type = 'l', col="blue",
   panel = function(x,y,...){
      panel.xyplot(x,y,...)
      panel.abline(c(a^2-1,-1), col="red")
   }
)

works. The problem is a^2  is just above the "drawable" y axis limit (it is
the intercept of the line at x=0 with slope -1, of course). This also
explains all your other comments.

Cheers,
Bert



-- 

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

> Hi,
>
> I recently encountered situations in which reference lines are not drawn
> with the lattice panel.abline function. Please, consider the following
> example code:
>
>
> require(lattice)
>
> a <- runif(1,0,100)
> data <- data.frame(x=c(0,a^2), y=c(0,a^2))
>
> xyplot(
>   y~x,
>   data = data,
>   type = 'l',
>   panel = function(x,y,...){
>     panel.xyplot(x,y,...)
>     panel.abline(c(a^2,-1.0), col=2)
>   }
> )
>
> Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some
> axis limits seems to bypass the problem.
>
> The problem also happens for different data source and abline
> coefficients:
> data <- data.frame(x=c(18,81), y=c(18,81))
> ...
> panel.abline(c(99,-1.0), col=2)
>
>
> Thank you in advance for your feedback.
>
> Sebastien
>
> PS: the problem was also posted at https://github.com/deepayan/
> lattice/issues/8
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com  Mon Jun 18 21:05:30 2018
From: @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com (Sebastien Bihorel)
Date: Mon, 18 Jun 2018 15:05:30 -0400 (EDT)
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
Message-ID: <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>


No, the intercept a^2 f the abline is exactly the upper limit of the data, so it is in the range. 


From: "Bert Gunter" <bgunter.4567 at gmail.com> 
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com> 
Cc: "R-help" <r-help at r-project.org> 
Sent: Monday, June 18, 2018 2:28:21 PM 
Subject: Re: [R] Porbably bug in panel.abline 

Note that: 

xyplot( 
y~x, 
data = data, 
type = 'l', col="blue", 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2-1,-1), col="red") 
} 
) 

works. The problem is a^2 is just above the "drawable" y axis limit (it is the intercept of the line at x=0 with slope -1, of course). This also explains all your other comments. 

Cheers, 
Bert 



-- 

Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 


Hi, 

I recently encountered situations in which reference lines are not drawn with the lattice panel.abline function. Please, consider the following example code: 


require(lattice) 

a <- runif(1,0,100) 
data <- data.frame(x=c(0,a^2), y=c(0,a^2)) 

xyplot( 
y~x, 
data = data, 
type = 'l', 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2,-1.0), col=2) 
} 
) 

Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some axis limits seems to bypass the problem. 

The problem also happens for different data source and abline coefficients: 
data <- data.frame(x=c(18,81), y=c(18,81)) 
... 
panel.abline(c(99,-1.0), col=2) 


Thank you in advance for your feedback. 

Sebastien 

PS: the problem was also posted at [ https://github.com/deepayan/lattice/issues/8 | https://github.com/deepayan/lattice/issues/8 ] 

______________________________________________ 
[ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To UNSUBSCRIBE and more, see 
[ https://stat.ethz.ch/mailman/listinfo/r-help | https://stat.ethz.ch/mailman/listinfo/r-help ] 
PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html | http://www.R-project.org/posting-guide.html ] 
and provide commented, minimal, self-contained, reproducible code. 





	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun 18 22:15:29 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 18 Jun 2018 13:15:29 -0700
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
 <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>
Message-ID: <CAGxFJbTwxi_jBbwyTx3BwGdGJVKcusVxdLgu8s7XEXgG+Tq9VA@mail.gmail.com>

hmmm...
Youre right: something subtle is occurring.

Here is a simpler reproducible example that illustrates the issue:

a <- 10
y <- x <- c(0,a)
for(k in c(-1,0,1)){
   print(xyplot(
      y~x,
      type = 'l', col="blue",
      panel = function(x,y,...){
         panel.xyplot(x,y,...)
         panel.abline(c(a+k,-1), col="red")
      }
   ))}

Somehow, the "drawable limits" seem to exclude the corners of the plotting
rectangle.

I would guess that this has something to do with how the plotting viewport
is clipped, but that's just a guess.

Cheers,
Bert

Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 12:05 PM, Sebastien Bihorel <
sebastien.bihorel at cognigencorp.com> wrote:

>
> No, the intercept a^2 f the abline is exactly the upper limit of the data,
> so it is in the range.
>
> ------------------------------
> *From: *"Bert Gunter" <bgunter.4567 at gmail.com>
> *To: *"Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
> *Cc: *"R-help" <r-help at r-project.org>
> *Sent: *Monday, June 18, 2018 2:28:21 PM
> *Subject: *Re: [R] Porbably bug in panel.abline
>
> Note that:
>
> xyplot(
>    y~x,
>    data = data,
>    type = 'l', col="blue",
>    panel = function(x,y,...){
>       panel.xyplot(x,y,...)
>       panel.abline(c(a^2-1,-1), col="red")
>    }
> )
>
> works. The problem is a^2  is just above the "drawable" y axis limit (it
> is the intercept of the line at x=0 with slope -1, of course). This also
> explains all your other comments.
>
> Cheers,
> Bert
>
>
>
> --
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel <sebastien.bihorel@
> cognigencorp.com> wrote:
>
>> Hi,
>>
>> I recently encountered situations in which reference lines are not drawn
>> with the lattice panel.abline function. Please, consider the following
>> example code:
>>
>>
>> require(lattice)
>>
>> a <- runif(1,0,100)
>> data <- data.frame(x=c(0,a^2), y=c(0,a^2))
>>
>> xyplot(
>>   y~x,
>>   data = data,
>>   type = 'l',
>>   panel = function(x,y,...){
>>     panel.xyplot(x,y,...)
>>     panel.abline(c(a^2,-1.0), col=2)
>>   }
>> )
>>
>> Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some
>> axis limits seems to bypass the problem.
>>
>> The problem also happens for different data source and abline
>> coefficients:
>> data <- data.frame(x=c(18,81), y=c(18,81))
>> ...
>> panel.abline(c(99,-1.0), col=2)
>>
>>
>> Thank you in advance for your feedback.
>>
>> Sebastien
>>
>> PS: the problem was also posted at https://github.com/deepayan/
>> lattice/issues/8
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From @tephen66 @end|ng |rom gm@||@com  Mon Jun 18 22:46:57 2018
From: @tephen66 @end|ng |rom gm@||@com (Honkit Wong)
Date: Mon, 18 Jun 2018 13:46:57 -0700
Subject: [R] How to modify data frame stored in a list
Message-ID: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>

Dear R community,
I have a question seems very simple but have trouble to do it. 
I have a list which stores many data frames. Now, I want to perform log10 on one column in each data frame in the list and save the value as a new column back to the original data frame in the list. How do I quickly do that with lapply function ?

Many thanks. 


From b@m|th030465 @end|ng |rom gm@||@com  Mon Jun 18 23:45:29 2018
From: b@m|th030465 @end|ng |rom gm@||@com (Brian Smith)
Date: Mon, 18 Jun 2018 17:45:29 -0400
Subject: [R] numeric comparison error
Message-ID: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>

Hi,

I am a little bit perplexed at why I am getting some values as FALSE:

> cpgbins <- seq(0,1,0.05)

> cpgbins
 [1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65
0.70 0.75 0.80 0.85 0.90 0.95 1.00

> cpgbins[1] == 0.00
[1] TRUE
> cpgbins[2] == 0.05
[1] TRUE
> cpgbins[3] == 0.10
[1] TRUE
> cpgbins[4] == 0.15
[1] FALSE
> cpgbins[5] == 0.20
[1] TRUE
> cpgbins[6] == 0.25
[1] TRUE
> cpgbins[7] == 0.30
[1] FALSE

> class(cpgbins)
[1] "numeric"

> class(cpgbins[7])
[1] "numeric"

What is the cause for this?

thanks!!

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun 18 23:50:17 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 18 Jun 2018 14:50:17 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
Message-ID: <DAE92D92-148A-4A34-827B-E6CF7DE2F32B@dcn.davis.ca.us>

Do you want it to run quickly or be quick to write?

Why have you specified that you want a solution that uses lapply? (Such constraints often arise in the context of homework, whereas someone interested in getting the job done does not usually care about which function is used.)

On June 18, 2018 1:46:57 PM PDT, Honkit Wong <stephen66 at gmail.com> wrote:
>Dear R community,
>I have a question seems very simple but have trouble to do it. 
>I have a list which stores many data frames. Now, I want to perform
>log10 on one column in each data frame in the list and save the value
>as a new column back to the original data frame in the list. How do I
>quickly do that with lapply function ?
>
>Many thanks. 
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From m@cqueen1 @end|ng |rom ||n|@gov  Mon Jun 18 23:52:32 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 18 Jun 2018 21:52:32 +0000
Subject: [R] subsetting lists....
Message-ID: <7E0D239E-4A56-49A4-A2F5-F15924D1D6F9@llnl.gov>

The unlist solution is quite clever.

But I will note that none of the solutions offered so far succeed if the input is, for example,

   YH <- list(1:5, letters[1:3], 1:7)
    iuhV <- c(2,2,4)

and the desire is to return a list whose elements are of the same types as the input list. Which would be the sensible thing to do if the input list mixes types.

(Note that the output structure was not specified in the original question, nor was it stated whether the input list could mix types)

unlist(YH, recursive = FALSE, use.names = FALSE)[cumsum( lengths(YH)) - lengths(YH) + iuhV]
[1] "2" "b" "4"

However,

> lapply( 1:length(YH), function(i) { YH[[i]][iuhV[i]]})
[[1]]
[1] 2

[[2]]
[1] "b"

[[3]]
[1] 4

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/18/18, 10:00 AM, "R-help on behalf of Berry, Charles" <r-help-bounces at r-project.org on behalf of ccberry at ucsd.edu> wrote:

    
    
    > On Jun 18, 2018, at 4:15 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
    > 
    > correction....I want the method without a for loop
    
    Here are two. The first is more readable, but the second is 5 times faster.
    
    mapply("[", YH, iuhV)
    
    unlist(YH, recursive = FALSE, use.names = FALSE)[cumsum( lengths(YH)) - lengths(YH) + iuhV]
    
    HTH,
    
    Chuck
    
    > ________________________________
    > From: akshay kulkarni <akshay_e4 at hotmail.com>
    > Sent: Monday, June 18, 2018 4:25 PM
    > To: R help Mailing list
    > Subject: subsetting lists....
    > 
    > dear members,
    >                            I have list YH and index vector iuhV. I want to select iuhV[1] from YH[[1]], iuhv[2] from YH[[2]], iuhv[3] from YH[[3]]......iuhv[n] from YH[[n]]...
    > 
    > How to do this?
    > I searched SO and the internet but was bootless....
    > 
    > Very many thanks for your time and effort.....
    > Yours sincerely,
    > AKSHAY M KULKARNI
    > 
    > 	[[alternative HTML version deleted]]
    > 
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun 18 23:53:00 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 18 Jun 2018 14:53:00 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
Message-ID: <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>

It depends on whether you wish to refer to the column to be logged by name
or index.

Reprex:

set.seed(1234)
dat <- lapply(1:3, function(i)data.frame(a = runif(5), b =
sample(letters,5)))

## by numerical index of column
d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})

## by name of column
dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})

There are also slight variations on how you can do the "[" indexing that
others may post.
Note that you have to return the modified data frame in the function.

Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com> wrote:

> Dear R community,
> I have a question seems very simple but have trouble to do it.
> I have a list which stores many data frames. Now, I want to perform log10
> on one column in each data frame in the list and save the value as a new
> column back to the original data frame in the list. How do I quickly do
> that with lapply function ?
>
> Many thanks.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun 18 23:53:11 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Mon, 18 Jun 2018 14:53:11 -0700
Subject: [R] numeric comparison error
In-Reply-To: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
References: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
Message-ID: <F7A22688-2365-42A9-BC6D-4D5BDA854E84@dcn.davis.ca.us>

FAQ 7.31, or take a university course in numerical analysis.

https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f

On June 18, 2018 2:45:29 PM PDT, Brian Smith <bsmith030465 at gmail.com> wrote:
>Hi,
>
>I am a little bit perplexed at why I am getting some values as FALSE:
>
>> cpgbins <- seq(0,1,0.05)
>
>> cpgbins
>[1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60
>0.65
>0.70 0.75 0.80 0.85 0.90 0.95 1.00
>
>> cpgbins[1] == 0.00
>[1] TRUE
>> cpgbins[2] == 0.05
>[1] TRUE
>> cpgbins[3] == 0.10
>[1] TRUE
>> cpgbins[4] == 0.15
>[1] FALSE
>> cpgbins[5] == 0.20
>[1] TRUE
>> cpgbins[6] == 0.25
>[1] TRUE
>> cpgbins[7] == 0.30
>[1] FALSE
>
>> class(cpgbins)
>[1] "numeric"
>
>> class(cpgbins[7])
>[1] "numeric"
>
>What is the cause for this?
>
>thanks!!
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun 18 23:58:53 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 18 Jun 2018 14:58:53 -0700
Subject: [R] numeric comparison error
In-Reply-To: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
References: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
Message-ID: <CAGxFJbSCoH17i+XaOH-mEXf-a1HSFduhDYA1UMvrBAe_C4GrQw@mail.gmail.com>

FAQ 7.31.

Binary arithmetic.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 2:45 PM, Brian Smith <bsmith030465 at gmail.com> wrote:

> Hi,
>
> I am a little bit perplexed at why I am getting some values as FALSE:
>
> > cpgbins <- seq(0,1,0.05)
>
> > cpgbins
>  [1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60 0.65
> 0.70 0.75 0.80 0.85 0.90 0.95 1.00
>
> > cpgbins[1] == 0.00
> [1] TRUE
> > cpgbins[2] == 0.05
> [1] TRUE
> > cpgbins[3] == 0.10
> [1] TRUE
> > cpgbins[4] == 0.15
> [1] FALSE
> > cpgbins[5] == 0.20
> [1] TRUE
> > cpgbins[6] == 0.25
> [1] TRUE
> > cpgbins[7] == 0.30
> [1] FALSE
>
> > class(cpgbins)
> [1] "numeric"
>
> > class(cpgbins[7])
> [1] "numeric"
>
> What is the cause for this?
>
> thanks!!
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Mon Jun 18 23:58:55 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Mon, 18 Jun 2018 21:58:55 +0000
Subject: [R] numeric comparison error
In-Reply-To: <F7A22688-2365-42A9-BC6D-4D5BDA854E84@dcn.davis.ca.us>
References: <CAEQKoCEO14MThEQ0PW=_uydQ_z2sZB-iDjX2fvUVMBcm4yVLGA@mail.gmail.com>
 <F7A22688-2365-42A9-BC6D-4D5BDA854E84@dcn.davis.ca.us>
Message-ID: <04854EA9-B098-4746-B823-985A3CDA19A8@llnl.gov>

What Jeff, said, plus to see it explicitly:

> print(cpgbins[5:7], digits=18)
[1] 0.200000000000000011 0.250000000000000000 0.300000000000000044

> print(c(0.2, 0.25, 0.3), digits=18)
[1] 0.200000000000000011 0.250000000000000000 0.299999999999999989

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/18/18, 2:53 PM, "R-help on behalf of Jeff Newmiller" <r-help-bounces at r-project.org on behalf of jdnewmil at dcn.davis.ca.us> wrote:

    FAQ 7.31, or take a university course in numerical analysis.
    
    https://cran.r-project.org/doc/FAQ/R-FAQ.html#Why-doesn_0027t-R-think-these-numbers-are-equal_003f
    
    On June 18, 2018 2:45:29 PM PDT, Brian Smith <bsmith030465 at gmail.com> wrote:
    >Hi,
    >
    >I am a little bit perplexed at why I am getting some values as FALSE:
    >
    >> cpgbins <- seq(0,1,0.05)
    >
    >> cpgbins
    >[1] 0.00 0.05 0.10 0.15 0.20 0.25 0.30 0.35 0.40 0.45 0.50 0.55 0.60
    >0.65
    >0.70 0.75 0.80 0.85 0.90 0.95 1.00
    >
    >> cpgbins[1] == 0.00
    >[1] TRUE
    >> cpgbins[2] == 0.05
    >[1] TRUE
    >> cpgbins[3] == 0.10
    >[1] TRUE
    >> cpgbins[4] == 0.15
    >[1] FALSE
    >> cpgbins[5] == 0.20
    >[1] TRUE
    >> cpgbins[6] == 0.25
    >[1] TRUE
    >> cpgbins[7] == 0.30
    >[1] FALSE
    >
    >> class(cpgbins)
    >[1] "numeric"
    >
    >> class(cpgbins[7])
    >[1] "numeric"
    >
    >What is the cause for this?
    >
    >thanks!!
    >
    >	[[alternative HTML version deleted]]
    >
    >______________________________________________
    >R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    >https://stat.ethz.ch/mailman/listinfo/r-help
    >PLEASE do read the posting guide
    >http://www.R-project.org/posting-guide.html
    >and provide commented, minimal, self-contained, reproducible code.
    
    -- 
    Sent from my phone. Please excuse my brevity.
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From bgunter@4567 @end|ng |rom gm@||@com  Tue Jun 19 00:04:57 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 18 Jun 2018 15:04:57 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
 <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
 <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
Message-ID: <CAGxFJbQDBtZ1KuLjxFE4oj19fpmE2ts4-wNB5Xy=ti4ehdPdng@mail.gmail.com>

search:

"Default function return R"

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 18, 2018 at 2:58 PM, Honkit Wong <stephen66 at gmail.com> wrote:

> Thanks!
> Why have to add ?x? at the end of function, which was what I missed.
>
> On Jun 18, 2018, at 2:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
>
> It depends on whether you wish to refer to the column to be logged by name
> or index.
>
> Reprex:
>
> set.seed(1234)
> dat <- lapply(1:3, function(i)data.frame(a = runif(5), b =
> sample(letters,5)))
>
> ## by numerical index of column
> d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})
>
> ## by name of column
> dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})
>
> There are also slight variations on how you can do the "[" indexing that
> others may post.
> Note that you have to return the modified data frame in the function.
>
> Cheers,
> Bert
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com> wrote:
>
>> Dear R community,
>> I have a question seems very simple but have trouble to do it.
>> I have a list which stores many data frames. Now, I want to perform log10
>> on one column in each data frame in the list and save the value as a new
>> column back to the original data frame in the list. How do I quickly do
>> that with lapply function ?
>>
>> Many thanks.
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From @tephen66 @end|ng |rom gm@||@com  Mon Jun 18 23:58:47 2018
From: @tephen66 @end|ng |rom gm@||@com (Honkit Wong)
Date: Mon, 18 Jun 2018 14:58:47 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
 <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
Message-ID: <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>

Thanks!
Why have to add ?x? at the end of function, which was what I missed. 

> On Jun 18, 2018, at 2:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> 
> It depends on whether you wish to refer to the column to be logged by name or index.
> 
> Reprex:
> 
> set.seed(1234)
> dat <- lapply(1:3, function(i)data.frame(a = runif(5), b = sample(letters,5)))
> 
> ## by numerical index of column
> d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})
> 
> ## by name of column
> dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})
> 
> There are also slight variations on how you can do the "[" indexing that others may post.
> Note that you have to return the modified data frame in the function.
> 
> Cheers,
> Bert
> 
> 
> 
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
>> On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com> wrote:
>> Dear R community,
>> I have a question seems very simple but have trouble to do it. 
>> I have a list which stores many data frames. Now, I want to perform log10 on one column in each data frame in the list and save the value as a new column back to the original data frame in the list. How do I quickly do that with lapply function ?
>> 
>> Many thanks. 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
> 

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Tue Jun 19 01:12:07 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 18 Jun 2018 16:12:07 -0700
Subject: [R] How to modify data frame stored in a list
In-Reply-To: <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
References: <A3A7D725-F08B-48FC-8FD2-9010E4C463A0@gmail.com>
 <CAGxFJbQYv1fURAvARk3fD7XqF5eTD5=dm+m+je2dNfjKSRPKMg@mail.gmail.com>
 <A6FFF7B3-EAB1-4EB4-90E4-9C1D327B6B57@gmail.com>
Message-ID: <CAF8bMcayfxSG9NJvdYSRkeeXBeyfB6khmqE_cNQotW1ffWKmCQ@mail.gmail.com>

 >Thanks!
>Why have to add ?x? at the end of function, which was what I missed.

You can see for yourself with some tests:

f1 <- function(x) { x[1] <- 10 }
f2 <- function(x) { x[1] <- 10 ; x }

print(f1(1:3)) # 10
print(f2(1:3)) # 10 2 3

An assignment returns the value of its right hand side but you want to
return the altered input.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 18, 2018 at 2:58 PM, Honkit Wong <stephen66 at gmail.com> wrote:

> Thanks!
> Why have to add ?x? at the end of function, which was what I missed.
>
> > On Jun 18, 2018, at 2:53 PM, Bert Gunter <bgunter.4567 at gmail.com> wrote:
> >
> > It depends on whether you wish to refer to the column to be logged by
> name or index.
> >
> > Reprex:
> >
> > set.seed(1234)
> > dat <- lapply(1:3, function(i)data.frame(a = runif(5), b =
> sample(letters,5)))
> >
> > ## by numerical index of column
> > d <- lapply(dat,function(x){x[,"logged"]<- log10(x[,1]); x})
> >
> > ## by name of column
> > dd <- lapply(dat,function(x){x[,"logged"]<- log10(x[,"a"]); x})
> >
> > There are also slight variations on how you can do the "[" indexing that
> others may post.
> > Note that you have to return the modified data frame in the function.
> >
> > Cheers,
> > Bert
> >
> >
> >
> >
> >
> >
> > Bert Gunter
> >
> > "The trouble with having an open mind is that people keep coming along
> and sticking things into it."
> > -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> >
> >> On Mon, Jun 18, 2018 at 1:46 PM, Honkit Wong <stephen66 at gmail.com>
> wrote:
> >> Dear R community,
> >> I have a question seems very simple but have trouble to do it.
> >> I have a list which stores many data frames. Now, I want to perform
> log10 on one column in each data frame in the list and save the value as a
> new column back to the original data frame in the list. How do I quickly do
> that with lapply function ?
> >>
> >> Many thanks.
> >> ______________________________________________
> >> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> https://stat.ethz.ch/mailman/listinfo/r-help
> >> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> >> and provide commented, minimal, self-contained, reproducible code.
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com  Tue Jun 19 04:16:04 2018
From: @eb@@t|en@b|hore| @end|ng |rom cogn|gencorp@com (Sebastien Bihorel)
Date: Mon, 18 Jun 2018 22:16:04 -0400 (EDT)
Subject: [R] Porbably bug in panel.abline
In-Reply-To: <CAGxFJbTwxi_jBbwyTx3BwGdGJVKcusVxdLgu8s7XEXgG+Tq9VA@mail.gmail.com>
References: <568887380.1732864.1529344871229.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbQ9JMa5L3nMZHF1XpWXgAe-mjT62SmPavaqdBnajwnLBA@mail.gmail.com>
 <298944307.1737183.1529348730559.JavaMail.zimbra@cognigencorp.com>
 <CAGxFJbTwxi_jBbwyTx3BwGdGJVKcusVxdLgu8s7XEXgG+Tq9VA@mail.gmail.com>
Message-ID: <296327582.1754843.1529374564328.JavaMail.zimbra@cognigencorp.com>

Paul Murrell posted some comments on [ https://github.com/deepayan/lattice/issues/8 | https://github.com/deepayan/lattice/issues/8 ]

----- Original Message -----
From: "Bert Gunter" <bgunter.4567 at gmail.com>
To: "Sebastien Bihorel" <sebastien.bihorel at cognigencorp.com>
Cc: "R-help" <r-help at r-project.org>
Sent: Monday, June 18, 2018 4:15:29 PM
Subject: Re: [R] Porbably bug in panel.abline

hmmm... 
Youre right: something subtle is occurring. 

Here is a simpler reproducible example that illustrates the issue: 

a <- 10 
y <- x <- c(0,a) 
for(k in c(-1,0,1)){ 
print(xyplot( 
y~x, 
type = 'l', col="blue", 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a+k,-1), col="red") 
} 
))} 

Somehow, the "drawable limits" seem to exclude the corners of the plotting rectangle. 

I would guess that this has something to do with how the plotting viewport is clipped, but that's just a guess. 

Cheers, 
Bert 

Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Mon, Jun 18, 2018 at 12:05 PM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 




No, the intercept a^2 f the abline is exactly the upper limit of the data, so it is in the range. 


From: "Bert Gunter" < [ mailto:bgunter.4567 at gmail.com | bgunter.4567 at gmail.com ] > 
To: "Sebastien Bihorel" < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > 
Cc: "R-help" < [ mailto:r-help at r-project.org | r-help at r-project.org ] > 
Sent: Monday, June 18, 2018 2:28:21 PM 
Subject: Re: [R] Porbably bug in panel.abline 

Note that: 

xyplot( 
y~x, 
data = data, 
type = 'l', col="blue", 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2-1,-1), col="red") 
} 
) 

works. The problem is a^2 is just above the "drawable" y axis limit (it is the intercept of the line at x=0 with slope -1, of course). This also explains all your other comments. 

Cheers, 
Bert 



-- 

Bert Gunter 

"The trouble with having an open mind is that people keep coming along and sticking things into it." 
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip ) 

On Mon, Jun 18, 2018 at 11:01 AM, Sebastien Bihorel < [ mailto:sebastien.bihorel at cognigencorp.com | sebastien.bihorel at cognigencorp.com ] > wrote: 

BQ_BEGIN
Hi, 

I recently encountered situations in which reference lines are not drawn with the lattice panel.abline function. Please, consider the following example code: 


require(lattice) 

a <- runif(1,0,100) 
data <- data.frame(x=c(0,a^2), y=c(0,a^2)) 

xyplot( 
y~x, 
data = data, 
type = 'l', 
panel = function(x,y,...){ 
panel.xyplot(x,y,...) 
panel.abline(c(a^2,-1.0), col=2) 
} 
) 

Adding noise (eg panel.abline(c(a^2+0.01,-1.0), col=2)) or adding some axis limits seems to bypass the problem. 

The problem also happens for different data source and abline coefficients: 
data <- data.frame(x=c(18,81), y=c(18,81)) 
... 
panel.abline(c(99,-1.0), col=2) 


Thank you in advance for your feedback. 

Sebastien 

PS: the problem was also posted at [ https://github.com/deepayan/lattice/issues/8 | https://github.com/deepayan/lattice/issues/8 ] 

______________________________________________ 
[ mailto:R-help at r-project.org | R-help at r-project.org ] mailing list -- To UNSUBSCRIBE and more, see 
[ https://stat.ethz.ch/mailman/listinfo/r-help | https://stat.ethz.ch/mailman/listinfo/r-help ] 
PLEASE do read the posting guide [ http://www.r-project.org/posting-guide.html | http://www.R-project.org/posting-guide.html ] 
and provide commented, minimal, self-contained, reproducible code. 





BQ_END



From md@umner @end|ng |rom gm@||@com  Tue Jun 19 07:32:25 2018
From: md@umner @end|ng |rom gm@||@com (Michael Sumner)
Date: Tue, 19 Jun 2018 12:32:25 +0700
Subject: [R] Subset Rasterbrick by time
In-Reply-To: <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
Message-ID: <CAAcGz99Md6L6efMRc7tBi+YFT7egGAnef4RYtnky-1eHCcnVYQ@mail.gmail.com>

On Mon, 18 Jun 2018, 22:09 David Winsemius, <dwinsemius at comcast.net> wrote:

>
>
> > On Jun 18, 2018, at 7:21 AM, Miluji Sb <milujisb at gmail.com> wrote:
> >
> > Dear all,
> >
> > I have a rasterbrick with the date/time information provided which I
> would
> > like to subset by year.
> >
> > However, when I use the following code for sub-setting;
> >
> > new_brick <- subset(original, which(getZ( original ) >=
> as.Date("2000-01-01
> > 10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))
> >
> > The date/time information seems to be lost.
> >
>

This is a bug, I tend to extract (getZ) the dates, do the subset logic on
both and restore (setZ).

It takes a bit of learning and practice, good luck. I can't expand more at
the moment. See R-Sig-Geo for more specific discussion forum, and #rstats
on twitter is really good.

Cheers, Mike

> > Furthermore, the class of the date/time seems to be character;
> >
> > ##
> > class(getZ( original ))
> > [1] "character"
> >
> > Is it possible to convert this string to date before sub-setting or
> retain
> > the date/time information after sub-setting?
>
> Yes, it is certainly possible, but why bother? R's Comparison operators
> work on character values so you should be able to do this (if the
> subsetting is syntactically correct:
>
>  new_brick <- subset(original, which(getZ( original ) >= "2000-01-01
> 10:30:00" & getZ(original ) <= "2014-12-31 10:30:00") )
>
>
> As always if you had presented the output of dput(head(original)) assuming
> that head is a meaningful operation on such an object, the demonstration
> would have been possible. An alternate would be to offer a library call to
> a package and then load a relevant example.
>
>
> Best;
> David
> >
> > ### original RasterBrick ###
> > class       : RasterBrick
> > dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
> > resolution  : 0.25, 0.25  (x, y)
> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > data source :
> >
> /work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_precip_windspd_sphum_daily_1986_2016.nc4
> > names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
> > X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
> > X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
> > X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
> > X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
> > X1986.01.15.10.30.00, ...
> > Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
> > varname     : v1
> >
> > ### new RasterBrick ###
> > class       : RasterStack
> > dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
> > resolution  : 0.25, 0.25  (x, y)
> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
> > names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
> > X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
> > X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
> > X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
> > X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
> > X2000.01.15.10.30.00, ...
> >
> > Any help will be greatly appreciated.
> >
> > Sincerely,
> >
> > Milu
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]



From m||uj|@b @end|ng |rom gm@||@com  Tue Jun 19 12:12:13 2018
From: m||uj|@b @end|ng |rom gm@||@com (Miluji Sb)
Date: Tue, 19 Jun 2018 12:12:13 +0200
Subject: [R] Subset Rasterbrick by time
In-Reply-To: <CAAcGz99Md6L6efMRc7tBi+YFT7egGAnef4RYtnky-1eHCcnVYQ@mail.gmail.com>
References: <CAMLwc7N3U2GH6+YJ030p9kJRtec=RdkkmYmBai9POK98jZXaYw@mail.gmail.com>
 <72F9131D-7C77-499E-8364-D1B191C9AE91@comcast.net>
 <CAAcGz99Md6L6efMRc7tBi+YFT7egGAnef4RYtnky-1eHCcnVYQ@mail.gmail.com>
Message-ID: <CAMLwc7MkDJh2vFQGCL5W9QM34cgPDfe2WXTZQGdb24uMd3KMEg@mail.gmail.com>

Dear David,

Subsetting works but the 'date' information is lost in the new file.

Thanks, Mike. I was not aware of the bug but will work on learning
about (getZ) and (setZ). Thanks again!

Sincerely,

Milu

On Tue, Jun 19, 2018 at 7:32 AM, Michael Sumner <mdsumner at gmail.com> wrote:

>
>
> On Mon, 18 Jun 2018, 22:09 David Winsemius, <dwinsemius at comcast.net>
> wrote:
>
>>
>>
>> > On Jun 18, 2018, at 7:21 AM, Miluji Sb <milujisb at gmail.com> wrote:
>> >
>> > Dear all,
>> >
>> > I have a rasterbrick with the date/time information provided which I
>> would
>> > like to subset by year.
>> >
>> > However, when I use the following code for sub-setting;
>> >
>> > new_brick <- subset(original, which(getZ( original ) >=
>> as.Date("2000-01-01
>> > 10:30:00") & getZ(original ) <= as.Date("2014-12-31 10:30:00")))
>> >
>> > The date/time information seems to be lost.
>> >
>>
>
> This is a bug, I tend to extract (getZ) the dates, do the subset logic on
> both and restore (setZ).
>
> It takes a bit of learning and practice, good luck. I can't expand more at
> the moment. See R-Sig-Geo for more specific discussion forum, and #rstats
> on twitter is really good.
>
> Cheers, Mike
>
>> > Furthermore, the class of the date/time seems to be character;
>> >
>> > ##
>> > class(getZ( original ))
>> > [1] "character"
>> >
>> > Is it possible to convert this string to date before sub-setting or
>> retain
>> > the date/time information after sub-setting?
>>
>> Yes, it is certainly possible, but why bother? R's Comparison operators
>> work on character values so you should be able to do this (if the
>> subsetting is syntactically correct:
>>
>>  new_brick <- subset(original, which(getZ( original ) >= "2000-01-01
>> 10:30:00" & getZ(original ) <= "2014-12-31 10:30:00") )
>>
>>
>> As always if you had presented the output of dput(head(original))
>> assuming that head is a meaningful operation on such an object, the
>> demonstration would have been possible. An alternate would be to offer a
>> library call to a package and then load a relevant example.
>>
>>
>> Best;
>> David
>> >
>> > ### original RasterBrick ###
>> > class       : RasterBrick
>> > dimensions  : 600, 1440, 864000, 11320  (nrow, ncol, ncell, nlayers)
>> > resolution  : 0.25, 0.25  (x, y)
>> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > data source :
>> > /work/mm01117/GLDAS_025_deg/daily/gldas_tavg_tmin_tmax_
>> precip_windspd_sphum_daily_1986_2016.nc4
>> > names       : X1986.01.01.10.30.00, X1986.01.02.10.30.00,
>> > X1986.01.03.10.30.00, X1986.01.04.10.30.00, X1986.01.05.10.30.00,
>> > X1986.01.06.10.30.00, X1986.01.07.10.30.00, X1986.01.08.10.30.00,
>> > X1986.01.09.10.30.00, X1986.01.10.10.30.00, X1986.01.11.10.30.00,
>> > X1986.01.12.10.30.00, X1986.01.13.10.30.00, X1986.01.14.10.30.00,
>> > X1986.01.15.10.30.00, ...
>> > Date/time   : 1986-01-01 10:30:00, 2016-12-31 10:30:00 (min, max)
>> > varname     : v1
>> >
>> > ### new RasterBrick ###
>> > class       : RasterStack
>> > dimensions  : 600, 1440, 864000, 5477  (nrow, ncol, ncell, nlayers)
>> > resolution  : 0.25, 0.25  (x, y)
>> > extent      : -180, 180, -60, 90  (xmin, xmax, ymin, ymax)
>> > coord. ref. : +proj=longlat +datum=WGS84 +ellps=WGS84 +towgs84=0,0,0
>> > names       : X2000.01.01.10.30.00, X2000.01.02.10.30.00,
>> > X2000.01.03.10.30.00, X2000.01.04.10.30.00, X2000.01.05.10.30.00,
>> > X2000.01.06.10.30.00, X2000.01.07.10.30.00, X2000.01.08.10.30.00,
>> > X2000.01.09.10.30.00, X2000.01.10.10.30.00, X2000.01.11.10.30.00,
>> > X2000.01.12.10.30.00, X2000.01.13.10.30.00, X2000.01.14.10.30.00,
>> > X2000.01.15.10.30.00, ...
>> >
>> > Any help will be greatly appreciated.
>> >
>> > Sincerely,
>> >
>> > Milu
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> <https://maps.google.com/?q=203+Channel+Highway+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
> Kingston Tasmania 7050 Australia
> <https://maps.google.com/?q=203+Channel+Highway+Kingston+Tasmania+7050+Australia&entry=gmail&source=g>
>
>

	[[alternative HTML version deleted]]



From m@ckenz|etjone@ @end|ng |rom gm@||@com  Tue Jun 19 23:54:42 2018
From: m@ckenz|etjone@ @end|ng |rom gm@||@com (Mackenzie Jones)
Date: Tue, 19 Jun 2018 16:54:42 -0500
Subject: [R] Multinomial Logistic Regression with Complex Survey using
 'Survey' Package in R
Message-ID: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>

Dear R Users,

I want to use a multinomial logistic regression model with survey data in the ?survey? package. The original package did not have a function for multinomial logistic regression, so Thomas Lumley suggested creating replicate weights for the survey and doing a multinomial regression with frequency weights in the mlogit package. See the below message for reference:

There isn't an implementation of multinomial regression in the survey package.  The easiest way to do this would be to create replicate weights for your survey if it doesn't already have them (with
as.svrepdesign()) and then use withReplicates() to do the regression using a function that does multinomial regression with frequency weights, such as mlogit() in the mlogit package.  The example on the withReplicates() help page shows how to do this for quantile regression, and it should be similar.

However, there has been a more recent release of the ?survey? package in May 2018, so I am wondering if there is now a function that does multinomial logistic regression with the survey. Please let me know if anyone knows of this update, or has any additional advice on how to perform this function.

Thank you,
Mackenzie


	[[alternative HTML version deleted]]



From @jd@m|co @end|ng |rom gm@||@com  Wed Jun 20 00:11:34 2018
From: @jd@m|co @end|ng |rom gm@||@com (Anthony Damico)
Date: Tue, 19 Jun 2018 18:11:34 -0400
Subject: [R] Multinomial Logistic Regression with Complex Survey using
 'Survey' Package in R
In-Reply-To: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
References: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
Message-ID: <CAOwvMDy0PiVaAF1fufRNJ9C8RPA5fT92nzjep1NHG+56oB8G_Q@mail.gmail.com>

hi, check out the news page..
https://cran.r-project.org/web/packages/survey/NEWS

On Tue, Jun 19, 2018 at 5:54 PM, Mackenzie Jones <mackenzietjones at gmail.com>
wrote:

> Dear R Users,
>
> I want to use a multinomial logistic regression model with survey data in
> the ?survey? package. The original package did not have a function for
> multinomial logistic regression, so Thomas Lumley suggested creating
> replicate weights for the survey and doing a multinomial regression with
> frequency weights in the mlogit package. See the below message for
> reference:
>
> There isn't an implementation of multinomial regression in the survey
> package.  The easiest way to do this would be to create replicate weights
> for your survey if it doesn't already have them (with
> as.svrepdesign()) and then use withReplicates() to do the regression using
> a function that does multinomial regression with frequency weights, such as
> mlogit() in the mlogit package.  The example on the withReplicates() help
> page shows how to do this for quantile regression, and it should be similar.
>
> However, there has been a more recent release of the ?survey? package in
> May 2018, so I am wondering if there is now a function that does
> multinomial logistic regression with the survey. Please let me know if
> anyone knows of this update, or has any additional advice on how to perform
> this function.
>
> Thank you,
> Mackenzie
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 20 00:33:40 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Tue, 19 Jun 2018 15:33:40 -0700
Subject: [R] Multinomial Logistic Regression with Complex Survey using
 'Survey' Package in R
In-Reply-To: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
References: <5b297ba3.1c69fb81.b24a7.1a24@mx.google.com>
Message-ID: <CAGxFJbQgpVV45P8=Owc2pjdvg1VD8ZitsMb2QXR7KrK2rrYF6A@mail.gmail.com>

Did you download the new package and check? Is there some reason you
shouldn't do this in any case?

There is also usually a News file in the package download that tells you
about new features.

-- Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Tue, Jun 19, 2018 at 2:54 PM, Mackenzie Jones <mackenzietjones at gmail.com>
wrote:

> Dear R Users,
>
> I want to use a multinomial logistic regression model with survey data in
> the ?survey? package. The original package did not have a function for
> multinomial logistic regression, so Thomas Lumley suggested creating
> replicate weights for the survey and doing a multinomial regression with
> frequency weights in the mlogit package. See the below message for
> reference:
>
> There isn't an implementation of multinomial regression in the survey
> package.  The easiest way to do this would be to create replicate weights
> for your survey if it doesn't already have them (with
> as.svrepdesign()) and then use withReplicates() to do the regression using
> a function that does multinomial regression with frequency weights, such as
> mlogit() in the mlogit package.  The example on the withReplicates() help
> page shows how to do this for quantile regression, and it should be similar.
>
> However, there has been a more recent release of the ?survey? package in
> May 2018, so I am wondering if there is now a function that does
> multinomial logistic regression with the survey. Please let me know if
> anyone knows of this update, or has any additional advice on how to perform
> this function.
>
> Thank you,
> Mackenzie
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From @|gbert @end|ng |rom w|w|@hu-ber||n@de  Wed Jun 20 10:08:11 2018
From: @|gbert @end|ng |rom w|w|@hu-ber||n@de (Sigbert Klinke)
Date: Wed, 20 Jun 2018 10:08:11 +0200
Subject: [R] Extract function parameters from a R expression
Message-ID: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>

Hi,

I have read an R program with

expr <- parse("myRprg.R")

How can I extract the parameters of a specifc R command, e.g. "library"?

So, if myprg.R containes the lines

library("xyz")
library("abc")

then I would like to get "xyz" and "abc" back from expr.

Thanks in advance

Sigbert

-- 
https://hu.berlin/sk



From h@w|ckh@m @end|ng |rom gm@||@com  Wed Jun 20 10:26:10 2018
From: h@w|ckh@m @end|ng |rom gm@||@com (Hadley Wickham)
Date: Wed, 20 Jun 2018 10:26:10 +0200
Subject: [R] Extract function parameters from a R expression
In-Reply-To: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
References: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
Message-ID: <CABdHhvERFOwgg0tSNbYUFp9wt23TRw_TdAp8YJ97KfXED90g8w@mail.gmail.com>

You need to recursively walk the parse tree/AST. See, e.g.,
https://adv-r.hadley.nz/expressions.html#ast-funs

Hadley

On Wed, Jun 20, 2018 at 10:08 AM, Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
> Hi,
>
> I have read an R program with
>
> expr <- parse("myRprg.R")
>
> How can I extract the parameters of a specifc R command, e.g. "library"?
>
> So, if myprg.R containes the lines
>
> library("xyz")
> library("abc")
>
> then I would like to get "xyz" and "abc" back from expr.
>
> Thanks in advance
>
> Sigbert
>
> --
> https://hu.berlin/sk
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
http://hadley.nz



From je@nph|||ppe@|ont@|ne @end|ng |rom g@@|@|n|n@|t  Wed Jun 20 12:53:00 2018
From: je@nph|||ppe@|ont@|ne @end|ng |rom g@@|@|n|n@|t (jean-philippe)
Date: Wed, 20 Jun 2018 12:53:00 +0200
Subject: [R] interpret a p-value result as a significance of a linear
 regression in terms of sigmas
Message-ID: <5B2A320C.9070301@gssi.infn.it>

dear R community,

I am running a linear regression for my dataset between 2 variables 
(disk mass and velocities).
This is the result returned by the summary function onto the lm object 
for one of my dataset.

Call:
lm(formula = df$md1 ~ df$logV, data = df)

Residuals:
      Min       1Q   Median       3Q      Max
-0.64856 -0.16492  0.04127  0.18027  0.45727

Coefficients:
             Estimate Std. Error t value Pr(>|t|)
(Intercept)   6.2582     0.2682  23.333  < 2e-16 ***
df$logV       1.2926     0.2253   5.738  6.5e-06 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1

Residual standard error: 0.3067 on 24 degrees of freedom
Multiple R-squared:  0.5784,    Adjusted R-squared:  0.5609
F-statistic: 32.93 on 1 and 24 DF,  p-value: 6.504e-06


I am interested to give the significance in terms of sigmas (as 
generally done in particle physics, see for instance the 7 \sigma 
discovery of the Higgs particle)
of my regression.
For this, if I understood well, I should look at the p-value for the 
F-statistic which is in this univariate linear regression the same as 
the one for logV.

My question is, am I right if I state that the significance in terms of 
sigmas (sign) is given by: p = 2*(1-pnorm(sign)) since I guess the 
p-value returned by R is for a two sided test (and assuming Gaussianity 
for my dataset)?

Otherwise is there any way to get the significance of this linear 
regression in terms of sigmas?

I would have a similar question also, as extension, for a multivariate 
linear regression for which the p-value associated to F statistics is 
not the same as the p-value for each variable of the regression.



Thanks in advance,


Best Regards


Jean-Philippe Fontaine

-- 
Jean-Philippe Fontaine
PhD Student in Astroparticle Physics,
Gran Sasso Science Institute (GSSI),
Viale Francesco Crispi 7,
67100 L'Aquila, Italy
Mobile: +393487128593, +33615653774



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 20 13:24:27 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 20 Jun 2018 04:24:27 -0700
Subject: [R] Extract function parameters from a R expression
In-Reply-To: <CABdHhvERFOwgg0tSNbYUFp9wt23TRw_TdAp8YJ97KfXED90g8w@mail.gmail.com>
References: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
 <CABdHhvERFOwgg0tSNbYUFp9wt23TRw_TdAp8YJ97KfXED90g8w@mail.gmail.com>
Message-ID: <CAGxFJbRJTVAoEcCOD4iZ9-NzTP++sV-mBrX+VEqVV-jPtr2K5g@mail.gmail.com>

... or if the argument is just quoted text or a numeric value as in your
library() example, don't parse the text and use regex's to search for the
function call and pick out the text of the arguments.

Again, this only works (I think) for the simple sort of case of your
example. Beyond that, you'll have to follow Hadley's prescription.

Cheers,
Bert





Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 20, 2018 at 1:26 AM, Hadley Wickham <h.wickham at gmail.com> wrote:

> You need to recursively walk the parse tree/AST. See, e.g.,
> https://adv-r.hadley.nz/expressions.html#ast-funs
>
> Hadley
>
> On Wed, Jun 20, 2018 at 10:08 AM, Sigbert Klinke
> <sigbert at wiwi.hu-berlin.de> wrote:
> > Hi,
> >
> > I have read an R program with
> >
> > expr <- parse("myRprg.R")
> >
> > How can I extract the parameters of a specifc R command, e.g. "library"?
> >
> > So, if myprg.R containes the lines
> >
> > library("xyz")
> > library("abc")
> >
> > then I would like to get "xyz" and "abc" back from expr.
> >
> > Thanks in advance
> >
> > Sigbert
> >
> > --
> > https://hu.berlin/sk
> >
> >
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
>
>
>
> --
> http://hadley.nz
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From murdoch@dunc@n @end|ng |rom gm@||@com  Wed Jun 20 13:42:48 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Wed, 20 Jun 2018 07:42:48 -0400
Subject: [R] interpret a p-value result as a significance of a linear
 regression in terms of sigmas
In-Reply-To: <5B2A320C.9070301@gssi.infn.it>
References: <5B2A320C.9070301@gssi.infn.it>
Message-ID: <fda79607-1ebe-251f-55f4-4bcaf7f3b777@gmail.com>

On 20/06/2018 6:53 AM, jean-philippe wrote:
> dear R community,
> 
> I am running a linear regression for my dataset between 2 variables
> (disk mass and velocities).
> This is the result returned by the summary function onto the lm object
> for one of my dataset.
> 
> Call:
> lm(formula = df$md1 ~ df$logV, data = df)
> 
> Residuals:
>        Min       1Q   Median       3Q      Max
> -0.64856 -0.16492  0.04127  0.18027  0.45727
> 
> Coefficients:
>               Estimate Std. Error t value Pr(>|t|)
> (Intercept)   6.2582     0.2682  23.333  < 2e-16 ***
> df$logV       1.2926     0.2253   5.738  6.5e-06 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 0.3067 on 24 degrees of freedom
> Multiple R-squared:  0.5784,    Adjusted R-squared:  0.5609
> F-statistic: 32.93 on 1 and 24 DF,  p-value: 6.504e-06
> 
> 
> I am interested to give the significance in terms of sigmas (as
> generally done in particle physics, see for instance the 7 \sigma
> discovery of the Higgs particle)
> of my regression.
> For this, if I understood well, I should look at the p-value for the
> F-statistic which is in this univariate linear regression the same as
> the one for logV.

The t value is probably what you want, but I think you'll have to ask 
your supervisor for the definition used in your area.

Duncan Murdoch

> 
> My question is, am I right if I state that the significance in terms of
> sigmas (sign) is given by: p = 2*(1-pnorm(sign)) since I guess the
> p-value returned by R is for a two sided test (and assuming Gaussianity
> for my dataset)?
> 
> Otherwise is there any way to get the significance of this linear
> regression in terms of sigmas?
> 
> I would have a similar question also, as extension, for a multivariate
> linear regression for which the p-value associated to F statistics is
> not the same as the p-value for each variable of the regression.
> 
> 
> 
> Thanks in advance,
> 
> 
> Best Regards
> 
> 
> Jean-Philippe Fontaine
>



From pd@|gd @end|ng |rom gm@||@com  Wed Jun 20 13:45:57 2018
From: pd@|gd @end|ng |rom gm@||@com (Peter Dalgaard)
Date: Wed, 20 Jun 2018 13:45:57 +0200
Subject: [R] interpret a p-value result as a significance of a linear
 regression in terms of sigmas
In-Reply-To: <5B2A320C.9070301@gssi.infn.it>
References: <5B2A320C.9070301@gssi.infn.it>
Message-ID: <61406CD4-5CF3-4852-B06A-6114D9B8179F@gmail.com>

Sorry to say so, but you seem confused. 

The "sigma" in physics parlance is presumably the s.e. of the estimate so the "number of sigmas" equal the t statistic, in this case 5.738. However, use of that measure ignores the t distribution, effectively assuming that there are infinite df (and 24 in not quite infinite). 

- pd

> On 20 Jun 2018, at 12:53 , jean-philippe <jeanphilippe.fontaine at gssi.infn.it> wrote:
> 
> dear R community,
> 
> I am running a linear regression for my dataset between 2 variables (disk mass and velocities).
> This is the result returned by the summary function onto the lm object for one of my dataset.
> 
> Call:
> lm(formula = df$md1 ~ df$logV, data = df)
> 
> Residuals:
>     Min       1Q   Median       3Q      Max
> -0.64856 -0.16492  0.04127  0.18027  0.45727
> 
> Coefficients:
>            Estimate Std. Error t value Pr(>|t|)
> (Intercept)   6.2582     0.2682  23.333  < 2e-16 ***
> df$logV       1.2926     0.2253   5.738  6.5e-06 ***
> ---
> Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> 
> Residual standard error: 0.3067 on 24 degrees of freedom
> Multiple R-squared:  0.5784,    Adjusted R-squared:  0.5609
> F-statistic: 32.93 on 1 and 24 DF,  p-value: 6.504e-06
> 
> 
> I am interested to give the significance in terms of sigmas (as generally done in particle physics, see for instance the 7 \sigma discovery of the Higgs particle)
> of my regression.
> For this, if I understood well, I should look at the p-value for the F-statistic which is in this univariate linear regression the same as the one for logV.
> 
> My question is, am I right if I state that the significance in terms of sigmas (sign) is given by: p = 2*(1-pnorm(sign)) since I guess the p-value returned by R is for a two sided test (and assuming Gaussianity for my dataset)?
> 
> Otherwise is there any way to get the significance of this linear regression in terms of sigmas?
> 
> I would have a similar question also, as extension, for a multivariate linear regression for which the p-value associated to F statistics is not the same as the p-value for each variable of the regression.
> 
> 
> 
> Thanks in advance,
> 
> 
> Best Regards
> 
> 
> Jean-Philippe Fontaine
> 
> -- 
> Jean-Philippe Fontaine
> PhD Student in Astroparticle Physics,
> Gran Sasso Science Institute (GSSI),
> Viale Francesco Crispi 7,
> 67100 L'Aquila, Italy
> Mobile: +393487128593, +33615653774
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com



From ggrothend|eck @end|ng |rom gm@||@com  Wed Jun 20 13:52:49 2018
From: ggrothend|eck @end|ng |rom gm@||@com (Gabor Grothendieck)
Date: Wed, 20 Jun 2018 07:52:49 -0400
Subject: [R] Extract function parameters from a R expression
In-Reply-To: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
References: <eb4e5ac8-fa85-d019-b69d-43aa8e18b37c@wiwi.hu-berlin.de>
Message-ID: <CAP01uRmn68-=mRwK3FKMaR25Y5d8++H0CQMEydMFv0VxD=ZWAw@mail.gmail.com>

If you specifically want to know which packages were loaded by the script
then using a vanilla version of R (i.e. one where only base packages are
loaded):

  vanilla_search <- search()
  source("myRprg.R")
  setdiff(search(), vanilla_search)



On Wed, Jun 20, 2018 at 4:08 AM, Sigbert Klinke
<sigbert at wiwi.hu-berlin.de> wrote:
> Hi,
>
> I have read an R program with
>
> expr <- parse("myRprg.R")
>
> How can I extract the parameters of a specifc R command, e.g. "library"?
>
> So, if myprg.R containes the lines
>
> library("xyz")
> library("abc")
>
> then I would like to get "xyz" and "abc" back from expr.
>
> Thanks in advance
>
> Sigbert
>
> --
> https://hu.berlin/sk
>
>
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com



From |orenzo@|@e||@ @end|ng |rom gm@||@com  Wed Jun 20 17:50:48 2018
From: |orenzo@|@e||@ @end|ng |rom gm@||@com (Lorenzo Isella)
Date: Wed, 20 Jun 2018 17:50:48 +0200
Subject: [R] Optimisation with Normalisation Constraint
Message-ID: <20180620155048.luwh3w7o7cp5lujr@masha>

Dear All,
I have a problem I haver been struggling with for a while: I need to
carry out a non-linear fit (and this is the
easy part).
I have a set of discrete values {x1,x2...xN} and the corresponding
{y1, y2...yN}. The difficulty is that I would like the linear fit to
preserve the sum of the values y1+y2+...yN.
I give an example below (for which there may even be an analytical
solution, but that is not the point here)

############################################################################
library(minpack.lm)



set.seed(124)

z <- rexp(3000,3)


zf <- z[z<= 0.5 | z>=0.9]

myhist <- hist(zf, plot=FALSE) 



df <- data.frame(x=myhist$mids, y=myhist$density)



myfit <- nlsLM(y~(A*exp(-lambda*x))
                ,data=df, start=list(A=1,lambda=1))



> sum(myhist$density)
[1] 5
> sum(predict(myfit))
[1] 4.931496

############################################################################
I would like sum(predict(myfit)) to be exactly 5 from the start,
without renormalising a posteriori the fit.

Any suggestion is appreciated.
Cheers

Lorenzo



From p@u|bern@|07 @end|ng |rom gm@||@com  Wed Jun 20 18:00:53 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Wed, 20 Jun 2018 11:00:53 -0500
Subject: [R] Any Unsupervised Learning Algorithm for Time Series Forecasting
 in R
Message-ID: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>

Dear friends,

Hope you are all doing great. I would like to know if R has any
unsupervised algorithm to generate forecasts for historical data.

Any help will be greatly appreciated,

Best regards,

Paul

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 20 18:30:51 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 20 Jun 2018 09:30:51 -0700
Subject: [R] 
 Any Unsupervised Learning Algorithm for Time Series Forecasting in R
In-Reply-To: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
References: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
Message-ID: <CAGxFJbTreby+0qo1J=GUhNTasYORyPrqfHjV4ffVHs491ZS5CA@mail.gmail.com>

Depending on exactly what you mean by"unsupervised", many.

See here under "Decomposition and filtering":

https://cran.r-project.org/web/views/TimeSeries.html

You could also search on something like "smooth time series R" etc.

However, assuming I have correcty interpreted "unsupervised algorithm," be
aware that extrapolating from such smoothed historical data can be
problematic precisely because no structure/model has been specified. See
here for some further background and R functions:

http://a-little-book-of-r-for-time-series.readthedocs.io/en/latest/src/timeseries.html#holt-winters-exponential-smoothing


Cheers,
Bert






Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 20, 2018 at 9:00 AM, Paul Bernal <paulbernal07 at gmail.com> wrote:

> Dear friends,
>
> Hope you are all doing great. I would like to know if R has any
> unsupervised algorithm to generate forecasts for historical data.
>
> Any help will be greatly appreciated,
>
> Best regards,
>
> Paul
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Wed Jun 20 18:34:34 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 20 Jun 2018 09:34:34 -0700
Subject: [R] 
 Any Unsupervised Learning Algorithm for Time Series Forecasting in R
In-Reply-To: <CAGxFJbTreby+0qo1J=GUhNTasYORyPrqfHjV4ffVHs491ZS5CA@mail.gmail.com>
References: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
 <CAGxFJbTreby+0qo1J=GUhNTasYORyPrqfHjV4ffVHs491ZS5CA@mail.gmail.com>
Message-ID: <CAGxFJbSV6N54KUQdsDeRvjF8rFttMbXMRjtPmTe5eEEFu6jkFw@mail.gmail.com>

... and II should have added that the "forecast" package may be what you're
looking for.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 20, 2018 at 9:30 AM, Bert Gunter <bgunter.4567 at gmail.com> wrote:

> Depending on exactly what you mean by"unsupervised", many.
>
> See here under "Decomposition and filtering":
>
> https://cran.r-project.org/web/views/TimeSeries.html
>
> You could also search on something like "smooth time series R" etc.
>
> However, assuming I have correcty interpreted "unsupervised algorithm," be
> aware that extrapolating from such smoothed historical data can be
> problematic precisely because no structure/model has been specified. See
> here for some further background and R functions:
>
> http://a-little-book-of-r-for-time-series.readthedocs.io/en/
> latest/src/timeseries.html#holt-winters-exponential-smoothing
>
>
> Cheers,
> Bert
>
>
>
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Jun 20, 2018 at 9:00 AM, Paul Bernal <paulbernal07 at gmail.com>
> wrote:
>
>> Dear friends,
>>
>> Hope you are all doing great. I would like to know if R has any
>> unsupervised algorithm to generate forecasts for historical data.
>>
>> Any help will be greatly appreciated,
>>
>> Best regards,
>>
>> Paul
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From h@@@n@d|w@n @end|ng |rom gm@||@com  Wed Jun 20 22:46:31 2018
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Wed, 20 Jun 2018 13:46:31 -0700
Subject: [R] 
 Any Unsupervised Learning Algorithm for Time Series Forecasting in R
In-Reply-To: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
References: <CAMOcQfNo+fKyUwXQ6wANkn8W1_yUvo1X_qwSRBK29eSvQ01x8g@mail.gmail.com>
Message-ID: <CAP+bYWDpfwQjrFROpCdNM8w-5KzFgU6Oawsm+brcGZ3Y=kh_YA@mail.gmail.com>

Paul,

On Wed, 20 Jun 2018 at 09:04, Paul Bernal <paulbernal07 at gmail.com> wrote:
> I would like to know if R has any unsupervised algorithm to generate forecasts for historical data.

Yes , it does. Perhaps you'd be kind enough to provide a sample of
your data --dput(sample(pauls.data)) on gist.github.com -- and what
you wish to achieve with it? Many thanks! -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 21 00:21:29 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 20 Jun 2018 15:21:29 -0700
Subject: [R] Optimisation with Normalisation Constraint
In-Reply-To: <20180620155048.luwh3w7o7cp5lujr@masha>
References: <20180620155048.luwh3w7o7cp5lujr@masha>
Message-ID: <697B5B62-649C-463C-86EA-D00BE707A0F8@dcn.davis.ca.us>

I recommend posting this on a mathematics discussion forum like Stack Exchange and (re-)reading the Posting Guide for this mailing list.

I think you are going to need to re-write your model function to algebraically combine your original model along with the constraint, and then use the original model alone for prediction... but I haven't tried it so might be quite far off the mark.

On June 20, 2018 8:50:48 AM PDT, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
>Dear All,
>I have a problem I haver been struggling with for a while: I need to
>carry out a non-linear fit (and this is the
>easy part).
>I have a set of discrete values {x1,x2...xN} and the corresponding
>{y1, y2...yN}. The difficulty is that I would like the linear fit to
>preserve the sum of the values y1+y2+...yN.
>I give an example below (for which there may even be an analytical
>solution, but that is not the point here)
>
>############################################################################
>library(minpack.lm)
>
>
>
>set.seed(124)
>
>z <- rexp(3000,3)
>
>
>zf <- z[z<= 0.5 | z>=0.9]
>
>myhist <- hist(zf, plot=FALSE) 
>
>
>
>df <- data.frame(x=myhist$mids, y=myhist$density)
>
>
>
>myfit <- nlsLM(y~(A*exp(-lambda*x))
>                ,data=df, start=list(A=1,lambda=1))
>
>
>
>> sum(myhist$density)
>[1] 5
>> sum(predict(myfit))
>[1] 4.931496
>
>############################################################################
>I would like sum(predict(myfit)) to be exactly 5 from the start,
>without renormalising a posteriori the fit.
>
>Any suggestion is appreciated.
>Cheers
>
>Lorenzo
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From dw|n@em|u@ @end|ng |rom comc@@t@net  Thu Jun 21 02:04:28 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Wed, 20 Jun 2018 17:04:28 -0700
Subject: [R] Optimisation with Normalisation Constraint
In-Reply-To: <20180620155048.luwh3w7o7cp5lujr@masha>
References: <20180620155048.luwh3w7o7cp5lujr@masha>
Message-ID: <D19FBACC-3A56-41BB-9D4F-038803F08A86@comcast.net>


> On Jun 20, 2018, at 8:50 AM, Lorenzo Isella <lorenzo.isella at gmail.com> wrote:
> 
> Dear All,
> I have a problem I haver been struggling with for a while: I need to
> carry out a non-linear fit (and this is the
> easy part).
> I have a set of discrete values {x1,x2...xN} and the corresponding
> {y1, y2...yN}. The difficulty is that I would like the linear fit to
> preserve the sum of the values y1+y2+...yN.
> I give an example below (for which there may even be an analytical
> solution, but that is not the point here)
> 
> ############################################################################
> library(minpack.lm)
> 
> 
> 
> set.seed(124)
> 
> z <- rexp(3000,3)
> 
> 
> zf <- z[z<= 0.5 | z>=0.9]
> 
> myhist <- hist(zf, plot=FALSE) 
> 
> 
> df <- data.frame(x=myhist$mids, y=myhist$density)
> 
> 
> 
> myfit <- nlsLM(y~(A*exp(-lambda*x))
>               ,data=df, start=list(A=1,lambda=1))
> 
> 
> 
>> sum(myhist$density)
> [1] 5
>> sum(predict(myfit))
> [1] 4.931496
> 
> ############################################################################
> I would like sum(predict(myfit)) to be exactly 5 from the start,
> without renormalising a posteriori the fit.

Wouldn't that happen if you minimized that absolute deviations from the fit rather than minimizing the sums of squares??
> 
> Any suggestion is appreciated.
> Cheers
> 
> Lorenzo
> 

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From @k@h@y_e4 @end|ng |rom hotm@||@com  Thu Jun 21 12:28:03 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Thu, 21 Jun 2018 10:28:03 +0000
Subject: [R] compiling functions....
Message-ID: <SL2P216MB00911F10E3834E8F0232FF2BC8760@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I a Day Trader based in INDIA. I use R for my research. I have a function ygusa(snlq,snlcqn) which takes 208 stocks and returns 4 best stocks for the next day(snlq is the list of 208 stocks and snlcqn is their names). However, the execution time is around 2 hrs, making it hard for me.

I recently read in the internet that you can precompile the code in R to make it run faster. Also that you can enable JIT(just in time compilation) from your R session automatically. I came to know that R 3.4.x has JIT enabled in it by default. Is it true? Is it also true that even after enabling JIT in R 3.4.x, the first run of a function is not Byte compiled?

So when I start my R session, download the data, and run ygusa(snlq,snlcqn), it is not byte compiled and therefore it is very slow? Will including the following lines in ygusa solve my problem:
> require(compiler)
> enableJIT(3)

?

Also, instead of compiling the function ygusa every time I run it, can I compile it once and store it, and run that compiled file instead of ygusa(snlq,snlcqn)?

Can you point me to some online resources that can help on this issue?

very many thanks for your time and effort...
Yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From @@r@h@go@|ee @end|ng |rom gm@||@com  Thu Jun 21 15:29:45 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Thu, 21 Jun 2018 09:29:45 -0400
Subject: [R] compiling functions....
In-Reply-To: <SL2P216MB00911F10E3834E8F0232FF2BC8760@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00911F10E3834E8F0232FF2BC8760@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAM_vjun6kQZFHNYT1GbGOSC=L7rq+J9icsQw3nnj=S2+51eYbg@mail.gmail.com>

There are many things you can do to improve speed in R. Byte compiling
is just one of them.

This chapter in Hadley Wickham's excellent Advanced R book covers both
profiling and byte compiling.

http://adv-r.had.co.nz/Profiling.html

I've gotten some stunning improvements in speed through profiling and
careful thought: 3 days to 3 seconds, even.

Sarah

On Thu, Jun 21, 2018 at 6:28 AM, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
> dear members,
>                             I a Day Trader based in INDIA. I use R for my research. I have a function ygusa(snlq,snlcqn) which takes 208 stocks and returns 4 best stocks for the next day(snlq is the list of 208 stocks and snlcqn is their names). However, the execution time is around 2 hrs, making it hard for me.
>
> I recently read in the internet that you can precompile the code in R to make it run faster. Also that you can enable JIT(just in time compilation) from your R session automatically. I came to know that R 3.4.x has JIT enabled in it by default. Is it true? Is it also true that even after enabling JIT in R 3.4.x, the first run of a function is not Byte compiled?
>
> So when I start my R session, download the data, and run ygusa(snlq,snlcqn), it is not byte compiled and therefore it is very slow? Will including the following lines in ygusa solve my problem:
>> require(compiler)
>> enableJIT(3)
>
> ?
>
> Also, instead of compiling the function ygusa every time I run it, can I compile it once and store it, and run that compiled file instead of ygusa(snlq,snlcqn)?
>
> Can you point me to some online resources that can help on this issue?
>
> very many thanks for your time and effort...
> Yours sincerely,
> AKSHAY M KULKARNI
>


-- 
Sarah Goslee
http://www.functionaldiversity.org



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Jun 21 18:35:36 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 21 Jun 2018 11:35:36 -0500
Subject: [R] KNN
Message-ID: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>

R-Help

 

Does one need to normalize ones data is using the knn function within the
caret Library.

 

Jeff


	[[alternative HTML version deleted]]



From dc@r|@on @end|ng |rom t@mu@edu  Thu Jun 21 18:43:00 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Thu, 21 Jun 2018 16:43:00 +0000
Subject: [R] KNN
In-Reply-To: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
References: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
Message-ID: <a483a42a966f46c9aaa715c3b33162c2@tamu.edu>

It depends on what you are trying to do and what kind of data you are using. If you are using Euclidian distance and your variables have different means and standard deviations, the answer is probably yes. That will weight each variable equally. Without standardization the variables with the larger magnitudes will determine the groups more than the variables with the smaller magnitudes.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff Reichman
Sent: Thursday, June 21, 2018 11:36 AM
To: R-help at r-project.org
Subject: [R] KNN

R-Help

 

Does one need to normalize ones data is using the knn function within the
caret Library.

 

Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From he||o @end|ng |rom e|v|nddov|k@com  Thu Jun 21 18:46:05 2018
From: he||o @end|ng |rom e|v|nddov|k@com (Eivind K. Dovik)
Date: Thu, 21 Jun 2018 18:46:05 +0200 (CEST)
Subject: [R] KNN
In-Reply-To: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
References: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
Message-ID: <alpine.LFD.2.21.1806211843390.911@localhost>

Yes, however using caret you  can do it directly 
using the preProcess parameter, e.g. train(y ~., data 
= train, method = "knn", preProcess = c("center", "scale")).

Hope this helps.


Eivind


On Thu, 21 Jun 2018, Jeff Reichman wrote:

> R-Help
>
>
>
> Does one need to normalize ones data is using the knn function within the
> caret Library.
>
>
>
> Jeff
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Jun 21 18:46:54 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 21 Jun 2018 11:46:54 -0500
Subject: [R] KNN
In-Reply-To: <a483a42a966f46c9aaa715c3b33162c2@tamu.edu>
References: <000601d4097d$e2434b50$a6c9e1f0$@sbcglobal.net>
 <a483a42a966f46c9aaa715c3b33162c2@tamu.edu>
Message-ID: <000d01d4097f$764caca0$62e605e0$@sbcglobal.net>

David

I figured out where I went wrong.  But thank you for the response

Jeff

-----Original Message-----
From: David L Carlson <dcarlson at tamu.edu> 
Sent: Thursday, June 21, 2018 11:43 AM
To: reichmanj at sbcglobal.net; R-help at r-project.org
Subject: RE: [R] KNN

It depends on what you are trying to do and what kind of data you are using
If you are using Euclidian distance and your variables have different means
and standard deviations, the answer is probably yes. That will weight each
variable equally. Without standardization the variables with the larger
magnitudes will determine the groups more than the variables with the
smaller magnitudes.

David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Jeff
Reichman
Sent: Thursday, June 21, 2018 11:36 AM
To: R-help at r-project.org
Subject: [R] KNN

R-Help

 

Does one need to normalize ones data is using the knn function within the
caret Library.

 

Jeff


	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t  Fri Jun 22 02:07:46 2018
From: Ach|m@Ze||e|@ @end|ng |rom u|bk@@c@@t (Achim Zeileis)
Date: Fri, 22 Jun 2018 02:07:46 +0200 (CEST)
Subject: [R] package colorspace and .WhitePoint question
In-Reply-To: <alpine.DEB.2.21.1806040940020.26338@paninaro>
References: <CAEvk5z+O3GKYu6pgaUamDS0pD1DDZALTST8Vo4WEtw2Z9d8waw@mail.gmail.com>
 <alpine.DEB.2.21.1806040940020.26338@paninaro>
Message-ID: <alpine.DEB.2.21.1806220203240.10704@paninaro>

As a follow-up to this issue:

A revised version of the "colorspace" package is now available on R-Forge 
at https://R-Forge.R-project.org/R/?group_id=20

This provides a function whitepoint() that can query and/or modify the 
whitepoint used in all color conversions within the package. To try it you 
can do:

install.packages("colorspace", repos="http://R-Forge.R-project.org")
example("whitepoint", package = "colorspace")

Glenn, it would be great if you could try this and let us know if any 
problems remain.


On Mon, 4 Jun 2018, Achim Zeileis wrote:

> Glenn,
>
> currently, this is currently not exposed in "colorspace" AFAICS. You can 
> modify it by changing .WhitePoint inside colorspace's NAMESPACE, though:
>
> R> assignInNamespace(".WhitePoint", rbind(c(95, 100, 105)),
> +    ns = "colorspace")
> R> as(XYZ(100, 100, 100), "LAB")
>       L        A        B
> [1,] 100 8.622384 3.226371
>
> I'll have another look whether this could be exposed easily (cc also Paul).
>
> Best,
> Z
>
> On Mon, 4 Jun 2018, Glenn Davis wrote:
>
>> In colorspace.R  I see:
>>
>>    setAs("color", "LAB", function(from)
>>      LAB(.Call("as_LAB", from at coords, class(from), .WhitePoint, PACKAGE = "
>> colorspace"),
>>          names = dimnames(from at coords)[[1]]))
>>    ...
>>    .WhitePoint = NULL
>> 
>> and then in colorspace.c and the function CheckWhite(),
>> I see that .WhitePoint = NULL is converted to D65.
>> 
>> I would like to pass a different .WhitePoint to
>>    as( XYZ( 100,100,100)  , "LAB" )
>> 
>> 
>> I have tried 3 methods:
>>    as( XYZ( 100,100,100)  , "LAB", .WhitePoint=XYZ(95,100,105) )
>>    .WhitePoint = XYZ(95,100,105)
>>    assign( ".WhitePoint", XYZ(95,100,105), env=as.environment('package:
>> colorspace') )
>> but all fail, for different reasons.
>> 
>> How can I transform XYZ to LAB using a whitepoint different than D65 ?
>> 
>> Thanks,
>> Glenn Davis
>> gdavis at gluonics.com
>>
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide 
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>> 
>



From hwborcher@ @end|ng |rom gm@||@com  Fri Jun 22 09:27:14 2018
From: hwborcher@ @end|ng |rom gm@||@com (Hans W Borchers)
Date: Fri, 22 Jun 2018 09:27:14 +0200
Subject: [R] Optimisation with Normalisation Constraint
Message-ID: <CAML4n3OuMBF3oVOm9WKRaii9UfyGbRWuyPBPrJANX2tGWbP4iA@mail.gmail.com>

One way will be to solve this as an ordinary optimization problem with
an equality constraint. Function `alabama::auglag` can do this:

    library(alabama)
    fn <- function(p) sum((df$y - p[1]*exp(-p[2]*df$x))^2)
    heq <- function(p) sum(p[1]*exp(-p[2]*df$x)) - 5

    # Start with initial values near first solution
    sol <- auglag(c(4, 4), fn=fn, heq=heq)

Solution with myfit:    4.134    4.078
Solution with auglag:   4.126763 4.017768

The equality constraint is still fulfilled:

    a <- sol$par[1]; lambda <- sol$par[2]
    sum(a*exp(-lambda*df$x))
    ## [1] 5

Plot the differences of these two solutions:

    plot(df$x, a*exp(-lambda*df$x) - predict(myfit), type='l')

Interestingly, the difference between 5 and `predict(myfit)` is *not*
just evenly spread across all 15 points.



From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Jun 22 12:12:28 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 22 Jun 2018 10:12:28 +0000
Subject: [R] parallel computing in r....
Message-ID: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                            I am taking recourse to parallel computing to speed up my R code.

The mcparallel function(in parallel package),presumably, sends a single task (an R function, to be precise) to a single core. Is this right? Is that one and only one core? What if there are other cores lying idle?

As far as I am concerned, I am going to rent an AWS EC2 server with 48 cores. I have four functions to be parallelized. Can I send the thread of one function to 12 cores, so that all 48 cores are utilized? If so, how do I do that with mcparallel function in the parallel package?

Very many thanks for your time and effort...
yours sincerely....
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Fri Jun 22 13:43:25 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 22 Jun 2018 11:43:25 +0000
Subject: [R] Help with transpose please.
Message-ID: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>

Good morning.


I have data in the form:

head(Edit041IA, n=25)
   ClaimServiceID  ClaimID DiagnosisCode
1       183056004 78044473          C562
2       183056004 78044473          C778
3       183056004 78044473          C784
4       183056004 78044473          C786
5       183056004 78044473         C7961
6       183056004 78044473         C7982
7       183056004 78044473         C7989
8       183056008 78044473          C562
9       183056008 78044473          C778
10      183056008 78044473          C784
11      183056008 78044473          C786
12      183056008 78044473         C7961
13      183056008 78044473         C7982
14      183056008 78044473         C7989
15      183139945 78078925        M79606
16      183139945 78078925         M7989
17      183139945 78078925          R600
18      183236728 78119632        H02831
19      183236728 78119632        H02832
20      183236728 78119632        H02834
21      183236728 78119632        H02835
22      183236728 78119632        H04123
23      183236728 78119632          Z411
24      183236728 78119632         H2513
25      183236728 78119632        H43813

And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:

There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.

    claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc


(If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",

"ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,

-1272L))



At the moment the classes are:

classes <- as.character(sapply(Edit041IA, class))

classes

# [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in

The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.

I have looked at a variety of webpages and cannot get this right,

dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
View(dta2)
 # https://www.r-bloggers.com/pivot-tables-in-r/

# https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function


dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
View(dta3)
dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
View(dta3)

dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
View(dta3)

dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
View(dta3)


dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
View(dta3)
 # https://www.r-statistics.com/tag/transpose/

 dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
View(dta3)


I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.

WHP





Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From r@me@h@y@p@|p@rv| @end|ng |rom |c|oud@com  Fri Jun 22 13:46:45 2018
From: r@me@h@y@p@|p@rv| @end|ng |rom |c|oud@com (Ramesh YAPALPARVI)
Date: Fri, 22 Jun 2018 07:46:45 -0400
Subject: [R] Help with transpose please.
In-Reply-To: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <93AA619D-1A7A-4875-94C2-4F3716656303@icloud.com>

Please check out tidyr package and use commands like spread/ gather which would make data wide or long



> On Jun 22, 2018, at 07:43, Bill Poling <Bill.Poling at zelis.com> wrote:
> 
> Good morning.
> 
> 
> I have data in the form:
> 
> head(Edit041IA, n=25)
>   ClaimServiceID  ClaimID DiagnosisCode
> 1       183056004 78044473          C562
> 2       183056004 78044473          C778
> 3       183056004 78044473          C784
> 4       183056004 78044473          C786
> 5       183056004 78044473         C7961
> 6       183056004 78044473         C7982
> 7       183056004 78044473         C7989
> 8       183056008 78044473          C562
> 9       183056008 78044473          C778
> 10      183056008 78044473          C784
> 11      183056008 78044473          C786
> 12      183056008 78044473         C7961
> 13      183056008 78044473         C7982
> 14      183056008 78044473         C7989
> 15      183139945 78078925        M79606
> 16      183139945 78078925         M7989
> 17      183139945 78078925          R600
> 18      183236728 78119632        H02831
> 19      183236728 78119632        H02832
> 20      183236728 78119632        H02834
> 21      183236728 78119632        H02835
> 22      183236728 78119632        H04123
> 23      183236728 78119632          Z411
> 24      183236728 78119632         H2513
> 25      183236728 78119632        H43813
> 
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
> 
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
> 
>    claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
> 1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc
> 
> 
> (If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
> 
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
> 
> -1272L))
> 
> 
> 
> At the moment the classes are:
> 
> classes <- as.character(sapply(Edit041IA, class))
> 
> classes
> 
> # [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
> 
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
> 
> I have looked at a variety of webpages and cannot get this right,
> 
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/
> 
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function
> 
> 
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
> 
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
> 
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/
> 
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
> 
> 
> I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
> 
> WHP
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @rued@ @end|ng |rom ced@u@b@e@  Fri Jun 22 14:13:36 2018
From: @rued@ @end|ng |rom ced@u@b@e@ (=?UTF-8?Q?Sarah=C3=AD_Rueda_Salazar?=)
Date: Fri, 22 Jun 2018 14:13:36 +0200
Subject: [R] Coxme, package updated on May 2018,
 Similar case to Re:  CoxME: Family relatedness
Message-ID: <CAHRw6-9Ma+BYY28qB4EY3x_AGK72WOHuDsonEVRAqBuT2P_WbA@mail.gmail.com>

Dear Terry,

I can imagine that you are overwhelming with a quite large demand of
request emails, so I hope (always optimistic) that you have time to see
this email.

It is related to the recently updated version of coxme package.  Currently,
I work with multistate models with changes in health status on elder
population.  I use coxPH by stratifying the hazard by different transition
type ( deterioration, health improvements, death from healthy status and
death from not healthy status). I use mstate and Biograph packages to
reshape my data disentangling different events by transition type (1:4)

So, I wondered if I can apply mixed effect on my multistate model to see
the differences by countries (shared frailty).  I?ve read the material you
post on May 11, 2018 and other several materials in this subject :Steele et
al:2004, Austin : 2017,Putter: 2014, Willekens: 2014, Brost?n:2011, Mills,
2011 and finally Allison which provide me a quite understandable approach
in the line of my humble knowledge in mathematical demography.

I thought it is not possible to use to multilevel in
multistate with coxme package. By stratifying the hazard  (reference risk
by interested covariates )  by my transitions type, I make hazard be
free(no proportional by transition type) and it means that the model
estimates separate baseline hazard for the different values of transition
type ( following this material by Putter( 2018:7
<https://cran.r-project.org/web/packages/mstate/vignettes/Tutorial.pdf>)

It is a simple model using sex , reference category "male" with my data:

> modelSex.0 <- coxph(Surv(Tstarta,Tstopa,status) ~
+                        SexF.1+ SexF.2+SexF.3+SexF.4+
+                       strata(trans),
+                     data=d0)

SexF.1= related to covariate sex  in transition 1(healthy to not healthy)
SexF.2 = transition healthy to death
SexF.3= transition  Not healthy to Healthy
SexF.4= transition  Not healthy to Death

But, I came across  this post
<https://stat.ethz.ch/pipermail/r-help/2014-September/421690.html>  where
you replied a request ( I copy a chunk that I?m interested in):

2. The model above is the correct covariance structure for a set of
> families. There is a
> single intercept per subject, with a complex correlation matrix. The
> simpler "per family"
> frailty model would be



> model4 <- coxme(Surv(Survival, Event) ~ Sex + strata(cohort) + SNP1 + SNP2
> + SNP3 +
> (1|famid), death.dat)



> This model lets each family have a separate risk, with everyone in the
> same family sharing
> the exact same risk. It is less general than model3 above which lets a
> family have higher
> risk plus has variation between family members. A model with both
> per-subject and per family terms is identical to one with a covariance
> matrix of s1 K + s2 B, where K is the kinship matrix, B is a block
> diagonal matrix which
> has a solid block of "1" for each family, and s1 s2 are the fitted
> variance coefficients.


 So, my strata would be my transition type (trans) instead "cohort"  and my
groups (instead famid) would be country, as follows


> modelSex.1 <- coxme(Surv(Tstarta,Tstopa,status) ~
+                        SexF.1+ SexF.2+SexF.3+SexF.4+
+                       (1|Country),
+                     data=d0)

> anova(modelSex.0,modelSex.1)

Analysis of Deviance Table
 Cox model: response is  Surv(Tstarta, Tstopa, status)
 Model 1: ~ SexF.1+ SexF.2+SexF.3+SexF.4+ strata(trans)
 Model 2: ~ SexF.1+ SexF.2+SexF.3+SexF.4+ strata(trans) + (1 | Country)
    loglik  Chisq Df P(>|Chi|)
1 -1342082
2 -1339605 4953.8  1 < 2.2e-16 ***
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1
> stem(exp(ranef(modelSex.1)[[1]]))

  The decimal point is 1 digit(s) to the left of the |

   6 | 589
   8 | 1448477
  10 | 115669
  12 | 0846

> exp(ranef(modelSex.1)[[1]])
       AT        BE        BG        CY        CZ        EE
1.1981346 0.9712875 0.8092424 1.3614033 0.8382588 1.0117071
       EL        ES        HU        IE        IT        LT
0.7514988 1.2761863 1.0085404 0.8760514 1.1615717 0.9708070
       LU        LV        MT        PL        PT        RO
1.1893096 1.3381012 1.0522161 0.7843473 1.1642434 0.7911292
       SK        UK
0.9440166 0.8428222

> fixed.effects(modelSex.1)
     SexF.1      SexF.2      SexF.3      SexF.4
 0.16349517 -0.63184370 -0.08578787 -0.61023260


The thing is that I?m not sure on how to interpret the frailty values by
countries (random effect described by the variance within groups)  because
I have four different effects (each related with my transition types). I
know that by using strata for my transition type is the same as I applied 4
different cox model (related for each type of transition). If I
apply separated model  I would obtain frailty random effect by groups
(countries) regarding specific transition but, doing this model with the
strata  ( modelSex.1 ) with my 4 transition type at once, I do not know
what those frailty values are telling me about the different type of hazard.

For other side, I have other question related to the recent article of
Mixed Effect (May, 2018) . Might be it is a very very silly question but I
need to understand .
In pag 9, second parraph , you describe the simple cox model : when you
describe the standard deviation (excess of risk for each group)  , you
state that "... 15% of the families to be 1 std dev or more above the
mean..."  Im working with that data and code but I couldnt find where you
got the value of 15%.


I hope this makes any sense to you,

Best wishes

 Sarah?


-- 
*Sarah? Rueda Salazar*
*Investigadora en Formaci?n (FPI/CED)*












*Centre d'Estudis Demogr?ficsCarrer de Ca n'Altay?, Edifici E2Universitat
Aut?noma de Barcelona,08193
Bellaterra, Barcelona/SPAINPhone: 34/93.581.30.60
<34%2F93.581.30.60>Fax: 34/93.581.30.61
<34%2F93.581.30.61>e-mail: srueda at ced.uab.es
<ssancho at ced.uab.es>http://www.ced.uab.es <http://www.ced.uab.es/>*


From bgunter@4567 @end|ng |rom gm@||@com  Fri Jun 22 17:53:37 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 22 Jun 2018 08:53:37 -0700
Subject: [R] Help with transpose please.
In-Reply-To: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <CAGxFJbQq8SZvgDbnmMSThpKaqfD5FYBipZK8YMbAbt7e5iQe2g@mail.gmail.com>

1. "The max number of columns based on this transpose of the DiagnosisCode
column (in this dataset) is 12 if that is important to know."

I count about 20 different DX codes in the data you show, so I don't know
what this means.

2. I was not able to unambiguously parse your request (I admit that I just
may be dense) , but maybe split() is what you want, at least to start with:

##untested in the absence of a reprex
## dat is your data frame

split(dat, dat$ClaimServiceID)


This will give you a list of data frames, one for eachClaimServiceID. You
can order each list however you like using, e.g. lapply() with order().

If I have missed your intent completely, just say so and hopefully someone
else can help. Or follow Ramesh's suggestion

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jun 22, 2018 at 4:43 AM, Bill Poling <Bill.Poling at zelis.com> wrote:

> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
>    ClaimServiceID  ClaimID DiagnosisCode
> 1       183056004 78044473          C562
> 2       183056004 78044473          C778
> 3       183056004 78044473          C784
> 4       183056004 78044473          C786
> 5       183056004 78044473         C7961
> 6       183056004 78044473         C7982
> 7       183056004 78044473         C7989
> 8       183056008 78044473          C562
> 9       183056008 78044473          C778
> 10      183056008 78044473          C784
> 11      183056008 78044473          C786
> 12      183056008 78044473         C7961
> 13      183056008 78044473         C7982
> 14      183056008 78044473         C7989
> 15      183139945 78078925        M79606
> 16      183139945 78078925         M7989
> 17      183139945 78078925          R600
> 18      183236728 78119632        H02831
> 19      183236728 78119632        H02832
> 20      183236728 78119632        H02834
> 21      183236728 78119632        H02835
> 22      183236728 78119632        H04123
> 23      183236728 78119632          Z411
> 24      183236728 78119632         H2513
> 25      183236728 78119632        H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID,
> and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique
> ClaimServiceID as the identifier when I join this data back into a longer
> single record length file by that column.
>
>     claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
> 1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete  dput of the 1272 records I will gladly
> provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer"   "integer"   "character" <---but do not have to be if
> that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode
> column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
>  # https://www.r-bloggers.com/pivot-tables-in-r/
>
> # https://stackoverflow.com/questions/18449938/pivot-on-
> data-table-similar-to-rehape-melt-function
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID,
> DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
>  # https://www.r-statistics.com/tag/transpose/
>
>  dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID,
> ClaimID))
> View(dta3)
>
>
> I am sure it's a basic,  simple procedure, but I am pressed for time on
> this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From B|||@Po||ng @end|ng |rom ze||@@com  Fri Jun 22 18:36:36 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 22 Jun 2018 16:36:36 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <CAGxFJbQq8SZvgDbnmMSThpKaqfD5FYBipZK8YMbAbt7e5iQe2g@mail.gmail.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <CAGxFJbQq8SZvgDbnmMSThpKaqfD5FYBipZK8YMbAbt7e5iQe2g@mail.gmail.com>
Message-ID: <CY1PR0201MB18348CE8430D063E2AD01A36EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>

Hi Bert and thank you for your assistance, I will try this.

I was not clear enough about the number of expected output columns based on the  DiagnosisCode column, my appologies.

Specifically, by virtue of the ClaimServiceID being the unique identifier, among them there is one with 12 DiagnosisCodes so the record length would be at the most 12 + the ClaimServiceID and the ClaimID

Example:
ClaimServiceID ClaimID DX1 DX2 DX3 DX4 DX5 DX6 DX7 DX8 DX9 DX10 DX11 DX12

And of course those ClaimServiceID?s with less than 12 DX?s would be NULL in place of a DiagnosisCode

I will work with what you suggest and report back thank you again Sir!

WHP


From: Bert Gunter [mailto:bgunter.4567 at gmail.com]
Sent: Friday, June 22, 2018 11:54 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

1. "The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know."

I count about 20 different DX codes in the data you show, so I don't know what this means.

2. I was not able to unambiguously parse your request (I admit that I just may be dense) , but maybe split() is what you want, at least to start with:

##untested in the absence of a reprex
## dat is your data frame

split(dat, dat$ClaimServiceID)


This will give you a list of data frames, one for eachClaimServiceID. You can order each list however you like using, e.g. lapply() with order().

If I have missed your intent completely, just say so and hopefully someone else can help. Or follow Ramesh's suggestion

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jun 22, 2018 at 4:43 AM, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
Good morning.


I have data in the form:

head(Edit041IA, n=25)
   ClaimServiceID  ClaimID DiagnosisCode
1       183056004 78044473          C562
2       183056004 78044473          C778
3       183056004 78044473          C784
4       183056004 78044473          C786
5       183056004 78044473         C7961
6       183056004 78044473         C7982
7       183056004 78044473         C7989
8       183056008 78044473          C562
9       183056008 78044473          C778
10      183056008 78044473          C784
11      183056008 78044473          C786
12      183056008 78044473         C7961
13      183056008 78044473         C7982
14      183056008 78044473         C7989
15      183139945 78078925        M79606
16      183139945 78078925         M7989
17      183139945 78078925          R600
18      183236728 78119632        H02831
19      183236728 78119632        H02832
20      183236728 78119632        H02834
21      183236728 78119632        H02835
22      183236728 78119632        H04123
23      183236728 78119632          Z411
24      183236728 78119632         H2513
25      183236728 78119632        H43813

And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:

There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.

    claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc


(If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",

"ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,

-1272L))



At the moment the classes are:

classes <- as.character(sapply(Edit041IA, class))

classes

# [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in

The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.

I have looked at a variety of webpages and cannot get this right,

dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
View(dta2)
 # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>

# https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>


dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
View(dta3)
dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
View(dta3)

dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
View(dta3)

dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
View(dta3)


dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
View(dta3)
 # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>

 dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
View(dta3)


I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.

WHP





Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}

______________________________________________
R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
and provide commented, minimal, self-contained, reproducible code.


Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From B|||@Po||ng @end|ng |rom ze||@@com  Fri Jun 22 18:39:00 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Fri, 22 Jun 2018 16:39:00 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <93AA619D-1A7A-4875-94C2-4F3716656303@icloud.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <93AA619D-1A7A-4875-94C2-4F3716656303@icloud.com>
Message-ID: <CY1PR0201MB18345A1D2336DF4A9546FD0EEA750@CY1PR0201MB1834.namprd02.prod.outlook.com>

Thank you Ramesh, I will investigate, appreciate your response Sir!

WHP


From: Ramesh YAPALPARVI [mailto:ramesh.yapalparvi at icloud.com]
Sent: Friday, June 22, 2018 7:47 AM
To: Bill Poling <Bill.Poling at zelis.com>
Cc: r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

Please check out tidyr package and use commands like spread/ gather which would make data wide or long



> On Jun 22, 2018, at 07:43, Bill Poling <Bill.Poling at zelis.com<mailto:Bill.Poling at zelis.com>> wrote:
>
> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
> ClaimServiceID ClaimID DiagnosisCode
> 1 183056004 78044473 C562
> 2 183056004 78044473 C778
> 3 183056004 78044473 C784
> 4 183056004 78044473 C786
> 5 183056004 78044473 C7961
> 6 183056004 78044473 C7982
> 7 183056004 78044473 C7989
> 8 183056008 78044473 C562
> 9 183056008 78044473 C778
> 10 183056008 78044473 C784
> 11 183056008 78044473 C786
> 12 183056008 78044473 C7961
> 13 183056008 78044473 C7982
> 14 183056008 78044473 C7989
> 15 183139945 78078925 M79606
> 16 183139945 78078925 M7989
> 17 183139945 78078925 R600
> 18 183236728 78119632 H02831
> 19 183236728 78119632 H02832
> 20 183236728 78119632 H02834
> 21 183236728 78119632 H02835
> 22 183236728 78119632 H04123
> 23 183236728 78119632 Z411
> 24 183236728 78119632 H2513
> 25 183236728 78119632 H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
>
> claimServiceID ClaimID Dx1 Dx2 Dx3 ...etc
> 1 183056004 78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008 78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer" "integer" "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>
>
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>
>
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
>
>
> I am sure it's a basic, simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.

Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}



From g||ted|||e2014 @end|ng |rom gm@||@com  Fri Jun 22 21:12:45 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Fri, 22 Jun 2018 20:12:45 +0100
Subject: [R] as.Date and Legend in a plot
Message-ID: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>

Dear Contributors,

I am surprised that I cannot add legend to a certain plot. Although the
x-axis indicates years, the actual data was in year, month and day format.
I then used as.Date to play around and get what I am looking for. I am,
however, worried that I cannot add legend to the plot no matter how I
tried. Looking at the axis, I tried:
legend(1998,3, c("Climax", "Thule", "Sopo"), lty = 1, col =
c("black","red","blue")). I also tried:

legend(as.Date(1998-02-10),3, c("Climax", "Thule", "Sopo"), lty = 1, col =
c("black","red","blue"))
but no result and no error.

I have attached the plot in case it will assist in your suggestions.

Many thanks for your time.

Ogbos


From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jun 22 22:33:38 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 22 Jun 2018 13:33:38 -0700
Subject: [R] as.Date and Legend in a plot
In-Reply-To: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
References: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
Message-ID: <B58340BA-654E-4095-9713-A5F08B6563A1@comcast.net>


> On Jun 22, 2018, at 12:12 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> 
> Dear Contributors,
> 
> I am surprised that I cannot add legend to a certain plot. Although the
> x-axis indicates years, the actual data was in year, month and day format.
> I then used as.Date to play around and get what I am looking for. I am,
> however, worried that I cannot add legend to the plot no matter how I
> tried. Looking at the axis, I tried:
> legend(1998,3, c("Climax", "Thule", "Sopo"), lty = 1, col =
> c("black","red","blue")). I also tried:
> 
> legend(as.Date(1998-02-10),

I don't think you understand the difference between character values and numeric values. Thr using 

as.Date("1998-02-10")


> 3, c("Climax", "Thule", "Sopo"), lty = 1, col =
> c("black","red","blue"))
> but no result and no error.
> 
> I have attached the plot in case it will assist in your suggestions.
> 
> Many thanks for your time.
> 
> Ogbos
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From m@cqueen1 @end|ng |rom ||n|@gov  Fri Jun 22 23:34:05 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Fri, 22 Jun 2018 21:34:05 +0000
Subject: [R] as.Date and Legend in a plot
In-Reply-To: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
References: <CAC8ss33cA9z9WV+bzidkndGZYMTGqf3S5fTQBk=BKubeJvbcEg@mail.gmail.com>
Message-ID: <9CC667B3-F92E-426A-9259-4BF329872ECB@llnl.gov>

What David Winsemius said, plus:

Does
  legend('topleft', c("Climax", "Thule", "Sopo"), lty = 1, col = ("black","red","blue"))
not work?

It should, which will illustrate that you CAN add a legend to the plot.

The x,y that you supply to legend must be values that are within the x,y range of the plot. Type
   par()$usr
to see what that range is, and I think you will see that 1998 is not within the plot range.

David showed you how to supply legend with an x value that is, we assume, within the plot range.

You *should* have had an error on your second try:

> as.Date(1998-02-10)
Error in as.Date.numeric(1998 - 2 - 10) : 'origin' must be supplied

-Don

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/22/18, 12:12 PM, "R-help on behalf of Ogbos Okike" <r-help-bounces at r-project.org on behalf of giftedlife2014 at gmail.com> wrote:

    Dear Contributors,
    
    I am surprised that I cannot add legend to a certain plot. Although the
    x-axis indicates years, the actual data was in year, month and day format.
    I then used as.Date to play around and get what I am looking for. I am,
    however, worried that I cannot add legend to the plot no matter how I
    tried. Looking at the axis, I tried:
    legend(1998,3, c("Climax", "Thule", "Sopo"), lty = 1, col =
    c("black","red","blue")). I also tried:
    
    legend(as.Date(1998-02-10),3, c("Climax", "Thule", "Sopo"), lty = 1, col =
    c("black","red","blue"))
    but no result and no error.
    
    I have attached the plot in case it will assist in your suggestions.
    
    Many thanks for your time.
    
    Ogbos
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From g||ted|||e2014 @end|ng |rom gm@||@com  Sat Jun 23 08:35:37 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Sat, 23 Jun 2018 07:35:37 +0100
Subject: [R] tapply and error bars
Message-ID: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>

Dear workers,
I have a data of length 1136. Below is the code I use to get the means B.
It worked fine and I had the mean calculated and plotted.

I wish to plot the error bars as well. I already plotted such means with
error bars before. Please see attached for example.

I tried to redo the same plot but unlikely could not get around it as I
lost my system containing the script.
Among many attempts, I tried:
library(gplots)

 plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68, main="Main
  effect Plot",barcol="black")
Nothing worked.

I would really be thankful should somebody return me to the track.
Many, many thanks for your time.
Ogbos

A sample of the data is:
S/N      A        B
1    -5  64833
2    -4  95864
3    -3  82322
4    -2  95591
5    -1  69378
6     0  74281
7     1 103261
8     2  92473
9     3  84344
10    4 127415
11    5 123826
12    6 100029
13    7  76205
14    8 105162
15    9 119533
16   10 106490
17   -5  82322
18   -4  95591
19   -3  69378
20   -2  74281
21   -1 103261
22    0  92473
23    1  84344
24    2 127415
25    3 123826
26    4 100029
27    5  76205
28    6 105162
29    7 119533
30    8 106490
31    9 114771
32   10  55593
33   -5  85694
34   -4  65205
35   -3  80995
36   -2  51723
37   -1  62310
38    0  53401
39    1  65677
40    2  76094
41    3  64035
42    4  68290
43    5  73306
44    6  82176
45    7  75566
46    8  89762
47    9  88063
48   10  94395
49   -5  80651
50   -4  81291
51   -3  63702
52   -2  70297
53   -1  64117
54    0  71219
55    1  57354
56    2  62111
57    3  42252
58    4  35454
59    5  33469
60    6  38899
61    7  64981
62    8  85694
63    9  79452
64   10  85216
65   -5  71219
66   -4  57354
67   -3  62111
68   -2  42252
69   -1  35454
70    0  33469
71    1  38899
72    2  64981
73    3  85694
74    4  79452
75    5  85216
76    6  81721
77    7  91231
78    8 107074
79    9 108103
80   10  7576

A<-matrix(rep(-5:10,71))
B<-matrix(data)
 AB<-data.frame(A,B)

x= B

 f<-factor(A)
AB<- tapply(x,f,mean)
x<--5:10
plot(x,AB,type="l")

-------------- next part --------------
A non-text attachment was scrubbed...
Name: true.png
Type: image/png
Size: 34158 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180623/67dd79a5/attachment-0002.png>

From drj|m|emon @end|ng |rom gm@||@com  Sat Jun 23 11:09:17 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sat, 23 Jun 2018 19:09:17 +1000
Subject: [R] tapply and error bars
In-Reply-To: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
Message-ID: <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>

Hi Ogbos,
This may help:

# assume your data frame is named "oodf"
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

Jim

On Sat, Jun 23, 2018 at 4:35 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Dear workers,
> I have a data of length 1136. Below is the code I use to get the means B.
> It worked fine and I had the mean calculated and plotted.
>
> I wish to plot the error bars as well. I already plotted such means with
> error bars before. Please see attached for example.
>
> I tried to redo the same plot but unlikely could not get around it as I
> lost my system containing the script.
> Among many attempts, I tried:
> library(gplots)
>
>  plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68, main="Main
>   effect Plot",barcol="black")
> Nothing worked.
>
> I would really be thankful should somebody return me to the track.
> Many, many thanks for your time.
> Ogbos
>
> A sample of the data is:
> S/N      A        B
> 1    -5  64833
> 2    -4  95864
> 3    -3  82322
> 4    -2  95591
> 5    -1  69378
> 6     0  74281
> 7     1 103261
> 8     2  92473
> 9     3  84344
> 10    4 127415
> 11    5 123826
> 12    6 100029
> 13    7  76205
> 14    8 105162
> 15    9 119533
> 16   10 106490
> 17   -5  82322
> 18   -4  95591
> 19   -3  69378
> 20   -2  74281
> 21   -1 103261
> 22    0  92473
> 23    1  84344
> 24    2 127415
> 25    3 123826
> 26    4 100029
> 27    5  76205
> 28    6 105162
> 29    7 119533
> 30    8 106490
> 31    9 114771
> 32   10  55593
> 33   -5  85694
> 34   -4  65205
> 35   -3  80995
> 36   -2  51723
> 37   -1  62310
> 38    0  53401
> 39    1  65677
> 40    2  76094
> 41    3  64035
> 42    4  68290
> 43    5  73306
> 44    6  82176
> 45    7  75566
> 46    8  89762
> 47    9  88063
> 48   10  94395
> 49   -5  80651
> 50   -4  81291
> 51   -3  63702
> 52   -2  70297
> 53   -1  64117
> 54    0  71219
> 55    1  57354
> 56    2  62111
> 57    3  42252
> 58    4  35454
> 59    5  33469
> 60    6  38899
> 61    7  64981
> 62    8  85694
> 63    9  79452
> 64   10  85216
> 65   -5  71219
> 66   -4  57354
> 67   -3  62111
> 68   -2  42252
> 69   -1  35454
> 70    0  33469
> 71    1  38899
> 72    2  64981
> 73    3  85694
> 74    4  79452
> 75    5  85216
> 76    6  81721
> 77    7  91231
> 78    8 107074
> 79    9 108103
> 80   10  7576
>
> A<-matrix(rep(-5:10,71))
> B<-matrix(data)
>  AB<-data.frame(A,B)
>
> x= B
>
>  f<-factor(A)
> AB<- tapply(x,f,mean)
> x<--5:10
> plot(x,AB,type="l")
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From djnord|und @end|ng |rom gm@||@com  Sat Jun 23 12:04:26 2018
From: djnord|und @end|ng |rom gm@||@com (Daniel Nordlund)
Date: Sat, 23 Jun 2018 03:04:26 -0700
Subject: [R] Help with transpose please.
In-Reply-To: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
Message-ID: <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>

On 6/22/2018 4:43 AM, Bill Poling wrote:
> Good morning.
> 
> 
> I have data in the form:
> 
> head(Edit041IA, n=25)
>     ClaimServiceID  ClaimID DiagnosisCode
> 1       183056004 78044473          C562
> 2       183056004 78044473          C778
> 3       183056004 78044473          C784
> 4       183056004 78044473          C786
> 5       183056004 78044473         C7961
> 6       183056004 78044473         C7982
> 7       183056004 78044473         C7989
> 8       183056008 78044473          C562
> 9       183056008 78044473          C778
> 10      183056008 78044473          C784
> 11      183056008 78044473          C786
> 12      183056008 78044473         C7961
> 13      183056008 78044473         C7982
> 14      183056008 78044473         C7989
> 15      183139945 78078925        M79606
> 16      183139945 78078925         M7989
> 17      183139945 78078925          R600
> 18      183236728 78119632        H02831
> 19      183236728 78119632        H02832
> 20      183236728 78119632        H02834
> 21      183236728 78119632        H02835
> 22      183236728 78119632        H04123
> 23      183236728 78119632          Z411
> 24      183236728 78119632         H2513
> 25      183236728 78119632        H43813
> 
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
> 
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
> 
>      claimServiceID ClaimID  Dx1   Dx2    Dx3  ...etc
> 1 183056004    78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008    78044473 C562 C778 C784 C786 C7961 ...etc
> 
> 
> (If you would prefer the complete  dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
> 
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
> 
> -1272L))
> 
> 
> 
> At the moment the classes are:
> 
> classes <- as.character(sapply(Edit041IA, class))
> 
> classes
> 
> # [1] "integer"   "integer"   "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
> 
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
> 
> I have looked at a variety of webpages and cannot get this right,
> 
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
>   # https://www.r-bloggers.com/pivot-tables-in-r/
> 
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function
> 
> 
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
> 
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
> 
> 
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
>   # https://www.r-statistics.com/tag/transpose/
> 
>   dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
> 
> 
> I am sure it's a basic,  simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
> 
> WHP
> 
> 
> 
> 
> 
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
> 

Bill,

you have received some good suggestions and since you are pressed for 
time this may be too late.  However, here is a solution using ave() 
function and  cast() from the reshape package.

# create diagnosis variable names
dxnames <- paste('Dx',ave(rep(1, nrow(have)), have[,1:2], FUN = 
seq_along), sep='')
# cast the data into wide format
cast(cbind(have,dxnames), ClaimServiceID + ClaimID ~ dxnames, 
value='DiagnosisCode')


Hope this is helpful,

Dan

-- 
Daniel Nordlund
Port Townsend, WA  USA



From j@b@y@t194 @end|ng |rom gm@||@com  Sat Jun 23 13:09:41 2018
From: j@b@y@t194 @end|ng |rom gm@||@com (javad bayat)
Date: Sat, 23 Jun 2018 15:39:41 +0430
Subject: [R] Deleting a specific value in a column of a data frame
Message-ID: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>

Dear R users;
I have two columns data frame (column names is A and B). I want to write a
function in order to compare column of B with A and if the values of B are
equal or greater than that of A, replace them with "NA" or delete them and
if the values of B are less than values in A, do nothing.

Sincerely.

-- 
Best Regards
Javad Bayat
M.Sc. Environment Engineering
Alternative Mail: bayat194 at yahoo.com

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun 23 16:26:44 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 23 Jun 2018 07:26:44 -0700
Subject: [R] Deleting a specific value in a column of a data frame
In-Reply-To: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>
References: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>
Message-ID: <CAGxFJbSMDYt2em5HFgXi8KL1D4Fp7R6RF05Re+d=hPcZE041CA@mail.gmail.com>

You understand, of course, that all columns in a data frame must be of the
same length; and that "NA" is not the same as NA?

This is pretty basic stuff and suggests you need to spend some time with an
R tutorial or two.

In any case, a construct of the form:

B[B >= A] <- NA

should do.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 23, 2018 at 4:09 AM, javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I have two columns data frame (column names is A and B). I want to write a
> function in order to compare column of B with A and if the values of B are
> equal or greater than that of A, replace them with "NA" or delete them and
> if the values of B are less than values in A, do nothing.
>
> Sincerely.
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From g||ted|||e2014 @end|ng |rom gm@||@com  Sat Jun 23 04:09:14 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Sat, 23 Jun 2018 03:09:14 +0100
Subject: [R] as.Date and Legend in a plot: Fixed
Message-ID: <CAC8ss33w1i_QJehakhHGCV_DBDSSiAmzY_WjF6RXiLUApsPA7w@mail.gmail.com>

Dear List,
I am happy to report that the problem is fixed. as.Date("1998-02-10") as
suggested by David handled the problem with easy. Many thanks to everybody.
as.Date(1998-02-10) really resulted in error. It is my oversight. I really
tried many things the day I was working on that and have forgotten some of
the errors.

Thanks again.



Ogbos


From dc@r|@on @end|ng |rom t@mu@edu  Sat Jun 23 19:25:00 2018
From: dc@r|@on @end|ng |rom t@mu@edu (David L Carlson)
Date: Sat, 23 Jun 2018 17:25:00 +0000
Subject: [R] Deleting a specific value in a column of a data frame
In-Reply-To: <CAGxFJbSMDYt2em5HFgXi8KL1D4Fp7R6RF05Re+d=hPcZE041CA@mail.gmail.com>
References: <CANTxAmK5iFv-YCd6oOv_9aPnL5sxgQT2M6y1ku=6zrSUg8OnEA@mail.gmail.com>
 <CAGxFJbSMDYt2em5HFgXi8KL1D4Fp7R6RF05Re+d=hPcZE041CA@mail.gmail.com>
Message-ID: <d4fab29a0744446e991187f63f6b24dc@tamu.edu>

Bert's solution works if A and B are vectors, but not if they are columns in a data frame. First, let's make up some data:

set.seed(42)
Dat <- data.frame(A=runif(10), B=runif(1))
Dat
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 3  0.2861395 0.9346722
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 6  0.5190959 0.9400145
# 7  0.7365883 0.9782264
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

It is safer to preserve the original data frame and store the modified data into a new one. To insert missing values:

Dat1 <- Dat
Dat1[Dat$B >= Dat$A, ] <- NA
Dat1
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 3         NA        NA
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 6         NA        NA
# 7         NA        NA
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Dat1 has the same number of rows as Dat with missing values for the rows that meet your logical expression. Here are three ways to remove those rows. We can delete the missing values:

Dat2 <- na.omit(Dat1)
Dat2
#           A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Or we can extract the rows we want by flipping the logical expression:

# Dat2 <- Dat
# Dat2 <- Dat[Dat$B < Dat$A, ]
# Dat2
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Or we can subset the original data frame with the subset() function:

Dat2 <- Dat
Dat2 <- subset(Dat, B < A)
Dat2
#            A         B
# 1  0.9148060 0.4577418
# 2  0.9370754 0.7191123
# 4  0.8304476 0.2554288
# 5  0.6417455 0.4622928
# 8  0.1346666 0.1174874
# 9  0.6569923 0.4749971
# 10 0.7050648 0.5603327

Notice that whichever one we use, the row numbers match the original data frame.


David L. Carlson
Department of Anthropology
Texas A&M University

-----Original Message-----
From: R-help [mailto:r-help-bounces at r-project.org] On Behalf Of Bert Gunter
Sent: Saturday, June 23, 2018 9:27 AM
To: javad bayat <j.bayat194 at gmail.com>
Cc: R-help <R-help at r-project.org>
Subject: Re: [R] Deleting a specific value in a column of a data frame

You understand, of course, that all columns in a data frame must be of the
same length; and that "NA" is not the same as NA?

This is pretty basic stuff and suggests you need to spend some time with an
R tutorial or two.

In any case, a construct of the form:

B[B >= A] <- NA

should do.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 23, 2018 at 4:09 AM, javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I have two columns data frame (column names is A and B). I want to write a
> function in order to compare column of B with A and if the values of B are
> equal or greater than that of A, replace them with "NA" or delete them and
> if the values of B are less than values in A, do nothing.
>
> Sincerely.
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Sat Jun 23 19:11:58 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (ruipbarradas)
Date: Sat, 23 Jun 2018 18:11:58 +0100
Subject: [R] Deleting a specific value in a column of a data frame
Message-ID: <1qletd906mwfuur4rmdyj5ht.1529773918921@email.android.com>

Hello,
Also possible is

is.na (B) <- B >= A

Hope this helps,
Rui Barradas?


Enviado a partir do meu smartphone Samsung Galaxy.-------- Mensagem original --------De: Bert Gunter <bgunter.4567 at gmail.com> Data: 23/06/2018  15:26  (GMT+00:00) Para: javad bayat <j.bayat194 at gmail.com> Cc: R-help <R-help at r-project.org> Assunto: Re: [R] Deleting a specific value in a column of a data frame 
You understand, of course, that all columns in a data frame must be of the
same length; and that "NA" is not the same as NA?

This is pretty basic stuff and suggests you need to spend some time with an
R tutorial or two.

In any case, a construct of the form:

B[B >= A] <- NA

should do.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 23, 2018 at 4:09 AM, javad bayat <j.bayat194 at gmail.com> wrote:

> Dear R users;
> I have two columns data frame (column names is A and B). I want to write a
> function in order to compare column of B with A and if the values of B are
> equal or greater than that of A, replace them with "NA" or delete them and
> if the values of B are less than values in A, do nothing.
>
> Sincerely.
>
> --
> Best Regards
> Javad Bayat
> M.Sc. Environment Engineering
> Alternative Mail: bayat194 at yahoo.com
>
>???????? [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]


From h@medh@@e|| @end|ng |rom gm@||@com  Sat Jun 23 22:23:10 2018
From: h@medh@@e|| @end|ng |rom gm@||@com (Hamed Ha)
Date: Sat, 23 Jun 2018 21:23:10 +0100
Subject: [R] Issue with R write() function
Message-ID: <CAAC89xeJeiJP12G6yK9DHhM7mZet9VxmFLuRRvrXvh2ROK5Bwg@mail.gmail.com>

I
am recently updated to R 3.5.0 and noticed some weird errors in write()
function. Further, I noticed that write.csv, write.table and generally the
functions that derive from write() are all weird.

   1. write() function does not accept a path longer than 256 characters
   neither on Windows or Unix. Noticed that a full path can be longer than 256
   characters, however, the directory name cannot, at least on windows.

   2. The append parameter does not work at all, just try
   ??
   ??
   write.table(x = 1,file =  '
   tmp
   ',append = TRUE)
   ? or write.csv(x = 1,file =  'tmp',append = TRUE)?

P
lease can someone report to the developement team?


Regards,
Hamed.

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun 23 23:58:33 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 23 Jun 2018 14:58:33 -0700
Subject: [R] Issue with R write() function
In-Reply-To: <CAAC89xeJeiJP12G6yK9DHhM7mZet9VxmFLuRRvrXvh2ROK5Bwg@mail.gmail.com>
References: <CAAC89xeJeiJP12G6yK9DHhM7mZet9VxmFLuRRvrXvh2ROK5Bwg@mail.gmail.com>
Message-ID: <6ACEFFE6-4741-4930-9D3E-60B2C011AB02@dcn.davis.ca.us>

1. This behavior is dictated by the file system (an operating system feature) that is in use. Chances of it changing in R are extremely small.

2. While not clearly documented, this behavior is consistent with the definition of what a "csv" file is. Headers located at other than line 1 are not valid, and the write.csv function cannot insure that multiple invocations will lead to a valid csv file. Since write.csv is just a convenience wrapper around write.table, you can probably accomplish what you are after by giving appropriate parameters to write.table. e.g.

write.table( x=1, file="tmp.csv", sep=",", row.names=FALSE )
write.table( x=2, file="tmp.csv", append=TRUE, sep=",", row.names=FALSE, col.names=FALSE )

It will be up to you to keep the format consistent.


On June 23, 2018 1:23:10 PM PDT, Hamed Ha <hamedhaseli at gmail.com> wrote:
>I
>am recently updated to R 3.5.0 and noticed some weird errors in write()
>function. Further, I noticed that write.csv, write.table and generally
>the
>functions that derive from write() are all weird.
>
>  1. write() function does not accept a path longer than 256 characters
>neither on Windows or Unix. Noticed that a full path can be longer than
>256
>   characters, however, the directory name cannot, at least on windows.
>
>   2. The append parameter does not work at all, just try
>   ??
>   ??
>   write.table(x = 1,file =  '
>   tmp
>   ',append = TRUE)
>   ? or write.csv(x = 1,file =  'tmp',append = TRUE)?
>
>P
>lease can someone report to the developement team?
>
>
>Regards,
>Hamed.
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From drj|m|emon @end|ng |rom gm@||@com  Sun Jun 24 12:24:43 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Sun, 24 Jun 2018 20:24:43 +1000
Subject: [R] tapply and error bars
In-Reply-To: <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
 <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>
 <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
Message-ID: <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>

Hi Ogbos,
If I use the example data that you sent, I get the error after this line:

oose<-as.vector(by(oodf$B,oodf$A,std.error))
Error in FUN(X[[i]], ...) : object 'std.error' not found

The reason is that you have not defined std.error as a function, but
as the result of a calculation. When I rewrite it like this:

std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

I get the expected plot.

Jim


On Sat, Jun 23, 2018 at 9:36 PM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Hi Jim,
>
> Thanks for assisting. Here is what I did:
>
> A<-matrix(rep(-5:10,71))
> B<-matrix(data)
> std.error = sd(B)/sqrt(sum(!is.na(B)))
>  oodf<-data.frame(A,B)
>
>  oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> And the error says:
> Error in FUN(X[[1L]], ...) : could not find function "FUN"
>
> Please note that I use:
> std.error = sd(B)/sqrt(sum(!is.na(B)))
>  to calculate the standard error as it requested for it.
>
> Thanks
> Ogbos
>
> On Sat, Jun 23, 2018 at 10:09 AM, Jim Lemon <drjimlemon at gmail.com> wrote:
>>
>> Hi Ogbos,
>> This may help:
>>
>> # assume your data frame is named "oodf"
>> oomean<-as.vector(by(oodf$B,oodf$A,mean))
>> oose<-as.vector(by(oodf$B,oodf$A,std.error))
>> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
>> dispersion(-5:10,oomean,oose)
>>
>> Jim
>>
>> On Sat, Jun 23, 2018 at 4:35 PM, Ogbos Okike <giftedlife2014 at gmail.com>
>> wrote:
>> > Dear workers,
>> > I have a data of length 1136. Below is the code I use to get the means
>> > B.
>> > It worked fine and I had the mean calculated and plotted.
>> >
>> > I wish to plot the error bars as well. I already plotted such means with
>> > error bars before. Please see attached for example.
>> >
>> > I tried to redo the same plot but unlikely could not get around it as I
>> > lost my system containing the script.
>> > Among many attempts, I tried:
>> > library(gplots)
>> >
>> >  plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68,
>> > main="Main
>> >   effect Plot",barcol="black")
>> > Nothing worked.
>> >
>> > I would really be thankful should somebody return me to the track.
>> > Many, many thanks for your time.
>> > Ogbos
>> >
>> > A sample of the data is:
>> > S/N      A        B
>> > 1    -5  64833
>> > 2    -4  95864
>> > 3    -3  82322
>> > 4    -2  95591
>> > 5    -1  69378
>> > 6     0  74281
>> > 7     1 103261
>> > 8     2  92473
>> > 9     3  84344
>> > 10    4 127415
>> > 11    5 123826
>> > 12    6 100029
>> > 13    7  76205
>> > 14    8 105162
>> > 15    9 119533
>> > 16   10 106490
>> > 17   -5  82322
>> > 18   -4  95591
>> > 19   -3  69378
>> > 20   -2  74281
>> > 21   -1 103261
>> > 22    0  92473
>> > 23    1  84344
>> > 24    2 127415
>> > 25    3 123826
>> > 26    4 100029
>> > 27    5  76205
>> > 28    6 105162
>> > 29    7 119533
>> > 30    8 106490
>> > 31    9 114771
>> > 32   10  55593
>> > 33   -5  85694
>> > 34   -4  65205
>> > 35   -3  80995
>> > 36   -2  51723
>> > 37   -1  62310
>> > 38    0  53401
>> > 39    1  65677
>> > 40    2  76094
>> > 41    3  64035
>> > 42    4  68290
>> > 43    5  73306
>> > 44    6  82176
>> > 45    7  75566
>> > 46    8  89762
>> > 47    9  88063
>> > 48   10  94395
>> > 49   -5  80651
>> > 50   -4  81291
>> > 51   -3  63702
>> > 52   -2  70297
>> > 53   -1  64117
>> > 54    0  71219
>> > 55    1  57354
>> > 56    2  62111
>> > 57    3  42252
>> > 58    4  35454
>> > 59    5  33469
>> > 60    6  38899
>> > 61    7  64981
>> > 62    8  85694
>> > 63    9  79452
>> > 64   10  85216
>> > 65   -5  71219
>> > 66   -4  57354
>> > 67   -3  62111
>> > 68   -2  42252
>> > 69   -1  35454
>> > 70    0  33469
>> > 71    1  38899
>> > 72    2  64981
>> > 73    3  85694
>> > 74    4  79452
>> > 75    5  85216
>> > 76    6  81721
>> > 77    7  91231
>> > 78    8 107074
>> > 79    9 108103
>> > 80   10  7576
>> >
>> > A<-matrix(rep(-5:10,71))
>> > B<-matrix(data)
>> >  AB<-data.frame(A,B)
>> >
>> > x= B
>> >
>> >  f<-factor(A)
>> > AB<- tapply(x,f,mean)
>> > x<--5:10
>> > plot(x,AB,type="l")
>> >
>> > ______________________________________________
>> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> > https://stat.ethz.ch/mailman/listinfo/r-help
>> > PLEASE do read the posting guide
>> > http://www.R-project.org/posting-guide.html
>> > and provide commented, minimal, self-contained, reproducible code.
>> >
>
>



From g||ted|||e2014 @end|ng |rom gm@||@com  Sun Jun 24 17:58:06 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Sun, 24 Jun 2018 16:58:06 +0100
Subject: [R] tapply and error bars
In-Reply-To: <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
 <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>
 <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
 <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>
Message-ID: <CAC8ss30FJ4GyDMsa5hVcq0uV8M4tYaRBabAij=Q6-o-mAJ2tYg@mail.gmail.com>

Hi Jim

Thanks again for returning to this.
please not that the line "oomean<-as.vector(by(oodf$B,oodf$A,mean))" was
omitted (not sure whether deliberate)  after you introduced the standard
error function.
When I used it, empty plot window with the correct axes were generated but
no data was displayed. No error too.

library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

When I included the line, the same empty graph window was generated but
with the former error "Error in FUN(X[[1L]], ...) : could not find function
"FUN""
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

I am sure am missing something but can't place it. Please have a look again
to track my mistake.

Warmest regards
Ogbos

On Sun, Jun 24, 2018 at 11:24 AM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ogbos,
> If I use the example data that you sent, I get the error after this line:
>
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> Error in FUN(X[[i]], ...) : object 'std.error' not found
>
> The reason is that you have not defined std.error as a function, but
> as the result of a calculation. When I rewrite it like this:
>
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> I get the expected plot.
>
> Jim
>
>
> On Sat, Jun 23, 2018 at 9:36 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> > Hi Jim,
> >
> > Thanks for assisting. Here is what I did:
> >
> > A<-matrix(rep(-5:10,71))
> > B<-matrix(data)
> > std.error = sd(B)/sqrt(sum(!is.na(B)))
> >  oodf<-data.frame(A,B)
> >
> >  oomean<-as.vector(by(oodf$B,oodf$A,mean))
> > oose<-as.vector(by(oodf$B,oodf$A,std.error))
> > plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> > dispersion(-5:10,oomean,oose)
> >
> > And the error says:
> > Error in FUN(X[[1L]], ...) : could not find function "FUN"
> >
> > Please note that I use:
> > std.error = sd(B)/sqrt(sum(!is.na(B)))
> >  to calculate the standard error as it requested for it.
> >
> > Thanks
> > Ogbos
> >
> > On Sat, Jun 23, 2018 at 10:09 AM, Jim Lemon <drjimlemon at gmail.com>
> wrote:
> >>
> >> Hi Ogbos,
> >> This may help:
> >>
> >> # assume your data frame is named "oodf"
> >> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> >> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> >> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> >> dispersion(-5:10,oomean,oose)
> >>
> >> Jim
> >>
> >> On Sat, Jun 23, 2018 at 4:35 PM, Ogbos Okike <giftedlife2014 at gmail.com>
> >> wrote:
> >> > Dear workers,
> >> > I have a data of length 1136. Below is the code I use to get the means
> >> > B.
> >> > It worked fine and I had the mean calculated and plotted.
> >> >
> >> > I wish to plot the error bars as well. I already plotted such means
> with
> >> > error bars before. Please see attached for example.
> >> >
> >> > I tried to redo the same plot but unlikely could not get around it as
> I
> >> > lost my system containing the script.
> >> > Among many attempts, I tried:
> >> > library(gplots)
> >> >
> >> >  plotmeans(errors~AB,xlab="Factor A",ylab="mean errors", p=.68,
> >> > main="Main
> >> >   effect Plot",barcol="black")
> >> > Nothing worked.
> >> >
> >> > I would really be thankful should somebody return me to the track.
> >> > Many, many thanks for your time.
> >> > Ogbos
> >> >
> >> > A sample of the data is:
> >> > S/N      A        B
> >> > 1    -5  64833
> >> > 2    -4  95864
> >> > 3    -3  82322
> >> > 4    -2  95591
> >> > 5    -1  69378
> >> > 6     0  74281
> >> > 7     1 103261
> >> > 8     2  92473
> >> > 9     3  84344
> >> > 10    4 127415
> >> > 11    5 123826
> >> > 12    6 100029
> >> > 13    7  76205
> >> > 14    8 105162
> >> > 15    9 119533
> >> > 16   10 106490
> >> > 17   -5  82322
> >> > 18   -4  95591
> >> > 19   -3  69378
> >> > 20   -2  74281
> >> > 21   -1 103261
> >> > 22    0  92473
> >> > 23    1  84344
> >> > 24    2 127415
> >> > 25    3 123826
> >> > 26    4 100029
> >> > 27    5  76205
> >> > 28    6 105162
> >> > 29    7 119533
> >> > 30    8 106490
> >> > 31    9 114771
> >> > 32   10  55593
> >> > 33   -5  85694
> >> > 34   -4  65205
> >> > 35   -3  80995
> >> > 36   -2  51723
> >> > 37   -1  62310
> >> > 38    0  53401
> >> > 39    1  65677
> >> > 40    2  76094
> >> > 41    3  64035
> >> > 42    4  68290
> >> > 43    5  73306
> >> > 44    6  82176
> >> > 45    7  75566
> >> > 46    8  89762
> >> > 47    9  88063
> >> > 48   10  94395
> >> > 49   -5  80651
> >> > 50   -4  81291
> >> > 51   -3  63702
> >> > 52   -2  70297
> >> > 53   -1  64117
> >> > 54    0  71219
> >> > 55    1  57354
> >> > 56    2  62111
> >> > 57    3  42252
> >> > 58    4  35454
> >> > 59    5  33469
> >> > 60    6  38899
> >> > 61    7  64981
> >> > 62    8  85694
> >> > 63    9  79452
> >> > 64   10  85216
> >> > 65   -5  71219
> >> > 66   -4  57354
> >> > 67   -3  62111
> >> > 68   -2  42252
> >> > 69   -1  35454
> >> > 70    0  33469
> >> > 71    1  38899
> >> > 72    2  64981
> >> > 73    3  85694
> >> > 74    4  79452
> >> > 75    5  85216
> >> > 76    6  81721
> >> > 77    7  91231
> >> > 78    8 107074
> >> > 79    9 108103
> >> > 80   10  7576
> >> >
> >> > A<-matrix(rep(-5:10,71))
> >> > B<-matrix(data)
> >> >  AB<-data.frame(A,B)
> >> >
> >> > x= B
> >> >
> >> >  f<-factor(A)
> >> > AB<- tapply(x,f,mean)
> >> > x<--5:10
> >> > plot(x,AB,type="l")
> >> >
> >> > ______________________________________________
> >> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >> > https://stat.ethz.ch/mailman/listinfo/r-help
> >> > PLEASE do read the posting guide
> >> > http://www.R-project.org/posting-guide.html
> >> > and provide commented, minimal, self-contained, reproducible code.
> >> >
> >
> >
>

	[[alternative HTML version deleted]]



From @e|||@ @end|ng |rom v@@@@r@edu  Sun Jun 24 20:00:51 2018
From: @e|||@ @end|ng |rom v@@@@r@edu (Simon Ellis)
Date: Sun, 24 Jun 2018 14:00:51 -0400
Subject: [R] Outputting variable names and their value bindings
Message-ID: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>

Hullo,

I'm writing a piece of scripting glue for a colleague who is doing
computations in several different languages. (It's the most convenient way,
right now.) My system calls the relevant program (e.g. Rstudio, MATLAB)
with a path to a script, captures stdout and parses it for output
variables, which it stores in its own environment for use later on.

This is easy with MATLAB, since it writes back the variable name with its
value, e.g.:

> freq = {somefunction}()
freq =

    <value>

All I have to do is look for lines with '=' on the end, then grab the next
section of non-empty lines as the binding for the variable. Boom.

With Rscript, if I write something like this:

Rscript -e "a = (2 + 2)" -e "a"

it prints

[1] 4

Is there any way to get R to print output similarly to MATLAB, in an x = y
format?

I have other solutions in mind, but they're all kludgy and I'd rather not
have to. Please can someone save me from the kludge? :-D

Thank you,

~Simon Ellis


-- 
Visiting Assistant Professor,
Department of Computer Science,
Vassar College,
Poughkeepsie, NY 12604

?The whole modern world has divided itself into Conservatives and
Progressives. The business of Progressives is to go on making mistakes. The
business of Conservatives is to prevent mistakes from being corrected.? *--
G. K. Chesterton*

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jun 24 22:03:53 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 24 Jun 2018 13:03:53 -0700
Subject: [R] parallel computing in r....
In-Reply-To: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <9479A978-896B-45F4-8DBF-C769B8BEFAF4@dcn.davis.ca.us>

You cannot send one task to 12 processors... the price of parallelism is that you must break down your task into smaller tasks. Once you have number of tasks equal to our more than the number of available cores then the higher level functions such as parLapply or mclapply can shuffle tasks onto cores. If you have 48 cores and 4 tasks, only 4 of the cores will be used. You probably should stay away from directly calling mcparallel as it is a low level function. Read the vignette about the base "parallel" package [1]. You might also like to use the forEach contributed package to simplify your work, and should look at the CRAN High Performance Computing Task View [2].

[1] vignette("parallel") or http://stat.ethz.ch/R-manual/R-devel/library/parallel/doc/parallel.pdf
[2] https://cran.r-project.org/web/views/HighPerformanceComputing.html

On June 22, 2018 3:12:28 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>      I am taking recourse to parallel computing to speed up my R code.
>
>The mcparallel function(in parallel package),presumably, sends a single
>task (an R function, to be precise) to a single core. Is this right? Is
>that one and only one core? What if there are other cores lying idle?
>
>As far as I am concerned, I am going to rent an AWS EC2 server with 48
>cores. I have four functions to be parallelized. Can I send the thread
>of one function to 12 cores, so that all 48 cores are utilized? If so,
>how do I do that with mcparallel function in the parallel package?
>
>Very many thanks for your time and effort...
>yours sincerely....
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sun Jun 24 22:14:07 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 24 Jun 2018 13:14:07 -0700
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
References: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
Message-ID: <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>

Yes and no. R does not have a "Matlab-output-compatibility" mode, but you can write your script to output anything you want it to using the "cat" function with various functions like "sprintf" and "as.character". You may want to write some functions that format some common objects that you typically output. Then just make sure to use those functions instead of the standard "put an object alone on a line" method of printing.

On June 24, 2018 11:00:51 AM PDT, Simon Ellis <sellis at vassar.edu> wrote:
>Hullo,
>
>I'm writing a piece of scripting glue for a colleague who is doing
>computations in several different languages. (It's the most convenient
>way,
>right now.) My system calls the relevant program (e.g. Rstudio, MATLAB)
>with a path to a script, captures stdout and parses it for output
>variables, which it stores in its own environment for use later on.
>
>This is easy with MATLAB, since it writes back the variable name with
>its
>value, e.g.:
>
>> freq = {somefunction}()
>freq =
>
>    <value>
>
>All I have to do is look for lines with '=' on the end, then grab the
>next
>section of non-empty lines as the binding for the variable. Boom.
>
>With Rscript, if I write something like this:
>
>Rscript -e "a = (2 + 2)" -e "a"
>
>it prints
>
>[1] 4
>
>Is there any way to get R to print output similarly to MATLAB, in an x
>= y
>format?
>
>I have other solutions in mind, but they're all kludgy and I'd rather
>not
>have to. Please can someone save me from the kludge? :-D
>
>Thank you,
>
>~Simon Ellis

-- 
Sent from my phone. Please excuse my brevity.



From drj|m|emon @end|ng |rom gm@||@com  Sun Jun 24 22:51:14 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 25 Jun 2018 06:51:14 +1000
Subject: [R] tapply and error bars
In-Reply-To: <CAC8ss30FJ4GyDMsa5hVcq0uV8M4tYaRBabAij=Q6-o-mAJ2tYg@mail.gmail.com>
References: <CAC8ss32Nm10vVGyS-e5uFNiaAfr=RPLYp1FTkmpiOJG=Tx_ugg@mail.gmail.com>
 <CA+8X3fWvoRQki20-BefZAGzbUx7Y3KYH5d9wymqweDhM+XrG+g@mail.gmail.com>
 <CAC8ss32iR+YpcArT_zFDg8+bhYipTdaGViSHgwmo7siTRd6aRQ@mail.gmail.com>
 <CA+8X3fUBmO+FgWF0_Qqfo_0JoAFdjNU5aRhzMosFnVu_=tHchQ@mail.gmail.com>
 <CAC8ss30FJ4GyDMsa5hVcq0uV8M4tYaRBabAij=Q6-o-mAJ2tYg@mail.gmail.com>
Message-ID: <CA+8X3fUSRmq0yPErQDYqQL6bR3MgWBVM=m6N=ymtNriY+2RMyA@mail.gmail.com>

Hi Ogbos,
The problem is almost certainly with the data. I get the plot I expect
with the sample data that you first posted, so I know that the code
works. If you try thIs what do you get?

oodf<-read.table(text="S/N      A        B
1    -5  64833
2    -4  95864
3    -3  82322
4    -2  95591
5    -1  69378
6     0  74281
7     1 103261
8     2  92473
9     3  84344
10    4 127415
11    5 123826
12    6 100029
13    7  76205
14    8 105162
15    9 119533
16   10 106490
17   -5  82322
18   -4  95591
19   -3  69378
20   -2  74281
21   -1 103261
22    0  92473
23    1  84344
24    2 127415
25    3 123826
26    4 100029
27    5  76205
28    6 105162
29    7 119533
30    8 106490
31    9 114771
32   10  55593
33   -5  85694
34   -4  65205
35   -3  80995
36   -2  51723
37   -1  62310
38    0  53401
39    1  65677
40    2  76094
41    3  64035
42    4  68290
43    5  73306
44    6  82176
45    7  75566
46    8  89762
47    9  88063
48   10  94395
49   -5  80651
50   -4  81291
51   -3  63702
52   -2  70297
53   -1  64117
54    0  71219
55    1  57354
56    2  62111
57    3  42252
58    4  35454
59    5  33469
60    6  38899
61    7  64981
62    8  85694
63    9  79452
64   10  85216
65   -5  71219
66   -4  57354
67   -3  62111
68   -2  42252
69   -1  35454
70    0  33469
71    1  38899
72    2  64981
73    3  85694
74    4  79452
75    5  85216
76    6  81721
77    7  91231
78    8 107074
79    9 108103
80   10  7576",
header=TRUE)
library(plotrix)
std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
oomean<-as.vector(by(oodf$B,oodf$A,mean))
oose<-as.vector(by(oodf$B,oodf$A,std.error))
plot(-5:10,oomean,type="b",ylim=c(50000,110000),
 xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
dispersion(-5:10,oomean,oose)

I get the attached plot;

Jim

On Mon, Jun 25, 2018 at 1:58 AM, Ogbos Okike <giftedlife2014 at gmail.com> wrote:
> Hi Jim
>
> Thanks again for returning to this.
> please not that the line "oomean<-as.vector(by(oodf$B,oodf$A,mean))" was
> omitted (not sure whether deliberate)  after you introduced the standard
> error function.
> When I used it, empty plot window with the correct axes were generated but
> no data was displayed. No error too.
>
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> When I included the line, the same empty graph window was generated but with
> the former error "Error in FUN(X[[1L]], ...) : could not find function
> "FUN""
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> I am sure am missing something but can't place it. Please have a look again
> to track my mistake.
>
> Warmest regards
> Ogbos
>

-------------- next part --------------
A non-text attachment was scrubbed...
Name: ooplot.pdf
Type: application/pdf
Size: 5776 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180625/fe014680/attachment-0002.pdf>

From r@turner @end|ng |rom @uck|@nd@@c@nz  Sun Jun 24 23:46:07 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 25 Jun 2018 09:46:07 +1200
Subject: [R] OT --- grammar.
Message-ID: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>


Does/should one say "the degrees of freedom is defined to be" or "the 
degrees of freedom are defined to be"?

Although value of "degrees of freedom" is a single number, the first 
formulation sounds very odd to my ear.

I would like to call upon the collective wisdom of the R community to 
help me decide.

Thanks, and my apologies for the off-topic post.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jun 25 00:06:16 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Sun, 24 Jun 2018 18:06:16 -0400
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <d75aa587-dd1d-f512-9e5d-e5f0cfbe3c3e@gmail.com>

On 24/06/2018 5:46 PM, Rolf Turner wrote:
> 
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?
> 
> Although value of "degrees of freedom" is a single number, the first
> formulation sounds very odd to my ear.
> 
> I would like to call upon the collective wisdom of the R community to
> help me decide.
> 
> Thanks, and my apologies for the off-topic post.

I'd agree with you:  "are".

Duncan Murdoch



From h@@@n@d|w@n @end|ng |rom gm@||@com  Mon Jun 25 00:08:47 2018
From: h@@@n@d|w@n @end|ng |rom gm@||@com (Hasan Diwan)
Date: Sun, 24 Jun 2018 15:08:47 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <CAP+bYWB5q_7+8ejpOOBrvSR-sRE0WmksuKvsvQkhps3Q1VbgVg@mail.gmail.com>

On Sun, 24 Jun 2018 at 14:46, Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?

"are", the noun in your statement is "degrees", while the fragment "of
freedom" acts as an adjective, narrowing the scope of the term
"degrees". Hope that helps... -- H
-- 
OpenPGP: https://sks-keyservers.net/pks/lookup?op=get&search=0xFEBAD7FFD041BBA1
If you wish to request my time, please do so using bit.ly/hd1AppointmentRequest.
Si vous voudrais faire connnaisance, allez a bit.ly/hd1AppointmentRequest.

Sent from my mobile device
Envoye de mon portable



From peter@|@ng|e|der @end|ng |rom gm@||@com  Mon Jun 25 00:17:01 2018
From: peter@|@ng|e|der @end|ng |rom gm@||@com (Peter Langfelder)
Date: Sun, 24 Jun 2018 15:17:01 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <CA+hbrhUQxVeiS48BmBUBMXYq9faTbhkDTF++waZexhxa9HWiXA@mail.gmail.com>

I would use "the number of degrees of freedom is defined... ".

Peter
On Sun, Jun 24, 2018 at 2:46 PM Rolf Turner <r.turner at auckland.ac.nz> wrote:
>
>
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?
>
> Although value of "degrees of freedom" is a single number, the first
> formulation sounds very odd to my ear.
>
> I would like to call upon the collective wisdom of the R community to
> help me decide.
>
> Thanks, and my apologies for the off-topic post.
>
> cheers,
>
> Rolf Turner
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From |oe@|jrg @end|ng |rom @ccucom@net  Mon Jun 25 00:40:45 2018
From: |oe@|jrg @end|ng |rom @ccucom@net (JRG)
Date: Sun, 24 Jun 2018 18:40:45 -0400
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <38251b00-9a89-ba39-72b3-59b6fffc657a@accucom.net>

(I suspect there will be much disagreement about "is" vs. "are".)

I'd say something like "the parameter degrees of freedom is defined to
be ..."

---JRG



On 06/24/2018 05:46 PM, Rolf Turner wrote:
> 
> Does/should one say "the degrees of freedom is defined to be" or "the
> degrees of freedom are defined to be"?
> 
> Although value of "degrees of freedom" is a single number, the first
> formulation sounds very odd to my ear.
> 
> I would like to call upon the collective wisdom of the R community to
> help me decide.
> 
> Thanks, and my apologies for the off-topic post.
> 
> cheers,
> 
> Rolf Turner
>



From ted@h@rd|ng @end|ng |rom w|@ndre@@net  Mon Jun 25 00:44:30 2018
From: ted@h@rd|ng @end|ng |rom w|@ndre@@net (Ted Harding)
Date: Sun, 24 Jun 2018 23:44:30 +0100
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <1529880270.3898.26.camel@deb2.fort.knox.uk>

On Mon, 2018-06-25 at 09:46 +1200, Rolf Turner wrote:
> Does/should one say "the degrees of freedom is defined to be" or "the 
> degrees of freedom are defined to be"?
> 
> Although value of "degrees of freedom" is a single number, the first 
> formulation sounds very odd to my ear.
> 
> I would like to call upon the collective wisdom of the R community to 
> help me decide.
> 
> Thanks, and my apologies for the off-topic post.
> 
> cheers,
> Rolf Turner

Interesting question, Rolf!
>From my point of view. I see "degrees of freedon" as a plural noun,
because of "degrees". But in some cases, we have only 1 degree of
freedon. Then the degrees of freedon is 1.

But we do not say, in that case, "the degree of freedom is defined
to be", or the degree of freedom are 1"

Nor would we say "The degrees of freedom are 19".!

So I thonk that the solution is to encapsulate the term within
aingle quotes, so that it becomes a singular entity. Thus:

The 'degrees of freedom' is defined to be ... "; and
The 'degrees of freedom' is 1.
Or
The degrees of freedom' is 19.

This is not the same issue as (one of my prime hates) saying
"the data is srored in the dataframe ... ". "Data" is a
plural noun (ainguler "datum"), and I would insist on
"the data are stored ... ". The French use "une donnee" and
"les donnees"; the Germans use "ein Datum", "der Daten";
so they know what they're doing! English-speakers mostly do not"

Best wishes to all,
Ted.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Mon Jun 25 01:38:30 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sun, 24 Jun 2018 16:38:30 -0700
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <CAPfrqaHKQKbGOZSfN83YoZw+WNLnM=XdmGk16fz-THeKcaKmYA@mail.gmail.com>
References: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
 <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>
 <CAPfrqaHKQKbGOZSfN83YoZw+WNLnM=XdmGk16fz-THeKcaKmYA@mail.gmail.com>
Message-ID: <444D6F5F-2C74-40CC-A6AD-22947B78210B@dcn.davis.ca.us>

Yes [1], though most people use it interactively, e.g.

?cat
?sprintf

[1] https://cran.r-project.org/manuals.html

On June 24, 2018 4:31:40 PM PDT, Simon Ellis <sellis at vassar.edu> wrote:
>Thank you for your reply.
>
>At the moment, my colleague and her students are just using
>zero-dimensional variables for output, no vectors or matrices, which
>does
>make my life easier.
>
>Since my code-glue parses through the scripts' code to substitute
>variables
>as required, I could code a command to cause my system to emit a line
>to
>get R to print something I could use.
>
>I am sure this is a dumb question, but is there a reference manual for
>R
>available online?
>
>On 24 June 2018 at 16:14, Jeff Newmiller <jdnewmil at dcn.davis.ca.us>
>wrote:
>
>> Yes and no. R does not have a "Matlab-output-compatibility" mode, but
>you
>> can write your script to output anything you want it to using the
>"cat"
>> function with various functions like "sprintf" and "as.character".
>You may
>> want to write some functions that format some common objects that you
>> typically output. Then just make sure to use those functions instead
>of the
>> standard "put an object alone on a line" method of printing.
>>
>> On June 24, 2018 11:00:51 AM PDT, Simon Ellis <sellis at vassar.edu>
>wrote:
>> >Hullo,
>> >
>> >I'm writing a piece of scripting glue for a colleague who is doing
>> >computations in several different languages. (It's the most
>convenient
>> >way,
>> >right now.) My system calls the relevant program (e.g. Rstudio,
>MATLAB)
>> >with a path to a script, captures stdout and parses it for output
>> >variables, which it stores in its own environment for use later on.
>> >
>> >This is easy with MATLAB, since it writes back the variable name
>with
>> >its
>> >value, e.g.:
>> >
>> >> freq = {somefunction}()
>> >freq =
>> >
>> >    <value>
>> >
>> >All I have to do is look for lines with '=' on the end, then grab
>the
>> >next
>> >section of non-empty lines as the binding for the variable. Boom.
>> >
>> >With Rscript, if I write something like this:
>> >
>> >Rscript -e "a = (2 + 2)" -e "a"
>> >
>> >it prints
>> >
>> >[1] 4
>> >
>> >Is there any way to get R to print output similarly to MATLAB, in an
>x
>> >= y
>> >format?
>> >
>> >I have other solutions in mind, but they're all kludgy and I'd
>rather
>> >not
>> >have to. Please can someone save me from the kludge? :-D
>> >
>> >Thank you,
>> >
>> >~Simon Ellis
>>
>> --
>> Sent from my phone. Please excuse my brevity.
>>

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun 25 02:03:57 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sun, 24 Jun 2018 17:03:57 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <1529880270.3898.26.camel@deb2.fort.knox.uk>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
Message-ID: <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>

Ted, et. al.:

Re: "Data is" vs "data are" ... Heh heh!

"This is the kind of arrant pedantry up with which I will not put."
(Attributed to Churchill in one form or another, likely wrongly.)

See here for some semi-authoritative dicussion:

http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sun, Jun 24, 2018 at 3:44 PM, Ted Harding <ted.harding at wlandres.net>
wrote:

> On Mon, 2018-06-25 at 09:46 +1200, Rolf Turner wrote:
> > Does/should one say "the degrees of freedom is defined to be" or "the
> > degrees of freedom are defined to be"?
> >
> > Although value of "degrees of freedom" is a single number, the first
> > formulation sounds very odd to my ear.
> >
> > I would like to call upon the collective wisdom of the R community to
> > help me decide.
> >
> > Thanks, and my apologies for the off-topic post.
> >
> > cheers,
> > Rolf Turner
>
> Interesting question, Rolf!
> >From my point of view. I see "degrees of freedon" as a plural noun,
> because of "degrees". But in some cases, we have only 1 degree of
> freedon. Then the degrees of freedon is 1.
>
> But we do not say, in that case, "the degree of freedom is defined
> to be", or the degree of freedom are 1"
>
> Nor would we say "The degrees of freedom are 19".!
>
> So I thonk that the solution is to encapsulate the term within
> aingle quotes, so that it becomes a singular entity. Thus:
>
> The 'degrees of freedom' is defined to be ... "; and
> The 'degrees of freedom' is 1.
> Or
> The degrees of freedom' is 19.
>
> This is not the same issue as (one of my prime hates) saying
> "the data is srored in the dataframe ... ". "Data" is a
> plural noun (ainguler "datum"), and I would insist on
> "the data are stored ... ". The French use "une donnee" and
> "les donnees"; the Germans use "ein Datum", "der Daten";
> so they know what they're doing! English-speakers mostly do not"
>
> Best wishes to all,
> Ted.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From |oe@|jrg @end|ng |rom @ccucom@net  Mon Jun 25 02:16:24 2018
From: |oe@|jrg @end|ng |rom @ccucom@net (JRG)
Date: Sun, 24 Jun 2018 20:16:24 -0400
Subject: [R] OT --- grammar.
In-Reply-To: <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
Message-ID: <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>


On 06/24/2018 08:03 PM, Bert Gunter wrote:
> Ted, et. al.:
> 
> Re: "Data is" vs "data are" ... Heh heh!
> 
> "This is the kind of arrant pedantry up with which I will not put."
> (Attributed to Churchill in one form or another, likely wrongly.)
> 
> See here for some semi-authoritative dicussion:
> 
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/


Hmmm.  "semi-authoritative or not", the 1980 Edition of the Oxford
American dictionary says:

"data (day-ta) n. pl. facts or information ...  'Data' should not be
used with a singular verb, as in 'the data is inconclusive'; it is by
origin a Latin plural (the singular is 'datum') and should be used with
a plural verb. ..."


Interesting how Latin seemed to have changed in the past 40 or so years.


---JRG

John R. Gleason



> 
> Cheers,
> Bert
> 
> 
> 
> Bert Gunter
> 
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
> 
> On Sun, Jun 24, 2018 at 3:44 PM, Ted Harding <ted.harding at wlandres.net>
> wrote:
> 
>> On Mon, 2018-06-25 at 09:46 +1200, Rolf Turner wrote:
>>> Does/should one say "the degrees of freedom is defined to be" or "the
>>> degrees of freedom are defined to be"?
>>>
>>> Although value of "degrees of freedom" is a single number, the first
>>> formulation sounds very odd to my ear.
>>>
>>> I would like to call upon the collective wisdom of the R community to
>>> help me decide.
>>>
>>> Thanks, and my apologies for the off-topic post.
>>>
>>> cheers,
>>> Rolf Turner
>>
>> Interesting question, Rolf!
>> >From my point of view. I see "degrees of freedon" as a plural noun,
>> because of "degrees". But in some cases, we have only 1 degree of
>> freedon. Then the degrees of freedon is 1.
>>
>> But we do not say, in that case, "the degree of freedom is defined
>> to be", or the degree of freedom are 1"
>>
>> Nor would we say "The degrees of freedom are 19".!
>>
>> So I thonk that the solution is to encapsulate the term within
>> aingle quotes, so that it becomes a singular entity. Thus:
>>
>> The 'degrees of freedom' is defined to be ... "; and
>> The 'degrees of freedom' is 1.
>> Or
>> The degrees of freedom' is 19.
>>
>> This is not the same issue as (one of my prime hates) saying
>> "the data is srored in the dataframe ... ". "Data" is a
>> plural noun (ainguler "datum"), and I would insist on
>> "the data are stored ... ". The French use "une donnee" and
>> "les donnees"; the Germans use "ein Datum", "der Daten";
>> so they know what they're doing! English-speakers mostly do not"
>>
>> Best wishes to all,
>> Ted.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/
>> posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>



From r@turner @end|ng |rom @uck|@nd@@c@nz  Mon Jun 25 02:16:26 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Mon, 25 Jun 2018 12:16:26 +1200
Subject: [R] OT --- grammar.
In-Reply-To: <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
Message-ID: <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>

On 25/06/18 12:03, Bert Gunter wrote:
> Ted, et. al.:
> 
> Re: "Data is" vs "data are" ... Heh heh!
> 
> "This is the kind of arrant pedantry up with which I will not put."
> (Attributed to Churchill in one form or another, likely wrongly.)
> 
> See here for some semi-authoritative dicussion:
> 
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/

I beg to differ.  "The data was out of date" sounds just plain stupid to 
my sensitive ears.

It's rather like using the phrase "begs the question" to mean "raises 
the question" or "invites the question" rather than to carry its 
*correct* meaning of "assumes what is to be proved".  The fact that the 
phrase is almost always used in its *incorrect* sense these days, and 
almost never in its *correct* sense, does not diminish the fact that 
those who use it incorrectly are ignorant scumbags!  The language is 
weakened and diminished by the encroachment of incorrect usage.

cheers,

Rolf


-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From drj|m|emon @end|ng |rom gm@||@com  Mon Jun 25 02:37:05 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Mon, 25 Jun 2018 10:37:05 +1000
Subject: [R] Outputting variable names and their value bindings
Message-ID: <CA+8X3fWmQkiRNd46RfA4-WSBT8F=86s+DoO-7fioM7zRHRBd9A@mail.gmail.com>

Hi Simon,
Easy to do if you call "print" directly:

print<-function(x) cat(deparse(substitute(x)),"=\n",x,"\n")
y<-3
print(y)
y =
 3

Obviously you will want to get rid of your print function when it is
not being used with "rm" or by starting a new session. Getting it to
bypass the default print method is more difficult and I don't have the
time to untangle that one at the moment.

Jim



From md@umner @end|ng |rom gm@||@com  Mon Jun 25 03:07:38 2018
From: md@umner @end|ng |rom gm@||@com (Michael Sumner)
Date: Mon, 25 Jun 2018 08:07:38 +0700
Subject: [R] OT --- grammar.
In-Reply-To: <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
Message-ID: <CAAcGz98=sxKDBPd35i1sALxU7954b+7TfOHt8JdSA+YAeNQT5w@mail.gmail.com>

No it isn't. Your stature is diminished by hateful behaviour.

Cheers, Mike

On Mon, 25 Jun 2018, 07:26 Rolf Turner, <r.turner at auckland.ac.nz> wrote:

> On 25/06/18 12:03, Bert Gunter wrote:
> > Ted, et. al.:
> >
> > Re: "Data is" vs "data are" ... Heh heh!
> >
> > "This is the kind of arrant pedantry up with which I will not put."
> > (Attributed to Churchill in one form or another, likely wrongly.)
> >
> > See here for some semi-authoritative dicussion:
> >
> >
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/
>
> I beg to differ.  "The data was out of date" sounds just plain stupid to
> my sensitive ears.
>
> It's rather like using the phrase "begs the question" to mean "raises
> the question" or "invites the question" rather than to carry its
> *correct* meaning of "assumes what is to be proved".  The fact that the
> phrase is almost always used in its *incorrect* sense these days, and
> almost never in its *correct* sense, does not diminish the fact that
> those who use it incorrectly are ignorant scumbags!  The language is
> weakened and diminished by the encroachment of incorrect usage.
>
>
>
> cheers,
>
> Rolf
>
>
> --
> Technical Editor ANZJS
> Department of Statistics
> University of Auckland
> Phone: +64-9-373-7599 ext. 88276
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
-- 
Dr. Michael Sumner
Software and Database Engineer
Australian Antarctic Division
203 Channel Highway
Kingston Tasmania 7050 Australia

	[[alternative HTML version deleted]]



From @e|||@ @end|ng |rom v@@@@r@edu  Mon Jun 25 01:31:40 2018
From: @e|||@ @end|ng |rom v@@@@r@edu (Simon Ellis)
Date: Sun, 24 Jun 2018 19:31:40 -0400
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>
References: <CAPfrqaEyi3hJOXMZTOOQKLvDT71Cnb-qHjN_si6RUQsUmZ=41Q@mail.gmail.com>
 <90CB96F9-7915-4F5B-B657-FA2F001617B2@dcn.davis.ca.us>
Message-ID: <CAPfrqaHKQKbGOZSfN83YoZw+WNLnM=XdmGk16fz-THeKcaKmYA@mail.gmail.com>

Thank you for your reply.

At the moment, my colleague and her students are just using
zero-dimensional variables for output, no vectors or matrices, which does
make my life easier.

Since my code-glue parses through the scripts' code to substitute variables
as required, I could code a command to cause my system to emit a line to
get R to print something I could use.

I am sure this is a dumb question, but is there a reference manual for R
available online?

On 24 June 2018 at 16:14, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:

> Yes and no. R does not have a "Matlab-output-compatibility" mode, but you
> can write your script to output anything you want it to using the "cat"
> function with various functions like "sprintf" and "as.character". You may
> want to write some functions that format some common objects that you
> typically output. Then just make sure to use those functions instead of the
> standard "put an object alone on a line" method of printing.
>
> On June 24, 2018 11:00:51 AM PDT, Simon Ellis <sellis at vassar.edu> wrote:
> >Hullo,
> >
> >I'm writing a piece of scripting glue for a colleague who is doing
> >computations in several different languages. (It's the most convenient
> >way,
> >right now.) My system calls the relevant program (e.g. Rstudio, MATLAB)
> >with a path to a script, captures stdout and parses it for output
> >variables, which it stores in its own environment for use later on.
> >
> >This is easy with MATLAB, since it writes back the variable name with
> >its
> >value, e.g.:
> >
> >> freq = {somefunction}()
> >freq =
> >
> >    <value>
> >
> >All I have to do is look for lines with '=' on the end, then grab the
> >next
> >section of non-empty lines as the binding for the variable. Boom.
> >
> >With Rscript, if I write something like this:
> >
> >Rscript -e "a = (2 + 2)" -e "a"
> >
> >it prints
> >
> >[1] 4
> >
> >Is there any way to get R to print output similarly to MATLAB, in an x
> >= y
> >format?
> >
> >I have other solutions in mind, but they're all kludgy and I'd rather
> >not
> >have to. Please can someone save me from the kludge? :-D
> >
> >Thank you,
> >
> >~Simon Ellis
>
> --
> Sent from my phone. Please excuse my brevity.
>



-- 
Visiting Assistant Professor,
Department of Computer Science,
Vassar College,
Poughkeepsie, NY 12604

?The whole modern world has divided itself into Conservatives and
Progressives. The business of Progressives is to go on making mistakes. The
business of Conservatives is to prevent mistakes from being corrected.? *--
G. K. Chesterton*

	[[alternative HTML version deleted]]



From @e|||@ @end|ng |rom v@@@@r@edu  Mon Jun 25 02:59:54 2018
From: @e|||@ @end|ng |rom v@@@@r@edu (Simon Ellis)
Date: Sun, 24 Jun 2018 20:59:54 -0400
Subject: [R] Outputting variable names and their value bindings
In-Reply-To: <CA+8X3fWmQkiRNd46RfA4-WSBT8F=86s+DoO-7fioM7zRHRBd9A@mail.gmail.com>
References: <CA+8X3fWmQkiRNd46RfA4-WSBT8F=86s+DoO-7fioM7zRHRBd9A@mail.gmail.com>
Message-ID: <CAPfrqaE0enu_81HOFUhr0BQYmveEuZpmMxyEKObUkbWgiXW9Uw@mail.gmail.com>

Hullo Jim,

That's wonderful: thank you so much! That makes things even easier. There
are also no problems regarding getting rid of the function as each set of
computations occurs in a new Rstudio process: it's not optimal, but given
the problem it was the best solution. My code will just stick this print
function at the very top of each R script, and then I can get my
collaborator to call it where there are variables to be read out.

This is great. Thank you again! :-)

On 24 June 2018 at 20:37, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Simon,
> Easy to do if you call "print" directly:
>
> print<-function(x) cat(deparse(substitute(x)),"=\n",x,"\n")
> y<-3
> print(y)
> y =
>  3
>
> Obviously you will want to get rid of your print function when it is
> not being used with "rm" or by starting a new session. Getting it to
> bypass the default print method is more difficult and I don't have the
> time to untangle that one at the moment.
>
> Jim
>



-- 
Visiting Assistant Professor,
Department of Computer Science,
Vassar College,
Poughkeepsie, NY 12604

?The whole modern world has divided itself into Conservatives and
Progressives. The business of Progressives is to go on making mistakes. The
business of Conservatives is to prevent mistakes from being corrected.? *--
G. K. Chesterton*

	[[alternative HTML version deleted]]



From p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz  Mon Jun 25 05:43:22 2018
From: p@u| @end|ng |rom @t@t@@uck|@nd@@c@nz (Paul Murrell)
Date: Mon, 25 Jun 2018 15:43:22 +1200
Subject: [R] HLS and HSV in package colorspace [not whitepoint related]
In-Reply-To: <CAEvk5z+_GBBpKqnptA7EJ+QdqiHFSit8+YbpkvaOV6Xm+G+e=A@mail.gmail.com>
References: <CAEvk5z+_GBBpKqnptA7EJ+QdqiHFSit8+YbpkvaOV6Xm+G+e=A@mail.gmail.com>
Message-ID: <443c7fa6-609d-b79f-404b-1dd829dcf760@stat.auckland.ac.nz>


Thanks Glenn.
I also favour restricting to sRGB<->HSV/HLS top remove ambiguity (so 
there is no direct conversion RGB<->HSV/HLS).
This would also be consistent with grDevices::rgb2hsv().

Paul

On 23/06/18 13:43, Glenn Davis wrote:
> Achim and Paul,
> 
> This is an entirely different subject - unrelated to whitepoint.
> 
> In the diagram I sketched, I made direct links between HSV and sRGB, and 
> HLS and sRGB.
> This is because the man page for HLS says:
> 
> This function creates colors in the HLS color space which corresponds to 
> the standard sRGB color space (IEC standard 61966).
> 
> and similarly for HSV.? But the C code in as_HSV()? actually does this:
> 
> case RGB:
> case sRGB:
>  ??? for(i = 0; i < n; i++) {
>  ??????? RGB_to_HSV(REAL(color)[i], REAL(color)[i+n], REAL(color)[i+2*n],
>  ??? ??? ???? &REAL(ans)[i], &REAL(ans)[i+n], &REAL(ans)[i+2*n]);
>  ??? }
>  ??? break;
> 
> And so both linear RGB and non-linear sRGB are converted to HSV in 
> exactly the same way.
> And it's the same for HLS (though not as obvious).
> My diagram does not match the C code since the code also has /direct 
> /links between RGB and HLS/HSV.
> This means that if one transforms from RGB to sRGB and then to HLS,
> it is not the same as? transforming from RGB to HLS in one step.
> A beginner probably would be surprised by this behavior.
> See an actual example below.
> 
> I can see the dilemma here.? The Wikipedia page
> https://en.wikipedia.org/wiki/HSL_and_HSV
> says
> Also, in general, HSL and HSV are today computed directly from 
> gamma-corrected <https://en.wikipedia.org/wiki/Gamma_correction> /R/?, 
> /G/?, and /B/??for instance in sRGB <https://en.wikipedia.org/wiki/SRGB> 
> space?but, when the models were developed, might have been 
> transformations of a linear RGB space.
> So some authors use linear RGB and some use non-linear RGB.
> In the *colorspace *package there are really 2 HLS spaces - a 
> linear-based HLS
> and a non-linear based HLS.? It is up to the user to keep things straight.
> As protection against confusion, I see that many *colorspace * 
> conversions to and from
> HLS/HSV generate the error message
> error("Ambiguous conversion");
> There is no mention of possible ambiguity in the man pages.
> 
> So what I am really bringing to your attention is a mismatch between the 
> man pages
> and the code.?? I see 2 ways to fix this mismatch:
> 
>  1. pick one HLS/HSV space (linear or non-linear) and stick to it and
>     document it.? I would recommend non-linear sRGB based on the
>     Wikipedia article.? Change the C code so it matches my sketch. 
>     There will no longer be any ambiguous transformations.
>  2. change the man pages and explain that HLS and HSV are currently
>     ambiguous, and so some conversions are also ambiguous.
> 
> I do not care, since I do not use these 2 spaces and probably never will.
> Option 1 might break someone else's package,
> so I would run this mismatch by your community of HLS/HSV users and see 
> what they think.
> 
> Glenn Davis
> 
> 
> An example of a non-commutative triangle:
> 
>> as( as( RGB(0.1,0.5,0.9), 'sRGB' ), 'HLS' )
>  ??????????? H???????? L???????? S
> [1,] 201.7339 0.6519387 0.8698137
> 
>> as( RGB(0.1,0.5,0.9), 'HLS' )
>  ?????? H?? L?? S
> [1,] 210 0.5 0.8
>> 
> 
> Note that 201.7339 0.6519387 0.8698137 != 210 0.5 0.8
> 

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/



From g||ted|||e2014 @end|ng |rom gm@||@com  Mon Jun 25 06:46:44 2018
From: g||ted|||e2014 @end|ng |rom gm@||@com (Ogbos Okike)
Date: Mon, 25 Jun 2018 05:46:44 +0100
Subject: [R] tapply and error bars: Problem Fixed
Message-ID: <CAC8ss31w5VrQ9riU9mbrEaJnDaJPhW7nSrKiZ75yAJXpBx2-Ag@mail.gmail.com>

HI Jim,

This is great!! It is also tricky!!! The problem lies in the choice of
ylim. And looking at the data and choosing ylim based on the maximum and
minimum values of y is a waste of time. And choosing it by other means was
yet much more difficult.

I had to start plotting part of the data with incremental step of 80 data
points and manually varying ylim till I got to the last data point 1136,
where I finally used ylim=c(150000,162000) which has nothing to do with the
raw data.

Many, many thanks.
Best wishes
Ogbos

On Sun, Jun 24, 2018 at 9:51 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Ogbos,
> The problem is almost certainly with the data. I get the plot I expect
> with the sample data that you first posted, so I know that the code
> works. If you try thIs what do you get?
>
> oodf<-read.table(text="S/N      A        B
> 1    -5  64833
> 2    -4  95864
> 3    -3  82322
> 4    -2  95591
> 5    -1  69378
> 6     0  74281
> 7     1 103261
> 8     2  92473
> 9     3  84344
> 10    4 127415
> 11    5 123826
> 12    6 100029
> 13    7  76205
> 14    8 105162
> 15    9 119533
> 16   10 106490
> 17   -5  82322
> 18   -4  95591
> 19   -3  69378
> 20   -2  74281
> 21   -1 103261
> 22    0  92473
> 23    1  84344
> 24    2 127415
> 25    3 123826
> 26    4 100029
> 27    5  76205
> 28    6 105162
> 29    7 119533
> 30    8 106490
> 31    9 114771
> 32   10  55593
> 33   -5  85694
> 34   -4  65205
> 35   -3  80995
> 36   -2  51723
> 37   -1  62310
> 38    0  53401
> 39    1  65677
> 40    2  76094
> 41    3  64035
> 42    4  68290
> 43    5  73306
> 44    6  82176
> 45    7  75566
> 46    8  89762
> 47    9  88063
> 48   10  94395
> 49   -5  80651
> 50   -4  81291
> 51   -3  63702
> 52   -2  70297
> 53   -1  64117
> 54    0  71219
> 55    1  57354
> 56    2  62111
> 57    3  42252
> 58    4  35454
> 59    5  33469
> 60    6  38899
> 61    7  64981
> 62    8  85694
> 63    9  79452
> 64   10  85216
> 65   -5  71219
> 66   -4  57354
> 67   -3  62111
> 68   -2  42252
> 69   -1  35454
> 70    0  33469
> 71    1  38899
> 72    2  64981
> 73    3  85694
> 74    4  79452
> 75    5  85216
> 76    6  81721
> 77    7  91231
> 78    8 107074
> 79    9 108103
> 80   10  7576",
> header=TRUE)
> library(plotrix)
> std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> oomean<-as.vector(by(oodf$B,oodf$A,mean))
> oose<-as.vector(by(oodf$B,oodf$A,std.error))
> plot(-5:10,oomean,type="b",ylim=c(50000,110000),
>  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> dispersion(-5:10,oomean,oose)
>
> I get the attached plot;
>
> Jim
>
> On Mon, Jun 25, 2018 at 1:58 AM, Ogbos Okike <giftedlife2014 at gmail.com>
> wrote:
> > Hi Jim
> >
> > Thanks again for returning to this.
> > please not that the line "oomean<-as.vector(by(oodf$B,oodf$A,mean))" was
> > omitted (not sure whether deliberate)  after you introduced the standard
> > error function.
> > When I used it, empty plot window with the correct axes were generated
> but
> > no data was displayed. No error too.
> >
> > library(plotrix)
> > std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> > oose<-as.vector(by(oodf$B,oodf$A,std.error))
> > plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> > dispersion(-5:10,oomean,oose)
> >
> > When I included the line, the same empty graph window was generated but
> with
> > the former error "Error in FUN(X[[1L]], ...) : could not find function
> > "FUN""
> > library(plotrix)
> > std.error<-function(x) return(sd(x)/(sum(!is.na(x))))
> > oomean<-as.vector(by(oodf$B,oodf$A,mean))
> > oose<-as.vector(by(oodf$B,oodf$A,std.error))
> > plot(-5:10,oomean,type="b",ylim=c(50000,110000),
> >  xlab="days (epoch is the day of Fd)",ylab="strikes/km2/day")
> > dispersion(-5:10,oomean,oose)
> >
> > I am sure am missing something but can't place it. Please have a look
> again
> > to track my mistake.
> >
> > Warmest regards
> > Ogbos
> >
>

	[[alternative HTML version deleted]]



From m|@thour| @end|ng |rom y@hoo@gr  Mon Jun 25 09:50:53 2018
From: m|@thour| @end|ng |rom y@hoo@gr (Maria Lathouri)
Date: Mon, 25 Jun 2018 07:50:53 +0000 (UTC)
Subject: [R] geom_text only in the first panel with facet_wrap in ggplot2
References: <1858534513.2037097.1529913053406.ref@mail.yahoo.com>
Message-ID: <1858534513.2037097.1529913053406@mail.yahoo.com>

Dear all, 


I am trying to add text only in the first panel of a faceted ggplot; I have been struggling to find a solution on this online but unfortunately none of what I found is working. 

Here it is a reproducible example. I hope it helps: 
library(gamm4) 
library(ggplot2) 

example<-read.csv("example.csv") 

head(example) 
#  Q  index ASB Year       WB_ID  S_ID score_1 score_2 works 
#1 100  1.02  1 2011 CL102021072830 157166     0   2.83    0 
#2 100  1.03  1 2014 CL102021072830 157166     0   2.83    0 
#3  80  1.02  1 2013 CL102021072860  1636     0  10.39    0 
#4  80  1.06  2 2006 CL102021072860  1636     0  10.39    0 
#5  80  1.06  2 2003 CL102021072860  1636     0  10.39    0 
#6  98  1.07  3 2002 CL102021072900  1635     0   7.57    0 

str(example) 
#'data.frame':    249 obs. of  9 variables: 
#  $ Q    : int  100 100 80 80 80 98 105 105 105 105 ... 
#$ index  : num  1.02 1.03 1.02 1.06 1.06 1.07 1.14 1.05 1.1 1.08 ... 
#$ ASB   : int  1 1 1 2 2 3 1 1 3 3 ... 
#$ Year  : int  2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ... 
#$ WB_ID  : Factor w/ 44 levels "CL102021072830",..: 1 1 2 2 2 3 3 3 4 4 ... 
#$ S_ID  : int  157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 ... 
#$ score_1: int  0 0 0 0 0 0 0 0 0 0 ... 
#$ score_2: num  2.83 2.83 10.39 10.39 10.39 ... 
#$ works  : num  0 0 0 0 0 0 0 0 0 0 ... 

# I need first to run a mixed-effect model
model<-gamm4(index~s(Q, by=factor(ASB))+Year+score_1+score_2+works, data=example, random=~(1|WB_ID/S_ID)) 


#I had to create a new dataset so I can use this with the ggplot2
newDat <- expand.grid(ASB = factor(example$ASB), 
Q = seq(from = min(example$Q, na.rm = TRUE), 
to = max(example$Q, na.rm = TRUE), 
length = 100), 
Year = 2002, 
score_1 = mean(example$score_1), 
score_2 = mean(example$score_2), 
works = mean(example$works), 
WB_ID = "CL102021072830", 
S_ID = "157166") 

datM <- predict(model$gam, type = "response", 
se.fit = TRUE, newdata = newDat) 

newDat$fit <- datM$fit 
newDat$upr <- datM$fit + (1.96 * datM$se.fit) 
newDat$lwr <- datM$fit - (1.96 * datM$se.fit) 



#I create a new variable for ASB so I can change the panel text
newDat$asb_1<-factor(newDat$ASB, levels=c(1, 2, 3), labels=c("ASB1", "ASB2", "ASB3")) 


#I plot this with ggplot2
p<-ggplot(newDat, aes(x = Q, y = fit, group = ASB)) + 
theme_bw() + 
geom_rug(data = example, aes(x = Q, y = 0.96), sides = "b") + 
ylim(0.96, 1.04) + 
geom_ribbon(aes(ymin = lwr, ymax = upr), col = NA, fill = "grey", 
alpha = 0.3) + 
geom_line(size = 1) + 
facet_wrap(~ asb_1, labeller = label_parsed) 


#When I try to add the text through geom_text, I get the text to all the three panels 
dat_text <- data.frame(label = c("Text", " ", " "), ASB  = c(1, 2, 3)) 

p + geom_text(x=20, y=1.03, data = dat_text, label = label) 

# or
p+geom_text(x=20, y=1.03 , aes(label=label), data=dat_text)


# I tried another way
ann_text <- data.frame(Q = 20, fit = 1.03, lab = "Text", ASB = factor(1,levels = c("1","2","3"))) 

p + geom_text(data = ann_text, label = "Text") 


# When I tried to use asb_1 instead of ASB, I got an errorann_text <- data.frame(Q = 20, fit = 1.03, lab = "Text", asb = factor("ASB1",levels = c("1","2","3"))) 


#Error in FUN(X[[i]], ...) : object 'ASB' not found

I would very much appreciate for your help. 

Thank you very much in advance. 

Kind regards,
Maria



From r@e@crump @end|ng |rom w@rw|ck@@c@uk  Mon Jun 25 13:49:18 2018
From: r@e@crump @end|ng |rom w@rw|ck@@c@uk (Ron Crump)
Date: Mon, 25 Jun 2018 12:49:18 +0100
Subject: [R] 
 geom_text only in the first panel with facet_wrap in ggplot2
Message-ID: <d4b94098-ec45-7e31-47ea-8027522e4916@warwick.ac.uk>

Dear Maria,

> I am trying to add text only in the first panel of a faceted ggplot
The following might help you to achieve what you
want. I created a small dummy dataset, but I tried to use
your column names in the hope this would help:

library(ggplot2)
# data.frame
DF <- data.frame(Q = rep(1:5, times=2),
                  fit = rep(1:5, times=2),
                  asb_1 = rep(letters[1:2], each=5))
# a DF holding the text and where to put it
tDF<-data.frame(Q = 2, fit = 3, str = 'example', asb_1 = "a")
# basic plot
p <- ggplot(DF, aes(x = Q, y = fit)) +
        geom_point() +
        facet_wrap(~ asb_1)
# and adding the text
p <- p + geom_text(data = tDF, mapping = aes(label = str) )

Hope this is useful,
Ron.



From john@@rch|e@mckown @end|ng |rom gm@||@com  Mon Jun 25 14:34:49 2018
From: john@@rch|e@mckown @end|ng |rom gm@||@com (John McKown)
Date: Mon, 25 Jun 2018 07:34:49 -0500
Subject: [R] OT --- grammar.
In-Reply-To: <CAAcGz98=sxKDBPd35i1sALxU7954b+7TfOHt8JdSA+YAeNQT5w@mail.gmail.com>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
 <CAAcGz98=sxKDBPd35i1sALxU7954b+7TfOHt8JdSA+YAeNQT5w@mail.gmail.com>
Message-ID: <CAAJSdjj65qA2XG+voF_f42JbBo0851mQ=ZTG8Uqu27vpvTfwEw@mail.gmail.com>

On Sun, Jun 24, 2018 at 8:08 PM Michael Sumner <mdsumner at gmail.com> wrote:

> No it isn't. Your stature is diminished by hateful behaviour.
>

?I will most likely also be labelled "hateful" for saying this, but I found
Rolf's post to be accurate, although phrased in a bit of an elitist way.?
Being a bit of a grammar Nazi (I may as well label myself as others likely
will), I sometimes come across as elitist as well. I am come across this
way because in any scientific endeavour, under which I include programming,
precision and accuracy is the top priority. Because if people think that
_I_ am a grammar Nazi, they haven't run into very many compilers
(especially for the archaic language COBOL) who will simply refuse to
compile something which doesn't make sense according to _its_ rules.

However, unlike Rolf, I do not take offense when people use idiomatic
expressions or even make up phrases on an English speaking mailing list
(English not being any kind of pristine, planned, language). So long as I
can puzzle it out, it is good to me. If I can't puzzle it out, I ignore it.
?
?My apologies to Dr. Sumner for originally sending this to him directly.
That was my error in not double checking that "reply" went to the proper
recipient. ?



>
> Cheers, Mike
>
> On Mon, 25 Jun 2018, 07:26 Rolf Turner, <r.turner at auckland.ac.nz> wrote:
>
> > On 25/06/18 12:03, Bert Gunter wrote:
> > > Ted, et. al.:
> > >
> > > Re: "Data is" vs "data are" ... Heh heh!
> > >
> > > "This is the kind of arrant pedantry up with which I will not put."
> > > (Attributed to Churchill in one form or another, likely wrongly.)
> > >
> > > See here for some semi-authoritative dicussion:
> > >
> > >
> >
> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/
> >
> > I beg to differ.  "The data was out of date" sounds just plain stupid to
> > my sensitive ears.
> >
> > It's rather like using the phrase "begs the question" to mean "raises
> > the question" or "invites the question" rather than to carry its
> > *correct* meaning of "assumes what is to be proved".  The fact that the
> > phrase is almost always used in its *incorrect* sense these days, and
> > almost never in its *correct* sense, does not diminish the fact that
> > those who use it incorrectly are ignorant scumbags!  The language is
> > weakened and diminished by the encroachment of incorrect usage.
> >
> >
> >
> > cheers,
> >
> > Rolf
> >
> >
> > --
> > Technical Editor ANZJS
> > Department of Statistics
> > University of Auckland
> > Phone: +64-9-373-7599 ext. 88276
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide
> > http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
> >
> --
> Dr. Michael Sumner
> Software and Database Engineer
> Australian Antarctic Division
> 203 Channel Highway
> Kingston Tasmania 7050 Australia
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>


-- 
There is no such thing as the Cloud. It is just somebody else?s computer.

Maranatha! <><
John McKown

	[[alternative HTML version deleted]]



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Mon Jun 25 16:36:48 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Mon, 25 Jun 2018 10:36:48 -0400
Subject: [R] Adding Axis value to R Plot
Message-ID: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>

Dear All: good morning



within this code, please see below,


plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt =
"n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)



Is there a way to force R to add the following Axis ticks to this plot


xticks <- c(15,25,35,45,55,65,75,85)
yticks <- c(300,400,500,600)



with many thanks
abou
______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*

	[[alternative HTML version deleted]]



From m|@thour| @end|ng |rom y@hoo@gr  Mon Jun 25 16:46:02 2018
From: m|@thour| @end|ng |rom y@hoo@gr (Maria Lathouri)
Date: Mon, 25 Jun 2018 14:46:02 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6ICBnZW9tX3RleHQgb25seSBpbiB0aGUgZmly?=
 =?utf-8?q?st_panel_with_facet=5Fwrap_in_ggplot2?=
In-Reply-To: <45144d17bdb88d003e998e623a6494ac@ruhr-uni-bochum.de>
References: <1858534513.2037097.1529913053406.ref@mail.yahoo.com>
 <1858534513.2037097.1529913053406@mail.yahoo.com>
 <45144d17bdb88d003e998e623a6494ac@ruhr-uni-bochum.de>
Message-ID: <392111583.2576251.1529937962889@mail.yahoo.com>

Dear Ulrik and all,
Thank you all so much; well, Ulrik's suggestion worked better. Very much appreciated.
Best,Maria 

    ???? 11:17 ?.?. ???????, 25 ??????? 2018, ?/? Ulrik Stervbo <Ulrik.Stervbo at ruhr-uni-bochum.de> ??????:
 

 Hi Maria,

you are on the right way. The data.frame with the text must have the 
same columns as you use in the clobal aesthetics, that is 'Q', 'fit', 
'ASB', and the facet variable ('asb_1') and the label you want shown.

ann_text <- data.frame(Q = 20, fit = 1.03, ASB = 1, plot_lab =? 
c("1","2","3"), asb_1 = c("ASB1", ASB2", "ASB3"))

p + geom_text(data = ann_text, aes(label = plot_lab)

should do the trick

HTH
Ulrik

On 2018-06-25 09:50, Maria Lathouri via R-help wrote:
> Dear all,
> 
> 
> I am trying to add text only in the first panel of a faceted ggplot; I
> have been struggling to find a solution on this online but
> unfortunately none of what I found is working.
> 
> Here it is a reproducible example. I hope it helps:
> library(gamm4)
> library(ggplot2)
> 
> example<-read.csv("example.csv")
> 
> head(example)
> #? Q? index ASB Year? ? ? WB_ID? S_ID score_1 score_2 works
> #1 100? 1.02? 1 2011 CL102021072830 157166? ? 0? 2.83? ? 0
> #2 100? 1.03? 1 2014 CL102021072830 157166? ? 0? 2.83? ? 0
> #3? 80? 1.02? 1 2013 CL102021072860? 1636? ? 0? 10.39? ? 0
> #4? 80? 1.06? 2 2006 CL102021072860? 1636? ? 0? 10.39? ? 0
> #5? 80? 1.06? 2 2003 CL102021072860? 1636? ? 0? 10.39? ? 0
> #6? 98? 1.07? 3 2002 CL102021072900? 1635? ? 0? 7.57? ? 0
> 
> str(example)
> #'data.frame':? ? 249 obs. of? 9 variables:
> #? $ Q? ? : int? 100 100 80 80 80 98 105 105 105 105 ...
> #$ index? : num? 1.02 1.03 1.02 1.06 1.06 1.07 1.14 1.05 1.1 1.08 ...
> #$ ASB? : int? 1 1 1 2 2 3 1 1 3 3 ...
> #$ Year? : int? 2011 2014 2013 2006 2003 2002 2013 2005 2013 2006 ...
> #$ WB_ID? : Factor w/ 44 levels "CL102021072830",..: 1 1 2 2 2 3 3 3 4 
> 4 ...
> #$ S_ID? : int? 157166 157166 1636 1636 1636 1635 1635 1635 134261 1631 
> ...
> #$ score_1: int? 0 0 0 0 0 0 0 0 0 0 ...
> #$ score_2: num? 2.83 2.83 10.39 10.39 10.39 ...
> #$ works? : num? 0 0 0 0 0 0 0 0 0 0 ...
> 
> # I need first to run a mixed-effect model
> model<-gamm4(index~s(Q, by=factor(ASB))+Year+score_1+score_2+works,
> data=example, random=~(1|WB_ID/S_ID))
> 
> 
> #I had to create a new dataset so I can use this with the ggplot2
> newDat <- expand.grid(ASB = factor(example$ASB),
> Q = seq(from = min(example$Q, na.rm = TRUE),
> to = max(example$Q, na.rm = TRUE),
> length = 100),
> Year = 2002,
> score_1 = mean(example$score_1),
> score_2 = mean(example$score_2),
> works = mean(example$works),
> WB_ID = "CL102021072830",
> S_ID = "157166")
> 
> datM <- predict(model$gam, type = "response",
> se.fit = TRUE, newdata = newDat)
> 
> newDat$fit <- datM$fit
> newDat$upr <- datM$fit + (1.96 * datM$se.fit)
> newDat$lwr <- datM$fit - (1.96 * datM$se.fit)
> 
> 
> 
> #I create a new variable for ASB so I can change the panel text
> newDat$asb_1<-factor(newDat$ASB, levels=c(1, 2, 3), labels=c("ASB1",
> "ASB2", "ASB3"))
> 
> 
> #I plot this with ggplot2
> p<-ggplot(newDat, aes(x = Q, y = fit, group = ASB)) +
> theme_bw() +
> geom_rug(data = example, aes(x = Q, y = 0.96), sides = "b") +
> ylim(0.96, 1.04) +
> geom_ribbon(aes(ymin = lwr, ymax = upr), col = NA, fill = "grey",
> alpha = 0.3) +
> geom_line(size = 1) +
> facet_wrap(~ asb_1, labeller = label_parsed)
> 
> 
> #When I try to add the text through geom_text, I get the text to all
> the three panels
> dat_text <- data.frame(label = c("Text", " ", " "), ASB? = c(1, 2, 3))
> 
> p + geom_text(x=20, y=1.03, data = dat_text, label = label)
> 
> # or
> p+geom_text(x=20, y=1.03 , aes(label=label), data=dat_text)
> 
> 
> # I tried another way
> ann_text <- data.frame(Q = 20, fit = 1.03, lab = "Text", ASB =
> factor(1,levels = c("1","2","3")))
> 
> p + geom_text(data = ann_text, label = "Text")
> 
> 
> # When I tried to use asb_1 instead of ASB, I got an errorann_text <-
> data.frame(Q = 20, fit = 1.03, lab = "Text", asb =
> factor("ASB1",levels = c("1","2","3")))
> 
> 
> #Error in FUN(X[[i]], ...) : object 'ASB' not found
> 
> I would very much appreciate for your help.
> 
> Thank you very much in advance.
> 
> Kind regards,
> Maria
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide 
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.


   
	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Mon Jun 25 17:00:49 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Mon, 25 Jun 2018 08:00:49 -0700
Subject: [R] Adding Axis value to R Plot
In-Reply-To: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
References: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
Message-ID: <CAGxFJbTKoswrAoMM-M2=2JfNMJUnAa1OKVy_LBbW9G3cXyef8A@mail.gmail.com>

See ?plot.default, where it says:

axes

a logical value indicating whether both axes should be drawn on the plot.
Use graphical parameter
<http://127.0.0.1:29349/help/library/graphics/help/graphical%20parameter>
"xaxt" or "yaxt" to suppress just one of the axes.
 and use the "at" argument of ?axis to draw the axis and add ticks where
you like.

Cheers,
Bert




Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Mon, Jun 25, 2018 at 7:36 AM, AbouEl-Makarim Aboueissa <
abouelmakarim1962 at gmail.com> wrote:

> Dear All: good morning
>
>
>
> within this code, please see below,
>
>
> plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt =
> "n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
> grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
>
>
>
> Is there a way to force R to add the following Axis ticks to this plot
>
>
> xticks <- c(15,25,35,45,55,65,75,85)
> yticks <- c(300,400,500,600)
>
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jw1085 @end|ng |rom w||dc@t@@unh@edu  Mon Jun 25 20:24:28 2018
From: jw1085 @end|ng |rom w||dc@t@@unh@edu (Jochen Wirsing)
Date: Mon, 25 Jun 2018 14:24:28 -0400
Subject: [R] Problems with 3.5.0 package installation & knitr
Message-ID: <5569677.kxo05TxI5a@lenny3>

Dear r-help,

I updated to R 3.5.0 a few days ago and was really excited about the new 
features it promised. Unfortunately, I ran into some serious trouble 
relatively quickly.
The main problem is, that I cannot install packages that depend on other 
packages. 
The problem has been (wrongfully) posted here: https://community.rstudio.com/
t/r-3-5-0-problem-installing-libraries/10155/3
A possibly connected problem is described here: https://community.rstudio.com/
t/file-does-not-exist-error-possibly-connected-with-r-3-5-0-update/10153

Both problems occur under R 3.5.0 (vanilla) as well as RStudio (1.1.453) and 
Antergos 18.04, as well as Win7.
The Antergos installation is brand new, the R installation in Win7 used to 
work absolutely perfectly before the update to 3.5.0

I hope those issues can be resolved quickly.


Thank you very much!
-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 488 bytes
Desc: This is a digitally signed message part.
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180625/4d93e154/attachment-0002.sig>

From murdoch@dunc@n @end|ng |rom gm@||@com  Mon Jun 25 22:04:39 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Mon, 25 Jun 2018 16:04:39 -0400
Subject: [R] Problems with 3.5.0 package installation & knitr
In-Reply-To: <5569677.kxo05TxI5a@lenny3>
References: <5569677.kxo05TxI5a@lenny3>
Message-ID: <8f53c9e1-38d4-4f15-8c26-dcb82f70fe93@gmail.com>

On 25/06/2018 2:24 PM, Jochen Wirsing wrote:
> Dear r-help,
> 
> I updated to R 3.5.0 a few days ago and was really excited about the new
> features it promised. Unfortunately, I ran into some serious trouble
> relatively quickly.
> The main problem is, that I cannot install packages that depend on other
> packages.
> The problem has been (wrongfully) posted here: https://community.rstudio.com/
> t/r-3-5-0-problem-installing-libraries/10155/3
> A possibly connected problem is described here: https://community.rstudio.com/
> t/file-does-not-exist-error-possibly-connected-with-r-3-5-0-update/10153
> 
> Both problems occur under R 3.5.0 (vanilla) as well as RStudio (1.1.453) and
> Antergos 18.04, as well as Win7.
> The Antergos installation is brand new, the R installation in Win7 used to
> work absolutely perfectly before the update to 3.5.0
> 
> I hope those issues can be resolved quickly.

You posted this same issue to R-devel yesterday, and got a response 
asking you some questions about your setup.

Duncan Murdoch



From p@u|bern@|07 @end|ng |rom gm@||@com  Mon Jun 25 22:07:47 2018
From: p@u|bern@|07 @end|ng |rom gm@||@com (Paul Bernal)
Date: Mon, 25 Jun 2018 15:07:47 -0500
Subject: [R] Automating Azure ML Experiments from R
Message-ID: <CAMOcQfOUYOsZw3f_XnXt6rWLcE8wvzFVQWqGNxJzdp5sHudLsw@mail.gmail.com>

Dear friends,

Hope you are all doing great. I created a forecasting model experiment in
azure ml studio and I am trying to automate the execution of the experiment.

Does anybody knows or has an idea of how to automate azure ml experiments
from R?

Best regards,

Paul

	[[alternative HTML version deleted]]



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Mon Jun 25 23:04:21 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Tue, 26 Jun 2018 02:34:21 +0530
Subject: [R] Correctly executing system code using R in Ubuntu server
Message-ID: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>

Hi,

I am curious on how to correctly run System code with R under Ubuntu. I
tried to execute below 2 lines of code using system() functions in Ubuntu
server, however could not achieve the desired result.

system('Xvfb :10 -ac &')
system('export DISPLAY=:10')

System parameters:
> Sys.info()
                                       sysname
                                       "Linux"
                                       release
                           "4.4.0-128-generic"
                                       version
"#154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018"
                                      nodename
                  "ubuntu-s-2vcpu-4gb-blr1-01"
                                       machine
                                      "x86_64"
                                         login
                                        "root"
                                          user
                                        "root"
                                effective_user
                                        "root"

Background:
I use RSelenium package to perform various testing using web-browser. I
have installed firefox to do the same, however to make RSelenium work, it
requires display parameter as guided in below link:
https://medium.com/@griggheo/running-selenium-webdriver-tests-using-firefox-headless-mode-on-ubuntu-d32500bb6af2
I want to set those parameters through R, each time I start R in Ubuntu
server.

Appreciate for any pointer.

Thanks,

	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Mon Jun 25 23:15:51 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Mon, 25 Jun 2018 14:15:51 -0700
Subject: [R] Correctly executing system code using R in Ubuntu server
In-Reply-To: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>
References: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>
Message-ID: <CAF8bMcaa+0KfZ36dkqyCofdHbbrd0fpPfSqM7s6U6T6Mn7Z6gg@mail.gmail.com>

Each call to system() starts and finishes a new shell so your approach will
not work.
Does the following do what you need?

> system('Xvfb :10 -ac &')
> Sys.setenv(DISPLAY=":10")
> x11()
Warning message:
In x11() : cairo-based types may only work correctly on TrueColor visuals



Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Jun 25, 2018 at 2:04 PM, Christofer Bogaso <
bogaso.christofer at gmail.com> wrote:

> Hi,
>
> I am curious on how to correctly run System code with R under Ubuntu. I
> tried to execute below 2 lines of code using system() functions in Ubuntu
> server, however could not achieve the desired result.
>
> system('Xvfb :10 -ac &')
> system('export DISPLAY=:10')
>
> System parameters:
> > Sys.info()
>                                        sysname
>                                        "Linux"
>                                        release
>                            "4.4.0-128-generic"
>                                        version
> "#154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018"
>                                       nodename
>                   "ubuntu-s-2vcpu-4gb-blr1-01"
>                                        machine
>                                       "x86_64"
>                                          login
>                                         "root"
>                                           user
>                                         "root"
>                                 effective_user
>                                         "root"
>
> Background:
> I use RSelenium package to perform various testing using web-browser. I
> have installed firefox to do the same, however to make RSelenium work, it
> requires display parameter as guided in below link:
> https://medium.com/@griggheo/running-selenium-webdriver-
> tests-using-firefox-headless-mode-on-ubuntu-d32500bb6af2
> I want to set those parameters through R, each time I start R in Ubuntu
> server.
>
> Appreciate for any pointer.
>
> Thanks,
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From drj|m|emon @end|ng |rom gm@||@com  Tue Jun 26 01:25:55 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Tue, 26 Jun 2018 09:25:55 +1000
Subject: [R] Adding Axis value to R Plot
In-Reply-To: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
References: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
Message-ID: <CA+8X3fUZLJnssb6AFhQh6YJNX-YWkTx7r_uNURDWYLmgQp87fw@mail.gmail.com>

Hi Abou,
You can't display an axis if it is not in the range of the plot. I
think you want:

plot(0,type="n",yaxs="i",xaxs="i",xaxt="n",yaxt="n",xlim=c(15,85),
 ylim=c(300,600),xlab="Age",ylab="Distance (ft)",cex.lab=1.5)
grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
xticks <- c(15,25,35,45,55,65,75,85)
yticks <- c(300,400,500,600)
axis(1,at=xticks)
axis(2,at=yticks)

Note the addition of xlim and ylim arguments.

Jim

On Tue, Jun 26, 2018 at 12:36 AM, AbouEl-Makarim Aboueissa
<abouelmakarim1962 at gmail.com> wrote:
> Dear All: good morning
>
>
>
> within this code, please see below,
>
>
> plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt =
> "n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
> grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
>
>
>
> Is there a way to force R to add the following Axis ticks to this plot
>
>
> xticks <- c(15,25,35,45,55,65,75,85)
> yticks <- c(300,400,500,600)
>
>
>
> with many thanks
> abou
> ______________________
>
>
> *AbouEl-Makarim Aboueissa, PhD*
>
> *Professor of Statistics*
>
> *Department of Mathematics and Statistics*
> *University of Southern Maine*
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From jwd @end|ng |rom @urewe@t@net  Tue Jun 26 02:58:05 2018
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Mon, 25 Jun 2018 17:58:05 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
Message-ID: <20180625175805.11fd5a3a@Draco.localdomain>

On Mon, 25 Jun 2018 09:46:07 +1200
Rolf Turner <r.turner at auckland.ac.nz> wrote:

> Does/should one say "the degrees of freedom is defined to be" or "the 
> degrees of freedom are defined to be"?
> 
I've leaned to differentiating between one degree of freedom and
multiple degrees of freedom and, when needed, phrase what I write
accordingly.  Canned phrases in the output of a routine may use
"degrees" simply because most of the time there are multiple degrees of
freedom.  After all, the only time "degree of freedom" would be
appropriate would be when there is just one.

JWDougherty



From jwd @end|ng |rom @urewe@t@net  Tue Jun 26 03:05:08 2018
From: jwd @end|ng |rom @urewe@t@net (John)
Date: Mon, 25 Jun 2018 18:05:08 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>
Message-ID: <20180625180508.70c545df@Draco.localdomain>

On Sun, 24 Jun 2018 20:16:24 -0400
JRG <loesljrg at accucom.net> wrote:

> On 06/24/2018 08:03 PM, Bert Gunter wrote:
> > Ted, et. al.:
> > 
> > Re: "Data is" vs "data are" ... Heh heh!
> > 
> > "This is the kind of arrant pedantry up with which I will not put."
> > (Attributed to Churchill in one form or another, likely wrongly.)
> > 
> > See here for some semi-authoritative dicussion:
> > 
> > http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/  
> 
> 
> Hmmm.  "semi-authoritative or not", the 1980 Edition of the Oxford
> American dictionary says:
> 
> "data (day-ta) n. pl. facts or information ...  'Data' should not be
> used with a singular verb, as in 'the data is inconclusive'; it is by
> origin a Latin plural (the singular is 'datum') and should be used
> with a plural verb. ..."
> 
> 
> Interesting how Latin seemed to have changed in the past 40 or so
> years.
> 
In fact, "the data are/is inconclusive" is shorthand for a longer
sentence.  Data are merely observations.  It is only after they are
made and summarized that a conclusion might be reached.  In which
case it was the analysis of the data that was inconclusive.  Since many
analyses of a single data set can be conducted and they are not
necessarily all going to be inconclusive, it really never was the data
that were inconclusive.

JWDoughetry



From dw|n@em|u@ @end|ng |rom comc@@t@net  Tue Jun 26 04:27:13 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Mon, 25 Jun 2018 19:27:13 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <20180625180508.70c545df@Draco.localdomain>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <408e101e-78a8-2860-3ae7-599efc6e2aeb@accucom.net>
 <20180625180508.70c545df@Draco.localdomain>
Message-ID: <586326E3-709E-42CB-B3E0-A714793ADDAB@comcast.net>

I?m surprised no on has reference the F distribution where the degrees of freedom are manifestly plural.

Sent from my iPhone

> On Jun 25, 2018, at 6:05 PM, John <jwd at surewest.net> wrote:
> 
> On Sun, 24 Jun 2018 20:16:24 -0400
> JRG <loesljrg at accucom.net> wrote:
> 
>>> On 06/24/2018 08:03 PM, Bert Gunter wrote:
>>> Ted, et. al.:
>>> 
>>> Re: "Data is" vs "data are" ... Heh heh!
>>> 
>>> "This is the kind of arrant pedantry up with which I will not put."
>>> (Attributed to Churchill in one form or another, likely wrongly.)
>>> 
>>> See here for some semi-authoritative dicussion:
>>> 
>>> http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/  
>> 
>> 
>> Hmmm.  "semi-authoritative or not", the 1980 Edition of the Oxford
>> American dictionary says:
>> 
>> "data (day-ta) n. pl. facts or information ...  'Data' should not be
>> used with a singular verb, as in 'the data is inconclusive'; it is by
>> origin a Latin plural (the singular is 'datum') and should be used
>> with a plural verb. ..."
>> 
>> 
>> Interesting how Latin seemed to have changed in the past 40 or so
>> years.
>> 
> In fact, "the data are/is inconclusive" is shorthand for a longer
> sentence.  Data are merely observations.  It is only after they are
> made and summarized that a conclusion might be reached.  In which
> case it was the analysis of the data that was inconclusive.  Since many
> analyses of a single data set can be conducted and they are not
> necessarily all going to be inconclusive, it really never was the data
> that were inconclusive.
> 
> JWDoughetry
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Tue Jun 26 05:30:41 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Tue, 26 Jun 2018 09:00:41 +0530
Subject: [R] Correctly executing system code using R in Ubuntu server
In-Reply-To: <CAF8bMcaa+0KfZ36dkqyCofdHbbrd0fpPfSqM7s6U6T6Mn7Z6gg@mail.gmail.com>
References: <CA+dpOJkVmfqf5=zNdD3iMUhu_Xo4v=eEpDMf7yQgdekX43yk_g@mail.gmail.com>
 <CAF8bMcaa+0KfZ36dkqyCofdHbbrd0fpPfSqM7s6U6T6Mn7Z6gg@mail.gmail.com>
Message-ID: <CA+dpOJ=AJA80eq775Z8ZtA=CP54bXGq3+3Rvng78c6vQ0jeBiA@mail.gmail.com>

It worked. Thanks,

On Tue, Jun 26, 2018 at 2:46 AM William Dunlap <wdunlap at tibco.com> wrote:

> Each call to system() starts and finishes a new shell so your approach
> will not work.
> Does the following do what you need?
>
> > system('Xvfb :10 -ac &')
> > Sys.setenv(DISPLAY=":10")
> > x11()
> Warning message:
> In x11() : cairo-based types may only work correctly on TrueColor visuals
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Mon, Jun 25, 2018 at 2:04 PM, Christofer Bogaso <
> bogaso.christofer at gmail.com> wrote:
>
>> Hi,
>>
>> I am curious on how to correctly run System code with R under Ubuntu. I
>> tried to execute below 2 lines of code using system() functions in Ubuntu
>> server, however could not achieve the desired result.
>>
>> system('Xvfb :10 -ac &')
>> system('export DISPLAY=:10')
>>
>> System parameters:
>> > Sys.info()
>>                                        sysname
>>                                        "Linux"
>>                                        release
>>                            "4.4.0-128-generic"
>>                                        version
>> "#154-Ubuntu SMP Fri May 25 14:15:18 UTC 2018"
>>                                       nodename
>>                   "ubuntu-s-2vcpu-4gb-blr1-01"
>>                                        machine
>>                                       "x86_64"
>>                                          login
>>                                         "root"
>>                                           user
>>                                         "root"
>>                                 effective_user
>>                                         "root"
>>
>> Background:
>> I use RSelenium package to perform various testing using web-browser. I
>> have installed firefox to do the same, however to make RSelenium work, it
>> requires display parameter as guided in below link:
>>
>> https://medium.com/@griggheo/running-selenium-webdriver-tests-using-firefox-headless-mode-on-ubuntu-d32500bb6af2
>> I want to set those parameters through R, each time I start R in Ubuntu
>> server.
>>
>> Appreciate for any pointer.
>>
>> Thanks,
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Tue Jun 26 10:16:55 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 26 Jun 2018 11:16:55 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
Message-ID: <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>

Thanks for the reply! I got that figured out, but still have some problems
with the quadratic programming.

It seems that my Amat and dvec are incompatible. Amat is a matrix of zeros
size: *2*J-3,J* and dvec is a vector of length *J*. There should be no
problem, but apparently there is. The piece of code looks like this:

Dmat <- matrix(0,nrow= J, ncol=J)
diag(Dmat) <- 1
dvec <- rep(0,J)
dvec
dvec <- -hsmooth
Aeq <- 0
beq <- 0
Amat <- matrix(0,2*J-3,J)
bvec <- rep(0,2*J-3)

for(j in 2:J)
{
Amat[j-1,j-1] = -1
Amat[j-1,j] = 1
bvec[j-1] = Delta1
}

for(j in 3:J)
{
Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
bvec[J-1+j-2]= Delta2
}

solution <- solve.QP(Dmat, dvec, Amat, bvec)


2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:

> Keep replies on list please.
>
> You are not accessing a value from vector Q if you access the zero'th
> element!
> R > Q <- c(3, 5, 8)
> R > Q[0]
> numeric(0)
> R > Q[1]
> [1] 3
> R > Q[2]
> [1] 5
>
> In the first iteration of the loop j is 2 thus j-2 is 0 and that's the
> reason for the error message: you are trying to replace a matrix element
> with a zero-length (i.e. unassigned) numeric value. Perhaps, in your mind,
> you are mixing up the index of a vector element and its value? If you need
> two zeros to start your vector, do something like
>
> R > Q <- c(0, 0, Q)
> R > Q
> [1] 0 0 3 5 8
>
>
> Clear now?
> B.
>
>
>
> > On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> >
> > Many thanks for your message!
> >
> > The thing is that I need  Q[j-2] to be zero for the first two iterations
> because I don't have those values (J starts from 1). Do you have any idea
> how to do it?
> >
> > Thanks again!
> >
> > Maija
> >
> > 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> > Q[j-2] gives you Q[0] in your first inner loop iteration.
> > R arrays start at one.
> >
> > B.
> >
> >
> > > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> wrote:
> > >
> > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> >
> >
>
>

	[[alternative HTML version deleted]]



From er|cjberger @end|ng |rom gm@||@com  Tue Jun 26 10:24:16 2018
From: er|cjberger @end|ng |rom gm@||@com (Eric Berger)
Date: Tue, 26 Jun 2018 11:24:16 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
Message-ID: <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>

 The statement

dvec <- -hsmooth

looks like it might be the source of the problem, depending on what hsmooth
is.


On Tue, Jun 26, 2018 at 11:16 AM, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com
> wrote:

> Thanks for the reply! I got that figured out, but still have some problems
> with the quadratic programming.
>
> It seems that my Amat and dvec are incompatible. Amat is a matrix of zeros
> size: *2*J-3,J* and dvec is a vector of length *J*. There should be no
> problem, but apparently there is. The piece of code looks like this:
>
> Dmat <- matrix(0,nrow= J, ncol=J)
> diag(Dmat) <- 1
> dvec <- rep(0,J)
> dvec
> dvec <- -hsmooth
> Aeq <- 0
> beq <- 0
> Amat <- matrix(0,2*J-3,J)
> bvec <- rep(0,2*J-3)
>
> for(j in 2:J)
> {
> Amat[j-1,j-1] = -1
> Amat[j-1,j] = 1
> bvec[j-1] = Delta1
> }
>
> for(j in 3:J)
> {
> Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
> Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
> bvec[J-1+j-2]= Delta2
> }
>
> solution <- solve.QP(Dmat, dvec, Amat, bvec)
>
>
> 2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>
> > Keep replies on list please.
> >
> > You are not accessing a value from vector Q if you access the zero'th
> > element!
> > R > Q <- c(3, 5, 8)
> > R > Q[0]
> > numeric(0)
> > R > Q[1]
> > [1] 3
> > R > Q[2]
> > [1] 5
> >
> > In the first iteration of the loop j is 2 thus j-2 is 0 and that's the
> > reason for the error message: you are trying to replace a matrix element
> > with a zero-length (i.e. unassigned) numeric value. Perhaps, in your
> mind,
> > you are mixing up the index of a vector element and its value? If you
> need
> > two zeros to start your vector, do something like
> >
> > R > Q <- c(0, 0, Q)
> > R > Q
> > [1] 0 0 3 5 8
> >
> >
> > Clear now?
> > B.
> >
> >
> >
> > > On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> > wrote:
> > >
> > > Many thanks for your message!
> > >
> > > The thing is that I need  Q[j-2] to be zero for the first two
> iterations
> > because I don't have those values (J starts from 1). Do you have any idea
> > how to do it?
> > >
> > > Thanks again!
> > >
> > > Maija
> > >
> > > 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
> > > Q[j-2] gives you Q[0] in your first inner loop iteration.
> > > R arrays start at one.
> > >
> > > B.
> > >
> > >
> > > > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
> > wrote:
> > > >
> > > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
> > >
> > >
> >
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Tue Jun 26 10:34:31 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Tue, 26 Jun 2018 11:34:31 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>
Message-ID: <CAJxz9NajxNm-MigCXPFA9mOn0nXZeh4m4WHecz7fj0ExBhAW-A@mail.gmail.com>

Thanks for the reply!

dvec, thus hsmooth, has the same length J. It shouldn't be the problem.

2018-06-26 11:24 GMT+03:00 Eric Berger <ericjberger at gmail.com>:

> The statement
>
> dvec <- -hsmooth
>
> looks like it might be the source of the problem, depending on what
> hsmooth is.
>
>
> On Tue, Jun 26, 2018 at 11:16 AM, Maija Sirkj?rvi <
> maija.sirkjarvi at gmail.com> wrote:
>
>> Thanks for the reply! I got that figured out, but still have some problems
>> with the quadratic programming.
>>
>> It seems that my Amat and dvec are incompatible. Amat is a matrix of zeros
>> size: *2*J-3,J* and dvec is a vector of length *J*. There should be no
>>
>> problem, but apparently there is. The piece of code looks like this:
>>
>> Dmat <- matrix(0,nrow= J, ncol=J)
>> diag(Dmat) <- 1
>> dvec <- rep(0,J)
>> dvec
>> dvec <- -hsmooth
>> Aeq <- 0
>> beq <- 0
>> Amat <- matrix(0,2*J-3,J)
>> bvec <- rep(0,2*J-3)
>>
>> for(j in 2:J)
>> {
>> Amat[j-1,j-1] = -1
>> Amat[j-1,j] = 1
>> bvec[j-1] = Delta1
>> }
>>
>> for(j in 3:J)
>> {
>> Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
>> Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>> Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
>> bvec[J-1+j-2]= Delta2
>> }
>>
>> solution <- solve.QP(Dmat, dvec, Amat, bvec)
>>
>>
>> 2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>>
>> > Keep replies on list please.
>> >
>> > You are not accessing a value from vector Q if you access the zero'th
>> > element!
>> > R > Q <- c(3, 5, 8)
>> > R > Q[0]
>> > numeric(0)
>> > R > Q[1]
>> > [1] 3
>> > R > Q[2]
>> > [1] 5
>> >
>> > In the first iteration of the loop j is 2 thus j-2 is 0 and that's the
>> > reason for the error message: you are trying to replace a matrix element
>> > with a zero-length (i.e. unassigned) numeric value. Perhaps, in your
>> mind,
>> > you are mixing up the index of a vector element and its value? If you
>> need
>> > two zeros to start your vector, do something like
>> >
>> > R > Q <- c(0, 0, Q)
>> > R > Q
>> > [1] 0 0 3 5 8
>> >
>> >
>> > Clear now?
>> > B.
>> >
>> >
>> >
>> > > On 2018-06-14, at 01:22, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com>
>> > wrote:
>> > >
>> > > Many thanks for your message!
>> > >
>> > > The thing is that I need  Q[j-2] to be zero for the first two
>> iterations
>> > because I don't have those values (J starts from 1). Do you have any
>> idea
>> > how to do it?
>> > >
>> > > Thanks again!
>> > >
>> > > Maija
>> > >
>> > > 2018-06-13 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>> > > Q[j-2] gives you Q[0] in your first inner loop iteration.
>> > > R arrays start at one.
>> > >
>> > > B.
>> > >
>> > >
>> > > > On 2018-06-13, at 07:21, Maija Sirkj?rvi <maija.sirkjarvi at gmail.com
>> >
>> > wrote:
>> > > >
>> > > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>> > >
>> > >
>> >
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posti
>> ng-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From berw|n@tur|@ch @end|ng |rom gm@||@com  Tue Jun 26 14:01:36 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Tue, 26 Jun 2018 20:01:36 +0800
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
Message-ID: <20180626200136.115557ce@goodenia>

G'day all,

On Tue, 26 Jun 2018 11:16:55 +0300
Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:

> It seems that my Amat and dvec are incompatible. Amat is a matrix of
> zeros size: *2*J-3,J* and dvec is a vector of length *J*. There
> should be no problem, but apparently there is. [...]

solve.QP solves the quadratic program:
	 min(-d^T b + 1/2 b^T D b) 
   where A^T b >= b_0.

Note the transpose. :)
If dvec is of length *J*, then b will be of length J too, and Amat
should be Jx(2J-3) so that its transpose is (2j-3)xJ, making it
compatible for matrix multiplication with b.

Cheers,

	Berwin

---
This email has been checked for viruses by Avast antivirus software.
https://www.avast.com/antivirus



From B|||@Po||ng @end|ng |rom ze||@@com  Tue Jun 26 14:07:22 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 26 Jun 2018 12:07:22 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
Message-ID: <CY1PR0201MB1834A9FA7E201A7069D50D9DEA490@CY1PR0201MB1834.namprd02.prod.outlook.com>

Thank you Dan, that was very helpful. Sorry for the delayed response.

Cheers

WHP



From: Daniel Nordlund [mailto:djnordlund at gmail.com]
Sent: Saturday, June 23, 2018 6:04 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

On 6/22/2018 4:43 AM, Bill Poling wrote:
> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
> ClaimServiceID ClaimID DiagnosisCode
> 1 183056004 78044473 C562
> 2 183056004 78044473 C778
> 3 183056004 78044473 C784
> 4 183056004 78044473 C786
> 5 183056004 78044473 C7961
> 6 183056004 78044473 C7982
> 7 183056004 78044473 C7989
> 8 183056008 78044473 C562
> 9 183056008 78044473 C778
> 10 183056008 78044473 C784
> 11 183056008 78044473 C786
> 12 183056008 78044473 C7961
> 13 183056008 78044473 C7982
> 14 183056008 78044473 C7989
> 15 183139945 78078925 M79606
> 16 183139945 78078925 M7989
> 17 183139945 78078925 R600
> 18 183236728 78119632 H02831
> 19 183236728 78119632 H02832
> 20 183236728 78119632 H02834
> 21 183236728 78119632 H02835
> 22 183236728 78119632 H04123
> 23 183236728 78119632 Z411
> 24 183236728 78119632 H2513
> 25 183236728 78119632 H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
>
> claimServiceID ClaimID Dx1 Dx2 Dx3 ...etc
> 1 183056004 78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008 78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer" "integer" "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>
>
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>
>
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
>
>
> I am sure it's a basic, simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>

Bill,

you have received some good suggestions and since you are pressed for
time this may be too late. However, here is a solution using ave()
function and cast() from the reshape package.

# create diagnosis variable names
dxnames <- paste('Dx',ave(rep(1, nrow(have)), have[,1:2], FUN =
seq_along), sep='')
# cast the data into wide format
cast(cbind(have,dxnames), ClaimServiceID + ClaimID ~ dxnames,
value='DiagnosisCode')


Hope this is helpful,

Dan

--
Daniel Nordlund
Port Townsend, WA USA

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Tue Jun 26 14:14:10 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Tue, 26 Jun 2018 05:14:10 -0700
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NajxNm-MigCXPFA9mOn0nXZeh4m4WHecz7fj0ExBhAW-A@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <CAGgJW74ukeKPVNW0L8i-XeBOYk_vtSnQNuPgqq8ECQsAGba+sg@mail.gmail.com>
 <CAJxz9NajxNm-MigCXPFA9mOn0nXZeh4m4WHecz7fj0ExBhAW-A@mail.gmail.com>
Message-ID: <B2938D61-C3EF-421C-B8D0-E509B77D315C@dcn.davis.ca.us>

The recommended (see the Posting Guide) way to resolve questions like this is to post a reproducible example so we can see the problem occur in our R session. There are a number of Internet resources that can help you get this right such as [1][2][3].

Note that one key to success is to learn how to configure your email program send plain text formatted email, since the mailing list will strip the HTML formatting anyway but this often leaves extraneous characters that make no sense to R. Most email attachments are removed, so keep including the code in the email body as you have been.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 


On June 26, 2018 1:34:31 AM PDT, "Maija Sirkj?rvi" <maija.sirkjarvi at gmail.com> wrote:
>Thanks for the reply!
>
>dvec, thus hsmooth, has the same length J. It shouldn't be the problem.
>
>2018-06-26 11:24 GMT+03:00 Eric Berger <ericjberger at gmail.com>:
>
>> The statement
>>
>> dvec <- -hsmooth
>>
>> looks like it might be the source of the problem, depending on what
>> hsmooth is.
>>
>>
>> On Tue, Jun 26, 2018 at 11:16 AM, Maija Sirkj?rvi <
>> maija.sirkjarvi at gmail.com> wrote:
>>
>>> Thanks for the reply! I got that figured out, but still have some
>problems
>>> with the quadratic programming.
>>>
>>> It seems that my Amat and dvec are incompatible. Amat is a matrix of
>zeros
>>> size: *2*J-3,J* and dvec is a vector of length *J*. There should be
>no
>>>
>>> problem, but apparently there is. The piece of code looks like this:
>>>
>>> Dmat <- matrix(0,nrow= J, ncol=J)
>>> diag(Dmat) <- 1
>>> dvec <- rep(0,J)
>>> dvec
>>> dvec <- -hsmooth
>>> Aeq <- 0
>>> beq <- 0
>>> Amat <- matrix(0,2*J-3,J)
>>> bvec <- rep(0,2*J-3)
>>>
>>> for(j in 2:J)
>>> {
>>> Amat[j-1,j-1] = -1
>>> Amat[j-1,j] = 1
>>> bvec[j-1] = Delta1
>>> }
>>>
>>> for(j in 3:J)
>>> {
>>> Amat[J-1+j-2,j] = -1/(Q[j] - Q[j-1])
>>> Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>>> Amat[J-1+j-2,j-2]= -1/(Q[j-1] - Q[j-2])
>>> bvec[J-1+j-2]= Delta2
>>> }
>>>
>>> solution <- solve.QP(Dmat, dvec, Amat, bvec)
>>>
>>>
>>> 2018-06-14 15:52 GMT+03:00 Boris Steipe <boris.steipe at utoronto.ca>:
>>>
>>> > Keep replies on list please.
>>> >
>>> > You are not accessing a value from vector Q if you access the
>zero'th
>>> > element!
>>> > R > Q <- c(3, 5, 8)
>>> > R > Q[0]
>>> > numeric(0)
>>> > R > Q[1]
>>> > [1] 3
>>> > R > Q[2]
>>> > [1] 5
>>> >
>>> > In the first iteration of the loop j is 2 thus j-2 is 0 and that's
>the
>>> > reason for the error message: you are trying to replace a matrix
>element
>>> > with a zero-length (i.e. unassigned) numeric value. Perhaps, in
>your
>>> mind,
>>> > you are mixing up the index of a vector element and its value? If
>you
>>> need
>>> > two zeros to start your vector, do something like
>>> >
>>> > R > Q <- c(0, 0, Q)
>>> > R > Q
>>> > [1] 0 0 3 5 8
>>> >
>>> >
>>> > Clear now?
>>> > B.
>>> >
>>> >
>>> >
>>> > > On 2018-06-14, at 01:22, Maija Sirkj?rvi
><maija.sirkjarvi at gmail.com>
>>> > wrote:
>>> > >
>>> > > Many thanks for your message!
>>> > >
>>> > > The thing is that I need  Q[j-2] to be zero for the first two
>>> iterations
>>> > because I don't have those values (J starts from 1). Do you have
>any
>>> idea
>>> > how to do it?
>>> > >
>>> > > Thanks again!
>>> > >
>>> > > Maija
>>> > >
>>> > > 2018-06-13 15:52 GMT+03:00 Boris Steipe
><boris.steipe at utoronto.ca>:
>>> > > Q[j-2] gives you Q[0] in your first inner loop iteration.
>>> > > R arrays start at one.
>>> > >
>>> > > B.
>>> > >
>>> > >
>>> > > > On 2018-06-13, at 07:21, Maija Sirkj?rvi
><maija.sirkjarvi at gmail.com
>>> >
>>> > wrote:
>>> > > >
>>> > > >  Amat[J-1+j-2,j-1]= 1/(Q[j] - Q[j-1]) + 1/(Q[j-1] - Q[j-2])
>>> > >
>>> > >
>>> >
>>> >
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide http://www.R-project.org/posti
>>> ng-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From B|||@Po||ng @end|ng |rom ze||@@com  Tue Jun 26 14:15:30 2018
From: B|||@Po||ng @end|ng |rom ze||@@com (Bill Poling)
Date: Tue, 26 Jun 2018 12:15:30 +0000
Subject: [R] Help with transpose please.
In-Reply-To: <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
References: <CY1PR0201MB18341893FAD2F0C85A2CBD74EA750@CY1PR0201MB1834.namprd02.prod.outlook.com>
 <8b877540-f7ba-4b8a-546c-0c32ada7c48b@gmail.com>
Message-ID: <CY1PR0201MB18348C8A71CEF766FC0F803DEA490@CY1PR0201MB1834.namprd02.prod.outlook.com>

Yep, thanks Dan, that?s got it. Thank you to everyone who responded as well.

WHP

ClaimServiceID  ClaimID     Dx1  Dx10  Dx11 Dx12     Dx2     Dx3     Dx4     Dx5     Dx6    Dx7    Dx8    Dx9
1        183056004 78044473    C562  <NA>  <NA> <NA>    C778    C784    C786   C7961   C7982  C7989   <NA>   <NA>
2        183056008 78044473    C562  <NA>  <NA> <NA>    C778    C784    C786   C7961   C7982  C7989   <NA>   <NA>
3        183139945 78078925  M79606  <NA>  <NA> <NA>   M7989    R600    <NA>    <NA>    <NA>   <NA>   <NA>   <NA>

From: Daniel Nordlund [mailto:djnordlund at gmail.com]
Sent: Saturday, June 23, 2018 6:04 AM
To: Bill Poling <Bill.Poling at zelis.com>; r-help (r-help at r-project.org) <r-help at r-project.org>
Subject: Re: [R] Help with transpose please.

On 6/22/2018 4:43 AM, Bill Poling wrote:
> Good morning.
>
>
> I have data in the form:
>
> head(Edit041IA, n=25)
> ClaimServiceID ClaimID DiagnosisCode
> 1 183056004 78044473 C562
> 2 183056004 78044473 C778
> 3 183056004 78044473 C784
> 4 183056004 78044473 C786
> 5 183056004 78044473 C7961
> 6 183056004 78044473 C7982
> 7 183056004 78044473 C7989
> 8 183056008 78044473 C562
> 9 183056008 78044473 C778
> 10 183056008 78044473 C784
> 11 183056008 78044473 C786
> 12 183056008 78044473 C7961
> 13 183056008 78044473 C7982
> 14 183056008 78044473 C7989
> 15 183139945 78078925 M79606
> 16 183139945 78078925 M7989
> 17 183139945 78078925 R600
> 18 183236728 78119632 H02831
> 19 183236728 78119632 H02832
> 20 183236728 78119632 H02834
> 21 183236728 78119632 H02835
> 22 183236728 78119632 H04123
> 23 183236728 78119632 Z411
> 24 183236728 78119632 H2513
> 25 183236728 78119632 H43813
>
> And wish to transpose to single record for single claimServiceID, ClaimID, and Dx1,Dx2,Dx3, etc:
>
> There can be multiple claimServiceIDs for a ClaimID so I want the unique ClaimServiceID as the identifier when I join this data back into a longer single record length file by that column.
>
> claimServiceID ClaimID Dx1 Dx2 Dx3 ...etc
> 1 183056004 78044473 C562 C778 C784 C786 C7961 ...etc
> 2 183056008 78044473 C562 C778 C784 C786 C7961 ...etc
>
>
> (If you would prefer the complete dput of the 1272 records I will gladly provide .Names = c("ClaimServiceID",
>
> "ClaimID", "DiagnosisCode"), class = "data.frame", row.names = c(NA,
>
> -1272L))
>
>
>
> At the moment the classes are:
>
> classes <- as.character(sapply(Edit041IA, class))
>
> classes
>
> # [1] "integer" "integer" "character" <---but do not have to be if that helps its just that's how the csv load pulled them in
>
> The max number of columns based on this transpose of the DiagnosisCode column (in this dataset) is 12 if that is important to know.
>
> I have looked at a variety of webpages and cannot get this right,
>
> dta2 <- melt(dta1, id=c("ClaimServiceID","ClaimID"))
> View(dta2)
> # https://www.r-bloggers.com/pivot-tables-in-r/<https://www.r-bloggers.com/pivot-tables-in-r/>
>
> # https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function<https://stackoverflow.com/questions/18449938/pivot-on-data-table-similar-to-rehape-melt-function>
>
>
> dta3 <- cast(Edit041IA, ClaimServiceID ~ DiagnosisCode, ClaimID)
> View(dta3)
> dta3 <- cast(Edit041IA, DiagnosisCode ~ ClaimServiceID, ClaimID)
> View(dta3)
>
> dta3 <- melt(Edit041IA, id=c("ClaimServiceID"))
> View(dta3)
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID, ClaimID, DiagnosisCode))
> View(dta3)
>
>
> dta3 <- aggregate(Edit041IA, by=list(ClaimServiceID))
> View(dta3)
> # https://www.r-statistics.com/tag/transpose/<https://www.r-statistics.com/tag/transpose/>
>
> dta3 <- aggregate(Edit041IA, by=list(DiagnosisCode, ClaimServiceID, ClaimID))
> View(dta3)
>
>
> I am sure it's a basic, simple procedure, but I am pressed for time on this one, any support will be greatly appreciated, thank you.
>
> WHP
>
>
>
>
>
> Confidentiality Notice This message is sent from Zelis. ...{{dropped:15}}
>
> ______________________________________________
> R-help at r-project.org<mailto:R-help at r-project.org> mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help<https://stat.ethz.ch/mailman/listinfo/r-help>
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html<http://www.R-project.org/posting-guide.html>
> and provide commented, minimal, self-contained, reproducible code.
>

Bill,

you have received some good suggestions and since you are pressed for
time this may be too late. However, here is a solution using ave()
function and cast() from the reshape package.

# create diagnosis variable names
dxnames <- paste('Dx',ave(rep(1, nrow(have)), have[,1:2], FUN =
seq_along), sep='')
# cast the data into wide format
cast(cbind(have,dxnames), ClaimServiceID + ClaimID ~ dxnames,
value='DiagnosisCode')


Hope this is helpful,

Dan

--
Daniel Nordlund
Port Townsend, WA USA

Confidentiality Notice This message is sent from Zelis. This transmission may contain information which is privileged and confidential and is intended for the personal and confidential use of the named recipient only. Such information may be protected by applicable State and Federal laws from this disclosure or unauthorized use. If the reader of this message is not the intended recipient, or the employee or agent responsible for delivering the message to the intended recipient, you are hereby notified that any disclosure, review, discussion, copying, or taking any action in reliance on the contents of this transmission is strictly prohibited. If you have received this transmission in error, please contact the sender immediately. Zelis, 2018.

	[[alternative HTML version deleted]]


From reg@rdt@@ch@|kwyk @end|ng |rom gm@||@com  Mon Jun 25 22:39:11 2018
From: reg@rdt@@ch@|kwyk @end|ng |rom gm@||@com (Regardt Schalkwyk)
Date: Mon, 25 Jun 2018 20:39:11 +0000
Subject: [R] Automating Azure ML Experiments from R
In-Reply-To: <CAMOcQfOUYOsZw3f_XnXt6rWLcE8wvzFVQWqGNxJzdp5sHudLsw@mail.gmail.com>
References: <CAMOcQfOUYOsZw3f_XnXt6rWLcE8wvzFVQWqGNxJzdp5sHudLsw@mail.gmail.com>
Message-ID: <VI1PR0402MB38858CFCEDC181084FA4AFFBA84A0@VI1PR0402MB3885.eurprd04.prod.outlook.com>

Hi Paul

Microsoft has made this really easy for you.
Just deploy the web service, go to services.azureml.net, select your web service, click on consume, go to sample code and select R.

It will give you a sample script using RCurl and rjson to consume your service.

Regards
Regardt

Regardt Schalkwyk
________________________________
From: R-help <r-help-bounces at r-project.org> on behalf of Paul Bernal <paulbernal07 at gmail.com>
Sent: Monday, June 25, 2018 10:07:47 PM
To: r-help at r-project.org
Subject: [R] Automating Azure ML Experiments from R

Dear friends,

Hope you are all doing great. I created a forecasting model experiment in
azure ml studio and I am trying to automate the execution of the experiment.

Does anybody knows or has an idea of how to automate azure ml experiments
from R?

Best regards,

Paul

        [[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org  Tue Jun 26 17:00:53 2018
From: @pencer@gr@ve@ @end|ng |rom e||ect|vede|en@e@org (Spencer Graves)
Date: Tue, 26 Jun 2018 10:00:53 -0500
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <20180626200136.115557ce@goodenia>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
Message-ID: <17542e52-7c8c-5ccb-e89a-61f369db16b9@effectivedefense.org>

 ????? sos::findFn('{quadratic programming}') just identified 156 help 
pages in 68 packages containing the term "quadratic programming".? The 
function mentioned by Berwin Turlach, "solve.QP", is in package 
"quadprog", which has not been updated since 2016-12-20.? I've used 
qudprod successfully, but you might wish to consider some of the other 
options in package(s) more actively maintained.


 ????? The "print" method for sos::findFn('{quadratic programming}') 
produced two sheets in my default browser.? The first of these contained 
156 rows for the 156 help pages in 68 packages, sorted by default by 
c('Count', 'MaxScore', 'TotalScore', 'Package', 'Score', 'Function').? 
The second sheet listed only the 68 packages sorted by c('Count', 
'MaxScore', 'TotalScore', 'Package').? You can click on the column 
headers to get them sorted in different orders, if you want.


 ????? "sos::findFn" is for me the fastest literature search for 
anything statistical.? I often write the list of help pages and the 
package summary to an Excel file using the "writeFindFn2xls" function, 
then annotate the package summary with other information to help me 
decide which package(s) and function(s) to try.


 ????? Hope this helps.
 ????? Spencer Graves, lead author of "sos"


On 2018-06-26 07:01, Berwin A Turlach wrote:
> G'day all,
>
> On Tue, 26 Jun 2018 11:16:55 +0300
> Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
>
>> It seems that my Amat and dvec are incompatible. Amat is a matrix of
>> zeros size: *2*J-3,J* and dvec is a vector of length *J*. There
>> should be no problem, but apparently there is. [...]
> solve.QP solves the quadratic program:
> 	 min(-d^T b + 1/2 b^T D b)
>     where A^T b >= b_0.
>
> Note the transpose. :)
> If dvec is of length *J*, then b will be of length J too, and Amat
> should be Jx(2J-3) so that its transpose is (2j-3)xJ, making it
> compatible for matrix multiplication with b.
>
> Cheers,
>
> 	Berwin
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @boue|m@k@r|m1962 @end|ng |rom gm@||@com  Tue Jun 26 17:35:34 2018
From: @boue|m@k@r|m1962 @end|ng |rom gm@||@com (AbouEl-Makarim Aboueissa)
Date: Tue, 26 Jun 2018 11:35:34 -0400
Subject: [R] Adding Axis value to R Plot
In-Reply-To: <CA+8X3fUZLJnssb6AFhQh6YJNX-YWkTx7r_uNURDWYLmgQp87fw@mail.gmail.com>
References: <CAE9stmdG-TeUZGtkNwrRUxqr2mbPh9Znc7oV97905oN8p5eVCg@mail.gmail.com>
 <CA+8X3fUZLJnssb6AFhQh6YJNX-YWkTx7r_uNURDWYLmgQp87fw@mail.gmail.com>
Message-ID: <CAE9stmc1Oz5sk+TxNowxYA3QbwyXC6Lr6n2w7dK3pVKyR7VM0Q@mail.gmail.com>

Dear Jim:

many thanks

abou

______________________


*AbouEl-Makarim Aboueissa, PhD*

*Professor of Statistics*

*Department of Mathematics and Statistics*
*University of Southern Maine*


On Mon, Jun 25, 2018 at 7:25 PM, Jim Lemon <drjimlemon at gmail.com> wrote:

> Hi Abou,
> You can't display an axis if it is not in the range of the plot. I
> think you want:
>
> plot(0,type="n",yaxs="i",xaxs="i",xaxt="n",yaxt="n",xlim=c(15,85),
>  ylim=c(300,600),xlab="Age",ylab="Distance (ft)",cex.lab=1.5)
> grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
> xticks <- c(15,25,35,45,55,65,75,85)
> yticks <- c(300,400,500,600)
> axis(1,at=xticks)
> axis(2,at=yticks)
>
> Note the addition of xlim and ylim arguments.
>
> Jim
>
> On Tue, Jun 26, 2018 at 12:36 AM, AbouEl-Makarim Aboueissa
> <abouelmakarim1962 at gmail.com> wrote:
> > Dear All: good morning
> >
> >
> >
> > within this code, please see below,
> >
> >
> > plot(0:1.0, 0:1.0, type = "n",  yaxs = "i", xaxs = "i", xaxt = "n", yaxt
> =
> > "n", xlab = "Age", ylab = "Distance (ft)",  cex.lab=1.5)
> > grid(nx = 10, ny = 10, col = "lightgray", lty = "dotted", lwd = 2)
> >
> >
> >
> > Is there a way to force R to add the following Axis ticks to this plot
> >
> >
> > xticks <- c(15,25,35,45,55,65,75,85)
> > yticks <- c(300,400,500,600)
> >
> >
> >
> > with many thanks
> > abou
> > ______________________
> >
> >
> > *AbouEl-Makarim Aboueissa, PhD*
> >
> > *Professor of Statistics*
> >
> > *Department of Mathematics and Statistics*
> > *University of Southern Maine*
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Wed Jun 27 02:37:57 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Tue, 26 Jun 2018 19:37:57 -0500
Subject: [R] Convert Hijri to Gregorian
Message-ID: <000001d40daf$190590a0$4b10b1e0$@sbcglobal.net>

R-help

 

Does R have a package or function that will convert Gregorian to Hijri
(Islamic) dates (time series)?

 

Jeff 


	[[alternative HTML version deleted]]



From m@|j@@@|rkj@rv| @end|ng |rom gm@||@com  Wed Jun 27 07:48:08 2018
From: m@|j@@@|rkj@rv| @end|ng |rom gm@||@com (=?UTF-8?Q?Maija_Sirkj=C3=A4rvi?=)
Date: Wed, 27 Jun 2018 08:48:08 +0300
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <20180626200136.115557ce@goodenia>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
Message-ID: <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>

Thanks for your reply! Unfortunately something is still wrong.

After the transpose, dvec and Amat are still incompatible.

> d <- -hsmooth
> dvec <- t(d)
> c <- dvec*Amat
Error in dvec * Amat : non-conformable arrays

Moreover, I don't understand the following:

> If dvec is of length *J*, then b will be of length J too.

I believe the length of dvec comes from the number of variables and the
length of b from the number of constraints. In this case they are not
equal.

2018-06-26 15:01 GMT+03:00 Berwin A Turlach <berwin.turlach at gmail.com>:

> G'day all,
>
> On Tue, 26 Jun 2018 11:16:55 +0300
> Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:
>
> > It seems that my Amat and dvec are incompatible. Amat is a matrix of
> > zeros size: *2*J-3,J* and dvec is a vector of length *J*. There
> > should be no problem, but apparently there is. [...]
>
> solve.QP solves the quadratic program:
>          min(-d^T b + 1/2 b^T D b)
>    where A^T b >= b_0.
>
> Note the transpose. :)
> If dvec is of length *J*, then b will be of length J too, and Amat
> should be Jx(2J-3) so that its transpose is (2j-3)xJ, making it
> compatible for matrix multiplication with b.
>
> Cheers,
>
>         Berwin
>
> ---
> This email has been checked for viruses by Avast antivirus software.
> https://www.avast.com/antivirus
>
>

	[[alternative HTML version deleted]]



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Wed Jun 27 22:53:58 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Wed, 27 Jun 2018 13:53:58 -0700
Subject: [R] Adding lines to the page
Message-ID: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>

Hi, I'm looking for a way to add lines to a report. To be clear, I don't want to add lines to any specific plot, but instead to add line(s) to the page itself - e.g. add a line to the footer area, above the actual footer text. 

Any thoughts on how to do this? Many thanks.



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Wed Jun 27 23:07:48 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Jun 2018 14:07:48 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
Message-ID: <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>

That would depend how you are generating the page... plots alone don't really have such options. If you don't know what this means then I suggest you read the Reproducible Research Task View [1]. knitr in conjunction with LaTeX (Rnw files) is very powerful, but there are many other tools as well (e.g. bookdown) depending on your preferences.

[1] https://cran.r-project.org/web/views/ReproducibleResearch.html

On June 27, 2018 1:53:58 PM PDT, Stats Student <stats.student4647 at gmail.com> wrote:
>Hi, I'm looking for a way to add lines to a report. To be clear, I
>don't want to add lines to any specific plot, but instead to add
>line(s) to the page itself - e.g. add a line to the footer area, above
>the actual footer text. 
>
>Any thoughts on how to do this? Many thanks.
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From n|cho|@@@wr@y @end|ng |rom nt|wor|d@com  Thu Jun 28 00:33:39 2018
From: n|cho|@@@wr@y @end|ng |rom nt|wor|d@com (Nick Wray)
Date: Wed, 27 Jun 2018 23:33:39 +0100 (BST)
Subject: [R] How long can a csv file label be?
Message-ID: <1066236676.882891.1530138819259@mail2.virginmedia.com>

Hi For various reasons too dull to go into I have been trying to write csv files from R with very long filenames.  However R doesn't seem to like my doing this, but it is not clear to me what the maximum filename size is, and I can't find the info on the net.  I believe that the maximum pathname is 255 characters but is that the same thing?

Thanks if anyone can enlighten me

Nick Wray
	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Thu Jun 28 00:39:30 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Wed, 27 Jun 2018 15:39:30 -0700
Subject: [R] How long can a csv file label be?
In-Reply-To: <1066236676.882891.1530138819259@mail2.virginmedia.com>
References: <1066236676.882891.1530138819259@mail2.virginmedia.com>
Message-ID: <067CF37F-5190-4347-A95E-6D8F83063C75@dcn.davis.ca.us>

This is operating-system-dependent. Check the documentation for your operating system (or the file subsystem you are using, since some OSes support multiple filesystems). Knowing this fact can make Googling more effective as well.

On June 27, 2018 3:33:39 PM PDT, Nick Wray via R-help <r-help at r-project.org> wrote:
>Hi For various reasons too dull to go into I have been trying to write
>csv files from R with very long filenames.  However R doesn't seem to
>like my doing this, but it is not clear to me what the maximum filename
>size is, and I can't find the info on the net.  I believe that the
>maximum pathname is 255 characters but is that the same thing?
>
>Thanks if anyone can enlighten me
>
>Nick Wray
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From drj|m|emon @end|ng |rom gm@||@com  Thu Jun 28 00:48:21 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Thu, 28 Jun 2018 08:48:21 +1000
Subject: [R] How long can a csv file label be?
In-Reply-To: <1066236676.882891.1530138819259@mail2.virginmedia.com>
References: <1066236676.882891.1530138819259@mail2.virginmedia.com>
Message-ID: <CA+8X3fWPZ9QCV918XL0v2UURFQfnG3bF1G_0xcv1T-0nimvEdw@mail.gmail.com>

Hi Nick,
You are probably using Windows, for which the maximum path length is
claimed to be 260 characters. The most common alternative, Linux, has
a maximum filename length of 255 and a maximum path length of 4096. If
you are simply writing a file to the current path, it won't make much
difference.

Jim

On Thu, Jun 28, 2018 at 8:33 AM, Nick Wray via R-help
<r-help at r-project.org> wrote:
> Hi For various reasons too dull to go into I have been trying to write csv files from R with very long filenames.  However R doesn't seem to like my doing this, but it is not clear to me what the maximum filename size is, and I can't find the info on the net.  I believe that the maximum pathname is 255 characters but is that the same thing?
>
> Thanks if anyone can enlighten me
>
> Nick Wray
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Thu Jun 28 00:56:09 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Wed, 27 Jun 2018 15:56:09 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
Message-ID: <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>

Thanks, Jeff. The Task View page was very informative.

To answer your question, I'm using ggplot to generate my plots and grid/gridExtra/gtable to place those plots on a page. 

Considering that there are ways to add text on a page through textGrobs, independent of the plots, I was wondering if there was a similar functionality for adding lines. Also noticed a package called pagenum for adding page numbers. 

knitr is certainly interesting, but might be an overkill for what I am trying to do (creating basic multipage reports with basic headers, footers). 




On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <jdnewmil at dcn.davis.ca.us> wrote:
>That would depend how you are generating the page... plots alone don't
>really have such options. If you don't know what this means then I
>suggest you read the Reproducible Research Task View [1]. knitr in
>conjunction with LaTeX (Rnw files) is very powerful, but there are many
>other tools as well (e.g. bookdown) depending on your preferences.
>
>[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
>
>On June 27, 2018 1:53:58 PM PDT, Stats Student
><stats.student4647 at gmail.com> wrote:
>>Hi, I'm looking for a way to add lines to a report. To be clear, I
>>don't want to add lines to any specific plot, but instead to add
>>line(s) to the page itself - e.g. add a line to the footer area, above
>>the actual footer text. 
>>
>>Any thoughts on how to do this? Many thanks.
>>
>>______________________________________________
>>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>>https://stat.ethz.ch/mailman/listinfo/r-help
>>PLEASE do read the posting guide
>>http://www.R-project.org/posting-guide.html
>>and provide commented, minimal, self-contained, reproducible code.
>
>-- 
>Sent from my phone. Please excuse my brevity.



From n|cho|@@@wr@y @end|ng |rom nt|wor|d@com  Thu Jun 28 00:58:01 2018
From: n|cho|@@@wr@y @end|ng |rom nt|wor|d@com (Nick Wray)
Date: Wed, 27 Jun 2018 23:58:01 +0100 (BST)
Subject: [R] How long can a csv file label be?
In-Reply-To: <CA+8X3fWPZ9QCV918XL0v2UURFQfnG3bF1G_0xcv1T-0nimvEdw@mail.gmail.com>
References: <1066236676.882891.1530138819259@mail2.virginmedia.com>
 <CA+8X3fWPZ9QCV918XL0v2UURFQfnG3bF1G_0xcv1T-0nimvEdw@mail.gmail.com>
Message-ID: <829245353.883175.1530140281580@mail2.virginmedia.com>

Thanks Jim

> On 27 June 2018 at 23:48 Jim Lemon <drjimlemon at gmail.com> wrote:
>
>
> Hi Nick,
> You are probably using Windows, for which the maximum path length is
> claimed to be 260 characters. The most common alternative, Linux, has
> a maximum filename length of 255 and a maximum path length of 4096. If
> you are simply writing a file to the current path, it won't make much
> difference.
>
> Jim
>
> On Thu, Jun 28, 2018 at 8:33 AM, Nick Wray via R-help
> <r-help at r-project.org> wrote:
> > Hi For various reasons too dull to go into I have been trying to write csv files from R with very long filenames. However R doesn't seem to like my doing this, but it is not clear to me what the maximum filename size is, and I can't find the info on the net. I believe that the maximum pathname is 255 characters but is that the same thing?
> >
> > Thanks if anyone can enlighten me
> >
> > Nick Wray
> > [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.

	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun 28 01:38:07 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 27 Jun 2018 16:38:07 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
 <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
Message-ID: <CAGxFJbQez+SMgH_PP-qfjK2Y54TojdGRdF_Qye_Gg1WvMzraJw@mail.gmail.com>

"Considering that there are ways to add text on a page through textGrobs.."

... and the linesGrob() function would do the same for lines, no?

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 27, 2018 at 3:56 PM, Stats Student <stats.student4647 at gmail.com>
wrote:

> Thanks, Jeff. The Task View page was very informative.
>
> To answer your question, I'm using ggplot to generate my plots and
> grid/gridExtra/gtable to place those plots on a page.
>
> Considering that there are ways to add text on a page through textGrobs,
> independent of the plots, I was wondering if there was a similar
> functionality for adding lines. Also noticed a package called pagenum for
> adding page numbers.
>
> knitr is certainly interesting, but might be an overkill for what I am
> trying to do (creating basic multipage reports with basic headers,
> footers).
>
>
>
>
> On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> wrote:
> >That would depend how you are generating the page... plots alone don't
> >really have such options. If you don't know what this means then I
> >suggest you read the Reproducible Research Task View [1]. knitr in
> >conjunction with LaTeX (Rnw files) is very powerful, but there are many
> >other tools as well (e.g. bookdown) depending on your preferences.
> >
> >[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
> >
> >On June 27, 2018 1:53:58 PM PDT, Stats Student
> ><stats.student4647 at gmail.com> wrote:
> >>Hi, I'm looking for a way to add lines to a report. To be clear, I
> >>don't want to add lines to any specific plot, but instead to add
> >>line(s) to the page itself - e.g. add a line to the footer area, above
> >>the actual footer text.
> >>
> >>Any thoughts on how to do this? Many thanks.
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> >--
> >Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From rmh @end|ng |rom temp|e@edu  Thu Jun 28 01:45:10 2018
From: rmh @end|ng |rom temp|e@edu (Richard M. Heiberger)
Date: Wed, 27 Jun 2018 19:45:10 -0400
Subject: [R] Adding lines to the page
In-Reply-To: <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
 <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
Message-ID: <CAGx1TMAUO6vxP1D8OqdErV3c3fc+bxkqqKZZWn5vjCcD2hdXyw@mail.gmail.com>

See if the microplot package provides what you need.
The package help file and the vignette will get you started.
Microplot works with Hmisc::latex or with MS Word into either Word or HTML.

On Wed, Jun 27, 2018 at 19:04 Stats Student <stats.student4647 at gmail.com>
wrote:

> Thanks, Jeff. The Task View page was very informative.
>
> To answer your question, I'm using ggplot to generate my plots and
> grid/gridExtra/gtable to place those plots on a page.
>
> Considering that there are ways to add text on a page through textGrobs,
> independent of the plots, I was wondering if there was a similar
> functionality for adding lines. Also noticed a package called pagenum for
> adding page numbers.
>
> knitr is certainly interesting, but might be an overkill for what I am
> trying to do (creating basic multipage reports with basic headers,
> footers).
>
>
>
>
> On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <
> jdnewmil at dcn.davis.ca.us> wrote:
> >That would depend how you are generating the page... plots alone don't
> >really have such options. If you don't know what this means then I
> >suggest you read the Reproducible Research Task View [1]. knitr in
> >conjunction with LaTeX (Rnw files) is very powerful, but there are many
> >other tools as well (e.g. bookdown) depending on your preferences.
> >
> >[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
> >
> >On June 27, 2018 1:53:58 PM PDT, Stats Student
> ><stats.student4647 at gmail.com> wrote:
> >>Hi, I'm looking for a way to add lines to a report. To be clear, I
> >>don't want to add lines to any specific plot, but instead to add
> >>line(s) to the page itself - e.g. add a line to the footer area, above
> >>the actual footer text.
> >>
> >>Any thoughts on how to do this? Many thanks.
> >>
> >>______________________________________________
> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> >>https://stat.ethz.ch/mailman/listinfo/r-help
> >>PLEASE do read the posting guide
> >>http://www.R-project.org/posting-guide.html
> >>and provide commented, minimal, self-contained, reproducible code.
> >
> >--
> >Sent from my phone. Please excuse my brevity.
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide
> http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From je@n@@udu@@e@u @end|ng |rom y@hoo@|r  Wed Jun 27 22:42:47 2018
From: je@n@@udu@@e@u @end|ng |rom y@hoo@|r (audusseau jean)
Date: Wed, 27 Jun 2018 20:42:47 +0000 (UTC)
Subject: [R] r crossed nested random effects lme4
References: <768880710.5092604.1530132167533.ref@mail.yahoo.com>
Message-ID: <768880710.5092604.1530132167533@mail.yahoo.com>


I am new to this forum. I try to find the appropriate model for the following data set with lme4:

Each individual subject goes through 3 conditions ("Group", within-subject factor). These 3 conditions include 9 items (3 items in each condition, but the items differ in each condition). Score (4th column not represented above) is a continuous dependant variable (reaction time).I am interested in the fixed effect of the "Cond" variable and also would like to take into account the dependencies between my factors, but I have difficulties to know if my factors should be considered as nested or crossed.Does the following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any help would be much appreciated.
-------------- next part --------------
A non-text attachment was scrubbed...
Name: 1530132091008blob.jpg
Type: image/png
Size: 13883 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-help/attachments/20180627/7bcffd6c/attachment-0002.png>

From bgunter@4567 @end|ng |rom gm@||@com  Thu Jun 28 03:48:08 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Wed, 27 Jun 2018 18:48:08 -0700
Subject: [R] r crossed nested random effects lme4
In-Reply-To: <768880710.5092604.1530132167533@mail.yahoo.com>
References: <768880710.5092604.1530132167533.ref@mail.yahoo.com>
 <768880710.5092604.1530132167533@mail.yahoo.com>
Message-ID: <CAGxFJbTPGts25RW4n+p01N1Qsmn-ki0BWZ7fhkR0+DgGJ60pPg@mail.gmail.com>

Generally speaking, purely statistical issues are off topic on this forum,
which is about programming in the R language. More to the point, the
r-sig-mixed-models forum is concerned with questions about mixed effects
models, so you should post there.

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Wed, Jun 27, 2018 at 1:42 PM, audusseau jean via R-help <
r-help at r-project.org> wrote:

>
> I am new to this forum. I try to find the appropriate model for the
> following data set with lme4:
>
> Each individual subject goes through 3 conditions ("Group", within-subject
> factor). These 3 conditions include 9 items (3 items in each condition, but
> the items differ in each condition). Score (4th column not represented
> above) is a continuous dependant variable (reaction time).I am interested
> in the fixed effect of the "Cond" variable and also would like to take into
> account the dependencies between my factors, but I have difficulties to
> know if my factors should be considered as nested or crossed.Does the
> following model seems correct to you ?Score~1+Cond+(1|Subject)+(1|item).Any
> help would be much appreciated.
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>
>

	[[alternative HTML version deleted]]



From m|korym @end|ng |rom protonm@||@com  Thu Jun 28 10:56:26 2018
From: m|korym @end|ng |rom protonm@||@com (mikorym)
Date: Thu, 28 Jun 2018 04:56:26 -0400
Subject: [R] R examples in Agronomy
Message-ID: <v6iRc6_t8x0yGPVeokJiP57xyBJIjbdrk-GAYPZzb7Rcq5XTvh7Xq3AH3y9Epp14-Y0UanqHVBRzgVlxG5TCybev6Fh8pa5LXBL_pLl1xLY=@protonmail.com>

> Dear all,
> Are there good R stat examples in the field of agronomy (especially field experiments)?
> Thanks
> ----------------------------------------/-----------------------------------------
> Khaled IBRAHIMI, PhD
> Assistant Professor, Soil Science & Environment
> Higher Institute of Agricultural Sciences of Chott-Mariem
> The University of Sousse, Tunisia
> Tel.: 216 97 276 835
> Email: ibrahimi.is... at gmail.com

I apologise preemptively if this reply messes up the formatting.

Hi Khaled

If your data has a lot of (possibly correlated) parameters, then I would
suggest to look at ade4. 

The main tool behind this package is Principal Component Analysis (PCA) and
although aimed at ecological data, there are specific applications to
agronomical contexts, such as: soil and leaf analyses; market price analyses
or yield analyses; dimensionality reduction of the weather component; and
several other types of possible agronomy related data contexts.

There are other packages for PCA as well, but I don't think they were
specifically aimed at a biological context.

If you are looking for specific papers on this, I would recommend as a
starting point any paper by Patrice Cadet. Or, if you have specific
questions, you are welcome to ask me.

Best regards
Phillip

Phillip-Jan van Zyl
MSc (Category Theory)



From tr|@podd@r19 @end|ng |rom gm@||@com  Thu Jun 28 11:45:12 2018
From: tr|@podd@r19 @end|ng |rom gm@||@com (Triparna Poddar)
Date: Thu, 28 Jun 2018 15:15:12 +0530
Subject: [R] CARET PACKAGE - PENALISED MULTINOMIAL REGRESSION MODEL
Message-ID: <CAOQsHG+bZrxoQSFO=F8DpwKr_nrtEGP3sqzskuSN==H6BDf5Gw@mail.gmail.com>

Hi,
     In the Caret package, in one of the training model method for
classification , penalised multinomial regression has been used? I could
not find anywhere how the penalised parameters have been chosen here . I
need the statistical methods that have been used. Can someone please help
me?

Thanks in advance.

	[[alternative HTML version deleted]]



From @t@t@@@tudent4647 @end|ng |rom gm@||@com  Thu Jun 28 15:24:42 2018
From: @t@t@@@tudent4647 @end|ng |rom gm@||@com (Stats Student)
Date: Thu, 28 Jun 2018 06:24:42 -0700
Subject: [R] Adding lines to the page
In-Reply-To: <CAGxFJbQez+SMgH_PP-qfjK2Y54TojdGRdF_Qye_Gg1WvMzraJw@mail.gmail.com>
References: <d715de2d-03a3-4395-bf27-59606f94ed2b@gmail.com>
 <BC8D52A3-CB90-4347-B39E-0C52B21E2D5F@dcn.davis.ca.us>
 <d5415e8b-75e2-4bbe-97d2-568c7160ce1b@gmail.com>
 <CAGxFJbQez+SMgH_PP-qfjK2Y54TojdGRdF_Qye_Gg1WvMzraJw@mail.gmail.com>
Message-ID: <CAMZO7w+Khpqa=ohXffTad6VmJ8c_os2xUnAvBwPO7wy5XTCpig@mail.gmail.com>

Didn't know about linesGrob(). Thanks



On Wed, Jun 27, 2018, 4:38 PM Bert Gunter <bgunter.4567 at gmail.com> wrote:

> "Considering that there are ways to add text on a page through textGrobs.."
>
> ... and the linesGrob() function would do the same for lines, no?
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along and
> sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Wed, Jun 27, 2018 at 3:56 PM, Stats Student <
> stats.student4647 at gmail.com> wrote:
>
>> Thanks, Jeff. The Task View page was very informative.
>>
>> To answer your question, I'm using ggplot to generate my plots and
>> grid/gridExtra/gtable to place those plots on a page.
>>
>> Considering that there are ways to add text on a page through textGrobs,
>> independent of the plots, I was wondering if there was a similar
>> functionality for adding lines. Also noticed a package called pagenum for
>> adding page numbers.
>>
>> knitr is certainly interesting, but might be an overkill for what I am
>> trying to do (creating basic multipage reports with basic headers,
>> footers).
>>
>>
>>
>>
>> On Jun 27, 2018, 2:07 PM, at 2:07 PM, Jeff Newmiller <
>> jdnewmil at dcn.davis.ca.us> wrote:
>> >That would depend how you are generating the page... plots alone don't
>> >really have such options. If you don't know what this means then I
>> >suggest you read the Reproducible Research Task View [1]. knitr in
>> >conjunction with LaTeX (Rnw files) is very powerful, but there are many
>> >other tools as well (e.g. bookdown) depending on your preferences.
>> >
>> >[1] https://cran.r-project.org/web/views/ReproducibleResearch.html
>> >
>> >On June 27, 2018 1:53:58 PM PDT, Stats Student
>> ><stats.student4647 at gmail.com> wrote:
>> >>Hi, I'm looking for a way to add lines to a report. To be clear, I
>> >>don't want to add lines to any specific plot, but instead to add
>> >>line(s) to the page itself - e.g. add a line to the footer area, above
>> >>the actual footer text.
>> >>
>> >>Any thoughts on how to do this? Many thanks.
>> >>
>> >>______________________________________________
>> >>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> >>https://stat.ethz.ch/mailman/listinfo/r-help
>> >>PLEASE do read the posting guide
>> >>http://www.R-project.org/posting-guide.html
>> >>and provide commented, minimal, self-contained, reproducible code.
>> >
>> >--
>> >Sent from my phone. Please excuse my brevity.
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>>
>
>

	[[alternative HTML version deleted]]



From jte||er|@@rproject @end|ng |rom gm@||@com  Thu Jun 28 18:52:17 2018
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Thu, 28 Jun 2018 18:52:17 +0200
Subject: [R] parallel computing in r....
In-Reply-To: <9479A978-896B-45F4-8DBF-C769B8BEFAF4@dcn.davis.ca.us>
References: <SL2P216MB00910EF5445FCCE42E0B2B02C8750@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <9479A978-896B-45F4-8DBF-C769B8BEFAF4@dcn.davis.ca.us>
Message-ID: <CAJXDcw1G6WKuZvzZiOky+9r4v4UtYpT-zS=Os_rMu0dY6_OyAw@mail.gmail.com>

Maybe this R-bloggers post could also help you:

https://www.google.es/amp/s/www.r-bloggers.com/implementing-parallel-processing-in-r/amp/

https://www.google.es/amp/s/www.r-bloggers.com/a-guide-to-parallelism-in-r/amp/

	[[alternative HTML version deleted]]



From jte||er|@@rproject @end|ng |rom gm@||@com  Thu Jun 28 19:01:55 2018
From: jte||er|@@rproject @end|ng |rom gm@||@com (Juan Telleria Ruiz de Aguirre)
Date: Thu, 28 Jun 2018 19:01:55 +0200
Subject: [R] Trouble with tibbles
In-Reply-To: <1387723f-be10-5b3d-4047-5cc03041786e@utoronto.ca>
References: <1387723f-be10-5b3d-4047-5cc03041786e@utoronto.ca>
Message-ID: <CAJXDcw04hjiH8NEzdH+oMDBgNoz2Li3YhcQniH4Hwo+T0C8W8g@mail.gmail.com>

Factor Data Type, indeed, is of typeof() Numeric.

Try converting that column to character with as.character()

Class transformation then must work :)

Juan

	[[alternative HTML version deleted]]



From ton|ght@then|ght @end|ng |rom gm@||@com  Thu Jun 28 19:58:13 2018
From: ton|ght@then|ght @end|ng |rom gm@||@com (Sam Albers)
Date: Thu, 28 Jun 2018 10:58:13 -0700
Subject: [R] Unable to return gmtoff from as.POSIXlt without converting date
 string to as.POSIXct first
Message-ID: <CADkXsV1=k28MhK9tGW7on3FnTfGSUjiwc3GJTD9HAxznCE3N1A@mail.gmail.com>

Is it possible for someone to explain what is going on here? I would expect
that `as.POSIXlt` would be able to accept `datestring` and return all the
elements without having to convert it using `as.POSIXct` first. Do
`as.POSIXlt` and `as.POSIXct` do different things with the `tz` arg?

datestring <- "2017-01-01 12:00:00"
foo <- as.POSIXlt(datestring, tz = "America/Moncton")
foo
[1] "2017-01-01 12:00:00 AST"
foo$gmtoff
[1] NA

bar <- as.POSIXlt(as.POSIXct(datestring, tz = "America/Moncton"))
bar
[1] "2017-01-01 12:00:00 AST"
bar$gmtoff
[1] -14400

Thanks in advance,

Sam

	[[alternative HTML version deleted]]



From kekwu @end|ng |rom ucd@v|@@edu  Thu Jun 28 21:53:44 2018
From: kekwu @end|ng |rom ucd@v|@@edu (Kelly Wu)
Date: Thu, 28 Jun 2018 12:53:44 -0700
Subject: [R] trouble with exiting loop if condition is met
Message-ID: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>

I am working on a clinical trial simulation with two groups, treatment and
placebo, and the outcome is dichotomous (recovery or no recovery) . I would
like to stop my loop if either of my conditions are met:

1) futility - there are no responses to treatment in the treatment group.
2) the p-value is significant (<=0.01).

The problem I am having is my loop continues to run 10,000 times even though
I am sure that at least one of the conditions are met in some instances. It
appears the main problem is that my if loop is not adequately filtering the
conditions I specified in it.

library(magrittr)
library(dplyr)

nSims <- 10000 #number of simulated experiments
futility1 <-numeric(nSims) #set up empty container for all simulated
futility
futility2 <-numeric(nSims) #set up empty container for all simulated
futility

significant1 <-numeric(nSims) #set up empty container for all simulated
significance
significant2 <-numeric(nSims) #set up empty container for all simulated
significance

for(i in 1:nSims){ #for each simulated experiment
 # Year 1

 # p1<-response in controls
 # p2<-response in treated
 # Generating random deviates from a Uniform(0,1) distribution
 control.year1<-(runif(16, min = 0, max = 1))
 treat.year1<-(runif(16, min = 0, max = 1))

 #Generating dichotomous response variables for each group
 control.respond1<-ifelse(control.year1<=0.05,1,0)
 treat.respond1<-ifelse(treat.year1<=0.30,1,0)

 #Summing number of responses from each group
 control.no1<-sum(control.respond1==0)
 control.yes1<-sum(control.respond1==1)
 treat.no1<-sum(treat.respond1==0)
 treat.yes1<-sum(treat.respond1==1)

 #Perform the Fisher's exact test (one sided) with p<0.01

fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
 f<-fisher.test(fisher,alternative = "greater") 

 #year 2
 if (f$p.value>0.01 && treat.yes1!=0){
   # Generating random deviates from a Uniform(0,1) distribution
   control.year2<-(runif(16, min = 0, max = 1))
   treat.year2<-(runif(16, min = 0, max = 1))

   #Generating dichotomous response variables for each group
   control.respond2<-ifelse(control.year2<=0.05,1,0)
   treat.respond2<-ifelse(treat.year2<=0.30,1,0)

   #Summing number of responses from each group
   control.no2<-sum(control.respond2==0)
   control.yes2<-sum(control.respond2==1)
   treat.no2<-sum(treat.respond2==0)
   treat.yes2<-sum(treat.respond2==1)

   #Perform the Fisher's exact test (one sided) with p<0.01

fisher2<-matrix(c(control.no2,control.yes2,treat.no2,treat.yes2),nrow=2,ncol=2)
   f2<-fisher.test(fisher2,alternative = "greater") 
 }


 significant2[i]<-ifelse(f2$p.value<0.01,1,0)
 futility2[i]<-ifelse(treat.yes2==0,1,0)
}

table(significant1)
table(futility1)

table(significant2)
table(futility2)



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Thu Jun 28 23:29:19 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 28 Jun 2018 16:29:19 -0500
Subject: [R] Plot Rect Transparency
Message-ID: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>

R-Help

 

Is there a way to make a rectangle transparent (alpha=0.1??)

 

  plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")

   rect(110, 300, 175, 350, density = 5, border = "red")

 

Can't figure out how to take the changepoint function results and plot in
ggplot2 so I can just simply add rectangles to the plot function, but I need
to make transparent and there doesn't seem to be an alpha option.

 

Jeff


	[[alternative HTML version deleted]]



From m@cqueen1 @end|ng |rom ||n|@gov  Thu Jun 28 23:45:52 2018
From: m@cqueen1 @end|ng |rom ||n|@gov (MacQueen, Don)
Date: Thu, 28 Jun 2018 21:45:52 +0000
Subject: [R] trouble with exiting loop if condition is met
In-Reply-To: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
References: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
Message-ID: <A3B1205D-BA6B-4DB8-A15F-B5FAF923F68A@llnl.gov>

Does this example help?

> for (ii in 1:10) { cat( ii,'\n') ; if (ii >3) break }
1 
2 
3 
4

The loop won't stop unless you tell it to stop, and I don't see any place where you told it to stop.

--
Don MacQueen
Lawrence Livermore National Laboratory
7000 East Ave., L-627
Livermore, CA 94550
925-423-1062
Lab cell 925-724-7509
 
 

?On 6/28/18, 12:53 PM, "R-help on behalf of Kelly Wu" <r-help-bounces at r-project.org on behalf of kekwu at ucdavis.edu> wrote:

    I am working on a clinical trial simulation with two groups, treatment and
    placebo, and the outcome is dichotomous (recovery or no recovery) . I would
    like to stop my loop if either of my conditions are met:
    
    1) futility - there are no responses to treatment in the treatment group.
    2) the p-value is significant (<=0.01).
    
    The problem I am having is my loop continues to run 10,000 times even though
    I am sure that at least one of the conditions are met in some instances. It
    appears the main problem is that my if loop is not adequately filtering the
    conditions I specified in it.
    
    library(magrittr)
    library(dplyr)
    
    nSims <- 10000 #number of simulated experiments
    futility1 <-numeric(nSims) #set up empty container for all simulated
    futility
    futility2 <-numeric(nSims) #set up empty container for all simulated
    futility
    
    significant1 <-numeric(nSims) #set up empty container for all simulated
    significance
    significant2 <-numeric(nSims) #set up empty container for all simulated
    significance
    
    for(i in 1:nSims){ #for each simulated experiment
     # Year 1
    
     # p1<-response in controls
     # p2<-response in treated
     # Generating random deviates from a Uniform(0,1) distribution
     control.year1<-(runif(16, min = 0, max = 1))
     treat.year1<-(runif(16, min = 0, max = 1))
    
     #Generating dichotomous response variables for each group
     control.respond1<-ifelse(control.year1<=0.05,1,0)
     treat.respond1<-ifelse(treat.year1<=0.30,1,0)
    
     #Summing number of responses from each group
     control.no1<-sum(control.respond1==0)
     control.yes1<-sum(control.respond1==1)
     treat.no1<-sum(treat.respond1==0)
     treat.yes1<-sum(treat.respond1==1)
    
     #Perform the Fisher's exact test (one sided) with p<0.01
    
    fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
     f<-fisher.test(fisher,alternative = "greater") 
    
     #year 2
     if (f$p.value>0.01 && treat.yes1!=0){
       # Generating random deviates from a Uniform(0,1) distribution
       control.year2<-(runif(16, min = 0, max = 1))
       treat.year2<-(runif(16, min = 0, max = 1))
    
       #Generating dichotomous response variables for each group
       control.respond2<-ifelse(control.year2<=0.05,1,0)
       treat.respond2<-ifelse(treat.year2<=0.30,1,0)
    
       #Summing number of responses from each group
       control.no2<-sum(control.respond2==0)
       control.yes2<-sum(control.respond2==1)
       treat.no2<-sum(treat.respond2==0)
       treat.yes2<-sum(treat.respond2==1)
    
       #Perform the Fisher's exact test (one sided) with p<0.01
    
    fisher2<-matrix(c(control.no2,control.yes2,treat.no2,treat.yes2),nrow=2,ncol=2)
       f2<-fisher.test(fisher2,alternative = "greater") 
     }
    
    
     significant2[i]<-ifelse(f2$p.value<0.01,1,0)
     futility2[i]<-ifelse(treat.yes2==0,1,0)
    }
    
    table(significant1)
    table(futility1)
    
    table(significant2)
    table(futility2)
    
    ______________________________________________
    R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
    https://stat.ethz.ch/mailman/listinfo/r-help
    PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
    and provide commented, minimal, self-contained, reproducible code.
    


From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun 29 00:16:30 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Thu, 28 Jun 2018 15:16:30 -0700
Subject: [R] 
 Unable to return gmtoff from as.POSIXlt without converting date
 string to as.POSIXct first
In-Reply-To: <CADkXsV1=k28MhK9tGW7on3FnTfGSUjiwc3GJTD9HAxznCE3N1A@mail.gmail.com>
References: <CADkXsV1=k28MhK9tGW7on3FnTfGSUjiwc3GJTD9HAxznCE3N1A@mail.gmail.com>
Message-ID: <A78DF603-7F6C-4445-AC81-71DC7A0E2777@dcn.davis.ca.us>

Read

?DateTimeClasses

regarding gmtoff. In short, it is implementation-dependent.

On June 28, 2018 10:58:13 AM PDT, Sam Albers <tonightsthenight at gmail.com> wrote:
>Is it possible for someone to explain what is going on here? I would
>expect
>that `as.POSIXlt` would be able to accept `datestring` and return all
>the
>elements without having to convert it using `as.POSIXct` first. Do
>`as.POSIXlt` and `as.POSIXct` do different things with the `tz` arg?
>
>datestring <- "2017-01-01 12:00:00"
>foo <- as.POSIXlt(datestring, tz = "America/Moncton")
>foo
>[1] "2017-01-01 12:00:00 AST"
>foo$gmtoff
>[1] NA
>
>bar <- as.POSIXlt(as.POSIXct(datestring, tz = "America/Moncton"))
>bar
>[1] "2017-01-01 12:00:00 AST"
>bar$gmtoff
>[1] -14400
>
>Thanks in advance,
>
>Sam
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From drj|m|emon @end|ng |rom gm@||@com  Fri Jun 29 00:18:41 2018
From: drj|m|emon @end|ng |rom gm@||@com (Jim Lemon)
Date: Fri, 29 Jun 2018 08:18:41 +1000
Subject: [R] trouble with exiting loop if condition is met
In-Reply-To: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
References: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
Message-ID: <CA+8X3fXg4B3cuyHv4wAJGPjgoFCNymptBH5Sn+z2Dy7_VXCRDg@mail.gmail.com>

Hi Kelly,
You seem to be testing the two "years" independently, so here is a
possible solution:

npg<-16
futility1<-futility2<-psignif1<-psignif2<-nrep<-0
while(!futility1 && !futility2 && !psignif1 && !psignif2 && nrep < 10000) {
 control_respond1<-sum(runif(npg,0,1) < 0.05)
 control_respond2<-sum(runif(npg,0,1) < 0.05)
 treat_respond1<-sum(runif(npg,0,1) < 0.3)
 treat_respond2<-sum(runif(npg,0,1) < 0.3)
 futility1<-treat_respond1 == 0
 futility2<-treat_respond2 == 0
 psignif1<-fisher.test(matrix(c(control_respond1,npg-control_respond1,
  treat_respond1,npg-treat_respond1),nrow=2),
  alternative="greater")$p.value < 0.01
 psignif2<-fisher.test(matrix(c(control_respond2,npg-control_respond2,
  treat_respond2,npg-treat_respond2),nrow=2),
  alternative="greater")$p.value < 0.01
 nrep<-nrep+1
}
cat("futility1",futility1,"futility2",futility2,"psignif1",psignif1,
 "psignif2",psignif2,"nrep",nrep,"\n")

The output tells you which condition was met and on which repetition
it occurred. The outcomes for all previous repetitions will be FALSE
and for the remaining repetitions, undefined (unless you have a cat
named Schrodinger)..

If you want to test the two "years" as sequential observations, it
will only require a minor modification.

Jim

On Fri, Jun 29, 2018 at 5:53 AM, Kelly Wu <kekwu at ucdavis.edu> wrote:
> I am working on a clinical trial simulation with two groups, treatment and
> placebo, and the outcome is dichotomous (recovery or no recovery) . I would
> like to stop my loop if either of my conditions are met:
>
> 1) futility - there are no responses to treatment in the treatment group.
> 2) the p-value is significant (<=0.01).
>
> The problem I am having is my loop continues to run 10,000 times even though
> I am sure that at least one of the conditions are met in some instances. It
> appears the main problem is that my if loop is not adequately filtering the
> conditions I specified in it.
>
> library(magrittr)
> library(dplyr)
>
> nSims <- 10000 #number of simulated experiments
> futility1 <-numeric(nSims) #set up empty container for all simulated
> futility
> futility2 <-numeric(nSims) #set up empty container for all simulated
> futility
>
> significant1 <-numeric(nSims) #set up empty container for all simulated
> significance
> significant2 <-numeric(nSims) #set up empty container for all simulated
> significance
>
> for(i in 1:nSims){ #for each simulated experiment
>  # Year 1
>
>  # p1<-response in controls
>  # p2<-response in treated
>  # Generating random deviates from a Uniform(0,1) distribution
>  control.year1<-(runif(16, min = 0, max = 1))
>  treat.year1<-(runif(16, min = 0, max = 1))
>
>  #Generating dichotomous response variables for each group
>  control.respond1<-ifelse(control.year1<=0.05,1,0)
>  treat.respond1<-ifelse(treat.year1<=0.30,1,0)
>
>  #Summing number of responses from each group
>  control.no1<-sum(control.respond1==0)
>  control.yes1<-sum(control.respond1==1)
>  treat.no1<-sum(treat.respond1==0)
>  treat.yes1<-sum(treat.respond1==1)
>
>  #Perform the Fisher's exact test (one sided) with p<0.01
>
> fisher<-matrix(c(control.no1,control.yes1,treat.no1,treat.yes1),nrow=2,ncol=2)
>  f<-fisher.test(fisher,alternative = "greater")
>
>  #year 2
>  if (f$p.value>0.01 && treat.yes1!=0){
>    # Generating random deviates from a Uniform(0,1) distribution
>    control.year2<-(runif(16, min = 0, max = 1))
>    treat.year2<-(runif(16, min = 0, max = 1))
>
>    #Generating dichotomous response variables for each group
>    control.respond2<-ifelse(control.year2<=0.05,1,0)
>    treat.respond2<-ifelse(treat.year2<=0.30,1,0)
>
>    #Summing number of responses from each group
>    control.no2<-sum(control.respond2==0)
>    control.yes2<-sum(control.respond2==1)
>    treat.no2<-sum(treat.respond2==0)
>    treat.yes2<-sum(treat.respond2==1)
>
>    #Perform the Fisher's exact test (one sided) with p<0.01
>
> fisher2<-matrix(c(control.no2,control.yes2,treat.no2,treat.yes2),nrow=2,ncol=2)
>    f2<-fisher.test(fisher2,alternative = "greater")
>  }
>
>
>  significant2[i]<-ifelse(f2$p.value<0.01,1,0)
>  futility2[i]<-ifelse(treat.yes2==0,1,0)
> }
>
> table(significant1)
> table(futility1)
>
> table(significant2)
> table(futility2)
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.



From murdoch@dunc@n @end|ng |rom gm@||@com  Fri Jun 29 02:57:19 2018
From: murdoch@dunc@n @end|ng |rom gm@||@com (Duncan Murdoch)
Date: Thu, 28 Jun 2018 20:57:19 -0400
Subject: [R] Plot Rect Transparency
In-Reply-To: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
References: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
Message-ID: <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>

On 28/06/2018 5:29 PM, Jeff Reichman wrote:
> R-Help
> 
>   
> 
> Is there a way to make a rectangle transparent (alpha=0.1??)
> 
>   
> 
>    plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")
> 
>     rect(110, 300, 175, 350, density = 5, border = "red")
> 
>   
> 
> Can't figure out how to take the changepoint function results and plot in
> ggplot2 so I can just simply add rectangles to the plot function, but I need
> to make transparent and there doesn't seem to be an alpha option.

Alpha is part of the colour spec.  For example,

rect(110, 300, 175, 350, density = 5, border = rgb("red")


rect(110, 300, 175, 350, density = 5, border = rgb(red=1, green=0, 
blue=0, alpha=0.1))

I'm not sure what is the quickest way to work out the rgb values for a 
named colour (col2rgb can do it, but not in a convenient format) if you 
want to add alpha to it.

Duncan Murdoch



From re|chm@nj @end|ng |rom @bcg|ob@|@net  Fri Jun 29 04:03:31 2018
From: re|chm@nj @end|ng |rom @bcg|ob@|@net (Jeff Reichman)
Date: Thu, 28 Jun 2018 21:03:31 -0500
Subject: [R] Plot Rect Transparency
In-Reply-To: <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
References: <000001d40f27$13ce5ee0$3b6b1ca0$@sbcglobal.net>
 <5a829f35-ee02-8ff7-bd84-cd07ea55caec@gmail.com>
Message-ID: <000a01d40f4d$617d3140$247793c0$@sbcglobal.net>

Duncan 

Thanks I was able to find it in the help doc.

x <- c(1,2,4,6,8,9,10,12,13,14,18,20)
y <- c(4,5,3,6,7,4,8,9,12,4,7,5)

mydata <- data.frame(x,y)

plot(mydata)
rect(5,0,8,8, col=rgb(0,1,0,alpha=0.2), border=F)

-----Original Message-----
From: Duncan Murdoch <murdoch.duncan at gmail.com> 
Sent: Thursday, June 28, 2018 7:57 PM
To: reichmanj at sbcglobal.net; R-help at r-project.org
Subject: Re: [R] Plot Rect Transparency

On 28/06/2018 5:29 PM, Jeff Reichman wrote:
> R-Help
> 
>   
> 
> Is there a way to make a rectangle transparent (alpha=0.1??)
> 
>   
> 
>    plot(c(100, 200), c(300, 450), type= "n", xlab = "", ylab = "")
> 
>     rect(110, 300, 175, 350, density = 5, border = "red")
> 
>   
> 
> Can't figure out how to take the changepoint function results and plot 
> in
> ggplot2 so I can just simply add rectangles to the plot function, but 
> I need to make transparent and there doesn't seem to be an alpha option.

Alpha is part of the colour spec.  For example,

rect(110, 300, 175, 350, density = 5, border = rgb("red")


rect(110, 300, 175, 350, density = 5, border = rgb(red=1, green=0, blue=0, alpha=0.1))

I'm not sure what is the quickest way to work out the rgb values for a named colour (col2rgb can do it, but not in a convenient format) if you want to add alpha to it.

Duncan Murdoch



From |r@@h@renow100 @end|ng |rom y@hoo@com  Fri Jun 29 08:36:23 2018
From: |r@@h@renow100 @end|ng |rom y@hoo@com (Ira Sharenow)
Date: Thu, 28 Jun 2018 23:36:23 -0700
Subject: [R] Convert list of data frames to one data frame
Message-ID: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>

I have a list of data frames which I would like to combine into one data 
frame doing something like rbind. I wish to combine in column order and 
not by names. However, there are issues.

The number of columns is not the same for each data frame. This is an 
intermediate step to a problem and the number of columns could be 
2,4,6,8,or10. There might be a few thousand data frames. Another problem 
is that the names of the columns produced by the first step are garbage.

Below is a method that I obtained by asking a question on stack 
overflow. Unfortunately, my example was not general enough. The code 
below works for the simple case where the names of the people are 
consistent. It does not work when the names are realistically not the same.

https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432 


Please note that the lapply step sets things up except for the column 
name issue. If I could figure out a way to change the column names, then 
the bind_rows step will, I believe, work.

So I really have two questions. How to change all column names of all 
the data frames and then how to solve the original problem.

# The non general case works fine. It produces one data frame and I can 
then change the column names to

# c("first1", "last1","first2", "last2","first3", "last3",)

#Non general easy case

employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),

data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),

data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones", 
"Smith", "Adams")),

data.frame(first1 = ("Al"), second1 = "Jones"))

employees4BList

bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))

# This produces a nice list of data frames, except for the names

lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))

# This list is a disaster. I am looking for a solution that works in 
this case.

employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),

data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),

data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones", 
"Smith", "Adams")),

data.frame(first4 = ("Al"), second4 = "Jones2"))

 ?bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))

Thanks.

Ira


	[[alternative HTML version deleted]]



From m|@thour| @end|ng |rom y@hoo@gr  Fri Jun 29 12:01:37 2018
From: m|@thour| @end|ng |rom y@hoo@gr (Maria Lathouri)
Date: Fri, 29 Jun 2018 10:01:37 +0000 (UTC)
Subject: [R] =?utf-8?b?zqPPh861z4Q6IHgtYXhpcyB0aWNrIG1hcmtzIGxlbmd0aCBp?=
 =?utf-8?q?n_ggplot2?=
In-Reply-To: <CALe7saLmjnDtGoJ6go6NB+NGx82RLNsTWwCdF9uZmh6sHyLLQw@mail.gmail.com>
References: <1894507928.4864388.1530116258439.ref@mail.yahoo.com>
 <1894507928.4864388.1530116258439@mail.yahoo.com>
 <CA+-dKdONv8Y+pWH42RU47YVccmtU_HOBAEnTkowdzUggjmi87g@mail.gmail.com>
 <624069206.5599815.1530185883999@mail.yahoo.com>
 <8316569.5602775.1530186534961@mail.yahoo.com>
 <CALe7saLmjnDtGoJ6go6NB+NGx82RLNsTWwCdF9uZmh6sHyLLQw@mail.gmail.com>
Message-ID: <1078453055.282011.1530266497799@mail.yahoo.com>

Dear Walter,?
I tried to use scale_x_continuous but the arguments that I found was to change the labels, the limits and the breaks. I was only able to increase the number of the tick marks.?
Best,Maria 

    ???? 3:14 ?.?. ??????, 28 ??????? 2018, ?/? Walter Pina <walter.pina1954 at gmail.com> ??????:
 

 Dear Maria, you are totally right!
Did you tried the scale_x_continuous function and its arguments?
RegardsWalter
2018-06-28 8:48 GMT-03:00 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com>:

Dear Abhimanyu, 

If I am not mistaken, this online help is to post questions, and if possible, these questions to be answered. NOT for sarcastic and insulting posts. You could have just easily ignored my question. So simple. ? ? 

Kind regards,Maria 

    ???? 12:38 ?.?. ??????, 28 ??????? 2018, ?/? Maria Lathouri <mlathouri at yahoo.gr> ??????:
 

 I am sorry but I didn't get your point. And I am not new in data science!!

Maria 

    ???? 11:38 ?.?. ??????, 28 ??????? 2018, ?/? Abhimanyu Khatry <khatryabhimanyu at gmail.com> ??????:
 

 How a beginner can get started on ggplot ? Is it right to start this if someone is new to data science ?
On Wed, Jun 27, 2018 at 9:47 PM, 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com> wrote:

Dear all, 


I would like to ask if there is a way to increase the length of the tick marks on the x-axis only. 


I got the code:

p+ theme(axis.ticks.length=unit(. 30, "cm"))

but this increases the length for both x and y axis; whereas, I would like only on x-axis. 


Thank you very much in advance. 


Kind regards,
Maria

-- 
-- 
You received this message because you are subscribed to the ggplot2 mailing list.
Please provide a reproducible example: https://github.com/hadley/ devtools/wiki/Reproducibility

To post: email ggplot2 at googlegroups.com
To unsubscribe: email ggplot2+unsubscribe@ googlegroups.com
More options: http://groups.google.com/ group/ggplot2

--- 
You received this message because you are subscribed to the Google Groups "ggplot2" group.
To unsubscribe from this group and stop receiving emails from it, send an email to ggplot2+unsubscribe@ googlegroups.com.
For more options, visit https://groups.google.com/d/ optout.


-- 
-- 
You received this message because you are subscribed to the ggplot2 mailing list.
Please provide a reproducible example: https://github.com/hadley/ devtools/wiki/Reproducibility
?
To post: email ggplot2 at googlegroups.com
To unsubscribe: email ggplot2+unsubscribe@ googlegroups.com
More options: http://groups.google.com/ group/ggplot2

--- 
You received this message because you are subscribed to the Google Groups "ggplot2" group.
To unsubscribe from this group and stop receiving emails from it, send an email to ggplot2+unsubscribe@ googlegroups.com.
For more options, visit https://groups.google.com/d/ optout.


   

   -- 
-- 
You received this message because you are subscribed to the ggplot2 mailing list.
Please provide a reproducible example: https://github.com/hadley/ devtools/wiki/Reproducibility
?
To post: email ggplot2 at googlegroups.com
To unsubscribe: email ggplot2+unsubscribe@ googlegroups.com
More options: http://groups.google.com/ group/ggplot2

--- 
You received this message because you are subscribed to the Google Groups "ggplot2" group.
To unsubscribe from this group and stop receiving emails from it, send an email to ggplot2+unsubscribe@ googlegroups.com.
For more options, visit https://groups.google.com/d/ optout.




   
	[[alternative HTML version deleted]]



From berw|n@tur|@ch @end|ng |rom gm@||@com  Fri Jun 29 12:29:25 2018
From: berw|n@tur|@ch @end|ng |rom gm@||@com (Berwin A Turlach)
Date: Fri, 29 Jun 2018 18:29:25 +0800
Subject: [R] Fwd: Quadratic programming, for loop
In-Reply-To: <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>
References: <CAJxz9NZtCd=wAEVy80Vm8-no4qM-ApVpHBjCqbqvfS+57MEj_w@mail.gmail.com>
 <CAJxz9NYhc1c_-zY5LfideTkYHBGE=fv++=_z4cuJW7xY13gj+g@mail.gmail.com>
 <FC12D5C5-EBFE-40A2-AE20-57191F90D25F@utoronto.ca>
 <CAJxz9Nbpxkm3PpM_yUSHypCgoeKatuH3=Q-Ar-zOA8mi6JZ7uQ@mail.gmail.com>
 <786D173F-D62D-4E6D-8774-D419B0D53105@utoronto.ca>
 <CAJxz9NayL=Xu95WTme5sBxTG_PNBCH3LQSXF0y4vVzT=EW60uA@mail.gmail.com>
 <20180626200136.115557ce@goodenia>
 <CAJxz9NYXLenNCeG5o8QZO3jnzdhDPJ5rZX3vgMQHJpKCx7sokg@mail.gmail.com>
Message-ID: <20180629182925.4606e7be@goodenia>

G'day Maija,

On Wed, 27 Jun 2018 08:48:08 +0300
Maija Sirkj?rvi <maija.sirkjarvi at gmail.com> wrote:

> Thanks for your reply! Unfortunately something is still wrong.
> 
> After the transpose, dvec and Amat are still incompatible.
> 
> > d <- -hsmooth
> > dvec <- t(d)
> > c <- dvec*Amat  
> Error in dvec * Amat : non-conformable arrays

'*' in R is element-wise multiplication and '%*%' implements
matrix/matrix (matrix/vector) multiplication as defined in matrix
algebra.  I presume you want to use the latter operator here.

> Moreover, I don't understand the following:
> 
> > If dvec is of length *J*, then b will be of length J too.  
> 
> I believe the length of dvec comes from the number of variables and
> the length of b from the number of constraints. In this case they are
> not equal.

As I said:

> > solve.QP solves the quadratic program:
> >          min(-d^T b + 1/2 b^T D b)
> >    where A^T b >= b_0.

The minimisation is with respect to b.

Note that the objective function contains the inner product of d
(passed to dvec) and b, so d and b must have the same
dimension/length.  b contains the parameters/variables over which you
want to minimise.  b_0 (passed to bvec) depends on the number of
constraints.

Cheers,

	Berwin



From @k@h@y_e4 @end|ng |rom hotm@||@com  Fri Jun 29 13:19:40 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Fri, 29 Jun 2018 11:19:40 +0000
Subject: [R] inconsistency in list subsetting in R in linux
Message-ID: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                           I am using GNU R(R in linux CLI). I am trying to debug a function called "grand.finalelPf". In the function the following line appears

> yhpf2 <- mclapply(LYG2[-w], fun = forecast, h = 1)

I execute the above line in browse[2] prompt. I then type the following:
Browse[2] > length(yhpf2)

It also is getting executed with the following output:
[1] 464

But when I type this:
Browse[2] > yhpf2[[3]]

the ouput is this:

[1] "Error in lapply(X = S, FUN = FUN, ...) : \n  argument \"FUN\" is missing, with no default\n"
attr(,"class")
[1] "try-error"
attr(,"condition")
<simpleError in lapply(X = S, FUN = FUN, ...): argument "FUN" is missing, with no default>
Browse[2] >

why is this getting outputted instead of a value? Even if all the yhpf's are NULL, the above is output is weird.

What is wrong? Why would the output relate to lapply? If the culprit was mclapply, then why does the line get executed without an error message? The same function is working perfectly well in windows(I used parLapply instead of mclapply).
Is this peculiar to R on Linux? Please help....

very many thanks for your time and effort,
Yours sincerely,
AKSHAY M KULKARNI


	[[alternative HTML version deleted]]



From wdun|@p @end|ng |rom t|bco@com  Fri Jun 29 15:51:36 2018
From: wdun|@p @end|ng |rom t|bco@com (William Dunlap)
Date: Fri, 29 Jun 2018 06:51:36 -0700
Subject: [R] inconsistency in list subsetting in R in linux
In-Reply-To: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAF8bMcbNuG4ah_2+-jy45R4U6fmnNN+24+Xcjs87OYB+ePd8Dg@mail.gmail.com>

> args(parallel::mclapply)
function (X, FUN, ..., mc.preschedule = TRUE, mc.set.seed = TRUE,
    mc.silent = FALSE, mc.cores = 1L, mc.cleanup = TRUE, mc.allow.recursive
= TRUE)

You gave it 'fun=forecast' instead of 'FUN=forecast'.  Case matters in R.

Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Fri, Jun 29, 2018 at 4:19 AM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                            I am using GNU R(R in linux CLI). I am trying
> to debug a function called "grand.finalelPf". In the function the following
> line appears
>
> > yhpf2 <- mclapply(LYG2[-w], fun = forecast, h = 1)
>
> I execute the above line in browse[2] prompt. I then type the following:
> Browse[2] > length(yhpf2)
>
> It also is getting executed with the following output:
> [1] 464
>
> But when I type this:
> Browse[2] > yhpf2[[3]]
>
> the ouput is this:
>
> [1] "Error in lapply(X = S, FUN = FUN, ...) : \n  argument \"FUN\" is
> missing, with no default\n"
> attr(,"class")
> [1] "try-error"
> attr(,"condition")
> <simpleError in lapply(X = S, FUN = FUN, ...): argument "FUN" is missing,
> with no default>
> Browse[2] >
>
> why is this getting outputted instead of a value? Even if all the yhpf's
> are NULL, the above is output is weird.
>
> What is wrong? Why would the output relate to lapply? If the culprit was
> mclapply, then why does the line get executed without an error message? The
> same function is working perfectly well in windows(I used parLapply instead
> of mclapply).
> Is this peculiar to R on Linux? Please help....
>
> very many thanks for your time and effort,
> Yours sincerely,
> AKSHAY M KULKARNI
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Fri Jun 29 16:02:40 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 29 Jun 2018 07:02:40 -0700
Subject: [R] inconsistency in list subsetting in R in linux
In-Reply-To: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB0091FD03E50494DA5F5989ADC84E0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <BA6D202C-C55F-4AF0-B848-BD2725157167@dcn.davis.ca.us>

Read the Value section of ?mclapply. That error is an encapsulated error from the forecast function.

I suggest not debugging your code running in parallel... temporarily replace mclapply with lapply to debug so you can step into your worker fictions. You may also want to temporarily reduce the volume of data you are working with.

On June 29, 2018 4:19:40 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>I am using GNU R(R in linux CLI). I am trying to debug a function
>called "grand.finalelPf". In the function the following line appears
>
>> yhpf2 <- mclapply(LYG2[-w], fun = forecast, h = 1)
>
>I execute the above line in browse[2] prompt. I then type the
>following:
>Browse[2] > length(yhpf2)
>
>It also is getting executed with the following output:
>[1] 464
>
>But when I type this:
>Browse[2] > yhpf2[[3]]
>
>the ouput is this:
>
>[1] "Error in lapply(X = S, FUN = FUN, ...) : \n  argument \"FUN\" is
>missing, with no default\n"
>attr(,"class")
>[1] "try-error"
>attr(,"condition")
><simpleError in lapply(X = S, FUN = FUN, ...): argument "FUN" is
>missing, with no default>
>Browse[2] >
>
>why is this getting outputted instead of a value? Even if all the
>yhpf's are NULL, the above is output is weird.
>
>What is wrong? Why would the output relate to lapply? If the culprit
>was mclapply, then why does the line get executed without an error
>message? The same function is working perfectly well in windows(I used
>parLapply instead of mclapply).
>Is this peculiar to R on Linux? Please help....
>
>very many thanks for your time and effort,
>Yours sincerely,
>AKSHAY M KULKARNI
>
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From @@r@h@go@|ee @end|ng |rom gm@||@com  Fri Jun 29 16:28:50 2018
From: @@r@h@go@|ee @end|ng |rom gm@||@com (Sarah Goslee)
Date: Fri, 29 Jun 2018 10:28:50 -0400
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
Message-ID: <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>

Hi,

It isn't super clear to me what you're after. Is this what you intend?

> dfbycol(employees4BList)
  first1 last1 first2 last2 first3 last3
1     Al Jones   <NA>  <NA>   <NA>  <NA>
2     Al Jones   Barb Smith   <NA>  <NA>
3     Al Jones   Barb Smith  Carol Adams
4     Al Jones   <NA>  <NA>   <NA>  <NA>
>
> dfbycol(employees4List)
  first1  last1  first2 last2 first3 last3
1     Al  Jones    <NA>  <NA>   <NA>  <NA>
2    Al2  Jones    Barb Smith   <NA>  <NA>
3    Al3  Jones Barbara Smith  Carol Adams
4     Al Jones2    <NA>  <NA>   <NA>  <NA>


If so:

employees4BList = list(
data.frame(first1 = "Al", second1 = "Jones"),
data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
"Smith", "Adams")),
data.frame(first1 = ("Al"), second1 = "Jones"))

employees4List = list(
data.frame(first1 = ("Al"), second1 = "Jones"),
data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
"Smith", "Adams")),
data.frame(first4 = ("Al"), second4 = "Jones2"))

###

dfbycol <- function(x) {
  x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
  x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
  x <- do.call(rbind, x)
  x <- data.frame(x, stringsAsFactors=FALSE)
  colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
  x
}

###

dfbycol(employees4BList)

dfbycol(employees4List)

On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
<r-help at r-project.org> wrote:
> I have a list of data frames which I would like to combine into one data
> frame doing something like rbind. I wish to combine in column order and
> not by names. However, there are issues.
>
> The number of columns is not the same for each data frame. This is an
> intermediate step to a problem and the number of columns could be
> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
> is that the names of the columns produced by the first step are garbage.
>
> Below is a method that I obtained by asking a question on stack
> overflow. Unfortunately, my example was not general enough. The code
> below works for the simple case where the names of the people are
> consistent. It does not work when the names are realistically not the same.
>
> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>
>
> Please note that the lapply step sets things up except for the column
> name issue. If I could figure out a way to change the column names, then
> the bind_rows step will, I believe, work.
>
> So I really have two questions. How to change all column names of all
> the data frames and then how to solve the original problem.
>
> # The non general case works fine. It produces one data frame and I can
> then change the column names to
>
> # c("first1", "last1","first2", "last2","first3", "last3",)
>
> #Non general easy case
>
> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>
> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>
> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> "Smith", "Adams")),
>
> data.frame(first1 = ("Al"), second1 = "Jones"))
>
> employees4BList
>
> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>
> # This produces a nice list of data frames, except for the names
>
> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>
> # This list is a disaster. I am looking for a solution that works in
> this case.
>
> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>
> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>
> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> "Smith", "Adams")),
>
> data.frame(first4 = ("Al"), second4 = "Jones2"))
>
>   bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>
> Thanks.
>
> Ira
>

-- 
Sarah Goslee
http://www.functionaldiversity.org



From |d1083-r @end|ng |rom y@hoo@com  Fri Jun 29 15:41:19 2018
From: |d1083-r @end|ng |rom y@hoo@com (=?UTF-8?Q?J=C3=A9r=C3=B4me_Fran=C3=A7ois?=)
Date: Fri, 29 Jun 2018 13:41:19 +0000 (UTC)
Subject: [R] Plot multiple time series on a seasonal plot
References: <615332437.512512.1530279679993.ref@mail.yahoo.com>
Message-ID: <615332437.512512.1530279679993@mail.yahoo.com>

Dear members,

I would like to plot a second time series (a forecast) to a seasonal plot made with function seasonplot() from the package forecast.


Here is a reproducible example:
ts1 <- structure(c(112035, 111182, 111015, 109331, 107525, 107749, 111435, 
111629, 112462, 112256, 109496, 107917, 108221, 107463, 105960, 
103883, 101038, 100056, 101628, 102973, 103371, 102463, 100774, 
100718, 100471, 99828, 99365, 98521, 95695, 96443, 96287, 97525, 
98293, 98014, 96658, 96736, 96089, 95337, 95382, 92748, 91448, 
91560, 92996, 94046, 94128, 93888, 93888, 91091, 91877, 91681, 
91045, 89367, 87912), .Tsp = c(2014, 2018.33333333333, 12), class = "ts")

ts2 <- structure(c(87867.2152330971, 89713.0862474283, 89600.565347383, 
91066.3196835822, 90523.1926861474, 89322.8025396445, 88771.5545520503, 
89247.0913151542, 88803.5578121458, 88060.0948570082, 87015.6578227365, 
85785.4121532206), .Tsp = c(2018.41666666667, 2019.33333333333, 
12), class = "ts")


library(forecast)seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE)


How can I add ts2 to the seasonal plot? I would like it to be distinguishable from ts1 (e.g. different color).

lines(ts2) doesn't work.
Thank you.
Sincerely,

J?r?me



From ru|pb@rr@d@@ @end|ng |rom @@po@pt  Fri Jun 29 19:33:11 2018
From: ru|pb@rr@d@@ @end|ng |rom @@po@pt (Rui Barradas)
Date: Fri, 29 Jun 2018 18:33:11 +0100
Subject: [R] 
 =?utf-8?b?zqPPh861z4Q6IHgtYXhpcyB0aWNrIG1hcmtzIGxlbmd0aCBp?=
 =?utf-8?q?n_ggplot2?=
In-Reply-To: <1078453055.282011.1530266497799@mail.yahoo.com>
References: <1894507928.4864388.1530116258439.ref@mail.yahoo.com>
 <1894507928.4864388.1530116258439@mail.yahoo.com>
 <CA+-dKdONv8Y+pWH42RU47YVccmtU_HOBAEnTkowdzUggjmi87g@mail.gmail.com>
 <624069206.5599815.1530185883999@mail.yahoo.com>
 <8316569.5602775.1530186534961@mail.yahoo.com>
 <CALe7saLmjnDtGoJ6go6NB+NGx82RLNsTWwCdF9uZmh6sHyLLQw@mail.gmail.com>
 <1078453055.282011.1530266497799@mail.yahoo.com>
Message-ID: <99a81d2d-1e2d-f0df-8a28-7e70e1ed5322@sapo.pt>

Hello,

I don't believe what you want is possible because:

axis.ticks.x and axis.ticks.y change the width of the tick marks

axis.ticks.length changes the length but there is no x and y axis 
versions, just a general purpose one.

Sorry I couldn't be of much help,

Rui Barradas

?s 11:01 de 29-06-2018, Maria Lathouri via R-help escreveu:
> Dear Walter,
> I tried to use scale_x_continuous but the arguments that I found was to change the labels, the limits and the breaks. I was only able to increase the number of the tick marks.
> Best,Maria
> 
>      ???? 3:14 ?.?. ??????, 28 ??????? 2018, ?/? Walter Pina <walter.pina1954 at gmail.com> ??????:
>   
> 
>   Dear Maria, you are totally right!
> Did you tried the scale_x_continuous function and its arguments?
> RegardsWalter
> 2018-06-28 8:48 GMT-03:00 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com>:
> 
> Dear Abhimanyu,
> 
> If I am not mistaken, this online help is to post questions, and if possible, these questions to be answered. NOT for sarcastic and insulting posts. You could have just easily ignored my question. So simple.
> 
> Kind regards,Maria
> 
>      ???? 12:38 ?.?. ??????, 28 ??????? 2018, ?/? Maria Lathouri <mlathouri at yahoo.gr> ??????:
>   
> 
>   I am sorry but I didn't get your point. And I am not new in data science!!
> 
> Maria
> 
>      ???? 11:38 ?.?. ??????, 28 ??????? 2018, ?/? Abhimanyu Khatry <khatryabhimanyu at gmail.com> ??????:
>   
> 
>   How a beginner can get started on ggplot ? Is it right to start this if someone is new to data science ?
> On Wed, Jun 27, 2018 at 9:47 PM, 'Maria Lathouri' via ggplot2 <ggplot2 at googlegroups.com> wrote:
> 
> Dear all,
> 
> 
> I would like to ask if there is a way to increase the length of the tick marks on the x-axis only.
> 
> 
> I got the code:
> 
> p+ theme(axis.ticks.length=unit(. 30, "cm"))
> 
> but this increases the length for both x and y axis; whereas, I would like only on x-axis.
> 
> 
> Thank you very much in advance.
> 
> 
> Kind regards,
> Maria
>



From dw|n@em|u@ @end|ng |rom comc@@t@net  Fri Jun 29 21:49:15 2018
From: dw|n@em|u@ @end|ng |rom comc@@t@net (David Winsemius)
Date: Fri, 29 Jun 2018 12:49:15 -0700
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
Message-ID: <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>


> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi,
> 
> It isn't super clear to me what you're after.

Agree.

Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:

library(dplyr)
 newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) ) 
 bind_rows(newList)

#---------

   first1 second1
1      Al   Jones
2     Al2   Jones
3    Barb   Smith
4     Al3   Jones
5 Barbara   Smith
6   Carol   Adams
7      Al  Jones2

Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.

-- 
David.
> Is this what you intend?
> 
>> dfbycol(employees4BList)
>  first1 last1 first2 last2 first3 last3
> 1     Al Jones   <NA>  <NA>   <NA>  <NA>
> 2     Al Jones   Barb Smith   <NA>  <NA>
> 3     Al Jones   Barb Smith  Carol Adams
> 4     Al Jones   <NA>  <NA>   <NA>  <NA>
>> 
>> dfbycol(employees4List)
>  first1  last1  first2 last2 first3 last3
> 1     Al  Jones    <NA>  <NA>   <NA>  <NA>
> 2    Al2  Jones    Barb Smith   <NA>  <NA>
> 3    Al3  Jones Barbara Smith  Carol Adams
> 4     Al Jones2    <NA>  <NA>   <NA>  <NA>
> 
> 
> If so:
> 
> employees4BList = list(
> data.frame(first1 = "Al", second1 = "Jones"),
> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> "Smith", "Adams")),
> data.frame(first1 = ("Al"), second1 = "Jones"))
> 
> employees4List = list(
> data.frame(first1 = ("Al"), second1 = "Jones"),
> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> "Smith", "Adams")),
> data.frame(first4 = ("Al"), second4 = "Jones2"))
> 
> ###
> 
> dfbycol <- function(x) {
>  x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>  x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>  x <- do.call(rbind, x)
>  x <- data.frame(x, stringsAsFactors=FALSE)
>  colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>  x
> }
> 
> ###
> 
> dfbycol(employees4BList)
> 
> dfbycol(employees4List)
> 
> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
> <r-help at r-project.org> wrote:
>> I have a list of data frames which I would like to combine into one data
>> frame doing something like rbind. I wish to combine in column order and
>> not by names. However, there are issues.
>> 
>> The number of columns is not the same for each data frame. This is an
>> intermediate step to a problem and the number of columns could be
>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>> is that the names of the columns produced by the first step are garbage.
>> 
>> Below is a method that I obtained by asking a question on stack
>> overflow. Unfortunately, my example was not general enough. The code
>> below works for the simple case where the names of the people are
>> consistent. It does not work when the names are realistically not the same.
>> 
>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>> 
>> 
>> Please note that the lapply step sets things up except for the column
>> name issue. If I could figure out a way to change the column names, then
>> the bind_rows step will, I believe, work.
>> 
>> So I really have two questions. How to change all column names of all
>> the data frames and then how to solve the original problem.
>> 
>> # The non general case works fine. It produces one data frame and I can
>> then change the column names to
>> 
>> # c("first1", "last1","first2", "last2","first3", "last3",)
>> 
>> #Non general easy case
>> 
>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>> 
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> 
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>> 
>> employees4BList
>> 
>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>> 
>> # This produces a nice list of data frames, except for the names
>> 
>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>> 
>> # This list is a disaster. I am looking for a solution that works in
>> this case.
>> 
>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>> 
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> 
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>> 
>>  bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>> 
>> Thanks.
>> 
>> Ira
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'   -Gehm's Corollary to Clarke's Third Law



From kekwu @end|ng |rom ucd@v|@@edu  Fri Jun 29 23:56:09 2018
From: kekwu @end|ng |rom ucd@v|@@edu (Kelly Wu)
Date: Fri, 29 Jun 2018 14:56:09 -0700
Subject: [R] trouble with exiting loop if condition is met
In-Reply-To: <CA+8X3fXg4B3cuyHv4wAJGPjgoFCNymptBH5Sn+z2Dy7_VXCRDg@mail.gmail.com>
References: <A231955A-9312-4EEB-90BC-35386779C182@ucdavis.edu>
 <CA+8X3fXg4B3cuyHv4wAJGPjgoFCNymptBH5Sn+z2Dy7_VXCRDg@mail.gmail.com>
Message-ID: <36234D0D-FF2D-4961-A753-01D4E9058530@ucdavis.edu>

Hi Jim & Don,


I was trying to use the break command originally before posting but for some reason it was making almost all of the p-values in the replications non significant. I think I am going to change the flow of the loop so I don?t have to use a break, such as the code Jim wrote. Thanks for your detailed response! 


Kelly


> On Jun 28, 2018, at 3:18 PM, Jim Lemon <drjimlemon at gmail.com> wrote:
> 
> " as sequential observations, it
> will only require a minor modification.
> 
> Jim
> 
> On Fri, Jun 29, 2018 at 5:53 AM, Kelly Wu <kekwu at ucdavis.edu> wrote:
> 


	[[alternative HTML version deleted]]



From r@turner @end|ng |rom @uck|@nd@@c@nz  Sat Jun 30 00:56:36 2018
From: r@turner @end|ng |rom @uck|@nd@@c@nz (Rolf Turner)
Date: Sat, 30 Jun 2018 10:56:36 +1200
Subject: [R] [FORGED]  Plot multiple time series on a seasonal plot
In-Reply-To: <615332437.512512.1530279679993@mail.yahoo.com>
References: <615332437.512512.1530279679993.ref@mail.yahoo.com>
 <615332437.512512.1530279679993@mail.yahoo.com>
Message-ID: <79cffece-fbfa-bedf-b3e0-73f230dccd3f@auckland.ac.nz>

On 30/06/18 01:41, J?r?me Fran?ois via R-help wrote:
> Dear members,
> 
> I would like to plot a second time series (a forecast) to a seasonal plot made with function seasonplot() from the package forecast.
> 
> 
> Here is a reproducible example:
> ts1 <- structure(c(112035, 111182, 111015, 109331, 107525, 107749, 111435,
> 111629, 112462, 112256, 109496, 107917, 108221, 107463, 105960,
> 103883, 101038, 100056, 101628, 102973, 103371, 102463, 100774,
> 100718, 100471, 99828, 99365, 98521, 95695, 96443, 96287, 97525,
> 98293, 98014, 96658, 96736, 96089, 95337, 95382, 92748, 91448,
> 91560, 92996, 94046, 94128, 93888, 93888, 91091, 91877, 91681,
> 91045, 89367, 87912), .Tsp = c(2014, 2018.33333333333, 12), class = "ts")
> 
> ts2 <- structure(c(87867.2152330971, 89713.0862474283, 89600.565347383,
> 91066.3196835822, 90523.1926861474, 89322.8025396445, 88771.5545520503,
> 89247.0913151542, 88803.5578121458, 88060.0948570082, 87015.6578227365,
> 85785.4121532206), .Tsp = c(2018.41666666667, 2019.33333333333,
> 12), class = "ts")
> 
> 
> library(forecast)seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE)
> 
> 
> How can I add ts2 to the seasonal plot? I would like it to be distinguishable from ts1 (e.g. different color).
> 
> lines(ts2) doesn't work.
> Thank you.


I don't know anything about forecast/seasonplot.  However my experience 
is that par(new=TRUE) usually rescues one in situations like this.

It's a bit shaganappi, but ...

seasonplot(ts1, year.labels = TRUE, year.labels.left = TRUE,
            main="Whatever")
OP <- par(new=TRUE,xaxt="n",yaxt="n")
seasonplot(ts2, col="red",main="")
par(OP)

seems to work.

It would be nice to have an "add=" argument (defaulting to FALSE, of 
course) to seasonplot().

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276



From |r@@h@renow100 @end|ng |rom y@hoo@com  Sat Jun 30 02:29:07 2018
From: |r@@h@renow100 @end|ng |rom y@hoo@com (Ira Sharenow)
Date: Sat, 30 Jun 2018 00:29:07 +0000 (UTC)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
Message-ID: <951618652.604333.1530318547705@mail.yahoo.com>

 
Sarah and David,

Thank you for your responses.I will try and be clearer.

Base R solution: Sarah?smethod worked perfectly

Is there a dplyrsolution?

START: list of dataframes

FINISH: one data frame

DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows. 

SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.

EXAMPLE: List with twodata frames

# DF1

First?? ???????Last

George Washington

?

# DF2

Start????????????? End

John?????????????? Adams

Thomas??????? Jefferson

?

# End Result. One dataframe

First1????? Second1??????? First2?????????? Second2

George Washington?????? NA??????????????????? NA

John?????????????? Adams??? Thomas??????? Jefferson

?

DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.

The suggested solution was:

library(dplyr)

bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))

?

On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))

For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.

I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.

In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.

Ira


    On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:  
 
 
> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
> 
> Hi,
> 
> It isn't super clear to me what you're after.

Agree.

Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:

library(dplyr)
 newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) ) 
 bind_rows(newList)

#---------

? first1 second1
1? ? ? Al? Jones
2? ? Al2? Jones
3? ? Barb? Smith
4? ? Al3? Jones
5 Barbara? Smith
6? Carol? Adams
7? ? ? Al? Jones2

Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.

-- 
David.
> Is this what you intend?
> 
>> dfbycol(employees4BList)
>? first1 last1 first2 last2 first3 last3
> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
> 2? ? Al Jones? Barb Smith? <NA>? <NA>
> 3? ? Al Jones? Barb Smith? Carol Adams
> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>> 
>> dfbycol(employees4List)
>? first1? last1? first2 last2 first3 last3
> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
> 3? ? Al3? Jones Barbara Smith? Carol Adams
> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
> 
> 
> If so:
> 
> employees4BList = list(
> data.frame(first1 = "Al", second1 = "Jones"),
> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> "Smith", "Adams")),
> data.frame(first1 = ("Al"), second1 = "Jones"))
> 
> employees4List = list(
> data.frame(first1 = ("Al"), second1 = "Jones"),
> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> "Smith", "Adams")),
> data.frame(first4 = ("Al"), second4 = "Jones2"))
> 
> ###
> 
> dfbycol <- function(x) {
>? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>? x <- do.call(rbind, x)
>? x <- data.frame(x, stringsAsFactors=FALSE)
>? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>? x
> }
> 
> ###
> 
> dfbycol(employees4BList)
> 
> dfbycol(employees4List)
> 
> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
> <r-help at r-project.org> wrote:
>> I have a list of data frames which I would like to combine into one data
>> frame doing something like rbind. I wish to combine in column order and
>> not by names. However, there are issues.
>> 
>> The number of columns is not the same for each data frame. This is an
>> intermediate step to a problem and the number of columns could be
>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>> is that the names of the columns produced by the first step are garbage.
>> 
>> Below is a method that I obtained by asking a question on stack
>> overflow. Unfortunately, my example was not general enough. The code
>> below works for the simple case where the names of the people are
>> consistent. It does not work when the names are realistically not the same.
>> 
>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>> 
>> 
>> Please note that the lapply step sets things up except for the column
>> name issue. If I could figure out a way to change the column names, then
>> the bind_rows step will, I believe, work.
>> 
>> So I really have two questions. How to change all column names of all
>> the data frames and then how to solve the original problem.
>> 
>> # The non general case works fine. It produces one data frame and I can
>> then change the column names to
>> 
>> # c("first1", "last1","first2", "last2","first3", "last3",)
>> 
>> #Non general easy case
>> 
>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>> 
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> 
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>> 
>> employees4BList
>> 
>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>> 
>> # This produces a nice list of data frames, except for the names
>> 
>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>> 
>> # This list is a disaster. I am looking for a solution that works in
>> this case.
>> 
>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>> 
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> 
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> 
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>> 
>>? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>> 
>> Thanks.
>> 
>> Ira
>> 
> 
> -- 
> Sarah Goslee
> http://www.functionaldiversity.org
> 
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.

David Winsemius
Alameda, CA, USA

'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law




  
	[[alternative HTML version deleted]]



From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun 30 03:33:46 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Fri, 29 Jun 2018 18:33:46 -0700
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <951618652.604333.1530318547705@mail.yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
Message-ID: <CAGxFJbSUVF5E8GDzzZ9X-SSBTQH8sV+Bywk4QZU-pOCe7p+RMA@mail.gmail.com>

Well, I don't know your constraints, of course; but if I understand
correctly, in situations like this, it is usually worthwhile to reconsider
your data structure.

This is a one-liner if you simply rbind all your data frames into one with
2 columns. Here's an example to indicate how:

## list of two data frames with different column names and numbers of rows:
zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a =
5:9,b = letters[11:15]))

## create common column names and bind them up:
do.call(rbind,lapply(zz,function(x){   names(x) <- c("first","last"); x}))

Note that the row names of the result tell you which original frame the
rows came from. This can also be obtained just from a count of rows (?nrow)
of the original list.

Apologies if I misunderstand or your query or your constraints make this
simple approach impossible.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Fri, Jun 29, 2018 at 5:29 PM, Ira Sharenow via R-help <
r-help at r-project.org> wrote:

>
> Sarah and David,
>
> Thank you for your responses.I will try and be clearer.
>
> Base R solution: Sarah?smethod worked perfectly
>
> Is there a dplyrsolution?
>
> START: list of dataframes
>
> FINISH: one data frame
>
> DETAILS: The initiallist of data frames might have hundreds or a few
> thousand data frames. Everydata frame will have two columns. The first
> column will represent first names.The second column will represent last
> names. The column names are notconsistent. Data frames will most likely
> have from one to five rows.
>
> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames.
> Then somehow do an rbindeven though the number of columns differ from data
> frame to data frame.
>
> EXAMPLE: List with twodata frames
>
> # DF1
>
> First          Last
>
> George Washington
>
>
>
> # DF2
>
> Start              End
>
> John               Adams
>
> Thomas        Jefferson
>
>
>
> # End Result. One dataframe
>
> First1      Second1        First2           Second2
>
> George Washington       NA                    NA
>
> John               Adams    Thomas        Jefferson
>
>
>
> DISCUSSION: As mentionedI posted something on Stack Overflow.
> Unfortunately, my example was not generalenough and so the suggested
> solutions worked on the easy case which I provided butnot when the names
> were different.
>
> The suggested solution was:
>
> library(dplyr)
>
> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>
>
>
> On this site I pointedout that the inner function: lapply(employees4List,
> function(x) rbind.data.frame(c(t(x))))
>
> For each data frame correctlyspread the multiple rows into  1 by 2ndata
> frames. However, the column names were derived from the values and were
> amess. This caused a problem with bind_rows.
>
> I felt that if I knewhow to change all the names of all of the data frames
> that were created afterlapply, then I could then use bind_rows. So if
> someone knows how to change allof the names at this intermediate stage, I
> hope that person will provide thesolution.
>
> In  the end a 1 by 2 data frame would have namesFirst1      Second1. A 1
> by 4 data framewould have names First1      Second1        First2
> Second2.
>
> Ira
>
>
>     On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <
> dwinsemius at comcast.net> wrote:
>
>
> > On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com>
> wrote:
> >
> > Hi,
> >
> > It isn't super clear to me what you're after.
>
> Agree.
>
> Had a different read of ht erequest. Thought the request was for a first
> step that "harmonized" the names of the columns and then used
> `dplyr::bind_rows`:
>
> library(dplyr)
>  newList <- lapply( employees4List, 'names<-', names(employees4List[[1]])
> )
>  bind_rows(newList)
>
> #---------
>
>   first1 second1
> 1      Al  Jones
> 2    Al2  Jones
> 3    Barb  Smith
> 4    Al3  Jones
> 5 Barbara  Smith
> 6  Carol  Adams
> 7      Al  Jones2
>
> Might want to wrap suppressWarnings around the right side of that
> assignment since there were many warnings regarding incongruent factor
> levels.
>
> --
> David.
> > Is this what you intend?
> >
> >> dfbycol(employees4BList)
> >  first1 last1 first2 last2 first3 last3
> > 1    Al Jones  <NA>  <NA>  <NA>  <NA>
> > 2    Al Jones  Barb Smith  <NA>  <NA>
> > 3    Al Jones  Barb Smith  Carol Adams
> > 4    Al Jones  <NA>  <NA>  <NA>  <NA>
> >>
> >> dfbycol(employees4List)
> >  first1  last1  first2 last2 first3 last3
> > 1    Al  Jones    <NA>  <NA>  <NA>  <NA>
> > 2    Al2  Jones    Barb Smith  <NA>  <NA>
> > 3    Al3  Jones Barbara Smith  Carol Adams
> > 4    Al Jones2    <NA>  <NA>  <NA>  <NA>
> >
> >
> > If so:
> >
> > employees4BList = list(
> > data.frame(first1 = "Al", second1 = "Jones"),
> > data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> > data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> > "Smith", "Adams")),
> > data.frame(first1 = ("Al"), second1 = "Jones"))
> >
> > employees4List = list(
> > data.frame(first1 = ("Al"), second1 = "Jones"),
> > data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> > data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> > "Smith", "Adams")),
> > data.frame(first4 = ("Al"), second4 = "Jones2"))
> >
> > ###
> >
> > dfbycol <- function(x) {
> >  x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
> >  x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
> >  x <- do.call(rbind, x)
> >  x <- data.frame(x, stringsAsFactors=FALSE)
> >  colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2),
> each=2))
> >  x
> > }
> >
> > ###
> >
> > dfbycol(employees4BList)
> >
> > dfbycol(employees4List)
> >
> > On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
> > <r-help at r-project.org> wrote:
> >> I have a list of data frames which I would like to combine into one data
> >> frame doing something like rbind. I wish to combine in column order and
> >> not by names. However, there are issues.
> >>
> >> The number of columns is not the same for each data frame. This is an
> >> intermediate step to a problem and the number of columns could be
> >> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
> >> is that the names of the columns produced by the first step are garbage.
> >>
> >> Below is a method that I obtained by asking a question on stack
> >> overflow. Unfortunately, my example was not general enough. The code
> >> below works for the simple case where the names of the people are
> >> consistent. It does not work when the names are realistically not the
> same.
> >>
> >> https://stackoverflow.com/questions/50807970/converting-
> a-list-of-data-frames-not-a-simple-rbind-second-row-to-
> new-columns/50809432#50809432
> >>
> >>
> >> Please note that the lapply step sets things up except for the column
> >> name issue. If I could figure out a way to change the column names, then
> >> the bind_rows step will, I believe, work.
> >>
> >> So I really have two questions. How to change all column names of all
> >> the data frames and then how to solve the original problem.
> >>
> >> # The non general case works fine. It produces one data frame and I can
> >> then change the column names to
> >>
> >> # c("first1", "last1","first2", "last2","first3", "last3",)
> >>
> >> #Non general easy case
> >>
> >> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
> >>
> >> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
> >>
> >> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
> >> "Smith", "Adams")),
> >>
> >> data.frame(first1 = ("Al"), second1 = "Jones"))
> >>
> >> employees4BList
> >>
> >> bind_rows(lapply(employees4BList, function(x)
> rbind.data.frame(c(t(x)))))
> >>
> >> # This produces a nice list of data frames, except for the names
> >>
> >> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
> >>
> >> # This list is a disaster. I am looking for a solution that works in
> >> this case.
> >>
> >> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
> >>
> >> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
> >>
> >> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
> >> "Smith", "Adams")),
> >>
> >> data.frame(first4 = ("Al"), second4 = "Jones2"))
> >>
> >>  bind_rows(lapply(employees4List, function(x)
> rbind.data.frame(c(t(x)))))
> >>
> >> Thanks.
> >>
> >> Ira
> >>
> >
> > --
> > Sarah Goslee
> > http://www.functionaldiversity.org
> >
> > ______________________________________________
> > R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> > https://stat.ethz.ch/mailman/listinfo/r-help
> > PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> > and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'
> -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun 30 04:50:58 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Fri, 29 Jun 2018 19:50:58 -0700 (PDT)
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <951618652.604333.1530318547705@mail.yahoo.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
Message-ID: <alpine.BSF.2.00.1806291929070.24125@pedal.dcn.davis.ca.us>

Code below...

a) Just because something can be done with dplyr does not mean that is the 
best way to do it. A solution in the hand is worth two on the Internet, 
and dplyr is not always the fastest method anyway.

b) I highly recommend that you read Hadley Wickham's paper on tidy data 
[1]. Also, having a group of one or more columns at all times that 
uniquely identify where the data came from is a "key" to success [2].

c) Please read and follow one of the various online documents about making 
reproducible examples in R (e.g. [3]). HTML formatting is really a pain 
(at best... at worst, it corrupts your code) on a plain-text-only list 
(you have read the Posting Guide, right?). Consider my example below as a 
model for you to follow in the future, and make sure to set your email 
program to send plain text. (Obviously your examples don't have to achieve 
success... but they should bring us up to speed with where you are having 
troubles IN R.)

[1] https://www.jstatsoft.org/article/view/v059i10
[2] http://r4ds.had.co.nz/relational-data.html#keys
[3] https://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

----
library(dplyr)
#>
#> Attaching package: 'dplyr'
#> The following objects are masked from 'package:stats':
#>
#>     filter, lag
#> The following objects are masked from 'package:base':
#>
#>     intersect, setdiff, setequal, union
library(tidyr)

# note that these data frames all have character columns
# rather than factors, due to the as.is option when the
# data are read in.
DF1 <- read.table( text =
"First          Last
George          Washington
", header=TRUE, as.is = TRUE )

# dput looks ugly but is actually much more practical for
# providing R data on the mailing list... here is an example
dput( DF1 )
#> structure(list(First = "George", Last = "Washington")
#>, .Names = c("First",
#> "Last"), class = "data.frame", row.names = c(NA, -1L))

DF2 <- read.table( text =
"Start              End
John               Adams
Thomas        Jefferson
", header = TRUE, as.is = TRUE )

DFL <- list( DF1, DF2 )

# DFNames is a set of unique identifiers
DFL1 <- data_frame( .DFNames = sprintf( "DF%d", 1:2 )
                   , data = DFL
                   )

DFL2 <- (   DFL1
         %>% mutate( data = lapply( data
                                  , function( DF ) {
                                      DF[[ ".PK" ]] <- seq.int( nrow( DF ))
                                      gather( DF, ".Col", "value", -.PK )
                                    }
                                  )
                   )
         %>% unnest
         %>% spread( .Col, value )
         )
DFL2
#> # A tibble: 3 x 6
#>   .DFNames   .PK End       First  Last       Start
#>   <chr>    <int> <chr>     <chr>  <chr>      <chr>
#> 1 DF1          1 <NA>      George Washington <NA>
#> 2 DF2          1 Adams     <NA>   <NA>       John
#> 3 DF2          2 Jefferson <NA>   <NA>       Thomas

#' Created on 2018-06-29 by the [reprex package](http://reprex.tidyverse.org) (v0.2.0).
----

On Sat, 30 Jun 2018, Ira Sharenow via R-help wrote:

>
> Sarah and David,
>
> Thank you for your responses.I will try and be clearer.
>
> Base R solution: Sarah?smethod worked perfectly
>
> Is there a dplyrsolution?
>
> START: list of dataframes
>
> FINISH: one data frame
>
> DETAILS: The initiallist of data frames might have hundreds or a few thousand data frames. Everydata frame will have two columns. The first column will represent first names.The second column will represent last names. The column names are notconsistent. Data frames will most likely have from one to five rows.
>
> SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data frames. Then somehow do an rbindeven though the number of columns differ from data frame to data frame.
>
> EXAMPLE: List with twodata frames
>
> # DF1
>
> First?? ???????Last
>
> George Washington
>
> ?
>
> # DF2
>
> Start????????????? End
>
> John?????????????? Adams
>
> Thomas??????? Jefferson
>
> ?
>
> # End Result. One dataframe
>
> First1????? Second1??????? First2?????????? Second2
>
> George Washington?????? NA??????????????????? NA
>
> John?????????????? Adams??? Thomas??????? Jefferson
>
> ?
>
> DISCUSSION: As mentionedI posted something on Stack Overflow. Unfortunately, my example was not generalenough and so the suggested solutions worked on the easy case which I provided butnot when the names were different.
>
> The suggested solution was:
>
> library(dplyr)
>
> bind_rows(lapply(employees4List,function(x) rbind.data.frame(c(t(x)))))
>
> ?
>
> On this site I pointedout that the inner function: lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
> For each data frame correctlyspread the multiple rows into ?1 by 2ndata frames. However, the column names were derived from the values and were amess. This caused a problem with bind_rows.
>
> I felt that if I knewhow to change all the names of all of the data frames that were created afterlapply, then I could then use bind_rows. So if someone knows how to change allof the names at this intermediate stage, I hope that person will provide thesolution.
>
> In? the end a 1 by 2 data frame would have namesFirst1????? Second1. A 1 by 4 data framewould have names First1????? Second1??????? First2?????????? Second2.
>
> Ira
>
>
>    On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius <dwinsemius at comcast.net> wrote:
>
>
>> On Jun 29, 2018, at 7:28 AM, Sarah Goslee <sarah.goslee at gmail.com> wrote:
>>
>> Hi,
>>
>> It isn't super clear to me what you're after.
>
> Agree.
>
> Had a different read of ht erequest. Thought the request was for a first step that "harmonized" the names of the columns and then used `dplyr::bind_rows`:
>
> library(dplyr)
> newList <- lapply( employees4List, 'names<-', names(employees4List[[1]]) )
> bind_rows(newList)
>
> #---------
>
> ? first1 second1
> 1? ? ? Al? Jones
> 2? ? Al2? Jones
> 3? ? Barb? Smith
> 4? ? Al3? Jones
> 5 Barbara? Smith
> 6? Carol? Adams
> 7? ? ? Al? Jones2
>
> Might want to wrap suppressWarnings around the right side of that assignment since there were many warnings regarding incongruent factor levels.
>
> -- 
> David.
>> Is this what you intend?
>>
>>> dfbycol(employees4BList)
>> ? first1 last1 first2 last2 first3 last3
>> 1? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al Jones? Barb Smith? <NA>? <NA>
>> 3? ? Al Jones? Barb Smith? Carol Adams
>> 4? ? Al Jones? <NA>? <NA>? <NA>? <NA>
>>>
>>> dfbycol(employees4List)
>> ? first1? last1? first2 last2 first3 last3
>> 1? ? Al? Jones? ? <NA>? <NA>? <NA>? <NA>
>> 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>> 3? ? Al3? Jones Barbara Smith? Carol Adams
>> 4? ? Al Jones2? ? <NA>? <NA>? <NA>? <NA>
>>
>>
>> If so:
>>
>> employees4BList = list(
>> data.frame(first1 = "Al", second1 = "Jones"),
>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>
>> employees4List = list(
>> data.frame(first1 = ("Al"), second1 = "Jones"),
>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>> "Smith", "Adams")),
>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>
>> ###
>>
>> dfbycol <- function(x) {
>> ? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>> ? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>> ? x <- do.call(rbind, x)
>> ? x <- data.frame(x, stringsAsFactors=FALSE)
>> ? colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))
>> ? x
>> }
>>
>> ###
>>
>> dfbycol(employees4BList)
>>
>> dfbycol(employees4List)
>>
>> On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>> <r-help at r-project.org> wrote:
>>> I have a list of data frames which I would like to combine into one data
>>> frame doing something like rbind. I wish to combine in column order and
>>> not by names. However, there are issues.
>>>
>>> The number of columns is not the same for each data frame. This is an
>>> intermediate step to a problem and the number of columns could be
>>> 2,4,6,8,or10. There might be a few thousand data frames. Another problem
>>> is that the names of the columns produced by the first step are garbage.
>>>
>>> Below is a method that I obtained by asking a question on stack
>>> overflow. Unfortunately, my example was not general enough. The code
>>> below works for the simple case where the names of the people are
>>> consistent. It does not work when the names are realistically not the same.
>>>
>>> https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>>>
>>>
>>> Please note that the lapply step sets things up except for the column
>>> name issue. If I could figure out a way to change the column names, then
>>> the bind_rows step will, I believe, work.
>>>
>>> So I really have two questions. How to change all column names of all
>>> the data frames and then how to solve the original problem.
>>>
>>> # The non general case works fine. It produces one data frame and I can
>>> then change the column names to
>>>
>>> # c("first1", "last1","first2", "last2","first3", "last3",)
>>>
>>> #Non general easy case
>>>
>>> employees4BList = list(data.frame(first1 = "Al", second1 = "Jones"),
>>>
>>> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>>>
>>> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first1 = ("Al"), second1 = "Jones"))
>>>
>>> employees4BList
>>>
>>> bind_rows(lapply(employees4BList, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> # This produces a nice list of data frames, except for the names
>>>
>>> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>>>
>>> # This list is a disaster. I am looking for a solution that works in
>>> this case.
>>>
>>> employees4List = list(data.frame(first1 = ("Al"), second1 = "Jones"),
>>>
>>> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones", "Smith")),
>>>
>>> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 = c("Jones",
>>> "Smith", "Adams")),
>>>
>>> data.frame(first4 = ("Al"), second4 = "Jones2"))
>>>
>>> ? bind_rows(lapply(employees4List, function(x) rbind.data.frame(c(t(x)))))
>>>
>>> Thanks.
>>>
>>> Ira
>>>
>>
>> --
>> Sarah Goslee
>> http://www.functionaldiversity.org
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.
>
> David Winsemius
> Alameda, CA, USA
>
> 'Any technology distinguishable from magic is insufficiently advanced.'? -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k
---------------------------------------------------------------------------

From |r@@h@renow100 @end|ng |rom y@hoo@com  Sat Jun 30 04:08:56 2018
From: |r@@h@renow100 @end|ng |rom y@hoo@com (Ira Sharenow)
Date: Fri, 29 Jun 2018 19:08:56 -0700
Subject: [R] Convert list of data frames to one data frame
In-Reply-To: <CAGxFJbSUVF5E8GDzzZ9X-SSBTQH8sV+Bywk4QZU-pOCe7p+RMA@mail.gmail.com>
References: <88041b92-8f0b-a5dd-b01a-fbfaff24b403@yahoo.com>
 <CAM_vjukRbWwkipHoKVcrvcZ6GGOQRAqsr04x7vN_tcYRNXGM-A@mail.gmail.com>
 <EC81E8ED-D619-44A5-994D-601ECF94753B@comcast.net>
 <951618652.604333.1530318547705@mail.yahoo.com>
 <CAGxFJbSUVF5E8GDzzZ9X-SSBTQH8sV+Bywk4QZU-pOCe7p+RMA@mail.gmail.com>
Message-ID: <388607cc-83f3-78fb-466e-f6fff4787077@yahoo.com>

Bert,

Thanks for your idea. However, the end results is not what I am looking 
for. Each initial data frame in the list will result in just one row in 
the final data frame. In your case

Row 1 of the initial structure will become 1 b 2 c3d NA NA NA NA in the 
end structure

Row 2 of the initial structure will become 5 k 6 l 7 m 8 n 9 o

Sarah?s code works

> dfbycol(zz)

first1 last1 first2 last2 first3 last3 first4 last4 first5 last5

one1b2c3d<NA><NA><NA><NA>

two5k6l7m8n9o


> 

dfbycol <- function(x) {

x <- lapply(x, function(y)as.vector(t(as.matrix(y))))

x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})

x <- do.call(rbind, x)

x <- data.frame(x, stringsAsFactors=FALSE)

colnames(x) <- paste0(c("first", "last"), rep(seq(1, ncol(x)/2), each=2))

x

}

Thanks.

By the way I am working with a colleague on this. Apparently the data 
came from reading in XML data.

Ira


On 6/29/2018 6:33 PM, Bert Gunter wrote:
> Well, I don't know your constraints, of course; but if I understand 
> correctly, in situations like this, it is usually worthwhile to 
> reconsider your data structure.
>
> This is a one-liner if you simply rbind all your data frames into one 
> with 2 columns. Here's an example to indicate how:
>
> ## list of two data frames with different column names and numbers of 
> rows:
> zz <-list(one = data.frame(f=1:3,g=letters[2:4]), two = data.frame(a = 
> 5:9,b = letters[11:15]))
>
> ## create common column names and bind them up:
> do.call(rbind,lapply(zz,function(x){?? names(x) <- c("first","last"); x}))
>
> Note that the row names of the result tell you which original frame 
> the rows came from. This can also be obtained just from a count of 
> rows (?nrow) of the original list.
>
> Apologies if I misunderstand or your query or your constraints make 
> this simple approach impossible.
>
> Cheers,
> Bert
>
>
>
> Bert Gunter
>
> "The trouble with having an open mind is that people keep coming along 
> and sticking things into it."
> -- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )
>
> On Fri, Jun 29, 2018 at 5:29 PM, Ira Sharenow via R-help 
> <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>
>
>     Sarah and David,
>
>     Thank you for your responses.I will try and be clearer.
>
>     Base R solution: Sarah?smethod worked perfectly
>
>     Is there a dplyrsolution?
>
>     START: list of dataframes
>
>     FINISH: one data frame
>
>     DETAILS: The initiallist of data frames might have hundreds or a
>     few thousand data frames. Everydata frame will have two columns.
>     The first column will represent first names.The second column will
>     represent last names. The column names are notconsistent. Data
>     frames will most likely have from one to five rows.
>
>     SUGGESTED STRATEGY:Convert the n by 2 data frames to 1 by 2n data
>     frames. Then somehow do an rbindeven though the number of columns
>     differ from data frame to data frame.
>
>     EXAMPLE: List with twodata frames
>
>     # DF1
>
>     First?? ???????Last
>
>     George Washington
>
>
>
>     # DF2
>
>     Start????????????? End
>
>     John?????????????? Adams
>
>     Thomas??????? Jefferson
>
>
>
>     # End Result. One dataframe
>
>     First1????? Second1??????? First2?????????? Second2
>
>     George Washington?????? NA??????????????????? NA
>
>     John?????????????? Adams??? Thomas??????? Jefferson
>
>
>
>     DISCUSSION: As mentionedI posted something on Stack Overflow.
>     Unfortunately, my example was not generalenough and so the
>     suggested solutions worked on the easy case which I provided
>     butnot when the names were different.
>
>     The suggested solution was:
>
>     library(dplyr)
>
>     bind_rows(lapply(employees4List,function(x)
>     rbind.data.frame(c(t(x)))))
>
>
>
>     On this site I pointedout that the inner function:
>     lapply(employees4List, function(x) rbind.data.frame(c(t(x))))
>
>     For each data frame correctlyspread the multiple rows into ?1 by
>     2ndata frames. However, the column names were derived from the
>     values and were amess. This caused a problem with bind_rows.
>
>     I felt that if I knewhow to change all the names of all of the
>     data frames that were created afterlapply, then I could then use
>     bind_rows. So if someone knows how to change allof the names at
>     this intermediate stage, I hope that person will provide thesolution.
>
>     In? the end a 1 by 2 data frame would have namesFirst1 Second1. A
>     1 by 4 data framewould have names First1 Second1???????
>     First2?????????? Second2.
>
>     Ira
>
>
>     ? ? On Friday, June 29, 2018, 12:49:18 PM PDT, David Winsemius
>     <dwinsemius at comcast.net <mailto:dwinsemius at comcast.net>> wrote:
>
>
>     > On Jun 29, 2018, at 7:28 AM, Sarah Goslee
>     <sarah.goslee at gmail.com <mailto:sarah.goslee at gmail.com>> wrote:
>     >
>     > Hi,
>     >
>     > It isn't super clear to me what you're after.
>
>     Agree.
>
>     Had a different read of ht erequest. Thought the request was for a
>     first step that "harmonized" the names of the columns and then
>     used `dplyr::bind_rows`:
>
>     library(dplyr)
>     ?newList <- lapply( employees4List, 'names<-',
>     names(employees4List[[1]]) )
>     ?bind_rows(newList)
>
>     #---------
>
>     ? first1 second1
>     1? ? ? Al? Jones
>     2? ? Al2? Jones
>     3? ? Barb? Smith
>     4? ? Al3? Jones
>     5 Barbara? Smith
>     6? Carol? Adams
>     7? ? ? Al? Jones2
>
>     Might want to wrap suppressWarnings around the right side of that
>     assignment since there were many warnings regarding incongruent
>     factor levels.
>
>     -- 
>     David.
>     > Is this what you intend?
>     >
>     >> dfbycol(employees4BList)
>     >? first1 last1 first2 last2 first3 last3
>     > 1? ? Al Jones? <NA>? <NA>? <NA> <NA>
>     > 2? ? Al Jones? Barb Smith? <NA>? <NA>
>     > 3? ? Al Jones? Barb Smith? Carol Adams
>     > 4? ? Al Jones? <NA>? <NA>? <NA> <NA>
>     >>
>     >> dfbycol(employees4List)
>     >? first1? last1? first2 last2 first3 last3
>     > 1? ? Al? Jones? ? <NA>? <NA>? <NA> <NA>
>     > 2? ? Al2? Jones? ? Barb Smith? <NA>? <NA>
>     > 3? ? Al3? Jones Barbara Smith? Carol Adams
>     > 4? ? Al Jones2? ? <NA>? <NA>? <NA> <NA>
>     >
>     >
>     > If so:
>     >
>     > employees4BList = list(
>     > data.frame(first1 = "Al", second1 = "Jones"),
>     > data.frame(first1 = c("Al", "Barb"), second1 = c("Jones", "Smith")),
>     > data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>     > "Smith", "Adams")),
>     > data.frame(first1 = ("Al"), second1 = "Jones"))
>     >
>     > employees4List = list(
>     > data.frame(first1 = ("Al"), second1 = "Jones"),
>     > data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones",
>     "Smith")),
>     > data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 =
>     c("Jones",
>     > "Smith", "Adams")),
>     > data.frame(first4 = ("Al"), second4 = "Jones2"))
>     >
>     > ###
>     >
>     > dfbycol <- function(x) {
>     >? x <- lapply(x, function(y)as.vector(t(as.matrix(y))))
>     >? x <- lapply(x, function(y){length(y) <- max(sapply(x, length)); y})
>     >? x <- do.call(rbind, x)
>     >? x <- data.frame(x, stringsAsFactors=FALSE)
>     >? colnames(x) <- paste0(c("first", "last"), rep(seq(1,
>     ncol(x)/2), each=2))
>     >? x
>     > }
>     >
>     > ###
>     >
>     > dfbycol(employees4BList)
>     >
>     > dfbycol(employees4List)
>     >
>     > On Fri, Jun 29, 2018 at 2:36 AM, Ira Sharenow via R-help
>     > <r-help at r-project.org <mailto:r-help at r-project.org>> wrote:
>     >> I have a list of data frames which I would like to combine into
>     one data
>     >> frame doing something like rbind. I wish to combine in column
>     order and
>     >> not by names. However, there are issues.
>     >>
>     >> The number of columns is not the same for each data frame. This
>     is an
>     >> intermediate step to a problem and the number of columns could be
>     >> 2,4,6,8,or10. There might be a few thousand data frames.
>     Another problem
>     >> is that the names of the columns produced by the first step are
>     garbage.
>     >>
>     >> Below is a method that I obtained by asking a question on stack
>     >> overflow. Unfortunately, my example was not general enough. The
>     code
>     >> below works for the simple case where the names of the people are
>     >> consistent. It does not work when the names are realistically
>     not the same.
>     >>
>     >>
>     https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432
>     <https://stackoverflow.com/questions/50807970/converting-a-list-of-data-frames-not-a-simple-rbind-second-row-to-new-columns/50809432#50809432>
>     >>
>     >>
>     >> Please note that the lapply step sets things up except for the
>     column
>     >> name issue. If I could figure out a way to change the column
>     names, then
>     >> the bind_rows step will, I believe, work.
>     >>
>     >> So I really have two questions. How to change all column names
>     of all
>     >> the data frames and then how to solve the original problem.
>     >>
>     >> # The non general case works fine. It produces one data frame
>     and I can
>     >> then change the column names to
>     >>
>     >> # c("first1", "last1","first2", "last2","first3", "last3",)
>     >>
>     >> #Non general easy case
>     >>
>     >> employees4BList = list(data.frame(first1 = "Al", second1 =
>     "Jones"),
>     >>
>     >> data.frame(first1 = c("Al", "Barb"), second1 = c("Jones",
>     "Smith")),
>     >>
>     >> data.frame(first1 = c("Al", "Barb", "Carol"), second1 = c("Jones",
>     >> "Smith", "Adams")),
>     >>
>     >> data.frame(first1 = ("Al"), second1 = "Jones"))
>     >>
>     >> employees4BList
>     >>
>     >> bind_rows(lapply(employees4BList, function(x)
>     rbind.data.frame(c(t(x)))))
>     >>
>     >> # This produces a nice list of data frames, except for the names
>     >>
>     >> lapply(employees4BList, function(x) rbind.data.frame(c(t(x))))
>     >>
>     >> # This list is a disaster. I am looking for a solution that
>     works in
>     >> this case.
>     >>
>     >> employees4List = list(data.frame(first1 = ("Al"), second1 =
>     "Jones"),
>     >>
>     >> data.frame(first2 = c("Al2", "Barb"), second2 = c("Jones",
>     "Smith")),
>     >>
>     >> data.frame(first3 = c("Al3", "Barbara", "Carol"), second3 =
>     c("Jones",
>     >> "Smith", "Adams")),
>     >>
>     >> data.frame(first4 = ("Al"), second4 = "Jones2"))
>     >>
>     >>? bind_rows(lapply(employees4List, function(x)
>     rbind.data.frame(c(t(x)))))
>     >>
>     >> Thanks.
>     >>
>     >> Ira
>     >>
>     >
>     > --
>     > Sarah Goslee
>     > http://www.functionaldiversity.org
>     <http://www.functionaldiversity.org>
>     >
>     > ______________________________________________
>     > R-help at r-project.org <mailto:R-help at r-project.org> mailing list
>     -- To UNSUBSCRIBE and more, see
>     > https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     > PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     > and provide commented, minimal, self-contained, reproducible code.
>
>     David Winsemius
>     Alameda, CA, USA
>
>     'Any technology distinguishable from magic is insufficiently
>     advanced.'? -Gehm's Corollary to Clarke's Third Law
>
>
>
>
>
>     ? ? ? ? [[alternative HTML version deleted]]
>
>     ______________________________________________
>     R-help at r-project.org <mailto:R-help at r-project.org> mailing list --
>     To UNSUBSCRIBE and more, see
>     https://stat.ethz.ch/mailman/listinfo/r-help
>     <https://stat.ethz.ch/mailman/listinfo/r-help>
>     PLEASE do read the posting guide
>     http://www.R-project.org/posting-guide.html
>     <http://www.R-project.org/posting-guide.html>
>     and provide commented, minimal, self-contained, reproducible code.
>
>


	[[alternative HTML version deleted]]



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Sat Jun 30 11:09:45 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Sat, 30 Jun 2018 21:09:45 +1200
Subject: [R] OT --- grammar.
In-Reply-To: <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
Message-ID: <20180630090945.GA14260@slingshot.co.nz>

How about "Physics / politics / economics are my favoruite subject"?

Might be fun to see how long we could make that list.  It seems to be
a fact of life that it's impossible to make a (useful) language that
has totally consistent grammar.  

Something else to consider:I knew an English teacher who frowned on
what Rolf wrote (to quote) "...almost never .. "  which *should be*
"... hardly ever ... "

How boring it would be if we all agreed. :-)

On Mon, 25-Jun-2018 at 12:16PM +1200, Rolf Turner wrote:

|> On 25/06/18 12:03, Bert Gunter wrote:
|> >Ted, et. al.:
|> >
|> >Re: "Data is" vs "data are" ... Heh heh!
|> >
|> >"This is the kind of arrant pedantry up with which I will not put."
|> >(Attributed to Churchill in one form or another, likely wrongly.)
|> >
|> >See here for some semi-authoritative dicussion:
|> >
|> >http://www.onlinegrammar.com.au/top-10-grammar-myths-data-is-plural-so-must-take-a-plural-verb/
|> 
|> I beg to differ.  "The data was out of date" sounds just plain
|> stupid to my sensitive ears.
|> 
|> It's rather like using the phrase "begs the question" to mean
|> "raises the question" or "invites the question" rather than to
|> carry its *correct* meaning of "assumes what is to be proved".  The
|> fact that the phrase is almost always used in its *incorrect* sense
|> these days, and almost never in its *correct* sense, does not
|> diminish the fact that those who use it incorrectly are ignorant
|> scumbags!  The language is weakened and diminished by the
|> encroachment of incorrect usage.
|> 
|> cheers,
|> 
|> Rolf
|> 
|> 
|> -- 
|> Technical Editor ANZJS
|> Department of Statistics
|> University of Auckland
|> Phone: +64-9-373-7599 ext. 88276
|> 
|> ______________________________________________
|> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
|> https://stat.ethz.ch/mailman/listinfo/r-help
|> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
|> and provide commented, minimal, self-contained, reproducible code.

-- 
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.   
   ___    Patrick Connolly   
 {~._.~}                   Great minds discuss ideas    
 _( Y )_  	         Average minds discuss events 
(:_~*~_:)                  Small minds discuss people  
 (_)-(_)  	                      ..... Eleanor Roosevelt
	  
~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.



From L@P|et@k @end|ng |rom poczt@@|m  Sat Jun 30 11:03:06 2018
From: L@P|et@k @end|ng |rom poczt@@|m (=?UTF-8?b?xYF1a2FzeiBQacSZdGFr?=)
Date: Sat, 30 Jun 2018 11:03:06 +0200
Subject: [R] Question
Message-ID: <hbqeaucobgtjfdbbzufb@kmye>


Hi, My name is Luke and I come from Poland. I have one question, maybe very simple, but I can not resolve it. In dynamic panel data (GMM estimator) after running the model, I recieve a AR test and Sargan test, but the "number of instruments" are not displayed. In Stata and Gretl this informatios is given, in R no. My question is, how to obtain the number of instruments?.
Thank you for helping.
Luke



From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun 30 17:00:46 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 30 Jun 2018 08:00:46 -0700
Subject: [R] OT --- grammar.
In-Reply-To: <20180630090945.GA14260@slingshot.co.nz>
References: <a8cdda40-443a-9e01-8b2b-4d811613f187@auckland.ac.nz>
 <1529880270.3898.26.camel@deb2.fort.knox.uk>
 <CAGxFJbSPGrmA=3vXhe9a9jW9GjRCEg7ghNrEZcpQgZaz2G_MLg@mail.gmail.com>
 <3ce3f4be-4a53-edf6-9c75-b4792d9dcd63@auckland.ac.nz>
 <20180630090945.GA14260@slingshot.co.nz>
Message-ID: <CAGxFJbSQYp3QUOwwEQRGRyS-nRDf_ZqxJNYAcpC+GFnOhKtPEw@mail.gmail.com>

No substantive comment.

But your addendum does bring to mind Gilbert and Sullivan (HMS Pinafore):

"
I am never known to quail At the fury of a gale, And I'm never, never sick
at sea! Chorus. What, never? Captain. No, never! Chorus. What, never?
Captain. Hardly ever! "

https://www.letssingit.com/gilbert-and-sullivan-lyrics-my-gallant-crew-good-morning-fv97wfr
LetsSingIt - The Internet Lyrics Database

Cheers,
Bert


Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 30, 2018 at 2:09 AM, Patrick Connolly <
p_connolly at slingshot.co.nz> wrote:

> How about "Physics / politics / economics are my favoruite subject"?
>
> Might be fun to see how long we could make that list.  It seems to be
> a fact of life that it's impossible to make a (useful) language that
> has totally consistent grammar.
>
> Something else to consider:I knew an English teacher who frowned on
> what Rolf wrote (to quote) "...almost never .. "  which *should be*
> "... hardly ever ... "
>
> How boring it would be if we all agreed. :-)
>
> On Mon, 25-Jun-2018 at 12:16PM +1200, Rolf Turner wrote:
>
> |> On 25/06/18 12:03, Bert Gunter wrote:
> |> >Ted, et. al.:
> |> >
> |> >Re: "Data is" vs "data are" ... Heh heh!
> |> >
> |> >"This is the kind of arrant pedantry up with which I will not put."
> |> >(Attributed to Churchill in one form or another, likely wrongly.)
> |> >
> |> >See here for some semi-authoritative dicussion:
> |> >
> |> >http://www.onlinegrammar.com.au/top-10-grammar-myths-data-
> is-plural-so-must-take-a-plural-verb/
> |>
> |> I beg to differ.  "The data was out of date" sounds just plain
> |> stupid to my sensitive ears.
> |>
> |> It's rather like using the phrase "begs the question" to mean
> |> "raises the question" or "invites the question" rather than to
> |> carry its *correct* meaning of "assumes what is to be proved".  The
> |> fact that the phrase is almost always used in its *incorrect* sense
> |> these days, and almost never in its *correct* sense, does not
> |> diminish the fact that those who use it incorrectly are ignorant
> |> scumbags!  The language is weakened and diminished by the
> |> encroachment of incorrect usage.
> |>
> |> cheers,
> |>
> |> Rolf
> |>
> |>
> |> --
> |> Technical Editor ANZJS
> |> Department of Statistics
> |> University of Auckland
> |> Phone: +64-9-373-7599 ext. 88276
> |>
> |> ______________________________________________
> |> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> |> https://stat.ethz.ch/mailman/listinfo/r-help
> |> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> |> and provide commented, minimal, self-contained, reproducible code.
>
> --
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>
>    ___    Patrick Connolly
>  {~._.~}                   Great minds discuss ideas
>  _( Y )_                 Average minds discuss events
> (:_~*~_:)                  Small minds discuss people
>  (_)-(_)                              ..... Eleanor Roosevelt
>
> ~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.~.
>

	[[alternative HTML version deleted]]



From @k@h@y_e4 @end|ng |rom hotm@||@com  Sat Jun 30 19:07:49 2018
From: @k@h@y_e4 @end|ng |rom hotm@||@com (akshay kulkarni)
Date: Sat, 30 Jun 2018 17:07:49 +0000
Subject: [R] parallel processing in r...
Message-ID: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>

dear members,
                             I am using mclapply to parallelize my code. I am using Red Hat Linux in AWS.

When I use mclapply, I see no speed increase. I doubt that the Linux OS is allowing fewer than the maximum number of cores to mclapply ( by default, mclapply takes all the available cores to it).

How do you check if the number of workers is less than the output given by detectCores(), in Linux? Is there any R function for it?

I do acknowledge that help on an OS is not suitable for this mailing list, but even Internet could'nt help me. Therefore this mail......

very many thanks for your time  and effort...
yours sincerely,
AKSHAY M KULKARNI

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun 30 19:41:35 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 10:41:35 -0700
Subject: [R] Question
In-Reply-To: <hbqeaucobgtjfdbbzufb@kmye>
References: <hbqeaucobgtjfdbbzufb@kmye>
Message-ID: <8FEC5AE2-3344-4050-B4F9-1AA3E5052061@dcn.davis.ca.us>

Your question is notable for what it is missing... any trace of R code. [1][2][3] Do read the Posting Guide.

I don't see "Sargan" in base R, so your analysis likely used a contributed package... there seem to be a couple, so your example code would clarify. I don't see the number of IVs listed in the print result of the ivmodels package, so you might have to use length( Z ) (your input) to record that. Note that it is typical of stats models in R to report degrees of freedom rather than number of inputs, so this may be intentional.

You should also keep in mind that contributed packages are maintained by their contributors. If they turn out to be missing features then adding those features will involve communicating with those contributors as indicated in the package DESCRIPTION file (summarized on the CRAN web site)... they may or may not subscribe to this mailing list.

[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 



On June 30, 2018 2:03:06 AM PDT, "?ukasz Pi?tak" <L.Pietak at poczta.fm> wrote:
>
>Hi, My name is Luke and I come from Poland. I have one question, maybe
>very simple, but I can not resolve it. In dynamic panel data (GMM
>estimator) after running the model, I recieve a AR test and Sargan
>test, but the "number of instruments" are not displayed. In Stata and
>Gretl this informatios is given, in R no. My question is, how to obtain
>the number of instruments?.
>Thank you for helping.
>Luke
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bgunter@4567 @end|ng |rom gm@||@com  Sat Jun 30 20:14:57 2018
From: bgunter@4567 @end|ng |rom gm@||@com (Bert Gunter)
Date: Sat, 30 Jun 2018 11:14:57 -0700
Subject: [R] parallel processing in r...
In-Reply-To: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <CAGxFJbTh7ie-AgkUz1ikTre0PTOMOaEbMXzmsijBx+=2ithKLw@mail.gmail.com>

The effectiveness of parallelizing code, be it with mclapply or otherwise,
depends in large part on the code, which you failed to show.

I cannot answer your other question.

Cheers,
Bert



Bert Gunter

"The trouble with having an open mind is that people keep coming along and
sticking things into it."
-- Opus (aka Berkeley Breathed in his "Bloom County" comic strip )

On Sat, Jun 30, 2018 at 10:07 AM, akshay kulkarni <akshay_e4 at hotmail.com>
wrote:

> dear members,
>                              I am using mclapply to parallelize my code. I
> am using Red Hat Linux in AWS.
>
> When I use mclapply, I see no speed increase. I doubt that the Linux OS is
> allowing fewer than the maximum number of cores to mclapply ( by default,
> mclapply takes all the available cores to it).
>
> How do you check if the number of workers is less than the output given by
> detectCores(), in Linux? Is there any R function for it?
>
> I do acknowledge that help on an OS is not suitable for this mailing list,
> but even Internet could'nt help me. Therefore this mail......
>
> very many thanks for your time  and effort...
> yours sincerely,
> AKSHAY M KULKARNI
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/
> posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun 30 20:16:19 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 11:16:19 -0700
Subject: [R] parallel processing in r...
In-Reply-To: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
Message-ID: <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>

Use "top" at the bash prompt.

Read about the "mc.cores" parameter to mclapply.

Make a simplified example version of your analysis and post your question in the context of that example [1][2][3]. You will learn about the issues you are dealing with in the process of trimming your problem, and will have code you can share that demonstrates the issue without exposing private information.

Running parallel does not necessarily improve performance because other factors like task switching overhead and Inter-process-communication (data sharing) can drag it down. Read about the real benefits and drawbacks of parallelism... there are many discussions out there out there... you might start with [4].


[1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example

[2] http://adv-r.had.co.nz/Reproducibility.html

[3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette) 

[4] https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html

On June 30, 2018 10:07:49 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>dear members,
>I am using mclapply to parallelize my code. I am using Red Hat Linux in
>AWS.
>
>When I use mclapply, I see no speed increase. I doubt that the Linux OS
>is allowing fewer than the maximum number of cores to mclapply ( by
>default, mclapply takes all the available cores to it).
>
>How do you check if the number of workers is less than the output given
>by detectCores(), in Linux? Is there any R function for it?
>
>I do acknowledge that help on an OS is not suitable for this mailing
>list, but even Internet could'nt help me. Therefore this mail......
>
>very many thanks for your time  and effort...
>yours sincerely,
>AKSHAY M KULKARNI
>
>	[[alternative HTML version deleted]]
>
>______________________________________________
>R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>https://stat.ethz.ch/mailman/listinfo/r-help
>PLEASE do read the posting guide
>http://www.R-project.org/posting-guide.html
>and provide commented, minimal, self-contained, reproducible code.

-- 
Sent from my phone. Please excuse my brevity.



From bog@@o@chr|@to|er @end|ng |rom gm@||@com  Sat Jun 30 21:39:14 2018
From: bog@@o@chr|@to|er @end|ng |rom gm@||@com (Christofer Bogaso)
Date: Sun, 1 Jul 2018 01:09:14 +0530
Subject: [R] A question on Statistics
Message-ID: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>

Hi,

I have a quick question on Statistical distribution as follows, hoping
Statisticians here would give me very insightful feedback.

Say, I have a large sample from a highly asymmetric distribution ranging
from -Inf to +Inf. Now I wish to calculate sample X1 and X2 within which
middle 70% probability would reside.

One approach
x = my sample
calculatte quantile(x, prob = 15%) & quantile(x, prob = 85%)

another approach
calculate quantile(abs[x], prob = 85%)
In this case X1 and X2 would be +/- of above result.

My question is in all scenarios, are above two approach equivalent? If not
which is the better approach to find such range.

Thanks,

	[[alternative HTML version deleted]]



From jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@  Sat Jun 30 21:51:50 2018
From: jdnewm|| @end|ng |rom dcn@d@v|@@c@@u@ (Jeff Newmiller)
Date: Sat, 30 Jun 2018 12:51:50 -0700 (PDT)
Subject: [R] A question on Statistics
In-Reply-To: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
References: <CA+dpOJnYysBxJaJTV998e9TUYT9yU3H2G5BWnwZNiWd93H_Ozw@mail.gmail.com>
Message-ID: <alpine.BSF.2.00.1806301246530.63310@pedal.dcn.davis.ca.us>

You should use Stack Exchange for questions about statistics.

You should also think a bit before you post, regardless of where. You are 
the one who described this as a highly asymmetric distribution, and didn't 
say anything about it being centered at zero. You already answered your 
own question, to the extent that it can be answered.

On Sun, 1 Jul 2018, Christofer Bogaso wrote:

> Hi,
>
> I have a quick question on Statistical distribution as follows, hoping
> Statisticians here would give me very insightful feedback.
>
> Say, I have a large sample from a highly asymmetric distribution ranging
> from -Inf to +Inf. Now I wish to calculate sample X1 and X2 within which
> middle 70% probability would reside.
>
> One approach
> x = my sample
> calculatte quantile(x, prob = 15%) & quantile(x, prob = 85%)
>
> another approach
> calculate quantile(abs[x], prob = 85%)
> In this case X1 and X2 would be +/- of above result.
>
> My question is in all scenarios, are above two approach equivalent? If not
> which is the better approach to find such range.
>
> Thanks,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
> https://stat.ethz.ch/mailman/listinfo/r-help
> PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
> and provide commented, minimal, self-contained, reproducible code.
>

---------------------------------------------------------------------------
Jeff Newmiller                        The     .....       .....  Go Live...
DCN:<jdnewmil at dcn.davis.ca.us>        Basics: ##.#.       ##.#.  Live Go...
                                       Live:   OO#.. Dead: OO#..  Playing
Research Engineer (Solar/Batteries            O.O#.       #.O#.  with
/Software/Embedded Controllers)               .OO#.       .OO#.  rocks...1k



From p_conno||y @end|ng |rom @||ng@hot@co@nz  Sat Jun 30 23:05:33 2018
From: p_conno||y @end|ng |rom @||ng@hot@co@nz (Patrick Connolly)
Date: Sun, 1 Jul 2018 09:05:33 +1200
Subject: [R] parallel processing in r...
In-Reply-To: <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
References: <SL2P216MB009102A054E8184CB0F5B1BBC84D0@SL2P216MB0091.KORP216.PROD.OUTLOOK.COM>
 <845BDBA2-B070-4F09-9F64-3246B789307D@dcn.davis.ca.us>
Message-ID: <50d1370d-9783-1917-e37b-c96b2142fc79@slingshot.co.nz>

If you use gkrellm, you'll get a plot of each core's activity so it's 
easy to see how many are being used.

yum install gkrellm.


HTH

On 07/01/2018 06:16 AM, Jeff Newmiller wrote:
> Use "top" at the bash prompt.
>
> Read about the "mc.cores" parameter to mclapply.
>
> Make a simplified example version of your analysis and post your question in the context of that example [1][2][3]. You will learn about the issues you are dealing with in the process of trimming your problem, and will have code you can share that demonstrates the issue without exposing private information.
>
> Running parallel does not necessarily improve performance because other factors like task switching overhead and Inter-process-communication (data sharing) can drag it down. Read about the real benefits and drawbacks of parallelism... there are many discussions out there out there... you might start with [4].
>
>
> [1] http://stackoverflow.com/questions/5963269/how-to-make-a-great-r-reproducible-example
>
> [2] http://adv-r.had.co.nz/Reproducibility.html
>
> [3] https://cran.r-project.org/web/packages/reprex/index.html (read the vignette)
>
> [4] https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
>
> On June 30, 2018 10:07:49 AM PDT, akshay kulkarni <akshay_e4 at hotmail.com> wrote:
>> dear members,
>> I am using mclapply to parallelize my code. I am using Red Hat Linux in
>> AWS.
>>
>> When I use mclapply, I see no speed increase. I doubt that the Linux OS
>> is allowing fewer than the maximum number of cores to mclapply ( by
>> default, mclapply takes all the available cores to it).
>>
>> How do you check if the number of workers is less than the output given
>> by detectCores(), in Linux? Is there any R function for it?
>>
>> I do acknowledge that help on an OS is not suitable for this mailing
>> list, but even Internet could'nt help me. Therefore this mail......
>>
>> very many thanks for your time  and effort...
>> yours sincerely,
>> AKSHAY M KULKARNI
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-help at r-project.org mailing list -- To UNSUBSCRIBE and more, see
>> https://stat.ethz.ch/mailman/listinfo/r-help
>> PLEASE do read the posting guide
>> http://www.R-project.org/posting-guide.html
>> and provide commented, minimal, self-contained, reproducible code.


	[[alternative HTML version deleted]]



